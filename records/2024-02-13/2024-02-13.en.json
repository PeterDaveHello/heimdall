[
  {
    "id": 39344956,
    "title": "Cloudflare triumphs over patent troll Sable in trial",
    "originLink": "https://blog.cloudflare.com/cloudflare-defeats-patent-troll-sable-at-trial",
    "originBody": "Cloudflare defeats patent troll Sable at trial 02/12/2024 Patrick Nemeroff Emily Terrell 8 min read For almost seven years, Cloudflare has been fighting against patent trolls. We’ve been doing this successfully through the efforts of our own legal team, external counsel, and the extraordinary efforts of people on the Internet looking for prior art (and getting rewarded for it) through our Project Jengo. While we refuse to pay trolls for their meritless claims, we’ve been happy to award prizes to Project Jengo participants who help stop the trolls through prior art that invalidates their patents or claims. Project Jengo participants helped us in the past roundly beat the patent troll Blackbird (who subsequently went out of business). Today, we’re back to talk about yet another win thanks to a lot of work by us, our external counsel, and Project Jengo participants. Sable Last Thursday, on a clear, sunny morning in Waco, Texas, a jury returned a verdict after less than two hours of deliberation. The jury found that Cloudflare did not infringe the patent asserted against Cloudflare by patent trolls Sable IP and Sable Networks. And while that would have been enough to decide the case by itself, the jury went further and found that Sable’s old and broadly-written patent claim was invalid and never should have been granted in the first place–meaning they can no longer assert the claim against anyone else. Since Sable first sued us, we’ve invalidated significant parts of three Sable patents, hamstringing their ability to bring lawsuits against other companies. It’s worth noting that very few lawsuits ever reach a jury. Most non-lawyers are shocked to learn that only about 1% of civil cases make it to trial, because trials are generally what they see on TV or in film. But professional litigators know that almost all cases are resolved much earlier through procedures that are much less entertaining to watch on screen: written motions, delay, or settlement. A big reason for this is that taking a case to trial–even on simple matters–is extremely costly. In patent cases, that means millions of dollars. As we described in our first Project Jengo blog post, these costs are the threat that patent trolls rely on to extract sizable settlements out of innovative technology companies. It’s often easier for technology companies to pay a settlement rather than pay millions more in litigation costs that likely can’t be recovered even if the technology company wins. Patent trolls usually don’t want to incur the costs of going to trial either, but they typically wait for the other side to blink first and pay up–especially because the company accused of infringement is the one that faces the risk of a bad verdict and damages award. But every once in a while the target doesn’t blink. Cloudflare’s hard fought victory, the culmination of three years of litigation, is a strong warning to all patent trolls–we will not be intimidated into playing your game. Background Let’s recap how we got here. This case began in March 2021 when Sable Networks and Sable IP filed a complaint against Cloudflare in federal court. Sable asserted around 100 claims spanning four patents against multiple Cloudflare products and features. The patents relied on by Sable were filed around the turn of the century, and they addressed the hardware-based router technology of the day. More specifically, they addressed a particular type of hardware focused on “flows'' composed of multiple linked packets. This approach is not used by modern-day software-defined services delivered on the cloud, particularly not services like Cloudflare that handle traffic on a packet-by-packet basis. But that didn’t stop Sable from arguing its broadly-worded patents covered essentially all router operations, including Cloudflare’s cutting edge technology–well beyond what the asserted patent claims were ever intended to cover. As with many patent trolls, Sable IP has never made or sold products and doesn’t employ a single person to create or design actual technology. Sable IP was created as a shell entity in 2020 to monetize the patent portfolio of Sable Networks, which itself was formed in 2006 and allegedly acquired the assets–including the patents–of Caspian Networks, a router company that had shuttered its operations. Sable IP is one of many such shell entities formed to “monetize” patents through lawyer-driven litigation campaigns. Cloudflare wasn’t Sable’s only target. Sable sued a number of other companies, including Cisco, Fortinet, Check Point, SonicWall, Juniper Networks, and others, each of which eventually resolved the lawsuit against them out of court. Cloudflare took a different approach. To kick off our fight against Sable, we launched another round of Project Jengo, crowdsourcing submissions of prior art for all of Sable’s active patents–including patents not asserted against Cloudflare–and committing a $100,000 award to be split among winners that submitted strong prior art. Dedicated readers will remember Cloudflare’s first round of Project Jengo, which helped put the notorious patent troll Blackbird out of business. We’ve received dozens of submissions since we launched this Sable-focused round of Project Jengo, and have awarded \\$70,000 since 2021. We will distribute the remaining \\$30,000 to winners of the Final Awards which we will announce after the official conclusion of the case per the Project Jengo Rules. Relying on prior art, we filed petitions for inter partes review to the U.S. Patent and Trademark Office (“USPTO”) seeking to invalidate Sable’s patents. The inter partes process is an administrative proceeding that involves filing briefs for administrative patent judges at the USPTO to determine if a patent should have been issued in the first place. In many cases it's a helpful process available to try and limit the threat of patent trolls. In May 2022, to avoid responding to one of those petitions–and to avoid the risk that its patent would be canceled altogether–Sable voluntarily canceled all of the claims asserted against Cloudflare under one of its patents. And in January 2023, we were successful in invalidating the portions of a second Sable patent that had been asserted against us. Two patents down, Sable refused to give up. By December 2023, through its petitions to the USPTO and related motions before the court, Cloudflare had successfully narrowed the number of patents and claims at issue from approximately 100 claims across four, to just five claims from two patents. Then, at the pretrial conference on December 13, 2023, the court issued summary judgment in our favor on a third Sable patent. Summary judgment is a process where the court determines that an argument is so clear that no reasonable jury could rule otherwise. This further narrowed the case to a single asserted claim on a single patent–claim 25 of U.S. Patent No. 7,012,919. Through years of hard work, we’d successfully whittled down Sable’s case from about 100 claims across four patents to just one claim of one patent. But despite all that success, the fact remained…we were heading to trial, and it can be difficult to know what a jury will decide–and what damages they may award–on heavily technical issues. Trials and tribulations for Sable IP and Sable Networks We weren’t just heading to trial, we were heading to the Western District of Texas. Waco, Texas, to be precise, where Sable chose to file its lawsuit. The Western District of Texas has in recent years become a popular venue for patent plaintiffs, as it has a reputation for being a friendly jurisdiction for patent holders. Sable’s trial story was not compelling. On the technical merits, Sable had the unenviable task of trying to map decades-old flow-based hardware router technology onto Cloudflare’s modern, software-defined packet-by-packet architecture. They attempted to do so through a series of hand waving exercises, equating the “line cards” required by the patent to various different software and hardware used by Cloudflare, and suggesting that any flow of packets across Cloudflare’s network could be construed as the specific “micro-flows” at the center of its patent. Beyond the technical issues, Sable’s story was simple, though not very attractive–Sable wanted money. Having acquired rights to the patents of a failed hardware company, they were seeking to “monetize” those patents to the greatest extent possible. If that meant leveraging a patent related to decades-old router hardware to sue a cloud-based service provider, so be it. And if it required leaps of logic and untethered claims that might make a toddler blush, oh well. When it was our turn, we told the jury our story. How Cloudflare was founded to help build a better Internet by moving past old, hardware-based solutions to new, cloud-based solutions delivered through our global network. We explained the hard work put into building our network, and all the services that sit on top of it. One of our outstanding engineers described what it’s like to create a new product, working with teams of engineers, product managers, and others to bring something exciting to the market for the first time. We drilled down into Sable’s twenty-year old patent, explaining the many reasons why the patent does not describe anything that Cloudflare actually does. Among other things, the patent requires various steps to be performed at a “line card,” and Cloudflare’s accused edge servers don’t include a single such line card. And while the patent focused on flow-based routing, Cloudflare designed its system to perform packet-by-packet inspection to protect against malicious traffic. We also explained that the patent claim asserted against Cloudflare is invalid–and never should have been issued–because it was obvious in view of the prior art and lacked the required written description. In fact, Sable’s patent covered, at best, only technology that had already been described by inventors at Nortel Networks and Lucent Technologies–leading routing technology companies at the time. During closing arguments, Cloudflare’s trial lawyer made one thing clear–this case was about more than Sable or Cloudflare. The patent system was designed to foster innovation and promote the progress of science, but what Sable was doing was exactly the opposite: bringing meritless cases in an effort to turn a buck, and stifling progress in the process. That distortion and abuse of the patent system has to stop and, ultimately, only the jury had the power to end it. To our great satisfaction, the jury answered that call. The jury’s decision did not take long. Less than two hours after leaving the courtroom to deliberate, the jury returned with a verdict that sends a message far beyond the courthouse. No infringement by Cloudflare, and Sable’s patent is invalid. The combined Cloudflare and external counsel team What’s next We’ll enjoy this verdict for a long time, but the hard work doesn’t stop here. Cloudflare is dedicated to rebalancing a system that is being distorted by trolls like Sable. As part of our efforts, we look forward to announcing the final awards for Project Jengo on this blog following the conclusion of the case. We’ll also plan to share additional thoughts and insights we’ve gleaned from facing down a troll at trial. For now, we want to express our sincere gratitude to the judge and jury for the hard work they put in at trial, including the jury weighing the evidence and understanding the complex technology at issue in the case. Cloudflare is deeply grateful for the jury’s time and efforts over the past week, its careful consideration of all the facts, and for its verdict. We also again want to thank our amazing trial lawyers from Charhon Callahan Robson & Garza PLLC, and The Dacus Firm. If you end up with a patent troll problem, we recommend them highly. We protect entire corporate networks, help customers build Internet-scale applications efficiently, accelerate any website or Internet application, ward off DDoS attacks, keep hackers at bay, and can help you on your journey to Zero Trust. Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer. To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Discuss on Hacker News JengoSable",
    "commentLink": "https://news.ycombinator.com/item?id=39344956",
    "commentBody": "Cloudflare defeats patent troll Sable at trial (cloudflare.com)1001 points by jgrahamc 19 hours agohidepastfavorite362 comments yashap 15 hours agoNice to see Cloudflare fighting the good fight, but patent trolls aren’t the only issue with software patents. A major issue that people talk about way less is well funded/large companies getting bullshit patents, and using them to sue their small startup competitors into the ground. It doesn’t even matter if they win - when a company with billions in the bank sues a company with millions in the bank, the small company is basically just screwed no matter what because they can’t afford the legal fees. It’s a cheap way for big, bloated, slow moving companies to eliminate fast moving, lean, disruptive competition. A major source of this problem IMO is the granting of bullshit patents in the first place - patents that should never have been granted because they’re obvious and/or there was prior art. Patent clerks aren’t actually subject matter experts in the field, and there’s little incentive for them to deny bullshit patents. They maybe deny them once or twice, but dedicated companies just keep applying and eventually get them granted, because the applicant has a major incentive to get the bullshit patent, and the patent office has only minor incentives to deny bullshit patents. I think these incentives need to be changed - for example, if company A sues company B over patent C, company B spends $10 million on their defence, and wins with the patent being deemed invalid, I think company B should get MAJOR financial rewards from BOTH company A and the patent office, on the order of 10x+ what they spent on their defence. If granting a bullshit patent was a $100 mil mistake, patent offices would be WAY more careful with the patents they grant, and applying for patents would be WAY more expensive, and those are both good things! The right incentives could keep the good parts of the patent system while eliminating the (currently pretty massive, out of control) downsides. Patents are currently a mediocre idea implemented incredibly poorly. reply Calavar 10 hours agoparent> company B should get MAJOR financial rewards from BOTH company A and the patent office, on the order of 10x+ what they spent on their defence By \"the patent office\" you mean taxpayers, right? Because we're the ones who foot the bill for any judgement against the government. I can't see any situation where individual patent clerks would be held accountable. First, it goes against established case law regarding civil cases against federal employees [1, 2]. Second, if you amend the law so that patent clerks are an exception and can be held individually liable for potentially tens of millions of dollars, only absolute idiots would agree to take that job. [1] https://www.justice.gov/jm/civil-resource-manual-33-immunity... [2] https://www.ojp.gov/ncjrs/virtual-library/abstracts/personal... reply scrubs 8 hours agorootparentThe idea would be for the patent office to get $I dollars funding from tax payers, from which they payouts are made when errors are made. If they flub it year after year they'd be forced into process improvements or a huge fight with Congress. Basically, as soon as control becomes separated from accountability, one organizationally hit into these problems. Another analogy: I'm sort of against housing brokers passing the mortgage onto Fannie Mae. By the time the government finds out something is wrong, it may be too late to \"untake\" the property. Brokers have short-term control goals and short term risk profile. They stick somebody else with the long term disk, while they're still paid. It's a misalignment. reply acomjean 5 hours agorootparentprevI believe that patent office budget is mostly fees. reply dataflow 9 hours agorootparentprev> By \"the patent office\" you mean taxpayers, right? Because we're the ones who foot the bill for any judgement against the government. I think they meant the patent office should cover that from fees, not from taxpayers. reply lolinder 9 hours agorootparentThat doesn't really help because money is fungible. In a city near me the taxpayers recently rejected a tax increase to pay for a bond because they were grumpy that the government took out the bond without asking them first. The city was still on the hook for the bond, so they just siphoned money from the roads fund. The same thing would happen here—you can say that the judgment must come from fees, but then the patent office will have to either raise fees to crazy levels in order to cover the risk (thus making patents even more of a large company advantage) or they'll siphon money from things that were being covered by fees and use taxpayer dollars to cover those things. reply jedberg 9 hours agorootparentprevThen the fees would be so high only the biggest companies could afford to file patents. reply joshuaissac 15 hours agoparentprevI think this is the main problem, rather than companies owning patents they do not implement, and suing the ones that do without a licence. There are so many bogus patents being granted. Prior art search done by patent clerks, from what I have read, can just be searching existing patents. So if something was invented long ago but never patented, then that might not even be caught in a search, even if there are many web pages or academic papers that describe that prior art. And like you said, they may not be able to realise that the invention is actually obvious, because they are not subject matter experts. There is another problem where the patent is valid but the defendant's product does not violate it. It is often too expensive for the victim to litigate it in court. Depending on the jurisdiction, the plaintiff may not even have to tell you exactly which patents they are alleging that you have violated, until they sue you. So you cannot even check whether their claim is reasonable. It needs to be easier and cheaper to challenge bad patents and false claims of infringement. reply Intermernet 43 minutes agoparentprevIf companies are found to have filed bad faith patents, there should be a rapidly escalating cost increase for future patents, ending in penalties including their existing patents being legally released into the public domain. There is, of course, the usual problems of companies spinning up shell companies to mitigate the risk, but that's a different problem that needs fixing for a whole bunch of reasons. reply jedberg 9 hours agoparentprev> patent clerks aren’t actually subject matter experts in the field This is sometimes true, but also isn't super relevant. The patent office contracts out to experts to help them evaluate a patent. My friend worked as one of these contractors. He would get patents in his field of expertise in which he holds a PhD and had 15 years of work experience, and then write a report and do the prior art searches. He would then send his report back to the patent clerk. The reason you get BS patents is because they only give the clerk a small amount of time to make a decision, so they have to work with whatever info they have -- they don't have time to seek out additional information. The patent office needs a lot more funding if you want it to be effective. reply btrettel 5 hours agorootparent> The reason you get BS patents is because they only give the clerk a small amount of time to make a decision, so they have to work with whatever info they have -- they don't have time to seek out additional information. As a former USPTO patent examiner, I can confirm that this is the main reason for low patent quality. > This is sometimes true, but also isn't super relevant. The patent office contracts out to experts to help them evaluate a patent. My friend worked as one of these contractors. He would get patents in his field of expertise in which he holds a PhD and had 15 years of work experience, and then write a report and do the prior art searches. He would then send his report back to the patent clerk. I never found the contract search help to be useful. (\"STIC search\" is what I'm thinking of. Your friend may have been on a different contract as I'm not familiar with specific contract subject matter experts providing search help.) I'd guess that the problem is that those folks get even less time than I did! reply bhaney 9 hours agoparentprev> patent trolls aren’t the only issue with software patents. A major issue that people talk about way less is well funded/large companies getting bullshit patents, and using them to sue their small startup competitors into the ground Those companies are patent trolls, not a separate issue. They don't stop being patent trolls just because they're large and well known. reply MobiusHorizons 2 hours agorootparentThere are two important differences. 1 Patent trolls are non practicing entities, ie they don’t produce anything other than lawsuits(pure rent seeking), big companies may not be producing on all of their patents, but they typically provide at least some societal value. 2 big companies aren’t typically making direct revenue from their patents, but rather use them as a moat to prevent challengers (which seems more similar to what patents are intended for even if it is often abused by being overly broad) reply bhaney 59 minutes agorootparent> Patent trolls are non practicing entities That's not a part of any commonly accepted definition of \"patent troll\" that I'm aware of, but of course NPEs can also be patent trolls. > use them as a moat to prevent challengers This is what makes one a patent troll. reply shiroiushi 2 minutes agorootparent>That's not a part of any commonly accepted definition of \"patent troll\" that I'm aware of It's exactly the definition I've heard of for the past 20+ years. >This is what makes one a patent troll. No, it isn't. Think about what a troll does: it hides under a publicly-owned bridge, and then forces anyone who wants to cross the bridge to pay a toll. This is exactly what the NPEs do with their BS patents: they get a patent on some obvious BS, and then charge people money to use \"their IP\". Big companies don't do this: they use patents to prevent competitors from operating. They don't grant licenses to their competitors at all. Trolls in mythology didn't refuse bridge access to anyone, they just forced them to pay a toll. The entire point of being an NPE is to get money from licensing (and lawsuits). bsimpson 4 hours agoparentprevI work at a large company. A colleague of mine filed a patent for a thing we were working on, and included me in the list of inventors. I spent that summer trading emails with lawyers trying to get the application to even resemble what we were actually doing. The patent was for computer animation, and the application had fucking clip art of printers and pagers and 50 pages of \"and this is novel because computers are shiny\" and \"if you figure out how to do this with a toaster, we've called dibs.\" I'm proud of the work I was doing; we were legitimately working at the frontier of motion design. It's cool that my name is in the historical record for that, but it's also embarrassing that it's in the form of a software patent - particularly one that looked like it had been copy/pasted from decades of bullshit patents and barely adapted to cover what we were actually proposing. Whatever little faith you have in the patent system will be even further eroded if you ever find yourself on the filing side of the patent. It shocked me how much of the application was broad and hand-wavey, citing irrelevant and obsolete technology to pad out the pages. Even worse, they didn't seem to care to understand the actual \"invention.\" If I didn't fight back, they would have filed (and probably won) something that could have been generated with the prompt \"please write me a generic patent application to pad out a tech company's portfolio.\" reply mcmoor 8 hours agoparentprevI think the most fatal flaw is, and in all other fields too, that money correlates with court victory. If we somehow able to erase just that, lots of laws suddenly becomes much fairer and closer to its original intent. reply zomgbbq 9 hours agoparentprevSounds like a problem AI could solve filtering patent applications before they make it to a person. reply btrettel 5 hours agorootparentFormer patent examiner here. Current AI patent search isn't that useful in my experience. The USPTO had multiple AI patent search tools circa 2022 (when I quit), most of which were of comparable quality to the similar documents listed at the bottom of a patent document on Google Patents. I've posted before about some of the issues here: https://news.ycombinator.com/item?id=33506286 reply mike_hock 12 hours agoparentprevSimple solution: Abolish patents. All the rhetoric about incentivizing innovation is bullshit. They stifle innovation, and they stifle competition. They're designed to protect slow, inefficient established corporations. That's all they ever did and that's all they'll ever do. reply palata 11 hours agorootparentI think it's a bit more nuanced than that, because in some industries patents may make sense. I would say \"Simple solution: abolish patents on software\". reply mopenstein 9 hours agorootparentprevPatents and copyrights are dangled like winning lottery tickets in front of the average citizen. Maybe you can invent something or write a book and sell it for millions! Which does happen... about as often as people win the lottery. More often a patent or copyright is one of thousands a giant company procures. But all the intellectual property profiteers need is that 1 in 300,000,000 chance dangling in front of a voter and they'll never agree to do away with IP, in fact, the opposite will happen. They'll actively fight to keep them in place. reply paledot 8 hours agorootparentSomehow the winning ticket in popular discourse is to be a patent troll: at best, \"sell my idea\" to some big company (troll); at worst convince a court to give you a pile of money because someone \"stole\" your idea (in advance). It is a rare person who dreams of coming up with a good idea and then working hard for years to make it a reality. reply freejazz 7 hours agorootparentHow many patent trolls do you know? As compared to people that you know who would/could be an inventor on a patent? I'm a patent litigator and it's still the latter for me. This narrative is a bit histrionic. reply chefandy 10 hours agorootparentprevI reckon simple solutions are often simple because they ignore important complexities. I'd love to abolish patents, but I don't see how our society could before figuring out stuff like how else to support the people that do important knowledge work, and incentivizing creating new things when it's a hell of a lot more profitable to just wait until someone else does it first. The software industry is already compatible enough that many companies open source their code voluntarily, but I don't see how we can generalize that. What incentive would companies have to pour all of those resources into complex chip design, intricate novel medical devices, or new medicine? You might be able to have open source insulin pump controllers, but how about a lifesaving new linear accelerator or chemotherapy drug when your competitor could just pay your lead engineer half of your 9 figure R&D budget to completely replicate the process and hit the market at nearly the same time? I'd love if this work could be done by universities or publicly funded because it so obviously benefits the greater good, but it's not, and that seems like a prerequisite you simply can't ignore. I'd love to be proven wrong, but I think the \"well if you wanna make an omelet...\" kind of attitude I usually see accompany sentiments like this seem more edge-lordy than anything else. reply sircastor 10 hours agorootparentprevI don't think they're designed to project established corporations, but lawyers move faster than congress. So much like the Tax code, they've already figured out how to take advantage of the existing system. In fact, I would say the ultimate realization of that is the existence of patent-trolls. The patent-holder which exists solely for the purpose of possessing the patent rather than creating it, or utilizing it to make their own product. reply ClassyJacket 11 hours agorootparentprevAgreed. I shouldn't be banned from inventing something just because somebody else already invented it. Patents suck. reply jMyles 11 hours agorootparentprevHear hear. But how? reply JumpCrisscross 8 hours agorootparentprev> Abolish patents. All the rhetoric about incentivizing innovation is bullshit. Oh, I would immediately start a fund that looks for good ideas at the germinating phase and then superfunds a competitor. reply froggertoaster 14 hours agoparentprev> A major issue that people talk about way less is well funded/large companies getting bullshit patents, and using them to sue their small startup competitors into the ground. Do you have any examples? reply jwr 18 hours agoprevWorth mentioning: Newegg is another company that doesn't blink and goes after patent trolls with a vengeance, at least they used to: https://www.newegg.com/insider/newegg-vs-patent-trolls-when-... reply adabyron 18 hours agoparentI don't believe they still do this & not sure their culture is the same. They were purchased by a company based out of China years ago. Lee Cheng I believe is responsible for a lot of that effort. He no longer works there. reply schmichael 18 hours agoprev> One of our outstanding engineers described what it’s like to create a new product This is a good reminder to enthusiastically help out your legal team if your company is the target of trolls! I had the opportunity to do it once. Our legal team was helpful, patient, and curious. The work was pretty annoying because you have to try to help them work out whether some bizarrely worded unrelated thing could possibly be construed to be part of our product. In our case the troll went away as soon as we made it clear we were serious about taking it to court. I cannot tell you how thankful I am for Cloudflare taking it as far as they can. The cost and risk must be considerable to them. reply creeble 16 hours agoprevNo mention of Cloudflare’s own large portfolio of software patents. Wonder when they’ll start enforcing their patent on CNAME flattening, for example: https://patents.justia.com/patent/11159479 Edit; clarity reply empath-nirvana 15 hours agoparentIt's a defensive patent portfolio. They use it to counter sue if a competitor sues them. reply greyface- 11 hours agorootparentHave they made any commitments, binding or non-binding, to this effect? reply hot_gril 10 hours agorootparentThat might reduce the effectiveness of this strategy. reply lathiat 7 hours agorootparentThere is precedent for this kindof thing: https://en.wikipedia.org/wiki/Open_Invention_Network reply greyface- 9 hours agorootparentprevHow would a commitment to not use their patent portfolio offensively prevent them from effectively using it defensively? reply hot_gril 9 hours agorootparentFor the commitment to be meaningful at all, it has to be partially binding, which could be exploited. And a totally nonbinding one could just as easily be given by a patent troll. reply remram 9 hours agorootparent> For the commitment to be meaningful at all, it has to be partially binding A non-binding and less-meaningful commitment would still be something. They could easily start there and they have not. reply hot_gril 9 hours agorootparentI don't see what they'd gain from that. Also, could calling your own patents \"defensive\" be seen as admission that they're bogus? reply EvanAnderson 15 hours agorootparentprevEdit: Removed a bone-headed hypothetical. reply toast0 14 hours agorootparent> My understanding is a patent holder must defend their rights, if they are aware of the infringement, at the peril of losing them. Pretty sure that's just for trademarks. reply EvanAnderson 13 hours agorootparentAgh. Absolutely. Wrong flavor of \"intellectual property\". Thanks. reply michael1999 11 hours agorootparentAnd that's why Stallman is so firm that there is no such thing as \"intellectual property\". As soon as you start using that term, you start believing there is something more general and meaningful to it and start muddying the concepts. But it is just a mirage. https://www.gnu.org/philosophy/not-ipr.en.html reply brlewis 14 hours agorootparentprevYou lose a trademark if you don't defend it. I don't believe the same is true of patents. reply EvanAnderson 13 hours agorootparentMy face is red. Thanks. I didn't stop and think long enough before I posted. reply rainsford 9 hours agoparentprevI recognize my position is far from airtight, but I'm honestly way, way less bothered by the fact that companies like Cloudflare have a large patent portfolio simply because they actually build useful stuff related to their patents. There is a robust debate to be had on the validity of obvious or generic software patents that only questionably constitute legitimate \"invention\", but that's almost entirely separate from the problem of the bottom feeding pond scum that collect patents for no other reason than to attempt to enrich themselves via parasitic extraction from people who had similar ideas but actually used them to create something useful. The former might be trying to get exclusivity from something that anyone could have come up with, but at least their idea is useful to someone. The latter brings nothing of value to anyone except maybe themselves, and arguably negative value to everyone else. reply Twirrim 5 hours agoparentprevAll major tech companies are building up a portfolio of patents, as a deterrent as much as anything else. So that when competitors come knocking on the door, they can use the portfolio to say, \"Well okay, but then you owe me license money for $x, $y, $z from my portfolio, how about we just not bother with this, agreed?\" reply rs_rs_rs_rs_rs 16 hours agoparentprevWhy should there be a mention about their patents? reply creeble 13 hours agorootparentSo that one can begin to judge how duplicitous their claims in defence of another's 'invalid' patent my be. reply patmcc 12 hours agorootparentIf Cloudflare starts trying to sue or shake down folks with their patents, this will be a very valid point. Until then it's a little silly; everybody holds patents for (at least) defensive reasons. reply MetaWhirledPeas 11 hours agorootparentExactly. As long as that's how the game is played you must play it or you will be sued out of existence. reply errantmind 15 hours agoprevThere is no evidence patents increase innovation. I suggest reading 'The Case Against Patents': https://files.stlouisfed.org/files/htdocs/wp/2012/2012-035.p... reply fargle 18 hours agoprevAwesome job! Thank you cloudflare. maybe this is the path to kill the trolls. tech companies could fund an insurance-like mutual scheme to defend instead of pay off the trolls and then drive them out of business. it can also research and invalidate their ridiculous patents. reply xpe 7 hours agoparentJust make sure the patent trolls don’t find a way to own their own patent troll insurance company. reply fargle 4 hours agorootparentha! i think we need to patent the method and practice of patent troll insurance... reply thih9 15 hours agoprev> the jury went further and found that Sable’s old and broadly-written patent claim was invalid and never should have been granted in the first place–meaning they can no longer assert the claim against anyone else Perhaps people/institutions that grant overly broad patents should be held responsible in a scenario like this? reply Aeolun 10 hours agoparentI don’t think it’s possible to hold the patent office responsible for these cases without making it impossible to run it. reply tharakam 9 hours agoprevLove this extract: \"Cloudflare’s hard fought victory, the culmination of three years of litigation, is a strong warning to all patent trolls–we will not be intimidated into playing your game.\" Thank you CloudFlare for doing your part! reply rvnx 19 hours agoprevAt the end of the day, this is a deep legislation issue, patents should not exist at all. They are supposed to promote innovation, in practice, it's more about protecting guys who sitting and waiting for passive cash. Once we give exclusive rights to all AI stuff to Nvidia, is the world going to be a better place ? What would be with ChatGPT if Google actually had enforced (or enforces) patents on Transformers. Is the world better since we have to pay a license to use the word \"Smiley\" and not \"Emoji\" ? (a >500M USD per year business btw). reply zackmorris 15 hours agoparentI second the abolishment of patents. The reasons people are for/against patents are political. A rightist view would be that patents allow first-to-the-finish-line inventors to reap financial awards that lead to success and freedom. A leftist view would be that the opportunity cost of patents is an increased cost (analogous to a tax) on everyone else in the form of licensing fees and barred entry to markets as improvements in science and technology make patents more obvious than innovative. If we don't reform the system by at least reducing patent durations to something reasonable like 3-5 years, then that will create an incentive to operate outside the market. People will just use open source and 3D printing to build their own stuff, rather than purchasing it from someone else. In other words, more patents = bigger black market and smaller market/profits for those operating legally. It's not a good look anymore to favor policies which encourage corruption. Other examples of unintended consequences include the War on Drugs, the Citizens United decision, NAFTA, etc etc etc. We know better now and we can do better, rather than letting special interests dictate the manner in which we do business. reply TimTheTinker 11 hours agorootparent> A rightist view would be that patents allow first-to-the-finish-line inventors to reap financial awards that lead to success and freedom. A leftist view would be that the opportunity cost of patents is an increased cost Patents as originally formulated were to incentivize public disclosure of new techniques for building things. Portland cement is a great example: the company could have kept the formula secret and profited significantly, but instead a patent was filed, they got a short monopoly, and for over a century we have enjoyed the benefits of a publicly known formula. Pure ideas (like math and physics) were considered non-patentable. If we can reform patents to disallow patenting software (and all other pure \"ideas\" with no physical realization), I think that will continue to help encourage public disclosure of helpful techniques (like Portland cement) without all the stupid baggage of software patents. reply adrr 15 hours agoparentprevSo you spend billions($2.5 billion being average) inventing a new drug and anyone should be allowed to copy and sell it? That would foster innovation and not kill pharmaceutical market? reply nottorp 11 hours agorootparent2.3 billion of that being marketing expenses? reply ahofmann 11 hours agorootparentThis is a very unhelpful pseudo question, that adds nothing to the conversation but can easily derail it. Do you have at least a source for that \"claim\"? reply nottorp 10 hours agorootparentEh, I'm hyperbolizing of course. But I remember seeing statements here and there that at least half the \"cost\" of a new drug is marketing. Commercials, paying for 'conferences' for doctors etc. Not going to search for citations, I'm sure you have something ready to prove me wrong and show how 95% of the cost is blood, sweat and tears. reply jandrewrogers 9 hours agorootparentThe marketing is critical because they have a limited window of time within which to recoup most of the development costs. If adoption ramps up too slowly, the company will not make enough money to offset the investment. Marketing improves time to revenue for a product where exclusivity will be short-lived. If they didn't spend on marketing, the R&D wouldn't exist, so it is kind of weird to act like this is a waste of money. It is like saying solar panels are bad for the climate because manufacturing them requires CO2 production. It shouldn't need to be said that no one would do marketing if it didn't more than pay for itself and offset the costs of the thing being marketed. reply nottorp 1 hour agorootparentSo most new medicine isn't useful? Or it would sell itself. reply rakoo 11 hours agorootparentprevWe need a pharmaceutical library, not a pharmaceutical market. Research doesn't cost $2.5 billion, lobbying does. reply adrr 10 hours agorootparentSpending 10 seconds to do a search yields a wiki page. https://en.wikipedia.org/wiki/Cost_of_drug_development reply mschuster91 10 hours agorootparentprev> Research doesn't cost $2.5 billion, lobbying does. It... actually does. The utter majority of pharmaceutical cost are the clinical trials, and the cost of \"failed\" compounds has to be absorbed by the few that eventually pass. It used to be the case that the development part would be done by universities and government grants, but universities these days prefer to hoard their inheritances instead of spending it, and governments lack the ideas and auditing capability, so everything has gotten privatized and with it, control transferred from democratically elected institutions to quarterly-focused boards accountable only to shareholders not society. reply thereisnospork 9 hours agorootparentprevLet's make a bet then, shall we? I'll wire you 2.6billion (the extra 0.1 for your trouble) in exchange for a cure for alzheimers deliverable 5 years from now against 5 billion if you can't deliver. Should be an easy 100million+ for you. Lmk once you have your side in escrow. reply huijzer 18 hours agoparentprevI'm not so convinced of your argument yet. You point out some cases in which granting a patent will lead to reduced innovation, which I agree is bad. But how about innovations which might never have happened without the patent system in place? I agree with you that patents a probably a net negative for innovation, but we need to come up with a stronger argument than monopolies are bad. reply spongebobstoes 16 hours agorootparentCan you provide some recent examples of where patents likely played a positive role in innovation? reply anonymouskimmer 16 hours agorootparentFifty years ago they paid for Xerox's PARC where WYSIWYG and GUI interfaces were first developed targeting a mass audience. reply nottorp 11 hours agorootparentIirc Apple paid (in Apple stock perhaps) but Microsoft didn't :) reply sophacles 14 hours agorootparentprevRight, I was so glad when those patents expired because the Xerox monopoly on my computer usage was annoying. reply anonymouskimmer 2 hours agorootparentSpecifically the Laser printer patents paid for PARC, and then some. As mentioned a few days ago by another commenter. reply AnimalMuppet 16 hours agorootparentprevProbably every pharmaceutical patent. In software? Um... . (But you asked \"where patents\" and not \"where software patents\", so...) reply 8note 14 hours agorootparentPharmaceutical parents seems like an odd choice. Aren't most of those inventions driven by government funding at universities? reply tick_tock_tick 12 hours agorootparentNo massive amount come from the private sector. Almost all the money used to get a hypothetically effective drug through the approval and trial process is private. reply dmoy 11 hours agorootparentRight, to be clear: If the initial research is funded by government grants or at Uni or whatever, the overwhelming majority of the cost is still in Phase 2 and 3 trials. This is why certain drugs don't get developed anymore - if it's a naturally occurring substance that can't be patented, nobody's gonna foot the gallion-dollar bill to go through trials. reply Exoristos 13 hours agorootparentprevYes, but they probably wouldn't be without patents to ensure income for the government's partners. reply notfed 15 hours agorootparentprev> Probably every pharmaceutical patent. Great, they've played their role, then. I'm ready for that stage to be over now. IMO if there's an incentive to manufacture distribute the product, let that be the incentive. reply patmcc 12 hours agorootparentHaving ~zero new drugs introduced does not seem like a great thing? Unless you completely revamp how drug discovery and research is funded and driven, anyway. reply AnimalMuppet 12 hours agorootparentprevTo the degree that patents have led to the creation of new pharmaceuticals, you're ready to stop doing that? You're ready for progress in pharmaceuticals to stop where we are, because you don't want patents to exist any longer? I strongly disagree. reply squeaky-clean 13 hours agorootparentprevARM CPUs reply seniorThrowaway 16 hours agoparentprevThere is a general problem with excessive rent seeking in our entire economy and society. But I don't think having zero patent protection is the answer. Like most problems with society, there is no easy answer, just a continual fight against corruption, rent-seeking, nepotism, collusion, price fixing and all the other crappy human behaviors. reply anonymouskimmer 18 hours agoparentprev> Is the world better since we have to pay a license to use the word \"Smiley\" and not \"Emoji\" ? (a >500M USD per year business btw). If this is true it would fall under copyright or trademark protections, not patents. reply rvnx 17 hours agorootparentYou are absolutely right, just a side & +/- related topic that made me upset and wanted to rant about :) reply duped 18 hours agoprevThere needs to be a \"use it or lose it\" doctrine/law around technological IP. I get all the arguments around creating a market for the patent rights, but it just leads to these bottom feeders creating no value and increasing costs for the industry and consumers. reply thelastgallon 17 hours agoparentPatents are property and we need taxes/fee on it. $500/year per patent, will ensure use it (if you think it is valuable) or lose it. This is no different from domain names, most people pay $10 - $100/year just to keep a domain name. Some domain names are used, most aren't. These taxes can fund free education or healthcare or defense. reply kstrauser 14 hours agorootparentI offer as an alternative: IP is property, and it's taxed at the value you declare that it's worth. However, if you swear to the IRS that it's worth $500/yr, then you can't claim in court that a violation of it is costing you $10,000,000/yr in losses. That would be perjury. Your patent is worth $10,000,000? Awesome! I bet your local school district will love to hear how much you'll be paying in taxes on it. reply beefield 13 hours agorootparentI offer one more alternative. Double the tax every year, and once the ip holder decides not to pay the tax, IP is released to public domain. No compnay has money to keep IP indefinitely in such a scheme. reply akoboldfrying 13 hours agorootparentWhat do you think will happen if IP becomes impossible to afford, as it surely will under such a policy? Do you think companies that value IP will bother investing further in R&D, let alone even stay in your country? Congratulations on the massive net loss in taxable income in your country. EDIT: Removed some mean words. reply hervature 12 hours agorootparentYou do not seem to understand how patents work because of other comments thinking that you can patent something without publicly disclosing the invention. In and of itself, this comment is silly because the answer to your question \"What do you think will happen if IP becomes impossible to afford, as it surely will under such a policy?\" is \"exactly what happens when patents expire currently.\" It appears you are unaware that companies still invest in R&D knowing they at most get a few decades of exclusive rights. reply patmcc 12 hours agorootparentprevIt'll only be impossible to hold for long periods of time. We can start the tax at $1, it hits $1mil after 20 years - and for 99.9999% of IP by year 20 it's either clearly worth zero or clearly worth >$1mil so it'll be an easy choice. It'll force things into the public domain faster and make it expensive to hold a big bullshit patent catalog, but for actively used properties it'll be fine. Companies are going to want to sell in one of the richest markets in the world; they can either pay for IP protection or not be granted it. edit: I'm not suggesting these exact $ values as clearly being the correct ones, it's just an example. reply dustingetz 13 hours agorootparentprevin the software ip case, they can invest in building competitive products in an open market. If your software IP is a secret then don’t publish! reply akoboldfrying 12 hours agorootparentSo, for example, the secret sauce that makes the CPLEX and Gurobi solvers tens or hundreds of times faster than open source equivalents should simply be released to the public, leading to the immediate loss of 90% of those products' competitive advantage? You don't see how such a policy would spur terror among large, profitable companies with trade secrets, leading to them moving overseas? reply Rygian 12 hours agorootparentIf it's secret sauce, it's not a patent. reply beepbooptheory 12 hours agorootparentprevIn these threads it always end up being: \"Sure Foo would be nice, but, I don't know if you are aware, we are actually held at gunpoint by the status quo; its all really a non starter when you consider this fact.\" If this is the only real problem, than why not just let them go overseas? Let the market play it out? The boon of progress and freedom X country would get from becoming even little more rational about IP would pay for itself and be better for actual people. reply mschuster91 10 hours agorootparent> The boon of progress and freedom X country would get from becoming even little more rational about IP would pay for itself and be better for actual people. That's what China has been doing for decades, and \"gongkai\" [1] is just one tiny part of it. While life for the average Chinese citizen has gone up - the CCP managed to lift hundreds of millions of people out of poverty - the life of most Western populations has gone down the drain as entire industries, entire towns were unable to cope with unfair competition. The societal consequences of that will haunt us all for many years to come. [1] https://www.bunniestudios.com/blog/?p=4297 reply kortilla 11 hours agorootparentprevI don’t think you understand how patents are used. It’s not secret sauce if it’s patented. reply KittenInABox 13 hours agorootparentprevI would suggest only for corporations above a certain size. I would appreciate if some old music composer somewhere gets to continue being old and stuff without worrying about this sort of thing. reply nextaccountic 13 hours agorootparentMusic is coveredby copyright , an entirely different law reply polishTar 13 hours agorootparentprevA lot of patent trolls are very small companies though reply kevin_thibedeau 13 hours agorootparentIt would have to be managed by tracking the number of active patents. You get 100 active patents tax free. Over that, and you have to pay an annual fee. This allows for independent inventors to operate as the system intended while clamping down on NPEs. reply DylanDmitri 13 hours agorootparentprevMusic compositions get covered by copyright. Patents are another section of law. reply margalabargala 13 hours agorootparentprevSomething like this genuinely does hurt very small businesses or inventors who invent something actually valuable but don't have time to quickly scale up. What I like for IP laws is as follows: When you create a protected work, you pay a very small fee. Say, $1 for copyright, maybe $500 for a patent. Each year thereafter, if you wish to maintain your IP protection, you must pay double what was paid the previous year. Otherwise the property reverts to the public domain. This ensures a period of protection if it's genuinely needed, but ensures that everything will eventually enter the public domain, especially in the case where no one is making any economic use of the material. reply hamandcheese 12 hours agorootparentPatent protection already is not indefinite. It seems much simpler and more fair to shorten the protection period. reply margalabargala 10 hours agorootparentEven if we halve the patent protection period, that is still ten years during which a patent troll can scoop up a BS patent and then simply send threat letters and rake in money, while chilling any actual advancement. Currently, there's an incentive to disallow progress. If someone does not want to make use of their own patent, they are currently incentivized to sit on it and keep the ability to create that thing out of the hands of anyone else, \"just in case\". If we shorten the period as you suggest, to half (for example), then that freezes that progress for a decade. If an incentive is created to put inventions into the public domain if one is not using them, then that is better for everyone. And by doubling the fee each year, it becomes financially infeasible for even large companies to keep things out of the public domain forever. A fee of $500 that doubles annually would, at the 20 year mark that is the current patent lifespan, cost a half a billion dollars to renew for that year. reply IanCal 14 hours agorootparentprevSomething I've wondered about - you specify a value and pay a tax accordingly. Anyone is then able to buy it from you for that price. Have some short term part for free, then fees scale over time. reply eitland 13 hours agorootparentA slightly different version was in use in Denmark: a ship declared the value of their cargo for toll purposes. They decided the price, but the catch was the customs could buy the cargo at that price. reply jstarfish 13 hours agorootparentThat is fiendishly clever. reply balderdash 13 hours agorootparentprevIt sounds nice in principal but I think it’s not so easy in practice, if I asked you what’s your car worth you probably say something along the lines of well it would cost x to replace it, or I paid y for it, or I could sell it for z on eBay (all three different prices) but if you then said that well whatever price you say someone can buy your car for and you’re stuck with without a car while you go figure out replacing is actually a price is not any of those prices, and is probably higher than the actual value, and may even be higher than the cost to replace it - you might say that’s the idea but ultimately it feels creepy to make people pay a tax to avoid the risk of an asset they rely on not to be taken away at an inconvenient time… reply IanCal 9 hours agorootparentThe value to me would be the replacement plus hassle value. There's clearly values I'd easily accept, you offer me a hundred grand for my car and you can take it whenever you want. Now for regular items like a car this would be hard. How do I value it and how do I not get caught out when second hand sales spike and I don't follow the markets? But we're not talking about everyone's car. We're talking about asking the state to forbid others to make or build certain things (yes I know it's more detailed but you get the meaning). reply balderdash 8 hours agorootparentYep but that’s kind of my point - let’s say your a poverty level worker with a POS car “worth” $2k but it’s reliable and you need it to go to work, and finding another one for a solar price carries the risk of finding a lemon or having unexpected bills your going to end up saying it’s worth $[4]k because it would be a really bad day for you not to have your car and taking the risk on a replacement is just not worth it. You end up paying a higher tax rate than the guy that’s got three cars in his garage and his happy wearing the risk over time of being slightly under replacement value since it lowers his effective tax rate and if he’s out a car for a bit at slight loss that’s no big deal.. That extra “value” (or tax on people) you ascribe to your car may or may not be distributed in manner that societally makes sense reply aldonius 10 hours agorootparentprevalternative: anyone is able to make it public domain for that price reply jandrewrogers 12 hours agorootparentprevThis creates a clear and obvious arbitrage opportunity that finance people on Wall Street will exploit almost instantly. reply IanCal 9 hours agorootparentOk? It results in them paying taxes while they hold it, to the value they ascribe to it. If they say it's higher than the original buyer, we get more in tax revenue Or have I misunderstood your point? reply ardel95 13 hours agorootparentprevThat would effectively kill software patents. Which is a fine outcome. reply thelastgallon 13 hours agorootparentprevThis is better than what I proposed. reply brookst 13 hours agorootparentprevDoesn’t work. Lots of people don’t know what their IP is worth, and it can change with market and tech trends. And the damages aren’t based on the harm to the IP owner, but on the benefit to the infringer. I could have a patent that I think is worthless, but in 10 years I discover that a multinational flat out stole the IP after an NDA meeting. What is the value that I should have declared? reply EnigmaFlare 14 hours agorootparentprevBut property usually isn't taxed. Trading is. If you license a patent to someone else for $500/year, you'd pay tax on that $500. But if it's actually worth more, of course you wouldn't charge such a low fee. reply thelastgallon 13 hours agorootparentProperty is almost always taxed. In Texas, property taxes on homes are 2.5 - 3% of value, most people pay between 8K - 30K every year. And this keeps going up! Over a 30 year mortgage, I'm sure most people pay more on property taxes than on their home. Approximately 50% of property taxes go to school districts, the rest for other municipal services. Some states also tax car as property. What is not taxed is Intellectual Property. Because it is almost completely owned by the super rich. And, of course, these billionaires need all the help they can get. How about we change this? We can think of wiping out property taxes for homeowners (making homes affordable) and fund education from patent taxes. After all, the super rich are deriving these patents from the education system, its only fair they pay their fair share. reply EnigmaFlare 43 minutes agorootparentReal property is an exception but we're talking about other kinds of property. I don't know of any other kind that's commonly taxed. reply kstrauser 13 hours agorootparentprevTo my knowledge, all US states have property tax. reply eitland 13 hours agorootparentprevThat's the point up thread. It isn't now, but we could make it so. reply nordsieck 17 hours agorootparentprev> $500/year per patent, will ensure use it (if you think it is valuable) or lose it. Not really. Some patents are fantastically valuable to patent trolls. Some are not. A $500/year fee isn't going to deter a \"company\" of lawyers who are making millions soaking businesses with patents that should never have been granted. If you want a scheme that actually does what you want, you'd need something like: The owner of the patent chooses the fee that they pay per year. And anyone can pay that fee * the remaining years on the patent * some multiplier (probably in the 2-10 range) to prematurely end the patent. So, if someone's got a patent on a hamster powered submarine, they can keep it for $1 per year (or whatever the minimum should be). And that's fine... because it isn't harming any one since no one wants to build such a thing. But a patent that a troll is using to milk the industry with will need to have a pretty stiff fee or people won't play ball, they'll just buy out the troll. reply mike_d 16 hours agorootparent> The owner of the patent chooses the fee that they pay per year. And anyone can pay that fee * the remaining years on the patent * some multiplier (probably in the 2-10 range) to prematurely end the patent. So basically ending patents? If you invent something fantastic, say a way for a self driving car to perfectly sense its surroundings, Ford could just come in and pay whatever amount to invalidate your patent and prevent you from bringing your invention to market? reply cynix 16 hours agorootparentNot having a patent doesn’t _prevent_ you from bringing your invention to market, it just accelerates _someone_ bringing it to market, and that’s a net good for society if the invention is useful, no? reply mike_d 15 hours agorootparentPatents are vital to bringing things to market. It lessens the risk associated with investors getting returns, which allows funding for development. I get that people don't like patents because they sometimes get abused, but on the whole I think we wouldn't have a lot of the things we take for granted if they didn't exist. reply chx 15 hours agorootparentLet me add a personal anecdote: my uncle has developed a better sprinkler head. Think of bearded inventor tinkering in his garage for a decade. This was late 80s /early 90s so not much CAD was involved. This is where the patent system shines. Because he got a patent he could shop around, sell it to a company which made a tidy profit on it. He didn't need to raise capital to establish a factory and all that to bring it to market and the company buying it seriously got ahead without spending an inordinate amount of money and time inventing the thing. reply jimkoen 14 hours agorootparentprev> If you invent something fantastic, say a way for a self driving car to perfectly sense its surroundings That sounds like a highly constructed example, and even if we take it for bare value, makes a lot of assumptions, for example that whatever you invent is patentable. The way you phrase it also makes it sound like patents are all about individual contributions, when in reality the era of lone genius inventors is long over (if they ever existed). In the US, it's practice for your funding institution to keep all the rights to your inventions, so if you invented the perfect sense for self driving, it's highly likely that a company like Ford already has the patent, because they quite literally own your intellectual output. Imo, I feel the same way like OP, there needs to be a use it or loose it doctrine, just like there is with trademarks. Overall the legislation around intellectual property and copyright feels to be in favor of big corps at the moment and should be heavily castrated. reply willsmith72 14 hours agorootparentDoesnt sounds constructed to me. The \"you\" in that case could very easily be a startup reply rpnx 13 hours agorootparentThe number of patents owned by startups is greatly dwarfed by the number owned by large companies. Furthermore, the competition opportunity for small businesses to offer similar products at lower prices greatly outweighs the value of patent invention. Some people would say large businesses can make things cheap in a way that small businesses can't compete with. However, that turned out to not happen in practice as big companies chase huge profit margins, supported only by the government. China doesn't have this problem the US does because they have weaker patent laws. Patents need to be eradicated ASAP or we will not be globally competitive. We are also harming humanity as a whole as the inventive utility of patents simply doesn't scale in proportion to the harms, with the large populations we have now, they are clearly harmful on balance. The fundamental problem with patents is that the benefit has lower asymptotic complexity with respect to population size than than the harm does. When you exceed some population size, patents become harmful. The utility of copying is N^2 since you have O(N) copiers and O(N) inventions to copy from. The harm of patents is therefore O(N^2) since this is the copying that patents prevent. What we find is that the benefits of patents seem to scale at most around some O(N /log N) ish metric. Doubling the population size increases the number of inventors, but the chance an invention was already invented by someone else increases as population size increases. Hence the benefits of patents scale worse than O(N). Applying that to the harm and we still get O(N(N/logN)) for harm and O(N/logN) for benefits. Clearly patents do not scale. * Here I am using Log N as a substituite for the difficulty increase of finding an invention not already invented. This exact measure is difficult to estimate. reply asoneth 10 hours agorootparentprevI agree that patents serve a purpose, but taxing intellectual property similarly to other property doesn't seem like it would end patents. A slightly different approach would be for patent owners to declare an estimated value and pay property taxes on that value to enforce their monopoly. (They may also wish to update the estimated value periodically as circumstances change, perhaps every few months or years.) To keep owners honest, anyone is allowed to pay the owner a multiple (1.5x? 2x? 10x?) of the patent's current estimated value to invalidate it. If the patent owner wishes to hang onto the patent but cannot afford the taxes then perhaps banks would be willing to offer a patent equity line of credit, like using any other income-generating property as collateral. To use your example, if you estimate that your self-driving patent is a ten million dollar asset and Ford pays you twenty million dollars to invalidate it that seems like you come out ahead because you have more than the patent was worth and can still build your product. reply efitz 16 hours agorootparentprevI don't think that the patent should be allowed to be ended early; the fee is paid to keep the patent protection in place. reply bawolff 15 hours agorootparentprev> Some patents are fantastically valuable to patent trolls. Some are not. A $500/year fee Part of the problem is having a huge number of BS patents driving up the cost of going through all of them to figure out what's what. Its not the only problem with patents, but i think a \"property tax\" solution would solve some of the issues. I'd like it to be incrementing each year - like first year $0/year, and increasing each year so the longer you keep things out of the public domain the more you need to be able to self-jystify its value. reply criddell 16 hours agorootparentprevMaybe when you file the patent, you have to submit an anticipated value statement and you are taxed some % / year on that anticipated value. If somebody violates the patent, you can sue them for up to the amount you anticipated, but not more. In the future you can amend the value claim, but you can only adjust it down. reply victorbjorklund 15 hours agorootparentSo someone inventing something for say mobile phones in the 80s that is still used would have estimated their patentent to not be so useful because the number of mobile phones wasnt that high. And if Apple violated their patent they would just pay pennies because of that? It is extremly hard to estimate the worth of a tech 30 years into the future invented today. Take a tech invented today and tell me what the market value will be in 30 years and how sure you are about that predicition. reply petsfed 14 hours agorootparentIf you invented and patented something in the US in 1989, you'd have protections until 2009 at the latest. If it wasn't usable until 2013, then that sucks for you, but it is what it is. Your invention doesn't get 20 guaranteed years of profitability. You get 20 years to figure out how to make it profitable. The two are very different concepts. edit: this is why you don't patent every damned thing, just the things that you believe will be profitable over the next 20 years. Otherwise, the cost of researching and filing the patent, as well as maintaining it, may well exceed whatever profit you actually get from the thing. reply TeMPOraL 14 hours agorootparent> this is why you don't patent every damned thing, just the things that you believe will be profitable over the next 20 years Unless you work for a corporation, that owns your intellectual output anyway, and encourages you to submit forms for anything that looks even remotely patentable. reply petsfed 11 hours agorootparentI want to be clear here: you submit a form for everything, then people in the legal and business development teams decide if its actually worth patenting. But even then, if you devise some thing that will be very useful if we ever get teleportation working, your employer may still not patent it, if they believe that teleportation is more than 20 years away. reply criddell 15 hours agorootparentprevYeah, that’s roughly how it would work, except 30 years feels way too long. If other people are better than you at seeing what some technology could be used for it, then maybe we should lower the barriers for those people. The whole point of the patent system should be to provide the greatest benefit to the greatest number of people. reply echelon 16 hours agorootparentprevThat's awful for protecting innovation. You don't know the market value of each individual invention with that level of granularity. Companies and researchers should be free to patent to protect themselves, but patent trolls with no clear technological development (no lab, no product, no licensing+developing) should be stopped. It seems easy to me to draw a bounding box around these behaviors with a simple test. Perhaps like a Howey test [1], but for patent trolling. [1] https://en.wikipedia.org/wiki/SEC_v._W._J._Howey_Co. reply noqc 15 hours agorootparentprev>a scheme that actually does what you want This seems like a pretty bad attempt at such a scheme. reply freejazz 17 hours agorootparentprev>making millions soaking businesses with patents that should never have been granted. Invalidity arguments and IPRs suddenly aren't things? reply brlewis 17 hours agorootparentThe troll can price their licenses slightly less than the presumed legal costs. Then most victims won't fight. Presumption of validity is what makes patent trolling more lucrative than other forms of predatory litigation. You're guilty until proven innocent, because the law assumes that the patent office is generally doing the right thing. reply freejazz 16 hours agorootparent> Presumption of validity It's just an evidentiary presumption that is trivially rebutted with any evidence. reply nordsieck 17 hours agorootparentprev> Invalidity arguments and IPRs suddenly aren't things? I'm sure that you're aware that when you go to court, the result is never certain. Bad ruling happen all the time. reply freejazz 16 hours agorootparentThe vast majority of these decisions are against the patent owners, which I'm sure you are aware of. Also, I wasn't the one who characterized something as a patent that \"should never have been granted.\" reply pwg 17 hours agorootparentprev> Patents are property and we need taxes/fee on it. $500/year per patent Those 'taxes' already exist (at least in the US system). They are called \"maintenance fees\". See https://www.fr.com/insights/ip-law-essentials/everything-abo... Failing to pay the fee causes the patent to expire, and be unable to be used to sue someone. So these troll firms must also be paying these fees to be able to sue based on the patent. reply madsbuch 16 hours agorootparentThis is interesting. So Oracle holding around 52000 patents pays around 23.000.000 USD a year in maintenance? reply ako 16 hours agorootparentYes, having patents is expensive. Large corporations often file patents for defensive reasons, and for this they employ multiple patent lawyers full time. reply madsbuch 15 hours agorootparentYeah, so add a couple of millions on top oof the 23.000.000 a year for lawyers and other staff. reply oezi 15 hours agorootparentprevI would be in favor of a fee that is 1024 * 2^n USD where n is the nth year you want to keep the patent. 1st year = 2000 USD 10th year = 1m USD per year 20th year = 1bn USD per year It becomes prohibitively expensive if you don't use it. After 23 years it would make only sense for the most insane blockbuster drugs to keep going for another year. reply atoav 16 hours agorootparentprevNever used a fixed number for anything. Just tie it to a percentage of yearly revenue of the entity. This way you can ensure: - small companies and private people can afford patents - big corps do not get an advantage, in fact the bigger they get, the more expensive holding a patent becomes, ensuring they have to use those patents and not patent everything just because - number of patents any single entity can hold is limited, unless they want to go in debt for holding patents - there could still be a minimum yearly amount as proposed by you reply ummonk 14 hours agorootparentThat just means patent trolls would split their patent portfolios into hundreds of holding companies. Also people would start filing bigger and bigger patents, stuffing more and more claims into a single patent. reply atoav 7 hours agorootparentWell this is a problem we need to tackle anyways. Splitting things into a thousand holding companies should be with considerable cost as well for those involved with a thousand holding companies. There is literally no case in which society profits from a corp being split up into a thousand holdings. reply thechao 15 hours agorootparentprevTie it to the expected value of the IP? If you think your idea is worth $1 billion, pay $10 million (1%) every year. reply atoav 7 hours agorootparentHow often are you allowed to change this? Could just undervalue it until you suddenly don't. If you are not allowed to change it that is not an uninteresting idea. reply IG_Semmelweiss 16 hours agorootparentprevDomain names pay per year because there's an ongoing service attached. There's no such thing for patent (besides fee to file) Why punish patent holders because of patent trolls or garbage patents ? Make it unprofitable to be a troll, and they will go away. Trolls need to be tagged , like pirates. There should be rules to make hunting for trolls profitable. For that, you need a \"bounty\". Here's my take: In any patent dispute[1], the loser will pay as punitive damages (this is the \"bounty\") to the winner, the lower of (i) the winner's legal costs, OR the loser's legal costs x 2, plus (ii) loser must disclose the ultimate name of the beneficial owners (or material, if public) of the loser. EINs not allowed. The \"trolls\" are thus, branded. The next lawsuit ensues. During research, it is found that one of the parties is a known troll that has lost 1 prior case. Now the damages, should troll lose, are 2X of any settlement OR punitive amount. Should troll lose again, an extra 2x (total, 4x) gets applied on the punitive damage[1] to the troll and so on. If troll wins, his x is halved. This does 3 things: 1- Incentivize public to seek out weak patents, or trolls, for a payout. 2- Makes Trolling much harder at scale. 3- Ensures huge companies face risks if they throw their weight around. Bigco can afford $$ penalties vs small fish, but cannot afford to be tagged a 2-4x troll. It makes them an attractive target for bigger fish looking for the 2X or 4X reward challenge of Bigco patent portfolio. reply notfed 16 hours agorootparent> Domain names pay per year because there's an ongoing service attached. There's no such thing for patent Erm, what service? A record in a database? How's that different from a patent office? I guess there's fancy registrar website...to do what...help me pay my recurring bill? reply IG_Semmelweiss 14 hours agorootparentI don't think you are arguing in good faith. OK fine want an ongoing patient fee ? Make it $9.99 per year just like a registrar, who gives you convenient ways to renew and pay fees from a working, modern site, and allow migration , with a few clicks. Is that going to prevent trolls ? Unequivocally, no. Parent was arguing for some ridiculous, unnecessary , tax. Then cited registrars as an example. My point, 1 gives a service, one does not. If you want to charge for a service, then make it transparent and make the fee reflect the service, not argue \"hey we already charge for registrars\" to make his/her point about a new, unecessary tax. reply jeltz 13 hours agorootparentI do not think you know the domain business, which I happen to work in (I own a small registrar and know people at registries). The reason domain costs money is to make it more expensive to hoard, not to pay for any service. There is a service but it just costs a tiny fraction of the registry fee the rest they often use for funding various non-profit initiatives to improve the internet not related at all the providing any service. The fee is set where it is to discourage hoarding. Edit: It is also there to make it slightly more expensive to create scam sites, but mostly for the anti-hoarding. reply IG_Semmelweiss 13 hours agorootparentMakes complete sense. Domain hoarding is not cool and makes sense to mitigate using fees as you describe. Now, Patents already require fees and also substantial paperwork. In effect that is the \"hoarding\" control. I stand corrected that the point of ICANN and registrars to charge something is to introduce a barrier to entry. Yet, I'd argue you are still providing a service if the fees go towards nonprofit activity to improve interoperability. Yet, introducing a huge fee to patents wouldn't really be conductive to anything on the patent side, which is at the core my issue: I'm not making a judgement about the margin on fees, i'm questioning whether there's a semblance of service. From my vantage point, registrars have made massive improvements in accessibility and ease of use, and as you said, they have lowered the barriers to entry.I can't say the same at all for patents. reply jeltz 13 hours agorootparentprev> Domain names pay per year because there's an ongoing service attached. There's no such thing for patent (besides fee to file) I work for a registrar and know people working at registries so I know that is not the case. The reason they charge more than like 1-2 dollars per year is to make it expensive to hoard domains. reply theshackleford 11 hours agorootparentSadly though, not expensive enough to actually prevent anyone other than the very low end of consumers from hoarding domains. I worked for a registrar for a decade+ and worked with a lot of hoarders. Very early on in my career I actually dobbed one in to our local registry authority (because I was naive, and he was CLEARLY breaching the requirements for our ccTLD and so I thought 'Well this is wrong and I should report it') and is how I discovered nobody actually cares about hoarding and just wants to maximise revenue. (Well duh I suppose.) reply cynix 15 hours agorootparentprev> loser must disclose the ultimate name of the beneficial owners (or material, if public) of the loser. EINs not allowed. The \"trolls\" are thus, branded. So TrollCo will just pay a different homeless person $100 to be the owner on paper for each of their patents? reply IG_Semmelweiss 14 hours agorootparentSure. Let them deal with getting the homeless persons to sign up. Open a bank account, pay taxes, get credit cards, run payroll, process permits, etc. I don't think you fully appreciate how tough is to run a business with someone's name on top of every document. Not to say its not possible for a determined actor, but its going to eliminate a lot of options from the get go. Then, let a judge find out! reply perlgeek 16 hours agorootparentprevAnother valuation/taxation scheme I've read about is: you can value your patent however you want, and it's taxed based on that value. The kicker is: the values are public, and if anybody wants to buy it for something higher than the assigned value (or maybe some fixed percentage above the assigned value), you HAVE to sell. Of course, the buyer is then taxed at the higher value. reply karaterobot 15 hours agorootparentThat seems like a terrible idea! If you underestimate the value of your invention, some big company can own it for $n+$.01. Or if you have invented something valuable but it takes years to get to market with it, you can go bankrupt in the mean time, or have your ownership eaten away by investors who suddenly have a ton of extra leverage over you. reply balderdash 13 hours agorootparentprevI generally think the principal of taxing property is fundamentally flawed (especially as it relates to property that has a market value that can be quite volatile or hard to value and even more so if the property generates no current income). My rationale is that it means that only people that are rich can own property as they can afford the taxes, and especially if the property has increased in value over time and has no or small associated cash flows. By all means tax gains on realization (though I’d argue there should be a CPI adjustment to the basis but that’s another conversation) reply adverbly 17 hours agorootparentprevThis is an interesting point of view. Reminds me in some sense of some of the ethical justifications behind land value tax or property taxes. The intention of legally enforced ownership is primarily to encourage development - and not to incentivize speculation as we seem to be doing in many situations. It seems reasonable to tax such speculation. I'm inclined to agree with you. reply gunapologist99 15 hours agorootparentprevWhy would we tax that property (at the federal level) and not others? What would this do to people who file their own patents to protect their own inventions? Historically, that's been the vast bulk of all useful inventions in this country. reply benlivengood 15 hours agorootparentprevWe need a fair-valuation tax; patents taxed yearly on their declared value and mandatory sale of the patent to anyone willing to pay the declared value. Some kind of deferred tax schedule (maybe 5-10 years?) for R&D. reply efitz 16 hours agorootparentprevNo, the fee should be exponential, to keep people from keeping technology out of the public domain longer than necessary. For example, maybe the fee is $10000 for the first year. This doesn't come close to recouping the cost of a single enforcement action, but it makes sure that someone has some skin in the game. Then every year the cost gets 10x more expensive. Of course you are free to choose your own base and multiplier. For someone to keep a patent for 5 years, the total cost would be $10k + $100k + $1M + $10M + $100M = $111110000. Maybe it's worth it for a patent like the light bulb. Probably not worth it for a drinking bird toy. But either way, the value decision is up to the patent holder, and the cost of the patent incentivizes rapid monetization rather than squatting. reply efitz 7 hours agorootparentJust curious: what about this comment made it worthy of downvoting? reply tracerbulletx 14 hours agorootparentprevI think a better model would just be something like adverse possession, where if the owner of the patent hasn't developed it, or done certain things it can be nullified. reply robertlagrant 17 hours agorootparentprev> These taxes can fund free education or healthcare or defense Why only those things? reply KMnO4 17 hours agorootparentAppeal to emotion. Taxes go towards all publicly funded projects, but it’s easier to convince people that a new tax is a good thing when it goes towards these things that benefit everyone. reply yieldcrv 16 hours agorootparentprevpatent maintenance fees are already higher than that. amusing opinions that remind me not to trust them reply phpisthebest 17 hours agorootparentprev>>These taxes can fund free education or healthcare or defense. is it is always a bad idea to ear mark a tax for a specific purpose. Especially if you desire to use the tax as a punitive measure to reduce that which you deem bad for society, if it works now you need to come up with the money for the thing you funded elsewhere because all government programs are permanent Look at smoking, all kind of things were funded on the back of smoking taxes, and when those punitive taxes worked to reduce smoking the revenue dried up but the budgets for for those programs did not so now the money had to come from somewhere else.... Using the tax code to punish or reward behavior is always bad reply ahtihn 16 hours agorootparent> Using the tax code to punish or reward behavior is always bad Isn't that pretty much the entire purpose of the tax code and why it's so complicated? It's one of the tools the government has to shape behavior. Actual tax revenue doesn't really matter since a permanent deficit and ever-growing debt is apparently fine. reply lukan 18 hours agoparentprevThere are research companies who only do research and get money by licencing their patents. I mean, I really would like to live in a world without patents, but currently those companies do provide value, but cannot exist, without guarding their IP. Yet they would cease to exist, with your proposal. reply jonwachob91 18 hours agorootparentIssuing a license is a form of \"using it\" in a use it or lose it scenario. Those are not patent troll companies. Patent troll companies file patents and then sit on the patent until they can sue another party for infringement, and never make an attempt to commercialize their patent. Another example of not using it in the use it or lose it scenario is Pfizer's acquisition of Esperion Therapeutics in 2004. Esperion was developing a competitor to Lipitor, so Pfizer purchased Esperion for $1.3BB and shelved the technology to prevent competition with their best selling drug. Had Pfizer \"lost\" their patent for failing to commercial Esperion's drug, that drug could have entered the market as a generic to compete with Lipitor and severely reduced the cost of statin drugs for consumers. reply crdrost 17 hours agorootparent> Issuing a license is a form of \"using it\" in a use it or lose it scenario. Patent trolls will point to their prior victims as current licensees, proving successful commercialization. reply pwg 17 hours agorootparentprev> Patent troll companies file patents and then sit on the patent until they can sue another party for infringement Many of the patents asserted by trolls were not actually filed by the trolls. Most often the troll company simply purchased the patent from the original owner (or, often, a bankruptcy court) and then they proceed to go about suing others using their newly acquired weapon. reply btilly 17 hours agorootparentWorse yet, the troll company was often created for the purpose of owning that specific group of patents. That limits the damage from a lawsuit gone wrong to just that group of patents, and not the many other patents owned by the hundreds of other similar troll companies that the same lawyer runs. We really need a patent troll version of anti-SLAPP laws. To go past the shell company, and hit the people who run them. reply amadeuspagel 17 hours agorootparentprevWhat's your bargaining position when you lose a patent that might be useful for only a few companies if you don't issue a license? reply ThrowawayTestr 17 hours agorootparentIf it's only useful to a few companies then it must be niche IP and therefore valuable. reply lukan 18 hours agorootparentprevThat is hard I think, as there are patents that are not licenced because no one wants to - but I think every holder of a patent must licence it to any party interested. So just \"sitting on patents\" is not really possible to my knowledge. (but I am really not an expert here) reply smachiz 17 hours agorootparentOnly for patents used in standards - where the standard enforces FRAND/RAND/other licensing schemes to insure that 'standards-required' patents are available to all. https://en.wikipedia.org/wiki/Reasonable_and_non-discriminat... This is Qualcomm's big business (and others), getting their patents into standards like 5G and then charging people a fair amount to use it - and they have to license it to everyone, even their arch nemesis. Or you just buy their chips. For a patent of something you invented, but did not submit to become part of a standards-body, you absolutely can choose not to license it for any amount of money. reply floating-io 17 hours agorootparentprevIf I'm understanding what you're saying correctly, then I'm not sure where you got that idea. Patent holders are not required to license their patents last time I checked. You are simply required to acquire a license prior to using patented technology. If they don't want to license it, you're SOL. (edit: if you were speculating on what should be, and not what is, then my bad... :) reply lukan 17 hours agorootparent\"Patent holders are not required to license their patents last time I checked.\" That is apparently right and I learned it wrong (but it does seems wrong to me). edit: after reading the siblings answer, I apparently wrongly overgeneralized the way it works with patents in standards reply duped 18 hours agorootparentprevWhy wouldn't they be able to exist? If you invent something, there's a work product. There is documentation, notes, blueprints, CAD files, software, etc. You can sell this and license it however you want. You can sue people that use it without a license. More importantly, you as the original author can use the IP as you see fit. All of that is what I would put under the category of \"use it.\" If you stop licensing it, then you \"lose it.\" Personally I don't think you should be able to sell the invention as an idea to another company that only relicenses it, but I get that there needs to be a market for IP itself. reply joshuaissac 15 hours agorootparent> If you invent something, there's a work product. There is documentation, notes, blueprints, CAD files, software, etc. You can sell this and license it however you want. These would only be protected by copyright. So if you invent something but do not have the resources to create the implementation yourself (and therefore cannot patent the invention under the scheme proposed by GGP), but you licence the work products (documentation, software) to one or more companies who can then implement it, a larger, well-resourced competitor can just reimplement it without paying you as long as they did not need to use any of your documentation or software. So that reduces the value of your work products. But if the converse happened, e.g., your customer reimplements something invented by the large competitor, they can get sued, because the large company, being able to implement their invention, can therefore file a patent. So it amplifies the effect of having more resources. It would be fairer to treat the large company the same way, and only let them copyright the work products rather than patent the invention, putting them on the same level as a smaller inventor. reply solomatov 17 hours agorootparentprevCould you give examples of such companies (I am really curious)? reply joshuaissac 16 hours agorootparent> Could you give examples of such companies One example is ARM, which licenses the processor designs they create, and do not build or sell the chips themselves. reply jandrewrogers 16 hours agorootparentprevI am aware of a few orgs that license interesting software R&D often with engineering support, sometimes with an equity component. Another variant is the R&D holding company that creates separate companies to commercially exploit the R&D in different parts of the public or private sector. Most such R&D orgs are very low-profile, they usually don't have an internet presence. Many use few or no patents these days, those economics don't make sense unless the business is largely owned by lawyers, which creates a different kind of company (much closer to patent trolls). It is a bespoke kind of business, tailored to the specific technology and investment network of the people involved. reply anonymouskimmer 18 hours agorootparentprevGreat point. And then if one of those companies sold a patent that wasn't immediately licensable to an IP firm for an immediate infusion of funds should the IP firm be considered a patent troll? reply lukan 18 hours agorootparentMaybe the patent system could work, without the possibility of selling patents at all? Have not thought it out, but I know musicians also seldom profit of selling their IP to the major labels. But they are pushed into it. reply anonymouskimmer 17 hours agorootparentBased on the text of the IP clause of the US Constitution I have wondered whether selling or licensing of IP (or even assigning it to a corporation) is technically allowable. https://constitution.congress.gov/browse/article-1/section-8... : To promote the Progress of Science and useful Arts, by securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries; \"Exclusive Right\" means exclusive right. And I don't think the definition has changed much since the US Constitution was written. https://www.etymonline.com/word/exclusive I think it must at least be licensable, or authors couldn't sell copies of their works. But whether the IP rights can be sold is another question. reply freejazz 16 hours agorootparentIt means the right is exclusively granted with them. I.e. no one besides the author gets to control the exclusive rights of a patent. By your logic, they can't even license it because \"it's an exclusive right\". reply anonymouskimmer 16 hours agorootparentThey control the license according to the terms of a license. But once a patent is sold the author of it no longer has any right to it. Authors and inventors are mentioned with the same language in the clause. Since it has always been true that authors can basically only profit from their writings by selling copies or originals of their works (without selling the right to the copyrighted material itself) then some form of licensing is necessarily included in the clause for both copyright and patents. There may have been journalists at the time who wrote works for newspapers owned by others. If so, this would be a reason to include the right of selling all of the rights to one's writings or inventions in the clause. I genuinely don't know if this was the case though. reply freejazz 16 hours agorootparentAuthors can license all of their rights away. They can sell their copyrights - I don't see your point... reply anonymouskimmer 14 hours agorootparentI'm asking whether the laws which allow this are within scope of the US Constitution's clause on intellectual property rights. There are plenty of laws which have been ruled unconstitutional. But it takes someone making the complaint to a court for this to happen. Otherwise the legislature does whatever it wants. Currently a majority of the US Supreme court thinks that the status quo at the time of the writing of the US Constitution or its amendments has bearing as to the meaning of those texts. Thus I mentioned back then authors sold copies of their works while retaining all other rights as indicating that \"licensing\" is within this clause. Whether or not total sales of the rights to the work is within the purview of the clause is another question that I'm curious about. reply freejazz 14 hours agorootparent> I'm asking whether the laws which allow this are within scope of the US Constitution's clause on intellectual property rights. Which laws are those? I'm not sure why it wouldn't be in the scope of the constitutional grant of authority to congress. \"by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries\" The use of exclusive here makes perfect sense with how things worked then, and today. I think you are getting caught up in non-existent semantics. What would be the purpose of the clause if authors/inventors couldn't sell their work? what would be secured in the exclusive rights that benefits the furthering of arts and science if inventors and authors couldn't exploit their exclusive rights? I'm a copyright and patent litigator and I've never heard anyone make the argument you are making. reply anonymouskimmer 2 hours agorootparent> What would be the purpose of the clause if authors/inventors couldn't sell their work? Not that they can't sell their work, but that they can transfer their exclusive rights in such a manner that they themselves can no longer exercise those rights. And laws which allow this are obviously, by definition of the words at the time, not \"securing\" those rights to the authors and inventors. You can't secure something to someone by allowing them to (both post-hoc and especially pre-hoc) permanently transfer those rights. Especially the pre-hoc transmission of rights as seen in various contracts (work for hire, etcetera) completely flouts the \"securing\" basis of the constitutional IP clause in that under no circumstances whatsoever did the rights ever belong to the author/inventor. The Constitution did not grant congress the authority to make laws allowing intellectual property protections to a pre-hoc transfer, but only possibly to transfer in which the author/inventor first had exclusive rights. Therefore any contracts which automatically assign any rights to any creations to another party the moment those creations are created cannot be covered by intellectual property protection laws created pursuant to Article 1, section 8, clause 8 powers, but must have some other constitutional basis (possibly under the commerce clause?). I guess you could get around this argument fairly easily by saying that the \"limited time\" is X number of years or until sold. But then I still don't understand under what authority the purchasing party gets these IP rights, as they are not the author or inventor, and thus not entitled to any securing of rights under this clause. If they do have rights it must be under either common law which pre-existed 1789, or under another section and clause of the Constitution, since this is not a 9th or 10th amendment issue. Congress can't just make law willy-nilly however it wants to, but must do so under one of its enumerated powers. I guess another way around this, and possibly the way it is done in IP law (you would know better than I), is that these rights aren't literally sold to another, but instead a permanent licensing contract is signed in which the author/inventor grants use of their exclusive rights to the licensee to do with however they wish. In this way the \"exclusive rights\" would still be secured to the author/inventor, though exercised by the other party. This seems like sophistry, but much of the law is. reply maxloh 15 hours agorootparentprevARM for example. reply willvarfar 17 hours agoparentprevWhilst good intentioned, it might well work the other way: Dedicated patent trolls will trivially overcome any hurdles by cheaply doing just enough to legally demonstrate they are working on future commercial applications blah blah honest. Meanwhile, it likely puts up a prohibitive cost that will prevent the smallest genuine inventors from inventing? reply ryandrake 17 hours agorootparentThat's the big problem with societies based on the letter of the law vs. the spirit of the law. Human nature has repeatedly demonstrated that if the letter of the law is what matters, people will work night and day to technically comply with the letter of the law, so they can continue to do the bad thing legally. Whole cottage industries will spring up to guide businesses right up to that legal line and sell them the tools and techniques to ensure they barely don't cross it. In such a society, the rules need to be enormous and complex, much more than a 2 sentence HN post, to eliminate all the edge cases and loopholes everyone will naturally want to take advantage of. reply dosethree 18 hours agoparentprevjust abolish the patent system entirely. at minimum, for software reply declaredapple 14 hours agorootparentI'm on board with this. It shouldn't exist for software, I'd be happy to see it go for hardware too. I'd be more on-board with the idea if non-software patents only had say a 5 year lifespan reply mistrial9 18 hours agorootparentprevcompare and contrast to industry practices today https://www.gnu.org/philosophy/software-patents.en.html reply dosethree 14 hours agorootparentfantastic article reply riazrizvi 12 hours agoparentprevWhile appealing to me as an entrepreneur, if I step back, I don't see how this law could work. Patent Law is the regulation of intellectual property, as such, the way property is regulated, informs the way intellectual property should be regulated. Would it be possible to pass a law that says you can't own a patch of land unless you develop it sufficiently for some public utility? You can't own it unless you build a house on it, or an office? What about all the rough land, that isn't close to a development yet, but is anticipated to be? If someone can tell me how a law like this has been shown to work, perhaps even in a limited case like densely populated zones, then I might be persuaded. reply hervature 12 hours agorootparent> Would it be possible to pass a law that says you can't own a patch of land unless you develop it sufficiently for some public utility? This is exactly how mineral rights work. The federal law says you need to do $100 worth of development on every claim every year to maintain it [1]. This is not something new. [1] - https://www.ecfr.gov/current/title-43/subtitle-B/chapter-II/... reply riazrizvi 12 hours agorootparentAh okay, thanks. This is what I was looking for. reply berniedurfee 16 hours agoparentprev100% agree. Pretty sure the original idea of patents was to protect the inventor while they brought a product to market or licensed the patent to others to improve their products. Holding a patent without even attempting to bring the idea to market should invalidate the patent after some reasonable amount of time. The whole system as it is today needs a hard sanity check. reply grishka 13 hours agoparentprevWould work even better if patents were non-transferable and only assignable to actual people, not companies or other entities. reply hcrean 11 hours agorootparentWhat if Bob and Alice and Charlie all had a hand in developing invention X... suddenly we would find ourselves just redefining companies. reply grishka 10 hours agorootparentThen you assign the patent to them collectively by listing them all as inventors. It's not redefining companies because it's still assigned to people, not an abstract entity that can arbitrarily change hands in the future. reply cft 17 hours agoparentprevThey will fake usage. Software parents should not exist reply IG_Semmelweiss 16 hours agoparentprevlaw of unintended consequences the moment you put an expiration date on patents due to lack of use, watch moneyed competitors sitting around waiting for your patent to expire instead of using yours to bring it to market reply KptMarchewa 16 hours agorootparentYou mean it would bring the price of licensing the patent down? I don't see the downside. reply IG_Semmelweiss 13 hours agorootparentI'm not sure how small inventors could benefit from their creativity. What is at the core of this need to steal other people's ideas? HN is supposed to respect the rule of law and western respect for innovation and collecting the fruits of your labor. If someone won't give you a decent price, reverse engineer their work and come up with a creative alternative. I'm not arguing that its OK to patent code or abstract ideas that are the basis for BS \"catch all\" patent infringement lawsuits or amazon 1-click buy nonsense. I'm talking is about real inventions. Television, radio, wheeled luggage, etc. I also think that code should be copyrighted, but cannot be patented. reply yieldcrv 16 hours agorootparentprevthen you shouldn’t form the patent then as you would still just be increasing costs for the industry by existing and delaying things you could have just written about it on your blog and been the same place and been a net positive for society reply IG_Semmelweiss 13 hours agorootparentI'm not arguing that its OK to patent code or abstract ideas that are the basis for BS \"catch all\" patent infringement lawsuits or amazon 1-click buy nonsense. I'm talking is about real inventions. Television, radio, wheeled luggage, etc. I also think that code should be copyrighted, not patented. Patents use to mean something else, and I can see we are talking about different things. reply ummonk 15 hours agoparentprevSo if I invent something but don’t have the capital to manufacture it myself, I shouldn’t be able to make money from licensing it to companies? reply declaredapple 14 hours agorootparent> but don’t have the capital to manufacture it myself You're looking at 10k to file it, and then all it gives you is the ability to sue. If [insert company] violates it, you could easily be looking at 100k+ for litigation that you may or may not win. > So if I invent something My problem is you don't need to \"invent\" anything. You just need to be the first to file the paperwork (and have the cash to do so). \"[sensor] on [smartwatch, glasses, goggles, belts, chairs, whatever]\" and now nobody else can do it for 20 years. Even if it's blatantly obvious that an chair can sense if you're sitting in it to turn on the tv automatically. reply iamthirsty 15 hours agorootparentprevWouldn't that be a \"use it\" situation? reply squeaky-clean 13 hours agorootparentHow are patent trolls not \"using it\" then? If licensing the patent is using it, this suggestion does nothing to prevent trolling. reply djbusby 18 hours agoprevLots of patent hate in the first few comments. If we take the position that an inventor should be able to try and get profit from their invention how can we protect that without patent system? reply kemayo 18 hours agoparentThe myth of patents is that some inventor working in their garage comes up with a genius invention, patents it, and then can leverage that patent-granted period of exclusivity into a thriving business. Hard work and smarts translating directly into rewards! This is, of course, a myth. It's not impossible for that to happen, theoretically, but the way the patent system actually works these days is that large companies patent anything they ever think of regardless of actual novelty, holding on to vast piles of patents as weapons of strategic deterrence. The megacorps exist in a state of patent detente -- unless someone is particularly blatant about a violation, it's better not to sue another corp because they'll just countersue with their own patent hoard. Then you'll both be stuck in years of litigation, working to get each other's patents invalidated, unsure of who is going to come out of it with a remaining claim. When the tiny independent inventor appears, however, they don't have any of that patent-hoard protection. So it's easy for a big company in a vaguely related industry to squash them if they want to. Or wait until there's enough money being made that it's worth showing up and demanding fees. Sure, the company's patents may well be bogus and unrelated, but the tiny inventor can't afford to spend the next five years litigating that. reply shagie 18 hours agorootparentBoard game rules fall under patents. It has an example of the garage process, patent, infringement, and win. https://www.insurancejournal.com/news/west/2012/11/26/271633... > A company headed by a Colorado professor who invented a strategy board game has won a $1.6 million patent infringement verdict. > ... > Innovention prevailed in a patent infringement against MGA, Wal-Mart Stores and Toys R Us. A federal court in New Orleans found that MGA’s Laser Battle game, sold through the two retailers, infringed on Innovention’s patent for Khet. https://boardgamegeek.com/boardgame/16991/khet-laser-game https://patents.google.com/patent/US7264242 --- Note the rarity of this happening that it makes the news compared to how often patents are thrown around in courts. reply brlewis 17 hours agorootparent> Board game rules fall under patents Please supply evidence. All links in your comment relate to a patent to an invention where lasers are an essential part of the claims. I'm not convinced that rules alone would be patentable subject matter. reply shagie 17 hours agorootparenthttps://www.upcounsel.com/board-game-patents https://patentpc.com/blog/example-of-how-a-board-game-is-pat... https://boardgamegeek.com/thread/493249/mythbusting-game-des... https://www.theiplawblog.com/2019/04/articles/intellectual-p... http://www.gamecabinet.com/info/PatentSearch.html https://boardgamegeek.com/filepage/93654/blue-and-gray-paten... (Blue and Gray) - this particular one is well known because Sid Sackson went trawling through patents and found it and wrote about it. From https://archive.org/details/gamutofgames0000sack/page/9/mode... > THE FILES OF PATENTS that have been granted are a fruitful hunting ground for forgotten games, although going through these files, as anyone who has ever been involved in a patent search well knows, is a time consuming job. Often the patented games are downright silly, such as a set of dominos made of rubber so that they can double as ink erasers (No. 729,489) or a sliding block puzzle with edible pieces so that a player who despairs of a solution can find consolation in gratifying his stomach (No. 1,274,294). Often the patents are repetitious: There are over a hundred variations of the well-known checkerboard and over a thousand different baseball games. > But often the patented games are a fascinating reflection of their time: races to the North Pole, war games to capture the Kaiser, automobile games, in the infancy of the automobile, and radio games for the crystal-set fanatic. https://patents.google.com/patent/US2026082A/en (Monopoly) https://patents.google.com/patent/US5662332A/en (Magic The Gathering) https://patents.google.com/patent/US6352262B1/en (Icehouse) reply brlewis 16 hours agorootparent> https://patents.google.com/patent/US5662332A/en (Magic The Gathering) Thank you. I concede, this one is proof that an application that's essentially board game rules can be accepted. Whether rules not tied to a particular machine should be accepted is debatable. https://en.wikipedia.org/wiki/Machine-or-transformation_test...? reply raverbashing 2 hours agorootparentprevBut Board Games are not software and there are other aspects of a game that can be IP protected (trademarks, etc) reply kentonv 16 hours agorootparentprevIt's not a myth! My uncle is such a garage inventor, and has made a comfortable living for himself by licensing a number of different inventions. One of the things he invented was the Zipit drain cleaner. It's a long piece of plastic with barbs on it. You shove it down your drain, pull it back out, and it pulls out a gigantic disgusting hairball that you had no idea was down there! It's really quite remarkable, it works so much better than what people were using to unclog their drains before. It seems obvious in retrospect, so why weren't such products already on the market? Unfortunately after seeing the success a competitor decided to copy it and, when my uncle tried to sue, the competitor got the patent invalided. Meanwhile my uncle lost much of his savings in legal fees. https://usinventor.org/portfolio-items/34660/ In my (biased) opinion, this was a case of a legitimate, deserving patent. But all the junk patents and patent trolls, and the arms race you describe, have shifted expectations so much that the patent review board now tends to invalidate everything brought before them. So now the patent system doesn't even work for the people it's supposed to work for, since when a small inventor makes something actually worth patenting, a big company can just invalidate the patent. With all that said, I do",
    "originSummary": [
      "Cloudflare has emerged victorious in a trial against patent trolls Sable IP and Sable Networks.",
      "The jury concluded that Cloudflare did not infringe on the asserted patent and declared Sable's patent claims invalid.",
      "The win can be attributed to the efforts of Cloudflare's legal team, external counsel, and participants in the Project Jengo initiative, which rewards individuals for providing evidence that invalidates patent trolls' claims.",
      "Cloudflare's success in invalidating parts of three Sable patents has limited their ability to file lawsuits against other companies.",
      "The case underscores the high costs and risks associated with patent litigation and sends a warning to patent trolls that Cloudflare will not be easily intimidated."
    ],
    "commentSummary": [
      "The discussion covers multiple aspects of the patent system, such as patent quality, patent trolls, software patents, intellectual property taxation, patent duration, and the role of patents in innovation.",
      "Suggestions for improvement include incentivizing companies to defend against invalid patents, increasing funding for the patent office, penalizing bad faith patent filings, and addressing the issue of companies creating shell entities.",
      "There are debates about the purpose and effectiveness of patents, with some advocating for their elimination and others emphasizing their role in protecting inventors and promoting development. The impact of patents on different industries, like pharmaceuticals and technology, is also discussed."
    ],
    "points": 1001,
    "commentCount": 362,
    "retryCount": 0,
    "time": 1707747282
  },
  {
    "id": 39344815,
    "title": "AMD Funds Open-Source CUDA Implementation for AMD GPUs on ROCm",
    "originLink": "https://www.phoronix.com/review/radeon-cuda-zluda",
    "originBody": "AMD Quietly Funded A Drop-In CUDA Implementation Built On ROCm: It's Now Open-Source Written by Michael Larabel in Display Drivers on 12 February 2024 at 09:00 AM EST. While there have been efforts by AMD over the years to make it easier to port codebases targeting NVIDIA's CUDA API to run atop HIP/ROCm, it still requires work on the part of developers. The tooling has improved such as with HIPIFY to help in auto-generating but it isn't any simple, instant, and guaranteed solution -- especially if striving for optimal performance. Over the past two years AMD has quietly been funding an effort though to bring binary compatibility so that many NVIDIA CUDA applications could run atop the AMD ROCm stack at the library level -- a drop-in replacement without the need to adapt source code. In practice for many real-world workloads, it's a solution for end-users to run CUDA-enabled software without any developer intervention. Here is more information on this \"skunkworks\" project that is now available as open-source along with some of my own testing and performance benchmarks of this CUDA implementation built for Radeon GPUs. From several years ago you may recall ZLUDA that was for enabling CUDA support on Intel graphics. That open-source project aimed to provide a drop-in CUDA implementation on Intel graphics built atop Intel oneAPI Level Zero. ZLUDA was discontinued due to private reasons but it turns out that the developer behind that (and who was also employed by Intel at the time), Andrzej Janik, was contracted by AMD in 2022 to effectively adapt ZLUDA for use on AMD GPUs with HIP/ROCm. Prior to being contracted by AMD, Intel was considering ZLUDA development. However, they ultimately turned down the idea and did not provide funding for the project. Andrzej Janik spent the past two years bringing ZLUDA to Radeon GPUs and it works: many CUDA software can run on HIP/ROCm without any modifications -- or other processes... Just run the binaries as you normally would while ensuring that the ZLUDA library replacements to CUDA are loaded. For reasons unknown to me, AMD decided this year to discontinue funding the effort and not release it as any software product. But the good news was that there was a clause in case of this eventuality: Janik could open-source the work if/when the contract ended. Andrzej Janik reached out and provided access to the new ZLUDA implementation for AMD ROCm to allow me to test it out and benchmark it in advance of today's planned public announcement. I've been testing it out for a few days and it's been a positive experience: CUDA-enabled software indeed running atop ROCm and without any changes. Even proprietary renderers and the like working with this \"CUDA on Radeon\" implementation. The ZLUDA implementation though isn't 100% fail-safe as NVIDIA OptiX support not being fully supported and some features such as software not using PTX assembly code isn't currently handled. But for the most part this implementation is surprisingly capable for being a single developer effort. For those wondering about the open-source code, it's dual-licensed under either Apache 2.0 or MIT. Rust fans will be excited to know the Rust programming language is leveraged for this Radeon implementation. NOTE: In my screenshots and for the past two years of development the exposed device name for Radeon GPUs via CUDA has just been \"Graphics Device\" rather than the actual AMD Radeon graphics adapter with ROCm. The reason for this has been due to CUDA benchmarks auto-reporting results and other software that may have automated telemetry, to avoid leaking the fact of Radeon GPU use under CUDA, it's been set to the generic \"Graphics Device\" string. I'm told as part of today's open-sourcing of this ZLUDA on Radeon code that the change will be in place to expose the actual Radeon graphics card string rather than the generic \"Graphics Device\" concealer. 55 Comments - Next Page Tweet Page 1 - Introduction Page 2 - More About ZLUDA For Radeon GPUs Page 3 - ZLUDA Radeon GPU CUDA Benchmarks Page 4 - ZLUDA Radeon GPU CUDA Benchmarks Page: 1 2 3 4 Next Page",
    "commentLink": "https://news.ycombinator.com/item?id=39344815",
    "commentBody": "AMD funded a drop-in CUDA implementation built on ROCm: It's now open-source (phoronix.com)973 points by mfiguiere 20 hours agohidepastfavorite378 comments Keyframe 17 hours agoThis event of release is however a result of AMD stopped funding it per \"After two years of development and some deliberation, AMD decided that there is no business case for running CUDA applications on AMD GPUs. One of the terms of my contract with AMD was that if AMD did not find it fit for further development, I could release it. Which brings us to today.\" from https://github.com/vosen/ZLUDA?tab=readme-ov-file#faq so, same mistake intel made before. reply tgsovlerkhgsel 11 hours agoparentHow is this not priority #1 for them, with NVIDIA stock shooting to the moon because everyone does machine learning using CUDA-centric tools? If AMD could get 90% of the CUDA ML stuff to seamlessly run on AMD hardware, and could provide hardware at a competitive cost-per-performance (which I assume they probably could since NVIDIA must have an insane profit margin on their GPUs), wouldn't that be the opportunity to eat NVIDIA's lunch? reply HarHarVeryFunny 7 hours agorootparentIMO the trouble is that CUDA is too low level to allow emulation without a major loss of performance, and even if there was a choice of CUDA-compatible vendors, people are ultimately going to vote with their wallets. It's not enough to be compatible - you need to be compatible while providing the same or better performance (else why not just use NVIDIA). A better level to target compatibility would be at the framework level such as PyTorch, where the building blocks of neural networks (convolution, multi-head attention, etc, etc) are high level and abstract enough to allow flexibility in mapping them onto AMD hardware without compromising performance. However, these frameworks are forever changing and playing continual catch-up there still wouldn't be a great place to be, especially without a large staff dedicated to the effort (writing hand-optimized kernels), which AMD don't seem to be able/willing to muster. So, finally, perhaps the strategically best place for AMD to invest would be in compilers and software tools to allow kernels to be written in a high level language. Becoming a first class Mojo target wouldn't be a bad place to start, assuming they are not already in partnership. reply hnfong 1 hour agorootparent> However, these frameworks are forever changing and playing continual catch-up there still wouldn't be a great place to be, especially without a large staff dedicated to the effort (writing hand-optimized kernels), which AMD don't seem to be able/willing to muster. The situation in reality is quite actually quite bad. Given that I have a M2 Max and no nVidia cards, I've tried enough PyTorch-based ML libraries that at some point, I basically expect them to flat out show an error saying CUDA 10.x+ is required once the dependencies are installed (eg. one of them being the bitsandbytes library -- in fairness, there's apparently some effort trying to port the code to other platforms as well). As of today, the whole field is moving too fast that it's simply not worth it for a solo dev or even a small team to even attempt getting a non-CUDA stack up and running, especially with the other major GPU vendors not (able to?) hiring people to port the hand-optimized CUDA kernels. Hopefully the situation will change after these couple years of frenzy, but in the time being I don't see any viable way to avoid using a CUDA stack if one is serious with getting ML stuff done. reply pheatherlite 11 hours agorootparentprevThe only reason our lab bought 20k worth of Nvidia gpu cards rather than amd was the cuda industry standard (might as wellbe). It's kind of mind boggling how much business amd must be losing over this. reply Rafuino 10 hours agorootparentSo, your lab bought ~1 GPU? reply polygamous_bat 10 hours agorootparentHey stop shaming the GPU poor, not everyone is Mark Zuckerberg ordering $8bn. of GPUs. reply exikyut 8 hours agorootparentprevHey, I should go play with those workstation/server configurators now they'll have been updated to supply A100Xs and such... reply paulmd 8 hours agorootparentprevor a rack of 3090s/4090s or quadros (the \"no datacenter\" clause obviously excludes workstations, and the terms of this license cannot be applied to the open kernel driver since it's GPL'd) reply Modified3019 9 hours agorootparentprevThat was a good decision. The amount of lamenting engineers I’ve seen over the years who’ve been given the task of trying to get more affordable AMD cards to work with enterprise functionality is nontrivial. AMD nearly borders on hostility with its silence, even if you want to throw millions at them, it’s insane. At least Nvidia, which I fucking hate, will happily hold out their hand for cash even from individuals. So now we’re in a hilarious situation where people from hobbyists to enterprise devs are hoping for intel to save the day. reply up2isomorphism 4 hours agorootparentprevYour “lab” does not sound like a lab in the classical sense. reply llm_trw 10 hours agorootparentprevNever underestimate AMD's ability to fail. Ryzen was a surprise to everyone not because it was good, but because they didn't fuck it up within two generations. AMD cards have more raw compute than nvidia, they are better than nvidia, yet the software is so bad that I gave up on using it and switched to nvidia. Two weeks of debugging driver errors vs 30 minutes of automated updates. reply tormeh 8 hours agorootparentIt's rather shocking that with RADV, Valve (mostly) has written a better RDNA2 driver than AMD has managed for their own cards. Besides the embarrassment, AMD is leaving tons of performance and therefore market share on the table. You have to wonder wtf is going on over at AMD. reply dralley 8 hours agorootparentRADV was started by David Arlie of Red Hat, although Valve been dedicating some very significant resources over the past few years. reply test6554 4 hours agorootparentprevNvidia controls CUDA the software spec, Nvidia also controls the hardware CUDA runs on. The industry adopts CUDA standards and uses the latest features. AMD cannot keep up with arbitrarily changing hardware and software while trying to please developers that want what was just released. They would always be a generation behind at tremendous expense. reply make3 11 hours agorootparentprevit's a common misconception that deep learning stuff is built in cuda. it's actually built on CUDNN kernels that don't use cuda but are actually gpu assembly written by hand by phds. I'm really not convinced that this project here would be able to be used for this. the ROCm kernels that are analogue to cudnn though, yes reply abbra 3 hours agorootparentThis project relies on ROCm for all it's CUDNN magic. reply VoxPelli 14 hours agoparentprevSounds like he had a good contract, would be great to read more about that, hopefully more devs could include the same phrasing! reply RachelF 10 hours agoparentprevYeah, AMD look like idiots for doing this. Either they are very stupid, or open sourcing the library stops NVidia from suing them in a repeat of the Oracle/Google lawsuit over Java APIs? I'm not sure what the reason is? reply yen223 7 hours agorootparentI think AMD is focusing on the \"inference\" side of ML, which doesn't really require CUDA or similar, and is what they believe a much larger market. Time will tell if that strategy is going to pan out. Ceding the ML \"training\" market entirely to Nvidia is certainly a bold move reply bitbang 8 hours agorootparentprevThat was my immediate thought: the software is made publicity available to help add value to their product offering, but they plausable deniability in court and don't have to bear the burden of potential lawsuits or support. reply jacoblambda 13 hours agoparentprevI mean it could also be that there was no business case for it as long as it remained closed source work. If the now very clearly well functioning implementation continues to perform as well as it is, the community may be able to keep it funded and functioning. And the other side of this is that with renewed AMD interest/support for the rocm/HIP project, it might be just good enough as a stopgap step to push projects towards rocm/HIP adoption. (included below is another blurb from the readme). > I am a developer writing CUDA code, does this project help me port my code to ROCm/HIP? > Currently no, this project is strictly for end users. However this project could be used for a much more gradual porting from CUDA to HIP than anything else. You could start with an unmodified application running on ZLUDA, then have ZLUDA expose the underlying HIP objects (streams, modules, etc.), allowing to rewrite GPU kernels one at a time. Or you could have a mixed CUDA-HIP application where only the most performance sensitive GPU kernels are written in the native AMD language. reply nikanj 14 hours agoparentprevThis should be the top comment here, people are getting their hopes up for nothing reply pk-protect-ai 13 hours agoparentprev> After two years of development and some deliberation, AMD decided that there is no business case for running CUDA applications on AMD GPUs Who was responsible at AMD for this project and why is he still not fired???????? How brain dead someone have to be to reject the major market share?????? reply enonimal 18 hours agoprevFrom the ARCHITECTURE.md: > Those pointers point to undocumented functions forming CUDA Dark API. It's impossible to tell how many of them exist, but debugging experience suggests there are tens of function pointers across tens of tables. A typical application will use one or two most common. Due to they undocumented nature they are exclusively used by Runtime API and NVIDIA libraries (and in by CUDA applications in turn). We don't have names of those functions nor names or types of the arguments. This makes implementing them time-consuming. Dark API functions are are reverse-engineered and implemented by ZLUDA on case-by-case basis once we observe an application making use of it. reply gdiamos 12 hours agoparentThese were a huge pain in the ass when I tried this 20 years ago on Ocelot. Eventually one of the NVIDIA engineers just asked me to join and I did. :-P reply jherico 10 hours agorootparentDo the job you want, not the job you have, eh? reply leeoniya 17 hours agoparentprevfertile soil for Alyssa and Asahi Lina :) https://rosenzweig.io/ https://vt.social/@lina reply smcl 14 hours agorootparentI know that Lina doesn't like a lot of the attention HN sends her way so it may be better if you don't link her socials here. reply leeoniya 9 hours agorootparentpretty sure she's a vt.social admin, so she can always do what jwz does with HN referer headers :D given how omnipresent she is with her live streaming, it's a bit like South Park's Worldwide Privacy Tour: https://www.youtube.com/watch?v=2N8_5LDkZwY reply bigdict 12 hours agorootparentprevSounds ridiculous, why have a public presence on a social network then? reply dralley 8 hours agorootparentIIRC, it's not that she doesn't like the attention to her work, it's that she doesn't like how quickly conversations get derailed by things that have nothing to do with the work. reply cyanydeez 12 hours agorootparentprevoh. I think the emphasis is on hacker news. you know certain social media sites contain certain toxic conversants. reply bigdict 12 hours agorootparent> you know certain social media sites contain certain toxic conversants. That's just people… reply throw10920 6 hours agorootparentprevHN isn't very toxic. You must be confusing it with another social media site. If anything, the Asahi devs are the ones acting out. reply throw10920 6 hours agorootparentprevI think it would be better to avoid mention of them (or the Asahi project) on HN entirely, for that matter. If they don't want HN to criticize them, then they should expect to not get the free publicity that HN offers. Seems fair enough. Also, between accusing HN of \"supporting trans genocide\" (which is some mix between \"impossible\" and \"false\"), and poisoning links with HN referrer URLs, they don't seem like very good people themselves. reply squigz 3 hours agorootparentCan you provide some context about this? reply squigz 3 hours agorootparentFound some... Seems crazy to me; this community has never felt transphobic to me... https://news.ycombinator.com/item?id=36226845 reply pests 3 hours agorootparentThat is unhinged. I am at a loss after reading that thread. I always thought HN was a little over represented in the queer and furry communities. reply PoignardAzur 14 hours agoparentprevHaving an ARCHITECTURE.md file at all is extremely promising, but theirs seems pretty polished too! reply Cu3PO42 17 hours agoprevI'm really rooting for AMD to break the CUDA monopoly. To this end, I genuinely don't know whether a translation layer is a good thing or not. On the upside it makes the hardware much more viable instantly and will boost adoption, on the downside you run the risk that devs will never support ROCm, because you can just use the translation layer. I think this is essentially the same situation as Proton+DXVK for Linux gaming. I think that that is a net positive for Linux, but I'm less sure about this. Getting good performance out of GPU compute requires much more tuning to the concrete architecture, which I'm afraid devs just won't do for AMD GPUs through this layer, always leaving them behind their Nvidia counterparts. However, AMD desperately needs to do something. Story time: On the weekend I wanted to play around with Stable Diffusion. Why pay for cloud compute, when I have a powerful GPU at home, I thought. Said GPU is a 7900 XTX, i.e. the most powerful consumer card from AMD at this time. Only very few AMD GPUs are supported by ROCm at this time, but mine is, thankfully. So, how hard could it possibly to get Stable Diffusion running on my GPU? Hard. I don't think my problems were actually caused by AMD: I had ROCm installed and my card recognized by rocminfo in a matter of minutes. But the whole ML world is so focused on Nvidia that it took me ages to get a working installation of pytorch and friends. The InvokeAI installer, for example, asks if you want to use CUDA or ROCm, but then always installs the CUDA variant whatever you answer. Ultimately, I did get a model to load, but the software crashed my graphical session before generating a single image. The whole experience left me frustrated and wanting to buy an Nvidia GPU again... reply sophrocyne 11 hours agoparentHey there - I'm a maintainer (and CEO) of Invoke. It's something we're monitoring as well. ROCm has been challenging to work with - we're actively talking to AMD to keep apprised of ways we can mitigate some of the more troublesome experiences that users have with getting Invoke running on AMD (and hoping to expand official support to Windows AMD) The problem is that a lot of the solutions proposed involve significant/unsustainable dev effort (i.e., supporting an entirely different inference paradigm), rather than \"drop in\" for the existing Torch/diffusers pipelines. While I don't know enough about your set up to offer immediate solutions, if you join the discord, am sure folks would be happy to try walking through some manual troubleshooting/experimentation to get you up and running - discord.gg/invoke-ai reply Cu3PO42 10 hours agorootparentHi! I really appreciate you taking the time to reply. I have since gotten Invoke to run and was already able to get some results I'm really quite happy with, so thank you for your time and commitment working on Invoke! I understand that ROCm is still challenging, but it seems my problems were less related to ROCm or Invoke itself and more to Python dependency management. It really boiled down to getting the correct (ROCm) versions of packages installed. Installing Invoke from PyPi always removed my Torch and installed CUDA-enabled Torch (as well as cuBLAS, cuDNN, ...). Once I had the correct versions of packages, everything just worked. To me, your pyproject.toml looks perfectly sane, so I wasn't sure how to go about fixing the problem. What ended up working for me was to use one of AMD's ROCm OCI base images, manually installing all dependencies, foregoing a virtual environment, cloning your repo (, building the frontend), and then installing from there. The majority of my struggle would have been solved by a recent working Docker image containing a working setup. (The one on Docker Hub is 9 months old.) Trying to build the Dockerfile from your repo, I also ended up with a CUDA-enabled Torch. It did install the correct one first, but in a later step removed the ROCm-enabled Torch to switch it for the CUDA-enabled one. I hope you'll consider investing some resources into publishing newer, working builds of your Docker image. reply doctorpangloss 7 hours agorootparent> Installing Invoke from PyPi... To me, your pyproject.toml looks perfectly sane, so I wasn't sure how to go about fixing the problem. You can't install the PyTorch that's best for the currently running platform using a pyproject.toml with a setuptools backend, for starters. Invoke would have to author a setup.py that deals with all the issues, in a way that is compatible with build isolation. > The majority of my struggle would have been solved by a recent working Docker image containing a working setup. (The one on Docker Hub is 9 months old.) Why? Given the state of the ecosystem, what guarantee is there really that the documentation for Docker Desktop with AMD ROCm device binding is going to actually work for your device? (https://rocm.docs.amd.com/projects/MIVisionX/en/latest/docke...) There is a lot of ad-hoc reinvention of tooling in this space. reply Cu3PO42 2 hours agorootparent> You can't install the PyTorch that's best for the currently running platform using a pyproject.toml with a setuptools backend, for starters. I see. I do know Python, but my knowledge of setuptools, pip, poetry and whatever else have you. To get my working setup, I specified an --index-url for my Torch installation. Does that not work while using their current setup? > Why? Given the state of the ecosystem, what guarantee is there really that the documentation for Docker Desktop with AMD ROCm device binding is going to actually work for your device? Well, they did work for me. Though I think only passing /dev/{dri,kfd} and setting seccomp=unconfined was sufficient. So for my particular case, getting a working image was the only missing step. From a more general POV: it might not make sense to invest in a ROCm OCI image from a short-term business perspective, but in the long term and based purely on principal, I do think the ecosystem should strive to be less reliant on CUDA and only CUDA. reply sophrocyne 8 hours agorootparentprevYou bet - Thanks for the feedback. Glad you're enjoying Invoke! We do have Docker packages hosted on GH, but I'll be the first to admit that we haven't prioritized ROCm. Contributors who have AMDs are a scant few, but maybe we'll find some help in wrangling that problem now that we know there's an avenue to do so. reply Cu3PO42 2 hours agorootparentI hate maintaining my own build instructions as much as the next guy, so I'll try to get your Dockerfile working for me and then send a PR. reply latchkey 11 hours agorootparentprevInvoke is awesome. Let me know if you guys want some MI300x to develop/test on. =) We've also got some good contacts at AMD if you need help there as well. reply nocombination 13 hours agoparentprevAs other folks have commented, CUDA not being an open standard is a large part of the problem. That and the developers who target CUDA directly when writing Stable Diffusion algorithms—they are forcing the monopoly. Even at the cost of not being able to squeeze every ounce out of the GPU, portability greatly improves software access when people target Vulkan et al. reply westurner 14 hours agoparentprev> Proton+DXVK for Linux gaming \"Building the DirectX shader compiler better than Microsoft?\" (2024) https://news.ycombinator.com/item?id=39324800 E.g. llama.cpp already supports hipBLAS; is there an advantage to this ROCm CUDA-compatibility layer - ZLUDA on Radeon (and not yet Intel OneAPI) - instead or in addition? https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#hi... https://news.ycombinator.com/item?id=38588573 What can't WebGPU abstract away from CUDA unportability? https://news.ycombinator.com/item?id=38527552 reply Certhas 17 hours agoparentprevThey are focusing on HPC first. Which seems reasonable if your software stack is lacking. Look for sophisticated customers that can help build an ecosystem. As I mentioned elsewhere, 25% of GPU compute on the Top 500 Supercomputer list is AMD. This all on the back of a card that came out only three years ago. We are very rapidly moving towards a situation where there are many, many high-performance developers that will target ROCm. reply ametrau 16 hours agorootparentIs a top 500 super computer list a good way of measuring relevancy in the future? reply latchkey 16 hours agorootparentNo, it isn't. What is a better measure is to look at businesses like what I'm building (and others), where we take on the capex/opex risk around top end AMD products and bring them to the masses through bare metal rentals. Previously, these sorts of cards were only available to the Top 500. reply llm_trw 9 hours agorootparentprevYes it is, it's how cuda got it's dominance 10 years ago. Businesses don't release their source code, super computers are attached to labs and universities and have much better licenses for software, or publish papers about it. reply nialv7 13 hours agoparentprevI am surprised that everybody seem to have forgotten the (in)famous Embrace, Extend and Extinguish strategy. It's time for Open Source to be on the extinguishing side for once. reply bntyhntr 15 hours agoparentprevI would love to be able to have a native stable diffusion experience, my rx 580 takes 30s to generate a single image. But it does work after following https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki... I got this up and running on my windows machine in short order and I don't even know what stable diffusion is. But again, it would be nice to have first class support to locally participate in the fun. reply Cu3PO42 14 hours agorootparentI have heard that DirectML was a somewhat easier story, but allegedly has worse performance (and obviously it's Windows only...). But I'm not entirely suprised that setup is somewhat easier on Windows, where bundling everything is an accepted approach. With AMD's official 15GB(!) Docker image, I was now able to get the A1111 UI running. With SD 1.5 and 30 sample iterations, generating an image takes under 2s. I'm still struggling to get InvokeAI running. reply washadjeffmad 9 hours agorootparentThat has to include the model(s), no? Also, nothing is easier on Windows. It's a wonder that anything works there, except for the power of recalcitrance. Not dogging Windows users, but once your brain heals, it just can't go back. reply Cu3PO42 3 hours agorootparentIt actually doesn't include the models! The image is Ubuntu with ROCm and a number of ML libraries, such as Torch, preinstalled. > Also, nothing is easier on Windows. As much as I, too, dislike Windows, I still have to disagree. I have encountered (proprietary) software which was much easier to get working on Windows. For example, Cisco AnyConnect with SmartCard authentication has been a nightmare for me on Linux. reply bavell 5 hours agoparentprevTry with ComfyUI... works great and easy setup on my 6750XT. I've had it working for about a year now with SD, LlamaCpp and WhisperCpp. reply whywhywhywhy 16 hours agoparentprev> I'm really rooting for AMD to break the CUDA monopoly Personally I want Nvidia to break the x86-64 monopoly, with how amazing properly spec'd Nvidia cards are to work with I can only dream of a world where Nvidia is my CPU too. reply weebull 12 hours agorootparent> Personally I want Nvidia to break the x86-64 monopoly The one supplied by two companies? reply Keyframe 11 hours agorootparentMaybe he meant homogeneity which Nvidia did try and tries with Arm.. but, on the other hand how wild would it be for Nvidia to enter x86-64 as well? It's probably never going to happen due to licensing if nothing else, lest we remember nForce chipset ordeal with intel legal. reply paulmd 8 hours agorootparenthttps://en.wikipedia.org/wiki/Project_Denver#History reply paulmd 8 hours agorootparentprev\"minor spelling/terminology mistake, activate the post-o-tron\" reply mickael-kerjean 10 hours agorootparentprevHow would this a good idea? I am not very familiar with GPU programming but the small amount I've tried was nothing but pain a few years ago on linux, it was so bad that Torvald publicly used the f word in a very public event. That aside, CUDA seem like a great way to lock people in even further like AWS does with absolutely everything reply Qwertious 6 hours agorootparent>I am not very familiar with GPU programming but the small amount I've tried was nothing but pain a few years ago on linux, it was so bad that Torvald publicly used the f word in a very public event. I'm pretty sure Torvalds was giving the finger over the subject of GPU drivers (which run on the CPU), not programming on the Nvidia GPU itself. Particularly, they namedropped Bumblebee (and maybe Optimus?) which was more about power-management and making Nvidia cooperate with a non-Nvidia integrated GPU than it was about the Nvidia GPU itself. reply smcleod 14 hours agorootparentprevThat’s already been done with ARM. reply kuschkufan 16 hours agorootparentprevapt username reply formerly_proven 13 hours agoparentprev> I'm really rooting for AMD to break the CUDA monopoly. To this end, I genuinely don't know whether a translation layer is a good thing or not. On the upside it makes the hardware much more viable instantly and will boost adoption, on the downside you run the risk that devs will never support ROCm, because you can just use the translation layer. On the other hand: > The next major ROCm release (ROCm 6.0) will not be backward [source] compatible with the ROCm 5 series. Even worse, not even the driver is backwards-compatible: > There are some known limitations though like currently only targeting the ROCm 5.x API and not the newly-released ROCm 6.x releases.. In turn having to stick to ROCm 5.7 series as the latest means that using the ROCm DKMS modules don't build against the Linux 6.5 kernel now shipped by Ubuntu 22.04 LTS HWE stacks, for example. Hopefully there will be enough community support to see ZLUDA ported to ROCM 6 so at least it can be maintained with current software releases. reply fariszr 19 hours agoprev> after the CUDA back-end was around for years and after dropping OpenCL, Blender did add a Radeon HIP back-end... But the real kicker here is that using ZLUDA + CUDA back-end was slightly faster than the native Radeon HIP backend. This is absolutely crazy. reply toxik 19 hours agoparentIs AMD just a puppet org to placate antitrust fears? Why are they like this? reply swozey 16 hours agorootparentIs this really a theory? If so my $8 AMD stock from, 2015? is currently worth $176 so they should make more shell companies they're doing great. I guess that might answer my \"Why would AMD find that having a CUDA competitor isn't a business case unless they couldn't do it or the cards underperformed significantly.\" reply kllrnohj 12 hours agorootparentFor some reason AMD's GPU division continues to be run, well, horribly. The CPU division is crushing it, but the GPU division is comically bad. During the great GPU shortage AMD had multiple opportunities to capture chunks of the market and secure market share, increasing the priority for developers to acknowledge and target AMD's GPUs. What did they do instead? Not a goddamn thing, they followed Nvidia's pricing and managed to sell jack shit (like seriously the RX 580 is still the first AMD card to show up on the steam hardware survey). They're not going big enough dies at the top end to compete with nvidia for the halo, and they're refusing to undercut at the low end where nvidia's reputation for absurd pricing is at an all time high. AMD's GPU division is a clown show, it's impressively bad. Even though the hardware itself is fine they just can't stop either making terrible product launches, awful pricing strategies, or just brain dead software choices like shipping a feature that triggered anti-cheat, getting their customers predictably banned & angering game devs in the process And relevant to this discussion Nvidia's refusal to add VRAM to their lower end cards is a prime opportunity for AMD to go after the lower-end compute / AI interested crowd who will become the next generation software devs. What are they doing with this? Well, they're not making ROCm available to basically anyone, that's apparently the winning strategy. ROCm 6.0 only supports the 7900 XTX and the... Radeon VII. The weird one-off Vega 20 refresh. Of all the random cards to support, why the hell would you pick that one??? reply swozey 11 hours agorootparent> The (AMD) CPU division is crushing it I worked at a baremetal CDN with 60 pops and a few years ago we had to switch to AMD because of PCIE bandwidth over to our smartNICs and nvmeOF sort of things. We'd long hit limits on Intel before the Epyc stuff came out so we had to have more servers running than we wanted because we had to limit how much we did with one server to not hit the limits and cause everything to lock. And we were excited, not a single apprehension. Epyc crushed the server market, everyone is using them. Well, it's going ARM now but Epyc will still be around awhile. reply acchow 4 hours agorootparentprevDoes this have anything to do with AMD's GPU division being a result of an acquisition (ATI)? reply dehrmann 6 hours agorootparentprevLike Mozilla? reply lambdaone 18 hours agoprevIt seems to me that AMD are crazy to stop funding this. CUDA-on-ROCm breaks NVIDIA's moat, and would also act as a disincentive for NVIDIA to make breaking changes to CUDA; what more could AMD want? When you're #1, you can go all-in on your own proprietary stack, knowing that network effects will drive your market share higher and higher for you for free. When you're #2, you need to follow de-facto standards and work on creating and following truly open ones, and try to compete on actual value, rather than rent-seeking. AMD of all companies should know this. reply RamRodification 18 hours agoparent> and would also act as a disincentive for NVIDIA to make breaking changes to CUDA I don't know about that. You could kinda argue the opposite. \"We improved CUDA. Oh it stopped working for you on AMD hardware? Too bad. Buy Nvidia next time\" reply freeone3000 17 hours agorootparentMost CUDA applications do not target the newest CUDA version! Despite 12.1 being out, lots of code still targets 7 or 8 to support old NVIDIA cards. Similar support for AMD isn’t unthinkable (but a rewrite to rocm would be). reply lambdaone 10 hours agorootparentThat's exactly the point I was making above. reply mnau 17 hours agorootparentprevAlso known as OS/2: Redux strategy. reply outside415 15 hours agorootparentprevNVIDIA is about ecosystem plays, they have no interest in sabotage or anti competition plays. Leave that to apple and google and their dumb app stores and mobile OSs. reply 0x457 15 hours agorootparent> NVIDIA is about ecosystem plays, they have no interest in sabotage or anti competition plays. Are we talking about the same NVIDIA? The entire Nvidia GPU strategy for nvidia is - make a feature (or find existing one) that performs better on their cards - pay developers to use (and sometimes misuse) it extensively. reply tester756 11 hours agoparentprevIf you see: 1) billions of dollar at the stake 2) one of the most successful leadership 3) during hottest peroid of their business where they heard about Nvidia's moat probably thousands of times during last 18 months... and you call some decision \"crazy\", then you probably do not have the same informations that they do or they underperformed, who knows, but I bet on #1 reason. reply Eisenstein 10 hours agorootparentThe 'crazy' decision is them slowly abandoning the PC gaming market which is where consumers get these cards, and focusing on the 'client' market to sell their 'Insight' datacenter/AI cards. I think the parent you are responding to isn't questioning why it is a bad 'make money now' profit decision but why it is a bad 'get people to use your system' decision. \"AMD’s client segment, mostly chips for PCs and laptops, rose 62% year over year to $1.46 billion in sales, thanks to recent chip launches. Sales in AMD’s gaming segment, which includes “semi-custom” processors for Microsoft Xbox and Sony PlayStation consoles, fell 17%. \" * https://www.cnbc.com/2024/01/30/amd-earnings-report-q4-2024.... reply saboot 18 hours agoparentprevYep, I develop several applications that use CUDA. I see AMD/Radeon powered computers for sale and want to buy one, but I am not going to risk not being able to run those applications or having to rewrite them. If they want me as a customer, and they have not created a viable alternative to CUDA, they need to pursue this. reply weebull 12 hours agorootparentDefine \"viable\"? reply croutons 7 hours agorootparentA backend that runs PyTorch out of the box and is as easy to setup / use as nvidia stack. reply swozey 16 hours agoprevI may have missed it in the article, but this post would mean absolutely nothing to me except for the fact that last week I got into stable diffusion so I'm crushing my 4090 with pytorch and deepspeed, etc and dealing with a lot of nvidia ctk/sdk stuff. Well, I'm actually trying to do this in windows w/ wsl2 and deepmind/torch/etc in containers and it's completely broken so not crushing currently. I guess awhile ago it was found that Nvidia was bypassing the kernels GPL license driver check and I read that kernel 6.6 was going to lock that driver out if they didn't fix it, and from what I've read there was no reply or anything done by nvidia yet. Which I think I probably just can't find. Am I wrong about that part? We're on kernel 6.7.4 now and I'm still using the same drivers. Did it get pushed back, did nvidia fix it? Also, while trying to find answers myself I came across this 21 year old post which is pretty funny and very apt for the topic https://linux-kernel.vger.kernel.narkive.com/eVHsVP1e/why-is... I'm seeing conflicting info all over the place so I'm not really sure what the status of this GPL nvidia driver block thing is. reply bongodongobob 9 hours agoparentJust run that stuff in Linux, you're making it harder than it needs to be. Can it work in Windows? Sure. Is there as much documentation? Not even close. reply AndrewKemendo 19 hours agoprevROCm is not spelled out anywhere in their documentation and the best answers in search come from Github and not AMD official documents \"Radeon Open Compute Platform\" https://github.com/ROCm/ROCm/issues/1628 And they wonder why they are losing. Branding absolutely matters. reply sorenjan 18 hours agoparentFunnily enough it doesn't work on their RDNA (\"Radeon DNA\") hardware (with some exceptions I think), but it's aimed at their CDNA (Compute DNA). If they would come up with a new name today it probably wouldn't include Radeon. AMD seems to be a firm believer in separating the consumer chips for gaming and the compute chips for everything else. This probably makes a lot of sense from a chip design and current business perspective, but I think it's shortsighted and a bad idea. GPUs are very competent compute devices, and basically wasting all that performance for \"only\" gaming is strange to me. AI and other compute is getting more and more important for things like image and video processing, language models, etc. Not only for regular consumers, but for enthusiasts and developers it makes a lot of sense to be able to use your 10 TFLOPS chip even when you're not gaming. While reading through the AMD CDNA whitepaper I saw this and got a good chuckle. \"culmination of years of effort by AMD\" indeed. > The computational resources offered by the AMD CDNA family are nothing short of astounding. However, the key to heterogeneous computing is a software stack and ecosystem that easily puts these abilities into the hands of software developers and customers. The AMD ROCm 4.0 software stack is the culmination of years of effort by AMD to provide an open, standards-based, low-friction ecosystem that enables productivity creating portable and efficient high-performance applications for both first- and third-party developers. https://www.amd.com/content/dam/amd/en/documents/instinct-bu... reply slavik81 18 hours agorootparentROCm works fine on the RDNA cards. On Ubuntu 23.10 and Debian Sid, the system packages for the ROCm math libraries have been built to run on every discrete Vega, RDNA 1, RDNA 2, CDNA 1, and CDNA 2 GPU. I've manually tested dozens of cards and every single one worked. There were just a handful of bugs in a couple of the libraries that could easily be fixed by a motivated individual. https://slerp.xyz/rocm/logs/full/ The system package for HIP on Debian has been stuck on ROCm 5.2 / clang-15 for a while, but once I get it updated to ROCm 5.7 / clang-17, I expect that all discrete RDNA 3 GPUs will work. reply stonogo 14 hours agorootparentIt doesn't matter to my lab whether it technically runs. According to https://rocm.docs.amd.com/projects/install-on-linux/en/lates... it only supports three commercially-available Radeon cards (and four available Radeon Pro) on Linux. Contrast this to CUDA, which supports literally every nVIDIA card in the building, including the crappy NVS series and weirdo laptop GPUs, and it basically becomes impossible to convince anyone to develop for ROCm. reply phh 18 hours agoparentprevI have no idea what CUDA stands for, and I live just fine without knowing it. reply rvnx 18 hours agorootparentCountless Updates Developer Agony reply hyperbovine 13 hours agorootparentLost five hours of my life yesterday discovering the fact that \"CUDA 12.3\" != \"CUDA 12.3 Update 2\". (Yes, that's obvious, but not so obvious when your GPU applications submitted to a cluster start crashing randomly for no apparent reason.) reply egorfine 17 hours agorootparentprevThis is the right definition. reply smokel 17 hours agorootparentprevCompute Unified Device Architecture [1] [1] https://en.wikipedia.org/wiki/CUDA reply moffkalast 18 hours agorootparentprevCleverly Undermining Disorganized AMD reply alfalfasprout 14 hours agorootparentprevCrap, updates destroyed (my) application reply rtavares 19 hours agoparentprevLater in the same thread: > ROCm is a brand name for ROCm™ open software platform (for software) or the ROCm™ open platform ecosystem (includes hardware like FPGAs or other CPU architectures). > Note, ROCm no longer functions as an acronym. reply ametrau 16 hours agorootparent>> Note, ROCm no longer functions as an acronym. That is really dumb. Like LLVM. reply Farfignoggen 9 hours agoparentprevLisa Su in a later presentation/event announced that ROCM is no longer an acronym! So Radeon Open CoMpute is no longer the definition there! But ROCm/HIP and CUDA/CUDA Tools, and OneAPI/Level-0 are essentially the same coverage/scope for AMD, Nvidia, Intel respectively as far as GPU Compute API support goes and HPC/Accelerator workloads as well. So there's a YouTube Video from some Supercomputer conference where the presenter goes over the support Matrix info for ROCm/HIP, CUDA/CUDA Tools, and OneAPI/Level-0 and they are similar in scope there. reply atq2119 18 hours agoparentprevMy understanding is that there was some trademark silliness around \"open compute\", and AMD decided that instead of doing a full rebrand, they would stick to ROCm but pretend that it wasn't ever an acronym. reply michaellarabel 18 hours agorootparentYeah it was due to the Open Compute Project AFAIK... Though for a little while AMD was telling me they really meant to call it \"Radeon Open eCosystem\" before then dropping that too with many still using the original name. reply marcus0x62 19 hours agoparentprevThat, and it only runs on a handful of their GPUs. reply NekkoDroid 18 hours agorootparentIf you are talking about the \"supported\" list of GPUs, those listed are only the ones they fully validate and QA test, other of same gen are likely to work, but most likely with some bumps along the way. In one of the a bit older phoronix posts about ROCm one of their engeneers did say they are trying to expand the list of validated & QA'd cards, as well as destinguishing between \"validated\", \"supported\" and \"non-functional\" reply machomaster 11 hours agorootparentThey can say whatever but the action is what matters, not wishes and promises. And the reality is that list of supported GPUs has been unchanged since they first announced it a year ago. reply slavik81 18 hours agoparentprevThat is intentional. We had to change the name. ROCm is no longer an acronym. reply AndrewKemendo 17 hours agorootparentI assume you’re on the team if you’re saying “we” Can you say why you had to change the name? reply alwayslikethis 19 hours agoparentprevI mean, I also had to look up what CUDA stands for. reply mjcohen 10 hours agorootparentCan't Use Devices (by) AMD reply hasmanean 16 hours agorootparentprevCompute unified device architecture ? reply Farfignoggen 13 hours agoprevPhoronix Article from earlier(1): \"While AMD ships pre-built ROCm/HIP stacks for the major enterprise Linux distributions, if you are using not one of them or just want to be adventurous and compile your own stack for building HIP programs for running on AMD GPUs, one of the AMD Linux developers has written a how-to guide. \"(1) (1) \"Building An AMD HIP Stack From Upstream Open-Source Code Written by Michael Larabel in Radeon on 9 February 2024 at 06:45 AM EST.\" https://www.phoronix.com/news/Building-Upstream-HIP-Stack reply rekado 11 hours agoparentYou can also install HIP/ROCm via Guix: https://hpc.guix.info/blog/2024/01/hip-and-rocm-come-to-guix... > AMD has just contributed 100+ Guix packages adding several versions of the whole HIP and ROCm stack reply JonChesterfield 13 hours agoparentprevHähnle is one of our best, that'll be solid. http://nhaehnle.blogspot.com/2024/02/building-hip-environmen.... Looks pretty similar to how I build it. Side point, there's a driver in your linux kernel already that'll probably work. The driver that ships with rocm is a newer version of the same and might be worth building via dkms. Very strange that the rocm github doesn't have build scripts but whatever, I've been trying to get people to publish those for almost five years now and it just doesn't seem to be feasible. reply Farfignoggen 10 hours agorootparentFrom the Phoronix comments section of the Article that I linked to: https://www.phoronix.com/forums/forum/linux-graphics-x-org-d... And I'm on Linux Mint 21.3 and so how to change any instillation script to think that Mint is Ubuntu to get that to maybe work there but there's no how-to for Mint like the one that AMD provides for Ubuntu! And really that's compiled By AMD for the specific Linux Kernel so not any DKMS sort of methods there AFAIK! but I'm no Linux Expert and just want some one-click install or that to ship with the Distro already working so Blender 3D's iGPU/dGPU accelerated Cycles rendering is possible on AMD Radeon consumer GPUs. reply JonChesterfield 10 hours agorootparentIf you wait for a while then Debian packaging effort will flow down through the repos and you'll have apt install or synaptic GUI access to the prebuilt binaries. You've already got an amdgpu driver in your kernel. Possibly an old one but it'll be there. ROCm is userspace. reply Farfignoggen 10 hours agorootparentI'm waiting for Rusticl(OpenCL Implemented in the Rust programming language) as part of the MESA driver stack to get enabled in Mint 22(Sometime in April 2024). And maybe I can use the Older Legacy Blender 2.93/earlier editions that use OpenCl as the GPU compute API instead of Blender 3.0/later editions that have dropped support for OpenCL in favor of CUDA/PTX(Whatever) that requires the HIP part of ROCm to get translated to a form that can be executed on Radeon GPU hardware. CUDA PTX is that Intermediate Language representation that's portable for cross platform usage but I'm not exactly sure how that is implemented for Blender 3.0/later. P.S I have Ryzen 3000/Zen+ series APUs and Vega Integrated Graphics on 2 systems and the laptop has Ryzen 3550H/Vega 8CU iGPU and Polaris Radeon RX560X dGPU while the Mini Desktop PC has Ryzen 3400G/Vega 11CU iGPU only. reply wheybags 19 hours agoprevCannot understand why AMD would stop funding this. It seems like this should have a whole team allocated to it. reply otoburb 19 hours agoparentThey would always be at the mercy of NVIDIA's API. Without knowing the inner workings, perhaps a major concern with this approach is the need to implement on NVIDIA's schedule instead of AMD's which is a very reactive stance. This approach actually would make sense if AMD felt, like most of us perhaps, that the NVIDIA ecosystem is too entrenched, but perhaps they made the decision recently to discontinue funding because they (now?) feel otherwise. reply blagie 19 hours agorootparentThey've been at mercy of Intel x86 APIs for a long time. Didn't kill them. What happens here is that the original vendor loses control of the API once there are multiple implementations. That's the best possible outcome for AMD. In either case, they have a limited window to be adopted, and that's more important. The abstraction layer here helps too. AMD code is !@#$%. If this were adopted, it makes it easier to fix things underneath. All that is a lot more important than a dream of disrupting CUDA. reply lambdaone 18 hours agorootparentMore than that, a second implementation of CUDA acts as a disincentive for NVIDIA to make breaking changes to it, since it would reduce any incentive for software developers to follow those changes, as it reduces the value of their software by eliminating hardware choice for end-users (which in some case like large companies are also the developers themselves). At the same time, open source projects can be pretty nimble in chasing things like changing APIs, potentially frustrating the effectiveness of API pivoting by NVIDIA in a second way. reply tikkabhuna 18 hours agorootparentprevMy understanding is that with AMD64 there's a circular dependency where AMD need Intel for x86 and Intel need AMD for x86_64? reply monocasa 17 hours agorootparentThat's true now, but AMD has been making x86 compatible CPUs since the original 8086. reply rubatuga 18 hours agorootparentprevx86 is not the same, the courts forced the release of x86 architecture to AMD during an antitrust lawsuit reply hardware2win 18 hours agorootparentYou think x86 would be changed in such a way that it'd break and? Because what else? If so, then i think that this is crazy because software is harder to change than hardware reply anon291 18 hours agorootparentprevYou don't think the courts would force the opening of CUDA? Didn't a court already rule that API cannot be patented. I believe it was a Google case. As long as no implementation was stolen, the API itself is not able to be copyrighted. Here it is: https://arstechnica.com/tech-policy/2021/04/how-the-supreme-... reply jcranmer 18 hours agorootparent> Didn't a court already rule that API cannot be patented. I believe it was a Google case. As long as no implementation was stolen, the API itself is not able to be copyrighted. That is... not accurate in the slightest. Oracle v Google was not about patentability. Software patentability is its own separate minefield, since anyone who looks at the general tenor of SCOTUS cases on the issue should be able to figure out that SCOTUS is at best highly skeptical of software patents, even if it hasn't made any direct ruling on the topic. (Mostly this is a matter of them being able to tell what they don't like but not what they do like, I think). But I've had a patent attorney straight-out tell me that in absence of better guidance, they're just pretending the most recent relevant ruling (which held that X-on-a-computer isn't patentable) doesn't exist. In any case, a patent on software APIs (as opposed to software as a whole) would very clearly fall under the \"what are you on, this isn't patentable\" category of patentability. The case was about the copyrightability of software APIs. Except if you read the decision itself, SCOTUS doesn't actually answer the question [1]. Instead, it focuses on whether or not Google's use of the Java APIs were fair use. Fair use is a dangerous thing to rely on for legal precedent, since there's no \"automatic\" fair use category, but instead a balancing test ostensibly of four factors but practically of one factor: does it hurt the original copyright owner's profits [2]. There's an older decision which held that the \"structure, sequence, and organization\" of code is copyrightable independent of the larger work of software, which is generally interpreted as saying that software APIs are copyrightable. At the same time, however, it's widespread practice in the industry to assume that \"clean room\" development of an API doesn't violate any copyright. The SCOTUS decision in Google v Oracle was widely interpreted as endorsing this interpretation of the law. [1] There's a sentence or two that suggests to me there was previously a section on copyrightability that had been ripped out of the opinion. [2] See also the more recent Andy Warhol SCOTUS decision which, I kid you not, says that you have to analyze this to figure out whether or not a use is \"transformative\". Which kind of implicitly overturns Google v Oracle if you think about it, but is unlikely to in practice. reply monocasa 17 hours agorootparentTo be fair, there were patent claims in Oracle vs. Google too. That's why the appeals went through the CAFC rather than the 9th circuit. Those claims were simply thrown out pretty early. Whether that says something about more generally or was simply a set of weak claims intended for venue shopping is a legitimate discussion to be had though. reply Symmetry 18 hours agorootparentprevRegardless of the legal status of APIs, this Phoronix article is about AMD providing a replacement ABI and I wouldn't assume the legal issues are necessarily the same. But because this is a case where AMD is following a software target there's the possibility, if AMD starts to succeed, that NVidia might change their ABI in ways that deliberatly hurt AMD's compatibility efforts in ways that would be much more difficult for APIs or hardware. That's, presumably, why AMD is going forward with their API emulation effort instead. reply anon291 18 hours agorootparentIf you read the article, it's about Google's re-implementation of the Java API and runtime. Thus, yes, Google was providing both API and ABI compatibility. reply Symmetry 18 hours agorootparentI read the article when it came out and re-scimmed it just now. My understanding at the time and still was that the legal case revolved around the API and the exhibits entered into evidence I saw were all Java function names with their arguments and things of that sort. And I'm given to understand that the Dalvik Java implementation Google was using with Android was register based rather than than the stack based standard Java, which sounds to me like it would make actual binary compatibility impossible. reply visarga 16 hours agorootparentprev> They would always be at the mercy of NVIDIA's API. They only need to support PyTorch. Not CUDA reply viraptor 4 hours agorootparentAMD should be able to pay for two teams. They had a decent growth period recently. Doing one doesn't stop them from doing the other. reply hd4 19 hours agoprevhttps://github.com/vosen/ZLUDA - source reply MegaDeKay 19 hours agoparentLatest commit message: \"Nobody expects the Red Team\" reply pella 19 hours agoparentprevhttps://github.com/vosen/ZLUDA/tree/v3 reply CapsAdmin 17 hours agoprevOne thing I didn't see mentioned anywhere apart from the repos readme: > PyTorch received very little testing. ZLUDA's coverage of cuDNN APIs is very minimal (just enough to run ResNet-50) and realistically you won't get much running. reply throwaway2037 6 hours agoprevFrom the same repo, I found this excellent, well-written architecture document: https://github.com/vosen/ZLUDA/blob/master/ARCHITECTURE.md I love the direct, \"no bullshit\" style of writing. Some gems: > Anyone familiar with C++ will instantly understand that compiling it is a complicated affair. > Additionally CUDA allows, to a large degree, mixing CPU code and GPU code. What does all this complexity mean for ZLUDA? Absolutely nothing > Since an application can dynamically link to either Driver API or Runtime API, it would seem that ZLUDA needs to provide both. In reality very few applications dynamically link to Runtime API. For the vast majority of applications it's sufficient to provide Driver API for dynamic (runtime) linking. reply codedokode 11 hours agoprevAs I understand, Vulkan allows to run custom code on GPU, including the code to multiply matrices. Can one simply use Vulkan and ignore CUDA, PyTorch and ROCm? reply PeterisP 1 hour agoparentYou probably can, but why would you? The main (only?) reason to ignore the CUDA-based stack is so that you could save a bit of money by using some other hardware instead of nVidia. So the amount of engineering labor/costs you should be willing to accept is directly tied to how much hardware you intend to buy or rent and what % discount, if any, the alternative hardware enables compared to nVidia. So if you'd want to ignore CUDA+PyTorch and reimplement all of what you need on top of Vulkan.... well, that becomes worthy of discussion only if you expect to spend a lot on hardware, if you really consider that savings on hardware can recoup many engineer-years of costs - otherwise it's more effective to just go with the flow. reply Const-me 9 hours agoparentprevI did a few times with Direct3D 11 compute shaders. Here’s an open-source example: https://github.com/Const-me/Cgml Pretty sure Vulkan gonna work equally well, at the very least there’s an open source DXVK project which implements D3D11 on top of Vulkan. reply sorenjan 6 hours agoparentprevncnn uses Vulkan for GPU acceleration, I've seen it used in a few projects to get AMD hardware support. https://github.com/Tencent/ncnn reply 0xDEADFED5 5 hours agoparentprevthere's a pretty cool Vulkan LLM engine here for example: https://github.com/mlc-ai/mlc-llm reply eddiewithzato 7 hours agoparentprevof course, but then you are just recreating CUDA. And that won’t scale well across an industry since each company would have their own language. AMD can just do what you are describing and then sell it as a standard. I mean they literally did that, but then dropped it so yea reply miduil 19 hours agoprevWow, this is great news. I really hope that the community will find ways to sustainable fund this project, being suddenly run a lot of innovative CUDA based projects on AMD GPUs is a big game-changer, especially because you don't have to deal with the poor state of nvidia on linux support. reply hd4 18 hours agoprevThe interest in this thread tells me there are a lot of people who are not cool with the CUDA monopoly. reply Qwertious 5 hours agoparentAMD's budget isn't measured in people, it's measured in dollars. HN commenters don't necessarily decide how many graphics cards their business will buy. reply smoldesu 17 hours agoparentprevThose people should have spoken up when their hardware manufacturers abandoned OpenCL. The industry set itself 5-10 years behind by ignoring open GPGPU compute drivers while Nvidia slowly built their empire. Just look at how long it's taken to re-impliment a fraction of the CUDA featureset on a small handful of hardware. CUDA shouldn't exist. We should have hardware manufacturers working together, using common APIs and standardizing instead of going for the throat. The further platforms drift apart, the more valuable Nvidia's vertical integration becomes. reply mnau 17 hours agorootparentCommon API means being replaceable, fungible. There are no margins in that. reply smoldesu 17 hours agorootparentCorrect. It's why the concept of 'proprietary UNIX' didn't survive long once program portability became an incentive. reply Avamander 16 hours agorootparentprevIs my impression wrong, that people understood the need for OCL only after CUDA had already cornered and strangled the market? reply pjmlp 3 hours agorootparentI attended a Webminar from Khronos were no one in the panel understood why the research community would want anything beyond C to program GPUs. Meanwhile NVidia was adding C++, Fortran, PTX, supporting other programming language communities trying to target GPUS (Java, .NET, Haskell,..). Making it as easy to debug GPUs as modern graphical debuggers for CPUs, building libraries,... Intel, and AMD together with Khronos did this to themselves. reply smoldesu 13 hours agorootparentprevYou're mostly right. CUDA was a \"sleeper product\" that existed early-on but didn't see serious demand until later. OpenCL was Khronos Group's hedged bet against the success of CUDA; it was assumed that they would invest in it more as demand for GPGPU increased. After 10 years though, OpenCL wasn't really positioned to compete and CUDA was more fully-featured than ever. Adding insult to injury, OS manufacturers like Microsoft and Apple started to avoid standardized GPU libraries in favor of more insular native APIs. By the time demand for CUDA materialized, OpenCL had already been left for dead by most of the involved parties. reply zoobab 16 hours agoprev\"For reasons unknown to me, AMD decided this year to discontinue funding the effort and not release it as any software product.\" Managers at AMD never heard of AI? reply navbaker 15 hours agoprevThe other big need is for a straightforward library for dynamic allocation/sharing of GPUs. Bitfusion was a huge pain in the ass, but at least it was something. Now it’s been discontinued, the last version doesn’t support any recent versions of PyTorch, and there’s only two(?) possible replacements in varying levels of readiness (Juice and RunAI). We’re experimenting now with replacing our Bitfusion installs with a combination of Jupyter Enterprise Gateway and either MIGed GPUs or finding a way to get JEG to talk to a RunAI installation to allow quick allocation and deallocation of portions of GPUs for our researchers. reply CapsAdmin 17 hours agoprevHope this can benefit from the seemingly infinite enthusiasm from rust programmers reply sharts 17 hours agoprevAMD fail to realize software toolchain is what makes nvidia great. AMD thinks the hardware is all that’s needed reply JonChesterfield 17 hours agoparentNvidia's toolchain is really not great. Applications are just written to step around the bugs. ROCm has different bugs, which the application workarounds tend to miss. reply bornfreddy 13 hours agorootparentYes. This is what makes Nvidia's toolchain, if not great, at least ok. As a developer I can actually use their GPUs. And what I developed locally I can yhen run on Nvidia hardware in the cloud and pay by usage. AMD doesn't seem to understand that affordable entry-level hardware with good software support is key. reply JonChesterfield 13 hours agorootparentAh yes, so that one does seem to be a stumbling block. ROCm is not remotely convinced that running on gaming cards is a particularly useful thing. HN is really sure that being able to develop code on ~free cards that you've got lying around anyway is an important gateway to running on amdgpu. The sad thing is people can absolutely run ROCm on gaming cards if they build from source. Weirdly GPU programmers seem determined to use proprietary binaries to run \"supported\" hardware, and thus stick with CUDA. I don't understand why AMD won't write the names of some graphics cards under \"supported\", even if they didn't test them as carefully as the MI series, and I don't understand why developers are so opposed to compiling their toolchains from source. For one thing it means you can't debug the toolchain effectively when it falls over, weird limitation to inflict on oneself. Strange world. reply pjmlp 3 hours agorootparentStrage world is expecting we are all Gentoo users, that like to build our software like making fire with stones and sticks. Then people act surprised CUDA was won the hearts of the scientific developer community, that rather spend their time actually doing research work. reply sorenjan 5 hours agorootparentprevMaybe someone that's trying to use a GPU to solve a particular problem doesn't necessarily also have the time, energy, knowledge, or interest to also first 1) find out how to construct the toolchain, 2) build said toolchain, and 3) debug the toolchain. Just because you're a programmer writing code for physics simulations, image processing, AI models, or whatever, doesn't mean you also want to spend hours or days on getting your tools working before you can even start writing your own code. And then do it again when deploying on another computer. And it's really not surprising that people, GPU programmers included, doesn't want to spend time and money on trying out unsupported hardware and software combinations when again, it's supposed to be a tool to get a job done. If I got some Phillips head screws I'm not reaching for a flat head screwdriwer even though it probably will work, and if it's the only thing I have I'll buy some Phillips head ones for the next project. reply michalf6 18 hours agoprevZłuda roughly means \"delusion\" / \"mirage\" / \"illusion\" in Polish, given the author is called Andrzej Janik this may be a pun :) reply rvba 14 hours agoparentArguably one could also translate it as \"something that will never happen\". At the same time \"cuda\" could be translated as \"wonders\". reply ultra_nick 16 hours agoprevIf anyone wants to work in this area, AMD currently has a lot of related job posts open. reply irusensei 15 hours agoprevI'll try later with projects in which I had issues to make it work like TortoiseTTS. I'm not expecting comparable Nvidia speeds but definitely faster than pure CPU. reply sam_goody 19 hours agoprevI don't really follow this, but isn't it a bad sign for ROCm that, for example, ZLUDA + Blender 4's CUDA back-end delivers better performance than the native Radeon HIP back-end? reply whizzter 19 hours agoparentCould be that the CUDA backend has seen far more specialization optimizations whereas the seeingly fairly fresh HIP backend hasn't had as many developers looking at it, in the end a few more control instructions on the CPU side to go through the ZLUDA wrapper will be insignificant compared to all the time spent inside better optimized GPU kernels. reply fariszr 19 hours agoparentprevIt really shows how neglected their software stack is, or at least how neglected this implementation is. reply mdre 18 hours agoparentprevI'd say it's even worse, since for rendering Optix is like 30% faster than CUDA. But that requires the tensor cores. At this point AMD is waaay behind hardware wise. reply KeplerBoy 19 hours agoparentprevSurely this can be attributed to Blender's HIP code just being suboptimal because nobody really cares about it. By extension nobody cares about it because performance is suboptimal. It's AMDs job to break that circle. reply btown 19 hours agoprevWhy would this not be AMD’s top priority among priorities? Someone recently likened the situation to an Iron Age where NVIDIA owns all the iron. And this sounds like AMD knowing about a new source of ore and not even being willing to sink a single engineer’s salary into exploration. My only guess is they have a parallel skunkworks working on the same thing, but in a way that they can keep it closed-source - that this was a hedge they think they no longer need, and they are missing the forest for the trees on the benefits of cross-pollination and open source ethos to their business. reply hjabird 18 hours agoparentThe problem with effectively supporting CUDA is that encourages CUDA adoption all the more strongly. Meanwhile, AMD will always be playing catch-up, forever having to patch issues, work around Nvidia/AMD differences, and accept the performance penalty that comes from having code optimised for another vendor's hardware. AMD needs to encourage developers to use their own ecosystem or an open standard. reply jvanderbot 16 hours agorootparentIf you replace CUDA -> x86 and NVIDIA -> Intel, you'll see a familiar story which AMD has already proved it can work through. These were precisely the arguments for 'x86 will entrench Intel for all time', and we've seen AMD succeed at that game just fine. reply ianlevesque 16 hours agorootparentAnd indeed more than succeed, they invented x86_64. reply sangnoir 15 hours agorootparentx86_64's win was helped by Intel's Itanium misstep. AMD can't bank on Nvidia making a mistake, and Nvidia seems content with incremental changes to CUDA, contrasted with Intel's 32-bit to 64-bit transition. It is highly unlikely that AMD can find and exploit a similar chink in the amor against CUDA. reply LamaOfRuin 15 hours agorootparentIf they're content with incremental changes to CUDA then it doesn't cost much to keep updated compatibility and do it as quickly as any users actually adopt changes. reply stcredzero 15 hours agorootparentprevAnd indeed more than succeed, they invented x86_64. If AMD invented the analogous to x86_64 for CUDA, this would increase competition and progress in AI by some huge fraction. reply jvanderbot 10 hours agorootparentWhy \"if only\". Intel had been around forever when AMD showed up. CUDA isn't unassailable reply pjmlp 14 hours agorootparentprevOnly works if NVidia misteps and creates the Itanium version of CUDA. reply stcredzero 14 hours agorootparentYou don't think someone would welcome the option to have more hardware buying options, even if the \"Itanium version\" didn't happen? reply clhodapp 15 hours agorootparentprevIf that's the model, it sounds like the path would be to burn money to stay right behind NVIDIA and wait for them to become complacent and stumble technically, creating the opportunity to leapfrog them. Keeping up could be very expensive if they don't force something like the mutual licensing requirements around x86. reply ethbr1 15 hours agorootparentprev> These were precisely the arguments for 'x86 will entrench Intel for all time', and we've seen AMD succeed at that game just fine. ... after a couple decades of legal proceedings and a looming FTC monopoly case convinced Intel to throw in the towel, cross-license, and compete more fairly with AMD. https://jolt.law.harvard.edu/digest/intel-and-amd-settlement AMD didn't just magically do it on its own. reply samstave 15 hours agorootparentprevTransmetta was Intels boogey-man in the 90s. reply hjabird 17 hours agorootparentprevThere are some great replies to my comment - my original comment was too reductive. However, I still think that entrenching CUDA as the de-facto language for heterogeneous computing is a mistake. We need an open ecosystem for AI and HPC, where vendors compete on producing the best hardware. reply ethbr1 16 hours agorootparentThe problem with open standards is that someone has to write them. And that someone usually isn't a manufacturer, lest the committee be accused of bias. Consequently, you get (a) outdated features that SotA has already moved beyond, (b) designed in a way that doesn't correspond to actual practice, and (c) that are overly generalized. There are some notable exceptions (e.g. IETF), but the general rule has been that open specs please no one, slowly. IMHO, FRAND and liberal cross-licensing produce better results. reply jchw 16 hours agorootparentVulkan already has some standard compute functionality. Not sure if it's low level enough to be able to e.g. recompile and run CUDA kernels, but I think if people were looking for a vendor-neutral standard to build GPGPU compute features on top of, I mean, that seems to be the obvious modern choice. reply zozbot234 16 hours agorootparentThere is already a work-in-progress implementation of HIP on top of OpenCL https://github.com/CHIP-SPV/chipStar and the Mesa RustiCL folks are quite interested in getting that to run on top of Vulkan. (To be clear, HIP is about converting CUDA source code not running CUDA-compiled binaries but the Zluda project discussed in OP heavily relies on it.) reply bick_nyers 17 hours agorootparentprevThe latest version of CUDA is 12.3, and version 12.2 came out 6 months prior. How many people are running an older version of CUDA right now on NVIDIA hardware for whatever particular reason? Even if AMD lagged support on CUDA versioning, I think it would be widely accepted if the performance per dollar at certain price points was better. Taking the whole market from NVIDIA is not really an option, it's better to attack certain price points and niches and then expand from there. The CUDA ship sailed a long time ago in my view. reply swozey 16 hours agorootparentI just went through this this weekend - If you're running in Windows and want to use deepspeed, you have to still use Cuda 12.1 because deepspeed 13.1 is the latest that works with 12.1. There's no deepspeed for windows that works with 12.3. I tried to get it working this weekend but it was a huge PITA so I switched to putting everything into WSL2 then in arch on there pytorch etc in containers so I could flip versions easily now that I know how SPECIFIC the versions are to one another. I'm still working on that part, halfway into it my WSL2 completely broke and I had to reinstall windows. I'm scared to mount the vhdx right now. I did ALL of my work and ALL of my documentation is inside of the WSL2 archlinux and NOT on my windows machine. I have EVERYTHING I need to quickly put another server up (dotfiles, configs) sitting in a chezmoi git repo ON THE VM. That I only git committed one init like 5 mins into everything. THAT was a learning experience, now I have no idea if I should follow the \"best practice\" of keeping projects in wsl or having wsl reach out to windows, there's a performance drop. The 9p networking stopped working and no matter what I reinstalled, reset, removed features, reset windows, etc, it wouldn't start. But at least I have that WSL2 .vhdx image that will hopefully mount and start. And probably break WSL2 again. I even SPECIFICALLY took backups of the image as tarballs every hour in case I broke LINUX, not WSL. If anyone has done sd containers in wsl2 already let me know. I've tried to use WSL for dev work (i use osx) like this 2-3 times in the last 4-5 years and I always run into some catastrophically broken thing that makes my WSL stop working. I hadn't used it in years so hoped it was super reliable by now. This is on 3 different desktops with completely different hardware, etc. I was terrified it would break this weekend and IT DID. At least I can be up in windows in 20 minutes thanks to chocolately and chezmoi. Wiped out my entire gaming desktop. Sorry I'm venting now this was my entire weekend. This repo is from a deepspeed contrib (iirc) and lists the reqs for deepspeed + windows that mention the version matches https://github.com/S95Sedan/Deepspeed-Windows > conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia It may sound weird to do any of this in Windows, or maybe not, but if it does just remember that it's a lot of gamers like me with 4090s who just want to learn ML stuff as a hobby. I have absolutely no idea what I'm doing but thank god I know containers and linux like the back of my hand. reply bick_nyers 16 hours agorootparentVent away! Sounds frustrating for sure. As much as I love Microsoft/Windows for the work they have put into WSL, I ended up just putting Kubuntu on my devices and use QEMU with GPU passthrough whenever I need Windows. Gaming perf is good. You need an iGPU or a cheap second GPU for Linux in order to hand off a 4090 etc. to Windows (unless maybe your motherboard happens to support headless boot but if it's a consumer board it doesn't). Dual boot with Windows always gave me trouble. reply swozey 15 hours agorootparentAre you flipping from your main GPU to like a GT710 to do the gpu vfio mount? Or can you share the dgpu directly and not have to go headless now? I've done this on both a hackintosh and void linux. I was so excited to get the hackintosh working because I honestly hate day desktop linux, it's my day job to work on and I just don't want to deal with it after work. Unfortunately both would break in significant ways and I'd have to trudge through and fix things. I had that void desktop backed up with Duplicacy (duplicati front end) and IIRC I tried to roll back after breaking qemu, it just dumps all your backup files into their dirs, and I think I broke it more. I think at that point I was back up in Windows in 30 mins.. and all of its intricacies like bsoding 30% of the time that I either restart it or unplug a usb hub. But my Macbooks have a 30% chance of not waking up on Monday morning when I haven't used them all weekend without me having to grab them and open the screen. reply katbyte 16 hours agorootparentprevI recently gave this a go as I’d not had a windows desktop for a long time, have a beefy Proxmox server and wanted to play some windows only games - works shockingly well with an a4000 and 35m optical hdmi cables! - however I’m getting random audio crackling and popping and I’ve yet to figure out what’s causing it. First I thought it was hardware related in a Remote Desktop session leading me to think some weird audio driver thing have you encountered anything like this at all? reply swozey 15 hours agorootparentWhat are you running for audio? pipewire+jack, pipewire, jack2, pulseaudio? I wonder if it's from latency. Pulseaudio is the most common but if you do any audio engineering or play guitar etc with your machine we all use jack protocol for less latency. https://linuxmusicians.com/viewtopic.php?t=25556 Could be completely unrelated though, RDP sessions can definitely act up, get audio out of sync etc. I try to never do pass through rdp audio, it's not even enabled by default in the mstsc client IIRC but that may just be a \"probably server\" thing. reply carlossouza 16 hours agorootparentprevGreat comment. I bet there are at least two markets (or niches): 1. People who want the absolute best performance and the latest possible version and are willing to pay the premium for it; 2. People who want to trade performance by cost and accept working with not-the-latest versions. In fact, I bet the market for (2) is much larger than (1). reply bluedino 15 hours agorootparentprev> How many people are running an older version of CUDA right now on NVIDIA hardware for whatever particular reason? I would guess there are lots of people still running CUDA 11. Older clusters, etc. A lot of that software doesn't get updated very often. reply coderenegade 9 hours agorootparentEspecially if you're deploying models. The latest version of onnx runtime still defaults to cuda 11. reply kgeist 18 hours agorootparentprevIntel embraced Amd64 ditching Itanium. Wasn't it a good decision that worked out well? Is it comparable? reply kllrnohj 17 hours agorootparentIntel & AMD have a cross-license agreement covering everything x86 (and x86_64) thanks to lots and lots of lawsuits over their many years of competition. So while Intel had to bow to AMD's success and give up Itanium, they weren't then limited by that and could proceed to iterate on top of it. Meanwhile it'll be a cold day in hell before Nvidia licenses anything about CUDA to AMD, much less allows AMD to iterate on top of it. reply krab 13 hours agorootparentIsn't API out of scope for copyright? In the case of CUDA, it seems they can copy most of it and then iterate in their own, keeping a compatible subset. reply kevin_thibedeau 15 hours agorootparentprevThe original cross licensing was government imposed because a second source was needed for the military. reply atq2119 15 hours agorootparentMakes you wonder why DoE labs and similar facilities don't mandate open licensing of CUDA. reply teucris 17 hours agorootparentprevIn hindsight, yes, but just because a specific technology is leading an industry doesn’t mean it’s going to be the best option. It has to play out long enough for the market to indicate a preference. In this case, for better or worse, it looks like CUDA’s the preference. reply diggan 17 hours agorootparent> It has to play out long enough for the market to indicate a preference By what measures hasn't that happened already? CUDA been around and constantly improving for more than 15 years, and there is no competitors in sight so far. It's basically the de facto standard in many ecosystems. reply teucris 16 hours agorootparentThere haven’t been any as successful, but there have been competitors. OpenCL, DirectX come to mind. reply cogman10 16 hours agorootparentSYCL is the latest attempt that I'm aware of. It's still pretty active and may just work as it doesn't rely on video card manufactures to work out. reply zozbot234 15 hours agorootparentSYCL is the quasi-successor to OpenCL, built on the same flavor of SPIR-V. Various efforts are trying to run it on top of Vulkan Compute (which tends to be broadly support by modern GPU's) but it's non-trivial because the technologies are independently developed and there are some incompatibilities. reply coldtea 18 hours agorootparentprev>The problem with effectively supporting CUDA is that encourages CUDA adoption all the more strongly Worked fine for MS with Excel supporting Lotus 123 and Word supporting WordPerfect's formats when those were dominant... reply Dork1234 17 hours agorootparentMicrosoft could do that because they had the Operating System monopoly to leverage and take out both Lotus 123 and WordPerfect. Without the monopoly of the operating system they wouldn't of been able to Embrace, Extend, Extinguish. https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguis... reply bell-cot 17 hours agorootparentprevBut MS controlled the underlying OS. Letting them both throw money at the problem, and (by accounts at the time) frequently tweak the OS in ways that made life difficult for Lotus, WordPerfect, Ashton-Tate, etc. reply p_l 17 hours agorootparentLast I checked, Lotus did themselves by not innovating, and betting on the wrong horse (OS/2) then not doing well on a pivot to Windows. Meanwhile Excel was gaining features and winning users with them even before Windows was in play. reply robocat 17 hours agorootparent> betting on the wrong horse (OS/2) Ahhhh, your hindsight is well developed. I would be interested to know the background on the reasons why Lotus made that bet. We can't know the counterfactual, but Lotus delivering on a platform owned by their deadly competitor Microsoft would seem to me to be a clearly worrysome idea to Lotus at the time. Turned out it was an existentially bad idea. Did Lotus fear Microsoft? \"DOS ain't done till Lotus won't run\" is a myth[1] for a reason. Edit: DRDOS errors[2] were one reason Lotus might fear Microsoft. We can just imagine a narritive of a different timeline where Lotus delivered on Windows but did some things differently to beat Excel. I agree, Lotus made other mistakes and Microsoft made some great decisions, but the point remains. We can also suspect that AMD have a similar choice now where they are forked. Depending on Nvidea/CUDA may be a similar choice for AMD - fail if they do and fail if they don't. [1] http://www.proudlyserving.com/archives/2005/08/dos_aint_done... [2] https://www.theregister.com/1999/11/05/how_ms_played_the_inc... reply p_l 16 hours agorootparentI've seen rumours from self-claimed ex-Lotus employees that IBM made a deal with Lotus to prioritise OS/2 reply dadadad100 17 hours agorootparentprevThis is a key point. Before windows we had all the dos players - WordPerfect was king. Microsoft was more focused on the Mac. I’ve always assumed that Microsoft understood that a GUI was coming and trained a generation of developers on the main gui of the day. Once windows came out the dos focused apps could not adapt in time reply slashdev 18 hours agorootparentprevWith Nvidia controlling 90%+ of the market, this is not a viable option. They'd better lean hard into CUDA support if they want to be relevant. reply cduzz 18 hours agorootparentA bit of story telling here: IBM and Microsoft made OS/2. The first version worked on 286s and was stable but useless. The second version worked only on 386s and was quite good, and even had wonderful windows 3.x compatibility. \"Better windows than windows!\" At that point Microsoft wanted out of the deal and they wanted to make their newer version of windows, NT, which they did. IBM now had a competitor to \"new\" windows and a very compatible version of \"old\" windows. Microsoft killed OS2 by a variety of ways (including just letting IBM be IBM) but also by making it very difficult for last month's version of OS/2 to run next month's bunch of Windows programs. To bring this back to the point -- IBM vs Microsoft is akin to AMD vs Nvidia -- where nvidia has the standard that AMD is implementing, and so no matter what if you play in the backward compatibility realm you're always going to be playing catch-up and likely always in a position where winning is exceedingly hard. As WOPR once said \"interesting game; the only way to win is to not play.\" reply foobiekr 17 hours agorootparentIBM was also incompetent and the os/2 team in Boca was had some exceptional engineers but was packed witg mostly mediocre-to-bad ones, which is why so many things in OS/2 were bad and why IBM got upset for Microsoft contributing negative work to the project because their lines of code contribution was negative (they were rewriting a lot of inefficient bloated IBM code). A lot went wrong with os/2. For CUDA, I think a better analogy is vhs. The standard, in the effective not open sense, is what it is. AMD sucks at software and views it as an expense rather than an advantage. reply AYBABTME 16 hours agorootparentYou would think that by now AMD realizes that poor software is what left them behind in the dust, and would have changed that mindset. reply hyperman1 16 hours agorootparentMost businesses understand the pain points of their suppliers very well, as they feel that pain and gave themselves organized around it. They have a hard time to understand the pain points of their consumers, as they don't feel that pain, look trough their own organisation-coloured glases, and can't see the real pain points from the whiney-customer ones. AMD probably thinks software ecosystems are the easy part, ready to take it on whenever they feel like it and throw a token amount at it. They've built a great engine, see the carossery as beneath them, and don't understand why the lazy customer wants them to build the rest of the car too. reply neerajsi 16 hours agorootparentprevI'm not in the gpu programming realm, so this observation might be inaccurate: I think the case of cuda vs an open standard is different from os2 vs Windows because the customers of cuda are programmers with access to source code while the customers of os2 were end users trying to run apps written by others. If your shrink-wrapped software didn't run on os2, you'd have no choice but to go buy Windows. Otoh if your ai model doesn't run on an AMD device and the issue is something minor, you can edit the shader code. reply panick21_ 18 hours agorootparentprevIBM also made a whole bunch of strategic mistakes beyond that. Most importantly their hardware division didn't give a flying f about OS/2. Even when they had a 'better Windows' they did not actually use it themselves and didn't push it to other vendors. Windows NT wasn't really relevant in that competition for much longer, only XP was finally for end consumers. > where nvidia has the standard that AMD is implementing, and so no matter what if you play in the backward compatibility realm you're always going to be playing catch-up That's not true. If AMD starts adding their own features and have their own advantages, that can flip. It only takes a single generation of hardware, or a single feature for things to flip. Look at Linux and Unix. Its started out with Linux implementing Unix, and now the Unix are trying to add compatibility with with Linux. Is SGI still the driving force behind OpenGL/Vulcan? Did you think it was a bad idea for other companies to use OpenGL? AMD was successful against Intel with x86_64. There are lots of example of the company making something popular, not being able to take full advantage of it in the long run. reply chuckadams 17 hours agorootparentSlapping a price tag of over $300 on OS/2 didn’t do IBM any favors either. reply BizarroLand 17 hours agorootparentThat's what happens when your primary business model is selling to the military. They had to pay what IBM charged them (within a small bit of reason) and it was incredibly difficult for them to pivot away from any path they chose in the 80's once they had chosen it. However, that same logic doesn't apply to consumers, and since they continued to fail to learn that lesson now IBM doesn't even target the consumer market given that they never learned how to be competitive and could only ever effectively function when they had a monopoly or at least a vendor lock-in. https://en.wikipedia.org/wiki/Acquisition_of_the_IBM_PC_busi... reply incrudible 17 hours agorootparentprevWindows before NT was crap, so users had an incentive to upgrade. If there had existed a Windows 7 alternative that was near fully compatible and FOSS, I would wager Microsoft would have lost to it with Windows 8 and even 10. The only reason to update for most people was Microsoft dropping support. For CUDA, it is not just AMD who would need to catch up. Developers also are not necessarily going to target the latest feature set immediately, especially if it only benefits (or requires) new hardware. I accept the final statement, but that also means AMD for compute is gonna be dead like OS/2. Their stack just will not reach critical mass. reply BizarroLand 16 hours agorootparentTodays linux OS's would have competed incredibly strongly against Vista and probably would have gone blow for blow against 7. Proton, Wine, and all of the compatibility fixes and drive improvements that the community has made in the last 16 years has been amazing, and every day is another day where you can say that it has never been easier to switch away from Windows. However, Microsoft has definitely been drinking the IBM koolaid a little to long and has lost the mandate of heaven. I think in the next 7-10 years we will reach a point where there is nothing Windows can do that linux cannot do better and easier without spying on you, and we may be 3-5 years from a \"killer app\" that is specifically built to be incompatible with Windows just as a big FU to them, possibly in the VR world, possibly in AR, and once that happens maybe, maybe, maybe it will finally actually be the year of the linux desktop. reply coderenegade 7 hours agorootparentI don't think it'll be a killer app so much as a confluence of different factors. For one thing, we now live in a world where docker is fast becoming as ubiquitous as git, and unlike git, requires a Linux VM to run on Windows. It's also a key technology for the replication and distribution of ML models, which again, are developed on Linux, trained on clusters running Linux, and deployed to servers running Linux. And this is all done in Python, a language native to Linux, which is now one of the most used languages on Earth. We already see things like Google abandoning tensorflow support for Windows, because they don't have enough devs using Windows to easily maintain it. And of course, we have a changing of the guard in terms of a generation of software developers who primarily worked on Windows, because that was the way to do it, starting to retire. Younger devs came up in the Google era where Linux is a first class citizen alongside MacOS. I think these factors are going to change the face of technology in the coming 15 years, and that's likely to affect how businesses and consumers consume technology, even if they don't understand what's actually running under the hood. reply pjmlp 14 hours agorootparentprevThere is no competition when games only come to Linux by \"emulating\" Windows. The only thing it has going for it is being a free beer UNIX clone for headless environments, and even then, isn't that relevant on cloud environments where containers and managed languages abstract everything they run on. reply BizarroLand 14 hours agorootparentThanks to the Steam Deck, more and more games are being ported for Linux compatibility by default. Maybe some Microsoft owned games makers will never make the shift, but if the majority of others do then that's the death knell. reply pjmlp 12 hours agorootparentNah, everyone is relying on Proton, there are hardly any native GNU/Linux games being ported, not even Android/NDK ones, where SDL, OpenGL, Vulkan, C, C++ are present, and would be extremely easy to port. reply incrudible 12 hours agorootparentprevAre they ported though? I would say thanks to the Steam Deck, Proton is at a point where native Linux ports are unnecessary. It's also a much more stable target to develop against than N+1 Linux distros. reply BizarroLand 10 hours agorootparentMany are specifically ported to work with Linux without a wrapper, especially among indie games and games from smaller studios. Unity, Unreal and Godot all support compiling for Linux either by default or with inexpensive or possibly free add-ons. I'm sure many other game engines do as well, and when you're taking a few hours of work at most to add everyone who owns a steam deck or a steam deck clone as a potential customer to your customer base then that is not a tall order. reply pjmlp 4 hours agorootparentThey do, yet you will hardly find a big name Studio that will waste additional money doing builds, QA and customer support for GNU/Linux, just let Valve do the needful with Proton. reply paulmd 15 hours agorootparentprev> However, Microsoft has definitely been drinking the IBM koolaid a little to long and has lost the mandate of heaven. I think in the next 7-10 years we will reach a point where there is nothing Windows can do that linux cannot do better and easier without spying on you that's a fascinating statement with the clear ascendancy of neural-assisted algorithms etc. Things like DLSS are the future - small models that just quietly optimize some part of a workload that was commonly considered impossible to the extent nobody even thinks about it anymore. my prediction is that in 10 years we are looking at the rise of tag+collection based filesystems and operating system paradigms. all of us generate a huge amount of \"digital garbage\" constantly, and you either sort it out into the important stuff, keep temporarily, and toss, or you accumulate a giant digital garbage pile. AI systems are gonna automate that process, it's gonna start on traditional tree-based systems but eventually you don't need the tree at all, AI is what's going to make that pivot to true tag/collection systems possible. Tags mostly haven't worked because of a bunch of individual issues which are pretty much solved by AI. Tags aren't specific enough: well, AI can give you good guesses at relevance. Tagging files and maintaining collections is a pain: well, the AI can generate tags and assign collections for you. Tags really require an ontology for \"fuzzy\" matching (search for \"food\" should return the tag \"hot dog\") - well, LLMs understand ontologies fine. Etc etc. And if you do it right, you can basically have the AI generate \"inbox/outbox\" for you, deduplicate files and handle versioning, etc, all relatively seamlessly. microsoft and macos are both clearly racing for this with the \"AI os\" concept. It's not just better relevance searches etc. And the \"generate me a whole paragraph before you even know what I'm trying to type\" stuff is not how it's going to work either. That stuff is like specular highlights in video games around 2007 or whatever - once you had the tool, for a few years everything was w e t until developers learned some restraint with it. But there are very very good applications that are going to come out in the 10 year window that are going to reduce operator cognitive load by a lot - that is the \"AI OS\" concept. What would the OS look like if you truly had the \"computer is my secretary\" idea? Not just dictating memorandums, but assistance in keeping your life in order and keeping you on-task. I simply cannot see linux being able to keep up with this change, in the same way the kernel can't just switch to rust - at some point you are too calcified to ever do the big-bang rewrite if there is not a BDFL telling you that it's got to happen. the downside of being \"the bazaar\" is that you are standards-driven and have to deal with corralling a million whiny nerds constantly complaining about \"spying on me just like microsoft\" and continuing to push in their own other directions (sysvinit/upstart/systemd factions, etc) and whatever else, on top of all the other technical issues of doing a big-bang rewrite. linux is too calcified to ever pivot away from being a tree-based OS and it's going to be another 2-3 decades before they catch up with \"proper support for new file-organization paradigms\" etc even in the smaller sense. that's really just the tip of the iceberg on the things AI is going to change, and linux is probably going to be left out of most of those commercial applications despite being where the research is done. It's just too much of a mess and too many nerdlingers pushing back to ever get anything done. Unix will be represented in this new paradigm but not Linux - the commercial operators who have the centralization and fortitude to build a cathedral will get there much quicker, and that looks like MacOS or Solaris not linux. Or at least, unless I see some big announcement from KDE or Gnome or Canonical/Red Hat about a big AI-OS rewrite... I assume that's pretty much where the center of gravity is going to stay for linux. reply incrudible 12 hours agorootparent\"Neural assisted algorithms\" are just algorithms with large lookup tables. Another magnitude of binary bloat, but that's nothing we haven't experienced before. There's no need to fundamentally change the OS paradigm for it. reply paulmd 11 hours agorootparentI think we're well past the \"dlss is just FSR2 with lookup tables, you can ALWAYS replicate the outcomes of neural algorithms with deterministic ones\" phase, imo. if that's the case you have billion-dollar opportunities waiting for you to prove it! reply BizarroLand 14 hours agorootparentprevCounterpoint: Most AI stuff is developed on either an OS agnostic language like Python or C, and then ported to Linux/OSX/Windows, so for AI it is less about the OS it runs on than the hardware, drivers, and/or connections that the OS supports. For the non-vendor lock in AI's (copilot), casting as wide of a net as possible to catch customers as easily as possible should by default mean that they would invest the small amount of money to build linux integrations into their AI platforms. Plus, the googs has a pretty deep investment into the linux ecosystem and should have little issue pushing bard or gemini or whatever they'll call it next week before they kill it out into a linux compatible interface, and if they do that then the other big players will follow. And, don't overlook the next generation of VR headsets. People have gotten silly over the Apple headset, but Valve should be rolling out the Deckhard soon and others will start to compete in that space since Apple raised the price bar and should soon start rolling out hardware with more features and software to take advantage of it. reply coderenegade 6 hours agorootparentMost AI dev that I've seen tends to be done on Linux or MacOS first. Certainly the research and training are, because HPC tends to be Linux. And of course, the models are deployed in containers, a Linux technology, to webservers running Linux. MS has put a collosal amount money into catching up to at least be able to take advantage of the AI wave, that much is clear. Maybe for consumers this will be enough, but R&D wise I don't see them ever being the default choice. And this is potentially a huge problem for them in the long run, because OS choice by industry is driven by the available tooling. If they lose ML, they could potentially lose traditional engineering if fields like robotics start relying on Linux more heavily. reply andy_ppp 18 hours agorootparentprevWhen the alternative is failure I suppose you choose the least bad option. Nobody is betting the farm on ROCm! reply hjabird 17 hours agorootparentTrue. This is the big advantage of an open standard instead jumping from one vendors walled garden to another. reply mqus 10 hours agorootparentprevIf their primary objective is to sell cards, then they should make it as easy as possible to switch cards. If their primary objective is to break the CUDA monopoly, they should up their game in software, which means going as far as implementing support for their hardware in the most popular user apps themselves, if necessary. But since they don't seem to want to do that, they should really go for option one, especially if a single engineer already got so far. Let's say AMD sold a lot of cards with CUDA support. Now nvidia tries to cut them off. What will happen next? A lot of people will replace their cards with nvidia ones. But a lot of the rest will try to make their expensive AMD cards work regardless. And if AMD provides a platform for that, they will get that work for free. reply mindcrime 15 hours agorootparentprevYep. This is very similar to the \"catch-22\" that IBM wound up in with OS/2 and the Windows API. On the one hand, by supporting Windows software on OS/2, they gave OS/2 customers access to a ready base of available, popular software. But in doing so, they also reduced the incentive for ISV's to produce OS/2 native software that could take advantage of unique features of OS/2. It's a classic \"between a rock and a hard place\" scenario. Quite a conundrum. reply ianlevesque 15 hours agorootparentThinking about the highly adjacent graphics APIs history, did anyone really 'win' the Direct3D, OpenGL, Metal, Vulkan war? Are we benefiting from the fragmentation? If the players in the space have naturally coalesced around one over the last decade, can we skip the thrashing and just go with it this time? reply tadfisher 15 hours agorootparentThe game engines won. Folks aren't building Direct3D or Vulkan renderers; they're using Unity or Unreal or Godot and clicking \"export\" to target whatever API makes sense for the platform. WebGPU might be the thing that unifies the frontend API for folks writing cross-platform renderers, seeing as browsers will have to implement it on top of the platform APIs anyway. reply pjmlp 3 hours agorootparentprevYou missed the Nintendo and Sony APIs as well. FOSS folks make this a bigger issue than it really is, game studios make a pluggable API on their engi",
    "originSummary": [
      "AMD has financially supported the development of an open-source drop-in CUDA implementation called ZLUDA, which enables NVIDIA CUDA applications to run on AMD Radeon GPUs without modifying the source code.",
      "Originally developed for Intel graphics, ZLUDA has been adapted for use on AMD GPUs, but it is not completely fail-safe and lacks full support for NVIDIA OptiX.",
      "The open-source release of ZLUDA allows the identification of the actual Radeon graphics card string, rather than the generic \"Graphics Device\" label."
    ],
    "commentSummary": [
      "The discussion revolves around AMD's attempts to compete with NVIDIA in the GPU market, mainly in machine learning and software compatibility.",
      "Concerns are raised about the overwhelming dominance of CUDA and the difficulties in emulating it, emphasizing the need for open standards.",
      "The conversation also addresses AMD's software and driver support challenges and emphasizes the significance of operating systems in the AI field. A general call is made for increased accessibility, collaboration, and competition in the industry."
    ],
    "points": 973,
    "commentCount": 378,
    "retryCount": 0,
    "time": 1707746435
  },
  {
    "id": 39344770,
    "title": "Billions stolen in US wage theft, disproportionately impacting marginalized workers",
    "originLink": "https://www.theguardian.com/us-news/2023/jun/15/wage-theft-us-workers-employees",
    "originBody": "View image in fullscreen A construction worker on the ‘Signature Bridge’ in Miami in 2021. Florida does not have a state labor department to oversee the third largest workforce in the US. Photograph: Joe Raedle/Getty US unions This article is more than 7 months old ‘I have not seen one cent’: billions stolen in wage theft from US workers This article is more than 7 months old Employees across the country are not getting paid what they are owed, and critics say government is toothless to help Michael Sainato @msainat1 Thu 15 Jun 2023 06.00 EDT Jose Martinez worked for a construction contractor in New York City for six months in 2019 when he and his co-workers suddenly stopped getting paid. Martinez said the contractor, Star Builders, initially blamed the owners of the building for not dispersing money for the project. Martinez said he and his colleagues were eventually paid late, but the delays kept happening. The contractor came up with more excuses for the lack of payment. Eventually Martinez and several of his co-workers left after not getting paid for four weeks of work. Dirty planes and high prices: US workers and passengers expect further misery as air travel rebounds Read more “I have not seen one cent from that money that is owed yet,” added Martinez, who filed a wage theft claim with the New York state labor department in 2019 with assistance from the non-profit Make the Road New York. “It affected me a lot because at the time, I had to start finding other work, I had to pay bills and pay rent and I didn’t have money, so I had to get loans that I eventually had to pay back once I got another job.” The contractor, Star Builders, did not respond to multiple requests for comment. Martinez is far from alone. Workers in the US have an estimated $50bn-plus stolen from them every year, according to the Economic Policy Institute, surpassing all robberies, burglaries and motor vehicle thefts combined. The majority of these stolen wages are never recovered by workers. Between 2017 to 2020, $3.24bn in stolen wages were recovered by the US Department of Labor, state labor departments and attorney generals, and through class- and collective-action litigation. Wage theft disproportionately affects lower-wage workers, women, people of color and immigrant workers, and negatively affects local economies and tax revenues. There are numerous forms of wage theft, from employers not compensating workers for time worked, violating minimum wage and overtime laws, misclassifying employees as independent contractors, not providing legally required meal breaks, confiscating worker tips, or illegally taking deductions from worker wages. Wage-theft violators include some of the largest employers in the US; Amazon paid $18m in November 2022 to settle a wage-theft class-action lawsuit in Oregon, the largest in the state’s history, and paid a $61.7m fine in 2021 over allegations of stealing tips from Amazon Flex drivers. According to a 2018 report by Good Jobs, between January 2000 to 2018, Walmart paid over $1.4bn in fines and settlements over wage theft violations, FedEx paid over $500m during the same period, and Bank of America paid over $380m. Construction contractors have a notorious reputation for wage-theft violations, often affecting immigrant workers, and exploiting loopholes to avoid paying wage-theft claims, such as shutting down businesses and reopening under a different business filing. Martinez wants to warn others in the sector. “People need to be very careful with contractors, because they always say, ‘We have a lot of work for you to do’ to keep you there. They would say, ‘It’s just a matter of time, we just have to wait for the payment, it’s going to be OK,’ and so they’re always talking that way to keep people working there,” said Martinez. “Workers shouldn’t let more than one week go by without getting their payment because they’re always going to come up with some excuse.” Despite the state of New York’s worker protections and laws aimed at curtailing wage theft, the Center for Popular Democracy estimated in 2019 that wage theft may affect 2.1 million workers in New York every year, exceeding $3bn annually. Goma Yonjan Gurung has worked as a nail technician in the New York City area for 25 years, an industry where wage theft is rampant and scantily enforced. A February 2020 report by the New York Nail Salon Workers Association noted 82% of workers reported experiencing wage theft at an average amount of $181 per week. “Even though the government says the minimum wage is $15 an hour, what I know is it’s not happening for many nail technicians, including myself. In some places they pay as low as $10 an hour,” she said. “The government in the past has passed bills mandating minimum wage or time off, but what happens is it is not implemented or being practiced by employers.” Worker advocates have criticized the state’s labor department for lack of enforcement of wage-theft violations and not recovering stolen wages from employers. Other states, such as Florida, do not have a state labor department to oversee the third largest workforce in the US, leaving workers with fewer options to try to recover stolen wages. A bartender in Orlando, Florida who requested to remain anonymous because they still work in the industry, said they started a new bartending job in May and pushed back when they found out their hourly wage was just a daily rate of $30, despite working eight-hour shifts. “I reminded my manager that paying less than minimum wage was illegal, and added a link to a law firm’s page about it. He fired me,” the worker said. “Getting fired for not wanting to be paid below the already insanely low minimum wage after working in the industry for over 20 years was pretty rough.” The worker attempted to file a complaint with the US Department of Labor and the Florida attorney general’s office but was told they only prioritize higher wage violations and never heard back after being told someone would follow up. Rodrigo Camarena, director of the Justicia Lab, an advocacy group, said: “The process for filing a wage-theft complaint form is very onerous and cumbersome, so there’s an immediate obstacle in the process itself. But once that form is filed, it takes months if not years for the department of labor to even investigate it.” The Justicia Lab recently launched a digital tool, ¡Reclamo!, for workers to file wage-theft claims. Camarena said: “In the meantime, that person is going without that income that they earned potentially, and the employer isn’t being penalized in any way, so there’s a delay in enforcement and then the enforcement process also isn’t as thorough as it could be.” New York legislators and worker groups have been pushing to pass the Securing Wages Earned Against Theft (Sweat) Act to enforce New York’s wage-theft laws and make it more difficult for employers to avoid accountability for wage-theft violations. “There needs to be more work at the state level, that not just holds individual employers accountable but to really hold industries accountable that are problematic and root out the ways employers get out of paying wages owed,” added Camarena. “We need to ensure that worker rights are protected in all cases, because ultimately this issue is about the dignity of everyone.” Explore more on these topics US unions news Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=39344770",
    "commentBody": "Billions stolen in wage theft from US workers (theguardian.com)362 points by wahnfrieden 20 hours agohidepastfavorite398 comments spamizbad 19 hours agoThis phenomena is pretty widespread in the service industry and I would venture to say that a significant minority of businesses participate in some version of wage theft. For example, one of my jobs right out of high school was waiting tables at a local restaurant. If you were opening, the expectation from owners and management was you'd get in early to help open but would wait 15 minutes before service started before clocking in. So on those days you'd do 30-45 minutes of fully unpaid labor. There was well understood that if you complained about this not only would they fire you but they'd call up all their industry buddies and you'd basically be on every other restaurants no-hire list. At the time I was pretty naive and didn't think much of it, just figured that's the way the world worked. Doing the math, because I always made more than the tipped minimum wage, I think it only ended up costing me $7/week in wages - but if I stole $7 out of the till each week for a year in a half I'd be charged with a felony. reply MOARDONGZPLZ 19 hours agoparentI had a manual labor job when I was 16 that my parents wanted me to get to build some character. A night a week or so and one shift on the weekend. The need for labor was dependent on customer demand on a given day and weather and fluctuated greatly. Practice was so show up and wait around in the break room until it was busy enough that you were needed, and then people would be called in order of arrival. So some people would wait around hours to even find out if they might work that day. I did it a couple times and found it so demoralizing I quit. Later I found out that practice is very illegal. reply nonrandomstring 19 hours agorootparentYou think the construction industry is illegal. Wait till you hear about academia!! :) This is the life today for zero-hours, at-will employment in the university sector. As a visiting professor I've had universities ask me to deliver a semester course a year in advance, and call the week before to say they're not running it. At the very minimum a 12 week course takes 40 hours of preparation even if you're just refreshing the notes and practicals from last time. I've had Russell group universities not pay me for two years. They've flat out \"lost\" my invoices, three times! Two major league universities tried to stiff me out of over £2000 and had to be threatened with legal action. One London uni asked me to prepare a DSP course, then instead of hiring me to deliver it plagiarised my slides, took my name off them and got a junior lecturer to deliver the course instead. The last university I worked at were so careless with my payments that my accountant advised me to \"extricate immediately\" because there so many \"anomalies\" she couldn't keep track of them all. Universities are absolute f*king gangsters. reply londons_explore 17 hours agorootparentUniversities, unlike building firms, have actual assets and are unlikely to claim bankruptcy. That means you could easily take the above issues to small claims court as long as you had them in writing (and remember, even a agreement to pay you via email usually suffices - no formal documents or signatures required) reply nonrandomstring 17 hours agorootparentYou're not wrong, but my goodness... the effort, and the waiting. It's so sapping to have to work for your money like a regular person, and then work again and again just to get what's rightfully due to you. reply iinnPP 15 hours agorootparentThis is a very important point that a lot of folks miss. You van spend hundreds or even thousands of hours getting what is obviously due and often that is all lost. I have let many people go who I would persue in a world with my hours being paid(at a lawyers rate) in the event of a victory in the courtroom. Ahhh, should land... reply asadotzler 10 hours agorootparentprevThey have lawyers and you don't so expect this to be dragged out and expensive for you and your rewards, if successful, to not even cover the initial losses fully, much less the time and money of the suit. The big companies will always win. Better off suing the small construction company or building firm, as you're far more likely to be on even(er) ground with them. reply ebiester 17 hours agorootparentprev...and then your career in academia is over, regardless of the official rules of retribution. Which, based on all of the bad experiences, might be a blessing in disguise for adjuncts (UK or otherwise!) reply nonrandomstring 17 hours agorootparentNo, it's not like that. I write excoriating pieces in the Times Higher, completely damning the UK university system as \"unfit for teaching and leaning\" [0], and they still call me and ask \"can you just cover this class?\". Amusing as that desperation is, in a way it's more terrifying how the machinery of blind capitalism works. The system isn't capable of sentiment like that. They don't care what I say. It's just business. They're not there keeping a score of 'friends' and 'enemies'. Universities run on people like me who are of the \"academic mindset\", who can and will do things like teaching because we love it as a vocation even though the salary is a quarter or fifth of what is on offer privately. In the end, the only solution is to say no, even when you'd really like to do it. It's a weird modern tragedy. [0] https://cybershow.uk/blog/posts/cyber-education/ reply robertlagrant 16 hours agorootparent> Universities run on people like me who are of the \"academic mindset\", who can and will do things like teaching because we love it as a vocation even though the salary is a quarter or fifth of what is on offer privately. Everything runs like this. Jobs people want will pay less than jobs people don't want. reply alan-hn 16 hours agorootparentDoes that mean everyone wants to be a waiter and nobody wants to be a CEO? reply tristor 16 hours agorootparent> Does that mean everyone wants to be a waiter and nobody wants to be a CEO? Unironically, yes. Most people don't have enough exposure to actually understand what the job of a CEO is. I have had that exposure, and I don't ever want to be the CEO of any sizeable company. Once you become CEO, work/life balance utterly ceases to exist, because you are the person imbued as the corporation, meaning you are literally always working, always on call, always stuck with the most difficult or intractable decisions where maybe all the options are wrong, and no matter your choice everyone will hate you. It's a terrible job that people only do because it pays so well. I am not the CEO but I'm much higher up the food chain today than I was when I started. I often reminisce fondly about my time working phone tech support, because I could work my queue and walk out without having to give any thought to anything that occurred that day. That's not the reality of being in any sort of management role, and the higher up you go the less that matches reality. reply nonrandomstring 24 minutes agorootparentObligatory: \"You know, one day, my mother, she put me on her knee and she said to me, 'Gaston, my son, the world is a beautiful place. You must go into it and love everyone, try to make everyone happy, and bring peace and contentment everywhere you go,' and so, I became a waiter. Well, it's it's not much of a philosophy, I know... but, well,... fuck you. I can live my own life in my own way if I want to. Fuck off.\" Replace waiter with CEO and I think it would still work. I mean, why do any of us do anything? reply ghaff 15 hours agorootparentprevSenior exec positions (at large companies) pay really well for the most part--but I couldn't imagine doing that sort of thing for more than a few years with the mindset that I'm doing my time in purgatory so that I can retire early and have a sane life. (Some CEOs seem to have a better ability to carve off some me-time but it's still a job a lot of people wouldn't want for the long term.) reply HeatrayEnjoyer 15 hours agorootparentprevThis is no worse than the demands beared by countless $12/hr general managers. reply tristor 15 hours agorootparent> This is no worse than the demands beared by countless $12/hr general managers. That is grossly incorrect. Also, general managers don't make $12/hr. The average general manager in the US makes ~$87k/yr, and can be as high as $150k/yr, and depending on the specific industry you can end up with relatively sizeable compensation based on profit sharing and bonus structures. A general manager typically oversees a single location of a much larger business entity, with oversight for less than 500 staff, compared to a CEO that may have tens of thousands of people and their myriad workstreams that they are trying to weave into some unified vision/strategy plus dealing with the personnel challenges that go with that scale. I realize you were trying to be pithy, but let's not do that on HN. reply yen223 15 hours agorootparentprevI have yet to see a CEO choose to go back down the food chain, even though that is something they have the power to do. reply tristor 14 hours agorootparentTypically the way it works is the comp structure is such that after a few years in the role you can semi-retire. The goal of anyone who is a CEO is to try throw their hat in the ring, hopefully do a good job, and then step away to help other people who want to be CEOs. Generally they do this by taking on board seats or becoming an investor. The average CEO tenure is 7 years and the median is 5 years[1]. This is not a job you can do for a long time without it basically killing you due to the stress. I'm sure you've seen all the before/after pictures they always do for POTUS. If you saw similar photos for folks becoming CEOs of a major company, you'd see a similar change. Being a CEO is a job that will literally run you ragged. It destroys your health, and is not something most people can tolerate for longer than a decade. [1]: https://corpgov.law.harvard.edu/2018/02/12/ceo-tenure-rates/ reply ghaff 15 hours agorootparentprevCEOs of large companies generally don't go back down the food chain because they don't need to. They retire/semi-retire (e.g. get a board seat or some other advisor type of position) instead. reply HeatrayEnjoyer 15 hours agorootparentThe strongest factor in personal employment decisions is what we \"need to\". Of course a CEO doesn't need to continue pulling their weight when they have piles of cash to retire on. reply robertlagrant 9 hours agorootparent> The strongest factor in personal employment decisions is what we \"need to\". Possibly, but once that's satisfied, or even the satisfaction of that is well in the rear view mirror, other things become important. E.g. company mission; prestige; moving in the right circles; pushing into politics. reply ghaff 15 hours agorootparentprevAs a CEO (or elite athlete, etc.) it can also be getting an even more prestigious role. But, yes, failing that it probably makes sense to drop the whole thing and just enjoy your piles of cash (which may or may not involve still doing some nominal work). reply robertlagrant 11 hours agorootparentprev> Does that mean everyone wants to be a waiter and nobody wants to be a CEO? You've committed the fallacy of the single cause. A reason doesn't mean the reason for lower salaries. reply alan-hn 6 hours agorootparentIs it me committing the fallacy or am I responding to the fallacy? reply robertlagrant 1 hour agorootparentCommitting. reply Cheer2171 18 hours agorootparentprevUS academia has its problems, but UK academia is a whole different nightmare. reply iinnPP 15 hours agorootparentCanada would like a word. When 35% of a test is easily verified as incorrect and nobody is willing to fix it. Rain days.... Too cold days(-5°c)... reply avgcorrection 19 hours agoparentprev> not only would they fire you but they'd call up all their industry buddies and you'd basically be on every other restaurants no-hire list. So like a much-dreaded union for employers except it’s underhanded and illegal. reply ncallaway 18 hours agorootparentYes, exactly. And it’s underhanded and illegal when employers do it, because there’s an imbalance of power between employee and employee. Unions exist to even out that balance of power. When employers engage in that kind of activity it further increases the imbalance of power. For example, in this case, they were using that tactic to support their ability to steal from employees. reply mjburgess 17 hours agorootparentTo clarify this further: The employer is already a collective, \"A business\", and the hiring manager is operating with the full power of that collective in hiring/firing negotations. A union is a collective to balance power against the business (collective). A cartel is a collective of collectives (ie., a group of businesses) operating to defeat free market competition regulation, in this sense the cartel is balancing power against the state -- which is the only permitted \"collective of collectives\". Cartels challenge states (power to create free markets), whereas unions challenge businesses (power to hire/fire). This is why unions are permissible and cartels are not. reply dmoy 16 hours agorootparent\"Cartels of unions\" or whatever are legal in some jurisdictions. See e.g. solidarity action / sympathy strikes. Depending on the country, that varies from \"totally illegal\" to \"well of course you're gonna solidarity strike, that's how it's done\". reply fallingknife 13 hours agorootparentprev> unions challenge businesses (power to hire/fire). Which is kind of the problem with unions. If they stuck to negotiating pay levels while leaving businesses free to hire and fire who they see fit I think employers would be much more willing to work with them. Higher salary expenses are much less damaging to a business than not being able to fire incompetent workers. reply phpisthebest 17 hours agorootparentprevThis is very simplistic, and somewhat wrong First and foremost, states do not, and cannot \"create free markets\" the existence of a state to regulation a market makes is de-facto non-free This is also a very rose colored look at unions, while simultaneously demonizing businesses. In reality it is completely possible to have an exploitive union. At the end of the day, power corrupts, and the more power a person or group has over another person or group the more corrupting that power is. Thus in a very large union you will likely see just as much employee abuse, as in a very large company. The sweet spot has always as well always been in Medium sized organizations, or unions, above 300 employees, under 3000 employees. Anything larger or smaller and the risk of abuse and poor conditions go up considerably even if you are represented by a large union reply mjburgess 17 hours agorootparenterr.. no, free markets are state constructions. By default, an unregulated market becomes non-free essentially immediately, as cartels form (indeed, as cartels of cartels form, hence states). As Hobbes observed, in the state of nature there is no motivation to remain as an individual, so you form groups in order for self-protection. In an \"anarchical market\" you end up with incredible levels of monopolisation (etc.). A free market is a state construction whereby cartels, scams, fraud, (murder, theft, etc.) is prohibited so that limited liability collectives (another state construction) called \"businesses\" can freely compete for labour and profit. reply vundercind 17 hours agorootparentFWIW, to bystanders without context for this area of study, the parent is basically the orthodox take on the role of the state in modern economies and “free markets”: in short, you can’t have one (certainly not a highly-productive one that makes life not-suck) that lasts for any length of time without a state, and the “shape” it takes and whom it serves and to what degree is meaningfully determined by same state. reply mjburgess 16 hours agorootparentThere is an irony that capitalism is claimed by the anarcho-libertarian lot. As capitalism is the most collectivised system in human history (consider, only, the scale of Microsoft) -- and also the most anti-capitalist system (ie., it forces capitalists to compete and hence dramatically diminishes their power relative to other systems). Perhaps one day we might see capitalism as an \"iterated socialism\" (ie., socialism as thought about if you include time in your imagination). And communism, libertarianism, anarchism, etc. as all products of a time-free form of reasoning where you can just pause the world and imagine that all people will \"run the same program\". reply vundercind 16 hours agorootparentYeah, last I checked the “story” of capitalism and strong market economies is generally regarded as essentially having the emergence of the proto-nation-state (as in e.g. Spain under the “Catholic Monarchs”) as a prerequisite, as far as being something that can exist on an all-encompassing scale rather than in the margins, in tiny states navigating the “waters” between larger polities with other economic systems. Stability and guarantees from a strong central state really grease the wheels of commerce. reply kelseyfrog 16 hours agorootparentThat's essentially my understanding too. The legal construction of property, and rule and commodification of law are all necessary functions of market economies. reply samatman 16 hours agorootparentprevCartels are a feature of free markets. I would argue that it's good for the state to take some sort of interest in regulating them, one of several ways that I'm not a free-market fundamentalist. But arguing that the formation of cartels makes a market non-free is backward. Cartels emerge through free association in trade. Regulating them might make for a more functional market, a more efficient market (or it might not) but it makes for a less free market, always. I will add that I consider the very idea of \"absence of the state\" to be badly-formed, states vary considerably in their constitution but there's always something serving that role, even if it's a few elders in a village. reply asadotzler 10 hours agorootparentIf a cartel sets the price, rather than supply and demand, is it really a free market? Of course the answer is no and that's obvious to anyone giving it any thought at all. reply mjburgess 15 hours agorootparentprevA market isn't free if prices aren't set by supply and demand operating under the guarantees of free exchange given by states (ie., property rights, and the rest). A cartel sets prices, and is one of the many ways markets are unfree. There's a ton of confusion created by libertarian sorts who fail to distinguish between government regulation which sets prices, and regulation necessary for the operation of the market itself. Basically delusional ideologues have denied the latter exists, by just ignoring it. If a government acts to set prices it makes a market non-free, just as much as if a cartel does so. \"Free\" cannot plausibly mean that a mafia is fine but a police force isnt.. and the claim that it does is just libertarian propaganda. Governments which regulate markets so as to prevent cartels are acting to prevent the very sort of price-setting which \"free\" denotes does not occur reply ludwigDual 14 hours agorootparent> A cartel sets prices, and is one of the many ways markets are unfree. That's true, but cartels can't enforce this. New or external firms can compete with the cartel. If a cartel reduces production or raises prices then it incentivizes competitors to meet the market demand with lower prices. The only way the cartel can exclude new firms is by controlling the entirety of some resource or enforcing the cartel usually in the form of lobbying for regulations. reply wahnfrieden 14 hours agorootparentIn Ontario, the \"dairy cartel\" invaded the big name convenience stores and groceries and forcibly replaced product on the shelf with their own without repercussion reply ludwigDual 11 hours agorootparentI wonder what factors prevented competition with the \"dairy cartel\" in Ontario as would happen in a free market. Most likely there are restrictions on what products can be sold to willing customers that are costly for smaller firms to comply with. There may also be subsidies that have criteria that entrenched firms benefit from, but impose additional restrictions on how new firms can function. reply mjburgess 1 hour agorootparentWhy would it be worthwhile to compete with a dairy cartel? Of all the things one can do with capital, why go to war with a cartel over relatively small margins? You're assuming also that the cartel is operating only \"economically\", not also, eg., bribing, blackmailing, (stealing, murdering, ...), ...potential competitors. Why not just invite any competitor into the cartel? Why not buy them out? Why not \"make life difficult\" for them? The underlying assumption that \"things wash out\" requires supposing that an extremely simplistic newtonian model of an economy where politics doesnt really occur. But people are foremost political, ie., engaged in tribal behaviour, collectivising, using force, and so on. This doesnt \"wash out\". reply wahnfrieden 15 hours agorootparentprevgraeber/wengrow would disagree reply samatman 13 hours agorootparentNeither of those people are a good source on the common definition of free markets. \"Free market\" is just two words, they can mean whatever an author wants. But it's useful to have a common vocabulary, and respectful to stick with the definition used by whomever introduces a term. reply wahnfrieden 13 hours agorootparent> I will add that I consider the very idea of \"absence of the state\" to be badly-formed, states vary considerably in their constitution but there's always something serving that role, even if it's a few elders in a village. reply phpisthebest 17 hours agorootparentprevwell now we will get in a Hobbes vs Locke, I am more Lockean I disagree, and history has shown that free markets absent government control doe not instantly become monopolized, and infact through out most of history monopolize form when the government regulates the most Look at todays market as an example, the most competition is present in markets where the government has the least influence, where markets like energy, healthcare, etc which are the most regulated are also the most monopolized reply mjburgess 17 hours agorootparentI know of no example in all of human history of a free market without a state, at least one of more than a short period -- so my position is very weak here, if you can show only one, i'd have to at least modify it. Yet, I bet you cannot. Neutrally, using the term \"anarchical market\", i'd say that these markets are empheral. Everyone them has to act against rules which are not in their self-interest, it's highly unclear why a subgroup of market participants wouldnt immediately collectivise and outcompete everyone else. Collectivisation is human's superpower, and the obvious an immediate thing basically everyone does (hence: mafia, warlords, cartels, etc.). It would be remarkable to see this anarchical market of yours remain free for very long, so I'd gladly hear of one case. The main mechanism against collectivisation is that some biggest baddest collective decides to prohibit it (hence the state). There may be others, but I can think of none that would operate under anarchical conditions. reply tremon 15 hours agorootparent[an] example in all of human history of a free market without a state The Hanseatic League. This was basically its own trade association across North Europe, based on maritime trade. It had considerable market/economic power, but no legislative power; most participants were city-states so they were self-reliant to a degree, but none of them had jurisdiction or power over the entire group. reply mjburgess 15 hours agorootparentI can't speak to the example other than skimming wikipedia, but: > Hanseatic Cities gradually developed common trade regulations. > That year, the merchants of the Hansa in Cologne convinced King Henry II of England to exempt them from all tolls in London[26] and to grant protection to merchants and goods throughout England.[27]: 14–17 > etc. > By the mid-16th century, these weak connections left the Hanseatic League vulnerable, and it gradually unraveled as members became consolidated into other realms or departed, ultimately disintegrating in 1669. So it looks like the league was parasitic on the relevant states involved being able to implement regulations, so, basically exactly the point i'm making. And secondarily, insofar as the legague itself lacked a mechanism to enforce transnational agreeement, it was weak and collpased. So QED: insofar as participating states had viable regulating mechanisms the system work; insofar as challenges arose which requrired transnational mechanisms, it fell apart. reply mcv 16 hours agorootparentprevMarkets do not instantly become monopolized, but they do tend that way, and will also eagerly form cartels unless stopped by regulation. Of course it matters what kind of regulation; it's also possible to regulate markets in a way that protects monopolies, and some governments do that. So it's important to have a government that understands the importance of a free market. To give you some examples, the Dutch markets for health insurance and energy are entirely privatised but heavily regulated, and quite competitive. It's easy to switch from one provider to another, and so they compete hard on price. Although perhaps more so in the early days after privatisation than more recently. On the other hand, the market for software is not very regulated, it's heavily monopolised. Sometimes the EU makes moves to increase competition, but that's only piecemeal and not always terribly effective; Microsoft still rules the desktop, except in those areas where Apple now rules it. reply ludwigDual 14 hours agorootparent> Markets do not instantly become monopolized, but they do tend that way, and will also eagerly form cartels unless stopped by regulation. Monopolization requires control of land or resources. This is because any cartel's attempt to set artificially high prices can be undercut by new entrants to the market who aren't in the cartel. > On the other hand, the market for software is not very regulated, it's heavily monopolised. Software is monopolized primarily through regulated monopolies on software (re)production i.e. copyright. reply lostlogin 17 hours agorootparentprev> This is also a very rose colored look at unions, while simultaneously demonizing businesses. In reality it is completely possible to have an exploitive union. Have you got any examples of this? When I look at large unions where I am, it goes one of two ways. They get large and hopeless (teachers union and nurses union) or they get powerful enough that they can dictate such that they can make a meaningful change for their members. I’ve seen some impressive conditioned earned by doctors unions, police unions and one I belonged to for allied health professionals. None of them seem to be exoloiting their members, but I’m not sure how I’d find out about that. reply BurningFrog 17 hours agorootparentprevUnions are cartels of sellers of labor. If they're good or bad is another matter. reply mjburgess 17 hours agorootparentYeah, they can be, so its more vauge than i've made it out to be. The underlying problem is that employee-employer is individual-collective; so in some sense, there \"has\" to be a union option if this becomes too one sided. But a cartel is never required, since businesses competing with each other is the goal of a free market. I would agree that if unions become more powerful than businesses, so it ends up single-business vs \"union-of-unions\" you can get the same effects. Hopefully the asymmetry is clear though. Cartels are never permissible in a free market, but unions often are because of the need for labour to compete \"on the same terms\" as business. ie., the mere existence of a union isnt a sign the market is non-free; whereas the mere existence of a cartel is. reply avgcorrection 17 hours agorootparentprev> If they're good or bad is another matter. It’s pretty clear what you think though. reply Aurornis 17 hours agorootparentprevThe idea of industry-wide \"no-hire lists\" is a bogeyman that bad employers use to control young employees who don't yet know any better. At worst, you won't get a positive recommendation from an employer like this if somebody calls and asks. The idea that employers are busy maintaining \"no-hire lists\" and collecting names from all of their industry peers doesn't hold up, at least not outside of maybe weird small-town social bubbles. reply avgcorrection 16 hours agorootparentAh shame, shame, stupid low-experience employees just falling for some savvy bad-employer tricks. But it’s not like the small-town social bubble of West Coast software development is a stranger to collusion. What was that thing again? Apple and some other giant tech companies colluding on wages? Well, it was on HN a few times at least. I don’t remember the details. reply asadotzler 10 hours agorootparentprevNot true. I lived through the no-poaching agreements in Silicon Valley which is close and if that's not close enough for you, before that I worked in market research in Austin and we absolutely shared a no-hire list, and not just with our other branches, but among competing call centers. There were two other companies we regularly swapped low-skill call center workers with and the management teams of all three, I was on one, shared a list of disruptive and dangerous workers we'd had to fire and discouraged any of the three firms to hire. On our end, the list was in Lotus Notes and it was someone's job to make sure it integrated updates from the other call centers. That was the late 90s and the list sharing started in the late 80s before I got there but it was one of the thing you learned about when you got promoted to management, check the list before the interview! I started out on the phones and had many friends still on the floor when I got promoted, so learning about the list was a little bit disturbing, but the names I recognized on it from my time in our call center, had been escorted out by the police or carried out by EMTs. That firm was wild. We literally took on 20 guys from the child sexual abuse convict halfway house to work the phones. Only half made the cut after the trial period and only three of them stayed on more than a few months, and those three were quite good, one making the \"CEO\" team which was the highly capable group that could hold a CEO on the phone for a 45 minute interview about, for example, printers and multi-function devices conducted on behalf of Dell Computers to see if they were making any headway eating into HP printer sales or whatever. My point is that back in the '90s lists you say don't exist absolutely did. I not only knew of one, I used it, added to it, and I have every confidence that two other companies employing the same kind of people were using it as well. reply hobotime 17 hours agorootparentprevCan confirm. There's no \"no-hire lists\" in the heavy construction, restaurant, and IT companies that I've seen. However, in a small town, business owners may warn each other, and in a small bubble of companies, they may talk to each other. And if you need a reference, better pick a fellow employee. Other than that, ignore the boogeyman! reply asadotzler 10 hours agorootparentAustin TX was not a small town in the 90s and my company and two others who used the same kind of employees (call center workers) that were in slightly different industries (surveys, sales, political) regularly shared a list of workers we'd fired and we believed should not be hired. For my part, the fired workers that were added to the list had been escorted out by police or wheeled out by EMTs after causing property damage and physical harm to other employees. I didn't think much about it at the time. I was young and foolish and happy to have been promoted off the call center floor into management. I think the list had started a decade earlier for sharing across sister companies. My local company had been acquired by a larger foreign company which had several US subsidiaries in similar businesses, one of which was just the other side of the river from us. I think they first shared the list amongst themselves which despite them being different companies, is almost \"internal\", but eventually they started sharing it with another Austin business with a large call center over on Mopac that shared a bunch of workers across different shifts. They'd work for us during the day calling businesses and work theirs at night calling residential. Then a third company joined and I wouldn't be surprised if they shared it even more broadly after I left, but by then I suspect most of the phone workers in Austin were covered at that point. reply Lalabadie 18 hours agorootparentprevBut with enough lobbying, it _could_ be legal! (This to point out that most lobbies are to employers what unions are to employees) reply avgcorrection 18 hours agorootparentThey’re just voting with their (fat) wallets! reply joncrocks 18 hours agorootparentprevI think the word is Cartel. reply ToucanLoucan 18 hours agorootparentprevIf you want to demonstrate to someone why the legal system is designed for the wealthy and not the common people, I don't think you can do better than the entire subject of wage theft. Wage theft utterly eclipses every other form of larceny in the United States at least, and it is practically legal in every way apart from the letter of the law. Few companies ever see any consequences at all, and the few that do, it's fines here and there. No criminal liability. Certainly no SWAT teams raiding gated communities daily to haul off white collar criminals the way they'll roll out and obliterate an entire home (sometimes even the correct one) to catch someone selling weed. The societal impact of this crime cannot be overstated. Billions of dollars stolen from workers, practically free of consequence. reply TheCleric 17 hours agorootparentExactly. How many hand wringing articles have we seen in the past few years about roving bands of shoplifters vs how many about wage theft? reply hasty_pudding 18 hours agorootparentprevMost companies dont pay many taxes either. reply billy99k 17 hours agorootparentany proof of this? Every company I've worked for pays lots in taxes. reply Jensson 17 hours agorootparentprev> Wage theft utterly eclipses every other form of larceny in the United States at least If you define being late with payments as theft, then I'd bet that rent theft is way larger than wage theft. I don't see why you would say that it is theft when you are late with payments to a worker but not theft when you are late with payments to a company. If being late with payments isn't theft, then \"wage theft\" isn't theft, just like you missing to pay your rent one month isn't theft. reply analog31 16 hours agorootparentRent is a contractual obligation and the remedy for late payment is built into the contract. Hardly comparable. reply yardie 15 hours agorootparentprevConsidering most rentals require a first, last, and deposit there is no theft. There is only failure to meet the terms of the lease. reply uni_rule 17 hours agorootparentprev\"If this thing was an entirely different situation then the stakes would be different.\" Well, glad we got that part worked out. reply Jensson 17 hours agorootparentIt is the same situation, entity A didn't pay entity B the money they agreed to pay. reply ToucanLoucan 17 hours agorootparentEven looking past the time aspect which you slipped in (rent late, wages unpaid are definitionally different: unpaid is not, by necessity, late, and late is not necessarily \"never going to arrive\") wages are the payment of labor performed and rent is the payment of use of private property. Rent-seeking is derided behavior (by economists!) for this exact reason: A landlord does not (in the vast, vast, vast majority of cases) add value to a property: they merely own a thing, and charge people who need access to it, to access it. It's the free-market version of wind-drag: you aren't contributing anything, you're just taking a slice of production you haven't earned because you own a thing that's necessary for the larger system to operate. reply Jensson 16 hours agorootparent> rent late, wages unpaid Those two are the same, a person who is late would typically never pay if they didn't get threatening mail to \"remind\" them. reply ToucanLoucan 16 hours agorootparentCitation: Dude trust me Hot, hot, hot fucking garbage. When I was in college and broke, and struggled to make rent, I was KEENLY FUCKING AWARE I owed it. It was a fact that was on my mind 24 hours a day, including inducing stress nightmares about losing my place to live. Just absolute, 100%, shit from a bull's ass. Bullshit, you might say. I dunno where in the world you got this notion, but as someone who spent a youth in the poverty grinder, allow me to dispel you of it. Fuck no. Rent NEVER left my mind, even when it WAS paid. Making my rent payment every month was what kept me going to work when sick, what kept me at work when my boss treated me like shit, etc. etc. etc. This notion that people \"forget\" rent is some of the most ludicrous bullshit I've ever heard in my fucking life. I don't mean to personally attack, I don't know you, but I cannot fathom how you got this idea in your head if you've ever rented a place before that you had to personally pay for. reply Jensson 16 hours agorootparentYou don't think that the people who run companies that makes negative profits and thus can't pay workers since they lack the money doesn't feel the same? Just because some do that doesn't mean it is the norm. Edit: You see plenty of stories from company owners who worry if they can pay salaries next month and it is all they can think about, that is the kind of person you are calling a \"wage thief\" here, even though they just like you are just struggling and trying to make ends meet. reply FireBeyond 16 hours agorootparentIt's laughable that you think the only companies committing wage theft are those that are not profitable and are struggling to keep the lights on. And even if they are, remind me where your constitutional right to a profitable business is? If paying your workers means you can't keep the lights on, then you can't keep the lights on. Too many even in this situation think the answer is \"keep the lights on, before paying workers\". But highly profitable businesses (up to and including Apple) also commit wage theft. So please don't try to turn this into yet another \"poor small business owners\" trope. reply pertymcpert 15 hours agorootparentprevIf being late with payments was theft then by far, far the largest form of larceny would be B2B. Late payments from businesses to vendors eclipses late rent. That's why there's an entire industry built around collecting payments, called factoring companies. That's why there are people hired as credit controllers to chase late payments. Source: wife worked as a credit controller. reply MeImCounting 17 hours agorootparentprevTell me youve never worked in service industry without telling me youve never worked in the service industries. This isnt \"being late with payments\" that is as you have correctly pointed out, not theft. \"late\" implies that eventually the wages are in fact paid. This is not what people are talking about when they are talking about wage theft. reply Jensson 16 hours agorootparentTell me you have never rented out without telling me you have never rented out something. People refuse to pay rent all the time unless you start to threaten legal action over it. We call that late payment, but they would never pay unless you went after them, just like these companies. > This isnt \"being late with payments\" \"Being late with payments\" doesn't mean they are late, it means they haven't paid you yet. That is equivalent to wage theft, we just call it \"late\" to make it seem like a lesser evil, and \"theft\" when corporations do it to make it seem worse than it is. Of course some companies will never pay and will take you to court over it, but I don't see why you should lump all of that into a giant number alongside the very benign cases. reply MeImCounting 16 hours agorootparentI have actually worked in property management. It was incredibly educational. I learned a lot about how \"landlords\" are really the single greediest, laziest class of individuals one is ever likely to encounter. Eternally lamenting over how they're so under-appreciated and taken advantage of. There are always exceptions to any rule, sure but for the most part \"professional landlords\" are parasites. Anyway you clearly arent understanding the point here. If you rent an apartment and agreed to pay 3000 a month for it and instead only pay 2500 a month you would be taken to court and lose the case. If an employer did the same it would be \"a civil matter\" having seen this firsthand I can attest to the truth of this. reply Jensson 16 hours agorootparent> If you rent an apartment and agreed to pay 3000 a month for it and instead only pay 2500 a month you would be taken to court and lose the case. If an employer did the same it would be \"a civil matter\" having seen this firsthand I can attest to the truth of this. Both of those are decided in civil court, I don't see the difference. reply thebradbain 15 hours agorootparentPolice will forcefully evict you from a home. They will not guard the entrance to a restaurant and refuse entry to the owners until they pay their servers stolen wages/tips. reply ToucanLoucan 13 hours agorootparentprev> There are always exceptions to any rule We had what we thought were the dream landlords. They kept our rent low because we kept their property in good condition and we were tenants for literally a decade. I mowed both sides of the property, too, so they wouldn't need to service it. I replaced outlets, I was on-time with rent every single month. Then they wanted out of the business. We were harangued constantly by their real estate agent to arrange tours of the property, oftentimes without the requisite 24-hour notice by our states law. We had to allow strangers THROUGH OUR HOME routinely for a month. Then they sold the property, and the new owners increased rent by the maximum legal amount the next month, almost $400 at the time, fully intending to continue increasing it until it was at \"market rate\" which essentially doubled our rent over the course of the next few months. Thankfully my parents were in a particularly great position having had a windfall from a family member passing away, and they helped us a great deal in completing our savings for a down payment several years ahead of schedule, and helping us pay off some ancillary debt to give our credit score a shot in the arm. We managed to buy a home thanks to them and I will live in a fucking cardboard box before I kiss some landlord's ring again. Fuck em. reply ToucanLoucan 13 hours agorootparentprev> Tell me you have never rented out without telling me you have never rented out something. Ah. You're a landlord. That explains a lot. All the bemoaning and bitching I've ever heard from you lot has one answer: If it's so fucking bad, then sell your excess properties to people who actually want to live in them and leave the business. No one forced you to buy more housing/commercial space than you needed. You did that, because you wanted to profit from it while doing no work. In that lens, I hope it sucks for you. I hope you have problems every day from your tenants, from your buildings. I hope they hold you feet to the fire over every last problem they have with every ounce of legal leeway given them. I hope you're miserable. And I hope all of this because nobody made you get into that business and you're free to leave it at any time. reply castlecrasher2 17 hours agorootparentprevAgreed, and not sure why you're being downvoted for this. reply autoexec 15 hours agorootparentMaybe because if you redefine things that aren't theft as theft you can make any number of things more prevalent than wage theft, or maybe because it confused paying someone late with paying someone never, or maybe because it equated people who are unable to pay due to not having enough money for their basic needs with corporations who most often have plenty of money and assets but still refuse to pay their employees, or for any number of other reasons that it was a terrible argument. reply castlecrasher2 12 hours agorootparentI don't understand the chord this opinion strikes. Unless you're letting your personal bias get in the way, there's not a distinct difference between the two. reply autoexec 12 hours agorootparentIf you can't find a difference between the walmart employee late on rent because he doesn't have enough money to pay it until friday comes around, and walmart who has literal billions in profits, but has been repeatedly caught stealing money from workers you'd have to be keeping your eyes shut. Zero personal bias is required to see that those situations aren't even close the same thing. reply sixothree 14 hours agorootparentprevIf you're late with rent, the police will show up when called. reply madsbuch 17 hours agorootparentprev> > not only would they fire you but they'd call up all their industry buddies and you'd basically be on every other restaurants no-hire list. An interjection: Under GDPR this is illegal. (Just a reminder that \"tech\" legislation sometimes also improve on broader levels) reply dheera 16 hours agorootparentThe US isn't subject to GDPR. I see a lot of US websites with annoying GDPR popups and they really don't need to do that over here. reply autoexec 15 hours agorootparentThey don't need to do that over there either, unless they're doing something with cookies they don't need to be doing in the first place. reply Workaccount2 19 hours agoparentprevI working in restaurants for years. They purposely go for high school kids because they know they don't know the law, and know that they will think walking out with $50 is awesome, even if they worked 6 hours. reply BobaFloutist 18 hours agorootparentAnd then they get mad that the teenagers they made a point of hiring are irresponsible, unreliable, and have limited experience working. You know, teenagers. reply phpisthebest 17 hours agorootparentI started working at 16, at a walmart. I only called sick a handful of times, never was late, and did my job to the best of my ability. it is called work ethic. I started at $0.25 above minimum wage, as we given several raises, and position changes by the time I left at age 18, why because I was one of the most reliable teens they had, and they did not want me to go to another employer. Some parents instill work ethic in their children even teens, sadly we do not have many good parents these days it seems like and for the record, walmart never asked me and I never did work a single second off the clock... reply lostlogin 17 hours agorootparent> Some parents instill work ethic in their children even teens, sadly we do not have many good parents these days it seems like It turns out that there is a lot more to what makes a person than just the behaviour of their parents. reply BobaFloutist 14 hours agorootparentprevI think it's actually developmentally inappropriate for teenagers to have that level of work ethic. A teenager has far too many things on their plate at school to dedicate that much of their energy and motivation to Walmart, even ignoring the cost to their social and cognitive development. reply sixothree 13 hours agorootparentprevI don't see what you \"having responsibility\" has to do with taking advantage of children? Also I have to ask, and I mean this seriously. What did you do with the money from that job? Did it go into savings? Did you help with household bills? reply ChrisMarshallNY 17 hours agoparentprevRight after I finished tech school, and I was waiting for my first technician job, I worked for a friend's home remodeling contractor company for a few weeks. I was the \"helper,\" so, naturally, I got all the shit work. The wages were minimum wage. He kept jerking me around, paying fractions of what he owed me, then \"forgetting\" how much was left, etc. I probably ended up getting about a quarter or what I was owed. This was a \"friend\" (note the quotes). I can only imagine what happens with the contractors that hire laborers from the side of the street, in the local hispanic district. Those chaps don't have any recourse (Unless you count the local MS-13 chapter). I hear a lot of people tell me about the \"wait to clock in\" gig. Many of them \"help themselves\" to their employers' assets. I don't condone that, but I also don't condone their getting ripped off. Large-scale, white-collar employers probably reap billions from stolen wages. My first job was hourly, and I made a lot of money over my standard wages (it was actually an honest employer -defense contractor, so they were audited with a proctoscope). During my exempt career, I encountered all kinds of nickel-and-dime behavior. Those nickels and dimes add up to new Porsches in the driveways of senior managers. reply hobotime 17 hours agorootparentLaborers on the side are paid daily, unless a lot of trust has been built up. The most they'll be screwed is one day's labor. They're in demand because they work very hard, and they'll quickly find work. reply madsbuch 17 hours agoparentprevA danish labor union is currently suing for this. They have already settles on ~25.000 USD being paid out to one worker who was paid for 37 hours a week but according to his clocking in and out of the building area had worked up to 60 hours per week. This is exactly one of the key responsibilities for labour unions to manage this interest on behalf of their members. reply awo34oaw4u 15 hours agoparentprevAnd in academia. The University of Texas at Austin still owes me $14K in unpaid wages from 2017 where I was never paid for the classes I taught as a grad student. Unfortunately Texas has pathetically weak worker protections and the length of time you have to complain about wage theft is shorter than the length of time it takes the university to set up some payments, so by the time you realize you're not getting paid it's already too late to do anything about it. reply lupire 18 hours agoparentprevThe \"industry buddies\" but seems like a Boogeyman meant to scare people. reply eterm 18 hours agorootparentThat's exactly what it is, but the kids they employ don't know better. The idea that there's a cabal of restaurant owners who get together to discuss in detail how they're breaking the law and maintain a blacklist is absurd when you stop to think about it. But they're more than happy to let those kind of rumours keep doing the rounds to scare the naive young people into not sticking up for themselves. reply TheCleric 17 hours agorootparentI think there’s one way this might work. To get hired at the next place they might want you to have experience. So you put your prior employer on the application, the new restaurant checks your references and mysteriously decides to pass on you. reply tomatotomato37 18 hours agorootparentprevYeah the closest your going to get to a restaurant cabal are owners gossiping at the local wholesaler while waiting for their purchase to be processed, and even then there's a 50/50 chance a member of them is lying in order to bait a competitor into making a bad hire reply notdang 17 hours agorootparentprevIt might be funny, but in Mexico it's done differently. There are Whatsapp groups of HRs working in a particular group (tech, construction, etc.) where they communicate. Obviously they don't discuss the names openly but they do ask if someone is willing to give feedback on a candidate that worked at XY. reply 1234letshaveatw 18 hours agorootparentprevright, can you imagine some low level restaurant manager going over a list of potential hires that are still in high school with some managers from a couple of other restaurants? How many even bother to perform reference checks? It is a empty threat from a impotent person reply CityOfThrowaway 18 hours agorootparentprevYes, and in my experience the lore around both the vileness and power of the owner is fully invented by the staff. In many cases it's just teenagers being dramatic and coming up with external reasons why they are dealing with suboptimal conditions and not asking the owner about it. reply phone8675309 18 hours agorootparentprevAre you willing to risk extended unemployment and potentially homelessness in order to call that bluff? reply WillAdams 17 hours agorootparentprevWait until it's automated: https://marshallbrain.com/manna reply CalRobert 18 hours agoparentprevMaybe it's every industry. My wife was told she needed to be sitting at her desk ten minutes before clocking in when she worked at Accenture \"so the computer could warm up\" reply alkonaut 19 hours agoparentprevAn anonymous tip and a few inspections of staff logs and payrolls would make it pretty easy to make this disappear. The problem is that these sort of things (what regulations exist, whether authorities prioritize enforcing them) seems to always be answered with \"no, because it's a poor people problem\". It's unfair competition though, so it's really important that this doesn't happen. A restaurant that wants do to the right thing shouldn't have to worry about a few % worse competitiveness on wages because the asshat across the street has his staff work for free. If something like this earned you a $10k fee the first time and a 5 year ban from running any kind of business in the state if you repeat it, I'm sure it wouldn't be a problem. reply marcus0x62 19 hours agorootparent> An anonymous tip and a few inspections of staff logs and payrolls would make it pretty easy to make this disappear. And culturally treating it like any other theft: a crime that should subject the thief, in a practical sense, to the risk of imprisonment. reply pierat 19 hours agorootparentIn reality.... If you steal $100 worth of food from a store, they'll call the cops and arrest you. If the store steals wages from you in the tune of $1000+,its a.... CIVIL MATTER (waves hands). reply wahnfrieden 19 hours agorootparentWhich incident receives media coverage as it happens? reply commandlinefan 17 hours agorootparentI think you're getting the wrong takeaway from OP's comment... reply wahnfrieden 16 hours agorootparent? reply pierat 18 hours agorootparentprevGiven the breathless reporting of \"MAJOR CHAIN STORE SHUTS DOWN SINGLE BUSINESS DUE TO EXTREME THEFT\", yeah. https://www.pbs.org/newshour/show/as-retailers-close-stores-... https://www.npr.org/2023/09/28/1202264923/major-retailers-bl... https://www.cnbc.com/2023/12/19/target-store-closures-theft-... https://www.cbsnews.com/news/target-closing-stores-2023-san-... https://www.cnn.com/2023/09/26/business/target-retail-theft-... https://www.cbc.ca/news/business/target-stores-theft-1.69794... https://www.dailymail.co.uk/news/article-11965589/The-stores... ------------------------ However, on the actual wage theft side, is scattered articles about a single bad company, or policies from stuffy think tanks and \"boring\" and non-sensationalized sources. https://www.cohousedems.com/news/wage-theft-prevention-passe... https://www.dir.ca.gov/DIRNews/2024/2024-10.html https://www.propublica.org/article/wage-theft-law-new-york-v... https://blog.dol.gov/2024/02/07/protecting-workers-rights-at... https://calmatters.org/politics/capitol/2024/01/wage-theft-c... reply nullindividual 18 hours agorootparentThe Target store closings (in Seattle) were not due to violence/theft but rather a cost cutting measure; Target lied. https://www.cnbc.com/2023/12/19/target-store-closures-theft-... reply basil-rash 18 hours agorootparentThat article proves nothing of the sort. Shutting down stores that have too much theft is a cost cutting measure, and keeping stores open that have more theft but far more sales doesn’t invalidate it. reply sleepybrett 15 hours agorootparentI live two blocks from that store (the ballard one which was shut down). It was the worst targeted store i've ever seen. It was about 1/3 'groceries' while sitting within a block of two larger and cheaper grocery stores. All the stock that people would actually be interested in, home goods and the like (because the neighborhood lacks a store for that), were extremely thin on the shelves. Either because they didn't stock items are they were always sold out because they were meeting a neighborhood demand. Was there theft at that store.. I don't doubt it but never saw it in all the times i was in there searching, often without success, for some home item that would suit my place. It was just a bad target variant store that was plopped into the middle of a neighborhood that ended up being specialized in the wrong thing, if any target mucky muck had ever walked the neighborhood before putting the store in it could have been very successful (because we could really use a store where I can buy various home goods without jumping in my car and driving 10-15m). reply basil-rash 14 hours agorootparentI lived in 65th for the first half of COVID, so I want to that Target moderately regularly. Yes Ballard Market had better groceries (among the best in Seattle actually), but I’ve never seen Target as a grocery store. For the home goods we needed it was adequate, though my roommates Amazon subscription had to fill in some gaps. To your point about it not having the items you needed, I wouldn’t be inclined to separate that from the theft problem. If your stuff keeps getting stolen, you’ll be inclined to stock less stuff, especially if you don’t have sufficient sales to afford retrofitting locking cabinets everywhere and staffing sufficient to tend to them all. reply sleepybrett 11 hours agorootparentI'm not sure people are stealing a lot of shower caddies or little office/bathroom garbage cans... reply mrguyorama 17 hours agorootparentprevThe entire \"Theft is driving up prices\" narrative was bullshit. The national retail federation, the very group that is the lobbying voice of the retail industry, found that a majority of retail stores complained about theft, but if you look at the reported shrink numbers, they have been the same for 30 years. There has not been widespread increase in theft, by their own numbers. reply UncleMeat 17 hours agorootparentprevIt gets even worse than just the media. A bunch of legislation has been proposed or passed specifically to target \"organized retail theft.\" In Virginia, legislation upped the designation for \"stealing several thousand dollars of stuff with other people\" to the same felony category as stabbing somebody while jack shit is done to crack down on wage theft. reply wahnfrieden 16 hours agorootparentIf people don't care about the $ severity of the crime, what is it they care about to keep this going as it does? reply phone8675309 16 hours agorootparentprev> If you steal $100 worth of food from a store, they'll call the cops and arrest you. And if you're a person of color, if you try to pass a counterfeit $20 bill (unclear if you even know it's counterfeit) then the police just murder you and the person in charge of it gets a cheesecake sentence reply cscurmudgeon 18 hours agorootparentprevNah. No one will get arrested for even stealing $1000s of dollars of luxury items on camera (at least in CA, a trend setter for other states). https://amhsnews.org/10386/justice-awareness/shoplifting-the... > On September 30th, 2023, Governor Newsom signed into law Senate Bill No. 553, essentially making it illegal for retail workers to confront looters, burglars, and shoplifters. > A Walgreens employee working in San Francisco told a reporter that thieves come around 15-20 times per day > any theft under $950 is only considered a misdemeanor, which means it doesn’t lead to anything punitive by law Edit: Present data countering the virtue signaling and get downvoted. Keep it up folks. reply supertimor 14 hours agorootparentGod, this is such a tired take. I see it all the time, usually referencing how California is weak on crime, yada yada yada. California, in fact, has one of the lowest felony theft thresholds out of any of the states. In fact, it has the 10th lowest felony threshold in the union. [1] It was actually Oklahoma who started the trend to increase the felony threshold in the early 2000s. Newsom passed the bill you referenced so that minimum wage workers aren’t playing security for their employers. This bill did not raise the felony threshold. Do you want to know which states have the highest felony theft thresholds? It’s Texas and Wisconsin at $2500. In 2010, California went from a threshold of $400 to $950. In 2015, Texas went from a threshold of $1500 to $2500, so California’s threshold has always been much lower even in the recent past. [2] So no, California has not actually been any sort of trendsetter when it comes to felony theft thresholds, but it certainly is a convenient bogeyman. [1] https://worldpopulationreview.com/state-rankings/felony-thef... [2] https://www.pewtrusts.org/en/research-and-analysis/issue-bri... reply pierat 18 hours agorootparentprevHell, I worked at $retailer for a time, and even their statements were to \"DO NOT ENGAGE SHOPLIFTERS\". Worse yet, I can scarcely imagine some $12/hr being told to chase after shoplifters... That's gonna end up being shot or shivved. And frankly, there were times in which I saw people steal food. And in those cases, I never saw a thing! Especially when formula was being \"acquired\". One time, during Black Friday, someone stole a whole register full of cash. Again, not my job and not my problem. reply TheCleric 17 hours agorootparentThat’s because it’s a liability issue. Better to let someone steal a $100 item than get sued for $1000000 because an employee chased them into the parking lot and got stabbed. reply cscurmudgeon 18 hours agorootparentprevYou do realize that people who steal formula use it to cut drugs? https://city-attorney.columbus.gov/pdf/press/babyformulaband... There are a lot of organizations that give out formula for free but not at scale required for nefarious uses. reply amrocha 17 hours agorootparentLook yourself in the mirror and tell yourself you honestly believe drug dealers are stealing formula to cut drugs with rather than mom's just need to feed their babies reply wahnfrieden 16 hours agorootparenta lot of stolen inventory is resold for money but it's then in turn sold to moms on street markets (or sometimes back to unscrupulous store owners at a discount off wholesale to resell, sometimes via a proxy reseller). so you may be unhappy with who profits in various ways but it's evidently going to moms one way or the other reply cscurmudgeon 17 hours agorootparentprevMaybe you should stop looking at yourself in the mirror and look at the data? As a parent, I feel people like you are the reason formula ends up being unavailable for real babies as you enable gangs to steal them driving up cost. Here is a list of places with free baby formula and stuff in the Bay Area: https://www.211bayarea.org/sanfrancisco/food/food-programs/f... https://www.findhelp.org/goods/diapers-%26-formula--san-jose... https://www.needhelppayingbills.com/html/san_francisco_and_s... One advice: Stop with harmful virtue signaling. It is easy to virtue signal like you do here with looking at any data or bearing any of the real cost of virtue signaling. I will repeat. People like you are the reason formula ends up being unavailable for real babies as you enable gangs to steal them driving up cost and causing shortages during real crises. As a parent this is frustrating and rage inducing. https://www.cdc.gov/nutrition/infantandtoddlernutrition/form... reply phone8675309 16 hours agorootparentHow about we both: 1) Support low income people by giving them formula if they need it, AND 2) End the war on drugs and move people into treatment instead of the carceral slave system Sounds like a win-win. reply kcatskcolbdi 15 hours agorootparentprev>As a parent, I feel people like you are the reason... You must have missed the part of the post where they stated: >I worked at $retailer for a time, and even their statements were to \"DO NOT ENGAGE SHOPLIFTERS\". \"People like [them]\" are being told from their employers to not engage shoplifters. reply Spivak 17 hours agorootparentprevI feel like that is the least committal press release that could exist about this topic. The police might be correct but the facts described aren't as clear cut as they're making it. > Wilson has a history of drug offenses: felony drug abuse, felony possession of cocaine, and possession of drug paraphernalia. \"Offenses\" is carrying the whole team here. All this says is that he was charged with the crime of doing drugs while black. I could have been arrested for all of these at one time in my life or another. Without a trafficking charge they're just speculating he might be a dealer. > While a black market exists for stolen baby formula to be resold for its intended purpose, reports indicate that baby formula also is used as a cutting agent for cocaine, heroin, and methamphetamine by drug dealers looking to dilute their product and stretch their supply. So he could be cutting drugs with it, or he could just be stealing it to sell directly. He even could even be selling it to actual drug dealers. Not saying that's better but the police kinda gloss over that as presented that's the more likely option. I promise I'm not trying to drag you or anything but I'm originally from Columbus and you have to take anything the CPD says with a shaker of salt. Columbus is a fairly boring city and so CPD always tries to punch up the stories. reply willcipriano 18 hours agorootparentprevLow income mothers can get formula from the government. https://www.fns.usda.gov/wic It was probably all theft to exchange for drugs. During the pandemic there was a formula shortage and allowing theft rather than punishing it probably ensured some children went without unnecessarily. reply pierat 17 hours agorootparentAny means testing (and I do mean ANY) will always exclude people who have an actual need who'll never be able to get. And really, if 1 out of a thousand \"cuts drugs\" with formula, so be it. At least that's non-toxic... and frankly, laughable as DARE propaganda. reply willcipriano 14 hours agorootparentHalf of infants born in the US receive WIC. Can't be that hard. reply cscurmudgeon 17 hours agorootparentprevHere is a list of places with free baby formula and stuff in the Bay Area most without means testing: https://www.211bayarea.org/sanfrancisco/food/food-programs/f... https://www.needhelppayingbills.com/html/san_francisco_and_s... Just recently there was a baby formula shortage. And we were not prosecuting gangs stealing formula. Shameless and laughable. https://www.cdc.gov/nutrition/infantandtoddlernutrition/form... Edit: To person calling me a techbro below, I can't provide data for 1000s of cities in the US, genius. Feel free to do so. Non tech folks also live in the US (you would know if you live in the US). Also look up why we are discussing the Bay Area. reply pierat 17 hours agorootparentThe Bay Area is not the USA, techbro. reply cscurmudgeon 16 hours agorootparentI can't provide data for 1000s of cities in the US, genius. Feel free to do so. You provide data for zero other parts of the US. Non tech folks also live in the US (you would know if you live in the US). Also look up why we are discussing the Bay Area. reply sneak 19 hours agorootparentprevProperty crimes are rarely enforced against the ownership class. Law enforcement in the US exists to enforce the social order and class structure; they have no legal obligation to investigate or prosecute crimes. The system is working as intended. reply baq 18 hours agorootparentAlways has been. Government is quite literally a criminal organization except it was decided by someone (people, representatives, a monarch, whatever) that this particular one is not criminal and any others like it are, within self-described boundaries. It might or might not be doing criminal things (as in, things we associate with criminal), but it wants and needs a monopoly on those things, otherwise it risks dissolution by internal and/or external forces. It’s thus obvious it’ll prioritize protecting the mafia bosses/sovereigns/elites and thugs/enforcers. reply marcus0x62 19 hours agorootparentprevThat's why I described it as a cultural, not a legal problem. reply worsethanthat 18 hours agorootparentprev> The problem is that these sort of things[...] seems to always be answered with \"no, because it's a poor people problem\". It's not just that. There are people that will outright deny that it's happening. The reasoning trotted out is that if it were true that this were happening then it would be squashed. In other words, if it were happening, then it would not be happening. From the article: > According to a 2018 report by Good Jobs, between January 2000 to 2018, Walmart paid over $1.4bn in fines and settlements over wage theft violations, FedEx paid over $500m during the same period, and Bank of America paid over $380m. Sans data about Walmart's $1.4bn in fines, they'll reason to themselves that Walmart, even if it's not somewhere they personally would ever shop, is a reputable company, therefore this isn't something that happens at Walmart. I have experience firsthand (from a low spot in my life) that FedEx continues to do the same thing, especially to people who are powerless to do anything about it. To wit: Their warehouse workers get paid low wages and the arrangement is that you need to be available between 4:00 AM and ~10:30. It's not that you'll be working during those hours. No, instead what happens is the night before they determine how high of a load they have and then set the hours for that time. So you as a worker call in at around 9:00 PM the night before, listen to a recorded message that states e.g. \"On Tuesday, February 13, package sorters will begin work at 5:30\". So far not so good, but there's nothing especially illegal about this is as far as I know. (It stretches morality and ethics, however.) What is illegal as I understand it is incidents where they tell you to report to work at that time, people show up, and then find that the timeclocks are papered over with a sign saying not to clock in because there was an issue at the warehouse overnight and the systems aren't running, so they've moved the clock-in time ahead 45 minutes to when they expect the systems to be up and running. You are expected to wait there off the clock despite not being paid and being expected not to leave. reply pixl97 18 hours agorootparent> if it were happening, then it would not be happening. Note that this is US law enforcement in general. The \"if middle america were using drugs at the same rate of inner cities then we'd see arrest rates at the same levels\" argument we here. While studies show that drug use is similar between these groups, enforcement in cities, specifically against minority groups is much higher. reply plasticchris 15 hours agorootparentIndeed the overdose data seems to indicate a worse problem in rural areas, with West Virginia topping the per capita OD rate: https://www.cdc.gov/nchs/pressroom/sosmap/drug_poisoning_mor... reply nickpsecurity 16 hours agorootparentprev“Their warehouse workers get paid low wages and the arrangement is that you need to be available between 4:00 AM and ~10:30. It's not that you'll be working during those hours. No, instead what happens is the night before they determine how high of a load they have and then set the hours for that time. ” One of my buddies said they did this to them. I don’t know how common it is but it does happen. They were satisfied with their pay, though, compared to what many jobs in the area offered. reply avgcorrection 19 hours agorootparentprev> It's unfair competition though, so it's really important that this doesn't happen. A restaurant that wants do to the right thing shouldn't have to worry about a few % worse competitiveness on wages because the asshat across the street has his staff work for free. The true crime is as always the impact on businesses. reply vundercind 18 hours agorootparentI think it’s worth calling out that failing to enforce regulations corrodes entire industries to the point that it’s impossible to compete in many sectors of it without breaking the law and screwing over workers (and maybe also customers!) It’s a way in which this is bad that folks may not immediately connect to it. reply RHSeeger 17 hours agorootparentprev> The true crime is as always the impact on businesses It's hard to tell if you meant this as sarcasm or not, but... it really is a big deal. If all your competitors are screwing their employees in order to increase their margins, that means they can out-compete your on price. Which means you can either screw _your_ employees.. or risk going out of business. And eventually, the only players left are the ones that are screwing their employees. So yes, if you want to look out for employees, then you need to look out for businesses by making sure everyone is following the same rules. That doesn't mean the businesses themselves are more important, just that their health is vital to the well-being of the employees. reply avgcorrection 16 hours agorootparentI’m absolutely being sarcastic. The context is that the OP complained about one business colluding with others by way of informal no-hire lists for employees that don’t tolerate this wage theft. The response to that is to focus on how other businesses that don’t collude will get out-competed… And yeah I’m pretty sick of this framing. It’s an anecdote where employees are direct victims, and then the focus gets shifted to hypothetical and indirect victims (businesses). Even in my own social democratic place of residence there seems to be dominant narrative of “job creators” and how we need to “create jobs”, the outcome of which is to sacrifice things in order to directly benefit businesses in order to (ostensibly, in rhetoric) benefit workers. This was concretely demonstrated when, during the pandemic, the right-wing government was very insistent on giving handouts to failing businesses that obviously were going to have a hard time (like the travel industry) under the guise of “protecting jobs”. Meanwhile, the government proposed that we should temporarily make it easier for employers to put employees on temporary leave (whatever the English/American term is) in order for them to not just die. Which is fine in itself… except they wanted tax payers and workers to dis-proportionally pay for this temporary measure. What’s the only thing that made them “change their minds”? Labor groups and other such organizations. And then there was inflation, a predictable outcome of the spending-spree during the pandemic. So the central bank raised the rent. And again. And again. And the acknowledged consequence of that was that the poorest among us would struggle to make ends meet. But that’s not a problem at all—that a predictable outcome of a previous spending spree on businesses would impact regular people and make some people have to choose between mortgage/rent or food; not a problem. That’s just Economics. What’s the problem with corrupt politicians? On one hand you can simply say that the problem is that corrupt politicians corrupt the political system. On the other hand you can frame it as the outing of corrupt politicians causes “political distrust” and a “crisis of legitimacy” among the (stupid) voters. So you re-frame the issue as a few bad apples (politicians) which causes the real problem of voters/regular people becoming (justifiably) cynical and distrustful of the whole system. That’s the power of framing. And that’s why I don’t buy into the framing of helping businesses in order to (pinky swear) really helping workers. Yeah, those hand-out to businesses? Oh would you look at that—a “profit party” half a year later for the shareholders. Who woulda thunk it. But too bad about that inflation, though. Guess you should rethink owning a car or having hobbies other than taking walks in the park. reply RHSeeger 12 hours agorootparent> And yeah I’m pretty sick of this framing. It’s an anecdote where employees are direct victims, and then the focus gets shifted to hypothetical and indirect victims (businesses). No, the focus gets shifted to > We need to make sure that businesses that _do_ treat their employees well are able to succeed. And, to do that, we make sure that treating their employees well isn't turned into a penalty. We make sure that all companies are playing by the same rules. The thread went like this >>> Businesses should not be able to steal wages from their employees, and we should punish them harshly >> Yes, if businesses can get away with that, then the ones that treat workers well will go out of business > (you) Stop making this about the business being a victim here Seriously, what the heck. Everything about that bit of the thread was about making sure it's better for businesses to treat employees well. reply lupire 18 hours agorootparentprevThe Honest Employers Guild should sponsor investigations and lawsuits against the criminals to drive them out of business, like that company that buys anti-Tesla Super Bowl ads. reply empyrrhicist 16 hours agoparentprevSimilarly, I worked for a restaurant in high school that abused tips to pay wages for non-servers. When I was hired I asked about tips, and was told \"yep, you get tip share\". It turns out \"tip share\" meant \"you get a flat wage, and we pay for it using tips from the servers\". I turned down a job at a nice Italian place to work there because of that lie and a $1 difference per hour in the base wage. reply mcv 17 hours agoparentprevI honestly think managers responsible for this sort of thing should go to prison for it. That would end these sort of practices really quick. But somehow companies seem to have more rights than people. reply IG_Semmelweiss 12 hours agoparentprevi think you are underestimating how competitive businesses are - someone knowing that a competitor is exploiting an illegal advantage , has all the incentive in the world to report that illegal business practice and shame that competitor. You have to be operating in a very narrow niche or a very small community for illegal behavior to be the norm. what most employees don't know is that this type of theft is often a smokescreen for theft by a manager or someone below ownership. mention to owner anonymously, if no action, report the business that does this to you, put it on yelp, and move on. reply havblue 17 hours agoparentprevThis is more of a shade of gray, but I think over-assigning side work is also a form of unpaid labor that managers allow to happen to their front house staff as well. reply antisthenes 19 hours agoparentprevAmazing pettiness from the owners for what is essentially $10 worth of labor (or less) reply spacecadet 19 hours agorootparentThis sums up much of american rural small business... I started working at 12 and had many random jobs between 12-18 that were run by awful people. Our family has a small farm, my parents didn't think we did enough of that and put me in a white van full of migrant workers at 12 years old (hey the 80s!) to go pick produce in a field all day... It was grueling work but I got a first hand account of migrant farm workers and the way they are treated. reply vdaea 19 hours agorootparentnext [21 more] [flagged] Cheer2171 18 hours agorootparentThis logic validates any horrific human rights abuse, just as long as that abuse is an epsilon less horrific than what is happening elsewhere. reply yareal 19 hours agorootparentprevThat shouldn't be the bar. \"Brutal but better than where you came from.\" Should still be unacceptable. Work should afford someone dignity and fair compensation, not simply be better than the worst conditions the worker has dealt with. reply Cthulhu_ 19 hours agorootparentprevThis is a really shitty take. I don't think you're a decent person if that's how you truly feel. reply brvsft 19 hours agorootparentnext [6 more] [flagged] kjkjadksj 18 hours agorootparentThe conditions are very unsafe. Commercial farming has terrible air quality. Farmers have significantly higher rates of cancers including lung cancer. There is no one inspecting workplace conditions when you are hiring undocumented workers. Every bad heatwave in the southwest you hear sad stories of people in fields dying of heat exhaustion because their supervisors provide no shade for breaks or water stations. There are no standards federally even for what might be sufficient despite the massive rates of heat related deaths experienced by farm workers relative to the general population. reply Cheer2171 18 hours agorootparentprevWhat about the topic of this thread: wage theft? Should migrants have less rights to the product of their own labor not being stolen than citizens, just because they are not citizens? reply brvsft 18 hours agorootparentWhat is your point? Wage theft occurs regardless of migrant status. Why are you asking me to be responsible for the tangential discussion, that I did not start, on migrant status? Or are you going to post this exact same question to everyone up the chain including people you already agree with? reply 2024throwaway 18 hours agorootparentprevSounds a lot like an abuser saying “as long as there are no visible bruises, they’re fine”. Except way worse because you’re fine with bruises apparently. Death is where you draw the line. Disgusting. reply brvsft 15 hours agorootparentHahaha. reply wahnfrieden 19 hours agorootparentprev> Since the implementation of the ‘Remain in Mexico’ policy in 2019 and Title 42 in 2020, asylum seekers sent to Mexico have experienced kidnapping, rape, extortion, and other abuses by organized crime and Mexican officials. > When the United States sends migrants to Mexico, criminal cartels are enriched by kidnapping them and then extorting money from their US-based family members to secure their release. Just to comment on what your \"good option\" means for many. Maybe you meant the option is good for the US and employers, rather than for the migrant worker reply brvsft 18 hours agorootparentHow is the US responsible for Mexicans raping other Mexicans? Is it our responsibility to stop all bad things from happening or just those that happen in Mexico? Should we have a police force on Mexican soil? reply Cheer2171 18 hours agorootparentBecause they are not from Mexico, they are from elsewhere. They applied for asylum in the US, and that policy had US immigration agents force them to go to Mexico to wait years for an asylum hearing. reply lupire 18 hours agorootparentprevI can't see \"US\" and \"Mexico\" from space. Mexicans are US Americans human neighbors. reply brvsft 18 hours agorootparent> I can't see \"US\" and \"Mexico\" from space. You are speaking with an adult. These arguments do not work on me. I pay income tax to the US, not Mexico, and if I don't, the US throws me in a real prison cell. Countries are very real to me. reply themaninthedark 17 hours agorootparentprevOut of curiosity, what would your response be if Putin said \"I can't see Russia and Ukraine from space, I am just providing security support for my human neighbors\" reply wahnfrieden 17 hours agorootparentOnes talking about asylum, you’re talking about bombing campaigns reply BobaFloutist 18 hours agorootparentprev> How is the US responsible for Mexicans raping other Mexicans? ...Because we're all human beings? reply vdaea 18 hours agorootparentprevThat's a shame but I don't see how that's the US responsibility. This seems like a call for imperialism more than anything else. Let Mexico govern themselves please. reply badcppdev 18 hours agorootparentIt's a human responsibility to not steal from someone whatever the circumstances. And a human responsibility to not exploit people running away from a violent dangerous environment. If you only care about people with a certain piece of paper then it says something about your total lack of ethics and human compassion. reply themaninthedark 17 hours agorootparentHow far does this human responsibility extend? I agree don't steal and let's prosecute those who do. What about those in Mexico that steal from the the people who are fleeing violence? Why stop there, how about we do something about the violent dangerous environment? Would you support military action in Mexico and South America to try and fix the problems? reply wahnfrieden 17 hours agorootparentHow much do you understand about US state involvement with cartels? That’s a lot of optimism placed in bombs reply rightbyte 19 hours agorootparentprevI think some managers use petty potential conflicts to filter out people that are not naive, have a backbone or are not desperate enough to succumb. A worker that does not put up with petty BS is surely less likely to put up with major BS (like wrongful termination when getting pregnant or whatever). reply admissionsguy 19 hours agorootparentprevIt adds up. Multiply by the number of employees by the number of weeks in a year by the number of restaurants owned by the total number of ways in which the employees are deprived of small amounts at a time. reply sneak 19 hours agorootparentprev$10/week/employee adds up over decades. reply Cthulhu_ 19 hours agorootparentBut is it worth the resentment from said employees? Having to deal with the revolving door of naive new staff that needs to be trained, get up to speed, then leaves again when they realize they're being stiffed or they can do better? It just doesn't feel sustainable. Not to mention the chance that you'll be found out by the authorities; I want to believe the punishment for wage theft is much more than the savings. Of course, that depends on how many people report it and how much evidence can be retrieved I suppose. reply wahnfrieden 18 hours agorootparentIt's worth it to the tune of $50 billion per year with only $3 billion recovered reply antisthenes 13 hours agorootparentIt sounds like a lot, until you realize it's only roughly $30 per year per employee in the US (roughly). There's no justification in being shitty to your fellow citizen over this paltry sum of money. None. reply antisthenes 13 hours agorootparentprevIt really doesn't. Can't buy your way out moral bankruptcy with $10,400 over 2 decades. reply droopyEyelids 17 hours agoparentprevI also experienced wage theft while waiting tables, and also thought 'thats just how it works' As a server, aside from taking orders and carrying food, we had 'sidework' before and after our shift- stuff like cutting lemons into wedges for water, rolling silverware in napkins, refilling condiments, etc. That all needed to be done before/after clocking in. Additionally, if diners stayed late, our timecards were edited to reflect the hours we 'should have' been working. And the last thing that bugs me the most, is that we were required to give 10% of our tips to share with the back-of-house employees like bus boys. The manager collected this money directly and there was no accounting or way to see how much of it actually made its way to the other employees. That pisses me off the most because it was so arbitrary and so completely in the control of someone who was already stealing from us. reply RHSeeger 17 hours agorootparent> we were required to give 10% of our tips to share with the back-of-house employees like bus boys The places I worked - busboys were not back-of-house employees; they were out on the floor helping take care of tables (bussing them, refilling coffee, making deserts, etc). - the wait staff gave the 10% (or whatever it was) directly to the busboys. And some to the hostess, and some to the bartender; basically all the client facing staff. I have no memory of the owners doing anything dishonest to the staff (at any of the places I worked), so either I was blind to things, or there _are_ (were) some good ones out there. reply andrewoneone 18 hours agoparentprevI worked at Texas Roadhouse as a kid and this was the norm even for a chain. reply Chris2048 19 hours agoparentprev> not only would they fire you If they did so could you not bring up the suspicious timing with the labour board? reply cool_dude85 19 hours agorootparentObviously every state is different, and all state labor departments do surely go after wage theft to some extent. But as an example, my state does not have a \"department of labor\" - too commie! Instead it's the Department of Economic Opportunity. So one might imagine how much effort they put into small-time wage disputes. reply bena 18 hours agoparentprevThis is tangential, but part of the reason why I dislike talking to servers about the tipped minimum wage. Because it seems they deliberately don't want to understand the full context of the law. Or fully the type of work they are in. What you are describing is typically called \"side work\". Basically work that is not directly related to waiting a table. Folding napkins, putting up chairs, moving tables, etc. Even in cases where the restaurant clocks in their workers for every minute they are doing work, servers complain about doing side work because \"it costs them money\". And they want the federal minimum wage during that time. Which naively makes sense. But that's not at all how tipped wages work under the law. The formula is basically: (([hours worked] * [tipped minimum wage]) + [tips earned in pay period]) / [hours worked] = [hourly wage over pay period] So if you work 10 hours in a pay period, that's $21.30. If you collected $51.20 in tips during that time, you made $72.50 or $7.25/hr (based on current federal minimum wage, obviously numbers are different for different areas where the minimum wage is different from the federal). The restaurant is in the clear. Even if you worked 5 hours doing \"side work\" and 5 hours waiting tables where you got $51.20 in tips. Servers want to essentially prorate every minute they are not physically collecting a tip it seems. Worked an hour and every table stiffed you? They want $7.25 for that hour. Regardless of the fact that the previous hour they took in $20 in tips. Serving is more akin to being an independent contractor. You need to make hay while the sun is shining. The fat sustains you through the lean. You look at your per hour over the aggregate, not counting every hour. It's why contractors charge the rates they charge. If you are only billing half the year, those billings need to support you through the other half. Now, in your case, the reason they don't want you to clock in isn't to save $7 over a week. It's to up your average. Which is still wrong. Let's say at your current rate of collecting tips, you totaled $225 over 30 hours. That's $7.50. Restaurant doesn't owe you anything. Now, $225 over 32.5 hours (your low end over 5 days), that's only $6.92 / hour. The restaurant is short, not $7, but $41.28 And true, If you instead made $300 over those 30 hours, the extra 2.5 hours don't even matter to you. Your check wouldn't have been that different. But, it's money that's not coming from their pockets and it's really to push people near the bubble over their limit. reply jpalawaga 18 hours agorootparentIn the state of California, tips are a gratuity paid on top of minimum wage. This is also how it works in many other states, in Canada, and in many countries around the world. So you earn $16/hr for all time you’re at work, plus tips. Which is how it should be. You’re being employed. Those tips are for the employee, not a gratuity for the owner to offset their costs. “Tipped wages” are just another form of theft, bought by the restaurant lobby. reply RHSeeger 17 hours agorootparent> In the state of California, tips are a gratuity paid on top of minimum wage. This is also how it works in many other states, in Canada, and in many countries around the world. > So you earn $16/hr for all time you’re at work, plus tips. This is not true. According to California Waitress & Bartender Minimum Wage Laws California Tipped Minimum Wage Laws for 2023, 2024 [1], > California labor law allows tipped employees to be paid a lower cash wage than the standard California minimum wage by their employers, with different allowed tip credits applying to different classes of employer. That lower amount is $11 or $12 per hour, depending on the size of the company (vs the normal $16/hour rate for non-tipped employees). The numbers are lower for most (all?) of the rest of the country. [1] https://www.minimum-wage.org/california/tipped-employee-mini... reply pixl97 18 hours agorootparentprevNo, this entire you're working for $2 an hour and hoping to earn tips shit needs to end. >They want $7.25 for that hour. Regardless of the fact that the previous hour they took in $20 in tips. Good. It is the companies job to pay the minimum wage rate per hour regardless of weather customer come in or not. If the restaurant industry cannot survive this they have no legal right to slave wages to survive. reply reaperman 17 hours agorootparentThey do have a \"legal\" and ethical right federally in the USA (some smaller jurisdictions have stronger rules but that's not typical). But perhaps you mean to argue they shouldn't have a legal right, or don't have a \"moral\" right. I have worked restaurants and believe that minimum wage should be meted out on a per-hour basis because of the way the current system mis-aligns incentives. The restaurant owner is encouraged to keep the restaurant open much later than \"profitable\" hours because the cost of the additional late-night hours is only $2.13/hour per employee. So if even one table comes in during the 11PM to 1AM hours, that breaks even for the business. The business owner benefits from externalizing the true cost of staying open for those hours onto the employees. The workers end up working a lot of no-profit hours. If they were making $7.25/hr then the incentives would be (more) aligned for them to keep working those hours. But currently this is NOT a legal requirement. So your statement \"they have no legal right to slave wages to survive\" drips with hyperbole. reply lotsofpulp 17 hours agorootparent> But currently this is NOT a legal requirement It is in California, Oregon, and Washington. And probably a few other places in the US. reply bena 17 hours agorootparentprevnext [2 more] [flagged] reaperman 17 hours agorootparentnext [2 more] [flagged] bena 15 hours agorootparentThen fair enough. However, there's no shame in the actual hustle. But that is what's happening in the tipping system. I'm not trying to start a flamewar. Accusing others of that is just as intellectually dishonest as you think I was. And inflammatory in and of itself. As to \"you can believe what you want, but you're just wrong\", is the belief that the incentives are misaligned. The cost to keep the kitchen open is prohibitive enough to not do it for the random straggler. You need better than half a customer an hour. Servers do not want tipping to end. They want to be tipped and to be prorated when they're not actively tipped. They want it both ways. reply charcircuit 15 hours agoparentprev>I think it only ended up costing me $7/week in wages - but if I stole $7 out of the till each week for a year in a half I'd be charged with a felony. These are not comparable as working an extra 15 minutes is a consensual tranaction where getting $7 stolen from the business was an unconsensual transaction. A better comparison would be along for a $7 per week raise. reply riversflow 15 hours agorootparentIt's not really consent if you are being coerced by your employer. reply dbingham 19 hours agoprevOne of the clearest illustrations of the deeply injust structural power imbalance at the heart of our economic system is wage theft. If your employer withholds $20 from your paycheck it's a civil violation of contract law. You have to go through an extremely onerous and convoluted process that very likely won't go anywhere. If, in response, you decide to pay yourself by taking $20 from the till, that's criminal theft. You will be arrested by the police, sent to jail, and charged in the criminal justice system. reply crazygringo 17 hours agoparentTo be fair, it also works the other way -- If you withhold $20 from a bill payment, the worst that happens is collections. The company has to go through an extremely onerous and convoluted process that very likely won't go anywhere. If, in response, a company employee decides to settle the bill themselves by visiting your home and stealing $20 from your wallet, that's criminal theft. They will be arrested by the police, sent to jail, and charged in the criminal justice system. In the end, the imbalance isn't fundamentally one between employers and employees -- it's the fact that stealing is a very different situation than not paying money owed. Of course it does benefit employers in the end, since they get to receive work now and pay later. Which makes you wonder why it's never become a thing for workers to receive their daily/weekly/biweekly wages or salary at the start of the period? In which case any wage theft would come from quitting the job before the end of the period. reply remram 14 hours agorootparent> the worst that happens is collections > (...) by visiting your home and stealing $20 from your wallet You are being dishonest here. Here's my version: If you withhold $20 from a bill payment, the worst that can happen is having to pay an extra fee, getting a utility shut off, and a permanent hit to your credit score. If you charge a customer an extra \"service improvement fee\" or \"credit card surcharge\" or a $400 \"Mod Seq Other Qhp\" (an actual line from a bill I have in front of me), they'll have to pay it. reply crazygringo 14 hours agorootparent> You are being dishonest here. That's entirely uncalled for. My point was clear and, yes, honest. Obviously there are additional complications in both directions. Yes, if you don't pay your electric bill of course it will eventually get shut off. But if an employer stops paying their employees they eventually quit. If you're late in paying there may be a fine. Courts also fine employers punitive amounts for non-payment of wages. The situations aren't identical but my point stands that debt and stealing are different concepts and can go in both directions. And random line items added to a bill have nothing to do with this conversation. reply remram 13 hours agorootparentYour comparison added breaking and entering! > And random line items added to a bill have nothing to do with this conversation Doesn't it? I'm sure employers withholding wages have some sort of itemized justification too. reply crazygringo 13 hours agorootparentFine, they pickpocket you for $20 in the park. You're focusing on the wrong detail. My overall point is clear. You're wrong to say I'm being dishonest -- I was obviously trying to draw an equivalence. Pickpocketing is a better example, but I think my intention was clear. reply wahnfrieden 17 hours agorootparentprevBecause business owners and politicians working for the economy decide that. It’s fun to come up with rules that would fix imbalance but curious how you think such rules can happen without deeper (however achievable) changes to society predicating them outside current norms (eg voting and waiting; maybe organizing around getting more",
    "originSummary": [
      "Workers in the US experience over $50 billion in wage theft annually, making it the most prevalent form of theft in the country.",
      "Wage theft disproportionately affects lower-wage workers, women, people of color, and immigrant workers.",
      "Major companies like Amazon and Walmart, as well as construction contractors, have been implicated in wage theft violations."
    ],
    "commentSummary": [
      "The article explores wage theft and payment issues in academia, addressing concerns about late payments and mistreatment of workers.",
      "It discusses the pay and responsibilities of CEOs, highlighting the unequal power dynamics between employers and employees.",
      "The role of unions, regulations in free markets, the impact of cartels on competition, and the landlord-tenant relationship are also discussed, emphasizing the need for effective regulation and worker protections."
    ],
    "points": 362,
    "commentCount": 398,
    "retryCount": 0,
    "time": 1707746224
  },
  {
    "id": 39343746,
    "title": "Demystifying the Kalman Filter: Understanding and Implementing the Algorithm in Real-World Projects",
    "originLink": "https://thekalmanfilter.com/kalman-filter-explained-simply/",
    "originBody": "Kalman Filter Explained Simply FacebookTweetPin Most tutorials for the Kalman Filter are difficult to understand because they require advanced math skills to understand how the Kalman Filter is derived. If you have tried to read Rudolf E Kalman’s 1960 Kalman Filter paper, you know how confusing this concept can be. But do you need to understand how to derive the Kalman Filter in order to use it? No. If you want to design and implement a Kalman Filter, you do not need to know how to derive it, you just need to understand how it works. The truth is, anybody can understand the Kalman Filter if it is explained in small digestible chunks. This post simply explains the Kalman Filter and how it works to estimate the state of a system. The big picture of the Kalman Filter Lets look at the Kalman Filter as a black box. The Kalman Filter has inputs and outputs. The inputs are noisy and sometimes inaccurate measurements. The outputs are less noisy and sometimes more accurate estimates. The estimates can be system state parameters that were not measured or observed. This last sentence describes the super power of the Kalman Filter. Again, the Kalman Filter estimates system parameters that are not observed or measured. In short, you can think of the Kalman Filter as an algorithm that can estimate observable and unobservable parameters with great accuracy in real-time. Estimates with high accuracy are used to make precise predictions and decisions. For these reasons, Kalman Filters are used in robotics and real-time systems that need reliable information. What is the Kalman Filter? Simply put, the Kalman Filter is a generic algorithm that is used to estimate system parameters. It can use inaccurate or noisy measurements to estimate the state of that variable or another unobservable variable with greater accuracy. For example, Kalman Filtering is used to do the following: Object Tracking – Use the measured position of an object to more accurately estimate the position and velocity of that object. Body Weight Estimate on Digital Scale – Use the measured pressure on a surface to estimate the weight of object on that surface. Guidance, Navigation, and Control – Use Inertial Measurement Unit (IMU) sensors to estimate an objects location, velocity, and acceleration; and use those estimates to control the objects next moves. The real power of the Kalman Filter is not smoothing measurements. It is the ability to estimate system parameters that can not be measured or observed with accuracy. Estimates with improved accuracy in systems that operate in real time, allow systems greater control and thus more capabilities. Kalman Filter Algorithm Overview The process diagram above shows the Kalman Filter algorithm step by step. I know those equations are intimidating but I assure you this will all make sense by the time you finish reading this article. Let’s look at this process one step at a time. For your reference, here is a table of definitions that will be referred to throughout. x state variable n x 1 column vector Output P state covariance matrix n x n matrix Output z measurement m x 1 column vector Input A state transition matrix n x n matrix System Model H state-to-measurement matrix m x n matrix System Model R measurement covariance matrix m x m matrix Input Q process noise covariance matrix n x n matrix System Model K Kalman Gain n x m Internal Kalman Filter Algorithm Reference Terms The table above identifies the variables used in the algorithm. Each variable listed has a structure type and category. As this article continues, use the table as a reference. If you are enjoying this post, check out my book Kalman Filter Made Easy. You will learn: the first principles behind the Kalman Filter, how to create simulations and perform analysis on Kalman Filters, and more. Kalman Filter Radar Tracking Tutorial This tutorial will go through the step by step process of a Kalman Filter being used to track airplanes and objects near airports. The output track states are used to display to the air traffic control operators monitoring the air space. Kalman Filter Tutorial Notation Radars are not built equally. Each one has different capabilities and therefore provides different types of information to its supporting systems. For this example, the radar will output its measurements in 2D cartesian coordinates, x and y. These measurements will be represented as a 2-by-1 column vector, z. The associated variance-covariance matrix for these measurements, R, will also be provided by the radar along with the time tag for when the measurement occurred, t. The subscript m denotes the measurement parameters. And the k subscript denotes the order of the measurement. The Kalman Filter estimates the objects position and velocity based on the radar measurements. The estimate is represented by a 4-by-1 column vector, x. It’s associated variance-covariance matrix for the estimate is represented by a 4-by-4 matrix, P. Additionally, the state estimate has a time tag denoted as T. Step 1: Initialize System State Initializing the system state of a Kalman Filter varies across applications. In this tutorial, the Kalman Filter initializes the system state with the first measurement. xk Eqn. 1-1 Pk Eqn. 1-2 In this radar tracking example, the input measurements contain position only information. The output system state will contain the position and velocity of the object. When the first measurement comes, the only information known about the object is the position at that point in time. The system state estimate will be set to the input position after the first estimate. The system state error covariance will be set to the first measurement’s position accuracy. Initialize System State in Equations These equations show the input and output values for this Kalman Filter after receiving the first measurement. Step 2: Reinitialize System State The system state estimate is reinitialized because a velocity estimate needs a second position measurement for computation. xk Eqn. 2-1 Pk Eqn. 2-2 Velocity is estimated with a linear approximation. As you most likely recall from high school physics, velocity is equal to the distance traveled divided by the time it took to travel that distance. The updated system state estimate will be the second measurement’s position and the computed velocity. The updated system state error covariance will be the second measurement’s position accuracy and an approximated velocity accuracy. Note that this velocity accuracy approximation is something that can be tuned and adjusted after running data through your filter. There are different ways of approximating these values so if this doesn’t match your approximation, that’s okay! Reinitialize System State in Equations for the Kalman Filter These equations show the input and output values for this Kalman Filter after receiving the second measurement. Note the velocity variance terms in the state covariance matrix. These values are being set to 104. In other words, this value indicates a large uncertainty for the velocity state values. In this example, the velocity units are meters per second. Quick Note on Initialization Steps 1 and 2 used the first couple measurements to initialize and re-initialize the system estimate. Each application of the Kalman Filter may do this differently but the goal is to have a system state estimate that can be updated for future measurement with the Kalman Filter equations. Steps 3 through 6 demonstrate how measurements are filtered in and the state estimate is updated. Step 3: Predict System State Estimate When the third measurement is received, the system state estimate is propagated forward to time align it with the measurement. This alignment is done so that the measurement and state estimate can be combined. xp = Axk-1 Eqn. 3-1 Pp = APk-1AT + Q Eqn. 3-2 The system model is used to perform this prediction. In this example, a constant velocity linear motion model is used to approximate the objects position change over a time interval. Note that a constant velocity model does assume zero acceleration. Remember this because it will resurface later. The constant velocity linear motion model is something you may also remember from your high school physics class. The equation states that the position of an object is equal to its initial position plus its displacement over a specified time period assuming a constant velocity. A state transition matrix represents these equations. This matrix is used to propagate the state estimate and state error covariance matrix appropriately. You may be wondering why the state error covariance matrix is propagated. The reason for this is because when a state estimate is propagated in time, the uncertainty about its state at this future time step is inherently uncertain, so the error covariance grows. On the Q Matrix The Q matrix represents process noise for the system model. The system model is an approximation. Throughout the life of a system state, that system model fluctuates in its accuracy. Therefore, the Q matrix is used to represent this uncertainty and adds to the existing noise on the state. For this example, the systems actual accelerations and decelerations contribute to this error. On the H Matrix The Kalman Filter uses the state-to-measurement matrix, H, to convert the system state estimate from the state space to the measurement space. For some applications, this is a matrix of zeros and ones. For other applications that use the Extended Kalman Filter, the H matrix is populated with differential equations. To learn more about Extended Kalman Filters, check out my article on them here. In this tutorial, the H matrix is a simple matrix that is set up to reduce the state estimate and error covariance to position only values rather than position and velocity. Predict System State in Equations Step 4: Compute the Kalman Gain The Kalman Filter computes a Kalman Gain for each new measurement that determines how much the input measurement will influence the system state estimate. In other words, when a really noisy measurement comes in to update the system state, the Kalman Gain will trust its current state estimate more than this new inaccurate information. This concept is the root of the Kalman Filter algorithm and why it works. It can recognize how to properly weight its current estimate and the new measurement information to form an optimal estimate. K = PPHT (HPPHT + R)-1 Eqn. 4-1 Step 5: Estimate System State and System State Error Covariance Matrix The Kalman Filter uses the Kalman Gain to estimate the system state and error covariance matrix for the time of the input measurement. After the Kalman Gain is computed, it is used to weight the measurement appropriately in two computations. The first computation is the new system state estimate. The second computation is the system state error covariance. xk = xp + K(zk – Hxp) Eqn. 5-1 Pk = PP – KHPP Eqn. 5-2 Kalman Filter Estimation Equations The state estimate computed above is the only state history the Kalman Filter retains. As a result, Kalman Filters can be implemented on machines with low memory restrictions. If you enjoyed reading this post, check out my eBook Kalman Filter Made Easy and my Unscented Kalman Filter book. You will learn: the first principles behind the Kalman Filter, how to create simulations and perform analysis on Kalman Filters, how the Extended Kalman Filter and Unscented Kalman Filter work, and more! Next Steps I hope this post allowed you to see how amazing the Kalman Filter is. And when it is broken up into parts, it is not that intimidating. In conclusion, the Kalman Filter is a generic process for optimal state estimation. It is used in a variety of applications that require accurate estimation. So now that you know what it is and how it works, go out and use it in your projects! If you enjoyed reading this post, please share it with your friends on your favorite social network! Thanks for reading! FacebookTweetPin Published December 31, 2020By William Franklin Categorized as Uncategorized",
    "commentLink": "https://news.ycombinator.com/item?id=39343746",
    "commentBody": "Kalman Filter Explained Simply (thekalmanfilter.com)332 points by RafelMri 22 hours agohidepastfavorite85 comments chubs 11 hours agoRecently tasked with implementing a Kalman filter, I found it very very difficult to find good resources that explained it in language that made sense to a developer like me. So after spending a month learning it, I wrote a couple posts on it, perhaps someone might find it helpful? https://www.splinter.com.au/2023/12/14/the-kalman-filter-for... https://www.splinter.com.au/2023/12/15/the-kalman-filter-wit... As a developer I found the maths made sense only after implementing it, ironically. I guess we learn by building on top of what we already know? Is there a term for that? reply Subdivide8452 2 hours agoparentOff topic, but why are you one of those people who do a full screen “subscribe to my mailing list” overlay? I never understand why you’d wanna do that. reply girzel 15 hours agoprevNo thread on Kalman Filters is complete without a link to this excellent learning resource, a book written as a set of Jupyter notebooks: https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Pyt... That book mentions alpha-beta filters as sort of a younger sibling to full-blown Kalman filters. I recently had need of something like this at work, and started doing a bunch of reading. Eventually I realized that alpha-beta filters (and the whole Kalman family) is very focused on predicting the near future, whereas what I really needed was just a way to smooth historical data. So I started reading in that direction, came across \"double exponential smoothing\" which seemed perfect for my use-case, and as I went into it I realized... it's just the alpha-beta filter again, but now with different names for all the variables :( I can't help feeling like this entire neighborhood of math rests on a few common fundamental theories, but because different disciplines arrived at the same systems via different approaches, they end up sounding a little different and the commonality is obscured. Something about power series, Euler's number, gradient descent, filters, feedback systems, general system theory... it feels to me like there's a relatively small kernel of intuitive understanding at the heart of all that stuff, which could end up making glorious sense of a lot of mathematics if I could only grasp it. Somebody help me out, here! reply ndriscoll 14 hours agoparentIncidentally this is why people miss the mark when they get mad about mathematicians using single letter variable names. Short names let you focus on the structure of equations and relationships, which lets you more easily pattern match and say \"wait, this is structurally the same as X other thing I already know but with different names\". It's not about saving paper or making it easier to write (it is not easier to write Greek letters with super/subscripts in LaTeX using an English keyboard than it would be to use words). It is about transmitting a certain type of information to the reader that is otherwise very difficult to transmit. While it uses letters so it looks vaguely like writing, math notation is very pictorial in nature. Long words would obscure the pictures. reply elbear 14 hours agorootparentI disagree. Single letter variables are meaningless. In order to get the big picture, you have to remember what all those meaningless letters stand for. Using meaningful variables would make this easier. reply brobdingnagians 13 hours agorootparentIf you work with them long enough it becomes second nature to read them, and then it is easier to manipulate and compose them. The rest of the context is the background knowledge to understand the pithy core equations. Papers are for explaining concepts, equations are for symbolic manipulation. Meaningful variable names would be middle ground and not good at either, except to help someone not familiar with the subject to understand the equation, but a lot of the symbols are so abstract that they really need to be explained in more detail elsewhere or would be arbitrarily named. reply np_tedious 12 hours agorootparentIf you're in an abstract/general mathematical function, then sure: single letters. If you're doing more business logic kind of stuff (iterating through a list of db/orm objects or processing a request body) then the names should be longer reply ndriscoll 10 hours agorootparentprevOften the actual meaning of the symbols is subordinate to the point you're trying to convey. e.g. I can tell you that `integrate(boundary(Region), form) = integrate(Region, differentiate(form))`, which is great and all, but I might write ` = ` because what I'm trying to tell you is that you should think of these things as a dual-pairing of vector spaces (via integration) and that ∂ and d are somehow adjoint. They're both Stokes' theorem, but the emphasis is different, and in either case the hard part is the mountain of work it takes to define what the words even mean (limits, and integrals, and derivatives, and vectors, and covectors, and manifolds, and tangent spaces, and vector fields, and covector fields, and partitions of unity, and symmetric and alternating forms, and exterior derivatives, etc. etc. all so you can finally write one equation, which really just says that all the swirlies inside a region cancel out so if you want to add them all up, you can just add up the outer swirly). The thing about math is you need to be comfortable viewing the same concept through a bunch of different lenses, and various notations are meant to help you do that by emphasizing different aspects of \"the picture\" you're looking at. reply elbear 16 minutes agorootparentOk, I can accept that. At the same time, my impression is that mathematicians always use single-letter variables. It's like either they're not clear who their audience is or they're afraid to get off the beaten path. If they're explaining a classic algorithm, they use the common, single-letter variables instead of replacing them with meaningful names. reply svat 10 hours agorootparentprevIMO your comment seems not to be addressing the point made in its parent comment. To make the point again with different words: - Using long descriptive variable names would give them meaning, and make the particular equation/expression easier to understand or apply. - Using short single-letter variable names allows you to forget the meaning of the variables and see the underlying structure, thus making the expression easier to connect to other situations (with completely unrelated meanings) that happen to have the same underlying structure. (The letters being meaningless, or at least not carrying their meaning so strongly, is a feature, not a bug.) (See the highest-voted answer to https://math.stackexchange.com/questions/24241/why-do-mathem... for example.) (Another way of seeing the distinction is whether you consider the equation to be the final result, to be used and applied, or as a starting point, to be manipulated further.) reply elbear 24 minutes agorootparentOk, that makes sense. Then maybe use single-letter variables for when working on something, and meaningful variable names for when publishing. Edit: I realise, like someone mentioned in another comment, that sometimes you also want to make the pattern visible to readers. reply duped 13 hours agoparentprevYou're looking for the theory of linear (or nonlinear) dynamical systems. Unfortunately it's not one kernel of intuition backed by consistent notation, it's many with no consistency. A good course on controls and signals/systems will beat those intuitions into you and you learn the math/parlance without getting attached to any one notational convention. The real intuition is \"everything is a filter.\" Everything else is about analysis and synthesis of that idea. reply bonoboTP 15 hours agoparentprevMaybe check out Probabilistic Robotics by Dieter Fox, Sebastian Thrun, and Wolfram Burgard. It has a coherent Bayesian formulation with consistent notation on many Kalman-related topics. Also with the rise of AI/ML, classic control theory ideas are being merged with reinforcement learning. reply esafak 12 hours agorootparentI agree that Bayesian filtering is the most general and logical approach. There are Bayesian derivations of the Kalman filter too. Here is a broad survey: https://people.bordeaux.inria.fr/pierre.delmoral/chen_bayesi... reply girzel 15 hours agorootparentprevThanks for the recommendation! It would never have occurred to me to look at robotics, but I can understand why that's very relevant. I read Feedback Control for Computer Systems not too long ago, which felt like yet another restatement of the same ideas; I guess that counts as \"classic control theory\". reply thundercarrot 12 hours agoparentprevIf Q and R are constant (as is usually the case), the gain quickly converges, such that the Kalman filter is just an exponential filter with a prediction step. For many people this is a lot easier to understand, and even matches how it is typically used, where Q and R are manually tuned until it “looks good” and never changed again. Moreover, there is just one gain to manually tune instead of multiple quantities Q and R. reply ActorNightly 12 hours agoparentprevWhen you start dealing with linear systems and disturbances, you end up with basically matrix math and covariance in some form and way. The thing about Kalman filter is that its a pretty well known and exists in many software packages (just like PID) so its fairly easy to implement. But because noise is often not gaussian, and systems are often not linear, its more of a \"works well enough\" for most applications. reply plasticchris 15 hours agoparentprevHey, I had very similar thoughts many years ago! The trick is yes, many filters boil down to alpha/beta, and the kalman filter is (edit: can be) really a way to generate those constants given a (linear) model (set of equations describing the dynamics, ie the future states) and good knowledge of the noise (variance) in the measurements. So if the measurements always have the same noise it will just reduce the constants over time, and it is only really useful when the measurement accuracy can be determined well and also changes a lot. reply girzel 15 hours agorootparentInteresting. Are you characterizing Kalman filters mostly as systems of control/refinement on top of alpha-beta filters? I do feel like the core of it is essentially exponential/logarithmic growth/decay, with the option to layer multiple higher-order growth/decay series on top of one another. Maybe that's the gist... reply plasticchris 14 hours agorootparentYeah, because a lot of times the equations that fall out of the KF look the same, only with variable values for alpha/beta. reply bbstats 4 hours agoparentprevthere is no better smoother than a future predictor. I'm not entirely sure what the issue is here. reply foobarbecue 19 hours agoprevI've always thought math would be much easier to learn if they used descriptive variable names. Or, at least in an interactive medium like the web, add some tooltips at a bare minimum. Whenever I study math I spend 90% of the time looking up the symbols. Also when this person says the subscript \"denotes the order of the measurement\" I'm trying to figure out what kind of order he's talking about. I guess that's the index? It's been a while since I did kalman filters:-p reply shiandow 19 hours agoparentPeople always seem to forget that mathematical notation is designed to make algebraic manipulations easier to follow. It's not really intended as something that makes sense on its own, it's mostly physicists who think something like E=mc^2 should have any meaning. The more pure the mathematics the shorter the scope of most variables. Typically a variable is defined just before it's used, with a scope no longer than the proof or derivation it's in. Also some of the choices in this article are just plain silly. Such as using P as both variable and index, and then use it for the covariance matrix when the precision matrix is the exact inverse. reply atoav 16 hours agorootparentTo be honest a lot of things that are incredibly easy, incredibly intuitive — things of the \"I could come up with this myself\"-kind — can seem impenetrable when written down in mathematical notation. If you want people to understand, you skip the mathematical notation and use pseudocode, or at least you start with an explaination and once people know what they are looking at you go into the math notation. I understand that mathematical notation can be very practical for describing a certain class of problems concisely, but especially if you teach or explain things, consider that being concise is meaningless if people don't understand what you describe. Sometimes my feeling is that this is on purpose. People not understanding what you are doing (but you come across soo smart), is a feature to many. Even better: The layperson cannot tell whether you are talking utter gibberish or using the most precise language on earth. I, however, think you can recognize real smart people by the phenomenon that every room they are in seems to become smarter in total, because they lift people up in their wake of understanding things so deeply, they can just break them down into their very simple, managable parts and translate obscure domain-specific languages into something people can grasp. I too can go into deep domain specific lanuages, be it in philosophy, electrical regulation, film theory, programming lingo, music theory, control theory etc. But what is the point of doing that without making the person opposite understand what you're waffling on about? Because either you will seem like a knowledgeable person that has a total lack of self-perception or like a brick that doesn't care what message reaches the person opposite as long as rhey can hear themselves talk. That being said: Domain-specific language can be okay if it is used between people within that domain. But I have met many physicists or mathematicians who also think math notation sucks, so maybe there could be something better. reply shiandow 15 hours agorootparentUnecessary use of mathematical notation / terminology definitely happens. It's one of the things that annoy me to no end. Especially if after unwrapping the unintelligible mess of mathematical gibberish you're left with some inane argument. I still haven't quite forgiven the writers of UMAP for writing a theorem that uses pi^n/2 / Gamma(n/2+1) instead of the more reasonable \"volume of the unit sphere\". It makes it so confusing that they fail to spot the theorem doesn't work for low dimensional objects embedded in high dimensional spaces, which is their exact use-case. Luckily their informal conclusion does work, mostly. reply bonoboTP 15 hours agorootparentprevA great positive example would be Andrej Karpathy. reply CamperBob2 13 hours agorootparentGreat explainer -- incredibly so -- but not awesome in the variable-naming department, having just gone through his ML videos. reply toxik 18 hours agorootparentprevIn computer science, we straddle this divide where the usual way to describe things in scientific literature is using algebraic notation, but the usual way to actually write up a program is to use meaningful variable names. It's not K_i, it's current_gains or something like that. It leads to a funny kind of style where especially computer science-related fields start writing K_{current} in scientific manuscripts, and are then chided because that is not how you use subscripts. The reverse is also true, theory-adjacent code tends to use a lot more terse naming conventions. reply michaelrpeskin 18 hours agorootparentI often work with a guy who's a pure computer scientist. He communicates in LaTeX and pseudocode only. I don't think he could find a compiler if he tried. What I've learned to do is keep his notation whenever I implement something. I start the function with a comment that says what paper I'm referencing when I implement it and then comment all of the one-letter variables. (In this case I would use K[i]). Usually the stuff I'm implementing is complicated enough that reading the code without reading the paper won't have much meaning. And if you're reading the paper, it's good to have as close to a 1-1 representation to help give confidence that I implemented it right. I've had non-zero times where I took his pseudocode, pasted it into my IDE and did a search and replace of begin/end to braces and \" Also when this person says the subscript \"denotes the order of the measurement\" I'm trying to figure out what kind of order he's talking about. I hate that the most when reading papers. Authors trying to sound abstract and academic, but only accomplishing being frustratingly vague. AUTHORS YOU STILL HAVE TO INSERT THE SUBJECT INTO YOUR SENTENCES FOR THEM TO MAKE SENSE. I'm so frustrated at this aspect in research papers more than anything else. You must disambiguate. Use absolute descriptors and do not use relative descriptors. Don't tell me to look right, because I'll look left. Use absolute descriptors! \"then after spinning the prism the light cone blah blah blah\" SPIN!? SPIN IN WHAT DIRECTION????? LEFT?RIGHT?! LATERAL? UP? DOWN???? How fast? How slow? You imagine all of these CRITICAL ASPECTS in your head when writing such ambiguous sentences, but the reader cannot read your mind. reply saulrh 9 hours agorootparentHaving written papers like this before, a large part of the problem is that almost all CS research is published in conferences, rather than journals, and conferences frequently have extremely strict length limits, on the order of three or five pages. If you have an even slightly complicated procedure it can be nightmarishly difficult to get even the core information into your paper, and you can forget about details or tangents. reply max_ 16 hours agoparentprevI completely agree. And my insight similar to yours is that the greatest math book that no one has written is one where the meaning of notation, variables and a clear assortment of theorems across all topics are well curated. reply bonoboTP 15 hours agorootparentMany math books nowadays come with Python code eg jupyter notebooks. reply max_ 15 hours agorootparentPython code is abit of an over kill. I was for example reading a cryptography book and it has symbols like a hamadad product. reply pinkmuffinere 18 hours agoparentprev> Also when this person says the subscript \"denotes the order of the measurement\" I'm trying to figure out what kind of order he's talking about. I guess that's the index? It's been a while since I did kalman filters:-p The order referred to is the index-in-time that a value correspond to. Eg, x_3 would be the state at the third time step. I think their subscript “p” stands for prediction. x_p at time 3 is the state we expect at time 4. But then when time 4 comes around, we incorporate new measurements and calculate x_4 including that new information. Just to be explicit, this x_4 will be different from the x_p we calculated at time 3, as our prediction is always a bit incorrect reply o11c 7 hours agoparentprev> trying to figure out what kind of order For reference, the Wikipedia page \"Order (mathematics)\" is a disambiguation page almost as long as the top-level disambiguation page \"Order\". https://en.wikipedia.org/wiki/Order_(mathematics) I generally don't have a problem with variable names, but creating syntax and terminology that conflicts with other mathematical use is a real problem. reply malkia 9 hours agoparentprevCheck https://mitpress.ublish.com/ebook/structure-and-interpretati... reply foofie 17 hours agoparentprev> I've always thought math would be much easier to learn if they used descriptive variable names. I think the variable names are already picked to be descriptive. No one is picking them to be more obscure or harder to track. The problem is that those who are starting out still haven't picked up concepts or learned the standard notations for each problem domain, thus we are left with the pain of ramping up on a topic. reply Waterluvian 19 hours agoparentprevThis was 90% of my problem with math. Same when something is named descriptively: shield volcano, star dunes, vs. some person’s name like Rayleigh scattering. It’s just an extra layer to memorize and parse. reply bonoboTP 15 hours agorootparentI agree but this is a surface level issue impacting the very beginner phase only. Once you get familiar with the vocabulary, the hard stuff will be the actual material, understanding the thing itself, not its description. This differentiates fields that have an actual subject matter from fields that are essentially terminology and categorizations all the way through, a self-referential map with no territory. In math/physics/engineering the terminology is unfamiliar at first but very precise and hence learnable. The vast majority of STEM textbooks (at least from good US university publishers) make their best effort in presenting the material understandably without any intentional obscurantism or additional fanciness. Academic joirnal/conference papers do sometimes intentionally confuse to game the publication metrics but intro materials are an earnest effort at educating. The subject matter has some inherent complexity, there's no need to prop it up artificially for prestige (that happens more in other fields that are insecure about their level of inherent complexity). reply Waterluvian 15 hours agorootparentOh definitely! Eventually you've spent so much time that the thetas and lambdas and Lorentzes and whatever become your close intimate friends. I've most recently experienced this with learning piano and how an ocean of white and black keys all developed these individual \"identities.\" Like, \"ah yes,I won't forget you. We've had so many dramatic moments before, and remember that time I kept showing up at your neighbour's house instead?\" ...Okay maybe I'm just weird. reply colechristensen 15 hours agoparentprevI've always thought that code would be much easier to understand with shorter, less descriptive variable names. Whenever I look at new code most of the confusion involves searching through layers of abstraction for the part that actually does the thing as opposed to the layer upon layer of connections between abstractions which would be much less necessary if the entire behavior could be encoded in a single line. You can only have a small number of descriptive variables in an expression before it becomes entirely unreadable. That is opposed to single character with sub/superscripts where you can easily see what's happening with tens of variables in a single line of math. https://wikimedia.org/api/rest_v1/media/math/render/svg/a7d2... Here's a formula for calculating the downstream Mach number in a certain kind of supersonic flow. I cannot imagine any way to write this in \"descriptive variables\" which makes the formula understandable at all, you just could not see the structure. (from https://en.wikipedia.org/wiki/Oblique_shock ) reply shiandow 19 hours agoprevKalman filters might be one of those weird cases in mathematics where the 'simple' version is simplified beyond all recognition. I mean what you're really doing is take a measurement then simulate the possible future states and combine this information with the next measurement and repeat. You can imagine e.g. taking multiple pictures of a tennis-ball, estimate its position and speed from the first picture, simulate where it's going to end up, and compare this with the next picture to see which estimate is closer to the truth. Or more old school, measure the inclination of the sun and compare the resulting line of possible locations on a map to the spot you thought you were. Of course the exact calculations are beyond impractical. So you use sampling to simplify. However that still makes it difficult so you assume the distribution is somewhat close to a Gaussian distribution. And then you simplify even more by assuming the evolution of the system is just a linear transformation. And that's how you end up with the Kalman filter discussed here. I'd be amazed if anyone could really understand what's going on just based on the linear algebra. reply foobarian 18 hours agoparentI don't know what it is about the Kalman filter but so many explanations including the OP have this format: \"It's very simple! \" Your comment is the first I've seen actually providing intuition about what is happening. It doesn't help perhaps that the name itself is misleading as heck to computer people like me: it's not a filter as in stream processing or SQL. reply jvanderbot 17 hours agorootparentThe problem is 'simple' can mean a few things: - simple to predict / understand what it would do: Easily explained with pictures and hardly no math - simple to understand at a higher level / see why it works: Not easily explained without math and fraught with bayesian vs optimization vs EE-type approaches - simple to understand well enough to use: Not easily done without other relevant math that is not covered in KF explanation, e.g., controls, matrix analysis, Jacobians, etc - simple to understand why the equations are named what they are, and why they work: Not easily explained without math and historical context that takes a page or so to explain. > it's not a filter as in stream processing As you say \"filter\" means 'remove noise', but it also means 'process in order of arrival', so it's similar to your def of filter. So, we really need 4 guides. reply dwrtz 16 hours agorootparentprevyeah the \"filter\" term means something different in the KF context and is confusing filter: use measurements up to time t to estimate the state at time t smooth: use past and future measurements to estimate the state at time t predict: use measurements up to time t to estimate the state at time t+n reply shiandow 18 hours agorootparentprevI recall reading a very intuitive explanation including animations of a point cloud to show how it works. I've had no luck finding the article again though. reply jvanderbot 19 hours agoparentprevIt's simpler than that. The linear algebra is actually easier. The kalman filter tries to guess the hidden input that produced the measurements. It does so forming the minimization problem: 'minimize over x, the function [ actual_measurement - expected_measurement(x) ]^2/s^2', here 's' is sigma of noise. This follows from the state estimation problem: 'maximize over x, the likelihood of seeing the actual_measurement', because the only term that matters in the likelihood function is -([x-expected(x)]/s )^2. (look at the exponent in the Normal distribution, or any exponential distribution really). 'actual_measurement' is a constant, so if it happens that the function 'expected_measurement' is linear, this is trivially solved directly as a convex optimization, and if you take derivative, equate to zero, and solve, you'll get the kalman filter update step. If it so happens that the function is non-linear, well we just make a single netwton-rhapson step by linearizing the equation, minimizing, and returning the solution to the \"pretend linearization\". This is basic calc + linear algebra at an undergrad level, but nobody bothered to tell you that. --- It's also completely wrong. It's a hack from the 60s to maximize the likelihood function using a recursive, single-step linearization like this. A misreading of the Cramer Rao Lower Bound has \"proven\" to generations of engineers that this is optimal. It's not, not really.[^1] Nowadays we have 10,000x more compute, and any one of the following _will_ produce better performance: * Forming and solving the non-linear equation using many newton-rhapson steps * Keeping a long history of measurements, and solving using many newton-rhapson steps over this batch * Using sum-of-guassian representation to accomodate multi-modal measurement functions, esp when including the prior bullets All of these were well covered by state estimation research from 80s to now, but again, the textbooks seem to be written in stone in 1972. [^1]: (the cramer rao lower bound is only defined when all measurement likelihood functions are linearized at the true state - which is only possible asymptotically in a batch which preserves all the measurements - and not possible before time infinity and not possible with recursive filter) reply palebluedot 19 hours agorootparent> All of these were well covered by state estimation research from 80s to now, but again, the textbooks seem to be written in stone in 1972. Do you have any good resources (online or textbook) you could recommend, as an introduction to these concepts, that is more modern / up-to-date? reply jvanderbot 18 hours agorootparentI don't, sadly. The only coverage of this that was first-principles accessible was the course taught by Prof Stergios Romelioutis where I went to grad school. You could do fine by reading some old books by Bar-Shalom. Any practical textbook like his would include all the \"other stuff\" about the EKF that helps you understand how nonperforming it often is. But the actual derivation of the EKF is probably only one or two pages in such a textbook, which is a damn shame nobody includes it. The background required is simply: * Know the form of exponential family of PDFs (like Normal Gaussian) * Bayes rule * Recognize that to maximize f~= exp(-a), you have to minimize 'a' * Know how to take derivative of matrix equation ('a', above) * Solve it * Use 'matrix inversion lemma' to transform solution to what KF/EKF provides. Ah hell, I'll just write it up. reply markisus 18 hours agorootparentprevProbabilistic Robotics covers Kalman Filter from a first principles probabilistic viewpoint, and its extension the EKF. It's quite readable for someone with basic understanding of linear algebra, probability, and calculus. I believe it also has a refresher on these basics in the introduction. http://www.probabilistic-robotics.org/ reply hgomersall 13 hours agorootparentprevIt all depends on your background. If you come from a Bayesian background, looking at a Kalman filter as a posterior update mechanism is very intuitive. A distribution over state that gets updated as more information arrives... reply dwrtz 16 hours agorootparentprevYeah one needs to distinguish between the optimal state sequence and the optimal state at a particular time. In other words, a joint posterior (state trajectory up to now given all measurements up to now) vs a marginal posterior (state right now given all measurements up to now). the KF only gives you a marginal posterior. they are not the same reply eutectic 18 hours agorootparentprevBoth the Bayesian perspective and the optimization perspectice are legitimate ways of understanding the Kalman filter. I like the Bayesian perspective better. reply jvanderbot 17 hours agorootparentForgive me, I'm thoroughly confused by that dichotomy. How are they different? Approaching from bayes rule or a \"maximum likelihood\" approach produces the same results. The problems of the filter are present in both. reply hgomersall 13 hours agorootparentThe result is identical, the understanding is different. I would suggest that the Bayesian perspective leads to insights like the UKF [1] which IME is all round much better than the apparently better known EKF for approximating non linear systems. [1] That is, it is generally easier to approximate a distribution than a non linear function. reply eutectic 17 hours agorootparentprevWell, the derivations are different, and your comment seemed to imply that the maximum likelihood perspective was easier to understand. reply brcmthrowaway 8 hours agorootparentprevCan we just use Neural Networks? reply nayuki 19 hours agoprevI like this previous explanation: https://www.bzarg.com/p/how-a-kalman-filter-works-in-picture... , https://news.ycombinator.com/item?id=13449229 reply Moduke 15 hours agoparentI enjoyed the simplicity of this explanation as well: https://praveshkoirala.com/2023/06/13/a-non-mathematical-int... https://news.ycombinator.com/item?id=36971975 reply fho 14 hours agoparentprevThat's the one with the cute little robot, is it? I always liked that one the most :-) reply swyx 18 hours agoparentprevthis is way better, and should be at the top. reply 01HNNWZ0MV43FF 18 hours agoprevIf I really needed a Kalman filter I'm sure I could read this, or the Wikipedia page, or an implementation's source code (https://github.com/LdDl/kalman-rs/blob/master/src/kalman/kal...) and figure it out. But IME everyone in the entire world is a \"visual learner\" who learns best by examples. So I'm surprised that the tutorial midway through the page doesn't put any example numbers into the formulas (maybe I glanced over it?) and the pictures only start after a page of \"what is a Kalman filter\" text, and the pictures are just of more formulas. reply the__alchemist 17 hours agoparentAnother comment pointed out variable naming conventions as an obstacle to learning and understanding mathematical topics. I am sympathetic to that perspective, but even more so to this one you post. I am astounded by how common this is. A weaker form of this exists in software libraries that don't include code examples. reply cocostation 15 hours agoprevI really like this set of videos for explaining the KF. I 'got it' more than I did with the material on the original post. https://www.youtube.com/watch?v=CaCcOwJPytQ reply syntaxing 18 hours agoprevOne thing that clicked for me is that two uncertain distribution of measurements (a high variance in the distribution) makes a “more certain” measurement (a narrower distribution). Use this more certain measurement and combine it with the next measurement, then rinse and repeat and boom, you have a Kalman filter. reply pfdietz 20 hours agoprevMy late father used these all the time during his career, starting about the time they were invented. He worked on radar and missile guidance systems. reply lkdfjlkdfjlg 20 hours agoparentYou mean, actual engineering. reply willis936 19 hours agorootparentPlenty of EEs understand and apply DSP techniques today without making weapons. reply eclectic29 14 hours agoprevGenuine question: why does kalman filter come up so frequently on HN? Is this something I'm missing? I'm a machine learning engineer, not a data scientist. reply scarmig 11 hours agoparentML and Kalman filtering try to solve similar problems. Some theories even suggest that Kalman filtering (or a similar algorithm) provides a basis for neurobiological learning. See predictive coding (e.g. https://arxiv.org/pdf/2102.10021.pdf) (Why I'm interested in it, at least.) reply xchip 14 hours agoparentprevIt is considered a difficult topic and people want to show they understand it. A similar thing happens that had the word quantic or relativistic. I'm a physicist and we hardly talk about it, but here in HN we find people bringing in up every other day reply visarga 19 hours agoprevSimply put, it is an \"online\" model that which means that it learns on the fly. Specifically, it is the optimal online learning algorithm for linear systems with Gaussian noise. In a way it is like a primitive RNN, it has internal state, inputs and outputs. reply Symmetry 18 hours agoprevI've used them in robotics and for tracking satellites going overhead via radar. Apparently they're also used by economists for guessing the state of the economy, along with other filters in the standard robotics toolkit. reply bafe 12 hours agoparentEnsemble kalman filter (and similar techniques like variational assimilation) are also used heavily in the geosciences to assimilate measurements and model data in order to obtain a \"posterior observation\" which can be understood intuitively as an interpolation between model and observation weighted by their relative uncertainty (and covariance) reply mesofile 17 hours agoparentprevPurely idle curiosity – I've heard a lot about the Kalman filter over the years, it's a popular subject here, but what are the other filters in the standard robotics toolkit? reply dplavery92 13 hours agorootparentThe Kalman filter has a family of generalizations in the Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF.) Also common in robotics applications is the Particle Filter, which uses a Monte Carlo approximation of the uncertainty in the state, rather than enforcing a (Gaussian) distribution, as in the traditional Kalman filter. This can be useful when the mechanics are highly nonlinear and/or your measurement uncertainties are, well, very non-Gaussian. Sebastian Thrun (a CMU robotics professor in the DARPA \"Grand Challenge\" days of self-driving cars) made an early Udacity course on Particle Filters. reply elbear 13 hours agorootparentprevSomeone in another comment mentioned a book called Probabilistic Robotics. I think that covers everything. reply Symmetry 13 hours agorootparentprevParticle filters would be the main other one I'd reach for. The ability to represent multiple hypotheses is a big advantage they have. reply dplavery92 12 hours agorootparentYou can also construct multiple hypothesis trackers from multiple Kalman Filters, but there is a little more machinery. For example, Interacting Multiple Models (IMM) trackers may use Kalman Filters or Particle Filters, and a lot of the foundational work by Bar-Shalom and others focuses on Kalman Filters. reply mesofile 12 hours agorootparentprevThanks to everyone who replied. reply lopatin 14 hours agoprevDoes anyone here use Kalman filter for pairs trading? reply ModernMech 15 hours agoprevClose your eyes and walk around for a while. Imagine where you are. Now open your eyes. Is your actual location different from where you thought you were? That last bit, using an observation to update a belief on a state variable, that's what the Kalman filter does. reply hprotagonist 19 hours agoprev [–] “if you do it right, the noise washes out.” reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article presents the concept of the Kalman Filter, an algorithm used to estimate system parameters.",
      "It explores the inputs, outputs, and applications of the Kalman Filter in fields like object tracking, weight estimation, and guidance and control systems.",
      "The article provides a comprehensive overview of the Kalman Filter algorithm, explaining each step in the process, emphasizing the importance of initialization and reinitialization, and discussing the computation of the Kalman Gain and the estimation of system state and error covariance."
    ],
    "commentSummary": [
      "The Kalman filter is widely used in various fields like robotics, economics, and radar systems.",
      "Some participants express frustration with the lack of accessible resources and confusion caused by mathematical notation.",
      "Different perspectives on the use of single-letter variables versus meaningful variable names are discussed."
    ],
    "points": 332,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1707737588
  },
  {
    "id": 39354138,
    "title": "Stable Audio Demo: High-Fidelity Stereo Music Generation and Evaluations",
    "originLink": "https://stability-ai.github.io/stable-audio-demo/",
    "originBody": "stable-audio-demo ⚠ Warning: This website may not function properly on Safari. For the best experience, please use Google Chrome. arXiv: Stable Audio’s paper stable-audio-tools: code to reproduce Stable Audio stable-audio-metrics: code to evaluate Stable Audio Our model can generate variable-length and long-form stereo music at 44.1kHz: Generated Stereo Music PromptBerlin techno, rave, drum machine, kick, ARP synthesizer, dark, moody, hypnotic, evolving, 135 BPM. Loop.Uplifting acoustic loop. 120 BPM.Disco, Driving Drum Machine, Synthesizer, Bass, Piano, Guitars, Instrumental, Clubby, Euphoric, Chicago, New York, 115 BPM.Calm meditation music to play in a spa lobby.Drum solo. Differently from pervious state-of-the-art models, ours can generate stereo sound effects at 44.1kHz: Generated Stereo Sounds PromptDoor slam. High-quality, stereo.Sports car passing by. High-quality, stereo.Motorbike passing by. High-quality, stereo.Fireworks. High-quality, stereo.Reverberant footsteps inside a large rocky cave. High-quality, stereo. Note that all the examples in this website are generated with the same model that can generate both variable-length music and sound effects at 44.1kHz stereo. We append “high-quality, stereo” to our sound effects prompts because it is generally helpful. Long-form stereo music: comparison with state-of-the-art with MusicCaps prompts Prompt: This song contains someone strumming a melody on a mandolin while more people are whistling along. Then a mandolin, an e-bass and an acoustic guitar are playing a short melody in a lower key before breaking into the next part along with flutes and percussions. This song may be played outside by musicians performing. Our Model MusicGen-large MusicGen-stereo AudioLDM2 (stereo, 44.1kHz) (mono, 32kHz) (stereo, 32kHz) (mono, 48kHz) Prompt: The commercial music features a groovy piano melody played over snare rolls in the first half of the loop. Right after, there is a drop that consists of a punchy “4 on the floor” kick pattern, shimmering hi hats, claps, groovy piano and wide synth lead melody. It sounds happy, fun, euphoric and exciting. Our Model MusicGen-large MusicGen-stereo AudioLDM2 (stereo, 44.1kHz) (mono, 32kHz) (stereo, 32kHz) (mono, 48kHz) These prompts/audios were used for the qualitative study we report in our paper. Sound effects: comparison with state-of-the-art with AudioCaps prompts Prompt: Clicking and sputtering then eventual revving of an idling engine. Model Audiogen-medium AudioLDM2 (stereo, 44.1kHz) (mono, 32kHz) (mono, 48kHz)Prompt: Birds chirping loudly. Model Audiogen-medium AudioLDM2 (stereo, 44.1kHz) (mono, 32kHz) (mono, 48kHz)These prompts/audios were used for the qualitative study we report in our paper. Note the (randomly) selected prompts from AudioCaps did not require substantial stereo movement, resulting in renders that are relatively non-spatial. Autoencoder: reconstructions This comparison is useful to evaluate the audio fidelity capabilities of the autoencoder. On the left, we have the ground truth recording. On the right, we take the ground truth recording and end pass it through the autoencoder. Note that the autoencoder reconstruction is fairly transparent, very close to the ground truth. Ground truthAutoencoder reconstruction",
    "commentLink": "https://news.ycombinator.com/item?id=39354138",
    "commentBody": "Stable-Audio-Demo (stability-ai.github.io)302 points by beefman 6 hours agohidepastfavorite100 comments dr_dshiv 1 minute agoProposal: revenue from Generative AI should be taxed 10% for an international endowment for the arts. In exchange, copyright claims are settled. reply shon 4 hours agoprevInterestingly, Ed Newton-Rex, the person hired to build Stable Audio, quit shortly after it was released due to concerns around copyright and the training data being used. He’s since founded https://www.fairlytrained.org/ Reference: https://x.com/ednewtonrex reply doctorpangloss 3 hours agoparentFor generative models, if the model authors do not publish the architecture of their model; and, the model uses a transformation from text to another kind of media; you can assume that they have delegated some part of their model to a text encoder or similar feature which is trained on data that they do not have an express license to. Even for rightsholders with tens of millions to hundreds of millions of library items like images or audio snippets, the performance of the encoder or similar feature in text-to-X generative models is too poor on the less than billion tokens of text in the large repositories. This includes Adobe's Firefly. It is also a misconception that large amounts of similar data, like the kinds that appear in these libraries, is especially useful. Without a powerful text encoder, the net result is that most text-to-X models create things that look or sound very average. The simplest way to dispel such issues is to publish the architecture of the model. But anyway, even if it were all true, the only reason we are talking about diffusers, and the only reason we are paying attention to this author's work Fairly Trained, is because of someone training on data that was not expressly licensed. reply sillysaurusx 3 hours agorootparentIf you require licensing fees for training data, you kill open source ML. That’s why it’s important for OpenAI to win the upcoming court cases. If they lose, they’ll survive. But it will be the end of open model releases. To be clear, I don’t like the idea of companies profiting off of people’s work. I just like open source dying even less. reply sillysaurusx 3 hours agorootparentReplying to a deleted comment: > It sounds as if you imply that would be bad. But what if it wasn't? Entirely possible. The early history of aviation was open source in the sense that many unlicensed people participated, and died. The world is strictly better with licensing requirements in place for that field. But no one knows. And if history is any guide for software, it seems better to err on freedoms that happen to have some downside rather then clamping down on them. One could imagine a world where BitTorrent was illegal. Or cryptography, or bitcoin. reply raverbashing 1 hour agorootparentAre you really comparing licensing for a profession with licensing of IP? reply sillysaurusx 1 hour agorootparentIt’s much the same. Only authorized people are allowed to do X. Since X costs a lot of money, by definition it can’t be open source. There are no hobbyist pilots that carry passengers without a license, and if there are, they’re quickly told to stop. Generative AI faces a real chance of having the same fate. Which means open source will look similar to these planes trying to compete with commercial aircraft: https://pilotinstitute.com/flying-without-a-license/ If you can think of a better example, I’d like to know though. I’ll use it in future discussions. It’s hard to think of good analogies when the tech has new social effects. reply PeterStuer 17 minutes agorootparentIf I fly a plane and crash, my passengers die. If I generate an image using a model whose training included some unlicensed imagery... Disney misses out on a fraction of a cent? There is a real reason why some professions are licenced and others are not. Your analogy is nonsensical. Not having a better one is irrelevant. reply sillysaurusx 1 minute agorootparentIf training data requires licensing fees, ML practitioners will become a licensed field de facto, because no one in the open source world will have the resources to pursue it on their own. Perhaps a better analogy is movies. At least with acting, you can make your own movies, even if you’re on a shoestring budget. With ML, you quite literally can’t make a useful model. There’s not enough uncopyrighted data to do anything remotely close to commercial models, even in spirit. dkjaudyeqooe 1 hour agorootparentprevThat makes no sense. OpenAI must lose and it must not be possible to have proprietary models based on copyrighted works. It's not fair use because OpenAI is profiting from the copyright holders work and substituting for it while not giving them recompense. The alternative is that any models widely trained on copyrighted work are uncopyrightable and must be disclosed, along with their data sources. In essence this is forcing all such models to be open. This is the only equitable outcome. Any use of the model to create works has the same copyright issues as existing work creation, ie if substantially replicates an existing work it must be licenced. reply sillysaurusx 1 hour agorootparentFor what it’s worth, I agree with your second paragraph. But it would take legislation to enforce that. For now, it’s unclear that OpenAI will lose. Quite the opposite; I’ve spoken with a few lawyers who believe OpenAI is on solid legal footing, because all that matters is whether the model’s output is infringing. And it’s not. No one reads books via ChatGPT, and Dalle 3 has tight controls preventing it from generating Pokémon or Mario. All outcomes suck. The trick is to find the outcome that sucks the least for the majority of people. Maybe the needs of copyright holders will outweigh the needs of open source, but it’s basically guaranteed that open source ML will die if your first paragraph comes true. reply JoshTriplett 1 hour agorootparentprev> If you require licensing fees for training data, you kill open source ML. And likely proprietary ML as well, hopefully. (To be clear, I think AI is an absolutely incredible innovation, capable of both good and harm; I also think it's not unreasonable to expect it to play a safer, slower strategy than the Uber \"break the rules to grow fast until they catch up to you\" playbook.) I'm all for eliminating copyright. Until that happens, I'm utterly opposed to AI getting a special pass to ignore it while everyone else cannot. Fair use was intended for things like reviews, commentary, education, remixing, non-commercial use, and many other things; that doesn't make it appropriate for \"slurp in the entire Internet and make billions remixing all of it at once\". The commercial value of AI should utterly break the four-factor test. Here's the four-factor test, as applied to AI: \"What is the character of the use?\" - Commercial \"What is the nature of the work to be used?\" - Anything and everything \"How much of the work will you use?\" - All of it \"If this kind of use were widespread, what effect would it have on the market for the original or for permissions?\" - Directly competes with the original, killing or devaluing large parts of it Literally every part of the four-factor test is maximally against this being fair use. (Open Source AI fails three of four factors, and then many users of the resulting AI fail the first factor as well.) > If they lose, they’ll survive. That seems like an open question. If they lose these court cases, setting a precedent, then there will be ten thousand more on the heels of those, and it seems questionable whether they'd survive those. > To be clear, I don’t like the idea of companies profiting off of people’s work. I just like open source dying even less. You're positioning these as opposed because you're focused on the case of Open Source AI. There are a massive number of Open Source projects whose code is being trained on, producing AIs that launder the copyrights of those projects and ignore their licenses. I don't want Open Source projects serving as the training data for AIs that ignore their license. reply Ukv 12 minutes agorootparent> Fair use was intended for things like reviews, commentary, education, remixing, non-commercial use, and many other things \"many other things\" has included, for example, Google Books scanning millions of in-copyright books, storing internally them in full, and making snippets available. The basis for copyright itself is to \"promote the progress of science and useful arts\". For that reason a key consideration of fair use, which you've skipped entirely, is the transformative nature of the new work. As in Campbell v. Acuff-Rose Music: \"The more transformative the new work, the less will be the significance of other factors\", defined as \"whether the new work merely 'supersede[s] the objects' of the original creation [...] or instead adds something new\". > \"How much of the work will you use?\" - All of it For the substantiality factor, courts make the distinction between intermediate copying and what is ultimately made available to the public. As in Sega v. Accolade: \"Accolade, a commercial competitor of Sega, engaged in wholesale copying of Sega's copyrighted code as a preliminary step in the development of a competing product\" yet \"where the ultimate (as opposed to direct) use is as limited as it was here, the factor is of very little weight\". Or as in Authors Guild v. Google: “verbatim intermediate copying has consistently been upheld as fair use if the copy is ‘not reveal[ed] . . . to the public.’” The factor also takes into account whether the copying was necessary for the purpose. As in Kelly v. Arriba Soft: \"If the secondary user only copies as much as is necessary for his or her intended use, then this factor will not weigh against him or her\" While there are still cases of overfitting resulting in generated outputs overly similar to training data, I think it's more favorable to AI than simply \"it trained on everything, so this factor is maximally against fair use\". > Directly competes with the original, killing or devaluing large parts of it The factor is specifically the effect of the use upon the work - not the extent to which your work would be devalued even if it had not been trained on your work. reply andybak 26 minutes agorootparentprevBear with me here. Rushed and poorly articulated post incoming... In the broadest sense, generative AI helps achieve the same goals that copyleft licences aim for. A future where software isn't locked away in proprietary blobs and users are empowered to create, combine and modify software that they use. Copyleft uses IP law against itself to push people to share their work. Generative AI aims to assist in writing (or generating) code and make sharing less neccesary. I argue that if you are a strong believer in the ultimate goals of copyleft licences you should also be supporting the legality of training on open source code. reply magicalhippo 33 minutes agorootparentprev> \"What is the character of the use?\" - Commercial Your first factor seems to not at all be like that which Stanford has in its guidelines[1], which they call the transformative factor: In a 1994 case, the Supreme Court emphasized this first factor as being an important indicator of fair use. At issue is whether the material has been used to help create something new or merely copied verbatim into another work. LLMs mostly create something new, but sometimes seems to be able to regurgitate passages verbatim, so I can see arguments for and against, but to my untrained eyes doesn't seem as clear cut. [1]: https://fairuse.stanford.edu/overview/fair-use/four-factors/ reply sillysaurusx 58 minutes agorootparentprevIt’s not so clear cut. Many lawyers believe all that matters is whether the output of the model is infringing. As much as people love to cite ChatGPT spitting out code that violates copyright, the vast majority of the outputs do not. Those that do, are quickly clamped down on — you’ll find it hard to get Dalle to generate an image of anything Nintendo related, unless you’re using crafty language. There’s also the moral question. Should creators have the right to prevent their bits from being copied at all? Fundamentally, people are upset that their work is being used. But \"used\" in this case means \"copied, then transformed.\" There’s precedent for such copying and transformation. Fair use is only one example. You’re allowed to buy someone’s book and tear it up; that copy is yours. You can also download an image and turn it into a meme. That’s something that isn’t banned either. The question hinges on whether ML is quantitatively different, not qualitatively different. Scale matters, and it’s a difference of opinion whether the scale in this case is enough to justify banning people from training on art and source code. The courts’ opinion will have the final say. The thing is, I basically agree with you in terms of what you want to happen. Unfortunately the most likely outcome is a world where no one except billion dollar corporations can afford to pay the fees to create useful ML models. Are you sure it’s a good outcome? The chance that OpenAI will die from lawsuits seems close to nil. Open source AI, on the other hand, will be the first on the chopping block. reply bryanrasmussen 24 minutes agorootparent>Those that do, are quickly clamped down on — you’ll find it hard to get Dalle to generate an image of anything Nintendo related, unless you’re using crafty language. really it seems more like someone was afraid of angering Nintendo who is a corporate adversary one does not like to fight and thus it has a bunch of blocks to keep from generating anything that offends Nintendo, that does not really translate to quickly and easily stopping and blocking offending generations across every copyrighted work in the world. reply viraptor 1 hour agorootparentprev> \"How much of the work will you use?\" - All of it That depends on the interpretation of \"use\", and it would be interesting to read what lawyers think. You learned the language largely from speech and copyrighted works. (All the stories, books, movies, etc. you ever read/heard) When you wrote this comment did you use all of them for that purpose? Is the case of AI different? To be clear that's a rhetorical question - I don't expect anyone here to actually have a convincing enough argument either way. reply JoshTriplett 1 hour agorootparentPrinciples applied to human brains are not automatically applicable to AI training. To the best of my knowledge, there's no particular law that says a human brain is exempt from copyright, but it empirically is, because the alternative would be utterly unreasonable. No such exemption exists for AI training, nor should it. Ideas/works/etc literally live rent-free in your head. That doesn't mean they should live rent-free in an AI's neural network. Changing that should involve actually reducing or eliminating copyright, for everyone, not giving a special pass to AI. reply marcyb5st 2 hours agorootparentprevIs there a license that states: if you use this data for ML training you must open source model weights and architecture? reply sillysaurusx 2 hours agorootparentIt’s deeper than that. The basis of licensing is copyright. If the upcoming court cases rule in OpenAI’s favor, you won’t be able to apply copyright to training data. Which means you can’t license it. Or rather, you can, but everyone is free to ignore you. A license without teeth is no license at all. The GPL is only relevant because it’s enforceable in court. I’m sure some countries will try the licensing route though, so perhaps there you’d be able to make one. EDIT: I misread you, sorry. You’re saying that if OpenAI loses and license fees become the norm, maybe people will be willing to let their data be used for open source models, and a license could be crafted to that effect. Probably, yes. But the question is whether there’s enough training data to compete with the big companies that can afford to license much more. I’m doubtful, but it could be worth a try. reply deely3 2 hours agorootparentprev> If you require licensing fees for training data, you kill open source ML. kill open source ML -> decrease speed of improvements for some open source ML reply sillysaurusx 2 hours agorootparentSadly not. Making something illegal has social effects, not just legal effects. I’ve grown tired of being verbally spit on for books3. One lovely fellow even said that he hoped my daughter grows up resenting me for it. It being legal is the only guard against that kind of thing. People will still be angry, but they won’t be so numerous. Right now everyone outside of AI almost universally despises the way AI is trained. Which means you won’t be able to say that you do open source ML without risking your job. People will be angry enough to try to get you fired for it. (If that sounds extreme, count yourself lucky that you haven’t tried to assemble any ML datasets and release them. The LAION folks are in the crosshairs for supposedly including CSAM in their dataset, and they’re not even a dataset, just an index.) reply viraptor 1 hour agorootparentUS copyright has limited reach. There are models trained in China, where the IP rules are... not really enforced. It would be an interesting world where you use / pay for those models because you can't train them locally. reply multjoy 2 hours agorootparentprevIf everyone is unhappy with your rampant piracy, then perhaps that is a sign that you’re doing it wrong? reply sillysaurusx 2 hours agorootparentPerhaps. The reason I did it was because OpenAI was doing it, and it’s important for open source to be able to compete with ChatGPT. But if OpenAI’s actions are ruled illegal, then empirically open source wasn’t a persuasive enough reason to allow it. reply iamsaitam 1 hour agorootparentprevThe point should be to kill training on unlicensed material. There needs to be regulation and tools to identify what was the training data. But as always, first comes the siphoning part, the massive extraction of value, then when the damage is done there will be the slow moving reparations and conservationism. reply cornel_io 51 minutes agorootparentA ton of us out here don't agree with your goals. I think these models are transformative enough that the value added by organizing and extracting patterns from the data outweighs the interests of the extremely diffuse set of copyright holders whose data was ingested. So regardless of the technical details of copyright law (which I still think are firmly in favor of OpenAI et al) I would strongly opposed any effort to tighten a legal noose here. reply silviot 2 hours agorootparentprev> But anyway, even if it were all true, the only reason we are talking about diffusers, and the only reason we are paying attention to this author's work Fairly Trained, is because of someone training on data that was not expressly licensed. Thanks for putting this into words. I'm of the same opinion and this is the best articulation I have so far. reply az226 3 hours agoparentprevThat’s an interesting take. But quite the odd stance since he joined Stability and the training of Stable Diffusion was well known. reply prmoustache 2 hours agoparentprevNot that it would have stopped the company for doing it anyway, but couldn't he think about that before working from them? Or did he needed that as it i part of the business model of his certfications? reply jsiepkes 2 hours agoprev> Warning: This website may not function properly on Safari. For the best experience, please use Google Chrome. We've come full circle with the 90's and Internet Explorer. Well I guess this time the dominant browser is opensource so that's atleast something... Can someone please create an animated GIF button for Chrome which says: \"Best viewed with Google Chrome\"? reply Maxion 2 hours agoparentChrome isn't open source, chromium is. Best not to confuse the two. reply schleck8 1 hour agorootparentChrome and Chromium are virtually identical except for Google services, which aren't required to do anything with the browser except for installing Chrome extensions that can alternatively be sideloaded, so this is nitpicking. reply urbandw311er 52 minutes agorootparentJumping in to defend parent comment, there’s nothing Open Source about Google Chrome and it’s highly relevant in this context because they are notorious for putting technologies and tracking in there that many people find objectionable. reply forgotusername6 28 minutes agorootparentprevTangential, but I tried to build chromium the other day but stopped when it said it required access to Google cloud platform to actually build it. If something requires a proprietary build system, does it matter that it's open source? reply berkes 54 minutes agorootparentprevIt's essential nitpicking reply superb_dev 2 hours agoparentprevWebsite works fine on safari too, I didn’t notice any issues reply nness 16 minutes agorootparentSame, I wonder what issue they thought they had... reply romanzubenko 5 hours agoprevAs with Stable Diffusion, text prompting will be the least controllable way to get useful output with this model. I can easily imagine midi being used as an input with control net to essentially get a neural synthesizer. reply zone411 5 hours agoparentYes. Since working on my AI melodies project (https://www.melodies.ai/) two years ago, I've been saying that producing a high-quality, finalized song from text won't be feasible or even desirable for a while, and it's better to focus on using AI in various aspects of music making that support the artist's process. reply raincole 1 hour agoparentprevFor music perhaps. For sound effects I think text prompting is the rather good UI. reply numpad0 1 hour agoparentprevIt's crazy that nobody cares. It seems to me that ML hype trends focus on denying skills and disproving creativity by denoising randoms into what are indistinguishable from human generation, and to me this whole chain of negatives don't seem to have proven its worth. reply qwertox 4 hours agoprevI think we still need the step where the AI learns what a high quality sound library sounds like and then applies the previously learned abilities by triggering sounds of that library via MIDI. That way you'd get perfect audio quality with the creativity of a musical AI. reply jchw 3 hours agoparentI've always wished for something like that for image generation AI. It'd be much cooler/more interesting to watch AI try to draw/paint pictures with strokes rather than just magically iterate into a fully-rendered image. I dunno what kind of dataset or architecture you could possibly apply to accomplish this, but it would be very interesting. reply AuryGlenz 2 hours agorootparentI get what you’re saying, but if you watch Stable Diffusion do each step it’s at least kind of similar. If you keep the same seed but change a detail, often the broad “strokes” are completely the same. reply eru 4 hours agoparentprevHow would MIDI get you eg a guitar being played dirty? Or some subtle echo that comes from recording in a bathroom? reply qwertox 3 hours agorootparentIt would use a sampler and for the subtle echo effect add a reverb to the bus. https://www.youtube.com/watch?v=EQdp2QLiSYQ&t=187s reply arrakeen 3 hours agorootparentprevthe AI designs and controls the effects chain and mastering too reply 3ds 2 hours agoparentprevIsn‘t that what suno.ai does? reply ttul 3 hours agoprevI find it interesting that they are releasing the code and lovely instructions for training, but no model. They are almost begging anonymous folks to hook the data loader up to an Apple Music account and go nuts. Not that I am suggesting anyone do that. reply reissbaker 5 hours agoprevThis is incredibly good compared to SOTA music models (MusicGen, MusicLM). It looks like there's also a product page where you can subscribe to use it, similar to Midjourney: https://www.stableaudio.com/ Sadly it's not open-weight and it doesn't look like there's an API (again like Midjourney): you subscribe monthly to generate audio in their UI, rather than having something developers can integrate or wrap. reply nullandvoid 4 hours agoparentI was hoping to use it to generate some sound effects to use in a game I'm working on - but looks like I need an \"enterprise license\" (https://www.stableaudio.com/pricing) Why does this have a different clause I wonder, and doesn't just fall under \"In commercial products below 100,000 MAU\"? reply ex3ndr 4 hours agoparentprevThankfully you can train it at home, the bigger question is a data. reply lopkeny12ko 3 hours agoprev> We append “high-quality, stereo” to our sound effects prompts because it is generally helpful. It's hilarious that we've discovered you can get better outputs from LLMs by simply nicely telling it to generate better results. reply nine_k 3 hours agoparentMaybe sometimes you want an old cassette sound, or even older scratched 78 rpm sound, etc. Computers, as usual, do what you asked them to do, not what you meant. reply TillE 5 hours agoprevI was briefly excited about the idea of generating sound effects, but those \"footsteps\" are incredibly bad. reply laborcontract 3 hours agoparentI tried generating music on stableaudio.com and, yes, it's bad. However, given the blistering pace of developing in these models, I would not be surprised if these sound incredible in a year or two. reply berkes 50 minutes agorootparentEveryone every time seems to assume a linear (or exponential) curve upwards. But what is the proof for that? I consider it far more likely that we had a breakthrough and now rushing towards the next plateau. Maybe are nearing that. Like in the curve of a PID controller. It's how most or many human improvements go. reply leodriesch 13 minutes agorootparentI'd say most are thinking of Midjourneys success in image generation when talking about this kind of progress. reply alacritas0 4 hours agoprevthis can produce some pretty disturbing, but interesting music using the prompt \"energetic music, violin, voice, orchestra, piano, minimalism, john adams, nixon in china\": https://www.stableaudio.com/1/share/953f079e-d704-4138-904c-... reply FergusArgyll 2 hours agoparentIt reminds me a little of breath of the wild guardian music reply MrThoughtful 4 hours agoprevSo many questions ... They publish the code to train on your own music, but not the weights of their model? So you cannot just upload this thing to some EC2 instance and start creating your own music, correct? Is this the same as https://www.stableaudio.com? reply nextworddev 4 hours agoparentStabilityAI is just a marketing machine at this point that is praying for an acquisition, since the runway is diminishing reply alacritas0 4 hours agoparentprevthis sounds like progress, but it is still very bad except for highly repetitive music like the EDM examples they give, and even then, it still can't get tempo right reply lbourdages 5 hours agoprevThis is right into the \"uncanny valley\" of music. It definitely sounded \"like music\", but none of it is what a human would produce. There's just something off. reply bane 5 hours agoparentThe overall audio quality sounds pretty good and it seems to do a good job of sustaining a consistent rhythm and musical concept. But I agree there's something \"off\" about some of the clips. - The rave music sounds great. But that's because EDM can be quite out there in terms of musical construction. - The guitar sounds weird because it doesn't sound like chords a human hand can make on a tuning nobody tunes their guitar to - with a strange mix of open and closed strings that don't make sense. I think the restrictions of what a guitar can do aren't well understood by the model. - The disco chord progression is bizarre. It doesn't sound bad, but it's unlikely to be something somebody working in the genre would choose. - meditation music - I mean, most of that genre may as well just be some randomized process - drum solo - there's some weird issues in some of the drum sounds, things like cymbals, rides and hats changing tone in the middle of a note, some of the toms sound weird, it sounds like a mix of stick and brush and stick and stick and brush all at the same time...it's sort of the same problem the solo guitar has where it's just not produced within the constraints of what a drum player can actually do on an instrument made of actual drums - sound effects, all are pretty good, a little chunky and low bit-rate or low sample-rate sounding, there's probably something going on in the network that's reducing the rate before it gets build back up. There's a constant sort of reverb in all of the examples I honestly can't say I prefer their model over some of the musicgen output even if their model is doing a better job at following the prompts in some cases. All of the models have a very low bitrate encoding problems and other weird anomalous things. Some of it reminds me of the output from older mp3 encoders, where hihats and such would get very \"swishy\" sounding. You can hear some of it in the autoencoder reconstructions, especially the trumpet and the last example. However, in any case, I'm actually glad in some ways to see the progress being made in this area. It's really impressive. This was complete science fiction only a very few years ago. reply RobinL 3 hours agoparentprevHere is a silly song I generated using suno.ai, which I have found to be incredibly impressive (at least, a small percentage of its outputs are very good, most are bad). I think it's good enough that most humans wouldn't realise it's AI generated. https://app.suno.ai/song/8a64868d-9dd3-46db-91af-f962d4bec8b... reply npteljes 5 minutes agorootparentThat is fantastic. It has a bit of weirdness in the background, but nothing that would stop me from enjoying it. reply Agraillo 1 hour agorootparentprevVery good for my taste, but I should clarify, I'm obsessed with catchy tunes, as a listener and as a hobby musician, growing my own brainworms from time to time. And I must say that suno.ai is very impressive, in my case semi-ready brainworms are almost always in 30%-50% cases. And what's more important, it's really an inspiration tool for all kinds of tasks, like lyrics polishing or playing-along after track separation. Maybe catchy melodies are not for all, but who can argue with charts when The Beatles, ABBA and Queen were almost always producers of ones. reply urbandw311er 47 minutes agorootparentprevThat’s impressive. Why do the printed lyrics for the second chorus differ from the audio? (Which repeats those from the first chorus) reply RobinL 32 minutes agorootparentI generated the lyrics using ChatGPT 4 and the suno model attempts to follow them. It generally does a good job, but I have noticed it's fairly common in a second chorus for it to ignore the direction and instead use the same lyrics as the first chorus reply comex 1 hour agorootparentprevWow. I’m guessing it’s generating MIDI or something rather than synthesizing audio from scratch? Even so, the quality of the score is leaps and bounds better than any of the long-form audio on the Stable Audio demo page (either Stable Audio itself or the other models). The audio model outputs seem to take a sequence of 1 to 3 chords, add a barebones melody on top, and basically loop this over and over. When they deviate from the pattern, it feels unplanned and chaotic and they often just snap back to the pattern without resolving the idea added by the deviation. (Either that or they completely change course and forget what they were doing before.) Yes, EDM in particular often has repetitive chord structures and basic melodies, but it’s not that repetitive. In comparison, from listening to a few suno.ai outputs, they reliably have complex melodies and reasonable chord progressions. They do tend to be repetitive and formulaic, but the repetition comes on a longer time scale and isn’t as boring. And they do sometimes get confused and randomly set off in a new direction, but not as often. Most of the time, the outputs sound like real songs. Which is not something I knew AI could do in 2024. reply RobinL 33 minutes agorootparentI don't have any special insight into how it works, but I suspect it is largely synthesizing audio from scratch. The more I've thought about it, the task of generating music feels very similar to the task of text-to-speech with realistic intonation. So feels like the same techniques would be applicable. Suno do have an open source repo here that presumably uses similar tech: https://github.com/suno-ai/bark > Bark was developed for research purposes. It is not a conventional text-to-speech model but instead a fully generative text-to-audio model, which can deviate in unexpected ways from provided prompts. Suno does not take responsibility for any output generated. Use at your own risk, and please act responsibly. I've generated probably >200 songs now with Suno, of which perhaps 10 have been any good, and I can't detect any pattern in terms of the outputs. Here's another one which is pretty good. I accidentally copied and pasted the prompt and lyrics, and it's amazing to me how 'musically' it renders the prompt: https://app.suno.ai/song/d7bad82b-3018-4936-a06d-8477b400aae... Here are a couple more which are pretty good (i use it primarily for making fun songs for my kids): https://app.suno.ai/song/a308ca8a-9971-47a3-8bb3-a95126ff1a8... https://app.suno.ai/song/3b78a631-b52a-4608-a885-94f2edc190b... And this one's kindof interesting in that it can render 'gregorian chant' (i mean it's not very good): https://app.suno.ai/song/0da7502b-73cf-4106-88e8-26f4f465a5f... But this is one reason it feels like these models are very similar to text-to-speech but with a different training set reply otabdeveloper4 4 hours agoparentprevAI pictures are the same. We are more tolerant of six fingered-pictures with missing limbs, for some reason. reply ShamelessC 5 hours agoprevSo there aren't public weights, is that right? Having trouble finding anything that says one way or the other. edit: Oh okay, didn't realize this was somehow a controversial comment to make. It would have been great if you had answered the question before downvoting but that's fine I suppose. reply grey8 41 minutes agoparentNope. They did release code for training, inference and fine tuning, but no datasets or weights. See https://github.com/Stability-AI/stable-audio-tools reply ShamelessC 31 minutes agorootparentThanks! reply 8n4vidtmkvmk 5 hours agoprevThe music is pretty meh but the sound effects are exciting for indie game dev! reply AuryGlenz 2 hours agoparentToo bad according to their page you need an enterprise license for even indie games. reply nullandvoid 4 hours agoparentprevnext [–]reply ecmascript 1 hour agoprevJust a few days ago I was down voted for stating AI will be better in creating music than human would be: https://news.ycombinator.com/item?id=39273380#39273532 Now this is released and now I feel I got grist to my mill. Sure it still kind of sucks, but it's very impressive for a _demo_. Remember that this tech is very much in it's infancy and it's very impressive already. reply jpc0 3 hours agoprev> Warning: This website may not function properly on Safari. For the best experience, please use Google Chrome Do better reply pmontra 2 hours agoparentBy the way, it does work on Firefox Android. No idea of what there is in Safari that's not standard in Chrome and Firefox. reply popalchemist 3 hours agoparentprevHave you ever heard of an MVP? reply prmoustache 2 hours agorootparentThat would be pertinent if it wasn't just a static web page with just text and some audio files to be played. reply Aachen 2 hours agoparentprev...and recommend Firefox is what you meant to say right? :) reply andbberger 4 hours agoprevwake me up when it can write a fugue reply andrewstuart 4 hours agoprevI felt a great disturbance in the Force, as though all the music licensing lawyers in the USA all cried out at once. reply shon 4 hours agoparentPerhaps the disturbance you feel is actually the RIAA moving their Death Star into firing range of Stability.ai reply NoPedantsThanks 4 hours agoprevnext [10 more] [flagged] frizlab 4 hours agoparentI know right, what year is this? reply otabdeveloper4 4 hours agorootparentI do. It's year of the Google (c), like every year. (David Foster Wallace was wrong, there's no way a company of Google's caliber would settle for anything less than a whole decade.) reply shon 4 hours agorootparentIs it? To me it feels like Google is about where Microsoft was in 2002. Case in point: This thread about using anything other than Chrome… reply shon 4 hours agoparentprevWhat’s your preferred browser? reply otabdeveloper4 4 hours agorootparentAnything that isn't Chrome. reply DaiPlusPlus 4 hours agorootparentprevIf I could have my way, NCSA Mosaic. reply shon 4 hours agorootparentWish granted: https://archive.org/details/mosaic-ncsa-evolt_browsers reply XorNot 4 hours agoparentprevWorked fine in Firefox. reply consumer451 4 hours agorootparentAlso, worked fine in Safari mobile reader mode. reply webprofusion 1 hour agoprev [–] Music is perfect for AI generation using trained models, because artists have been copying each other for at least the past 100 years and having a computer do it for you is only notionally different. Sure a computer can never truly know your pain, but it can copy someone else's. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The website \"stable-audio-demo\" may not work correctly on Safari, and it is advised to use Google Chrome for optimal performance.",
      "The website offers code and tools related to Stable Audio, a model that can produce variable-length and long-form stereo music at a 44.1kHz sampling rate.",
      "Users can explore examples of generated stereo music and sound effects prompts on the website, along with comparisons to other cutting-edge models. Additionally, an evaluation of an autoencoder's audio fidelity capabilities is provided through reconstructions."
    ],
    "commentSummary": [
      "The discussion thread covers topics such as taxing revenue from generative AI for the arts, copyright concerns in the Stable Audio project, and the impact of licensing fees on open-source machine learning.",
      "Copyright laws and ethical implications in relation to AI training data are also discussed.",
      "There are discussions on alternative browsers, AI-generated music, the limitations and potential improvements in AI music generation, and observations on the Suno.ai music model."
    ],
    "points": 302,
    "commentCount": 100,
    "retryCount": 0,
    "time": 1707796252
  },
  {
    "id": 39353325,
    "title": "Nvidia Surpasses Amazon and Google, Becomes Most Valuable Tech Company",
    "originLink": "https://www.forbes.com/sites/dereksaul/2024/02/12/nvidia-is-now-more-valuable-than-amazon-and-google/",
    "originBody": "FORBESBUSINESS BREAKING Nvidia Is Now More Valuable Than Amazon And Google Derek Saul Forbes Staff I cover breaking news with a focus on markets and sports business. Follow Click to save this article. You'll be asked to sign into your Forbes account. Got it Feb 12, 2024,11:49am EST TOPLINE Nvidia’s market value surpassed those of fellow technology titans Amazon and Alphabet on Monday, an almost unbelievable feat accomplished as Nvidia’s stock more than quadrupled over the last 15 months as investors bought into Nvidia’s market-leading position in artificial intelligence. Nvidia stock's 17,000% runup over the last 10 years is far and away the best of any S&P 500 ... [+] GETTY IMAGES KEY FACTS Shares of Nvidia rose nearly 3% to an record high of over $740, bringing its market capitalization to $1.83 trillion, narrowly surpassing Alphabet’s $1.82 trillion and Amazon’s $1.8 trillion. The symbolic passing of the torch caps Nvidia’s remarkable journey as Wall Street flooded into the stock amid the AI boom. Nvidia’s market cap sat below $300 billion as recently as October 2022, just before the AI wave began to crest, lagging far behind Amazon and Alphabet’s above $1 trillion valuations at the time. Nvidia is now the fourth most-valuable public company in the world, trailing only Microsoft ($3.1 trillion), Apple ($2.9 trillion) and Saudi Aramco ($2 trillion). KEY BACKGROUND Nvidia is by far the most prominent producer of the semiconductor chip technology powering generative AI. Investors have been impressed not just by the potential for Nvidia to capitalize on the growing interest and corporate spending in AI, but also by its already exploding results. Nvidia’s earnings before interest, taxes, depreciation and amortization (EBITDA) expanded by more than 500% last quarter on a year-over-year basis thanks to runaway growth in its AI unit, far stronger than Amazon and Alphabet’s robust 20% or more earnings growth during the comparable period. Nvidia’s gross revenue and profits are less eye-popping than its trillion-dollar company peers – its $9.2 billion profit last quarter was far smaller than Apple’s and Microsoft’s over $22 billion profits during the comparable stretch – but analysts expect Nvidia’s financials to soon close the gap. Nvidia remains among the most popular stocks on Wall Street even after its more than 50% run-up this year, and is a top pick for analysts at both Goldman Sachs and Bank of America, each of which has an $800 price target for Nvidia, implying 8% further upside for the stock. SURPRISING FACT Nvidia stock’s 17,000% gain over the last decade is by far the best return of any stock on the S&P 500, nearly tripling the return of silver medalist and fellow chipmaker Advanced Micro Devices. A $1,000 investment in Nvidia a decade ago would now be worth about $175,000. WHAT TO WATCH FOR Nvidia will report earnings next Wednesday for its fiscal quarter ending last month. Analysts project the company to report its third consecutive quarter of record sales and profits. FURTHER READING MORE FROM FORBES Bigger Than Amazon? Nvidia Stock Surges After 'Cosmological' Profit Projections By Derek Saul MORE FROM FORBES Nvidia Is This Year's Hottest Stock. So Why Are Analysts Disappointed By Its 230% Gain? By Derek Saul Follow me on Twitter. Send me a secure tip. Derek Saul Follow I'm a New Jersey-based Senior Reporter on our news desk. I graduated in 2021 from Duke University, where I majored in Economics and served as sports editor for The ... Read More Editorial Standards Print Reprints & Permissions",
    "commentLink": "https://news.ycombinator.com/item?id=39353325",
    "commentBody": "Nvidia is now more valuable than Amazon and Google (forbes.com/sites/dereksaul)287 points by SeanAnderson 8 hours agohidepastfavorite288 comments behnamoh 7 hours agoSomehow I wish it weren't true because I hate monopolies in any markets. Nvidia has been enjoying their absurd premium on consumer and production GPUs and intentionally removed the NVLink capability in the GeForce 4090 series (3090 had them) to avoid cannibalizing their A100 and H100 business. With NVLink, people could chain multiple GPUs and increase the overall VRAM without much reduction in bandwidth. But without it, if you chain two 4090s, your effective bandwidth gets shrunk, so higher VRAM but much slower for LLM inference. I'm with Linus Torvalds on this—f*** NVidia. reply FredPret 7 hours agoparentI understand the sentiment. But the only reason you're mad at Nvidia is because they made something desirable (a GPU that does NN training) but didn't do it in the way you prefer (NVLink, Linux compatibility etc). It's not their fault AMD and others have been asleep at the wheel and handed them the whole market for free. Any company with a monopoly on the hot new thing would try to capitalize on it. When the other GPU makers eventually catch a wakeup, the situation will finally improve. reply benreesman 5 hours agorootparentI don’t have hard evidence of this, which makes it a thought experiment and not an assertion. Big-cap tech is utterly notorious for some of the worst anti-trust violations and other cartel-style behavior of any sector. This goes back as least as far as “Wintel” in the 90s and probably further that I didn’t watch up close. Suffice it to say that the Justice Department is extremely disincentivized to go after domestic economic Cinderella stories in a globally competitive world and has had to bring lawsuit after lawsuit on everything from bundling to threatening OEMs to flagrant wage fixing in print (I do have second-hand that the mass layoffs are coordinated aka Don’t Poach 2.0). Crippling “gaming” (high margin but not famine-price gouging margin) cards, controlling supply tightly enough to prevent the market clearing at MSRP routinely, stepping at least up to and likely over the line on the GPLv2: these things or things like them have been ruled illegal before (though it’s hard to imagine that happening again). It’s possible that tech is just a natural monopoly and we had it right with Ma Bell: innovation was high, customer prices were stable and within the means of most everyone, and investors got a solid low-beta return. It’s easy to view the past with rose-colored glasses and the Bell Era wasn’t perfect, but IMHO this status quo is worse. reply MichaelZuo 4 hours agorootparentTo be honest this just sounds like a bunch of talking points stuck together, can you write a credible argument based on known case-law/precedent/etc... if you have a legal angle to critique? reply mtsr 3 hours agorootparentSociety isn’t shaped just by current laws, but also by where we want things to go. If the current situations is undesirable, changing laws and regulations is the way to change it. (Of course actually enforcing current laws and regulations can also go a long way in many cases…) reply killingtime74 3 hours agorootparentSounds like it's just undesirable to you. (I don't own any Nvidia stock). Their growth to their current position in the market was organic. You don't just break down big companies for no reason other than them being big. If we did, there's a long line of companies ahead of Nvidia to be broken up first. reply fauigerzigerk 3 hours agorootparentprevSo what changes to the law do you propose? None of the little annoyances that Nvidia is occasionally creating amount to anything that could have resulted in their current dominance in AI processing. They made a good product. The competition is responding too slowly. And they got lucky with this crazy (in a good way) AI boom. I don't see how this could possibly be outlawed or why you would even want to. It will resolve itself on its own given enough time. reply qwertox 4 hours agorootparentprev> have been asleep I still don't see the required effort put into place by Intel together with AMD in order to create an attractive alternative to CUDA. Right now they're only only getting looks because their devices are cheaper for the hardware you get and for big projects because they're available, so you're required to have in-house experts who know how these platforms work in order to get stuff done that you know would definitely work on Nvidia. The games Nvidia is playing with the consumer market is really annoying, but we have to thank Intel and AMD that Nvidia is in a position to do this. Microsoft is probably also at fault. We're at a point where Apple only has to say \"Oh, one more thing, you can now put Nvidia GPUs in your Mac Pro\" for Intel and AMD to notice in what position they've put themselves into. reply lumost 4 hours agorootparentBig companies are weird. There are probably 10 teams each at intel, arm, and amd claiming that they can beat the h100 or build a better compute runtime. Half those teams are full of crap, a quarter will take the funds and try to do something like CUDA (but better) cough ROCm. Then another eighth to a quarter will simply not have the political clout to get the whole thing done. Add to this that we just funded 10 teams to get 1-2 functional teams… and you see why chasing after an incumbent is hard. Even when you have near infinite money to do so. reply jakogut 5 hours agorootparentprevUnfortunately, I think developers handed them the market too, it wasn't just the competition not being up to snuff. Developers valued their own development experience, features, and performance over value, efficiency, portability, openness, or freedom. The result is anyone depending on CUDA became vendor locked to Nvidia. Similar as the story with Direct3D, though thankfully there are workable solutions for D3D now implemented on top of Vulkan. Nvidia's CUDA moat may be less fordable. reply bmicraft 4 hours agorootparentJust today something very interesting came out: ZLUDA It's a reimplementation of cuda on top of rocm, and it's a drop in replacement you can use with already compiled binaries. It's even faster than native rocm/hip in blender reply sjwhevvvvvsj 5 hours agorootparentprevIf AMDs version of “asleep at the wheel” is them eating Intels lunch for the last few years, I’d hate to see them awake. Intel is weak, and it’s much smarter to put resources into squeezing Intel while they are on the ropes than shift too much focus to ML. reply namlem 5 hours agorootparentYeah exactly. AMD has other markets to compete in. Their desktop, laptop, and handheld offerings are incredible right now. I assume they are also going to replace Nvidia for the Switch 2. reply philistine 4 hours agorootparentNope. Nintendo is sticking with Nvidia. I'll eat my hat if they don't. reply FredPret 5 hours agorootparentprevI’m talking GPUs, not CPUs. reply ptero 4 hours agorootparentAnd he is saying AMD focusing on non-GPU markets and going from being a laughable underdog to a powerhouse hardly qualifies as \"being asleep at the wheel\". reply FredPret 4 hours agorootparentAlright, fair point, but that is also why they missed out on the AI boom. reply iraqmtpizza 3 hours agorootparentAs if it was just there for the taking. AMD doesn't have the money to do what Nvidia does reply latchkey 7 hours agorootparentprevAMD has figured it out and is in the process of catching up. It won't happen over night though. reply throwup238 6 hours agorootparentYeah we’ll have power positive fusion any day now. reply latchkey 6 hours agorootparentAzure, Oracle, Meta, Tesla, Hot Aisle... all buying up MI300x. https://www.cnbc.com/2023/12/06/meta-and-microsoft-to-buy-am... https://www.tomshardware.com/news/amd-scores-two-big-wins-or... https://www.tomshardware.com/tech-industry/artificial-intell... reply khazhoux 4 hours agorootparent> Azure, Oracle, Meta, Tesla, Hot Aisle... all buying up MI300x. You really should disclose that you’re a founder when you mention your company like that reply cko 3 hours agorootparentAviato reply latchkey 3 hours agorootparentI loved that show! reply latchkey 3 hours agorootparentprevIt is in my profile. Pretty well disclosed imho. reply abraae 3 hours agorootparentInsufficient disclosure. You must be aware that of the companies you listed, one (yours) sticks out as being unknown. Don't die on this hill, just do the decent thing and add a disclosure. This doesn't show you in a good light. reply latchkey 2 hours agorootparentNo hill to die on here. I did nothing wrong by mentioning my company. It is factual that I am buying these GPUs. There is nothing in the guidelines or faq on this topic. So, it is best that we conclude that you are making up some fake rule that you expect people to abide by and then claiming a weird superiority complex about how I am looking bad according to your made up rules. I do not need to tolerate that. Classic HN… getting downvoted by the silent minority. Would love to see how you deal with bullies. reply abraae 2 hours agorootparentI did not intend to be confrontational and you are correct that talking up your company without declaring your affiliation is not against HN guidelines. I feel it is however a convention that is widely followed and for good reasons. Obviously your call at the end of the day. reply sangnoir 37 minutes agorootparentTBF, they weren't \"talking up\" their company, they simply added the name to a list of companies doing something that's going against the grain. To quote Bill Burr roasting Apple, there's a bit of \"Einstein - Gandhi - Me\" going on, but its way below the threshold for identifying themselves as a founder, IMO. reply sufficer 50 minutes agorootparentprevMan you are wild. reply inemesitaffia 1 hour agorootparentprevYou've fe'd up reply matt_daemon 1 hour agorootparentprevGood way to ensure no one buys anything from your company. reply khazhoux 2 hours agorootparentprevIt is a norm here and a common courtesy to let people know whenever one mentions their own company, product, or project. Otherwise, we don’t know that a comment might be self-marketing. And yes, yours was an instance of self-marketing, even if unintentional, by name-dropping your company alongside power players like Meta and Tesla. You put yourself on people’s radar as a GPU-intensive company. reply throwup238 6 hours agorootparentprev“Meta and Microsoft say…” “Oracle is set to use…” “Elon Musk implies…” Not one of them have actually bought anything. AMD is just muddying the waters by grouping HPC sales with AI. It’s nonsense. Edit: I see you’ve got a startup on MI300x hardware. Now it makes sense, I guess - you need to believe. Good luck! reply mlyle 5 hours agorootparent> Not one of them have actually bought anything. AMD isn't shipping in large volume yet, but MI300x instances can be spun up in preview on Azure today with availability ramping up. Microsoft has absolutely bought a lot of MI300x. reply latchkey 4 hours agorootparentVideo proof: https://www.youtube.com/watch?v=AmJF2U6aqQ8 reply latchkey 4 hours agorootparentprev> I guess - you need to believe. Or maybe I know things you don't. =) reply SmokeyHamster 4 hours agorootparentprevIs that even logistically possible for rivals at this point? You think AMD doesn't want to carve out a chunk of that pie? What Nvidia is doing is hard and the engineers with the skill to design those chips are few far between. I'm sure Nvidia's already hired most of the best in the business. Anyone who wants to unseat Nvidia will need very talented people, who aren't cheap, and that means massive investment capital which largely doesn't exist. reply ActorNightly 2 hours agorootparentIf you look at graphics performance, AMD already is pretty much on par with Nvidia. All of the math with graphics and ML is largely the same. The thing that is missing is AMD focusing their software engineers that develop the drivers, and making them put work into RoCM to make it usable across all cards, all driver versions, like with NVIDIA. reply llm_trw 7 hours agorootparentprevThere is _one_ other GPU maker. reply akmittal 7 hours agorootparentThey don't even take themselves seriously reply throwoutway 7 hours agorootparentI'd say they took themselves too seriously, and rested on their high margin laurels for too long reply __float 7 hours agorootparentprevIntel makes desktop cards too reply PostOnce 6 hours agorootparentand they have more memory bandwidth (per dollar) and more VRAM per dollar the trajectory looks good if they can just resist giving up early without seeing instant success reply giantg2 6 hours agorootparent\"just resist giving up early without seeing instant success\" Sounds like I've been doing life wrong. reply ergocoder 6 hours agorootparentprevWhat the hell is intel doing? I have been holding their stock for a few years now. Where is the moon? reply nealabq 5 hours agorootparentASML recently delivered their first high-NA lithography system to Intel. While TSMC is being more cautious, hesitating to commit to this very expensive machine. Intel's making a big bet, and it may (or may not) pay off. We'll probably know by the end of 2025. Intel may end up back on top. https://www.asml.com/en/news/press-releases/2022/intel-and-a... https://www.datacenterdynamics.com/en/news/intel-receives-it... https://www.tomshardware.com/tech-industry/manufacturing/tsm... reply newsclues 6 hours agorootparentprevHoping to build chips for others as they open their foundry business up reply philistine 4 hours agorootparentprevIntel, AMD, Apple? reply oblio 3 hours agorootparentApple's not super relevant for a mass market OEM type of discussion. reply ij09j901023123 6 hours agorootparentprevThe only people that buy AMD GPUs are gamers; AMD have long since stopped targeting the enterprise side of their GPU market. NVIDIA makes the majority of their profits by selling A1000+ cards to businesses that require the power for computation (video rendering, LLM processing, etc). AMD neglected and disregarded productivity, and now they are paying the consequences. reply quickslowdown 6 hours agorootparentprevAMD being asleep at the wheel, or choked out by the Intel + Nvidia cartel? reply thfuran 6 hours agorootparentprev>Any company with a monopoly on the hot new thing would try to capitalize on it. So what? \"Any company with a monopoly\" would also pay children in company scrip to work 20 hours a day in unsafe factories unless compelled to do otherwise. reply jayd16 6 hours agorootparentprev\"You're only upset because they \" reply selectodude 6 hours agorootparentYou using your market advantage to exploit your employer or do you feel like you’re being paid a fair amount? reply jayd16 6 hours agorootparentI have exploitable market advantage? Explain. reply selectodude 5 hours agorootparentDo you work in tech in the United States? Congratulations, you’re one of the wealthiest people on the planet. That’s one hell of a market advantage. reply iraqmtpizza 2 hours agorootparentNothing like what it would have been without a non-stop flood of H-1Bs reply eru 6 hours agorootparentprevI'm not sure you can trust the (would-be) exploiters opinion on whether the amount they are being paid is 'fair'? reply FredPret 6 hours agorootparentprevThey gained market advantage by creating something that delights consumers. I'd call that a net win. reply jayd16 3 hours agorootparentThe complaint is about losing those delights now that the market is secured by software lockin. The bait and switch. reply iraqmtpizza 3 hours agorootparentprevAny evidence that the much less well-funded AMD has been \"asleep at the wheel\" w.r.t. the GPU market? Without going practically all-in on Zen, they'd be bankrupt. reply refurb 5 hours agorootparentprev> But the only reason you're mad at Nvidia is because they made something desirable This is true. It's like blaming the company for being successful. \"Stop making products that are so much better than any other product\". I'm not sure we want that? reply matwood 2 hours agorootparentNot dissimilar from the conversations around Apple. They have made products so much better than any of the competitors people want to force them to change. reply lukeschlather 7 hours agoparentprevI don't think Nvidia is worried about cannibalizing their A100 and H100 business, I think they're trying to keep the cards something resembling affordable for gamers. reply AnthonyMouse 6 hours agorootparentThen why wouldn't they just make more of them? The excuse is supposed to be fab capacity, but the 3070 has better performance than the 4060 etc. and is built on the older process which should no longer be in short supply. reply aurareturn 6 hours agorootparentThen why wouldn't they just make more of them? The excuse is supposed to be fab capacity, but the 3070 has better performance than the 4060 etc. and is built on the older process which should no longer be in short supply. There is actually very little margins in the midrange consumer discrete GPU market. The market for discrete GPUs have been shrinking since the mid 2000s.[0] Most GPUs are sold as integrated such as SoCs and in consoles nowadays. In a shrinking market, the midrange and low-end products will cease to be profitable. Hence, Nvidia's 60/70 offerings are lackluster because they don't make much money from them. They want you to buy the 80s and 90s cards. Furthermore, node advancements have stopped scaling $/transistor. So the transistors aren't getting cheaper, just smaller. Lastly, Nvidia wants to allocate every last wafer they pre-purchased from TSMC to their server GPUs. [0]https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1... reply AnthonyMouse 5 hours agorootparent> Most GPUs are sold as integrated such as SoCs and in consoles nowadays. But those are mostly AMD, and doesn't really have anything to do with what features someone puts on their discrete gaming cards, except insofar as it implies gamers don't need the cards some amateur ML hobbyist might buy. > In a shrinking market, the midrange and low-end products will cease to be profitable. That's assuming the products have high independent development costs, but that isn't really the case. The low end products are essentially the high end products with fewer cores which use correspondingly less silicon -- which have higher yields because you don't need such a large area of perfect silicon or can sell a defective die as a slower part by disabling the defective section, making them profitable with a smaller margin per unit die area. > Furthermore, node advancements have stopped scaling $/transistor. So the transistors aren't getting cheaper, just smaller. Which implies that they can profitably continue producing almost-as-good GPUs on the older process node. > Lastly, Nvidia wants to allocate every last wafer they pre-purchased from TSMC to their server GPUs. Which is why the proposal is for them to make as many GPUs as the gamers could want at Samsung. reply aurareturn 5 hours agorootparentCustomers who want midrange or low end GPUs are price sensitive. Therefore, midrange and low end GPUs are a low margin business. Hence, there's little to no reason to provide a very compelling product in those categories. While midrange GPUs are a cut from highend GPUs, they're still significantly more expensive to manufacture than say CPUs, at a transistor to transistor level. Look at an AMD 7950x transistor count, and then an RTX 4060 transistor count. The GPU has ~50% more transistors but sell at half the price. In addition, the GPU requires RAM, a board, circuitry, and a heatsink fan. The margins simply aren't there for lowend GPUs anymore. Previously, Nvidia and AMD can make it up through volume. But again, the market has gotten much smaller going from 60 million discrete GPUs per year sold to 30 million. That's half! Based on your logic, AMD should feast on midrange and low end discrete GPU market because Nvidia does not have value products there. But AMD isn't feasting. You know why? Because there's also no profit there for AMD either. Once you stop thinking like an angry gamer, these decisions start to make a lot of sense. reply AnthonyMouse 3 hours agorootparent> Customers who want midrange or low end GPUs are price sensitive. Therefore, midrange and low end GPUs are a low margin business. Customers who want petroleum are price sensitive. Therefore, petroleum exporting is a low margin business. This is why the Saudis make the profit margins they do. Wait, something's not right here. > Look at an AMD 7950x transistor count, and then an RTX 4060 transistor count. The GPU has ~50% more transistors but sell at half the price. You're comparing the high end CPU to the mid-range GPU. The AMD 8500G has more transistors than the RTX 4060 and costs less. > In addition, the GPU requires RAM, a board, circuitry, and a heatsink fan. The 8500G comes with a heatsink and fan. The 8GB of GDDR6 on the 4060 costs $27 but the 4060 costs $120 more. A printed circuit board doesn't cost $93. > Previously, Nvidia and AMD can make it up through volume. But again, the market has gotten much smaller going from 60 million discrete GPUs per year sold to 30 million. That's half! That's not because people stopped buying them, it's because they shifted production capacity to servers. > Based on your logic, AMD should feast on midrange and low end discrete GPU market because Nvidia does not have value products there. But AMD isn't feasting. You know why? Because there's also no profit there for AMD either. But they do though. You can find lower end AMD GPUs from the last two years for $125 (e.g. RX 6400) whereas the cheapest RTX 3000 or 4000 series is around twice that. And anyway who is talking about the bottom end? The question is why they don't produce more of e.g. the RTX 3070, which is on the old Samsung 8LPP process, has fewer transistors than the RTX 4060, is faster, and is still selling for a higher price. reply aurareturn 3 hours agorootparentAnd anyway who is talking about the bottom end? The question is why they don't produce more of e.g. the RTX 3070, which is on the old Samsung 8LPP process, has fewer transistors than the RTX 4060, is faster, and is still selling for a higher price. What do you think? I gave you my reasons. Why don't you take a crack at your own question? There has to be a logical business reason right? Customers who want petroleum are price sensitive. Therefore, petroleum exporting is a low margin business. This is why the Saudis make the profit margins they do. Wait, something's not right here. One is a commodity. The other is about as high tech as it gets. Completely different economic rules that govern these products. You're comparing the high end CPU to the mid-range GPU. The AMD 8500G has more transistors than the RTX 4060 and costs less. The 8500G comes with a heatsink and fan. The 8GB of GDDR6 on the 4060 costs $27 but the 4060 it costs $120 more. A printed circuit board doesn't cost $93. One has an entire board that needs soldering, assembled by a manufacturing line, tested with many parts, and a team of dedicated engineers optimizing drivers constantly. The other is a CPU that is machine tested, and shipped with a heatsink fan unattached. Come on now. That's not because people stopped buying them, it's because they shifted production capacity to servers. That's not true. The discrete GPU market has been shrinking for 14 years straight with some crypto boom years here and there. See the chart I posted previously. Fewer and fewer people are buying discrete GPUs But they do though. You can find lower end AMD GPUs from the last two years for $125 (e.g. RX 6400) whereas the cheapest RTX 3000 or 4000 series is around twice that. AMD cards do not \"feast\" on low-end and midrange. According to Steam charts, Nvidia still dominates midrange cards.[0] Furthermore, when I said \"feast\", I meant making profits. AMD does not make much profit from midrange or low end cards. The bottom line is, you keep wondering why no one is offering compelling value in the midrange area but there's a very obvious reason why: profit is not there. [0]https://store.steampowered.com/hwsurvey/videocard/ reply AnthonyMouse 2 hours agorootparent> Why don't you take a crack at your own question? There has to be a logical business reason right? Selling 30M GPUs with a huge margin is more profitable than selling 60M GPUs with a modest margin, and they can point to Bitcoin or AI as an excuse. But also, we're talking about them crippling the cards \"for gamers\" so there will be cards \"for gamers\" -- the premise of this has to be that they're supply constrained (artificially or otherwise) because otherwise they would just make more at the evidently profitable price gamers are already paying. It can't be a lack of demand because the purpose of removing the feature is to suppress demand (and shift it to more expensive cards). > One is a commodity. The other is about as high tech as it gets. Completely different economic rules that govern these products. So you're saying that if a high tech product only has a limited number of suppliers then they could charge high margins even if customers are price sensitive. > One has an entire board that needs soldering, assembled by a manufacturing line, tested, with many parts, and a team of dedicated engineers optimizing drivers constantly. The other is a CPU that is machine tested, and shipped with a heatsink fan unattached. Come on now. GPU manufacturing is automated. The CPU heatsink isn't attached because it mounts to the system board, not because attaching it would meaningfully affect the unit price. Driver development isn't part of the unit cost, its contribution per unit goes down when you ship more units. You can buy an entire GPU for the price difference between the 8500G and the RTX 4060. > That's not true. The discrete GPU market has been shrinking for 14 years straight with some crypto boom years here and there. See the chart I posted previously. That's only because you're limiting things to discrete GPUs and customers have increasingly been purchasing GPUs in other form factors (consoles, laptops, iGPUs) which have different attachment methods but are based on the same technology. > According to Steam charts, Nvidia still dominates midrange cards. Steam is measuring installed base. That changes slowly, especially when prices are high. > Furthermore, when I said \"feast\", I meant making profits. AMD does not make much profit from midrange or low end cards. They make a non-zero amount of profit, which is why they do it. reply aurareturn 2 hours agorootparentI think you answered your own question, really. Although I would modify your statement slightly: Original: Selling 30M GPUs with a huge margin is more profitable than selling 60M GPUs with a modest margin. Modified: Nvidia and AMD must sell at a higher ASP because the market for discrete GPUs has shrunk from 60m to 30m/year. That's your answer! It's what I've been arguing for since my very first post. It isn't Nvidia and AMD's choice to have the market shrink in terms of raw volume. It's because many midrange gamers have largely moved onto laptops, phones, and consoles for gaming since 2010. The remaining PC gamers are willing to pay more for discrete GPUs. Hence, both Nvidia and AMD don't bother making compelling midrange GPUs. I remember midrange GPUs that have great value such as the AMD HD 4850. I don't think those days are ever coming back. reply ksec 4 hours agorootparentprev>and is built on the older process which should no longer be in short supply. I am not sure where that idea came from. It is from Samsung 8nm Fab. It never had the capacity to play with in the first place. Especially when Samsung Foundry is upgrading to chase with leading node. reply AnthonyMouse 3 hours agorootparentIn general you want to upgrade your oldest fab to the newest node, or build a new one, instead of shutting down a recent one and taking it out of production even though there is still demand for that node. There are still plenty of things being produced in fabs with older technology than that. Global Foundaries is the third largest in the world and they're offering 12nm or worse. People buy it because not everything needs a node which less than six months old and the price is right. reply ksec 2 hours agorootparentYes. But that is specific to GF and TSMC when you have recurring customer on older node. Which is not true for Samsung Foundry. reply AnthonyMouse 2 hours agorootparentWhy is it different? Wouldn't Samsung prefer to build new fabs rather than retrofitting old ones given the demand, since they would then have more customers and make more money? reply autoexec 6 hours agorootparentprevIs it an issue of supply? I figure they think non-gamers will be willing and able to pay far more for their hardware than most gamers could ever afford. If they sold comparable products to gamers at a low price the non-gamers would just end up buying them up and even if there was enough supply to satisfy the needs of everyone Nvidia would still be out a fortune. It'd be better for them to sell low priced gaming cards that would perform poorly for non-gaming purposes and sell extremely high priced specialty cards to the people who want to use them for AI or crypto or whatever other non-gaming uses they come up with. That'd at least keep the price of video cards low for gamers, avoid supply issues, and allow nvidia to extract massive amounts of profit from companies with no interest in video games. The only downside would be that it makes it harder for anyone who doesn't have deep pockets to get into the AI game. reply AnthonyMouse 6 hours agorootparent> If they sold comparable products to gamers at a low price the non-gamers would just end up buying them up and even if there was enough supply to satisfy the needs of everyone Nvidia would still be out a fortune. That's the point. They're not trying to do gamers a favor, if it was that they'd just make more cards. What they're trying to do is market segmentation, which customers despise and resent. reply creato 3 hours agorootparentI don’t know, in the world you want, gamers don’t have GPUs, and NVIDIA has less money. The only winners are people buying hardware for data centers. reply AnthonyMouse 3 hours agorootparentThey could leave the connector on the GPUs and then make more of them. Then everybody has more GPUs and everybody wins except Nvidia. Or to put it the other way, in the status quo everybody loses except Nvidia. reply solardev 6 hours agorootparentprevThey used to do this with the Quattro workstation cards. What happened to those? reply mr_toad 4 hours agoparentprevNvidia purportedly enjoys a 1000% profit margin on H100’s. https://www.tomshardware.com/news/nvidia-makes-1000-profit-o... reply SideQuark 1 hour agorootparentOnly by ignoring all upfront costs, as also mentioned in the article. Marginal profits need to be high when upfront costs are huge. reply epivosism 1 hour agorootparentprevI think that is actually the markup number. Profit margin is capped at 100% since you can't profit by more than you sell something for. reply acchow 5 hours agoparentprevBig tech and AI startups would buy all the 4090's in existence if they had NVLink. You would not be able to find one for gaming without a multiple x markup reply eastbound 3 hours agorootparentSo we’re deeply hampering our AI startups, limiting their growth and possibilities by jacking up the prices x10, to reserve some silicium only for gamers which could perfectly be used for AI? Maybe gamers can wait and the next technological leap should have priority? reply imhoguy 2 hours agorootparent> jacking up the prices x10 AI is goldrush and Nvidia is selling golden shovels. They try to play it longterm though. Goldrush ends at some point, if they upset \"gardeners\" gamers, these may be jumping onto AMD or even Intel shovels already. That was already the case during Bitcoin goldrush. But I wouldn't be also surprised this is a plan agreed at closed door meetings between big corporations. They may want to just kill any independent AI advantage, and force everyone to their cloud walled gardens. Future will tell. reply blitzar 16 minutes agorootparentprevWon't somebody think of the crypto miners. reply FloorEgg 1 hour agorootparentprevYeah I guess to hell with all those people who are building the next generations of games and gaming platforms, and the millions of people who are looking forward to them. Let's sacrifice all their purpose and enjoyment so your AI startup can get cheaper hardware and push out some AI product no one wants, just so it can go out of business anyway when the VC money runs out. reply oblio 3 hours agorootparentprevThis is a ridiculous argument. People need entertainment, too, we're not machines. If the current ML craze is really that impactful, it will happen regardless. If it can't break through it's because most of it is just a bunch of hot air. reply guappa 2 hours agorootparentprev> the next technological leap should have priority? lol reply wastewastewaste 3 hours agorootparentprevlet the startups do some work on their own for once lol reply pdntspa 3 hours agoparentprevNN research and crypto assholes ruined the market for gaming graphics. I'm glad NVlink was taken out. reply MuffinFlavored 7 hours agoparentprev> Somehow I wish it weren't true because I hate monopolies in any markets. If you peel the layers back... isn't the real monopoly ASML? reply wbsun 7 hours agorootparentI am always wondering why ASML hasn’t got any antitrust lawsuits for their monopoly. reply dralley 6 hours agorootparentBecause they're not a monopoly based on anticompetitive practices, they're a monopoly because what they do is so difficult and massively expensive that the monopoly is the only thing that makes it economically viable. The worldwide market for these machines is only perhaps a few dozen a year at most, it just can't support paying the R&D bills of multiple competitors. ASML is also part-owned by their customers. Intel, Samsung and TSMC all invested in ASML to get EUV tech over the line - see aforementioned capital requirements. reply pbmonster 1 hour agorootparentAlso, it's only really a monopoly at the top end, and only right now. It's not like ASML is the only company building litho machines. Canon and Nikon still sell a lot of machines, they just decided not invest to much into competing at the top end over the last 10 years. This could, theoretically, change at any moment, and Canon is trying something with their new generation of nano-print tech. reply blackoil 6 hours agorootparentprevINAL. Antitrust is not against monopoly, but monopoly \"abuse\". MS is free to make an OS which everyone wants and free to be a monopoly. When they tried to leverage it to gain market share in the distinct market of browser and media players it became a problem. So till ASML starts abusing the position they should be good legally. reply eru 6 hours agorootparentWatch out, different jurisdictions have different 'anti-trust' laws. And, especially in common law jurisdictions, interpretations of a law can also change over time. reply rezonant 6 hours agorootparentWho's this warning for? Do we have any budding monopolists in the HN crowd who need the warning? reply eru 4 hours agorootparentThe warning is for armchair speculators like you and me. Specifically: > Antitrust is not against monopoly, but monopoly \"abuse\". So this might be true about anti-trust in the US right now. But I'm not sure whether it's true about ant-trust law in eg France? Also, in practice this was not true about anti-trust law in the US historically: Standard Oil was smashed into pieces without anyone proving in court that consumers had been harmed, or that the monopoly had been 'abused'. See eg https://fee.org/articles/the-myth-that-standard-oil-was-a-pr... and https://www.econlib.org/library/Enc/Antitrust.html reply blackoil 6 hours agorootparentprevMaybe for not lawyers like me who pretend to be expert in everything :| reply eru 4 hours agorootparentYes, sort-of. But no worries: in a democracy we expect ordinary people to have some interest in the laws, after all, they are supposed to be electing people who decide on how laws should be changed (or not). So layman need to talk about laws, too. I'm just always a bit cautious (or at least I should be). I know that eg in the US insider trading is about stealing secret from your employer; but in eg France insider trading is about having an unfair advantage over the public. I can image that there are jurisdictions that treat monopolies by themselves as a problem. (Perhaps France, again?) Btw, for the US herself have a look at https://fee.org/articles/the-myth-that-standard-oil-was-a-pr... to see how the prototypical case against Standard Oil wasn't really about monopoly abuse, either. At least no one really bothered proving that a monopoly was abused, they mostly just assumed it. reply renewiltord 4 hours agorootparentprevEveryone's learning to talk like a GPT. reply eru 4 hours agorootparentEh, I was already uncool before GPT came around. reply renewiltord 3 hours agorootparentThen perhaps it's the other way around and you're the reason I'm sometimes warned by LLMs that I shouldn't kill processes. reply pests 6 hours agorootparentprevAloca :( reply mikewarot 6 hours agorootparentprevThe relevant EU Law[1] seems to be \"Any abuse by one or more undertakings of a dominant position within the common market or in a substantial part of it shall be prohibited as incompatible with the common market insofar as it may affect trade between Member States.\" So, as long as it treats fabs in Europe fairly, it can do whatever it wants in the rest of the world. [1] https://en.wikipedia.org/wiki/European_Union_competition_law reply linksnapzz 6 hours agorootparentprevBecause the patents that they have for their deep EUV tooling are...licensed property of the US DoE. Someone doesn't want that disturbed. reply docandrew 6 hours agorootparentprevHave they actually engaged in anticompetitive behavior or are they just the only player? reply eru 6 hours agorootparentWell, that would be for a judge (or jury?) to decide, if someone sued. reply sjwhevvvvvsj 5 hours agorootparentprevthe answer is it’s a state sanctioned monopoly which concentrates control of advanced technological processes in the hands of NATO. ASML is a strategic asset. reply dehrmann 4 hours agorootparentprevI'm not sure if this is the motivation, but any sort of action against ASML would give Chinese fabs time to catch up. reply ksec 4 hours agorootparentprevI hope you are not being serious and it is missing /s somewhere. reply renewiltord 4 hours agorootparentprevThey're not the only lithography machines, just the only EUV lithography machines. It's not a crime to have a better product. reply kimixa 4 hours agoparentprevDesign and development-limited tech loves economies of scale. Stuff like software is functionally free per-unit past the development, hardware still scales very well as per-unit costs are a smaller proportion of the end unit cost (and much of their advantages is also in software, like CUDA and DLSS etc.). The steam survey suggests that Nvidia have over 90% of the GPU market, so for every design they sell somewhere near 10x the number of units, so if they sell at the same margins they get 10x the development resources per unit. That's a lot of slack to lose to business inefficiencies, or competing with more specialized but smaller market devices. Assuming they don't just purchase such possible competitors when they pop up. It may be that a monopoly is the \"natural\" end state of such tech markets. I think it's self-evident this isn't a good end state for consumers. reply foobiekr 2 hours agoparentprevNvidia’s value is completely out of line with their revenue and eventually that will catch up with them. reply leetcrew 3 hours agoparentprevI don't love nvidia, but this is not the example I would choose to show why. cutting edge hardware exists at prices that are affordable for hobbyists largely because a few key features for commercial use cases can be \"artificially\" turned off. it sucks that you don't get to pay consumer prices for your highly lucrative application anymore, but the alternative looks a lot more like \"tensor prices for geforce skus\" than \"geforce prices for tensor skus\". we are already seeing this play out with crypto mining to an extent. I'd hate to see what would happen to the consumer market if AWS could just buy a bunch of RTX parts to rent out. reply up2isomorphism 4 hours agoparentprevBut all Linux’s arch enemies are becoming more and more lucrative: Microsoft, apple, Nvidia. Actually less evil one s like Sun died. In fact these companies are so dominating now largely thanks to Linux and open source software. reply ksec 4 hours agoparentprev>Nvidia has been enjoying their absurd premium on consumer This has been running wild on the Internet. If anything Nvidia has arguably earned less premium in the consumer market with most of the initial R&D cost being amortised with their AI / datacenter chips. reply pavelstoev 6 hours agoparentprevYou can do this in software, effectively. reply system2 7 hours agoparentprevAMD is not too far behind. They can go wild in a few years. reply behnamoh 7 hours agorootparentIn the LLM world, each month is a year and each week is a month. AMD hasn't done anything substantive in the past two years since GPT-3/GPT-3.5. Almost every research paper implements their algorithm in CUDA. AMD can't beat software with good hardware. reply brucethemoose2 7 hours agorootparentThere's more ROCm compatibility than you'd think. I'm at a startup, and we'd love to be using MI300Xs. Out stack works with it, they are amazing, our wallet is open... But we can't! We simply can't find any. It seems they are unobtanium for megacaps only. reply HWR_14 6 hours agorootparentprevDidn't AMD just commit to a CUDA compatible api? Did I hallucinate that? reply lhl 6 hours agorootparentWell, you probably read a inaccurate headline about it. The project is called ZLUDA https://github.com/vosen/ZLUDA and it had a recent public update because of the opposite - AMD decide not to continue sponsoring work on it: > Shortly thereafter I got in contact with AMD and in early 2022 I have left Intel and signed a ZLUDA development contract with AMD. Once again I was asked for a far-reaching discretion: not to advertise the fact that AMD is evaluating ZLUDA and definitely not to make any commits to the public ZLUDA repo. After two years of development and some deliberation, AMD decided that there is no business case for running CUDA applications on AMD GPUs. > > One of the terms of my contract with AMD was that if AMD did not find it fit for further development, I could release it. Which brings us to today. It's worth noting that while ZLUDA is a very cool project, it's probably not so relevant for ML. Also from the README: > PyTorch received very little testing. ZLUDA's coverage of cuDNN APIs is very minimal (just enough to run ResNet-50) and realistically you won't get much running. > However if you are interested in trying it out you need to build it from sources with the settings below. Default PyTorch does not ship PTX and uses bundled NCCL which also builds without PTX: PyTorch has OOTB ROCm support btw and while there are some CUDA-only libraries I'd like (FA2 for RDNA, bitsandbytes, ctranslate2, FlashInfer among others), I think sponsoring direct porting/upstreaming compatibility of the libraries probably makes more sense. Also from the ZLUDA README: > ZLUDA offers limited support for performance libraries (cuDNN, cuBLAS, cuSPARSE, cuFFT, OptiX, NCCL). reply tomoyoirl 6 hours agorootparentprevIf you mean the one posted here earlier today, I believe that article was more like “we paid a contractor to implement this, and then decided not to use it, so per our terms it’s open source now.” reply dartos 6 hours agorootparentprevAMD has rocm and added a CUDA compat layer to it. Nvidia is in the limelight, but their product (GPU compute) is a commodity. Once someone else has it cheaper, then it’s a race to the bottom. reply pests 6 hours agorootparentThey did not add a compat layer, where did you get this? The recent news was about AMD giving up on that path. reply dingi 5 hours agorootparentprevOh please, AMD's offerings are worse than Nvidia's in every imaginable way except the open source nature of their Linux drivers. ROCm is shit. Nvidia actually supports CUDA on almost any Nvidia card. ROCm not so much. reply ralph84 7 hours agoprevNvidia is still run by a founder, while the other two aren’t. I’d always bet on a founder over a McKinsey consultant or a Harvard MBA. reply JoshTko 7 hours agoparentThis is a silly take the two largest companies are headed by non founder MBA grads. Each who grew their respective companies ~10x. reply rezonant 6 hours agorootparentMeanwhile I'm of the opinion that Google started it's slide downhill during Larry Page's time as CEO. Somewhat ironically, I think Google's brightest days had Eric Schmidt (MBA, \"adult in the room\") as CEO. This isn't to say MBAs are always a good thing either, and certainly Google isn't a typical example. reply VirusNewbie 4 hours agorootparentEric Schmidt started his career as a hacker at Bell Labs. He is an MBA in name only. reply gregw134 2 hours agorootparentBell labs, xerox parc, and sun microsystems. Quite the technical resume. >Early in his career, Schmidt held a series of technical positions with IT companies including Byzromotti Design, Bell Labs (in research and development),[19] Zilog, and Palo Alto Research Center (PARC). During his summers at Bell Labs, he and Mike Lesk wrote Lex,[23][7] a program used in compiler construction that generates lexical-analyzers from regular-expression descriptions. Sun Microsystems In 1983, Schmidt joined Sun Microsystems as its first software manager.[19] reply Retric 6 hours agorootparentprevWhich is underperforming compared to Nvidia. It’s not that founders are more skilled, it’s that successful ones who stick around have different priorities. The long term performance of their existing stock is worth more than hitting targets. Not a guarantee of success, but something to consider. reply magicalist 5 hours agorootparent> It’s not that founders are more skilled, it’s that successful ones who stick around have different priorities. The long term performance of their existing stock is worth more than hitting targets. We're still talking about the current first derivative of their stock price. Let's not go overboard reading those tea leaves. reply Retric 5 hours agorootparentThe market is pricing in those tea leaves. Look at the P/E ratios of Nvidia (95) and Facebook (31) vs Apple (29) and Google (25). reply outside415 2 hours agorootparentPE is stupid. at least do forward PE or DCF... cmon. reply Wohlf 6 hours agoparentprevThere's plenty of founders who ran their companies in to the ground, and even more who never got it off the ground in the first place. There's no guaranteed recipe for success. reply Jensson 6 hours agorootparentWe are talking successful founders here, that is a very different group from all founders. > There's no guaranteed recipe for success. Yes, which is why he said bet on, not know it will win. reply hasmanean 7 hours agoparentprevWell a founder can make decades long bets. Any other company would have had an annual review of progress or a review any time mid-level leadership changed hands. Assuming a 50/50 chance of survival each time, the odds of the project lasting 10 years would be 1 in 1024. reply kdnvk 5 hours agoparentprevWhat a minor thing to extrapolate into your world model. reply __loam 6 hours agoparentprevI will never understand the culture of founder worship. reply beebmam 7 hours agoprevIt seems deeply overvalued to me, as it's pretty likely that NVIDIA's competitors will have parallel computation hardware that competes well enough. I'm personally not a fan of NVIDIA's drivers or the reliability of their hardware. reply dave_sullivan 7 hours agoparent> I'm personally not a fan of NVIDIA's drivers or the reliability of their hardware. As compared to AMD or Intel? I wish there was real competition to Nvidia but there isn't. I'm not a fan of their defacto monopoly but they do have the best product on the market and their competition has been asleep for 10 years. AMD and Intel barely knew what deep learning was 10 years ago (and certainly did not appreciate the opportunity) and Nvidia was already investing heavily. reply TillE 4 hours agorootparentTen years ago, Intel was the leader in chip fabrication technology. Things can change fast. Intel has already been making good low-end GPUs (with lousy but rapidly-improving drivers). If they're smart, they'll keep at it. reply HDThoreaun 5 hours agorootparentprevAs compared to a hypothetical product that is better than whats available today. With literally a trillion dollars on the line I find it very difficult to believe no one will come and scoop this opportunity up. The real value in GPUs is the datacenter segment which largely didnt exist, certainly not in that state it is today before the LLM take off. Takes time to develop products but theyll arrive eventually. reply rezonant 5 hours agorootparentWell there's not really a trillion dollars on the line. This is a valuation, not revenue. All this says is that AI and LLMs are extremely over hyped, and the market believes Nvidia's tech is the only viable supplier of the platform LLMs run on. These are things we already knew, so it's not surprising the market is quadrupling what it thinks Nvidia is worth. reply HDThoreaun 5 hours agorootparentYes there is a trillion dollars on the line here. Market cap is what matters to investors end of the day, everything else is just influencing it. Yes the market is saying Nvdia is the only supplier for AI and LLM hype, but its also saying they will continue to be the only supplier long term and that seems deeply flawed to me. reply rezonant 4 hours agorootparentWhile there's certainly a feedback cycle involved, market cap is decided by investors in the large. The stock price is just reflecting buys and sells of those investors. People believe AI has a lot of money and hype in it, and Nvidia supplies necessary equipment for AI, so they buy Nvidia. As a result the stock price goes up, and the market capitalization goes up accordingly. As a thought experiment, imagine buying 50% of a company on the open market and then seeing the price go up accordingly as the market does, then saying it must be even more valuable than I thought! And buying the other half of the company at the higher price. You caused that \"value\" by buying. No one investor has a trillion dollar opportunity, and no competitor does either. Making an assumption that a competitor will come along and zero out Nvidia because they have a better AI chip is not rational. For one the value of Nvidia isn't solely based on this, and by the time you've made your AI chip the market is going to have changed. Considering how insanely inflated the public's expectations of what LLMs can do, despite the fact that they are only a mirage of intelligence, it would probably be foolhardy to build a new AI chip to replace them. I suppose for AMD they could see their stock increased by such a margin if they could just produce a chip that convinced the market, but were they not already trying to do that? reply pas 7 hours agorootparentprev> Nvidia was already investing heavily that sounds very interesting, can you link/share/describe some details on it? how much did they invest? how? into CUDA? what else? reply dave_sullivan 7 hours agorootparentMy statements based on high level meetings I had at the time with all 3 companies when I had started an early neural network PaaS company and was looking for them to invest. Nvidia knew what they were talking about and were already moving that direction, Intel heard about deep learning somewhere but didn't believe there was anything there, and AMD didn't know anything about anything. reply wslh 7 hours agorootparentSeems like a tale already told on \"Only The Paranoid Survive\" by Andrew Grove. Now Jensen should add some chapters. BTW I just discovered that their web page/brand is fully invested in AI, the title is: \"World Leader in Artificial Intelligence Computing\". I am curious about your PaaS because we were analyzing that business for fun first. A small thread here in HN: https://news.ycombinator.com/item?id=39329764 reply dave_sullivan 6 hours agorootparent> I am curious about your PaaS because we were analyzing that business for fun first. Here's an old tutorial video of the product: https://youtu.be/V2q9hVdi80w We were doing cool things and on the cutting edge but ultimately couldn't make a business out of it and weren't talking to the right people. reply throw0101b 6 hours agorootparentprev> how much did they invest? how? into CUDA? what else? CUDA 1.0 was released in 2007: * https://insidehpc.com/2007/07/nvidia-releases-cuda-10/ * https://developer.nvidia.com/cuda-toolkit-archive From SIGGRAPH 2007, \"GPU computing with NVIDIA CUDA\": * https://dl.acm.org/doi/10.1145/1281500.1281647 \"NVIDIA: The Era of the Personal Supercomputing\": * https://www.nvidia.com/content/events/siggraph_2007/supercom... Before AI/ML was hot, and before even the Bitcoin paper was released. NVidia was investigating/experimenting/investing in the concept before there was any kind of 'killer app' for it. reply pjmlp 3 hours agorootparentAnd even better, NVidia understood not everyone wants to use plain old C for their GPGPU coding, and early on staring with CUDA 3.0 in 2010, introduced C++ support and PTX. Later on they acquired PGI, which thanks to PTX, had C, C++ and Fortran compilers, thus adding Fortran into the mix. Followed along by all the IDE, graphical debuggers tooling and library ecosystem. Meanwhile Intel and AMD were doing who knows what at Khronos stuck in their \"C is good enough\" mentality, and barely released useful developer experiences. reply fnordpiglet 7 hours agoparentprevI’m not sure I would bet an ads/spyware company with admittedly deep deep pockets would beat a specialized hyper focused company at its core business, especially as they have deeper pockets now with 30 years of experience in the sub sector. If Nvidia were wandering in the desert like Cisco I could believe it. But Nvidia isn’t, and I don’t believe Google, Amazon, or others will beat Nvidia at their own game. (Given my time in FAANG, I also speak from inside knowledge of how deeply f’ed these companies are - making your own arm chip or network adapter isn’t the same thing as taking on high end designers at their own game) reply microtherion 7 hours agorootparentIt's interesting that you would name drop Cisco. They exploded in market valuation in 1999/2000, having a near-monopoly on infrastructure that was in high demand due to the Web boom. Nvidia similarly profited from the Crypto/AI boom, but I wonder whether that is bound to end similarly. reply fnordpiglet 3 hours agorootparentAll things end, and Nvidia will probably decay at some point. But they’ve had a long and strong run. reply rgmerk 7 hours agorootparentprevHave you worked at a large (say 500+ employee) company that you would say isn't \"deeply f'ed\"? I once read a fascinating corporate history of Xerox, and that company became deeply, deeply f'ed up in ways that are of their time but do have strong parallels to the issues I understand that FAANG, particularly Google, have. reply dehrmann 4 hours agorootparent> Have you worked at a large (say 500+ employee) company that you would say isn't \"deeply f'ed\"? You get a weird insider bias where all you see are bug reports and problems, so you get the impression the product is shit, even if 99% of customers love it. reply eru 6 hours agorootparentprev> Have you worked at a large (say 500+ employee) company that you would say isn't \"deeply f'ed\"? Perhaps Google until around 2010? Or Goldman Sachs until the 1990s? reply Horffupolde 6 hours agorootparentprevCould you please share any links or pointers for that? Sounds interesting. reply rgmerk 5 hours agorootparentOne of them was called Xerox: American Samurai, and dates from 1986 (I read it when I was a teenager in the early 1990s, I think). There was another one from the early 1990s, I believe. This book lauded Xerox's success at reforming its corporate culture, regaining a strong position in the photocopier market and even spent a chapter detailing their success in getting into electronic typewriters! With the benefit of hindsight the company didn't survive its core product losing all relevance any better than Kodak did, but that was still some way in the future (if foreseeable by the 1980s). That said, much of the material about a hugely bloated organisation, with a sclerotic bureaucracy and lots of cushy middle managers assembled through a previous period of explosive growth, turning out poor-quality product, sounds very reminiscent of some of what we now hear about the current big tech companies. The title reflects another American obsession at the time - the idea that the US was \"losing\" to Japan. reply pb7 7 hours agorootparentprev>Given my time in FAANG, I also speak from inside knowledge of how deeply f’ed these companies are Please tell us more of your expertise and deep insight, FAANG employee #1,908,680. Google has developed their own chips. Apple has developed their own chips. It’s really not that hard if your pockets are deep enough or the bottom line checks out. When Apple launches their AI offering this year, it’s not going to need NVIDIA. reply fnordpiglet 6 hours agorootparentThey have, over many years and not against a company at the top of their game and with considerable help. Apples move is an ARM chip, not an Apple chip. Googles chips are competitive in spaces like network infrastructure. TPUs are illustrative of their inability to provide a viable alternative. Apple isn’t going to launch with an Nvidia killing alternative, I’ll bet you $1,908,680 it’s backed by Nvidia. They will likely use their neutral chips for local models, but their data center stuff will be 100% Nvidia. reply AnthonyMouse 6 hours agorootparentThe interesting question isn't whose hardware they use for the launch, it's what the public-facing software API looks like. Apple isn't likely to directly expose CUDA. At which point they're free to swap out the hardware with whatever they want at any time. Also, Apple has a longstanding dislike for Nvidia and even if they weren't going to design their own chips at launch, they could be using AMD. reply KaoruAoiShiho 7 hours agorootparentprevDo you have any knowledge of what it runs on? I was pretty sure it was NVIDIA (accessed through cloud providers as a customer). reply riku_iki 7 hours agorootparentprevTPU is a thing and well competitive already for a long time?.. reply kccqzy 4 hours agorootparentTPUs are made primarily to satisfy Google's own needs (especially YouTube), not necessary what GCP customers need. reply fnordpiglet 6 hours agorootparentprevExcept they come tied to GCP and don’t offer as high precision training and inference. These are pretty major disadvantages. reply tuyguntn 7 hours agorootparentprevdon't underestimate market forces. Same could have been told about Intel, but Apple anyway beat them in some ways and took away big market share reply AnthonyMouse 6 hours agorootparentAMD has taken more CPU market share from Intel than Apple. But the weird thing about the \"Nvidia will remain undefeated forever\" theory is that it seems to assume they have some kind of permanent advantage. Nvidia was well positioned to make an early investment in this because they had the right combination of existing technology and resources. Other companies would have had to invest more because they were starting from a different place (e.g. Microsoft), or didn't have the resources to invest at the time (AMD). But now the market is proven and there are more than half a dozen 800 pound gorillas who all want a piece of it. It's like betting that Tesla will retain their 2022 market share in electric car market even as the market grows and everyone else gets in. Maybe some of the others will stumble, but all of them? Apple, AMD, Google, Intel, Microsoft, Amazon and Facebook? reply eru 6 hours agorootparent> It's like betting that Tesla will retain their 2022 market share in electric car market even as the market grows and everyone else gets in. Yes. Especially once you take the Chinese electric car companies into account, that are already outselling Tesla. reply AnthonyMouse 5 hours agorootparentAnd even a Tesla optimist would presumably admit that maintaining a third of the EV market would be a huge win for Tesla, as the EV market becomes \"the car market\" going forward. Maybe that won't happen, but it's at least within the realm of possibility -- maybe some of the existing carmakers stick the transition and some of them fail, but Tesla remains the biggest one, that's not impossible. But maintaining the 80% they had a few years ago, much less 100%? That's not optimism, it's fantasizing. reply eru 4 hours agorootparentAgreed. Btw, I was talking about global electric car production. I don't know whether Tesla ever did 80% of global electric car sales? reply AnthonyMouse 4 hours agorootparent~80% was the US number from 2020. reply fnordpiglet 6 hours agorootparentprevIntel isn’t top of their game and haven’t been for many many years. reply AnthonyMouse 6 hours agorootparentIntel knows how to make software and libraries for their hardware, which is the thing people keep lamenting about AMD. Intel's current GPUs are mediocre but priced competitively for what they are, and Intel having more competitive hardware in the future is not implausible. Which could lead to Intel realizing the opportunity they have. Create decent libraries that work across every vendor's GPUs. In the short term this helps AMD at the expense of Nvidia, which in itself helps Intel by preventing Nvidia from maintaining a moat. In the medium term Intel then has people using Intel's libraries to write code that will work on their future GPUs and then their problem is limited to producing competitive hardware. reply nicce 3 hours agoparentprev> I'm personally not a fan of NVIDIA's drivers A bit funny thing is that they are essentially software company which focuses on software quality, if you look at the stats how many people are working with software over there. And still it is not good enough? reply nalllar 7 hours agoparentprevTheir biggest competitor in the GPU space is AMD who have spent years chasing deadlock issues that won't stay fixed, playing whackamole, in between trying to do actual driver development. Following the amdgpu mailing list is not fun. reply rgmerk 7 hours agoparentprevNot having done any GPU programming...is most of the code out there tied to the Nvidia architecture? I mean, if AMD or somebody else builds a better mousetrap, how much work would it be to switch? reply cowsandmilk 7 hours agorootparentMost of the AI and ML related programming uses frameworks that abstract away what brand of GPU you are using. They could care less whether it is nvidia or AMD. reply latchkey 7 hours agorootparentThis is true for making things just work, however to really squeeze performance out of a GPU, you need to go lower level and that is tied to the architecture. reply virtue3 7 hours agorootparentThis has happened before and it will probably go the same way. Software and compilers will make up the difference, or hardware will become so cheap and ubiquitous it wont super matter. In 3-5 years what will a 10% performance difference matter to you? Then calculate how much that 10% performance difference is going to cost in real dollars to run on nvidia hw and then the fun math should start. reply latchkey 7 hours agorootparentPerformance for GPUs isn't just speed, but also power efficiency. The complexity of GPUs doesn't lend itself to just being solved with better tooling. They are also not going to get cheaper... especially the high end ones with tons of HBM3 memory. Given that data centers only have so much power and AI really needs to be in the same data center as the data, if you can squeeze out a bit more power efficiency so you can fit more cards, you are getting gains there as well. When I was mining ethereum, the guy who wrote the mining software used an oscilloscope to squeeze an an extra 5-10% out of our cards and that was after having used them for years. That translated to saving about 1 MW of power across all of our data centers. Let me also remind you that GPUs are silicon snowflakes. No two perform exactly the same. They all require very specific individual tuning to get the best performance out of them. This tuning is not even at the software level, but actual changes to voltage/memory timings/clock speeds. reply eru 6 hours agorootparentYou are right to worry about power efficiency. Though do keep in mind that power is also fungible with money, especially in a data centre. I suspect a lot of AI inference (thought probably not the majority) will happen on mobile devices in the future. There power is also at a premium, and less fungible with money. reply spenczar5 6 hours agorootparentprevWe are so, so, so far away from compilers that could automatically help you, say, rewrite an operation to achieve high warp occupancy. These are not trivial performance optimizations - sometimes the algorithm itself fundamentally changes when you target the CUDA runtime, because of complexities in the scheduler and memory subsystems. I think there is no way that you will see compilers that advanced within 3 years, sadly. reply ric2b 6 hours agorootparentprevAnd yet I see tons of stuff requiring CUDA. reply dheera 6 hours agorootparentprevexcept AMD produces nothing remotely close to the compute capability of an H100. they only compete at the gaming card level. reply edward28 6 hours agorootparentThey released the MI300 which beats a H100 but is close to a H200. reply saberience 2 hours agorootparentActually, this hasn't been shown yet. AMD showed some \"on paper\" specs which could \"theoretically\" be faster than a H100, but they didn't show any practical tests which could be recreated by third parties. Also, some of the tests AMD ran on H100's were deliberately not using the correctly optimized software, massively slowing down the H100 performance... As a result there is a lot of sceptism as to whether it's actually faster in real world scenarios. There are a few articles explaining this situation. Here is one: https://www.forbes.com/sites/karlfreund/2023/12/13/breaking-... reply gitgud 4 hours agorootparentprevA lot of projects have trouble moving off of Nvidia's proprietary CUDA platform. An example is this [1] ML repo, the issue has been open for years... [1] https://github.com/alicevision/AliceVision/issues/439 reply teaearlgraycold 7 hours agoparentprevGoogle is actually working on 1st party datacenter chips. Although I doubt those would be user-facing GPUs. reply Laremere 7 hours agorootparentGoogle Pixels have a \"neural core\", and they have edge TPUs in addition to their data center TPUs. However Google hardware seems much less poised to take immediate advantage of the AI gold rush. reply ein0p 6 hours agorootparentprevNobody other than Anthropic and a few other large cloud customers like that really cares what Google is working on. They bet the farm on a DL framework (Jax) with 2% market share. That’s a very deep hole to climb out of, particularly considering the popularity of PyTorch in generative AI space. reply jeffbee 7 hours agorootparentprevThe last decade of Google datacenter engineering can be viewed as an elaborate plan to avoid paying either Intel or Nvidia any more money than was really necessary. reply fnordpiglet 7 hours agorootparentAnd, yet. reply what_ever 7 hours agorootparentYet, what? reply kccqzy 4 hours agorootparentYet, Google's customers still demand Google to pay Nvidia exorbitantly. reply teaearlgraycold 3 hours agorootparentGoogle has plenty of first party servers. reply fnordpiglet 3 hours agorootparentprevAnd intel. reply eru 6 hours agoparentprevFeel free to short sell NVIDIA? reply jumploops 7 hours agoprevThe crypto bubble (circa 2017/2018 [0]) looks like an ant hill compared to the recent Gen AI-based gains! $68/share in August 2018 would be $722/share today. [0] https://www.fool.com/investing/2018/08/22/the-cryptocurrency... reply mmaunder 7 hours agoparentIt’s the guy collecting currency shells on the beach compared to a new Iron Age and the guy who has all the iron. reply dheera 6 hours agoparentprevwell $1000 of crypto in early-2017 would be worth $50000 now if you didn't panic sell in 2018 so ... reply HWR_14 6 hours agorootparentThey were talking about the effect of crypto mining on NVidias stock price. reply ein0p 6 hours agoprevAs much as I’d like to say it’s overpriced, its only potential competitor, AMD, is even more overpriced with an eye watering P/E of 324 as of right now, three times that of NVIDIA. Such numbers are stark raving insanity for hardware companies. For comparison, Apple, fully in possession of the world’s most valuable brand, and a gigantic money printer powered by a loyal, billion+ user strong customer base, and a deep pipeline of products, has P/E one third that of NVIDIA, and 1/10th of AMD. Make this make sense. reply yCombLinks 6 hours agoparentThe forward PE is 31 for AMD, and Nvidia is at 33. Apple's forward PE is 26. The market prices are based on future expectations. Nvidia is expected to increase earnings by something like 3x, and AMD by 10X reply nerdponx 5 hours agorootparentApparently, AMD can remain irrational longer than retail investors can remain solvent. reply gpt5 3 hours agorootparentTo be fair, it's much easier to increase your profits when your profit margins are 5% (AMD) vs 50% (Nvidia) reply yCombLinks 5 hours agorootparentprevRight, I'm not saying they will hit those projections, that's what they are though reply givemeethekeys 1 hour agorootparentprevHow does one find information on forward P/E? Are there historical forward P/E charts to get some context on whether the current prices are expensive / in-line with how tech is valued over the past ten.. twenty years? Thanks! reply HDThoreaun 5 hours agoparentprevIntel is jsut as much a competitor to Nvdia as AMD. I suspect they will work together on creating a CUDA alternative which is the biggest problem both of them face. If they can figure it out I dont see how nvdia isnt fucked as the money is in the big cloud purchasers who have every incentive to switch as soon as a legitimate alternative presents itself. Even if amd/intel dont beat Nvdia coming close with a product that \"just works\" for half the price is certainly on the table and will be compelling for the hyperscalers. reply ein0p 5 hours agorootparentIntel can’t even make a competitive CPU anymore, let alone a competitive compute-oriented GPU. It’s way behind on lithography, with no end in sight. Their GPUs also aren’t properly integrated with any popular DL framework. I honestly have no idea what they’re thinking. If I were them, at least PyTorch would work flawlessly with their current Arc offerings. It doesn’t - it’s a decidedly “enthusiast” affair for people with too much time on their hands. You don’t even need a huge team for this. 25-30 competent C++ folks for 9 months to a year is all it takes. reply dehrmann 4 hours agorootparentprev> CUDA alternative The should name it OpenCL. reply eru 6 hours agoparentprevFeel free to short sell both? reply linksnapzz 6 hours agoparentprev\"Nowhere to go but up!\" reply ein0p 2 hours agorootparentUp? Idk, I certainly don't have the nerve to buy into a position at this kind of P/E. But they don't need to run faster than the bear, and their next best competitor has the agility of a stoned sloth when it comes to the software side of things. reply jedberg 7 hours agoprevConsidering how much money Amazon and Google (and Microsoft and Oracle and....) are giving NVIDIA, this makes sense. Amazon and Microsoft in particular seem to be staking a pretty big part of their business on things that need GPUs. And even though Amazon makes GPUs, they are still buying NVIDIAs by the truckload. reply grogenaut 7 hours agoparentAmazon buys whatever they can sell to customers. You want windows? We got that. Oracle, got it. Amd, got it, Intel, got that. Mac, got that. Arm? Got that. Nvidia, got it. Their own arms, got em. Their own training and inference? Got it. They buy things by the cargo ship load. reply CSSer 5 hours agorootparentAlright, alright! We got it already. reply sebmellen 8 hours agoprevAnd with a P/E ratio of 95, versus 25 and 59 for Google and Amazon, respectively! reply foolswisdom 6 hours agoparentThat's a P/E ratio based on the past four reported quarters, over which time earnings at Nvidia increased so much that the earnings for the last reported quarter was over 4 times that of four quarters ago. Assuming that future earnings for the next year are consistent with the last reported quarter, they're valued at 45x earnings. But of course such a valuation still only reddit makes sense assuming growth (and the projected earnings for the next quarterly report is indeed expected to be 12% higher, giving a 40x p/e valuation). Consider that Amazon's P/E (using the last reported quarter as the baseline for the future - Amazon has had consistently increasing earnings over the last year, let's assume it doesn't decrease from here) is 43x. reply what_ever 7 hours agoparentprevNvidia haven't released their latest earnings yet. reply MuffinFlavored 7 hours agorootparent> NVIDIA Corporation Common Stock is expected* to report earnings on 02/21/2024 after market close. reply tomoyoirl 7 hours agoparentprevTrailing or forward earnings? reply refurb 5 hours agoparentprevThe thing with P/E ratios is that they are backwards looking while stock prices represent future estimations. Bankers put together detailed models to estimate the earnings per share in the future. Yes they are estimates, but informed as best as possible. The model spits out an estimated $/share. If the current price is lower, they think the future value of the share is actually higher than the current price, so they buy or convince others to buy. reply jgalt212 7 hours agoparentprevagreed, it's very high, but with M2 growing again such outlandish valuations seem sustainable. https://fred.stlouisfed.org/series/WM2NS reply throw0101b 6 hours agorootparent> agreed, it's very high, but with M2 growing again such outlandish valuations seem sustainable. You know whose M2 has also been rising for decades? Japan's. And yet for most of that time the Nikkei has been flat (even negative): * https://fred.stlouisfed.org/graph/?g=17sx4 China's M2 has also been going up steadily: * https://fred.stlouisfed.org/series/MYAGM2CNM189N What has the Shanghai Stock Exchange (index) been doing lately? The UK's M2 has been going up continuously: * https://fred.stlouisfed.org/series/MSM2UKQ How's the FTSE 100? > https://fred.stlouisfed.org/series/WM2NS Now let's overlay the S&P 500: * https://fred.stlouisfed.org/graph/?g=1gvKR A giant spike in M2 in 2020, and yet at the same time the S&P 500 dropped. M2 has been on a downward trend since April 2022, and the S&P 500 bottomed in ~October 2022, but has been rising since then—while at the same time M2 has been dropping. reply brcmthrowaway 7 hours agorootparentprevWhat is the implication of M2? reply pclmulqdq 7 hours agorootparentIt's the amount of money in the economy, and its growth is one measure of inflation. GP may be commenting that the \"good times\" of super-high valuations are about to come back thanks to inflation. That isn't the financial datum that really matters, though - what matters for P/E ratios is the risk free rate (which establishes the discount rate for the time value of money), which is still very high. reply FredPret 7 hours agorootparentBy risk-free rate, do you mean the yield on US gov bonds? reply pclmulqdq 4 hours agorootparent\"Risk-free rate\" is a theoretical concept that represents the rate of return you get without taking any risk. T bill rates, reverse repo rates, and money market savings rates are a practical proxy for it, but it's not any one of these. reply jgalt212 7 hours agorootparentprev> what matters for P/E ratios is the risk free rate Where's the research showing the empirical relationship between P/E ratios and the risk free rate? Also, we are living in a a time of unprecedented monetary aggregate growth (for the US at least). I posit his why the yield curve has been inverted for so long and yet there is no recession in sight. The predictive power of asset prices seemingly no longer exists. reply pclmulqdq 4 hours agorootparentThere's a ton of it: here's one person's regression. You can find the same in academic papers (although economics papers don't exactly deserve that label). https://www.currentmarketvaluation.com/posts/sp500pe-vs-inte... It's also just common sense if you understand company valuation. reply smsm42 2 hours agoprevCould somebody explain to me what is the moat that prevents somebody else from taking on Nvidia? OK, they make GPUs. Why somebody else can't make GPUs? AMD took on Intel, Google took on Microsoft and Apple - is GPU market somehow harder to enter? I mean, we're talking piles of money from the looks of it - Amazon and Google do a ton of stuff, and NVidia only does (roughly speaking) one thing - and that thing is not even directly consumed by the customers, so \"it's hard to migrate\" shouldn't be a huge deal since it's not the customers that would be doing the migration. So what are the barriers that make Nvidia unique? reply alecco 1 hour agoparentGPUs are very complex. Nvidia pioneers in everything related to GPUs. A rich software stack, the most sophisticated Tensor Cores, and bleeding edge features like 8 bit floating point (FP8) support. And they are working with FP4 next. This matters because by halving the data size it almost doubles the flops (see Hopper specs [1]). The compute is so powerful it creates bottlenecks in data loading. So they have SXM, Nvlink, and since Hopper smart data async load to Tensor Cores (TMA). It's so advanced the ML software hasn't caught up yet. And it's not trivial to tile and schedule properly at these levels. (See FlashAttention [2]) I wouldn't be surprised if they stay on Hopper for a while and just crank up the bandwidth and bundle more GPUs together. They already released H100 NVL which is basically 2 H100s. And the H200 with faster High Bandwidth Memory (v3). AMD and Intel are way behind and have nothing even remotely close in planning. [1] https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor... [2] https://crfm.stanford.edu/2023/07/17/flash2.html reply ptelomere 5 hours agoprevWhen there's a gold rush, sell the best shovels you can make. Pretty much the business model of Steam, Amazon, nVidia, Nintendo, all to some degree, we can go on and on. reply xyst 2 hours agoprevWith the recent story of openai pitching VCs for a collective $5-7 trillion dollars and a GPU manufacturer becoming more “valuable” than diverse companies such as Amazon or Google. I am thinking this market is due for a massive correction. It’s not sustainable and built on the “promise” or con it will continue to skyrocket YoY. Just like the cryptocurrency/digital currency craze. This one (artificial intelligence) will also come crashing down. I give it maybe 1-2 years at this rate. We will look back and these types of stories will be the red flags people will point to when the market is about to sink. reply lm28469 1 hour agoparentIt's literally the same story over and over again, buy the hype, buy the futur hypothetical profits, disregard everything else including logic. Pure greed Enron called it HFV, hypothetical future value reply zmmmmm 2 hours agoprevOur organization tried to buy an A100 last year. We were informed 12 months wait. nVidia can literally just print money at this point for the next 5 years I think. reply Aeolun 7 hours agoprevHmm, AMD is worth 55B, and somehow almost keeping up. I'd consider that a success. I do think it's a bit sad they have basically no representation in the AI market though. Whenever it's about AI it's Nvidia all the way. reply tempsy 7 hours agoparentAMD's market cap is 278B Not sure where you got 55B reply Aeolun 4 hours agorootparentWikipedia? Huh, I see what you mean. Either I’m reading the numbers wrong, or wiki just doesn’t have that info and I plucked a random one out of the list. reply dagmx 6 hours agoprevAt the time of posting this, NVIDIA has dropped below both companies. I expect them to bounce back, but the headline as shared was not true at the time the article was submitted reply testless 2 hours agoprevLofty valuation with a PE ratio of over 90 - even considering the growth and margins. Also almost no revenue growth in 2022/23 according to quickfs.net. Too expensive for my taste. reply jsnell 1 hour agoparentYou're being misled by the site. Those aren't really their 2023 results, but their FY2023 results. And Nvidia's fiscal years are just nuts, basically FY2023 is 2022. Their 2023 results will be reported as FY2024, and aren't out yet. But just the first three quarters showed 50% more revenue than the entire FY2023. reply testless 45 minutes agorootparentYou are right, I was wrong. I have compared financial years, not actual years. There seems to be strong improvements with respect to revenue (66% TTM increase) and earnings per share (334% increase TTM). reply 37 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nvidia has surpassed Amazon and Alphabet in market value, thanks to its strong position in the AI market and impressive financial results.",
      "Nvidia's stock has grown over 17,000% in the past decade, making it the best-performing stock on the S&P 500.",
      "Analysts predict further upside potential for Nvidia's stock, as the company is expected to report its third consecutive quarter of record sales and profits."
    ],
    "commentSummary": [
      "Nvidia's dominance in the GPU market is a major topic of discussion, raising concerns about monopolistic practices.",
      "Various debates revolve around the importance of competition and the potential for anti-trust violations.",
      "The role of developers, profitability of GPU sales, and challenges faced by rival companies like AMD are also part of the conversation."
    ],
    "points": 287,
    "commentCount": 288,
    "retryCount": 0,
    "time": 1707788916
  },
  {
    "id": 39343919,
    "title": "macOS workaround enables more app icons without hiding under MacBook Pro notch",
    "originLink": "https://flaky.build/built-in-workaround-for-applications-hiding-under-the-macbook-pro-notch",
    "originBody": "💡 TL;DR: You can adjust MacOS whitespace settings from the command line to display more application icons in the top right section of the menu bar. Hidden Apps Beneath the 14” and 16” MacBook Pro Notch A frustrating aspect of the new MacBook Pro models is the notch. The notch itself isn't the problem; rather, it's that Apple hasn't automatically adjusted the menu bar icons so they don't hide behind the notch when many apps are running. My colleagues often suggest purchasing Bartender for about 20€ to solve this issue. While it offers many features, I've refused to pay for a 3rd party solution to Apple's poor design decision. I have nothing against Bartender but I just don’t want to install yet another app into my machine to solve such a simple problem. Recently, I discovered a free, built-in macOS workaround that doesn't require installing Bartender or any other additional apps. See the results in the images below: With the default settings, the MacBook top menu bar can only accommodate 13 different apps. After adjusting the whitespace settings, it can fit several more. Adjusting the Menu Bar Whitespace Settings from the Command Line You can modify the default padding and spacing in the Menu bar by opening Terminal.app and executing the following commands: # Change the whitespace settings value defaults -currentHost write -globalDomain NSStatusItemSelectionPadding -int 6 defaults -currentHost write -globalDomain NSStatusItemSpacing -int 6 # After running these commands, you need to log out and log back in You can adjust the values from 0 to 6 to accommodate even more icons. Personally, I found 6 to be a good fit. This will allow you to add more items to your menu bar before they will be hidden under the notch. I estimate that with the value of 6 I can fit 21 apps to the menu bar with my 14” MBP. If your apps will again be hidden under the notch you can just lower this value. ‼ NOTE: Applying this workaround will allow you to fit more items to your menu bar but the same issue will resurface if you keep adding more apps which run in the menu bar. Reverting to the Original Values If you're unhappy with the results, you can delete the settings by executing the following commands: # Revert to the original values defaults -currentHost delete -globalDomain NSStatusItemSelectionPadding defaults -currentHost delete -globalDomain NSStatusItemSpacing # After running these commands, you need to log out and log back in Sources I first learned about these settings in this answer on the Apple-themed Stack Exchange, Ask Different: Can the spacing of menu bar apps be modified in macOS Big Sur and later? It's much too wide, which is a problem if you use a lot of menu bar apps. https://apple.stackexchange.com/a/465674/74811 Changelog 12-02-2024 3:17 PM: I clarified that I have nothing against Bartender after Eric_WVGG shared a good point in HN. I haven’t been writing a lot before and it seems I still have work to do to be more considerate towards others 🙇 12-02-2024 8:05 PM: I added a note that this will just postpone the issue after aeturnum commented about it in HN. 12-02-2024 9:12 PM: I renamed the article from Native macOS fix for applications hiding under the MacBook Pro notch to Built-in MacOS workaround for applications hiding under the MacBook Pro notch to avoid confusion.",
    "commentLink": "https://news.ycombinator.com/item?id=39343919",
    "commentBody": "Built-in workaround for applications hiding under the MacBook Pro notch (flaky.build)241 points by onnimonni 21 hours agohidepastfavorite213 comments flohofwoe 19 hours agoI really like my M1 Mac, but the notch has to be the dumbest design decision in the history of laptops :/ I would accept any design compromise for the webcam, make it grainy / low-res and put it under the display, put it at the bottom so it points up my nose, or move into a small 'corner notch' in the top-right corner so that the camera looks at me from the side ... anything really but please get rid of that stupidly oversized center notch. reply thimp 18 hours agoparentHaven't really noticed mine. Even after I've used it plugged into the studio display for a couple of days and go back to laptop mode, it's just such a non issue. reply WWLink 9 hours agorootparentNo way lol. I bought a 15\" macbook air and the notch is the one thing I hate on that laptop. Like seriously, why is it so dang big?! I could understand a little cutout for the camera, but it's not like there's a faceid scanner array in there. It's just a dang camera. They could've stuck the ambient light sensor anywhere else. reply wtallis 3 hours agorootparentIIRC, Apple used to have the ambient light sensor under the left speaker grille. If you happened to rest your hand there, it would make your screen suddenly start dimming. When using the laptop in a dark environment, it was also prone to a feedback loop where the screen dimming would result in less light hitting the sensor, leading to further screen dimming, or runaway brightening. Putting the sensor facing outward from the plane of the screen minimizes that feedback. reply lloeki 17 hours agorootparentprevI live with it, the most annoying part being how big it is vertically. It has a weird psychological effect of screaming WASTED SPACE!!! at me, even though I rationally know that if the screen would start below would make for less space. It's constantly bothering me to the point that I set a background with a black area at the top so that it blends with the menubar. I don't have a problem with the menubar icons though because I keep that tidy and minimal. I punt on the issue through clamshell mode most of the time though. To each their own, and TBH I have worse pet peeves. reply devsda 16 hours agorootparentThe way I see it, we can think of the screen below the notch as actual display area and consider the area next to notch as bonus display dedicated for menubar. The bonus area goes dark when in fullscreen app. So, the app area is consistent in both modes. This way you don't have to feel like there's wasted space. reply j45 14 hours agorootparentprevIs there a chance anything that us paid attention to grows in size. Would anyone be willing to go to an older laptop without it? Assuming not, what are the options? External displays? I find I usually look at the content on the screen not the webcam or the notch, but it could be different for others reply tcdent 15 hours agorootparentprevI've had my M2 Air for about a month now and this thread is the only reason I know that it's there. Never would have noticed. reply naikrovek 8 hours agorootparentHow can you not notice that? Hate it or not it is incredibly easy to notice. reply wtallis 3 hours agorootparentIt's trivial to notice when you go looking for it. But if you keep your machine in dark mode and don't use apps with an overloaded menu bar, it's also very easy for the notch to entirely disappear from your awareness. reply pdntspa 18 hours agorootparentprevI agree here. I thought it was dumb but the OS works around it really nicely; the only time it ever got in the way was with some non-native software reply gniv 19 hours agoparentprev> I would accept any design compromise for the webcam, make it grainy / low-res I think this is a minority opinion. I personally don't remark the notch anymore. reply ambyra 19 hours agorootparentIt’s an okay solution, not the best, but definitely the most expensive. Another solution that would have been cool and expensive: if they put a camera in each corner of the screen. Then at least they could have the rounded corners they always wanted. Also four cameras could be used for cool 3d effects and AI to keep your eyes looking at the center of the screen. reply threeseed 14 hours agorootparentI think you need to think through that four camera concept a bit more. It would significantly increase the screen bezels because instead of just one notch you now have to bring in all four edges to accomodate the cameras. reply LeonenTheDK 18 hours agorootparentprev> Also four cameras could be used for cool 3d effects and AI to keep your eyes looking at the center of the screen. Nvidia has been doing the eyes with a single generic camera for over a year now: https://www.nvidia.com/en-us/geforce/news/jan-2023-nvidia-br... reply lxgr 18 hours agorootparentFacetime has been doing this for a few years now too. It's called something not-quite-straightforward in the settings (\"enhance attention\" or something). reply rcdemski 18 hours agorootparentNot sure if it was renamed but today the setting is called “Eye Contact” reply cooper_ganglia 18 hours agorootparentprevWait a second, I think you’re onto something here… reply mceachen 16 hours agorootparenthttps://en.m.wikipedia.org/wiki/Fire_Phone had a camera on every corner of the front screen. reply cooper_ganglia 16 hours agorootparentThanks for the link! I went in search of a product like this to read about it's development, but didn't find one in my short search. This was super convenient! reply pompino 15 hours agorootparentprevIt's the majority opinion, infact Apple also believes that the notch is a compromise. Apple has been trying to develop the under-screen webcam tech. They just don't have the technical capability to eliminate it. When Apple and others finally eliminate the notch it will be heralded as the best thing ever. Few will realize how Apple milked you twice - once to accept the horrible design (that they created), and again to accept how wonderful they are for eliminating the problem. reply Tagbert 12 hours agorootparentAll designs involve compromise. That doesn’t mean that those designs are bad, just that they are taking into account factors which are in opposition. Factors such as size, capacity, function, and legibility are examples of the kinds of oppositional factors that designs often need to take into account. The MacBook notch is a clever design that increases the size of the screen without increasing the size of the overall case. There are some, relatively minor, downsides. 1. Some applications have an unusual number of menu items. The system takes this into account and renders those menu items to the right of the notch. In many cases, those are the less often used menu items “Window” and “Help” so the impact is lower. 2. When there are large numbers of app icons in the menubar, they may not all fit and some are truncated. This has always been a problem with that feature and many people have solved this by using utilities such as Bartender that hide extra app icons and move them to secondary panels. 3. There is an additional visual element on the screen. Many people quickly learn to ignore the notch and soon forget that it is there. For those who are bothered by it, there are a couple of simple ways to reduce the visibility of it. One method is to change the resolution of the screen so that all content appears below the notch. The downside of that solution is that there is less screen area. Another method is to use a utility to turn the menubar black. This makes the notch blend into the menubar so that it is much less visible. reply pompino 11 hours agorootparentDo you agree that there is good and bad design? Furthermore, I don't see what is wrong in criticizing bad design when the Vendor also acknowledges that it's bad and they're rushing to fix it. This isn't software where you can just run an update. No, you have to re-buy the machines to get the fixed design. reply halostatue 11 hours agorootparentI do believe that there is bad design and Apple occasionally falls prey to it. Design that is not suited to purpose, like the late-2010s keyboards, is bad design. Design that is intentionally anti-human (anti-loitering architecture, HP printer locks, etc.) is bad design. The notch is not bad design: it is a design compromise. In reality the presence of the notch increases the overall screen space with the reduced bezel. That electronics wizardry and physics do not currently permit under-screen high definition cameras means that you need bezel space for it. That Apple managed to get it to be ~35mm x ~9mm is impressive. On every other laptop in the world with a webcam at the top, that ~9mm is required forehead on the laptop, meaning at least a ~9mm bezel. And Apple is not rushing to replace this. After all, we've had three generations of Apple laptops released with the notch. Sure, if/when they prove they can do a quality under-screen camera, they will update this (after they update the iPhone family). But calling this \"bad design\" is suggesting that you could do better. reply pompino 10 hours agorootparentIt's horrible for consuming media, among many other things. I honestly don't get why you're defending something that is bad design. And yes, I could do better. Remove the notch. ta-da ! Instantly better. Users, developers, testers, device repair folks, part suppliers, all will thank me :) reply wtallis 10 hours agorootparent\"Consuming media\" seems like the worst possible argument against the notch, since the area below the notch is already 16:10 and will have letterboxing when watching 16:9 or wider content whether or not the notch exists. reply pompino 6 hours agorootparentPictures don't exist? Sorry, I am out of this conversation. Its patently obvious that I will fail to convince the fans of the notch here. reply halostatue 5 hours agorootparentprevI have never noticed the notch when watching fullscreen videos or seeing fullscreen pictures. I do notice it with my current background, but it doesn't bother me. Removing the notch (by removing the webcam) is not an option that most people are interested in. Removing the notch by putting a forehead (and therefore shrinking total available screen space) is not an option that most people are interested in. What is your design brilliance for a relatively lightweight 14\" laptop with minimal bezels and a high quality web camera in the centre of the screen? You don't have one, because you have convinced yourself that anyone who disagrees with you \"likes\" the notch. Literally everyone who has said that you're wrong has said some variation of: 1. Haven't really noticed it in X time using it 2. It doesn't bother me, because I have more screen space for the main windows, and the menu / task icons are now in space that wasn't available before 3. It's not a selling point for the laptop, but neither is it a disaster, and it's barely noticeable. You have called it bad design. Pretty much everyone who has responded to your repetitive message has said \"it's a compromise\". Bad design is anti-human. This isn't anti-human, it's a compromise. Statistically, no one is going to immediately buy a new version of a MacBook that does not have the notch just because it does not have the notch. They will do so because it offers a substantial boost over their current configuration (speed, RAM, display space, storage), and they may not even notice that there's not a notch anymore…unless they have used tools like Bartender or Hand Mirror that can take advantage of your cursor being under the notch to trigger useful functionality. If you actually had a useful suggestion, I’m sure that Apple would love to hear from you (I’ll bet they've tried a lot of ideas that you have had and many more you haven't; they're not perfect, but they are really good at design experimentation and industrial processes). Until then, you’re just another Abe Simpson complaining about things on the Internet. reply pompino 4 hours agorootparent>1. Haven't really noticed it in X time using it 2. It doesn't bother me, because I have more screen space for the main windows, and the menu / task icons are now in space that wasn't available before 3. It's not a selling point for the laptop, but neither is it a disaster, and it's barely noticeable. I routinely jump between different devices with and without notches. The notched devices continue to highlight the flawed UX each time. For people who unconditionally love Apple (quite a few on HN) or don't care either way, its not a problem. >You have called it bad design. Pretty much everyone who has responded to your repetitive message has said \"it's a compromise\". Its true, 10 people on an online forum disagreed with me. >Bad design is anti-human. Anti-human? You've lost me sorry. >Statistically, no one is going to immediately buy a new version of a MacBook that does not have the notch just because it does not have the notch. They will do so because it offers a substantial boost over their current configuration (speed, RAM, display space, storage), and they may not even notice that there's not a notch anymore…unless they have used tools like Bartender or Hand Mirror that can take advantage of your cursor being under the notch to trigger useful functionality. Yes, I agree and said so. Its not enough of an irritant to disqualify the purchase. > I’m sure that Apple would love to hear from you (I’ll bet they've tried a lot of ideas that you have had and many more you haven't; they're not perfect, but they are really good at design experimentation and industrial processes). Until then, you’re just another Abe Simpson complaining about things on the Internet. Apple doesn't want to hear from me because they already know the notch is ridiculous. They're working on removing it, they have stated all but publicly - because Apple never acknowledges their flaws unless they are sued. reply pb7 5 hours agorootparentprevHe's probably just a young kid or trolling. Kids have a tendency to overdial on the thing itself instead of the utility the thing can offer you. There's no way a fully functioning adult can be this obtuse. reply choilive 9 hours agorootparentprevGreat! You removed the notch. Now we don't have a webcam. reply pompino 6 hours agorootparent:) reply pb7 7 hours agorootparentprev>And yes, I could do better. Remove the notch. ta-da ! I can do one better. Don't buy it! Ta-da! Notch gone from your life and you can be happy again. Consider that you are wrong and are not adept to designing products when compromises need to be made. reply pompino 6 hours agorootparentIf you like it so much, take a piece of black tape and apply a notch to all your screens. I'll continue to criticize bad design. reply pb7 6 hours agorootparentIt's a compromise, not a feature in itself. I get more screen for the compromise of having a small portion of it be blacked out. If you hate it so much, cover the entire menu bar with black tape and change the resolution and pretend like that's how it came if you want less screen space for no reason. In the kindest way possible, consider that you may have OCD or similar. Like others have said, we haven't noticed or thought about this once in years of using it all day everyday. Preferring worse function (read: less display) over form (read: no notch) is not the galaxy brain you think it is. reply pompino 5 hours agorootparentOh you want more display? Lets add 20 notches to the bezel and stuff some pixels where we don't have any screws and fasteners. Sorry dude, I'm having a real tough time taking your pro-notch argument seriously. Lets agree to disagree here. I'm tapping out. reply resfirestar 13 hours agorootparentprevI don't see anyone saying the notch on a laptop is a \"good\" thing that they bought the laptop to get, just people who bought a laptop for other reasons justifying why an imperfect screen shape wasn't enough to make them regret the purchase. They're not being \"milked\" in any way I can see. Compare phones, where manufacturers have actually created a narrative that camera cutouts are a desirable feature. Maybe people who bought new phones because they like the cutout design are getting milked twice. reply pompino 13 hours agorootparentIts an MBA thing. Engineers and nerds would never support it. https://www.google.com/search?q=apple+incremental+innovation reply arrowleaf 9 hours agorootparentprevI'm saving up to replace my personal intel MBP with a new one partially because using my work MBP I really appreciate that little bit of extra screen space. In regular use I hardly notice the notch, sometimes I'll even have fun watching my cursor jump back and forth when it gets close to one side of it. reply KerrAvon 13 hours agorootparentprevUnless you've actually conducted a survey, you don't know how many people feel like you do. I get that you hate it, but I personally haven't noticed the notch in day to day use ever -- I've been using an M1 in light mode since it came out. reply pompino 13 hours agorootparentI am not saying its the most pressing design feature that disqualifies a purchase. I just don't get the push-back when pointing out obvious flaws. reply newdee 7 hours agorootparentI think the push-back is largely due to you ascribing your own preferences/opinions to the “majority” user base without any supporting data. reply pompino 6 hours agorootparentIf the notch is so good, maybe the fans of the notch should convince Apple and others to stop their efforts to remove it. reply kstrauser 15 hours agoparentprevIf you look at it as \"the notch took away part of the screen\", it's annoying. I see it like \"the notch gave me new chunks of screen that wouldn't have been there otherwise\". reply pompino 15 hours agorootparentA customer should care about looking at a retail product with their own POV, not someone else's. This is the classic \"you're holding it wrong\" response. reply kstrauser 15 hours agorootparentOK. I'm the customer here, and I'm looking at it with my own POV. I think it's neat that I have extra pixels to hold the menu bar so that the rest of the screen can be dedicated to the apps I'm running. reply pompino 15 hours agorootparentGood, so are you going to pay Apple twice? Once for creating the problem, and again when they develop the under-screen tech to fix it? reply kstrauser 15 hours agorootparentUm, yeah? I bought my current laptop with the extra pixels at a time I needed a new laptop. If Apple comes up with a way to add more extra pixels by the next time I'm looking to buy one, I'll get that. The notch is an improvement over the old thick bezel design. Presumably they'll find an even better solution down the road. When they do, I'm not going to complain that they didn't jump forward to the currently nonexistent technology on the first iteration. reply pompino 13 hours agorootparentIt's called incremental innovation \"this changes everything, again\" (yawn!) , so they can slow talk you into opening up your wallet yet again. You can bet your bottom dollar if Apple saw a significant threat to their money maker, you'd see them eliminate the notch in gen 1 itself. Suddenly the \"non existent\" tech would magically appear. reply arrowleaf 9 hours agorootparentYou seem to be thinking that Apple will introduce under-screen cameras next... I highly doubt that. Under-screen will never have the fidelity of a camera without layers of screen in front of it. If anything the notch's dead space will become physically smaller, with the visible notch staying the same size to provide 'dynamic island' functionality, like on the iPhones. I'd pay for that. reply pompino 6 hours agorootparentCompetitors have already introduced it, but the quality is shit, so Apple having a higher bar for image quality isn't quite ready to introduce it. They have been hard at work though. https://www.patentlyapple.com/2023/12/apple-updates-their-un... https://9to5mac.com/2023/12/06/under-screen-face-id-2/ https://www.macrumors.com/2023/12/06/iphone-under-display-ca... reply pb7 6 hours agorootparentprevI can't imagine how pissed you're going to be when they release a laptop that lasts 30 hours instead of 20 hours. Scammed again by evil Apple. :'( reply pompino 6 hours agorootparentThe earth will thank you for creating more e-waste. /s Not sure what is so joyous about opening your wallets for Apple. Normally people want more for their money, not less. reply threeseed 15 hours agorootparentprevThe under screen tech doesn't even exist in a product today. Did you want Apple to hold off on giving people extra real estate until that happened ? reply pompino 13 hours agorootparentYou've already accepted the premise that Apple is \"giving\" a feature to the customer, so there doesn't seem to be any room for a conversation. reply MikusR 10 hours agorootparentprevUnder screen cameras have been in mass produced devices for 4 years. reply AvesMerit 8 hours agorootparentprevApple added 74 px vertically and the notch lives entirely in that space. It's simply more real estate. What is the \"problem\" they've created? That's like complaining about my apartment coming with a balcony reply yungporko 15 hours agorootparentprevno it's just a fact. before the notch, the parts of the screen either side of it were not screen, but now they are. the complaints about the notch literally boil down to \"it's not enough extra screen\". reply pompino 15 hours agorootparentThe only \"fact\" here is that Apple is going to milk you twice. Once when they sold you a knowingly flawed design and again, when they finally develop the tech to eliminate the notch, Apple fans will happily line up to pay them again. reply SkyMarshal 15 hours agorootparentprevIt's more the classic glass half empty vs half full response. Although given the small size of the notch, it's more like 10% empty vs 90% full. reply pompino 13 hours agorootparentI don't see a problem with criticizing the one of richest companies in the world on legitimate issues, or holding them to a very high standard. They can defend themselves just fine. I'd give a smaller company much more leeway. I own several Apple products (often the ones I criticize the most are the ones I personally purchased and used long term), but I'm not part of the Apple \"community\" or other Apple fanbases. reply xattt 15 hours agorootparentprev“Screen half black vs half lit up” reply nicoburns 8 hours agorootparentprevThis is even literally true as they made the screen (and screen resolution) bigger with the introduction of the notch. Given the existence of macOS's menubar I personally think it's a great design. reply dimask 8 hours agorootparentprevThis. And makes the laptop smaller. I have a notchless M1 13\" air and it is almost the same size as my 14\" M3 mac, albeit with bigger screen. reply wulfeet 19 hours agoparentprevI've been using a M1 for well over a year, and until about two weeks ago I didn't know it had a notch. I don't follow the tech press, who I'm sure discussed it a great length when it was released. And I'm not personally invested in the Mac, it's owned by my employer. So I didn't notice the notch until my cursor disappeared while scrolling across the top of the screen. reply TillE 17 hours agorootparentYeah it's completely invisible if you use a background that's very dark near the top, I haven't thought about the notch in months. reply bombcar 16 hours agorootparentprevThe notch is really noticeable if you have a white menubar. I'd take a screenshot of it but ... ha! reply mort96 13 hours agoparentprevJust don't think of it as a 15.4:10ish screen with a hole cut out of it, think of it as a 16:10 screen with some extra space on top for the menu bar. Realistically, what you're proposing is to remove the part of the screen with the notch in it to make it a normal 16:10 screen, and tbh that seems like a straight-up downgrade. I do think the machine looks better with a dark menu bar in the \"notched\" area though. That's how I have my Asahi Linux system set up. reply Miraste 12 hours agorootparentI don't believe those are the only options. Why is the notch so big? If they kept the webcam the same size and made it a hole punch in the display, instead of surrounding it with a giant blob that still can't do Face ID, it would solve the whole problem. reply mort96 54 minutes agorootparentI agree that it certainly seems wider than necessary. reply Tagbert 12 hours agorootparentprevBecause there is more than just a camera. There is the camera, two sensors, and some mounting hardware. It all adds up to some space. The specific size doesn’t really matter especially if you use Bartender to properly manage the app icons. See the camera module here: https://forums.macrumors.com/attachments/img_0383-jpeg.22053... reply Miraste 12 hours agorootparentI know, but the other two sensors are for color temperature and light level. There's no reason they couldn't be in the bezel or the bottom of the display, and they don't need that massive chunk just to mount a camera. Before Apple Silicon I always set the menu bar to autohide, and it bugs me unreasonably that I can't do that anymore. reply duxup 19 hours agoparentprev> put it at the bottom so it points up my nose My Dell has a nose cam… it’s so unpleasant a view that it is unusable IMO. reply dev_tty01 19 hours agoparentprevJust use something like RDM to set the screen size to the choice that is a few pixels shorter. The system will take those pixels off the top and the notch will disappear. The top of the active pixel area will be a bit lower. I suspect those settings are available in the controller because some Apple engineers also hate the notch. reply Groxx 16 hours agoparentprevI really hate it. I lose menu bar applications and application menus behind it literally every single day. I don't mind that it exists and that some people prefer it to large bezels... I just wish there was a way to say \"claim my screen is -X pixels and show me the full menu\" like before. Without both requiring one app to be full screen and that crazy scaling mode that makes everything fuzzy. reply renewedrebecca 15 hours agorootparentThat’s literally possible… there’s some criteria that will force the display into that mode (although I can’t remember off hand what it is) reply Groxx 15 hours agorootparentFull screen app + tell it to shrink (afaik only available if it doesn't natively declare support for the notch). And it achieves it by scaling the whole screen ever so slightly, ruining pixel offsets everywhere and making everything fuzzy, seemingly so it doesn't ever present a non-standard display ratio despite the notch being very non-standard already, and despite full screen apps already working on external monitors that can have any ratio. It's not an option anywhere else. Nor would I want that fuzzy mess anyway. It's such an insane design. reply kalleboo 7 hours agorootparentIncorrect System Settings > Displays > Advanced > Show resolutions list > Select the 16:9 resolution with slightly fewer vertical pixels than your current one reply andrei_says_ 16 hours agoparentprevThe notch gives me a larger screen combined with a camera and a smaller body. I personally value these and the decision to use that real estate for the hardware camera is imo quite creative. I paid a few dollars for the bartender app which solves for the hidden apps. Haven’t thought about it since. reply ActorNightly 14 hours agoparentprev>but the notch has to be the dumbest design decision in the history of laptops The virtual escape key on the touch bar, all while Apple was pushing their laptops as developer friendly, is magnitudes worse reply bri3k 19 hours agoparentprevYou can change the resolution in System Settings->Displays, make it so the entire display is below the notch. reply tambourine_man 12 hours agorootparentIt is extremely hidden, but here's how you access all available resolutions, including the ones which work below the notch: https://support.apple.com/en-ke/guide/mac-help/mchl86d72b76/.... reply flohofwoe 19 hours agorootparentprevThe thing is, I really like the thin bezel, but why has the notch to be so massively big? The camera hole looks like it's just about 3..4 millimeters in diameter. PS: also looking around, there seem to be plenty of laptops with thin display bezel and no notch, if others can do it, why not Apple? reply Wowfunhappy 19 hours agorootparent> PS: also looking around, there seem to be plenty of laptops with thin display bezel and no notch, if others can do it, why not Apple? Because those laptops have worse webcams. You don't have to agree with the tradeoff Apple made, in fact I don't, but I think the reasoning is pretty clear. reply jwells89 19 hours agorootparentprevMost of those other laptops have asymmetric bezels, which Apple was probably trying to avoid. They wanted thin bezels on all edges. The extra room in the notch is likely there in case they want to change webcam parts to something larger, add Face ID, etc so they don’t also have to change the display panel and can continue to use existing stock. Apple seems to like to try to avoid changing parts/tooling wherever possible and will go as far as to awkwardly keep using a chassis until stock of that part has been exhausted if necessary (see the 13” M1 Touch Bar MBP). reply nottorp 19 hours agorootparent> Most of those other laptops have asymmetric bezels, which Apple was probably trying to avoid. They wanted thin bezels on all edges. Yeah, I'm thinking firing Johnny Ive wasn't enough. reply Waterluvian 19 hours agorootparentprevThere’s like four different things in the notch. Not just a camera. Plus some recessed screw holes to mount it. The notch feels weird, but when I try to redesign it without sacrificing features, I can’t come up with a better option. …Not that I’m a brilliant designer by any means. reply pimanrules 18 hours agorootparentNot really? There's a webcam, an indicator LED, an ambient light sensor, and a lot of empty space. As far as I can tell, the MacBook notch is wide just to make it look like the iPhone notch. https://guide-images.cdn.ifixit.com/igi/5JIdAqwLsxWAFAyZ reply Tagbert 18 hours agorootparentThere is also the mounting hardware. It’s not an unreasonable size for what it contains. If they were to really redesign the module they might shave a little off of it but how impactful would that reduction really be? reply Tagbert 12 hours agorootparentHere is the module behind the notch: https://forums.macrumors.com/attachments/img_0383-jpeg.22053... reply johnwalkr 14 hours agorootparentprevThey probably set the notch size with some margin too, so they could develop the camera module and LCD at the same time. reply dlivingston 16 hours agorootparentprev> The MacBook notch is wide just to make it look like the iPhone notch. I'm convinced this is true, at least partially. The iPhone notch is branding and a visual differentiator from the competition, which is Apple's forte, and carrying over that very distinctive design element to other product lines seems right in Apple's playbook. In other words: glass slab in your hand? Who knows. Glass slab with a black notch? iPhone. Person typing on metallic laptop in a cafe? Who knows. Ah, but the screen has a notch? MacBook. reply dur-randir 17 hours agoparentprev>but the notch has to be the dumbest design decision in the history of laptops No, it had been the touch bar. There're multiply solutions for the notch, none had been imagined for that abomination. reply mjcohen 10 hours agorootparentI got the original 13\" M1 MPB and put some additional \"buttons\" on the touch bar. Sort of miss it on my 16\" M1 MBP. reply __jonas 9 hours agoparentprevHm I don’t have one of those notch MacBooks but it kind of seems like a great idea to me if my understanding of how it works is correct. I usually use my apps in fullscreen, which hides the menu bar, this has the very annoying side effect that moving the cursor to the top of the screen (where a lot of apps have buttons) will make the menu bar drop down and cover the buttons. I am assuming a fullscreen app will not extend under the notch, so with this notch thing I imagine I could always have the menu bar visible on fullscreen apps without sacrificing screen real estate and without the annoying animation triggering when I want to interact with the upper part of the app. Can someone confirm it really works like this? I feel like it would be a huge improvement. reply eastbound 9 hours agorootparentIf that were true, it would be losing a centimeter off the too of the screen, wouldn’t it? reply nicoburns 8 hours agorootparentYou do lose a centimeter off the top of the screen, but luckily they added a centimeter to the screen (compared to the previous model) when they built it. So it's pretty strictly a win. The area of the screen below the notch is 16:10 resolution. The bar at the top is \"extra\". reply __jonas 9 hours agorootparentprevWould it? I wouldn't consider the bezel/notch area part of the screen, since I assume an app in fullscreen mode doesn't extend into that area anyways because how would they deal with UI elements that fall into the top center? I mean maybe it's a bit of mental gymnastics, of course it's technically screen space taken away, but I am guessing the top bezel also becomes thinner so it seems like a great use of space to me, feels like it would allow me to justify always having the menu bar visible without feeling like it being there is wasting my space (because nothing else can be there). And having the menu bar always visible + avoiding this animation is something I would love. reply swozey 18 hours agoparentprevI've had an m1 max 14\" since the week they first released 2-3 years ago and I actually COMPLETELY forgot there was a notch until I read this post. I can't think of like, one time when it was an issue but I also have probably used TopNotch since then. reply Fnoord 17 hours agoparentprevI own a M1 MBP. What you wrote about notch isn't a fact but a (controversial) opinion. Some people feel very strongly about it in a negative way, but many don't care. Personally, I don't care much about notches, and if you can put the pixels very dark/black (ie. OLED) I don't think you should care either. With Settings -> Accessibility -> Reduce Transparency you can make the menubar very dark. But to be fair, miniLED isn't OLED. I am using Bartender to hide items in menubar. I did so before notch existed. Without it, I wouldn't be able to fit my menubar (with or without notch). reply bombcar 16 hours agorootparentI prefer to think of it as two large full-color notches going upwards as compared to a small black notch coming down. Too bad they didn't increase the resolution of the display slightly for that. reply selectodude 15 hours agorootparentThey absolutely did though. The notched MacBooks are 15.5:10 instead of 16:10. reply bombcar 11 hours agorootparentI'm honestly amazed I didn't know that, perhaps Apple should have shipped the NotchBook Pro™ with the menubar below the notch, and everything above black, and had a setting you could change to turn it to how it is now. reply Fnoord 11 hours agorootparentThere's some apps in the App Store which allow you to, on top of the accessibility setting I mentioned earlier. It isn't ideal. Let me put it this way: if too many people dislike the notch, I'm cool they go without it. Or have two versions. The issue simply doesn't bother me, I'm indifferent about it. MBPs have had much worse issues between 2016 and 2020. reply bombcar 10 hours agorootparentYeah, the notch is not a real issue for me, though I did end up getting Bartender to work around it when on laptop only. The phone notch is much less annoying now that they did whatever they did in the latest iOS to make it hardly noticeable. reply anais9 15 hours agoparentprevCompletely agree - I made https://notchbegone.com to help mask it visually when it came out expecting Apple to quickly obviate via their own design updates and yet years later we're still having this conversation. My tinfoil hat take is that the true primary purpose of the notch is to drive upgrade purchases at some point in the future whenever serious technical advancements are waning. reply amanzi 15 hours agoparentprevYou're right about the dumb design decision. There's no good technical reason that it's so massive compared to the single tiny webcam. The only way it would have made any sense was if it also contained the FaceID array of cameras too. This was just Apple going all-in on the notch that was part of the \"iconic\" iPhone design. Now that the iPhone notch is on the way out, I expect they'll introduce the dynamic island to the MBP in a future update. reply bloopernova 18 hours agoparentprevI use my mac docked and closed, so I hardly ever see the notch. However I think Apple should be able to use some fancy engineering to keep the camera as hidden as possible in the edge of the screen surround. Or use multiple fibre optic points embedded in the screen along with those fancy neural processors to create an eye-to-eye webcam. reply apple4ever 10 hours agoparentprev> the notch has to be the dumbest design decision in the history of laptops Agreed. It's such a bad bad bad design. No reason to hide the camera. Just make the bezel taller. Its fine. It's just as bad as the notch/pill on the iPhone. Drives me crazy everytime I look at it. Can't wait til we move to a notch free world. reply Sohcahtoa82 9 hours agorootparent> Can't wait til we move to a notch free world. Never gonna happen. Apple sales continue to grow despite the notch, so obviously users LOVE the notch. The notch is here until we can put a camera and any other sensors inside the screen without losing pixels. reply porphyra 14 hours agoparentprevI don't think the notch is inherently dumb. It's a great use of the space in the macOS menu bar that is otherwise usually wasted. Moreover, having a good webcam is very important to a lot of Macbook users who would not be able to tolerate grainier cameras or the nostril-peering bottom positioning on some XPS laptops. It is, however, super annoying that various implementation bugs have not been fixed after years. reply naikrovek 8 hours agoparentprevYou can set screen resolutions which bring down the top of the screen to the bottom of the notch and leave everything else alone. You lose 64(?) pixels of vertical screen but the notch goes away. reply lcnmrn 17 hours agoparentprevI sold a M2 MBA and bought a M1 MBA because of the notch. reply ClassyJacket 7 hours agoparentprevI could deal with a hole punch camera like on Android phones, or a Dynamic Island or something, but why on Earth does it need to be so big? The camera itself is tiny, and it's far bigger than the Dynamic Island despite containing only a camera, and not a depth sensor too. We get that gigantic black notch and don't even get FaceID. Is it something to do with the lid being thinner than an iPhone so the entire camera assembly needs a cutout rather than just the lens? That's the only reason I can think of. Personally, I'd rather even have a physical notch extending out from the edge of the screen, like a tab in the middle, than the current black cutout. reply Eric_WVGG 20 hours agoprev> While it offers many features, I've refused to pay for a solution to Apple's poor design decision. The phrasing of this kind of gets under my skin. Like, it's fine to call it \"refusing to pay\" if it's some kind of Apple tax. Bartender is great little indie app, a real quality-of-life enhancement. I like to reward creative developers who come up with solutions for weird edge-case users like us. reply jeroenhd 20 hours agoparentI can understand the sentiment. It's not necessarily something against independent developers, it's anger about a problem that shouldn't happen in the first place to a device this expensive. Windows had a similar problem with its notifications tray growing to unreasonable size, and they fixed that back in Windows Vista, after applying some auto-hiding algorithm in versions before that. Apple missing this problem or not being able to come up with a solution is simply not believable, this has to be the result of them simply not caring or refusing to address the issue for stylistic reasons. I'm sure Bartender is great software (even without the notch problem, from what I can tell!) but Apple is the one forcing their users to pay extra for their stupid design decisions. $16 to fix a problem other operating systems fixed almost twenty years ago is a steep price to pay when you're expecting a quality laptop. reply sofixa 19 hours agorootparent> I can understand the sentiment. It's not necessarily something against independent developers, it's anger about a problem that shouldn't happen in the first place to a device this expensive. Especially considering how much people harp on about Apple's amazing UX and quality and how that makes the absurd prices worth it. The notch problem, as well as other UX bugs (like scroll direction having two separate toggles in mouse/touchpad settings, that toggle each other) really don't look all that polished to me. reply HumblyTossed 19 hours agorootparentprev> I can understand the sentiment. It's not necessarily something against independent developers, it's anger about a problem that shouldn't happen in the first place to a device this expensive. This. Apple cultivates this myth that they only release polished devices/software. When they fail to do even the littlest things like work with a design decision they made, people, rightfully, get frustrated. reply lex-lightning 19 hours agorootparentI agree. I love my iPhone and my iPad. But that touch bar era on the Mac was rough. reply cqqxo4zV46cp 19 hours agorootparentprevPolished doesn’t mean perfect. This sounds like you’ve got an axe to grind and nothing more. reply HumblyTossed 19 hours agorootparentSounds like you're just a wee sensitive. No axe, just telling like it is. reply hobs 19 hours agorootparentprevHow many trillions of dollars does Apple need before we can complain about menu bar items? reply onnimonni 19 hours agorootparentprevThanks @jeroenhd for giving me the benefit of doubt and explaining it even better than I could! My intention was definitely not to bash bartender and I need to select my words more carefully in the future. It was just the only solution I knew before yesterday for a such a simple stupid design flaw from Apple. I have nothing against Bartender or its developers. I just wish I wouldn't need to install 3rd party software to fix Apple's issues. reply haswell 19 hours agorootparentThere was a time when I would have agreed pretty whole-heartedly with you and dismissed this as a \"simple stupid design flaw\". I've been writing production code for over 20 years, and the existence of solutions like Bartender is evidence that the problem can't be that hard, right? And then I became a product manager for a large suite of capabilities for which large customers would spend millions/year, and my mind changed pretty significantly. Every release, I was forced to choose the 10-15 things that we could reasonably accomplish from a list of hundreds. Many dozens of the things that we didn't do could be classified as \"simple stupid design flaws\". There was one of these flaws in particular that I was determined to fix when I took the role. \"This makes us look stupid\" I thought. It had been a gap in the product for years, and I always marveled at the fact that no one had fixed it. But the reality was, the product was architected to be extensible, and to allow 3rd party developers to build their own solutions. And in this case, there were numerous solutions in the community that solved the problem quite well. When faced with the reality of a mile-long backlog, and many of those items having no solution at all, and no affordance for developers to solve them, the already-solved design flaw always fell below the cut line for each release, despite my best efforts to prioritize it. And I begrudgingly had to acknowledge that this was the right choice at the time. I have a slightly different view on these types of issues now. It's easy to call this a design flaw, but on the flip side, Apple has clearly made it possible for the community to solve this issue. I'm 100% positive someone at Apple is trying their hardest to get this thing fixed, but most likely keeps getting thwarted by more critical issues, and the realities of managing a large and complex platform/ecosystem. \"Apple has all the money; they should just scale up the dev team\". And if they did, those new devs would be assigned to the next 10-15 items on that mile-long list that are still more important than a 1st party solution to a solved problem. It does show the cracks in Apple's marketing, but it's also far more understandable and reasonable than I once would have believed. (I don't/didn't work for Apple). reply tzs 19 hours agorootparentprevIt still makes no sense to me because I don't see how it is relevant that it is fixing what you see as a design flaw from Apple. If the gutters on one side of my house frequently get clogged up with needles because the builder planted some pine and fir trees close to the house (but not so close as to be against any codes or regulations), I'm not going to just live with it because it is the builder's fault and so I'm not going to spend money to install gutter guards or have the trees removed. I think it is a design flaw in many car mirror systems that when a car that is overtaking you gets close enough to no longer be visible in the center mirror it isn't yet visible in the side mirror. It is never occurred to me to just live with it because fixing it means spending money to fix the car's design flaw. I fix this by buying a cheap little stick on convex mirror and sticking it on the side mirror. Then there is overlap between what I can see in the center mirror and what I can see in the side mirror, and I can see overtaking cars at all times. (Or bicyclists and motorcyclists that are lane splitting). reply Nullabillity 17 hours agorootparent> I'm not going to just live with it because it is the builder's fault and so I'm not going to spend money to install gutter guards or have the trees removed. No, you'd complain to the builder until they fix their fuckup. reply onnimonni 18 hours agorootparentprevYou're right and anyone can fix this same issue with Bartender too. You can also fix this issue by using your MacBook solely with external monitor :D My point was just to raise awareness that there's a free alternative which doesn't require any 3rd party apps. reply jwells89 19 hours agorootparentprevI think Apple hasn’t followed Microsoft on status item (that the name of menubar icons on macOS) management is simply because they didn’t intend for the API to be used even a fourth as much as it is. In older releases (back when in it was still known as OS X), persistent status items weren’t something devs could do without dipping into hacks. That part of the menubar was intended solely for system stuff, e.g. the display and sound menus. There were always APIs for transient status items, but those were intended for use by “normal” apps with a dock icon that you have open only temporarily to accomplish some tasks (which means these status items wouldn’t accumulate). Status items added this way couldn’t even be rearranged like the system ones. So in short, there’s no management because they’re designing for the user who has a couple of status items, not 5, 10, or 15+. reply cpuguy83 17 hours agorootparentprevThis is not the same thing as Windows. MacOS users choose to have those things in the menu bar. On Windows the notification bar was a dumping ground that you couldn't prevent apps from using. reply clawoo 20 hours agoparentprev> While it offers many features, I've refused to pay for a solution to Apple's poor design decision. Well then you're in luck, because there's a free app called Hidden Bar[1] on the Mac App Store that allows you to hide icons which you're not interested in. I am not affiliated with the author(s?), I am just a happy user and I would probably be using it even if the Macbook didn't have a notch. [1] https://apps.apple.com/us/app/hidden-bar/id1452453066?mt=12 reply onnimonni 16 hours agorootparent> Well then you're in luck, because there's a free app called Hidden Bar[1] on the Mac App Store that allows you to hide icons which you're not interested in. Author here: I did try Hidden Bar yesterday before finding this workaround and I uninstalled it today. I want to see all of the 16 apps that I have. I don't want to hide any of them. By changing the whitespace mentioned in the blog post I now can see all of them. reply bitcurious 18 hours agorootparentprevHidden bar has the added benefit of not asking to record your screen, an insane thing to consent to for this very basic bit of functionality. reply thesuitonym 19 hours agorootparentprevStill sort of insane that you need extra apps to fix an issue that Microsoft figured out decades ago. The GP says it was in Windows Vista, but I'm pretty sure even Windows 98 had it. I know XP did. How has Apple not addressed this? reply evilduck 19 hours agorootparentWeirder still is that they did, they have an entire expanding control panel pane with redundant pop out controls for stuff that was previously in the menu bar, they just failed to universally integrate it with the system so that third parties could use it. reply seba_dos1 19 hours agorootparentprev98 did not, XP was the first one. So, this was addressed there merely 23 years ago, give them some slack! ;) reply lxgr 18 hours agoparentprevBesides the freeware/shareware issue, I'd like to limit the number of various little tools running on my computer, often with effectively full access to my data (since software that provides that type of quality-of-life improvements for core OS functionality is often hard/impossible to sandbox). I can't even use most of these on my work Mac for the same reason (it's outright not allowed/possible by policy). reply sunshowers 8 hours agoparentprevMore than the cost, it's the fact that it's yet another app with its own updater, attack surface, etc that's a bother. (I don't know if this app has an App Store version available -- but in general, even if they are, they're often worse than the non-App Store versions.) reply daviddever23box 18 hours agoparentprevIt is perfectly acceptable to provide a zero-cost, command-line focused solution to a single, specific user-interface constraint, while, at the same time, providing additional parametric insight to macOS user preferences. reply OJFord 19 hours agoparentprevNo, that's clearly not 'I should not have to pay Bartender for its work'; it's 'I should not have to find a third-party who can sell me a fix'. reply risho 19 hours agoparentprevespecially considering that apple is full of poor design decisions that people have already been using third party software to compensate for. for example a lack of any form of reasonable window management that the many people use stuff like magnet or rectangle to compensate for. or the fact that mouse scroll direction and trackpad scroll direction are linked. or the fact that you can't control volume on a per app basis. reply pushedx 20 hours agoparentprev30% or more of the cost goes directly to Apple, so there are some perverse incentives at play with such unofficial fixes. reply hannes0 19 hours agorootparentYou can purchase directly on their website or via Setapp. So, I would count this as an argument. reply cqqxo4zV46cp 19 hours agorootparentprevI assure you that whatever money Apple would make from this wouldn’t make a dent in even some lower-level Apple pleb’s P&L. This sort of unbound cynicism isn’t intelligent or useful. It shouldn’t be conflated with being usefully or interestingly critical. reply lynndotpy 18 hours agorootparentIt adds up when you need to pay $25 to get per-app volume control, $20 to fix to the menu bar, $10 to get window management, etc, per seat. I don't think it's cynical to point out the perverse incentive. I think it's a useful point for discussion, especially given anyone familiar with any of the other major desktop environments (Windows, GNOME, KDE, etc.) might be surprised to learn that there's a modern desktop environment lacking these amenities. reply delfinom 18 hours agoparentprevHandling the app icons properly due to the notch IS something that Apple should have done. It's pure idgaf incompetence on Apple's part. Their software quality has been declining the past few years in respects to macOS. reply kalleboo 6 hours agorootparent> Their software quality has been declining the past few years in respects to macOS Was there a previous version of MacOS where this problem was solved? I remember literally running into this same problem on Macintosh System 7 when running MS Office apps that had too long menus for a PowerBook screen, there was a third party app back then as well to solve it (by replacing the \"File\", \"Edit\", etc menu names with icons to make them shorter) reply aqme28 19 hours agoparentprev“Refusing to pay for…Apple’s design decisions” makes no sense when you just spent $2000 on an Apple laptop, in order to not pay an indie dev $16 reply wtetzner 18 hours agorootparentI think the point is that you shouldn't need to spend anything extra after spending $2,000 on an Apple laptop for something Apple should have already addressed. reply aeturnum 17 hours agoprev> * I discovered a free, native macOS solution that doesn't require installing Bartender or any other additional apps.* > You can adjust the values from 0 to 6 to accommodate even more icons. Personally, I found 6 to be a good fit. It's ultimately a really petty point - but this is not a fix. This increases the number of apps on the top bar before the problem occurs. Bartender (and hidden[1] - which I discovered in this thread) fix the problem. Calling a technique that delays the problem \"a solution\" after sneering at a project that actually is a solution just rubs me the wrong way. Edit: Though I'll leave my rude comment in its original form, it's also important to note that OP added a note clarifying this may not fix the problem for everyone in what I thought was a mature reaction to a petty complaint. [1] https://github.com/dwarvesf/hidden reply onnimonni 16 hours agoparentYou're correct that there are certain scenarios that won't be addressed by this. Would it be more fair to say to write that this will only postpone the issue? To offer a counterexample, I've been using my machine for slightly over a year now, and the number of applications running in the menu bar have stabilized to 16 apps. So this undeniably resolves the issue on my machine and for my usage. EDIT: I think this was a great point and I added a notice section to the blog post so that everyone using this hack will be well informed to make best decisions. Thanks for the feedback! reply aeturnum 16 hours agorootparentI appreciate you taking my very petty feedback! I totally agree that it's a clever change that will allow most people to avoid the problem. reply onnimonni 11 hours agorootparentI really appreciate your original comment and it was straight to the point. It's probably good to still reflect about that part since other users might feel offended. Thanks also for the EDIT part too. It makes me feel that HN users won't tolerate bullshit but will nonetheless give great feedback :) Your comment original comment lead me to ask if HN admins could rephrase the blog article from: \"Native macOS fix for applications hiding under the MacBook Pro notch\" -> \"Built-in MacOS workaround for applications hiding under the MacBook Pro notch\" Which is more accurately representing the contents of the article. I also changed the title in my own blog post to this already. reply rollcat 14 hours agoparentprevI endorse Hidden Bar, it's just such a simple and obvious solution. I use my Mac with a 43\" screen at 4k/1x, so the space in the menu bar has never been a real problem... It's the sheer number of icons and the resulting clutter, especially as they're all tiny, monochromatic, and therefore hard to tell apart. IMHO, 80% of apps that put icons on the menu bar, shouldn't, but the system doesn't really give them any better place. Lunar (I think they made the correct choice. Do you understand how much harder layout is when its not on a rectangle? reply threeseed 14 hours agoparentprev> Just to get a slimmer bezel which is not a useful feature I would much rather have more screen real estate. And if you need to have a perfectly rectangular display you can just make your apps full screen. reply beretguy 19 hours agoprevPeople need to vote with their wallets and stop buying MacBooks with a notch instead of complaining. reply stewx 19 hours agoparentIMO, complaining is probably a more effective way to get the message to Apple in this case than buying a different computer. reply evilduck 19 hours agoparentprevTo buy a Windows laptop with a half dozen worse problems instead? Hard pass, I’ll take an even bigger notch instead please. reply klaushardt 16 hours agoprevI just dump my default changes here. Maybe somebody finds something usefull for themself. Added the command from this thread too. :) Edit: Looks like i already did edit this before since mine was already at 8 and 12. Added the original source like its linked above. # Defaults and other Stuff sudo scutil --set HostName nix # https://macos-defaults.com/ defaults write NSGlobalDomain NSNavPanelExpandedStateForSaveMode -bool true defaults write NSGlobalDomain PMPrintingExpandedStateForPrint -bool true defaults write NSGlobalDomain NSDocumentSaveNewDocumentsToCloud -bool false defaults write com.apple.dock \"autohide-delay\" -float \"0\" && killall Dock defaults write com.apple.dock \"autohide-time-modifier\" -float \"0.3\" && killall Dock defaults write NSGlobalDomain ApplePressAndHoldEnabled -bool false defaults write NSGlobalDomain AppleShowScrollBars -string \"Always\"; killall Finder defaults write com.apple.screencapture \"disable-shadow\" -bool \"true\" defaults write com.apple.dock \"tilesize\" -int \"38\" && killall Dock defaults write com.apple.dock \"mineffect\" -string \"scale\" && killall Dock defaults write com.apple.finder \"ShowExternalHardDrivesOnDesktop\" -bool \"false\" && killall Finder defaults write com.apple.finder \"ShowRemovableMediaOnDesktop\" -bool \"false\" && killall Finder defaults write com.apple.dock \"mru-spaces\" -bool \"false\" && killall Dock defaults write com.apple.TimeMachine \"DoNotOfferNewDisksForBackup\" -bool \"true\" defaults write com.apple.dock \"enable-spring-load-actions-on-all-items\" -bool \"true\" && killall Dock defaults write com.apple.Music \"userWantsPlaybackNotifications\" -bool \"false\" && killall Music # https://www.jessesquires.com/blog/2023/12/16/macbook-notch-and-menu-bar-fixes/ # https://www.reddit.com/r/MacOS/comments/16lpfg5/hidden_preference_to_alter_the_menubar_spacing/ # https://flaky.build/native-fix-for-applications-hiding-under-the-macbook-pro-notch # https://news.ycombinator.com/item?id=39343919 defaults -currentHost write -globalDomain NSStatusItemSelectionPadding -int 8 defaults -currentHost write -globalDomain NSStatusItemSpacing -int 12 # https://www.reddit.com/r/macgaming/comments/16ra8di/metal_hud_enabledisable_shortcut/ # https://www.icloud.com/shortcuts/1271048e407543d391415934cad5edcd defaults write -g MetalForceHudEnabled -bool YES /bin/launchctl setenv MTL_HUD_ENABLED 1 reply jwr 19 hours agoprevI don't mind the notch (I understand the reason it's there and it's a compromise), but it boggles my mind that Apple decided to just place the icons under the notch, where they aren't visible. This is a clear example of lack of dogfooding: clearly Apple executives do not use many apps, or they would have been infuriated at the stupid problem. reply nottorp 19 hours agoparentApple executives don't have time to use computers :) reply josephd79 20 hours agoprevI just use TopNotch. reply speedgoose 20 hours agoparentIt's not doing what you think it does. reply kjkjadksj 18 hours agoparentprevBroken in Sonoma reply luuurker 16 hours agorootparentTop Notch is working well here with 14.3.1. This app only makes the menu bar black though, so it's not really a fix for what the article complains about. reply Erratic6576 20 hours agoprevThere’s a FOSS alternative to bartender reply Sohcahtoa82 9 hours agoparentWhy would you drop a comment like this without saying what it is? reply euroderf 18 hours agoparentprevDo tell reply DarthNebo 17 hours agorootparentHiddenBar reply Simulacra 20 hours agoprev [–] I find the notch the be an utterly horrible design choice. Like the iPhone notch, it seems like a major step back in aesthetic. I found both too distracting for comfort. reply lioeters 17 hours agoparent [–] I agree, Steve Jobs would have never accepted such a design compromise. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A built-in workaround in macOS allows users to adjust whitespace settings in the menu bar to display more application icons and prevent them from being hidden under the notch on new MacBook Pro models.",
      "By using Terminal.app and executing specific commands, users can modify the padding and spacing in the menu bar. A value of 6 proved effective in accommodating more icons.",
      "It's important to note that continuously adding more apps to the menu bar will still cause the same issue, and users can revert back to the original settings if desired."
    ],
    "commentSummary": [
      "The presence of the notch on MacBook Pro laptops is a topic of discussion and debate in the tech community.",
      "Some users dislike the size of the notch and suggest alternative placements for the webcam, while others see it as bonus display space.",
      "There are debates about the practicality and design compromises of the notch, as well as discussions about potential future solutions like under-screen webcam technology. Some users appreciate the larger screen it allows for, while others criticize Apple for selling a flawed design and the need for third-party solutions."
    ],
    "points": 241,
    "commentCount": 213,
    "retryCount": 0,
    "time": 1707739541
  },
  {
    "id": 39351023,
    "title": "Amazon Prime Video Removes Dolby Vision and Atmos Support from Ad Tier Without Notice",
    "originLink": "https://arstechnica.com/gadgets/2024/02/prime-video-cuts-dolby-vision-atmos-support-from-ad-tier-and-didnt-tell-subs/",
    "originBody": "Surprise — Prime Video cuts Dolby Vision, Atmos support from ad tier—and didn’t tell subs To get them back, you must pay an extra $2.99/month for the ad-free tier. Scharon Harding - 2/12/2024, 8:47 PM Enlarge / The Rings of Power... now in HDR10+ for ad-tier users. Prime Video reader comments 154 On January 29, Amazon started showing ads to Prime Video subscribers in the US unless they pay an additional $2.99 per month. But this wasn't the only change to the service. Those who don't pay up also lose features; their accounts no longer support Dolby Vision or Dolby Atmos. As noticed by German tech outlet 4K Filme on Sunday, Prime Video users who choose to sit through ads can no longer use Dolby Vision or Atmos while streaming. Ad-tier subscribers are limited to HDR10+ and Dolby Digital 5.1. 4K Filme confirmed that this was the case on TVs from both LG and Sony; Forbes also confirmed the news using a TCL TV. \"In the ads-free account, the TV throws up its own confirmation boxes to say that the show is playing in Dolby Vision HDR and Dolby Atmos. In the basic, with-ads account, however, the TV’s Dolby Vision and Dolby Atmos pop-up boxes remain stubbornly absent,\" Forbes said. Amazon hasn't explained its reasoning for the feature removal, but it may be trying to cut back on licensing fees paid to Dolby Laboratories. Amazon may also hope to push HDR10+, a Dolby Vision competitor that's free and open. It also remains possible that we could one day see the return of Dolby Vision and Dolby Atmos to the ad tier through a refreshed licensing agreement. Amazon has had a back-and-forth history with supporting Dolby features. In 2016, it first made Dolby Vision available on Prime Video. In 2017, though, Prime Video stopped supporting the format in favor of HDR10+. Amazon announced the HDR10+ format alongside Samsung, and it subsequently made the entire Prime Video library available in HDR10+. But in 2022, Prime Video started offering content like The Lord of the Rings: The Rings of Power in Dolby Vision once again. Advertisement Amazon wasn’t upfront about removals Amazon announced in September 2023 that it would run ads on Prime Video accounts in 2024; in December, Amazon confirmed that the ads would start running on January 29 unless subscribers paid extra. In the interim, Amazon failed to mention that it was also removing support for Dolby Vision and Atmos from the ad-supported tier. Forbes first reported on Prime Video's ad-based tier not supporting Dolby Vision and Atmos by assuming that it was a technical error. Not until after Forbes published its article did Amazon officially confirm the changes. That's not how people subscribing to a tech giant's service expect to learn about a diminishing of their current plan. It also seems that Amazon's removal of the Dolby features has been done in such a way that it could lead some users to think they're getting Dolby Vision and Atmos support even when they're not. As Forbes' John Archer reported, \"To add a bit of confusion to the mix, on the TCL TV I used, the Prime Video header information for the Jack Ryan show that appears on the with-ads basic account shows Dolby Vision and Dolby Atmos among the supported technical features—yet when you start to play the episode, neither feature is delivered to the TV.\" As streaming services overtake traditional media, many customers are growing increasingly discouraged by how the industry seems to be evolving into something strongly reminiscent of cable. While there are some aspects of old-school TV worth emulating, others—like confusing plans that don’t make it clear what you get with each package—are not. Amazon didn't respond to questions Ars Technica sent in time for publication, but we'll update this story if we hear back. reader comments 154 Scharon Harding Scharon is Ars Technica’s Senior Product Reviewer writing news, reviews, and analysis on consumer technology, including laptops, mechanical keyboards, and monitors. She’s based in Brooklyn. Advertisement Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39351023",
    "commentBody": "Prime Video cuts Dolby Vision, Atmos support from ad tier–and didn't tell subs (arstechnica.com)199 points by nickthegreek 12 hours agohidepastfavorite147 comments commandlinefan 11 hours agoIt looks like these streaming services have been hemorrhaging cash for years now and they just can't hide it any more. They're going to have to take drastic steps to try to become profitable - remains to be seen whether customers will bite. OTOH, we don't have the infrastructure to go back to the days of DVD rentals. reply selcuka 6 hours agoparent> OTOH, we don't have the infrastructure to go back to the days of DVD rentals. We already have streaming rentals. I believe while monthly subscription models are not profitable, pay per view still makes money. reply joshspankit 10 hours agoparentprevToo bad they’re unwilling to seriously consider P2P distribution for streamed media. Would cut costs way down. reply callalex 10 hours agorootparentMy residential wired home internet in Silicon Valley has an unreasonable data cap that I hit every month, so I would not be able to use a service that also requires upload. (Which is very intentionally anticompetitive because they will happily sell you access to their streaming service that doesn’t count towards the cap). reply joshspankit 8 hours agorootparentThey would have to make allowances for people with data caps yes reply snird 9 hours agorootparentprevIsn't the content and licensing costs are the majority of their costs? Honestly asking, I never assumed infrastructure and bandwidth might be the majority reply joshspankit 8 hours agorootparentIt depends on the service. For Disney and Paramount+ they already own the IP and the costs then would be storage + bandwidth + metadata/transcoding servers + engineer time. Of those, the bulk would be bandwidth. Similar for content that’s owned by the platform. Netflix, Apple, and others invested in to original programming and in those cases there’s again no need to license. reply paulmd 10 hours agoparentprev> OTOH, we don't have the infrastructure to go back to the days of DVD rentals. amazon is perfectly capable of doing the old disc-based netflix/blockbuster model if they want - actually it would complement their pivot into distribution and shipping perfectly. Just some mylar mailers and a bunch of BD-R blanks - licensing is another matter but what is the logistical problem? Print QR code and put on disc, send it out, get it back, scan QR code when it's \"returned\" and goes back to inventory... reply schlauerfox 10 hours agorootparentI suppose they mean that your phone, tablet, laptop or smart TV have no optical drive so no way to watch physical media unless it came on a new format like a usbC device or something which the studios historically refuse on copyright infringement reasons. reply VanTheBrand 10 hours agorootparentprevnot saying I agree with the OP but player install base would be the infrastructure hurdle more than the discs reply ggm 10 hours agoprevThe fifth paragraph goes directly to Qui Bono: It costs them licencing fees to people like Dolby Laboratories. So, it's the kind of choice which drives directly to outflows of revenue. They made a bet less people will cancel, than the net outflow of licences, and those who pay $2.99 are on their way to being made to pay more rather than meeting the licence-tax. reply steveBK123 10 hours agoparentYes, it's interesting how fast streaming has rotated from fierce competition to be better (more content, exclusive content, big name productions, dolby, 4k, ad-free, etc) to being worse (reduce ability to share / insert ads / what can we cut / slowing the new content pipelines). Feels like a super accelerated version of seeing capital rush into a space and then right back out. Everyone is now desperate to stop burning money, and will either cut or merge themselves into break even. reply makeitdouble 10 hours agoparentprevPrime Video is in that weird spot where most people have low expectations and don't feel like they paid for it. There were already pre-roll ads (for other prime shows) under some conditions, so people who stuck through them will probably also stick through the new sponsored ads I guess. I think this will be the straw in the camel's back for only a small slice of their members, especially as Netflix is also enshittifying their service. reply gentleman11 11 hours agoprevThis is called segmentation. People with home theatres are more likely to be willing to pay extra, so they’re squeezing those users for more money. Likewise, other people are more price sensitive and are more likely to be willing to watch ads to save money, so they’re squeezing them in a different way. With ai and mass surveillance in the future, companies will be able to segment at an individual level. What would they squeeze you or your kids for one day? reply Czarcasm 11 hours agoprevI cancelled my Prime within 24hrs of them adding the ads to the base tier. Just isn't worth it anymore. reply WXLCKNO 11 hours agoparentI only have prime for the actual amazon purchases and don't really use prime much except for the boys and invincible from to time to time. But even with that, this move makes me consider cancelling just to spite them. reply steveBK123 10 hours agorootparentI think Man in the High Castle was the last Prime content I watched.. I guess that was 5 years ago, lol. reply crazygringo 10 hours agoprevHaving less features on a cheaper tier is entirely normal. Should Amazon have been more up-front about it? I guess. But most people don't even care. If you have the money and space for a full Atmos-enabled surround-sound setup at home and/or true mega-bright HDR screen and regularly watch Prime Video, you're probably already paying the extra $3/mo. for no ads anyways. It's not like any of those features matter if you're watching on an iPad or a regular TV or even regular surround sound speakers. Of all of the corporate outrages to upvote here on HN, this one feels like the absolute tiniest. reply donohoe 10 hours agoparentThe cheaper tier was the normal tier. They they downgraded the normal tier when the added ads and you had to pay extra to remove them. This is just adding insult to injury. reply crazygringo 10 hours agorootparentI mean, I'm happy they introduced tiers rather than raise prices for everyone which was the alternative. If I subscribe to Prime just for the shipping, I don't want to be subsidizing people who are heavy video watchers. I see neither insult nor injury, just normal market segmentation. reply selcuka 6 hours agoparentprev> Having less features on a cheaper tier is entirely normal. Oh, definitely. Removing features from your existing subscription, on the other hand, is not normal. I guess we will have to get used to live with skimpflation [1], but it's not \"normal\". [1] https://en.wikipedia.org/wiki/Shrinkflation#Skimpflation_or_... reply TheJoeMan 7 hours agoparentprevPrime Subscription is annual, not monthly. So they’ve substantially changed the product in the middle of a contract term. reply crazygringo 5 hours agorootparentThat's not true, there are both monthly and annual options. And judging from lots of comments online, even if you have annual, they'll refund your remaining time if you cancel in the middle. Sometimes automatically, sometimes you need to request it. So that part doesn't seem to be a problem. reply galleywest200 10 hours agoparentprev> Atmos-enabled surround-sound setup Headphones. You dont need a full setup to enjoy this feature. reply crazygringo 10 hours agorootparentI don't think Prime Video supports even 5.1 surround sound over headphones. I tried pulling up content in Prime Video on my iPad with my AirPods Pro and the sound output in iPadOS says \"Spatializing Stereo\". Not \"Spatial Audio\" which indicates receiving an actual 5.1 source. So with certain other apps yes, but with Prime Video specifically it seems like no. (Nor can I find anything reputable online confirming it's supported.) Also, the vast majority of content is only 5.1 surround sound anyways. Atmos is still only used in a minority of modern films, and only the tiniest sliver of TV shows. reply nelblu 10 hours agoprevI had a trial subscription of Prime couple of years ago and I hated that they showed skippable ads about other Prime content at the beginning. That was enough for me to never join Prime. reply razodactyl 10 hours agoprevThis is a bit of a petty way to artificially widen the value gap between tiers no? We're not really in the era of customers not knowing any better anymore. reply VanTheBrand 10 hours agoparentThere are 167 million prime subscribers. If only 5% don’t know better that’s over 8 million subscriber. If you surveyed 100 random Amazon customers what percent do you think would actually know what Atmos and Dolby Vision are? I doubt it’s even 50% reply harrylepotter 10 hours agoprevI cancelled my Prime membership 3 years ago after moving to Australia. Haven't missed it in the slightest. I make far fewer impulse purchases and found prime video anaemic at best. reply joemi 10 hours agoprevWhat would it take to have an open alternative to the various license-required Dolby formats? Are there any initiatives already underway? Is it just algorithms and software or do they also make codec chips or some other kind of required hardware? reply sakopov 10 hours agoprevSeems like we made a full circle back to cable-like services but more expensive. reply ado__dev 11 hours agoprevThe greed knows no bounds. Amazon Prime cancelled. reply 1970-01-01 11 hours agoprev5.1 audio channels is all you really need. reply juliusdavies 11 hours agoparentI recently streamed the Taylor Swift Eras concert movie through Apple TV (Dolby Atmos) and Amazon Prime (Dolby DDS I think?) to compare (through a Denon X6200W with a 9.1 speaker setup). Yes, I paid the $19.89 two times. For science. The audio quality with Atmos was substantially better. reply randgoog 10 hours agorootparentThe confusing thing about Atmos is that there are basically two versions of it. There is the TrueHD version that you get on BluRay discs which is the highest, uncompressed quality. And then there is the streaming version which uses Dolby Digital Plus as a wrapper for a compressed version of the audio signal. Atmos on its own really just tells you that there are height channels. Dolby has made all this stuff quite misleading and confusing to the average user. reply bombcar 11 hours agoparentprevI would be interested to know the actual audio setup of most video watching ... I suspect that even if you ignore whatever (probably huge?) percentage is on mobile, that much of it comes out of whatever TV speakers are being used. Even my 7.1 receiver is down to a single laughable channel, because I've not been arsed to fully set it up and a wire is loose. reply o11c 11 hours agorootparentI expect most people use at most a soundbar. Which, regardless of what it advertises, is really just 2-3 channels and maybe a subwoofer. And the rise of phones means there's a lot of stereo or even mono. reply stuaxo 11 hours agorootparentprevBought a receiver years back, only ever bought two speakers - whole thing isn't plugged in since I moved two years ago, just the little speaker in the TV with no bass. reply woobar 11 hours agorootparentprevMy guess is a lot of people with bigger TVs are getting soundbars. They are easy to setup and doesn't require wires. I won't switch from 5.1 setup but if I ever move I would give it a try. Built-in speakers I've used in hotels/airbnbs are not great. reply recursive 10 hours agorootparentSoundbar marketing has a lot of snake oil about bouncing soundwaves around a room to simulate 13 discrete speakers or something. I've got no science, but I do have some serious doubt whether the bouncing stuff works at all. In my imagination, soundbars are basically stereo, or maybe 2.1 reply woobar 7 hours agorootparentI was skeptical for a while. But I have a friend who is used to a 5.1 setup and moved to a much smaller apartment. He has switched to a soundbar with Atmos and says it is on par. The fact that he \"downloads\" Dolby Atmos versions of movies even when they are available for streaming added some weight to his opinion. I still did not compare myself so would not go to fight over this. reply recursive 5 hours agorootparentI don't know your friend, but people are not good at listening. There's a whole industry catering to audiophiles with products that can't pass a blind test. Cynically, I might suspect that your friend is trying to justify their purchase to themselves. Or maybe I'm wrong. But the anecdote doesn't convince me either way. reply bombcar 10 hours agorootparentprevI've always considered them the \"Bose\" of our generation (built on shitty engineering) - they sound better and bassy and so they sound \"good enough\". reply solardev 11 hours agorootparentprevJust wait a few years and you'll be like me, seven speakers and one good ear. reply catchnear4321 11 hours agoparentprevjust in case anyone is wondering what happened to the audio on their ad tier videos next month… reply ChrisArchitect 11 hours agoprev[dupe]/Related: Amazon Prime Video Ad Tier Sparks Class Action Lawsuit from Subscribers More discussion: https://news.ycombinator.com/item?id=39350257 reply Animats 11 hours agoprev\"I am altering the deal. Pray I do not alter it any further.\" reply hnburnsy 7 hours agoparentAltering the deal was the ads, removing Dolby is altering it further. A year from now the ad load will increase, altering it even further. All consumer prayers go unanswered. reply tpowell 11 hours agoprevI’m letting my Prime lapse for the first time in well over a decade. I don’t watch Prime Video much, but this rubbed me the wrong way when they’re making money hand-over-fist on top of recent Prime increases. reply Larrikin 11 hours agoparentI don't use Prime Video much either but this was the straw that broke the camels back and made me really consider the value I was getting from Prime. I realized I was actively avoiding buying from Amazon for multiple fears. Lately fear of getting absolute junk drop shipped from China. I didn't trust them to get anything to me that was sensitive. I had a hard drive delivered in a static bag and one single bubble. They still do OK if you have a specific brand or model in mind. Despite HNs insistent that all they do is deliver counterfeit goods, I've never gotten any, just lately cheap junk or occasionally clearly used items being new. And Prime doesn't even mean two or one day delivery anymore, just free shipping and we'll get it to you when we get it to you. I'll save the 100+ dollars and just pick up from target when I need something quick. reply nickjj 10 hours agorootparent> And Prime doesn't even mean two or one day delivery anymore, just free shipping and we'll get it to you when we get it to you. I never had Prime and shipping is about the same with the only exception that you must spend $35 or more to be eligible for free shipping. It used to be $25+ but they changed it. I've gotten packages in 1-2 days a number of times and 5-7 days most of the time but I don't order a lot. Usually what happens is I'll order something on let's say a Monday, it won't ship until Friday and then I get it on Saturday. reply jacurtis 10 hours agorootparentprev> And Prime doesn't even mean two or one day delivery anymore, just free shipping and we'll get it to you when we get it to you. I laughed at the final sentence. My wife and I were talking with friends last week and both of us have independently decided to cancel prime on the next renewal because the prime shipping is random. We summed it up the same way, \"For $12 /month we will deliver your product for free... eventually\". Sometimes I get it stuff the next day (rare but does happen), sometimes I get it in 3 days, sometimes a week, sometimes several weeks. I have a book that I ordered 3 weeks ago. It never shipped, so I cancelled it. Then as soon as I cancelled and went to the product page, I saw that it was available to get the next day, so I ordered it again and sure enough the new order arrived the next day. We had a package that arrived about a week ago. We weren't expecting a package, but we opened it up, and it was something that we had ordered 6 weeks earlier and had forgotten that we ordered. Furthermore, we used to have Amazon Key delivery into our garage. I know a lot of people think its creepy but we loved it. Packages were always safe, we had a camera in the garage we could see whenever the driver dropped it off, plus packages always were delivered to the right house since they could see the garage door open, the knew it was the right place. Then randomly, Amazon started charging either $3 extra per delivery for this a few months back, or you had to wait an extra week to get it for free. What? We pay a premium subscription for delivery already, why do we have to pay more for a delivery that is more secure, costs Amazon nothing, and was more reliable? So we started just getting stuff delivered to the door. Since then, we have only received about 2/3 of our deliveries. They are consistently delivered incorrectly. So we are forced to either a) pay a $3 premium per order to get it delivered reliably, b) wait a week to get it delivered without a surcharge (only the cost of our subscription), or c) roll the dice with the door delivery. Keep in mind, UPS and FedEx never have problems with deliveries, only Amazon because they are random gig-worker drivers who are not experienced, just delivering as quick as possible to get the next gig shift. On top of the \"eventual\" delivery, now Prime Video, which was already the worst of all the streaming services started doing ads. I bit my tongue on it, but now the loss of Dolby Vision and Atmos pisses me off, because I have an amazing home setup that supports both of these and we really appreciate and notice these technologies. All in all, we are cancelling Prime. Prime Video was not that great anyway. And if I am just going to get random delivery times that can take upwards of several weeks to arrive, then I see no reason to pay for that. I can still get free shipping on $35+ orders from Amazon that will also arrive in a week without a prime subscription. Or I'll just pay the surcharge when I need a faster delivery. This all leads to us using Amazon less, which I am honestly fine with. reply mdasen 9 hours agoparentprev> this rubbed me the wrong way when they’re making money hand-over-fist on top of recent Prime increases. Are they? AWS is very profitable, but the e-commerce business isn't doing as well. In North America, their operating margin is 4.2% for the past 12 months. International operating margin is -2.0% so they're still losing money on their international retail business. Overall, their retail business net margin is probably around 1.8%. They're making good money, but AWS is less than 5% of their revenue and accounts for 67% of their profits. The retail business does a ton of sales, but has very thin margins on those sales. I definitely encourage people to do things like cancel Prime. Companies offer better deals when they know people will walk away. However, I wouldn't say that Amazon is making money hand-over-fist on their retail business. Their margins are pretty tight there. reply wheels 10 hours agoparentprevDitto. Price doubled while the service declined. Amazon used to offer a credit card in Germany that offered more cashback with Prime, and they pulled that too. I mostly only care about the fast shipping, and that doesn't seem to be much different than non-prime shipping anymore. For the few times I actually need it, I can pay for fast shipping explicitly and still come out under €90. Things have been so bad with the direction of Prime that I've actually wondered if they're trying to kill it off. reply enobrev 11 hours agoparentprevJust dropped it as well after maybe a decade of membership. Waiting an extra couple days for shipments has been fine. We don't trust Amazon as a store anymore anyway so we don't order much from there. reply Mistletoe 10 hours agoparentprevSame here, it’s just not worth it anymore and the ads on Prime Video sealed the deal for me. Anything I wanted to watch on my list has been replaced by “rent or buy” below it and what’s left is trash. We buy too much crap from Amazon anyway and I’m done paying $139 a year for the privilege. We cancelled our Netflix too. HBO Max continues to be the only thing that has actual movies on it. Let me edit my comment to add some more substance. If these statista numbers are true, it seems like I'm not the only one. The first lower number ever happened in 2023. It will be interesting to see the 2024 numbers. https://www.statista.com/statistics/1223385/amazon-prime-sub... reply A4ET8a8uTh0 11 hours agoparentprevI cancelled when they announced limited ads ( or however they phrased it ) to create new content. I did not watch Prime and was using Amazon less and less ( after actually going through my orders, it turned out not to be enough to spend on Prime membership ) and they still had to balls nickel and dime me. I suppose I should thank them to kinda force me re-evaluate this relationship. I suppose Cory was right; enshitiffication continues unabated. I am not certain people approach the way I do. Hell, I was ready to drop Sirius after their upcoming changes letter came in, but wife is clearly addicted so baby steps there are needed. Maybe amazon figured they don't need to be good. reply indigodaddy 10 hours agorootparentI just started a siriusxm trial (never used before) on a new truck and the audio quality is so atrocious that I can’t bear to listen to it. Maybe for like sports talk it might be tolerable but definitely it’s so much worse than even radio (seems like 4x worse than terrestrial radio) for the audio quality that how can anyone pay for this service? reply TylerE 10 hours agorootparentBecause it existed for 15 years before data roaming existed. reply mikestew 10 hours agorootparentNo, it’s because the audio quality used to be good, before they tried to see how many channels they could ram in there. Must have been going on 20 years now since we first got XM. When Sirius and XM merged,that’s about the time I recall the quality going way down. And good luck to OP in cancelling that trial. We bought a new car, too, and I didn’t even bother to activate satellite radio. reply TylerE 6 hours agorootparentIt was never good. Maximum bittate per channel was something like 48kbps. reply jrnichols 7 hours agorootparentprevit seems like they gave a bunch of satellite bandwidth to the stupid Howard Stern channels and cut back on the music ones. at least some of them. reply TylerE 5 hours agorootparentThat happened in 2008. Relatively ancient history. Getting Howard was the entire reason they bought out Sirius reply A4ET8a8uTh0 10 hours agorootparentprevI use it to listen to listen to talk radio, which does not have to be great quality. Business news/talk are also somewhat interesting. In other words, it has moments. It is ok for music if you are half deaf like me:D reply jbl0ndie 10 hours agorootparentprevEnshittification it is indeed. reply sys32768 10 hours agoprevI cancelled due to ads a few weeks ago after 10+ years of Prime. I was also sick of yelling at Alexa who pretends not to understand me. Streaming has lost its appeal to me compared to owning the discs. eBay is especially affordable now with so many Goodwill sellers offering used blu-rays. reply mns 1 hour agoparentWait, if you drop prime you can't use Alexa any more? reply webworker 5 hours agoparentprevI still have prime, but only to keep shipping costs down. I don't use any of the other junk. I second the used media. That's a great way to very affordably build your collection. reply tootie 10 hours agoprevI have genuinely no clue what Dolby Atmos is even for. I assume it's for some specific sound setup? And I also assume I don't have that. reply wccrawford 10 hours agoparentYeah, it adds speakers above you. It sounds dumb, but even crappy speakers really did make our sound more immersive. That said, we moved the TV to another room and decided against installing Atmos speakers there... So I guess it's not compelling enough to really care. A good 5.1 setup is enough. reply crazygringo 9 hours agorootparentYeah, it's really not much meaningful benefit over 5.1. If you want cool effects in a war movie of a plane flying by overhead, then awesome. But in most television and movie scenes, the sound is coming from a circle around you on the ground. Putting another 2 (or 4) speakers on the ceiling isn't usually going to make much of a difference. It's truly just diminishing returns. For the war or action movies where it does, my advice is just to go see it in the theater. reply randgoog 10 hours agoparentprevAtmos has height channels added to the audio track. So you'll either need speakers in your ceiling or a setup which tries to emulate that by bouncing the sound off the ceiling to really benefit from it. reply tech_ken 10 hours agoprevI cancelled Prime many months back with the fortuitous expiration date of the last subscription coming up in early March. Feels really great to be leaving as this massive wave of enshittification comes crashing down. reply causality0 11 hours agoprevI'd be happy to give up Prime Video entirely for five dollars off my yearly subscription. reply fabian2k 11 hours agoprevI canceled Prime after they added ads. I might have canceled it anyway at some point, but this was a very clear and significant reduction in value. They never really competed all that well, but there were some interesting original shows on there that kept me interested enough to keep a subscription. But they were really bad about having the original language audio, and they rotate content out pretty fast, my watchlist is always half-gone. reply TigeriusKirk 11 hours agoparentI did the same. I know it won't matter to them, but I feel better not paying for a product they're actively and intentionally making worse. It does also mean I'll be doing much less frequent business with their store. reply A4ET8a8uTh0 11 hours agoparentprevnext [–]This behavior has led to existing film studios folding and getting bought out by these giants. Netflix, Paramount and the rest are swallowing up small productions too. From an industry-outsider's perspective - now seems to be the best time in history for small, quirky, weird, niche productions to get in front of huge viewership numbers. [1] https://www.washingtonpost.com/technology/2024/01/29/amazon-... [2] https://gamerant.com/citadel-prime-video-expensive-failure-e... reply bombcar 11 hours agorootparentDisney did a few \"direct to Disney+\" releases (and eventually on DVD, Blurry, etc). The third Hotel Transylvania movie was direct to Prime (Amazon bought it fully made). reply sleepybrett 11 hours agorootparentprevTed Lasso was an AppleTV+ production. One of the biggest streaming success stories, right up there with your stranger things, etc. The Boys was an Amazon production. Also a huge success story. reply VanTheBrand 10 hours agorootparentTed Lasso is a Warner Brothers production licensed to AppleTV more accurately. reply woobar 10 hours agoparentprevTraditional studios was also \"propped\" by unrelated business. Seagram/Unviersal, Gulf+Western/Paramount, Transamerica/UA, (Time,AOL,AT&T)/WB, Sony/Columbia, News/Fox. On what grounds a business should not be allowed to buy another unrelated business? reply threeseed 11 hours agoparentprev> Both of these are propped up on the profits of unrelated business units and offered below cost to viewers Do you have evidence of this ? Apple has historically chosen not to use the loss-leader approach. reply VanTheBrand 10 hours agorootparentI agree. Apple offers TV+ in their Apple One bundle. Their services revenue is huge and this is a big driver of it. News+ and TV+ on their own are not necessarily profitable but I would bet the bundle that includes them is more profitable than the iCloud extra storage only tiers and more than makes up for the cost. This is very different from they make a lot of money on iPhones so they can afford to waste it on TV shows. reply zelos 11 hours agoprev> The Rings of Power... now in HDR10+ for ad-tier users. I'm not sure even the power of Dolby Vision could make Rings of Power worth watching, though. reply JoshTriplett 11 hours agoparenthttps://en.wikipedia.org/wiki/De_gustibus_non_est_disputandu... reply jeffbee 11 hours agoparentprevThis is the real problem with Prime Video. The first party content is terrible. reply bigstrat2003 11 hours agorootparentClarkson's Farm is legitimately good. It's worth checking out. reply Loughla 11 hours agorootparentI'll second this. It also helped me to humanize Jeremy Clarkson as more than just an old oaf. The moment at the end of the first season when they're totaling up his profit for the year. It is delicious. Top 10 TV moments, when the realization of what he's doing washes across his face. reply FredPret 10 hours agorootparentHe's a really good actor. He obviously knew his farm was losing money before that scene. reply 1000100_1000101 10 hours agorootparentprevI'd like to see a fairer accounting, amortizing the equipment costs instead of incurring them all in full on year one. reply minimaxir 11 hours agorootparentprevThe Boys/Invincible are generally at the top of the Most Watched lists on Prime when they release new episodes. reply shahar2k 10 hours agorootparentsame here and there's a few non \"shipping time\" bonuses I remember hearing about and noting that I wanted to try... but then never did, I wonder if I should cut them off because I really dont mind just \"acquiring\" those shows otherwise if I want to watch them reply ilikecakeandpie 11 hours agorootparentprevThe Boys is great, but I can't really say there's anything else that I'm excited about reply tptacek 10 hours agorootparentprevMr. & Mrs. Smith is good, brand new, and seems critically well-liked. Their general catalog is about as good as, if not better than, Netflix, even if their original content isn't. The Ad-free subscription for Prime Video doesn't cost enough for me to care about. reply MBCook 11 hours agorootparentprevThey’ve had a few. Marvelous Mrs. Maisel was fantastic. So was Sneaky Pete with Giovanni Ribisi. Unfortunately that doesn’t seem to be well-known. I don’t really know much else they’ve done, besides the man in the high castle. I just don’t hear about them much, and the fact that I find their app rather obnoxious means I don’t go looking in there very often. As soon as they announced they were adding ads I deleted the app off all my devices. I basically never use it anyway, and now I definitely don’t want to. And clearly I don’t like it well enough to pay to remove the ads. Honestly I wish the government would somehow break up prime. I’m happy to pay for shipping but I basically don’t want a single other benefit. reply Cyph0n 10 hours agorootparentMy two favorite hidden gems are Patriot and ZeroZeroZero. They also did Outer Range, A Hero (movie), Red Oaks, Good Omens, and Mozart in the Jungle. The Boys and Invincible are both excellent, but more “mainstream” shows. reply zer00eyz 11 hours agorootparentprevThe app sucks, the way they present content sucks. There was a series on prime called Mammals that remains seared into my brain. I have no idea why I started watching it, or why, because nothing about the show is my taste. By the end I was oh so glad I did... I have yet to find someone else who has seen it. reply melvinram 11 hours agorootparentprevJack Ryan and Reacher are pretty good. reply Someone1234 10 hours agorootparentReacher's first season was good. Second season turned into a bad action movie. Bad writing, little time spent on characters/development while adding six new characters we were given no reason to know or care about. It is legitimately too bad, they really had something with S1. reply kasey_junk 8 hours agorootparentThat is very authentic to the books. reply nocommandline 9 hours agorootparentprevReacher is based on the books. The ‘new’ characters were in the book (they were part of Reacher’s team and were being killed off). reply parthdesai 11 hours agorootparentpreveh, both had great 1st season and then they were terrible in the following seasons. reply javajosh 10 hours agorootparentprev\"Reacher\" is simply right-wing violence-porn. Its moral turpitude is only exceeded by the risible \"Mr. and Mrs. Smith\" that somehow wants me to like protagonists who kill and hurt strangers without any justification. I've loved everything Donald Glover was in, until now. Meanwhile, \"Rings of Power\" is left-wing girl-boss porn that utterly disrespects everything Tolkien made. Above all, Amazon's blatant anti-labor practices and monopolistic size makes it an important company to avoid. There are many smaller, better companies that specialize in different markets and offer better deals and support, and if they do err at least they will do so at a much smaller scale (personally I like alibris for books, discogs for music, b&h photo for electronics, the local dollar store for supplies like toothpaste and detergent, and the local thrift store for everything else). reply Alupis 10 hours agorootparent> \"Reacher\" is simply right-wing violence-porn. > Meanwhile, \"Rings of Power\" is left-wing girl-boss porn You are aware not everything needs to be political, right? Sometimes bad television is just bad television... reply javajosh 10 hours agorootparentI think it's an accurate description that successfully conveys the manipulative, puerile, and harmful nature of these shows in a compact way. My description isn't political in the \"right vs left\" sense although I admit it may be political in the \"extremism vs moderate\" sense. Personally, I think that the information we consume cannot help but shape our world-view, so identifying how it shapes our world-view is valid criticism. Reacher and Galadriel are, in my view, icons of their respective flavors of extremism, and I think Amazon does poorly to produce such content. reply Alupis 9 hours agorootparentHave you actually watched Reacher? There is no politics in it at all. It's reminiscent of poorly written 80's action flicks, disguised as a noir mystery. Again, sometimes bad television is simply bad television. Not everything needs political coloring. reply jeffbee 8 hours agorootparent\"Ex-military strongman solves our problems through murder\" is an inherently political framework for a story. It is as politically tainted as the old show \"24\", where any and all ethical frameworks were shredded on the altar of the ticking bomb scenario. reply Alupis 6 hours agorootparentPlease explain the politics of \"Ex-military strongman solves our problems through murder\". Specifically, what is the political message being pushed? reply jeffbee 6 hours agorootparentThat the maintenance of the rule of law requires One True Man to stand outside the law and protect us through extrajudicial killing and torture. It is a statement on the core concept of law and justice. reply Alupis 3 hours agorootparentOk, and what are the politics of that statement, if any? reply nocommandline 9 hours agorootparentprevIn the books, Reacher was violent when he needed to be. The author made him ‘huge/large’ and his size enabled his act of violence/ability to mete out justice to the bad guys. Reacher’s size in the books is why folks complained when Tom Cruise starred as Reacher in the movies reply _joel 10 hours agorootparentprevThe Expanse was fantastic (although checking now it started on Syfy for first 3 series). reply ohthatsnotright 10 hours agorootparentThere is a network that has consistently shot themselves in the foot, and refuses to understand it. The number of great shows that started on SyFy (and some from Showtime that moved to SyFy and then moved on) is incredible but they all end the same, abruptly cancelled because they didn't get the ratings that WWE would get. reply dualboot 11 hours agorootparentprevThis is not even remotely true. Patriot is amazing. reply evanelias 3 hours agorootparentAnother vote for Patriot here. I think it flew under the radar due to the poor choice of title, but it's just so ridiculously good. Darkly hilarious writing and a really solid cast. It's funny how Michael Chernus keeps playing brother roles (\"Cool Rick\" on Patriot, Cal on Orange is the New Black) or brother-in-law (Ricken on Severance). Dude just has a real brotherly vibe, perfect choice for this show. And then separately it's kind of weird to think that Patriot's showrunner's real-life brother is an actor in the show (playing Dennis), considering some of the scenes that character is in... reply jjulius 11 hours agorootparentprev>This is not even remotely true. It's a subjective opinion, therefore entirely true to OP and not even remotely true to you. reply tptacek 10 hours agorootparentprevPatriot rules, and is criminally under-watched. True facts: I watched the first season of that show without realizing that my sister-in-law is in it, until she shows up in like episode 2 (and through the rest of the season). An extremely WTF moment, I recommend everybody have it on some kind of show. reply jeffbee 11 hours agorootparentprevThere is no accounting for taste of course, but this show appears to have a 35% dislike vote fraction among Google users and 68% favorable on Metacritic. Which puts it objectively well below other Prime shows that I personally think are extremely bad, such as Reacher and Jack Ryan. reply mdhen 11 hours agorootparentPatriot is amazing. One of the best black comedys ever made. reply sleepybrett 11 hours agorootparentprevAlso 'The Boys' is quite popular, 'Bosch' and 'Reacher' are very popular.. there are a few others that do well. If you are old enough think back to the haydays of the network television evening programming. There were hits, there were misses, there was tons of stuff in between. For every 'Friends' there is a 'Two Guys a Girl and a Pizza Place'. reply nytesky 10 hours agorootparent2GGPP launched Ryan Reynolds and Nathan Fillian and Susan Cryer from Silicon Valley. It’s a bit of a gem in its own way reply manquer 11 hours agorootparentprevFor every “Friends” there are thousands of ‘Two guys a girl and a pizza’ reply jhallenworld 10 hours agorootparentprevI had such high hopes for Wheel of Time.. reply thelastparadise 11 hours agorootparentprevTurns out gobbling up IP and hitting the print button isn't such a great business model. Also see: Disney. reply sleepybrett 11 hours agorootparentSee also every television/cable network ever. Every season a few shows would rise to the top and a few would get put out of the misery, you just move on and hope the good bets make more money than the bad bets burn. reply jeffbee 11 hours agorootparentI don't get why this would be an issue for Prime. They don't have to fill up a schedule so they can sell ad slots. They can make as little or as much content as they want. They don't need to make a \"Veronica's Closet\" to cram in between \"Seinfeld\" and \"ER\". reply lnxg33k1 10 hours agoprev [–] I salute with happiness everything that is disliked by people, multimedia is a waste of time, free shipping is shallow consumerism, well done amazon! reply 4death4 10 hours agoparent [–] What do you spend your time doing? reply lnxg33k1 6 hours agorootparent [–] Defending myself from American culture reply 4death4 4 hours agorootparent [–] Doesn’t really sound anymore fulfilling than multimedia or shallow consumerism. In many ways, it seems substantially worse. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Amazon Prime Video has quietly removed support for Dolby Vision and Dolby Atmos from its ad-supported tier, leaving subscribers unaware of the change.",
      "Users opting for the ad-supported tier are now restricted to HDR10+ and Dolby Digital 5.1, potentially to reduce licensing fees paid to Dolby Laboratories and promote HDR10+ as a no-cost alternative.",
      "This is not the first time Amazon has made changes to its Dolby features, further frustrating customers who are feeling the shift towards streaming services resemble traditional cable TV. Amazon has not given a reason for the removal."
    ],
    "commentSummary": [
      "There are ongoing discussions and debates about various topics related to Amazon Prime Video and Amazon's services.",
      "Topics include the removal of Dolby Vision and Atmos support, the addition of ads on the streaming service, customer satisfaction, market segmentation strategies, soundbars, delivery services, cancellation of Prime subscriptions, satellite radio, profitability of Amazon Prime Video, original content, presentation of content, and the political nature of TV shows.",
      "Opinions among users differ, with some expressing satisfaction and others expressing dissatisfaction with different aspects of Amazon's services."
    ],
    "points": 199,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1707774704
  },
  {
    "id": 39345618,
    "title": "The True Motivation Behind Max Planck's Quantum Physics: Debunking the Ultraviolet Myth",
    "originLink": "http://www.arxiv.org/abs/2402.03405",
    "originBody": "Physics > General Physics arXiv:2402.03405 (physics) [Submitted on 5 Feb 2024] Title:The Ultraviolet myth Authors:Nils-Erik Bomark, Reidun Renstrøm Download PDF HTML (experimental) Abstract:It is very common to introduce quantum physics in an historical context. Though there are advantages to this, it is a problem that many of the stories that have become central to the physics lore are mere pseudo-histories far detached from the real events. It is about time that we stop uncritically copying these stories and instead make an effort to present the development of quantum physics as it actually was. This paper deals with one of the most common myths in quantum history, the one about the ultraviolet catastrophe and how it motivated Planck's introduction of quantum physics. On closer inspection it turns out this story has the time-line completely turned on its head. The ultraviolet catastrophe was first discussed several years after Planck published his radiation law so it played no role in his motivation. Instead Planck was concerned with finding a theoretical derivation of the law for blackbody radiation. This law was first thought to be Wien's radiation law, but when new data disagreed, Planck came up with his own law that fitted the data. Planck's radiation law first came about as an elaborate fit to data and to derive it he found no other way than to use statistical mechanics and divide the energy that was to be distributed on the atomic oscillators into packages $hf$ so that he could count the number of ways to distribute this energy. Planck did not consider this a quantization, but merely a mathematical trick to be able to calculate the entropy of the oscillators. Comments: Accepted for publication as proceedings for EPS-HEP 2023 Subjects: General Physics (physics.gen-ph) Cite as: arXiv:2402.03405 [physics.gen-ph](or arXiv:2402.03405v1 [physics.gen-ph] for this version)https://doi.org/10.48550/arXiv.2402.03405 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Nils-Erik Bomark [view email] [v1] Mon, 5 Feb 2024 14:21:07 UTC (32 KB) Full-text links: Access Paper: Download PDF HTML (experimental) Other Formats view license Current browse context: physics.gen-phnewrecent2402 Change to browse by: physics References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=39345618",
    "commentBody": "The Ultraviolet Myth (arxiv.org)198 points by Luc 18 hours agohidepastfavorite86 comments stracer 14 hours agoThis particular part of \"physicist's history of physics\" about quantization and Planck's work, promulgated by some sources, is well-known to be a false account of history and motivations, and has been criticized in mainstream literature before, e.g. by Helge Kragh [1] (and probably by many others). The present authors apparently are not aware of this, which makes me suspicious that they did not do their homework on this topic... [1] https://dept.math.lsa.umich.edu/~krasny/math156_article_plan... reply djmips 8 hours agoparentMaybe, maybe not but the false account continues to be propagated. reply alecst 17 hours agoprevIt's so interesting. This isn't the only paper written about this, because I actually came across this same idea last month in a much older paper. Here's an extract from it: > It might have been thought, by some scientists in the 1890's, that refined mathematical analysis of this kind would play a role in resolving the fundamental problems of classical physics associated with the apparent failures of the equipartition theorem. But that is not what happened. > Although the quantum hypothesis did dispose of the paradox of specific heats of polyatomic gases, and eliminated the possibility that ether-vibrations (having an infinite number of degrees of freedom) would drain an indefinite amount of energy out of material systems at any finite temperature, these were not the anomalies that provoked the introduction of the quantum hypothesis in the first place. Max Planck was not one of the physicists who worried about the validity of the equipartition theorem before 1900, and the myth that his distribution law for blackbody radiation was concocted merely to escape from an \"ultraviolet catastrophe\" predicted by the Rayleigh-Jeans law has now been thoroughly demolished. It was Paul Ehrenfest who invented the ultraviolet catastrophe (eleven years after the publication of Rayleigh's and Planck's papers in 1900) in order to dramatize what would have been the consequences of the equipartition theorem if it had been valid for all classical dynamical systems (though neither Rayleigh nor Planck believed that it was). I have this saved as a note, but can't find the exact source atm. Here's another source though, from the 60s: https://sci-hub.ru/https://doi.org/10.1007/BF00327765 reply crdrost 17 hours agoparentI would be very interested to read this. I found one comment in the abstract a little bit off-putting: > Planck did not consider this a quantization, but merely a mathematical trick to be able to calculate the entropy of the oscillators. My understanding was that Planck absolutely understood that his approach would have been a mathematical trick if he took the limit h → 0, but that in stopping at a nonzero small number he was explicitly aware that he was saying something peculiar about the energies in the system, and had strayed far away from that realm of pure mathematics into something that we would today effortlessly identify as quantum, even if that word did not exist at the time. reply lumost 14 hours agorootparentOften, when inventing something new - it can be difficult to assess how novel the \"new\" thing is. Particularly when there isn't yet a word for it. Planck may have simply believed that this hinted towards something equivalent of an \"atom\" of light. Atom's were after all a relatively recent discovery in 1827, why couldn't you have an atom-like construct for light? and why would light atoms be any different regular atoms? While we now know a great deal about this topic - placing such speculation in a paper would be problematic. Hypothesizing that such quantizations are common for other quantities would be even more problematic. EDIT: Removed eroneous mention of michelson-moorly instead of milikan oil drop experiment. reply Sharlin 13 hours agorootparentThe question of whether light is a particle or a wave dates back to at least Newton (who thought it was a particle) and Hyugens (who thought it was a wave). By the end of the 19th century, before Einstein brought up the photoelectric effect, the consensus opinion was pretty firmly on the \"wave\" side of the dispute, and apparently Planck was not an outlier. See another comment: https://news.ycombinator.com/item?id=39349027 reply lisper 5 hours agorootparentprev> Atom's were after all a relatively recent discovery in 1827 Atoms were controversial well past that. Their existence was not definitively settled until Einstein's work on Brownian motion in the early 20th century (which, incidentally, is what he won the Nobel Prize for, not relativity — Update: turns out I got that wrong. See child comment.). The controversy around the atomic theory was so intense it drove Ludwig Boltzmann to suicide [1]. [1] https://paperpile.com/blog/ludwig-boltzmann/ reply kkylin 4 hours agorootparentNit pick: Einstein was awarded the Nobel for the photoelectric effect. https://www.nobelprize.org/prizes/physics/1921/summary/ (I think he could have won it for the theory of Brownian motion too!) reply lisper 4 hours agorootparentI stand corrected :-) reply DiogenesKynikos 14 hours agorootparentprevI think you mean the Millikan oil drop experiment. reply alacritas0 11 hours agorootparentEven though this is tangential, I think it's important to note that this experiment should be called as the Millikan-Fletcher oil drop experiment to acknowledge Harvey Fletcher's contribution to this experiment as a grad student which he was coerced into relinquishing to receive his PhD reply shagie 8 hours agorootparentFor any who wish to read about this: My work with Millikan on the oil-drop experiment - https://web.archive.org/web/20160128151252/http://www.cce.uf... reply tangj 13 hours agorootparentprev... Since Michelson-Morley was supposed to show the relative speed of the Earth through the ether, but instead showed there was no ether at all. reply lumost 13 hours agorootparentprev:doh: good catch :facepalm: it's been too long since physics undergrad. reply prof-dr-ir 17 hours agoprevThis paper is nice but appears to stretch its result quite a bit. First, the authors make a general claim about \"most physics textbooks\" without providing a single example. I think one will often encounter more nuanced statements in the better and more widely used textbooks. And I think the paper sorely lacks evidence for the general claim in the concluding sentence: \"The idea that physics progress through a series of crisis, is hard to defend.\" Not only do they present only a single example, but even in that case one could claim that the \"crisis\" started after the discovery of Planck's formula! After all, it fitted the data supremely well but required this mystery constant: h. It took physicist a quarter century to resolve the deeper meaning of Planck's constant. If that was not a crisis in physics then I do not know what would qualify as one. reply btilly 16 hours agoparentI have no idea about current textbooks. But certainly the physics textbook that I learned from quoted the myth. And it is easy to find examples online, like https://chem.libretexts.org/Bookshelves/Physical_and_Theoret..., that still do. I wish it were otherwise, but there are some weird dynamics in the textbook industry that reward looking like other textbooks more than accuracy and usefulness. A classic essay showing this is \"The Case of the Creeping Fox Terrier Clone\" in Gould's book Bully for Brontosaurus\" that traces the history of textbooks comparing Hyracotherium* to a fox terrier. This, despite the fact that most students and authors have absolutely no real idea how big a fox terrier is. And it wouldn't help if they did know, given that Hyracotherium actually weighed over twice as much! Another classic essay showing how textbooks repeat other textbooks without properly questioning what should be taught is https://web.williams.edu/Mathematics/lg5/Rota.pdf. If you've taken some variant of the differential equations course that he discusses, I highly recommend reading his essay. I guarantee that it is far from the only standard course with such levels of silliness. reply ilya_m 15 hours agorootparent> Another classic essay showing how textbooks repeat other textbooks without properly questioning what should be taught is https://web.williams.edu/Mathematics/lg5/Rota.pdf. If you've taken some variant of the differential equations course that he discusses, I highly recommend reading his essay. I guarantee that it is far from the only standard course with such levels of silliness. Thank you for sharing Rota's delightful lecture! I wish more professors/instructors took a critical look at their material, which is nearly always is taught in the order that was put in place for some now utterly irrelevant or forgotten reasons. If the science progresses at the speed of the hearse, the education of scientific subjects barely moves at all. reply tomjakubowski 8 hours agorootparentprevsee also Econ 101 textbooks repeating the myth of widespread barter economy \"before\" money reply BlueTemplar 7 hours agorootparentWoah, woah, woah - first that, now this - my world is crumbling ! D: reply pflats 14 hours agoparentprevI was curious, so I grabbed three undergraduate-level physics texts I had nearby. One explicitly recites the Ultraviolet Catastrophe prompted Planck story, complete with Rayleigh's incomplete formula. One essentially matches the story in section 2, using the lesser version of Rayleigh's formula, but (just like the story) does not explicitly tie Planck's work to it. (That textbook notes \"an act of desperation\" is a quote from one of Planck's letters.) The third one is interesting! It says that \"late nineteenth century physicists tried to understand the shape of the blackbody spectrum [...] using their knowledge of thermodynamics and electromagnetic waves. Their efforts ended in failure.\" This third text never mentions Rayleigh by name and doesn't specifically show \"Rayleigh's Lesser Formula\", but it does graph that formula vs. the observed blackbody radiation (interestingly, as a function of frequency instead of wavelength). The text then eventually says that in 1900, Planck used a photon argument \"to make a theoretical prediction that is in excellent agreement with the experimental spectrum\". It does not explicitly state cause and effect, but it's kinda implied from the structure of the writing. Reading into the third text a smidge, it feels like the result of wanting to use the Rayleigh/Catastrophe story and yet knowing it wasn't quite true. reply stracer 14 hours agorootparentThe third source is still wrong, as Planck certainly would not agree that he used the photon argument to make a prediction. He tried to explain the experimental data on blackbody radiation, which manifested the spectral peak, and an agreement with the Rayleigh-Jeans and Wien laws in the two frequency limits. Thus not a prediction, but an explanation of the observed thing. And he did not believe in photons, he interpreted his work in terms of classical EM radiation obeying some entropy condition, and quanta of energy that he used were considered either a math trick to make calculations with that entropy, or a condition on the emission process only in his later theories. He never assumed or believed that EM radiation consists of quanta. reply smcin 13 hours agorootparentprevUseful to give the title, author, and date of those three texts. reply alecst 16 hours agoparentprevIt's not a stretch at all in my opinion, not only was I taught this myself (multiple times at two separate universities in the US) but there was a paper addressing this myth as far back as the 60s. Though I do agree with your second point. I can name two crises off the top of my head: the black hole information paradox, and the galaxy rotation curves which some claim are due to dark matter. One is a major theoretical problem, and the other is a major experimental problem. And though crises they may be, it's not like people are running around with their hair on fire. reply d0mine 13 hours agorootparentThere is a crisis in cosmology right now e.g., the apparent conflict in our measurements of the expansion rate of the early versus the modern universe. https://youtube.com/playlist?list=PLd19WvC9yqUf5TRqYoMYxEwjT... reply nullc 10 hours agorootparentIt's not really a conflict in rates that is the issue, so much as a conflict about the jerk of cosmic inflation? :P reply cyberax 12 hours agoparentprevRealistically, the UV catastrophe was not a crisis. Simply because pretty much nobody understood its implications. It was like: \"Quantization of light makes this formula work? OK, whatever\". At that time, the main catastrophe was caused by the null results in the search for the luminiferous aether (Michelson-Morley experiments). At the same time, questions about the structure of matter and the composition of the atom were another crisis point. Earnshaw's theorem states that matter can't be held together by electromagnetic forces alone. reply f1shy 15 hours agoparentprevI do not think calling out specific books would be remotely good idea in many different levels. There are ao many examples, it makes no sense to enumerate any. Virtually every explanation I know starts with that myth. reply bmacho 14 hours agorootparentWhy do you think that? I think naming 3 of them would be better than naming 0 of them. reply _dain_ 13 hours agorootparentI don't have a textbook at hand but I remember being taught this history by physics lecturers in my undergrad. I find it strange that many people in this thread are gainsaying the existence of this narrative. It's surely a commonplace part of physics education? reply vondur 15 hours agoparentprevMy Physical Chemistry textbook also refers to it as the UltraViolet Catastrophe. reply alacritas0 16 hours agoparentprevi wouldn’t consider a quarter century of work by the field a crisis reply littlestymaar 16 hours agoparentprev> to defend.\" Not only do they present only a single example Really? When there Mercury's perihelion mystery at the exact same period? (Which got us general relativity) reply bjornsing 17 hours agoprevI have a masters degree in physics from a Swedish university, and I don’t think I’ve ever heard the “myth”. But the actual story as described in the paper is vaguely familiar. Before reading it my mind wandered to Einstein and quantization of light. Is this mainly a US myth perhaps? reply bgirard 17 hours agoparentIt's very common on Youtube physics education videos. My take away from was exactly what the article states. That the ultraviolet catastrophe was observed and that the study of it lead to Quantum physics because it was noted that it could only be explained if things existed in discrete energy levels. reply jerf 16 hours agorootparentI'm not even entirely sure the article establishes that it was false. The wrong equations really had a problem with an ultraviolet catastrophe. If the physicists of the time don't seem to be running around panicking about that, it's because equations not being entirely correct as they are in the process of being refined was even by then a relatively mundane thing, obviously part of the process. We (hopefully) historically stand in a similar position with regard to General Relativity and Quantum Mechanics. We know they don't go together. We don't know what the correct answer is. It's an understood problem. But it's not like physicists spend their days running around and shrieking and breaking down into tears about it, and in the meantime, we get on with using GR & QM to predict things. It may be too strong to say \"Physicists observed this issue with the equations and their freakout about them directly led to quantization.\" But it was a real problem with the equations, and it's certainly related to what led to quantization, and if the story glosses over yet another instance of what a physicists perceived as a mathematical convenience that turned out to be quite physically real, I'm not sure that's a vital detail for every high school student. reply twoodfin 15 hours agorootparentIs it possible there’s some confusion here about the understanding (then and now) of “catastrophe”? As I understand, it wasn’t meant to mean that the theory had a catastrophic flaw, but rather that the infinite energy implied at the asymptote itself represented an (obviously unobserved, thus curious) physical catastrophe. I agree with your characterization that an unresolved catastrophe of the latter kind does not imply a crisis of science the way an unresolved “catastrophe” of the former kind might. reply jerf 14 hours agorootparentCould be. My understanding of the term is the same as yours, but reading it the wrong way would fit the facts, and I have to admit in general I can't be too critical of such a reading. The physics sense of \"catastrophe\" in use here is pretty obscure; I'm not sure I can think of another instance of it I've come across in English. reply Nevermark 12 hours agorootparent“Catastrophe” or “crisis” have a long history of use for sudden change phenomena, especially associated with some major failure or blow up of a previous pattern of system behavior. “Critical” may be a more familiar word used in similar contexts, honed in on a specific threshold of a dramatic behavior change. None of these words in this usage style refer to the scientific social process, but to the phenomena. reply bananskalhalk 17 hours agoparentprevI was taught this in a Swedish high school and it was repeated at a Swedish university one year later. reply bananskalhalk 13 hours agorootparentAdded: Please not that the authors are Norwegian at a Norwegian university, and the first citation are \"KVANTEFYSIKKENS UTVIKLING i fysikklærebøker, vitenskapshistorien og undervisning\" by Reidun Renstrøm at the University of Oslo, all proclaiming the myth being perversive. I would be careful proclaiming this being some kind of American phenomenon. reply BoardsOfCanada 15 hours agorootparentprevSame here as for at Swe university reply somedudetbh 8 hours agoparentprev> Is this mainly a US myth perhaps? I have basically no physics education, but I was educated in the US. In my high school, where I took an ordinary, low-quality physics course (the one for weak students that didn't require calculus), the introduction of quantum mechanics was motivated by the photoelectric effect. Now, like I said, I don't really have any physics education and I don't really understand the photoelectric effect _or_ quantum mechanics, but my basic recollection was waves hands you shine a light on certain materials and electrons pop out, and it looks for various reasons like this behavior is packet-y rather than smooth as one might expect. Basically in an intro American physics class, if they've got an opportunity to get Einstein involved, they're gonna take it. I've never heard of this myth either. FWIW, the authors, Nils-Erik Bomark and Reidun Renstrøm, also appear to work at .no universities. reply Fomite 8 hours agorootparentIt's always been a great irony to me that physics without calculus is (IMO) wildly more difficult than physics with it. reply redavni 17 hours agoparentprevIt has been repeated by YouTube \"science communicators\" quite frequently and very recently. reply dr_dshiv 14 hours agorootparentIt might not be historically accurate, but it’s easy and valuable to learn reply smcin 13 hours agorootparentSince we're on that beat, do we really believe an apple fell on Isaac Newton's head? Rather than merely that he saw an apple fall nearby, and wondered why it fell downwards. reply BeetleB 17 hours agoparentprevSame here. Studied it in 2 different countries, and it was always presented as \"trying to explain black body radiation\". I think UV catastrophe was merely mentioned as a side note. reply f1shy 15 hours agoparentprevSo was explained to me in another non us university. We used books used in MIT, Caltech and Stanford; in all books there was a mention to it. reply kurthr 12 hours agorootparentI've seen many mentions of the Ultraviolet Catastrophe, but I don't remember reading that it directly caused Plank to look for (a quantized) solution. That seems like a historical justification that a QM physics class doesn't need. I looked through both Liboff and Baym and don't see even a mention of ultraviolet (other than problem sets) or catastrophe, but maybe I missed it. These are searchable. https://archive.org/stream/LIBOFFIntroductoryQuantumMechanic... https://archive.org/details/lecturesonquantu0000baym/mode/2u... I don't think the Mechanical Uselessverse (as we referred to it) would be a text for these schools, thought it was produced at caltech and it apparently does refer to the ultraviolet catastrophe. I think you're more likely to find it in videos and narrative historical materials where story is more important. https://archive.org/details/beyondmechanical0000olen/mode/2u... reply pif 17 hours agoparentprevSame here, Italian background. reply bowsamic 17 hours agoparentprevWe were taught this myth in the UK EDIT: both at high school and across multiple different lecturers at university reply ThrowawayTestr 16 hours agoparentprevThere's a whole Wikipedia page for it: https://en.wikipedia.org/wiki/Ultraviolet_catastrophe reply littlestymaar 16 hours agorootparentThere are millions of “whole wikipedia pages” for things most poeple will never hear of in their life… reply adtac 17 hours agoprevDouglas Hofstader has a talk on this topic called \"Albert Einstein on Light; Light on Albert Einstein\" that I often revisit: https://www.youtube.com/watch?v=ePA1zq56J1I (watch 10:30 to 12:00 if you're pressed for time, but I recommend the whole thing) reply agonz253 13 hours agoparentIndeed. I recommend also checking out the 2nd volume of Einstein's collected papers. There is one with the proceedings from a conference on the subject, and Einstein is basically alone in trying to convince his peers, including Planck, of the reality of \"quanta\" of light, independent of the process of emission and absorption or mathematical tricks. reply djmips 8 hours agoparentprevThanks. Watching NOW. reply sgdpk 17 hours agoprevTo be fair, I was taught exactly what this paper claims in my Physics degree. Although I was also taught what they call the \"myth\" in other classes. reply josh-sematic 17 hours agoparentAgreed; my professors did use Planck's trick to introduce quantization, but made it very clear that he was just fitting the data and thought the discretization would disappear with further analysis. reply pdonis 17 hours agoparentprevI was never taught the myth in an actual class. Every time I have seen it has been in the context of a pop science article or book. reply Sesse__ 17 hours agorootparentSeemingly also the Wikipedia article (https://en.wikipedia.org/wiki/Ultraviolet_catastrophe) claims the pop-sci ordering: “As the theory diverged from empirical observations when these frequencies reached the ultraviolet region of the electromagnetic spectrum, there was a problem.[3] This problem was later found to be due to a property of quanta as proposed by Max Planck: There could be no fraction of a discrete energy package already carrying minimal energy.” reply fsmv 17 hours agoprevThis video talks about this story and in particular acknowledges that it was called the ultraviolet catastrophe after Plank https://youtu.be/gXeAp_lyj9s reply DrDroop 17 hours agoparentI wanted to post the same thing, quiet a coincidence I watched it yesterday. reply SKCarr 15 hours agorootparentSeems to have come out one day before this paper was submitted, which is quite a coincidence. reply lewtun 11 hours agoprevThe myth is also promoted in Chapter 3 of The Making of the Atomic Bomb by Richard Rhodes: > Plank had taught at Berlin since 1889. In 1900 he had proposed a revolutionary idea to explain a persistent problem in mechanical physics, the so-called ultraviolet catastrophe reply pbj1968 6 hours agoprevThe Planck institute sent some borderline animal to my city where he proceeded to criticize everything and everyone he saw. He directed some blah blah department under their purview. Completely unimpressed here. reply sho_hn 16 hours agoprevAs a physics layman, I learned his part of history from the book \"Quantum\" by Manjit Kumar, which as far as I can tell got the Planck bit right and covered his black body work correctly, FWIW. It was a good read. reply mcnamaratw 15 hours agoprevhttps://en.wikipedia.org/wiki/Rayleigh–Jeans_law reply adrian_b 16 hours agoprevBesides the myth busted in this paper, that the actually later work of Rayleigh could have influenced Planck, there is another incorrect myth, that Planck has introduced the \"constant of Planck\" in his publication from 1900, where he presented the deduction of the Planck formula from the supposition that the emission and absorption of electromagnetic radiation are quantized. This frequently seen claim is also wrong. Planck has introduced the constant of Planck and he has also computed its value with excellent precision for that time (4% relative error) in an earlier work published in 1899: Max Planck, \"Ueber irreversible Strahlungsvorgaenge\", \"Sitzungsberichte der koeniglich preussischen Akademie der Wissenschaften zu Berlin. Jahrgang 1899\", pp. 440-480. There Max Planck has presented deductions of the formulae previously established by Wien for the blackbody radiation, where he replaced the empirical constants of Wien with functions of other universal constants and of the new universal constant introduced by him. Already Maxwell, a quarter of century earlier, had shown that it is possible to determine the units for all physical quantities with a single arbitrary choice (in his example, the wavelength of the yellow light emitted by sodium vapor). In 1899, Planck has shown that the law of blackbody radiation provides an additional relationship between the units of length, time and energy, which, together with the previous relationships considered by Maxwell, can determine the units of all physical quantities without any arbitrary choice. So at the end of this work from 1899, where the constant of Planck has been introduced, he has also presented the system of natural units known now as the Planck units. Nevertheless, the system of Planck units cannot be used as the base of a practical system of units, because the uncertainty of measuring the Newtonian constant of gravitation is huge. This makes useless one of the equations that connect the units of length, time and energy. Because of that, any practical system of units must contain a single arbitrary choice of a unit, which in the case of SI is the frequency of a certain hyperfine transition of the cesium-133 atom, while all the other units result from this choice by adopting conventional values for the universal constants, except for the Newtonian constant of gravitation, which must be measured experimentally (some constant determining the intensity of the electromagnetic interaction, e.g. the fine structure constant, must also be measured experimentally, but for that the uncertainty is extremely low). BTW, another extremely frequent incorrect claim about the constant of Planck is that it is a quantum of action. This is very wrong, it is a quantum of angular momentum (the ratio between energy and frequency is an angular momentum, like also the ratio between their integrals, i.e. between action and plane angle). The origin of the mistake is the fact that many follow the suggestions of the recent SI brochures (there was a resolution adopted by vote that the unit of plane angle is not a base unit, which is equivalent with establishing by vote that 2 + 2 = 5), and they omit the unit of plane angle in the dimensional formulae, in which case it appears that the unit of action is the same with the unit of angular momentum, but they are not the same, as any attempt to change the unit used for plane angles would demonstrate, e.g. between radians and degrees or cycles. The original constant of Planck corresponds to plane angles measured in cycles, while the so-called h bar is the same constant converted to correspond with plane angles measured in radians. reply BlueTemplar 7 hours agoparent> The original constant of Planck corresponds to plane angles measured in cycles My German is bad, is that from that publication ? Any closest ones in other languages ? Asking for a friend : https://tauday.com/tau-manifesto reply btilly 17 hours agoprevYet another example where it is tempting to retrofit a modern understanding onto a historical debate. We're tempted to do this because when you're embedded to the modern worldview, it is hard to remember that others were once possible. And it is tempting to believe that history was a straight arrow to modern truths. In fact it was seldom such a straight path. Kuhn complained about this in The Structure of Scientific Revolutions. When trying to teach the history of science to scientists, you have to work to get them to stop trying to think the \"correct\" way, so that they can understand the actual historical debate. reply csours 17 hours agoparentOne could easily adopt the idea that the history of science is \"Some smart guy figured this out\" over and over again. The real history of science is: A lot of people became interested in problems and worked on theory and test apparatus and put their ideas into public discussion and eventually and sometimes suddenly we developed narratives and equations that explain observations. Along the way there was a lot of contention and conflict. reply btilly 16 hours agorootparentIt is easy to retrofit many simple stories onto science. In this case the \"smart guy who figured it out\" usually didn't understand the discovery in the same way that we do today. Something was figured out, but typically not in the modern glory that we explain it with today. reply leephillips 15 hours agorootparentprevThe equations don’t just congeal out of the air, no matter how many people are thinking about the problems. They are indeed the results of some smart people figuring things out. reply bee_rider 17 hours agoparentprevI wonder if it might be pop-sci vs science, rather than modern vs historical. Physicists (from the outside at least) have always seemed more like hunters than the town watch, they go looking for the problems. There isn’t some catastrophic looming threat of physics approaching that they have to deal with, haha. Unexplainable data is an opportunity and all that. reply btilly 16 hours agorootparentWhat I'm talking about is very much modern vs historical. To take a trivial example, most of us would like to draw a straight line from Darwin writing The Origin of the Species to the current acceptance of his theory of evolution. We have no particular desire to follow how Darwin's work inspired Francis Galton to study heredity. Unfortunately Galton discovered regression to the mean when he did. Further experiments undermined Darwin's theories as it uncovered evidence for \"natural types\". The result was that a half-century after Darwin's great book, many scientists doubted Darwin's theories. But then R. A. Fischer managed to explain the mess with population genetics based on Mendel's theories. \"Natural types\" disappeared from the literature, and Darwin was back. Today Galton is likely to be remembered as a dilletante who invented the idea of eugenics. And Fischer as a genius in statistics. We retrofit a story with heroes (Darwin and Fischer) and villains (Galton). We skip over the bad parts, and focus on the good. In the process we forget that Darwin also took it for granted that blacks must be inferior to whites. And that Fischer was also a supporter of eugenics. And that Galton set out to confirm Darwin, then accepted the data that he encountered. We want a story, not a mess. But history is full of messes. Arranging the right ideas in the right ways involved a whole lot of trial and error that wasn't obvious at the time. While some of us enjoy learning about the history, it actually isn't very helpful for scientists. Because there is little point in learning every wrong idea that people used to hold, only to immediately learn that you can forget it again because it was wrong. But while that exercise does not help us learn what is currently known, maybe it can help give us more humility about what it is we think we know today? reply CamperBob2 16 hours agorootparentBecause there is little point in learning every wrong idea that people used to hold, only to immediately learn that you can forget it again because it was wrong. Of course there's a point, one you suggest yourself. \"If great scientists like Darwin could be wrong about X, is there a chance that I'm wrong about Y?\" reply btilly 16 hours agorootparentThat point can be reached with a relatively small amount of history. Nobody could possibly learn all of it. reply photochemsyn 15 hours agoprevPedagogically, this is an argument against teaching physics using the historical development model. You end up with post hoc arguments and simplified narratives, and I think it it just makes life harder for undergraduate students. Maybe 'history of science' should be its own subject? Some textbooks (e.g. Molecular Quantum Mechanics, Atkins & Friedman) take a more nuanced view. They present failures of classical calculations of the heat capacity of solids near absolute zero side by side with blackbody radiation: > \"Einstein recognized the similarity between this problem and black-body radiation, for if each atomic oscillator required a certain minimum energy before it would actively oscillate, then at low temperatures some would be inactive and the heat capacity would be smaller than expected.\" Debye improved the theory by allowing atoms to oscillate with different frequencies. So looking back, one can say matter appears to be quantized, and this shows up at low temperatures, and radiation appears to be quantized, and this shows up at high frequencies - which is a nice symmetric argument, visible in hindsight, that probably helps students grasp the concept of the quantized harmonic oscillator (and why they need to learn about it). One major development was Bose deriving Planck's radiation law using quantum statisical arguments (and no classical physics), with further development by Einstein c. 1924 - but this might be a difficult place to start from, teaching-wise. https://en.wikipedia.org/wiki/Bose%E2%80%93Einstein_statisti... reply lowbloodsugar 15 hours agoprevNever heard of this, despite a physics degree. Is this what happens after social media is invented and all sorts of bullshit is spread as fact? reply wiml 14 hours agoparentNo, I was taught this at least twice before social media became a thing. reply csours 17 hours agoprevIn which a more satisfying story \"beats\" the messiness of true history. reply demondemidi 15 hours agoprevFunny I spent Sunday afternoon watching youtubers talk about this and they all pretty much said that the catastrophe predated Plank's corrections (or caused them). Is this wrong, or is it just pedantic? Most importantly, is the wikipedia page correct: https://en.wikipedia.org/wiki/Ultraviolet_catastrophe reply kazinator 16 hours agoprev> many of the stories that have become central to the physics lore are mere pseudo-histories far detached from the real events But, like, you know how Newton discovered gravity when an apple fell on his head? Totally true, pinky swear! reply tremarley 18 hours agoprev [–] Quantum physics: where the only certainty is that even scientists are uncertain, but don't worry, nobody understands it, not even the scientists themselves! reply astrange 5 hours agoparentQuantum physics (QFT) is just about the most proven thing there is. Physics has the opposite problem - they know it's wrong but they can't find a way to disprove it. It's too good. reply zamadatix 16 hours agoparentprev [–] This is about misunderstanding purely of history, the actual derived physics are not mistaken in either version of the tale. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This paper debunks a popular myth in quantum physics about Max Planck's motivation for introducing quantum physics.",
      "The authors argue that the commonly told story of the ultraviolet catastrophe is incorrect and that Planck was actually focused on deriving the law for blackbody radiation.",
      "Planck used statistical mechanics to calculate the entropy of atomic oscillators, highlighting the need for presenting the true historical development of quantum physics."
    ],
    "commentSummary": [
      "The discussion covers various topics in quantum physics, including the Ultraviolet Catastrophe and Max Planck's discovery of energy quantization.",
      "Participants debate the accuracy of information in textbooks and YouTube videos, as well as the challenges of teaching differential equations and understanding historical scientific debates.",
      "The conversation highlights the need for a nuanced approach to teaching science and emphasizes the value of studying the history of science as a distinct subject."
    ],
    "points": 198,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1707750662
  },
  {
    "id": 39349992,
    "title": "Neural Networks Unveil Beautiful Fractals in Training Process",
    "originLink": "https://sohl-dickstein.github.io/2024/02/12/fractal.html",
    "originBody": "Neural network training makes beautiful fractals 2024-02-12 • Jascha Sohl-Dickstein My five year old daughter came home from kindergarten a few months ago, and told my partner and I that math was stupid (!). We have since been working (so far successfully) to make her more excited about all things math, and more proud of her math accomplishments. One success we've had is that she is now very interested in fractals in general, and in particular enjoys watching deep zoom videos into Mandelbrot and Mandelbulb fractal sets, and eating romanesco broccoli. My daughter's interest has made me think a lot about fractals, and about the ways in which fractals relate to a passion of mine, which is artificial neural networks. I've realized that there are similarities between the way in which many fractals are generated, and the way in which we train neural networks. Both involve repeatedly applying a function to its own output. In both cases, that function has hyperparameters that control its behavior. In both cases the repeated function application can produce outputs that either diverge to infinity or remain happily bounded depending on those hyperparameters. Fractals are often defined by the boundary between hyperparameters where function iteration diverges or remains bounded. Motivated by these similarities, I looked for fractal structure in the hyperparameter lanscapes of neural network training. And I found it! The boundary between hyperparameters for which neural network training succeeds or fails has (gorgeous, organic) fractal structure. Details, and beautiful videos, below. For a more technical presentation, see the short paper The boundary of neural network trainability is fractal. Neural network training and hyperparameters In order to train an artificial neural network, we iteratively update its parameters to make it perform better. We often do this by performing gradient descent steps on a loss function. The loss function is a measure of the neural network's performance. By descending the loss by gradient descent, we find values of the parameters for which the neural network performs well. Training depends on hyperparameters, which specify details about how parameter update steps should be performed and how the network should be initialized. For instance, one common hyperparameter is the learning rate, which sets the magnitude of the update we make to the model’s parameters at every training step. If the learning rate is too large, then the parameter update steps are too large. This causes the parameters to diverge (grow towards infinity) during training, and as a result causes the training loss to become very bad. If the learning rate is too small, the training steps are too short, and it takes a very large number of training steps to train the neural network. Requiring a very large number of training steps makes training slow and expensive. In practice, we often want to make the learning rate as large as possible, without making it so large that the parameters diverge. Visualizing the hyperparameter landscape We can visualize how adjusting hyperparameters (like the learning rate) affects how quickly a neural network either trains or diverges. In the following image, each pixel corresponds to training the same neural network from the same initialization on the same data — but with different hyperparameters. Blue-green colors mean that training converged for those hyperparameters, and the network successfully trained. Red-yellow colors mean that training diverged for those hyperparameters. The paler the color the faster the convergence or divergence The neural network I used in this experiment is small and simple; it consists of an input layer, a \\(\\operatorname{tanh}\\) nonlinearity, and an output layer1. In the image, the x-coordinate changes the learning rate for the input layer’s parameters, and the y-coordinate changes the learning rate for the output layer’s parameters. Figure 1: Hyperparameter landscape: A visualization of how neural network training success depends on learning rate hyperparameters. Each pixel corresponds to a training run with the specified input and output layer learning rates. Training runs shown in blue-green converged, while training runs shown in red-yellow diverged.2 Hyperparameters leading to the best performance (lightest blue-green) are typically very close to hyperparameters for which training diverges, so the boundary region is of particular interest. The best performing hyperparameters — those that are shown with the palest blue-green shade, and for which the neural network trains the most quickly — are near the boundary between hyperparameters for which training converges and for which it diverges. This is a general property. The best hyperparameters for neural network training are usually very near the edge of stability. For instance, as suggested above, the best learning rate in a grid search is typically the largest learning rate for which training converges rather than diverges. The boundary of neural network trainability is fractal Because it is where we find the best hyperparameters, the boundary between hyperparameters that lead to converging or diverging training is of particular interest to us. Let’s take a closer look at it. Play the following video (I recommend playing it full screen, and increasing the playback resolution): As we zoom into the boundary between hyperparameter configurations where training succeeds (blue) and fails (red), we find intricate structure at every scale. The boundary of neural network trainability is fractal! 🤯 (If you watched the video to the end, you saw it turn blocky in the last frames. During network training I used the \\(\\operatorname{float64}\\) numeric type, which stores numbers with around 16 decimal digits of precision. The blockiness is what happens when we zoom in so far that we need more than 16 digits of precision to tell pixels apart.) This behavior is general. We see fractals if we change the data, change the architecture, or change the hyperparameters we look at. The fractals look qualitatively different for different choices though. Network and training design decisions also have artistic consequences! Figure 2: Neural network training produces fractals in all of the experimental configurations I tried. The figure is taken from the companion paper, and shows a region of the fractal resulting from each experimental condition. Experimental conditions changed the nonlinearity in the network, changed the dataset size, changed between minibatch and full batch training, and changed the hyperparameters we look at. Here are the remaining fractal zoom videos for the diverse configurations summarized in Figure 2. You can find code for these experiments in this colab3. Changing the activation function to the identity function: i.e. the network is a deep linear network, with no nonlinearity. Change the activation function to \\(\\operatorname{ReLU}\\): This is a neat fractal, since the piecewise linear structure of the \\(\\operatorname{ReLU}\\) is visually apparent in the straight lines dividing regions of the fractal. Train with a dataset size of 1: i.e. only train on a single datapoint. Other experiments have a number of training datapoints which is the same as the free parameter count of the model. Train with a minibatch size of 16: Other experiments use full batch training. Look at different hyperparameters: I add a hyperparameter which sets the mean value of the neural network weights at initialization. I visualize training success in terms of this weight initialization hyperparameter (x-axis) and a single learning rate hyperparameter (y-axis). Other experiments visualize training success in terms of learning rate hyperparameters for each layer. This fractal is extra pretty — I like how it goes through cycles where what seems like noise is resolved to be structure at a higher resolution. This isn’t so strange after all Now that I’ve shown you something surprising and beautiful, let me tell you why we should have expected it all along. In an academic paper I would put this section first, and tell the story as if I knew fractals would be there — but of course I didn't know what I would find until I ran the experiment! Fractals result from repeated iteration of a function One common way to make a fractal is to iterate a function repeatedly, and identify boundaries where the behavior of the iterated function changes. We can refer to these boundaries as bifurcation boundaries of the iterated function; the dynamics bifurcate at this boundary, in that function iteration leads to dramatically different sequences on either side of the boundary. For instance, to generate the Mandelbrot set, we iterate the function \\(f( z; c ) = z^2 + c\\) over and over again. The Mandelbrot fractal is the bifurcation boundary between the values of \\(c\\) in the complex plane for which this iterated function diverges, and for which it remains bounded. The parameter \\(c\\) is a (hyper)parameter of the function \\(f( z; c )\\), similarly to how learning rates are hyperparameters for neural network training. Figure 3: The Mandelbrot fractal is generated by iterating a simple function, similar to the way in which update steps are iterated when training a neural network. Other examples of fractals which are formed by bifurcation boundaries include magnet fractals, Lyapunov fractals, the quadratic Julia set, and the Burning Ship fractal. Fractals can result from optimization One particularly relevant class of bifurcation fractals are Newton fractals. These are generated by iterating Newton's method to find the roots of a polynomial. Newton's method is an optimization algorithm. Newton fractals are thus a proof of principle that fractals can result from iterating steps of an optimization algorithm. Figure 4: Newton fractals, like the one shown, are formed by iterating Newton's method to find roots of a polynomial, and color coding initial conditions by the specific root the iterates converge to. Newton fractals are a proof of principle that optimization can generate a fractal, since Newton's method is an optimization procedure. They motivate the idea of fractal behavior resulting from training (i.e. optimizing) a neural network. Artificial neural networks are trained by repeatedly iterating a function When we train a neural network by iterating steps of gradient descent, we are iterating a fixed function, the same as for Mandelbrot, Newton, and other fractals. Like for Newton fractals, this fixed function corresponds to an optimization algorithm. Specifically, when we train a neural network using steepest gradient descent with a constant learning rate, we iterate the fixed function \\(f(\\theta; \\eta ) = \\theta( \\eta ) - \\eta\\, g( \\theta )\\). Here \\(\\eta\\) is the learning rate hyperparameter, \\(\\theta\\) are the parameters of the neural network, and \\(g( \\theta )\\) is the gradient of the loss function. There are many differences between neural network training and traditional fractal generation. The fractals I just discussed all involve iterating a function of a single (complex valued) number. The equation definining the iterated function is short and simple, and takes less than a line of text to write down. On the other hand, neural network training iterates a function for all the parameters in the neural network. Some neural networks have trillions of parameters, which means the input and output of the iterated function is described with trillions of numbers, one for each parameter. The equation for a neural network training update is similarly far more complex than the function which is iterated for traditional fractals; it would require many lines, or possibly many pages, to write down the parameter update equations for a large neural network. Nonetheless, training a neural network can be seen as a scaled up version of the type of iterative process that generates traditional fractals. We should not be surprised that it produces fractals in a similar way to simpler iterative processes.4 Closing thoughts Meta-learning is hard Meta-learning is a research area that I believe will transform AI over the next several years. In meta-learning we learn aspects of AI pipelines which are traditionally hand designed. For instance, we might meta-train functions to initialize, optimize, or regularize neural networks. If deep learning has taught us one thing, it's that with enough compute and data, trained neural networks can outperform and replace hand-designed heuristics; in meta-learning, we apply the same lesson to replace the hand-designed heuristics we use to train the neural networks themselves. Meta-learning is the reason I became interested in hyperparameter landscapes. The fractal hyperparameter landscapes we saw above help us understand some of the challenges we face in meta-learning. The process of meta-training usually involves optimizing hyperparameters (or meta-parameters) by gradient descent. The loss function we perform meta-gradient-descent on is called the meta-loss. The fractal landscapes we have been visualizing are also meta-loss landscapes; we are visually how well training succeeds (or fails) as we change hyperparameters. In practice, we often find the meta-loss atrocious to work with. It is often chaotic in the hyperparameters, which makes it very difficult to descend5. Our results suggest a more nuanced and also more general perspective; meta-loss landscapes are chaotic because they are fractal. At every length scale, small changes in the hyperparameters can lead to large changes in training dynamics. Figure 5: Chaotic meta-loss landscapes make meta-learning challenging. The image shows an example meta-loss landscape for a learned optimizer, with darker colors corresponding to better meta-loss. The two axes correspond to two of the meta-parameters of the learned optimizer (similar to the visualization in Figure 1, where axes correspond to two hyperparameters). See this paper for details. This meta-loss landscape is difficult to meta-train on, since steepest gradient descent will become stuck in valleys or local minima, and because the gradients of the rapidly changing meta-loss function are exceptionally high variance. Fractals are beautiful and relaxing Recent AI projects I have collaborated on have felt freighted with historical significance. We are building tools that will change people's lives, and maybe bend the arc of history, for both better and worse. This is incredibly exciting! But it is often also stressful. This project on the other hand ... was just fun. I started the project because my daughter thought fractals were mesmerizing, and I think the final results are gorgeous. I hope you enjoy it in the same spirit! Acknowledgements Thank you to Maika Mars Miyakawa Sohl-Dickstein for inspiring the original idea, and for detailed feedback on the generated fractals. Thank you to Asako Miyakawa for providing feedback on a draft of this post. 1 In more detail, the baseline neural network architecture, design, and training configuration is as follows: Two layer fully connected neural network, with 16 units in the input and hidden layers, and with no bias parameters. The only parameters are the input layer weight matrix, and the output layer weight matrix. \\(\\operatorname{tanh}\\) nonlinearity in the single hidden layer Mean square error loss Fixed random training dataset, with number of datapoints the same as the number of free parameters in the network Full batch steepest descent training, with a constant learning rate A different learning rate for each layer. That is rather than training the input and output layer weight matrices with the same learning rate, each weight matrix has its own learning rate hyperparameter. All experiments change one aspect of this configuration, except for the baseline experiment, which follows this configuration without change. If you want even more detail, see the arXiv note or the colab notebook I used for all experiments. 2 The discerning reader may have noticed that training diverges when the output learning rate is made large, but that if the input learning rate is made large, performance worsens but nothing diverges. This is due to the \\(\\operatorname{tanh}\\) nonlinearity saturating. When the input learning rate is large, the input weights become large, the hidden layer pre-activations become large, and the \\(\\operatorname{tanh}\\) units saturate (their outpus grow very close to either −1 or 1). The output layer can still train on the (essentially frozen) \\([-1, 1]\\) activations from the first layer, and so some learning can still occur. 3 Like the fractals, the research code in the colab has vibes of layered organic complexity ... user beware! 4 Many fractals are generated by iterating simple functions, such as low order polynomials, or ratios of low order polynomials. Iterating these simple functions often generates simple symmetries, that are visually obvious when looking at the resulting fractals. The fractals resulting from neural networks are more organic, with fewer visually obvious symmetries. This is likely due to the higher complexity of the iterated functions themselves, as well as the many random parameters in the function definitions, stemming from the random initialization of the neural network and random training data. 5 My collaborators and I have done more research into how to optimize a chaotic meta-loss. Especially see the papers: Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies, and Variance-Reduced Gradient Estimation via Noise-Reuse in Online Evolution Strategies. BibTeX entry for post: @misc{sohldickstein20240212, author = {Sohl-Dickstein, Jascha}, title = {{ Neural network training makes beautiful fractals }}, howpublished = \"\\url{https://sohl-dickstein.github.io/2024/02/12/fractal.html}\", date = {2024-02-12} }",
    "commentLink": "https://news.ycombinator.com/item?id=39349992",
    "commentBody": "Neural network training makes beautiful fractals (sohl-dickstein.github.io)193 points by telotortium 9 hours agohidepastfavorite38 comments alexmolas 3 hours agoThe results of the experiment seem counterintuitive just because the used learning rates are huge (up to 10 or even 100). These are not the lr you would use in a normal setting. If you look at the region of small lr it seems all of them converge. So I would say the experiment is interesting, but not representative of real world deep learning. In the experiment, you have a function of 272 variables with a lot of minima and maxima, and at each gradient descent step you take huge steps (due to big lr). So my intuition is that convergence is more a matter of luck rather than hyperparameters. reply dmarchand90 2 hours agoparentI think the article is very honest about this just being a fun exploration. They even show how you can get similar patterns with newton's algorithm which is a more \"classical\" take reply alexmolas 2 hours agorootparentYes, the author is clear in this regard. But I've seen people interpreting this paper as \"training deep networks is chaotic\", and I don't think that's the case. I interpret it more as \"if you're not careful with your learning rate your training will be chaotic\" reply repelsteeltje 46 minutes agorootparentYes. I immediately had visions of a misconfigured PID controller or similar chaotic emergence encountered in control theory. I was surprised and delighted though, that this type of chaos has so much fractal beauty. reply sdenton4 41 minutes agoparentprevThere was a nice paper about five years ago that also found that the best hyperparams were in the bounty of divergence, even for 'real' imagenet models. reply locuscoeruleus 34 minutes agorootparentWhat paper was that? reply PheonixPharts 5 hours agoprevI find this result absolutely fascinating, and is exactly the type of research into neural networks we should be expanding. We've rapidly engineered our way to some very impressive models this past decade, and yet gap in our real understanding of what's going on has widened. There's a large list of very basic questions about LLMs that we haven't answered (or in some cases, really asked). This is not a failing of people researching in this area, it's only that things move so quickly there's not enough time to ponder things like this. At the same time, the result, unless I'm really misunderstanding, gives me the impression that anything other than grid search hyper parameter optimization is a fools errand. This would give credence to the notion that hyper parameter tuning really is akin to just re-rolling a character sheet until you get one that is over powered. reply sigmoid10 1 hour agoparent>exactly the type of research into neural networks we should be expanding. While it certainly makes for some nice visualizations, the technical insight of this is pretty limited. First of all, this fractal structure emerges at learning rates that are far higher than those used in training actual neural networks nowadays. It's interesting that the training still converges for some combinations and that the (expected) hit-and-miss procedure yields a fractal structure. But if you look closely at the images, you'll see the best hyperparameters are, while close, not at the border. So even if you want to follow the meta-learning approach outlined in the post, your gradient descent has already screwed up before if it ever ends up in this fractal boundary region. reply krallistic 2 hours agoparentprev> gives me the impression that anything other than grid search hyper parameter optimization is a fools errand. This would give credence to the notion that hyper parameter tuning really is akin to just re-rolling a character sheet until you get one that is over powered. The visualizations only show that at the Border there are a lot of fractals, not in every part of the space. (Although the highest performance is often achieved close to the border.). I would not state hparam search as bad as that.. reply dylan604 3 hours agoparentprevwhat was the name of the Google app (Dreaming or some such) that would iterate frames similar to this that would find lizard/snakes/dogs/eyes and got super trippy the longer it ran? The demos would start with RGB noise, and within a few iterations, it was a full on psychedelic trip. It was the best visual of AI \"hallucinating\" I've seen yet reply 0xDEADFED5 3 hours agorootparenthttps://en.wikipedia.org/wiki/DeepDream reply dylan604 3 hours agorootparentwinner winner chicken dinner. thanks! always thought we now know what the android's dreams were like reply telotortium 9 hours agoprevTwitter: https://twitter.com/jaschasd/status/1756930242965606582 ArXiv: https://arxiv.org/abs/2402.06184 Abstract: \"Some fractals -- for instance those associated with the Mandelbrot and quadratic Julia sets -- are computed by iterating a function, and identifying the boundary between hyperparameters for which the resulting series diverges or remains bounded. Neural network training similarly involves iterating an update function (e.g. repeated steps of gradient descent), can result in convergent or divergent behavior, and can be extremely sensitive to small changes in hyperparameters. Motivated by these similarities, we experimentally examine the boundary between neural network hyperparameters that lead to stable and divergent training. We find that this boundary is fractal over more than ten decades of scale in all tested configurations.\" Contains several cool animations zooming in to show the fractal boundary between convergent and divergent training, just like the classic Mandelbrot and Julia set animations. reply Imnimo 4 hours agoprevIf you are a fan of the fractals but feel intimidated by neural networks, the networks used here are actually pretty simple and not so difficult to understand if you are familiar with matrix multiplication. To generate a dataset, he samples random vectors (say of size 8) as inputs, and for each vector a target output, which is a single number. The network consists of an 8x8 matrix and an 8x1 matrix, also randomly initialized. To generate an output from an input vector, you just multiply by your 8x8 matrix (getting a new size 8 vector), apply the tanh function to each element (look up a plot of tanh - it just squeezes its inputs to be between -1 and 1), and then multiply by the 8x1 matrix, getting a single value as an output. The elements of the two matrices are the 'weights' of the neural network, and they are updated to push the output we got towards the target. When we update our weights, we have to decide on a step size - do we make just a little tiny nudge in the right direction, or take a giant step? The plots are showing what happens if we choose different step sizes for the two matrices (\"input layer learning rate\" is how big of a step we take for the 8x8 matrix, and \"output layer learning rate\" for the 8x1 matrix). If your steps are too big, you run into a problem. Imagine trying to find the bottom of a parabola by taking steps in the direction of downward slope - if you take a giant step, you'll pass right over the bottom and land on the opposite slope, maybe even higher than you started! This is the red region of the plots. If you take really really tiny steps, you'll be safe, but it'll take you a long time to reach the bottom. This is the dark blue section. Another way you can take a long time is to take big steps that jump from one slope to the other, but just barely small enough to end up a little lower each time (this is why there's a dark blue stripe near the boundary). The light green region is where you take goldilocks steps - big enough to find the bottom quickly, but small enough to not jump over it. reply nighthawk454 4 hours agoparentGreat description! Now we just need one on fractals for all us NN people haha reply fancyfredbot 37 minutes agoprevThis is really fun, and beautiful. Also, despite what people are saying about the learning rates being unrealistic, the findings also really fit well with my own experience in using optimisation algorithms in the real world. If our code ever had a significant results difference between processor architectures (e.g. a machine taking an avx code path vs an sse one) you could be sure that every time the difference began during execution of an optimisation algorithm. The chaotic sensitivity to initial conditions really showed up there, just as it did in the author's newton solver plot. Although I have knew at some level that this behaviour was chaotic it never would have occurred to me to ask if it made a pretty fractal! reply KuzMenachem 51 minutes agoprevReminds me of an excellent 3blue1brown video about Newton’s method [1]. You can see similar fractal patterns emerge there too. [1] https://www.youtube.com/watch?v=-RdOwhmqP5s reply magicalhippo 7 hours agoprevHere's the associated blog post, which includes the videos: https://sohl-dickstein.github.io/2024/02/12/fractal.html Not a ML'er so not sure what to make of it, beyond a fascinating connection. reply int_19h 2 hours agoprevI hope one day we'll have generative AI capable of producing stuff like this on demand: https://www.youtube.com/watch?v=8cgp2WNNKmQ reply passion__desire 1 hour agoparentNot just that AI can overlay artistic styles like below on top of such fractal structures. http://sub.blue/inkwell reply int_19h 1 hour agorootparentGenerating a single still image is not an issue, obviously. It's more about picking \"good\" fractal parameters, a \"good\" spot to zoom in on said fractal, and \"good\" colors to dress it all up. Even more so if you are trying to time it all to specific music matching the visuals, as some of the fractal art videos do. reply why_only_15 5 hours agoprevI appreciate that his acknowledgements here were to his daughter (\"for detailed feedback on the generated fractals\") and wife (\"for providing feedback on a draft of this post\") reply albertgt 3 hours agoprevDave Bowman> omg it’s full of fractals HAL> why yes Dave what did you think I was made of reply karxxm 3 hours agoprevWhat’s that color-map called? reply nossid 1 hour agoparentIn the notebook you can see it set to Spectral. https://github.com/Sohl-Dickstein/fractal/blob/main/the_boun... reply kalu 6 hours agoprevSo this author trained a neural network billions of times using different hyper parameters ? How much dod that cost ? reply TheCoreh 5 hours agoparentThe networks trained were really small, with only one hidden layer, and a width of 16. reply mkl 5 hours agoparentprevVery small networks are cheap and easy (even 20 years ago). reply fallingfrog 7 hours agoprevThis is kind of random but- I wonder, if you had a sufficiently complex lens, or series of lenses, perhaps with specific areas darkened, could you make a lens that shone light through if presented with, say, a cat, but not with anything else? Bending light and darkening it selectively could probably reproduce a layer of a neural net. That would be cool. I suppose, you would need some substance that responded to light in a nonlinear way. reply gwern 6 hours agoparentYou can do a lot. 'Digital sundials' come to mind: https://en.wikipedia.org/wiki/Digital_sundial https://gwern.net/doc/math/1991-stewart.pdf But yes, you are restricted to linear things and you can't make a good photonic cat detector out of that easily. So all the photonic neural networks you may have heard of like https://arxiv.org/abs/2106.11747 wind up sticking some mechanical or electrical nonlinearity somewhere. reply theWreckluse 6 hours agoparentprevA research out of ETH Zurich, based on which the company Rayform https://rayform.ch/ was founded does exactly this! I was so excited when I saw the paper for the first time a couple of years ago. reply mhh__ 6 hours agoparentprevI've seen a student project that did just that. I don't have a link for you unfortunately. reply uoaei 7 hours agoparentprevYou can simulate materials, apply the wave equation, and get \"layers\" that compute outputs from given inputs, each modeled as points in space. It may be possible to manufacture such layers with metamaterials or something like that. https://www.science.org/doi/10.1126/sciadv.aay6946 reply 7e 5 hours agoprev [–] Today I learned that if something is detailed, it is now fractal. reply magicalhippo 1 hour agoparentIt would be interesting to compute the fractal dimension[1] to see if it really is fractal[2] or just looks like it. I recall similar tests being done on paintings by Pollock and of other artists trying to copy his style to determine authenticity[3]. [1]: https://en.wikipedia.org/wiki/Fractal_dimension [2]: https://mathworld.wolfram.com/Fractal.html [3]: https://cpb-us-e1.wpmucdn.com/blogs.uoregon.edu/dist/e/12535... reply bluetintedfort 6 minutes agorootparentThe sister paper[1] contains the fractal dimensions of some of the images using a boxcount paper. [1]: https://arxiv.org/pdf/2402.06184.pdf reply lifthrasiir 5 hours agoparentprevFractal is not necessarily self-similar; it just has to show enough detailed structures when zoomed in ad infinitum. While no single defiition for fractals exists, at least that's one of the common denominators (because otherwise many \"fractals\" in the nature can't be called so). reply paulrudy 5 hours agoparentprev [–] I'm only a fractal enthusiast, but my impression is that the key distinction that makes these fractals, or at least fractal-like, is not their detail per se, but that there is complexity at every scale. From the article: > we find intricate structure at every scale > At every length scale, small changes in the hyperparameters can lead to large changes in training dynamics reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author discovers a connection between fractals and neural network training, revealing that the boundary between successful and unsuccessful training exhibits a fractal structure.",
      "Adjusting hyperparameters, like the learning rate, has an impact on the training process, with the best-performing hyperparameters typically found near the convergence-divergence boundary.",
      "Fractal patterns emerge when zooming in on specific training configurations, due to the repeated iteration of functions and the occurrence of bifurcation boundaries. Neural network-generated fractals differ from those produced by low order polynomials in that they appear more organic and lack obvious symmetries."
    ],
    "commentSummary": [
      "Neural network training can produce visually appealing fractals, but these results do not accurately reflect real-world deep learning due to the use of extremely high learning rates.",
      "A study examines the boundary between stable and divergent training in neural networks when generating fractals, but its practical implications are limited.",
      "The article emphasizes the need for careful selection of learning rates and questions the effectiveness of meta-learning approaches. Additionally, it highlights the significance of choosing appropriate step sizes for weight updates during the process of generating fractals using neural networks.",
      "The conversation also delves into topics such as chaotic behavior, fractal patterns in mathematical and neural network models, photonic neural networks, and the potential of non-linear elements.",
      "Overall, the article highlights the enjoyment of exploring neural network training and stresses the importance of optimizing hyperparameters."
    ],
    "points": 193,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1707769547
  },
  {
    "id": 39349389,
    "title": "FCC requires telcos to disclose personal info breaches",
    "originLink": "https://www.theregister.com/2024/02/12/fcc_gets_tough_on_telcos/",
    "originBody": "Security 6 FCC gets tough: Telcos must now tell you when your personal info is stolen 6 Yep, cell carriers didn't have to do this before Brandon Vigliarolo Mon 12 Feb 2024 // 18:45 UTC The FCC's updated reporting requirements mean telcos in America will have just seven days to officially disclose that a criminal has broken into their systems. After releasing a proposed rule in early January and giving the industry 30 days to respond, the FCC's final rule was published today. It solidifies what the agency proposed a little more than a month ago, and what was teased in early 2022 when FCC chairwoman Jessica Rosenworcel drafted initial changes to the commission's 16-year old security \"breach\" reporting duties. Along with requiring that attacks are reported to the FCC within seven days of a telco discovering them, the same deadline now exists to report any data leaks to the FBI and US Secret Service as well. As the FCC planned, the new rule also eliminates the mandatory seven-day waiting period for reporting break-ins to consumers. The FCC now \"requires carriers to notify customers of breaches of covered data without unreasonable delay … and in no case more than 30 days following reasonable determination of a breach.\" \"Reasonable determination\" of a data blurt is further defined as \"when the carrier has information indicating that it is more likely than not that there was a breach\" and \"does not mean reaching a conclusion regarding every fact surrounding a data security incident that may constitute a breach.\" In other words, if customers are affected then they had better be notified post-haste. The FCC has additionally extended the scope of data exposure types that telecom customers must be notified of. Prior to the passage of the new rule customers only had to be told if Customer proprietary network information (CPNI) was exposed to the world. CPNI, for those unfamiliar, is all the data a cellular carrier retains about phone calls and service agreements - i.e., the data that appears on a bill. Personal identifiable information (PII) wasn't included in previous reporting requirements, meaning carriers whose customer records were exposed, didn't have to tell customers if CPNI wasn't accessed. \"Without an FCC rule requiring breach notifications for the above categories of PII, there would be no requirement in Federal law that telecommunications carriers report non-CPNI breaches to their customers,\" the FCC said of the new rule. Starting now, names, government ID numbers, data used for authentication purposes, email addresses/passwords and biometric data is all included in the FCC's reporting requirements. Dissociated data, if linkable to an individual using other data criminals accessed during a break-in, has to be reported as well. The new rules add an exception for customer notifications as well. If a carrier can \"determine that no harm to customers is reasonably likely to occur,\" then it doesn't have to inform subscribers of the incident. Along with increased reporting rules for the content of data leaks, the new rule also expands the FCC's definition of \"breach\" to include \"inadvertent access, use or disclosure of customer information.\" Inadvertent, much like the exposure of 63k employee records Verizon reported last week. Luckily for Verizon it won't have to worry about falling foul of the new rules, which don't go into effect until March 13. Telecom relay service providers, which provide assistance for hearing-impaired phone users, will be covered under the new rule as well. Here a breach, there a breach, everywhere a breach report The FCC's updated directive is the latest in a string of federal agency breach reporting requirements, with rules passed by the FTC and SEC set to go into effect later this year, and federal contractors getting their own set of newly-proposed IT security breach reporting rules too. As has been the case with those other rules, the FCC's requirements, when formally proposed last month, ran up against opposition. Future of America's Cyber Safety Review Board hangs in balance amid calls for rethink Blackbaud settles with FTC after that IT breach exposed millions of people's info Mon Dieu! Nearly half the French population have data nabbed in massive breach 40% of IT security pros say they've been told not to report a data leak Per the FCC, the Cellular Telecommunications Industry Association raised an objection on several grounds, including that the FCC rule would create a system of dual jurisdiction between the FCC and FTC once the latter's rule goes into effect. As has been the case with objections raised to the wide and varying data leak reporting requirements now enacted by the US federal government, the FCC said it finds industry objections \"unpersuasive.\" Congress has even raised objections to some of the new reporting rules, with bills introduced in the House and Senate to overturn the SEC's four-day reporting deadline for data break-ins that could have a \"material\" effect on a company's finances and, by extension, its investors. The feds were generally dismissive of the complaints, with the Biden administration saying it would veto any attempts to undo the SEC's reporting rules. Industry figures, and congressional representatives, have pointed to the Cybersecurity and Infrastructure Security Agency's forthcoming rules for security breach requirements as a potential inter-agency standard. It's not clear whether CISA's rules, a draft of which is expected to be published next month, will harmonize standards or otherwise eliminate the need for companies covered under multiple rules to make multiple reports. ® Whitepaper: Top 5 Tips For Navigating Your SASE Journey Share More about Cybersecurity Data Breach FCC More like these × More about Cybersecurity Data Breach FCC Telecommunications Narrower topics 5G AT&T British Telecom Comcast EE Emergency Services Network Ericsson Mobile Network National Broadband Network NTT Orange RSA Conference Telecommunications Act of 1996 TETRA Verizon Vodafone Voice over IP Broader topics Sector Security More about Share 6 COMMENTS More about Cybersecurity Data Breach FCC More like these × More about Cybersecurity Data Breach FCC Telecommunications Narrower topics 5G AT&T British Telecom Comcast EE Emergency Services Network Ericsson Mobile Network National Broadband Network NTT Orange RSA Conference Telecommunications Act of 1996 TETRA Verizon Vodafone Voice over IP Broader topics Sector Security TIP US OFF Send us news",
    "commentLink": "https://news.ycombinator.com/item?id=39349389",
    "commentBody": "FCC: Telcos must now tell you when your personal info is stolen (theregister.com)193 points by rntn 14 hours agohidepastfavorite29 comments happytiger 13 hours agoYea, that’ll teach them. Now they have to tell you when they utterly fail to protect you. Just as hard hitting as making robovoices illegal rather than requiring providers to end spam calls on their networks effectively. https://www.fcc.gov/document/fcc-makes-ai-generated-voices-r.... Bear in mind this is the TOP consumer complaint. And they have done basically a minor law change to clarify that the law still applies, and that it’s definitely still illegal. Uh, but they haven’t addressed the problem or fixed it in any substantive way. Such a tough FCC. I will say that Jessica Rosenworcel is an angel compared to Ajit “Screw Consumers ITB As Much As Possible” Pai. I miss that guy like a hemmeroid. I’m sure he’s enjoying his job as a partner at the private-equity firm Searchlight Capital where he is now seeking to “close the gap” on the broadband failures he was largely responsible for expanding for several years. https://www.wsj.com/articles/searchlight-capital-bets-on-uni... It’s amazing. The FCC seems to be either very bad at their job or completely 0wn3d by the revolving door of private industry. reply drtz 13 hours agoparent> Such a tough FCC. I had the same thought: this is \"tough?\" No fines for failing to protect your data? No additional requirements for data security? They just have to tell you when the screwed up. sigh reply happytiger 13 hours agorootparentYea. This is failure masquerading as improvement as far as I can honestly tell. The idea that someone thought it was a good idea to put out a press release or whatever is a little baffling. It should read, “FCC once again fails to substantively improve the lives of consumers OR address data breaches and the loss of consumer data by countless companies.” Its baffling. But it’s still better than the TSA. ;) reply RajT88 12 hours agorootparentprevOnce upon a time the FCC had a reputation as the \"Benevolent Dictator\" (at least when I once worked for an ISP). No longer. reply KRAKRISMOTT 11 hours agoparentprevThey need to carry identity theft insurance for sim swapping and other similar attacks, or if a rogue employee misuses the data (very common considering that they probably have tens of thousands of front line staff with access to customer data). reply tristor 13 hours agoprevI like how this is considered \"tough\". What would be tough is instituting actual data security and privacy regulations that telcos and service providers have to follow at risk of being fined out of business to be replaced by an organization that can. reply aeternum 13 hours agoprevOne major problem is that PII/Personal info is uselessly broad. Legislation like this would be much more useful if it had clear rules or fines for various levels of PII. For example, getting your social security number stolen is significantly worse than a stolen e-mail address or phone number. All the notifications about e-mail being \"stolen\" are just noise that few care about. reply ummonk 12 hours agoparentWhat’s actually insane is treating an unchanging non random 9 digit retirement benefits identifier as some kind of secret, knowledge of which is assumed to be proof of identity. reply washadjeffmad 8 hours agoprevThis would have helped when someone defrauded Verizon's wired line division, converted the account to wireless, and then pinned it on me. Instead, I can't seem to convince at least one of the three arbiters of credit that the other two are correct, and I have never lived on \"Crooks Ave\". I've filed everything I was told to and fended off creditors and debt purchasers alike, and I still can't get it cleared. Just who do I need to sue to get this sort of meaningless shit cleared in the US? reply johnny99k 13 hours agoprevI think I've gotten at least 5 different notices in the mail from different companies (healthcare, kids school) that told me my info was involved in a breach. I figured some new law must have gotten passed because most companies would never do this willingly. reply WaitWaitWha 12 hours agoparentYou know what is even more frustrating? When I get 5 different notices in the mail from different companies that told me my info was involved in a breach, *and I never did direct business with any of them or have been notified that my data been given to them, ever.* reply bdcravens 13 hours agoprevI suspect it being stolen is less common than it being sold. reply m463 12 hours agoparentI get hardcore phishing emails sent to the email address I have only used with AT&T DSL. full email address, full first, middle, last name. reply 1970-01-01 12 hours agoprevI'm sorry, but a set of circumstances have led to your data being lost. We're making sure that set of circumstances will never occur exactly the same way it did. Sincerely, James Johnson Jr. CEO BigNetCorp reply dylan604 13 hours agoprevSo immediately after a new user signs up, they should just send out an email saying their data has been taken. save everyone time. reply vmfunction 9 hours agoprevHow about, a huge fine! And use the fine to found EFF or open source security experts to audit them (All the big Telcos!) and harden their securities. At this piont Telcos are should be treated as public utility companies! reply Repulsion9513 13 hours agoprevTheis much more accurate: FCC publishes final version of new breach report rules reply SlightlyLeftPad 13 hours agoprevBalls of steel the FCC has. Is this the first consumer friendly thing they’ve actually done in a couple decades? reply throwbadubadu 13 hours agoprev... what's up next in this tough cruel world? Banks must tell you when someone stole your money? Companies must tell you when they go bankrupt and gambled your assets? I fear madness ahead. reply nottorp 12 hours agoprevWhy just telcos? reply dredmorbius 11 hours agoparentBecause the remit and legislative mandate of the US Federal Communications Commission is ... communications: As specified in section one of the Communications Act, the Commission’s mission is to “make available, so far as possible, to all the people of the United States, without discrimination on the basis of race, color, religion, national origin, or sex, rapid, efficient, Nation-wide, and world-wide wire and radio communication service with adequate facilities at reasonable charges.” 1 In addition, section one provides that the Commission was created “for the purpose of the national defense” and “for the purpose of promoting safety of life and property through the use of wire and radio communications.” FEDERAL COMMUNICATIONS COMMISSION Fiscal Year 2008 Performance and Accountability Report, p. 4:For general commercial enterprise requirements, you'd want the Federal Trade Commission, whose mandates are antitrust and general consumer protection. reply nottorp 10 hours agorootparentAnd what's the \"Trade Commission\" doing about this? Taking bribes? Sorry, listening to lobbyists ... reply Waterluvian 8 hours agoprevAnd they must say they’re sorry and they must say how important our privacy is to them and they must commit to doing better but they mustn’t make us whole. reply apapapa 11 hours agoprevSo futuristic reply olliej 12 hours agoprevI'll take it as being tough when companies are financially liable for data exposure along the same lines of HIPAA. Maybe something akin to: * $10 per element of data not directly required for legal purposes or for the direct provision of services explicitly requested by customers (e.g. their shipping address) * $2 for element of data not legally mandated. For data stored to meet legal data retention requirements: * If the law requires that information be made available in a fully automated and online manner, then $0.50 per element of data, and $5 per element of data from the government (state vs federal) that mandated the data be stored and accessible * If the law does not require fully automated online access, then if the data is not encrypted such that it requires concurrent action by multiple employees to decrypt, then it's $100/data (e.g. no claiming it's needed for legal reasons but keeping it accessible for profit reasons). Essentially, make it so customer data is not purely a balance sheet asset. Also make it so credit agencies knowingly reporting incorrect information is a crime, and make them liable for all costs incurred (higher interest rates) and financial penalties for extreme cases (refusing loans outright, refusing rental, demanding higher deposits, etc). The fact that the agencies themselves are selling \"monitoring services\" shows that they are aware that their reporting is fraudulent. reply balderdash 11 hours agoparentThere should also be a sliding scale element e.g. fines doubled if for more than 100k customers affected, if over a million the greater of 20% of gross profit or 10x the fine…etc. reply doublerabbit 13 hours agoprevCurse my cynical mind of the delayed \"ohhh, we had no idea we were breached. Sorry about that folks btw your details were stolen lol\" excuse. reply rsynnott 13 hours agoprevI mean, that doesn’t seem _particularly_ tough. reply timmattison 12 hours agoprev [–] Wow, they have to do what other companies have to do. Brutal. /s reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The FCC has introduced new reporting requirements for telcos in the US, giving them a seven-day deadline to report security breaches to the FCC and the FBI/US Secret Service.",
      "Telcos will no longer have to wait seven days to notify consumers of breaches and will now be required to report a wider range of data leaks.",
      "The updated rules, which include \"inadvertent access, use, or disclosure of customer information,\" will take effect on March 13."
    ],
    "commentSummary": [
      "The FCC has introduced new regulations mandating telecommunication companies to notify customers when their personal information has been compromised.",
      "Critics argue that these rules are insufficient in addressing the larger issue of data breaches and fail to hold companies responsible for inadequate customer data protection.",
      "Some speculate that the FCC's actions may be due to incompetence or undue influence from private industry."
    ],
    "points": 193,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1707767058
  },
  {
    "id": 39351195,
    "title": "Philosopher Daniel C. Dennett on the Value of Collaboration and Questioning Beliefs",
    "originLink": "https://behavioralscientist.org/ive-been-thinking-daniel-dennett-what-if-im-wrong/",
    "originBody": "Science What If I’m Wrong? By Daniel C. Dennett October 12, 2023 I used to be a much more conscientious scholar than I am now. I would encounter a journal article or book that was relevant to my interests but forbiddingly technical (or, if the author was a philosopher, just forbiddingly badly written, convoluted, and jargon packed), and I would beat my head against it for hours and hours, running down and checking out all the references—a time-consuming library job in the old days before internet links. I made it something of a point of honor to arrive at a state of confident understanding; I kept at it until I owned that argument. Now I give such candidates for my attention a quick skim, remembering that life is short and if this novelty is worth understanding, somebody I trust will soon explain it to me in terms I can readily digest. These days I almost always outsource the hard work of comprehension when I encounter difficulties, and the policy works wonders—for me. Distributed understanding is a real phenomenon, but you have to get yourself into a community of communicators that can effectively summon the relevant expertise. I don’t know if other philosophers have the same policy; many of them seem to me to spend their whole careers working largely alone and grappling with a few narrow issues, voluntarily giving themselves tunnel vision. Perhaps, I think, they cannot do otherwise, given their training. After all, many scientists are in similar trenches. I once asked a promising young neuroscientist, after I’d spent hours watching him run experiments on monkeys with chronically implanted electrodes, what he thought the implications of his research might be, and his answer was “Oh Dan, I don’t have time to think!” All my early due diligence was probably good for me. It got me to confront the difficulty of the questions, seeing with my own eyes the pitfalls that trap many very smart and conscientious thinkers. This injected a small dose of modesty into my growing confidence that I had found—and partly invented—a prodigious explanation-device that reliably devoured difficulties, day after day. The insights (if that is what they were) that I had struggled so hard to capture in my dissertation and my first book have matured and multiplied, generating answers to questions, solutions to problems, rebuttals to objections, and—most important—suggestions for further questions to ask with gratifying consilience. I just turn the crank and out they pour, falling into place like the last pieces in a jigsaw puzzle. Perhaps my whole perspective is a colossal mistake—some of my critics think so—and perhaps its abundant fruits are chimeras. What if I’m wrong? Good thinkers frequently ask themselves this question, the way good doctors frequently check their practices against the Hippocratic oath they swore, and not just as a formulaic ritual. What if I’m wrong? Good thinkers frequently ask themselves this question, the way good doctors frequently check their practices against the Hippocratic oath they swore. My favorite chapter of Mark Twain’s Adventures of Tom Sawyer tells of Tom’s brilliant stunt of getting his friends to pay him for the privilege of whitewashing the fence in front of his house, not just saving him a chore but enriching him. This inspired me to adopt the same strategy with my books: I invite Tufts students to help me write my books by sharing the penultimate draft with them in a seminar, where they are all encouraged to point out errors, challenge arguments, demand more clarity, and in general complain about anything that strikes them as amiss. They don’t get paid for this excellent editorial service—in fact they are paying one of the highest rates of tuition in the country—but they do get thanked in the preface by name, and they get an autographed copy of the book when it’s published. I believe everyone involved has been quite content with this arrangement. I particularly cherish the intrepid naysayers who force me to expand, revise, or drop what I had thought were good points. Students often come to my office to discuss their term-paper projects in my courses, and a familiar combination of ambition and anxiety is the enthusiastic student who has a Big Idea—a Refutation of some well-regarded claim of mine or of some other writer we have read. They’re itching to go for it, but “What if I’m wrong?” I have some not-quite-foolproof advice: take courage and set out to write up the Great Discovery; if after many hours of red-hot thinking and writing you discover to your dismay a fatal flaw, something that you overlooked or underestimated, all is not lost. Go back to the first paragraph and write something along the lines of “It is tempting to think that . . . , because there seems to be a powerful argument to the effect that . . . , but as we shall see, this is an error.” Then make a few minor adjustments to the rest of the paper, pointing carefully to the error that you almost made, and you’re ready to submit it. If your Big Idea was tempting to you, it might well be tempting to others. Showing the field that this is a cul-de-sac to be avoided is a genuine contribution. The same strategy, writ large, is good advice for a whole career. Try your Big Hunch out on a few knowledgeable people; if nobody can knock it down right away, then take a leap, make a major investment of your time (bearing in mind the large cost of lost opportunities if you make a bad choice) and hope for the best. You may at least be able to salvage a definitive refutation of your hunch, all the more credible for having been composed by somebody who was initially a partisan. Take courage and set out to write up the Great Discovery; if after many hours of red-hot thinking and writing you discover to your dismay a fatal flaw . . . all is not lost. Go back to the first paragraph and write something along the lines of “It is tempting to think that . . . ” The Discovery Institute is the well-funded propaganda site for Intelligent Design, as creationism is now called. I have often scoffed publicly at the dismal ratio of propaganda to peer-reviewed science in its output and urged its directors to put their money into some real science that might, conceivably, prove them right. So when they announced in 2005 that they were setting up a serious research facility, the Biologic Institute, to do experiments aiming to refute the theory of evolution by natural selection, they asked me to express my opinion of this innovation. I wrote back that I applauded this move, since there are scads of unasked questions in evolutionary biology that are neglected by biologists simply because they’re sure they already know the answer: How did species X with feature Y come to be? It evolved, of course, but we don’t know the details. Nobody wants to sic a graduate student or postdoc on any of those questions, because the reaction among the influential workers in the field to the results would be along the lines of “Ho hum, what else is new?”—not a good way to start a career. If, however, the Biologic Institute wants to fund young scientists who are passionately committed to disproving evolution, this will harness their energy and training without our having any scruples about encouraging them to waste their precious time. They will see themselves as crusaders on a divine mission, and what could be more glorious than that? They will try to find hidden among these unasked questions embarrassing examples of “irreducible complexity” that couldn’t have evolved gradually. They will eventually discover that they’re wrong, and we will have yet further examples of evolution’s devious paths. In my terminology, their dogged search for skyhooks will uncover heretofore unimagined cranes. And precisely because their conclusions will be the opposite of what they hoped to discover, we will take them seriously. Good theories thrive on serious attempts to refute them that fail in instructive ways. What, though, if my supposed insights are just generated by a prodigiously fertile mistake? It’s worth remembering that this has happened before, on a cosmic scale. Descartes wrote his retrospectively preposterous books—Le Monde (eventually published in full in 1667) and Principia Philosophiae (1644)—presenting the first detailed TOE (theory of everything). He had deduced (he claimed) the truth about everything under the sun and beyond the sun, including starlight and planets, tides, volcanoes, magnets, and much, much more, most of it dead wrong. It was Newton’s majestic Principia (1687) that decisively refuted Descartes. Descartes’s theory of everything is, even in hindsight, remarkably coherent and persuasive. It is hard to imagine a different equally coherent and equally false theory! He was wrong, and so of course I may well be wrong, but enough other thinkers I respect have come to see things my way that when I ask myself, “What if we are wrong?” I can keep this skeptical murmur safely simmering on a back burner. Adapted from I’ve Been Thinking. Copyright (c) 2023 by Daniel C. Dennett. Used with permission of the publisher, W. W. Norton & Company, Inc. All rights reserved. When you buy a book using a link on this page, we receive a commission. Thank you for supporting Behavioral Scientist’s nonprofit mission.",
    "commentLink": "https://news.ycombinator.com/item?id=39351195",
    "commentBody": "What If I’m Wrong? (2023) (behavioralscientist.org)190 points by jrlocke 11 hours agohidepastfavorite162 comments ggm 10 hours agoI've grown used to being corrected, to the point that it's a pleasant surprise to be told I might be right. What I notice more and more, is the \"you're wrong\" is used to buttress opinion masquerading as fact. If you preface \"I think that..\" to asserts it doesn't stop the \"you're wrong\" but it at least puts the discussion into the realms of conjecture about things, including facts, rather than simple asserts of facts which are often not as factual as they seem. I also notice that argument by analogy is being over-used. Because you want to compare your large single CPU to a multi CPU doesn't mean it actually is a Bull compared to a herd of chickens. Or that cat-herding is actually much harder than it looks: you need the right kind of cream. Wait.. that analogy might not work here.. reply The_Colonel 15 minutes agoparentArguing by analogy is indeed problematic. You can often find rough analogy which supports the argument, but also a different analogy which disproves it. Additionally, I think arguing by analogy is a sign that you lack real / structural arguments, real understanding. reply haswell 9 hours agoparentprev> I also notice that argument by analogy is being over-used This one seems especially pernicious, not because of extremely over-wrought comparisons, but because sometimes the analogy fits really well on the surface. But beyond the structural fit, it does not really help prove anything. Too often I'll encounter an analogy wielded as if it proves the underlying point, when the reality is that it breaks down quickly if you dive into the details. Analogies can be great to help establish new mental models, or to try out an idea with terminology that people already understand, but can be quite misleading. Better used for learning than trying to prove things. reply ben_w 9 hours agorootparentAnalogies are like a box of chocolates: overused clichés, but we hand them out and gobble them down with delight. reply efitz 9 hours agorootparentAnalogies are decorative writings, not arguments. reply Jensson 8 hours agorootparentThey can be arguments, for example if you want to show that the other person has inconsistent views due to feelings or bias an analogy between the two inconsistent scenarios can make that clearer. I've changed my mind thanks to analogies many times. reply haswell 6 hours agorootparentTo split hairs a bit, analogies can support arguments, but are not considered a conclusive form of evidence/argumentation in and of themselves in formal logic. While the analogy may have been instrumental in helping change your mind, it likely did so by helping you understand the actual underlying argument. reply Jensson 5 hours agorootparentIf a human based their views solely on formal logic then they wouldn't have an inconsistent world view in the first place, so I don't see why you bring up formal logic here. > While the analogy may have been instrumental in helping change your mind, it likely did so by helping you understand the actual underlying argument. The world would be a much better place if that was true, but sadly people base their world view largely on feelings and those feelings often doesn't care about the underlying arguments but they can feel the analogies. That goes for you and me as well, feelings are a fundamental part of human thinking, you can't just ignore that just because formal logic says it isn't important. For example, a person might say that they are against racism but they are pro discriminating against white people. That aligns with their feelings, but it is inconsistent and you would need something more than formal logic to make them see that inconsistency. And once they see it you didn't do it by making them understand a formal argument, you did it by changing how they feel about things, they already agreed with you that discrimination is bad they just didn't apply that consistently due to their feelings clouding their minds. reply defrost 5 hours agorootparent> If a human based their views solely on formal logic then they wouldn't have an inconsistent world view in the first place, Can you remind the class about Gödel's second incompleteness theorem and what it says about consistency in formal logic systems? reply Jensson 5 hours agorootparentNope, I wrote that based on a feeling not formal logic. But now I'm starting to feel that I was wrong there, see my mind is changing without any formal arguments. reply ggm 9 hours agorootparentprevI love the orange cream. I hate the nougat. reply dylan604 7 hours agorootparentwhat if you're wrong reply ggm 5 hours agorootparentThen I have to change my mind. But I think right now, it's not that I'm wrong to prefer orange cream, it's that I can't justify it from objective criteria except that one time I split a tooth on hard nougat which might colour my preferences reply dylan604 4 hours agorootparentIf you're not wrong, then I'm wrong, and well, that's just not possible ;^) reply Terr_ 4 hours agorootparentprevAnalogy discussions break down when people aren't in agreement about which features are or aren't important to map across... or worse, when one or both sides haven't even considered what they are. reply wombatpm 5 hours agoparentprevMy inner jerk likes to assert Hitchin’s razor: what can be asserted without evidence can also be dismissed without evidence reply taneq 5 hours agoparentprev> you need the right kind of cream. Ina a similar vein, when people talk about managing creative technical types as ‘herding cats’ I respond that this is a management style issue: You don’t herd cats, you give them something to chase. reply paulpauper 10 hours agoparentprevI have grown accustomed to being wrong a lot as well, especially online, but it would be nice being right more often too. It's like \"Am I really that far off the mark? Maybe I am. Downvotes coming.\" I like to think my opinions are not that bad. Yet when it comes to investing in other aspects in life ,where money is at stake or making income, I have been right more often than not. So I guess I right where it matters most, and wrong about the less important things. Or maybe I am wrong about those things because I don't invest as much mental energy into having the perfect or correct opinion compared to things where there is money at stake. reply digbybk 10 hours agorootparent> I like to think my opinions are not that bad. I find this sentence kind of funny. If you thought your opinions were bad wouldn’t you change them? reply rfrey 10 hours agorootparentOf course \"I think my opinions are correct\" is a tautology. But what people mean when they say things like \"I think I have good opinions\" is that they think they were reasonably careful and thoughtful in forming their opinions... that they don't hold opinions just because they read a comment on an internet forum, for example. IMO. reply ihaveajob 10 hours agorootparentprevI suppose they meant that their opinions are not that controversial or against the norm. I've encountered this when I talk online about car safety, speeding, and generally about safe streets. There's a particular type of car lovers who are always waiting to swamp any dissenting opinion with downvotes, effectively drowning the discussion. I think my opinions are not that bad but for that crowd, it would make you reconsider your priors; if they're so offended by what I said, am I wrong? reply efitz 9 hours agorootparentprevThe problem with opinions is not that they are good or bad, it’s how difficult they are to change. Other people who are unwilling to change “bad” opinions in the face of contradictory evidence is easily observed. If you find yourself never changing your own opinions, then you probably have a problem. reply nonrandomstring 9 hours agorootparentThe odd thing is, and I think this is Socrates, that it's hard to tell. Having been won over by the gentle force of the better argument what were once not your ideas feel like your ideas. In fact, now they are your ideas, and feel like they always were. reply Jensson 8 hours agorootparent> In fact, now they are your ideas, and feel like they always were. Some people don't remember what opinions they had in the past? Remembering all the time I was wrong and learned something new or changed my mind etc is embarrassing, not sure how you could forget all that. Like, people must remember which candidates they voted for in the past, right? So if they switch side during an election, do they really fool themselves into thinking that they always supported their new side? I don't really believe that. I'd rather believe that they lie about their past because it is embarrassing to have been wrong. reply backpackviolet 7 hours agorootparent> Like, people must remember which candidates they voted for in the past, right? I have noticed that in myself, but I have observed in some people it takes the form of “I didn’t shift, the party did”. They aren’t completely wrong either, political parties like the people that comprise them are constantly changing. But if you aren’t careful to avoid fooling yourself it’s not too hard to do. reply bo1024 3 hours agorootparentprev“Or I’m wrong, I just don’t know how. I guess when someone’s wrong, they never know how.” -The Big Short, more or less reply randomdata 10 hours agorootparentprevI’d rather not ever be right. If I am that means I learned nothing, making it a waste of time. reply thfuran 9 hours agorootparentIf you've never been right about anything, you might need to reconsider your approach to learning. I think you're doing it wrong. reply randomdata 9 hours agorootparentPerhaps you missed the communication subtext? Once I'm certain I'm right I'm not going to talk it about it ever again. What would be the point? There's nothing left to learn. I'll have moved on to new topics where I don't yet know what is right – where I'm hopefully wrong so there is something to learn. reply Jensson 7 hours agorootparentHow would you go to right but unsure to right but sure without learning anything? I don't think that being right prevents you from learning, at least you had to learn something about other arguments so you could reject those. reply randomdata 6 hours agorootparentBy being right, sometimes. But I'd rather not be. reply latency-guy2 6 hours agorootparentprevIf all you ever do is be wrong, I will promptly fire you. reply randomdata 6 hours agorootparentAn action (do) is never right or wrong, it just is. A recount of an action may be wrong. e.g. \"He did X\" when in actuality he did Y. reply roenxi 9 hours agoparentprevOn the topic of opinion masquerading as fact - if you check the dynamics there it quickly gets quite interesting. Political arguments are unusual if they involve an expert. On the big ones (economics, medical, military and technical policy) it is relatively rare to see an expert and doubly rare to find one who isn't pushing some sort of agenda. There tends to be a tiny pool of people doing a speaking circuit that turn up again and again and they're there for a reason. If you run the numbers on (informed people informing the discourse about a topic) / (people who know about topic) the numbers are a bit grim too. And a big driver of that seems to be that either the debate isn't about facts so nobody cares, or frequently that the experts don't have a well advertised an opinion on an important subject. It really turns up in economics where finding facts is a challenge. The biggest economic miracle of our time is China's industrial policy and it isn't particularly obvious what the facts about that are. I'm sure that there are economists who are devoting their lives to figuring out what happened in China because it is an interesting and important topic. But where the facts are being surfaced is not obvious and it isn't going to make its way through the broader public discourse. TLDR; finding any facts in any public discussion is actually a bit of a challenge. It tends to be opinion all the way down until the trail goes cold. reply balderdash 8 hours agorootparentI generally agree with you, but at the same time don’t think it’s always nefarious. At least personally, I’d say I definitely am more opinionated (have more of staked out positions) in areas I know something about / spent time thinking through - I’d imagine the same is true for many “experts” - it doesn’t mean they are “right” but based on their underlying conceptual frameworks[1], most of the time they’ve come to a conclusion and are going to push that. [1] I find most policy debates I get into with friends have nothing to do with the policy at hand but rather more core political/philosophical questions underlying their thinking (e.g. do the ends justify the means or are they more individualist va collectivist) reply pitaj 8 hours agorootparentprev> The biggest economic miracle of our time is China's industrial policy and it isn't particularly obvious what the facts about that are. I'm not sure exactly what you're referring to, but I think it's pretty well understood that the growth of China is thanks to the market reforms in the 70s and 80s. reply HideousKojima 8 hours agorootparentprev>The biggest economic miracle of our time is China's industrial policy and it isn't particularly obvious what the facts about that are. Is it though? China's economic growth doesn't seem that far off (per capita) from that of South Korea or Taiwan. reply roenxi 8 hours agorootparentMy understanding is that China modelled itself on Singapore too, so I'm not expecting any radical policies. But part of the miracle is the scale of the thing, not just what happens per capita. If we go small enough, one man can go from whoever to billionaire in one generation. Getting a billion people up to a nice standard of living is harder than that. reply XorNot 10 hours agoparentprev\"best-practice\" is a specific, over-used term in the tech industry. People instinctively give opinions and say \"well best-practice is...\" to fortify it against being criticized, and then lean heavily on the fact that if you actually ask them to support that notion then they imply or accuse the questioner of being hostile. \"It's best practice\" should invite the question of \"according to who, in which publications? What are the circumstances of the practice, are they similar to our circumstances?\" reply aspenmayer 10 hours agorootparent> A weasel word, or anonymous authority, is a word and phrase aimed at creating an impression that something specific and meaningful has been said when in fact only a vague, ambiguous, or irrelevant claim has been communicated. The terms may be considered informal. Examples include the phrases \"some people say\", \"it is thought\", and \"researchers believe\". Using weasel words may allow one to later deny any specific meaning if the statement is challenged, because the statement was never specific in the first place. Weasel words can be a form of tergiversation and may be used in advertising, (popular) science, opinion pieces and political statements to mislead or disguise a biased view or unsubstantiated claim. https://en.wikipedia.org/wiki/Weasel_word Edit: Verb tergiversate (third-person singular simple present tergiversates, present participle tergiversating, simple past and past participle tergiversated) (intransitive) To evade, to equivocate using subterfuge; to obfuscate in a deliberate manner. (intransitive) To change sides or affiliation; to apostatize. (intransitive, rare) To flee by turning one's back. https://en.wiktionary.org/wiki/tergiversate reply nonrandomstring 10 hours agorootparentThere's a spectrum isn't there, between weasel words that are avoidant and non-attribution which is done out of respect or kindness. News is full of passive prose; \"A source claimed yesterday\", because anonymous sources need protection. A barrister might say in court; \"It has been said that...\", not to invite libel or misidentify a witness. Or a teacher might say \"It's been brought to our attention that some children...\" not to embarrass a kid in front of everyone. reply aspenmayer 10 hours agorootparentThese are good points. Here are some links I found relating to legitimate points you have raised: Why does The New York Times use anonymous sources? https://www.nytimes.com/article/why-new-york-times-anonymous... A Look at Journalists' Use of Anonymous Sources https://www.voanews.com/amp/journalists-use-anonymous-source... Society of Professional Journalists Ethics Committee Position Papers: Anonymous Sources https://www.spj.org/ethics-papers-anonymity.asp Everything-but-the-kitchen-sink: a guide to confidential sources https://ethics.journalism.wisc.edu/2018/12/07/the-everything... https://en.wikinews.org/wiki/Wikinews:Avoid_weasel_words https://en.wikipedia.org/wiki/Wikipedia:Avoid_peacock_terms https://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Word... https://en.wikipedia.org/wiki/Puffery reply bongodongobob 10 hours agorootparentprevNah. Best practice usually means \"assume a spherical cow\". The idea is to point in the right direction because there are no one size fits all solutions for anything. It's a starting point that isn't stupid and is backed by the blood of poor bastards from the past. reply RaftPeople 8 hours agorootparentBut frequently, in technology, the term \"best practice\" is used where it's not really settled whether it's a good practice 80% percent of the time or only 20% percent of the time. If you look at the history of industry trends over the last X decades, most of which were replaced by the next trend due to the pain that was eventually discovered, you will find many people claiming the new trend was \"best practice\" typically mid-way through the hype cycle and before the actual trade-offs become well known. reply pixl97 10 hours agorootparentprevI mean, not writing your own encryption library is best practice. reply briHass 5 hours agorootparentIt's not clear, even, to what depth this 'best practice' applies. Writing your own crypto primitives is probably a bad idea, but what about combining them? AEAD approaches demonstrate there can be nuance even with battle-tested primitives and how they're combined or used in practice. Oh, but what about key derivation or protecting the keys in general? What good is that library's encrypt method if the DIY key secrecy/rotation/exchange is sloppy? reply Eisenstein 9 hours agorootparentprevIf someone asks you 'why?' can you tell them? If not, you are using it as a weasel word. If so, then you are using it as shorthand for 'I could explain it but I don't think I need to right now'. reply delichon 11 hours agoprevPtolemy was wrong. But he was wrong with a large pile of actual measurements of celestial bodies, and a falsifiable theory. That made him wrong in the positive sense of wrong in the phrase \"not even wrong\", where wrong is just the first step of the ladder. I wish I could say the same about Freud, but that ladder is distressingly horizontal. reply dekhn 10 hours agoparentI think the right phrase here is not 'not even wrong' but 'wrong but for the right reasons' or 'all models are wrong, but some models are useful (possibly by being less wrong' reply bsder 9 hours agoparentprevPtolemy was not \"wrong\". His model worked quite well within the margin of his measuring tools. And, in fact, Ptolemy was more \"right\" than heliocentric circles (as opposed to ellipses). You have to have both elliptical orbits and inverse square law forces to predict better than Ptolemy. It wasn't until the telescope allowed seeing Venusian phases that geocentricity was actively disproven. reply javajosh 10 hours agoparentprevThere is a strong analogy in software engineering here. Often the first implementation is \"wrong\" in the sense that it doesn't resolve the inherent tensions in the system. But that doesn't make it useless - in fact, it's quite useful because it actually showed you what is important. Plus, the people who attempt the initial solution to a problem deserve special honor, even if their work is eventually tossed away, specifically because they revealed these system tensions. The common dictum to \"write a prototype and throw it away\" is largely based on this insight. What I'm saying is that Ptolemy, Aristotle, etc did a great service to humanity by taking a stab at hard problems, even if their solutions were convincing but wrong. Whether they knew it or not they were the primordial programmers writing a throw-away prototype upon which all future progress was based. reply QuercusMax 9 hours agorootparentI work on healthcare at Alphabet, and in late 2016 I set out to build a flexible DICOMweb STOW-RS receiver in the form of a GCP API - the first time anyone had done that at Alphabet. (I've worked on the same project across Verily and Google). In the process I researched and built a bunch of little prototypes built in a variety of ways, and for example had to rule out building it as an App Engine API - because DICOMweb uploads can potentially be gigabytes in size, and App Engine didn't support handling a POST as a stream as it arrived. At any rate, along the way over the course of 9 months or so I found a technology stack that supported all my requirements and ran into a bunch of roadblocks. Lots of things related to how internal bits of GCP APIs are handled - the internal libraries had documentation indicating that streaming APIs were supported, and that each chunk of the request would be passed from the API proxy/backend multiplexer to the actual API server as they arrived. This worked for streaming responses, but not for streaming requests, and so I had to add that functionality to the API proxy. That was a huge pain - really hairy c++ code using fibers with multiple layers of request processing wrappers. But I worked thru that and got it landed into the google-wide binary, and never worried about it again. I got this project to the level I needed it to support the precise requirements for the (regulated medical device) system I was working on. Around this time the GCP Cloud Healthcare group was getting started, and they built a new system using a fair number of bits of my implementation, which they'd eventually replace completely. But my first system saved them most of a year or work, resulting in the CHC feature set rapidly leapfrogging what I'd built. reply jyunwai 9 hours agorootparentprevA similar idea about the importance of planning as a way to improve your understanding of a problem was expressed by Dwight D. Eisenhower, said in a speech while he was in office as the US President in 1957 [1]. Reflecting on his experience in the Second World War, he said: \"Plans are worthless, but planning is everything. There is a very great distinction because when you are planning for an emergency you must start with this one thing: the very definition of “emergency” is that it is unexpected, therefore it is not going to happen the way you are planning.\" [1] https://quoteinvestigator.com/2017/11/18/planning/ reply nonrandomstring 9 hours agorootparentprevYour software engineering example made this click for me. I think what we might be talking about is the method of abduction [0][fn] [fn] not kidnapping, but a logical (procedural) method like induction or deduction [0] https://plato.stanford.edu/entries/abduction/ reply aspenmayer 10 hours agoparentprev> \"Not even wrong\" is a phrase often used to describe pseudoscience or bad science. It describes an argument or explanation that purports to be scientific but uses faulty reasoning or speculative premises, which can be neither affirmed nor denied and thus cannot be discussed rigorously and scientifically. The phrase \"not even wrong\" is synonymous with \"unfalsifiable\".[0][1] [0] https://en.wikipedia.org/wiki/Not_even_wrong [1] https://www.theguardian.com/science/2005/sep/19/ideas.g2 reply dataflow 10 hours agorootparentI'm not sure \"not even wrong\" actually means the same thing as \"unfalsifiable\" like Wikipedia claims? I thought \"not even wrong\" means the asker is so confused that their question doesn't make sense. As I understand it, \"ghosts exist\" (or even \"the universe is infinite\") may well be impossible to falsify, but it doesn't signal any sort of confusion on the part of the asker. But if the statement was \"ghosts exist because the universe is infinite\", then I thought that would fall into the \"not even wrong\" bucket. reply aspenmayer 10 hours agorootparentI understand “not even wrong” to be synonymous with unfalsifiable in the sense that the statement being described as such is not a truth claim, or is otherwise not a valid formal statement or claim, such that the scientific method is not able to be deployed to consider its validity. > In religion, a truth claim is an assertion that the belief system holds to be true; however, from the existence of an assertion that the belief system holds to be true, it does not follow that the assertion is true. For example, a truth claim in Judaism is that only one God exists. Conflicting truth claims between different religions can be a cause of religious conflict. The theory of truth claims has been advanced by John Hick. https://en.wikipedia.org/wiki/Truth_claim reply killthebuddha 10 hours agorootparentprevHmm. I always thought \"not even wrong\" meant \"correct, but answering the wrong question\" or more generally \"correct but irrelevantly so\". reply aspenmayer 10 hours agorootparentI think that your example is something I would consider “beside the point,” whereas the flavor of “not even wrong” to me seems to describe a statement or claim that has truthiness[0] rather than a truth value[1]. A statement which is not even wrong is one that can’t or isn’t expressed properly as a logical assertion or argument but rather asserted without evidence or in such a way that it is made to seem inherently or intuitively obvious. Such a statement isn't argued for or against properly or logically, or isn’t otherwise properly expressed or derived, or a statement or claim which falls short of making a concrete point or argument which can be dismissed or validated on the basis of evidence or logical argument. [0] https://en.wikipedia.org/wiki/Truthiness > Truthiness is the belief or assertion that a particular statement is true based on the intuition or perceptions of some individual or individuals, without regard to evidence, logic, intellectual examination, or facts. Truthiness can range from ignorant assertions of falsehoods to deliberate duplicity or propaganda intended to sway opinions. [1] https://en.wikipedia.org/wiki/Truth_value > In logic and mathematics, a truth value, sometimes called a logical value, is a value indicating the relation of a proposition to truth, which in classical logic has only two possible values (true or false). reply paganel 10 hours agoparentprevTrying to apply falsifiable theory to Freud (or to psychoanalysis) is wrong in itself, as a matter of fact thinking about Freud and psychoanalysis in the realm of scientifically right or wrong is, well, scientifically wrong. reply helloplanets 2 hours agorootparentIn that case, how should we think about it? Genuinely curious. reply paganel 50 minutes agorootparentHe (Freud) had some very good insights, almost genius-like, for example the part with Eros and Thanatos. With that said, I don't think there's a best way to approach his works, I do know though that treating them as science would do no-one any good. As for psychoanalysis as a whole, it's definitely not my preferred cup of tea but I do believe those people that say that it has genuinely helped them, in which case all the power to them and to psychoanalysis. Maybe treat it through a functionalist prism? (just an idea) Similar to meditation, let's say (similar as in there's no scientific \"basis\" behind it but I also do believe that meditation helps some people, similar to psychoanalysis). Of course, that would not solve the issue with \"what should we do with the psychoanalysis crooks?\", the same issue that probably gets asked when it comes to meditation crooks, meaning grifters trying to live off psychoanalysis/meditation/any similar movement. I don't know what the best answer for that would be, maybe some sort of community-based validation/word of mouth thingie? reply atdt 10 hours agoprevWonderful piece. Dennett knows how to write. And he captures the pleasure and privilege of Hacker News with this felicitous phrase: > Distributed understanding is a real phenomenon, but you have to get yourself into a community of communicators that can effectively summon the relevant expertise. reply a_wild_dandan 7 hours agoparentI agree. We have an eclectic community of thoughtful laypeople and experts. That's why I remain here. It's lazy to point out warts in any community (even peer-reviewed ones!), presume that good is the enemy of perfect, and thus dismiss said community. But I think the SNR here is wonderful presently, and I appreciate you all. reply wayeq 8 hours agoparentprevare you sure that's us? :) reply Jensson 5 hours agorootparentYes, you have a combination of people who learn and people who know here. That is what he described, and environment where you are allowed to be wrong and where people will correct you when you are. You don't get banned from HN for being wrong, so you are allowed to be wrong here, unlike many other forums like most of reddit. reply Capricorn2481 2 hours agorootparentWhat is being described is that people will know what they're talking about, which is debatable. You might be corrected on here, but I've seen more cases of people being loudly wrong but having enough general knowledge on a subject that they sound correct, and lucky enough that no one with specific knowledge stumbled on their posts to correct them. Frankly, I don't think hackernews is all that different in terms of community from Reddit. People are just better at hiding it. Many are regurgitating rhetoric they've heard in other posts without having experience with a subject. Even in the realms of programming, it's not hard to see how little experience people have with the things they demonize or evangelize. reply calf 3 hours agorootparentprevMaybe he's talking about the string theorist community reply DiscourseFan 7 hours agorootparentprevYeah I'm having serious doubts reply mtlmtlmtlmtl 10 hours agoprevDaniel Dennett is still the only modern philosopher I know of that is capable of explaining his ideas to non-philosophers without it devolving into meaningless(to me) babble, or even worse, an endless cataloguing of all the possible views one could hold on something, along with their names. reply bpshaver 6 hours agoparentWho are some examples of the type of modern philosopher you mean? reply briHass 5 hours agorootparentNot OP, and it depends on how 'modern' (or alive) fits the bill, but Heidegger is pretty impenetrable as a novice. reply gwd 8 hours agoprevI think the more important question is, \"How would I know if I were wrong?\" As a thinking Christian, and I've thought very carefully on what kind of evidence could be presented to me to show that Christianity was wrong; I'd be interested in what kind of evidence Dennet would accept to show him that his atheism was wrong. reply Ensorceled 7 hours agoparent> I've thought very carefully on what kind of evidence could be presented to me to show that Christianity was wrong This is inside out. What evidence was presented to you that made you believe Christianity was right? I became an Atheist in large part because I took Latin my first year in high school and realized that the Roman's actually believed in their gods the same way that I believed in the Christian god. And I gradually realized that they had the same reason to believe that I did ... they were told from a young age that this was real and just kept believing as they grew up. > I'd be interested in what kind of evidence Dennet would accept to show him that his atheism was wrong. I can't speak for Dennet, but for me it would just be ANY evidence: a verifiable miracle, proof of life after death, or meeting an angel/demon. reply knightoffaith 4 hours agorootparent>This is inside out. What evidence was presented to you that made you believe Christianity was right? I don't think this is really the right way to think about Christianity for many believers. C.S. Lewis says, \"I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.\" It's not so much that Christianity is just another fact lying out there that we just happened to stumble upon, and now we use scientific tools to investigate whether it's true or false. No - it's a belief that shapes the very way we understand the world. It's a worldview. That's not to say that it's necessarily correct, but just that it's not a belief that we necessarily acquire in the same way we might acquire a belief about what 1+1 is or how many planets orbit the sun. It's much like how someone born and raised atheist doesn't hold their belief in atheism because of some evidence for that view. We can still argue about Christianity, atheism, or other religions, of course, that's fine - but it's not obvious that there's some inherent irrationality in asking \"what could show Christianity to be false\" instead of \"what convinced me Christianity is true\". >they were told from a young age that this was real and just kept believing as they grew up. This is true, but if the implication is that belief in Roman paganism is on just as firm intellectual ground as belief in Christianity, that seems unfair given the rich intellectual history spanning millennia of the latter to which the former isn't really comparable at all. reply edanm 11 minutes agorootparent> No - it's a belief that shapes the very way we understand the world. It's a worldview. For Christians. You kind of do have to grapple with the fact that billions of people do not have that worldview, and therefore you do have to compare the Christian worldview to the non-Christian worldview. > >they were told from a young age that this was real and just kept believing as they grew up. > This is true, but if the implication is that belief in Roman paganism is on just as firm intellectual ground as belief in Christianity, that seems unfair given the rich intellectual history spanning millennia of the latter to which the former isn't really comparable at all. Maybe that's the case with Roman mythology (though I don't have the dates), but what about Hinduism? Buddhism? Islam? Judaism? All of these have comparable histories. reply Capricorn2481 2 hours agorootparentprevI don't have evidence someone is a psychic, but I have common sense that if they're predictions could apply to anyone, they are probably scamming me. Just like if someone chalks up inconsistencies in the Bible to \"God testing us\" or the fact that the Bible has been edited repeatedly, picking whatever parts supported their authority at the time, that I'm probably being scammed. Now Christianity is so fragmented and personal in it's belief system that to say \"what evidence do you have that it's not real\" does feel backwards. I have equal evidence in any religion as I do in Christianity. reply gwd 4 hours agorootparentprev> This is inside out. What evidence was presented to you that made you believe Christianity was right? It sounds like maybe some people are taking this as a challenge from me to atheists. I'm not really; just like Dennet is in TFA, I'm talking about general principles for someone trying to live as a rational creature: each of us should examine our own beliefs, and not only ask \"What if I'm wrong?\" but \"How would I know if I were wrong\"? That goes for Christians and Hindus and Muslims as much as for atheists. \"Take the plank out of your own eye before you try to remove the speck out of your brother's eye\" and all that. It's specifically because Dennet is such a deep thinker and effective communicator that I genuinely wonder how he'd answer that question. I'm not sure what evidence was provided to me as a child that the world was round; but I had relatives who lived in Germany and Thailand, and at the age of 12 I'd actually flown to Thailand and experienced jet-lag. The \"world is round\" hypothesis satisfactorily explained my experience (both first- and second-hand, through people I knew personally) in a way that the \"flat earth\" hypothesis doesn't. In the same way, the vast majority of evidence I had as a child to confirm what as taught about Christianity to me was experiential. But of course, all sorts of people from different faiths have religious experiences; how do I know that there's not some better explanation for my experiences -- either religious or reductive -- which will be more predictive (in the sense of getting better results more efficiently)? > I became an Atheist in large part because I took Latin my first year in high school and realized that the Roman's actually believed in their gods the same way that I believed in the Christian god. And I gradually realized that they had the same reason to believe that I did ... they were told from a young age that this was real and just kept believing as they grew up. This seems a bit strange to me... so the Romans believed in supernatural beings, and the Christians also believed in supernatural beings (and of course so did the Greeks, and the Persians, and the Babylonians, and the Egyptians, and...); but instead of this being evidence that there were supernatural beings of some sort (with some people maybe being closer to the truth of the matter than the others), you decided this was evidence that there weren't supernatural beings? Isn't that like reading several different conflicting scientific theories, and then deciding that all science is bunk? Sorry I don't have the exact quote, but there's a place where C.S. Lewis points out that being a Christian, he's free to believe that people of other religions were partly right and partly wrong; but that when he was an atheist, he had to believe that the majority of humans were completely wrong about the most important questions in life. If the entire world were atheists except Christians, wouldn't that be far stronger evidence against the supernatural? The fact that the Romans believed in the supernatural and the afterlife is evidence -- weak evidence, I grant, but evidence nonetheless -- that the supernatural and the afterlife exist. > but for me it would just be ANY evidence: a verifiable miracle, proof of life after death, or meeting an angel/demon. What would satisfy your requirements for a \"verifiable miracle\"? It sounds like a lot of these might be very personal experiences. First of all, if you had a single experience of an angel, would that actually change your mind? Wouldn't you be inclined to believe you'd had some sort of hallucination (wondering perhaps if someone had slipped LSD into your drink or something like that)? Similarly, once you had that experience and became convinced, how would you convince anyone else? Supposing there were another person who was exactly like you -- the fact that you were convinced you'd seen an angel wouldn't have any effect on whether they were convinced that angels existed, would it? FWIW I know a lot of people who started out as atheists and became Christians, and although this sort of rational \"apologetics\" sometimes did factor into part of their decision, by far the biggest influence was personal experience: first with genuine Christians, then with with Jesus, through reading the Bible and worshipping him at church. I tend not to focus on that kind of thing in a venue like this, because it's the least logically sound reason; but if you're genuinely interested in having a personal experience to let you put Christianity to the test, that's what I'd look for. As for me, I've got what I consider to be more objectively sound reasons to believe; but \"“I have discovered a truly marvelous proof of this, which however [this comment] is not large enough to contain.” Hopefully at some point I'll write it up in a way that's easy to link to. reply epiccoleman 7 hours agoparentprevI would be genuinely interested to hear what conclusions you came to - and I don't say that as a typical internet atheist waiting to pounce on some flaw in your logic. I've come at this from the other side many times and, though there's certainly a part of me that would like to, I just cannot find it within myself to believe that the human condition is explained in any way by Christian theology. I've found a good deal of resonance in the mystical traditions of various religions - I'm especially a fan of some of the Jewish mystical stuff (e.g. Kabbalah and other portions of the long tradition of debate and interpretation of scripture). But in spite of a lot of examination I've still wound up with, at most, a kind of \"spiritual but not religious\" attitude, which usually translates to, frankly, not much. I've found myself somewhat jealous of people of faith, who can find some system of belief that seems resonant enough to provide comfort and a framework for living a good life - but also, frankly somewhat nonplussed that people can buy into these various theologies and not run up against the same \"...really, that's supposed to explain all this?\" that I do. reply knightoffaith 7 hours agorootparentWhy is it that you think the human condition is not explained by Christian theology? To be sure, you don't mean \"I think Christianity is false\", right? It can be false but still explain the human condition. reply epiccoleman 7 hours agorootparent> It can be false but still explain the human condition. Sure - and as a matter of fact, this is largely the angle I approach religion from these days - i.e. that we collected a series of parables, rules, and traditions that, when combined, lead to a \"good life\" (or, more cynically, provide competitive advantages to societies who adopt them in a sort of \"memetic natural selection\" paradigm). But when I look at the mythology of Christianity, especially the parts of it that are mainstream and not parts of mystical or esoteric traditions, I don't find it to be a compelling enough story to base my life around (or at least, not enough to go and declare my faith in it every Sunday). The central \"myth\" of Christianity is that humans are born into a state of sin and cannot reach salvation (Heaven, eternal life, or maybe more \"mystically\" a state of oneness with the Divine). And the myth goes on to state that God essentially allowed/caused humans to sacrifice his son to Him so that this original sin could be washed away and allow humans to be \"saved.\" It seems to me that this has very little explanatory power for the sorts of existential questions like \"why are we here,\" \"why are we conscious,\" \"why is there so damn much other stuff in the universe\". As a story, there's a lot of appeal to me. Jesus as a role model, as an example of how we ought to try to be, has some good features (some bad ones too, but that's OK with me since I'm not taking the story as the literal word of God). I just don't know how people go from \"this story has some nice features worth meditating on in a secular way\" to \"this story explains why things are the way they are and what we're supposed to do about it.\" This is one of the things I find more appealing about Judaism, because there appears (to an outsider) to be much more of a tradition of grappling with faith, of trying to unpack the meaning of the \"words of God\" and relate them to the human condition. I'm sure there's some of that in Christian traditions too, but it was never a mainstream feature of the Catholicism that I grew up with. reply knightoffaith 4 hours agorootparentI don't know that the story of Jesus's crucifixion and resurrection specifically is supposed to explain something like \"why we are conscious\", but here is my (somewhat shoddy) explanation of what Christianity says about the human condition: The purpose of our life is to be in a loving relationship with God. This entails becoming who we are - becoming our true, ideal selves, who express our love for God through our lives, building the kingdom of God. This is why God has created us. We cannot attain this full self-actualization without the help of God. Thankfully, in God's infinite love, He has given us His son, allowing us to attain salvation. Indeed, no matter how wretched and sinful one might think one is, because of Christ's sacrifice, nobody is beyond repair (see Luke 15). >This is one of the things I find more appealing about Judaism, because there appears (to an outsider) to be much more of a tradition of grappling with faith, of trying to unpack the meaning of the \"words of God\" and relate them to the human condition. I'm sure there's some of that in Christian traditions too, but it was never a mainstream feature of the Catholicism that I grew up with. I grew up as a Catholic as well, so I understand why you might think this. But I really do not think this is because of Catholicism so much as it is because of shallow education (possibly because it's hard to get someone to think deeply about these issue when they're young, and it's far easier for them to get them to be able to recite John 3:16). If anything, Catholicism is a highly intellectual tradition. I know Orthodox Christians and some Protestants actually dislike Catholicism because they think it is too rational, that they bring too much of human reason into religion when they should just trust in the traditions handed down to us. Catholicism, and Christianity in general, have a very strong tradition of grappling with faith and trying to understand how the words of God relate to the human condition. Like, it's quite surprising that your takeaway is that Christianity doesn't do this and that this is the reason you don't find it appealing because if anything this is a key characteristic of Christianity. 2000 years of people arguing about biblical exegesis, theology, Christology, etc. It is really a great shame that catechesis today is so poor that people like you who are genuinely open to it have come away thinking \"These people aren't really grappling with their faith or seriously engaging with the word of God and what it means for us today.\" TL;DR - There's more to Christianity. Even if you haven't found anything I've said above interesting, it would probably be worth your time looking more deeply into it. reply cksquare 7 hours agoparentprevThis is the tired kind of equivocating that's used by lazy Christians to claim atheism is a discrete and well-formed ideology. Atheism is just that, a-theism, a rejection of the notion of a supernatural dimension occupied by 'personal' god(s). What evidence (or counter-evidence) do you suggest I present to show that my disbelief in Thor or Odin is wrong? reply gwd 7 hours agorootparent\"Unicorns exist\" and \"unicorns don't exist\" are both factual statements of which one can have a belief. Right now you probably hold one or the other. Sure, if you'd never heard of unicorns, such a thing wouldn't enter your head; but you have heard of unicorns, and thus you do have an opinion on their existence. Similarly, if one lived all one's life in a rationalist bubble, and never even heard the mention of God or gods or religion or the supernatural, then perhaps one could not have an opinion on whether God exists. But that applies neither to you nor to Dennet. How would I know that my disbelief in Thor is wrong? At a first cut, I'd need to have someone propose a more concrete proposition to evaluate; then I could try to evaluate it. But whatever that proposition is, it would need to be able to accommodate all that we've learned about the world and about science; it would need to be falsifiable; and it would need to explain the world in a more satisfactory manner than the alternative worldviews. reply cksquare 7 hours agorootparent\"Unicorns exist\" and \"unicorns don't exist\" are not factual statements, they are premises. Establishing the truth or falsehood of either has nothing to do with my opinion of the existence of unicorns--unicorns would not exist in spite of my fervent desire for them to be real, or if I just happened to think they were really cool. Assuming that you believe in the miracles of the old and new testaments, how would such things be proven false? For them to be positive evidence for the existence of God, we should at least be able to imagine how we'd go about refuting them. reply backpackviolet 6 hours agorootparentprev> Right now you probably hold one or the other. No, right now you probably have no opinion on the subject. And depending on context are perfectly willing to entertain either or neither. The world will be a much better place when people stop having opinions on things just because someone asked them to pick a team. reply gwd 6 hours agorootparentA reasonably mature thinker holds beliefs in terms of Bayesian estimates, and as Dennet says, one should always be willing to entertain evidence that contradicts your current Bayesian estimates. That doesn't mean you don't have beliefs. reply Jensson 7 hours agorootparentprevWhen you read a fantasy story you don't really think about whether it is true or not, if someone asked you then you would say it isn't true, but you never thought about it before prompted. So for me the first time I really thought about whether god existed was in internet discussions. When I learned about the religions in school it was just a bunch of cool stories and cultural things, there was no need to think whether any of that was real or not. And when I got into internet discussions and first encountered religious people I wondered why they thought a fantasy story was real, but apparently you can't ask them that. reply knightoffaith 6 hours agorootparentMaybe there are some people you can't ask that, but of course, many are happy to deal with the question. And indeed, historically, theists have long engaged with questions about why their religion is true. Anyway, unlike fantasy stories, religious people are led into belief due to things like people insisting that a religion is true, arguments that suggest that God exist, and spiritual experiences. Maybe this isn't convincing to you, but it's markedly different from a fairy tale. reply Jensson 5 hours agorootparent> people insisting that a religion is true, arguments that suggest that God exist, and spiritual experiences I just never met such people irl so I have no idea what that is like. Like, having a bunch of people trying to gaslight you into believing in these stories feels like a nightmare to me, I can see why you would say you believe just to make the nightmare end. The only very religious person I talked to about these things irl said that belief is a very personal thing and he didn't care about what others thinks or doesn't think. I think that is much healthier, and with such an approach you get almost no believers since there is no longer any pressure to believe things we wouldn't naturally believe in. reply knightoffaith 4 hours agorootparentI don't know what in my comment provoked such a negative reaction from you - maybe the word \"insisting\" came off as too strong? I really just meant to say that there are many people who seriously believe in religion, and you can't say the same for fantasy stories. If you're not interested, that's fine. Anyway, they're not really \"gaslight[ing] you into believing in these stories\" any more than a climate change activist is doing that. They believe their stories are true and that it would have a positive effect on you and the world if you too were to believe in it. reply Jensson 7 hours agoparentprev> I'd be interested in what kind of evidence Dennet would accept to show him that his atheism was wrong. Not sure what you mean, any clear sign from a god would apply here. You seem to believe that such a thing isn't possible making their position irrational, but then I wonder how you can still say you believe in a god? Do you believe that God can't intervene in this world? But for example, if God manifested giant talking heads all over the world I am pretty sure atheism would disappear very quickly. reply bglazer 7 hours agoparentprevPersonally, if there was an easily verifiable, continuous example of a phenomena that violated basic physics and it was arranged in such a way that it sent a clear message confirming the existence of a deity, then I’m easily done with atheism. Like if the gases of a nebula got rearranged to spell out “God is real”, then sure yeah I guess they are real. reply jibalt 43 minutes agoparentprev\"I've thought very carefully on what kind of evidence could be presented to me to show that Christianity was wrong\" I don't believe this. \"I'd be interested in what kind of evidence Dennet would accept to show him that his atheism was wrong.\" Perhaps the reason you aren't aware that he has addressed this at length is that you don't have have his name right. Also, as Chris Hitchens noted, religion poisons everything, including this thread. reply edanm 9 minutes agorootparentYou're being unnecessarily mean and confrontational, that isn't a good fit for HN. You can take parent at their word that he's thought about it and engage, or you can choose not to engage. No reason to disparage them. reply Scubabear68 7 hours agoparentprevI think the very definition of Christianity is that you are accepting the creed on faith. There really aren’t any claims you can verify or falsify until after you die (or during the special time of the Rapture). reply a_wild_dandan 7 hours agorootparentPersonal revelation requires no faith. Such evidence might then rationally lead to belief, like any other anecdotal conviction. That it provides little external evidence is just unfortunate for the rest of us. reply felipefar 7 hours agorootparentprevThat's not the definition of Christianity. Catholicism has a long philosophical tradition discussing the existence of God, and that tradition is far from refuted. reply Scubabear68 7 hours agorootparentI think you misunderstand. There are no physical proofs available that Christian it is right. As I say, it is all based on faith and belief. Several other religions also have long philosophical traditions that are equally plausible - or not - and for which no physical proof exists. reply a_wild_dandan 7 hours agorootparentMathematical proofs need no physical evidence. They're saying something similar is accepted by some Christians. That's an internally consistent viewpoint. Us skeptics simply misunderstand their irrefutable logical proof. reply Scubabear68 6 hours agorootparentMath is a tool used to describe the universe, not the universe itself. The map is not the territory. reply a_wild_dandan 2 hours agorootparentYou appear to be shadowboxing an argument where no arguments were made. If anything in my observational comment strikes you as remotely controversial or contradictory to yours, something has gone awry. reply MeImCounting 3 hours agorootparentprevThank you for saying this. This is very true and a perspective that is all too relevant to this discussion and many others. reply Ensorceled 7 hours agorootparentprevIt is literally impossible to prove that god does not exist. It is not a disprovable statement. I also can't prove Ra, Zeus, Thor, Unicorns, Ghosts, or Superman don't exist. reply knightoffaith 7 hours agorootparentWell, there are some atheists that argue that God's omnibenevolence is incompatible with the evils in the world, meaning God cannot exist (or at least, is either not omnibenevolent or not omnipotent, and if these are part of the definition of God, then God insofar as the term refers to something with at least these two properties, does not exist). Theists have responses to this argument, but the point is that the subject matter is something that can be rationally discussed. reply slothtrop 7 hours agorootparentprevDiscussing, not doubting (Except as an exercise to criticize skepticism). reply a_wild_dandan 7 hours agoparentprevThe same evidence that you'd need for belief in other gods. He just goes one god further than you. reply Vecr 7 hours agoparentprevI'm not sure what Daniel Dennett's current position is on action without free will, but assuming it's something reasonable, I'd consider it plausibly wrong if gassing hell and nuking heaven failed to produce the desired effect in a way that's almost impossible to fake. reply viscountchocula 8 hours agoparentprevOut of curiosity, what might that evidence Christianity is wrong be? reply kgwxd 7 hours agoparentprevYou have 0 evidence that Christianity is \"right\", whatever that even means. Provide just a tiny shred of evidence, and Dennet, along with the rest of us, will reconsider the position. reply CornCobs 9 hours agoprev> They will eventually discover that they’re wrong, and we will have yet further examples of evolution’s devious paths. In my terminology, their dogged search for skyhooks will uncover heretofore unimagined cranes. And precisely because their conclusions will be the opposite of what they hoped to discover, we will take them seriously. An important part of being able to truly ask oneself if they are wrong is the humility to seriously consider an alternative. The author's treating of ID research as a foregone conclusion, even with his acknowledgment that we could be wrong in the next paragraph, seems rather ironic. Isn't it this kind of hubris that he is precisely calling out? reply jibalt 46 minutes agoparent\"An important part of being able to truly ask oneself if they are wrong is the humility to seriously consider an alternative.\" Which he did, at length. \"The author's treating of ID research as a foregone conclusion\" No, it's a consequence of massive amounts of evidence, not just of evolution, but of the character of the sort of people who work at the Discovery Institute. reply Blahah 8 hours agoparentprevNo it isn't. Because there is precisely no evidence for, or coherent argue in favour of, ID. If you imagine ID is an alternative to evolution then that is to misunderstand the concept of evolution which is, at least in its fundamental form, inherently true. It's mathematically true. It has demonstrably happened and is demonstrably happening. ID is purely conjecture that is only contradicted by evidence. I do think Dennett is being rather sneering in his inclusion of ID in the essay at all. But he's not wrong that good work can be funded, and genuinely useful, and appreciated without malice, for misguided reasons. reply ketzo 8 hours agoparentprevI think he’s simultaneously acknowledging the wild unlikelihood of creationism, while also poking a little fun at himself with the irony of “of course I’m not wrong about this.” reply ChrisMarshallNY 8 hours agoprevI live by a life philosophy that tells me to own my defects and shortcomings, and promptly admit them. I remember being told once, \"Congratulations! It's your fault!\". The thinking is that, if it's some[one|thing] else's fault, there's nothing I can do to change it, but if it's my fault, then I have the power to amend the situation. In every conflict in my life; even when I am clearly in the right, and the other party is clearly in the wrong, I always have something to address, on my end. Sometimes, I may even need to apologize for it; which can really suck. In my coding, I have found that writing unit tests always finds bugs. Happened to me yesterday, in fact. Since the test ran through 35,000 records, and took almost an hour, it was painful. I can't remember the last time that I wrote unit tests that didn't find bugs in the CuT. But I am now satisfied that the code I wrote is top-shelf. reply jibalt 48 minutes agoparentHaving spent months trying to track down bugs that turned out to be due to occasional timing errors in esoteric mechanical devices, it is indeed a relief when I discover that a bug is due to something I did wrong and am able to fix. reply DiscourseFan 7 hours agoprevSo, everyone in the world knows what a circle is, or has a basic idea of a circle: you won't find a person who doesn't recognize one, right? But, there are no circles in the world, empirically--every circle you've ever thought you've seen is actually an ellipse, even the earth itself is oblong, just like all the stars and planetary bodies. Well, would we call it a mistake if someone described what, empirically, was an ellipse, as a circle? The question itself \"What if I'm wrong?\" is flawed: we are always already wrong. But it is the wrongness which makes the world, for us; and to the extent our creations are false, to that same extent they are true. So why concern yourself with questions of true or false, right or wrong, Good and Evil? Go out, create your own truth, make the world anew...leave behind all this worrying over nothing. reply selecsosi 3 hours agoparentI would argue we utilize symmetry of rotation and balance along with holding a blade at a fixed point (laythe) or rolling hot metal between two bodies (ball bearings), the avantage / creation of that was one of the crucial advances of humanity (being able to make actual circles / cylinders / spheres, since most objects you mentioned are also 3d) What makes the circle unique (or a copy / scaling of the unit circle) is that it exists defined by a relationship that is true on the euclidean plane, something itself which is ideal, and only exists in our imaginations. With mater being quantized at some level, we are always approximating, and for my car's sake, things rolling at several thousand rpms, we have some pretty circular things. reply Jensson 7 hours agoparentprev> But, there are no circles in the world, empirically Only if you have an overly strict definition of circle. I don't think it is wrong to call the outline of a ball a circle, or the shape you do if you take an Y shaped object and rotate it along one of those branches, it isn't a perfect circle but it is still a circle. reply mtlmtlmtlmtl 7 hours agorootparentAnd crucially, lots of things like the ones you mentioned are often not better approximated by an ellipse than a circle(I realise circles are just a subset of ellipses). reply DiscourseFan 6 hours agorootparent>I realise circles are just a subset of ellipses Ah, but in a circle the circumference is always equidistant to the centre, which is never true of an ellipse. I suppose there is only one circle in the world. reply jibalt 39 minutes agorootparent> Ah, but in a circle the circumference is always equidistant to the centre, which is never true of an ellipse. It's never true of an ellipse that isn't a circle. i.e., this is a--ahem--circular argument. reply DiscourseFan 6 hours agorootparentprevThere is only one definition of a circle, and its universal. Anything else is not a circle. reply jibalt 38 minutes agorootparentThere is not only one definition of a circle. There are many definitions, all of which are consistent with each other. reply neilv 8 hours agoprev> This inspired me to adopt the same strategy with my books: I invite Tufts students to help me write my books by sharing the penultimate draft with them in a seminar, where they are all encouraged to point out errors, challenge arguments, demand more clarity, and in general complain about anything that strikes them as amiss. Two professors from whom I was fortunate to learn, who did something like this in classes: * Marvin Minsky (MIT) -- While he was researching The Emotion Machine, class sessions would often be him talking about whatever he'd been working on earlier that day, and related thoughts from his formidable knowledge, and people would ask questions and share information. For example, one day, general anesthesia came up, and a physician/surgeon who was sitting in on class that day added to that (something about, in some cases, the patient is conscious but doesn't remember after, which was a memorable idea to hear). * Peter Wegner (Brown U.) -- He was working on theory of interactive models of computation (e.g., whether interacting objects were reducible to Turing Machines), and some days would put up drafts of a paper on a projector, for class discussion around them. IIRC, he'd first read sections of the paper, and then ask questions of the class around that. Of course, we learned more than he did, but perhaps we were also a helpful rubber duck on some ideas he was thinking through. Also, drafts of textbooks are a thing: Leslie Kaelbling (then Brown U.) arranged to use draft copies of Norvig & Russell's intro AI book, which were two comb-bound volumes with unfinished bits, and IIRC we could feed back comments. Which reminds me of the time I was taking classes at the community college, and the author of one of the textbooks was in the department (though not my instructor), so I wrote down some comments as I worked though the book. The author seemed kind and delighted to be getting book feedback from a student, even though I assume now that my comments weren't of any help. reply SamBam 7 hours agoparentWhile I probably would be happy to be in Daniel Dennett's class and engage seriously with his unfinished manuscript, I actually had a philosophy (of mind, as well) professor like this in my own university, and it was a lot less fun. Probably because this professor was no Daniel Dennett, and so his ideas were really just rehashings of other people's ideas – a primer, really, on work on consciousness. I just felt like we were being kind of used as free editors, rather than peers to engage with the intellectual ideas. reply felipefar 8 hours agoparentprevThere are even more ways to benefit your work from other more mundane activities. It helps a lot to find a day job where you can learn a skill that will help on one independent project you will tackle. It's a great idea as well to test ideas and arguments when having a casual conversation with someone: it both deepens the conversation and you have a better feel about how your opinion will be received. reply nonrandomstring 10 hours agoprevDid anyone else read \"Minds I\"? I loved that book, and come to think of it the 'soul searching' comments always had that note of humble fallibilism in there. reply lIl-IIIl 9 hours agoparentYes, it was one of my favorite books when I was young. I picked it up after reading GEB, of which there was discussion here recently. reply codeulike 10 hours agoprev\"I've Been Thinking\" is the best possible name for a philosopher's autobiography reply jibalt 52 minutes agoparentEspecially for this philosopher, whose life work has been in Theory of Mind, delving into what thinking is, how it happens, and how it works. reply layer8 9 hours agoparentprevDescartes would like it. reply wavemode 10 hours agoprev> Take courage and set out to write up the Great Discovery; if after many hours of red- hot thinking and writing you discover to your dismay a fatal flaw ... all is not lost. Go back to the first paragraph and write something along the lines of “It is tempting to think that ...” I love this. I go through similar experiences with software engineering. I notice some area of the field that appears overly complicated (build systems, CI/CD, version control, web frameworks, so on and so on) and start thinking to myself \"Why all the complexity? Surely we could just-\" and then I'm down a rabbit hole for weeks. The usual end result being I learn a lot of new things and discover for myself what all the complexity was for. But hey, occasionally maybe I really do come up with a Next Big Thing. reply svat 10 hours agoprevWhat is his life's work / major insight that he's referring to here? > I had found— and partly invented— a prodigious explanation- device that reliably devoured difficulties, day after day. The insights (if that is what they were) that I had struggled so hard to capture in my dissertation and my first book have matured and multiplied, generating answers to questions, solutions to problems, rebuttals to objections, and— most important— suggestions for further questions to ask with gratifying consilience. I just turn the crank and out they pour, falling into place like the last pieces in a jigsaw puzzle. Perhaps my whole perspective is a colossal mistake— some of my critics think so— and perhaps its abundant fruits are chimeras. reply jibalt 56 minutes agoparentYou can find numerous discussions of his dissertation and first book on line. reply tempaway11751f 10 hours agoparentprevhttps://en.wikipedia.org/wiki/Multiple_drafts_model reply JonChesterfield 10 hours agoparentprevPlausibly that described in the previous paragraph under distributed understanding, where he takes the consensus of some nominally informed group to be truth. See \"Reddit as reality\" for the failure mode of that strategy. reply jibalt 54 minutes agorootparentHave you considered the possibility that you're wrong? Because that's definitely not it. Consider that, as you acknowledged, you don't even know who he is, so you certainly aren't familiar with his work. reply svat 8 hours agorootparentprevI don't think so -- as he tells it, the \"distributed understanding\" is a shortcut he's using in his later life (if something is important someone will tell/explain it to him), which he contrasts with the diligence/conscientiousness he had earlier. The distributed understanding is a working style, orthogonal to the insight/program he's talking about. reply jrlocke 10 hours agoparentprevI think, broadly, it's that a theory of mind should be informed by empirical evidence, by scientific research, and that liberal doses of the those will dissolve away many of the classic problems in philosophy of mind. reply a_square_peg 7 hours agoprevI never got to ask this as an interview question, but I always thought it would be interesting to ask - 'if you were wrong, would you want to know?' Not on any particular topic but in general. When I asked this in casual settings, I thought it was illuminating that no one gave a simple 'yes' as an answer. reply calf 3 hours agoparentThat's so alien to me, because my answer to your question is an enthusiastic \"Yes!!\". On further thought, I think the only humane objection is whether truth can ever really be separated from judgment. People don't like being judged and especially not judged unfairly, and true propositions can nevertheless connote judgment by contextual salience of the particular thing we tell someone that they're wrong about and why they're wrong, etc. reply briHass 5 hours agoparentprevI would definitely think this would be very topic-dependent. Perhaps the flip side to this is to consider when (if ever) lies or mistruths are allowable. After all, a lie, believed sincerely, makes the believer 'wrong' about something. I can certainly think of things told to me by people I care about, that if they turned out to be lies, I wouldn't gain any utility or value from their revelation. reply EVa5I7bHFq9mnYK 7 hours agoprevIdiots never ask themselves that question, that's why they usually win the argument. reply FrustratedMonky 10 hours agoprevI actually got a little suckered in, and thought this might be Dennett opening up to being wrong and giving some new account of what he might now think is correct. Especially after all the debates on free will with Sapolsky. Instead it ended up being backhanded self complement, more like, \"a lot of other great people agree with me, so maybe I'm wrong, but probably not\". \"Descartes’s theory of everything is, even in hindsight, remarkably coherent and persuasive. It is hard to imagine a different equally coherent and equally false theory! He was wrong, and so of course I may well be wrong, but enough other thinkers I respect have come to see things my way that when I ask myself, “What if we are wrong?” I can keep this skeptical murmur safely simmering on a back burner.\" reply PaulDavisThe1st 10 hours agoparentI had an interesting email exchange with Dennett in the 90s. He had just brought out his book \"Consciousness Explained\". I read it and emailed him a short note saying that I thought the book was mistitled - the contents were an explanation of what we were conscious of not how we could be conscious. I expected him to write back with some eloquent or witty or pithy defense of the link between the title and the contents, but he just thanked me and said, \"yes, now that you put it that way, it probably is the wrong title. Oops, too late.\" reply jibalt 59 minutes agorootparentDan was toying with you ... his thesis was on the distinction between consciousness and the contents of consciousness, and he more than anyone was familiar with the point you were making (erroneously). reply nonameiguess 10 hours agorootparentprevThis probably means I'm a bit younger than you, but I also had some e-mail conversations with Dennett about the same book, I think in 2001 or so. I always found him gracious and patient and he is still the only public intellectual I have ever carried on a meaningful conversation with and gained insight from in this way, and I was just a random college student, not even his student. reply bbor 10 hours agorootparentprevThe beauty and flexibility of radical skepticism :). Minsky, another noted skeptic of idealist claims (from the opposite angle?), had a quote that stuck with me from one of his YouTube lectures on Society of Mind. I can’t find it at the moment but it was along the lines of; “when you write your own cognitive theory, leave room in the edges for it to grow. You never know what parts will be proven wrong, and you shouldn’t let that stifle the overall exercise.” In other words, any attempt to break down the mind into component parts is better than declaring it a lost cause and hypothesizing your favorite alternative instead (god, soul, one-ness, consciousness as an essential property, etc). reply jibalt 1 hour agoparentprevHave you considered the possibility that you're wrong? Because I for one think you're seriously misreading and mischaracterizing his piece, and failing to extract from it some valuable advice. reply bbor 10 hours agoparentprevYeah but he’s engaging seriously with self-doubt. Which I think is admirable. I also find his “explaining away” of the rest of the field tiresome, but I don’t think calling it self-complimentary is necessarily fair. After all, this is a retrospective/polemic, not a revelation of some new discovery reply FrustratedMonky 8 hours agorootparentYeah, he is a huge figure in the field. It's just from the title, I thought there was going to be some 'inciteful about face', like he had some new 'other way to think about things' that just couldn't wait for the next book. So had hopes up more. reply bbor 4 hours agorootparentHe is very good at faking out his detractors with his choice of titles, apparently! It’s something of a pattern at this point… reply tsunamifury 9 hours agoprevI applaud the author and thinker for taking on this timely and hard topic. I struggle with this question in the same way I think as the author, but in technology we are afforded less time to ponder if we are wrong and more time to test if we are wrong. However the author points out, even in testing as he does with his students, we can be wrong in a fundamental way that all the branches of my iterations stem from the wrong source. So I’m left with: who thinks I’m wrong and why does that matter. I’m finding that outside of reddit, very very few people will tell me im wrong and this is deeply frustrating. Really only my wife who is tired of my pondering fully engages in what might be wrong with what I’m working on and I’m thankful for that. But I wish more people would help me be “constructively wrong” which means they understand the goal but want to correct the approach. Most online merely want to point out irrelevant wrongness for sport. reply randomdata 5 hours agoparent> I wish more people would help me be “constructively wrong” What's the value proposition? As you noted, not even your own wife will help you until she sees some kind of return for herself (abating her tiredness). Online actors pointing out irrelevant wrongness get to laugh at the meltdown of the maladjusted \"intellectual\" that usually follows. This is what consultancy is for. You pay someone to look at what you are doing and tell you where you are going wrong. The pay offers the incentive. Most people are quite happy to offer consultant services for pay. But presumably you are having this wish because you want it for free? reply tsunamifury 2 hours agorootparentI get your point, but to be genuine with you I have paid. Very very few people you are paying with genuinely critique or disagree with you for very obvious reasons. However I can’t help but point out that you’re being exactly as I’ve described redditors…argue an adjacent point to just say the original point is ‘stupid’. It’s a waste of good brain cells. reply thomastjeffery 9 hours agoprevThe most useful reason to know things is not so that you can stand idly correct: it is so that the next \"maybe\" you invent can be unique. reply JonChesterfield 10 hours agoprev [–] > if this novelty is worth understanding, somebody I trust will soon explain it to me in terms I can readily digest That's unsound. It prevents learning anything which is not widely known and simply explained. I don't know the author. All the context I have is the article up to that point where I lost interest. However yes, if all you try to learn are the trivial things everyone agrees on, for some circular definition of \"wrong\", you won't be wrong. Bad strategy. High value are things few people know. Highest value are things people know to be true that are not so. reply a_wild_dandan 6 hours agoparentYou've mistaken a heuristic for a formal argument, making your disinterest is a self-inflicted wound. Everyone uses heuristics to manage their precious, finite time. Sifting through ideas via academic prescreening and the clarity of their expression are excellent heuristics -- especially for a famous philosopher. reply jibalt 1 hour agoparentprevHave you considered the possibility that you're wrong? Dan Dennett is one of the world's most renowned thinkers, and you would do well to take the broader lesson of his article to heart. Also look into Dunning and Kruger. reply layer8 9 hours agoparentprevNo, it means no single person needs to be a giant on which shoulders we stand. Instead we can form a pyramid of arbitrarily small dwarfs. reply pixl97 10 hours agoparentprev [–] What value is something that only you know? The moment you act on these hidden bits of information you start leaking entropy that points back to the knowledge you keep. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Philosopher Daniel C. Dennett believes in seeking input from others to understand complex concepts, relying on trusted colleagues to explain difficult articles or books.",
      "He involves students in the editing process of his books, appreciating their critical feedback and encouraging risk-taking in research and writing.",
      "Dennett highlights the benefits of exploring alternative viewpoints, using the example of the Discovery Institute's research facility to disprove evolution. He emphasizes the importance of humility, questioning one's beliefs, and collaboration in intellectual pursuits."
    ],
    "commentSummary": [
      "The conversation covers a diverse range of topics such as argument by analogy, the role of formal logic and emotions in shaping worldviews, and the challenges of changing opinions.",
      "It also explores the lack of factual information in public discussions, the use of weasel words and anonymous sources, and the concept of \"best practice\" in problem-solving.",
      "The participants discuss the meaning of \"not even wrong,\" the difficulty in understanding different belief systems, and even touch on the existence of God. The conversation emphasizes the intricacies and complexity of these subjects."
    ],
    "points": 190,
    "commentCount": 162,
    "retryCount": 0,
    "time": 1707775600
  },
  {
    "id": 39349366,
    "title": "US Rail Safety Legislation Stalled a Year After East Palestine Ohio Disaster",
    "originLink": "https://www.wlbt.com/2024/02/02/rail-safety-legislation-still-stalled-one-year-after-east-palestine-disaster/",
    "originBody": "Skip to content Promote Your Business Careers News Watch Live 3 On Your Side Investigates First Alert Weather Traffic Jackson Water Studio 3 Elections Sports What's On TV About Us Home Watch Live WLBT Apps Submit Your Pics First Alert Weather Get a Weather Radio SkyCams Closings Request a First Alert Weather School Visit News Hinds County Madison County Rankin County Education Crime 3 On Your Side Investigates Mississippi Strong National Crime Metro Crime Jackson Homicides Jackson Crime Mississippi Crime Traffic Gas Prices Studio 3 Adopt a Pet Birthday Club Cowboy’s Kitchen Healthier Mississippi Luxury Living Made in Mississippi Mississippi History Mississippi Strong Mississippi Weekend Shop Local Taste Mississippi Thank You For Your Service Sports Mississippi State Ole Miss Southern Miss Jackson State SWAC Saints The End Zone HS Football Scores Stats & Predictions How to Watch Health Power of Pink Community Mississippi Strong About Us Careers Contact Us Meet the Team Programming LawCall Programming Schedule Gray DC Bureau Circle Country Zeam - News Streams InvestigateTV PowerNation Promote Your Business 8 weather alerts in effect Dismiss Weather Alerts Alerts Bar Rail safety legislation still stalled one year after East Palestine disaster Members of Congress blast industry for putting profits over safety A major train derailment in East Palestine, Ohio spurred calls for changes in railroad safety. By Joce Sterman Published: Feb. 2, 2024 at 4:41 PM UTC (InvestigateTV) — It’s been one year since a train derailment in Ohio thrust the issue of rail safety back into the national spotlight. Congressional lawmakers immediately introduced legislation designed to protect Americans and hold rail companies accountable. But the longest-serving woman in Congressional history says little has changed since the disaster. U.S. Representative Marcy Kaptur, D-Ohio, talked with InvestigateTV on Capitol Hill in advance of the February 3rd anniversary of the crisis in East Palestine, saying of the rail industry, “It’s like they’re a power unto themselves. And they’re very, very - in my opinion - destructive to the country in the way they’re behaving.” Kaptur, who’s held Congressional office since 1983, pulled no punches as she talked about the ripple effects of the massive incident that forced the evacuation of more than 1,000 people last February. The evacuation came after a Norfolk Southern train carrying hazardous materials derailed in eastern Ohio near the Pennsylvania border, with toxic chemicals contaminating the air, water, and soil all around the area. A photo from the NTSB investigative file shows the aftermath of a massive 2023 train derailment in East Palestine, Ohio(NTSB) Within weeks congressional lawmakers proposed bipartisan bills in the Senate and House designed to improve rail safety. Those bills included language mandating two-person crews for certain freight trains, updating inspection regulations and bumping up fines for companies that break safety laws. The Senate version of the legislation initially made progress, moving through committee with provisions added. But one year after East Palestine, both bills are at a standstill, with no changes made since May. Asked why the proposed legislation hasn’t moved forward, Kaptur blamed the rail industry. “I think because they have a whole lot of power,” Kaptur said. “They have a lot of political power. And in the committees that are responsible, they do enough to block it.” Congresswoman Marcy Kaptur, D-Ohio, talks about rail safety in her office on Capitol Hill(Scotty Smith, InvestigateTV) That sentiment, was echoed by U.S. Senator Sherrod Brown, D-Ohio, who sponsored the Rail Safety Act in the Senate and held a virtual press conference this week to talk about the stalled legislation. Both Brown and Kaptur said lobbying groups and major rail companies continue to oppose the legislation, with the industry putting profits over public safety. The Association of American Railroads, the lobbying group representing the nation’s major rail companies, told InvestigateTV in a written statement, “Railroads and policymakers share the same goal of making the rail network even safer. The industry is dedicated to advancing safety through our own initiatives and in collaboration with policymakers. Despite some allegations, railroads have never been opposed to the Railway Safety Act (RSA) and have had open, productive conversations with policymakers including Rep. Kaptur’s staff.” Although the railroad lobby has repeatedly been unavailable for on-camera interviews with InvestigateTV, the organization has been clear in materials on its website that it sees challenges in the legislation, specifically with the proposed crew staffing mandates and inspection requirements. “They don’t think that they need anybody but themselves,” Kaptur said. “And look at the country. They’re not meeting the mark.” Other major rail issues also remain unsolved despite national attention Congresswoman Kaptur said the industry is also failing when it comes to fixing another major rail problem brought into sharp focus last year: blocked crossings. The issue, highlighted in an InvestigateTV/ProPublica series, found stopped trains delaying first responders, cutting off communities and forcing children in Hammond, Indiana to do the unthinkable: crawl over and under trains just to get to school. An InvestigateTV/ProPublica investigation into blocked crossings affects changes. Video captured in Hammond, Indiana sheds light on a larger issue in the U.S. Last May the congresswoman officially logged the series into the Congressional Record, saying “Railroads of America, wake up.” “I was trying to get it out to other Americans so that they can speak up from their parts of the country,” Kaptur said. “All of these places have had accidents. Frankly, I’ve had deaths in my district and the behavior of the companies is that you may as well make them kings.” During the interview, and in Kaptur’s time on the House floor, the congresswoman urged President Biden and Transportation Secretary Pete Buttigieg to get rail stakeholders together to work to fix systematic rail problems that exist from coast to coast, saying the billions allocated in infrastructure funding provide a pivotal moment for action. “We need visionary planning. They don’t give it to us. I would like those CEOs - I’ll invite them, I’ll buy pizza, we’ll spend the whole weekend - let them roll up their sleeves. I want to see how good they are. They shouldn’t feel so good about the legacy they’re leaving to their children and grandchildren because it’s non-functional. It’s not going to be able to meet the needs of the country going forward. Shame on them,” she said. The Association of American Railroads said in a press release it has and will continue to “engage in conversations about how legislation can improve safety, encourage innovation and keep the supply chain moving”. The organization also pointed to a number of steps it says the rail industry has independently taken to improve safety in the wake of the East Palestine disaster, including training thousands of first responders in communities across the country and doubling the number of people who can access a specialized system that gives real-time information about what rail cars are carrying. Copyright 2024 Gray Media Group, Inc. All rights reserved. Most Read Students call on JSU to prioritize safety after man is seen with automatic rifle near campus Horses killed and riders injured after crash in Copiah County Honor society advisor at Mississippi community college arrested for embezzlement Sonic Boom of the South performs during Super Bowl 31 people arrested after year-long investigation in Mississippi News Watch Live First Alert Weather Sports Programming Careers About Us Send In News Tips WLBT 715 South Jefferson Street Jackson, MS 39201 (601)948-3333 Public Inspection File PUBLICFILE@WLBT.COM - 601-960-4436 Closed Captioning/Audio Description Terms of Service Privacy Policy EEO Report FCC Applications Advertising Non-Discrimination Certification Promote Your Business At Gray, our journalists report, write, edit and produce the news content that informs the communities we serve. Click here to learn more about our approach to artificial intelligence. A Gray Media Group, Inc. Station - © 2002-2024 Gray Television, Inc. advertisement advertisement advertisement",
    "commentLink": "https://news.ycombinator.com/item?id=39349366",
    "commentBody": "US rail safety legislation stalled one year after East Palestine Ohio disaster (wlbt.com)169 points by PaulHoule 14 hours agohidepastfavorite97 comments legitster 13 hours agoTrain derailments are already on a long downward trend since they peaked in 1978: https://data.transportation.gov/dataset/Railroad-Equipment-A... This legislation was kind of a hot-blooded fast-twitch response to the East Palestine disaster, but it's not exactly clear that it would have done anything other than address some of the superficial concerns at the time. Since then the DOT has already updated several of their derailment policies, the EPA has updated their procedure for burning off hazardous chemicals. reply zamadatix 13 hours agoparentAnother user responded here asking if this was the result of increased regulation considered burdensome at the time it was introduced and then deleted the question, presumably after reading more about it. The question itself is interesting though: the period after the 1970s saw substantially decreased regulation for railways in general and a loosening in how security regulation was approached for a massive decline in railroad safety issues. I.e. the market was heavily over-regulated at the time and prescriptive regulation had been having the opposite of the intended effect. I'm highlighting this not as one who despises regulation, quite the opposite, but just because it's a good point to highlight reacting to every accident with more regulation is not the right way to approach further regulation. https://railroads.dot.gov/sites/fra.dot.gov/files/fra_net/16... reply flavius29663 12 hours agorootparentIt can make sense. I come from a country(Romania) where fire regulations are insanely strict and complicated. If the fire department comes to inspect, they will 100% find issues and fine you. The result is that the most sane and basic requirements get drowned in a sea of useless regulations, so you end up with escape doors that are locked, missing alerting systems, flammable materials where there shouldn't be etc. reply ToucanLoucan 12 hours agorootparentI need a more detailed explanation of what you're suggesting here: I get that having too many regulations can create a situation where an inspector will always find fault, that makes sense: but unless inspectors have a cap on the number of issues they're allowed to report, which doesn't seem sane under any circumstance, why would that then cause more obvious basic regulations to be unenforced? If anything I would expect the opposite. reply flavius29663 8 hours agorootparentThere are 2 things that happen: you bribe the firefighters(rarer), OR you just continue functioning without their signoff(more common). Because most businesses were not compliant all of the sudden, the government couldn't just shut down everything, so they allow businesses and buildings to function without authorization, simply by filling in an affidavit saying you acknowledge firefighters didn't approve and you continue at your own risk. Even the capitol building, where the MPs \"work\" everyday, is without proper authorization! When you go to a nightclub, you don't know if they have an actual permit from the firefighters, or a mere affidavit...and you end up with disasters like https://en.m.wikipedia.org/wiki/Colectiv_nightclub_fire This whole situation made everyone very complacent with fire safety, to the point it's worse than if people and businesses would have been left alone. reply gbear605 11 hours agorootparentprevI can’t speak for Romania, but if the outcome of any mistake is that you get shutdown, there’s an implicit cap on how much you can get punished. reply woodruffw 12 hours agoparentprevSome confounding factors on derailment statistics: * Individual trains are longer than ever, which means that they carry more than ever. That means bigger derailments in absolute terms with a larger potential variety of components, even if the overall magnitude of derailments has decreased. * Deferred line maintenance and other cost-cutting measures (like running longer trains with just one or two engineers) means more severe derailments (more cars off the rails, more extensive damage, fewer people available to detect or remediate problems). reply Geezus_42 9 hours agorootparentSounds like you might be interested, or already a fan. https://news.ycombinator.com/item?id=39352570 reply rgbrenner 12 hours agoprevSaying \"Congress\" isn't advancing it, lets the people responsible avoid blame. While the bills have bipartisan sponsors, only democrats are willing to vote for the bill on the house/senate floor. In the senate, republicans are threatening to filibuster the bill, so it cant pass without a supermajority. And the gop-led house refuses to bring the house bill to the floor. 2023 was the least productive Congress since the Great Depression. Passing a total of 23 bills last year. https://www.axios.com/2023/12/19/118-congress-bills-least-un... reply legitster 11 hours agoparentTo just rephrase your point a bit more clearly - there is not even a particular partisan reaction to the bill itself - one of the two parties our government needs to run is currently collapsing in on itself so nothing is getting done. reply deprecative 7 hours agorootparentTo rephrase your point a bit more accurately. One of the parties is the party of no. The other is the party of \"idk, what do you guys think?\" reply hayst4ck 7 hours agorootparent> One of the parties is the party of no. Not at all. The republican party realized that if they want to push unpopular policy they cannot do it via democratic means. So they made the very strategic decision (and strategically correct, since there have been no consequences for republicans worth mentioning), to gridlock the government and prove that it doesn't work, which directly gives them credibility. They have packed the courts with ideologues from the heritage foundation and then gridlocked the body that does oversight. So in good years they build their power foundation, and in bad years they work on both weakening their opponents power and harming their credibility and exercising the power they built in their good years. That is very very far from being a \"party of no\". The part of \"no compromises\" maybe. They are winning. Choosing to defect in a game of prisoners dilemma is rational if you don't think your opponent will defect too or if the cost of their defection is too low. \"Speak softly, but carry a big stick\" means in the game of prisoners dilemma, cooperate, but be able to punish defection. Democrats don't punish defection. Democrats don't have a big stick. Democrats are just speaking softly. If you want cooperation, you must have the ability to meaningfully defect. reply BitwiseFool 12 hours agoparentprevIs there some poison pill in the bill? It's a really common tactic for the party in power to put wishlist items in the \"Good things for America Act\" that they know the opposition cannot support in order to get fodder for making the other side look so unreasonable. reply supertimor 8 hours agorootparentNah, it’s just an election year. The republicans have been stonewalling everything so they can claim the democrats aren’t getting anything done. They even killed the bipartisan border deal, which they have been asking for for awhile and which initially had Republican support but when their likely nominee told them to drop it, they did. reply hayst4ck 7 hours agoparentprevIn a \"me vs you\" situation in the context of the relationship, whoever cares about the relationship the least has the most power. The republican party sees power as the most important goal and are willing to sacrifice the union to get it (US Generals including Milley and Mattis have nearly directly said this and did directly say this in the context of the republican party's king). Democrats on the other hand are like a desperate ex in denial that the relationship has already ended. Both parties are at fault. Being a victim does not disavow a responsibility to seek a better outcome. Blame is the opposite of responsibility and democrats are not taking responsibility. Instead, they are blaming republicans, voters, or the law. None of those things are stopping republicans from exerting increasingly more power. Republicans (republican leaders anyway) don't complain about lack of voter support. They create Fox News to manufacture support, or directly attempt a coup. Republcian's don't complain about malfunctioning courts, they load them with ideologues. Republicans don't complain about lack of voters, they gerrymander districts and concoct schemes to make it harder for voters they don't like to vote. They don't complain about a gridlocked congress, they push policy with the courts instead. Republicans are taking responsibility to achieve the outcomes they want. Democrats are busy jerking themselves with useless result-less blame. So you can blame republicans if you want, but as a fellow liberal leaning person, you should definitely realize that democrats benefit greatly by not having to step up. They don't want to hold corporations feet to the fire any more than republicans do. They can say they do, but franky I do not believe that democrats want to hold corporations to account any more than republicans do. There are a few progressives like AOC and Bernie who do, but the party as a whole is part of the problem, and I think they are a co-equal part. Nancy Pelosi got in front of a camera and said \"I have a right to participate in the free market.\" That's the closest thing to a leader for the democratic party saying they have a right to conflicts of interest. The most powerful democrat during the previous presidency said they have a right to be corrupt. Democrats can say they want to stop congresspersons from trading stock, but they can only say that for the same reason that a couple of republicans are allowed to vote outside of party lines when there are already enough votes. This is just another example of the same behavior. reply kevincrane 7 hours agorootparentI’ve read through this twice and I can’t figure what you’re trying to both-sides here. reply hayst4ck 5 hours agorootparentLets say we're playing prisoners dilemma. You know I will initially attempt to cooperate. You know that if you defect, I will still try to cooperate. What is your most rational strategy? Your most rational strategy is very obviously to defect. My strategy of cooperation, and your knowledge of my strategy made defecting the rational choice for you. So who is to blame? You for rationally choosing your own self interest? Or me for failing to come up with a strategy that leads to better outcomes? Republicans packed the courts while Democrats were complaining about republican obstructionism under Obama. You can blame republicans all you want, but democrats need to take responsibility. So what I am saying is both sides are responsible. reply Drunk_Engineer 13 hours agoprevThis \"safety\" legislation is mainly about requiring 2-man crews on trains. The unions are of course very much in favor, but it would do nothing to prevent derailments like what happened at E. Palestine. reply bluGill 13 hours agoparentThe problem should be solved with maintenance and automation. But that would hurt the union (though there would be more opportunity in maintenance. reply AnthonyMouse 12 hours agorootparentThe biggest problem unions have seems to be that they've never heard of the Jevons paradox. They try to \"create jobs\" at the expense of efficiency on the theory they'll get more work, causing everything they do to become prohibitively expensive and then it gets cut or offshored. reply kyrra 13 hours agoparentprevAs a reminder for those that don't follow this in detail: One of the main pushes of this bill would be requiring at least 2 people on all freight trains to \"help improve safety\". Can you guess how many engineers there were on the East Palastine train? 3. That obvious had no impact on this incident. As others have pointed out, more engineers are a security/safety theaters solution. It also makes unions happy, as it means they need to employ more people. This is a terrible bill that was reactionary at the time, and does nothing to actually improve safety. https://www.wsj.com/articles/railroad-crew-size-mandate-dera... reply zthrowaway 12 hours agorootparentOver the past decade the Class 1's have been working towards doing 1 man crew's. But they're still 2 man at minimum. This bill achieves nothing. This is a \"hey we did something about it! (please don't read what's in the bill and catch us bullshitting).\" What they should be doing is looking at the absurd increase in length of these trains to increase profits for the sake of safety, and the shortcutting of car maintenance. The latter which would've caught this issue to begin with. reply kiba 13 hours agoprevWe need investments in rail infrastructure to take trucks off the road and to improve safety and to keep goods moving. For some reason, our railroad are privately owned rather than owned by the states or the fed. reply JumpCrisscross 13 hours agoparent> For some reason, our railroad are privately owned rather than owned by the states or the fed Who do you think built them? We have the world’s largest rail network for a reason. reply jacoblambda 13 hours agorootparent> Who do you think built them? We have the world’s largest rail network for a reason. I don't know if shear size is a great way to evaluate what method of rail ownership is superior. The US is literally the third largest country on earth so it makes sense that we have a lot of \"largests\" when it comes to infrastructure networks. What probably would make more sense would be a rail density metric instead. Something like km of rail per sq km of land would work (but has it's own flaws). But that metric then shows a number of other countries that clearly beat the US despite having nationalised or hybrid rail networks. A good example would be Japan which has roughly triple as much rail relative to the size of their country and I doubt many people would argue that Japan's rail network is less effective than the US rail network. reply briankelly 13 hours agorootparentIn the US, rail is used for freight, while in Japan it’s used for passengers. Both are successful in their own ways but Japan’s rail network is much more visible. reply jacoblambda 12 hours agorootparentOh for sure but that's a very different discussion than just \"largest rail network\" as a qualifier for success. If we want to talk freight utilisation, Japanese freight rail usage is low because of the country's geography/generally easy access to water/maritime shipping (since shipping by water is always more cost/energy effective per tonne relative to rail). So a comparable example in that case would be China who has similar geography, a similar sized country, and a rail network roughly 70% the size of the US rail network (#2 largest network). However China moves nearly 3x more raw mass per year relative to the US and 50% more tonne kilometers per year relative to the US. Point being that US freight rail is massive because it geographically and economically makes sense for it to be so. Similar networks exist in other countries that take nationalised or hybrid rail approaches yet those countries consistently outperform US rail in basically every metric but shear size. reply criddell 12 hours agorootparent> shipping by water is always more cost/energy effective per tonne relative to rail Is that true? I always thought it was the other way around. Rail has relatively low rolling resistance so I thought it would take a lot less energy to move the same weight by rail compared to water. reply quickthrowman 12 hours agorootparentTry this experiment: Attempt to push a boat while swimming in the water, then try to push the same boat while it is on a trailer on land. Which one is easier to move? reply criddell 12 hours agorootparentYeah, I can see that. At the same time, swimming speed isn’t very useful for anybody. What are the relative energy requirements to move ten thousand pounds at 30 mph in the water vs on rails? reply jacoblambda 12 hours agorootparenthttps://en.wikipedia.org/wiki/Energy_efficiency_in_transport... >transport modeFuel consumption>----------------------BTU per short ton-milekJ per tonne-kilometre>Domestic waterborne217160>Class 1 railroads289209>Heavy trucks3,3572,426>Air freight (approx.)9,6006,900In other words waterborne freight is generally around 25% cheaper energy wise and far easier/cheaper to scale capacity relative to rail. It's also worth looking at some of the other numbers on that page. German numbers work out ocean freight to be over 3x cheaper energywise per tkm relative to rail. reply zardo 4 hours agorootparentprev15 mph is more typical for a cargo ship than 30. reply quickthrowman 12 hours agorootparentprevRiver barges are more efficient than trains, see the two sources below as well as the sibling comment. > Per one gallon of fuel: > A truck can carry one ton of cargo just 59 miles. > By rail, one ton of cargo can travel 202 miles. > An inland barge can carry one ton of cargo 514 miles. https://www.portoflittlerock.com/2023/10/the-benefits-of-riv... > The study shows that barges can move a ton of cargo 647 miles with a single gallon of fuel, an increase from an earlier estimate of 616 miles. In contrast, trains can move the same ton of cargo 477 miles per gallon, and trucks can move the same ton of cargo 145 miles per gallon. > https://maritime-executive.com/article/barge-transport-wins-.... reply briankelly 12 hours agorootparentprevYeah I think China is a more fit comparison and highlights what the issue is in the US - very little central planning authority. People discuss the American “government” like it’s a monolith when it’s fiefdoms at all levels; it’s not surprising we can’t build anything anymore. reply kiba 11 hours agorootparentThe problem is not the lack of centralized authority, it's the vetocracy, gridlock, and political resistance to anything that's not car-based pattern of development. Notice that we managed to build an interstate system and lot of other infrastructure. reply jacoblambda 11 hours agorootparentWe only managed to build an interstate system via a massive, centralised effort by the federal government to plan out and fund construction of the interstate highway system. The yellow book (designed by the federal govt) maps extremely closely to what became the final interstate system. The states did the actual building and own the actual land but the federal govt told them where to build, gave them the money, and otherwise forced their hand into the construction. I'm not necessarily saying federal control over all infrastructure is a good thing but it really was in large part due to the federal government that the interstate system actually happened. reply briankelly 11 hours agorootparentprevI was referring to the problems you describe by that. All that infrastructure got built with PWA era pork barrel politics and many of the projects were highly illogical. The books The Power Broker and Cadillac Desert dissect these issues, the latter focusing on our hydrology infra which is as at least as, if not way more stupid than our roads. You’re right though that it’s not exactly about it being centralized. reply tremon 13 hours agorootparentprevWho do you think built them? Slaves? reply newsclues 13 hours agorootparentCapitalist. Exploitation and cheating sure, but the railroads are recent. reply skyyler 12 hours agorootparenthttps://railroads.unl.edu/topics/slavery.php The slaves were also recent. >Southern railroad companies began buying slaves as early as the 1840s and used enslaved labor almost exclusively to construction their lines. Thousands of African Americans worked on the southern railroads in the 1850s There is a temporal overlap between \"slave america\" and \"railroad america\". reply newsclues 11 hours agorootparentSlavery didn’t account for the majority of railroads built reply kevingadd 13 hours agorootparentprevWasn't much of the US rail network funded by a public-private partnership? Why should the rails be privately owned? Didn't the government provide a lot of the land, too? reply davidw 13 hours agorootparentThe checkerboard pattern you see in Oregon's forests from a satellite are because the government gave away a crapload of land to fund railroad development https://www.google.com/maps/@43.7155994,-122.829874,73748m/d... https://en.wikipedia.org/wiki/Oregon_and_California_Railroad... reply bugglebeetle 13 hours agorootparentprevAnd yet the Chinese rail network is infinitely more productive, smaller in size, transports millions of people around a comparably sized country, in addition to the inputs and outputs of its massive industrial base, and is largely a state construction. It would seem that extent of rail is not the measure of value here, nor is that correlated with private ownership, but instead we should assess the overall productive capacity of the infrastructure. reply volkl48 12 hours agorootparentUS freight rail moves roughly 40% of the cargo in the country, China's moves about 15% (and is in long stagnation/decline in terms of how much it moves). Roughly 80% of what moves within China does so by an endless sea of trucks. That's a pretty huge difference in terms of modal share. And even with the sprawling size of the US network (and differences in things like labor costs), US freight rail is still more efficient at moving cargo in terms of costs. reply bugglebeetle 11 hours agorootparent> That's a pretty huge difference in terms of modal share. Now do comparison of transporting people and that’s impact on the economy reply onepointsixC 13 hours agorootparentprevInfinitely more productive? That's a claim. China's rail has $900B in loans, and profits haven't covered servicing that debt for nearly a decade. reply jdlshore 13 hours agorootparentprevYou’re comparing a passenger rail system to a freight rail system. Totally different beasts. reply sitharus 13 hours agorootparentLets quickly check Wikipedia China: Total length: 155,000 km (100,000 km electrified) Total passenger/km: (1,470.66 billion passenger-kilometres, 2019) Total freight: 3,018 billion cargo tonne-kilometres (2019) US: Total length: 257,722 km (160,141 mi) (I can't find figures on electrified length, seems at most 2000km?) Total passenger/km: (10.3 billion, 2014) Total freight: 1.71 trillion short ton-mile, approx 963 billion tonne-kilometres (I used wolfram alpha for that conversion) So if my calculations are correct - which they may not be - on fewer rails China transports an order of magnitude more passenger and freight traffic. reply anonexpat 12 hours agorootparent94% of China's population lives in the 43% of the country closest to the ocean. https://en.wikipedia.org/wiki/Heihe%E2%80%93Tengchong_Line reply ses1984 12 hours agorootparentWhat percent of people in the US live in the 43% of the country closest to the ocean? reply AnimalMuppet 12 hours agorootparentprevYour conversion is wrong. 1 mile is about 1.6 kilometers; 1 short ton is about 0.9 tonnes. One short ton-mile will be about 1.5 tonne-kilometers. reply AnthonyMouse 12 hours agorootparentprevRail networks aren't capacity-limited by the number of miles of track and China has three times the population. But the premise is meaningless. It's easy for a government to affect the usage of something by subsidizing it or constraining alternatives to it, which has little to do with whether it would be more efficient or well-managed as a public agency. reply bugglebeetle 13 hours agorootparentprev…as the parent did when they asserted that the US has the largest rail network, which encompasses both, so no, not really “totally different beasts.” reply Almondsetat 13 hours agorootparentprevChinese rail network is a money sink reply njarboe 12 hours agoparentprevJapan's famously on-time and efficient rail system is made up of many privately owned systems. reply bobthepanda 12 hours agorootparentEfficient if you look at the big three JRs (Central, East, West). JR Shikoku, JR Hokkaido, and JR Freight are basket cases. reply switch007 12 hours agoparentprevIt’s tragic in the UK at the moment. The government has taken over some large rail operators and are busy reducing services and increasing costs. They’re making many other detrimental changes to the railway system too We can’t believe it but some of us enthusiasts are actually wanting privatisation back Public can be good. Private can be good. Public can be bad. Private can be bad… reply jMyles 13 hours agoparentprev> rather than owned by the states or the fed. Are those actually the only options for public goods focus though? I generally lean softly toward anarchic solutions, so of course my mind goes toward some kind of non-profit NGO or DAO rather than the same government structures that lead to war for oil, etc. > or the fed. Is there another example of a central bank owning a railroad? I don't doubt that it has happened historically, but this is the first time I've even thought of it as a possibility. reply pests 12 hours agorootparent> or DAO Oh, an entity like the original DAO that led to Ethereum selling out? \"The Contract is the Law\" until its not. Very anarchic. reply zht 13 hours agorootparentprevhe probably means the federal government lol reply oatmeal1 13 hours agoparentprev> For some reason, our railroad are privately owned rather than owned by the states or the fed. Because we want them to work well? Look at how the government handles the infrastructure it owns. reply eropple 13 hours agorootparentSo we're talking about transportation, and I guess I have to ask exactly what transportation infrastructure you then mean? Because the only serious, broad, federally-managed transportation infrastructure I can think of are like, military airbases. Which tend to be pretty good! That's assuming, of course, you mean the US government--which does not own things like highways, for those unclear; it does have a controlling stake in Amtrak, but aside from the NEC (which is great IMO) Amtrak does not own the railways that actually serve as rail infrastructure. Because, of course, country governments elsewhere regularly own or have majority stakes in both railroads and railways, to pretty good success. Or, on the other other hand, maybe you mean non-transporation infrastructure? 'Cause frankly, the US Postal Service was pretty great 'til \"the government doesn't work and we're going to prove it by ripping out big chunks of it\" politicians got their hands on it. reply oatmeal1 12 hours agorootparent> That's assuming, of course, you mean the US government--which does not own things like highways I was responding to a comment which said \"states or the fed,\" so of course I was referring to those both. The states own the highways. reply orwin 10 hours agorootparentprevAlso, the argument for \"companies are more efficient than government\" is that the free market will sink corrupt/inefficient organizations. I don't see how it applies to infrastructure management. I understand how it can apply to energy producers (overall disagree on that, i work for a big energy producer who have multiple plant of a lot of different types, and in the end the electricity market the EU copied from the US made us less efficient, i have math to prove it), to service providers, or even to train companies and railroad building companies. And i think that for non-critical infra construction it's even good. But managing infrastructure is hard, and put a company at the right place (between consummer and producers) to both put a toll on a service, and to be increasingly susceptible to corruption. reply oatmeal1 8 hours agorootparentThe government has invested grotesque amounts of money to support the most inefficient, isolating, unhealthy, environmentally damaging mode of transit known to the public (cars). Transit would be vastly cheaper, cleaner and faster if private industry were to have been in charge. reply AnthonyMouse 11 hours agorootparentprev> Because the only serious, broad, federally-managed transportation infrastructure I can think of are like, military airbases. Which tend to be pretty good! I hope you're not putting forth the Department of Defense as a positive exemplar of government efficiency. > That's assuming, of course, you mean the US government--which does not own things like highways The federal government funds 90% of the interstate highway system. The job it does at this is kind of medium and has all of the usual problems that happen when you're spending somebody else's money, e.g. the roads are always under construction because the construction companies get paid if they're \"working\" (even if that means standing around) so finishing projects quickly is disfavored because they want the work to expand to fill the available budget rather than the other way around. The general problem with government projects in the US is that they put too much emphasis on false economies of scale and try to allocate contracts that are too large. For example, instead of contracting with one company for rolling stock and it maintenance, they should buy rolling stock as-needed from anyone who makes it broadly matching a required spec (e.g. the correct width of the track) and then contract with separate companies for maintenance. The most important thing, which they fail at utterly, is to make contracts small and simple and make it easy for companies that don't specialize in government contracting to bid on them. Because otherwise they only get companies that do specialize in government contracting, even when the contract is for some fungible commodity, and end up paying unreasonable rates for everything. > the US Postal Service was pretty great 'til \"the government doesn't work and we're going to prove it by ripping out big chunks of it\" politicians got their hands on it. The US Postal Service had a monopoly on first class mail at a time when lots of things were delivered via first class mail. It wasn't particularly cost efficient but it delivered the mail and it couldn't be outcompeted by someone else because competing with it was prohibited by law. Then first class mail got replaced by email while online purchasing increased enough to give UPS and FedEx enough economies of scale to outcompete USPS for package delivery even with the USPS having existing trucks delivering the mail. Then it actually had to compete on efficiency, which it failed to do and ran into problems. Then people started trying to reform it. Which never really worked because a government agency is constrained by political forces, e.g. public sector unions that capture legislators (\"management\") who are supposed to represent the general public against the unions representing the public's employees. If you then put it into competition with private companies, it will generally operate less efficiently and go bankrupt. Which is fine as long as the private companies continue to operate in a competitive market themselves, until someone decrees that we need to save the publicly operated business that failed in the market. reply velcrovan 13 hours agorootparentprevWhich government? State-owned trains in Europe and Japan are amazing. The US could do fine too if it cared to actually fund infrastructure rather than letting it whither on the vine. reply jdminhbg 13 hours agorootparentThe problem isn't the amount of funding, the problem is competence administering the funding. California's HSR has tens of billions invested and no track laid. I'd love to import European or Japanese rail administrators so that the investment could result in trains actually running, but that doesn't seem to be in the cards. reply briankelly 12 hours agorootparentThey did bring in a French HSR operator that built rail in Asia, but they bailed for projects in a less politically dysfunctional landscape… North Africa [1]. It’s our pork barrel political machinery that’s fucked up. [1] https://archive.is/2023.09.19-135838/https://www.nytimes.com... reply creato 13 hours agorootparentprevThey'd run into the exact same problems getting rights of way. There may be incompetence in administration, but it's not the only problem. reply njarboe 12 hours agorootparentBrightline is a privately company building a bullet train from LA to Las Vegas opening in 2027. The same company recently completed a new bullet train from Miami to Orlando. reply woodruffw 11 hours agorootparent> The same company recently completed a new bullet train from Miami to Orlando. Brightline is an accomplishment, but this significantly oversells it: the Orlando-Miami route tops out at 125mph, which is barely HSR by any normal standard. A good chunk of the route is on pre-existing lines that top out at 79mph. For comparison, trains on the LGV Nord (31 years old) operate at 190mph[1]. I hope they continue to invest in HSR, but I don't think we should settle for marketing here. [1]: https://en.wikipedia.org/wiki/LGV_Nord reply bobthepanda 12 hours agorootparentprevAn interesting feature of the Brightline West project is that it does not go deep into populated urban areas to save money. The terminus in Las Vegas is south of the airport and the Strip. The terminus in “LA” is in Rancho Cucamonga, 37 miles east of LA and in a whole different county. CAHSR was partially sold as a downtown revitalization project, and so has expensive full speed approaches into Fresno, Bakersfield, Merced, etc. reply fwip 13 hours agorootparentprevI'd love if our railroads ran on time anywhere near as often as the postal service does. Or even as often as the city bus does. reply Geezus-42 9 hours agoprevEas Palestine Derailment - Well There's Your Problem https://youtu.be/4xprT_3CArE?si=n2nTRBjEK7EOyOSK reply steviedotboston 12 hours agoprevIs \"disaster\" really the correct term for an incident where zero people where injured or died and everything in the town was back to normal pretty quickly? reply pas 7 hours agoparentthe real issue is that there's no tracking for freight, it took too long to figure out what happened and how severe it was. the network is lacking basic safety features. (because the network is big, and because checks were mostly done by relatively cheap labor, but both regulation and crew got watered down.) the worry is that, since these happen quite frequently, eventually it'll happen in some city. reply Overtonwindow 11 hours agoprevThis kind of deadlock should not happen. I think it’s indicative of what has gone wrong with the United States. Congress, nobody is willing to give an inch, and everything is a personal fight to the death. reply Spivak 13 hours agoprev> Members of Congress blast industry for putting profits over safety Headlines like this make me laugh because it sounds like something is getting done when it's just congresspeople with no actual power making grand speeches that amount to nothing. They really gave those profiteers a real Congressional finger wag! reply unethical_ban 13 hours agoparentIt seems odd to criticize an elected representative who comments on the irresponsible behavior of corporations. reply ejb999 13 hours agorootparentDoesn't seem odd to me - if all someone (an elected person) does is get in front of the camera and make speeches about something a corporation is doing wrong - but never writes/sponsors a bill (and more importantly gets the votes to get it written into law) to fix those bad things - then they are doing exactly zero to make things better - they deserve all the criticism they get. reply JoshTko 13 hours agorootparentprevThe attitude probably reflects decades of effective messaging by big corporations to paint gov as inefficient and corporations as the only solution to problems. reply Spivak 13 hours agorootparentprevBecause they can't actually do anything. They don't charge people with negligence or levy fines. The opinion of a congressman on this issue is only slightly more valuable than mine. The regulations they're proposing won't be punitive in any way and won't dare actually disrupt the flow of profits. And that's fine, that's the point of congress. Now if the DoJ had words to this effect then it might come to something. reply hospadar 12 hours agorootparentcounterpoint: the amount of money that congresspeople and potential congress people are paid by corps and interest groups to get elected (i.e. \"a lot\") suggest that, in fact, their opinions _are_ much more valuable then a non-congresspersons. reply 2OEH8eoCRo0 12 hours agoprevHow many people were killed or injured? Are we making an assumption about the severity of this disaster? reply happytiger 13 hours agoprevDid it “stall?” Did they “blast the industry?” Because they cashed their checks. https://www.opensecrets.org/industries//summary?cycle=All&in... Edit: They are demanding that they cover the cost: https://www.wkyc.com/article/news/local/northeast-ohio/ohio-... While the same quoted congressperson had time to get behind rail initiatives while safety stalled out: https://kaptur.house.gov/media-center/press-releases/kaptur-... Oh, and found 10M from the Federal government to quietly pay for the upgrades: https://kaptur.house.gov/media-center/press-releases/congres... I am no expert here, but it sure seems like a lot of railroad stuff is happening and money moving around for a “stalled out” safety initiative. Maybe someone else can provide more context? reply FemmeAndroid 12 hours agoparentWhen you filter by election cycle it looks like they aren’t making any huge donations compared to their baseline. Maybe the baseline donations stop things like this, but I don’t think I’d jump to that being the clear reason. reply happytiger 8 hours agorootparenthttps://www.opensecrets.org/dark-money/basics I think the Panama papers did that for me. FTX also contributed. And there is plenty more. It’s not like we don’t have enough evidence. I would strongly suggest following the work of one of the last bastions of real independent journalism the ICIJ: https://www.icij.org/ They are a gift to society and deserve our deepest support. reply nitwit005 10 hours agoparentprevCorruption isn't exactly required. Congress essentially isn't passing any legislation of any sort. reply happytiger 4 hours agorootparentThat’s super valid as an argument. reply refulgentis 13 hours agoparentprevWho is they? Legitimately: I can't figure out if I'm accessing the links wrong on mobile, or if they shape shifts across the 3 links reply rhcom2 13 hours agorootparentMembers of Congress reply happytiger 13 hours agorootparentThanks. I’m not sure if the links are working properly. They are working for me but two of them as very slow loads on my mobile. reply tootie 12 hours agoparentprevFTA: \"That sentiment, was echoed by U.S. Senator Sherrod Brown, D-Ohio, who sponsored the Rail Safety Act in the Senate and held a virtual press conference this week to talk about the stalled legislation. Both Brown and Kaptur said lobbying groups and major rail companies continue to oppose the legislation, with the industry putting profits over public safety.\" I mean, you're not exposing some conspiracy. Several Republicans with key committee seats took a ton of money and are now opposing the bill. Voters know who they are and are free to vote them out of office, but they probably won't. reply hanniabu 12 hours agoparentprev> Maybe someone else can provide more context? Corruption reply ChrisArchitect 13 hours agoprev [–] [dupe] / Related: Residents' lives still in limbo a year after East Palestine toxic derailment https://news.ycombinator.com/item?id=39337237 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Proposed legislation aimed at improving rail safety and holding rail companies accountable in Ohio has stalled due to opposition from the rail industry.",
      "Congresswoman Marcy Kaptur and Senator Sherrod Brown blame the rail industry for prioritizing profits over public safety.",
      "Issues such as crew staffing mandates, inspection requirements, and blocked crossings are still unresolved, prompting Kaptur to call on President Biden and Transportation Secretary Pete Buttigieg to address systematic rail problems and allocate infrastructure funding for rail safety improvements."
    ],
    "commentSummary": [
      "The discussions cover a range of topics including rail safety legislation, political issues, transportation infrastructure, and corporate influence in the rail industry.",
      "There is debate about the effectiveness of regulation in improving railway safety and the role of unions and government ownership in the industry.",
      "Concerns about the influence of corporations in elections and potential corruption in the legislative process are also mentioned."
    ],
    "points": 169,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1707766983
  },
  {
    "id": 39344786,
    "title": "The Reliability and Cheers of Zigbee and Z-Wave in My Smart Home",
    "originLink": "https://arstechnica.com/gadgets/2024/02/i-was-wrong-to-ignore-zigbee-and-z-wave-theyre-the-best-part-of-my-smart-home/",
    "originBody": "Waggle dance for the win — I was wrong to ignore Zigbee and Z-Wave. They’re the best part of my smart home. There's plenty of room for this early-aughts tech in a modern connected space. Kevin Purdy - 2/12/2024, 12:30 PM Enlarge / Where it all started for the author, even if he didn't know it at the time. Getty Images reader comments 148 I've set up dozens of smart home gadgets across two homes and two apartments over the last five years. I have a mental list of brands I revere and brands from which nothing shall ever be purchased again. In my current abode, you can stand in one place and be subject to six different signal types bouncing around, keeping up the chatter between devices. What can I say? I'm a sucker for a certain kind of preparedness and creativity. The kind that's completely irrelevant if the power goes out. When I started at Ars in the summer of 2022, the next generation of smart home standards was on the way. Matter, an interoperable device setup and management system, and Thread, a radio network that would provide secure, far-reaching connectivity optimized for tiny batteries. Together, they would offer a home that, while well-connected, could also work entirely inside a home network and switch between controlling ecosystems with ease. I knew this tech wouldn't show up immediately, but I thought it was a good time to start looking to the future, to leave behind the old standards and coalesce into something new. Instead, Matter and Thread are a big mess, and I am now writing to tell you that I was wrong, or at least ignorant, to have ignored the good things that already existed: Zigbee and Z-Wave. I've put in my time with Wi-Fi, Bluetooth, and various brittle combinations of the two. They're useful for data-rich devices and for things that can stay plugged in. Zigbee and Z-Wave have been around, but they always seemed fidgety, obscure, and vaguely European at a glance. But here, in the year 2024, I am now an admirer of both, and I think they still have a place in our homes. Advertisement Getty Images Hue bulbs did a Trojan horse on me, and I am thankful Two brands have done a savvy job of incorporating Zigbee into their tech without making a big deal of it: Philips Hue and Ikea. Hue bulbs were, for me and many others, a first step into home automation. Back then—2018, looking at the receipts—I knew that Hue bulbs ran on their own kind of ad-hoc network, but I didn't know exactly how. All I knew was that, as time went on, the Hue bulbs proved to be the most reliable devices anywhere I set them up. If the Hue bridge had power and Ethernet, and the bulbs were in anything resembling house distance of one another, they worked. They did not, like a Nest camera above a former garage, lose signal midway through an update and require a 6-foot ladder and multiple support phone calls for a reset. They did not, like a couple Tuya devices I acquired, require registering as a Canadian IoT developer to get local control (long story). I have never tried to turn on a Hue bulb, had it fail, and then start wondering if it was my router, an Amazon Web Services outage, or just a cruddy little antenna inside the thing. Yes, Hue stuff is not cheap, and the Hue app would occasionally ping me about new features and holiday sales, but I could turn off notifications. There was never an important notification because nothing ever went wrong. And while I didn't know it back then, there was always the option to reset the bulbs and have them run on straight Zigbee, even if you lose some niceties, like fading and multi-bulb schemes. When I got the chance to review the Homey Pro, I had to research and work more directly with Zigbee and its even more obscure (at least in the US) cousin, Z-Wave. The Homey team had sent me a few devices to test out with their hub, including a motion sensor and a magnetic open/close door or window sensor. I procrastinated a bit on setting them up, vaguely stressed by everything I'd read about hubs, routing, and \"self-healing\" networks. Page: 1 2 Next → reader comments 148 Kevin Purdy Kevin is a senior technology reporter at Ars Technica, covering a variety of technology topics and reviewing products. He started his writing career as a newspaper reporter, covering business, crime, and other topics. He has written about technology and computing for more than 15 years. Advertisement Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39344786",
    "commentBody": "Zigbee and Z-Wave are the best part of my smart home (arstechnica.com)162 points by mfiguiere 20 hours agohidepastfavorite151 comments joshstrange 18 hours agoThis is the advice I give everyone who is interested in smart home stuff: Pick Zigbee or Z-Wave and only buy that type of product, WiFi is trash. I'm not super keen on Thread/Matter seeing how one of its goal seems to be allowing your devices access to the internet which is the exact opposite of what I want. I want my devices to be dumb, only able to talk to the hub, and then the hub can optionally run some code to connect outside the network if and when I decide. The best part about my Z-Wave setup is every manufacturer can go out of business and I won't even notice. That's a stark difference to something WiFi based which almost always requires a cloud component. I understand why people start with WiFi devices, they don't need a hub, but having a local hub is the best way to do anything \"smart home\" by far. Personally I use Home Assistant but before that I used SmartThings and liked it well enough. reply ssl-3 16 hours agoparentBut reality seems to be more nuanced than that: Matter devices can be \"dumb\". They're intended to be able to work without Internet. Matter uses IP, and Thread provides IPV6, but that doesn't mean that either thing needs to be able to talk to the WAN. Wifi devices can also be \"dumb\". For example: I have ESPHome devices that Just Work and that don't have any outside connectivity. I don't advise anyone who asks me about smart home stuff. I'll tell them some about what I'm doing in my own home, and answer any questions they have accurately, but their eyes glaze over when they hear phrases like Zigbee or MQTT, and they've completely stopped listening by the time something like Home Assistant comes 'round. I don't know that Matter and/or Thread will make anything better or more secure by default. The Matter 1.0 spec is only a year and a half old and it isn't clear at all how implementation is going to wind up being shaped in the real world. But they can improve things and I hope that they will. reply wokkel 10 hours agorootparentThe main thing that i remembered from thread/matter is that vendors can lock out devices and other users hostile stuff. I sure hope plain zigbee is here to stay as having bigtech decide the brand of my in-wall switches are wrong would truly suck. reply ssl-3 8 hours agorootparentHow can a vendor \"lock out\" a device that cannot talk to the outside world? reply carlhjerpe 5 hours agorootparentMAC address ranges or something would make sense reply zamalek 12 hours agoparentprev> Pick Zigbee or Z-Wave Picking both is fine. Zigbee is significantly cheaper, but you have to make sure that the device is interoperable (Ecobee is a good example of a manufacturer to avoid - Zigbee interoperability is optional). If not, that's where Z-Wave steps in. Having an \"off-brand\" Zigbee adapter is a good bullshit force field. I use the Aoetec USB for Z-Wave and the Sonoff USB for Zigbee. Both are incredibly interoperability conscious, so I have no problem supporting them (I also have a lot of Zooz devices, who are equally awesome). All the WiFi devices went to Goodwill. reply bradgessler 17 hours agoparentprevThere’s really good WiFi smart home hardware out there, like anything Leviton ships I’d recommend. There’s also a lot of crap out there too. I think the ideal smart home device can connect to the internet to check for updates either when I manually want to update it or setup an auto update schedule. An account should NOT be required, which sadly lots of smart home hardware requires. reply CharlesW 14 hours agoparentprev> I'm not super keen on Thread/Matter seeing how one of its goal seems to be allowing your devices access to the internet which is the exact opposite of what I want. Happily, that's not a goal and definitely not a requirement. Thread/Matter work great without internet access unless you use them via a platform which does (e.g. Alexa). reply vineyardmike 12 hours agorootparentMost commercial platforms, which people will realistically use, are border routers. IP routers with internet access. Beyond that, the protocol allows for logs to be uploaded to your ecosystem of choice, and allows for OTA installation of software updates. Internet access is not a requirement for protocol, but neither is any other part of the modern “networked software” stack. Good luck with your internet-disabled SMTP server. reply Lendal 14 hours agoparentprevI use Hubitat but everything is Z-wave except for one Alexa-only bulb, which was a gift so I can't get rid of it. What I've learned is that smart wall switches of all types are still too failure-prone for me. Now I'm converting back to standard wall switches with Z-wave relays wired in behind them. I don't like the extra lag they have, but I do like that standard wall switches last forever compared to smart wall switches. If anyone knows how to reduce the lag, I'm all ears. The switch operates the relay which sends its signal to the hub, which then sends a signal back for the light to turn on. This process introduces a noticeable time delay between the switch closing and the light coming on. reply pxmpxm 6 hours agorootparentDo you have a recommendation for the relays? Would love to decouple the smart stuff from the switches. reply windows2020 14 hours agoparentprevThere are some fantastic products (LIFX, Twinkly) that are WiFi and don't require the cloud. Zigbee falls apart when controlling a large number of devices in real-time. reply rootusrootus 13 hours agoparentprevIn my experience it's more nuanced. Some of my most unreliable devices are Zigbee (but they're also Aqara, and that may well be the real problem there). My Z-Wave devices have been pretty solid once configured, but they were also some of the most finicky to get paired up and on the network. My WiFi switches have been rock steady, not a single problem. reply stavros 13 hours agorootparentI got a Sonoff Zigbee USB dongle to use with Zigbee2MQTT and it's been bulletproof. It even managed to upgrade my finicky IKEA Zigbee devices to rock-solid firmware versions. reply 35mm 12 hours agorootparentI can also vouch for the Sonoff reply billfor 14 hours agoparentprevI’ve used Tasmota with Wi-Fi and mqtt and it works great. reply 35mm 12 hours agoparentprevAlso wifi devices always seem to want a special app or account registration first, whereas with Zigbee you just allow new devices and then turn on your new device. reply ashman5 17 hours agoparentprevI use both and both work well. There a pos/negs to both, Zigbee tends to be cheaper, but there is a complete lack of dimmer plugs. reply somehnguy 17 hours agorootparentI use both as well and see no reason to pick only one or the other. The USB stick hubs are very cheap and Home Assistant does all the heavy lifting seamlessly. Having both gives me pretty much unlimited flexibility. For devices I usually pick whatever standard has the device I want at a more reasonable price or is on sale. So far I've yet to run into a scenario where I wish I had chosen the other standard for a specific device. I also have a ton of devices on WiFi via Esphome on both esp8266 & esp32. Fantastic project, years of them running completely trouble free. reply happymellon 14 hours agorootparentprevI have dimmer switches, and I only have Zigbee. Candeo are pretty reliable. reply SI_Rob 11 hours agoparentprevShelly's WiFi devices are all fairly cloud-optional - you can completely disconnect the internet and they will all work with Home Assistant just fine. Still, I'm not as excited about them as I used to be (mainly due to realizing there's a ton of cool-looking I/O flexibility they have that ends up being redundant once you settle on a control plane for wifi - MQTT in my case), and because their exposure of features and properties is somewhat inconsistent across device families. But as a way to unburden your (usually one and only) Zigbee channel from certain types of chatty messaging, such as high-accuracy presence sending or complex lighting curve adjustments that can't be done ergonomically (or at all) via Zigbee, they are invaluable. Wifi (jailed in a VLAN, if you like) also provides a layer of failure protection should your Zigbee coordinator die unexpectedly. reply nirav72 8 hours agorootparentShelly is one of few HA component makers that have an open http API. I love that I can script a CURL call directly against a shelly smart plug. reply magicalhippo 11 hours agoparentprevThat was my approach as well when I invested some years ago in various dimmers, heater controllers and such. One positive with Z-wave is that fallback is built into the protocol. So the switches can talk directly to the appropriate dimmer if the controller is down, for example. reply aeturnum 14 hours agoparentprevI think your attitude is almost exactly right but I will add: you can pick both. The two ecosystems don't really step on each others' toes and as long as you find a hub(s) to feed a single view there are basically no downsides. reply vanviegen 12 hours agorootparentI can think of two downsides: - Harder to get coverage. Both zigbee and zwave use mains powered devices (like light bulbs) as signal relays for other devices. If you're using both, you need to ensure proper coverage for both networks. - No protocol native groups and scenes. At least zigbee allows you to set any number of bulbs to a certain scene using a single fast broadcast command. When using something like Home Assistant to unify both networks, recalling a scene will cause each individual bulb to be sent a separate command, which can be sloooow when you have many bulbs in one room. reply bryanlarsen 17 hours agoparentprevThread is based on Zigbee. It functions fine without the internet. reply abollaert 17 hours agorootparentI thought both Thread and Zigbee run on top of IEEE802.15.4, but Thread is based on 6LoWPAN / IPv6 where Zigbee uses its own network layer. But Thread idd functions fine without the internet (although you probably could connect devices to the internet if you'd want to). reply ianburrell 16 hours agorootparentAlso important is that Zigbee is both the transport protocol and multiple home automational protocols. Zigbee compatibility is pretty good with the same protocol but not across different protocols. Thread is a transport protocol for Matter home automation protocol. Matter is complex because it tries to do everything in one protocol. reply vineyardmike 12 hours agorootparentprevThread is based on Zigbee in the sense that the thread designers read papers about the Zigbee spec. Also matter is partially based on Zigbee with its use of Zigbee clusters (deep in the stack, away from end users). Zigbee and thread are different protocols and incompatible. You cannot mix them and that’s what most people are about. reply JshWright 13 hours agoparentprevIf you're using 2.4GHz WiFi, then consider Z-Wave. It's a little pricier, but doesn't use the same chunk of RF spectrum (so won't cause interference). reply tw04 12 hours agoprev+1 for Hubitat - assuming they don't sell out their business model is perfect. They sell the base hardware which you'll need to upgrade over time as new z-wave/zigbee/other protocols come out. Additionally they will sell a subscription for backing up the hub configuration to the cloud, and essentially creating a reverse proxy to manage their hubs remotely. The hub can operate completely offline, or if you're technically capable of setting up a reverse proxy/vpn/whatever to manage it you can do that as well. They provide timely updates, the hub for the most part has been rock solid, and the upgrade path between generations is pretty painless. I've got a mix of both zigbee, z-wave, and a handful of wifi devices (that were free, I would never ever spend money on a wifi smart device if I could avoid it). As an added bonus if you were a smartthings user, you can migrate your automation/drivers/etc with little to no modifications. Think about them as smart things 2.0. www.hubitat.com Disclaimer: not affiliated, just a fan. reply santialbo 19 hours agoprevI'm running Zigbee2Mqtt on my Homeassistant and so far it's been a very pleasant experience buying devices from different brands without having to use each vendors app. The compatibility list is gigantic https://www.zigbee2mqtt.io/supported-devices/ reply rekoil 19 hours agoparentI've seen a lot of references to Zigbee2MQTT. If I'm going to be using it through Home Assistant anyway, why should one choose Zigbee2MQTT over say ZHA? reply function_seven 18 hours agorootparentI used to run ZHA on my Home Assistant setup, and switched to Z2M a couple years ago. At the time it had a longer list of supported devices, and the UI for configuring them was better. It felt kind of “dirty” to layer in yet another protocol (MQTT) between the Zigbee side and the HA side, but it’s worked great. It could very well be that ZHA today is the same or even better than Z2M, but at the time I made the switchover, there was some device that I couldn’t use with ZHA that Z2M supported. reply rekoil 18 hours agorootparentI haven't really run across any devices that haven't worked in ZHA. I did recently buy the latest generation of Philips Hue Festavia string lights and Home Assistant (via ZHA) had no clue how to set any of the scenes on it. I was able to use the official app to set scenes via Bluetooth though, while still being able to use ZHA to control power and brightness. I believe the product was released very near the Christmas period though, so I'm sure it'll have full support in ZHA by next year, might just bring em out early and do it myself if nobody else has done it by then. reply stavros 13 hours agorootparentSame here, but with Z2M. Even some random, no-name, $20 thermostat works perfectly with Z2M, I can even set the week's schedules easily. reply rekoil 2 hours agorootparentAnd how do they work in HA? Is there lots of setup with each entity because I have to talk to it over MQTT? I noticed that Z2M seems to say it supports effects on my string lights, do you know if that also means it'll automatically show UI for setting effects in HA? It's sounding like I made a mistake choosing ZHA thinking it was the \"HA native\" solution... reply stavros 2 hours agorootparentEverything just shows up, I don't know about string lights but everything else shows the proper UI, and some of my bulbs show RGB controls, so I assume string lights will too. reply rekoil 1 hour agorootparentAh, talking about effects (scenes, blinking lights, etc.) that run on the string lights processor, custom Zigbee commands, RGB controls is fairly standardised. But from all the praise Z2M is getting here I guess I'll have to try it! One last question if you end up seeing this, can you still group things when using Z2M? reply zer00eyz 13 hours agorootparentprevI like home assistant. There's tons of reasons to use it. You get a lot of good enough moving parts out of the box. MQTT is something you should set up ASAP. There are plenty of reasons to set it up: ESPresnse is a big one (can't say enough about this offering) AWTRIX is another, even if you aren't going to integrate zigbee. MQTT becomes a cheap and easy way to add data to, and interact with home assistant. And, any device that communicates over MQTT can be controlled by you (custom code, dead easy) outside HA. reply rekoil 2 hours agorootparentOh I do have MQTT setup already, just haven't tried Z2M. reply pavon 12 hours agorootparentprevAnother minor reason is that AFAIK ZHA has to run on the same machine as Home Assistant, while Z2M can run on a different machine, and is less resource intensive than all of HA. So you can plug the zigbee coordinator usb dongle into a centrally located OpenWRT router and run Z2M on it, while your Home Assistant machine can be located anywhere that is convenient. reply AHTERIX5000 12 hours agorootparentprevI used ZHA until I encountered devices ZHA didn't support or the support was broken yet they worked with Zigbee2MQTT. That said Zigbee2MQTT isn't without its problems, it's still hobby-grade and not hard to crash with cheap and badly behaving devices. reply iforgotpassword 18 hours agorootparentprevI can second the sibling comment. I naively started out with ZHA for less moving parts in December. Switched to mosquitto and z2m a week ago because of one completely and one partially unsupported device. It's more involved and if something doesn't work you have to check two (three) different places now, but it seems worth it. reply wkat4242 18 hours agorootparentprevI prefer DeCONZ instead. It's got a really nice UI both the web interface for the pairing and a great live network view over VNC. ZHA is much more bare bones. I didn't try the mqtt one but I'm not so interested in something that uses mqtt in the middle. Another thing that can break.. reply rusk 14 hours agorootparentI was on deconz, but eventually migrated to Z2M due to compatibility issues with some devices. It’s a far better experience to be honest. Haven’t looked back! reply santialbo 17 hours agorootparentprevAnother silly reason is that unlike ZHA, Z2M doesn't restart everytime you restart HA. reply rekoil 16 hours agorootparentThat's actually a lot more of an upside than it should be... reply devonkim 14 hours agoprevOne thing I found a bit unsettling about some products is how manufacturers can say they support a standard when they’re really using it as a basis for a proprietary lock-in strategy. I didn’t realize the standards were so loose until I started researching some newer devices to support Home Assistant, namely the Aqara U100 which seems to require the Aqara hub to be able to support standard Zigbee when it’s advertised as supporting Zigbee https://community.home-assistant.io/t/aqara-u100-smart-lock/... reply yurishimo 14 hours agoparentIs this true of Zwave? From what I understood, one of the reasons that zwave devices are substantially more expensive, is that the licensing and certification requirements are much more strict. There also isn't a \"first party\" zwave hub that I can find. The Zwave alliance seems to only deal with the protocol and licensing, thus, any hub that claims to support zwave, will work with any zwave device. reply gh02t 12 hours agorootparentNo. Loosely speaking, Zwave pretty strictly defines a list of device types (lightbulb, thermometer, etc) and supported formats for read/writes to it by device type (turn on/off, reports temperature,...). The API to handle those is then standardized, and the device manufacturer just fills in the code to implement the calls appropriate to the device. Devices are more-or-less \"self-describing.\" Baseline Zigbee is a bit more freeform (it's not solely a home automation protocol) and is a transport for whatever data format manufacturers want to send, with devices implementing their own details on top. Later on there was an attempt to standardize the communication format for home automation similar to how Zwave works and it was somewhat successful, but manufacturers still have a bad habit of having deviations and quirks. The standard is also not as rigidly enforced like it is with Zwave. Again this is all simplified and there's more nuance but that's generally the breakdown. Practically speaking you'll have more consistency with Zwave devices, but nowadays Zigbee devices have a lot more variety. Support for (and quality of support for) new devices in Zigbee can be a bit more hit-or-miss, but it's usually pretty good nowadays with Zigbee having more marketshare/momentum. I use both, I have more problems with Zigbee, but I also have more devices for it by virtue of their being more choices. reply organsnyder 13 hours agorootparentprevThat's been my experience so far. I have ~20 Z-wave devices from a variety of manufacturers. They all work very well with Home Assistant, and many of them now support firmware updating directly through HA as well. reply vineyardmike 12 hours agoparentprevThis seems like an edge case. It’s pretty rare to see a product advertise a protocol that isn’t freely used like this one. It even explicitly says in the product description it requires a hub. Aqara has always played fast and loose with support of various open specs. Ecobee remote thermometers use Zigbee, but they can’t be generally paired to non ecobee products, and as such they don’t advertise Zigbee support. reply bombcar 18 hours agoprevThe main thing I've learned from this smarthome stuff is make sure your light switches also work when damn near everything but the power itself is off. Really annoying not being able to turn the lights on or off because something (doesn't matter what) is not cooperating on a software level. reply eddieroger 14 hours agoparentI went with Lutron Caseta switches (though they're not the only ones that do this) for that reason. When all else fails, they are just dimmers and remotes that talk to said dimmer. When I want them to be more than that, they work with HomeKit and Home Assistant just great. But Lutron is a switch company first and foremost, and that shows in these switches. They surpass the Partner Acceptance Factor. I'd add to your advice and say \"do as much as you can to keep the experience vanilla,\" which in this case means standard fixtures and bulbs, just replacing the switches. For the price of half of one Hue bulb, my whole fixture is smart now, and I can still use whatever bulb I want. reply ydant 12 hours agorootparentHave you found LED bulbs that dim nicely with the Caseta? It's been a few years since I've tried, but in the past I went through so many bulbs that whine when dimming that I gave up and put in smart bulbs where I can conceivably hear the bulb. Which means I've got switches that don't work properly if the hub is down. I love the Caseta otherwise. We use it for recessed cans and the whine is just not quite noticeable. But, e.g. over my bed it's very noticeable. Maybe newer models of Caseta solved something and the bulbs aren't the solution? reply bombcar 11 hours agorootparentDimming is always the problem. I'm so fed up with bulbs in general that I may next time just wire multiple bulb-holders instead of one in each area. The dimmable room that is working \"best\" is the one where everything is Hue and controlled \"together\" but it has issues when the Internet is down. The push-button switch they no longer make works decently well even then (sometimes): https://meethue.co/products/philips-hue-tap/ reply amluto 6 hours agorootparentprevI haven’t tested Caseta, but the current generation of Philips LED bulbs dim quite nicely with other Lutron dimmers. reply Avamander 18 hours agoparentprevYea, the behaviour I want is always just to enhance not replace. This is why I dislike smart bulbs with dumb switches and similar bad combos. Smart home appliances shouldn't hide any features behind an app either. But every manufacturer has perverse incentives to push their apps. reply bombcar 18 hours agorootparentThings have regressed - the older Hue stuff could have switches that had no batteries (pressing the button generated enough electricity to send the signal) and they could communicate directly with the gateway or even the bulbs. Now everything is wifi or bluetooth and it sucks. Five years ago I would have designed a new house entirely around these things; now it would be so old-fashioned it wouldn't look out of place in the 1950s. reply xrd 14 hours agorootparentYes, it is insane how these things work. We bought a 60s house which presumably had bad wiring. The sellers elected to use \"smart bulbs\" and \"smart switches\" for everything to probably save money on the rewiring cost. The thing you never realize, is that for each extra communication protocol and endpoint you add, you need to then troubleshoot across all the permutations. So, if you are only using a wire to connect to another wire, there is only one path that can fail, the wire between them. Electricians are good at troubleshooting that. If you add a wifi access point, and a smart bulb router (or whatever the fuck it is) and then you add a wifi extender, when things fail, which path did it take when it failed, or when it worked? The permutations you need to troubleshoot are suddenly an N^4 problem. Get your graph theory textbooks out and study up on the traveling salesman problem. That's why we have had electricians come by who cannot figure out why when we push the wifi light dimmer button in one bedroom, that the other bedroom lights turn off. It just started happening a few months back. It's absolutely maddening. All these smart devices are awful. As a related aside, our Amazon Ring devices no longer allow you to connect to their wifi with the Amazon Ring app, and we have a bunch of cameras that are dead once the power goes off. Used to be you could just join their temp wifi connection, register the device on the home wifi, and go. They turned that off. Now, they all say you need to get the QR code, but we cannot find that on the devices, so they are bricked. I'm sure this is because probably someone found an open wifi Ring camera, added it using their phone when they walked by, and spied on the family. But, I don't really care, I just know cameras are sitting there unusable by me, until some hacker walks by and figures out how to register them. I won't be spending anymore money on Amazon cameras, but I'm sure Amazon would be happy to have me just buy new ones. reply WirelessGigabit 17 hours agoparentprevI have one place like this. There is no connection from the switch to the lightbulb. If the network is down, no lights. I have some TP-link press-switches (so no on-off, just press to invert state), and they work amazing. They work when the network is down. And you can read the state. Even if you turn off the network, flip the state, and turn it back on, it works correctly. reply doubled112 14 hours agorootparent> I have some TP-link press-switches (so no on-off, just press to invert state), and they work amazing. I just bought a 2 plug smart plug and this was a major selling feature. What happens if I'm standing there and I don't have a device on me? I just press the button like I would anyway. reply devnulll 17 hours agoparentprevThe key engineering point here is about failure modes. If the failure mode is a brick, then the engineering and design team behind that switch has failed. The failure mode for a smart switch needs to be a \"classic\" switch. This applies equally to garage door openers, showers, door locks, and the rest of the smart devices. Note: I'll give a bit of a pass to smart window blinds as a selling point is lack of strings and cables and the therefore look cleaner. reply bombcar 17 hours agorootparentIt's like the failure mode of elevators vs escalators - the elevator fails and it's useless, the escalator fails and it's just a flight of stairs. reply AlexandrB 14 hours agorootparentNot necessarily so. (Warning, video of a bunch of people getting injured): https://m.youtube.com/watch?v=qE2Lv-t9BHk reply codingminds 1 hour agoparentprevThat's the reason why I've chosen KNX. As long as there's power, it's working. Just keep a spare power supply and you'll be fine. Also no mesh and network fiddling, just a bus wire. reply WorldMaker 13 hours agoparentprevRelated to this, I still think think the original version of the Hue Tap switch was clever and I'm still surprised didn't have more clones and didn't entirely survive the internal revision wars/external protocol wars: the original didn't use a disposable \"button\" battery and instead used mechanical energy of pushing the button to power sending the Zigbee signal. It takes more force than a regular light switch to hit it with enough physical power, but it's also kind of satisfying in the way a mechanical keyboard button can be or a big chonky \"snooze button\" that you kind of want to smack with some force anyway. I've heard it said that sort of mechanical powered switch with Thread/Matter is much harder, except with these old existing ones in bridges with old Zigbee compatibility, and more's the pity. It still seems such a good idea to me, one less battery to waste/go bad at exactly the wrong time. reply bombcar 11 hours agorootparentIt was a phenomenally amazing idea, and I'm really sad it was discontinued. When I realized how it did the magic, it almost singly-handedly sold me on Hue (their stupid upcoming app account requirement unsold me, let me tell you). reply WorldMaker 11 hours agorootparentYeah, I'm not thrilled about that account \"requirement change\" either. To be fair, for various different reasons over the years, I've used third party apps a lot more than the main Hue apps, so this may just be a push to switch back to third party apps again and/or finally upgrade from a Hue-only bridge to something like Apple Home Hub, which I'd been considering lately anyway because Apple HomeKey sounds like something useful to me (I'm less likely to forget my watch than my keys these days). reply bradhanson 17 hours agoparentprevCheck out the Shelly products. They use local control of a relay using standard switching hardware, so if your network is broken the lights still work as normal. Technically the switch isn't actually switching the power so there's _some_ element of electronics between you and mains power, but it's close enough for me. reply bombcar 17 hours agorootparentI've started using these switches: https://assets.lutron.com/a/documents/369987_eng.pdf as they work fine with the network off. Amusingly enough the failed Best Buy product line still work great with Apple HomeKit (and manually) - even though they discontinued the cloud service and refunded all purchases as gift cards. reply bhaney 13 hours agoprevApparently I'm one of the rare few people who fell on the WiFi side of the WiFi/Zigbee smart home war. All of my lightbulbs, occupancy sensors, etc just connect directly to WiFi, and run custom firmware that I wrote so I know exactly what they're doing and how to control them. They make no attempt to access the wider Internet, but they're all on a vlan without Internet access anyway. It feels like introducing Zigbee to this would just be an extra hub device taking up space, acting as an extra point of failure, and making it more complicated to develop against my devices. As it stands now I can easily manually control devices by piping crap into netcat if I need to for some reason, since they're all just normal IP networked devices. I think I would have to jump though extra hoops to do similar things with Zigbee. Is the main aspect driving people to Zigbee just that off the shelf consumer smart devices that use WiFi tend to be annoying dogshit, and Zigbee keeps manufacturers in line better? I don't see any reliability or simplicity benefits to it, just the market poisoning WiFi and Zigbee being the only worthwhile alternative. reply alwa 13 hours agoparentI’m a latecomer to the home automation game, so I’m speaking from theory more than experience. In the environments where I’m thinking about building out, the WiFi is… you know, fine, but it’s not a rock solid corporate campus pushing reliable signal to every crevice of every garage and outbuilding where I might be interested in adding sensors. Power, though, is plentiful, and Zigbee’s auto-meshing capabilities are therefore attractive to me. I also have an impression that Zigbee et al are more friendly to extremely low-power, battery-operated sensors participating in the network in situations where a WiFi radio might drain down quickly. You do mention occupancy sensors, though—if you have experience with battery-powered models that work reliably on WiFi, I’d be open to changing my mind. reply bhaney 12 hours agorootparent> I also have an impression that Zigbee et al are more friendly to extremely low-power, battery-operated sensors That makes sense. All of my \"smart\" devices are wired to power because I don't want to maintain batteries, and \"power is plentiful\" as you said. But I can see why WiFi would be a detriment for battery-powered devices, and why some devices would be annoying to hard wire to power (door/window sensors come to mind). > if you have experience with battery-powered models that work reliably on WiFi I don't. Most of my sensor devices are just generic sensor components wired into a ESP8266 breakout board, plugged into power. Not much that's ready off-the-shelf. reply dzikimarian 13 hours agoparentprevThere's at least a few interesting points for zigbee: * If you use universal hub like Home Assistant, they are pretty interoperable between various manufacturers * Devices don't have direct connection to internet (again esp. with HA), so better privacy, they are faster (no cloud lag) and do not depend on internet connection * Battery life is way better for small devices * Mesh is nice when you have bigger area to cover * If you have to use shitty ISP router, it will have issues with large number of devices * Usually easy push-to-pair setup And there isn't many downsides - one time cost of some kind of coordinator and very slightly pricier equipment. reply karlgkk 13 hours agoparentprevFor zigbee, you could either obtain a zigbee/usb dongle (interact over virtual serial port to send zigbee commands - tons of libraries exist to provide an api surface), or obtain a hub and figure out its api. Zigbee also has functional mesh features that wifi doesn't. One is designed for high bandwidth single point communication while the other is designed for low bandwidth long range. reply matthew-wegner 12 hours agoparentprevHow long do your battery-powered devices last? AFAIK a big benefit of Zigbee is that it's designed to be low-power. I have motion sensors that last for 2-3 years on a coin battery, depending on location/traffic. Mains-powered devices like lightbulbs act as repeaters in a Zigbee network, so placement can be anywhere. reply Tomuus 13 hours agoparentprevZigBee is a mesh network, this is very important in many situations eg. battery powered or large area reply edude03 18 hours agoprev(I've been running home automation stuff for ~10 years now but) I am little surprised the author thought wifi/bluetooth would be better than technology made specifically for (home?) automation. To me meshing is a natural fit for interconnecting devices all around the house vs the hub and spoke model that wifi has. Furthermore, I (read) and kind of disagree that thread/matter is a mess, but I'm coming from the point of view of an engineer who is keenly interested in home automation tech; for the typical consumer that's probably a fair take. reply agloe_dreams 18 hours agoparentThread and matter are a mess from both technical and consumer angles. Yes, they are both good technologies...but the players in the hub space have made an utter mess of it if you have multiple hubs or, like most Americans, use an iPhone but have Nest or Echo devices. Then you have the lack of adoption of thread in general. And finally, Matter support being always 6 months away for everything or just straight up not working. It is mind blowing to me that it was easier for me to set up my Wiz bulbs to work in Homekit via HA than to get them to actually frickin work over Matter...seeing as the Matter logo was on the box when I bought them. Honestly, I'm kinda shocked that no hub company has shipped a Cheap Zwave/Zigbee integrated HA hub. Sure you have HA Green and Yellow and all that, but you could get that price way down with a simple partnership and purpose built hardware that is elegant. reply edude03 15 hours agorootparentYeah, not having a way to share keys between thread networks I think is the biggest technical challenge for the user/user experience. Home Assistant for example is able to import keys from an iOS device using its app and join a HomeKit thread network, but I don't know if that approach is scalable. > Cheap Zwave/Zigbee integrated HA hub The ikea Dirigera and smartthings hub have great HA support from what I understand, I'm not sure what'd it take to get the HA logo slapped on the box and have them officially supported though reply Xelynega 18 hours agorootparentprevI think an integrated hub would be a bit extra tbh. Amazon sells a coordinator usb for $20, so pair that with anything that can rub home assistant(raspi, ha green/yellow, old laptop, etc.) and you have a ZigBee hub that's plug and play for ZHA and Z2M. reply rlpb 10 hours agorootparentprev> Honestly, I'm kinda shocked that no hub company has shipped a Cheap Zwave/Zigbee integrated HA hub. Samsung SmartThings does both, doesn't it? Source: https://support.smartthings.com/hc/en-us/articles/3600523901... reply Xelynega 18 hours agoparentprevI haven't looked too much into thread/matter, but my understanding of them has been basically this: https://xkcd.com/927/ I shudder at the idea of ipv6 addresses for my lightbulbs. reply edude03 15 hours agorootparentFrom what I understand the benefit of ip addressing for IoT things is that apps on your phone (for example) can communicate with them directly, ignoring the underlying transport (and therefore, no need to have a thread radio in your phone for the manufacturer specific app to work) I've always found that the most reliable combination is the Manufacturers app + hub + IoT devices (for example all Aqara or all Nest or all Hue) and interop hasn't worked great because there are special features that only work with the app made for the device (which again, only works with that manufacturers hub) so thread should fix that by making the hub just a dumb Zigbee to IPv6 adapter. reply tremon 13 hours agorootparentthe most reliable combination is the Manufacturers app + hub + IoT devices This means that the standard has failed to be an actual Standard, and thread/matter really is a big mess. reply jwr 19 hours agoprevIncidentally, I am building my own lighting controllers, largely because everything that is out there on the market sucks. Most importantly, I didn't want any \"online accounts\" for managing my devices, I didn't want to \"agree to our privacy policy, your privacy is important\" and then share all of my data with a company, and I didn't want anything that is Wi-Fi based. I decided to go with Bluetooth Mesh and so far I'm really happy with how it is designed and how it works. It hasn't seen much adoption in the consumer space, being mostly used in industrial settings — indeed, its apparent complexity may seem baffling at first. But if you start with a good implementation (Zephyr OS on Nordic devices), it works very well. reply iforgotpassword 18 hours agoparentI went with zigbee simply because there seems to be a ton of devices available, and while many vendors try to build devices that don't adhere to default messages so you'd have to use their gateways that talk to the cloud, zigbee is simple enough to reverse engineer the communication and add support in all the open source ha solutions. reply marcus0x62 19 hours agoprevI've run around 20 Zigbee and an equal number of Zwave devices for several years. Zigbee is great. Zwave is terrible: despite operating at a better frequency for a home environment (lots of walls,) in my experience is has worse propagation, higher latency, and an unreliable mesh topology that randomly breaks and has to be manually repaired. reply planb 19 hours agoparentAnecdote from the other side: my zwave devices just work for 8 years now, while there are times some zigbee devices just don’t respond. I suspect the zwave network is more stable because all routers are powered all the time, while I have lots of zigbee bulbs that are behind a real switch so they leave the network if I turn the lights off. There seems like to be no way in zigbee from preventing those devices to be used as routers. reply iforgotpassword 18 hours agorootparentI've read zigbee really doesn't like routers that aren't available 24/7 so I'm planning on avoiding this. reply yanellena 14 hours agorootparentprevYeah Zigbee routers need to be on all the time, if you turn them off, other devices will start to form connections with other mesh nodes and will fail unexpected when you flip the switch back on. reply robalfonso 19 hours agoparentprevI've found that some people have great zigbee experiences and terrible z-wave and just as many are the opposite. I chalk it up to individual environments etc. Go with what works best from you. reply rlpb 9 hours agoparentprevI had that experience with Z-Wave using openzwave. Then I switched to node-zwave-js and the difference was night and day. All unreliability gone. My impression is that it therefore very much depends on the quality of the controller software since various mesh management operations are delegated to it. reply somehnguy 18 hours agoparentprevInteresting, maybe your ZWave dongle is not the greatest? I also run a mix of ZWave & Zigbee with their own appropriate dongles plugged into my Home Assistant server and they've both been great. No issues with devices dropping or needing to manually repair anything. For both I use a 6ft USB extension cable to mount the dongles up on the wall behind my server instead of hanging out of the USB port. reply marcus0x62 15 hours agorootparentIt has been consistent across the following hubs/zwave adapters: Micasa Verde Smart Things Hubitat Home Assistant with the Zooz Zwave radio. reply jauntywundrkind 18 hours agorootparentprevThere's also many generations of zwave specs. Everything is backwards compatible but perhaps perhaps perhaps the presence of older devices might slow down or degraded what newer devices might otherwise be speaking. reply bliteben 19 hours agoparentprevWhat zwave devices have you been using? I have only used zwave (leviton, ge) and have only had to restart a switch 2-3 times. My biggest gripe with zwave was when home assistant switched the supported plugin. reply marcus0x62 18 hours agorootparent* GE/Jasco switches (the bulk of my devices, around 10 total.) * GE/Jasco outdoor outlet controls * Schlage motorized door locks * Linear garage door controller * Aeotec outlet control * Aeotec repeater * Aeotec temperature and humidity sensor reply CharlesW 17 hours agoprevFor people who haven't started their smart home project, my advice is to focus on Thread and Matter. Regardless of growing pains, Thread and Matter work today, have momentum, and are clearly the future. (Note: The negative article the author linked to under \"Matter and Thread are a big mess\" to support his position was written by the same person.) Z-Wave was a pre-IP proprietary standard that was forced towards standardization (Z-Wave Alliance remains a gatekeeper), but its future is unclear at best. Thread and Matter are the spiritual descendants of Zigbee, all of which are based on IEEE 802.15.4. Also, I've seen posts praising the old protocols because they allow local control, but those concerns are unrelated. Alexa supports Thread and Matter but does not support local control, while HA and HomeKit support Thread and Matter and do support local control. reply santialbo 17 hours agoparentI tried that and gave up. Get ready to spend a lot of moeny, sensors and devices are still very expensive compared to the ZB counterparts. Most Matter devices go with Wifi rather than Thread which makes your wifi network implode if you plan on installing a large number of them. For that reason I decided to go with what's cheap and works today, which is Zigbee. reply CharlesW 16 hours agorootparent> I tried that and gave up. Get ready to spend a lot of moeny, sensors and devices are still very expensive compared to the ZB counterparts. When you compare apples-to-apples, there's no price penalty — for example, a Leviton Decora smart dimmer is $56 for Zigbee or $50 for Matter. Kasa's Matter dimmer switch is $27, and I see $3 Matter devices on AliExpress. Matter and Thread don't currently match Zigbee in terms of device diversity, but that's just a matter of time. > Most Matter devices go with Wifi rather than Thread which makes your wifi network implode if you plan on installing a large number of them. Even hundreds of Matter devices using Wi-Fi would collectively use an insignificant portion of your Wi-Fi network's throughput. reply santialbo 16 hours agorootparentTry having more that 40-50 devices connected to your home router and you will see devices disconnecting randomly because your router can't keep up with them. reply CharlesW 15 hours agorootparentI have more than that on my ordinary consumer router and have never seen a problem. Worst case, it'd be straightforward to dedicate a Wi-Fi router to your smart devices in the same way that you have a hub (and possibly repeaters) for your Zigbee devices. reply dm_me_dogs 17 hours agoparentprevHomeKit-over-Thread and Matter-over-Thread has been pretty okay in my experience, using HomePods and an Apple TV 4K as the border routers. I'm using Home Assistant, and the HomePods control everything nicely. Setup is a little weird (you have to set up your devices in HomeKit first, remove and then add again in Home Assistant without resetting) but they work great. My only complaint is that HomePod Software and tvOS updates tend to bork the devices until I reboot HA, but that takes 10 ish seconds so not a big deal. reply ex3ndr 14 hours agoparentprevThat is a super bad advice: most of the matter stuff simply unstable, very few devices. Apple's support is also subpar and unstable. reply CharlesW 13 hours agorootparentYeah, I can't relate to that at all. My Matter devices are more reliable than what they replaced (mostly switches and dimmers so far), and HomeKit support has \"just worked\". Matter's a 16-month-old baby, though, so YMMV. reply ars 12 hours agoparentprevThis is very bad advice. You should do the opposite of that. Buy Z-Wave devices and use them. They just work. Later, your Hub will add Tread/Matter support and you can do that too, but right now it's not worth the trouble. reply WaitWaitWha 9 hours agoprevI started domotics with X10, and migrated time to time to some newfangled solution once they stabilized. Right now, I use Home Assistant (HA) with Zigbee, Z-Wave, WiFi, BLE, and LoRa. Some talk directly to HA, some go to MQTT, some through ESPHome, some through HACS integrations. Current winners are Z-Wave and Zigbee. Both very much depend on the manufacturer's implementation. I have some Zigbee or Z-Wave devices that choke randomly, but provide too many niceties (I am looking at you Aqara). I am leery of WiFi solutions as many have noted. I block all access to the world, and on some sites where I have domotics, there is no internet most of the time. I have been delighted with Martin Jerry and Shelly WiFi switches. They work like fresh butter on a crispy garlic toast in a cold morning. Many others on the other hand are super heavy with outbound traffic. (Why does a thermostat need to \"check for firmware\" daily?) There is something about Matter that just puts me off. Not the technology mind you, but the invisible business posture on how Matter may end up functioning. \"You can use our Matter our device any way you want to and can connect to anything, as long as it goes through our Matter Commissioner first\"... alas, I might not have to worry about this maturing. reply ab_goat 18 hours agoprevI've been using Z-wave devices since 2017 for the following: 1. Dimmer lighting 2. Door sensors 3. Relays to customize radiant flooring better than thermostats 4. Seasonal lighting (outdoor string lights/Christmas tree) 5. Thermostat Overall it's been a good experience, however I think the SmartThings app is a pain in the butt and should be a much better experience. reply mlichvar 17 hours agoprevMy current understanding of the wireless technologies wrt to home automation: - wifi is most reliable, secure, easiest to debug, but usable only for mains-powered devices due to higher energy consumption - bluetooth LE has lowest energy consumption, best for unreliable broadcasting of data (e.g. temperature sensors), but has shorter range - zigbee is best for battery-powered devices where reliable communication is needed and is initiated by the device (e.g. switch, window/door sensor) - zwave is best for battery-powered devices which need to quickly receive data (e.g. door lock or directly controller radiator valves), but security seems problematic according to some reports reply burnerthrow008 17 hours agoparentRegardless of theory, my experience has been that WiFi communications are significantly less reliable than Zigbee or BLE, and typically have worse latency to boot. Unless you have a bunch of WiFi APs around your house, practical range with Zigbee is also better than WiFi because powered Zigbee nodes (like lightbulbs and switched outlets) act as mesh routers. One additional benefit of Zigbee and Wave is the possibility of creating battery-less devices, like the Philips Hue Tap switch, which uses a hammer and piezoelectric generator for power. reply santialbo 17 hours agoparentprevAdd to wifi that if you plan on having a lot of devices your router might commit seppuku. Zigbee can hold hundreds of devices (as long a you have zb routers in your mesh) reply zehaeva 19 hours agoprevI'm very privacy forward with respect to my home networks. I run a home zigbee network which does everything I want it to in the home. Yes I can't turn the lights on and off from the other side of the world, but neither can anyone else. reply marcus0x62 19 hours agoparentHome Assistant (or, really, any local HA controller) plus a VPN will allow you to control them from anywhere you have Internet connectivity without exposing anything to a cloud-based service. reply Medox 18 hours agorootparentOr a combination of HA + Telegram (bots) that will trigger and respond to a /, even with buttons. Maybe less secure than a VPN connection (e.g. if somebody gets control over the channel or bots instead of you/other trusted members) and of course more finicky until the bot works as desired, but always a nice party trick. Or a combination of VPN for home-critical automations and telegram bots for the simple/shared ones. reply srmarm 19 hours agoparentprevThere are still even ways to expose the zigbee stuff, I can turn my zigbee lights on from the other side of the world and even access it via Google Home but it's on my terms and under my control. The actual switch itself is relatively dumb (which is a positive in this case!) (not to say you're doing it wrong btw, just to let others know that zigbee can still be linked onwards to the internet from the gateway) reply HumblyTossed 18 hours agoparentprevBetween timers and motions sensors, I'm pretty much fully covered. There just isn't a reason for me to turn something on or off when I'm away. reply yesimahuman 13 hours agoprevMy zigbee devices are the best part of my smart home setup (with home assistant). They always work, battery life is ridiculous, and they’re interoperable. Have only had issues with one motion detector from a brand that has otherwise been rock solid. If I had only known about zigbee before I swore off smart home tech (instead of wifi and proprietary hubs) the last time I tried I would have had a lot more fun! reply password4321 4 hours agoprevRelated today: Home Assistant: Three years later https://news.ycombinator.com/item?id=39345122 reply t43562 13 hours agoprevI have had a rotten time so far trying to get anything to happen with my Tradfri lights - I started off assuming that all of this could be done from the commandline - no not without difficulty. How do you pair your computer's zigbee with the lightbulb? Who @#$#$ knows. The button - how do you EVER get that to pair or do you? I'm so hacked off with it I cannot go back and try again for a while but IMO it all has a very long way before it gets as simple even as bluetooth and that was always pretty horrible itself (from the commandline at least). reply wlesieutre 18 hours agoprevWhat happens if your gateway dies and has to be replaced? From what I've read, this theoretically can be done, but in practice you end up unlinking and migrating every device one by one. But it's been a few years since I looked into it, maybe someone has made improvements? Otherwise, this is a huge advantage of wifi-based smarthome devices. reply Klathmon 18 hours agoparentSo for zigbee this is very possible and I've recently done it multiple times without any issues whatsoever. I used to use a ConbeeII as my zigbee coordinator, but my server rack is located at an awful position in the house for coverage, so I picked up a TubeZB PoE EFR32 based coordinator [1] which has been incredible! I use home assistant, and it was trivial to backup the network, unplug the ConbeeII, put in the IP address of the new coordinator, and import the backup there and everything just continued to work. Then I had that die, it was actually the PoE portion which died, so I did the reverse and transferred everything back to my ConbeeII while I diagnosed and fixed it, then when it was fixed transferred everything back to the TubeZB coordinator. It actually took longer to get the IP address assigned on the TubeZB coordinator than it did to transfer my network each time, it was incredibly simple. I'm not sure for z-wave though. I do use it, but I've never had a z-wave gateway die on me, or had any reason to replace it where I wasn't also moving or something. [1] https://tubeszb.com/product/efr32-mgm21-poe-coordinator/ reply wlesieutre 18 hours agorootparentGood to know! One of the more specific things I was wondering is that when you relinked everything if HA would forget what's what or if it would hook the devices back up to all their automations afterward. I have some Hue bulbs which are Zigbee, but I've been considering getting out of Hue's ecosystem for controlling them. reply Klathmon 18 hours agorootparentThe names seemed to reset for some of my zigbee devices (interestingly not all of them, just some of them, it's likely something else going on and unrelated but I don't know for sure), but they still work in their original automations and in my UI everywhere that I have them. reply LeafItAlone 18 hours agoparentprevI just replaced my Ikea hub (changed from Tradfri to Dirigera). It was annoying to do, but not hard. Took about ~90 seconds for each device. I did them individually, but I could have done them in parallel to speed it up. Not something I want to do once a month, but once every two years is “reasonable” (compared to non-smart home items). reply rlpb 9 hours agoparentprevAIUI, at protocol level, Z-Wave supports multiple controllers and if you have two and one dies then you can switch to the other and replace the first. I can't see consumers arranging that though, and nor do I know how to do it. reply mannyv 17 hours agoparentprevI believe the re-pair process is a side effect of how security was implemented. I also heard it was technically possible to migrate without pairing, but i think right now it's between hubs from the same manufacturer. It's been years since i checked. reply alistairSH 17 hours agoparentprevZwave devices definitely seem to be \"sticky\" - you have to unpair/pair each device. At least that's been my experience using Zwave with a Smartthings hub. reply sdflhasjd 17 hours agoprevWhen I started I had a good mix of all 3 (WiFi, Zigbee & Z-wave). 5 years layer, everything's slowly been absorbed into Zigbee. WiFi isn't a mesh network, so there's extremities with poor reliability. Z-wave just seemed to suffer from poor device availability, and everything turned out to be more expensive with no real benefit. Also, one other thing to mention with WiFi and Bluetooth is how it's basically a massive red flag, a stamp of \"hey, this device needs our shit app to use.\" It's just a shame there's no Zigbee ESP32 equivalent for all my hobby bits. reply shellfishgene 13 hours agoparentThere is [1], but it's not open source and 'advanced' functions, like battery operation, cost money. Also this [2] project is promising, but in the early stages I think. Also I guess newer ESP32 support zigbee in principle, there is some discussion of adding this to ESPHome. [1] https://ptvo.info/zigbee-configurable-firmware-features/ [2] https://github.com/ffenix113/zigbee_home reply walth 8 hours agoprev> Z-Wave is in some ways the better pick going forward Z-Wave unfortunately is already dead. The legacy certification process, the higher cost chips, and the global frequency bifurcation. reply the_mitsuhiko 11 hours agoprevZigbee continues to be the only reliable thing in my household. I switched to the IKEA Dirigera hub for most of it and it's pretty stable. Cannot say that about almost anything else and I tried a lot. reply cqqxo4zV46cp 19 hours agoprevAmen to this. So many ‘smart home’ battles end up being WiFi battles. Zigbee is itself not perfect, but I’d much prefer to deal with Zigbee problems instead of propitiatory-protocol-and-app-probably-using-a-cloud-service-over-WiFi problems any day of the week. reply alright2565 19 hours agoparentIt's the opposite for me. I have so many problems with Zigbee devices dropping off the mesh for no reason and batteries dying in 1/10th the advertised time. Meanwhile my ESPHome devices have never had any issue whatsoever. reply blagie 18 hours agorootparentESPHome is fine, but it's not representative of what people mean by \"wifi devices.\" Most wifi devices require a proprietary app, sweep up your data to some fly-by-night operation, stop working during an internet outage, don't interoperate between vendors, \"call home,\" and yet never receive security updates. Technically, it's 802.11, but by design, ESPHome is closer to Zigbee with a different underlying interface (802.11 rather than 802.15) than it is to most wifi devices. It's 100% open, simple, documented, reliable, etc. I'd be fine with wifi devices if they were ESPHome underneath. Heck, I'd probably set up a separate network for HomeAssistant and IoT. To that point, one major upside of 802.15 over 802.11 is battery life. I don't have any battery-powered 802.11 devices. It is possible to power zigbee devices from mains, and on my to do list at some point is to move a few of them from batteries to external power. reply wkat4242 19 hours agoparentprevIf you have a lot of it it's an ever ongoing war with empty batteries and lost pairing though. Every week I have to fix some switch, temperature or door sensor... reply anonuser1234 17 hours agoprevI actually went down the zigbee rabbit hole with my house last week. I tried the best selling zigbee motion sensors on amazon, however, they only worked within line of sight of the zigbee antenna. I then tried the Phillips hue motion sensors. They worked flawlessly throughout my home. reply apapapa 12 hours agoprevSo functionality isn't the best part of your smart home? For me it is a wirelessly-controlled deadbolt reply malermeister 18 hours agoprevZigbee and Z-Wave are the best, I agree. Inherently local-only, so no cloud that sends your data god knows where and can be turned off without any notice. A standard system, so you can buy stuff from any manufacturer and be sure it works with your hub. It's what smart home should be. reply alistairSH 17 hours agoparentThe only \"catch\" is if you want to use a voice assistant/smart speaker, which is either built into the hub, or requires a integration. reply r2_pilot 17 hours agorootparentI rolled my own several years ago with Voice Attack and python reply malermeister 17 hours agorootparentrhasspy is a popular open source solution - I've used it before, but I'm not sure if it's still in development reply m463 11 hours agoprevquestion - what system would you recommend for people in high density housing? reply otterley 18 hours agoprevI would very much like to adopt Zigbee at home since it has the privacy and reliability features I want. The problem is the market: there just aren’t enough equipment options out there, and the few that are available are nontrivial to acquire (and who knows how long the vendors will survive). Sure, I can get some light switches, but not at my local home supply. And light switches are just one type of controller. I’ve got shades, door locks, thermostats, and more. The choices are so few. Sure, maybe an example exists, but if I don’t like the ergonomics or style, well, too bad. It’s like shopping in the former Soviet Union. reply hiddencost 17 hours agoprevI've been using zigbee for industrial applications. The security angle is particularly appreciated by a factory that wants to control their vents from one button without running tons of copper wiring. They're not going to put that on their network. reply apapapa 11 hours agoparentIf their only worry is using less copper, I am worried. reply eternityforest 7 hours agorootparentIf it's done well, less copper might mean easy maintenance, more room for other stuff, extensibility, etc. \"one wire per thing\" installations move the difficulty out of the software and onto physically keeping track of all those wires. reply sitzkrieg 17 hours agoprev [–] becoming more and more impressed at the number of devices being crammed into each home clogging up the already decimated ism bands reply eternityforest 6 hours agoparent [–] But at the same time more and more stuff that actually uses heavy bandwidth is moving out into 5GHz and other high frequency bands. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author acknowledges their mistake of overlooking Zigbee and Z-Wave technology in their smart home setup and praises their reliability compared to other standards.",
      "They highlight Philips Hue bulbs as an example of a device that consistently and seamlessly operates on its own network.",
      "The author also shares a positive experience reviewing the Homey Pro hub, which utilizes Zigbee and Z-Wave technology."
    ],
    "commentSummary": [
      "The discussion revolves around the pros and cons of using Zigbee, Z-Wave, WiFi, Thread, and Matter for smart home devices.",
      "Users share their experiences and opinions on reliability, interoperability, compatibility, and privacy concerns associated with the different protocols and devices.",
      "Important factors such as mesh networking, battery life, and local control are also discussed, but there is no unanimous agreement among users as their preferences and experiences with each technology vary."
    ],
    "points": 162,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1707746297
  }
]
