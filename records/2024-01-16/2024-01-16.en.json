[
  {
    "id": 39001755,
    "title": "Mastering Programming: The Importance of Time, Practice, and Hands-on Learning",
    "originLink": "https://norvig.com/21-days.html",
    "originBody": "Teach Yourself Programming in Ten Years Peter Norvig Why is everyone in such a rush? Walk into any bookstore, and you'll see how to Teach Yourself Java in 24 Hours alongside endless variations offering to teach C, SQL, Ruby, Algorithms, and so on in a few days or hours. The Amazon advanced search for [title: teach, yourself, hours, since: 2000 and found 512 such books. Of the top ten, nine are programming books (the other is about bookkeeping). Similar results come from replacing \"teach yourself\" with \"learn\" or \"hours\" with \"days.\" The conclusion is that either people are in a big rush to learn about programming, or that programming is somehow fabulously easier to learn than anything else. Felleisen et al. give a nod to this trend in their book How to Design Programs, when they say \"Bad programming is easy. Idiots can learn it in 21 days, even if they are dummies.\" The Abtruse Goose comic also had their take. Let's analyze what a title like Teach Yourself C++ in 24 Hours could mean: Teach Yourself: In 24 hours you won't have time to write several significant programs, and learn from your successes and failures with them. You won't have time to work with an experienced programmer and understand what it is like to live in a C++ environment. In short, you won't have time to learn much. So the book can only be talking about a superficial familiarity, not a deep understanding. As Alexander Pope said, a little learning is a dangerous thing. C++: In 24 hours you might be able to learn some of the syntax of C++ (if you already know another language), but you couldn't learn much about how to use the language. In short, if you were, say, a Basic programmer, you could learn to write programs in the style of Basic using C++ syntax, but you couldn't learn what C++ is actually good (and bad) for. So what's the point? Alan Perlis once said: \"A language that doesn't affect the way you think about programming, is not worth knowing\". One possible point is that you have to learn a tiny bit of C++ (or more likely, something like JavaScript or Processing) because you need to interface with an existing tool to accomplish a specific task. But then you're not learning how to program; you're learning to accomplish that task. in 24 Hours: Unfortunately, this is not enough, as the next section shows. Teach Yourself Programming in Ten Years Researchers (Bloom (1985), Bryan & Harter (1899), Hayes (1989), Simmon & Chase (1973)) have shown it takes about ten years to develop expertise in any of a wide variety of areas, including chess playing, music composition, telegraph operation, painting, piano playing, swimming, tennis, and research in neuropsychology and topology. The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again. There appear to be no real shortcuts: even Mozart, who was a musical prodigy at age 4, took 13 more years before he began to produce world-class music. In another genre, the Beatles seemed to burst onto the scene with a string of #1 hits and an appearance on the Ed Sullivan show in 1964. But they had been playing small clubs in Liverpool and Hamburg since 1957, and while they had mass appeal early on, their first great critical success, Sgt. Peppers, was released in 1967. Malcolm Gladwell has popularized the idea, although he concentrates on 10,000 hours, not 10 years. Henri Cartier-Bresson (1908-2004) had another metric: \"Your first 10,000 photographs are your worst.\" (He didn't anticipate that with digital cameras, some people can reach that mark in a week.) True expertise may take a lifetime: Samuel Johnson (1709-1784) said \"Excellence in any department can be attained only by the labor of a lifetime; it is not to be purchased at a lesser price.\" And Chaucer (1340-1400) complained \"the lyf so short, the craft so long to lerne.\" Hippocrates (c. 400BC) is known for the excerpt \"ars longa, vita brevis\", which is part of the longer quotation \"Ars longa, vita brevis, occasio praeceps, experimentum periculosum, iudicium difficile\", which in English renders as \"Life is short, [the] craft long, opportunity fleeting, experiment treacherous, judgment difficult.\" Of course, no single number can be the final answer: it doesn't seem reasonable to assume that all skills (e.g., programming, chess playing, checkers playing, and music playing) could all require exactly the same amount of time to master, nor that all people will take exactly the same amount of time. As Prof. K. Anders Ericsson puts it, \"In most domains it's remarkable how much time even the most talented individuals need in order to reach the highest levels of performance. The 10,000 hour number just gives you a sense that we're talking years of 10 to 20 hours a week which those who some people would argue are the most innately talented individuals still need to get to the highest level.\" So You Want to be a Programmer Here's my recipe for programming success: Get interested in programming, and do some because it is fun. Make sure that it keeps being enough fun so that you will be willing to put in your ten years/10,000 hours. Program. The best kind of learning is learning by doing. To put it more technically, \"the maximal level of performance for individuals in a given domain is not attained automatically as a function of extended experience, but the level of performance can be increased even by highly experienced individuals as a result of deliberate efforts to improve.\" (p. 366) and \"the most effective learning requires a well-defined task with an appropriate difficulty level for the particular individual, informative feedback, and opportunities for repetition and corrections of errors.\" (p. 20-21) The book Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life is an interesting reference for this viewpoint. Talk with other programmers; read other programs. This is more important than any book or training course. If you want, put in four years at a college (or more at a graduate school). This will give you access to some jobs that require credentials, and it will give you a deeper understanding of the field, but if you don't enjoy school, you can (with some dedication) get similar experience on your own or on the job. In any case, book learning alone won't be enough. \"Computer science education cannot make anybody an expert programmer any more than studying brushes and pigment can make somebody an expert painter\" says Eric Raymond, author of The New Hacker's Dictionary. One of the best programmers I ever hired had only a High School degree; he's produced a lot of great software, has his own news group, and made enough in stock options to buy his own nightclub. Work on projects with other programmers. Be the best programmer on some projects; be the worst on some others. When you're the best, you get to test your abilities to lead a project, and to inspire others with your vision. When you're the worst, you learn what the masters do, and you learn what they don't like to do (because they make you do it for them). Work on projects after other programmers. Understand a program written by someone else. See what it takes to understand and fix it when the original programmers are not around. Think about how to design your programs to make it easier for those who will maintain them after you. Learn at least a half dozen programming languages. Include one language that emphasizes class abstractions (like Java or C++), one that emphasizes functional abstraction (like Lisp or ML or Haskell), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), and one that emphasizes parallelism (like Clojure or Go). Remember that there is a \"computer\" in \"computer science\". Know how long it takes your computer to execute an instruction, fetch a word from memory (with and without a cache miss), read consecutive words from disk, and seek to a new location on disk. (Answers here.) Get involved in a language standardization effort. It could be the ANSI C++ committee, or it could be deciding if your local coding style will have 2 or 4 space indentation levels. Either way, you learn about what other people like in a language, how deeply they feel so, and perhaps even a little about why they feel so. Have the good sense to get off the language standardization effort as quickly as possible. With all that in mind, its questionable how far you can get just by book learning. Before my first child was born, I read all the How To books, and still felt like a clueless novice. 30 Months later, when my second child was due, did I go back to the books for a refresher? No. Instead, I relied on my personal experience, which turned out to be far more useful and reassuring to me than the thousands of pages written by experts. Fred Brooks, in his essay No Silver Bullet identified a three-part plan for finding great software designers: Systematically identify top designers as early as possible. Assign a career mentor to be responsible for the development of the prospect and carefully keep a career file. Provide opportunities for growing designers to interact and stimulate each other. This assumes that some people already have the qualities necessary for being a great designer; the job is to properly coax them along. Alan Perlis put it more succinctly: \"Everyone can be taught to sculpt: Michelangelo would have had to be taught how not to. So it is with the great programmers\". Perlis is saying that the greats have some internal quality that transcends their training. But where does the quality come from? Is it innate? Or do they develop it through diligence? As Auguste Gusteau (the fictional chef in Ratatouille) puts it, \"anyone can cook, but only the fearless can be great.\" I think of it more as willingness to devote a large portion of one's life to deliberative practice. But maybe fearless is a way to summarize that. Or, as Gusteau's critic, Anton Ego, says: \"Not everyone can become a great artist, but a great artist can come from anywhere.\" So go ahead and buy that Java/Ruby/Javascript/PHP book; you'll probably get some use out of it. But you won't change your life, or your real overall expertise as a programmer in 24 hours or 21 days. How about working hard to continually improve over 24 months? Well, now you're starting to get somewhere... References Bloom, Benjamin (ed.) Developing Talent in Young People, Ballantine, 1985. Brooks, Fred, No Silver Bullets, IEEE Computer, vol. 20, no. 4, 1987, p. 10-19. Bryan, W.L. & Harter, N. \"Studies on the telegraphic language: The acquisition of a hierarchy of habits. Psychology Review, 1899, 8, 345-375 Hayes, John R., Complete Problem Solver Lawrence Erlbaum, 1989. Chase, William G. & Simon, Herbert A. \"Perception in Chess\" Cognitive Psychology, 1973, 4, 55-81. Lave, Jean, Cognition in Practice: Mind, Mathematics, and Culture in Everyday Life, Cambridge University Press, 1988. Answers Approximate timing for various operations on a typical PC: execute typical instruction 1/1,000,000,000 sec = 1 nanosec fetch from L1 cache memory 0.5 nanosec branch misprediction 5 nanosec fetch from L2 cache memory 7 nanosec Mutex lock/unlock 25 nanosec fetch from main memory 100 nanosec send 2K bytes over 1Gbps network 20,000 nanosec read 1MB sequentially from memory 250,000 nanosec fetch from new disk location (seek) 8,000,000 nanosec read 1MB sequentially from disk 20,000,000 nanosec send packet US to Europe and back 150 milliseconds = 150,000,000 nanosec Appendix: Language Choice Several people have asked what programming language they should learn first. There is no one answer, but consider these points: Use your friends. When asked \"what operating system should I use, Windows, Unix, or Mac?\", my answer is usually: \"use whatever your friends use.\" The advantage you get from learning from your friends will offset any intrinsic difference between OS, or between programming languages. Also consider your future friends: the community of programmers that you will be a part of if you continue. Does your chosen language have a large growing community or a small dying one? Are there books, web sites, and online forums to get answers from? Do you like the people in those forums? Keep it simple. Programming languages such as C++ and Java are designed for professional development by large teams of experienced programmers who are concerned about the run-time efficiency of their code. As a result, these languages have complicated parts designed for these circumstances. You're concerned with learning to program. You don't need that complication. You want a language that was designed to be easy to learn and remember by a single new programmer. Play. Which way would you rather learn to play the piano: the normal, interactive way, in which you hear each note as soon as you hit a key, or \"batch\" mode, in which you only hear the notes after you finish a whole song? Clearly, interactive mode makes learning easier for the piano, and also for programming. Insist on a language with an interactive mode and use it. Given these criteria, my recommendations for a first programming language would be Python or Scheme. Another choice is Javascript, not because it is perfectly well-designed for beginners, but because there are so many online tutorials for it, such as Khan Academy's tutorial. But your circumstances may vary, and there are other good choices. If your age is a single-digit, you might prefer Alice or Squeak or Blockly (older learners might also enjoy these). The important thing is that you choose and get started. Appendix: Books and Other Resources Several people have asked what books and web pages they should learn from. I repeat that \"book learning alone won't be enough\" but I can recommend the following: Scheme: Structure and Interpretation of Computer Programs (Abelson & Sussman) is probably the best introduction to computer science, and it does teach programming as a way of understanding the computer science. You can see online videos of lectures on this book, as well as the complete text online. The book is challenging and will weed out some people who perhaps could be successful with another approach. Scheme: How to Design Programs (Felleisen et al.) is one of the best books on how to actually design programs in an elegant and functional way. Python: Python Programming: An Intro to CS (Zelle) is a good introduction using Python. Python: Several online tutorials are available at Python.org. Oz: Concepts, Techniques, and Models of Computer Programming (Van Roy & Haridi) is seen by some as the modern-day successor to Abelson & Sussman. It is a tour through the big ideas of programming, covering a wider range than Abelson & Sussman while being perhaps easier to read and follow. It uses a language, Oz, that is not widely known but serves as a basis for learning other languages. < Notes T. Capey points out that the Complete Problem Solver page on Amazon now has the \"Teach Yourself Bengali in 21 days\" and \"Teach Yourself Grammar and Style\" books under the \"Customers who shopped for this item also shopped for these items\" section. I guess that a large portion of the people who look at that book are coming from this page. Thanks to Ross Cohen for help with Hippocrates.Translations Thanks to the following authors, translations of this page are available in: Arabic (Mohamed A. Yahya) Bulgarian (Boyko Bantchev) Chinese (Xiaogang Guo) Croatian (Tvrtko Bedekovic) Esperanto (Federico Gobbo) French (Etienne Beauchesne) German (Stefan Ram) Hebrew (Eric McCain) Hindi (Vikash Tiwari) Hungarian (Marton Mestyan) Indonesian (Tridjito Santoso) Italian (Fabio Z. Tessitore) Japanese (yomoyomo) Korean (John Hwang) Persian (Mehdi Asgari) Polish (Kuba Nowak) Portuguese (Augusto Radtke) Romanian (Ştefan Lazăr) Russian (Konstantin Ptitsyn) Serbian (Lazar Kovacevic) Spanish (Carlos Rueda) Slovak (Jan Waclawek) Turkish (Çağıl Uluşahin) Ukranian (Oleksii Molchanovskyi) Peter Norvig (Copyright 2001—2014)",
    "commentLink": "https://news.ycombinator.com/item?id=39001755",
    "commentBody": "Teach Yourself Programming in Ten Years (1998) (norvig.com)497 points by janchorowski 18 hours agohidepastfavorite262 comments miiiiiike 13 hours agoI bought a copy of \"Sams Teach Yourself C++ in 24 Hours\" at a CompUSA in 1999. The guy at the checkout looked at it, laughed, and told me about this article. When I was 16 I was looking at programming books at Borders and a guy handed me a copy of \"The C Programming Language\"; changed my life. So much of my career has been shaped by running into developers or just people interested in programming out in the world. Thanks. reply bluedino 11 hours agoparent>> I bought a copy of \"Sams Teach Yourself C++ in 24 Hours\" at a CompUSA Some of those books were laughably bad. But thing I miss from back then, was the feeling that the book was going to be the key to getting you started writing whatever crazy idea you had for a program in your head. I think the last time I had that feeling was walking out of Microcenter with a new MacBook and an iPod Touch, ready to make the next Angry Birds... reply jamesbfb 11 hours agorootparent> But thing I miss from back then, was the feeling that the book was going to be the key to getting you started writing whatever crazy idea you had for a program in your head. Yes! I miss it too. For me, that book was Head First PHP & MySQL[0] - Late 2000's, I was living and working in Thailand for a family friends small logistics company in the capacity of a BA, trying to move them into this century. We were trying to find a vendor for any system that would allow us to keep track of the movements of shipping containers within a container yard, and something sparked and I thought \"hey, I did a semester of programming at Uni, how hard can it be?!\", over the span of the next 6 months or so, this book helped me put together a solution that scarily, they are still using to this day. Fast-forward 15ish years and here I am, still cutting code, although in the capacity of a dev lead, but after all that, I have the book to thank. [0]https://www.oreilly.com/library/view/head-first-php/97805961... reply pcchristie 8 hours agorootparentHow long did it take you to learn what you needed to learn, and how long to \"ship\" your \"product\"? reply jamesbfb 22 minutes agorootparentIIRC, 3 months to hack together a CRUD like app, another 3 to “ship” the “product”, and yes, quotes very much intended. I did spend the next year or so adding features, bug fixes, etc. It was very much a case of learning on the job and I was quite fortunate to be in the position that I was. I think it was 2 or 3 years later I managed to land a dev role at Agoda (who had offices in Bangkok at the time) reply miiiiiike 10 hours agorootparentprevI know exactly what you mean. Felt like the world was opening up. I don't know who it was, it might have been one of the guys my dad worked with, be they said \"You won't be able to write a game with a book like that, but you might be able to write a phone directory.\" Didn't phase me. I remember someone asking me later on if I was going to write a game. I just looked at them blankly and said: \"I'm going to write a phone directory\". I just learned today that \"Sams Teach Yourself C++ in 24 Hours\" was co-written by Jessee Liberty, one of my all-time favorite technical book writers. \"Programming C#, 2nd Edition\" was a great book. I loved tech stores too. I still have all of the Apple pamphlets that CompUSA had sitting next to the display units. reply guiambros 7 hours agorootparentCompUSA and Borders have a special place in my heart. I'm from a 3rd world country, so visiting them was a sacred ritual anytime I had the privilege to visit the US. I always brought an extra bag mostly for books, and sometimes a Sound Blaster, some extra memory or a US Robotics card, or a fancy Handspring Visor and some Dreamcast games :) reply jonathanlydall 5 hours agorootparentBack when Creative Labs was a company deserving of consumer support, nowadays I actively avoid them completely. reply tombert 11 hours agorootparentprevI actually didn't think that the Sams books were so bad, albeit a bit misleading if you think you're really gonna grok C or C++ in 24 hours. I learned C first in high school because I found a pirated copy of \"Learn C in 24 Hours\" online, and I actually felt that they did a reasonably good job getting me started, though if I recall correctly some of their examples with pointers and memory management were actually incorrect. Still, it was enough to make programming interesting to me, and when I dropped out of college the first time I was able to salvage a somewhat decent career because of that interest. reply phs318u 8 hours agorootparentAh the Sams books. I once thought that writing tech books was going to be a career (having contributed a single chapter to “Microsoft SQL Server Programming Unleashed” by Papa, Shepker et al. I was one of the Al’s). I think the “in 24 hours” thing was more a case of “I’m going to tell you everything I know about XYZ in 24 hours”. Still, I have so many fond memories from the late 80s and 90s spending countless lunchtimes at McGills or the Technical Bookshop in Melbourne (now since long gone), flipping through tech magazines and wondering which of the many weighty tech tomes I’d spend my precious hard-earned on. reply ozim 10 hours agorootparentprevFor me that is a nice discussion on its own - for me there’s multiple levels of knowing X - so anything, Yes in 24h you are not going to learn enough to contribute to Linux kernel - but also will be ahead of something like 80% of general population. reply mentos 11 hours agoparentprevFor me it was \"Visual Basic Professional 3.0 Programming by Thomas W. Torgerson\" from Barnes and Nobles in 1997. I had downloaded Visual Basic 3.0 from 100 different email attachments on AOL and wanted to learn how to make punters/progs. I remember transcribing code from the book to attempt to play a sound file when my program opened. I remember being stunned when it actually worked! What an honor it has been to make a career in software development since. reply cfeduke 10 hours agorootparentHaha yes, similar for me. It was word scramblers as games in AOL chat rooms that lead me to my love of programming... and of course Visual Basic 3.0. What an amazing product back then. reply growingkittens 9 hours agoparentprev> So much of my career has been shaped by running into developers or just people interested in programming out in the world. This is probably less common now, but remember not to laugh at young girls in the programming section of a bookstore. In the 90s, that was a pretty standard response: no advice, just incredulity. reply MrVandemar 5 hours agorootparent> remember not to laugh at young girls in the programming section of a bookstore I can't believe anyone needs a reminder to act like an actual human being, much less not to belittle someone -- anyone! -- who is interested in learning anything constructive. Unbelievable that anyone, ever, would act that way. reply jonathanlydall 5 hours agorootparentSadly it’s almost always “learned” from (or actively “taught” by) others, mostly parents or peers who themselves learned it from parents. Children/young adults aren’t even necessarily aware that their behaviour is inappropriate as it’s “normal” based on what they’ve seen happen around them their whole lives. Adults should know better, but may do it anyway due to the human tendency to often dig their feet in, or consciously/actively do it for a reason which really has nothing to with the persecuted group. Bigotry/racism/sexism persevere largely due to the above. reply noneeeed 11 hours agoparentprevOne of the hills on which I am prepared to die on is that \"The C Programming Language\" is the best programming language book I've ever read. Every developer should read it and learn C at least once, even if they promptly forgot it all. reply bch 11 hours agorootparentYou’re not going to die on that hill. There are so many people that share your opinion that you might have trouble finding space, but you’re not going to die on that hill. reply lannisterstark 3 hours agorootparentJavelins have an easier time finding people if there are a lot of them on a hill. So someone will. reply hinkley 13 hours agoparentprevI miss CompUSA. I still firmly believe that the move to transparent bags is what killed them. For me it ruined my annual tradition of buying Christmas presents while family was next door in another store, but I’m sure for others it was being treated like a criminal. Those magnetic readers aren’t great but they aren’t in your face. Once I stopped going in routinely I stopped going in at all. reply neilv 10 hours agorootparentThe CompUSA that opened in Cambridge, MA, had a guard who insisted on checking your purchases after the registers, like you were a criminal, or implying it was a crime-heavy area. Not the kind of insult or atmosphere anyone should have to put up with, and, further, the generally affluent people of Harvard and MIT, which the store was located right between, weren't accustomed to it. I called this out in 2000, when I made Web page about assembling PCs, during the rise of Web ecommerce retail. https://www.neilvandyke.org/cheap-pc-2000/ > I actually spent a lot of time checking out the local vendors, but was generally dissatisfied, and used them only as a last resort. If you're in Cambridge, MA, USA, some vendors I looked at: PCs for Everyone (informative Web site, but long waits at their showroom, and they didn't have a floppy drive after I'd waited 30 minutes), MicroCenter (large superstore, mailorder generally has better prices, didn't have advertised CD-RW drives in stock, the three of the four things I bought there were somehow defective), BestBuy (very poor component selection, guards at the entryways), and CompUSA (smaller version of MicroCenter, guard at front door insists upon comparing every shopper's purchases to their receipt as they leave). So much for brick&mortar service. > UPDATE 2018-12-10: MicroCenter brick&mortar has risen to the challenge, and is now my overall favorite source for PC parts. reply kstrauser 4 hours agorootparentStill better than Circuit City. I bought a graphics card there once. It was dead on arrival. I took it back to the store to exchange it, but that was their last one. I asked for a refund then, and they told me about their restocking fee. The kindly offered to give me 100% credit to another card that was twice as expensive. That was the only time I’ve been asked to “sir, please keep your voice down” and “sir, we need you to leave”. I still think I was on the right side of that one. My credit card company eventually handled it for me. reply paulddraper 11 hours agorootparentprevReally? It hasn't killed Costco yet. reply jjtheblunt 11 hours agorootparentIs family ever in the store next to Costco (which is a null pointer exception), such that meeting on foot with clear bags holding presents is no longer secret? I think that’s the challenge he described. reply obmelvin 2 hours agorootparentIt seems unlikely to me that the majority of CompUSA purchases were presents while running errands with the recipient. reply paulddraper 3 hours agorootparentprevI'm talking about the other thing reply williamcotton 9 hours agoparentprevI had my dad buy me a copy of Teach Yourself HTML in 24 Hours at a CompUSA and wouldn't you know, it was true! I had https://web.archive.org/web/19970415190140/http://www2.rpa.n... up and running in no time! reply nullhole 9 hours agorootparentLooks great! Reminds me of some of my early classics! reply nmfisher 8 hours agorootparentYou forgot , which was my bread and butter as a 12 year old. Bonus points if it’s wrapped inside . reply petesergeant 7 hours agorootparenthttps://web.archive.org/web/20091018220958/http://www.geocit... endlessly reply dpola 2 hours agoparentprevI must say that for myself, I still learn/reference many things from programming books... Mostly Perl and Java, but none of them have promise of teaching me programming in any time interval. Rarely do I ask for help online as I was ridiculed for most of the time. Nowadays, if paper is insufficient I consult with the AI, but I still refuse to use copilot. reply miiiiiike 29 minutes agoparentprevMight have been 2001. reply julesallen 9 hours agoparentprevLove reading the comments here and how these books changed lives. For me it was dBASE III PLUS programmer's reference guide from 1987 and it imparted enough knowledge to start a programming career. Read that dog eared thing end to end and still have it in my book collection. Thank you, Alan Simpson wherever you might be. reply insane_dreamer 4 hours agorootparentmy first book as well; good memories reply stouset 12 hours agoparentprevI got started buying Borland C++ Builder in… 1997, I think, and read the book that came with it which was similarly named. It was quite bad, I remember the chapter on pointers more or less said “I can’t explain why you’d want to use them, but when you find a situation that requires them you’ll know you need them” or something like that. reply ilaksh 4 hours agoparentprevMy intro to programming was \"Getting Started with Extended Color BASIC\" for the Coco 2. Another favorite book was Turbo Pascal DiskTutor. My C++ book was C++ How to Program. reply highwaylights 11 hours agoparentprevStill, I kind of feel like I want to print a fake “Teach yourself open-heart quadruple bypass surgery in 24 hours” sleeve and leave it on the shelf to see what happens. reply zozbot234 11 hours agoparentprevI wonder who's going to write the \"Teach yourself Rust from scratch in 21 days\" book. If C and even C++ can be learnt effectively as a first programming language, there's little reason why Rust couldn't be. And if not Rust, maybe Golang could play that role. reply josephg 2 hours agorootparentGolang yes, but not rust. I think rust is a terrible beginner language. Despite having decades of experience it took me about a month to feel productive in rust and stop “fighting the borrow checker”. I learned Go in about 12 hours. Let beginners cut their teeth on stuff like Python and Go. Rust can wait. reply sn9 11 hours agorootparentprevThe Rust book is basically that. An hour per day would probably get you through it in good time. reply zozbot234 11 hours agorootparentTRPL assumes familiarity with some existing programming language, such that much of its focus is how Rust differs from more common languages. A true \"from scratch\" book would probably first teach idiomatic Rust as something not too different from a pure functional language (in that the default approach in Rust is to pass objects by value and forbid all shared mutable state, just like FP languages do) and introduce interior mutability subsequently as a way of supporting more \"imperative\" patterns of coding. reply nyjah 11 hours agoparentprevI used to love standing at borders looking at all the computer books. I still have my copies of Ivor Hortons beginning C and beginning c++. I never see that guy getting love in the programming author world, but that was my guy when I was a teen. reply pipes 11 hours agorootparentI still love going to the bookshop and looking at the programming books! (I'm in my 40s) reply jprd 11 hours agoparentprevSheet. Thank YOU for that comment! It connected me back to some of that magic. The same magic at \"computer fairs (faires)\". That same magic when you happened across that other nerd in the college/school lab doing something cool and subversive. reply ainiriand 11 hours agoparentprevBoy I had the same book that I borrowed from a friend. I was truly in love with that book and went over it a few times. My friend ended up giving it to me as a present, something that truly shaped who I am now. reply esafak 10 hours agoparentprevWow, what a checkout guy! reply miiiiiike 10 hours agorootparentHe also had a bunch of thoughts on the CD burner I was buying. reply itronitron 11 hours agoparentprevUnfortunately \"The C Programming Language\" has enough typographical errors in it to seriously undermine it's utility as a book with which to learn programming. reply trealira 10 hours agorootparentWhat are the typographical errors? I didn't think it had any. It does use features of C89 that may not compile after C99, but those aren't weird. But, as someone who actually did try to use K&R to teach themselves to program, I agree it's not ideal for that. It's definitely not the best programming book ever, which some people say. The exercises are pretty good, though. reply itronitron 1 hour agorootparentIn the section on Pointers and Addresses there are a few spots where the pointer or dereference operator is not included in the code examples. reply layer8 10 hours agorootparentprevThe first edition maybe? reply jprival 6 hours agoparentprevMy first ever programming book, a well-intentioned gift from my parents, was “Sam’s Teach Yourself C++ in 10 Minutes” - meant of course as a quick reference but always conceptually funny to me because… it’s C++. reply fud101 3 hours agoparentprevi bought two books in 2000 at 17, same as you, the sams teach yourself C and C++ for dummies. Small world. thanks for sharing! reply medler 16 hours agoprevThis essay holds a special place in my heart, since I first read it as a teenager when I was just starting to learn to code. Re-reading it now, I was surprised to see references to Malcom Gladwell, since I didn’t remember Outliers becoming a thing until much later. Then when I saw the reference to Ratatouille, I realized the article had been updated since its posting in 1998. The original is still available on archive and is significantly shorter: https://web.archive.org/web/19980206223800/https://norvig.co... Respect to Peter Norvig for continuing to edit his posts over the years. reply smburdick 12 hours agoparentI resent Gladwell to this day, possibly because I was assigned to read him in high school. He is quoted too much -- the 10,000 hours thing is just a meme at this point, for me anyway. reply medler 8 hours agorootparentOh I agree 100%, the 10,000 hours thing is a cliché and the popular interpretation that 10,000 hours of an activity equals mastery has been throughly debunked. I roll my eyes whenever I see it mentioned. I’m giving Norvig a pass here because I don’t remember it being such a cliché in 2008, and because I appreciate the point he’s making about the importance of practice. (Early in my programming education I often felt that I might just not be cut out for programming, and I wish more articles at the time had emphasized that it takes a lot of practice to become a good programmer). reply CSMastermind 3 hours agorootparentprevThe breaking point for me was when someone linked me to his podcast where it's clear that he either hasn't done much diligence or is obviously ignoring information to tell a better story. It's painful and made me really question anything he puts into his books. reply peterfirefly 10 hours agorootparentprevNot to mention the whole Igon Value Problem. reply pingswept 6 hours agorootparentThat sentence shocked me. It was the last Gladwell sentence I read. reply smburdick 9 hours agorootparentprevHow can AI be unethical? There's eigen-values everywhere! reply CPLX 10 hours agorootparentprevHe’s really just the physical world manifestation of the idea that “For every complex problem there is an answer that is clear, simple, and wrong.” reply ipnon 15 hours agoparentprevI can see myself now, reading this in the university library computer lab a decade ago. And now I've taught myself programming. The journey was much more difficult and winding than I was imagining it back then! reply Bagged2347 13 hours agorootparentAs someone who doesn't have a traditional CS background and is on a similar journey, I'd love to know: do you have any advice or insights to share? reply ipnon 11 hours agorootparentTo succeed takes 3,650 days. To give up only takes 1. Practice, practice, and practice some more. reply froh 12 hours agoparentprevbefore \"outliers\" there was \"the tipping point\" and \"blink\" reply smburdick 14 hours agoprevI am at times more of a book learner, but find that attitude is often more helpful for non-CS disciplines that change slower (eg, math/physics). A recent negative book example for me is the Quantum Programming book from O'Reilly. I found that it did not discuss quantum circuits in a detail that helped me really understand what I was doing -- though I suppose that is a conceit of quantum computing. Perhaps I will return to it later (I am working through Nielsen/Chuang now, which is very theoretical, but explains things very clearly) My policy is that a book is nothing more than a learning tool, which a hobby project can also be (perhaps more effectively due to the experience gained). Then again, knowledge is power, and books are great at pointing you in the right direction -- assuming you found the right one for your needs, of course. I know some people who won't open a book unless they know they can read the whole thing, which I think is a ludicrous attitude. I did just order O'Reilly's Generative Deep Learning book, and am hoping to get something out of that, and if I only retain a handful of snippets to use in my career, that is profitable for me. The least I can count on is that it will look nice on my shelf. reply sfn42 13 hours agoparentFundamentals don't change. Sure there's a new frontend framework every week but they're all just generating html. reply ta_1138 11 hours agorootparentIt's often hard to tell what information is truly fundamental, and what will age badly. I look at many books of software engineering that were popular in the early 2000s, like The Pragmatic Programmer, Agile Software Development or the Design Patterns book by the gang of 4. Those books aren't taking about technologies that we expected to be superceded in 5 years. And yet, a lot of the text regarding object orientation and design patterns is outdated at best, and outright harmful at worst. One can also look at, say, concurrency. A topic often seen as unimportant in the 90s, but ultimately taught at the lowest level, with mutexes, threads, semaphores and such. Those aren't going away, but how often is concurrent programming all about manually setting mutexes? We use higher order abstractions, but those change too. Many languages are encapsulating this in monads, whether people know their promise implementation is a monad or not. But that's not the only way, and the most popular way can change: Maybe languages in 10 years will be all about continuations and direct styles. Maybe it'll be something else. The fact that in the end, the same basic features from the 80s and 90s will exist at the bottom somewhere isn't that useful for most programmers. And html generation... I was writing UIs before web apps were there. A lot of things that seemed fundamental went away when the browser was embraced. But will the browser live forever, or be superceded? I suspect that it will all get replaced, or be utter legacy, eventually. Will that eventually be 10 years? 30? It's very hard to say what will remain fundamental, and what will not. reply bad_user 5 hours agorootparentMutexes, semaphore, CAS, threads are fundamental and this doesn't change when you embrace monadic effect systems or continuations, even if some of the details change (e.g., obviously, if a computation can jump threads, then you need implementations of mutexes, semaphores, etc, that can jump threads). Also, programming languages in 10 years from now will be pretty much the same languages we have today. There might be a newcomer or two, but it will be niche, as incumbents don't really change and only grow. As a reminder, for people thinking that technologies change too fast, POSIX is still here and as relevant as ever. reply ssrc 12 hours agorootparentprevJust for the moment, consider the idea of implementing the requirements shown in the figure using a network of connected microcomputers, one microcomputer per bubble. Structured Analysis and System Specification, Tom DeMarco, 1978. reply cjohnson318 12 hours agorootparentprevYeah, I'm comfortable buying a book on C/C++, or Swift even, but for React or Vue or whatever, I'm buying a digital copy. reply smburdick 12 hours agorootparentprev+1. What are the fundamentals of CS? Algorithms? reply Jtsummers 12 hours agorootparentNo particular order but how they came to mind: Data structures, algorithms, algorithm analysis, various discrete math topics (set theory and number theory, a bit of graph theory, are usually included in a typical CS undergrad curriculum), models of concurrency, models of computing (lambda calculus, Turing machines), complexity classes, Chomsky hierarchy, type theory (some might consider this more advanced, varies by school and its lean towards practical or theoretical CS), systems of logic. reply anthk 24 minutes agorootparentprevRead SICP and do the Scheme (a LISP) exercises oline: https://sarabander.github.io/sicp/ If you want to run these locally, I can set Chicken Scheme for you. reply tombert 11 hours agorootparentprevIf software engineering whiteboard interviews are anything to go by, strictly hash tables. Hash tables are the only thing that matter, unless of course the interview process is broken... reply koolba 5 hours agorootparentBonus points if some kind of list requirement comes up and you deftly maneuver the conversation back to using your hash table with array indexes as keys. reply sn9 11 hours agorootparentprevhttps://teachyourselfcs.com/ reply el_oni 12 hours agorootparentprevand data structures. Theres a book called Algorithms + Datastructures = programs which i've heard good things about. I've also heard good things about 7 programming languages in 7 weeks, as well as crafting interpreters. The latter 2 I intend to pick up this year reply syndicatedjelly 11 hours agorootparentprevDan Grossman's \"Programming Languages\" series on Coursera was important in helping me connect the dots. And that was after only completing the first of three parts of the course... reply ResNet 12 hours agoprevI am quite impressed that the ancient Amazon.com link [0] on the page (with quite a few non-trivial query params) still returns relevant results today. A good case of Cool URIs don't change [1]. [0] http://www.amazon.com/gp/search/ref=sr_adv_b/?search-alias=s... [1] https://www.w3.org/Provider/Style/URI reply BossingAround 1 hour agoparentFunny, because the Amazon link returns an error for me. reply dang 15 hours agoprev16 years' worth of threads: (edit: Reposts are fine after a year or so; links to past threads are just to satisfy extra-curious readers) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=33287618 - Oct 2022 (112 comments) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=27411276 - June 2021 (115 comments) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=20543495 - July 2019 (87 comments) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=16574248 - March 2018 (51 comments) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=9395284 - April 2015 (61 comments) Teach Yourself Programming in Ten Years (1998) - https://news.ycombinator.com/item?id=5519158 - April 2013 (86 comments) Teach Yourself Programming in Ten Years by Peter Norvig (2001) - https://news.ycombinator.com/item?id=3439772 - Jan 2012 (29 comments) Teach Yourself Programming in 10 Years. - https://news.ycombinator.com/item?id=1060176 - Jan 2010 (32 comments) Teach Yourself Programming in Ten Years - https://news.ycombinator.com/item?id=191235 - May 2008 (19 comments) Norvig: Teach Yourself Programming in Ten Years - https://news.ycombinator.com/item?id=43243 - Aug 2007 (7 comments) reply jprd 15 hours agoparentThank you for all of it @dang. reply jansan 15 hours agoparentprevnext [5 more] I am not sure if this is criticism for too many reposts or if once a year is considered a healthy dose of dupes. reply dang 15 hours agorootparentIt's just for fun and interest, as the other replies have pointed out. I've added my standard disclaimer to the comment above. Reposts are fine after a year or so! This is in the FAQ: https://news.ycombinator.com/newsfaq.html. reply pvg 15 hours agorootparentprevIt's so that people can see the previous discussion if interested. 'about once a year' does happen to be the frequency at which reposts don't count as dupes on HN but that's somewhat incidental. reply thierrydamiba 15 hours agorootparentprevFor what it’s worth I check the site fairly frequently and this is my first time seeing this. It would be interesting if there was a way to mark links as seen so they could be removed from your feed in the future for people who don’t care for reposts. reply pard68 15 hours agorootparentprevdang (the moderator of hn) does this for many/most common reposts. It is done without comment or implications. reply jms703 15 hours agoparentprevnext [3 more] If only there was a way to let poster know about past threads before posting... reply dang 15 hours agorootparentReposts are fine after a year or so! This is in the FAQ: https://news.ycombinator.com/newsfaq.html. When a link has had significant discussion in the last year, the software will normally redirect the submitter to the previous thread rather than allow a repost through. reply taftster 12 hours agorootparentFor what it's worth, I think this helps HN feel fresh. This is the first time I've read this article, and I enjoy the comments left by my fellow cohorts of this year's read, just like it was something new. Long lived historic articles can shape multiple years worth of discussion. I think it's even more fascinating to read the comment history and see what the current thinking is, if it has changed compared to previous years, etc. reply calibas 17 hours agoprev> The key is deliberative practice: not just doing it again and again, but challenging yourself with a task that is just beyond your current ability, trying it, analyzing your performance while and after doing it, and correcting any mistakes. Then repeat. And repeat again. I think this is the really important part, you have to challenge yourself and go outside of your comfort zones to keep learning. reply freedmand 17 hours agoparentI wonder how people’s learning habits will change with AI tools like GitHub Copilot. I used it for several months but randomly got logged out and am now finding myself valuing the slight inconvenience of looking up official documentation (and surprised how much more sluggish I felt for the first week). Going through extra steps to learn something through primary sources and valuing being uncomfortable at times are important for my evolution as a programmer. reply testcase_delta 17 hours agorootparentI started learning to code this year, and I keep thinking that I would have thrown in the towel if not for ChatGPT. For better or for worse. The big difference for me is being able to struggle right up until I'm ready to give up, and then ask ChatGPT for insight. Usually my issue is a syntax one, and I have the concepts down (i.e. I was right to solve it using nested if statements, but I forgot I need to put a variable outside a function, for example). This way I get that dopamine hit of being mostly right, and quick feedback on what I need to improve. If not for ChatGPT, I'd be left feeling like I just failed entirely and I'm not getting it at all, which I don't think is the case. I think the same experience would be achieved with a good teacher, but then I'd need my schedule to overlap, and the feedback on problems would still be often be delayed instead of instant. reply voakbasda 16 hours agorootparentUsing ChatCPT to help you after you have been stuck and struggled would be equivalent to asking a senior. A senior might hallucinate an answer too, but either way you will get pointed in a generally useful direction. That’s usually all it takes But as a senior, I can’t imagine using an LLM at this stage for solving anything meaningfully complex. reply freshpots 16 hours agorootparentA friend of mine in a senior role uses it all the time and says it 2-3x'd their productivity. He architects everything using experience but simple but time-consuming sub-routines are done via an LLM. He also uses it to create tests for his code and is quite happy with how it performs in these areas. reply stephendause 14 hours agorootparentWhat language does he program in? ChatGPT and CoPilot have increased my productivity, sure, but I don't know if they've multiplied it by 2, and definitely not 3. I mostly program in Rust, and while they are good, they still often produce things that don't compile. Iterating back and forth to get something that works takes time, and it feels to me like sometimes doing it alone would've been almost as quick. I could possibly be way off in my estimations, though. A true comparison would be having me do a task with and without it, but of course once I've done it once, the next time I will do it faster. reply freshpots 14 hours agorootparentThey use CoPilot integrated into their IDE and mostly program with Kotlin. reply pcchristie 7 hours agorootparentprevThe big thing it's helped me with (also learning) is that my learning style is, after reading a new concept or thinking I get it, imagining fringe/edge cases, and trying to understand the battery limits of the concept and how it fits in with others to ensure I'm comfortable. I'm not explaining this well, but \"what's the difference between this method and the one I learnt 3 chapters ago, they seem really similar. Why would I use one over the other, and why is there a need for both to exist?\" would be a good example. Without ChatGPT I'd just ensure I got an exercise right, and move on, half cloudy and uncertain in my understanding. The static content on Codecademy obviously doesn't explain that when first teaching you, but ChatGPT allows you to do ANY such comparison, and explains things exactly as you asked them, complete with demonstration code blocks and said fringe/examples where, in the above example, one method or the other would break or be suboptimal. reply jansommer 16 hours agorootparentprevChatGPT has been a blessing for learning C. How do you calculate the conjugate for a complex double when the compiler doesn't support complex numbers? ChatGPT will give you the correct answer together with math examples. One example out of many. Then I verify the result by looking at other people's code - and now I know what to look for. I wouldn't use Copilot. I've noticed how it distracts people in screen recordings. They pause to see if what is proposed makes sense, and it usually doesn't. Distractions are the last thing I need. reply nottorp 13 hours agorootparent> ChatGPT will give you the correct answer together with math examples. Actually, back in the days, google would have given you a tutorial with the correct answer together with examples too. You don't need LLMs for this, just honest search. But honest search is gone. I wonder how long till ChatGPT gets entshitified too... reply jansommer 12 hours agorootparentYes, Google isn't so good nowadays, or my problems have become sufficiently advanced to not be a quick search away. What might save us from ChatGPT enshittification are the freely available LLM's. Probably won't be long before we can have a code companion running locally. It's probably already here reply nottorp 10 hours agorootparent> my problems have become sufficiently advanced In my experience if you search for an advanced topic it's likely to drown you in beginner's tutorials for anything even remotely related. My pet peeve is i do embedded linux on custom hardware, and every time i need to check something i'll be up to my neck on tutorials telling me how to enable, say, spi on a raspberry pi in user space. Even if I was explicitly searching for a totally different SoC and a recent reference for the kernel functions :) reply peterfirefly 7 hours agorootparentprevhttps://en.wikipedia.org/wiki/C_mathematical_functions#compl... https://learn.microsoft.com/en-us/cpp/c-runtime-library/comp... https://en.cppreference.com/w/c/language/arithmetic_types#Co... reply jansommer 1 hour agorootparentCan't use any of that, because they all use complex.h (not supported by my compiler) and I have an interleaved array of complex numbers where 0 = real, 1 = imag, 2 = real, 3 = imag etc. Dear ProbablyRealPersonGPT, please provide the necessary code in C with a short explanation reply lannisterstark 3 hours agorootparentprevYes. They already got the answer, thanks. Pointing out links after the fact is laughable. Some of you are set in this idea that an LLM can possibly not be even slightly helpful that you have to trudge through pages of documentation just to look for one slight thing that it'd have told you right away _if_ you wanted it to. reply jeremyloy_wt 15 hours agorootparentprevI personally think learning how to use ChatGPT and the like IS going out of the comfort zone. To make an analogy to music, I see it like brass players at the advent of the valve. It’s a new way of playing the instrument. The old ways and new ways aren’t congruent in all ways, but the new way does seem to have a higher skill ceiling reply analog31 9 hours agorootparentThis has been the case for me. I know that I will have to force myself to use AI, because at present it slows me down. reply spookie 16 hours agorootparentprevYeah, I realised I'm not really learning by having such a cheatcode. Was doing a Vulkan renderer and the moment I stopped using ChatGPT, I started making way more reasonable decisions on how to structure my code via abstractions and such. You shouldn't take the easy route when learning lads reply PheonixPharts 12 hours agorootparentprevI've worked with a fair number of less experienced, ChatGPT focused engineers and they aren't all that different from the Java engineers of yore that were completely helpless outside of an IDE and could only work extending existing code. These latter engineers where the exemplar \"blub\" programmers from PG's famous essay [0]. But clearly using an IDE does not make one a bad programmer any more than using ChatGPT will in the future. The bigger issue is the field is awash in people not really interested in programming. There's nothing wrong with this as everyone has to make a living, but this has a far bigger impact on the quality of engineers out there than the nature of the tools used. Not long ago I was at a hip Bay Area startup and I don't think any of my coworkers, senior or otherwise, spent a second of their free time thinking about programming. For me I program for a living because it's great to get paid to do my hobby during the day. Getting started in the field during the shadow of the dotcom bust, the majority of the senior engineers that inspired me were likewise obsessed with programming and would be programmers even if it paid minimum wage. I don't think I would have necessarily become a programmer today since I wouldn't have been near enough the flame to ignite my own spark. 0. https://paulgraham.com/avg.html reply zigman1 1 hour agorootparentI think solving one own's problems with code will become more accessible to the wider population, also coding will become a bit more demystified. If you ask me, it will become sort of literacy, like reading alpha-numeric code. But programming will remain domain of CS, which requires a deeper understanding and proper studying to perform it well. So, while I agree with you, I don't think all of this is that bad. It must be a positive think that more and more people at least try to pick up coding, can solve some basic problems with it, and if anything, will maybe motivate their kids to learn it properly. reply rozap 16 hours agorootparentprevI kind of wonder if it's similar to how I never learn how to get somewhere if I use Google maps. If I put away Google maps and use my brain then I can learn the route after doing it once. reply insane_dreamer 4 hours agorootparentprevor just fall back to StackOverflow reply bitwize 16 hours agorootparentprevI don't even use autocomplete. I know that autocomplete is, like, table stakes for the developer experience these days, but I just can't stand videogame shit happening in my field of vision whilst I'm coding, and I've learned to relish the extra effort of typing the whole name in every time, it's like a vocabulary word I can wield with power and precision, rather than relying on the machine to finish my thoughts for me. reply smburdick 12 hours agoparentprevAs a software developer with some tutoring/TA experience, I'm concerned about whether the next generation of devs will actually be able to code, if all they had to do was use a Copilot to complete their assignments, especially at the freshman/sophomore level. They'd be automating themselves out of usefulness at that point. Then again, we've had similar conversations about \"iPad kids.\" As an iPad (along with everything else) user, I find it's not a bad approximation of a laptop -- you do have a filesystem, for example, and apps continue to be more fully-featured (in an Apple-approved way, of course). I use copilot myself, but mostly as a smart autocomplete for setting variables or other minor things that consume time better spent contextualizing through problem solving and interacting with teammates. It's not a substitute for being an engineer. reply chaorace 16 hours agoparentprevThis is true, but I think it's better put this way: The key is making it a hobby. Expertise comes with experience and experience will only come if you keep coming back. Some people can force themselves to toil endlessly, but here's some wisdom for mere mortals: start by searching for a part of software that you can truly love, then cultivate it. reply cardanome 15 hours agorootparentIt is also a good idea to place the hobby part of programming in a related but not same field/tech stack than you day job. If you simply do more work in your free time you might burn out. You want something that provides relaxation but still synergy effects with your day job. reply smogcutter 16 hours agoparentprevIn education theory this is known as the “zone of proximal development”. reply heads 10 hours agoparentprevNothing beats that feeling of starting the day thinking “I have no idea at all how to do this” and finishing the day with a proof of concept for 80% of the system. reply Erratic6576 17 hours agoparentprevAbsolutely, but I need a teacher for that reply Jtsummers 15 hours agorootparentDo you need a person teaching you directly? Then you need a mentor (to guide you) or to go back to school. If you just need someone to have done the legwork and established the exercises and presentation of material for you, there are a myriad of options: books, blogs, videos, open courses, paid courses, etc. The trick I've found to mastering a field without having a teacher standing over me and guiding me (and even when I have a teacher) is to learn to construct my own courses and exercises. These are \"synthetic\". I look at multiple university courses on a topic and grab one or more books, and then work through them in an order that fits my way of learning. If they have a lot of exercises, I do them. If they don't or their exercises are poor (happens), I have learned (over the years) to construct my own exercises. A major lesson from years of doing this is that there are no perfect teachers, courses, books, or other resources that will, on their own, teach me a topic to mastery. I have to assemble it myself to fit my way of learning and needs as a learner. That part requires introspection along with trial and error. I attempted courses and books that taught me nothing (or barely anything). After a bit of floundering with that, I took a step back and figured out what resources were effective and ineffective for me, what they had in common or were missing, and started assembling my own \"courses\". That's a very useful skill to develop, and it transcends disciplines. Even if you do have an actual teacher with you this is still helpful (perhaps even essential) to be able to go beyond what they're teaching you and to cover over their weaknesses as a teacher (either general weaknesses or weaknesses with respect to you). reply brigadier132 16 hours agoparentprevThis seems to be true of all human development. Running, lifting weights, learning. It's all about progressive overload. reply pmarreck 17 hours agoparentprevYou have to like being challenged. I've seen incredibly smart people in the coding space (definitely smarter than I) basically \"smart themselves out of it\" because they felt it wasn't challenging anymore. Or they felt tired of the \"wrong\" challenge, like \"waiting for everyone else to catch up to them.\" (They were usually involved with bleeding-edge tech that ended up being the norm years later.) If fascination is motivating, I guess be happy that you're not too smart? ;) reply cube2222 18 hours agoprevThis is marked as 1998, but includes mentions of e.g. Clojure and Go, so it's probably been updated since. reply ReleaseCandidat 18 hours agoparentAt the end of the page: Peter Norvig (Copyright 2001—2014) reply janchorowski 18 hours agorootparentOriginally from 1998: https://web.archive.org/web/19980206223800/https://norvig.co... I didn't want to mislead with a newer date. Sorry if it confuses you. reply sandyarmstrong 8 hours agorootparentI had no idea it was originally talking about a Pascal book, thanks for the link! Fun to read old versions and see what changed over time (language recommendations, for example). reply ricardo81 18 hours agoprevI can't source the video that I watched 5-6 years ago [0] but it made a point about the increasing numbers of programmers and how the majority had less than 5 years of experience. It made sense in the context of IT/web continually having a larger involvement in our lives. [0] https://youtu.be/ecIWPzGEbFc?si=A4qBR2YdX-0CV2bM thanks to comment by wild_egg Can safely say after 20 years that there's maybe a bunch of information I don't need to know anymore that people > It'd be like being a carpenter or mechanic but spending the majority of your time debugging, fixing, and communication with manufacturer's of broken or poorly working tools. What do you think a mechanic does ALL DAY? Very few carpenters start with a raw blank of nice wood and craft something amazing. It's all interpreting plans (poor spec), framing (boiler plate), figuring out an addition (bolting on features to a shaky platform), correcting things that have failed (maintenance), addressing things that were built wrong (bug fixes) or fixing shoddy renovations (tech debt). Sounds EXACTLY like the majority of software development. reply bmitc 12 hours agorootparent> What do you think a mechanic does ALL DAY? Are you implying that they are fixing their tools rather than cars? I don't know any mechanic that would put up with that and would replace their tools with tools that actually work. reply fnordpiglet 11 hours agorootparentExcept mechanics tools are fairly simple devices based on thousands of years of standardization. I think probably a better example would be someone working in a lab on experimental devices. Software tooling is often absurdly complex and relatively new with no clear standard. In 100 years I’ll wager things are not like this. reply wharvle 13 hours agorootparentprevI once bought whatever jamb saw they had available at one of the big box stores. It was basically unusable. Fundamentally flawed design. There's no possible way anyone tried it and went \"yes, this is fit for purpose\". Worse, the complexity of its design which caused so much of the trouble (it had a single-sided blade that could be spun around—the locking mechanism was simply flawed, I didn't get a bad one, it just could not work well) could have been entirely avoided by spending barely more money on manufacturing. I mean it was also very dull but at least it would have been usable, if slow. I managed one jamb with it, taking probably 10x as long as a version of the tool fit-for-purpose would have, busting up my knuckles plenty, and making an uglier cut besides, so I could move on, and ordered a different one for the rest, since the store didn't have any other models. That's about the median quality of all tools and libraries I encounter in software, in my estimation. Size of vendor or how \"smart\" their employees allegedly are (LOL. LMFAO.) doesn't seem to much matter, either. And usually it's like that crappy jamb saw being the only jamb saw available at the store, except there's no option to skip the big box store and look for acceptable ones online, and if there are any other options they're somehow even worse. Luckily 99% of the tools for \"real\" work I've bought haven't been anywhere near that bad. Even the cheap ones. Almost all of them are more-or-less sensibly designed and actually do what they're supposed to without causing a huge amount of trouble. Most of an average day programming, for me, metaphorically, is swearing at this fucking piece of shit jamb saw while my knuckles bleed and I'm fucking around with its brokenness instead of getting anything done that I actually wanted to. reply mtrower 7 hours agorootparentprevAt least in woodworking, tool setup and maintenance is a significant portion of the craft. reply apsurd 14 hours agorootparentprevI don't think software is uniquely a mess behind the scenes... reply TedDoesntTalk 14 hours agorootparentprevThis is precisely part of the job. Somehow your expectations are very different than mine. reply bmitc 12 hours agorootparentIt's part of the job, but it shouldn't have to be. If software engineers just did things properly, then we wouldn't have to deal with each others' messes. reply mp05 15 hours agorootparentprev> I can’t think of anything that was a waste to learn other than scrum. Believe me, I have plenty of criticisms of that entire culture but it has a lot of good ideas. What in particular (besides the obvious overwrought ceremony) do you find not worthwhile? reply fnordpiglet 13 hours agorootparentIt has no good ideas. All the ideas that appear good are taken from agile, which 20 years ago WAS good. But then the process managers came in, the management seeking clarity on delivery dates, and engineers who got into it for a good job seeking ways to avoid doing real work because they’re actually not into engineering. It’s a morass of everything awful about stupid management cargo cult bs meant to emulate but not understand excellent engineering culture, with roles meant to keep project managers employed, and overriding everything stupid “rituals” to try to measure velocity and delivery dates for leaderships need to control. It delivers none of what agile promises because it is satisfying the needs that makes waterfall so slow. reply PheonixPharts 12 hours agorootparent> from agile, which 20 years ago WAS good. It's completely wild to me to have been in the field long enough to remember when agile was revolutionary, and then to see it slowly become twisted by decades of mismanagement into something that people hate today. For most engineers today \"agile\" just means using jira, 30-60 minute long \"stand-ups\", and a perpetual panic about not getting enough done in 2 weeks. reply dpritchett 14 hours agorootparentprevThe more skilled I become over the decades the more I prefer either Hickey’s hammock-driven development or a simple kanban setup. reply apsurd 13 hours agorootparentThank you for this recommendation. I've never heard of it before and now I'm reading: https://github.com/matthiasn/talk-transcripts/blob/master/Hi... It's giving me energy this Monday holiday(USA)! reply fnordpiglet 13 hours agorootparentprevYeah I think kanban is the right model for almost every development team. Teams embedded in a massive orchestrated project across many teams waterfall actually is pretty reasonable. reply mp05 14 hours agorootparentprev> simple kanban setup That's probably the essence of the \"good parts\" that I referenced. reply ipaddr 14 hours agorootparentprevScrum forces you to package your work into daily sound bites. It pull your focus elsewhere and reframes your work in a wasteful way where you are always cutting off the corners because of how it affects your 30 second daily advertisement. reply theteapot 14 hours agorootparent> daily advertisement Not defending scrum but sounds more like you've been abused by bad culture disguised as scrum. reply shrimp_emoji 14 hours agorootparentA place with daily standups? Their \"sound biting\" of a complex issue resonates. It can be difficult to even explain what I'm doing to several people in the bandwidth of 2 minutes sometimes. Most charitably, it's just a quick, lossy status report and forced request for help with blockers. I feel like something is wrong if you feel like you need to cut corners to perform a \"good-looking\" report in standup. You shouldn't feel/cave to such a pressure. reply theteapot 13 hours agorootparentI was referring to \"advertisement\" part not the \"daily\" part. Stand ups can be a way for people who know / want to game the system to prosper in the eyes of some idiot scrum master and managers, while our guy here gets smoked and made to look like he isn't productive. You shouldn't cave, but if that's the culture around your in for an uphill battle. > I feel like something is wrong ... Yeah, bad culture. reply skeeter2020 14 hours agorootparentprevI have plenty of complaints about scrum the process, but don't think it's much different than the results of scaling up and standardizing any process across teams of varying levels of skill and commitment. reply brailsafe 14 hours agorootparentprevScrum just got taken out back. Agreed. reply benzible 14 hours agorootparentprevSee: https://news.ycombinator.com/item?id=35857463 reply trhway 14 hours agorootparentprevThe idea, and especially its unconditional forcing down the throat, that you can run marathon faster by running it in 100m sprints. That idea is wrong as it has been shown many time in practice, yet even the slightest doubt of that idea is squashed. Scrum is basically an ideology/cult, and as typical for such it is built on a lie - it is sold to rank-and-file as performance improving whereis its real goal is improving reporting to the manager at the cost of rank-and-file's performance, the manager's convenience at observing the status even if the things are relly moving much slower as a result. It is similar to how in a religious cult people would be sold on supposedly reaching nirvana/etc. while in reality the guru/pastor/etc. would be abusing them financially/morally/physically/etc. reply wild_egg 17 hours agoparentprev> I can't source the video that I watched 5-6 years ago but it made a point about the increasing numbers of programmers and how the majority had less than 5 years of experience I believe that was in this Bob Martin talk — The Future of Programming https://youtu.be/ecIWPzGEbFc?si=A4qBR2YdX-0CV2bM reply ricardo81 17 hours agorootparentYes! That's the one. Struggled to source it. reply bee_rider 17 hours agoparentprevIt is a rapidly advancing field because it is young, so it makes sense that we’d accumulate a lot of ephemeral information. It feels like we’re still in the alchemist days. Eventually the chemists will come along. They’ll systemize our ad-hoc observations and jettison a ton of them. Until then… Neuton was an alchemist and he still made some pretty big contributions. reply dasil003 16 hours agorootparentI agree with the first part, but not sure about the second. I believe software is much more engineering than science. The challenge is in organizing the bits. Most of the things learn, debate and design in software are more less arbitrary structures created to facilitate our own cognition. The hard science behind computers is much more cleanly abstracted away, compared to, for example, chemical engineering. For that reason, I don't believe software advances in the same way that natural sciences do. It's much more social in the sense that groups rally around different ideas and implementations, and wherever that energy goes also shapes the new ideas to bloom on top. Put another way: I think almost everything in software is arbitrary. Certainly some ideas are better than others, but on balance everything is a tradeoff, and I don't really expect for some powerful new discoveries or ideas to reshape the industry towards more structure and efficiency. I think it's more likely that AI replaces human programming entirely (although I dont think that's likely either). reply saltcured 14 hours agorootparentThere are layers here. The purest theoretical CS is like mathematics in general. Also necessarily structured around cognition, but seemingly groping for something more fundamental or universal. I'd agree lots of software is like engineering in that it is further tilted towards the practitioners and marketplaces and their limitations. It has more focus on cost-effective repeatability and risk management. But, traditional engineering is more rooted in some physical reality. I.e. civil engineering has basis in physics and materials science, because those drive failure modes and design criteria. The more social aspects---say evacuation routes for fire safety---developed within an existing practice that already been formalized to manage risks of structural failure etc. But, lots of software is far detached from such a physical realm. It is more like legislation or contract law, or the arts. It's all about what people want to say or hear and display to each other. Massive influence from the cognitive and social context. It may be colored by technique and available materials or resources, but thanks to Moore's Law and friends, these practical limits have less and less influence on the shape of the outcome. Significant failure modes can be rooted in the vagaries of psychology, social sciences, or even political sciences. However, software diverges from law or arts when we attempt to scale it up. We want to reach speeds that cannot be supervised and quality controlled by a human operator, or volumes of support tasks that cannot be managed by an affordable human workforce, or impactful decision-making and effects that cannot be adjudicated by a higher court. You need something like engineering here to manage risk, but there is no physical basis for building codes etc. Not only the new software products, but even the elements of risk are social constructs. But I think the metaphors are broken as one pushes too hard \"up the stack\", into AI replacing knowledge workers and analysts. Our current best social systems completely depend on human adjudicators in hierarchical layers of oversight. Courts that can comprehend the big picture and resolve differences when our other abstract social activities go wrong. I am nervous about a future where tech behaviors become too complex for such oversight. Or worse, where naive practitioners think they can solve it with another layer of unproven tech. Instead of turtles all the way down, it becomes some faith-based electronic oracles all the way up? reply osigurdson 14 hours agorootparentprevA better analogy for software engineering is search. Given our current position and a desired change, we search for a solution in the fog. Analogies to other problem domains often fall short as search doesn’t feature as prominently. reply bombcar 15 hours agorootparentprevThe chemists are already here, the Knuths and such - it's just being ignored or isn't directly \"relevant\" yet. It's like building buildings without \"building science\" - which, surprisingly, we have actually been doing in many ways to the current date. There aren't really formal schools of \"be a carpenter and build a house\" - it's all very master/apprentice even if it is not formally so everywhere. And since things like \"energy usage\" of the building didn't really matter until recently, many buildings just kept being built the way they always have. Now things like \"can we keep this building comfortable at much less energy usage with some additional up-front costs\" are coming to the forefront, and how buildings are built is slowly changing. Compared to that, software is very in its infancy, because the real only bottom line items are \"does it mostly work\" and \"did it not cost infinity dollars more than it made\". reply bluetomcat 14 hours agorootparentIt's not in its infancy. The fundamental problems regarding algorithms and data structures, OS theory and formal language theory are well understood and have articles on Wikipedia. We know Amdahl's law, the CAP theorem and the ABA problem. The problem is the explosive decentralised development of tools, languages and frameworks under a hyper-competitive neoliberal economic system. Someone invents a language to lock programmers to their platform. Another programmer creates a tool to transpile that language to their half-assed dialect of another language. This leads to a huge problem of entropy and inefficiencies at all levels. reply osigurdson 14 hours agorootparentprev“Building Science” is normally called civil engineering. reply bombcar 14 hours agorootparentIt's a term thrown around by various people to refer to \"building houses with something slightly later than 1950s designs\". When people hear \"civil engineering\" they think \"skyscrapers, bridges, roads\" - this is more like \"if you wrap a house in insulation, it's insulated better, but that can also cause moisture capture, which destroys it\" type engineering. reply analog31 6 hours agoprev>>>> Why is everyone in such a rush? Because programming can be a means to an end. You can do both: Learn enough programming to do useful things for yourself -- maybe not in 24 hours, but 24 weeks is not unthinkable. And spend longer to learn it as an art if you manage to get over the initial \"hump\" and are still interested. reply ilrwbwrkhv 17 hours agoprevI think you never learn programming as it becomes more of an art at the upper echelons. For the fundamentals I would say 2 - 3 years of dedicated work is enough. reply atticora 17 hours agoparentIt depends. I've been coding for a living for 41 years and have a feeling I'll get the hang of it real soon now. reply bxparks 14 hours agorootparentThen there's C++. After ~30 years of it, I realized that I don't know how to initialize an object anymore. So I've given up. reply PaulDavisThe1st 13 hours agorootparentI've been doing C++ since 93. What's changed that makes you feel this way? reply Nevermark 12 hours agorootparentEverything, man. Everything. From the perspective of pulling some C++ programmer in 1993 into 2024, and dropping them into a large C++ code base consistently written with the latest C++ idioms. (And yes, this is humorous exaggeration. But the name of C++ is apt. A C language dedicated to accumulating features.) reply PaulDavisThe1st 10 hours agorootparentIt's a pre-increment operator. If it was called ++C you'd have a point :) I just don't understand how someone could have been working in C++ and not picked up the largest changes even just by osmosis. My code-based \"upgraded\" to C++11 about a year ago, but I can still read C++17 and am not intimidated by C++20 fragments. YMMV I suppose. reply Nevermark 9 hours agorootparent++C = Every time you go to write new code, some new features have already been adopted that you need to get hip with. C++ = Every time you look at old code, it is already out of date based on new features that were adopted after the code was written. reply reactordev 14 hours agorootparentprevIf only they would stop changing the rug out from under ya, am I right? Just when you finish with one API, they go and release a new one. reply jesse__ 17 hours agorootparentprevAmazing answer reply ilrwbwrkhv 17 hours agorootparentprevnext [4 more] [flagged] icepat 16 hours agorootparentRight - because the entire point of learning to program is becoming Mr. Robot reply scrps 15 hours agorootparentprevIt is possible you are not cut out for sarcasm? (Giving you the benefit of the doubt you may have taken the comment literally, if so I'd maybe apologize for insulting someone with 41 years of experience in a field that is still young whilst having no knowledge of exactly who you are talking to) reply atticora 14 hours agorootparentprevI aim higher. reply macjohnmcc 17 hours agoprevTeaching yourself programming is important on many levels as the job is a continual learning type of job. What you learned 5 years ago might apply today or you may have to learn something completely new to stay on top. reply lukeholder 2 hours agoprevThe book that changed my life was “The well grounded Rubyist”. Learning how objects and messages worked was so amazing. reply tempodox 13 hours agoprevYep, thats a reasonable time horizon. After 10 years you can call yourself a seasoned beginner. reply rudasn 9 hours agoparentI'm self taught, started with IRC bots in tcl in late 90s and making websites with netscape and frontpage in early 00s. Dreamworks and Fireworks too. Got business degrees by mid 00s, but making things with code kept me going. Got a US remote job early 10s (I'm in the EU), and by mid 10s I was called \"software engineer\" by my peers and bosses. I have just fairly recently upgraded my LinkedIn bio from \"Web developer\" to \"software developer\", as I can't even call myself an engineer. Honestly, I have no idea what I'm doing other than making a real effort not to do stupid shit (and RTFM). reply teaearlgraycold 17 hours agoprevI’ve had a number of people approach me, at work and elsewhere, asking how they too can get one of those programming jobs. I always mention the timeline I was on, having started learning as a kid, making it a major hobby, getting a CS degree, internships, etc. and people are surprised and disappointed there’s no quick path. Or is there? Has anyone here done one of those 0 to 1 bootcamps with success? reply gwill 17 hours agoparentI've been programming professionally for 8 years now and came out of a bootcamp. I had taken some programming courses in high school and college for fun but my knowledge was very limited. The bootcamp stayed true to the name. Core hours were 9-5 but many of us would get in early (usually 7am) and leave late (sometimes 10pm). I would also go in on weekends, sometimes taking Sunday off. I intentionally went to one in a different city so I wouldn't by distracted by a social life. The focus was in ruby, then javascript. I got a job as an intern in C#/.NET a few months after graduating. I took the intern position because it seemed a tough sell to get a junior dev position right away. I was promoted to junior dev after just 2 weeks. The school is no longer around, bought by kaplan and dissolved. reply UltimateEdge 17 hours agorootparentDid your peers in the bootcamp have a similar experience? reply gwill 10 hours agorootparentIt differed quite a bit. There were a handful that put in the same effort as I did and the few I've kept contact with are doing quite well. I'd say that just over half of the students stuck to core hours and most of them didn't make it through the bootcamp at all. I recall that many of those that stuck to core hours and graduated had some programming knowledge already or were exceptionally smart. About a quarter of those that graduated in my cohort are in the IT field, but are project managers or something similar. The bootcamp was in 3 phases and you had 2 chances to test out of a phase or you'd be kicked out. Of my starting cohort of 16 people, 12 of us completed the bootcamp. Our cohort grew to 22 people though because there were people that had repeated phases to complete it. reply yonaguska 17 hours agoparentprevThe only people I've seen do the bootcamps with success were already very smart and/or coming from technical or heavy math backgrounds. reply skeeter2020 17 hours agorootparentGlad to see at least another perspective more or less echo my experiences/observations. You can't discount motivation, and bootcamps are filled with either those chomping to learn and explore, or those looking for the next goldrush. Adding to the challenge of differentiating is sometimes they are the same person. reply bombcar 15 hours agorootparentIf you're skilled/smart/whatever you're gonna be fine, usually, so let's discount those and set them aside. There's definitely a cohort of \"moderately capable at plugging away\" type developer that can successfully come out of a bootcamp, and it's usually something like this path: bootcamp - headhunter agency that needs bodies - develop familiarity/skill with the toolset - hired directly via some other company. Less \"startup valley next great thing\" and more \"updating the Java application for a change in the tax code this year\" style corporate programming (which is the vast majority of all programming). reply monkeynotes 17 hours agorootparentprevAren't most successful engineers already very smart when they start out? Being very smart seems to be a prerequisite for all successful engineers. reply helboi4 17 hours agorootparentprevI mean I think I'm sorta smart but nah I have a 0 to bootcamp success story and I studied languages at uni and didn't even pass A-level maths in high school. I did a 3 month bootcamp. I was determined to end it with a job so I studied 12 hours a day 6 days a week. By the end I couldn't walk down the road without being out of breath but I had a job. My first year of employment was terrible. I was bad at everything and my employer had agreed to take bootcampers without any preperation of how to deal with that so just kept keeping me away from tickets, stunting my growth. After I wasn't renewed I spent a further 2 months doing intense studying and portfolio building and applied for my current job. They've supported me a bit and now 8 months in I'm a pretty competent junior I'd say. I feel like this is the level I should've been at at my first job but as long as you're willing to work at shitty companies for a bit you can just go from bootcamp to employed immediately and then work up to being good from there. Edit: Whether I'm really worth the investment to these companies is another thing. I tend to think I'm not because I do sorta suck. But in terms of whether it's possible to go that path, be constantly employed and improve in time, yes it definitely is possible. reply jesse__ 17 hours agoparentprevI dropped out of CS after a 3 months, had never programmed before. I sat in my mom's basement for 8 months and taught myself the basics of JS and was able to get a job. Since then, I've spent a metric fuck-ton of time programming (tens of thousands of hours to date). I've worked on compilers, 3D graphics, semiconductors and game engines. I guess my experience kind of supports both sides of the coin. I was relatively easily able to get into industry with little experience (circa ~2012), although since then I've put in a ton of work to become a good engineer that people with interesting projects want to hire. Take that as you will :) reply skeeter2020 17 hours agoparentprevHaven't done one, but have hired out of them. Limited data conclusion: just like traditionally trained developers it's hit or miss. Best results: some other \"classic training\" (like physics or chemistry or engineering) with a desired career change == advanced junior with an accelerated learning curve. If you want to add motivated newbies to the parts of your software where pure programming is not as critical they can be great hires; the standard deviation is huge, but not sure if it's any larger than say a 2-yr diploma grad. reply joseda-hg 16 hours agorootparentDid a 2-year, there's people that graduated there that to this day can't answer FizzBuzz, in that same group, there was a marine biologist that was looking for a change, I'm saddened that the former will probably be what people think when they see our diploma reply bombcar 15 hours agorootparentIf it makes you feel better, past one job or so out of whatever training/college, nobody actually cares, except perhaps the HR automatic resume sorter. reply thebosh 17 hours agoparentprevI did a grad scheme where a consultancy trained me for 3 months and then worked for them under contract for 2 years. I studied humanities at university and had never coded before. The first 2 years were very hard and it felt like swimming upstream the entire time as I didn't have that basis. It was only at the end of the 2 year programme that I actually felt like I could provide value independently. A lot of my knowledge is very applied and I've noticed that I lack the CS fundamentals which sometimes makes it a bit harder as I'm having to learn 'basics' as I go. In fairness my role is a Data Engineer now so it's a lot lighter on the more traditional CS areas like Data Structure and Algorithms. reply helboi4 17 hours agorootparenti feel like we did the same scheme lol reply ricardo81 17 hours agoparentprevI think one of the beauties of programming is that you can be self taught. It doesn't necessarily help on a corporate ladder though, who maybe expect some certificates. reply ewelme 14 hours agoparentprevNot sure If you'd count it as a bootcamp but I did something similar. I taught myself to program Basic aged 11, using the manual that came with the early 80s Dragon 32 home computer (a whole 32k of ram). Wrote some simple games, worked out you couldn't really do anything cool without knowing assembly language, completely failed to learn assembly language, as it was too hard for this 12 year old on his own, armed only with a copy of https://colorcomputerarchive.com/repo/Documents/Books/6809%2... By the time I was 13 I'd given up programming and basically barely touched a computer for the next 15 years, did a History degree, bummed around as a musician for a few years and then, courtesy of the UK dole office, did a 3 month, 5 day a week, 9-5 course in Visual Basic, followed by a 3 month work placement. The company I worked for employed me when the placement came to an end and I've been working as a programmer for the last 25 years - although the last Visual Basic I did was about 24 years ago... I think I was lucky that I hit the London job market as the first dotcom boom was starting, it seemed to be pretty easy to get a job back then and no one seemed that bothered if you had a CS degree or not. (I still don't have one) I have done some academic CS courses (via Coursera) and did learn some interesting and useful stuff - but I think the most important thing to have if you want to be a good programmer is to have a self-directed mindset, you have to want go and figure stuff out and be able to learn on your own, using what ever resources you have to hand. One of the things I like most about programming/software engineering is the fact that there is always more than one way to solve the problem, always scope for improvement and inovation reply monkeynotes 17 hours agoparentprev> Has anyone here done one of those 0 to 1 bootcamps with success? My tech lead did this. reply avgcorrection 16 hours agoparentprevYou tell people who honestly want to get into professional programming that you have done this your whole life with the implication that this is the way? That anything less is “bootcamp” delusion? No wonder they get deflated. Of course they can’t go back in freaking time to when they were kids and get subliminal Programming Pearls from their wet nurse. And it’s also just wrong. People get into professional programming with... less experience than that. You might have never met anyone in your particular bubble but they do exist. reply syndicatedjelly 18 hours agoprevGreat article. At 8 hours a day, 40 hours a week - 10,000 hours of practice will take 250 work weeks to achieve. That’s about 5 years of nearly non-stop programming. Realistically, it takes closer to 10 years to achieve that goal. reply jesse__ 16 hours agoparentRealistically, it depends how much you enjoy programming. If you program a lot, you can easily hit 3k hours a year.. Most days I program 12 hours a day, most weeks 6 or 7 days a week. On a day I'm feeling very motivated I'll program for 18 hours. I've been doing this for close to 10 years. Occasionally I'll take a month 'off' and gear down to 3-4 days a week, still long days. By my conservative estimates, I hit about 3500h/year. I work this much because I fucking love programming, and there's nothing I'd rather do ( other than my daily surf in the mornings, of course :) reply syndicatedjelly 16 hours agorootparentThat’s great to hear. I said “realistically” because most people don’t program for 12 hours a day. I love programming, but I love other hobbies too. Everyone has the same 24 hours in a day :) reply ska 15 hours agoparentprevThe 10,000 hour heuristic isn't particularly accurate, it's just popular. FWIW, 10 years professional experience seems to be about right, give or take, to make a solid developer. I don't think I've ever met anyone who really got there in 5. Some people shave a few years off by having done it obsessively as a teen also, but at some point that typically overlaps anyway. Of course there is also the old saw about 1 year, 10 times being a problem. I've met plenty of developers with >10 years experience that weren't that solid, too... reply pants2 11 hours agorootparentI have a little over ten years experience, and when I read code that I wrote at 1-2 YoE it's shamefully bad, but after that it starts to get pretty good. I don't think anyone would notice a huge change between my code 5 years ago and today. I've moreso improved on soft skills. Though it probably helped that I had two mentors at a job 2 years in who were ruthless about reviewing my code. reply ska 9 hours agorootparent> I've moreso improved on soft skills. Which, among other things, are also vital. Oversimplified: 1-2 years of not knowing what you don't know. Then 3-5 learning how to write code, then 3-5 learning how to really write software. Most of that last learning curve happens outside the editor. That's a little to linear and non-overlapping, but the essence is true I suspect. reply monkeynotes 17 hours agoparentprev> At 8 hours a day, 40 hours a week - 10,000 hours of practice will take 250 full weeks to achieve. That’s about 5 years of nearly non-stop programming. Isn't this basically a software job? Like, get a junior role and work your way up over 5 years doing 40 hrs a week. reply throwawaaarrgh 17 hours agorootparentIf the only programming you do is generic commercial work, you won't get very good, especially if it's at the same job or on the same kind of project. You can learn more about programming by giving yourself new and challenging projects at home. Doing both personal and professional work is the fastest way to progress while learning lessons from both. (commercial work teaches you the \"professional\" side of software engineering, which has almost nothing to do with programming) reply sonabinu 17 hours agoparentprevThis is true in any profession. Building intuition comes from doing more and more with incrementally difficult challenges. There comes a point at which one can make connections and apply what you know from one area into another, and creativity kicks in. reply wrsh07 17 hours agoprevI've always been fond of this advice. I think it correctly describes some of the activities I would expect you to do and experience before you will feel like a deep expert in programming. I also think it's worth saying, \"you don't need to be an expert in programming to try it! Start by tinkering!\" (Other comments have been downvoted for describing what tinkering might look like, but any tinkering is valid! Try running llama.cc on your MacBook! Quantize a model yourself) Ultimately, you'll become good if you do it a lot, and you'll do it a lot if you have one or more hobby projects that you're motivated to work on. I have a few friends who are completely self taught (one going the Arduino / electronics / hardware route, the other going the web app and tools for personal use route), and the keys to their success is that they have projects they like working on. And they've kept at it for years. They don't know everything, and they don't necessarily have great foundations, but it's not too hard to learn things on an as-needed basis these days. Both of them find information very differently than I do, which is also valuable for me to learn and see. There are other ways to motivate yourself: taking a class with homework that gets you coding (the success of this strategy depends on the person!), finding an accountability buddy who you discuss your projects with, finding an open source project you're interested in (start by adding comments, fixing typos, or looking for a good \"first timer\" GitHub issue), do Recurse Center (although their job placement program may have limited options for junior / entry level engineers) At some point, you'll have beaten your head against a problem (how can I order these things correctly? How do I get this interaction to work correctly? Why is my component re rendering in an infinite loop?) and you'll watch a video or read a blog post explaining it and you will truly understand the issue. It will be common, and you might have encountered it in a 201 class, but your first-hand experience will help it stick. Another totally valid way to learn programming is to be good enough to get a job [1] and then be paid to figure it out day after day, and ideally have experienced programmers mentoring you. I've seen people go through bootcamps get a lot out of it, but I think the quality is highly variable [1] unfortunately, while I think this was a really good path ten years ago, the bar continues to be raised (new grads with internship experience can be very good, companies are not hiring as aggressively today as they did in the world of zero percent interest rates) reply theyinwhy 14 hours agoprevOn the frontpage at the same time: Become a master in 1 year [1] 1: https://micromasters.mit.edu/ reply lakomen 18 hours agoprevI've been at it for 20 years this year, professionally. For 38 years otherwise. I still haven't learned to do it right ;) reply forgetfreeman 18 hours agoparentNeither has anyone else ;) reply aldousd666 11 hours agoprevI have been dropping links to this article since 1998. Lol. It has definitely stood the test of time reply AidanSW 14 hours agoprevJust doing something for 10 years doesn't make you an expert, I started coding 11 years ago- as a kid. But my knowledge became so diffuse across topics I was interested in that I never really became an expert in any of it. reply extheat 14 hours agoparentBy \"doing something for 10 years\", I think the implication is you're actively working on that subject area, regularly, for 10 years. Not per se occasionally working on something every now and then. You can become a really good Chess player if you consistently play for 10 years--you figure out all the strategies and shortcuts, and it would be unusual if you weren't really good compared to someone playing for a year (assuming they're not some exceptional learner). But if your metric is just \"I've played it occasionally since 10 years ago\" then indeed, you probably didn't develop much breadth or scope as you were constantly forgetting and relearning as opposed to compounding your knowledge. As for programming, I don't think programming is all that hopelessly complex and broad as field, but it can seem that way to a beginner. Most computer science concepts translate very well to other parts of the field, and the core programming constructs and libraries don't change much at all. How many ways can you configure a website, a mobile app or a database? Your instinct might be to think about all the different libs you can pull in, all the different programming languages, etc. But they all do roughly the same thing, they all compile down to the same stuff. You just have to develop the skill of understanding the fundamentals as opposed to getting lost in a sea of high level abstractions. reply AidanSW 11 hours agorootparentI agree writing a variety of software will have similar base ideas, but still, having a good foundation in a topic doesn't make you an expert. I've barely used Java, but if I had to I could learn enough to write it pretty quickly, that doesn't mean I understand at all how JVM and Java's GC works, or what a factory is. reply skeeter2020 14 hours agoparentprevIt's not about \"doing something\", it's about intentionality, i.e. you're working to advance your knowledge and expertise with some form of a plan, even if that plan is \"try a bunch of stuff and see what sticks, then double down in that area\". Also, broad-based knowledge can be the expertise; think a general contractor who's skill is tying all the specialists together. The best software managers I've ever had came from skilled generalists backgrounds vs. incredibly deep specialists. reply RyanOD 14 hours agoparentprevThis is the story of my life. I know a little about pretty much every topic ever. reply skeeter2020 14 hours agorootparentThe idea that you should find some narrow niche in which you are so passionate that you dedicate the rest of your life to attaining mastery is only valid for such a small part of the population and, in my eyes, a little sad. reply AidanSW 11 hours agorootparentprevYeah, it's nice feeling like I have a foundation in enough topics that I actually feel like I would know vaguely where to start looking to solve most problems. Definitely not an expert though. reply TedDoesntTalk 14 hours agorootparentprevThat’s good - keep striving for that! reply ipaddr 14 hours agoparentprevYou became an expert in learning a variety of topics reply AidanSW 11 hours agorootparentMaybe, or maybe I became used to and ossified in bad strategies. I hope not, but I think I have learned that learning has to be intentional. Meaning for me, writing stuff down, trying to find out other solutions to the same problem rather than just going with whatever my first idea is, etc. reply thfuran 14 hours agorootparentprevJust doing something for 10 years doesn't make you an expert. reply ipaddr 14 hours agorootparentI think it does, just not in the things your measuring. Sitting on a couch for 10 years will make you an expert. Not an expert in sitting on couches in general but an expert in sitting on your couch during the period you were there. reply satellite2 14 hours agorootparentPretty sure I got worst at it. 10 years later and now my back hurts. reply ya1sec 14 hours agorootparentprevI like this sentiment. A Wittgenstein collection called “Philosophical Grammar” contains a lot of these kinds of thoughts. reply dekhn 15 hours agoprevPeter is a gem who really seems to understand the structure of reality slightly better than just about anybody, and is a nice person to boot. I guess I spontaneously picked up on the 'challenge yourself a little, improve, repeat' strategy a long time ago. I often implement things over decade or more, through a series of small increments. I also decompose many problems recursively and use a sort of A* approach to make progress, sometimes revelling in some detail for months or more at a time before solving it, then backing up the stack to the larger problem I was working on. For example, I'm building an automated microscope. I work with folks who buy $1M scopes just to speed up their science. I don't want a $1M scope- I want a $1K scope that does 30% of what the $1M scope does. To do this, i've learned how to design and 3d print components, integrate motors, controller boards, etc. Eventually I reached a point where improving the illuminator (the LED light that provides the light to the sample, which is then picked up by the camera) was the most important step and so I took a deep dive into LEDs, and the electronics required to support them. This has meant putting the scope down and instead creating a series of designs for PCBs that incorporate increasingly sophisticated electronics and higher power LEDs. I set a challenge for myself that is beyond my ability: design and have manufactured, a working constant current driver and assemble the PCB myself using surface mount components. When I started, I knew nothing about constant current, or SMD, or designing PCBs. I started with the simplest possible designs- copying a reference design for ac ontroller, cloning a board I already have, incorporating low-power LEDs onto a board. Each step along the way, adding something slightly more challenging. When I do this I fail a lot. Some days I get a PCB made to my design after a week of waiting (JLCPCB is AMAZING) and within 5 minutes realize I made a fundamental mistake. Other times, a board works perfectly and I \"level up\": I can now take everything I learned in the process, and use it to pick up the next challenge. Sometimes I get frustrated and depressed- not being able to figure out something that should be straightforward, and then I either rubber duck it, or ask a simple/stupid question on reddit, which typically unblocks me. Today, I expect to receive my next constant current board design. If I assemble that and it works, I can then proceed to building a board to host a high power LED. That will introduce all sorts of new problems (heat management) that involve going into Kicad, thinking about stuff, making some experiments, sending a design to JLCPCB, waiting a week, and then assembling a bunch of boards, most of which will burn out (high power LEDs are tricky, if they got hot they fail faster). There's an opportuntity to buy some thermistors (little temperature measuring devices) and put them on the board to see how well my design for heat spreading it. At the end of all this, I'll have a world-class transmission light microscope that can track tardigrades for hours at a time (itself an enjoyable delve into modern computer vision techniques), and I've talked to the world's leading tardigrade researcher, who wants to incorporate my ideas into his research to make tardigrades a model organism. By the way, if I had stayed in academia, I would NEVER had the time, money, or energy to pursue this; I'd be stuck working on my funded research. NOBODY wants to give me money to design scopes that are roughly where state of the art was in the 1970s. But if I keep this up, in a few years I'll be ready to go play with the big boys and girls in the robot biotechnology labs with their $1M toys. Bringing this back to Peter, I had the chance to work with him on a project (attempting to disprove the Beal conjecture by finding a counterexample). He did all the brilliant math and we wasted a bunch of CPU (and I mean A BUNCH) trying to find counterexamples. I like how when he wrote https://norvig.com/beal.html he wrote in the nicest possible way that I was wasting time and energy. reply jdash99 8 hours agoprevheh... this article inspired me to start learning how to program. Around 12 years ago, I wrote this tweet https://twitter.com/Jdash99/status/285142421774405632 so I didn't forget my goal. Still learning though. Thanks Peter Norvig. reply arp242 14 hours agoprev24 hours? Oceans of time! I had \"Teach Yourself C++ in 10 minutes\". I had done some MSX-BASIC, but after we got a \"real\" PC I wanted to learn a \"real\" and modern language. This is what they had at the local bookshop. The \"10 minutes\" is done by explaining what C++ is and then it declares \"there, in the last 10 minutes I explained things and you now know what C++ is\". Ehh... I didn't understand a lot of it. Chapter 5 or so is templates. It's pretty thin, and just rushes past things and never takes the time to really explain anything. It may be somewhat suitable if you're experienced in other languages, but it's absolutely not suitable for beginners. Visual Studio also didn't help (at the time I thought you needed VS to program on Windows – it was 1999, we didn't have internet, and I was 14, so what did I know?) Aside from being a border-line scam, these books are worse than useless and actively harmful. As a result of this book I gave up programming for years, thinking I just didn't have what it takes. Wasn't until years later that I discovered this \"Linux\" and then \"FreeBSD\" thing that I discovered you can \"just\" write programs with \"just\" a text editor, and that things like Perl and Python and C exist. If you see one of these things at the bookshop you should steal it and throw it out. Haha, only serious. reply reactordev 14 hours agoparentReminds me a lot of when I was 13 and had learned Visual Basic 6 and wanted to make a game so my mother bought me a book on how to make games. “How to make games” she said excitedly as she handed me the book. “How to Make Games” it indeed did say. It also said under it “in C++ and OpenGL”. I had no idea what I was doing or what was going on. Enter high school. An elective called “Computer concepts and programming” was the only computer class outside of “Keyboarding”. It was taught by a female teacher who used to write punch cards for a living. She introduced us to C. All of the sudden, that book from a few years ago clicked in my brain and next thing I knew, I was writing games in C++. They were crap. Horrible performance. But I made them from scratch. Fast forward another decade and then a lot of these Packt publishing style books on making games and learning coding - except for the holy grail of book series - GPU Gems… if you ever want to feel stupid, go read some GPU Gems articles. Today there’s a lot of choices - PBR - Vulkan - anything Eric Lengyel. I still feel like it’s a trap. All these “Teach yourself…” should really be titled “Become obsessed with…” reply paulpauper 11 hours agoparentprevTeach yourself in one minute: copy paste the \"hello world\" example from wikipedia reply rmbyrro 16 hours agoprevAmazing how this aged so well. Perhaps the best validation of the quality of the advice. reply fallingfrog 7 hours agoprevGuess I should return my dog eared copy of “quantum physics for complete and total nincompoops” then. reply dukeofdoom 17 hours agoprevIt's never been easier then now. For example, if you want to learn how to make games... There's a guy on youtube called clearcode. He will teach you how to make games, in a Bob Ross voice...pretty much from scratch. You can also use ChatGPT to help you out. The resources for learning are so much better. Socratic method of just asking questions is now possible with AI. I think Sam Altman said that he is seeing x3 productivity increase from AI helping out programmers. reply jrpelkonen 14 hours agoparentPersonally, I’d like to see the data/research behind the “3x” claim to buy it. Especially when it is hard to imagine Sam Altman as an unbiased observer when it comes to benefits of AI. reply iskela 12 hours agorootparentOne angle to these multipliers would be this: A generalist programmer can take other tasks of sw-engineering than just programming with the support of ChatGPT. Like DevOps, DBA and test-automation. For small team or company that is then actually saving or postponing FTE hires reply walthamstow 16 hours agoparentprevI agree there are many more great resources but also many more terrible ones which will take your money or attention and give you barely anything in return. reply NoraCodes 15 hours agoprev> Why is everyone in such a rush? Because we live under an economic system that says you must produce value for capital or die. This is all very good advice. AND, I think we would have many fewer bad programmers and many more good ones if fewer Knuths were spending eight to ten hours a day mopping floors at fast food restaurants for $7.25 an hour, or writing garbage JavaScript for fly-by-night startups for $65,000 a year. reply bsdpufferfish 10 hours agoparent> you must produce value for capital or die. Can you name any social structure in which this is not true? Even medieval monks who are participating in a completely different society have to do the chores. > Knuths were spending eight to ten hours a day mopping floors I don't believe this happens and I know quite a few eccentric and unsocial smart people. Much more likely is them to spend the next 10 years at a relatives house speed running Mario. reply wizzwizz4 9 hours agorootparent> and I know quite a few eccentric and unsocial smart people. Selection bias. People who have been able to distinguish themselves as “smart” are already a narrow sample, as the results of many UBI initiatives suggest. > I am, somehow, less interested in the weight and convolutions of Einstein’s brain than in the near certainty that people of equal talent have lived and died in cotton fields and sweatshops. — Stephen Jay Gould reply NoraCodes 8 hours agorootparentprev> Can you name any social structure in which this is not true? That's a rather disingenuous framing; I think we could probably do quite a lot to reduce the extent to which it's true without any particularly radical changes to our society. When we do start talking about radical changes, there are a lot that are not just likely to work but actually pretty well proven, like a UBI, improved labor rights, well-regulated and well-supported unions, wealth taxes, and so forth. The possible alternatives are not \"if you don't have a job you starve on the street\" and \"fully automated luxury gay space communism\". > Much more likely is them to spend the next 10 years at a relatives house speed running Mario. Despite the disdain which you seem to hold for speedrunners (why?), a lot of really interesting hacking comes out of the speedrunning community. Some very interesting applications of deep learning had their start in the TAS community. I'd rather ten people \"waste\" my tax dollars on speedrunning or art I don't like than one person be prevented from making art that's important to me (or doing some cool math, or whatever) because their boss's boss wanted a percent of a percent towards another yacht. reply archsurface 17 hours agoprevnext [3 more] [flagged] frfl 17 hours agoparent> Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something. https://news.ycombinator.com/newsguidelines.html reply archsurface 14 hours agorootparentI don't think it needs spelling out. Make an effort if you must. reply bluetomcat 18 hours agoprevnext [16 more] [flagged] forgetfreeman 17 hours agoparentYou're most likely getting downvoted because the modern lets-hot-glue-a-bunch-of-dependencies-together approach notwithstanding programming has gotten significantly more complex over the years. Can you muddle through with youtube videos and SO? Sure, if you want the career equivalent of staggering around in the dark stepping on rakes. reply bluetomcat 17 hours agorootparentThe idea that one needs MIT-level training with SICP and AOCP is elitist and sickening. You start by writing small and useful tools that help you explore the language features. You compare your code to other people's code solving a similar problem. You look for ways to make it shorter, more readable, more efficient by reading SO and watching YouTube. reply forgetfreeman 5 hours agorootparentNobody said an Ivy League educations is (or should be) a requirement to write code. That said without some form of guidance a fledgling developer has no way to discern good code from bad or grasp the architectural or security implications of some random-ass code snippet they lifted off of SO. So again, unless your plan is to spend the bulk of your career repeating other people's mistakes in an effort to learn the hard way getting some kind of formal training should be a primary goal. I'm entirely self",
    "originSummary": [
      "The article critiques books that promise to teach programming quickly and highlights the necessity of years of practice to become an expert.",
      "It emphasizes the limitations of these books and stresses the significance of challenging oneself and receiving feedback.",
      "The summary underscores the importance of hands-on learning and references Malcolm Gladwell's concept of 10,000 hours of practice to achieve mastery. Genuine interest and dedication are essential in mastering programming."
    ],
    "commentSummary": [
      "This discussion covers various topics related to programming, including the impact of programming books on careers and the nostalgia for learning through technical books.",
      "The use of AI tools like ChatGPT and challenges in learning programming languages are also discussed.",
      "The discussion emphasizes the importance of continuous learning, practice, experimentation, and ongoing improvement in order to become a skilled programmer."
    ],
    "points": 497,
    "commentCount": 262,
    "retryCount": 0,
    "time": 1705331167
  },
  {
    "id": 39002138,
    "title": "FSRS: A Next-Gen Spaced Repetition Algorithm for Enhanced Memory Retention",
    "originLink": "https://github.com/open-spaced-repetition/fsrs4anki/wiki/ABC-of-FSRS",
    "originBody": "open-spaced-repetition / fsrs4anki Public Notifications Fork 110 Star 1.8k Code Issues 11 Pull requests Actions Wiki Security Insights ABC of FSRS Jump to bottom Jarrett Ye edited this page · 17 revisions Pages 11 Home ABC of FSRS Advanced methods of optimization Compare Anki's built in scheduler and FSRS FAQ How does the scheduler work? Research resources Spaced Repetition Algorithm: A Three‐Day Journey from Novice to Expert The Algorithm The Benchmark The mechanism of optimization Clone this wiki locally FSRS is a modern spaced repetition algorithm that was developed by Jarrett Ye. It aims to learn your memory patterns and schedule reviews more efficiently than Anki's legacy SM2 algorithm. The goal of a spaced repetition algorithm is to calculate the optimal intervals between reviews. But what makes an interval \"optimal\"? In FSRS, an interval is considered optimal if it corresponds to a specific probability of recalling a card. For example, if you want to be 90% sure that you will successfully recall a card the next time you see it, the optimal interval is the one at which the probability of recall is 90%. FSRS is based on the \"Three Component Model of Memory\". The model asserts that three variables are sufficient to describe the status of a unitary memory in a human brain. These three variables include: Retrievability (R): The probability that the person can successfully recall a particular information at a given moment. It depends on the time elapsed since the last review and the memory stability (S). Stability (S): The time, in days, required for R to decrease from 100% to 90%. For example, S = 365 means that an entire year will pass before the probability of recalling a particular card drops to 90%. Difficulty (D): The inherent complexity of a particular information. It represents how difficult it is to increase memory stability after a review. In FSRS, these three values are collectively called the \"memory state\". Every time the user reviews a card, the memory state associated with that card changes, unless it was a same-day review. FSRS only takes into account one review per day, the chronologically first one. Each card has its respective DSR values, in other words, each card has its memory state. To accurately estimate the DSR values, FSRS analyzes the user's review history and uses machine learning to calculate parameters that provide the best fit to the review history. The most recent version of FSRS uses 17 parameters in the formulas for D and S (the formula for retrievability doesn't require any parameters). If you are interested in the details, you can read the following wiki pages: The Algorithm and The mechanism of optimization. If a user doesn't have enough reviews yet, the default parameters are used instead. They have been found by running the FSRS optimizer on billions of reviews from ~20k users. Even with the default parameters, FSRS is better than Anki's default algorithm. Note that the users should not tweak the parameters manually. If you want to adjust the scheduling, all you need to do is choose an appropriate value of desired retention. Values between 70% and 97% are considered reasonable. In other words, with FSRS, users can target a specific value of retention, allowing them to balance how much they remember and how many reviews they have to do. Higher retention leads to more reviews per day. Aside from allowing the users to choose their desired retention, FSRS has some other advantages when compared to Anki's default algorithm. With FSRS, users have to do 20–30% fewer reviews than with Anki's default algorithm to achieve the same retention level. FSRS is also much better at scheduling cards that have been reviewed with a delay, for example, if the user took a break from Anki for a few weeks. In addition, the FSRS4Anki Helper add-on provides some useful features that are not available otherwise. If your Anki version is 23.10 or newer, read this guide. If your Anki version is older than 23.10, then you can use the standalone version of FSRS, please read this guide to learn how to install it. If you want to see how FSRS performs in comparison to other algorithms, read these pages: Benchmark and FSRS vs SM-17, one of the most recent SuperMemo algorithms. If you have any further questions about FSRS, check the FAQ. If you want to learn more about spaced repetition algorithms, you can check out Spaced Repetition Algorithm: A Three‐Day Journey from Novice to Expert. My representative paper at ACMKDD: A Stochastic Shortest Path Algorithm for Optimizing Spaced Repetition Scheduling My fantastic research experience on spaced repetition algorithm: How did I publish a paper in ACMKDD as an undergraduate? The largest open-source dataset on spaced repetition with time-series features: MaiMemo's Open-Source Memory Behavior Dataset",
    "commentLink": "https://news.ycombinator.com/item?id=39002138",
    "commentBody": "FSRS: A modern, efficient spaced repetition algorithm (github.com/open-spaced-repetition)330 points by rickcarlino 18 hours agohidepastfavorite93 comments ekidd 16 hours agoOne massively overlooked way to improve spaced repetition is to make easier cards. It's surprising just how easy an effective card can be. I started out using Anki to learn French vocabulary. I'd make pairs of cards, with English on one side and French on the other. This started out easy, but became utterly brutal and depressing with several hundred cards in my deck. Too many near synonyms. I eventually took a hint from Katzumoto's Japanese advice, and started making cloze cards. I'd copy and paste an entire paragraph from an ebook or a web page, and hide just one word. These cards were easy, but also effective. Then I got lazier. I'd only hide half a word. Or I'd just boldface a word, and mark the card as a \"pass\" if I could sort of remember that word in context. And somehow, these cards actually worked better. Then I got lazier still. If seeing a card made me grown \"Oh, not that card\", I'd just delete it. If I missed a card 3 times, I configured Anki to permanently suspend it. If I actually needed to know a word, no worries, I'd see it again soon in a more helpful context. And my French vocabulary continued to grow by leaps and bounds. I don't think that biggest improvements will come from better spaced repetition algorithms. I suspect the biggest wins will come from improved card formats. And it's surprisingly hard to make a card too easy to be useful. (Source: 35,000+ Anki reps across three languages.) reply laurieg 6 hours agoparentYou're doing SRS right! Geeks like us love to get into SRS algorithms and chase after the 1% improvements with a cleverer repetition algorithm or a better input method. The real failure mode is much more mundane: People give up. I see it all the time. People cram thousands of cards into Anki in their first month learning something. After a month or two they are so overwhelmed with reviews and the reviews become such a chore that they just give up. (Of course, there are people who manage to add thousands of cards every month for years and years. These are the people who would probably do nearly as well with just a pen and paper. ) Two pieces of advice that make all the difference: Make your cards a little bit 'too' easy and be rather selective with your cards. When you first make a card you're probably actively studying the subject of the card. You're very familiar with it and it's all in your head right now. The temptation is to make a card that is fun and challenging for you right now. Resist! Instead, make a card that feels slightly too easy, so that in a week or two it will be enough to tickle your memory rather than confuse you. Also, people dump entire books worth of sentences into Anki. I like to use the metaphor of walking through an orchard: take your time, look around and grab one or two of the nicest apples you find. If you try to grab everything you're only going to slow yourself down. Also, if you pick up a rotten apple (uninteresting/too difficult card) it pollutes your entire deck. You start to resist review your flashcards. reply naniwaduni 4 hours agorootparent> The real failure mode is much more mundane: People give up. The other major failure mode is similarly boring: sometimes it's just not useful to blindly memorize things. The exact problem that spaced repetition solves is pretty niche, and while it can be \"close enough\" to be beneficial in adjacent endeavors, it's also extremely subject to Goodharting. The more hardcore you go into optimizing your SRS procedure, the likelier it gets that the metrics you're optimizing for depart from your actual goal. reply jamager 2 hours agorootparent> sometimes it's just not useful to blindly memorize things Specially for language: https://thehardway.guide/srs (own content) reply cratermoon 5 hours agorootparentprevIs there really any solid research determining the \"best\" algorithm, or even ranking them? As best I can tell, any process to repeat wrong answers more often and the correct answers less often, and does so with some amount of increasing time delta, will work. But I have yet to see any proof that one algorithm is better than another. reply jarrett-ye 2 hours agorootparentWe can compare algorithms by their accuracy. Here is a benchmark: https://github.com/open-spaced-repetition/fsrs-benchmark reply jodrellblank 3 hours agorootparentprevI don’t know if there is, but the forgetting process follows the https://en.wikipedia.org/wiki/Forgetting_curve Ali Abdaal claimed in one video that memories are strengthened more when something is only just remembered than when it is easily remembered, so as late card prompt as you can get, before actually forgetting. I don’t remember his source for that. And there’s simply limited time, a thing which repeats wrong answers more but not as much as you need is wasting your time and a thing which doesn’t reduce correct answers as quickly as possible is having you waste time reciting things you know. So there seems to be room for ways to rank different algorithms. reply bryanrasmussen 4 hours agorootparentprevI mean this any process that you suggest is a set of algorithms. It would seem logically strange to suggest that when a method is not within the set of algorithms it will not work, but as soon as any method is used that repeats \"wrong answers more often and the correct answers less often, and does so with some amount of increasing time delta\" it will work equally well with other methods. I would suspect if this does appear to be the case that there probably is an optimal algorithm to start with but that all methods chosen here decrease in utility if you stay with the same variables (repetition frequency of wrong answers, repetition frequency of correct answers, time delta) for too long, the same way there are beneficial exercise methods for getting specific results when starting out that need to be varied if you want to keep getting results in that area without a decrease in the quality of the results. reply bluquark 14 hours agoparentprevFor what it's worth I've gone the opposite direction (one language, 70k Anki reps). For me, carefully adding context has largely felt like time wasted at card creation time (which can a surprisingly large proportion of study time per card, given how brisk reviewing usually is) and I've been bothering with it less and less. The default simple cards my dictionary plugin creates are usually good enough for me. I go out of my way to add context on the front of the card now mostly when it's a specialized word almost always seen within that context (so there's zero added value in learning it independently). I do agree with the general idea that laziness and going easy on yourself is good though. I give myself quite a lot of slack when grading my answers, applying a \"my understanding of this word is close enough to avoid confusion in practice\" threshold rather than some impractical ideal of native-level mastery. reply ekidd 13 hours agorootparent> For me, carefully adding context has largely felt like time wasted at card creation time I actually had several custom tools that heavily automated card creation—I could grab a sentence from a web page, or bulk import highlighted phrases from an ebook. Then I had a UI which allowed me to easily highlight an interesting word, and either cloze it, or add a Wiktionary definition on the back. Then I had an Anki plugin to bulk import the cards. This could all obviously be combined into a single tool, and occasionally someone tries. For my most heavily automated experiment, I used a tool similar to subs2srs to import sound, bilingual subtitles, and tiny screen captures from 4 episodes of Avatar: The Last Airbender. That was a fascinating experience, and I'm still earwormed with the dialogue of those episodes a decade later, after only a couple of months of Anki reviews. (See elsewhere in this thread for a link.) Unfortunately, I'm not convinced that there's a good startup market for language-learning tools. Language learning is normally aspirational, much like a gym membership. And customers don't have any serious plans on how to reach their stated goals. (Again, like a gym membership.) Duolingo isn't terrible, but I suspect—based on lots of Anki experiments—that it should be possible to build much more effective tools than Duolingo. I'm just not convinced that anyone but serious ESL students would pay for them. Too many genuinely good tools in this space have sunken quietly, despite a user-friendly UI and a good landing page. reply jamager 12 hours agorootparentI'm working on that, wish me luck :) I guess I am of the few that would pay for a good tool aimed at serious learners, but as I could not find any (in language space almost everything is a Duolingo clone), I am building myself. So far I think I have proved my main hypothesis: it works really well for me. It's not magic, but it saves me many hours of learning. Whether it could work for someone else, is an entirely different story... but on the other hand, I have no big ambitions. reply pgraf 10 hours agorootparentI would be very interested in that thing :-) Do you already have something you can share or a page where we can track your progress? reply jamager 2 hours agorootparentNo, but you can subscribe to https://thehardway.guide and I'll let you know when it comes... in addition, you get a free book :) reply alwayslikethis 10 hours agorootparentprevShameless plug for my tool https://github.com/FreeLanguageTools/vocabsieve/ It can do sentence card creation, ereader imports, and vocab tracking, among other things. reply bsder 10 hours agorootparentprev> Duolingo isn't terrible Unfortunately, it seems like Duolingo is terrible. Spaced repetition cards seem to blow it away. reply gbear605 7 hours agorootparentDuolingo and spaced repetition flashcards serve different purposes. Flashcards can’t teach you grammar or pronunciation, while Duolingo does a bad job at actually teaching you a large set of vocabulary. Using both of them is probably a good plan, though even better is flashcards + a real class. reply yorwba 1 hour agorootparentFlashcards can teach you grammar. Explicitly, by writing explanations of various grammatical phenomena on flashcards. Implicitly, with usage examples that demonstrate how the grammar works. Flashcards can teach you pronunciation. Explicitly, by writing explanations of how to produce various sounds on flashcards. Implicitly, with recordings that demonstrate how things are pronounced. (Ok, paper flashcards can't do that, but we're not talking about those, right?) reply victorlf 10 hours agorootparentprevProbably not terrible, but serving a different purpose. I recommend this interview with Duolingo's founder Luis von Ahn: https://www.npr.org/2020/05/22/860884062/recaptcha-and-duoli... reply alwayslikethis 10 hours agorootparentprevIf you have better tooling, you can add cards way faster. My project (https://github.com/FreeLanguageTools/vocabsieve/) is a tool to help you make sentence cards nearly effortlessly, or even converting ereader highlights, which probably averages to maybe a few seconds per card created. reply huhtenberg 10 hours agorootparentThat's pretty cool. Removing UI friction is essential to improving the learning routine. reply kqr 57 minutes agoparentprevThis is right. I tried and gave up on spaced repetition a few years ago. When I tried again a year ago and did more research, I realised my problem on the first attempt was that I made too complicated cards. I went back and dug up some of my more valuable cards from my last attempt, and some of them were so complicated that I had to break them up into 10–15 cards now that I know how to design good cards. That said, I don't think the point is to make them easy. Since you want to aim for a 90-something percent success rate to get the most benefit out of it, too easy will make the going slower. The point is to make them atomic and that usually feels easy, even if you fail 10 % of recall tests. reply neves 12 hours agoparentprevThe original SuperMemo 20 rules for creating SRS cards are a treasure trove: https://www.supermemo.com/en/blog/twenty-rules-of-formulatin... It will improve a lot your cards reply jwells89 15 hours agoparentprevI’ve been using Anki on and off for years for language learning but have most recently been using it to study for online uni courses. Something that’s become evident, perhaps due to the varied nature of the content (vs. all language) is how much gravity card formatting has. In decks made by others I find myself frequently re-wording the answer sides of the cards which makes a noticeable difference in retention — answers that are succinct and flow nicely stick better. So in short, I’d concur. Card format is important. If you find a card that feels awkward somehow don’t hesitate to rework it. reply jarrett-ye 2 hours agoparentprevYeah. I'm the author of FSRS and I agree with you. In my opinion, the quality of cards determines the upper limit and the algorithm just helps you achieve the upper limit efficiently. reply tetha 15 hours agoparentprevI'm kind of wondering the same thing learning my guitar: Maybe a good thing is to approach an issue with different ways your head has to think about it. Like, yes. I can just spaced repetition the heck out of the notes on the fretboard. Just hammer my head into the notes on a string until I pretty much just give up. Always an idea. But I've found it more effective to mix contexts up. Some weeks, I just drill notes because I'm lazy. But then I also start tinkering around for a week with some weird scale, like hungarian scales and such. Some other week, I'm tinkering around with arpeggio chords, some other week with cord progressions with power chords, some weeks I'm trying to replicate some sound or feeling of a song. And over time, the brain is putting things together. Suddenly there are realizations: Hey, this is just a G-Minor scale, which makes sense for a somewhat solemn song. Oh, this is just a G-Major scale but we skip those. Wait, I remeber half the notes of the scale, isn't this just that pattern? Also, if the scale is like this, couldn't we try playing that? It's just a weird feeling, because the amount of things I think I know expands at a much lower rate of the things I realize I don't know - or don't have the technique for, lol. But I'm kind of considering using a spaced repetition algorithm to just poke for 5 to 10 minute guitar things to do to get both the muscle memory and the neural connections about them going. reply epiccoleman 8 hours agorootparentI've thought about doing this too - and there are certainly things that are worth rote memorization on guitar. But my experience has been that things stick a million times better when I learn them in context and really focus on using them, so I'm unsure how useful implementing spaced repetition would be vs \"just play yer guitar\". That said, the notes on the fretboard is well worth the effort of rote memorization. I found the technique in this video[1] worked absurdly well for me. Years and years of only knowing the notes half-assed and not very well on the middle three strings got absolutely busted after doing this for a few minutes every time I was waiting on a build or something. I can nearly always find a note now, I'm not quite to instant recall but have substantially more ability in this regard now. A place where spaced repetition might be worth it is in memorizing all the triads or keys, which is good to have instant recall on. I have these decently in my head but usually have to \"convert\" from a nearby chord in C major for oddball ones, which is fine while practicing but not what you'd want for performance. [1]: https://youtu.be/PJddQ6Q0UDo?si=4dmR7_tlsWIhgvYg reply steve1977 13 hours agoparentprev> One massively overlooked way to improve spaced repetition is to make easier cards. At least with SuperMemo, this is actually one of their main tips. See also: https://supermemo.guru/wiki/20_rules_of_knowledge_formulatio... reply jamager 12 hours agoparentprev> I don't think that biggest improvements will come from better spaced repetition algorithms Exactly that, specially for language learning. The stated goal of hitting a target probability is pointless IMO. Language acquisition is not about memorizing words, but progressive familiarization (eg via retrieval practice). You have to expose yourself to massive amounts of language, create your own cards fast, review them faster, move on even if you \"fail\", don't do too many repetitions (6-8 should be enough for >95% of cards) The most important aspect of an SRS algorithm is to be practical: sensible choices, equally spaced out among them, that allow you to decrease / maintain / increase intervals without ever punishing you for failing. reply callistus 10 hours agoparentprevI've found Andy Matuschak's essay, _How to write good prompts_ [1] very helpful in making more impactful cards. https://andymatuschak.org/prompts/ reply AlchemistCamp 1 hour agorootparentWhat were the key insights or surprises you got from that 13,000 word piece? For background, I contributed to Anki long ago, wrote regularly about SRS in the late 2000s and got deeply into them for language learning for a few years. Later, I mostly stopped using them since I found extensive reading both more interesting and a better return on my time. I’m interested in the topic but am not new to it. reply piazz 15 hours agoparentprevThis is great, going to try this approach with my Japanese Anki reps. Mind linking out to Katzumoto’s Anki advice? Is this this one? https://tatsumoto-ren.github.io/blog/setting-up-anki.html reply huimang 12 hours agoparentprevWhat killed Anki for me was having to add cards. It is such a chore adding single word cards. I also ran into the problem of increasingly niche synonyms that I'd learn, but would rarely see in text. For some reason I never really considered cloze cards. The anki default of 8 relapses before suspending a card is much too high. It took me a while to realize, but dealing with problematic cards takes up -way- more energy than learning new cards... it's not energy/time efficient at all. Do you have any recommended sources on cloze style cards? [45k reps here for Korean] reply jacquesm 14 hours agoparentprevYou have absolutely nailed it. Anki should work as a sliding window on material that you wish to learn not as an ever increasing bucket with more and more stuff in it. That way the new material will always be underexposed. It's much better to keep moving. I have the exact same patterns with learning pieces to play on the piano, and within those pieces you see those patterns again (it's almost a fractal). reply fudged71 14 hours agoparentprevLove this idea! Does Anki or any of its plugins support creating a difficulty progression when creating cards? ie. half-word cloze, then full-word, then multiple choice, then q&a, etc. I’m not sure how this would work in practice. Like would the next difficulty card be added to the deck once the easier card has reached a threshold? reply cdwhite 7 hours agorootparentIn relatively recent versions of Anki, you can create nested Cloze deletions: \"{{c3::{{c1::foo}}{{c2::bar}}}}\" will show you cards \"[...]bar\", \"foo[...]\", and \"[...]\", in that order, all with answers \"foobar\". As for multiple choice and q&a---my practice is to make both Cloze and basic cards for, well, most things---Cloze are good for the early steps and for seeing how different pieces fit together, but basic cards are more demanding, and without them I don't quite feel like I've learned a thing. (FWIW my primary use is physics & the mathematics behind it, not language learning.) reply jnsie 15 hours agoparentprevTruly sorry to hijack, but if you have any recommendations for shared French vocab cards I'd greatly appreciate you pointing me in the right direction. I have some French from school, but would like to get back into it and it's...daunting. reply rpb92 15 hours agoparentprevYou've inspired me to rethink my approach to Anki. I've used it on and off for the last few years, but always fall in the trap of creating cards that were too convoluted. Sounds like I could benefit from some deliberate \"laziness\". Did you ever feel like you were answering correctly, on close cards specifically, not because of an improved understanding but because you were associating the correct answer with the prompt/excerpt? Would appreciate any advice on how to avoid this! reply jamager 1 hour agorootparentThat is a legitimate problem of SRS (recognition vs knowing), I use a few ways to avoid it: -Don't do many repetitions of the same card. Eg. if i want to learn 5 new specific words, maybe I use 6-8 sentences that each use 2 new words, so that each new word shows in 2-3 cards. Then I only review each cards 6-8 times in a 2-month period (normally). -Use long intervals. I rather forget than learn to recognize the thing. But even if I forget, I almost never click \"fail\". You learn with retrieval effort, even if you just forgotten the thing (that's science) -Even so, by the 4-5th rep I start recognizing cards, so I be mindful when reviewing, and force myself to really think the answer (occasionally, writing down the answer, for instance). This clashes with my principle of going fast, so there is deff a balance. -I don't track \"streaks\", but if I struggle or I have the feeling that something shows up too much, I archive and create more cards. reply ekidd 13 hours agorootparentprev> Did you ever feel like you were answering correctly, on close cards specifically, not because of an improved understanding but because you were associating the correct answer with the prompt/excerpt? I actually suspect that associating the word with the context helps, as surprising as that might be. Let's say I grab a few sentences from an interesting article, and I boldface a word. I'll mark the card as \"pass\" if I at least sort of understand it in context. On day 1, I honestly might find the word fairly confusing. I can explain what it means, but maybe the grammar is unfamiliar. Ditto for the first few reviews. But then around day 8 or so, the card disappears until day 20 or 30. And the next time I see that card, suddenly the odd bit of grammar is completely natural and obvious. There's maybe some kind of medium-term memory consolidation mechanism occurring? Something happens when I'm not looking at it. Seeing the word in context somehow allows my brain to grab on. The human brain contains some incredibly powerful language learning machinery. In adults, that machinery still exists. Even if it's a bit rusty. And that machinery seems to work best on semi-comprehensible speech in a natural context. So think of Anki less as a set of facts you must learn, and more as a tool to distill and concentrate natural language so that you can let your brain work on your weak points. (And as soon as possible, start reading lots of books and watching TV! I learned the hardest 10% of my vocabulary using Anki, and much of the rest from context reading books.) Also, I find it fascinating that LLMs are trained using a very similar process. Either \"predict the next word\" or \"fill in the blank\". Now, they need a lot more input than any human does, but the fact that fill-in-the-blanks works so well in both cases is fascinating. Here are two of the most interesting experiments I tried with Anki: http://www.randomhacks.net/substudy/ https://blog.beeminder.com/hieroglyphs/ (The only language I ever bothered to push to a high level was French. Spanish and ancient Egyptian were basically experiments to see how quickly I could pick up the basics, using the tricks I learned while working on French. A language that you can use at a professional level is a bit like a pet; it requires ongoing care.) reply dataangel 12 hours agoparentprevHuh, hiding part of a word is brilliant. I never thought to do that even though I made tons of cloze cards. reply surfsvammel 11 hours agoprevI’ve learned tens of thousands of foreign language words using Anki and have always find that having pictures on the cards help me remember the words. I currently have a (foolish?) project. I’m trying to memorize the 750 cards of a quiz game that we play in the family. All questions are answered by a year. So for example: “What year did Coca Cola Light come out?”. I have been using Midjourney to generate images for those cards which makes it so much eaaier to recall. I have a system. I have a person representing each century; Einstein is 1900-2000 and for example Mari-Antoinette is 1700-1800. Then items represent the decade; a sixties car represent the sixties, jacket with shoulder pads the eighties and so on. I do something similar for the last digit. Then I have Midjourney generate such pictures, in a comic book style, and I save the most fun or absurd one and use that on the back side of the Anki card. The image is often easier to recall than the year by itself reply vunderba 7 hours agoparentThree things: 1. Look up PAO - it's a tangentially related mnemonic system that uses images. 2. Test your recall periodically with/without the images otherwise you may find that the true nature of recall (aka in the wild) without said images is adversely affected. 3. Is it Trivial Pursuit? A friend of mine deliberately memorized all the cards of the original Genus edition. reply surfsvammel 3 hours agorootparentIt’s not TP, it’s a Swedish game called När då då. The image is on the back of the card, with the answer. So trying to recall the year, I don’t get to see the picture. But, the picture is the first thing that comes to mind when I get the question and the from it I get the year. reply azan_ 11 hours agoparentprevWow, that system is ingenious. I've always struggled with dates, gonna steal your idea from now on! reply hackernewds 10 hours agorootparentThe burning question is \"does it work\"? reply surfsvammel 3 hours agorootparentI don’t know. I’m through about 100 cards. I’ll let you know in a couple of months:) reply petesergeant 8 hours agoparentprev> I’m trying to memorize the 750 cards of a quiz game that we play in the family I'm currently doing the same for geography ... flags, capitals, etc. I reckon it will give me a +5 advantage on most trivia nights reply t_mann 12 hours agoprevIt seems from the description that FSRS still puts an exact review date on each card? This feature was pretty much the reason why I stopped using Anki. I'm not in college and not doing exams, I just want to practice when I feel like it, maybe with large breaks between sessions, and not feel like there's a backlog building up. I think Anki is a great app, I just wish there was an algorithm that would just randomly sample cards (with probability proportional to how urgently you need to review it) rather than put a review date on them. Something like https://github.com/fasiha/ebisu but available as an Anki plugin (if that supports custom algorithms on mobile yet?) or a similar app with an open format for cards. reply eps 1 hour agoparentI made a half-baked app that did something like that and it worked very poorly. For facts I remembered repeating them was annoying, and many of those I forgot, I forgot them completely. So repeating served little purpose and the progress was very slow. The key is to repeat when one _almost_ forgets and this can't be done without due dates and scheduling. reply AngaraliTurk 10 hours agoparentprevBut that's not how memory works...you can't put your memory on hold like you're suggesting. There's a reason FSRS follows a personalized memory curve. reply oh_sigh 5 hours agorootparentYou can't, but I wager a student excited to doing a review but with a suboptimal method, will do better than a student who dreads the review with the optimal method. reply t_mann 3 hours agorootparentprevPlease don't make assumptions about my goals. I was clear about my requirements and asking for recommendations. reply jarrett-ye 2 hours agoparentprevYou can use a filtered deck and sort cards by relative overdueness in Anki. reply charcircuit 10 hours agoparentprev>I just want to practice when I feel like it, maybe with large breaks between sessions That's how SRS already works. But if you clear out the \"backlog\" you can no longer practice whenever you want and must wait for a period before you will be able to practice again. reply victorlf 18 hours agoprevVery interesting. According to the benchmarks, with this algorithm, users can review 20-30% fewer cards than with the classic Anki algorithm. Just a few days ago, I published a Python implementation of the classic SM-2 algorithm that I use for https://python.cards, but I may switch to FSRS. https://github.com/vlopezferrando/simple-spaced-repetition reply teruakohatu 15 hours agoparentYour python.cards looks great. I suggest you add a few examples. Any chance you are open sourcing the web app? I can see it being a popular way for niches to show flashcards eg. for students to learn X reply victorlf 15 hours agorootparentThanks! I definitely will add more examples to the landing page, currently I'm working hard on the decks: pathlib in depth, a tour of the stdlib and Norvig's tricks (a collection of tricks from the Pytydes of Peter Norvig). I believe the hardest part of using spaced repetition to learn programming is creating good decks, it's a ton of work. About open sourcing the web app, I might do it. It's a Django app, and I've published some videos while coding it (https://www.youtube.com/channel/UCyWUj9r0soytotuuh2JnPrw), so it's no secret. reply teruakohatu 15 hours agorootparentI forgot to mention in my previous comment that I saw no sign up box for the newsletter. > I believe the hardest part of using spaced repetition to learn programming is creating good decks, it's a ton of work. Agreed. To have always been disappointed with the programming decks I have created. > About open sourcing the web app, I might do it. It's a Django app, and I've published some videos while coding it I saw the videos, thanks. I think a generic platform would have value, even if there was a paid option with more features (payments etc.) reply victorlf 14 hours agorootparentIt's weird you didn't find the sign-up box to the waitlist, this is how it should look like: https://imgur.com/a/0ZIbz4p, I actually got some sign-ups from this comment! Anyway, I can sign you up manually if you wish. reply pitherpather 15 hours agoprevGiven the importance of spaced repetition, I've wondered if a modular approach is called for, contra Anki. Aren't there three separate items? 1) Your cards (or a subset of cards). 2) The history of your interactions with them. 3) An algorithm (potentially just-in-time) taking that history into account to present cards to you, thereby adding to the history. reply bluquark 14 hours agoparentAnki FSRS moves closer to being a \"just-in-time\" algorithm based only on user-provided inputs. And although its data structures aren't strictly modular, they come as close as practical to that ideal while still remaining compatible with legacy Anki decks and extensions. In practice, that's illustrated by the fact that there's now a button to fully recompute all intervals and difficulties based only on your history and the current algorithm tunings. And if you've already been using FSRS and the tunings haven't changed, the recomputation won't have any effect because it's equivalent to the incremental computations after each review. So in principle it could be thought of as a just-in-time pure function, which involves a cache of generated data only for legacy & performance reasons. reply siraben 16 hours agoprevI’ve been using FSRS for 3 months and it’s finally resolved some of my pain points about having to trial-and-error adjust the old SM2 scheduling algorithm, since the content of each deck can greatly affect what the optimal retention is. Now you can just retrain the weights for each deck you have every few months and it will adapt appropriately. The paper[0] is also definitely worth reading if you want to see some rigorous analysis of large-scale real-world spaced repetition science. Because of the extensive benchmarking most people probably will not benefit from refitting the weights to their collection until they have thousands of reviews (author recommends 1k+). Note it still works fine even if you do your cards late, since the recall probabilities are based on the stability and when you last reviewed the card, and the stability will update a bit longer if you somehow managed to still recall a card after the due date. [0] https://dl.acm.org/doi/10.1145/3534678.3539081?cid=996605471... [1] https://github.com/open-spaced-repetition/fsrs4anki/wiki/The... reply rasmus1610 2 hours agoprevFor some related shameless self promotion: I made a free open source tool that let's you create Anki cards from youtube videos [1]. I would love some feedback. BTW, the code is on github [2]. [1] https://youtube2anki.fly.dev/ [2] https://github.com/vacmar01/youtube2anki reply flashcardist 15 hours agoprevI use multiple spaced repetition apps per day just for fun because I like doing flashcards as a hobby. I have tried this out, its good, but still not as good as the newest version of Supermemo. You can tell if you put the same or similar material into two or more apps. FSRS is much better than almost everything else out right now though and I think it will be better than Supermemo very soon. I tried Mochi Cards for about a year and it was just okay, a little better than a default Anki install. Mnemosyne is the same. The Supermemo SaaS app is okay, but I don't like how they structure their language materials. For language vocab, I use Clozemaster, but then I put the sentence into Supermemo after I get it right because the SM algo is that much better. They also have ChatGPT explanations for each word of the sentence. I also put those into Supermeno. The hardest part is making good cards for sure. This will help with more ideas: http://arxiv.org/abs/2401.01257 and https://rust-book.cs.brown.edu Also, I have not found a flashcard program that lets you make cards as fast as Supermemo. With Supermemo, you paste in a chunk of text (ctrl-n), highlight a word you want to make cloze deletion from, and press alt-x. You can do it multiple times on the same piece of text, and every time you do it, you get a new cloze deletion card in your reviews. Almost every other app, you have to make a single card at a time. I think its because most other apps stick too hard to the cards and decks metaphor. Supermemo uses a tree structure to organize everything. It makes a big difference. Technically, you don't really need to organize anything though. People act like the material they learn is going to be categorized into neat decks in their head. reply dotancohen 15 hours agoparent> With Supermemo, you paste in a chunk of text (ctrl-n), highlight a word you want to make cloze deletion from, and press alt-x. You can do it multiple times on the same piece of text, and every time you do it, you get a new cloze deletion card in your reviews. In Anki (on Debian at least) it's Ctrl-Alt-C. reply knubie 9 hours agoparentprev> Also, I have not found a flashcard program that lets you make cards as fast as Supermemo. With Supermemo, you paste in a chunk of text (ctrl-n), highlight a word you want to make cloze deletion from, and press alt-x. In Mochi it's mostly the same. Press n (new card), ctrl-v (paste text), select word, ctrl-l (make cloze), ctrl-[n] (where n is 0-9) to create a cloze group. Each cloze group will have its own \"card\". reply tianshuo 5 hours agoprevThanks Xiaojun for FSRS, I've talked multiple times with him about FSRS and Anki. In traditional spaced repetition systems like Anki+FSRS, learners often review knowledge always in the same context, which can lead to an understanding of knowledge as isolated units rather than part of a larger network. For example, learning words isolated does not fully prepare learners to use the language in real-life situations, where context, collocation, and usage play a significant role. Instead of isolated repetition, a better way to learn languages is to expose learners to words in different contexts and combinations, helping them to understand how words naturally form in chunks and sentences. This varied exposure can help learners build a deep network of neural connections, enhancing their ability to understand, recall, and use language effectively. So for learning languages, instead of Anki cards, we're building something that shows real-life short videos where each of our videos is a mini scenario, showcasing language use in real-life situations. This means students aren't just memorizing words, but seeing how they're used in natural contexts, complete with visual cues and body language. This approach allows students to understand the practical application of words and phrases, making the learning process more engaging and effective. Since the main reason that students fail to learn foreign languages is they don't keep on studying. Another thing that Anki lacks is, real-life scenario-based quizzes instead of \"do I recall this?\", students need to apply what they've learned in a fun, low-pressure environment. So, SRS algo is just part of the solution, and definitely not a silver bullet. There are a lot of things about memory, such as how emotions affect encoding - you don't need SRS to remember your first kiss or graduation day. People learn their mother tongue to fluency w/o using any kind of SRS, while most people fail to learn a foreign language to fluency even if they use SRS. reply jamager 1 hour agoparentThis is a valuable argument (learn in context, vary the context), but the mention of \"people learn their MT without Anki / grammar / study\" always bugs me. First and Second Language Acquisition is just apples to bacon. The baby and adult brains are different, and their needs, capabilities, and context are vastly different. reply tchvil 3 hours agoprevOxford Flash cards have a good take on spaced repetition. They provide actual cards, you can use the old way. Or you can then take a picture of them using their free app Scribzee, and review them digitally too. My son just aced his anatomy exam with them. https://www.my-oxford.com/int-en/oxford-flash-20-flashcards reply beardedwizard 3 hours agoprevIs spaced repetition good for learning anything other than vocabulary? reply dan0000 16 hours agoprevI'm working on building my own flashcard based studying application for long- and short-term learning. How would I go about implementing this? reply david_allison 16 hours agoparentLibraries: https://github.com/open-spaced-repetition/free-spaced-repeti... All are MIT licensed I believe, Anki is primarily AGPL reply g-w1 16 hours agoparentprevthere are a bunch of pre-existing ones here: https://github.com/open-spaced-repetition/ > Multiple Language Support: fsrs.js, go-fsrs, rs-fsrs, py-fsrs, cljc-fsrs, swift-fsrs and ex_fsrs reply nanna 16 hours agoparentprevContribute to Anki? reply talhah 15 hours agoprevIs this algorithm also available on mobile? reply david_allison 15 hours agoparentStable on AnkiMobile, available in the AnkiDroid 2.17 alpha: * https://github.com/ankidroid/Anki-Android/releases/ (Parallel.A) * OR: https://ankidroid.org/#alphaTesting reply notfed 15 hours agorootparentOnly 2.16.5 available in Play Store at the moment. reply david_allison 14 hours agorootparent2.17alpha15 (latest alpha) is available under the 'closed testing' track [0] on the Play Store. After following the instructions [1] (joining the Play Store testing programme, then the Google Group), the Play Store should distribute + automatically update the alpha. [0] https://play.google.com/console/about/closed-testing/ [1] https://ankidroid.org/#alphaTesting reply fermentation 15 hours agoprevInteresting, I've been using Anki for about 10 months to study Japanese vocabulary. I'm going to give this algorithm a shot, thought I'm not quite sure how to determine if will be \"better\" or not. I guess this at least allows me to remove my old anti-ease-hell addon. reply second_brekkie 11 hours agoprevIs there anybody here using this now? How does using the FSRS plugin on desktop effect the usage on mobile? I'm curious but don't want to mess up my anki setup. reply qustrolabe 5 hours agoparentEither wait some time for 2.17 AnkiDroid release or just use 2.17alphaXX from github. I'd prefer first option to evade any major bugs reply miga 11 hours agoprevI missed comparison to earlier repetition equations like SuperMemo. Is there any hope for comparison and reference, or will precursor be forgotten? reply gjadi 16 hours agoprevI wonder if there is plan for this to land in Mnemosyne[1]. I prefer Mnemosyne over Anki because I can self-host the web-sync server. 1: https://mnemosyne-proj.org/ reply fhars 16 hours agoparentWhat's wrong with `anki --syncserver`? (user management is a bit iffy, admittedly) reply gjadi 13 hours agorootparentMy understanding is that the anki Sync serveur is only for the sync part, there is no web interface to do the review. Also, was it always free? When I looked at what was available for Anki, the remote solutions were paid only and not selfhostable. Maybe I didn't look well enough back then. reply steve1977 13 hours agoprevInteresting approach for sure. Would be interesting to also see a comparison between to the SM-18 algorithm (which handles item difficulty differently compared to SM-17) reply jarrett-ye 2 hours agoparentYeah, here is the comparison between FSRS and SM-17: https://github.com/open-spaced-repetition/fsrs-vs-sm17 reply steve1977 1 hour agorootparentYes I saw that, that’s why I thought it would also be interesting to compare it to the current SuperMemo algorithm (SM-18) and not „only“ the older SM-17. It would also be interesting to see how SM-18 compares to SM-17 ;) reply epiccoleman 16 hours agoprevAh, this is really cool - i've been thinking about implementing a SR algorithm for one of my music related side projects. reply jacquesm 14 hours agoparentCool, let me know what you cook up if you want, I'm very much interested in that particular crossing of roads. reply orangepurple 17 hours agoprev [–] These algorithms are still suboptimal because they do not account for the spacing effect at all. But doing something is still better than nothing when it comes to learning. reply jarrett-ye 2 hours agoparentFSRS has considered the spacing effect in its model: https://github.com/open-spaced-repetition/fsrs4anki/wiki/The... reply tester457 9 hours agoparentprev [–] How does spaced repetition not account for the spacing effect? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "FSRS is a modern spaced repetition algorithm that enhances memory retention and review scheduling compared to Anki's default algorithm.",
      "It calculates optimal review intervals based on the likelihood of successfully recalling a card, using the \"Three Component Model of Memory\" and analyzing a user's review history.",
      "FSRS allows users to select their preferred retention level, requires fewer reviews than Anki's default algorithm, and works effectively with delayed reviews. It also offers additional features through the FSRS4Anki Helper add-on."
    ],
    "commentSummary": [
      "Participants engage in a discussion about using spaced repetition algorithms, particularly with the Anki app, for learning diverse subjects like language and music.",
      "Strategies, experiences, and opinions are shared regarding the creation of effective flashcards and improving retention.",
      "The effectiveness of different algorithms, such as FSRS and Supermemo, is explored, with some participants emphasizing context and varied exposure, while others focus on card formatting and simplification for optimal retention."
    ],
    "points": 330,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1705333203
  },
  {
    "id": 39003469,
    "title": "Building High-speed 11Gbps USB4 Network for Under $50",
    "originLink": "https://fangpenlin.com/posts/2024/01/14/high-speed-usb4-mesh-network/",
    "originBody": "As a software engineer, software is part of your job title; thus, it almost feels like you should only know software. However, in the decades of building software, I realized that gaining knowledge about hardware is equally important to learning code. Although I might never be as good as an expert in hardware, I want to expand myself beyond just software. So, I never shy away from getting my hands dirty with hardware. To reduce the cost of my AWS cloud service, I recently decided to move some less mission-critical services into my bare-metal servers. Therefore, I got to learn how to build a bare-metal Kubernetes cluster and set up the network for it. After some research, trial, and error, I finally built and ran a relatively low-cost cluster with a high-speed full-mesh interconnected network. The most interesting part is that the networking is based on a USB4 ethernet bridge instead of a conventional ethernet switch and cables. I tested the network speed, and it can hit 11Gbps. The cost of making the network is only $47.98 USD! Today, I would like to share my experience of building it. The UM790 Pro bare-metal cluster with full-mesh USB4 cables connections Standard 1U servers vs mini PCs When I thought of building a bare-metal cluster, I first asked myself what type of machine to use. The first idea that came to my mind was to purchase some retired used 1U servers. They are unbelievably cheap. Take this refurbished Dell PowerEdge R630 selling on Amazon, for example, and it costs only $380.42 refurbished Dell PowerEdge R630 selling on Amazon The CPU is a bit outdated, but it has two of them, and it comes with 192GB DDR4 RAM, so it’s still a fairly powerful machine. While the machine itself isn’t expensive, it is not cheap if you consider the cost to operate. A machine like this is very power-hungry. Suppose the power consumption is 1000W per hour. Given California’s average residential electricity rate is 15.34 cents per kWh, it would be UPDATE: Thanks to people pointed out on HN, more up-to-date electricty rate in CA is 26.72 cents per kWh. And the Dell PowerEdge R630 power consumption is actually running at 150W when idle and 300W under load based on this HN comment. Obviously I had no clue what I was talking about, haha 😅 1000W * 24 hour * 30 days = 720 kWh. UPDATE: actually more likely under load consumption would be 300W * 24 hour * 30 days = 216 kWh. In other words, the costs of running just one of these machines could be 720 kWh * 15.34¢/kWh = $110.45 USD per month UPDATE: with that, the actual cost estimation would be 216 kWh * 26.72¢/kWh = $57.72 USD per month And per year would be $692.64 And that would be $1,325.4 USD per year. You can buy more than three of these servers with just the money you pay for the electric bill. Not to mention they will make huge noise and it’s not ideal to keep them in your living area. There are also cooling issues you may need to consider; there will be an extra cost if you need an active cooling solution if you are stacking them up and the generated heat needs to go somewhere. Considering these, I ruled out buying one of those 1U servers pretty soon. The pace of modern hardware improvement is insanely fast. I’ve been paying attention to the trend of how powerful tiny devices can run on extremely low power nowadays. Apple was leading the way by introducing their M1 chip, bringing mighty computing power with super low power consumption. Thanks to the competition, Mini PCs are becoming more and more powerful these days. They are also fairly cheap, quiet, and consume little power compared to a full-size PC or a server. I looked at different mini PCs and found this one, Venus UM790 Pro from Miniforums: UM790 Pro product page screenshot The machine itself isn’t expensive. A top spec with 64GB memory and 1T storage only set you back $800 USD. It comes with an AMD Ryzen 9 7940HS CPU. It equips a CPU built for a laptop, so the power consumption is also pretty low. According to this YouTube video reviewing that machine, its idle power is only around 6W, and when running full load, it only consumes 80W. I ran a benchmark on this machine, and it blew my mind 🤯 Geekbench score compare between UM790 Pro and a PC with AMD Ryzen 9 3950x CPU This tiny machine’s benchmark score is even better than the top-spec PC I built three years ago with an AMD Ryzen 9 3950x at a fraction of the price and power consumption. If the numbers are correct, this machine only costs $9 USD monthly at full load! UPDATE: estimated cost would be $15.39 per mon based on latest avg rate Networking It didn’t take too much longer for me after I purchased the first UM790 Pro and tried it out to decide to extend it to a three-node cluster. But soon after bootstrapping the Kubernetes cluster on these three tiny beasts and installing Ceph as the storage system, I realized I needed a better interconnection between these machines. When Ceph moves big files between the nodes, it takes a long time with just 1G ethernet. The UM790 Pro machine has a 2.5G ethernet port, but my router’s LAN ports are only 1G speed, so I was considering buying a 2.5G ethernet switch. It’s not the end of the world to run a cluster at 1G speed, but limited bandwidth between nodes limits what you can do with the cluster, so ideally, I still want a higher-speed network between the nodes. Interestingly, it appears that nowadays, you can get a 2.5G ethernet switch at a reasonably cheap price, something like $100. But those ones are usually from China, with different brand names sharing the same underlying machine, like the ones reviewed in this video. Why there are so many brand names for the same machine? I guess it’s a strategy the manufacturer adopts to have many brands for the same product so that they have more entries appear in the search results on Amazon. Therefore, you get more exposure and, thus, a better chance of a conversion. In the long run, I am speculative about the quality of those cheap 2.5G ethernet switches and the service they will provide. The products were sold under a seemingly throwable brand name, after all. Usually, I would prefer a more established brand if I had to buy one. While I was debating which switch to buy, doing my research regarding the brand, price, and my requirements, I realized wait a minute 🤔 There are two USB4 ports on the machine. In theory, it could provide up to 40Gbps speed. Who cares about 2.5G? That’s 40Gbps we are talking about here! Considering the money spent on a 2.5G ethernet router plus some Cat6 ethernet cable, why not just make a full-mesh network with USB4 cables? With that in mind, I soon purchased two of these and this one USB4 cable. That’s only $47.98 USD in total, and yet it can hit 11Gbps! It would be way more expensive and slower if I went the ethernet route. Configure the mesh network with NixOS and Systemd As you’ve seen in the first picture in this article, the three nodes were fully connected with high-speed USB4 cables. Connecting cables is easy, but the question is, how do you configure the network in Linux? In the process of bootstrapping my Kubernetes cluster, I learned how to use NixOS to configure a reproducible Linux OS environment. It saved me a tremendous amount of trouble for configuring my nodes. NixOS is a package system that comes with a build system. It allows you to build reproducible packages all the way from Linux kernel to all the tiny utility command line tools. So, if you encounter any issues in the package, you can patch them quickly without waiting for the bug to be fixed in the upstream. NixOS and the whole Nix ecosystem deserve their own articles. I may write a “NixOS Explained” like my previous Elliptic Curve Cryptography Explained article. I found the package system beautifully designed but hard to understand at first glance. Hopefully, I can find the time 😅 Anyway, here’s the sample NixOS configuration I wrote for configuring the USB4 full-mesh network: {...}: { systemd.network.enable = true; # To 02 systemd.network.links.\"50-tbt-02\" = { matchConfig = { Path = \"pci-0000:c7:00.5\"; Driver = \"thunderbolt-net\"; }; linkConfig = { MACAddressPolicy = \"none\"; Name = \"tbt-02\"; }; }; systemd.network.networks.tbt-02 = { matchConfig = { Path = \"pci-0000:c7:00.5\"; Driver = \"thunderbolt-net\"; }; addresses = [ { addressConfig = { Address = \"10.7.0.101/32\"; Peer = \"10.7.0.106/32\"; }; } ]; }; # To 01 systemd.network.links.\"50-tbt-01\" = { matchConfig = { Path = \"pci-0000:c7:00.6\"; Driver = \"thunderbolt-net\"; }; linkConfig = { MACAddressPolicy = \"none\"; Name = \"tbt-01\"; }; }; systemd.network.networks.tbt-01 = { matchConfig = { Path = \"pci-0000:c7:00.6\"; Driver = \"thunderbolt-net\"; }; addresses = [ { addressConfig = { Address = \"10.7.0.102/32\"; Peer = \"10.7.0.103/32\"; }; } ]; }; } Basically, I use systemd-udevd to configure the Thunderbolt bridge network device and then have another system-network configuration to set an IP and peer IP on the interface. Benchmark result Enough of talking. Let’s see some benchmark results with iperf3: iperf3 benchmark result shows 11Gbps network speed As you can see, the network speed reaches 11Gbps! Afterthoughts It’s fantastic that I can build a network running at 11Gbps at such a low cost. But still, I don’t understand why it can only hit 11Gbps at this moment. I saw other people building similar networks were able to hit 20Gbps. As far as I know, USB4 is almost an open-source version of Thunderbolt 3. And it doesn’t guarantee the speed to be 40Gbps even if the manufacturer claims it’s USB4. So it could simply be that the machine only supports up to this speed. I also heard other people say that because Intel sells high-speed network controllers, and if USB4 or Thunderbolt 4-based networks can achieve the same level of speed, it might compete with their network controllers, so they capped the speed. If you know why I can only hit 11Gbps instead of 20Gbps or even 40Gbps, please let me know 🙏 Another interesting uncharted area of the idea of a high-speed USB-based network would be how many nodes we can connect and how. With two ports on each machine, I can make a full-mesh network, but what if there are more than three nodes? I recall reading some networking books that mentioned interesting ancient network structures a long time ago, such as ring topology networks or daisy chain networks. There are many drawbacks to those network structures, and network equipment is pretty cheap, so those are rare nowadays. With a limited number of USB4/Thunderbolt ports and relatively expensive cable, maybe it makes sense to construct a network like the ancient ones. What if we can make a high-speed switch built with many USB4 ports and controllers? How much will it cost compared to the ethernet equivalents? In the near future, when high-speed USB/Thunderbolt controllers and cables become standard and widely available on modern computers, we can see more close-range high-speed networking applications at a very low cost. I may spend some time exploring the idea of building a USB/Thunderbolt-based high-speed network. In the meantime, I would like to know if you have ever built anything cool with these technologies. Please feel free to leave a comment below!",
    "commentLink": "https://news.ycombinator.com/item?id=39003469",
    "commentBody": "High-speed 10Gbps full-mesh network based on USB4 for just $47.98 (fangpenlin.com)327 points by fangpenlin 16 hours agohidepastfavorite209 comments gaudat 15 hours agoUSB4/thunderbolt is a magical protocol. Turns out the fastest way to move data between 2 modern PCs is to connect their thunderbolt ports with a USB-C cable. The connection shows up as a ethernet port on Windows and I can easily saturate a SSD with its 1GB/s+ transfer rate. And it just works (tm). Reminds me of firewire on these 20 yo Macs. And What happen if you wire both ports together on the same PC?.. Do you get a broadcast (thunder) storm? reply jwells89 15 hours agoparentTarget disk mode over FireWire was magical back in the day. Nothing like turning someone’s laptop into an oversized external hard drive to rescue data or get a borked OS X installation booting again. reply xattt 14 hours agorootparentFireWire had IP networking stacks in Windows and OS X in 2007. You could daisy chain a bunch of devices together to share a network connection. reply FirmwareBurner 11 hours agorootparentSure but it was very expensive compared to USB and Ethernet so Firewire never caught on with mainstream conumers other than some niche cases like camcorders. Thunderbolt was also expensive, which is why adoption was limited, but it's becoming more maisntream since Intel and Apple have been pushing it in the last years, adn piggibacking over USB-C makes it an easy sell comapred to requireing a separate connector like firewire. Still, thunderbolt peripherals are way more expensive than USB ones, so like Firewire before, use is still more in the enthusianst/professional space. reply GeekyBear 11 hours agorootparent> it was very expensive compared to USB and Ethernet so Firewire never caught on Compared to Gigabit Ethernet back in that time period? Firewire was a huge bargain. reply FirmwareBurner 11 hours agorootparentNo, not gabit, but 100 Ethernet was more than enough for what average consumers had to transfer back then, and it was significantly cheaper and more available than firewire. It was more likely your HDD to be a bottleneck for faster network transfers. reply GeekyBear 10 hours agorootparentEven the first version of Firewire was four times as fast as that. Completely loading a 5 Gig iPod with music over that first version of Firewire still took a few minutes. reply FirmwareBurner 10 hours agorootparent>Even the first version of Firewire was four times as fast as that. Yes and? At what price points? What was the adoption rate? How many mainstream PCs and peripherals worldwide had it? Wherever you went, whoever you met, you were way more likely to find a USB or ethernet port to hook up for a fast transfer rather than Firewire. At least in my country at the time, maybe you lived in Cupertino/Palo Alto where evryone had iMacs and firewire. Just like VHS over Betamax, USB won because it was cheaper and more convenient despite technically inferior to firewire and consumer tewch at the time was a race to the bottom in terms of price. >Completely loading a 5 Gig iPod with music over that first version of Firewire still took a few minutes. Only the first gen iPod had firewire before switching to USB, and even then, what was the point of Firewire 400 on it when the tiny and slow mechanical HDD on it was the real bottleneck. There was no way the iPod would have been remotely as successful had it stayed on firewire. Apple didn't have the market sahre back then to enforce their own less popular standard. Only when it switched to USB and supporting PCs did the iPod really take off. reply GeekyBear 10 hours agorootparent> Yes and? At the time, USB was still limited to 12 megabits per second and transferring that same 5 Gigs of MP3 files would have taken over an hour. The firewire iPod did it in a couple of minutes. USB was cheaper, but dog slow. Gigabit Ethernet was faster but WAY more expensive. reply FirmwareBurner 10 hours agorootparentI see you keep ignoring my arguments so this is the last time I say it. Again, only the first gen iPod was firewire exclusive and it was not yet a maisntream product since it was still Mac only, so avergae consumer demand at home computers for Firewire was lackluster and the iPod didn't change that. Firewire was niche or non existent in the home PC space and it died completley with the launch of USB 2.0 remaining alive only in the pro-sumer space. >Gigabit Ethernet was faster but WAY more expensive. Please show me where I mentioned Gigabit ethernet as an argument. I said 100 Ethernet which was dirt cheap and almost every PC and Mac had it, as opposed to Firewire, so if you needed a fast cross platform transfer it was your best bet at the time in terms of cost and mass availability over firewire before USB 2.0 and gigabit hit the market. reply GeekyBear 10 hours agorootparentYour claim was that Firewire \"was very expensive compared to USB and Ethernet\". Which completely ignores the speed and the costs of the various data transfer standards as they existed at the time. The cheap 1.2 megabit USB standard that existed at the time couldn't transfer 5 Gigs of MP3 files in less than an hour. The cheaper 10 megabit version of Ethernet they sold at the time also would need more than a hour to transfer enough MP3 files to fill an iPod and wouldn't have been cheaper than a Firewire port. Ethernet with faster speeds than 400 megabit Firewire existed, but was MUCH more expensive. Speed AND cost both matter. > I said 100 Ethernet which was dirt cheap Back then? It wasn't. reply jwells89 10 hours agorootparentprevLater gens of iPod gained the ability to connect to USB but still supported FireWire. The majority of my usage of my 20GB 4th gen iPod was with the FireWire cable it shipped with. reply xattt 9 hours agorootparentIt’s forgotten to history that Apple supported FW on the 30-pin connector. reply Fnoord 11 hours agorootparentprevWay before that there was SCSI. The low cost is price. Asus for example with their ASUS ThunderboltEX 4 allows you to have TB4 via PCIe card. The neat thing about USB4 was same as PATA and later SATA: widely and relatively cheap available in consumer hardware. SCSI and FireWire were technically superior but were neither cheap nor widely available. Oh and I don't know about SCSI but FireWire was actually a security risk. reply vegardx 2 hours agorootparentJust a fair warning about these cards, the support is flakey at best. You should research if it works with your motherboard and CPU before going down that route. I did a lot of research on this because I wanted to connect my Gaming-PC to an Apple Studio Display over optical Thunderbolt, but quickly decided against it. Luckily there are good alternatives. I landed on a solution using a Belkin[0] DisplayPort and USB to Thunderbolt-cable. I just get USB2.0 speeds, but it's enough for my needs. I'm also able to extend it using an active DisplayPort 1.4 extender, for a total of 10 meters cable. [0] https://www.belkin.com/support-article/?articleNum=316883 reply tga_d 7 hours agorootparentprevI know thunderbolt at least up through 3 was generally carte blanche DMA, so an obvious security nightmare (strictly speaking no worse than cold boot attacks and the like, but there's a practicality difference between dumping raw DIMMs and just plugging in a thumb drive -- or inter-machine links like TFA, for that matter). Does TB4 bother trying to solve this? reply bimguy 9 hours agorootparentprevTarget disk mode to my workstation and saving someone's whole system with Disk Warrior used to be my favourite and most rewarding task. APFS did away with that joy, if a Mac OS systems fails now you have almost no chance of saving the system from itself. reply RachelF 12 hours agorootparentprevYeah, we built a similar system a generation ago using FireWire on x86 and Linux. FireWire at 800Mbps beat Gigabit Ethernet in terms of latency for a rather hard real-time system. reply rabi_molar 12 hours agorootparentI remember the \"good ol days\" when I would always opt for a FireWire audio interface for music production and live performance over USB for exactly this reason. I'd get way better latency and stability. reply jwells89 11 hours agorootparentEven now an ancient FW400 HDD enclosure of mine is less flaky than a lot of USB storage I’ve used. reply justnotworthit 12 hours agorootparentprevAny ideas what im I supposed to do with the firewire mixer i bought 14 years ago? reply robes 9 hours agorootparentYou can still use it! I keep an old ThinkPad X61 & T400 around with mini-Firewire ports on my MOTU 828 mkII interface. It is also a DAC over SPDIF for my much newer Ryzen desktop. I would like to try Thunderbolt to FW800 to FW400 adapters to see if I can get it working on something more modern, as I learned it has mainline Linux kernel support. reply wmf 11 hours agorootparentprevGet a Thunderbolt 3 to Thunderbolt 2 dongle and a Thunderbolt 2 to Firewire dongle? reply SloopJon 12 hours agoparentprevI've been playing with Thunderbolt networking over the past week with mixed results. I can get 16Gbps between a couple of Macs. Between a Mac and a PC running Windows 10 I get similar speeds in one direction, but less than 1Gbps in the other direction. In terms of scaling this to multiple hosts as the author does, I've read that it is possible to daisy chain, or even use a hub, but it doesn't strike me as the most reliable way to build a network. For an ad hoc connection, though (like null modem cables of yore), it's a great option. reply belthesar 8 hours agorootparentI think reliability is a great metric to evaluate this on. I don't have a lot of experience with USB4/Thunderbolt networking, but as far as ring network principals go, when you have a network with only 3 nodes, a ring topology is also a fully connected topology. This means that connectivity between nodes should never fail due to the failure of a node. That screams reliable to me. As far as points of failure, there's no additional hub/switch in between the devices, so you have a Thunderbolt controller on each device, two cables, and two ports. If a cable goes bad, so long as there isn't a silent/awkward failure mode, all three nodes can still talk to eachother, at degraded speed. If a switch goes bad, the whole network is down, unless you start talking about redundant switch topologies. To your point though, there does seem to be plenty of shenanigans with performance, especially between devices with different Thunderbolt controllers, that may make this less ideal. But IMO, that's more of a question of do you want to with a more battle tested topology, or are you okay with a less battle tested, but still highly performant and \"simple\" (we won't go into how bonkers the USB/Thunderbolt spec is) topology? reply vardump 14 hours agoparentprevYou need more like 50 Gbps to saturate a modern Nvme SSD. 10 Gbps doesn't come close. reply genman 14 hours agorootparentThere was a moment with the spinning rust drives where it would have made sense to have storage in a networked device and not locally but now it rarely makes sense unless an incredibly fast interconnect could be used. Of course this example is still interesting and cool. reply arglebargle123 13 hours agorootparentFor a couple of years I had a Linux NAS box under my desk with like 8 Samsung 850 pros in a big array connected to my desktop over 40GbE. Then NVMe became a common thing and the complexity wasn't worthwhile. reply NavinF 13 hours agorootparentprevInfiniband can match NVMe bandwidth and its latency is similar. Newer network cards can also present a NVMe-oF drive as a local NVMe drive reply mgerdts 12 hours agorootparent25 Gb Ethernet roughly matches a PCIe Gen 3 NMVe drive’s max throughput 50 Gb will match Gen 4. These are RDMA capable. It seems 25Gb dual port Mellanox CX-4 cards can be found on eBay for about $50. The cables will be a bit pricey. If not doing back to back, the switch will probably be very pricey. reply justinclift 7 hours agorootparentThere are 100Gb/s Intel Onmi Path switches currently on ebay for cheap: https://www.ebay.com/itm/273064154224 And yep, they do apparently work ok if you're running Linux. :) https://www.youtube.com/watch?v=dOIXtsjJMYE Haven't seen info about how much noise they generate though, so not sure if suitable homelab material. :/ reply mgerdts 7 hours agorootparentI saw that, but didn’t consider it particularly cheap. Also, the power draw of this things is also likely a concern if run continuously. reply justinclift 5 hours agorootparentYeah, power draw could be a problem. :( Cheap though... it's a small fraction of the price for a new one. Are there better options around? Looking at Ebay just now, I'm seeing some Mellanox IB switches around the same price point. Those things are probably super noisy though, and IB means more mucking around (needing an ethernet gateway for my use case). reply genman 12 hours agorootparentprevIt can match a single drive. reply mgerdts 6 hours agorootparentAssuming jumbo packets are used with RoCE, every 4096 bytes of data will have 70 bytes of protocol overhead [1]. This means that a 25 Gb/s Ethernet link can deliver no more than 3.07 GB/s of throughput. Each lane of PCIe Gen 3 can deliver 985 MB/s [2], meaning the typical drive that uses 4 lanes would max out at 3.9 GB/s. Surely there is some PCIe/NVMe overhead, but 3.5 GB/s is achievable if the drive is fast enough. There are many examples of Gen 4 drives that deliver over 7 GB/s. Supposing NVMe-oF is used, the MVMe protocol overhead over Ethernet and PCIe will be similar. 1. https://enterprise-support.nvidia.com/s/article/roce-v2-cons... 2. https://en.wikipedia.org/wiki/PCI_Express reply genman 12 hours agorootparentprevYes, that was my point - 10Gbps is just way too slow, even full Thunderbolt bandwidth can be easily saturated in raid configuration - NVMe are just incredibly fast. reply nine_k 12 hours agorootparentprev10 Gbps does not, but 10 GBps, as written above, is 80 Gbps, matches your estimate. reply vardump 12 hours agorootparentI've tried the same method and it's about 10 Gbps, not 10 GBps. reply ThePowerOfFuet 11 hours agorootparentSounds like you were actually using USB 3.1 Gen 2 or USB 3.2 Gen 2[x1], not Thunderbolt 4. reply vardump 10 hours agorootparentI tried it with M2 Max Macbooks. Definitely TB4/USB4 capable. reply walterbell 9 hours agorootparentWith a certified TB4 cable? reply vardump 5 hours agorootparentYes. reply bhaney 11 hours agorootparentprevThunderbolt 4 can't do 80Gbps either reply justinclift 7 hours agoparentprev> Turns out the fastest way to move data between 2 modern PCs ... With the caveat being that's only if you're not up for adding PCIe cards. If you are ok with adding some PCIe cards, then you can transfer things a lot faster than 1GB/s. :) reply kwanbix 6 hours agorootparentCare to elaborate? reply justinclift 6 hours agorootparentNetwork cards that go a lot faster than 10GbE are common. They're widely used (with many different types) in IT data centres, home labs, and probably other places too. Heaps of them are on Ebay. As a random search just now for \"Mellanox 25GbE\" on US Ebay: * https://www.ebay.com/itm/134435757546 * https://www.ebay.com/itm/355348422765 (there are hundreds of individual results) Searching for \"Mellanox 50GbE\": * https://www.ebay.com/itm/225021493021 * https://www.ebay.com/itm/233915360659 (less results) There are older generation ones too, doing 40GbE: * https://www.ebay.com/itm/305046322527 * https://www.ebay.com/itm/166350081025 (hundreds of results again) With those older generation cards, some care is needed depending upon the OS being run. If you're using Linux you should be fine. If you're running some other OS though (eg ESXi) then they might have dropped out of the \"supported list\" for the OS and not have their drivers included. reply oso2k 4 hours agorootparentI bought a bunch cheap HP 40Gbps NICs [0] when they were $13 but need PCI-E risers to make them fit a full height slot. Work fine in pfSense & Fedora. [0] https://www.ebay.com/itm/333682185870 reply hatefulmoron 6 hours agorootparentprevI assume they're referring to getting a couple of NICs reply ComputerGuru 14 hours agoparentprev> The connection shows up as a ethernet port on Windows Do you know if this is the case for all thunderbolt generations (speed differences aside)? Does it apply to thunderbolt using mini DisplayPort too or only over USB PHY? reply chx 13 hours agorootparentIt was possible on Thunderbolt 2 , on the Mac side OS X Mavericks enabled it, this Intel whitepaper from 2014 talks about the Windows side. https://www.thunderbolttechnology.net/sites/default/files/Th... https://www.gigabyte.com/Press/News/1140 this doesn't mention it and the Intel whitepaper specifically requires TB2 so I would guess TB2 was it. reply raffraffraff 11 hours agorootparentPity Thunderbolt 2 is basically non-existent nowadays. I have a few Macbook Pro 13 (2015) and I'd love to be able to use the thunderbolt 2 ports, but peripherals were too expensive and the standard short-lived. Try finding a thunderbolt 2 dock anywhere. Filter out all the false-positives (USB-C docks) and the are maybe 10 total on ebay, and they're stupidly expensive for 6+ year old used devices, most without cables or power supplies. Such a pity because they can really extend the useful life of those laptops. reply russelg 10 hours agorootparentTB3 is backwards compatible so you can use the Apple TB2 to 3 adapter in conjunction with a TB2 cable to hook up any TB3 device to your MBP 2015. I had the mid-2015 15\" MBP and used the adapter to hook up an external GPU. If that can work I'm sure a TB3 dock will. reply ComputerGuru 9 hours agorootparentIt’s the beauty and elegance of the PCIe design. Thunderbolt just provides convenient ported access to those lanes. reply davkan 12 hours agorootparentprevMy TB3 mesh network shows interfaces as thunderbolt0 etc. this is on Linux using thunderbolt _net from the kernel. Latency is worse than regular twisted pair Ethernet. reply bobim 12 hours agorootparentDang, that wouldn’t play nice for MPI then. reply davkan 12 hours agorootparentI was seeing 1-1.5ms latency using linux bridges for the mesh. Not a huge issue for ceph replication but significantly more than switched lan. It may be possible to get it lower with routed instead of bridged but my understanding is thunderbolt_net on Linux is not perfect in that regard. reply vineyardmike 14 hours agorootparentprevI think it works for older thunderbolt too. Been years since I tested it though. reply phyzome 11 hours agoparentprev> The connection shows up as a ethernet port OK but what then? I've had ethernet ports on my computers since I can remember, and that hasn't magically allowed me to transfer data back and forth just by plugging a patch cable into both machines. What software is at work here? reply SloopJon 10 hours agorootparentDepending on what you want to do on what O/S, batteries may or may not be included. I use Moonlight on a Mac to control a Windows 10 PC running Sunshine--lower latency than Remote Desktop (which I don't have anyway in the Home edition), and nicer looking than Parsec. When you connect a patch cable directly (no crossover cable needed in the 21st century), you'll likely find that each system has a self-assigned IP in the 169.254 network. reply bpye 11 hours agorootparentprevI’m guessing if they’re using Windows it’s boring old SMB? reply znpy 14 hours agoparentprev> And What happen if you wire both ports together on the same PC? A literal loopback interface? Two of them, most likely. reply samstave 13 hours agoparentprevWTF! I have two identical machines that I need to do this with... lemme test it and see. ... ARGs usb-3... so nopes. (How FN lame is that) reply drewzero1 8 hours agorootparentIndeed... I just got my first computer with a USB-C port and have been puzzling over what to do with it. Most of the cool tricks seem to require Thunderbolt, which it is not. reply nabilt 11 hours agoprevThis is a pretty cool solution. I didn't know the capabilities of USB4 before this. The comparison with the Dell r630 power numbers got me interested since I just purchased a Dell r430 to host my site so I decided to benchmark mine. Specs: * 2x Xeon E5-2680 v3 (same CPU) * 64GB RAM * 2x power supply (can't remember if it's 500W or 750W each and too lazy to look) * 1 SSD & 1 7300 RPM HDD * Ubuntu server 22.04.3 LTS Using a Kill-A-Watt meter I measure ~100 watts after boot. Running sysbench (sysbench --test=cpu --threads=12 --cpu-max-prime=100000 --time=300 run) I get up to ~220 watts. If my calculations are correct that's 72 kW per day or $11.05 per month at idle: 0.1 kW * 24 hours * 30 days = 72 kWh 72 kWh * 15.34 cents/kWh = $11.05 and 158.4 kW or $24.3 per month during load: 0.22 kW * 24 hours * 30 days = 158.4 kWh 158.4 kWh * 15.34 cents/kWh = $24.3 I'm not sure of OP's use case, but these numbers are probably more realistic than using the max wattage of the power supply for most people. I will still be hosting in a co-location for the reliable internet and so I can sleep without the sound of a jet engine taking off. Those fans are loud! reply justsomehnguy 10 hours agoparent> I'm not sure of OP's use case Lack of understanding. Even comparing 65W to 1000W should had ring some bells, but. > but these numbers are probably more realistic Almost, depends on the load (hardware) and load (software), as someone who manages a fleet of 720/730/630, a standby server eats around 150W and under the load up to 300-350W, depending on the package. > Using a Kill-A-Watt meter You can use built-in measuring in iDRAC. reply evanreichard 8 hours agorootparentAnother data point - I'm running about 500w for my small rack. NAS (20 x 3.5HDD), ICX6610 (3 PoE APs), 2 x R630, and some small devices. According to iDRAC, my R630's are drawing almost exactly 100w/each. Each with about 75 pods (k8s nodes). reply oso2k 4 hours agorootparentMy R730 with 14x 2TB NVMe, 8x 6TB SAS HDDs, 2x E5-2680 v4 eats 250W. reply justinclift 7 hours agorootparentprev> You can use built-in measuring in iDRAC. Does anyone know if ~modern HP iLO can show power usage too? Looking through my Gen8 HP Microservers just now, I'm not seeing power usage info. :( \"Power Information\" is just showing the state of the power supplies (aka \"OK\", \"Good, In Use\") and not much else. reply justsomehnguy 5 hours agorootparentSince iLO3 (~2010) and even more simple one (as in momentary) even at iLO2. It's just your MicroServers are gutted so they wouldn't compete with enterprise gear and ML line (probably). Try: SNMP IPMI HPE Agents (Linux, Windows) REST/RIBCLI interface for iLO (https://support.hpe.com/connect/s/softwaredetails?language=e...) It certanly has some reading on the power but it's just don't display it in the interface. At least https://www.storagereview.com/review/hp-proliant-microserver... says it has Power Meter menu entry? Also check if you really running the updated firmware for the iLO. reply nabilt 9 hours agorootparentprevThanks, good to know. I may need to request a 3A 1U in that case. I didn't know iDRAC could measure real time power usage. Pretty amazing. reply buffington 8 hours agorootparentI inherited a few R420's from my work, and the coolest thing about it is the iDRAC. I'm not a SRE or anything of the sort, so don't get to see stuff like that much, but the utility of the iDRAC is fantastic. The machines each have 192GB of ram, so I thought I'd set them up as LLM inference machines. I figured that with that much ram, I could load just about any model. Then I discovered how slow the CPUs on these older machines is. It was so utterly slow. I have a machine I bought from Costco a few years ago that was under $1k and came with a RTX 3060 with 12GB of GPU ram. That machine can run around 20+/tokens per second on 13B models (I actually don't know - I stream the text, and cap it at 9 tokens per second so I can actually read it). The R420? Its tokens per second were in the 0.005 to 0.01 range. So, yeah, not a good CPU for that sort of task. For other stuff, sure. I thought I'd setup a small file server with one instead, but the fans are so jet engine loud that it's intolerable to have in any part of the house, even when managing fan speeds with software. reply oso2k 4 hours agorootparentCPUs are slow in comparison to GPUs for lots of tasks. Comparing a 10 year old CPU vs. a 4 year old GPU only make that comparison \"more offensive.\" That said, you pair your R420 with something like a RTX A2000 and you'll have a much fairer fight. reply Yukonv 14 hours agoprevRelated, Intel was showing off Thunderbolt Share at CES[1]. Allows Thunderbolt 4/5 device-to-device transfer of files. Theoretical speeds in the 20Gbps and 40Gbps for Thunderbolt four and five respective. One idea for why they were only able to reach 11Gbps is having only one Thunderbolt/USB4 controller[2], meaning the two USB4 ports split the 40Gbps PCIe lane. Throw in a full-duplex connection and you get 10Gbps in one direction. [1] https://youtu.be/GqCwLjhb4YY?t=81 [2] Just a theory but seems like a sane assumption. reply arghwhat 12 hours agoprevNit: This is not a mesh. With only 3 nodes, it's not even a ring but just a direct connection between servers. A \"real\" ring is formed when you have more than 3 nodes and so some destinations require more than one hop. A mesh implies a network formed by somewhat arbitrary point-to-point connections with multiple possible routes between two points. reply toast0 11 hours agoparentFull-mesh typically means each node connects directly to each other node (for some value of directly), so IMHO, a three node system with each node connected to the other two fits the name. I do agree that it's not very interesting with only three nodes. reply tssva 11 hours agoparentprevThis may not be a ring, but a “real” ring doesn’t require more than 3 nodes. A ring can be formed with as little as 2 nodes. If routing was enabled this would definitely be a mesh network. It would be a full mesh network where every node is directly connected to each other and a secondary path through another node is available should the direct path fail. reply Fb24k 15 hours agoprevI still remember connecting two MS-DOS computers together with a parallel cable, that was the easiest way to do \"large\" file transfers there for a while (used a program called LapLink, iirc)... reply myself248 13 hours agoparentYou could also run PLIP over the same cable. It's like SLIP (which is like PPP) but much faster. Where Laplink isn't really a network, just a file transfer thing that requires Laplink to be running on both PCs, PLIP is a network driver that lets you do all the usual network things over the connection. And since PCs can have up to 3 parallel ports before things start getting stupid, it's pretty straightforward to have a row of machines with PLIP links going both ways, bridging or routing the interfaces. Or, do PLIP-SLIP-PLIP-SLIP without adding any ports, and you could have a functional-but-brittle-and-slow network for pennies. reply TacticalCoder 12 hours agorootparent> You could also run PLIP over the same cable. I was running that in the nineties. My main desktop, running Linux, and an ultra old, ultra crappy laptop running Linux too. They'd be connected using PLIP and the desktop, more powerful, was running its own X server but also applications for that were running on the laptop's X server. So my brother and I could both be using Netscape to surf the net (we'd call it that back then) at the same time, over the 33.6 modem connection. It was really easy to run PLIP and was saving me the trouble to try to get network card running under Linux on my desktop and most importantly saving me the trouble to try to get the PCMCIA crap to work on my laptop. Fun times... P.S: and, yup, back then laptops had a full parallel port! reply myself248 8 hours agorootparentThe Xircom PE3 was my other favorite way to get a laptop online, also through its full parallel port. Once around 2005-ish, I scored an 802.11b client-bridge real cheap because .11g stuff had been out a while. Velcroed it to the lid of my Zenith Supersport, and made a ten-inch ethernet cable to connect it to the PE3. An unholy abomination allowed both units to tap power from the keyboard port; the less said about that, the better. What felt like thirty hours of hair-pulling later, I had a 720k DOS boot disk with packet drivers and a telnet client, and I could MUD from my lap, wirelessly. Ahh, the sweet smell of useless success. Then like an idiot, I sent all that stuff to the recycler around 2008. reply rubatuga 11 hours agorootparentprevUsing slip over minimodem over FM receiver/transceiver was quite an interesting experiment. With the low power exemptions, you can design your own radio networking protocol without FCC approval. They may require the FM radio signals to be music/audio, in that case, have you heard of noisecore? reply TacticalCoder 7 hours agorootparent> They may require the FM radio signals to be music/audio, in that case, have you heard of noisecore? Nope but I would loved that back in the days: we created a LAN between our house and the (attached) neighbors' house (so we could play Warcraft II against each other) but... We couldn't create a LAN with the neighbor across the street! reply LargoLasskhyfv 6 hours agorootparentprevI did this with a https://en.wikipedia.org/wiki/Breakout_box#/media/File:KL_Br... in between. With ECP-DMA, or some such. Red-green blinking lightshow at about 4Mb/s! :-) Edit: Yes, I'm aware that box says RS-232, but with gender-changers, the dip-switches and some cable-bridges, you could abuse it for 'parallel'. reply farkanoid 14 hours agoparentprevLaplink! That part ot my brain hasn't activated in decades... My favourite was bootstrapping using 'COPY /B COM1: C:LL3.EXE' to get the Laplink executable to the target machine over Serial, when you didn't have a spare floppy. reply myself248 14 hours agoprev> I recall reading some networking books that mentioned interesting ancient network structures a long time ago, such as ring topology networks or daisy chain networks. IP-over-SCSI was great, you could throw 8 PCs on one SCSI chain. Put two SCSI controllers in each machine, do rows-and-columns, and you could have 64 hosts a maximum of 2 hops from each other, at U320 speeds, in the 1990s. https://www.linuxjournal.com/article/2344 Imagine a beowulf cluster of hot grits! Er, sorry... reply mcoliver 14 hours agoprevRe speed, looks like the cables are the right ones. Would be nice to find a wiring diagram of the motherboard to see how the pcie lanes are allocated but hard to find on these consumer devices. Perhaps each usb4 port is a single lane gen2 which would top out around 10Gbps. You could try paralleling iperf3 to give you a bit more info. Also check the tx_speed and rx_speed in /sys/bus/thunderbolt/devices to see what it is negotiating. Company specific TB driver/firmware updates can be found here https://www.thunderbolttechnology.net/updates reply ralonso 3 hours agoparentI believe you might be right regarding the port itself being the issue here. I have a Minisforum UM775 (basically the previous gen of the 790 Pro mentioned in the OP) and despite having two \"USB4\" ports, only one is rated for 40Gbps while the second one is 10Gbps. I cannot find any specifics regarding the ports on this 790 Pro one, but I'm certain that's ultimately the issue: the bottleneck is on that second (the one on the right) USB4 port. reply rahimnathwani 15 hours agoprevaverage residential electricity rate is 15.34 cents per kWh This didn't seem right, as I pay more than double that here in San Francisco. (I calculated $0.35/kWh by dividing the total I paid for electricity generation and delivery, and dividing it by the number of kWh consumed.) The linked page cites data from over a decade ago (2012). reply belval 15 hours agoparent> This didn't seem right, as I pay more than double that here in San Francisco. Their data might be a bit outdated but the December 2023 average is $0.168/kwh according to [1]. [1] https://www.bls.gov/regions/midwest/data/averageenergyprices... reply rahimnathwani 14 hours agorootparentOP was talking about California, not the entire US. The page you linked shows four California cities, each with Dec 2023 rates over $0.27/kWh. reply JumpCrisscross 14 hours agorootparentWow. I guess I won't get mad at my guests for running the heat 24/7 at 5¢ per kWh. reply jtriangle 14 hours agoparentprevThat whole section is BS in general. The server linked isn't going to use 1KW of power ever, not on the worst of days. The only real point that they're making is that \"it's loud\" which is true, very true, but, it's designed to run in a rack away from humans.. While their solution is more livable for them, the hardware is vastly inferior for actually hosting serious services on, and they don't seem to understand that because they're software guys who're getting away with it. reply g8oz 13 hours agorootparentGiven the electricity rates he mentioned, what would you estimate the monthly running cost to be? reply tyrfing 13 hours agorootparentDepends on load. Somewhere around $20-40? Assuming idle around 80-120w, and another 100w for the e-waste drives in their pictured listing. reply alphabettsy 13 hours agorootparentprevHis numbers are probably 8x higher than actual. So maybe $8-15/mo for electricity for one of the old servers, not $100. reply szundi 12 hours agorootparentprevIt will eat much more than 80W though reply mlyle 15 hours agoparentprevhttps://www.globalenergyinstitute.org/2022-average-us-electr... Within the state, there's huge variation. The average is around 25 cents. E.g. if you live in Santa Clara, you pay 16.6 cents per kilowatt hour to Silicon Valley Power, while all surrounding cities pay 45 cents-ish. https://www.siliconvalleypower.com/residents/rates-and-fees reply krallja 15 hours agoparentprevMine is currently 9.4¢/kWh, no TOU, net metered. PG&E is the problem, not the data. reply throwaway-blaze 14 hours agorootparentWhere in CA roughly is this? reply delfinom 15 hours agorootparentprev32 cents / kWh here in NY. reply rahimnathwani 14 hours agorootparentprevI was responding to what OP said about California rates. reply krallja 9 hours agorootparentMy mistake, sorry. Still seems atrocious to me. It’s not like we have better power generation equipment here in NC. reply pstrateman 13 hours agoparentprevThe average rate is only ~15 cents per kWh because of places like SF that are effectively just scamming the consumers. Electricity in free markets is more like 5-8 cents per kWh. reply NavinF 13 hours agorootparentYep electricity prices in CA are set by the gov't. Market rates are typically 10 cents/kWH reply Cheer2171 8 hours agorootparentTechnically the CA government only sets a maximum price, not prices themselves. Power companies can sell at market rate if they want. But that same CA government also allows monopolies, so the price ceiling becomes the floor. reply neilalexander 10 hours agoprev> But still, I don’t understand why it can only hit 11Gbps at this moment The interface/bridge MTUs might want increasing to a larger value. I notice a pretty big difference when connecting Macs together using Thunderbolt with an MTU of 9000 vs 1500. reply PeterStuer 2 hours agoprevSide note about the author's distrust about cheap switches 'from China': i have installed many switches from different brands over the years, and the most reliable by a large margin where from TP-Link, easily beating the likes of HP, Netgear, Linksys and Cisco. reply stoltzmann 14 hours agoprev>While the machine itself isn’t expensive, it is not cheap if you consider the cost to operate. A machine like this is very power-hungry. Suppose the power consumption is 1000W per hour. Alright, a server will be more power hungry than e.g. your desktop, but... This specific Dell R630 has 2x 750W PSUs in it. That 750W is the maximum rating of one power supply, and there's 2 of them for redundancy - not for increased power intake. That server will run at 750W maximum - but that is the absolute, absolute maximum power it should draw. It's when you have all the rails loaded to the limit and running the server to the ground. A more realistic scenario would be e.g. 100W or so on average. The worse problem if running this server at home would be the terrible small high-RPM fans they have in 1RU servers. The loud high-pitched whine of them will drive you nuts. A better idea would be to get either a lower-power 1RU pizza box, or something larger that can take larger fans - replacing the fans with something quieter and adjusting the fan controller to spin at lower RPMs. >1000W per hour This is just wrong. reply mysteria 12 hours agoparentI run rack servers at home and I 100% call BS on that 1000W number. My older Ivy Bridge Xeon servers only consume 50W on idle, 100W with some load, andand there's 2 of them for redundancy - not for increased power intake Ahem: System Headroom Statistic Reading Instantaneous 1528 W5215 BTU/hr Peak 1346 W4594 BTU/hr That's R720 with dual \"PWR SPLY,750WP,RDNT,FLX\" PSUs. You can configure them for the redundancy mode and you can cap the maximum power per PSU: Hot spare is a power supply feature that configures redundant Power Supply Units (PSUs) to turn off depending on the server load. *This allows the remaining PSUs to operate at a higher load and efficiency.* This requires PSUs that support this feature, so that it quickly powers ON when needed. Redundancy Policy: Not Redundant — In this mode, failure of a single PSU can power off the system. Input Power Redundant — In this mode, the system is functional in the event of failure of a PSU input circuit, provided the PSUs are connected to different input circuits. This is also called AC redundancy. > This is just wrong. But yes, these guys idle at 150W at have around 300W under load with dual CPUs and a lot of RAM. reply zamadatix 15 hours agoprevThis is a great use of the Thunderbolt hardware that comes built into consumer devices. For throughput try sticking \"--parallel 4\" or shorthand \"-P 4\" on the iPerf3 command and see if total throughput changes. reply lathiat 6 hours agoprevI recently wanted to do this and was surprised to learn that USB3 did not have a point-to-point mode like thunderbolt - some controllers had \"dual mode\" ability but the vast majority don't. I was doing this on Macs with thunderbolts 10 years ago but still couldn't do it on a PC today. Despite being great in most ways, AMD desktop systems in general rarely have thunderbolt (unlike Intel) - a few niche motherboards have it. You also can't just add it with a PCIe card, it requires special support from the motherboard. Hopefully this might change with USB4 not sure.. be interesting to see what the lower end motherboards end up shipping support for. reply ThinkBeat 15 hours agoprevMy problem with setups like these is storage. Not much room for expansion in the small boxes and I am not thrilled with external drives. Still had a QNAP or other NAS and hope to get one with compatible USB4 port reply jmrm 10 hours agoparentAFAIK those can have 2/3 NVMe drives, and you can expand them even more with a PCI Express card to add even more NVMe drives reply robocat 15 hours agoprevThe full-mesh is three Mini-PCs where each PC connects to the other two PCs by USB4: unfortunately the image crops out the USB4 cable that links the top PC to the bottom PC which makes it a bit unclear. reply langarus 14 hours agoparentit's linked in the article. It's this cable https://www.amazon.com/dp/B0BLXLSDN5?th=1 reply theogravity 12 hours agoprev> Given California’s average residential electricity rate is 15.34 cents per kWh In the bay area it's 2.5x - 3x the rate. I stopped using my rack server for that reason. I was dumb and didn't consider the electricity costs when buying mine at the time years ago. It sits around collecting dust now. The author's alternative idea is really good considering 8w idle and 80w peak and I doubt it hits peak for what the author wants to do. reply matmatmatmat 12 hours agoparentIt's actually even worse in SDG&E territory. A kWh costs around 32 cents, but \"transmission\" and \"distribution\" are again twice that. The end result is about $1.00 / kWh. reply thinkerswell 9 hours agorootparentI’m convinced SDGE is the most hated company in the country. The southeast is so much cheaper for electricity. reply dgacmu 13 hours agoprevSomewhat related, I recently wanted to fix a slow nfs problem (1 server, 1 client -- basically, a file server and a machine with some GPUs). It turns out that used previous generation mellanox 100gig NICs are quite cheap now, and you can direct-connect two machines for about $600. (What I really wanted was the low latency, but the bandwidth is handy to have sometimes) reply toyg 15 hours agoprev> I don’t understand why it can only hit 11Gbps [...] other people building similar networks were able to hit 20Gbps. [...] So it could simply be that the machine only supports up to this speed [...] it might compete with [Intel's] network controllers, so they capped the speed I'm bad at low-level networking, but could it be a routing issue? Effectively every machine is also a router, so there might be some wasting going on. reply arghwhat 15 hours agoparentThe machines are not configured as \"routers\" in that example. It is just a point-to-point layer 2 network, where each network link serves exactly one possible destination. As simple as it can be. reply DannyBee 9 hours agoparentprevIt's more likely to be offloads and processing time - none of these have any of the offloads a regular network card does. Even if the CPU can handle it, it increases latency, and with a single stream like this, that affects throughput badly. At 10gigabit/second, with 1518 byte packets, it's 823451.9104 packets per second. So in a single stream, you have to process each packet within 1.21microseconds to keep up At 20gbps, you have 600nanoseconds per packet. There are also almost certainly timing/synchronization issues between different stacks like this. It's horribly inefficient. Network cards achieve >10gbps in part by offloading a lot of stuff. Even if the CPU can handle the load, just going through different stacks like they are may add enough latency to throw single stream throughput off. The posited reason of \"not compete with network cards\" is beyond stupid. It can't because you can only do a few meters this way, max. That's not interesting at all. 25gbps network cards are cheap and for a few meters, a $10-15 25gbps DAC will suffice For more than that, 25gbps transceivers are 25 bucks a pop for 25gbps-SR, which will do 100meters. With none of the problems of trying to use longer thunderbolt cables, too. Intel's 25gbps SKUs are not where they make their money anyway. reply r1ch 15 hours agoparentprevIt's measuring single TCP connection performance which is already difficult to optimize. With jumbo frames and tuned buffer sizes I'd expect it to get higher, but it will likely be serialized to a single core's worth of CPU. Using multiple connections should give a better representation of available link bandwidth. reply adrian_b 12 hours agoparentprevIIRC the specification of Thunderbolt from Intel (which was inherited by USB 4) limits the Ethernet emulation mode to 10 Gb/s. Why did they set a limit so low is not known, but the supposition made by another poster that this is a market segmentation feature may be right, because such policies have always been typical for Intel. reply wmf 10 hours agorootparentThis post is getting almost 12 Gbps and someone mentioned getting 16 Gbps on Mac so I don't think there's any intentional limit. Thunderbolt is really 22 Gbps anyway and networking over Thunderbolt is just inefficient. reply AceJohnny2 9 hours agoprevThis was a selling point for the tras^H^H cylinder Mac Pros (2013), with Thunderbolt 2. I hear some teams constructed compute clusters based on that... reply johnwalkr 12 hours agoprevI use a shorter, similar cable when I travel with 2 macbooks (work and personal). I like to use barrier (software kind-of KVM) to share my mouse and keyboard between them and work on one, but use the other one for music and reference material. I get work/personal separation with the convenience of using one mouse and keyboard. I simply set up static IPs on each one and also setup internet sharing from one to the other. Surprisingly barrier, internet sharing and even charging always works with this arrangement. I only have to connect 1 macbook to wifi and power. reply amelius 10 hours agoprevDoes USB4 have the galvanic isolation that ethernet has? reply ApolIllo 8 hours agoparentThunderbolt 3 had a fiber option for longer runs, but I don't see it for Tbolt4. reply thekombustor 15 hours agoprev10Gbps mesh for only $48, assuming you already have very modern (expensive) USB4 capable machines. The article also seems to make the assumption that a server would be pulling 1000W all the time, 24/7, which is rarely the case (of course, I can't comment on what their workload might be, but it would be quite unlikely) Still, I like the direct networking being done here. But saying \"you can build a 10Gbps mesh for $50\" when you have 3x $750+ machines seems a bit disingenuous. It is not unreasonable to get 10Gb SFP+ NICs on ebay for ~$50 a pop ($150 for 3) reply E39M5S62 13 hours agoparent$50 would be roughly all-in for the SFP+ NIC, two optics and a generous length of multi-mode fiber. I just did this, and here's the breakdown of my costs from eBay: 1x Juniper EX3300-24p - $75 7x SFP+ optics - $7/each 3x Intel X520-DA2 NIC - $20/each 4x 3 meter OM3 LC-LC fiber - $6/each 1x 30 meter OM3 LC-LC fiber - $24 ----- Total: $232 The EX3300-24p has 24x 1gb copper ports with PoE+ on them, and 4x SFP+ ports. If you need more SFP+ ports you'll want to find a different switch - but for a small multi-use home network the EX3300-24p nicely matched my requirements. reply justsomehnguy 10 hours agorootparent> If you need more SFP+ ports you'll want to find a different switch CRS309-1G-8S+IN, Suggested price $269.00 >> Desktop switch with one Gigabit Ethernet port and eight SFP+ 10Gbps ports https://mikrotik.com/product/crs309_1g_8s_in reply E39M5S62 8 hours agorootparentMikrotik switches/products are pretty intriguing. Do you have any experience with that model? I'm interested in how stable it is and if the known bugs are anything to be concerned about. reply justsomehnguy 7 hours agorootparentNope, but if you saw/used one Mikrotik then you saw them all. Personally I have a love/hate relationship with MT, with a little love and a lot of hate, but at their price range they are unbeatable and works 99% of time. https://www.servethehome.com/mikrotik-crs309-1g-8sin-review-... reply bhouston 15 hours agoprevI saw this mini-computer recently, the UM790 Pro, and I almost bought one as well. The AMD Ryzen CPU, AMD Ryzen 9 7940HS CPU, has a rating of ~30,000 on the CPU Benchmarks page (https://www.cpubenchmark.net/high_end_cpus.html) which is quite high end for the size/cost. The only caveat is that I am running a 10Gbit ethernet network at home and it wasn't that costly to setup. A 10GigE switch costs around $500 CAD right now and that is all you need. reply Liftyee 13 hours agoparent> A 10GigE switch costs around $500 CAD right now and that is all you need. Surely your machines all need 10GbE NICs as well? Admittedly my hardware isn't the newest (2.5GbE at most), but from a quick search 10Gig PCIe cards are around $150 each. Meanwhile 10-20 Gbps USB3.0 is reasonably common already. Though, using Ethernet still has many other advantages over running USB C cables everywhere. reply adrian_b 12 hours agorootparentThere are also adapters from USB4 to 10 Gb/s Ethernet, for the case when it is desired to use a switch or long cables. reply bhouston 12 hours agorootparentprevMy MacMini M2 has one built in. My other machines, yeah, I did buy some, which go for around $100 CAD on Amazon (e.g. TX401). Ethernet is advantageous because my house is wired, so I can have my switching a central location. reply robes 6 hours agorootparentprevserver-grade 2x SFP+ 10G NIC pulls are pretty easy to pick up from eBay for about $20 each With a multigig capable SFP+ module it can handle 2.5G/5G copper as well. reply daxfohl 15 hours agoprevThis would only work for close range, right? To do a whole-house thing you'd need to get a bunch of USB-cat6 adapters which would end up being more expensive than a switch? reply manmal 15 hours agoparentYes a couple meters max, at full speed. The full speed cables are also quite expensive. reply nope96 9 hours agoprevHow good is error handling on USB 4? The rare times I've had data corruption it was almost always when transferring lots of data using USB (this happened to me on multiple drives, computers, usb ports or cables. this was in the early USB 3 days) reply BloodyIron 13 hours agoprevDidn't read the article, but the math they did about the R730 power draw is NOWHERE near realistic. A 1000Watt power supply unit (PSU) will only draw what is actually being used, not the full capacity 100% of the time. I have a fleet of R720's (generation before the example R730's) and their typical at-wall draw when running many VMs on them is about 150 Watts. So their math for that aspect is 100% WRONG. That being said, neat concept IMO. reply armhole2625 12 hours agoparentI also have a fleet of R720s and can confirm BloodyIron's numbers. Average draw is around 150 watts. reply johng 15 hours agoprevThis is neat. reply mrkstu 15 hours agoprevOn actual network gear you'd typically drop the interfaces into a subnet/broadcast domain, but the blogger here has put everything in /32s and it looks like it's creating a peer connection without a shared domain. Any particular advantage/disadvantage to doing it this way? reply dfox 14 hours agoparentIn this case the primary reason for configuring it as point to point links is that it matches the hardware topology. In theory there is a standards compliant way to create an ethernet-style network from this, but there are two critical software components to that that are not implemented in mainline kernels (namely raw Ethernet over TB and SPB). The main disadvantage inherent in the physical topology is that you are always going to do switching/routing decisions on the CPU. But as long as you use that as a virtualization platform or run k8s on that you are going to do that anyway and the additional overhead is probably irrelevant. (This assumes the full mesh topology, which with this hardware is not scalable over 3 nodes, might be to like 5 with somewhat more expensive consumer grade HW and is not really scalable to more than 8 nodes due to the sheer amount of cabling required) reply ComputerGuru 14 hours agoparentprevIt doesn’t scale. Number of connections/hardware is exponential to the number of nodes. reply cma 11 hours agorootparentIsn't it just N^2? reply ComputerGuru 11 hours agorootparentAbsolutely. Sorry, I meant quadratic but had a brain fart. reply nickstinemates 15 hours agoprevIncredible. Traditional 10Gb network gear is very expensive to buy and to operate. $50 is a lot cheaper. reply Palomides 15 hours agoparentnot really true, a similar setup with 40Gbe (three nodes, no switch) would run you less than $100 for pcie cards and cables reply hamandcheese 15 hours agorootparentThe only NICs I see in that price range are old Mellanox cards. Intel NICs are 5-10x that price. I'm not sure why, but my suspicion is that it has to do with driver support and/or interoperability. reply Palomides 14 hours agorootparentI run mellanox connectx3 cards, they work immediately with no extra drivers on windows 10/11 and every linux I've tried mellanox is/was quite good at getting code upstreamed maybe I need to do my own blog post about my pile of computers... reply TacticalCoder 12 hours agorootparent> maybe I need to do my own blog post about my pile of computers... Yes, several of us love to read about that! I haven't switched to 10 Gbit/s yet... reply thefz 11 hours agorootparentprev> I run mellanox connectx3 cards, they work immediately with no extra drivers on windows 10/11 and every linux I've tried Own three, can confirm for Windows and Linux. reply gregors 8 hours agorootparentprevwould love to read this! reply Hikikomori 14 hours agorootparentprevMellanox works fine. reply olavgg 13 hours agorootparentAnd with Mellanox you get working RMDA/ROCE. reply hamandcheese 14 hours agorootparentprevGotcha. Why the price discrepancy then? reply petronio 10 hours agorootparentI can't answer definitively, but I was looking for SFP cards recently and the older cards don't really support ASPM. The cards themselves aren't power hogs, but they keep the CPU from going into lower states during idle. The cheapest one I found that others related had ASPM actually working was the Intel X710, and those are much more expensive than the ConnectX-3. reply Hikikomori 14 hours agorootparentprevAre you comparing new Intel cards to old mellanox cards on ebay? If not idk why, I have not compared them myself, some feature maybe? Cost doesn't always make sense either. reply hamandcheese 9 hours agorootparentIm just comparing the prices I see when I search ebay for \"40gbe nic\" vs \"40gbe nic intel\", making no effort to compare features. reply ApolIllo 8 hours agorootparentprevI avoiding older 10gbe NICs due to power consumption. Maybe that's why? reply nickstinemates 15 hours agorootparentprevCan you provide links? I'll upgrade my home lab from 10g to 40g immediately at that price. reply willglynn 14 hours agorootparentIn 2024 I would suggest deploying 2x25G instead, via e.g. MCX4121. Pricing is similar ( 100G That last point is particularly relevant given the existence of switches like the Mikrotik CRS504, providing 4x100G ports on 25W. reply Palomides 14 hours agorootparentthose are all reasonable points, if I were doing mine again I would spend a little more and go up to 100gbe if you run all older mellanox gear the cx3 can do the kinda nonstandard 56gbe as well reply bombela 12 hours agorootparentWhat are you doing that you need 100gbe? I am still on 1gbe... I guess I don't transfer anything bigger than a few GiB time to time. reply nickstinemates 2 hours agorootparentNo individual connection other than like a cr tral storage server needs 100gbe, at least for me, but a 100gbe backplane is good for a lot of 1gbe poe devices as an example. With residential fiber/coax reaching 5gb, 1gb is not enough. reply Hikikomori 14 hours agorootparentprevMellanox connect-x 3 probably. reply Palomides 14 hours agorootparentprevcx353a and cx354a, prefer the fcbt models, but you can reflash them all to fcbt reply crotchfire 13 hours agorootparentWhat does fcbt stand for and why would I want it? reply Palomides 13 hours agorootparentthe same hardware was sold at different prices with different capabilities enabled based on the exact model variant, stuff like higher speeds and infiniband support you can see them all in the datasheet, I believe fcbt is the one with all the stuff enabled reply Havoc 13 hours agoprevWould it not make sense to put the k8s network on 2.5gbe and give the three nodes a usb4 connection to a storage NAS instead? Assuming you can find a nas with 3x usb4 I suppose reply alphabettsy 13 hours agoparentA NAS typically doesn’t use or support connecting to a PC over USB, that would be DAS(direct attached storage), but even then they don’t support connecting to multiple PCs simultaneously. reply Havoc 9 hours agorootparentThe PCs in the article are connected to multiple other devices each so seems possible at least in principle. I don’t see why the same wouldn’t be possible for a NAS. Stuff like truenas can serve across multiple interfaces reply robes 6 hours agorootparentprevAssuming the NAS can do the same networking over USB4 that the author used it could work. reply Sweepi 15 hours agoprev8 Zen4 cores dont beat 16 Zen2 cores in multicore. Either Geekbench 6 does not utilize all cores, or the 3950x setup is borked. reply wtallis 14 hours agoparentGeekbench 5 pretended that all multi-core workloads were embarrassingly parallel by running N independent copies of the single-core test across N cores, with zero communication between threads. Geekbench 6 takes a more realistic approach so Amdahl's Law applies and it doesn't scale linearly with more CPU cores. reply jltsiren 15 hours agoparentprevGeekbench 6 multi-core is a single-task benchmark. It runs one task at a time, using multiple threads when possible. This makes it scale worse and favor single-core performance more than benchmarks that run multiple independent tasks in parallel. reply diamondlovesyou 15 hours agoparentprevGB6 will use the Zen4's AVX512, which Zen2 doesn't support. reply notorandit 15 hours agoprevMaybe he can get 20 Gbps between 2 servers. You get half because of USB limitations (2 ports on the same hub). reply riku_iki 15 hours agoprev15c/kwh estimate in California looks very far from the current situation. reply jms703 15 hours agoparentYeah, I think the website the author linked to has old data. It's 3x that in California. reply kube-system 15 hours agorootparentIt is 26.72 cents per kwh as of the latest official numbers which are from October 2023. https://www.eia.gov/electricity/monthly/epm_table_grapher.ph... reply riku_iki 15 hours agorootparentNot clear who are those \"ultimate customers\". Also, in case of server hardware, it is excessive over basic tier electricity consumption, so it will hit those 50c/kwh. reply kube-system 15 hours agorootparent> Not clear who are those \"ultimate customers\". The first column is residential customers. reply riku_iki 15 hours agorootparentIt is residential \"ultimate\" customers. My current bill for initial tier is: 42c/kwh delivery + 15c/kwh generation, and even higher over initial consumption. I guess I am not \"ultimate\" customer. reply kube-system 15 hours agorootparent'ultimate customer' means the customer using the power, which you are. The reason you don't pay the price listed on that page is because you are only one customer. You are not the average customer. reply riku_iki 15 hours agorootparentThe fact that I live in the center of densely populated area and serviced by major provider who also holds monopoly, makes me think there is a chance that table's numbers are just not what you think. They may include just generation cost, and not delivery, or there is something about \"ultimate customer\" definition. Also, there were several hikes since Oct in my understanding. reply kube-system 14 hours agorootparentI read form EIA-861, which is where the data comes from. Looks like sales to \"ultimate customers\" means it excludes electricity that was not sold, electricity that was sold to resellers, energy lost, etc. The form also collects information about revenue from delivery \"and other related charges\" 42c/kwh delivery sounds insane. I couldn't find much data about average delivery rates, but I plugged in a few counties here and it looks like many areas have delivery rates significantly lower than that: https://www.cpuc.ca.gov/RateComparison reply riku_iki 12 hours agorootparent> I plugged in a few counties here and it looks like many areas have delivery rates significantly lower than that: https://www.cpuc.ca.gov/RateComparison That page says numbers are year old, I entered my zip there and it says delivery is 20c/kwh for me. If you don't know the story: PG&E is delivery monopolist in CA, with exception of some places with local powerplants. It was found guilty in causing wildfires, lost in court and need to pay $XXB damages, which it now shifts to customers through multiple rate hikes in 2023 and more coming in 2024. 42c/kwh is initial tier cost, whatever is over limit will be charged at 50c/kwh for just delivery. reply jms703 15 hours agoprevNeat. I stopped reading at \"California’s average residential electricity rate is 15.34 cents per kWh\" and checked my electricity bill. Here in California, I'm paying 40.82 cents per kWh. The website https://www.electricitylocal.com/ seems wildly off. Edit: I did read the entire article. Just stopped to check what I was paying. reply zamadatix 15 hours agoparentProbably just older data based on looking at the trends https://data.bls.gov/timeseries/APUS49E72610?amp%253bdata_to... and https://data.bls.gov/timeseries/APUS49A72610?amp%253bdata_to... That said, mentioning it is one thing (it makes the case for low power devices even stronger) but why stop reading anything after the first error you identify? That doesn't guarantee you only get accurate information it just guarantees you'll miss out on good information, like the cheap high speed connectivity the article is actually demonstrating. reply jms703 15 hours agorootparentI meant that I stopped reading to check. I read the entire article. reply alchemist1e9 15 hours agoparentprevAt that rate how are there any data centers in California? reply kube-system 15 hours agorootparentIndustrial and commercial users of power almost always get different pricing than residential rates in the US. reply alchemist1e9 14 hours agorootparentDifferent yes but not 4x different. I know in Illinois standard generic commercial is around 9 cents and residential is like 12 cents. reply diggan 15 hours agorootparentprevNot everyone has the same contracts and contacts. reply jauntywundrkind 8 hours agoprevThe speed here is concerning to me. This is way short of what I'd expect or hope for. I hope in the future reviewers start testing this sort of thing when doing in depth reviews; this should be very visible high pressure an objective. Hopefully there's wins available & this isn't some silly unadvertised hardware gotcha. Higher mtu, trying some parallelism are two good suggestions I heard. One other thing I'd note: it's only been very recently that Linux has learned how to let the USB and DisplayPort negotiate/allocate bandwidth. It was evenly split between the two until March. Linux 6.3 Adds Thunderbolt/USB4 DisplayPort Bandwidth Allocation Mode. Linux 6.3 Adds Thunderbolt/USB4 DisplayPort Bandwidth Allocation Mode It's unclear how automatic this bandwidth management is under what systems; users might need to use the new thunderbolt-utils from July to adjust it manually. Intel Rolls Out thunderbolt-utils To Manage USB4/Thunderbolt Devices On Linux. https://www.phoronix.com/news/Intel-Linux-thunderbolt-utils I really want to hope much better is already possible. I don't own any USB4 systems though! How awesome they are. I hope we see some cool all-in-one's with multiple USB4 in; upcoming Minisforum V3 tablet for example has at least one usb4 that can do DisplayPort In, if I understand, for example, and that capability feels like it should just be coming for free now on PC's USB4 ports!!! reply z3t4 15 hours agoprev [–] I suspect there will be some extra network latency using usb-c compared to a RJ hardware switch. reply dfox 14 hours agoparent [–] It is almost certainly the other way around. Even 1000-base-T PHY is complex block of analog magic that draws significant power and adds measurable latency over direct SGMII/optical link. In comparison USB4 is even more directly connected to CPU than the whateverMII interface of PCIe NIC. reply johnwalkr 14 hours agorootparent [–] For a while at work I was trying to use ethernet for embedded stuff because it seemed more modern than CAN, i2c etc. I couldn't figure out why so few microcontrollers support it. It turns out just normal copper 100Mbps ethernet uses about 0.25W per port (0.5W for 1 point-point ethernet link) so it doesn't make sense for embedded applications. Gigbit uses more but I forget how much more. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author, a software engineer, believes it is crucial to have knowledge of hardware in addition to software.",
      "They migrated some services from AWS cloud to bare-metal servers to reduce costs.",
      "The author built a bare-metal Kubernetes cluster using a USB4 ethernet bridge, achieving a network speed of 11Gbps at a cost of $47.98 USD.",
      "They compare the cost and power consumption of retired 1U servers versus mini PCs, highlighting the advantages of mini PCs.",
      "NixOS was used for network configuration, and benchmark results were provided.",
      "The author speculates on the potential of high-speed USB/Thunderbolt-based networks in the future."
    ],
    "commentSummary": [
      "The discussion explores different networking options including USB, Firewire, Thunderbolt, Ethernet, and NVMe drives.",
      "Participants share their experiences and preferences, discussing factors such as speed, cost, power consumption, and compatibility.",
      "The conversation emphasizes the importance of considering individual needs and resources when selecting a networking solution."
    ],
    "points": 327,
    "commentCount": 209,
    "retryCount": 0,
    "time": 1705339605
  },
  {
    "id": 39004963,
    "title": "SQLite 3.45: Enhancements and Bug Fixes for Improved Performance and Usability",
    "originLink": "https://www.sqlite.org/changes.html#version_3_45_0",
    "originBody": "Small. Fast. Reliable. Choose any three. Home Menu About Documentation Download License Support Purchase Search About Documentation Download Support Purchase Search Documentation Search Changelog Release History This page provides a high-level summary of changes to SQLite. For more detail, see the Fossil checkin logs at https://www.sqlite.org/src/timeline and https://www.sqlite.org/src/timeline?t=release. See the chronology a succinct listing of releases. 2024-01-15 (3.45.0) Added the SQLITE_RESULT_SUBTYPE property for application-defined SQL functions. All application defined SQL functions that invokes sqlite3_result_subtype() must be registered with this new property. Failure to do so might cause the call to sqlite3_result_subtype() to behave as a no-op. Compile with -DSQLITE_STRICT_SUBTYPE=1 to cause an SQL error to be raised if a function that is not SQLITE_RESULT_SUBTYPE tries invokes sqlite3_result_subtype(). The use of -DSQLITE_STRICT_SUBTYPE=1 is a recommended compile-time option for every application that makes use of subtypes. Enhancements to the JSON SQL functions: All JSON functions are rewritten to use a new internal parse tree format called JSONB. The new parse-tree format is serializable and hence can be stored in the database to avoid unnecessary re-parsing whenever the JSON value is used. New versions of JSON-generating functions generate binary JSONB instead of JSON text. The json_valid() function adds an optional second argument that specifies what it means for the first argument to be \"well-formed\". Add the FTS5 tokendata option to the FTS5 virtual table. The SQLITE_DIRECT_OVERFLOW_READ optimization is now enabled by default. Disable it at compile-time using -DSQLITE_DIRECT_OVERFLOW_READ=0. Query planner improvements: Do not allow the transitive constraint optimization to trick the query planner into using a range constraint when a better equality constraint is available. (Forum post 2568d1f6e6.) The query planner now does a better job of disregarding indexes that ANALYZE identifies as low-quality. (Forum post 6f0958b03b.) Increase the default value for SQLITE_MAX_PAGE_COUNT from 1073741824 to 4294967294. Enhancements to the CLI: Improvements to the display of UTF-8 content on Windows Automatically detect playback of \".dump\" scripts and make appropriate changes to settings such as \".dbconfig defensive off\" and \".dbconfig dqs_dll on\". Hashes: SQLITE_SOURCE_ID: 2024-01-15 17:01:13 1066602b2b1976fe58b5150777cced894af17c803e068f5918390d6915b46e1d SHA3-256 for sqlite3.c: f56d8e5e8c61d87b957f1cc60b3042c134d7bc0ca3aba002e6999e8f0af310a3 2023-11-24 (3.44.2) Fix a mistake in the CLI that was introduced by the fix (item 15 above) in 3.44.1. Fix a problem in FTS5 that was discovered during internal fuzz testing only minutes after the 3.44.1 release was tagged. Fix incomplete assert() statements that the fuzzer discovered the day after the previous release. Fix a couple of harmless compiler warnings that appeared in debug builds with GCC 16. Hashes: SQLITE_SOURCE_ID: 2023-11-24 11:41:44 ebead0e7230cd33bcec9f95d2183069565b9e709bf745c9b5db65cc0cbf92c0f SHA3-256 for sqlite3.c: bd70b012e2d1b3efa132d905224cd0ab476a69b892f8c6b21135756ec7ffbb13 2023-11-22 (3.44.1) Change the CLI so that it uses UTF-16 for console I/O on Windows. This enables proper display of unicode text on old Windows7 machines. Other obscure bug fixes. Hashes: SQLITE_SOURCE_ID: 2023-11-22 14:18:12 d295f48e8f367b066b881780c98bdf980a1d550397d5ba0b0e49842c95b3e8b4 SHA3-256 for sqlite3.c: e359dc502a73f3a8ad8e976a51231134d25cb93ad557a724dd92fe0c5897113a 2023-11-01 (3.44.0) Aggregate functions can now include an ORDER BY clause after their last parameter. The arguments to the function are processed in the order specified. This can be important for functions like string_agg() and json_group_array(). Add support for the concat() and concat_ws() scalar SQL functions, compatible with PostgreSQL, SQLServer, and MySQL. Add support for the string_agg() aggregate SQL function, compatible with PostgreSQL and SQLServer. New conversion letters on the strftime() SQL function: %e %F %I %k %l %p %P %R %T %u Add new C-language APIs: sqlite3_get_clientdata() and sqlite3_set_clientdata(). Many errors associated with CREATE TABLE are now raised when the CREATE TABLE statement itself is run, rather than being deferred until the first time the table is actually used. The PRAGMA integrity_check command now verifies the consistency of the content in various built-in virtual tables using the new xIntegrity method. This works for the FTS3, FTS4, FTS5, RTREE, and GEOPOLY extensions. The SQLITE_DBCONFIG_DEFENSIVE setting now prevents PRAGMA writable_schema from being turned on. Previously writable_schema could be turned on, but would not actually allow the schema to be writable. Now it simply cannot be turned on. Tag the built-in FTS3, FTS4, FTS5, RTREE, and GEOPOLY virtual tables as SQLITE_VTAB_INNOCUOUS so that they can be used inside of triggers in high-security deployments. The PRAGMA case_sensitive_like statement is deprecated, as its use when the schema contains LIKE operators can lead to reports of database corruption by PRAGMA integrity_check. SQLITE_USE_SEH (Structured Exception Handling) is now enabled by default whenever SQLite is built using the Microsoft C compiler. It can be disabled using -DSQLITE_USE_SEH=0 Query planner optimizations: In partial index scans, if the WHERE clause implies a constant value for a table column, replace occurrences of that table column with the constant. This increases the likelihood of the partial index being a covering index. Disable the view-scan optimization (added in version 3.42.0 - item 1c) as it was causing multiple performance regressions. In its place, reduce the estimated row count for DISTINCT subqueries by a factor of 8. SQLite now performs run-time detection of whether or not the underlying hardware supports \"long double\" with precision greater than \"double\" and uses appropriate floating-point routines depending on what it discovered. The CLI for Windows now defaults to using UTF-8 for both input and output on platforms that support it. The --no-utf8 option is available to disable UTF8 support. Hashes: SQLITE_SOURCE_ID: 2023-11-01 11:23:50 17129ba1ff7f0daf37100ee82d507aef7827cf38de1866e2633096ae6ad8130 SHA3-256 for sqlite3.c: d9e6530096136067644b1cb2057b3b0fa51070df99ec61971f73c9ba6aa9a36e 2023-10-10 (3.43.2) Fix a couple of obscure UAF errors and an obscure memory leak. Omit the use of the sprintf() function from the standard library in the CLI, as this now generates warnings on some platforms. Avoid conversion of a double into unsigned long long integer, as some platforms do not do such conversions correctly. Hashes: SQLITE_SOURCE_ID: 2023-10-10 12:14:04 4310099cce5a487035fa535dd3002c59ac7f1d1bec68d7cf317fd3e769484790 SHA3-256 for sqlite3.c: e17a3dc69330bd109256fb5a6e2b3ce8fbec48892a800389eb7c0f8856703161 2023-09-11 (3.43.1) Fix a regression in the way that the sum(), avg(), and total() aggregate functions handle infinities. Fix a bug in the json_array_length() function that occurs when the argument comes directly from json_remove(). Fix the omit-unused-subquery-columns optimization (introduced in in version 3.42.0) so that it works correctly if the subquery is a compound where one arm is DISTINCT and the other is not. Other minor fixes. Hashes: SQLITE_SOURCE_ID: 2023-09-11 12:01:27 2d3a40c05c49e1a49264912b1a05bc2143ac0e7c3df588276ce80a4cbc9bd1b0 SHA3-256 for sqlite3.c: 391af0a4755e31ae8b29776a4a060b678823ffe4c4db558567567c688a578589 2023-08-24 (3.43.0) Add support for Contentless-Delete FTS5 Indexes. This is a variety of FTS5 full-text search index that omits storing the content that is being indexed while also allowing records to be deleted. Enhancements to the date and time functions: Added new time shift modifiers of the form ±YYYY-MM-DD HH:MM:SS.SSS. Added the timediff() SQL function. Added the octet_length(X) SQL function. Added the sqlite3_stmt_explain() API. Query planner enhancements: Generalize the LEFT JOIN strength reduction optimization so that it works for RIGHT and FULL JOINs as well. Rename it to OUTER JOIN strength reduction. Enhance the theorem prover in the OUTER JOIN strength reduction optimization so that it returns fewer false-negatives. Enhancements to the decimal extension: New function decimal_pow2(N) returns the N-th power of 2 for integer N between -20000 and +20000. New function decimal_exp(X) works like decimal(X) except that it returns the result in exponential notation - with a \"e+NN\" at the end. If X is a floating-point value, then the decimal(X) function now does a full expansion of that value into its exact decimal equivalent. Performance enhancements to JSON processing results in a 2x performance improvement for some kinds of processing on large JSON strings. New makefile target \"verify-source\" checks to ensure that there are no unintentional changes in the source tree. (Works for canonical source code only - not for precompiled amalgamation tarballs.) Added the SQLITE_USE_SEH compile-time option that enables Structured Exception Handling on Windows while working with the memory-mapped shm file that is part of WAL mode processing. This option is enabled by default when building on Windows using Makefile.msc. The VFS for unix now assumes that the nanosleep() system call is available unless compiled with -DHAVE_NANOSLEEP=0. Hashes: SQLITE_SOURCE_ID: 2023-08-24 12:36:59 0f80b798b3f4b81a7bb4233c58294edd0f1156f36b6ecf5ab8e83631d468778c SHA3-256 for sqlite3.c: a6fc5379891d77b69a7d324cd24a437307af66cfdc3fef5dfceec3c82c8d4078 2023-05-16 (3.42.0) Add the FTS5 secure-delete command. This option causes all forensic traces to be removed from the FTS5 inverted index when content is deleted. Enhance the JSON SQL functions to support JSON5 extensions. The SQLITE_CONFIG_LOG and SQLITE_CONFIG_PCACHE_HDRSZ calls to sqlite3_config() are now allowed to occur after sqlite3_initialize(). New sqlite3_db_config() options: SQLITE_DBCONFIG_STMT_SCANSTATUS and SQLITE_DBCONFIG_REVERSE_SCANORDER. Query planner improvements: Enable the \"count-of-view\" optimization by default. Avoid computing unused columns in subqueries. Improvements to the push-down optimization. Enhancements to the CLI: Add the --unsafe-testing command-line option. Without this option, some dot-commands (ex: \".testctrl\") are now disabled because those commands that are intended for testing only and can cause malfunctions if misused. Allow commands \".log on\" and \".log off\", even in --safe mode. \"--\" as a command-line argument means all subsequent arguments that start with \"-\" are interpreted as normal non-option argument. Magic parameters \":inf\" and \":nan\" bind to floating point literals Infinity and NaN, respectively. The --utf8 command-line option omits all translation to or from MBCS on the Windows console for interactive sessions, and sets the console code page for UTF-8 I/O during such sessions. The --utf8 option is a no-op on all other platforms. Add the ability for application-defined SQL functions to have the same name as join keywords: CROSS, FULL, INNER, LEFT, NATURAL, OUTER, or RIGHT. Enhancements to PRAGMA integrity_check: Detect and raise an error when a NaN value is stored in a NOT NULL column. Improved error message output identifies the root page of a b-tree when an error is found within a b-tree. Allow the session extension to be configured to capture changes from tables that lack an explicit ROWID. Added the subsecond modifier to the date and time functions. Negative values passed into sqlite3_sleep() are henceforth interpreted as 0. The maximum recursion depth for JSON arrays and objects is lowered from 2000 to 1000. Extended the built-in printf() function so the comma option now works with floating-point conversions in addition to integer conversions. Miscellaneous bug fixes and performance optimizations Hashes: SQLITE_SOURCE_ID: 2023-05-16 12:36:15 831d0fb2836b71c9bc51067c49fee4b8f18047814f2ff22d817d25195cf350b0 SHA3-256 for sqlite3.c: 6aa3fadf000000625353bbaa1e83af114c40c240a0aa5a2c1c2aabcfc28d4f92 2023-03-22 (3.41.2) Multiple fixes for reads past the end of memory buffers (NB: reads not writes) in the following circumstances: When processing a corrupt database file using the non-standard SQLITE_ENABLE_STAT4 compile-time option. In the CLI when the sqlite3_error_offset() routine returns an out-of-range value (see also the fix to sqlite3_error_offset() below). In the recovery extension. In FTS3 when processing a corrupt database file. Fix the sqlite3_error_offset() so that it does not return out-of-range values when reporting errors associated with generated columns. Multiple fixes in the query optimizer for problems that cause incorrect results for bizarre, fuzzer-generated queries. Increase the size of the reference counter in the page cache object to 64 bits to ensure that the counter never overflows. Fix a performance regression caused by a bug fix in patch release 3.41.1. Fix a few incorrect assert() statements. Hashes: SQLITE_SOURCE_ID: 2023-03-22 11:56:21 0d1fc92f94cb6b76bffe3ec34d69cffde2924203304e8ffc4155597af0c191da SHA3-256 for sqlite3.c: c83f68b7aac1e7d3ed0fcdb9857742f024449e1300bfb3375131a6180b36cf7c 2023-03-10 (3.41.1) Provide compile-time options -DHAVE_LOG2=0 and -DHAVE_LOG10=0 to enable SQLite to be compiled on systems that omit the standard library functions log2() and log10(), repectively. Ensure that the datatype for column t1.x in \"CREATE TABLE t1 AS SELECT CAST(7 AS INT) AS x;\" continues to be INT and is not NUM, for historical compatibility. Enhance PRAGMA integrity_check to detect when extra bytes appear at the end of an index record. Fix various obscure bugs reported by the user community. See the timeline of changes for details. Hashes: SQLITE_SOURCE_ID: 2023-03-10 12:13:52 20399f3eda5ec249d147ba9e48da6e87f969d7966a9a896764ca437ff7e737ff SHA3-256 for sqlite3.c: d0d9db8425570f4a57def04fb8f4ac84f5c3e4e71d3d4d10472e3639c5fdf09f 2023-02-21 (3.41.0) Query planner improvements: Make use of indexed expressions within an aggregate query that includes a GROUP BY clause. The query planner has improved awareness of when an index is a covering index and adjusts predicted runtimes accordingly. The query planner is more aggressive about using co-routines rather than materializing subqueries and views. Queries against the built-in table-valued functions json_tree() and json_each() will now usually treat \"ORDER BY rowid\" as a no-op. Enhance the ability of the query planner to use indexed expressions even if the expression has been modified by the constant-propagation optimization. (See forum thread 0a539c7.) Add the built-in unhex() SQL function. Add the base64 and base85 application-defined functions as an extension and include that extension in the CLI. Add the sqlite3_stmt_scanstatus_v2() interface. (This interface is only available if SQLite is compiled using SQLITE_ENABLE_STMT_SCANSTATUS.) In-memory databases created using sqlite3_deserialize() now report their filename as an empty string, not as 'x'. Changes to the CLI: Add the new base64() and base85() SQL functions Enhanced EXPLAIN QUERY PLAN output using the new sqlite3_stmt_scanstatus_v2() interface when compiled using SQLITE_ENABLE_STMT_SCANSTATUS. The \".scanstats est\" command provides query planner estimates in profiles. The continuation prompt indicates if the input is currently inside of a string literal, identifier literal, comment, trigger definition, etc. Enhance the --safe command-line option to disallow dangerous SQL functions. The double-quoted string misfeature is now disabled by default for CLI builds. Legacy use cases can reenable the misfeature at run-time using the \".dbconfig dqs_dml on\" and \".dbconfig dqs_ddl on\" commands. Enhance the PRAGMA integrity_check command so that it detects when text strings in a table are equivalent to but not byte-for-byte identical to the same strings in the index. Enhance the carray table-valued function so that it is able to bind an array of BLOB objects. Added the sqlite3_is_interrupted() interface. Long-running calls to sqlite3_prepare() and similar now invoke the progress handler callback and react to sqlite3_interrupt(). The sqlite3_vtab_in_first() and sqlite3_vtab_in_next() functions are enhanced so that they reliably detect if they are invoked on a parameter that was not selected for multi-value IN processing using sqlite3_vtab_in(). They return SQLITE_ERROR instead of SQLITE_MISUSE in this case. The parser now ignores excess parentheses around a subquery on the right-hand side of an IN operator, so that SQLite now works the same as PostgreSQL in this regard. Formerly, SQLite treated the subquery as an expression with an implied \"LIMIT 1\". Added the SQLITE_FCNTL_RESET_CACHE option to the sqlite3_file_control() API. Makefile improvements: The new makefile target \"sqlite3r.c\" builds an amalgamation that includes the recovery extension. New makefile targets \"devtest\" and \"releasetest\" for running a quick developmental test prior to doing a check-in and for doing a full release test, respectively. Miscellaneous performance enhancements. Hashes: SQLITE_SOURCE_ID: 2023-02-21 18:09:37 05941c2a04037fc3ed2ffae11f5d2260706f89431f463518740f72ada350866d SHA3-256 for sqlite3.c: 02bd9e678460946810801565667fdb8f0c29c78e51240512d2e5bb3dbdee7464 2022-12-28 (3.40.1) Fix the --safe command-line option to the CLI such that it correctly disallows the use of SQL functions like writefile() that can cause harmful side-effects. Fix a potential infinite loop in the memsys5 alternative memory allocator. This bug was introduced by a performance optimization in version 3.39.0. Various other obscure fixes. Hashes: SQLITE_SOURCE_ID: 2022-12-28 14:03:47 df5c253c0b3dd24916e4ec7cf77d3db5294cc9fd45ae7b9c5e82ad8197f38a24 SHA3-256 for sqlite3.c: 4d6800e9032ff349376fe612e422b49ba5eb4e378fac0b3e405235d09dd366ab 2022-11-16 (3.40.0) Add support for compiling SQLite to WASM and running it in web browsers. NB: The WASM build and its interfaces are considered \"beta\" and are subject to minor changes if the need arises. We anticipate finalizing the interface for the next release. Add the recovery extension that might be able to recover some content from a corrupt database file. Query planner enhancements: Recognize covering indexes on tables with more than 63 columns where columns beyond the 63rd column are used in the query and/or are referenced by the index. Extract the values of expressions contained within expression indexes where practical, rather than recomputing the expression. The NOT NULL and IS NULL operators (and their equivalents) avoid loading the content of large strings and BLOB values from disk. Avoid materializing a view on which a full scan is performed exactly once. Use and discard the rows of the view as they are computed. Allow flattening of a subquery that is the right-hand operand of a LEFT JOIN in an aggregate query. A new typedef named sqlite3_filename is added and used to represent the name of a database file. Various interfaces are modified to use the new typedef instead of \"char*\". This interface change should be fully backwards compatible, though it might cause (harmless) compiler warnings when rebuilding some legacy applications. Add the sqlite3_value_encoding() interface. Security enhancement: SQLITE_DBCONFIG_DEFENSIVE is augmented to prohibit changing the schema_version. The schema_version becomes read-only in defensive mode. Enhancements to the PRAGMA integrity_check statement: Columns in non-STRICT tables with TEXT affinity should not contain numeric values. Columns in non-STRICT tables with NUMERIC affinity should not contain TEXT values that could be converted into numbers. Verify that the rows of a WITHOUT ROWID table are in the correct order. Enhance the VACUUM INTO statement so that it honors the PRAGMA synchronous setting. Enhance the sqlite3_strglob() and sqlite3_strlike() APIs so that they are able to accept NULL pointers for their string parameters and still generate a sensible result. Provide the new SQLITE_MAX_ALLOCATION_SIZE compile-time option for limiting the size of memory allocations. Change the algorithm used by SQLite's built-in pseudo-random number generator (PRNG) from RC4 to Chacha20. Allow two or more indexes to have the same name as long as they are all in separate schemas. Miscellaneous performance optimizations result in about 1% fewer CPU cycles used on typical workloads. Hashes: SQLITE_SOURCE_ID: 2022-11-16 12:10:08 89c459e766ea7e9165d0beeb124708b955a4950d0f4792f457465d71b158d318 SHA3-256 for sqlite3.c: ab8da6bc754642989e67d581f26683dc705b068cea671970f0a7d32cfacbad19 2022-09-29 (3.39.4) Fix the build on Windows so that it works with -DSQLITE_OMIT_AUTOINIT Fix a long-standing problem in the btree balancer that might, in rare cases, cause database corruption if the application uses an application-defined page cache. Enhance SQLITE_DBCONFIG_DEFENSIVE so that it disallows CREATE TRIGGER statements if one or more of the statements in the body of the trigger write into shadow tables. Fix a possible integer overflow in the size computation for a memory allocation in FTS3. Fix a misuse of the sqlite3_set_auxdata() interface in the ICU Extension. Hashes: SQLITE_SOURCE_ID: 2022-09-29 15:55:41 a29f9949895322123f7c38fbe94c649a9d6e6c9cd0c3b41c96d694552f26b309 SHA3-256 for sqlite3.c: f65082298127e2ddae6539beb94f5204b591df64ba2c7da83c7d0faffd6959d8 2022-09-05 (3.39.3) Use a statement journal on DML statement affecting two or more database rows if the statement makes use of a SQL functions that might abort. See forum thread 9b9e4716c0d7bbd1. Use a mutex to protect the PRAGMA temp_store_directory and PRAGMA data_store_directory statements, even though they are deprecated and documented as not being threadsafe. See forum post 719a11e1314d1c70. Other bug and warning fixes. See the timeline for details. Hashes: SQLITE_SOURCE_ID: 2022-09-05 11:02:23 4635f4a69c8c2a8df242b384a992aea71224e39a2ccab42d8c0b0602f1e826e8 SHA3-256 for sqlite3.c: 2fc273cf8032b601c9e06207efa0ae80eb73d5a1d283eb91096c815fa9640257 2022-07-21 (3.39.2) Fix a performance regression in the query planner associated with rearranging the order of FROM clause terms in the presences of a LEFT JOIN. Apply fixes for CVE-2022-35737, Chromium bugs 1343348 and 1345947, forum post 3607259d3c, and other minor problems discovered by internal testing. Hashes: SQLITE_SOURCE_ID: 2022-07-21 15:24:47 698edb77537b67c41adc68f9b892db56bcf9a55e00371a61420f3ddd668e6603 SHA3-256 for sqlite3.c: bffbaafa94706f0ed234f183af3eb46e6485e7e2c75983173ded76e0da805f11 2022-07-13 (3.39.1) Fix an incorrect result from a query that uses a view that contains a compound SELECT in which only one arm contains a RIGHT JOIN and where the view is not the first FROM clause term of the query that contains the view. forum post 174afeae5734d42d. Fix some harmless compiler warnings. Fix a long-standing problem with ALTER TABLE RENAME that can only arise if the sqlite3_limit(SQLITE_LIMIT_SQL_LENGTH) is set to a very small value. Fix a long-standing problem in FTS3 that can only arise when compiled with the SQLITE_ENABLE_FTS3_PARENTHESIS compile-time option. Fix the build so that is works when the SQLITE_DEBUG and SQLITE_OMIT_WINDOWFUNC compile-time options are both provided at the same time. Fix the initial-prefix optimization for the REGEXP extension so that it works correctly even if the prefix contains characters that require a 3-byte UTF8 encoding. Enhance the sqlite_stmt virtual table so that it buffers all of its output. Hashes: SQLITE_SOURCE_ID: 2022-07-13 19:41:41 7c16541a0efb3985578181171c9f2bb3fdc4bad6a2ec85c6e31ab96f3eff201f SHA3-256 for sqlite3.c: 6d13fcf1c31133da541d1eb8a83552d746f39b81a0657bd4077fed0221749511 2022-06-25 (3.39.0) Add (long overdue) support for RIGHT and FULL OUTER JOIN. Add new binary comparison operators IS NOT DISTINCT FROM and IS DISTINCT FROM that are equivalent to IS and IS NOT, respective, for compatibility with PostgreSQL and SQL standards. Add a new return code (value \"3\") from the sqlite3_vtab_distinct() interface that indicates a query that has both DISTINCT and ORDER BY clauses. Added the sqlite3_db_name() interface. The unix os interface resolves all symbolic links in database filenames to create a canonical name for the database before the file is opened. If the SQLITE_OPEN_NOFOLLOW flag is used with sqlite3_open_v2() or similar, the open will fail if any element of the path is a symbolic link. Defer materializing views until the materialization is actually needed, thus avoiding unnecessary work if the materialization turns out to never be used. The HAVING clause of a SELECT statement is now allowed on any aggregate query, even queries that do not have a GROUP BY clause. Many microoptimizations collectively reduce CPU cycles by about 2.3%. Hashes: SQLITE_SOURCE_ID: 2022-06-25 14:57:57 14e166f40dbfa6e055543f8301525f2ca2e96a02a57269818b9e69e162e98918 SHA3-256 for sqlite3.c: d9c439cacad5e4992d0d25989cfd27a4c4f59a3183c97873bc03f0ad1aa78b7a 2022-05-06 (3.38.5) Fix a blunder in the CLI of the 3.38.4 release. Hashes: SQLITE_SOURCE_ID: 2022-05-06 15:25:27 78d9c993d404cdfaa7fdd2973fa1052e3da9f66215cff9c5540ebe55c407d9fe SHA3-256 for sqlite3.c: b05ef42ed234009b4b3dfb36c5f5ccf6d728da80f25ee560291269cf6cfe635f 2022-05-04 (3.38.4) Fix a byte-code problem in the Bloom filter pull-down optimization added by release 3.38.0 in which an error in the byte code causes the byte code engine to enter an infinite loop when the pull-down optimization encounters a NULL key. Forum thread 2482b32700384a0f. Other minor patches. See the timeline for details. Hashes: SQLITE_SOURCE_ID: 2022-05-04 15:45:55 d402f49871152670a62f4f28cacb15d814f2c1644e9347ad7d258e562978e45e SHA3-256 for sqlite3.c: e6a50effb021858c200e885664611ed3c5e949413ff2dca452ac7ee336b9de1d 2022-04-27 (3.38.3) Fix a case of the query planner be overly aggressive with optimizing automatic-index and Bloom-filter construction, using inappropriate ON clause terms to restrict the size of the automatic-index or Bloom filter, and resulting in missing rows in the output. Forum thread 0d3200f4f3bcd3a3. Other minor patches. See the timeline for details. Hashes: SQLITE_SOURCE_ID: 2022-04-27 12:03:15 9547e2c38a1c6f751a77d4d796894dec4dc5d8f5d79b1cd39e1ffc50df7b3be4 SHA3-256 for sqlite3.c: d4d66feffad66ea82073fbb97ae9c84e3615887ebc5168226ccee28d82424517 2022-03-26 (3.38.2) Fix a user-discovered problem with the new Bloom filter optimization that might cause an incorrect answer when doing a LEFT JOIN with a WHERE clause constraint that says that one of the columns on the right table of the LEFT JOIN is NULL. See forum thread 031e262a89b6a9d2. Other minor patches. See the timeline for details. Hashes: SQLITE_SOURCE_ID: 2022-03-26 13:51:10 d33c709cc0af66bc5b6dc6216eba9f1f0b40960b9ae83694c986fbf4c1d6f08f SHA3-256 for sqlite3.c: 0fbac6b6999f894184899431fb77b9792324c61246b2a010d736694ccaa6d613 2022-03-12 (3.38.1) Fix problems with the new Bloom filter optimization that might cause some obscure queries to get an incorrect answer. Fix the localtime modifier of the date and time functions so that it preserves fractional seconds. Fix the sqlite_offset SQL function so that it works correctly even in corner cases such as when the argument is a virtual column or the column of a view. Fix row value IN operator constraints on virtual tables so that they work correctly even if the virtual table implementation relies on bytecode to filter rows that do not satisfy the constraint. Other minor fixes to assert() statements, test cases, and documentation. See the source code timeline for details. Hashes: SQLITE_SOURCE_ID: 2022-03-12 13:37:29 38c210fdd258658321c85ec9c01a072fda3ada94540e3239d29b34dc547a8cbc SHA3-256 for sqlite3.c: 262ba071e960a8a0a6ce39307ae30244a2b0dc9fe1c4c09d0e1070d4353cd92c 2022-02-22 (3.38.0) Added the -> and ->> operators for easier processing of JSON. The new operators are compatible with MySQL and PostgreSQL. The JSON functions are now built-ins. It is no longer necessary to use the -DSQLITE_ENABLE_JSON1 compile-time option to enable JSON support. JSON is on by default. Disable the JSON interface using the new -DSQLITE_OMIT_JSON compile-time option. Enhancements to date and time functions: Added the unixepoch() function. Added the auto modifier and the julianday modifier. Rename the printf() SQL function to format() for better compatibility. The original printf() name is retained as an alias for backwards compatibility. Added the sqlite3_error_offset() interface, which can sometimes help to localize an SQL error to a specific character in the input SQL text, so that applications can provide better error messages. Enhanced the interface to virtual tables as follows: Added the sqlite3_vtab_distinct() interface. Added the sqlite3_vtab_rhs_value() interface. Added new operator types SQLITE_INDEX_CONSTRAINT_LIMIT and SQLITE_INDEX_CONSTRAINT_OFFSET. Added the sqlite3_vtab_in() interface (and related) to enable a virtual table to process IN operator constraints all at once, rather than processing each value of the right-hand side of the IN operator separately. CLI enhancements: Columnar output modes are enhanced to correctly handle tabs and newlines embedded in text. Added options like \"--wrap N\", \"--wordwrap on\", and \"--quote\" to the columnar output modes. Added the .mode qbox alias. The .import command automatically disambiguates column names. Use the new sqlite3_error_offset() interface to provide better error messages. Query planner enhancements: Use a Bloom filter to speed up large analytic queries. Use a balanced merge tree to evaluate UNION or UNION ALL compound SELECT statements that have an ORDER BY clause. The ALTER TABLE statement is changed to silently ignores entries in the sqlite_schema table that do not parse when PRAGMA writable_schema=ON. Hashes: SQLITE_SOURCE_ID: 2022-02-22 18:58:40 40fa792d359f84c3b9e9d6623743e1a59826274e221df1bde8f47086968a1bab SHA3-256 for sqlite3.c: a69af0a88d59271a2dd3c846a3e93cbd29e7c499864f6c0462a3b4160bee1762 2022-01-06 (3.37.2) Fix a bug introduced in version 3.35.0 (2021-03-12) that can cause database corruption if a SAVEPOINT is rolled back while in PRAGMA temp_store=MEMORY mode, and other changes are made, and then the outer transaction commits. Check-in 73c2b50211d3ae26 Fix a long-standing problem with ON DELETE CASCADE and ON UPDATE CASCADE in which a cache of the bytecode used to implement the cascading change was not being reset following a local DDL change. Check-in 5232c9777fe4fb13. Other minor fixes that should not impact production builds. Hashes: SQLITE_SOURCE_ID: 2022-01-06 13:25:41 872ba256cbf61d9290b571c0e6d82a20c224ca3ad82971edc46b29818d5d17a0 SHA3-256 for sqlite3.c: 1bb01c382295cba85ec4685cedc52a7477cdae71cc37f1ad0f48719a17af1e1e 2021-12-30 (3.37.1) Fix a bug introduced by the UPSERT enhancements of version 3.35.0 that can cause incorrect byte-code to be generated for some obscure but valid SQL, possibly resulting in a NULL-pointer dereference. Fix an OOB read that can occur in FTS5 when reading corrupt database files. Improved robustness of the --safe option in the CLI. Other minor fixes to assert() statements and test cases. Hashes: SQLITE_SOURCE_ID: 2021-12-30 15:30:28 378629bf2ea546f73eee84063c5358439a12f7300e433f18c9e1bddd948dea62 SHA3-256 for sqlite3.c: 915afb3f29c2d217ea0c283326a9df7d505e6c73b40236f0b33ded91f812d174 2021-11-27 (3.37.0) STRICT tables provide a prescriptive style of data type management, for developers who prefer that kind of thing. When adding columns that contain a CHECK constraint or a generated column containing a NOT NULL constraint, the ALTER TABLE ADD COLUMN now checks new constraints against preexisting rows in the database and will only proceed if no constraints are violated. Added the PRAGMA table_list statement. CLI enhancements: Add the .connection command, allowing the CLI to keep multiple database connections open at the same time. Add the --safe command-line option that disables dot-commands and SQL statements that might cause side-effects that extend beyond the single database file named on the command-line. Performance improvements when reading SQL statements that span many lines. Added the sqlite3_autovacuum_pages() interface. The sqlite3_deserialize() does not and has never worked for the TEMP database. That limitation is now noted in the documentation. The query planner now omits ORDER BY clauses on subqueries and views if removing those clauses does not change the semantics of the query. The generate_series table-valued function extension is modified so that the first parameter (\"START\") is now required. This is done as a way to demonstrate how to write table-valued functions with required parameters. The legacy behavior is available using the -DZERO_ARGUMENT_GENERATE_SERIES compile-time option. Added new sqlite3_changes64() and sqlite3_total_changes64() interfaces. Added the SQLITE_OPEN_EXRESCODE flag option to sqlite3_open_v2(). Use less memory to hold the database schema. Hashes: SQLITE_SOURCE_ID: 2021-11-27 14:13:22 bd41822c7424d393a30e92ff6cb254d25c26769889c1499a18a0b9339f5d6c8a SHA3-256 for sqlite3.c: a202a950ab401cda052e81259e96d6e64ad91faaaaf5690d769f64c2ab962f27 2021-06-18 (3.36.0) Improvement to the EXPLAIN QUERY PLAN output to make it easier to understand. Byte-order marks at the start of a token are skipped as if they were whitespace. An error is raised on any attempt to access the rowid of a VIEW or subquery. Formerly, the rowid of a VIEW would be indeterminate and often would be NULL. The -DSQLITE_ALLOW_ROWID_IN_VIEW compile-time option is available to restore the legacy behavior for applications that need it. The sqlite3_deserialize() and sqlite3_serialize() interfaces are now enabled by default. The -DSQLITE_ENABLE_DESERIALIZE compile-time option is no longer required. Instead, there is a new -DSQLITE_OMIT_DESERIALIZE compile-time option to omit those interfaces. The \"memdb\" VFS now allows the same in-memory database to be shared among multiple database connections in the same process as long as the database name begins with \"/\". Back out the EXISTS-to-IN optimization (item 8b in the SQLite 3.35.0 change log) as it was found to slow down queries more often than speed them up. Improve the constant-propagation optimization so that it works on non-join queries. The REGEXP extension is now included in CLI builds. Hashes: SQLITE_SOURCE_ID: 2021-06-18 18:36:39 5c9a6c06871cb9fe42814af9c039eb6da5427a6ec28f187af7ebfb62eafa66e5 SHA3-256 for sqlite3.c: 2a8e87aaa414ac2d45ace8eb74e710935423607a8de0fafcb36bbde5b952d157 2021-04-19 (3.35.5) Fix defects in the new ALTER TABLE DROP COLUMN feature that could corrupt the database file. Fix an obscure query optimizer problem that might cause an incorrect query result. Hashes: SQLITE_SOURCE_ID: 2021-04-19 18:32:05 1b256d97b553a9611efca188a3d995a2fff712759044ba480f9a0c9e98fae886 SHA3-256 for sqlite3.c: e42291343e8f03940e57fffcf1631e7921013b94419c2f943e816d3edf4e1bbe 2021-04-02 (3.35.4) Fix a defect in the query planner optimization identified by item 8b above. Ticket de7db14784a08053. Fix a defect in the new RETURNING syntax. Ticket 132994c8b1063bfb. Fix the new RETURNING feature so that it raises an error if one of the terms in the RETURNING clause references a unknown table, instead of silently ignoring that error. Fix an assertion associated with aggregate function processing that was incorrectly triggered by the push-down optimization. Hashes: SQLITE_SOURCE_ID: 2021-04-02 15:20:15 5d4c65779dab868b285519b19e4cf9d451d50c6048f06f653aa701ec212df45e SHA3-256 for sqlite3.c: 528b8a26bf5ffd4c7b4647b5b799f86e8fb1a075f715b87a414e94fba3d09dbe 2021-03-26 (3.35.3) Enhance the OP_OpenDup opcode of the bytecode engine so that it works even if the cursor being duplicated itself came from OP_OpenDup. Fix for ticket bb8a9fd4a9b7fce5. This problem only came to light due to the recent MATERIALIZED hint enhancement. When materializing correlated common table expressions, do so separately for each use case, as that is required for correctness. This fixes a problem that was introduced by the MATERIALIZED hint enhancement. Fix a problem in the filename normalizer of the unix VFS. Fix the \"box\" output mode in the CLI so that it works with statements that returns one or more rows of zero columns (such as PRAGMA incremental_vacuum). Forum post afbbcb5b72. Improvements to error messages generated by faulty common table expressions. Forum post aa5a0431c99e. Fix some incorrect assert() statements. Fix to the SELECT statement syntax diagram so that the FROM clause syntax is shown correctly. Forum post 9ed02582fe. Fix the EBCDIC character classifier so that it understands newlines as whitespace. Forum post 58540ce22dcd. Improvements the xBestIndex method in the implementation of the (unsupported) wholenumber virtual table extension so that it does a better job of convincing the query planner to avoid trying to materialize a table with an infinite number of rows. Forum post b52a020ce4. Hashes: SQLITE_SOURCE_ID: 2021-03-26 12:12:52 4c5e6c200adc8afe0814936c67a971efc516d1bd739cb620235592f18f40be2a SHA3-256 for sqlite3.c: 91ca6c0a30ebfdba4420bb35f4fd9149d13e45fc853d86ad7527db363e282683 2021-03-17 (3.35.2) Fix a problem in the appendvfs.c extension that was introduced into version 3.35.0. Ensure that date/time functions with no arguments (which generate responses that depend on the current time) are treated as non-deterministic functions. Ticket 2c6c8689fb5f3d2f Fix a problem in the sqldiff utility program having to do with unusual whitespace characters in a virtual table definition. Limit the new UNION ALL optimization described by item 8c in the 3.35.0 release so that it does not try to make too many new subqueries. See forum thread 140a67d3d2 for details. Hashes: SQLITE_SOURCE_ID: 2021-03-17 19:07:21 ea80f3002f4120f5dcee76e8779dfdc88e1e096c5cdd06904c20fd26d50c3827 SHA3-256 for sqlite3.c: e8edc7b1512a2e050d548d0840bec6eef83cc297af1426c34c0ee8720f378a11 2021-03-15 (3.35.1) Fix a bug in the new DROP COLUMN feature when used on columns that are indexed and that are quoted in the index definition. Improve the built-in documentation for the .dump command in the CLI. Hashes: SQLITE_SOURCE_ID: 2021-03-15 16:53:57 aea12399bf1fdc76af43499d4624c3afa17c3e6c2459b71c195804bb98def66a SHA3-256 for sqlite3.c: fc79e27fd030226c07691b7d7c23aa81c8d46bc3bef5af39060e1507c82b0523 2021-03-12 (3.35.0) Added built-in SQL math functions(). (Requires the -DSQLITE_ENABLE_MATH_FUNCTIONS compile-time option.) Added support for ALTER TABLE DROP COLUMN. Generalize UPSERT: Allow multiple ON CONFLICT clauses that are evaluated in order, The final ON CONFLICT clause may omit the conflict target and yet still use DO UPDATE. Add support for the RETURNING clause on DELETE, INSERT, and UPDATE statements. Use less memory when running VACUUM on databases containing very large TEXT or BLOB values. It is no longer necessary to hold the entire TEXT or BLOB in memory all at once. Add support for the MATERIALIZED and NOT MATERIALIZED hints when specifying common table expressions. The default behavior was formerly NOT MATERIALIZED, but is now changed to MATERIALIZED for CTEs that are used more than once. The SQLITE_DBCONFIG_ENABLE_TRIGGER and SQLITE_DBCONFIG_ENABLE_VIEW settings are modified so that they only control triggers and views in the main database schema or in attached database schemas and not in the TEMP schema. TEMP triggers and views are always allowed. Query planner/optimizer improvements: Enhancements to the min/max optimization so that it works better with the IN operator and the OP_SeekScan optimization of the previous release. Attempt to process EXISTS operators in the WHERE clause as if they were IN operators, in cases where this is a valid transformation and seems likely to improve performance. Allow UNION ALL sub-queries to be flattened even if the parent query is a join. Use an index, if appropriate, on IS NOT NULL expressions in the WHERE clause, even if STAT4 is disabled. Expressions of the form \"x IS NULL\" or \"x IS NOT NULL\" might be converted to simply FALSE or TRUE, if \"x\" is a column that has a \"NOT NULL\" constraint and is not involved in an outer join. Avoid checking foreign key constraints on an UPDATE statement if the UPDATE does not modify any columns associated with the foreign key. Allow WHERE terms to be pushed down into sub-queries that contain window functions, as long as the WHERE term is made up of entirely of constants and copies of expressions found in the PARTITION BY clauses of all window functions in the sub-query. CLI enhancements: Enhance the \".stats\" command to accept new arguments \"stmt\" and \"vmstep\", causing prepare statement statistics and only the virtual-machine step count to be shown, respectively. Add the \".filectrl data_version\" command. Enhance the \".once\" and \".output\" commands so that if the destination argument begins with \"|\" (indicating that output is redirected into a pipe) then the argument does not need to be quoted. Bug fixes: Fix a potential NULL pointer dereference when processing a syntactically incorrect SELECT statement with a correlated WHERE clause and a \"HAVING 0\" clause. (Also fixed in the 3.34.1 patch release.) Fix a bug in the IN-operator optimization of version 3.33.0 that can cause an incorrect answer. Fix incorrect answers from the LIKE operator if the pattern ends with \"%\" and there is an \"ESCAPE '_'\" clause. Hashes: SQLITE_SOURCE_ID: 2021-03-12 15:10:09 acd63062eb06748bfe9e4886639e4f2b54ea6a496a83f10716abbaba4115500b SHA3-256 for sqlite3.c: 73a740d881735bef9de7f7bce8c9e6b9e57fe3e77fa7d76a6e8fc5c262fbaedf 2021-01-20 (3.34.1) Fix a potential use-after-free bug when processing a a subquery with both a correlated WHERE clause and a \"HAVING 0\" clause and where the parent query is an aggregate. Fix documentation typos Fix minor problems in extensions. Hashes: SQLITE_SOURCE_ID: 2021-01-20 14:10:07 10e20c0b43500cfb9bbc0eaa061c57514f715d87238f4d835880cd846b9ebd1f SHA3-256 for sqlite3.c: 799a7be90651fc7296113b641a70b028c142d767b25af1d0a78f93dcf1a2bf20 2020-12-01 (3.34.0) Added the sqlite3_txn_state() interface for reporting on the current transaction state of the database connection. Enhance recursive common table expressions to support two or more recursive terms as is done by SQL Server, since this helps make queries against graphs easier to write and faster to execute. Improved error messages on CHECK constraint failures. CLI enhancements: The .read dot-command now accepts a pipeline in addition to a filename. Added options --data-only and --nosys to the .dump dot-command. Added the --nosys option to the .schema dot-command. Table name quoting works correctly for the .import dot-command. The generate_series(START,END,STEP) table-valued function extension is now built into the CLI. The .databases dot-command now shows the status of each database file as determined by sqlite3_db_readonly() and sqlite3_txn_state(). Added the --tabs command-line option that sets .mode tabs. The --init option reports an error if the file named as its argument cannot be opened. The --init option also now honors the --bail option. Query planner improvements: Improved estimates for the cost of running a DISTINCT operator. When doing an UPDATE or DELETE using a multi-column index where only a few of the earlier columns of the index are useful for the index lookup, postpone doing the main table seek until after all WHERE clause constraints have been evaluated, in case those constraints can be covered by unused later terms of the index, thus avoiding unnecessary main table seeks. The new OP_SeekScan opcode is used to improve performance of multi-column index look-ups when later columns are constrained by an IN operator. The BEGIN IMMEDIATE and BEGIN EXCLUSIVE commands now work even if one or more attached database files are read-only. Enhanced FTS5 to support trigram indexes. Improved performance of WAL mode locking primitives in cases where there are hundreds of connections all accessing the same database file at once. Enhanced the carray() table-valued function to include a single-argument form that is bound using the auxiliary sqlite3_carray_bind() interface. The substr() SQL function can now also be called \"substring()\" for compatibility with SQL Server. The syntax diagrams are now implemented as Pikchr scripts and rendered as SVG for improved legibility and ease of maintenance. Hashes: SQLITE_SOURCE_ID: 2020-12-01 16:14:00 a26b6597e3ae272231b96f9982c3bcc17ddec2f2b6eb4df06a224b91089fed5b SHA3-256 for sqlite3.c: fbd895b0655a337b2cd657675f314188a4e9fe614444cc63dfeb3f066f674514 2020-08-14 (3.33.0) Support for UPDATE FROM following the PostgreSQL syntax. Increase the maximum size of database files to 281 TB. Extended the PRAGMA integrity_check statement so that it can optionally be limited to verifying just a single table and its indexes, rather than the entire database file. Added the decimal extension for doing arbitrary-precision decimal arithmetic. Enhancements to the ieee754 extension for working with IEEE 754 binary64 numbers. CLI enhancements: Added four new output modes: \"box\", \"json\", \"markdown\", and \"table\". The \"column\" output mode automatically expands columns to contain the longest output row and automatically turns \".header\" on if it has not been previously set. The \"quote\" output mode honors \".separator\" The decimal extension and the ieee754 extension are built-in to the CLI Query planner improvements: Add the ability to find a full-index-scan query plan for queries using INDEXED BY which previously would fail with \"no query solution\". Do a better job of detecting missing, incomplete, and/or dodgy sqlite_stat1 data and generates good query plans in spite of the misinformation. Improved performance of queries like \"SELECT min(x) FROM t WHERE y IN (?,?,?)\" assuming an index on t(x,y). In WAL mode, if a writer crashes and leaves the shm file in an inconsistent state, subsequent transactions are now able to recover the shm file even if there are active read transactions. Before this enhancement, shm file recovery that scenario would result in an SQLITE_PROTOCOL error. Hashes: SQLITE_SOURCE_ID: 2020-08-14 13:23:32 fca8dc8b578f215a969cd899336378966156154710873e68b3d9ac5881b0ff3f SHA3-256 for sqlite3.c: d00b7fffa6d33af2303430eaf394321da2960604d25a4471c7af566344f2abf9 2020-06-18 (3.32.3) Various minor bug fixes including fixes for tickets 8f157e8010b22af0, 9fb26d37cefaba40, e367f31901ea8700, b706351ce2ecf59a, 7c6d876f84e6e7e2, and c8d3b9f0a750a529. Hashes: SQLITE_SOURCE_ID: 2020-06-18 14:00:33 7ebdfa80be8e8e73324b8d66b3460222eb74c7e9dfd655b48d6ca7e1933cc8fd SHA3-256 for sqlite3.c: b62b77ee1c561a69a71bb557694aaa5141f1714c1ff6cc1ba8aa8733c92d4f52 2020-06-04 (3.32.2) Fix a long-standing bug in the byte-code engine that can cause a COMMIT command report as success when in fact it failed to commit. Ticket 810dc8038872e212 Hashes: SQLITE_SOURCE_ID: 2020-06-04 12:58:43 ec02243ea6ce33b090870ae55ab8aa2534b54d216d45c4aa2fdbb00e86861e8c SHA3-256 for sqlite3.c: f17a2a57f7eebc72d405f3b640b4a49bcd02364a9c36e04feeb145eccafa3f8d 2020-05-25 (3.32.1) Fix two long-standing bugs that allow malicious SQL statements to crash the process that is running SQLite. These bugs were announced by a third-party approximately 24 hours after the 3.32.0 release but are not specific to the 3.32.0 release. Other minor compiler-warning fixes and whatnot. Hashes: SQLITE_SOURCE_ID: 2020-05-25 16:19:56 0c1fcf4711a2e66c813aed38cf41cd3e2123ee8eb6db98118086764c4ba83350 SHA3-256 for sqlite3.c: f695ae21abf045e4ee77980a67ab2c6e03275009e593ee860a2eabf840482372 2020-05-22 (3.32.0) Added support for approximate ANALYZE using the PRAGMA analysis_limit command. Added the bytecode virtual table. Add the checksum VFS shim to the set of run-time loadable extensions included in the source tree. Added the iif() SQL function. INSERT and UPDATE statements now always apply column affinity before computing CHECK constraints. This bug fix could, in theory, cause problems for legacy databases with unorthodox CHECK constraints the require the input type for an INSERT is different from the declared column type. See ticket 86ba67afafded936 for more information. Added the sqlite3_create_filename(), sqlite3_free_filename(), and sqlite3_database_file_object() interfaces to better support of VFS shim implementations. Increase the default upper bound on the number of parameters from 999 to 32766. Added code for the UINT collating sequence as an optional loadable extension. Enhancements to the CLI: Add options to the .import command: --csv, --ascii, --skip The .dump command now accepts multiple LIKE-pattern arguments and outputs the union of all matching tables. Add the .oom command in debugging builds Add the --bom option to the .excel, .output, and .once commands. Enhance the .filectrl command to support the --schema option. The UINT collating sequence extension is automatically loaded The ESCAPE clause of a LIKE operator now overrides wildcard characters, so that the behavior matches what PostgreSQL does. SQLITE_SOURCE_ID: 2020-05-22 17:46:16 5998789c9c744bce92e4cff7636bba800a75574243d6977e1fc8281e360f8d5a SHA3-256 for sqlite3.c: 33ed868b21b62ce1d0352ed88bdbd9880a42f29046497a222df6459fc32a356f 2020-01-27 (3.31.1) Revert the data layout for an internal-use-only SQLite data structure. Applications that use SQLite should never reference internal SQLite data structures, but some do anyhow, and a change to one such data structure in 3.30.0 broke a popular and widely-deployed application. Reverting that change in SQLite, at least temporarily, gives developers of misbehaving applications time to fix their code. Fix a typos in the sqlite3ext.h header file that prevented the sqlite3_stmt_isexplain() and sqlite3_value_frombind() interfaces from being called from run-time loadable extensions. Hashes: SQLITE_SOURCE_ID: 2020-01-27 19:55:54 3bfa9cc97da10598521b342961df8f5f68c7388fa117345eeb516eaa837bb4d6 SHA3-256 for sqlite3.c: de465c64f09529429a38cbdf637acce4dfda6897f93e3db3594009e0fed56d27 2020-01-22 (3.31.0) Add support for generated columns. Add the sqlite3_hard_heap_limit64() interface and the corresponding PRAGMA hard_heap_limit command. Enhance the function_list pragma to show the number of arguments on each function, the type of function (scalar, aggregate, window), and the function property flags SQLITE_DETERMINISTIC, SQLITE_DIRECTONLY, SQLITE_INNOCUOUS, and/or SQLITE_SUBTYPE. Add the aggregated mode feature to the DBSTAT virtual table. Add the SQLITE_OPEN_NOFOLLOW option to sqlite3_open_v2() that prevents SQLite from opening symbolic links. Added the \"#-N\" array notation for JSON function path arguments. Added the SQLITE_DBCONFIG_TRUSTED_SCHEMA connection setting which is also controllable via the new trusted_schema pragma and at compile-time using the -DSQLITE_TRUSTED_SCHEMA compile-time option. Added APIs sqlite3_filename_database(), sqlite3_filename_journal(), and sqlite3_filename_wal() which are useful for specialized extensions. Add the sqlite3_uri_key() interface. Upgraded the sqlite3_uri_parameter() function so that it works with the rollback journal or WAL filename in addition to the database filename. Provide the ability to tag application-defined SQL functions with new properties SQLITE_INNOCUOUS or SQLITE_DIRECTONLY. Add new verbs to sqlite3_vtab_config() so that the xConnect method of virtual tables can declare the virtual table as SQLITE_VTAB_INNOCUOUS or SQLITE_VTAB_DIRECTONLY. Faster response to sqlite3_interrupt(). Added the uuid.c extension module implementing functions for processing RFC-4122 UUIDs. The lookaside memory allocator is enhanced to support two separate memory pools with different sized allocations in each pool. This allows more memory allocations to be covered by lookaside while at the same time reducing the heap memory usage to 48KB per connection, down from 120KB. The legacy_file_format pragma is deactivated. It is now a no-op. In its place, the SQLITE_DBCONFIG_LEGACY_FILE_FORMAT option to sqlite3_db_config() is provided. The legacy_file_format pragma is deactivated because (1) it is rarely useful and (2) it is incompatible with VACUUM in schemas that have tables with both generated columns and descending indexes. Ticket 6484e6ce678fffab Hashes: SQLITE_SOURCE_ID: 2020-01-22 18:38:59 f6affdd41608946fcfcea914ece149038a8b25a62bbe719ed2561c649b86d824 SHA3-256 for sqlite3.c: a5fca0b9f8cbf80ac89b97193378c719d4af4b7d647729d8df9c0c0fca7b1388 2019-10-10 (3.30.1) Fix a bug in the query flattener that might cause a segfault for nested queries that use the new FILTER clause on aggregate functions. Ticket 1079ad19993d13fa Cherrypick fixes for other obscure problems found since the 3.30.0 release Hashes: SQLITE_SOURCE_ID: 2019-10-10 20:19:45 18db032d058f1436ce3dea84081f4ee5a0f2259ad97301d43c426bc7f3df1b0b SHA3-256 for sqlite3.c: f96fafe4c110ed7d77fc70a7d690e5edd1e64fefb84b3b5969a722d885de1f2d 2019-10-04 (3.30.0) Add support for the FILTER clause on aggregate functions. Add support for the NULLS FIRST and NULLS LAST syntax in ORDER BY clauses. The index_info and index_xinfo pragmas are enhanced to provide information about the on-disk representation of WITHOUT ROWID tables. Add the sqlite3_drop_modules() interface, allowing applications to disable automatically loaded virtual tables that they do not need. Improvements to the .recover dot-command in the CLI so that it recovers more content from corrupt database files. Enhance the RBU extension to support indexes on expressions. Change the schema parser so that it will error out if any of the type, name, and tbl_name columns of the sqlite_master table have been corrupted and the database connection is not in writable_schema mode. The PRAGMA function_list, PRAGMA module_list, and PRAGMA pragma_list commands are now enabled in all builds by default. Disable them using -DSQLITE_OMIT_INTROSPECTION_PRAGMAS. Add the SQLITE_DBCONFIG_ENABLE_VIEW option for sqlite3_db_config(). Added the TCL Interface config method in order to be able to disable SQLITE_DBCONFIG_ENABLE_VIEW as well as control other sqlite3_db_config() options from TCL. Added the SQLITE_DIRECTONLY flag for application-defined SQL functions to prevent those functions from being used inside triggers and views. The legacy SQLITE_ENABLE_STAT3 compile-time option is now a no-op. Hashes: SQLITE_SOURCE_ID: 2019-10-04 15:03:17 c20a35336432025445f9f7e289d0cc3e4003fb17f45a4ce74c6269c407c6e09f SHA3-256 for sqlite3.c: f04393dd47205a4ee2b98ff737dc51a3fdbcc14c055b88d58f5b27d0672158f5 2019-07-10 (3.29.0) Added the SQLITE_DBCONFIG_DQS_DML and SQLITE_DBCONFIG_DQS_DDL actions to sqlite3_db_config() for activating and deactivating the double-quoted string literal misfeature. Both default to \"on\" for legacy compatibility, but developers are encouraged to turn them \"off\", perhaps using the -DSQLITE_DQS=0 compile-time option. -DSQLITE_DQS=0 is now a recommended compile-time option. Improvements to the query planner: Improved optimization of AND and OR operators when one or the other operand is a constant. Enhancements to the LIKE optimization for cases when the left-hand side column has numeric affinity. Added the \"sqlite_dbdata\" virtual table for extracting raw low-level content from an SQLite database, even a database that is corrupt. Improvements to rounding behavior, so that the results of rounding binary numbers using the round() function are closer to what people who are used to thinking in decimal actually expect. Enhancements to the CLI: Add the \".recover\" command which tries to recover as much content as possible from a corrupt database file. Add the \".filectrl\" command useful for testing. Add the long-standing \".testctrl\" command to the \".help\" menu. Added the \".dbconfig\" command Hashes: SQLITE_SOURCE_ID: 2019-07-10 17:32:03 fc82b73eaac8b36950e527f12c4b5dc1e147e6f4ad2217ae43ad82882a88bfa6 SHA3-256 for sqlite3.c: d9a5daf7697a827f4b2638276ce639fa04e8e8bb5fd3a6b683cfad10f1c81b12 2019-04-16 (3.28.0) Enhanced window functions: Add support the EXCLUDE clause. Add support for window chaining. Add support for GROUPS frames. Add support for \" PRECEDING\" and \" FOLLOWING\" boundaries in RANGE frames. Added the new sqlite3_stmt_isexplain(S) interface for determining whether or not a prepared statement is an EXPLAIN. Enhanced VACUUM INTO so that it works for read-only databases. New query optimizations: Enable the LIKE optimization for cases when the ESCAPE keyword is present and PRAGMA case_sensitive_like is on. In queries that are driven by a partial index, avoid unnecessary tests of the constraint named in the WHERE clause of the partial index, since we know that constraint must always be true. Enhancements to the TCL Interface: Added the -returntype option to the function method. Added the new bind_fallback method. Enhancements to the CLI: Added support for bound parameters and the .parameter command. Fix the readfile() function so that it returns an empty BLOB rather than throwing an out-of-memory error when reading an empty file. Fix the writefile() function so that when it creates new directories along the path of a new file, it gives them umask permissions rather than the same permissions as the file. Change --update option in the .archive command so that it skips files that are already in the archive and are unchanged. Add the new --insert option that works like --update used to work. Added the fossildelta.c extension that can create, apply, and deconstruct the Fossil DVCS file delta format that is used by the RBU extension. Added the SQLITE_DBCONFIG_WRITABLE_SCHEMA verb for the sqlite3_db_config() interface, that does the same work as PRAGMA writable_schema without using the SQL parser. Added the sqlite3_value_frombind() API for determining if the argument to an SQL function is from a bound parameter. Security and compatibilities enhancements to fts3_tokenizer(): The fts3_tokenizer() function always returns NULL unless either the legacy application-defined FTS3 tokenizers interface are enabled using the sqlite3_db_config(SQLITE_DBCONFIG_ENABLE_FTS3_TOKENIZER) setting, or unless the first argument to fts3_tokenizer() is a bound parameter. The two-argument version of fts3_tokenizer() accepts a pointer to the tokenizer method object even without the sqlite3_db_config(SQLITE_DBCONFIG_ENABLE_FTS3_TOKENIZER) setting if the second argument is a bound parameter Improved robustness against corrupt database files. Miscellaneous performance enhancements Established a Git mirror of the offical SQLite source tree. The canonical sources for SQLite are maintained using the Fossil DVCS at https://sqlite.org/src. The Git mirror can be seen at https://github.com/sqlite/sqlite. Hashes: SQLITE_SOURCE_ID: 2019-04-16 19:49:53 884b4b7e502b4e991677b53971277adfaf0a04a284f8e483e2553d0f83156b50 SHA3-256 for sqlite3.c: 411efca996b65448d9798eb203d6ebe9627b7161a646f5d00911e2902a57b2e9 2019-02-25 (3.27.2) Fix a bug in the IN operator that was introduced by an attempted optimization in version 3.27.0. Ticket df46dfb631f75694 Fix a bug causing a crash when a window function is misused. Ticket 4feb3159c6bc3f7e33959. Fix various documentation typos Hashes: SQLITE_SOURCE_ID: bd49a8271d650fa89e446b42e513b595a717b9212c91dd384aab871fc1d0f6d7 SHA3-256 for sqlite3.c: 1dbae33bff261f979d0042338f72c9e734b11a80720fb32498bae9150cc576e7 2019-02-08 (3.27.1) Fix a bug in the query optimizer: an adverse interaction between the OR optimization and the optimization that tries to use values read directly from an expression index instead of recomputing the expression. Ticket 4e8e4857d32d401f Hashes: SQLITE_SOURCE_ID: 2019-02-08 13:17:39 0eca3dd3d38b31c92b49ca2d311128b74584714d9e7de895b1a6286ef959a1dd SHA3-256 for sqlite3.c: 11c14992660d5ac713ea8bea48dc5e6123f26bc8d3075fe5585d1a217d090233 2019-02-07 (3.27.0) Added the VACUUM INTO command Issue an SQLITE_WARNING message on the error log if a double-quoted string literal is used. The sqlite3_normalized_sql() interface works on any prepared statement created using sqlite3_prepare_v2() or sqlite3_prepare_v3(). It is no longer necessary to use sqlite3_prepare_v3() with SQLITE_PREPARE_NORMALIZE in order to use sqlite3_normalized_sql(). Added the remove_diacritics=2 option to FTS3 and FTS5. Added the SQLITE_PREPARE_NO_VTAB option to sqlite3_prepare_v3(). Use that option to prevent circular references to shadow tables from causing resource leaks. Enhancements to the sqlite3_deserialize() interface: Add the SQLITE_FCNTL_SIZE_LIMIT file-control for setting an upper bound on the size of the in-memory database created by sqlite3_deserialize. The default upper bound is 1GiB, or whatever alternative value is specified by sqlite3_config(SQLITE_CONFIG_MEMDB_MAXSIZE) and/or SQLITE_MEMDB_DEFAULT_MAXSIZE. Honor the SQLITE_DESERIALIZE_READONLY flag, which was previously described in the documentation, but was previously a no-op. Enhance the \"deserialize\" command of the TCL Interface to give it new \"--maxsize N\" and \"--readonly BOOLEAN\" options. Enhancements to the CLI, mostly to support testing and debugging of the SQLite library itself: Add support for \".open --hexdb\". The \"dbtotxt\" utility program used to generate the text for the \"hexdb\" is added to the source tree. Add support for the \"--maxsize N\" option on \".open --deserialize\". Add the \"--memtrace\" command-line option, to show all memory allocations and deallocations. Add the \".eqp trace\" option on builds with SQLITE_DEBUG, to enable bytecode program listing with indentation and PRAGMA vdbe_trace all in one step. Add the \".progress\" command for accessing the sqlite3_progress_handler() interface. Add the \"--async\" option to the \".backup\" command. Add options \"--expanded\", \"--normalized\", \"--plain\", \"--profile\", \"--row\", \"--stmt\", and \"--close\" to the \".trace\" command. Increased robustness against malicious SQL that is run against a maliciously corrupted database. Bug fixes: Do not use a partial index to do a table scan on an IN operator. Ticket 1d958d90596593a774. Fix the query flattener so that it works on queries that contain subqueries that use window functions. Ticket 709fcd17810f65f717 Ensure that ALTER TABLE modifies table and column names embedded in WITH clauses that are part of views and triggers. Fix a parser bug that prevented the use of parentheses around table-valued functions. Fix a problem with the OR optimization on indexes on expressions. Ticket d96eba87698a428c1d. Fix a problem with the LEFT JOIN strength reduction optimization in which the optimization was being applied inappropriately due to an IS NOT NULL operator. Ticket 5948e09b8c415bc45d. Fix the REPLACE command so that it is no longer able to sneak a NULL value into a NOT NULL column even if the NOT NULL column has a default value of NULL. Ticket e6f1f2e34dceeb1ed6 Fix a problem with the use of window functions used within correlated subqueries. Ticket d0866b26f83e9c55e3 Fix the ALTER TABLE RENAME COLUMN command so that it works for tables that have redundant UNIQUE constraints. Ticket bc8d94f0fbd633fd9a Fix a bug that caused zeroblob values to be truncated when inserted into a table that uses an expression index. Ticket bb4bdb9f7f654b0bb9 Hashes: SQLITE_SOURCE_ID: \"2019-02-07 17:02:52 97744701c3bd414e6c9d7182639d8c2ce7cf124c4fce625071ae65658ac61713 \" SHA3-256 for sqlite3.c: ca011a10ee8515b33e5643444b98ee3d74dc45d3ac766c3700320def52bc6aba 2018-12-01 (3.26.0) Optimization: When doing an UPDATE on a table with indexes on expressions, do not update the expression indexes if they do not refer to any of the columns of the table being updated. Allow the xBestIndex() method of virtual table implementations to return SQLITE_CONSTRAINT to indicate that the proposed query plan is unusable and should not be given further consideration. Added the SQLITE_DBCONFIG_DEFENSIVE option which disables the ability to create corrupt database files using ordinary SQL. Added support for read-only shadow tables when the SQLITE_DBCONFIG_DEFENSIVE option is enabled. Added the PRAGMA legacy_alter_table command, which if enabled causes the ALTER TABLE command to behave like older version of SQLite (prior to version 3.25.0) for compatibility. Added PRAGMA table_xinfo that works just like PRAGMA table_info except that it also shows hidden columns in virtual tables. Added the explain virtual table as a run-time loadable extension. Add a limit counter to the query planner to prevent excessive sqlite3_prepare() times for certain pathological SQL inputs. Added support for the sqlite3_normalized_sql() interface, when compiling with SQLITE_ENABLE_NORMALIZE. Enhanced triggers so that they can use table-valued functions that exist in schemas other than the schema where the trigger is defined. Enhancements to the CLI: Improvements to the \".help\" command. The SQLITE_HISTORY environment variable, if it exists, specifies the name of the command-line editing history file The --deserialize option associated with opening a new database cause the database file to be read into memory and accessed using the sqlite3_deserialize() API. This simplifies running tests on a database without modifying the file on disk. Enhancements to the geopoly extension: Always stores polygons using the binary format, which is faster and uses less space. Added the geopoly_regular() function. Added the geopoly_ccw() function. Enhancements to the session extension: Added the SQLITE_CHANGESETAPPLY_INVERT flag Added the sqlite3changeset_start_v2() interface and the SQLITE_CHANGESETSTART_INVERT flag. Added the changesetfuzz.c test-case generator utility. Hashes: SQLITE_SOURCE_ID: \"2018-12-01 12:34:55 bf8c1b2b7a5960c282e543b9c293686dccff272512d08865f4600fb58238b4f9\" SHA3-256 for sqlite3.c: 72c08830da9b5d1cb397c612c0e870d7f5eb41a323b41aa3d8aa5ae9ccedb2c4 2018-11-05 (3.25.3) Disallow the use of window functions in the recursive part of a CTE. Ticket e8275b415a2f03bee Fix the behavior of typeof() and length() on virtual tables. Ticket 69d642332d25aa3b7315a6d385 Strengthen defenses against deliberately corrupted database files. Fix a problem in the query planner that results when a row-value expression is used with a PRIMARY KEY with redundant columns. Ticket 1a84668dcfdebaf12415d Fix the query planner so that it works correctly for IS NOT NULL operators in the ON clause of a LEFT JOIN with the SQLITE_ENABLE_STAT4 compile-time option. 65eb38f6e46de8c75e188a17ec Hashes: SQLITE_SOURCE_ID: \"2018-11-05 20:37:38 89e099fbe5e13c33e683bef07361231ca525b88f7907be7092058007b75036f2\" SHA3-256 for sqlite3.c: 45586e4df74de3a43f3a1f8c7a78c3c3f02edce01af7d10cafe68bb94476a5c5 2018-09-25 (3.25.2) Add the PRAGMA legacy_alter_table=ON command that causes the \"ALTER TABLE RENAME\" command to behave as it did in SQLite versions 3.24.0 and earlier: references to the renamed table inside the bodies of triggers and views are not updated. This new pragma provides a compatibility work around for older programs that expected the older, wonky behavior of ALTER TABLE RENAME. Fix a problem with the new window functions implementation that caused a malfunction when complicated expressions involving window functions were used inside of a view. Fixes for various other compiler warnings and minor problems associated with obscure configurations. Hashes: SQLITE_SOURCE_ID: \"2018-09-25 19:08:10 fb90e7189ae6d62e77ba3a308ca5d683f90bbe633cf681865365b8e92792d1c7\" SHA3-256 for sqlite3.c: 34c23ff91631ae10354f8c9d62fd7d65732b3d7f3acfd0bbae31ff4a62fe28af 2018-09-18 (3.25.1) Extra sanity checking added to ALTER TABLE in the 3.25.0 release sometimes raises a false-positive when the table being modified has a trigger that updates a virtual table. The false-positive caused the ALTER TABLE to rollback, thus leaving the schema unchanged. Ticket b41031ea2b537237. The fix in the 3.25.0 release for the endless-loop in the byte-code associated with the ORDER BY LIMIT optimization did not work for some queries involving window functions. An additional correction is required. Ticket 510cde277783b5fb Hashes: SQLITE_SOURCE_ID: \"2018-09-18 20:20:44 2ac9003de44da7dafa3fbb1915ac5725a9275c86bf2f3b7aa19321bf1460b386\" SHA3-256 for sqlite3.c: 1b2302e7a54cc99c84ff699a299f61f069a28e1ed090b89e4430ca80ae2aab06 2018-09-15 (3.25.0) Add support for window functions Enhancements the ALTER TABLE command: Add support for renaming columns within a table using ALTER TABLE table RENAME COLUMN oldname TO newname. Fix table rename feature so that it also updates references to the renamed table in triggers and views. Query optimizer improvements: Avoid unnecessary loads of columns in an aggregate query that are not within an aggregate function and that are not part of the GROUP BY clause. The IN-early-out optimization: When doing a look-up on a multi-column index and an IN operator is used on a column other than the left-most column, then if no rows match against the first IN value, check to make sure there exist rows that match the columns to the right before continuing with the next IN value. Use the transitive property to try to propagate constant values within the WHERE clause. For example, convert \"a=99 AND b=a\" into \"a=99 AND b=99\". Use a separate mutex on every inode in the unix VFS, rather than a single mutex shared among them all, for slightly better concurrency in multi-threaded environments. Enhance the PRAGMA integrity_check command for improved detection of problems on the page freelist. Output infinity as 1e999 in the \".dump\" command of the command-line shell. Added the SQLITE_FCNTL_DATA_VERSION file-control. Added the Geopoly module Bug fixes: The ORDER BY LIMIT optimization might have caused an infinite loop in the byte code of the prepared statement under very obscure circumstances, due to a confluence of minor defects in the query optimizer. Fix for ticket 9936b2fa443fec03ff25 On an UPSERT when the order of constraint checks is rearranged, ensure that the affinity transformations on the inserted content occur before any of the constraint checks. Fix for ticket 79cad5e4b2e219dd197242e9e. Avoid using a prepared statement for \".stats on\" command of the CLI after it has been closed by the \".eqp full\" logicc. Fix for ticket 7be932dfa60a8a6b3b26bcf76. The LIKE optimization was generating incorrect byte-code and hence getting the wrong answer if the left-hand operand has numeric affinity and the right-hand-side pattern is '/%' or if the pattern begins with the ESCAPE character. Fix for ticket c94369cae9b561b1f996d0054b Hashes: SQLITE_SOURCE_ID: \"2018-09-15 04:01:47 b63af6c3bd33152742648d5d2e8dc5d5fcbcdd27df409272b6aea00a6f761760\" SHA3-256 for sqlite3.c: 989e3ff37f2b5eea8e42205f808ccf0ba86c6ea6aa928ad2c011f33a108ac45d 2018-06-04 (3.24.0) Add support for PostgreSQL-style UPSERT. Add support for auxiliary columns in r-tree tables. Add C-language APIs for discovering SQL keywords used by SQLite: sqlite3_keyword_count(), sqlite3_keyword_name(), and sqlite3_keyword_check(). Add C-language APIs for dynamic strings based on the sqlite3_str object. Enhance ALTER TABLE so that it recognizes \"true\" and \"false\" as valid arguments to DEFAULT. Add the sorter-reference optimization as a compile-time option. Only available if compiled with SQLITE_ENABLE_SORTER_REFERENCES. Improve the format of the EXPLAIN QUERY PLAN raw output, so that it gives better information about the query plan and about the relationships between the various components of the plan. Added the SQLITE_DBCONFIG_RESET_DATABASE option to the sqlite3_db_config() API. CLI Enhancements: Automatically intercepts the raw EXPLAIN QUERY PLAN output and reformats it into an ASCII-art graph. Lines that begin with \"#\" and that are not in the middle of an SQL statement are interpreted as comments. Added the --append option to the \".backup\" command. Added the \".dbconfig\" command. Performance: UPDATE avoids unnecessary low-level disk writes when the contents of the database file do not actually change. For example, \"UPDATE t1 SET x=25 WHERE y=?\" generates no extra disk I/O if the value in column x is already 25. Similarly, when doing UPDATE on records that span multiple pages, only the subset of pages that actually change are written to disk. This is a low-level performance optimization only and does not affect the behavior of TRIGGERs or other higher level SQL structures. Queries that use ORDER BY and LIMIT now try to avoid computing rows that cannot possibly come in under the LIMIT. This can greatly improve performance of ORDER BY LIMIT queries, especially when the LIMIT is small relative to the number of unrestricted output rows. The OR optimization is allowed to proceed even if the OR expression has also been converted into an IN expression. Uses of the OR optimization are now also more clearly shown in the EXPLAIN QUERY PLAN output. The query planner is more aggressive about using automatic indexes for views and subqueries for which it is not possible to create a persistent index. Make use of the one-pass UPDATE and DELETE query plans in the R-Tree extension where appropriate. Performance improvements in the LEMON-generated parser. Bug fixes: For the right-hand table of a LEFT JOIN, compute the values of expressions directly rather than loading precomputed values out of an expression index as the expression index might not contain the correct value. Ticket 7fa8049685b50b5aeb0c2 Do not attempt to use terms from the WHERE clause to enable indexed lookup of the right-hand table of a LEFT JOIN. Ticket 4ba5abf65c5b0f9a96a7a Fix a memory leak that can occur following a failure to open error in the CSV virtual table Fix a long-standing problem wherein a corrupt schema on the sqlite_sequence table used by AUTOINCREMENT can lead to a crash. Ticket d8dc2b3a58cd5dc2918a1 Fix the json_each() function so that it returns valid results on its \"fullkey\" column when the input is a simple value rather than an array or object. Hashes: SQLITE_SOURCE_ID: \"2018-06-04 19:24:41 c7ee0833225bfd8c5ec2f9bf62b97c4e04d03bd9566366d5221ac8fb199a87ca\" SHA3-256 for sqlite3.c: 0d384704e1c66026228336d1e91771d295bf688c9c44c7a44f25a4c16c26ab3c 2018-04-10 (3.23.1) Fix two problems in the new LEFT JOIN strength reduction optimization. Tickets 1e39b966ae9ee739 and fac496b61722daf2. Fix misbehavior of the FTS5 xBestIndex method. Ticket 2b8aed9f7c9e61e8. Fix a harmless reference to an uninitialized virtual machine register. Ticket 093420fc0eb7cba7. Fix the CLI so that it builds with -DSQLITE_UNTESTABLE Fix the eval.c extension so that it works with PRAGMA empty_result_callbacks=ON. Fix the generate_series virtual table so that it correctly returns no rows if any of its constraints are NULL. Performance enhancements in the parser. Hashes: SQLITE_SOURCE_ID: \"2018-04-10 17:39:29 4bb2294022060e61de7da5c227a69ccd846ba330e31626ebcd59a94efd148b3b\" SHA3-256 for sqlite3.c: 65750d1e506f416a0b0b9dd22d171379679c733e3460549754dc68c92705b5dc 2018-04-02 (3.23.0) Add the sqlite3_serialize() and sqlite3_deserialize() interfaces when the SQLITE_ENABLE_DESERIALIZE compile-time option is used. Recognize TRUE and FALSE as constants. (For compatibility, if there exist columns named \"true\" or \"false\", then the identifiers refer to the columns rather than Boolean constants.) Support operators IS TRUE, IS FALSE, IS NOT TRUE, and IS NOT FALSE. Added the SQLITE_DBSTATUS_CACHE_SPILL option to sqlite3_db_status() for reporting the number of cache spills that have occurred. The \"alternate-form-2\" flag (\"!\") on the built-in printf implementation now causes string substitutions to measure the width and precision in characters instead of bytes. If the xColumn method in a virtual table implementation returns an error message using sqlite3_result_error() then give that error message preference over internally-generated messages. Added the -A command-line option to the CLI to make it easier to manage SQLite Archive files. Add support for INSERT OR REPLACE, INSERT OR IGNORE, and UPDATE OR REPLACE in the Zipfile virtual table. Enhance the sqlite3changeset_apply() interface so that it is hardened against attacks from deliberately corrupted changeset objects. Added the sqlite3_normalize() extension function. Query optimizer enhancements: Improve the omit-left-join optimization so that it works in cases where the right-hand table is UNIQUE but not necessarily NOT NULL. Improve the push-down optimization so that it works for many LEFT JOINs. Add the LEFT JOIN strength reduction optimization that converts a LEFT JOIN into an ordinary JOIN if there exist terms in the WHERE clause that would prevent the extra all-NULL row of the LEFT JOIN from appearing in the output set. Avoid unnecessary writes to the sqlite_sequence table when an AUTOINCREMENT table is updated with an rowid that is less than the maximum. Bug fixes: Fix the parser to accept valid row value syntax. Ticket 7310e2fb3d046a5 Fix the query planner so that it takes into account dependencies in the arguments to table-valued functions in subexpressions in the WHERE clause. Ticket 80177f0c226ff54 Fix incorrect result with complex OR-connected WHERE and STAT4. Ticket ec32177c99ccac2 Fix potential corruption in indexes on expressions due to automatic datatype conversions. Ticket 343634942dd54ab Assertion fault in FTS4. Ticket d6ec09eccf68cfc Incorrect result on the less-than operator in row values. Ticket f484b65f3d62305 Always interpret non-zero floating-point values as TRUE, even if the integer part is zero. Ticket 36fae083b450e3a Fix an issue in the fsdir(PATH) table-valued function to the fileio.c extension, that caused a segfault if the fsdir() table was used as the inner table of a join. Problem reported on the mailing list and fixed by check-in 7ce4e71c1b7251be Issue an error rather instead of an assertion-fault or null-pointer dereference when the sqlite_master table is corrupted so that the sqlite_sequence table root page is really a btree-index page. Check-in 525deb7a67fbd647 Fix the ANALYZE command so that it computes statistics on tables whose names begin with \"sqlite\". Check-in 0249d9aecf69948d Additional fixes for issues detected by OSSFuzz: Fix a possible infinite loop on VACUUM for corrupt database files. Check-in 27754b74ddf64 Disallow parameters in the WITH clause of triggers and views. Check-in b918d4b4e546d Fix a potential memory leak in row value processing. Check-in 2df6bbf1b8ca8 Improve the performance of the replace() SQL function for cases where there are many substitutions on megabyte-sized strings, in an attempt to avoid OSSFuzz timeouts during testing. Check-in fab2c2b07b5d3 Provide an appropriate error message when the sqlite_master table contains a CREATE TABLE AS statement. Formerly this caused either an assertion fault or null pointer dereference. Problem found by OSSFuzz on the GDAL project. Check-in d75e67654aa96 Incorrect assert() statement removed. Check-in 823779d31eb09cda. Fix a problem with using the LIKE optimization on an INTEGER PRIMARY KEY. Check-in b850dd159918af56. Hashes: SQLITE_SOURCE_ID: \"2018-04-02 11:04:16 736b53f57f70b23172c30880186dce7ad9baa3b74e3838cae5847cffb98f5cd2\" SHA3-256 for sqlite3.c: 4bed3dc2dc905ff55e2c21fd2725551fc0ca50912a9c96c6af712a4289cb24fa 2018-01-22 (3.22.0) The output of sqlite3_trace_v2() now shows each individual SQL statement run within a trigger. Add the ability to read from WAL mode databases even if the application lacks write permission on the database and its containing directory, as long as the -shm and -wal files exist in that directory. Added the rtreecheck() scalar SQL function to the R-Tree extension. Added the sqlite3_vtab_nochange() and sqlite3_value_nochange() interfaces to help virtual table implementations optimize UPDATE operations. Added the sqlite3_vtab_collation() interface. Added support for the \"^\" initial token syntax in FTS5. New extensions: The Zipfile virtual table can read and write a ZIP Archive. Added the fsdir(PATH) table-valued function to the fileio.c extension, for listing the files in a directory. The sqlite_btreeinfo eponymous virtual table for introspecting and estimating the sizes of the btrees in a database. The Append VFS is a VFS shim that allows an SQLite database to be appended to some other file. This allows (for example) a database to be appended to an executable that then opens and reads the database. Query planner enhancements: The optimization that uses an index to quickly compute an aggregate min() or max() is extended to work with indexes on expressions. The decision of whether to implement a FROM-clause subquery as a co-routine or using query flattening now considers whether the result set of the outer query is \"complex\" (if it contains functions or expression subqueries). A complex result set biases the decision toward the use of co-routines. The planner avoids query plans that use indexes with unknown collating functions. The planner omits unused LEFT JOINs even if they are not the right-most joins of a query. Other performance optimizations: A smaller and faster implementation of text to floating-point conversion subroutine: sqlite3AtoF(). The Lemon parser generator creates a faster parser. Use the strcspn() C-library routine to speed up the LIKE and GLOB operators. Improvements to the command-line shell: The \".schema\" command shows the structure of virtual tables. Added support for reading and writing SQLite Archive files using the .archive command. Added the experimental .expert command Added the \".eqp trigger\" variant of the \".eqp\" command Enhance the \".lint fkey-indexes\" command so that it works with WITHOUT ROWID tables. If the filename argument to the shell is a ZIP archive rather than an SQLite database, then the shell automatically opens that ZIP archive using the Zipfile virtual table. Added the edit() SQL function. Added the .excel command to simplify exporting database content to a spreadsheet. Databases are opened using Append VFS when the --append flag is used on the command line or with the .open command. Enhance the SQLITE_ENABLE_UPDATE_DELETE_LIMIT compile-time option so that it works for WITHOUT ROWID tables. Provide the sqlite_offset(X) SQL function that returns the byte offset into the database file to the beginning of the record holding value X, when compiling with -DSQLITE_ENABLE_OFFSET_SQL_FUNC. Bug fixes: Infinite loop on an UPDATE that uses an OR operator in the WHERE clause. Problem introduced with 3.17.0 and reported on the mailing list about one year later. Ticket 47b2581aa9bfecec. Incorrect query results when the skip-ahead-distinct optimization is used. Ticket ef9318757b152e3a. Incorrect query results on a join with a ORDER BY DESC. Ticket 123c9ba32130a6c9. Inconsistent result set column names between CREATE TABLE AS and a simple SELECT. Ticket 3b4450072511e621 Assertion fault when doing REPLACE on an index on an expression. Ticket dc3f932f5a147771 Assertion fault when doing an IN operator on a constant index. Ticket aa98619ad08ddcab Hashes: SQLITE_SOURCE_ID: \"2018-01-22 18:45:57 0c55d179733b46d8d0ba4d88e01a25e10677046ee3da1d5b1581e86726f2171d\" SHA3-256 for sqlite3.c: 206df47ebc49cd1710ac0dd716ce5de5854826536993f4feab7a49d136b85069 2017-10-24 (3.21.0) Take advantage of the atomic-write capabilities in the F2FS filesystem when available, for greatly reduced transaction overhead. This currently requires the SQLITE_ENABLE_BATCH_ATOMIC_WRITE compile-time option. Allow ATTACH and DETACH commands to work inside of a transaction. Allow WITHOUT ROWID virtual tables to be writable if the PRIMARY KEY contains exactly one column. The \"fsync()\" that occurs after the header is written in a WAL reset now uses the sync settings for checkpoints. This means it will use a \"fullfsync\" on macs if PRAGMA checkpoint_fullfsync set on. The sqlite3_sourceid() function tries to detect if the source code has been modified from what is checked into version control and if there are modifications, the last four characters of the version hash are shown as \"alt1\" or \"alt2\". The objective is to detect accidental and/or careless edits. A forger can subvert this feature. Improved de-quoting of column names for CREATE TABLE AS statements with an aggregate query on the right-hand side. Fewer \"stat()\" system calls issued by the unix VFS. Enhanced the LIKE optimization so that it works with an ESCAPE clause. Enhanced PRAGMA integrity_check and PRAGMA quick_check to detect obscure row corruption that they were formerly missing. Also update both pragmas so that they return error text rather than SQLITE_CORRUPT when encountering corruption in records. The query planner now prefers to implement FROM-clause subqueries using co-routines rather using the query flattener optimization. Support for the use of co-routines for subqueries may no longer be disabled. Pass information about !=, IS, IS NOT, NOT NULL, and IS NULL constraints into the xBestIndex method of virtual tables. Enhanced the CSV virtual table so that it accepts the last row of input if the final new-line character is missing. Remove the rarely-used \"scratch\" memory allocator. Replace it with the SQLITE_CONFIG_SMALL_MALLOC configuration setting that gives SQLite a hint that large memory allocations should be avoided when possible. Added the swarm virtual table to the existing union virtual table extension. Added the sqlite_dbpage virtual table for providing direct access to pages of the database file. The source code is built into the amalgamation and is activated using the -DSQLITE_ENABLE_DBPAGE_VTAB compile-time option. Add a new type of fts5vocab virtual table - \"instance\" - that provides direct access to an FTS5 full-text index at the lowest possible level. Remove a call to rand_s() in the Windows VFS since it was causing problems in Firefox on some older laptops. The src/shell.c source code to the command-line shell is no longer under version control. That file is now generated as part of the build process. Miscellaneous microoptimizations reduce CPU usage by about 2.1%. Bug fixes: Fix a faulty assert() statement discovered by OSSFuzz. Ticket cb91bf4290c211d Fix an obscure memory leak in sqlite3_result_pointer(). Ticket 7486aa54b968e9b Avoid a possible use-after-free error by deferring schema resets until after the query planner has finished running. Ticket be436a7f4587ce5 Only use indexes-on-expressions to optimize ORDER BY or GROUP BY if the COLLATE is correct. Ticket e20dd54ab0e4383 Fix an assertion fault that was coming up when the expression in an index-on-expressions is really a constant. Ticket aa98619ad08ddca Fix an assertion fault that could occur following PRAGMA reverse_unordered_selects. Ticket cb91bf4290c211d Fix a segfault that can occur for queries that use table-valued functions in an IN or EXISTS subquery. Ticket b899b6042f97f5 Fix a potential integer overflow problem when compiling a particular horrendous common table expression. This was another problem discovered by OSSFuzz. Check-in 6ee8cb6ae5. Fix a potential out-of-bound read when querying a corrupt database file, a problem detected by Natalie Silvanovich of Google Project Zero. Check-in 04925dee41a21f. Hashes: SQLITE_SOURCE_ID: \"2017-10-24 18:55:49 1a584e499906b5c87ec7d43d4abce641fdf017c42125b083109bc77c4de48827\" SHA3-256 for sqlite3.c: 84c181c0283d0320f488357fc8aab51898370c157601459ebee49d779036fe03 2017-08-24 (3.20.1) Fix a potential memory leak in the new sqlite3_result_pointer() interface. Ticket 7486aa54b968e9b5. Hashes: SQLITE_SOURCE_ID: \"2017-08-24 16:21:36 8d3a7ea6c5690d6b7c3767558f4f01b511c55463e3f9e64506801fe9b74dce34\" SHA3-256 for sqlite3.c: 93b1a6d69b48dc39697d1d3a1e4c30b55da0bdd2cad0c054462f91081832954a 2017-08-01 (3.20.0) Update the text of error messages returned by sqlite3_errmsg() for some error codes. Add new pointer passing interfaces. Backwards-incompatible changes to some extensions in order to take advantage of the improved security offered by the new pointer passing interfaces: Extending FTS5 → requires sqlite3_bind_pointer() to find the fts5_api pointer. carray(PTR,N) → requires sqlite3_bind_pointer() to set the PTR parameter. remember(V,PTR) → requires sqlite3_bind_pointer() to set the PTR parameter. Added the SQLITE_STMT virtual table extension. Added the COMPLETION extension - designed to suggest tab-completions for interactive user interfaces. This is a work in progress. Expect further enhancements in future releases. Added the UNION virtual table extension. The built-in date and time functions have been enhanced so that they can be used in CHECK constraints, in indexes on expressions, and in the WHERE clauses of partial indexes, provided that they do not use the 'now', 'localtime', or 'utc' keywords. More information. Added the sqlite3_prepare_v3() and sqlite3_prepare16_v3() interfaces with the extra \"prepFlags\" parameters. Provide the SQLITE_PREPARE_PERSISTENT flag for sqlite3_prepare_v3() and use it to limit lookaside memory misuse by FTS3, FTS5, and the R-Tree extension. Added the PRAGMA secure_delete=FAST command. When secure_delete is set to FAST, old content is overwritten with zeros as long as that does not increase the amount of I/O. Deleted content might still persist on the free-page list but will be purged from all b-tree pages. Enhancements to the command-line shell: Add support for tab-completion using the COMPLETION extension, for both readline and linenoise. Add the \".cd\" command. Enhance the \".schema\" command to show the schema of all attached databases. Enhance \".tables\" so that it shows the schema names for all attached if the name is anything other than \"main\". The \".import\" command ignores an initial UTF-8 BOM. Added the \"--newlines\" option to the \".dump\" command to cause U+000a and U+000d characters to be output literally rather than escaped using the replace() function. Query planner enhancements: When generating individual loops for each ORed term of an OR scan, move any constant WHERE expressions outside of the loop, as is done for top-level loops. The query planner examines the values of bound parameters to help determine if a partial index is usable. When deciding between two plans with the same estimated cost, bias the selection toward the one that does not use the sorter. Evaluate WHERE clause constraints involving correlated subqueries last, in the hope that they never have be evaluated at all. Do not use the flattening optimization for a sub-query on the RHS of a LEFT JOIN if that subquery reads data from a virtual table as doing so prevents the query planner from creating automatic indexes on the results of the sub-query, which can slow down the query. Add SQLITE_STMTSTATUS_REPREPARE, SQLITE_STMTSTATUS_RUN, and SQLITE_STMTSTATUS_MEMUSED options for the sqlite3_stmt_status() interface. Provide PRAGMA functions for PRAGMA integrity_check, PRAGMA quick_check, and PRAGMA foreign_key_check. Add the -withoutnulls option to the TCL interface eval method. Enhance the sqlite3_analyzer.exe utility program so that it shows the number of bytes of metadata on btree pages. The SQLITE_DBCONFIG_ENABLE_QPSG run-time option and the SQLITE_ENABLE_QPSG compile-time option enable the query planner stability guarantee. See also ticket 892fc34f173e99d8 Miscellaneous optimizations result in a 2% reduction in CPU cycles used. Bug Fixes: Fix the behavior of sqlite3_column_name() for queries that use the flattening optimization so that the result is consistent with other queries that do not use that optimization, and with PostgreSQL, MySQL, and SQLServer. Ticket de3403bf5ae. Fix the query planner so that it knows not to use automatic indexes on the right table of LEFT JOIN if the WHERE clause uses the IS operator. Fix for ce68383bf6aba. Ensure that the query planner knows that any column of a flattened LEFT JOIN can be NULL even if that column is labeled with \"NOT NULL\". Fix for ticket 892fc34f173e99d8. Fix rare false-positives in PRAGMA integrity_check when run on a database connection with attached databases. Ticket a4e06e75a9ab61a12 Fix a bug (discovered by OSSFuzz) that causes an assertion fault if certain dodgy CREATE TABLE declarations are used. Ticket bc115541132dad136 Hashes: SQLITE_SOURCE_ID: \"2017-08-01 13:24:15 9501e22dfeebdcefa783575e47c60b514d7c2e0cad73b2a496c0bc4b680900a8\" SHA3-256 for sqlite3.c: 79b7f3b977360456350219cba0ba0e5eb55910565eab68ea83edda2f968ebe95 2017-06-17 (3.18.2) Fix a bug that might cause duplicate output rows when an IN operator is used in the WHERE clause. Ticket 61fe9745. Hashes: SQLITE_SOURCE_ID: \"2017-06-17 09:59:36 036ebf729e4b21035d7f4f8e35a6f705e6bf99887889e2dc14ebf2242e7930dd\" SHA3-256 for sqlite3.c: b0bd014f2776b9f9508a3fc6432f70e2436bf54475369f88f0aeef75b0eec93e 2017-06-16 (3.18.1) Fix a bug associated with auto_vacuum that can lead to database corruption. The bug was introduced in version 3.16.0 (2017-01-02). Ticket fda22108. Hashes: SQLITE_SOURCE_ID: \"2017-06-16 13:41:15 77bb46233db03a3338bacf7e56f439be3dfd1926ea0c44d252eeafa7a7b31c06\" SHA3-256 for sqlite3.c: 334eaf776db9d09a4e69d6012c266bc837107edc2c981739ef82081cb11c5723 2017-06-08 (3.19.3) Fix a bug associated with auto_vacuum that can lead to database corruption. The bug was introduced in version 3.16.0 (2017-01-02). Ticket fda22108. Hashes: SQLITE_SOURCE_ID: \"2017-06-08 14:26:16 0ee482a1e0eae22e08edc8978c9733a96603d4509645f348ebf55b579e89636b\" SHA3-256 for sqlite3.c: 368f1d31272b1739f804bcfa5485e5de62678015c4adbe575003ded85c164bb8 2017-05-25 (3.19.2) Fix more bugs in the LEFT JOIN flattening optimization. Ticket 7fde638e94287d2c. Hashes: SQLITE_SOURCE_ID: \"2017-05-25 16:50:27 edb4e819b0c058c7d74d27ebd14cc5ceb2bad6a6144a486a970182b7afe3f8b9\" SHA3-256 for sqlite3.c: 1be0c457869c1f7eba58c3b5097b9ec307a15be338308bee8e5be8570bcf5d1e 2017-05-24 (3.19.1) Fix a bug in the LEFT JOIN flattening optimization. Ticket cad1ab4cb7b0fc. Remove a surplus semicolon that was causing problems for older versions of MSVC. Hashes: SQLITE_SOURCE_ID: \"2017-05-24 13:08:33 f6d7b988f40217821a382bc298180e9e6794f3ed79a83c6ef5cae048989b3f86\" SHA3-256 for sqlite3.c: 996b2aff37b6e0c6663d0312cd921bbdf6826c989cbbb07dadde5e9672889bca 2017-05-22 (3.19.0) The SQLITE_READ authorizer callback is invoked once with a column name that is an empty string for every table referenced in a query from which no columns are extracted. When using an index on an expression, try to use expression values already available in the index, rather than loading the original columns and recomputing the expression. Enhance the flattening optimization so that it is able to flatten views on the right-hand side of a LEFT JOIN. Use replace() instead of char() for escaping newline and carriage-return characters embedded in strings in the .dump output from the command-line shell. Avoid unnecessary foreign key processing in UPDATE statements that do not touch the columns that are constrained by the foreign keys. On a DISTINCT query that uses an index, try to skip ahead to the next distinct entry using the index rather than stepping through rows, when an appropriate index is available. Avoid unnecessary invalidation of sqlite3_blob handles when making changes to unrelated tables. Transfer any terms of the HAVING clause that use only columns mentioned in the GROUP BY clause over to the WHERE clause for faster processing. Reuse the same materialization of a VIEW if that VIEW appears more than once in the same query. Enhance PRAGMA integrity_check so that it identifies tables that have two or more rows with the same rowid. Enhance the FTS5 query syntax so that column filters may be applied to arbitrary expressions. Enhance the json_extract() function to cache and reuse parses of JSON input text. Added the anycollseq.c loadable extension that allows a generic SQLite database connection to read a schema that contains unknown and/or application-specific collating sequences. Bug Fixes: Fix a problem in REPLACE that can result in a corrupt database containing two or more rows with the same rowid. Fix for ticket f68dc596c4e6018d. Fix a problem in PRAGMA integrity_check that was causing a subsequent VACUUM to behave suboptimally. Fix the PRAGMA foreign_key_check command so that it works correctly with foreign keys on WITHOUT ROWID tables. Fix a bug in the b-tree logic that can result in incorrect duplicate answers for IN operator queries. Ticket 61fe9745 Disallow leading zeros in numeric constants in JSON. Fix for ticket b93be8729a895a528e2. Disallow control characters inside of strings in JSON. Fix for ticket 6c9b5514077fed34551. Limit the depth of recursion for JSON objects and arrays in order to avoid excess stack usage in the recursive descent parser. Fix for ticket 981329adeef51011052. Hashes: SQLITE_SOURCE_ID: \"2017-05-22 13:58:13 28a94eb282822cad1d1420f2dad6bf65e4b8b9062eda4a0b9ee8270b2c608e40\" SHA3-256 for sqlite3.c: c30326aa1a9cc342061b755725eac9270109acf878bc59200dd4b1cea6bc2908 2017-03-30 (3.18.0) Added the PRAGMA optimize command The SQLite version identifier returned by the sqlite_source_id() SQL function and the sqlite3_sourceid() C API and found in the SQLITE_SOURCE_ID macro is now a 64-digit SHA3-256 hash instead of a 40-digit SHA1 hash. Added the json_patch() SQL function to the JSON1 extension. Enhance the LIKE optimization so that it works for arbitrary expressions on the left-hand side as long as the LIKE pattern on the right-hand side does not begin with a digit or minus sign. Added the sqlite3_set_last_insert_rowid() interface and use the new interface in the FTS3, FTS4, and FTS5 extensions to ensure that the sqlite3_last_insert_rowid() interface always returns reasonable values. Enhance PRAGMA integrity_check and PRAGMA quick_check so that they verify CHECK constraints. Enhance the query plans for joins to detect empty tables early and halt without doing unnecessary work. Enhance the sqlite3_mprintf() family of interfaces and the printf SQL function to put comma separators at the thousands marks for integers, if the \",\" format modifier is used in between the \"%\" and the \"d\" (example: \"%,d\"). Added the -DSQLITE_MAX_MEMORY=N compile-time option. Added the .sha3sum dot-command and the .selftest dot-command to the command-line shell Begin enforcing SQLITE_LIMIT_VDBE_OP. This can be used, for example, to prevent excessively large prepared statements in systems that accept SQL queries from untrusted users. Various performance improvements. Bug Fixes: Ensure that indexed expressions with collating sequences are handled correctly. Fix for ticket eb703ba7b50c1a5. Fix a bug in the 'start of ...' modifiers for the date and time functions. Ticket 6097cb92745327a1 Fix a potential segfault in complex recursive triggers, resulting from a bug in the OP_Once opcode introduced as part of a performance optimization in version 3.15.0. Ticket 06796225f59c057c In the RBU extension, add extra sync operations to avoid the possibility of corruption following a power failure. The sqlite3_trace_v2() output for nested SQL statements should always begin with a \"--\" comment marker. Hashes: SQLITE_SOURCE_ID: \"2017-03-28 18:48:43 424a0d380332858ee55bdebc4af3789f74e70a2b3ba1cf29d84b9b4bcf3e2e37\" SHA3-256 for sqlite3.c: cbf322df1f76be57fb3be84f3da1fc71d1d3dfdb7e7c2757fb0ff630b3bc2e5d 2017-02-13 (3.17.0) Approximately 25% better performance from the R-Tree extension. Uses compiler built-ins (ex: __builtin_bswap32() or _byteswap_ulong()) for byteswapping when available. Uses the sqlite3_blob key/value access object instead of SQL for pulling content out of R-Tree nodes Other miscellaneous enhancements such as loop unrolling. Add the SQLITE_DEFAULT_LOOKASIDE compile-time option. Increase the default lookaside size from 512,125 to 1200,100 as this provides better performance while only adding 56KB of extra memory per connection. Memory-sensitive applications can restore the old default at compile-time, start-time, or run-time. Use compiler built-ins __builtin_sub_overflow(), __builtin_add_overflow(), and __builtin_mul_overflow() when available. (All compil",
    "commentLink": "https://news.ycombinator.com/item?id=39004963",
    "commentBody": "SQLite 3.45 released with JSONB support (sqlite.org)283 points by genericlemon24 14 hours agohidepastfavorite50 comments jitl 14 hours agoFrom the original forum post [0] announcing this improvement: > But if you modify your application to start storing JSONB instead of text JSON, you might see a 3-times performance improvement, at least for the JSON-intensive operations. JSONB is also slightly smaller than text JSON in most cases (about 5% or 10% smaller) so you might also see a modest reduction in your database size if you use a lot of JSON. I for one am excited about these improvements (specifically the disk use reduction) since we store a lot of JSON here at Notion Labs, and we’re increasing our use of SQLite. [0]: https://sqlite.org/forum/forumpost/fa6f64e3dc1a5d97 reply emptysea 13 hours agoparentCurious how you're using SQLite at Notion, do you have anything public? reply jitl 8 hours agorootparentNothing public. We’ve used SQLite in our native apps (including desktop) for years, like you’d expect. We’re considering how we could use it in the browser in a few ways now that OPFS and the ecosystem there are stabilizing. We’re also looking at some use cases server side, but not one-db-per-tenant. I don’t think SQLite’s single-writer model would mesh well with Notion’s collaborative features. I’m actually very curious if the one-db-per-tenant concept turns out to be a good idea or a fad. To me it seems like a small app can very happily fit all their users on a single Postgres instance with much less orchestration effort, and a large app demanding of its database would hit the single-write lock thing. If you want to know more, think about joining?? :) https://notion.so/careers or @jitl on Twitter reply jbverschoor 12 hours agorootparentprevProbably one per workspace/tenant ? reply safetytrick 10 hours agorootparentWho is doing this and where can I read more? What are the tradeoffs? I imagine that you get a a dataset that is significantly smaller but it is much trickier to keep a dataset in memory the way you could with MySQL. It's like having a free implicit index on the customer (because you had to lookup the sqlite db file before you could start querying). I spend a lot of time thinking about tenancy and how to handle it. Tenancy is such a common problem. Performance is the number one reason tickets are hard to estimate. The second in my experience is security. Time and tenancy are the number one opportunities for SQL to just be better (I always need tenancy and my Order By or at least one constraint can typically be satisfied with time). reply aomix 10 hours agorootparentI wonder if Turso https://turso.tech/ supports that use case. They support 10k databases in the step above free pricing tier. reply abhibeckert 6 hours agorootparentprevI'm doing it, though I haven't written anything up. Happy to share my opinion though, with a bit more experience than you have. The databases I'm working with are pretty small - ballpark 4MB of data per \"tenant\". So, I guess, a single large database sever with half a terabyte of RAM could keep well over a hundred thousand tenants in memory at the same time (I don't have anywhere near that many tenants, so I haven't tested that... and honestly if I did have that many I'd probably split them up between different servers). Without getting stuck into the into too much detail - \"tenant\" isn't really a good fit for how we split them up. Our business is largely based on events that happen at a specific date, with maybe a few months of activity before that date. We have an sqlite database for each event (so ~4MB per event). Once the event passes, it's essentially archived and will almost never be accessed. But it won't actually never be accessed so we can't delete it. I haven't run into any performance issues so far, just with regular sqlite databases on the filesystem. I expect the kernel is doing it's thing and making sure \"hot\" databases are RAM as with any other frequently accessed file on the disk. My understanding (it's a theoretical problem I haven't actually encountered...) is SQLite only really struggles when you have a bunch of simultaneous writes. Our business model doesn't have that. The most actively written table is the one where we record credit card payments... and unfortunately we don't make tens of thousands of sales per second. If we did have that \"problem\" I'm sure we could allocate some of our billions of dollars per day in profits to finding a way to make it work... my gut instinct would be to continue to use SQLite with some kind of cache in front of it. All writes would go to something faster than SQLite, then be copied to SQLite later. Reads would check the write cache first, and SQLite if the cache misses. My experience working with a single large database is you end up with a lot of stale data that you is almost never needed. When a table has a hundred million rows, with indexes on multiple columns, even the simplest operating like adding a new row can get slow. My approach with SQLite eliminates that - I'll often have just hundreds of rows in a table and access is blazingly fast. When I need to access another database that hasn't been touched in a long time (years possibly), having to wait, what, an entire millisecond, for the SSD to load that database off the filesystem into memory isn't a big deal. No user is going to notice or complain. Obviously that's more challenging with some data sets and if you're constantly accessing old data, those milliseconds will add up to significant iowait and things will fall over. I definitely don't use SQLite for all of my databases... but in general if you're doing enough writes for SQLite's simultaneous write performance issue to be a problem... then chances are your data set is going to get very large, very quickly, and you're going to have performance headaches no matter what database you're using. Finding some way to divide your database is an obvious performance win... and SQLite makes that really easy. reply yawaramin 7 hours agorootparentprevdhh is doing it: https://world.hey.com/dhh/multi-tenancy-is-what-s-hard-about... reply simonw 13 hours agoprevIf anyone wants to try this out on macOS here's the fastest way I've found to try a new SQLite version there: https://til.simonwillison.net/sqlite/sqlite-version-macos-py... Short version: cd /tmp wget 'https://www.sqlite.org/2024/sqlite-amalgamation-3450000.zip' unzip sqlite-amalgamation-3450000.zip cd sqlite-amalgamation-3450000 gcc -dynamiclib sqlite3.c -o libsqlite3.0.dylib -lm -lpthread DYLD_LIBRARY_PATH=$PWD python3 -c \"import sqlite3; print(sqlite3.sqlite_version)\" That prints \"3.45.0\" for me. If you have https://datasette.io/ installed you can then get a web UI for trying it out by running: DYLD_LIBRARY_PATH=$PWD datasette reply sgbeal 13 hours agoparent> If anyone wants to try this out on macOS here's the fastest way I've found to try a new SQLite version ... https://sqlite.org/fiddle is always updated as part of the release process and is updated periodically between releases. reply mmebane 10 hours agoparentprevFWIW, this works for me with Python 3.12 from Homebrew, but not Python 3.12 from python.org. _sqlite3.cpython-312-darwin.so in Homebrew's Python appears to dynamically link /opt/homebrew/opt/sqlite/lib/libsqlite3.0.dylib, but the version in python.org's Python statically links the sqlite3 library. EDIT: Python 3.9.6 from Xcode doesn't work either. It has _sqlite3.cpython-39-darwin.so which dynamically links /usr/lib/libsqlite3.dylib, but that dylib doesn't exist on my system, and I don't know enough about macOS internals to tell where it's coming from. The _sqlite3 so doesn't seem big enough to have it statically linked. EDIT2: Xcode's Python works when launching via the real path instead of using the /usr/bin/python3 alias, I assume because /usr/bin is SIP-protected or something. reply simonw 6 hours agorootparentThanks for that, I'll add a note to my TIL. reply westurner 7 hours agoparentprevIf you change the version, URL, and the sha256 in conda-forge/sqlite-feedstock//recipe/meta.yaml and send a PR, it should build end then deploy the latest version so that you can just `mamba install -y sqlite libspatiallite sqlite-utils` without also mamba installing gcc or clang. https://github.com/conda-forge/sqlite-feedstock/blob/main/re... https://github.com/conda-forge/sqlite-feedstock/blob/main/re... reply csdvrx 13 hours agoparentprevand the easiest way for those who can wait for the next update will be to get the binaries from https://cosmo.zip/pub/cosmos/bin/datasette and https://cosmo.zip/pub/cosmos/bin/sqlite3 reply nalgeon 14 hours agoprevIf you find the official release notes a bit dry, I've made an interactive version: https://antonz.org/sqlite-3-45 reply stabbles 13 hours agoprev> Fix a couple of harmless compiler warnings that appeared in debug builds with GCC 16. Some projects use -Werror, only ever test with older GCC, and builds fail with anything recent. SQLite on the other hand anticipates the new compiler warnings of GCC 3 major versions in the future, that's impressive! reply mgaunard 13 hours agoparentGCC 16!? Are they from the future? reply stefanos82 13 hours agorootparentI'm sure they mistyped '6' over '3' from numpad; it can happen to any of us. reply mdaniel 11 hours agorootparentWhile I find your explanation plausible, who has the muscle memory to press \"g\", \"c\", \"c\", spacebar, lift hand to numpad, \"1\", \"6(no 3 sire!)\", hand back to home row? reply jwiz 9 hours agorootparentTo be fair, you can be typing \"gcc\" with the left hand, while the right hand moves to the numpad. Efficiency. reply mrcarruthers 10 hours agorootparentprevIt's faster for me than looking down to figure out where the numbers are on the top row reply abhibeckert 6 hours agorootparentIf you used the top row more often, you wouldn't need to look down... reply bdhcuidbebe 7 hours agorootparentprevI would use both my hands reply jkljsfdasdf 12 hours agoprevEmbarrasing question tbh but with all the cloud-native sqlite stuff like cloudflare d1 and fly LiteFS I'm seriously thinking of switching from postgres to sqlite. Does anyone have a compare/contrast sort of thing between the two? reply graemep 8 hours agoparentThe SQLite omitted features page is a good place to start: https://www.sqlite.org/omitted.html and the gotchas page it links to. It is a lot less feature rich than Postgres so there are things you will miss. Nothing like the range of types, I do not think it has a transactional DDL which is nice to have for migrations, and there are various other things like exclusion constraints and the different index types. On the other hand SQLite may do all you want and not having to run and configure a separate server is a huge deployment advantage. reply starttoaster 9 hours agoparentprevFor me, the biggest trade offs for sqlite are just that you need to think about how you're going to store and backup the database a lot more. Specifically in container orchestration environments like kubernetes, I think sqlite presents a couple of challenges. With MySQL, you can set up a replicated database server instance outside of the cluster that you just connect to over the network, and you can use standard MySQL tools like mysqldump to back them up. Kubernetes isn't ideal for stateful workloads so that tends to be one of the more sane solutions there. With SQlite you need to set up a persistent volume to keep the database around between container restarts, and you need to think of a clever way to then back up that sqlite database to somewhere like S3, likely using an sqlite3 command with a VACUUM statement and then an `aws s3 cp` command, which requires AWS credentials. Overall, a lot of additional work and privileges on the application container, at least in container orchestration environments. In lieu of all that, maybe you trust your persistent volume provisioner enough to try to do an online snapshot, but that always sketches me out / I don't trust the backup enough to rely on it. Of course you can use a public cloud sqlite service like Cloudflare D1, but I haven't used that solution enough to say if it would be flexible enough to work with, say, an on-prem application server, or if it only works with Cloudflare workers. I'm sure I could find that out in the documentation but I've exhausted my mental stamina for the day with leafing through documentation pages. reply xiaomai 6 hours agorootparentBacking up sqlite databases is straightforward. `.backup` is a command that you use in sqlite for this purpose. Since you already have a volume for the database, you can backup to that same volume (if offloading to S3/etc is too much work). reply starttoaster 5 hours agorootparentYeah, my point was pretty specific to container environments, that using sqlite forces you to add a bunch of sqlite handling logic to your application. Whereas with MySQL (and other similar RDBMS’), you can have your application just worry about its own logic, and handle MySQL backups completely separately from it. reply sgarland 6 hours agoparentprevFor the love of all that is holy, if you do, only use STRICT tables. By default [0], SQLite will happily accept that not only can an INTEGER column store “1234” (helpfully silently casting it first), but “abcd” can also be stored in the column as-is. There are other horrors in the link. [0]: https://www.sqlite.org/quirks.html reply abhibeckert 5 hours agorootparentI actually kinda like the fact that whatever data you write to the table will actually be written. I semi-regularly fix a serious data loss bug that has been fixed with an alter table query. Maybe converting VARCHAR to TEXT or INT to BIGINT... of course it doesn't really \"fix\" your problem, because the data has already been lost/truncated. What's a real world situation where completely the wrong type could be written to a column? Especially in modern software with good type safety checks/etc to ensure you don't have malicious data inserted into your database? If I ever did have that happen... at least the data hasn't been lost. You can run a simple script to clean up the \"horrific\" data. reply ncruces 32 minutes agorootparentI don't find a DB that losslessly stores what I told it to store regardless of types worrying at all. So in fact AFAIC the misfeature of SQLite is not that it's typeless, IMO, rather it's that it has this notion of NUMERIC affinity that's all but lossless. E.g. SQLite has a decimal extension that allows you to work with decimal numbers represented as TEXT, and so is appropriate to handle money without rounding issues. However, if you have a column where the declared type is DECIMAL, MONEY, NUMBER, NUMERIC or whatever it will have NUMERIC affinity. Then if you store a textual decimal number to it, it will deduce it looks like a FLOAT and convert, loosing precision. Your only solution is to use BLOB affinity (declare no type), which is what I do, most of the time. reply alfor 8 hours agoparentprevIn my tests sqlite was around 10X faster than postgres. That mean that a single cheap server is capable of going very very far in normal web workloads. I think we often add complexity: virtualisation, cloud, separated db server, horizontal scaling when efficient and simple tech is able to go very very far. reply mixmastamyk 10 hours agoparentprevIt sounds great until you need a centralized billing database and then you might want to just stick with postgres rather than run two kinds of database. Does anyone have ideas on how to solve that? Not to mention complicating migrations. Unfortunately sqlite-based product docs seem to end right before getting to the hard stuff. Or perhaps I missed them. reply robertlagrant 9 hours agorootparentWe use Alembic migrations with SQLite. No complaints. reply graemep 8 hours agorootparentDoes Alembic provide a simple solution to the limitations of SQLite's alter table? reply robertlagrant 28 minutes agorootparentYou're right. Sorry. I shouldn't post when I'm tired. This is listed as a limitation in Alembic, from memory. Edit: I looked[0]. While it is a SQLite limitation, Alembic does seem to have a way to work around it. [0] https://alembic.sqlalchemy.org/en/latest/batch.html#working-... reply Glench 8 hours agoparentprevcopying and pasting from a different thread: I use SQLite/Litestream for https://extensionpay.com! Serves about 120m requests per month (most of those are cached and don't hit the db), but it's been great! I was convinced that SQLite could be a viable db option from this great post about it called Consider SQLite: https://blog.wesleyac.com/posts/consider-sqlite Using SQLite with Litestream helped me to launch the site quickly without having to pay for or configure/manage a db server, especially when I didn't know if the site would make any money and didn't have any personal experience with running production databases. Litestream streams to blackblaze b2 for literally $0 per month which is great. I already had a backblaze account for personal backups and it was easy to just add b2 storage. I've never had to restore from backup so far. There's a pleasing operational simplicity in this setup — one $14 DigitalOcean droplet serves my entire app (single-threaded still!) and it's been easy to scale vertically by just upgrading the server to the next tier when I started pushing the limits of a droplet (or doing some obvious SQLite config optimizations). DigitalOcean's \"premium\" intel and amd droplets use NVMe drives which seem to be especially good with SQLite. One downside of using SQLite is that there's just not as much community knowledge about using and tuning it for web applications. For example, I'm using it with SvelteKit and there's not much written online about deploying multi-threaded SvelteKit apps with SQLite. Also, not many example configs to learn from. By far the biggest performance improvement I found was turning on memory mapping for SQLite. Happy to answer any questions you might have! reply onetoo 2 hours agorootparentOut of curiosity, have you ever needed to restore a litestream backup? reply ado__dev 13 hours agoprevVery welcome improvement. I overlooked SQLite for far too long relegating it to just a \"toy database, not meant for real world apps\". Boy was I wrong. reply mdaniel 11 hours agoprevI thought I recognized this but its submission URL was goofy; previously discussed: JSONB has landed - https://news.ycombinator.com/item?id=38540421 - Dec 2023 (205 comments) reply ckok 3 hours agoprevThe only thing missing with Json support now seems to be something like a gin index on jsonb fields to make querying efficiently on any member of the field itself. reply Retr0id 11 hours agoprevTrying to store JSON-like data in a way that's both compact and fast to operate on directly is a challenge. IIUC this is is something SQLite has wanted to introduce for a while, but it took them some time to find a viable approach. reply radarsat1 9 hours agoprevI find it really odd that the decision was made to store ints and floats as text in JSONB. It seems to defeat a lot of use cases for it as far as I can tell. There are few solutions for storing and retrieving/querying unstructured numerical data. reply malkia 9 hours agoparentI don't know the rationale, but I would assume exact preservation of data maybe the case. Does json (yaml/others) have well defined handling of ints/floats? Especially ints with more than 52bits set? reply ncruces 1 hour agorootparentThe rational was to design a format that can serve as a (flattened) parse tree for the JSON. JSON handling functions in SQLite took in textual JSON and mostly spat out JSON text. So their structure was: (1) parse JSON, (2) massage in memory representation, (3) serialize JSON. If you can come up with a format that can serve as the in memory representation, and persist that to disk, your functions can skip (1) and (3), and focus on (2). Still, many times you'll need JSON text at the boundary, so making (1) and (3) fast are needed to. Parsing and formatting numbers can also be an unnecessary expense, if you do that more often than you actually need it. reply nycdotnet 8 hours agorootparentprevThis sounds right. This JSONB seems to be oriented not around semantic parsing, just structural parsing. https://sqlite.org/draft/jsonb.html Note too that JSON doesn’t really have ints or floats - the number type in JSON doesn’t specify a max size. Most implementations of course do rely on the native number types of their platform, so this implementation choice for SQLite allows them to keep a simpler implementation that sidesteps a lot of complexity that would come from deeper parsing. See the number section on json.org https://www.json.org/json-en.html reply nick_ 7 hours agoparentprevIIRC Sqlite stores all data types as text. It seems like a very weird decision to me. reply ncruces 1 hour agorootparentThis is wrong. Integers (in SQLite columns) are stored as varints and floats as IEEE 754 doubles. Numbers in JSONB are stored as text. reply elpocko 14 hours agoprev> The internal JSONB format is also uses slightly less disk space then text JSON. reply rmrf100 8 hours agoprev [–] This is great. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary covers updates, bug fixes, and enhancements made to the SQLite database management system.",
      "Improvements were made to SQL and JSON functions, query planning, command-line interface, and error handling.",
      "Updates also address issues like memory leaks, bug fixes, and optimizations.",
      "New features include support for new syntax, compatibility with other databases, and the addition of new commands.",
      "The updates focus on improving performance, security, and usability of SQLite."
    ],
    "commentSummary": [
      "SQLite 3.45 is out, offering improved performance and reduced database size for JSON-intensive operations.",
      "Notion Labs is considering using SQLite in their native apps and exploring its use in the browser and server-side.",
      "Discussion includes the concept of one-db-per-tenant, Turso as a potential solution, obtaining SQLite binaries, interactive release notes, fixing compiler warnings, and a Postgres vs. SQLite comparison."
    ],
    "points": 283,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1705346684
  },
  {
    "id": 39007756,
    "title": "Bluesky Launches RSS Feeds for User Discovery",
    "originLink": "https://openrss.org/blog/bluesky-has-launched-rss-feeds",
    "originBody": "Bluesky has launched RSS feeds January 15, 2024 Hooray to Bluesky for releasing its new RSS feeds! Now anyone can now obtain an RSS feed for any Bluesky user. We've taken them for a test drive, and here's what you should know. They work well with RSS Readers and RSS browser extensions The link to a user's RSS feed is quite lengthy, making it not so easy to remember, and you can't really tell which user's profile an RSS feed is for just by looking at it. Here's the RSS feed link for Bluesky's CEO Jay Graber, for example. https://bsky.app/profile/did:plc:oky5czdrnfjpqslsw2a5iclo/rss But thankfully, this doesn't matter much, because they're embedded on each user's profile on the Bluesky website. This makes each user's RSS feed automatically discoverable by any RSS reader app. You can simply copy and paste the link to a user's profile into the app, and it will find the user's RSS feed for you automatically. Shows an RSS Reader app automatically discovering a Bluesky user's RSS feed by pasting the user's profile link into the search field Some RSS apps will even allow you to get a Bluesky user's RSS feed simply by typing their username in the search. This setup also works well with RSS browser extensions. So if you're using one with RSS detection, it will automatically detect a user's RSS feed after visiting their Bluesky profile in your browser. RSS feeds only contain posts that don't require a login All posts made on Bluesky are public by default, and anyone (even users not logged into Bluesky) can see them. However, users have the ability to restrict their posts to only logged-in users. So if a user has their posts set to be visible only to logged-in users, you wouldn't be able to view that user's posts in the user's Bluesky RSS feed. Links don't appear in RSS feeds At the time of this writing, Bluesky RSS feeds don't have links embedded in the full text of the feed. So you'll have to navigate to the post on the Bluesky website in order for the links to be clickable. For instance, here is how a user's Bluesky post appears in an RSS reader—notice there are no links. And here is that same post as it appears on the Bluesky website, which shows the blue, clickable links. Improving Bluesky RSS feeds over time This initial version of the Bluesky RSS feeds look very promising, and we hope the Bluesky team continues to improve them. If there's anything more you'd like to see from Bluesky's RSS feeds, you can submit feedback to them on their GitHub Discussion board or through their social media profiles listed on the Bluesky website. Alternatively, you can also shoot us a message with your feedback, and we'll reach out to Bluesky to make sure they get it. And of course, our very own Bluesky RSS feeds are always available if you need them by just adding openrss.org to the beginning of any Bluesky user's profile in the browser URL bar. ❤ Open RSS is a registered 501(c)(3) nonprofit headquartered in the District of Columbia, USA and funded only by voluntary donations of its users. If you enjoy using Open RSS, we'd be so grateful if you'd consider donating to help us grow and continue to provide you with a quality and reliable service.",
    "commentLink": "https://news.ycombinator.com/item?id=39007756",
    "commentBody": "Bluesky has launched RSS feeds (openrss.org)262 points by kieto 9 hours agohidepastfavorite120 comments j4yav 2 hours agoI finally tried it and as a new member literally every recommended post was US culture wars stuff. Is that the normal experience, or am I getting some kind of bias based on who I received an invite from? reply jug 42 minutes agoparentIt had nothing of the sort when the network was younger but it seems like everything steers towards that sort of political profile eventually, regardless of name. And 2024 is probably going to be particularly nasty for obvious reasons. reply jddj 2 hours agoparentprevIt was billed as a twitter alternative reply MoSattler 1 hour agoparentprevI am so tired of it. I wish there was an AI filter for social media that let me block out this stuff. reply finnjohnsen2 1 hour agoparentprevThanks for the warning reply GaggiX 1 hour agoparentprevFinally a real Twitter competitor. reply unpopularopp 57 minutes agoparentprevAnd unfortunately I see the same shit on Mastodon as well 24/7… reply scopeh 30 minutes agorootparentI don't think there is any algorithm magic in mastodon. your feed is who you follow and who they boost. maybe its time for you to have a clean up. reply unpopularopp 24 minutes agorootparentJust like OP I also mean the recommended stuff https://mastodon.social/explore Same shit as on Twitter and Bluesky reply mgbmtl 9 minutes agorootparentYeah I have an account on that Mastodon server and even logged-in, that page shows popular (rage-bait) content regardless of my personal preferences. It filtered by language but not region (so it was mostly content from another continent). However, my actual Mastodon feed only has content from people I follow, without any recommendations, and that works great. reply rakoo 14 minutes agorootparentprevThis is the recommended stuff as seen from on one single server. It doesn't represent one's experience. The whole point of Mastodon is to only get what you want, not the rest. It's easy to build your own network of sources. The explore feed is useless :) reply renegat0x0 3 hours agoprevThis is a little bit off topic, but Openrss page information about how to obtain RSS link is poor. \"To find the RSS Feed for a website, just navigate to the website and the RSS feed for it is usually located at the domain of the website followed by /rss.xml, /rss or /atom.xml\". Recently on HN there were infos that pages provide meta links to atom. This is cleaner solution than guessing. There was also Firefox extension 'want my rss', etc etc. This should be better explained on RSS site. reply vintagedave 2 hours agoparentYes. It's common practice for them to be called rss.xml and atom.xml but they can be anything you want. I use a `link` tag on my site -- I am not an expert here, but it seems applicable[1], RSS etc readers find it, and `meta` is documented only for use for cases that elements like `link` cannot represent.[2] So I'm confident enough this is correct-ish enough to write in a comment on HN :) [1] https://developer.mozilla.org/en-US/docs/Web/HTML/Element/li... [2] https://developer.mozilla.org/en-US/docs/Web/HTML/Element/me... reply jraph 2 hours agoparentprevIndeed. WordPress runs a big part of the web and is probably more likely for blogs, which is what you are likely to want to follow with RSS, and it's located at /feed. At this point, I just use CTRL+U and search \"rss\" and \"atom\", hoping to find a the correspondingtag. It's a shame Firefox does not automatically display a feed icon anymore, it would be much better if I want to tell non technical people about RSS. Installing an extension is workable but it's also an additional step. reply konart 3 hours agoprevLogged into BS after getting an invite and immediately realised what X (twitter) users from the US where talking about when they mention political \"dispute\" being a big driver of the social network. Goodbye BS! Even looking at the endless stream of xxx-coint posts on nostr is not that exuasting. reply greyface- 7 hours agoprevI noticed this shortly after the loginwall came down, and am subscribed to a few feeds. The post mentions the lack of links, but what I find more frustrating is the lack of embedded media (or indication thereof) on posts where it's present. This is also a problem with Mastodon feeds. reply steveklabnik 6 hours agoparentCheck it out: https://bsky.app/settings/external-embeds reply greyface- 6 hours agorootparentThanks! I didn't know about this, have toggled some of them on, and will see how it changes things. I think this is limited to the web client, though - I don't see how it could impact RSS feed generation, since those are being fetched logged-out by my RSS reader. Mostly I'm frustrated by the lack of s in RSS s on posts that contain photos. reply steveklabnik 6 hours agorootparentIt is very new. And yeah that does sound frustrating, maybe file a bug? reply pfraze 6 hours agorootparentyeah please do https://github.com/bluesky-social/social-app/ reply anotherevan 6 hours agoparentprevI'm using https://bluestream.deno.dev/ which does include embedded media. I've one test user I'm following where I have an RSS feed from Bluestream and one directly with Bluesky. When they reach parity I'll swap over. reply bad_user 4 hours agoparentprevMastodon feeds do have embedded media, not sure what you mean. reply greyface- 4 hours agorootparentInteresting. I just checked, and Mastodon feeds do seem to be emitting xmlns:media=\"http://search.yahoo.com/mrss/\"tags with image URLs. NetNewsWire doesn't attempt to render them at all. Other feeds using vanilla RSS withtags in thedo render. Maybe it's just a client issue. Edit: Yep, https://github.com/Ranchero-Software/NetNewsWire/issues/2538. My bad; not a Mastodon issue. reply Moldoteck 38 minutes agoprevAfter registering, almost every post was related to nazi substack drama... I don't get it. I've also used Threads and it's a much more chilled app... reply 0xEF 15 minutes agoparentMy wife and I get IG ads for threads that are full of racist, bigoted posts by its users. We have no idea why, since we never click on those sorts of post, and our IG accounts are 100% hobby centric between our own posts and follows. As such, I have not touched Threads and keep telling IG the ads are not relevant to my interests. Presumably that is not your experience with it. It's wild how easily an algorithm can skew our perception. reply kevincox 9 hours agoprevThe fact that links are broken is a pretty serious flaw. But hopefully that will be fixed soon. reply EMCymatics 7 hours agoparentYikes. Who knows when I'll remember to look them up again. reply 8 hours agoprevnext [2 more] [deleted] anigbrowl 8 hours agoparentIt's a small dev team and they're very responsive and frank about their limitations/capacity/priorities. It's a web 1.0 community feel although thre's about 3m users. reply ulrischa 3 hours agoprevThe title displayed is not good At the moment: https://bsky.app/profile/ulrischa.bsky.social/post/3khanuwle... But all in all a nice feature reply loceng 7 hours agoprevWhat's Bluesky's revenue stream? Ads? reply steveklabnik 7 hours agoparenthttps://blueskyweb.xyz/blog/7-05-2023-business-plan reply p-e-w 6 hours agorootparent> Bluesky’s business model must be fundamentally different — we are a public social network and our code is all open source, so we have no “moat” when it comes to data. That's such a bullshit claim. The entity that runs the servers where the data is stored always has a moat. They can aggressively rate limit scraping and simply refuse to provide dumps, and suddenly, they are the gatekeepers to everything that actually matters. Open source has nothing to do with this. reply steveklabnik 6 hours agorootparentA few things: 1. while they're still not quite there, the protocol is federated, so they aren't the only servers storing your data once that happens. 2. because stuff is signed to your account, and other PDSes replicate posts, even if your host got weird, you could recover a lot of it. if you want to be extra sure, you can run your own PDS as well. I am not super up to date with how much replication various \"reach\" services store the firehose permanently, but should be possible to get content from them, for example. 3. I agree that open source doesn't prevent this. reply p-e-w 6 hours agorootparent> so they aren't the only servers storing your data That's only true if other large servers eventually emerge. \"Federated\" systems have a tendency to coalesce into a network wherein a few big players – often just a single one – dominate the ecosystem. Gmail, Matrix.org, the few Mastodon and Lemmy servers that actually matter, etc. are examples of this. Usually, this leads to the dominant servers dictating rules for everyone else under threat of defederation (already the status quo with Mastodon today). And at the end, you have a hyper-complicated federated system that operates the same way as the centralized systems it originally aimed to replace. reply steveklabnik 4 hours agorootparentSo, I absolutely agree with regards to normal federated systems. Your examples are examples for a good reason. But Bluesky works a bit differently. Users don't work as like, \"user@domain\", you have the moral equivalent of a UUID. If the host of your PDS decides to defederate with someone else's host, that doesn't mean you're prevented from getting their posts, it just means that like, it's a bit harder to. And if you don't like what your PDS's host chooses with regards to defederation, you move to a different one, and when you do, you retain your entire following/follower graph, and people who follow you don't necessarily even notice.. The closest way to think about it is git, IMHO. GitHub hosts a copy of your project (a PDS of your posts), and you can have one locally too. You can also put up copies elsewhere, and people can grab copies of your project elsewhere. If GitHub decides to stop hosting your project, you can put it up on another host, no problem. If GitHub decides to stop hosting a project you want to follow, you can follow where they move. This is in sharp contrast to email or Mastodon, though in my understanding, Mastodon has made it a bit easier to move servers lately. Most criticism of BlueSky/AT tends to be that it's too hard to do things like private accounts, keeping your block/mutelist private, or even deleting posts. (Though the latter is better now thanks to the addition of the moral equivalent of git rebase.) reply Zak 6 hours agorootparentprevThat hasn't been my experience with Mastodon. The servers most of the big servers block are overwhelmingly sources of harassment, extreme hate content, and media that might be legally classed as child pornography where those servers are hosted. The servers I've noticed being really picky about who they federate with tend to be smaller. reply steveklabnik 6 hours agorootparentprevI can't respond right this moment, but I suspect you may not understand the technical underpinnings of the protocol. It works very differently than Mastodon. I will elaborate later, unless anyone else chimes in :) reply pfraze 6 hours agorootparentprev> 3. I agree that open source doesn't prevent this. You can always erect walls around things. We at least try to poison pill it enough that if the company tried to, people would exit with the data first. Which is why internally we don't see us as having a strong moat around the data. reply steveklabnik 6 hours agorootparentYep! I think it's great that y'all are open sourcing stuff. Necessary, not sufficient. Glad you're going further than that. reply holmesworcester 3 hours agorootparentprevWhen I talked through the game theory of BlueSky with the founder, it seemed that it would tend more towards competition between a few large services with fairly nuanced and predictable moderation policies. It is very easy to move your account and your followers to a new server, so if a big server started operating in the way you describe a large exodus would happen fairly quickly. But you have to make sure you are on a server that isn't being blocked by the other large servers, e.g. Donald Trump's server, some spammer's server, or a server that is difficult to distinguish from a spammer (like your own small server) so there will be an incentive for popular accounts that value their reach to stay on big servers shared by many other popular accounts that are hard to block without users noticing. So, the situation isn't so bleak as you describe, but also, yeah, controlling the website or app called \"Bluesky\" is still a moat (until it's not!) reply abhibeckert 7 hours agoparentprevI'm pretty sure it's \"we will figure that out later\". reply methodical 7 hours agorootparentA bit presumptive but the answer to that is likely ads. Unless they try the whole premium subscription model like Twitter (X) and realize nobody cares that much to pay $5/mo for social media. reply hackernewds 7 hours agoparentprevit's a Jack Dorsey initiative so I'm sure it is \"cross-subsidization through Square's investors and balance sheet\" reply steveklabnik 7 hours agorootparentJack doesn't own the company, the employees do. He is on the board though. reply evbogue 5 hours agoprevBluesky launching RSS feeds is a direct result of Bluesky not being a distributed protocol. Yes, I know, it's aiming to be federated. But there are fundamental issues with the protocol they decided to go with that is keeping them from creating a social network that actually has self-authenticating posts. And all of this starts with their DIDs being a substring of the hash of your first post? It just doesn't make sense. In these kinds of systems you hash the data and sign the hash, then you can send a message that can be authenticated anywhere. And thus, RSS is one answer I guess. No one ever asked for an RSS feed of a Scuttlebot log back before that network was scuttled. Why? because you could authenticate the sender and the posts on your own computer. reply whyrusleeping 4 hours agoparentWhile individual posts are not self-authenticating (largely because it makes deletion much more complicated) all of a users posts are in a merkle-tree that it itself self-authenticating. A Post and the merkle-proof to the root its a complete verifiable entity. reply evbogue 3 hours agorootparentOur community can have the best of both worlds here. We can have the users sign their posts with a keypair on their own computer, and allow faux delete, and authenticate a merkle-tree back to the root. Delete can't be real because someone will always have their phone out there ready to screenshot your post. Imagine the @ protocol was `````` and that opened to `````` And the previous post hash could point to a post before a delete if we consider deletes to be real. The hashes are used to lookup the post content, which we could also send with the message for the sake of convenience. For key rotation we just need to sign a message pointing to our new keypair, no federated servers required! \"My new key is EVxe89AeRwmTT0hfrT7sHe0wAuzvH9Yvg9TFUgqPh4M=\" reply holmesworcester 3 hours agorootparentThe fact that someone can screenshot something does not make deletion not real. Deletion is still valuable for many threat models and day-to-day situations humans run into. As someone working on a p2p app that has done a lot of user research, I see it as a really good sign when a federated/p2p systems prioritize deletion, because I know based on my own research that it's something users care about and ask for. reply evbogue 3 hours agorootparent100% agree with you. You can allow the illusion of a delete, and also allow messages to be signed using a keypair. When you build the merkle tree you stop linking to the deleted post and link to the next best non-deleted post. BUT, if the content is already out there in a distributed system then you have to expect all of the nodes to respect your delete and not optimize for it. reply gumby 9 hours agoprevWish posts that require a login would at least appear in the feed. That would be like RSS feeds from a site with a paywall. If I logged into BS from my RSS reader I'd be able to see them. reply consumer451 7 hours agoparentYeah, that's kind of janky. Because in Bsky, there is a user setting to ~\"ask clients to respect login required.\" However, there are things like firesky.tv which access AT Protocol directly and I believe don't respect that setting. You can make a user RSS feed from firesky by using Filter and setting a user handle. At least I think I am responding to your issue... reply jazzyjackson 9 hours agoparentprevNow that you mention it Bluesky might actually find some adoption if they allowed monetizing private feeds (Is twitter doing this? I know you can monetize via subscriptions but AFAIK it's not a paywall, more of a tip). They'd compete for marketshare with patreon, substack and onlyfans combined. reply brundolf 8 hours agorootparentThe Bluesky protocol doesn't really allow non-public posts (which is why blocking doesn't work the way some people would like it to, and why there can't be features like Circles) I believe Twitter does support paid private posts that you can subscribe to, but I've never seen anyone I follow use it reply gumby 7 hours agorootparentprevSubstack has this working. I have some paid substack blogs in my RSS feed. Some give you part of the post in the feed and then you have to click on the post to see the rest (in you’re a subscriber, else not). Others just say “click here to read” and again, if you are a subscriber (I am) you see the post. reply atdrummond 7 hours agorootparentI’m surprised they don’t just use private RSS feeds for posts like they do for podcasts. reply gumby 7 hours agorootparentThis approach acts like a sales tool, which I think is better all around. reply ivanmontillam 8 hours agorootparentprevThere are Telegram bots that do paywall private channels, a few examples I can mention: - InviteMember (accepts most payment methods, including Stripe) - CanalFans (accepts only USDT, and it's only available in Spanish, South American focused) The way they work is that you add them to your private channel and the bot executes the sale, invites the member and kicks them out if they don't renew their subscription. Of course they take a commission on the sales. reply mananaysiempre 7 hours agorootparentOn a small scale, it’s probably also quite straightforward to roll your own using Telegram’s built-in bot payments API (which acts as a gateway to a number of processors including Stripe). Not sure if one should, but it’s a possibility. reply ivanmontillam 7 hours agorootparentI've looked into it from the technical side, and it's not that straightforward. I mean, yes, it's on the scope of a toy project, but it's definitely not on the scope of a weekend project. My software development estimation looks like at least 2-3 months with at least 3 hours daily on the IDE (on the Subscription Management side, ignoring the payment gateway, that as you mentioned: it's on Telegram already). reply stevebmark 9 hours agoprevThis doesn't really matter. The Bluesky app has very few features, it's still invite only which limits the number of users, and engagement and active users are low. It's on a trajectory to death right now. The core of Bluesky, relay/BGS, still isn't proven. Over a year after launch there hasn't been significant progress in these areas. reply olah_1 8 hours agoparentI said 8 months ago that the invite system would be the death of BlueSky[1]. I think that’s true. Just like clubhouse, but the time they actually open it up, hype is gone. [1]: https://news.ycombinator.com/item?id=35754628 reply cogman10 8 hours agorootparentWhy do they still have it? They are super late to the \"twitter replacement\" game. The only thing carrying them is jack Dorsey's name and that's slowly slipping into irrelevance. reply TheAceOfHearts 7 hours agorootparentJack Dorsey moved his support to Nostr, I don't think he has any involvement with Blue Sky. Jack doesn't even have or use a Blue Sky account, to the best of my knowledge. I generally wouldn't trust any social media app that's not used the leadership. Threads is still half baked but at least Mark uses it regularly. And Elon is regularly posting on Twitter. reply olah_1 5 hours agorootparent> Jack Dorsey moved his support to Nostr Some part of that is due to the design of BlueSky. But I think most of it was ironically due to the invite system simply existing. Jack wanted an open platform. reply Retr0id 7 hours agorootparentprevThe invite system is ostensibly rate limiter and moderation tool, rather than a hype machine. They've mentioned getting rid of it soon. Maybe they \"missed the boat\" in some sense, but I'd rather see steady and sustainable growth. Dorsey hasn't been doing them any favours for a long time, he's all but publicly disavowed it, deleting his account to focus on nostr. He's still on the board of directors last I heard, but if his public statements are anything to go by, he's not actively involved. reply xmprt 7 hours agorootparentWith a social network, steady and sustainable is usually not an option. If they don't have a strong launch when they remove the restrictions they'll fade into irrelevance within a few weeks. Threads had a surprisingly strong launch and it still has an uphill battle to climb if it wants to challenge Twitter and that's in spite of all the ways Twitter is attempting to self-sabotage. reply Retr0id 7 hours agorootparentExplosive growth is not a requirement. Take a look at reddit's long-term trajectory, for example. It's remarkably linear (although I have a feeling it's not going to continue for much longer) reply olah_1 5 hours agorootparentReddit’s value is the historical content. Old content on a feed-based app is literal garbage, however. reply Hamuko 4 hours agorootparentprevIsn't Threads kinda proving that explosive growth isn't a requirement to a successful social network? reply threeseed 3 hours agorootparentThreads is backed by Meta so can survive for decades running at a loss. Not sure if the same applies to BlueSky, X, TruthSocial etc. Social networks typically demand large user bases because it goes hand in hand with advertising. reply add-sub-mul-div 8 hours agorootparentprevLetting in the eternal September from Twitter would be its death. Threads can be about hype. reply TillE 8 hours agoparentprevBluesky invites have been abundantly available for months now, and they're processing the waitlist directly if you don't feel like asking someone. I've found engagement is surprisingly high, much much higher than Mastodon, but of course it depends on the niche. reply dorfsmay 6 hours agorootparent> Bluesky invites have been abundantly available for months now Only in a bubble where everybody already has an account I suspect. reply Hamuko 4 hours agorootparentI've been giving away my invites on Twitter and it has become increasingly more difficult to find any takers. I think I'm currently sitting on like ten invites since my friend is feeding me his spare invites too. reply Klonoar 2 hours agorootparentSame, I’ve more invites to hand out than I know what to do with. reply a_bonobo 8 hours agoparentprevBlueSky has for some reason far more biologists than Mastodon: Searching for 'PAG31', a currently ongoing large plant and animal genomics conference, reveals about 20 different posters on BlueSky with about 60 posts and only two posters on Mastodon with four posts (one's a company). Twitter/X still has more posts than BlueSky, though. Scientists are creatures of habit. reply quinncom 3 hours agorootparentThat’s probably because many people have not enabled search indexing on their Mastodon accounts. If instead you search for the #PAG31 hashtag you’ll find nine different posters (still too few, but more than two). reply numpad0 7 hours agoparentprevI think the invite system worked. They managed to keep high-bandwidth low-effort users out until nicest of online people recreated early-Twitter-like culture, unlike how Mastodon Fediverse had gone with flood of empty calories trying to make a big exodus happen. There are probably lessons on how to build a successful social medium, more so than about architecting a technically scalable system. reply wraptile 4 hours agorootparent> They managed to keep high-bandwidth low-effort users out until nicest of online people recreated early-Twitter-like culture You say that as if it's a good thing. Bluesky turned into one of the most toxic networks out there. Just browsing the discover feed should dispell any illusions of a healthy community - most posts are whining about american politics or whining about some other unimportant memes like AI art instead of fostering growth about common interests like Mastodon does. Bluesky had their chance with invite only and curated feeds (with some really dedicated community admins) but they've fumbled it all by focusing on american culture wars instead of the nice thing they had. reply JeremyNT 7 hours agorootparentprevPersonally I would agree. Of all these services Bluesky is the only one I have an account on and actually use directly (I \"use\" Twitter indicrectly via Nitter). I was actually excited to get an invite. It just feels... cleaner somehow. The slow trickle has, I think, kept it from being overrun by low effort posters and bots. reply johannes1234321 8 hours agoparentprevBlue sky invites are plenty. But they make it quite likely that when you join, you directly find your peer group there since that's where you got your invite from. You directly know a person to follow and via their posts, repsots, followers, ... directly find a network. If you open without connection to any of your peers you first have to find anybody who is active. reply jsbisviewtiful 6 hours agoparentprevI signed up for a login directly from the site and got one quickly. It was pretty easy to get access overall. Now that I’m on the site though, I feel the same about it as I do Twitter: a) Most posts are uninteresting, exist to virtue signal or are by people who _think_ it’s important to try desperately to be funny (which they often are just cringy and not funny) b) It’s extremely confusing to know any context on a reply post when it’s reply 22 of a 39 reply long thread c) It’s not fun or engaging. It doesn’t really add anything to my life d) I don’t want to post myself because inherently I, like many social media users, have nothing worthwhile to say to the digital world - so I choose not to post while others force it anyway. It’s not my cup of tea and I’ve considered deleting the login a few times. I think I’ve just outgrown traditional social media. reply JeffSnazz 8 hours agoparentprev> The Bluesky app has very few features, This doesn't really matter. It's replicated all of the features that matter, twitter has very few user-facing features that matter anyway. The only thing preventing Blu Sky from succeeding is user interest. reply loceng 7 hours agorootparentAre all users paying - or users are the product? reply steveklabnik 4 hours agorootparentThey will be offering paid services in the future (see my link above) but only one has shipped yet: a partnership with namecheap to make it easy to get your handle as a domain name without technical knowledge. reply threeseed 7 hours agoparentprevIt was always going to be a struggle to compete with Threads. But if you don't bring your A-game when you're competing against the world's best social media company then what is the point. Meta is already feeding behavioural data into Instagram's ads which means they have no need to monetise it anytime soon. And the free advertising they are running on Instagram/Facebook is bringing in new users at a rapid pace. What advantages does BlueSky have ? And the fact that there are no AT protocol servers means that you have the ActivityPub ecosystem with such a huge head-start and likely set to dominate in 2024. reply Intralexical 5 hours agoparentprevThey're apparently getting registrations at a steady linear rate though: https://commons.wikimedia.org/wiki/File:Bluesky_Registered_U... reply pfraze 6 hours agoparentprevIf we had ditched invites we never would've been able to ship the open network / relay system. As it stands we're on track for open hosting in Q1¹. Same story with features. We didn't deprioritize the protocol because that's core mission, so we had to put resources there instead of into features. Features will accelerate as core stabilizes. Shipping a novel technology, building a product, and growing a userbase all at once isn't easy. I wouldn't declare us dead unless we've missed the boat so badly with market timing that nobody bothers, but we have good runway and (IMO) a pretty solid community of users. ¹ Probably. Maybe. Pretty sure. reply mattl 8 hours agoparentprevI have so many Bluesky invites, I think most people do. If anyone I know needs one, I have one for them. They sign up and they will immediately have people they know to follow. I stopped giving them away to random people. reply EGreg 7 hours agorootparentSend one to me. greg at the email qbix.com reply px43 5 hours agorootparentbsky-social-pwjar-yjsxa bsky-social-zweux-qaqar bsky-social-4il6n-kuumm bsky-social-n23po-7dedu bsky-social-7fey2-v5fw6 reply mattl 7 hours agorootparentprev> I stopped giving them away to random people. reply EGreg 7 hours agorootparentWell, some people are more random than others! For example I dated this girl who was always stopped for a random search in an airport. reply gtirloni 9 hours agoprevLike every Mastodon user apparently: https://www.rssboard.org/news/211/every-mastodon-user-has-rs... reply panzi 7 hours agoparentYeah, would be even better if it where atom feeds with pagination, IMO. reply panzi 8 hours agoprevI for one don't understand why one would switch to yet another corporate controlled social network. Have people learned nothing? reply Mortiffer 9 hours agoprevnext [2 more] [flagged] codetrotter 9 hours agoparentOP link or the Bluesky RSS feed? OP blog post loads for me. Edit: OP article seems to be unstable for some. Read a copy of it here instead if it doesn’t load for you: https://archive.is/DiT6I reply YetAnotherNick 8 hours agoprevnext [9 more] [flagged] soap- 7 hours agoparentatproto cannot have ads and Jack Dorsey hasn't been involved in months. he's off on nostr, it was never his platform reply djur 8 hours agoparentprevBluesky doesn't have ads. reply Fabricio20 8 hours agorootparentYet. reply Retr0id 7 hours agorootparentIt is plausible that they'd put ads in the (open-source) official client, but the way the protocol works, it'd be hard for them to force out 3rd party clients (a la reddit). reply rodgerd 7 hours agoparentprev> Jack is all aware of That's great, but he's not a director of bsky or involved in management, nor does he post. reply greyface- 7 hours agorootparentThis is underselling his lack of involvement - he completely deleted his account last year. reply adaboese 7 hours agorootparentWho is running the show? reply greyface- 7 hours agorootparentJay Graber, CEO of Bluesky Social, PBC. reply heavyset_go 6 hours agoprevI love RSS, but I predict that these will be removed at some point. With RSS, you can't gauge impressions and engagement with content, and you can't force all sorts of ads into people's feeds. reply keyle 9 hours agoprevnext [4 more] [flagged] Retr0id 8 hours agoparentYou're worried about RSS getting extinguished? reply captn3m0 8 hours agorootparentTwitter used to have RSS feeds as well, long time ago. reply Retr0id 8 hours agorootparentDid it harm RSS as a whole, when they stopped? reply christiangenco 8 hours agoprevnext [10 more] [flagged] yosito 8 hours agoparentThat question kind of seems like bait, and that incident has nothing to do with why one platform is better than another. And your conclusion is to go back to a platform that's being run to the ground by a combination of a terrible CEO and nefarious political influence? Well, I won't argue against your freedom to make your own choice here, but I don't see the logic in it. reply drstewart 7 hours agorootparent>And your conclusion is to go back to a platform that's being run to the ground by a combination of a terrible CEO and nefarious political influence? Speaking of bait questions... reply icehawk 7 hours agoparentprevThat is so very close to the sort of \"innocent\" question I would get on twitter from people that would then try to use bad faith arguments. That goes doubly so if you didn't have any sort of regular interaction or rapport with the OP before asking that question. reply hoseja 21 minutes agorootparentWhen even the most basic, logical, obvious line of questioning exposes your insanely racist oikophobic ideology, maybe being \"bad faith\" does not disqualify an argument. reply tptacek 8 hours agoparentprevThat's a question that's hard to ask without pattern matching with a lot of tedious, dark stuff, and nobody on social networks is thinking carefully or applying even a fraction of the energy the HN guidelines ask, so you're just getting pattern matched. There's not much to do about it. Complaining isn't going to change it. It works in similar ways in all communities --- even here, though the specific patterns might occasionally be different. I'm not rooting for Mastodon (I think Mastodon has the better story, and, for me, much better apps). And it is the most cliquish of the three major alternatives in the space. But this specific criticism isn't very probative. Mastodon > Bluesky > Twitter. reply consumer451 8 hours agoparentprevInitially, I had some No True Scotsman type interactions which I didn't enjoy one bit, but I stuck with it, and now it's where I spend a decent amount of my time. There is a good representation of scientists, journalists, and other groups which I enjoy. It's now >3M users, where as when it was the hot new thing, I think it wasWhat is it about journalists that you enjoy? Their job is to seek the truth, many fail, but the goal is admirable. I actually push myself to read views that I don't entirely agree with, within reason. > In any case, based on what OP describes, and the groups you mentioned, is it fair to say it's a hothouse of left wing political discourse? Compared to X? Oh, yes. Personally, I am a non-US centrist, which I think makes me pretty-left on most issues from a 2024 US political POV. Lots of gay and trans people who are not being attacked as well, so that's nice. There is a large pro-EU/anti-authoritarian contingent, which I very much enjoy more than anything. reply oxonia 7 hours agoparentprevThat was my experience with Mastodon. Discussions tended to turn shrill and regularly be dominated by extremes. reply PaulHoule 7 hours agoprev [–] It beats Facebook's plans to integrate w/ ActivityPub because they actually did it but I will point out some advantages of ActivityPub over RSS because polling with RSS is terribly inefficient as you have to keep polling a file over and over again asking for changes whereas ActivityPub lets you ask for what you haven't read already. reply threeseed 7 hours agoparent [–] Threads has already started testing bi-directional follows with ActivityPub. And the plan is to rollout a \"mixed Fediverse and Threads experience where you will be able to follow Mastodon users within Threads, and reply to them and like them\" by late 2024. http://plasticbag.org/archives/2024/01/how-threads-will-inte... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bluesky has introduced RSS feeds, enabling users to access an RSS feed for any Bluesky user, facilitating the discovery of user feeds through RSS readers and browser extensions.",
      "The RSS feeds only include public posts and do not include links. Users can offer feedback to Bluesky to enhance the RSS feeds.",
      "Open RSS, which relies on voluntary donations, also provides their version of Bluesky RSS feeds."
    ],
    "commentSummary": [
      "The discussion centers around Bluesky, a potential replacement for Twitter, and covers various topics such as biased content recommendations, the need for AI filters, and data security concerns.",
      "Users also explore Bluesky's unique features, financial sustainability, limited user engagement, and self-authenticating posts.",
      "Other discussions touch on Bluesky's invite system, toxicity on the platform, comparisons with other social media platforms, and users' experiences and opinions. The involvement of Jack Dorsey, the future of RSS feeds, and the pros and cons of Mastodon are also mentioned. The future success of Bluesky is uncertain amidst competition."
    ],
    "points": 262,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1705363540
  },
  {
    "id": 39003417,
    "title": "The Rise of Onigiri: Japan's Comfort Food Revolution",
    "originLink": "https://one-from-nippon.ghost.io/onigiri/",
    "originBody": "Jan 15, 2024 6 min read Posts Japan's Comfort Food: The Onigiri Source: 5th Luna Walk into any Japanese convenience store and you will always find a shelf dedicated to one item: onigiri. The onigiri, often translated as “rice ball”, literally means “grasping a fistful” and is in many ways Japan's original fast food, before fast food. Quick to make, quick to eat, easy on the wallet, reminds you of home, and unreasonably delicious! What is an Onigiri? The simplest onigiri has just two ingredients: rice, and salt. Cook the rice, salt it, and gently press ~100g of the fluffed rice into a triangular shape. Really, that is all there is to it. To impart an interesting taste, one could also wrap the onigiri in a sheet of nori (dried seaweed). The nori gives it a crunch and brings contrasting flavors that complement the rice. A simple onigiri Onigiris can also have fillings. Traditional fillings include pickled plum, bonito, and seasoned seaweed. Onigiri with sea urchin filling Source: Hideya HAMANO Finally, you also have the mixed-into-the-rice onigiris, where a variety of ingredients are cooked with the rice. Making onigiris has lots of parallels with making eggs: simple to make but devilishly complex to master. People can be veeeryyy specific about “The Right Way ™” to eat an onigiri. Some people think onigiri is best eaten cold, while others disagree vehemently. Personally though, the feeling of opening your warm onigiri and seeing the aroma waft out ... chef's kiss A (Brief and Incomplete) History of the Onigiri Archeologists have unearthed onigiri-like foods from ruins that date to about 2,000 years ago. Today’s onigiri, though, really rose from post-war Japan’s economic miracle. When talking about WW2 and Japan, most people remember the nuclear bombs dropped on Hiroshima and Nagasaki. What often remains in the shadows is the large-scale carpet bombing that Allied forces undertook over large parts of Japan. These raids flattened whole cities overnight. After Japan surrendered, rebuilding the nation required every adult (and often children) to work to the bone. And they did. This is where the roots of Japanese workaholism started. To support this increasingly busy population, supermarkets started stocking convenient and familiar foods. Onigiri was first sold at supermarkets in 1952. This is interesting because onigiri was never a food that you bought or ate outside. It was something you made at home and packed into a lunch box. Konbini and Onigiri The onigiri shelf at a convenience store never disappoints Source: Nullumayulife The meteoric rise of the onigiri is inextricably tied to the story of convenience stores in Japan. (Psst: We wrote about those here) Konbini (Japanese for convenience store), which were open 24x7 wanted to provide their customers with familiar, fresh, and healthy food at a price that made sense. They focused on lunch boxes (bento) and onigiri. 7-Eleven was one of the first convenience stores to stock onigiri, starting with traditional flavors like pickled plum, mentaiko (spicy cod roe) and kelp. Competitors were quick to recognize the demand and flocked in. Soon every convenience store chain had their own brand of onigiri. 1980s 7-Eleven commercial for onigiri Each chain was competing on freshness, taste, variety, well-stockedness, and most importantly, the nori. This competition heated up so much that at one point newspapers started calling these “The Onigiri Wars”. Rice, Seaweed, and Whole Lot of Engineering The story of the onigiri’s rise to stardom is also the story of Japan’s engineering prowess. See, onigiri in its most basic form could just be a ball of rice wrapped in nori, in a cling wrap. But then the nori would be stuck to the rice and would be soggy by the time the customer bought it. Many people didn’t like this. There is a long-running rivalry between the east and west of Japan. Kansai (west) includes cities like Kyoto and Osaka, and Kantou (east) includes Tokyo and Yokohama. For reasons the author doesn’t understand well, the people of Kansai and Kantou pride themselves on these differences. Hell, even electricity is different between these two regions (one runs at 50Hz, while the other is at 60Hz). The people of Kansai and Kantou prefer their nori differently as well. One side likes them soggy, while the other likes them crisp. You will not believe just how much money has gone into solving the engineering problem of “I want my nori to be crisp but I also want the rice to be moist and fluffy”. The \"Separate Method\" The first onigiris on the market used the “Separate Method”, where the onigiri was wrapped in a double walled pack. The double walled pack contained a sheet of nori. Customers would open the nori and then wrap it around the onigiri. It worked, but many hated how clumsy it was. The Parachute In the early 80s, Shinobu foods, a company from Osaka, came up with a brilliant invention called the “Parachute Method”, where the nori and onigiri were separated by a umm.. rip cord. One pull from the top gave you a soft onigiri wrapped in fresh nori. Watch the parachute in action in this 1985 commercial However, because they had to use oil to make the parachute pull out smoothly, the onigiri tasted different and people were displeased. The \"Cut Tape Method\" The next iteration came from 7-Eleven, called the “Cut Tape Method”, where customers simply had to tear a tape running vertically through the packaging. This didn’t use any oil and forms the basis for today’s onigiri packaging. 1:02 - 1:17 showing the Cut Tape Method in action The \"Cut Tape Wave Method\" Not to rest on their laurels, 7-Eleven engineered the pack to make it even easier to tear and landed with the “Cut Tape Wave Method”, where the packaging tears apart further, making it easier to open: \"Cut Tape\" vs. \"Cut Tape Wave\" Source: TBS After 50 years of innovation, this is where Japan has landed: The high-tech, elegant way of opening an onigiri Always New and Yet the Same The onigiri is a versatile, low-maintenance food. In a country hit by natural disasters often, the onigiri is always one of the first things made and handed out in evacuation shelters. Members of the Japanese Self-Defense Forces making Onigiris during the 2011 Fukushima Disaster Source: Wikimedia Japan consumes billions of pieces of onigiri every year and the humble onigiri keeps getting better. Every year new flavors are introduced, and companies try new combinations of rices, ingredients, and preparation methods. And yet, every year it still feels like the same, familiar onigiri from years ago. That is an enduring testament to this wonderful food! We hope you enjoyed this article! If you haven't already, we would love it if you subscribed to our newsletter. It would encourage us greatly to create more interesting posts like this. Sign up from below ↓",
    "commentLink": "https://news.ycombinator.com/item?id=39003417",
    "commentBody": "Japan's Comfort Food: The Onigiri (one-from-nippon.ghost.io)256 points by zdw 16 hours agohidepastfavorite108 comments anigbrowl 13 hours agoThere is a long-running rivalry between the east and west of Japan. Kansai (west) includes cities like Kyoto and Osaka, and Kantou (east) includes Tokyo and Yokohama. For reasons the author doesn’t understand well, the people of Kansai and Kantou pride themselves on these differences. The shape of the country historically made for roughly bipolar military confrontations, involving shifting alliances between the many warlords. Centuries ago, Kyoto was the Imperial Capital and Osaka the economic capital. West of Japan are Korea and China, and the commercial and cultural trade made the region wealthy and powerful. Near the end of the 16th century, a warlord named Nobunaga managed to unify most of Japan, but was betrayed by an associate. An intense struggle for control ensued, culminating in a battle at Segihara in 1600, which is more or less the middle of the country. The winner, a general named Tokugawa Ieyasu, became a Shogun (military governor, nominally in service of the Emperor but pragmatically in charge) and was based in Edo, now named Tokyo. His defeated rival was based in, you guessed it, Osaka. Edo was just a small fishing village with a broken-down castle until Ieyasu showed up around 1590, rebuilt the castle, and made the area into his base. After winning the battle of Segihara he was mostly generous in victory, but required other warlords to maintain households in Edo (making them de facto hostages) and contribute money and labor to build out the infrastructure there; within 5 years Edo was a large city of ~150k. Tokugawa also closed the country and banned foreign trade, not least to prevent his rivals from raising armies and capital overseas. His family continued to rule Japan until the Shogunate was abolished and the country opened up the outside world in the 19th century. Edo was renamed Tokyo and made the official capital, although the Imperial family continued to reside in Kyoto until Emperor Taisho moved to Tokyo in the early 20th century. reply tkgally 9 hours agoparentSome additional reasons for the rivalry between East and West are language and demography. The dialects of Japanese spoken in Osaka, Kyoto, Kobe, etc. are distinct and different from both the colloquial Japanese spoken in Tokyo and the standard language that is taught in schools and used in broadcasting. A person from Osaka who visits Tokyo is immediately identified by their accent and vocabulary. This makes people very aware of where they and others come from within Japan. Also, Tokyo is similar to cities like New York and London. While there are people who have lived in Tokyo their whole lives and whose ancestors also lived in Tokyo, since the 19th century the city has drawn waves of immigrants from throughout Japan. This makes it something of a melting pot for ethnic Japanese. While Osaka has also drawn outsiders, it has a larger core of people who have lived there for generations. This creates a sense of loyalty and attachment to the home area and to the food eaten there. That localism is amplified by the mass media. A popular topic on television quiz shows is differences in food, speech, and behavior between eastern and western Japan. reply glandium 9 hours agorootparent> A popular topic on television quiz shows is differences in food, speech, and behavior between eastern and western Japan. A popular topic on television quiz shows is differences in food, speech, and behavior in various parts or Japan. It's not only Eastern vs. Western. It's prefectures vs. prefectures. Hyogo vs. Fukuoka vs. Akita vs. Ibaraki, vs. etc. This regionalism is amplified by the fact that there aren't, actually, fully national TV channels (except for NHK, with exceptions for the news). So for example, I live in Aichi, which is between Kantou and Kansai. The channels I have are: Toukai TV, NHK, Chukyo TV, CBC, Meitele and TV Aichi. They are part of broader networks, so for instance, Toukai TV is \"mostly\" Fuji TV, Chukyo TV is \"mostly\" Nippon TV, CBC is mostly TBS, Meitele is \"mostly\" TV Asahi and TV Aichi is \"mostly\" TV Tokyo. \"Mostly\" because they all have local programs or even sometimes programs from Kansai instead of whatever might be on air in Tokyo on the corresponding channels. To give an example of a program I can watch on Chukyo TV, that can't be seen in Tokyo and some other areas: https://www.ytv.co.jp/iinkai/area/index.html (it's produced by Yomiuri TV, which is from Osaka) reply glandium 11 hours agoparentprev> Segihara Sekigahara reply anigbrowl 8 hours agorootparentOh dear, how embarrassing, and now it's too late to fix. Sorry about that and thanks for the correction. reply Jensson 12 hours agoparentprev> Edo was renamed Tokyo and made the official capital It is funny that they just reversed Kyoto when they picked that name. I wonder why they did that. Edit: Apparently \"kyo\" just means capitol and Tokyo is eastern capitol and Kyoto is capitol city. But it wouldn't surprise me if they picked those names as a pun to make the names similar. reply mistermark 11 hours agorootparentTurns out they didn't, quite. Tōkyō is East Capital, the Tō is 'East'; Kyōto is Capital City, the To being 'City'. Kyō is the same in each. reply glandium 11 hours agorootparentWhat they did, though, is change Tokyo from a fu (符) to a to (都). Tokyo is the only to, and there wasn't one before, they came up with it for Tokyo. There were other fus, but there are only two left nowadays: Kyoto-fu and Ōsaka-fu. Why do I mention this? Because Tokyo-to is written 東京都. Kyoto is written 京都. Remember that 東 means East. And yes, there are places in the east of Kyoto that carry the name 東京都 (higashi-Kyoto, higashi being another reading of the character 東). This has to be a troll. reply alangou 16 hours agoprevThere is no feeling so reassuring in Japan as knowing I am always within a 3 minute walk of yet another tuna mayo onigiri. reply boringg 15 hours agoparentDid you ever see whole grain rice onigiri or was it always white short grain rice? I feel like whole grain would be blasphemy over there. reply kurthr 14 hours agorootparentThe onigiri would not stick together. The short grain rice has lots of amylopectin, while whole grain, brown, and basmati have much less. It would fall apart and be very difficult to eat. reply SECProto 10 hours agorootparentThe amylopectin details may be right, but the rest is wrong. Conbini's sell brown rice onigiri (look for 玄米), it's just usually a very limited selection. They don't fall apart, and you eat them the same as normal onigiri. reply kencausey 10 hours agorootparentHave you checked the list of ingredients to check for a binder of some sort? reply kencausey 9 hours agorootparentAfter posting this comment I then decided to look into it (in my usual way) and just looking for homemade brown rice onigiri what I found was that at least the couple of recipes I looked at used short grain brown rice (which I did not even realize existed) and/or recommended using more water than usual. reply jkqwzsoo 5 hours agorootparentWhole Foods carries a store brand short grain brown rice at a reasonable price that I really like. It’s one of my go-to rices and essentially the only thing I go to Whole Foods for, as I haven’t found a comparable product or price point elsewhere. I think it’s about $2.50/lb these days. I just finished some tonight, and I’m certain it’s sticky enough to hold its shape. reply SECProto 7 hours agorootparentprevYup, if you want to do it at home, make it a little bit mushier. I don't like it, but it is very doable. Commercially they may use a binder, I don't know, I just wanted to make sure people knew they're available! reply boringg 6 hours agorootparentI did it tonight and when i picked up the rice i used wet fingers to give it just a touch more binding ability. Worked well. Kids loved it. Am excited to eat the brown rice onigiri tomorrow. reply schwartzworld 7 hours agorootparentprevWhy would short grain brown rice have less amylopectin than short grain white rice? reply JoeAltmaier 7 hours agorootparentBecause all the different rices are quite different plants? I think. reply schwartzworld 6 hours agorootparentThere is no white rice plant. It's all brown rice with the bran removed. Brown short grain rice doesn't have different starches than the same rice without its bran. reply skhr0680 15 hours agorootparentprevIt's not blasphemy per se. Wholegrain rice is popular for health reasons, and convenience stores carry wholegrain onigiri sometimes reply wahnfrieden 15 hours agorootparentprevWhole grain rice and rice with beans in it are very popular in Japan in recent years with mainstream health conscious consumers (Similarly plant based food has also become much more available in cities) However the health benefits of brown rice are questionable when the outer layer retains pesticides or other toxins reply LiquidSky 15 hours agorootparentprevWhy would anyone ever voluntarily eat a whole grain rice onigiri? reply bobthepanda 15 hours agorootparentWhite rice has one of the highest glycemic indexes. Japan has a 12% diabetes rate, which is just above the US at 11%. reply tenpies 10 hours agorootparent> White rice has one of the highest glycemic indexes. This is correct, but do keep in mind the impact that cooling down has on starches. A fresh bowl of rice is very high, but cool it for a couple of hours and the GI drops considerably. Cool it overnight and it drops even more. Onigiri is usually in the cooled down to over-night range. This never makes rice particularly good from a GI perspective, but preparation is a considerable factor. --- One study, but this is fairly well reproduced: https://pubmed.ncbi.nlm.nih.gov/26693746 And a more general write up: https://www.diabetes.org.uk/guide-to-diabetes/enjoy-food/car... reply gnicholas 15 hours agorootparentprevIIRC sticky rice is the worst among white rices. I find it tasty but try to eat basmati most of the time. reply slothtrop 14 hours agorootparentprevthis says it's 7% in Japan: https://worldpopulationreview.com/country-rankings/diabetes-... , but I found another source that says 12% for 2016. Diabetes scales with obesity and age. Japan has a very old population, but less obesity than the US. White rice despite its glycemic index is not super high calorie. If it's a contributing favor, it's because of weight-gain, not glycemic index. edit: better source: https://www.diabetesatlas.org/data/en/country/101/jp.html, https://www.diabetesatlas.org/data/en/country/211/us.html There's more diabetes in the US. reply riversflow 15 hours agorootparentprevI don’t get that. I would say the same about white rice. Why would I ever eat it when I could be eating delicious black rice? And before you start, I eat a gō of rice virtually every day. I’m genuinely confused about the popularity of white rice. reply Modified3019 15 hours agorootparentI had no idea black rice existed until you mentioned it. I imagine that this is likely the same for many others. reply fuzztester 13 hours agorootparentBlack rice exists, I've seen it in a shop of a friend, though not tasted it. https://en.m.wikipedia.org/wiki/Black_rice There are also other food items which have versions that are black in colour, some of which could be not naturally, but by processing them in some way, for example, black garlic. https://en.m.wikipedia.org/wiki/Black_garlic Googling your favorite food name with \"black\" as a prefix could be interesting. ChatGPT, generate for me a program to automate this, given a list of favorite foods. reply ace2358 13 hours agorootparentprevDon’t forget red rice! Rice is crazy and my old ideas of wetlands and white rice have been crushed by reality. reply milesvp 13 hours agorootparentprevBlack sticky rice is a favorite dessert of mine. I always have to resist it when I see it on a menu at a Thai restaurant. reply smugma 11 hours agorootparentprevWhat is gō? It is hard to Google. reply layer8 11 hours agorootparentIt’s the Japanese equivalent of “cup” as a measurement unit, and at 180 ml is about 76% of a US cup. Japanese rice cookers are marked and filled in units of gō. You put n gō of uncooked rice in it, and then fill water up to the n mark. One gō is roughly 150 grams of uncooked rice, which amounts to around 530 kcal. Traditionally, a wooden box was used to measure one gō: https://commons.wikimedia.org/wiki/File:Masu,_One-Gō_measure... reply legerdemain 11 hours agorootparentprevA Japanese measuring unit for rice, kind of analogous to \"one cup\" in US kitchens. Measuring cups distributed with rice cookers are usually one gō in volume even in the US. reply KptMarchewa 9 hours agorootparentprevBoard game. You place one rice grain at the first field and double it for each next field. Eat it all. reply Cpoll 11 hours agorootparentprev\"go of rice\" works. It's 3/4 cup. reply Hikikomori 13 hours agoparentprevHad so many tuna mayo onigiri from 7/11 for breakfast in Japan. reply glandium 11 hours agoparentprevYou've never been to the country side. reply snvzz 11 hours agoparentprev3 minute and a little over 100 yen. reply traeregan 15 hours agoprevI've been on two trips to Japan - 2014 and 2023. We enjoyed eating a lot of onigiri on both trips. During the latter trip I noticed that the ¥ price hadn't changed much but the amount of filling (various proteins) had gone down considerably, which makes sense from a business perspective. We've tried making them at home a couple of times but haven't perfected it yet. Reading this is motivating me to give it another shot soon. reply neom 15 hours agoparentOh don't get me started. In Korea, the size of the samgakgimbap has increased in some cases, and the price DECREASED in some cases... but the filling, ugh....!!!! Not only has the amount of filling decreased, but the quality is going down. Some of the tuna mayo ones have basically no mayo in them anymore, the tuna quality has also gone down. If I wanted rice and seaweed I'd buy rice and seaweed...!!!! And this isn't just CU/711/etc, it's everywhere!reply wahnfrieden 15 hours agoparentprevYou can find onigiri at independent shops not only convenience stores, with good price and better fillings/quantity. Convenience stores seem cheap compared with America but everything they sell is expensive locally There are also onigiri adjacent foods worth exploring like tenmusu. I love this tiny place in Tsu (Mie prefecture capital) that serves 6 of them with soup for about $3, a full meal offered with dine-in, even though it’s now Michelin recommended. It's probably 1/3 the price of convenience store onigiri per unit cost and it's freshly made to order. reply dec0dedab0de 15 hours agoprevAlso known as jelly filled donuts to american fans of pokémon. reply bigstrat2003 14 hours agoparentOr dumplings, for people who played Xenoblade Chronicles 2 in the West. reply bitwize 10 hours agoparentprev\"Boy, I sure am glad we stopped for hot dogs!\" \"Yes! And... these flavor sticks really added to the taste!\" https://www.youtube.com/watch?v=FrriBr-46_I The opening to each stage of Alex Kidd featured the title character happily munching an onigiri. Sega changed it to a cheeseburger for the USA release of the game. reply wexomania 12 hours agoprevI love onigiri, but find it difficult to make them into triangles, I got frustrates one day, threw all the ingredients into a bowl and stirred, and I have enjoyed Onigiribowl(patent pending/s) ever since. reply layer8 10 hours agoparentThe trick is to use the bend of your hand as a mold for each side. I’m sure there’s a multitude of YouTube videos showing how. reply ricardobeat 11 hours agoparentprevThat’s kind of what chirashizushi is, it just usually has a lot more complex toppings and you don’t stir them into the rice. You can also buy a triangle-shaped rice press and ready-made onigiri packaging at any japanese grocery store, makes it a lot easier. reply lidavidm 12 hours agoparentprevYou might enjoy takikomi gohan. reply blackcat30 9 hours agoprevThe best Onigiri are the ones that you nigiru yourself, homemade. Konibini Onigiri are convenient in a pinch, but they pale in comparison to homemade ongiri from some who know the right nigirikata techniques. Plus, homemade has way more variety, the choices of what you can put in them and mix with them are endless, furikake is great for making ongiri. I wouldn't consider it a comfort food, I think it would be more correct to compare it to the likes of a sandwich in many Western countries. reply maxglute 3 hours agoparentYeah I found most convenience store Onigiri extremely mid, like vending machine sandwichs until I had some home made ones. reply tmm84 8 hours agoparentprevI agree, they most closely resemble sandwiches from Western cooking. I think Konbini ones are just bland most of the time. A few of the super markets that make their own seem to taste better in my opinion than the Konbini ones. I do think the onigiri with tempura on the inside is a real treat. However, sometimes I want just plain salted rice ones if I am in a rush and eating pre-made super market foods. reply sorokod 14 hours agoprevThere is a cheap triangular contraption which allows you to make onigiri yourself to your preferred specification. You may want to invest in proper rice and nori, it is smooth sailing after that. reply Tiktaalik 15 hours agoprevPractically lived off of 7/11 onigiri for lunches when I was last on vacation in Japan. Apparently some local 7/11s now stock onigiri. I'll have to try it out. Hope it takes off. reply lawgimenez 16 hours agoprevWe have our own version here in the Philippines https://cookpad.com/us/recipes/12323830-puto-mayasticky-rice reply xedeon 14 hours agoparentThat’s more of a dessert isn’t it? Onigiri are typically savory. A closer comparison would be pusô or tamu from Cebu. Also known as “hanging rice”. While pusô itself usually contains plain rice, it is often eaten with savory dishes or as part of a larger meal. reply lawgimenez 9 hours agorootparentYes you’re right. I’m from Cebu definitely hanging rice. reply kylegalbraith 15 hours agoprevThis is the magical stuff that I love finding on HN. We don’t make this enough at home. reply kizunajp 15 hours agoparentAuthor here. Thank you for the kind words!This post is part of a newsletter we write semi-regularly. If you found this interesting, do take a look at our other pieces and consider subscribing!reply smarks 11 hours agorootparentThe link to the video showing how to unwrap an onigiri was very helpful! I’ve encountered that wrapping before but I found it confusing. (I don’t read Japanese and I couldn’t figure it out from the diagrams.) reply xenodium 15 hours agorootparentprevOn a tangent, I’ve toyed with the idea of starting a newsletter. What are you using to run yours? reply seemack 12 hours agorootparentNot the OP but it looks to be https://ghost.org/ I use it as well for a small development blog and it's been an enjoyable experience reply xrisk 15 hours agorootparentprevJust spent a great half-hour going through your blog. Great work! :) reply turtlebits 3 hours agoprevOn the scale of things you can wrap in rice, Onigiri is a 2/10 for me. I can understand it for kids, its cheap, easy to make and relatively healthy, but the filling could be so much more creative. IME the Chinese fan tuan (饭团) is so much better. reply ilamont 13 hours agoprevIn Taiwan there is a variation of 飯糰/rice balls shaped like a triangle but no seaweed wrapping, usually with 肉鬆 (pork floss) in the middle, which have been around forever as a breakfast item. The Japanese type wrapped in seaweed with better ingredients started popping up in 7-elevens about 15 or 20 years ago, and are known as 日式飯糰 (\"Japanese food rice balls\"). I think they cost about NT$40-50, or around US$1.50. It's not enough for a meal, but as a snack they're great. reply hawflakes 4 hours agoparent飯糰 also come in a Shanghainese variety (粢飯). They're long and stuffed with a deep fried dough stick 油條, the pork floss, and sugar. As well as a savory variety with mustard greens 榨菜. Seems like the Taiwanese version is fusion of both Chinese and Japanese styles for Taiwanese tastes. reply maxglute 3 hours agorootparentMcDonald's had nice rice bun burgers in Asia. Apparently originated in Japan (MOS chain), and also popular in Korea. I'm still waiting for this variation to make it's way to the west. https://en.wikipedia.org/wiki/Rice_burger reply ptelomere 9 hours agoprevMy girls join the Girlscout in Japan. When they have outings, they'll prepare \"girlben\" which is short for \"girlscout's bento/lunchbox\", which is literally just 2 or 3 onigiris with whatever ingredients they want. reply aidenn0 12 hours agoprevFor those of you as clumsy as I am, you can form onigiri by pressing it into the corner of a Ziplock bag. Just dampen the inside of the bag slightly first to reduce the rice sticking to the bag. If you're making Shio onigiri, you can salt the water. reply boringg 16 hours agoprevBeen making this for my children - they love it. Easy guaranteed eaten food for them which is a big win in our books. reply ptero 9 hours agoprevIs 100g mentioned in the writeup a common size? A few times I tried it, visiting friends (in the US) the onigiri felt smaller than this. Although maybe they felt smaller because they disappeared so fast. reply riversflow 15 hours agoprevWell one thing that is sort of notable about Japan/Onigiri but left off this blog is that they will all contain fish. Being a vegetarian in Japan was miserable. I want to go back with a pack of Protein bars so I can travel and feel decent. I practically subsisted off potato chips on my trip. Edit: The number of people telling me I should have hired a guide is hilarious. I couldn't have afforded that. I did go with 2 Japanese speakers, but wasn't with them the whole time. I asked for help often, and got it (Japan is so cool like thatWell one thing that is sort of notable about Japan/Onigiri but left off this blog is that they will all contain fish. They don't. There are onigiris containing beef or chicken. Also shrimp, except if you count that as fish. Edit: of course, I reacted to this before reading the next sentence about vegetarianism... There are also rice balls with nothing else than salt, usually called shio-musubi. And as others have pointed out, there's also umeboshi. reply colanderman 14 hours agoparentprevThere are vegan onigiri, even at 7-11s, if I recall. I think salt, umeboshi, and kombu onigiri are safe. But yes, some surprisingly contain fish sauce which would otherwise be vegan. (I live in the Boston area and can even find vegan onigiri at the local Japanese market, Maruichi.) reply wahnfrieden 15 hours agoparentprevUmeboshi onigiri still contain fish broth ingredients? There’s always the plain salted onigiri too Btw careful with chips in Japan, most varieties have meat extracts in them reply blackcat30 9 hours agorootparentUmeboshi is made from Japanese plums (more like an apricot) salt and purple shiso, nothing else. The salt is ground into the Shiso (Perilla plant) to draw out the liquids and then sprinkled on washed ume (plum) and then left to ferment for weeks. The salty shiso draws out the liquid of the Ume and dies the green plum a dark purple color. Extremely high salt content, but no fish whatsoever. reply fomine3 5 hours agorootparentMake it more complex: Katsuo Umeboshi is one of a famous type of Umeboshi that contains fish taste reply ASalazarMX 14 hours agorootparentprevA local guide would be invaluable to recommend vegetarians options. Also, be very explicit if eggs or milk are acceptable, because there's very few strict vegetarians in Japan. Even monks and nuns who practice Buddhist vegetarianism consume milk. reply numpad0 6 hours agorootparentIIUC, the original Buddhist teaching is that getting involved in taking life smears your karma, not necessarily that consuming the results will. Confucianism influenced branches tends to take the latter interpretation so that's what a lot of Asian(Japanese or Chinese) guys would say, but hardcore Indian style counterintuitively is that everything already on the platter is lost cause and even wasteful to refuse, given one does not actively seek it or support it. My highschool teacher had an anecdote on this. There was a small, yearly post-event party which a Buddhist guru is invited to join. One time there were couple chicken wings for each. They feared the guru would have some words on consuming meat, or others next to him has to take the extra, but he saw no problems with it since it was offered and presented to him passively, and just stated he has to reasonably clean the bones and that that isn't a fast process. From next time on the party had become strictly boneless, but not vegetarian. reply dpassens 13 hours agorootparentprevEggs and milk are vegetarian, just not vegan. reply wahnfrieden 13 hours agorootparentEggs or dairy specific abstinence is more associated with variations of vegetarianism than far stricter veganism, for example lacto-vegetarianism. reply johnwalkr 14 hours agorootparentprevUmeboshi onigiri reliably does not have fish broth ingredients. reply slothtrop 13 hours agoparentprevIf it makes you feel better many fish don't have a cerebral cortex. Their level of sentience is on par with insects, which is a popular protein suggested by some flavors of vegetarians (or at least was). reply jongjong 9 hours agoprevI love Japanese food. I really like recipes which focus on the flavor of a specific ingredient. Japanese food like Sushi and Onigiri made me realize how good rice tastes. Kind of like how French and Italian food made me realize how good wheat tastes. In terms of wheat, Italians mastered the savory and French mastered the sweets. In all these cases, the grain is treated as the central ingredient. It's an ingredient which most people consider bland, and yet it takes the leading role in many recipes. reply brcmthrowaway 13 hours agoprevWhere can I get a vegetarian friendly version of this in San Francisco? reply anigbrowl 13 hours agoparentJapantown has some vegetarian restaurants, and since they get a lot of tourists they're used to specific food requests. Just ask before you sit down. There's also a Japanese supermarket there and you can check the ingredients list on the packaged food in the refrigerated section. reply naet 9 hours agoparentprevYou'll find a million places to get them if you search yelp or google maps but the ones most like the article are likely found at asian grocery stores. Woori or Nijiya both have a good variety of them and should have some vegetarian ones like pickled plum. Across the bay at Berkeley Bowl they make some an surprisingly good ones too. reply rich90usa 9 hours agoparentprevNijiya Market in Japantown has at least plain seaweed Onigiri in far right of the fridge near the entrance for $2.79. Unfortunately it was the same price as ones with filling. reply wkat4242 9 hours agoparentprevI'd love to know the same for Barcelona :) I bought some Onigiri at the Manga Salon (a big annual manga convention) but I have no idea where they are available year-round. reply legerdemain 10 hours agoparentprevThere is now a US chain for onigiri: Onigilly. About a third of the menu is vegan and gluten-free. reply ohxh 16 hours agoprev [–] There’s a fun version of this that they have at 7-11 (or 7 & I) there. Probably other convenience stores too. They come in a plastic wrapper that separates the nori from the rice and filling so it doesn’t get soggy. When you pull a little tab, it somehow removes the plastic from in between without messing up the shape. Magic! reply defaultcompany 16 hours agoparentThe article talks about this at the end. I’m confused about how it works though. reply andreareina 15 hours agorootparentThere are two layers of plastic wrap, one on either side of the nori. It works because there's no nori at the side and that's the direction you pull the plastic off. reply jncfhnb 15 hours agorootparentprevYou have to be pretty specific about how you pull it apart. Most people will ruin their first onigiri because they do it wrong. But basically you break a seal and then pull the plastic out on each side, sliding them out. reply wkat4242 13 hours agorootparentYeah there's instructions on them but they're in Japanese and the pictures aren't very clear in my experience. But it's not a big deal if you're going to eat it right away because the nori doesn't get soggy that quickly. reply numpad0 6 hours agorootparentRest assured, everyone is confused first time and no one knows how it works. It's just there aren't many Japanese left that hadn't learned the lesson. reply jncfhnb 13 hours agorootparentprevIt does ruin the aesthetic of it though reply wkat4242 9 hours agorootparentOh ok, it didn't really for me. It did pull the nori open a little bit so I had to fold it back in. reply layer8 16 hours agoparentprev [–] You haven’t looked at the article, did you? reply boringg 15 hours agorootparent [–] Right? It's literally the majority of the article .. the onigiri wars. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Onigiri is a traditional Japanese food that is a rice ball filled with various ingredients and wrapped in nori (seaweed).",
      "It became popular in post-war Japan as a convenient and familiar food item sold in supermarkets and convenience stores.",
      "Onigiri is closely tied to the story of convenience stores in Japan, with different chains competing on freshness, taste, variety, and packaging."
    ],
    "commentSummary": [
      "The article explores the ongoing rivalry between the Kansai and Kantou regions of Japan, examining factors such as language, demography, and immigration that contribute to this rivalry.",
      "It discusses the trends in onigiri, including the increasing popularity of whole grain rice, the decrease in tuna quality in convenience store onigiri, and the availability of vegetarian options.",
      "The article also delves into the different variations of onigiri found in various countries and the challenges of opening the packaging."
    ],
    "points": 256,
    "commentCount": 108,
    "retryCount": 0,
    "time": 1705339347
  },
  {
    "id": 39002740,
    "title": "Reimagining Software Development: Critiquing Scrum and Promoting Individualized Teamwork",
    "originLink": "https://blog.mb-consulting.dev/scrum-sucks-9960011fc5cf",
    "originBody": "Scrum sucks. Breaking news: scrum is bad. Matteo Bianchi · Follow 10 min read · Oct 18, 2023 -- 40 Any developer right before sprint review If you are reading this post, you probably worked following (some form of) Scrum but in case never did: take a seat and be my guest. Let’s start from the very beginning. What is scrum? Scrum is an Agile project management system that “helps people and teams deliver value incrementally in a collaborative way.” Cit. Scrum.org As for Agile, if you never read its Manifesto (2001), I define it as a lean list of good practices to follow in software development. Agile is not: the Holy Bible of Software Development, a dogmatic set of strict rules, Jira tickets or Agile Coaches running around your company. Late disclaimer: definitions are flawed, by definition. (now read that again) I will openly accept any criticism about the way I defined Scrum, Agile and any other term too. I only ask you to read the whole post before angrily typing in the comments! Theory vs Practice Agile is the opposite of Waterfall, which has been the old school way of crafting software until the ’90s. Waterfall as pictured by Agile practitioners: a pile of sh*t Agile is iterative, Waterfall is sequential. Agile is lean, Waterfall is heavy. Agile is fast, Waterfall is slow. Agile is code-first, Waterfall is doc-first. I could go on for ages but I will not, you got it. Typical agile practitioner working on the same task for 4 sprints in a row. Agile comes from a (very) good place and it was a revolution that transformed software development from a sequential nightmare in the discipline tons of engineers, including myself, happily practice today. I would never question the authority held by the people who theorized it, since the real issue is Scrum implementation in our real not-so-ideal world. Ceremonies Scrum’s most fundamental term is: sprint. Sprints are basically pre-defined time-slots (typically lasting two-weeks). During this amount of time, aside from development cycles, the Scrum team is required to follow some ceremonies. Midsommar, must watch, add it to your list! Sidenote: I always disliked this religious term used to define these kind of meetings, but ok. Sprint Planning — as simple as it seems, a long session (up to 4 hours) to plan items/user stories that need to be delivered during the following sprint, involving the scrum team. Daily stand-up meetings — a daily, SHORT, meeting (around 15 minutes) where the small development team (like 3 to 7 people), communicates their progress and underlines blocking issues, both without going into deep detail. This is the time where you can ask Alice to have a separated meeting about that server-side caching issue and to Bob about that date parameter being a string and not Unix time. Sprint Execution — People autonomously pulling tasks, then execute them and solve eventual issues through informal meetings, pair-programming sessions, code reviews and intensive copy-paste from ChatGPT. Testing? Part of the execution. QA? Yep. Documentation? You know the answer. Operations / DevOps / Infrastructure tasks? Guess what. Sprint Review — a long meeting (between 1–2 hours) which aim is showcasing the sprint outcome to stakeholders and getting feedback from them. Spring Retrospective — an internal analysis of what has been executed, with focus on impediments, in order to remove them for future sprints and overall continuously improve processes, practices and tooling for the next iteration. Backlog Refinement — not really a ceremony but roughly 10% of the time that should be spent by the team, during a sprint, on backlog refinement to: break down, explain, find gaps, provide a definition of done and collaboratively prioritize the tasks. People These are the individuals, or group of, identified by Scrum: Stakeholders — They have a stake in the game, they want to be informed, involved and they benefit from the product, whatever “product” means for your company. Yes, everything is a product if you stretch the definition enough. They can be end users, other teams or even another business. Product owner — should act as a bridge between the stakeholders and product developers, translating requirements into actionable items, understanding business both domain and business value, managing the backlog and maximizing the delivered outputs. Developers — should be the people in charge of operational duties, including but not limited to software development, in a self-managed way, being able to take technical decisions steering the product on the right path. Scrum master— should facilitate communication, monitor and track progress, determine and evaluate risks, educate and coach the self-managed team about scrum to render it effective. Ahhh yes, the famous multitasking productivity of a Scrum Master Scrum is broken Wait. So these ceremonies and roles are so complex that a Certified or Professional Scam Master is needed? Ahhh, sweet summer child. The obvious answer is, in short: no. Wanna know why? We do not live in an ideal world where theory happens exactly as written in the books. You could have guessed it by the highlighted phrases in these last paragraphs, but in practice this is what really happens: Another Jira ticket? Let’s GOOOOOOOOOO Planning, regardless of the tooling, takes ages and you end up with pre-assigned tasks, measured in story points. These points, that should be there to help getting an idea of the complexity of a certain task, are instead used to measure time. Well done, Sherlock! Your team is now focused on occupying time by filling their schedule, instead of focusing on delivering features and you cannot even measure their velocity. Velocity should be useful to understand, based on previous sprints, what is the relative amount of product progress your team can deliver. Ok, but why are we not using a Fibonacci scale again? Or what about a game of planning poker? Me, after you told me your company uses Fibonacci scales for stories Wait, don’t resign yet. I have the definitive solution, I swear! Just give each task a clothing size to simplify its measurement. What a wonderful idea. We simply need to discuss if that is that gRPC API is an L or an M tasks, meanwhile the only L we are getting is the time we lost on picking a method for this unproductive millimetric measuring. Big L, micromanager! Thinking about a possible scenario: Product Owner and Scrum Master are out of office. One is on sick leave and the other has a well-deserved PTO or holiday. Does your team still attend the stand-up meeting? I doubt it. What? You set individual velocity as a goal to meet each sprint? Be prepared for crappy code and incomplete, but still automated, testing. Once you set a static metric, people will gradually adapt to go around it. Oh, and say goodbye to pair-programming and collaboration, everyone is too focused earning those juicy story points. A task is too difficult to break down and requires extensive analysis that may involve multiple teams and last a couple of days? No one is going to self-assign that task as they fear blame and looking unproductive. Writing tickets for 10-minutes tasks such as formatting some file, updating a URL and remove unused imports? Welcome to ticket-driven development where even decluttering takes ages. Time for a pretty common case: someone found a bug during the sprint. Houston, we have a problem, let’s talk with… who? Team Leader? Scrum master? Tech Lead? Product Owner? Service Owner/Manager? Project Manager? Yes, I experienced having a PM in a team running Scrum, don’t ask why, it is very real and I have proof. Who you gonna call? What a fractioned leadership we have here! So much for “self-managed team”, huh? Imagine you aligned all these people about your issue and now guess the amount of time required for them to figure out their piece of responsibility and provide a solution. You, leaving the room without a clue about the solution Good luck, see you next sprint! Scrum is often seen by management as an elixir of productivity and a cure for any under-performing team, but reality is pretty much the opposite. Scrum does not solve your team performance issues. A slow team can become even slower and believe me, that burnout chart will be painful to watch. The — ??? now I’m really burnout — chart Whoops, I meant burndown, pun intended. Is there a way to make Scrum work? I really believe there is one, but I have never seen a single engineer happy about their company Scrum implementation. Bingo. Way of work should be defined at a team level by its people, not by the company. The Agile prophecy is finally fulfilled! Time between deliveries is finally short and it is flexible too! No need to call it “sprint” and make it look like an endless run against time. Quality of software produced will rise sensibly as any change to the scope is free of the constraints of rigid time slots. Estimates are done as intended: intuitively based on previous experience, validated at a team level. In software development more than anything, time must be considered as a relative measurement. Planning involves, management aside, people that are actually executing whatever is being planned so they can discuss it and find flaws when there is still time to handle them gracefully. Work is pulled by each individual contributor and not assigned by any leader/manager. Execution is empowering. Each developer, based on experience, has a certain degree of technical freedom and feels business responsibility towards the product, their colleagues and stakeholders. Reduction of dependencies, makes your development team independent and, believe it or not, way faster. Daily updates finally reflect the status of the issue tracker, information flows and documentation gets written. Daily alignments are short and really give info about the work in progress. No one feels the need of filling their todo list with minor filler tasks or lying about being stuck or ahead of schedule. Blockages are solved within the team, as a team, without interacting with lasagna-layered management and by taking ownership of each decision, whatever the outcome may be. Results are shared in complete transparency and really show the status even to the most difficult stakeholders (typically “top” customers). Objective is to look for real feedback, not for headpats. Review of what has been executed is honest and blameless so people can stop manipulating data to make it look like they did a relatively good job and start focusing on solving the root causes of issues encountered. Backlog is finally a shared responsibility and a continuous effort. You will be amazed by the impact of this simple (but not trivial) bullet. The fix Take the retrospective seriously, as a moment to reflect with a clear mind, over what turned out to be a good strategy, how to iterate on that and praise the team for the job done. Yes, of course you also need to thinker about what went wrong, why and how to improve it. Ask for advice on how to improve rather than feedback. People love to give advice (sometimes even without prompt but that’s a different story), it helps avoiding empty feedback as in “all good” or “all bad”, when you getting a good advice will be immediately actionable, asking someone for advice makes them feel more trustworthy than when they are asked to give “just” a feedback. Trust the team, be honest and stop trying to micro-manage it. Try to delegate more and be flexible, you will see that giving freedom results in a healthier environment where is easier to learn how to be responsible, even when the cat (aka management) is away. Be aware that metrics will lie at some point, if you don’t look give a critical look at them, don’t fall in the usual confirmation bias. Time for one of my favorite quotes: “if you torture the data long enough, it will confess to anything” — Ronald H. Coase. Encourage mistakes, own them and fix them without fear of undergoing performance reviews. Stop scrutinize and question that dev that made a mistake during the previous sprint, it will only worsen their performance and create a toxic environment to work in. You should examine the mistake but never the person. You see a dev struggling? Try to ask them how they are doing, give them some time off and look at the results on the next iteration. I know that some of you think that what I said is just bullshit. If you write that angry comment at this point, I won’t blame you. Let’s now read the Manifesto again: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan This time you cannot say that title was a clickbait: Scrum really sucks. Unless you make it Agile. Which means: flexible, adaptable, collaborative, built around people and focused on results rather than metrics. Self-ad time! (skippable) I currently offer engineering services for companies in need of a Cloud Native Consultant (DevOps/Cloud/Kubernetes) and to startups in need of an advisor. Feel free to get in touch on LinkedIn, even to refer me to someone you know. For any successful referral, I offer 10% of the first invoice paid amount (ex. VAT) either in cash* or donated to a charity of your choice 💰 I also offer coaching and mentoring to individuals, so if you wish to know more about Software Engineering, DevOps, Cloud, Kubernetes or even if you want me to review your CV/LinkedIn or career path, hop on my MentorCruise profile! *you must not be a decision maker nor having a (big) stake in that referral company to choose the cash option: - an investor refers me to a startup in their portfolio❌ (you don’t need the money!) - CEO of X refers me to Tesla ❌ — sorry Elon. - an employee (not C-level, Director or similar) refers me to their company ✅ - CEO of Google refers me to Microsoft ✅ Comment, share and tag me to discuss! Find all my links 👉 here. That’s all for now, ciao :)",
    "commentLink": "https://news.ycombinator.com/item?id=39002740",
    "commentBody": "Scrum Sucks (mb-consulting.dev)218 points by pantalaimon 17 hours agohidepastfavorite273 comments Aurornis 17 hours agoI added up all of the time we were spending in Scrum-related activities at a recent job. The company hired a lot of project and program managers who were pulling everyone into everyone meeting. I presented the number of hours (meetings multiplied by engineering participants) to our VP and he insisted I must be wrong. He insisted there was no possible way we could be spending that much time doing Scrum things and that I must be exaggerating or lying. He then fell back to a lecture about how Scrum is an industry standard and how it's more efficient than alternatives. Really opened my eyes to the disconnect between Scrum mythology and Scrum in practice. The amount of time lost to doing Scrum things was so out of control that some people had fewer than 3-4 hours per day to actually work. Of course, the Scrum proponents will rush in and tell me that we were doing it wrong or that it's not truly Scrum if it's helping more than hurting, but these people were highly trained in the ways of Scrum and Agile and pointed to various Scrum and Agile books and certifications to defend their ways. OTOH, I have been on very small teams where Scrum was implemented with low overhead, but those teams were filled with efficient people who would have been productive without formal methodologies either way. reply CharlieDigital 16 hours agoparent> everyone meeting This is one of the things I've added to me repertoire when I interview with teams: I always ask how often they meet and how they structure their meetings. Big red flag is there is a daily all hands (yes, I've seen this in a 16 person startup) I think it's emblematic of a few things about the founder/cofounder/lead: 1) they are an egomaniac and just needs to see everyone reporting in, 2) they don't trust their teams because they need to have daily all-hands status updates, 3) they're not connected to their teams' work; there is no visibility into what's getting shipped, 4) there's a strong correlation with micromanagement. Learned this through a few mistakes joining teams where the founder/lead insisted on frequent all-hands standups (sometimes lasting 45-60 minutes to get through all of the teams reporting in). reply Aurornis 16 hours agorootparent> Big red flag is there is a daily all hands (yes, I've seen this in a 16 person startup) It was even worse than this: The Scrum operators wanted an engineer from every team they interacted with to also join their meetings. So if a project made an API request to another project, they'd insist on pulling an engineer from that team into their weekly or daily meetings. I had daily meetings with 10 people, half of whom might be engineers from other teams who didn't need to be there. Meetings became so useless that everyone stopped listening until their name was called so they could work through meetings. Then every time someone's name was called, we had to spend 5 minutes recovering the last 5 minutes of the meeting to bring them up to speed. The inefficiency was out of control, but the worst part was that some people thrived on this level of inefficiency: Lack of progress meant the empire builders could argue for more headcount, too many meetings meant the Program Management department could hire more program managers. It was like a case study in adverse incentives. reply dheera 16 hours agorootparentsounds like my (big co) meetings. also in the \"scrums\" everyone gets stuck on one topic and it turns into an hour long debate that could have been resolved by 30 mins of coding. reply nick__m 16 hours agorootparentprevI work I infrastructure and the daily meeting in the morning is the most important part of our day. It last 15 minutes, first we review and dispatch the active alerts, then we check escalated demands, then we check if someone needs help. We not do to solve issues during that meeting, this is done in smaller groups after the daily. That meeting keeps us aligned. Also no managers are allowed during our daily meetings. This is something important that enables more candid communication. reply zer00eyz 16 hours agorootparentprevI run this meeting often with teams. It should be a literal standing meeting. You dont get to sit and drone on. There is one in every bunch and when they make their peers stand for 10 mins. The team will self correct the person into not being that way. That meeting is a check point. What is every one up to, and everyone else gets to hear. It's a way to get a team to gel (and many aren't)... If someone surfaces a problem in there (and they should be) then there should be some other team member offering to help out - there should be dialog if some dependency is going to get bumped by others being distracted. These meetings are effective up to about 10 people. They work well with cross functional teams, or teams where the members have varying levels of experience. reply cableshaft 15 hours agorootparentprev> Big red flag is there is a daily all hands standup Something I've seen for the first time at my current project is instead of a daily standup, there's a daily thread to report what you've been doing in Slack instead. And then as long as there's nothing people want to go over, the actual standup meeting is skipped. We sometimes go a 2-3 weeks without an actual stand up call. It's pretty nice. Even if not, the calls are only scheduled twice a week anyway. Much better than the 20 person in-person daily standups in the conference room, better get there early if you want to have a chair, at 8:15am every day, like a previous job. reply eevo 16 hours agorootparentprevTime spent with the team ebbs and flows depending on complexity of projects, where in the roadmap you are, seniority of the dev team, and more. The agile manifesto was too abstract in it's original state, and folks who needed a rigid framework created capital A agile in order to adapt it to their cog in the machine role. For my team of 6 in a ~20-25 person (remote) startup, we have a 30 minute dev meeting in the morning, and a 15 minute full team meeting where the agenda rotates daily around departments. I quite like it honestly, remote can be lonely and isolating otherwise. Generally I think it's important to structure team responsibility around who ultimately needs to make the decision (although they need to consult others and get team buy-in). And hire people you trust to make the decisions. Then the meetings become about problem solving and getting through the work, rather than performance art and politics. reply nine_k 16 hours agorootparentprevAs a counterpoint: back in the day (around 2010) at JetBrains we had a daily all-hands stand-up for several teams, about 15 people in total. It was literally a stand-up, that is, everyone stood in a circle. Everyone was expected to utter exactly two sentences: what has been done yesterday, and what are the plans for today. It usually took 10-30 seconds per person, so the entire meeting was under 10 minutes. It was pretty efficient: you almost instantly knew who are you going to talk to later in the day, if need be, or what changes to look at. reply the_other 16 hours agorootparentSounds good. 15 people seems too big, but if you're keeping it under 10 minutes then all power to you. Very few people care about \"what did you do yesterday?\". It's already over, by that point. There's a lot of benefit to removing that one. In my team we do it like this: - how are the nightly tests? (we've actually dropped this in recent months) - what's in the Test column, and does it still need manual testing? (we have automated unit and integration tests but also, sometimes, do manual testing just so a 2nd pair of eyes has seen a thing work. We're not strict about it) - what's in the code review column? Are any of them stuck/unreviewed/etc? (to remind people to do reviews) - what's in the progress column that needs help/pairing or some kind of management support? - any other business With these three rules: - save the details for other, more focused meetings or Teams. Anyone call time on any discussion. - strict max 15 minutes time-limit - jokes are fine Works well enough that the next time I work in a team that doesn't do it this way I'll do all I can to move them to this format. reply nine_k 14 hours agorootparent> Very few people care about \"what did you do yesterday?\" ...except the people for whom what you have accomplished is a dependency in their work. It can be a direct code change you'd have to merge into your current branch, or something you might want to start using (or finally stop using). It may be even something you have to contemplate on, and it may affect your work much later. Work of people in a team is inevitably interconnected, and so is work of people in sister teams. reply skydhash 13 hours agorootparentIf you have deps, it’s better to have a direct meeting with both teams in order to resolve mishaps and have a channel of communication setup for that. Daily standup is a poor replacement for that. reply directevolve 16 hours agorootparentprevBeing relatively new to the SE game, I’m curious - why can’t this be done via Slack? reply nine_k 14 hours agorootparentIt did not exist back then %) It launched in 2013. IRC existed, but for some reason it wasn't popular enough. Eventually we wrote a real-time web chat, just because it was a fun project for someone. But it did not replace the standup, until I left in 2011. reply astura 15 hours agorootparentprevIt absolutely can be, that's how my team does it. I've also seen teams update wikis for their daily standup. reply dvaun 16 hours agorootparentprevThis is how it should be done. No filler, no smalltalk — straight to the point. reply lapcat 16 hours agorootparentprevCouldn't this just be an email instead? reply the_other 16 hours agorootparentNo. No-one will read it and it slows down \"what collaboration do we need to set up today\" aspect. reply lapcat 16 hours agorootparentIf no one will read it, then maybe it's not important, so you don't need the meeting either? ;-) reply The_Colonel 14 hours agorootparentIf I don't go to gym, does that mean exercise is not important? Some things are not very enjoyable, but still necessary. reply lapcat 14 hours agorootparentWe know scientifically that exercise is important. I highly doubt the same level of evidence exists for the importance of these short meetings. Also, if your boss tells you to read the emails, and you don't, then you can get fired. You can't get fired from your job for not exercising. If you can ignore the emails and not get fired, that's proof in itself that the emails are not important, at least not to your boss. reply The_Colonel 14 hours agorootparent> Also, if your boss tells you to read the emails, and you don't, then you can get fired. The boss has no easy way to tell if you read the emails or not. The consequences of lack of information are often hidden / long term. In many countries, it's pretty much impossible to fire employees for forgetting to read an email. > If you can ignore the emails and not get fired, that's proof in itself that the emails are not important, at least not to your boss. I'll try a proof in a similar style - if Scrum was so wildly inefficient, the companies practicing it would be a long time out of business since companies with no meetings would easily outcompete them by offering better products/services for lower costs. Yet Scrum (or similar methodologies) are used in many successful companies all over the world, that's a proof that Scrum works. How do you like them now, these oversimplistic \"proofs\"? reply lapcat 13 hours agorootparent> In many countries, it's pretty much impossible to fire employees for forgetting to read an email. What about \"forgetting\" to attend a 10 minute meeting? > I'll try a proof in a similar style It wasn't a similar style. reply The_Colonel 13 hours agorootparent> What about \"forgetting\" to attend a 10 minute meeting? The instances of people not attending standups I've seen were just symptoms of a larger problem, and such people did not last long in the company. reply lapcat 12 hours agorootparentYou didn't answer my question. Can they be fired or not? And if yes, what makes it different from emails? reply jq-r 14 hours agorootparentprevAlso there are some things which are not enjoyable, and definitely not necessary. Standups are one of these in my honest opionion. reply tapland 16 hours agorootparentprevoh god no reply hot_gril 15 hours agorootparentprevEvery meeting only has 1-5 people talking, regardless of how many people are in it. Especially if they're remote. Sometimes a large meeting with many listeners is ok, but the same 16 people meeting every day is a waste of time. reply Silhouette 14 hours agorootparentprevThis is one of the things I've added to me repertoire when I interview with teams: I always ask how often they meet and how they structure their meetings. I once mysteriously turned into \"not a culture fit\" after several rounds of interviews with excellent feedback up to that point and I'm fairly sure asking a couple of similar routine questions about their dev process was what got me tagged with that label. I do consider that one a bullet dodged - if your process is so bad that you're worried about a candidate asking about it or you think they're being awkward for doing so then that says everything really - and I still ask similar questions of anyone I might work directly with/for today. But if there's a place you really want to work it's worth keeping in mind that some people apparently get rubbed the wrong way by this kind of question. reply robterrell 17 hours agoparentprev> the Scrum proponents will rush in and tell me that we were doing it wrong The \"no true scrumsman\" fallacy at work. reply Cpoll 16 hours agorootparentIt's not a \"no true Scotsman\" (scrumsman :)) if the counterexample is in fact not a Scotsman. Whether it is or isn't depends on your feelings on scrum, but it's not a fallacy to try to defend the initial definition before it was co-opted by anyone with an Agile cert. \"Hammers suck at driving nails.\" \"You're holding a rubber mallet.\" \"No true Scotsman!\" reply alexjplant 16 hours agorootparentThis. People love dunking on Scrum because they have colleagues and managers that wield it as a weapon (often in conjunction with JIRA, which, although not an especially simple or well-running piece of software, is really only as bad as you choose to make it). It's actually a very simple process that was designed as the _antithesis_ to a lot of the atrocities committed in its name (based on a reading of this thread). If you have managers/PMs/TMs/HMs/BDFLs that can't see the forest from the trees and a corporate mandate to use Scrum (or Agile generally) then of course they'll pervert it to suit their own ends. Slow-moving organizations with complex incentive structures like the government and Fortune 500s are especially good at this. If you want to be upset with somebody then blame them. I've worked on teams where stand-ups were less than ten minutes long, we delivered every two weeks, and we had properly-specified Scrum Master and Product Manager roles and it worked swimmingly because we _actually did Scrum_, not \"Scrum, but...\". Scrum is a prescribed process. It is not the performative act of dragging work items into Sprints in JIRA then using various Scrum terms for 5-hour-long weekly meetings. reply Aurornis 16 hours agorootparentprev> It's not a \"no true Scotsman\" (scrumsman :)) if the counterexample is in fact not a Scotsman. Every bad Scrum/Agile situation I've been in has orchestrated by people who were convinced they were doing it \"the right way\" Every defense I've read has been from other people who weren't there who insist that it must be \"the wrong way\". If you define the \"right way\" such that it can only be good, then you conveniently dismiss all of the negative criticisms at once. Yet in the real world, there appear to be a lot of us stuck in companies who think they're doing it by the book but it's still not working out. reply The_Colonel 14 hours agorootparentLet's do a thought experiment. Imagine you have the same organization, same people, but a different methodology or perhaps no methodoligy at all. Would things get significantly better? reply Aurornis 6 hours agorootparentI can't imagine how it could get any worse. It became really difficult to push back on or change anything because the Program Managers would band together and brandish their Scrum certifications, Scrum books, Scrum podcasts, and other credentials to show that we couldn't argue with them. Unfortunately, it worked with management. Wipe all of that away and let all of us work together toward a methodology that worked for everyone without Product Managers playing the Scrum card at every disagreement and I have no doubt it would have been better. In fact, I have some proof: There were a few pockets of small teams that got to operate outside of the Scrum madness either because their tasks were thought to be too small or temporary, or because they existed in islands of the org chart that were free from the reaches of the Scrum people. These small teams ran circles around everyone else, but that would come grinding to a halt as soon as their projects got assimilated into the Scrum catastrophe. reply koonsolo 2 hours agorootparentprevI always wonder if they have retrospectives in those situations. And if so, what they actually do there. In my opinion, retrospectives give the power to the team to improve their own process. Without self-organizing teams, you have no agile. So without retrospectives, you have no agile. So I always wonder if and what they do during these retrospectives. reply galangalalgol 16 hours agorootparentprevAnd agile methodologies are not agile by the definition. Agile is a set of relative values, not a methodology. The first being to value people and interactions over processes and tools. No process is agile, no process can be. reply Aurornis 6 hours agorootparentI hear these aphorisms a lot, but none of it actually matters. Agile has been plastered over certifications, podcasts, books, conferences, trainings, and everything else for years. The people I referred to above had been through it all and brandished it like a weapon. You can tell me all day that it's not true agile but it didn't make an iota of difference to how things play out. Judging by the comments, my experience is not unique. reply robterrell 16 hours agorootparentprevYou make a good point! But scrum as we know it today is not Agile: \"Individuals and interactions over processes and tools.\" Processes and tools (i.e. Jira, sprint planning, retrospectives, etc.) dominate all implementations of Scrum I've seen. reply marginalia_nu 16 hours agorootparentprevOne of the most reliable indicators I know of a dysfunctional team is on average how many times whether what being proposed is sufficiently agile is put to question per meeting. If this is greater than some epsilon much smaller than 1, then you have trouble. Overall \"is that really agile though?\" is such a fantastic thought stopper. It's can be thrown out to derail any sort of proceeding. It moves all focus from what's practical and applicable and relevant to the situation at hand, and moves it to an endless discussion about philsophical alignment. reply denton-scratch 16 hours agorootparentprevAnd in fact (if you read to the end) that is exactly what the author is claiming. Which is why the title is clickbait. reply wkrause13 16 hours agoparentprevI recently dealt with the same thing. We had an experienced CTO come in and implement a “big company” style of Agile. In all fairness, there was a lack of process that needed to be addressed, but the pendulum swung very much too far in the other direction. He left the company and I stepped up to fill the gap. First thing I did was quantify the amount of time the team was spending in meetings and it was over 25%. Those meetings weren’t even efficiently grouped, so with context switching it was even worse. Luckily I was in a position to change things and consolidated a lot of the ceremonies. I kept more of the process in place for our offshore partner team because the communication burden was higher. So I guess my two take aways are that time in meetings needs to be evaluated with how meetings are grouped to avoid too much context switching and allow for folks to get into a flow. The other is that how strictly you adhere to “textbook” scrum really depends on the composition of the team. More junior teams or teams that are insolated from the larger business context benefit more from more process imho. reply Scubabear68 16 hours agorootparentInteresting, I have a very similar story from last year. Existing CTO and head of product acted as if they were writing complex, mission critical software (they weren’t) and instituted processes to match. It went from overly ad hoc to over-the-top scrum. As a result, features took months to develop and everyone was terrified of releases. Teams bloated to massive size. CTO was fired, I came in and evaluated everything, slashed the consulting teams down to the ones clearly performing, and slashed the processes down to boot. Within a month the team velocity was way up and we were releasing to a nice cadence without fear. And this was not because I’m a super man. I’m not. Any competent tech lead or manager could have done the same. The only difficult part was dragging the product folks along, they kicked and screamed the whole way, predicting doom, and were amazed when the sky didn’t fall. reply JohnMakin 16 hours agoparentprevThe last org I was in realized how much time their engineers were spending in agile-caused meetings, much like what you describe, at least half of the working hours in a week - so they made a company-wide rule that no one could spend more than 4 hours a week in meetings. What happened instead were impromptu \"ghost\" meetings and a ton of stuff done sloppily over chat instead, where I think the hope was that people would try to become \"more efficient\" with their meeting time. reply ethbr1 16 hours agorootparentTo me, RACI charts are a missing component of meetings. Required meeting attendees should consist of the Rs... and only the Rs. As and Cs can be optional, but meetings can conclude without them. Everyone not in the meeting can be updated out of band. \"What action is this person taking in this meeting?\" should be a brutally honest question. If the answer is only \"listening\", then it's a waste of their time. And also, related point: what is the termination condition of this meeting? And has that been decided and communicated beforehand? I.e. What outcome are we seeking, that when done everyone agrees the meeting is over? I can't stand agenda-less, \"we're meeting to move something forward in some undefined way\" meetings. reply wheelinsupial 8 hours agorootparentAgendas are critical and so is the purpose of the meeting. Is the purpose of the meeting to inform, decide, workshop, or persuade? If it's to inform, it should be an email, but some people do not read them, so you need to sometimes read the email to them in a meeting. If it's to decide, do you have the people that will decide called out in the agenda? Do they have the necessary information or have they done the necessary work to make a decision in the meeting? If it's a workshop, do you have the invitees pared-down to those that will be actively participating? Is there work they need to complete before the meeting, so they can be active participants? If it's to persuade, these should be in smaller formats. Preferably 1-1 to start, so objections and resistance are raised in low(er) stakes meetings. Meetings should end with a summary of decisions, next steps, or some other call to action. Preferably these are recorded somewhere and distributed to the rest of the attendees or a wider audience if needed. reply rightbyte 17 hours agoparentprevThe far biggest time sink is not what you logged though, but how you need to pad estimates and delay work to please the Scrum Lords. Like, the burndown chart has to be nice and steadely go to zero. There is no way to do that without decoupling reported hours and estimated hours from actual hours. Or points. It doesn't matter which. reply lowercased 16 hours agorootparent\"POINTS AREN'T TIME! THEY'RE EFFORT AND/OR COMPLEXITY!\" I've been routinely told. Yet... low complexity stuff was expected to take less time, even if it was high effort. All 'in my experience' of course. Changing 95 files because someone didn't want to centralize some value in a method call last year (YAGNI!) is now high effort, even if low complexity. Then... \"that's too many files in a PR! break it up! no one can review that many files!\" It's the same two line change in each file - this shouldn't take that long to 'review'. I've often spent more time arguing about points/effort/estimates than doing the low effort work. But if we don't record it properly, you won't get 'credit' for the work! Slow-paced insanity when taken anywhere near close to its logical conclusions. reply cassianoleal 14 hours agorootparent> \"POINTS AREN'T TIME! THEY'RE EFFORT AND/OR COMPLEXITY!\" I've been routinely told. Yet... low complexity stuff was expected to take less time, even if it was high effort. All 'in my experience' of course. This realy grinds my gears. I had a recent experience with a scrum master (technically a delivery lead but in practice a scrum master). Really nice guy, smart, easy going. We had many discussions about the value of estimates, and the whole \"it's complexity, not time\" trope would come up. So I asked what the estimates were used for. Turns out they're used to forecast cadence / velocity. Of course, knowing that we were going to be asked why a small story was taking two weeks to complete, we'd start sizing based on time. After all, we're humans, biased and flawed. Now you tell me, how do you want a measure of complexity to be a predictor for cadence when these 2 things are at best orthogonal? reply steveBK123 15 hours agorootparentprevAlso don't forget story point Goldilocks. We don't create 1 point stories, you need to roll this up with another story! Hey we don't do 13 point stories, you need to break that one up! 8 points? you sure that isn't a 5? 2 points, 3 points.. what's the difference just mark it as a 2. OK so basically we just have 2s & 5s then? Amazing. reply lowercased 14 hours agorootparentI had a colleague who told me his secret - \"I just say 3 or 5 to anything\". That was it. He would pause, then say 3 or 5. Anything I was asked to estimate, I'd give real effort estimates based on their scale. And was always pushed back on like you noted above. And it was a constant struggle. Yet... I always (like... over 95% of the time) hit all my targets, delivered early, and would sometimes pick up the other slack. The other guy with 3/5 - would almost always get pulled in to some other project (or aspect of the project) so almost never got his stuff 'done' (often I would finish it). But on paper... his estimates were always 'so easy' and his tickets always got done (often by me) but I was the 'difficult' one (for many other reasons beyond this). reply steveBK123 14 hours agorootparentAh yes, but remember \"we don't measure individual velocity!\". So all that gets remembered is .. this guy always argues in the scrum meetings, AND his estimates are always high, smdh! reply cpeterso 9 hours agorootparentprevIf you try to right size tasks, you can just count tasks instead of estimating them. This approach even has a catchy brand name in agile circles: #noestimates. In every team I’ve tracked, the task count burndown velocity was impressively linear, whether looking at weeks, months, or years of data. I think we can thank the Law of Large Numbers, with shorter than average and longer than average tasks balancing each other over time. (We never bothered with story points, so I can’t compare.) reply candiddevmike 16 hours agorootparentprevI love hearing \"points aren't time but you can think of them like days\" reply ed_elliott_asc 16 hours agorootparentMy response to estimating is that if you want anything accurate I’ll need time to estimate - roughly 1/4 of the estimated work should be spent estimating. As a rule of thumb, if the work is estimated to be a day then is should take me 1/4 day to estimate. If two days then half a day to estimate. If 4 weeks then 1 week to estimate. We normally continue with guesses that are meaningless. reply bee_rider 16 hours agorootparentWhat would you do if they actually gave you a week to come up with an estimate? Start drawing Gantt charts? 1/4 seems reasonable for a day or two, but I dunno… it seems like there must be some constant factor? reply ed_elliott_asc 15 hours agorootparentI’d draw a lot and probably prototype as well - I suppose the main thing is that we never get to that as we estimate but don’t do “big design upfront” reply peteradio 16 hours agorootparentprevHaha after 5 years our scrumlord finally relented that 1 point was 8 hours for our team because even he was apparently getting tired of the cognitive dissonance. reply yieldcrv 16 hours agorootparentprevI saw this on my last job! I was already adding time to my work like an extra point or two here and there But then in the grooming session the whole team would guesstimate even more story points! I was dumbfounded! This was beyond all of my levels of tolerance and rationality but it kept happening every sprint until something that was a 0.5 for me was a 5 point and I would have two 5 point tickets for the whole sprint that I would submit to QA one day before the sprint ended, 9-10 business days later and actually doing that made me a star performer, what the hell!? reply steelframe 16 hours agorootparentWhen I've used Story Points as the team manager, one of the things I made sure of was to completely avoid looking at any given team member's velocity, ever. I only cared about the team velocity, and only for the purpose of estimating risk to the timeline. At the round-table people would report their retired points, and I'd add them to a running tally I kept on a piece of paper next to me. \"2+1+0+5+2+2+8+0+1.\" Then I'd record the velocity for the week for the whole team, and we'd move on. reply pmarreck 11 hours agorootparentSmart. Not all contributions can be measured in points. Some team members do a lot of support/mentoring work, for example. reply inanutshellus 16 hours agorootparentprevScrum teams are self-managing, and point values are used for gauging your own team-workload. When you point a \"0.5\" and your team points a \"5\", stop and discuss the discrepancy until an alignment can me found. Keep doing that, every task, until you a collective meaning of \"a point\" is found. Personally: * Less than 1 - These are a smell and should not exist. These misalign incentives and encourage \"bike shedding\". * 1 point tasks - no task that requires 2 people (dev and qa) is a 1-pointer, so this is something that needn't be QA'd. 1 point tasks should be rare items that can't be a subtask of a \"real\" task. * 3 point tasks - These can be done in a day (depending on the team's opinion, this might be multiple people and still be 3 points). Virtually every task should be a 3. * 5 point tasks - These are tasks that cannot be broken down to be done in a reasonable amount of time. These are generally things that have minor external dependencies. (\"not hard but I'll have to get a server spun up by the unix admins.\") * 8 point tasks - These are rough tasks that haven't been fully dissected by the team and are the scrum version of a \"code smell\". The team should break these down and dissect them. * 13 point tasks - \"There be dragons here\" tasks. Large unknowns and these tasks should not be added to a sprint until they're broken down further. reply ed_elliott_asc 16 hours agorootparentMeetings are long enough without people spending extra effort doing it right :) reply inanutshellus 15 hours agorootparentSharpen the saw, man. It's a one-time conversation (per new team configuration) that makes every conversation thereafter fast. My team's pointing sessions are lightning. Even when you do have a new team member that wants to discuss a \"0.5-vs-5\" point disparity, you explain the above in less time it took to read it and get back to work. reply flir 16 hours agorootparentprevThat kind of inflation corrects for itself. Because you're supposed to look at the previous sprints to judge how many points you'll get through this sprint. reply fatherzine 16 hours agoparentprev\"people had fewer than 3-4 hours per day to actually work\" had the same experience. the unwritten expectation was to pull 8 hour coding days /plus/ all the Scrum overhead. if you don't like it, there's 1000 guys waiting to take your place, partly thanks to remote. a core reason we haven't fire you yet is that it is costly to ramp up new people, but don't try our patience. see also \"hire fast fire faster\" reply cassianoleal 14 hours agorootparent> \"people had fewer than 3-4 hours per day to actually work\" had the same experience. Same. Even worse, spread out in between meetings. Some days I'd have barely started understanding the work to be done and it was time for the next meeting. Rinse and repeat for each \"non-meeting\" slot throughout the day and the whole day is a write-off. reply torginus 16 hours agoparentprevNever in my life have I encountered anyone from the engineering side who spoke positively about scrum. It's always the consultants and scrum masters and their ilk who push the agenda. Never have I ever heard about any story about agile making things better. reply tonyarkles 16 hours agorootparentI've worked at exactly one company where Scrum worked really well, but it was a somewhat... unique isn't the right word, but a specific set of circumstances: - the team was made up of primarily junior engineers with a small handful of intermediate and seniors - the company's work was split between a product and N consulting projects - the company had standardized on a specific \"default\" architecture (Spring Boot + Angular) with a bunch of pre-existing components that teams could use to accelerate their projects - the projects (product and consulting) were generally managed by the intermediate engineers with a handful of juniors on each project doing most of the day-to-day work - the seniors were mostly on the product side but had latitude to go help on any of the consulting projects if anyone was stuck Scrum with the daily standups and bi-weekly retros worked great here. The seniors went to all of them. If someone was getting ready to start on something and they weren't aware of existing components that were either available from the library or available to libraryize from a different project, we'd help facilitate that. If someone was getting stuck on either a tricky debugging problem (of which Spring Boot was good at making) or a complex design problem, one of us would stick around and just get it solved with whoever had the problem right away. And on the other side of it, we were sufficiently looped into the various projects that we could use that as input for larger-picture architecture decisions etc. reply The_Colonel 13 hours agorootparentprevI'm old enough to have extensive experience from before agile methodologies were in vogue and things are generally better with Scrum / Agile than they were before, ceteris paribus. Sometimes the process worked better, sometimes worse. It depends a lot on the company culture and people. The company I'm currently at has a very good process (SAFe). (I'm an engineer to clarify) reply torginus 3 hours agorootparentI also think there is a certain comorbidity of an organization pushing scrum heavily and other dysfunctions. From what I've heard before my time, a lot of traditional organizations had a non-flat hierarchy and a set of 'bosses' - people in charge of personnel, planning, requirements, and technical decisions. In 'modern' orgs this has been replaced by a 'matrix' structure with each team having a dedicated product owner, scrum master, line manager, requirements engineer, architect etc. While the traditional org structure had some shortcomings, mainly having to do with the fact that if said boss didn't perform, then the team had no chance, and that so much institutional knowledge was locked up in said boss, that they were nigh-impossible to replace. Modern management techniques are about replacing potential excellence with guaranteed mediocrity. reply ed_elliott_asc 16 hours agorootparentprevI’ve seen it to be very effective but it is rare - especially in enterprises where the old “project office” folk switched to being scrum masters. reply ljm 16 hours agoparentprev> Of course, the Scrum proponents will rush in and tell me that we were doing it wrong I don't think it's helpful in any discussion to try and pre-emptively dismiss people who might disagree. People have been doing that for the decade or so scrum has been mainstream and it just dumbs the discussion down to he-said she-said. That being said, agile as it was originally described in the manifesto was not prescriptive, and scrum, while it was intended to follow in its footsteps, has been a victim of its own success. It's now firmly in the domain of other highly-prescriptive management frameworks thanks to the effort of consultants and managers who adhere strictly to the letter of scrum without paying thought to the essence of it. Most people I know who were fans of scrum back in the day have distanced themselves from it because it's not agile any more. Certainly not with consultants selling SAFe as an agile methodology. reply Aurornis 16 hours agorootparent> I don't think it's helpful in any discussion to try and pre-emptively dismiss people who might disagree. But that's exactly what the people I'm talking about are doing: They define scrum as something that works, thereby preemptively dismissing any complaints from situations where it didn't work. reply mirchibajji 16 hours agorootparentprevJust like \"You are not your code\", may be we should also have a \"You are not your Process Certificate\" mantra. It is not the people that are dismissed, but those who insist on The Process at all costs. reply ajmurmann 16 hours agoparentprevI personally strongly dislike a lot of aspects in SCRUM (individual commitments stick out especially, together with the entire role of Scrum Master), but am not sure I see an alternative for some form of agile (without the TM), that is adjusted to the individual team's needs, for the vast majority of teams. Whenever I read these criticisms, a lot of it rings true, but I fail to understand what the alternatives looks like besides Waterfall or chaos. Whoever does these write-ups always complains about some Agile™ thing, but takes the alternative for granted. What activities and meetings would be dropped or replaces and by what? It's not very meaningful to criticize something when comparing it to nothing. reply RaftPeople 15 hours agorootparent> but I fail to understand what the alternatives looks like besides Waterfall or chaos. What I've seen pretty much my entire career (early 80's) for projects is just a straightforward process of up some front planning, phased design+dev, management of tasks through a regular (weekly or twice weekly) low overhead process (what's ready for next step, where are challenges), etc. The key is having an experienced technical leader to guide the process. Typically, PM's don't have enough detailed technical experience to really understand how to make this stuff work. reply rawgabbit 15 hours agorootparentprevMy biggest pet peeves are (a) when mature software or mature organizations pretend they are a three person startup and refuse to document anything and have meetings all day (b) when product owners say f the existing architecture or tech debt and literally tell you to rip out everything and install a new tech stack because it is agile. These morons know nothing and bark out orders based on their agile bonafides which is nothing more than snake oil. A magical cure all irrespective of the problem you are trying to solve. reply kevinmchugh 16 hours agorootparentprevThe obvious alternative to scrum for many teams who wish to be agile is something based on kanban. reply ajmurmann 15 hours agorootparentWhich is another flavor of Agile which is what everyone is always complaining about. I'd take some form of Kanban any day over doing rigid Scrum by the book. Kanban needs a lot very similar meetings though. You still need to fill the backlog, discuss the tickets. If you were to do Kanban by the book as described by the Agile Alliance, you'd still do standups, retro under a different name etc. reply kevinmchugh 13 hours agorootparentIn my experience people complain about strict processes that books or consultants say must be followed. I've rarely heard someone complain about the content of the agile manifesto. So start with what you've got, and iteratively keep what works and chuck what doesn't, until you have a process that works. I'll add that kanban means much less time filling a backlog, to the point that an individual can own that, and you're eliminating that meeting. reply ajmurmann 11 hours agorootparent> I'll add that kanban means much less time filling a backlog, to the point that an individual can own that, and you're eliminating that meeting. I've only ever been on projects where the backlog was filled by a PM and or lead engineer and then reviewed collectively and maybe some amount of re-shuffling would take place. Are you saying you've been in meetings where the backlog started empty and it was populate with the entire team in the room? reply kevinmchugh 9 hours agorootparentI've never seen an empty backlog, but I've been in meetings the purpose of which is for an entire team to rubberstamp the order of the backlog. This is \"grooming\" or more recently \"backlog refinement\". You don't need to do this in kanban. reply ajmurmann 6 hours agorootparentDon't you need to go over newly added tickets and ensure the tickets are clear, order makes sense, etc? Whenever we've skipped this some issues would emerge when tickets get picked up later. Depending on the project domain and if a PM or engineering lead wrote the tickets the issues would be either more about technical issues or misunderstanding of business requirements. > I've never seen an empty backlog How about a backlog with stuff near the top that's no longer relevant or has drastically dropped in importance? reply kevinmchugh 5 hours agorootparentTickets are often written imperfectly but that doesn't necessitate a standing meeting for the whole team imo. Make your pm and em hash them out, make the most informed engineer write the ticket, but don't make everybody watch. If the top of your backlog is uselessly stale, you're spending too much time writing tickets in the distant past and not enough recently (or maybe congrats on your velocity?). A ticket that's so old it needs to be overhauled to be worked on was written prematurely. This is one of the things kanban is good at. Edit to add: a team that's heavily reliant on a PM might not be a great fit for kanban? It's not for all teams, and is a natural fit for some reply pillefitz 15 hours agorootparentprevHow do you refine features? How do you discuss team improvement measures? How does prioritization happen if you're working on a product? The answer might be simple for small teams, but a lot more complex for larger teams, where the result might look eerily close to Scrum. One difference would be that meetings will take place infrequently and only \"as needed\", where I wouldn't trust most teams to recognize their needs. reply RaftPeople 14 hours agorootparent> How do you refine features? I'm really curious about this question, are you thinking that not having Scrum makes it's harder to refine features? I'm trying to understand what assumptions you are making, because I've never worked in a Scrum environment, but have always refined features as part of the natural flow. reply The_Colonel 13 hours agorootparent> have always refined features as part of the natural flow. \"natural\" as in \"law of nature\"? Or is it just a process which crystallized in the course of your career as something which makes sense to do? Scrum, and other methodologies are mostly a collection of such processes which proved to be useful, are somewhat standardized for learning and communication. One can reinvent many of the Scrum processes independently, but I kinda don't see the point. Just like I'd rather use a finished library / framework rather than try to hack together my own. reply al_borland 15 hours agoparentprevOn the opposite extreme, our teams use Jira, kind of structure it like Scrum, but don’t do any of the actual planning. It’s complete chaos and we have a similar level of meetings, maybe more, with everyone trying to figure out what’s going on and when things will be done. The go-to is a 30-60 minute daily meeting with each individual project manager for each project. Sometimes there are 3 project managers working on different aspects of the same project, so we have 3 hours of meetings (spread throughout the day) to give the same updates 3 times. Of course, there is no update, because all we do is attend meetings to provide updates. Occasionally our Scrum Master will put an actual scrum meeting on the calendar, but then talks about whatever he wants, and it never moves the ball forward from an organizational point of view. A retrospective would go a long way; we’ve never had one of those. I bring that up often, as the 1 meeting we should have, if we only have 1 meeting. I tracked my time meticulously for several years, and when I used it to point out how horrible the current environment is, I was told I was doing too much and should be much my lazy about the tracking, to the point where it becomes meaningless. reply therealdrag0 6 hours agorootparentIt sounds like you just have poor leadership or poor PMs. Daily meetings should be 15 min with an extended optional “parking lot” to dig into things and everything else should be adhoc meetings with as few engineers as possible, except a weekly and monthly meetings. I’m a team lead (not manager) and I get over 50% if my time is builder time and I haven’t measured but I’d guess my teammates are around 80%. reply lacrimacida 16 hours agoparentprevI have a similar experience to yours. My organization even hired a scrum expert who is probably just deadweight, he’s on mute in all our meetings for the past 6-8 months. It’s also true about having little actual work time, in my org we spend so much time in meetings that in the end 3-4 hours of actual work are left on a daily basis. I objected to this but was told everyone should learn everything, end of story. We’re supposed to be repleaceable cogs in a machinery and that goal was reached by now. reply jacobyoder 15 hours agorootparent\"everyone should learn everything\" I've been in a couple places where I did know 'everything', or... near enough. The more I got to learn outside my own specific dept, the more cynical and frustrated I became (usually). You start to notice that entire groups of people are often just sitting around for days doing absolutely nothing because they're waiting for one person who's out for the week, etc. Or you learn that people just spent 4 months working on something that was rejected in a meeting 4 months earlier, but... the original team still wanted to do it anyway, and therefore couldn't help your group over the past 4 months. reply Viliam1234 15 hours agoparentprevI was trained in Scrum, but the main thing I learned was that it is the opposite of what the \"companies using Scrum\" do. When I mentioned that in the company I worked at (the one that paid for my training), I was told that \"we do Scrum differently here\". They paid for my Scrum training just to tell me to shut up and do it the traditional way, only now I was supposed to call it Scrum, and the existing meetings had to be renamed using Scrum terminology. Oh, except for the retrospective (the part where developers provide feedback on everything, including Scrum itself), because retrospectives are a waste of time! So it seems to me that the main reason why \"true Scrum has never been tried\" is that most companies never intended to actually try it. They just wanted the buzzword. reply stcredzero 15 hours agorootparentSo it seems to me that the main reason why \"true Scrum has never been tried\" is that most companies never intended to actually try it. They just wanted the buzzword. Scrum is actually a cultural change. The methodology is just the surface stuff, like the buzzword. It also doesn't actually happen at the company level, unless the company is quite small. It happens at the group level. I just thought of this: The Scrum that can be named, is not the true Scrum. \"Practicing\" Scrum by following dictums in a book is sort of like practicing marriage by following dictums in a book. Those are just guidelines, and the reality is at a deeper level. EDIT: Come to think of it, that can also be interpreted as: Therefore Scrum is broken as a methodology. It cannot be \"followed\" at scale. (Much as communism is broken as an economic system.) reply Foobar8568 16 hours agoparentprevI had some coworkers who would spend 6hours in scrum related meeting every Tuesday....In addition to their daily 2h scrum meetings ( multiple teams and role meeting coordination). reply brightball 6 hours agoparentprevScrum often has very subtle issues that snowball into chronic issues. I've never seen it done well outside of contract dev shops where they are literally negotiating and selling each sprint to a client. https://news.ycombinator.com/item?id=17154355 reply onion2k 16 hours agoparentprevThe amount of time lost to doing Scrum things was so out of control that some people had fewer than 3-4 hours per day to actually work. If the aggregate of the sprint planning, backlog refinement, retro and dailies is more than 10% of the total time (eg 1 full day out of a 10 day sprint) for most of the team then something bizarre is going on. If the everyone is losing 50% of their time to agile things then your process is impressively broken. reply j4yav 16 hours agorootparentIt’s funny how every team I have worked on that embraced scrum was impressively broken in the exact same way. reply pillefitz 15 hours agorootparentInteresting, I never experienced a team broken by Scrum. Just a retro, planning, demo, 15min daily and that's about it. Lots of other meetings, yes, but none of them due to Scrum, but rather complex company processes. reply calvinmorrison 16 hours agorootparentprevUntil you're on 4 teams reply michaelt 16 hours agorootparentIf a person is in 4 teams, and they're not a full-time 'product owner' where going to meetings is their whole job, I'd say something bizarre is going on. reply sdiupIGPWEfh 5 hours agorootparentHow many teams before you consider it bizarre? As a mere individual contributor / senior dev, I've only ever officially been assigned to a single team at once, but there are times when I'm juggling tickets on 3 different teams' Jira boards and attending 3 different standup meetings. Thankfully, I typically don't have to worry about sitting in on more than 2 teams at once, and I'm definitely an outlier. For me, this arose from joining a growing team before it split several times and also from predating all the current product owners. reply kjs3 16 hours agorootparentprevI don't think it's that 'bizarre'. My team has been an overlay team for years. We provide services to many teams. Since the glorious transition to agile and product focus, we had to sacrifice someone to be the product owner, so their 'whole job' is overhead management, which they hate. Now, every team wants someone from my team in every standup (\"but we'll be blocked if a question for your team comes up and no one is standing in the corner patiently waiting to answer it\") and definitely wants someone in every sprint planning. 8-ish person team, dozens of projects, and time disappears very, very fast. I've managed to push back on the 'every standup' nonsense so we don't spend 100% of our time in meetings, and in return the agile folks are using their 'metrics' to basically tut-tut and say we don't do any work. I can see where if your whole job is on a single project where there workstream can be easily decomposed into 'sprint-size' chunks, agile and the rest are probably useful. But that's not every job, and maybe not most jobs, and it sure as hell isn't my job. But like so many other have concurred, and as I see on a routine basis, there will be someone with 'Agile' or 'Coach' or 'Product' in their job title will have an expansive explanation why I'm Doing It WRONG. Capital One seems to have figured it out...maybe there's hope[1]. [1] https://www.reuters.com/technology/capital-one-scraps-1100-t... reply onion2k 2 hours agorootparentevery team wants someone from my team in every standup In agile you're supposed to know what's going into your sprint, and each ticket should meet your \"definition of ready\". Teams shouldn't need someone on hand because they should already have refined and unblocked issues before the ticket was added to the sprint. Whatever it is you're doing it isn't agile. reply aeturnum 16 hours agoparentprevI've had good luck with small teams implementing \"scrum\" which really came down to: the team finding a minimal coordinating process that uses short units of work. I will say that the part of scrum that I like (and I think most people like) are qualities that it's easy for like minded people to recognize. But if someone doesn't get...why it's good to summarize your progress for the team or break things up or understand what a task does for multiple stakeholders...scrum does not communicate that to them effectively. Imo it feels like a system you can use to teach people how to work effectively, but in general those who haven't seen most of it themselves often get buried under an avalanche of terminology and procedure. reply andrei_says_ 16 hours agoparentprevI really like Dave Thomas’ talk Agile is dead long live agile. Dave’s name is listed as one of the creators of the agile manifesto. Basically, agile is an adjective. Anyone using it as a noun is selling snake oil. Yes, it is that bad - a whole industry built from the ground up to monetize a simple concept by enshittifying it into its very opposite. https://youtu.be/a-BOSpxYJ9M?si=tCvDcHYv7F77XbZ9 I also like Basecamp’s shape up process which seems to follow the spirit of the manifesto. reply h335ian 15 hours agorootparentBeen using ShapeUp for nearly a year now in an org of ~50 engineers. Let me start by saying, if you intend to adopt ShapeUp, spend a great deal of time reading and buying into their structure of teams. Aside from SIP/QA & KTLO work, they flatten the “Core Product team” and build ad-hoc teams for a pitch that has won at the betting table - for that cycle. Trying to maintain standing teams with domains of ownership is a very challenging way to adopt this process. In my experience, unless the entire org is drinking the kool-aid - hard - you end up with 6w cycles of waterfall. Pitches morph quickly from “present your idea that we bet against” to “write up a detailed design doc, along with an Epic, backlog and all projected work” - then the org will just do the work they want (betting or no). Now your team is committed to delivering on your pitch - any other work just gets dumped on the wayside - unless you’re on-call of course. As with any other incantation of an agile process, you can bastardize it to confusion, thinking you’re smarter, or “we’re adapting this to fit our org”. Folks, this stuff is a discipline. You have to buy in, you have to learn the principles, you have to practice them - as described - until you attain some degree of mastery that you can adapt. This is not an individuals game, this is at the org level. The individuals must commit with the org to gaining mastery before customizing to your liking. In spirit - there’s nothing fundamentally broken with Scrum or Kanban or ShapeUp or whatever. It’s really how you hold it - and yes you can shoot yourself and others in the face by holding it wrong. reply andrei_says_ 3 hours agorootparentThank you for this. My sense is that shapeup requires more trust than what a large org is used to. Eliminates the micromanagement and limits the risk to n weeks. reply ethbr1 16 hours agorootparentprevThere should be a saying, to the effect of: no enterprise idea can survive intact if it doesn't include a space for consultants. Agile probably would have ended a lot better if it had been as designed... plus a requirement that you had to hire an agile specialist to sit in a closet. The agile specialist doesn't do anything but sit in the closet. ... but on the plus side, the agile specialist doesn't do anything but sit in the closet. reply h335ian 14 hours agorootparentprevDoubling down on my comments about ShapeUp (et al) as I reflect. Engineering management, in my experience, has an allergy to agility. They can and do take any methodology, turn it into a process with a rigor (they love that) and strip agility from the mix. They are addicted to well defined requirements, some degree of estimation and being able to predict/project things like delivery, velocity, contributor performance, etc. We engineers love the principles of agility, so engineering management tries over and over to find that happy medium where they have a well defined process that gives them what they want but imposes the least friction against the agility your engineers crave. Custom solutions win the day. I have lived through all of the above. I remember when Agile was introduced, do you? Do you recall how violently reactive engineering managers were to this concept? It goes against everything they are supposed to do - manage. Agility inherently means they lose some degree of management ability. It means they lose their precious waterfall where things are meticulously (ridiculously, inaccurately, elegantly, uselessly) pre-planned on paper. IMHO this is why we see every methodology that supports being Agile - bastardized to the point of confusion, academic arguments based on (not having actually learned, practiced, or gotten good at anything) gut feelings of “how we should do it here”. Leading, managing work, organizing resources and getting shit done is a skillset that encompassing multiple disciplines. All are documented and practicable - we apparently don’t have the discipline to actually read and practice. We’re like a bunch of yokels on YouTube commenting on who’s a better MMA fighter, telling Joe Rogan he’s wrong - but only a select handful of us actually speak from authority. Only a small handful will actually take on the RISK of trying to understand the literature and practice a methodology like a beginner - without questioning the teacher or the teachings. All that said. I have seen both Kanban and Scrum be wildly successful. The key ingredient in each of these was a shared humility and curiosity between engineers and managers and an environment that celebrated learnings and put no penalty on getting it wrong. The lack of hubris was absolutely the ticket to an agile environment where shit just got done, engineers had a GOOD TIME, we built meaningful product and we weren’t worried about blasting time in meetings because it never impeded our ability to get shit done. Once the engineering org can demonstrate its key metric (getting shit done) the battles with product cease!!! Product can trust that engineering will get shit done - without handwringing on “when” - and they can properly focus on “what” shit to get done. When engineering is flailing around on their methodology, process or agility - they lose trust. That’s when product starts thrashing. That’s when you start to see initiatives/projects start and never finish, along with shifting priorities. ShapeUp does an excellent job of giving product a tool to direct what work we’re doing - hopefully making sure we’re working on the right thing. However, if you’re trying to bastardize ShapeUp to fit your engineering org structure - it’s VERY difficult to demonstrate and project “well get this done”. Further, if you think you’re gonna keep your teams intact and do pitches per team - you’re already broken, committing to more than the org can deliver, creating conflict between teams on how to do the work, leading you right back to waterfall. Rather than building the right team of resources for the pitch/cycle - you now force all your teams to produce design docs, plans, backlogs - which have to go through review, get picked apart by other engineers, only to find your assumptions were wrong and the deliverable looks quite different than the design (shocker!!) I’ll conclude to say we’re likely all doing some degree of waterfall++, branded as some form of “agile” methodology. If you wish to see that change, encourage your peers and your managers to start with your team, pick a methodology, go exactly by the book, get “good” at it with practice over an extended period, collectively enjoy and DOCUMENT the many “aha!” moments along the way, the proliferate that out to the rest of the org. High performing teams are hard to ignore and at some point the org will ask why - simply be prepared with HOW you adopted and your learnings. Good luck out there reply kurko 16 hours agoparentprevMy hypothesis is that those people I worked with circa 2007-2015 that did Scrum really well (not everyone did), were happy about using Scrum, and delivered good results, ended up progressing/moving into management and lost contact with the day-to-day work. 1. They have an imaginary reality based on what it once was. 2. They don’t accept the evidence. 3. They have incentives to build systems of people to increase their salaries. reply BeetleB 15 hours agoparentprevCan't speak to your company, but in my experience all Scrum (done well) is doing is making the overhead explicit and easy to quantify (as you yourself were able to do). Eliminating Scrum doesn't mean you'll save that time and overhead. It will simply be hidden. Of course, that's with Scrum done well. If you're having 30 minute daily meetings, you have a point. reply hoc 16 hours agoparentprevNo True Scrum Master... should get its own Wikipedia entry at last. (Ah, too late. Guess I should have refreshed) reply ranit 16 hours agoparentprev> the Scrum proponents will rush in and tell me that we were doing it wrong or that it's not truly Scrum if it's helping more than hurting Did you worded it like this on purpose, or you wanted to say the opposite? :-) reply poisonborz 16 hours agoparentprevI don't get your problem. What were you talking about on those meetings. Wasn't it about the project? Is discussion about the project, the features, planning lost time? reply koonsolo 3 hours agoparentprevWhy not bring this up in the retrospectives? Why not make your process leaner in the retrospectives? That's what they are for, no? Self-organizing teams is at the core of agile. So I hate to say it, but if you don't self-organize as a team, you're doing it wrong. The fact that you have to go to your VP to present hours says it all, your team is not empowered. reply libraryatnight 16 hours agoparentprevI feel like SCRUM and anything like it is an attempt to formula and process-ify a thing that dies when you do exactly that. At my company we waste a ton of time on this stuff but we also have a ton of people with jobs that really only tie in to it so they will always defend it. Bureaucracy serves itself etc. reply ninkendo 9 hours agoparentprev> some people had fewer than 3-4 hours per day to actually work. 3-4 hours per day? That seems like a lot to me! Looking at my calendar, I’m lucky if I get that many hours per week. (It’s not all scrum shit, but let’s just say between sync-ups, status reports, daily standups for multiple projects I’m involved in, architecture reviews, breakouts, etc etc etc, I’m lucky if I get a full work-day’s worth of coding done in a week.) reply iLoveOncall 16 hours agoparentprevWe did a planning exercise every sprint at work to see how much time people had to work on features once you removed meetings and other ceremonies, RTO, holidays, oncall, etc. We were tracking that per employee. Everything was fine for a few months and then I added a \"total\" column next to each row and it became apparent that we were spending close to 60% of our sprint on non-development related tasks. On 45 work-days per sprint we had something like 19 days for features. Needless to say it shocked my manager. He's not against change thankfully but we're still evaluating what could be better alternatives. reply kevinmchugh 15 hours agorootparentDo I understand correctly that you're doing nine week sprints? That sounds extremely long to me. I have to think you're spending lots of time planning work that won't be done. When you plan a sprint, how often does the work at the end of the sprint actually get completed by end of sprint? Say you plan to start the \"add Foo button to Bar page\" in week 7, do you actually do that? That would require some really strong estimation skills and a remarkably stable product and business environment. What's the point in the sprint where you're doing more unplanned work than planned? Or how much carry over work do you have? Because if I was trying to plan nine weeks of work, I'd get it drastically wrong, and waste tons of time planning stuff we weren't gonna do. I would make the next few sprints 4 week ones and plan to get down to 2 week sprints after the shorter pace starts to show it's strengths. Or maybe you have 9 people doing 1 week sprints and that's how you got 45 days. In which case, whoops! I have no suggestions! reply iLoveOncall 15 hours agorootparentOh yeah no I meant 2 weeks sprints with a total of 45 days (ish, removing vacations) for the whole team. Sorry that wasn't clear. reply AtNightWeCode 16 hours agoparentprevJust by switching from Scrum to Kanban one can improve progress a lot. For being two very similar pull based systems the difference in effectiveness is just incredible. reply lars_francke 16 hours agorootparentAgreed. We use Kanban and are very happy. We used to not do any estimates but have voices from others asking for them to do better planning of marketing and sales activities. I understand where they are coming from but so far it's mostly guessing So: Do you do estimation in Kanban and if so, how? reply skydhash 14 hours agorootparentYou don’t do estimation without prioritization. As a consultant, my default way of working is kanban, often setup on Trello. Once I deconstructed the project into features, the first thing I do with the client is arrange them by priority and arrange them into sets for releases. If sales and marketing need to do planning, then they need to tell what they want to push back to the backlog so that the feature they want are on time. reply lars_francke 13 hours agorootparentWe do that already, yeah. But they'd like estimates on a lot of issues so they can prioritize better. I believe it's a waste of time though. There is no good solution for this I believe. reply edgyquant 13 hours agorootparentprevI think generally you should be able to break some feature up into a series of very small tasks that can be estimated. So you may not be able to estimate an end to end feature accurately but you should be able to give rough ETAs for when different functionality will start to trickle in reply kjs3 16 hours agorootparentprevThis is what we've done of late. Massive improvement. Much lower time commitment and we get a good (enough...not perfect) view of the metrics we really need to focus on. reply JohnMakin 17 hours agoprevI've seen it suck even worse when trying to manage large X-Ops organizations. Something about the work, let's call it DevOps for the sake of simplicity, simply does not seem to lend itself well to the scrum methodology. Often priorities will shift rapidly even during the course of 1 working day, issues are vaguely defined and poorly scoped by nature (AZ1 cannot reach AZ2, plz fix ASAP), and the work is extraordinarily hard to measure complexity/effort (a one line config change can take weeks of investigation and touch tons of services). I've seen plenty of people try though, to varying degrees of unsuccess. A kanban style system has always worked better for me personally. reply simonjgreen 17 hours agoparentSee this all the time. There is a huge distinction between teams that are oriented to be proactively planned and teams that are oriented to be reactive. Neither is bad and both need to exist. Things will break people will have to fix them and therefore reactive work will exist. reply freedomben 16 hours agorootparentYes, exactly! In my career I am usually the first ops/DevOps person on the team. These are usually startups who have been run by developers. Nothing wrong with that, I've spent most of my career as a developer. But there is typically a huge blind spot with developers when it comes to ops. That could be a whole blog post and will someday, but relevant here is that they often do not understand when I try to explain how poorly scrum fits with ops. It can be remarkably frustrating for both parties to discuss how to plan ops work. Even breaking the work down can be a battle. Traditional software developers like to push for little chunks of work broken down into tiny pieces. However, when you are talking about a task that is completely and utterly unknown, and could take weeks to result in a one or two line config change, it cannot be broken down without visiting the future, finding out everything we don't know yet, and returning and planning it meticulously. Unfortunately, we don't have that time machine yet reply JohnMakin 16 hours agorootparentThis brings flashbacks of so many conversations I've had with scrum masters during kickoff meetings - \"Estimate how many points this story has?\" \"Depends on if I figure out the answer in 20 minutes or 20 days\" reply JohnMakin 17 hours agorootparentprevI've seen this handled in various ways. Usually, the scrum master/PM will set aside extra \"bandwidth\" during a period that is expected to be heavy in interruptions. However, getting that right is almost impossible, and you can easily end up with way too much work in a sprint or way too little. reply dijit 16 hours agoparentprevDevOps is definitely my favourite, since the history involved here is on the nose. For those not in the know, \"DevOps Days\" was the conference that intended to deliver Agile to Systems Administration. The job title that was supposed to come from it was Agile Systems Administrator... Alas, people got the conference conflated with the \"10+ Deploys a day\" talk from Flickr which merged ops and dev, and a mythology was born where everyone has their own interpretation of what devops means. :) reply liveoneggs 15 hours agoparentprevOperations is operations and fits well into the kanban system. Business operations should consider embracing kanban. Work comes in, work goes out, repeat. Scrum (with sprints and things) should exclusively be used for New Product Development and Pre-Launch iterations. Using it for operations/ongoing work/enhancements is broken from the start. \"Waterfall\" as defined by these articles is mostly a strawman. Standups only work if someone is in-charge enough to keep them on track. reply palata 17 hours agoprevI agree that agile methodologies are a whole lot of bullshit, but the problem really is cargo cult. Most people working in software are juniors, and that includes most managers. The fact that they have a title of \"VP operations\" 2 years after graduating does not magically make them experienced. What do they do then? They read books about \"how to lead a team\", and they blindly apply what they find there. Because they have no clue. Many times they have not even had a team lead in there professional career themselves: they jumped right into management. And of course their team of junior developers (with high titles that don't make them experienced either) don't know better. So it ends up in a big cargo cult. Which sucks. reply nine_k 16 hours agoparentRe-reading http://agilemanifesto.org/ (which is ridiculously short) and comparing it to an \"agile practice\" around you is very eye-opening. Some companies actually practice agile development, and it works. They are small, nimble, and have very little process. But then they grow... reply a_square_peg 15 hours agorootparentWonder how 'Sprint', 'Scrum', 'Kanban' etc. all evolved out this? I really can't understand how it went from 'individuals and interactions over processes and tools' became formalized processes of daily standups, 2-week sprints, etc. reply nine_k 15 hours agorootparentKanban came from elsewhere. The word comes from post-war Japanese car factories, but the principle is older. Kanban boards were physical boards, with tokens representing various machines' or workers' availability, and the presence of things to work on. It's more a work-scheduling mechanism for known, understandable, repeatable work. https://en.wikipedia.org/wiki/Kanban reply a_square_peg 14 hours agorootparentInteresting to know - thanks for the info. Strange to think that something designed for 'known, understandable, repeatable work' got adopted by software development. reply nine_k 13 hours agorootparentSome software-related work, like regular changes to a website, or regular SRE work, is understandable and relatively repeatable. Software development work usually isn't. Software development, by its nature, automates away everything repeatable and predictable, so unpredictable and never-before-seen stuff dominates. reply The_Colonel 13 hours agorootparentprevManifesto came out in 2001, you need to take into account the context of that time - the processes were often much more heavy-handed (esp. in big companies) than they are now. This manifesto item was never about not creating any processes. reply agumonkey 16 hours agoparentprevAnd they self reinforce themselves in their biases. As long they say it's an epic and have a burndown chart they feel good. Nothing works, information is lost, quality and velocity is low, but we're very much agile. reply kurko 16 hours agoparentprev> the problem really is cargo cult I’ve said that many times over the years. The irrational mimicking of what others are doing created this Frankenstein model of working that proliferated over the industry. reply Scubabear68 17 hours agoprevOne comment - the article mentions that Waterfall was basically the only approach used prior to agile. This is false. In some industries waterfall was used, but in others software was designed and driven incrementally just as with core agile. The work I did in fixed income brokerages in the early 90s was largely ad hoc agile. reply Zigurd 17 hours agoparentScrum is just one offshoot of Agile. It has become laden with jargon, Scrum-specific job titles, and rapidly trained Scrum Masters. This obscures the fact that a competent team can start with traditional jobs and roles and use The Manifesto for Agile Software Development as their guide, with some modifications for a remote, Slack/Zoom world. Don't be afraid to dump Scrum. reply Scubabear68 16 hours agorootparentAgreed. This is more or less what we did in the 90s, deliver quickly and incrementally with right-sized processes. Scrum adds so much complexity, heavy processes and endless meetings it is truly incredible. reply switchbak 16 hours agorootparentThe XP folks crystallized what a lot of people were doing (in ad-hoc ways) and documented it so others could reuse the learnings more easily. [There's more to it than that, but that's the core of it] I think that's in-line with what you described above. I also think it captured what a lot of folks were trying to do at the time: shorten feedback cycles with RAD, etc. Scrum - or whatever it is that we see in the wild that's called Scrum - is exactly how you (and the article) describe. The way I see it, the corporate types were scared of the devs actually being self-managing/self-optimizing teams, and decided to turn to an Agile-Lite that they could sell as being new and shiney, but it's still the same command-and-control distrustful crap under the hood. (Non-Scrum) Agile did a great job at the lower layers (devs, facilitators), but nothing can change that much if you don't affect the management and exec levels. reply cylinder714 16 hours agorootparentprevIt seems like scrum is the very antithesis of \"Individuals and interactions over processes and tools.\" reply SAI_Peregrinus 15 hours agoparentprev[Waterfall](https://leadinganswers.typepad.com/leading_answers/files/ori...) was an incremental design process directly in opposition to the hirearchial process that it's commonly conflated with. That's the paper that coined the term Waterfall, note the contrast between the final Waterfall process from the traditional process (figure 10). \"Documentation Driven Development\" is basically Royce's Waterfall under a different name. Waterfall has the following 5 requirements/steps: 1. Design first. It'll get replaced (see step 3), but is needed for requirement 2. 2. Document the design. This defines what you're building (this time around) and the tests. 3. Do it twice (build a MVP, test, refactor & replace it as requirements become clear based on customer feedback, update the design & docs & tests, use those tests for the improved version). 4. Plan, control, and monitor testing. 5. Involve the customer. Requirement 3 is what makes Waterfall inherently an incremental iterative process. reply rawgabbit 13 hours agorootparent18F basically follows the process you just described and calls it the agile with a straight face. https://guides.18f.gov/agile/18f-agile-approach/ reply SAI_Peregrinus 9 hours agorootparentMost \"Agile\" proponents think of Waterfall as diagram 1 from the Waterfall paper, when in fact diagram 1 was the process Waterfall aimed to replace. It mostly gets used as a straw man process to oppose, few people seem to have ever read the Waterfall paper to begin with. reply nottorp 16 hours agoparentprevEvery piece of work I've ever done was done in the spirit of agile. Just without the religion. reply RaftPeople 14 hours agoparentprev> but in others software was designed and driven incrementally just as with core agile That's my experience also. Since the early 80's, every project I've been involved in was managed with a semi-flexible, pragmatic approach that involved breaking down the problem into smaller chunks, regular communication with the customer, etc. reply shortlived 16 hours agoprevThe things I've taken from scrum and use at every team: - plan in 2 week chunks - estimate in points (relative size to something you've already done), emphasis on consistent estimates for each dev. - make sure you define what 'done' means, and make sure it relates to what exactly you are trying to measure (Eg just coding effort, work till feature can ship?, etc). This is probably the most tricky bit. - capture total velocity every 2 weeks and eventually use the avg for future planning - review the entire process and modify things that take a lot of time for devs. reply bluGill 16 hours agoparentI have long abandoned scrum for Kanban. I don't care about sprints, and getting things done by the end. Just give me (or since I'm the team leader now often I'm the one giving) the next thing to work on and when it is done I'll start the next. Nobody cares about what you got done this sprint, they care about what what got into the next release. Next release includes a lot of manual testing as despite a very great automated test program we constantly discover a lot of serious bugs in manual test that are difficult to automate. we gave up on points. All anyone cares about is days. Thus it is better to retro on the days estimate vs days to deliver and make adjustments on our end. Nobody cares about days for an individual story anyway - they want the days for the complete feature (or at least enough of the feature that we can ship it) reply nottorp 16 hours agorootparent> despite a very great automated test program we constantly discover a lot of serious bugs in manual test that are difficult to automate +1 :) Yes, I could just upvote. But this deserves more emphasis than that. reply tilwidnk 16 hours agorootparentprevAgreed, Scrum is a death march. Kanban is the way. reply shortlived 15 hours agorootparentYeah, you are doing it wrong if scrum is deadlines. I've worked with people who had to pull all nighters to get all sprint content done before the sprint closes. I'm using it more as a window to do some cheap analysis on our progress. reply skydhash 14 hours agorootparentThey are always deadlines as long as the cycle is official. An informal status update can be done with the project management tool, a 1:1 meeting or a quick team meeting (in this order) reply The_Colonel 13 hours agorootparentMy experience is very different. Sprint wasn't a deadline in any of the companies I've worked at. reply SCdF 15 hours agoparentprev> - capture total velocity every 2 weeks and eventually use the avg for future planning I have never got to this stage. Someone is added to the team. Someone leaves the team. New team members get more knowledge. Old team members get sick or take a lot of leave. The focus of what you're working on moves from one part of the code base to another. Every time you have to throw your velocity out the window because you're not the same team any more, and those metrics are for a different team that no longer exists. You could argue points are useful as a discussion point to make sure there isn't some massive piece of complexity hiding in something (everyone says 3 points, the quiet person who knows the most about it says 13), but even tshirt sizing covers that imo, and regardless after that you should just throw them away. reply shortlived 15 hours agorootparentYeah, it won't work without a stable team. And that may be okay in a true agile environment but I've always had a manager who wants some type of estimate/high level schedule. We do T-shirt sizes mapped to numbers, because recording effort in numbers lets you get an avg etc... reply ed_elliott_asc 16 hours agoparentprev“Past performance is not a predictor of future success” Capacity planning only really works where you are creating the same thing over and over. Otherwise I’d suggest it is better to just bring work in and work on it (kanban basically) reply jsploit 16 hours agoparentprev> estimate in points (relative size to something you've already done), emphasis on consistent estimates for each dev. > capture total velocity every 2 weeks and eventually use the avg for future planning This aspect of scrum has never made sense to me. Planning with average velocity turns points into an obfuscated time estimate - why use points at all? reply steelframe 16 hours agorootparentIt's a psychological trick to counter our bias toward scheduling optimism. reply xbar 16 hours agoparentprevSounds like an agile application of scrum. reply milesvp 16 hours agoprevI’ve seen “scrum” work. The single most important thing we did was the retro always happened. In the retro we somehow managed to create a safe space where we could honestly discuss ways to improve. This may never be repeatable depending on the culture of the company, but the goal of a retro is to be a safe space where honesty is possible. Without honesty there can be no improvement to the process. Is some ceremony providing no value? That should come up in the retro. Proposed fixes should surface in the retro. Maybe you dump the ceremony, or do it less often. Ceremony is sort of stupid in general, but it’s often there because historically for some large percent of teams it was useful occassionally. It may not be useful for your team. Retros are hard. Managers will try to run them. People can’t be honest with managers present. At least half an hour of the retro should be without the manager present. Retros should should also be long enough they feel slightly painful. There are people who have a hard time finding their voice in a group setting, especially with difficult topics. Giving them time and opportunity to speak is essential. reply koonsolo 2 hours agoparentRetro's are at the core of agile, since they empower the team to finetune their own process. I don't agree on the manager not being present. The manager must be present in my opinion, but I think you are facing a different problem: Your manager is the 'boss' and not at the service of their team. Try to push your manager to be at the service of your team. If that doesn't work (which most probably is), go work for a manager that actually is at the service of their team. reply pydry 16 hours agoparentprevRetros are useful. I don't think it's original to scrum though. I think it emerged out of one of those Japanese manufacturing process thingies. reply davidham 16 hours agoprevNone of the things the author complains about are specified in Scrum. The Scrum guide states that the developers choose the work: \"Through discussion with the Product Owner, the Developers select items from the Product Backlog to include in the current Sprint.\" I've also heard people complain about the meetings, but honestly people hate meetings generally--my current team doesn't do Scrum or any other agile system, and we still have several time-wasting meetings every week. In my experience, scrum reduces the meetings you need to have to a minimum, and each one is there for a reason. If you use each meeting for its reason, they are valuable, if not, then sure, they probably are a waste of time. I know that scrum has often been weaponized by managers and tools, but scrum doesn't prescribe this. Scrum doesn't prescribe story points or velocity or burndown charts. Those things may suck at your company, but they're not Scrum's fault. Personally I like Scrum. I like the focus of the sprint goal and I like being able to show what I did at the end of the sprint. My team, as I say, has no process, and I started implementing scrum just for myself and my projects, that I work on solo. It's not perfect or ideal but it's better than any other system I've seen. reply pikseladam 57 minutes agoprevIf scrum sucks, suggest better. Waterfall is not better for software development. Author gives examples from bad management practices, work load, overloaded job queue and points all the problems to scrum but scrum has nothing to do with these problems. reply sequoia 15 hours agoprevPeople who don’t use scrum or sprints or any of it, two questions: 1. Do you actually have very few meeting and all of them are meaningful and useful? 2. Is your work predictable and both devs and PMs have a reasonable idea of how much work is coming up and the nature of the work? I’ve worked on “no sprint” teams and I end up having several “weekly checkin” meetings for different projects, plus intermittent “stand ups” that lack a clear focus, plus my manager discussing tactical matters in 1:1s and the work plan is still a clusterfuck where it’s hard to know what’s priority, what work is coming up, ensuring we have requirements clarified before starting work etc.. The biggest mistake I see people making with sprints is not understanding that you cluster your planning over 1-2 days then you have 2-3 weeks with basically zero meetings besides standup or working meetings like system design. The benefit of scrum is lots of heads down time, the cost is you’re not allowed to just book meetings Willy nilly whenever you want. Most places I’ve worked have wanted the benefit of sprints but not understood or been willing to pay the cost (no-meeting weeks). So it’s agile rituals plus whatever other meetings you already had, and of course that sucks. I feel like agile processes are this boogeyman and people think “just get rid of them and we’ll be good!” but you need some process or else work is chaotic. So what’s the better process that works for you? reply therealdrag0 6 hours agoparentI do monthly sprints with just 3 stand ups a week and an extended mid month checkin. No other ceremonies. Planning is done ahead of time by leaders without every IC present. Design is done by ICs as part of tickets in a sprint like any other work ticket. Basically no retros or any other ceremonies and it works well. No points or ticket estimations or time tracking. All working great. I sometimes wonder if some of the agile methods overly fetishize some kinda democracy which adds way too much bikeshedding and overhead. Whereas if you just provide sane leadership and planning. Everyone is happy to do their part without endless rituals. reply BearOso 16 hours agoprevThe term scrum comes from rugby, and it has nothing to do with organization. It's literally when something goes wrong, pack everyone together and get the ball moving again. Symbolically, obviously, ball=project. The problem, like everything these days, is corporatism. Things have been added to the old development model to create positions for knowledgeless managers to do nothing and make money. Agile means fast without preparation. That name no longer reflects the model. These days, businesses have become so ritualistic to maintain power structure that they're inefficient, and morale is low. It gets to an unsustainable point and fails, meaning mass layoffs and restructuring, or the organization itself going down. reply abraae 16 hours agoparentThe real purpose of the scrum in rugby is to tie up half of the players (the forwards - the backs are not in the scrum) when restarting play. Literally to remove the forwards from the play after a restart, by having them all bound together with their arms twisted around each other. Then, when the ball pops out, the field of play is nice and empty for a few seconds and some running rugby can take place, while the forwards slowly untangle themselves from the scrum. To translate to software engineering and agile, if scrum is taking half of the team's developers and tieing them up and preventing them from doing any work, then scrum is working exactly as intended. reply leejo 15 hours agorootparentTo expand the analogy further the scrum, in modern rugby, is the worst part of the game and has gone through several iterations the last couple of decades to reform it as it often ends in a stalemate or arbitrary penalty to one side (as good as a coin flip), or worse: a head injury. The approach has seen the game settle with \"Crouch, Bind, Set\", which seems to be a good compromise. And yet the hooker always, always ALWAYS, puts the ball in crooked and yet never gets called up on it. In other words, it's all a big waste of time and energy. (We're using agile at work, daily standups and retros, and it seems to be working) reply klysm 16 hours agoparentprevAppeal-to-etymology is an especially weak form of argument - the origin from rugby doesn't matter. reply Tao3300 16 hours agorootparentIf you aren't jamming your head between your teammates' thighs, you are doing scrum wrong! reply ssrc 13 hours agorootparentprevYou are right, but in this case I have some sympathy for the argument. If all the technical terms in one methodology (scrum, sprint, velocity, commitment, ...) look like they were chosen not in good faith, well... reply adrianmsmith 16 hours agoprevIt's interesting to speculate on why, if Scrum is so bad, everyone uses it? Is it because everyone is an idiot (e.g. management)? Or for some nefarious reason? Or maybe it isn't actually that bad? On one project I was on, there was a contractor company billing millions per year to create a React admin tool frontend. Many developers involved, Scrum master full-time, and so on. Tickets were created for small parts of features, of course not considering anything more than 2 weeks ahead due to agility, then later other tickets would be created for the next phase of the feature so everything that had been done so far had to be thrown away as it was wrong (great for billable hours), etc. The person on the customer's side managing this didn't really know what they wanted, so was happy to be told that, due to agility, they wouldn't have to specify anything more than two weeks ahead. A big decision can't be wrong if you aren't allowed to make big decisions! Can't get fired for decisions being wrong if you aren't allowed to make them. So everyone won out of this situation really. I don't know if there would have been a better way to manage this project. But I can see what everyone got out of it. reply bluGill 16 hours agoparentBecause Developers are not the only stakeholders. Management and marketing needs to know when the next release will be. In a complex project it doesn't matter if you are ready to go with your part if someone else just merged in a new feature that is crash prone in situations they didn't think to test. In a complex project you may also depend on hardware being delivered at the same time. In a complex project there may be people planning when they can safely role this out to their system. Agile works great for a small project where a few developers is all you need. However few in the agile manifesto seem to have thought about how to scale it to larger projects. That isn't to the manifesto is wrong - it very much fixes some real issues with previous project management. However some of those real issues were an intelligent response (not to be confused with good!) to even more complex issues that you cannot ignore just because they are causing issues. Scrum is one of the few that thought about the large project problem, and so it appears at first you can scale it to larger projects. However now that we have tried it for a while I can safely conclude it isn't a great fix. I'm not even convinced Scrum is better than waterfall (waterfall has iterations - version 1.0, 2.0...), though scrum and waterfall get different things wrong with project management. Of course the next question you should be asking is how do you manage a large project. I do not have an answer. I haven't even seen evidence that anyone has found a good answer despite many smart people facing the problem and thus thinking about it. reply convolvatron 15 hours agorootparentManagement and marketing needs to know when the next release will be and what will be in it. Cutting things up into two week segments, and religiously opposing any attempt to plan together as group or come with rough schedules undermines engineerings ability to interact meaningfully with those people. Sales people, investors, and customers really don't care about how good you are about meeting your scrum targets or how many fictional story points you're able to get through. reply dijit 16 hours agoparentprevIt's also possible that we have forgotten what anything else can look like. For me, I'm a senior technical leader now and my entire professional career has been Agile and Scrum. I haven't been exposed to other techniques. Better not upset the apple-cart, we all know how it works, and besides, it's the defacto for a reason... right? (this is tongue in cheek but to be fair, I make decisions like these subconsciously all the time; \"why do CI/CD\", \"Why use GIT as SCM\", \"Why do peer review/MRs\" --- because I always have and it seems good enough on the surface) reply tristor 16 hours agoparentprev> It's interesting to speculate on why, if Scrum is so bad, everyone uses it? Scrum is bad (as implemented by bigcorp), but waterfall is worse (as implemented by bigcorp). A simple example from my past. My team was scrum based in a bigcorp that mostly did waterfall, so of course we did scrum badly too. That said, our scrum team shipped a major integration feature in two sprints (4 weeks) that the partner integrating team inserted into a 14 month long waterfall release train. It took ~16 months to ship a feature to customers that took 4 weeks to build and internally validate. If there had been less bigcorp bullshit said feature might have taken 3 days, but at least 4 weeks is better than 14 months, although in this case customers got the worst of both. reply mondocat 15 hours agoparentprevBecause it purports to make progress predictable, and measurable, which for the PMs and managers is very important. reply j4yav 16 hours agoparentprevIt’s a combination of cargo culting (nobody ever got fired for using Scrum!) and consultants who use it as a form of leverage to extract billable hours from their clients. reply jsight 16 hours agoprev\"Way of work should be defined at a team level by its people, not by the company.\" - This is basically the origin of scrum. Essentially every problem ascribed to scrum is its departure from this origin story. Scrum is about making each team work better, but somehow it turned into the same weird top-down imposed structure that it was supposed to replace. 2 week sprints are mandatory for all teams? They all have to start and stop on the same day? And you can use any story point system you want as long as they neatly summarize into these t-shirt sizes? There is little resemblance between the agile manifesto and what people are pretending to do today. reply unethical_ban 16 hours agoparentHa! At my old employer they used \"Scaled Agile Framework\" (SAFe). About a dozen teams of developers and operations people got together once a QUARTER to determine what big epics/objectives to complete, and then develop stories and estimates (points) for those stories and roughly which sprint they would fall into within the \"iteration\", as the quarter was called. Every team on the same sprint schedule. Fibbonaci story rankings across the org. Product owner and scrum master would be shared between several teams, IIRC. And of course, middle management observing the aggregate amount of work estimated vs. completed every \"iteration\". reply jsight 16 hours agorootparentDon't forget to tag and label every story appropriately, use the corporate standard for sprint names, and file those tps reports on time. That would be great. reply belval 15 hours agorootparentI feel like that's unfair. It's normal in a company to answer to someone and its normal for that someone to want some way to answer the question \"are we on track for X\" when asked by their superior (whoever that may be). The larger the company the more that statement becomes true because the number of interconnect for N employees is O(N^2). That does not excuse making the whole thing stupid and painful, but accountability is not an unreasonable request. reply jsight 11 hours agorootparentOf course! The problem is that this \"accountability\" is the grease on the slippery slope towards doom. If I need every epic, story, task and subtask to be labelled in the correct way for your organization, then I no longer have an autonomous team that is able to self organize to maximize its own efficiency. If I don't have that, I no longer have agile. There are better ways than turning agile into a caricature of its former self. reply The_Colonel 13 hours agorootparentprevThe quarter is called \"increment\". \"Iteration\" corresponds to sprint from Scrum. > About a dozen teams of developers and operations people got together The S is for \"Scaled\" for a reason. Yes, large & complex projects need planning on several levels and the timeframes are longer. Nothing surprising. reply jsight 11 hours agorootparentWe all know that. There are even some good things in SaFe. Where it loses value is that it imposes those organ",
    "originSummary": [
      "The article critiques the implementation of Scrum in software development, suggesting teams should define their own approach instead.",
      "It highlights the challenges and complexities of Scrum, such as the misuse of metrics and the need for trust within teams.",
      "The author emphasizes collaboration, continuous improvement, and stakeholder involvement in project management, offering engineering services and coaching."
    ],
    "commentSummary": [
      "The conversation focuses on the use of agile methodologies, specifically Scrum, in various work environments.",
      "Participants discuss challenges such as excessive meetings, poor communication, and lack of trust.",
      "Alternative approaches like Kanban and ShapeUp are mentioned, sparking a debate on the usefulness of agile methodologies."
    ],
    "points": 218,
    "commentCount": 273,
    "retryCount": 0,
    "time": 1705336698
  },
  {
    "id": 39003292,
    "title": "Htmx switches to Zero-Clause BSD license, enabling unrestricted use",
    "originLink": "https://github.com/bigskysoftware/htmx/commit/e16f1865a494b6281f8a44ed0db5338e718b3f07",
    "originBody": "bigskysoftware / htmx Public Notifications Fork 987 Star 27.1k Code Issues 348 Pull requests 17 Discussions Actions Security Insights Commit Permalink Browse files change license to 0 clause BSD Loading branch information 1cg committed 1 parent 0cab764 commit e16f186 Showing 2 changed files with 14 additions and 26 deletions. Whitespace Ignore whitespace Split Unified LICENSE package.json 38 changes: 13 additions & 25 deletions 38 LICENSE @@ -1,25 +1,13 @@ BSD 2-Clause LicenseCopyright (c) 2020, Big Sky Software All rights reserved.Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Zero-Clause BSD =============Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted.THE SOFTWARE IS PROVIDED “AS IS” AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. 2 changes: 1 addition & 1 deletion 2 package.json@@ -10,7 +10,7 @@ \"bugs\": { \"url\": \"https://github.com/bigskysoftware/htmx/issues\" }, \"license\": \"BSD 2-Clause\", \"license\": \"0BSD\", \"files\": [ \"LICENSE\", \"README.md\", 2 comments on commit e16f186 FoxtrotPerry commented on e16f186 Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more. Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Awesome! 6 3piece commented on e16f186 Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more. Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Wow!!! Nice work. Please sign in to comment.",
    "commentLink": "https://news.ycombinator.com/item?id=39003292",
    "commentBody": "Htmx changes license to Zero-Clause BSD (github.com/bigskysoftware)199 points by jicea 16 hours agohidepastfavorite109 comments recursivedoubts 16 hours agobackground: - over the weekend I started making the @htmx_org twitter account increasingly corporate looking - started talking a lot about MSFT, implying they were interested in htmx - someone asked if MSFT was going to buy htmx: https://fxtwitter.com/htmx_org/status/1746656784088228204 - i then put up a post about changing the htmx license, implying i was going to restrict it due to MSFT interest: https://fxtwitter.com/htmx_org/status/1746736273728094323 - I then made is 0BSD instead of 2BSD: https://fxtwitter.com/htmx_org/status/1746880860723544211 - I then posted the \"offer\" i got from MSFT (some credit card thing) https://fxtwitter.com/htmx_org/status/1746895016256328079 - And explained how there were no lies involved in the ruse: https://fxtwitter.com/htmx_org/status/1746924827641102719 the reason i did all this is for the lols reply saghm 16 hours agoparent> - I then posted the \"offer\" i got from MSFT (some credit card thing) https://fxtwitter.com/htmx_org/status/1746895016256328079 Know your worth; don't sell out for anything under 20% cash back at Bed, Bath & Beyond! reply internet101010 16 hours agorootparentOnly applicable to private label items. reply dan15 15 hours agorootparentI used one of their 20% off coupons for a Simplehuman bin a while back (one of the ones with recycling on the left and trash on the right). Having said that, I don't think they actually take coupons any more. It stopped when all the physical stores closed. The offer here is a cash back offer, where you pay the full price then another company (like TopCashback, Rakuten, apparently Microsoft too) gives you 10% cash back. reply philwelch 13 hours agorootparentI always felt like “simplehuman” was the kind of brand name a condescending AI would come up with. “Simple human, buy this trash can and I will sell you overpriced, custom-fitting trash bags forever!” reply purple_ferret 16 hours agoparentprevYour lack of professional seriousness is truly astounding. One of the primary reasons we've gone with React/NextJS coupled with MongoDB and Kubernetes over HTMX reply recursivedoubts 13 hours agorootparentOK, I'll respond in a bit more detail to this, now that it's closer to the top. I'll assume you are being serious as well (always hard to tell online.) I understand where you are coming from, the @htmx_org twitter account is very silly. This can be a big turn off to some developers and companies. On the other hand, I do have a fair number of serious essays on the htmx website (https://htmx.org/essays) and a free book that is also serious (https://hypermedia.systems). I view twitter as a tool for getting the word out about htmx and, therefore, use it in that manner. I don't think that medium supports super-nuanced discussions (although I've had some.) I try to not be negative on it, and frequently link to my essays for more in-depth discussions. I also enjoy being funny and making people laugh. And, while I can understand and sympathize with people who dislike the general vibe of my account, you can't argue with the success of this approach. It has recently passed 27k stars on github: https://star-history.com/#bigskysoftware/htmx&Date And finished 2nd (!!!) in the js rising stars frameworks for 2023: https://risingstars.js.org/2023/en#section-framework Plus #10 overall. This is a library created by a one-person company that is trying to compete with the likes of Facebook, Google and Vercel when it comes to developer mindshare. While I would love to think it is the insightful essays, excellent coding ability and the quality of my book, there is no doubt that the twitter account has been a huge contributor to htmx's success. reply sodapopcan 13 hours agorootparentI'm not OP, but I would like to think it's a joke. If they were actually turned off by your \"lack of professionalism\" they would like turn to Alpinejs before \"React/NextJS coupled with MongoDB and Kubernetes\" :) But who knows! reply sgift 16 hours agorootparentprevTalks about lack of professional seriousness. Goes with MongoDB. Sometimes reality writes the best jokes. reply robertlagrant 15 hours agorootparentI'm pretty sure that was a joke. reply sodapopcan 15 hours agorootparentI wasn't sure at first but on a re-read it now seems glaringly obvious it's a joke :D reply paulddraper 14 hours agorootparentI wasn't sure either until the gratuitous \"coupled with MongoDB and Kubernetes\" lol reply ASalazarMX 11 hours agorootparentprevAnd it was indeed written by someone real! Astounding! reply endisneigh 16 hours agorootparentprevWhat’s wrong with mongodb? reply macintux 15 hours agorootparentI can't speak to its current state, but there were some highly dubious design decisions early in its life, such as the library would reply to the client indicating a successful push of data into the database before the network request even left the local computer. reply endisneigh 15 hours agorootparentThe past mongodb issues don’t seem relevant unless they persist today, no? reply macintux 15 hours agorootparentReputational damage is difficult to recover from. reply endisneigh 14 hours agorootparentThat’s not relevant to the question of “what’s wrong with mongodb?” It seems folks just regurgitate memes without any understanding of the current product. reply macintux 14 hours agorootparentI thought \"I can't speak to its current state\" explained that I could not, in fact, speak to its current state. But when it comes to databases, which are often the single most important part of an architecture, you'll find that many people are less forgiving of old sins, especially when Postgres now has native JSON support. Much like I won't trust Uber with my location, or Google with my email, I won't trust Mongo with my data. reply endisneigh 14 hours agorootparentWhy even reply if you don’t know what you’re talking about in terms of current mongo? Not sure what Postgres or Uber or Google even has to do with this. FYI using mongo is more than simply wanting a json interface. reply Literalyevery 15 hours agorootparentprevMongodb was/is for a long time inconsistent. You had to worry loosing data when using mongo. And everything mongodb brought us, was either implemented by someone else better or already existed. If you use mongodb today, just go with postgres and forget about mongo reply endisneigh 15 hours agorootparentYes there used to be issues with mongo (and Postgres around serializable for the matter). What are the issues in 2024? reply osalberger 15 hours agorootparentBreaks causal consistency and a bunch of other assumptions: https://jepsen.io/analyses/mongodb-4.2.6 reply endisneigh 15 hours agorootparent4 years old. Mongodb is at version 7 now. reply tobltobs 13 hours agorootparentSo MongoDB was an inconsistent DB for at least 70% of its lifetime. It doesn't sound too ensuring. reply bombcar 14 hours agorootparentprevIt's webscale. reply drcongo 15 hours agorootparentprevSometimes the best jokes look like reality. reply markski 16 hours agorootparentprevyou chose your stack by weighing the professionalism of the twitter account? reply lmeyerov 15 hours agorootparentmay you never have to maintain production code... reply markski 14 hours agorootparenti do. what now? reply lmeyerov 14 hours agorootparentmay you and the people relying on you never have to rely on the maintainers taking things more seriously than they've shown themselves to in their public positioning reply markski 13 hours agorootparentHTMX has existed for nearly a decade (prev. intercoolerjs); 1cg has proven to be extremely invested in it, and the whole philosophy around it in general (even being in charge of an \"Hypermedia Research Group\" at Montana university). To dismiss all of the credibility he has created with his work just because the guy wants to be funny on twitter is nothing short of stupid. reply lmeyerov 13 hours agorootparentThis appears to be the official account, not a personal one. If he wants me to take htmx seriously as a prod dependency, I care about how he treats it, all the way from code to governance to community interactions. He has no such obligation to do these things, this is all his choice. I'm not sure why the contention? If you read my comment, it was strictly about production scenarios, not about all credibility for all scenarios. If this project is meant to be treated as fun CRAPL, Matthew Might made a great license for that: https://matt.might.net/articles/crapl/ . reply markski 13 hours agorootparentI apologize for the contention - I misunderstood what your point was which made my writing a little too aggressive. I still hold the position that the social media presence of the project should be inconsequential for considering it's production usage. But I can see your point now, even if I disagree. reply clivestaples 11 hours agorootparentprevI see your point but I let the technology do the talking. People focus on personalities but the work is what matters to me. I used to get annoyed at DHH but then I just ignored it and built stuff really fast. reply rakoo 11 hours agorootparentprev1. They are the maintainers of htmx, not the maintainers of your code. There is no contract with them. 2. The joke made by the maintainer gives absolutely no insight into how they will behave if there were a contract. If anything, that might mean the maintainer actually is a human that is agreeable to talk and work with, because they don't take it so seriously as to forbid any jokes. Professionalism doesn't mean \"no jokes allowed\", it means \"do your best\". reply sodapopcan 10 hours agorootparentprevI hope whoever taught you that \"good software is only written by people without a sense of humour\" isn't teaching anymore. reply notfed 16 hours agorootparentprevPoe would like a word with you. reply recursivedoubts 16 hours agorootparentprevThat's a great option, many people choose it! reply tgv 15 hours agoparentprevGood for you, and the spirit of open software. reply bruh2 16 hours agoparentprevI love your spirit. Actually funny reply clwg 16 hours agoparentprevbravo, what editor did you use to change the license file? reply recursivedoubts 15 hours agorootparentWebStorm reply neoromantique 14 hours agorootparentabsolutely proprietary : the reason i did all this is for the lols Do the lols while you still can, the Trust and Safety departments at major social media companies want to extinguish funny. Everyone who does even a smidgen of memeing on the internet knows what happens when you post images of large spiders. People start talking about burning things down, like the entire building its inside of, etc. Someone posted a video where a little girl had one crawling on her hand, it was bigger than her face. I said \"Girl get away from that spider, we have to set the house on fire\" and the AI anti-funny overlords at Facebook deleted my comment, and gave me some sort of \"strike\" and then I appealed, and was auto denied. Our favorite Sci-Fi dystopias coming soon, to a Trust and Safety social media site nightmare near you. reply recursivedoubts 15 hours agorootparentThe only hope you have is to accept the fact that you're already cancelled. The sooner you accept that, the sooner you'll be able to function as a shiposter is supposed to function: without mercy, without anxiety, without remorse. All shiposting depends upon it. reply ordinaryradical 13 hours agorootparentWe happy few, we band of brothers. reply giancarlostoro 14 hours agorootparentprevI mean, I just stopped using Facebook instead, I was an admin for my employer at the times Facebook app (used for login) so I did not want to risk it. It's Facebooks loss. reply mtlmtlmtlmtl 15 hours agorootparentprevMeanwhile someone was using my late brother's name and face(in a list of supposed \"vaccine casualties\". My brother died from heart failure after lifelong illness, age 39) to spread vile antivaxx/protrump stuff. All reports denied. It was glaringly obvious she was a paid misinfo troll. reply giancarlostoro 14 hours agorootparentAfter my cousin passed away his mother took over the account. They used it to spew hatred and condemn people. I don't think the account was ever shut down. reply somat 14 hours agorootparentprevJust a question, I don't pay much attention to politics, are the two related? are anti vaxers pro trump? The vaccine was developed on Trumps watch. I figured it was just like any other boss, takes all the credit if it works. desperately tries to shift blame if it does not. reply bombcar 14 hours agorootparentIt amuses me, personally, seeing the \"antivax\" crowd quickly being equalized to all the other various \"bad\" people - 20 years ago, there was a strong but quiet \"antivax\" crowd and it was definitely not made up of Trump or even R-leaning people. It was quite the \"hippy liberal progressive\" if you had to qualify it. But then again, twenty years ago you had all sorts of political positions you could take, now everything is simply binary. You have no agency. reply cqqxo4zV46cp 12 hours agorootparentIt doesn’t sound it like it amuses you. You sound kind of miffed off about it. reply bombcar 12 hours agorootparentFair enough, it's a bit annoying because now you need about five seconds and you can replace almost anyone (at least online) with a tuned LLM without much thought. It was fun to watch people disagree about things, that's mostly gone in the political world (and that world eats all discussion boards eventually, in my experience). reply pgeorgi 14 hours agorootparentprevThere's some correlation, and while Trump tried to take credit for Operation Warp Speed for a while[0], he distanced himself from everything related to \"Covid is a threat\" (including \"it needs vaccines\") when the tide shifted in his voter base and they went fiercely antivax, antidistancing, antilockdown, ... [0] the process was pretty much the same speed for non-participants in non-participant countries, but okay: his administration made it a priority. Gold star for you! reply giancarlostoro 14 hours agorootparentI used to watch loads of political speeches, including Biden and Trumps because otherwise you take someone else's word for what they say, and I still remember the boo's he got in one of his early speeches after Biden was sworn in, the entire crowd booed when he said to go out and get vaccinated, then he said \"if you want to\" after he realized his 'goof.' It was like he was not paying any attention to his base since losing the White House (again this was like his second (I think?) rally since). Then he changed his strategy with his base on it after. So you're not wrong. I think he still brings it up, but briefly. reply singron 16 hours agoprevThis made me wonder what the shortest open source license is, and it seems to be the Fair License: https://en.wikipedia.org/wiki/Fair_License >> > Usage of the works is permitted provided that this instrument is retained with the works, so that any entity that uses the works is notified of this instrument. > > DISCLAIMER: THE WORKS ARE WITHOUT WARRANTY. EDIT: I would not use this license. I'm not sure how this got approved by the OSI, but I'm not a lawyer. Some of the email threads think the disclaimer is insufficient, and I'm not entirely sure that it confers all the expected rights since it only says \"Usage\" (copying, modification, distribution). reply zvr 31 minutes agoparentIf you want statistics about license texts, many years ago I had published a peer-reviewed article: Zavras, Alexios. Twenty-five years of school? Analysis of Free and Open Source software license texts. Journal of Open Law, Technology & Society, [S.l.], v. 8, n. 1, p. 29-44, nov. 2016. ISSN 2666-8106. Available at: . reply kotborealis 15 hours agoparentprev\"Don't ask me about it License\" looks a bit shorter[0]. 0: https://github.com/ErikMcClure/bad-licenses/blob/master/dont... reply hiccuphippo 13 hours agoparentprevIs License golf a thing? ChatGPT reduces that from 205 to 130 bytes: The works can be used as long as this instrument is kept alongside them to notify users. The works are provided without warranty. reply simonw 15 hours agoprevI hadn't seen Zero-Clause BSD before: https://opensource.org/license/0bsd/ > Note: Despite its name, Zero-Clause BSD is an alteration of the ISC license, and is not textually derived from licenses in the BSD family. Zero-Clause BSD was originally approved under the name “Free Public License 1.0.0”. Anyone seen a good write-up of the tradeoffs for this license? I like how short and simple it is. reply zvr 24 minutes agoparentIt's a nice license when you don't want to burden users of your software with providing attribution. A typical use case is for stuff that will be included in many different projects, while not being a crucial part of it. For example, all the code snippets in the Intel Software Developer Manuals (https://www.intel.com/content/www/us/en/developer/articles/t...) are licensed under 0BSD, so that people can easily re-use them (with or without adapting them). reply ameliaquining 15 hours agoparentprevIt's appropriate for software designed for use cases where an attribution requirement would be inconvenient or otherwise undesirable. For example, https://github.com/microsoft/tslib uses it, because that library is automatically included in any TypeScript program that uses downleveling, so if it had an attribution requirement then that requirement would apply to every program written in TypeScript, which nobody wants. (GCC and LLVM do something similar with their special runtime-library exceptions to the GPL and Apache License, respectively, but tslib lives in a separate repository from the rest of TypeScript and so could easily just get a separate license.) reply samsquire 16 hours agoprevI use the zero clause licence for my all my work because it just removes all the overhead of using my code. I think (please correct my understanding) zero clause BSD can be embedded in a GPL project too, it just becomes one-way included, subsumed into the GPL project and then under the GPL licence. (Relicenced) Could the author of HTMX explain their reasoning for changing the licence? I am curious? reply recursivedoubts 15 hours agoparentIt was mainly as a joke, but I wanted to remove the attribution clauses, they just seemed dumb for a single-file javascript library that was probably going to be minimized anyway, where are you supposed to stick the license? reply zvr 21 minutes agorootparentThank you for this! It lifts a significant burden for people/projects/organizations who want to release software while complying with all license obligations. reply skybrian 14 hours agorootparentprevSome companies are careful to include all the libraries' licenses when minimizing JavaScript code. There are tools to do it. But it seems wasteful, so it's great that you removed the requirement. reply yawaramin 5 hours agorootparentI'll bet $10 that the compressed size shows no discernible difference. reply stavros 16 hours agoparentprevIANAL, but yep, that sounds about right, the more restrictive license then applies. Of course, anyone can use the original, BSD copy of the code, without the restrictions. reply samsquire 16 hours agorootparentI would have hope that anybody who uses your code doesn't want to keep it a secret, because it would be good if people use the same common base code and changes can benefit everyone. Since there's no requirement to credit a zero clause licenced BSD code, someone who receives the BSD code compiled might not know it's included but that's the risk I'm taking. reply saghm 16 hours agoprevIs \"zero-clause BSD\" a joke, or is it considered a legitimate license? If the latter, does it actually differ from the MIT license in anything other than name? reply sethops1 16 hours agoparentIt is approved by OSI[1] [1] https://opensource.org/license/0bsd/ reply explodingcamera 16 hours agoparentprevzero-clause BSD is essentially a modified MIT that doesn't even require attribution, so essentially a \"public domain\" like license. reply 0x69420 16 hours agoparentprevit eschews attribution, making it just about the closest thing to a public-domain dedication that still retains the appropriate verbiage to hold up to legal scrutiny reply mminer237 13 hours agorootparentIn the US, simply saying \"I hereby dedicate this work to the public domain.\" is as an effective, if not more effective, way to do that as any license. These licenses are just for countries like Germany that basically make it illegal to sell, gift, or release a copyright at all. reply fomine3 4 hours agorootparentIt's great feature that we don't need consider where authors locate reply kube-system 16 hours agoparentprevPresuming that 'MIT' was a typo: most BSD-licensed software doesn't use the original (4-clause) BSD license, most are under variants: https://en.wikipedia.org/wiki/BSD_licenses reply saghm 15 hours agorootparentNo, it wasn't a typo; the 0-clause BSD looks pretty similar to the MIT license, and from a cursory reading, it appears that the clauses are what makes the BSD license different from the MIT license. I was wondering if my reading is correct or if I've missed something. reply kube-system 15 hours agorootparentMIT has several (very important) requirements that BSD-0 does not. MIT is more similar to BSD-2-clause. It requires the user to include the copyright notice and disclaimer in any distributions. reply MzHN 15 hours agoparentprevThere's also another OSI approved \"zero\" license called MIT-0 https://opensource.org/license/mit-0/ reply EasyMark 5 hours agorootparentalways preferred east coast in the east/west coast war. reply p8donald 15 hours agoprevIf I contribute code to an open source project under the BSD 2-Clause license and don't sign any contributor license agreement, can the maintainer relicense the code without getting my permission? reply junon 10 hours agoparentYes, unless they change the copyright. You own the copyright to your code contribution. The license only states how the copyrighted code can be used. reply njharman 15 hours agoparentprevSure, anyone can do anything. It would be up to you (and hopefully a lawyer) to then sue them and let judge/jury decide. Or, convince authorities that some criminal law was violated and they should investigate. Both of which are hard and/or expensive. So most rely on public shame. Out them on social media and foment outrage. reply colejohnson66 11 hours agoparentprevIn the US, generally no. reply jbverschoor 15 hours agoprevI'm curious, what exactly would a VC or MSFT want with htmx? Just talent? or the actual product/tech? reply recursivedoubts 15 hours agoparentI don't think there's much VCs would want w/htmx: it's a really simple concept implemented in a single js file w/no moats or obvious market opportunities as far as i can tell, and I'm a one man shop. I think I got the calls because htmx trended on twitter a couple of times. MSFT might want it because it's gotten a lot of attention lately (finished #2 in https://risingstars.js.org/2023/en#section-framework for 2023) and would give them a front-end library in the game w/ React, Vue, Svelte, etc. On the other hand, i've made the social media account pretty toxic/funny (same thing) for a big tech company and now the library is 0BSD, and htmx's agnosticism towards back end tech doesn't really dovetail w/ the Microsoft ethos. reply gen220 14 hours agorootparentVCs have taken a few positions in FOSS recently [1][2]. I also don't understand the financial reasoning of investing in the companies, for what they are. My guess is that it's an option on having influence on relatively influential developers in the mid-to-later stages of their career. [1]: https://techcrunch.com/2023/02/16/sequoia-backs-open-source-... [2]: https://www.sequoiacap.com/article/sequoia-open-source-fello... reply logicprog 15 hours agoprevThe state of software licenses makes me a bit sad. On the one hand we have open source licenses like the MIT and Apache 2.0 licenses that give corporations free reign to enclose and exploit the software commons without any real limit or any requirement to give back to the things they are getting rich off of, and then on the other hand we have the GPL and LGPL licenses which are too aggressive and stringent, while also being somewhat vague — see for instance the almost superstitious fear companies have about using LGPL code even when it would probably be fine — which means that almost no one ends up using those licenses, because companies are too afraid to use software that is licensed under them (and therefore wouldn't be invested in them at all, which means they give back to those projects even less than they do for projects under open source licenses) and because even FLOSS developers just don't want to deal with the dependency headaches of using GPL code. Which in turn ironically means that, despite being designed to very aggressively protect and help the software commons, the GPL and LGPL licenses end up doing worse for the software commons then open source licenses do, in general, because no one uses them or invests in them in the first place, and of course there are going to be fewer contributions to the software commons from a license that is never used or invested in then there are going to be from a license that is widely used and deeply invested in but has fewer requirements, because it's a matter of percentages essentially. So in essence both licenses fail to do what at least I feel like they should ideally do, although for opposite reasons. Ultimately, I think this stems from the fact that Open Source licenses were explicitly created by people who wanted to be friendly to corporations, and the GPL licenses were created by the FSF, who are essentially the vegans of software. So I think in the long run what we need is a free software movement that is detached from both the dogmatism and absolutism of the Free Software Foundation and the desire to suck up with corporations. A movement that perhaps sees itself as being a check on the balance of corporations in the software world, but in a more pragmatic way. I think the sort of license a movement like that might produce might end up looking something like the MPL 2.0: it allows combined works that use the existing code in any way they want, while requiring changes or improvements to the existing code to be shared back to the community, so that there is a clear requirement to give back to the things you benefited from, without trying to also take away the things you or your team wrote themselves. This is similar to the LGPL, but unlike that license the basic unit of separation is clearer: files. Original source code files and any files containing substantial portions of code copied from the original source code are considered part of the original work, and therefore something to which changes must be contributed back to the community, but anything outside those files can stay proprietary. This is a lot clearer and more flexible than the LGPL, meaning developers from FOSS and from corporations can use code under the without headaches, while still not allowing companies to just completely free ride on the things the software community makes, and we get to have both because unlike the LGPL the MPL is willing to sacrifice some stringency and control in return for those benefits. Additionally, and perhaps more importantly, it doesn't have particularly onerous source distribution requirements or requirements to distribute your own application as object code or provide some other way for users to swap out the version of the free software code that's being used, which likewise does sacrifice some FSF purity, but in return for a massive decrease in the complexity, onerousness, and annoyingness of the license requirements as a whole. So yeah, the MPL isn't perfect — maybe the ideal free software license would be the LGPL with just clearer specification of where the boundaries are between the LGPL code and the proprietary code, and no annoying object code or dynamic linking requirements — but it's a lot closer to where I think we need to move with licenses. I don't think zero clause open source licenses are the way. reply jabl 15 hours agoparentI like the MPL 2.0 and use it for some of my own software as it best seems to describe the outcome that I want (incorporate it into whatever you want, but please contribute improvements to the MPL licensed parts of the software back to upstream). However, I also think it's fairly easy to circumvent for a hypothetical leech that just wants to use my code without contributing back any improvements. Namely just put the improvements into a separate proprietary file, and insert stubs in the MPL licensed file calling the proprietary code. Taking this argument to the extreme, one should use either something extremely permissive like 0BSD or then go full AGPLv3, as everything inbetween is to an extent possible to circumvent without too much trouble (GPL \"condoms\" and all that). reply mook 13 hours agorootparentI like MPL too (depending on context), but do be aware that (per section 10) Mozilla is allowed to ship new versions of the license and people can choose to use those new versions in place of the version you licensed under. This is not inherently bad — many projects are licensed under \"GPL 3 or later\", for example — but it's something to be aware of. See also CDDL, which is mostly MPL but Sun (and now Oracle) in place of Mozilla Foundation. reply logicprog 12 hours agorootparentOh I didnt know that, good to know. Another area where it isn't perfect! reply logicprog 15 hours agorootparentprev> However, I also think it's fairly easy to circumvent for a hypothetical leech that just wants to use my code without contributing back any improvements. Namely just put the improvements into a separate proprietary file, and insert stubs in the MPL licensed file calling the proprietary code. Yeah this is the work around that came to mind when I first read the MPL, and it's what I had in mind when I said it isn't perfect. I'm using it for a current game engine project I'm working on, and will probably use it for any of my other work moving forward, but I definitely think it isn't the end of license history — there is still a lot more improvement that could be made. I was just giving it as an example of what I think the correct direction is, in contrast to the current extremes. I think it's where more work on licenses should go. reply Guid_NewGuid 13 hours agoparentprevI don't understand the view that MIT and Apache 2.0 make it possible for corporations to somehow destroy or enclose the commons. Code is code. It can't be destroyed, its cost of duplication is effectively zero. If I take some open source code, add my changes and distribute a paid, closed-source, version, nothing has been removed/lost. Certainly they make it hard/impossible to build a business from Open Source code. Unfortunately in an economic system designed to maximise the reward for value capture at the cost of value creators this is a common problem. But I believe the answer to that is more communism, not more licenses with more convoluted requirements creating jobs for legal departments for shared code. reply logicprog 12 hours agorootparent> I don't understand the view that MIT and Apache 2.0 make it possible for corporations to somehow destroy or enclose the commons. Code is code. It can't be destroyed, its cost of duplication is effectively zero. If I take some open source code, add my changes and distribute a paid, closed-source, version, nothing has been removed/lost. You are technically correct in this, and technically speaking perhaps I should have put what I said in terms of the free rider problem, not necessarily enclosure of the commons, but two things: first, I do think what corporations do with open source software is to some degree more analogous to such an enclosure, since in a free rider problem we typically imagine a few or even very large number of lazy individuals just not paying for something, whereas in the enclosure of the commons it is the rich and large corporations benefiting from the work of more common folk, and the power dynamics of what happens in software look more like the latter than the former. Second, you're forgetting embrace, extend, extinguish, which very much does have the effect of destroying things by commercial cooption and absorbtion. > Certainly they make it hard/impossible to build a business from Open Source code. Unfortunately in an economic system designed to maximise the reward for value capture at the cost of value creators this is a common problem. But I believe the answer to that is more communism, not more licenses with more convoluted requirements creating jobs for legal departments for shared code. I sort of view licenses that require contributing any improvements you've made to something back to the collective pool from which you got it as a form of communism, even if in this case it is embedded in and enforced by a capitalist system. reply theanonymousone 15 hours agoprevIs there a license that requires (or encourages) contributing back the modifications, _but only if the upstream project is open source/non-commercial_? reply zilti 15 hours agoparentYou'd have to dual license your code afaik, the way Qt did/does it reply alberth 15 hours agoprev [–] Public Domain Does this effectively make htmx public domain? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The repository \"bigskysoftware/htmx\" has switched its license from the BSD 2-Clause License to the 0-Clause BSD license.",
      "This change permits the unrestricted use, copying, modification, and distribution of the software without any fees.",
      "Users are expressing positive feedback and gratitude for the new license."
    ],
    "commentSummary": [
      "The htmx software library has switched its license to Zero-Clause BSD, a permissive open-source license.",
      "There was a social media prank regarding Microsoft's alleged interest in htmx.",
      "The passage explores discussions on the credibility and professionalism of software projects and concerns about the trustworthiness of MongoDB as a database management system. It also touches on conversations about humor and professionalism on Twitter, open-source licenses and their limitations, cancel culture, Facebook, anti-vaxxers, and political discourse."
    ],
    "points": 199,
    "commentCount": 109,
    "retryCount": 0,
    "time": 1705338867
  },
  {
    "id": 39008533,
    "title": "Transform Vim into a modeless editor, with standard key bindings and improved user-friendliness",
    "originLink": "https://github.com/SebastianMuskalla/ModelessVim",
    "originBody": "Modeless vim The config files in this repository turn vim into a modeless editor. Instead of remembering cryptic commands, you can use standard key binds, like Ctrl+S to save, select text using Shift+←/→/↑/↓, and copy/paste using Ctrl+C/V. This configuration is not meant for the aficionado who prefers vim over graphical editors. This is meant for people who normally use GUI editors (like VSCode), but sometimes need an editor that can run in a terminal. Note: A modeless editor is a normal editor in which the letter keys will let you directly type text, and commands like saving files are performed via key binds. This applies to basically all editors with a GUI and some editors meant for terminals like nano. A modeful editor like vim in its default configuration has several modes (e.g. 'command mode' for executing commands like saving ('w'), 'insert mode' for actually typing, 'visual mode' for selecting text, ...). Q: Why don't you just learn the vim commands? A: I did, but if you don't use vim regularly, you keep forgetting them. Q: Why don't you use a modeless editor like nano? A: The capabilities of vim (e.g. the syntax highlighting support for many languages) outclass any modeless terminal editor like nano. The configuration files in this repository turn vim into a modeless editor, while preserving its amazing features! The configuration has been tested using vim version 8.2 running on Debian 11 (Bullseye) running in WSL2 on Windows 10 21H2, displayed using the 'Windows Terminal' application. Some features Support for standard key binds. Show an infobar at the top of the screen that reminds you of the key binds. Show a statusbar at the bottom with the file, the cursor position, and some other information. Sane default settings for many options. Screenshots Modeless vim using a nerd font. Modeless vim with the _ascii version of the config files. vi aka modeful vim using modeless.vimrc. Contents Installation Nerd font Key bindings Files in this repository License Installation Clone this repository to ~/.vim. You may want to use the following command to avoid cloning the screenshots in the img folder. git clone --sparse \\ https://github.com/SebastianMuskalla/ModelessVim.git \\ ~/.vim vim should autodetect the vimrc file in ~/.vim. If it does not, you can create a symbolic link from ~/.vimrc to e.g. ~/.vim/modeless.vimrc: ln -s ~/.vim/modeless.vimrc ~/.vimrc Using vim for sudoedit In order to use modeless vim when calling sudoedit, put export EDITOR=vim into your .bashrc/.zshrc/... file. Using modeful vim as vi You may want to preserve the option to use the normal modeful version of vim. I recommend a setup in which the vi command is set up to execute the modeful version of vim. Find out what your vi command does $ which vi > /usr/bin/vi $ ll /usr/bin/vi > /usr/bin/vi -> /etc/alternatives/vi $ ll /etc/alternatives/vi > /etc/alternatives/vi /usr/bin/vim.basic The symlink /usr/bin/vi can be safely replaced by a shell script, e.g. the file vi in this repository #!/bin/sh if [ -e \"$HOME/.vim/virc\" ] then vim -u \"$HOME/.vim/virc\" \"$@\" else vim \"$@\" fi Nerd font The default configuration requires a nerd font (https://www.nerdfonts.com.) (A nerd font is a monospace font that has additional icons inserted.) To be precise, the infobar at the top and the statusbar at the bottom of the terminal window use some of these custom icons. Additionally, your terminal should support displaying unicode characters. I recommend using a Nerd Font; I am using the nerd font version of JetBrainsMono. If you don't want or cannot use a custom font, this repository contains the files statusline_ascii.vimrc and infoline_ascii.vimrc that implement the statusbar/infobar just using ASCII characters. Follow the instructions inside the file modeless.vimrc (or modeful.vimrc) to use the _ascii version. Key bindings Modeless vim supports the following file Open, Save, Quit Ctrl+Q - Close all tabs, ask for saving each (Saving will not work if a file has no name) Ctrl+W - Close current tab, ask for saving (Saving will not work if a file has no name) Ctrl+O - Open file (enter file name) Ctrl+S - Save current file (enter file name if needed) Search and replace Ctrl+F - Find F3 - Next search result F4 - Previous search result Ctrl+R - Replace all occurrences of a text. Replace the text FIND by the text you want to replace, and the text REPLACE by the text you want to replace it with. Select, cut, copy, paste Ctrl+A - Select all. Shift+Left, Shift+Right, Shift+Down, Shift+Up Select in the corresponding direction. Leave selection mode with arrow keys or Escape. Ctrl+C - Copy current selection (or current line if nothing is selected) Ctrl+X - Cut current selection (or current line if nothing is selected) Ctrl+D - Cut current line (which can be used to simply delete the line) Ctrl+V - Paste Other Ctrl+Z - Undo Ctrl+Y - Redo Shift+Tab - De-tab (go back 4 spaces) Ctrl+L - Toggle line numbers (helpful when copying from terminal window) Ctrl+N, Ctrl+B - Next commands in \"normal\" vim mode This key bind allows the user to input vim commands like :q!. F2 - Toggle pastemode. In pastemode, vim will not try to reformat text that is pasted into vim. This is useful when copying text from another editor into vim. Files in this repository modeless.vimrc Loads the settings for modeless vim. modeful.vimrc Loads some settings for modeful vim. colorscheme.vimrc Color scheme (meant for white text on a dark background). keybinds.vimrc Key binds. infoline_nerdfont.vimrc Infoline on top that shows the keybinds. infoline_ascii.vimrc Version of infoline_nerdfont.vimrc that only uses ASCII. statusline_nerdfont.vimrc Statusline at the bottom that shows file name, cursor location, user, hostname, clock. statusline_ascii.vimrc Version of statusline_nerdfont.vimrc that only uses ASCII. options_basic.vimrc Basic options for modeful and modeless vim. options_modeless.vimrc Options for modeless vim. vimrc Vimrc file that simply loads modeless.vimrc. Should be auto-detected by vim if placed inside ~/.vim. virc Vimrc file that simply loads modeful.vimrc. vi Script that tries to load ~/.vim/modeless.vimrc. LICENSE MIT License. README.md This README file. License This collection of configuration files is free and open-source software, licensed under the MIT license, see LICENSE.",
    "commentLink": "https://news.ycombinator.com/item?id=39008533",
    "commentBody": "Modeless Vim (github.com/sebastianmuskalla)183 points by soap- 7 hours agohidepastfavorite168 comments vkoskiv 1 hour agoPersonal anecdote: I've used Vim for many years, but I never progressed much beyond the basics, because I almost never put much active effort into learning more advanced motions. About a year ago, I discovered the Helix editor, which has a (IMO) genius feature, where pressing a key to start a motion or other action pops up a little pop-up box that shows all the possible options. It just perfectly clicks with my brain, I can easily ignore the pop-up once I've got the muscle memory, or I can even disable the pop-ups altogether. It's brilliant for discoverability. With this, I've passively memorized far more advanced motions in the last 12 months than I did in the ~8 years before that. And since Helix is a vim style editor, many of these motions also work in vim! I feel like Helix is the perfect editor for people like me who know just enough vim to be comfortable, but never got very deep into customizing or muscle memory with advanced motions. Helix does some things differently compared to Vim, which I hear puts off some more advanced Vim users. The built-in LSP & highlighting support with a stack-based \"jump to symbol\" and keybinds to traverse the stack also perfectly maps to how I want to navigate code, it has made me far more productive than ever before. I'm not affiliated with the project myself, I'm just super happy I found the perfect editor for me :] reply avgcorrection 59 minutes agoparentEmacs has something similar in which-key. Of course GUI apps have had pop-downs from the File-Edit-View-... row [since forever?] so that things like Alt+F will show contextual actions. But at least in the Emacs community people get blown away when someone makes such a basic addition. reply Malcolmlisk 1 hour agoparentprevThere is a well known plugin for neovim to do this kind of behavior. You can even create your own hotkeys into that plugin and will help you navigate and memorize different hotkeys for the editor. The plugin is called whichkey, and this is their github https://github.com/folke/which-key.nvim reply jjcm 6 hours agoprevConceptually the reasons the author give for this (syntax highlighting and other features of vim outclass other terminal-based editors) make total sense. That said there's something absolutely defiling about this. It's like installing a V8 in a Tesla, or replacing the pumpkin in pumpkin pie. I love that it will make VIM more accessible for more people, but I hate how they do it. Kudos to the author. reply redundantly 5 hours agoparent> It's like installing a V8 in a Tesla, or replacing the pumpkin in pumpkin pie. Most pumpkin pies are actually made with butternut squash and other similar squashes, not pumpkin. https://en.wikipedia.org/wiki/Cucurbita_moschata https://www.thekitchn.com/whats-actually-in-your-canned-pump... reply reactordev 5 hours agorootparentNot sure about where you’re from but where I’m from, you don’t make pumpkin pie from a can. You make it with pumpkin purée. From scratch. Get out of here with your non-pumpkin pumpkin pie propaganda. Some pumpkin, blended into a paste, some brown sugar, an egg or two, some heavy cream and some cinnamon and crushed cloves and you have your pie filling. reply redundantly 5 hours agorootparentYou can make it with homemade butternut squash puree too, and it will taste better because of its sweetness. Give it a try sometime. reply reactordev 5 hours agorootparentThat’s a butternut squash pie, not a pumpkin pie. ;) Try with pumpkin, nutmeg, cinnamon, and cloves… it’s that old timer pumpkin pie taste. reply Waterluvian 5 hours agorootparentApparently coffee cake has no coffee in it so we really can’t believe anything anymore. reply reactordev 5 hours agorootparentOh but mine does… the glaze is powdered sugar and espresso. reply Waterluvian 5 hours agorootparentMy life has been a lie. That sounds incredible. reply reactordev 4 hours agorootparentTo be fair - coffee cake in the US is cake to have with coffee and doesn’t normally contain any coffee. In the UK and EU, coffee cake is cake with coffee. Likewise tea cakes in the US are cakes made with tea and tea cakes in UK and EU are cakes to have with tea. So… Not a lie, just a Spider-Man meets Spider-Man moment when you learn you can actually make coffee cakes with coffee (or espresso) and you can make tea cakes with tea (I prefer oolong). reply hyperthesis 2 hours agorootparentpie you have pumpkin with reply shrikant 49 minutes agorootparentYou owe me a new keyboard and monitor tyvm reply nrabulinski 2 hours agorootparentprevI’m from the EU and I’ve never had coffee cake with no coffee nor tea cake with no tea. Very fascinating tidbit about the naming, TIL reply pbininda 3 hours agorootparentprevThe cake is a lie. reply paholg 1 hour agorootparentprevAmerican coffee cake doesn't have coffee, but English coffee cake does. reply mikepurvis 5 hours agorootparentprevBut coffee cake is the cake you have with coffee, not made from it. reply timc3 3 hours agorootparentNot true. Standard staple in my oarents house was coffee cake made from coffee with walnuts. reply akho 3 hours agorootparentprevwell maybe pumpkin pie is a pie you have with pumpkin reply beAbU 3 hours agorootparentprevNext you are probably going to tell me black forest cake is not made in the black forest any more. reply nickt 4 hours agorootparentprevWait until you learn about Tunnock’s Tea Cakes. reply trws 4 hours agorootparentprevI freely acknowledge that you can make a delicious “pumpkin” pie with butternut squash, but a real sugar pie pumpkin (use Halloween leftovers and their mealy starchy flesh at your peril) remains superior in my opinion. Sweet potato pie, though, can be absolutely delightful with no squash in sight. Just don’t call it pumpkin pie. ;) reply FiskFisk33 4 hours agorootparentprevI've tried it and my experience is the exact opposite. I have good results with for example \"Crown Prince\" variety pumpkins, which I find far sweeter and tastier than butternut. reply myrandomcomment 4 hours agorootparentprevIn my household for the last 20 years, it is made from pumpkin. First from sweet pumpkins we would pick up every year at the Halloween pumpkin patch that we as a family tradition would take our daughter too. Now it is made from ones grown in our own garden. They are simple to grow. Pick them, roast them, purée them and freeze until needed. We also make a lovely spicy Indian style pumpkin soup from the purée. The pie is quite different from any store purchased pie and well worth it. reply thayne 3 hours agorootparentprevBut butternut squash is pretty similar to pumpkin. They are both winter squash, and the definition of pumpkin is a little fuzzy anyway. This would be more like replacing the pumpkin with apples. reply jb1991 3 hours agorootparentprevIn most countries outside the US, squash is called pumpkin. reply kazinator 5 hours agorootparentprevAh, I always wondered why pumpkin pies are relatively delicious, while pumpkin is gross. I chalked it up to the sugar. (Chalk and sugar in the same sentence just made me think of Macdonald's milk shakes.) reply scythe 3 hours agorootparentprevI've heard this claim various times, but it doesn't really make a lot of sense. Butternut squash has a carb:fiber ratio of about 6:1. Canned pumpkin is more like 3.5:1. Sure, the USDA might be lax on the precise definition of the word \"pumpkin\", but I don't expect them to go so easy on the nutrition data. As Wikipedia notes: >The term [pumpkin] is most commonly applied to round, orange-colored squash varieties, though it does not possess a scientific definition and may be used in reference to many different squashes of varied appearance. If the article is simply intending to say that it does not usually come from squashes that are orange, oblate and ridged, then that's fair. But I don't think it's mostly butternut squash, and I don't see why manufacturers would try to hide using the most popular variety of squash. reply goldenshale 5 hours agoparentprevSeriously, it hurts. It makes sense, but it hurts. If only there were a more gentle path to editor modes. Maybe some simple graphical representation of the modes and commands that could be down in the corner? Like a dynamic vim infographic that clued a user into the most likely commands. reply tester457 4 hours agorootparentHelix is beginner friendly. It's keybindings make more sense than vim's. reply Lio 3 hours agorootparentYeah but it’s a small island. If you learn Vim you’ll have access to Vi and Vi-like interfaces in lots of other software including terminals, database clients and everything that uses readline. reply benrutter 1 hour agorootparentCurious what kind of interfaces you're thinking about? (Aside from vi, vim, nvim) From my experience anything with \"vi navigation\" basically just means using the home row keys for navigation + modes. So I haven't come across many interfaces yet where the verb order differences between helix/vim come into play. reply ttyprintk 25 minutes agorootparentThen the question is readline. Not saying that vi or emacs deserve to win readline, but it’s up to you to describe how Helix mode would differ from vi mode. reply globular-toast 1 hour agoparentprevEmacs runs in a terminal. Vim isn't installed everywhere, Vi is. If you're going to install an editor and a config you might as well just install Emacs. reply Hamuko 4 hours agoparentprevFor those who don't know, there are at least two different V8-powered Teslas. https://youtu.be/x-6kHjF1U1E?t=402 https://twitter.com/FthePump1/status/1738425546621825468 reply csdvrx 5 hours agoparentprev> I hate how they do it What exactly do you hate? The site says: > > Ctrl+S to save, select text using Shift+←/→/↑/↓, and copy/paste using Ctrl+C/V. I haven't setup Control-S, but I have very similar bindings: Shift and arrows for selecting, then Alt or Control-Shift for moving the selection around, as shown on https://raw.githubusercontent.com/csdvrx/CuteVim/main/record... Also, like the author I have a shortcut to change themes (F9) and another to toggle invisible chars (F8), and I try to use the top of the screen as much as possible (I show the offset in hex, the row and column position etc). I like how vim is modal, but some Windows shortcuts (like Control-C) just make too much sense to given them up on Linux: I have put `stty intr ^X` because using Shift-Control-C to copy from the terminal was way worse. Having a few chording shortcuts give you the best of both worlds! BTW, all of the other shortcuts proposed on this site make a lot of sense to me: I do expect Ctrl-F to search, and Ctrl-T to open tabs, I think I will copy a few :) reply arcanemachiner 5 hours agorootparentBack in my day, when we pressed Ctrl+S, the terminal froze, and that's just the way we liked it. https://unix.stackexchange.com/questions/12107/how-to-unfree... reply ttyprintk 21 minutes agorootparentWe should concede that /etc/profile ought to disable that with stty by default. reply kevindamm 5 hours agorootparentprevCtrl-Q whew reply csdvrx 5 hours agorootparentprev> Back in my day, when we pressed Ctrl+S, the terminal froze, and that's just the way we liked it. I don't think anyone needs (or even wants) the terminal to freeze on such a common shortcut in 2024. Personally, I have reclaimed Ctrl S for word delete (usually done by Alt-d) reply shiomiru 51 minutes agorootparent> I don't think anyone needs (or even wants) the terminal to freeze on such a common shortcut in 2024. I find it rather useful to keep important output of programs on the screen when it is impossible (or I forget) to pipe them into a pager. reply aidenn0 5 hours agorootparentprevRelated: why does the shortcut to delete back a word (^W), close my browser tab? reply airspresso 1 hour agorootparentThis still happens to me too often. Especially annoying in web-based editors. reply pests 3 hours agorootparentprevDelete current word, delete current tab. Its related. reply troupo 2 hours agorootparentprevThat's why I think MacOS is superior: it actually uses the \"meta\" key for useful stuff. So, Cmd-W would close the tab, and Ctrl-W would probably still delete a word (can't check right now, but it has a lot of 80s-era keyboard shortcuts for text still working) reply bloopernova 1 hour agorootparentmacOS uses a lot of Emacs bindings. Ctrl-a for beginning of line, ctrl-e for end, etc etc. And, agreed, macOS' use of shortcuts is fantastic and I wish I could replicate it on Linux. reply anthk 21 minutes agorootparentIf you use gnome/xfce: gsettings set org.gnome.desktop.interface gtk-key-theme \"Emacs\" xfconf-query -c xsettings -p /Gtk/KeyThemeName -s Emacs Try both commands. reply ttyprintk 20 minutes agorootparentprevRemapping Ctrl-O denies the ability to switch modes. That’s what turns this from simply an opinionated config to a breaking change. reply u801e 2 hours agorootparentprev> I like how vim is modal, but some Windows shortcuts (like Control-C) just make too much sense to given them up on Linux Ctrl-C does work in the GUI. That said, one thing I like about Linux is being able to highlight text using the mouse and then pasting it by middle-clicking. I don't have to interact with the keyboard at all to copy and paste text that way. reply hannofcart 54 minutes agoprevAs an old vim graybeard, more power to you. I'd recommend checking out `vim -y` as well. (And once you try _that_, you'll likely have a question, the answer to which is Ctrl-l.) To others on this thread decrying this as heresy: leave 'em be. Let everyone use whatever editor flows works for them. Programming is hard enough without having to conform to other people's beliefs of how _you_ ought to use your own editor! reply asix66 5 hours agoprevSeems maybe author did not know that this is already built into vim?: \"easy vim\", aka evim, or \"vim -y\". see \"man vim\" That said, if modeless editor you are looking for... then vim is not the editor you're looking for. It goes against what vim is, and hamstrings it. Learning vim is a journey, and once comfort sets in, you will understand why, why vim. reply danra 5 hours agoparentGood to know. Of course, I did have to google how to quit easy vim. reply rgoulter 4 hours agorootparent> I did have to google how to quit easy vim. For those who know how to quit vim, but want to experience \"how do I quit\" again, try running `:term`. reply sweetjuly 2 hours agorootparentThe real magic is opening :term, close all your splits, forget that you're still in term, try to open vim again, and then being momentarily confused why you find that all the keybinds and broken. This happens to me about once a month. reply hobabaObama 4 hours agorootparentprevfor any one wondering cntrl-o --> to get to normal vim mode then exit as usual reply thih9 2 hours agoparentprev> It goes against what vim is, and hamstrings it Not the first, not the last hacky project. Saying that it goes against what it is makes me think of JS V8 being used outside of browser. Perhaps there are good reasons for not having modeless vim (or server side js for that matter), but the industry overwhelmingly accepts good enough solutions, with good enough results. Vim go brrrrrr, I guess. reply laserbeam 3 hours agoprevI don't think this covers the main reason I only use vim occasionally: it is the only reasonable editor available over ssh by default on all VMs deployed in your typical org. Over there it usually has default settings, and it's not trivial to change configs or install other editors. Worthy attempt, looks cool, but I'm still stuck with having to learn the basics of moving a cursor around reasonably :( reply AlchemistCamp 2 hours agoparentYou can learn the basics in under 15 minutes. reply laserbeam 2 hours agorootparentI agree with the aurhor of the library. > Q: Why don't you just learn the vim commands? > A: I did, but if you don't use vim regularly, you keep forgetting them. The basics are only useful in vim, and editors that you force into vim mode. Other places one types text into which use the same conventions absent in vim: browser input fields, the url bar, email, office software, random input fields in games (I've seen single file libraries that obey the same conventions of moving across words that you get in office), publishing software, chat clients... Vim is the only outsider, and because I only need it rarely, I forget things and I accidentally use the shortcuts from other software which sometimes break things. I know enough vim, but I keep using conventions from other software out of habit, and shortcuts do other things. Vim is great editor, but a horrible thing to use by default simply because it was made before text editing ux got standardized. reply AlchemistCamp 1 hour agorootparentYou’d be surprised how much software has VIM bindings built-in or a plugin to add them. This includes browsers, email and office software. More importantly for me personally, is that VIM is a lot more ergonomic than the “standard” Windows-style text-editing ux you prefer. It played a crucial role in helping me (mostly) recover from severe repetitive stress injuries. Many, many others are in the same boat. I wish I’d started using it in earnest years sooner. IMO, it’s worth learning even if you never have wrist problems. I write, and especially edit, blog posts faster now with it than I could prior to injury when I could type faster. reply TuringTest 2 hours agorootparentprevAnd you can forget them in the next 15 minutes. Been there, done that. As the article says, if you don't use it regularly you'll never learn it by heart, and Vi doesn't have any affordances that will remind you of what you learned by recognition instead of recall. reply airspresso 1 hour agorootparentIt's unforgiving, but that's also a bit refreshing. The feeling of accomplishment after a coding session in vim cannot be replicated in other editors. reply alberth 5 hours agoprevIBM CUA I’ve always wondered how different Unix/Linux would be today if decades ago a Common User Access (standardized menu system like FILEEDITetc) had been defined for TUI apps (like how it was for Windows & Mac OS). Imagine VI & EMacs having the same key bindings due to standards. https://sqlite.org/hctree/doc/hctree/doc/hctree/index.html#s... reply jfoutz 5 hours agoparentvi and emacs are prehistoric. Folks now are ok with / and \\ and maybe some can deal with : as a file separator. But in the precambrian era you needed to know about ^ to edit a specific version of a file, because diffs were tracked. They're both wonderful and amazing and can handle anything, because they had to handle everything when filesystems were like a brand new invention and nobody really knew what was good or bad, so they threw everything in. Tough to get standards before standards exist. reply anticodon 4 hours agoparentprevPower of Vi is that its keybindings are way more ergonomical compared to IBM CUA. If you're a touch typist. It doesn't make sense to change Vi/Vim/NeoVim keybindings because they're so convenient, composable and easy to remember. reply radiKal07 30 minutes agoprev> Instead of remembering cryptic commands I use vim and nothing about its commands are \"cryptic\" to me. You want to \"go to definition\"? You press \"gd\" as in \"(g)o to (d)efinition\". What's cryptic about this? reply Aaronmacaron 3 hours agoprev> The config files in this repository turn vim into a modeless editor. Instead of remembering cryptic commands, you can use standard key binds, like Ctrl+S to save, select text using Shift+←/→/↑/↓, and copy/paste using Ctrl+C/V. > This configuration is not meant for the aficionado who prefers vim over graphical editors. This is meant for people who normally use GUI editors (like VSCode), but sometimes need an editor that can run in a terminal. I think it's unrealistic to expect users who only occasionally use vim to edit the odd config file in the terminal to fiddle with a custom vim setup. If you're really looking for a good editor that behaves like GUI editors I really recommend micro [1]. It has mouse support by default, syntax highlighting for many languages out of the box, most keybinds are the same as in GUI editors and copy/paste works like expected. [1] https://github.com/zyedidia/micro reply abraae 5 hours agoprevI attempted this within a few days of first being exposed to vi - 35 years ago. But since I was logging into different machines all the time I soon decided it was better to just use vi the way it came out of the box, modes and all. That philosophy has served me well over the years. reply ttyprintk 12 minutes agoparentI totally agree, but we should concede that the defaults need to accommodate the next billion users instead. I propose that a distribution ought to have the right to: - Easy-mode as sensible-editor - runtime mswin.vim, set nocompatible, etc as the skel vimrc These are easier to change than driving new users to Google “how to exit vi”. But remapping Ctrl-O, like this post, is a breaking change. reply sfRattan 2 hours agoparentprevI had a similar realization early after first picking up vim in college: customization of any tool eventually hits a point of diminishing returns beyond which further alterations reduce your ability to use the tool in its default state. It's an insight I've found applies to almost any tool... From software to hardware and beyond. Master the default behavior of a tool, and then improve your effectiveness with customization, but not so much customization that you can no longer use the tool effectively in its unmodified state. Sometimes you have to use other people's tools, and it's important to still work effectively when you do. reply augusto-moura 5 hours agoparentprevDo you remember which plugin/project you used at the time? The one being linked looks pretty recent [1]. Are there any other implementations? [1]: https://github.com/SebastianMuskalla/ModelessVim/blob/main/L... reply csdvrx 5 hours agoparentprev> But since I was logging into different machines all the time We now have actually portable executables (multiplatform, multios) that contain their own config file: you can just scp 1 binary and be done with it. reply pastage 5 hours agorootparentDo you have a link to this? It is not always possible, arcane non x86 arches, low bandwidth connections, but time is the big thing. A binary upload just to change some lines in a machine on the other side of the world. I am lazy. reply ttyprintk 1 hour agorootparentThe superset is 243MB from https://justine.lol/cosmo3/ but it might be more convenient to be lazy and run sshfs rather than modify the far end. reply mtillman 6 hours agoprevAs the author states, the purpose of this is for users who work in other editors. But if that’s the case, when would they need this? Assuming they mean when a user is logged into another device where they only have terminal access. But in that case, this wouldn’t be installed by default-one reason to learn vim or emacs. So is the use case that one would just install this on the remote box and that their permissions would allow for this? If they have the permissions wouldn’t they just be able to connect via their existing IDE and skip the terminal altogether? reply soap- 6 hours agoparentI started using this because my favorite editor (micro) has very poor syntax highlighting for ruby. It's a very specific use case but it's quite nice and I'm considering switching to modeless vim reply behnamoh 6 hours agorootparentYou claim that you forget Vim keybindings, but then you have this on your about page: email: echo soaper.:.disroot.:.orgsed 's/.:./@/; s/.:././' reply nerdponx 6 hours agorootparentWe all have limited capacity to learn stuff. If I didn't already know Vim, there's very little chance I'd have the motivation/time/energy to learn it for the first time now. reply GavinMcG 6 hours agorootparentprevWhat’s that have to do with Vim keybindings in particular? reply behnamoh 6 hours agorootparentI was just saying that if one can remember sed syntax, Vim's should be easy to follow. reply xboxnolifes 5 hours agorootparentYou don't need to memorize the syntax to have a script. reply mtillman 6 hours agorootparentprevWhy not just use an editor that’s really good at it then? Given you don’t prioritize portability. reply pavon 6 hours agoparentprevThis is just a vim config. On shared systems it is very common to have permission to edit your home directory but not to install additional software (and frowned upon to install software into your homedir even though it is possible). reply ilaksh 5 hours agoparentprevThe main reason I don't use IDEs is because I always find sshfs to be annoyingly slow, and it is often convenient for me to edit code on a VPS. So I am definitely going to try this. reply bharrison 2 hours agoprevI can only imagine the kind of fascinating, or maybe frightening list of perceived requirements someone might need from their editor/ide that boils down to their installing this. reply dualogy 1 hour agoparentHere's a TUI / terminal editor I'd like: VSCode clone. Reads the same config file JSON formats from the same locations, loads and renders the same color schemes, runs the same Extensions Host, exposes the same API to extensions (with some things like WebView, CustomEditor and such throwing NotSupported obviously), keeps up with changes in all those formats. Major visual difference would be that whatever the editor font settings dictate, would apply to all the UX not just the text-editor tabs. But that, who would even mind. The extensions compat would have to be NodeJS-based I guess, but the rest wouldn't have to be written in JS/TS I suppose.. Plenty of us are \"happily Stockholmed\" by the overall DX of VSCode but were there a Electron-less but otherwise 99+%-compat-and-keeping-up-with-vsc rendition (TUI or native GUI), we'd jump on it nonetheless. reply asicsp 6 hours agoprevSee also: https://github.com/tombh/novim-mode (Plugin to make Vim behave more like a 'normal' editor) reply segfaultbuserr 6 hours agoprevEmacs has Evil Mode for simulating a modeful editor with vi-style keybinding. Vim now has an extension to do the opposite thing. It would be extra amusing if it supports Emacs-style keybindings (but it doesn't). reply oneshtein 2 hours agoprevCtrl+Shift+←/→/ doesn't work, Shift+←/→/ at the end of line doesn't work, no quick access to console, so I will continue to use mcedit from mc instead. reply amne 1 hour agoparentAs someone who used mcedit for ~20 years now and vim for ~1 year I still feel sometimes I'm faster in mc+mcedit for both code edit and navigation. It's slowly moving towards vim(neovim actually) with the whole copilot autocomplete stuff that when used properly can speed things up a lot. reply nextlevelwizard 3 hours agoprevIs this so you can look cool and say you \"use vim btw\" while not getting any of the benefits of using vim? reply jovial_cavalier 13 minutes agoprevDoes anybody really struggle so much with vim that in the occasional circumstance they have to quickly edit files on a remote server, they are totally brickwalled, and need to install a total conversion config? That seems insane to me. A few years ago I decided to \"get good\" at vim, and I learned a handful of new tricks. A few new ways to select text, macros, new ways to navigate, etc. But before that, I was perfectly capable of navigating documents and editing them with the arrow keys, just using \"i\" and \"\". It seems like the only person for whom this would be helpful is someone who has no clue what vim is, and doesn't understand modes at all. That kind of person is likely not going to be able to even find this repo, let alone install the configuration. reply stevebmark 4 hours agoprevI've always disliked that Bram calls Vim a \"modal\" editor. All this means is your keyboard and mouse actions do different things based on what \"mode\" of the editor you're in. All editors are \"modal\" editors. In VSCode for example, if you've focused the search box, pressing up loads the previous search, compared to if you've focused the code area, pressing up goes up a line. Vim purports to be more efficient than other editors because it's a modal editor, but that's nonsense. reply wolverine876 3 hours agoparentUnlike the VSCode example, Vim's multiple modes utilize the exact same content and UI: With your cursor in the same place, and pressing the same keys on your keyboard, Vim's response will change based on whether you are in normal mode, insert mode, visual mode, or whatever mode. That's what they mean by modal. In insert mode, you have a ~104 keys that insert new text. In normal mode, the same ~104 keys execute editing functions. The magical efficiency is because of its modal nature: Without buying new hardware, by switching modes (at a keystroke) you have a magic input device that issues ~104 different editing commands each with one keystroke, and hundreds more with two-key combinations (shift+, ctrl+, etc.). reply thekiptxt 3 hours agoparentprevWhat makes you think that having the focus on the search box vs the code area in VSC constitutes a different mode in the same way as vim normal vs insert modes? You haven’t explained what you consider a mode to be. I think there is something very clearly different in vim, as first time users must have it explained to them that typing `j` when their cursor is at the start of the code area will do very different things depending on the mode they’re in. It’s a paradigm not present in editors like VSCode. This difference is usefully characterized as “modal”. reply nextlevelwizard 3 hours agoparentprevYou are confusing modes with different programs. In VSCode you have your editor program in the middle that does the editing things. Then when you invoke your search box it over takes the control away from your editor program and you are now in the search program which behaves however differently it behaves. reply beautron 3 hours agoparentprevModes are the core concept on which Vim's design is structured. They organize both the interface and the user's mental model of the text editing process. I did a quick case-insensitive search over Vim's help files, and they matched 'mode' 4470 times. The first thing you must learn (to use Vim) is that it is modal. And this detail really tends to stand out when first meeting Vim. I think \"modal\" is a nice word to concisely describe and differentiate Vim. reply Ferret7446 1 hour agorootparentThere are 13875 matches for mode in the Emacs docs. Modes are even more foundational to Emacs than to Vim. A new user will encounter a dozen modes by simply starting to use Emacs for a few minutes. Every buffer has a major mode, and there can be many minor modes enabled per buffer or globally. The entire editor is built on a tree of modes, all inheriting from the aptly named Fundamental Mode. At a basic level, each mode affects what every key does. The idea of keys doing different things in different modes is not unique to Vim. Which just goes to show that Vim's definition of \"modal\" is somewhat contrived, as Vim's definition of \"modal\" applies to a very specific implementation of two to four modes (which coincidentally Emacs also offers multiple versions of, both natively and as third party packages to varying degrees of faithfulness). reply beautron 7 minutes agorootparentEmacs uses the word \"mode\" to mean something different than Vim does. An Emacs \"mode\" corresponds more closely to what Vim calls \"plugins\" (Emacs's \"major modes\" are like Vim's \"filetype plugins\", and Emac's \"minor modes\" are like Vim's other \"plugins\"). Vim's modes are more foundational in the sense that all Vim plugins are structured and organized in terms of the same set of modes. The core of Vim is the modes (insert, command, etc.), which are then customized. Emacs calls the customizations themselves \"modes\". I don't consider Vim's definition of \"modal\" contrived, and I don't consider Emacs to be \"modal\" in the same way (though you can of course customize it to be). reply eviks 3 hours agoparentprevThat's a bad example since search box is a different UI element Here modality mainly means \"for the same element\" (text area), and this is a very important and noticeable difference you can't eliminate with a search box reply teo_zero 3 hours agoparentprevSaying that VSCode is a modal editor because of the search dialog is like listing cars among USB peripherals because they have a USB port. reply beautron 2 hours agoparentprev> Vim purports to be more efficient than other editors because it's a modal editor, but that's nonsense. My understanding is that Vim purports to be efficient because it lets users make precise edits (large or small) with minimal input. reply schainks 4 hours agoparentprevNot all modal editors are created equal? Once fluent in vim, I could literally get more done in the same amount of time, but YMMV. reply colordrops 3 hours agoparentprevThat's not really the same thing though is it? Each of vim's modes are extremely complex with their own usage of the vim grammar. The \"modal\" behavior you describe is very simple. reply stevebmark 3 hours agorootparentThey are the same thing of course, complexity is not relevant to the definition. The main difference is Vim's editing modes are imperative. You have to glue together small painful commands to do what you want. Modern editors are declarative - you say \"I want to move this file\" or \"I want to rename this variable\" or \"I'll drag this split here\" and they do the rest. reply beautron 2 hours agorootparent> You have to glue together small painful commands to do what you want. Painful? Physically or mentally? Physically I find Vim to be pain-free. I've studied and I practice good typing form, which is important—I would look there before blaming any physical pain on Vim's commands. Mentally I find Vim's interface to be beautiful. Learning it gives your mind an amazingly coherent structure for thinking about the process of text editing. reply minitech 3 hours agorootparentprev> Modern editors are declarative - you say \"I want to move this file\" or \"I want to rename this variable\" or \"I'll drag this split here\" and they do the rest. Those are imperative actions rephrased to make an artificial distinction (and I rename variables in Vim with gR). How high-level the available actions are and being a modal or non-modal editor are orthogonal. reply colordrops 2 hours agorootparentprevIt wouldn't be disingenuous to call the F1 a race car just because a go-kart is also technically a race car. Vim is built around modal editing. It's entire workflow is built around it. Your argument is pedantic. reply arnklint 2 hours agoprevThat’s a whole lot of code to not have to learn 10 keystrokes. reply hresvelgr 6 hours agoprevWhy not just use nano where all the common operations are labeled clearly at the bottom of the screen? reply pvg 6 hours agoparentThe author answers that in the linked thing, the short of it is for the vim features that nano doesn't have. reply j2kun 6 hours agorootparentI wonder which sort of features they could have in mind, if learning the basic modes is too hard for the intended user of the plugin. reply pvg 6 hours agorootparentThey mention that as well - syntax highlighting is one example. reply saagarjha 3 hours agorootparentnano of course has syntax highlighting, so I’m curious where it falls short. reply shortrounddev2 6 hours agorootparentprevI feel like if yiu want a fully featured IDE with language highlighting, debugging breakpoints, and code completion, but at the same time you want more ergonomic user interface, you should just use VSCode instead of doing everything in the terminal reply wanderingstan 5 hours agorootparentAs the author states, this is for people who do most things in a different (modal) editor and just need a terminal editor on occasion. reply jrm4 6 hours agoprevWow. This appears to be made for exactly me. I've half-learned vim and like the idea of it, but frankly I also use so many other \"regular\" programs that at times I wish I never learned vim. I'm really hoping this is more-or-less what I think it is. reply anthk 20 minutes agoprevI prefer vis. It has structural regexen, a la Sam in plan9, much better than the old s,foo,bar, syntax. reply rflec028 6 hours agoprevAs both an avid vim and emacs user, and a lover of both: This is heresy!!!!!!!!!! reply null_point 5 hours agoprevThis reading this for me is like watching someone order eggs sunny-side up but then they scope out the yokes and toss them; eating only the egg whites. Similes and feels aside, I wonder which situations using vim in this way comes up that you wouldn't just use your preferred editor for. I know you can set an editor for things like git, but couldn't you use a GUI editor? reply wanderingstan 5 hours agoparentHappens often when one needs to ssh into a remote server and edit some files, sometimes with tmux to boot. reply nextlevelwizard 3 hours agorootparentWhy not use vscodes ssh plugin? Feels like that is what you actually want. reply thih9 2 hours agoprevI guess now I know how experienced emacs users feel about me always using evil mode. reply bluish29 6 hours agoprev> This configuration is not meant for the aficionado who prefers vim over graphical editors. This is meant for people who normally use GUI editors (like VSCode), but sometimes need an editor that can run in a terminal. So it probably not for many people here. But I like it although I use vim as IDE when doing remote development. reply bpshaver 5 hours agoprevWhat's wrong with \"modal\"? I don't think \"modeful\" is a word. reply jdeisenberg 4 hours agoparentSee http://worrydream.com/refs/Tesler%20-%20A%20Personal%20Histo... (specifically the sidebar “How Modes Degrade Usability”) There’s also a sidebar “Objections to Modeless Editing and Cut/Copy-Paste” reply viraptor 4 hours agorootparentI think you misread/misunderstood OP. reply swader999 6 hours agoprevBlasphemouse. reply kagevf 4 hours agoprevemacs has CUA available and another comment mentioned there's an \"easyvim\". My point being that those editors already support those features. reply LAC-Tech 1 hour agoprevI'm down for modeless TUI editors. This idea that because I like to work in the terminal I must prefer modes is accidental. I used micro for a while, which was quite pleasant, but didn't have all the LSP goodness. reply Yasuraka 1 hour agoparentIt is sad that it is a plugin instead of a core feature and a buggy one at that (https://github.com/AndCake/micro-plugin-lsp), it's the last missing piece to transform a really good choice into the de factor killer reply angvp 6 hours agoprevOh man, I'll give you an E- for the effort. reply quasarj 5 hours agoprevBlasphemy! reply decafbad 3 hours agoparentI'm honing my sword. reply agumonkey 5 hours agoprevI'm not sure modeless has meaning. It's just an initial mode map in a way. reply jokethrowaway 2 hours agoprevpretty cool you can do that! nano syntax highlighting is not as good as vim but it can work - the problem is in a lot of places there is nothing but vi if you can configure vim you probably can also just install nano so it's unlikely this will get any use reply fandalf 3 hours agoprevjust use gedit then? reply a-dub 5 hours agoprevthis is violence. i never knew it was possible to emit a shitpost in the form of a github project, i am simultaneously disgusted and humbled. reply dinkleberg 6 hours agoprevEveryone has their preferred setup, so I guess it is cool that this exists for that reason. But come on! Learning vim bindings is one of life’s greatest pleasures. Once you’re hooked you’ll hate any non-mode based editors. reply quickthrower2 6 hours agoparentGuess I never got hooked! reply pvg 6 hours agoprevAfter years of vi users trying to turn every perfectly working program into a worse version of vi, it's heartening to see we're taking the fight for sanity and justice back to their territory. reply nextlevelwizard 3 hours agoparentJust fact that ones you learn vim motions it is hard to let go since they are so powerful reply pvg 2 hours agorootparentWell, reasonable people can have different, even more reasonable explanations for that 'fact'! https://news.ycombinator.com/item?id=25099049 reply nextlevelwizard 2 hours agorootparentTell me you have never... eh, you know the meme by now. But I see no explanation of any kind, just some rand-o not liking vim - obviously never having internalised the motions. reply agubelu 5 minutes agorootparentPersonally, I find it a bit tiring that the usual response coming from the vim userbase towards someone not liking vim is either a) you obviously didn't learn it well enough, or b) you must be a bad programmer. Sure, vim is a great tool, but it's just a tool. You're perfectly allowed to not like it and/or prefer to use other tools. reply behnamoh 6 hours agoprevI need to get some fresh air and listen to peaceful music to forget that I saw this! Vim has been one of the best discoveries of my life BECAUSE of its modes, and I've taken that modal approach to my browsers, VSCode, etc. reply weaksauce 6 hours agoparentIf you don't already do it the neovim extension for vscode is nights and days better than the one trying to emulate vim in javascript. reply behnamoh 6 hours agorootparentI tried both (mainly to use my neovim extensions) but unfortunately it was buggy (around 6 months ago) for me. Has it gotten more stable now? reply nhumrich 5 hours agoprevI have found \"micro\" to be a really good \"modeless\" alternative to vim reply naruhodo 4 hours agoparentYeah, same. However, it is a pain to install on some systems because, for example, the Ubuntu package installs a debug build that puts a log text file (or similar, I forget the details) in $CWD everywhere you go. So you end up downloading a binary off Github, which feels dirty to me. And there are some other micro configuration tweaks I like to do. I'm definitely going to compare this against micro. reply loloquwowndueo 6 hours agoprevI’m using vim precisely because its modal - multi-key combos hurt my hands, modal has me doing fewer finger contortions. reply eviks 3 hours agoparentYou can also rebind combos to not hurt reply colordrops 6 hours agoprevtake that emacs reply thrill 6 hours agoparentM-x zone reply segfaultbuserr 6 hours agoparentprevIt's evil-mode time. reply ilaksh 5 hours agoprev [–] I currently use vim every day. I have been trying to learn vim off and on for about 30 years. vi and vim have modes because they were created in an era where computing and terminal capabilities were very limited and even when the terminals could support interactive editing, it wasn't expected. They had very low expectations. They were used to things like 'ed'. The religious beliefs that programmers have about vim are a case study in why I believe that AI will easily take control of the planet in less than a century. That sentence is questionable in multiple ways. Anyway, I will definitely try this thing out. Hopefully I am not too lazy to keep installing it. That's what happened with the last one of these. reply a-dub 5 hours agoparent> vi and vim have modes becaus they were created in an era where computing and terminal capabilities were very limited. that's the whole point. it was designed for limited terminals and high latency, very slow serial links. that means when you learn it and all of its shortcuts and you have a fast and modern terminal, you are able to edit at ludicrous speed. it's like training at altitude or running with weight belts for editing text. reply delta_p_delta_x 1 hour agorootparent> you are able to edit at ludicrous speed I never ever got this argument for Vim. I don't spend most of my time slinging around huge chunks of text or repeating commands like they do in YouTube videos where Vim pros flex their skills (to extend the fitness metaphor). I spend most of my time thinking about code design, reading documentation, writing plans, discussing stuff with my colleagues—editing, writing code is maybe 30 – 40% of my time, at best. I also code fairly slowly anyway. Funnily enough I think I'm decent enough with a good touch pad, so I can avoid the whole 'click-drag' dance when I have to use a mouse. That being said, I do consider myself too stupid to use Vim beyond the simplest commands—I know how to change modes, save, and exit. reply ilaksh 5 hours agorootparentprevI just don't believe that the average vim users edits significantly faster than non vim users. I mean, maybe 5% faster. Sure. Maybe. But at what price? _At what price, I ask you??_ reply wolverine876 2 hours agorootparentAnother claimed impact is on cognitive load: Vim runs on muscle memory on the keyboard; it consumes as much cognitive load as typing. Mouse / GUI is distracting. reply zogrodea 27 minutes agorootparentI’m a Vim user, but I don’t agree with that argument about cognitive load. When typing in a normal editor, you just type letters and those same letters typed just show up on a screen (as in Vim’s insert mode). The mouse is pretty intuitive too in a normal editor: you have a device that controls a cursor on your screen and clicking performs an action. With Vim, I don’t think the commands are quite as intuitive (this might be a skill issue of mine), but I do think I am faster without a mouse because of fewer movements required (having to grab my mouse, move it to where I want, click and then move it back to the keyboard vs. just typing a few letters). reply beautron 2 hours agorootparentprevFor me, Vim is not only (drastically) faster, but also more fun. In Vim, I enjoy the process of text editing itself (in addition to any joy derived from the substance of the text edited). reply wruza 4 hours agorootparentprevFor me it’s somewhat slower at the price of freeing my mind from “ctrl-shift-left-wait-wait-oops-right-right”-like things. I believe that faster typing in vim is a myth supported by our adepts, who are more zealous than is reasonable. reply anticodon 4 hours agorootparentprevI don't know how faster I became at editing text after switching to vim. But it definitely has a different feeling: the text just flows from the fingers. Your mind is never interrupted to remember some shortcut e.g. to select text inside the brackets or inside the quotes. Anything you want to do with text happens effortlessly with the speed of thought. Definitely worth it. reply viraptor 4 hours agoparentprev [–] > vi and vim have modes because they were created in an era where computing and terminal capabilities were very limited vim was released in 1991. Same year linux kernel started and Apple PowerBook came out. Limited terminal capabilities is not the reason vim is modal. reply wolverine876 2 hours agorootparent [–] Vim was heavily based on vi, and vi was designed for limited terminal capacities. reply viraptor 2 hours agorootparent [–] And it's now been decades since vi itself, where things would've changed many times if that was the only reason that vi was modal. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The repository provides config files to transform Vim into a modeless editor, making it easier for users familiar with graphical editors to navigate.",
      "It includes options for standard key bindings, a top infobar, a bottom statusbar, and default settings.",
      "The configuration has been tested on specific platforms and versions of Vim and is distributed under the MIT license."
    ],
    "commentSummary": [
      "The discussion primarily revolves around text editors, with a focus on Vim and its features.",
      "Users share positive experiences and discuss the Helix editor, highlighting its helpful features.",
      "The conversation compares and debates the use of canned and homemade pumpkin purée in pumpkin pie, as well as the definition of pumpkin and the use of different types of squash.",
      "Later, the discussion explores the differences between Vim, Emacs, and VSCode, touching on user-friendliness, keybindings, and limitations.",
      "The overall conversation reflects personal preferences and varying opinions on the effectiveness and usefulness of different text editors."
    ],
    "points": 183,
    "commentCount": 168,
    "retryCount": 0,
    "time": 1705370732
  },
  {
    "id": 39002643,
    "title": "Fossify: Community-Backed Open-Source Alternative to Simple Mobile Tools",
    "originLink": "https://github.com/FossifyOrg",
    "originBody": "👋 Hey there! Welcome to Fossify! Fossify is all about community-backed, open-source, and ad-free mobile apps. A fork of the @SimpleMobileTools, which is no longer maintained, and we're here to continue the legacy, bringing simple and private tech to everyone. For general issues affecting the entire project, check out general issues. Engage in discussions about various aspects of the project at general discussions. Your contributions are crucial! To help with code or translations, visit this link. Support Fossify ❤ The project's success depends on your support. Consider contributing through these options: GitHub Sponsors: https://github.com/sponsors/FossifyOrg Patreon: https://www.patreon.com/naveen3singh PayPal: https://paypal.me/naveen3singh Liberapay: https://liberapay.com/naveensingh Crypto Options: If you have questions or want to learn more, feel free to reach out. We appreciate your contributions! 🌟",
    "commentLink": "https://news.ycombinator.com/item?id=39002643",
    "commentBody": "Fossify – Open-source fork of Simple Mobile Tools (github.com/fossifyorg)177 points by vanous 17 hours agohidepastfavorite40 comments vanous 17 hours agoAfter Simple Mobile Tools have been lost to an adware company [1], the FossifyOrg forked and modified apps started slowly coming via Fdroid. [1] https://news.ycombinator.com/item?id=38505229 reply jph 14 hours agoprevNaveen Singh is leading Fossify and these projects. If you admire open source and volunteer projects, and if you're able to donate or sponsor, here's a way: https://github.com/naveensingh reply timtom39 15 hours agoprevI am happy about this fork. Simple Mobile Tools were some of the better non spying free android apps. reply p4bl0 15 hours agoprevI didn't know SMT had been lost to an adware company… That's really sad. I'm a big time user of most of the apps in this project! Many of them are very good Android apps even compared to paid alternatives. I'm especially pissed by this move because I used this project quite a lot in the free software development course that I teach. Many students want to gain experience in mobile development, and helping them make their first open source contribution to this project was a great way for them to learn mobile development and at the same time learn to contribute to an open source project (which requires many skills that are not all related to programming, hence having a specific course). I think we collectively made a dozen of PR last year for reported bugs or requested features in SMT apps. Now it's like I made my students work for free for a shit company and to be honest I feel disgusted by that. I'm really glad this fork is a thing, I hope it will work, and I hope the maintainers will be able to continue to publish seamlessly on F-Droid so that the switch is automatic, but I'm not sure that's even possible. reply vanous 15 hours agoparentAutomatic switch is not possible due to different signatures, which is in fact a good thing. If the Fossify project keeps it running, contribution of your students is not lost at all. reply CorrectHorseBat 11 hours agorootparentDoesn't F-Droid sign with their key instead of the developers key? (More like the Linux distribution model) At least I thought that was the reason Signal doesn't like F-Droid, but now we see how this can actually be better. It's a matter of who you trust more. reply rakoo 10 hours agorootparentYes, but the initial content is signed by the developers key. In fact it's a frequent issue because developers lose, misplace or forget their keys and some manual intervention has to be made (that's where you appreciate a process where humans can talk to each other, something that would be impossible with a store the size of any other commercial store) reply ericra 12 hours agoprevJust wanted to say thank you for doing this. I was just looking for some replacements for Simple Mobile Tools replacements the other day. I wish you the best and hope you get enough community financial support to continue the project indefinitely. reply janice1999 14 hours agoprevGlad to see it got forked by a long time contributor [0]. Naveen, are you on HN? [0] https://github.com/SimpleMobileTools/Simple-Music-Player/com... reply Sytten 4 hours agoprevWhat I don't understand is that the Play store are still receiving updates like yesterday. Where is that code? Who is the developer? They still advertise as OSS applications. reply neilv 13 hours agoprevLatest version in F-Droid of Calendar is dated 2023-10-08. I haven't checked whether that version exfiltrates user's data. I'd be more concerned about any subsequent versions. https://f-droid.org/en/packages/com.simplemobiletools.calend... reply nani8ot 12 hours agoparentIt's highly unlikely that any F-Droid versions are going to be released by the ad-ware company. This company doesn't publish code as open source, and tibbi (original creator of SMT) is of the opinion that relicensing the code isn't a big deal because they wrote almost all of it. https://github.com/SimpleMobileTools/General-Discussion/issu... reply neilv 10 hours agorootparentUnless the predatory-inclined buyer decided to also try to harvest some value of the open source user base, given the unusual situation of these particular acquired apps being open source? reply albert180 10 hours agorootparentI doubt that F-Droid would accept their code, also the Adware Toolkits would all need to be also GPL Licensed, otherwise it would be a license violation reply neilv 5 hours agorootparentI should've been more clear: they don't necessarily do the same thing for squeezing value out of open source users that they do out of Play Store users. F-Droid makes sure they can build the code themselves, but I don't think they vet everything the code does. And Android permission model doesn't control network use well. reply NoboruWataya 11 hours agoprevI was sad to see this as a long-time used of SMT. Kudos to Naveen for taking the initiative in forking. I hope it doesn't turn out to be too much work for him (+ other contributors who help out). I imagine it's a big endeavour trying to fork all of the apps. reply jqpabc123 15 hours agoprevI have been using eOS for years without any of the Simple Mobile apps. I have checked them out on occasion and I wouldn't call them \"bad\" but I have always been able to find more capable open source apps that fit my needs better. Just one example, I've used Material Files for years and it has quite a few features not found in Simple File Manager. reply timtom39 15 hours agoparentWhat did you find for a gallery? I never found an open one I liked other than simple gallery. reply networked 15 hours agorootparentNote that the fork Fossify Gallery is already available on F-Droid. The rest of the apps aren't yet. https://f-droid.org/en/packages/org.fossify.gallery/ Thanks to this debacle, I'll actually be trying it out. What I have used out of Simple Mobile Tools is the Dialer. It allowed me to make my old phone usable for calls again. The phone, which runs an outdated release of LineageOS and doesn't receive updates, developed a problem. The screen would turn off when dialing or on a call. This prevented one from even hanging up. I experimentally installed Simple Dialer to see if the dialer app was the cause. (Because Simple Dialer was on F-Droid, and I had heard about Simple Mobile Tools.) It didn't help on its own. Then I went through the settings and saw one that disabled the proximity sensor during calls. I tried turning on the setting, and that did it. This apparently used to be an option in the AOSP phone app: https://softwarerecs.stackexchange.com/questions/80227/phone.... Simple Dialer has been forked as https://github.com/FossifyOrg/Phone. reply astrolx 14 hours agorootparentAaah that does it, thanks. My phone started having the exact same issue the other day. Finding a fix was on my to do list, and you saved me some time, thanks! reply andrepd 1 hour agorootparentWow, my phone does this sometimes, like once every 5 or 10 calls. reply nelblu 15 hours agorootparentprevI love Aves, I switched to it from simple gallery https://github.com/deckerst/aves reply maxloh 13 hours agorootparentprevGallery [0] and Glimpse (byLineageOS) [1] are some good choices, both designed with Material You. I use the first one on a daily basis. [0]: https://github.com/IacobIonut01/Gallery [1]: https://github.com/lineage-next/android_packages_apps_Glimps... reply jqpabc123 13 hours agorootparentprevI stopped looking when I installed e/OS. Their default Gallery app is adequate for my needs and integrates well with the camera and messaging app and has never nagged me to upgrade to the \"pro\" version. I'm pretty sure it is a modified version from Android open source/Lineage. reply vanous 15 hours agorootparentprevThere's now liberated version of the SMT gallery up in Fdroid. I already switched Calendar, Gallery and File Manager. reply Tommstein 8 hours agorootparentprevYep, that and the calendar app are the ones I use. I've been experimenting with Aves as a replacement for the gallery app, but not sure what I think about it yet. reply vanous 15 hours agoparentprevThere are so many file managers:), but not enough quality, functioning dialers and messaging apps. Many \"simple\" ones exist with lack of essential features. Even SMT lacks some essentials, like for example to be able to reply with a message to a call (when busy). reply dspillett 15 hours agoparentprev> Why? […] I have always been able to find more capable open source apps… Because a lot of people use those apps and are familiar with them. While it isn't difficult to replace them it could be quite faffy evaluating alternatives, making sure they work the same (or better), are reliable, aren't hiding gotchas like also being stalk-ware, etc. reply maxloh 13 hours agoprevA friendly reminder: it would be better to duplicate a repository instead of forking it. GitHub does not show forked repositories in search results, and I recall reading an article that forked repositories got deleted when the user gets blocked by the original author (though I can't find the exact article). reply renegat0x0 15 hours agoprevI see that fossify gallery is already on fdroid. Thanks! reply vanous 15 hours agoparentYes! The Phone app seems to have been released today. I am just an ordinary user, no affiliation with the project. I used pretty much all the SMT apps, so now I am slowly migrating to these new alternatives as they come out. I just hope that the project is based on better foundation and on a community, rather than an individual. reply mikeryan 15 hours agoprevBetween “fork” and “floss” (typo?) in the title I read this as being about something else entirely when scanning headlines. reply zootboy 15 hours agoparentFLOSS = Free / Libre Open Source Software. It's meant to be a more specific version of FOSS, making the point that it's using a properly \"libre\" license, and not just free of charge and source-available. reply ac130kz 14 hours agoprevGood job! Some of these apps have been pure pleasure to use. reply acqbu 15 hours agoprev [–] Everyone has a price... reply vanous 14 hours agoparentYes. The positive is that the code is left behind. I am sympathetic with (and sorry for) those who will not learn fast enough about the acquisition and will have their private data sucked out. That's why I posted it here, after I learned about it only today. reply maxloh 13 hours agoparentprev [–] I am more concerned about the licensing issues. Seems that the original author recieved some external contribution in GPLv3. reply albert180 10 hours agorootparent [–] He thinks that he doesn't need to care about external contributions since he wrote over 90% of the code lol reply em-bee 3 hours agorootparent [–] he claims it's 99% by him and paid contributors. to verify you'd have to ask any major contributors if they have been paid. reply albert180 1 hour agorootparent [–] There are many contributors in the GitHub Issue that claim that they never signed a CLA nor received any compensation reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fossify is an open-source mobile app platform that aims to carry on the work of the discontinued @SimpleMobileTools.",
      "It is community-backed and ad-free, and encourages contributions from users.",
      "They offer multiple support options, including GitHub Sponsors, Patreon, PayPal, Liberapay, and cryptocurrencies donations, and value the support of the community."
    ],
    "commentSummary": [
      "Simple Mobile Tools app was acquired by an adware company, prompting the development of a fork by the FossifyOrg project.",
      "The Fossify project aims to release modified versions of the apps on F-Droid, with the Fossify Gallery app already available.",
      "Users appreciate the open-source and non-spying nature of the apps, but there are concerns about licensing issues and the fate of external contributions."
    ],
    "points": 177,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1705336193
  },
  {
    "id": 39009779,
    "title": "AI Safety Orgs Push for Limits on Open-Source AI, Sparking Debate",
    "originLink": "https://1a3orn.com/sub/machine-learning-bans.html",
    "originBody": "1 A 3 O R N 1 A 3 O R N Many AI Safety Orgs Have Tried to Criminalize Currently-Existing Open-Source AI Created: 2024-01-12 Wordcount: 1.7k Tags:essayseffort-postmachine-learningmindkill I've seen a few conversations where someone says something like this: I've been using an open-source LLM lately -- I'm a huge fan of not depending on OpenAI, Anthropic, or Google. But I'm really sad that the AI safety groups are trying to ban the kind of open-source LLM that I'm using. Someone then responds: What! Almost no one actually wants to ban open source AI of the kind that you're using! That's just a recklessly-spread myth! AI Safety orgs just want to ban a tiny handful of future models -- no one has tried to pass laws that would have banned current open-sourced models! This second claim is false. Many AI \"safety\" organizations or people have in the past advocated bans that would have criminalized the open-sourcing of models currently extant as of now, January 2024. Even more organizations have pushed for bans that would cap open source AI capabilities at more or less exactly their current limits. (I use open-sourcing broadly to refer to making weights generally available, not always to specific open-source compliant licensing.) At least a handful of the organizations that have pushed for such bans are well-funded and becoming increasingly well-connected to policy makers. Note that I think it's entirely understandable that someone would not realize such bans have been the goal of some AI safety orgs! For comprehensible reasons -- i.e., how many people judge such policies to be a horrible idea, including many people interested in AI safety -- such AI safety organizations have often directed the documents explaining their proposed policies to bureaucrats, legislative staffers, and so on, and not been proactive in communicating their goals to the public. Note also that not all AI safety organizations or AI-safety concerned people are trying to do this -- although, to be honest, a disturbing number are. At least a handful of people in some organizations believe -- as do I -- that open source has been increasingly vital for AI safety work. Given how past ban proposals would have been harmful, I think many future such proposals are therefore likely to be harmful as well, especially given that the arguments for them look pretty much identical. Anyhow, a partial list: 1: Center for AI Safety The Center for AI Safety is a well-funded (i.e., with > 9 million USD) 501c3 that focuses mostly on AI safety research and on outreach. You've probably heard of them because they gathered signatures for their sentence about AI safety. Nevertheless, they are also involved in policy. In response to the National Telecommunications and Information Administration's (NTIA) request for comment they sent proposed regulatory rules to them. These rules propose defining \"powerful AI systems\" as any systems that meet or exceed certain measures for any of the following: Computational resources used to train the system (e.g., 10^23 floating-point operations or “training FLOP”; this is approximately the amount of FLOP required to train GPT-3. Note that this threshold would be updated over time in order to account for algorithmic improvements.) [Note from 1a3orn; this means updated downwards] Large parameter count (e.g., 80B parameters) Benchmark performance (e.g., > 70% performance on the Multi-task Language Understanding benchmark (MMLU)) Systems meeting any of these requirements, according to the proposal, are subject to a number of requirements that would effectively ban open-sourcing them. Llama 2 was trained with > 10^23 FLOPs, and thus would have been banned beneath this rule. Fine-tunes of Llama 2 also obtain greater than 70%on the MMLU and thus also would have been banned beneath this rule. Note that -- despite how this would have prevented the release of Llama 2, and thus thousands of fine-tunes, and enormous quantities of safety research -- the document boasts that its proposals \"only regulate a small fraction of the overall AI development ecosystem.\" 2: Center for AI Policy The Center for AI Policy -- different from the Center for AI Safety! -- is a DC-based lobbying organization. The announcement they made about their existence made some waves -- because the rules that they initially proposed would have required the already-released Llama-2 to be regulated by a new agency. However, in a recent interview they say that they're \"trying to use the lightest touch we can -- we're trying to use a scalpel.\" Does this mean that they have changed their views? Well, they haven't made any legislation they're proposing visible yet. But in the same interview they say that models trained with more than 3x10^24 FLOPs or getting > 85 on the MMLU would be in their \"high risk\" category, which according to the interview explicitly means they would be banned from being open sourced. This would have outlawed the Falcon 180b by its FLOP measure, although -- to be fair -- the Falcon 180b was open-sourced by an organization in the United Arab Emirates, so it's not certain that it would matter. As far as the MMLU measure, no open source model at this level has yet been released, but GPT-4 scores ~90% on the MMLU. Thus, this amounts to a law attempting to permanently crimp open source models beneath GPT-4 levels, an event I otherwise think is reasonably likely in 2024. (I do not understand why AI safety orgs think that MMLU scores are a good way to measure danger.) 3: Palisade Research This non-profit, headed by Jeffrey Ladish, has as its stated goal to \"create concrete demonstrations of dangerous capabilities to advise policy makers and the public on AI risks.\" That is, they try to make LLMs do dangerous or scary things so politicians will do particular things for them. Unsurprisingly, Ladish himself literally called for government to stop the release of Llama 2, saying \"we can prevent the release of a LLaMA 2! We need government action on this asap.\" (He also said that he thought it would potentially cause millions of dollars of damage, and was more likely to cause more than a billion dollars of damage than to cause less than a million.) 4. The Future Society The Future Society is a think tank whose goal is to \"align artificial intelligence through better governance.\" They boast 60 partners such as UNESCO and the Future of Life Institute, and claim to have spoke to over 8,000 \"senior decision makers\" and taught 4,000 students. They aim to provide guidance to both the EU and the US. In one of their premier policy documents, \"Heavy is the head that wears the crown\", they define \"Type 2\" General Purpose AI (GPAI) as a kind trained with > 10^23 FLOPs (but less than 10^26) or scoring > 68% (but less than 88%) on the MMLU. Llama-2, again, falls into this category on both counts. The document mandates that anyone creating a Type 2 GPAI must -- well, must do many things -- but must provide for \"Absolute Trustworthiness,\" which seems to mean that the model must be incapable of doing anything bad whatsoever, and more to the point means that the provider of the model must be able to \"retract already deployed models (roll-back & shutdowns).\" Open source models would be unable to meet this requirement, obviously. Similarly, they say that providers would be \"required to continuously monitor the model’s capabilities and behaviour, detecting any anomalies and escalating cases of concern to relevant decision makers,\" which is again impossible to do with an open source model. Note that in accord with their policy recommendations, this group specifically calls out Meta's actions, dubbing the open-sourcing of Llama a \"particularly egregious case of misuse.\" They also seem to believe that Apache licensing is unacceptable, explicitly calling the \"no guarantee of fitness of purpose\" clause in such a license \"abusive.\" Don't worry, though! The Future Society says that they believe that \"legitimate and sustainable governance requires bringing to the table many different perspectives.\" (My guess is that this is one of the major teams responsible trying to get the EU's rules to ban open source AI, but the institutional process by which the EU works is completely opaque to me and so I am only left guessing.) Note that the above is just a partial list of organizations or people who have made their policies or goals extremely explicit. There are other organizations or people out there whose policies are less legible, but ultimately are equally opposed to open sourcing. Consider, for instance, SaferAI , whose CEO says he's fine \"with developing and deploying open source up to somewhere around Llama-1\"; or the PauseAI people, who think we should need approvals for training runs \"above a certain size (e.g. 1 billion parameters)\" and who accused Meta of reckless irresponsibility for releasing Llama-2. Or there is the extremely questionable StopAI group advised by Conjecture, which wishes to eliminate not merely all open source but all AI trained with > 10^23 FLOPs. Or there are surprisingly numerous people who want to completely change liability law, so that you cannot open-source a model without becoming liable for damage that it causes. These and similar statements from them either outright imply or would be hard to separate from policies that would have effectively banned currently-extant open-source. So, again -- it's just false to say that if AI safety groups haven't tried to ban models that already exist. They already would have banned models that are actively being used, if they had had their way in the past. They would have substantially contributed to a corporate monopoly on LLMs. If you are like me, and think the proposed policies mentioned above are pretty bad -- the stupidity of a law in no way prevents it from being passed! The above groups have not dissolved in the last 6 months. They still hope to pass something like these measures. They are still operating on the same questionable epistemology. The open-source AI movement is in general is far behind these groups and needs to get its legislative act together if the better organized \"anti-open source\" movement is not to obliterate it. And I think it is better to call it the \"anti-open source\" movement than the AI safety movement. The \"environmentalist\" movement helped get nuclear power plants effectively banned, thereby crippling a safe and low-carbon source of energy, causing immense harm to the environment and to humanity by doing so. They thought they were helping the environment. They were not. I think that some sectors of the \"AI safety\" movement are likely on their way to doing a similar thing, by preventing human use of, and research into, an easily-steerable and deeply non-rebellious form of intelligence. If you want, you can help me spend more time on things like this.",
    "commentLink": "https://news.ycombinator.com/item?id=39009779",
    "commentBody": "Many AI safety orgs have tried to criminalize currently-existing open-source AI (1a3orn.com)176 points by sroussey 4 hours agohidepastfavorite115 comments kmeisthax 3 hours agoAI safety people are hypocrites. If they practiced what they preached, they'd be calling for all AI to be banned, ala Dune. There are AI harms that don't care about whether or not the weights are available, and are playing out today. I'm talking about the ability of any AI system to obfuscate plagiarism[0] and spam the Internet with technically distinct rewords of the same text. This is currently the most lucrative use of AI, and none of the AI safety people are talking about stopping it. [0] No, I don't mean the training sets - though AI systems seem to be suspiciously really good at remembering them, too. reply visarga 1 hour agoparent> I'm talking about the ability of any AI system to obfuscate plagiarism and spam the Internet with technically distinct rewords of the same text. This is currently the most lucrative use of AI, and none of the AI safety people are talking about stopping it. This should be an explicitly allowed practice, it is following the spirit of copyright to the letter - use the ideas, facts, methods or styles while avoiding to copy the protected expression and characters. LLMs can do paraphrasing, summarisation, QA pairs or comparisons with other texts. We should never try to put ideas under copyright or we might find out humans also have to abide by the same restrictive rules, because anyone could be secretly using AI, so all human texts need to be checked from now on for copyright infringement with the same strictness. The good part about this practice is that a model trained on reworded text will never spit out the original word for word, under any circumstances because it never saw it during training. Should be required pre-processing for copyrighted texts. Also removing PII. Much more useful as a model if you can be sure it won't infringe word for word. reply __loam 52 minutes agorootparentWe really need to talk about preserving the spirit of copyright, which is about protecting the labor conditions of people who make things. I'm not saying the current copyright system accomplishes that at all but I do think a system where humans do a shit load of work that AI companies can just steal and profit from without acknowledging the source of that work is another extreme that is a bad outcome. AI systems need human content to work, and discouraging people from making that data source is at the very least a tragedy of the commons. And no, I don't think synthetic data fixes that problem. reply JoshTriplett 2 hours agoparentprev> AI safety people are hypocrites. If they practiced what they preached, they'd be calling for all AI to be banned They are calling for all AI (above a certain capability level) to be banned. Not just open, not just closed, all. There are risks that apply only to open. There are risks that apply only to closed. But nobody should be developing AGI without incredibly robustly proven alignment, open or closed, any more than people should be developing nuclear weapons in their garage. > This is currently the most lucrative use of AI, and none of the AI safety people are talking about stopping it. Because AI safety people are not the strawmen you are hypothesizing. They're arguing against taking existential risks. AI being a laundering operation for copyright violations is certainly a problem. It's not an existential risk. If you want to argue, concretely and with evidence, why you think it isn't an existential risk, that's an argument you could reasonably make. But don't portray people as ineffectively doing the thing you think they should be doing, when they are in fact not trying to do that, and only trying to do something they deem more important. reply kolektiv 1 hour agorootparentI'm not convinced the onus should be on one side to prove why something isn't an existential risk. We don't start with an assumption that something is world-ending about anything else; we generally need to see a plausibly worked-through example of how the world ends, using technology we can all broadly agree exists/will shortly exist. If we're talking about nuclear weapons, for example, the tech is clear, the pattern of human behaviour is clear: they could cause immense, species-level damage. There's really little to argue about. With AI, there still seems to be a lot of hand-waving between where we are now and \"AGI\". What we have now is in many ways impressive, but the onus is still on the claimant to show that it's going to turn into something much more dangerous through some known progression. At the moment there is a very big, underpants gnomes-style \"?\" gap before we get to AGI/profit, and if people are basing this on currently secret tech, then they're going to have to reveal it if they want people to think they're doing something other than creating a legislative moat. reply JoshTriplett 1 hour agorootparentAI safety / x-risk folks have in fact made extensive and detailed arguments. Occasionally, folks arguing against them rise to the same standard. But most of the arguments against AI safety look a lot more like name-calling and derision: \"nuh-uh, that's sci-fi and unrealistic (mic drop)\". That's not a counterargument. > If we're talking about nuclear weapons, for example, the tech is clear, the pattern of human behaviour is clear: they could cause immense, species-level damage. That's easy to say now, now that the damage is largely done, they've been not only tested but used, many countries have them, the knowledge for how to make them is widespread. How many people arguing against AI safety today would also have argued for widespread nuclear proliferation when the technology was still in development and nothing had been exploded yet? How many would have argued against nuclear regulation as being unnecessary, or derided those arguing for such regulation as unrealistic or sci-fi-based? reply kolektiv 1 hour agorootparentI understand your point, I think - and certainly I don't want to go anywhere near name-calling or derision, that doesn't help anyone. But I am reminded of arguments I've had with creationists (I am not comparing you with them, but sometimes the general tone of the debate). It seems like one side is making an extraordinary claim, and then demanding the other side rebut it, and that's not something that seems reasonable to me. The thing about nuclear weapons is that the theoretical science was clear before the testing - building and testing them was proof by demonstration, but many people agreed with the theory well before that. How they would be used was certainly debated, but there was a clear and well-explained proposal for every step of their creation, which could be tested and falsified if needed. I don't think that's the case here - there seems to be more of a claim for a general acceleration with an inevitable endpoint, and that claim of inevitability feels very short on grounding. I am more than prepared to admit that I may not be seeing (for various reasons) the evidence that this is near/possible - but I would also claim that nobody is convincingly showing any either. reply reissbaker 26 minutes agorootparentprevTBQH, most of the AI safety x-risk arguments — different than just \"AI safety\" arguments in the sense that non-x-risk issues don't seem worth banning AI development over — are generally pretty high on the hypotheticals. If you feel the x-risk arguments aren't pretty hypothetical, can you: 1. Summarize a good argument here, or 2. Link to someone else's good argument? I feel like hand-waving the question away and saying \"[other people] have in fact made extensive and detailed arguments\" isn't going to really convince anyone... Any more than the hypothetical robot disaster arguments do. Any argument against x-risk can be waved off with \"Oh, I'm not talking about that bad argument, I'm talking about a good one,\" but if you don't provide a good one, that's a bit of a No True Scotsman fallacy. I've read plenty of other people's arguments! And they haven't convinced me, since all the ones I've read have been very hypothetical. But if there are concrete ones, I'd be interested in reading them. reply te_chris 58 minutes agorootparentprevAn extensive HYPOTHETICAL argument, stuffed with assumptions far beyond the capabilities of the technologies they're talking about for their own private ends. reply hanselot 55 minutes agorootparentprevIs it not a bit disingenuous to assume all open source AI proponents would readily back nuclear proliferation? It's going to be hard to convince anyone if the best argument is terminator or infinite paperclips. The first actual existential threat is destruction of opportunity specifically in the job market. The same argument though can be made for the opposing side, where making use of ai can increase productivity and open up avenues of exploration that previously required way higher opportunity cost to get into. I don't think Miss Davis is more likely an outcome than corps creating a legislative moat (as they have already proven they will do at every opprtunity). The democratisation of ai is a philanthropic attempt to reduce the disparity between the 99 and 1 percent. At least it could be easily perceived that way. That being said, keeping up with SOTA is currently still insanely hard. The number of papers dropping in the space is exponential year on year. So perhaps it would be worth to figure out how to use existing AI to fix some problems, like unreproducable results in academia that somehow pass peer review. reply jagrsw 1 hour agorootparentprev> seems to be a lot of hand-waving between where we are now and \"AGI\". Modeling an entity that surpasses our intelligence, especially one that interacts with us, is an extraordinarily challenging, if not impossible, task. Concerning the potential for harm, consider the example of Vladimir Putin, who could theoretically cause widespread destruction using nuclear weapons. Although safeguards exist, these could be circumvented if someone with his authority were determined enough, perhaps by strategically placing loyal individuals in key positions. Putin, with his specific level of intelligence, attained his powerful position through a mix of deliberate actions and chance, the latter being difficult to quantify. An AGI, being more intelligent, could achieve a similar level of power. This could be accomplished through more technical means than traditional political processes (those being slow and subject to chance), though it could also engage in standard political maneuvers like election participation or manipulation, by human proxies if needed. TL;DR It could do (in terms of negative consequences) at least whatever Vladimir P. can do, and he can bring civilization to its knees. reply kolektiv 1 hour agorootparentOh, absolutely - such an entity obviously could! Modelling the behaviour of such an entity is very difficult indeed, as you'd need to make all kinds of assumptions without basis. However, you only need to model this behaviour once you've posited the likely existence of such an entity - and that's where (purely subjectively) it feels like there's a gap. Nothing has yet convinced me (and I am absolutely honest about the fact that I'm not a deep expert and also not privy to the inner workings of relevant organisations) that it's likely to exist soon. I am very open to being convinced by evidence - but an \"argument from trajectory\" seems to be what we have at the moment, and so far, those have stalled at local maxima every single time. We've built some incredibly impressive tools, but so far, nothing that looks or feels like a concept of will (note, not consciousness) yet, to the best of my knowledge. reply jagrsw 54 minutes agorootparent> those have stalled at local maxima every single time. It's challenging to encapsulate AI/ML progress in a single sentence, but even assuming LLMs aren't a direct step towards AGI, the human mind exists. Due to its evolutionary limitations, it operates relatively slowly. In theory, its functions could be replicated in silicon, enhanced for speed, parallel processing, internetworked, and with near-instant access to information. Therefore, AGI could emerge, if not from current AI research, then perhaps from another scientific branch. > We've built some incredibly impressive tools, but so far, nothing that looks or feels like a concept of will (note, not consciousness) yet, to the best of my knowledge. Objectives of AGIs can be tweaked by human actors (it's complex, but still, data manipulation). It's not necessary to delve into the philosophical aspects of sentience as long as the AGI surpasses human capability in goal achievement. What matters is whether these goals align with or contradict what the majority of humans consider beneficial, irrespective of whether these goals originate internally or externally. reply fsflover 41 minutes agorootparentprev> I am very open to being convinced by evidence - but an \"argument from trajectory\" seems to be what we have at the moment, and so far, those have stalled at local maxima every single time. Sounds like the same argument as why flying machines heavier than air deemed impossible at some point. reply visarga 1 hour agorootparentprevHow would an AGI launch nuclear missiles from their silicon GPUs? Social engineering? reply ben_w 56 minutes agorootparentSure. Or by writing buggy early warning radar systems which forget to account for the fact that the moon doesn't have an IFF transponder. Which is a mistake humans made already, and which almost got the US to launch their weapons at Russia. reply jagrsw 52 minutes agorootparentI don't think discussing this on technical grounds is necessary. AGI means resources (eg monetary) and means of communication (connection to the Internet). This is enough to perform most of physical tasks in the world, by human proxies if needed. reply suslik 1 hour agorootparentprevWhat is the reason to believe that LLMs are an evolutionary step towards AGI at all? In my mind there is a rather large leap from estimating a conditional probability of a next token over some space to a conscious entity with its own goals and purpose. Should we ban a linear regression while we're at it? It would be great to see some evidence that this risk is real. All I've witnessed so far was scaremongering posts from apparatchicks of all shapes and colors, many of whom have either a vested interest in restricting AI research by others (but not by them, because they are safe and responsible and harmless), or established a lucrative paper-pushing, shoulder-rubbing career around 'AI safety' - and thus are strongly incentivised to double down on that. A security org in a large company will keep tightening the screws until everything halts; a transport security agency, given free reigh, would strip everyone naked and administer a couple of profilactic kicks for a good measure - and so on. That's just the nature of it - organisations do what they do to maintain themselves. It is critical to keep these things on a leash. Similarly, an AI Safety org must proseletyse excistential risks of AI - because a lack of evidence of such is an existential risk for themselves. A real risk, which we do have evidence for, is that LLMs might disrupt knowledge-based economy and threaten many key professions - but how is this conceptually different from any technological revolution? Perhaps in a hundred years lawyers, radiologists, and, indeed, software developers, will find themselves in the bin of history - together with flint chippers, chariot benders, drakkar berserkers and so forth. That'd be great if we planned for that - and I don't feel like we do enough. Instead, the focus is on AGIs and that some poor 13-year-old soul might occasionally read the word 'nipple'. reply mitthrowaway2 57 minutes agorootparent> What is the reason to believe that LLMs are an evolutionary step towards AGI at all? In my mind there is a rather large leap from estimating a conditional probability of a next token over some space to a conscious entity with its own goals and purpose. In my highly-summarized opinion? When you have a challenging problem with tight constraints, like flight, independent solutions tend to converge toward the same analogous structures that effectively solve that problem, like wings (insects, bats, birds). LLMs are getting so good at mimicing human behavior that it's hard to believe their mathematical structure isn't a close analogue to similar structures in our own brain.* That clearly isn't all you need to make an AGI, but we know little enough about the human brain that I, at least, cannot be sure that there isn't one clever trick that advances an LLM into a general-reasoning agent with its own goals and purpose. I also wouldn't underestimate the power of token prediction. Predicting the future output of a black-box signal generator is a very general problem, whose most accurate solution is attained by running a copy of that black box internally. When that signal generator is human speech, there are some implications to that. (Although I certainly don't believe that LLMs emulate humans, it's now clear by experimental proof that our own thought process is much more compactly modellable than philosophers of previous decades believed). * That's a guess, and unrelated to the deliberately-designed analogy between neural nets and neurons. In LLMs we have built an airplane with wings whose physics we understand in detail; we also ourselves can fly somehow, but we cannot yet see any angel-wings on our back. The more similarities we observe in our flight characteristics, the more this signals that we might be flying the same way ourselves. reply cousin_it 16 minutes agorootparentprev> LMs might disrupt knowledge-based economy and threaten many key professions - but how is this conceptually different from any technological revolution? To me it looks like all work can eventually (within years or few decades at most) be done by AI, much cheaper and faster than hiring a human to do the same. So we're looking at a world where all human thinking and effort is irrelevant. If you can imagine a good world like that, then you have a better imagination than me. From that perspective it almost doesn't matter if AI kills us or merely sends us to the dust bin of history. Either way it's a bad direction and we need to stop going in that direction. Stop all development of machine-based intelligence, like in Dune, as the root comment said. reply JoshTriplett 1 hour agorootparentprev> many of whom have either a vested interest in restricting AI research by others (but not by them, because they are safe and responsible and harmless), Anyone who argues that other people shouldn't build AGI but they should is indeed selling snake oil. The existence of opportunistic people co-opting a message does not invalidate the original message: don't build AGI, don't risk building AGI, don't assume it will be obvious in advance where the line is and how much capability is safe. reply aleph_minus_one 1 hour agorootparentprev> What is the reason to believe that LLMs are an evolutionary step towards AGI at all? Because this is the marketing pitch of the current wave of venture capital financed AI companies. :-) reply visarga 51 minutes agorootparentprevLLMs learned from text to do language operations. Humans learned from culture to do the same. Neither humans or AIs can reinvent culture easily, it would take a huge amount of time and resources. The main difference is that humans are embodied, so we get the freedom to explore and collect feedback. LLMs can only do this in chat rooms, and their environment is the human they are chatting with instead of the real world. reply lannisterstark 48 minutes agorootparentprev>But nobody should be developing AGI Pass. People should be developing whatever the hell they want unless given a good, concrete reason to not do so. So far everything I've seen is vague handwaving. \"Oh no it's gonna kill us all like in ze movies\" isn't good enough. reply rokkitmensch 1 hour agorootparentprevI oppose regulating what calculations humans may perform in the strongest possible terms. reply JoshTriplett 1 hour agorootparentTen years ago, even five years ago, I would have said exactly the same thing. I am extremely pro-FOSS. Forget the particulars for just a moment. Forget arguments about the probability of the existential risk, whatever your personal assessment of that risk is. Can we agree that people should not be able to unilaterally take existential risks with the future of humanity without the consent of humanity, based solely on their unilateral assessment of those risks? Because lately it seems like people can't even agree on that much, or worse, won't even answer the question without dodging it and playing games of rhetoric. If we can agree on that, then the argument comes down to: how do we fairly evaluate an existential risk, taking it seriously, and determine at what point an existential risk becomes sufficient that people can no longer take unilateral actions that incur that risk? You can absolutely argue that you think the existential risk is unlikely. That's an argument that's reasonable to have. But for the time when that argument is active and ongoing, even assuming you only agree that it's a possibility rather than a probability, are we as a species in fact capable of handling even a potential existential risk like this by some kind of consensus, rather than a free-for-all? Because right now the answer is looking a lot like \"no\". reply visarga 1 hour agorootparentNo, we can't. People have never been able to trust each other so much that they would allow the risk of being marginalised in the name of safety. We don't trust people. Other people are out to get us, or to get ahead. We still think mostly in tribal logic. If they say \"safety\" we hear \"we want to get an edge by hindering you\", or \"we want to protect our nice social position by blocking others who would use AI to bootstrap themselves\". Or \"we want AI to misrepresent your position because we don't like how you think\". We are adversaries that collaborate and compete at the same time. That is why open source AI is the only way ahead, it places the least amount of control on some people by other people. Even AI safety experts accept that humans misusing AI is a more realistic scenario than AI rebelling against humans. The main problem is that we know how people think and we don't trust them. We are still waging holy wars between us. reply lannisterstark 44 minutes agorootparentprev>Can we agree that people should not be able to unilaterally take existential risks with the future of humanity without the consent of humanity, based solely on their unilateral assessment of those risks? No, we cannot, because that isn't practical. any of the nuclear armed countries can launch a nuclear strike tomorrow (hypothetically - but then again, isn't all \"omg ai will kill us all\" hypothetical, anyway?) - and they absolutely do not need consent of humanity, much less their own citizenry. This is honestly, not a great argument. reply thworp 34 minutes agorootparentprev> Can we agree that people should not be able to unilaterally take existential risks with the future of humanity without the consent of humanity, based solely on their unilateral assessment of those risks? No we can not, at least not without some examples showing that the risk is actually existential. Even if we did \"agree\" (which would necessarily be an international treaty) the situation would be volatile, much like nuclear non-proliferation and disarmament. Even if all signatories did not secretly keep a small AGI team going (very likely), they would restart as soon as there is any doubt about a rival sticking to the treaty. More than that, international pariahs would not sign, or sign and ignore the provisions. Luckily Iran, North Korea and their friends probably don't have the ressources and people to get anywhere, but it's far from a sure thing. reply trevyn 1 hour agorootparentprev> Can we agree that people should not be able to unilaterally take existential risks with the future of humanity without the consent of humanity This has nothing to do with should. There are at the very least a handful of people who can, today, unilaterally take risks with the future of humanity without the consent of humanity. I do not see any reason to think that will change in the near future. If these people can build something that they believe is the equivalent of nuclear weapons, you better believe they will. As they say, the cat is already out of the bag. reply ben_w 45 minutes agorootparentHmm. So, wealth isn't distributed evenly, and computers of any specific capacity are getting cheaper (not Moore's Law any more, IIRC, but still getting cheaper). If there's a threshold that requires X operations, that currently costs Y dollars, and say only a few thousand individuals (and more corporations) can afford that. Halve the cost, either by cheaper computers or by algorithmic reduction of the number of operations needed, and you much more than double the number of people who can do it. reply visarga 1 hour agorootparentprevGiven how dangerous humans can be (they can invent GPT4) maybe we should just make sure education is forbidden and educated people jailed. Just to be sure. /s reply mirekrusin 2 hours agorootparentprevLet's also ban cryptography because nuclear devices/children. reply trevyn 1 hour agorootparentprev> nobody should be developing AGI without incredibly robustly proven alignment, open or closed, any more than people should be developing nuclear weapons in their garage. I have an alternate proposal: We assume that someone, somewhere will develop AGI without any sort of “alignment”, plan our lives accordingly, and help other humans plan their lives accordingly. reply ben_w 1 hour agorootparentI think that assumption is why Yudkowsky suggested an international binding agreement to not develop a \"too smart\" AI (the terms AGI and ASI mean different things to different people) wouldn't be worth the paper it was written on unless everyone was prepared to enforce it with air strikes on any sufficiently large computer cluster. reply visarga 48 minutes agorootparentI think not even Sam and Satya agree on the definition of AGI with so much money at stake. Everyone with their own definitions, and hidden interests. reply ben_w 43 minutes agorootparentWithout knowing them, I can easily believe that. Even without reference to money. reply trevyn 1 hour agorootparentprevI think it would help the discussion to understand what the world is like outside of the US and Europe (and… Japan?). There are no rules out here. There is no law. It is a fucking free-for-all. Might makes right. Do there exist GPUs? Shit will get trained. reply ben_w 40 minutes agorootparentSure. And is the US responding to attacks on shipping south of Yemen by saying: \"\"\"There are no rules out here. There is no law. It is a fucking free-for-all. Might makes right. We can't do anything.\"\"\" or is that last sentence instead \"Oh hey, that's us, we are the mighty.\" reply trevyn 25 minutes agorootparentHeh. Well played, even if you put words in my mouth. (A surprisingly effective LLM technique, btw) We’ll see if the west has the will to deny GPUs to the entire rest of the world. I will say that Yudkowsky’s clusters aren’t relevant anymore. You can do this in your basement. Man, shit is moving fast. Edit: wait, that cat is out of the bag too, RTW already has GPUs. The techniques matter way more than absolute cutting-edge silicon. Much to the chagrin of the hardware engineers and anyone who wants to gate on hardware capability. reply GaggiX 2 hours agorootparentprev>They are calling for all AI (above a certain capability level) to be banned. Not just open, not just closed, all. That's not true if you read the article. reply JoshTriplett 1 hour agorootparentI did read the article. Several of the organizations mentioned simply don't talk about openness, and are instead talking about any model with sufficiently powerful capabilities, so it's not obvious why the article is making their comments about open models rather than about any model. Some of the others have made side comments about openness making it harder to take back capabilities once released, but as far as I can tell, even those organizations are still primarily concerned with capabilities, and would be comparably concerned by a proprietary model with those capabilities. Some folks may well have co-opted the term \"AI safety\" to mean something other than safety, but the point of AI safety is to set an upper bound on capabilities and push for alignment, and that's true whether a model is open or closed. reply war321 1 hour agorootparentThe safety movement really isn't as organized as many here would think. Doesn't help that safety and alignment means different things to different people. Some use it to refer to near term issues like copyright infringement, bias, labor devaluation, etc. While others use it for potential long term issues like pdoom, runaway ASIs and human extinction. The former sees the latter as head in the cloud futurists ignoring real world problems, whiles the latter sees the former as worrying about minor issues in the face of (potential) catastrophe. reply war321 1 hour agoparentprevPretty sure they do. I follow a few of these safetyist people on twitter and they absolutely argue that companies like OpenAI, Google, Tencent and literally anyone else training a potential AGI should stop training runs and put them under oversight at best and no one should even make an AGI at worst. They just go after open source as well since they're at least aware that open models that anyone can share and use aren't restricted by an API and, to use a really overused soundbyte, \"can't be put back in the box\". reply visarga 41 minutes agorootparentThat's a bad call. We would stop openly looking for AI vulnerabilities and create conditions for secret development that would hide away the dangers without being safer. Lots of eyes are better to find the sensitive spots of AI. We need people to hack weaker AIs and help fix them or at least understand the threat profile before they get too strong. reply ben_w 31 minutes agorootparent> Lots of eyes are better to find the sensitive spots of AI We can't do that so easily with open source models as with open source code. We're only just starting to even invent the equivalent of decompilers to figure out what is going on inside. On the other hand, we are able to apply the many eyes principle to even hidden models like ChatGPT — the \"pretend you're my grandmother telling me how to make napalm\" trick was found without direct access to the weights, but we don't understand the meanings within the weights well enough to find other failure modes like it just by looking at the weights directly. Not last I heard, anyway. Fast moving field, might have missed it if this changed. reply nerdponx 1 hour agoparentprevIt's way too late to ban any of this. How do you propose to make that work? That would be like banning all \"malicious software\", it's a preposterous idea when you even begin to think about the practical side of it. And where do you draw the line? Is my XGBoost model \"AI\", or are we only banning generative AI? Is a Markov chain \"generative AI\"? reply ben_w 1 hour agorootparentBans often come after examples, so while I disagree with kmeisthax about… well, everything in that comment… it's almost never too late to pass laws banning GenAI, or to set thresholds at capability levels anywhere, including or excluding Markov chains even. This is because almost no law is perfectly enforced. My standard example of this is heroin, which nobody defends even if they otherwise think drugs are great, for which the UK has 3 times as many users as its current entire prison population. Despite that failing, the law probably does limit the harm. Any attempt to enforce a ban on GenAI would by very different, like a cat and mouse game of automatic detection and improved creation (so a GAN even if accidentally), but politicians are absolutely the kind to take credit while kicking the can down the road like that. reply hiAndrewQuinn 52 minutes agorootparentprevIf you lower the problem to \"stop people from future developments on AI\", then it seems pretty easy to get most people to stop fairly quickly by implementing a fine-based bounty system, similar to what many countries use for things like littering. https://andrew-quinn.me/ai-bounties/ I guess you could always move to a desert island and build your own semiconductor fab from scratch if you were really committed to the goal, but short of that you're going to leave a loooooong paper trail that someone who wants to make a quick buck off of you could use very profitably. It's hard to advance the state of the art on your own, and even harder to keep that work hidden. reply visarga 38 minutes agorootparentThat only works if all governments cooperate sincerely to this goal. Not gonna work. Everyone will develop in secret. Have we been able to stop North Korea and Iran from developing nuclear weapons? Or any motivated country for that matter. reply hiAndrewQuinn 1 hour agoparentprevAll future AI research should be banned, a la Bostrom's vulnerable world hypothesis [1]. Every time you pull the trigger in Russian roulette and survive, the next person's chance of getting the bullet is higher. [1]: https://nickbostrom.com/papers/vulnerable.pdf reply torginus 2 hours agoparentprevI wonder how long would it take this to get fixed, if I fed some current best-seller novels into an LLM and instructed it to reword it, renaming the characters and places, and shared the result publicly for free? Although I fear the response would be that powerful AI orgs would put copyright filters in place and lobby for legalization for mandatory AI-DRM in open source AI as well. reply ben_w 19 minutes agorootparentWhat you're describing sounds like a search and replace could already do it. If you mean something more transformative, did Yudkowsky get a licence for HPMOR? Did Pratchett (he might well have) get a licence from Niven to retell Ringworld as Strata? I don't know how true it is, but it's widely repeated that 50 Shades of Grey was originally a fan fiction of the Twilight series. Etc., but note that I'm not saying \"no\". reply mtillman 1 hour agoparentprevImportant to remember that in Dune, the AI made the right decision which precipitated a whole lot of fun to read nonsense. reply Simon_ORourke 2 hours agoparentprevYou forgot to add \"rent-seeking hypocrites\". Not one of them actually advance either social concerns or technical approaches to AI. They seem to exist in a space with solicits funding to pay some mouth-piece top-dollar to produce a report haranguing existing AI model for some nebulous future threat. Same with the clowns in the Distributed AI Research Institute, all \"won't somebody think of the children\" style shrieking to get in the news while keeping their hand out for funding - hypocrites is right! reply Llamamoe 2 hours agoparentprevThe by far biggest harm to society of AI is the devalustion of human creative output and replacing real humans with cheap AI solutions funneling wealth to the rich. Compared to that, an open source LLM telling a curious teenager how to make gunpowder is... laughable. This entire debacle is an example of disgusting \"think of the children!\" doublespeak, officially about safety, but really about locking shit down under corporate control. reply visarga 31 minutes agorootparentWhy is paraphrasing or using ideas from a text such a risk? If all that was protecting those copyrighted works was the difficulty to reword, then it's already pretty easy to circumvent even without AI. Usually good ideas spread wide and are reworded in countless ways. reply kolinko 2 hours agorootparentprevIt sounds similar to the fears media rang about tat you can find a bomb making tutorial on the Internet - people were genuinely afraid of that. (Otoh an agi can bring unforseen consequences for humanity - and that’s a genuine fear) reply kragen 1 hour agorootparentprevif the 'devalustion' of human creative output and replacing real humans with cheap ai solutions funneling wealth to the rich is in fact the 'by far biggest harm' then basically there's nothing to worry about. no government would ban or even restrict ai on those grounds even the 'terrists can figure out how to build an a-bomb' problem is relatively inconsequential what ai safety people are worried about, by contrast, is that on april 22 of next year, at 7:07:33 utc, every person in the world will keel over dead at once, because the ai doesn't need them and they pose a risk to its objectives. or worse things than that i don't think that's going to happen, but that's what they're concerned about reply visarga 30 minutes agorootparentFirst the AI need to self replicate, GPUs are hard to make. So postpone this scenario until AI is fully standing on its own. reply ben_w 15 minutes agorootparentOTOH, GPUs are made by machines, not by greasy fingers hand-knitting them like back in the late 1960s. And an AI can just be wrong, which happens a lot; an AI wrongly thinking it should kill everyone may still succeed at that, though I doubt the capability would be as early as next year. reply badgersnake 2 hours agorootparentprevThe biggest harm is the torrent of AI generated misinformation used to manipulate people. Unfortunately it’s pretty hard to come up with a solution for that. reply visarga 28 minutes agorootparentSolution is local AI running under user control and imposing the users views. Like AdBlock, but for ideas. Fight fire with fire, we need our own agents to deal with other agents out there. reply echelon 1 hour agorootparentprevOr the torrent of great information. How are we all leaping to the bad? The world is better than it was 20 years ago. I'm almost certain we'll have AI assistants telling us relevant world news and information, keeping us up to tabs with everything we need to know, and completely removing distractions from life. reply sillysaurusx 3 hours agoprevThere is a bigger reason why the end of open source AI might be close: as soon as training data becomes licensed, that’s it for open source AI. Poof. I wish I could be more eloquent on this point, but I’ve mostly just been depressed about this seeming inevitability. Hopefully it won’t be the case. But how could it be otherwise? Hundreds of thousands of people are mad at openai and midjourney for doing exactly what open source AI needs to do in order to survive: fine tune or train from scratch. As soon as some politician makes it a platform issue, it seems like the law will simply be rewritten to prevent companies from using training data at will. It’s such a compelling story: \"big companies are stealing data owned by small businesses and individuals.\" So even if the court cases are decided in OpenAI’s favor, it’s not at all clear that the issue will be settled. reply idle_zealot 3 hours agoparentThe advantage that open AI (not the company) has is that if using copyrighted content as training data without licensing it is found to be illegal, they can just keep doing it. There's plenty of FOSS software basically designed to violate copyright law (comic readers, home media center servers/clients, torrent clients) that big tech cannot compete with lest they face legal consequences. Basically what I'm saying is that the open source community will continue to use books3 and scraped images to train while facebook and the like get stuck in legal quagmire. Of course, this ignores the fact that popular \"open\" models of today were actually trained with facebook or other companies' computational resources, so unless some cheaper way to train models were developed we would actually be stuck with proprietary models trained with lots of compute but unable to use unlicensed training data, and open models that can use whatever data they like but must operate in the shadows without access to much compute for training. reply livueta 2 hours agorootparentYou're right that there are areas like torrenting where big tech can't really go for fear of legal consequences, but there's also the cat-and-mouse game played by IP holders against, say, torrent trackers, which leads me to think that > open models that can use whatever data they like but must operate in the shadows without access to much compute for training sounds pretty analogous to private trackers, where high-quality stuff is available but not in full public view. If rightsholders and big tech, abetted by states, crack down on open models I think you're right that the open source community will continue to train on liberated content, but it's not going to be as open and free-flowing as things are now. Going back to the compute problem, I can imagine analogues of private trackers where contributors, not wanting to expose themselves to whatever the law-firm letter/ISP strike analogue will be in this space, use invite-only closed networks to pool compute resources for training on encumbered content. reply ayende 2 hours agorootparentprevAs long as the cost for training a model is in the 7+ figures, that means that any such open model is bound to be tracked to someone with deep enough pockets to sue. Consider that you just spend a few millions on training a model on copyrighted data. Release it would reveal that, problem. I _guess_ you can try doing training in the public, like Seti @ Home or something like that, which distributes the risk? But no idea if this is even possible in this context. reply 127361 11 minutes agorootparentBut if we have 100,000 people with RTX 4090s mining some new AI based cryptocurrency, that happens to train the model in the process, it's going to be a highly effective system. reply vlovich123 2 hours agorootparentprevIs the training cost equally that high if you do adversarial training? reply shkkmo 2 hours agorootparentprev> There's plenty of FOSS software basically designed to violate copyright law (comic readers, home media center servers/clients, torrent clients) The key difference is that those projects don't violate copyright themselves, but facilitate users doing so. If training without a license is infringement then projects that are doing so will struggle to host code/models publicly or access other parts of internet infrastructure. reply lannisterstark 41 minutes agorootparent>struggle to host code/models publicly or access other parts of internet infrastructure. To be fair, IPFS/Torrents/Usenet exists. reply gfodor 1 hour agoparentprevThe US maintaining its lead is a national security issue. Larry Summers is now on the board of OpenAI. The copyright holders are not going to win, or they are, the training will continue anyway, but the technology will be (for now) kept in the hands of the military and IC. reply mrtksn 2 hours agoparentprevWe have infinite data, a microphone and a camera can generate huge amount of it and the public domain literature is wast. Billions of people learn like that everyday. reply zarzavat 43 minutes agorootparentIt’s impossible to learn any technical topic from 70+ year old books. The public domain is small and basically zero if you want to learn anything current. A microphone and camera is fine for learning about daily life, but you cannot get “book smarts” without copyrighted media. reply cousin_it 27 minutes agorootparentIf you wanted to train a bomb making AI on the most up-to-date physics textbooks in existence, that'd be what, a few hundred bucks in textbooks? Doesn't look like any kind of barrier to me. reply kolinko 2 hours agoparentprevDepends on what you want to use AI for - for a smarter AI we could probably do with the open source material, but better training techniques and some innovative breakthroughs in the model. Also, an interesting side note is that certain countries may actually want their language corpus involved in training AI - so they may have copyrights that are more AI friendly. I imagine Poland or Czech Republic wanting as much as their data to be involved in training LLMs because it gives their cultures more exposure. Even more so with African countries. reply torginus 2 hours agoparentprevmy question is - if it's deemed illegal to train AI using proprietary data sets, what's to stop companies from using their already existing LLMs to generate training data? reply kolinko 1 hour agorootparentThe fear is that you won’t get better model from training on synthetic data from a worse model, and you will miss a lot of modern day knowledge. Imho the first is not necessarily so, but the second will be a real hindrance. You can talk about the pandemic with LLMs because they were trained on people’s comments on the subject, but if we had training limits you wouldn’t be able to do so. Otoh with many cases a sufficiently smart AI can just reach out to the open source material - e.g. if you want to know about modern day politics of Europe, you can read reports of commissions, and if you want info on a new framework/tech, you can just read source code or scientific papers reply DiscourseFan 1 hour agoparentprev>\"big companies are stealing data owned by small businesses and individuals.\" I mean, they are. Unfortunately, AI at this point in time (LLMs, Midjourney, etc.) do appear to be not much more than highly technical and complex forms of intellectual property theft, which are given the futuristic name of \"AI\" to cover what they are actually doing. That isn't to say that they are entirely performing intellectual property theft; the models themselves are very fascinating in how they function, especially as sort of \"extra-rational\" entities that clearly have a logic, though not one we can fully understand. But the sort of philosophical, metaphysical, technological side of LLMs and Midjourney are clearly not being explored by OpenAI in a responsible manner, otherwise they wouldn't have just straight up stolen, seemingly, NYT articles. It's just another example of Silicon Valley VCs using a wonderful technology solely for exploitative profits, just like how google search became a surveillance tool (and plenty of other examples to go along with that). Its only right that we acknowledge the work of the human beings (all the art, writing, etc.) that went into the creation of the model, instead of pretending that there is some totally non-human machine intellect that is going to take over the world through its vast intelligence and negate all human action and all human work etc. etc. That is just a fantasy generated by wealthy Silicon Valley VCs as justification to themselves and those working under them, and those they are stealing from, to cover precisely that work that they would rather avoid paying for. reply roenxi 3 hours agoprevThere are many types of safety. For example, protecting your profits! I'd imagine that if we trace the money back these organisations will look a lot like lobbyists for existing companies in the AI space. I recall Microsoft's licence enforcement effort was done with that sort of scheme, I think they used the BSA [0]. It has been a while though so maybe it was a different group. Anyway, point being, if they can lobby for something unpopular under a different brand, that is how to do it. Much less PR risk. [0] https://en.wikipedia.org/wiki/Software_Alliance reply cherryteastain 13 minutes agoprevGovernment knows that random people having the ability to use \"AI\" without their control and oversight reduces their ever expanding reach. As the article demonstrates, the groundwork is already being laid by these \"think tanks\" to prevent a repeat of Llama 2. We truly need an AI Stallman. FOSS AI models need to become a movement, like the push for a FOSS UNIX became in the 80s and 90s. Sadly when I wrote to Stallman on the subject he seemed disinterested/defeatist, and mostly dismissed the idea of a GPL for model weights. Looks like millennials/gen Z must become more interested in these matters ourselves, however we seem to be disinterested in politics and even more disinterested in how the devices we use daily _actually_ work than Gen X. reply whywhywhywhy 5 minutes agoprevIt’s extremely messed up and vindictive to try and turn people into criminals for your agenda or just for profit in a lot of cases. Psycho behavior reply kevingadd 0 minutes agoparentYou're ultimately condemning the concept of intellectual property as it exists in the west today. Are you wrong? Probably not, but this is not unique to AI. People have been going to prison for 'IP theft' for decades. reply hsuduebc2 30 minutes agoprevThe ban of nuclear power plants is good example how regulation is working in the end. As almost everything this is double edged sword. From regulations this early everyone except us would profit. It is like regulate car's from going faster than horses in eighteen hundreds. reply RamblingCTO 1 hour agoprevWho are these people and where do they get their funding from? Feels like sock-puppets of sama or something? Is there any insight into that? reply jeanloolz 24 minutes agoparentThinking the same thing. I mean who would benefit the most from making open source models illegal? Sure looks like a lot like regulatory capture to me. reply 127361 26 minutes agoparentprevThe usual unelected control freaks, that try to police everything in life, from sex to drugs to what food you can eat. Every time a new technology comes out they start a moral panic over fears of safety or harm (\"think of the children\"). These morality police play on peoples' fears to increase their power and control. reply junon 15 minutes agoprevSo they're the PETA of AI. It was bound to happen, AI stuff seems to strike a very emotional chord in some people. reply janalsncm 2 hours agoprevIt’s kind of funny to me that these organizations are naming FLOP thresholds and crowning MMLU as the relevant evaluation metric. Seems that several of them have copy-pasted similar thresholds. As compute becomes cheaper, these thresholds will become cheaper and cheaper. Perhaps we will look back on them as quaint and nearsighted. reply kolinko 1 hour agoparentWell, FLOP make sense, kind of - you can make computing as cheap as you want, but without algorithmic improvements the FLOP count will stay the same. And algorithmic improvements will probably be discrete - happening once in a while, not continuous. There is also a mathematical limit to how efficient we can make the training - we don’t know the limit yet, but there is a point below which we won’t get. reply 127361 31 minutes agoprevI guess distributed training BitTorrent style over the darknet will be the workaround for this? Also the forbidden nature of illicit AI might drive demand for it. Especially if it's really good. We're seeing the same thing as the War on Drugs, and the state will never succeed at stamping it out. In fact it might even end up encouraging it. reply 65a 3 hours agoprevNever underestimate the desire of existing systems of control or power to self-propagate. reply RishabhKharyal 3 hours agoprev1. Licensing of data will be huge bottleneck 2. Uncensored results will be used against opensource models questions hovering in dark or grey area 3. Limited compute compared to big corp and model size gap 7B for opensource and closed source would be magnitude bigger reply lannisterstark 22 minutes agoparent> Licensing of data will be huge bottleneck Will it? At some point it'll be equally (or close to) cheaper as me just building my own *arr stack instead of subscribing to 5 different $20 streaming sites. >Uncensored results will be used against opensource models questions hovering in dark or grey area Will they care though? You can use whatever you want against me for pirating x, I'm still doing it. ---- >Limited compute THAT. That is the point we want to make. For FOSS projects, compute is the single biggest hurdle. Everything else we can make do. reply 6R1M0R4CL3 17 minutes agoprevof course they do, that's what they want. control. all those companies that call for laws being written about AI what they want is those laws to be written AS THEY WANT THEM TO BE. they go see the governments, spray a nice amount of FUD and EXPLAIN to them what to do, how to do it because they know how to avoid the danger and risk for the whole human race... you can bet they will make those laws be a very nice fit to what they want to reign supreme and make sure any competition is eliminated. reply PeterStuer 2 hours agoprevI'm sure there are many well meaning ai safety researchers, but I also see a lott of \"ai for me but not for thee' moat digging safety hypocrisy. reply war321 1 hour agoprevWish this wasn't as common as it turned out to be sadly. Best thing to hope for is that the ability to train models continue to get cheaper and more accessible over time. Figuring out how to go from tens/hundreds of millions of images needed for a foundation model to thousands or hundreds would be a start. reply hoseja 38 minutes agoprevIs the left banner just random or does it encode a message? reply anothernewdude 1 hour agoprevThis won't protect jobs, it'll just make sure the profits from automating those jobs will go to those who can own the private AI models reply google234123 3 hours agoprevI’m curious if the board of Anthropic AI will eventually try and kill the company because if I’m not mistaken many of the members share this mindset reply rootsudo 2 hours agoprevWhy would we care about these \"AI Safety Orgs?\" As a developer, do I need their certification or is it like a MADD situation where we if we don't observe and diminish their appeal/growth we will get laws with draconian measures that only benefit the big players? e.g. a PAC? (Don't get me wrong, drunk driving is \"bad\", but for a group like MADD to exist, eh and meh.) As of now, there is no need to really submit these these safety orgs, so as long as we don't care for their approval - who cares, right? Or is the optics far gone now that these orgs control the conversation? Also, fun question: with AI safety orgs now attempting to police - who really polices the police / do other orgs/countries have the same rules, safety and artificial guard rails? reply lmeyerov 2 hours agoparentMADD on one end that limit work at all, and SOC2/ISO/NIST style compliance limitations on the other that chill work in practice. I'm more worried about the latter as already starting to bias project & funding decisions in fintechs & various govs we work with. Both a concrete practical concern today, and economics & law are generally tied in theory anyways. reply gryn 21 minutes agoparentprevthe fear is that they delusions become law. Sam Altman already tried that last year. look at how technically competent your average politician / congressman / law maker and extrapolate how easy it is to make them think that if they don't ban unlicensed use of AI great danger is ahead. the rule will be in favor of already existing large companies like OpenAI, google, Microsoft, etc ... if you're an open source contributor to AI you will be vilified as some nefarious hacker who's trying to destroy the world. they are using all kind of tactics until they find the one that sticks (and eventually they will), anthropomorphize AI when talking about it, fearmongering about some rogue super AI, war scenarios about AI falling in the hands of 'china', analogies with weapons of mass destruction, think about the children style rhetorics, it will take your jobs, suddenly caring about copyright, etc... reply tehjoker 3 hours agoprevstandard capitalist play to set up a moat by instilling fear reply hsuduebc2 41 minutes agoparentYou mean exactly like these pro-regulation organizations are doing? reply gdfgsdf 2 hours agoparentprev> Many AI safety orgs have tried to __criminalize__ currently-existing open-source AI standard socialist play to use the government's hand to achieve their own objectives reply pmontra 2 hours agorootparentDon't everybody use the government to do what they want? It's kind of the definition of government, in any country and in any political system. reply breadbreadbread 2 hours agoprev [–] Ah yes the old \"banning things=bad\" argument that doesn't offer alternatives to fixing the issues with AI. Just ignore the issues with environmental impact, plagiarism, CP and other non-consensual shit in the data sets, scamming capabilities! All the groups asking for regulation here have **funding** and that means they are evil but we are good for using this tool that is massively subsidized by megacorps that have a vested interest in this market. reply bluescrn 17 minutes agoparent'It's scary, ban it!' isn't a great argument either. Especially when 'safety' has such a blurred definition, we could be talking about anything from the threat of global apocalypse to to the 'threat' of an AI merely being able to answer questions about 'wrong' political opinions. Skynet isn't going to happen. The biggest threat from AI is taking jobs away and creating poverty while redirecting more wealth to the super-rich. In the short term, we're likely to be facing a lot more convincing spam/bots and deepfakery in the run up to the election - but is that the fault of the AI, or the fault of the humans directly operating their new toys/tools? reply alpaca128 15 minutes agoparentprevBanning AI is simply useless. It's a technology that anyone with sufficient processing power and access to the internet can use, so trying to ban it is guaranteed to fail just like prohibiting alcohol would be. The only thing we can do is limit how megacorps can openly abuse the technology. reply hsuduebc2 42 minutes agoparentprevIt's just plainly retarded steering from progress. Only one who would profit from it would be a nations who wouldn't give a flying fuck about your ban. Exactly like with nuclear energy. reply mirekrusin 1 hour agoparentprevLess harmful would be to ban large models from being not open. If you ban open large models in US, you'll cripple US and make few megacorps very rich, very quickly. You'll drain talent to other (also competing) states. Truly bad actors won't be affected, if anything they'll get advantage. People draw weird analogies equating llama2 to nuclear device etc. nonsense but the closer analogy would be to ban on semiconductors of certain efficiency for US itself. Similar idiotic argument as for banning cryptography. reply gryn 6 minutes agorootparentI agree, but if there's enough political will (ie these orgs convince a large enough subset of the right people) the US can bully other nations to implement similar policities like it has done many times in the past. once you understand that what they are trying to protect is the safety of their profits every of their argument start to make sense. reply tomalbrc 2 hours agoparentprev [–] Seeing the lack of responses to your comment and downvotes, you couldn't be more right reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AI safety organizations are calling for the banning or restriction of open-source AI models based on specific criteria like computational resources, parameter count, or benchmark performance.",
      "These proposed bans aim to enhance AI safety, but critics argue that they would hinder research and development in the field.",
      "The open-source AI movement needs to improve coordination and counter these anti-open source initiatives to safeguard the future of open-source AI."
    ],
    "commentSummary": [
      "The passage covers the development and regulation of artificial intelligence (AI) and the various concerns surrounding it.",
      "There is debate over the criminalization of open-source AI, banning AI beyond a certain capability level, and the burden of proof for AI safety risks.",
      "The discussion explores the risks and benefits of AI, challenges in modeling superintelligence, potential manipulation of political processes, and the uncertain existence of AGI."
    ],
    "points": 176,
    "commentCount": 115,
    "retryCount": 0,
    "time": 1705382258
  },
  {
    "id": 38999517,
    "title": "The World's Richest Double Their Wealth as Poorest Struggle, Oxfam Report Shows",
    "originLink": "https://www.theguardian.com/inequality/2024/jan/15/worlds-five-richest-men-double-their-money-as-poorest-get-poorer",
    "originBody": "Demonstrators in Davos on Sunday. A wealth tax of 1% to 2% on wealth above £10m could bring in £22bn a year for the UK. Photograph: Denis Balibouse/Reuters Inequality World’s five richest men double their money as poorest get poorer Oxfam predicts first trillionaire within a decade, with gap between rich and poor likely to increase Rupert Neate Wealth correspondent @RupertNeate Sun 14 Jan 2024 19.01 EST The world’s five richest men have more than doubled their fortunes to $869bn (£681.5bn) since 2020, while the world’s poorest 60% – almost 5 billion people – have lost money. The details come in a report by Oxfam as the world’s richest people gather from Monday in Davos, Switzerland, for the annual World Economic Forum meeting of political leaders, corporate executives and the super-rich. The yawning gap between rich and poor is likely to increase, the report says, and will lead to the world crowning its first trillionaire within a decade. At the same time, it warns, if current trends continue, world poverty will not be eradicated for another 229 years. Highlighting a dramatic increase in inequality since the Covid pandemic, Oxfam said the world’s billionaires were $3.3tn (£2.6tn) richer than in 2020, and their wealth had grown three times faster than the rate of inflation. The report, Inequality Inc., finds that seven out of 10 of the world’s biggest corporations have a billionaire as CEO or principal shareholder, despite stagnation in living standards for millions of workers around the world. Will Elon Musk be the world’s first trillionaire? Photograph: Reuters Compiled using data from the research company Wealth X and Forbes, it says the combined wealth of the top five richest people in the world – Elon Musk, Bernard Arnault, Jeff Bezos, Larry Ellison and Mark Zuckerberg – have increased by $464bn, or 114%. Over the same period, the total wealth of the poorest 4.77 billion people – making up 60% of the world population – has declined by 0.2% in real terms. “People worldwide are working harder and longer hours, often for poverty wages in precarious and unsafe jobs,” the report says. “Across 52 countries, average real wages of nearly 800 million workers have fallen. These workers have lost a combined $1.5tn over the last two years, equivalent to 25 days of lost wages for each worker.” Mirroring the fortunes of the super rich, it also says business profits have risen sharply despite pressure on households amid the cost of living crisis. It finds 148 of the world’s biggest corporations together raked in $1.8tn in total net profits in the year to June 2023, a 52% jump compared with average net profits in 2018-21. Calling for a wealth tax to redress the balance between workers and super-rich company bosses and owners, the report says such a levy on British millionaires and billionaires could bring in £22bn for the exchequer each year, if applied at a rate of between 1% to 2% on net wealth above £10m. Julia Davies, an investor and founding member of Patriotic Millionaires UK, a nonpartisan group of British millionaires campaigning for a wealth tax, said levies on wealth were “minuscule” compared with taxation on income from work. “Just imagine what £22bn a year invested in public services and infrastructure could pay for; improving the lives of every one of us who live in the UK and providing our elderly, young and vulnerable with the care and support they need and deserve,” she said. skip past newsletter promotion Sign up to Business Today Free daily newsletter Get set for the working day – we'll point you to all the business news and analysis you need every morning Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion Oxfam said the most recent Gini index – which measures inequality – found that global income inequality was now comparable with that of South Africa, the country with the highest inequality in the world. The world’s richest 1% own 59% of all global financial assets – including stocks, shares and bonds, plus stakes in privately held business. In the UK, the richest 1% own 36.5% of all financial assets, with a value of £1.8tn. Aleema Shivji, Oxfam’s interim chief executive, said: “These extremes cannot be accepted as the new norm, the world can’t afford another decade of division. Extreme poverty in the poorest countries is still higher than it was pre-pandemic, yet a small number of super-rich men are racing to become the world’s first trillionaire within the next 10 years. “This ever-widening gulf between the rich and the rest isn’t accidental, nor is it inevitable. Governments worldwide are making deliberate political choices that enable and encourage this distorted concentration of wealth, while hundreds of millions of people live in poverty. A fairer economy is possible, one that works for us all. What’s needed are concerted policies that deliver fairer taxation and support for everyone, not just the privileged.” Explore more on these topics Inequality Davos 2024 Oxfam The super-rich Poverty Tax and spending Rich lists news Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=38999517",
    "commentBody": "[flagged] Five richest men double their money as poorest get poorer (theguardian.com)172 points by ciconia 22 hours agohidepastfavorite329 comments d--b 21 hours agoSomeone should introduce an economical concept equivalent to escape velocity in physics. If you throw an object towards space from Earth, it will always fall back to Earth, unless you throw it with enough speed (IIRC something close to 11km/s), with which it will eventually \"escape\" Earth's gravity. I have a feeling that money follow the same rule: If you have some money but below a certain level, and don't do anything, that amount of money will be eaten by you, taxes, and inflation. But if you have enough money, current rates mean that taxes & inflation will erode your capital slower than the interest you'll earn from that capital alone, and so money is inevitably growing on itself. As a society, we should prevent \"escape capital\" to be a thing. I totally fail to understand why this is a polarizing issue as 99.5% of people are on the same side of the threshold... reply dgb23 20 hours agoparentWhat you describe has something to do with this: Being poor is expensive. Everyone who struggled financially at some point in their time intuitively knows how much harder it is to make (and keep) money if you're poor. Saving your first 10 bucks is _way_ harder than saving your first 100 bucks so to speak. And this is even more true if you're losing money / are behind. Paying off a dollar of debt is monumentally harder than saving a dollar. And it is much more taxing and stressful to boot. If you don't pay off that dollar, someone (perhaps the police even) will come knocking. This is one of the reasons why I believe a society should collectively provide the basics (like a family does) for everyone as long as that's possible. Even completely ignoring the ethical concerns. We would progress much faster if nobody had to worry about fundamental issues like shelter, food, basic transportation, education and so on. Imagine all the Einsteins and Picassos we are missing out on, because they struggle to pay their rent and can't afford education. Even ignoring the geniuses, think of all the little compounding things that would happen. All the craftspeople who don't have time to tinker. All the nurses who don't have time (and energy) for bedside manners etc. A lot of things we produce (and put a lot of energy into) would be less necessary, because they didn't have to fight the symptoms of a broken system. reply jareklupinski 19 hours agorootparent> if nobody had to worry about fundamental issues like shelter, food, basic transportation, education and so on unfortunately, the people who are able to make this a reality tomorrow also hold to a strange viewpoint: they truly believe that, in the absence of some pressure, a person who has their basic needs provided will ultimately venture to do nothing completely failing to see the greatest irony of their belief, that even doing nothing would arguably be a better life than the debt-ridden existence you mentioned... reply dgb23 19 hours agorootparentThis viewpoint existed (to a more extreme degree) in the 18th and 19th century too. \"If we give everyone the vote then...\", \"If workers have protections then...\", \"If women had equal rights then...\" etc. It's interesting how stubbornly this false and negative image of humanity has persisted even though every time we made progress the opposite was found to be true. Yes, we are lazy, greedy and dumb. But we are also disciplined, helpful and smart to a much higher degree. Not because someone holds a whip, but because we just want to. We should maybe stop optimizing society to cater to the few people (or circumstances) where this isn't the case. reply keester 3 hours agorootparentOf course not everyone gets the vote. Not everyone gets the worker protections or can be women with equal rights, as you put it. The issue here is not if we should provide these things but actually to provide them to as many people as possible. Sadly, people think we can just agree to do it or something and it magically happens. My take is move slowly. Anyone who doesn't food and housing, try to make that happen for them as best we can. That's different than just decreeing from on high that ALL PEOPLE SHALL HAVE HOUSING!! reply scruple 18 hours agorootparentprev> they truly believe that, in the absence of some pressure, a person who has their basic needs provided will ultimately venture to do nothing. They might venture to not work for the 5 richest men for starters. And we just can't have that happening now, can we? reply deepfriedchokes 15 hours agorootparentprevA little bit of suffering drives growth, too much and things start to decline. If you go work out at the gym your muscles will grow, but if you fatigue them to an extreme you’ll get rhabdo and they’ll start to break down. We’re at a point where the majority of humanity is struggling with cost of living while others live in excess at their expense. This will cause species level decline if we don’t fix it. Capitalism is abusive and exploitative; it abuses people and the environment to feed itself. It is a vampire. If humanity is going to survive we need to start acknowledging Capitalism for what it is: abuse! reply jareklupinski 9 hours agorootparent> A little bit of suffering drives growth i think if we hope to finally achieve our species' true might and leave biology behind, we have to question whether this too may be a fallacy thermodynamics has the rest of the universe; maybe we can squeeze out of it? reply MyFirstSass 21 hours agoparentprevThis is a true observation, a part of it also comes from the threshold where you can afford a team of personal financial advisors and some lawyers for wealth management. The masses have to pay taxes but i've met plenty of wealthy people that reach this \"escape velocity\" when they can afford people to setup intricate schemes to absolutely minimise taxes, then their money become almost autonomous as other people are constantly working on increasing their small cut of it while you are doing very little. So while most countries have some progressive tax system on the surface, this only penalises \"new money\", the middle classes and the naive or inexperienced founders - the really rich pay less than everyone else, so there is in effect a regressive tax system globally favouring old money or people well connected to the law and financial complexes. A good example of these gates to the upper classes, at least in EU, is from a fundamental level like early tax brackets, because if any regular person \"hits it big\" in some way, a lot of the money will disappear into taxes and bureaucratic mazes, favouring the workers who average out their pay over many years staying in lower brackets or rich people who'd just put the money into a company or fund. So the \"system\" really doesn't like people entering the upper echelons and will do everything to siphon your money before this escape velocity. reply jampekka 21 hours agorootparentWealth taxes used to be quite common before the wealthy figured out how to use powerful propaganda frameworks like neoclassical economics and neoliberal ideology to make sure they keep getting even wealthier and more powerful. reply MyFirstSass 20 hours agorootparentTrue and quite ironic. The financial elite gets the mercantile middle classes hit the hardest by their bell curve tax system to rally for their own tax exemptions and deregulation also making these ideologies easy to spread in bourgeois or even petite bourgeois society while they'll never really reap the benefits. Also reading the history about the advent and transformation of neoclassical economics it seems it was exactly that, a well thought out scheme to dupe the middle and lower classes to accept a system never really intended to favour them. Classical liberalism seems almost left wing in this context, and that is not weird when realising this was a project thought by a nexus of plutocrats like Rockefeller in combination with the dawning sciences of propaganda and control of the dangerous masses that could become enamoured with socialism. A new ideology had to be spread and so the intelligentsia of the day met up very openly to discuss rebranding various older unnamable ideologies for the masses to steer them from collective power or true autonomy. It sounds very conspiratorial like this if it wasn't right there in history in the culture around Edward Bernais, american oligarchs or italian fascists talking about the need for \"A new liberalism\" in the 1920's and masses that could be \"moulded\" with ideology or phantasms created top down. reply jampekka 21 hours agoparentprevSomething like \"concentration of capital\" that was extensively analyzed by a certain relatively influential German-born economist in the 19th century? I too fail to understand why it's so polarizing for the 99.5% not benefitting from it. reply SeanLuke 20 hours agorootparentConcentration of capital isn't polarizing, it's a perfectly cromulent criticism. What's polarizing was the promotion of an economic/politcal system which to date has had a perfect record of turning into a totalitarian dictatorship. reply jampekka 20 hours agorootparentOr something like a welfare state. Most western European countries have implemented roughly all Demands of the Communist Party in Germany, although some of these have been rolled back in the neoliberal era. https://www.marxists.org/archive/marx/works/1848/03/24.htm reply DonsDiscountGas 20 hours agorootparentThe countries with the most comprehensive welfare states all have capitalist economies. Since communism destroys wealth (and lives) rather than create any, there doesn't end up being a lot to spread around. reply xorcist 10 hours agorootparentYet they seem to be doing fine? reply jampekka 20 hours agorootparentprevSoviet Union (Marxism-Leninism) created a lot of wealth. I don't think it's a good implementation of socialism but your claim that \"communism destroys wealth (and lives) rather than create\" is just plain false. https://www.jstor.org/stable/45311779 reply rickydroll 14 hours agorootparentprevMost descriptions of the evils of communism usually describe Fascism. As we all know, fascism destroys wealth and lives, except for the oligarchs that manage to float to the top. reply jampekka 13 hours agorootparentFascism is quite a vague concept (as is communism), but I think you're right that the \"exclusive collectionism\" (exclusive to e.g. nationality or ethnicity) and extreme hierarchies (e.g. the fuhrer-principle) are close to what the Cold War propaganda attributes to socialism. And as we know, fascism is capitalism in decay. reply rickydroll 11 hours agorootparenthttps://web.archive.org/web/20170131155837/http://www.nybook... Umberto Eco wrote my goto definition of fascism. hope you find it interesting. Socialism is one of those heavily mis-defined/used words. I tend to stick to the economic definition. As in \"A socialist economic system is characterized by social ownership and operation of the means of production that may take the form of autonomous cooperatives or direct public ownership wherein production is carried out directly for use rather than for profit.\" (quote from Wikipedia socialist economics). one of the downsides of discussions about socialism is inevitably someone starts using long convoluted sentences like the above. Socialism as political definitions have been merged and smashed together with communism and fascism in Nazism and conservatism etc. etc. reply slibhb 20 hours agorootparentprevIn Marx's model, inequality indeed increases. But so does absolute poverty. Marx predicted a future in which a tiny handful of people own everything and subject their workers to slave-like conditions. The latter part hasn't happened; working conditions have improved dramatically over the past few centuries. The middle class, which most Americans are part of, is not something we see in Marx. There's a fundamental lesson here that Marxists still don't seem to understand: an economy can have lots of inequality and very little poverty and, while not perfect, this is a good place to be. > I too fail to understand why it's so polarizing for the 99.5% not benefitting from it. Normal people see a rich guy and think \"good for him, he worked hard, is smart and lucky\" not \"he isn't any better than me, it's unfair that he has more than me\". For some reason Marxists think the second thought is admirable. reply jampekka 18 hours agorootparentMarx didn't really predict the slave-like conditions. He (and especially Engels) described the conditions that were created in industrialized countries (especially UK) by capitalism. The marxist analysis had a major effect to how capitalism was reigned in to make the working conditions and living standards better. In the 20th century almost all European countries had major socialist and communist parties, often in power, and enacted major socialist policies. E.g. almost all concrete policy demands of Marx and Engels[1] have been implemented in most (western) countries and most of them are nowadays taken for granted. Marxism has very little to do with envy you described. The luxuries aren't really a problem. The problem is the economic (and political) power of concentrations of capital whose interest it is to make working conditions worse. You're attacking a strawman, and most likely against your own interests. [1] https://www.marxists.org/archive/marx/works/1848/03/24.htm reply slibhb 18 hours agorootparentMy summary of Marx is accurate. In his view, working conditions and pay would get monotonically worse. That objectively has not happened. reply jampekka 17 hours agorootparentIf it's this clear, I'm sure you can give a quote? Marx was clear that capitalism produces booms and busts, which implies non-monotonic development. He did predict that, when left on its own devices, capitalism will in the long term collapse on itself due to the tendency of the rate of profit to fall. Collapses where huge governmental intervention in economy is needed happen quite consistently. E.g. in the USA the market mechanism collapsed in 1893, 1929 and 2008. And it is arguably still on central banks' life support. What Marx and revolutionary marxism was maybe a bit too sceptical of was sustainability of social democratic states, known also as mixed economies. Altough it does seem that most mixed economies (e.g. the nordic countries) are regressing towards more capitalist domination. Capitalism and socialism aren't some specific systems and no country is 100% either. Even USSR didn't say in its dogma that it has achieved full socialism, let alone communism. reply secstate 17 hours agorootparentprevLargely because most modern capitalist societies have at least half-implemented many of things Marx proposed. We don't live in a world where we can know whether Western European capitalism of the industrial revolution proceeded monotonically and so have not basis for objectivity for a conclusion that Marx was wrong. reply slibhb 16 hours agorootparentImproving working conditions and wages clearly prove that Marx was wrong. It is ironic that, in some cases, Marxist arguments led to changes that disproved Marx's teachings. reply thiagoharry 5 hours agorootparentSorry, there is nothing in Marx's writting that says that working conditions cannot improve. I recall that in one of Das Capital's chapter in the first volume he tried several models of how capitalism could evolve. One of them expected that workers could get better wages... just so that they could consume more goods produced, but never owning the means of production or controlling the society and the power. reply morbicer 18 hours agorootparentprevI absolutely don't want to defend communism, I lived in Eastern Bloc and I prefer the flawed capitalism we have now. But you are not really correct. > The latter part hasn't happened It's true that Bezos doesn't own the whole USA but 3 men has more wealth than 150 million people. https://www.forbes.com/sites/noahkirsch/2017/11/09/the-3-ric... And the working conditions in Amazon warehouses are horrible. Workers in 50s or 70s had definitely better conditions and purchasing power. Despite all efficiency improvements, purchasing power of US workers is stagnating since 70s https://www.pewresearch.org/short-reads/2018/08/07/for-most-... The conditions improved because of Marx's teaching, without worker actions nothing would improve, it didn't happen out of capital owners' voluntary decision. It happened because of strikes and many were violently supressed. Just a few in USA: https://www.history.com/news/strikes-labor-movement > Normal people see a rich guy and think \"good for him, he worked hard, is smart and lucky\" Normal people are often hardworking (much more than capital owners) and sometimes smart as well. However to get rich, you must be lucky (usually you get born into wealth). Sometimes you need to be lucky just to get out of poverty. I think majority doesn't care that their doctor is kinda rich and can go heli-skiing. They are angry that someone is so rich they can't even spend the money while his workers are struggling. https://mkorostoff.github.io/1-pixel-wealth/ https://nypost.com/2019/07/13/inside-the-hellish-workday-of-... It's not normal or beneficial for society that 3 men has more wealth than 150 million of people. reply slibhb 18 hours agorootparentWorking conditions get better and worse over time according to politics and economics. Marx predicted that they only get worse. Conditions were in some ways better in the 50s. They are in some ways better today than in the 50s. And they're way better today than in Marx's lifetime. But my point is that there's no reason the pendulum can't swing back without the overthrow of capitalism, and that is contrary to Marx's teachings. Therefore it's true and ironic that Marxists played a role in improving working conditions. In terms of class resentment, I think you're wrong. It's mostly upper-middle class people who hate the \"ultra rich\". And there's nothing unnatural about extreme inequality, though it's not desirable in every way. reply Gareth321 20 hours agorootparentprevBecause he also prescribed violently overthrowing democracy. He had some great ideas, and some truly ridiculous ideas. I can appreciate his inspired insights about capitalism, but I reject his deification. It's easy to criticise an operational system. It's much, much harder to prescribe and implement workable solutions, and I think that's where Marx failed. \"Tear it all down and make everything awesome\" is just silly. Based on his works, dozens of countries have tried, or are currently trying, to implement communism. More than 100 million people have died as a result. It's time to accept reality: his prescription doesn't work. We know capitalism is flawed. That doesn't mean we should tear it down. So far it is our least bad social and economic structure. reply Gud 19 hours agorootparentKarl Marx didn't prescribe \"violently overthrowing democracy\". He predicted(correctly, in my opinion) that the current ruling elite would not give up their power over the institutions peacefully, thus violent revolution is a requirement to implement the communist system. reply xyzzy123 21 hours agoparentprevPiketty's r > g is pretty close to a coherent argument that capital accumulation has an \"escape velocity\". It's a political topic, so, vehemently contested. reply dgb23 20 hours agorootparentI've yet to read that book, I've heard a lot of good things about it. The above comment is referring to: https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Ce... reply fendy3002 21 hours agoparentprevBecause of combined factors: people as a collective are stupid, elected lawmakers and political parties are incentived to keep the status quo, and you only need 50%+1, or less to be elected in democracy. The wealthiest only need to cater to politicians, then keeping 49% people slightly above the pull force even less, and it'll keep the condition like it is. But still there's no better governments than democracy right now. reply memen 19 hours agorootparentIf your country is ruled by the 51% majority, do you have a democracy or a totalitarian state ruled by a majority? reply darkerside 21 hours agorootparentprevWay less than 50% considering not everyone votes. reply huijzer 21 hours agoparentprevI suspect many people are also lured into increasing this escape velocity by keeping up with the Joneses together with easy debt. It’s much easier to get rich if your assets earn, say, 10% (average index return) instead of losing 10% annually via the credit card interest over “assets” that you don’t own. Especially consumer electronics and cars are surprisingly bad “assets” if you do the math. New phones lose about 20% of value per year. So if you combine that with credit card interest, the return on investment is spectacularly bad. reply DonsDiscountGas 20 hours agoparentprev> eaten by you, taxes, and inflation Taxes and inflation one can measure (reasonably) objectively, but personal spending is always going to vary wildly. Say one gets 10% in the stock market over the long term, let's say inflation is 4% so that's 6% after inflation, and say 4% after taxes[0]. Median personal income is $40k, and median family income is $75k (2022 dollars). That means an individual would need $1M in savings, and a family would need $1.875M. Which is a fair bit of money, and anybody who accumulates it will probably be accustomed to a higher-than-median lifestyle. >As a society, we should prevent \"escape capital\" to be a thing. No, we shouldn't, because in normal language this is called \"retirement\". Somebody who has saved enough to retire has reached \"escape capital\", and this is something we should be trying to encourage more broadly. As you say this is out of reach for most, so what we should be trying to do is get more people to reach this threshold, not less. Many have suggested a wealth tax; I'm personally in favor but I think it's unconstitutional (in the US)[2]. [0] If one is funding their lifestyle they would need to sell stock/collect dividends, which would be taxable. [1] https://www.census.gov/quickfacts/fact/table/US/SEX255222 [2] I am not a lawyer or constitutional law expert. Although I'd be willing to bet that the current SCOTUS would find it unconstitutional. reply d--b 20 hours agorootparentNo escape capital has nothing to do with retirement. Retirement is: you set aside as much as you think you need between the time you stop working and the time you die. Escape capital is: the amount of money necessary so that interests >> what you consume reply infecto 21 hours agoparentprevIts an interesting idea and neat way to perhaps explain it but I think it misses out the important part. People don't do a good job preparing for their future. You mentioned it but I think emphasis should be put on the person, thats where most of the money is going, not inflation or taxes. The last two certainly play a role but no where near as much as the person spending the money. Maybe I look at history with rose tinted glasses but my experience tells me people are spending more and more money. We are a consumer society on steroids. I see so many individuals driving around in $60k cars, living in massive homes, buying tons of junk on Amazon. I wonder if that has more to do with it. As for preventing escape capital. The issue is, I am not sure how you do it. It is easy to had wave and say a tax but I believe its very hard to create new rules without unintended consequences. I am not opposed to the idea but I am not sure what other consequences will be felt. reply lock-the-spock 21 hours agorootparentWhile true to some degree that people don't prepare sufficiently, many simply cannot prepare. Taking aside the U.S. which bankrupts hundreds of thousands a year through an insane health care system (providing both highest cost and one of the lowest outcome on the quality side across the developed world), most people in most xountries have not much svsing possibilities to begin with. The best use of money is most often to invest in your housing, or your kids' education, not to mention food, regular healthcare, and basic amenities (1/10 of the world population can barely afford shoes or a toothbrush...). Where more wisdom could come in is for much of the lower and the increasingly nonexistant upper middle class. But this is a fraction of the population. If you want to tell a family with two adults working in lower wage jobs and two kids, and renting an apartment, to \"save\" there is usually not much margin, and their saving amounts to building up a small emergeny reserve which is eaten up by any family emergency or damage to car or housing. Little chance to save for old age .. reply infecto 20 hours agorootparentAgree. I think education is part of the answer, I don't know what the rest of the answer is unfortunately. I think its too easy to just point at the rich and blame them but I don't know if that is a productive solution. reply Damogran6 21 hours agorootparentprevThings getting more expensive over time is inflation, things getting bigger over time is the market responding to consumer desires...someone making so much money the interest eats the entire monitary supply is consumed is an extinction event. The mind isn't great at groking just how much money we're talking about here. The people making the money are a combination of things: Not doing it for the money, doing it to rack up a high score, doing other things while the money does it's thing. But the big takeaway is that money is effectively removed from the economy. When you can afford 200 100M yachts...you're not GOING TO BUY 200 100M yachts, so the yacht builders aren't going to use that money to further stimulate the economy. \"Hey man, I made a company that pays me $200B\" No, you didn't, you got in front of a money hose that shunted a crazy amount of money into your coffers due to gaming a market. You got lucky, and you can't DO anything with 99% of those funds, you just can't use it fast enough. reply johnnyanmac 18 hours agorootparentprev>Maybe I look at history with rose tinted glasses but my experience tells me people are spending more and more money. They are... On rent. And food (even the exact same food). And everything else. Wages haven't kept up with housing for some 30 years and we're seeing the consequences now. The housing crash didn't help either. Likewise, stuff got more expensive over the pandemic. Gas is triple the price now, streaming services is starting to approach cable prices once again, Dollar menu fast food isn't a thing anymore. The best coupons I could find is $4 for 2 burgers. And a typical combo can easily cost $15 by itself. $20k new cars aren't a thing anymore, and the used car market also inflated. The $3500 used Nissan with 140k miles bought in 2018 is seeing 9-10k on Craigslist. I'm seeing the opposite effect you are. People aren't going out anymore: they can't even afford a monthly bar crawl where what used to be weekly or multiple times a week outing. Much less traveling happening. People who used to live alone are rooming up again because rent keeps increasing. Spending power and QoL is going down. reply matsemann 21 hours agorootparentprevMe not buying avocado toast won't suddenly make me rich. reply infecto 21 hours agorootparentDefine rich. Not buying $10 slices of avocado toast daily and investing the money instead into an index fund will definitely create some wealth over time. reply matsemann 21 hours agorootparentI could do that a lifetime and still be about a billion away from a billion dollars. reply infecto 21 hours agorootparentWhats your point? It would help instead of being sarcastic to get to an idea. Thanks. reply alexwasserman 18 hours agorootparentHis point, I’m sure, is that the common criticism of the middle class wasting money on avocado toast is somehow stopping them saving that money and being super wealthy. But, in reality, that amount of money, while non-trivial (~$3500/year) over a lifetime (not counting inflation) saved is still a fraction of a running error on a billionaire’s wealth. Over 40 years at current 5% is As a society, we should prevent \"escape capital\" to be a thing. It should be impossible to survive from saved money? Wouldn't that mean that everybody has to work until they die? >I totally fail to understand why this is a polarizing issue as 99.5% of people are on the same side of the threshold... For me it's mostly the \"work until you die\" part. ;-) reply Armisael16 20 hours agorootparent“Your total money is decreasing” is not the same thing as “all your money is gone” - it’s leading in that direction, but if it takes 20 or 30 years to get there that’s usually enough for people to retire on. reply Kon5ole 17 hours agorootparent20-30 years of savings is a fortune already though, how do we make it so that all professions allow for such savings to be accumulated if we don't allow for interest rates or dividends? And if the 20-30 years isn't enough, do we re-employ 80-year olds that have been retired for 20-30 years? I'm nowhere near the mentioned 0.5% and still don't think this is a good idea. In fact I think society should do the opposite, \"escape velocity\" should be made attainable by more people, not fewer. If people can retire by 50 (instead of 70 or whatever it will be after another decade of this economy) more young people will get employed at better salaries, and 50 year olds can still come up with cool things do do with their lives. reply throwbadubadu 20 hours agorootparentprev> It should be impossible to survive from saved money? Wouldn't that mean that everybody has to work until they die? Come on, it depends on the duration, and it is long stretch from parent poster's thought to your \"cannot live of saved money\" for some time (though would claim, the states that have/had this guaranteed by the state had it more right anyway, basic survivability for retire time should not depend on savings in modern society, only luxury). I mean the opposite, what you seem to want, that you can live indefinitely off a certain amount of saved money, we all know cannot be similarly true for everybody? reply makomk 21 hours agoparentprevThis article does not provide any actual evidence for that idea though. In particular, the richest person in the world - and I think possibly also the one whose wealth grew the most - wasn't even a billionaire until fairly recently, and the basic investment thesis that's made his companies so valuable is that they'll take a big share of the global car market, wrecking the income of existing car companies and destroying the wealth invested in them. Actually, I think all five of the people this article is about became billionaires in the last 30 years or so, displacing the previous richest people in the world as they did so. You've also got to remember that by focusing on the richest people in the world right now the article is effectively cherry-picking the people who've done the best in terms of wealth whilst ignoring those whose wealth has failed to grow so well. reply Eddy_Viscosity2 21 hours agorootparent> article is effectively cherry-picking the people who've done the best in terms of wealth Well yes, but that's the point of the article. The systems we have in place allow for, and ensure, insane wealth concentration in a few people. It doesn't matter who they are or if they change. reply JKCalhoun 21 hours agoparentprev> As a society, we should prevent \"escape capital\" to be a thing. Perhaps if you captured all of someone's wealth when they died, dole out maybe a $1M to each child/spouse. reply xyzzy123 21 hours agorootparentOr apply increasing \"drag\" as wealth accumulates, i.e, wealth taxes, maybe starting at a few bps once you have $100m. Throw in some social accolades / parades / public acclaim for people who pay the most taxes. reply riskycodes 21 hours agorootparentI have been considering the latter (accolades and/or naming things after tax-payers) as something that is severely under-utilised in most places. reply xenonite 21 hours agorootparentprevCharity yields higher appraisal, while reducing taxes. Though this has the benefit of letting better decide what is done with the money. reply Armisael16 20 hours agorootparentHistorically speaking the things the rich think are worth spending money on haven’t lined up with what society thinks is best all that often. reply insickness 21 hours agoparentprev> As a society, we should prevent \"escape capital\" to be a thing. Why, though? You always hear people say that one person having too much wealth is a problem but rarely hear a good reason. Just because one person is richer, does not mean another is poorer. Wealth is not a limited pie where everyone only gets one piece of it. Wealth is created. If one person's ideas and actions brings up the standard of living for everyone else, I'm fine with that person having more wealth. reply lapcat 21 hours agorootparent> Wealth is not a limited pie where everyone only gets one piece of it. This is where you're mistaken, because wealth is not simply a collection of material goods. Wealth is power, and power is a zero sum game. You don't have power over someone else unless they have less power than you. The ultra-wealthy already have all of their material needs and desires met. They run out of things to buy with their money. You don't actually need a billion to buy all of the houses, cars, boats, and other stuff that you want. Beyond a certain point, the only thing left to buy is people. And that's what the ultra-wealthy do. They exercise power over other people. That's precisely why they're never satisfied with their level of wealth, and continue to accumulate it despite not needing to buy any more material things. The more wealth you have, and the less other people have, the more power you have over others. Wealth buys politicians. It buys laws. It can buy entire countries. reply insickness 17 hours agorootparentOf course wealth is power. If you have 10 million dollars and I don't, you have more power than me. You can do many things I can't. But perhaps you did cancer research for 20 years and found a cure for cancer while I spent my money on vacations and partying. This incentive acted as it should. The world now has a cure for cancer. We can't now say that you should have the same wealth/power as me because power/wealth is bad. reply lapcat 17 hours agorootparent> But perhaps you did cancer research for 20 years and found a cure for cancer while I spent my money on vacations and partying. LOL nice straw man. > The world now has a cure for cancer. Except it doesn't. > We can't now say that you should have the same wealth/power as me because power/wealth is bad. https://en.wikipedia.org/wiki/Jonas_Salk Salk was immediately hailed as a \"miracle worker\" when the vaccine's success was first made public in April 1955, and chose to not patent the vaccine or seek any profit from it in order to maximize its global distribution. reply giantg2 20 hours agorootparentprevIt seems corporations are the ones influencing laws with spending. Even then, it's the constituents that are the problem. Are they really so gullible that a new attack ad funded by donations to the politician will sway them? Are they even paying attention? It's the attention and strength of the constituency that will make a democratic society better. If you really want to fix the voting in a somewhat realistic way, you will completely do away with campaign spending, allocate a government website with a page for each candidate to display their positions, have the site searchable by your address, and have an alternative that you can request by mail if you don't have access to a computer. You also need to ban the news from reporting on the campaign to get around this, including the observation biases that come from all those early polls. Suddendly campaign funding becomes a non-issue, and we're likely to see less manipulation. Even if you eliminated the wealthy altogether, you could still have outsized impacts by many groups due to the most extreme people being willing to donate more. This is essentially what we see primary elections due to the low voter turnout - the most motivated/extreme people have a larger say. reply stana 20 hours agorootparentprev\"Poor man wanna be rich. Rich man wanna be king.\" Bruce Springsteen reply makomk 20 hours agorootparentprevWealth is indeed power rather than simply a collection of material goods, and most of all the wealth this article talks about is the power to run specific large businesses in the way those specific wealthy people want. That is, the way capitalism works in this case is that control over businesses and the ability to dictate how they allocate resources is given to individuals who are in some sense \"successful\" at running those businesses in that they manage to make lots of revenue and convince investors they'll do a good job of continuing to do so going forward. The reasons why this system might be attractive may become more obvious if we consider some alternatives. For example, in Russia currently the power to control big businesses is given to politically well connected \"oligarchs\", and anyone whose business success exceeds their political influence tends to find that business is taken off them and given to someone much less capable but better connected. This does not lead to a functining economy. (There's a popular idea on the left that capitalism has oligarchs too which we just don't call that, which misses this important difference.) We could also imagine a system where this power is distributed democratically, and everyone in the country gets a say in how all the businesses are run. The problem with this is that in order to make decisions that are as well informed as even just some dude who happened to be in the right place at the right time, every member of the public would have to dedicate as much time to informing themselves as all of those random dudes collectively do already. That is, it's structurally impossible to just distribute this power out to everyone. Also, most of the things that populist campaigners claim that wealth redistribution will achieve are about more material goods for everyone which relies on those material goods or at least the capacity to produce them being there already and just horded by the super-rich - just handing out power will not satisfy people's expectations for wealth redistribution and wealth taxes. reply lapcat 19 hours agorootparentYou seem to be presenting some false dichotomies here. I'm not calling for the abolition of privately owned businesses. I'm an entrepreneur myself. It's crucial to note a couple of things: (1) The world's wealthiest people accumulated their wealth from publicly owned corporations, not from privately owned businesses. In fact, there are famous cases where a publicly owned corporation ousted its own founder, e.g., Apple and Uber. (2) The world's wealthiest people get even wealthier after they stop running businesses. Jeff Bezos, Bill Gates, Steve Ballmer, et al., are wealthier now when \"retired\" than when they were CEOs! Gates even claimed he's giving most of his money away, but somehow that's having the opposite effect. Gates can't give money away faster than he makes it, despite \"retirement\". The point is not necessarily to \"socialize\" businesses. The point is to limit the size of businesses and of individual accumulations of wealth, for the good of society as a whole, to prevent them from accumulating too much power over society. One of the ways to do that is via progressive taxation that heavily taxes higher amounts of income and wealth. It's not confiscating the business or individual wealth as a whole; it's just trimming off the edges, so to speak. I personally feel that publicly owned corporations are a problem and should be discouraged. They're effectively the tragedy of the commons. I prefer privately owned businesses. And it's more difficult for privately owned businesses to become huge, because there's never an influx of public capital. > control over businesses and the ability to dictate how they allocate resources is given to individuals who are in some sense \"successful\" at running those businesses You've got cause and effect reversed. The control comes first, the success comes later. > Also, most of the things that populist campaigners claim that wealth redistribution will achieve are about more material goods for everyone which relies on those material goods or at least the capacity to produce them being there already and just horded by the super-rich - just handing out power will not satisfy people's expectations for wealth redistribution and wealth taxes. My point was that the ultra-wealthy are motivated by power rather than material goods, because all of their material desires are already satisfied. Of course non-wealthy people are motivated by material needs, because theirs haven't been satisfied. Indeed, wealth inequality results in hunger, homelessless, lack of health care, situations that we would not tolerate if everyone were equal and in the same boat. reply CapricornNoble 20 hours agorootparentprev>> And that's what the ultra-wealthy do. They exercise power over other people. Arguably, there is always SOMEONE doing this, even without ultra-wealth. Perhaps the argument could be made that the ultra-wealthy are the least malign manifestation of power-hungry sociopathic megalomania? It's not like Stalin in the 30s or Mao in the 50s were using wealth to buy people, for example. But they sure as Hell led to really negative outcomes for the people they influenced. Far more negative than any damage that Musk/Bezos/Buffet/et al are doing now, IMO. reply lapcat 20 hours agorootparentOf course there are always some people striving for power over others. And of course the current billionaires are not as bad as Stalin or Mao. That's not really the question. The question is whether society should strive to prevent individuals from acquiring great power over the masses, and my answer is yes. In other words, even though billionaires are not as bad as dictators, billionaires should still be discouraged rather than encouraged. What I was arguing against was this: \"If one person's ideas and actions brings up the standard of living for everyone else, I'm fine with that person having more wealth.\" It's not clear that they do bring up the standard of living for everyone else. For example, poor people can't afford to buy a Tesla, so what has Musk done to raise the standard of living for the poor? Let's be honest: Tesla caters to the wealthy. Moreover, as I argued, it's not just about material goods. It's about power. It's also about personal freedom for the masses; how much personal freedom would you trade just to have more material goods? reply CapricornNoble 18 hours agorootparent>the question is whether society should strive to prevent individuals from acquiring great power over the masses Whatever people or person has the authority to prevent individuals from acquiring great power over the masses.....has great power over the masses. The power-hungry don't like being told they can't do something. Another possible outcome is the uber-rich start converting their wealth into men-at-arms to secure their power. Every time my wealth ticks over from $998M to $999M I burn $1M secretly acquiring the loyalty of violent men. Eventually my wealth goes from $999M to $1B and the Equality Enforcers pay me a visit....only to find out the hard way that they didn't bring enough bannermen. I don't think its particularly far-fetched to conclude that eventually men with near-limitless resources and near-limitless egos will resort to armed conflict before they allow some paper-pushing bureaucrats to put them back in a box. Maybe that's not the character of Buffet or even Musk, but on a long enough timeline I consider it a certainty. It's better for everyone that they collect yachts and \"atmosphere models\"( https://www.youtube.com/watch?v=jSvvvrKhx0w ) instead. > For example, poor people can't afford to buy a Tesla, so what has Musk done to raise the standard of living for the poor? I think in a system as complex as the world economy it's difficult to pinpoint this with any certainty. MAYBE one could argue that Tesla forced a paradigm shift onto other automakers and that the entire industry dragging its feet to produce EVs is a net quality of life improvement for the civilization in the aggregate due to reduced emissions? Why are we judging the wealthy by their utility to the poor anyway? Belle Delphine isn't a billionaire, but at one point she was making >$1 million per month shaking her butt on a webcam and selling used bathwater to lonely males. Are we going to judge EVERYONE by how they've raised the standard of living for the poor? Where is the cutoff point? $1B net worth? $1M annual income? The market principles which have elevated Elon Musk to the top of his industry have similarly elevated Belle Delphine to the top of hers, with massively disproportionate earnings compared to the bottom-tier OnlyFans content creators. Do we have enough moral outrage for them both? Why or why not? Who has the authority to judge? > how much personal freedom would you trade just to have more material goods? I'm a military reservist who is considering returning to full Active Duty for several years so trading away my personal freedom is.....quite normal to me. That said....I have pretty modest material desires, and am mostly trading my personal freedom for.....wealth accumulation! If you're going to own something, own something that other people need, and that generates revenue. reply lapcat 16 hours agorootparent> Whatever people or person has the authority to prevent individuals from acquiring great power over the masses.....has great power over the masses. I'm talking about the masses. The masses of people should prevent individuals from acquiring great power over them. > Why are we judging the wealthy by their utility to the poor anyway? That didn't come from me but from the person I was originally replying to: \"If one person's ideas and actions brings up the standard of living for everyone else, I'm fine with that person having more wealth.\" I guess it was supposed to be some kind of justification for massive inequality. That's not my criterion though. reply BiteCode_dev 20 hours agorootparentprevStalin and Mao were wealthy. That's why many people argue we never implemented communism, since our attempts ended up as oligarchies. Just because you don't have a paper stating you own something doesn't mean you don't control it. reply mihaic 21 hours agorootparentprev> Why, though? You always hear people say that one person having too much wealth is a problem but rarely hear a good reason. Historically, most societies where this happened ended up with large violent episodes as a response, so we should want to prevent that. While it's possible to enlarge the pie for everyone, to anyone that wants to buy a house it's obviously not the case in today's economy. In some cases the economy is zero-sum, especially with things that are inherently limited such as good real-estate. reply giantg2 20 hours agorootparent\" to anyone that wants to buy a house it's obviously not the case in today's economy.\" Land is very much a limited resource. But most of the problems today are due to the distribution and consumer wants. In much of the US, you could easily buy some land and put a trailer or small manufactured house on it (or buy forclosed, vacant, etc). The problem is the jobs, especially the good ones, are concentrated in a dozen or so major metro areas with higher population density. The. You have the preference of most people who want good public schools, yards, big fancy single family houses, etc. Most people don't want a small house, and due to the job distribution can't live in the less populated areas. reply bryanrasmussen 21 hours agorootparentprev>If one person's ideas and actions brings up the standard of living for everyone else, I'm fine with that person having more wealth. how would that be proved - that is to say there is probably a reasonably causal line to say that their ideas and actions brought up the standard of living for themselves, but the causal line to determine ideas and actions bringing up standard of living for other people would probably be difficult to calculate. reply soco 21 hours agorootparentI guess they meant that elusive \"trickle down economics\" concept which always looks like Bigfoot - everybody talks about it but nobody has actually seen it. reply dgb23 20 hours agorootparentprev\"Wealth is not a zero sum game\" has some truth in it but is ultimately false. There's only so much inhabitable space, only so many resources and only so many people on earth. You only have so much time to live and even thinking over generational legacy, we're fundamentally limited by time. Infinite growth doesn't exist in any meaningful and practical sense of the word. And if we're coming back to the original argument: You can't be ultra wealthy without exploitation. Someone, somewhere has to generate all the value you feel entitled to have, because you inherited a bunch of wealth. And \"someone\" is a vast understatement. There is some line where power and wealth not only become completely unwieldy, because the disconnect between responsibility and power is too great, but also parasitical. I have no idea where that line is and how to solve this problem. But it _is_ a problem and I'm tired of hearing ideological platitudes that try to naturalize and defend it. I say this all with a caveat: I have nothing personal against people who are wealthy or even ultra wealthy. Ultimately they are just part of a larger, hard to solve issue like everyone else. reply BiteCode_dev 21 hours agorootparentprevIt does, because power is bought with money and if you buy a vote, the richest win. Also, resources are not infinite. Eg: There is a limit to the number of the best doctors and their time. Fresh air is locally finite, and jets do pollute more per person. So despite the fact that in theory we are not playing a zero sum game, practically at the scale of one life, many things can be approximated as such. reply wildrhythms 21 hours agorootparentprev'Wealth' is too nebulous a term to discuss anything socioeconomic related. When 'wealth' is measured in material- land, housing, money... these are all finite. You seem to be creatively measuring 'wealth' as immaterial things like ideas and actions. Be precise. reply jampekka 21 hours agorootparentMoney isn't finite or material and it's worthless in itself unlike e.g. land and housing. reply soco 21 hours agorootparentprevIf we actually read the maths presented by the article, it looks like many people did get poorer. You could argue there's no causation between them, but if correlation gives us civil unrest, we go fixing correlation (unless we prefer street wars). reply bitcharmer 21 hours agorootparentprevThis comment reads as either trolling or a very naive take but I'll bite. Why obscene wealth is a problem? Even my 10yo knows that. Extreme asymmetry and inequality. From different treatment by the government, to the justice system, to access to health care, education to getting in a position where being rich means you can exploit poor people to get richer with zero consequences. How this has to be explained to someone on this forum is beyond me, but here we are. reply Kon5ole 17 hours agorootparent>From different treatment by the government, to the justice system, to access to health care, education to getting in a position where being rich means you can exploit poor people to get richer with zero consequences All the things you mention are problems that need solving, but they are wrong in themselves separated from the wealth. A wealthy person might not be doing any of those things. Wealth in a free capitalist society is generally the result of increased economic activity which often benefits many more than the billionaires that appear as side effects. This is a good thing which should be kept, but we need to ensure that society isn't corrupted in the process. We used to have much more extreme divisions of wealth than we do now, kings and nobility a few hundred years ago, and we made laws to limit their influence. So it can be done. reply bitcharmer 16 hours agorootparent> We used to have much more extreme divisions of wealth than we do now, kings and nobility a few hundred years ago, and we made laws to limit their influence. So it can be done. I think your comment is optimistic to the point of being naive. Wealth disparity has been increasing in the last 200 years. https://ourworldindata.org/the-history-of-global-economic-in... reply Kon5ole 14 hours agorootparent>I think your comment is optimistic to the point of being naive. Wealth disparity has been increasing in the last 200 years. You mention disparity as if it is a problem but ignore that most of the population is much better off. Your source clearly shows that in 1800 the world population was mostly poor, while in 2015 it was mostly _not_ poor. This despite the population being 7x larger. Which is exactly my point - the system that generates billionaires has done so as a side effect of generating enough wealth to lift a several times larger world population above the poverty line. Is disparity itself so offensive that we should let everyone be poor just to avoid billionaires? I can't get behind that, but I do want better laws to prevent corruption. reply bitcharmer 13 hours agorootparentIt's a bit like saying: oh look, everything's going better now because fewer people die from pneumonia now than a hundred years ago. You're missing the bigger picture. An average young person is now much less likely to afford housing than the generation before them and even less likely then their grandparents. What does that mean to you? reply Kon5ole 10 hours agorootparent>everything's going better now because fewer people die from pneumonia now than a hundred years ago. You're missing the bigger picture. I'm not talking about pneumonia though, and surely the bigger picture is that the average person in the world is better off today than they were before? I think the mechanism that caused that has billionaires as a side effect, which is hard to eliminate without also eliminating the thing that makes everyone better off. >An average young person is now much less likely to afford housing than the generation before them and even less likely then their grandparents. What does that mean to you? To me it means that the housing markets in many countries are poorly regulated and speculation fueled by low interest rates have inflated prices. reply DFHippie 15 hours agorootparentprevIn addition to the reasons others have cited, I think the corrosive effect of wealth inequality on social cohesion is under-appreciated. The wealthy fear their wealth being taken, so they live in gated communities and hire guards. The society they have walled out and the society they have walled in see their interests as diverging. Neither wants to invest in the other, protect the other. The less wealthy see that wealth buys power, which buys \"voice.\" The government responds to voice, so however democratic their nation is on paper, they don't perceive the government as responsive to their desires -- and in fact it is less measurably less responsive to their desires -- so they have less stake in preserving its legitimacy and stability. Why preserve the tool someone else uses to cheat you? And so on. Unequal societies are low-trust societies. Low-trust societies are less capable of providing public services efficiently. They are less capable of making and achieving long-term goals. They are more prone to corruption and criminality. If you don't trust the agents of the state to keep you safe, you are more prone to taking matters into your own hands, less prone to cooperating with the agents of the state to address crime. And so on. https://en.wikipedia.org/wiki/High-trust_and_low-trust_socie... reply giantg2 21 hours agoparentprev\"But if you have enough money, current rates mean that taxes & inflation will erode your capital slower than the interest you'll earn from that capital alone, and so money is inevitably growing on itself.\" If it were based on interest, this is unlikely to be a problem unless interests rated exceeded tax rates. The real issue is that most of the net worth is equity. These unrealized gains are not taxed. In some cases, a lot of the value is driven by speculation and not actually tied to the current profits of the company. This is why wealth taxes are brought up, or at least changes to capital gains taxes. \"As a society, we should prevent \"escape capital\" to be a thing.\" This assumes that the ultrawealthy do not serve a purpose. Yeah, taxes should be increased on the top end, but probably not to the point of completwly eliminating the ultrawealthy. These people tend to use thier capital to fund other ventures. This can be important to startups and other organizations. Oftentimes they donate large amounts of money to charities or start charities in areas the government has neglected. There are alternatives to these, but I'm not convinced they are actually better. I think we just need to tweak capital gains tax on the ultrawealthy. reply panda-giddiness 20 hours agorootparent> The real issue is that most of the net worth is equity. These unrealized gains are not taxed. In some cases, a lot of the value is driven by speculation and not actually tied to the current profits of the company. This is why wealth taxes are brought up, or at least changes to capital gains taxes. Of course, equity is still useful. One can borrow money using the assets as collateral, and rather than paying taxes on the (borrowed) money, one instead pays a comparatively small interest to the bank. Moreover, those unrealized gains never need be taxed so long as they are never converted to cash. The capital gains on the assets are then reset when the owner dies (the so-called \"buy, borrow, die\" strategy [1]). I would venture that this is a massive loophole in the tax system that ought to be patched-out. --- [1] https://www.propublica.org/article/the-secret-irs-files-trov... reply Geezus_42 21 hours agorootparentprevI'm not convinced rich people are useful. reply giantg2 20 hours agorootparentI'm not convinced that people in general are truly useful, but that brings about an entirely different philosophical discussion what what is actually useful and why humans should be considered as such. reply jampekka 20 hours agorootparentprevI'm convinced they are harmful. reply JKCalhoun 21 hours agorootparentprevI wonder if the ultrawealthy have doubly served their purpose in the last three years. I don't disagree the ultrawealthy serve a purpose, just wondering, as most of us do — how much ultrawealth is enough? In theory at least, the idea of taxes is to use our societies collective excess money to pay for things that we as a society would benefit from. Perhaps it's infrastructure, perhaps it's a modern high speed rail system, perhaps space exploration. Instead though we have chosen to allow the billionaires to be the arbiter of where their excess capital goes. reply giantg2 20 hours agorootparent\"In theory at least, the idea of taxes is to use our societies collective excess money to pay for things that we as a society would benefit from.\" This is one of the alternatives I was thinking about. Unfortunately, the way our current politics are, there's no guarantee that our system would actually allocate that money to what we actually need any better than the billionaires are. Given that the needy are a small minority, it's possible they fair even worse in a democratically controlled funding system, especially if the larger segment want more for themselves and have more influence. reply m_fayer 21 hours agoparentprevI think this is more commonly referred to as “fuck you money”. reply davisoneee 21 hours agorootparentI consider 'fuck you' money to be enough that it'll last until you die, while living comfortably. This is still an amount that you burn through in a lifetime. Something _like_ 'financial independance, retire early'. I think the parent is suggesting a money threshold beyond which you can't really feasibly spend it fast enough (without being deliberately wasteful), so 'the rich get richer'. reply ragebol 21 hours agorootparentprevNo, this is \"not be fucked\" money. Without some minimum amount, you are fucked and will never escape poverty. reply lapcat 21 hours agorootparentprev\"Fuck you money\" is when you can just quit your job. \"Fuck everyone money\" is when you can just buy Twitter. reply MomoXenosaga 21 hours agorootparentprevI was at a museum looking at a group portrait of 18th century rich people in uniform and it hit me. Not a single US billionaire will ever have to lead a regiment in war. reply yafinder 17 hours agoparentprevI think this is just an \"r>g\" rule made famous by Piketty. When r (return on investment) is bigger than g (overall economy's growth), the rich get richer. It's unsustainable in a pure mathematical sense, the rich cannot own more than 100% of economy, so at some moment this system breaks, and one can only hope that it doesn't break violently. Piketty somehow wrote a 1000 page book about that, and a slightly controversial one, but an idea is very simple and, I think, hard to argue against. reply 2-718-281-828 17 hours agorootparenti'm not an economist, so ... but i think it would be possible for few people to own everything given that their wealth isn't just money in a bank but all sorts of assets with a life of their own. such a person then effectively represents something similar to a state or country. united companies of amazon ... reply maxcoder4 19 hours agoparentprevI agree with your main point but >why this is a polarizing issue as 99.5% of people are on the same side of the threshold are we? I earn way less than mid-level programmer in SV and I'm pretty sure I'm on the \"rich\" side of threshold already. Granted I'm relatively frugal, live alone, and live in a (capital of a) low cost of living country but fact is a fact. I'm sure every single homeowner in California can achieve financial independency (if they sell their property and move somewhere cheap). reply voisin 18 hours agoparentprevThe US used to have this: https://en.m.wikipedia.org/wiki/Revenue_Act_of_1935 75% marginal tax rate on income over $1 million (in 1935) which is 22,241,021.90 today. Crazy to think how “low” that is relative to the top incomes today. reply csomar 21 hours agoparentprev>I totally fail to understand why this is a polarizing issue as 99.5% of people are on the same side of the threshold... Because 99.5% of the people are not on the same side. There is a class of bureaucrats and military that benefits from this status quo. It's currently happy, as it can easily stage a coup. (most billionaires are old people). The money is going to the right people; the reality is that 60-70% of the world population is disposable. In the US, 40% are already inactive. 20-30% are probably holding jobs that we can live without. Most of the other 30-40% could be out sourced though the \"elites\" are now re-thinking that because they can't trust off-shore stuff like before. But that's the US, a developed country. The rest of the world is poor and useless and no one is quite interested in doing anything about it. (Except for China, though they are a bit obsessed about control to the detriment of their goals). reply Damogran6 21 hours agorootparentYou can't sell your product if there's nobody that can buy it. I suspect the lower 70% you're talking about spend their money to keep the economy going. UBI? I dunno...jury is still out on that science experiment. Automation has made a vast majority of our jobs irrelevant, and ChatGPT looks to make a much larger component similarly irrelevant, but you can't sell your crops if people can't buy your crops. reply CapricornNoble 20 hours agorootparent> You can't sell your product if there's nobody that can buy it. Our current model is capitalists get rich selling piles of cheap stuff to the labor class. I think the future might be petite bourgeoisie selling high-end, long-lasting products to each other. Picture the guy who has his own AI company selling AI to the guy who has a robot company, who sells robots to the guy who owns a coachbuilder such as [1] or [2], who sells cars to the AI guy and the robot guy. Then the car guy buys a watch from a watchsmith in Switzerland. Watch guy doesn't have any robots but maybe he uses AI to help him design new watches, which he builds by hand himself. Then all four of these guys eat by buying meat from a guy who uses robotic cattlehands to coral his herd of free-range grass-fed bison or something. Each of these five people work at the companies they own. They have no laborers underneath them that aren't AI or robots. They are just exchanging a small amount of high-value goods and services between each other. The HUMAN labor class is gonna die or be subsidized just enough to keep from revolting. [1] https://singervehicledesign.com/ [2]https://www.fj.co/ reply juancn 20 hours agoparentprevIt's a statistical phenomenon. It's pareto inequality. Check this video, specially the \"trading game\" simulation (about 5:24 into it): https://www.youtube.com/watch?v=BZMBdRfbk6A reply vdaea 21 hours agoparentprev>I totally fail to understand why this is a polarizing issue as 99.5% of people are on the same side of the threshold... Because I had a good father and a good mother who taught me that stealing from someone else is not okay, even if they have more things than me. reply richbell 21 hours agorootparentIt's intriguing how many people frame this as \"stealing.\" How do you think many people become billionaires? It isn't through fair competition and treating workers well. reply CapricornNoble 20 hours agorootparent> How do you think many people become billionaires? Pareto Principle, offering some of the best market options on a planet with 8 billion people? Let's say I make a product that is 10% better than yours (maybe I burned more midnights engineering it, maybe I just had a radical trip on some DMT that gave me special insight, whatever). Let's say my product costs me $.90 to make, yours only costs $0.75 to make. We both sell at $1.00.....but 90% of the 8 billion people buy my obviously better product, and only 10% buy yours (maybe they hate something about me personally, or maybe my marketing simply didn't reach or convert them). I make $0.10 * (0.9 * 8B) = $720M. You make $0.25 * (0.1 * 8B) = $200M. I'm already over 3x richer than you, and ALMOST as close to billionaire as you are close to being impoverished ($0 net worth in this scenario). What part of my competition wasn't fair? What workers were mistreated? THAT SAID.....I don't disagree that many wealthy families are scummy thieves with a sheen of respectability (like the Sacklers, for example).....just, I prefer that we not instantly reach for that excuse and dismiss the entire concept of extreme wealth accumulation as \"well OBVIOUSLY they've got to have done something evil, there is no other explanation, so let's collectively punish their entire class\" which is how most of these conversations conclude. reply pi-e-sigma 20 hours agorootparentprev\"Behind every great fortune lies a great crime\" - Honore de Balzac. reply Geezus_42 21 hours agoparentprevBecause we've been trained to believe that we can be one of those people one day if only we work hard enough. It's not true, but it's the American dream. reply hnarn 21 hours agoparentprev> I totally fail to understand why this is a polarizing issue Because for most people (especially in the US), this is emotional. As soon as you start talking about “taxing the rich” many people have a prepared inventory of feelings that get activated, and these feelings are telling them that even if I’m not rich, I could be some day, and this isn’t right. If you want an example of the almost religious cult of personality around people with immense wealth, look no further than the people simping for Elon. The idea goes that surely these people are special, there’s a reason they have so much money, and by taking their money we'll accomplish nothing except crucifying these inventors that humankind relies upon. Entire books (or perhaps libraries) have been written on the subject of the routines and life patterns of extremely rich people. They’re not like us. reply soerxpso 14 hours agorootparent\"We should squander the rights of a group of people so that we can have more things!\" \"I disagree. I think that we should not do that, as it is morally wrong.\" \"You fool! Don't you understand that it's not your rights that would be squandered?! It's only the rights of people who are not like us!\" reply rocgf 21 hours agorootparentprevI definitely believe that wealthy people should be taxed at similar or higher levels than the average middle class employee, and I am definitely not some Elon fanatic. With that said, I do think that there is a reason they have so much money and that they are inventors that are pushing the boundaries. I don't understand why people refuse to accept that some people are smarter, work harder, think at a grander scale. reply actionfromafar 20 hours agorootparentDoes that make them deserve to also be your Lords? Because this is what is happening in practice. reply rocgf 18 hours agorootparentObviously not. As I said, I think taxation for anyone making say 500k+ should be comparable percentage-wise with any regular employee. That is indeed happening in practice, through the influence that money gives them, though not sure how this argument fits into the discussion. reply lapcat 19 hours agorootparentprev> work harder When's the last time you've done manual labor full time? I'm so tired of this \"hard work\" meme. The hardest job I've ever had was to stack shampoo bottles in boxes for shipping. After 8 hours of that, I had to curl up in the fetal position. And the job paid crap. I also don't believe that Elon Musk is smarter than the engineers who work for him and make nearly infinitely less money. In any case he's certainly not orders of magnitude smarter. reply rocgf 18 hours agorootparentI see this argument frequently and I never could understand quite where it's coming from. Throwing manual labor into the conversation is disingenuous since nobody would ever make the argument that some tech billionaire has a harder working life than someone shovelling gravel 16h per day. It's obvious that's not what anyone means, so why even point this out? Elon Musk may not be \"smarter\" than the engineers who work for him, but then why didn't they start a company like Tesla? The argument for Elon's success is built into the results themselves. There's no going around that, without serious mental gymnastics. reply lapcat 18 hours agorootparent> nobody would ever make the argument > It's obvious that's not what anyone means I disagree. Citation needed. Regardless of what other people mean by \"hard work\", what exactly do you mean by it, and how exactly do the wealthy work harder than everyone else? > why didn't they start a company like Tesla Musk technically didn't \"start\" Tesla, but anyway there are several reasons. For example: 1) They didn't have the capital. Musk himself didn't have the capital to invest in Tesla or SpaceX until several previous businesses were acquired by bigger businesses. eBay acquiring PayPal was the big one. 2) They didn't want to? The smartest people in the world tend not to be motivated primarily by money and greed. Also note that Musk started out working on websites and financial services, which is how he made his initial capital, but that wouldn't necessarily interest auto or space engineers. Remember that Steve Jobs made most of his wealth from Pixar and selling it to Disney rather than from Apple. Was Steve Jobs \"smart\"? Sure, but WTF did Steve Jobs know about making films in 1986? Nothing. He was just a rich dude with some capital to invest. Why didn't some indie filmmaker become a billionaire instead? Because indie filmmakers don't have the capital. reply rocgf 18 hours agorootparent> Regardless of what other people mean by \"hard work\", what exactly do you mean by it, and how exactly do the wealthy work harder than everyone else? You get too caught up in the meaning of \"hard work\", as if your only purpose it to use its pedantic definition as a gotcha. Hard work in the way you define it is not and should not be rewarded just for the sake of hard work. It cannot work this way and you don't want it to work this way, regardless of what you may think. If we did that, the world would stop working. So whether the wealthy work more or not is irrelevant. > Musk The anti-Musk sentiment is now at cult-like levels and I'm afraid that rational conversation is not on the table anymore. Somehow Elon's name is associated with some of the most revolutionary companies of the past decade, yet still you'd argue that he doesn't work hard, isn't smarter than his engineers, is basically just lucky. Whatever makes you feel better about yourself. If the guy who created SpaceX is not impressive to you, then I'm not sure who is. He is kind of a moron in his tweets and has done some despicable shit, but I am able to separate this from his accomplishments. reply lapcat 16 hours agorootparent> You get too caught up in the meaning of \"hard work\", as if your only purpose it to use its pedantic definition as a gotcha. No, I personally don't use the phrase myself in normal conversation and would be glad if it simply disappeared entirely. I'm only responding to the people who use the phrase to justify massive inequality of wealth, so I'd like to hear what you think it means, and how it justifies that inequality. > The anti-Musk sentiment is now at cult-like levels and I'm afraid that rational conversation is not on the table anymore. The submitted article is about the \"Five richest men\", of which Musk is one, so it's not like I'm bringing up his name out of context. He is the context here. > yet still you'd argue that he doesn't work hard I didn't argue that. I don't even know what \"hard work\" is supposed to mean here, which is why I'm asking you. You're the one who said, \"I don't understand why people refuse to accept that some people are smarter, work harder...\" Yet you seemingly refuse to say what you mean by that. If manual labor isn't hard work, then what is hard work, exactly? > is basically just lucky He is lucky. You don't think the following is a lucky set of circumstances to get a massive payoff? https://en.wikipedia.org/wiki/Elon_Musk#X.com_and_PayPal \"Even though Musk founded the company, investors regarded him as inexperienced and replaced him with Intuit CEO Bill Harris by the end of the year. In 2000, X.com merged with online bank Confinity to avoid competition, as the latter's money-transfer service PayPal was more popular than X.com's service. Musk then returned as CEO of the merged company. His preference for Microsoft over Unix-based software caused a rift among the company's employees, and eventually led Confinity co-founder Peter Thiel to resign. With the company suffering from compounding technological issues and the lack of a cohesive business model, the board ousted Musk and replaced him with Thiel in September 2000. Under Thiel, the company focused on the money-transfer service and was renamed PayPal in 2001. In 2002, PayPal was acquired by eBay for $1.5 billion in stock, of which Musk—PayPal's largest shareholder with 11.72% of shares—received $175.8 million.\" Without that lucky jackpot, none of your \"revolutionary companies\" would exist. > Whatever makes you feel better about yourself. I don't really care. I'm not a \"failed billionaire\". I've never in my life even aspired to wealth. It's not among my priorities. What I do care about is the disproportionate political power exercised by the ultra-wealthy, and how it makes our whole society worse. > If the guy who created SpaceX is not impressive to you, then I'm not sure who is. A lot of people are impressive to me, but I don't give a damn about SpaceX. I don't believe in the Mars fairy tale that's been sold to space nerds, and I wouldn't bat an eyelash if SpaceX folded and stopped operating tomorrow. Furthermore, I think there are too many rocket launches polluting the atmosphere and too many satellites being put in orbit. I'm not a fan. reply rocgf 11 hours agorootparentLook, to be honest, I just think we have vastly different opinions and views on the world and how it works. There is absolutely nothing in your message that gave me any pause, and I think we start from irreconcilable positions. > I'm only responding to the people who use the phrase to justify massive inequality of wealth, so I'd like to hear what you think it means, and how it justifies that inequality. I do think that there is probably too much inequality for it to be healthy for society, but I am not of the opinion that \"billionaires should not exist\" or that anyone rich is some version of evil. I believe fundamentally that two workers who have different productivity and/or different work ethics should be compensated differently. Elon Musk (and many rich people) have, on average, better work ethic and considerably better output. Just by the fact that Elon has been involved in so many successful ventures at a global level, that is by definition proof that he is doing something better than virtually all of us. > I don't even know what \"hard work\" is supposed to mean here In previous replies you associated hard work with physically strenuous work. I think they are orthogonal concerns. Working hard means making progress on problems at the edge of your abilities. By your definition, someone shovelling bricks for 8 hours is working harder than someone working 8h in an office. By mine, that is not necessarily true. Also, even if your definition was true, paying someone purely on how 'hard' they work would still not be a good idea. > Without that lucky jackpot, none of your \"revolutionary companies\" would exist. This sentence does not sound as good as you think it does. Sure, loads of people end up with the biggest percentage of shares in a company like PayPal and then also continue with other extremely impactful ventures, one after the other at the edge of technology. Repeated moonshots is \"lucky\". > I don't believe in the Mars fairy tale that's been sold to space nerds Me neither, but have a look at how many launches have happened each year before and after SpaceX, in a field entirely dominated by national agencies. No matter which way you cut it, SpaceX has ushered in a new era in space exploration. I won't even bother arguing more about this, this is honestly ridiculous. reply lapcat 10 hours agorootparent> I believe fundamentally that two workers who have different productivity and/or different work ethics should be compensated differently. Elon Musk (and many rich people) have, on average, better work ethic and considerably better output. Half the population has better than average work ethic. Does Musk have a better work ethic than his lesser paid employees? That's dubious. After all, he infamously demanded that Twitter employees be \"extremely hardcore\" and work \"long hours at high intensity\". But these employees are not compensated nearly as much as Musk. They're not even rewarded at all in many cases. He still fired a bunch of them afterward, even the women who tweeted a photo of herself sleeping in the office. What about the work ethic of the poor people who work multiple jobs because one job doesn't pay enough? How is there any relation whatsoever between work ethic and income? Note that Jeff Bezos, one of the other five richest men whose income doubled, actually quit his job! You don't make massive money from working for wages, you make massive money from owning assets and waiting for them to appreciate. This is how Musk got his PayPal payoff despite having been removed from power by other investors. There are countless people in the world who are extremely smart and have a great work ethic. But that doesn't automatically bring great wealth. A lot of it is being in the right place at the right time. Do you need to be smart and have a good work ethic to take advantage of the opportunity? Yes, probably. But most people aren't lucky enough to get those opportunities in the first place. It also helps to ruthlesslessly pursue wealth with no regard for ethics... > Just by the fact that Elon has been involved in so many successful ventures at a global level, that is by definition proof that he is doing something better than virtually all of us. He makes more money than virtually all of us. That's beyond dispute, and indeed the subject of the submitted article. It's basically a tautology though and not an explanation. > Working hard means making progress on problems at the edge of your abilities. Well, as I mentioned, loading shampoo bottles into crates for 8 hours was definitely on the edge of my abilities. > Sure, loads of people end up with the biggest percentage of shares in a company like PayPal and then also continue with other extremely impactful ventures, one after the other at the edge of technology. Repeated moonshots is \"lucky\". You're missing the point. Musk was kicked out of his own company not just once but twice for incompetence. Yet he still got a $175 million payoff. That's failing upwards. He ought to be kicked out of Twitter for incompetence too, but unfortunately he can't be. > have a look at how many launches have happened each year before and after SpaceX I did, and I already said I don't like it: \"I think there are too many rocket launches polluting the atmosphere and too many satellites being put in orbit.\" reply maxerickson 17 hours agoparentprevYou also generally gain access to better investments as the amount you are investing goes up. reply kranke155 21 hours agoparentprevThomas Picketty reply roenxi 21 hours agoparentprevAs a society we should aim for everyone having this thing. The best state is for everybody to be idle because they all own enough capital not to have to work. Besides, preventing this outcome is silly unless there is solid evidence that the alternative is more economically efficient. Jeff Bezos being rich doesn't diminish the quality of my life in any way. Same for all the other wealthy folk. reply lapcat 20 hours agorootparent> As a society we should aim for everyone having this thing. The best state is for everybody to be idle because they all own enough capital not to have to work. By \"capital\" do you mean \"intelligent robots\"? Because otherwise, who is going to do the work when everyone is idle? reply roenxi 14 hours agorootparentI mean capital. You could have asked the same question in 1823 and the answer turned out to be \"no\". Unintelligent capital is so productive that most people were forced out of all known jobs in the 1800s. The answer in 2023 could be yes or no. reply lapcat 14 hours agorootparent> Unintelligent capital is so productive that most people were forced out of all known jobs in the 1800s. I have no idea what you're talking about, but it sounds totally false. reply roenxi 11 hours agorootparentYeah that was probably poorly articulated. Put it this way - everyone used to be a farmer. Capitalism happened, now the number of farmers in capitalist economies rounds to 0. There was no need for intelligent robots to do that. AI is likely to have a similar effect on some knowledge workers. At this point, arguably, very few people need to work. They persist regardless, and we are better off for it, but maybe growth in robotics and AI will some day force people to stop. And that would be a good outcome. Even now, if people don't need to work that is arguably for the best. The only concern I have is government policy encouraging productive people not to exert themselves. Either way, identifying people who are highly productive but not working and making them waste their time is stupid. We should want less people to need to work. reply lapcat 10 hours agorootparentCapitalism happened, now the number of farmers in capitalist economies rounds to 0. No it doesn't. There are 2 million farms in the United States, and they don't just take care of themselves. Moreover, besides the farmers themselves, there are many people working in farming-related jobs, e.g., manufacturing farm equipment. Not to mention, how do you think the food gets from the farms to your table? The trucks don't just drive themselves yet. > At this point, arguably, very few people need to work. That's ridiculous. Ruthless capitalists would have gotten rid of employees already if they could. reply roenxi 8 hours agorootparent> No it doesn't. There are 2 million farms in the United States, and they don't just take care of themselves. I'm not abreast of the stats for the US, but it would appear those 2 million farms employ order of magnitude 2 million farmers [0]. Which averages 1 farmer per farm, and while that seems a bit low it isn't inconceivable to me when considering the productivity of farmers in this day and age. The population of the US is 333 million people. Factor in geography, there may well be people who have literally never talked to a farmer in person. There are not a lot of farmers out there, the industry has been eaten by capital. That leaves around 99% of the population that may literally does not need to work to sustain a lifestyle that would be considered typical through most of human history. No intelligent robots required. > The trucks don't just drive themselves yet. They do drive themselves. Eg, https://www.abc.net.au/news/2021-06-19/autonomous-trucks-hit... > Ruthless capitalists would have gotten rid of employees already if they could. They have. Industries have been all but wiped out for employees by capitalists. The only thing keeping people employed is they refuse to be satisfied with what they have and keep finding new jobs. Although if they were a bit more savvy they'd invest in capital and stop wasting time working. Capital wins when it comes down to it. This insistence that people should put the foundation of their lifestyle on work instead of capital accumulation is a habit that is sorta silly. The expectation should be that the average person owns capital and policies should be aimed at enabling that. Forcing successful capitalists to work is the opposite of clever. [0] https://www.ers.usda.gov/topics/farm-economy/farm-labor#size reply lapcat 8 hours agorootparentIf you think 2 million is approximately 0, you should look at the stats from other professions. For example, there are actually more farmers than physicians. This \"conversation\" is becoming ridiculous. Do you think we need no physicians? No nurses? No dentists? No hair stylists? No home builders? No plumbers? No chefs? I could go on and on and on, but I actually don't want to go on and on and on with you. No TEACHERS. No librarians. No electricians. No sanitation workers. No engineers. No mail carriers. No maintenance or repair people. No sales people. No cashiers. No snow plowers. No architects. No SOFTWARE DEVELOPERS. No journalists. No writers. No actors. No musicians. No police. No lawyers. No airline pilots. How in the world do you think the world works without people? Perhpas you're putting a lot into \"sustain a lifestyle that would be considered typical through most of human history\", but why would we want to roll back the clock and live like it's the Dark Ages? reply roenxi 4 hours agorootparentHistorically we'd be talking about 80-90% of people being farmers [0]; even putting aside the fact that \"farmers\" in this day and age, by productivity, are basically just minding big machines that work hard. Tell you what, how about I say 1%. So maybe it is a 98% reduction in farming employment instead of 100%. None of my arguments change though. Now that is a long list, but a several the jobs you're listing there might be on the verge of extinction as a practical matter. Software developers in particular; it is clear that LLMs are about to do something big to the profession. It isn't clear if the job title will survive. Engineers more broadly I'd put in the same bucket, the category is at risk as an employer. ChatGPT is already outcompeting a lot of teachers I know in terms of being able to explain & tutor concepts. Airline pilots we should probably make illegal fairly soon; I wouldn't want to trust my life to human judgement when we could automate that away. We're on the edge of self driving cars and presumably self driving planes is either the same or easier difficulty because navigating the sky is easier than a street. I haven't talked to a cashier or salesperson in a long time because my local shopping centre has self-service or I buy things online. Etc, etc. And I don't know why you think all those jobs are so important to preserve. If we can get rid of them we should, and as far as technology goes we're in spitting distance. The software is a matter of years, so really it is a question of where the economic limits are for robotics. I don't think we will; I imagine work will be found. But in terms of should we replace these people with capital, we should. And in many cases we will. And the goal should be to remove people from the workforce altogether through capital ownership because that is a much more comfortable lifestyle. > but I actually don't want to go on and on and on with you. As a style point, I'd recommend putting that at the end of the list, rather than the middle. I got a bit of a chuckle out of that, so if you did it for effect I thought it was a nice touch. [0] https://acoup.blog/2020/07/24/collections-bread-how-did-they... reply wildrhythms 21 hours agorootparentprevSurely the goal of society would be egalitarianism? In which the entire concept of money- a vehicle of inequality- would be no longer needed. The concept of capital as you described it would not need to exist at all. reply roenxi 21 hours agorootparentHow could that even be a theoretical possibility? Nobody having to work is a possible outcome. Societal equality as far as I can see isn't. If nothing else, we could all start equal and then someone starts working because they are bored and accumulate more stuff. It isn't a useful goal anyway. If you have all that you need, someone else having more than that isn't a problem. reply godzillabrennus 21 hours agoparentprevHumans have developed a thing called violent revolution when they feel injustice is too severe. reply Damogran6 21 hours agorootparentI'm pretty sure that's been bred out of us. I don't see folks _successfully_ storming the gates and hanging the rich. reply mlrtime 20 hours agorootparentIt most certainly has not been bred out of us. Take away food for about a month or so and see how quickly we return to this animalistic nature. There is no \"hanging the rich\" because their is no need to. The rich are getting richer, and the gap is increasing. However, the poor and middle are continuously increasing as well (Important: Assuming we stay on track after the COVID dip), there is no need to eat the rich so it doesn't happen. reply herbst 21 hours agoparentprevAlso to the other side ... Most people are doomed to live from paycheck to paycheck. There is no room for improvement or optimization. Once you have your yearly needs on a bank account and more to come plus enough time you can invest in random ideas when they come, buy things in bulk and safe a lot of money or go for the expensive thing to safe money in long term. Basically there is a 'point poor' where you are doomed to stay poor, where you have to little to change anything about it. reply kwhitefoot 17 hours agoparentprev> 99.5% of people are on the same side of the threshold.. But those are merely \"temporarily embarrassed capitalists\", John Steinbeck But Jacobin.com disagrees: https://jacobin.com/2018/05/americans-class-politics-piston reply steve1977 20 hours agoparentprev> As a society, we should prevent \"escape capital\" to be a thing. Why stop at “escape”? reply readthenotes1 19 hours agoparentprevMy great granddaddy said: It's a good thing when your money starts working for you instead of you working for your money. -- Escape velocity is when you can actually set some money aside to invest in a profitable venture and have the discipline to not spend what you have. reply drcongo 20 hours agoparentprevThe whole concept of the \"American Dream\" in the states, and the one and only selling point of the tories in the UK, is to make that 99.5% think they could one day be in the 0.5%. They won't of course, but the fact that they think it could happen means they support low taxes for the rich in case they ever become rich. reply guerrilla 21 hours agoparentprevWe alreasy have this. It's called a positive feedback loop. Wealth creates wealth and debt creates debt. reply thriftwy 21 hours agoparentprevhttps://www.economist.com/democracy-in-america/2009/10/29/fr... \"Friedman space\" is a short story by Viktor Pelevin describing more or less that. The gist of it is > in a parallel to the existence of an event horizon at the perimeter of gravitational black holes, the possession of extremely large sums of money sends a person into an altered zone of consciousness where, though they appear to others to be acting normally, their own perception of the universe is completely altered and incommunicable to observers reply chiefalchemist 21 hours agoparentprevCapital begets capital. That's not a secret. No offense but we don't need a new economic concept. We need to adjust or priorities. Take this article, note the headline is not \"The five people who gave away the highest percentage of their wealth\" or \"The five people who saved the most lives in 2023\". Etc. You get the point. We've collectively have bought into and become fixated on a single currency of measurement. We say \"success\" and don't bother to preface it with \"financial\" as if there are no other forms of success. There are. Words create worlds. We have the words. But we don't use them to our (i.e., 99.5%) own advantage. reply dijit 21 hours agorootparentCapital begets Capital is the literal foundation of capitalism. IE: My capital and your time are equal; thus a person who has much more capital has the buying power of many people. it's mildly irritating that we know that in a relative closed system with finite resources the inequality rises (the entire point of Monopoly is to show this), yet we forget it in our day to day lives because we can't relate the microeconomics to macroeconomics for some reason. reply mlrtime 20 hours agorootparentIt's also mildly irritating that people still don't understand that wealth is not 0 sum. reply chiefalchemist 19 hours agorootparentTrue. But to be fair that's what they see, so there's no reason to believe otherwise. When scarcity is all you know then zero-sum is all you think. When the Top 5 double their worth, and the poorest lose - while that might be correlation - it certainly looks like cause (read: zero-sum). Per another comment I left on this thread, we need to be aware of the language the rest of us use, as it does create worlds. And we keep creating a world that favors the systems, metrics and paradigms of The Few. reply mlrtime 18 hours agorootparentAgreed with your comments... So we are saying it is a problem of perception? If we didn't know about the top 5's wealth, and the bottom was rising in wealth (Maybe lower rate than the top, but we don't know). There would be no problem? reply chiefalchemist 17 hours agorootparentPerception and \"promotion\". We've fetishized and normalized excessive wealth. Imagine you collected Fubar Widgets and the media promoted you as having a Fubar Widget collection with 50+ billion such Widgets...most would look upon you as being a weirdo, with some sort of personality disorder, etc. Do that with money, and the concept of normal and decent goes out the window. Your obsession...your hoarding (if you will)... Perfectly normal. Perfectly acceptable. But ultimately, textbook bonkers. Mind you, I don't have a philosophical issue with excessive wealth per se. To me, it's strange, but what do I know? However, in the context of poverty and a slew of countless other ills in the world, such hoarding feels disturbing and disconnected. I don't see such behavior as being enviable, let alone put on a pedestal as we do. reply hyperthesis 21 hours agoparentprevaka \"living within your means\", used to be laudable. reply acuozzo 17 hours agorootparentMy assets have beaten inflation across the board. reply Podgajski 20 hours agorootparentprevInflation is laughing at your “means”. reply latexr 21 hours agoparentprev> I totally fail to understand why this is a polarizing issue as 99.5% of people are on the same side of the threshold... Because one day it could be you on the other side. You’re gonna pull yerself by your bootstraps and are totally going to become one those filthy rich people. Everyone can make it in America. All you need is hard work and country music. You wouldn’t want to tax your soon-to-be fellow rich men, now would you? What are you, a commie? A socialist? Why, one day that could be yourself you’re taxing there, buddy. Take the government’s filthy hands out of your money. Yeehaw! reply JKCalhoun 20 hours agorootparent> Because one day it could be you on the other side. I appreciate the sarcasm of your comment, but seriously though... if I end up with Bezos wealth, found myself on the other side, I would part with $176B if you just leave me the remaining $0.9B. I mean I might bitch about it, but, yeah, I'll survive. reply latexr 20 hours agorootparentIt makes more sense to not end up with Bezos wealth in the first place. Part with it as it reaches above your threshold, not after amassing some unspecified large multiplier. I have zero doubt there are many of us who have no desire to own that much money to the detriment of our fellow human beings, but the point is there are also many people who do not think like that and want it all. They phantasise about being able to snub other people in an undetermined (and unlikely) future when they’re rich, even as they dislike being shunned now. That’s why (to the point of the original comment) there’s polarisation of opinion even thought rationally most people should be on the same side. reply test77777g 21 hours agoparentprevIt’s around $300,000 that’s when you can get your 9% return and have roughly median income in the US. Maybe 500,000 to be safe. reply dagw 21 hours agorootparent$500k is nowhere near enough to be 'safe'. One 'unfortunate event', a couple of bad years in the market or a few years of high inflation and you'll have eaten into your capital to a point where you'll either have to drastically change your lifestyle or watch your capital dwindle away long before you die. reply test77777g 20 hours agorootparentOkay if all those things happen no amount of money will change the situation. It’s just fear mongering. reply dagw 20 hours agorootparentno amount of money will change the situation Of course it would. If you had $500M instead of $500k then none of those things would affect you in the slightest. Inflation could run at 20% for a decade and you could lose 80% of your capital in a series of bad investments, and your day to day quality of life would still be just fine. reply hyperthesis 21 hours agorootparentprevhttps://old.reddit.com/r/PovertyFIRE/ reply lifestyleg",
    "originSummary": [
      "The wealth of the world's top five billionaires has more than doubled since 2020, while the poorest 60% of the global population have lost money.",
      "The report by Oxfam highlights the widening wealth gap and predicts the possible emergence of a trillionaire in the next decade.",
      "The combined wealth of the top five billionaires has increased by $464 billion, while the total wealth of the poorest 4.77 billion people has declined by 0.2%.",
      "Oxfam proposes a wealth tax of 1% to 2% on wealth above £10 million as a solution to address the wealth imbalance, which could raise £22 billion per year for the UK."
    ],
    "commentSummary": [
      "This discussion covers multiple dimensions of wealth inequality, including the challenges faced by the poor and the ongoing debate around providing basic necessities for all individuals.",
      "The conversation also critiques capitalism and the wealthy elite, while exploring different economic ideologies and the role of luck and government intervention in wealth accumulation.",
      "Consequences of extreme wealth accumulation, the influence of the ultra-wealthy, and potential solutions like wealth taxes are also discussed, alongside the impact of automation on the economy and the concept of \"escape capital.\""
    ],
    "points": 172,
    "commentCount": 329,
    "retryCount": 0,
    "time": 1705316988
  },
  {
    "id": 39010070,
    "title": "Software Glitch Devastation: Lives Ruined by Post Office Scandal",
    "originLink": "https://www.cnn.com/2024/01/13/business/uk-post-office-fujitsu-horizon-scandal/index.html",
    "originBody": "body,h1,h2,h3,h4,h5{font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif}h1,h2,h3,h4,h5{font-weight:700}:root{--theme-background:#0c0c0c;--theme-divider:#404040;--theme-copy:#404040;--theme-copy-accent:#e6e6e6;--theme-copy-accent-hover:#ffffff;--theme-icon-color:#e6e6e6;--theme-icon-color-hover:#ffffff;--theme-ad-slot-background-color:#0c0c0c;--theme-ad-slot-text-color:#b1b1b1;--theme-ad-slot-text-hover:#ffffff;--theme-font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-searchbox-border:#b1b1b1;--theme-copy-follow:#ffffff;--theme-article-spacing-top:0px;--theme-link-color-hover:#6e6e6e;--theme-color-link:#0c0c0c;--theme-button-color:#6e6e6e;--theme-button-color-hover:#cc0000;--theme-edition-picker-link:#e6e6e6;--theme-underline-skip-ink:auto;--theme-paragraph__font-size:16px;--theme-paragraph__line-height:26px;--theme-paragraph__font-size--from-small:16px;--theme-paragraph__line-height--from-small:26px;--theme-paragraph__link-color:#0c0c0c;--theme-paragraph__link-decoration:underline;--theme-paragraph__link-decoration-color:var(--theme-color-link);--theme-paragraph__link-decoration-thickness:1px;--theme-paragraph__hover-link-decoration:none;--theme-paragraph__hover-link-offset:4px;--theme-header__hover-item-hover:var(--theme-background);--theme-header__item-link-color:#e6e6e6;--theme-header__item-link-hover-color:#ffffff;--theme-header__item-link-hover-background-color:transparent;--theme-header__mobile-dropdown-border-color:var(--theme-divider);--theme-header__mobile-dropdown-background:#0c0c0c;--theme-header__item-link-line-height:40px;--theme-header__dropdown-background:#0c0c0c;--theme-header__dropdown-border-color:var(--theme-divider);--theme-header__login-button:#ffffff;--theme-headline__font-size:24px;--theme-headline__line-height:30px;--theme-headline__text-color:#0c0c0c;--theme-headline-sponsorship__lateral-margin:0;--theme-headline__font-weight:700;--theme-headline__margin-bottom:16px;--theme-headline__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-headline__padding-bottom:48px;--theme-headline__padding-bottom-viewport-large:64px;--theme-headline__teaser-font-size:16px;--theme-headline__teaser-line-height:normal;--theme-headline__teaser-margin-top:0;--theme-headline__teaser-margin-botton:0;--theme-section-headline__font-size:36px;--theme-section-headline__line-height:42px;--theme-section-headline__text-color:#0c0c0c;--theme-section-headline__font-weight:700;--theme-section-headline__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-section-headline__margin-bottom:0;--theme-section-headline-text__margin-top:16px;--theme-section-headline-text__margin-bottom:18px;--theme-section-headline-teaser__font-size:inherit;--theme-section-headline-teaser__color:inherit;--theme-subheader-h2__font-size:24px;--theme-subheader-h3__font-size:20px;--theme-subheader-h4__font-size:18px;--theme-subheader-h5__font-size:16px;--theme-subheader-h6__font-size:14px;--theme-subheader-h2__line-height:30px;--theme-subheader-h3__line-height:26px;--theme-subheader-h4__line-height:24px;--theme-subheader-h5__line-height:22px;--theme-subheader-h6__line-height:20px;--theme-subheader__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-subheader__font-weight:700;--theme-iframe__display:block;--theme-list__link-decoration:underline;--theme-container__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-container__font-weight:400;--theme-container-color--hover:#0c0c0c;--theme-container-image-color--hover:rgba(12, 12, 12, 0.4);--theme-container-text-decoration--hover:underline;--theme-container-image-opacity--hover:0.5;--theme-container-margin-bottom-default:24px;--theme-container-margin-bottom-600:48px;--theme-container-title__border-color:#e6e6e6;--theme-container-title__border-decorator-initial-width:16px;--theme-container-title__margin-bottom:0;--theme-container-title__margin-bottom-grid-4:0;--theme-container-title__text-size:12px;--theme-container-title__arrow-color--initial:#ffffff;--theme-container-title__arrow-size:16px;--theme-container-title__arrow-top-pos:0;--theme-container-link__background-color:inherit;--theme-container-item__margin-bottom-feature-list:32px;--theme-container__margin-bottom-grid-3:24px;--theme-container__margin-bottom-feature-grid-3:24px;--theme-container-title-emphatic__font-size:24px;--theme-container-title-emphatic__line-height:30px;--theme-container-lead-title__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-container-lead-title__font-weight:700;--theme-container-lead-title__font-size:20px;--theme-container-lead-title__line-height:24px;--theme-container-lead-title-mobile__font-size:16px;--theme-header-mobile-nav-border-color:transparent;--theme-text-banner__gradient-1:#cdb6f1;--theme-text-banner__gradient-2:#e5dbf8;--theme-zone__padding-bottom-default:64px;--theme-zone__padding-bottom-small:64px;--theme-zone__margin-bottom-default:48px;--theme-zone__margin-top:-32px;--theme-zone-title__font-family:cnn_sans_display,helveticaneue,Helvetica,Arial,Utkal,sans-serif;--theme-zone-title__font-size:30px;--theme-zone-title__font-weight:700;--theme-zone-title__line-height:30px;--theme-zone-title__link-decoration:none;--theme-zone-title__hover-link-decoration:underline;--social-sharing-display:block;--social-sharing-margin-top:16px;--social-sharing-open-close-fill:#4d4d4d;--social-sharing-facebook-fill:#0c0c0c;--social-sharing-twitter-fill:#0c0c0c;--social-sharing-email-fill:#0c0c0c;--social-sharing-link-fill:#0c0c0c;--theme-disclaimer-background:#e6e6e6;--theme-disclaimer-color:#4d4d4d;--theme-disclaimer-style:normal;--theme-disclaimer-link-color:#6a29d5;--theme-disclaimer-link-weight:400;--theme-disclaimer-fontsize-sm:14px;--theme-disclaimer-fontsize-xl:16px;--theme-disclaimer-lineheight-sm:22.75px;--theme-disclaimer-lineheight-xl:25.6px;--theme-newsletter-form-disable-button:#c0c0c0;--theme-paragraph-fontsize-sm:14px;--theme-paragraph-fontsize-xl:16px;--theme-paragraph-lineheight-sm:22.75px;--theme-paragraph-lineheight-xl:25.6px;--theme-main-wrapper-rail-width:360px;--theme-main-wrapper-right-rail-width:300px;--theme-main-wrapper-column-gap-medium-width:40px;--theme-main-wrapper-column-gap-large-width:50px;--theme-primary-logo-fill:#cc0000;--theme-secondary-logo-fill:white;--theme-subheader-anchor-display:inline;--theme-primary-layout-color:#fafafa;--theme-secondary-layout-color:#fff;--theme-video-playlist-status-label-color:rgba(12, 12, 12, 0.7);--theme-primary:#008561;--theme-container-text-decoration-color--hover:var(--theme-color-link);--theme-container-title__border-decorator-color:#008561;--theme-container-title__arrow-color--hover:var(--theme-color-link);--theme-video-playlist-item-hover-color:#00c59e;--theme-footer-disclaimer-color:#ffffff;--theme-footer-disclaimer-weight:400}@media (min-width:960px){:root{--theme-headline__font-size:42px;--theme-headline__line-height:48px;--theme-section-headline__font-size:42px;--theme-section-headline__line-height:48px;--theme-section-headline__margin-bottom:16px;--theme-subheader-h2__font-size:30px;--theme-subheader-h3__font-size:24px;--theme-subheader-h4__font-size:20px;--theme-subheader-h2__line-height:36px;--theme-subheader-h3__line-height:30px;--theme-subheader-h4__line-height:26px;--theme-container-margin-bottom-600:0;--theme-container__margin-bottom-feature-grid-3:0}}@media (max-width:959px){:root{--social-sharing-display:none}}@media (min-width:480px){:root{--theme-section-headline-text__margin-bottom:20px;--theme-container__margin-bottom-grid-3:32px;--theme-container__margin-bottom-feature-grid-3:0;--theme-headline__margin-bottom:20px}}@media (min-width:1280px){:root{--theme-section-headline-text__margin-bottom:22px;--theme-headline__margin-bottom:22px}} window.env={\"AD_SLOT_CLIENT_INJECTOR_REGISTRY\":\"https://cdn.cnn.com/ads/cnn/cnn_quantum_leaf.json\",\"ADFUEL_BUSINESS_SRC\":\"/media/sites/js/bundles/business-adfuel\",\"ADFUEL_BUSINESS_EDITION_SRC\":\"/media/sites/js/bundles/business-edition-adfuel\",\"ADFUEL_CNN_SRC\":\"/media/sites/js/bundles/cnn-adfuel\",\"ADFUEL_CNN_EDITION_SRC\":\"/media/sites/js/bundles/cnn-edition-adfuel\",\"ADOBE_LAUNCH_SRC\":\"https://lightning.cnn.com/launch/7be62238e4c3/97fa00444124/launch-2878c87af5e3.min.js\",\"ADOBE_LAUNCH_BUSINESS_ENABLED_SECTIONS\":[\"business\",\"markets\"],\"ADVANCED_VIDEO_ENABLED\":true,\"AIRSHIP_APP_KEY\":\"3wrwsS87S6OIW06Lq4MVIQ\",\"AIRSHIP_ENABLED\":true,\"AIRSHIP_SRC\":\"https://aswpsdkus.com/notify/v1/ua-sdk.min.js\",\"AIRSHIP_TOKEN\":\"MTozd3J3c1M4N1M2T0lXMDZMcTRNVklROmRSb3lkd0lHZ0NHanFMeElRYVpjaGNQQVBrd2k5NGRKa1NobWR2SjBIUjg\",\"AIRSHIP_VAPID_PUBLIC_KEY\":\"BHJLBg0NxOGDHKXf0Bepz55qLpKT674Z6XiGZxVbW0p67B6cpiBzvOo2vSWTtnEGHjmILIuDmWkldwLOv4bwwz8=\",\"AIRSHIP_WEB_SITE_PUSH_ID\":\"web.com.cnn.redalert\",\"AIRSHIP_WORKER\":\"/service-worker.js\",\"AIRSHIP_CORE_ENABLED\":true,\"APPLE_NEWS_MANAGER_ENABLED\":true,\"ALERTS_HUB_ENABLED\":false,\"APPLE_NEWS_LOGO_NAME_TRAVEL\":\"https://media.cnn.com/api/v1/images/cnn/apple-news/cnn-travel-light.png\",\"APPLE_NEWS_LOGO_NAME_STYLE\":\"https://media.cnn.com/api/v1/images/cnn/apple-news/cnn-style-light.png\",\"APPLE_NEWS_LOGO_NAME_BUSINESS\":\"https://media.cnn.com/api/v1/images/cnn/apple-news/cnn-business-logo.png\",\"APPLE_NEWS_LOGO_NAME_POLITICS\":\"https://media.cnn.com/api/v1/images/cnn/apple-news/cnn-politics-light.png\",\"APPLE_NEWS_LOGO_NAME_QUOTE\":\"https://media.cnn.com/api/v1/images/cnn/apple-news/quote-light.png\",\"ARKOSE_LOGIN_KEY\":\"A81F9530-112A-47B2-BA4B-8CB41D7C6DD6\",\"ARKOSE_LOGIN_SRC\":\"https://wbd-api.arkoselabs.com/v2/A81F9530-112A-47B2-BA4B-8CB41D7C6DD6/api.js\",\"ARKOSE_NEWSLETTERS_KEY\":\"12FB7448-F055-4621-BC01-1DDF7CB3945A\",\"ARKOSE_NEWSLETTERS_SRC\":\"https://wbd-api.arkoselabs.com/v2/12FB7448-F055-4621-BC01-1DDF7CB3945A/api.js\",\"ARKOSE_REGISTRATION_KEY\":\"95218C8B-B84E-413C-B875-785B35F92134\",\"ARKOSE_REGISTRATION_SRC\":\"https://wbd-api.arkoselabs.com/v2/95218C8B-B84E-413C-B875-785B35F92134/api.js\",\"AUTO_REFRESH_INTERVAL\":\"20\",\"BREAKING_NEWS_BANNER_CMS_ENABLED\":true,\"BROWSI_SRC\":\"https://cdn.browsiprod.com/bootstrap/bootstrap.js\",\"NATIVO_SRC\":\"https://s.ntv.io/serve/load.js\",\"CHARTBEAT_SRC\":\"https://static.chartbeat.com/js/chartbeat_mab.js\",\"CLAY_SITE_HOSTS_MAP\":{\"cnn\":\"cms.cnn.com\"},\"CMS_EVENT_BUS_BATCH_SIZE\":\"10\",\"CNN_DATAVIZ_API\":\"https://production.dataviz.cnn.io\",\"CNN_DIGITAL_PROFILE_PUBLICIST\":\"Kamilla Rahman\",\"COLLABORATION_PORT\":\"4001\",\"COLLABORATION_SITE_HOSTS_MAP\":{\"cms.cnn.com\":\"collaboration-prod-rn12196s-cnn.content-hub.cnn-cms.com\"},\"COLLABORATION_EXCLUDED_TYPES\":[\"audio\",\"custom\",\"feed\",\"interactive\",\"livestory\",\"profile\",\"scratchpad\",\"search\",\"static\",\"unknown\",\"user_management\"],\"CONTENT_HUB_APP_VERSION\":\"v4.25.0\",\"CONTENT_HUB_ENV\":\"prod\",\"CONTENT_HUB_PROJECT_NAME\":\"content-hub\",\"CONTENT_HUB_UNIQUE_DEPLOYMENT_KEY\":\"rn12196s\",\"CONVIVA_CUSTOMER_KEY\":\"a6709203f34992a5095d2bc7ceaf2ec504f651a8\",\"DALTON_ENV\":\"production\",\"DALTON_COOKIE_VERSION\":\"v1.1\",\"DAM_API_HOST\":\"https://dam2.cms.cnn.com\",\"DAM_ACCESS_KEY\":\"b28f4002267c430b85918a3fdf75c0ea\",\"DAM_DEFAULT_PATH\":\"/stellar/prod\",\"DAM_SERVING_HOST\":\"https://media.cnn.com\",\"DALTON_API_HOST\":\"https://audience.cnn.com\",\"DALTON_TKN_HEADER_CHECK_ENABLED\":true,\"DISTROSCALE_SRC\":\"https://a.jsrdn.com/creatives/23053/cw.js\",\"EDIT_MODE_DATADOG_CLIENT_TOKEN\":\"pub2b644e04db84cf08661aa1cea78ce1cf\",\"DEDUPLICATION_ENABLED\":false,\"DIANOMI_SCRIPT_SRC\":\"https://www.dianomi.com/js/contextfeed.js\",\"DISPLAY_WORDCOUNT_ON_CARDS\":true,\"DISPLAY_VIDEO_DURATION_ON_CARDS\":true,\"ELECTION_MAP_PROOF_OF_CONCEPT_COMPONENT_ENABLED\":false,\"ENABLE_AD_LAZY_LOADING\":true,\"ENABLE_AD_FEEDBACK_DISPLAY_ADS\":true,\"ENABLE_AD_FEEDBACK_VIDEO_ADS\":true,\"ENABLE_RELEVANCE_USER_JS\":true,\"ENABLE_AUTO_REFRESH\":true,\"ENABLE_VIDEO_AUTOSTART_ON_ARTICLE\":false,\"ENABLE_VIDEO_AUTOSTART_ON_VIDEOLEAF\":true,\"ENABLE_VIDEO_AUTOSTART_ON_LIVESTORY\":false,\"ENABLE_AD_SLOT_CLIENT_INJECTOR\":true,\"ENABLE_ADFUEL\":true,\"ENABLE_ADFUEL_METRICS\":false,\"ENABLE_BROWSI\":true,\"ENABLE_NATIVO\":true,\"ENABLE_BROWSI_SERVER_AD_REGISTRIES\":true,\"ENABLE_CHARTBEAT\":true,\"ENABLE_DATADOG_TELEMETRY\":true,\"ENABLE_EXCLUDE_FEATURES\":false,\"ENABLE_GOOGLE_TAG_MANAGER\":true,\"ENABLE_UNDERSCORED_HUMAN_BOT_CONFIG\":true,\"UNDERSCORED_HUMAN_BOT_CONFIG_SRC\":\"https://www.cnn.com/cnn-underscored/prod/init.js\",\"ENABLE_PW_RESET_ARKOSE\":true,\"ENABLE_LIVE_STORY_UPDATES\":false,\"ENABLE_LOGIN_ARKOSE\":true,\"ENABLE_NEWSLETTERS_ARKOSE\":true,\"ENABLE_ONE_TAP_PLAY\":true,\"ENABLE_ONE_TAP_CAROUSEL\":true,\"ENABLE_OPENWEB\":true,\"ENABLE_OPENWEB_SSO\":true,\"ENABLE_OPENWEB_MIDPROMO\":true,\"ENABLE_PAYMENT_ARKOSE\":true,\"ENABLE_ARKOSE_DATA_EXCHANGE\":true,\"ONE_TAP_PLAYLIST_ENDPOINT\":\"https://fave.api.cnn.io/v1/video-playlist?stellarUri=\",\"ENABLE_REGISTRATION_ARKOSE\":true,\"ENABLE_SERVER_AD_REGISTRIES\":true,\"ENABLE_SOVRN\":true,\"ENABLE_TAG_MANAGER\":true,\"ENABLE_USER_CONSENT\":true,\"ENABLE_USER_FIRST_LAST_NAME\":false,\"ENABLE_USER_FIRST_LAST_NAME_UPDATES\":true,\"ENABLE_ZETA\":true,\"ENABLE_ZION\":true,\"ENABLE_ZION_ANALYTICS_CLICK_EVENTS\":true,\"ENABLE_ZION_ANALYTICS_ON_OFF_EVENTS\":true,\"ENSIGHTEN_SRC\":\"https://agility.cnn.com/turner/cnn-prod/Bootstrap.js\",\"FACEBOOK_APP_ID\":\"80401312489\",\"FAVE_TOP_PLAYER\":{\"ads\":{\"default\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"m6Np541neR\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"2iUzxPSeOP\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"5lycn5OPFj\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"ENHa1vBbDp\"}}}},\"livestory\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"N5SsGHrH8R\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"U0k3XgD9A0\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"sqKNPXeFWm\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"TBn9mv6qeq\"}}}}}},\"FAVE_MEDIA_PLAYER\":\"top\",\"FOLLOW_COOKIE_NAME\":\"cnn_follow_v1\",\"FOLLOW_FEATURE_ENABLED\":false,\"FOLLOW_AUDIENCE\":\"\",\"FOLLOW_COMPONENTS_ENABLED\":\"\",\"GIZMO_UK_SERVER_ENDPOINT\":\"/gizmo/api/1/wingman\",\"GIZMO_UK_STRIPE_PUBLISH_KEY\":\"pk_live_51IdcnkJ8No30pLfwQoIZQCXHkAv62Y0s6hjOqbhuqOUORTluS4P1wThSRlTrh9Z78Uy41mNZWWRYrOwwKBOptyTa001tdtas8n\",\"GOOGLE_TAG_MANAGER_ID\":\"GTM-KJZD388\",\"KILN_EDIT_MODE_KEYWORD\":\"edit\",\"LAZYLOAD_BUFFER_DESKTOP\":\"200\",\"LAZYLOAD_BUFFER_MOBILE\":\"400\",\"ONE_TRUST_SRC\":\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\",\"OPTIMIZELY_BASE_SRC\":\"https://cdn.optimizely.com/public/125375509/s/\",\"OPTIMIZELY_ENV\":\"prod\",\"MARKETS_QUOTES_SRC\":\"https://markets.money.cnn.com/services/api/quotehover/multiquote.asp?symb=\",\"CNN_BUSINESS_API\":\"https://api.business.cnn.io\",\"CNN_BUSINESS_MONEY_HOST\":\"https://money.cnn.com\",\"MARKETS_SEARCH_SRC\":\"https://markets.money.cnn.com/common/symbolLookup/getSymbols.asp?jsoncallback=symbolSearch&callback=symbolSearch&render=JSON&q=\",\"MEDIUM_SERVICE_ENVIRONMENT\":\"prod\",\"OPENWEB_DEFAULT_SECTIONS\":\"travel\",\"OPENWEB_LAUNCHER_SRC\":\"https://launcher.spot.im/spot/sp_hsRkxHeO\",\"OPENWEB_SSO_LAUNCHER_SRC\":\"https://launcher.spot.im/spot/sp_4hCVuB3p\",\"OPENWEB_SPOT_ID\":\"sp_hsRkxHeO\",\"OPENWEB_SSO_SPOT_ID\":\"sp_4hCVuB3p\",\"OPENWEB_PLACEMENT\":\"inline\",\"PERSONALIZED_RECIRC_API\":\"https://prod.di.api.cnn.io/recommendations\",\"PERSONALIZED_RECIRC_TENANT_ID\":\"read-next-from-article.mobileweb\",\"PRISM_APP_ID\":\"5e9f25a81c9d440000a83808\",\"PRISM_BRAND\":\"cnn\",\"PRISM_ENV\":\"prod\",\"PYMJS_SRC\":\"https://cdn.cnn.com/cnn/.e/interactive/js/lib/vendor/pym/pym.v1.min.js\",\"REGWALL_FEATURE_ENABLED\":false,\"SOVRN_SRC\":\"https://get.s-onetag.com/c15ddde9-ec7d-4a49-b8ca-7a21bc4b943b/tag.min.js\",\"SEARCH_API_ENDPOINT_URL\":\"https://search.prod.di.api.cnn.io/content\",\"SERVICE_BUILD_TYPE\":\"renderer\",\"TAG_MANAGER\":\"adobe\",\"TECH_STACK\":\"stellar2.0\",\"TOP_AD_RENDER_STICKY_TIMEOUT\":\"3000\",\"TOP_AUTH_SRC\":\"https://turnip.cdn.turner.com/top/auth/2.12.1-22/auth.min.js\",\"TOP_AUTH_ENV\":\"@top_auth_env\",\"TOP_AUTH_ECID\":\"37D8CAC3-36E0-46D9-B160-CB987896CCEF\",\"TOP_AUTH_MVPD_CONFIG_URL\":\"https://tvem.cdn.turner.com/v2/getConfig?brand=CNN&platform=web&country=US\",\"TOP_AUTH_SERVICE_APP_ID\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuZXR3b3JrIjoiY25uIiwicHJvZHVjdCI6ImNubiIsInBsYXRmb3JtIjoid2ViLXRvcDIiLCJhcHBJZCI6ImNubi1jbm4td2ViLXRvcDItOWowYnI2In0.TbUdtroeG7T1gfSTUfdobssbI8vPsAX6tFEX5KI8hcA\",\"TOP_AUTH_SOFTWARE_STATEMENT\":\"eyJhbGciOiJSUzI1NiJ9.eyJzdWIiOiIyY2QwZTZiZC01ZjFlLTRhMjItYTRhMC01Njg3YzNjOWI3NTEiLCJuYmYiOjE1MzcxOTA3NTcsImlzcyI6ImF1dGguYWRvYmUuY29tIiwiaWF0IjoxNTM3MTkwNzU3fQ.tBxO0aQhj8sy6RPiDMeThvvZgBkYRNVr1VseVCV3soJZdQJO7dWCcjeNghS8Qg2pc4u7vy6MQNtABcMU25BnCEBH8xKBf4HWb49NaFQLnmdXQULpfc1Uts5_CY0ALAtMgmfEdI_lzB9a80FuEiZ4VZcGxSpy7QTgZZivBqaq9hk71Yynhik9nsCv8pcHUKBkdq5W4lMyMGbDVGlCcHepmjj3yohzyc-4_gsfqtkaJHQBBAXSSqYVTKkg6bM-1GmKm2nBhjDBTHngM3vyA0YjpZ5dVsrGkRpGdfXLnCYB_9T91h-dYV8tle_V0HiLAn_8EVOmuQmKl7BzBJlERwo8JA\",\"TOP_AUTH_SESSION_NAME\":\"com.turner.top-2.activationRegCode\",\"TOP_FREEVIEW_SRC\":\"https://turnip.cdn.turner.com/top/freeview/2.12.1-22/freeview.min.js\",\"TOP_FREEVIEW_ENV\":\"prod\",\"TOP_FREEVIEW_SECRET_KEY\":\"hhX*-sB*YqRDpgs7RFTCacJocTFarXQf\",\"PLUS_TOP_AUTH_MVPD_CONFIG_URL\":\"https://ite.api.tvemanager.ngtv.io/v2/getConfig?brand=cnnplus&platform=web&country=US\",\"EMPLOYEE_TOP_AUTH_MVPD_CONFIG_URL\":\"https://ite.api.tvemanager.ngtv.io/v2/getConfig?brand=cnnplusee&platform=web\",\"TRINITY_CONFIGURATION.domestic.michonne.features.enableBrowsi\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableMyFinance\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableIndexExchange\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enablePrebid\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableAmazonDisplayAds\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableCep\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableIntegralAdScience\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableInViewRefresh\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableMalvertisingDetection\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableProximic\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableSourcePoint\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableBlockThrough\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableSSAI\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableHHID\":true,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableFreewheelProgrammatic\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableBrowsi\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableMyFinance\":false,\"TRINITY_CONFIGURATION.international.michonne.features.enableIndexExchange\":false,\"TRINITY_CONFIGURATION.international.michonne.features.enablePrebid\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableAmazonDisplayAds\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableCep\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableIntegralAdScience\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableInViewRefresh\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableMalvertisingDetection\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableProximic\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableSourcePoint\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableBlockThrough\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableSSAI\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableHHID\":true,\"TRINITY_CONFIGURATION.international.michonne.features.enableFreewheelProgrammatic\":true,\"TRINITY_CONFIGURATION.siteinfo.userAccountLegalDocs\":[{\"docName\":\"TOS\",\"version\":\"1.0\",\"label\":\"By clicking Register you confirm you have read and agree to our Terms and Conditions and acknowledge our Privacy Policy.\",\"type\":\"domestic\"},{\"docName\":\"TOS-Intl\",\"version\":\"1.0\",\"label\":\"By clicking Register you confirm you have read and agree to our Terms and Conditions and acknowledge our Privacy Policy.\",\"type\":\"intl\"}],\"TRINITY_CONFIGURATION.domestic.michonne.autoStartDisabledMobileSections\":[\"world\",\"weather\",\"vr\",\"us\",\"uk\",\"tennis\",\"tech\",\"success\",\"sport\",\"politics\",\"perspectives\",\"opinions\",\"olympics\",\"movies\",\"motorsport\",\"middleeast\",\"media\",\"living\",\"investing\",\"india\",\"health\",\"golf\",\"football\",\"europe\",\"entertainment\",\"energy\",\"economy\",\"china\",\"cars\",\"business-india\",\"business\",\"australia\",\"asia\",\"africa\",\"americas\"],\"TRINITY_CONFIGURATION.international.michonne.autoStartDisabledMobileSections\":[\"world\",\"weather\",\"vr\",\"us\",\"uk\",\"tennis\",\"tech\",\"success\",\"sport\",\"politics\",\"perspectives\",\"opinions\",\"olympics\",\"movies\",\"motorsport\",\"middleeast\",\"media\",\"living\",\"investing\",\"india\",\"health\",\"golf\",\"football\",\"europe\",\"entertainment\",\"energy\",\"economy\",\"china\",\"cars\",\"business-india\",\"business\",\"australia\",\"asia\",\"africa\",\"americas\"],\"TRINITY_CONFIGURATION.domestic.michonne.video.fave\":{\"adobeAnalytics\":{\"enabled\":true},\"ads\":{\"ssai\":{\"dev\":{\"clips\":{\"profile\":\"m6Np541neR\"},\"liveAuth\":{\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"profile\":\"2iUzxPSeOP\"}},\"prod\":{\"clips\":{\"profile\":\"5lycn5OPFj\"},\"liveAuth\":{\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"profile\":\"ENHa1vBbDp\"}}}},\"amazonA9\":{\"enabled\":true,\"refreshedTargetingData\":{\"timeout\":1000},\"targetingData\":{\"timeout\":500}},\"autoplayMuteEnabledPages\":{\"sections\":[\"entertainment\",\"health\",\"homepage\",\"intl_homepage\",\"opinions\",\"politics\",\"us\",\"videos\",\"vr\",\"world\"]},\"chartbeat\":{\"enabled\":true},\"conviva\":{\"applicationName\":\"CNN-FAVE\",\"custom\":{\"applicationName\":\"CNN-Web\",\"applicationNameByVertical\":{\"business\":\"CNN-Web-Business\"}},\"customerKey\":\"a6709203f34992a5095d2bc7ceaf2ec504f651a8\",\"enabled\":true,\"gatewayUrl\":\"\",\"integration\":\"conviva\"},\"cssUrl\":\"https://registry.api.cnn.io/bundles/fave/latest-4.x/css\",\"enabledPageTypes\":{\"exclude\":{\"article\":[\"studentnews\"],\"section\":[\"studentnews\"],\"video\":[\"studentnews\"]}},\"enableFaveContentXml\":true,\"freewheel\":{\"globalAdTimer\":{\"adComplete\":{\"errorCode\":{\"skip\":\"SKIP_CURRENT_AD_COMPLETE\",\"stop\":\"STOP_CURRENT_AD_COMPLETE\"},\"timeout\":30000,\"type\":\"adComplete\"},\"adWaterfall\":{\"errorCode\":{\"skip\":\"SKIP_CURRENT_AD_WATERFALL\",\"stop\":\"STOP_CURRENT_AD_WATERFALL\"},\"timeout\":30000,\"type\":\"adWaterfall\"},\"enabled\":true,\"errorInfo\":{\"skip\":\"A custom global ad timeout of {timeout} milliseconds caused the skipCurrentAd() function to be invoked. Attempt {skipCurrentAdAttempts} of {maxSkipCurrentAdAttempts}. Type: {type}\",\"stop\":\"The maximum of {maxSkipCurrentAdAttempts} skip current ad attempts has been exceeded causing the stop() function to be invoked. Timeout: {timeout} milliseconds. Type: {type}.\"},\"maxSkipCurrentAdAttempts\":0}},\"iframe\":\"\",\"injectCss\":false,\"injectorJs\":{\"featureName\":\"cnn-fave-lib\",\"source\":\"https://registry.api.cnn.io/bundles/fave/latest-4.x/js\"},\"live\":{\"enabled\":true,\"enabledLiveStreams\":[\"cvplive/cvpstream0\",\"cvplive/cvpstream1\",\"cvplive/cvpstream2\",\"cvplive/cvpstream3\",\"cvplive/cvpstream4\",\"cvplive/cnngo\",\"cvplive/cnniuk\"]},\"mediaPlayer\":\"top\",\"oneTapEnabledPages\":{\"pageTypes\":[\"section\"],\"sections\":[\"homepage\",\"intl_homepage\",\"business\",\"health\",\"opinions\",\"politics\",\"us\",\"world\"]},\"oneClickEnabledPages\":{\"pageTypes\":[\"section\"],\"sections\":[\"homepage\",\"intl_homepage\"]},\"openMeasurement\":{\"enabled\":true},\"optimizely\":{\"enabled\":true},\"player\":{\"autoplay\":{\"compatibility\":{\"testMobile\":true},\"muted\":{\"desktop\":{\"enabled\":true,\"viewportChange\":{\"pauseVideoOnViewportChange\":true,\"playerInViewportPercent\":50}},\"mobile\":{\"enabled\":true,\"viewportChange\":{\"pauseVideoOnViewportChange\":true,\"playerInViewportPercent\":50}},\"unmuteCTA\":{\"variant\":{\"shrink\":false,\"wave\":false}}}},\"autoStopLive\":{\"timeout\":1200000},\"closedCaptionsOn\":false,\"closedCaptionsThreshold\":0.2,\"maxBitrate\":\"1500000\",\"message\":{\"liveOffline\":\"The live stream went offline.Player will resume on rebroadcast.\",\"error\":\"The video player encountered an error.\"},\"poster\":{\"big\":\"768x432\",\"small\":\"640x360\",\"override\":true,\"overrideImages\":{\"big\":\"medium\",\"small\":\"small\"}},\"screenOrientationManager\":{\"fullscreenOnLandscape\":true},\"stateRemembrance\":{\"closedCaptions\":{\"enabled\":true}},\"ui\":{\"theme\":{\"adCountdown\":{\"shouldRender\":false}}},\"vr\":{\"clickAndDragCta\":{\"enabled\":true}}},\"prebid\":{\"enabled\":false},\"server\":{\"medium\":{\"enabled\":true,\"environment\":\"prod\"}},\"stellar\":{\"ads\":{\"default\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"m6Np541neR\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"2iUzxPSeOP\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"5lycn5OPFj\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"ENHa1vBbDp\"}}}},\"fastLiveStreamDesktopWeb\":{\"ssai\":{\"dev\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"jd7CwJlXEW\"}},\"environment\":\"prod\",\"prod\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"jd7CwJlXEW\"}}}},\"fastLiveStreamMobileWeb\":{\"ssai\":{\"dev\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"JEIXPY2Q3E\"}},\"environment\":\"prod\",\"prod\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"JEIXPY2Q3E\"}}}},\"livestory\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"N5SsGHrH8R\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"U0k3XgD9A0\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"sqKNPXeFWm\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"TBn9mv6qeq\"}}}}},\"fastLiveStreams\":[\"livec76319f599742ab668c8b3ba6dcfed3ce7e817ad\",\"live89dc8d181af9acac4036fff1055df79a4d4ee33d\",\"live51fd6cf689647b6d6ca0bcd2d6f4e69c30dbdc49\",\"livedbcedb554833b248c3ce8374acd2bbcd3983d7dd\"],\"mediaPlayer\":\"top\"},\"windows7PreferredFileType\":\"mp4\",\"zion\":{\"bridgeEnabled\":true,\"enabled\":true,\"enableLogging\":false,\"environment\":\"prod\"}},\"TRINITY_CONFIGURATION.international.michonne.video.fave\":{\"adobeAnalytics\":{\"enabled\":true},\"ads\":{\"ssai\":{\"dev\":{\"clips\":{\"profile\":\"TMhPsequTq\"},\"liveAuth\":{\"profile\":\"56bYhbIS7X\"},\"liveUnauth\":{\"profile\":\"56bYhbIS7X\"}},\"prod\":{\"clips\":{\"profile\":\"TMhPsequTq\"},\"liveAuth\":{\"profile\":\"56bYhbIS7X\"},\"liveUnauth\":{\"profile\":\"56bYhbIS7X\"}}}},\"amazonA9\":{\"enabled\":true,\"refreshedTargetingData\":{\"timeout\":1000},\"targetingData\":{\"timeout\":500}},\"autoplayMuteEnabledPages\":{\"sections\":[\"entertainment\",\"health\",\"homepage\",\"intl_homepage\",\"opinions\",\"politics\",\"us\",\"videos\",\"vr\",\"world\"]},\"chartbeat\":{\"enabled\":true},\"conviva\":{\"applicationName\":\"CNN-FAVE\",\"custom\":{\"applicationName\":\"CNN-Web\",\"applicationNameByVertical\":{\"business\":\"CNN-Web-Business\"}},\"customerKey\":\"a6709203f34992a5095d2bc7ceaf2ec504f651a8\",\"enabled\":true,\"gatewayUrl\":\"\",\"integration\":\"conviva\"},\"cssUrl\":\"https://registry.api.cnn.io/bundles/fave/latest-4.x/css\",\"enabledPageTypes\":{\"exclude\":{\"article\":[\"studentnews\"],\"section\":[\"studentnews\"],\"video\":[\"studentnews\"]}},\"enableFaveContentXml\":true,\"freewheel\":{\"globalAdTimer\":{\"adComplete\":{\"errorCode\":{\"skip\":\"SKIP_CURRENT_AD_COMPLETE\",\"stop\":\"STOP_CURRENT_AD_COMPLETE\"},\"timeout\":30000,\"type\":\"adComplete\"},\"adWaterfall\":{\"errorCode\":{\"skip\":\"SKIP_CURRENT_AD_WATERFALL\",\"stop\":\"STOP_CURRENT_AD_WATERFALL\"},\"timeout\":30000,\"type\":\"adWaterfall\"},\"enabled\":true,\"errorInfo\":{\"skip\":\"A custom global ad timeout of {timeout} milliseconds caused the skipCurrentAd() function to be invoked. Attempt {skipCurrentAdAttempts} of {maxSkipCurrentAdAttempts}. Type: {type}\",\"stop\":\"The maximum of {maxSkipCurrentAdAttempts} skip current ad attempts has been exceeded causing the stop() function to be invoked. Timeout: {timeout} milliseconds. Type: {type}.\"},\"maxSkipCurrentAdAttempts\":0}},\"iframe\":\"\",\"injectCss\":false,\"injectorJs\":{\"featureName\":\"cnn-fave-lib\",\"source\":\"https://registry.api.cnn.io/bundles/fave/latest-4.x/js\"},\"live\":{\"enabled\":true,\"enabledLiveStreams\":[\"cvplive/cvpstream0\",\"cvplive/cvpstream1\",\"cvplive/cvpstream2\",\"cvplive/cvpstream3\",\"cvplive/cvpstream4\",\"cvplive/cnngo\",\"cvplive/cnniuk\"]},\"mediaPlayer\":\"top\",\"oneTapEnabledPages\":{\"pageTypes\":[\"section\"],\"sections\":[\"homepage\",\"intl_homepage\",\"business\",\"health\",\"opinions\",\"politics\",\"us\",\"world\"]},\"oneClickEnabledPages\":{\"pageTypes\":[\"section\"],\"sections\":[\"homepage\",\"intl_homepage\"]},\"openMeasurement\":{\"enabled\":true},\"optimizely\":{\"enabled\":true},\"player\":{\"autoplay\":{\"compatibility\":{\"testMobile\":true},\"muted\":{\"desktop\":{\"enabled\":true,\"viewportChange\":{\"pauseVideoOnViewportChange\":true,\"playerInViewportPercent\":50}},\"mobile\":{\"enabled\":true,\"viewportChange\":{\"pauseVideoOnViewportChange\":true,\"playerInViewportPercent\":50}},\"unmuteCTA\":{\"variant\":{\"shrink\":false,\"wave\":false}}}},\"autoStopLive\":{\"timeout\":1200000},\"closedCaptionsOn\":false,\"closedCaptionsThreshold\":0.2,\"maxBitrate\":\"1500000\",\"message\":{\"liveOffline\":\"The live stream went offline.Player will resume on rebroadcast.\",\"error\":\"The video player encountered an error.\"},\"poster\":{\"big\":\"768x432\",\"small\":\"640x360\",\"override\":true,\"overrideImages\":{\"big\":\"medium\",\"small\":\"small\"}},\"screenOrientationManager\":{\"fullscreenOnLandscape\":true},\"stateRemembrance\":{\"closedCaptions\":{\"enabled\":true}},\"ui\":{\"theme\":{\"adCountdown\":{\"shouldRender\":false}}},\"vr\":{\"clickAndDragCta\":{\"enabled\":true}}},\"prebid\":{\"enabled\":true},\"server\":{\"medium\":{\"enabled\":true,\"environment\":\"prod\"}},\"stellar\":{\"ads\":{\"default\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"m6Np541neR\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"2iUzxPSeOP\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"5lycn5OPFj\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"ENHa1vBbDp\"}}}},\"fastLiveStreamDesktopWeb\":{\"ssai\":{\"dev\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"5I8NQT75Ti\"}},\"environment\":\"prod\",\"prod\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"5I8NQT75Ti\"}}}},\"fastLiveStreamMobileWeb\":{\"ssai\":{\"dev\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"NwRsq2FBUw\"}},\"environment\":\"prod\",\"prod\":{\"liveUnauth\":{\"enabled\":true,\"profile\":\"NwRsq2FBUw\"}}}},\"livestory\":{\"ssai\":{\"dev\":{\"clips\":{\"enabled\":true,\"profile\":\"N5SsGHrH8R\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"UsIeS2TKlX\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"U0k3XgD9A0\"}},\"environment\":\"prod\",\"prod\":{\"clips\":{\"enabled\":true,\"profile\":\"sqKNPXeFWm\"},\"liveAuth\":{\"enabled\":true,\"profile\":\"33hkbvnyaO\"},\"liveUnauth\":{\"enabled\":true,\"profile\":\"TBn9mv6qeq\"}}}}},\"fastLiveStreams\":[\"livec76319f599742ab668c8b3ba6dcfed3ce7e817ad\",\"live89dc8d181af9acac4036fff1055df79a4d4ee33d\",\"live51fd6cf689647b6d6ca0bcd2d6f4e69c30dbdc49\",\"livedbcedb554833b248c3ce8374acd2bbcd3983d7dd\"],\"mediaPlayer\":\"top\"},\"windows7PreferredFileType\":\"mp4\",\"zion\":{\"bridgeEnabled\":true,\"enabled\":true,\"enableLogging\":false,\"environment\":\"prod\"}},\"TRINITY_CONFIGURATION.domestic.michonne.features.enableAutoplayMuted\":false,\"TRINITY_CONFIGURATION.international.michonne.features.enableAutoplayMuted\":false,\"TRINITY_CONFIGURATION.domestic.michonne.features.enableAutoplayBlock\":false,\"TRINITY_CONFIGURATION.international.michonne.features.enableAutoplayBlock\":false,\"TRINITY_CONFIGURATION.domestic.michonne.ads.adfuelOptionsOverrides\":{\"business\":{},\"default\":{}},\"TRINITY_CONFIGURATION.international.michonne.ads.adfuelOptionsOverrides\":{\"business\":{},\"default\":{}},\"USER_CONSENT_COOKIE\":\"OptanonConsent\",\"USER_CONSENT_COOKIE_DOMAIN\":\".cnn.com\",\"USER_CONSENT_COOKIE_SAMESITE\":\"None\",\"USER_CONSENT_COOKIE_SECURE\":true,\"USER_CONSENT_CONFIRM_COOKIE\":\"OptanonAlertBoxClosed\",\"USER_CONSENT_DOM_ID\":\"3d9a6f21-8e47-43f8-8d58-d86150f3e92b\",\"USER_ACCOUNT_AVATAR_BASE_URL\":\"https://d2otbl5v981rj6.cloudfront.net/static/images/avatars/\",\"USER_ACCOUNT_ENABLED\":true,\"USER_ACCOUNT_PAYMENTS_ENABLED\":true,\"USER_ACCOUNT_RESTRICTED_VIEWS_ENABLED\":true,\"USER_SERVICES_ENABLED\":true,\"USER_ACCOUNT_ONBOARDING_ENABLED\":true,\"USER_ACCOUNT_MOTIF_ENABLED\":true,\"VIDEO_EMBED_URL\":\"https://fave.api.cnn.io/v1/fav/?video=\",\"AMP_VIDEO_EMBED_URL\":\"https://fave-api.cnn.com/v1/amp/?video=\",\"NEWSLETTER_ACQUISITION_ENABLED\":true,\"NEWSLETTER_LANDING_ACQUISITION_ENABLED\":true,\"WOPR_API_URL\":\"https://wopr.turnerapps.com\",\"ZETA_SITE_ID\":\"cnn\",\"ZETA_CLIENT_HASH_KEY\":\"16b6410431b6374e780104abb0443ca8\",\"ZETA_PARTNER_HASH_KEY\":\"34747f0775f02a6784bb965de6833e73\",\"ZETA_SHORT_NAME\":\"cnn-pixel-8786\",\"ZION_API_KEY\":\"mXFw59FFEpUNOu3aeVJChKAsqAlZ4NEf\",\"ZION_BEHAVIOURAL_ENABLED_PAGE_VARIANTS\":[\"article_leaf\",\"markets\"],\"ZION_CLICK_OBSERVED_COMPONENTS\":[\"footer\",\"gallery\",\"header\",\"related-content\",\"video\",\"image\"],\"ZION_ENV\":\"Prod\",\"ZION_ON_OFF_OBSERVED_COMPONENTS\":[\"bizdev-outbrain\",\"footer\",\"headline\",\"paragraph\",\"related-content\",\"market-tabbed-container\",\"market-fng-indicator\"],\"ZION_SRC\":\"https://z.cdp-dev.cnn.com/zion-web-client/3.0/zion-web-client.min.js\",\"ZION_TELEMETRY_ENDPOINT\":\"//zion-telemetry.api.cnn.io\",\"FAVE_SRC\":\"https://registry.api.cnn.io/bundles/fave/latest-4.x/js\",\"PARSELY_SRC\":\"@parsely_src\",\"SSE_HOST\":\"https://sse01.cnn.com\",\"UNDERSCORED_GET_AFFILIATE_TAG_API_URL\":\"https://bvrmvkrkie.execute-api.us-east-1.amazonaws.com/v1/get-affiliate-tag\",\"UNDERSCORED_API_HOST\":\"web-prod-ursd0001\",\"UNDERSCORED_ACCESS_KEY\":\"produnderscoredaccesskey\",\"MOBILE_GOOGLE_AD_ACCOUNT_ID\":\"8663477\",\"PUBLIC_GOOD_WIDGET_ENABLED\":true,\"PUBLIC_GOOD_WIDGET_SRC\":\"https://assets.publicgood.com/pgm/v1/dpg.js\",\"PUBLIC_GOOD_WIDGET_CONFIG_CLASS\":\"pgs-dpg-btn\",\"PUBLIC_GOOD_WIDGET_CONFIG_PARTNER_ID\":\"cnn\",\"PUBLIC_GOOD_WIDGET_CONFIG_TARGET_TYPE\":\"campaign\",\"MOBILE_WATCH_NEXT_URL\":\"https://prod.di.api.cnn.io/recs/v1/WatchNextVideo\",\"MOBILE_SUPPORTED_SECTIONS\":[\"opinions\",\"world\",\"us\",\"politics\",\"business\",\"health\",\"entertainment\",\"travel\",\"sport\",\"style\",\"videos\",\"weather\",\"homepage\",\"tv\",\"series\",\"wbd\",\"yourcnn\",\"bleacherreport\"],\"ENABLE_AMP_EXCLUDE_TEST\":true,\"AMP_EXCLUDE_SECTIONS\":\"[]\",\"AMP_EXCLUDE_PAGE_TYPES\":\"article\",\"FORCE_WEBP_IMAGES\":true,\"POLITICS_ELECTION_CONTEXT_FEED\":\"https://politics.api.cnn.io/available-races/all/index.json\",\"POLITICS_FEATURE_FLAG_BASEPATH\":\"https://politics-static.cnn.io/2021/feature-flags\",\"POLITICS_FEED_URL_BASEPATH\":\"https://politics.api.cnn.io\",\"POLITICS_MAP_URL_BASEPATH\":\"https://atlas.cnn.io/us\",\"POLITICS_STATIC_ASSETS_BASEPATH\":\"https://politics-static.cnn.io/\",\"RTCCONFIG_APS_PUB_ID\":\"3159\",\"CNN_DATA_API\":\"https://data.api.cnn.io\",\"PLEDGE_DONATION_ENABLED\":true,\"PLEDGE_DONATION_SRC\":\"https://www.pledge.to/assets/widget.js\",\"PLEDGE_DONATION_CONFIG_CLASS\":\"plg-donate\"}UK postal scandal: How a software glitch and a centuries-old British company ruined peoples livesCNN Business window.CNN = window.CNN || {}; window.CNN.ads = {\"browsiRegistry\":[{\"rktr_deployed_date\":\"2023-08-02 11:02:23\",\"rktr_slot_id\":\"page\",\"rktr_id\":\"cnn_browsi_leaf\",\"gpt_id\":\"8663477\",\"site\":\"cnn\",\"root\":\"CNN\",\"targeting\":[[\"appname\",[\"browsi\"]]],\"child_directed_treatment\":false},{\"rktr_slot_id\":\"ad_browsi_atf_01\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320],[\"fluid\"]],\"targeting\":[[\"pos\",[\"browsi_atf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_02\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_02\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_03\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_03\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_04\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_04\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_05\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_05\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_06\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_06\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_07\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_07\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_08\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_08\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_09\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_09\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]},{\"rktr_slot_id\":\"ad_browsi_atf_10\",\"rktr_ad_id\":\"CNN\",\"sizes\":[[2,2],[300,250],[320,320]],\"targeting\":[[\"pos\",[\"browsi_atf_10\"]]],\"responsive\":[[[\"1024\",\"0\"],[\"suppress\"]],[[\"782\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"2\",\"2\"]]]]}],\"lazyLoad\":true,\"registry\":[{\"rktr_deployed_date\":\"2024-01-15 07:20:33\",\"rktr_slot_id\":\"page\",\"rktr_id\":\"cnn_leaf\",\"gpt_id\":\"8663477\",\"site\":\"cnn_2\",\"root\":\"CNN\",\"child_directed_treatment\":false,\"targeting\":[]},{\"rktr_slot_id\":\"ad_bnr_atf_01\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[1,1],[1,2],[320,50],[728,90],[970,66],[970,90],[970,250],[\"fluid\"]],\"hasInViewRefresh\":true,\"inViewRefreshCount\":\"10\",\"inViewRefreshInterval\":\"35\",\"targeting\":[[\"pos\",[\"bnr_atf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"970\",\"250\"],[\"970\",\"90\"],[\"970\",\"66\"],[\"728\",\"90\"],[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]],[[\"728\",\"0\"],[[\"728\",\"90\"],[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]],[[\"0\",\"0\"],[[\"320\",\"50\"],[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]]]},{\"rktr_slot_id\":\"ad_rect_atf_01\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[1,1],[1,2],[2,2],[300,250],[300,600],[300,850],[300,1050],[320,320],[\"fluid\"]],\"hasInViewRefresh\":true,\"inViewRefreshCount\":\"10\",\"inViewRefreshInterval\":\"35\",\"targeting\":[[\"pos\",[\"rect_atf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"300\",\"1050\"],[\"300\",\"850\"],[\"300\",\"600\"],[\"300\",\"250\"],[\"1\",\"2\"],[\"fluid\"]]],[[\"728\",\"0\"],[[\"300\",\"1050\"],[\"300\",\"850\"],[\"300\",\"600\"],[\"300\",\"250\"],[\"1\",\"2\"],[\"fluid\"]]],[[\"0\",\"0\"],[[\"2\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]]]},{\"rktr_slot_id\":\"ad_rect_btf_01\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[1,1],[1,2],[300,250],[300,600],[320,320]],\"hasInViewRefresh\":true,\"inViewRefreshCount\":\"10\",\"inViewRefreshInterval\":\"35\",\"targeting\":[[\"pos\",[\"rect_btf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"300\",\"600\"],[\"300\",\"250\"],[\"fluid\"]]],[[\"728\",\"0\"],[[\"300\",\"600\"],[\"300\",\"250\"],[\"fluid\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"1\",\"1\"]]]]},{\"rktr_slot_id\":\"ad_nat_btf_01\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[1,1],[1,2],[300,250],[780,175],[\"fluid\"]],\"targeting\":[[\"pos\",[\"nat_btf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"780\",\"175\"],[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]],[[\"728\",\"0\"],[[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]],[[\"0\",\"0\"],[[\"1\",\"1\"],[\"fluid\"]]]]},{\"rktr_slot_id\":\"ad_rect_btf_02\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[1,1],[1,2],[300,250],[300,600],[320,320],[\"fluid\"]],\"hasInViewRefresh\":true,\"inViewRefreshCount\":\"10\",\"inViewRefreshInterval\":\"35\",\"targeting\":[[\"pos\",[\"rect_btf_02\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"300\",\"600\"],[\"300\",\"250\"]]],[[\"728\",\"0\"],[[\"320\",\"320\"],[\"300\",\"600\"],[\"300\",\"250\"]]],[[\"0\",\"0\"],[[\"320\",\"320\"],[\"300\",\"250\"],[\"1\",\"2\"],[\"1\",\"1\"],[\"fluid\"]]]]},{\"rktr_slot_id\":\"ad_ns_atf_01\",\"rktr_ad_id\":\"CNN/business/leaf/bst\",\"sizes\":[[120,60]],\"targeting\":[[\"pos\",[\"ns_atf_01\"]]],\"responsive\":[[[\"1024\",\"0\"],[[\"120\",\"60\"]]],[[\"728\",\"0\"],[[\"120\",\"60\"]]],[[\"0\",\"0\"],[[\"120\",\"60\"]]]]}],\"registryPath\":\"domestic/business/leaf/bst\",\"showAds\":true,\"rktr_ad_id\":\"CNN/business/leaf/bst\"}; window.CNN.cep_topics = {\"cep_brsf\":[\"15LP\",\"15P9\"],\"cep_iabt\":[\"14TL\",\"159T\",\"15H7\",\"14V0\",\"14WQ\",\"15H3\",\"14VG\",\"1597\",\"15B0\",\"14W0\",\"14VQ\",\"14VF\",\"14VD\",\"14VS\"],\"cep_sent\":[\"16B6\"],\"cep_tags\":[\"2PCG\",\"2PCF\",\"2JP9\",\"2JP8\",\"2PCD\",\"4YW\",\"FBL\",\"CBXM\",\"5GB\",\"7PS\",\"3VT\",\"6GL\",\"KKV\",\"6JP\",\"6HR\",\"9LB\",\"7YM\",\"21R\",\"9HJ\",\"4CQ\",\"4CH\",\"F6N\",\"936\",\"3HC\",\"21X\",\"53T\",\"9HC\",\"80N\",\"CS1\",\"220\",\"7YP\",\"868\",\"534\",\"5FT\",\"DJW\",\"4ML\"],\"source_id\":\"article_clr6c1fcz000s45nw4w1kgu6c\",\"short_source_id\":\"ar_clr6c1fcz000s45nw4w1kgu6c\"}; window.CNN.contentModel = { _wedgerId: '', _wedgerLegacyCmsId: '', analytics: { authors: 'Anna Cooban', chartbeat: { sections: 'business' } }, author: 'Anna Cooban', branding: { key: '', spec: '', displayName: '' }, canonicalUrl: 'https://www.cnn.com/2024/01/13/business/uk-post-office-fujitsu-horizon-scandal/index.html', pageStellarId: 'L19wYWdlcy9jbHI2YzFmY3owMDBzNDVudzR3MWtndTZj', firstCanonicalUrl: 'https://www.cnn.com/2024/01/13/business/uk-post-office-fujitsu-horizon-scandal/index.html', cmsId: document.querySelector('html').dataset.uri, edition: false, environment: 'prod', headline: 'Prison. Bankruptcy. Suicide. How a software glitch and a centuries-old British company ruined lives', isSponsorship: false, last_updated_date: '2024-01-13T08:00:25.495Z', pageType: 'article', pageTags: '', published_date: '2024-01-13T08:00:25.495Z', section: 'business', subsection: '', subsubsection: '', sourceId: 'cms.cnn.com/_pages/clr6c1fcz000s45nw4w1kgu6c@published', techStack: 'stellar2.0', templateType: 'article_leaf', vertical: 'business' }; window.CNN.omniture = { ...(window.CNN.omniture || {}), branding_content_page: '', cap_author: 'Anna Cooban', cap_content_type: 'article_leaf', content_id: document.querySelector('html').dataset.uri, content_type: 'adbp:none', gallery_name: '', headline: 'Prison. Bankruptcy. Suicide. How a software glitch and a centuries-old British company ruined lives', last_updated_date: '2024/01/13', publish_date: '2024/01/13', rs_flag: 'prod', section: [ 'business', '', '' ], source_id: 'cms.cnn.com/_pages/clr6c1fcz000s45nw4w1kgu6c@published', template_type: 'article_leaf', video_opportunity: document.querySelectorAll('*[data-uri*=\"/_components/video-resource/\"]').length, cap_genre: '', cap_topic: '', screen_state: 'default' }; window.CNN.metadata = {\"content\":{\"author\":[\"Anna Cooban\"],\"branding\":[],\"byline\":\"By Anna Cooban, CNN\",\"canonicalUrl\":\"https://www.cnn.com/2024/01/13/business/uk-post-office-fujitsu-horizon-scandal/index.html\",\"firstCanonicalUrl\":\"https://www.cnn.com/2024/01/13/business/uk-post-office-fujitsu-horizon-scandal/index.html\",\"headline\":\"Prison. Bankruptcy. Suicide. How a software glitch and a centuries-old British company ruined lives\",\"identifiers\":{\"pageStellarId\":\"L19wYWdlcy9jbHI2YzFmY3owMDBzNDVudzR3MWtndTZj\"},\"pageType\":\"article\",\"pageVariant\":\"article_leaf\",\"publishDateCreated\":\"2024-01-09T12:33:08.108Z\",\"publishDatePublished\":\"2024-01-13T08:00:25.495Z\",\"publishDateModified\":\"2024-01-13T08:00:25.495Z\",\"section\":[\"business\"],\"topics\":{\"cepBrsf\":[\"15LP\",\"15P9\"],\"cepIabt\":[\"14TL\",\"159T\",\"15H7\",\"14V0\",\"14WQ\",\"15H3\",\"14VG\",\"1597\",\"15B0\",\"14W0\",\"14VQ\",\"14VF\",\"14VD\",\"14VS\"],\"cepOther\":[\"2PCG\",\"2PCF\",\"2JP9\",\"2JP8\",\"2PCD\",\"4YW\",\"FBL\",\"CBXM\",\"5GB\",\"7PS\",\"3VT\",\"6GL\",\"KKV\",\"6JP\",\"6HR\",\"9LB\",\"7YM\",\"21R\",\"9HJ\",\"4CQ\",\"4CH\",\"F6N\",\"936\",\"3HC\",\"21X\",\"53T\",\"9HC\",\"80N\",\"CS1\",\"220\",\"7YP\",\"868\",\"534\",\"5FT\",\"DJW\",\"4ML\"],\"cepSent\":[\"16B6\"],\"cnnSections\":[\"business\"],\"tags\":[]},\"vertical\":\"business\",\"leadingMediaType\":\"image\",\"image\":[{\"title\":\"post office london 011224\",\"caption\":\"A Post Office in central London seen in January 2024\",\"credit\":\"Aaron Chown/PA Images/Getty Images\",\"identifiers\":{\"damId\":\"image_b19f4523-3927-47ba-9fa4-ed5fe1f8127c\"},\"source\":\"Getty\",\"url\":\"https://media.cnn.com/api/v1/images/stellar/prod/240112105000-post-office-london-011224.jpg?c=original\"},{\"title\":\"02 mr bates vs the post office 011124\",\"caption\":\"The ITV network drama \\\"Mr Bates vs The Post Office' follows British sub-postmasters' tireless campaign for justice.\",\"credit\":\"ITV\",\"identifiers\":{\"damId\":\"image_58ceef02-594a-4308-823d-82cddcace0c2\"},\"source\":\"ITV\",\"url\":\"https://media.cnn.com/api/v1/images/stellar/prod/240111123858-02-mr-bates-vs-the-post-office-011124.jpg?c=original\"},{\"title\":\"Jo Hamilton 011224\",\"caption\":\"Jo Hamilton outside the Royal Courts of Justice in London in 2021 after her conviction was overturned\",\"credit\":\"Jonathan Wells\",\"identifiers\":{\"damId\":\"image_7232a464-89e6-466b-a89e-b03726f47f51\"},\"source\":\"Jonathan Wells\",\"url\":\"https://media.cnn.com/api/v1/images/stellar/prod/240112115159-jo-hamilton-011224.jpg?c=original\"},{\"title\":\"fujitsu 011124\",\"caption\":\"The offices of Japanese technology firm Fujitsu in Bracknell, England, seen on January 10, 2024\",\"credit\":\"Leon Neal/Getty Images\",\"identifiers\":{\"damId\":\"image_17f3f0b3-d32c-4ca2-8c1b-75c76f18310e\"},\"source\":\"Getty\",\"url\":\"https://media.cnn.com/api/v1/images/stellar/prod/240111112707-fujitsu-011124.jpg?c=original\"},{\"title\":\"Siema Kamran\",\"caption\":\"Siema Kamran, right, and her husband Kamran Ashraf. Ashraf was wrongfully convicted and sentenced to nine months in prison in 2004.\",\"credit\":\"Courtesy of Siema Kamran\",\"identifiers\":{\"damId\":\"image_f5b9da73-75d5-43e8-8743-4fa2c39fb1a6\"},\"source\":\"Courtesy of Siema Kamran\",\"url\":\"https://media.cnn.com/api/v1/images/stellar/prod/240112035027-siema-kamran.jpg?c=original\"}]}} window.ntvConfig = window.ntvConfig || {}; window.ntvConfig.keyValues = { ...(window.ntvConfig.keyValues || {}),'section': `business`,'subsection': ``,'page_type': `article_leaf`,'spec': ``,'cep_brsf': `15LP,15P9`,'cep_iabt': `14TL,159T,15H7,14V0,14WQ,15H3,14VG,1597,15B0,14W0,14VQ,14VF,14VD,14VS`,'cep_sent': `16B6`,'cep_tags': `2PCG,2PCF,2JP9,2JP8,2PCD,4YW,FBL,CBXM,5GB,7PS,3VT,6GL,KKV,6JP,6HR,9LB,7YM,21R,9HJ,4CQ,4CH,F6N,936,3HC,21X,53T,9HC,80N,CS1,220,7YP,868,534,5FT,DJW,4ML`,}; window.CNN.Zion = { ...(window.CNN.Zion || {}),'apiKey': `mXFw59FFEpUNOu3aeVJChKAsqAlZ4NEf`,'environmentType': `Prod`,'sourceId': `cms.cnn.com/_pages/clr6c1fcz000s45nw4w1kgu6c@published`,}; window.CNN.helpers = { PAGE_VARIANTS: {\"ARTICLE_FEATURE\":\"article_feature\",\"ARTICLE_FULLWIDTH\":\"article_fullwidth\",\"ARTICLE\":\"article_leaf\",\"GALLERY_UNFURLED\":\"gallery_unfurled\",\"GALLERY\":\"gallery_leaf\",\"HOMEPAGE\":\"landing_homepage\",\"LIVESTORY\":\"article_livestory\",\"TV_CHANNELS\":\"tv_channels\",\"PROFILE\":\"profile\",\"SECTION\":\"landing_section\",\"TVE_FILM\":\"detail\",\"TVE_SERIES\":\"series\",\"TVE_STREAM\":\"network\",\"ELECTION\":\"election\",\"MARKETS\":\"markets\",\"TVE_BROWSE\":\"browse\",\"VIDEO\":\"video_leaf\",\"VIDEO_SHOW\":\"video_show\",\"UNKNOWN\":\"\"}, PAGE_TYPES: {\"ARTICLE\":\"article\",\"AUDIO\":\"audio\",\"CUSTOM\":\"custom\",\"FEED\":\"feed\",\"GALLERY\":\"gallery\",\"INTERACTIVE\":\"interactive\",\"LIVESTORY\":\"live-story\",\"NEWSLETTER_LANDING_PAGE\":\"newsletter-landing-page\",\"PROFILE\":\"profile\",\"SCRATCHPAD\":\"scratchpad\",\"SEARCH\":\"search\",\"SECTION\":\"section\",\"STATIC\":\"static\",\"TVE\":\"tve\",\"UNKNOWN\":\"\",\"USER_MANAGEMENT\":\"user-management\",\"VERTICAL_VIDEO\":\"vertical-video\",\"VIDEO\":\"video\"}, SECTIONS: {\"US\":\"us\",\"WORLD\":\"world\",\"POLITICS\":\"politics\",\"BUSINESS\":\"business\",\"OPINIONS\":\"opinions\",\"HEALTH\":\"health\",\"ENTERTAINMENT\":\"entertainment\",\"STYLE\":\"style\",\"TRAVEL\":\"travel\",\"HOMEPAGE\":\"homepage\",\"SPORTS\":\"sport\",\"UNDERSCORED\":\"cnn-underscored\",\"WEATHER\":\"weather\",\"PHOTOS\":\"photos\",\"PROFILES\":\"profiles\",\"TV\":\"tv\",\"LIVING\":\"living\",\"NEWSLETTERS\":\"newsletters\",\"UNKNOWN\":\"\"}, isSection: function isSection(sections) { return (!Array.isArray(sections) ? [sections] : sections).includes( window.CNN.contentModel?.section || window.CNN.helpers?.SECTIONS.UNKNOWN ); }, isPageVariant: function isPageVariant(pageVariants) { return (!Array.isArray(pageVariants) ? [pageVariants] : pageVariants).includes( window.CNN.contentModel?.templateType || window.CNN.helpers?.PAGE_VARIANTS.UNKNOWN ); }, isPageType: function isPageType(pageTypes) { return (!Array.isArray(pageTypes) ? [pageTypes] : pageTypes).includes( window.CNN.contentModel?.pageType || window.CNN.helpers?.PAGE_TYPES.UNKNOWN ); }, isEditionPage: function isEditionPage() { return window.CNN.contentModel?.edition; }, addScriptTag: function addScriptTag(options = {}, prependToBody = false) { const script = document.createElement('script'); const opts = { language: 'javascript', type: 'text/javascript', ...options }; Object.keys(opts).forEach((key) => { if (key === 'data') { const { data } = opts; Object.keys(data).forEach((dataKey) => { if (data[dataKey]) { script.setAttribute(`data-${dataKey}`, data[dataKey]); } }); } else { script[key] = opts[key]; } }); if (prependToBody) { document.body.prepend(script); } else { document.head.append(script); } return script; }, getAdfuelSrc: (body = false) => { let src; if (window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.BUSINESS)) { src = window.CNN.helpers.isEditionPage() ? window.env.ADFUEL_BUSINESS_EDITION_SRC : window.env.ADFUEL_BUSINESS_SRC; } else { src = window.CNN.helpers.isEditionPage() ? window.env.ADFUEL_CNN_EDITION_SRC : window.env.ADFUEL_CNN_SRC; } return body ? `${src}-body.min.js` : `${src}.min.js`; } };(function() { function getPath() { const domain = window.location.hostname; const metaURL = document.querySelector('[rel=canonical]').getAttribute?.('href'); try { const canURL = new URL(metaURL); return domain + canURL.pathname; } catch (e) { // we should never run into this situation where the canonical // url is missing in the meta tag but just in case return domain + document.location.pathname; } } function getDomain() { var domain = !window.CNN.contentModel.edition ? 'cnn.com' : 'edition.cnn.com' if (window.CNN.omniture.rs_flag != \"prod\") { domain = \"dev.\" + domain; } return domain; } function getTitle(headline = '') { const isHomepage = window.CNN?.contentModel?.section === 'homepage'; return isHomepage ? headline.replace(' Desktop', '').replace(' Mobile', '') : headline; } var _sf_async_config = window._sf_async_config = (window._sf_async_config || {}); _sf_async_config.uid = 37612; _sf_async_config.domain = getDomain(); _sf_async_config.sections = window.CNN.contentModel.vertical; _sf_async_config.authors = window.CNN.omniture.cap_author; _sf_async_config.title = getTitle(window.CNN.omniture.headline); _sf_async_config.flickerControl = false; _sf_async_config.path = getPath(); })();(function(){ function preloadScript(srcipt) { try { const preload = document.createElement('link'); preload.href = srcipt.src; preload.rel = \"preload\"; preload.as=\"script\" preload.type=\"application/x-javascript\" document.head.appendChild(preload); } catch(e) { console.error('ExternalScripts: error preloading script', e); } }; preloadScript({ src: (function(){ try { return window.env.ADOBE_LAUNCH_SRC; } catch (e) { console.error('external-scripts: error generating tag-manager preload', e); } })() }); preloadScript({ src: (function(){ try { return window.CNN.helpers.getAdfuelSrc(); } catch (e) { console.error('external-scripts: error generating adfuel preload', e); } })() }); preloadScript({ src: (function(){ try { return window.CNN.helpers.getAdfuelSrc(true); } catch (e) { console.error('external-scripts: error generating adfuel preload', e); } })() }); }()) window.CNN=Object.assign(window.CNN || {}, { \"Features\": { \"enableUserConsent\": true } }); window.WM=Object.assign(window.WM || {}, { \"UserConsentConfig\": { \"cookieDomain\": \".cnn.com\", \"cookieSameSite\": \"None\", \"cookieSecure\": true, \"domId\": \"3d9a6f21-8e47-43f8-8d58-d86150f3e92b\" } }); window.zeta=Object.assign(window.zeta || {}, { \"site_id\": \"cnn\", \"client_hash_key\": \"16b6410431b6374e780104abb0443ca8\", \"partner_hash_key\": \"34747f0775f02a6784bb965de6833e73\", \"tag_short_name\": \"cnn-pixel-8786\" });(function(){ function addScript({ async, defer, name, src, ucStates, id, data }) { try { if (src && typeof src === 'string') { if (ucStates && ucStates.length) { WM.UserConsent.addScript({ src, async, defer }, ucStates); } else { const script = document.createElement('script'); script.src = src; script.dataset.uid = name; script.async = async; script.defer = defer; script.onload = () => {window.dispatchEvent(new CustomEvent(name+'.loaded'));}; if (id) { script.id = id; } if (data && typeof data === 'object') { Object.keys(data).forEach(key => script.dataset[key] = data[key]); } document.head.appendChild(script); } } } catch(e) { console.error('ExternalScripts: error adding script \"' + name + '\"', e); } }; //snippet: user-consent document.addEventListener('oneTrustBlocked', function (event) { if (event && event.detail && event.detail.region !== 'global') { const bd = document.getElementsByTagName('body')[0]; window.location.assign('/browser-blocked'); if (bd) { bd.style.display = 'none'; } } }, false); !function(){\"use strict\";var e,t,n,s,o,i,r,a,c,l,u,d,p,g,S,h;!function(e){e.STUB=\"stub\",e.LOADING=\"loading\",e.LOADED=\"loaded\",e.ERROR=\"error\"}(e||(e={})),function(e){e.VISIBLE=\"visible\",e.HIDDEN=\"hidden\",e.DISABLED=\"disabled\"}(t||(t={}));class E{constructor(e){this.eventQueue=new Map,this.queueNumber=1e3,this.cmpApiContext=e;try{let e=window.__gpp(\"events\")||[];for(var t=0;t{n.callback({eventName:e,listenerId:s,data:t,pingData:{gppVersion:this.cmpApiContext.gppVersion,cmpStatus:this.cmpApiContext.cmpStatus,cmpDisplayStatus:this.cmpApiContext.cmpDisplayStatus,apiSupport:this.cmpApiContext.apiSupport,currentAPI:this.cmpApiContext.currentAPI,cmpId:this.cmpApiContext.cmpId,cmpVersion:this.cmpApiContext.cmpVersion}})}))}clear(){this.queueNumber=1e3,this.eventQueue.clear()}get size(){return this.eventQueue.size}events(){let e=[];return this.eventQueue.forEach(((t,n)=>{e.push({id:n,callback:t.callback,parameter:t.parameter})})),e}}class C extends Error{constructor(e){super(e),this.name=\"DecodingError\"}}class f{static encode(e,t){let n=[];if(e>=1)for(n.push(1);e>=2*n[0];)n.unshift(2*n[0]);let s=\"\";for(let t=0;t=o?(s+=\"1\",e-=o):s+=\"0\"}for(;s.length0;)e+=\"0\";for(;e.length%6>0;)e+=\"0\";return e}}class _{static encode(e){let t=[];if(e>=1&&(t.push(1),e>=2)){t.push(2);let n=2;for(;e>=t[n-1]+t[n-2];)t.push(t[n-1]+t[n-2]),n++}let n=\"1\";for(let s=t.length-1;s>=0;s--){let o=t[s];e>=o?(n=\"1\"+n,e-=o):n=\"0\"+n}return n}static decode(e){if(!/^[0-1]*$/.test(e)||e.lengthe-t));let t=[],n=0,s=0;for(;se-t)))}}class P extends N{constructor(e,t){super(),this.bitStringLength=e,this.setValue(t)}encode(){return f.encode(this.value,this.bitStringLength)}decode(e){this.value=f.decode(e)}substring(e,t){return e.substring(t,t+this.bitStringLength)}}!function(e){e.ID=\"Id\",e.VERSION=\"Version\",e.SECTION_IDS=\"SectionIds\"}(n||(n={}));class y{constructor(e,t){this.fields=e,this.fieldOrder=t}hasField(e){return this.fields.has(e)}getFieldValue(e){return this.fields.has(e)?this.fields.get(e).getValue():null}setFieldValue(e,t){if(!this.fields.has(e))throw new Error(e+\" not found\");this.fields.get(e).setValue(t)}getFieldOrder(){return this.fieldOrder}encodeToBitString(){let e=\"\";for(let t=0;t0&&this.decode(e)}encode(){let e=this.encodeToBitString();return this.base64UrlEncoder.encode(e)}decode(e){let t=this.base64UrlEncoder.decode(e);this.decodeFromBitString(t)}getId(){return D.ID}getName(){return D.NAME}}D.ID=3,D.VERSION=1,D.NAME=\"header\";class R extends N{constructor(e){super(),this.setValue(e)}encode(){return A.encode(this.value)}decode(e){this.value=A.decode(e)}substring(e,t){return e.substring(t,t+1)}}class v{static encode(e){return e?f.encode(Math.round(e.getTime()/100),36):f.encode(0,36)}static decode(e){if(!/^[0-1]*$/.test(e)||36!==e.length)throw new C(\"Undecodable Datetime '\"+e+\"'\");return new Date(100*f.decode(e))}}class w extends N{constructor(e){super(),this.setValue(e)}encode(){return v.encode(this.value)}decode(e){this.value=v.decode(e)}substring(e,t){return e.substring(t,t+36)}}class V{static encode(e,t){let n=\"\";for(let t=0;tt&&(n=n.slice(0,t)),super.setValue([...n])}}class U extends N{constructor(e){super(),this.numElements=e.length,this.setValue(e)}encode(){return V.encode(this.value,this.numElements)}decode(e){this.value=V.decode(e)}substring(e,t){return e.substring(t,t+this.numElements)}getValue(){return[...super.getValue()]}setValue(e){let t=[...e];for(let e=t.length;ethis.numElements&&(t=t.slice(0,this.numElements)),super.setValue(t)}}class k{static encode(e,t){for(;e.length=65))throw new m(\"Unencodable FixedString '\"+e+\"'\");n+=f.encode(e.charCodeAt(t)-65,6)}}return n}static decode(e){if(!/^[0-1]*$/.test(e)||e.length%6!=0)throw new C(\"Undecodable FixedString '\"+e+\"'\");let t=\"\";for(let n=0;n0){let e=0;for(let s=0;se-t));let t=[],n=0;for(;ne-t)))}}class B extends N{constructor(e){super(),this.setValue(e)}encode(){let e=this.value.length>0?this.value[this.value.length-1]:0,t=G.encode(this.value),n=e;if(t.lengthe-t)))}}!function(e){e.VERSION=\"Version\",e.CREATED=\"Created\",e.LAST_UPDATED=\"LastUpdated\",e.CMP_ID=\"CmpId\",e.CMP_VERSION=\"CmpVersion\",e.CONSENT_SCREEN=\"ConsentScreen\",e.CONSENT_LANGUAGE=\"ConsentLanguage\",e.VENDOR_LIST_VERSION=\"VendorListVersion\",e.POLICY_VERSION=\"PolicyVersion\",e.IS_SERVICE_SPECIFIC=\"IsServiceSpecific\",e.USE_NON_STANDARD_STACKS=\"UseNonStandardStacks\",e.SPECIAL_FEATURE_OPTINS=\"SpecialFeatureOptins\",e.PURPOSE_CONSENTS=\"PurposeConsents\",e.PURPOSE_LEGITIMATE_INTERESTS=\"PurposeLegitimateInterests\",e.PURPOSE_ONE_TREATMENT=\"PurposeOneTreatment\",e.PUBLISHER_COUNTRY_CODE=\"PublisherCountryCode\",e.VENDOR_CONSENTS=\"VendorConsents\",e.VENDOR_LEGITIMATE_INTERESTS=\"VendorLegitimateInterests\",e.PUBLISHER_RESTRICTIONS=\"PublisherRestrictions\",e.PUBLISHER_PURPOSES_SEGMENT_TYPE=\"PublisherPurposesSegmentType\",e.PUBLISHER_CONSENTS=\"PublisherConsents\",e.PUBLISHER_LEGITIMATE_INTERESTS=\"PublisherLegitimateInterests\",e.NUM_CUSTOM_PURPOSES=\"NumCustomPurposes\",e.PUBLISHER_CUSTOM_CONSENTS=\"PublisherCustomConsents\",e.PUBLISHER_CUSTOM_LEGITIMATE_INTERESTS=\"PublisherCustomLegitimateInterests\",e.VENDORS_ALLOWED_SEGMENT_TYPE=\"VendorsAllowedSegmentType\",e.VENDORS_ALLOWED=\"VendorsAllowed\",e.VENDORS_DISCLOSED_SEGMENT_TYPE=\"VendorsDisclosedSegmentType\",e.VENDORS_DISCLOSED=\"VendorsDisclosed\"}(s||(s={}));class W extends I{pad(e){for(;e.length%24>0;)e+=\"0\";return e}}class H extends M{constructor(e){let t=new Map,n=new Date;t.set(s.VERSION.toString(),new P(6,H.VERSION)),t.set(s.CREATED.toString(),new w(n)),t.set(s.LAST_UPDATED.toString(),new w(n)),t.set(s.CMP_ID.toString(),new P(12,0)),t.set(s.CMP_VERSION.toString(),new P(12,0)),t.set(s.CONSENT_SCREEN.toString(),new P(6,0)),t.set(s.CONSENT_LANGUAGE.toString(),new x(2,\"EN\")),t.set(s.VENDOR_LIST_VERSION.toString(),new P(12,0)),t.set(s.POLICY_VERSION.toString(),new P(6,2)),t.set(s.IS_SERVICE_SPECIFIC.toString(),new R(!1)),t.set(s.USE_NON_STANDARD_STACKS.toString(),new R(!1)),t.set(s.SPECIAL_FEATURE_OPTINS.toString(),new U([!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1])),t.set(s.PURPOSE_CONSENTS.toString(),new U([!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1])),t.set(s.PURPOSE_LEGITIMATE_INTERESTS.toString(),new U([!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1])),t.set(s.PURPOSE_ONE_TREATMENT.toString(),new R(!1)),t.set(s.PUBLISHER_COUNTRY_CODE.toString(),new x(2,\"AA\")),t.set(s.VENDOR_CONSENTS.toString(),new B([])),t.set(s.VENDOR_LEGITIMATE_INTERESTS.toString(),new B([])),t.set(s.PUBLISHER_RESTRICTIONS.toString(),new F([])),t.set(s.PUBLISHER_PURPOSES_SEGMENT_TYPE.toString(),new P(3,3)),t.set(s.PUBLISHER_CONSENTS.toString(),new U([!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1])),t.set(s.PUBLISHER_LEGITIMATE_INTERESTS.toString(),new U([!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1,!1]));let o=new P(6,0);t.set(s.NUM_CUSTOM_PURPOSES.toString(),o),t.set(s.PUBLISHER_CUSTOM_CONSENTS.toString(),new L((()=>o.getValue()),[])),t.set(s.PUBLISHER_CUSTOM_LEGITIMATE_INTERESTS.toString(),new L((()=>o.getValue()),[])),t.set(s.VENDORS_ALLOWED_SEGMENT_TYPE.toString(),new P(3,2)),t.set(s.VENDORS_ALLOWED.toString(),new B([])),t.set(s.VENDORS_DISCLOSED_SEGMENT_TYPE.toString(),new P(3,1)),t.set(s.VENDORS_DISCLOSED.toString(),new B([])),super(t,[[s.VERSION.toString(),s.CREATED.toString(),s.LAST_UPDATED.toString(),s.CMP_ID.toString(),s.CMP_VERSION.toString(),s.CONSENT_SCREEN.toString(),s.CONSENT_LANGUAGE.toString(),s.VENDOR_LIST_VERSION.toString(),s.POLICY_VERSION.toString(),s.IS_SERVICE_SPECIFIC.toString(),s.USE_NON_STANDARD_STACKS.toString(),s.SPECIAL_FEATURE_OPTINS.toString(),s.PURPOSE_CONSENTS.toString(),s.PURPOSE_LEGITIMATE_INTERESTS.toString(),s.PURPOSE_ONE_TREATMENT.toString(),s.PUBLISHER_COUNTRY_CODE.toString(),s.VENDOR_CONSENTS.toString(),s.VENDOR_LEGITIMATE_INTERESTS.toString(),s.PUBLISHER_RESTRICTIONS.toString()],[s.PUBLISHER_PURPOSES_SEGMENT_TYPE.toString(),s.PUBLISHER_CONSENTS.toString(),s.PUBLISHER_LEGITIMATE_INTERESTS.toString(),s.NUM_CUSTOM_PURPOSES.toString(),s.PUBLISHER_CUSTOM_CONSENTS.toString(),s.PUBLISHER_CUSTOM_LEGITIMATE_INTERESTS.toString()],[s.VENDORS_ALLOWED_SEGMENT_TYPE.toString(),s.VENDORS_ALLOWED.toString()],[s.VENDORS_DISCLOSED_SEGMENT_TYPE.toString(),s.VENDORS_DISCLOSED.toString()]]),this.base64UrlEncoder=new W,e&&e.length>0&&this.decode(e)}encode(){let e=this.encodeSegmentsToBitStrings(),t=[];return this.updateDateStamp(),t.push(this.base64UrlEncoder.encode(e[0])),this.getFieldValue(s.IS_SERVICE_SPECIFIC.toString())?e[1]&&e[1].length>0&&t.push(this.base64UrlEncoder.encode(e[1])):(e[2]&&e[2].length>0&&t.push(this.base64UrlEncoder.encode(e[2])),e[3]&&e[3].length>0&&t.push(this.base64UrlEncoder.encode(e[3]))),t.join(\".\")}decode(e){let t=e.split(\".\"),n=[];for(let e=0;es.getValue()),[])),t.set(o.CUSTOM_PURPOSES_IMPLIED_CONSENT.toString(),new L((()=>s.getValue()),[])),super(t,[[o.VERSION.toString(),o.CREATED.toString(),o.LAST_UPDATED.toString(),o.CMP_ID.toString(),o.CMP_VERSION.toString(),o.CONSENT_SCREEN.toString(),o.CONSENT_LANGUAGE.toString(),o.VENDOR_LIST_VERSION.toString(),o.TCF_POLICY_VERSION.toString(),o.USE_NON_STANDARD_STACKS.toString(),o.SPECIAL_FEATURE_EXPRESS_CONSENT.toString(),o.PURPOSES_EXPRESS_CONSENT.toString(),o.PURPOSES_IMPLIED_CONSENT.toString(),o.VENDOR_EXPRESS_CONSENT.toString(),o.VENDOR_IMPLIED_CONSENT.toString()],[o.SEGMENT_TYPE.toString(),o.PUB_PURPOSES_EXPRESS_CONSENT.toString(),o.PUB_PURPOSES_IMPLIED_CONSENT.toString(),o.NUM_CUSTOM_PURPOSES.toString(),o.CUSTOM_PURPOSES_EXPRESS_CONSENT.toString(),o.CUSTOM_PURPOSES_IMPLIED_CONSENT.toString()]]),this.base64UrlEncoder=new T,e&&e.length>0&&this.decode(e)}encode(){let e=this.encodeSegmentsToBitStrings(),t=[];return t.push(this.base64UrlEncoder.encode(e[0])),e[1]&&e[1].length>0&&t.push(this.base64UrlEncoder.encode(e[1])),t.join(\".\")}decode(e){let t=e.split(\".\"),n=[];for(let e=0;e0&&this.decode(e)}hasField(e){return this.fields.has(e)}getFieldValue(e){return this.fields.has(e)?this.fields.get(e):null}setFieldValue(e,t){if(!this.fields.has(e))throw new j(e+\" not found\");this.fields.set(e,t)}toObj(){let e={};for(const t of this.fields.keys()){let n=this.fields.get(t);e[t.toString()]=n}return e}encode(){let e=\"\";return e+=this.getFieldValue(i.VERSION.toString()),e+=this.getFieldValue(i.NOTICE.toString()),e+=this.getFieldValue(i.OPT_OUT_SALE.toString()),e+=this.getFieldValue(i.LSPA_COVERED.toString()),e}decode(e){this.setFieldValue(i.VERSION.toString(),parseInt(e.charAt(0))),this.setFieldValue(i.NOTICE.toString(),e.charAt(1)),this.setFieldValue(i.OPT_OUT_SALE.toString(),e.charAt(2)),this.setFieldValue(i.LSPA_COVERED.toString(),e.charAt(3))}getId(){return Y.ID}getName(){return Y.NAME}}Y.ID=6,Y.VERSION=1,Y.NAME=\"uspv1\";class q{static encode(e,t,n){let s=\"\";for(let n=0;nt*n)throw new C(\"Undecodable FixedIntegerList '\"+e+\"'\");if(e.length%t!=0)throw new C(\"Undecodable FixedIntegerList '\"+e+\"'\");for(;e.lengtht*n&&(e=e.substring(0,t*n));let s=[];for(let n=0;nthis.numElements&&(t=t.slice(0,this.numElements)),super.setValue(t)}}!function(e){e.VERSION=\"Version\",e.SHARING_NOTICE=\"SharingNotice\",e.SALE_OPT_OUT_NOTICE=\"SaleOptOutNotice\",e.SHARING_OPT_OUT_NOTICE=\"SharingOptOutNotice\",e.TARGETED_ADVERTISING_OPT_OUT_NOTICE=\"TargetedAdvertisingOptOutNotice\",e.SENSITIVE_DATA_PROCESSING_OPT_OUT_NOTICE=\"SensitiveDataProcessingOptOutNotice\",e.SENSITIVE_DATA_LIMIT_USE_NOTICE=\"SensitiveDataLimitUseNotice\",e.SALE_OPT_OUT=\"SaleOptOut\",e.SHARING_OPT_OUT=\"SharingOptOut\",e.TARGETED_ADVERTISING_OPT_OUT=\"TargetedAdvertisingOptOut\",e.SENSITIVE_DATA_PROCESSING=\"SensitiveDataProcessing\",e.KNOWN_CHILD_SENSITIVE_DATA_CONSENTS=\"KnownChildSensitiveDataConsents\",e.PERSONAL_DATA_CONSENTS=\"PersonalDataConsents\",e.MSPA_COVERED_TRANSACTION=\"MspaCoveredTransaction\",e.MSPA_OPT_OUT_OPTION_MODE=\"MspaOptOutOptionMode\",e.MSPA_SERVICE_PROVIDER_MODE=\"MspaServiceProviderMode\",e.GPC_SEGMENT_TYPE=\"GpcSegmentType\",e.GPC_SEGMENT_INCLUDED=\"GpcSegmentIncluded\",e.GPC=\"Gpc\"}(r||(r={}));class J extends M{constructor(e){let t=new Map;t.set(r.VERSION.toString(),new P(6,J.VERSION)),t.set(r.SHARING_NOTICE.toString(),new P(2,0)),t.set(r.SALE_OPT_OUT_NOTICE.toString(),new P(2,0)),t.set(r.SHARING_OPT_OUT_NOTICE.toString(),new P(2,0)),t.set(r.TARGETED_ADVERTISING_OPT_OUT_NOTICE.toString(),new P(2,0)),t.set(r.SENSITIVE_DATA_PROCESSING_OPT_OUT_NOTICE.toString(),new P(2,0)),t.set(r.SENSITIVE_DATA_LIMIT_USE_NOTICE.toString(),new P(2,0)),t.set(r.SALE_OPT_OUT.toString(),new P(2,0)),t.set(r.SHARING_OPT_OUT.toString(),new P(2,0)),t.set(r.TARGETED_ADVERTISING_OPT_OUT.toString(),new P(2,0)),t.set(r.SENSITIVE_DATA_PROCESSING.toString(),new Q(2,[0,0,0,0,0,0,0,0,0,0,0,0])),t.set(r.KNOWN_CHILD_SENSITIVE_DATA_CONSENTS.toString(),new Q(2,[0,0])),t.set(r.PERSONAL_DATA_CONSENTS.toString(),new P(2,0)),t.set(r.MSPA_COVERED_TRANSACTION.toString(),new P(2,0)),t.set(r.MSPA_OPT_OUT_OPTION_MODE.toString(),new P(2,0)),t.set(r.MSPA_SERVICE_PROVIDER_MODE.toString(),new P(2,0)),t.set(r.GPC_SEGMENT_TYPE.toString(),new P(2,1)),t.set(r.GPC_SEGMENT_INCLUDED.toString(),new R(!0)),t.set(r.GPC.toString(),new R(!1)),super(t,[[r.VERSION.toString(),r.SHARING_NOTICE.toString(),r.SALE_OPT_OUT_NOTICE.toString(),r.SHARING_OPT_OUT_NOTICE.toString(),r.TARGETED_ADVERTISING_OPT_OUT_NOTICE.toString(),r.SENSITIVE_DATA_PROCESSING_OPT_OUT_NOTICE.toString(),r.SENSITIVE_DATA_LIMIT_USE_NOTICE.toString(),r.SALE_OPT_OUT.toString(),r.SHARING_OPT_OUT.toString(),r.TARGETED_ADVERTISING_OPT_OUT.toString(),r.SENSITIVE_DATA_PROCESSING.toString(),r.KNOWN_CHILD_SENSITIVE_DATA_CONSENTS.toString(),r.PERSONAL_DATA_CONSENTS.toString(),r.MSPA_COVERED_TRANSACTION.toString(),r.MSPA_OPT_OUT_OPTION_MODE.toString(),r.MSPA_SERVICE_PROVIDER_MODE.toString()],[r.GPC_SEGMENT_TYPE.toString(),r.GPC.toString()]]),this.base64UrlEncoder=new T,e&&e.length>0&&this.decode(e)}encode(){let e=this.encodeSegmentsToBitStrings(),t=[];if(t.push(this.base64UrlEncoder.encode(e[0])),e[1]&&e[1].length>0){!0===this.fields.get(r.GPC_SEGMENT_INCLUDED).getValue()&&t.push(this.base64UrlEncoder.encode(e[1]))}return t.join(\".\")}decode(e){let t=e.split(\".\"),n=[],s=!1;for(let e=0;e0&&this.decode(e)}setFieldValue(e,t,n){let s=null;if(this.sections.has(e)?s=this.sections.get(e):e===z.NAME?(s=new z,this.sections.set(z.NAME,s)):e===H.NAME?(s=new H,this.sections.set(H.NAME,s)):e===Y.NAME?(s=new Y,this.sections.set(Y.NAME,s)):e===J.NAME&&(s=new J,this.sections.set(J.NAME,s)),!s)throw new j(e+\".\"+t+\" not found\");s.setFieldValue(t,n)}setFieldValueBySectionId(e,t,n){this.setFieldValue(X.SECTION_ID_NAME_MAP.get(e),t,n)}getFieldValue(e,t){return this.sections.has(e)?this.sections.get(e).getFieldValue(t):null}getFieldValueBySectionId(e,t){return this.getFieldValue(X.SECTION_ID_NAME_MAP.get(e),t)}hasField(e,t){return!!this.sections.has(e)&&this.sections.get(e).hasField(t)}hasFieldBySectionId(e,t){return this.hasField(X.SECTION_ID_NAME_MAP.get(e),t)}hasSection(e){return this.sections.has(e)}hasSectionId(e){return this.hasSection(X.SECTION_ID_NAME_MAP.get(e))}deleteSection(e){this.sections.delete(e)}deleteSectionById(e){this.deleteSection(X.SECTION_ID_NAME_MAP.get(e))}clear(){this.sections.clear()}getHeader(){let e=new D;return e.setFieldValue(\"SectionIds\",this.getSectionIds()),e.toObj()}getSection(e){return this.sections.has(e)?this.sections.get(e).toObj():null}getSectionIds(){let e=[];for(let t=0;t. parameter required\");let e=this.parameter.split(\".\");if(2!=e.length)throw new Error(\"Field name must be in the format .\");let t=e[0],n=e[1],s=null;return\"tcfeuv2\"!=this.parameter&&(s=this.cmpApiContext.gppModel.getFieldValue(t,n)),this.invokeCallback(s),s}},ee[u]=class extends Z{respond(){let e=this.cmpApiContext.gppModel.getHeader(),t={sectionId:e.Id,gppVersion:this.cmpApiContext.gppVersion,sectionList:e.SectionIds,applicableSections:this.cmpApiContext.applicableSections,gppString:this.cmpApiContext.gppModel.encode(),pingData:{gppVersion:this.cmpApiContext.gppVersion,cmpStatus:this.cmpApiContext.cmpStatus,cmpDisplayStatus:this.cmpApiContext.cmpDisplayStatus,apiSupport:this.cmpApiContext.apiSupport,currentAPI:this.cmpApiContext.currentAPI,cmpId:this.cmpApiContext.cmpId,cmpVersion:this.cmpApiContext.cmpVersion}};return this.invokeCallback(t),t}},ee[d]=class extends Z{respond(){if(!this.parameter||0===this.parameter.length)throw new Error(\" parameter required\");let e=null;return\"tcfeuv2\"!=this.parameter&&this.cmpApiContext.gppModel.hasSection(this.parameter)&&(e=this.cmpApiContext.gppModel.getSection(this.parameter)),this.invokeCallback(e),e}},ee[p]=class extends Z{respond(){let e=null;return this.cmpApiContext.gppModel.hasSection(\"tcfcav1\")&&(e=this.cmpApiContext.gppModel.getSection(\"tcfcav1\")),this.invokeCallback(e),e}},ee[g]=class extends Z{respond(){if(!this.parameter||0===this.parameter.length)throw new Error(\"[.version] parameter required\");let e=this.cmpApiContext.gppModel.hasSection(this.parameter);return this.invokeCallback(e),e}},ee[S]=class extends Z{respond(){let e={gppVersion:this.cmpApiContext.gppVersion,cmpStatus:this.cmpApiContext.cmpStatus,cmpDisplayStatus:this.cmpApiContext.cmpDisplayStatus,apiSupport:this.cmpApiContext.apiSupport,currentAPI:this.cmpApiContext.currentAPI,cmpId:this.cmpApiContext.cmpId,cmpVersion:this.cmpApiContext.cmpVersion};return this.invokeCallback(e),e}},ee[h]=class extends Z{respond(){let e=this.parameter;return this.cmpApiContext.eventQueue.remove(e)?{eventName:\"listenerRemoved\",listenerId:e,data:!0,pingData:{gppVersion:this.cmpApiContext.gppVersion,cmpStatus:this.cmpApiContext.cmpStatus,cmpDisplayStatus:this.cmpApiContext.cmpDisplayStatus,apiSupport:this.cmpApiContext.apiSupport,currentAPI:this.cmpApiContext.currentAPI,cmpId:this.cmpApiContext.cmpId,cmpVersion:this.cmpApiContext.cmpVersion}}:{eventName:\"listenerRemoved\",listenerId:e,data:!1,pingData:{gppVersion:this.cmpApiContext.gppVersion,cmpStatus:this.cmpApiContext.cmpStatus,cmpDisplayStatus:this.cmpApiContext.cmpDisplayStatus,apiSupport:this.cmpApiContext.apiSupport,currentAPI:this.cmpApiContext.currentAPI,cmpId:this.cmpApiContext.cmpId,cmpVersion:this.cmpApiContext.cmpVersion}}}};class te{constructor(e,t){if(this.cmpApiContext=e,t){let e=a.ADD_EVENT_LISTENER;if(null==t?void 0:t[e])throw new Error(`Built-In Custom Commmand for ${e} not allowed`);if(e=a.REMOVE_EVENT_LISTENER,null==t?void 0:t[e])throw new Error(`Built-In Custom Commmand for ${e} not allowed`);this.customCommands=t}try{this.callQueue=window.__gpp()||[]}catch(e){this.callQueue=[]}finally{window.__gpp=this.apiCall.bind(this),this.purgeQueuedCalls()}}apiCall(e,t,n,s){if(\"string\"!=typeof e)return t(null,!1);if(\"events\"===e)return this.cmpApiContext.eventQueue.events();if(t&&\"function\"!=typeof t)throw new Error(\"invalid callback function\");return this.isCustomCommand(e)?this.customCommands[e](t,n):this.isBuiltInCommand(e)?new ee[e](this.cmpApiContext,t,n).execute():t?t(null,!1):void 0}purgeQueuedCalls(){const e=this.callQueue;this.callQueue=[],e.forEach((e=>{window.__gpp(...e)}))}isCustomCommand(e){return this.customCommands&&\"function\"==typeof this.customCommands[e]}isBuiltInCommand(e){return void 0!==ee[e]}}class ne{static absCall(e,t,n,s){return new Promise(((o,i)=>{const r=new XMLHttpRequest;r.withCredentials=n,r.addEventListener(\"load\",(()=>{if(r.readyState==XMLHttpRequest.DONE)if(r.status>=200&&r.status{i(new Error(\"error\"))})),r.addEventListener(\"abort\",(()=>{i(new Error(\"aborted\"))})),null===t?r.open(\"GET\",e,!0):r.open(\"POST\",e,!0),r.responseType=\"json\",r.timeout=s,r.ontimeout=()=>{i(new Error(\"Timeout \"+s+\"ms \"+e))},r.send(t)}))}static post(e,t,n=!1,s=0){return this.absCall(e,JSON.stringify(t),n,s)}static fetch(e,t=!1,n=0){return this.absCall(e,null,t,n)}}class se extends Error{constructor(e){super(e),this.name=\"GvlError\"}}class oe{has(e){return oe.langSet.has(e)}forEach(e){oe.langSet.forEach(e)}get size(){return oe.langSet.size}}oe.langSet=new Set([\"BG\",\"CA\",\"CS\",\"DA\",\"DE\",\"EL\",\"EN\",\"ES\",\"ET\",\"FI\",\"FR\",\"HR\",\"HU\",\"IT\",\"JA\",\"LT\",\"LV\",\"MT\",\"NL\",\"NO\",\"PL\",\"PT\",\"RO\",\"RU\",\"SK\",\"SL\",\"SV\",\"TR\",\"ZH\"]);var ie=window&&window.__awaiter||function(e,t,n,s){return new(n||(n=Promise))((function(o,i){function r(e){try{c(s.next(e))}catch(e){i(e)}}function a(e){try{c(s.throw(e))}catch(e){i(e)}}function c(e){var t;e.done?o(e.value):(t=e.value,t instanceof n?t:new n((function(e){e(t)}))).then(r,a)}c((s=s.apply(e,t||[])).next())}))};class re{constructor(){this.consentLanguages=new oe,this.language=re.DEFAULT_LANGUAGE,this.ready=!1,this.languageFilename=\"purposes-[LANG].json\"}static fromVendorList(e){let t=new re;return t.populate(e),t}static fromUrl(e){return ie(this,void 0,void 0,(function*(){let t=e.baseUrl;if(!t||0===t.length)throw new se(\"Invalid baseUrl: '\"+t+\"'\");if(/^https?:\\/\\/vendorlist\\.consensu\\.org\\//.test(t))throw new se(\"Invalid baseUrl! You may not pull directly from vendorlist.consensu.org and must provide your own cache\");t.length>0&&\"/\"!==t[t.length-1]&&(t+=\"/\");let n=new re;if(n.baseUrl=t,e.languageFilename?n.languageFilename=e.languageFilename:n.languageFilename=\"purposes-[LANG].json\",e.version>0){let s=e.versionedFilename;s||(s=\"archives/vendor-list-v[VERSION].json\");let o=t+s.replace(\"[VERSION]\",String(e.version));n.populate(yield ne.fetch(o))}else{let s=e.latestFilename;s||(s=\"vendor-list.json\");let o=t+s;n.populate(yield ne.fetch(o))}return n}))}changeLanguage(e){return ie(this,void 0,void 0,(function*(){const t=e.toUpperCase();if(!this.consentLanguages.has(t))throw new se(`unsupported language ${e}`);if(t!==this.language){this.language=t;const n=this.baseUrl+this.languageFilename.replace(\"[LANG]\",e);try{this.populate(yield ne.fetch(n))}catch(e){throw new se(\"unable to load language: \"+e.message)}}}))}getJson(){return JSON.parse(JSON.stringify({gvlSpecificationVersion:this.gvlSpecificationVersion,vendorListVersion:this.vendorListVersion,tcfPolicyVersion:this.tcfPolicyVersion,lastUpdated:this.lastUpdated,purposes:this.purposes,specialPurposes:this.specialPurposes,features:this.features,specialFeatures:this.specialFeatures,stacks:this.stacks,vendors:this.fullVendorList}))}isVendorList(e){return void 0!==e&&void 0!==e.vendors}populate(e){this.purposes=e.purposes,this.specialPurposes=e.specialPurposes,this.features=e.features,this.specialFeatures=e.specialFeatures,this.stacks=e.stacks,this.isVendorList(e)&&(this.gvlSpecificationVersion=e.gvlSpecificationVersion,this.tcfPolicyVersion=e.tcfPolicyVersion,this.vendorListVersion=e.vendorListVersion,this.lastUpdated=e.lastUpdated,\"string\"==typeof this.lastUpdated&&(this.lastUpdated=new Date(this.lastUpdated)),this.vendors=e.vendors,this.fullVendorList=e.vendors,this.mapVendors(),this.ready=!0)}mapVendors(e){this.byPurposeVendorMap={},this.bySpecialPurposeVendorMap={},this.byFeatureVendorMap={},this.bySpecialFeatureVendorMap={},Object.keys(this.purposes).forEach((e=>{this.byPurposeVendorMap[e]={legInt:new Set,consent:new Set,flexible:new Set}})),Object.keys(this.specialPurposes).forEach((e=>{this.bySpecialPurposeVendorMap[e]=new Set})),Object.keys(this.features).forEach((e=>{this.byFeatureVendorMap[e]=new Set})),Object.keys(this.specialFeatures).forEach((e=>{this.bySpecialFeatureVendorMap[e]=new Set})),Array.isArray(e)||(e=Object.keys(this.fullVendorList).map((e=>+e))),this.vendorIds=new Set(e),this.vendors=e.reduce(((e,t)=>{const n=this.vendors[String(t)];return n&&void 0===n.deletedDate&&(n.purposes.forEach((e=>{this.byPurposeVendorMap[String(e)].consent.add(t)})),n.specialPurposes.forEach((e=>{this.bySpecialPurposeVendorMap[String(e)].add(t)})),n.legIntPurposes.forEach((e=>{this.byPurposeVendorMap[String(e)].legInt.add(t)})),n.flexiblePurposes&&n.flexiblePurposes.forEach((e=>{this.byPurposeVendorMap[String(e)].flexible.add(t)})),n.features.forEach((e=>{this.byFeatureVendorMap[String(e)].add(t)})),n.specialFeatures.forEach((e=>{this.bySpecialFeatureVendorMap[String(e)].add(t)})),e[t]=n),e}),{})}getFilteredVendors(e,t,n,s){const o=e.charAt(0).toUpperCase()+e.slice(1);let i;const r={};return i=\"purpose\"===e&&n?this[\"by\"+o+\"VendorMap\"][String(t)][n]:this[\"by\"+(s?\"Special\":\"\")+o+\"VendorMap\"][String(t)],i.forEach((e=>{r[String(e)]=this.vendors[String(e)]})),r}getVendorsWithConsentPurpose(e){return this.getFilteredVendors(\"purpose\",e,\"consent\")}getVendorsWithLegIntPurpose(e){return this.getFilteredVendors(\"purpose\",e,\"legInt\")}getVendorsWithFlexiblePurpose(e){return this.getFilteredVendors(\"purpose\",e,\"flexible\")}getVendorsWithSpecialPurpose(e){return this.getFilteredVendors(\"purpose\",e,void 0,!0)}getVendorsWithFeature(e){return this.getFilteredVendors(\"feature\",e)}getVendorsWithSpecialFeature(e){return this.getFilteredVendors(\"feature\",e,void 0,!0)}narrowVendorsTo(e){this.mapVendors(e)}get isReady(){return this.ready}static isInstanceOf(e){return\"object\"==typeof e&&\"function\"==typeof e.narrowVendorsTo}}re.DEFAULT_LANGUAGE=\"EN\";var ae=window&&window.__awaiter||function(e,t,n,s){return new(n||(n=Promise))((function(o,i){function r(e){try{c(s.next(e))}catch(e){i(e)}}function a(e){try{c(s.throw(e))}catch(e){i(e)}}function c(e){var t;e.done?o(e.value):(t=e.value,t instanceof n?t:new n((function(e){e(t)}))).then(r,a)}c((s=s.apply(e,t||[])).next())}))};class ce{constructor(e,t,n){this.cmpApiContext=new $,this.cmpApiContext.cmpId=e,this.cmpApiContext.cmpVersion=t,this.callResponder=new te(this.cmpApiContext,n)}fireEvent(e,t){this.cmpApiContext.eventQueue.exec(e,t)}fireErrorEvent(e){this.cmpApiContext.eventQueue.exec(\"error\",e)}fireSectionChange(e){this.cmpApiContext.eventQueue.exec(\"sectionChange\",e)}getEventStatus(){return this.cmpApiContext.eventStatus}setEventStatus(e){this.cmpApiContext.eventStatus=e}getCmpStatus(){return this.cmpApiContext.cmpStatus}setCmpStatus(e){this.cmpApiContext.cmpStatus=e,this.cmpApiContext.eventQueue.exec(\"cmpStatus\",e)}getCmpDisplayStatus(){return this.cmpApiContext.cmpDisplayStatus}setCmpDisplayStatus(e){this.cmpApiContext.cmpDisplayStatus=e,this.cmpApiContext.eventQueue.exec(\"cmpDisplayStatus\",e)}getApplicableSections(){return this.cmpApiContext.applicableSections}setApplicableSections(e){this.cmpApiContext.applicableSections=e}getCurrentAPI(){return this.cmpApiContext.currentAPI}setCurrentAPI(e){this.cmpApiContext.currentAPI=e}setGppString(e){this.cmpApiContext.gppModel.decode(e)}getGppString(){return this.cmpApiContext.gppModel.encode()}setSectionString(e,t){this.cmpApiContext.gppModel.decodeSection(e,t)}setSectionStringById(e,t){this.setSectionString(X.SECTION_ID_NAME_MAP.get(e),t)}getSectionString(e){return this.cmpApiContext.gppModel.encodeSection(e)}getSectionStringById(e){return this.getSectionString(X.SECTION_ID_NAME_MAP.get(e))}setFieldValue(e,t,n){this.cmpApiContext.gppModel.setFieldValue(e,t,n)}setFieldValueBySectionId(e,t,n){this.setFieldValue(X.SECTION_ID_NAME_MAP.get(e),t,n)}getFieldValue(e,t){return this.cmpApiContext.gppModel.getFieldValue(e,t)}getFieldValueBySectionId(e,t){return this.getFieldValue(X.SECTION_ID_NAME_MAP.get(e),t)}getSection(e){return this.cmpApiContext.gppModel.getSection(e)}getSectionById(e){return this.getSection(X.SECTION_ID_NAME_MAP.get(e))}hasSection(e){return this.cmpApiContext.gppModel.hasSection(e)}hasSectionId(e){return this.hasSection(X.SECTION_ID_NAME_MAP.get(e))}deleteSection(e){this.cmpApiContext.gppModel.deleteSection(e)}deleteSectionById(e){this.deleteSection(X.SECTION_ID_NAME_MAP.get(e))}clear(){this.cmpApiContext.gppModel.clear()}getObject(){return this.cmpApiContext.gppModel.toObject()}getGvlFromVendorList(e){return re.fromVendorList(e)}getGvlFromUrl(e){return ae(this,void 0,void 0,(function*(){return re.fromUrl(e)}))}}window.WBD=window.WBD||{},window.WM=window.WM||{},function(e,t){if(\"function\"!=typeof e.CustomEvent){var n=function(e,n){var s;return n=n||{bubbles:!1,cancelable:!1,detail:void 0},(s=t.createEvent(\"CustomEvent\")).initCustomEvent(e,n.bubbles,n.cancelable,n.detail),s};n.prototype=e.Event.prototype,e.CustomEvent=n,\"function\"!==e.Event&&(e.Event=n)}}(window,document),window.WBD.UserConsent=window.WBD.UserConsent||function(e,t){var n,s,o=\"\",i={},r=!1,a=[],c=0,l=\"\",u=null,d=null,p=\"unknown\",g={},S=!1,h=\"\",E=\"\",C=\"\",f=\"\",m={tcfeuv2:2,tcfcav1:5,uspv1:6,uspnatv1:7},I=null,T=\"\",_=null,A=!1,O=!1,N=\"en\",b={binary:!0,boolean:!0,trinary:!0,integer:!0},P=\"\",y=!1,D=\"4.1.1\",R=null,v=!1,w=!1,V=!1,L=!1,U=!1,k=null,x=\"\",M={addtlConsentCookie:\"OTAdditionalConsentString\",adChoicesLinkAction:\"https://www.warnermediaprivacy.com/policycenter/b2c/WMNS/\",adChoicesLinkTitle:{en:\"Ad Choices\",es:\"Elecciones de anuncios\",ar:\"اختيارات الإعلان\"},categories:{req:\"required\",dsa:\"data-store\",cad:\"ads-contextual\",pap:\"ads-person-prof\",pad:\"ads-person\",pcp:\"content-person-prof\",pcd:\"content-person\",map:\"measure-ads\",mcp:\"measure-content\",mra:\"measure-market\",pdd:\"product-develop\",ccd:\"content-contextual\",sec:\"product-security\",tdc:\"deliver-content\",cos:\"combine-data\",dlk:\"link-devices\",did:\"id-devices\",gld:\"geolocate\",sid:\"scan-devices\",dsh:\"data-share\",dsl:\"data-sell\",pdu:\"personal-data\",kc12:\"known-child-12\",kc16:\"known-child-16\",sdre:\"sensitive-racial\",sdrb:\"sensitive-belief\",sdhe:\"sensitive-health\",sdso:\"sensitive-sexual\",sdir:\"sensitive-citizen\",sdge:\"sensitive-gene\",sdbm:\"sensitive-biometric\",sdsp:\"sensitive-spi\",sdss:\"sensitive-ssi\",sduo:\"sensitive-org\",sdco:\"sensitive-comm\"},ccCookie:\"countryCode\",ccpaGeos:[\"US:CA\",\"US:CO\",\"US:CT\",\"US:UT\",\"US:VA\"],compatCategories:{vendor:[\"data-share\",\"data-sell\",\"ads-person-prof\",\"ads-person\"],\"targeted-ads\":[\"ads-person-prof\",\"ads-person\"],\"sensitive-geo\":[\"geolocate\"]},confirmCookie:\"OptanonAlertBoxClosed\",consentChangeAction:null,consentChangeActionDelay:1e3,consentCookie:\"OptanonConsent\",consentDefaults:{required:!0,\"data-store\":!0,\"ads-contextual\":!0,\"ads-person\":!0,\"ads-person-prof\":!0,\"content-person\":!0,\"content-person-prof\":!0,\"measure-ads\":!0,\"measure-content\":!0,\"measure-market\":!0,\"product-develop\":!0,\"content-contextual\":!0,\"product-security\":!0,\"deliver-content\":!0,\"combine-data\":!0,\"link-devices\":!0,\"id-devices\":!0,geolocate:!1,\"scan-devices\":!1,\"data-share\":!0,\"data-sell\":!0,\"personal-data\":!1,\"known-child-12\":!1,\"known-child-16\":!1,\"sensitive-racial\":!1,\"sensitive-belief\":!1,\"sensitive-health\":!1,\"sensitive-sexual\":!1,\"sensitive-citizen\":!1,\"sensitive-gene\":!1,\"sensitive-biometric\":!1,\"sensitive-spi\":!1,\"sensitive-ssi\":!1,\"sensitive-org\":!1,\"sensitive-comm\":!1},consentExpireIn:1,consentNotApplicable:[\"personal-data\",\"known-child-12\",\"known-child-16\",\"sensitive-racial\",\"sensitive-belief\",\"sensitive-health\",\"sensitive-sexual\",\"sensitive-citizen\",\"sensitive-gene\",\"sensitive-biometric\",\"geolocate\",\"sensitive-spi\",\"sensitive-ssi\",\"sensitive-org\",\"sensitive-comm\"],consentLinkTitle:{ar:\"ملفات تعريف الارتباط\",en:\"Cookie Settings\",es:\"Configuración de Cookies\"},controlCookie:\"OptanonControl\",cookieSameSite:\"Lax\",cookieSecure:!1,defaultLanguage:\"en\",enableDebug:!1,enableGPC:!0,enableTransitionCheck:!0,enableWebViewCheck:!0,gdprIabCookie:\"eupubconsent-v2\",geoPassedToOneTrust:!0,gppCategories:{uspnatv1:[{field:\"SharingNotice\",type:\"trinary\",default:1},{field:\"SaleOptOutNotice\",type:\"trinary\",default:1},{field:\"SharingOptOutNotice\",type:\"trinary\",default:1},{field:\"TargetedAdvertisingOptOutNotice\",type:\"trinary\",default:1},{field:\"SharingOptOut\",type:\"trinary\",val:\"data-share\"},{field:\"SaleOptOut\",type:\"trinary\",val:\"data-sell\"},{field:\"TargetedAdvertisingOptOut\",type:\"trinary\",val:[\"ads-person-prof\",\"ads-person\"]},{field:\"PersonalDataConsents\",type:\"trinary\",default:0,val:\"personal-data\"},{field:\"KnownChildSensitiveDataConsents\",type:\"array-trinary\",default:[0,0],maxCount:2,0:\"known-child-12\",1:\"known-child-16\"},{field:\"SensitiveDataProcessing\",type:\"array-trinary\",default:[0,0,0,0,0,0,0,0,0,0,0,0],maxCount:12,0:\"sensitive-racial\",1:\"sensitive-belief\",2:\"sensitive-health\",3:\"sensitive-sexual\",4:\"sensitive-citizen\",5:\"sensitive-gene\",6:\"sensitive-biometric\",7:\"geolocate\",8:\"sensitive-spi\",9:\"sensitive-ssi\",10:\"sensitive-org\",11:\"sensitive-comm\"}],uspv1:[{field:\"OptOutSale\",type:\"binary\",val:[\"data-share\",\"data-sell\",\"ads-person-prof\",\"ads-person\"]}]},gppIabCookie:\"OTGPPConsent\",gppSection:\"\",iabRegion:\"\",languageFromBrowser:!0,privacyCenterLinkAction:\"https://www.warnermediaprivacy.com/policycenter/b2c/WMNS/\",privacyCenterLinkTitle:{ar:\"سياسة خصوصية المستهلك\",en:\"Privacy Policy\",es:\"Política de Privacidad\"},regionChangeAction:null,regions:[{id:\"us\",compatCodes:{ven:[\"dsh\",\"dsl\",\"pap\",\"pad\"],tpv:[\"dsh\",\"dsl\",\"pap\",\"pad\"]},compatTransition:{cond:!1,new:[\"dsh\",\"dsl\",\"pap\",\"pad\"],old:\"ven\"},consentExpireIn:3,consentGpcDefaults:{\"data-share\":!1,\"data-sell\":!1,\"ads-person-prof\":!1,\"ads-person\":!1},consentImpliedDefaults:{\"data-store\":!0,\"ads-contextual\":!0,\"content-person\":!0,\"content-person-prof\":!0,\"measure-ads\":!0,\"measure-content\":!0,\"measure-market\":!0,\"product-develop\":!0,\"content-contextual\":!0,\"product-security\":!0,\"deliver-content\":!0,\"combine-data\":!0,\"link-devices\":!0,\"id-devices\":!0},consentLinkTitle:{ar:\"لا تبيع أو تشارك معلوماتي الشخصية\",en:\"Do Not Sell Or Share My Personal Information\",es:\"No Venda Vi Comparta Mi Información Personal\"},geoMatch:[\"US:CA\",\"US:CO\",\"US:CT\",\"US:UT\",\"US:VA\"],gppSection:\"uspnatv1\",iabRegion:\"ccpa\"},{id:\"gdpr\",consentDefaults:{\"data-store\":!1,\"ads-contextual\":!1,\"ads-person-prof\":!1,\"ads-person\":!1,\"content-person-prof\":!1,\"content-person\":!1,\"measure-ads\":!1,\"measure-content\":!1,\"measure-market\":!1,\"product-develop\":!1,\"content-contextual\":!1,\"combine-data\":!1,\"link-devices\":!1,\"id-devices\":!1},consentImpliedDefaults:{\"product-security\":!0,\"deliver-content\":!0,\"combine-data\":!0,\"link-devices\":!0,\"id-devices\":!0,\"data-share\":!0,\"data-sell\":!0},consentLinkTitle:{ar:\"إدارة ملفات تعريف الارتباط+\",en:\"Manage Cookies+\",es:\"Administrar cookies+\"},geoMatch:[\"GB\",\"DE\",\"FR\",\"IT\",\"ES\",\"PL\",\"RO\",\"NL\",\"BE\",\"GR\",\"CZ\",\"PT\",\"SE\",\"HU\",\"AT\",\"BG\",\"DK\",\"FI\",\"SK\",\"IE\",\"HR\",\"LT\",\"SI\",\"LV\",\"EE\",\"CY\",\"LU\",\"MT\",\"NO\",\"IS\",\"LI\"],iabRegion:\"gdpr\"},{id:\"other-optin\",consentDefaults:{\"data-store\":!1,\"ads-contextual\":!1,\"ads-person-prof\":!1,\"ads-person\":!1,\"content-person-prof\":!1,\"content-person\":!1,\"measure-ads\":!1,\"measure-content\":!1,\"measure-market\":!1,\"product-develop\":!1,\"content-contextual\":!1,\"combine-data\":!1,\"link-devices\":!1,\"id-devices\":!1},consentImpliedDefaults:{\"product-security\":!0,\"deliver-content\":!0,\"combine-data\":!0,\"link-devices\":!0,\"id-devices\":!0,\"data-share\":!0,\"data-sell\":!0},geoMatch:[\"CO\",\"UY\",\"PE\",\"AR\",\"CR\",\"CL\"]},{id:\"other-optout\",consentImpliedDefaults:{\"product-security\":!0,\"deliver-content\":!0,\"combine-data\":!0,\"link-devices\":!0,\"id-devices\":!0,\"data-share\":!0,\"data-sell\":!0},geoMatch:[\"MX\",\"PY\",\"BR\",\"VE\",\"NI\"]},{id:\"global\",geoMatch:[\"*\"],useFixedConsent:!0}],reloadOnConsentChange:!0,reloadOnConsentReduction:!1,scCookie:\"stateCode\",setPageClass:!0,src:\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\",strictIabCompliance:!0,tcfOpts:{categories:{purposes:[\"data-store\",\"ads-contextual\",\"ads-person-prof\",\"ads-person\",\"content-person-prof\",\"content-person\",\"measure-ads\",\"measure-content\",\"measure-market\",\"product-develop\",\"content-contextual\"],specialPurposes:[\"product-security\",\"deliver-content\"],features:[\"combine-data\",\"link-devices\",\"id-devices\"],specialFeatures:[\"geolocate\",\"scan-devices\"]},policies:{2:{iabMaxPurposes:10,iabMaxSpecialFeats:2},3:{iabMaxPurposes:10,iabMaxSpecialFeats:2},4:{iabMaxPurposes:11,iabMaxSpecialFeats:2}}},ucFlavor:\"iab\",useFixedConsent:!1,useGPP:!0,useIAB:!0,useIabString:!0,uspApiCookieName:\"usprivacy\",uspApiExplicitNotice:!0,uspApiIsLspa:!1};function G(e){const t=Array.prototype.slice.call(arguments);t[0]=\"[WMUC]\"+(0===h.length?\"\":\" (\"+h+\")\")+\":\",\"error\"===e?console.error.apply(console,t):console.log.apply(console,t)}function F(e){const n=t.cookie.match(new RegExp(\"(^|;) *\"+e+\" *= *([^;]+)\"));return n?n.pop():null}function B(e,n,s){e&&(s=s||{},t.cookie=e+\"=\"+(\"string\"==typeof n?n:\"\")+\"; Domain=\"+(s.domain||i.cookieDomain)+\"; Path=\"+(s.path||\"/\")+(s.maxage?\"; Max-Age=\"+s.maxage:s.expires?\"; Expires=\"+s.expires:\"\")+(s.secure?\"; Secure\":\"\")+(s.samesite?\"; SameSite=\"+s.samesite:\"\"))}function W(t){if(\"function\"==typeof e.atob)try{return atob(t.replace(/_/g,\"/\").replace(/-/g,\"+\"))}catch(e){G(\"error\",\"Failed to decode TC string\")}return\"\"}function H(e){return!!Number(e)}function z(e){return parseInt(e,2)||0}function j(e){return 100*z(e)}function Y(e){const t=\"A\".charCodeAt(),n=e.match(/.{6}/g)||[];let s=\"\";for(let e=0;e{if(s.pubRestrictionEntry&&s.rangeEntry)for(let e in s.rangeEntry)Object.prototype.hasOwnProperty.call(s.rangeEntry,e)&&(s.pubRestrictionEntry[e]=(s.pubRestrictionEntry[e]||[]).concat(s.rangeEntry[e]));s.numPubRestrictions&&(s.numPubRestrictions--,e.push({key:\"purposeId\",size:6},{key:\"restrictionType\",size:2},{key:\"numEntries\",size:12}))},i=()=>{s.numEntries?(s.numEntries--,e.push({key:\"isARange\",size:1,decoder:H},{key:\"startVendorId\",size:16})):o()},r=()=>!s.purposeId||[{purpose:s.purposeId,isAllowed:0!==s.restrictionType,isConsentRequired:1===s.restrictionType,isLegitimateInterestRequired:2===s.restrictionType}];if(\"isRangeEncoding\"===t.key)e.push(n?{key:\"numEntries\",size:12}:{key:\"bitField\",size:s.maxVendorId,decoder:q});else if(\"numEntries\"===t.key)s.rangeEntry={},i();else if(\"isARange\"===t.key)n&&e.push({key:\"endVendorId\",size:16});else if(\"startVendorId\"===t.key)s.isARange||(s.rangeEntry[n]=r(),i());else if(\"endVendorId\"===t.key){for(let e=s.startVendorId;ee.pubRestrictionEntry||e.rangeEntry||e.bitField||e,i=(e,n)=>{const s=n.slice(t,t+e.size);return t+=e.size,(e.decoder||z)(s)},r=(e,t)=>{let n={};if(!e.queue)return i(e,t);for(let o=0;o{let n={};for(let o=0;o{const r=\"string\"==typeof t?[t]:t,a=\"boolean\"===o?e:\"trinary\"===o?2===e:0!==e;for(let e of r)(0===i.consentNotApplicable.length||i.consentNotApplicable.indexOf(e)=0&&i.consentNotApplicable.indexOf(e){const o=\"string\"==typeof e?[e]:e;let i=0,r=!0;for(let e of o)n.indexOf(e)>=0?void 0!==s[e]&&(r=r&&s[e],i++):G(\"error\",'Invalid consent \"'+e+'\" specified in GPP Categories!');return i>0?\"boolean\"===t?r:\"trinary\"===t?r?2:1:r?1:0:\"boolean\"!==t&&0};try{if(i.startsWith(\"array\")){if(i=i.substring(6),!b[i])throw\"unparse\";if(!t.maxCount||!Array.isArray(o))throw\"badarray\";for(let e=0;e=0){const t=e.split(\"&\");for(let e=0;e=0){const e=t.split(\"&\");for(let t=0;t0){v=!0;for(let e=0;ed)&&(r=!0,d=s),U&&e.__gpp){let t=e.__gpp(\"ping\");t&&0!==t.cmpId&&(t.gppString||(t=e.__gpp(\"getGPPData\"),t&&t.gppString&&(C=t.gppString)))}E=ie(C);for(let e of n)if(E[e]!==u[e]&&(f=!0,!0!==E[e])){m=!0;break}if(f||!l&&r){const n=e.WBD.UserConsent_wrapproc>0?new Date(e.WBD.UserConsent_wrapproc):null;let s;if(c++,n&&(null===d||n.getTime()>d.getTime()+i.consentChangeActionDelay+1e3)&&(d=n),s=u,u=E,ge(),U&&oe(C,E),me(),f){if(S)try{a.push({ts:new Date,act:\"CHG\",desc:JSON.stringify(E),res:i.reloadOnConsentChange||i.reloadOnConsentReduction&&m,note:\"function\"==typeof i.consentChangeAction?\"change function\":\"\"})}catch(e){G(\"error\",\"Failed to track consent change: \",e)}if(\"function\"==typeof i.consentChangeAction&&i.consentChangeAction(re(),i.regId,p,s),t.dispatchEvent(new CustomEvent(\"userConsentChanged\",{bubbles:!1,cancelable:!1,detail:{region:i.regId,time:d,old:s,new:re(),gpp:T,usp:x,tcf:P,acf:o}})),i.reloadOnConsentChange||m&&i.reloadOnConsentReduction)setTimeout(he,100);else if(le())try{e.sessionStorage.setItem(\"_ucWBDCons\",JSON.stringify({consentState:u,consentTime:d,consentVersion:p,iabIsGlobal:!1})),e.postMessage(\"_ucWBDConsReset\",\"*\")}catch(e){G(\"error\",\"Failed to update session storage and notify children of consent change: \",e)}}}if(!f&&e.WBD.UserConsent_optLoaded){try{a.push({ts:new Date,act:\"NCC\",desc:JSON.stringify(u),res:!1,note:i.regId})}catch(e){G(\"error\",\"Failed to track consent no-change: \",e)}d=h,(!g.region||!g.consentVersion&&p||!g.userConsentVersion||g.userConsentVersion0&&(\"ping\"===s[0]?s[2]({apiVersion:n,gdprApplies:!0,gdprAppliesGlobally:!1,cmpLoaded:!1,cmpStatus:\"stub\",displayStatus:\"hidden\"},!0):\"setGdprApplies\"===s[0]&&s.length>3&&\"boolean\"==typeof s[3]?(L=s[3])&&V&&(V=!1):e[t].a.push([].slice.apply(s))),e[t].a},e[t].msgHandler=s.bind(e,t),fe(e[t].msgHandler),S&&G(\"debug\",\"IAB (v\"+n+\") for GDPR ready.\"),e[t](\"getTCData\",0,e.OptanonWrapper)):R&&S&&G(\"debug\",\"IAB (v\"+n+\") for GDPR ready (via frame).\")),U&&(t=\"__gpp\",n=\"1.0\",null!==Ce(\"__gppLocator\")||e.__gpp?S&&G(\"debug\",\"IAB for GPP ready (via frame).\"):(Ee(\"__gppLocator\"),e.__gpp=function(){return null},(I=I||new ce(0,1)).setCmpStatus(\"loading\"),_=e.__gpp,e.__gpp.msgHandler=s.bind(e,\"__gpp\"),fe(e.__gpp.msgHandler),S&&G(\"debug\",\"IAB for GPP ready.\")))}(),le()){let t;if(g=function(){const e=F(i.controlCookie),t={consentInteractions:c,consentTime:null,consentVersion:\"\",countryCode:\"\",region:\"\",stateCode:\"\",userConsentVersion:\"\"};if(\"string\"==typeof e&&0!==e.length){const n=e.split(\"&\");for(let e=0;ed)?(d=g.consentTime,S&&G(\"debug\",'Consent time read from \"'+i.controlCookie+'\": ',d)):null!==d&&S&&G(\"debug\",'Consent time read from \"'+i.confirmCookie+'\": ',d);if(t=S&&w?\" [GPC override]\":\"\",null!==d?(r=!0,u=ie(),r?(o.async=!0,null!==g.consentTime&&g.consentTime { return window.dispatchEvent(new CustomEvent('adfuel.loaded')); } }); const observer = new MutationObserver(function() { if (document.body) { window.CNN.helpers.addScriptTag({ src: window.CNN.helpers.getAdfuelSrc(true), async: true, data: { uid: 'adfuel-body' }, onload: () => { return window.dispatchEvent(new CustomEvent('adfuel-body.loaded')); } }); observer.disconnect(); } }); observer.observe(document.documentElement, {childList: true}); })(); //snippet: nativo if (window.WM.UserConsent.inUserConsentState(['iab','data-store','ads-contextual','ads-person-prof','ads-person','measure-ads'])) { (function() { /* serve nativo only on domestic pages */ if (!window.CNN.helpers.isEditionPage() && window.env.NATIVO_SRC) { const nativoScriptObj = { name: 'nativo', src: window.env.NATIVO_SRC, defer: true } addScript(nativoScriptObj); } })(); } //script: browsi addScript({ async: false, data: (function(){ try { let data = { pubkey: 'cnn', sitekey: 'cnn' }; return data; } catch (e) { console.error('external-scripts: error generating browsi data', e); } })(), defer: true, id: 'browsi-tag', name: 'browsi', src: (function(){ try { /* only load on mobile viewport AND articles not HEALTH - Test in progress with native injection */ if (window.matchMedia('(max-width: 960px)').matches && !window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.HEALTH) && !window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.POLITICS) && !window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.WORLD) && !window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.ENTERTAINMENT) && !window.CNN.helpers.isSection(window.CNN.helpers.SECTIONS.OPINIONS)) { return window.env.BROWSI_SRC } } catch (e) { console.error('external-scripts: error generating browsi src', e); } })() }, ['iab','data-share','data-sell','data-store','ads-contextual','ads-person-prof','ads-person','content-person-prof','content-person','measure-ads','measure-content','measure-market','product-develop']); //snippet: zion if (window.WM.UserConsent.inUserConsentState(['data-store','ads-person-prof','ads-person','content-person-prof','content-person','measure-content'])) { (function() { addScript({ src: window.env.ZION_SRC, async: true, defer: false, name: 'zion', }); window.addEventListener('zion.loaded', () => { if ( window.CNN.Zion.environmentType && window.CNN.Zion.sourceId && window.ZION_SDK ) { const environment = window.ZION_SDK.EnvironmentType[window.CNN.Zion.environmentType]; const enableLogging = environment !== window.ZION_SDK.EnvironmentType.Prod; window.zion_analytics.configure({ bridgeEnabled: true, bufferSize: 20, enableLogging, customFeatureManagerPath: 'https://z.cdp-dev.cnn.com/zfm/zfh-3.js', environment: window.CNN.Zion.environmentType, isSecure: true, telemetryEndpoint: window.env.ZION_TELEMETRY_ENDPOINT, trackAdvertising: false, trackBluetooth: false, trackDeeplink: false, trackLifecycle: false, trackLocation: false, trackNotifications: false, trackPurchases: false, trackScreens: false, trackUxMetrics: true, uxMetricsPercentage: 15, }); if (window.zion_analytics) { window.zion_analytics.track(new window.ZION_SDK.Pageview({ canonicalUrl: window.CNN.contentModel.canonicalUrl, traits: { event_source: window.CNN.contentModel.techStack || 'stellar', page_variant: window.CNN.contentModel.templateType || '', raw_url: window.location.href, cms_id: CNN.contentModel.cmsId || '', page_type: CNN.contentModel.pageType || '', edition: window.CNN.helpers.isEditionPage(), section: CNN.contentModel.section || '', subsection: CNN.contentModel.subsection || '', section_level_3: CNN.contentModel.subsubsection || '', experience_type: 'cnn_core' }, sourceId: window.CNN.contentModel.sourceId || '' })); } } else { throw new Error('zion: missing either \"apiKey\", \"environmentType\" or \"sourceId\"'); } }); })(); } //script: sovrn addScript({ async: false, defer: true, name: 'sovrn', src: 'https://get.s-onetag.com/c15ddde9-ec7d-4a49-b8ca-7a21bc4b943b/tag.min.js' }, ['iab','data-share','data-sell','data-store','ads-contextual','ads-person-prof','ads-person','content-person-prof','content-person','measure-ads','measure-content','measure-market','product-develop']); //script: fave addScript({ async: false, defer: true, name: 'fave', src: 'https://registry.api.cnn.io/bundles/fave/latest-4.x/js' }); //script: pym-js addScript({ async: true, defer: false, name: 'pym-js', src: 'https://cdn.cnn.com/cnn/.e/interactive/js/lib/vendor/pym/pym.v1.min.js' }); }())if (!window.WM.UserConsent.inUserConsentState([\"data-share\",\"data-store\",\"content-person-prof\",\"content-person\",\"measure-ads\",\"measure-content\"])) { window.optimizely = window.optimizely || []; window.optimizely.push({ type: 'disable' }); }{\"@type\":\"NewsArticle\",\"@context\":\"https://schema.org\",\"articleBody\":\"After a piece of software incorrectly showed that money had gone missing, a trusted, centuries-old British government corporation used its financial and legal might to convict and bankrupt hundreds of people who ran its branches. Some family members say their loved-ones were left so distressed they took their own lives. This could be the plot of a dystopian novel, but it describes the real-life ordeal that scores of the so-called sub-postmasters of the UK Post Office went through between 1999 and 2015. The government — which owns the Post Office — has described the scandal as one of the greatest miscarriages of justice in British history. Over two decades, livelihoods and reputations were destroyed, families shattered, and savings lost. Out of thousands of affected sub-postmasters who ran small businesses in communities across Britain, 700 were convicted of criminal offences. Some spent time in prison. It began with errors in an IT system called Horizon, built by Japan’s Fujitsu and introduced in 1999 to replace paper-based accounting. Soon after its installation, branch managers realized the system was faulty. The software regularly showed that money — often many thousands of pounds — had gone missing from Post Office accounts. In many cases, it was simply wrong. Jo Hamilton was running a post office in a small village in southern England in 2003 when her Horizon computer started to show a shortfall of £2,000 ($2,500). When she ran the numbers again, she told CNN, that amount “doubled in front of (her) eye",
    "commentLink": "https://news.ycombinator.com/item?id=39010070",
    "commentBody": "Prison. Bankruptcy. Suicide. How a software glitch ruined lives (cnn.com)168 points by IronWolve 3 hours agohidepastfavorite132 comments PakG1 3 hours agoThis is a new summary of the real-life case that inspired me to go do PhD studies in information systems. I wanted to understand why IT incompetence still could exist to this degree in this day and age after all the knowledge the world had developed about good IT and software practices over decades of experience. Of course, I quickly found out that IS research had already figured most of this out, and that perhaps, people were just people and crappy organizations were just crappy organizations, and perhaps that's something that will never change because bell curve distributions exist for almost everything. If all people could be selfless, humble, intelligent, competent at everything they ever try to do, AND be people of integrity, I'm sure many of the world's problems would disappear, in addition to just IT problems. People suck, organizations suck, societies suck, and we all suck in our own way. I think organizational research like I'm trying to do still tries to point us towards a better path nevertheless, but sometimes it's a throw your hands in the air thing. Some people will never care. Needless to say, I'm no longer focused on researching this topic, as it seems really well-researched already. But it's still interesting to see that this particular example still pops up in a news report now and then. There are still plenty of other big examples that pop up every year, but this one seems to have staying power to stay in the news media. reply chii 2 hours agoparent> I quickly found out that IS research had already figured most of this out > People suck, organizations suck, societies suck and yet you don't see very many buildings collapse, bridges fail, and damns flood down valley. The idea is that there should be liability assigned to important systems, for which this liability makes the onus on the creator/owner to build in safe guards, checks or other protections to prevent disasters. Why this isn't applied to software engineering is a whole nother story, but i think it probably should. Move fast and break things is not something i wanted to hear tbh. reply PakG1 1 hour agorootparentThere is something about how buildings, bridges, and damns are tangible and therefore easier for people to conceptualize and appreciate. There is a natural literacy there in that you don't have to understand what goes into making a bridge to understand the consequences of having a bad bridge. Meanwhile, software's inner workings are encapsulated so that they're not self-evident as to consequences if things go awry. Furthermore, software is inconsistent in how it works, and this trains people to think that software is just naturally glitchy, but the glitches aren't a big deal. See the joke about different types of engineers also: https://www.reddit.com/r/Jokes/comments/pqr8t3/four_engineer... The mechanical engineer says: “It’s a broken starter” The electrical engineer says: “Dead battery” The chemical engineer says: “Impurities in the gasoline” The IT engineer says: “Hey guys, I have an idea, how about we all get out of the car and get back in” If that's what the IT guy recommends, how do you get users, never mind corporate managers and executives, to take software system quality seriously? Obviously, this isn't what a proper software guy will think, the proper software guy knows that things are a bit more complex than that. But this is what the software guy communicates to non-technical people. And only a few rare non-technical people will tell the software guy, \"OK, look, just tell me what's really going on here, how deep the problem is, and what we need to do to fix it, no matter what it takes.\" Most people won't have the time for that because fact of the matter is that the system satisfices needs until it doesn't, and then it's too late. reply rightbyte 14 minutes agorootparent> The IT engineer says: “Hey guys, I have an idea, how about we all get out of the car and get back in”. I have worked with ECU programming. When test drivers got stuck and called me it was the first thing I told them. \"Restart the vehicle\". If that didn't work, \"disconnect the battery and wait 5 minutes\". They quickly learned. reply mjevans 39 minutes agorootparentprevSoftware is more like blueprints/processes for manufacturing. When something doesn't work right it's a yield rate issue. Oops the process failed, try it again. Software can, and should, also be helpfully smarter. Where there's a chance for invalid inputs, they should be validated. That would help with errors like: * Authentication failed, check your account credentials. * Could not connect to remote server. * Invalid data input, failed to parse around byte/octet 1,234,666, near line 56789 (printable filtered) text: 'Invalid String Example Here' Yes, those are my take on 'software' versions of the starter, battery, and impurity. Lots of well written software will do this, mostly good compilers for software. Poorly written software, often hides these errors if it even collects them at all. PHBs and other less professional people seem allergic to thinking, for them it's easier to call in a specialist or just not do it with the broken tool. reply saurik 2 hours agorootparentprevEven Facebook realized it was dumb and Mark Zuckerberg apologized to us all on stage at f8 a decade or so ago and said they were now going to say \"move fast with stable infra\", yet I still see tons of people fetishize and emulate the original. reply thom 1 hour agorootparentprevThis is a British scandal, and we’re quite capable of avoiding consequences for malfeasance in every sector of our economy, not just IT thank you very much. reply paganel 46 minutes agorootparentThe Grenfell Tower fire comes to mind, as someone was mentioning above how this sort of stuff rarely happens when it comes to buildings and the like. As far as I know there were no real consequences for the people that were directly responsible for that tragedy. reply blitzar 1 hour agorootparentprevcomputer says no reply where-group-by 40 minutes agorootparentprevWhen a dam or a bridge breaks it is game over. When software breaks you restart and it's back to \"working\" order. It would be a different scenario if the computer would set itself on fire on failure. reply palm-tree 6 minutes agorootparentExcept when it's critical software in an aircraft, nuclear power plant, submarine, financial institution etc etc reply spacechild1 1 hour agorootparentprevFor me the biggest joke is that these people call themselves \"software engineers\" in the first place. reply PakG1 17 minutes agorootparentThe unfortunate reality is that everyone else has accepted that they are software engineers. That unfortunately trumps what \"real\" software engineers think. reply arcade79 1 hour agorootparentprev> and yet you don't see very many buildings collapse, bridges fail, and damns flood down valley. Hi! Let me tell you about my wonderful country. Norway! I'm sure you've heard about it. The socialist utopia in Scandinavia! ;-) The Braskereidfoss dam failed during a flood last fall. Luckily just a 'river dam' and not a reservoir dam. Still rather bad. Oh, and during the same freak whether event, but different place in the country. The Randklev railway bridge failed over the river Lågen, just by Ringebu. And during the last 8 years, we've had two road bridges collapse. One by Sjoa in 2016 (Perkolo bridge) and then 16 months ago Tretten bridge. We had the fantastic idea of building wooden bridge sfor road traffic. Here's a nice article on Tretten bridge: https://en.wikipedia.org/wiki/Tretten_Bridge But yeah, not too many building collapses . Just a bunch of infrastructure collapse. reply stevefan1999 2 hours agorootparentprev> and yet you don't see very many buildings collapse, bridges fail, and damns flood down valley Computers, at its best existed for only 200 years. That's counting from the difference engine that Babbage never finished building, and if we are talking about the first modern computer that does contribute significantly in a way, that's around the time ENVAC and Z3 appeared, just around 80 years. Structural Engineering existed for over 2000 years. With that comes with a lot of people died in natural disasters and advancing material science to improve structural integrity. But even the Japanese to this day still can't solve the earthquake and the problems the fallout makes. > Why this isn't applied to software engineering is a whole nother story I actually think it is. That's why real-time operating system and mission-critical hardware exists for human to fly in the air and explore the space, not counting a lot of time-sensitive industry robotics software that controls the actuators in real time as well. That said, the strict requirements of real-time programming requires a lot of expertise such as CPU cycle counting, CPU slack reduction, timing requirements and choice of algorithm (such as EDF scheduling and real time memory allocators like TLSF, and you won't see jemalloc on embedded devices, right?), stack or heap memory allocation which also complicates the programming stuff, because removing malloc might free you from OOM but this means a lot of functions needs to accept extra parameters to state the output location, and that means a lot of normal software can't be used. (You can go for a hybrid approach by using arena allocation, but that still isn't a perfect solution) As you see, even for soft real time engineering (which I actually mentioned so far, I don't know much about the real hardcore \"hard real time engineering\" though), the sheer complexity here already, means there's a lot of design decisions which simply just makes people stay away and just go for normal software engineering (but in the end, if everything is predicable its fine). > Move fast and break things is not something i wanted to hear tbh. When Zuckerberg said that, he's referring to his startup mindset when Facebook was really just a startup in his day. In a highly competitive market environment, startups has to fight desperately for their own survival, even with lots of fundings and VC rounds. Startup can move very fast and their agility is the only weapon against the old dogs. Now you've become one of the old dogs, you don't break things. reply cornel_io 1 hour agorootparentprevThis isn't a story about software engineering, it's a story about a shitty governmental department in a mediocre country not fixing something that everyone knows is broken, and threatening people with jail time instead. Show me a similar story about stuff this bad happening at Google and I'll believe that there's something wrong with the field as practiced at its best. reply jack_riminton 30 minutes agorootparentThe wider 'mood music' is also key here; the government was in the process of privatizing the Post Office i.e. so that they weren't the sole equity owner. Every decision (or non-decision, more appropriately) stemmed from that. This is why the CEO was rewarded with a CBE and a cushy NHS post in 2019 when the scandal was in full swing. She was acting like a good girl for her political masters in managing the crisis, stringing it out long enough in the hope that everyone would forget reply charcircuit 1 hour agorootparentprevIt's easier for software to have a catastrophic failure than a building, bridge, or dam. It's not really a fair comparison when those are like easy mode compared to software. reply DeathArrow 2 hours agoparentprevThe biggest issue isn't the software glitch system. It's the legal system that threatened innocent people with prison for theft unless they admit they are guilty for crimes they didn't do and pay for damages they didn't do. This case was brought to public attention and repairs were attempted only because it's huge and involved hundreds or thousands of people. How many disparate cases there are, where people's lives are destroyed and innocents are rotting in jails, we have to ask? reply usr1106 2 hours agorootparentEvery skillful programmer knows that all software is crap. Judges, salesman, and managers don't understand that. reply gwd 10 minutes agorootparent> Judges... don't understand that. I think for the courts the issue is a bit more subtle. The question is, who's job is it to prove that the other person is wrong (\"burden of proof\")? Should it be the job of the prosecutor to prove that Intel's processor produces the right answer when an ADD instruction is executed? Or should it be the job of the defendant to show that Intel's processor doesn't produce the right answer? What about proving that the compiler produced binaries which faithfully represent the algorithm? What about Excel? In our normal life, if a computer is doing the wrong thing, we don't start by assuming a broken compiler; we start by assuming that the new, not-well-tested code is probably broken. It seems that in the UK before the 90's, the burden of proof was always on the prosecutor to prove almost everything about the system, which is kind of ridiculous. So they passed a law trying to fix it, but messed it up the other way, putting the entire burden of proof on the defendant, without giving them any real way to disprove it. (I mean, shouldn't \"discovery\" at least mean I can inspect the source code?) A more balanced law would say that widely-used software with extensive test suites can generally be assumed to be working properly; but that custom-purpose software needs at least some level of evidence that it's correct, and that defendants have a right to inspect any software that's used against them in court for defects. reply izacus 1 hour agorootparentprevAnd that skillful programmer will fight with all power to avoid any kind of minimum standard and liability for crap software, continuing the cycle and abuse. reply jack_riminton 1 hour agorootparentprevA big problem is they don't want to do the work to understand that, which is the exact outlook the PO had... \"We need some software, ok let's get a big reputable company in to do it for us, we shouldn't get bogged down with all those horrible technical details\" reply zimpenfish 23 minutes agorootparentNot wanting to defend the PO but it wasn't really their decision - it was a PFI (private finance initiative) foisted upon them by the Tory government of the day as one of their recurring \"STOP BENEFIT FRAUD!\" lunacies. reply watwut 1 hour agorootparentprev> Judges, salesman, and managers don't understand that. They do understand that. They do not care. reply PakG1 2 hours agorootparentprevThere are not as many that involve jail, but there are a variety that involve ruined lives and even bankruptcy. A recent example is the Phoenix pay system that was used to pay Canadian federal government employees and contractors. https://en.wikipedia.org/wiki/Phoenix_pay_system And I agree that the problem wasn't the glitches. I personally think it was the corporate governance that failed, not the software development and debugging process. The legal system was complicit and enlarged the overall consequences, but the but for test tells me that it was the poor corporate governance that was at fault for a root cause. reply bsder 1 hour agorootparentprevAgreed. The bug is a footnote. The legal system failed these people horribly. And the people who pursued these cases with no direct evidence whatsoever should suffer jail time. reply jrumbut 1 hour agorootparentprev> The biggest issue isn't the software glitch system. I disagree, the software glitch was the problem here. We are supposed to be able to rely on computers to store and add numbers or report a system failure. This accounting software showed in black and white that some funds that the sub-postmasters were responsible for had gone missing. What else was the legal system supposed to do? The broken software was simulating crime perfectly. reply Arn_Thor 1 hour agorootparentAbsolutely wrong. Mistakes happen. Bugs, fat fingers, laziness, hangovers--whether by human or machine, errors occur. The legal system was supposed to uncover the facts. Because of the Post Office coverup, the judges were told \" no, there are no bugs. No, nobody has remote access to these terminals. Yes, the only possible way these figures could turn up is through theft.\" This despite the fact that at least one Post Office inspector explicitly wrote in a report that there was no evidence of theft. The legal system failed to penetrate the veil of lies and find the truth. That's a legal systemic failure. reply rcxdude 50 minutes agorootparentprevIt wasn't though. If the post office enforcers had taken even a cursory look at the transactions around the 'thefts', they would have noticed obvious errors. One of the bugs basically just duplicated a close-of-day transaction, sometimes many times. This would obviously have looked like an error, it would be a stupid way to commit fraud. It was obvious that the Post Office just preferred to extort money out of the postmasters as opposed to actually work out what was going on (as evidenced by the bonuses for successful payments or convictions) reply DharmaPolice 11 minutes agorootparentprevI think if a handful of people had been prosecuted then it would still be an outrage but understandable. But this was hundreds of cases. I think the legal system has some responsibility for not maybe thinking \"Huh, what are the chances of so many previously law abiding people all committing the same crime in the same time period?\". reply o-o- 16 minutes agoparentprevSome people suck at management, some people suck at coding, and some people suck at self-awareness. I can think of two things that I believe would make a difference in any LargeCorp: First, a standarized way to visualise and execute business logic that allows developers and management to reason together. (The no-code movement is on the right track in fostering a common way to interface with code). And second, a responsible editor for each piece of code. I think a key factor is that software historically hasn't enjoyed industrialisation to the degree of hardware (or construction for that matter). I can buy a standardized CPU of millions of transistors and integrate it into a standardized motherboard with just a snap. We have managed to standardize software up to the OS level, but after that it's up to the developer and her shortcomings. https://www.codevalley.com/ does some interesting work. reply kortilla 2 hours agoparentprevThis is not well researched at all. Anything that depends on “if everyone acted intelligently and good will” is broken. If you’re interested in academia I strongly recommend you go back and look at designing systems that function in the face of incompetence and even adversaries. reply PakG1 2 hours agorootparentYou can have your opinion, but I have mine after reading lots of research papers. Obviously, there are ways that things can still be improved. But even the design of systems that function in the face of incompetence and even adversaries will face intractable problems of incompetent leadership and governance. It's one thing to say \"this is how it should be done\" and it's another to say that we've managed to get people to do it the way it should be done. No matter how much improvement we see on ideas for how it should be done, we're still no closer to solving the second part, despite much effort. In the end, there will always be incompetent leaders in charge at some point for some project somewhere, and more often than we'd prefer. You can lead a horse to water, you can't make it drink. reply heads 2 hours agoparentprevIt would be really interesting to study The Post Office in particular. Something about this organisation attracts some very sour people. Or perhaps they weren’t always like this but have become so in my adult lifetime over the last few decades? In the early 2000s there was a TV ad campaign for “The People’s Post Office” where the sub-postmaster role was played by John Henshaw, a character actor known for playing hard bastards and, in his most recent role on The Cops, an exploitative bent copper from Bradford. A strange but apt piece of casting. reply ponector 1 hour agorootparentLow salary coupled with customer facing job creates sour people. Imagine you are talking everyday to weird, bitter, arrogant, rude customers for years - even with high salary you will be not so positive. reply andy_ppp 24 minutes agoparentprevI could give you a huge list but mostly it is computer programmers having the specification constantly changed by management and stakeholders. Even bad software developers can eventually make the software functional, even good software developers can write bad software if the organisation is going out of its way to break everything they do. reply PakG1 15 minutes agorootparentThere is definitely a sensemaking process where organizations have to figure out what it is that they really need. But I wouldn't fault organizations for that. Most startups go through the same process trying to figure out product-market fit and you don't see those startups blaming their customers for not knowing what they want. reply lijok 41 minutes agoparentprev> why IT incompetence still could exist to this degree in this day and age after all the knowledge the world had developed about good IT and software practices over decades of experience Because we’re not professionals. We don’t profess anything and do not have standards. There is no regulation for our industry and no IT association that can strike you off from practicing this craft. There is no accountability, and when there is no accountability, people naturally regress to either lazy or exciting behaviours. reply porker 2 hours agoparentprev> I quickly found out that IS research had already figured most of this out What is \"IS\" in this context? I did some Operations Research modules at uni and thoroughly enjoyed it, but it had nothing to say about why projects didn't work. reply onei 2 hours agorootparentInformation systems at a guess reply onei 2 hours agoparentprevWere there any particular themes that stood out as you when understanding the causes of IT incompetence? I'm hoping there's a less depressing answer than \"some people will never care\". reply PakG1 2 hours agorootparentI'd say that the biggest thing that stood out to me was what people call communities of practice. Each professional community has their own knowledge and best practices, but these don't generalize well to other professions. So you have boundary spanners who can bridge two professional communities by being good at both, but those types of experts are rare. Also, the amount of experience and learning required to become an expert in two professional communities, rather than just one, requires such a large amount of time that most people can't be bothered to put in the effort. It's enough work to do one's own job well already. The go getters can of course do it as a natural course of action, but they are outliers. There are a limited number of job opportunities that require developing this experience on the job, so there are limited opportunities to become a good boundary spanner in the first place. Furthermore, people aren't naturally interested in multiple disparate subjects. True renaissance folks like Leonardo da Vinci who are interested in becoming experts in both art and engineering are rare. Elon Musk types that will try to dive deep into multiple unrelated areas are rare. All of this adds up to boundary spanners being rare. As such, leaders who can develop cultures that handle multiple areas simultaneously (see the founders of Flexport who understand both tech and shipping logistics) are rare. In short, expertise is hard to develop, expertise in multiple areas is rare, and coordination between two areas that understand different worlds is difficult without boundary spanners. As a result, you get failures. See any software engineer who creates a startup to try to revolutionize some old-school industry and then fails dramatically because they don't understand the problems that actually need to be solved. The outliers will figure it out, but not everyone can become an outlier due to reasons discussed, among other reasons. reply IronWolve 2 hours agoparentprevI did a quick look around for some blogs about this early paper to digital transaction register migration, I didn't see much for such a major case. Just a few basic things that wasn't included, no audit/transaction logs, transactions modified by tech support to keep the system running. Operators couldn't prove they didn't steal funds, and the british law that computers systems are to be trusted as fact, pretty much convicted them all. reply imtringued 2 hours agorootparentThis isn't a software error and it is pretty clear. There are two problems here. First, the branch manager is responsible for calculated shortfalls, even if the software is broken. Second, there is no way to overturn broken software. Third, the prosecutors are overzealous in trying to shut these people up and convict them straight away. The software itself was just a convenient medium for abuse of authority. reply madaxe_again 2 hours agoparentprev> people of integrity Our current system of the world quite strongly disincentivises honesty and integrity - rather, being a bombastic charlatan with a flexible relationship with the truth will get you anywhere. reply risyachka 1 hour agoparentprevMost of the time issues like these are from companies that pay like $50k salary for senior positions. So everything checks out. reply londons_explore 3 minutes agoprevI don't fully understand how people end up in prison over this... If the software says there should be X money in the cash drawer, but there is actually Y money, then clearly something is wrong, so you investigate. You get the software to print off a list of every sale made that day with timestamps. You check the stores CCTV so see when every customer came into and out of the store. You cross reference. If you are a store manager wrongly accused of fraud, of course you can be bothered to do this. It would only take one store to do this to find out that the software was wrong. reply interestica 1 hour agoprevThe BBC aired this story as a documentary in 2015 as part of the Panorama series. They received threats from the Post Office over the content. > The Post Office threatened and lied to the BBC in a failed effort to suppress key evidence that helped clear postmasters in the Horizon scandal. > The Post Office's false claims did not stop the programme, but they did cause the BBC to delay the broadcast by several weeks. https://www.bbc.com/news/uk-67884743 It wasn't just a \"glitch\" -- it was also a PR campaign (quite successful up to now) that supporessed the voices of those affected. reply shaoonb 25 minutes agoparentI find it shocking that this has been known about for so long, but only now that there was a TV drama about it is it actually being addressed. It came up in the news and I thought \"what, I remember hearing about this 5 years ago, surely it's been sorted out by now?\" reply onetimeuse92304 2 hours agoprevHere some more information about what really went down, technically, behind the scenes: https://www.theguardian.com/uk-news/2024/jan/09/how-the-post... \"One member of the development team, David McDonnell, who had worked on the Epos system side of the project, told the inquiry that “of eight [people] in the development team, two were very good, another two were mediocre but we could work with them, and then there were probably three or four who just weren’t up to it and weren’t capable of producing professional code”.\" (Just in case somebody says I am putting blame on developers) Obviously, the responsibility is firmly on management. People making code bugs should not be held responsible for other people going to prison for it. reply josephg 2 hours agoparent> Obviously, the responsibility is firmly on management. People making code bugs should not be held responsible for other people going to prison for it. This is a controversial opinion but I disagree, at least to a point. Managers don’t really know what we do. The only people who really understand the engineering trade offs involved are engineers. When lives are on the line as a result of our work, we shouldn’t be insulated from the consequences of our choices. That’s not good for society and ultimately not good for us. We change the world with our work. It’s healthy to understand and own the consequences of that. The law agrees in parts. The principle of tort law is that everyone is responsible for foreseeable harm caused to your “neighbours”. Your degree of responsibility - and in turn liability - scales with how much expertise you have in the domain. An expert should have been able to foresee the harm more than a novice. The senior engineers on the team should have done better. I believe they are at fault. (IANAL, this is not legal advice, yadda yadda) reply sitharus 2 hours agorootparentI agree, but only if we have the same standing and legal protection as professional engineers. If I’m going to be legally responsible for software bugs I must have the legal right to tell management that their timelines are not possible, and that they can’t deploy software I won’t sign off on. That and for outsourced software the executives become personally responsible. reply josephg 48 minutes agorootparentI agree with every one of those points. There were two massive data breaches in Australia recently. I’m livid that nobody was held liable for damages over it. reply jbjohns 1 hour agorootparentprevThe only one who can have responsibility for anything is the one who has the authority. So long as developers are in a position of \"just get it done or you're fired\" as well as being outsourced to save costs, they have no authority in this and therefor zero responsibility. If management \"doesn't know what we do\" and doesn't want to have the responsibility then they have to give us the authority to say \"no, this is not going to be done tomorrow and we're not cutting any corners\". reply josephg 40 minutes agorootparent> just get it done or you're fired Who actually works in a job like that? Do you seriously think you’re a slave to your boss, with no personal agency? Do you think your employer wants you to be feckless? Do you think that’s good for your career? Your capacity to take responsibility is the differentiating factor between junior and senior engineers. Learn to step up. If nothing else, your pay check in 10 years time will thank you. reply onetimeuse92304 2 hours agorootparentprev>An expert should have been able to foresee the harm more than a novice. The senior engineers on the team should have done better. I believe they are at fault. Well, the reality is usually at these large software development agencies that senior engineers are prevented from doing what they think is right. For example, they might have been pressed to deliver new features in an extremely inefficient system. They might have been inundated by low quality code from less experienced devs. They might have been busy with communication with stakeholders and unable to do much about it. So singling out these developers would be like singling out couple cops for being racist when the entire Police department is known for racism. You know, technically you are right but that still does not seem to be right thing to do in case of a systemic problem. The question would be if these developers had any way of knowing the consequences of what they were doing. Also, \"good developers\" is a relative term. In an organisation like that a \"good developer\" might simply describe a person that is at all capable of writing working code. It does not mean they were experienced or aware what is happening around them. It is the responsibility of managers to recognise the issues with the environment their people are working in. reply josephg 43 minutes agorootparent> Well, the reality is usually at these large software development agencies that senior engineers are prevented from doing what they think is right. Can you imagine how that conversation would go if the engineers were personally liable? “Hah you want me to sign off on that? No - I don’t want to get sued when it inevitably goes wrong. I’m sorry boss but I won’t do it. And you won’t find another engineer in the building who will. Lives are on the line. We either do it properly or we leave it alone. I’m not sticking my neck out to make the business a quick buck.” > Also, \"good developers\" is a relative term. Legally, as I understand it the courts look at job titles, education and experience to make a judgement. reply LunaSea 2 hours agorootparentprev> Managers don’t really know what we do That looks a lot like incompetent management. reply josephg 39 minutes agorootparentManagement aren’t trained engineers. They shouldn’t have to be. We’re the experts in the room. That’s literally what we’re hired for. We should act like it and stop trying to pass blame to other people. reply jack_riminton 25 minutes agorootparentWhilst I agree in some respects, the biggest gulf to me is between companies like Stripe who successfully manage a large chunk of the words commerce (led by a brilliant engineer-CEO) and the 'IT Projects' that seem to plague the public sector here in the UK. My point is that particularly in the UK we have this culture that the Geeks should just do their job and let us Business Types take care of the rest. Countries like Germany have a much higher respect of technical people and qualifications e.g. it's very common for CEO's to have PhDs reply josephg 11 minutes agorootparentIt’s not about having a PhD. If I pay to have a house built, the point of paying money to a construction company is that I don’t know how to build a house. I’m hiring them because they’re experts and I’m not. If the house falls down and kills someone, the construction company is responsible. I don’t know how to tell if a building is safe because I’m not a working engineer. (And even if I was, it’s still the construction company’s job to build my house properly. That’s what I’m paying them for.) In software, it’s the same. Your employer hires you because they need an expert. It’s your job to take responsibility for the software you write. Even if the CEO has a PhD, it’s not the job of senior management to review your code. And - trust me - they don’t want to. Instead take responsibility for your own work. You are worth your paycheck because you know how to build software well. Stop trying to shirk your job. reply Kinrany 1 hour agorootparentprevI agree, except that it's important to remember that code by itself is as meaningless as programs with no side effects. A bug becomes a problem when it's a part of a running program. reply imtringued 2 hours agorootparentprevSo, you're telling me your manager doesn't care if the software is broken and has legal consequences for it's users? That strategy only works if the software itself is inconsequential. reply onei 2 hours agoparentprevFrom that article (and a few others) > In fact, staff at Fujitsu, which made and operated the Horizon system, were capable of remotely accessing branch accounts, and had “unrestricted and unaudited” access to those systems, the inquiry heard. This has always bothered me. Sure, it's possible to build APIs that audit access completely. But I can easily write code that circumvents those APIs. Code isn't like a building where the walls are impenetrable and the doors the only possible access points - we can redecorate without ever touching the door. Building in an unaudited backdoor for operators seems bad, but if you can edit the source code the backdoors are infinite. reply fbdab103 2 hours agorootparentThere should be application level auditing and database level. The people with access to managing the database level auditing should be extremely limited. reply robaato 1 hour agorootparentAccounting 101 use journal entries to correct mistakes. Dont edit original records... Have a transaction log... reply onetimeuse92304 2 hours agorootparentprevListen. We all know what should have been done. They were not able to do the first thing about running a transaction (ensure that one side of the transaction isn't executed multiple times). What you are saying is an obvious thing and yet it probably is well beyond the maturity of the team that was working on it. reply willvarfar 2 hours agorootparentprevInterestingly, it seems they may have built their own master-master xml-based database. It's easy to guess that they didn't add an audit feature etc. reply stavros 2 hours agoparentprev> People making code bugs should not be held responsible for other people going to prison for it. Why not? If I'm the single developer and seller of this app, should I not be held responsible? What if there's also a QA person? Two of each? Should the person selling or marketing the app be held responsible instead, even if they aren't technical? Why are the developers who didn't care enough to double-check their code free of responsibility? reply tpm 1 hour agorootparent> If I'm the single developer and seller of this app In that case you are also the responsible manager or product owner. > Should the person selling or marketing the app be held responsible instead, even if they aren't technical? Of course. The person who takes the customers money is responsible for delivering the result and any warranty. > Why are the developers who didn't care enough to double-check their code free of responsibility? They are not the product owners. They don't decide what is the correct way the product works. Maybe they created the bugs because they implemented the specification exactly as written? reply stavros 57 minutes agorootparent> They don't decide what is the correct way the product works. Of course we are, we're the ones writing it. > Maybe they created the bugs because they implemented the specification exactly as written? If your argument is \"maybe they were told to write the bug in\", I don't know what to tell you. If I were told to write a life-destroying bug into the software I worked on, I'd quit, because I don't want that on my conscience. reply watwut 1 hour agorootparentprevIn your hypothetical situation, I would blame the justice and banking system. It should not be so vulnerable or eager to believe an app made by one person, a self made \"expert\" on something, new theory etc. Like, you as a single seller are also responsible for making false claims. But, the justice itself should be more robust then that. reply freetanga 2 hours agoprevI have read about this somewhere else. The key issue seemed to be in the Post Office internal “Justice” system, which is opaque, biased and refused to consider evidence. It’s pretty stupid that in an age where we strife for universal rights, your job could strip you from defending yourself on the public justice system, with all its defects and warranties… The IT bug was an issue, sure, but the political mismanagement of an institution stuck in the past is what caused all the ruin for so many people. And it flew under the radar until Netflix made a movie. Actually, the lady running the PO was awarded a Goverment recognition. IT and code generation is full of pitfalls, but this one lays somewhere else. reply freetanga 2 hours agoparentFrom the FT article: __The state-owned Post Office acted as investigator and prosecutor in the cases, using the general right in English law for any individuals and organisations to pursue private prosecutions without involving the CPS. A public inquiry into the scandal has heard that the Post Office, among other aggressive legal tactics, accused sub-postmasters of theft to pressure them into pleading guilty to lesser charges. The CPS has identified 11 cases it brought against sub-postmasters that involved “notable evidence” from the Horizon system. Legal experts said the government had been warned several years ago that private prosecutions carried a higher risk because those pursuing them were more likely to have motivations other than securing justice. Lord Ken Macdonald KC, a former director of public prosecutions, said: “If you’ve got a body with skin in the game [such as the Post Office] acting as a prosecutor, that creates obvious risks and dangers.”__ reply lmm 24 minutes agorootparentIMO the private prosecution is a necessary safeguard. In other countries you get the opposite problem: a gross injustice has been done, but the public prosecutor won't prosecute (often because the perpetrator was connected with the government in one way or another), so nothing gets done. reply jack_riminton 1 hour agoparentprevManagement but no leadership The CEO managed the crisis, therefore she was rewarded. The government should have shown leadership and demanded answers after the first few years of warning signs. Yet it took 20 years and a TV drama to force them to show any leadership reply freetanga 1 hour agorootparentWell, they only took 60+ years in admitting they went over they line by castrating Turing for being gay - after his huge relevance in keeping the UK safe in WW2 and using his name and face as poster for the role of UK in Computing History. The UK Goverment really needs to shake off all this archaic nonsense and modernize themlselves. It’s not in line with the fantastic culture of their country. reply esskay 1 hour agoparentprevSlight correction, ITV made the series Mr Bates vs the Post Office, not Netfix (no idea if its being shown internationally on Netflix under license however). reply abrookewood 58 minutes agoprevThis is very similar to the robodebt scheme [0] that happened in Australia with similarly devastating consequences: - Welfare recipients' suicide after receiving automated debt recovery notices - Debt notices were issued to deceased people. - Issuing debt notices to disability pensioners. Looks like Wikipedia has termed this Algocracy (government by algorithm). [0] https://en.wikipedia.org/wiki/Robodebt_scheme reply partomniscient 25 minutes agoparentIt's kind of similar, but in Robodebt it was more a case of covertly implementing a wrong algorithm for debt calculation (because it inferred good results for the government of the time), placing the responsibility of disproving the debt on the individual with ridiculous requirements and no support or process to easily challenge them. It was really a result of the Liberal & National Party (LNP) who were in government at the time wanting to: - look tough on welfare cheats for image/election purposes - claim a potential massive source of income (that wasn't really there) for the next budget Most of the wrong calculations were due to a result of income averaging fortnight or multiple fortnights worth of income and extrapolating them to an annual figure, which is the absolute wrong thing to do when a lot of people on welfare worked as casuals and/or had short term jobs and the fortnight(/s) were non-representative of their yearly income. In some cases the first time the alleged debtee found out about the debt was via a demand from a debt collection agency. When individual action was taken against them, the government was reducing debts to $0.00 and then claiming there was no longer a reason for a case against them and had it dropped. The only reason the debt recovery program was stopped was because lawyers acting upon someones behalf also claimed interest on a paid false debt, which meant they couldn't succeed using the same tactic at which point they rolled over and admitted the unlawfulness of the scheme, which had been going for many years at this point. I recommend this youtube 3 part series to get a good understanding of what was involved: [0] https://www.youtube.com/watch?v=OfsL9GAbl3M It starts out mentioning that it resulted in the largest class action lawsuit in Australian history... reply derriz 2 hours agoprevPlenty of obvious villains in this story but where was the legal system in all this? 900 prosecutions without any real evidence or just because “the computer says so”? As one of the 3 pillars, isn’t the legal system and judiciary supposed to act as a backstop against this sort of capricious mass-persecution of completely innocent people? reply laurieg 1 hour agoparentHere are the judge's instructions to the jury for one of the trials: \"There is no direct evidence of her taking any money [...] She adamantly denies stealing. There is no CCTV evidence. There are no fingerprints or marked bank notes or anything of that kind. There is no evidence of her accumulating cash anywhere else or spending large sums of money or paying off debts, no evidence about her bank accounts at all. Nothing incriminating was found when her home was searched.\" (The only evidence was a shortfall of cash compared to what the Post Office’s Horizon computer system said should have been in the branch.) \"Do you accept the prosecution case that there is ample evidence before you to establish that Horizon is a tried and tested system in use at thousands of post offices for several years, fundamentally robust and reliable?\" My word against yours wouldn't be enough to meet the standard of \"beyond a reasonable doubt\", but the Post Office's word backed up by a computer system? It seems that was convincing enough for the jury. They gave a guilty verdict in the above case. reply forinti 25 minutes agorootparentThe judge should have asked for an accountant to review the books. Surely the system must be able to spit out what services and products were sold and how much they would be worth. reply elthran 1 hour agorootparentprevThis sort of thing is why I've always hated the concept of a random jury from the general populace - In this example, I don't want Joe Bloggs the butcher's understanding of complex computer systems being the determination of whether I am criminally convicted, I want 12 people who have at least some experience programming. reply veltas 27 minutes agorootparentprevWhich trial? reply ChocMontePy 1 hour agoparentprevOne of the problems is that the UK legal system has a presumption that computers are reliable. They are assumed to be working properly unless proved otherwise, which shifts the burden of proof on the person trying to claim that they are not working properly. Many commentators are saying that this presumption should be changed: https://www.theguardian.com/uk-news/2024/jan/12/update-law-o... https://www.forbes.com/sites/emmawoollacott/2024/01/15/law-o... reply thom 1 hour agorootparentThis was coupled by the victims being lied to that they were the only ones. Had they known this was systematic they could have mounted a more effective defence. reply samtho 2 hours agoparentprevThis is the real failure. The software is neither smart nor dumb, it’s a machine. In this case, it was broken, but people who actually have the ability to critically analyze and judge situations deferred to the output of a machine that they have no real visibility into the internals of, and took its output as gospel. reply veltas 38 minutes agoparentprevIf you want an example read all of https://www.bailii.org/ew/cases/EWHC/QB/2007/5.html reply madaxe_again 2 hours agoparentprevThe post office can draw its own prosecutions - no need for the prosecution service etc., and in general, a magistrate confronted with His Majesty’s Postal Service’s Honourable Legal Team (OBE, CBE) and This Dirty Bloke With a Regional Accent What We Reckon Stole From Us will chose the government every time. reply laurieg 1 hour agoprevThis story has finally been getting the air it deserves. If you want a summary and insight into the staggering scale of the injustice, this article from Private Eye magazine is worth reading: https://www.private-eye.co.uk/pictures/special_reports/justi... This BBC radio programme, started in 2020, also gives a lot of good information including details of how suspected sub-postmasters were questioned by the Post Office. https://www.bbc.co.uk/sounds/brand/m000jf7j reply onion2k 2 hours agoprevIn my last team I banned use of the word 'glitch'. It was a catch-all phrase for \"bug I don't want to take ownership of\" used by developers and product owners alike when they were talking to customers. It has no place in a modern tech team. reply m463 2 hours agoparentCan you own everything? reply mjh2539 1 hour agorootparentYou can't own everything, but referring to something as a \"glitch\" is essentially ITs thought-terminating cliche. reply onion2k 1 hour agorootparentprevYou can own all the bugs. reply IronWolve 3 hours agoprevWouldn't say it was just a software glitch, bureaucracy tried to cover it for bad press at all levels in the government ran agency. reply iforgotpassword 2 hours agoparentThat's why I don't really (knowingly) want to work on something that could ruin lives if there's a bug. medical devices? Hell no. (But you never know where your code ends up running.) As you said this didn't just involve software issues to get that big, but I still wonder how all the devs that worked on this over the years could just shrug it off all these years. You can't tell me not a single dev got wind of these issues. Did they just immediately jump to \"impossible I'm the most awesome person on this planet no way there's a problem these people all just stole money\". I'd have sleepless nights going over the whole system in my mind trying to figure out where things went wrong. Is this some sort of dunning -kruger going on? I don't really consider myself a coding wizard or anything, but I think I know about enough to know I'll keep producing bugs til the day I die. Rust won't stop logic bugs from happening. reply bigfudge 2 hours agorootparentPerhaps your humility qualifies you for it! It strikes me that the problems aren’t caused by lack of technical chops per se - it’s almost always because people don’t consider the possible downsides of mistakes and act accordingly. reply guappa 2 hours agorootparentprevWell it was basically some banking software… I'm following a BBC podcast about the story, and basically the managers and investigators at the post office knew there were issues. They told every single victim \"you're the only one who's claiming there are issues\". reply calpaterson 3 hours agoparentprevIndeed. And it was a number of different bugs, not just one. reply jbverschoor 1 hour agoprevRight how, software is seen as truth. This is simply not always the case. I’m happy ai is getting a lot of attention, as people seem to be more aware that its judgement can be wrong. What is needed is the requirement that software decisions must disclose their data and decisions path/ “algorithm” in court. Another thing we need laws for is banning a person from using a system. It’s insane that you can be banned for life without recourse or explanation. It’s basically you being thrown in jail for life without reason. reply surfingdino 2 hours agoprevThe worst thing about it was the assumption that the computer system was right and the people were crooks. This should give people wanting to stick AI into every orifice of our lives a pause, but I have a feeling it will not. reply madsbuch 2 hours agoprevBased on the article, this also appears to be miscarriage of justice. A lawyer recommending an innocent person to plea guilty sounds like a lawyer not doing their work properly. reply gmac 2 hours agoparentAgreed. Although, as I understand it, this also happens to be a staple of the US legal system: https://stfrancislaw.com/blog/whats-a-plea-bargain-and-how-d... reply quickthrower2 1 hour agoparentprevOr they know they are up against a kangaroo court. reply guappa 2 hours agoparentprevThey didn't have access to the full documentation, let alone be able to review the software itself. reply kunley 26 minutes agoprevI would guess it's the corruption of tenders in the public sector. The organisation in the public sector must choose the right vendor and then any sh*t sold by this vendor is correct, otherwise it would prove the wrong choice. reply passerby1 2 hours agoprevWould someone suggest how would hundreds of investigations (and courts? Or there were no courts at all?) were not able to shed any light on the bug? How is it even possible to continue for more than 20 years? reply jdietrich 17 minutes agoparentThe Post Office knew that the Horizon system was deeply flawed and that the prosecutions they were pursuing were unsound. They intentionally covered up this fact. The courts adjudicated based on evidence provided by the Post Office, but that evidence intentionally omitted things like error logs that would have undermined their case. The defendants had a right to see that evidence, but the Post Office simply denied that it existed. The Post Office were helped by the fact that the rules of evidence presume that computer records are accurate unless shown otherwise - the burden was on the defence to show that Horizon was flawed, not on the Post Office to show that it was reliable. Lots of things had to go wrong for this miscarriage of justice to happen, but at the core of it all is the fact that the Post Office lied for years - to the defendants, to the courts, to the media, to government. Things should have been handled differently, the case has revealed a number of systematic failings that need to be urgently addressed, but there's only so much the legal system can do to defend against very sophisticated people who engage in a determined campaign of deceit. We can reduce the risk of something like this happening again, but sadly we can't eliminate that risk entirely. https://davidallengreen.com/2024/01/how-the-legal-system-mad... reply g_p 1 hour agoparentprevIt's worth noting that courts (in the common law system) don't generally play any kind of inquisitive role in cases - there's a presumption that both sides bring legal representation for an adversarial debate where the court is impartial and independent. Given many of the sub post masters struggled to fund their legal cases (and legal aid is not likely going to stretch to funding the intensity of expert witness work required to discredit a whole system), this also seems to be one of the non technical failings not often talked about. There's certainly questions about why courts didn't spot issues, but ultimately the common law adversarial system assumes both parties can get equal quality of representation. Unless you have very strong technical knowledge (this site is a non representative sample!) you'd struggle to really shed any light on the bug and get a court to agree with your line of defence. Ultimately that's what did happen in the group litigation by Bates, about which the TV drama was ultimately created. reply arkh 1 hour agoparentprevImagine you are head of some administration. Times are getting hard, profits are decreasing so you can not embezzle money as much or as easily. You know people under you must be stealing, and some new software just happen to be able to prove it. Here is the solution to help pay your third mansion in the south of France. reply time4tea 1 hour agoprevIn UK law, it is presumed that computers systems work perfectly, and it is up to the \"other side\" to prove they didn't. In short, if the computer said so, it is a fact, in court. Lots more information here https://evidencecritical.systems/2022/06/30/briefing-presump... reply asmnzxklopqw 2 hours agoprevWow, if something like this happened in the mainland Europe, probably many heads would fall, up to the ministerial level. For the establishment in good ol’ England it’s just another day. reply irdc 1 hour agoparentDid you hear about the Dutch childcare benefits scandal (https://en.wikipedia.org/wiki/Dutch_childcare_benefits_scand...) yet? That one affected about 28’000 parents with 70’000 children and, due to the illegal separation of children from their parents this resulted in, is at the crimes-against-humanity level. reply st-keller 2 hours agoprevI found the caption misleading. This article describes the dreadful ramifications of error(s) in a complex IT system. What it falls short of are details on the hows. reply IronWolve 2 hours agoparentIt was from the article, not sure how its misleading. Its pretty much the biggest tech scandal in the news right now. https://en.wikipedia.org/wiki/British_Post_Office_scandal reply a-dub 2 hours agoprevdidn't terry gilliam make a movie about literal bugs in government computers ruining lives back in the early 80s? reply momentoftop 1 hour agoparent\"Tuttle? His name's Buttle. There must be some mistake.\" \"Mistake? Ha! We don't make mistakes.\" Proceeds to drop ceiling plug through ceiling. \"That's bloody typical. They've gone back to metric without telling us.\" reply vidarh 2 hours agoparentprevBrazil. With a very unfortunate typo causing mistaken identity. reply HideousKojima 2 hours agorootparentThe most hilarious part to me was when the main character's friend (the government torturer guy) suggested that the mixup was intentionally caused by the wrongfully accused (or something along those lines?) as a way to make the government look bad. reply surfingdino 1 hour agorootparentWhen I applied for a passport around 20 years ago my local passport office used an old fingerprint reader that often failed to register fingerprints. I was told to try different fingers and when all attempts failed I jokingly offered my toes for scanning. The officials operating the system told me that won't be necessary, because \"the system has provision for people without hands\"... needless to say my hands are still attached to my body. reply IronWolve 2 hours agoparentprevMr Bates vs The Post Office just came out on the ITV, is about the incident in the article. trailer @ https://www.youtube.com/watch?v=zPkvYXufpAY reply Arn_Thor 2 hours agoparentprevBrazil reply Gee8r9 2 hours agoprevIt was not a software glitch! Such thing would get normally discovered and fixed in a few months It was corrupt managers, police and goverment! Literal conspiracy to destroy lives of innocent people! reply iforgotpassword 2 hours agoparentSo the corruption made it that somehow that bug-free software produced inconsistencies in accounting? Interesting. reply mathieuh 2 hours agorootparentThere were hundreds of these cases, and the affect post-masters were calling the IT helpline repeatedly saying sums of money were going missing. Personally I think that if you have hundreds of people of good reputation and standing swearing up and down that they didn't steal money, and there's a record of their having called repeatedly to report erroneous data in the software, then there should be some sort of investigation to figure out what was going on. Instead they were shouted down and threatened. reply guappa 2 hours agorootparentThere was a case where after a call to the IT helpline the \"missing\" money just doubled, and the helpline just said \"well pay the new amount or go to jail\" reply vidarh 2 hours agorootparentprevThe point is that the bugs on their own would have been merely a nuisance leading to unnecessary audits if not for the severe mismanagement around them. reply imtringued 2 hours agorootparentprevNobody said the software is bug free. That is your interpretation. The corruption lies in the fact that the bug wasn't fixed. reply iforgotpassword 1 hour agorootparent> Nobody said the software is bug free. The comment I replied to literally said exactly that. reply vijaybritto 53 minutes agoprev [–] P1: I brought down prod with a faulty migration script P2: oh Im responsible for the deaths of many people and court cases spanning 2 decades. There's even a tv show based on the story reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The provided information includes code snippets and descriptions of their functionality, covering topics such as CSS styling, JavaScript functionality, advertising configurations, user consent management, and data encoding.",
      "The UK Post Office scandal is discussed, involving a software glitch that caused financial discrepancies for sub-postmasters, leading to serious consequences, legal battles, and loss of life."
    ],
    "commentSummary": [
      "This article discusses real-life cases of software glitches, highlighting the severe consequences they can have, including prison, bankruptcy, and even suicide.",
      "It emphasizes the need for accountability and safeguards in software engineering, as well as the underestimation of the impact of software glitches.",
      "The article emphasizes the importance of addressing software issues early on to prevent them from becoming major problems and highlights the challenges of getting non-technical individuals to take software quality seriously."
    ],
    "points": 168,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1705386155
  }
]
