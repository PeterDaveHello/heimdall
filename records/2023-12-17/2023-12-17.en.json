[
  {
    "id": 38666032,
    "title": "\"The New Essential Guide to Electronics in Shenzhen\": Updated Book Reveals Digital Etiquette and Cultural Changes",
    "originLink": "https://www.bunniestudios.com/blog/?p=6886",
    "originBody": "« Name that Ware, November 2023 The New Essential Guide to Electronics in Shenzhen Some might remember a book I released in 2016, “The Essential Guide to Electronics in Shenzhen”. A lot has changed in the world since then, and Shenzhen is no exception. There’s a new maintainer of the guide, Naomi Wu (@realsexycyborg), and she is crowdfunding an updated, new version with a snazzy red cover, called “The New Essential Guide to Electronics in Shenzhen”. While the technical Chinese terms haven’t changed much, a lot has changed in the culture and ways to do business; her new text gives pointers on how to engage on Wechat, digital etiquette in China, updated maps, and much more. If you enjoyed The Guide in the past, or hope to visit the electronics markets in Shenzhen in the future, you can reserve your copy today. This entry was posted on Saturday, December 16th, 2023 at 11:19 pm and is filed under Made in China, Social. You can follow any responses to this entry through the RSS 2.0 feed. You can leave a response, or trackback from your own site. Leave a Reply Name (required) Mail (will not be published) (required) Website bunnie's blog is proudly powered by WordPress Entries (RSS) and Comments (RSS).",
    "commentLink": "https://news.ycombinator.com/item?id=38666032",
    "commentBody": "The New Essential Guide to Electronics in ShenzhenHacker NewspastloginThe New Essential Guide to Electronics in Shenzhen (bunniestudios.com) 333 points by kungfudoi 16 hours ago| hidepastfavorite111 comments TheLegace 9 hours agoI own this book. It was invaluable navigating Shenzhen electronics markets. In Shenzhen it is easy to find any electronic part you need and has an extensive recycling ecosystem. You can find parts on the street which find it&#x27;s way upstream and end up in completed phones. Those phones are then resold.That was my goal when I was there to build an iPhone in my hotel room by buying every individual part. And except for the thumbprint(because it needs to be reflashed) everything worked perfectly. I even named it my non-Sweatshop iPhone. reply cortesoft 4 hours agoparent> I even named it my non-Sweatshop iPhoneAre the conditions at the parts factories any better than at the final assembly factory? reply KeplerBoy 2 hours agorootparentProbably. I guess the final assembly requires the highest amount of cheap relatively unskilled labor.Actual chip foundries are no sweat shops. reply conception 7 hours agoparentprevThat sounds like an amazing vlog&#x2F;blog article. Any chance you made one? reply starkparker 7 hours agorootparentNot OP, but: https:&#x2F;&#x2F;www.strangeparts.com&#x2F;how-i-made-my-own-iphone-in-chi...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=14100989EDIT: Noticed that&#x27;s Naomi Wu with the top comment on that HN discussion. reply mensetmanusman 6 hours agoparentprevHow much cheaper was it? reply smashed 5 hours agorootparentIt doesn&#x27;t have to be about saving money. reply jacquesm 1 hour agoprevNote this not so veiled warning in the text:\"The other reason there won’t be an electronic edition is that unlike bunnie, I’m a Chinese national. My offering an app or download specifically for English-speaking hardware engineers to install on their phones would be… iffy. If at some point \"I\" do offer you such a thing, I’d suggest you not use it.\"Especially the \"I\" bit. reply zoom6628 41 minutes agoprevPlaced my order out of respect for Bunnie and Naomi. Legends for different reasons but for any real hardware hacker they are worthy of due respect for their work, their communicating of it, and their sharing. reply kqr2 11 hours agoprevThere used to be some hacker tours of Shenzhen via Dangerous Prototypes and Noise Bridge. Any other recent or current ones? reply jancsika 14 hours agoprevIs there any niche of vendors somewhat equivalent to free software zealots in Shenzhen? E.g., \"you can boot this little keychain thingy without blobs.\" reply carom 13 hours agoparentThere are another few bunnie blogs [1] on that. The concept is called gongkai. It means open in the sense of IP is shared freely.1. https:&#x2F;&#x2F;www.bunniestudios.com&#x2F;blog&#x2F;?p=4297 reply jancsika 12 hours agorootparentHm, if that&#x27;s the case then why don&#x27;t Western open source hardware projects just send a bilingual tourist over to Shenzhen to muck around until they connect with someone who can give them the docs needed to bootstrap the relevant firmware&#x2F;drivers for the boards? reply aleph_minus_one 12 hours agorootparentMy guess: legal concerns. What is legal (or at least tolerated) in China with respect to gongkai is not necessarily legal in the Western world. reply jancsika 11 hours agorootparentI&#x27;m just surprised there seems to be no bridge whatsoever between the two.Like the developer asks, \"what&#x27;s the address to set this bit?\" and the tourist responds with whatever it is. reply numpad0 2 hours agorootparentprevWhy wouldn&#x27;t they be able to ask in IRC&#x2F;Discord&#x2F;whatever still works in Hong Kong? Or, just have a Taiwanese hacker guy in the group? reply DeathArrow 3 hours agorootparentprevBecause that costs money. reply contrarian1234 11 hours agorootparentprevDo you know what he&#x27;s up to?I remember he was working on some super encrypted FPGA phone ages ago.. and then I haven&#x27;t hear his name in .. years? reply 0xCMP 11 hours agorootparentHe is still working on it, the precursor, they&#x27;re just starting development of the messaging app that will run on that dev platform and eventually run on the betrusted final device. reply wannacboatmovie 13 hours agoparentprevThere&#x27;s plenty of free software thieves (the GPL violating kind) in Shenzhen. Sadly, there isn&#x27;t a goddamn thing we can do about it.Go ahead, try enforcing the GPL in China. They&#x27;ll just laugh in your face whilst trying to sell you the next shoddy widget on AliExpressazon. reply Animats 11 hours agorootparent> Go ahead, try enforcing the GPL in China.Naomi Wu has actually done that.[1][1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Vj04MKykmnQ reply wannacboatmovie 10 hours agorootparentThe same Naomi Wu that recently was visited by CCP goons who told her to mind her p&#x27;s and q&#x27;s? Yeah I don&#x27;t see this happening again. reply chpatrick 8 hours agorootparentAs far as I know it was because of \"reactionary\" tweets, not GPL enforcement. reply NicoJuicy 8 hours agorootparentNo, it was after she went to a business that violated gpl.She put it on YouTube and then she got silenced. reply lvturner 1 hour agorootparentAssuming this linked video is accurate, your statement is not quite correct.https:&#x2F;&#x2F;youtu.be&#x2F;3p7bl7eFaEo?si=kAXZHfA2lxbXlLv- reply faitswulff 9 hours agorootparentprevHow is that relevant to enforcing GPL? reply obmelvin 6 hours agorootparentSee this peer comment - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38669000 reply NicoJuicy 10 hours agorootparentprevReallySexyCyborg?Yeah, she tried that and then guess what happened...> Ok for those of you that haven&#x27;t figured it out I got my wings clipped and they weren&#x27;t gentle about it- so there&#x27;s not going to be much posting on social media anymore and only on very specific subjects. I can leave but Kaidi can&#x27;t so we&#x27;re just going to follow the new rules and that&#x27;s that. Nothing personal if I don&#x27;t like and reply like I used to. I&#x27;ll be focusing on the store and the occasional video. Thanks for understanding, it was fun while it lasted.https:&#x2F;&#x2F;twitter.com&#x2F;RealSexyCyborg&#x2F;status&#x2F;167748080945083596...She stopped uploading YouTube videos 6 months ago after 7 years.More here: https:&#x2F;&#x2F;www.hackingbutlegal.com&#x2F;p&#x2F;naomi-wu-and-the-silence-t... reply JimDabell 2 hours agorootparentThat wasn’t anything to do with attempting to enforce the GPL though. reply kahnclusions 2 hours agorootparentprevWow, the police sent plainclothes thugs to her home to harass her, and her partner who is an Uygher is banned from leaving the country. reply DeathArrow 3 hours agorootparentprevI think many Chinese companies freely share code between them, regardless if it&#x27;s open source or not. They just don&#x27;t care about licenses and IP the way the West does.So, if you want to get the source code for X, you just have to learn Cantonese, go there and ask nicely. reply isnifailed 12 hours agorootparentprevSo, exactly like in the West? reply neilv 12 hours agorootparentI get the impression that Western companies (and Chinese companies with non-disposable brands marketed in the West) can have GPL enforced against them.For example: https:&#x2F;&#x2F;sfconservancy.org&#x2F;activities&#x2F;I know one of the other dynamics is when the GPL copyright holder is more of a crunchy-granola hippie guru, who might just want to lovingly bring the lost soul into the fold, because they know not what they do.That&#x27;s really not a deterrent to the people who know exactly what they&#x27;re doing.Personally, I&#x27;d like to see copyright holders be less flower-child toward abusers, and more like a Scout who was helping an elderly person across the street, when they were attacked by a group of violent racists. It&#x27;s not time to turn the other cheek, but to grab a heavy stick. reply cscurmudgeon 12 hours agorootparentprevFalse equivalencehttps:&#x2F;&#x2F;opensource.stackexchange.com&#x2F;questions&#x2F;11452&#x2F;have-th...How many of those are in mainland China?mEven the neighboring country of Taiwan is careful about GPLhttps:&#x2F;&#x2F;www.leetsai.com&#x2F;ltp-special-column&#x2F;legal-issues-that... reply userbinator 5 hours agorootparentIncidentally, don&#x27;t call Taiwan a \"neighboring country\" when in mainland China. replyjonatron 14 hours agoprevThere&#x27;s not a lot of info about the Shenzhen SEZ Visa on arrival, but I can say that if you use the Luohu&#x2F;Lo Wu port, aim to get there as they open because they don&#x27;t get through many before they stop for lunch. reply woutr_be 3 hours agoparentI’ve gotten that visa countless times at the Lok Ma Chau border crossing, never had to wait more than 15-30 minutes really.There’s now also 15-day visa free travel if you’re one of 6 countries: https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;world-asia-china-67516777 reply juujian 13 hours agoparentprevI got over half a dozen of those. Never remember there being much traffic anyways at the office where they issue those. Time period is ~2016--2019. reply autocanopener 12 hours agoparentprevnext [10 more] [flagged] Grimburger 11 hours agorootparentThat article is paywalled, looking at the numbers I got this:> the first half of 2023 witnessed a total of 168 million inbound and outbound individuals passing through China’s immigrationhttps:&#x2F;&#x2F;www.china-briefing.com&#x2F;news&#x2F;chinas-tourism-in-2023-o...Seems fairly decent. reply mbajkowski 9 hours agorootparentDon&#x27;t have any numbers myself, but per persons who recently attended KubeCon China earlier this year they have not seen Shanghai this empty of tourists in years. Also, supported by a friend of mine who was head of accounting for a cosumer goods firm over there until recently. reply nojs 7 hours agorootparentYeah, I was in Shanghai recently and it felt like there were an order of magnitude less tourists than a few years ago. reply autocanopener 11 hours agorootparentprevThat number is counted whenever citizens travel to&#x2F;from Hong Kong and Macau. There are people making day trips to&#x2F;from Hong Kong every day. reply seanmcdirmid 10 hours agorootparentI still don’t understand why HK is still considered a foreign destination in China. reply nerdbert 7 hours agorootparentPeople from many countries can enter Hong Kong without a visa. It draws tourists and helps with many export businesses.For this reason people in Hong Kong have not passed the stricter scrutiny applied to people who visit the mainland, so they have to be re-checked at the border. reply zhivota 8 hours agorootparentprevWhy would an authoritarian government give up a preassembled internal border checkpoint? Makes sense for them to keep it. reply seanmcdirmid 7 hours agorootparentMaybe they do it so they can count all tourism between the SAR as international tourism. Results in lots of gained face. reply zztop44 7 hours agorootparentprevIt (still) has different laws, different visa rules and a different passport. replyofrzeta 14 hours agoprevI have a hard time imagining how you can get into business with people in Huaqiangbei without speaking Mandarin even with that guide in hand but without an interpreter. But maybe it can work out with pointing and writing down arabic numbers? reply terminous 13 hours agoparentReal time voice translation is getting really good. Standard text translation is pretty much perfect for technical details, but just may miss idioms. You just have your smartphones out, type your message, and show the translation to the other person. They read it and start typing on their phone, then show it to you. I got through China pretty painlessly this way, and it is so normal for many, especially the young. I went to one restaurant where they got the younger waiter when they saw me walk in, who I thought would speak English. She just knew the phone text translation ritual, but was an expert in that.But for millennia, people have gone to far away lands where they don&#x27;t speak the language, and somehow managed to build trade routes without even having a dictionary or calculator. It is not that hard to work out a pidgin. Tons of things you can do with pointing and gesturing. Marco Polo would have killed to even have Google Translate circa 2010.I&#x27;ll also assert with no evidence that it is generally harder for an English speaking engineer to successfully communicate a technical idea into business speak for English speaking VC investors than it is for an English speaking engineer to communicate a request to buy a specific part to a Mandarin speaking engineer. reply DeathArrow 3 hours agorootparentMy baby son doesn&#x27;t talk yet, aside of 5 words, but he still manages to transmit me what he wants by using his hands, muttering and mumbling on different tones. If I still don&#x27;t get it, he grabs me by the hand and go show me what he wants by pointing his finger.I somewhat did the same when traveling to foreign countries and meeting people that don&#x27;t speak any of the languages I speak. reply ClumsyPilot 6 hours agorootparentprev> I&#x27;ll also assert with no evidence that it is generally harder for an English speaking engineer to successfully communicate a technical idea into business speak for English speaking VC investors than it is for an English speaking engineer to communicate a request to buy a specific part to a Mandarin speaking engineersounds like a fun challange, probably true reply Saigonautica 5 hours agorootparentI&#x27;ve never done this in China, but I&#x27;ve done it in Vietnam (before I learned more of the language) and in Japan.It is surprising how much you can communicate by drawing circuit diagrams, sketches of oscilloscope traces, and equations! It works quite well!However one problem I encountered was that many (maybe most) vendors were not engineers and had no understanding of the parts sold. They just knew the name of the parts they had in stock, and how much they could sell them for, and that&#x27;s it. Often they weren&#x27;t even being paid -- it&#x27;s a family business and they were just the niece or nephew that got roped in to vaguely watching the store while playing games on their phone.This was much more of an issue in Vietnam (Nhat Tao market) than in Tokyo (Tokyo Radio tower). In the latter there appeared to be quite a few retired engineers who were quite enthusiastic to meet someone who was looking for something specific. It was pretty neat, and I occasionally encountered someone with a wealth of knowledge! reply smackeyacky 11 hours agoparentprevIt&#x27;s not quite as bad as that. I speak no Mandarin but managed to purchase parts in the markets just by gesticulating and having part numbers (where appropriate).A surprising number of the vendors had at least a little english - enough for commerce anyway. reply jonatron 13 hours agoparentprevThey usually have a calculator to show you prices. Translation apps that aren&#x27;t Google work to some extent. Some speak enough English to haggle, so numbers mostly, and it&#x27;s not hard to learn Chinese numbers. reply DeathArrow 3 hours agoparentprev>I have a hard time imagining how you can get into business with people in Huaqiangbei without speaking MandarinBy speaking the same language as they do, which is Cantonese? reply lvturner 59 minutes agorootparentIt’s MOSTLY Mandarin you will hear spoken in Shenzhen, while it is true that Guangdong province is generally Cantonese speaking - Shenzhen is a city mostly made up of migrants from all over China so Mandarin is the lingua franca.Somewhat related, as a result of this, Shenzhen is a great place to try out many different regional Chinese foods. reply ofrzeta 2 hours agorootparentprevYou know, I got that idea from the Crowdsupply page that says \"... sourcing tool for non-Mandarin speakers\". reply zeroCalories 13 hours agoprevI don&#x27;t plan on ever doing business in China, much less purchasing electronics, but the book looks very interesting from the index. Might buy a copy. reply toomuchtodo 13 hours agoparentI bought the first one to send a copy to the Internet Archive for long term physical archival. Going to do the same with this release. reply autocanopener 12 hours agoparentprevnext [14 more] [flagged] eunos 12 hours agorootparentFDI began to shift from made in China for global export to made in China for the Chinese market and nowadays local Chinese companies outcompete these companies. Witness how global automotive companies (especially Japanese) got trounced hard because they don&#x27;t have EV offerings reply autocanopener 12 hours agorootparentNo, foreign FDI shifted from China to south east asia factories. There&#x27;s a reason xi Jing ping was begging to share on a &#x27;common dream&#x27; when he visited Vietnam this month.Sure, foreign companies are losing in Chinese auto markets. That&#x27;s to be expected with Chinese government support of local EV companies, as well as nationalistic fervor. The Chinese auto market is a small one compared to US however. And it&#x27;s shrinking with China&#x27;s economic collapse. reply eunos 11 hours agorootparent> The Chinese auto market is a small one compared to US howeverUh no... https:&#x2F;&#x2F;www.factorywarrantylist.com&#x2F;car-sales-by-country.htm... https:&#x2F;&#x2F;www.theglobaleconomy.com&#x2F;rankings&#x2F;passenger_cars_sal... reply autocanopener 11 hours agorootparentfake market propped up by government subsidy. should crash 30-50%, much like the real estate prices these days in China.A subsidy-fueled boom helped build China into an electric-car giant but left weed-infested lots across the nation brimming with unwanted battery-powered vehicles.https:&#x2F;&#x2F;www.bloomberg.com&#x2F;features&#x2F;2023-china-ev-graveyards&#x2F; reply redandblack 11 hours agorootparentprevYou are talking about the same - you are focusing on large multi-national who have political pressures from their home country regimes. This is about local talent which has grown over 30&#x2F;40+ years and are impervious to all this nonsense. Just think them about them like Silicon Valley - insiders know how to take a tech idea to a product, including financing. Not sure about financing, but a insider in Shenzhen, especially on you side, can get your product done&#x2F; reply Beijinger 10 hours agorootparentprevChinese car market is double the size of the USA: https:&#x2F;&#x2F;www.linkedin.com&#x2F;pulse&#x2F;exploring-worlds-top-10-large...\"And it&#x27;s shrinking with China&#x27;s economic collapse.\"I don&#x27;t know about that. Same with Russia. GDP growth over 3%, extremely low unemployment, life expectancy rising (besides the war!). And oligarch can&#x27;t invest their money anymore offshore, now they have to invest in Russia. Putin is a dog but don&#x27;t underestimate him. Currently the war seems to hurt the West more than Russia. reply kilolima 11 hours agorootparentprev\"Russia&#x27;s war against Europe\"... Are you saying that Russia isn&#x27;t European? Because I thought solving problems with violence was a traditional European past time. reply Tao3300 9 hours agorootparentAlmost cute. That&#x27;s been the past time since before all our ancestors left trees. reply nojvek 12 hours agorootparentprevOh bummer. US is the biggest importer of China. Most crap we buy for Christmas and New Years - come from China.90% of crap Amazon sells - China. Go to any store, most things are made in … China. reply autocanopener 12 hours agorootparentLet me supply you with some hard knowledge.China Now Sells Fewer Goods to the US Than Mexico or Canada Dohttps:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2023-08-08&#x2F;china-los...For the first three quarters of the year, China&#x27;s exports to the U.S. fell by 16.4%https:&#x2F;&#x2F;www.cnbc.com&#x2F;2023&#x2F;10&#x2F;13&#x2F;china-trade-exports-and-impo...Exports to the EU fell 11% from a year earlier to $38.3 billion in November comparedhttps:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;china-exports-imports-decline-eco... reply echelon 11 hours agorootparentMexico is on an absolute tear.With rail, highway, and shipping directly into Texas, it&#x27;s turning into a manufacturing powerhouse.Texas is a huge beneficiary of this too and will get to build a lot of finished goods manufacturing.https:&#x2F;&#x2F;www.bloomberg.com&#x2F;graphics&#x2F;2023-mexico-china-us-trad...https:&#x2F;&#x2F;www.dallasfed.org&#x2F;research&#x2F;economics&#x2F;2023&#x2F;0711 reply hollerith 11 hours agorootparentAlso cheap natural gas from Texas. reply syndicatedjelly 10 hours agorootparentprevHow does it feel to be righteous and good all the time? reply narag 13 hours agoprevI love the cover. Nice mix. reply Animats 14 hours agoprevIt&#x27;s good to know that Naomi Wu is still allowed to communicate with the outside world, a little. reply user_7832 14 hours agoparentOut of the loop, what happened with her? reply toomuchtodo 14 hours agorootparentHeavy hand of the CCP.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37154414https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37154745 reply user_7832 14 hours agorootparentThanks! reply toomuchtodo 11 hours agorootparentHappy to help! reply lvl102 12 hours agoparentprevnext [3 more] [flagged] chillingeffect 12 hours agorootparentI&#x27;m hoping you either forgot a &#x2F;s or have some hitherto unrevealed and amazing evidence for your claim.What is the basis of your claim?How hard is it to believe an attractive woman can be good and creative in DIY electronics?Most men don&#x27;t even understand the basics of dressing well or being attractive when all the info is right at our fingertips. And it doesn&#x27;t take enough time that we can&#x27;t also practice engineering.Sigh... I&#x27;m not even one of those far lefties and that remark is...vestigial. reply ClumsyPilot 6 hours agorootparentprevit&#x27;s okay, sometimes i also wish i was an attractive woman working in tech.On other days I think again, and I don&#x27;t. Most days i am not sure reply lifeisstillgood 13 hours agoprev>>> Since ... 2016, the population of Shenzhen has grown by over 2 million people, the metro system has added over one hundred kilometers of track, and dozens of new stations have been opened. The city’s taxi and bus fleets were converted from gas to electric. The entirety of Huaqiangbei Road - the center of the electronic market district - has been torn up and replaced with a pedestrian boulevard.Holy crap. As a Brit we have recently spent 100 billion and twice that time to fail to build a railway between two cities, London still runs almost all petrol bus and taxis and ...As we have (hopefully) an election coming soon and might see some change I would be interested in why the UK - who about 150 years ago woukd have growth stats very similar to that - has got well, meh.The usual suspects for such terrible performance are- much lower starting point. It&#x27;s easier to setup mobile phone masts than replace the POTS.- too much regulation (from safety to public consultations that allow NIMBYism to slow things down)- we are not growing - if the number of people buying mobile phones in year X is twice the number of people who already have a phone, then you can see a different market than if everyone keeps their phone for one extra year. Does something else play out for cities, streets and factories?- just money coming in. The UK is having serious lack of growth and presumably shenzen is not.Or is it, that \"ooomph\" ? a level of belief that tomorrow will be better? reply hnthrowaway0315 12 hours agoparentThere are a lot of contributing factors:1. Shenzhen is sort of a tech center of Southern China so it requires good and new infras2. Local governments are economically and politically encouraged to build infra (Google 土地经济) in general3. Infra is built faster and cheaper in China so Shenzhen is not an outlier. Usually it starts with some planning to build a line in a remote area (to save buyout costs) -> line gets built -> other infrastructures including super markets, post offices, whatever get built -> apartment buildings get built -> government gets paid back by taxes collected from real estate companies, super markets and other expanded economy entities4. Some cities actually lost the bets on building new infras and this created a whole range of issues (Google 地方债 and 地方融资平台公司债) reply nirui 3 hours agorootparentA well-know thing is, rebuilding things was a fairly common (and for some, important) method for the local gov to raise funds.One instance in our city almost 10 years back, they built a perfectly acceptable 4-lane city road, and then completely rebuilt it again just few years later.Of course that method is no longer be used as wild as it did under chairman Xi and his uh... successful economic policy which greatly reduced the need of roads. But things are bit different back in 2016. reply tim333 9 hours agoparentprevLondon&#x27;s black cabs are now 50% electric and rising https:&#x2F;&#x2F;electrek.co&#x2F;2023&#x2F;12&#x2F;07&#x2F;half-of-londons-iconic-black-... reply jacquesm 56 minutes agorootparenthttps:&#x2F;&#x2F;www.wired.co.uk&#x2F;article&#x2F;levc-geely-london-electric-b... reply nox100 9 hours agoparentprevSF spent $1.6 billion and 10 years to make 2.7k line that no one rideshttps:&#x2F;&#x2F;sfist.com&#x2F;2023&#x2F;03&#x2F;16&#x2F;central-subway-ridership-alread...I love public transportation when it&#x27;s good (Tokyo, Singapore, HK, Seoul, Paris, London, Berlin, Amsterdam, ...) but I have zero expectations for public transportation to get to \"good\" levels in any city in the USA except the 3 where it&#x27;s already just so-so (NYC, Chicago, DC)As long as it&#x27;s seen as \"the thing poor people who can&#x27;t afford a car use\" it will always be funded and run as such. ... and feel like it. I never feel safe on SF nor NYCs public transit. reply vmurthy 7 hours agorootparentAs a Sydneysider, I feel offended that you left us out ;-). Or included in the “…” reply wannacboatmovie 12 hours agoparentprevThe West has safety regulations that are followed.If a building collapses or a train crashes in China, they just brick over it and build a new one. reply toyg 51 minutes agorootparentYes. Also, rules and regulations on expropriation of land, relocation of people etc, with plenty of long appeal processes.China? \"Go away or else\". reply djmips 9 hours agorootparentprevMove fast and break things. reply autocanopener 12 hours agoparentprevAs always, engineers on hacker news have like 2-3 year delay of news out of China. The rest of the world has already moved onto other countries.1.) \"just money coming in\"Outflows of foreign direct investment in China have exceeded inflows for the first time as tensions with the U.S. over semiconductor technology and concerns about increased anti-spying activity heighten risks. FDI came to minus $11.8 billionhttps:&#x2F;&#x2F;asia.nikkei.com&#x2F;Economy&#x2F;Foreign-investment-in-China-...Moody’s Cuts China Credit Outlook to Negative on Growing Debt Riskshttps:&#x2F;&#x2F;www.wsj.com&#x2F;finance&#x2F;moodys-cuts-chinas-credit-outloo...2.) \"the metro system has added over one hundred kilometers of track\"China’s Cities Are Buried in Debt, but They Keep Shoveling It OnChina has long pursued growth by public spending, even after the payoff has faded. Cities stuck with the bill are still spending — and cutting essential services.https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;03&#x2F;28&#x2F;business&#x2F;china-local-fina...China orders local governments to cut exposure to public-private projects as debt risks risehttps:&#x2F;&#x2F;www.reuters.com&#x2F;markets&#x2F;asia&#x2F;china-orders-local-gove...3.) \"we are not growing\"Shenzhen reports decrease in populationThe southern boomtown of Shenzhen reported a slight population decrease for 2022 — a first since the city&#x27;s founding in 1979.https:&#x2F;&#x2F;www.chinadaily.com.cn&#x2F;a&#x2F;202305&#x2F;10&#x2F;WS645b514ba310b605... reply ClumsyPilot 6 hours agorootparent> China’s Cities Are Buried in Debt, but They Keep Shoveling It OnFinance is fictional, trains are real. In the anglospheric West, when a spreadsheet and real world disagrees, Beancounters will believe their spreadsheet. reply fatih-erikli 11 hours agoprev [20 more] [flagged] justin66 10 hours agoparentI&#x27;m certain anyone considering a trip to Shenzhen knows more about their local electronics supply than you do. reply tomcam 11 hours agoparentprev [–] Why do you care whether other people travel? And what other parts of their lives do you plan to advise them on? reply fatih-erikli 11 hours agorootparent [–] I don&#x27;t mind. People can go wherever they want. These are opinions. My opinion is traveling is overrated. Not only me though, world health organization thinks the same. reply autocanopener 11 hours agorootparent [17 more] [flagged] Beijinger 11 hours agorootparent [–] \"Pay $5000 for a normal airline seat\"Dude, Corona is over. Tickets have never been cheaper.China is an amazing place. reply Beijinger 10 hours agorootparentReplying here. Comment seems to have been deleted:\"What China offers beside electronic components? \"It is a magical place with a rich and old culture. When I lived there, I don&#x27;t think anywhere people partied harder than there. Bars that were empty and filling up at 2pm and people dancing on the table. And I don&#x27;t mean a Saturday night, I mean a Monday. Or Clubs that fill up at 8 or 9 AM. You could smell business opportunity in the air. Doors were open It was a place where things happened. It was a weird place. A crazy place. When there was no place left for me in this world. China welcomed me with open arms. Gave me food and shelter and access to health care.\"Is there unique a place that can&#x27;t be found in a other city in your home country?\"There are many.\"Please don&#x27;t tell me food is good in China. Food is good in any country.\"Doubt it. There are only a few major cuisines in the world with China being one of them. Sure, you can get great food in NYC. You can eat in a Michelin Star restaurant. But this does not give America a great cuisine.And Chinese women are outstanding. reply fatih-erikli 10 hours agorootparentIt&#x27;s me asked these questions then deleted later assuming that there won&#x27;t be a satisfying answer. My assumption was correct, there is nothing China offers to their visitors by reading your answer. reply Beijinger 10 hours agorootparentWell, what would you expect? Any magic medicine? Any clothing brand you can buy only there? There are cars you can only buy in China.There are a ton of tourist attractions that can&#x27;t be found anywhere except in China. I mean, what can you find in Italy that you could not get in the States? Pizza? Armani? Ice Cream? Fiat cars? You can get all this shit in the states. Strangely, shitloads of American heading to Italy every year. reply fatih-erikli 10 hours agorootparentI don&#x27;t know, that&#x27;s what I am asking. For instance, In Norway, you see Fjords, Nordic houses, dark colored sea. In Germany, you see technical museums, abandoned railways, airports. I am expecting that kind of things that make me not regret spending money. reply Beijinger 9 hours agorootparentYou must be trolling. China is one of the oldest cultures. At least how they define it (continuous culture).Visit the Huangshan mountains: https:&#x2F;&#x2F;www.google.com&#x2F;search?sca_esv=591566523&q=huangshan+...Or Guilin Mountains: https:&#x2F;&#x2F;www.google.com&#x2F;search?q=china+guilin+mountains&tbm=i...Or the desert. The forbidden city. Summer palace. Clay soldiers in Xiamen....But yes, you can see airports in Germany. Even airports they took 10 years to build (Berlin). reply fatih-erikli 9 hours agorootparentThey look pretty much the same with what I see when I visit the nearest highest peak in the place I live. Not convinced, not trolling, I am trying to ask fair questions. reply Beijinger 9 hours agorootparentWhere do you live? reply fatih-erikli 9 hours agorootparentSomewhere around Black sea. replydefrost 10 hours agorootparentprevThe Colosseum, the Vatican, Pompeii, toilets older than the USofA, actual style, ... reply Beijinger 10 hours agorootparentOr Venice. A shady little town that was was a financial empire. Nothing compared to NYC. Forget about it. And it is sinking! reply defrost 9 hours agorootparentNYC is pretty jelly of Venice .. they&#x27;re already flooding their subways in anticipation of replacing transport with gondolas by 2100. replyseanmcdirmid 10 hours agorootparentprevThe number of flights between China and the rest of the world is still around half as it was pre Covid. The high prices are simply a function of too much demand (people wanting to travel to China) and not enough supply (seats on airplanes available). Closing off Russian airspace has also hurt, making flights use more fuel and many direct flights less feasible. reply Beijinger 10 hours agorootparentFrom Europe I can fly to China for around 420 Euros. Not bad.Yes, Russia hurts. Especially my lost Aeroflot Gold status.... reply seanmcdirmid 7 hours agorootparentTell me about it. My favorite airline from Beijing to anywhere in Europe was Aeroflot, the Burger King at the airport in Moscow served beer. Glad you can find flights so cheap, all I can find from Seattle ATM is $2k&#x2F;person, most with one day layovers. We used to have so many direct flights a day, it’s around 30+ hours now unless you want to pay even more for something that is only 20 hours.Far Eastern territory airspace being closed really hurts the west coast. reply autocanopener 11 hours agorootparentprev [2 more] [flagged] dang 6 hours agorootparent [–] We&#x27;ve banned this account because single-purpose accounts aren&#x27;t allowed here, and neither is using HN primarily for nationalistic, political, or ideological battle.Please don&#x27;t create accounts to break HN&#x27;s rules with.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Naomi Wu is launching a crowdfunding campaign for a revised edition of her book \"The Essential Guide to Electronics in Shenzhen,\" called \"The New Essential Guide to Electronics in Shenzhen.\"",
      "The updated version will feature additional content on digital etiquette in China, updated maps, and insights into cultural and business changes.",
      "Interested readers can reserve a copy of the book through the crowdfunding campaign."
    ],
    "commentSummary": [
      "\"The New Essential Guide to Electronics in Shenzhen\" provides insights into navigating the electronics markets in Shenzhen, China, including the abundance of electronic parts and the recycling ecosystem.",
      "The book highlights the challenges faced by Western open-source projects in Shenzhen, such as legal concerns and language barriers.",
      "It discusses the enforcement of GPL licenses and the experiences of individuals with the Shenzhen SEZ Visa.",
      "The conversation explores obstacles in doing business in China, like the language barrier and the decline of foreign companies in the Chinese auto market.",
      "It briefly mentions limitations faced by DIY electronics creators and the growth and development of Shenzhen's infrastructure.",
      "The discussion also includes topics like public transportation, safety regulations, traveling to China, and tourist attractions in different countries.",
      "Lastly, it mentions an account being banned on a website for violating guidelines related to nationalistic, political, or ideological battles."
    ],
    "points": 333,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1702747504
  },
  {
    "id": 38664729,
    "title": "Introducing SSH3: A Faster and More Secure Shell Experience with HTTP/3 and QUIC",
    "originLink": "https://github.com/francoismichel/ssh3",
    "originBody": "SSH3: faster and rich secure shell using HTTP/3 SSH3 is a complete revisit of the SSH protocol, mapping its semantics on top of the HTTP mechanisms. In a nutshell, SSH3 uses QUIC+TLS1.3 for secure channel establishment and the HTTP Authorization mechanisms for user authentication. Among others, SSH3 allows the following improvements: Significantly faster session establishment New HTTP authentication methods such as OAuth 2.0 and OpenID Connect in addition to classical SSH authentication Robustness to port scanning attacks: your SSH3 server can be made invisible to other Internet users UDP port forwarding in addition to classical TCP port forwarding All the features allowed by the modern QUIC protocol: including connection migration (soon) and multipath connections Tip Quickly want to get started ? Checkout how to install SSH3. You will learn to setup an SSH3 server and use the SSH3 client. SSH3 stands for the concatenation of SSH and H3. ⚡ SSH3 is faster Faster for session establishment, not throughput ! SSH3 offers a significantly faster session establishment than SSHv2. Establishing a new session with SSHv2 can take 5 to 7 network round-trip times, which can easily be noticed by the user. SSH3 only needs 3 round-trip times. The keystroke latency in a running session is unchanged. SSH3 (top) VS SSHv2 (bottom) session establishement with a 100ms ping towards the server. 🔒 SSH3 is secure While SSHv2 defines its own protocols for user authentication and secure channel establishment, SSH3 relies on the robust and time-tested mechanisms of TLS 1.3, QUIC and HTTP. These protocols are already extensively used to secure security-critical applications on the Internet such as e-commerce and Internet banking. SSH3 already implements the common password-based and public-key (RSA and EdDSA/ed25519) authentication methods. It also supports new authentication methods such as OAuth 2.0 and allows logging in to your servers using your Google/Microsoft/Github accounts. 🥷 Your SSH3 public server can be hidden Using SSH3, you can avoid the usual stress of scanning and dictionnary attacks against your SSH server. Similarly to your secret Google Drive documents, your SSH3 server can be hidden behind a secret link and only answer to authentication attempts that made an HTTP request to this specific link, like the following: ssh3-server -bind 192.0.2.0:443 -url-pathBy replacingby, let's say, the random value M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU, your SSH3 server will only answer to SSH3 connection attempts made to the URL https://192.0.2.0:443/M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU and it will respond a 404 Not Found to other requests. Attackers and crawlers on the Internet can therefore not detect the presence of your SSH3 server. They will only see a simple web server answering 404 status codes to every request. 💐 SSH3 is already feature-rich SSH3 provides new feature that could not be provided by the SSHv2 protocol. Brand new features UDP port forwarding: you can now access your QUIC, DNS, RTP or any UDP-based server that are only reachable from your SSH3 host. UDP packets are forwarded using QUIC datagrams. X.509 certificates: you can now use your classical HTTPS cerificates to authenticate your SSH3 server. This mechanism is more secure than the classical SSHv2 host key mechanism. Certificates can be obtained easily using LetsEncrypt for instance. Hiding your server behind a secret link. Keyless secure user authentication using OpenID Connect. You can connect to your SSH3 server using the SSO of your company or your Google/Github account, and you don't need to copy the public keys of your users anymore. Famous OpenSSH features implemented This SSH3 implementation already provides many of the popular features of OpenSSH, so if you are used to OpenSSH, the process of adopting SSH3 will be smooth. Here is a list of some OpenSSH features that SSH3 also implements: Parses ~/.ssh/authorized_keys on the server Parses ~/.ssh/config on the client and handles the Hostname, User, Port and IdentityFile config options (the other options are currently ignored) Certificate-based server authentication known_hosts mechanism when X.509 certificates are not used. Automatically using the ssh-agent for public key authentication SSH agent forwarding to use your local keys on your remote server Direct TCP port forwarding (reverse port forwarding will be implemented in the future) Installing SSH3 You can either download the last release binaries or generate these binaries yourself by compiling the code from source. Tip SSH3 is still experimental and is the fruit of a research work. If you are afraid of deploying publicly a new SSH3 server, you can use the secret path feature of SSH3 to hide it behing a secret URL. Compiling SSH3 from source You need a recent Golang version to do this. Downloading the source code and compiling the binaries can be done with the following steps: git clone https://github.com/francoismichel/ssh3 # clone the repo cd ssh3 go build -o ssh3 cli/client/main.go # build the client go build -o ssh3-server cli/server/main.go # build the server If you have root/sudo priviledges and you want to make ssh3 accessible to all you users, you can then directly copy the binaries to /usr/bin: cp ssh3 /usr/bin/ && cp ssh3-server /usr/bin Otherwise, you can simply add the executables to your PATH environment variable by adding the following line at the end of your .bashrc or equivalent: export PATH=$PATH:/path/to/the/ssh3/directory Deploying an SSH3 server Before connecting to your host, you need to deploy an SSH3 server on it. There is currently no SSH3 daemon, so right now, you will have to run the ssh3-server executable in background using screen or a similar utility. Note As SSH3 runs on top of HTTP/3, a server needs an X.509 certificate and its corresponding private key. If you do not want to generate a certificate signed by a real certificate authority, you can generate a self-signed one using the generate_openssl_selfsigned_certificate.sh script. This provides you with similar security guarantees to SSHv2's host keys mechanism, with the same security issue: you may be vulnerable to machine-in-the-middle attacks during your first connection to your server. Using real certificates signed by public certificate authorities such as Let's Encrypt avoids this issue. Here is the usage of the ssh3-server executable: Usage of ./ssh3-server: -bind string the address:port pair to listen to, e.g. 0.0.0.0:443 (default \"[::]:443\") -cert string the filename of the server certificate (or fullchain) (default \"./cert.pem\") -enable-password-login if set, enable password authentication (disabled by default) -generate-selfsigned-cert if set, generates a self-self-signed cerificate and key that will be stored at the paths indicated by the -cert and -key args (they must not already exist) -key string the filename of the certificate private key (default \"./priv.key\") -url-path string the secret URL path on which the ssh3 server listens (default \"/ssh3-term\") -v verbose mode, if set The following command starts a public SSH3 server on port 443 and answers to new sessions requests querying the /ssh3 URL path: ssh3-server -cert /path/to/cert/or/fullchain -key /path/to/cert/private/key -url-path /ssh3 Note Similarly to OpenSSH, the server must be run with root priviledges to log in as other users. Authorized keys and authorized identities By default, the SSH3 server will look for identities in the ~/.ssh/authorized_keys and ~/.ssh3/authorized_identities files for each user. ~/.ssh3/authorized_identities allows new identities such as OpenID Connect (oidc) discussed below. Popular key types such as rsa, ed25519 and keys in the OpenSSH format can be used. Using the SSH3 client Once you have an SSH3 server running, you can connect to it using the SSH3 client similarly to what you did with your classical SSHv2 tool. Here is the usage of the ssh3 executable: Usage of ssh3: -pubkey-for-agent string if set, use an agent key whose public key matches the one in the specified path -privkey string private key file -use-password if set, do classical password authentication -forward-agent if set, forwards ssh agent to be used with sshv2 connections on the remote host -forward-tcp string if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport -forward-udp string if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport -insecure if set, skip server certificate verification -keylog string Write QUIC TLS keys and master secret in the specified keylog file: only for debugging purpose -use-oidc string if set, force the use of OpenID Connect with the specified issuer url as parameter -oidc-config string OpenID Connect json config file containing the \"client_id\" and \"client_secret\" fields needed for most identity providers -do-pkce if set, perform PKCE challenge-response with oidc -v if set, enable verbose mode Private-key authentication You can connect to your SSH3 server at my-server.example.org listening on /my-secret-path using the private key located in ~/.ssh/id_rsa with the following command: ssh3 -privkey ~/.ssh/id_rsa username@my-server.example.org/my-secret-path Agent-based private key authentication The SSH3 client works with the OpenSSH agent and uses the classical SSH_AUTH_SOCK environment variable to communicate with this agent. Similarly to OpenSSH, SSH3 will list the keys provided by the SSH agent and connect using the first key listen by the agent by default. If you want to specify a specific key to use with the agent, you can either specify the private key directly with the -privkey argument like above, or specify the corresponding public key using the -pubkey-for-agent argument. This allows you to authenticate in situations where only the agent has a direct access to the private key but you only have access to the public key. Password-based authentication While discouraged, you can connect to your server using passwords (if explicitly enabled on the ssh3-server) with the following command: ssh3 -use-password username@my-server.example.org/my-secret-path Config-based session establishment ssh3 parses your OpenSSH config. Currently, it only handles the Hostname; User, Port and IdentityFile options. Let's say you have the following lines in your OpenSSH config located in ~/.ssh/config : Host my-server HostName 192.0.2.0 User username IdentityFile ~/.ssh/id_rsa Similarly to what OpenSSH does, the following ssh3 command will connect you to the SSH3 server running on 192.0.2.0 on UDP port 443 using public key authentication with the private key located in .ssh/id_rsa : ssh3 my-server/my-secret-path If you do not want a config-based utilization of SSH3, you can read the sections below to see how to use the CLI parameters of ssh3. OpenID Connect authentication (still experimental) This feature allows you to connect using an external identity provider such as the one of your company or any other provider that implements the OpenID Connect standard, such as Google Identity, Github or Microsoft Entra. The authentication flow is illustrated in the GIF below. Secure connection without private key using a Google account. The way it connects to your identity provider is configured in a file named ~/.ssh3/oidc_config.json. Below is an example config.json file for use with a Google account. This configuration file is an array and can contain several identity providers configurations. [ { \"issuer_url\": \"https://accounts.google.com\", \"client_id\": \"\", \"client_secret\": \"\" } ] This might change in the future, but currently, to make this feature work with your Google account, you will need to setup a new experimental application in your Google Cloud console and add your email as authorized users. This will provide you with a client_id and a client_secret that you can then set in your ~/.ssh3/oidc_config.json. On the server side, you just have to add the following line in your ~/.ssh3/authorized_identities: oidchttps://accounts.google.comWe currently consider removing the need of setting the client_id in the authorized_identities file in the future.",
    "commentLink": "https://news.ycombinator.com/item?id=38664729",
    "commentBody": "SSH3: SSHv2 using HTTP&#x2F;3 and QUICHacker NewspastloginSSH3: SSHv2 using HTTP&#x2F;3 and QUIC (github.com/francoismichel) 316 points by kieto 18 hours ago| hidepastfavorite176 comments adontz 17 hours agoI believe security models for HTTP and SSH are pretty different. HTTP is usually public and anonymous, SSH is usually private and authenticated. While QUIC is definitely a great technology for HTTP use case, I&#x27;m not so sure about SSH. Not saying it&#x27;s not, just it&#x27;s something to reason about.For example x509 seems to be a disadvantage to me. I do not want anyone with a cheap DigiCert certificate be able to log in to my server, even as a result of some fat finger misconfiguration. OAuth assumes that both client and service provider can reach identity provider. Is it so for most serves? I am used to see pretty restricted setups, where many servers have no internet access and only update from a private package repository.From one side, I really like the idea of reusing HTTP. Who does new protocols these days? Everything is JSON or XML over HTTP. And it&#x27;s good enough for most cases. But is it good enough for SSH? WinRM works over HTTP, but it uses Kerberos for authentication.Are there any significant real practical advantages? I don&#x27;t see any. Are there any vulnerabilities, possibilities for misconfiguration, architectural flaws? Quite possible. reply vore 16 hours agoparentI don&#x27;t see anything about using an X.509 certificate for logging in, just for a client authenticating the remote server. And, even then, TLS has support for mutual authentication so someone with a cheap DigiCert certificate logging into your server is not really a problem if you could configure mTLS on the server side to accept only certificates in a certain chain. reply nixgeek 17 hours agoparentprev“cheap DigiCert certificate” is already possible with misconfiguration of SSH’s TrustedUserCAKeys and without any out of tree patches. https:&#x2F;&#x2F;smallstep.com&#x2F;blog&#x2F;use-ssh-certificates&#x2F; reply frutiger 13 hours agorootparentSSH Certs are not related to x509 PKI certs. SSH certs are created with ssh-keygen and is the result of one key signing another. The public portion of the signing key (ie. the “cert”) needs to be distributed separately. reply vetinari 12 hours agorootparentDid you follow the link? The point was exactly setting up X.509 PKI for SSH authentication. Yes, it can be used with SSH, that was the GP&#x27;s point. reply e12e 8 hours agorootparentThe link talks about setting up a ssh ca, not x509?> For our part, the most recent release of step & step-ca (v0.12.0) adds basic SSH certificate support. In other words:> step-ca is now an SSH CA (in addition to being an X.509 CA)> step makes it easy for users and hosts to get certificates from step-caIt&#x27;s a tool that do x509 ca for x509 things and ssh ca for ssh. reply frutiger 12 hours agorootparentprevI’m replying to parent not the overall post. reply whatisyour 12 hours agorootparentprevyou can disable X.509 for SSH reply sargun 13 hours agoparentprevYou can already use certificates to login via SSH. Usually you setup your own certificate authority and sign your own certs because they need special attributes. reply adontz 13 hours agorootparentSSH certificates (I encourage using them!) are not x509, absolutely incompatible. reply ReK_ 3 hours agorootparentYou&#x27;re thinking of SSH keys, which are not certificates. SSH certificates are indeed x.509: https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc6187 reply dilyevsky 12 hours agorootparentprevIt’s same general principle and same security model just different way of going about it. It supports CAs and extensions just like x509 reply HeckFeck 16 hours agoparentprev> Who does new protocols these days?My business brain understands why, but my engineer’s heart laments. reply iknowstuff 14 hours agorootparentQUIC is damn good though! Its minimal header has a very tiny overhead, and the protocol gives us so much for free. What’s to lament? The userspace impl? reply magicalhippo 16 hours agoparentprev> OAuth assumes that both client and service provider can reach identity provider.You could use client credentials flow with a certificate. Then all you need is to register the public key with the server, much like good old SSH. reply lakomen 8 hours agoparentprevYeah those filthy cheap DigiCert certs plebs pshh gasp. Only expensive Verisign golden batch certs get to log into my computers snobbynoseSCNR, I know it&#x27;s HN which is short for \"Humor? No we don&#x27;t understand humor\". reply ironhaven 15 hours agoprevWhy is there http&#x2F;3 in the middle? SSH over QUIC makes a lot of sense and was something I thought about before.The SSH protocol is designed to multiplex many “channels” over an encrypted tcp socket. Over each channel you can run things like a shell or SFTP.It would need some engineering but you could keep the same SSH features but replace the multiplexing channels over tcp with QUIC channels over udp. Where does HTTP&#x2F;3 fit in besides to add overhead? reply wmf 12 hours agoparentYou can use HTTP for authentication. reply ironhaven 5 hours agorootparentUnless you can use an off the shelf http client to make ssh connections I can’t think of a benefit for using http headers vs non-http key value pairs. reply gonzo 3 hours agorootparentLooks like http(s). reply egberts1 14 hours agoparentprevDo you want to maintain a state machine for each QUIC-SSH session 1-N pairing? Or worse, M-N pairing? reply anticensor 52 minutes agorootparentWhy not have 1:1 relationship between QUIC connection IDs and open SSH sessions? reply CoolGuySteve 13 hours agorootparentprevYes. The attack surface would be much smaller. reply Ayesh 16 hours agoprevSSH over QUIC would be nice.I don&#x27;t see any advantage of layering HTTP&#x2F;3 here. It adds more friction, and the only advantage it brings is being able to \"hide\" the SSH server over a URL path. I guess x.509 certificates would be fine, but SSH hostkeys, SSHFP or TOFU is enough and far more secure (because it implicitly pins the server public key).It&#x27;s a relatively new project from the looks of it, so I&#x27;d definitely not use it anywhere half important having to create something interesting with QUIC and HTTP&#x2F;3. reply acdha 16 hours agoparentThey list other advantages in the README such as tying into the web authentication model, which is pretty big for enterprise use as everything moves towards OIDC. If they could eventually use passkeys that’d be really nice. reply kdklol 16 hours agorootparentSSH supports passkeys: https:&#x2F;&#x2F;developers.yubico.com&#x2F;SSH&#x2F;#_fido2 reply acdha 11 hours agorootparentWith hardware tokens, yes, I use that. I was thinking that building it on a web server would be really handy with an integrated client you could use with iCloud, Windows Hello, etc. reply ikiris 11 hours agorootparentThis already exists too reply e12e 8 hours agorootparentprevFor oidic there&#x27;s at least:https:&#x2F;&#x2F;github.com&#x2F;salesforce&#x2F;pam_oidchttps:&#x2F;&#x2F;github.com&#x2F;EOSC-synergy&#x2F;ssh-oidc reply ycombinatrix 11 hours agorootparentprevI already already use passkeys for ssh. libfido. reply ikiris 11 hours agorootparentprevYou can already do all of this with ssh reply InvaderFizz 15 hours agoparentprevIt sure would be nice to be able to easily throw up a CDN like Cloudflare in front of my ssh server with no client side special sauce required.I didn&#x27;t see it stated in the documentation, it this feels like something that might work for that setup. reply ryandvm 14 hours agorootparentWhy are people obsessed with implanting CloudFlare right in the middle of everything they do? There is absolutely nobody that needs DDoS for their SSH server.I get that CloudFlare has been a well behaved netizen so far, but let&#x27;s be real, it won&#x27;t last forever. It never does. Eventually the shareholders start turning the screws and CloudFlare is going to succumb to the same pressures every company does and they&#x27;re going to start extracting advertising value from their \"customers\".How about we save the CDNs for the serious stuff and just run our SSH servers and low traffic HTTP sites ourselves? reply adastra22 14 hours agorootparentWhy would you intentionally MITM your SSH connection? reply InvaderFizz 13 hours agorootparentprevAbsolutely nothing to do with DDoS in my case. I want censorship regimes to have to break large portions of the internet for their citizens to stop even the most simple leak vector. Let them block Cloudflare, Akamai, and Cloudfront. reply ranting-moth 9 hours agorootparentprevI&#x27;m pretty sure even if CF went rouge you&#x27;d be able to keep your SSH connections ad free for a low $1.99&#x2F;month subscription. reply JCharante 14 hours agorootparentprevEvery personal blog is low traffic until it lands at the top of HN reply chrisandchris 14 hours agorootparentWhich still means that the HTTP-server can be behind CloudFlare, but nobody accesses your blog through SSH (hence not necessary to put it behind CloudFlare). reply bitwize 14 hours agoparentprevIn the 90s it was commonplace to design a new protocol on top of TCP&#x2F;IP. These days, all the tooling and infrastructure is for HTTP. Designing a new protocol, you&#x27;d be starting from scratch; HTTP is much, much easier to build an application on top of. reply unilynx 13 hours agorootparentI doubt QUIC is easier than TCP to build on. But it&#x27;s much easier to get your new protocol through firewalls and other middleware when using port 443 than trying to introduce a new port (or worse: a new protocol number) reply tengwar2 9 hours agorootparentWhich sounds like more of a disadvantage if you are running a firewall. reply anticensor 42 minutes agorootparentIf your firewall drops unknown protocols, then it is broken. Internet is designed to be default-open, not default-closed. reply mkesper 16 hours agoparentprevSsh hostkeys offer no solution for first connect to ephemeral hosts. reply Ayesh 16 hours agorootparentStrict SSHFP can theoretically solve it [1], assuming it&#x27;s used in the first place and has DNSSEC. I personally use it for all servers I manage purely because I like the additional security, but it not at all common and DNSSEC isn&#x27;t all that perfect either.[1] https:&#x2F;&#x2F;aye.sh&#x2F;blog&#x2F;sshfp-verification reply overstay8930 10 hours agorootparentIt&#x27;s crazy that SSHFP hasn&#x27;t taken off, I don&#x27;t think a single person on earth has ever verified a host key before attempting to connect, and deploying DNSSEC is trivial now that you can use ECC and ED25519. reply tptacek 5 hours agorootparent* Deploying DNSSEC is obviously not trivial, as doing so has taken some of the largest companies on the Internet fully off the Internet for multiple hours, within the last year, so much so that it has become a running joke when companies have prolonged outages to suggest that DNSSEC is the culprit.* There are still resolvers that can&#x27;t handle Ed25519* Being able to use Ed25519 was never the ops problem with getting DNSSEC rolled out!* It&#x27;s weird to assume that people would want to enroll their server integrity --- something that doesn&#x27;t in any way depend on an Internet PKI designed to allow strangers to verify your identity, and that enlists de facto government support to make that use case work --- in a global PKI, especially when SSH already has a perfectly good certificate system that solves the same problem without any of the above liabilities.What boggles my mind, and I mean this sincerely, not as snark, is that anybody in the entire world takes SSHFP seriously. Even if you stipulate that DNSSEC (and&#x2F;or DANE) works, just arguendo, it&#x27;s still a totally different use case than resolving SSH key continuity problems. reply jeroenhd 16 hours agorootparentprevIf hosts are configured with SSH certificates as part or their setup, you can definitely skip TOFU and determine trust on the first connection. That won&#x27;t work for the \"I need to connect to a random IP address\" scenario, but any cloud server exposing SSH can be configured with a certificate signed by a company&#x2F;personal SSH certificate authority.You could configure something delightfully atrocious like https:&#x2F;&#x2F;github.com&#x2F;mjg59&#x2F;ssh_pki but I think for most use cases where you connect to loads of SSH servers, host keys and certificate authorities will work just fine. We can do with an ACME-like protocol for distributing these certificates, though. reply mcfedr 15 hours agorootparentGiven how rare this is, using https seems like a great idea reply cortesoft 15 hours agorootparentprevYou can set up your ephemeral hosts to come up with properly signed host keys. reply ikiris 11 hours agorootparentprevSSh hosts have supported certs for at least a decade. reply zaik 17 hours agoprevThis is not related to OpenSSH or the RFCs for SSH3 published by IETF. It is just someone&#x27;s random project. reply nextaccountic 13 hours agoparentI think it was a lot of hubris to call this ssh3, as if it were to be picked officially reply pdntspa 7 hours agorootparentYeah, it is really rude of them reply say_it_as_it_is 15 hours agoparentprev2 phd students reply stjohnswarts 14 hours agoparentprevIt still seems like a nice experiment if nothing else. If only it was done in rust ;) reply say_it_as_it_is 12 hours agorootparentNot if they wanted to complete the work in time reply hackernudes 17 hours agoprevMaybe similar to https:&#x2F;&#x2F;github.com&#x2F;moul&#x2F;quicsshI&#x27;ve done ssh over websocket before (to bypass a corp proxy)... been thinking about it a lot lately. I would love if mosh got support for different transports than just udp and it would be cool if the initial handshake could be done over http instead of ssh. reply epaulson 16 hours agoprevI know this isn&#x27;t an actual v3 of the SSH protocol, but if there ever is a version 3 of SSH, it really needs some kind of (encrypted) SNI or at least a standardized metadata block that can be passed to any jumphost without having the know the specifics of the ProxyCommand on that middlebox. reply idorosen 16 hours agoparent`ProxyJump` already exists, so you don’t need to know where netcat resides on the jumphost anymore.SNI-like metadata might have some adverse security implications, but a fancier ProxyJump with session routing would be nice. reply qudat 9 hours agoparentprevSNI is absolutely needed. Over at https:&#x2F;&#x2F;pico.sh we have to request an IP for each ssh server even though from a resource perspective we really only need 1 VM. It increases the complexity of our deployments and overall makes us want to figure out how to merge all of our SSH apps into one. reply georgyo 17 hours agoprevPeople are being perhaps a little too over dramatic here.Yes, this is not SSHv3 as defined by a standards body. It is very much SSHv2 over HTTP&#x2F;3. (Which sorta sounds like how HTTP&#x2F;3 is actually HTTP&#x2F;2 over QUIC)But there is lots of SSH servers and clients, such as Dropbear SSH, OpenSSH, libssh, libssh2 (which is very different from libssh which also supports sshv2), and more. So I don&#x27;t blame the creators from putting SSH in the name.The code itself looks like mostly glue code to other more well established libraries. I&#x27;m not saying that they didn&#x27;t introduce new flaws, just that they did not roll their own crypto here.Their paper on their work is pretty interesting: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2312.08396.pdfI kinda hope this succeeds. The faster connection time is nice, but really OpenSSH is so change adverse that it&#x27;s painful.IE, I have to have a pretty large patch sets to open SSH, one of them being HPN ssh for getting any kind of reasonable throughput over high latency links. This patch set is decades old and the problems well known, but OpenSSH maintainers do not care. Replacing the transport layer would force things like having reasonable window scaling.Another is loadbalancing and routing SSH connections. You cannot know where a client wants to connect to till after they done a full hand shake. This is pretty painful. If we had something like SNI we could route clients to the correct servers using only a single IP and port.I fully welcome these ideas and am glad a group is working on testing these concepts.Please don&#x27;t dismiss things too hard too soon. reply dang 17 hours agoparentOk, I&#x27;ve put SSHv2 in the title to make that clearer. If there&#x27;s a better way, we can change it again. reply nixgeek 16 hours agorootparentI don’t think this is SSHv2 though the GitHub talks about reimplementation on HTTP semantics, and the paper illustrates SSHv2 vs SSH3 as being extremely different for session setup.In naming; Francois also explains SSH3 is a concatenation of SSH and HTTP&#x2F;3 — we can not like that here on HN (due seemingly to the lack of IETF involvement?) but it’s what the project creators picked. reply dang 12 hours agorootparentSure, but that project name is still in the title - what I change was the description. I don&#x27;t know enough to say if the description needs to be more accurate. Others here surely do? reply gchamonlive 16 hours agorootparentprevWould SSHTTP3 have been more adequate for the project&#x27;s name? reply magicalhippo 16 hours agorootparentSHT3 as in SSH over HTTP3 reply wmf 15 hours agoparentprevI think something like QSH (QUIC shell) might be a better name. reply e12e 8 hours agorootparentQuiche? (Or quissh) reply wmf 8 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;cloudflare&#x2F;quiche is taken reply r1ch 15 hours agoprevI feel like they&#x27;re missing some benchmarks here, show off the benefit that QUIC brings! OpenSSH&#x27;s fixed window size significantly bottlenecks throughput on long fat links. I&#x27;d love to see ssh+rsync running at 2+ gbps. reply pulpfictional 14 hours agoparentThere is also: https:&#x2F;&#x2F;www.psc.edu&#x2F;hpn-ssh-home&#x2F;> HPN-SSH is a series of modifications to OpenSSH, the predominant implementation of the ssh protocol. It was originally developed to address performance issues when using ssh on high speed long distance networks (also known as Long Fat Networks: LFNs). By taking advantage of automatically optimized receive buffers HPN-SSH could improve performance dramatically on these paths. Later advances include; disabling encryption after authentication to transport non-sensitive bulk data, modifying the AES-CTR cipher to use multiple CPU cores, more detailed connection logging, and peak throughput values in the scp progress bar. More information can be found on HPN-SSH page on the PSC website. reply formerly_proven 13 hours agorootparentSSH started out with a maximum window size of 128K, which was bumped to 2M in the mid-2000s. It&#x27;d be entirely reasonable to bump this to the 64M to 128M range; it&#x27;s not a fixed buffer allocated for each channel, and the peers explicitly manage the window size, so there really shouldn&#x27;t be any compatibility issues. This would already solve most of these issues, the more complicated parts of HPN-SSH aren&#x27;t really needed, and things like multithreaded crypto are entirely unnecessary with modern CPUs unless you need to saturate a 100G link with one connection. reply nubinetwork 13 hours agorootparent> unless you need to saturate a 100G link with one connectionMaybe not 100gig, but I routinely transfer data over 10gig links. I used to be a heavy user of HPN, but Gentoo pretty much stopped supporting it because the multithreading is supposedly broken. reply password4321 17 hours agoprevIf you want to tunnel UDP (WireGuard) or TCP (SSH) over the WebSocket protocol, check out https:&#x2F;&#x2F;github.com&#x2F;erebe&#x2F;wstunnel reply kernel_cat 17 hours agoparentAlso https:&#x2F;&#x2F;github.com&#x2F;nnathan&#x2F;monopiped. Just plugging my own project. reply IAmLiterallyAB 13 hours agoparentprevLooks neat. Have you looked into using the new WebTransport protocol?https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;draft-ietf-webtrans-ov... https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;draft-ietf-webtrans-ht...Still early stages, but it looks promising! Notably it supports multiple streams and unreliable datagrams since it goes over QUIC reply PrimeMcFly 17 hours agoparentprevWhy would you tunnel WireGuard over SSH? reply password4321 16 hours agorootparentAlthough not relevant to my post above, tunneling WireGuard over SSH sounds like an interesting challenge...Because WireGuard and SSH are at different layers of the network stack, it might be necessary (though slow) to bridge two WireGuard networks through a single TCP socket port-forwarded by SSH. I&#x27;m actually curious now what tools would best be used to accomplish this, how much effort would be needed to configure things, and how badly performance would suffer when faced with normal internet traffic congestion. reply oarsinsync 16 hours agorootparent> I&#x27;m actually curious now what tools would best be used to accomplish this“Tunnel UDP over SSH”https:&#x2F;&#x2F;superuser.com&#x2F;questions&#x2F;53103&#x2F;udp-traffic-through-ss... has some suggestions reply tssva 16 hours agorootparentprevPerhaps reread the comment. It presents info for running Wireguard or SSH over websockets and not running Wireguard over ssh. reply alphazard 18 hours agoprevThis is pretty neat, definitely better to move to UDP, so that we can have the proper response to unauthorized contact--no response.QUIC is fine as is though, no need to layer HTTP3 on top of it. reply vlovich123 17 hours agoparentThe reason they’re using HTTP is to allow for hiding the SSH server so that it pretends to be a dummy HTTP server that responds to 404 on all requests unless you know the special random URL that hosts the SSH capabilities. It’s a neat idea but overkill when you’re not using that capability (didn’t dig into the code so maybe it is bypassed if you don’t ask for a secret URL). It does make me hesitant as I don’t know how secure Go’s HTTP stack is since an exploit there could expose quite a bit and I don’t know that it’s been hardened to host directly, but it is an interesting idea. May be worth hand-rolling a custom server to do the routing but at the same time it makes it easier to fingerprint. I think it makes more sense to separate the routing secret to a standard reverse proxy that’s harder to fingerprint. One could imagine that the secret URL idea in a normal HTTP stack is susceptible to scanning techniques since there’s only one route to guess. reply neild 14 hours agorootparentHTTP&#x2F;3 is almost indistinguishable from any other protocol running over QUIC, and QUIC itself is almost indistinguishable from random noise in UDP packets. If you want to masquerade as HTTP&#x2F;3 traffic, just using UDP on port 443 will generally be sufficient.(Only “almost” indistinguishable, because it’s possible to decrypt the first packets of the client’s handshake and examine the ALPN parameters used to negotiate an application protocol. And QUIC may be further distinguishable from other UDP traffic through statistical analysis of packet sizes and response latencies, as well as the few unencrypted header bits.) reply gnyman 14 hours agorootparentprevIt&#x27;s not exactly the same but you can \"hide\" a ssh server on port 443 with haproxyIt&#x27;s not really hidden as if you initiate a connection with ssh it will reveal itself, but if you try https it will reply as a webserverIt world by looking at the first few bytes and deciding what to do based on thatAt one point I was running https&#x2F;ssh&#x2F;openvpn&#x2F;custom-tcp all on one port..Here is someone else explaining how to do it, I don&#x27;t think I ever wrote it uphttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8925938 reply stjohnswarts 14 hours agorootparentI never even thought of that, atlassian has a page on it: https:&#x2F;&#x2F;confluence.atlassian.com&#x2F;bitbucketserver&#x2F;setting-up-... reply jofla_net 15 hours agorootparentprevYeah its overkill. Its like trying to hide a meth lab by just putting up a sign that says daycare. (and if you do a special knock on the door you go to the secret room) Edit: vs having an invisible building which if you knock on it the right way, materializes...The best thing about QUIC if its udp is definately that it could be made un portscannable. reply withinboredom 16 hours agorootparentprevIt&#x27;s likely the URL can be discovered via basic timing attacks as virtually zero routers do constant-time comparisons for route matching. reply codetrotter 15 hours agorootparentIf the URL path is meant to be kept secret, such as here, they should use a password hashing algorithm such as for example bcrypt or scrypt for the URL path and hash the path of every incoming request and then check the hash of the path instead of the path itself reply withinboredom 9 hours agorootparentI&#x27;m unaware of any http router that does this out-of-the-box. It would have to be something custom. reply heyoni 17 hours agoparentprevIsn’t it necessary for oauth? reply vlovich123 17 hours agorootparentIt might be easier to integrate but you’ve got a custom server and client in this case so it should be possible to do both without HTTP being involved for the server&#x2F;client layer without an HTTP server? At least I think that’s right but it’s been a long long while since I wrote OAUTH code.Seems like it’s primarily to implement the masking feature to pretend to be a normal HTTP server hosted on a port until the shared secret URL is knocked. reply the8472 17 hours agorootparentprevThe client and server need to talk http to the authorization server, that doesn&#x27;t mean they need to talk http to each other. reply wackget 16 hours agoprevWhat if you already run a web server which uses port 443? Strange that the readme doesn&#x27;t mention that scenario because it&#x27;s extremely common.Presumably you&#x27;d choose a different port but then it&#x27;d be pretty obvious you&#x27;re running something if your server has a random HTTPS server exposed on port 444 or whatever. reply xyst 16 hours agoparentFront load service with nginx server or load balancer…nginx exposed on 443:if route is &#x2F;web then route to web service on port 1234if route is &#x2F;ssh3-secret-string -> route to ssh3 server service on port 1265if route doesn’t exist then 404… reply extraduder_ire 15 hours agorootparentCan nginx proxy-pass encrypted data now? I tried this before and failed pretty hard, had to use HAproxy at the time and pass based on the hostname in the SNI header. Was still pretty unreliable.If so, I assume the encryption on the SSH is handled separately from the http headers. reply xyst 14 hours agorootparenthttps:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;docs&#x2F;quic.htmlSince 1.25.0 reply eichin 10 hours agoparentprevThat already has a (brutal) solution now - sslh https:&#x2F;&#x2F;www.rutschle.net&#x2F;tech&#x2F;sslh&#x2F;README.html - the current version is more sophisticated, but it was originally just a perl script that would send the connection to sshd or the https web server, based on regex matching on an initial string (and I probably timing out and going to sshd if it didn&#x27;t see one? Something like that, I haven&#x27;t dug out the old code to check.) reply xgbi 16 hours agoparentprevCan&#x27;t you simply `proxy_pass` the traffic with any load balancer or reverse proxy (that you probably have anyways if you use TLS)? reply okasaki 16 hours agoparentprevYou can run different hosts on one web server, like company.com goes to localhost:5555 (your app or whatever) and ssh.company.com goes to localhost:8443 (let&#x27;s say you&#x27;re running ssh3 on that port) reply qingcharles 16 hours agorootparent* depending on your web server&#x2F;reverse proxy configuration[for instance, I run Kestrel and it really isn&#x27;t designed to target more than one site; I do it, but it&#x27;s like bending that Lego brick to make it fit where it shouldn&#x27;t go] reply okasaki 15 hours agorootparentYes I suppose, although you can always put a web server that does support it (like nginx) in front of your web server that doesn&#x27;t support it. reply qingcharles 11 hours agorootparentYeah, this is what MS used to recommend, although they now say their own version YARP is better. reply ajross 12 hours agoparentprevSSHv2 is likewise trivially probable though (\"nc $HOST 22\" replies with \"SSH-2.0-whatever\"!), and that never hurt it. If you want to hide your services from attackers, there are many tools for that. I don&#x27;t see why it needs to be part of the application protocol. reply rubyfan 15 hours agoprevSomething about calling this SSH3 feels like when Comcast named a thing 10G. reply apatheticonion 11 hours agoprevInteresting. Having HTTP&#x2F;3 layered over the top, which I presume allows for SSL certificates to be applied to the connection, might result in the SSH connection appearing to observers as standard - uninteresting - website traffic.Assuming one could connect to an SSH server this way and tunnel ports, could this allow for a means to bypass China&#x27;s GFW?China&#x27;s firewall allows http and https connections through however VPNs, SSH and similar are detected upon connection and blocked on demand.Hiding a VPN connection by tunneling to a remote SSH server over HTTP&#x2F;3, forwarding the VPN port and connecting to it might fly under the radar as it could be perceived as regular web traffic.Would be an interesting thing to try. reply kiitos 5 hours agoprevThe interesting thing here isn&#x27;t so much the improved latency or whatever, it&#x27;s the ability to ssh from a client that&#x27;s on a network which restricts access to anything other than 80&#x2F;443 reply cwillu 6 hours agoprevNot related to IETF, no RFC, entirely unrelated to the processes involved in the standard.Protecting against the potential for confusion from and&#x2F;or abuses like this is what trademarks are for. reply Bu9818 7 hours agoprevFor faster session establishment in OpenSSH consider ControlMaster in ssh_config(5), which multiplexes multiple sessions in one connection instead of creating a new connection for each session. reply mynameisnoone 2 hours agoparentnext [–]# ~&#x2F;.ssh&#x2F;config # Place at the *End-of-file* Host * ControlMaster auto ControlPath ~&#x2F;.ssh&#x2F;sockets&#x2F;%C.sock ControlPersist 600 ServerAliveInterval 60 ServerAliveCountMax 10 IPQoS throughput TCPKeepAlive yes # :: Security Exception :: Purposeful for UX usability of machine-to-machine hops ForwardAgent yes # ssh-audit recommendations https:&#x2F;&#x2F;www.ssh-audit.com&#x2F;hardening_guides.html # CASignatureAlgorithms sk-ssh-ed25519@openssh.com,ssh-ed25519,rsa-sha2-512,rsa-sha2-256 HostKeyAlgorithms sk-ssh-ed25519-cert-v01@openssh.com,ssh-ed25519-cert-v01@openssh.com,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-256-cert-v01@openssh.com,sk-ssh-ed25519@openssh.com,ssh-ed25519,rsa-sha2-512,rsa-sha2-256 HostbasedAcceptedAlgorithms sk-ssh-ed25519-cert-v01@openssh.com,ssh-ed25519-cert-v01@openssh.com,sk-ssh-ed25519@openssh.com,ssh-ed25519,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-512,rsa-sha2-256-cert-v01@openssh.com,rsa-sha2-256 PubkeyAcceptedAlgorithms sk-ssh-ed25519-cert-v01@openssh.com,ssh-ed25519-cert-v01@openssh.com,sk-ssh-ed25519@openssh.com,ssh-ed25519,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-512,rsa-sha2-256-cert-v01@openssh.com,rsa-sha2-256 KexAlgorithms sntrup761x25519-sha512@openssh.com,curve25519-sha256,curve25519-sha256@libssh.org MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr # GSSAPIKexAlgorithms gss-curve25519-sha256-,gss-group14-sha256-,gss-group16-sha512- reply throwawaaarrgh 13 hours agoprevThrowaway&#x27;s maxim: no new protocol works without HTTP reply jsiepkes 16 hours agoprevMissed chance not to call it SSHTTP3 ;-) reply egberts1 14 hours agoprevSSH3 does not equate to SSHv2 over HTTP&#x2F;3-QUIC. reply Sleaker 14 hours agoprevWhat makes this any better than say, MOSH? reply wslh 15 hours agoprevIs there a security audit for this code? reply zelly 14 hours agoprevSeems cool but mosh already exists reply JCharante 14 hours agoprevOauth for ssh sounds annoying reply cvalka 15 hours agoprevWhy no support for mTLS? Certificate based authentication for clients is a must. reply Jhsto 17 hours agoprevSounds like something to try in an internal network where you want to do X11 or Wayland application forwarding! reply k__ 18 hours agoprevHow does it compare to Mosh? reply mcfedr 15 hours agoparentSounds like it as to solve completely different set of problems reply jedisct1 14 hours agoprevThis is cool, but calling that SSH3 is not appropriate. It&#x27;s an independent project, not a new version of the SSH protocol. Sure, it&#x27;s \"SSH3\" and not \"SSHv3\". Still, introducing a confusion with something that could be an official protocol is not nice. reply netsharc 9 hours agoparentI&#x27;m surprised no one&#x27;s opened an issue on their repo and that no brigade has opined with lots of comments and emojis... reply jhatemyjob 15 hours agoprevSo let me get this straight, from reading the README, the only tangible benefit is faster session establishment? With the downsides being, he&#x27;s using a more complicated protocol, which apparently has slower throughput?? I guess this is a cool experiment but why would anyone use this over OpenSSH or libssh2? reply skywhopper 13 hours agoprevThis is a really cool project and a great idea that seems to be decently implemented.Calling it “SSH3”, however, is misleading at best, and misrepresents what the project is. Please consider choosing a better name. reply gsu2 12 hours agoprevThis seems bad?- SSH3 is a bad name: this isn&#x27;t a successor to SSHv2 and will only cause confusion- The authors don&#x27;t seem to understand that SSHv2 predates all of their chosen technologies, and provides \"robust and time-tested mechanisms\" they claim to be adding- How is \"hiding your server behind a secret link\" a feature? This is, at best, security through obscurity, which can be layered on any network protocol (e.g. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Port_knocking); this implies that the authors don&#x27;t have much of a security background...?- ...Which explains why they think something as complicated as OpenID Connect is a good thing to add to SSH (i.e. https:&#x2F;&#x2F;security.stackexchange.com&#x2F;questions&#x2F;148292&#x2F;why-is-o...)- The abstract in the linked paper seems to conflate SSHv1 and SSHv2; I couldn&#x27;t really bring myself to read much past thatIn summary: this seems bad. reply janosdebugs 11 hours agoparentI concur. They seem to have reinvented a part of the protocol without actually addressing many of the issues of SSH. The paper also doesn&#x27;t bother to go into details on any the advancements that have been made to SSH since the original RFC, such as keyboard-interactive, GSSAPI, etc.> Some SSH implementations such as OpenSSH or Tectia support other ways to authenticate users. Among them is the certificate-based user authentication: only users in possession of a certificate signed by a trusted certificate authority (CA) can gain access to the remote server [12]. Available for more than 10 years, this authentication method requires setting up a CA and distributing the certificates to new users and is still not commonly used nowadays.Somebody had an agenda to make SSH look as bad as possible. You can implement OIDC authentication with keyboard-interactive, no need for HTTP&#x2F;3 for that. However, it gets very tricky if you want automated &#x2F; script access, so it doesn&#x27;t solve the authentication problem.As an aside, Tatu Ylonen, the original author of the SSH protocol, published a paper in 2019 titled \"SSH Key Management Challenges and Requirements\"[1], which is an interesting read. It would seem the authors of this paper should have at least read it.[1] https:&#x2F;&#x2F;www.ylonen.org&#x2F;papers&#x2F;ssh-key-challenges.pdf reply insanitybit 11 hours agoparentprev> This is, at best, security through obscurity, which can be layered on any network protocol (e.g. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Port_knocking); this implies that the authors don&#x27;t have much of a security background...?This isn&#x27;t security through obscurity. The url would be a secret. This is a form of capability security, where to connect to the server you must be able to name the server.A URL with a secret is, in my opinion, far more sane than port knocking, and will be much more efficient as well.> (i.e. https:&#x2F;&#x2F;security.stackexchange.com&#x2F;questions&#x2F;148292&#x2F;why-is-o...)Your link doesn&#x27;t support your statement at all. No one there answers \"here&#x27;s why oid is less secure\", they say the opposite. reply idlephysicist 11 hours agoparentprevI&#x27;d agree with you. The readme calls out \"Significantly faster session establishment\" and goes into greater detail later on.> Establishing a new session with SSHv2 can take 5 to 7 network round-trip times, which can easily be noticed by the user. SSH3 only needs 3 round-trip times. The keystroke latency in a running session is unchanged.I, for one, can say that sometimes session establishment can take a little while but not to the extent that it would be a selling point (so to speak) for me to adopt SSH3. reply commandersaki 11 hours agoparentprevSSH over HTTP&#x2F;(url) is a killer feature if you&#x27;re working on hostile networks that block SSH and go even as far as to try and detect the protocol over the wire. reply badrabbit 11 hours agoparentprevYour points are great but SSH is extensible so openid connect support doesn&#x27;t mean much since you can do it with existing ssh.\"Security by obscurity\" is only a thing if you&#x27;re relying on that mechanism for security. People already configure SSH port knocking as you noted. It can be considered attack surface reduction and is a good feature given they&#x27;re not using a secret link for any security control.One benefit of their approach might be how you can use TLS pki now instead if setting up ssh-ca&#x27;s. Potentially you would need to manage less pki.But a criticism I have is how http* has much more vulns and new attack techniques being developed all the time unlike ssh. I can imagine LFI or request smuggling on the same http&#x2F;2 web server causing RCE via their protocol. reply anthk 15 hours agoprevMeh. OpenBSD does it fine. If not, Mosh works great on flakey connections. reply out_of_protocol 18 hours agoprevIf you want SSH via UDP, try mosh. If you have it installed on both client and server side, it just works, re-using auth, sessions etc fron ssh itself and only replacing sending actual session bytes back and forth. Don&#x27;t break on unstable connections, have way lower latency reply georgyo 18 hours agoparentMosh and this project have fairly different goals.Mosh uses regular TCP SSHv2 to authenticate and setup the udp connection. As such your initial connection time is actually slower than just normal v2, and you cannot auth with something like oauth.Mosh is heavily focused on interactive sessions. You could not use mosh for batch programs easily. reply gabeio 16 hours agorootparent> Mosh is heavily focused on interactive sessions. You could not use mosh for batch programs easily.Correct, the goals are better human interaction with a high delay internet or server. Effectively allowing the client side to guess a bit as to where your input went (it does decently at it). But the key thing that I&#x27;ve loved is even if my client machine goes to sleep and I go to a different building I&#x27;m still connected to the server. That is wonderful. Agreed the connection time is slower. Mosh = Mobile shell. reply v3ss0n 17 hours agoparentpreveternal is better than mosh https:&#x2F;&#x2F;eternalterminal.dev&#x2F; reply chungy 16 hours agorootparent\"ET uses TCP\"Right there, Eternal doesn&#x27;t even try to cover the same use case as Mosh. It might be an alternative, same way regular SSH is an alternative, but there&#x27;s no way it can be \"better\" reply ckwalsh 17 hours agorootparentprevDo you happen to know where I can read about how ET and Mosh each establish their connections?I have used Mosh for years and recently heard of ET, but when I tried it I experienced noticeable hangs that I don’t get with Mosh, and I went back.I heard from several people that “ET is the new Mosh”, but it won’t be for me unless I can figure out&#x2F;resolve those hangs reply password4321 16 hours agorootparentprevI would probably choose between the two based mostly on their security track record, but I haven&#x27;t needed the comparison yet. reply binkHN 17 hours agorootparentprevNeat.> While mosh provides the same core functionality as ET, it does not support native scrolling nor tmux control mode (tmux -CC). reply password4321 16 hours agoprevSSH3 seems a bit of a clickbait project name, it&#x27;s not clear to me that this project uses anything protocol-wise from SSH though it offers similar functionality.A PhD project from Belgium that combines several Golang libraries to offer HTTP-based authentication on top of backwards compatibility with OpenSSH keys, configuration, agents, etc. -- it looks pretty solid but the associated paper titled \"Towards SSH3\" acknowledges \"This article is a first step\" in the conclusion. reply mmaunder 17 hours agoprevWARNING: This is not ssh3. This is someone’s project. Install at your own risk. reply heyoni 17 hours agoparentThey should have called it SSHTTP3 reply tsimionescu 17 hours agorootparentSecure SHell -Text Transfer Protocol 3? reply arp242 17 hours agoparentprevAnyone should treat any new crypto project which hasn&#x27;t seen a lot of testing from others as such, no matter who it came from. Even if this was some sort of proposal of the OpenSSH people.The project is associated with the Louvain university; I would rate the risk of outright malicious tomfoolery to be quite low. reply tjoff 16 hours agorootparentWell, if it was a proposal of the OpenSSH people you&#x27;d bet it would get a lot of testing from others real quick.But to even consider calling it SSH3 is really quite silly, first impression doesn&#x27;t exactly inspire confidence. reply arp242 16 hours agorootparent\"Confidence\" in what? Ability to name things? It&#x27;s making a mountain out of a molehill. It&#x27;s certainly not an issue with the crypto or code. reply tjoff 16 hours agorootparentJudgement? Having attention for detail? Being in touch with the community?Just a bad look &#x2F; first impression. replyikiris 17 hours agoprevAside from the weird claim of being SSH3, this project seems to not understand that ssh already supported cert auth. reply tenebrisalietum 16 hours agoprevI&#x27;m going to use this to do UUCP over QUIC. reply egberts1 18 hours agoprevNot going there with anything HTTP&#x2F;3.Disclaimer: I write network packet parsers for XNS&#x2F;IPS&#x2F;IDS for a living, to look for \"bad things\". reply nixgeek 16 hours agoparentThe standards bodies don’t seem to buy the “bad things” argument and appear resolute on making it harder to MITM traffic on the wire and attempting to force IDS&#x2F;IPS to all be run on the client.Is there a 5-10 year future where you just can’t do this as a middlebox? reply jeroenhd 16 hours agorootparentProtocols supported MITM with correct configurations and it led to complete ossification of said protocols because middleboxes suck at following standards.It seems that at the time these features were dropped, most middleboxes have ignored features like exporting keys or configuring static RSA keys and went for CA-MitM attacks instead. You should expect these tools to break if they&#x27;re actively trying to subvert protocols to do things they&#x27;re not designed to support.I don&#x27;t really see what changed, though. I guess static keys were dropped to provide forward secrecy, but other than that running your own rogue CA is as possible as it was 20 years ago. Middleboxes lagging behind in support for features like HTTP&#x2F;3 is probably annoying, but that&#x27;s because of a lack of implementation more than anything.You can still use your domain tools&#x2F;MDM configuration&#x2F;settings to configure an HTTPS proxy and firewall off the normal ports if you want to MitM your network reliably. If yiur prozy doesnt support http&#x2F;3, it will happily downgrade your connection to HTTP&#x2F;1.1 for you. Android&#x27;s insistence on not actually applying user-installed certificates is a pain for many apps, but other operating systems will happily and silently drop security measures like certificate transparency when they encounter a user-operated MitM CA.The lack of MitMability comes down to Android being fussy, IoT devices you had no chance of ever controlling needing workarounds, and devices you don&#x27;t have permissions to manage not being manageable. I really do wish Android would let MDM solutions inject certificates into the system store (though I can see why they don&#x27;t with the wide range of stalkerware in the wild). reply egberts1 14 hours agorootparentSecond paragraph: \"most middleboxes ...\"It is the \"others\". reply mmaunder 17 hours agoparentprevHow intentionally vague. reply lajamerr 17 hours agorootparentI assume he means with the encrypted metadata in HTTP&#x2F;3 &#x2F; QUIC that it makes it harder as a security admin to \"peek\" at what is going on in the network.In my opinion its short sighted, because if we care about security, then we should care about user security and privacy as well. Because if the security admin has the ability to packet inspect stuff, so does a potential malicious app. reply insanitybit 16 hours agorootparentOdd, surely SSHv2 already suffers from inability to inspect on the wire. reply egberts1 14 hours agorootparentFrom the Github:SSH3 is a complete revisit of the SSH protocol, mapping its semantics on top of the HTTP mechanisms. In a nutshell, SSH3 uses QUIC+TLS1.3 for secure channel establishment and the HTTP Authorization mechanisms for user authentication.So, it has nothing to do with SSH2; more about HTTP&#x2F;3-QUIC security theater: hostname is still being sent over TLS&#x2F;1.3 negotiation. reply insanitybit 12 hours agorootparentTo be clear, my reading of the parent post is that the grandparent doesn&#x27;t like HTTP&#x2F;3-QUIC making it harder to read data off of the wire (ie: for internal security analytics).But I don&#x27;t see how this is worse than SSHv2. In both cases retrieving the hostname &#x2F; IP is obviously trivial since you just instrument DNS for the hostname and, of course, the IP is cleartext. reply NegativeK 12 hours agorootparentprevThe owning organization or user should already have full admin on all endpoints.Malicious apps and attackers should not. reply egberts1 14 hours agorootparentprevMore like incomplete state machine for HTtP&#x2F;3-QUIc reply password4321 16 hours agoparentprevMy understanding is limited, but HTTP&#x2F;3 boils down roughly to HTTP&#x2F;2+QUIC.Major cloud providers are still shaking issues out of HTTP&#x2F;2 like \"Rapid Reset\" 2 months ago, the nesting and layers open gaps and new edge cases as naive implementations were clearly not yet battle hardened even against old attack families like amplification&#x2F;resource exhaustion.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37830987 The novel HTTP&#x2F;2 &#x27;Rapid Reset&#x27; DDoS attackhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37837043 HAProxy is not affected by the HTTP&#x2F;2 Rapid Reset Attack reply qwertox 17 hours agoparentprevI wish you would share some of your thoughts. reply xorcist 14 hours agoparentprevNot sure why this is downvoted. HTTP3&#x2F;QUIC is a lot more complex to implement than SSH.SSL is a very well studied standard, but it is clearly a committee product with lots of features built on enterprise standards like X.509, and SSH is made by a few protocol engineers with a razor sharp use case.It is easy to see why someone who audits parsers for a living would be much more comfortable with SSH as compared to a something over HTTP&#x2F;SSL&#x2F;QUIC. reply znpy 18 hours agoprev [–] Is this wayland all over again? We do three or four new things well, and everybody is supposed to just stop doing everything else ?Is this \"a secure shell\" (as in, somebody&#x27;s personal spin on the topic) or like a new \"official\" direction?The readme isn&#x27;t clear on these aspects. reply amluto 18 hours agoparentWhat does “official” mean? The OpenSSH team? IETF?Anyway, SSH authentication is extremely inflexible, and the protocol is not particularly performant, especially on large bandwidth-delay links. Moving to HTTP3 seems like an excellent idea if it’s implemented well.(Although… we really need a way to do TLS&#x2F;QUIC to an endpoint without a domain name.) reply aseipp 17 hours agorootparentYeah, right now for auth, if you want to use e.g. OIDC I think the best you can do is to essentially shove everything in the square hole using very short-lived SSH certificates and OOB auth flow; e.g. \"open this browser link to get a cert for the next 15 minutes&#x2F;24 hours.\" So, you&#x27;re basically treating short-lived certs like session tokens, more or less. I got this working with my own homegrown SSH CA infrastructure last year, but never took it out of prototype stage. Even slightly more flexible authentication would be very welcome. reply amluto 17 hours agorootparentCloudflare offers this as a service. It’s obviously a second class citizen (it’s intensely buggy, has low availability, doesn’t work especially well even on a good day, has incoherent configuration, and no support whatsoever).On the other hand, all Cloudflare configuration seems incoherent, and it gets more so over time. I was recently highly entertained when I tried to access one of the Zero Trust [0] pages. The UI cheerfully informed me that only the new UI could configure Zero Trust, and it redirected me to a new domain that was IIRC “one.dash.cloudflare.com”. You can’t make this up — maybe it’s called One Trust internally? The new panel looked quite a lot like the old one except that the Zero Trust pages worked.Well, “worked”. None of the Zero Trust config makes any sense.[0] Is there any logic at all to what lives under the Zero Trust umbrella? reply the8472 17 hours agorootparentprev> (Although… we really need a way to do TLS&#x2F;QUIC to an endpoint without a domain name.)Generate self-signed cert, let the client TOFU. And skip the HTTP part. Just like SSH. There&#x27;s no reason to do things like a browser. reply amluto 15 hours agorootparentI think we could do much better than this with a small amount of creativity.But it really ought to be possible to securely configure locally-connected devices with a browser, and this is not really possible today. reply uxp8u61q 18 hours agorootparentprevThe RFCs for SSH2 were all published by IETF, so I would definitely expect IETF to be involved in a project that claims to be \"SSH3\". If some random person started an OS project and called it \"Windows 12\", people would rightfully be confused. reply lnxg33k1 18 hours agorootparentAgree I also think that we should leave naming stuff SSH to IETF and OpenSSH to OpenBSD, in this case the maintainer seems to be unrelated to both reply tlivolsi 18 hours agorootparentprevAgreed. The name is terribly misleading. reply ctz 13 hours agorootparentprevThe IETF SSH working group was disbanded in 2006. You will be waiting a long time if you expect anything else to come from there by magic. reply mseepgood 18 hours agoparentprevIt&#x27;s obviously a personal project. reply uxp8u61q 18 hours agoparentprev [–] It&#x27;s just someone&#x27;s project. As far as I can tell it&#x27;s unrelated to IETF, if that&#x27;s what you mean by \"official\". In any case it&#x27;s presumptuous for the author to call this \"SSH3\". reply brunoqc 17 hours agorootparent [–] it&#x27;s probably just ssh + http&#x2F;3 replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SSH3 is a revised version of the SSH protocol that uses HTTP mechanisms to offer a faster and more secure shell experience.",
      "It employs QUIC+TLS1.3 for secure channel establishment and HTTP Authorization for user authentication.",
      "SSH3 provides faster session establishment, improved authentication methods (OAuth2.0, OpenID Connect), robustness to port scanning attacks, UDP port forwarding, and features of the modern QUIC protocol.",
      "It allows for hiding the SSH server and supports X.509 certificates for authentication.",
      "SSH3 is currently experimental and can be installed by downloading the binaries or compiling the code from source.",
      "An SSH3 server needs to be deployed to use SSH3, and the SSH3 client supports various authentication methods."
    ],
    "commentSummary": [
      "The comment thread covers a range of topics related to SSH, such as compatibility with protocols like HTTP/3 and QUIC, the use of certificates for authentication, and the potential for a new version of SSH.",
      "Alternative protocols like Mosh are also discussed.",
      "The discussion includes various perspectives and concerns regarding security, efficiency, implementation, network censorship, protocol hiding, and device management."
    ],
    "points": 316,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1702739202
  },
  {
    "id": 38667596,
    "title": "Multiple Security Vulnerabilities Found in MongoDB; Update Recommended",
    "originLink": "https://www.mongodb.com/alerts",
    "originBody": "11/07/2023 CVE-2023-0436 4.5 Secret logging may occur in debug mode of Atlas Operator The affected versions of MongoDB Atlas Kubernetes Operator may print sensitive information... View more... AFFECTS: MongoDB Atlas Kubernetes Operator VERSIONS: 1.5.0 affects 1.7.0 and prior versions Reference Link → 08/29/2023 CVE-2021-32050 4.2 Some MongoDB Drivers may publish events containing authentication-related data to a command listener configured by an application Some MongoDB Drivers may erroneously publish events containing authentication-related data... View more... AFFECTS: MongoDB C Driver VERSIONS: 1.0.0 affects versions prior to 1.17.7 Reference Link → 08/23/2023 CVE-2023-1409 5.3 Certificate validation issue in MongoDB Server running on Windows or macOS If the MongoDB Server running on Windows or macOS is configured to use TLS with a specific... View more... AFFECTS: MongoDB Server VERSIONS: 6.3 affects 6.3.2 and prior versions 5.0 affects 5.0.14 and prior versions 4.4 affects 4.4.23 and prior versions Reference Link → 08/08/2023 CVE-2023-4009 7.2 Privilege Escalation for Project Owner and Project User Admin Roles in Ops Manager In MongoDB Ops Manager v5.0 prior to 5.0.22 and v6.0 prior to 6.0.17 it is possible for an... View more... AFFECTS: MongoDB Ops Manager VERSIONS: 6.0 affects versions prior to 6.0.17 5.0 affects versions prior to 5.0.22 Reference Link → 06/09/2023 CVE-2023-0342 3.1 MongoDB Ops Manager may disclose sensitive information in Diagnostic Archive MongoDB Ops Manager Diagnostics Archive may not redact sensitive PEM key file password app... View more... AFFECTS: MongoDB Ops Manager VERSIONS: v5.0 affects versions prior to 5.0.21 v6.0 affects versions prior to 6.0.12 Reference Link → 02/21/2023 CVE-2022-48282 6.6 Deserializing compromised object with MongoDB .NET/C# Driver may cause remote code execution Under very specific circumstances (see Required configuration section below), a privileged... View more... AFFECTS: MongoDB .NET/C# Driver VERSIONS: 0 affects v2.18.0 and prior versions Reference Link → 05/11/2022 CVE-2022-24272 6.5 MongoDB Server (mongod) may crash in response to unexpected requests An authenticated user may trigger an invariant assertion during command dispatch due to in... View more... AFFECTS: MongoDB Server VERSIONS: 5.0 affects 5.0.6 and prior versions Reference Link → 04/12/2022 CVE-2021-32040 6.5 Large aggregation pipelines with a specific stage can crash mongod under default configuration It may be possible to have an extremely long aggregation pipeline in conjunction with a sp... View more... AFFECTS: MongoDB Server VERSIONS: 5.0 affects versions prior to 5.0.4 4.4 affects versions prior to 4.4.11 4.2 affects versions prior to 4.2.16 Reference Link → 02/04/2022 CVE-2021-32036 5.4 Denial of Service and Data Integrity vulnerability in features command An authenticated user without any specific authorizations may be able to repeatedly invoke... View more... AFFECTS: MongoDB Server VERSIONS: 5.0 affects 5.0.3 and prior versions 4.4 affects 4.4.9 and prior versions 4.2 affects 4.2.16 and prior versions 4.0 affects 4.0.28 and prior versions Reference Link → 01/20/2022 CVE-2021-32039 5.5 MongoDB Extension for VS Code may unexpectedly store credentials locally in clear text Users with appropriate file access may be able to access unencrypted user credentials save... View more... AFFECTS: MongoDB for VS Code VERSIONS: MongoDB for VS Code affects 0.7.0 and prior versions Reference Link → 12/15/2021 CVE-2021-20330 6.5 Specific replication command with malformed oplog entries can crash secondaries An attacker with basic CRUD permissions on a replicated collection can run the applyOps co... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.27 4.2 affects versions prior to 4.2.16 4.4 affects versions prior to 4.4.9 Reference Link → 11/24/2021 CVE-2021-32037 6.5 User may trigger invariant when allowed to send commands directly to shards An authorized user may trigger an invariant which may result in denial of service or serve... View more... AFFECTS: MongoDB Server VERSIONS: 5.0 affects 5.0.2 and prior versions Reference Link → 08/02/2021 CVE-2021-20332 4.2 MongoDB Rust Driver may publish events containing authentication-related data to a connection pool event listener configured by an application Specific MongoDB Rust Driver versions can include credentials used by the connection pool ... View more... AFFECTS: MongoDB Rust Driver VERSIONS: 2.0.0-alpha 2.0.0-alpha1 1.0.0 affects 1.2.1 and prior versions Reference Link → 07/23/2021 CVE-2021-20333 5.3 Server log entry spoofing via newline injection Sending specially crafted commands to a MongoDB Server may result in artificial log entrie... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.20 4.0 affects versions prior to 4.0.21 4.2 affects versions prior to 4.2.10 Reference Link → 06/10/2021 CVE-2021-20329 6.8 Specific cstrings input may not be properly validated in the Go Driver Specific cstrings input may not be properly validated in the MongoDB Go Driver when marsha... View more... AFFECTS: MongoDB Go Driver VERSIONS: 1.0 affects 1.5.0 and prior versions Reference Link → 05/24/2021 CVE-2021-20331 4.2 MongoDB C# Driver may publish events containing authentication-related data to a command listener configured by an application Specific versions of the MongoDB C# Driver may erroneously publish events containing authe... View more... AFFECTS: MongoDB C# Driver VERSIONS: 2.12 affects 2.12.1 and prior versions Reference Link → 04/30/2021 CVE-2021-20326 6.5 Specially crafted query may result in a denial of service of mongod A user authorized to performing a specific type of find query may trigger a denial of serv... View more... AFFECTS: MongoDB Server VERSIONS: 4.4 affects versions prior to 4.4.4 Reference Link → 04/12/2021 CVE-2020-7924 4.2 Specific command line parameter might result in accepting invalid certificate Usage of specific command line parameter in MongoDB Tools which was originally intended to... View more... AFFECTS: MongoDB Database Tools VERSIONS: 3.6.5 affects versions prior to 3.6* 4.0 affects versions prior to 4.0.21 4.2 affects versions prior to 4.2.11 100 affects versions prior to 100.2.0 Reference Link → 04/06/2021 CVE-2021-20334 4.8 Local privilege escalation in MongoDB Compass for Windows A malicious 3rd party with local access to the Windows machine where MongoDB Compass is in... View more... AFFECTS: MongoDB Compass VERSIONS: 1.3.0 affects versions prior to 1.x* Reference Link → 02/26/2021 CVE-2020-7929 6.5 Specially crafted regex query can cause DoS A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.21 4.0 affects versions prior to 4.0.20 Reference Link → 02/26/2021 CVE-2018-25004 4.9 Invariant failure when explaining a find with a UUID A user authorized to performing a specific type of query may trigger a denial of service b... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.11 4.0 affects versions prior to 4.0.6 Reference Link → 02/25/2021 CVE-2021-20327 6.4 MongoDB Node.js client side field level encryption library may not be validating KMS certificate A specific version of the Node.js mongodb-client-encryption module does not perform correc... View more... AFFECTS: mongodb-client-encryption module VERSIONS: 1.2.0 Reference Link → 02/25/2021 CVE-2021-20328 6.4 MongoDB Java driver client-side field level encryption not verifying KMS host name Specific versions of the Java driver that support client-side field level encryption (CSFL... View more... AFFECTS: mongo-java-driver VERSIONS: 3.11 affects 3.11.2 and prior versions 3.12 affects 3.12.7 and prior versions Reference Link → 02/11/2021 CVE-2021-20335 6.7 SSL may be unexpectedly disabled during upgrade of multiple-server MongoDB Ops Manager For MongoDB Ops Manager <= 4.2.24 with multiple OM application servers, that have SSL turn... View more... AFFECTS: Ops Manager VERSIONS: 4.2 affects 4.2.24 and prior versions Reference Link → 12/01/2020 CVE-2019-20924 6.5 Invariant in IndexBoundsBuilder A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 4.2 affects versions prior to 4.2.2 Reference Link → 11/30/2020 CVE-2020-7925 7.5 Denial of Service when processing malformed Role names Incorrect validation of user input in the role name parser may lead to use of uninitialize... View more... AFFECTS: MongoDB Server VERSIONS: 4.2 affects versions prior to 4.2.9 4.4 affects versions prior to 4.4.0-rc12 Reference Link → 11/30/2020 CVE-2020-7926 6.5 Specific query can cause a DoS against MongoDB Server A user authorized to perform database queries may cause denial of service by issuing a spe... View more... AFFECTS: MongoDB Server VERSIONS: 4.4 affects versions prior to 4.4.1 Reference Link → 11/30/2020 CVE-2020-7927 8.1 Potential privilege escalation in Ops Manager API Specially crafted API calls may allow an authenticated user who holds Organization Owner p... View more... AFFECTS: MongoDB Ops Manager VERSIONS: 4.2 affects 4.2.17 and prior versions 4.3 affects 4.3.9 and prior versions 4.4 affects 4.4.2 and prior versions Reference Link → 11/30/2020 CVE-2019-2392 6.5 $mod can result in UB A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.20 4.0 affects versions prior to 4.0.20 4.2 affects versions prior to 4.2.9 4.4 affects versions prior to 4.4.1 Reference Link → 11/30/2020 CVE-2019-2393 6.5 Crash while joining collections with $lookup A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.15 4.0 affects versions prior to 4.0.13 4.2 affects versions prior to 4.2.1 Reference Link → 11/30/2020 CVE-2019-20923 6.5 Crash while handling internal Javascript exception types A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.7 Reference Link → 11/30/2020 CVE-2018-20802 6.5 Post-auth queries on compound index may crash mongod A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.9 4.0 affects versions prior to 4.0.3 Reference Link → 11/30/2020 CVE-2018-20804 6.5 Invariant failure in applyOps A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.13 4.0 affects versions prior to 4.0.10 Reference Link → 11/30/2020 CVE-2018-20805 6.5 Invariant with $elemMatch A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 3.6 affects versions prior to 3.6.10 4.0 affects versions prior to 4.0.5 Reference Link → 11/24/2020 CVE-2019-20925 7.5 Denial of service via malformed network packet An unauthenticated client can trigger denial of service by issuing specially crafted wire ... View more... AFFECTS: MongoDB Server VERSIONS: 4.2 affects versions prior to 4.2.1 4.0 affects versions prior to 4.0.13 3.6 affects versions prior to 3.6.15 3.4 affects versions prior to 3.4.24 Reference Link → 11/23/2020 CVE-2020-7928 6.5 Improper neutralization of null byte leads to read overrun A user authorized to perform database queries may trigger a read overrun and access arbitr... View more... AFFECTS: MongoDB Server VERSIONS: 4.4 affects versions prior to 4.4.1 4.2 affects versions prior to 4.2.9 4.0 affects versions prior to 4.0.20 3.6 affects versions prior to 3.6.20 Reference Link → 11/23/2020 CVE-2018-20803 6.5 Infinite loop in aggregation expression A user authorized to perform database queries may trigger denial of service by issuing spe... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.5 3.6 affects versions prior to 3.6.10 3.4 affects versions prior to 3.4.19 Reference Link → 08/21/2020 CVE-2020-7923 6.5 Specific GeoQuery can cause DoS against MongoDB Server A user authorized to perform database queries may cause denial of service by issuing speci... View more... AFFECTS: MongoDB Server VERSIONS: 4.4 affects versions prior to 4.4.0-rc7 4.2 affects versions prior to 4.2.8 4.0 affects versions prior to 4.0.19 Reference Link → 05/13/2020 CVE-2019-2388 5.8 Potential exposure of log information in Ops Manager In affected Ops Manager versions there is an exposed http route was that may allow attacke... View more... AFFECTS: Ops Manager VERSIONS: 4.0.9 4.0.10 4.1.5 Reference Link → 05/06/2020 CVE-2020-7921 4.6 Administrative action may disable enforcement of per-user IP whitelisting Improper serialization of internal state in the authorization subsystem in MongoDB Server'... View more... AFFECTS: MongoDB Server VERSIONS: 4.2 affects versions prior to 4.2.3 4.0 affects versions prior to 4.0.15 3.6 affects versions prior to 3.6.18 4.3 affects versions prior to 4.3.3 Reference Link → 04/09/2020 CVE-2020-7922 6.4 Kubernetes Operator generates potentially insecure certificates X.509 certificates generated by the MongoDB Enterprise Kubernetes Operator may allow an at... View more... AFFECTS: MongoDB Enterprise Kubernetes Operator VERSIONS: 1.0 1.1 1.2 affects 1.2.4 and prior versions 1.3 affects 1.3.1 and prior versions 1.4 affects 1.4.4 and prior versions Reference Link → 03/31/2020 CVE-2019-2391 4.2 JS-bson may incorrectly serialise some requests Incorrect parsing of certain JSON input may result in js-bson not correctly serializing BS... View more... AFFECTS: js-bson VERSIONS: 1.0 affects 1.1.3 and prior versions Reference Link → 08/30/2019 CVE-2019-2389 5.3 Process termination via PID file manipulation Incorrect scoping of kill operations in MongoDB Server's packaged SysV init scripts allow ... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.11 3.6 affects versions prior to 3.6.14 3.4 affects versions prior to 3.4.22 Reference Link → 08/30/2019 CVE-2019-2390 8.2 Code execution on Windows via OpenSSL engine injection An unprivileged user or program on Microsoft Windows which can create OpenSSL configuratio... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.11 3.6 affects versions prior to 3.6.14 3.4 affects versions prior to 3.4.22 Reference Link → 08/06/2019 CVE-2019-2386 7.1 Authorization session conflation After user deletion in MongoDB Server the improper invalidation of authorization sessions ... View more... AFFECTS: MongoDB Server VERSIONS: 4.0 affects versions prior to 4.0.9 3.6 affects versions prior to 3.6.13 3.4 affects versions prior to 3.4.22 Reference Link →",
    "commentLink": "https://news.ycombinator.com/item?id=38667596",
    "commentBody": "MongoDB security noticeHacker NewspastloginMongoDB security notice (mongodb.com) 240 points by ciudilo 13 hours ago| hidepastfavorite152 comments iaresee 12 hours agoWe are completely locked out of our Atlas account and the support portal right now. We Okta-auth with Mongo and all attempts to auth right now are failing with \"The request contained invalid data.\" displayed on their login screen.Of course, the support portal requires you to auth to use it...to get help with auth failing.Anyone else seeing issues getting in to their dashboard?Edit: Auth started working for us and dashboard access became available for us around 5:15 pm ET. reply meghan 11 hours agoparentMongoDB employee posting:The login issues are unrelated to the security incident. We notified all of our customers and users concurrently resulting in a spike in login attempts. Please try again in a few minutes if you are still having trouble logging in.Please continue to monitor our alerts page: https:&#x2F;&#x2F;www.mongodb.com&#x2F;alerts reply asdfsadfkljlkj 10 hours agorootparentI mean that totally sounds related (hah!) although I guess we all know what they mean reply cowthulhu 9 hours agorootparentThat’s a funny point, I guess I never really though of whether “related” was more correlation or causation. reply alexzeitler 12 hours agoparentprevupstream request timeout when trying to sign in reply iaresee 12 hours agorootparentOn our side, Okta is saying the auth is good.I&#x27;m trying my personal account as well and it&#x27;s telling me MFA isn&#x27;t set up (it is) and it&#x27;s making me go through the MFA setup flow again. All attempts to setup another 2FA code in 1Password or to get even an SMS code sent to my phone are failing.Edit: Personal account with a TOTP 2FA is working again now as well.This is feeling worse than they&#x27;re letting on to. reply alexzeitler 11 hours agorootparentSign in now worked once and sent me into the MFA setup loop but it failed. reply ThePowerOfFuet 11 hours agorootparentprevYou really should not be using SMS for 2FA. reply salil999 11 hours agorootparentFor my own knowledge, if the options were between using SMS for 2FA or not having 2FA at all then what is better? I&#x27;ve heard mixed things about this. reply mtremsal 11 hours agorootparentSMS 2FA is better than no MFA at all, despite the very valid concerns about SMS. It at least protects against credential stuffing and similar automated attacks. reply wyldfire 10 hours agorootparentI guess I&#x27;ve always cynically assumed that companies want my phone number to make the data they gather more valuable by making it easier to link with a unique index like a phone number. reply rezonant 8 hours agorootparentTwo things can be true at the same time. reply rezonant 8 hours agorootparentprevWell a simswap attack requires the account password, since otherwise you would not be able to receive an SMS message for the two factor part.But without two factor, only your account credentials are needed.So yeah, it&#x27;s definitely better than nothing, you are effectively forcing your opponent to social engineer your carrier, and doing that generally requires knowing the full number and usually at least your name, if not more identifying information that&#x27;s harder to get, like social security number or equivalent.Sure, TOTP or other two factor mechanisms are better because they require access to one of your authenticated devices (assuming the TOTP isn&#x27;t done by a secure enclave), but SMS two factor is definitely better than disabling two factor. reply iaresee 11 hours agorootparentprevYou really aren&#x27;t following along closely enough: all other options were failing for me. reply speedgoose 11 hours agorootparentBut you have setup SMS 2FA enabled, which is convenient this time but a big security hole. You should consider disabling it once the situation comes back to normal. reply iaresee 11 hours agorootparent> But you have setup SMS 2FA enabledNo. I did not. Nor do I now.I had a TOTP setup in 1Password and Mongo was telling me MFA _wasn&#x27;t_ set up and sending me through the MFA setup flow again.All options, SMS included, were failing in that MFA setup flow they pushed me in to.They&#x27;re back now and my existing TOTP token is generating one time use passwords that work now. reply rezonant 8 hours agorootparentI bet that&#x27;s because different parts of their stack disagreed. Obviously a two factor setup should not be acceptable when one is already in place-- if the frontend thought it wasn&#x27;t but the backend&#x2F;auth services thought it was, it could explain that. replycalyhre 12 hours agoparentprevSame here with Google SSO reply iaresee 11 hours agorootparentWe regained dashboard access around 5:15 pm ET. reply insanitybit 12 hours agoprevNice and to the point, makes it clear that this is early, explains the current scope, tells us to expect a follow up as the information makes its way to them.I like this tbh and I hope people won&#x27;t punish them for not including more info when this is clearly in the early days of investigation. reply webappguy 11 hours agoparentIt was only DETECTED on the 13th, and they suspect had been going on &#x27;for some time&#x27;. And basically not sure if user data was touched but they suspect or haven&#x27;t provided it yet buly saying&#x27;NOT&#x27;.I want answers. reply insanitybit 11 hours agorootparentYes, usually breaches take time to detect, and usually the attackers are around for a while first.I&#x27;m sure they want answers too, but they&#x27;re working on it, and this is what they have right now. reply rezonant 8 hours agorootparentprevYour options are: (A) Vendor waits until all the facts are in place and the investigation is finished or (B) Vendor tells customers as early as practical so they can take their own mitigation steps.You do not have the option of (C) Vendor should tell me about a breach they don&#x27;t yet know about. reply sigzero 10 hours agorootparentprevHow does it feel to want? They are doing their due diligence currently. reply abrookewood 7 hours agorootparentprevGive them some time. reply infamouscow 10 hours agoparentprevAgreed.For all the shit MongoDB gets, this is something that people should take a step back and recognize as very high in integrity, transparency, and trust.Other businesses should follow their lead here.I&#x27;m more inclined to do business with MongoDB because they&#x27;ve demonstrated these principles first-hand. reply rezonant 8 hours agorootparentI don&#x27;t use Atlas but I do use self hosted MongoDB, and have been pretty happy with that product. I have the impression that a lot of the dirt slung at Mongo was about unreliability and data loss of the core product early on, which (knock on wood) hasn&#x27;t been a problem for me on the small to medium scale use cases I&#x27;ve deployed it on. Seems reliability has taken a lot of positive strides over the years. reply PeterZaitsev 10 hours agoprevThis highlights risks of extreme consolidation - even if Atlas customers were not affected it is natural for them to be concerned after announcement overwhelming web site or support channels.More independent MongoDB DBaaS providers is what would offer true redundancy in this case, though it is highly restricted due to SSPL license change.Hopefully FerretDB will be successful building feasible alternative reply nextworddev 9 hours agoparent“Extreme consolidation” - wait till us-East-1 goes down reply _sword 9 hours agorootparentHappened in 2012 after a big thunderstorm and took most of the internet down reply rezonant 8 hours agorootparentprevAmazon sells it cheap compared to other regions-- it&#x27;s economically incentivized for us-east-1 to take out half of the Internet. reply PeterZaitsev 8 hours agorootparentprevYep. Though to be fair AWS provides options for multi region availability.What did not happen (yet) is complete AWS meltdown reply didip 7 hours agorootparentprevFriends don’t let friends run on us-east-1. Consolidate on us-west-1 or us-west-2 instead. reply bobnamob 4 hours agorootparentus-west-1 wouldn’t be my first choice either forreply jhardy54 10 hours agoprev> […] regularly rotate their MongoDB Atlas passwordsIs there some context I’m missing, or is this a modern security team recommending password rotation? reply richbell 8 hours agoparentRegularly rotating secrets for applications is good. Forcing users to regularly rotate their passwords is not so good. reply twisteriffic 8 hours agorootparentCorrect! NIST recommends against forcing password expiry unless the password is known to be compromised.https:&#x2F;&#x2F;pages.nist.gov&#x2F;800-63-FAQ&#x2F;#q-b05 reply ronabop 7 hours agorootparentThankfully all of my users are extreme statistical aberrations who do not re-use the same memorized password (or a variation on it) for more than one thing, ever, at all OR they diligently watch every single possible place they have ever re-used any of their memorized passwords, with the globally mandated and complied with reporting, so they can know if a password they once re-used at grandmas-cookies.blog.example.com has been compromised.The fact that all websites, servers, systems (etc.) check to see if passwords are known to be compromised (since NIST says verifiers will do that) makes things a lot easier, too. reply webappguy 11 hours agoprevJust got email alert reply rompledorph 12 hours agoprevReceived this security notice today:Hi Redacted,MongoDB is investigating a security incident involving unauthorized access to certain MongoDB corporate systems. This includes exposure of customer account metadata and contact information. At this time, we are NOT aware of any exposure to the data that customers store in MongoDB Atlas.We detected suspicious activity on Wednesday (Dec. 13th, 2023) evening US Eastern Standard Time and immediately activated our incident response process. We are still conducting an active investigation and believe that this unauthorized access has been going on for some period of time before discovery. We have also started notifying relevant authorities.What should you do next? Since we are aware that some customer account metadata and contact information was accessed, please be vigilant for social engineering and phishing attacks. If not already implemented, we encourage all customers to activate phishing-resistant multi-factor authentication (MFA) and regularly rotate passwords. MongoDB will continue to update mongodb.com&#x2F;alerts with additional information as we continue to investigate the matter.Sincerely, Lena Smart MongoDB CISO reply sampli 12 hours agoparentYeah I received the same email. Luckily I don’t actually use mongodb atlas reply 0xblinq 12 hours agoprev“Your data is safe, because we’ve never written it to disk.” reply satvikpendem 11 hours agoparent&#x2F;dev&#x2F;null is web scalehttps:&#x2F;&#x2F;youtube.com&#x2F;watch?v=b2F-DItXtZs reply hybridtupel 11 hours agorootparentLuckily already using https:&#x2F;&#x2F;devnull-as-a-service.com&#x2F; reply parkerduckworth 11 hours agorootparentprevDoes &#x2F;dev&#x2F;null support sharding? reply belter 11 hours agoparentprevAsked 11 years ago and still going strong... \"To what extent are &#x27;lost data&#x27; criticisms still valid of MongoDB?\" - https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;10560834&#x2F;to-what-extent-... reply insanitybit 11 hours agorootparentHN users would rather meme than read. reply dgellow 11 hours agorootparentprevIsn’t mongodb data losses commonly referred related to their use of fsync()? From what I vaguely remember they call fsync() every 100ms or so and just assume everything went fine, resulting in potential data loss. reply Too 1 hour agorootparentIt all depends on your writeConcern setting. This option is super critical to understand when deploying an MongoDb. Older versions had defaults that were more optimized for availability than consistency.Even so, not flushing each write is not as bad as it sounds, if you have a 3-node replicaset and your w-parameter is set to majority (default), it means at least 2 servers have the write in memory. It would take both of them crashing at the same time for the unflushed write to be lost.The idea is that MongoDB allows you to choose which corner of the CAP triangle you want, if you chose AP, that’s your decision. The defaults can of course be argued and I believe it’s been gradually moving over to more and more C for each version. Nowadays the journal does get flushed as next comment described. reply winrid 3 hours agorootparentprevNo. The default write concern as of version 5 is \"majority\" which \"Requests acknowledgment that write operations have been durably committed to the calculated majority of the data-bearing voting members\" (as long as writeConcernMajorityJournalDefault is true which is the default).So fsync is called on every write. reply Salgat 10 hours agorootparentprevYep, Jepsen has not only confirmed but later reconfirmed that MongoDB has for many years been on par with other NoSQL databases when it comes to transaction guarantees and data consistency. reply belter 10 hours agorootparentEr...no....\"Jepsen Disputes MongoDB’s Data Consistency Claims\" - https:&#x2F;&#x2F;www.infoq.com&#x2F;news&#x2F;2020&#x2F;05&#x2F;Jepsen-MongoDB-4-2-6&#x2F; reply fortani 10 hours agorootparentAlso, \"2020-05-26: MongoDB identified a bug in the transaction retry mechanism [2] which they believe was responsible for the anomalies observed in this report; a patch is scheduled for 4.2.8.\" [1][1] https:&#x2F;&#x2F;jepsen.io&#x2F;analyses&#x2F;mongodb-4.2.6[2] https:&#x2F;&#x2F;jira.mongodb.org&#x2F;browse&#x2F;SERVER-48307 reply Salgat 10 hours agorootparentprevThose same issues exist in most NoSQL databases. If you&#x27;re going to avoid MongoDB for data safety reasons, you should just go straight to SQL. reply sigzero 8 hours agorootparentprevThat is 3 years old. reply webappguy 11 hours agoparentprevMongo has made huge improvements tbf, but this is funny reply goenning 11 hours agoprevI never used&#x2F;tried MongoDB, what are the reasons people choose MongoDB over other DBs? reply rglover 9 hours agoparent- Highly-flexible. Because you&#x27;re not developing against a schema, you can, for example, retool a feature and its data quickly without having to stress about migrations. A big advantage for a startup looking to move fast.- Queries look more like application code so you&#x27;re not wasting mental cycles and time trying to translate an idea into a SQL query. From experience, this leads to less-fragile queries.- Little to no concern over injection attacks (you have to go out of your way to create potential for them).- Easier to write non-trivial queries than with SQL (IMO).- Type-casting data can be done in code as opposed to with SQL you have to use inline, platform-specific functions like field_name::timestamp.- A single source of truth for how to query and develop with it (with SQL, you&#x27;re almost always developing against a flavor of it).- Scales reasonably well (and easily) for a majority of use cases.- No room for dogmatic fervor&#x2F;confusion around a specific variety of MongoDB as there&#x27;s only one variety. reply risson 4 hours agorootparentSo basically nothing Django and a postures db can&#x27;t do. reply djrobstep 9 hours agorootparentprev> Because you&#x27;re not developing against a schema, you can, for example, retool a feature and its data quickly without having to stress about migrations. A big advantage for a startup looking to move fast.Why wouldn’t you need to worry about migrations without developing against a schema? You’ll need to worry more about migrations because your data will be more messy. reply winrid 8 hours agorootparentIt could be rephrased as \"worry about them later\" :P gotta get those returns on the VC money and pawn those issues onto the next team in 7yrs :) reply rglover 8 hours agorootparentNot necessarily. If you&#x27;re utterly careless, sure. A MongoDB migration is far less of a headache than a SQL one (you&#x27;re just writing code to map&#x2F;replace values). With SQL, you have to be frustratingly surgical about everything which can slow momentum to a crawl (read: punishment for mistakes in the migration is far worse than with MongoDB in my experience). reply winrid 6 hours agorootparentI completely agree! Kind of preaching to the choir :) reply rglover 8 hours agorootparentprev> Why wouldn’t you need to worry about migrations without developing against a schema? You’ll need to worry more about migrations because your data will be more messy.If you&#x27;re careless with your data, yes. \"With great power comes great responsibility.\" reply yawaramin 6 hours agorootparentBeing careful with my data is exactly why I use a strongly typed RDBMS in the first place. reply 010101010101 11 hours agoparentprevIt was an early player when everyone thought NoSQL document databases solved every problem. reply jtriangle 11 hours agorootparentThey did solve many problems, and then they caused many more problems...At first at least, haven&#x27;t checked in on that in awhile reply throwawaaarrgh 10 hours agorootparentprevAnd now everyone knows RDBMS solves every problem. Especially when it&#x27;s SQLite. reply bossyTeacher 11 hours agoparentprevMongo is the main nosql choice. Mongo is great if you think a flexible schema is good. Mongo is not great if you think a flexible schema is bad. That sums it up reply iLoveOncall 11 hours agorootparentThis is too reductive, you can essentially have flexible schemas with most modern relational databases and without the downsides of document-based DBs.In 99% of the cases, even if you need a flexible schema, PostgreSQL will remain the best choice. reply pleoxy 9 hours agorootparentUnless it&#x27;s not. reply tgv 11 hours agoparentprevI use it on-prem (well, on a VPS). It stores JSON documents, and it&#x27;s easy to work with. If your data looks like a tree, it works pretty well, also for large documents. If you depend on relations between documents, you&#x27;re better off with an SQL database, but note that for many cases --I&#x27;d say practically all mundane cases-- there&#x27;s really no need for relations the SQL way. MongoDB also does relations, but a bit more convoluted. reply cpursley 9 hours agorootparentPostgres does all that plus 100x. reply winrid 8 hours agorootparentBut the horizontal scaling is easier with Mongo than Citus. reply yawaramin 6 hours agorootparentBut you don&#x27;t need to horizontally scale if you use a beefy Postgres instance. Horizontal scaling is a problem created by using an inefficient DB in the first place. reply winrid 6 hours agorootparentI have DB clusters with masters with a terrabyte of ram. Going beyond that is a PITA with warming up cache, backups, and so on. There is a reason there&#x27;s a huge industry for shared databases.Also, query for query, Mongo isn&#x27;t going to be that much slower than PG, and faster for some usage patterns... replysalil999 11 hours agoparentprevIt&#x27;s pretty easy to start with. MQL is also pretty easy to understand + MongoDB kinda makes it fun.Note: I work at MongoDB reply floydnoel 10 hours agorootparentAnd Atlas has a free tier! It&#x27;s been powering my site (https:&#x2F;&#x2F;bongo.to) for years for a total price of $0. Incredible! reply webappguy 11 hours agorootparentprevWhat&#x27;s the update internally here? How long this been going on for? Any juice? reply Jonovono 11 hours agoparentprevIt&#x27;s a really great alternative to firebase for mobile apps. Works pretty nicely with Realm so you get offline first db with powerful syncing. All the benefits of realm on the edge device with the power of the mongo platform. I dismissed mongo atlas for years because \"mongo\", until I finally gave it a chance. Overall been pretty pleased. reply kagevf 10 hours agorootparent> It&#x27;s a really great alternative to firebase for mobile apps.Isn&#x27;t firebase built on top of mongoDb? reply endisneigh 8 hours agorootparentNo reply webappguy 11 hours agoparentprevEasy, flexible scheme nosql, plenty of baked in features. Has it&#x27;s place, and many times when it would not be a good choice too. reply insanitybit 11 hours agoparentprevEnterprise support, lots of documentation, does what it says it does. reply sgift 11 hours agoparentprevnext [10 more] [flagged] salil999 11 hours agorootparentI see this Jepsen link posted all the time. People: PLEASE don&#x27;t use outdated software. MongoDB has made mistakes and they are public about their data issues on https:&#x2F;&#x2F;www.mongodb.com&#x2F;alerts. MongoDB 4.2.6 is old and I believe it&#x27;s approaching EoL based on https:&#x2F;&#x2F;www.mongodb.com&#x2F;support-policy&#x2F;lifecyclesI&#x27;m not going to push for you to use MongoDB but am merely trying to provide some context around that Jepsen analysis. reply sgift 10 hours agorootparentThat&#x27;s why I&#x27;ve added the last part. Mongodb highlights old Jepsen analysis&#x27; on their page (https:&#x2F;&#x2F;www.mongodb.com&#x2F;jepsen), but they never got around to ask them for another analysis to show things are so much better with MongoDB 5 or 6? Yeah. Sure. People are free to believe whatever they want, I&#x27;ll continue to highlight the best info available. reply lolinder 11 hours agorootparentprevBased on that lifecycle doc, the 4.2 line is already EOL, and 4.4 will be soon. reply insanitybit 11 hours agorootparentprev> That they haven&#x27;t paid for a thorough follow-up analysis after their supposed fix is all one needs to knowAs much fun as Jepsen is, I&#x27;d probably not follow up with a company that turned my product into a mockery. I enjoy the hell out of reading that report as an outsider, and I personally would be a repeat customer, but I can see how a company might not love the writeup. reply sgift 10 hours agorootparentSure, but to me that just looks like they have no faith in the supposed quality of their product. If they really fixed MongoDB there&#x27;s nothing to fear. Aphyr is harsh, but fair. reply insanitybit 10 hours agorootparentAgain, I can see why they would not be interested in engaging again. You can think that it&#x27;s because they&#x27;re afraid, but they also may have just really disliked the service they paid for. reply sigzero 11 hours agorootparentprevSo nothing has changed in the 3 years since that article? reply chx 11 hours agorootparentI am not sure what&#x27;s going on with Jepsen any more.https:&#x2F;&#x2F;jepsen.io&#x2F;analysesthere were zero done in 2021, two in early 2022 and even the footer copyright say 2022. reply sgift 10 hours agorootparentaphyr seems to still work on it, so probably just not that many companies who want to pay to get told the truth anymore: https:&#x2F;&#x2F;github.com&#x2F;jepsen-io&#x2F;jepsen replycpursley 9 hours agoprevWhy are people still choosing Mongo over Postgres these days? If there&#x27;s something I&#x27;m missing, I&#x27;m genuinely curious as I&#x27;m not against json data and frequency use jsonb tables in Postgres. reply godzillabrennus 8 hours agoparentPeople use MongoDB because it’s easy to get started. It does “db stuff” and “authentication”. I’ve given up trying to fight the trend. I just recognize immediately when it is used early on that the devs are still operating with training wheels on. reply winrid 8 hours agorootparentSometimes this is the case but not always... It&#x27;s nice to just work with objects in some languages... for some projects. That&#x27;s engineering - picking trade offs :) reply superduperer 12 hours agoprevAre they doing well? Seems like the hype has kind of died down. reply bytearray 11 hours agoparentYeah, as a company they pretty much dominate the NoSQL space. 1B+&#x2F;year in revenue and that market is still growing at like 30ish% YoY or so. reply skatanski 11 hours agoparentprevRecent 7.0.0 version has dropped old and introduced quite broken new query planner. Caused a lot of our queries to miss. We’ve had the displeasure to work with the support on multiple related issues. reply baq 10 hours agoparentprevThe hype died but the tool is almost mature now and quite useful, plenty of paying enterprise customers who fly low but have fat wallets. I’d give it a few more years to be a primary data store, but it’ll do if you want a horizontally scalable, capable and performant document database to give some breathing room to the primary SQL cluster.For now, there are way too many critical issues found late in the release cycle. reply WJW 12 hours agoparentprevThey&#x27;re apparently still growing quite rapidly, though the company is not yet profitable. reply superduperer 11 hours agorootparentnext [9 more] [flagged] chrisco255 10 hours agorootparentJust because you don&#x27;t like something or it isn&#x27;t favored in the HN diaspora does not mean it is an unsuccessful product. There is a great big world outside of your bubble. reply WJW 11 hours agorootparentprevThey state these things in their quarterly filings with the SEC, in which to my knowledge it is not legal to knowingly misrepresent facts. If you have actual proof that MongoDBs auditors are lying to the SEC, you can probably get a pretty good whistleblower reward or at the very least make a ton of money selling this money to hedge funds specializing in shorting failing companies. reply superduperer 11 hours agorootparentThe SEC listings don’t contain real numbers about who is using the software. They can claim a bsbillion people use it as long as they can launder investor money into fake usage (like substack does) These numbers support my claim. If they had REALLY been growing they’d be a huge company right now, not having to pay people to use there products reply rubege 9 hours agorootparentThey do contain their customer count - quick google search says it’s over 46,000 now which was surprising to me. reply bushbaba 11 hours agorootparentprevThey are growing revenue which can be possible without growing adoption reply lolinder 11 hours agorootparentprevWhy come ask a question if you apparently have inside information that contradicts the answers you get? reply superduperer 11 hours agorootparentMy “inside information” is just basic knowledge of the software industry. If MongoDB is growing is like claiming Morbius is a good movie. It’s just silly. Go ahead disagree with be, but it’s kinda silly. reply insanitybit 11 hours agorootparentFeel free to contact the SEC. replywg0 12 hours agoprevIrrelevant but curious if MongoDB is still being picked up for Greenfield projects given it&#x27;s licensing. reply ranting-moth 12 hours agoparentTheir license \"is to require that enhancements to MongoDB be released to the community.\"I think it only hurts people who want to freeride the project and extend it for selfish personal gains. That&#x27;s OK by me. reply peterfarkas 6 hours agorootparentAnyone can provide Postgres, MySQL or other open source databases as a service.For this reason, there are many providers to choose from, and there is a healthy amount of innovation and competition in the space. Prices are set by market and demand, as it should be.And then there is MongoDB where only a handful of providers could negotiate a license, and the price is set by MongoDB Inc.In my opinion this is by no means \"fine\" from a user perspective as we are talking about database software.If anyone did freeriding, it is MongoDB Inc. who chose to freeride on the open source community for marketing purposes, before switching to SSPL. reply PeterZaitsev 10 hours agorootparentprevNot really. It really designed to prevent anyone else having MongoDB DBaaS without having license from MongoDB, which it does rather successfully. reply varelaz 11 hours agorootparentprevThat&#x27;s reply to Amazon abuse of MongoDB (DocumentDB) reply PeterZaitsev 10 hours agorootparentIt is the opposite. Amazon would have released MongoDB as a service, same as they do for PostgreSQL or MySQL. As MongoDB changed license they implemented DocumentDB instead.Note AWS significantly contributes to PostgreSQL and MySQL communities (though you could always want even more) but of course does not to MongoDB. While this is fine for MongoDB Inc I think it is not great for MongoDB community at large reply pleoxy 11 hours agoparentprevNothing wrong with picking mongo if it&#x27;s a good fit for your use case. reply cpursley 9 hours agorootparentAnd what&#x27;s a good use case over Postgres jsonb? reply Thaxll 9 hours agorootparentPostgress is single master which is a huge limitation. reply cpursley 9 hours agorootparentHow so? reply Thaxll 8 hours agorootparentHow do you scale a single master out of the box? reply cpursley 4 minutes agorootparentWhat&#x27;s nice about Postgres is there&#x27;s a ton of Postgres compatible products that do scale for the 10% who actually need it. And it&#x27;s still all just Postgres &#x2F; SQL. pleoxy 9 hours agorootparentprevWhen one doesn&#x27;t want SQL for one.Nosql is a fun target to beat up on of late. But there are good, even infamous, reasons to avoid SQL. Particular if you want to accomplish flexible record queries from untrusted clients. reply cpursley 9 hours agorootparentI’ll ask again, what’s a good use case over Postgres jsonb. reply pleoxy 8 hours agorootparentAll you do is poop all over the story about postgres. I&#x27;m convinced that no use cases will convince you of anything. I&#x27;m not really looking to involve myself in a database holy war. reply cpursley 0 minutes agorootparentIs jsonb in Postgres not flexible enough? I dump external json in there all the time (like large API responses). The jsonb operators work well. And there&#x27;s an escape hatch that lets you easily convert json to a table. And importantly, you get indexes with Postgres.webappguy 11 hours agorootparentprevExactly reply PeterZaitsev 10 hours agoparentprevOh yes. By people who do not or does not care about Open Source... and these are many reply dnndev 12 hours agoparentprevWhat’s wrong with licensing? reply mananaysiempre 11 hours agorootparentMongoDB’s SSPL is neither an open source license[1] nor, most likely, a free software one[2]. Its definition of offering the licensed software as a service is so broad most Linux distributions[3–6] flat out refuse to ship MongoDB (not even in a nonfree repository or the equivalent) so as to (among other things) avoid placing the operators of their package mirrors in legal jeopardy.[1] https:&#x2F;&#x2F;blog.opensource.org&#x2F;the-sspl-is-not-an-open-source-l...[2] https:&#x2F;&#x2F;opensource.stackexchange.com&#x2F;q&#x2F;13888[3] https:&#x2F;&#x2F;bugs.debian.org&#x2F;cgi-bin&#x2F;bugreport.cgi?bug=915537[4] https:&#x2F;&#x2F;fedoraproject.org&#x2F;wiki&#x2F;Changes&#x2F;MongoDB_Removal[5] https:&#x2F;&#x2F;bugzilla.opensuse.org&#x2F;show_bug.cgi?id=1122267[6] https:&#x2F;&#x2F;lists.archlinux.org&#x2F;archives&#x2F;list&#x2F;arch-dev-public@li... reply sigzero 12 hours agorootparentprevhttps:&#x2F;&#x2F;www.mongodb.com&#x2F;licensing&#x2F;server-side-public-license...I am not sure really.\"It should be noted that the new license maintains all of the same freedoms the community has always had with MongoDB under AGPL - they are free to use, review, modify, and redistribute the source code. The only changes are additional terms that make explicit the conditions for offering a publicly available MongoDB as a service.Obviously, this new license helps our business, but it is also important for the MongoDB community. MongoDB has invested over $300M in R&D over the past decade to offer an open database for everyone, and with this change, MongoDB will continue to be able to aggressively invest in R&D to drive further innovation and value for the community.\" reply bdcravens 12 hours agorootparentprevhttps:&#x2F;&#x2F;thenewstack.io&#x2F;the-case-against-the-server-side-publ... reply forwardemail 12 hours agorootparentprevEncryption at rest is not supported in the community&#x2F;free version of MongoDB.We built an email service (IMAP support added a month ago) and wrote a WebSocket to SQLite layer to solve our encryption at rest needs for storage.See our deep dive at https:&#x2F;&#x2F;forwardemail.net&#x2F;blog&#x2F;docs&#x2F;best-quantum-safe-encrypt... for insight. reply Nextgrid 11 hours agorootparentI wonder, why would you want DB-managed encryption instead of just putting its storage directory in a LUKS-encrypted volume? reply forwardemail 11 hours agorootparentWe store each user&#x27;s individual mailbox as its own encrypted SQLite database file on an encrypted volume. Even if the volume is decrypted, mailboxes can still not be read. This is the main reason and we detail this in the link we shared.Another requirement was full text search on the mailboxes with the data itself being encrypted at rest (SQLite fit our needs for that too; not many others provide this). We have a comparison chart at https:&#x2F;&#x2F;forwardemail.net&#x2F;blog&#x2F;docs&#x2F;best-quantum-safe-encrypt.... reply PeterZaitsev 8 hours agorootparentprevNote Percona Server for MongoDB is drop-in replacement for MongoDB and supports Data at Rest Encryption, on SSPL versionhttps:&#x2F;&#x2F;docs.percona.com&#x2F;percona-server-for-mongodb&#x2F;5.0&#x2F;data... reply dnndev 12 hours agorootparentprevReally? How many open source databases do you offer? Some may say it’s not right for randos to complain when you give something away and they complain that it’s missing basics. I just happy someone else wrote most of what I need and I can extend it if needed. reply cianigga 12 hours agoprevnext [4 more] [flagged] ceejayoz 11 hours agoparentHe’s been selling consistently for years. https:&#x2F;&#x2F;finance.yahoo.com&#x2F;news&#x2F;insider-sell-mongodb-incs-pre... reply mtremsal 11 hours agoparentprevThis is almost certainly normal activity under a 10b-5 plan, meant to protect specifically against suspicion of insider trading, which is what you’re implying. reply stockocean 11 hours agoparentprevHas consistently been selling, but yeah quite a big unload https:&#x2F;&#x2F;archive.is&#x2F;aPcRF reply throwawaaarrgh 10 hours agoprevnext [2 more] [flagged] forwardemail 10 hours agoparentWe switched from MongoDB to SQLite for email; see https:&#x2F;&#x2F;forwardemail.net&#x2F;encrypted-email reply toasted-subs 10 hours agoprevAlmost decided to use MongoDB in a project for the first time.Kind of makes me unsure if it’s going to be the right choice. reply dissident_coder 7 hours agoparentIf you’re trying to solve a problem and think “I’ll use mongodb”, well now you’ve got two problems.Just pick postgres. If you have unstructured data as input, either put in the effort to create some kind of schema for it if you can or just use jsonb if you can’t. reply cpursley 9 hours agoparentprevMongo is never the right choice. Postgres is nearly always the right choice, however. reply merek 8 hours agorootparentLegitimate question, please don&#x27;t downvote.Are you basing this opinion on:- popular HN opinion- issues that Mongo experienced in its infancy- mis-modelling highly relational data on a non-relational DB, and blaming the DB for ensuing problemsOr are you basing it on extensive experience with wide range of use cases? reply clwg 1 hour agorootparentI&#x27;m of a similar opinion. I experienced all the issues of MongoDB&#x27;s infancy; it wasn&#x27;t a good time, but the mmap functionality seemed worth it at the time if you had enough memory or constrained your access patterns appropriately.Nowadays, PostgreSQL has JSON&#x2F;JSONB types, a full suite of extensions like pgvector and PostGIS, and I can scale with Citus or use it in any of the big managed clouds.From a functionality perspective, MS SQL Server makes a more compelling alternative to me simply by way of its native graph database support. reply nojvek 5 hours agorootparentprevWe started our startup on Mongo. Hit some pretty hard performance problems and eventually did a multi month long migration to Postgres (Aurora on AWS).MongoDB is only a valid choice if all you&#x27;re doing is story key document pairs. The moment you need joins or any sort of aggregations like count&#x2F;sum e.t.c - Mongo perf is horrendous. Postgres runs circles around Mongo in every way.With jsonb columns, not much is lost. SQL is a huuuuge bonus. Mongo query language is a giant pain for everyone on team to learn and manage. reply c0pium 7 hours agorootparentprevMuch like saying “no offense” doesn’t make something not offensive, saying “honest question” doesn’t make a question not disingenuous. If you find yourself typing “don’t downvote” you should consider rephrasing your question to not be worthy of downvotes.This post could just be “can you explain your experiences that have lead you to this conclusion” and we’d all be better off. replyjbverschoor 10 hours agoparentprevNo reason to use mongo imo reply donutpepperoni 10 hours agorootparentAgreed. It&#x27;s an over optimization and most problems can be solved by traditional relational databases. reply rglover 9 hours agoparentprevThe problem here is with the hosted service, not the database itself or its performance. reply yawnxyz 10 hours agoprev [–] Wow lucky I moved our data out not too long ago. Trying to login to MongoDB, I&#x27;m just getting \"server error\" now. reply KomoD 10 hours agoparent [–] \"The login issues are unrelated to the security incident.\" replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Multiple security vulnerabilities have been identified in different versions of MongoDB and its associated components.",
      "These vulnerabilities include data exposure, denial of service attacks, and privilege escalation.",
      "It is highly advised to update to the latest versions to minimize the risks associated with these vulnerabilities."
    ],
    "commentSummary": [
      "MongoDB Atlas has been a subject of discussions and debates, with criticisms about its security vulnerability in SMS two-factor authentication and MongoDB's response to a breach.",
      "There are concerns about data loss and criticisms about the advantages and drawbacks of using MongoDB as a database.",
      "MongoDB's compatibility with Realm for mobile applications, the current status of Jepsen and its analysis of databases, and licensing issues with MongoDB have also been discussed."
    ],
    "points": 240,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1702760222
  },
  {
    "id": 38664412,
    "title": "Moving from Relational Data to Events: A Guide for Transition and the Importance of Event Sourcing",
    "originLink": "https://event-driven.io/en/the_end_is_near_for_crud_data/",
    "originBody": "Hitchhiker's Guide To Moving From Relational Data To Events 2023-12-15 OSKAR DUDYCZ EVENT SOURCING Knock knock? Who’s there? It’s me, Oskar, the end is near, did you know that? Ah, you know it but don’t know how to proceed? Let’s talk about the end of the CRUD world. Let’s provide a Hitchhiker’s Guide To Moving Relational Data To Events. I hope that you know why the end is near. We’ve been trying to optimise the storage size; we’ve made some sins of overriding and losing our precious business data. Don’t worry; I already talked with Saint Peter, and he will pass us through. Those sins shall be forgiven, as we had no other choice. Yet, now we do. We can optimise for information quality instead of its size. Saint Peter, send me to his colleague, Santa Claus; you remember him? He’s making a list and checking it twice. Gonna find out who’s naughty or nice. And we’ve been naughty, oh we were! So, Santa showed me something from his list to prove it: Ordering Process Model, a blast from the past. Don’t you recognise it? Yes, it’s not super-readable. Could I zoom it in? Of course, I could, but would it really help us to understand it? We’d see better what data we keep, but only a little about what’s happening in our system. Finding processes and how they interact and pass information would be, at best, guessing. But no worries, I told you, the end is near, and it will wash away our past mistakes. In Event Sourcing Church, we’re not doing that anymore. We’re not losing business data; we keep them. We keep them as events. Events are facts about what has happened, and we store them after each operation. And we’re also making a list like Santa, but we call it Event Stream. It’s a list of everything that has happened with our record. It’s a pity, but you cannot change events, as they’re immutable. But you can add a new one in the end and fix your past mistakes. When making decisions, just like Santa, we’re reading and checking a list of events (not always twice; we’re busy, as we’re working more than one day a year). If you join our Order, you’ll find your life more peaceful. We have a clear way of behaving. We start modelling our process by discovering events: Then we find commands, so intentions to run some action. Yes, we’re always having good intentions: And we finish our mantra by defining business rules. Ok, we have a bit more, and we even have a “picture that explains everything” (per Alberto Brandolini): Sounds a bit simpler than your past mantras, isn’t it? But still, events are critical here. They tell the story and show us critical parts of the process. They’re building a shared understanding of the process between technical and business people. Yet, time is running out! The storm is here; the end is coming, so let me tell you how you can help yourself get a second life. If you’re deep into the misery of the DDD, so Database-Driven Design, you should not immediately drop all you had. You should embrace the past, do an examination of conscience and move on! What should you especially examine? 1. Look for status columns. Find what values they had; quite often, they may reflect the lifetime phases of your data. So, an order may be initiated, shipped, paid, etc. They can be transferable to events like Order Initiated, Order Shipped, Order Paid. Of course, be careful and don’t assume that they’re complete. They may be a flattened interpretation of the business process. Always consult that with someone who knows more: best with business. Ah, and remember, in Event Sourcing Church, we don’t sware. We’re not naming events as Order Created, Order Updated, Order Deleted. I told you that you should drop your past sins and start fresh! State Obsession is a big sin in our decalogue, so beware! 2. Check for dates Dates columns can tell you a lot about significant occurrences in your process’s lifetime. That speaks something if they’re significant enough to keep them as dedicated columns. Of course, CreatedDate and ModifiedDate won’t tell you much, but ShipmentDate, DeliveryDate, and OrderPlacementDate will give you better information. They can tell you both about the business lingo, confirm our assumptions we got from statuses or introduce new events. For instance: ShipmentDate would be a next clue for introducing Order Shipped event, OrderPlacementDate can suggest that Order Initiated event may be better named Order Placed, and best trigger discussion with the business if they’re actually the same thing, DeliveryDate may mean we should also introduce a new Order Delivered event. And again, talk to domain experts; they can help you be a better member of Event Sourcing Church by embracing the truth about the business process. 3. Analyse columns optionality If columns are non-nullable, then it means that you have to be always provided. Nullable that they may be either provided later (so in other operations) or that they’re optional. So, in our Ordering Process, if columns are required, then the data we keep them should also be provided in the first Order Initiated event. Remember that a single event type is not always a starting point for the stream; there may be more. 4. Search for tables with the most 1 to Many relationships At Event Sourcing Church, we believe that setting up boundaries is an essential aspect. To make our processing effective, we group our data around the business process, not the storage normalisation (as our friends from our fellow Document-Based Approach convent). To find the stream boundaries, you can start by finding tables that have 1 to Many relationships. Those that have a lot of ones are candidates for the stream types. We should also logically think if this data can live without each other. For instance, shipment can be a separate process from order, but the order line cannot live without it. Once we start discussing those boundaries, we may find more events and enrich our understanding of the process. 5. Don’t lie, introduce explicit events for import Once you distinguish all events you’re fine with and want to migrate your relational data, don’t try to cheat; don’t reuse your newly found events during import. Relational data is flattened; if you try to retrofit what happened from the final state, you will likely fail or not be precise at best. It’s better to be explicit and provide the Order Imported event with all the current states and the code to interpret it. It gives us clear information on how we got the data about its lifetime, which can be crucial for troubleshooting and diagnostics. 6. Experiment and validate Don’t be afraid to prototype and see your model in motion. Our church is forgiving! Try migrations in a safe environment, compare the result with expectations, rinse and repeat. Don’t rush things out. We wouldn’t like to lose old information but improve our future based on it. I hope this guide will help you resurrect information you have in your data. The end is near: The end of flattened data and losing business information. Better to start now. Cheers! Oskar p.s. You may also like General strategy for migrating relational data to document-based. p.s.2. Ukraine is still under brutal Russian invasion. A lot of Ukrainian people are hurt, without shelter and need help. You can help in various ways, for instance, directly helping refugees, spreading awareness, putting pressure on your local government or companies. You can also support Ukraine by donating e.g. to Red Cross, Ukraine humanitarian organisation or donate Ambulances for Ukraine. 👋 If you found this article helpful and want to get notification about the next one, subscribe to Architecture Weekly. ✉ Join over 4200 subscribers, get the best resources to boost your skills, and stay updated with Software Architecture trends! Loading... Oskar Dudycz For over 15 years, I have been creating IT systems close to the business. I started my career when StackOverflow didn't exist yet. I am a programmer, technical leader, architect. I like to create well-thought-out systems, tools and frameworks that are used in production and make people's lives easier. I believe Event Sourcing, CQRS, and in general, Event-Driven Architectures are a good foundation by which this can be achieved. A few notes on migrating storage library 2023-12-07",
    "commentLink": "https://news.ycombinator.com/item?id=38664412",
    "commentBody": "Moving from relational data to eventsHacker NewspastloginMoving from relational data to events (event-driven.io) 222 points by alexzeitler 19 hours ago| hidepastfavorite125 comments asah 17 hours ago2c: if you need PostgreSQL elsewhere in your app anyway, then store your event data in PostgreSQL + FOSS reporting tools (apache superset, metabase, etc) until you hit ~2TB. After that, decide if you need 2TB online or just need daily&#x2F;hourly summaries - if so, stick with PostgreSQL forever[1]. I have one client with 10TB+ and 1500 events per sec @ 600 bytes&#x2F;rec (80GB&#x2F;day before indexing), 2 days of detail online and the rest summarized and details moved to S3 where they can still query via Athena SQL[2]. They&#x27;re payingI love event sourcing in theory. In practice, there&#x27;s so much boilerplate necessary to add a new CRUD workflow, or to quickly and reliably roll out the types of interventions and hotfixes that early-to-mid-stage startups need to do all the time for unforeseen circumstances.The biggest pain point I had working on an event sourced system at an early stage startup was around schema changes, where changes (especially quick or unplanned) introduced something pathological in event data for some period of time that we didn&#x27;t realize was an issue until it conflicted with some change much later on.Often the discovery of these issues would come at a bad time and block something important, e.g. because of small differences in dev environment seed data and real production data, leading to temptation and&#x2F;or pressure to \"just do a quick tiny mutation\" to old events to address the problematic events from the past mistake, which realistically often just caused a different issue, because reasoning about all of the potential impacts of the change was hard.These days in early-stage land I am only interested in event sourcing for contained areas of a product where it can provide real value, rather than as a cornerstone of an entire application. reply btown 5 hours agorootparent> reasoning about all of the potential impacts of the change was hardIt&#x27;s far easier for us as humans to think \"this change will affect new data going forward\" rather than \"when I make a change in the present, it will transform all data from the past as if it had always been the case.\" Perhaps comic book writers would make good event sourcing engineers - but I digress.One of the saving graces of event sourcing is that you can spin up a parallel world where you make those changes, rerun your entire event history, and do a diff between your production derived data and your proposed production derived data as of a point in time, identifying the actual situations where pathological cases would occur. But this takes a lot of discipline, and it&#x27;s not perfect, because events don&#x27;t exist in a vacuum - they are snapshots of a human being taking an action relative to the data they saw at the time, and if you&#x27;re retconning the data they saw, it might not match the reasons they took the actions they did.A common pathological case I find is: \"Someone overrode value X to Y, now I have the ability to automate that fix - but did they mean to freeze Y for a different business reason outside the one I did? If at some time in the future it changes upstream from X to Z, should I keep the user&#x27;s intent to freeze Y or change it to Z because the freeze to Y was just because we didn&#x27;t have the fix?\"Relational approaches don&#x27;t solve this, to be sure, and in fact there&#x27;s worse tooling to have good answers to this question. But they do incentivize the discipline of talking to stakeholders before making a giant wide-scoped UPDATE on data at rest. Event sourcing&#x27;s power to retcon makes it far too easy to say \"let&#x27;s just reinterpret the history, what&#x27;s the worst that can happen?\" reply gukoff 13 hours agorootparentprevFrom your experience, where does it bring value? reply macNchz 10 hours agorootparentI liked it on an application with a complex conversion flow that could be initiated from a few different starting points with a few required steps and a mix of optional steps that might be executed in different orders. Storing the user&#x27;s profile data from each step as an event helped us model the whole process as a state machine, which made it easier to reason about this big complex thing, as well as to introspect the previous stages of a user&#x27;s journey right in the application.I&#x27;ve also thought it made sense on an application that regularly synced down data from 3rd party systems, where it wasn&#x27;t uncommon to have some kind of weird data introduced and struggle to reconcile when&#x2F;where it came from against changes made by application users on our end. Having everything as a series of events can be really awesome in that case. reply lacrimacida 13 hours agorootparentprevIm not the OP but I’d chime in: first and foremost it’s on the resume.Of course im not bashing event sourcing altogether but right now resume boosting seems to be the driving force to apply it everywhere.And this comes from my experience at my current workplace. Event sourcing has brought so much unnecesary complexity to a an older system and it’s not even implemented properly. The engineers who took the initiative padded their resumes then went on to greener pastures while leaving a giant mess behind. reply agentultra 15 hours agorootparentprevThe problem with audit logs for deriving state is that migrations are a forgetful operation. They’re great for telling you who changed what and when… but if the table lives long enough the audit logs will hold references to columns that no longer exist or data that is gone with no way to trust that it can be recovered properly.The author has another post on that site on when to avoid event sourcing. reply gopher_space 14 hours agorootparentprev> I love event sourcing in theory.I&#x27;ve never heard this term before. From a quick scan it seems like a design tool for reasoning with unfamiliar schemas but that doesn&#x27;t match the conversation. Would you mind explaining the context around its use or suggesting a link? reply btown 6 hours agorootparenthttps:&#x2F;&#x2F;martinfowler.com&#x2F;eaaDev&#x2F;EventSourcing.html reply datadeft 17 hours agoparentprevWhen a comment on HN has more merit than the article.The only problem with postgres is that inserting has some interesting scaling problems. Putting a queue between the event sources and the db is usually recommended. reply refset 16 hours agorootparent\"normalize until it hurts, denormalize until it works\" is evergreen advice for scaling both reads and writes. Synchronously enforcing referential integrity and other forms of normalized constraints is what gets expensive.Pat Helland has some really good writing on this stuff, e.g. https:&#x2F;&#x2F;pathelland.substack.com&#x2F;p&#x2F;i-am-so-glad-im-uncoordina... reply ldng 16 hours agorootparentAnd in between, at the coma, revise seriously your indexing policy and don&#x27;t hesitate to remove unused and underused index (even on foreign key if you don&#x27;t need them that much). People too often underestimate the impact of rebuilding and index on large inserts. reply refset 9 hours agorootparentAbsolutely, there&#x27;s no beating the RUM Conjecture. reply withinboredom 17 hours agorootparentprev> Putting a queue between the event sources and the db is usually recommended.Emphasis on _usually_. If your db is at 2% CPU utilization with&#x2F;without queues ... you probably don&#x27;t need a queue. reply asah 16 hours agorootparentsee my reply above - one classic case is db system maintenance. reply layer8 16 hours agorootparentprev> Putting a queue between the event sources and the db is usually recommended.That depends on the nature of the events and whether you can live with the database being out-of-date while the events are still in the queue. reply asah 16 hours agorootparentprevthanks! forgot to mention queuing (e.g. SQS), which is SUPER valuable, for example when you want to do large scale maintenance on the database (major version upgrade where the on-disk format can change) reply varelaz 14 hours agorootparentSQS has eventual consistency, you can get the same message twice on 2 different intances for example (which was often the case for my projects). I would rather suggest Amazon MQ. reply icedchai 10 hours agorootparentThis is often possible to work around by adding a UUID to the message, on the sender side. Then either handle dupes at the DB level by ignoring duplicate inserts, or using something like redis. In practice, even with other queue systems, you can wind up with dupes due to bugs, timeouts, retries, like duplicate sends when the first one actually went through but wasn&#x27;t acknowledged. I worked on systems sending thousands of messages&#x2F;second through rabbitmq, originating from various third parties, and dupes would happen often enough that we needed to work around it on the receiving \"worker\" side. reply withinboredom 9 hours agorootparentSQS is weird in that you can get the same message in Japan and Germany at the exact same time and \"race\" to process the message. It&#x27;s annoying af. I do not recommend SQS unless you are at some kind of scale (in company&#x2F;team size, not revenue) where you can deal with it properly. reply icedchai 6 hours agorootparentI used extensively at a previous company for longer running background tasks. It was simpler to use SQS than dealing with standing up our own RabbitMQ cluster. Their Amazon MQ service did not exist at the time. Our system was built to tolerate duplicates and it worked well enough. For something higher volume I&#x27;d definitely use RabbitMQ though. reply withinboredom 2 hours agorootparentA cluster! Yeah, if you have enough messages warranting a cluster, SQS might be simpler (but probably far more expensive). It&#x27;s always tradeoffs I guess. replydfee 15 hours agoparentprevIs the general idea to have a table with definition {id:uuid,created_at:timestamptz,data:jsonb}?It’s difficult to get index functionality in JSONB, especially against diverse event structures and event definitions that evolve.I guess I should become more familiar with: https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;datatype-json.html#J... reply asah 10 hours agorootparentyes re table definition.To answer your question, for indexing there&#x27;s a couple of options: - if you know which fields you want to index, use an expression index with a regular B-tree. - if you don&#x27;t know which fields you want to index, use a GIN index on the whole field.Blogpost which covers both cases: https:&#x2F;&#x2F;scalegrid.io&#x2F;blog&#x2F;using-jsonb-in-postgresql-how-to-e...That said, I generally don&#x27;t bother indexing the \"raw\" table, but instead create a parsed+summary table that breaks out the fields I want to index into &#x27;real&#x27; sql columns and summarizes the data to reduce the number of records. In particular, I use a partitioned table for the raw data which keeps the data-per-table tiny enough to fit in RAM, and \"real time\" queries just hit the latest raw table(s). For big, real-time data, I sometimes use TABLESAMPLE queries to create estimates, or triggers to do exact counting (which is what NoSQL databases do, just without the nice structure of triggers). reply dgellow 15 hours agoparentprevLet’s say I want to setup such a system, any idea where I could find a detailed write up? reply ryanjshaw 12 hours agorootparentThis is an extremely well documented postgresql event sourcing reference implementation: https:&#x2F;&#x2F;github.com&#x2F;eugene-khyst&#x2F;postgresql-event-sourcing reply NomDePlum 7 hours agorootparentSeconded as an excellent resource.My team used it as a reference point for creating an event store for the write model and separate projection based read model in Golang. If you happen to be a Java shop you could obviously use the implementation too. reply asimpletune 12 hours agoprevSomething that might be missing from these discussions is when event driven architecture is even appropriate. The short answer is if your customer did something and expects a response it&#x27;s not even driven, that&#x27;s just request&#x2F;response.Event driven is when something happens out of band. E.g. you push your code to GH, which triggered a build. In this example, you reloading the page to see that your updated code is request&#x2F;response, however that CI build that was enqueued is event driven.Hope that helps. reply move-on-by 18 hours agoprevI was a team once that strongly considered event sourcing. To me, it seemed like a solution looking for a problem. It could have worked for us, but we ended up passing on it as the benefits were not immediately clear and the risk of doing something new and the lessons learned that would come with it just didn’t seem in the best interest of the project&#x2F;company. Maybe that makes us tools for passing up a learning opportunity, but I don’t regret getting into that rabbit hole without a fox chasing us down it. reply Nextgrid 18 hours agoparentA boring, conventional system that works is a threat to a bloated engineering team who don&#x27;t have any work to do & polish their resumes with and might feel at threat of redundancy. That is the \"problem\" this solution solves. reply alecco 17 hours agoparentprevTemporal databases make a lot of sense for financial data, for example.But in most cases you can just have a normal database and store the historic changes in auxiliary tables. So the main database is kind of a materialized view. reply GartzenDeHaes 16 hours agorootparentThe traditional way to handle this is to use a GAAP style transaction&#x2F;journal and a roll-up summary table. The current state can be reconstructed from the read only transaction table and you don&#x27;t need any complex event processing system. reply theteapot 13 hours agorootparent> The current state can be reconstructed from the read only transaction table ..Isn&#x27;t that called event-sourcing? reply devjab 13 hours agoparentprevAlmost every piece of data we store in SQL would be better on a document database, but since nobody is familiar with those we keep on trucking. I don’t mind too much, I don’t even think we made the wrong choice, but it does cause us some issues with how we have to handle data model changes.I think most data storage didn’t really keep pace with how a lot of software is being build now though, and things like events and queues are what we build on top of what we have because we need it. For the most part a lot of the data relations happen outside of our databases today through various services, because that’s just how the modern IT landscape looks in many organisations. You’ll have internal master data that supports different teams in the business and interacts with 300+ different IT systems and applications in order to streamline things. With micro services it’s easy to keep the business logic and data models clean, but then you need to manage events, queues and data states as well as reliant storage. Which is just so complicated right now.I do like SQL but these days, the systems we’re building could frankly be put in a SQLite and be perfectly fine, well almost. reply audnaun252 15 hours agoprevModelling domain events is useful for describing the problem your trying to solve with the domain experts, and it should probably be left in the documentation when planning a solution.For actually implementing a system that provides an audit trail of long-lived state machines, you&#x27;re probably better off using something like Temporal.io&#x2F;durable functions which uses event sourcing internally for their persistence, and has a programming model which forces you to think about deduplication&#x2F;idempotency by adding different constraints for the code that orchestrates the functionality (workflows), vs the code that actually interacts with the real world (activities) reply DenisM 10 hours agoparentDurable functions suffer from lack of Observability tho.I’d love to hear suggestions on overcoming this issue. reply mfateev 9 hours agorootparenttemporal.io just released .NET SDK. The observability and scalability of the platform is really good.Disclaimer: I&#x27;m one of the founders of the project. reply DenisM 8 hours agorootparentWhat I meant specifically is that the current state of a workflow is stored in a format that’s opaque to any component other than the workflow itself.E.g. if I have a “shopping cart checkout” workflow and the user is not making progress, how can I can I tell which step of the workflow the user is stuck at? reply audnaun252 8 hours agorootparentThe function&#x27;s event data and current state is all stored in table storage, so you could query that - I&#x27;d expect you&#x27;d need to query an event-store-based solution in a similar way? reply mfateev 8 hours agorootparentprevEvery step of the workflow is durably recorded. So you have the full information about the exact state of each workflow. To troubleshoot, you can even download the event history and replay workflow in a debugger as many times as needed.The ease of troubleshooting is one of the frequently cited benefits of the approach.Check the UI screenshot at https:&#x2F;&#x2F;www.temporal.io&#x2F;how-it-works. replycolonwqbang 18 hours agoprevThe concept sounds interesting, but the article doesn&#x27;t do a great job of explaining how it works. How do I efficiently reconstruct the current state from the event stream? How would the event stream be modelled in the database? reply alexzeitler 18 hours agoparentThere are several talks by the author:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gG6DGmYKk4Ihttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jnDchr5eabIhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ArcypYS5XBQhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=uODSwR2CIV4He also maintains samples on GitHub:https:&#x2F;&#x2F;github.com&#x2F;oskardudycz&#x2F;EventSourcing.NetCorehttps:&#x2F;&#x2F;github.com&#x2F;oskardudycz&#x2F;EventSourcing.NodeJShttps:&#x2F;&#x2F;github.com&#x2F;oskardudycz&#x2F;EventSourcing.JVM reply mrkeen 15 hours agoparentprev> How do I efficiently reconstruct the current state from the event stream?There isn&#x27;t one &#x27;current state&#x27;. That thinking comes from centralising everything in one DB.You create different states in different systems according to different requirements. If you&#x27;re building a shopping system, with Purchases and Customers, one service could read events and produce a relational table for finance purposes. Another service could read events and produce a key-value store of customer data. A third service could power an OpenSearch service for searching over products.> How would the event stream be modelled in the database?It&#x27;s a list. If you&#x27;re using something fit-for-purpose like Kafka, then it&#x27;s multiple lists (topics, partitions, etc.). reply tiku 15 hours agoparentprevIt would make more sense to use this for certain streams that change a lot and the data is interesting enough to see what happened along the line. But that could be solved within the relational model.. reply corethree 17 hours agoparentprevTwo ways to do it.1. Use a database designed for this stuff. Google big query, Amazon redshift, clickhouse..etc. all current data is essentially a type of aggregation. Or in other words it&#x27;s equivalent to a group-by query on an event database.It makes sense right? With events I can technically rebuild the current state or the past state of the data through some aggregation query.2. Rename your relational storage and call it a caching layer that lives next to the event system. It&#x27;s functionally the same thing but won&#x27;t trigger any red flags in people who are obsessed with making everything event driven.The architecture he describes exists. It&#x27;s just massively complicated so services that utilize it usually do very targeted things. Think Google analytics, data dog, splunk... etc. Etc. reply nivertech 18 hours agoprevIt&#x27;s top-down vs bottom-up, or custom vs generic.Top-down vs bottom-up:Top-down: starting from the business domain, and then mapping an implementation onto available technologies, tools, and vendors.Bottom-up: starting from the available technologies, tools, and vendors, and thinking how to bolt up a working solution out of them.Custom vs generic:Custom: DDD, CQRS&#x2F;ES, Sagas, TBUI (Task-based&#x2F;driven UI), GraphQL, Algebraic Data Types, etc.Generic: RDBMS, CRUD, REST, ACID transactions, CDC, generic admin UIs, nocode&#x2F;lowcode, limited&#x2F;generic types, etc. reply tiku 15 hours agoprevYeah, ehh I&#x27;m just going to stick to good old fashioned relational data. reply agentultra 15 hours agoparentGood, do it until you can’t. Don’t use a hammer on a screw. reply ChicagoDave 17 hours agoprevI&#x27;m on board with event-based architectures, but this article struggles to get its point across.I would focus on the difference between data relations and business behaviors. Once you start thinking in terms of behaviors and business activities, the move away from operational relational data stores becomes much more obvious. reply 3abiton 1 hour agoparentOn an abstract level, events can be modelled as relations. reply erikpukinskis 10 hours agoprevEvent sourcing has a lot of nice properties, so I’m intrigued. But don’t you still need relations? And then how do you implement those?If the answer is “they’re all implicit in the application layer code” then that’s not really acceptable. I still need some way to query for relations, or keep relation views up to date, or something like that.I don’t mind if relations are not core to your persistence model, but they have to be implemented _somewhere_ in your data layer, and I’m not seeing any mention of that here.I have the same issue with Firestore, everyone does relations _somehow_ but it’s all just spaghetti application code which isn’t scalable. reply mdm12 9 hours agoparentIn event sourced systems, you project the event stream into read models, of which there can be many (relational, time series, etc.) If you&#x27;re familiar with functional programming, it is essentially a fold operation over the stream of events into a single state.Having worked with event sourced systems in the past, there are benefits in having a persisted explicit event history, but there is much added complexity (how do those read models actually get generated? how do you version the model? do you have snapshots of your read models?). In my experience, the additional complexity was not worth it for most contexts in which the pattern was applied... reply jstummbillig 11 hours agoprevI was not aware of event driven design until recently, but coincidentally concluded something like it, after considering the optimal data structure in an AI powered world.While it&#x27;s clear how event driven design might have been worth the trade off (assuming you were able manage the complexities and actually made use of the data) being able to query an AI with knowledge of every event that happened to your business, with will make it ubiquitous over the coming years. reply zabzonk 18 hours agoprevall the comments are negative, but the post at this time 64 upvotes - why? i&#x27;ve seen this so often on HN, but i really don&#x27;t understand it. reply lolinder 18 hours agoparentCertain topics get a lot of interest (positive and negative) based on the title alone.Event-driven isn&#x27;t quite peak hype any more, but it still gets a lot of instinctive love from a certain group of people, and a lot of instinctive hate from another. So you get a whole bunch of upvotes (but they don&#x27;t have anything substantial to say about it), then a whole bunch of negative reactions in the comments based on the title alone. And then in this case, you get a whole bunch of negative reactions from people who tried to read the article and couldn&#x27;t get past the weird tone. reply RaftPeople 12 hours agorootparentI don&#x27;t think it&#x27;s just the tone. At the start of the article, it implies relation and CRUD approaches should and will be replaced by Event Sourcing approach, but he doesn&#x27;t support that, or even provide a good sense of pros and cons. In one of his comments (comment section) he mentions that the article was supposed to be a \"how\" not \"why\", and links to a \"why\" article, but that \"why\" article also doesn&#x27;t do a good job of why with pros and cons.In summary: not a good presentation of the pros and cons which allows a person to clearly identify under what conditions this approach might be a reasonable tool.Additional note: A typical competing model, IME, is a relational model that writes business events at the same time state updates occur. reply lolinder 11 hours agorootparentIt&#x27;s definitely a bad article. I was more commenting on why there isn&#x27;t much substantial conversation here, even though there are lots of upvotes. Very few people even bothered to read it because the tone was so bizarre—I couldn&#x27;t get past it, but it&#x27;s not surprising to me that the content is low quality too. reply simonbarker87 18 hours agoparentprevHate the article enough to leave a negative comment, want to see the fall out of it and have it not drop off the front page, so stick an upvote on it as well would be my guess. I have commented on this but haven’t upvoted as it clearly a bonkers article. reply jupp0r 18 hours agoparentprevBecause you can&#x27;t downvote submissions, you can only go in and write a negative comment. Makes complete sense to me to see the effects of that with this article. reply zabzonk 16 hours agorootparentyes, i&#x27;m not denying the comments, it&#x27;s the upvotes that i don&#x27;t understand. reply jupp0r 13 hours agorootparentThere are probably some people who find the article interesting and well written or who upvote based solely on the headline without reading it. reply revskill 16 hours agoprevNo, what you need is a command queue, command event is not domain event. reply freecodyx 18 hours agoprevSounds like a junior work reply onion-soup 13 hours agoprevIT is doomed reply ulrischa 16 hours agoprevI made a php demo for a idea: a event based observer based modelling system. I.e. for game of life: https:&#x2F;&#x2F;github.com&#x2F;ulrischa&#x2F;OCell reply alecco 19 hours agoprevThis article is not good. Event Sourcing and the Relational Model are orthogonal.SQL:2011 added a lot of temporal features.Datomic is based on Datalog which even though is not relational it&#x27;s kind of the same, and has temporal support. [2][1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SQL:2011[2] https:&#x2F;&#x2F;vvvvalvalval.github.io&#x2F;posts&#x2F;2018-11-12-datomic-even...(BTW 24 points at the top of HN and no comments? Hmm) reply ithkuil 18 hours agoparentDatalog is relational in the original sense of relational algebra. reply alecco 18 hours agorootparentSure. But the point of the article is for Document or Object-Oriented. And the specific points would apply to Datalog, too.My point was you can do the equivalent of Event Sourcing with SQL and even better with Datomic.> In Event Sourcing Church, we’re not doing that anymore. We’re not losing business data; we keep them. We keep them as events. reply refset 17 hours agoparentprev> Datomic [...] has temporal supportNote it only supports \"transaction time\" (or \"system time\" per SQL:2011) but not \"valid time\" (~\"event time\") which is needed for a bitemporal data model. [1][1] https:&#x2F;&#x2F;vvvvalvalval.github.io&#x2F;posts&#x2F;2017-07-08-Datomic-this... reply cmrdporcupine 18 hours agoparentprevDatalog is definitely relational. More so than SQL.In terms of temporal data handling & relational & Datalog, it&#x27;s worth looking at Differential Datalog: https:&#x2F;&#x2F;github.com&#x2F;vmware&#x2F;differential-datalog reply hot_gril 16 hours agoparentprevYou don&#x27;t need specific temporal support for an event-oriented DB, nor would I want it. I usually design a vanilla relational schema around events regardless of which DBMS I&#x27;m using. E.g. instead of an \"order\" table with multiple states updated in-place, I&#x27;d have \"order_placed\" and \"order_filled\" where each row is an event, insert-only. reply simonbarker87 18 hours agoprevWhat on earth is this article trying to accomplish? The tone is bizarre and the underlying concept sounds horrendous to work with if you truly want to replace your static data store with it. By all means add a formal event layer on top of your existing data store but to replace it sounds madness.If that’s not what the article is proposing then for once I’m going to say it’s not a failure of my intelligence, it’s the articles fault here. reply mrkeen 15 hours agoparent> What on earth is this article trying to accomplish?Most articles explain building event-driven systems from a greenfield point of view. This article is for when you want to build an event-driven system but you already have brownfield relational data. reply corethree 17 hours agoparentprevEh. The model he describes is actually standard for analytics.And because it&#x27;s standard there are literally databases designed and optimized to do what he says. It&#x27;s not madness when it already exists and is really common.Think, redshift, snowflake, biq query, clickhouse..Additionally their already exists user interfaces and web services that already do what he says.Datadog, splunk, Google analytics... Anything related to logs, analytics and aggregation of those analytics. What he proposes actually already exists.That being said I don&#x27;t agree with the articles point to replace everything with this model. Usually these types of services target very specific use cases.I think your reaction is a bit extreme here. I don&#x27;t agree with his proposed model but I see where he&#x27;s coming from and it&#x27;s not that the model won&#x27;t work... It&#x27;s been proven to work from all the examples I gave above.The problem with it is that it&#x27;s just slower and much more complicated. But his proposal does increase the capabilities of your data.You can increase speed by having a pre-caching layer for your aggregations. Basically what was originally your static store is now a caching layer where the developer or user pre specifies an aggregation that the system should count live as the events come in as well as throwing the events into the event db. If when querying for that aggregation you get a \"cache miss\" then it hits the event layer and has to do the aggregation job live.So essentially if you build it like this you have all the capabilities and speed of your original static data store but now you have the ability to re aggregate events differently so you have MORE ways to deal with your data. It can work and it will have more features its just really really really complicated to make an entire system centered around events. Additionally theres also a boatload of extra data to deal with which is another engineering problem.That&#x27;s why when people do build these systems it&#x27;s usually centered around some business requirement that absolutely needs this ability to dynamically query and aggregate events. Logs and analytics being the two big ones. Or some service to data scientists as well.The theory behind it is attractive. All static data can be represented as a series of events. In fact static data is simply the result of a certain of aggregation query on an event database. It&#x27;s attractive to use smaller primitives in programming and build higher level abstractions through composition so this style of event driven services seems more fundamental and proper. But of course like I said there&#x27;s practical issues with it when you look past the theory such that this model is usually only applied to the specific use cases I mentioned above.So there is a failure here. Not of your intelligence. Failure of your experience.And as I side note I agree with you on the tone of the article. He&#x27;s trying to be witty but he&#x27;s trying too hard. reply hot_gril 16 hours agorootparentRelational and event-driven aren&#x27;t exclusive concepts, that&#x27;s the problem with the article. Also, it&#x27;d help to have a real example of the solution it proposes, since we all know the \"old\" way it describes is in Postgres&#x2F;MySQL&#x2F;whatever. reply AtlasBarfed 17 hours agoparentprevFour years ago I heard \"Kafka IS your database\".I thought maybe these insane people (probably parroting some tech company enterprise penetration propaganda e.g. Confluent) would have a better story, but... no.Anyway, yeah, sure, keep logs. But a lot of that article about commands and events is something that only exists if you had one ubiquitous language, system, and OS. You know, the almost literal \"seamless\" where there aren&#x27;t any seams.Sure that will probably plug into some enterprise bus and enterprise integration and enterprise ... anyway.Competent developers will understand what events to preserve and log and possibly allow retry&#x2F;repeats.Anyone who has looked at a Splunk bill will realize that just storing all the logs everywhere is very expensive, which is another way of saying \"wasteful\". But any generic enterprisey event system will basically start and end with splunk-level log aggregation and kinda-analysis. reply dgellow 15 hours agorootparentDealt with something like this when I joined a previous job years ago, Kafka was the main data store, microservices had their state in memory they would build at startup by processing their whole history of events (that was ridiculously slow for some of them). Then GDPR came in place and the whole “keep everything in Kafka forever” had to face the reality of “not allowed to keep PII for longer than 30 days” :)(Before someone suggests it, no messages weren’t encrypted, just throwing the key away wasn’t an option) reply andsbf 13 hours agorootparent> ... they would build at startup by processing their whole history of events (that was ridiculously slow for some of them)There is a basic technique to solve this, you snapshot every \"nth\" event reply jabradoodle 15 hours agorootparentprevWould be expensive but you can do a copy and replace to keep the data you need, on a new topic.If you don&#x27;t need the data, then you don&#x27;t need it. reply alephnan 16 hours agoparentprev> What on earth is this article trying to accomplishMost of these articles are for the author to promote themselves reply candiddevmike 18 hours agoprevWhere&#x27;s the hitchhikers guide to moving back to relational data after our whiz bang dev made us event driven and left for a new opportunity? reply mhd 16 hours agoparentNext to the 97 part video tutorial on how to get back from your semi-hydrated micro-frontend to something sane for your 12 person company ;) reply revskill 16 hours agorootparentTHe problem is everyone&#x27;s interpretation and implementation of micro-frontend is different. reply blowski 18 hours agoparentprevSo long, and thanks for all the eventual consistency issues reply mrkeen 14 hours agorootparentWhy not get rid of git too while you&#x27;re at it?Just store the current state of the code base. You can&#x27;t have merge conflicts without conflicting commits. reply corethree 17 hours agorootparentprevActually event driven stuff is highly consistent. Event insertion is fast as hell and all of it is timestamped and tagged with a unique Id so there&#x27;s no consistency issues.The problem is availability. You have to aggregate those events to get anything meaningful about it and aggregation can be really really slow. reply blowski 17 hours agorootparentExactly. Because the aggregation is so slow, you cache the aggregates, but then the caching layer becomes slow to invalidate, and you get eventual consistency problems. reply corethree 16 hours agorootparentI wouldn&#x27;t call that a consistency issue. That&#x27;s just lag. The aggregation is valid for a specific time point. Caches aren&#x27;t the source of truth. The source of truth remains consistent here. reply blowski 15 hours agorootparentThe event store and the cache are both part of the same system, and it&#x27;s this whole system that is \"eventually consistent\".Say I create widgets on screen 1 and they are persisted with event sourcing into Postgres. I see the list of created widgets on screen 2, loaded from a materialised view in Postgres (or Elasticsearch). The \"lag\" between it being created on screen 1 and appearing on screen 2 is the \"eventual consistency\" issue I&#x27;m referring to here, whereas I think you&#x27;re referring to the consistency only of the persistence on screen 1.I&#x27;m sure we both agree there&#x27;s no getting away from CAP theorem. Event sourcing accepts less consistency, and every part of the system needs to deal with that. reply corethree 14 hours agorootparent>The event store and the cache are both part of the same system, and it&#x27;s this whole system that is \"eventually consistent\".Then every single system of the face of the earth at a high enough level has a consistency issue. Just go to the level of the full client and backend system using web browsers. You don&#x27;t refresh the browser you of course will eventually have a \"consistency\" issue.Usually when they refer to this stuff it&#x27;s referring to the source of truth: The database. When you shard the database into two synchronizing copies, you increase the availability with a second copy but that leads to the potential for both copies to be inconsistent. reply jabradoodle 15 hours agorootparentprevIt&#x27;s hardly a cache if it&#x27;s the only way to query the data, it&#x27;s a materialized view reply corethree 14 hours agorootparentThen it&#x27;s an outdated materialized view. If you don&#x27;t refresh your view from a browser is it a consistency issue? No. Not in in the way the term is usually used. replytkiolp4 18 hours agoparentprevExactly. These kind of devs (like OP) cannot be quiet and need to constantly introduce something “cool” so that they can get a good salary raise. The moment they cannot introduce more BS, they move on to another company. The poor other “average” devs need to maintain all the crap. reply mrkeen 15 hours agoparentprevDo it like an accountant would:Throw away all invoices and receipts, and just represent each customer&#x27;s balance as a single number. When it changes, get your crayon, cross it out, and write the new number. reply jtwebman 18 hours agoparentprevHe tried at the beginning to say only when the DB gets too big should you even think about this but there are things you can do there as well. reply seanhunter 17 hours agorootparentThere is no “too big” in databases and in particular size of data is not the criterion for deciding on using something like event sourcing. It’s a really niche paradigm that is only ever going to be useful in quite unusual circumstances. Most of the time people don’t need it, and most of the time when people do it, they find their immutable event source is very inconvenient for lots of the normal things you want to do with your data, so they end up doing something like CQRS[1] (ie having a database as well). This is one of those Martin Fowler[2] type things that looks good on a whiteboard but most people would be better off avoiding most of the time.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Command_Query_Responsibility_S...[2] This Martin Fowler, https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Martin_Fowler_(software_engine... not this Martin Fowler https:&#x2F;&#x2F;metro.co.uk&#x2F;2023&#x2F;11&#x2F;06&#x2F;eastenders-star-reveals-why-m... reply Nextgrid 17 hours agorootparentprevThe way I see it, either your business domain requires querying over a large amount of data, or it doesn&#x27;t.If an application allows someone to be able to enter let&#x27;s say an order number from anywhere in the world from the last 10 years and be able to find the order, there is no magic - some server out there is going to have to scan a huge amount of data to find a match.Tricks such as indexes, partitioned tables, etc can be employed, but those tricks have nothing to do with event-sourcing and are independent of it. reply mrkeen 14 hours agorootparent> Tricks such as indexes, partitioned tables, etc can be employed, but those tricks have nothing to do with event-sourcing and are independent of it.You might want to use different tricks in different situations. Different situations means different services, and different tricks means different storage&#x2F;query technologies.So how do you get your data into three systems - and more crucially - keep them in sync? Webhooks? Triggers? Some bidirectional sync magic app that claims to beat CAP?Just use event-sourcing (append-only, disallow modification) and the multiple systems will stay in sync as long as they know how to process one more message. reply Nextgrid 14 hours agorootparentAgreed with your points but this article seems to present event-sourcing as a replacement for your database(s) and even makes claims about saving storage space, thus at least hinting at not using databases anymore. reply mrkeen 14 hours agorootparentIt&#x27;s a replacement for your source-of-truth, not your database(s). Although you&#x27;re right about the article not explicitly mentioning slurping the events back into a DB. I suspect the reason is that there are plenty of articles which explain how to event-source from greenfield, but this is the first one I&#x27;ve seen which focuses on existing brownfield relational data - see the title.> makes claims about saving storage spaceI don&#x27;t think that was the right reading about saving storage space:> We’ve been trying to optimise the storage size; we’ve made some sins of overriding and losing our precious business dataI think it&#x27;s his strawman RDBMS developer who optimised for saving storage space, and lost business data as a result. The suggested approach is:> We can optimise for information quality instead of its size. replytarruda 18 hours agoparentprevThis reminds me of https:&#x2F;&#x2F;youtu.be&#x2F;b2F-DItXtZs reply CodeCompost 17 hours agoprevDidn&#x27;t read the article but I&#x27;m in the process of eradicating Event Sourcing from a codebase and returning to the classical ACID database model. The boneheaded decisions made by our predecessors is staggering and choosing to use Event Sourcing for everything is the dumbest of them all. reply lolinder 16 hours agoparentI worked on a project where we decided that event sourcing was the way to go for a variety of legitimate business needs. We then implemented it with ACID transactions—an application-level framework writes the event to the Postgres database and in the same transaction updates all the computed views. At the scale we were working, this was totally fine performance-wise.Most people who have had bad experiences with event sourcing were actually having bad experiences with eventual consistency. All that event sourcing means is that you treat the events as the source of truth and everything else as computed from those events (and you could theoretically recompute it all at any time). Eventual consistency is an implementation detail and not a necessary one: you can implement event sourcing in a single Excel file if need be. reply capableweb 17 hours agoparentprevOk? Not sure what you want to talk about here, you probably need to give us a bit more context, especially if you even acknowledge you haven&#x27;t even opened up the article to talk about the submission itself...Sometimes, the situation when something gets created and designed, looks very different from the current situation you&#x27;re in N years later. So what might have looked like a boneheaded decision, could have been the best decision at that point.But us engineers like to lament our predecessors&#x27; code, I&#x27;m guilty of this sometimes too. But I try to remember that I don&#x27;t have the full context of how things were when the code was initially written. reply mrkeen 15 hours agorootparent> But I try to remember that I don&#x27;t have the full context of how things were when the code was initially written.Ironically, that&#x27;s what event-sourcing is for.If the facts were kept, then a better decision can be made today. reply hot_gril 16 hours agoparentprevJust beware, if you&#x27;re using Postgres or MySQL, it&#x27;s not fully ACID (specifically \"I\") unless you run xacts in serializable mode. reply politician 16 hours agoparentprevWhat are the major deficiencies of ES in that particular codebase? If you could drop some specifics in bullets that would be really helpful for me. I promise not to ambush you with apologetics. reply CodeCompost 11 hours agorootparentThis system was developed from 2008-2013, a very different time when hardware was \"cheap\" and the Cloud was not not a thing.Event Sourcing dictates that Events are never deleted which means that the data volume keeps growing and growing. There is - in this system - no way to delete old events. When I brought this up, the response was \"Just add another hard drive\". In the modern Cloud era, adding a hard drive is extremely expensive.The system uses CQRS and all events generate reports that are stored in Elasticsearch. Data is never deleted, only an extra event gets added &#x2F;saying&#x2F; it&#x27;s deleted. The data is still cached in Elasticsearch. All of it, all the data back to 2013. Added an extra 32GB of RAM just to keep up with it is ludicrously expensive.We&#x27;re in Europe. Guess what a system like this does to GDPR. Can you tell me which events I need to delete when somebody says they want to be forgotten? Yeah.I can&#x27;t delete old data. It&#x27;s impossible without collapsing the entire system like a house of cards.Finally, and this is the piece de resistance, the developers decided to develop a relational database structure ON TOP OF EVENT SOURCING. We&#x27;re talking primary keys, foreign keys, cascading and non-cascading deletes. Importing an Excel sheet of 10000 rows takes TWO WEEKS because it generates hundreds of events per Excel cell that is being read. We brought it down to 10 minutes and there is plenty of room for improvement it&#x27;s just that we have other priorities right now. Currently, simple flat \"tables\" with no foreign keys take several seconds to import (just like in a regular RDMS).Oh yeah note that this is a system that is used by 4-5 users at a time, not hundreds or thousands of users. reply xwowsersx 18 hours agoprevI was looking forward to reading this based solely on the title, but I find the writing style and tone to be quite unbearable. The forced attempt at being relatable and light-hearted comes across as patronizing and distracts from the intended message or points being conveyed. reply hot_gril 15 hours agoparentI don&#x27;t take offense to the tone, it&#x27;s just too much text and too little substance. reply bananaowl 18 hours agoprevThe architecture from hell. Hard to debug. Why didn&#x27;t my service pick up that event? Error handling. What happens with the state if a service throws an exception? Resource hog. How do I map&#x2F;reduce all these events into a state?I do like events. They go into my elk stack where I can look at pretty graphs which gives me a story of how my system behaves over time. reply mrkeen 14 hours agoparent> Why didn&#x27;t my service pick up that event?What event? If you&#x27;re not event-sourcing, you can&#x27;t even ask that question. Instead, some user interacted with the system and got a 500. Maybe you got a stack trace in the logs, but the user&#x27;s data is gone (or maybe half of it was stored).Persistent events mean you get to fix the problem and try again - no data lost.> What happens with the state if a service throws an exception?Whatever you programmed it to do. Same as any other service.> How do I map&#x2F;reduce all these events into a state?There&#x27;s no one way to store them like there is in an RDBMS. UserService listens to User events. TransactionService listens to Transaction events. SearchService listens to both. All three have different schemas. Those schemas can be thrown away and redesigned at any time without data loss.Do a bad job of map&#x2F;reducing them into a state today. Do it better tomorrow. reply ekorz 18 hours agoprevI’ve never before seen a post hit #1 here after 30 minutes with zero comments. Is that normal? reply jddj 18 hours agoparentTo give the benefit of the doubt, maybe it was an intriguing title?I didn&#x27;t personally think that the style of the writing or the content itself was particularly good, but event sourcing has an almost narcotic appeal.ES (nosql did too) has this wild ability to slip past scepticism. It feels right, I think because it milks some dopamine by feeling both simpler in a rewarding abstract sense and sufficiently (for Devs) complex in a day to day operations sense. reply alecco 18 hours agoparentprevAnd at 1 hour it&#x27;s still at the top in spite of all the negative comments. I&#x27;m assuming it got flagged by enough of us and yet it prevails. Odd. reply rockwotj 18 hours agoparentprevSomeone got around the upvote ring detection? I know there are lots of folks that claim to know how to get around it, but agreed it seems sketchy reply Tao3300 18 hours agoparentprevI&#x27;ve got nothing smart to say about databases on a Saturday reply alexzeitler 18 hours agoparentprevFunny, I had the same thought reply wrestlingmonkey 17 hours agoprevLot of negative comments so thought I should counter as I quite liked it. The article style isn’t great but I get the impression it was only ever meant to be a toe dip into one aspect of thinking about events.I’ve worked at a couple of places that have had a lot of success with EDA, DDD and microservices. I’m sure these patterns are considered by many as buzzwords but they’ve been around for a long, long time now and they can be very effective. There’s no such thing as a silver bullet but the problems these ideas look to solve I’ve experienced very often, so I don’t buy into it being a solution in search of a problem. reply 2023throwawayy 18 hours agoprev> Once you distinguish all events you’re fine with and want to migrate your relational data, don’t try to cheat; don’t put your events as small and granular. Relational data is flattened; if you try to retrofit what happened from the final state, you will likely fail or not be precise at best... what? reply mrkeen 15 hours agoparentI think I follow.The article is aimed at people who already have relational data, and want to build an event-driven system (whose events will eventually end up as relational data again downstream.)Your system A might look like:NameBalance| Michael$3.03 |You might design your system B to have the events AmountCredited{name, amount} and AmountDebited{name, amount}.You don&#x27;t know how system A ended up at its current state. That&#x27;s what&#x27;s meant by \"flattened\". When you want to \"migrate the relational data\", i.e. convert system A&#x27;s relations into events, it&#x27;s tempting to use the obvious AmountCredited{\"Michael\", $3.03} because you know it will result in Michael having the correct balance in the final system.But it&#x27;s not good to reuse AmountCredited, _because no such event actually happened_, which is why it could be called \"cheating\". If future-you looks at historical data, $3.03 won&#x27;t correspond to any real transaction that happened. Instead you should instead make a special event like AmountImported{name, amount}. reply lelanthran 14 hours agorootparentFor this example the convention in accounting is to use &#x27;balance brought forward&#x27;.It&#x27;s a real transaction that happened, and everyone knows what it means i.e. the previous ledger with this account was closed off and the new one has the balance that was there when th book was closed.Using &#x27;imported&#x27; describes what you did, but not what the intention was. reply kinddevil 14 hours agoprev [–] Question has been asked every time when someone wants to use event sourcing -- why do you want to redo the stuff that databases already did? \"Ensure your design works if scale changes by 10X or 20X, not 100x\". reply baq 14 hours agoparent [–] because the database is inconsistent and incorrect is usually the answer. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the transition from relational data to events and provides a guide for making this shift.",
      "It highlights the benefits of event sourcing, storing events after each operation, for understanding business processes.",
      "The guide advises examining status and date columns, as well as column optionality, when migrating to event sourcing, and suggests introducing explicit events for data import."
    ],
    "commentSummary": [
      "The author delves into the challenges and advantages of event sourcing in software development, including handling schema changes and the implications for historical event data.",
      "The potential limitations of relying exclusively on audit logs are also explored, along with the usage of message queuing systems like RabbitMQ and SQS.",
      "The suitability of SQL databases for contemporary software development practices is discussed, as well as various techniques and tools for event-driven design and data storage systems."
    ],
    "points": 222,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1702736838
  },
  {
    "id": 38664875,
    "title": "The Declining Nutritional Value of Crops: Causes and Solutions",
    "originLink": "https://jeroenvanbaar.substack.com/p/data-dispatch-4-the-falling-nutritional",
    "originBody": "Share this post Data dispatch #4: the falling nutritional value of crops jeroenvanbaar.substack.com Copy link Facebook Email Note Other Data dispatch #4: the falling nutritional value of crops The mineral content of wheat and rice is lower today than sixty years ago. Why is that and what does it mean for how we eat? Jeroen van Baar Dec 15, 2023 2 Share this post Data dispatch #4: the falling nutritional value of crops jeroenvanbaar.substack.com Copy link Facebook Email Note Other Share Article voiceover 1× 0:00 -8:00 Eat your vegetables! When you were little, your parents probably went to great lengths to see you munch on your greens. And even now, as adults, many of us are inundated with public health messaging around the importance of a healthy diet. What you might not know is that those vegetables were more nutritious when you were growing up than they are today. Ironically, this means that you need to eat even more of them to obtain the same amounts of essential minerals. A parent feeding their toddler vegetables. If this photo looks weird, that’s because it’s AI-generated. In dietary advice, fruits, vegetables, and grains are considered particularly important because they contain a bunch of minerals and vitamins you need for your body to function, such as iron and vitamin A. This led the U.S. Dietary Guidelines for Americans, 2020-2025 to recommend that you get 85% of your daily calories from vegetables, fruits, grains, dairy, and protein—in that order. But the nutritional value of these ingredients seems to be shrinking over time. An important data point comes from this a recent article in the International Journal of Food Sciences and Nutrition, written by a team of researchers from Coventry in the United Kingdom. They compared data on the contents of fruits and vegetables measured in three different historical periods: 1925-1939 (published in 1940), 1982-1990 (1991), and 2011-2015 (2019). When comparing the same quantities of the same foods over time, they found that the amount of sodium (Na), iron (Fe), copper (Cu), and magnesium (Mg) found in them had significantly declined between the first and the last time point. In some cases, a serving of vegetables got you 50% less of these minerals in 2019 than it would have in the 1930s. [Side bar: I had no idea that you needed to consume copper in your food, but apparently you do. It’s found in meats, nuts, and chocolate, among others.] Source Share Subscribe Why did nutritional value drop? It’s counterintuitive, but it has to do with the fact that agriculture has become much more successful since the 1960s. The first reason for this is a revolution that swept the world but remains unknown to most people today. I’m not talking about any military revolution, but about a scientific one: the so-called Green Revolution in farming. During this period (roughly 1950-1970) scientists like Norman Borlaug cross-bred crops to produce new, high-yielding dwarf varieties of staples like wheat and rice. These dwarf plants had smaller, thicker stems, which enabled them to send more energy to their fruits and carry more weight even in bad weather. Another reason—which surprised me—is climate change. As you may remember from school, plants take carbon dioxide (CO₂) out of the air and, with help from sunlight and water, turn it into carbohydrate molecules (photosynthesis). These carbohydrates make up the bulk of plant tissue. It turns out that today’s higher concentrations of CO₂ in the atmosphere, as well as rising temperatures, allow plants to ramp up photosynthesis and thereby grow faster. Many crops today simply have an easier time growing big than they would have had in the 1960s, thanks to more favorable environmental conditions. Hybrid crops and climate change, together with innovations in fertilizer and agricultural machinery, led to much larger agricultural yield (weight of harvest per hectare of land) in the second half of the 20th century. This saved the booming world population from starvation, and Green Revolution hero Borlaug rightfully got the 1970 Nobel Peace Prize for his work. The growth in yield was quite dramatic, as you can see on this graph from a 2020 paper: Trends in wheat yield (tons per hectare) and thousand kernel weight (TKW) of a long-running wheat experiment in the UK. The dashed line represents the introduction of dwarf varieties of wheat in 1968. Source However, a side-effect was that these bigger crops had a lower relative mineral content. The problem is that while dwarf varieties and increased CO₂ levels allowed wheat and rice to grow larger, the amount of nutrients they sucked up out of the soil stayed roughly the same. In other words, the balance between CO₂ and essential nutrients shifted toward CO₂, which caused crops to contain relatively more carbohydrates and relatively fewer minerals, proteins, and other good stuff. For billions of people worldwide, this change is already leading to “micronutrient malnutrition”: a shortage of vitamins and minerals needed for growth and development. As one example, the World Health Organization estimates that 42% of children under 5 years of age and 40% of pregnant women worldwide suffer from anemia due to a lack of iron, folate and/or vitamins B12 and A. A primary cause of this problem (although there are others) is the lack of these minerals in people’s diet. Remember that iron (Fe) was one of the minerals whose presence in fruits and vegetables was found to drop by 50% between 1940 and 2019 in the first study I mentioned. Whether this affects you depends largely on where you live. For low-income countries in South Asia and Sub-Saharan Africa, micronutrient malnutrition is a huge problem—and this demands a global solution. Estimated cases of anemia in children per region of the world. Source If you live in a wealthy country with a reliable food supply, it all depends on the choices you make. One interesting nugget I found in my research for this post is the idea that daily energy intake from food may actually have dropped because our lifestyles have changed.1 Turns out sitting in an office chair makes you less hungry than working in a factory all day! And since eating less food reduces your total mineral intake even more, this can cause problems if you don’t change how you balance your foods. The solution, then, is to actually follow advice like the 85% rule from the Dietary Guidelines for Americans. As science writer Bárbara Pinho points out in her excellent piece on the topic: In the UK, vegetables make up a meagre 6.3% of the average shopping basket. Keeping an eye on how the nutritional content of food changes in a changing planet is important, but returning to typical dietary guidelines still seems to be a priority. In other words, as long as you eat your recommended amount of fruits and vegetables, you will get all the nutrients you need. But as the CO₂ levels in the Earth’s atmosphere keep rising, we might end up having to eat even more greens and grains to obtain the same amount of minerals. And that, I’m afraid, presents an even bigger dinner-time challenge for young parents. Good luck! An Educated Guess is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. And if this post has been worth your time, share it with someone else to keep the newsletter going. Thank you! ~Jeroen Subscribe Share An Educated Guess 1 I also found data showing the opposite effect, so I don’t know what the right answer is about this specific point. 2 Share this post Data dispatch #4: the falling nutritional value of crops jeroenvanbaar.substack.com Copy link Facebook Email Note Other Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=38664875",
    "commentBody": "The falling nutritional value of cropsHacker NewspastloginThe falling nutritional value of crops (jeroenvanbaar.substack.com) 210 points by AnEducatedGuess 18 hours ago| hidepastfavorite137 comments reason-mr 17 hours agoIf you repeatedly harvest crops from soil without working on building it, this is what happens. Each crop progressively removes some nutrients from the soil with the result that the soil nutrients, and nutrients in the derived food gradually decay. Most petroleum&#x2F;chemically derived fertilizers do not replace such. It is a known phenomena organic farming circles. Organizations like Rodale institute are working to correct this my improving soil health - but in general we’re been on a long program of “withdrawing money from the bank account without paying in”. reply caminante 17 hours agoparent> If you repeatedly harvest crops from soil without working on building it, this is what happens.Per the article, that doesn&#x27;t appear to be a critical factor.> The problem is that while dwarf varieties and increased CO₂ levels allowed wheat and rice to grow larger, the amount of nutrients they sucked up out of the soil stayed roughly the same. Sounds like you can grow&#x2F;gather the same size apple faster, leaving less time to soak nutrients. reply hinkley 15 hours agorootparentThis is not recent news to some of us.The theoretical model put forth is this: the nutrition in fruits and seeds comes from the plant, not the ground. It’s substantially what’s been saved up all season. So when a smaller plant has bigger fruit, it doesn’t have the reserves you’d expect for such a volume of produce. Hence nutritionally anemic food.Add to this fruits and veg selected for shipping stability. Longer times to rot, and thicker skins that don’t bruise when loaded into crates. That shitty bland tomato you bought probably wasn’t even ripe when it was picked. It ripened in transit, possibly by being exposed to chemicals that boost ripening. Underripe fruits were picked before they were ready. reply caminante 14 hours agorootparent> It ripened in transit,Don&#x27;t get me started on tomatoes. We have ourselves to blame for pivoting the supply to tomato varieties with no flavor. [0]> But as growers bred tomatoes to meet those priorities, flavour gradually diminished. “Every time they bred it and tasted it, they thought, ‘that doesn’t taste so bad,&#x27;” says Tieman. “But after doing it over and over, the flavour has changed.”[0]https:&#x2F;&#x2F;chatelaine.com&#x2F;food&#x2F;trends&#x2F;tomatoes-taste-florida-re... reply hinkley 13 hours agorootparentI&#x2F;we use tomatoes because the sad fate of the tomato is the best rallying cry we have.I don’t even like tomatoes, but they piss a lot of people off.I heard an NPR interview a few years ago where a farmer was trying to do for peaches what we have done for apples - make a palette of flavors instead of the 2 we get. Those are selected for shipping as well. They are only really flavorful just before they spoil, or when baked. reply nightski 12 hours agorootparentprevTomatoes are very easy to grow in a garden and besides are more like a herb because they have basically no nutritional value at 15 calories a piece. reply kevincox 13 hours agorootparentprevThe core problem seems like you can&#x27;t see the nutritional value in the grocery store. So you can&#x27;t prefer more nutritional produce so there is no incentive for the industry to cultivate more nutritional crops.Imagine if every farm needed to test their produce for nutritional value and have nutrition labels at the store. I&#x27;m sure things would change. reply aeturnum 13 hours agorootparentprevIt&#x27;s probably both - right?Because there&#x27;s more CO₂ each individual plant will grow larger and draw up proportionally fewer nutrients. At the same time, we are also able to rotate crops more often, so whatever replenishes nutrients in soil is probably now \"covering\" a larger numbers of growth cycles. reply maxerickson 17 hours agoparentprevOf course industrial agriculture routinely applies micronutrients, so no, they are not withdrawing without paying in.Odd that you would be well informed about organic farming circles but blissfully unaware of the routine practice used by the majority of the agricultural industry. reply hinkley 15 hours agorootparentOver time, agricultural soil begins to resemble hydroponic growth medium. It’s not soil, it’s just something to hold roots and deliver water and fertizers.Which means it definitely doesn’t have much nitrifying bacteria and absolutely doesn’t have any fungi transporting minerals from deeper underground or by organically weathering sand particles. reply vram22 13 hours agorootparentYes.I keep sharing Gabe Brown&#x27;s three-part video series titled Treating the Farm as an Ecosystem, now and then, here on HN, whenever such threads come up.Some really solid practical and pragmatic stuff there, on regenerative agriculture, which, as I understand it [1], goes beyond organic farming, and is related to many of the issues talked about in this thread.[1] I had done organic gardening successfully, for a few years, some time earlier, so I have at least some practice and experience (and also a lot of reading and thinking about what I read) as the basis for my opinions of his work and those of others I mention, such as Elaine Ingham (a video by her is below too).One of her most astonishing finds &#x2F; claims is that (IIRC, I saw the video a few years ago), almost all soils anywhere on earth have more than enough nutrients for plants for many many years.She said the real issue and limitation is the lack of soil organic content and soil structure and mycorrhiza ( https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Mycorrhiza), without which even applying tons of nutrients is useless.And, Gabe has a big farm, a few thousand acres (so not small scale) in North Dakota, USA, with field crops, green manure, livestock on pasture &#x2F; prairie, etc. And is making profits from his farming operations, sustainably, even regeneratively, without government subsidies, and more than his conventionally-farming neighbors, some of whose soils are getting worse, while his get better over time, by objective measures (checked by external govt. agencies) that he mentions.Here is Part 1.Treating the Farm as an Ecosystemhttps:&#x2F;&#x2F;youtu.be&#x2F;uUmIdq0D6-A?si=bTLRoacXTGiAP-QrAnd here is the video by Elaine Ingham, The Roots of your Profits, in which she talks about the points I mentioned above, and some more relevant ones:The Roots of your Profitshttps:&#x2F;&#x2F;youtu.be&#x2F;x2H60ritjag?si=MskMBEIgTUStrWsX reply vram22 13 hours agorootparentHere is an earlier comment subthread by me, on an earlier HN thread on the same general topic, as I said I&#x27;ve done, above. It mentions Gabe, Elaine, and a few others, including Geoff Lawton, permaculture pioneer, who are doing good work in this area, with a few more details:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24827234 reply chabes 15 hours agorootparentprevIndustrial agriculture adding fertilizer to soil is simply feeding the plant. There is no attempt to actually recover a deficit taken from the soil directly. Instead the farmer calculates the seasonal fertilizer needs of growing their crop(s).If the intention was long term sustainability, focus should be on feeding the soil, not the crop. reply AndrewKemendo 17 hours agoparentprevPretty simple:Human waste never makes it back into the ecosystemSo we only extract minerals, consume them, then bury them (landfill) or put them into the ocean (wastewater)Modern humans halt the natural cycle of life in every region we inhabit reply galangalalgol 17 hours agorootparentMany treatment plants are producing a fertilizer product now. reply bluGill 16 hours agorootparentTrue, but that doesn&#x27;t get back the farms in the same quantity that nutrients left. some farms near the city get more than they need while others get very little. Most fruit in the stores (US at least) is grown in Chili - they have a great climate for this (there is lots of reason to debate this that would take books to get into, so for now lets accept this simplistic statement), but how much sewage from the US goes back to that area? Cattle produce a lot of manure, some farms sell that to local farms and it goes back to the soil (dairy farms typically do this - often they own the fields the cow feed comes from), but other cattle end up on giant feedlots where there are not enough farms around to take the generated manure and so the local fields end up over fertilized while more distance farms don&#x27;t.Note that this waste is a bio hazard. So the obvious, just send the waste back to the fields in the empty truck cannot work. Once a tank has been used for waste you cannot use it for food again. Thus you end up with twice the trucks gong back and forth if you try this - and this in turn presents more CO2. reply nuc1e0n 13 hours agorootparentNot being able to return sewage to where food is grown is a consequence of shipping food long distances. This also causes more CO2 emissions. I think we need to grow food more close to our population centres. reply AndrewKemendo 17 hours agorootparentprevWhich is great and isn’t necessarily new but it’s too little too lateWe have to actually restructure society to get to any kind of widespread health reply galangalalgol 17 hours agorootparentI love change in general, but when I hear talk about architecting society I get mental images of mass graves. I just made a post advocating climate engineering in addition to net neutral carbon, but the potential unintended consequences of planet scale climate fiddling scare me far less than trying to plan societal changes that will counter human nature even just a bit. reply contrarian1234 17 hours agoparentprevwhat is nutritious to a human and to a plant is obviously fundamentally differentSo drawing a straight line between soil nutrients and food nutrients is simplistic reply CharlieDigital 17 hours agorootparentI think the point is that nutrients like trace minerals have to come from somewhere. And if they are lacking in the soil, they will be lacking in the plant.Molecules that would be synthesized by the plant from trace compounds or pathways that require trace compounds would be lacking in the plant if it&#x27;s lacking in the soil.So if the soil is lacking in those trace compounds, there will be a gap in the output nutrients when we consume the plant or vegetable as food. This goes up the chain and is a reason why grass fed livestock is higher in Omega 3 fatty acids due to the differences in the feedstock.Same as how farmed salmon don&#x27;t have orange flesh because they do not consume the same food sources as wild salmon. So their flesh lacks the molecular compounds that result in the natural pigmentation that results from consuming organisms that consume krill.Commercial fertilizers replenish the compounds that are required for the rapid cellular growth of the plant, but do not sufficiently replenish the trace compounds that would be in the soil from natural cycles of growth, decay, and recovery. There is also the factor of biodiversity as different plants, animals, and fungi will enrich the soil composition in different ways through their natural lifecycle which does not occur in monoculture industrial farming.(Not critiquing modern monoculture industrial farming as its efficiency has allowed for huge growth in the human population, but it&#x27;s clear why it would result in less nutrients in the output over time as the soil itself becomes depleted) reply contrarian1234 16 hours agorootparentSure, lack of nutrients will stunt the plant in some way, and will reduce the production of some plant compounds. But the original comment&#x27;s logic is just too simplistic. You can&#x27;t then safely jump to the conclusion that the lack of nutritional value in plants is primarily due to the reduction in these plant compoundsThe main drivers could very easily be due to a variety of other factors. Like the sibling comment says, it could for instance be changes in agricultural practices (like the plants growing faster) b&#x2F;c farmers naturally optimize for volume and not nutritional value per-kg or per-calorieThere are just a million other variables at play - and the nutrients in the soil aren&#x27;t intrinsically the limiting factor for the nutritional of plants - b&#x2F;c what&#x27;s nutritional is fundamentally different reply BiteCode_dev 17 hours agorootparentprevNo, that&#x27;s understanding you don&#x27;t replace a complex system with 1000 variables with a solution of 10 variables.Soil are complete ecosystems. Plants are complex organisms.You can dumb it down a lot and get very good result for some time, but eventually what made it anti-fragile, à la nassim taleb, will run out. And your alternative is not anti-fragile. reply hinkley 15 hours agorootparent> 10 variables.That’s generous. Someone’s in the holiday spirit. reply Sharlin 17 hours agoparentprev> [I]n general we’re been on a long program of “withdrawing money from the bank account without paying in”.Yes, in general indeed. Essentially every major sustainability problem on the planet is caused by people refusing to acknowledge that there are no free lunches, and no free loans either. reply kevmo 16 hours agoparentprevThis reminds me of the _Les Miserables_&#x27;s lengthy digression on sewers, which begins thusly:Paris casts twenty-five millions yearly into the water. And this without metaphor. How, and in what manner? Day and night. With what object? With no object. With what intention? With no intention. Why? For no reason. By means of what organ? By means of its intestine. What is its intestine? The sewer.Twenty-five millions is the most moderate approximative figure which the valuations of special science have set upon it.Science, after having long groped about, now knows that the most fecundating and the most efficacious of fertilizers is human manure. The Chinese, let us confess it to our shame, knew it before us. Not a Chinese peasant—it is Eckberg who says this,—goes to town without bringing back with him, at the two extremities of his bamboo pole, two full buckets of what we designate as filth. Thanks to human dung, the earth in China is still as young as in the days of Abraham. Chinese wheat yields a hundred fold of the seed. There is no guano comparable in fertility with the detritus of a capital. A great city is the most mighty of dung-makers. Certain success would attend the experiment of employing the city to manure the plain. If our gold is manure, our manure, on the other hand, is gold.What is done with this golden manure? It is swept into the abyss. reply tekla 17 hours agoparentprev> Most petroleum&#x2F;chemically derived fertilizers do not replace suchThose fertilizers are also responsible for saving the lives of millions of people.Perhaps we should go back to nightsoil instead. reply BiteCode_dev 17 hours agorootparentTwo things can be true. reply Log_out_ 16 hours agoparentprevAscientific Nonsense. Trace elements or the lack of them are detectable via drill core samples, drone footage and satellite footage. And in the harvest itself.And they are routinely re-added while working on the fields. All it would have taken is a visit to a online fertilizer storefront for farmers.The problem is the rising efficiency of photosynthesis with higher carbondioxid in the air. Means, faster growth, more sugar, less everything else.In addition I want to express my deep disgust to the \"blood and soil\" nazi ideology most back to natural farming people push as soon as you drill down on the consequences. reply tchaffee 14 hours agorootparentCalm down reply graphe 17 hours agoparentprevWon&#x27;t matter once the world gets warmer. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chernozem will get these frozen black soil zones. If Ukraine joins the EU the whole of Europe will lose their farming competition and nobody will be able to grow against Ukraine. reply _Microft 17 hours agorootparent> Won&#x27;t matter once the world gets warmer. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chernozem will get these frozen black soil zones. If Ukraine joins the EU the whole of Europe will lose their farming competition and nobody will be able to grow against Ukraine.That&#x27;s a strange argument to make. Once these fertile soils become usable it is preferrable to have these resources inside the EU, not outside of it. And if you&#x27;re worried about competition in the agricultural sector inside the of EU, then you could as well be concerned about a few other countries in the EU right now. reply graphe 17 hours agorootparentFor the sake of the EU yes. For the sake of farmers in the EU no. They&#x27;re lobbying against it. reply lostlogin 14 hours agorootparentprevUkraine is going to be a massive minefield for decades by the looks of it. reply mikrotikker 11 hours agorootparentThey&#x27;re working hard on solutions. AI powered drone discovery is one such method. I&#x27;m sure you&#x27;ve seen the vids of Ukrainian farmers making their tractors remote control, to run rollers in front to find mines. reply waihtis 15 hours agorootparentprevspeculative question, how much weight do you think this carries in the EU zeal to get Ukraine in as a member reply graphe 15 hours agorootparentA lot.https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;world&#x2F;2023&#x2F;12&#x2F;15&#x2F;ukraine-memb... https:&#x2F;&#x2F;www.reuters.com&#x2F;markets&#x2F;commodities&#x2F;ukraine-says-pol... It will probably destroy all non Ukrainian farms for grain and might even do it for specialty foods because it&#x27;s hard to complete with (guessing) 40% black soil verus 1% or less. They can grow for a very long time with no need for crop rotation or fertilization. reply waihtis 14 hours agorootparentInteresting, many thanks. reply scythe 15 hours agorootparentprevAs a Hacker News thread goes longer, the probability of someone bringing up Ukraine approaches 1. Anyway, the map on Wikipedia seems to belie this notion:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chernozem#&#x2F;media&#x2F;File:Chernoze... reply risyachka 17 hours agorootparentprevYou mean the competition will finally be motivated to invest in research and improve what they have now reply graphe 17 hours agorootparentNo, you can&#x27;t beat Ukraine. It&#x27;s impossible. Subsidies are the only competition they&#x27;ll get and that costs the country more than it helps. reply csdvrx 16 hours agorootparentThe map shows much of it is in Russia. Can&#x27;t it produce more cheaply using the large surface available when the world gets warmer?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chernozem?useskin=vector#&#x2F;medi...(and wouldn&#x27;t that be an incentive for Russia and Canada to have the world warm up? reply graphe 15 hours agorootparentRussia and Canada will gain more human habitable land from global warming. reply MichaelZuo 13 hours agorootparentSo why did you say &#x27;No, you can&#x27;t beat Ukraine&#x27;?When clearly at least one other country has even more black soil? reply graphe 13 hours agorootparentWhich country? The depth of black soil in other places is incomparable with Ukraine&#x27;s. It&#x27;s like comparing the marianas trench to the Caribbean. The total landmass might be lower but the total volume in Ukraine is leagues larger.>Chernozem layer thickness may vary widely, from several centimetres up to 1.5 metres (60 inches) in Ukraine reply MichaelZuo 12 hours agorootparent> The depth of black soil in other places is incomparable with Ukraine&#x27;s.How do you know it&#x27;s incomparable?That statement would still hold for other countries with layer thicknesses in the 1m to 1.5m range. Which seems entirely comparable considering the area covered is multiple times greater. replywouldbecouldbe 18 hours agoprevNeeds a lot more arguments to tie that to a rising iron deficiency, or any rising deficiency.There have been many changes in the consumption pattern in the last century.Many fruits & vegetables where not available year round, so even if they have less mirconutrients, orange, bananas, strawberries, etc. used to not be consumed as much as now.There&#x27;s also been a huge drop in the consumption of organ meats, which contain much more vitamin and minerals then most vegetables (with the exception of vitamin c). reply crazygringo 14 hours agoparentExactly. Does it really matter if fresh pineapples or mangoes have half as many of certain vitamins, if we&#x27;re eating 30x as many of them than were available 40 years ago, when we were lucky to eat them more than once a year?And it&#x27;s also certainly not like the ways in which we used to can and&#x2F;or boil vegetables was great at preserving vitamins either.We currently have unprecedented variety of produce. Even if one item is lower in a vitamin that it didn&#x27;t have much of to begin with, now you get to eat something else that naturally has tons more. reply smolder 2 hours agorootparentYes, it matters. Is it unsurmountable? No, that&#x27;s different. reply dehrmann 15 hours agoparentprevI&#x27;m also curious what widespread deficiencies there are. reply oidar 18 hours agoprevThe actual paper:Historical changes in the mineral content of fruit and vegetables in the UK from 1940 to 2019: a concern for human nutrition and agriculturehttps:&#x2F;&#x2F;www.tandfonline.com&#x2F;doi&#x2F;epdf&#x2F;10.1080&#x2F;09637486.2021.1... reply jimnotgym 18 hours agoprevI&#x27;m not sure the article supports what the headline says.There are not half as many carbs in wheat and potatoes as there were. I don&#x27;t understand nutritional value to mean &#x27;amount of trace vitamins&#x27;, and neither does wikipedia. Is this a fair definitionhttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Nutritional_value reply JumpCrisscross 18 hours agoparentThey&#x27;re talking about \"the amount of sodium (Na), iron (Fe), copper (Cu), and magnesium (Mg) found in [crops] ha[ving] significantly declined.\" The significant ones are iron and magnesium.\"Almost half (48%) of the US population consumed less than the required amount of magnesium from food in 2005-2006\" [1]. Iron deficiency is less prevalent, peaking among pregnant women around 25% [2]. I couldn&#x27;t find data from 1940 for either. My iron is indirectly tested for (hemoglobin), but I couldn&#x27;t find any recent bloodwork for magnesium.Agree, broadly, that the article is a nothingburger. The real story might be the lack of testing for magnesium deficiency.[1] https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;22364157&#x2F;[2] https:&#x2F;&#x2F;lpi.oregonstate.edu&#x2F;mic&#x2F;micronutrient-inadequacies&#x2F;o... reply hash872 16 hours agorootparentIn a previous similar discussion on HN a few years ago, someone made the same point- and lots of people said that supplementing magnesium permanently changed their mental state for the better. So I started supplementing with magnesium-threonate, and it low-key changed my life. Less anxiety and depression, and I swear that my long distance vision sharpened up a bit. Anyways, seeing as reading the HN comments changed my life for the better a little bit, I always try to give back and tell people my experience with supplementing magnesium reply jimnotgym 14 hours agorootparentDid you choose a particular brand? I don&#x27;t trust the supplement industry! reply efields 12 hours agorootparentIf New Chapter makes what you’re looking for, they’re one of the more reputable brands. reply CydeWeys 17 hours agorootparentprevFortunately these are really easy to supplement&#x2F;fortify back into foods. Plus it&#x27;s not like meat has any less of them these days, so it&#x27;ll mostly affect vegans. reply aantix 17 hours agorootparentA steak has 58mg of Magnesium.The rda for a male is 400+mg.Unless you’re eating tons of pumpkin seeds everyday, everyone is missing the mark.And magnesium deficiency is implicated in depression, anxiety, etc. reply orev 18 hours agoparentprevI do not recall “carbs” ever being used to mean “nutritional value”. In fact it’s almost always the opposite, with “empty carbs” (i.e. foods that contain carbs and almost no other vitamins, etc.) being the primary target of campaigns telling people to avoid them. If anything, carb-heavy foods would benefit from having lower carbs, since it would increase the relative amounts of actually healthy stuff in them.Focusing on carbs leads to situations where people may be overweight, but also malnourished, which is increasingly common in poor areas. reply jimnotgym 14 hours agorootparentI didn&#x27;t say carbs meant nutritional value. However when a product containing mostly carbs is said to have half the nutritional value it used to hand, one might reasonably assume that the components of its nutritional makeup had reduced in proportion. The headline is clickbait. What they meant was that some of the micronutrients were there in a lower proportion. That is a very different story reply throwup238 17 hours agorootparentprevThey have to be qualified as “empty carbs” because fiber is a complex carbohydrate and that’s pretty crucial to gut microbiome health and blood sugar regulation. reply orev 16 hours agorootparentThe presence of fiber alone doesn’t necessarily offer these kinds of health benefits. It largely has to do with the structure of the fiber and if it’s affecting the speed of digestion of the food. A smoothie is far less healthy than the unprocessed fruit (assuming nothing else is added to the smoothie) simply because the act of blending the fruit liberates the sugars from inside the cells, allowing faster absorption (and resulting in insulin spikes&#x2F;crashes).Any fiber is still better than none, but it’s not just a matter of amounts. reply datameta 17 hours agorootparentprevAfaik empty carbs moreso refers to starch or sugar containing foods that otherwise bring little to the table in terms of vitamins, minerals, etc. Especialy high glycemic index food items. reply tyrfing 17 hours agorootparentprevWould straw or rock have excellent nutritional value, then? reply jefftk 17 hours agorootparentIf you can&#x27;t get anything out of it then it doesn&#x27;t have nutritional value. reply thaumasiotes 17 hours agorootparentIn other words, when we say \"nutritional value\", what we mean is carbohydrates.This is something that everyone understands when we&#x27;re talking about bears, but somehow forgets when we&#x27;re talking about people. Those \"empty\" carbs are 99% of the reason you eat anything. \"Nutritional value\" and \"energy content\" are the same thing. reply orev 16 hours agorootparentIf you’re not trolling, I think you need to learn more about the difference between carbs, other nutrients, and indigestible material. “Carbs” does not mean “anything you can digest” (which seems to be how you’re using it).For all animals, of course ensuring that you have enough energy to function is a primary concern, but health studies in modern contexts always assumes that the supply of carbs is a solved problem (modern foods generally have far more carbs than most people need), but at the expense of reducing other nutrients. reply jefftk 14 hours agorootparentprevNo, that&#x27;s stronger than I&#x27;d say and I suspect than you think? For example, I think almost anyone would say the nutritional value of 100 calories of whole wheat flour is greater than 100 calories of enriched white flour, is greater than 100 calories of plain white flour. reply thaumasiotes 13 hours agorootparentSure, but the differences there are very small compared to the nutritional value of the 100 calories of white flour.Note also that 100 calories of whole wheat flour is more flour than 100 calories of white flour, which will matter to people who need to eat, but gets glossed over as you do the calorie-for-calorie comparison. replyjcutrell 16 hours agorootparentprevThis is in itself misleading. Carbs are the fundamental nutrient required for energy production (specifically for glycogen). So much so that without them the body undergoes glycogenesis. Carbohydrates might be “empty” in that they aren’t filling &#x2F; are higher calorie per gram, but they are no less a nutrient. reply orev 16 hours agorootparentWithin a general nutrition context, yes of course carbs are essential, however in a modern context the supply of carbs is so abundant that the conversation mostly revolves around the over abundance of them, while other nutrients are neglected. This and many other studies are highlighting this problem, where people crops have been optimized for size, yield, and fast growth (which almost always results in empty carbs being produced quickly), at the expense of all the other nutrients being reduced. reply qup 18 hours agoparentprevAs a counterpoint, that&#x27;s kinda my personal definition. I don&#x27;t think of calories, carbs, fats when I think about \"nutritional value.\"A related phrase is \"empty calories,\" which I define as foods with no vitamins or minerals, but plenty of carbs.I don&#x27;t think it means you&#x27;re wrong, you&#x27;re just ignoring a common use. reply NelsonMinar 17 hours agoparentprevYes, the Substack author and this post have greatly exaggerated the article. The actual data is that some fruits and vegetables have 50% less Sodium, Iron, and Copper in them than before. (Also a 10% decrease in Magnesium). That&#x27;s interesting but a far cry from \"nutritional value has dropped by 50%\". reply CydeWeys 17 hours agorootparentThe drop in sodium is funny because if anything that&#x27;s a good thing as most people eat way too much of it, and it&#x27;s super easy to supplement on the rare occasion it proves necessary. (Every one of us has a shaker of 100% bioavailable sodium sitting on our table.) reply BytesAndGears 18 hours agoparentprevThe first sentence lists it as including> carbohydrates, fat, protein, minerals, and vitaminsSo, it seems accurate to include minerals, which are essential for health reply jimnotgym 17 hours agorootparentBut when you say something has half the nutritional value it had, then shouldn&#x27;t there be less of everything, not just the smallest group? reply hansvm 17 hours agorootparentImagine reducing the fiber, sugar, water, minerals, and \"everything\" else in some apple slices by half. You haven&#x27;t made it less nutrient-dense; you&#x27;ve eliminated everything that makes it up; i.e., you&#x27;ve just made it smaller.The researchers aren&#x27;t arguing that we eat less. They&#x27;ve defined some things as important \"nutrients\" in some sense and noted that the relative (not absolute) concentrations of those have decreased.Whether that matters for a particular application is up for debate. Certainly macronutrients matter. It&#x27;s really not hard to understand what they mean though. reply jcutrell 16 hours agorootparentFor the average person, this pushes the incorrect narrative that somehow our food is becoming drastically less useful. The primary use of these crops has always been the carbohydrate content, followed by micronutrients; all this really says is that we should still have a diverse intake of food to reach RDA’s of said micros. reply hansvm 13 hours agorootparentThat may well be true, but that disagreement at least bothers to engage with what the authors were obviously saying, whereas the former posts were an exercise in pedantry. It&#x27;s actually a point worth bringing up, which is commendable.Secondarily, I disagree with you a bit I think:(1) Wheat is an important iron source. Lack of vitamins minerals in modern rice definitely killed a bunch of poor east-Asians who couldn&#x27;t or didn&#x27;t know they should supplement their diet more heavily with non-rice foods.(2) Even if the focus on cereal grains were the main point, an obvious side-suggestion is that cereal grains would not be the only afflicted crop. At a minimum, that would need more study. Some of that study has been done though, and potassium and iron (among others) have significantly declined in other common vegetable crops this century.(3) A diverse intake of food absolutely does not suffice to reach RDA&#x27;s of said micros. Just to leave things brief in the context of short interweb comments, (a) how would you hit an RDA of calcium in a day&#x27;s worth of calories and without additional supplements, (b) is that diet \"diverse\", and (c) does that plan leave enough budget in your available calories for the other micros you&#x27;d like to target? Calcium isn&#x27;t the only micro which is hard to satisfy with a generic \"diverse\" or \"raw\" or \"natural\" or whatever diet, and in 2000 calories (less as you age or if you&#x27;re smaller) it&#x27;s very, very difficult to hit all your micros with any combination of commonly available foods, especially if your strategy isn&#x27;t to explicitly make sure you hit those RDAs. reply jefftk 17 hours agorootparentprevIf there was a 10% increase in one area and an 80% decrease in two others I would still be okay saying half as much. And then there is some wiggle room in how you weight the categories.(But that&#x27;s not what&#x27;s going on here) reply ooterness 17 hours agoparentprevI agree. Their one relevant chart has seven items, probably cherry-picked to suppprt their narrative. One is sodium (Na), which is overabundant in modern diets. reply thaumasiotes 17 hours agorootparent> One is sodium (Na), which is overabundant in modern diets.Sodium consumption per capita has remained rock-steady in the face of an intense demonization campaign. It doesn&#x27;t really go up (as you might expect, if people develop food to satisfy cravings for it) or down (as you might expect if people pay attention to public messaging).(See e.g. https:&#x2F;&#x2F;www.cdc.gov&#x2F;mmwr&#x2F;volumes&#x2F;70&#x2F;wr&#x2F;mm7042a4.htm :> Mean usual energy intake–adjusted sodium intake among U.S. adults aged ≥19 years was lowest (3,333 mg&#x2F;day) during 2003–2004, and was 3,464 mg&#x2F;day during 2015–2016. )This tends to suggest that it is not in fact overabundant in modern diets. reply trenchgun 14 hours agoparentprevThe article is talking about micronutrients, minerals.Per wikipedia: >Nutritional value or nutritive value as part of food quality is the measure of a well-balanced ratio of the essential nutrients carbohydrates, fat, protein, minerals, and vitamins in items of food or diet concerning the nutrient requirements of their consumer. reply modzu 18 hours agoparentprevthere are seven major classes of nutrients in food: carbohydrates, fats, fiber, minerals, proteins, vitamins, and water reply firebot 18 hours agorootparentOh, oh, which ones are macro and which micro? reply marcus0x62 17 hours agorootparentOh, I get it! That must mean the macros are more important.That’s why you’ll die without adequate carbohydrate intake, but you don’t really need any, say, vitamin a, right? Right? reply graphe 17 hours agorootparentNobody is sustaining their iron copper and magnesium through carrots. Not eating carrots won&#x27;t kill anyone. None of your points matter unless you&#x27;re a vegan that only eats carrots. reply marcus0x62 17 hours agorootparentI only made one point: it is silly to pretend that macro nutrients are somehow more important than the micronutrients, when, in fact, you can do without one of the macronutrients entirely and without any ill effect whatsoever but there are many micronutrients that you will die or suffer life-threatening disease without an adequate supply of.You may not like that fact, but it is a fact and your straw man about vegans eating carrots that you hallucinated into my post doesn’t change that. reply graphe 17 hours agorootparentIt would be, if it had a bearing on reality. Your fantastical scenario is only relevant for sailors before they ate limes. replyjacknews 18 hours agoparentprevExactly, this is just clickbait. Certain minerals may have become less prevalent, but that&#x27;s not at all the same as a reduction in &#x27;nutritional content&#x27;. reply orev 17 hours agorootparentThe minerals are the nutritional content, so yes, that’s exactly what it means. reply jacknews 17 hours agorootparentThat&#x27;s ludicrous.The \"nutritional content\" is the part of the food that your body can make use of.Mostly carbs, proteins, etc.The trace minerals are essential, but hardly central.Even if the definition of &#x27;nutrition&#x27; is just those trace minerals (because somehow all the carbs, proteins, and everything else are &#x27;free&#x27;), the article grossly exaggerates.And given the whole shtick of this blog is &#x27;using science to make sense of society&#x27;, it&#x27;s a poor show. reply TheCoelacanth 15 hours agorootparentCarbs and proteins are macronutrients. Minerals are micronutrients. Both are central parts of nutrition. reply graphe 17 hours agorootparentprevNobody eats carrots for sodium and copper. That&#x27;s like saying you only use your computer for the floppy disk. reply mharig 13 hours agorootparentAnd what would you have done in say 1993 with a computer without floppy disk? reply ponector 17 hours agorootparentprevIf there are less minerals than there are more substitutes. Which are also nutrition content with some value.Therefore we can say that nutrition value increased as well! reply jcutrell 16 hours agoparentprevWas just going to say, the correct title might be “the micronutrient variety has reduced”, but that is misleading on its own. Unless the crops are becoming impossible to digest &#x2F; akin to cardboard, nutrition is just changing.Micronutrients are still important but there are relatively abundant sources still available, for example in leafy greens. reply LordKeren 18 hours agoprevMy takeaway from this is that this issue is not something that can be efficiently solved at the agricultural level if the root cause truly is the increased yields of modern farming.Is there an issue with taking a daily multivitamin that I am not aware of? reply narag 17 hours agoparentA few years ago, I learned as much as I could about vitamins and how to buy them.Multivitamin pills are the worst bang for the buck. Amounts of actual vitamins are very small. It&#x27;s better to buy mono-vitamin pills.Many of the vitamins have no strong evidence of usefulness. I keep buying Omega-3, D3+K2, Magnesium and B, specially B1 but there are good compounds.Magnesium is ridiculously difficult to source in good quantities, the labels are consistently misleading, bordering the scam. Happens with all, but Mg is the worst offender. reply grey8 17 hours agorootparentI also read into vitamins and minerals (while trying to ignore all the snake oil), and I agree with you!I tried a lot and the ones I keep buying are the same you do - Magnesium, Omega-3, D3+K2 and a B complex. These are not only the ones that most people are likely to be deficient in, these were also the ones that I subjectively felt had a positive effect on me, and either low or deficient levels were confirmed by blood tests. I feel a lot better, too! :)Regarding the magnesium: I did not know that. How do you make sure the brand and&#x2F;or it&#x27;s magnesium is of good quality?It&#x27;s curious you say this, I wasn&#x27;t totally sure, but I sometimes felt like there was a difference in quality, even between the same brand or product of the same form of Magnesium. reply narag 16 hours agorootparentRegarding the magnesium: I did not know that. How do you make sure the brand and&#x2F;or it&#x27;s magnesium is of good quality?The ultimate quality is impossible for me to judge. I just believe them at face value. The problem is that there are different kind of Mg (citrate, carbonate, oxyde) and different ways to write the quantities in the label. It&#x27;s been a long time since I read it.One common trick is saying that there is one gram per serving. But in the fine print they say that a serving is not one pill, but two pills. Or three or four.Another trick was playing with total vs. elemental Mg weight. reply gruez 17 hours agorootparentprev>Magnesium is ridiculously difficult to source in good quantities, the labels are consistently misleading, bordering the scam. Happens with all, but Mg is the worst offender.Any recommendations for vendors&#x2F;brands? reply narag 17 hours agorootparentI live in Spain and bought everything through Amazon.es. I guess the products are also available in the rest of Europe. Most of the links give me 404 now. Still working:https:&#x2F;&#x2F;www.amazon.es&#x2F;Omega-3-Aceite-Pescado-Salvaje-concent...https:&#x2F;&#x2F;www.amazon.es&#x2F;Complejo-Vitamina-Cápsulas-Vitaminas-M...I bought B1 much cheaper in powder, but no idea where... some site for bodybuilders&#x27;s supplements. That Aavalabs complex is also good. Magnesium is from the same brand as Omega-3, Zenement. The D3+K2 is from GloryFeel. reply Marsymars 16 hours agorootparentprevAs a mostly-vegetarian, I&#x27;ve settled on roughly the same, though I typically buy D3 without K2 and eat nattō a few times a week. reply foobar2723 14 hours agoprevBased on a quick scan, this seems like weak tea to me. The article is based on a small sample of repeated measurements across three periods and multiple variables. The significance levels are small and the changes vary over time. For example, in the 90s it seems many variables increased quite a bit only to fall later. It seems to me to be quite possible that we’re seeing “significant” results simply due to random variation. I suspect this is a publish or perish exercise. reply SamPatt 17 hours agoprevExtremely misleading headline.The underlying study doesn&#x27;t support this claim in the slightest.An accurate claim: some crops contain a few nutrients in smaller quantities than they contained in the 1960s. Primarily sodium and iron.This is absolutely not a crisis, especially in the developed world. reply omgJustTest 18 hours agoprevGreen revolution pumped volume of crops, mineral density remained the same in soil.Somewhat expect just the affect is unknown. reply cyberax 14 hours agoparent> Green revolution pumped volume of crops, mineral density remained the same in soil.Most minerals are in plants because plants need them for their own needs. So it doesn&#x27;t automatically follow at all.Copper is probably the only mineral where your simplistic model applies. reply adriansgarden 8 hours agoprevMost of the best work in this field has been summarized by John Kempf on his podcast and book.Nutrient density is driven by two related systems - the photosynthetic efficiency (amount of sunlight converted into sugars) which can range from 10% up to 30% + and the soil microbiology. As photosynthesis improves more sugars are exuded into the soil - often to select for microbes that perform certain function- such as making magnesium or phosphorus into a plant available form. This begins a flywheel in the soil. As microbes in a healthy soil die, larger proteins and amino acids are consumed by plants roots. Now plants have to spend less energy building these larger compounds and they become more efficient at producing the proteins and amino acids that make food healthy.IMHO - after 10 years of farming vegetables - this can all be jumpstarted by testing plant leaves for nutrients via plant sap analysis and then providing folier sprays that help improve photosynthesis and address protein synthesis pathways.On the consumer side…we aren’t that far off from a device that can scan a fruit and have your phone tell you how nutrient dense it is. Bio-nutrient food association and the gathering of open ag technology have been working on this for some time. reply graphe 18 hours agoprev>When comparing the same quantities of the same foods over time, they found that the amount of sodium (Na), iron (Fe), copper (Cu), and magnesium (Mg) found in them had significantly declined between the first and the last time point.Doesn&#x27;t seem concerning at all. If you&#x27;re a man you probably have too much iron. reply giovannibonetti 18 hours agoparentOn the other hand, for women it seems concerning:> As one example, the World Health Organization estimates that 42% of children under 5 years of age and 40% of pregnant women worldwide suffer from anemia due to a lack of iron, folate and&#x2F;or vitamins B12 and A. A primary cause of this problem (although there are others) is the lack of these minerals in people’s diet. Remember that iron (Fe) was one of the minerals whose presence in fruits and vegetables was found to drop by 50% between 1940 and 2019 in the first study I mentioned. reply wouldbecouldbe 17 hours agorootparentEasiest solution, if someones eats meat, is to eat a bit of organ meat regulary. Women need more iron in general due to their cycle. In general Iron from plants is also absorbed less. reply kylehotchkiss 18 hours agorootparentprevCooking on cast iron can help reduce this problem though right? reply JumpCrisscross 17 hours agorootparent> Cooking on cast iron can help reduce this problem though right?Probably [1]. That said, most Americans get enough iron.[1] https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC8266402&#x2F; reply Klonoar 17 hours agorootparentprevNot enough to fix the issue. reply graphe 17 hours agorootparentprevThat&#x27;s a good point, but it doesn&#x27;t seem to be affected by the us crops as much as other factors. Low iron is probably from low meat intake, Indian politicians had to fight strict vegetarians over giving developing children a SINGLE egg a day to eat over all vegetables.If you were sustaining yourself from vegetables even if they had 1950s and before iron, I doubt it would positively affect anemia. reply Turing_Machine 17 hours agoparentprevAnd, at least according to the doctors, many of us have too much sodium.Copper deficiency is extremely rare, and it&#x27;s mostly due to a rare disease rather than a dietary deficiency. reply talldatethrow 13 hours agorootparentThe salt thing is overblown. There are more people salt deficient than that get too much salt, at least if you look at the average person that tries to be healthy.I have helped two different girlfriends with almost lifelong migraines basically completely get rid of them by upping their salt intake. reply alecco 17 hours agoprevIt&#x27;s not on purpose. Farming is incentivized to increment yield without regarding micro-nutrients. A simple fix could be a label indicating if the product is below, at, or above average for its micro-nutrients.But we can&#x27;t even have simple labels warning for high sugar, saturated fats, and sodium. SMH reply chrisbrandow 14 hours agoprevOf course compared to 70 years ago the average city dweller probably has more than 2x access to fresh fruit and veggies, so the trace mineral intake is probably higher for at least some folk. reply CrzyLngPwd 15 hours agoprevPoisons relentlessly sprayed on the fields, destroying the life that extracts these nutrients from the soil and allows the plants to use them...and we&#x27;re surprised to find the plants have less of these nutrients.We&#x27;re a complex system of interactions, and our approach of killing life we don&#x27;t like hurts us more than we&#x27;ll ever know. reply trenchgun 14 hours agoparentIt&#x27;s not that, it&#x27;s just the fact that plants produce more from same area, leaving less vitamins and minerals per kg of produce. reply CrzyLngPwd 12 hours agorootparentOh, so you think poisons killing the bacterial life that turns rocks into readily available plant nutrients have no impact? reply viburnum 16 hours agoprevScientists were aware of this way back in the 1970s:https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S00652... reply talldatethrow 17 hours agoprevMy father gathers his own seeds from his favorite examples, or ofshoots of plants when appropriate.His tomatoes, dill, pomegranates, lemons, oranges, grapefruit and grapes are better than you can buy in any store, no matter how organic, special, artisan you try to get. There is definitely something to quality soil, and no chemicals rushing the process. reply jcutrell 16 hours agoparentCan you explain how they are better? Just curious what aspects you would determine that from, since I assume you’re not referring to nutrient content which would be pretty tough to judge. reply talldatethrow 13 hours agorootparentThey are so much better tasting, and so much obviously fuller in color, that only an academic would look at them or taste them and say that he&#x27;s not sure if there&#x27;s more nutrients in them. reply massifist 12 hours agoprevFour apples a day keeps the doctor away. reply BobbyTables2 18 hours agoprevI was inclined to dismiss the claims of CO2 on crops. This kind of language sounds to me as kids spouting agendas they don’t even really understand… People too easily scream “climate change” every time there is a severe storm.That said, I found CO2 levels seem to have changed by 25-30% from 1960. And a small multiples of the current concentration, humans tend to feel effects.https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;1091926&#x2F;atmospheric-conc...Maybe there is something to this? reply sbierwagen 16 hours agoparentCommercial hydroponic greenhouses frequently add CO2 to the grow room to increase yield: https:&#x2F;&#x2F;dutchgreenhouses.com&#x2F;en&#x2F;climate&#x2F;co2-enrichment If high CO2 levels reduce the mineral content of vegetables, then everything coming out of the Netherlands has been the nutritional equivalent of wax fruit for quite some time now.Somewhat awkwardly, the CO2 produced by the Climeworks DAC plant was initially sold to such a greenhouse, which was used to boost plant growth and then immediately exhausted to the atmosphere. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Climeworks#Projects Carbon captured... but not quite sequestered. reply graphe 17 hours agoparentprevMuch higher CO2 doesn&#x27;t mean an actual higher temperature as evidenced in reality. reply dcchambers 14 hours agoprevThis is my personal (unproven) theory about the obesity epidemic. People eat more than ever but are still hungry for more. It&#x27;s because our food is less nutritional. Although we&#x27;re getting adequate calories - we&#x27;re not getting enough nutrients, and our bodies are telling us to eat more. reply ch4s3 13 hours agoparentThat’s not at all how satiety works. People over eat for all kinds of reasons and there is a lot of low volume and highly calorically dense food available now. You feel full a little while after you’ve hit a certain level of physical fullness in your stomach.Very few people in the west have meaningful micro nutrient deficiencies. reply dcchambers 11 hours agorootparentOr do we not have micro nutrient deficiencies because we overeat in order to hit those needs?Obviously there&#x27;s flaws in my silly theory. I&#x27;m not a biologist or chemist, just something I think correlates in an interesting way. reply ch4s3 11 hours agorootparentThe why doesn’t really matter, we don’t have a hunger regulation mechanism that relates to micro nutrients. reply d_burfoot 17 hours agoprev [–] > This led the U.S. Dietary Guidelines for Americans, 2020-2025 to recommend that you get 85% of your daily calories from vegetables, fruits, grains, dairy, and protein—in that order.It&#x27;s absolutely astonishing to me that after the absolutely catastrophic response to the pandemic by 3-letter agencies like the CDC, WHO, and FDA, people still believe their advice when it comes to nutrition. The output of those agencies is just a toxic mishmash of various special interests, it has no relationship to reality. These are the same people who, 20 years ago, promoted the \"Food Pyramid\" with massive servings of carbs as the base. reply jefftk 17 hours agoparent [–] That is from the USDA, which in addition to not being a 3-letter agency wasn&#x27;t involved in any of the pandemic response you were unhappy with. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The nutritional value of crops like wheat and rice has decreased over the past sixty years due to factors like the Green Revolution, climate change, and the use of hybrid crops.",
      "These factors have resulted in larger crops with lower mineral content, leading to \"micronutrient malnutrition\" in many people, especially in low-income countries.",
      "To compensate for the decrease in nutritional value, it is recommended to follow dietary guidelines and consume a higher proportion of fruits and vegetables. However, as CO₂ levels rise, even greater amounts of these foods may be necessary to obtain adequate minerals."
    ],
    "commentSummary": [
      "There is concern about the decreasing nutritional value of crops and its potential impact on human health.",
      "Potential solutions discussed include organic farming, regenerative agriculture, and the use of human waste as fertilizer.",
      "The debate also touches on the impact of monoculture farming, changes in consumption patterns, and the importance of macronutrients and micronutrients in maintaining a balanced diet. Further research and the complexity of the food system are highlighted."
    ],
    "points": 210,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1702740382
  },
  {
    "id": 38666340,
    "title": "Sydney Actuary 'Annihilator' Takes Home Excel World Championship",
    "originLink": "https://www.theguardian.com/australia-news/2023/dec/15/you-didnt-just-succeed-you-exceled-sydney-man-dubbed-the-annihilator-wins-excel-world-championship",
    "originBody": "Andrew Ngai, the Microsoft Excel world champion, won $15,000 at this year’s event held at the HyperX esports arena in Las Vegas. Photograph: Andrew Ngai esports ‘You didn’t just succeed, you Exceled’: Sydney man dubbed the ‘Annihilator’ wins spreadsheet world championship Andrew Ngai, who works as an actuary, fends off competitors from around the globe to reclaim the event, televised live on ESPN Follow our Australia news live blog for latest updates Get our morning and afternoon news emails,free app or daily news podcast Daisy Dumas Thu 14 Dec 2023 09.00 EST There was a moment in the semi-final of the Microsoft Excel world championship when Andrew “the Annihilator” Ngai thought he had been eliminated. With the clock ticking and the Las Vegas audience on the edge of their seats, the two-time spreadsheet world champion started “furiously checking” his answers. Had he made a rounding error? Were his decimal places off? Stressed and doubting himself, Ngai decided it wasn’t his night. Michael “the Jarman Army” Jarman from the UK or Peter Sharl – no nickname – from the US looked set to win. But Ngai had no reason to worry. Pushing Buttons: Is the Olympics getting video games all wrong? Read more “For some unknown reason there was a mismatch between the scoresheet and the live stream,” he tells Guardian Australia from the US. “No one really knows why but it got out of sync.” The glitch was fixed, the scoreboard corrected and the 36-year-old from Sydney stormed to victory on Saturday night, becoming the triple world champion in data processing. “You didn’t just succeed – you Exceled,” Microsoft told Ngai via its Instagram feed. On X, one fan said the victory “will go down as a historical American sports moment on par with Babe Ruth calling his home run shot in the 1932 World Series”. Sign up for Guardian Australia’s free morning and afternoon email newsletters for your daily news roundup Microsoft Excel is officially an esport. In each round, eight players are given a big ream of data, plus a set of instructions. Contestants need to create formulas and subsets to process the data, working against the clock to solve stages of the case and earn bonus points. Every seven and a half minutes the lowest scorer is eliminated. “We have to decide, do we go for the bonus questions and get them in before others, or do you solve levels and progress further along?” says Ngai, who was given his nickname by “another Excel guru” on TikTok. When he’s not inputting cell values on a stage in Vegas, Ngai is a senior actuary in central Sydney. He says he is “not bad” at maths – by which he means he came top in the state of New South Wales in his year 12 maths exams. Since graduating from university, where he was awarded a degree in actuarial studies, he has used Excel every day for work. He started competing in the Excel championships in 2018 after hearing about the series. He won the title in 2019 when the competition was still in its infancy. Since then, the game has evolved. With entertainment in mind, the organisers shortened rounds to 30 minutes and livened up the cases. For example, Ngai had to calculate the market value of a fleet of spaceships using real data from the video game Eve Online – with the action televised live on ESPN. skip past newsletter promotion Sign up to Morning Mail Free daily newsletter Our Australian morning briefing breaks down the key stories of the day, telling you what’s happening and why it matters Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion The drama on the night made his win feel “crazy”, he says – not unlike last year, when he beat Brittany Deaton by just five points. If the game format sounds surprisingly gripping, it is also helped by the setting. Luxor hotel’s HyperX esports arena is complete with big screens, gaming seats and two enthusiastic commentators. Alongside the $15,000 prize money is an oversized boxing-style leather belt. Saturday’s 16 semi-finalists came from all over the world, including Poland, Brazil, Canada, Australia, the US and the UK. The community is tight-knit and the championships coincided with the Active Cell conference, where fans can join Excel masterclasses and finesse their skills in the spreadsheet’s new functions. Nowadays the spreadsheet is bulging with action, with computer programming and links to other software built into its design. If there’s one thing Ngai has learned from his three wins it is that sometimes simple is best. “The nature of this competition is you don’t necessarily have to know everything about Excel to be successful,” he says. “Keeping it simple can be quite effective.” But the last word goes to Brandon Moyer, who was eliminated in the final. In his post-game interview, the US competitor thanked his wife, who “never made fun of me, even once, for competing in the Microsoft Excel world championship”. Explore more on these topics esports Microsoft features Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=38666340",
    "commentBody": "Sydney man dubbed the &#x27;Annihilator&#x27; wins spreadsheet world championshipHacker NewspastloginSydney man dubbed the &#x27;Annihilator&#x27; wins spreadsheet world championship (theguardian.com) 209 points by tonyedgecombe 16 hours ago| hidepastfavorite76 comments tkzed49 14 hours agoPersonally I&#x27;m a fan of MAKRO, I think his commentary on the meta is very insightful.https:&#x2F;&#x2F;youtu.be&#x2F;xubbVvKbUfY reply resolutebat 14 hours agoparent\"What&#x27;s up sheetheads!\" Looking forward to the Annihilator crushing next year&#x27;s Ballmercon, at least if MS gets their fucking shit together and fixes the Chinese key bindings. reply scrlk 13 hours agoparentprevDid the pro scene ever get over the introduction of XLOOKUP overturning years of established meta?https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ICp2-EUKQAI reply blitzar 10 hours agorootparentI cant believe they nerfed VLOOKUP like that. reply ta8645 12 hours agoparentprevJudging from the other replies, this is a real thing. But I was convinced it was a parody comedy video after watching it myself. reply orthoxerox 11 hours agorootparentNo, it&#x27;s a comedy video, but life imitates art. reply resolutebat 9 hours agorootparentprevCongratulations, you are one of today&#x27;s lucky 10,000 [1] to discover Krazam. Start with Microservices: https:&#x2F;&#x2F;youtu.be&#x2F;y8OnoxKotPQ?feature=shared[1] https:&#x2F;&#x2F;xkcd.com&#x2F;1053&#x2F; reply mongol 12 hours agoparentprevHe was the one who introduced me to the pro scene. reply throwup238 14 hours agoprevI was not expecting a sweet photo of a beaming actuary when opening an article about someone nicknamed the “Annihilator.”That Excel championship wrestling belt is really cool though. reply lianna-vba 14 hours agoparentThe prizes are really cool. The winner of the sister competition (more finance focused) gets a large &#x27;diamond&#x27; encrusted ring.I encourage anyone who enjoys problem solving and Excel to sign up for the upcoming 2024 competition. Who knows, maybe you&#x27;ll get flown out to Las Vegas to compete in the finals next year?https:&#x2F;&#x2F;fmworldcup.com&#x2F;product-category&#x2F;battles&#x2F; reply wyclif 1 hour agoparentprevOther than becoming an actuary, how do these people become Excel gurus? What Excel books do they read? reply resolutebat 13 hours agoparentprevIt&#x27;s not a novel observation that in the online world, the people with the most badass handles tend to the most harmless in real life.In Ngai&#x27;s favor, though, apparently somebody else came up with his moniker. reply sundvor 12 hours agoprevEve Online (aka spreadsheets in space) players past and present might enjoy the reference that was made in the article. Was it an in-joke?\"For example, Ngai had to calculate the market value of a fleet of spaceships using real data from the video game Eve Online – with the action televised live on ESPN.\" reply ozim 8 hours agoparentNo, Eve Online was one of the sponsors. Surprisingly pro level gamers use spreadsheets more than one would expect from „gaming”.Final round was really about calculating stuff based on game economy. Challenge was created by top game guy. Which in some ways was surprising for finance guys. reply sundvor 8 hours agorootparentAhh, that&#x27;s pretty cool - thanks for that info!I played Eve for a good while (more than a decade) and the complexities was one of the appealing aspects, but unfortunately at one point the time between my sessions increased more and more, and I fell behind the learning and time curve, and dropped out. reply brendamn 12 hours agoprev> He says he is “not bad” at maths – by which he means he came top in the state of New South Wales in his year 12 maths examsAs an Australian that has worked with American companies for a while, this is a behaviour I’ve had to overcome. If you tell an Australian you’re “not bad” at something then they’ll take that to mean that you’re actually quite good, whereas many Americans will understand it to mean that you’re not good. reply doesnt_know 12 hours agoparentI&#x27;m sure you&#x27;re aware, but thought I&#x27;d drop this for our American friends. Australia and New Zealand (where I&#x27;m from) share Tall poppy syndrome[1] and going by that Wikipedia page, there are various over countries that have a similar concept.Being overly self-congratulatory comes across as this sort of grotesque and unattractive quality. It is even true in the corporate environments I&#x27;ve worked at where you would normally otherwise expect it. Kiwis don&#x27;t like it and I&#x27;ve seen many foreigners, especially the few Americans that have come over into management roles completely flounder and have almost everyone hate them because of it.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tall_poppy_syndrome reply yawnxyz 11 hours agorootparentAs an American who&#x27;s spent two years in Sydney and having met VC types here, it&#x27;s like they toe the line of not wanting to boast but really speak down on a lot of people. There&#x27;s some sort of hidden aristocracy here, and you can feel like they think they&#x27;re way better than you.You get some of that in the US too but there are also way more down-to-earth people there who actually want to help, and advice is actually helpful, rather than regurgitations of PG essays and Lean Startup. reply about3fitty 8 hours agorootparentThis was my experience as a dual citizen. Sydneysiders are sometimes wannabe Londoners with an odd superiority complex and frequent use of passive aggression. reply manmal 8 hours agorootparentHaving returned from London an hour ago, I think Londoners are mostly decent and friendly people. reply gerdesj 10 hours agorootparentprevWe have a similar concept in the UK too. However, I have never heard of tall poppy syndrome. reply Waterluvian 11 hours agorootparentprevInteresting!In Canada being modest is quite important… unless it’s a job interview (whether explicit or implicit), in which case it’s the “one time you should really brag about what you’re good at.” reply Grimburger 12 hours agoparentprevUnderstatement is a cultural thing to the point that chatbots have to be retrained to understand it: https:&#x2F;&#x2F;www.itnews.com.au&#x2F;news&#x2F;agl-trains-its-chatbot-alfie-... reply foob 11 hours agoparentprevDoes it always mean that in Australia, or does it depend on how you say it? I think both usages are actually pretty common in the US, but you tell the difference based on the inflection. If you emphasize \"too\" and go down in pitch on \"bad\" then it means you&#x27;re actually not that good at something, if you emphasize \"bad\" and go up in pitch then it means you&#x27;re actually good at it. We also have alternative constructions, like \"not too shabby,\" which carry the positive connotation regardless of how they&#x27;re pronounced. reply firecall 11 hours agorootparentThat’s my practical understanding of the term as well.Me: English, living in Australia for >20 years reply inopinatus 10 hours agoparentprev“Sorry to bother you” - I have a life-critical emergency“That is remarkable” - It is horrifyingly bad“Have you had your tea?” - Get out of my house reply InCityDreams 9 hours agorootparent>“Have you had your tea?” - Get out of my house\"Tea\", meaning &#x27;dinner&#x27;, I presume. reply defrost 9 hours agorootparentIn traditional Australia Tea meaning Tea the drink .. vast quantities have been consumed here, at least until the rise of the coffee shop - but the main thing is water is mostly boiled before drinking - flavour added.It was once universal custom in Australia to offer either tea or a beer when someone arrived - rehydration in a hot country is a thing to do.\"Have you finished that drink yet\" - depending on inflection it&#x27;s either an offer of another or a strong cue to hit the road. reply userbinator 6 hours agoparentprevThe same culture of understatement is present in the UK, which is where Australia likely inherited it from. reply nosrepa 7 hours agoparentprevMust not have worked with any Minnesotans then! reply AuryGlenz 2 hours agorootparentHeh, as a Minnesotan I was confused by the original comment until now. I didn’t realize that was a regional thing. reply refurb 7 hours agoparentprev> whereas many Americans will understand it to mean that you’re not goodI haven&#x27;t found that to be true. Tooting your own horn is generally looked upon as impolite in many circles. It&#x27;s pretty common for someone who is outstanding at something to say \"yeah, not bad\".And in a very meta way, it can be seen as a flex. Someone who is undeniably the best at something can say \"yeah, I&#x27;m not bad\" with a smirk to show that yeah, they know they are very good.Now there are some circles in the US where bragging is common - banking, VC, hell even tech. But that&#x27;s not America. reply barbazoo 7 hours agoprevI wonder if I’ll ever find another type of software that makes me as happy as spreadsheets, whatever implementation really, Excel, Google sheets, …. Perhaps not the Apple one actually. reply cobbaut 1 hour agoparentNothing beats Lotus123 :) reply codeulike 11 hours agoprevThis is the 3 hour video of the final apparentlyhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UDGdPE_C9u8The bit where Andrew Ngai&#x27;s scores dont correctly update seems to be at about 24:00Hope someone can make a highlights reel or something? reply hexane360 12 hours agoprevHere&#x27;s a great video about these Excel competitions: https:&#x2F;&#x2F;youtu.be&#x2F;N2QC6VQXo8U reply deebosong 12 hours agoparentMake it into an e-sports competition.But rather than try to hype it up like fighting game tournaments, have it be somewhat milder in aesthetics and tone, for the type of crowd it might draw. Like \"Best in Show\" or \"Great British Bake Off\" or what have you. reply ozim 8 hours agorootparentExactly I feel that belt - albeit funny - is more cringey than whatever else they could come up with.Then I say dynamic commentary is still something you want - but talkative host asking a guy that is going to drop underground in seconds is not bes use of watch time reply fbdab103 11 hours agoprevDo they publish the questions&#x2F;data anywhere? Would love to have an informal competition among similarly minded friends.Of course, I would try to do it in Pandas and get crushed. reply tacon 11 hours agoparentI just heard of this Excel competition, but Modeloff world championship has been going for somewhat longer. It tests Excel skills plus financial modeling skills. They have all the old questions available for study:https:&#x2F;&#x2F;corporatefinanceinstitute.com&#x2F;resources&#x2F;financial-mo... reply neontomo 8 hours agoprevIf you like nerdy championships like these, also check out:Classic Tetris World Championships - https:&#x2F;&#x2F;www.youtube.com&#x2F;@ClassicTetrisWebflow Speed Build Challenge - https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9regpz3xvrs reply dgrin91 15 hours agoprevI wish they would explain more about what the actual tasks are. They basically jus said &#x27;you get data and you do calculations&#x27;. Well thanks, thats basically all excel. A link to the problem set would be interesting. Real time data from Eve is pretty cool, but whats the actual results they are trying to get? How do they do scoring? reply codetrotter 15 hours agoparentI have a feeling that these sorts of questions will be answered if we look at the actual video from the finals.https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;UDGdPE_C9u8 reply lIl-IIIl 12 hours agorootparentThe puzzle description begins at 1:18:44.But it doesn&#x27;t feel like it&#x27;s a complete description of the puzzle, just the data format. Do the competitors have a list of questions? reply itishappy 12 hours agorootparentIndeed they do get lists of questions (including bonus ones)! The puzzle description at 13 minutes explains a bit more.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UDGdPE_C9u8&t=811s reply Tyr42 13 hours agorootparentprev13 minutes in. reply TOMDM 15 hours agoparentprevThere are some sample cases on the Financiaal Modelling World Cup website.https:&#x2F;&#x2F;fmworldcup.com&#x2F;sample-cases&#x2F; reply BLKNSLVR 13 hours agoparentprevDirect excerpt that gives an idea of the task(s):\"With entertainment in mind, the organisers shortened rounds to 30 minutes and livened up the cases. For example, Ngai had to calculate the market value of a fleet of spaceships using real data from the video game Eve Online – with the action televised live on ESPN.\" reply Tao3300 14 hours agoparentprevThat&#x27;s probably above the Guardian&#x27;s heads. I don&#x27;t mean that as a diss, just that that level of technicality isn&#x27;t their thing. reply peetabix 12 hours agoparentprevI think &#x27;People make games&#x27; did a video on it on YouTube. reply throwawaysugar 12 hours agoprevLink to the finals https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UDGdPE_C9u8 reply SOLAR_FIELDS 9 hours agoprevIt does seem fitting that an actuary would win this considering how much of their work day and job description revolves around Excel and what it can do reply arnaudsm 10 hours agoprevI&#x27;d be very interested in watching traditional competitive programmers tackling these challenges. Can they beat low-code excel ? reply manav 14 hours agoprevExcellent. reply 29athrowaway 14 hours agoprevI never thought I was going to see an Excel world tournament with commentators, etc. That is, Excel as an e-sport. reply cglong 14 hours agoparentI actually watched this live at a sports bar airing ESPN-U. It was a surreal experience haha reply RcouF1uZ4gsC 13 hours agoprev> with the action televised live on ESPN.That’s what happens where there are more TV minutes than sports minutes. reply boomboomsubban 13 hours agoparentAs someone who steamed a bit of kabaddi last weekend, we are nowhere near that point. reply PrimeMcFly 13 hours agoprevWell that&#x27;s weird. Moreso that it was televised by ESPN and had an audience on the edge of their seats. reply marcod 13 hours agoprev> But the last word goes to Brandon Moyer, who was eliminated in the final. In his post-game interview, the US competitor thanked his wife, who “never made fun of me, even once, for competing in the Microsoft Excel world championship”. reply bryancoxwell 13 hours agoparentAw. reply blitzar 9 hours agoparentprev* to his face reply kazinator 12 hours agoprevOK, let&#x27;s have a show of hands. How many of you would trade your software dev &#x2F; coding skills for that title? reply mynameisnoone 4 hours agoparentOnly if it was accomplished with SuperCalc. reply aregreabn 14 hours agoprevnext [4 more] [flagged] rmccue 14 hours agoparentHe’s Australian. reply manav 14 hours agoparentprevChinese-Australian. Nearly 20% of AU is Asian. reply ganeshkrishnan 14 hours agoparentprevThe Australian math team for any year is going to blow your mind https:&#x2F;&#x2F;threesides.com.au&#x2F;wp-content&#x2F;uploads&#x2F;2022&#x2F;02&#x2F;2022_EG... reply xyst 13 hours agoprev [–] “…spreadsheet world championship”There’s a competition for everything now. What’s next?Most Compelling Deck Championship?edit; I’m convinced this is a just a massive MS excel advertisement. Smh reply onion2k 12 hours agoparentMost Compelling Deck Championship?Not quite the same but I&#x27;ve attended a few barcamp conferences that have had \"PowerPoint kareoke\" competitions - the goal is to present a random deck from SlideShare that you haven&#x27;t seen before, and the most entertaining (by judges or by the crowd) wins. It&#x27;s very funny. reply Loughla 13 hours agoparentprevIt can be both. It can be a fun competition and an advertisement for excel.People go nuts over how many times a group of people can kick a ball into a net, why not spreadsheets? reply boomboomsubban 13 hours agoparentprev>edit; I’m convinced this is a just a massive MS excel advertisement. SmhIf Microsoft was behind this, why would they hide their involvement? And if they were, why would that change anything about it? reply iancmceachern 13 hours agoparentprevAren&#x27;t moat sporting events just one massive advertisement? reply acomjean 12 hours agoparentprevIt might be a MS pr move. But it seems a lot of competitions are for boosting an industry. The Oscar&#x27;s celebrate movies, he Grammys promote music, \"the game awards\" promote games.I imagine a fornite competetion would be sponsored by epic. reply gU9x3u8XmQNG 13 hours agoparentprevMuch support, especially if it is run by kiwi’s. reply constantly 13 hours agoparentprev> Most Compelling Deck Championship?Usually people try to avoid deck measuring contests. reply yowlingcat 10 hours agoparentprev [–] I think this is a flippant comment. You can do just about anything in Excel, so being good at it to me feels akin to winning a programming olypmiad -- abstract, sure, but still indicative of strong, transferrable skills. To me, to dismiss that is to reflect your own close mindedness and intellectual laziness rather than anything about the comeptition. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Andrew Ngai, also known as the \"Annihilator,\" emerged as the winner of the Microsoft Excel world championship, securing a prize of $15,000.",
      "Ngai, an actuary from Sydney, triumphed over participants from various countries in a competition focused on processing data using Excel formulas and subsets within a specified timeframe.",
      "Initially, doubts were raised about Ngai's victory due to a scoring error, but it was later verified, solidifying his championship. The event occurred at the HyperX esports arena in Las Vegas and was broadcasted live on ESPN."
    ],
    "commentSummary": [
      "A man from Sydney, known as the \"Annihilator,\" has won the spreadsheet world championship, showcasing his problem-solving and Excel skills.",
      "The competition offers unique prizes and encourages participants to sign up for future competitions.",
      "The discussions revolve around the use of real data from a video game, the involvement of professional gamers, cultural observations, and comparisons between Australian and American attitudes.",
      "The comment thread debates the legitimacy of the Excel world championship, questioning if it is a marketing advertisement for the software.",
      "The passage highlights the importance of recognizing the valuable skills gained through participating in the olympiad."
    ],
    "points": 209,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1702749588
  },
  {
    "id": 38666287,
    "title": "Apter Trees: Simplifying Tree Structures with Efficient Vector Operations",
    "originLink": "https://github.com/tlack/atree",
    "originBody": "Apter Trees in C++ Apter Trees are a simpler representation of trees using just two vectors: [nodevalues, parentindices]. This repo contains a tree-like data type implemented in C++17, in the style of Stevan Apter in Treetable: a case-study in q. Who cares? A tree is a data structure in which values have parent-child relationships to each other. They come in many forms. In most software, trees are implemented like a typical binary tree, where each node contains its own data and a pointer to each of its children, nominally just left and right, which are also nodes. The cycle continues. Using such a data structure can be challenging due to recursion and slow due to cache behavior in modern systems and frequent malloc()s. The concept of who \"owns\" a tree node in such a system can become complex in multi-layered software. Apter Trees are much faster, easier to reason about, and easier to implement. How it works An Apter tree is implemented as two same-sized arrays. One is a vector (array) of data (we'll call it d). These correspond to the values, or things that each node contains. The other is a vector of parent indices (p). The index of an item in the d vector is used as its key, which we will call c in the examples below. Often, the key/index c will just be an int. So, if we had a dog family tree in which Coco was the father of Molly and Arca, and Arca had a son named Cricket, you might have a data structure like:tree.d = [\"Coco\", \"Molly\", \"Arca\",\"Cricket\"]tree.p = [0,0,0,2] A node with a key of 0 whose parent is zero is the root node. Apter trees require a root node, or the use of -1 to mean \"no parent\", which is slightly less elegant so I'll ignore it. Computers are very, very fast at manipulating vectors. They're so much faster than pointer operations that comparisons of big-O notation for an algorithm don't play out in practice. Operations in psuedocode The technique is applicable in all languages. This library is written in C++ but I will use psuedocode to explain how it works. Empty tree tree() = { {d:[], p:[]} } # some sort of [data,parentidxs] vector Number of nodes nodecnt(t) = { len(t.p) } Keys of all nodes join(x,y) = { flatten(x,y) } # append to vec. i.e., x.push_back(y), x[]=y, etc. range(x,y) = { # Q til, APL/C++ iota; return [x, x+1, x+2, ...y-1]i=x; ret=[]; while(i++<y) ret=join(ret,i); return ret } keys(t) = { range(0, nodecnt(t)) } Add an item to the tree: insert(t, val, parentidx) = {t.d = join(t.d,val)t.p = join(t.p,parentidx) } Determine parent of a given node: Remember, we use the numeric index of a node (childidx) as its identifier: parentof(t,childidx) = { t.p[childidx] } Retrieve value of node: We'll use c instead of childidx, from here on out. data(t,c) = { t.d[c] } Scan for keys that have a given value: where(vec,val) = { # return indices of vec that contain valmatches=[]for idx,v in vec: if(v==val, {matches=join(matches,idx)})return matches } search(t,val) = { where(t.d,val) } Determine children of a node: childnodes(t,c) = { where(t.p,c) } Retrieve child nodes' values # We're assuming you can index with a vector; otherwise loop required childdata(t,c) = { data(childnodes(c)) } Determine leaf nodes (those with no children): First, build a vector of all the indices. Then remove those indices that are also in p. The psuedocode below is a slow implementation; should be done as a single loop. except(x,y) = { # return elements of x except those in y. set subtractionret=[];for idx,xx in x: if(!xx in y, {ret=join(ret,xx)});return ret; } leaves(t) = { except(keys(t), t.p) } Determine vector of parents for a given node, or path to node: Here we keep going up the tree until we can't go any further (ends at 0). When node zero's parent is zero, we know we've reached the root node - that the \"checking last value\" trick works. We call this form of iteration exhaust. It's called scan in K and Q. We reverse the result so that it is in parentA.parentB.parentC.child order. exhaust(vec,start) = {ret=[]; last=x=startdo { last=x ret=join(ret,x) x=vec[x]} until x==lastreturn ret } parentnodes(t,c) = { reverse(exhaust(t.p, c) } Determine data for path through tree (i.e., all parents of a node) parentdata(t,c) = { data(parentnodes(t,c)) } In order traversal The simplest way is to get the list of leaves, and then determine the path to each. We finally sort those vectors. I believe there is a simpler way that can work in a single pass, or at least a single pass with a sufficiently large stack. I'm still exploring this idea. Let me know if you have any suggestions. We're assuming a fairly flexible sort function here which can handle sorting vectors of vectors. all(t) = { sort(each(leaves(t), (c){ parent(t, c) })) } Delete item This can vary depending on your application. A sentinel value like MAXINT in the parent column is probably easiest. Some systems uses -1 to represent an empty node if you can spare the sign bit. Again, who cares? (Unfounded editorializing) I think this is the most elegant implementation style of trees I've seen. Given the right vector operations library, it's by far the shortest, which means you can easily understand it, find bugs in it. Given the simplicity, it's easy to adapt for other usage scenarios. For instance, you could maintain a third index of keys to create low overhead sorted order for data. You can ignore the parent index vector and iterate quickly through the values if you are searching for something, which is like a deep map, for free. You can remap all parent-child relatioships in one go. You can build a serialized version instantly or transmit it over a network without iteration. It's GPU friendly. It's easy to use in an embedded context. It's secure because you can easily impose boundaries (by not allowing the vectors to grow beyond a certain size). Given common sense it's also the fastest. There's very little memory overhead, and in many cases, access will be linear. Intermediate values and recursion is minimized. Computers are great at handling ints cuz that's what the benchmarks do. Pointers are annoying anyway. Origins I've been lazily trying to figure out who invented this technique. It's so obvious I would imagine it must have had a name during the vector-oriented 60s and 70s. The first full explanation I saw was from Apter as explained above, but it was also documented widely as early as K3. Here's a version in Q: / nested directory: use a parent vector, e.g. / a / b / c / d / e p:0N 0N 1 2 1 / parent n:`a`b`c`d`e / name c:group p / children n p scan 3 / full path I must have read that a hundred times before I internalized its genius. See four other ways to represent trees in K each in about three lines of code. APL, or at least Dyalog, seems to implement trees in a more traditional way, using nested boxes: see here for more. They do however use a similar technique for vector graphs. It appears to be known to J users as seen in Rosetta Code's tree implementation in J (with some illuminating comments). John Earnest goes into [much more detail about vector tree implementations] (https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Trees.md), including the \"index of offsets\" approach to deleting entries. Worth a read. A more elaborate approach is to also track the depth of each item. Details about that approach can be found in Aaron W. Hsu's paper on the subject. Other common tree implementations Here are some other well known trees. None of these do the same thing as an Apter tree, and some are far larger due to generalizations, but it's still interesting to consider how much code different styles of trees requires to do simple operations. FreeBSD's kernel tree implementation klib's tree a tree class in Ruby Python declarative tree class Status of this code I've made a sorta lazy attempt at implementing this in C++ as a way to learn C++17. Not really ready for use or fully fleshed out. I still have a lot to learn about C++. Thanks Arthur Whitney, Apter, others: inspiration. John Earnest: source materials Dave Linn: proof reading.",
    "commentLink": "https://news.ycombinator.com/item?id=38666287",
    "commentBody": "Atree: A simple and efficient pointer-free tree implementationHacker NewspastloginAtree: A simple and efficient pointer-free tree implementation (github.com/tlack) 199 points by spenczar5 16 hours ago| hidepastfavorite94 comments tlack 14 hours agoAlways surprising to click through a link on HN and discover it is one&#x27;s own work. For a time I was very interested in lightweight array-based implementations of common data structures and this one seemed particularly handy. reply spenczar5 14 hours agoparentIt sounds a little like it didn’t work out as well as you hoped. How did it fare?I am interested because I have some scientific software (astrodynamics - propagating orbits in space) that would really benefit from a cache-friendly tree, and this seemed promising. reply ninepoints 14 hours agorootparentIt does? Feels like an O(n) scan every time you need to query the children of a node is a nonstarter for most applications (the readme is strangely optimistic about this point). Plenty of cache friendly tree implementations out there, and this one seems actually cache hostile with few benefits in my mind aside from ease of implementation.Also, I write a lot of code that runs on a gpu, and the claim that this tree is somehow gpu friendly I find particularly dubious. reply a1369209993 12 hours agorootparent> Feels like an O(n) scan every time you need to query the children of a node is a nonstarter for most applications (the readme is strangely optimistic about this point).The trick is that querying the children of N different nodes is usually still a single O(N) scan, so if you operate on it array-style (which APL heavily encourages anyway), it&#x27;s amortized constant time. Of course that&#x27;s not always viable, but APL programmers tend to be surprisingly good at making array operations out of things you wouldn&#x27;t expect to use arrays for.> cache hostileIf you additionally enforce that all parent indexes point to lower numbers, a preorder traversal is a linear scan forward, and a postorder traversal with child order reversed (which you can usually correct for one way or another) is a linear scan backward.(This assumes you only need dependency ordering, ie the parent node uses or supplies data to&#x2F;from its children; if you need a true sequential traversal, the array has to be sorted according to that traversal (but is still a valid Apter Tree).)> the claim that this tree is somehow gpu friendly I find particularly dubiousYeah, array programming is generally kind of hit-or-miss at that and this does look like a miss. reply ninepoints 12 hours agorootparentThe linear scan you are talking about I don&#x27;t think gives you any sort of ordered traversal right? Unless I&#x27;m missing something. reply a1369209993 11 hours agorootparentFor a arbitrary Apter Tree, a linear scan is unordered. You can impose additional constraints to get a ordered traversal (in the same way that, eg, you can sort a assoc-list&#x2F;JSON-style key-value table by keys to get a key-order traversal), and the result is still a valid Apter Tree (respectively valid list of key-value pairs). reply ninepoints 8 hours agorootparentYes but that is not what is presented (a B+ tree is not a B tree even with minor modifications) and it changes the complexity of your other update operations drastically. The thing that grates me (as someone that has written a dozen or so different tree structures) is that this one is presented as a particularly good one, and I think it excels at almost nothing, hence its obscurity. reply toasted-subs 2 hours agorootparentprevWhenever somebody says cache friendly without additional context I assume they got code from somebody else without understanding what makes things \"cache-friendly\". reply spenczar5 14 hours agorootparentprevFor me, N is small. Its also N-ary, not binary, which crosses off a bunch of the first options. Anyway, I am not sure this will work, just worth trying. Empirical numbers beat theory every time :) reply ninepoints 12 hours agorootparentYou are using N in a different sense than I am. Unless I&#x27;m reading the tree description incorrectly, N is the size of the tree itself, not the number of children. reply spenczar5 12 hours agorootparentOh, I was being sloppy and mixed N into the ariness: I meant N elements, each with a variable number of children (as many as 8). reply ninepoints 11 hours agorootparentI would hazard a guess that a regular n-ary tree would outperform the OP tree in many usage scenarios with no extra effort, and with a number of B+ tree variants being strictly better at the cost of more effort. reply mgaunard 13 hours agorootparentprevVector programming requires you to change your way of thinking; instead of computing something for 1 element, you compute it for N elements. reply ninepoints 12 hours agorootparentI do lots of simd and shader programming, but regardless of register width, O(n) is not O(1) reply marginalia_nu 10 hours agorootparentI don&#x27;t think looking at asymptotic behavor makes a lot of sense in situations where n is small and bounded. Big O says nothing about such cases. reply ninepoints 8 hours agorootparentSorry, do you not have trees for which the size of the tree is large. Do all your trees fit inside a few cache lines of storage? reply marginalia_nu 7 hours agorootparentI deal with very large tree structures (~100 GB) in my search engine, but even there the dominant factor for performance isn&#x27;t big O, but reducing block reads, access patterns and keeping relevant data in the disk cache.Big O isn&#x27;t irrelevant, but it is not the full story either. There&#x27;s a solid reason why hash tables are a thing in memory but aren&#x27;t really a thing on disk. reply ninepoints 5 hours agorootparentDo you understand the data structure being proposed in the original post, and are you claiming that scanning 100GB of data every time you want to perform a childof operation is acceptable? Please, use the proposed tree for your application since big o isn&#x27;t the full story to you lol reply 8organicbits 3 hours agorootparentI&#x27;m not sure why you&#x27;re suggesting those claims were made. The parent appears to be talking about non-asymptotic behavior. Very often algorithms with worse big O perform better; its use-case specific. Hyper focus on big O isnt productive, but fairly common due to how CS curriculums focus on it. In some cases it takes unexpectedly long for the big-O to impact performance, as other factors dominate.The parent commenter writes a wonderful blog that covers their experience with building and optimizing a search engine, well worth a read.https:&#x2F;&#x2F;www.marginalia.nu&#x2F;log&#x2F;87_absurd_success&#x2F; reply ninepoints 2 hours agorootparentYes and I&#x27;m pointing out that non-asymptotic behavior doesn&#x27;t apply when N here is the total number of nodes in the tree. replymgaunard 11 hours agorootparentprevThe point is that you shouldn&#x27;t try to get all the children of a single node, but rather all the children of all the nodes, which is still O(n) and not O(n^2). reply ninepoints 8 hours agorootparentThis doesn&#x27;t make any sense to me. reply jiggawatts 14 hours agorootparentprevThere are use cases where that doesn’t matter, such as some compilers where it makes a full pass over the source code for every optimisation type. reply tlack 12 hours agorootparentprevI still like that setup for using trees in low level languages.But personally I’ve been working at higher levels of the stack the last few years, where these kinds of decisions seem less important.And on another level, it seems like coders in general aren’t that interested in vector oriented languages and techniques which makes their study somewhat isolating. reply loxias 9 hours agorootparent\"Isolating\" is where the performance (innovation) is.I used a very similar setup, first time I needed to implement a tree. Now, I&#x27;m a fan of Eytzinger layout. (referenced in a previous comment in this thread)Yeah, most coders in general don&#x27;t seem to be as interested in this stuff, but it&#x27;s still necessary. They&#x27;ll want more performance. reply caslon 4 hours agorootparentWhy do they need more performance? Hardware gets faster all the time, and the most popular implementations of the most popular programming languages have so much low-hanging fruit you can get a 10x improvement by rolling your cat on the keyboard.I don&#x27;t think programmers actually care about performance as much as they care for convenience. Every year the stack moves a bit higher, and everyone is okay with websites taking days to load on brand new phones with Gigabit wireless connections. There are companies that care about performance on the margin, like stock trading firms, but to get into one of them, you have to get pretty lucky, or come from a pretty special background. Even the banks are using Python more and more, these days. reply loxias 2 hours agorootparentShrug.People will always care about performance because they will always want more functionality.I bet you care about the performance of your database or how fast your pages load. You want your streaming videos to be skip-free and your phone calls to sound lifelike. Performance will always matter. Because while people like me will be always trying to squeeze more, \"the other side\" will always be ready to use it for some new feature. reply 59nadir 55 minutes agorootparentThe post you&#x27;re replying to sounds more like it&#x27;s lamenting the complacency of most developers more than it&#x27;s saying that performance isn&#x27;t worth caring about, or I&#x27;m projecting my own feelings onto it.I&#x27;m not under the impression that people care at all, to be honest, outside of certain communities. If you&#x27;re not in those communities talking about performance as a corner stone feels mostly like screaming into the void. reply fwsgonzo 12 hours agorootparentprevIt is always like that when you venture off the well trodden path. I am studying low latency emulation and it&#x27;s also isolating. reply chii 8 hours agorootparentprev> working at higher levels of the stack the last few years, where these kinds of decisions seem less important.but then accumulated outcome of this is the slowness you see in web software! reply runeblaze 6 hours agorootparentprevFWIW I worked also on scientific software (phylogenetics, which is all about biological evolutionary trees) and the tree structure is like Atree (https:&#x2F;&#x2F;github.com&#x2F;RuneBlaze&#x2F;internode&#x2F;blob&#x2F;main&#x2F;src&#x2F;tree.rs...).It does help (roughly ~5x vs. pointer-chasing trees, probably can be further optimized) for my workload, but at the same time quite some time was spent just making sure the tree is correct. reply loxias 9 hours agorootparentprevI&#x27;m interested in the same stuff&#x2F;area. There&#x27;s a lot of great results to read, check out cache-oblivious B-trees by Dr. Demaine (or honestly anything by him.) This link is a good distillation of some of the concepts. https:&#x2F;&#x2F;algorithmica.org&#x2F;en&#x2F;eytzingerI&#x27;m _also_ interested in scientific software, but that&#x27;s more a hobby than a job. =)For propagating a large number of orbits in space, I&#x27;m really curious what the Correct (tm) numerical algorithm is, mind sharing more? I love that space right at the intersection of lots of math + need to understand how computers really work. Once upon a time I implemented fast multipole method for the n-body problem, but I certainly don&#x27;t claim to deeply understand it, anymore. :) reply 8372049 11 hours agoparentprevFriendly heads up, \"pseudo\" is frequently misspelled \"psuedo\" in the readme. reply edflsafoiewq 12 hours agoprevThis is the representation I usually see used for the tree of nodes for skinning 3D models. There each node has a transform, and the most common operation is to recompute the world transform for all nodes, formed by composing the transform for each node with the one for all of its parents. If the array is sorted so that parents always precede their children, that&#x27;s just a straight loop over the arrays for i = 0, num_nodes do if parents[i] == -1 then world_xforms[i] = xforms[i] else world_xforms[i] = world_xforms[parents[i]] * xforms[i] reply ninepoints 3 hours agoparentI would hope your joint hierarchy is at least depth sorted or the loop as shown would not work. The proposed ATree has no order invariants... reply rav 13 hours agoprevLots of comments about iterating over children being O(N) for this style of trees. It&#x27;s actually easy to generalize the atree design by e.g. adding pointers for \"first child\" and \"next sibling\" and potentially removing the parent pointers, if that&#x27;s what you need in your application. I think the \"Operations in psuedocode\" section should simply state that there&#x27;s no O(1) way to access children of a node - instead of recommending the O(N) approach, you should recommend changing the data structure to support the operations you need.Storing nodes in arrays and using indices for pointers is a must whenever you&#x27;re implementing algorithms on trees. I typically prefer using an array of structs, putting the key and the parent index next to each other, instead of putting them in separate arrays. If you need to access the children of a node, then be sure to consider if you can save memory by having a separate structure for leaves - remember that over half of the nodes will be leaves, so using space to store a child pointer on both internal nodes and leaves can be wasteful use of memory. reply akoboldfrying 6 hours agoparentOne way to maintain leaves efficiently (amortised O(1) time and space to add&#x2F;remove) is to keep 2 extra vectors that \"point at each other\": L[] is a vector containing the indices of all leaves, and LP[] is a vector such that LP[i] stores the index within L[] of the value i if i is a leaf, and -1 otherwise. That is, for i a non-leaf, LP[i] == -1, while for i a leaf, L[LP[i]] == i.To find the indices of all leaves: That&#x27;s just L[].To add a leaf i: Append i to L[], and set LP[i] to L.length - 1.To remove a leaf i in constant time: j = L[L.length - 1] L[LP[i]] = j LP[j] = i LP[i] = -1. DropLastElement(L[]) reply matt3210 12 hours agoprevAn integer which references another data location is a pointer. This project only replaces system pointers with home grown pointers reply 8372049 11 hours agoparentI think in this context, \"pointer-free\" is meant to imply (spatial) locality of reference, no additional memory allocations, address-independent and presumably memory safety (but I didn&#x27;t read the code and may be wrong about the last one). reply nine_k 9 hours agoparentprevIt&#x27;s not exactly so right on the hardware level. Many architectures, including the ubiquitous x64, have an ability to add a direct offset to a memory-access operation (like mov), or efficiently compute the address with an offset and element size (like lea). This removes an extra pointer deteference, which may be hugely expensive.With a cache-friendly structure like array, the one dereference you may need for the array access has a high chance to be served from L2 or L1, saving you a lot of clocks, because RAM has huge latency. reply naasking 3 hours agoparentprevThis is typically referred to as a handle rather than a pointer. Handles can permit more flexibility than pointers. reply huhtenberg 10 hours agoparentprevOh, please.There are technically correct nitpicks with some merit and there are trivial remarks like yours. It is perfectly clear what \"pointer-free\" was referring to in the post title. reply akoboldfrying 6 hours agorootparentIt&#x27;s a legitimate criticism. The claimed benefit of \"vector processing is faster than pointer chasing\" will materialise only when the most common access pattern is to read or write all node values, since in that case the accessed values are contiguous -- but that&#x27;s a consequence of the data structure being a struct-of-arrays (instead of the more common array-of-structs), which is wholly independent of the pointers-or-indices question. For any of the (very common) other access patterns, like a preorder traversal, \"index-chasing\" needs to happen, and that will be exactly as bad as pointer-chasing would be if the entire memory block had been reserved ahead of time in the same way.The only real advantages of indices over pointers are serialisability and ease of debugging. reply kitd 2 hours agorootparentprevIs it? Please tell me because I had the same question.From the programmer&#x27;s PoV, having no pointers gives little to no benefit. From the CPU&#x27;s PoV, (in c&#x2F;c++) indices become pointers anyway. Maybe the compiler can optimise more easily, but that&#x27;s not obvious.Cache coherence is the key goal, but you can do that with pointers easily enough. reply bicsi 2 hours agoprevI find it a bit odd how this tree representation as a parents array (which is, by the way, I think the most basic representation in any CS course), got so much traction on HN. I think this goes to show how far a good presentation can drive a trivial idea. On top of that, it just casually presents suboptimal procedures for a lot of essential operations, without diving into too much details about the impact of the suboptimality. Good PR I guess… reply sinuhe69 2 hours agoprevWhat is a array index if not a “pointer”? In fact, access an array member involves a pointer arithmetic: array_p + index * data_sizeThe fact that traditional tree implementation requires malloc is solely based on the wish to dynamically provide and remove of nodes. If the tree can have a limited size with no frequent delete operation, an array implementation is fine. Otherwise, expand an array can be a very costly or even an impossible operation in some circumstances.And full scanning is not efficient. reply kleiba 1 hour agoparentThe difference lies in the CPU cache. reply zeroCalories 13 hours agoprevLooks nice. That said, if you want to reduce mallocs and encourage data locality, maybe you could try a more traditional tree implementation using a pool of nodes similar to thread pools. I&#x27;ve found that most of my problems related to those were solved by such techniques. reply OnlyMortal 13 hours agoparentA custom pool for objects is often a good idea. Pre-allocate “enough” memory and dish them out as appropriate, releasing back to the pool when the reference count goes to zero.You can also use the pool to bound the maximum size you’re able to allow. reply winrid 6 hours agorootparentMan, if only something already did this. We could call it Oak... Or maybe Java? :) reply mathiasgredal 12 hours agorootparentprevWhy is this better than an arena style allocator? reply akoboldfrying 6 hours agorootparentIt is an arena-style allocator.At least, if someone asked me to explain what an arena allocator is&#x2F;does, I would say essentially what they wrote -- likely without the \"disappears automatically once all references disappear\" part, which is IMHO just a clever nice-to-have. reply irreducible 2 hours agoprevFor anyone interested, I sketched out a basic implementation of this in Rust. https:&#x2F;&#x2F;github.com&#x2F;irreducible-io&#x2F;apter-tree reply conradludgate 2 hours agoparentPetgraph uses a similar design (two vecs) for storing graphs https:&#x2F;&#x2F;docs.rs&#x2F;petgraph&#x2F;latest&#x2F;petgraph&#x2F;graph&#x2F;struct.Graph.... reply emmanueloga_ 7 hours agoprevA lot of people commenting about \"an index into an array is also a pointer\", I thought people commonly referred to integer indexes of this kind as handles, or index-handles? (like in this article [1]).This way of representing trees reminds me of two classic data structures: heaps [2] and disjoint-sets [3].--1: https:&#x2F;&#x2F;floooh.github.io&#x2F;2018&#x2F;06&#x2F;17&#x2F;handles-vs-pointers.html2: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Heap_(data_structure)3: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Disjoint-set_data_structure reply icsa 13 hours agoprevSee Aaron Hsu&#x27;s excellent descriptions (using APL):https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=hzPd3umu78g https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=X5_5MtOYNos reply mihaic 14 hours agoprevOne change I&#x27;d make to this structure would be to pack all the children of a node together. That way you could find out the list of all children of a node with a binary search, and they&#x27;d have some cache-friendly properties.Inserting a child would need a memmove in O(N), but if edits are rare after an initial build it wouldn&#x27;t be that bad. reply snovv_crash 10 hours agoparentYou could also have extra space allocated for where extra data should go. By aggressively rebalancing you should only need to do a full reallocation when the tree is actually getting pretty full. reply catlifeonmars 14 hours agoprevI feel like atree in TFA is just giving a name to something I do all the time when it makes sense to so. For example, I used something similar recently when building a ECS entity tree for a game engine. reply amluto 13 hours agoprev> Pointers are annoying anyway.But the parent indices are pointers. Not in the index-into-all-memory sense but in the offset-into-array sense. They’re smaller, type safe, inherently well packed, and can’t point outside the instance of the data structure in question if they’re bounds checked. But I would still think of them as a sort of pointer.So this is just a tree, with only parent pointer, in SOA form, and iterable (in no particular order). Which is maybe useful if you want that specific data structure.And it’s utterly useless if you want, say, a tree with children and need better-than-O(n) access to children. Which you probably do need. Of course, you can add child pointers in SOA form if you want.(SOA is Struct Of Arrays) reply alexchamberlain 13 hours agoparentI think you could achieve something close to (I haven&#x27;t sat down and thought about it) O(logN) with sorted arrays? You&#x27;d have the downside of inserting things in the middle, but I think that would be lost in cache efficiency elsewhere for many use cases. reply amluto 13 hours agorootparentA sorted array to less inefficiently iterate children of a node? This is getting ridiculous.The “no pointers” thing is cache efficient for three reasons:1. Indices can be smaller than pointers.2. The data is packed in memory. This means that cachelines will be full of relevant data, and adjacent cache lines (which are a bit faster than faraway lines) get used.3. SOA form is more or less cache efficient depending on what you’re doing with it.And that’s it.If you need child pointers, use child pointers. If you want a cache-efficient tree, use a cache-efficient tree, e.g. a B-tree or an appropriate variant. reply alexchamberlain 12 hours agorootparentSorted arrays can be navigated like a tree. For sufficiently randomised data, the middle element is approximately the middle of your data. You can use binary search. You can implement range iteration very efficiently. It&#x27;s not wholly ridiculous. reply amluto 12 hours agorootparentBinary search into a sorted array is slow. Intro algorithms classes might count operations, and you discover that about log_2(n) operations are needed, which is optimal in a certain sense.But those operations are horrible operations. Until you are log_2(cache line size &#x2F; element size) steps from the leaves, you are hitting a different cache line each time, and you’re doing a branch such that the next cache line you want depends on the branch result.So this is like log_2(n)-3 serial (cache miss, compare, branch, compute address operations). (Assume 8-byte entries — it’s much worse with bigger entries.) This not even close to optimal.You will find that, for reasonably large data sets (maybe a few hundred elements or more?), any cache-optimized searchable data structure will beat binary search by a large factor. And for small arrays (or the last stage of an optimized large structure), you want a vectorized linear search.Binary search is mostly nice because sorted arrays are elegant and binary search can be implemented in very little code. And it’s easy to explain and analyze. reply senderista 8 hours agorootparentEytzinger (\"heap\") layout packs the pivots as efficiently as possible, so cache misses are confined to the lower levels of the tree. But ordered iteration is slower, and of course it only works for static data. I agree that for dynamic structures I have yet to find anything more cache-efficient than a B-tree. reply GrumpySloth 8 hours agorootparentprevMeasurements suggest that binary search is at least competitive with linear search and is often the winner, so it’s a reasonable default[1].But naive binary search can also be improved upon by dividing the searched space into 3 subranges instead of 2[2].[1]: [2]:reply amluto 6 hours agorootparentTo clarify, I’m not saying that binary search is a bad way to search a sorted array. I’m saying that, if you have a bunch of data, you intend to preprocess that data and then search it repeatedly, that sorting it and binary searching is not a great solution. replymamcx 8 hours agoprevOh, cool.I made my own attempt at the same kind of idea at https:&#x2F;&#x2F;elmalabarista.com&#x2F;blog&#x2F;2022-flat-tree&#x2F;.Is pretty simple actually. What I have observed (and my tree exploit) is that most tree are \"too much\" and I only have cared by pre-order tree and \"sequentially\" scan is the major op.So, the major takeaway is that if your case is simple, Go! Go! Vec! reply ufo 9 hours agoprevI&#x27;m curious about the performance of separating the data from the pointers. On one hand, homogenous arrays pack better. On the other, the traditional version that packages the data and child pointers next to each other might have better cache locality. reply gumby 14 hours agoprevA pointer is simply an index into an array which is RAM. reply senderista 8 hours agoparentIt&#x27;s all just names, all the way down.https:&#x2F;&#x2F;www.dropbox.com&#x2F;s&#x2F;mmi46lxk8ipoci0&#x2F;Principles%20of%20... reply mrkeen 12 hours agoparentprevBut they point into your RAM, which means you can&#x27;t store them on disk or pass them over the network. reply edflsafoiewq 11 hours agorootparentSoA form also lets you trivially store additional data at every node, eg. if an algorithm needs a flag for each node, you just alloc an array for it. reply gumby 12 hours agorootparentprevA minor but legitimate benefit. reply zappb 13 hours agoparentprevPointers are a bit more abstract than that. Since each program has a virtual address space, and said address space is made up of memory pages, even raw pointers need to be translated to the physical address via TLBs. In that sense, indices into arrays are more like pointers than the other way around. reply lelandbatey 14 hours agoparentprevConceptually, yes. There are a lot of finer points to this concept though. One of the points most relevanthere is that accessing \"RAM\" is not _actually_ an O(1) operation, due to CPU caches which can speed up sequential access of \"close together\" data. Thus, if you manually ensure that data is \"close together\" (by putting it all in an array together), you can massively speed up your program in the real world because now all your keys&#x2F;data can be squeezed into the cache at once. reply gumby 13 hours agorootparentYou can allocate your data the same way, especially using custom allocators in C++. And every reference requires some arithmetic too, if you&#x27;re worrying about that.But my point is that storing them in another array doesn&#x27;t buy you a lot if you allow deallocations (you can then still have a use-after-free, or even read the wrong object) while if you don&#x27;t deallocate you might as well just use pointers.Just trying to understand the benefit of going to all this work. I can see the point in old FORTRAN code before FORTRAN 90 reply lelandbatey 13 hours agorootparentI think it&#x27;s mostly just an experiment, example, proof-of-concept or other \"toy\" implementation demonstrating&#x2F;exploring the idea. reply gumby 12 hours agorootparentYeah, no judgement on that.But I’ve worked with indexed classes (mixin class) to avoid pointers in the past and have never found them worth the effort. Since someone else is mentioning it here on HN I’m asking if there is an advantage over pointers that I don’t realise — if so I might be glad to take advantage of it myself. replystevage 13 hours agoprevInteresting the casual references to languages K, J and Q. I have never heard of them, and they are hard to google. Anyone know? reply spenczar5 13 hours agoparentOh boy, they are weird. They are all related to APL. Extremely terse, dense languges. Got some traction in actuarial and financial circles.Arthur Whitney is the origin of much of that family of languages. Bryan Cantrill’s interview with him is good: https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;1515964.1531242 reply mgaunard 13 hours agoparentprevK and Q are the languages behind KDB.K is the lower-level language and is a variant of APL. Q is the higher-level one, bringing in elements of SQL.J is another APL-like programming language, unrelated to KDB, by the actual creator of APL.All are easy to google by adding \"programming language\" to your query, and each has a wikipedia page. reply laszlokorte 12 hours agoparentprevThey are array languages. If you have never heart of array languages check out the code_report youtube channel. reply readthenotes1 13 hours agoprevThis reminds me of data structures used to represent data on the old tape devices reply jiggawatts 14 hours agoprevI was about to comment that this reminds me of Aaron Hsu’s Dyalog compiler, but it’s mentioned right there in the README as one of the inspirations.IMHO, compilers are about an order of magnitude slower than they could be, and this type of tree representation could be one key element for fixing that.One interesting approach would be to combine egg[1] with this style of vectorised trees for efficient optimisation passes.[1] https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2004.03082.pdf reply nurettin 12 hours agoprevWow this is pretty similar to how I used to store hierarchical data back in my qbasic days to solve minimax problems. Didn&#x27;t know it was called steven or whatever. reply rewmie 14 hours agoprevIt might be of interest to anyone that there&#x27;s an implicit binary tree data structure dubbed Eytzinger&#x27;s tree&#x2F;method that only requires a single vector.https:&#x2F;&#x2F;opendatastructures.org&#x2F;ods-cpp&#x2F;10_1_Implicit_Binary_...I dare say that no tree data structure beats Eytzinger&#x27;s method in cache locality. reply amluto 13 hours agoparent> I dare say that no tree data structure beats Eytzinger&#x27;s method in cache localityCache locality is good toward the leaves and bad everywhere else. This is why binary search on a sorted array is actually quite slow.ORC in Linux, for example, was first prototyped as a sorted array of little structures. It got much faster by adding an auxiliary index giving O(1) access to a credible starting point for a search. reply funcDropShadow 10 hours agorootparent> Cache locality is good toward the leaves and bad everywhere else.1. That depends on the operation performed. I&#x27;d say cache-locality is near perfect for depth-traversal.2. Whether the effective performance of the cache is good or bad depends on the alternative. If the alternative is adding two 64 bit pointer to every 32 bit value in the tree node. And each of those node may be spread through out the heap. Then this representation starts to look quite good. reply bjourne 7 hours agoparentprevVan Emde Boas trees are asymptotically cache optimal. In practice when cache sizes are known they may be slower than other tree types however. reply ulatich 14 hours agoparentprevThere is also the “Binary Ostensibly-Implicit Tree”. Like Eytzinger‘s tree&#x2F;method but without the need to pad memory. Generalises to n-ary trees too. reply dgreensp 14 hours agoprev [4 more] [flagged] dmw_ng 13 hours agoparent [–] It&#x27;s not just cache locality, but also at least the effectiveness of cache prefetching and the ability to use wider operations.. simple array loops are something compilers can often vectorize without assistance. reply dgreensp 9 hours agorootparent [–] Yes, but, operations like, “Does this node have children or is it a leaf?” should not require reading the entire array. Or, how many children; get the first child. Traversing the tree in pre-order or post-order doesn’t just have less cache locality than a B tree (say), it involves sorting a vector of vectors and is at best N log N and O(N) extra space. Deleting a node requires a O(N) writes. Every little operation is massively less local and less efficient.I stand by the lack of integrity that I got downvoted for pointing out! I’ll die on that hill. reply ninepoints 3 hours agorootparent [–] No idea why your parent comment was flagged. The proposed data structure is truly horrendous but somehow, this post remains on the front page... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apter Trees are a simplified representation of trees using two vectors, implemented in C++17 for faster and easier tree manipulation.",
      "The implementation offers operations such as adding items, finding parent nodes, retrieving node values, and more.",
      "Apter Trees have advantages such as adaptability, low memory usage, linear access time, and support for GPU utilization. Other tree implementations are also discussed in the repository, which is still a work in progress."
    ],
    "commentSummary": [
      "The article explores the implementation and efficiency of tree data structures, focusing on Atree, a pointer-free tree implementation.",
      "Discussions revolve around topics such as suitability for GPU programming, ordered traversals, cache-friendliness, scalability, and performance in software development.",
      "Participants debate the benefits and drawbacks of different implementations and data structures, including using indices instead of pointers, and highlight the importance of choosing appropriate data structures and algorithms for efficient searching."
    ],
    "points": 199,
    "commentCount": 94,
    "retryCount": 0,
    "time": 1702749168
  },
  {
    "id": 38668713,
    "title": "Intel, Samsung, and TSMC Showcase 3D-Stacked Transistors at IEEE Meeting",
    "originLink": "https://spectrum.ieee.org/cfet-intel-samsung-tsmc",
    "originBody": "SEMICONDUCTORS NEWS Intel, Samsung, and TSMC Demo 3D-Stacked Transistors The Big Three can now all make CFETs—next stop on the Moore’s Law roadmap SAMUEL K. MOORE17H3 MIN READ At the IEEE International Electron Devices Meeting this week, TSMC revealed their take on the CFET—a stack of logic needed for CMOS chips. TSMC",
    "commentLink": "https://news.ycombinator.com/item?id=38668713",
    "commentBody": "Intel, Samsung, and TSMC Demo 3D-Stacked TransistorsHacker NewspastloginIntel, Samsung, and TSMC Demo 3D-Stacked Transistors (ieee.org) 196 points by jnord 10 hours ago| hidepastfavorite63 comments tambourine_man 7 hours agoIt’s fun to be just a curious bystander for many years in this industry.Every now and then Moore’s law hits a roadblock. Some experts see that as a clear sign that it’s reaching its end. Others that it’s already dead, because actually, the price per transistor has increased. Others that it’s physics, we can approach Y but after X nm it can’t be done.Then you read others that claim that Intel has just been lazy enjoying its almost monopoly for the past decade and was caught off guard by TSMC’s ultraviolet prowess. Or people who really know how the sausage is made, like Jim Keller, enthusiastically stating that we are nowhere near any major fundamental limitation and can expect 1000X improvement in the years to come at least.Anyway, it’s really fun to watch, like I said. Hard to think of a field with such rollercoaster-like forecasting while still delivering unparalleled growth in such a steady state for decades. reply zozbot234 7 hours agoparentThe limitations are very real. Dennard scaling has been dead since the mid-2000s (that is, power use per unit area has been increasing, even though energy use per logic operation is very much dropping at leading edge nodes) which means an increasing fraction of all silicon has to be \"dark\", power-gated and only used for the rare accelerated workload. Additionally, recent nodes have seen very little improvement in SRAM cell size which is used for register files and caches. So perhaps we&#x27;ll be seeing relatively smaller caches per core in the future, and the addition of eDRAM (either on-die or on a separate chiplet) as a new, slower L4 level to partially cope with that. reply projectileboy 3 hours agorootparentI&#x27;m ignorant of this space, but it seems like the obvious solution for heat dissipation is to layer lattices and not solid layers, in order to increase the overall surface area of the chip. I assume the manufacturing is too difficult...? reply fooker 2 hours agorootparentThat&#x27;s one of the promises of 3D stacked transistors, yes. reply mikepurvis 6 hours agorootparentprevWhat if it went the other way and you got much larger die area dedicated to caches or even on-chip RAM, since that usage is relatively cheaper from a power&#x2F;heat point of view? Or is the process different enough between the two that it just doesn&#x27;t make sense to have them interwoven like that? reply treesciencebot 5 hours agorootparentThe point of SRAM, especially at the L1&#x2F;L2 level is having an extremely high BW and extremely low latency (a few clock cycles). So it is not really an option to put them somewhere else (although L3 and as mentioned other lower level layers) can and are already being put into either separate chiplets in the same PCB w&#x2F;extremely fast ring OR directly on top of the die (3D stacking). reply chongli 4 hours agorootparentYeah. The analogy for cache that I like to use is a table at the library. If you think about doing research (the old fashioned way) by looking through a library shelf by shelf and bringing books to your table to read through more closely. If you have a bigger table you can store more books which can speed your lookup times since you don’t need to get up and go back and forth to the shelves.But at some point making your table larger just defeats the purpose of the library itself. Your table becomes the new library, and you have to walk around on it and look up things in these piles of books. So you make a smaller table in the middle of the big table.Your fundamental limitation is how small you can make a memory cell, not how big you want to make a cache. That’s akin to making the books smaller print size so you can fit more on the same size table. reply DeathArrow 4 hours agorootparentprevIs it possible to use big and fat CPU registers instead of cache? There might be no wasted clock cycles and no delay. reply Nevermark 3 hours agorootparentA compiler AND processor design amateur here. (Latter in school.)Once you have enough registers, having more mean lowers active utilization for any given instruction (bad use of space, vs. fast pipelined access to cached stack) or higher levels of parallel instruction dispatch (much greater complexity, and even greater inefficiency for branching misses).Then you have to update instruction sets, which could be impossible given how tightly they fit in current instruction sizes.Ergo, increasing register banks is a major architecture & platform change from hardware to software redesign, with heavy end user impact, and a fair chance of decreasing performance.In contrast, anything that improves caching performance is a big non-disruptive win. reply als0 32 minutes agorootparentWhat about if you use register windows or special renaming of architectural registers to internal ones? https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Register_window reply Dylan16807 3 hours agorootparentprevRegisters are quite expensive in space and power, because multiple at once have to be accessible in many places.If you add more registers, the cost per register increases rapidly, and you very quickly hit your limits.If you make registers wider, that&#x27;s still very expensive, and you introduce extra steps to get to your data most of the time.So no, you can&#x27;t do that in a reasonable way. reply DeathArrow 3 hours agorootparentThank you! reply adgjlsfhk1 5 hours agorootparentprevthe caches are already ~75% of the space. you can&#x27;t significantly increase that. On die ram is also relatively unlikely due to process differences. my best guess is more 3d cache chips. if we can get the interconnects small enough and fast enough, I could see a future where the logic is stacked on top of a dozen (physical) layers of stacked cache reply iopq 3 hours agorootparentAMD stacked cache is a significant increase and gives a huge boost in certain gaming scenarios, to the point that it&#x27;s a 100% increase in certain games that rely on huge caches reply ksec 3 hours agoparentprev>It’s fun to be just a curious bystander for many years in this industry. Every now and then Moore’s law hits a roadblock. Some experts see that as a clear sign that it’s reaching its end......That is just mainstream reporting.If one actually went and read the paper referred or what the context was. It was always the same thing. It was all about the economics, all the way back from early 90s. We cant do x node because it would be too expensive to sustain it at a node every two years.Smartphone era ( Referring to Post iPhone launch ) essentially meant we ship an additional ~2 Billions Pocket computer every year including Tablet. That is 5x the most optimistic projection to traditional PC model at 400M &#x2F; year. ( Which we never reached ). And that is ignoring the Server market, Network Market, GPU market, AI Market etc. In terms of transistor and revenue or profits the whole TAM ( Total Addressable Market ) went up at least 10x more than those projection. Which is essentially what scale us from 22nm to now 3nm, and all the way to 2nm and 1.4nm. And my projection of 1nm by 2030 as well. I even wrote on HN in ~2015 I have a hard time to see how we could sustain this post 3nm. At the time when trillion dollar company was thought to be impossible.On the other side of things, the cost projection to next node ( e.g 2nm ), and next next node (e.g 1.4nm ) was always higher than what its turns out. As with any large project management it is was better to ask and project more in case shit hits the fan. ( Intel 10nm ) But every time TSMC has executed so well.So as you can see there is a projection mismatch at both ends. Which is why the clear sign of progress coming to end keeps being wrong.> and can expect 1000X improvement in the years to come at least.I just want to state that this figure keeps being throw around. It was Jim Keller comparing at the time Intel 14nm ( Which is somewhere close to TSMC N10 ) to hypothetical physics limit. At 3nm we are at least 4x pass that. Depending on how you want to measure it we could reach less than 100x by 2030.AI trend could carries us forward to may be 2035. But we dont have another product category like iPhone. Server at hyperscaler are already at a scale growth is slowing. We will again need to substantially lower the development cost of leading node ( My bet is on the AI &#x2F; Software side ) and some product that continues to grow the TAM. May be Autonomous Vehicles will finally be a thing by 2030s ? ( I doubt it but just throwing in some ides ). reply pjmlp 1 hour agorootparentHowever there is a big difference between those \"~2 Billions Pocket computer every year including Tablet\" and regular computers, so to speak.They are mostly programmed in managed languages, where the respective runtimes and OS collaborate, in order to distribute the computing across all available cores in the best way possible, with little intervention required from the developers side.Additionally, the OS frameworks and language runtimes collaborate in the best way to take advantage of each specific set of CPU capabilities in an almost transparent way.Quite different from the regular POSIX and Win32 applications coded in C and C++, where everything needs to be explicitly taken care of, which is what kind of prevents most of the cool CPU approaches to take off, sitting there idle most of the time. reply fl7305 9 minutes agorootparent> They are mostly programmed in managed languages, where the respective runtimes and OS collaborate, in order to distribute the computing across all available cores in the best way possible, with little intervention required from the developers side.I was under the impression that distributing workloads across many CPU cores (or HW threads) is done at the process and thread level by the OS? That gives managed and unmanaged languages the same benefits.Managed languages provide higher level primitives that makes it easier to create a multi-threaded application. But isn&#x27;t that still manually coded in the mainstream managed languages?I&#x27;m thinking of inherently CPU-intensive custom workloads. UI rendering and IO operations become automatically distributed with little intervention.Or am I missing something, where there is \"little intervention required from the developers side\" to create multi-threaded apps? reply oldesthacker 2 hours agorootparentprev> It was all about the economics, all the way back from early 90s. We cant do x node because it would be too expensive to sustain it at a node every two years.Totally agree.> AI trend could carries us forward to may be 2035. But we dont have another product category like iPhone.There will be fancier iPhones with on board offline Large Language Models and other Foundation Models to talk to, solving all kinds of tasks for you that would require a human assistant today. reply ChuckMcM 9 hours agoprevFun times.I think one of the interesting takeaways here should be that they have a 48 - 50nm \"device pitch\" which is to say the transistors are small in the XY plane there are pitch widths much larger than \"5nm\" or \"3nm\" (people familiar with chip production realize this but too often people who don&#x27;t have a very deep understanding of chip production are mislead into thinking you can put down transistors 5nm apart from each other)So from a density perspective, a perhaps 30 - 40% gain in overall number of transistors in the same space.Looking at the Intel inverter design, it looks like if they were willing to double the depth they could come up with a really compact DRAM cell. A chiplet with 8 GB of ECC DDR memory on it would be a useful thing both for their processors and their high end FPGA architectures. reply bogtog 7 hours agoprevGeneral question about semiconductors: Why is there so much emphasis on the density of transistors rather than purely on the costs of production (compute&#x2F;$)? CPUs aren&#x27;t particularly large. My computer&#x27;s CPU may be just a few tablespoons in volume. Hence, is compute less useful if it&#x27;s spread out (e.g., due to communication speeds)? reply sabbey 6 hours agoparentLight travels at one foot per nanosecond. So a processor one foot wide you&#x27;d expect to run at 1 GHz max. reply smolder 39 minutes agorootparentThat&#x27;s only if you needed a signal to cross the whole chip in one cycle. There&#x27;s no such limitation preventing a 1 foot wide chip from being filled with 5ghz cores on an appropriate ring bus. reply DeathArrow 4 hours agorootparentprevIsn&#x27;t Apple M3 larger in size than other Arm CPUs? Still, they don&#x27;t run slower. reply badrabbit 6 hours agorootparentprevOnly if it is so badly designed that data needs to cross the entire dye&#x27;s cross section. reply cma 6 hours agorootparentLook at how much space cache uses on a die. reply badrabbit 5 hours agorootparentThe core would use cache near it? Memory access delay such as caches is not considered part of cpu frequency either afaik. reply tux3 5 hours agorootparentCache takes X number of cycles to return a resultYou can make X lower by reducing the frequency (= having each cycle be longer)But apart for that, the main reason big chips would clock slower is power, not timing. If you have a lot of transistors all switching on a high voltage so that the frequency is high, you get molten metal and the magic smoke leaves.Big chips aren&#x27;t one big stage where light travels from one side to the other. But they are giant weaves of heating elements that can&#x27;t all run fast all of the time replybrennanpeterson 3 hours agoparentprevIt is?A factory makes transistors ,and if you increase a &#x27;node&#x27;, you make twice as much. If you do an amazing job, you might reduce cost 10%.So by far the best way to maximize value in semiconductors is to enable shrink.But you also just don&#x27;t hear it in the popular or even engineering press. Most manufacturers and designers look at a PPAC curve (power, performance, area, cost) and find optimal design points.As for spreading it out: the unit of production isn&#x27;t a wafer, it is a lithographic field, which is roughly 25*35mm. You cant practically &#x27;speead out&#x27; much more (ok, you sort of can with field stitching, but that is really expensive). reply iopq 3 hours agoparentprevBecause when you make it denser, you can cut the CPU into smaller parts, which decreases costswhen you make it less dense, it can clock up higher, but you will have fewer cores per mm^2AMD went with both approaches, where their hybrid CPU will have densely packed low speed Zen 4C cores and some high speed Zen 4 cores to boost at the highest frequency reply cubefox 1 hour agorootparentIncreasing density has caused chip cost per FLOP&#x2F;s to decrease exponentially over the last decades. But nowadays the price per transistor doesn&#x27;t go down as fast with increased density like it used to.E.g. new Nvidia GPUs are getting smaller for the same price, which means they are getting more expensive for the same size. At some point, the price per transistor will actually increase. Then Moore&#x27;s Law (the exponential increase in transistor density) will probably stop, simply because it&#x27;s not economical to produce slower chips for the same price. (Maybe the increased power efficiency will still make density scaling worth it for a little while longer, but probably not a lot longer.) reply jpgvm 37 minutes agorootparentThis isn&#x27;t due to fundamental cost increasing per transistor though, this is because NVidia changed their pricing strategy to decouple it from that.They are simply making greater % profit&#x2F;transitor. reply xhrpost 7 hours agoparentprevYou could always purchase a multi CPU system (effectively what you&#x27;re suggesting) from several years ago for much cheaper than modern hardware. If you&#x27;re using it regularly though, the electrical cost will eventually eat away any money savings vs the same computational power in a modern single CPU. reply Salgat 6 hours agoparentprevPersonal usage still relies on fast single threaded performance. As far as business usage, the cost is primarily energy which requires smaller node size for the same performance. reply noam_k 5 hours agoparentprevIn addition to the answers already given, there are defects during the process that are more likely to render your chip useless the larger your chip is. This is true for smaller chips as well, and often the design handles a defunct component, but you prefer minimizing defects per chip. reply DeathArrow 4 hours agoparentprevWhat do you mean by spread? Multi socketed mainboards?That would help only for parallelizable workloads. For many workloads is the single threaded performance that matters most. reply uluyol 6 hours agoparentprevDensity is one of the main ways to get cost savings. But there are others too, and there&#x27;s also a lot of hype around them. Chiplets for example. Or CXL for memory. reply wahnfrieden 7 hours agoparentprevYes, electricity doesn’t move instantly reply foolfoolz 7 hours agoparentprevreducing costs is nice for consumer… making cpu higher cost that goes brrrrt is better for business reply twobitshifter 7 hours agoparentprevI believe this was some of the advantage of the AMD Zen series of chips which moved to a larger die size from Athlon. reply nsonha 7 hours agoparentprevthe physical limitation of more CPUs: heat, which in turn downgrades performance reply mikepurvis 6 hours agorootparentBut I think the GP&#x27;s point is that heat is far easier managed when spread out over a larger area, so why all the emphasis on ultra tiny transistors vs just making a chip that&#x27;s two inches by two inches or something?And I think the main answer to that comes when you look at some of the discourse around Apple&#x27;s M-series chips, that doing a larger-die design is just way riskier: there are huge implications on cost, yield, flexibility, etc, so it was really something that Apple was uniquely positioned to move aggressively on vs a player like Qualcomm who needs to be way more conservative in what they try to sell to their main customers (phone OEMs like Samsung). reply sh1mmer 6 hours agoprevMaybe I’m missing something here, but wouldn’t heat become a bigger issue? Right now we have pretty intense cooling solutions to get heat off the surface of a comparatively thinner chip. If chips become more cubic how would we cool the inside? reply TOMDM 5 hours agoparentIf we keep going down this route I have to wonder if we&#x27;ll see something drastic in the cooling space.CPU dies are optimised towards being cooled from one side. I wonder if we&#x27;ll eventually see sockets, motherboards and heat spreaders shift towards cooling both sides of the CPU.Probably not, can&#x27;t imagine what a halfway feasible solution to integrating pin out and a heat spreader would be. reply mook 41 minutes agorootparentA couple years back they noted that they were looking at having essentially cooling pipes _inside_ the chips. There hasn&#x27;t been much noise in terms of commercialization, but that&#x27;s the kind of extreme they were looking at.https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;tsmc-exploring-on-chip-sem... reply teaearlgraycold 3 hours agorootparentprevA relatively easy win here is to have a “stock” set of fins built into the motherboard behind the CPU socket. The CPU could get attached to it with a pad or paste on the back. reply andrewstuart 8 hours agoprevWhat real world outcomes might we expect from this technology?Anyone know? reply thunderbird120 8 hours agoparentFaster chips which use less power to do the same amount of computation, same as ever.CFETs are very much real world technology which are on the roadmaps for all leading edge fabs. They&#x27;re the same as current gen FinFets and GAAFets a year or two from now in that they essentially just do the same thing as previous generations of chip tech except they do it better. reply WaxProlix 7 hours agoparentprevNovel cooling solutions, among others, one suspects. reply dcreater 8 hours agoprevSince it&#x27;s still a GAA channel, are the channel lengths sthr same as the latest 3nm node? reply anthk 1 hour agoprevAny EE member here? How&#x27;s photonics&#x27; computing going? reply 29athrowaway 7 hours agoprevWhat does heat do in these chips? How does it not melt? reply 0x1ceb00da 6 hours agoprevIs that going to increase the GHz as well or just the number of cores. reply rishav_sharan 6 hours agoparentDoubt that. Frequency will be tied to heat dissipation. And in a 3d stack, the heat dissipation of the inner transistors is going to be very difficult reply Dylan16807 4 hours agorootparentThese two layers are touching, nanometers apart. The heat dissipation will be the same for both layers. It&#x27;s still a simple problem of density, not a more complicated problem similar to trying to cool multiple dies.Edit: To throw math at it, silicon conducts at 2-4 Watts per centimeter-Kelvin. If we need the heat to travel an extra 100nm, and we&#x27;re looking at a 1cm by 1cm area of chip, then it takes 20 to 40 kilowatts flowing through that slice before the top and bottom will differ by more than 0.1 degrees. reply sundvor 5 hours agorootparentprevIn gaming, especially simulators: The 5800x3d and then the 7800x3d has proved how exemplary performance benefits can be gained in certain use cases, in some cases outperforming Intel with less than half the power usage (if not a third).Limiting overclocking is a price to pay for that, but you kind of get it back with the monthly power bills - and still going toe to toe with Intel in general. reply DeathArrow 4 hours agorootparentI doubt that for one user using one CPU the power bill is going to matter. People still use AC, washing machines and electrical heating consuming thousands of kw. reply sundvor 1 hour agorootparentIt&#x27;s a 100-150w difference. It all adds up.This also means you don&#x27;t need to run the fans in your system as high. reply georgeburdell 5 hours agorootparentprevLook at the specs for the Core series since 2007. The clocks have doubled. It’s not a fast increase, to be sure, but it’s happening reply rishav_sharan 6 hours agoparentprevDoubt that. Frequency will be tied to heat dissipation. And in a 3d stack, the heat dissipation of the inner transistors is going to be very difficult reply DeathArrow 4 hours agoparentprevGHz might not increase but maybe they can do more IPC by having a wider architecture. reply oldesthacker 2 hours agoprevInteresting bit about Samsung’s secret sauce:Samsung went even smaller than Intel, showing results for 48-nm and 45-nm contacted poly pitch (CPP), compared to Intel’s 60 nm, though these were for individual devices, not complete inverters. Although there was some performance degradation in the smaller of Samsung’s two prototype CFETs, it wasn’t much, and the company’s researchers believe manufacturing process optimization will take care of it. Crucial to Samsung’s success was the ability to electrically isolate the sources and drains of the stacked pFET and nFET devices. Without adequate isolation, the device, which Samsung calls a 3D stacked FET (3DSFET), will leak current. A key step to achieving that isolation was swapping an etching step involving wet chemicals with a new kind of dry etch. That led to an 80 percent boost in the yield of good devices. Like Intel, Samsung contacted the bottom of the device from beneath the silicon to save space. However, the Korean chipmaker differed from the American one by using a single nanosheet in each of the paired devices, instead of Intel’s three. According to its researchers, increasing the number of nanosheets will enhance the CFET’s performance. reply cubefox 2 hours agoprev [–] > Experts estimate CFETs to roll out commercially seven to ten years from now, but there is still a lot of work before they are ready.So the technology is still very much science fiction at this point. reply smolder 11 minutes agoparent [–] No, they&#x27;ve been made, just not via scaled-up commercial production process. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Intel, Samsung, and TSMC have successfully developed 3D-Stacked Transistors called CFETs, which are essential for advancing CMOS chips.",
      "This achievement is a major milestone in the progression of Moore's Law, which predicts the exponential growth of transistor density and performance in computer chips.",
      "TSMC demonstrated their implementation of CFETs at the IEEE International Electron Devices Meeting, showcasing the potential for future advancements in chip technology."
    ],
    "commentSummary": [
      "Experts are divided on the future of Moore's Law, with some believing it has reached its limits, while others suggest potential improvements like layering lattices in 3D stacked transistors.",
      "There is ongoing debate about whether to prioritize increasing cache size or utilizing larger CPU registers, with potential solutions including register windows or special renaming.",
      "The concept of using 3D cache chips is mentioned as a way to enhance capacity, while challenges related to reducing development costs and the importance of transistor density and size are also discussed."
    ],
    "points": 196,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1702768555
  },
  {
    "id": 38663733,
    "title": "Rethinking Education: Active Reading, Memory, and Innovative Approaches",
    "originLink": "https://www.dwarkeshpatel.com/p/andy-matuschak",
    "originBody": "Share this post Andy Matuschak - Self-Teaching, Spaced Repetition, & Why Books Don’t Work www.dwarkeshpatel.com Copy link Facebook Email Note Other Dwarkesh Podcast Andy Matuschak - Self-Teaching, Spaced Repetition, & Why Books Don’t Work 22 Share this post Andy Matuschak - Self-Teaching, Spaced Repetition, & Why Books Don’t Work www.dwarkeshpatel.com Copy link Facebook Email Note Other 1 1× 0:00 -2:22:39 Andy Matuschak - Self-Teaching, Spaced Repetition, & Why Books Don’t Work \"I was shocked with how intense, painstaking, and effective his learning process was\" Dwarkesh Patel Jul 12, 2023 22 Share this post Andy Matuschak - Self-Teaching, Spaced Repetition, & Why Books Don’t Work www.dwarkeshpatel.com Copy link Facebook Email Note Other 1 Share A few weeks ago, I sat beside Andy Matuschak to record how he reads a textbook. Even though my own job is to learn things, I was shocked with how much more intense, painstaking, and effective his learning process was. So I asked if we could record a conversation about how he learns and a bunch of other topics: How he identifies and interrogates his confusion (much harder than it seems, and requires an extremely effortful and slow pace) Why memorization is essential to understanding and decision-making How come some people (like Tyler Cowen) can integrate so much information without an explicit note taking or spaced repetition system. How LLMs and video games will change education How independent researchers and writers can make money The balance of freedom and discipline in education Why we produce fewer von Neumann-like prodigies nowadays How multi-trillion dollar companies like Apple (where he was previously responsible for bedrock iOS features) manage to coordinate millions of different considerations (from the cost of different components to the needs of users, etc) into new products designed by 10s of 1000s of people. Watch on YouTube. Listen on Apple Podcasts, Spotify, or any other podcast platform. Read the full transcript here. Follow me on Twitter for updates on future episodes. To see Andy’s process in action, check out the video where we record him studying a quantum physics textbook, talking aloud about his thought process, and using his memory system prototype to internalize the material. You can check out his website and personal notes, and follow him on Twitter. Cometeer Visit cometeer.com/lunar for $20 off your first order on the best coffee of your life! If you want to sponsor an episode, contact me at dwarkesh.sanjay.patel@gmail.com. Timestamps (00:00:52) - Skillful reading (00:02:30) - Do people care about understanding? (00:06:52) - Structuring effective self-teaching (00:16:37) - Memory and forgetting (00:33:10) - Andy’s memory practice (00:40:07) - Intellectual stamina (00:44:27) - New media for learning (video, games, streaming) (00:58:51) - Schools are designed for the median student (01:05:12) - Is learning inherently miserable? (01:11:57) - How Andy would structure his kids’ education (01:30:00) - The usefulness of hypertext (01:41:22) - How computer tools enable iteration (01:50:44) - Monetizing public work (02:08:36) - Spaced repetition (02:10:16) - Andy’s personal website and notes (02:12:44) - Working at Apple (02:19:25) - Spaced repetition 2 Transcript (00:00:52) – Skillful reading Dwarkesh Patel 00:00:52 Today I have the pleasure of speaking with Andy Matuschak, who is a researcher, engineer, and designer working on tools for thought. In addition to this podcast we did an interesting collaboration on Andy's YouTube channel which I encourage you all to check out, where I just watched Andy try to learn some new material. It was just an intro chapter of quantum mechanics. Honestly I was expecting to see some cool techniques or be impressed but I was way more surprised than I expected to be by the deliberateness and the effortfulness of the practice. It was 15 minutes a page in this textbook. And for every small thing that Andy thought, ”I don't fully understand this, the author's trying to say something here, he's trying to draw an analogy or relationship, I'm not sure I totally comprehend the relationship between classical mechanics equation and the quantum mechanics equation, the author thinks is analogous,” just really delving deep in that. I thought that it was really interesting that this is a way to approach new material. So in this conversation I'm looking forward to talking with Andy about not only that experience, but a whole bunch of his other research and the other tools he's built. Let me ask you this. That experience made me think that this is somebody who actually cares about understanding the material. Do you think people in general care about actually integrating and understanding the material they're consuming in books and textbooks? Don't you think they'd make more effort to actually assimilate that information if they cared to? (00:02:30) - Do people care about understanding? Andy Matuschak 00:02:30 I think the statement is just a little too general to comment on. I think it's certainly the case that most students don't actually want to do this because they're learning stuff that they don't actually care about learning or even if they do care about learning it, often there isn't a clear connection between whatever reading or activity they're doing in the moment and the thing that originally inspired them for the subject and what they actually want to do. So there's always something tenuous going on. On the other hand, it's amazing to look at subreddits and to look at the level of nerdy and fascination that will be brought to bear on gardening equipment or knots, for instance. People are competing to tie some very obscure 18th century knot or whatever, and they're flipping through almanacs from the period. So when people are interested and it connects to something that's truly meaningful for them, they really do want to absorb and we see that in their behavior. There is a second thing that I think is relevant. To explain this, I will reference Mortimer Adler and Van Doren's How to Read a Book, which is a great guide on serious reading. They consider the case of people who often have difficult or demanding books on their bedside table. So these are kind of aspirational, like, “Oh, I wish I could read King Lear. I want to be the kind of person who reads King Lear.” You put it on your bedside table and people will read it before bed. They'll find that they fall asleep while they're reading it, they're not really absorbing or understanding this book. It's not just an issue of memory, they simply are not apprehending the words on the page. The authors of How to Read a Book make the case that the issue with these people who are falling asleep reading King Lear is not that they don't want to stay awake and to really deal with that text, in many cases, it's that they actually don't know how. They butt their heads up against this very difficult wall of material. It's almost like a rock climber who's not very experienced going up against a wall that only has these really subtle notches. To an experienced rock climber, those subtle notches are like a ladder and they can get right in there and start making some progress and seeing what's up with this wall. But if you're an inexperienced rock climber, it just looks like a solid wall. The claim, maybe this is an optimistic claim, you can take me to task, is that there is such a thing as being a more skillful reader and being a more skillful reader will actually, in practice, in many cases, when the reading is aligned with your actual interests, produce a more serious, more understanding, forward kind of reading. Dwarkesh Patel 00:05:18 Right. So there's two models of why people might fail to retain the material they're consuming. One is they got it at some point, but they forgot it. And the other is they never understood it in the first place and they just never noticed that they never understood it. What I found really interesting was you going paragraph by paragraph, sentence by sentence, and asking “Have I got this?” This was material that I had tried to go through the week before. And there were things when you dwelled on something, I'm like, “Actually, I don't understand that either.” and I didn't notice I didn't understand that. How are you able to notice your confusion while you are going through it? Andy Matuschak 00:05:56 This is a kind of habit. It's a skill that can be built. Adler and Van Doren suggest that the first and most important rule of skillful reading, active reading, is asking questions and trying to answer them. If you just dwell on that, what kinds of questions should I be asking and how should I go about asking them? How should I go about answering them when the author isn't present? And so on and so forth. [Unclear] They also say conversely, and this is meant as a criticism, an undemanding reader asks no questions and gets no answers. I certainly have read many, many books that way, particularly before I developed this habit and I often found myself falling into that second category. The issue was not that I failed to remember things, but rather that my eyes just skidded across paragraphs without even realizing. Dwarkesh Patel 00:06:47 You're halfway through a chapter and you're thinking, what is the chapter about? (00:06:52) – Structuring effective self-teaching Ok, the broader question is — now that we have all these online resources, some of which you’ve helped develop like Khan Academy, it seems that the value of conscientiousness as a trait has dramatically increased. If you can motivate yourself to learn these things, the world is out there for you to absorb. What are the sort of design or UI or even content modifications that can be made to give you a conscientiousness boost? In the past you had a professor, you had peers, you had in-person deadlines to motivate you. Is there something equivalent to a pen and paper and how that boosts your mathematical IQ for conscientiousness? Andy Matuschak 00:07:33 Right. One enduring result in education psychology is that when you're doing a lot of cognition, metacognition is difficult. What I mean by that is when you're thinking really hard about the stuff on the page, it's very difficult for you to plan, to regulate yourself, to figure out what the best next action to do is, to reflect and evaluate on whether you're understanding things. All that gets harder as the material gets harder and as it gets less familiar. So one common thread, at least in learning science stuff, has been outsourced metacognition. Some of the ways we outsource that are actually very familiar, they're things like somebody gives you a syllabus and tells you what to read when and you reference that. That is a user interface, that is a design practice. If you're a self-motivated student, one thing you can do and that I've done, is just go appropriate a syllabus from some graduate level course that corresponds to the text that you're reading as that might be a good guide to what's most important and how to approach this. There are also lots of things that one can build directly into the interfaces. Just as one example, in Quantum Country, which was a textbook that Michael Nielsen and I developed to explore some ideas around augmented reading experiences, we embedded a bunch of review questions every 1500 words or so in this text on quantum computation. Our primary intention in doing this was to help people remember what they read. We had this theory that part of what makes it hard to learn a complex subject is that there's all these new definitions and notation and terms and things being thrown at you at once and you're being asked to combine these things, which are still unfamiliar. And so you're constantly having to retrieve these elements and struggling to do it, either it's taking a while or your success rate is low. That was our motivation but it had this other metacognitive benefit that was really important. When you’re asked these questions after reading 1500 words it is an opportunity for you to notice that you did not in fact absorb what was in that thing. Not that you don't remember but that there's a word in the question that is apparently important that you simply didn't even notice. And so not only does that give you feedback, it tells you that maybe you need to reread that specific section, but it may also change your behavior towards future sections. In interviews, readers told us that after they reached the first set of questions or a particularly difficult set of questions, they found themselves slowing down and reading more attentively or actually realizing that their reading practices were ineffective in general. In the way that you were mentioning towards the start of the conversation. There's been a bunch of research on adjunct questions, questions that go along with a text, and they have all kinds of effects. The adjunct questions have the kind of effects on forward material I was just describing and they also have the effect of making you reflect on what you've just learned. And in addition to the questions being asked, you might find yourself pondering, “Well, I'm being asked about this. But why does this matter?” Dwarkesh Patel 00:10:58 Yeah, on the point of adopting a syllabus from somebody else. One problem you might have as a self learner is you have some goal, a reason for learning, and then you start thinking, “Well, do I really need this chapter? Do I really need this content?” At this point, you're doing the metacognition that you were trying to use a syllabus to avoid. Andy Matuschak 00:11:16 Yeah. Dwarkesh Patel 00:11:20 If you are trying to self learn and there is a resource that is a close approximation of the syllabus you want. Should you just think “Hey, I don't know why I need this chapter. I'm just going to go through it.” or should you use your own judgment there? Andy Matuschak 00:11:33 This is a pretty classic issue for learning in general. You have this problem where to bootstrap yourself in a domain you have to outsource the question of what is necessary to know. You might know, for instance, that you really want to build a model that can generate images given descriptions, like Midjourney, but you don't even know what you need to study to do that. So you pick up some textbooks on machine learning. You're outsourcing the answer to this question to the author. What is necessary to know to build things? Maybe you can find a book that's actually labeled “What you need to know to make an image generating model” But even then, you're outsourcing the answer to the author. You can take that answer as a start and treat it as tentative and revise it iteratively. And as you become more skilled you can lean less on it. And you probably should. I think a very common mistake that people make is to feel that they need to do the thing the right way and that is exhaustive and completionist. If they fail because they find themselves bored or unmotivated because the material doesn't actually seem to relate to what they want to know, but they're just going on faith that, “Well, if I follow what the author says, everything will be good.” Anyway, they find themselves having trouble for that reason, and then they just stop. This is bad. They would be better off just skipping around according to their interest and continuing. One other thing I'll say about this is that the role that these syllabi play is as a scaffold. This is a term of art from learning science, but it relates to the thing we're familiar with. If you want to get higher up a building, you may not be able to climb it yourself, but you can build some scaffolding around it and then suddenly you can reach that top shelf or the top of that building. The scaffolding is ubiquitous in education. We give you simpler versions of questions first, that's a kind of scaffolding. We partially work the answer first, that's a kind of scaffolding. We give you worked examples first, where we might ask you to predict the next step of the work example. That's also a kind of scaffolding. Where the metaphor breaks down is that once you become more capable, we try to remove the scaffolding. It's called fading. The idea is that once you have solved a lot of calculus problems, you don't need half of it worked out and you're just filling in one of the blanks anymore. And in fact, doing that would not be as effective a learning experience. If I'm studying something in computer science, which is a domain that I know really well, I don't need those syllabi, not in the same way for most subjects, and I think that's mostly just because the amount of cognitive demand that's placed on me by the subject is just much lower than it is for other subjects. So much of it is familiar already that I can deploy my own planning more effectively as I go. But it's also the case that because I know so many things about the subject, I can do a better job from the get go of making a plan. Because making a plan requires modeling a path or predicting a path or saying, “Well, I guess I'd need to see how this connects to that or something like this.” And if your destination and your starting point are very far away, then you can't necessarily see all the things in between or how to draw those lines. But if those things are only a couple hops away, you can maybe infer pretty accurately. Dwarkesh Patel 00:15:22 Right. I guess this maybe implies that if you do want to learn about a subject, it might just be helpful to just do an Intro to X subject course or textbook, not necessarily because it is instrumentally valuable to whatever problem you're interested in but because it'll give you the context by which to proceed on, the actual learning. Andy Matuschak 00:15:45 That's true. It's also the case that you don't even know all the stuff there is. This is another key problem and this is another reason why we outsource stuff. There's a fundamental tension in unschooling, for instance. Just let the kids pursue what they're interested in. That's cool. There's a lot of good things about that. But say that a kid's true passion turns out to be ocean geology or something and they're in a landlocked country and there's just no one around them that talks about ocean geology, then they're missing out on some great opportunity. But if the school had a program where they are bringing in guest speakers and then there's a special lecture on ocean geology from this person and it lights up the kid's world, even if they wouldn't have chosen that lecture, that's a good thing. Dwarkesh Patel 00:16:33 Yeah. Unschooling is actually an interesting subject to talk to you about. (00:16:37) – Memory and forgetting But before that, I want to ask you about this excerpt from a Paul Graham blog post titled How You Know and it says, “Reading and experience train your model of the world. And even if you forget the experience or what you read, its effect on your model of the world persists. Your mind is like a compiled program you've lost the source of. It works, but you don't know why.” So it's a compiled program, you don't need the source code. Is it okay that we're forgetting so much of what we're reading? Andy Matuschak 00:17:05 What he's saying is true, to some extent, whether or not that extent is sufficient is going to depend a great deal on the situation and on what you need. If your aspiration actually depends on having a deep, detailed understanding of the material, then the imprint on your worldview or on your automatic responses made by the book may not be sufficient. On the other hand, if what you want is to absorb a lot of different ways of looking at the world, knowing the details of these isn't necessarily important. Maybe you just want to know that Confucius emphasizes community and society as a moral patient in contrast to the individualism of a bunch of humanist philosophers. And if that's kind of the level that you feel like you need to make decisions in that domain then I think that's fine. Very practically speaking, it's funny that he uses the word compile, because one of the prominent theories of cognition, that is how we come to know and learn things, is this theory called ACT-R by John Anderson. A key part of it is this process that he calls knowledge compilation. This is the process by which we take individual facts and turn them into higher level patterns that we can generalize and apply in more contexts. And I think that's what Paul is gesturing at. By reading a book which contains a story or a case study you learn to generalize to some extent and you apply it in other contexts when it seems relevant. The reason why I bring up Anderson's theory is just that he has a bunch of specific claims about what's necessary for knowledge compilation to happen and what you'll be able to do as a consequence of certain degrees of knowledge compilation. I think he'd probably respond to this by saying that — actually, in order to effectively compile things that you've learned into schemas that will match feature scenarios effectively, you need to be exposed repeatedly to those things, you need to use them, you need to do a variety of things that will basically show your brain that is relevant to apply these things in combination. And simply reading probably won't do that. But if you read and you have a lot of conversations and you're in a context where it's demanding and it's drawing on what you read, then you may naturally do that kind of compilation step. Dwarkesh Patel 00:19:41 I've actually been thinking about this in preparation of talking with you. I've had the pleasure of talking to a lot of interesting people across a lot of different fields. When I look back on some of my old conversations, I notice that I actually had a lot more context at the time I interviewed them and had done all the prep than I can remember now. Sometimes I'll listen back to a conversation and I won't even remember the content in the conversation. And I remember thinking after the conversation, I knew so much more about this field than was compressed into this one hour interview, right? I had to prep other things that might come up. And afterwards I'm like, “I don't even remember the things that were in this one hour.” But then the other part of me thinks, “Well, I'm getting better at doing the podcast”, that might imply that I've picked up something. But it is a shame that I didn't have some sort of rigorous practice throughout the time of retaining the material that I was keeping. Andy Matuschak 00:20:31 Well, yeah, I expect the main [unclear] in which you're getting better, is actually not really about any of the details of those materials. I think it's about your practices as an interviewer, the way that you generate questions, you probably have a bunch of patterns, whether you know it or not. You read a thing that a person has written in hopes of generating good questions about it. And even though you maybe don't have this habit for textbooks yet, of constantly demanding things of the textbook, you have started to develop this for essays or blog posts that interesting people you're interviewing have read. And to point to this Anderson theory, in the course of repeatedly doing that, you've made parts of it automatic, so that you don't need to do it consciously, you can focus more on the material, you can probably take on more difficult material, or actually understand material at a higher level than you could have before, because less of yourself is engaged in this question of how do I make the questions from the material? Dwarkesh Patel 00:21:36 Yeah, I certainly hope so. Otherwise, there's a question to be asked of what I've been doing all these years. Having interviewed some of these people who are infovores and have consumed and continuously consume a lot of content, they don’t have a note-taking practice. This is something you also noticed and pointed out in your notes. Tyler Cowen, for example, I don't think he has any sort of note-taking practice. He just devours information. What is your theory of how these people are integrating things that they're reading? Andy Matuschak 00:22:07 Tyler's a good example. I think he's actually a little easier than some others we might discuss. So, let's talk about Tyler for a second. One of the other things that's so interesting about Tyler is his writing obligations. This is a man who's blogged every day since 2007 or something and has a weekly Bloomberg column, something like 1500 words, and also has published something like a book a year for a decade or more, and occasionally publishes some academic articles, plus like a bunch of other collateral. That is notes. And I think it's also important to note that like the way that Tyler writes these blog posts and the way that Tyler does these columns and even the books is very different from the way that many other book authors work. Tyler’s blog posts often have this a real first draft mentality to them. He's just thinking out loud and he's got decades of practice thinking out loud and like writing down a decent take the first time. And so he gets something pretty good, the first time, much of the time. And that works for him. So that is a note, right? Your initial thoughts on the subject is what you would write in a note. Dwarkesh Patel 00:23:24 Yeah, one of my former guests, Scott Young, was comparing Bryan Kaplan’s books and Tyler Cowen's books and he said, when you read a Brian Kaplan book it's like a chess game. If you try to move a pawn up on this case for education, I've got this rook that I can move here. With Tyler, it's more like he’s shooting the shit on a subject. Andy Matuschak 00:23:43 Bangladeshi train stations Dwarkesh Patel 00:23:44 Yeah, right, right. On a separate question, do LLMs make memorization more or less valuable? There's a case you can make for both. But on net, is it more important to have more Anki cards in your deck now that GPT-4 is out? Andy Matuschak 00:23:58 Maybe this is a good time to talk about what memorization is or what it's for. We could use that word to refer to the practice of learning more trivia. For instance, a thing that I and some people I know have done is, we’ve gone through a book called Cell Biology by the Numbers, which says all of these things like, how big exactly is a nucleotide? Like how much volume does it take up? It's kind of helpful occasionally to know that it's about a nanoliter. And that can help you model things. So you can just commit all of those things to memory, right? That's one kind of memorization. And we could talk about how LLMs affect that. But I just want to make the case that so much of what you do and experience day to day is memory bound, or is memory influenced in important ways. For instance, your ability to understand a difficult argument, even in the course of a text, is memory bound. Some of that's working memory. But your ability to understand an argument that has many steps in it, more steps than you can keep in your working memory, depends on your ability to think of some of those steps in terms of some stuff that you already know, so that you can kind of reduce it or abstract it. Likewise in creative work, there's a bunch of studies trying to catalog case studies of how it is that people have flashes of insight. It's a little hard to talk about that but one of the things that's a pretty consistent source of insight for people is noticing a surprising connection or a surprising contradiction. It probably feels pretty familiar, right? You're reading through the newspaper and you see that people have finally figured out how to do X and you're like, “Wait a minute, that means if I combine it with this other thing, like we'd be able to do Y!” or something like that. Now that's only possible if the other thing is in your memory. If you have to think to look up the other thing, the newspaper wouldn't seem so salient to you. Early on in my time in Khan Academy I learned a whole lot of details about the education market in a very thorough way using memory systems. This let me be in high level executive kinds of conversations where we're trying to figure out strategy stuff and somebody would propose a particular direction and I could say things like, “Well the total budget spending for instructional materials is this and that market is growing by this percent per year and 10% of students in the US are in this place” and so on and so forth. Basically I could evaluate ideas on the fly in a way that others couldn’t. Anyway, this and other things are just part of my rant about how people in general under-appreciate the role that memory has in our lives. So just to come back to the question, explicit memorization or explicit making sure that you can recall the thing reliably. We can test it against these things. So for the case of the creative instinct, for instance, noticing the contradiction, noticing the connection, I imagine that we will have future notebooks that will do some of this noticing with us and that will decrease our need to be able to rely on our own sense of salience or something like that. But I guess I don't know how much. My own experience coming up with weird ideas that feel very new is that it feels very personal, it feels very [unclear]. I often haven't been able to describe, textually, the constituents of the thing very clearly. There's just kind of a feeling that something in this general direction is connected with something in that general direction, or there's a tension. That makes me a little hesitant. LLMs depend on our ability to externalize things and to make them legible. Back to the learning point about the role of memory. If what you're trying to do is to understand something pretty difficult, your ability to understand that thing is still absolutely going to be bound on your memory of the constituent material. Dwarkesh Patel 00:28:11 Do you think there's pedagogical value in forgetting? Some anecdotal or unrelated evidence is in neural networks where sometimes you can improve performance by pruning some of the weights. Obviously, we forget things and we don't remember everything. When we sleep, we lose a lot of our memories. Is it possible that by not getting the details and only getting the gist, that actually helps us better generalize the insights we're getting from text and things like that? What do you think of that way of thinking? Andy Matuschak 00:28:42 Yeah, it could be. Memory is very connected to attention. And we can't attend everything. So one of the roles of memory is to help guide us to the things that are important. Maybe I happen to know that the magnitude and energy of an electron volt, that's something I can draw on because of the memory system stuff, but I also don't want that to be front and center in my mind all the time. I don’t want it to be hyper salient the way that I want some very important design principles to be. So yeah, there's some role there. There's also some theories that the reason we have forgetting is that our environment or ancestral environment was very traumatic. So we would like our episodic memory in particular to maybe not be all that faithful. I actually don't know the status of those theories. Dwarkesh Patel 00:29:30 Probably why you forget dreams as well, right? Dreams are pretty traumatic. If you thought of them as the same as a real life experience. Andy Matuschak 00:29:37 Yeah. Another weird thing about memory is that as far as we can determine, memories aren't lost exactly, at least not completely. There's a series of interesting experiments that people have used to demonstrate that decades later, things are still there. If you can cue them right, people can bring things back, even things that they feel are lost. And of course, you can also cue people in ways that are hallucinatory so you need to be careful about that. I guess the reason why I bring that up is that it flies in the face of this view that there's a limit. One of the things that I think is kind of weird about this memory system stuff, or like memory champions, or something like that is “Oh, if you do these things, will you start to forget other normal human stuff?” And what's weird is, no. I've been doing this memory system stuff for years and I just know more stuff now. This is aligned with the experimental literature, which seems to suggest that, there's probably upper bounds but we're not close to them. Some of these memory champions have memorized maybe two orders of magnitude more things than I have practiced. Certainly people who are multi-lingual have really, really absurd numbers of things memorized. So there isn't a resource management argument. Dwarkesh Patel 00:30:59 If there isn't, why do we forget so many things? Is there some reason the brain just forgets some of the things we’re coming across? Maybe we were training the ancestral environment to find certain things salient that don’t just map onto books? Andy Matuschak 00:31:16 It’s a good question. We're getting to a part of the cognitive science space that I'm less familiar with and also that I suspect we simply know less about. But let me just riff a little bit. One of the things that we sort of know is this idea of spreading activation. When you go to try to look something up or when you try to deal with a particular situation, there's something almost kind of like DNS exchanges or like routing on a network or something where we start from some point that is like a stimulus, and speaking very informally, we kind of expand outwards from there and there are effectively like weights on those connections. By tuning those weights effectively, we route the packets on the network effectively. Memory is encoded in these weights, at least partially. So if you didn't forget things, then you might just have this weird cacophony on the network and in particular, what's salient? What to do next? Which response seems most appropriate to this question? You might answer those kinds of things very effectively, because all this stuff is coming up for you, that is much less relevant. One of the theories about how well we remember stuff in what circumstances is actually called predictive utility theory. And it suggests that the probability of retrieval of a particular item in a given situation actually does correspond with basically a model of to what extent the brain predicts it will be useful. Dwarkesh Patel 00:32:48 Right. And then the prediction but doesn't necessarily map on to… Andy Matuschak 00:32:54 Doesn’t necessarily, exactly. So when you repeatedly access something, when you practice retrieving it, the prediction of the utility of the thing goes up. And when you do it in a variety of situations, it goes up across a broader distribution. (00:33:10) – Andy’s memory practice Dwarkesh Patel 00:33:10 Okay, so this is interesting. When did you start your memory practice? Presumably it was after after Apple? Andy Matuschak 00:33:14 Yeah. Dwarkesh Patel 00:33:15 Okay. Let me ask you this. At Apple, you were in charge of a bunch of important flagship features on iOS and I'm guessing other things. Presumably you didn't have some sort of practice but since you were encountering these things day to day, that natural frequency and way in which problems came up, did you have a worse understanding of those problems then compared to now, knowing what you do and having the practices you do, you're able to comprehend now? I don't know if that question made sense. Andy Matuschak 00:33:45 No, that's a great question. Here's a fun thing. I was much better at what I was doing then than I am at what I'm doing now. That's pretty funny. It was just totally different. Let's talk about this a little bit. This feels very, very juicy for me. Most of what I was doing was engineering. Some of it was very difficult engineering, but mostly engineering, and mostly on things that were fairly well understood. I wasn't trying to decide what should be done, sometimes I was from a technical perspective, but certainly rarely from a product perspective. It was rarely a relevant question for me. I was a somewhat design minded engineer and I did a bunch of engineering and design-ish things on tasks which were set out for me. By the time I joined Apple I had been programming for a really long time, 13 years maybe, and programming in Apple's ecosystem for probably two to three thirds of that time. So everything was just really familiar. It was mostly flow all the time, every day. I was just in it. I knew the stuff that I needed to know. I was very well practiced. And the space didn't change that much. Most engineers at Apple most of the time are not pushing the frontier of what is known, like trying to discover. They're doing very difficult technical work, mostly applying things that they already know and understand quite well to problems which are usually not always pretty well understood. Memory was essential to me doing that job well, but I had already built most of it by the time I got there. I'd already built just tons of stuff for Apple's platform. I had to learn a lot of stuff. I learned a ton of stuff about the internals of those systems. But because I already had such a rich understanding, both of Apple's platforms and of computer science and engineering in general, I had this really rich network for stuff to slot into. Learning stuff is easier when you have other stuff to connect to. It's a nice principle. Metacognitive load on me was lighter because others were figuring out what we should be doing. Just like by contrast, now I'm doing research, I'm trying to discover things that are not known. I'm trying to make things that didn't exist. The hard questions that I answer are mostly, what should be done or what should I do? And that question is not just a technical one of how I should implement this feature that needs to get built, but what intervention on a reader should be taken? That requires synthesizing lots of different unfamiliar literature. Dwarkesh Patel 00:36:30 There's two different threads I want to go on. Maybe I'll just mention the other one. This is also related to the thing we're talking about a few minutes ago with LLMs. Swanson-Linking. Swanson was just somebody who read the medical literature and he was just familiar with a lot of esoteric results. Different things would come up and he would be able to figure out what different things are connected. For example, he noticed in one case that headaches are linked to some other symptom and that other symptom is linked to magnesium deficiency. Apparently a whole bunch of people's headaches were solved once they were given magnesium supplements and he noticed that connection. Again, this is the kind of sort of combinatorial thing that you wouldn't notice otherwise. But on this subject itself, there's this natural way in which you're able to get up to speed in all the things that are happening at Apple. Is it possible and maybe advantageous to do similar kinds of things in other fields? For example, instead of doing an explicit space repetition system when you're trying to absorb material from books, you just read a cluster of books and hopefully things would just come up that are relevant to get in again. Or is there a value in having explicit practice of setting up cards and so on? Andy Matuschak 00:37:50 Yeah, again the answer is going to be it depends. Maybe the most familiar example of what you're talking about is immersion learning a new language. Immersion learning is like a great thing and it's going to be more interesting and more effective than doing space repetition practice. It's going to be integrative. It's going to be socially based. So there's a bunch of stuff about social learning that's relevant. A problem though is that say you decide you want to learn Swahili today and you go down to the local Swahili community center and you're like, “Cool, I'm going to immerse myself” Good luck. You can't even get started. So through this lens, explicit practice is a way to bootstrap yourself. All of the best pianists at sight reading that I knew in university played with churches. They were so good at sight reading because they had to show up every Sunday and they're playing a different thing. New hymn every Sunday. So this is immersion also. Over time, they're learning all these cadences and these things that are really common and whatever. But you can't show up and be the church pianist every Sunday in the first place if you don't already have some decent foundation. This is a bootstrapping argument. One role for explicit practice of this kind is to get yourself into a position where you can more naturalistically reinforce. But there are still going to be instances where naturalistic reinforcement isn't going to work. For example, the linking that you brought up, one issue for doctors is rare diagnosis. So if it's only going to be once every couple of years that you see a patient that's going to present with these symptoms, that's not going to be frequent enough to naturally reinforce your memory of that. You're going to need some out of band mechanism. And unfortunately, I think for many kinds of creative leaps and creative insights, that may be closer to the regime that we’re in. Dwarkesh Patel 00:39:50 Yeah, that makes a lot of sense. Where in many fields, the things you're regularly doing is the thing you need to reinforce. It makes a lot of sense that if you're a researcher, the long tail of events that might come up is a thing, it might happen once every few months but the regularity is not a thing that matters, right? It's [unclear] on your work. (00:40:07) – Intellectual stamina Here's a question I actually have. When we were doing the quantum mechanics textbook, it was like three hours and afterwards, I was just exhausted. I was actually surprised that you went the entire three hours without interruption. Afterwards, I was packing up and you're like, “Hey, I'm about to actually go to my piano lesson.” I was so confused at how you had the stamina to keep going. Is the stamina just inherent in you? Or is that something you did to develop? Andy Matuschak 00:40:39 One of the things that I think is funny about stamina is first off, there's some kind of weird grass is always greener kind of situation where, I often feel struck by other people's stamina and feel like I have very little of it. I struggle with energy. I've actually written extensively about all my struggles with energy and ways of managing energy. I spent a lot of time thinking about it, managing the energy levels and structuring my day around it. So I think there is something where one often feels maybe lower stamina than one actually is because one misapprehends other's stamina. Okay, in that particular situation, how do I explain why three hours of studying, etc. First off, social. So if I were alone and studying that book for three hours, and I weren't effectively trying to perform for you Dwarkesh, it wouldn't have been nearly as energizing for me. And I definitely would have taken breaks. I still would have been able to go for three hours, I think. Part of the reason for that is that it's simply way less hard than things I normally do. In some sense, learning quantum mechanics should be much harder and it kind of is cognitively demanding in a lot of ways. It's much more cognitively demanding in kind of a direct way than what I actually do day to day. But it's much less demanding on what William James calls the Energies of Men, which is something like a life force that permits you to act according to your will or something like that. Maybe it's gumption, maybe it's willpower, maybe some people call it [unclear], these aren't all the same thing exactly. But sitting and staring at a page and deciding what you should do next on a research project is incredibly draining on that resource. The sitting and not knowing is the hardest thing that I do in my work. It's a wonderful vacation to be presented with, “Oh great, somebody else is going to tell me what to do. This is great.” Dwarkesh Patel 00:42:40 So although it might be less demanding than our usual work, it is definitely more demanding than the way in which I or most people approach textbooks or other material in the sense that, I would just read through and then once I get to the exercise, I'm like, “let's see what I didn't understand.” Whereas just the attention and the intensity to go through sentence by sentence and constantly being paying attention seems to be way more exhausting. Andy Matuschak 00:43:07 Yeah, I mean, so this is sort of true. It's definitely the case that I will occasionally do some of this before bed reading, where I think “Oh, let me just do a little bit more.” and it's basically useless. But I want to make the case that there is a kind of pocket that you can fall into. Maybe you call it flow where the demandingness that you're bringing to bear is matched to your ability, the book is not overwhelming, you feel like you can make your way through it, and this is actually more engaging. I occasionally will find myself reading as an undemanding reader and finding my attention kind of slipping because I'm just not that attached to the text emotionally, I'm kind of reading dutifully, I'm like trying to get through it. That sometimes produces an adversarial aspect where the text is in my way or it's kind of something to be accomplished. And often I will find that I need to bring more gumption to bear to power through and make myself sit there and keep flipping the pages than I need if I actually just open my curiosity and attention and really start engaging the book. (00:44:27) – New media for learning (video, games, streaming) Dwarkesh Patel 00:44:27 There are ideas that people have come up with for different pedagogical tools, which are mediums that give closer connection to the reader. One is, you have some sort of fiction account, where a concept is introduced and reinforced, or you have a video game with characters you care about. As far as I know, there isn't something that has really taken off using these sorts of new mediums. Why do you think that is? Is it just an inherent limitation of everything but text and lectures or people just haven't given it the right content and design? Andy Matuschak 00:45:00 Yeah, I'm fascinated by this question. Let's see, I can say a few things about it. One is that I would argue that one medium has taken off in an absolutely enormous way and that’s video. People love video. People will watch Grant Sanderson spend an hour going through some explanation of an esoteric math problem, people who would never crack a Springer graduate textbook in mathematics or something like that. The issue is that they will not walk away from that interaction with much understanding but they're much more engaged. So that's cool. That's suggestive and it suggests the question, is there a version of that which actually produces detailed understanding? Maybe one approach to producing that might be like a game. My favorite example of this is The Witness by Jonathan Blow. Have you played The Witness? Dwarkesh Patel 00:45:52 No. Andy Matuschak 00:45:54 I think The Witness is an absolutely extraordinary work of art. It's a game that has no text, at least no text that's relevant to the game elements. In kind of classic Myst style, you wake up on an island, and figure out what's going on. And the game proceeds to explain to you, without using words, but just by shaping your environment, a series of extremely complex mechanics of a system that exists in this world. You learn a bunch of stuff and it gets to the point where it feels like you're in conversation with the game's designers. It's like, “Ah, he's asking me to do this here.” No one's asking you, right? There's no text, but you can feel that you are being asked. You perform some interaction in the environment and you feel that you have answered the game's response in kind. This is very, very interesting. It's like a medium of action. Some people have tried to make educational games, games that are explicitly about arithmetic or something, Jonathan Blow's game is not about that. It's the mechanics that you learn are they're about the environment. I don't think anybody has yet really succeeded in doing this about explicit subjects. There are, for instance, things like Kerbal Space Program. Maybe people learn some things about project management or orbital mechanics from that. Zachtronics has a bunch of games that are sort of about assembly language, roughly speaking. Maybe you can learn some things about that. The issue seems to be that games are ultimately in aesthetic form. The purpose of the game is to have an experience that feels a particular way. And so they're sort of serving a different purpose than Grant's videos or a text. Grant's videos are also serving a different purpose from the text. The text you might pick up because you're like, “I want to be able to build a robot.” So you pick up a textbook on robotics or something. And so is there something that you can pick up that's sort of like a game in so far as it's an active environment that you use in a similar situation to “I want to learn to build a robot?” Maybe kind of? We don't quite have those yet. We have some things that are kind of like that. I don't know if you've seen From Nand to Tetris. This is a very interesting project that's kind of along these lines. And what characterizes it, like games, is doing. It's active. So when I was asking all those questions of the book, that was active learning, active reading, Nand to Tetris is naturally active. So this is a course in which you kind of start with basically nothing. You start with memory and you build a virtual computer and build Tetris. You build a processor and stuff. The whole thing's active. The whole time you're making the computer grow. This is doing a similar job to the question asking that I was doing, except that you don't have to regulate all of that yourself. The regulation, the choice of what activity to do, is in the course, is in the structure of the material. I think some kind of mass medium that is like that is waiting to be created, but that can be applied in many, many circumstances. We have the non-mass medium version of it already and it's apprenticeship. If you want to be a good yoga teacher, you go hang out in yoga studios. If you want to be a good surfer, you go to the beach when the other surfers are there and you participate peripherally and you talk to them and you learn about their tactics. They might give you some feedback eventually and you'll start to participate less and less peripherally over time and eventually you'll be part of the community. This isn’t a mass medium. We can't print billion copies of it like we can with a book. Dwarkesh Patel 00:49:46 What is the experience of watching George Hotz on the stream code up tiny grad? How does that compare to just being in an office with him? Because even if you're in an office with him, there would be constraints on his time and how much engagement there would be. Why isn’t video a scalable way to increase apprenticeship? Andy Matuschak 00:50:07 I'm actually incredibly excited about streaming as a medium for this. We're gesturing at a particular kind of learning that needs to happen. It's often called tacit knowledge. One of the things that you have to learn to do as an engineer is to learn to deal with 100,000 different weird situations where something is not behaving the right way. Eventually you learn pattern recognition, you learn ways of dealing with this. Much of this is not described in any book. It's not explicitly taught. You just learn it by doing it over a long period of time. By watching George do it, I think that people do absorb stuff. They can absorb some of that knowledge. That's part of how apprentices absorb that knowledge. There's a few things that are missing. You're not getting feedback. There's a whole lot of chaff there. There's a whole lot of stuff that probably isn't all that meaningful. It's also true for apprentices. I'm pretty excited about streaming videos. I've complained loudly that there aren't more designer streamers. One of the things that I think is really interesting is that we have some disciplines like programming where there are a million books on courses about how to learn to program. They don't give you everything you need. There's this tacit knowledge stuff that you need to develop. If you work through these courses, if you go through the MIT OpenCourseWare for computer science, you'll be able to build some stuff and you'll be able to lift yourself up. This is not true in all domains. In particular, design, but lots of other domains that are like that, like musical composition, architecture, something like this. Nope. It's normally done in studio classes. Lots and lots of hands-on feedback. The feedback is highly contingent. It's highly contextual. We just haven't figured out how to communicate this. It's good to see lots of programmer streamers, but I really want to see the streamers in these other domains. Dwarkesh Patel 00:52:10 On the point about more programming books. Ironically, the reason why there's some more resources on programming is that it's just so legible, but it already makes it easier to understand in the first place. You just have this reinforcement. Nand to Tetris is like a video game analog to learning, maybe not just programming, but how things in the internals of a computer work but programming has an element where it already feels like a video game. I have a friend who has a sort of intense sort of manic energy, and he used to be addicted to video games when he was a teenager, and now he just stays up all night in these coding binges. It's just the same part of the brain. Are you optimistic about things like video games and fiction being able to work and feel as though they're not already kind of like a video game, like programming? Andy Matuschak 00:52:56 I think what makes programming feel like a video game is this sense of instantaneousness, this sense of direct contact with the environment. You're learning about a conceptual world, but that world is right underneath your hands, and as you manipulate it, you're constantly getting this feedback, the red squiggly lines, you’re pressing command R regularly, and you're seeing it fail, and that feels great. There's this feeling that's very common for programmers, and it's laden with doom. The feeling is it's like 9 p.m., and you've been working on a thing all day, and it's almost working. It's almost working. And you know, if you just debug this one thing, then your project will be done, and you'll be able to go to, so you're like, “Well, I'll just stay up and I'll debug this one last thing.” And then you start debugging it, and you get it, and you solve it, and that feels great then immediately you run into one more thing, like, “Oh, it's almost running all the way through, it's almost going end to end,” and you're like, “Well, I'll just stay up a little bit longer.” Before you know it, it's 2 a.m. You keep going because it feels so good. You feel the sense of forward progress. You're not just staring at a wall. For the programming problems where you are at a brick wall, it doesn't feel like this. It feels bad. Can every field be transformed into something where you can feel the sense of forward progress? You can get this rapid feedback cycle. I think that's really hard. It's not clear to me that some fields can be transformed in that way. I think we can get a lot closer in most cases than we're at right now. What's hard about designing a user interface is that often there's this feeling of exploring a combinatorial search space. Programming often feels like a search problem too. You have a sense that there's some right way to solve the problem. There might be some set of right ways to solve the problem, and you're looking for it. And you have some heuristics that guide you to, like, “Oh, this might be a dynamic programming problem!”, or this might be something that is solved well by separating concerns or something like that. Design often feels less like that. You have those heuristics, too. You have those patterns, too. Often it just feels like, “Nope, I just need to try 300 things.” The core action of Figma is to duplicate. You have an artboard, you tried something, and that didn't work so you select it, and you press Command D. And what you end up with, and when you look at Design Twitter, it's just all these screenshots of people's Figmas with a million artboards. They're just trying stuff. And you don't have this feeling, or at least I don't, and I think many designers don't have this feeling of progress. You're just kind of exploring parts of the search space, and you're learning that parts of the search space don't work. And eventually you stumble on one that does, but you don't have this feeling of getting closer often. Often there will be like weeks that go by without feeling like you're getting closer, because what you're doing is just kind of like narrowing the search space. Dwarkesh Patel 00:56:22 Interesting. Although there are people who are obsessed with Design. What is the sort of loop that keeps them obsessed with a process that doesn't feel intrinsically forward feeding? Andy Matuschak 00:56:34 So to some extent, I think they are skillful. The people that I know who are like this, it's a combination that they’re often skillful and the nature of the problems that they're solving are highly tractable. An example of a kind of thing that designers will often rabbit hole into is designing a poster. It actually often used to be kind of a cliche that at Facebook, there were all these posters up on the wall of the office. Very, very elaborate, beautifully designed posters for a talk that someone was coming to give at Facebook. Why did somebody put all this effort into it? Well, it feels really good, because a poster is really constrained, it’s finite, it's ephemeral. You can start it and yeah, there's a search space, but you can find a decent part of the search space pretty rapidly. And once you're there, there's this beautiful and very enticing feeling of turning the crank and like making it better and polishing it and trying this or that. But when you're trying this or that, like, all of the options are kind of okay. And you're kind of trying them out of curiosity, or like maybe it can be even better. And that's very different from the kind of design where you're just like, “I simply don't know how to do this.” And I think it's part of why those designers loved making those posters. It's a snack. It's a treat. It's also something they get to control whereas ordinarily, they don't. Dwarkesh Patel 00:58:08 Yeah, just don't tell the manager how many software engineering hours were used up in the poster designing at Facebook. Andy Matuschak 00:58:19 Well, no software engineering. It's only designers. But for the software engineers, code golf is the equivalent, right? Dwarkesh Patel 00:58:25 What is code golf? Andy Matuschak 00:58:27 You know, in golf, you try to get the lowest score. So code golf, you try to solve the problem as minimally as possible. Like, “Ah. I don't need this. I can combine this. I can do it in three lines. If I use Haskell, I can do it in one line.” That's a kind of thing programmers do that's like this. But just endless refactoring is another thing that's kind of like this. You have the thing working, but it could be more beautiful. (00:58:51) – Schools are designed for the median student Dwarkesh Patel 00:58:51 Right. So it seems like the tools and the ideas you're developing seem especially geared towards very intelligent and very motivated students. If they would be different, what would the tools that you would develop for a median student in the education system look like? Both in motivation and in other traits? Andy Matuschak 00:59:14 Yeah, they'd be super different. I kind of got out of the educational space in part because I don't like the framing of this problem. For the median student, the education system mostly wants to make the student do things they don't want to do. It's not about helping them achieve their goals more easily or more effectively. For the most part, it's about achieving goals that aren't theirs. Obviously, that's not always true. But for the median student, it kind of is true. When I was at Khan Academy I was kind of thinking about this problem. At Khan Academy, we were mostly thinking about not just the median learner, but like maybe the 25th percentile learner. One of the angles that felt most relevant, maybe not from an efficacy perspective, but for me, from like a breaking out of this, getting them to follow goals that aren't their own perspective, was to focus on inquiry learning and to focus on transforming the learning experience into something that actually is related to their goals. That is, we're asking questions that are authentically interesting, that they authentically want to answer, and that they can participate in in a way that feels natural. We did a lot of experiments with dynamic media, representations of things. The idea being that, you've probably seen these like plastic blocks or things that people can play with when they're kids to get an idea of numbers and number systems. Kids will play with these things unprompted because they're fun. It's just a pleasure to handle them. It's a pleasure to manipulate them. When you have them in hand, it's very natural to suggest, “Ah, can you make a pattern like this? Why can't you seem to make patterns like that? Why is that?” Cuisenaire rods is the name for a set of 10 rods that have basically unit length 1 to 10, and they're all different colors. You can do things like take the rod that represents 8, and put 2 of the rods that represent 4 up next to it, and show that this one you can divide into 2 rods effectively. But then if you take 7 there is no other pair of rods, for the same color, you can put it next to it. So, you get these different patterns and things kind of naturally suggest themselves by experimenting with these materials and having conversations with people around these materials. One of the things we were interested in was, are there things that are like that that are more advanced topics? Can we create something that's kind of like those rods, but that is about a more advanced topic in math or about debates in history or something like that? One of our tactics was to lean heavily on social interaction. People like talking about stuff with people, if it's a real conversation. For the same reason that I had to use less willpower to study that quantum mechanics text, because you were there with me, a student who's engaged in a real activity with a peer will need less willpower as well. They'll also learn from their peers if you structure things right. Social learning becomes interesting. But I think at a high level, I mostly have abandoned this question to others. Basically everyone in the educational space, this isn't totally true, but like 90+% of people in the educational space are focused on the bottom quartile, not even the median. And there's a good reason for this. Many people who are in education are motivated by arguments of equity and opportunity. They want everybody to have the opportunities they had. They're very motivated by the injustices that they see in the differing access and the differing support that different people have. And they're very motivated by the very real disadvantages that accrue to the bottom quartile performing students. It's also true that the marginal impact that you'll have in that student's life will be much greater, probably, than the marginal impact on say an 80th percentile performing student or so the argument goes, like that student will be fine, which is probably true. Dwarkesh Patel 01:03:57 But there's a big marginal difference between fine and supercharged. Andy Matuschak 01:04:04 Yeah, that's true. Anyway, I say all this to say that I understand why the vast majority of people in education are focused on what they're focused on. And I think it is good. And I'm glad they're doing it. I have mostly decided to let them do that. I’d focus elsewhere. Dwarkesh Patel 01:04:22 Yeah. No, I see tremendous value in focusing on the cool new shit that's coming out, where's that coming from? And what's the way to increase that? It's interesting to know that the same tools might not just work across the spectrum. Andy Matuschak 01:04:38 Yeah. Part of the trouble here is that the cool shit is very likely to come from students who are performing at the 20th percentile in school, because they're disaffected and bored and none of this stuff matters to them, right? Part of the trouble here is that by opting out of helping these people learn, there are all kinds of interesting inventions that could probably occur that aren't occurring. So I don't quite know how to contend with that. I guess basically I'm trying to bite off a piece of a problem that feels maybe tractable. (01:05:12) – Is learning inherently miserable? Dwarkesh Patel 01:05:12 Once all the tools are built, when you're at the end of your career, is the learning process supposed to feel fun? Or does it have to feel fun? Is there an element of even when all the tools are there, that there's just like a level of David Goggins, this is going to be miserable, but I've decided to learn this in this way and I just had to go through it. Andy Matuschak 01:05:33 Where does misery come from? I'm asking this honestly, not really rhetorically. Let me try to answer my own question. Let me say first off that I am, broadly speaking, very opposed to what I understand to be David Gogginsesque attitude towards almost anything. In this particular instance, I think what I think is something like, if I ask why is it miserable to learn a particular subject? The answers that come to mind are things like, first off, I don't care about this subject. And I think that's not what we're talking about. You're asking about a world in which these great tools exist and someone's using one of these tools to try to do something they really care about. So another reason why it could be miserable that I think is pretty common is that you have some idea about, you're not going fast enough, or you're failing, or you're struggling, and the misery comes from resisting that. It comes from feeling like you're doing poorly and you shouldn't be doing poorly, it's bad that you're doing poorly. And maybe you're feeling fearful that others are going to judge you or you don't have enough time or something like that. And I think that's basically like an emotional problem that needs to get healed, rather than like a practical problem with learning. In the case of something like organic chemistry, where you truly do just need to learn 200 names or something. One answer is that it can be done very cheaply using modern memory systems. Organic chemistry students suffer through this and they don't need to. But even with modern memory systems, you're probably going to spend a total of 100 or so minutes across some weeks, studying all of these formulae. That still is unpleasant so can that be resolved? And I think the answer is yes, actually. I was thinking about this in the context of the Cell Biology By The Numbers book I was telling you about where there's all of these things like the volume of the nucleotide is a nanoliter. To study the flashcard “What's the volume of a nucleotide?” is not terribly pleasant. I'm not sure it constitutes suffering exactly. It's fine. I'll do it while waiting in line. But I think there is a better version of that, which is like solving an interesting Fermi problem which involves that term. So something like, if I have a vial of the COVID vaccine, how many copies of the COVID RNA are likely to actually be in it if the vial is a milliliter large? That's a fun little question and I can enjoy sitting and noodling on that. And in doing so, I will need to retrieve the volume of the nucleotide to help me make that approximation. So I think there's moves like that you can use to paper over any remaining stuff that feels kind of necessarily unpleasant or rote. Dwarkesh Patel 01:08:30 I'm actually surprised to hear you say that because one way in which I read some of your stuff is that this is actually a way of endorsing the traditional way of thinking about education, but using new tools to get the traditional ones. To give you an example of what I'm talking about, you go back to a headmaster from the 1900s, and you say, is it important to have the taxonomy of a subject memorized? You say, of course it is, that's why you’re going to spend a year memorizing the taxonomy. And then you would say memorizing is actually important so that you have a dictionary by which to proceed on the subject. So in those ways you have new systems for doing that same kind of thing. And the reason in this particular case, I was expecting you to say, No, you have to be disciplined if you decided to learn something. I expected that in the case of the three hours of intense learning followed by an intense piano session, you were just really tired at the end and you're like, “But no, this is something I have to do this evening.” So yes, I'm actually surprised to hear you say that. Andy Matuschak 01:09:33 Yeah, no, I really enjoy this tension. I'm probably reacting to the Goggins reference with a bit of an over extreme overcorrection or something but this really is how I feel. And I feel this tension all the time. The histories in educational psychology that I'm most aligned with are the most robotic, authoritarian kind of histories, and also the ones that are most kind of unschooling and Montessoriesque. I really have a ton of sympathy for elements of both of these directions and there's kind of a weird synthesis of this in my head that I can't fully externalize. I guess part of what I'm saying is aspirational. It certainly is the case that I do in practice use willpower to make things happen. Just as an example of something totally contrary to everything I was saying, I use a tool called Beeminder, which charges me if I don't do certain things. This sounds kind of military, but it's certainly more authoritarian than this kind of freewheeling butterflies kind of gesture I was making a moment ago. And I use it to make sure that I do my memory practice. Shouldn't my memory practice be so joyful? It's at the center of my research, right? It should be the most interesting, exciting part of my day, but often it's not. And so I use this to do it anyway. So there's some tension here. I think I do want to say the reason why I'm willing to endorse this headmaster's view about the taxonomy has to do with the price. I did a bunch of memorization in high school, and it was very inefficient, and it was very uncertain. It was emotionally difficult because I wouldn't even feel confident that I'd learned the stuff. I didn't know what it was to learn something reliably, to be confident that I'd be able to recall it. And it was hugely time consuming because I didn't have techniques or tools. And now, part of why I respond so favorably to just learning the taxonomy is that, for me, it's just trivial. Like, yeah, sure, whatever, throw it into the deck. It'll consume a total of 15 minutes over the next few weeks and then I'll know it. It just doesn't cost anything. Other things in learning do still have real costs and those are maybe more difficult to negotiate. (01:11:57) – How Andy would structure his kids’ education Dwarkesh Patel 01:11:57 Actually, this is maybe a good place to ask you about unschooling and your attitude towards it. Somebody on Twitter had this question, how are you structuring the education of your kids as they're growing up? Andy Matuschak 01:12:10 Well, okay, so to be clear, I don't have kids. Dwarkesh Patel 01:12:14 Right. Hypothetical kids. Andy Matuschak 01:12:17 So yeah, so you're gonna hear the foolish response of a person talking about what one would do hypothetically. This is very difficult. The school, of course, has many purposes other than instructional, right? It has a social purpose, it has a societal purpose, it has a behavioral purpose, and it also has like a pragmatic purpose of basically babysitting. Those things can be unbundled. I think it's pretty interesting to consider that. If I actually did have a kid, I would probably consider that project pretty thoroughly. I think it's pretty likely that some kind of homeschooling situation would occur. It probably wouldn't be [unclear] the teacher, but it would probably be the people I would hire. I have some resources. I'm not wealthy but I have some resources, that is maybe a difference. During the pandemic, I was struck by a company called Schoolhouse, which is now defunct, started by Brian Toball. The idea was that he noticed that people were getting together in pods, right? That was the thing we did during the pandemic. And in particular, they got together in pods with their classmates from school, maybe five or six kids. And some of these pods started hiring elementary school teachers who were not working because of the pandemic. And the elementary school teachers would come to the backyard of one of these people's houses, and the five or six kids would get together with the elementary school teacher, and they do stuff all day. Buying this one teacher's time split five or six ways was actually really very tractable. Say you want to pay the person $50 an hour, maybe that seems reasonable for a teacher, this is not that hard to do, and actually costs substantially less than a private school. I think Schoolhouse costs something like a fifth or whatever, the cost of an elementary school. Once you get to older grades you may need specialists. It's actually not clear if you do. My friend, Alec Resnick, is working on a very interesting school called Powder House in Somerville, Massachusetts, that does something like the model I just described, where you have adults who are in more of like a coaching role, and they aren't necessarily domain specialists, but they'll connect people with domain specialists. Anyway, I would explore something like that model. I'm sorry, this is a little bit vague. If you want to ask about something specific... Dwarkesh Patel 01:14:38 Sure, let me ask you a more specific question. This child grows up and is now 12. At this point, you have taught arithmetic, reading and everything. Do you proceed and say you have to learn your biology, you have to learn chemistry, or do you just say, what are you interested in? Are you interested in Roman history? Oh, let's learn about the aqueducts. Or is there an actual curriculum that proceeds until they get to college? Andy Matuschak 01:14:59 Yeah, this is really challenging. One of the heroes of the reform school movement is this philosopher named John Dewey, and he has a lovely book called Experience and Education, sort of written near the end of his time, looking back on all of his efforts to reform schooling in a kind of unschooling-ish direction. He was never as extreme as that, but broadly looking for freedom on the child's part. And he makes this wonderful argument that because these kids don’t have a fully developed prefrontal cortex, certainly don’t have a fully developed kind of sense of self, to let them do whatever it is that their whim commands them to do in any given moment is actually not freedom, but rather is chaining them to whatever that impulse is. It makes them the subject of these tides of impulse. And I think that's a pretty compelling argument. It doesn't authorize tyranny, but it also suggests that, you know, you got to be a little bit skeptical about the planning or the plans of 12-year-olds, I guess. How skeptical should one be? I don't know. I think I would probably have stronger opinions on that if I had a 12-year-old. But my instinct as a foolish non-parent would be something of a mix. I would be interested in exposing the 12-year-old to lots of topics and possibilities. I would be voluble in expressing the consequences of any particular actions. Like if they just want to compose music all day, we could talk about like, well, what does that mean? What kind of life does that look like? I would try to be non-coercive in this as much as possible. And I think to some extent, the child should be allowed to feel the consequences of their choices. This is complicated by the fact that, again, I'm not wealthy, but any child of mine would have chances. If they made some weird choice about a career path when they're 13 and so they didn't get into Harvard or whatever, that would be okay. They could be 24 and finally figure it out then, or 32 and finally figure it out then. It would probably turn out fine. This doesn't seem like reliable guidance. You should notice I'm feeling very confused about it. Dwarkesh Patel 01:17:36 Yeah, no worries. So one question I have is historically, and maybe even to the modern day, it seems like improving education has been a very intractable problem. And you did reference this earlier when we were talking about gearing towards median student versus whatever percentile you're working with. But I don't know. Do you feel like there's been progress even in the percentile you're gearing your stuff towards? And if not, what is the explanation for the relative stasis? I mean, this is something you talked about. We have so many new tools with IT. What explains the broader sort of stagnation here? Andy Matuschak 01:18:09 The funny answer to your question is actually there's been a ton of progress. Actually, things are pretty good. I think the stat is that in 1900, 6% of teenagers graduated high school in the US. Now, that doesn't mean that 94% didn't have an education that we would regard as a high school education, but it roughly means that. Now, these people are homeschooled. It's also the case that a high school education meant something lesser back then. A substantial fraction of high schoolers now study AP courses and complete them in high school. That's at the high end. On the low end, illiteracy was a very live situation 100 years ago in the US and is emphatically not now. Now it is the case that something like 10 to 15% of adults, depending on which polls you use, maybe would struggle to perform simple kinds of number manipulation or reading or writing kind of tasks, but our bar is basically moved. It used to be like, can you read it all? These tasks are maybe a little artificial. They're maybe not relevant to their day to day, and that's actually why they're experiencing this. The number of people, the fraction of the population who graduates at 17 or something, knowing a particular amount of stuff has basically moved up monotonically. And this is mostly about the bottom portion of the population. It used to be the majority were effectively uneducated past age 10 or something other than informally and in their trade. And really the story of the 20th century has been in part one of mass education. Part of why we have a service economy, an IT economy, is that basically all of our population is educated to a particular level. If you look at the national tests of fourth, eighth and 12th grade math and language proficiency, you'll see really pretty slow movement in the 75th percentile and practically none at all in recent decades. But you'll see absolutely enormous movement in the bottom quartile. And so in some sense the story, especially the last 20, 30 years, has been closing what's often called the performance of achievement gap where certain groups, part of underfunded schools, or who might have households that are unsupportive, or difficult, were just not having anything like the educational attainment of their peers. And that story has changed. Dwarkesh Patel 01:21:02 One thing I'm curious about is that every other part of the distribution has been moved upwards. Has the ceiling been raised significantly? Andy Matuschak 01:21:10 Depends on what we mean by the ceiling. Dwarkesh Patel 01:21:14 Because you can go back like hundreds of years and the most learned people around. It's just incredible you look back on how many books Thomas Jefferson read. There's some story where Kennedy was hosting a bunch of Nobel laureates in the White House in 1963 or something. And he says, this is the greatest collection of genius and insight and wisdom that has been collected into this room ever since the time that Thomas Jefferson dined alone. Andy Matuschak 01:21:48 Right. I think it's very hard to raise the ceiling. The ceiling has aristocratic tutors. The ceiling has whatever family dynamics and heritable propensities produce tremendous intellectual greatness. Early 20th century schools produced von Neumann. Right. And it's certainly not at all clear that they're now producing more von Neumanns or something like that.In fact, von Neumann's productions seem to have probably very little to do with any kind of mass schooling that we would recognize. As far as the very top, I think that's difficult. We're talking about an institution that was created for the masses. I guess there have always been people who have been using resources outside of those kinds of systems. So the mass system doesn't seem to help those people, I guess. That doesn't seem surprising. Dwarkesh Patel 01:22:45 By the way, on the von Neumann thing. Okay, a mass system doesn't help them. What is the production function for a von Neumann? Andy Matuschak 01:22:53 Yeah, so lots of people have studied this. I actually am not a student of Von Neumann's history. I know that many of his peers, the 20th century greats, got something like aristocratic tutoring or came from small Eastern European incredible schools that there's stories about these things. I actually don't know them. I'm sorry. Dwarkesh Patel 01:23:14 I mean, I’m sure you’ve heard about that one high school. Andy Matuschak 01:23:18 Yes. Yes. Dwarkesh Patel 01:23:20 Okay, interesting. Are we getting worse at the von Neumann production or is it just static? Andy Matuschak 01:23:26 Well, maybe. I don't know. So let's see. Here's the theory that seems kind of plausible. If someone was going to have aristocratic tutors in the late 19th century, would they now go to a fancy private school and would that experience now actually be less good for them? I don't know. I think it's probably more likely that they'd go to the fancy private school and also still have fancy tutors and then go to a very exclusive university where they're going to get a bunch of highly hands-on kind of interaction with professors. Dwarkesh Patel 01:23:58 Although the reason that might not be the case is the opportunity costs for people who might become teachers or aristocratic tutors is much higher now, whereas the kind of person who would be, your tutor can now directly be making lots of money on Silicon Valley or Wall Street. Andy Matuschak 01:24:13 That's interesting. Okay, so that would be an argument that maybe it's not so much about the 20th century that we've gotten worse about this, but more like over history. Maybe Aristotle was a tutor to Alexander the Great, and now Aristotle would be like a full professor and wouldn't need to take that job. That might be so. It may be the case that some tutors have been priced out of the market, but it's not clear to me that the most expensive tutors actually would be the best. There is a bunch of empirical research on tutoring, and one of the questions they ask is, what kind of experience level do the tutors need to have? And it's interesting, how far you get in tutoring efficacy when the tutor doesn't necessarily know anything. Just having another warm body there actually contributes a very large effect. I mean, things get better as you get an expert. And I also have a kind of healthy skepticism of these studies. I think part of the role of having Aristotle as a tutor is communicating a worldview. It's not something that would show up on a test or something that these studies would be measuring. And so having an extremely inspiring individual might actually be the important component, and inspiring is going to be highly correlated with expensive, I think. Not necessarily, I don't know. That feels complicated. Dwarkesh Patel 01:25:32 I mean, especially today, the material is available. What the tutor is bringing is the inspiration and the motivation. Not exclusively but one of the large parts. Andy Matuschak 01:25:41 That's right. They're not really responsible for instruction. I'll also say that I know lots of people who have postdoc tutors right now. These people, as graduate students, they're very pleased often to have a $60 an hour tutoring kind of commission. And that's a little sad. But, you know, the pool of available postdocs to hire as tutors is very large now compared to how it would have been 100 years ago. The pool being bigger doesn't mean that the top 1% are getting more though. So I think that's undecided. There is a question of, have teachers gotten better at their jobs over the last 50 years? And there are some ways in which maybe they have. There's been a bunch of projects of trying to disseminate certain research results, ways of instruction that are more effective in other ways. For instance it's better to interleave stuff than doing blocked units where it's like, “Okay, like, we're going to talk about the Civil War, and then we're going to talk about women's suffrage.” It's somewhat far apart but it's better to kind of weave these things into each other, not just in history, but in general. So that kind of dissemination has been happening more systematically in the last few decades. I'm unaware of any kind of studies or results trying to establish anything about the efficacy of teachers now versus long ago. Dwarkesh Patel 01:27:10 Well, I'm sure you've seen the claim that one of the consequences of the very unforeseen circumstance of the mid-20th century, was that one of the very few occupations an intelligent woman could pursue was teaching. And now that other options are available, which is obviously hugely good, you know, there's other competition for the same very intelligent woman. Andy Matuschak 01:27:34 Oh, that's interesting. I haven't heard that claim. Yeah, I'd have to think about it. I guess it's not clear to me how much intelligence matters. If you want to think of that as some kind of separable quantity. Dwarkesh Patel 01:27:48 Or whatever trade is relevant to just that. You just had a population that was hostage to either housework or teaching. Andy Matuschak 01:27:56 I guess what I'm saying is something like, if that were true, and there are like a bunch of people who are now astrophysicists or something, it's not clear to me actually that they would have been good teachers. Being a good teacher is often about empathy and effective communication and care. It's very personal. It's very intimate. You need to understand the subject but to teach a 15 year old or something, you actually don't need to understand it at a postgraduate level necessarily. It's very interesting to see that there's a bunch of studies of the impact of domain knowledge on teaching efficacy. I've read some in math, I'm sure they exist in all fields. And one of the things that comes up is like, if you aren't very familiar or comfortable in math, then you will struggle specifically to do inquiry oriented classes, classes that are more about creative ways of thinking with math, or open ended problems, as opposed to like here's how to do this algorithm. Because to conduct those kinds of classes, you have to be able to think on your feet. You pose a difficult question to which there may not be just one appropriate answer and your students will throw all kinds of stuff at you. And you have to be able to take that stuff and integrate it and show how one student's answer relates to another student's answer and show how those conceptions can be built upon in order to produce some useful understanding for what you had in mind. Anyway, this kind of improvisation requires a mathematical familiarity and ability. But I don't think it requires anything like extraordinary ability. Dwarkesh Patel 01:29:39 Yeah, but more than the extraordinary have been pulled out of teaching as a consequence. Andy Matuschak 01:29:43 Yeah, I guess I'm just wondering what the correlation is. If it's the case that actually effective teaching is mostly about empathy, then maybe it's anti-correlated. Like the people who are going to be good particle physicists are actually like they wouldn't make good teachers anyway. Maybe. (01:30:00) - The usefulness of hypertext Dwarkesh Patel 01:30:00 Interesting. Why hasn't hypertext changed how people write more? Often I write a blog post and I actually do wonder how much different it is with the knowledge that I can add footnotes and I can link to things. I'm actually kind of a fan of how Wikipedia organizes content. It is genuinely surprising how often the best explanation of a subject is just this resource that is trying to explain every single subject. Because there's this practice of you don't need to do exposition in every single topic. You can just hide it behind links and things like that. Anyway, so why hasn't hypertext changed online writing more? Andy Matuschak 01:30:34 This is a really good question. I think the reason why Wikipedia works as well as it does is that encyclopedia entries are already forced to stand on their own. And that was true before hypertext existed. In fact, encyclopedias were already hypertext-ish before there was hypertext. There are some other interesting kinds of hypertext that existed pre-computers. There is this very interesting book called The Syntopicon from Adler. If you wanted to understand what classical authors had to say about a topic like the father's responsibility to a daughter, you can look that up in The Syntopicon and you will get references across Rousseau, through the Bible, and so on and so forth. And those are kind of hyperlinks. They were printed on dead trees, but you're expected to get the books down and look up the appropriate pages. The Syntopicon wasn't that successful. I think it's in part because those concepts, unlike the Wikipedia entries, don't quite stand on their own so cleanly. You kind of need sinews, you need linkages. And actually, I want to make the case that while Wikipedia is an astounding resource, I find it rarely to be the best available introduction or explanation of a topic. I find it often to be like a good jumping off point. It'll help me know the right thing to ask about. It's good as a reference. Hypertext is a very effective navigational aid. It can help you get to a spot that you're looking for very quickly because it's about automating flipping through pages. And so for a reference, it's very effective. If what you have is a book of chemical compounds and their properties, hypertext is going to let you navigate that book very effectively. Likewise, dictionaries have been revolutionized by hypertext. Navigating around the sources by clicking on links to say like, “Oh, shade it a little bit more like that.” It's like a much better thesaurus. I guess I'm making the case that there are certain kinds of texts that are more amenable to hypertext, because they are more amenable to having the reader dropped in the middle of them. Encyclopedias are like that, dictionaries are like that. Most texts are not like that and most concepts are not like that. I guess most ideas are embedded in something kind of holistic or richer. They require a narrative arc. They're difficult to excerpt. Not everything, but things that are not so raw and atomically informational. There were all these dreams of hypertext novels, for instance, and some people wrote them. And one of the problems that a hypertext novel has, and it actually can be seen in a choose your own adventure book that existed before there was digital hypertext, that the author is forced to write something like a lowest common denominator story, the page that is the destination of a hyperlink, it has to work as the endpoint of all of its reference. And so it can't establish any kind of coherent or consistent arc, unless there's a kind of sameness to all of the reference. And the more that there's sameness to the reference, the less useful hypertext is. So a lot of people have been disappointed by this conclusion. I, among them. I'll say that I do find hypertext very useful in my own notes, not really for reading. I actually don't think it makes for a very good reading experience for others. Dwarkesh Patel 01:34:15 Having been a reader, you have a separate webpage where you have your working notes. It is a very cool UI to explore your thoughts. Andy Matuschak 01:34:24 Thanks. It does an interesting thing for me as a writer. It lets me build stuff up over time. Today, I was reading this very old cognitive psychology paper on the topic of adjunct questions, which we discussed earlier, the effects of asking questions while you read, not on remembering the information covered in the questions, but on the general effect it has on stuff that isn't touched by the questions. I have some notes on the design decisions of the mnemonic medium, this Quantum Country thing that I was talking about earlier, interleaving the questions into the text. Those notes are kind of partial. They evolve over time. What was the impact of doing this? My notes about that, they've come from interviews with readers. They expand when I read a paper that's relevant to them. It means that when I go to design the next system, and I'm thinking about the role of questions in text, I'll have a place to look. The role of hypertext is roughly a navigational aid. It's possible to do this without hypertext. You’d just end up with what Neumann had, a giant dresser-like thing, but made of card files rather than drawers for clothing. Dwarkesh Patel 01:35:50 This actually goes back nicely to the original conversation we had about why people like Tyler are able to integrate so much information without an explicit note-taking system. Another person who comes to mind immediately is Byrne Hobart. Again, you have an example of somebody who is extremely prolific and writes a tremendously detailed and insightful daily financial newsletter. It's a daily note-taking practice in some sense. Andy Matuschak 01:36:18 Nothing quite accumulates for either of them, at least not in the same way. It's very interesting. They're doing the whole thing over again every day. One thing I find interesting about Levine's newsletter is that when he's talking about a topic repeatedly, like the recent bank collapse or something, he will have to explain some concept like interest rate risk over and over again for days. Every day he has to explain it, but every day he explains it anew, and every day the explanation is colored a little bit by that day. This is an argument against the kind of note-taking that I do. It's an argument for ephemerality, for recreating the thing every day, because it will change and it will become inflected by what you're thinking about and your experiences. It's pretty interesting. I find myself doing a mix these days. I have a journal that's about today, and I'll do a bunch of writing. Often I'm recapitulating stuff I've written before, and I have other things that are trying to be more durable, and be a useful reference that can stand outside of time. The combination feels useful. I don't yet have a clearer model of when one is better than the other. Dwarkesh Patel 01:37:37 An interesting way to tie in what you just said with the hypertext: Byrne’s newsletter doesn't give that much context. Often you'll find yourself lost about the concept being talked about if you're not familiar with the topic. I asked him at some point, have you considered doing narrations of your blog post? Scott Alexander has somebody who has a podcast where they narrate his blog posts. He said, “I don't think it would work out as well for mine, because I heavily rely on the old blogosphere’s norms around hypertext, where you can add jokes and sarcasm.” One example of this is his write up about SBF and his collapse. It has a bunch of links - if you want to learn more about margin calls, read this. And he goes, and if you want to learn more about the psychology of utilitarian bets, read this, and it's just a link to the Amazon page of Crime and Punishment. That kind of stuff is harder to do. Andy Matuschak 01:38:39 Yeah, you're right. He's leaning more on his past explanations, which is interesting, because he can't update them. That format of writing a newsletter and then linking it to past newsletters, or as you say, the former blogosphere thing to do, you have a series of six words and each word is linked to a previous post on the topic. I certainly have written stuff like that. It's kind of funny. It's approximating the durable note thing I was writing about, but without the ability to revise it over time. Maybe for many topics, you don't need that ability. I wonder now what fraction of my notes are in the state they were when I did my first major revision of them. It's probably at least a third, it might be more than half. Dwarkesh Patel 01:39:24 What percentage of notes have you published? Andy Matuschak 01:39:27 By word count? By note? I don't know. For instance, my journal notes are not published. There's one of those every day so there's a lot of them. If we're looking by note, we're excluding all of those. I also have a note about all of the people in my life and those are not public, unless they're public individuals. There's a lot of notes that are not public, but they're mostly not durable. They wouldn't be all that meaningful to others. The journals might be, but they're also intimate. Dwarkesh Patel 01:40:01 Are they written in a way that would be intelligible to somebody else? Andy Matuschak 01:40:05 It depends. Usually my journals are complete sentences, complete paragraphs. Sometimes bullets, sometimes veering and breaking and changing to new subjects suddenly. They tend to be filled with links to the things that I'm talking about, in part because I'm trying to accumulate context in those things. Dwarkesh Patel 01:40:27 How come they're not just shorthand? Andy Matuschak 01:40:31 It's partially because past me is another person, it's kind of a cliche. I am routinely looking at journal entries from a year ago. You could view that as a failure of this note writing system. In some ideal sense, I shouldn't be looking at these journal entries, because if something's important, and it's going to be something I refer to a year later, it should be in some durable evergreen note. I don't know. You don't always want to do that. It feels like prepping. Maybe there's an amount of prepping that's good. We live in California and maybe everybody should have an earthquake kit. Maybe that's good, but maybe you don't need to hoard 300 cans of beans. There's an amount of prepping that feels like a reasonable amount to do and there's an amount that feels kind of dutiful and unpleasant. (01:41:22) – How computer tools enable iteration Dwarkesh Patel 01:41:22 As a researcher, who is in the Silicon Valley circles, what is your opinion on the startup advice “Do things fast. Fail fast. Get to users immediately with an MVP.”? As somebody who is making products, but is also in a different mode than a typical startup, how do you think about advice like that? Andy Matuschak 01:41:42 I have complicated feelings about this. I need different advice on differen",
    "commentLink": "https://news.ycombinator.com/item?id=38663733",
    "commentBody": "Self-teaching, spaced repetition, and why books don&#x27;t workHacker NewspastloginSelf-teaching, spaced repetition, and why books don&#x27;t work (dwarkeshpatel.com) 196 points by ColinWright 21 hours ago| hidepastfavorite142 comments pyjarrett 19 hours agoThe real problem is teaching children that \"reading\" is merely decoding words off a page, and \"listening\" is merely hearing the words someone says.The book itself is a way to open the door to learning, not the end point. Reading subject titles first, cross-referencing, and working examples and doing projects help teach and cement ideas.There&#x27;s techniques like SQ4R [1] for reading, and hugely applicable to general technical and article reading is \"How to read a paper\" [2]. For lecturers, there&#x27;s \"How to Speak\" [3], and for those attending a talk there&#x27;s the Cornell Notes system. [4][1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SQ3R[2]: https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;ee384m&#x2F;Handouts&#x2F;HowtoReadPape...[3]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Unzc731iCUY[4]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cornell_Notes reply dan-g 15 hours agoparentTo others wondering about the discrepancy between SQ4R being mentioned in the comment text and the title of the linked source being SQ3R (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SQ3R), it looks like others [1] add an additional R (marked with an asterisk below), for the following: 1. Survey 2. Question 3. Read 4. Recite 5. *Rephrase 6. Review[1] https:&#x2F;&#x2F;www.american.edu&#x2F;provost&#x2F;academic-access&#x2F;sq4r.cfm reply jackphilson 13 hours agorootparentare there more accepted alternatives to this, or is this optimal? reply flir 17 hours agoparentprevYour first link is interesting. Looks like an expanded \"see one do one teach one\".Everything revolves around a \"cementing\" stage, doesn&#x27;t it. Practice makes perfect. reply konschubert 20 hours agoprevWhen I studied Physics, I could sometimes take hours to digest a single page of a textbook or my lecture notes - providing that it was a good textbook.It’s not enough to just understand what is written. You have to understand why it is like described. Why it can’t be different - or could it? You need to build an intuition for both the physics and the math describing it.You have to push until it clicks.It’s hard work. reply andai 20 hours agoparentWhen learning new programming concepts, I would often have to learn them 5 or 10 times before they clicked. Once they clicked, they seemed completely obvious, and I couldn&#x27;t imagine what it&#x27;s like to not understand it.Two mathematicians are discussing a theorem. The first mathematician says that the theorem is trivial. He then proceeds with two hours of exposition. At the end of the explanation, the second mathematician agrees that the theorem is indeed trivial. reply dotnet00 18 hours agorootparentI remember this having been my experience with teaching myself to code as a kid. All I remember is initial endless frustration from having to re-read tutorials and documentation and still not understanding anything. Then at some point I can&#x27;t remember, everything clicked into place and I can&#x27;t understand why I didn&#x27;t understand it before. Once I had those basics down, I haven&#x27;t had that kind of struggle.I went through a similar phase with math, struggled with basic algebra for years, then at some point it all clicked into place and I unintentionally ended up skipping all high school algebra to get to early calculus.It makes it really hard when helping other people through those early concepts (like pointers), because \"keep working and at some point it&#x27;ll just click for you\" isn&#x27;t very convincing. reply AlexErrant 16 hours agorootparent> keep working and at some point it&#x27;ll just click for youHaha, monads still haven&#x27;t clicked for me despite knowing F# and Clojure pretty well. I think of them as \"functors that you can flatten\" (and functors are \"things you can `map` over\", and `map` is \"a structure-preserving transformation\"). I know monads syntactically, but not intuitively. Despite this I still manage to work with monads pretty well - sometimes rote knowledge is enough. Maybe if my work involved discovering new monads I&#x27;d feel like I&#x27;d know them better. (I just see the same option&#x2F;list&#x2F;result(ish)&#x2F;generator-style monads over and over.) reply chowells 14 hours agorootparentAh, so you understand monads. The trick is that someone told you they&#x27;re a big important deal. They aren&#x27;t. They&#x27;re useful, so they get used. But there&#x27;s no great insight or revelation waiting for you. You&#x27;ve already got it. reply cvhashim04 16 hours agorootparentprevThis describes me as well.I’ve started to call it paying the “time tax” or “staring tax”, I have to just review tough concepts (code, concept, leetcode solution, math problem) for a long while before it eventually clicks. reply dotnet00 14 hours agorootparentThat brings to mind a learning staircase that comes up in art, where you go between stages of learning to draw better and learning to observe better. Since you can&#x27;t draw better until you can observe better, but you can&#x27;t observe better if you can&#x27;t draw well enough to match your current observation skills. So in a similar way, you have to pay some \"time tax\" to move forward. reply WalterBright 15 hours agorootparentprevThat&#x27;s the way it happened for me with computer programming. reply wegfawefgawefg 19 hours agorootparentprevI used to require this, but after having spent many years programming this stopped being the case. I&#x27;ve reached the point where i can see a new abstraction and usually immediatly understand it, regardless of language. reply MaxBarraclough 17 hours agorootparentHas your career taken you across many different programming paradigms?A C programmer with no experience in concatenative or, especially, functional languages will have little chance of understanding code written in Forth or Haskell. They will have to start at the bottom of the learning curve.The differences between languages aren&#x27;t just skin-deep. Same goes for the design patterns in those languages. Haskell&#x27;s applicatives have no analog in C, for instance. reply dehrmann 15 hours agorootparent> Forth or HaskellYou&#x27;re not wrong, but those don&#x27;t crack the top-10 of in-demand languages. Enough functional paradigms have also crept into more popular languages that you wouldn&#x27;t be completely lost. reply chongli 20 hours agoparentprevYes. This is the same for both math and programming. These skills take a lot of practice to develop. It’s like playing a musical instrument: you won’t learn how to do it if all you do is read the book.What’s strange to me is how people seem to resist this fact. Like it’s obvious to pretty much everyone that you need to practice an instrument to be able to play music on it. But for math and physics at least they seem to think it’s somehow different? That they ought to be able to solve the problems just by picking up a pencil? And when they don’t get a decent grade on the exam they look over at the person who got 100 and say “that’s why! I can’t do it because I’m not a genius like they are!” reply cinntaile 20 hours agorootparentThe feedback is a lot faster when playing an instrument, you hear if it sounds good or not. The reward is built-in. This is a bit harder for maths&#x2F;physics once you&#x27;re past the trivial stuff and most people don&#x27;t find it rewarding to solve physics&#x2F;maths problems. reply dotnet00 14 hours agorootparent>The feedback is a lot faster when playing an instrument, you hear if it sounds good or notThe feedback is only fast if you&#x27;re already skilled. It&#x27;s pretty common for new students to have no proper sense of what sounds good (particularly since it&#x27;s familiar to them), such that they struggle to figure out what they need to improve. Similar to digital artists flipping the image often to make it easier to identify issues by making the image somewhat unfamiliar to them, forcing their brain to actually look at the image rather than just using its previous idealized mental representation of what the image looked like. reply mr_mitm 17 hours agorootparentprev> most people don&#x27;t find it rewarding to solve physics&#x2F;maths problems.Maybe that&#x27;s the difference between people who are good at it and people who aren&#x27;t. I found solving math problems (the ones you get in a practice course at a university) hugely rewarding. Finally figuring it out was so satisfying.Coincidentally, my endeavors playing an instrument were never particularly fruitful. reply palata 18 hours agorootparentprevTo be fair, the \"you need to practice an instrument to be able to play music on it\" hides a very complex process.Some people \"practice\" by trying to play the same thing over and over, and it is equivalent to \"hearing\" vs \"listening\". Learning how to play an instrument (and also a particular piece of music) is a very complex process. Just like you need to learn the skills to \"learn from a book\", you need to learn the skills to \"practice an instrument\". reply Asraelite 14 hours agorootparentprevI agree with your point but I think playing a musical instrument is a bad analogy because of one fundamental difference:In most intellectual fields, you can take your sweet time to remember what you learned so long as you remember it eventually. Music requires practice to recall everything in real time. reply beebeepka 20 hours agorootparentprevNot everything is hard work. Some are smarter (or better equipped) than others. You can spend an eternity teaching me math and still won&#x27;t be able to accomplish anything. It&#x27;s almost like different people exist and they have different skill sets and interests. reply Tainnor 20 hours agorootparentUnless you have a specific learning disability, I refuse to believe that you are unteachable. Maybe you have zero interest (in which case, of course you won&#x27;t learn). That&#x27;s fine. Maybe abstract reasoning doesn&#x27;t come as natural to you as it does to others, that&#x27;s possible. But we know how plastic the brain is. Given enough time and dedication, you should be able to learn things - certainly not PhD level stuff, but the basics. reply caskstrength 15 hours agorootparent> Maybe you have zero interest (in which case, of course you won&#x27;t learn).Quoted sentence does a lot of heavy lifting in your reasoning. Being intrinsically interested in something is integral part of learning. And, yes, obviously for people who have zero interest in subject it will act as \"specific learning disability\". I know this because I tend to be interested in programming-related subjects and, consecutively, capable of learning them, but I could never muster any interest trigonometry or calculus homework. I&#x27;ve also known multiple people who felt the same way about debugging their software development homework - they weren&#x27;t interested and hated every second of it. reply Tainnor 11 hours agorootparentI don&#x27;t think you can count \"zero interest\" as being a learning disability. I hated drawing and still do (and other things too), but I could probably still learn the basics of it if, say, my life depended on it. reply caskstrength 1 hour agorootparentExactly! And another person in your class that is interested in painting could become world class in it while you will be struggling to learn basics. reply beebeepka 19 hours agorootparentprevI guess you mean well but this sort of reasoning is borderline offensive. I said math is hard to me and you immediately jumped to \"abstract reasoning\" as if that means math and nothing else.Saw plenty of this in school. Not appreciated. reply Tainnor 19 hours agorootparentI apologise if I have caused any offense, because that wasn&#x27;t my intent.I feel you missed the main point of my comment, though. Even if abstract reasoning, or certain forms of abstract reasoning, were not natural to you (something that I can impossibly judge), it wouldn&#x27;t mean, as you initially claimed, that it would be impossible to teach you mathematics. reply beebeepka 19 hours agorootparentOh, understood the main point just fine. You are not wrong.Just got a little upset about the rest. I wouldn&#x27;t have reacted as I did had you phrased it a bit differently, like in the post I am currently replying to. reply wegfawefgawefg 19 hours agorootparentI don&#x27;t think your offense was warranted. You&#x27;ve got a chip on your shoulder. Other people may be able to tell but either haven&#x27;t confronted you about it, because it wasn&#x27;t worth it to them, or you haven&#x27;t responded well to feedback.Either way I recommend reflecting on it. replyflappyeagle 17 hours agorootparentprevYeah I experienced this firsthand. My roommate in college was a physics genius. He would grok concepts without really studying very intensely— often after a single reading or lecture.He would intuit solutions to problems based on extrapolating from the textbook. The undergraduate stuff all clicked right away for him.Even when we scored the same on an exam, the difference in effort expended was dramatic reply mr_mitm 20 hours agorootparentprevYou are confusing the difference between a necessary condition and a sufficient one. The argument was that practicing was necessary to gain a deep understanding of math, not that it was sufficient.Ironically, this is one of the first things they teach you in college level math (or at least they did in my case). reply chongli 18 hours agorootparentprevI’ve tutored many students in math and it’s really common for people to feel the way you do. They’ve had bad experiences at some point or another, whether it’s with teachers or classmates.There are a lot of different reasons why students feel the way you do and (unfortunately) give up on math. It’s a shame because I believe most of those reasons are specific to the high school setting and from what I’ve seen, students have a much better time if they come back to math later in life and study without that environment.Interest also plays a role, of course. And not everyone will have the interest to go back and study again, later in life. reply beebeepka 13 hours agorootparentI did come back to it as an adult. Spent a while doing 2d and 3d graphics. It was much easier as an adult but rendering involves too much of this math stuff and I gave up. Definitely not for equipped to shine as graphics programmer.Which brings us to my original point - not everyone can do it (well). reply deafpolygon 10 hours agorootparentI bet they said this back in the day when illiteracy was a widespread thing. Some people just weren&#x27;t \"cut out to read\". replyreadingnews 19 hours agoparentprevThis is the \"problem\" today that I see in the classroom (I used to teach CS until recently)... learners today do not want to dedicate the time it takes to truly understand. Not all of them, but a LOT of them have the opinion that they just need to get through this damn algorithms class, get the damn piece of paper (diploma) so they can go out and start a job doing \"real\" programming.Those students, they do not get FAANG jobs, or make big money. The few that want to understand are much more like the articles description, and they end up five years on far ahead of their peers at work.Just my $0.02. reply watwut 15 hours agorootparentI remember having schoolmates like that 20 years ago. reply justanotherjoe 19 hours agoparentprevI wish they&#x27;d always explain &#x27;the initial seed&#x27; first. What was the initial thought or idea, that, when pursued and expanded on, resulted in the concept that im trying to learn right now?That sort of initial seed would give me so much information... reply AlexAndScripts 18 hours agoparentprevI find it beneficial to just keep asking why. Sure, the answer is sometimes \"because universe\", but asking why (not just how) over and over again helps me build my mental model.On that topic... Does anyone have any clue how and why magnetism works? I have a A Level Physics test next week :) reply seanmcdirmid 18 hours agoparentprevI simply can’t read the text book, at least without context. Doing the problem sets over and over again works better for me. Practice is the key, it might make sense to unsuccessfully attempt the problems before ready the chapter, since you would have more context for readying. reply portpecos 15 hours agoparentprevIf someone were to create an animation of that physics page you described, do you think it might have shortened the time spent to digest that concept? reply Balgair 15 hours agorootparentI never really got the difference between the dot and cross products until many years after graduation. And then I only got it because I managed to stumble upon a good video with somewhat decent animations.Like, 2-D, sure, seems easy enough. But once you go to 4-D, things get really hard to grok.Passionate science educators online have really filled in a lot of my education. reply goeiedaggoeie 18 hours agoparentprevmath requires something different than memory, it requires understanding and fluency in its variety of symbolic languages, which can only built with intellectually engaged work. reply ThinkBeat 20 hours agoprevBooks work well and have been the standard for learning many topics for hundreds of years. They have few technical problems, Easy to sell, borrow, give away.Yes, you can go about reading a book in different ways depending on what and why you are reading and what works for you.I think it is highly unfortunate that universities these days, at least in science, then to force students to buy a new edition every year, or at least every couple of years.There are just about no scientific discoveries in math that requires undergraduate and few matters that require an entirely new edition of graduate books.I have also heard but never experienced that some books apparently have an online component that is valid only for one person or one semester or possibly one student per semester. If true this is even worse.I strongly prefer books to videos. A lecture is good to prepare you or to wet your appetite. And to clarify known difficult spots in the book. reply eviks 20 hours agoparent> have been the standard for learning many topics for hundreds of yearsThat means very little, history is littered with awful standards used for centuries, there is no magic that translates longevity into greatness> They have few technical problemsHard to bookmark (and find what those are for later), hard to search, hard to annotate (and search those later), hard to edit, hard to embed rich&#x2F;dynamic content, hard to track understanding, hard to adjust content based on that, hard to tailor to a specific reader in general, hard to update layout, hard to collaborate, ... reply Tainnor 19 hours agorootparentWell, books continue to work for a lot of people (including myself). Every time I read a book about a topic, I come away with deeper and more contextual knowledge than if I just piece together scraps of information from badly written blog posts and overly technical documentation - and that&#x27;s only for programming stuff, for history etc. books tend to be even more valuable.> Hard to bookmark (and find what those are for later), hard to search, hard to annotate (and search those later), hard to edit, hard to embed rich&#x2F;dynamic content, hard to track understanding, hard to adjust content based on that, hard to tailor to a specific reader in general, hard to update layout, hard to collaborate, ...Not all of these are even true of physical books - people have been bookmarking them and scribbling in the margins for ages. And also, e-books and PDFs exist, for the people that prefer them.As for the \"tailoring to a specific reader\" and \"tracking understanding\", that&#x27;s a problem for any learning resource, as people are incredibly varied. Maybe in certain situations, learning resources exist that are extremely adaptable, but I&#x27;ve rarely seen that. In general, for a given topic one should check out different books until one finds one that is well-suited, skip sections that are obvious, consult other sources where one remains confused, do exercises if the book has them, etc.Books being hard to edit and&#x2F;or collaborate on could maybe (if it&#x27;s even true) be a problem for authors, but why does it matter for readers?The one thing that I do consider true is that you can&#x27;t do extremely fancy visualisations in a book. But there&#x27;s no problem with supplementing a book with e.g. a website where you can find interactive visualisations, etc. (also: simply not every topic needs complex interactive visualisations). reply eviks 18 hours agorootparentWell, books also continue to fail a lot of people> Not all of these are even true of physical books - people have been bookmarking them and scribbling in the margins for ages.All of that is true for physical books, if you&#x27;re limited to tiny margins and can&#x27;t easily find your margin scribbles later, then it&#x27;s a format fail, you just continue to use the same flawed logic \"done for ages = good\"> And also, e-books and PDFs exist, for the people that prefer them.Which mostly repeat the paper medium, so fail to solve most of those issues> As for the \"tailoring to a specific reader\" and \"tracking understanding\", that&#x27;s a problem for any learning resource, as people are incredibly varied.Yet it&#x27;s especially a problem with books> In general, for a given topic one should check out different booksIn general one should not limit oneself to books, even for just a starting point> Books being hard to edit and&#x2F;or collaborate on could maybe (if it&#x27;s even true) be a problem for authors, but why does it matter for readers?For example, to remove \"sections that are obvious\", add \"exercises\", find reference to \"other sources\", see explanations from other readers etc.> there&#x27;s no problem with supplementing a book with e.g. a website where you can find interactive visualisations, etc.The problem is it&#x27;s a big limitation of the format, and you can&#x27;t integrate it well if you have to switch back and forth> also: simply not every topic needs complex interactive visualisationsWhich topic do you think can&#x27;t benefit from one? reply Tainnor 11 hours agorootparent> Well, books also continue to fail a lot of peopleYes, because learning is hard. A book is not a guarantee that you&#x27;ll learn something - but neither is any other sort of resource.The thesis of this discussion is that \"books don&#x27;t work\" and that&#x27;s blatantly false. Maybe there&#x27;s certain people for whom they really \"don&#x27;t work\", but as a general statement, it&#x27;s false.> Which topic do you think can&#x27;t benefit from one?I don&#x27;t need fancy data visualisation if I read up on the history of the Roman Empire, for example. Or if I want to read Plato. Or to understand axiomatic set theory.---I&#x27;ll just put it differently: if you prefer other kinds of resources and they work for you - great. But to say \"books don&#x27;t work\" just means that you artificially limit the things you learn. Writing books is comparatively easy (if you&#x27;re an expert in the area). Doing fancy interactive experiences etc. requires much more time, skill, knowledge etc. - there&#x27;s probably 3 to 4 orders of magnitude more stuff that has been written in books than has been made available through other means, so saying \"books suck\" means just locking yourself out of a lot of stuff. reply ThinkBeat 17 hours agorootparentprevBoomkarking a physical book is super easy and a lot more intuitive and easy to use than an eBook version.Some books come with one or two strings built in that can be used. Mostly to track where you are in the book right now, and the other one for something you find important.Then there are thousands of different bookmarks you can buy as many as you need.You also have adhesive-colored tabs you can use to mark whatever you like.You can also bend the top or bottom corner of a page, Or use scissors and remove the corner entirely.Bookmarking technology for real life books is mature and easy to use.Some books make it easy to write down here you are externally. Page Numbers, or like the Bible with several numeric markings that makes finding a quote fast and easy.Books can come with indexes that make finding things easier. To browse through index entries can also provide interesting insight.It is super easy to annotate. You can use a pencil and things can be erased if you desire. You can use pens You can use highlighters, You can use stickers, You can write the margins You can attach post it notes You can attach documents (pressed between the existing pages.The way you do bookmark, highlight, and scribble can be of tremendous value for the next reader. (Or it can be flat out annoying).It is also easy these days to take a photo of a page with your cellphone and do whatever you want. then you can if you so wish print and glue it in, or insert a page or whatever into the book.A book can have very rich illustrations and graphics.If you do need to reference rich media you can print a QR code in the relevant part of the book so people can quickly pull up the video or whatever there is a need for. reply eviks 16 hours agorootparentYou&#x27;re describing a bunch of variations is a primitive unsearchable design, there is no value in that sticky richness related to the issue I&#x27;ve describedHow do you group all the bookmarks that are related to a given topic? Use a specific bookmark color? How do you then change the whole group? Or, physically go to every single bookmark and change it to a different color? How would you list all paragraphs you&#x27;ve bookmarked together (let&#x27;s say you want to track a story of a given character interaction with another one)? How do you add longer custom text to the bookmarks? Physical ones don&#x27;t have enough space for your questions that you&#x27;d later like to go back to to find answers toI mean even in the most trivial case- using a string to track where you are: why is this even needed when a computer can do the tracking automatically? Also, that string only tracks 2 pages, not the exact point in textIndexes are also not great, they&#x27;re slow to use, usually incomplete (so any primitive full-text search would beat them), and uneditable by the reader, so don&#x27;t reflect\"Take a picture\" is a laughable suggestion, why would I also need to waste time to OCR \"to do whatever I need\" when I could start with a better format in the first place? reply montefischer 14 hours agorootparentprevWhat is your favorite alternative medium? reply brandall10 20 hours agoparentprevThe university textbook issue was big when I was a student in the mid-late 90s.In fact, one of my CS professors went on a rant about it, how it is simply a way to invalidate the used book market... he then told us to buy books from an online storefront with this funny name (that he assured us had nothing to do with the rainforest) that sold them for a sizable discount instead our own university bookstore. reply Tainnor 20 hours agoparentprev> I think it is highly unfortunate that universities these days, at least in science, then to force students to buy a new edition every year, or at least every couple of years.This seems to be a specifically American (or anglo? not sure about the UK&#x2F;Australia&#x2F;etc.) thing. I&#x27;ve never heard about this happening in Germany where there are standard textbooks in about every field that people have been using for decades - and in many cases, people just simply go with the lecture and the associated notes instead of a textbook. reply Tomte 12 hours agorootparentI studied CS in Germany and pretty quickly learned not to buy textbooks too fast: lecture was announced with book X as necessary to have.First lecture the professor holds up book X. \"I have taught using this book for years. A few days ago I decided to use book Y (holds it up) going forward.\" reply Tainnor 10 hours agorootparentTIL, but still: the lecturer changing their book preference at the last minute still seems different than \"you have to use edition 15 of this book (which came out 3 months ago) which is exactly the same as all the previous editions, but the exercises are rearranged, so you&#x27;ll get confused if you use an older edition\", which - if I understand it correctly - is what seems to happen sometimes in the US. reply zabzonk 19 hours agorootparentprevit happens in the uk as well as the us - university lecturers are bribed by the publishers. reply Tainnor 19 hours agorootparentDo you have any evidence specifically about lecturers being bribed? Because there could be a whole other range of other explanations for why this practice continues. reply zabzonk 19 hours agorootparentworking for two uk universities. and this not the only stuff these corrupt people got up to - one had the cheek to photocopy his own (crap) book using free to him university copiers, and then make his students pay for the copies. nothing was done about it, of course. reply Tainnor 18 hours agorootparentThat&#x27;s of course deplorable. But it just feels to me that if it happens so regularly, there must be some systemic causes and not just instances of invidual educators being bribed reply zabzonk 18 hours agorootparentwhat other reason can there be for very, very bad authors have new editions of books come out every year and get enforced on students by tenured clowns? reply Tainnor 18 hours agorootparentWell, instead of individual educators the blame could be on faculties or whole universities who maybe strike deals with publishers. replybsder 7 hours agorootparentprev> it happens in the uk as well as the us - university lecturers are bribed by the publishers.I really, really, really wish people would quit repeating this without evidence.Maybe ... maybe ... this is true for some huge name who can force the adoption of some huge number of textbooks. Maybe.However, for any random lecturer who teaches an upper level technical class, the maximum level of revenue any seller can expect from that class is probably about $200 x 50 students = $10,000.Where the hell is the bribe money going to come out of that? By the way, last I checked, the publishers wouldn&#x27;t even let us keep the sample copy they sent to us. Yeah, they&#x27;re that cheap.And do you really think that your technical lecturer&#x2F;professor or anybody in the publisher is going to risk going taking potentially illegal behavior for $1000?If your lecturer&#x2F;professor is that money driven, they would be better off simply not taking an underpaid, overworked position teaching your sorry ass and instead teach the same technical material to professionals who will pay more than your semester tuition for a one-week program.Now, if you want to talk about the publishers bribing government bureaucrats over high school textbooks, that is an entirely different and completely documented thing. reply ekianjo 20 hours agoparentprevMost books are very badly written. reply palata 18 hours agorootparentMost [everything] is bad. It&#x27;s your job to find the good ones and enjoy them. reply zabzonk 19 hours agorootparentprevcompared with what? reply dkjaudyeqooe 20 hours agoprevI find two things help me learn:A top down description: start with what something is, why it&#x27;s important, and how it fits in with other things, then an outline of the details, then the finer details and so on. This is almost impossible to find in textbooks or lectures, which for the most part are bottom up.Trying to figure out the thing without any help, or very little help, at each step of the above. This sounds pointless, but it actually works really well. If I try my best to figure out how something works without knowing anything I end up \"priming\" my brain for the answer, and end up getting a (relatively) instant understanding. It&#x27;s like you make a hole that is the rough shape of the answer in your mind and the answer fills the void. Put another way you motivate your brain to wanting to know what it is. The best bit is how far you can get by yourself and the positive feeling that gives you.This might just be me, I&#x27;ve never met anyone who feels the same way about learning. reply Avicebron 19 hours agoparentI don&#x27;t think it&#x27;s just you, I have a similar need for a holistic understanding of the process&#x2F;needs before I feel that I&#x27;m learning&#x2F;contributing in an organized way. I left the biotech startup world a while ago because I found that in the organizations I was working with, there was an extreme siloing happening from top down management, and I chafed under the unspoken assumption that I was expected to operate as a black box transforming data from input to output without knowing the whole processThis isn&#x27;t helped by how the biotech world stratifies itself into PhDs and non-PhDs reply danielbln 19 hours agoparentprevTowards your first point, I love interacting with LLMs (ignoring all the issues about confabulation etc.) because I can ask it for top down, high level outlines and drill down to the bottom however I please, and ask for multiple paths down as well. reply dkjaudyeqooe 14 hours agorootparentI agree, that&#x27;s a bright spot which I&#x27;ve just started to get into. It&#x27;s a real boon for personalised learning. Even mistakes by LLMs are helpful: you know that they&#x27;re unreliable and you have to stay on your toes, so what they&#x27;re telling you makes sense. That only benefits actual understanding, rather than rote learning. reply dilawar 19 hours agoparentprev> Trying to figure out the thing without any help, or very little help, at each step of the above. This sounds pointless, but it actually works really wellI found it to be very effective though time consuming. Even if you don&#x27;t figure out the solution, when you read other solution later, everything just clicks. reply dkjaudyeqooe 14 hours agorootparentI like to think about it when I&#x27;m doing something else that doesn&#x27;t require thinking. You also have to let it percolate. It kind of reflects the focused&#x2F;diffused thinking modes of actual learning. reply rickcarlino 19 hours agoprevI&#x27;ve used spaced repetition to memorize nearly 5,000 words over the last 15 years, but I struggle to apply spaced repetition outside of key&#x2F;value pair memorization.It seems that SRS is best used for \"know what\" rather than \"know how\".I am curious if anyone has applied spaced repetition to memorization of things other than terminology and how they did it. reply dan-g 17 hours agoparentI was in this boat until I read Andy’s article on how to write good prompts, which I’d highly recommend: https:&#x2F;&#x2F;andymatuschak.org&#x2F;prompts&#x2F; reply gbacon 11 hours agoparentprevI built an Anki deck[0] to prepare for and pass on my first attempt the Certificated Flight Instructor (CFI) initial oral exam, considered by some to be the toughest checkride — although pass rates have been rising in recent years[1].[0]: https:&#x2F;&#x2F;ankiweb.net&#x2F;shared&#x2F;info&#x2F;1069780390[1]: https:&#x2F;&#x2F;jasonblair.net&#x2F;?p=3326 reply Asraelite 14 hours agoparentprevThe problem with SRS in my opinion is the inability to do many-to-one mappings. That is, a single question that builds upon your knowledge of already-learned simpler concepts by combining them together into a compound problem.In the context of language learning this could be a sentence which tests multiple individual vocabulary items and grammatical patterns together. In the context of maths it could be using multiple techniques in sequence to solve a more complex equation.I think this would bridge the gap between the atomic knowledge that flashcards give you and the more generalized knowledge that applied practice gives you.AFAIK, no existing SRS is capable of this. I started working on a prototype web app that could do it but I haven&#x27;t finished it yet. I plan to return to it at some point. reply crazygringo 18 hours agoparentprevNope, you&#x27;re entirely correct.It&#x27;s for vocabulary and terminology mainly, or other simple facts like historical dates, country capitals, etc.It&#x27;s irrelevant to conceptual learning, where it may be very difficult to understand something, but once you do you understand it for life. reply JohnFen 20 hours agoprevBooks don&#x27;t work? I beg to differ. Books are how I&#x27;ve learned 80% of what I know. They work better for me than any other method I&#x27;ve experienced. However, I&#x27;d agree that textbooks don&#x27;t work. At least, they don&#x27;t work for me. reply AlexErrant 20 hours agoprevUlgh why didn&#x27;t the blog link to \"Why books donʼt work\" https:&#x2F;&#x2F;andymatuschak.org&#x2F;books&#x2F;Some select disjoint passages:> Like lectures, books have no carefully-considered cognitive model at their foundation, but the medium does have an implicit model. And like lectures, that model is transmissionism. Sequences of words in sequences of lines in sequences of pages, the form of a book suggests people absorb knowledge by reading sentences. In caricature: “The author describes an idea in words on the page; the reader reads the words; then the reader understands the idea. When the reader reaches the last page, they’ve finished the book.” Of course, most authors don’t believe that people learn things this way, but because the medium makes the assumption invisible, it’s hard to question.> Readers must learn specific reflective strategies. “What questions should I be asking? How should I summarize what I’m reading?” Readers must run their own feedback loops. “Did I understand that? Should I re-read it? Consult another text?” Readers must understand their own cognition. “What does it feel like to understand something? Where are my blind spots?”> These skills fall into a bucket which learning science calls “metacognition.” The experimental evidence suggests that it’s challenging to learn these types of skills, and that many adults lack them.Baker, L. (1989). Metacognition, comprehension monitoring, and the adult reader. Educational Psychology Review, 1(1), 3–38. Worse, even if readers know how to do all these things, the process is quite taxing. Readers must juggle both the content of the book and also all these meta-questions. People particularly struggle to multitask like this when the content is unfamiliar.> My collaborator Michael Nielsen and I made an initial attempt with Quantum Country, a “book” on quantum computation. But reading this “book” doesn’t look like reading any other book. The explanatory text is tightly woven with brief interactive review sessions, meant to exploit the ideas we just introduced. Reading Quantum Country means reading a few minutes of text, then quickly testing your memory about everything you’ve just read, then reading for a few more minutes, or perhaps scrolling back to reread certain details, and so on. reply montefischer 14 hours agoparentA far more practical idea is to internalize the practice of &#x27;metacognition&#x27; so you can apply it to the vast corpus of books that already exist.It is also interesting to consider previous attempts to wrap a cognitive model around the physical medium of the book, like the monastic &#x27;lectio divina&#x27; of the middle ages. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lectio_Divina reply lawn 20 hours agoprev> Why Books Don’t WorkI think it should be clear that it&#x27;s not books that don&#x27;t work, but how many people approach books that&#x27;s ineffective.Just reading books isn&#x27;t enough, you have to internalize the lessons which is often hard work. reply keiferski 20 hours agoprevI like books, but I basically agree with the idea that the traditional front-to-back text narrative format is hugely inefficient. I think a lot of people interpret technological developments as some of natural process, and therefore the omnipresence and long existence of books implies that they are a great learning method.In reality, though, the format of a book itself is probably just more \"evolutionarily fit\" compared to alternatives. If a device that could record and replay audio was somehow invented prior to the printing press, it seems highly likely to me that we&#x27;d live in a audio-based world, not a text one. After all, societies spent thousands of years using only spoken language, with writing as a fairly recent phenomenon.A more efficient book system, IMO, would incorporate spaced repetition more directly, whether by highlighting the key points at the bottom of each page, or even by deliberately including \"reminder\" paragraphs throughout the book. reply Avicebron 20 hours agoprevI typically have a low opinion on rote memorization, I remember years ago at university my roommate swore by his note cards (physical index cards at the time) while I strongly maintained the need to build up intuition around the math and physics I was doing. He was in med school and I was in engineering, but I felt that the memorization while successful at least for him, was limiting in terms of potential innovation. reply AlexErrant 15 hours agoparentI was listening to a podcast with someone who went from BS&#x2F;Mechanical Engineering => MD. He had to give up his \"first principles\" style of engineering-thinking and just accept that rote memorization was the way to go, at least for the majority of his courses.I disagree that rote memorization limits innovation in the medical field. Biology has complex problems, and \"For every complex problem there is an answer that is clear, simple, and wrong\". There&#x27;s a reason why so many clinical trials fail, and it&#x27;s not for a lack of technical innovation.I feel like the medical _system_ as a whole needs systematic&#x2F;organizational disruption, not technological disruption. For example, CGMs are a technology that have been around for decades and only now are we seeing usage in non-diabetic populations. The system (they require a prescription) is preventing the innovation. reply voisin 20 hours agoparentprevLikely each successful strategies for the different specializations. reply dsgnr 20 hours agoparentprevYeah med students seem to be unique in the amount of stuff they need to remember, at least in terms of users Ive worked with. The amount of things medical students need to memorize to pass their USMLE exams is insane. I designed and built a learning tool at a startup for med students using picture mnenomics and spaced repetition quizzing that seriously helped those students and lead to the startup being acquired. reply AlexErrant 19 hours agorootparentThe ability to link image-metaphors&#x2F;mnemonics to concepts is something that really should spread to other (non-medical) domains.An example of a picture mnemonic for others: https:&#x2F;&#x2F;dornsife.usc.edu&#x2F;news&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;7&#x2F;202...Article: https:&#x2F;&#x2F;dornsife.usc.edu&#x2F;news&#x2F;stories&#x2F;usc-dornsife-alumnus-r...If you&#x27;re comfortable saying, did your startup&#x2F;acquirer have any interest in developing products for other domains? reply Avicebron 19 hours agorootparentI&#x27;m not the one you&#x27;re asking, but I surprised you don&#x27;t think that mnemonic isn&#x27;t used in other domains.It typically doesn&#x27;t look like a fully fleshed out pizza shop, but I distinctly remember explaining an cell scaffold that I had synthesized like a bowl of spaghetti and meatballs to some of the undergraduates I was mentoring..I never felt that other domains didn&#x27;t address the natural inclination to use abstraction as a way to convey concepts&#x2F;processes. reply AlexErrant 17 hours agorootparentTo be clearer, I&#x27;m talking about explicit integrative pictures like the one I linked. I know simple ones like this existhttps:&#x2F;&#x2F;www.build-electronic-circuits.com&#x2F;wp-content&#x2F;uploads...but I&#x27;m _surprised_ that complex metaphorical images like the one in the parent haven&#x27;t spread to other domains. As you said, we often make verbal metaphors when teaching, but explicit visual metaphors are _relatively_ rare. I&#x27;m talking about literal political cartoon as mnemonic device. How often do you see visual metaphors in textbooks? They&#x27;re usually more interested in correctness.Perhaps AI will make generating these images easier, if the difficulty in creating the graphics was the sticking point. Or maybe the problem is in sharing them, which is a problem that I&#x27;m working on. replypawelduda 20 hours agoprevSpaced repetition is underrated. I still remember a lot from my cards despite not having studied them for years reply andai 20 hours agoparentI had the opposite experience. If something&#x27;s easy to remember, I don&#x27;t need Anki. If something&#x27;s hard to remember (I really struggle with birthdays, for example), even Anki doesn&#x27;t help! The cards all end up as \"leech\" and Anki stops showing them to me. (I found this behaviour amusing, since the whole point of using Anki is to help me learn things that are difficult to remember!)They say if a card is ending up as a leech, it&#x27;s a \"problem\" card and you should somehow improve it. But I&#x27;m not sure how to improve this: Side A: name. Side B: birthday. (Cards are also shown reversed.)Arguably I could add some kind of mnemonics, or learn the Mnemonic Major System for remembering numbers. (On that note, does anyone have specific advice for remembering birthdays? The Dutch among you will say \"hang a birthday calendar in your toilet\", which was probably the correct solution all along...) reply davisoneee 18 hours agorootparentGive yourself more opportunities to latch onto the card.Instead of Name -> Birthday, try \"X&#x27;s birthday is in {month}\", or \"Y&#x27;s birthday is the {N}th of January\" or \"Z&#x27;s birthday is just before {some notable date, like Christmas}\" or \"A&#x27;s birthday is just after {B ... someone whos birthday you remember}\". e.g. I remember my best friend&#x27;s wife&#x27;s birthday because it occurs shortly after mine. I remember a girl who I used to live across from 25 years ago because her birthday was just before mine.This way, you have multiple different ways of relating to the information. If the related key date is coming up, you can think \"oh...Z&#x27;s birthday is around now\"...which should be enough for you to functionally act on it.Try to avoid the mindset of single cards. If you _really_ want the information, break it down in different ways.Wrestling with the information in this way is a good way to find patterns and relations to it in the first place (put the information IN your brain well)...then use spaced repetition to practice getting the information OUT of your brain well. reply blackbear_ 20 hours agorootparentprev> If something&#x27;s easy to remember, I don&#x27;t need Anki.That probably depends on what and how much you are trying to memorize with Anki. It is easy to learn a few words in a foreign language, but try to learn three to five new words per day for a year straight and suddenly you realize how far spaced repetition can bring you.For leeches, what helps is to create more cards with the same concept (and do not suspend the leech, you are right that is not a good idea). If I struggle learning a word, I create more sentences using that word, or connect it with synonyms and antonyms. For birthdays, maybe try to add some memories related to that birthday: some particular gift, a happy moment during that day, the weather or location where you celebrated... Just see what sticks :) reply Tomte 20 hours agorootparentprevWhy would you need to learn birthdays (except maybe closest family)? It&#x27;s maybe the canonical thing to put into a calendar.\"Because I want to\" is obviously fine, but it still reminds me of the infamous \"capitals of the world\" flashcards that spaced repetition practitioners warn against. reply andai 16 hours agorootparentFor me specifically the motivation was that my mother, who is naturally very good with dates and birthdays, would keep telling me \"It&#x27;s your {uncle, grandma, cousin}&#x27;s birthday, don&#x27;t forget!\" and I would think to myself, \"what kind of bad person am I, that I don&#x27;t even know my own family&#x27;s birthdays?\"Similarly, I struggle with understanding&#x2F;remembering the structure of my family tree, at least for the family members that I never met (I am often told stories about ancestors, and am shamed for my inability&#x2F;unwillingness to naturally and automatically memorize them). So I broke the family tree up into individual relations and made Anki cards of them.That worked a little better than the birthdays, but still a struggle, because it is \"meaningless information\" as far as my own brain is concerned. I might consciously think it&#x27;s important to have knowledge of your ancestry, but my neurology apparently disagrees... Alas! reply esafak 14 hours agorootparentDon&#x27;t bother. Do you want your distant relatives to toil away trying to remember where you fit in the family tree? Life is too short for that. Forgive yourself and move on.I&#x27;m bad at it too and my wife is not, so she can figure out my own family tree better than I can; it makes for good party banter. reply jonpurdy 20 hours agorootparentprevIt wasn&#x27;t until I discovered Anki a few years ago that I finally was able to remember my parents&#x27; and sisters&#x27; birthdays (despite calendar reminders every year).Why remember something that can be looked up? Latency; it&#x27;s super useful to have things appear in your brain so you can immediately do something useful with them instead of slowing down and looking something up and potentially losing context. reply andai 17 hours agorootparentSo, Anki did help me learn a few of them, while a few would just never stick for some reason. Amusingly, the few birthdays I did learn didn&#x27;t really help me because even though I knew the birthdays, they wouldn&#x27;t come to mind until days or weeks after the birthday passed!So what I&#x27;d actually need is \"what are all the birthdays that occur this month\", and then have a ritual habit installed that at the first day of the month I would spend a few minutes pondering this list in my mind.(Again, the birthday wall calendar would probably work better here...) reply Tainnor 19 hours agorootparentprevWhy are spaced repetition \"practitioners\" warning against that?I have a \"Roman Emperors\" Anki deck. It serves absolutely no purpose except making me feel good about it, but it works well (except maybe for the final few emperors, those tend to be leeches). reply Tomte 19 hours agorootparentIf you&#x27;re truly interested in Roman Emperors, that&#x27;s fine, of course. The warning is more about \"I just started spaced repetition, I need cards quick, so let&#x27;s do capitals, US states, and other random trivia\".I admit birthdays of acquaintances don&#x27;t quite fit under \"random trivia\", but I&#x27;ll still maintain that learning random birthdays seems useless, when the calendar works so well. reply Tainnor 19 hours agorootparentWell yes, I would agree that memorising facts that you&#x27;re not interested in is probably not a very good use of your time and mental energy. reply david_allison 20 hours agorootparentprev>> (I found this behaviour amusing, since the whole point of using Anki is to help me learn things that are difficult to remember!)> Eliminating 10% of the most difficult items in a generic material may produce an increase in the speed of learning of up to 300%.https:&#x2F;&#x2F;super-memory.com&#x2F;articles&#x2F;theory.htm reply cinntaile 20 hours agorootparentprevA calendar in your toilet? Go digital and use your phone&#x27;s built-in calendar. reply andai 16 hours agorootparentThe difference here is important. I see the birthday calendar (well, my Dutch housemate&#x27;s one) every time I sit down on the toilet. As for non-wall calendars (both digital and physical), stuff goes into them but it never comes out!(Though the digital one does become useful due to the automatic reminders.) reply ahoka 20 hours agorootparentprevLearn the month and day separately? reply andai 16 hours agorootparentI did consider this, especially since the few that I was able to memorize didn&#x27;t help me remember the birthday on time. So perhaps a more useful association would be:[month] -> [list of important birthdays] reply Syzygies 19 hours agoparentprevPimsleur is my favorite system for learning foreign languages, based on spaced repetition.I&#x27;m a casual tourist, who likes to pick up some rudimentary language skills before travel. There are many of us; we understand the importance of smiling at our hosts and getting the words out while more formal learners are stalled in self-induced aphasia.For us, the design of spaced-repetition systems misses a crucial point: We don&#x27;t care about measurable process while stockpiling some language skills before a trip, and we certainly don&#x27;t have time to sit around studying once we&#x27;re on a trip. The goal is to ingest as much content as we can, in some form that sticks, to recall more flexibly as we struggle to speak in-country.For this purpose, memorizing a radio play as if one is an actor is more effective than spaced repetition. For example, just the Pimsleur dialogs, edited from audio files one owns. The words are there, slow to access but quicker than opening up a phrase book. Within a week traveling, one&#x27;s mind reorganizes access to the language one actually uses.The dig on learning a radio play is one doesn&#x27;t know the words out of sequence. Yeah, that&#x27;s why one can learn them so efficiently. For those of us of a certain age, it&#x27;s the \"next song on the album\" effect. What did Knuth say about premature optimization? Learn the words one actually needs out of sequence, on the ground, in use. reply andai 16 hours agorootparentI was wondering about the usefulness of spaced repetition for language (both natural and programming). I thought of analyzing a language for how frequently tokens appear in it (or vocabulary for a human language) and then prioritizing those cards first, and making them appear more frequently... then I realized, reality already does that for you, automatically!(On the other hand, Pimsleur is great, and taking a systematic approach to \"100%ing\" the \"core\" of a language is probably a great idea.) reply j4yav 20 hours agoprevI can assure you, books work reply loughnane 15 hours agoprevBooks work—good books anyway—, but most of us aren’t taught how to read well.The next time you want to get something from a book do some new things with it.1. Skim it first.2. Find some interesting entries in the index if it has one and jump there to check it out.3. Ask questions while you read. Write them down the book.4. Reread the book (spaced repetition). It will go faster because you e built a structure with your notes the first time.5. Don’t waste time on bad books.A good analogy is pitching. The pitcher is the writer, the ball is the knowledge and you are the catcher. Nothing works if the pitcher can’t throw or if the catcher can’t catch. Likewise if there’s no ball to throw.So it is you’ll get nothing out of the book if the writer can’t deliver or has nothing to say. But a well crafted book stuffed with knowledge won’t to any good if you receive it. reply Smaug123 18 hours agoprevI know everyone always just responds to the title, but do read&#x2F;listen to this one. I think it&#x27;s Dwarkesh&#x27;s best episode ever. Dwarkesh always asks great questions, and Matuschak has this amazing knack of interpreting those questions in the most interesting ways, while constantly challenging their assumptions. reply fredoliveira 18 hours agoparentI&#x27;m a huge fan of Andy&#x27;s work and have been for years. Absolutely loved this episode.If I may suggest another one of Dwarkesh&#x27;s episodes that I thoroughly enjoyed: his 2 episode interview of Carl Shulman. It is an absolute treat. Completely different subjects, of course, but equally engaging. reply andymatuschak 18 hours agoparentprevThank you for these very kind comments! reply iandanforth 20 hours agoprevAfter watching the studying video I&#x27;m surprised there is no direct GPT-4 integration with his tool. There&#x27;s a clear opportunity for dynamic question generation such that you have notes&#x2F;cards which can&#x27;t be memorized but instead ask novel questions around the same point. reply apienx 20 hours agoprevThe director of the Australian Society for Medical Research has a nice TEDx talk about all aspects of learning here: https:&#x2F;&#x2F;youtu.be&#x2F;kKvK2foOTJM?si=RF479ogKABAtcCUE reply hyperthesis 18 hours agoprevIn math textbooks, the exercises contain much of the exposition. Some is in the answers. And some of facts you are expected to learn only appear in your own workings.So \"reading\" a math textbook misses most of it. reply glimshe 19 hours agoprev\"Expert\" educated through books tells us why books don&#x27;t work. reply blackbear_ 18 hours agoparentYour point being...? reply steve1977 15 hours agoprevI’m a huge fan of the incremental reading approach as provided by SuperMemo.While it’s certainly even better suited to hypertext, it also works well for most non-fiction (e)books, at least for me.https:&#x2F;&#x2F;supermemo.guru&#x2F;wiki&#x2F;Incremental_reading reply ryloric 14 hours agoprev> Books don&#x27;t workStupidest title I&#x27;ve seen in some time. Maybe there&#x27;s some additional context I&#x27;m missing. reply Smaug123 13 hours agoparentThe context you appear to be missing is actually the content of the post. It&#x27;s often the way with articles: they give a title, which is then expanded upon in the main text. reply ryloric 6 hours agorootparentThat&#x27;s called clickbait. reply matheusiacono 11 hours agorootparentprevEven books follow this way. reply venus-project 20 hours agoprevShameless plug número doshttps:&#x2F;&#x2F;www.knowledgize.com&#x2F;en&#x2F;d&#x2F;python-glossary&#x2F;learn&#x2F;flash... reply masto 18 hours agoprevWhy books don&#x27;t work... for Andy Matuschak.People are different, you know. reply demondemidi 20 hours agoprevGlad he provided a transcript, which is technically, a book. reply satisfice 11 hours agoprevI wrote about a more relaxed version of this, some years ago. See Secrets of a Buccaneer-Scholar.I wrote it to explain the techniques I use to compete as a technical guy who dropped out of high school.It’s actually not very hard to compete if you see education as an ongoing process of personal construction, rather than some plug of knowledge that an expert gave you (along with a certificate).I collect books and papers which I ignore until I have a relevant problem, at which point I go into a process of intensive inquiry similar to that describe in the post. reply Zigurd 18 hours agoprevDepends on the kind of book and subject matter. Dwarkesh is right about books you need to read all or nearly all of to get the benefit. But to answer \"Do people care about understanding?\" for a lot of books: No. The reader cares about their problems and solving them.Based on reader feedback, only a special kind of reader reads a programming book cover to cover. 90%+ people who read substantial parts of a programming book, dip into the parts that interest them after, perhaps, reading the first few chapters to figure out how to navigate the book.Online, you have the freedom to do better and to publish similar material in multiple modes, from passive and linear, to self-paced interactive to human-guided. There isn&#x27;t one answer, which the post touches on in several places including regarding spaced repetition.LLMs are likely to have an impact on the value of pedagogical techniques like spaced repetition because spaced repetition is a tool for overcoming human impediments to acquiring and navigating huge, difficult, knowledge bases. Then using that knowledge requires enormous effort and aptitude. That&#x27;s where humans competing with LLMs are like pick-and-shovel miners competing with a giant dragline at mining coal. reply Zigurd 17 hours agoparentOTOH if the knowledge base is finite but a real mf&#x27;er, spaced repetition is great for humans. Git comes to mind as perhaps ideal subject matter. reply lapcat 20 hours agoprevnext [6 more] [flagged] Tomte 20 hours agoparentDon&#x27;t complain reflexively without looking at the submission. It&#x27;s >95% text, the whole video transcript. reply lapcat 19 hours agorootparent> Don&#x27;t complain reflexively\"Please add\" is not a complaint, it&#x27;s a polite request.The fact that there&#x27;s also a video transcript just proves that the [video] label is accurate. reply Tomte 18 hours agorootparentYou&#x27;re wrong. [video] is only an (unnecessary) warning for people who don&#x27;t like videos. If most of the page is text there is no reason at all to \"warn\" anyone. reply lapcat 17 hours agorootparentThe HN guidelines don&#x27;t say anything about transcripts: \"If you submit a video or pdf, please warn us by appending [video] or [pdf] to the title.\" https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply Tomte 17 hours agorootparentIt&#x27;s not a video! replyvictorlf 20 hours agoprevShameless plug: I&#x27;m building https:&#x2F;&#x2F;python.cards to learn Python with spaced repetition. I&#x27;ve uploaded some videos on Youtube of the process of distilling the information from the Python docs into flashcards, and have plans on trying out LLMs to help in this process. reply AlexErrant 20 hours agoparentAs someone also building an SRS product, why did you decide on Python as your initial market? I genuinely feel like programming is best learned by _doing_, and thankfully it&#x27;s pretty easy to practice writing Python. I feel like a better way to learn Python is to introduce a concept&#x2F;word, and give a playground where the student can play with it. reply victorlf 19 hours agorootparentMany reasons, most of them hypothesis. For one, the book \"The programmer&#x27;s brain\" says that spaced repetition is the best way to learn the syntax, idioms, caveats of a programming language, but it&#x27;s hard to find a product that offers this.I don&#x27;t suggest you should learn Python _only_ with python.cards. I assume every python.cards user will be doing some online course, or working with Python, and my decks will just boost their knowledge of the language.I think a lot of people program in Python but programming in Python is not their main occupation. These people struggle to accumulate knowledge, because they may encounter concepts or APIs only from time to time, and by that time they already forgot.Also, I want to cover some \"unorthodox\" topics for which spaced repetition may be specially well suited. For example, I&#x27;m building a deck called \"A tour of the standard library\", where you can learn all the modules that are available, just so you know what is out there, without going deep into it.Another idea is to have decks to learn all the built-in exceptions by heart, or the nomenclature. I think this helps build a mental model of the width and depth of the language so you can better integrate all the knowledge you find while coding, searching online, or reading code. reply AlexErrant 15 hours agorootparent> the book \"The programmer&#x27;s brain\" says that spaced repetition is the best way to learn the syntax, idioms, caveats of a programming languageUnfortunately, hard disagree. The best way to learn a Lisp is to write Lisp. You can look at code all you want, but you won&#x27;t get used to the syntax&#x2F;parens until you start writing it. Same applies to non-Lisps.> I think a lot of people program in Python but programming in Python is not their main occupation. These people struggle to accumulate knowledge, because they may encounter concepts or APIs only from time to time, and by that time they already forgot.This is a great point. Static typing is great for API discovery, which Python sadly lacks. However, I wonder how much LLMs are eating this \"low-code\" market. Also, if Python is non-critical to their jobs, I suspect that they won&#x27;t feel motivated to explicitly study Python over the long term. Doing spaced repetition is famously hard, and non-motivated people will likely give up and just do \"JIT learning\".> Also, I want to cover some \"unorthodox\" topics for which spaced repetition may be specially well suited. For example, I&#x27;m building a deck called \"A tour of the standard library\", where you can learn all the modules that are available, just so you know what is out there, without going deep into it.FWIW I&#x27;m learning Rust, and to \"learn what&#x27;s out there\" I&#x27;ve just been binging random Rust videos on Youtube at 2x over lunch. Granted I&#x27;m an experienced dev and I have an intuition as to what \"should\" be out there, so perhaps this story is of limited use. reply victorlf 12 hours agorootparentYou may be interested in rust.cards, which I&#x27;m also working on :D reply AlexErrant 4 hours agorootparentLOL I&#x27;ll check it out. replytedmcory77 20 hours agoprev [–] Yea, it&#x27;s always bugged us that we learn the way folks did hundreds of years ago.Which is why we built https:&#x2F;&#x2F;www.munkle.it the way we did and focused on speed of review.I used to not like the feeling that spaced repetition did (it&#x27;s always in that slightly hard stage) but apparently that&#x27;s what helps you remember. reply andai 16 hours agoparent [–] I can&#x27;t tell (neither from the website, nor from using it) how this is different from any other flashcard software?You mention you focused on \"speed of review\". How did you do that?There are apparently no hotkeys? (My speed of review is therefore lower than Anki, due to needing to use the mouse.) reply tedmcory77 15 hours agorootparent [–] Q,W,E < No need for mouse. First card in Welcome to Munkle Deck. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article features a conversation with researcher and designer Andy Matuschak on education, learning, memorization, and product creation.",
      "Active reading, memory, and hands-on experience are emphasized as crucial elements in education.",
      "The conversation covers the limitations of traditional schooling, the need for innovative approaches, and the impact of tutors and teachers."
    ],
    "commentSummary": [
      "The article and discussion explore various learning methods, such as self-teaching and spaced repetition, and their effectiveness in learning complex subjects like coding and mathematics.",
      "Understanding, practice, and personal interest are highlighted as crucial aspects of the learning process.",
      "The conversation delves into the use of spaced repetition tools like Anki and the potential impact of artificial intelligence on learning. A Python learning platform incorporating spaced repetition is also introduced."
    ],
    "points": 196,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1702729489
  },
  {
    "id": 38667503,
    "title": "Chimera: A New Linux OS that Simplifies Setup and Customization",
    "originLink": "https://chimera-linux.org/",
    "originBody": "Chimera is a general-purpose OS born from unhappiness with the state of Linux distributions. It's built around the core idea that a simple system does not have to require endless setup and customization to be practical. It aims to capture the convenience of complex distributions while retaining conceptual simplicity. To this purpose, it is built from scratch using novel tooling and approaches. Read more for details.",
    "commentLink": "https://news.ycombinator.com/item?id=38667503",
    "commentBody": "Chimera LinuxHacker NewspastloginChimera Linux (chimera-linux.org) 174 points by MaximilianEmel 13 hours ago| hidepastfavorite104 comments krupan 3 hours agoIf you are along time GNU user (meaning GNU grep, sed, less, awk, find, tar, etc., etc.) this will be way more frustrating than you realize to use. Having lived in the UNIX days, I can still remember the subtle differences in all the command-line tools driving me nuts. This is actually how the GNU tools became popular even before Linux was a thing, you could install them on irix, hpux, sun, any UNIX, and you wouldn&#x27;t have to deal with the quirky differences between hpux grep and irix grep (for example). reply lucideer 1 hour agoparentIf the APIs of CLI utils is the primary concern, it&#x27;s worth noting that they say their core userland is provided by \"FreeBSD, NetBSD, OpenBSD\" - so any friction here should in theory just be equivalent to the friction of using a BSD today (or Mac). reply pjmlp 1 hour agoparentprevI do confess having installed the GNU ports on Solaris multiple times.Unfortunely Aix and HP-UX servers were out of my control, thus scripts had to stay POSIX compatible for anything that had to run across all our servers, or written in Perl. reply simonh 20 minutes agorootparentOh sure, I still remember getting my first 1&#x2F;4” tape of the GNU tools source code through the post. This is why it’s so hilarious to me when the kids nowadays complain that MacOS has different command line tools to Linux. “Why can’t they just use GNU?”.Get off my lawn! ;) reply Rediscover 1 hour agoparentprevtar(1) was the command that often bit back at me across the different Un*x implementations, vs awk(1) which for some unknown reason I had internalized the most miniscule differences.I got into the habit of immediately installing gtar on any Solaris box I had root on (damn the leading \"&#x2F;\" in the archive).-----The 2nd worst part was dealing with SunOS and HP&#x2F;UX at work and Ultrix outside of work. Worst part was not grokking why MS-DOS wouldn&#x27;t buffer keystrokes the few times I was exposed to it. reply 5- 11 hours agoprevi really like a lot of design choices in chimera linux (particularly around its packaging&#x2F;build system), but as a current alpine linux (main pc, not docker) user, i find i still can&#x27;t justify musl. i like small simple correct software, but musl, despite being all of those things, is, in my experience- slower than glibc, and in occasionally difficult to predict spots;- causes just a bit too much trouble porting software to it -- most upstreams are reluctant to accept patches, resulting in maintenance overhead for the distribution;- occasionally subtly breaks things at runtime -- e.g. both alpine and chimera builds of firefox have the same two crashes which neither the official mozilla nor archlinux builds exhibit.in the end i find i have to rely on my glibc chroot (e.g. for mozilla firefox build) too much for my liking. reply NewJazz 10 hours agoparent[musl is] slower than glibc, and in occasionally difficult to predict spotsNote that sometimes (&#x2F;often) this purely due to the allocator, and as far as I remember Chimera uses a different allocator than the stock musl one. reply celrod 9 hours agorootparentChimera uses the scudo allocator, which is Ajay also the default on Android and Fuscia.Yet I can&#x27;t find many benchmarks.Frustratingly, it&#x27;s listed here, but not actually included in the results: https:&#x2F;&#x2F;github.com&#x2F;daanx&#x2F;mimalloc-bench Might be fun trying to run the benchmarks myself. reply q66 4 hours agorootparenti ran that when doing the initial porting: https:&#x2F;&#x2F;gist.github.com&#x2F;q66&#x2F;84288d3b8e70146a630f65dc1de4b683that said, scudo is highly configurable, and the performance reflects the configuration (you can even swap out the primary allocator, secondary cache, you can tune all the parameters, the TSD registry implementation has a big impact on multithreaded code, etc.), so it&#x27;s not 100% representative - chimera&#x27;s current configuration is further tweaked for both better performance and lower memory usagescudo being this configurable is excellent because it is what enables such integration in the first place (other allocators e.g. frequently rely on ELF TLS, i.e. __thread and the likes, which would make libc integration very difficult and would require major changes to the dynamic linker, with scudo we instead implement a custom TSD registry and simply shove an extra pointer in the pthread structure) reply sidkshatriya 5 hours agorootparentprevHappy chimera user here. It feels fast in regular usage though I use ssh much more than desktop.What’s actually amazing about chimera is the musl + clang&#x2F;llvm&#x2F;compiler-rt combination. It allows you to do all kinds of amazing things easily from a programming perspective.The apk 3 package manager, build system (cbuild) is also excellent. Everything feels modern and clean. Package availability is still limited and you would probably need to compile many of your favourite packages from source but I would still highly recommend this distribution. reply LeFantome 4 hours agorootparent“What’s actually amazing about chimera is the musl + clang&#x2F;llvm&#x2F;compiler-rt combination. It allows you to do all kinds of amazing things easily from a programming perspective.”Any examples? reply q66 6 hours agorootparentprevin most applications where it matters, it actually tends to be the allocator; you&#x27;ll find that especially interactive applications (e.g. browsers) tend to feel significantly more responsive in chimera than in alpine, as well as other things (e.g. LTO link times with lld take a third of the time) reply freedomben 10 hours agoparentprevThis has been my experience with alpine as well. musl just ends up causing much more trouble than it is worth reply sidkshatriya 6 hours agorootparentFor the longest time using anything but gcc was a problem. But people found clang&#x2F;llvm better in many respects and persisted. Today clang&#x2F;llvm is a drop in option, even to compile the Linux kernel.Similarly we should persist with musl. It’s infinitely cleaner, simpler and understandable. reply musicale 4 hours agorootparentAs you imply, it&#x27;s not really a standard unless there are multiple implementations.I am in favor of standardizing the behavior of libc and having multiple implementations that are commonly used. reply LeFantome 4 hours agorootparentThere are many, many implementations of the C standard library. Every OS has one—even Windows.There are also many other POSIX ( UNIX-like ) operating systems such as FreeBSD and OpenBSD which have their own.Redox has a Rust-based C library called Relibc that even works on Linux.There are also other C libraries that work on Linux such as dietLibc and of course Bionic, which is the standard C library on Android.The problem is not the lack of a standard, it is that Glibc does not follow the standard and is itself the de facto choice for desktop Linux. Applications that assume Glibc may not work on other implementations ( like MUSL ). reply sidkshatriya 1 hour agorootparentprevI think we should not standardise lunch on Linux. Firstly it will create a lot of acrimony as different people may have opinions.There is already a standard you need to adhere to. It lives one level lower and is the Linux userland-kernel interface i.e the syscall interface. reply j4ah4n 7 hours agoparentprevOff topic, but would you have any suggestion or resources to start using alpine on a main pc? I have a System 76 machine I wouldn’t mind trying this out with. reply prmoustache 55 minutes agorootparenthttps:&#x2F;&#x2F;dataswamp.org&#x2F;~solene&#x2F;2023-04-30-alpine-as-desktop-c... reply NewJazz 3 hours agorootparentprevTheir homepage is pretty straightforward. As is the setup-alpine installer. reply tomphoolery 34 minutes agoprevInteresting take on SystemD. I personally find it very helpful, but one of its major downsides as a project is that it is, to borrow a quote from Benno Rice, \"aggressively Linux-specific\". That said, it appears their own software choices prevent them from using it as summarized in the following quote:> That’s why one of the goals in Chimera is to implement the actual useful systemd functionality, but independently and in our own way, without the shortcomings.I question whether it would be possible for SystemD to be portable to other software stacks? Seems like it would be useful enough to attempt that port rather than literally rewrite SystemD, and you get to satisfy _both_ the SystemD stans and the haters at the same time! But who knows, it might lead to some kind of future innovation to have competing products doing the same thing... reply LeFantome 4 hours agoprevFor everybody trying to figure out the point of Chimera Linux, it is Void Linux taken one step further. The founder used to be the maintainer of Void for PPC. That also explains the supported arch selection for Chimera.My take on Chimera is that it is what a FreeBSD user would want if they were going to use Linux. They share the same compiler and userland. The build system rings a lot of bells.At first, GNOME seems an odd choice but Chimera wants to avoid a lot of legacy and is pipewire and Wayland from the start. reply jchw 3 hours agoparentIt looks quite nice though yeah, the choice of GNOME makes me a little bit less enthused. I wonder if System76&#x27;s COSMIC will ever take off enough to be a consideration, as I would really like to see a new stable, pragmatic, productivity + user-focused DE take off. Plasma&#x27;s a bit too buggy, GNOME feels not so pragmatic and definitely not so user-focused, the rest feel like they lack some level of polish and maintenance. System76 seems to have money to put into something good here, and they seem to have the right incentives to make something focused on user&#x27;s needs and sensibilities more than developer&#x27;s ideals, so it seems like in some time it could become a major contender. reply prmoustache 51 minutes agorootparentGnome is one of my favorite DE as to me it is so easily usable and efficient with maximise use of the keyboard straight out of the box while still being very practical to use with a tactile screen.I do understand that it may not be for everyone but my understanding is that when people say a desktop is not user focused, what they really mean is it isn&#x27;t focused to people resistant to changes reply nilsherzig 50 minutes agorootparentprevWhat Gnome do you think doesn&#x27;t feel user focused? I use 90% of the time minimalist window manager, but when I need a full desktop I find Gnome the best choice. Gnome isn&#x27;t particularly exciting, but in my experience, everything I can&#x27;t say about other desktops just works. Apart from that, Adwaita looks incredibly much better Qt. reply eternityforest 11 hours agoprevIt&#x27;s really cool, but I get worried anytime I see something that seems to want to be a user friendly, mainstream distro, after seeing how hard Manjaro tried with the whole \"Bring simplicity to the masses\" stuff and how many issues they still have.Is this an experimental or hobby distro or does it intend to be something grandma can use?If I had to choose this or BSD, it looks like I&#x27;d very strongly considering this or something like it, but it definitely doesn&#x27;t seem like an Ubuntu or Windows replacement. Simplicity is just not a factor end users consider.As a dev who likes modern software and isn&#x27;t really into lightweight hacker friendly stuff... the odds of me using anything that&#x27;s not at least 1% or total desktop market share is pretty low. Anyone who&#x27;s not an Arch&#x2F;Kali&#x2F;BSD&#x2F;suckless enthusiast type has a finely tuned sense of \"Oh no, that makes me feel the same way that thinking about a project car does, I&#x27;m outta here\".It could drill be a wonderful worthwhile project... but it&#x27;s going to be an uphill battle to interest anyone but tinkerers and I always kind of worry about people, because this stuff takes a lot of time and without managed expectations it can really be a disappointment when it doesn&#x27;t take off. I&#x27;ve tried several times to start new projects and it&#x27;s been pretty hard realizing they&#x27;re unlikely to go anywhere anytime soon.I think getting any mainstream adoption would require changing the entire software ecosystem in general. I would imagine there would be some kind of issues trying to port current mega apps like Steam or Chrome to this.Plus, dynamic linking seems like it&#x27;s not that well suited to user friendly distros meant for end users.Unless you have snap or Flatpak or something like that, I don&#x27;t see how you can have cutting edge large complex third party packages without at least occasional compatibility issues.My experience with dynamic distros generally hasn&#x27;t been terrible, but it always seems like there&#x27;s some issue or other.Does this have any kind of AppArmor type sandboxing? reply Levitating 9 hours agoparent> Is this an experimental or hobby distro or does it intend to be something grandma can use?It&#x27;s an experimental hobby distro. If you want something grandma can use, you want to use use something everyone uses.Chimera is fairly niche and goes against all standards. You&#x27;re always going to run into Chimera specific issues. Chimera also has a nice transparant build system that one can tinker with.As for Manjaro, I don&#x27;t think it&#x27;s hard to make a distro based on Arch that just works. Manjaro developers just suck. reply ekianjo 6 hours agorootparent> Manjaro developers just suckThis. They cant even be trusted to renew their certificate 4 times in a row. The level of incompetency reaches new highs. reply arp242 9 hours agoparentprevExpecting any project to take off is likely end up in disappointment regardless of what kind of project it is, because most projects out there don&#x27;t take off. By and large you have to do these kind of things because you find it useful for yourself and&#x2F;or fun, but not because you want it to take off.I also think it&#x27;s fine for projects to target a specific more hobby-esque audience. Not every project has to be for everyone. reply eternityforest 7 hours agorootparentI totally agree, but I see lots of projects with a site that looks a lot like an end user project, and some design choices that kind of seem like it&#x27;s meant to be mainstream, without really being clear on what it&#x27;s for.It took me a long time to learn not to expect too much, and my choice of projects has been very different since learning this.Some projects seem like they&#x27;re held back by trying to be kinda-mainstream-ish, rather than being fully able to try whatever they want. reply gjvc 10 hours agoparentprev\"\"\"Anyone who&#x27;s not an Arch&#x2F;Kali&#x2F;BSD&#x2F;suckless enthusiast type has a finely tuned sense of \"Oh no, that makes me feel the same way that thinking about a project car does, I&#x27;m outta here\".\"\"\"excellent observation reply creatonez 6 hours agoparentprevThe website doesn&#x27;t really give the impression that it intends to be a mainstream OS. Marketing seems to be \"lightweight hacker distro using musl, but simpler than the others in the same category\".I wish Linux distributions could advertise to existing Linux users without inadvertently causing this sort of confusion among the non-Linux tech media. Many Linux users don&#x27;t want the OS to take off, because things will get materially worse in many regards if it gets popular. You often only find the new users and tech media theorizing about the &#x27;year of the Linux desktop&#x27;, or about Linux&#x27;s product weaknesses in the narrow lens of comparing it to Windows.Fedora is able to balance this public image issue fairly well. In their landing page, they emphasize that it is for \"developers and makers of all kinds\". But because Fedora Workstation actually is fairly close to being an easy-for-all-users distro, in their \"Is Fedora For Me\" page, they have this paragraph that essentially explains that it might also be for non-developers as long as they are curious&#x2F;enthusiastic about computers in general:> The Fedora distribution is made for enthusiastic and curious computer users that like to learn and experience newer versions of software and therefore might not suit everyone. Although the Project works hard to make Fedora as usable as possible for the widest possible audience there are inherent limitations on how fast a new software can be translated, gain accessibility features, provide the most comprehensive documentation and guidance. If you on the other hand need a stable Linux distribution that supports even the latest hardware, are willing to put some effort to help the free and open source software (FOSS) community and file some bug reports this might be a perfect system for you! reply q66 6 hours agorootparentit&#x27;s designed to be a hacker distro; i just felt like \"hacker distros\" frequently tend to make a lot of things overly manual for no reason primarily due to halfassed choices made when packaging things - the way things are built in chimera is so that whatever is in the repo is \"install and go\" - and this includes things like large complicated desktops, in general things are designed so that if you bootstrap a system from scratch (by installing all the packages in an empty root) you need to do nothing more - other than the stuff you wish to explicitly change, and this is done without involving complicated scripts or anything of the likes, vast majority of packages install by simply unpacking themselvesto a degree your system package graph also defines your system configuration for things that are coarse enough to allow it; it&#x27;s also easily auditable reply akosoaaafjdr 9 hours agoparentprevI mean yeah, this is transparently a BSD esque project it looks like, as in its pretty clearly tailored specifically to provide the kinds of features professional systems programmers and admins have been clamoring for from Linux for a very long time. Chimera is basically exactly what FreeBSD is but with a Linux kernel (for instance, clang&#x2F;LLVM as the system compiler and lack of glibc as system libc), I&#x27;d imagine there is substantial overlap in our communities. I&#x27;ll also add that I think these are worthwhile and long overdo technical improvements over the very substandard and strictly worse-than-unix situation in common Linux distros these days. So I support the project, if only to support something that can hopefully prevent Linux from completing its transition into utter shit.You are spot on about this project I think in your analysis and I think it simply isn&#x27;t ever going to be something everybody will want to use. That&#x27;s okay, like you said, some don&#x27;t want to participate in operating system development, you are mostly looking to be a user. There are plenty of free and open source operating systems that will mostly provide that kind of experience for you. The intent with something like Chimera is probably to dogfood these sorts of improvements so that other more user friendly distributions can use it as an upstream source in the future. So maybe one day we will see a more user friendly version of this. reply q66 5 hours agorootparentchimera is not much like freebsd at all, besides adopting the same core tools; it&#x27;s mostly designed from scratch, and does not particularly try to \"emulate\" anythingi do like freebsd, i used it for around a decade so it probably left some mark (just like other systems i have touched over the years, like void and debian), but chimera does not try to explicitly be like anything else - i simply do what i feel are fitting design choices reply eternityforest 7 hours agorootparentprevAlways good to see ongoing research on improving OSes!I tend to focus a lot on having a clear purpose, just because I meet so many devs that don&#x27;t quite understand how an non-tinkerer types see computing, and why the rest of us like Android, Web, Ubuntu, and Snap so much.I have a hard time imagining someone making even a super polished derivative end users would want, but that&#x27;s perfectly fine if the audience is hobbyists with a deep interest in OS stuff, and I wouldn&#x27;t be surprised if the actual mainstream distros adopt some of the ideas if you discover something relevant to everyday use. reply q66 6 hours agoparentprevthe system does not aim to bring anything \"to the masses\" right now, considering the stage it&#x27;s in; likely won&#x27;t in the future either, as it&#x27;s aimed at power users primarilyyou can run steam in flatpak (it&#x27;s there), chromium will probably come natively in not that long, it does not seem like that big of a nightmare besides the ways chromium is a nightmare in in general (you can run it in flatpak too right now)there is no apparmor right now, but it&#x27;ll come reply the8472 9 hours agoparentprev> Anyone who&#x27;s not an Arch&#x2F;Kali&#x2F;BSD&#x2F;suckless enthusiast typeNot sure if Arch should be grouped with those. On the Steam statistics it&#x27;s more popular than ubuntu, and that&#x27;s not counting SteamOS. reply akosoaaafjdr 9 hours agorootparentIt shouldn&#x27;t, and neither should Kali. Neither of those demand the professional level skillsset that BSD and suck less are mostly tailored at. Those communities are composed almost entirely of hobbyists in the OS and systems programming space, or in the case of Kali, not really even strictly an OS project at all and mostly just people repackaging various security related stuff (which is fine of course, there is a legitimate need for some of that, it&#x27;s just definitively not OS development in the way something like OpenBSD is).In that sense, both of them are products, not projects, to the vast majority of users, and that influences what the core teams choose to focus on. reply debo_ 5 hours agoparentprevIn case it&#x27;s useful: my mother is almost 80 and she uses Zorin just fine. reply pzmarzly 29 minutes agoprevIf someone is also looking for more details on dinit, here is the repo: https:&#x2F;&#x2F;github.com&#x2F;davmac314&#x2F;dinit reply devit 9 hours agoprev\"that a simple system does not have to require endless setup and customization to be practical\" and \"alternative userland\" don&#x27;t go together since obviously any \"alternative userland\" is going to break lots of stuff and thus require extensive tweaking work. reply q66 5 hours agoparentthey do though, just not in the way you think; in general chimera is designed so that whatever you install from the repositories, it&#x27;ll yield a working out of the box configurationyou want a desktop? you install it and it works; there is no (mandatory) tinkering with getting dbus, audio, wifi&#x2F;bluetooth, or whatever else to work - most importantly things are set up in a way that installs are consistently deterministic and auditable (there is no reliance on complicated shell hooks or anything of the sort to do any kind of \"fixups\", most packages consist solely of extraction)sure, when you involve third party shell scripts or whatever, there is a chance you&#x27;ll run into compatibility troubles, but perhaps not as often as you think either reply eternityforest 44 minutes agorootparentI&#x27;m not a \"hacker distro guy\", so my opinion doesn&#x27;t matter much, but thisn definitely seems far more interesting than the piles of shell scripts most distros use. reply nine_k 3 hours agoparentprevIf it&#x27;s alternative but largely compatible, I don&#x27;t see a lot of tweaking ahead. If it&#x27;s materially different, it&#x27;s mostly going to be learning, before any tweaking. reply qweqwe14 7 hours agoprevChimera was developed by the same person that ported Void Linux to PowerPChttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230811081600&#x2F;https:&#x2F;&#x2F;voidlinux... https:&#x2F;&#x2F;voidlinux.org reply abeyer 5 hours agoprevI think I&#x27;d be a lot more excited about this if it didn&#x27;t seem to be bought into the wayland hype train.I feel like they made a lot of good decisions in being simple enough without too simple, and backwards compatible enough without too much legacy... but imho wayland doesn&#x27;t fit in that same space for me (at least not yet.) reply eternityforest 51 minutes agoparentIt seems like all the big name companies are 100% for Wayland, breaking compatibility with them seems like a hassle, regardless of how good Wayland itself is. reply q66 4 hours agoparentprevgood news for you then, since there is a full distribution of xorg in the contrib repo and it&#x27;s not expected to go away anytime soon (if ever) reply abeyer 4 hours agorootparentGood to know. Their package search from the main site must not include contrib,though, as it only turns up wayland related packages, and nothing x11&#x2F;xorg. reply suprjami 11 hours agoprev> Chimera is a general-purpose OS born from unhappiness with the state of Linux distributions. It&#x27;s built around the core idea that a simple system does not have to require endless setup and customization to be practical.This seems disingenuous at best.Many distros already supply this feature. Debian is the most notable but there are many others. Install it, make any tweaks you want from the base install, sit on it for many years unchanged.Considering the next paragraph goes on to describe OpenBSD userland, LLVM compiler, and musl libc, it appears the aim is actually to build a Linux distribution without GNU.I usually steer away from projects which are defined by what they are not. It seems to build a community whose roots are based in hostility. reply q66 5 hours agoparenti believe you are just making assumptions here; debian in this context does not count as a \"simple system\", if anything it&#x27;s as complex as a distro can be and its packaging approach is a polar opposite of chimera&#x27;si still like debian either way, because it&#x27;s a nice community with good values&#x2F;principles that has provided and still provides great value to the ecosystem, but it can also often be very fragilethe \"just works\" point of chimera stems from how things are built; everything it comes with is made to be \"install and go\" without having to go extra length to enable and set it up (while still being entirely transparent to the user), while being deterministic (packages in general don&#x27;t rely on install hooks etc.) to ensure safe upgrades and easy auditing, and all that in a framework of a system that has a fraction of the complexity of a large distro and is maintainable by a small teamwe make it consistently clear that it&#x27;s not a reactionary project (https:&#x2F;&#x2F;chimera-linux.org&#x2F;docs&#x2F;faq, https:&#x2F;&#x2F;floss.social&#x2F;@chimera_linux&#x2F;111553324359284350, etc) and has no hostility to GNU or any of the projects we use alternatives to by default (and anybody displaying such hostility is unwelcome in the community) reply fmoralesc 11 hours agoparentprevNot just not GNU: they also ditch systemd for dinit, syslog-ng and a bunch of homegrown plumbing:> We are also putting a lot of effort into writing fresh low-level plumbing. For example, Chimera comes with first-class and built-in support for user services and other things dependent on session tracking (such as a shared session bus), implemented from scratch thanks to our Turnstile project, finally bringing functionality previously only available on distributions using systemd. This is being implemented in a vendor-independent manner so that other distributions can adopt it. reply hedora 10 hours agorootparentGood to know. That was my first question.I hope this means they also get rid of nonsense like pulseaudio and logind.I’m a bit skeptical of the “shared session bus” though. Linux supports inode watches for things that want to react to configuration changes, and session busses add a ton of complexity (including a second authorization language, and a userland SPOF) reply NewJazz 9 hours agorootparentThey use pipewire IIRC (which is 1.0 now!!).And they have a custom alternative to login AIUI. reply MBCook 4 hours agorootparentThey’re working on it. The reason is explained in the FAQ.For now they seem to be using a different alternative to do at least some of it. I think it was called elogind? reply LeFantome 10 hours agoparentprev“I usually steer away from projects which are defined by what they are not. It seems to build a community whose roots are based in hostility.”This is a somewhat ironic indictment of a project opting to avoid GNU. In fact, your quote could serve as a valid argument to avoid GNU. I cannot think of a project more completely defined by what it is not. I would certainly find it difficult to argue that GNU and its founder have not been a source of discord and hostility. The Open Source movement is a direct response to the hostile politics of GNU and Free Software.In the case of Chimera Linux though, the founder has been pretty clear that they made their choices for engineering reasons and not political ones. There are lots of GNU packages in Chimera if you want them. reply xcv123 9 hours agorootparentGNU is defined as what it is; that it is an operating system and that it is free software.\"What is GNU? GNU is an operating system that is free software—that is, it respects users&#x27; freedom.\"https:&#x2F;&#x2F;www.gnu.orgAlthough GNU stands for \"GNU is NOT Unix\" that doesn&#x27;t count as its a boomer hacker meme that started before GNU. reply akosoaaafjdr 9 hours agorootparentI&#x27;ll add that most anti-GNU people I know in the BSD space and related projects are not at all against GNU politically speaking or it&#x27;s ideals or the free software movement.We mostly think that a variety of terrible technical decisions have been made and allowed to metastisize over the years, and that they are largely unfixable so long as Linux remains an operating system devoted primarily to ease of use, popularity, and packaged for non-professionals. A lot of this happened rather early on due to the influx of hobbyist programmers from the PC space, and so I think the GNU userland was mostly doomed from the beginning due to the qualifications (or lack thereof) of its programmers when important foundational design choices were made (they are better programmers and more professionally qualified these days, but they aren&#x27;t about to roll back most of these foundational mistakes because it would collapse the whole thing like a tower of Jenga blocks).Those goals actually align a lot with the GNU philosophies and so I support the Linux community fully in that way and for making free software available to as many as possible. But technically speaking, GNU userland is a pile of dog shit, and you&#x27;ve really got to rip it out and start from scratch like Chimera is doing as a bare minimum to actually make any kind of progress there. reply musicale 4 hours agorootparentWhat are some good examples of where a BSD userland is much better than GNU userland?One thing that possibly comes to mind for me is macOS&#x27; launchd, which doesn&#x27;t seem to give me the same headaches as systemd even though they&#x27;re kind of the same thing (see also: windows services manager.)Another is&#x2F;was clang&#x2F;llvm vs. gcc, but gcc seems to have improved since clang originally came out. And clang is readily available on linux distros.BSD pioneered containers with jails (and zones on Solaris), but I have gotten used to (and perhaps come to appreciate) Linux&#x27;s a-la-carte namespace&#x2F;cgroups design. I don&#x27;t really enjoy working with docker and kubernetes though.One thing I like about FreeBSD is its documentation, which seemed (to me at least) to be reasonably clear, complete and well-organized.I&#x27;ve liked NetBSD for a variety of reasons (somewhat coherent classic BSD organization, synchronized kernel and userland releases, great multiplatform support, support for classic systems and architectures, pkgsrc which works nicely across platforms and without root access, &#x2F;usr&#x2F;games, and just having a different kernel implementation) but I&#x27;m not sure I can point to individual utilities being better than their GNU alternatives. reply petre 3 hours agorootparent> One thing that possibly comes to mind for me is macOS&#x27; launchd, which doesn&#x27;t seem to give me the same headaches as systemd even though they&#x27;re kind of the same thing (see also: windows services manager.)XML definitions for service startup and inconsistent switches. Launchd is worse than systemd in those regards. I was quite happy to let go of my work iMac and do development on Linux. reply cycomanic 6 hours agorootparentprevYour statement is incredibly handwavy. GNU userland was doomed because the programmers were not professionals? Apart from the fact that many of the programmers were actually professionals, what were the design decisions that were made, keeping in mind that much of the userland design is essentially governed by posix.Also if I look at many of the \"professional\" unixes userland tools I&#x27;d choose GNU userland any day, because the userland tools are incredibly handicapped, e.g. name one Solaris (or even better hp ux) core userland tool that is better than it&#x27;s GNU equivalent. reply anthk 53 minutes agorootparentprevHyperbola GNU&#x2F;Linux will be rebased soon under an OpenBSD 7.0 kernel and userland so you will get the both worlds: A GNU licensed OS without a bloated userland, we even got Xenocara. We don&#x27;t even have DBUS. Emacs and notifications.el? write your own (notifications-notify) at ~&#x2F;.emacs callling play from sox and herbe with (&rest arg) as the function arguments, where externally a script would suffice to call both as a single program.On the GNU userland, something I hate it&#x27;s the lack of integration. Emacs&#x27; calc shoudln&#x27;t be calling Gnuplot, but GNU plotutils, at these should be enhanced to create 3D plots. Also, GNU Texinfo shoudln&#x27;t be calling a full Texlive install to render math and PS&#x2F;PDF files, but GNU Groff and geqn&#x2F;gpic...OFC reply mig39 11 hours agoparentprev> If that&#x27;s the aim then just state that.At the top of the first page, under the Chimera Linux logo: \"A modern, general-purpose non-GNU Linux distribution\" reply 0xDEAFBEAD 7 hours agoparentprevThere is this bit (emphasis mine)>This means Chimera is not a GNU&#x2F;Linux system, as it utilizes neither GNU utilities, nor GNU libc, nor GNU toolchain. However, *the project is not anti-GNU&#x2F;GPL*, and its userland choice is primarily technical. Users are generally free to use whichever software they like.https:&#x2F;&#x2F;chimera-linux.org&#x2F;about&#x2F;#alternative-userlandThis quote from the faq literally made me laugh out loud:>Another side of the coin is the so-called “systemd-free community”, which tends to spread a lot of misconceptions and frankly deranged opinions that end up hurting any sort of positive effort. Chimera as a project denounces such people, and is explicitly not a part of this community. Such people should also not view Chimera as some sort of haven, because it is not. The project is explicitly anti-elitist and aims to find constructive solutions.https:&#x2F;&#x2F;chimera-linux.org&#x2F;docs&#x2F;faqAnyway, I wonder if they should be emphasizing security more on their homepage.>Being a single lightweight package, it makes hardening the userland a lot easier too. It is possible to compile the Chimera userland with CFI and other techniques very easily, and it applies to all of the tools. With GNU tools trying to using these tends to fail, and addressing the issues becomes harder because it is out of our control and involves a much chunkier codebase where more can go wrong and where things are harder to track down.https:&#x2F;&#x2F;chimera-linux.org&#x2F;docs&#x2F;faqI would like to see more security-focused operating systems. And simplicity is obviously quite valuable for security. Perhaps they could find a nice niche as an accessible, UX and desktop-focused competitor to OpenBSD? Qubes is nice for desktop security, but it requires a powerful machine, and also maybe I could run Chimera in a qube some day for defense-in-depth :-)One advantage of a desktop focus is someday you could make money selling laptops with preinstalls. I&#x27;ll bet a lot of people would buy a cheap security-focused laptop to manage critical accounts, infrastructure, private keys even. Especially big companies that care about security. Then roll your profits into creating a great bug bounty program for your OS, in a virtuous cycle. reply darkwater 11 hours agoparentprevCame here to paste the same quote, just to highlight how disconnected from reality can be advertising \"does not have to require endless setup\" and then describe a rolling update distro, focused on power users and based on FreeBSD userland with a Linux kernel. reply Loxicon 5 hours agoprevwhat is non-GNU? reply SuperNinKenDo 5 hours agoparentSee [1]. Essentially the programs which most Linux distributions come with are provided by the GNU project, especially basic infrastructure stuff. Stuff like sed, less, awk, etc.However these programs have cousins in stuff like BSD or Busybox, which implement similar functionality, but have a mostly, or completely separate codebase, and some differences in what they can do and how you make them do it, with a common user-facing one being differences in the command line flags available, and precisely how they behave.In this case, Chimera uses a mix of stuff from FreeBSD and elsewhere, and also uses an alternative toolchain for compiling C, called musl, which is not glibc (glibc being a GNU project).Since Linux distributions that use GNU are almost the universal rule, distros like this describe themsekves as \"non-GNU\".https:&#x2F;&#x2F;chimera-linux.org&#x2F;about&#x2F;#alternative-userland reply Y_Y 4 hours agorootparent> I&#x27;d just like to interject for a moment. What you&#x27;re refering to as non-GNU Linux, is in fact, Linux, or as I&#x27;ve recently taken to calling it, GNU plus Linux minus GNU. reply Levitating 9 hours agoprev> Chimera is a general-purpose OS born from unhappiness with the state of Linux distributions.https:&#x2F;&#x2F;xkcd.com&#x2F;927&#x2F;It seems to have a nice build system. But I am not sure this solves any issue any other distribution has. And with the amount of opinionated choices this distribution has I imagine there are few who it fits. I think for many, Void would be a better choice.They do defend&#x2F;document their choices well. Though I don&#x27;t know why they&#x27;d support that many architectures, I think they might regret that.Anyway I wish this team the best of luck. Who knows, maybe some of their homegrown projects might see use elsewhere. reply q66 5 hours agoparentchimera is designed to solve many issues other distros have; this includes e.g. the poor state of toolchain security hardening (you won&#x27;t find any other distro with the same practical scope that&#x27;s more strongly hardened in builds)cbuild is also designed to solve real issues, particularly proper sandboxing and linting of builds to allow for a small team to maintain it while at the same time being fast and ensuring correctness (distro build systems often tend to be bash&#x2F;make monstrosities that do nowhere near enough where they need to while doing too much where they shouldn&#x27;t)i used to work on void, and there are good reasons i went to start a new project instead; this includes poor quality packaging for a lot of void stuff (by part caused by xbps-src design choices), poor platform support (all non-x86 stuff is buggy, partly because of cross-compiling and not running unit tests for things being built) and state of infrastructure, design issues of xbps itself (lack of solver, poor implementation of shlibs system and virtual packages, etc.), lacking service management (no oneshots, no transparent&#x2F;standardized support for user services, no support for dependencies, no support for service-integrated dbus activation etc.), lots of stuff sticks with legacy nonsense where systemd has taken over and improved things in the meantime (e.g. handling of dbus, user management and tmpfiles management, user services as mentioned before, etc), and so on and so onwe are also addressing the whole thing with \"everybody has adopted systemd and its functionality, and distros without systemd have instead stuck their head in the sand and pretend systemd is the devil and implement none of the stuff people want\" which is leading to increased dependence on systemd in various upstreams, and an increasing amount of bad hacks in non-systemd systemssupporting a lot of architectures is not something to regret, it&#x27;s a good goal to have and aids keeping the ecosystem healthy as well as giving people the choice of running the system on hardware they like; any pain caused by supporting multiple archs pays off several times reply Phelinofist 1 hour agorootparentWhile I&#x27;m a die hard Arch user and also kinda like systemd, I think the goals you have are good for the whole FOSS space overall, so I hope you succeed! :) reply natrys 8 hours agoparentprevChimera creator is a former Void dev iirc, maintained the PowerPC arch among other things. reply dataangel 11 hours agoprevSo they&#x27;re basically saying \"our system will be better because more things will just work\" but then they decided to use nonstandard libc and coreutils so actually getting existing Linux scripts and software to work in this distro will be harder. reply akosoaaafjdr 8 hours agoparentI think they are saying that in the operating system developer way, where \"just works\" means coherent and behaving according to some technical specification.It absolutely does not mean \"no manual programming or customization from the user required\". It means no dirty hacks, like the ones mainstream distros employ to make some of the customization and programming unnecessary that is actually kind of inherent to the way Unix has traditionally worked.That may very well be much less easy to work with from a consumer perspective, but from a systems programmer perspective it&#x27;s the opposite way. Those hacks that allow for the ease of use in a GNU userland make programming a massive pain in the ass where nothing \"just works\" the way it should, because GNU programs and libraries are in flagrant violation of every specification and rule of thumb that has ever really mattered for Unices.Also, it&#x27;s GNU libc that has gone out of its way to fail to adhere to standards, not musl. GNU does not give a single crap about open standards, because they believe that whatever GNU is IS the standard, which apparently is your view as well. That&#x27;s simply unacceptable for a lot of people. reply cycomanic 6 hours agorootparentCitation needed, seriously if you make such broad, sweeping statements at lest back it up with specific evidence. reply anthk 51 minutes agorootparentGNU glibc has some gratuitous extensions over ANSI C&#x2F;C99. Unix utilities have long non-standard and non-POSIX based flags. reply q66 5 hours agoparentprevthe point with \"just working\" applies to what the system ships, obviously third party whatever is outside of our controlthe system aims to have high quality packaging that results in a system that is consistently deterministic and auditable, while indeed making things just work (no extra effort beyond just installation required to get any software the system ships to work - on any CPU architecture it supports) - you can bootstrap a fully working system pretty much just by installing a single metapackage + a kernel in a root (and then refreshing the bootloader) reply mynameisnoone 4 hours agoparentprevThat&#x27;s also how I read it. For people who are masochists and want to invite yet more snowflake differences problems. Being too special and causing surprises leads to net negative productivity that swamps all other claimed goals and properties. reply torstenvl 10 hours agoparentprevSaying musl is non-standard is a serious allegation. Can you expand on that? In what way does it violate the standard? reply wavemode 10 hours agorootparentI read \"nonstandard\" in their comment by its dictionary definition (\"not average, normal, or usual\"). Not that it literally violates a published standard. reply NewJazz 10 hours agorootparentMost Linux installs are going to be using Bionic libc, so still dubious to call glibc \"standard\". This is Linux. There is no standard. OpenWRT used uClibc until 2019. reply LeFantome 9 hours agorootparentI am a fan of Chimera Linux and both Alpine and Void also use MUSL. But there is no denying that Glibc is the de facto standard on Linux Desktops and many desktop applications assume it.To me, that is a bad thing and we agree that diversity should be possible.We do not agree that “most Linux installs are going to be using Bionic”. Android uses the Linux kernel but it is not what people mean when they say “Linux”. The applications running on Android and the ones running on your Linux desktop are separate universes. reply NewJazz 6 hours agorootparentAndroid uses the Linux kernel but it is not what people mean when they say “Linux”.Speak for yourself.In my mind, Linux is home routers, smart TVs, digital signage, tablets, smartphone, fridges, and yes, servers and workstations. reply cycomanic 6 hours agorootparentAre you saying that just to be contrarian? When somebody tells you they&#x27;re running Linux on the laptop, you actually think they are owning a chrome book (considering that there are likely more chrome books than laptops with other linuxes), when you read a job add which requires Linux admin knowledge, you think they mean being able to install apps on android? reply NewJazz 4 hours agorootparentNo and no. reply xcv123 9 hours agorootparentprevGNU&#x2F;Linux is the standard, as in most common. That&#x27;s where it all started. Android is not used as a desktop or server OS. reply Conscat 3 hours agorootparentAndroid is used as a desktop OS in a limited capacity among a small group of hackers. replydataangel 6 hours agorootparentprevyes exactly what I meant reply torstenvl 10 hours agorootparentprevThat strikes me as disingenuous. Can you show me even one example of another person using \"nonstandard\" in this way as applied to a C library? reply dataangel 6 hours agorootparentThat is really how I meant it. Using Linux for almost 20 years I&#x27;ve found the most important part of having a working system is being on the beaten path. Distros that do too much exotic stuff spend all their time fruitlessly trying to keep up with porting and end up confined to a small user base of OS geekery enthusiasts. reply arp242 8 hours agorootparentprevYou are replying to someone who did, so there&#x27;s your example. There&#x27;s a bunch of other people in this thread as well – you really don&#x27;t need to look very far.\"Standard\" is one of those words that can mean different things. Insisting on one absolute definition and calling anyone who uses another definition \"disingenuous\" is not hugely constructive. reply trenchgun 24 minutes agorootparentAre you saying there is not only one \"standard\" use of the word \"standard\"? reply xcv123 9 hours agorootparentprevGlibc is the standard (as in the most commonly used) libc. Musl is not commonly used. Musl is not the standard libc on Linux.It requires some effort to migrate applications to musl, and there are functional differences from glibc. https:&#x2F;&#x2F;wiki.musl-libc.org&#x2F;functional-differences-from-glibc... replydizhn 2 hours agorootparentprevIf a distro is advertising the fact that they are not using glibc, then that&#x27;s the standard. I don&#x27;t mean no snark. This is the way parent probably used the term. It doesn&#x27;t mean musl is not good or it violates some standard. Though you are more likely to have problems with it as an end user where gentoo&#x2F;arch wikis won&#x27;t be of any help. reply marcus0x62 10 hours agorootparentprev> Saying musk is non-standard is a serious allegation.No, it isn&#x27;t. It&#x27;s the GP&#x27;s opinion.Standard has a few different meanings, including something typically or commonly used. As in \"GNU Libc has been the standard C library used by Linux distributions since 1991.\" That would be, you know, a statement of fact. Musl is, at best, a niche option used by a few distros. reply dataangel 6 hours agorootparentIt&#x27;s not used by any of the major ones, so in practice lots of apps will be broken. I like musl, and I link it for my own stuff but I only have to make sure my stuff works. if I had to make sure everyone&#x27;s existing stuff worked glibc is the only practical choice. reply mynameisnoone 3 hours agorootparentYep. There are lots of edge-cases and macros that glibc provides are difficult to emulate because they require a lot of domain-specific knowledge and special handling. There isn&#x27;t really a way to use musl in any large distro without lots and lots of patching and giving up correctness and completeness. It&#x27;s akin to not using ICU4{C,J} and praying that simplistic Unicode handling like normalization will magically work.Using musl is fine for limited uses, but it&#x27;s magical thinking to believe that it&#x27;s at exact feature and functional parity replacement for glibc. replyalberth 11 hours agoprevnext [2 more] [flagged] marcus0x62 10 hours agoparentThey&#x27;ve gone out of their way to use non-GNU tools and libraries. reply atlas_hugged 3 hours agoprev [6 more] [flagged] pjmlp 3 hours agoparent [–] People that shit at GNU forget that without it, Linux would never ever taken off.It was the AT&T vs BSD lawsuit, giving uncertainty to BSD&#x27;s future, combined with the maturity of GNU userspace that gave Linux the opportunity to be relevant at all.Nowadays it is the GNU religion.Personally I couldn&#x27;t care less of what shape of UNIX I get to use, though I do acknowledge that GNU religion is what allowed me not to spend endless nights at the university compute center fighting for a DG&#x2F;UX or Solaris terminal, instead we could work on assignments from the comfort of our homes. reply atlas_hugged 2 hours agorootparent [–] Fundie Apología isn’t much better. reply pjmlp 2 hours agorootparent [–] macOS, iOS, Android, ChromeOS, PlayStation and WSL.Welcome to what a world without GNU looks like. reply anthk 1 hour agorootparent [–] That \"GNU\" religion you call it has been able to speed up computing like no time else.Android have been enshitifying the last releases on encryption and privacy. Ironically Replicant 6 (libred Android 6.0) has more settings for that than the current Android 12.On Chrome OS, it&#x27;s just a shell to Google services. Put these services down, no your device it&#x27;s 75% useless.On PS, it&#x27;s just a DRM -potentially-brickable-without-internet- console, and I &#x27;ve had more fun overall with 8-16 bit games on a EEPROM based device (technically not a computing device, it&#x27;s everything hardware, so it&#x27;s fine), than the current DRM locked consoles with &#x27;always-online&#x27; features making them useless too when your ISP goes down. At least with a ROM burned handheld I can play games anywhere and any time. reply pjmlp 35 minutes agorootparent [–] You should be answering to OP, not me.HN, where people quick fire answer to comments without reading the threads properly, alongside lack of English compreehension.==> \"People that shit at GNU forget that without it, Linux would never ever taken off.\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Chimera is a new operating system designed as an alternative to existing Linux distributions.",
      "It aims to offer a straightforward and practical system without the need for extensive setup and customization.",
      "Chimera combines the convenience of complex distributions with conceptual simplicity using innovative tools and approaches."
    ],
    "commentSummary": [
      "The discussion revolves around Chimera Linux, a non-GNU Linux distribution, and its suitability for longstanding GNU users.",
      "There is a debate about the use of different C libraries like musl and glibc, as well as the associated performance and compatibility issues.",
      "Users share their opinions on the builds and performance of Chimera Linux and its potential as an alternative to BSD."
    ],
    "points": 174,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1702759535
  },
  {
    "id": 38670465,
    "title": "Study reveals varying performance and user perceptions of modern CAPTCHAs",
    "originLink": "https://arxiv.org/abs/2307.12108",
    "originBody": "Computer Science > Cryptography and Security arXiv:2307.12108 (cs) [Submitted on 22 Jul 2023] Title:An Empirical Study & Evaluation of Modern CAPTCHAs Authors:Andrew Searles, Yoshimichi Nakatsuka, Ercan Ozturk, Andrew Paverd, Gene Tsudik, Ai Enkoji Download PDF Abstract:For nearly two decades, CAPTCHAs have been widely used as a means of protection against bots. Throughout the years, as their use grew, techniques to defeat or bypass CAPTCHAs have continued to improve. Meanwhile, CAPTCHAs have also evolved in terms of sophistication and diversity, becoming increasingly difficult to solve for both bots (machines) and humans. Given this long-standing and still-ongoing arms race, it is critical to investigate how long it takes legitimate users to solve modern CAPTCHAs, and how they are perceived by those users. In this work, we explore CAPTCHAs in the wild by evaluating users' solving performance and perceptions of unmodified currently-deployed CAPTCHAs. We obtain this data through manual inspection of popular websites and user studies in which 1,400 participants collectively solved 14,000 CAPTCHAs. Results show significant differences between the most popular types of CAPTCHAs: surprisingly, solving time and user perception are not always correlated. We performed a comparative study to investigate the effect of experimental context -- specifically the difference between solving CAPTCHAs directly versus solving them as part of a more natural task, such as account creation. Whilst there were several potential confounding factors, our results show that experimental context could have an impact on this task, and must be taken into account in future CAPTCHA studies. Finally, we investigate CAPTCHA-induced user task abandonment by analyzing participants who start and do not complete the task. Comments: Accepted at USENIX Security 2023 Subjects: Cryptography and Security (cs.CR) Cite as: arXiv:2307.12108 [cs.CR](or arXiv:2307.12108v1 [cs.CR] for this version)https://doi.org/10.48550/arXiv.2307.12108 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yoshimichi Nakatsuka [view email] [v1] Sat, 22 Jul 2023 15:36:13 UTC (1,815 KB) Full-text links: Access Paper: Download PDF PostScript Other Formats Current browse context: cs.CRnewrecent2307 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=38670465",
    "commentBody": "AI bots are now outperforming humans in solving CAPTCHAsHacker NewspastloginAI bots are now outperforming humans in solving CAPTCHAs (arxiv.org) 129 points by vincent_s 4 hours ago| hidepastfavorite118 comments caymanjim 1 hour agoGoogle CAPTCHAs were designed and deployed as a mechanism to train AIs. That&#x27;s why they are the way they are. Any security theater surrounding them is entirely incidental. So it&#x27;s no surprise that the AIs are now good at solving them. We&#x27;ve trained them for years. reply noduerme 1 hour agoparentAll true, except: While these are considered just an excruciating security pain for users, they do serve a non-theatrical purpose in many cases of throttling the speed of brute force attacks (or at least costing your opponent money). reply snordgren 1 hour agorootparentGPT-4 (in)famously tricked a human to do a captcha for it. The current GPT-4 with vision would probably have been able to do it without the human, but maybe it has been “gaslit” by all the content online saying that only humans can solve captchas, that it doesn’t consider it? reply stavros 35 minutes agorootparentI really doubt that GPT-4 had the \"will\" to do anything. Someone must have asked it to \"want\" to trick a user. reply JimDabell 4 minutes agorootparentIt’s from here: https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;gpt-4.pdf (search for \"CAPTCHA\"). It was an artificial exercise that got massively exaggerated. It was explicitly instructed to do nefarious things like lie to people, it didn’t do those things of its own accord. reply stavros 3 minutes agorootparentThank you for the link, I had found it after some Googling but neglected to post. Yep, they instructed GPT-4 to be nefarious, and it followed the instruction.Hardly the AI uprising, though definitely a good tool for anyone, good or evil. hhh 17 minutes agorootparentprevIt’s safety trained to not solve captchas. reply rvnx 12 minutes agorootparentYes, and you can workaround it by asking it to read ancient writings on antiques for example.I don’t think it should be OpenAI deciding what is allowed or not though. reply Pesthuf 13 minutes agorootparentprevI’ve seen screenshots of people tricking it into solving captchas. reply pyeri 34 minutes agoparentprevOnce they get fully trained then how will websites ever distinguish between an intelligent bot and real human? At least now, they are outsourcing that filtering to services like cloudflare. But with this kind of training, how will even cloudflare distinguish between bot and the human? reply JimDabell 3 minutes agorootparent> how will websites ever distinguish between an intelligent bot and real human?Things like Private Access Tokens: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;eliminating-captchas-on-iphones-... reply szundi 3 minutes agorootparentprevEU digital ID, asking for mobile number and sending text, so something that is linked to an ID and&#x2F;or costs money to have. Goodbye anonimity, probably. reply jacquesm 7 minutes agorootparentprevThe human will be the slower one. reply candiodari 3 minutes agorootparentYeah, no offence, but sleep(2 + random.sample(coffee + toilet + sneezing + normal response time)) has been a required part of web scrapers since forever.With coffee N(1,5 minutes, 20 seconds), toilet N(4 minutes, 30 seconds), ... reply candiodari 5 minutes agorootparentprevThe thing about CAPTCHAs is that convnets were already better than the average human at reading most&#x2F;all visual captchas, since ~2000. You still needed to program the logic of the captcha (it couldn&#x27;t follow instructions like \"find the red lights\", but it could take a picture and find the red lights).I wonder when we&#x27;ll get to the point that employers can&#x27;t tell the difference between transformers and real humans anymore ... reply panny 38 minutes agoparentprev>So it&#x27;s no surprise that the AIs are now good at solving themFunnily enough, AI may be better at solving them than people. I&#x27;ve encountered many Google captchas which reject the correct answers, because you know... bots trained it to accept incorrect ones. Anyway, at least it&#x27;s not stop signs anymore. It must have been truly embarrassing that Google was simultaneously selling \"self driving\" cars but at the same time demonstrating that stop sign recognition couldn&#x27;t be done by robots. reply leobg 1 hour agoparentprevI still find it funny that Google, with the advantage of having millions of Internet users train their AI like galley slaves for free, hasn’t yet been able to crack vision driven self driving. Tesla had no such advantage when training their FSD to recognize traffic lights, bicycles, motorcycles, etc. reply eviks 1 hour agorootparentIt&#x27;s a much harder problem, and Tesla is nowhere close to the solution reply noduerme 1 hour agorootparentprevTesla, the company that just recalled 2 million self driving cars?In fairness, the company best positioned to harness user input to an AI that avoids crashes would probably be Rockstar. OTOH, that AI would definitely not obey stop signs or pedestrians. reply bb123 1 hour agorootparentBy recall you mean a completely routine OTA software update done while the driver is asleep. reply csydas 38 minutes agorootparentA recall for essential maintenance is just that. I would focus on the need for an urgent update due to the flaws rather than the issuing agency&#x27;s lack of more accurate terminology for a relatively new element to cars. Rolling around in semantic mud on the term recall is not sensible, as the definition in regards to cars is fairly specific [0]. Basically a recall just means there is a safety defect that must be addressed by the manufacturer. In Tesla&#x27;s case, yes, they can push out an update, but the delivery mechanism of the means of addressing the defect should not be the focus.0 - https:&#x2F;&#x2F;www.progressive.com&#x2F;lifelanes&#x2F;on-the-road&#x2F;understand... reply tempestn 1 hour agorootparentprevAmusingly the infotainment system in our Model Y actually crashed on the way home tonight, and when it rebooted it decided to install the update then, while driving. Sent me a notification on my phone immediately afterwards. To be fair, the updates don&#x27;t usually go that way. reply imjonse 1 hour agorootparentprevHow can it detect the driver is asleep? reply noduerme 1 hour agorootparentA neural implant that only kills 10% of monkeys. reply cm2187 15 minutes agorootparentMonkeys at the wheel is probably the solution for self driving cars. reply bheadmaster 1 hour agorootparentprevTesla recalled two million vehicles after federal officials said it had not done enough to make sure that drivers remained attentive when using the system. Not because their self-driving system sucks, or whatever you were trying to imply. reply diputsmonro 38 minutes agorootparentIf the self driving system were worth it&#x27;s salt, it wouldn&#x27;t matter if the drivers weren&#x27;t paying attention. Ergo, the system sucks, or is at the very least not nearly as good as Tesla likes to tout. reply hehhehaha 1 hour agorootparentprev\"recall\" reply mike_d 1 hour agorootparentprev> hasn’t yet been able to crack vision driven self drivingBut they have? For years Google Street view has read signs, house numbers, phone numbers of businesses, etc. from the environment. It is safe to assume they have this built into Waymo as well.I assume you might be trying to reference \"vision only\" self-driving, which is a fantasy made up by Elon Musk because nobody would sell him LiDAR sensors cheaply.https:&#x2F;&#x2F;www.thedrive.com&#x2F;tech&#x2F;43779&#x2F;this-tesla-model-y-dummy... reply codedrivendev 4 minutes agoprevI think I prefer the recent CAPTCHAs (where you solve a puzzle by rotating an item, or finding the matching item). The older ones from years ago (deciphering mangled text and trying to work out if it is an `i`, `1` or `l` were more annoying) reply gary_0 1 hour agoprevDoes HN ever require CAPTCHAs? It seems to do pretty well with its basic but battle-tested moderation&#x2F;antispam tools, and rate-limiting that seems to repel all but the most concerted DDoS attacks. I don&#x27;t think HN has any unreasonable restrictions on scraping or third-party clients, either. And it manages to serve 5M unique visitors a month and 10M views a day[0].[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33454140 reply bongobingo1 54 minutes agoparentI cant tell if the audience of HN are more likely to script something untoward against HN, be that DDOS or just \"check out my product\" spam, because its a bunch of hackers - or less likely to do it because (maybe) we like having nice things, or figure the audience is too in the know to fall for boring crypto spam. reply SXX 13 minutes agorootparentHN audience is rich enough to just pay $10 for 1000 solved CAPTCHAs of any complexity since those services are human powered. reply ShamelessC 12 minutes agoparentprevThey go down somewhat frequently. I think it’s like four 9’s? I’m not sure why they insist on running just a few machines though. They have more than enough money and probably make up the difference by the advertising for YC that they get. reply rezonant 9 minutes agorootparentUnless something changed, it&#x27;s just the one server. reply jamiek88 1 hour agoparentprevOn one machine! :) reply anonzzzies 1 hour agoprevI guess validating a payment card is going to be the next step to sign up for whatever. Don’t allow pre paid BINs and let’s go. Gonna be pretty miserable, however someone needs to find something as I currently would rather pay 0.01$ instead of solving a captcha. Especially the select all the bicycles; it’s a waste of life. reply mrtksn 53 minutes agoparentThe next step is device attestation. IIRC Safari already does this, so you should not see captcha on places that support it.Something that can work on any browser can be like this: Scan the QR code in your iPhone or Android device that supports attestation. Will ask you if you approve login, then will attest for you. If you turn out to be a bad actor, the website can ban this device - so no flooding with a single device. reply shwouchk 1 hour agoparentprevPlease. Last time I had to solve a captcha it was wasted 15 minutes (not exaggerating!) of my life, clicking on an endless stream of bikes, motorcycles, buses and stoplights. As punishment for using a vpn. reply pasc1878 21 minutes agorootparentI&#x27;ve managed that without a VPN - although I do have poor sight.It also does not help that the shown busses, water hydrants, pavements look totally unfamiliar to me. (Why aren&#x27;t captures taken from all over the world Indian busses would be fun - London ones would be too boring) reply calderknight 1 hour agoparentprevor just use Worldcoin reply ackbar03 1 hour agorootparentha! someone actually beat me to this comment reply 2Gkashmiri 1 hour agoparentprevlook up indian UPI. \"validating payment card\" and all that snazzy bits are error prone, old, archaic and cost a fortune to businesses.in upi system, you are presented with a QR code or you input your UPI ID, you click pay and it gets through.if you are worried about \"fraud protection\", why rely on an intermediary like ebay or credit card company and instead should take up with your bank or the seller or courts. reply EGreg 1 hour agorootparentThere is literally nothing you can do to prevent bot accounts online now, other than requiring people to show up to events periodically. And even then, they can just use bots AFTER they’ve validated their accounts.The Internet will become a dark forest, and since that is where all of our communication and transactions happen of any significance, that’s pretty much game over for the significance of human activity.Think I am overstating the fact? It already happened with wall street trading. First, institutions prefer bots to human. Then, you will come to prefer bots to humans. Then every human will be surrounded with 999 bots and unable to change anything or appeal to any significant number of humans to change anything. reply rezonant 17 minutes agoprevAs best as I can tell this study explores many facets of how humans solve captchas. I couldn&#x27;t find anything about AIs outperforming humans in the study. Can someone give me a section reference?Solving reCAPTCHA v2&#x2F;v3 requires more than just clicking the box and an image puzzle. If that was all it was we would be overrun by now.Lots of folks commenting that the title&#x27;s statement makes sense because CAPTCHAs are meant to train AIs. While this is broadly true, that&#x27;s a nice side effect. The way modern CAPTCHAs like reCaptcha V2+ work, is they monitor behavioral analytics-- from things like your browsing history to how your mouse moves on the page. This is why most of the time, most people only need to click a box. I&#x27;m not sure there&#x27;s a LMM out there that includes mouse movement as a modality.The kinds of AIs that are designed to beat CAPTCHAs also don&#x27;t have the data from Google et al to use to train, unless we&#x27;re concerned Google is training it&#x27;s own bots to bypass CAPTCHAs, I suppose it&#x27;s not inconceivable? reply jon_richards 6 minutes agoprevThe problem with designing a bear proof trash can is that there’s significant overlap between the smartest bears and the dumbest tourists. reply ixmerof 18 minutes agoprevHave they tried with puzzles used by Rockstar Games or HBO Max to reset a password? They are impossible to solve, asking to solve 17 questions and more and still failing you to retry with higher count. Even the audio version is quite innovative reply dasrecht 7 minutes agoprevSo we now proof that we&#x27;re human by failing those tests? reply urig 28 minutes agoprevHow did the OP get from the article linked to the title of this post? reply rezonant 15 minutes agoparentI&#x27;m also wondering this. I don&#x27;t think it has anything to do with AI solves. reply mdale 2 hours agoprevI think captchas disappear next year or so. Already was soft human determination. reply lakpan 1 hour agoparentThat’s excessively optimistic. The most likely scenario is that we’ll have captchas for the next 30 years but only humans will be bothered by them. reply zztop44 1 hour agorootparentJust like the technology basically exists for fully autonomous self-owned fleets of self driving robotaxis. Where the only jobs for humans are cleaning vomit off the back seat. reply js8 14 minutes agorootparentprevSounds like DRM - pirates do not care, legitimate users are bothered. reply resolutebat 34 minutes agorootparentprevThis. There are plenty of government websites etc out there that have completely antiquated captchas next to the helpful \"works best in Internet Explorer 6\" suggestion. reply topspin 2 hours agoparentprevWhat replaces captchas? Are there any not excessively burdensome tests that a standard issue human can pass that a machine somehow cannot? I&#x27;m assuming the \"find all the bicycles\" tests are also obsolete. reply ReactiveJelly 2 hours agorootparentSadly, probably something like TPMs or email logins (from a reputable email provider of course, one who requires SMS to sign up, from a reputable phone provider of course, one who doesn&#x27;t offer free VoIP numbers and requires a credit card to sign up, from a reputable card brand of course, not a burner card) reply radium3d 1 hour agorootparentfrom a reputable card brand who doesn&#x27;t allow usage of stolen cards? lol maybe the internet just implodes. reply nomel 2 hours agorootparentprevSomething realtime, like video, is beyond most models at the moment. After that, realtime input, like little mini game you have to show proficiency at by scoring 5. I think the mini game approach could be fun. It could probably work for a year or two. :-\\ reply serf 1 hour agorootparentthe minigame thing has been defeated for a long time. it&#x27;s trivial to solve when there are only so many subsets of a game, however randomized the starting states are.I guess there is a silver-lining in the premise of AI generated one-time-use games for that sake, but then there is a significant \"can a human even do this?\" problem to conquer at that point.. and worse the same AI tech is going to be established on the opposite side of the wall trying to defeat the thing.I think it&#x27;ll all boil down to some sort of state-license fallback method like \"please enter a CC or ID number to continue\" -- which is ultimately a defeat of the user, unfortunately. reply chii 1 hour agorootparentprev> a standard issue human can pass that a machine somehow cannot?may be the premise is wrong.Why prevent non-humans from registering&#x2F;using&#x2F;viewing? reply shadowgovt 1 hour agorootparentBecause automated systems operating at scale outstrip the ability of the administrator to maintain the service provided. reply chii 57 minutes agorootparentIf each additional user is not adding additional revenue that exceeds the cost of that user (automated or not), you don&#x27;t have a business model. reply shadowgovt 21 minutes agorootparentBut if you can keep the bots off your bandwidth you don&#x27;t necessarily need a business model, depending on what you intend to share online. reply hiAndrewQuinn 1 hour agorootparentprevA market of human-oriented hardware keys, where the keys are only intended to be sold to actual human beings, with legal or otherwise cash bounties in place for people who can provide evidence of the keys being sold to or otherwise falling into the hands of non-human entities. reply Roark66 1 hour agorootparentWhat&#x27;s stopping a human buying a thousand to use for his bot farm? reply hiAndrewQuinn 47 minutes agorootparentAs mentioned, a bounty system. Someone who buys a thousand to use would have to be very clever to evade the eyes of all the people interested in profiting off of revealing his actions and getting the chips turned off. reply quickthrower2 1 hour agorootparentprevAn international identity card :-&#x2F; reply SirMaster 2 hours agorootparentprevDoesn&#x27;t the checkmark thing work?Or are bots somehow able to do those too? reply tomjen3 1 hour agorootparentprevNothing. People will have to realise that when you put things out for the world you put things out for the world. reply shadowgovt 1 hour agorootparentWho pays for the bandwidth and download resources then? reply JumpCrisscross 1 hour agoprevSomeone will get rich turning this into a browser plug-in. reply beAbU 1 hour agoparentNope, the moment this becomes a viable solution then spammers will pick it up, making captcha useless amost overnight.Websites will very quickly pivot to alternative solutions like payment card verfification, etc. reply cinntaile 1 hour agorootparentSolving captchas is pretty rare nowadays. Now you usually just press a button and then it does some sort of fingerprinting to determine if you&#x27;re a human. reply plsbenice34 1 hour agorootparentIf you make zero attempts toward privacy maybe. Just turn on a commercial VPN or Tor and you&#x27;ll find that your quality of life can quickly become severely damaged by captchas. I cant even do a Google search without a captcha so I started using Mullvad Leta as a proxy. reply cinntaile 23 minutes agorootparentI block ads and stuff but you&#x27;re right that I don&#x27;t use VPNs or Tor.A lot of bots also use VPNs and Tor so captchas being a pain in the ass is probably working as intended, that way most people won&#x27;t bother using services like that? This is different from regular internet users, there is no reason to make their life more difficult than necessary. reply ponector 1 hour agorootparentprevTry to use VPN. You will get captcha with tons of bicycles to click... reply addandsubtract 41 minutes agorootparentWhy is the UI such a pain in the ass, when it&#x27;s designed to be used by humans?! Why do I have to click 8 individual boxes and can&#x27;t just drag-select an area. I hate those captchas with a passion. reply Xenoamorphous 26 minutes agorootparentAnd does the post count as traffic light? reply mkl 25 minutes agorootparentprevAnd the infuriatingly slow fade out and in when it changes pictures. It seems designed to frustrate humans. reply shadowgovt 1 hour agorootparentprevOr to the next unsolved problem in machine learning. The whole point of ReCAPTCHA, at least, is to convert all this human labor into training data. reply LoganDark 1 hour agoparentprevYou can already buy captcha solves through browser plugins. The only difference is they currently use clickfarms full of underpaid workers from third-world countries reply tunnuz 25 minutes agoprevWhat a surprise since CAPTCHAs were created to gather data to train AIs reply ArtTimeInvestor 1 hour agoprevThe solution could be a cryptocurrency which can be mined in the browser. Hashcash, which was one of the inspirations for Bitcoin, was initially invented to prevent email spam.Consumer devices have a lot of spare CPU and RAM. So a proof-of-work algorithm which consumes those resources for a minute might work?If it generates $0.01 for the website owner in that minute, maybe that would work? reply swinglock 1 hour agoparentProof of work can already be implemented without a token.Tor has such a feature for denial of service protection.https:&#x2F;&#x2F;blog.torproject.org&#x2F;introducing-proof-of-work-defens...A benefit of a token is you can recycle previous proof of work by using a small amount of Bitcoin, which could be transferred using Lightning. The value could also be transferred back some amount of time after registration given no bad behavior, allowing for larger sums than a cent, which could provide better protection. reply ArtTimeInvestor 55 minutes agorootparentWith a token, you probably get a higher efficiency. Similar to how a heatpump is more efficient than a heater.If you only consume resources on the client side, then you hope that an attacker thinks \"I won&#x27;t invest $0.01 of resources just to log in here\".If you also transfer the consumed resources to the server, you get an additional benefit: The server thinks \"$0.01 is enough to cover the costs of a fake signup\".And the second benefit is probably even better than the first. The server will never really know how cheaply attackers can access resources. But they probably know how much a fake signup costs them. reply trompetenaccoun 34 minutes agorootparentI think a fairer solution will be some form of proof of personhood that isn&#x27;t PoW-based. Your idea isn&#x27;t bad but it gives more power to those who can afford a lot of devices. You know those Chinese mobile phone click farms they use to game app stores? It will be like that, PoW can prevent spam only to a certain degree and with all the social media and networks we have today there is a lot of money in influencing the users. So spending a few million dollars on devices can be very profitable if it lets you boost certain messages. reply ArtTimeInvestor 14 minutes agorootparentDepends on the use case.If the captcha is to prevent overuse of a free trial, then nobody will operate a lot of devices just to get more free trials if the paid version is cheaper than those devices.If the use case is to improve democracy, then it gets more complicated. reply swinglock 22 minutes agorootparentprevBut is it worth billions? You just need to increase the cost 1000 fold and pay it back after a holding period to implement that.The drawback is it gets a lot more complex when using a token, because of the additional state, communication, costs and security.A one shot proof of work can be very simple, but probably not effective enough, given that mobile users likely do not want to wait what may have to be many minutes and drain their battery.Freezing a cent or a dollar for days seems like a better option. Might very well be that VISA&#x2F;MasterCard figures this out before the crypto bros build anything usable. It will be far easier to do without decentralization and would also be great to spy on and control people. reply sideshowb 23 minutes agoparentprevJust what we need, another way to waste energy reply ric2b 47 minutes agoparentprevThose devices have a lot of spare CPU and RAM but basically no spare battery capacity. reply insanitybit 1 hour agoparentprevWouldn&#x27;t any proof of work be just as easy for a computer to achieve as a human? reply SturgeonsLaw 4 minutes agorootparentYeah but it would cost spammers who want to impersonate a large number of humans at once reply trompetenaccoun 26 minutes agorootparentprev&#x27;Proof of Work&#x27; as it&#x27;s generally understood is done by computers only. But I guess I understand what you&#x27;re asking and the answer is yes, that is a problem. For Sybil resistance it&#x27;s better to know if someone is a unique human, not if they&#x27;re a machine that has paid the toll: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Proof_of_personhoodThere are exotic solutions like the &#x27;Idena Network&#x27;. But sadly I have to admit the best solution I&#x27;ve seen so far is Sam Altman&#x27;s Worldcoin. Not that I&#x27;m a fan, I still hope we can find something better than scanning everyone&#x27;s eyeball. reply CaptainFever 24 minutes agorootparentprevYes, but it&#x27;s more of an anti spam measure. reply k4rli 1 hour agoprevAre there any open local models for basic alphanumeric picture captchas to save on 2captcha? reply bawolff 1 hour agoparentA surprising number can be solved with teseract and simple preprocessing (e.g. thresholding, expand and contract lines).For more complex cases, not AI but consider the attack in https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;conference&#x2F;woot14&#x2F;woot14... reply bamboozled 1 hour agoprevGoogle created this problem, let’s see them solve it. reply hiAndrewQuinn 1 hour agoprevGood. Hardware authentication is where it&#x27;s at. reply rgrieselhuber 1 hour agoparentLike the Clipper Chip? reply olliej 2 hours agoprevIt&#x27;s really amazing when we still get those text ones and nowadays you can literally select the text in many of the images and copy&#x2F;paste into the input field. reply yaomtc 2 hours agoparentI&#x27;ve never seen a text version that lets me select the text, that&#x27;s bizarre reply _rutinerad 2 hours agorootparentI’m assuming that he means that on (for example) Mac you can select text from any image and copy paste it.https:&#x2F;&#x2F;uk.pcmag.com&#x2F;macos&#x2F;138058&#x2F;not-just-iphone-how-to-use... reply olliej 2 hours agorootparent100% correct, I assumed windows also let people do that given text recognition is apparently trivial now (to the extent it&#x27;s annoying - trying to drag images and get text selection instead is annoying :-&#x2F;) reply serf 1 hour agorootparentWindows has gone sort of the opposite way, copy&#x2F;paste is now often hindered if the engine recognizes the string to be sensitive or otherwise un-wise to copy to your clipboard.I&#x27;ve had a few instances on Windows 11 and surrounding software where ctrl-C as well as the context menu entry for &#x27;Copy&#x27; were greyed out for this reason when skimming through logfiles, presumably because there was something about the line that triggered the MS \"that&#x27;s a password!\" regex; stuuuupid stuff. reply reddalo 1 hour agorootparentprevI think Windows now does it as well, but of course (as all things Windows) it works only in very few apps (forget Win32 ones, for example). reply olliej 1 hour agorootparentprev@_rutinerad got it - on macOS you can select text in any image, and I just assumed you could do that on windows as well (I figure in the context of linux it would be much more dependent on specific configuration so unilateral assumptions on behaviour would be questionable).It&#x27;s honestly annoying as it frequently interferes with dragging images out of safari, except on those occasions when I do want the text when it&#x27;s super useful. I think the iOS interface just tells you there&#x27;s text in an image or photo and gives you the option to copy it rather than cursor based selection you get on Mac.[edit: from other comments it sounds like windows can do this but it&#x27;s not always present, and not present in all circumstances, which makes me wonder how many cases in cocoa&#x2F;uikit&#x2F;swiftui it does not work] reply timschmidt 1 hour agorootparentAm I the only one paranoid enough to think that this means Apple is now indexing even the text content of images stored on it&#x27;s users computers? reply llamaInSouth 4 hours agoprevI already had issues with captchas (specially on tor).... so now its going to get worst? reply muzani 1 hour agoparentTor is practically unusable for me because it triggers so many captchas. I end up using Mullvad Browser, which is similar but byo VPN. reply shadowgovt 1 hour agoparentprevThe price we pay for obfuscating the trust signals on our connection is that our connection is untrusted.As an American, I have a similar experience when I travel across the Atlantic. It&#x27;s always funny to me when I land in the UK, start using websites I use normally at home, and get cookie verification modals from hell to breakfast. reply maksimur 1 hour agorootparentCan&#x27;t vouch for other Europeans but I got used to them to the point my arm moves automatically where needed before clicking, even accounting for extra modals. I almost don&#x27;t register them anymore. reply visarga 1 hour agoprevsimple - if the user solves is too well, reject reply muzani 1 hour agoparentval delay = 500 + Math.random() * 3000 reply peter_retief 1 hour agoprevIs this really so surprising? Probably a better captcha would be sign of life not puzzles. reply hknmtt 1 hour agoprev [–] no need for captchas, just implement throttling per ip. like bcrypt dues for passwords. if a bot fills up a form(or whatever), so be it, but it won&#x27;t be able to do it for another N seconds or minutes..so the problem then is lowered from per try, which can be thousands of submissions, all the way down to per period and per ip. reply Roark66 1 hour agoparent [–] Hell no... Some of us sit behind CGNAT, half a million of us on a single public IP. reply vanviegen 58 minutes agorootparent [–] Exactly. Besides that, a bad actor may well have easy access to tens of thousands of ip address from all over the globe.. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The study examines the effectiveness and user experience of modern CAPTCHAs, which are used to prevent bots.",
      "Researchers evaluated the solving time and user perceptions of popular CAPTCHAs through manual inspection and user studies.",
      "The study found significant differences in the performance and perception of different types of CAPTCHAs, as well as the impact of the experimental context on CAPTCHA-solving tasks."
    ],
    "commentSummary": [
      "The effectiveness and challenges posed by CAPTCHAs in different situations are under discussion.",
      "AI bots are becoming increasingly better at solving CAPTCHAs, prompting the search for alternative user validation methods.",
      "The potential disappearance of CAPTCHAs raises concerns about online security, with suggestions for alternatives such as device attestation or payment systems. Privacy concerns and frustrations with CAPTCHAs are also brought up, along with the possibility of using proof of personhood as an alternative to proof of work. Other topics include text recognition in images, Apple's text copying feature, and the inconvenience of cookie verification modals for international users."
    ],
    "points": 132,
    "commentCount": 119,
    "retryCount": 0,
    "time": 1702789831
  },
  {
    "id": 38668080,
    "title": "Samsung and ASML Partner to Develop 2nm Chips",
    "originLink": "https://www.koreaherald.com/view.php?ud=20231215000518",
    "originBody": "Most Popular 6 10 flights canceled in Jeju as S. Korea braces for cold wave 7 S. Korea expresses 'stern' protest to China, Russia over air defense zone incursion 8 Haenam poised to become top travel destination for culture, history buffs 9 Global viewers warm to Korea's 'slow paced' dating shows 10 Half of Koreans could be over 65 by 2072 1 Police tracking suspect of graffiti vandalism at Seoul palace 2 Cold wave hits S. Korea; temperatures to further drop 3 Only 1 of 4 women in 20s want to get married: report 4 [Weekender] Korea's elderly poverty reveals itself in heart of Seoul 5 S. Korea, US to complete guidelines on nuclear strategy planning, operation by mid-2024: Seoul official 6 10 flights canceled in Jeju as S. Korea braces for cold wave 7 S. Korea expresses 'stern' protest to China, Russia over air defense zone incursion 8 Haenam poised to become top travel destination for culture, history buffs 9 Global viewers warm to Korea's 'slow paced' dating shows 10 Half of Koreans could be over 65 by 2072 1 Police tracking suspect of graffiti vandalism at Seoul palace 2 Cold wave hits S. Korea; temperatures to further drop 3 Only 1 of 4 women in 20s want to get married: report 4 [Weekender] Korea's elderly poverty reveals itself in heart of Seoul 5 S. Korea, US to complete guidelines on nuclear strategy planning, operation by mid-2024: Seoul official NewsletterSubscribe Start your day with a roundup of key stories from The Korea Herald with news and comment on all that’s happening in Korea. Samsung chief returns from Netherlands, satisfied with ASML deal Deal with ASML raises possibility that Samsung could get ahead in producing cutting-edge 2-nanometer chips By Jo He-rim Published : Dec. 15, 2023 - 15:10 Link copied Samsung Electronics Chairman Lee Jae-yong speaks to a reporter at Gimpo International Airport upon returning from his trip to the Netherlands, on Friday. (Yonhap) Samsung Electronics Chairman Lee Jae-yong hinted at his satisfaction over his trip to the Netherlands with President Yoon Suk Yeol on Friday, saying that most of the achievements made there were focused on semiconductors. \"About 90 percent of the achievements made in the trip to the Netherlands are on semiconductors,” Lee told reporters when asked about the achievements of the trip, at Gimpo International Airport on Friday, with a satisfied smile on his face. Lee returned from the trip to the European country in the early morning. He had accompanied the president during the four-day state visit to meet with Dutch leaders as well as the heads of prominent Dutch chip equipment firms, including ASML, to forge a number of deals. ASML is the sole manufacturer of EUV equipment -- a key system for producing the world's most advanced semiconductor chips with nodes at 7 nanometers and below -- with unrivaled technology. Securing an order of the ASML's EUV machines, of which only 40 to 50 units per year are produced, has become a mission for global chip suppliers, as the equipment is deemed a crucial factor that can sway chipmakers' survival in the market. Samsung, the world's top memory chipmaker by revenue, inked a 1-trillion-won ($762 million) deal with the Dutch equipment supplier to build a research facility for developing highly advanced EUV technology in Korea. Samsung Electronics Vice Chairman Kyung Kye-hyun, head of the Device Solutions Division, which oversees the company’s chip business, also underscored that the latest agreements will support Samsung's priority to secure the Dutch firm's next-generation high-numerical aperture EUV lithography scanner equipment. \"Samsung has secured a priority over the High-NA equipment technology,\" Kyung said, as he arrived in the airport with Lee. \"(From the trip), I believe we created an opportunity for us to optimize the usage of High-NA technology for our production of DRAM memory chips and logic chips, in the long term,\" he said. According to Kyung, Samsung and ASML will build a joint research facility in Dongtan, Gyeonggi Province and bring the High-NA EUV equipment into the facility. There, the engineers of the two companies will work together to enhance the chipmaking process, Kyung said. \"Rather than focusing on how fast we bring the High-NA EUV machine into Korea, it is more important for us to build the partnership (with ASML) so that Samsung can better use the next-generation equipment,\" Kyung said, adding that Samsung did forge a strong partnership with a very \"sturdy ally.\" The high-NA EUV equipment raises the lens' numerical aperture -- indicating its light-collecting ability -- from 0.33 to 0.55, allowing chip manufacturers to utilize ultrafine patterning technology to produce 2nm-node chips. ASML is preparing to launch the product for the first time in the industry in the coming months. ASML is expected to supply 10 units of the High-NA EUV equipment to the market next year, and Intel has reportedly secured six of them. The Dutch firm said it aims to increase annual production of the new product to 20 in the coming years. With the goal to catch up to market leader TSMC in the foundry business, Samsung's foundry division announced it will start production of chips with 2nm nodes in late 2025. Jo He-rim herim@heraldcorp.com Articles by Jo He-rim Samsung's AI model to be trained on 20,000 telecom-related academic papers Samsung chief returns from Netherlands, satisfied with ASML deal More from Headlines S. Korea to face worst population scenario in 50 years: data Israel strikes Gaza as pressure grows to free more hostages Rival parties set to clash over Yoon’s new Cabinet picks [Herald Interview] Group 14, SK Materials to operate Asia’s largest silicon plant for EVs Legendary singers' idol group comeback as 'Golden Girls' evokes mixed feelings [Today’s K-pop] NewJeans to put out 1st remix album",
    "commentLink": "https://news.ycombinator.com/item?id=38668080",
    "commentBody": "ASML and Samsung seal deal on 2nm chipsHacker NewspastloginASML and Samsung seal deal on 2nm chips (koreaherald.com) 125 points by ycdxvjp 12 hours ago| hidepastfavorite73 comments phkahler 11 hours agoEverything over the last years tells me we are very close to the end game in chip production.1. power stopped scaling2. clocks stopped - 4x over 20 years?3. node names became fiction.4. EUV now differentiates the top from everyone else.5. IPC improvements are a trickle.6. Tons of non-moores law ideas are here:A) GPUsB) chipletsC) stacked dieD) specialized accelerators7. Governments are now involved in dividing up the tech. Since its finally mature &#x2F; done.It has been incredible to watch the progression over the last 50 years. reply JB_Dev 9 hours agoparentI used to agree with you until I saw this presentation by Jim Keller, one of the biggest names in chip architecture. It really illustrates how many more options we have to improve performance.https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;oIG9ztQw2Gc?si=vCBGGm0tkhG-VOyd reply 2OEH8eoCRo0 8 hours agorootparentI like that one. Building a chip involves many different manufacturing steps, each of which has room for improvement. I liked how he even mentions that advances in sandpaper allow us to make better chips. reply huijzer 10 hours agoparentprevDepends what you consider as part of chip production. If you consider new instructions and the related software as new chip production, then the performance improvements have continued quite dramatically. Single chip inference has gone 1000x over the last 10 years according to Bill Dally from Nvidia [1] at 10 minutes (probably not original source). Main gains according to the video have been different numeric types (fp16 for example) and more specialised hardware together with more complex instructions. Note that process improvements have only caused a 2.5x from that 1000x. He also mentions that Google‘s TPU has no fundamental benefit over dedicated instructions in GPUs. Quite an interesting video IMO.[1]: https:&#x2F;&#x2F;youtu.be&#x2F;kLiwvnr4L80 reply DeathArrow 3 hours agorootparentSo going from 65nm to 3nm only gave us 2.5x speed? If by speed we only understand frequency, then it might be true. But speed depends also on IPC and having more transistors means higher IPC. reply huijzer 2 hours agorootparentAh yes thanks! Makes sense. So, more transistors allow for the more complex instructions, which allow for more effective instructions per cycle (such as SIMD). reply thechao 10 hours agoparentprevDennard scaling stopped years ago. There&#x27;s definitely room at the bottom for different topologies — probably 5–10 generations worth. But! These are probably 5 year steps, not two year steps. Also, there&#x27;s just as much room for the improvement of HW design as there is in peeling off SW abstraction layers above the HW. reply ahartmetz 1 hour agoparentprevI think us software types may be more sad about the end of the \"free lunch\" than the buying public. The 90s in particular had amazing performance increases, but you also needed to buy a new computer (which were more expensive then) every ~3 years, or upgrade roughly every 18 months if you wanted to stay near the top.Anyway, my optimization skills will stay in demand :) reply faeriechangling 1 hour agoparentprevWe have a long way to go before we get to the end of the road in where we can go in chip design. The real sore spot moving forward is the grind it&#x27;s going to be to improve price&#x2F;performance ratios.Increasingly I&#x27;m adjusting by being willing to spend more than I would previously consider reasonable on big ticket tech purchases, rather than waiting for prices to drop. reply DeathArrow 3 hours agoparentprevI think there was a lot of research to use other kind of materials beside silicon for making chips. One of them was carbon. I even heard about optical chips, using light instead of electricity. reply hardware2win 1 hour agoparentprevWe arent.There are materials which could make cpus eg 1000x faster, but their life span would be e.g year or two and cost would be 10000x>Tons of non-moores law ideas are here:What? reply Dalewyn 8 hours agoparentprevEvery time someone says we&#x27;ve hit peak microprocessing, we in fact have not hit peak microprocessing. reply ahartmetz 1 hour agorootparentThat can be true while approaching an asymptote. Unless there is a switch in technology (optical, different materials, whatever), I don&#x27;t expect much for the time being. At least in CPUs and especially in single core performance. GPUs and other massively parallel devices are easier to improve with 3D techniques and such. reply colechristensen 10 hours agoparentprevI&#x27;m guessing we&#x27;re not done, we&#x27;re just reaching the endgame with silicon dies. Next steps will be new tech sometimes with a long lead time until it has been developed to the extent that it&#x27;s competitive with silicon. Things like integrated photonics (or a completely photonic CPU), quantum computers, or diamond instead of silicon (or other materials instead of silicon).Are we not still getting exponential growth in capability vs time? reply layer8 10 hours agorootparentIt&#x27;s impossible for growth to be exponential indefinitely. Eventually it&#x27;ll end up as a sigmoid curve.Secondly, progress isn&#x27;t smooth. It comes in phases and leaps, and it&#x27;s possible for it to stagnate for a long time. reply DeathArrow 3 hours agorootparentI think we are only limited by the amount of matter and energy in the Universe. We are far from reaching any limit. reply colechristensen 9 hours agorootparentprevCertainly. We&#x27;re near the top of the computational capacity for silicon chips. However, the computational capacity of a cubic centimeter of our universe is mind bogglingly enormous, what we can do now is a drop of water in the ocean (or much much smaller). There are lots of other ways to compute and many of them in active development.Folks have been saying exponential growth is over for many decades now. It may have slowed in some ways or growth might be going in different directions, but it&#x27;s still growth and I see no signs that the end is near or we&#x27;re close to a major longterm slowdown of growth. reply HarHarVeryFunny 10 hours agoprevJust for size reference, the SARS-CoV-2 (covid) virus is 100nm in diameter.A banana is 200,000,000nm, just in case you were wondering. reply huytersd 10 hours agoparentJust for completeness, “2nm” is more like 12-45nm actual transistor size. So on average about 5 of these transistors could fit inside a single SARS-CoV-2 viron. reply HarHarVeryFunny 10 hours agorootparentInteresting - 100 micro bananas - I didn&#x27;t realize these nominal node sizes had gotten quite so far from actual measurements! reply projektfu 10 hours agorootparentprevSo it&#x27;s not the vaccine, but Covid itself, that is going to deploy the 5G chips into people&#x27;s bodies? reply huytersd 7 hours agorootparentIt’s insane how small transistors are now. Technically you could have a full 2 bit adder inside a single virion within a generation. reply DeathArrow 3 hours agorootparentWell, so instead of giving money to Intel, you go get infected by your virus of choice. You still have to manage heat, though.I wonder how can you install software, or does it come in ROM? reply layer8 10 hours agoparentprevThat&#x27;s a lot of banana chips. reply amelius 8 hours agoparentprevBananas are radioactive, so better keep them away from the chips. reply kaycebasques 10 hours agoprevJust read this in Chip War (p. 333) by Chris Miller:> Gelsinger has cut a deal with ASML to let Intel acquire the first next-generation EUV machine, which is expected to be ready in 2025. If Intel can learn how to use these new tools before rivals, it could provide a technological edge.Is the book talking about the same tech or different? If the same, does it mean that Intel only gets a year or two of headstart? reply PaywallBuster 7 hours agoprev> ASML is expected to supply 10 units of the High-NA EUV equipment to the market next year, and Intel has reportedly secured six of themouch reply huijzer 11 hours agoprevAnyone here who knows what are the benefits of going from, say, 4 or 3nm to 2nm? ASML talks about energy cost per function mostly, but it’s not as clear cut as transitions in the 2000s were if I‘m not mistaken. reply refulgentis 11 hours agoparentConcisely, but eliding: smaller transistors consume less power. Using smaller transistors, you can get the same performance at a lower power budget, or more performance at the same power budget. reply analognoise 9 hours agorootparentYou get less dynamic power loss. Static power hasn’t been as forgiving for a while now though. reply nabla9 8 hours agoprevAtomic radius (average distance from the center to the outermost isolated electron) of copper 135pm, silicon 0.11pm.2nm is 7 copper atoms or 9 silicon atoms. reply DeathArrow 3 hours agoparentMaybe we can construct transistors using subatomic particles. If only we can convince those quarks and bosons to do calculation for us... reply mathematicaster 8 hours agoparentprevAnd for our next trick ... ... pattering to drive transistor switching rather than just transistor etching! reply nabla9 8 hours agorootparentSingle-atom transistor https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Single-atom_transistor reply nathan_phoenix 11 hours agoprevHow far does a $762 million deal get you? Doesn&#x27;t seem like such a huge sum for priority access to next gen 2nm machines, but also hard to judge as a layperson... reply lucubratory 11 hours agoparentJust based on some price familiarity with previous generations and extrapolating forward, that does seem like a contract for one machine with a gold-plated service contract or two machines with a good service contract. It seems to me more like a pilot program, but Samsung is a very significant player in semi so idk... I&#x27;m not familiar enough with this industry. It could just be because it&#x27;s very early in the generation. reply DeathArrow 3 hours agoparentprevI like how users talk about hundreds of millions or billions like it&#x27;s just small change for them. reply Culonavirus 10 hours agoparentprev> How far does a $762 million deal get you?Oh, you know, a billion here, a billion there, who counts anymore, right? (The other posters already aswered this one, seems like two top of the line machines?)Anyways... the numbers being invested at the top of this game are completely nuts. The future like in Cyberpunk 2077 doesn&#x27;t seem that crazy! It begins with Metaverses, Neuralinks, LLMs, hundreds of billions of spending in the hardware&#x2F;silicon business (boosted by AI demand) and ends in, well play Cyberpunk. They may even get the year right. reply DeathArrow 3 hours agoprevSamsung still has to solve yield and capacity problems. It wasn&#x27;t only process node advantage that made customers form lines in front of TSMC shop. reply DeathArrow 3 hours agoprevI wonder why Nvidia doesn&#x27;t establish it&#x27;s own fab business. It might be a good fit for them. reply dataking 3 hours agoparentAFAIK the cost of producing semiconductors on a leading-edge node are so high you are forced to aggegate demand across seveal chip designers. Intel offering foundry services is evidence of this dynamic.Edit: grammar. reply DeathArrow 3 hours agorootparentTrue, but aside the internal demand I don&#x27;t see why can&#x27;t they get external customers.I think Samsung did the same. reply jiggawatts 10 hours agoprevJust to head off the inevitable comments about how 2nm isn&#x27;t really 2nm: yes, we know, it&#x27;s just a convention in the industry to indicate relative performance. It&#x27;s basically a marketing term, more than anything else.The numbers VLSI engineers actually care about are things like millions of transistors per square millimeter (MTr&#x2F;mm^2), power per bit in picojoules (pJ), transistor rise times in nanoseconds, etc...In those metrics, steady gains have been made, it&#x27;s just that the actual component sizes haven&#x27;t matched up to the gains recently. Instead, new types of technologies like \"gate-all-around\" have been used to eke out more performance instead of simply shrinking everything proportionally. reply sgift 7 hours agoparentI really hope they can all decide on a better number which everyone agrees on soon. It&#x27;s ridiculous having to look up each time if Intel 10nm is the same as which one from TSMC again and all of that. There have been some contenders, but the lure of saying \"hey, I have the smallest number, so my process is best!\" is just too strong it seems. reply DeathArrow 3 hours agorootparent>I really hope they can all decide on a better number which everyone agrees on soon.How about 2nm, 2nm Ultra, 2nm Ultra Pro and 2nm Ultra Pro Max.Or, like Intel used to call iterations of their 14nn technology, 10nm, 10nm+, 10nm++, 10nm+++ and 10nm++++. reply verall 4 hours agorootparentprevSince Intel changed their node names you can roughly assume that for a given node TSMC > Intel > Samsung.This might change in the future if Intel gets their shit together but I&#x27;m not buying their stock yet, they look like the Boeing of microchips to me. reply jasonwatkinspdx 5 hours agorootparentprevHave you considered that things are complicated enough now it can&#x27;t be boiled down to single number comparisons? reply qwoiej 9 hours agoprevA few days ago it was reported that Chine companies started producing 5nm chips (model Kirin 9006C) - many years earlier than US government expected they will be able to do so. With this insane progress I will not wonder if Chinese companies start mass producing 2nm chips earlier than anyone else. reply DeathArrow 3 hours agoparentI would expect another decade until China will be on par with the West. And another few years on top if they&#x27;ll overtake it. reply borissk 11 hours agoprevSurely ASML would prefer that Samsung and Intel could keep up with TSMC on manufacturing the latest and greatest CPU&#x2F;GPU&#x2F;SoCs. So not hard to believe that they&#x27;ll sell the first next gen machines to Samsung. reply DeathArrow 3 hours agoparentI think ASML will be happy to sell to whoever wants to buy. The more, the better. reply gjm11 10 hours agoprev [–] Nigel Tufnel, chief scientist at TSMC, explains the merits of the latest hardware from ASML:\"This is a fab, but it&#x27;s very special because if you can see, the numbers all go down to 2nm. Look, right across the board. 2nm, 2nm, 2nm, 2nm ...\"\"And most of the fabs go down to 3.\"\"Exactly.\"\"Does that mean it&#x27;s ... smaller? Is it any smaller?\"\"Well, it&#x27;s one smaller, isn&#x27;t it? It&#x27;s not 3. You see, most fabs are going to be running at 3. You&#x27;re on 3 on your fab -- where can you go from there? Where?\"\"I dunno.\"\"Nowhere, exactly. And what we do is, if we need that extra push over the cliff, you know what we do?\"\"Put it down to 2.\"\"2. Exactly. One smaller.\" reply tromp 10 hours agoparentNice Spinal Tap parody...[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Up_to_eleven reply ezequiel-garzon 6 hours agorootparentThanks to both! I didn&#x27;t know about it, so I needed the clarification. The scene: https:&#x2F;&#x2F;youtu.be&#x2F;4xgx4k83zzc reply fiftyfifty 9 hours agoparentprevI know this is a joke, but TSMC is already talking about 1.4nm processes by 2027-2028:https:&#x2F;&#x2F;www.tomshardware.com&#x2F;tech-industry&#x2F;manufacturing&#x2F;tsm...It really looks like the current tech could take us to sub 1nm. reply zarzavat 9 hours agorootparentThe point is that the number of “nanometers” has precious little physical significance anymore. It’s just a version number that counts downwards. reply kittoes 8 hours agoparentprevI know you just, but the numbers being so small makes a full decrement all that more impressive; 3 -> 2 is equivalent to 6 -> 4, 9 -> 6, 12 -> 8, ... reply iaseiadit 10 hours agoparentprevYou joke but it does seem like we’re near the end of the line. We can go from 3 nm to 2 nm to 1 nm, but we can’t go negative nanometers. That’s it. reply throwup238 9 hours agorootparentNext up is picometers, femtometers, attometers, zeptometers, yoctometers, rontometers, and quectometers (not to be confused with quesometers). They can just keep going until they hit the Planck length as they continue to divorce their marketing from reality. reply DeathArrow 3 hours agorootparentAnd if we run out of prefixes we will add new ones. reply iaseiadit 9 hours agorootparentprevThose units sound made up. Nobody will believe them. reply throwup238 8 hours agorootparentThey&#x27;re all made up. reply yardstick 6 hours agorootparentprevNot too long ago nanometer was made up. reply Tempest1981 5 hours agorootparentprevNot just # of atoms? reply wffurr 8 hours agorootparentprevIntel has gone with ångstroms. reply ofrzeta 10 hours agorootparentprevThere&#x27;s no (natural) law that prescribes that integers must be used, is it? Also, from what I understand that nanometer count is a bit symbolic, less literal.EDIT: for instance IMEC talks about \"sub 1nm\" process, that is 0.7nm (https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;imec-reveals-sub-1nm-trans...) reply iaseiadit 9 hours agorootparentGoing from 1 nm to 0.7 nm is hardly as impressive as going from 3 nm to 2 nm. It’s only 0.3 nm less! reply mathematicaster 8 hours agorootparent(relative) size (still) matters! reply nabakin 8 hours agorootparentprevThey are joking too reply 2OEH8eoCRo0 8 hours agorootparentprev0.5nm, 0.25nm, 0.125nm ... reply tomcam 10 hours agoparentprev> Nigel TufnelDeep cut reply smoldesu 10 hours agorootparent\"Nigel gave me a drawing that said 2nm. Your understanding of pitch width and packaging technology is not my problem. I do what I&#x27;m told.\" reply pezezin 9 hours agoparentprev [–] Dude, I almost spilled my coffee xD replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Samsung Electronics Chairman Lee Jae-yong is pleased with his trip to the Netherlands, where he finalized a deal with ASML to establish a research facility in Korea for advanced EUV technology.",
      "The partnership aims to help Samsung acquire high-numerical aperture EUV lithography scanner equipment for the production of DRAM memory chips and logic chips.",
      "The collaboration will involve joint research and cooperation between Samsung and ASML engineers, focusing on the development of 2nm-node chips using the high-NA EUV equipment, which is anticipated to be available in the industry in the near future."
    ],
    "commentSummary": [
      "ASML and Samsung have partnered to collaborate on producing 2nm chips, showcasing advancements and constraints in chip production.",
      "The discussion explores potential enhancements through new instructions, specialized hardware, and process improvements, while also considering the future of chip design and the possible need for alternative materials.",
      "Samsung has secured a $762 million deal for priority access to 2nm machines, which offer advantages in power consumption due to smaller transistors. The challenges of producing chips on a leading-edge node, Intel's foundry services, and the role of ASML are also explored, alongside the debate over using integers or ångstroms for measurement."
    ],
    "points": 125,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1702763531
  },
  {
    "id": 38663713,
    "title": "Preparing for Remote Missions: Essential Tips for Developers",
    "originLink": "https://www.bitecode.dev/p/preparing-for-missions-in-difficult",
    "originBody": "Share this post Preparing for missions in difficult places www.bitecode.dev Copy link Facebook Email Note Other Preparing for missions in difficult places Can I bring my emotional support dog? Dec 16, 2023 6 Share this post Preparing for missions in difficult places www.bitecode.dev Copy link Facebook Email Note Other 2 Share Summary Some devs are 10x. Some people are talented designers. Some are capable of staring at the screen for 10 hours in a row. I'm nothing like that. I'm a regular dude. But I have one little flex few of my colleagues have: I got specialized in dev and training missions in hard-to-reach places. Those missions have different requirements that traditional ones. You can't assume you'll have anything at hand, so you need to pack all sorts of things, from a bar of soap to HDMI cables to protective gloves to a hunting knife. You also need a backup for everything. You'll pack 2 laptops, 2 IDs, and assume one will get lost, stolen or destroyed. And you'll set up a lot of software to be available to work offline. For example, I may have a few Gb of Python installers, duplicated on two hard drives, stored in different bags. Subscribe The road very much taken I always thought how bonkers it was that we asked kids to jump from having to raise their hand to be allowed to pee, to choose the path that will define their own life in the course of a few weeks. Guidance counselors are a joke, because life is weird, and most people don't end up at all where they expected to go. Of course most youngsters don't expect much, because they don't know what anything is about. Even among the rare ones that were lucky enough to know what field they wanted to be in, and how to start in that direction, for example by enrolling in a specific university. And so my grandmother tried to become rich in Venezuela, my mother took care of pets and performed magic shows, my father took me all around the world for his work and my other grandfather sold shoes. I have friends that were, or are, drug dealers, prostitutes, millionaires, nurses, cooks, teachers... Some are even front end developers! The madness. Needless to say, most of them didn't really plan to be where they are in life, and neither did I. You see, I have kind of a strange specialty. I perform dev and training gigs in hard-to-reach places. In the desert, in the snow, in a remote Asian village or a jungle town in Africa. It's not the only thing I do. Truth is, I do mostly regular industry stuff, in start ups, in corporate offices, on Teams, from my living room, etc. But this is the one thing I do that most people don't. The one thing that makes me peculiar. How did I end up doing this? I have no idea. It just... happened. Now I'm known by my some of my customer as the guy you send there because other people don't wanna go, or wouldn't know how. If nobody speaks the language, at least hire the guy who is not afraid of looking like a fool. So I'm in a position to write an article that few people would be capable to write. How do you prepare for such mission? Stating the obvious At first I didn't plan to mention those, because that's pretty much the ground zero, but I realized many people don't travel that much, so I'll go through the typical list you need to check for traveling. Yes, you have to figure out the logistics of your travel. This includes transport, visa, vaccines, checking the weather, bringing enough of the proper clothes. Yes, you have to read the latest news, go to the gov and embassy websites to know what you are getting into, make sure you know recommendations for the area, etc. Evidently, you don't want to torrent movies in Germany, be invited to drink alone in Russia, get caught with drugs in Thailand, drink tap water where you should not, and so forth. Yes, you need to take care of how you are going to pay for things once you arrive, which in some countries like Burma or Cuba have a few layers. Yes, friends and family should know your itinerary with an ETA for when you leave and come back. And sure, you'll want to bring in painkillers, C vitamins and activated charcoal no matter where you go. That's the basics. If you go on holiday, those are also good advice. However, I want to talk about the specific things for those missions that may end up in the middle of goats, with no signal, no running water, no electricity, and a job to do anyway. Don't assume you'll have anything If you travel a lot, you know in 2023 you can buy pretty much the bear bare necessities anywhere. Tim Ferris famously advice to not bother bringing things like toothbrush or show gel, because they take space and you can cheaply acquire them once you arrive. It allows for traveling light, and it's fun. You get to interact with locals; it's overall, a richer traveling experience. But in our context, I am not a tourist. First, I need to perform, second, where I go I may not have shops. Or much of anything really. So I don't rely on a hotel providing a towel, I don't expect to be able to purchase razors, I pack like if I had to get by with just what I have. This includes: A bar of very rustic soap, because it can also be used to clean clothes. A head light, as you make the error of taking light for granted only once. Pens and paper, because that's the only thing that is reliable. Really. Additional fully charged battery, they are small and commoditized now. A multi-tool and protective gloves. Doesn't take much space, rare use, bug huge ROI if you do. A book. I'll have to wait many times and don't want to eat the batteries. A BIG hunting knife. You almost never use it. But you don't want to miss it when you need it. Check local laws for this one. I insist, it must be BIG. A small wifi/ethernet access point. If the network is down, you build your own. An HDMI/ethernet cable, adapters of all sorts, at least 2 USB C laptop chargers. Something will fail or will be missing. It's a guarantee. Salt and a Neti Pot to clean your nose. It's disgusting, but also will save you all sorts of troubles. A power strip and adapters. They never have enough. Yes, this means you need to have one checked luggage. This is a business trip, not a hobo adventure. Doesn't mean you should bring a huge one, though, since you may have to carry that on rough terrain, climb stuff or be at sea. It's a balance. Lifting weight helps with that. No kidding. Assume destruction Everything you bring must be something you can part with. If you bring a laptop, back it up before you go. Same with your phone. Don't bring your favorite of anything, don't bring ultra high-quality stuff unless the mission requires it. Your equipment can be taken by authorities, it can get lost, it can get stolen or just broken. Memory may get wiped out, or corrupted. Airlines can delay you luggage delivery for days or weeks. You may even get locked out of your own devices and services for various reasons. You could have to evacuate in a hurry. Happened to me twice, and depending of the urgency, do you want to be slowed down? One of those things will, in fact, likely happen. I factor the price of that in the quote I send the client. You learn more and more ways of seeing your stuff go as you travel. My team lost a whole case of hard drives in Senegal once. It disappeared between the moment it came out of the plane, and the airport luggage belt. My phone died once because I didn't realize that the monsoon meant I didn't have a margin of error when going outside. I had a wall of water on me in a minute, sewage water up to my knees in 15. I now travel with an old smart phone I don't use anymore, plus one dumb phone, with local SIM cards I buy at the airport. I also have plastic zip bags for everything that matters, papers, money, cards, phones... It protects them from the rain, the insects, the dust, you name it. I also never buy fancy luggage anymore. I tried expensive one with \"life guarantee\", and it's not worth it. They break just as well, they get lost/stolen the same way. The guarantee never covers what really happens to it in the wild. For me, luggage is a consumable now. Headphones as well, for that matter. Get a backup for everything This means 2 types of ID documents, and a photocopy of each. This means 2 credit cards with different networks and bank accounts, plus cash. This means 2 hard drives, 2 laptops, 2 thumb drives. This means your tickets should be copied to all your devices, and printed on paper. In fact, I have my full trip printed on paper, with addresses, numbers, maps of the areas, names of persons of interest and contacts, etc. Those back-ups should be stored in different places. One ID in your pocket, one in your small bag. One hard drive and laptop in the small bag, one in the big luggage. The idea is that when one will inevitably be not available to you anymore, you can get to the second one. I went without ID nor card 3 weeks in Mali once. Never. Again. Software to pack Those kinds of missions are niche. Not many organizations need to send someone in Uganda to code a tuberculosis diagnosis software. Besides, more and more of the world is now equipped with electricity and the internet. In fact, there are some places with terrible water supply but excellent 4G signal, and with Starlink coupled to solar panels, I expect this to become only more and more common. On top of that, I have little experience with low-level languages. Many remote places, such as platforms in the ocean or bunkers, have old systems that are completely out of my skillset. I worked mostly with Python, JS, PHP and Bash. I can sorta code in Java and I'm currently learning Rust, but I would not count them as something I would sell for short missions where I can’t ramp up the required knowledge. This means the jobs people will send me to do are even more specialized than this niche. Mostly, they will call me for Python things, because it's been around since the nineties and it's installed by default on most Linux systems, so you find it everywhere. Plus I have a lot of practice with it, I can recall the API from the top of my head and teach it on the spot. I will usually know the tech I’ll deal with in advance, but not always much more. If it's for training, I can ask questions about the OS, the Python version, etc. But if it's for building a network of computers that will run on solar power and discuss by sending text messages to each other, that can be controlled by old Nokia 3310 plugged on car batteries, I don't necessarily know what I'm getting into. I've done that by the way. It was so cool. So I'll install every single version of Python I can on both my Linux partition and my Windows one. And I'll add dozens of installers for Mac and Windows on 2 hard drives for subsequent installations on other machines. Not always possible, the clients may have locked up machines I can't plug anything into, but just to be safe. For some missions I may even set up a partial local mirror of pypi and download a ton of documentation offline. Getting some portable versions of run of the mill apps is useful as well. I’ve never regretted having a copy of portable Python, VLC, Firefox or Libre Office at hand. I even indulge in having binaries for ripgrep and fdfind now. We live in luxurious times, where software is amazing and disk space is cheap. This goes without saying, everything must work out of the box without any connection. You can't have something that locks you out because it needs to update to the latest version, you can't have something depending on the cloud, you can't have trial versions that expire, or things that need a driver to be installed or a licence server to be available. Making sure you can unlock everything that requires a password is a must before you leave, including the password manager itself. If I have a few online services I still hope to be able to use there, I attempt to use a VPN outgoing to the target country and connect from there. Geofancing is a nightmare. This is also why I don't rely on any Google service anymore, since big G will suspect foul play too easily and will lock me out of my own life on a whim, calling that security. If I do need to use a Google service, I make sure I have 3 yubikeys setup as a second factor for it, it relaxes the giant. Still, not requiring anything online is the only really safe option. Because USB ports may not be allowed, it's time to double check that I can share things among devices on a local network, and add new machines to my little access points. This includes files, but also access to local services, such as a DB or the pypi mirror. That’s not something you want to debug on premise. This is also where you want to polish your scripting skills. In Python, bash, cmd.exe… Get cheat sheets, recipes and references accordingly, it's unlikely ChatGPT will be available (although I will enjoy the heck of local coding models once they can run on my laptop comfortably). Knowing by heart is ideal, being able to use anything when a UI is not available as well. Not that I like coding using VI (not Vim) through a telnet connection from inside an isolated dark and humid room with shitty lighting. If need be, what am I going to say? Sorry pal, don’t like it, I'm going back? Plus it's money. I like money. Most articles are not like this one. But they are still pretty good. You should really subscribe. Just sayin’ Subscribe 6 Share this post Preparing for missions in difficult places www.bitecode.dev Copy link Facebook Email Note Other 2 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=38663713",
    "commentBody": "Preparing for missions in difficult placesHacker NewspastloginPreparing for missions in difficult places (bitecode.dev) 110 points by _dain_ 21 hours ago| hidepastfavorite36 comments mynegation 18 hours agoOk, forget the packing lists, advice, and all this survivalist stuff. All I want to know is what _kind of jobs_ requires preparation like this. This is not covered in the article, I have an impression - deliberately so. reply BiteCode_dev 17 hours agoparentYes, deliberately indeed.But I as suspect you may believe, I didn&#x27;t work for the military.I worked for NGOs, governments bodies, the UN and WHO, and of course the private sector.At home I have a fridge, hot water, heating, nobody is shooting guns except in the shows I can stream in HD thanks to fiber while eating an organic avocado.So it&#x27;s easy to forget a huge part of the world is not comfortable. But those areas do have a lot of human activity, and some need computers.In the article I hint about a text message base system to control a cluster of computers. That was in 2000 something, and Uganda was trying to control a big tuberculosis epidemic. The goal was to synchronize all medical outposts. In this country, this meant dozens of very remote places, in the jungle, in the mud, etc.It could take up to 3 months to gather enough data about all the cultures of each new batch to prescribe the proper treatment. Often too late.One day the NGO Find decided to attempt to create a system that would link all them using GPRS. So they sent me there. Text messages was the only thing that would be semi-reliable, and locals would plug their nokias on the batteries on their Jakartas (a popular chinese bike that was everywhere) to have them always available, so we used that, and cheap laptops to host the software.Another time I got hired at the last minute to help with a training to promote Microsoft products in remote places in the hope that once they become a market, they would chose them. When I arrived, the African MS representative gave a speech, a few t-shirts, pocketed the money, and left immediately.Without the MS expert to take a lead, I didn&#x27;t have much of a plan. So I trained the entire audience how to use Linux.Good times.Want to entertain a bunch of stranded scientists on an island? Give them a Python training, it&#x27;s part of the budget anyway. Want to prove some legal issues? Lock the expert with an airgap system and let him figure it out.I get all sorts of offers. Some are questionable, of course.Once the parliament of Mali asked me to craft some very shady accounting system. I refused.But I can only tell you about it only because this particular governing body have little power over me today. reply mynegation 17 hours agorootparentOMG, thank you so much for this comment! As interesting as the original post was, it pales I comparison with this. I can understand this prep from someone with MSF or rescue team member, but I was specifically interested about software development&#x2F;tech ops in this context. Stay safe and I hope one day you can write a book or two with this material, this would be epic. Please keep your memos and records. On paper if needs be. And do and verify your backups, lol, PSA for everyone reading this. reply anon7725 16 hours agorootparentprevThis was one of the most enjoyable HN comments I’ve ever read - you should write more about this on your blog. reply neilv 10 hours agorootparentprevI was concerned when I read about trying to infect areas of presumably developing nations with MS. But it was poetic justice that there was corruption all the way down. The Linux that they got was almost certainly in their actual interests. reply AlotOfReading 17 hours agoparentprevI used to be an archeologist and had a checklist of similar preparations before I would head out to the field. However, unlike the article, I couldn&#x27;t pack two of everything because I had to carry it myself alongside whatever gear, shovels, samples, sieves, survey equipment, etc I had.A few things I learned though:* FOSS software was consistently the most reliable stuff I used, as it wouldn&#x27;t automatically lock itself if it couldn&#x27;t see the Internet every 30 days.* You need to be much more thoughtful about the code you write. Think twice, write once.* Stick to a daily power budget, and cut it in half from what you can nominally afford.* Prioritize properly. In many cases, the electronics are not the most important thing to be handled. Don&#x27;t babysit them, go do camp chores and sieve dirt if it needs doing. reply defrost 9 hours agoparentprevGeophysical exploration surveying for one - I&#x27;ve written well over a million+ SLOC and traveled through and over more than two thirds of the 190+ countries on the planet.Flying million line km grids 80m above ground at 70 m&#x2F;s, driving, logging drill hole samples, positioning base stations, ground truthing the \"new\" WGS84 GPS datum against hundred of older paper maps and many many old ellisoids and datums, etc.It&#x27;s good to be unfazed by vehicle failures, supply chain breakdowns, political upheavals, coup d&#x27;état, unexpected bad weather, wild fires, and so forth.Suprise nuclear testing was one interesting day on the job. reply lazyasciiart 18 hours agoparentprev“ I perform dev and training gigs in hard-to-reach places. In the desert, in the snow, in a remote Asian village or a jungle town in Africa.” reply jrexilius 15 hours agoprevIt sounds like we overlapped in a few locations and missions ;-) One thing I would add to your list is extra USB drives with lotsa storage (>256GB), and at least one with a hardware write-protect switch (like the Kanguru ones). Collecting and sharing data is like collecting and sharing beer.. great way to make friends and build network effects. The Kanguru ones are nice when you need to share with a risky machine (cyber cafe, hotels, etc.). reply resolutebat 14 hours agoprevInteresting read. As a former 100% travel road warrior in semi-exotic places (data centers in developing countries), I&#x27;m very surprised he&#x27;s checking in bags though, that&#x27;s just asking for trouble. I presume it&#x27;s the big hunting knife that makes this unavoidable, but is this really that necessary? reply jauer 9 hours agoparentA bit above where he mentions checking a bag, he says:> But in our context, I am not a tourist. First, I need to perform, second, where I go I may not have shops. Or much of anything really.Just the supplies to stay functional without being able to rely on any local infra (food&#x2F;water&#x2F;shelter&#x2F;medical) makes not having a checked bag challenging IMO.I&#x27;m on-roster with a tech NGO (sounds like he does something similar?) and travel with a duffel that gets checked in addition to my carry-on backpack. Backpack has \"here and now\" stuff. A change of clothes, lots of socks, laptops, GPS, satphone, granola bars. Basically whatever I need to live for a day or two and get started doing site surveys so I&#x27;m not totally useless even if the duffel gets held up or lost.Duffel gets _everything_(1) that I need to do what I&#x27;ve been sent to do, which gets bulky and usually makes airport security unhappy: Tools (EMT shears(2), multitool, screwdriver, wrenches to assemble VSAT dishes, ethernet crimpers, etc). Food&#x2F;MREs for half a week of working hard, maybe a small drone if it&#x27;s legal. Sometimes cable and network equipment if it&#x27;s a small response and nobody is pulling stocks from UNHRD.Granted, I usually do field networking instead of coding, but the basic idea is the same. Sometimes you have to do the project even if it means sleeping in a house with no roof on an island with no power after a hurricane.1. Technically, everything short of local transportation. 2. TSA doesn&#x27;t mind the EMT shears, but airports south of the equator kept confiscating mine. reply a_t48 9 hours agorootparentDid TSA care about the magnesium heaters in the MREs or did you fish them out first? reply jauer 9 hours agorootparentfished them out :) reply neilv 10 hours agoparentprevMaybe the Crocodile Dundee school of thought:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=dSnosk4tWrg&t=10s reply dist-epoch 13 hours agoparentprevThe knife is probably to deter someone messing with you thinking you&#x27;re an easy target. reply wisemang 13 hours agoprevSome other interesting writing along these lines can be found on Jan Chipchase’s website[0][0] https:&#x2F;&#x2F;janchipchase.com&#x2F; reply Simon_ORourke 15 hours agoprevIt&#x27;s like trying to do work in any one of many corporate networks that glue plastic tabs over their employees USB ports.Been there, done similar without the capricious Senegalese baggage handlers. reply tuukkah 16 hours agoprevIf someone wants to do something like this, I hear the Red Cross has pools of technical experts for emergency response situations. Does anyone have experience about that? reply alwa 10 hours agoparentThey do, although there are some organizational aspects to consider. Each nation has its own Red Cross&#x2F;Red Crescent&#x2F;Red Diamond committee and draws first from its own local roster. Other nations request specific expertise from sister committees from time to time, but it’s pretty rare. The American Red Cross, for example, deploys about 2 dozen individuals to support foreign disaster relief operations in a given year. As I recall that involves mainly people who are really good at setting up comms infrastructure, management experts, and GIS experts.The ICRC, as I understand it, works more across international lines, but their “technical” experts tend to specialize in aspects of international humanitarian law rather than technology per se.You certainly can, though, support domestic relief operations for the American Red Cross. Disaster Support Technologies roles tend to have more of a helpdesk flavor than the remote, wild-and-wooly jack-of-all-trades kind of experience that the OP describes. And there are also information and planning functions on large disaster relief operations, where your data analysis and GIS chops might be put to good use.Those jobs sometimes unfold in austere conditions—think after a hurricane or a wildfire—but they’re extremely well-supported, by contrast to the OP’s missions: you’ll have a safe and dry place to sleep, plenty to eat, the national warehouses will get you the stuff you need (albeit maybe not today), and so forth. The training is thorough and the crowd is mission-oriented. You can even work I&P roles remotely. reply BiteCode_dev 16 hours agoparentprevIt&#x27;s the case for many NGO. Just know that:- NGOs won&#x27;t pay nearly as much as the private sector, obviously.- It&#x27;s very hard to get in, at least for deployed missions. So do not hesitate to try again and again for a long time.- Once you are in, it ripples, and you easily get access to many other missions, provided you did a good job. It can be useful to accept something completely out of your main thing, just to get the foot in the door.- A lot of NGO work is actually not helping anybody. Be prepared to be disappointed. Some is good, but the amount of PR, virtue signaling and scams is staggering. Although many people are under the delusion they save the world. Do it for the experience, and maybe you&#x27;ll get lucky and you&#x27;ll do more good that bad, on average. Some days, I&#x27;m still unsure I did. But emergency responses are where the most unambiguous good is done.- If you do it for long enough, you will get hurt. That&#x27;s just how it is. Sick, wounded, bankrupt... Something. That&#x27;s one of the prices to pay. E.G: in West Africa, our first Malaria was kinda a rite of passage. We&#x27;d joke about it. You can&#x27;t take pills with side effects for ever.- You&#x27;ll need to be pretty autonomous. Nobody is going to take you by the hand. But the cool part of this is that you&#x27;ll get responsibilities and freedom of action you&#x27;ll have nowhere else. It can be a curse as much as a blessing, but I loved it. reply maCDzP 15 hours agoparentprevI did training for the Red Cross to join the rooster. Never been deployed so I don’t have any field experience. I have friends whose whole career revolves around different deployments in hardship areas.From hearing people that have been in the field it sounds like a total shit show. But also very boring since you get to wait a lot.You also se a lot of traumatized people which I believe takes a toll on your mental health.I was surprised by the partying, alcohol seems like the preferred way to cope with the environment.All in all, the people I have met don’t seem at peace with themselves. reply BiteCode_dev 15 hours agorootparentAlcohol, sex and a generous stock of dark humor. reply Luc 12 hours agoprevFun article! If the author is still reading the comments, I wouldn&#x27;t mind learning more about why the Neti Pot (allergies? dust?) and the LARGE hunting knife are essential equipment. reply x86x87 18 hours agoprevThis should be a TV show. Hire this person for a job in a remote place and after that hire another person to fuck him them and sabotage what they are trying to do. Film it -> Success reply BiteCode_dev 18 hours agoparentIt&#x27;s not as exciting as it look: you spend a lot of time waiting. And then working in difficult conditions. Then waiting. Then something fail and you look for a hack. Then you work. And you wait. And you come back.I did get into serious trouble once or twice, but over two decades, the average netflix factor is pretty low.Corruption and nature owning you is surprising the first few times, but after the 50th occurrence, it&#x27;s just the new normal.So you&#x27;d have to make some talented editing. reply ForkMeOnTinder 17 hours agorootparentThat&#x27;s normal for reality shows.Cooking shows? You spend a lot of time waiting, who wants to sit and watch a pie bake for an hour?Ever seen those \"how it&#x27;s made\" shows? Editing can make anything interesting.I&#x27;d watch the heck out of a techie version of Survivor (early years). reply x86x87 16 hours agorootparentprevyeah. not worried about the waiting part. that can be edited out. also, the adversarial element would make for some good drama.failing and looking like a hack is what would make the show insanely popular. the only challenge I see is that people might think it&#x27;s scripted and&#x2F;or would not have the depth of knowledge to understand why something is happening. both of them can be addressed (so what if people think it&#x27;s scripted - remember man vs wild? + you could introduce a few \"expert\" commentators that dumb it down and explain things to the peasants while the action is going on) reply airstrike 15 hours agorootparentprev> talented editingthat&#x27;s what all these shows excel at reply palemoonale 12 hours agoprevWhat&#x27;s with all this &#x27;mission&#x27; talk? You are coders, stop that BS.(worked in places like Libya and Uganda, never felt it was my mission! Had to follow requests made to my employer,thats it) reply jrexilius 11 hours agoparentThe \"mission\" terminology is common in the NGO world and not everyone is hired as a \"coder\". Quite frequently these are projects to effect outcomes rather than support billets to be filled by coders. There is a wide spectrum out there, your experiences may vary.. reply BiteCode_dev 18 hours agoprevSmall summarySome devs are 10x. Some people are talented designers. I&#x27;m a regular dude.But I have one little flex few of my colleagues have: I got specialized in dev and training missions in hard-to-reach places.Those missions have different requirements that traditional ones. You can&#x27;t assume you&#x27;ll have anything at hand, so you need to pack all sorts of things, from a bar of soap to HDMI cables to protective gloves to a hunting knife.You&#x27;ll pack 2 laptops, 2 IDs, and assume one will get lost, stolen or destroyed.And you&#x27;ll set up a lot of software to be available to work offline. reply s5300 16 hours agoprevThough he did not explicitly state to not forget to bring a towel, he has implied that he does not count on a hotel to supply him with a towel. reply aaron695 12 hours agoprevA small chili sauceeSIM32000 mAh is a limit on battery packs (in SE Asia, other countries&#x2F;layovers maybe lower).If yours is larger I&#x27;d consider buying one where you can remove the label and replace it with a lower number (I wouldn&#x27;t have no label). They were reading labels when I last went through.Powerstrip - with protection.Obviously a universal power adapter and USB. You&#x27;ll always be in multiple countries with layovers and stuff.I don&#x27;t get people who have luggage vs. backpack.Bribe&#x2F;emergency money, inc lower dominations.As they hint, a VPN in case you have to do banking etc (so your IP is in your home country)Similarly if using a burner phone log into everything once at home. And grab the local Grab (Uber) I had to APK one that was phone region locked. Know how to do this.Water tablets&#x2F;Steripen. Sometimes it&#x27;s a PiTA to go buy more water. And alcohol gel, which I guess is standard for normies(vs. scared EuroTravelers) post COVID.> A small wifi&#x2F;ethernet access point. If the network is down, you build your own.What&#x27;s the best way to do this? Link to product? Can you connect something to your phone or laptop, or will that not work if you are Phone -> Laptop internet-ing reply tekla 17 hours agoprev [–] The only part difficult about this is the computers due to power and maybe network conditions (increasingly irrelevant due to Starlink). Everything else is pretty basic shit. reply BiteCode_dev 17 hours agoparentGetting to the north pole is a series of a lot of pretty basic shits, I&#x27;m afraid.Life is mostly mundane, after all. And there is a limit to what you can prepare for.One day my taxi, or should I say death trap, went fast and furious on a pedestrian in the middle of Bamako. The procedure for the locals at the time was to stone the culprit to death before the police arrive, as anybody with money will pay their way out.Not much you can pack to help you with that.And not programming related anyway. reply anon7725 16 hours agoparentprev [–] There’s a big difference between doing basic shit in your pajamas from the home office and doing it in a remote location while contending with all of the accompanying complications. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post emphasizes the importance of being prepared and having backups when traveling to challenging and remote locations as a developer.",
      "Thorough planning, essential items, and offline software and documentation are highlighted as crucial for success in these environments.",
      "Backing up devices and information, as well as using software that works offline, is stressed as essential.",
      "The article concludes by encouraging readers to subscribe and providing a link to a related post on preparing for missions in difficult locations."
    ],
    "commentSummary": [
      "The article focuses on the author's experiences working in challenging and remote locations using technology for data gathering and training.",
      "It provides advice on record-keeping, backups, storage, and hardware solutions in these environments.",
      "The article also discusses the challenges and opportunities of working in emergency response situations and the physical and mental toll of humanitarian work, with suggestions for coping mechanisms and necessary items to pack."
    ],
    "points": 110,
    "commentCount": 36,
    "retryCount": 0,
    "time": 1702729256
  }
]
