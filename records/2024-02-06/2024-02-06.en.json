[
  {
    "id": 39261861,
    "title": "Vesuvius Challenge 2023 Winners Decipher 2000-Year-Old Scroll Using Machine Learning",
    "originLink": "https://scrollprize.org/grandprize",
    "originBody": "Vesuvius Challenge 2023 Grand Prize awarded: we can read the first scroll! The 2000-year-old scroll discusses music, food, and how to enjoy life’s pleasures. February 5th, 2024 We’re announcing the winners of the Vesuvius Challenge 2023 Grand Prize. We’ll look at how they did it, what the scrolls say, and what comes next. Join the winners for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. More to come. Victory Two thousand years ago, a volcanic eruption buried an ancient library of papyrus scrolls now known as the Herculaneum Papyri. The scrolls were carbonized by the eruption of Mount Vesuvius in 79 AD. In the 18th century the scrolls were discovered. More than 800 of them are now stored in a library in Naples, Italy; these lumps of carbonized ash cannot be opened without severely damaging them. But how can we read them if they remain rolled up? The scroll read by the winners. Result of an attempt to physically unroll a scroll. On March 15th, 2023, Nat Friedman, Daniel Gross, and Brent Seales launched the Vesuvius Challenge to answer this question. Scrolls from the Institut de France were imaged at the Diamond Light Source particle accelerator near Oxford. We released these high-resolution CT scans of the scrolls, and we offered more than $1M in prizes, put forward by many generous donors. Seth Parker scanning a scroll at the Diamond Light Source particle accelerator. Artistic visualization of constructing a 3D volume. A global community of competitors and collaborators assembled to crack the problem with computer vision, machine learning, and hard work. Less than a year later, in December 2023, they succeeded. Finally, after 275 years, we can begin to read the scrolls: Text from PHerc.Paris. 4 (Institut de France), unseen for 2,000 years. Roughly 95% of the scroll remains to be read. The thoughts of our ancestors, locked in mud and ash for 2000 years, hidden in darkness — now, with the light of a worldwide effort shining upon them, finally seen again. Grand Prize We received many excellent submissions for the Vesuvius Challenge Grand Prize, several in the final minutes before the midnight deadline on January 1st. We presented these submissions to the review team, and they were met with widespread amazement. We spent the month of January carefully reviewing all submissions. Our team of eminent papyrologists worked day and night to review 15 columns of text in anonymized submissions, while the technical team audited and reproduced the submitted code and methods. There was one submission that stood out clearly from the rest. Working independently, each member of our team of papyrologists recovered more text from this submission than any other. Remarkably, the entry achieved the criteria we set when announcing the Vesuvius Challenge in March: 4 passages of 140 characters each, with at least 85% of characters recoverable. This was not a given: most of us on the organizing team assigned a less than 30% probability of success when we announced these criteria! And in addition, the submission includes another 11 (!) columns of text — more than 2000 characters total. The results of this review were clear and unanimous: the Vesuvius Challenge Grand Prize of $700,000 is awarded to a team of three for their excellent submission. Congratulations to Youssef Nader, Luke Farritor, and Julian Schilliger! Youssef Nader Luke Farritor Julian Schilliger All three winning team members have been strong community contributors since the very beginning of the Vesuvius Challenge. You may remember Youssef. He is the Egyptian PhD student in Berlin who was able to read a few columns of text back in October, winning the second-place First Letters Prize. His results back then were particularly clear and readable, which made him the natural lead for the team that formed. You might remember Luke as well: he is the 21-year-old college student and SpaceX intern from Nebraska, who was the first person in history to read an entire word from the inside of a Herculaneum scroll (ΠΟΡΦΥΡΑϹ, “purple”). This won him the first-place First Letters Prize, a few weeks before Youssef’s results. And finally, you might remember Julian. He is the Swiss robotics student at ETH Zürich, who won three Segmentation Tooling prizes for his incredible work on Volume Cartographer. This enabled the 3d-mapping of the papyrus areas you see before you. For the Grand Prize, they assembled into a superteam, crushing it by creating what was unanimously deemed the most readable submission. The submission contains results from three different model architectures, each supporting the findings of the others, with the strongest images often coming from a TimeSformer-based model. Multiple measures prevent overfitting and hallucination, including results from multiple architectures, a study across input/output window sizes, label smoothing, and varying validation folds. Like with all our prizes, this ink detection code has been made public as open source (on GitHub), leveling up everyone in the community. The winners’ main submission image (TimeSformer 64x64). In addition to unparalleled ink detection, the winning submission contained the strongest auto-segmentation approach we have seen to date (more about the process of “segmentation” below). ThaumatoAnakalyptor (roughly: Miracle Uncoverer) by Julian generates massive papyrus segments from multiple scrolls. Re-segmentations of well known areas validate previous ink findings, and entirely new segmentations reveal writing elsewhere, such as the outermost wrap of the scroll! Outputs from auto-segmentation. The top row overlaps with the submission image, the bottom row has new segments. Much work remains to improve this promising tool. Congratulations to Youssef, Luke, and Julian. You are the well-deserved winners of the 2023 Vesuvius Challenge Grand Prize! Runners up Of the remaining submissions, the scores from our team of papyrologists identify a three-way tie for runner up. These entries show remarkably similar readability to each other, but still stand out from the rest by being significantly more readable. Congratulations to the following teams, each taking home $50,000! Shao-Qian Mah. GitHub Elian Rafael Dal Prá, Sean Johnson, Leonardo Scabini, Raí Fernando Dal Prá, João Vitor Brentigani Torezan, Daniel Baldin Franceschini, Bruno Pereira Kellm, Marcelo Soccol Gris, and Odemir Martinez Bruno. GitHub Louis Schlessinger and Arefeh Sherafati. GitHub These teams each brought to the table new approaches to the subtleties of ink labeling and sampling. Be sure to check out their methods at the links above. Other teams may also now choose to share their approaches, so be sure to follow our Discord community for updates. Joining our community also provides access to the CT data and more images under our data agreement, as well as a front-row seat to daily discovery and collaboration! What does the scroll say? To date, our efforts have managed to unroll and read about 5% of the first scroll. Our eminent team of papyrologists has been hard at work and has achieved a preliminary transcription of all the revealed columns. We now know that this scroll is not a duplicate of an existing work; it contains never-before-seen text from antiquity. The papyrology team are preparing to deliver a comprehensive study as soon as they can. You all gave them a lot of work to do! Initial readings already provide glimpses into this philosophical text. From our scholars: The general subject of the text is pleasure, which, properly understood, is the highest good in Epicurean philosophy. In these two snippets from two consecutive columns of the scroll, the author is concerned with whether and how the availability of goods, such as food, can affect the pleasure which they provide. Do things that are available in lesser quantities afford more pleasure than those available in abundance? Our author thinks not: “as too in the case of food, we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.” However, is it easier for us naturally to do without things that are plentiful? “Such questions will be considered frequently.” Since this is the end of a scroll, this phrasing may suggest that more is coming in subsequent books of the same work. At the beginning of the first text, a certain Xenophantos is mentioned, perhaps the same man — presumably a musician — also mentioned by Philodemus in his work On Music. Philodemus, of the Epicurean school, is thought to have been the philosopher-in-residence of the villa, working in the small library in which the scrolls were found. Initial, rough draft transcriptions: col. -8, ll. 2-14: 2 ...]ι̣μ̣εν τοὺϲ̣ [πα]ρ̣[ὰ Ξ]ε̣- νοφάντωι το̣ιούτου[ϲ, ὃ καὶ ὑπ’ ἄ̣λλων δοκεῖ 5 γείνεϲθαι, παραπλη- ϲίωϲ δ̣’ ο̣ὐδὲ παρ̣’ ἑτέρωι ἴδι̣ον το̣ῦ δ̣οκοῦ̣ντοϲ̣ εἶναι καὶ παρὰ πλε̣ί- οϲ̣ι̣ν̣ ἥδιο̣ν, ἀλλ’ ὡ̣ϲ̣ καὶ 10 ἐ̣π̣ὶ τῶν βρω̣μ̣άτ̣ων ο̣ὐ̣κ ἤδ̣η τὰ ϲπάνια πάντωϲ̣ καὶ ἡδ̣ίω τῶν δ̣αψιλῶν̣ ε̣ἶναι̣ 14 νομίζ̣ο̣με̣ν· οὐ γ̣ὰρ̣ col. -7, ll. 4-10: λ̣ει παρὰ τὰ δαψιλῆ. 5 θεωρηθήϲεται δὲ τὰ τοιαῦθ’ οὕτω{ι} πολ̣λά- κιϲ πότερον ὅ̣ταν πα- ρῇ τὸ δαψιλέϲτερον ἡ φύϲιϲ ἥδιον ἀπαλλάτ- 10 τει το̣ύ̣τ̣ο̣υ̣ καὶ πάλ̣ι̣ν̣ ̣ ̣ Later in the scroll: In the closing section of the text our author takes a parting shot at his adversaries, who “have nothing to say about pleasure, either in general or in particular, when it is a question of definition.” col. -2, ll. 2-8: 2 ἑ̣κάϲτηϲ κριτηρίων θεωροῦνται. πρὸϲ δὲ οὔτε καθόλου περὶ 5 ἡδονῆϲ ἐχόντων τι λέγειν οὔτε περὶ τῆϲ κατὰ μ̣έ̣ρο̣ϲ̣, ὅ̣τε ὡ- 8 ριϲμένον τι, ἀλλ’ οὖν … Finally the scroll concludes: “… for we do [not] refrain from questioning some things, but understanding/remembering others. And may it be evident to us to say true things, as they might have often appeared evident!” col. -1, ll. 1-6: 1 ὰρ ἀπ̣εχόμ̣ε̣θ̣α̣ τὰ μὲν κρίνειν, τὰ δὲ κατέχειν καὶ ἐμφαί νoιθ’ ἡμῖν ἀληθῆ λέ- 5 γειν ὥϲπερ πολλά̣κιϲ ἂν ἐ̣μφανε̣ίη̣{ι}. Richard Janko writes: “Is the author Epicurus' follower, the philosopher and poet Philodemus, the teacher of Vergil? It seems very likely. Is he writing about the effect of music on the hearer, and comparing it to other pleasures like those of food and drink? Quite probably. Does this text come from his four-part treatise on music, of which we know Book 4? Quite possibly: the title should soon become available to read. Is the Xenophantus who is mentioned the celebrated flute-player, or the man famous in antiquity for being unable to control his laughter, or someone else entirely? So many questions! But improvements to the identification of the ink, which can be expected, will soon answer most of them. I can hardly wait.” Federica Nicolardi told us: “Epicureanism says hi, with a text full of music, food, senses, and pleasure!” From Bob Fowler: “Like other Epicureans, he valued pleasure above all - but pleasure rightly understood, not mere indulgence. Living in ancient Rome - a society not known for abstinence - Philodemus could expect to meet with scepticism from his readers.” Scholars might call it a philosophical treatise. But it seems familiar to us, and we can’t escape the feeling that the first text we’ve uncovered is a 2000-year-old blog post about how to enjoy life. Is Philodemus throwing shade at the stoics in his closing paragraph, asserting that stoicism is an incomplete philosophy because it has “nothing to say about pleasure?” The questions he seems to discuss — life’s pleasures and what makes life worth living — are still on our minds today. We can expect many more works from Philodemus in the current collection, once we’re able to scale up this technique. But there could be other text as well — an Aristotle dialog, a lost history of Livy, a lost Homeric epic work, a poem from Sappho — who knows what treasures are hidden in these lumps of ash. And there is the hope of a much bigger library still in the ground, since two levels of the villa remain unexcavated. More about this below! How accurate are these pictures? Machine learning models are infamous for “hallucinating”: making up text or pictures that look similar to their training data. Similarly, there might be ways for contestants to cheat by making up images themselves, e.g. by embedding those in the model weights. How do we know that that’s not happening here? There are a couple of answers: Technical reproduction. The Vesuvius Challenge Technical Review Team reproduced the winning submissions manually. We made sure to clearly understand every part of the code, and that when we run it independently we get similar output images. Since all code and training data is now open source, you can do the same! Multiple submissions of the same area. You might have noticed that all submission images above show the same area of the scroll. This is because we released 3d-mapped papyrus sheets within the CT-scan (“segments”) created by our segmentation team, which were then used by all contestants. The resulting output images — created by different ML models and training labels — have produced extremely similar results. This holds not just for the winners and runner ups, but also for the other submissions that we received. Small input/output windows. The ink detection models are not based on Greek letters, optical character recognition (OCR), or language models. Instead, they independently detect tiny spots of ink in the CT scan, the writing appearing later when these are aggregated. As a result, the text appearing in the images is not the imagined output of a machine learning model, but is instead directly tied to the underlying data in the CT scan. The models use small input/output windows. In some cases, the output is even only binary (“ink” vs “no ink”), as shown in this animation. This makes it extremely unlikely for the model to hallucinate shapes that look like letters. How does the unrolling work? Roughly, virtual unwrapping works in three steps: Scanning: creating a 3D scan of a scroll or fragment using X-ray tomography. Segmentation: tracing the crumpled layers of the rolled papyrus in the 3D scan and then unrolling, or flattening, them. Ink Detection: identifying the inked regions in the flattened segments using a machine learning model. These scrolls were scanned at Diamond Light Source, a particle accelerator near Oxford, England. The facility produces a parallel beam of X-rays at high flux, allowing for fast, accurate, and high-resolution imaging. The X-ray photos are turned into a 3D volume of voxels using tomographic reconstruction algorithms, resulting in a stack of slice images. Scrubbing through the slice images of the scroll. The next step is to identify individual sheets of papyrus in 3D space. For this we primarily use a tool called Volume Cartographer, created by Seth Parker and others in Brent Seales’ lab, and augmented by our contestants, primarily Julian Schilliger (Grand Prize winner) and Philip Allgaier. Volume Cartographer is operated by our team of full-time segmenters: Ben Kyles, David Josey, and Konrad Rosenberg. They use a combination of automatic algorithms and manual adjustments to map out large areas of papyrus. This is still a painstaking process, with lots of room for improvement if we’re going to segment all the scrolls. Animation showing manual and automatic segmentation in Volume Cartographer. Finally, ink detection. Stephen Parsons at Brent’s lab had shown that Herculaneum ink could theoretically be detected in CT scans, but so far only using smaller fragments — detecting ink in the larger scans of complete scrolls had yet to be achieved. For months this part proved elusive, until progress was made on two separate tracks: Crackle pattern. Last summer, Casey Handmer discovered a strange pattern of “crackle” by looking at raw flattened surface volumes. This pattern appeared to form letters. Casey won the First Ink Prize for this monumental discovery and shared it with the community, and a flurry of activity followed. Luke Farritor (Grand Prize winner), immediately started hunting for more crackle in flattened surface volumes produced by the segmentation team. He then trained a machine learning model on the shapes he found, which led directly to him winning the First Letters Prize in October. Kaggle competition. Separately, hundreds of teams tried building the best machine learning model for detecting ink in open fragments — pieces that had broken off during the physical unrolling process of scrolls, hundreds of years ago. Instead of labeling crackle (which wasn’t known yet), they had the benefit of ground truth data directly from photos of these fragments. Photo of Fragment 1 Aligned infrared Aligned binary ink labels This resulted in excellent models, but they did not seem to work on the flattened segments which the segmentation team produced. That was, until Youssef Nader (Grand Prize winner) used domain adaptation techniques on them, the start of a technique that ultimately won him the second place First Letters Prize. After the success of the First Letters Prize, the Grand Prize seemed within reach. Youssef, Luke, and Julian teamed up, with several other teams putting in strong submissions as well. What did it take? With the Vesuvius Challenge, we hope not only to solve the problem of reading the Herculaneum Papyri, but also to inspire similar projects. For that, it’s helpful to know what has contributed to our success in 2023. Here are some things we believe were important: An inspiring goal and a clear target. There are many worthy causes in the world, so it helps that our goal is unusual for a computing competition. It drew more press and donations early on, it attracted an intrinsically motivated community, and it increased our probability of success to begin with (emerging research area => a higher marginal utility of dollars spent). We’d love to see more projects that are “out there,” for exactly these reasons! A solid starting point. The foundation was laid by Dr. Seales and his team. They spent two decades making the first scroll scans, building Volume Cartographer, demonstrating the first success in virtual unwrapping, and proving that Herculaneum ink can be detected in CT. Brent Seales, Seth Parker, and Michael Drakopoulos at the particle accelerator. Blending competition and cooperation. A Grand Prize on its own would suffer from information “hoarding”: no one would share their intermediate work, because others could take it and use it to beat them to the finish line. Without information sharing, the probability of a single team solving all the puzzle pieces to win the Grand Prize would be dramatically lower. Instead, we blended competition and cooperation by adding “progress prizes” along the way. These were smaller prizes (often in the $1,000-10,000 range) every ~2 months. To win a progress prize, you had to publish your code or research as open source, thereby benefiting the entire community. Some of the many prize winners. Besides “leveling up” the entire community, this had several side benefits. We generated buzz and excitement in the community, which was motivating for everyone. It allowed winners to re-invest their winnings into better equipment, compute time, or even reduced hours at work or study to dedicate more to the competition. And it allowed people to find each other and form teams — like we saw with the Grand Prize winners. Hiring an in-house segmentation team. Every week we asked ourselves: what is the best thing we can do now to maximize the chance that someone wins the Grand Prize? In early summer, this led to the (then somewhat controversial) decision of hiring a full-time team of data labelers to manually trace the papyrus inside the scrolls and open source the flattened segments. An alternative was to leave the problem of segmentation to the contestants, or even to award separate prizes for segments, but this had several downsides. First, it’s hard to judge segment quality before knowing what to look for (we didn’t have working ink detection yet). Incentivizing segment quantity would automatically penalize quality. Second, labeling work is tedious and time consuming, and turned out to have a long learning curve, so it’s desirable to guarantee some compensation, which can’t be done with a prize. Third, the feedback loop with prizes can be pretty long. We were not dogmatically attached to just being referees; we were willing to run out onto the field and kick the ball a little. So we did what we thought would maximize success, and for the critical bottleneck of segmentation, that meant hiring a team. Our wonderful segmentation team: Ben, David, and Konrad. Also a big shout-out to former team members! Ultimately, this decision worked out great. It led directly to Casey Handmer’s discovery of the “crackle pattern” — the first directly visible evidence of ink and letters within the complete scrolls. The in-house segmentation expertise also turned out to be invaluable throughout the rest of the competition, discovering areas with potentially high ink signal, and figuring out the intricacies of the structure of the scrolls. And the segmenters worked closely with community contestants, which led to much better segmentation software. It was the best of both worlds! Maximizing surface area for breakthroughs. Our success was the result of many smaller breakthroughs by a broad group of people. It’s remarkable how many things had to come together to make this happen. Remove any of these, and we would not have succeeded, at least not within this timeframe. There are many more contributions than we can list here - even ideas and discoveries landing outside the critical path were still important, because a massive search space had to be exhausted to find the ideas that worked. Given the right framework, the collective intelligence of a community like this is very powerful. What’s next? Announcing the 2024 Vesuvius Challenge Grand Prize. When we started the competition, most of us estimated that we had a less than 30% probability of success within the year. At that point, no letters had yet been discovered inside of a scroll. On top of that, the scrolls had barely been segmented at all. We had doubt as to whether the project could succeed, especially by the deadline we set. Was the ink signal present? Were the scans high-resolution enough? Could the techniques used to identify ink in the fragments be transferred into a scroll? None of this was known at the time. But we knew it was worth trying! In Stage 1 of the Vesuvius Challenge, we answered all of these questions, extracting 15 columns of never-before-seen text from inside a lump of carbon. We now have proven techniques for virtually unrolling the papyrus scroll and recognizing ink using machine learning. Vesuvius Challenge Stage 2 In 2023 we got from 0% to 5% of a scroll. In 2024 our goal is to go from 5% of one scroll, to 90% of all four scrolls we have scanned, and to lay the foundation to read all 800 scrolls. The primary goal for 2024 is to read 90% of the scrolls, and we will issue the 2024 Grand Prize to the first team that is able to do this. More details on the exact grand prize judging criteria will be available in March. The bottleneck to achieve this milestone is the process of tracing the surface of the papyrus inside the scroll. Today this is extremely manual. It cost us more than $100 per square centimeter in manual labor to produce the text we can read today. At this price, it would cost hundreds of millions or maybe even billions of dollars to segment all of the scrolls. While improvements to our segmentation tools have increased our efficiency, it is still far too manual and expensive. What we need is automation. And so our primary goal for stage 2 is to perfect autosegmentation. Done right, this will also allow us to read the most challenging regions within the scroll – areas where the scroll was heavily compressed, cracked, delaminated, or otherwise damaged – which in many cases our current tools cannot even penetrate. In 2023 we were amazed by the community contributions. We loved the competition for the grand prize, which brought out the best in the contestants, but we were also thrilled to see the community collaborate towards intermediate goals. In 2024 we are leaning into that, still offering a grand prize, but allocating even more of the prize pool towards community contributions – a pool that will grow as we raise more money. We’re also planning to help speed things along ourselves, balancing prizes and in-house expertise to continue the collaboration that worked so well in 2023. To this end, we’ll hire a small software/ML team, in addition to the full-time segmentation team, who will work in the open with our community to advance the state of the art. If you are interested in contributing to our funding, and joining the craziest archeological project in existence, please contact us. And after that? After that, we will scan and read every scroll. We estimate that the scrolls we have in Naples contain more than 16 megabytes of text. Some members of our papyrology team say that revealing this text will be the greatest revolution in the classics since the Renaissance. However it goes, it will certainly be fun to try! And as if the prospect of reading hundreds of scrolls isn’t good enough, there might be an even bigger payoff at the end of all of this (as Nat said on the Dwarkesh podcast: “there is gold in this mud”). Dr. Garrett Ryan (toldinstone) writes it best on our History page: “The scrolls we have now may be just the beginning. When part of the Villa of the Papyri was cleared in the 1990s, archaeologists realized that the building was much larger than previously thought, with two unexcavated levels. At the very least, these floors likely contain more papyri in cabinets and carrying cases. And it’s probable that they conceal a far greater treasure. We have not yet found the villa’s main library, which would have contained a much wider range of Greek and Latin literature. That library, with its thousands or even tens of thousands of scrolls, must still be buried. If those texts are discovered, and if even a small fraction can still be read, they will transform our knowledge of classical life and literature on a scale not seen since the Renaissance.” The potential of tens of thousands of scrolls, still buried, waiting to be discovered?! The most exciting days still lay ahead. Read more detail about what comes next in our Master Plan. Thank you This couldn’t have happened without the many, many people who contributed in various ways, and we’d like to say thanks to all of them: Everyone who competed, shared insights, wrote code, made analyses, and brought energy to the project. Our adventurous donors, all of whom are private individuals from the tech world, who supported this project when it was not at all clear that there was any chance of success. The organizing teams (listed on our homepage): Vesuvius Challenge team, EduceLab team, and Papyrology team. Our partners: EduceLab, Institut de France, Diamond Light Source, Biblioteca Nazionale di Napoli, the Getty, and Kaggle — and all their respective funders. The professional and amateur papyrologists, historians, classicists, and other scholars — who helped answer countless questions in Discord. The supporting staff on the Vesuvius Challenge side (Sean, Emily, Frank, Lulu), and on the University of Kentucky side (Lindsey, Eric). The many contributors to the cause who came before us — who did excavations, wrote code, made scans, and built machines out of catgut and pig bladders to try to physically unroll the scrolls. And of course the Grand Prize winners! Thank you all so much!! Now let’s get on with it and read the rest of the scrolls. The best is yet to come. Join the winners for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. More to come. Edit this page",
    "commentLink": "https://news.ycombinator.com/item?id=39261861",
    "commentBody": "Vesuvius Challenge 2023 Grand Prize awarded: we can read the first scroll (scrollprize.org)1005 points by amrrs 19 hours agohidepastfavorite152 comments ImageXav 13 hours agoI was ridiculously excited when I first read about this in October (if I remember correctly) last year, when a few of the first results were beginning to pop out. I found the methodology fascinating. First of all the digital unwrapping of the scrolls, then the recognition that crackling in the paper was the sign of ink, and finally putting together a model to detect it, piece by piece. I need to look into the final repository to understand what exactly they did, but they seem to have used a TimeSFormer. I'm confused by this choice as I thought it was for video. How did they apply this to images? In the end though, what a wonderful day for archeology. These young minds deserve a huge round of applause for what they have achieved. reply marcyb5st 24 minutes agoparentmy understanding is that the scan they did on the scrolls returned the layers themselves. Like so: ``` xxxxxxxxxxAbsolutely insane the level of wizardry being applied here to turn a lump of blackened, charred scrolls into readable text. Imagine what we'll be able to do to brains, dead or alive, in 100 years. And in 10,000, maybe we'll be reconstructing the light cone. Maybe that's what we are right now. (Not serious, but it's a fun thought experiment.) reply xvector 3 hours agorootparentThis is why I am going for cryopreservation if I ever have the luxury of choosing the way I die. reply echelon 2 hours agorootparentWell, that could go lots of ways. Maybe some rich trillionaire buys you and spawns you into an endless horror simulation. They might be into torture and get off on it. (\"No real humans harmed.\") But if the future can reverse the light cone, nobody is immune to that fate. Who knows what the future holds. These are just sci-fi flights of fancy. reply exe34 1 hour agorootparentI remember learning about ancestor simulations by the vile offspring in accelerando, but reversing the light cone is quite chilling - is there any sci-fi novel that deals with that you would recommend? reply noduerme 17 minutes agoprev>> “as too in the case of food, we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.” However, is it easier for us naturally to do without things that are plentiful? “Such questions will be considered frequently.” This reminded me, since they're scarce but also abundant... Has anyone actually eaten these giant waterbugs at Nue in Seattle? Is that like, a reasonable thing to subject a date to? reply jdminhbg 16 hours agoprevHere is the link to their \"master plan\" to read all of the excavated scrolls: https://scrollprize.org/master_plan It looks like there are two main bottlenecks to reading more: the need for manual intervention in segmenting the scanned scrolls, and the cost in scanning new scrolls. reply tysam_and 4 hours agoparentFunding is a huge one as well. Funding is the wheel that drives the project (source, have been hanging around the project people for a little while). If you know anyone that would help chip in for the Phase 2 of the project (scaling up, please let Nat know! (not directly affiliated with the project management team, just pointing to him as a great contact for that....The book you're describing sounds like \"Rainbows End\" by Vernor Vinge. In this near-future sci-fi novel, set in 2025, one of the subplots involves a project called the \"Library Project,\" where the UCSD (University of California, San Diego) library decides to digitize its entire collection. The process is somewhat as you described: books are destructively scanned by being shredded into tiny pieces, which are then scanned and digitized, with the text being reconstructed from the scans. This process is a part of the broader themes of the book, which include the effects of technology on society and the concept of \"wearable computing\" and augmented reality. Vernor Vinge, a retired San Diego State University professor of mathematics, computer scientist, and Hugo Award-winning author, is well-known for his works in the science fiction genre, especially for exploring the concept of the technological singularity. reply gwern 7 hours agorootparentI'm not surprised ChatGPT can answer it - I'm not sure why, but _Rainbows End_ is one of the most commonly-asked about SF books like that. Everyone remembers the book-tornado doing shotgun sequencing, but they can never remember its name or anything else that happens. I guess that's the problem with having a technology whose mental image is so compelling but also mostly disconnected to the rest of the book. (I know I can't tell you much about the rest without rereading the WP entry.) reply prezjordan 9 hours agorootparentprevhttp://www.technovelgy.com/ct/content.asp?Bnum=1109 Rainbows End by Vernor Vinge (ChatGPT helped with the search) reply yourapostasy 4 hours agoparentprevI’m now wavering a bit on my earlier dismissal of people freezing their bodies for an indeterminate future revival. I could probably get into a science fiction story with this premise: Instead of relying upon machinery, some zillionaire has their body dry frozen and stashed in a lunar south pole crater, with a foundation funding interstellar propulsion research to move the body to the coldest stable points discovered along the way towards the Boomerang Nebula (1° Kelvin) and research to revive back from burnt-crisp state. The foundation incites all sorts of advancements along the way like working out practical fusion and ever more exotic energy generation, AGI, gravity manipulation, Drexlerian nanotech, Dyson swarm, star wisps, self-modifying bodies and so on, in its quixotic quest to fulfill its mandate. reply namaria 12 minutes agorootparentI kinda wanna write an horror story about people freezing their bodies or heads only to be revived in the future bat shit insane from the excruciating experience of existing for several decades in a sort of limbo... reply bglazer 16 hours agoprevOne aspect of archaeology that I really find fascinating is the practice of leaving certain artifacts unexplored. The original discoverers of the scrolls tried to unroll a few, apparently found it was impossible without completely destroying the scroll, and then just left the rest undisturbed. Rather than pushing forward and destroying everything, they left these as a mystery for a future age. Two centuries (!!) later we can finally begin to understand these, with the aid of technology that would be utterly unthinkable to those people who very thoughtfully restrained themselves. reply unsupp0rted 16 hours agoparent> Rather than pushing forward and destroying everything In the early days they wouldn't have accomplished anything by pushing forward, so it doesn't take all that much restraint. I'm more impressed by people in, say, the 1990s or early 2000s. They might've had a shot but there was still too much risk, so they restrained themselves until it was a safer bet. reply gwern 15 hours agorootparentYeah, I can't give the King's men much credit here. They destroyed a lot of scrolls, and it was only because they weren't getting much of anything that they stopped and abandoned excavations or focused on digging out sculptures they could show off (many now in the Getty Museum - great museum, but I did feel a bit melancholy thinking about the scrolls while I was there in 2019). reply klyrs 13 hours agorootparentprevOn the other hand, we ground up mummies for paint to the point that we ran out and used fresher corpses to meet demand. It is a bit of miracle that they were preserved, and not just discarded. reply ska 12 hours agorootparentWorse than that, lots were ground up (and consumed) for medicines. reply UberFly 10 hours agorootparentIn one of the Futurama episodes, Fry eats one of Farnsworth's mini mummies and Farnsworth is upset because he wanted to eat it. Fry said it tasted like jerky I think. reply wayvey 12 hours agorootparentprevWhere can I read more about this? Frankly I'm a bit surprised that I've never heard about this considering how shocking it sounds. reply klyrs 12 hours agorootparentWild, isn't it? Hands down my favorite historical fact learned in 2023. https://en.m.wikipedia.org/wiki/Mummy_brown reply aruggirello 12 hours agorootparentWild? Wait until you read about people actually eating mummies and corpses https://www.nationalgeographic.com/history/article/mummy-eat... reply boffinAudio 25 minutes agorootparentThe things Futurama made me look up on Wikipedia... reply klyrs 12 hours agorootparentprevWow. I like aged cheese but that is a bridge too far. reply topper-123 11 hours agoparentprevOne aspect of that time period is they absolutely idolized the romans. A lot of education at the time consisted of learning latin and at the same time people were well aware that only a fraction of the classical texts had been preserved. I find it very believable that they understood the significance of preserving and potentially unlocking these scrolls. reply dmurray 16 hours agoparentprevAn example of the same thing at a macro level: https://www.smithsonianmag.com/smart-news/archaeologists-reb... reply _a_a_a_ 15 hours agorootparentBigger yet by far https://en.wikipedia.org/wiki/Mausoleum_of_the_First_Qin_Emp... He of the terracotta army. Not excavated yet for fear of damage, but I would so love to know... reply cameron_b 7 hours agorootparentThe feeling you get when you’ve gone into one of those aircraft hanger-size buildings and then you see some of the information they’ve gotten with ground tests ( radar, mercury, etc ) is wild. The site is huge. One of the suppositions is that the main chamber contained a model of his entire kingdom, replete with rivers of mercury. So yes. Archaeology is a bit destructive, and sometimes the destruction can go both ways. Proceed with caution. reply tobinfricke 13 hours agoparentprevSimilarly, there are large sections of Pompeii, which remain unexcavated -- left for the future. reply Tronno 13 hours agorootparentHerculaneum, where these scrolls are from, is 75% unexcavated! And it will likely remain this way for some time, as Naples sits right on top of it. reply ffgjgf1 2 hours agorootparentThe town of Ercolano sits on top of it. Of course effectively it’s a suburb of Naples these days reply countrymile 17 hours agoprevQuite incredible work, with the original breakthrough model being trained on a 1070: https://twitter.com/LukeFarritor/status/1754532281690243339 reply sangnoir 15 hours agoparentLarge Language Models have skewed the perception on the amount of compute required to do useful things with ML. reply mNovak 6 hours agoprevThe scroll segmentation looks like it'd be a very manageable task for distributed volunteer work too, at least as a kickstart if that's really the bottleneck now. Just a 100 or 1000 halfway dedicated volunteers (small by internet standards, for a useful and simple task) could make a big dent. Don't know how many scan layers are in a single scroll, but for instance Project Gutenberg's proofreading network has processed millions of pages, one by one. reply sekai 18 hours agoprev> We estimate that the scrolls we have in Naples contain more than 16 megabytes of text. Some members of our papyrology team say that revealing this text will be the greatest revolution in the classics since the Renaissance Amazing achievement, let's hope the Italian government allows for additional excavation of the villa. reply riffraff 17 hours agoparentthey likely would, Pompeii and Herculaneum are _still_ being excavated after two centuries, it's not like things are still. But we have only read 5% of this scroll and there are a ton more already excavated, it will probably take years before we manage to process what we already have. reply seydor 16 hours agorootparent> it will probably take years In the direction things are going ... maybe a few months :) reply pimlottc 15 hours agorootparentThere’s more to processing than scanning, it has has to be reviewed, transcribed and translated by linguistics experts, and then analyzed and studied by academics and researchers who can put in context and integrate it with what we currently know about history, cultural, philosophy, etc of the time. reply kristopolous 10 hours agorootparentprevThe biggest bottleneck is getting the experts to read it. You need a decade or so of graduate level education and interpreting things takes apparently quite a long time. Maybe that's another AI application. reply digging 9 hours agorootparentAs much as I'd like to endorse study of the classics, I'm almost certain that AI will be better at interpreting the texts than humans very soon. reply ffgjgf1 2 hours agorootparentGPT 4.0 isn’t even remotely close to being useful at all in this case so I have some doubts about ‘very soon’ reply Digory 13 hours agorootparentprevIf you can automate the input, you can probably automate much of the basic analysis (things that would be \"revolutionary\" to undergrads). \"ChatGPT, give me the highlights of these ancient Greek scrolls ...\" reply wl 16 hours agoparentprevThe big problem is that the Villa of the Papyri is underneath modern buildings. That doesn't mean that excavation without demolition is impossible (see the Scavi underneath the Basilica of Saint Peter), but it makes things far more difficult. reply BlueTemplar 12 hours agorootparentIf the prospect is very high to multiply by several times the total remaining classical works, I doubt that the money will be particularly hard to find ? reply wl 11 hours agorootparentDavid W. Packard (HP heir) has been trying to throw money at doing this for years, so the money isn't as much of an issue as you'd think. The larger issue is that the locals don't want digging underneath their buildings, no matter how careful the excavators are. Also, all the money that would be necessary to excavate has made the project a target for the mafia who wants to get their share. reply jobs_throwaway 4 hours agorootparent> the money isn't as much of an issue as you'd think. The larger issue is that the locals don't want digging underneath their buildings, no matter how careful the excavators are This sounds like the money IS a huge issue. How expensive can it be to buy out the locals? We're talking about priceless cultural artifacts reply jacquesm 2 hours agorootparentprev> Also, all the money that would be necessary to excavate has made the project a target for the mafia who wants to get their share. I wonder how far Italy will go once - if - they get rid of the mafia, it is like trying to drive a car with the handbrake on. reply dang 14 hours agoprevRelated: First word discovered in unopened Herculaneum scroll by CS student - https://news.ycombinator.com/item?id=37857417 - Oct 2023 (207 comments) The Vesuvius Challenge - https://news.ycombinator.com/item?id=35322809 - March 2023 (32 comments) Vesuvius Challenge - https://news.ycombinator.com/item?id=35169869 - March 2023 (32 comments) reply dang 14 hours agoparentFrom today there's also this article, which maybe goes into more background (I haven't checked): Can AI Unlock the Secrets of the Ancient World? - https://news.ycombinator.com/item?id=39261465 - Feb 2024 (1 comment) and this tweet which presumably covers the same ground as OP: The $700k Vesuvius Challenge prize has been won - https://news.ycombinator.com/item?id=39261933 - Feb 2024 (2 comments) reply codeulike 15 hours agoprevOver 2000 years ago a chap called Philodemus sits in the library of a luxurious villa owned by a rich guy who likes collecting art and writing. He writes his thoughts on pleasure, and the relationship between the quantity of something and the pleasure that might derive from it. The scroll goes on the shelves with the others. He writes lots. At some point later the villa is covered by lava from mt vesuvius. 2000 years later we scan the carbonised scrolls with (basically) magic rays and use thinking machines to reconstruct what Philodemus wrote. I wish we could tell him. Sounds like he was a thinker, he would really appreciate it. reply clawoo 14 hours agoparentI have too wild imagination sometimes. I picture him with a shocked look on his face, similar to what one of the modern 'thinkers' would have if they forgot to clear their browser history and somehow someone restored it in the future. \"You recovered... uh... everything?\" reply cooper_ganglia 13 hours agorootparentYour comment prompted me to go in search of something I'd seen several years ago: something about an advertisement in Pompeii for prostitutes, or something like that. Anyway, I couldn't find exactly what I went in search of, but I did stumble upon this oddly specific, yet interesting, Wikipedia entry: https://en.wikipedia.org/wiki/Erotic_art_in_Pompeii_and_Herc... Priapus had it goin' on! Reading the Priapeia for the first time is a treat... reply rrr_oh_man 12 hours agorootparent> something about an advertisement in Pompeii for prostitutes, or something like that Maybe something along these lines? https://en.wikipedia.org/wiki/Lupanar#Graffiti reply bee_rider 14 hours agorootparentprevThat recovery is much easier though, it is using the device as intended. And of course, rm just unlinks, doesn’t actually delete, so even going a step further and recovering deleted content is hardly magic. This is more like if, sometime in the future, they somehow successfully reconstructed a snapshot of our computers’ volatile memory by examining the power supply, or something ridiculous like that. reply the8472 8 minutes agorootparent> rm just unlinks, doesn’t actually delete, On HDDs. On SSDs it'll lead to now-unusued space getting TRIMed which actually erases the blocks. Back to scraping the papyrus. reply nindalf 13 hours agorootparentprevBig if. We’ll lose a lot of digital data simply because we won’t have the means to read it. CD-readers aren’t manufactured anymore in volume. It’s easy to imagine society in 40 years not having any CD readers handy but having a bunch of CDs they want to read. Now multiply that by all the funny storage formats we’ve created over the years. reply bornfreddy 12 hours agorootparentNo need for a CD reader if you have a CT scanner and software that converts those ridges into bits. The bigger question is how well preserved those CDs will be. reply bee_rider 12 hours agorootparentprevI’m almost certain it is impossible to actually do what I said. But then again, I bet anybody 2000 years ago would say the same of reading scrolls that have been consumed by a volcano! reply gwern 7 hours agoparentprevEpicureans were atomists (https://en.wikipedia.org/wiki/Epicureanism#Physics), so if you explained it to him, he might not be nearly as shocked as most people of the era would be. Epicureans also tended to invoke extremely insubstantial 'images' composed of especially tiny gossamer arrangements of atoms as explanations for things like dreams, and you can see how well that would work as an analogy with using X-rays to look at subtle changes in the arrangement of atoms in charred scrolls. (These are covered in https://en.wikipedia.org/wiki/De_rerum_natura - if you have some time, I highly recommend reading Stalling's rhyming translation. You'll be shocked and admire the rationality & scientificness of Epicurean materialist atomist explanations of the world, even where they get it totally wrong.) reply jacquesm 2 hours agorootparentIt's a testimony to the power of mind equivalent to Einstein's 'Gedankenexperimenten'. The only reason they got some of it totally wrong is because they lacked the scientific apparatus to test their hypothesis, but they were on the right track. reply codeulike 12 hours agoparentprev... and what would he think of us, 2000 years later thought has led us to amazing advances in technology that would be inconceivable to him. But the sort of things the people of his day thought about, virtue, happiness, how to live the right way, not a lot of progress has been made. He might be surprised by that. In his time at the dawn of written thought-for-thoughts sake, they might have reasonably expected that soon people might think their way to a golden age of happiness and contentment. But 2000 years later we have learnt that you dont seem to be able to think your way to happiness. reply dougmwne 11 hours agorootparentI think we have learned not that you can’t think your way to happiness, but that for the sake of the consumer economy and worker productivity it’s best that you don’t. reply mkl 8 hours agoparentprevAsh, not lava. reply ChatGTP 11 hours agoparentprevMaybe in 20 years when resurrection is possible (singularity event) we'll be able to let him know? reply ptelomere 5 hours agoprevMy God, once in a while, you need to read something like this, reflect, ask the question \"can I do better in my work ?\", such an inspiring story of technical feat, persistence, and ingenuity. reply iandanforth 13 hours agoprevI was recently reading the Greek Myths series by Stephen Fry and he makes a point of how there are so many stories we know of but have been lost from ancient texts. Stories and authors that were famous enough to be mentioned by multiple other authors but which themselves have been lost. This collection of scrolls could contain some of those lost stories and the possibility of that is terribly exciting. reply 0x_rs 11 hours agoparent>stories we know of but have been lost from ancient texts So many there's a lengthy list on Wikipedia about it. It's fascinating reading ancients casually referencing works that we otherwise know nothing else about. Without the careful, laborious copying (often imperfect) over the centuries most things would've been lost completely. There's also other works such as maps that did not survive, the Tabula Peutingeriana for example is thought to be a derivative work of one commissioned by Augustus of the known world at the time (to Romans) and of which there's a few mentions in some works by historians at the time. https://en.wikipedia.org/wiki/Lost_literary_work reply xinayder 19 minutes agorootparentA great example about lost work is that the insights we have onto Viking mythology was pretty much documented by a single guy, Snorri Sturluson. What we know about Norse mythology is just a tiny piece of their mythos, as they didn't have the habit of writing down their tales/legends/stories and most of it got lost after they converted to Christianism. reply laichzeit0 49 minutes agorootparentprevSeutonius' Lives of Famous Whores is a lost text I've always hoped we would recover at some point. reply arbuge 11 hours agoparentprevAnd those are just the known unknowns. Besides those, to borrow from Rumsfeld, there are the unknown unknowns. reply dekhn 8 hours agoparentprevI would love to read the Telegony. Homer did such a good job with episodes I and II that I'm really curious how the story ends. reply colechristensen 12 hours agoparentprevNot just works of fiction or mythology but also histories, and works of science and philosophy. reply eszed 12 hours agorootparentI want Aristotle's treatise on Comedy, and if I'm allowed to be terribly greedy, just one more play by Aeschylus. This is the most exciting thing in the world to me right now, these scrolls, along with the thought that there might be literally thousands more still in the ground. reply CamperBob2 11 hours agorootparentMight want to put on a pair of gloves and a respirator if you find that Aristotle volume. Some people were pretty offended by it, I understand. reply manyty 2 hours agoprevNetflix documentary soon please! Big ups for the winners - this is so cool and hopefully can be replicated for deciphering many other lost manuscripts. reply dekhn 9 hours agoprevWe truly live in a golden age of physical and mathematical discovery. To get here required many thousands of years of technological development. The developers of the transformer, as a group, should win some sort of significant prize; it has had more impact in a short time than anything I've seen before. Will we find better architectures in the near future? reply laichzeit0 5 hours agoparentJust don’t say something like this out aloud near Gary Marcus. reply ComputerGuru 13 hours agoprevBetter but less technical writeup: https://www.bloomberg.com/features/2024-ai-unlock-ancient-wo... reply jaredhallen 11 hours agoprevI'm sure the original authors didn't expect to be incinerated by a volcano (and I'm also sure that the future legibility of their writings would be the very least of their concerns!), but it really bends the mind to imagine their reaction if they could have known how this would all unfold (unroll? Sorry...) reply leoc 15 hours agoprevApparntly the bad news is that the remaining scrolls most likely contain yet more Epicurean philosophy, maybe largely from not-top-rated guys like Philodemus. (Apparently it's possible that the library actually is, or incorporates, Philodemus' personal library.) https://twitter.com/DrFrancisYoung/status/175453630645602754... reply dougmwne 15 hours agoparentThat’s quite premature, but even if we are looking at a personal library containing only personal writings, you’d be looking at a massive increase of information on the ancient world, like a neural map of a single ancient mind that contained all their experiences and thoughts. The worse case would be that it was 800 copies of the same scroll waiting to be sold off to other libraries. reply Leo_Germond 15 hours agorootparentAll the 847 chapters of Philodemus fan fiction of MLP (my little Plato) reply r_klancer 12 hours agoparentprevThat's not necessarily bad news. Everyone interested in this story should read Stephen Greenblatt's The Swerve (https://www.pulitzer.org/winners/stephen-greenblatt). It traces the story of a Renaissance humanist who tracked down and translated the Epicurean philosopher/poet Lucretius' De Rerem Natura, which Greenblatt describes as portraying a strikingly modern way of seeing the world. In particular Lucretius and the Epicureans denied the existence of supernatural causes, were opposed to religious fear, and posited the ideas of atomism and biological evolution. Of course they're better known for their approach to living life, which Greenblatt shows is more sophisticated than sometimes caricatured, and which he portrays as a breath of fresh air compared to the oppressive moralism and hypocrisy of the Church at the time. (Jefferson and many of the American Founders described themselves as Epicureans.) He goes on to imply that Epicureanism was influential and widespread in the ancient world but suppressed by the early Church, so that we now know little of it. Anyone, one of the tantalizing parts of the book is where he describes the carbonized and unreadable Herculaneum scrolls, since they were the private library of a wealthy patron of the Epicureans. I think he thinks being able to read the scrolls will really change our understanding of the ancient world. And remember: if they hadn't been carbonized, they would have crumbled to dust. That's why we only have the texts that managed to get copied. (Anthony Doerr's Cloud Cuckoo Land is a novel about the survival and 21st century rediscovery of an imaginary Greek play, and ... I'll let you read it yourself - https://www.anthonydoerr.com/books/cloud-cuckoo-land) (Apologies for any errors above, as basically all I know about this subject is what I read in the book!) reply telotortium 1 hour agorootparentI realize citing Wikipedia risks some serious error, but my impression is that by late antiquity (after AD 200), the main philosophical systems in the Roman world were Christianity and Neoplatonism (itself heavily influenced by Christianity) and to a lesser extent Stoicism. Stoicism, Epicureanism, and Middle Platonism were more characteristic of Classical Antiquity (200 BC-200 AD). The Wikipedia page on Epicureanism[0] supports this impression: \"By the late third century CE, however, there was little trace of its existence.[7] With growing dominance of Neoplatonism and Peripateticism, and later, Christianity, Epicureanism declined.\" [0] https://en.wikipedia.org/wiki/Epicureanism reply digging 9 hours agorootparentprev> Everyone interested in this story should read Stephen Greenblatt's The Swerve (https://www.pulitzer.org/winners/stephen-greenblatt). It's interesting reading for a layperson, but as with any other pop-history book, one should read this with a heaping plate of salt at hand. (I'm... not sure what that metaphor actually means or if this is an appropriate way to extend it.) Things are always more nuanced than can be laid out in a sweeping narrative format and the compression required can lose some critical information, even with the best of intentions. There's also just getting things wrong, which most non-historians do and many historians will do on topics that aren't their expertise. I'd read this criticism from AskHistorians (not infallible, I know) https://old.reddit.com/r/AskHistorians/comments/ejfxe5/comme... reply riffraff 2 hours agorootparentThe \"grain of salt\" reference relates to some antidote, which contained a grain of salt. The reduction to \"handle with care\" is modern. So the extended metaphor makes no literal sense according to the Pliny text, but it makes sense according to our interpretation of it, which is what matters. reply akprasad 11 hours agorootparentprevYou might also be interested in the Charvaka school of ancient India [1], which is a close counterpart to Epicureanism. The Charvaka school was likewise influential and widespread, and it likewise become obscure over time, for reasons I don't know. [1]: https://en.wikipedia.org/wiki/Charvaka reply generationP 10 hours agoparentprevProbably true, but there are more rooms in the Villa yet to be excavated. What we have is essentially a bookshelf in a larger library. If it is sorted by alphabet, it might be representative, but what if it is sorted by topic? reply foota 1 hour agoprevI could help but wonder while reading this how everyone involved would feel if the \"last step\" involving the papyrologists was automated as well. reply newzisforsukas 55 minutes agoparentAmazing? As whomever made it would have likely created an incredibly powerful generally useful tool. That would be much more exciting than probabilistically distinguishing layers of ink in soot. reply est31 8 hours agoprevThis is great news for preservation efforts as we have a large set of stuff that can't be opened. I wonder what this means for the maya codices, many of which are in similar shape: https://en.wikipedia.org/wiki/Maya_codices#Other_Maya_codice... reply darkwater 1 hour agoprevEven if I really do think this is an amazing effort, I'll spoil the techno-optimist party here by noting that's a bit sad that this kind of achievements are pulled off only by rich patrons that became millionaires doing another unrelated thing and they just want to scratch a personal itch/curiosity. Yeah, patrons and maecenas have been around forever, but I would really prefer that we as society were mature enough to achieve such things collectively. We did it, at least for a few decades and even if coming from wrong incentives, with space exploration. reply imranq 5 hours agoprevThe methods are incredible, but it seems like the text is ordinary and nothing to write home about reply s0rce 5 hours agoparentNot too surprising, but I like the random ancient texts https://en.wikipedia.org/wiki/Complaint_tablet_to_Ea-n%C4%81... reply f5ve 4 hours agorootparentThere really is one for everything: https://xkcd.com/2758/ reply hoten 5 hours agoparentprevI dunno, I found it pleasurable. reply gmd63 9 hours agoprevGiven that AI is able to hallucinate, how can we be convinced the results are accurate? Did they create a new scroll, burn it, and compare the results to what was actually written? reply WorkerBee28474 9 hours agoparentThe ML models were trained without knowledge of the scrolls' language. The models extracted images, and human experts were able to read the images as text. There was no text corpus fed in that could be leaked into the output. reply leeoniya 9 hours agoparentprevread the article reply gmd63 9 hours agorootparentThanks. From the article, for anyone else skimming who had the same question: Technical reproduction. The Vesuvius Challenge Technical Review Team reproduced the winning submissions manually. We made sure to clearly understand every part of the code, and that when we run it independently we get similar output images. Since all code and training data is now open source, you can do the same! Multiple submissions of the same area. You might have noticed that all submission images above show the same area of the scroll. This is because we released 3d-mapped papyrus sheets within the CT-scan (“segments”) created by our segmentation team, which were then used by all contestants. The resulting output images — created by different ML models and training labels — have produced extremely similar results. This holds not just for the winners and runner ups, but also for the other submissions that we received. Small input/output windows. The ink detection models are not based on Greek letters, optical character recognition (OCR), or language models. Instead, they independently detect tiny spots of ink in the CT scan, the writing appearing later when these are aggregated. As a result, the text appearing in the images is not the imagined output of a machine learning model, but is instead directly tied to the underlying data in the CT scan. reply leeoniya 9 hours agorootparenttl;dr: cross-validation between competing submissions reply laser 11 hours agoprevThis is amazing, sci-fi-like-reality. I wonder if they pull off an auto-segmentation breakthrough if the techniques might apply in other areas, like automating neuron mapping (eg. see EyeWire). reply cooper_ganglia 12 hours agoprevThis is amazing and very, very exciting! It is wild to me, though, that if I have an SSD fail it's essentially unrecoverable, but a 2,000-year old, rolled-up, lava-burnt scroll of Papyrus can be read using Technology™! I love to see it! reply BlueTemplar 12 hours agoparentAre you sure it wouldn't be recoverable using something on a similar level than they did (particle accelerator scanning) ? reply pimlottc 16 hours agoprevThis is really cool! Is the output resolution limited by the granularity of the CT scans? reply thom 13 hours agoprevSo excited to see how much text is recoverable and to what extent this can bolster our collection of Epicurean writings! reply low_tech_punk 13 hours agoprevLack of information retrieval technology ≠ loss of information. reply nerdo 15 hours agoprevIncredible effort. Text of scroll is essentially \"drink more Ovaltine\" which is on theme. reply TremendousJudge 16 hours agoprevThis is exciting, it's very unusual for new texts to be added to our collection of ancient literature. reply m3kw9 11 hours agoprevPretty cool engineering to pull this off reply jacobwilliamroy 12 hours agoprevI don't know if anyone who worked on this project is going to read this but if you are: good job! This looked like it was really hard. reply yieldcrv 13 hours agoprevtl;dr The general subject of the text is pleasure, which, properly understood, is the highest good in Epicurean philosophy. In these two snippets from two consecutive columns of the scroll, the author is concerned with whether and how the availability of goods, such as food, can affect the pleasure which they provide. Do things that are available in lesser quantities afford more pleasure than those available in abundance? Our author thinks not: “as too in the case of food, we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.” However, is it easier for us naturally to do without things that are plentiful? “Such questions will be considered frequently.” reply verisimi 10 hours agoprevI still think this methodology can be tested by creating equivalent carbonised scrolls, where you write some specific text and check the result against what you wrote. Ie you run your test artifacts through the scanner and software, and the process should return you your test text that you wrote before carbonising the scroll. At that point you can be assured that the process is not making stuff up from noise. But, without that process, you can have no comfort than what is occurring is valid. The software might reliably see a letter in some noise, but so? It doesn't mean the letter is actually there... One can't verify the scroll, and one hasn't verified the process. reply verisimi 2 hours agoparentI think this suggestion of mine was downvoted last time too, but I don't get why! One would always want to test stuff in software development, especially if it was fraught and can easily be tested. Mostly there are no tests to be undertaken in history -hence it it's so much hearsay. But here is an opportunity to gain some genuine certainty, in a way that is normally unavailable! The implementors of this method should absolutely test their process! reply ffgjgf1 2 hours agorootparentAFAIK the scanning process is pretty expensive reply lostlogin 10 hours agoprevI was worried it would contain something boring like tax records, but it's even worse than that. Fingers crossed it gets a little more interesting than the average social media post. reply glfharris 10 hours agoparentI'm pretty sure there are academics who would bite their own legs off for tax records from this period. reply kilroy123 10 hours agorootparentIsn't that what most ancient Roman texts we do have are? Tax records. reply ffgjgf1 2 hours agorootparentDo we have any or any significant number of Roman tax receipts? Most Roman/Greek texts that we have had to survive until ~1000 AD. If a text was available back then there is a reasonably good chance that we have it (or rather a medieval copy of it), why would anyone waste time copying tax receipts though? reply dylan604 11 hours agoprev [–] \"4 passages of 140 characters each, with at least 85% of characters recoverable\" oh good grief, even back then, we were limited to this value reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The winners of the Vesuvius Challenge 2023 Grand Prize have been announced, and they have successfully read a 2000-year-old scroll from the Herculaneum Papyri.",
      "The scroll discusses topics such as music, food, and pleasure, providing valuable insights for further study.",
      "The winning team utilized machine learning models and auto-segmentation tools, but they still need to improve upon them.",
      "The research process involved the use of X-ray tomography and machine learning to analyze the papyrus scrolls.",
      "The competition promoted cooperation and information sharing.",
      "The next challenge, the 2024 Vesuvius Challenge, has been announced, aiming to unlock more texts from buried scrolls to enhance our understanding of classical life and literature.",
      "The winners of the challenge will celebrate at the Getty Villa Museum."
    ],
    "commentSummary": [
      "Scientists have made progress in reading ancient scrolls through digital unwrapping and AI algorithms, leading to potential advancements in archaeology and technology.",
      "Challenges in manual segmentation and scanning of more scrolls, as well as the need for funding, are hindering further developments in this field.",
      "Excitement surrounds the potential discovery of lost manuscripts and the understanding of Epicurean philosophy in the scrolls, but concerns about accuracy and verification persist."
    ],
    "points": 1004,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1707145202
  },
  {
    "id": 39266396,
    "title": "Adjustable Acceleration: Exploring Relativistic Spaceship at 0.00% Speed of Light",
    "originLink": "https://dmytry.github.io/space/",
    "originBody": "Welcome to the Relativistic Spaceship page. Click anywhere on the Acceleration slider. The ship is flying at 0.00% of the speed of light. γ = 1.00 Distance (light years) = 0.0 Screen center Doppler factor = 1.00 Max Doppler factor = 1.00 Ship time (years) = 1 World time (years) = 1 © 2020 Dmytry Lavrov. A C C E L E R A T I O N B R I G H T N E S S",
    "commentLink": "https://news.ycombinator.com/item?id=39266396",
    "commentBody": "Relativistic Spaceship (dmytry.github.io)750 points by thunderbong 13 hours agohidepastfavorite345 comments ryandrake 13 hours agoGreat visualization of the unintuitive nature of special relativity. It's kind of mind blowing to realize that if we could accelerate our spaceship at a mere 1G continuously, we could visit the center of the Milky Way in under 20 years (spaceship time), totally do-able in a human lifespan. Of course 27900 years would have passed on Earth, so you wouldn't be able to tell anyone about your vacation. reply onetimeuse92304 21 minutes agoparentNot doable. There exists nothing, even theoretically that you can put on the spaceship to get you that 1G continuous acceleration. I don't remember exactly what is the maximum achievable delta V but if I remember well it is not a high portion of the speed of light, more like 60% of speed of light. And that assuming you have crazy things like carry a small black hole with you and use it to convert mass into energy at 40% efficiency. reply AlexAndScripts 12 hours agoparentprevI suppose you would also have to worry about surviving the trip - every atom in the interstellar medium would damage your ship, likely penetrating the entire way through, and electromagnetic repulsion would only work with charged particles. reply MilStdJunkie 12 hours agorootparentEvery proton would have the energy of a baseball. It's bananas. Granted, space is really empty, but it's not that empty, somewhere around a hundred atoms per cubic meter. Your ship might look like a very, very long shooting star. Probably dialing the speed down a touch would be worth it for whatever your shielding material is, but who knows? We're talking miracle engines here. I think in the \"Valkyrie\" ship-on-a-string concept, they had some sort of magnetic thingummy that generated more power as more stuff smacked into it, then as they decelerated they let out this sort of gas mist to go ahead of the ship and smack into things. reply heads 3 hours agorootparentIf you’re doing 2e8 m/s, your ship is long and thin with a 1m3 nose cone, and space has 100 baseballs per m3 then you’re being hit by 2e10 baseballs a second. How do I get an idea for what 20 billion baseballs (2TJ) feels like? Apparently bullets are about an order of magnitude more energetic than baseballs (800J vs 80J) so I guess I could try to build my intuition based on being shot ~2 billion times a second instead. A kiloton of TNT is 4GJ, so it’s also like a 500 kiloton bomb going off every second. Dropping 5e5kg of rock into the worlds biggest dumpster truck at 10m/s yields 25MJ of chaos so it’s also like a parking lot of 80,000 of those being filled with a continuous stream of rubble. That’s probably the best analogy given that we’re talking about machinery — your spaceship needs to have the build resilience of tens of thousands of dumpster trucks but condensed into the cross sectional area of a dinner table. reply khazhoux 24 minutes agorootparent> How do I get an idea for what 20 billion baseballs (2TJ) feels like? In the 90s, the show Special Relativity’s Funniest Home Videos would often have guys getting hit in the crotch 20B times with a baseball. Honestly, it never gets old. reply kaashif 3 hours agorootparentprev> A kiloton of TNT is 4GJ, so it’s also like a 500 kiloton bomb going off every second. Funnily, my first reaction to this comparison is that it makes it seem more plausible to me that this is possible. After all, a Star Destroyer can take gigaton level hits! But the problem with that is Star Destroyers are fictional. I've been spending too much time on spacebattles.com. reply heads 3 hours agorootparentThe numbers are big but they don’t seem “big big” like Sagittarius A* is big or the distance to Andromeda is big. reply a_gnostic 5 minutes agorootparentprevA magnetic Ramjet could help (1) 1. https://www.sciencedirect.com/science/article/pii/S009457652... reply robertlagrant 12 hours agorootparentprevI like that old Arthur C Clarke novel, The Songs of Distant Earth[0], where they travel with an ablative shield in front made of ice, and they can make new shield segments by finding planets with water. [0] https://en.wikipedia.org/wiki/The_Songs_of_Distant_Earth reply jcul 11 hours agorootparentI read project hail Mary over Christmas, and they deal with this problem too. Though I can't say much without giving away spoilers. A great read if you are a sci-fi fan! reply e40 8 hours agorootparentMy second favorite sci-fi book of all time. Three body being the first. reply satvikpendem 7 hours agorootparentIndeed. Have you read the rest of the series? It just gets crazier and crazier. reply satvikpendem 7 hours agorootparentprevI recommend the audiobook in particular for this book. reply The_Colonel 4 hours agorootparentprevI think Hail Mary (and Astronaut) is more suited for people who don't usually like sci-fi. reply insane_dreamer 4 hours agorootparentI like sci-fi, and enjoyed Hail Mary very much reply slowmovintarget 12 hours agorootparentprevAlistair Reynolds also used this in his ship designs. reply dfee 10 hours agorootparentprevI’d like to see a map of the known universe visualizing atomic density on a log scale. I’d never seen “a hundred atoms per cubic meter”, but it’s always been my intuition that, without some quite interesting shielding, you couldn’t make it anywhere near the speed of light. And on the other hand, I’ve seen claims that “space is really big” as you mentioned; but that claim has always seemed dubious. reply sega_sai 5 hours agorootparentOne nice illustration of \"space is really big\" is a fact that if you take the cube with the side equal to the distance from the Sun to the nearest star and fill it with water, then the mass of this cube will be roughly equal to the mass of the whole visible Universe. reply wincy 4 hours agorootparentAnother good one for me is that a cubic light year or butter would immediately collapse into a black hole with a Schwarzchild radius larger than the observable universe. reply tlonny 24 minutes agorootparentThis sounded completely false to me initially. When I think of taking mass and turning it into black holes, it involves squashing the mass into a strictly smaller volume. Thus I would've expected the radius of the black hole to be necessarily smaller than the dimensions of the butter cube. However, I now realize my mistake - in examples like squashing mount Everest or earth or a neutron star into a black hole, we're starting with masses that are stable/in equilibrium. This would not be the case for a cubic light year of butter! Further, it looks like the radius is directly proportional to the mass. Given that mass grows cubic with respect to dimension, it's expected the radius of the black hole would eventually outgrow the cube of butter if made sufficiently large... reply jemfinch 4 hours agorootparentprevIt's impossible for your fact and the fact you're replying to both be true. Water is denser than butter, and the nearest star to the sun is about 4.3ly away; if your fact were true, the universe would be a black hole. A cubic lightyear is about 8.468e+50 liters, and butter weighs 911 g/L, giving the mass of a cubic lightyear of butter to be 7.714348e+50, whose Schwarzchild radius is about 121,103,293 lightyears, about 100x smaller than the radius of the known universe. reply lloeki 2 hours agorootparent> if your fact were true, the universe would be a black hole ... maybe it is? Hear my pet theory out. Extrapolating backwards from the expansion of our universe, the Big Bang model posits a hyperdense state that exceeds black hole levels originating from a singularity, yet it's thought that somehow it did not collapse back, handwaving it as \"physics as we know it did not apply\". But maybe physics as we know it does apply. Notably physics as we know it does not imply a specific direction for the arrow of time. So our universe might very well be a black hole, but we have time backwards compared to the usual way we think of black holes: what we think of as the origin of time and space is what we think of as the irremediable end of time and space in a black hole. reply heads 3 hours agorootparentprevWasn’t one of the great puzzles of the 20th century exactly this — will the universe collapse back into a singularity or not? reply WitCanStain 4 hours agorootparentprevSource? reply penteract 4 hours agorootparenthttps://www.wolframalpha.com/input?i2d=true&i=Divide%5B%5C%2... reply eru 9 hours agorootparentprev> I’d never seen “a hundred atoms per cubic meter”, but it’s always been my intuition that, without some quite interesting shielding, you couldn’t make it anywhere near the speed of light. It's not that bad. With currently known science, your fuel would most likely be hydrogen so you can run a fusion reactor. The rocket equation tells you that most of your starship by mass would be fuel, if you want to go fast. Of all the stuff on your ship that's not fuel, you'd probably need quite a bit of water for survival needs. So you would make your spaceship relatively long and thin (to maximize internal volume for a given frontal area), and you would store your fuel (and water) in front of you to serve as exactly that shield. reply tsimionescu 2 hours agorootparentWouldn't your water and food then become highly radioactive over time? Even if no, it would mean your shield will be gradually consumed. Not sure this is the best idea. reply eru 1 hour agorootparentYour fuel is the outermost layer of your shields (modulo whatever is necessary to keep the fuel in place. But you might use magnetic fields perhaps). That's basically free shielding: you have to carry the fuel around anyway, so you might as well put it to good use. If you run a nuclear fusion reactor, you won't really lose much of the mass of your fuel, unless you want to. Eg you could use the helium you produce as the reaction mass for your ion drive. (I haven't done the numbers to see how the required mass per second for your ion drive compares to the helium mass per second a nuclear fusion reactor would spit out.) Because it's a free shield, you don't really get to complain about your shield being gradually consumed. Of course, you can have some extra shielding further inside. You would keep your water forward of your people, but behind your fuel. So your water would not bear the brunt. Hydrogen doesn't really get all that radioactive: you can use chemical means to remove any helium or so you might accidentally produce; and hydrogen's isotopes are both pretty short lived and relatively easy to separate. (At least much easier than eg enriching uranium.) Your water and food is also only a very small fraction of the overall mass of your rocket: as always, the vast majority is made up of fuel. reply wongarsu 9 hours agorootparentprev100 atoms per cubic meter is on the lower end of typical densities in the interstellar medium. It can get many orders of magnitude denser than that. Outside galaxies you have better chances of surviving high speeds. The intergalactic medium is only 1-10 particles per cubic meter in the web of gas we call the warm–hot intergalactic medium, and possibly less outside of that. reply micw 4 hours agorootparentSo would probably better to get out of the galaxy disc, travel -fast- to the other end and dive back into rather that go straight through the galaxy? reply wordpad25 3 hours agorootparentExcept we can't get to edge of the galaxy quickly. I guess Hitchhikers guide to the galaxy building space highways destroying everything in the way could be more than a gag after all. reply GuB-42 9 hours agorootparentprevEven if you managed to avoid matter, at some point, photons will start to become a problem. As you continue to accelerate, eventually, the cosmic microwave background itself will become deadly X-rays. reply antihipocrat 9 hours agorootparentWould a layer of water in the forward hull positions mitigate this? reply mr_mitm 3 hours agorootparentTo a point, sure. Lead would be better. Some joke that this is the reason why Klingons have these thick foreheads. reply foota 12 hours agorootparentprevThese regenerative braking schemes are getting out of hand. reply TaylorAlexander 6 hours agorootparentprevWhat do you mean “the energy of a baseball”? A baseball at what speed? reply mlyle 4 hours agorootparentThey're saying a fastball pitch-- 340 joules or so of energy. The thing is, you need to be going implausibly fast to have a proton have a fastball level of energy. Even at .99999999 C, a hydrogen atom still has less than a microjoule of energy. You need a lot of 9's to get up to 340 joules. 1/sqrt(1-(0.99999999)^2) * (1 atomic mass unit * (speed of light)^2 1.05529895 × 10-6 joules reply moosedev 5 hours agorootparentprevI assumed they meant a baseball at baseball speed. reply idiotsecant 4 hours agorootparentprevI feel like regardless of the exact speed of the baseball, that's somewhat more energy than a typical proton. reply j4yav 3 hours agorootparentprevA baseball at football speed, of course reply abhibeckert 10 hours agorootparentprev> Every proton would have the energy of a baseball I wonder if you could capture that energy and use it to generate thrust. Most of the energy is coming from your thrust so it'd be a lossy process however if you're able to capture all of the energy then there won't be anything left to damage the ship. reply function_seven 9 hours agorootparentIsn't this kinda like mounting a fan on your car's roof to charge the battery? You have accelerated your spaceship to 0.995C (or whatever) and now you are encountering space dust at a phenomenal rate. Some of that dust is moving away from you, some of it toward you, some of it is at rest. On average it's all just sitting there unaware that your vessel is about to smack into it. The energy is in the difference between your speed and the particle's. If you try to harness it, you slow down. (I'm asking genuinely here. My analogy might be wrong because it's too classical!) reply sudhirj 5 hours agorootparentprevThere's two different kinds of energy here - the kinetic energy of a moving thing hitting you in opposition is a problem. No way to capture that as far as I know - it's like running into a wall and asking how it can help you go faster. But then there's e=mc^2, so if the stuff you're running into is the fuel source for your fusion engine (could be a fission engine, but unlikely you'll run into heavy atoms like Uranium or Plutonium) then you have an unlimited source of energy... So maybe sort of? Running into things slows you down, but then you capture that mass and release the energy out of it to go faster... because of the nature of e=mc^2 you'll usually get more energy out of something if you convert its mass than what you lose by running into that mass. reply _factor 2 minutes agorootparentI’m imagining a ship with a hole in it and a piece of fuel at the backside where the particles hit. It would slow you down first since you’re tethered to the particles, then the explosion would push you forward. The issue is that the energy for that explosion comes from the slowing down of your ship, so it doesn’t work. wiml 9 hours agorootparentprevThe old Bussard ramjet concept was to capture these high velocity protons (with some kind of magnetic field), cause them to fuse, and use the fusion energy for propulsion. There are a few engineering difficulties with the idea but it makes for some good SF stories... reply fyver 4 hours agorootparentThe spaceship in Poul Anderson's Tau Zero uses a Bussard ramjet. reply zwaps 4 hours agorootparentAlso all Stat Trek Federation ships reply amelius 9 hours agorootparentprevThis is a bit like driving into a brick wall, and then asking if you could use the released energy to go faster ... reply sveolon 4 hours agorootparentImagine you drive into a wall of tnt, break through it, and as you exit it explodes and gives you an extra boost. Yes, you’ve lost some speed at the beginning but you’ve gained much more reply _factor 0 minutes agorootparentThe tnt has potential energy. The only reason those protons have energy is because you’re smacking through them with energy you’ve already found. tomtomistaken 2 hours agorootparentprevSo such ships would look \"aerodynamic\"? reply defrost 2 hours agorootparentMore like bridges and skyscrapers, perhaps with an ablating sheild at the lead end, maybe an electromagnetic field to divert particles away. If the thrust is high enough, a tenth of a G to 1.5 maybe, the ship has to \"stand up\" on the thrusting engine in the same manner as a building must stand up over it's footprint, supporting itself against the force of (artifical) gravity. If it's higher thrust (as the human meatsacks are suspended in a fluid they've also swallowed ??) then the ship has to look even more like a heavy load brutilist building. reply whimsicalism 10 hours agorootparentprevwhy are protons more likely to be closer to rest relative to earth than relative to the fast spaceship? reply schiffern 10 hours agorootparent\"Although the density of atoms in the interstellar medium is usually far below that in the best laboratory vacuums, the mean free path between collisions is short compared to typical interstellar lengths, so on these scales the ISM behaves as a gas (more precisely, as a plasma: it is everywhere at least slightly ionized), responding to pressure forces, and not as a collection of non-interacting particles.\" https://en.wikipedia.org/wiki/Interstellar_medium reply actionfromafar 10 hours agorootparentprevBecause the entire Milky Way is mostly at rest relative to itself. If you are charging full speed ahead into its center, you are going against just about everything, including energetic particles no doubt coming the from the crowded center of the galaxy. reply perardi 12 hours agorootparentprevUnless you could somehow make an Alcubierre warp drive. Of course…even if that was possible, it’s conjectured that the colonists already at your destination won’t appreciate you boiling the atmosphere when you hit them with blue shifted radiation. https://www.universetoday.com/93882/warp-drives-may-come-wit... reply VanillaCafe 10 hours agorootparent> Unless you could somehow make an Alcubierre warp drive. Even if you can make it, even though it's theoretically possible that the warp bubble could move through space faster than the speed of light, it's a separate and completely open question as to how you might actually get it to move that fast to begin with. reply throwaway11460 11 hours agorootparentprevAh, so that's why they never warp near planets in Star Trek :) reply perardi 10 hours agorootparent[pushes up glasses] They implied they avoided that because warping into a gravity well would cause some vague catastrophe. Of course, the real reason was far more sinister: it’s way more dramatic to slowly creep up on the planet while listening to the captain’s log monologue to start the episode. reply actionfromafar 10 hours agorootparentIf nothing else, if you miss just a little dropping out of warp inside a planet, must be a Very Bad Thing in-universe. The ramifications would be seen even out-of-universe. ;-) reply eru 9 hours agorootparentPlanets are tiny compared to the vastness of space. So you would never accidentally warp inside a planet. reply BHSPitMonkey 8 hours agorootparentSure, if your probability distribution looks at every point in the universe equally. But we're talking about introducing error in a situation where you're _trying_ to drop yourself right next to a planet, so the areas nearest to your target have a much greater probability. reply eru 4 hours agorootparentThe volume of space up to only geostationary orbit is about 177 times bigger than the volume of the earth. Given that Star Trek's impulse drives are already traveling at up to around 0.9c, parking somewhere between the earth and the moon (which is about 1 light-second out), the ratio of space to volume of earth becomes 219,648. That ratio growth with the cube of the distance to the planet. reply cameron_b 8 hours agorootparentprevIf we’re talking about the known universe, the odds of your near-light navigation accidentally clipping a not-mapped-yet planet are certainly not zero. Our gaze into the heavens is much better at spotting stars than their dark orbiting bodies, and we have fingers left over from one hand counting the number of observation platforms observing deep space from above our shimmering atmosphere. reply Dylan16807 6 hours agorootparent> If we’re talking about the known universe, the odds of your near-light navigation accidentally clipping a not-mapped-yet planet are certainly not zero. If we're still talking about Star Trek, then on a solar scale those ships can stop on a dime. They're not going to hit an unmapped planet while putting around. reply StevePerkins 7 hours agorootparentprevIndeed. We can't even agree on whether or not there's an extra Neptune-sized gas giant out beyond the orbit of Pluto, and that's right here in our OWN solar system! reply eru 4 hours agorootparentSo? Even ten extra Jupiters or thousand extra suns would take up only a tiny amount of space compared to the size of the solar system out to Pluto: The distance from the sun to Pluto is about 5.9 billion km. The radius of the sun is about 696,340 km. The ratio of radii is about 8,473. Cube that to get the ratio of volumes, and you get 608,263,848,559 for the ratio of volume in a sphere out to Pluto vs volume of the sun. (Doing the numbers, I'm actually surprised: I had expected the ratio of radii to be bigger than 8,473. But I'm not surprised that the sun barely takes up any space.) reply eru 8 hours agorootparentprevIt doesn't matter whether we can see those dark orbiting bodies: we observe minuscule gravitational impact on the stars, and that places a very sharp upper limit on the amount of mass that's outside of the star in a solar system. The sun contains roughly 99.8% of the mass of the solar system, and is by far the largest object in it. But you wouldn't hit the sun randomly either. Space is just so damn large. reply api 10 hours agorootparentprev> it’s conjectured that the colonists already at your destination won’t appreciate you boiling the atmosphere when you hit them with blue shifted radiation. There's a general principle known as Jon's Law (not sure where the name comes from) that any powerful space drive is by definition a weapon of mass destruction. You see this in The Expanse when incredibly powerful fusion torchship rockets (a major part of the Expanse 'verse) are attached to asteroids and these are used to kinetically bombard inner planets. The results are far worse than a nuclear attack, from kinetic energy alone. Anything capable of traveling close to the speed of light would be \"death star\" level planet killer. We're talking smashing through the crust and boiling off the atmosphere or if it were massive maybe even fragmenting the planet. Obviously anything even wilder like an Alcubierre Drive would be likewise. Anything capable of going to the stars within a human lifetime could annihilate worlds. Even present-day chemical rockets could be pretty destructive. Get something massive that won't burn up (like a rod of tungsten) up to interplanetary velocities and you can approach the yield of a small tactical nuke from just kinetic energy. This has been studied at least on paper by militaries. I think the phrase \"rods from God\" was used by DARPA at one point for the rod of tungsten idea. This is glossed over in the vast majority of space sci-fi. Nobody even asks in Star Trek what happens if you point the Enterprise at a planet and say \"warp 9, engage!\" I'm guessing it would go poorly for the Enterprise but even worse for the planet. reply ahazred8ta 10 hours agorootparentLarry Niven's Known Space gave us the Kzinti lesson: \"a reaction drive's efficiency as a weapon is in direct proportion to its efficiency as a drive.\" -- https://tvtropes.org/pmwiki/pmwiki.php/Main/WeaponizedExhaus... reply tsimionescu 2 hours agorootparentprevI think that law is basically Newton's second law of motion. F=ma essentially tells you that anything that decelerates a lot, such as a very fast spaceship crashing into the rock of your planet, pushes with an awful lot of force before it stops. Edit: to be slightly more pedantic, the right form that still remains true with relativity is F = dp/dt, i.e. the force the spaceship would exert is equal to its change in momentum. reply webmaven 5 hours agorootparentprev> Even present-day chemical rockets could be pretty destructive. Get something massive that won't burn up (like a rod of tungsten) up to interplanetary velocities and you can approach the yield of a small tactical nuke from just kinetic energy. This has been studied at least on paper by militaries. I think the phrase \"rods from God\" was used by DARPA at one point for the rod of tungsten idea. Also known as \"Project Thor\", it was devised by Jerry Pournelle before he became a science fiction author. More on various iterations of the concept can be found in Wikipedia: https://en.m.wikipedia.org/wiki/Kinetic_bombardment reply ben_w 10 hours agorootparentprev> There's a general principle known as Jon's Law (not sure where the name comes from) that any powerful space drive is by definition a weapon of mass destruction. Also known as the Kzinti Lesson, from Larry Niven's Known Space series. I've not read where in that series this term is first introduced, but they're somewhere in all that. > Obviously anything even wilder like an Alcubierre Drive would be likewise Not yet known; the original Alcubierre Drive is a toy model that demonstrates the point, but has so many problems with it that, as is, it definitely won't work. Something else along similar lines that does work? The only thing it won't act like when it hits something, is like being hit by normal matter that's actually moving at the speed of light, because if it did it would also be an infinite free energy source. reply eru 9 hours agorootparentprev> Even present-day chemical rockets could be pretty destructive. Get something massive that won't burn up (like a rod of tungsten) up to interplanetary velocities and you can approach the yield of a small tactical nuke from just kinetic energy. Of course, that energy didn't come for free: if the rod came from earth, your rockets have to provide the energy. reply zem 10 hours agorootparentprevin niven's \"known space\" universe that was known as the \"kzinti lesson\"; the kzinti were a warlike race that thought humanity would be easy pickings because their telepathic spies said they had a civilisation completely at peace. turns out humanity figured out really fast that their mining lasers, fusion drives, etc could be used as weapons when the hostiles showed up. reply ryandrake 12 hours agorootparentprevSure, there are plenty of practical problems that would make the trip impossible. The fuel mass alone that would have to be shot out the back to make that trip would be something on the order of 800 million times the mass of the payload (you). So a 100kg person sitting in a 100kg spaceship would require something like 160 billion kg of fuel, assuming zero energy loss in burning the fuel. Relativistic rocket calculators are fun! reply pants2 6 hours agorootparentFun fact: if you got 250 MPG in a space car loaded up with as much gasoline as there is water in the ocean, you could could drive to the edge of the observable universe. reply jvanderbot 12 hours agorootparentprevWell that depends on the ejection velocity. If you could shoot it out at close to speed of light, you'd need much less. reply LoganDark 12 hours agorootparentIf you were to shoot it out at close to the speed of light, you'd knock the Earth out of its orbit. reply jvanderbot 10 hours agorootparentThat's silly. My flashlight shoots stuff at speed of light all the time. Mass matters. Shooting just enough mass at very high velocity is not much different than shooting a lot more mass at lower velocity, in terms of force. reply LoganDark 10 hours agorootparent> Mass matters. Exactly. You try accelerating 200kg up to anywhere close to the speed of light (say 80%). That is a lot of force. Technically even photons can exert force on objects, but they have such a small mass that it's a difficult effect to observe. reply jvanderbot 8 hours agorootparentThis is getting overly pedantic. Opening comment said that you'd need absurd amounts of mass to accelerate a person to near light speed. I said that the velocity of ejecting that mass mattered. That if you could push out mass at speed of light, you'd need a lot less mass. Not that you'd push out the same mass at speed of light. Or that you could arbitrarily push things out at speed of light. Sheesh. reply hotpotamus 10 hours agorootparentprevFrom memory, photons are massless, otherwise they could not move at light speed. They do have momentum though. reply eru 9 hours agorootparentPhotons have mass, but no rest mass. (Or something like that.) reply tsimionescu 2 hours agorootparentTypically momentum is thought as mass times velocity, and since photons do have momentum, there was a desire to give them some kind of \"relativistic mass\". In more recent times, it has been seen as easier to use just one concept of mass, and to redefine momentum entirely. So, photons have a mass of 0, and we don't need to specify \"rest mass\". But they do have momentum. reply scubbo 6 hours agorootparentprevMomentum but no mass, if I recall my physics correctly (low certainty). Wait, hang on, we have access to an appreciable-chunk of the world's knowledge at our fingertips... https://en.wikipedia.org/wiki/Photon - \"Photons are massless[...]In empty space, the photon moves at c (the speed of light) and its energy and momentum are related by E = pc, where p is the magnitude of the momentum vector p[...]Current commonly accepted physical theories imply or assume the photon to be strictly massless\" reply LoganDark 10 hours agorootparentprevOh, thanks for the correction. reply hwillis 2 hours agorootparentprevno, the earth is actually big. 47 trillion times heavier than that mass. At 90% c that 160 billion kg would still be a small fraction of the planets (moving 10,000x slower, at 30 km/s) kinetic energy. 500,000x less. Of course that .06 m/s velocity change would be near instant, so bad things would happen. Probably a humanity-ending but not life-ending disaster. Global tsunamis and incredibly large tectonic changes, for sure. Imagine the entire water column of the marianas trench jumping up in the air and slamming into the ground below. If the energy was transferred at a single point, it'll be the worst extinction event ever (4000x worse than chicxulub) but I'd bet single-celled and maybe even some multicellular life would survive. Anything bigger than a mouse is fucked, though. reply knodi123 12 hours agorootparentprevaim a bit to the left. reply mcswell 5 hours agorootparentSure, Han! reply fouc 11 hours agorootparentprevan ion thruster that shoots ions out at the speed of light probably won't affect Earth reply LoganDark 10 hours agorootparentYes because ions are... ions. You don't see photons knocking the planet out of orbit, do you? They can exert force but they don't exert that much force. But if you're trying to avoid self-propulsion and want to launch from Earth, say, even a 200kg craft, anywhere \"close to the speed of light\", then that will most probably require a significant enough amount of force to knock the planet out of orbit. reply eru 9 hours agorootparentNo, what makes you think so? If you can apply small force over a long time, that will get you up to speed, too. Someone did the math in the thread, and suggested that a constant 1g of acceleration would get you to the centre of the galaxy in 20 years (as measured by the clocks traveling on your spaceships). 1g of acceleration for 200kg is about 1962 Newton. (This back of the envelope calculation assumes you have eg someone fire a laser at your ship to give you the energy you need. If you need to bring your own fuel, the rocket equation increases the total mass needed. But the same principle still applies: something like an ion drive has very little force, even if the top speed it can reach can be enormous.) reply shadowgovt 12 hours agorootparentprev\"Sir Isaac Newton is the deadliest son of a bitch in space.\" reply pantalaimon 10 hours agorootparentprevImagine a generation ship, consuming the energy of an entire star for the trip. reply actionfromafar 10 hours agorootparentWe have one of those (stars)! Just need to build a parabolic reflector on one side of it and point it towards the opposite direction where we want to go. When the reflector shoots to far from the same, tilt the reflectors, drop down closer to the Sun by gravity, tilt them back, do it again. We could be going places in a few billion years! reply eru 9 hours agorootparentYes. And that's not the only way to make this work. Btw, the sun is also an extremely inefficient engine. With a bit of extra engineering we could probably scoop up hydrogen from the sun, and 'burn' it much more efficiently. reply tum92 5 hours agorootparentprevFun thought, we’re kind of all on one right now! Regardless of how you choose to define “human,” we’ve been around for much less time than a single revolution around the Milky Way. We get no say in the route, and our star is feeding us rather than fueling our travel, but still a wild thought. reply csomar 58 minutes agorootparentprevMy ship has a quantum shield that changes the location of incoming atoms; putting them just a bit to the safe side of the ship. Doesn't work with molecules though but that's coming up on v2. reply phist_mcgee 55 minutes agorootparentMusk is that you?? reply dylan604 10 hours agorootparentprevOr stopping. It takes the same amount of time to slow down as it did to speed up. Presumably, you'd have to rotate 180° so you are now thrusting in the opposite direction. So at the speeds you've reached to get there in 20 years (ship time), you'd just race on by. reply JumpCrisscross 10 hours agorootparent> takes the same amount of time to slow down as it did to speed up Assuming you're going somewhere, you can use atmospheres and gravity to slow down. Decelerating should take less time than accelerating in practical contexts. reply ithkuil 9 hours agorootparentThat is doable for \"normal\" speeds, not one where you accelerate 1G for twenty years, reach relativistic speeds that make you travel for hundreds of thousands of light-years in merely 20 years ship time reply JumpCrisscross 9 hours agorootparent> doable for \"normal\" speeds, not one where you accelerate 1G for twenty years It's still a lot of energy you can bleed off, particularly if you're aiming for a system with gas giants. I'm not suggesting one only rely on passive deceleration. But especially given it's fuel saved at the very end of the journey, fuel you no longer need to accelerate and decelerate for the entire duration of the trip, the savings could be sizeable. reply PaulDavisThe1st 9 hours agorootparentthe top of this thread is filled with a discussion of the almost unimaginably catastrophic consequences of a ship moving at 0.9C hitting atoms in interstellar space. trying to decelerate by \"braking\" anywhere close to a gravitionally significant mass sounds like a guarantee to total destruction from the impact of \"stuff\" (even individual photons). reply JumpCrisscross 8 hours agorootparent> a ship moving at 0.9C You decelerate from 0.9C to 50 km/s conventionally, more if you can aerobrake or line up multiple slingshots, and that last 0.00001% with gravity assist. It saves you more than that in fuel, because the fuel you'd have used on that last bit of deceleration needed to be accelerated and decelerated the entire way from 0 to 0.9C back to close to zero. reply eru 9 hours agorootparentprevIf you are going really, really fast, you wouldn't just want gas giant planets. You'd want the outer layers of red giant stars. reply chuckhend 6 hours agorootparentprevWe'd still be limited by however many Gs human body can handle right? reply dylan604 9 hours agorootparentprevRight, because space is known to be full of atmospheres to use to slow down. ??? reply JumpCrisscross 9 hours agorootparent> space is known to be full of atmospheres to use to slow down The places people talk about travelling to tend to have atmospheres and gravity, yes. reply antihipocrat 9 hours agorootparentHow many G's of deceleration are we talking here? I imagine even 2Gs of force wouldn't be tolerable for humans for more than an hour reply JumpCrisscross 8 hours agorootparent> even 2Gs of force wouldn't be tolerable for humans for more than an hour You can tolerate 2G for hours, particularly if everyone's oriented eyeballs in. That said, both aerobraking and gravity assists are intermittent accleerations. reply dylan604 9 hours agorootparentprevso you've been traveling at some large speed for quite some time, and you are now proposing to come to a near stop to come into orbit around some far away planet? and what magical tech have you forgotten to tell us about that allows that sudden deceleration to not liquefy the bags of meat inside the ship? reply Terr_ 6 hours agorootparentprevI wonder how fast the interstellar medium of gas etc. drifts and flows... could sacrificial sweeper-ships drill out a less-dense-holes for other traffic on a reasonable timescale? reply steffenfrost 8 hours agorootparentprevCouldn't you shoot an electron bream ahead of the ship to ionize the atoms and the deflect them with a magnetic field? reply bhickey 8 hours agorootparentBriefly: No. I read a paper on the topic a few years back. My recollection is that once you go faster than about 0.3c it becomes impossible to shed heat faster than you gain it from collisions with Helium. I'll try to dig it up. reply wholinator2 7 hours agorootparentI'm interested if that's physically impossible or just currently technologically impossible reply caturopath 11 hours agorootparentprevWhy not just increase power to the main deflector? reply qsi 7 hours agorootparentBecause you need to reverse the polarity first. reply otikik 12 hours agorootparentprevMy ship exterior hull is made of quadratic jergotrons, precisely to avoid that issue. reply mcswell 5 hours agoparentprevBut think of all the leave time I'd accumulate! reply alberth 6 hours agoparentprev> accelerate our spaceship at a mere 1G continuously Do you mean accelerate at 9.8 m/s^2 ? reply robofanatic 9 hours agoparentprevHow many years will it take to accelerate from normal speed to that speed and decelerate back? reply multiplegeorges 9 hours agorootparent10. Assuming a straight line and assuming 1G is your max acceleration: you accelerate for 10 years, reach your maximum velocity then flip and do the same thing in the other direction. You'll reach your destination with 0 velocity. reply EA-3167 12 hours agoparentprevIt's worth saying that 1G is heavy acceleration to maintain, nothing \"mere\" about it. When you run the numbers the amount of energy involved basically adds up to needing a rocket made entirely of antimatter, and a similar mass of 'normal' matter to react with. Keep in mind that when talking about long-distance journeys in space under any sort of constant acceleration, the numbers are generally in thousandths of 1G. reply slow_typist 12 hours agorootparentBut accelerating by 1 g is very convenient for the crew. No muscle and bone degeneration, no space sickness, etc. reply EA-3167 9 hours agorootparentIt would be cheaper in every sense to turn something like a giant asteroid into a rotating habitat ship than achieve a constant 1g to even the closest systems. Realistically interstellar travel is not a thing that (biologically modern) humans will ever be suited for, robotic probes don't need thousands of kg of food and water to stay alive, don't need artificial gravity, air, or entertainment. The fact that the trip is inevitably 1-way won't bother probes and robots either. reply eru 9 hours agorootparentYou are right. One addendum: many humans would be bothered by one-way trips, but humanity is large, and in absolute numbers there are still plenty of volunteers for one-way trips to the planets and stars. reply BHSPitMonkey 8 hours agorootparentAnd how many in that group are actually fit to spend many years living that lifestyle without losing their mind and getting into deadly fights with one another? And who's covering the great expense of building these generational colony ships and training their only inhabitants, only to have them zip away never to be heard from again? (With no benefit other than believing there's a slight chance we've succeeded in making our species multi-plantary)? reply eru 4 hours agorootparentAs humanity becomes more numerous and richer, the fraction of humanity you need that have such strange ideas and desire keeps shrinking. (Btw, I share your intuition that the number of people willing to sign up for a one-way trip to the stars, or even just Mars, is fairly low. However, if you already look at people who are dedicated enough to become astronauts, I suspect the additional filter of asking for one-way-trip volunteers for a mission to the stars isn't all that severe. My purely speculative guess is that at least 10-20% of current astronauts would be willing to sign up.) reply EA-3167 7 hours agorootparentprevWhen talking about how efficient a given reaction mass engine, such as a rocket, can be the unit is specific impulse in seconds. That unit represents how long a given engine carrying a given propellant can maintain 1g acceleration. For context, the most powerful chemical rockets peak around 450s-530s. A nuclear rocket of the sort we can build today would be more than twice that value, and super-efficient ion thrusters can have IspS in the tens of thousands of seconds. But we're talking about an engine with a specific impulse measured in decades, and as far as anyone knows that means having catastrophic amounts of antimatter. I don't think plucky explorers on a one-way trip are going to have access to a small moon's worth of antimatter, and if they did, imagine how many more interesting things they could do with it than fly to nowhere? reply vl 5 hours agorootparent>imagine how many more interesting things they could do with it than fly to nowhere? Like what? reply lostmsu 9 hours agoparentprevIt does not take much more years to the edge of the visible universe. reply EA-3167 9 hours agorootparentIirc to get to Proxima Centauri at a constant 1g would require a fairly impressive mass of antimatter, to continue to the edge of the observable universe would be so many more orders of magnitude more energy than that it's barely worth discussing. Even though we can't reach c, as we start to approach it the energy requirements rise catastrophically, along with the risk of colliding with some random mote of Hydrogen and remembering that your relative velocity is .99999c, in the moment before you and your ship are atomized. reply jcadam 10 hours agoparentprevCould use such a ship as a time machine (well, that only goes one way). reply daedalus_j 9 hours agorootparentThe Forever War novels have this as a key plot point, if you're interested in that sort of thing. reply Tostino 4 hours agorootparentThe whole Ender's game series also uses this as a plot device. reply tshaddox 10 hours agorootparentprevDo you mean that someone in the space ship could, without extending their own lifespan beyond what is already expected, use the space ship to \"travel\" to Earth's distant future? reply ithkuil 9 hours agorootparentPrecisely. That's the famous Twin \"paradox\" (which is not a paradox) reply hackerlight 10 hours agorootparentprevKip Thorne said it's theoretically possible. One end of the wormhole is on earth, the other is on the spaceship. Then you fly the spaceship and hop into the wormhole and arrive into the future on Earth. reply wholinator2 7 hours agorootparentYou don't even need the wormhole. You just accelerate away to relativistic speeds then turn around and come back. It doesn't matter which direction you're going, just that you're going _fast_. reply dtgriscom 7 hours agorootparentprevMy comfy chair is a one-way time machine. reply agos 25 minutes agorootparentprevobligatory XKCD: https://xkcd.com/209/ reply huytersd 9 hours agoparentprevTime travel seems so easy and we could do it with the tools we have now for the most part. Maybe we’ll never go into the past but relatively contemporary humans are going to be all over the future in all kinds of places. After the first time it happens people in the future can start to expect a human from the past to keep visiting every so often. reply tempestn 8 hours agorootparentIf that did start happening, it's not like the people from the past would just pop up suddenly. We would be aware of their journey. It's not like a time machine where someone just disappears from the past and appears in the future. reply huytersd 6 hours agorootparentSure, and we would probably be able to tell when they were from based on the approaching crafts. It’s going to be amazing to be able to step 50,000 years into the future to see how humanity has turned out. I’d give up anything to have a chance at that. reply lp4vn 3 minutes agorootparentIf you stop to think, a trip to the future is a trip to immortality because you can go to a time where the technology to live forever will be available. reply tempestn 6 hours agorootparentprevYou could always take a flier on cryonics. reply thatwasunusual 12 hours agoparentprevWe would also need to find a way to slow down. reply MagicMoonlight 12 hours agorootparentYou just turn around at the half way point reply notfed 11 hours agorootparentAt which point shielding gets even more complicated. reply PeterisP 1 hour agorootparentThis is already an unrealistic thought experiment, since continuous 1g acceleration for 20 years is so ridiculous that it requires a magic engine (i.e. consuming most of the ship mass in a matter-antimatter reaction) so if we're at it, we can also assume magic shielding which will also shield the crew from all that antimatter and its annihilation. It's not a coincidence that the original post relativistic spaceship doesn't even bother considering larger accelerations than 0.1g, since achieving even that is a wild assumption. reply timschmidt 10 hours agorootparentprevLess complicated. The rocket exhaust literally forms a plasma shield in front of the decelerating rocket. reply cooper_ganglia 10 hours agorootparentWell then, it's easy: Just always face the exhaust in that direction! It's not rocket science! reply JumpCrisscross 10 hours agorootparent> always face the exhaust in that direction! It's not rocket science! You don't see a problem with trying to accelerate with two exhaust streams at 180º to each other? reply ithkuil 9 hours agorootparentWhat if the front one is only a small fraction of the thrust at the rear? Would that be enough to \"clear the path\". Surely it would cost some efficiency but it may beat he alternative reply timschmidt 6 hours agorootparentWhipple shields [1] don't weigh much, and don't involve negative acceleration of any kind. 1: https://en.wikipedia.org/wiki/Whipple_shield reply cooper_ganglia 7 hours agorootparentprevIn a universe where every action has an equal and opposite reaction, why not make those reactions argue about it? reply senectus1 9 hours agorootparentprevwhat about for the period of time that you're travelling sideways with a largely unshielded broadside facing not exactly empty space? reply eru 9 hours agorootparentYou wouldn't literally turn around. You'd probably move your rocket engine over to the other side (or have both a front and back engine in the first place). Most of the mass of your spaceship will be fuel (like 90%+). You can use that as shielding. reply m3kw9 12 hours agoparentprevI wonder what is a safe acceleration to get to light speed for long periods without hurtin too much reply bee_rider 12 hours agorootparentYou can’t “get to” light speed, that’s one of the big punchlines in relativity. If you pick an acceleration equal to the acceleration we experience on Earth (aka 1g, aka ~9.8m/s^2), you hit relativistic speeds (speeds at which you need to take into account the effects of relativity to do anything) surprisingly fast. On the order of hundreds of days. So, it is not really a matter of safe acceleration on a long space trip. Instead you have to worry about the actual speed you are traveling at—even though space is very empty, there are still atoms floating around out there, and you’ll be moving at very high speeds relative to them, leading to interesting collisions. reply andrewflnr 7 hours agorootparent> that’s one of the big punchlines in relativity It's kind of funny that the actual big punchline is that light speed matters at all. There would be no meme of \"reaching lightspeed\" without relativity, despite that meme originating from relativity specifically mentioning lightspeed as something you can't reach. reply ryandrake 11 hours agorootparentprev> Instead you have to worry about the actual speed you are traveling at That's the other big punchline in relativity: There's no one \"actual speed\" because that implies that there is a single \"important\" frame of reference wherein those atoms are floating around waiting to be hit by a spaceship. reply eru 8 hours agorootparentOh, 'relativity' might not have a preferred speed. But our universe absolute does. It's the inertial frame of reference that makes the cosmic microwave background look most uniform. See https://en.wikipedia.org/wiki/Comoving_and_proper_distances#... > A comoving observer is the only observer who will perceive the universe, including the cosmic microwave background radiation, to be isotropic. Non-comoving observers will see regions of the sky systematically blue-shifted or red-shifted. Thus isotropy, particularly isotropy of the cosmic microwave background radiation, defines a special local frame of reference called the comoving frame. The velocity of an observer relative to the local comoving frame is called the peculiar velocity of the observer. reply acchow 11 hours agorootparentprevWhat if you define the \"important\" reference frame as the speed of light's (in the same direction you are going). Since c is universally constant, it seems like a reasonable privileged reference. reply carpdiem 10 hours agorootparentDoesn't really work this way. A lot of the wonkiness in SR is tied to the fact that the speed of light is the same, measured in _any_ reference frame. So, say you're on earth and you measure the speed of light... you find that it's c (~3x10^8 m/s). Now you get on a spaceship and accelerate to 0.5c with respect to earth, and you measure the speed of light relative to your spaceship... still c! In this way, you can't really define a reference frame with a speed \"the same as the speed of light\". And if you try, you'll run into nasty infinities in all your equations that will cause them to blow up and stop being useful. reply naikrovek 10 hours agorootparentSo depending on how you measure, you’re always stationary or moving near light speed, or somewhere in between, depending on your measurement reference (the thing you’re moving relative to)? How is there a speed limit at all, if that’s the case? You can accelerate to 0.5c and then toss an apple out the window and say you’re moving at the speed of an apple tossed out of the window, relative to the apple. You have all of c available as headroom again? You can accelerate up to 0.5c again, relative to the apple you tossed out the window? I am imagining you will say that it will seem like this is what is happening to folks in the spaceship, but what’s really happening is that time is slowing for the spaceship and it’s passengers, and that they still can’t reach c. Fine. But c relative to what? There is no absolute c because there are no truly fixed points, so c relative to what? reply pests 9 hours agorootparentThere is no underlying reference frame. All motion is relative. Everyone, no matter how fast they are already going, will measure the speed of light as c. Accelerate to .99c and shine a flashlight in front of you. That light is moving ahead of you at the speed of c. Because to you, you are not moving. reply eru 8 hours agorootparentThat's true for the laws of physics, yes, but our universe does have a 'natural' frame of reference. > A comoving observer is the only observer who will perceive the universe, including the cosmic microwave background radiation, to be isotropic. Non-comoving observers will see regions of the sky systematically blue-shifted or red-shifted. Thus isotropy, particularly isotropy of the cosmic microwave background radiation, defines a special local frame of reference called the comoving frame. The velocity of an observer relative to the local comoving frame is called the peculiar velocity of the observer. From https://en.wikipedia.org/wiki/Comoving_and_proper_distances#... reply stavros 9 hours agorootparentprev> You can accelerate to 0.5c and then toss an apple out the window and say you’re moving at the speed of an apple tossed out of the window, relative to the apple. You have all of c available as headroom again? You can accelerate up to 0.5c again, relative to the apple you tossed out the window? Yes you can. You can even do it with 0.6c for both those speeds. reply tempestn 8 hours agorootparentBut critically, having done that, you still won't be going >=1.0C relative to the road. reply stavros 1 hour agorootparentYep, exactly. reply gosub100 8 hours agorootparentprev> so c relative to what? it's either \"relative to any observer.\" or \"relative to any inertial reference frame\". no matter where you go (on the ship, on a planet you pass by, on another ship) you will never see the apple travel as fast as the photons coming out of your flashlight. Depending on where the observer is, they will see the apple accelerate to 0.5c (if they are aboard the ship) or they will see it gain mass (or rather, see you throw it more slowly as if it had gained mass), contract in the direction it's thrown, and slow down (due to time dilation...relative to the moving frame). The case I don't know how to answer is two apples thrown at each other, each with a speed greater than 0.5c. reply ryandrake 7 hours agorootparentIf you want to explore/understand the velocities of these relativistic apples, look into the Velocity-addition formula[1]. 1: https://en.wikipedia.org/wiki/Velocity-addition_formula reply richardw 11 hours agorootparentprevNot a physicist, but my impression is that you're always going 0 percent of the speed of light (in all directions) from your own frame of reference. All you notice is that our solar system is moving away, faster. I guess you'd notice a change in light frequency based on the light in front/behind. Redder behind, bluer in front. Edit: supposedly we can measure our speed compared to the cosmic microwave background which is fairly uniform, which gives us a value of 400 to 800km/s relative to the CMB: https://www.researchgate.net/post/How_can_we_practically_mea... reply eru 8 hours agorootparentSee also https://en.wikipedia.org/wiki/Comoving_and_proper_distances#... reply Koshkin 10 hours agorootparentprevIn short, a reference frame moving at c is pretty much a logical absurdity, because by definition it would mean having massive objects move at c as well. reply bee_rider 10 hours agorootparentprevI’m not sure I’d call that a punchline of relativity; the idea of frame of reference is also part of the classical model. reply tshaddox 10 hours agorootparentRelativity (the fact that the laws of motion are the same in all inertial frames of reference) is itself a crucial part of Newtonian mechanics, except that Einstein's theories of relativity were such a big deal that we now tend to reserve the word \"relativity\" for his stuff, and call the old thing \"Galilean invariance\" or similar. reply whimsicalism 10 hours agorootparentprevdumb question - why does going faster make it more likely you encounter fast protons? couldn’t protons in any reference frame be going quite fast relative to you? reply elihu 8 hours agorootparentNah, most of the random atoms floating around in space are going to be travelling very roughly as fast as the things (stars, planets, etc..) around them -- because anything travelling much faster is likely to eventually bump into something and lose some of its momentum. There is the occasional weird exception though: https://en.wikipedia.org/wiki/Oh-My-God_particle reply eru 8 hours agorootparentprev> couldn’t protons in any reference frame be going quite fast relative to you? By the laws of physics, yes. But most of the stuff in our universe, and definitely in our galaxy, tends to move roughly at the same speed. See https://en.wikipedia.org/wiki/Comoving_and_proper_distances#... reply zabzonk 10 hours agorootparentprevnot so much protons (which would be a problem, but could at least notionally be deflected), but atoms. reply actionfromafar 10 hours agorootparentAn hydrogen atom and a proton are roughtly the same thing, right? reply zabzonk 10 hours agorootparentno a proton is a hydrogen nucleus (or at least can be seen as one) and has a charge. travelling near lightspeed you would have to worry most about uncharged atoms/molecules (because of their mass) and neutrons, neither of which can be deflected. reply monocasa 10 hours agorootparentprevA proton is a hydrogen ion and isotope. reply jtriangle 12 hours agorootparentprev~9.8 m/s sounds pretty comfortable. reply caymanjim 10 hours agorootparentYou're accelerating at 9.8m/s^2 toward your chair right now, so it depends on how comfortable the chair is. reply jtriangle 7 hours agorootparentBold of you to assume I'm not standing on a Uline rubber anti-fatigue mat reply jonplackett 0 minutes agoprevAm I the only one disappointed this isn’t a link to a real relativistic spaceship? reply dcanelhas 1 hour agoprevIn case you're interested in these kinds of relativistic effects, there is a toolkit called OpenRelativity http://gamelab.mit.edu/research/openrelativity/ that you can use, for your simulated near-luminal speed graphics. It's used by the (free) game \"A Slower Speed of Light\". http://gamelab.mit.edu/games/a-slower-speed-of-light/ reply A_D_E_P_T 12 hours agoprev~850 years of ship time at max acceleration and the universe is 10^30 years old. At this point, only white dwarfs, neutron stars, and various stellar remnants remain. Galaxies have dissipated, and stars like our Sun are a distant memory. (If any still exist to remember them. Which is, I'll add, not out of the question. Life can cling to structures built around black holes, white dwarfs, etc., and extract energy from those bodies for a very long time.) We're a long, long way from \"heat death\" -- from the Universe becoming an undifferentiated entropic sea of particles -- but it is already a very different place. Puts things in perspective. reply CobrastanJorji 9 hours agoparentYou could imagine a technically advanced society using it as a sort of penal death sentence. \"You were not safe around our people, so we are sending you to the end of time.\" reply trenchgun 57 minutes agorootparentVernor Vinge, Across the Realtime trilogy reply goblinux 9 hours agorootparentprevIsn’t that the plot of Skyrim? reply PerryCox 3 hours agorootparentIn Skyrim they didn't send Alduin into the end of time, just into the future (also there is going to be an Elder Scrolls VI so V can't be the end of time, but will likely be the end of the fifth era). It was one of the reasons that the Felldir the Old was not onboard with the plan to use the Elder Scroll on Alduin. They didn't know how far into the future he would be sent. Most people on Nirn at the time of Skyrim didn't believe that dragons were real, much less Alduin who signals the end times. The Dragonborn ultimately ends up defeating Alduin, but because Alduin is immortal (in a way that the other dragons are not) he will return at a time deemed by his father Akatosh and actually destroy all of existence in that universe. Going back to your original point it's a little different than sending him to the end of the universe, they sent him forward in time, but they actually had no idea how far or where there were sending him. reply anonyfox 1 hour agorootparentthe unrealistic part of the whole narrative is: in that distant future he returns, another \"hero\" might step up and just kill him again, so he can't just \"destroy all existence\", or even Tamriel after some hundreds of years has modern/advanced military tech and will just obliterate a spawning dragon completely. If something can be \"killed\" by a dude with an axe, it ain't a world-ending superpower for me. I get that Alduin could harass the known world by eating people or burn down villages if left unchecked, but \"end of the world\" for me is kinda different scale. reply noduerme 21 minutes agoprevSo, this does seem to take the angle I'm flying at into account. If I'm accelerating to 99.9% the speed of light, and I yaw 180deg the view, I start \"decelerating\". What happens if I keep maximum acceleration and pitch up 90deg? The software seems to keep flying on the original vector. Is this a bug or is it intended to be a simulation of how light would behave under those circumstances? reply AlexAndScripts 12 hours agoprevI had no idea you could achieve relevant amounts of time dilation so \"easily\" with relatively small (1m/s) of constant thrust - such that interstellar travel becomes somewhat viable provided you can continuously accelerate for the entire trip. Googling it, it would take approximately three years of observed time for a traveller to get to alpha centauri at 1g. Could any somewhat-plausible technologies (fusion etc) get us to that point? I don't know how to do relatavistic maths, but it seems that directly converting mass to energy and ignoring relatavistic effects requires 50 000kg to accelerate 100 000 kg (with a constant relationship, as the C^2 cancels out) to the speed of light. reply MilStdJunkie 12 hours agoparentOne gee over the course of months is insane. Even if you converted the entire \"fuel\" reaction mass directly into momentum, you're still carrying tens or hundreds of thousands of tons of fuel for any remotely habitable spacecraft. And no engine has perfect mass conversion. Matter-Antimatter has been simulated to be maybe sixty percent efficient, fusion is around 17%, nuclear pulse propulsion a surprising 7%, fission nuclear gas rockets might max out at 12% but those numbers are dodgy as we don't have sharp numbers on gas core reactors. As an SF writer, it's pretty interesting, though, to think of the weird shapes a society would take when your astronauts are outliving entire civilizations. I imagine a sort of neo-Polynesian culture, with travellers never quite knowing how the place will look if they ever come back that way. reply knodi123 12 hours agorootparentIn the book series The Expanse, that was pretty much the only unrealistic technology that the humans had, which allowed them to colonize the solar system. Sure, there was some might-as-well-be-magic alien stuff later in the book, but by page 1, humans have colonized the solar system, purely with a hand-wavy engine that can generate sustained thrust without needing tons of reaction mass and without turning your exhaust port into an unimaginable hell cannon. reply MilStdJunkie 9 hours agorootparentI'm going to embarrass myself horribly here, but I've only seen the series, so I'm not a hundred percent clear on how much acceleration they're pulling in cruise[1]. If it's something like .3 g then they're fairly close[2] to the limits of something like a fusion pulse drive (tiny nodules of deuterium or whatever, ejected out the back of the ship, then lasered into fusing, then the reaction pushes on the whatever - magnetic field, pusher planet, etc). That would make the solar system something more like what the Atlantic Ocean was in the days of sail. They'd need refuels every stop though. Like with early coal fired steamers back in the day. I got a funny feeling that without much better genetic muckety muck, the hard limit will be the human organism itself. Someone will get to the stars = if we don't screw everything up - but the someone won't be human, or maybe nothing like human. [1] I know in emergencies they pull mad g, but it doesn't seem like something they keep up for long. Would still burn through their deuterium in no time though. [2] Like, within an order of magnitude or two. reply Eddy_Viscosity2 9 hours agorootparentThe ships cruise anywhere from 0.3 to 1G, the lower end mainly for comfort of people who grew up in space. But, the fictional drive is so efficient it could sustain 10s of G for extended periods (weeks, months). reply moron4hire 10 hours agorootparentprevNo, the exhaust port definitely was an unimaginable hell cannon. The characters spoke several times about slagging a ship or a surface base in their drive plume. reply knodi123 9 hours agorootparentOh, I missed that! Seems like those drives ought to have been more carefully regulated then. reply caust1c 8 hours agorootparentCool detail about that in the Nauvoo launch sequence, slagging the scaffolds / gantries / whatever the construction exoskeleton is. https://youtu.be/0KZRFIdbJzc?t=147 reply neaden 11 hours agorootparentprevEh, there is a ton of unrealistic technology in book 1, the stealth ship for instance is impossible. By the authors own words they don't think of the books as being Hard Sci-Fi, harder then Star Trek sure. reply mplewis9z 10 hours agorootparentWhat makes you think the stealth ship is impossible? They explain the concept pretty well in the first book: extensive cooling systems to soak up waste heat, large liquid tanks to store that heat internally for a while, and radar-absorbing coatings. We literally have all of those pieces today, it’d just cost unfathomable amounts of money to build with our current technology. As a bonus, they even talk about the radar-absorbing coating not being perfect, and being able to detect the stealth ship as an object a few Kelvin above the background radiation when they pumped their radar into it. reply fredthedeadhead 2 hours agorootparentProject Rho gives several compelling reasons why there ain't no stealth in space https://www.projectrho.com/public_html/rocket/spacewardetect... reply mplewis9z 2 hours agorootparentI don't know when that was written, but it definitely feels like The Expanse authors read that exact page and built their stealth system to address those points - the stealth ships in the books aren't permanently stealthy (they have to radiate their heat from the internal heatsinks after some amount of time, seemingly on the order of months), and are immediately detected when they light up their engines (and hence coast until they reach their destination). The main characters also manage to find a stealth ship after coming across coordinates to it - it was parked and completely offline (and unmanned) in the orbit of a small asteroid, which would further obscure any signature it might give off. reply ryandrake 12 hours agorootparentprev> As an SF writer, it's pretty interesting, though, to think of the weird shapes a society would take when your astronauts are outliving entire civilizations. I guess this all depends on how you define simultaneity. Say I got on a relativistic rocket traveling near c and colonized Planet X in 10 years ship time and say 20,000 years Earth time. I put up my TV antenna as soon as I land, and I'd still be receiving Earth transmissions from approximately 10 years after I left, no? So even though civilization is long gone from Earth's point of view, from my point of view, I can keep up with the latest news as if I were still living there. So from my point of view I did not outlive anything. If I were to go back, yes, everything would be gone. reply sophacles 10 hours agorootparentThat's not how it works. If the planet is N light years away from earth, the transmissions you receive would be those sent 20000-n years ago. along the way you'd get most of the messages sent during the 20k years as very red-shifted light, and extremely rapidly from your pov. reply BoiledCabbage 8 hours agorootparentI think you may have that wrong (If I'm understanding you correctly). If you traveled at the speed of light then you'd be at the planet in 0 time your time, and you would arrive with the first of the broadcasts over those 20k years. So once on the planet you'd get to watch all 20k years of broadcasts. If you traveled at 1/2 the speed of light (not focusing on your dilation for the moment), then you'd still beat 50% of the transmissions and have 10k earth years of broadcasts to watch. I think the question is what % of the speed of light is a gamma factor of 20k/10 = 2000. That's something like 99.9999999% of the speed of light. Meaning you would get there before 99.99999% of the broadcasts had arrived and you'd be able to watch just about all of them in real time over the next (just less than) 20k years. Assuming those two planets are roughly in the same reference frame, the only way 20k years could pass on earth w.r.t. your arrival is if the destination planet is 20k light years away. If the destination planet is moving relativistically away from earth at an appreciable percentage of the speed of light then I couldn't say what the math would be. Maybe still the same, maybe not. reply hakuseki 3 hours agorootparentAre you planning to decelerate by crashing into the planet at relativistic speed? reply cypherpunks01 12 hours agorootparentprevWhile traveling near c, I believe you'd be receiving Earth transmissions from approximately the same time you left, Earth clocks would appear to slow down to a crawl. But if you land on another planet and change reference frame to be more \"stationary\" again relative to Earth, I think a massive amount of Earth time would suddenly appear to have elapsed very quickly during the process of slowing/landing because of the huge shift in simultaneity. reply ryandrake 12 hours agorootparentPretty sure only those 10 ship years worth of transmissions would suddenly appear. You're still 20K light years away so the rest of those years' transmissions are still in flight. reply cypherpunks01 11 hours agorootparentHmm I suppose you're right. I guess you'd see very few transmissions during the journey due to time dilation, and then those 10 years would arrive relatively quickly when slowing/stopping? I was thinking of this being the first half of the twin paradox, but perhaps for the apparent \"time gap\" in the spacetime diagram to appear, it's necessary for the traveling twin to turn and head back towards Earth quickly to shift simultaneity plane back in the other direction. reply slow_typist 11 hours agorootparentprevThere is no payback day in time dilation. reply agent281 8 hours agorootparentprevThat's basically the plot of the Forever War. When you drop out of hyper drive (or whatever they called it) you never know if you are going to be battling a ship from your future or your past. The very society that you fight for is completely alien. It's incredibly alienating. reply marmaduke 1 hour agorootparentprevWhat do you think about the gravity well \"drive\" in three body problem trilogy? I thought it was fairly clever, especially given the stories describing it beforehand (maelstrom iirc?) reply EvanAnderson 11 hours agorootparentprev> I imagine a sort of neo-Polynesian culture This makes me think of the Quen Ho in Vernoe Vinge's \"Zones of Thought\" universe. reply perardi 9 hours agorootparentprevHave you read Tao Zero? https://en.wikipedia.org/wiki/Tau_Zero Classic hard sci-fi. A colony ship’s Bussard ramjet has a glitch, and it cannot stop accelerating—and basically forever, given time dilation. reply Teever 12 hours agorootparentprevWhat if you didn't carry the fuel? Use stationary lasers from your starting point to power your journey half way until you lasers from your destination to slow your craft down. reply cypherpunks01 12 hours agorootparentI think the perceived output from stationary lasers on Earth would appear to decrease as your speed increases, since you're accelerating away from the laser photon packets. Because of that behavior, I'm not sure it's a feasible way to get up to relativistic speed? I think the lasers would also need ~10,000 years of fuel, as opposed to ~10 years of fuel if you could somehow figure out how to carry it. But the energy to sustain in either case is probably measured in Dyson spheres, or some fraction of all energy in the universe pretty quickly too. reply PeterisP 1 hour agorootparentTime dilation also has an effect, since you're receiving 10000 Earth-years of laser energy over 10 ship-years. reply MilStdJunkie 9 hours agorootparentprevThat's the drive of the eponymous generation ship in Kim Stanley Robinson's Aurora. It sends a mirror ahead of itself, then the Sol-Mercury lasers bounce off the mirror, back on the ship to slow it down. I could see the light spacecraft with their matter-antimatter engines laying down \"lightways\", like railroads in the old west. Once a lightway is established, then it's much less of a big deal to get from system to system. Apart from the tens of thousands of years in subjective time, of course. reply pc86 12 hours agorootparentprevOf all the dangers associated with spaceflight it's a pretty interesting concept to add \"lasers at the origin shut off for whatever reason\" and \"lasers at the destination never turn on / are misaligned / turn on too soon / turn on too late\" to the list. Not sure I'd want to be in a spacecraft careening through the cosmos with no realistic way to slow it down. reply jandrese 11 hours agorootparentThere is also the question of how you get the lasers to your destination in the first place. reply MilStdJunkie 9 hours agorootparentSend a mirror ahead, bounce the beam back toward the ship to push it backwards. Loses a lot of efficiency, though. Laser propulsion, a lot of the thrust is coming from ablation of the surface. reply eru 8 hours agorootparentHow do you 'send a mirror ahead'? Do you want it to stop, or just keep flying away indefinitely? reply MilStdJunkie 8 hours agorootparentYep, throwaway mirror, it goes off to wherever once it's done bouncing light back at your ship. Again, much less efficient, so when you get where you want to go, you'd want to put in a laser station there too. reply Teever 10 hours agorootparentprevUse lasers for the first half of the journey to send a rocket that can decelerate and build the laser station at the destination. reply NotYourLawyer 12 hours agorootparentprevThe farther you get, the dimmer the laser gets. The faster you get, the less energy each photon has. reply slow_typist 11 hours agorootparentNote that the 2nd statement only applies because of the Doppler effect - energy of the photon is a function of its frequency. reply AnimalMuppet 12 hours agorootparentprevCan you explain why matter-antimatter only has 60% efficiency? reply mikeyouse 11 hours agorootparent> This is the primary reason for selecting the annihilation of a proton (p+) and antiproton (p–-); the products include neutral and charged pions (πo, π+, π-), and the charged pions can be trapped and directed by magnetic fields to produce thrust. However, the pions produced in the annihilation reaction do possess (rest) mass (about 22% of the initial protonantiproton annihilation pair rest mass for charged pions, 14% for the neutral pions), so not all of the protonantiproton mass is converted into energy. This results in an energy density of the proton-antiproton reaction of \"only\" 64% of the ideal limit, or 5.8x1016 J/kg. I love that someone wrote and published a serious paper where the end design involved first stage thrust of 550 million ft-lbs and the total ship weighs something like 17 million metric tons and if I'm reading page 26 correctly, the payload on the ship has to be 7,500 kilometers from the ignition source to survive. https://www.relativitycalculator.com/images/relativistic_pho... reply c12 1 hour agorootparentprevWhile there may be a 100% anilation with matter-antimatter reactions the resulting thrust is not perfectly efficient due to energy consumed as the rest mass of charged and uncharged pions, energy consumed as the kinetic energy of the uncharged pions (which can't be deflected for thrust); and energy consumed as neutrinos and gamma rays. I'm unsure if the resulting efficienty is 60% however, not all of the energy produced in the anilation is converted to \"stuff\" that is useful for thrust. reply JumpCrisscross 12 hours agorootparentprev> Can you explain why matter-antimatter only has 60% efficiency? We don’t know how to use all the reaction products for thrust [1]. [1] https://en.m.wikipedia.org/wiki/Electron–positron_annihilati... reply darreninthenet 11 hours agoparentprevEven the GPS satellites have to take into special relativity - they have to correct for a tiny amount of time per day due to time dilation causing the moving clocks on the satellites to tick slightly slower than the stationary ones on Earth. reply Koshkin 10 hours agorootparentCuriously, general-relativistic effects needed to be accounted for as well. Quoting Wikipedia, GPS “must account for the gravitational redshift in its timing system, and physicists have analyzed timing data from the GPS to confirm other tests. When the first satellite was launched, some engineers resisted the prediction that a noticeable gravitational time dilation would occur, so the first satellite was launched without the clock adjustment that was later built into subsequent satellites. It showed the predicted shift of 38 microseconds per day. This rate of discrepancy is sufficient to substantially impair function of GPS within hours if not accounted for.” reply ianburrell 12 hours agoparentprevIt isn't possible without a magic reactionless drive; it might even require a zero-energy drive since the kinetic energy is huge and needs to come from somewhere. The rocket equation kills you. A reasonable fusion rocket would require an enormous (like an entire planet worth) to continuously accelerate to relativistic speeds. Antimatter drives are the only option and still require large amounts of reaction mass since have to absorb the energy to throw it out the back, or use a laser. reply nabla9 11 hours agorootparentYou need to get around the rocket equation. > we estimate the neutral hydrogen density in the unperturbed local interstellar medium of 0.195 ± 0.033 cm−3 https://iopscience.iop.org/article/10.3847/1538-4357/abb80a You need a hydrogen 'scoop' and fusion. If you can accelerate to 0.01c, you can collect enough hydrogen for 1000 MW fusion power from 32 km2 (6 km diameter) scoop area. Faster you fly, more you get. You can accelerate until interstellar particles start to do real damage. reply eek2121 11 hours agorootparentprevWell the obvious solution would be to figure out a mechanism to capture the particles that bombard your ship and figure out a way to turn those particles into thrust so you don’t need to take a bunch of fuel with you, which I get it, is another hard problem to solve, but maybe not impossible. We have done some incredible things before. reply qayxc 11 hours agorootparentThe good old Bussard Ramjet. Problem is, recent calculations showed that it's not viable - even for a Kardashev Type II civilisation [1] [1] https://www.sciencedirect.com/science/article/pii/S009457652... reply throwaway11460 11 hours agorootparentIt's not viable to use it to visit the galactic center during a lifetime, but it still flies, if I understand that correctly? reply qayxc 9 hours agorootparentTheoretically it works, yes, though not nearly as well as initially thought. The engineering and the required materials, however, are still questionable and way beyond our current understanding of physics and material science. It's a similar story for solar sails, unfortunately, though progress is being made in that area. Personally, I think that's the only realistic way of interstellar travel given our current knowledge of physics and engineering. reply Workaccount2 12 hours agoparentprevEven if you can figure out the problem of thrust, you still have to deal with particles slowly swiss-cheesing your ship. And even beyond that, you either witness the ships leaving and never hear back or you embark on one and comeback to whatever Earth is in thousands of years from now. reply phire 5 hours agoparentprevThings get more insane the further you go. After an observed 12 years of constant 1g acceleration, you will be 113,000 lightyears from your point of departure, which is enough distance to cross from earth to the opposite side of our galaxy. Of course, you are now traveling at 99.999999996% of the speed of light. If you actually wanted to stop at the other side of the galaxy to take a look around, you would need to turn around at the halfway point to decelerate, which roughly doubles the travel time. reply galangalalgol 5 hours agorootparentIs there any relativistic bonus that makes deceleration easier? Does it take less energy to go from 0.999C to 0.99C than to go from 0.009C to 0C? reply phire 4 hours agorootparentAcceleration and Deceleration are symmetrical. It takes the same amount of delta-v to accelerate between up to 0.999c as it takes to decelerate all the way back down to 0. Though as you burn fuel your ship gets lighter and the actual energy usage to maintain that constant delta-v of 1G will go down. As for the energy used to accelerate from 0C to 0.009C compared to 0.99C to 0.999C, I'm not sure. I know the time taken (from an external reference frame) changes, but part of me suspects the total energy stays the same and the difference in time taken is caused entirely by time dilation. However, I suspect I might be messing up reference frames, I don't actually know the equations. reply JumpCrisscross 12 hours agoparentprev> Could any somewhat-plausible technologies (fusion etc) get us to that point? Nuclear thermal or nuclear pulse propulsion. No fusion needed. reply ben_w 12 hours agorootparentFor practical values, nuclear pulse propulsion would only get you up to a few percent of the speed of light. The best nuclear thermal, gas core, would give you 7000 seconds[0]. A \"dusty plasma\" rocket (suspend the nuclear fuel in dust form in a magnetic field) might get 100,000 seconds, or just over a day of accelerating at 1g. [0] for the benefit of non-space nerds: the unit of measure is \"lb-force seconds per lb-mass of fuel\", which is kinda like \"seconds at 1g\" if the fuel is a very small fraction of the total mass, which it really won't be in a practical rocket. reply ninkendo 10 hours agorootparent> which is kinda like \"seconds at 1g\" if the fuel is a very small fraction of the total mass, which it really won't be in a practical rocket. I think you mean “a very large fraction of the total mass”… generally the best efficiency comes if your fuel mass fraction is high, as it means there is little overhead of things in your spacecraft of things that are not fuel (the mass of the engine, etc) reply ben_w 9 hours agorootparentNo, I mean small, because I'm talking about the quality of the approximation not the way to maximise delta-v. If you have 1 gram of fuel and a 1 ton payload and that fuel has 1e6 seconds of Isp, you can accelerate the ship for 1 second at 9.8m/s/s. If you have 1 ton of fuel and a 1 gram payload and the same fuel and burn at 1 gram/second, the first second is mostly spent accelerating the fuel, which means you're no longer able to just approximate the Isp as \"seconds at 1g\" in a nice linear fashion — it starts off at 1 gee in this example, but ends up at 10^6 gee in the last moment, a million seconds later. reply mattclarkdotnet 8 hours agorootparentprevg-seconds then? That seems like a very handy unit reply Dylan16807 5 hours agorootparenthttps://en.wikipedia.org/wiki/Specific_impulse reply ianburrell 12 hours agorootparentprevNuclear thermal or pulse, fission or fusion, aren't enough for interstellar relativistic speeds. They have way too low specific impulse. They don't even have enough for constant acceleration inside the solar system unless the acceleration is really low or the fuel ratio is huge. reply JumpCrisscross 12 hours agorootparent> unless the acceleration is really low or the fuel ratio is huge You’d need kilotons of nuclear fuel and a 10^3 fuel ratio. But that’s plausible. The economically-plausible answer is antimatter, where the ratio stays in the single digits and starts permitting deceleration. But I wouldn’t call that technologically plausible at this time. reply floxy 12 hours agoparentprev\"Roundtrip Interstellar Travel Using Laser Pushed Lightsails\" https://ia600704.us.archive.org/view_archive.php?archive=/24... \"A one-way interstellar flyby probe mission uses a 1000 kg (1-metric-ton), 3.6-km-diam. lightsail accelerated at 0.36 m/s2 by a 65-GW laser system to 11% of the speed of light (0.11 c), flying by a Centauri after 40 years of travel. \" \"...The third mission uses a three-stage sail for a roundtrip manned exploration of e Eridani at 10.8 light years distance.\" reply qayxc 11 hours agorootparentHoly cow! I just read the energy requirements of that third mission. Total electricity generation capacity of the entire world is about 12TW today [1], whereas that 3rd mission would require a \"formidable\" - as the author admits - 45,000TW at least. A mere three orders of magnitude more :) [1] https://www.statista.com/statistics/267358/world-installed-p... reply Keyframe 12 hours agoparentprevas far as we understand, you have to eject mass in order to move there. pick your choice in that regard. reply 82 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The page allows users to interact with a relativistic spaceship and adjust its acceleration.",
      "Users can view various measurements such as distance, Doppler factor, ship time, and world time on the page.",
      "The page, created by Dmytry Lavrov, has a theme centered around brightness and acceleration."
    ],
    "commentSummary": [
      "The discussion covers various topics related to space travel and the challenges associated with it, including limitations of accelerating a spaceship to visit the center of the Milky Way and potential damage from interstellar particles.",
      "Topics also include the use of fuel as a shield, feasibility of using kinetic energy for propulsion, and density of atoms in space.",
      "The conversation explores the concept of space as a weapon, potential destructive power of advanced space drives, concept of time travel, feasibility of interstellar travel, effects of acceleration on the human body, and potential risks and limitations of navigating at high speeds in space."
    ],
    "points": 750,
    "commentCount": 344,
    "retryCount": 0,
    "time": 1707163667
  },
  {
    "id": 39263854,
    "title": "Atopile: Designing Circuit Boards with Code",
    "originLink": "https://news.ycombinator.com/item?id=39263854",
    "originBody": "Hey HN! We are the founders of atopile. We’re building a tool to describe electronics with code. Here is a quick demo: https:&#x2F;&#x2F;youtu.be&#x2F;7-Q0XVpfW3YCould you imagine the pain of building an entire software product using only assembly code? That’s about how we felt designing hardware. We don’t currently have good ways to describe what we need, reuse existing designs and compile that description down to a product.We started atopile to fix this. atopile is an open-source language and toolchain to describe circuits with code. The compiler is here: https:&#x2F;&#x2F;github.com&#x2F;atopile&#x2F;atopile Docs are here: https:&#x2F;&#x2F;atopile.io&#x2F;getting-started&#x2F; . For a detailed deep dive designing an ESP32 module, see this video: https:&#x2F;&#x2F;youtu.be&#x2F;eMWRwZOajdQWe realized this was a problem in our previous jobs. Narayan and I (Tim) had to manually, draw and export all our electronic circuit boards. This lasted until our friend Matt, a software engineer, showed us his development workflow. All his projects were built, tested, and merged automatically via GitHub. So we asked: Can we build the same for hardware?We observed that the ability to abstract electronics effectively hinged on using a language to describe the requirements, so we came up with the “ato” language. In ato, you can break down circuits into modules, components and interfaces. You can nest and connect those blocks with each other. Here is an example with an RP2040 microcontroller: import RP2040Kit from \"rp2040&#x2F;RP2040Kit.ato\" import LEDIndicatorBlue from \"generics&#x2F;leds.ato\" import LDOReg3V3 from \"regulators&#x2F;regulators.ato\" import USBCConn from \"usb-connectors&#x2F;usb-connectors.ato\" module Blinky: micro_controller = new RP2040Kit led_indicator = new LEDIndicatorBlue voltage_regulator = new LDOReg3V3 usb_c_connector = new USBCConn usb_c_connector.power ~ voltage_regulator.power_in voltage_regulator.power_out ~ micro_controller.power micro_controller.gpio13 ~ led_indicator.input micro_controller.power.gnd ~ led_indicator.gnd led_indicator.resistor.value = 100ohm +&#x2F;- 10%From there, the compiler produces a netlist that describes how the circuit is connected and selects jelly-bean components for you (https:&#x2F;&#x2F;atopile.io&#x2F;blog&#x2F;2024&#x2F;01&#x2F;31&#x2F;cloud-components&#x2F;). Our next focus will be to add layout reuse, mathematical relations between values and define circuits by traits (similar to Rusts’).At the moment, atopile is intended to design all types of printed circuit boards (PCB) with low to medium complexity. The circuit complexity that the compiler can handle will steadily increase until it becomes suited for production usage. We often get asked if the compiler is meant for chip design rather than PCBs, but that is not the case. The language is exclusive to PCBs. At least for now..!A big part of why the software community is so prolific is thanks to open source and open core technology. The ability to share software packages with each other and efficiently chain tools together has made the software world an awesome place for developers. As hardware engineers, we would love our field to benefit from this as well. That’s why we’ve made atopile’s core open source (Apache 2.0). We plan to generate revenue by selling entreprise targeted features, similar to GitLab.We would love to have your thoughts on the compiler! What’s your story in electronics? What would you want us to build?",
    "commentLink": "https://news.ycombinator.com/item?id=39263854",
    "commentBody": "Atopile – Design circuit boards with code493 points by Timot05 16 hours agohidepastfavorite250 comments Hey HN! We are the founders of atopile. We’re building a tool to describe electronics with code. Here is a quick demo: https://youtu.be/7-Q0XVpfW3Y Could you imagine the pain of building an entire software product using only assembly code? That’s about how we felt designing hardware. We don’t currently have good ways to describe what we need, reuse existing designs and compile that description down to a product. We started atopile to fix this. atopile is an open-source language and toolchain to describe circuits with code. The compiler is here: https://github.com/atopile/atopile Docs are here: https://atopile.io/getting-started/ . For a detailed deep dive designing an ESP32 module, see this video: https://youtu.be/eMWRwZOajdQ We realized this was a problem in our previous jobs. Narayan and I (Tim) had to manually, draw and export all our electronic circuit boards. This lasted until our friend Matt, a software engineer, showed us his development workflow. All his projects were built, tested, and merged automatically via GitHub. So we asked: Can we build the same for hardware? We observed that the ability to abstract electronics effectively hinged on using a language to describe the requirements, so we came up with the “ato” language. In ato, you can break down circuits into modules, components and interfaces. You can nest and connect those blocks with each other. Here is an example with an RP2040 microcontroller: import RP2040Kit from \"rp2040/RP2040Kit.ato\" import LEDIndicatorBlue from \"generics/leds.ato\" import LDOReg3V3 from \"regulators/regulators.ato\" import USBCConn from \"usb-connectors/usb-connectors.ato\" module Blinky: micro_controller = new RP2040Kit led_indicator = new LEDIndicatorBlue voltage_regulator = new LDOReg3V3 usb_c_connector = new USBCConn usb_c_connector.power ~ voltage_regulator.power_in voltage_regulator.power_out ~ micro_controller.power micro_controller.gpio13 ~ led_indicator.input micro_controller.power.gnd ~ led_indicator.gnd led_indicator.resistor.value = 100ohm +/- 10% From there, the compiler produces a netlist that describes how the circuit is connected and selects jelly-bean components for you (https://atopile.io/blog/2024/01/31/cloud-components/). Our next focus will be to add layout reuse, mathematical relations between values and define circuits by traits (similar to Rusts’). At the moment, atopile is intended to design all types of printed circuit boards (PCB) with low to medium complexity. The circuit complexity that the compiler can handle will steadily increase until it becomes suited for production usage. We often get asked if the compiler is meant for chip design rather than PCBs, but that is not the case. The language is exclusive to PCBs. At least for now..! A big part of why the software community is so prolific is thanks to open source and open core technology. The ability to share software packages with each other and efficiently chain tools together has made the software world an awesome place for developers. As hardware engineers, we would love our field to benefit from this as well. That’s why we’ve made atopile’s core open source (Apache 2.0). We plan to generate revenue by selling entreprise targeted features, similar to GitLab. We would love to have your thoughts on the compiler! What’s your story in electronics? What would you want us to build? addaon 13 hours agoUnless I'm missing something, this is not circuits-as-code, it's just circuits-as-text. It's basically a non-standard way to represent a netlist, and to hang metadata off that netlist -- which is, to be fair, quite cool and useful. But take the example from [0] of a voltage divider. I agree that that is a textual description of a voltage divider that can be compiled to a netlist, a BOM, etc. But what is the actual division properties? What's the combined tolerance stackup? What I /want/ to be able to do is define a module generator function that takes a ratio, a desired output tolerance, and a maximum output current and generates the divider module with resistors chosen (both resistance and tolerance) that will meet those properties. And while I'm wishing, given that (for low output currents) this is an underdefined problem, I'd also like a way to lean towards components already in the BOM, either by just manually using preferred values (yuck), or by outputting multiple possibilities and having a selector downstream that does BOM line count optimization. Besides taking much, much more of the drudge work out of this, it also makes these circuit-as-code text files reviewable, in much the same way code is. Consider an input pin for an ADC on a microcontroller. On the signal path, I might have at a minimum a voltage divider to get things in range, a low pass filter to get rid of aliasing, and a buffer to satisfy the input pin impedance requirements. If this is three different modules, each with two or five components... reviewing this is equivalent to designing it, I need to check each bit. If, instead, this is generate_divider(1/3, 0.1%); generate_lowpass(200 Hz); module my_standard_opamp_bufer -- then I only need to review those implementations once, and can trust the use of them (for, potentially, dozens of ADC pins). [0] https://atopile.io/getting-started/ reply napowderly 13 hours agoparentFor sure, we found that to start with something useful from day 0 we needed to be able to completely represent any possible circuit. Starting by just providing a cleaner way to write out a netlist is just the beginning. We are working to add an equations solver to our compiler over the next few weeks, which will allow you to do things like set the ratio of a divider and total resistance, then have the solver pick optimal values based on availability, cost etc. I think that gets really exciting when you start to be able to link these together, its trivial from there to directly set the output voltage of a power supply in volts, which will internally configure the feedback resistor divider. Also verified designs will be super important. Its a little crazy that the status quo is you will almost inevitably make a silly mistake on your first spin. I am imagining designers will go off, make a new circuit, build and test it then make a PR to merge it into main. reply addaon 12 hours agorootparentGet even a basic equation solver in there and I'll be a user! Have it handle units properly and I'll be a happy user. Have it be able to handle both worst-case and RSS tolerance stackups and I'll be in love. reply napowderly 12 hours agorootparentExcited to hear it! Our language already captures tolerances and the solver we are building does proper tolerances stackups. You specify the desired output with a tolerance, eg my_regulator.power_out.voltage = 4.75V to 5.25V and we will solve the stack up to get you there. Hang tight, its coming soon! reply bboygravity 6 hours agorootparentWill it take into account temperature ranges and other parameters as well? reply mawildoer 3 hours agorootparentIf we can build the equation solver our hearts are set on, you should be able to account for as many factors as your design requires - albeit with some performance limitations at some point. That is, assuming temperature can be factored into equations in the same manner as any other parameter or attribute reply mawildoer 11 hours agorootparentprevWe're also super stoked about getting topology and equations together in the same file (and even code-base!) The equation solver is soon on our roadmap: https://atopile.io/roadmap/#language-features reply Timot05 13 hours agoparentprevHad a play here for equations: https://github.com/atopile/atopile/blob/tim/equations/sandbo... reply addaon 12 hours agorootparentThis is great. The pragmatic bit that makes it a bit more challenging (or, perhaps, a bit more of a search optimization problem than analytical) is that most of the cost functions are step functions. Once you need better than 10% tolerance on a resistor, you might as well step down to 1% -- available tolerances are discrete, and 5% and 2% tolerance parts are rarely cheaper than 1%. Similarly going to 0.1%. So once it's clear that preferred_tolerance_N is not going to solve, you can assume preferred_tolerance_N+1, and then push that through -- and hopefully push a few marginal parts up a bucket. There's also a similar step-function cost for adding a new BOM line, especially for hobby-scale projects; this is a project-global optimization, where I might change a 10 kΩ / 2.2 kΩ resistor ladder to 6.8 kΩ / 1.5 kΩ if I already have 1.5 kΩ, 6.8 kΩ, and 10 kΩ in my BOM but would otherwise need to add 2.2 kΩ (assuming everything else still solves, of course; more likely than not, since we usually don't care much about the total resistance of a ladder, as long as it's stiff enough, and doesn't leak too much). reply Timot05 12 hours agorootparentHadn't thought about the BOM line one but that definitely makes sense. The implementation I linked is definitely math heavy but might actually not be the best idea. As you say, the cost functions has steps. For less than a given amount of components, random search might be suited. Past that point, we might use maths to constrain the problem and then search within that range. We have equations at the top of our todo list and hope to get there soon :) Matt setup a roadmap here with things we want to work on: https://atopile.io/roadmap/ reply Joker_vD 12 hours agoparentprev> it's just circuits-as-text. atopile (1) — convert ASCII to pile of electronic components reply napowderly 12 hours agorootparentlove it reply assimpleaspossi 1 hour agoprev>Could you imagine the pain of building an entire software product using only assembly code? That’s about how we felt designing hardware. I've done both. What you called \"pain\" I called \"fun\". I started life as an electronic engineer but am now a software engineer and was very comfortable in both areas--including building from the TTL level. So I'm automatically suspicious of anything that calls such things painful. My kneejerk reaction is \"you've never done this professionally\" but it's 3am where I'm at and can't watch the video right now. reply michaelt 15 hours agoprevVery nice! The state of electronics tooling has long been extremely bad - 99% of people who put a regulator into their schematic will want an appropriate input and output capacitor as the datasheet demands. 99% of people who put a microcontroller will want a crystal and a programming port and a reset pin pull-up. It's only because of closed source tools stuck in the stone age that the state of the art is to copy out of a PDF. And multiple people working on the same design and merging their changes? Forget about it! It'll be very exciting if we can move towards a more modular world, where designs can be composed. reply crote 4 hours agoparent> It's only because of closed source tools stuck in the stone age that the state of the art is to copy out of a PDF. Not really. KiCad is open-source and a very capable EDA suite, for example. The problem is that it's a really hard problem for which no one-size-fits-all solution exists. There's basically an infinite number of properties which are important when designing electronics, many of which will have to be nudged depending on your design. Capturing all that in a data format is virtually impossible, and any attempt to do so is likely to degrade into something unusual quite quickly once you get past the trivial stuff. In my experience reading it out of a PDF is usually not that big of a deal, once you get used to it. For things like schematics symbols and footprints there are data interchange formats available - and there's a pretty decent chance these days they'll be openly available for the part you are using. But they always contain mistakes, and I find it way faster to just roll my own from the PDF than to copy it ready-made from a 3rd party and fix the errors. reply napowderly 15 hours agoparentprevFor sure, we definitely subscribe to works out of the box / path most taken. We have been working on adding equations to our language so we can solve component values based on requirements like output current and ripple for a regulator to get cap values for example. I hope in the future our component models will capture a good fraction of the info you have to go to the datasheet for today. reply stephen_g 3 hours agoparentprevAs an electronic design engineer, it just feels to me like these kind of things aren't really huge problems day-to-day... In terms of decoupling designs etc., the reason nobody has come up with a better solution is firstly that it doesn't actually take up enough time in the scheme of things to bother, and secondly that you often have to deviate. For variable regulators for example, the output capacitor (and inductor if it's not included in the device) are chosen based on output voltage, the switching frequency you choose, and sometimes other variables. You often want to deviate from the recommended circuit in the application notes for various reasons. I'd think of a circuit board production as more like putting together a magazine than working on a software codebase, where you'd have a bunch of people working on overlapping parts of the code. I mean even for a lot of boards we do (even quite complex ones) we'll just have one design engineer and one layout engineer, but for things where multiple people work on the schematic we just have people work on their own sheets and then somebody brings them together into the final design - kind of like where you might have an overall designer/editor that pulls a magazine together but individual people having put together individual articles. But it's pretty common that it would still be mostly laid out by a single engineer unless you're doing something extremely complex... reply mawildoer 2 hours agorootparentWe have some plans and atopile already supports some configuration regarding those deviations. There's a component selector which can choose resistors, caps, inductors etc... from a database of known components. Currently it's a free-for-all, but naturally we expect to be able to constrain this to a subset of components like \"thing we already use at this company\". That database means (once equations are also in) we'll be able to capture those requirements and change those output components depending on the scenario. reply moffkalast 12 hours agoparentprevYeah, trying to learn KiCad is worse than learning Blender. If JLCPcb made a simple online editor that sourced from available parts and integrated directly with their store they'd be running out of banks to put their money into. reply lelanthran 14 minutes agorootparent> Yeah, trying to learn KiCad is worse than learning Blender. I dunno. I've used others, and KiCad was no harder to start with than the others (Horizon, LibrePCB, Lepton/gEDA, some others I forgot). I asked for recommendations a week ago on HN for EDA products, and tried them all. You know which one I eventually settled on? The one with the most components (symbols + footprints). Turns out, features are nice (rules checker, etc) but not having to f*&^ing create my own symbols for a mass-produced part, then design the footprint for the same part is a huge timesaver.[1] For many of us non-professionals designing a board, the UI just isn't as big of an issue as having to create our own components. [1] At any reasonable hourly rate, having to create a library of just 1 component costs more than whatever you think you'll save with a slicker UI. reply napowderly 12 hours agorootparentprevThey do have this, its called EasyEDA. In my experience its not as good as kicad and definitely not as good as the 'professional' tools like cadence and altium. Our tool does basically do that though! We have a big library of kicad components that can be used in your designs as well as an import just about any JLC component just using its JLCPN. We love their service, would love to see that model proliferated to other companies also, so hard to beat having parts available and in stock. reply drunkonvinyl 6 hours agorootparentprevthis resonates. i will share that i'm trying out and having luck with flux.ai. it's not perfect, but for a small hobby project and someone with little experience and not getting far quickly in kicad, it works. i have a pcb in-hand from jlcpcb right now and it works. it also introduces some of the shared features discussed above. (i don't work for them, just looking for something that would let me do a fairly fast PoC) reply fxtentacle 6 hours agorootparentprevThey did and there's even tools to import their component library into Altium or Eagle. reply brokensegue 11 hours agorootparentprevI learned kicad fairly quickly. I've tried several times to learn blender and failed. Then again I'm bad at art. reply wkipling 12 hours agorootparentprevKicad is not that difficult to use. Sourcing parts can be though. reply gedy 12 hours agorootparentprevThey do! EasyEDA, and have used it to make custom keyboard PCBs. It's pretty handy and I found the learning curve to be much easier than KiCAD, etc. reply fxtentacle 6 hours agoprevDid you know that the KiCad file format for schematics and PCB layouts is text? And it kind of reads like source code? You can even check it into Git. What stops electronics from becoming like programming is the routing. It's NP hard and even the big car companies haven't solved it yet, let alone any tool accessible to hobbyists and startups. So you spend an hour designing the schematics, a few minutes placing the components, and then hours doing the routing by hand. If your product only replaces the first step, that'll save me at most 10% of the work. If you want to make a crater in this industry, add an autorouter to KiCad and make it sophisticated enough to handle an ESP32 2-layer board without manual assistance. Altium is like $15k per year and cannot do it yet. reply Timot05 3 hours agoparentAutorouting would for sure be a valuable tool to add to EEs toolchains. The reason we focused on the language first is because it is critical to provide high quality information to autorouter for them to do a good job. And achieving that with a schematic is tough, as it only captures part of the information required to doing a good job laying out the circuit. A bunch of information is currently implicit. reply 4b11b4 5 hours agoparentprevyou can do this with the Freerouting plugin it's non-trivial, you need to fiddle with parameters to encourage the autoroute towards certain behaviors. there are also some schematic patterns that lend towards better netlists and in turn better routing reply fxtentacle 5 hours agorootparentIn general, yes, but when I tried it, all free autorouters (and the paid one in Altium) failed to do the fan-out/escape of the ESP32's BGA. I then built a little CLI tool which used bitmap images and ConvNets to do just that one fan-out, but then I lost interest in it as soon as the PCB was finished. reply OJFord 15 hours agoprevYes yes yes! I love it when people make the things I think would be a good idea, and then stay on the hobby project idea list for years to come. (I'm struggling to make that not sound sarcastic - maybe it's just my British reading! - but I really am sincere.) When I was thinking about it, a couple of further directions I had in mind were 1) ecosystem/library/sharing of modules, so something like the voltage divider example is not something you'd need to do (even once) for every project; if it really took off the pipedream would be that application notes examples were just provided as modules, so you could take whatever IC wnd just import the module if you were using it in a standard way; 2) if you did a similar thing for layout constraints, you could then have that as part of the same module, and when you compile the whole thing (in hand-wavey generalised theory if sufficiently constrained) you could generate the overall layout for a project with say a SMPS and also sensitive analogue circuitry in a way that makes sense without either of those modules having to know that the other is in use, just because they have rules like distance from transistor, bypass cap to IC could be fully constrained, so you always get exactly the same sensible-looking layout, etc. Anyway, looks great, I look forward to trying it properly some time! reply mawildoer 15 hours agoparentAbsolutely love to hear that! 100% agreed about the ecosystem too. We've already created a perhaps-too-scrappy package manager, but it works! https://packages.atopile.io/ We're pretty convinced that the awesomeness of the software ecosystem is a function of its openness and open-source and atopile largely came from working out how we could seed a similar shift in the hardware world. I can't wait for the day I can `ato install` SMPS, filters, radios and servo-drives with the confidence they'll just work! reply napowderly 15 hours agoparentprevSpecifically on the layout section, I have been thinking along the lines of start with sensible 'seed' layouts that users will contribute, then mutate the layouts with a physics driven solver. Imagine links between components as a spring and repulsion forces to model creepage/clearance distances, you could imagine the layout warping into a suitable shape for your board. I am pretty excited to get to this bit. reply helpfulmountain 14 hours agorootparentAs someone who just taught themself Kicad to make a simple MIDI controller PCB usi an STM32F4, I was totally blown away, coming from software, how \"manual\" everything was, how abstruse and arcane. It's quite difficult as a beginner to know that a design is \"correct\", or perhaps \"correct enough\", with respect to component placement and EMI. It seems like even top EE who specialize in board design utilize rules of thumb rather than rely on simulation. I was also blown away that the state of the art autorouter for traces seems to be from the early 2000's -- no recent AI magic going on here. Where is my \"autoplacer\"? It seems like an AI trained on millions of schematic/pcb combos, even just gerber files via image ingestion, ought to be able to generate a pretty decent layout + routing given constraints. Or perhaps I'm spoiled coming from software and web because it's so much further removed from physics. But it's still the case that there are a ton of modular components with \"API's\" that should have a templating language, so very much bravo to this project. reply crote 4 hours agorootparent> It seems like even top EE who specialize in board design utilize rules of thumb rather than rely on simulation. Yup, almost 100% this. Most parts of most boards are pretty trivial, and the design decisions you make don't really matter all that much. Unless you're working at a company the size of Apple, it really doesn't make sense to spend several hours of engineering time to figure out if that $0.001 decoupling capacitor is really needed. And in the end it's often a lot easier to just build the thing and test if it works. We see the same in programming: it's technically possible to mathematically prove that some programs are correct, but in practice you can get 99% of the way there for all programs in a fraction of the time by just writing a bunch of unit tests. Simulation is definitely done, but it's limited to the really hard stuff like antenna design or high-speed signalling. reply rcxdude 10 hours agorootparentprevYes, it is like 90% rules of thumb and experience. The reason being simulation is expensive: not just in the software itself, but in the time it takes to learn how to use it, set it up for a particular design, and then run through it and understand if it's actually reflecting reality or not. I've been working on some projects where we really care deeply about noise performance, and even the super-expensive packages which exist (which we can't really afford) don't seem to actually be able to answer the questions we have about the design. Autorouting is similar, autoplacing is basically a disaster here. I am confident a lot of this is an accessibility and UI issue: if you want to disrupt this you could focus on making simulation and auto-placement tools that are cheap and actually usable, and help inform the rules-of-thumb. But that's a very big investment and mostly orthogonal to making a different way to specify your netlist. reply mawildoer 10 hours agorootparentWe share similar thoughts about the core of the auto-routing/placement/simulation issues being UX! We're a bit more bullish on code being able to fix that as well. Noticing that these tools are infrequently even configured because it's simply too much of a pain to do so for every new design - we're hoping the expressive, reuse-focussed code-based-approach means people need to capture these things once and then everyone gets to reuse them. This is all a while away, but after we're able to get design currently captured in schematics working smoothly we certainly plan to tackle auto-routing/layout as well reply Timot05 14 hours agorootparentprevThanks for the support! For the autolayout part, one thing we realized is that it’s very hard for a computer to do a good job at it when there is a lot of implicit requirements that are not baked into the schematics. We are hoping that by capturing those through code, auto layout can be improved. On the design check, we aren’t doing a lot there for the moment but the comment above also applies: if you have clear requirements in the code, it becomes easier to test if the solution fits those requirement. reply fecal_henge 6 hours agoprevHi, EE here, but started my career as unskilled labor in a test lab. This is in contrast to my colleagues who are often physicists. I love the graphical nature of Schematic design. It helps me visualise problems that my colleagues would admittedly rather code. I take a lot of care in my schematic layout, and it can help me make a good guess as to wether my circuit is planar or not. - usefull when you dont want to incurr the parasitics on a via somewhere. I would also remark that there is no reason why design reuse would necessitate a text based caprure. We already have reuse though subsheet heirachy, ctrl c/ctrl c and to some degree reference designs. The only other thing I would add is that a lot of people come from a hobbyist background, which means small volumes. For commercial contract manufacturing, drawing out the same old schematic features for voltage regulators doesnt add up to much NRE as a fraction of the project cost. reply Timot05 3 hours agoparentWell designed schematics are great. Especially if you are sharing them with your team as documentation. The point we would like to move towards is one where atopile enables you to generate high quality documentation about your design in a similar fashion to a datasheet but not entangling the documentation with the source design, which is what a schematic forces you to do. There are some features we'd want to build that could enable that like a visualizer for important parts of a schematic, a fan out view of the consumed interfaces around a chip, the results of a spice simulation... reply helpfulmountain 14 hours agoprevI think this is a wonderful idea and begins to create a foundation of data richness and interoperability for a very exciting new approach to PCB design, as I commented elsewhere in this thread However I do want to mention that I think it might be necessary to be able to \"cross-compile\" to visual schematic format, and back. Or perhaps there is an open schematic tool that can be extended? The issue is that I think electrical schematics are significantly more familiar to EE types, contain more legible information. Instead of reinventing the wheel there, it'd be nice to see a system that can switch back and forth between text and visual schematic. How are schematics described as files currently? Is there an open standard? Can it be converted to atopile format, and back? reply polalavik 13 hours agoparentI was thinking the same thing (I'm an EE by day). I think this idea is very cool, but since the dawn of time schematics and PCB layout have always been visual because you are actually building a physical thing. Its easy to see hardware bugs in schematics visually. However, it might be very hard to track it in code, unless the code is one day smart enough to find the bugs for you. You have to hold more context in your head that you cant export to your visual senses when its written as code. You cant see the actual circuit flow. edit: just wanted to double down on this being very cool though. i dont mean to deflate this project and I'm about to design a pcb for a personal project - I might give this a go for fun. the promise is there and asthe project and feature set grows i can see it being the way forward. reply napowderly 13 hours agorootparentI have found taking a 'functional programming' like approach, where you build up your circuit from small blocks with specific functions that are easy to hold in your mind and then building up by combining those. For example instead of sticking a bunch of resistors and caps in your top level file, you can abstract them into their functions like a filter, resistor divider etc. Very curious to get your thoughts on using the tool! reply cmos 11 hours agorootparentprevI agree - also an EE - and I think it is similar to 'programming music' packages like Sonic Pi. If you are used to reading and writing standard music coding will be an odd and difficult change. Right now we have a comfort for seeing the layout and such physically, and since that is how we manufacture it this is going to be an output anyway, but there is some future world where it is all put together automatically within the requirements we specify and we have an entirely new way of designing circuit boards. Each component would come with not only a footprint but an array of basic design implementations that would mix and match with others.. autorouting on steroids of sorts. reply Timot05 13 hours agorootparentprevWe do agree. We built an early version of a viewer in the project but later moved away from it because it wasn't good enough to interact with. We might come back to it with something that is more targeted at inspecting only sections of the circuit or provide a block diagram level representation. But we don't think that just outputting a schematic the way they look today is the right solution. reply whartung 6 hours agorootparentI worked on this for a little while myself. It wasn't so much \"pc board by code\" so much, but it was more a \"pc board by CLI\" approach. And by that what my goal was, was to offer primitives and utility functions that would build the board up over time, but it was to be done incrementally in a Lisp REPL. My use case scenario, was ancient AutoCAD. Back in the day, while you could hook up a tablet or other pointing device (I'm talking pre-mouse here) to make AutoCAD drawings, a lot of it was done simply through typing in commands, in AutoLISP. (lineto 100 100) kind of thing. And the drawing would appear on the screen over time, you'd save the data model, and manipulated with the REPL. If you wanted 10 lines: (dotimes (i 10) (let ((x (* i 10)) (y 100)) (line x y x (+ y 100))) (HN does not have a paren matching editor, apologies...) Where it broke down for me was coming up with a graphic rendition using CL. If emacs had anything reasonable regarding graphic support (its SVG support is Not Good), I'd have done it there. Rethinking it, it just occurred to me I could have probably gone a good way using ABCL in a Java GUI shell. But the key point is that I think using a REPL for building up something like a circuit can actually work, actually be efficient for users, especially if it's extensible (i.e. (defun grid ...) ). Especially a hybrid (like clicking on a line pastes an identifier into the REPL). My experiences with KiCAD drove me down that mad hole. reply techdragon 10 hours agorootparentprevYou might find this a stumbling point for adoption. My first thought is this could be a good tool for me to use, but how can I send a design to someone else to get feedback on if I’m not going to expect them to also also learn how to use this or how can I get my design manufactured if the tools can’t export out the, normally very visual, layout files. reply Timot05 10 hours agorootparentI do think that is fair. The reason that we don't have a visualizer is not that we don't want one, but rather that the value to effort ratio is quite low (and really because the effort is high, not because of low value). I'm sure we'll get there at some point. But at the moment there are more pressing issues for the people who are ok dealing with no visualization (like typing, language server, equations etc...). reply techdragon 10 hours agorootparentI’d definitely consider not letting some basic visual schematic outputs fall too far down the priority list. A lot of existing EE is basically just the visual diagrams and a lot of existing EE people will expect the tools to give them the visual diagrams they work with somehow… like even just including the compiled schematic as an SVG in with the compiled outputs of netlist, gerber, etc… something that other software can be used to convert to PDF without extra complexity in your tool and can be used to interoperable with the existing talent pool of EE people who have not just no idea how to use your tool… but know how to read typical style circuit diagrams. reply Timot05 14 hours agoparentprevYeah that’s an interesting aspect. We did implement a viewer very early on. And we then removed it from the project. What we discovered is that: - making a visual viewer is a non trivial endeavor. It takes a lot of time but the value add is marginal for an average viewer. - people tend to spend a lot of time making the viewer look good instead of improving the circuit We think that in the long run, a viewer could be awesome to inspect what is going on or get a general understanding of the circuit. But it’ll be difficult to justify the time spent on it early on in the project. reply napowderly 13 hours agorootparentWorth adding, we have found much higher returns building tools to solve the problems that a visualizer would normally help you with in other ways. For example ERC checking and modular abstraction of circuits. Working at a 'block diagram' level is much more intuitive than at the net level in my experience. We also think that there might be better and more interesting ways to view your data, for example maybe you want to just see all the power paths through your circuit, or investigate how a signal travels from your input to your adc through filters, protection etc. Often on big designs these things might be strewn across multiple sheets and a bit hard to follow. reply malfist 13 hours agorootparentprevAs a novice, a viewer would be really helpful to me to understand what it's actually doing. I did bookmark this for the next project I have in mind. reply napowderly 13 hours agorootparentI am definitely curious for feedback from people after using it for a while. I felt the same in the beginning, but after writing a fair bit of it, I rarely find myself wanting it. I could imagine for more casual or new users it could be helpful at least for the transition. reply jhallenworld 12 hours agoprevWhy not use Verilog or SystemVerilog? module blinky ( input v3v3, input gnd ); wire led; wire led_r; rp2040 u1 ( .vcc (v3v3), .gnd (gnd), .gpioa15 (led) ); resistor #(.VALUE(\"220\"), .TOLERANCE(\"5%\"), .PART(\"ERJH2CF1R10X\"), .SIZE(\"1206\")) r1 ( .a (led), .b (led_r) ); led #(.PART(\"WP7113SURDK14V\")) d1 ( .anode (v3v3), .cathode (led_r) ); endmodule Use Verilog parameters for all of the part information you might want, like links to digikey part number.. or bury them into modules with different names. FWIW: Cadance \"conceptHDL\" is a schematic entry program which generates a Verilog netlist like this as its output (usually for board level simulation including ASICs and FPGAs). But if you're careful, Verilog could used directly as the input- the board-level schematic is pretty simple compared with the chip source code. I'm sure there is a tool somewhere to convert this into an EDIF netlist for Kicad or whatever. [Icarus can do it: https://steveicarus.github.io/iverilog/targets/tgt-fpga.html ] Also: this is not limited to digital: there is a variant of Verilog called Verilog-AMS specifically designed for analog simulation. https://en.wikipedia.org/wiki/Verilog-AMS In Verilog-AMS, you can define a simulation models of your components: module resistor ( inout electrical a, inout electrical b ); parameter real R = 1.0; analog V(a,b)It should just be a library in a real language The last thing I want to worry about is having malware in an M5 bolt. reply Timot05 11 hours agorootparentFrom a security perspective, it does help that ato is not executable! reply ukd1 14 hours agorootparentprevYa OpenSCAD is great for in/cross project re-usable components. The only issues I've had is how it outputs circular things for cutting - it does a series of polygons (configurable number), rather than an arc/circular - places like send-cut-send won't accept it, claiming it causes issues with their machines. reply xnzakg 13 hours agorootparentOld issue, but annoying nonetheless. Less of a problem when outputting STL files (for printing) which only support polylines and not arcs/circles. Funnily enough, 3D printers nowadays support arcs natively in G-code, so some slicers support detecting rounded polylines and converting them back into circles or arcs. Found a script[0] that does this for DXFs in a github issue[1]. [0]: https://github.com/nophead/Mendel90/blob/master/dxf.py [1]: https://github.com/openscad/openscad/issues/4605 reply ukd1 7 hours agorootparentI actually opened that issue - I'm ukd1 on github too. I looked at fixing it at some point, but it tbh didn't seem that easy or like they had time to help, I should probably revisit. The script I couldn't get working right last time I tried, but I should give it a re-look! reply dekhn 14 hours agorootparentprevI found OpenSCAD's 3d model representation to be very challenging for anything complicated. I used FreeCAD, which is scriptable, but also uses a brep representation instead of CSG, which IME works a jillion times better. reply napowderly 14 hours agorootparentprevI have used it, I think its great. I am excited to see whole products defined in code. reply Taig 12 hours agoprev`import Y from X` is a terrible language design decision, established by the JavaScript ecosystem. It should be along the lines of `import X.Y` or `from X import Y` so that autocomplete tools can assist you. reply Timot05 12 hours agoparentAspects of the python lexer and parser implementation were borrowed from python, which is partly why we ended up here. I do agree though. reply echoangle 11 hours agorootparentPython does from x import y though. reply Timot05 10 hours agorootparentYeah, I think we only allow import x from y for the minute. And because we don't have a language server yet, it wasn't obvious that it was an issue. That'll change soon when the server is up though! reply napowderly 12 hours agoparentprevAgreed, we need to flip this. reply amonith 12 hours agoparentprevDisagree. I rarely remember what lib has the class/function/whatever I need. Doesn't help that some libs often use \"proprietary\" names (e.g. \"Uno\", \"Avalonia\", \"Rotativa\"). I often don't even write \"imports\" myself. I use stuff in code and let my IDE autoimport stuff. reply mplewis 12 hours agoparentprevReally? When I type import { someVal in JS, VSCode autocompletes it to import { someValue } from “somePackage”. I haven’t had issues here. reply cyberax 14 hours agoprevLOVE IT LOVE IT LOVE IT!!! I'm doing a lot of home automation work, and I absolutely hate that I need to use breadboards, hunt for pre-assembled components, or to spend days designing a PCB for simple things like relay modules with customized IO. E.g. I have ratgdo for my garage door opener, but its power supply is an ugly buck convertor taped to the box. I'd love to just re-make the ratgdo board, but with a built-in 12V-to-3V buck convertor. I tried that, but PCB manufacturing with custom component placing requires just too much work. Is there a way to donate to the project? I'd love to support it. reply Timot05 14 hours agoparentThat’s exactly what we are going for! Have a look at packages.atopile.io. We have a package with power supplies that you can just add to your board with ato install regulators https://gitlab.atopile.io/packages/regulators reply Timot05 13 hours agoparentprevForgot to reply to the support aspect: Best way to support us right now is to try the project and give feedback on where you'd like to see this going. The project is open source so feel free to raise issues or contribute as well :) reply Liftyee 16 hours agoprevLooks really useful! As a hardware designer I've had plenty of copy pasting bits of schematics to duplicate common functionality. Seems like this could be really helpful in preventing mistakes and increasing quality once used to it. Have you got any plans for defined interfaces/modularity so devices using SPI, I²C, etc. can be chained together without manually defining pin connections? Also, will there be support for importing schematics from other formats? reply napowderly 16 hours agoparentWe do have interfaces! They are super useful, I am very stoked that I dont have to remember which way around MISO/MOSI go any more. Interfaces are just a collection of signals eg interface I2C: signal sda signal scl signal gnd you can connect two together like so: micro.i2c ~ sensor.i2c Importing schematics would be possible, but IMO not super valuable as all we could import would be the raw connectivity, a big benefit of our language is being able to add a layer of abstraction on that. reply xnzakg 13 hours agorootparentHow does this handle connecting two microcontrollers with one being a SPI master and one being a slave? Or connecting UART between two devices? reply napowderly 13 hours agorootparentToday, poorly. We just do a dumb matching of signal names. I imagine we will do something like add a property to the interfaces on each device. reply wildzzz 15 hours agoparentprevKicad allows you to keep a library of projects containing layouts and schematics of small circuits that you may wish to reuse in other circuits by just simply importing them to the current design. You can then modify as needed. reply napowderly 15 hours agorootparentIndeed, Altium has similar features also. I think what has been missing is an effective way to collaborate on hardware projects as a community and be able to share them like you would packages on pypi or npm. reply yitchelle 2 hours agoprevDesigning circuit boards is not than describing a collection of electronic components and how each component's pins are connected together. For circuit board design we are missing * PCB layer management * copper dimensioning * track management * Design rules management * many others.... At best, I would describe this tool as a vim for schematic capture in its current iteration. One question to the founders, what are the real pain points for you that atopile are relieving? reply syedkarim 15 hours agoprevCould you please explain the difference between Atopile and Jitx (https://www.jitx.com/)? Both seem to provide software-defined hardware development. reply Timot05 14 hours agoparentOur language is also a markup language more than a programing language. The goal here is that we would want the code to become a description of what the circuit is, instead of how to obtain it. The obtaining part is the job of the compiler. Not the human. reply yoz 10 hours agorootparentPlease forgive me if you know this already, but just in case: the terms Declarative and Imperative may be useful here. Declarative: the code describes the desired result. Imperative: the code describes the operations to take. Most programming languages are Imperative, but some are Declarative, and some allow a mix of the two. More here: https://www.educative.io/blog/declarative-vs-imperative-prog... reply Timot05 2 hours agorootparentThanks for sharing the docs! Our language is mostly declarative at the moment. There are some features we discussed that would be imperative and we might introduce them in future versions of the compiler. reply napowderly 15 hours agoparentprevWe are taking the open-source route (eventually moving to open-core). We think a big part of moving the industry in this direction is building a community around it, much like the way Github started out. reply phlipski 15 hours agoprevFirst off - best of luck to y'all. The HW EDA space is sorely in need of tooling improvements. I'm curious as to how your product differs from JITX. They claim the same sort of thing - code based PCB development. And they've been around for a few years now. reply Timot05 15 hours agoparentThanks!! The open source aspect was really important to us. We are hoping that ato modules can become a convenient language for the community to share modules with each other, in a similar fashion to python and pypi. Having an open code base also makes it more convenient for our users to chain tools together. This is currently hard to achieve with the existing close source standards we are dealing with in hardware. ato is also a markup language (like markdown or latex) more than an actual programming language. We think this makes it more readable and helps guide the user writing code that compiles. reply nikeee 12 hours agoprevFinally I can just install some package and have a spec-compliant ESP32 circuit which I don't have to copy from somewhere else. This is great. One small thing regarding the imports: If you plan to have some rich autocomplete functionality (which helps dicoverability of packages) it is better to have the source of something first and the imported stuff afterwards. Python - which you seem to draw inspiration from - does this as well: from xy import z The editor can offer auto completions when the cursor is after \"import \", which is not possible if it's the other way round: `import z from xy` (like it is in JS). I'll try this out, it looks very promising! reply Timot05 11 hours agoparentGreat point. We'll change that soon! Especially true for interfaces too since modules might have tons of accessible interfaces and the language server could list them out for you. Did you see the ESP32 in the package registry? https://packages.atopile.io reply nihzm 11 hours agoprevLooks quite neat, but as other have pointed out I do not really see how this is different from traditional HDL languages such as verilog and VHDL. I say this because by looking a bit into atopile examples I only saw easy \"digital\" circuit stuff with GPIO and resistors, which are all things that can be implemented using FPGAs. However the most difficult things when designing advanced PCBs are EMC / EMI [1] problems with advanced subsystems such as an USB hub or analog filters. BOM generation and modular abstraction are already solved problems in industry (even though I hated every minute of working with Xilix Vivado) and tools like F4PGA [2] are slowling catching up. If I may add my two cents, I think you should concentrate on making it possible to go beyond lumped element models (which can already be simulated using SPICE, etc) and simple abstraction (solved by VHDL & co) and focus on being able to offer advanced subsystems to less experienced PCB EDA users. Basically, to go for the Altium path, but without Altium. For example, it would be a killer feature if it were possible to import an FTDI USB chip module and a switching power supply module, and obtain a PCB that has a guarantees (up to a degree) that the two will not interfere with each other. Or say, have it automatically optimize a design to guarantee a certain SWR [3]. [1]: https://www.analog.com/media/en/training-seminars/tutorials/... [2]: https://f4pga.org/ [3]: https://en.wikipedia.org/wiki/Standing_wave_ratio reply napowderly 10 hours agoparentFor sure, our goal is to solve the toughest problems in electrical engineering, we are starting with the low hanging fruit. Confident reuse of designs that can be verified and validated before a chip is placed sounds pretty exciting to me! BOM generation and abstraction have definitely not made it to PCBA design yet, so that is where we are starting. Stoked to get to the hard stuff. reply thrwwycbr 3 hours agoprev> Could you imagine the pain of building an entire software product using only assembly code? Speaking of it, THIS would be a killer product. A program gets compiled down to x86/x64 assembly, and you take that LL file and generate an FPGA from it. Of course there's a lot of limitations in regards to OS APIs, but those could be represented with an SDK (e.g. a network socket API that is compatible with linux's headers and leads to a NIC being controlled with a firmware replacement). reply bb88 14 hours agoprevI think you should do one thing really well, before expanding. Import from public GitHub libraries could be fun. Differential pairs. Impedance controlled traces. Going further, if I have one supplier's stack up with controlled impedance lines, and I need to switch to a different supplier's stack up, what netclasses would change? reply Timot05 14 hours agoparentI do agree. The package registry (https://packages.atopile.io) is an attempt at importing from existing GitHub/GitLab ato projects. This will need quite a bit more polish until it gets to the level Rust's crates.io or python's pypi.org On the language side there are additional features we would like to work on like traits and types (types would include diff pairs and impedance). reply AnyTimeTraveler 8 hours agoprevThis reminds me of writing VHDL in the Sigasi IDE. You could write the description for a component, have it's syntax checked and get autocomplete while typing and once you were done, you could click a button and see an overview of your component and how its signals were connected to other components, kind of like a schematic. It helped me learn and find bugs quickly and I was really missing that when I got started with KiCAD. I am very excited to use this! My optimal workflow would be, to use code for describing the netlist using components, then use a combination of graphical and code editor to layout the PCB, like how the UI editor in Android studio used to work. (I don't know if it still works this way) I'd love to layout my components using UI like in the CAD program \"Onshape\", which let's you set your constraints visually and the program visualizes conflicting constraints. I would love to start working on a project in code and then make an export into KiCAD to make final changes and send it off. Then, as the project gets further along, the point where I would switch to KiCAD would gradually shift further and further towards production. If I see this correctly, you are already aiming for that and I commend you for that approach :) reply mawildoer 7 hours agoparentThank you!! That's just about the workflow as where we lie today - albeit without the full suite of potency we're working towards. I haven't actually used Onshape, so I'm not intimately familiar with their constraints system. Thank you for the recommendation, I'll have to check it out for some hints. reply chrsw 15 hours agoprevPart of the magic here would be to get your team's hardware engineers to adopt a more software development style workflow. reply napowderly 15 hours agoparentIndeed, the ability to branch and merge is a pretty exciting concept for me as a hardware designer. Another simple one is building artifacts in CI and doing quality checks, I have make some silly manual errors that have been very expensive during export. reply crote 4 hours agorootparent> Another simple one is building artifacts in CI and doing quality checks, I have make some silly manual errors that have been very expensive during export. I set up a CI pipeline for the hardware company I worked for. It automatically generated things like gerbers and board renders for each commit, and made them available as PNGs. I added a little tool which made it really easy to view the results side-by-side, and see both the front and the back. It definitely saved us from some really expensive mistakes a few times! reply chrsw 14 hours agorootparentprevThis is very cool and the concept is something I've been wishing on for a while. Unfortunately I work in an enterprise type of design team. I'm a software developer but our hardware team has standardized on Cadence tools and are pretty dug in on how they work, which is kind of opaque to us software guys. reply napowderly 13 hours agorootparentI was a designer at a big company in my last job. Many of my colleagues shared the sentiment that the tools were trash, I think people just need an exciting future to rally around. I think being able to link across disciplines is super exciting also, firmware and hardware can be versioned along side eachother, no more checking schematics for pinouts and meetings about which pin which signal should be on, just put up a PR, have both hardware and FW teams review. reply Timot05 13 hours agorootparentprevThe core compiler is open source so hopefully the stakes are low to start using it on non-production equipment like test fixtures, bed of nails, quick prototypes... Based on experience using the compiler on those project, it could be transitioned to higher stakes designs. reply earlyriser 15 hours agoprevHi Tim, I'm just starting with electronics, following the Make Electronics book with my kid. And this seems super useful to understand circuits better (at least for people who code), do you have the plan to make a series of lessons for beginners with the app? Like going from the simple battery-led to complex things? Feel free to email. reply Timot05 15 hours agoparentHey! Really love that. My dad gave me a piece of wood with some basic components like LEDs, motors, resistors and light bulbs and a battery that I could connect those to and understand how they worked. Glad to see you are doing something similar :) We do have a couple videos and certainly plan to make more: - Get started guide: https://youtu.be/7aeZLlA_VYA - ESP32 module: https://youtu.be/eMWRwZOajdQ - Logic gates kit: https://www.youtube.com/watch?v=hSeDv3QqRc0 We are also hoping for the package registry to become a place where you can get access to pre-designed modules to put together into a circuit: https://packages.atopile.io Feel free to reach out per email or discord if you need help setting things up! reply mikeortman 14 hours agoprevThis has sooo much promise, I can't describe how excited I am and will definitely be contributing if I can. This would make it easy to implement a fancy optimizer. Each component tends to have certain acceptable thresholds for their dependencies like input voltages, current limits, external resistor/capacitor/inductor values/ratings, etc. Then, each component could have different implementations. You can have different manufacturers produce the exact same inductor/capacitor/resistor in different packages. You can link it up to your existing BOM or hook into vendor APIs to get pricing. Imagine optimizing for cost, removing redundancy, simplifying footprints, and prioritizing in-stock inventory over new order components. This could be a huge deal, looking forward to its progress reply napowderly 14 hours agoparentWe have been working on an optimizer for solving components that we will put a post out about soon. But the gist is figuring out which constraints are expensive, for example a precision inductor might be quite expensive, but a precision resistor is comparatively cheap. We can look at where to shift precision in your components to get the desired output for the lowest total cost. We already do a few things like prioritize in stock parts with high availability. I am excited to add more constraints, like board area, multi-sourcing etc. reply mawildoer 13 hours agoparentprevThat's awesome! We're definitely thinking along the same lines in terms of a lot of those optimisations / cost-functions. Here's some of the basics Tim was playing with earlier: https://github.com/atopile/atopile/blob/d25686952534e0f96582... reply AMICABoard 7 hours agoprevOkay here is a wish list: Chip fan out modules. A repo of all popular chips with traces to pins fanned out and variations (Chip XXXX, Fanout A, Fanout B, Fanout C, Compact Fanout D etc) Ideally the fanout modules should have required decoupling caps etc placed compactly). Accommodate provision for chips such as i.MX 6ULL, the have so many pins that writing connection code would be daunting, maybe have pin groups and groups wired to groups syntax. Provisions for chips where pins can be configured. A repo of supporting circuits/modules like clock, clock distribution, PMIC / Power modules etc. A CPU for example module should come with a list of compatible auxiliary modules such as a suitable PMIC/Power module. The user will have to wire the relevant pin groups from module to module. reply mawildoer 2 hours agoparentLot of good stuff! We're working on some updates to the package manager now that should make a lot of that super tenable to build out. reply markrages 14 hours agoprevIs this related to skidl https://github.com/devbisme/skidl ? reply Timot05 14 hours agoparentHey, We did use skidl for a little while as we were figuring things out (see a project here: https://gitlab.atopile.io/pew-pew-and-friends/sizzle-sack). But we later ended up moving away from it towards ato for mainly two reasons: - Baking a description of a circuit into python describes how to obtain the circuit, but doesn't really describe what the circuit is. Skidl projects quickly become hard to read. The user is also not guided towards writing code that compiles since you need to deal with all the complexity of Python as well as the circuit itself. - Contributing to the project and adding features was non trivial reply mNovak 5 hours agoprevI agree some format to attach more metadata into schematics is useful, especially if enough good modules become easily available -- something as simple as \"hey this is a 5V rated component\" is nice not to have look up sometimes. But to add to the wishlist of innovations in PCB layout; someone please give us better gerber editing/conversion tools. Geber strikes me as being very like pdf -- absolutely standard, well reproducible, but awful to edit in any way other than 'intended'. reply napowderly 2 hours agoparentIndeed! We do support quite a few parameters for component selection today, but definitely want to add a lot more. I think this opens up some exciting possibilities, for example not needing to explicitly call out a part number for generic components in your source code, retaining information about what the requirements of that part are. Of course in production you would want a lock file to make sure things are not changing arbitrarily, but I personally would have loved something like that while I was dealing with chip shortages a few years back. reply alistairjallan 13 hours agoprevAbsolutely love this, always wondered why there wasn’t a nocode for hardware that outputs a gerber. reply duskwuff 12 hours agoparent> always wondered why there wasn’t a nocode for hardware that outputs a gerber. Because hardware tends to be informed by messy physical factors which are hard to represent programmatically. Think along the lines of \"the cables are coming from this side of the board\", or \"buttons need to be reachable by fingers\", or \"if you're building a weather station, the temperature sensor should be far away from components that generate heat\". reply napowderly 12 hours agorootparentFor sure, there will always be some 'user' type requirements that we need to build a way to input, for starters it will be something like a lock file with component positions of things you need in a particular spot. I see alot of value in automating things you just dont care about, particularly if 'sensible' rules can be applied. For example if the tool could automatically determine trace widths, not just at a net level, but for each link based on how hot you were happy for it to get and what loads it would see. reply napowderly 12 hours agoparentprevThanks! reply andrejk 11 hours agoprevThis looks really cool. I need to dig through some more examples before I'd take anything I say without a massive grain of salt. :) Maybe I've been writing too much React and Android Compose UI lately, but instead of a declarative structure, have you considered a functional structure? That seems to be a create way to build composable components and add enough programmability (e.g. loops, conditionals) and keep a nice one-way flow down the line. Something like ``` import {Resistor, Signal, Ohms, Float} ... def VoltageDivider(totalR: Ohms, ratio: Float, signal1: Signal, signal2: Signal, signalOut: Signal) { r1 = Resistor(totalR/ratio, signal1, signalOut) r2 = Resistor(totalR(1-ratio),signal2,signalOut) } def MyBoard() { s1 = Signal() s2 = Signal() s3 = Signal() div1 = VoltageDivider(totalR: 100_000, ratio:.33, signal1: s1, signal2: s2, signalOut: s3) } It's similar to what you have but maybe a bit more of a programming language than a declarative format. The trade-off is that tooling support gets harder as you add some basic language features, but the upside is a more powerful language. reply napowderly 11 hours agoparentFor sure, we have been pretty focused on the low level part of the language, I think it will be interesting to see how our language evolves as we are able to abstract away more of the low level connectivity and configuration. I think eventually we will end up building something like a python library on top of ato to get the best of both worlds. reply distortedsignal 14 hours agoprevI'm curious if you have component checking - does the circuit overload the regulator? am I going to overvolt this capacitor? what is this LED's lifetime? - or if that's somewhere on the roadmap? I'm also curious if you're able to use an autorouter to minimize board layers. Seems like it should be pretty straightforward to apply some graph theory to this and state the minimal number of layers for a given board, but this also might be NP-hard? I haven't kept up with the theory here. reply napowderly 14 hours agoparentWe have some basic component parameters that we can define, like value, dielectric and voltage rating for capacitors. I think these become much more powerful once we add in equations to help relate these values and link them together. For example if I configure my powersupply for a 12V input, the tool should know that the capacitors need 12V * some safety factor of rating. I think I see the entry point for auto routing to be taking advantage of the fact that layers have become pretty cheap (atleast for prototyping) and engineering time is the expensive bit. If the tool can help me layout a board in half the time, particularly for test hardware or the likes, that would be huge. Eventually I think we will get to a place where computers will do a better job of layout than most people, but thats a ways off. reply DHaldane 14 hours agoprevI think a compiler for PCBs is a great idea! Are you fully open source today? How has the community aspect been going? reply napowderly 14 hours agoparentI bet you do ;) We are fully opensource today, but we will eventually have some features we sell to enterprise. We have a small community of mostly friends at the moment, we are hoping to grow that very soon now that we have something we believe is worth sharing! reply DHaldane 14 hours agorootparentI've been doing a lot of selling to enterprise recently - mostly US based. Let me know if I can be of support! reply napowderly 14 hours agorootparentFor sure, would be awesome to have a chat some time! reply sapientiae3 14 hours agoprevThis is a great start, well done! Eventually it would be amazing to import (for example) a buck converter circuit with a wide voltage input, fixed output suitable for RF, and have it automatically check available components at JLCPCB and then lay it all out with, adhering to best practices (ground planes & capacitors right next to pins etc.) If the available components change, it can tweak the footprints and layout without having to start from scratch. Good luck, I’ll be following closely! reply napowderly 14 hours agoparentFor sure the goal! Our current component tool will find components that are available on JLC, in stock and to your spec, no more looking for resistor part numbers. The layout side is going to be exciting, we are just scratching the surface there. reply hackskale 1 hour agoprevvery interesting. hope you can improve the tedious hardware design process. you might want to look into digital hardware description languages such as verilog and vhdl. reply Hasz 11 hours agoprevFor context, I am very familiar with KiCAD and somewhat familiar with Eagle. I think KiCAD gets a lot of things right. Some of the broken things: parts management (There is no central repo, a la LVFS, where I can get a part/pinout/3d model to easily import) export process (feels kludgey, although some manufactures take the native KiCAD files) multiple users, same project -- it's hard to put artifacts into git and merge changes. I see this solving the last issue, perhaps the second as well. Commercially, I think it is worth pursing the first. Other thoughts: When I spec parts for certain types of designs, I need a whole lot more than just tolerance. e.g, for a mlcc capacitor, I need to spec dielectric, voltage, tolerance, ESR, sometimes leakage. For resistors, inductors, and other jellybean parts, similar metrics apply. Specing active \"common\" parts (like bjt/fet, diodes, etc) has even more parameters to consider. I would also love the ability to take a design and drop it into SPICE for simulation. reply crote 4 hours agoparent> export process (feels kludgey, although some manufactures take the native KiCAD files) I fear a lot of this is due to manufacturers. There are quite a few variables in the file definition, and every manufacturer requires them to be set slightly different. Having pre-baked per-manufacturer templates in a dropdown box would already be quite the improvement, though. reply napowderly 11 hours agoparentprevIndeed, we think the community aspect of this is super important. Being able to reuse high quality work confidently is very nice. Our export is pretty cool already! We build outputs in CI on a server, ready to drag and drop directly into JLC, including BOM and PNP files. Being able to use git was our fundamental motivator, we all previously worked a big companies and found it maddening that we couldnt work in parallel on projects without breaking everything. On parts specs, for sure, we currently capture all the data you would see on JLCs website. We do have dielectric and voltage ratings for caps. Eventually we plan to scrape a bunch of datasheets to build out a high quality dataset, I am very excited about this! reply pitherpather 8 hours agoparentprevAlso, is there any workflow option in current Kicad for importing a component-naming netlist (of the kind so many existing schematic packages can output), without having a live Kicad schematic? One lesson of this thread could be: There is enough interest in text-based \"schematics\" -- aka netlist import -- for Kicad layout to add support for the approach, if it does not currently exist. reply DenseComet 16 hours agoprevCongratulations on the launch and good luck building a business around it! I remember running into you folks at OpenSauce last year and thinking just how useful it could be. reply Timot05 15 hours agoparentThanks for the support! We will try get a booth at open sauce again this year. Hope to see you there :) reply mamcx 13 hours agoprevI think this will be well received in the personal keyboards community (I will like to see how to design the PBC for custom keyb!) reply Timot05 13 hours agoparentOh yeah we did think about that. Would be cool to have an ato package for a keyboard! Or maybe a script that generates both the CAD (with OpenSCAD or similar) and the ato code would ne nice. reply Timot05 12 hours agoprevHey everyone, if you want to see a complete project, please check out the Spin Servo Drive that Narayan designed: https://github.com/atopile/spin-servo-drive It can be a good example of how to setup an ato project. reply jhallenworld 12 hours agoprevIt should produce a schematic as one of its output products.. maybe use graphviz, see: https://observablehq.com/@nturley/netlistsvg-how-to-draw-a-b... HDL tools all do this. reply Timot05 12 hours agoparentNetlistSVG is great yeah. We had a play with it. We had a visualizer in the compiler early on in the compiler implemented with JointJS. But it was a pain to maintain and difficult to get value out of. I'm sure we will have some flavor of a visualizer in the compiler one day. But outputting a \"normal\" schematic doesn't seem like it's the right approach. We might actually end up with a bunch of different ways to \"visualize\" your circuit, each one optimized for a specific thing you are trying to achieve. reply elamje 10 hours agoprevThis is an amazing concept. You still need heavy EE understanding to know how to develop PCBs, so it’s not going to turn every software engineer into a PCB pro, but it could totally change the game for EEs that can learn to code. This is definitely a step in the right direction though and I’m wondering how much of a PCB can be represented in an abstract syntax tree or something similar. Are there edge cases, or could you completely describe a PCB layout using code? reply mawildoer 9 hours agoparentDefinitely agree this isn't taking away EEs - anytime soon or ideally ever! The goal is to make EEs far more potent, rather than bring SWEs to hardware (although letting them easily tweak existing board's filter constants, vdivs etc... would be awesome too!) We're honestly not sure how explicitly we want to describe a layout in code, or if it's a more declarative thing. Currently we're leaning more towards the declarative approach (eg. this trace carries 100mA of current) rather than the imperative (this trace is 0.150mm wide) since it should scale more intuitively with equations and layer better with DFM specs etc... Have you got some ideas? reply elamje 9 hours agorootparentTreating it declaratively is what I initially thought it would be, but what happens when the user needs to tweak the layout for some unique requirement? My guess is what would happen is it would force them to completely eject from your declarative approach, similar to how if you build software on low-code tools, and need to tweak something, you typically have to completely eject. The low-code thing has no understanding to render your custom thing. Idk maybe this can be solved, but seems problematic to describe layouts like SQL then rely on query planners to deliver the perfect execution. reply peter_retief 43 minutes agoprevGreat concept, I have used KICAD to design in the past, some of the problems I have had as an amateur are: 1) Selecting the right components, are they available, standard size, surface mount or leaded? 2) Single or double side? Vias can be used to hop tracks I will try out your sw and give feedback. reply wildzzz 15 hours agoprevWhy ato over existing hardware description languages or things like SPICE (and it's many derivatives)? reply mawildoer 15 hours agoparentGreat question! Current HDLs tend to primarily be focussed on digital circuit design, while at the PCBA level, there's a lot more focus on the \"fuzziness\" of the physical world (eg. tolerances). We also noticed that most EEs we've worked with were a bit put off by the syntax and preferred something a bit more terse, but more intuitive and easier to read. There perhaps an analog here in software - where we started with assembly (~ SPICE), moved up through things like C and now languages like Python and JavaScript are prolific and accessible. reply waterheater 12 hours agoprevFor reference, I've designed ~10 PCBs of varying complexity (simple to highly complex) and done plenty of programming. I've used Eagle, KiCad, and Altium. My comments will try to push you to think about some specific points. Looking at your demo video, it seems that atopile is less a \"tool to build electronic circuit boards with code\" and more a tool to perform schematic capture in code. Do you agree with that characterization? I ask that question because you're clearly relying on the KiCad toolchain for PCB layout, which is a crucial part of the overall PCB design process but is not \"PCB design\" itself. Right now, KiCad is a tool for PCB design, and you are providing an alternative method of schematic capture. I think you should make sure that the description of your creation accurately reflects its capabilities. Is anything preventing you from taking output from the existing KiCad schematic representation system and transpiling it into ato? What about transpiling from ato into the KiCad schematic representation system? Does ato provide any focus on routing? It could be nice to state in software that I want a component or trace constrained to a specific layer on the PCB (or in the PCB, if there's internal layers). I'm assuming no, since ato appears to be purely focused on schematic capture, but I'm curious of your thoughts on this. It could also be nice to include placement constraints in software. For example, say I have a handful of resistors which I want placed in the same relative area of a board and in an orderly row. Do you provide functionality to allow this? The general aesthetics of PCB layout might be programmatically defined with ato. Just like Arduino took the nitty-gritty away from microcontroller programming, think about how you can take the nitty-gritty away from schematic capture. One way this could work is with a hierarchical schematic templating system. You'd need to build significant documentation to teach people how to use it, but it could vastly simplify the schematic capture process to a few lines of code by importing a template schematic class and instantiating multiple schematic objects into a project and wiring them together. It makes sense to me that an \"interface\" as you define it can be imported for a given project. For example, \"Bob's Interface\" is the set of a +12V barrel-type power input, a USB-A port, a 3.5mm headphone jack, and a 10-pin GPIO header. Any project using \"Bob's Interface\" has a known set of input and output capabilities. The term \"input/output complex\" also gets at this idea. Is that how you think of an interface? That's all for now. :) reply napowderly 12 hours agoparentWe have indeed started with the schematic/requirements half of the problem. My experience in industry is there can be much more direct reuse/configuration in schematic as many boards might have similar features. Layout is typically quite bespoke as it will have mechanical constraints. That said, we are absolutely looking to take on the layout section in the near future. We are starting with some augmentations of kicad, for example we just released a layout reuse feature, where component layouts can be captured and shared along with the ato code. I think with few exceptions defining explicit layout choices in our language will be painful and not the right path (perhaps connector positions would be an exception). We have not put a huge amount of energy into this yet, but from some initial playing around, we believe capturing all the information that a person would use to judge a quality layout will be crucial. For example, current tools do not have concepts of current/voltage and definitely not transient behavior. To get to actually good auto-layout that doesnt suck is going to be a slog for sure. Thanks! reply JRKrause 14 hours agoprevVery neat, nice work. I tooled around with a similar idea sometime back. There are clear advantages of code over graphical-schematics when it comes to automatic generation of component values / re-use of elements / speed of development / automatic SPICE testing / etc. The primary issue I ran into was that: electronic circuits are inherently graph-structured and the traditional circuit schematic is well suited, optimal even, for displaying this kind of information. Trying to understand an analog circuit that is described as code seems awkward. reply Timot05 13 hours agoparentYeah we did run into a similar issue. Someone designed a power supply and it wasn't immediately obvious how the elements of the circuit were hooked up in ato. I think a viewer would be nice ultimately. But we haven't exactly figured out how the solution might look like. ideally something that allows you to create datasheet-like snapshots of part of your design? reply JRKrause 13 hours agorootparentA nebulous description of my ideal setup would be something like this: Side-by-side schematic symbol view / code view that are actively synced to one-another in real-time. Schematic view allows basic arranging of parts, editing interconnects, triggering jump-to-reference within the code view, adding probe points for SPICE, displaying SPICE output graphs. Code side does all the heavy lifting like creating new parts, scripted behaviors, editing component values, all the cool shit that would be a nightmare to sort into a GUI. Much easier said than done, of course. reply Timot05 12 hours agorootparentYeah the side by side thing makes sense. Especially for very low level or analog designs. But in some cases it wouldn't be desirable to show the whole circuit. Say you are dealing with a module that has been characterized and that you know works. In this case, using a language server or a linter that shows you available interfaces might be easier to use. For the spice graphs, having a jupyter notebook-like interface would be great to document why your design looks the way it does. If you have specific ideas or drawings of how this might look like, please send them over in our discord server :) reply AMICABoard 7 hours agoprevOkay here is a feature that I'd like to see. This has a VS Code extension, but I don't use VS Code, I like to use other editors like Kate. Having a LSP Server and xml for syntax would be a great feature. reply mawildoer 2 hours agoparentYou're not the first person to ask for alternative syntax highlighting! Might be something we need to address soon. I think an LSP server is what we're really excited about, since it also means we can provide far richer autocomplete and inline docs as we go too. reply vrtnis 12 hours agoprevCongrats on the launch! Couple of quick questions: Are there any initiatives or resources planned for educational institutions to adopt atopile? Outside of GitHub, are there specific areas or tasks where you’re seeking community or volunteer contributions? Thanks! reply napowderly 11 hours agoparentThanks! We definitely want to get involved on the education side. Currently we are super focused on building out the tool and growing a community around it. We are looking for people to use our tool and give feedback on what works and what sucks. Would be excited to chat about what you would want to see from an education standpoint! reply vrtnis 11 hours agorootparentcool, i believe this is a scenario where targeted educational/univ. chats could help further enterprise trials (or early constructive feedback). would be great to chat more on discord/email! reply cupcakecommons 14 hours agoprevReminds me of openscad - https://openscad.org/ but for circuits instead of shapes. Turning complex wysiwyg editor operations into reusable code is such an improvement, especially with the advent of usable LLMs to help with boilerplate. reply Timot05 13 hours agoparentI do agree. Though it is interesting to try figure out why openscad (and similar projects) haven't become more prominent in the industry. It feels like some aspects about code to hardware have to be tweaked for it to become the standard way to design. reply AMICABoard 7 hours agoprevReally love this idea! I will give it a try. I have seen code to circuit before but this seems like it has potential. reply mawildoer 7 hours agoparentThanks mate! reply TobiasJacob 10 hours agoprevI like the idea in general, but I absolutly hate it when people invent their own weird programming language instead of using a well defined existing one... Why not just use Python? reply mawildoer 10 hours agoparentGreat question! We hope we have a few good reasons. This iteration of the project actually came after first working with and then modifying another awesome project called SKiDL (https://github.com/devbisme/skidl). It's based on Python - but we found that since it's procedural, turing complete and has a rich eco-system - people use to that and there aren't standard composable ways of designing things. Instead of describing your board, you (practically) write a script that generates your board. It entangles your targets with your source-code and can make it difficult to understand the ultimate outcome of what you've written. Additionally, since it's a potentially very long program, it was hard to write good language support around (a language server for VSCode, a schematic visualiser etc...) that were snappy, responsive and lent to examining modules as well as the whole program. There's a few operators and first-class language features we wanted as well, like units and tolerances (3.3V +/- 100mV) that just aren't the same when embedded in a string, or class init method. reply speed_spread 10 hours agoparentprevSir, this is Hacker News. reply spuz 12 hours agoprevThe final part of the demo shows the output of the automatic build as something you can upload directly to a PCB manufacturer. How does this work given the output of the compiler is a netlist, not a PCB layout or Gerber file? reply Timot05 12 hours agoparentThere are actually two steps to the design process: - First, requirements. In ato, you define how your circuit is connected and the requirements for the components that sit within it. From there, we generate a netlist and a BOM. - Second, the netlist is turned into an actual object during the layout operation. We use KiCAD's layout tool in our case. There are infinitely more dimensions in the real world than there are instructions in a computer. So we do need that second step to point the requirement to one implementation in the real world. But technically there could be a quasi infinite implementations that fit the requirements written in ato. The manufacturing files are a combination of the ato output files, like the BOM and the KiCAD output files, like the gerbers. reply voctor 14 hours agoprevIt reminds me of the Akka Graph DSL[1] [1] https://doc.akka.io/docs/akka/current/stream/stream-graphs.h... reply mawildoer 14 hours agoparentInteresting! Haven't come across it before but those linked `~>` operators do indeed quite familiar. If you're familiar with GraphDSL do you have some elements we should look into? reply voctor 12 hours agorootparentBy reading some code here https://github.com/Timot05/logic-card/blob/main/elec/src/log... I wonder if with directional arrows, instead of writing \"out ~ switch.in; switch.out ~ power.gnd\", we could write \"out ~> switch ~> power.gnd\" instead? But without distinction between in and out ports it may not be possible to check if connections are valid ones. Anyway, this project really makes me want to learn electronics! Congrats! reply mawildoer 9 hours agorootparentYou're absolutely right! We've been thinking very similar ways about \"dipole\" components and how to best do this; and I think you've nailed it. What about using dunder __in__ and __out__ attributes? Easy enough to implement for us and overload for folks in the future. reply voctor 14 hours agorootparentprevI've only worked with Akka Graph DSL to build some data pipelines or protocol stacks. And I've loved working with it! The equivalent of atopile signal would be port with Akka I think. A combination of ports gives us a shape. A source shape is just one OUT port. A flow shape is one IN and one OUT port, etc. I'm very new to electronics so I don't know if it makes sense, but connecting all these ports with directional arrows was really helpful to understand the data flow. reply resters 13 hours agoprevThis is great! So many ways to improve upon the status quo approaches to circuit design -- notably allowing a single representation to be used for design through spice through layout. reply napowderly 13 hours agoparentFor sure, its amazing how many places you need to write down basically the same information today. EDA tool, SPICE, requirements pages, documentation. SPICE is definitely an exciting one, particularly as the model can be versioned along with the package with parametrized tests that will automatically run in CI. reply resters 13 hours agorootparentExactly. A new level of modularity will be possible. Pretty incredible! Also parametric designs of modules (a function call with 3.3v vs 5v, or 8bit vs 12bit ADC) all the way down. reply Timot05 13 hours agoparentprevYeah, that would be great. We currently don't compile down to spice but we hope to get there one day. reply ukd1 14 hours agoprevThis is really cool, and love that it's open source. Congrats! reply Timot05 13 hours agoparentThanks! reply nimish 11 hours agoprevOh nice, I made a really half-assed attempt with Kicad and python. This looks so much nicer. reply mofosyne 8 hours agoprevHow technically possible is it to integrate this with KiCAD? reply mawildoer 8 hours agoparentSuper! So far that’s all we support for layout and we love that it’s also super-low-barrier to entry OSS. reply lijok 14 hours agoprevWould be good to see a comparison to Verilog reply napowderly 14 hours agoparentPretty similar in concept, a few important nuances that come with building boards in the real world. For example dealing with tolerances. The language is definitely an important part of this, but we think alot of the surrounding infrastructure like package managers, CI pipelines and SPICE integration will be critical also. reply Joel_Mckay 15 hours agoprevThe Net-list stage of abstraction is the easy part, but auto-routing is not. People have tried many times to build a universal router with physics awareness for decades. The issue is in the real world there are countless edge cases where the EE must make a decision on the layout. For low speed digital design... routers have partially worked since the 90's, but for most other things the edge cases make it counter-productive to automate. EEs are good people to have around, and some know how to build things reliably. Have a wonderful day, and I really hope the project does well. =) reply napowderly 15 hours agoparentFor sure, we are starting with the schematic/requirements side of things and will push in the layout direction soon. We have started with some simple layout snippet reuse that is available today. My experience with autorouters is they do not have a good understanding of the problem, we hope to improve that by being able to capture more information about the circuit, for example physical values like voltage and current are captured today. Our goal generally is to automate tasks that are boring/repetitive like multi-day reviews of big schematics to see if anything accidentally changed. Definitely building a lever for EEs, not a replacement. Thanks! reply bagful 15 hours agoparentprevAgree, I wish them the best of luck — I’m not convinced a computer will ever beat me in the single-sided perf board niche, and I’m but an amateur, but I’d be happy if one did. reply napowderly 14 hours agorootparentYou might be right, dont think we will be tackling perf boards any time soon :D reply binsquare 12 hours agoprevFine tune an ai on the docs and you've got a new company of AI generated circuit boards reply napowderly 12 hours agoparentFor fun I did have a play with GPTs doing a little fine tuning on some ato code. Definitely not my domain, but pretty amazing how quickly it kinndaa worked. Our focus at the moment is building out the layer that designers (human or otherwise) can operate on. I do think that we need some pretty solid testing infrastructure for us to get to a place where we would ship 'black box' pcbs. Maybe one day. reply binsquare 2 hours agorootparentSo exciting, hope that happens! I'll be sure to keep an eye out reply anon291 16 hours agoprevI love that this is human-readable plain text. Plain text is almost always the best format for anything. reply zokier 15 hours agoparentWorth noting afaik all kicad file formats were already sexprs, can't get much better than that. In that vein, I'd imagine it would make lot of sense to build a lisp on top of that, macros and sexpr manipulation are very much the strong points of lisps. reply topspin 15 hours agoparentprevText puts the problem squarely into the sights of generative models. reply quailfarmer 15 hours agorootparentMaybe one day, but I’ve asked the various models basic EE interview questions, and it’s painfully obvious that while it can make a paragraph that has the right words, it’s incapable of reasoning spatially, or describing complex connections. My job is secure (for this year). reply napowderly 15 hours agorootparentI have noticed a huge improvement in ChatGPTs coding abilities having an interpreter to check its work. I expect we will be able to bring a similar feedback loop to hardware once we can integrate things like simulation and equations. Also having modules that are tricky to configure incorrectly. reply topspin 12 hours agorootparentThe performance of ChatGPT (4) changes frequently. Lately it has been crazy good. I fed it a non-trivial but naïvely written (and thus slow) numerical algorithm written in Python yesterday. I then told it to vectorize, which worked and was both correct and several orders of magnitude faster. Then parallelize. Faster yet, and still correct. Pretty amazing. Just an anecdote. reply dartos 15 hours agorootparentprevI’ve noticed the opposite with chatgpt. To be fair, idk how much elixir code is in the training set. reply napowderly 13 hours agorootparentyeah I have only really used it for simple python things, its pretty good at that. reply mawildoer 15 hours agorootparentprevAbsolutely! With only a few dozen lines of context to pick up the syntax, copilot is already able to make useful contributions like configuring regulators and filters. reply mawildoer 15 hours agoparentprevThank you! We've certainly been heavily inspired by python and Guido's insight that code is read more often than it is written. reply andrewstuart 14 hours agoprevI'd like to hear the opinion of Lady Ada on this - one of the industries greatest hardware designers. reply napowderly 14 hours agoparentSo would we! I think we are trying to do much the same things, make hardware design faster and more accessible. reply markrages 14 hours agoparentprev> one of the industries greatest hardware designers Is this meant sarcastically? reply andrewstuart 14 hours agorootparent>>Is this meant sarcastically? No I don't mean it sarcastically, why do you ask? Do you not see Lady Ada as a shining light of the industry? Lady Ada is one of the industry's greatest hardware designers and I would value her opinion on this. If you don't know who she is, her name is Limor Fried and she founded AdaFruit. I don't have current stats but from 2016: Revenue US$45 million (2016)[1] Number of employees 105 Front page of Make Magazine: https://blog.adafruit.com/2017/05/08/limor-ladyada-fried-on-... Front page of Wired: https://www.wired.com/2011/03/wired-magazines-cover-features... Front page of Smore magazine: https://www.adafruit.com/product/3920 Front page of Hackspace: https://www.flickr.com/photos/adafruit/40061387915 reply markrages 13 hours agorootparentBy \"industry\" you mean \"electronics hobbyists\"? reply MSFT_Edging 13 hours agorootparentAdafruit breakouts, libraries, and other various components are often leveraged at early prototype stages in general industry. That is unless all you do is high speed FPGA work and that's all you consider to be \"industry\". reply andrewstuart 13 hours agorootparentprevI oh see you are wanting to diminish her capabilities for some reason. I'm not interested buddy, you can take your sneering elsewhere until you show me the multi million dollar company you have created, the hundreds of commercial quality boards you have designed and sold for real money, the driver software you wrote to make them usable and the industry accolades you have received - on merit. reply markrages 13 hours agorootparentShe's a solid entrepreneur and a competent engineer. Calling her \"greatest\" seems odd, for implementing breakout boards with datasheet circuits. reply joemi 12 hours agorootparentI agree. She's really great for hobbyists and for prototyping. She's done a ton to help beginners. And Adafruit is a very interesting company. I seriously admire her. But as to the original claim that she's \"one of the industries greatest hardware designers\", when you look at the electronics industry on a whole (an industry where people design incredibly complex things that are used by millions/billions of people), her _designs_ are nothing special. reply leptons 9 hours agorootparentprev> and sold for real money \"Lady Ada\" and Adafruit certainly are good at price gouging. They often charge exorbitant prices for the same stuff we can get elsewhere at a fraction of the cost. No, providing datasheets and some instruction isn't enough, there's a thousand other sites with better instructions in most if not all cases. reply joemi 6 hours agorootparentAs far as I can tell, Adafruit doesn't price gouge. More expensive than some other US places, sometimes, but usually not by much. Sometimes they're cheaper than similar US places. The only places that sell same or similar items for drastically less than Adafruit are places like Aliexpress (or the same foreign sellers selling on Ebay), and there are many reasons why Adafruit is more expensive than those places... Some of the stuff Adafruit sell is likely sourced from Aliexpress (or perhaps from Alibaba if they're buying in large enough quantity) and is indeed priced higher at Adafruit, but that's because if they price it the same or lower they make no money. So we know for those items, they must mark them up. But how much they need to be marked up is kind of complicated. Buying lots of things in order to resell them is more complicated than buying just one or two things for yourself, especially when the seller is on the other side of the world. Simply put: there's a lot more overhead when buying for resale that you don't have to worry about when buying low quantities for yourself. One big difference is that they need _reliable_ suppliers with large quantities consistently available, and those are rarely the same sellers selling things for pennies. (I could go into more differences, because there are many, but this reply is already getting pretty long. Ask me if you want to know more, or google for info about how to open and run a retail business.) Also, bear in mind that some of that stuff that you can get elsewhere at a fraction of the cost than Adafruit are actually Adafruit's own designs being directly cloned, like a lot of their breakout boards. In those cases, you really can't blame Adafruit, since the reason those items are cheaper elsewhere is because someone's specifically trying to undercut them (often at the expense of overall quality and sometimes even at the expensive of authentic correctly-working parts). reply ipsum2 12 hours agoprevI saw your project at Open Sauce last year, happy to see the official release. reply napowderly 12 hours agoparentThanks! Hope to see you there again this year! reply al2o3cr 7 hours agoprevIMO it's hard to spot the \"holes\" for parameters in a module - for instance, in the logic-card project the instantiations of \"LDOReg\" end up setting values of objects in \"Vdiv\" two abstraction layers down. https://github.com/Timot05/logic-card/blob/a63581636233dd1f9... reply mawildoer 7 hours agoparentYou're right. It definitely is currently. This is a hole we're planning to fill between linters and a language server. Picture a red-underline under an instance which is insufficiently configured, for example reply robomartin 9 hours agoprev@Timot05 I wish you the best. Among other things, you are reinventing Verilog and other attempts. Yet, of course, evolution does not happen without people who are willing to devote their valuable time and effort to consider new ideas. My personal perspective, after having designed hundreds of PCB's, is that there's a reason for which symbol-based data entry has survived decades of computer-based circuit design evolution. I have also written more software than I can remember in more languages than I am able to list. I have less than zero interest in using a software process to describe circuits of any kind. What makes sense for hardware design inside an FPGA somehow does not translate well outside the chip. Software and hardware engineering are very different things. It is probably correct to bring-up the fact that many have tried to turn software engineering into precisely the opposite; dragging symbols around and connecting them in schematic form. That approach has failed but for the most trivial educational tools. > Could you imagine the pain of building an entire software product using only assembly code? That’s about how we felt designing hardware. Having done this dozens of times, I don't think it is painful and don't see a parallel between assembly coding and designing electronics. In fact, assembly coding is easy for the professional experienced software engineer. Of course, it is probably close to a nightmare for someone who's never done it or never even studied machine level coding. Ballroom dancing is impossible for me. I am not a dancer. And it should be in a range between difficult and impossible for anyone without the requisite training and practice. So, that's not the right metric. Drawing schematics is easy. Schematics convey lots of information quickly. Function, structure, constraints, implementation notes, support/service notes, fabrication guidelines, etc. Also, they are trivially and instantly easy to understand, gather around and discuss. They present a mental image and state that would require fairly deep concentration to develop if reading a schematic as code (except for trivial circuits, which don't really matter). Schematics, as I said earlier, have survived the test of time for a reason: They work. That's not to say a different approach isn't possible. All I am saying is that I would think hard before attempting something that very clearly few engineers want and care about. For reference, I started life drawing all of my schematics and PCB layouts by hand. I then transitioned to using AutoCAD v1.0 and writing tons of LISP code to make that easier. From there I migrated and used a bunch of tools most experienced EE's have touched: OrCAD, Protel, Mentor, Cadence, Altium, KiCad, Eagle and likely others I can't remember. Oh, yes, I also completed a few layouts back in the day using X-acto knives and stick-on traces and doughnuts on vellum. That was fun. This page shows a number of approaches. I all of these back in the early 80's. https://www.pcbwizards.com/handtape.htm Yes, that's a roll of black tape she is using: https://i.imgur.com/yUgZ5zz.png Schem",
    "originSummary": [
      "The creators of atopile have developed an open-source language and toolchain called atopile to describe circuits using code.",
      "The goal is to abstract electronics effectively and enable the reuse of designs, inspired by software engineers' workflow in hardware design.",
      "The atopile compiler generates netlists and selects components for the circuit, with a current focus on designing PCBs with low to medium complexity."
    ],
    "commentSummary": [
      "Atopile is a tool that allows circuit board design using code, with a focus on automation, collaboration, and component selection.",
      "The article explores the limitations of current electronics design tools and the challenges of converting visual schematics into code.",
      "It discusses the potential for a software ecosystem in hardware engineering, including optimization of component selection, the benefits of a code-based approach, and potential growth in the open-source community."
    ],
    "points": 493,
    "commentCount": 251,
    "retryCount": 0,
    "time": 1707154250
  },
  {
    "id": 39269327,
    "title": "SMS-based Authentication: Companies Blamed for SIM-Swap Attacks",
    "originLink": "https://keydiscussions.com/2024/02/05/sim-swap-attacks-can-be-blamed-on-companies-embracing-sms-based-password-resets/",
    "originBody": "Security Companies embracing SMS for account logins should be blamed for SIM-swap attacks February 5, 2024February 6, 2024 Spencer Dailey SIM-swap attacks continue year after year because companies (that know better) leaned into the awful idea of using SMS for password resets and account logins. These companies include Apple, Dropbox, PayPal, Block, Google, and many others. What is a SIM-swap attack? It’s where a bad guy asks a carrier to port your cell-phone number to their phone. (Carriers are required to port your number easily because of pro-competition laws in the US.) Then, the crook triggers and receives account login info via SMSes from companies and proceeds to steal money and sensitive info from the victim. It happens all the time… Here are just a few of the higher profile instances: Is there a way to stop SIM swap attacks? Yes, it’s simple: Companies SHOULD NOT LET CUSTOMERS LOG IN via SMS, or allow SMS-based password resetting. If SMS 2FA is offered, it must only be if they provide more secure options like Authy or Google Authenticator (and SMS should never serve as a fallback for account recovery). For many years, people in the industry have invariably said something like: “Well… offering SMS-based authentication is better *overall* for customer security, because of its convenience (despite its shortcomings) vs other methods” (such as the far-more secure-able use of email for verification). To that I say: “who are *YOU* to deprive your customers of security?” Defending against targeted attacks must be an integral part of any company’s defense posture. It’s so arrogant to say otherwise, and it boils my blood, it really does. Offering SMS-based logins is a bad idea, and it never had a chance of being a good one. Sending an SMS to a customer is like sending a postcard through the mail. It’s plaintext (not encrypted), and anyone can open your mailbox and intercept/read it (which is what happens in a SIM-swap attack). The protocol was never designed to be secure. Is SMS the best option for password resets? NO! Reseting passwords via an email is far more secure. Is SMS a good 2FA option? No! Apps like Authy or using email are better. Is logging your customer in via SMS ever acceptable? No! [After reading Hacker News comments, let me be clear – I’m not just talking about SMS 2FA, in fact I’m primarily talking about the ubiquitous state of SMS-based password reseting, user onboarding, and account recovery. All are varying degrees of weak. SMS-based 2FA is, when offered as an option alongside stronger 2FA, the least-bad of the weak-security scenarios but is not the focus of the post.] Much of the ire relating to SIM-swap attacks has, understandably, been directed at carriers. Indeed, carriers do a terrible job of securing customers’ phone numbers, and may be liable for that shortcoming. But here’s the thing: carriers’ security has always been bad, it has even been legislated into being bad, and other companies have still chosen to build mission-critical systems on top of that weak link. Despite it being commonplace, it is important to remember that baking SMS into authentication flows was an awful, shortsighted choice made by companies. Despite offering poor security, SMS offers a nearly frictionless way to sign up new customers (think of Uber’s onboarding) and handle password resets, and companies felt they had to match competitors’ adoption of this technique. They dug the hole, pushed us in, and now they must get us out. Companies adopt the naive outlook that, somehow, crooks won’t try hard enough to SIM swap individuals. Clearly the criminals will – even to the point of pretending to be customers at physical store locations. It’s time for them to call it on this experiment. It failed. And I’m sorry, but after nearly a decade, we can call it: efforts to strengthen telephony protocols like SHAKEN/STIR, will never happen. If the willpower had existed in the industry, it would have happened 5 years ago. Promises of protocol upgrades never were (and certainly are not now) a satisfactory excuse to continue to send password reset codes over SMS. Nor would a stronger protocol even stop SIM swap attacks. People are being harmed day-in and day-out, while the industry equivocates. [Note: the EU’s “Sim Verify” initiative is worth a look.] While SIM-swapping attacks are prevalent and headline-grabbing, SMSes are also vulnerable to man-in-the-middle attacks. These are likely carried out frequently by nation states. The fact that nation states can abuse SMS verification may even explain some of the overall inertia in allowing a broken system to remain. If I sound heated, it’s because I’ve been banging this drum for over 7 years. Others have written about it years ago, and yet SIM-swap attacks continue unabated. I’m frustrated because many of these companies talk a big game about putting their customers’ safety and security first. I’m mad because, with all the intractable problems facing tech nowadays like deepfakes (including audio deepfakes that I wrote about here) and disinformation, this is one that can actually be solved, and yet nothing (concrete) is being done. We need a win, and here’s one for the taking! To repeat: If some random person convinces T-Mobile, AT&T, Verizon, etc to port my number, MY DIGITAL SAFETY SHOULD NOT BE PORTED AS WELL. How companies embraced this broken tech Apple: Apple helped seal SMS’ role in password resets and account logins via its keyboard feature it announced in 2018: Automatically fill in SMS passcodes on iPhone . It also allows scenarios where SMS can be used to reset your Apple account. Google: In 2019, Google followed Apple’s bad idea with the same thing for Android, SMS autofill for one time codes. Cloud providers like Twilio/Amazon/Microsoft/Google etc: There is a large industrial complex behind SMS codes. Many companies have profit incentives to continue offering SMS one time codes to customers. Azure, AWS, Twilio, Google, etc. Selling these services is unethical. It’s a fundamentally broken technology, sold as a secure solution. Money management services Unbelievably, SMS reset/account login functionality is completely ubiquitous even when it comes to your money, as well as SMS 2FA and account recovery: Wells Fargo, Cash App (Block), Robinhood, Schwab, Paypal, Bank of America, etc etc. Again, these are SMS options offered as a way of “verifying that it’s you”, something that SIM-swapping crooks love to hear. Also, never carelessly change your phone number, you’ll be locked out of your PayPal! Basically every other company at this point: From food ordering services to social networks and even data storage firms like Dropbox — SMS is unfortunately, by default, a way to reset your account. If there’s even a way to turn it off, it’s incumbent upon you the user, to go in and opt out –service by service– and disable the crappy tech. Many services don’t offer an opt out. Customers think they like SMS reset options Customers don’t understand the broken nature of SMS resets. It’s not their job to. They appreciate that it’s more convenient than resets via email (an actually-secure option) or log in 2FA codes via 2FA apps like Authy. iPhone’s SMS autofill is oftentimes (dubiously) heralded as the best thing in iOS. The issue is: it’s not the customer’s job to understand whether systems are secure, it’s tech companies’. And tech companies have failed, leaving all of their customers exposed in the process. Hopefully a combination of lawsuits and legislation will eventually change the status quo. In the meantime, companies need to be brave and call the situation for what it is: a complete shit show. And then roll back their support of SMS verification services. A few more things: There have been really fantastic comments on Hacker News: Traveling in an area where you don’t get SMSes? Shucks, you are locked out. Are you a customer of a bank like Bank of America, which requires SMS 2FA be enabled for any 2FA to be enabled? That’s broken! It’s only your money for crying out loud! Locked out of Viber because you changed numbers? Damn! Citibank “requiring SMS authentication to change the phone number on the account“? Not only is that silly, but that’s a bank that safeguards your hard earned cash! (One that happens to have just been sued by the NY AG for taking inadequate precautions to safeguard users from fraud and online scams, by the way.) Does your carrier stick you with SMS roaming fees? You are paying for shit security. Are you in a place where, if you forget to refill your balance, your SIM gets blocked, denying you SMS? Too bad all of these companies force you to have a SIM :/. Did you know that, as of Oct. 2023 guidance – NIST has harsh guidance when it comes to using SMS or phone calls for user identification? I did not, pass it on! Someone who works at banks in the EU notes that thankfully using SMS there remained more expensive than in the US and it never caught on as much, for SMS 2FA, which is “liable to both security breaches and locking out users”. All of these commenters testify in a way I never could (with any authority at least) to the myriad ways you can be screwed as customers because of companies’ misguided decisions regarding SMS. It all hammers home the same point from above: the state of SMS-based verification in the industry is truly a shit show. And companies must be brave, suck it up, and roll it back. SMS is not cool anymore. Love your customers, don’t hurt them. Pass it on! Please share this article wherever you think it may make an impact. It is insane to me that SIM swapping attacks are entirely preventable and yet allowed to happen by flawed choices regarding the “convenience vs security” tradeoff. Please drop a link in Slack/Teams, or post to Reddit or wherever you feel that consumers or builders may be best informed. Seriously, I don’t have ads or monetize this site at all — these words are literally passion spilling out on to the page. Please share this with a buddy and lets try and change things. SIM swapping attacks are preventable. Robust Identity services are more important than ever in the age of deepfakes. Moving away from telephone-number-based identity services is a major and necessary step in realizing robust means of customer identification, which is even more important these days. The era of old school KYC (Know Your Customer) enforcement is over, with fake ID AI services going mainstream. Throw in “voice print” identification services, which have been used for years by financial companies, ISPs, and more – as an awful trend that won’t be useful in the wake of deepfake audio and determined hackers. Check out my post on this from 2021. In any case, we should move away from unencrypted, SIM-swap-prone verification identity services like SMS. Many ransomware attacks are downstream of SIM-swap attacks Another seemingly intractable problem facing IT around the world is ransomware. SIM-swapping attacks represent a significant vector for compromising a company’s network. Again, rolling back support for SMS logins could take a bite out of the ransomware scourge. One HN commenter mentioned the “SIM Verify” initiative in the EU, where companies relying on SMS can at least check to see if a SIM had recently been ported. That’s something, and we’ll see if it goes anywhere, but if the SHAKEN/STIR rollout has taught me anything, changes like this may reach the US many years from now. Finally, a dedicated home to this question I created a site at a permanent URL that bluntly answers the question “Is using SMS for logins a good idea?”, for sharing with people in your industry.",
    "commentLink": "https://news.ycombinator.com/item?id=39269327",
    "commentBody": "Companies embracing SMS for account logins should be blamed for SIM-swap attacks (keydiscussions.com)390 points by spenvo 9 hours agohidepastfavorite269 comments zaptheimpaler 7 hours agoBefore this new wave of SMS trash, we just had TOTP codes that 1password could auto fill for me on any device in any location. Now i need to pull out my phone constantly and pay for international roaming or setup SMS forwarding to travel even if I don't need the number. Yay security! If the argument is that phone number can always be recovered from real world identity, link the damn authenticator app to SMS instead of having to hand out your phone number to every company in the world. reply Groxx 7 hours agoparentThe problem is that your authenticator app doesn't give them access to a relatively stable, cross-site/app/etc identifier that they can sell for advertising peanuts. reply fastball 6 hours agorootparentAlso an identifier that is much harder to create bots/spam with, as phone numbers are harder to come by than email addresses. reply Frost1x 5 hours agorootparentAlmost counterintuitively I deal with more spam SMS than I do email but that’s probably less a factor of actual volume and more a factor of the need and sophistication of filters for both services. reply masklinn 2 hours agorootparentIt’s likely also a function of the market / location / network incentives. May own anecdote is that I almost never receive spam sms despite having nothing in place beyond whatever my service provider does. Spam mails make it through two+ layers of filters (service provider + my own) more often than I get spam SMS, and I have to trawl the wasteland that is the spam box once in a while to ensure important mails have not been missclassified. reply nicbou 3 hours agorootparentprevThat's why my banks use their own apps as 2FA factors. reply JumpCrisscross 7 hours agorootparentprevRequire a phone number for account creation and support TOTP. Win-win. reply lcnPylGDnU4H9OF 6 hours agorootparentIt’s a loss from the business’ perspective. They could support 2FA with SMS and check a box; to additionally support it with TOTP would only be additional cost -- albeit with the bonus of “doing it right”. Unfortunately, that’s an abstraction which a lot of businesses consider to be achieved when they can check the box. reply nikau 7 hours agorootparentprevAlso average Muppet consumer can't manage it reply bugbuddy 6 hours agorootparentNot true. If we make Yubi keys cheap enough (below $5) then everyone would want them. Everyone is already carrying around keys, they won’t mind 1 more key. Why can’t we make yubi keys cheaper? reply hedora 6 hours agorootparentPocket space is finite. There's no way I'm carrying a yubikey unless I can jam it in my laptop USB port (defeating the purpose of it) and forget about it. reply bootlooped 6 hours agorootparentThat wouldn't defeat the purpose of it. reply scrose 6 hours agorootparentprevA Yubikey used in that way is still more efficient and secure than every other option. Someone would need to physically take your laptop, unlock it, and get your account passwords before they could use your yubikey to login to accounts. reply bofaGuy 5 hours agorootparentThen why not just store the encrypted credential on the device itself? Would that be what passkeys would be? reply numpad0 3 hours agorootparentPasskeys is like embedded Yubikeys, or, Yubikeys are like external passkeys. The point of passkeys that the key is kept inside a separate secure computer running secure blobs, so user codes can't touch it. That sounds sketchy but contactless payments using similar embedded secure computer has been fine so this should be too. reply crote 5 hours agorootparentprevTheft: A $2000 laptop is an easy target for anyone with sticky fingers, and so is a $1000 smartphone. A Yubikey has essentially zero resale value, so you will not lose them due to random theft. Durability: If you drop your smartphone, there's a pretty good chance you'll shatter the screen and buy a new one. You can play tennis with a Yubikey and it'll be fine. You can run it through the washing machine and it'll be fine. Longevity: Laptops and smartphones generally only have a 3-5 year lifespan due to battery degradation, and many people will want to swap it for one with more storage or whatever anyways. A Yubikey will essentially last forever, and if you stay clear of the insanity that is Passkeys its Webauthn element can support an infinite number of websites. Portability: I have a smartphone, a work laptop, a home laptop, and a home desktop. My Yubikey has USB and NFC, so it can trivially be used with all of them. Individually enrolling each device would be a nightmare, and having the credentials sync is a bad idea from a security perspective. Security: If your device gets compromised, it's pretty much game over: the attacker can now log in to all your accounts, any time they want. With a Yubikey I have to physically insert it and tap the button for each login - which is relatively rare because active sessions don't tend to expire. This means I would have to actively participate in a mass compromise of my accounts, making it way more likely to be noticed. reply freddie_mercury 3 hours agorootparentprev$5 is cheap where? Most internet companies are global and have little desire to cut off customers in developing countries, since that's a major area of growth. $5 in the US is roughly equivalent to $20 in my country, when you adjust for purchasing power parity. We have over 70 million people who use Facebook and Youtube daily. If rich Americans won't pay $20 for a Yubi key (and they are currently $25) why should we be expected to? reply x0x0 3 hours agorootparentprevIt has nothing to do with cost. Using a yubikey says, specifically, that if I lose this little device and the bypass codes, that I have presumably stored on encrypted storage in a way that doesn't require the yubikey to access, then I want it to either be impossible or exceedingly difficult to recover access to this account. Very few people actually want that, and if yubikeys become widespread, there will be a wave of people having tantrums because their yubikey is lost and the account is unrecoverable. If it isn't extremely difficult to recover an account in the absence of a yubikey and the loss of the bypass codes generated on enrollment, then there's no point to them. I've run a b2c website. There is a shocking percent of internet users -- I'd estimate 20% -- that cannot reliably tell you their email address (5% that literally can't, and another 15 that can't reliably). Those users having yubikeys would be an utter disaster. reply lukeschlather 3 hours agorootparentIt's absolutely a problem with cost, though a little bit with UX. If YubiKeys cost $5, it would be reasonable to have 3 of them, and you keep on your keychain, one at home, and one somewhere else. The UX problem is that you would want a way to enroll a YubiKey that you don't physically possess, but that is a solvable problem. The bigger problem is that a large number of sites don't implement MFA properly, and don't allow you to enroll multiple MFA devices. This really could only be fixed with regulation that clearly defined MFA, so there would be consequences for improperly implementing it. reply x0x0 3 hours agorootparentI promise you there is a significant percentage of people that would fumble enrollment; you handwaved away a giant problem (multiple enrollment, not present); and many people would put them all on the same keychain. In the politest way possible, I question whether you've interacted with the modal user. edit: I can try to dig up the article, but here's the precis: 5-ish years ago, google briefly changed their search results ranking. Lots of people were logging into facebook by searching facebook, instead of typing facebook.com, then following the top result. Some other site briefly was the top result when searching for google. That site got a wave of users submitting help requests because they couldn't log in with their facebook credentials, and accusations of subterfuge or wrongdoing because their accounts were deleted. I think it was pinterest, but I may not remember correctly. Either way, it looked nothing like facebook and didn't use blue. That's what a significant fraction of internet users are like. reply ern 3 hours agorootparentprevThere is a shocking percent of internet users -- I'd estimate 20% -- that cannot reliably tell you their email address (5% that literally can't, and another 15 that can't reliably). My email address is firstname.midddlename@.com I get a dozen emails a week from companies and government agencies trying to reach people with the same first + middle name combination from around the world. People seem to think they automatically get an email address with their name provisioned or something and they just sign up for accounts and services using that combo. reply anonzzzies 5 hours agorootparentprevI have and use yubi keys; they are annoying to set up and use compared to sms. No one will want that outside a few geeks. reply xpressvideoz 5 hours agorootparentprevNo freaking way. I don't use YubiKeys not because they are expensive, but they are less convenient than other options. reply irjustin 5 hours agorootparentprevNo I promise you they won't \"want one\". RSA keypads were an example. Absolutely free. Hung on keychains. Work well in that it was \"secure\" and worked, but an absolute nightmare for the banks to manage. UX was equally terrible (sure Yubikey isn't that). The only way to mass introduce it is require multiple key entites to push and collaborate like your bank + phone provider to push it out for free. Yubi keys are a logistical nightmare for my parents. SMS is not. For my parents, sticking to something in the phone is good. reply rlt 6 hours agoparentprev> we just had TOTP codes that 1password could auto fill for me on any device in any location Doesn’t using your password manager as TOTP code generator reduce the number of factors back to 1? reply artimaeis 5 hours agorootparentIf the attacker is targeting your 1P, then yes. If the attacker got a list of passwords from a leak and your password was on it, the 2nd factor provided by the TOTP will still save you. So, it just depends on your threat vectors. I’d rather people I support keep unique passwords alongside TOTP in a manager they’ll actually use than skip or use SMS TOTP because of a vague concern about targeted hacking of their manager. reply lolinder 5 hours agorootparentIf you're already using a password manager with secure randomized passwords, you're not vulnerable to credential stuffing unless that specific service had a breach. I suppose TOTP may still protect against unsophisticated phishing, but only as long as the attacker doesn't phish a TOTP code at the same time and pass it straight along to the service. Are there other threats that TOTP-in-password-manager can protect against that the randomized passwords don't already? reply Groxx 4 hours agorootparent>Are there other threats that TOTP-in-password-manager can protect against that the randomized passwords don't already? tbh the UX problem of 2fa for \"I use random passwords and am not vulnerable to credential stuffing\" users is a pretty big reason to stick TOTPs in your password manager. Security is always a series of trade-offs, and 2fa brings some hideous trade-offs in many sites (well over half only allow one at a time, for example, and then you lose access permanently). TOTP with a standard like this lets you choose, rather than the site choosing for you. reply 8organicbits 2 hours agorootparentprev> unless that specific service had a breach Right, and if an attacker can dump password hashes they can likely dump TOTP seeds as well. With that level of database access the attacker may be able to steal all your info from the impacted service, so talking about the password may even be a distraction since all your data is already stolen. reply klempner 5 hours agorootparentprevIn practice the only widespread attack that either TOTP or SMS authentication help with is credential stuffing, and if you use a password manager to use unique passwords on each site you're not susceptible to credential stuffing to begin with. reply Symbiote 2 hours agorootparentBoth provide some protection against phishing sites, where the phisher needs to maintain their access. reply Alpha3031 5 hours agorootparentprevSome password managers do offer the option of challenge-response from a hardware key, but technically speaking the password manager vault file can be considered \"something you have\" so long as you store it securely, like your SSH private key. reply crote 5 hours agorootparentI'd have to disagree. The problem is that the vault file can be copied, which means this is now \"something you and your attacker have\". Even worse, it's not just the (probably encrypted) vault file: if your computer ever gets compromised, it is trivial to wait until you unlock the vault, at which point they can extract the now-plaintext TOTP secrets. The way I understand it, the \"something you have\" factor is something which is intrinsically only a single item: either you have it, or you do not. If it can be copied, one of the copies could be compromised without you noticing - and because it's a copy you wouldn't even be able to revoke it without changing your own token too. reply RaisingSpear 40 minutes agorootparent> if your computer ever gets compromised If that happens, nothing will save you. The malware can just grab your session tokens whenever you log in, then do whatever it pleases. reply lolinder 5 hours agorootparentprevYes, it's something you have, but it's not a second factor if you're storing your (randomized) password in the same place. If you do that it's just two redundant checks that you have access to the same single password manager vault. reply prmoustache 3 hours agorootparentWell in the context of mobile login so is TOTP, push based microsoft auth and other kind of mobile based shit. I don't know anyone who buy a second smartphoe to make it sure 2FA is on a separate device. reply fulafel 5 hours agorootparentprevMulti-factor isn't an end to itself, one strong factor is fine for most things. If your pw manager is good enough to not get tricked by phising, that's already better than most manually used MFA. reply mook 5 hours agorootparentprevWouldn't you still need the password database, plus the password or whatever used to open that database? The two factors are related though (a good keylogger should be able to get both). reply WWLink 5 hours agorootparentprevYou could always use a different password manager or different buckets. Both the apps I use (one for TOTP and one for passwords) can do both lol. reply eru 4 hours agoparentprevI agree with most of what you say, however: > [...] pay for international roaming [...] I don't remember ever having to pay to receive SMS abroad. Is that a common feature with the plans where you live? (I mostly have experience with pre-paid plans from Asia, Australia and Europe.) reply reedciccio 3 hours agorootparentAmericans screwed up mobile phones since the beginning: they pay on both ends, to receive and to make calls and sms. reply rgbrenner 7 hours agoparentprevBefore this new wave of SMS trash, we just had TOTP codes SMS 2FA predates cell phones. First SMS 2FA was AT&T in 1996 using pagers. The first draft of the RFC for TOTP was written in 2008. Google Authenticator came out in 2010. reply minitech 7 hours agorootparentAnd TOTP predates “this new wave of SMS trash”, when every service actually started using it. reply ensignavenger 6 hours agoparentprevI use my Google Voice number for everything because I can't trust I will have the same number if I change carriers (I have found the porting numbers between MVNOs can be hit and miss) and because I sometimes travel internationaly. Now, stupid companies are demanding a phone number, and blocking Google Voice from being used... reply AnonC 6 hours agorootparentGoogle Voice (the free service) has its own pitfalls, which I believe make it a very poor choice to use for online accounts. I’m speaking from personal experience. If you happen to not use it for a little while, Google Voice will send an email with minimal notice (with Murphy’s Law, this will be during a vacation break) that the number will be deactivated. Once that happens, you cannot reclaim that Google Voice number using the same linked phone number. You have to get a new phone number that has never ever been used with Google Voice and then try to link it. Even then, Google Voice will send the OTP and make it seem as if the linking worked but will show as unlinked (and the Google Voice number unavailable) after just a minute or two. You’ll have to retry with another number over and over again until you start banging your head against the wall. After maybe a few weeks or several weeks, that Google Voice number will not even show up for reclamation. Google Voice is a total mess, and as a “free” consumer service that Google has shown little interest in maintaining and supporting, you don’t get any kind of support or help whatsoever. My sincere advice (if you’re a free Voice user) would be to delink your Google Voice number from all critical services. Get a real phone number for which you have the ability to get customer support. reply alpaca128 1 hour agorootparentprevTrusting Google for anything is a lot riskier than trusting a carrier once in many years. Their own internal teams as well as game studios didn't know about Stadia's end until the day it happened, what makes you think they'll treat you better with an unpaid service? reply prmoustache 3 hours agorootparentprev> I use my Google Voice number for everything because I can't trust I will have the same number You can trust google they will let you use forever and won't block your account anytime without warning though. reply kurthr 6 hours agorootparentprevDon't worry, soon Google Voice will be abandoned by tehGoog. (Perhaps this is just dread since I use it for the same purpose) reply WWLink 5 hours agoparentprev> Before this new wave of SMS trash My favorite is it's often paired with \"passwordless\" trash lol. Why can't I just give my whole fucking credential out in 1 action. What's this nonsense where I have to enter my username, THEN wait for the page to load, THEN click \"send verification email\" or \"send code\", then half the time they want to SMS me and have me enter another code lmao. reply iacvlvs 3 hours agorootparentI use 1password with Fastmail integration to create unique email addresses for each login. This new “sipping from thimbles” approach to authentication breaks that because iOS and/or 1pass don’t recognise it as a login until the password screen, so I’m swapping and searching and copying and pasting just to log in. I viscerally hate that sort of user hostile design of the auth/login. reply EVa5I7bHFq9mnYK 2 hours agorootparentprevAnd don't forget to solve 10-stage captcha before eveey page load! reply gruez 7 hours agoparentprev>Now i need to pull out my phone constantly and pay for international roaming Weird, all the carriers I used either have free international roaming (at least for receiving text), or have wifi calling which allows me to use my phone as if I'm on the home network anywhere with an internet connection. reply ensignavenger 6 hours agorootparentI am occasionally out of the country for more than a month... I usually pause my phone plan because I don't want to pay for a service I am not using. Sometimes I even get a different number when I return and restart my plan. That is why I use Google Voice, because I can use it over wifi or a data only plan, and the number doesn't change. But now, some stupid companies are blocking Google Voice from being used. reply lxgr 6 hours agorootparentprevMine doesn't! And though the one I used before did, I usually have a cheaper local SIM in my phone for data use when I'm traveling, and I'm not swapping SIMs just to authenticate to some company that hates its customers. reply daveoc64 5 hours agorootparentprevAs a European, the idea of paying to receive a call or text is alien to me, but I understand it happens in the USA. I'm pretty sure it's illegal for an EU network to charge for receiving a standard SMS or MMS - even while roaming. I can therefore receive an SMS OTP in any country and won't pay a penny. reply rootusrootus 5 hours agorootparent> I understand it happens in the USA. False reply jeromegv 6 hours agorootparentprevThank you for your anecdote. However your personal experience doesn't reflect everyone. Many people don't have free international roaming, in fact mine only has roaming for US (I'm in Canada) and for zero roaming options available outside of North America. reply Symbiote 2 hours agorootparentOutside North America, receiving text messages is always free. Receiving calls isn't necessarily free when roaming. reply davchana 6 hours agoparentprevInuse a simple APK which makes http post request on very incoming SMS. That post request is processed by my own Google apps Script to send it to my own telegram bot. When I travel where my phone will not work in that country, my wifi connected devices get OTP right away, in about 5 seconds. reply 2Gkashmiri 6 hours agoparentprevIn India your Sim card stops working if you do not recharge ebery month and after 2nd month, the number gets blocked, after 90 days the number gets canceled and recycled. The going argument is, WhatsApp if your number gets unused for 90 days doesn't let you reset password or something so its all fine. Then its a matter of submitting a written application with the bank to change your mobile number so its all fine reply lakpan 2 hours agorootparentA few countries in the area have such a short length unfortunately. I’m lucky to have my European SIM card that I can top up once every 12 months. And even if they deactivate it after 13 months, I can recover it within the successive 12 months if I remember correctly. reply davchana 5 hours agorootparentprevI recharge my airtel with Rs 1700 something, which gives me a 365 days validity, without need of any additional recharge (plus some GB data everyday). reply 2Gkashmiri 3 hours agorootparentthat is.......... a lot to spend in one go reply samarthr1 1 hour agorootparentIf you can afford a phone, you can afford 1700 for a year. If not, EMIs are a thing. reply LouisSayers 6 hours agoprevSMS for any significant action on an account is terrible. 1) Phones can be lost or stolen 2) People move country 3) SMS attacks 4) Phone numbers get reused 5) Users must maintain a paid phone plan For the love of science, DO NOT tie accounts to phone numbers!!! -- edit -- I updated the first line to clarify that I'm not talking about one-off notifications etc. reply lakpan 2 hours agoparent1) By definition, if your 2FA device gets stolen, you’re screwed anyway. Goodbye Authenticator. At least with SMS you can get the same number by contacting your carrier. 2) Roaming. Often free to receive texts abroad. 3) True 4) True, but it’s easy to keep it active assuming you at least have data on it 5) True, but it can cost peanuts with the right setup. I’m holding onto my European and Thai SIM cards with less than $5/year. My Google Voice number is free since 2009. I agree I’d just prefer using Authenticator and Passkeys, but let’s not lie about the advantages of SMS. reply pitaj 1 hour agorootparentGoogle Authenticator backs up to your Google account now, somehow. Not sure exactly how that works. reply lakpan 0 minutes agorootparentThe problem is logging into your Google account without your 2FA device or phone number. The answer in all these cases is having more than one option enabled. I just recently tested my Google and Apple login simulating a loss of phone and computer. It was tough but there are options (e.g. Apple lets a friend be your full 2FA, so you can even recover encrypted data) al_borland 5 hours agoparentprevI have a huge issue with the phone becoming one’s identity. I often see couple’s using each other’s phones and knowing each other’s passcodes. I’m not sure I could ever trust someone that much. I don’t think I’d even give my passcode to my own mother, and she’s never given me a reason not to trust her. The worst part about it all is that it’s not opt-in. They just randomly start using SMS as 2FA. If I were to change phone numbers, I’m not sure what I’d even do. How can I change to a new number without control of the old number to get into my account? What happens if I miss one, because they randomly decide to use 2FA on an account I didn’t think to update? It’s a really bad system all around. reply sibit 6 hours agoparentprevI don't know. I like when my ISP or power company let's me opt-into texts about outages and provides periodic updates (as long as you can reply STOP). I was on a 2 week camping trip and a nasty storm rolled through my home state. Power went out for 5 days and I wouldn't have known if it wasn't for the SMS notifications. I immediately cleared out my fridge and freezer when I got back. reply sdf4j 6 hours agorootparentThat’s not the use case in discussion. reply sibit 6 hours agorootparent> SMS for anything other than one-time use cases is terrible. I can agree it's unacceptable for security while also disagreeing with this statement. reply LouisSayers 6 hours agorootparentI've updated the first line to clarify what I was meaning here reply LouisSayers 6 hours agorootparentprevNotifications are fine, what I mean is more things like verifying it is your account, forgot password etc. Anything tied to material account actions shouldn't have anything to do with SMS. Flight delays or notifications of works in your area etc won't lead to account takeovers or denying access to your account - but the way many companies use SMS can potentially lead to this. reply lgkk 5 hours agoparentprevI think it’s fine as long as an email is always collected. This way if the phone is compromised your email is still there. As far as convenience goes it is convenient in actual practice as an end user. I’m sure even if 1% have this issue that’s billions who are not. It’s cheap and it’s convenient. Your phone gets the message and autofills. You don’t need to switch apps to check email or something. And your account will always be recoverable as long as your email isn’t compromised. If you lose your email I mean that sucks. But that happens anyway and it’s why people should rotate passwords and set up MFA. Security can never be 100%. That’s just a fools errand. It should be convenient enough and secure enough that it works for as many people as possible. Literally everyone else outside of HN doesn’t even care or understand. They don’t need to. Just use the apps to do your thing and move on. Let the nerds handle the backend. reply jojobas 6 hours agoparentprevWhat's science compared to the \"requirement\" of getting a valid phone no-account link to sell to Google and Facebook? reply wslh 7 hours agoprevThere was a big issue with Payoneer's SMSs in Argentina under Movistar. I tried to rise the issue here in HN but got unnoticed. There is an insightful tweet [1] in Spanish that is translated as follows: \"\"\" Well guys, the payoneer mystery is solved. #PayoneerHacked - The attacker compromised the gatway SMS used to send the 2fa to Movistar customers (the platforms use this to sneak the cost) - The attacker saw 2fa messages passing from Payonerr to a Movistar phone number but had the problem of not knowing the email of the Payoneer user to change the password and make the transactions. - The attacker, to discover what email was behind each phone, set up a phishing site to try to take ONLY THE EMAIL from there and with the email + the phone + the 2fa that accessed the compromised SMS gateway in real time, he was able to change the password, access the account and send money since I kept reading the 2fa that arrived on the Movistar phones. - That's why the victims saw several real SMS with 2fa coming during the night that emptied their account. - Even if Payoneer customers had fallen for phishing, they would only have had one 2fa stolen, and not all that is needed to log in, add an account and transfer. This need makes it evident that the commitment to the SMS gateway existed. - The victims of this scam lost their money because the last mile of the security stack was compromised. Be careful, because Facebook, Twitter and others share the same gateways to save money on SMS. Here I leave a screenshot of the SMS that arrived during the early hours of the morning to a victim and that the victim was never able to share in any phishing and that were necessary to empty them. (whatever you read in the media... fruit, lots of salad and little sauce. here's the post) Thanks to everyone who cooperated. \"\"\" [1] https://twitter.com/julitolopez/status/1748440685743587811 reply qingcharles 7 hours agoprevIt also sucks if you lose your phone number. I haven't been able to log into my primary Google account for many years because while I have the username, the password and the recovery email address (and all the emails are forwarded to me), I no longer have the phone number associated with the account, so clearly I'm trying to break in. reply AnonC 5 hours agoparentGoogle is really atrocious in this respect. It won’t even use recovery email addresses properly. The only solution is to move back to an IP address range that seems like your original “home” location and pray that it works. I have some choice words for whoever in Google thought not allowing account access or recovery is a good thing. reply Pufferbo 7 hours agoparentprevOr if you’re just traveling. I’ve been logged out of accounts while abroad and with no access to SNS. reply mixmastamyk 7 hours agorootparentOr refuse to give them a phone number. I lost access to two accounts where they now demand it. Even have the audacity to send me an email with “someone tried to log in with your username and password!” Yeah, that was me clowns. :-p reply diego_sandoval 7 hours agorootparentI'm in a similar situation with LinkedIn. Out of nowhere, they locked me out of my account, then they asked for my phone number, and I had to put in a code received through SMS. But that was not enough, because then they asked for a national ID card (the gall!). Of course I did not send it. However, I kept trying to log in with the password and SMS code for a couple of days hoping that the ID requirement faded away, and now they say that I \"have reached the maximum number of attempts. Please try again at a later date.\". Well, duh. So, now I have a ghost LinkedIn account with my face and my data that I can't even delete. I'm seriously thinking about asking a bunch of people to mass report my account for racial hate speech or something so that at least it gets deleted. reply mixmastamyk 7 hours agorootparentWell, keep in mind almost nothing is deleted any longer. Only a deleted_at column is populated in the database, which prevents it from being listed by default. But data is not deleted, and those accusations might last forever as well. This is where being an EU resident would be handy. reply amatecha 6 hours agorootparentYeah, it sure would be nice if the same nations that deeply/fundamentally benefit from being epicentres of cutting-edge technology would actually do something to protect the rights of people who are reliant on and are affected by said technology. reply ranger_danger 7 hours agorootparentprevnone of my google accounts even have phone numbers, and I've never been asked for one... reply amatecha 5 hours agorootparentYeah, that's what's especially insidious about it. Until you attract the eye of Sauron by somehow setting off whatever unknown security trigger (which btw will never ever be disclosed to you), you'll never notice just how quickly everything can be taken away without any recourse. Everything seems just fine, doesn't it? Until it isn't. reply hsbauauvhabzb 3 hours agoparentprevI swear this is a bug, the recovery email is supposed to remove the need for sms auth. But google have no help desk or ability to report bugs. Shame on you google. reply hedora 6 hours agoparentprevOnce I was in a situation where I could either have wired ethernet or cell service, but not both (it was a 30 minute drive to cell service). There was no way to log into my Google account because it decided my laptop was suspicious (due to the strange IP address, probably). When I got back to civilization, I turned off Google 2FA, and will never turn it back on, at least for personal accounts. I would rather drop my usage of their services than deal with their account login bullshit. reply diego_sandoval 8 hours agoprev> [Customers] appreciate that [SMS reset is] more convenient than resets via email. Anecdotally, I'm annoyed every time I have to log into a Google account using phone verification, because I have to stand up from my desk and find my phone (which sometimes is in a different room) in order to receive the call/message with the code. TOTP is much more convenient in comparison. I don't have to stand up from my desk, because I store the codes in KeePassXC. reply kalleboo 4 hours agoparentIn the Apple ecosystem, the SMS syncs to your Mac, Safari detects the code and autofills it in the web page, and then it auto-deletes the SMS when you're done for you. It couldn't be more seamless. reply rrr_oh_man 2 hours agorootparentWhich, ironically, requires you to forever \"opt-in\" to 2FA on your Apple ID. reply garciansmith 8 hours agoparentprevYou can click the \"try another way\" link, which will allow you to use a TOTP code (which they call the \"Get a verification code from the Google Authenticator app\" option even if you've never used Authenticator). reply AnonC 6 hours agorootparentI don’t have experience with TOTP on this, but I’ve seen that the “try another way” doesn’t even work with a recovery email address and a code sent to it. Google seems to make it almost impossible to login if you move away from your “home” location, unless perhaps you use its apps and are already logged in. reply toomuchtodo 8 hours agoparentprevCreate a passkey on each of your devices. https://www.google.com/account/about/passkeys/ https://blog.google/technology/safety-security/passkeys-defa... Sites that support Passkeys: https://passkeys.directory/ reply chrisfinazzo 6 hours agorootparentExtra security is welcome, but I'm simultaneously terrified that I'll somehow get locked out of my Apple ID or main Gmail account. Everything I read about Passkeys says this scenario is 100% impossible, as it's based on biometrics and no longer using a text string that can get lost, but I'm still nervous AF. I've had to do the \"reset a password that's behind 2FA\" dance before and it makes me want to crawl in a hole and die - super duper scary. Somebody tell me to chill out. reply hedora 6 hours agorootparentprevHard pass. What if I lose all my devices? (Except a fireproof offsite box with a piece of paper containing most of my passwords in it.) More realistically, what if Google decides to disable my account, and holds my passkey database hostage (which they can, by design)? reply toomuchtodo 5 hours agorootparentNote I said “each of your devices.” Even if Google locks you out, they are all still on at least one of your devices (if not more). My passkeys are shared with family members in iCloud (where they are synced to) for bus factor. I don’t recommend using Google for any consumer services if you can avoid it, especially syncing your password/passkey database, as there is zero support if something goes wrong. reply janpieterz 5 hours agorootparentThere are stories of Apple locking users out of their iCloud accounts. reply toomuchtodo 5 hours agorootparentAnd all of your passkeys should still be on each device in such a case. It’s sync, not a singular vault. reply Aerbil313 1 hour agorootparentprevCan you provide source? I've never seen Apple locking someone out of their account à la Google, only rare dumb user errors in the system clearly designed to effectively prevent them. reply worthless-trash 7 hours agorootparentprevA lot of companies still mess up passkeys, Allowing them only as a 1:1, using one terminates the session of another, or in some cases invalidates the previous passkey entirely. Its implementations specific I'm sure, hwoever its not as straight forward as one would hope. reply lxgr 7 hours agorootparentAlso a favorite: \"Your browser does not support Passkeys\". It sure does, which these horrible sites could easily verify by invoking the single line of JavaScript [1] to learn as much, instead of assuming \"Firefox -> must be unsupported\". Absolutely infuriating. [1] https://gist.github.com/miguelmota/ad833d2e6f024a7189f803664... reply aiisahik 7 hours agoprevUsing SMS makes PERFECT SENSE for the online service provider. The following are very similar but separate goals: 1. proof of account ownership (person attempting action has ownership of account) 2. limiting accounts created by non-legitimate users SMS is a very effective for (2) because few people are going to have access to 100 different phone numbers. Having a cell phone number also typically involves a personal process that requires things like your address, passport, SSN, etc. There are hoops to jump through for this. Companies rely on SMS because they can outsource the KYC process to cell phone companies. They are not doing this to have the most optimal or secure solution for proof of account ownership. People who continue to complain about this clearly has never had to make this type of auth decision for a company involved in regulated or financial services. reply aikinai 7 hours agoparentYour point is completely orthogonal to account takeover. You can require a phone number to create an account and not allow SMS to the number to takeover the account. reply AnonC 6 hours agorootparentWhat happens when the owner of the number discontinues the phone service, loses the number and the same number is give to another customer who then tries to register for an account on the same platform? Phone providers may recycle numbers in as short a period as a few months. reply rrr_oh_man 2 hours agorootparent> Phone providers may recycle numbers in as short a period as a few months. Then, I guess, the account on that German home automation online forum was maybe not that important, after all. reply pnt12 1 hour agorootparentSuch a strawman. People get locked out of accounts with important stuff for them all the time. Let's demand more of tech companies who have the means to do proper security , instead of bling user mistakes. reply rrr_oh_man 45 minutes agorootparentNo, I’m not blaming the user. Look at this from the other perspective: I have an apartment, a vacation home, a chicken coop, a shed with old tools, a car, a bank deposit box. Do all of those things need a blockchain-enabled SuperDuperLock 3000™ with the patented Forensic Upgrade Crypto Key™ technology? Not really. This is how I look at accounts. Somebody stealing my bank account? Okay, that would suck. Somebody breaking into the shed and stealing that old broken Toyota diff lock actuator I swear I'm going to fix at some point? Please. reply hedora 6 hours agorootparentprevWhy does the service provider care about account takeover, from a financial perspective? They can always reset the password on their end, given proof of identity (if the account matters). reply romwell 5 hours agorootparent>Why does the service provider care about account takeover, from a financial perspective? Indeed, caring in any way about users of your product or service is merely a liability and a cost center. reply rrr_oh_man 2 hours agorootparentI honestly don't want that type of overprotective caring that cares so. much. about you that it restricts you in meaningful ways. reply lxgr 7 hours agoparentprevJust because I understand precisely why companies do it doesn't mean I need to be happy with it, does it? By the same logic, you could justify companies tracking their users and selling their personal information: It makes money, and making money is an important part of running a business! reply Terr_ 6 hours agorootparentOr: \"Robocalls with fraudulent caller-IDs make perfect sense for the companies doing them...\" reply gruez 6 hours agoparentprev>(2) because few people are going to have access to 100 different phone numbers There's a plethora of sms verification providers where you can pay a trivial amount (eg. 50 cents) per verification, and have tens/hundreds of phone numbers available. This isn't stopping anyone who's mildly determined. reply rrr_oh_man 2 hours agorootparent> There's a plethora of sms verification providers where you can pay a trivial amount (eg. 50 cents) per verification, and have tens/hundreds of phone numbers available. This isn't stopping anyone who's mildly determined. But that's the point: If you're really determined, nothing's gonna stop you. How much on the freedom vs. restriction scale do you want to get pushed to the right for \"security\" before it's too much? Or is it okay, because it's not inconvenient to you? reply lxgr 6 hours agoprevWhat I hate most is when companies insist that my (Google Voice) number \"can't be used for authentication\" or, even more crass, \"isn't a valid phone/mobile number\". Some have even done this after initially allowing me to sign up using it, changing their policy sometime after I've signed up, and I usually only notice when I end up locked out of my account. Fortunately it's mostly been store apps or payment services that I can just avoid going forward, since they clearly don't value my business, but I'm concerned that one day, my bank will do the same and just lock me out of my account. reply Liquix 6 hours agoparenthoovering up users' phone numbers for profit is so widespread because - everyone has a phone - most people rarely change their numbers (if ever) - many people are more likely to give out their phone number than their social security number they couldn't care less about the security of your account or the fact that it's a valid number you control. they want the number that will uniquely identify you and already resides in the db of whichever adtech company bids the highest for your data. reply AnonC 6 hours agoparentprevBased on my experience with Google Voice, I think of not allowing Google Voice as a positive that could help people. I’ve written a little bit about why not to use Google Voice in this comment (on this same post) here: https://news.ycombinator.com/item?id=39270503 My experience may not apply to you, but it is still a risk, IMO, to rely on the “free” Google Voice. reply lxgr 5 hours agorootparentThat's not a good reason to block Google Voice at all. Regular phone numbers also get recycled by phone providers after a few months of not paying the bills (or not topping up a prepaid account). The chance of me losing my regular prepaid number after a few months of traveling internationally is significantly higher than losing my Google Voice number. I also seriously doubt that blocking VoIP numbers is anything other than companies making their own lives marginally easier (because VoIP numbers can be used by people generating multiple trial accounts in case they're used as a (bad) \"proof of personhood\"). reply AnonC 5 hours agorootparentGP here. Maybe I should’ve worded it differently. I wanted to say that it’s better for the users not to rely on an unsupported and poorly designed platform like the free Google Voice service. I’m not in favor of companies blocking VoIP numbers. reply rrr_oh_man 2 hours agorootparent> Maybe I should’ve worded it differently. I wanted to say that it’s better for the users not to rely on an unsupported and poorly designed platform like the free Google Voice service. But that Romanian SIM card I bought at a roadside kiosk on a boozy weekend in Timisoara without any ID is fine? reply thanksgiving 6 hours agoparentprev> Some have even done this after initially allowing me to sign up using it, changing their policy sometime after I've signed up, and I usually only notice when I end up locked out of my account. Viber did this to me. My Viber account is from 2012. I only found out when I switched phones. reply Retr0id 8 hours agoprevCounterpoint: SMS login and account recovery is good UX, and it's the telcos that need to step up their collective game. reply pdntspa 8 hours agoparentNo, it's not, and it's fucking annoying to deal with. I am on my desktop computer, stop sending me to my phone just to log in because you don't want to support FIDO or some other form of real 2FA. There's a fingerprint reader on my laptop, face id on my phone, and a yubikey in my USB. Fucking use it reply wannacboatmovie 6 hours agorootparentHey look, a bunch of disjointed, vendor-specific non-standards that become impossible to support. Imagine some hapless Filipino support agent trying to explain to an irate customer their YubiKey drivers are borked. Why don't we just issue everyone PIV smart cards? reply pdntspa 3 hours agorootparentI don't know about the windows side of things, but on Mac I imagine there's just one fingerprint API to support, same with face id. Yubikeys either work or get their drivers from the cloud like most other devices nowadays. I also dont know much about what android has, but I would be suprised to learn if there wasn't native support for the various standards that are in place today, even if manufacturers aren't using it. reply rrr_oh_man 2 hours agorootparentprev> Why don't we just issue everyone PIV smart cards? Particle Image Velocimetry? Penis in Vagina? Pentium 4? Edit: Hah! Personal Identity Verification! reply thelibrarian 5 hours agorootparentprevNon-standards? They all implement the WebAuthN standard. reply lotsofpulp 7 hours agorootparentprevThe macOS/iOS integration for autofilling SMS 2FA is so convenient due to this. Basically everything I do online now requires it. reply wannacboatmovie 6 hours agorootparentWhen it works. I switched this off by choosing the wrong answer to some vague prompt and could never figure out how to re-enable it. Assuming it's like the many iOS settings that can be reverted only by resetting the phone to factory defaults. reply sunnybeetroot 5 minutes agorootparentWhich iOS settings require a factory reset? reply AnonC 5 hours agorootparentprevIt doesn’t work on all sites and apps, which is an annoyance. Why it can’t intelligently offer the SMS OTP when a user is just waiting on an input field and an SMS comes with a code is beyond me. They should be able to decipher the messages, regardless of variations in formats, and know the code. BTW, the setting to enable or disable this seems to be under Settings->Passwords->Password Options->AutoFill Passwords and Passkeys. Turning it off and on may also work (as these things tend to behave across devices and operating systems). reply 2OEH8eoCRo0 8 hours agorootparentprev> There's a fingerprint reader on my laptop, face id on my phone, and a yubikey in my USB. Great! Not everyone has that! I do but if I could only implement one type of 2FA I'd probably still pick SMS. reply chrispeel 7 hours agorootparentEveryone can get an app on their phone or computer that supports TOTP, such as Google Authenticator https://en.wikipedia.org/wiki/Time-based_one-time_password reply supertrope 6 hours agorootparentThe problem is customer support load. Also what does the company do about those without a smartphone? No smartphone no service? This is why businesses peg account authentication to phone numbers. It offloads IAM overhead to phone companies. reply gruez 6 hours agorootparentprevWhat happens when they smash their phone and now you have to do account recovery? With SMS authentication you can presumably offload that to the carrier. reply torstenvl 7 hours agorootparentprevFar far more people have a biometric reader or smart token than have a cell phone. Smart phones are obviously phones and have biometrics. What you're left with is comparing the number of people with non-smart phones (~31 million in the U.S.) to the number of people without smartphones but who have biometric tablets, Windows Hello-enabled computers, PIV cards, etc. reply kevml 7 hours agorootparentDo you have statistics on the number of people who do not have smart phones but do have these other devices? I am not sure the intersection is as high as you imply. reply torstenvl 6 hours agorootparentThe only people who don't use smartphones and don't have an iPad or similar tablet and don't have a recent computer... probably don't benefit enough from 2FA to justify the risk of account lockout. In my social circle, the people who don't have smart phones are: - People with disabilities that make reading from a small screen or texting a lot impractical. - People who work in harsh environments who want something more rugged than a device made out of glass. - People wary of the distraction of carrying around an entertainment device. All of these people except one also have an iPad (especially the first group, as the larger screens help a lot). The one who doesn't does have a Dell XPS 13. reply jonhohle 6 hours agorootparentprevI would wager the number of people in the US with a smart token (I’m assuming you mean something like a Yubikey, ≈22M worldwide, most users have two) is probably close to 1:1. I would also wager the number of people with dumb phones are close (but not as close) to those having computers without any biometric capabilities (and if they have them, they’re not set up). reply alexdunmow 7 hours agorootparentprevOutrageous claims require outrageous evidence. reply torstenvl 6 hours agorootparentYes. They do. reply ranger_danger 7 hours agorootparentprevnext [2 more] [flagged] abdulmuhaimin 5 hours ago [flagged]rootparentsource - my ass reply mooreds 7 hours agoparentprevI wrote a comment 11 days ago talking about SMS for a second factor, but it applies in general as well: https://news.ycombinator.com/item?id=39130032 Email is better, for sure, but mostly because email providers are either controlled by the user (for us nerds with a custom domain) or a large, impersonal entity (google or similar). Neither is available to change by attackers in the same way as phone number providers are. I work for an identity provider and we have a number of folks who want us to support this, almost always from a UX perspective. I think that there also needs to be some onus on the phone providers, as suggested above. With the continued push to have the phone number as a global identifier (offline and online), we need our telco providers to require more to change phone numbers. reply lxgr 6 hours agorootparent> With the continued push to have the phone number as a global identifier (offline and online), we need our telco providers to require more to change phone numbers. No, we need to push back on this user-hostile trend, not stick on yet more band-aids. Phone numbers are country-specific, impossible to own in any meaningful way for private individuals (unlike e.g. domain names), and add an unnecessary point of failure. reply dkjaudyeqooe 7 hours agoparentprevYes having an SMS sent to a number you no longer own is great UX. reply lrvick 7 hours agoparentprevNot everyone has (or wants) a phone or to grant control of their life to a cell phone carrier reply spenvo 8 hours agoparentprevFrom the article: > For many years, people in the industry have invariably said something like: \"Well... offering SMS-based authentication is better overall for customer security, because of its convenience (despite its shortcomings) vs other methods\" (such as the far-more secure use of email for verification). To that I say: \"who are YOU to deprive your customers of security?\" and > Much of the ire relating to SIM-swap attacks has, understandably, been directed at carriers. Indeed, carriers do a terrible job of securing customers’ phone numbers, and may be liable for that shortcoming. But here’s the thing: carriers’ security has always been bad, it has even been legislated into being bad, and other companies have still chosen to build mission-critical systems on top of that weak link. and > Despite offering poor security, SMS offers a nearly frictionless way to sign up new customers (think of Uber's onboarding) and handle password resets, and companies felt they had to match competitors' adoption of this technique. This last bit was unfortunately overwritten in a Wordpress post update, and I added it back. reply j16sdiz 8 hours agorootparent> such as the far-more secure use of email for verification Hmm.. sure? They have different threat profile. Don't think it is more secure. reply spenvo 8 hours agorootparentThere is a straightforward manner to overtake your phone number (call your carrier and use social engineering). There is nothing you, the customer, can do to lock that down. (I've tried with my carrier.) With email, you can lock that down with robust 2FA (Google Authenticator/Authy/etc) and crooks have no straightforward way of defeating that. This is how it plays out year after year and why SIM-swap gangs are so prevalent. reply kelseyfrog 7 hours agoparentprevCounter-counterpoint, when companies implement a system with a known flaw, then they're responsible for the consequences of creating that system. reply batch12 7 hours agorootparentOTP can be social engineered, hardware keys can be stolen, who determines what constitutes a flaw? Edit: also, do both pay in this case? The telcom and the service? reply tamimio 7 hours agorootparentThat’s a problem with the user, not the protocol or the system, users have been and will be always the weakest point, but they are accountable for it if it happens, not the case for sim swap attacks. reply batch12 7 hours agorootparentYes, true. However- to paraphrase a red team operations book I read, if the user can be tricked into into compromising your security with a click, then you can't blame the user. An organization's defensive security strategy should not hinge on a single user's decision to click or not. Edit: I am swapping users with you, sorry for the confusing reply. I'm thinking telcom employee, you user of the app that got swapped (I think, apologies if I am wrong) reply tamimio 7 hours agorootparentHa! I was going to say if you solve the user vulnerability then congratulations, all systems are mostly safe! Before reading that you meant telecom employees. The reality is TOTP despite any issues, is far more secure and available than SMS, security for obvious reasons but also availability, you can have your TOTP token accessible everywhere (say in your password manager) but if you can’t receive an SMS because you lost your phone or maybe traveling, then you are in a tough position, maybe even locked out completely. I personally even back up the TOTP tokens so I can reuse them without being tied to specific platform/app (I am looking at you Authy!) reply batch12 7 hours agorootparentI completely agree with you. reply Pufferbo 7 hours agoparentprevIf you don’t have your phone; if you’re abroad and don’t have SNS; if you’re in a building with no service; if you changed your phone number, they all suck. Also, another valid point is that often times it’s hard to tell what’s a legitimate SNS message and what’s phishing. Their phone numbers are always gibberish and sometimes change between requests. reply batch12 8 hours agoparentprevFrom the examples I've seen, the attackers essentially become the customer. They've either socially engineered the customer or done research to gain access to enough information to validate themselves as the customer. Come up with a solution and sell it. You'll make some money. reply PeterisP 7 hours agorootparentThat's kind of the point, US Telcos don't really validate customer identity - probably because they can't, due to the general limitations of USA documents leading to relatively easy identity theft where merely having enough information is sufficient to impersonate someone. (A simple test - is your verification process likely to stop someone's parent, spouse or sibling from impersonating them? If no, you're not really verifying identities.) It's not something where a private entity can sell a solution, you need a more solid root of trust for verifying actual identities, like many other countries do, but that's not going to happen in USA any time soon. reply batch12 7 hours agorootparentprevWell that got me thinking. You could stand up a third party verification service and sell the offering to companies that don't want to be bothered with authenticating the user. Something like Okta (I know, bad example when talking infosec at the moment) for real life. reply wahnfrieden 7 hours agorootparentThey won't pay for it reply lxgr 6 hours agorootparentSomebody already pays for it. Once regulations ensure that it's the companies skimping on KYC themselves, most will happily outsource that task to the cheapest (compliant) provider. reply batch12 7 hours agorootparentprevI just realized this does exist (kinda) in the US with identogo. Could be an easy service offering for them or a partner for another company focused on the mfa issue. reply batch12 7 hours agorootparentprevWith the right legal language, I think they would. reply crmd 7 hours agoparentprevIf having your account hijacked is is a good user experience then I have no idea what UX means. reply croes 7 hours agorootparentMaybe SIM swapping shouldn't be so easy in the first place. reply bfdm 7 hours agorootparentSure, agreed, but until that changes stop using SMS for 2fa systems. reply johnneville 7 hours agoparentprevwhile it works well a majority of the time, it results in an exceptionally bad UX if you lose your phone, don't have reception, or are traveling outside of your service area reply justin_oaks 6 hours agorootparentI once worked in a building with terrible cell reception. I hated anything that required SMS for 2FA because I'd have to go outside to get the text message. My in-laws lived in an area with poor cell reception too. Whenever I'd go there, I couldn't use SMS either. Both of those places had good Internet service. Any time SMS was required, my UX was terrible. Hooray for anyone who supported TOTP, email, or any other form of 2FA. reply lxgr 7 hours agoparentprevIf you never move internationally, travel abroad, are outside cell coverage, and don't value security too highly, it sure is. reply __MatrixMan__ 7 hours agoparentprevAny auth mechanism that requires a trusted third party is hardly an auth mechanism at all. reply j45 8 hours agoparentprevTelcos are not responsible for using fingerprint or facial recognition as joint user+password. When it comes to good UX it’s important to clarify whose goals it’s best for: compromise security for convenience and adoption of an app? Or setting up the user to succeed more. SMS is a lazy form of 2Fa. it reminds one of the descriptions of sms being an open postcard. Theatre and pageantry have limited value where it sets users up for much worse reply neallindsay 8 hours agoparentprevYou know that they won't though, so why even make this argument? reply Retr0id 8 hours agorootparentBy that logic, consumers and tech companies won't change either and we can bypass this whole discussion. I live in a part of the world where, on occasion, governments decide to regulate such things. reply romwell 5 hours agoparentprev>Counterpoint: SMS login and account recovery is good UX, and it's the telcos that need to step up their collective game. Oh, yeah, fantastic UX. I've had my phone and credit cards stolen while traveling abroad (such a hard-to-imagine scenario, innit?), and was consequently locked out of all important services. Very good UX: being left without a phone and access to bank account and email and most messengers at the same time (thankfully, Skype isn't one of them). Double props to CitiBank for requiring SMS authentication to change the phone number on the account. reply johnea 7 hours agoparentprevI completely disagree. Using a corporate account for personal identification is a major failure of public infrastructure. The US government should step up it's game. An individual's identity financial transactions should NOT be determined by holding an account at one of 4 mega-corporations. We should work towards something in this direction: https://e-estonia.com/solutions/e-identity/id-card/ reply paiute 7 hours agorootparentI’m so happy other people think this too!!! No one trusts the government, but usps is still offers pretty good privacy. I want mandatory acceptance of a gov issued ID, but at the same time i want to be able to use things anonymously. reply zeven7 7 hours agorootparentprevGetting the government involved in this is the only worse idea than delegating to 4 major corporations. It should be delegated more broadly and users should have more options not less. reply treflop 8 hours agoprevI agree that SMS is a terrible multi-factor. But it caught on because asking people to install an app is a massive ask. Not to mention, people never save those recovery codes. Sure, you can use Authy and back up your codes but that’s pretty much squarely in the “for technical people” camp. So at the end of the day, SMS is the only real solution for your average normal person. Let’s get cellular carriers to make SIM swapping harder. reply lxgr 6 hours agoparentIt worked for every single card-issuing bank in Europe. SMS are fortunately both expensive enough there to make them uneconomical for banks to use them as an OTP factor, and have been found too insecure for payment authentication by themselves, requiring a second factor. This has practically lead to banks offering something more secure and/or ergonomic, e.g. bank-specific authenticator apps (which often work without internet, and always work without cell signal, e.g. when traveling internationally), hardware authenticators, WebAuthN etc. > Let’s get cellular carriers to make SIM swapping harder. No, let's get financial companies to step up their game and offer something not liable to both security breaches and locking out users (when traveling, losing access to their number etc.) reply 76SlashDolphin 5 hours agorootparentI wouldn't generalise an entire continent like that. Both my Bulgarian and Austrian bank accounts have SMS-based 2FA on online transactions and logins. Some banks in Bulgaria allow to use eSignatures as 2FA but afaik that has seen tiny adoption in the consumer space. reply lxgr 5 hours agorootparentI don't know about Bulgaria, but in Austria, verification apps are very popular and I don't know many banks that still allow SMS-OTP for e.g. 3DS authentication or online banking transaction confirmation. reply daveoc64 5 hours agorootparentprevMany banks and card issuers are using SMS for 2FA in Europe. reply lxgr 5 hours agorootparentNo bank is using (only) SMS as an authentication factor for 2FA. It's not allowed under the EBA's technical interpretation of the PSD2 regulation. Some banks do still allow it as a fallback option, together with another factor, e.g. a password or other knowledge factor. My bank even made it a paid service, which I fully support – SMS is extremely overpriced. reply daveoc64 5 hours agorootparentI'm in the UK, so our implementation of the PSD2 regulation may be a bit different (in came in while the UK was leaving the EU), but I get SMS 2FA codes from American Express all the time in the 3D Secure process. reply lxgr 5 hours agorootparentSome banks do still allow SMS by itself as the only authentication factor (presumably because they haven't got around to updating their solution or maybe think they've found a workaround), but it's not compliant with the PSD2 regulation in the EU at least. The solutions I've seen usually use a password or security question as the other factor. reply pests 8 hours agoparentprevGoogle Authenticator now syncs to your google account. reply Mistletoe 8 hours agorootparentI’m not even sure this is a positive thing. reply fattire 8 hours agorootparentYou can opt out of it thankfully. reply davchana 5 hours agorootparentprevI have always saved my dtrings in a separate keypass database. New Google Auth takes a second or 5 to show accounts. I use old apk because that one shows accounts in a millisecond. reply jameshart 8 hours agoparentpreviOS’s inbuilt password manager supports TOTP second factor authentication right in the operating system, no app needed. reply __MatrixMan__ 7 hours agorootparentIsn't the point of a second factor that it's... Not the same as the first factor? My TOTP app password is one of the few that don't go into the password manager. Might as well make 'em compromise each separately. reply kccqzy 6 hours agorootparentAccessing TOTP or passwords in the iOS built-in password manager requires someone to (1) have your phone; (2) pass a biometric authentication or a passcode authentication. That's the two factors right there. reply __MatrixMan__ 4 hours agorootparentOr to be able to push updates to the iOS built-in password manager: one factor. reply kccqzy 3 hours agorootparentMy threat model doesn't include Apple or Google, the maker of the operating system. If you assume they could push an update to the built-in password manager, you need to assume they could push a keylogger that exfiltrates both your regular password and the password for your TOTP app. reply vel0city 6 hours agorootparentprevEh. It still makes the credentials rotating credentials instead of permanent credentials. If your username + password + single TOTP value gets stolen, they won't be able to re-auth once that credential gets invalidated. So say a site accidentally logs auth attempts, and someone finds the log. Sure, they know your username + password now, but they don't know a good current TOTP value. And TOTP values are supposed to be one-time-use, so even if they catch it quick it'll be invalid very fast. Its better than not having TOTP, but not quite as secure as it could be. Theoretically its still something you know and something you have in that its something you \"know\", the static password, and something you \"have\", the rolling TOTP generator. reply __MatrixMan__ 4 hours agorootparentIf the password manager was compromised (not accessed without permission, but updated without permission) then it wouldn't be just the single TOTP value that leaked, it would be the underlying key. On a mobile device you might be a bit limited in how \"distant\" you can keep the two, since the vendor is typically almighty in that scenario. But in general, you have options and you might as well avoid keeping both eggs in the same basket. reply iknowstuff 8 hours agorootparentprevYeah but no normie knows about it. It never prompts to store them. reply jay_kyburz 8 hours agoparentprevMy bank made me install Symantec VIP. Yuck. To do my tax I need MyGovID. Also Yuck. reply autarch 7 hours agorootparentThe Symantec app is just a regular TOTP app but a bit more annoying. You can usually replace it. See https://locima.com/2019/06/01/replacing-symantec-vip-with-a-... for one method. I did this to get my Etrade account TOTP from Symantec into Authy. reply zadokshi 7 hours agorootparentprevHow did the bank “make” you do this? Does your country only have one bank? reply jay_kyburz 6 hours agorootparentAs much as I hate the apps, I'm not prepared to refinance my house just to avoid installing them on my phone. Especially when the other banks probably have the same policies, or will soon. reply protocolture 8 hours agoprevLets try the same logic everywhere else. Companies embracing password login should be blamed for sticky note thefts. Companies embracing email 2FA should be blamed for email account theft. I dont know if this holds up hey. We see this time and again. An entity that does not break the law, makes itself available to the law, and its customers get hit by a criminal entity that does not follow the law. Because we cant snap our fingers and demand the government make thieving criminals double or triple illegal, people reach for a largely innocent party and want to make their lives worse. Take a deep deep breath and let it go. Theres no unharmful level of punishing the innocent on behalf of the guilty. This is going to sound wild and crazy but the people swapping the sim should be blamed for the sim swapping attack. What? Blame the criminal? I know its a bold stance but its correct. reply caconym_ 8 hours agoparent> Lets try the same logic everywhere else. The difference between SMS 2FA and the examples you mentioned is that the former is literally impossible to use securely because there is (AFAICT) no (American) consumer mobile provider that implements proper safeguards against unauthorized SIM swaps and similar. Any company implementing SMS 2FA ought to know this, and any company knowingly implementing a deeply flawed 2FA system and selling it to consumers as \"more secure\" ought to be held liable when it fails. And the sooner SMS 2FA dies, the sooner the same old websites that implement SMS 2FA and nothing else will be forced to implement something that's actually secure. reply xxs 6 hours agorootparentUnfortunately, there are already laws that demand sms auth, e.g. online gambling in some US states (new jersey, being one). The persevere practice has been established as 'strong login'. reply mcmoor 6 hours agoparentprevThis is what I thought about the 23andMe debacle. They may should have done better, but any attempt to \"punish\" them really feels like ex post facto law. Make new regulation or something and punish future incidents, but not this one. reply balls187 6 hours agoparentprevAnd blame the carriers. reply protocolture 6 hours agorootparentCarriers can certainly carry an amount of blame. IIRC in Aus its gotten harder to activate a new sim for these reasons. The attacks haven't stopped entirely but its gotten more rare. It now relies on a very persistent social engineering attack to pull off. That said number portability is a really deep well. And theres utility in keeping it somewhat liquid for the many many many people it benefits rather than making it terrible for everyone to prevent a number of attacks. reply mx_03 8 hours agoparentprevThats a strawman fallacy. You can control not writing your sticky note. You cant control a sim swap attack. reply spenvo 8 hours agorootparentYup it's a strawman argument. And furthermore, even the rhetoric used to downplay the idea of holding companies accountable is off: The idea of \"blame\" (with some handwaving) carries weight in court and sways juries. And companies are getting sued for big sums over negligence regarding SIM-swaps, like here https://www.techmeme.com/190723/p15#a190723p15 reply Jiro 4 hours agorootparentAT&T won that case: https://blockworks.co/news/att-crypto-sim-swap-lawsuit reply powerapple 3 hours agoprevWhy can I set a level of security to my account, how about let me choose how secure it should be? There are many accounts I don't care about, I don't even want to use password with it. I should be responsible for my account security, and I should make that decision. reply talkingtab 5 hours agoprevUnderstanding the root cause or causes of a problem is required before discussing a solution. Is the problem that people use SMS? Or rather is the problem that carriers allow bad actors to easily port a phone number? We know it is wrong for a carrier to do this. If we know that some used car dealers rip people off, is the fix to stop buying used cars? Then how do we fix the problem that carriers do not protect our phone numbers from being ported? We sue them. In most if not all states it is relatively easy to file a small claims case. For some reason most people do not consider this. Maybe someone could provide an example filing. Courts should and must provide relief to common citizens when they are aggrieved. If this is indeed a common problem it should be documented and fixed. reply alefarx 5 hours agoparentYikes, this is a woefully misguided attempt at a seemingly rational response. Chalk up Auth-n security to the courts? Yes, this is a known problem and, no, shrugging off the issue to the lawyers is not appropriate. Candidly it's downright irresponsible if not criminal. reply k8svet 8 hours agoprevAs usual, this conversation seems to be one side pointing out how god awful SMS is for security, usability, etc, and the other side going \"but how else can we accommodate helpless users\". (edit: sorry missed an important negation wording mistake) Like sure, if I could, I'd make SMS disappear, but really, I'd settle for just punishing those companies so lazy they can't roll out any non-SMS support. reply wraptile 1 hour agoprevHere in Thailand phone carriers re-use phone numbers every 2 years or so. Recently I forgot password to a local amazon (Lazada) and did a phone reset that logged me into some other persons account with credit card attached and everything. Also, pay as you go phone numbers tend to expire in 2 months without a way to reset this so you're always at risk of losing your identity confirmation. I really don't understand how phone numbers became so accepted as an identity confirmation. reply cco 7 hours agoprevThis exact topic came up by chance at the lunch table today (I work at Stytch, we do auth). SMS as a primary (or frankly even as a second factor) is fraught. But as comments in this thread call out, they can be incredibly smooth UX for end users on mobile devices. And in fact, for some user bases, far and away more ubiquitous than emails. There are many populations that just don't have email to serve as a primary factor, but do have phone numbers. So it's a nuanced topic. Everyone, both users and developers, need to have eyes wide open to the danger and protect against it. And let's not forget the telecoms, they need to recognize that the phone number serves as a primary login factor and treat it more carefully. That might mean in person or stronger identification requirements on changes. reply qweqwe14 2 hours agoprevCouple of factors lead to companies \"embracing\" SMS: 1. A phone number is a useful piece of information to have on a customer (to sell to someone or whatever). 2. Some (most?) people are too dumb to manage passwords/TOTP and shouldn't be allowed to use a computer. As a result, everyone suffers and is forced to use broken SMS 2FA that can be SIM-swapped. 3. Companies want to stop bots and use phone numbers for that, even if it's a non-issue for bot operators in practice. A little inconvenience, sure, but it doesn't change the bigger picture in any way. reply 8organicbits 2 hours agoprevI'm fascinated by the way Signal solves this problem. You can register a phone number, verify it over SMS, set up a registration lock PIN, and then have quite secure communications. The registration lock can be bypassed if someone tries to register the number (like when the phone number is assigned to someone else), waits for a while, and the previous owner doesn't re-register. Services that do SMS delivery of OTP may want to consider delivery over Signal or WhatsApp when available as they add this additional security. I've also thought about building an OAuth provider (like sign-in with Google) that does Signal-like phone number verification and lock PINs. This reduced some spam concerns, as it's harder to create burner phone numbers than email addresses. A centralized OAuth service would make it easier than having every web app need their own SMS phone verification integration. reply trevoragilbert 8 hours agoprevIt’s a tough pill to swallow the argument that one of the most widely used and beloved features (autofill codes from SMS) is against the best interests of the user. reply pembrook 8 hours agoparentIt’s a much easier pill to swallow if said user has a US phone plan and ever tries traveling abroad. Good luck getting those SMS codes. And good luck getting the US carrier to not shut off your plan if you travel for longer than a few months. reply okanat 6 hours agorootparentWell that's because US exceptionalism itself. More or less the rest of the world uses exactly the same tech for mobile so cellular roaming works in every country. It's the US carriers that try carrier proprietary tech to trap their customers into their networks. I never had problems with getting SMS around the world with roaming. It just works. reply hedora 6 hours agorootparentI've never had problems with using SMS + wifi around the world without roaming. (I've had that problem domestically, due to having laptop internet with no wifi password, though.) reply jameshart 8 hours agoparentpreviOS Autofill of one time codes works with email and with true TOTP codes. Authenticating a user securely on their phone can be seamlessly secure without relying on SMS. reply scintill76 8 hours agoparentprevThe argument is that autofill makes it so easy, that users accept it and companies are more likely to adopt SMS-based flows, right? Autofill doesn't seem inherently bad. reply WirelessGigabit 6 hours agoprevBank of America on iOS still ONLY supports text as a 2FA. On my desktop I can do username, password and YubiKey. But iOS is username, password and text, or Face ID and text. Disabling text means disabling disabling 2FA. Ridiculous. reply internet101010 6 hours agoparentCharles Schwab does \"My voice is my password\" when calling. That's going to cause a lot of problems in the near future if it hasn't already. reply spenvo 5 hours agorootparentYes! Here is a bit I wrote on that a couple of years ago. This voice print ID tech is everywhere as well, used by financial companies, ISPs, and more! https://keydiscussions.com/2021/12/07/despite-the-prevalence... reply xyst 6 hours agoprevWhat needs to be done to get rid of SMS as 2FA? Fed regulation? It will be slow (ie, took many years for the US to fully get rid of mag stripes as the standard), but at least it will motivate US companies (effects to possibly ripple across the pond) to get their shit together or find a new vendor. Multiple banks I use still use SMS as primary 2FA. Kind of sad. reply wiether 2 hours agoprevCan someone recommend a 2FA app that can provide the users with confidence? I don't want to use Google Auth because I have absolutely no trust is this company and how unreliable they are with their products. I currently use Authy but it's free, offered by a company (Twilio) and I can't really see what their endgame is here. So they could drop the service one morning because it's not useful for their main business anymore. They already announced dropping their desktop apps. Say in another way : is there a security company somewhere selling a 2FA app and in which it's easier to put trust? Sure Bitwarden can provide TOTP, but then I still need to put MFA on my Bitwarden account itself. reply Maakuth 2 hours agoparentThere's TOTP support in Keepass2Android and KeepassXC (and surely other Keepass implementations too). These are open source and you can control how the password database is kept: cloud storage is supported as well as local file (that you can sync with Syncthing or whatnot). reply M4v3R 2 hours agoparentprevIf you’re at a point where you would have your users pay for a 2FA app why don’t build your own (or build TOTP functionality into some existing app)? TOTP is very easy to implement yourself, it’s literally just a handful lines of code. reply rrr_oh_man 2 hours agorootparentIt's not that it's hard building it, but: Do you want to maintain it? On iOS, on Android? Through all update cycles? On all screen resolutions? Keeping up with the regular bullshit, especially coming from Apple? Random app store bans? Reviews? Support? etc. reply giancarlostoro 6 hours agoprevWait.. what? Shouldnt we be blaming tel co companies for being insanely stupidly easy to hack instead? I mean I have seen teenagers talking about how easy it is. When its so easy even a minor can do it, you have a major problem. reply charlie0 7 hours agoprevIt baffles me that we all services haven't defaulted to something like Google Authenticator or similar. Users should be given a choice. reply rinron 7 hours agoprevFor a lot of companies they choose sms for no other reason than it really limits spam and cuts down on fake accounts. People are conditioned to for the most part to be free with their phone number. Making it pretty much the only identifier that cant be easily and without cost or human effort changed(its not too hard and often normal to block voip numbers) Sure you can say well then also require some other form of authentication. these companies are trying to make money and go to a lot of effort to reduce even the slightest friction to new customers. Besides once they have sms and 98% are happy with that why put more work in? The real problem though is what other choice do they have? Yes you and i would put the effort in to both secure and properly manage better systems but when the vast majority would quickly forget or loose any other method. They have to make a system that is \"secure\" for them anyway, why implement other systems(yes i know you and i think it would be worth it for us but maybe the bean counters dont). Its completely understandable that the average person THINKS that sms is secure, everyone depends on their phones, uses it for very personal, private and sensitive business calls. even without tech companies using it for auth it would be exploited, just not as much. Unfortunately it would just take an incredible amount of cooperation, expense and growing pains to properly secure the telecom network. They are extremely interconnected legacy systems that are designed with the assumption there is no security besides trust. that being said they could improve things a whole lot more if they were able to verify their customers better on support calls or at least had higher security options you could enroll in. So they didnt put people who cared about security with the ones who cant even keep track of their own account numbers. Personally without governments coming together to implement a digital \"secure\" citizen identification system (also very scary) probably the best we can hope for and i think google now allows is after its verified by phone remove it as a authentication and recovery option and setup multiple hardware security keys/passkeys. ya people will still be idiots and use sms even when there are better options but at least some of us can be secure. reply Hobadee 4 hours agoprevSurprised nobody has mentioned NIST SP 800-63B §5.1.3.3. SMS based authentication is explicitly insecure and not allowed. https://pages.nist.gov/800-63-3/sp800-63b.html#pstnOOB reply seanwilson 8 hours agoprev> What is a SIM-swap attack? It’s where a bad guy asks a carrier to port your cell-phone number to their phone. How do they get away with this in practice? Can't the carrier phone the number for the SIM or txt to attempt to confirm the owner? Or send you an email or postal letter with a code? Or make you go to the store to show ID? And if you claim to have no access to the above, send a txt/email/letter alert that you have 5 days to reply to before the switch happens? Do any carriers advertise themselves as having strong security against SIM-swap attacks as a unique selling point? reply hedora 6 hours agoparentStep 1: Confirm victim is out of cell range. Step 2: Sob story about how you lost your cell phone. Step 3: Fake ID / Social engineering. The five day wait would work well, though it doesn't protect against \"I stole the phone and I yanked the SIM or looked at the push notification\" attacks. reply ajsnigrutin 6 hours agoparentprevYep, I never understood that either.... you have to confirm your old number before you can transfer it to a new telco, so sim swaps are not really a thing. But it's primarily a US problem, and they have a lot of ID problems, like using their SSN as \"passwords\", and other stuff that would be impossible anywhere else (like illegal immigrants getting jobs at large companies and enrolling their kids in schools without anyone verifying who they are). reply donmcronald 7 hours agoparentprevThey could and it could be similar to emergency / fallback access in password managers. Send an SMS to the number (aka current SIM) before approving changes and force the person requesting the change to wait for X hours or days if there's no response to the SMS asking for authorization. That's what the providers around me do, but I think it's because one of them got sued a while back and we only have about 3 providers pretending to be 10 different companies (aka fake competition). reply zadokshi 7 hours agoparentprevExactly, it wouldn’t be hard for the mobile providers to require sms confirmation and/or written authorisation before a number is ported out. I don’t know if it’s government law or phone company laziness getting in the way of SIM security, but giving up on SIM security seems nonsensical and silly. Fix SIM porting security. reply joshe 8 hours agoprevThe problem is that average sms security is higher than email, but email CAN be much more secure. So for mass market accounts sms makes a good login confirmation and improves security. But if you've bothered to have somewhat secure email it sure would be nice to use that instead, and not worry about the 50,000 retail and support staff at telcos who can grab your sms account based on a convincing phone call. So, please, I beg of you login developers, offer email wherever you use sms now. reply kredd 7 hours agoparentI understand it’s a naive statement, but in order to log in into your email you would end up relying on some other sort of 2FA. And we’re back to square one to relying on SMS, because UX of other authentication flows has irrecoverable flaws. reply hedora 6 hours agorootparentExactly. You could use a trustworthy mail provider with a domain you own (registrar and DNS provider in two other accounts, probably), and then a second mail account for the 2FA for the other three accounts, but then what's the 2FA for the second email account? reply tamimio 7 hours agoprevThat’s what I have been saying for years every time I have an opportunity, last one few days ago https://news.ycombinator.com/item?id=39247480 But it won’t happen, that phone number is NEEDED to be tied to your identity for a lot of reasons, that’s why banks (where most people have their real identity) are still requiring a phone number. reply NoPicklez 5 hours agoprevI do disagree with the title, telco's should be responsible for SIM swap attacks as they should have better processes to prevent people's mobile numbers from being ported. Additionally, whilst people rave about 2FA apps, not many people talk about an approach to recovering your 2FA app account if you lose your device or anything else. reply 486sx33 7 hours agoprevI absolutely hate SMS verification. Email providers want sms verification, my corporate Microsoft account wants SMS verification to login on PCs and then it also wants Microsoft Authenticator verification ! What it really wants is me to “stay logged in” all the damn time. On my Mac, outlook needs to relogin to Gmail in safari every damn time I clear safaris cache. What the god damn well hell. What if I changed my phone number? I’d lose access to almost everything… wait is that the point ? CIA ? NSA ? KYC ? Cmon ! The internet used to be fun, but now it’s just a hassle reply NoPicklez 6 hours agoprevHow about they create a permanent site that guides people who have read the article in how to switch to app based 2FA? Doesn't have to name applications, but explain the process and common pitfalls people find themselves in when switching to app based 2FA and how to prevent them. reply jsnell 8 hours agoprev\"Companies should not let account recovery happen over SMS, they should just let the accounts be completely and irrevocably lost.\" The position of the post is just rigid absolutism that has no chance of surviving the real world, and it's not at all clear that the author actually has any expertise in the subject. It should be completely obvious that password + SMS 2FA is better than just a password. And while the industry has been trying hard to get people to move away from SMS 2FA (yes, the industry would actually like that, despite the author's conspiracy theories), it is slow going. TOTP has horrible ergonomics and doesn't permit passing side-channel information about what exactly is being authorized. Emails get caught in spam filters. Push-notification style app authentication is secure, but a lot of people will refuse to install your app unless you're like their bank. Yes, SMS isn't the best form of 2FA for a bunch of reasons. Sim-swaps honestly aren't one of those reasons. But they are the form that you can actually get people to use, and succeed in using. Ah, but what about single-factor SMS, you say (unlike the author, who doesn't seem to understand the difference). Again, consider the alternatives. If you don't allow for account recovery over SMS, what is your account recovery story? Human customer service will just be socially engineered as easily as the mobile operator was. TOTP seeds, recovery codes, etc can be irrecoverably lost. Phones with authentication apps can be stolen and fail to be bootrapped again. Email accounts or IDP accounts can be lost to hijackers, and are also frequently lost when people change jobs, graduate, etc. Security questions can be stolen and brute-forced. SMS has a unique property that makes it invaluable as a recovery factor: it's a globally accessible communications channel that can be bootstrapped from just your real-world identity even if lost. That said, allowing SMS for account recovery does carry some security risks. They can be managed or mitigated by e.g. require a cooling down period, during which the account owner is notified about the recovery attempt and can cancel it. But like everything in this space, those mitigations are also tradeoffs. Which tradeoffs are the right ones depends a lot on what the account is for, there's no one-size fits all. reply k8svet 7 hours agoparentI'm so frustrated reading these comments because I assume this is the logic used at these companies that make my life a daily pain in the ass. My email is more secure than my phone. This is shown to be evident on a monthly or bimonthly basis, despite insistence from sms proponents that it's the only feasible oh and also secure way. Bollocks. Every single time, it basically boils down to the truth - SMS auth is circumvental, recoverable, whatever you want to call it. And there's ample evidence of that being used for account takeovers. I honestly don't understand how this remains a discussion. reply jsnell 7 hours agorootparentGreat, go ahead use your email address rather than a phone number then! If the author's point had been that there should be a non-SMS option, I would not have commented. But that wasn't their point. They thought it should be removed as an option from everyone. It's just an amateurish idea, completely ignoring the real world and the tradeoffs. reply 17 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Security companies relying on SMS for account logins and password resets should be held responsible for SIM-swap attacks.",
      "SIM-swap attacks occur when criminals trick carriers into transferring victim's phone number to their device, granting access to SMS account login details and sensitive information.",
      "High-profile companies like Apple, Google, and PayPal have adopted SMS-based authentication despite its known security flaws, and the author argues for the adoption of more secure options such as Authy or Google Authenticator."
    ],
    "commentSummary": [
      "The conversation explores different methods of account authentication and security measures, such as SMS, Yubikeys, TOTP apps, and email.",
      "There is disagreement about the reliability and effectiveness of using SMS for account-related purposes due to concerns about SIM swapping attacks.",
      "The discussion emphasizes the limitations and vulnerabilities of various authentication methods, calling for stricter regulations and improved implementation of multi-factor authentication to achieve a balance between security and user convenience."
    ],
    "points": 391,
    "commentCount": 269,
    "retryCount": 0,
    "time": 1707180517
  },
  {
    "id": 39259602,
    "title": "How many self-employed individuals sustain their own ventures without external funding?",
    "originLink": "https://news.ycombinator.com/item?id=39259602",
    "originBody": "How many of you are self employed? What do you do? I won&#x27;t count startups that are funded, but more the individual who started something for themselves. Curious to know what sustains people.",
    "commentLink": "https://news.ycombinator.com/item?id=39259602",
    "commentBody": "How many of you are self employed?328 points by asim 23 hours agohidepastfavorite395 comments How many of you are self employed? What do you do? I won't count startups that are funded, but more the individual who started something for themselves. Curious to know what sustains people. nlh 17 hours agoCurrently self-employed as a.....rare coin dealer! Odd path for a tech nerd hacker like me, but certainly the most fun thing I've ever done with no plans to change this gig ever. My backstory: Collected coins as a kiddo, took a 35-year detour into startup land: Started a VC-backed Web 1.0 company from 1999-2002, ran a non-tech company for ~10 years, then 2014-2022 did very traditional early stage tech product management / utility infielder roles. All fun times with at least one legit acquisition/IPO so far, but it turns out I don't love long zoom meetings and politics and formal process all that much. In 2021 I started getting back into my old coin-collecting hobby and dabbled in buying and selling at a local coin show, and boy oh boy did that escalate quickly (it was one of the most fun and dopamine-filled weekends I can remember in a long time). Cut to 2023 and I'm running my own rare coin business full-time -- buying, selling, and trading. It's such a fascinating business and very quiet multi-billion dollar industry with enormous opportunity. You need to have a passion for coin collecting and have a knack and aesthetic eye for quality (it's not all spreadsheet Moneyball), but man is it fun. Feel free to AMA about being a tech nerd full-time coin dealer :) reply bibliotekka 15 hours agoparentAwhile back a friend of mine started talking about how he was getting into coin dealing as a full time job. I was never able to quite believe him, and then was just kinda baffled when he started buying houses and nice cars and boats and taking expensive vacations. Was he legit or was he dealing drugs? Is the coin game that lucrative? reply nlh 8 hours agorootparentHmmm I mean it can certainly be lucrative but it is NOT a get-rich-quick kind of business. It's a get-rich-slow business if you know what you're doing and put lots of effort in over years. So I'd say I'm skeptical, but you never know! I'm not sure I'd jump to the conclusion that he was dealing drugs, but it's certainly an option that he was...shall we say....washing his income. reply dogman144 16 hours agoparentprevTo what extent did your past income (IPOs, executive…) provide the necessary capital to do this profitably? I wonder if there are some economies of scale required outside of numismatics know-how - ie get positive expected value/profit if you can front to buy $100k worth of coins for the 1 coin that is worth it at $101k. reply nlh 8 hours agorootparentThat is an excellent and reasonable question. I was able to put a moderate chunk of capital into my inventory and yes, that absolutely has helped (the old 'it takes money to make money'), but at the same time, I'm not the most efficient capital allocator. I know people who make just as much as I do (and more!) with 1/10th the capital, but they play a different version of the game I do and have a different set of skills. I do think that numismatic know-how is an absolute must and the more you have the more opportunities there are. There's very little money to be made simply churning bullion, for example. That doesn't require a ton of know-how other than hanging a shingle and buying and selling gold and silver. But margins there are 2-3% if you're lucky, so that's a hard game to play unless you've got a BIG chunk of capital to throw at it. (Also, I'd argue bullion slinging is on the fringe of true \"numismatics\" but I'm a snob about that lol) reply toomuchtodo 5 hours agoparentprevDo you do paid appraisals of collections? reply nlh 5 hours agorootparentYes! And free appraisals if the collection is for sale and I can have an opportunity to make an offer :) It's a balance of time investment for me. If I know someone has no intention of selling and just needs an insurance appraisal, then that would be a paid service since I'm simply selling my time and expertise (which I'm more than happy to do). If there's an opportunity for me to purchase the collection, I'll usually put the bid together at no charge since that's a sales & marketing expense on my internal brain books. A lot of dealers will try to split the difference -- they'll offer the appraisal at no charge if they get to purchase the collection, and if they don't end up purchasing then the appraisal fee comes into play. I actually think that's a reasonably fair model and may adapt that. reply bruce511 3 hours agorootparentDoesn't that make for a tricky conflict of interest? (No offense intended). I mean if you're paid for the appraisal then there's no incentive for your number not to be honest. On the other hand if you are valuer, then buyer, then it pays you to err on the low side. Not \"wrong\", just \"low\". I don't mean to impinge your ethics of course, but as a model (which I'm sure the whole industry follows) it seems to leave the seller open to abuse from folks with imperfect motivations. To be sure though, I can't suggest a better alternative. The best people to value it are dealers. Short of more-or-less auctioning it to multiple dealers at the same time. I think this is true for most collectibles. And especially true for the collections of those who have passed. My suggestion to any collector is for them to sell it themselves before they die. reply ethanpil 16 hours agoparentprevI have been curious about using computer vision to bulk scan and identify valuable coins. Have systems like this been put into use already? If not do you think they might dilute the value of \"rare\" coins by creating many more \"finds\" then were typically possible without the technology? reply nlh 7 hours agorootparentHasn't been done (well) yet, and it's absolutely doable. BUT - I don't think that's actually one of the big problems to be solved. I would argue there are enough knowledgable eyeballs out there that there really aren't too too many \"undiscovered\" rarities. And what I mean by that is, for example: The 1909-S VDB or the 1955 Doubled Die are two of the mega rarities when it comes to Lincoln cents. They are worth $500+ even in the worst shape. But they're very obvious to someone with even basic coin knowledge, and there are lots of books and pictures out there. And in fact, I'd argue there are very very very few of those coins out there that haven't been identified for what they are -- they've been known rarities for 114 and 68 years respectively. So computer vision telling someone that it's a rare coin isn't going to be too much of a game-changer. (This is a strongly stated, loosely held belief btw - I can easily be argued into a different perspective). I think a much more interesting application for computer vision to the business is when it comes to grading (coins are graded on a 1-70 scale for Reasons). And in some cases, the difference a single grade point makes can be $thousands. Official grading is still done entirely by human eyes. An efficient computer vision system to look for undergraded coins I think has real opportunity. It's not an easy feat though - you can't really truly grade with static photos, and there needs to be normalization, so you'd need video clips w/ depth mapping of many thosands of coins to train a model properly. But it could be done! reply paulette449 14 hours agoparentprevWhat percentage of your sales are to other dealers vs collectors/non-industry customers? Thx reply nlh 5 hours agorootparentThis is a good question and one that comes up often. I'd say it's around 60% to dealers, 40% to collectors. I'd like the skew to be more like 10%/90%, and that's my aim, but I take the position that a quick profitable sale to a dealer can be better than waiting for the right collector to come around and pay full retail price. It's a delicate dance and you need to develop an intuition for what coins are collector-friendly and quick sellers vs. what's more likely to sit around for a while. And the answer is different for every dealer and every series of coin. There are a lot of variables! reply lwhalen 17 hours agoparentprevIf you're comfortable answering, I'd be SUPER interested to know how the income compares to tech! reply nlh 7 hours agorootparentIf I may give you a somewhat indirect answer: One of the best things about this business is it returns proportionate to the effort you put in. I know people working with $50k in capital who make $500k a year. I also know people with $1m in capital who make $100k a year. (And I know people with $50k in capital making $50k a year). And at the extreme: I know one high-volume wholesale dealer (who's been doing this for decades) talking about his business. He has about $250k in capital for inventory and he turns his inventory 36 times a year --- $9m in gross sales! And he's a high margin guy -- so I'm guessing he's making $1.5-$2m a year on $250k in rolling inventory. There are a lot of ways to make money in the coin business and one of the most fun parts is learning new and different strategies every day. reply pillefitz 2 hours agorootparentAnd then there's the other half that's losing money reply erehweb 17 hours agoparentprevIs forgery ever an issue? reply tiborsaas 17 hours agoparentprevHow does tech help you to run this business? reply jwithington 17 hours agoparentprevhow specific is the hobby? are folks generalist collectors or do people go deep on a specific region/period? reply nlh 5 hours agorootparentAll of the above! There are people who are SUPER specific -- they collect only a single series (say, Buffalo Nickels from 1913-1938), some people who only collect a very specific type within a series (Buffalo Nickels from San Francisco in MS65 or better), and generalists who just like anything that's pretty or interesting or gold or silver or from their hometown, etc. There are 1001 ways to collect and it's fun to meet all the different folks and learn about their different approaches. reply bbsz 15 hours agoparentprevhuh! that's awesome, personally - this is a very inspiring bio. reply nlh 5 hours agorootparentThank you!! reply 93po 17 hours agoparentprevAre you hiring? Haha reply nlh 5 hours agorootparentEventually, I hope so! Gotta spin up the machine a bit more. I don't ever want more than a handful of people working on this I am a big fan of the 2-pizza team, but I know I need to scale to a bit more than just me. reply philip1209 22 hours agoprevI've been self-employed for the last ~18 months. In the past I started two VC-backed startups, then was a PM at some later-stage companies before returning to entrepreneurship. This time around, I'm building a solo \"digital product studio\" [1] instead of a startup. So, I'm staying one person, haven't raised money, and have multiple revenue-generating products. Product revenue doesn't cover my costs yet, so I do occasional consulting to bridge the gap. I like the flexibility of this lifestyle. I'm based in NYC, but writing this from Tokyo where I've been doing a creative residence for the past two weeks. And, a fun technicality - I truly self-employed in the sense that I have a salary and a payroll system. This is because my company is registered as an S-Corp in the USA, which requires the owner to be on a salary. [1] https://www.contraption.co/essays/digital-product-studios/ reply bicx 20 hours agoparentI have a similar story. I’ve been self-employed for the last 6 months after 14 years of startups. Started out as an engineer in TN, and moved to SF a couple years ago where I got into management just in time to help with rounds of layoffs. Got some severe burnout, quit, and now I’m working on my own products while doing consulting/contracting on the side through my agency. I live fulltime in an RV traveling the country and working remotely. At the moment, I never want to work for someone else again. reply ohthatsnotright 17 hours agorootparentHow do you find work? I've been trying to start a similar consultancy but I've had a hard time finding organizations who don't want staff augmentation. reply bicx 12 hours agorootparentSo far, 100% through referrals from my past connections. reply matsemann 18 hours agoparentprev> And, a fun technicality - I truly self-employed in the sense that I have a salary and a payroll system. That's how most devs here in Norway would do it. Make a \"proper\" company, where you own 100 % of the shares. Then hire yourself, and pay yourself salary, withhold taxes, pay into a pension program etc. Mainly because if you make good money, it's better to leave some of it in the company (and for instance re-invest it into some index funds or something), instead of taking it out immediately as salary and getting it taxed before re-investing. But then still take enough salary to cover your expenses, get social security benefits etc. reply jacobyoder 17 hours agorootparentdoesn't the 'company' itself also pay taxes on the income? For most solo folks in the US, the revenue flows directly to you. You could set up a more complex corporate structure to hold the income that you don't pay to yourself, but that corporation would itself have to pay taxes on the income too. I suspect there's not any real savings/benefit until there's enough 'leftover' money to start getting creative/flexible. reply rungabajje 17 hours agorootparentCompany taxes are paid based on the profit. If you spend all the company income, on salaries or equipment or whatever, there’s no profit, and thus no taxes. reply matsemann 15 hours agorootparentYup, it's the same here. So there is a tax on the profit of the year that you let remain in the company, but it's a much lower tax than a wage tax. So it's better to leave it in the company until you need it, instead of paying a high marginal tax rate on taking it out as wage immediately. reply jacobyoder 15 hours agorootparentprevNot all expenses are deductible, or 100% deductible in one year. The biggest issue we've seen in software was the 2017 tax act, affecting software R&D starting in 2022. Depending on how you classify those expenses, you could have a sizeable tax bill, even without any 'profit'. But even hardware - that's typically going to be amortized over minimally a few years. Bring in $200k in revenue. Spend $20k on hardware. You may only get to deduct $4k of that hardware expense in each of the next 5 years. reply asim 22 hours agoparentprevThis is super cool! I was/am a startup founder too, bootstrapped an open source project, raised VC money, but ultimately it didn't work out. Now thinking about a solo business again and the studio model was exactly what I was looking at. How did you decide what to build? reply philip1209 22 hours agorootparentMy first product Postcard [1] is a personal website builder. I built that because I thought a personal website maker made logical sense as an indie business, and I wanted a way to stay in touch with friends after I deleted social media. But, it's hard to scale - user acquisition is the name of the game, willingness to pay is lower, the product isn't super differentiated, and I don't have a lot of experience in B2C. So, it makes money and continues to grow - but is small in absolute terms. I decided to work on a more ambitious project that I had been thinking about for years, inspired by a product I wanted at my last startup, and by the chaos of being in 100+ slack channels at a previous job. I hate how people use Discord + Slack - they're good for urgent communications, but we need a \"low-attention\" version for important communications in communities and at work. So, I started building this product last Summer. Booklet is an async, newsletter-first community platform [2]. Something like Google Groups with the polish of Slack. Booklet's far more complex than Postcard, but plays into my skills more - such as complex permissions systems, email marketing infrastructure, B2B sales, and being able to incorporate all the latest OpenAI goodies quickly. I launched it about three months ago, it has revenue, and I've been scrambling to build things in response to user feedback. I'm thinking of doing a bit of a relaunch next week as some foundational flows come together, such as full PWA support, search, and Stripe member sync. Coincidentally - the project I launched to dogfood Booklet, called FRCTNL [3], is doing quite well. I had no intention of monetizing it, but I included a referral link to the accounting service I use. People have been using that referral link, and last quarter FRCTNL was my highest-earning product. I'm sure in a few years I will have some great stories after the fact about the lessons I was missing in plain sight. But, things feel a little chaotic, uncertain, and fun at the moment. The core theme is building things that I want. My main insight so far has been to build unique, differentiated products that I want to use myself. [1] https://postcard.page [2] https://booklet.group [3] https://frctnl.xyz reply mamidon 21 hours agorootparentVery interesting, I like the idea of frctl. Signed up. reply derzan 17 hours agorootparentprevWhat avenues did you go through to reach VC funding? Prior connections, or other points of communication? reply philip1209 16 hours agorootparentIt was a little bit of everything, to be honest. reply paulette449 14 hours agoparentprevI hate to have to ask this but how do you manage healthcare being a solo s-corp? I was under the impression this could only be done through a company if two unrelated family members owned the company? The only other alternative is \"Obamacare\"? I could be totally wrong. reply blatzguzzler 11 hours agorootparentSpeaking as someone who has been mostly self-employed since about 2002, Obamacare is a godsend. Massively better than the old individual \"underwriting\" system that basically made it impossible to get coverage. Yes, health insurance is expensive, but you may be amazed that the ACA marketplace plans frequently cost less than employer plans with better market protections. The only way to do health insurance nowadays is to assume it's only for catastrophes; ie: an $8-15k deductible is nothing compared to a $250k hospital visit. Basically, you are buying a discount plan (your insurer's negotiated rates) plus a stop-loss cover. An example: I am an old fart at 63 and have an HSA plan with a $7,500 deductible. My premium is $900/mo, thus the MOST I will ever have to pay for health care in any 12 month period is $18,300. Way less than a $300k uncomplicated heart attack or a $1M cancer diagnosis. Work your tax returns right, and you can get subsidies that reduce the annual costs even more . . . reply whitepoplar 11 hours agorootparentAre you able to purchase a PPO plan in your state? reply hotpotamus 11 hours agorootparentprevIt's probably worth remembering this sort of thing when people say there is no difference between the parties. Every Republican voted against it, they almost repealed it, and apparently are gearing up for another crack at repeal https://www.theatlantic.com/politics/archive/2024/01/trump-o... At your age, you'll likely be on Medicare soon either way, but some of us are still decades away. reply blatzguzzler 8 hours agorootparentI truly am waiting for Medicare (traditional only, no Advantage plans as those are a complete rip-off). I can tell you though, I've been continuously on the ACA since it started selling plans in 2012 and it's always been better than anything I could cobble together before. It's fantastic to be able to decide how and where I want to live my life without being locked into a shitty job or tied to a crap insurer because you can't pass underwriting to get on a different plan. Also, I am on the highest ACA premium tier because of my age. Someone who's 35 could get the same policy I have for about $400/mo., unsubsidised. reply hotpotamus 7 hours agorootparentThank you - as someone with a bit of disability and facing future hip surgery, that's a helpful perspective. You're not far off on my age; I actually aged off my parents insurance right around the time the ACA passed and so I was able to get back on because of that law which extended parental coverage until 26. I'm currently quite happy with most aspects of my employment which includes my health insurance, but that situation never seems to last. reply philip1209 8 hours agorootparentprevI found a broker who would give me insurance for one person, but the offering wasn't good. So, I'm on a mediocre Helathcare.gov plan. This article has good details: https://www.collective.com/blog/health-insurance-for-s-corps reply voiceblue 13 hours agorootparentprev> unrelated family members Is such a thing even possible? reply whitepoplar 13 hours agorootparentprevI'd love to know this as well! reply nlh 17 hours agoparentprevThis is awesome! Nice work. This model was a dream of mine for a while -- I generally love being solo but even a small group of 3-6 people working on a revenue-generating digital product studio has so much potential to be super super fun. Good luck with it and keep us posted! reply rainclouds 14 hours agoparentprevThere is someone renting a room around Mount Fuji on AirBNB that advertises themselves as a systems engineer with fiber in the middle of the woods. Sounded like a great place to work to me! reply philip1209 8 hours agorootparentStarlinks are starting to pop up on Airbnb listings. reply kgdiem 21 hours agoparentprevWow! I’m working on the same thing at https://stackstudio.dev right now. Your blog post was really eloquent, it’s always inspiring when someone else shares your idea. Best of luck. reply philip1209 21 hours agorootparentThanks! I'm trying to do more essay writing there [1]. Most indie makers seem to have some content strategy where they share their story. I avoid social media and don't desire to become a Youtuber, so I'm focusing on writing as a content channel. I'm focusing essays on my creative process, inspiration, and specific experiences as an operator - the stuff I want to read. I'm avoiding prospective predictions about the future, being negative (an actual self-imposed rule), and talking about things that feel more like theory than practice. The next piece I plan to publish tomorrow will be a recap of a talk I gave over the weekend, covering how most of our knowledge work practices come from factories, and ways software engineers are at the forefront of changing those industrial-era practices. P.S. - if you're ever in NYC, come join for a dinner of Dimes Square Ventures [2], which is a little community I run for local indie makers (using Booklet!) [1] https://contraption.co/essays [2] https://dimessquareventures.com reply kgdiem 15 hours agorootparentI live in Hoboken :D sending you an email for dimessquare! reply j4yav 19 hours agoparentprevReally cool - I’m in a similar boat, having created startups and also was a PM in senior roles at a few great companies. I’ve been consulting, which is fine, but wanted something with a little more connection to the project so I just set up https://metaluna.io and am aiming for something on the agency route. That said, I really like the way you’re thinking of a “digital project studio”. Is there a community of people doing this somewhere? reply pawelwentpawel 17 hours agoparentprevSame here! I've been running my own digital products (https://flat.social and some smaller ones) and bridging the gap with consulting. For me, the flexibility lead to a fully location-independent lifestyle which allowed me to work from places where I feel at my best. Currently writing this from a tropical patio in Brazil :) reply hellojebus 18 hours agoparentprevLove the comparison against Grand Seiko. I'm a self-proclaimed watch nerd and owner of a Shunbun. Grand Seiko makes beautiful watches! reply benjaminwootton 17 hours agoparentprevIsn’t it difficult for one person to market multiple products or websites? It’s hard enough getting traction for one product, let alone a portfolio? reply philip1209 16 hours agorootparentAfter I sold my last company, I felt like my identity was overly tied to one product. So, I decided to build a company separate from the products, so that over time the products can change but I have a through line company brand. When I started this comapny, I didn't have a product - but I had the holding company (Contraption Company). My first product was Postcard, but now I spend most of my time building Booklet. As the shift in products has happened, my professional email address has been the same, the terms of service have been shared between services, and I have a unified blog + announcements email list. This also means I can launch lightweight experiments such as \"FRCTNL\", and even if it's not commercially successful - I benefit from compounding returns in the brand and mailing list. reply mentos 16 hours agorootparentI'm self employed in NYC and its a dream of mine to travel/work in Japan. I've sort of written the idea off that unless I can speak the language its going to be too difficult. Curious if you agree or not. reply philip1209 16 hours agorootparentI speak zero Japanese. I've met a lot of immigrants here in the last couple of weeks, and it seems that you can get to a working level of Japaneses within a couple of months. After that, it seems that working for a Japanese company IRL is the biggest determinant of becoming fluent. The good news it that Japan seems to be in desperate desire of skilled foreigners, and announced plans this week for a digital nomad visa: https://www.japantimes.co.jp/news/2024/02/02/japan/society/d... I've heard that the path from temporary visa to a more permanent one is somewhat straightforward for a self-employed person if you're able to show moderate revenue from Japanese clients. reply bouh 19 hours agoparentprevCan you tell us a bit more about this creative residence and how did you get accepted there ? reply philip1209 19 hours agorootparentYes, it's called Almost Perfect. I previously followed the illustrator Luis who co-runs it, and applied back in 2022. https://almostperfect.jp However, the current \"version\" of Almost Perfect is ending in about a year, and I think they are fully booked until then: https://www.instagram.com/almostperfecttokyo/p/C2PCMtpS_wq/ It's been a fun experience, though - I shared a house with an illustrator from LA. I spent time exploring Tokyo and working on Booklet. At the end, every resident gives a gallery - normally it's visual, such as drawings, but mine became a presentation. reply sixQuarks 17 hours agoparentprevWhat is a creative residence? reply philip1209 16 hours agorootparentKind of like a structured professional sabbatical / workcation with a built-in community and some events. (I paid for it, to be clear.) Here's a video one of the residents made about the program I did: https://vimeo.com/350701368 reply sixQuarks 15 hours agorootparentInteresting, what did you work on there? reply philip1209 8 hours agorootparentI've been building Booklet features: https://hq.booklet.group/posts reply ryanwaggoner 10 hours agoparentprevI thought NYC didn’t recognize the S-corp, so you end up paying the corporate tax rate. Has that changed? reply philip1209 8 hours agorootparentHasn't change, it's pretty terrible but my accountants thought it was marginally better. I've heard that some people get an office outside the city (such as Hoboken) to \"work\" outside the city. reply hypertexthero 17 hours agoprevSelf-employed on and off as a graphic and web design consultant since 2005 or so, with some time in offices, making websites with static generators, PHP/WordPress, and Python/Django, and print work with pencil, ink, paper, and graphics apps. Tips: 1. Live simply and reduce expenses. Avoid debt if you can. Rice and beans recipe: https://hypertexthero.com/eat-play-read/ 2. Try to be nice to other nice people and stay in touch with past co-workers, especially the nicest ones. They make the best bosses or clients later. Don’t burn bridges unless there is no other option. 3. Always be working on a project for yourself that you enjoy and can learn new skills from. If the project could be useful for others, clean it up a bit and share it. 4. Use a paper weekly planner and write down things to do and cross them out when they’re done. Write ideas and things to look up here. Have a drawer or cardboard box in which you throw pieces of paper with ideas written on them. Open the drawer and pick a random piece of paper when feeling stuck. 5. Look in the mirror now and again and ask yourself if you are happy with the upcoming day. If there are too many days in a row when you’re not, time to change, move, etc. More: https://hypertexthero.com/reignite-passion/ reply neilv 15 hours agoparentThe first tip about being self-employed is funny and telling: > 1. Live simply and reduce expenses. Avoid debt if you can. Rice and beans recipe: Some people can make really good money self-employed, but for the rest of us (including myself), salaried employment would've been much easier. Also, a period of lower income will keep paying negative dividends afterwards, because it's expensive to be poor. There might also be long-term impact of stress, if the lower income and uncertainty of being self-employed had more net bad stress than the corporate job would've. (Though corporate BS as an employee can be the worst stress, worse than not knowing whether you can keep your self-employed business afloat.) reply bruce511 2 hours agorootparentBeing self employed is not for the faint-hearted. You get to work long hours, for irregular pay, for lots of different bosses (I mean customers), and as a bonus (if you succeed) you get to deal with difficult staff. And those are the good bits... On the other hand you are more in control. You decide what to work on, and when. You decide how many zoom meetings to have (well, sort of.) You won't be laid off (although you might not get paid.) There's no office politics, and no boss to get jn your way. Sure it can end up being financially rewarding, but a good job, with good investing, likely comes out ahead. reply kmarc 15 hours agoparentprev> Live simply and reduce expenses. Besides the obvious message here (less spending, more money to save), the simple life is that gives you less headache and burden of administration, which is a huge pro when it comes to \"being on your own\" (eg managing yourself as a business). In general, minimalistic lifestyle xnot owning stuff (especially expensive stuff like a car, home, etc) gives so much freedom... reply spookybones 7 hours agoparentprevAre you still finding clients for static websites and Wordpress? I got out of that game six years ago and am considering getting back in as a side-hustle. It seems though that most of that freelance work has dried up. reply mauvehaus 17 hours agoprevI am a self-employed furniture maker. I'm that guy who somewhat infamously no longer builds software[0]. About a year ago I moved my operations from a makerspace to my own shop. That's come with its ups and downs. On the one hand, I know which idiot last used a tool: me. On the other, I would no longer see other humans besides my wife most weeks. To keep sane I also work one day a week at a bike shop fixing bikes. It's something I'd done on a volunteer basis many years back. The unexpected nice thing about this is that it gives me projects that are an hour or two in size in addition to the many-week sized projects that I do as part of my business. It's sort of like getting to fix a small bug in the midst of adding a big feature; it lets me pop out of the big project for a bit and see something else through from start to finish and see some tangible progress before diving back into a long-running project that moves forward in fits and starts. Beyond getting to tackle some bite-sized projects, I'd say the thing that sustains me is getting to work with clients. It's tons of fun when people come to me with a vision that we can iterate on and bring into reality. And then the flip side is also rewarding: getting to scratch an itch and turn a design I've been turning over in my mind into reality. Edited to add: If you've got an idea for a furniture or woodworking project, my contact info and website are in my profile. https://github.com/docker/cli/issues/267#issuecomment-695149... reply oooyay 16 hours agoparentHah I remember seeing this issue. It made me chuckle. I also do wood working part time, it's kinda funny how similar software and woodworking are. I'm hoping to open up a hobby shop one day that teaches both software and woodworking. Congrats to you on following your dreams. reply buttermonster 16 hours agoparentprevI'd love to hear more about this. I'm a software developer by day and woodworking is a huge passion. Alas due to full time job, kids and other commitments, I don't have much time for it at the moment. Did you start off with woodworking as a hobby? If so, has it affected your enjoyment now it's a job? What pitfalls did you find when you first started out? reply mauvehaus 15 hours agorootparentI'm sorry you don't much time to pursue it; It's a delight to get to build things! I might be a little weird in that I started woodworking by taking classes to explore it as a possible career change. I took some evening classes, followed by some week-long classes to see how it would feel to do it all day for a full week. It's not directly comparable, but it was close enough. Given that I got into this with the intent of it possibly being a job instead of going from hobby to career, I'm not sure I have a good basis for answering whether doing it for work has sucked the enjoyment out of it. I love building stuff, and when I get tired of doing one kind of project, I seek out other types. Sometimes I quote something lower than I otherwise would if it's something I'd like to do (or vice-versa). Honestly, I feel incredibly lucky to be able to do this for work. The parts that do sometimes wear me down are the non-woodworking parts. Today I'm in front of my computer getting my books finalized to get a P&L to my accountant for our taxes. I can enthusiastically recommend FreshBooks for having excellent support, but damn, bookkeeping is not my thing. Figuring out how to market the product is also a trick; I don't have a background in that, and I'm probably overlooking opportunities as a result. Keeping a website up to date is sometimes kind of a hassle. My wife does most of the nuts-and-bolts work (because otherwise I'd get hung up on stupid stuff that doesn't matter), but I'm still very much a part of generating the content. As for pitfalls, I guess the above has pretty well covered it :-D Figuring out the non-woodworking aspects is a continuous learning experience. reply jeanlucas 16 hours agoparentprevI still find your comment hilarious reply darajava 19 hours agoprevI am working on https://audiodiary.ai as a solo founder, I recently have been getting enough income to just about cover my living expenses and haven’t received any funding and didn’t do any marketing, with 9k users so far since launch last May. It’s fulfilling and great to see people use and love a product I’ve built. I’m obviously highly motivated to grow so it keeps me busy. reply jamesmurdza 18 hours agoparentCongrats—That is awesome! Curious, how long did it take you to get your first customer? reply darajava 16 hours agorootparentIt happened very soon after launch actually, maybe a few days. Because the name essentially is a search term, people were able to find it right away reply plants 17 hours agoparentprevThis is such a good idea, I wish I’d thought of it. I have trouble maintaining consistency in journaling, but this makes it a heck of a lot easier. I just signed up - good luck! reply darajava 16 hours agorootparentThanks very much for signing up! Any issues, questions, or ideas please contact me-you can directly email me from the app. reply bart7782 17 hours agoparentprevI could not find any pricing options on your website. In order to find how much your service would cost, i needed to create an account and also download the app. You also did not specify which features would be locked behind a paywall. Can you be more transparent about this? I like to know what i'm getting myself into before i start using a product. reply darajava 16 hours agorootparentSuch a good point, I never thought of that and think it would add credibility to the product too. 90% of traffic comes from the app store and the pricing is shown there on Google and Apple, most people never see the landing page, but I think this would be good to add. PS it’s about $30 for a year and $6 for a month (depending on your state/country) reply throwaway2203 16 hours agoparentprevLooks cool. Would love to know pricing and how/where you store data? reply darajava 16 hours agorootparentPricing depends on the country but have addressed that in another comment! The privacy policy explains how we store data but will make this clearer and more upfront. I store recordings separately from user info in an S3 bucket and the database is hosted in digital ocean. Recordings are sent to OpenAI for ephemeral analysis and transcription. reply throwaway2203 13 hours agorootparentCan I export the recordings and the resulting (presumably text) diary? reply jjackson5324 18 hours agoparentprevThat's really amazing. You should start doing some marketing to accelerate the growth! If you don't mind, can you share how much you're currently able to make from this? reply darajava 16 hours agorootparentThanks very much! I’d like to learn more about marketing to help me grow it. It’s hard to put an exact figure on it because it’s essentially growing every day which i’m so happy about, but recently it’s become just enough to sustain me. Perhaps at an entry level software engineering position reply fredsted 19 hours agoprevI've been working on https://webhook.site since 2016 when I posted it here on HN. In fall 2023, I quit my job to work on it full time, and it's one of the best decisions I've ever made. I have around 1400 subscribers, which is enough to pay myself a good salary. I've not done any funding or marketing so far. reply jjice 19 hours agoparentWow, I use your service all the time for misc testing and it's fantastic. Lean, responsive, and straight forward. I honestly didn't realize there way any paid option until I read this and took a look around the website to find it (I completely missed the upgrade button in the upper right). I figured I'd mention that from a user's perspective to give you a data point. Great service! reply fredsted 18 hours agorootparentThanks for the feedback! reply belinder 19 hours agoparentprevThis looks really useful, I've used similar websites in the past but it's nice that it's all together here in one place. If only you could not have it redirect on load, it makes the back button break. Clicking back to return to hackernews is almost impossible reply fredsted 4 minutes agorootparent> not have it redirect on load I've not been able to reproduce this in neither Safari nor Chrome (https://sf.gl/share/1707213387.mp4), curious to know which browser you're using. Thanks! reply snovv_crash 18 hours agorootparentprevPress and hold the back, then select the one you want, works on many browsers reply ohthatsnotright 16 hours agorootparentJobs told everyone they're holding the phone wrong, but it's still shitty that it was broken to begin with. reply bobobob420 17 hours agorootparentprevCtrl/cmd click back button reply scottydelta 18 hours agoparentprevIt's a great product. I have used to test things. One feature that might not align perfectly with your service but definitely something I would use is Email to webhook forwarding and vice versa. reply fredsted 18 hours agorootparentThanks! You can do this with Custom Actions: https://docs.webhook.site/custom-actions.html :-) reply berkayozturk 18 hours agoparentprevI use it almost everyday at work! Thank you for making it. reply svenhof 19 hours agoparentprevThank you for making this great tool. reply ja27 14 hours agoparentprevNice. I was just thinking of building something like this last week lol reply greenie_beans 19 hours agoparentprevnice! good job reply V-2 21 hours agoprevIn Poland, where I'm from, it's pretty much the norm to be self-employed in Poland in the IT sector. I believe that around 50% of workers are technically contracted one-man companies, and this percentage is inversely correlated with the seniority level - the greater the earnings (and the sense of job security that goes along with expertise and experience), the greater the incentive. Going B2B makes a substantial difference in terms of fiscal burdens. Other than that, your day-to-day work looks pretty much the same though. You're just sending monthly invoices to the same employer, typically a single one, sometimes for years on end. reply jacquesm 21 hours agoparentThat's for tax reasons only though, technically it is just another form of long term employment. As soon as you have multiple customers that you send invoices to with some regularity and you have autonomy would you pass the 'self employed' test in other countries. If you refer to them as your client and you only have one then you're technically an employee, if you refer to your contact at your client as 'your boss' then you also are an employee. We have a lot of this in NL as well, the long term effect is the slow erosion of the social safety net. Because good luck if your client decides they no longer need your services, suddenly you find out what the downside of being self employed is. Nothing to fall back on. So save like your life depends on it. reply V-2 20 hours agorootparentI can't see why a company couldn't have one long-term customer. It's not unusual eg. in the building sector (where large construction projects, not unlike software projects, can take years to complete). Another common example is MDs - quite a lot of private doctor's offices are contracted by the National Health Fund, basically providing their services for the public healthcare that way. Clearly having multiple customers isn't a reasonable requirement for a small company. Software engineering isn't like private residential plumbing - \"sink drain unclogged, next please!\" :) > good luck if your client decides they no longer need your services, suddenly you find out what the downside of being self employed is. That goes without saying, and the same obviously applies if you're running a \"regular\" company, with employees, like a restaurant or whatever. The risk is arguably even greater, as you will usually pile up some financial obligations (such as credits) and other commodities limiting your financial fluidity (remember Covid? Restaurant owners do). By the way, you can insure yourself against loss of income. Many insurance companies offer this service. reply mcv 18 hours agorootparentThis is definitely a source of friction with the tax service. A couple of years ago, the Dutch tax service was trying to tackle the problem of fake self-employed people who were really just employees without the same rights, pensions, etc. The Dutch postal service PostNL was notorious for firing firing all their mail deliverers and hiring them back as self-employed people who still had to wear their uniform and work according to their schedule. And somehow the tax service approved that. But self-employed programmers who hop between big projects, negotiate their own pay (which tends to the high side) and have a lot of control over the projects they work on and the way they work on them, suddenly have to prove that they're really \"zelfstandig\", self-sufficient. It's frustrating. I recently went back to regular employment and I hated it. Tons of extra rules, limited vacation days, and significantly lower pay. I guess I prefer being in control, saving for my own retirement, and going on vacation as often or as little as I like. Seriously, how many vacation days I had left used to give me stress. It's significantly healthier for me to be self-employed. The way I see it: if a large company can have a single client and just rent out all their employees to that single company, why can't a small one-man company do the same? And I think I'm a lot more self-sufficient than that company; if my contract ends, I can easily get a new contract elsewhere for myself. But if their contract ends, they need to find new work for all of their employees at once, and they'll likely fire some or all of them, making the whole job security argument moot. Their risk is higher than mine, and their security isn't. I really think having lots of self-employed contractors like me is better for the industry than the overhead of having to organise into companies. reply Tade0 15 hours agorootparentIn Poland the government is in on it when it comes to specialists of any kind, as this is how they prevent people from emigrating to the west or \"emigrating\" (tax-wise only) to the Czech Republic, which offers a similar deal. For a while it was possible to have a flat 5% income tax rate, but I guess someone pointed out that it's too generous, so the best option now is a flat 12% and 3% healthcare contributions. reply jacquesm 19 hours agorootparentprev> I can't see why a company couldn't have one long-term customer. Let's hope you won't find out why that's a very bad idea. > Clearly having multiple customers isn't a reasonable requirement for a small company. On the contrary, it's a must. > Software engineering isn't like private residential plumbing - \"sink drain unclogged, next please!\" :) That's a strawman. Sorry, but if you have just one customer and you're developing software other than taxes and your rights you are less than an employee. Don't kid yourself, that tends to lead to rude awakenings. If at the end of the year you've only sent invoices to a single customer then you are simply at risk. You need multiple customers to be stable and secure. Two is better than one and three is really the minimum. Loss of income insurance is to take care of mishaps, not to insure against market downturns or other normal risks that a business is exposed to. reply mcv 18 hours agorootparentI have multiple customers over time; 3 years ago, I worked on a different project, for a different client, than I do now. But with the kind of projects I work on, it's hard to do several of these projects at once, and they're too long to do several in a year. Expecting self-employed contractors to have multiple clients is unreasonable. As for job security, employment doesn't give a shred more job security than being a self-employed contractor these days. My job security comes from my skills and the succession of successful projects I've worked on. And there are a lot of companies that have a single large customer. I think I have a lot more flexibility than they do. reply jacquesm 18 hours agorootparent> I have multiple customers over time; 3 years ago, I worked on a different project, for a different client, than I do now. But with the kind of projects I work on, it's hard to do several of these projects at once, and they're too long to do several in a year. So please be very careful and if you can find a side gig that doesn't interfere with your main one so you have at least some protection. It could be a low hours but high pay job that way you don't end up eating into your time too much, for instance a coaching job. > Expecting self-employed contractors to have multiple clients is unreasonable. On the contrary: it's a must. Without multiple clients you are super fragile, don't have a strong negotiation position and in case of any kind of headwind you're immediately on the ropes. If you insist on doing long running contracts try getting two that do not overlap in terms of run-time, make one two days a week, the other two days a week or three days a week and bill the smaller job a higher rate. > And there are a lot of companies that have a single large customer. I think I have a lot more flexibility than they do. That's true, but they tend to have a much stronger position than you do due to the kind of contracts that get written between large entities. In a conflict with a much larger entity you usually end up drawing the short stick. They could stiff you on a bill and it would already pull you under water. reply mcv 17 hours agorootparent> so you have at least some protection. Protection from what exactly? > Without multiple clients you are super fragile, don't have a strong negotiation position and in case of any kind of headwind you're immediately on the ropes. Not at all. I can walk away and I have my financial reserves. My negotiation position is stronger than when I'm an employee. > If you insist on doing long running contracts try getting two that do not overlap in terms of run-time, make one two days a week, the other two days a week or three days a week and bill the smaller job a higher rate. This sounds like an absolutely terrible idea. I'm not going to undermine myself like that. > They could stiff you on a bill and it would already pull you under water. One (very small) client did stiff me on a bill. I won't work for them anymore, and I tend to prefer larger clients now that simply do pay their bills. I have considered suing them, but the amount was too small to be worth it. It didn't pull me under water. reply jacquesm 17 hours agorootparentOk, never mind me then. Best of luck with the career! reply V-2 16 hours agorootparentprev> > I can't see why a company couldn't have one long-term customer. > Let's hope you won't find out why that's a very bad idea. The way you phrased it feels needlessly patronizing (perhaps unintentionally), but more importantly, it does not really address my comment. I wasn't arguing if it is a good idea or not. I was responding to the argument that having multiple customers is necessary to be regarded as \"truly\" self-employed in the eyes of the taxman. My point is that it's not uncommon nor unusual for a small company to be invoicing only a single customer. Hence my examples. Whether it is safe business-wise is another story. > If at the end of the year you've only sent invoices to a single customer then you are simply at risk. You need multiple customers to be stable and secure. Two is better than one and three is really the minimum. Noone denies that having diversified sources of income is (other things being equal) the safer option. But the subject was legal recognition, not optimal business strategies. reply jacquesm 15 hours agorootparentIt may come across as patronizing because that's roughly how I see this. I'm at the end of my career after a very productive stint and have absolutely nothing to lose by letting you have the benefit of my experience to date, which spans a couple of continents, six countries and a substantial amount of money. Whether you are open to that kind of experience backed input is entirely up to you, I have no upside here, but you do and you also have a possible downside. But: when I was 27 or so I might have still seen things your way so maybe in 30 years you'll be telling someone else the same things. I sincerely hope that you will never find the true measure of how important those things are and if I could give my younger self some advice that would be it. As for legal recognition: the only reason this is a thing right now is because the social contract is broken, in any other setting you'd be an employee. reply KptMarchewa 15 hours agorootparentprevWhat rude awakening? The situation is exactly the same as losing a job: you are now jobless and need to find the next one. The \"safety net\" for a high earning individual does not exist anyway. reply dappermanneke 18 hours agorootparentprevsounds like you simply really don’t like freelancers. you know no one stops you from accumulating reserves in your company or in general, right? reply jacquesm 18 hours agorootparentYou're funny. I've been self employed for the last 30+ years and I really enjoy it. But I know the risks and I'm making sure I don't get burned because having only one customer is just setting yourself up for various kinds of failure. I love freelancers and I love freelancing. But I know the difference between being a freelancer and running a company and being an employee in all but name and you really don't ever want to be in that position. reply dappermanneke 18 hours agorootparentthe way not to get burned is to charge high enough with trustworthy clients, take some insurances and to be aware of your pension provisions that will vary by country. whether you have 1 or 3 clients at one point in time is immaterial as long as it doesn't sour your relationship with your clients I appreciate that it sounds like you had a bad experience with a client though. reply jacquesm 18 hours agorootparent> the way not to get burned is to charge high enough with trustworthy clients That helps. What helps even more is to have a nice fat savings account that allows you to negotiate properly, to weather the inevitable dry spells, to build a solid base of clients that value you and that will repeatedly hire you. > take some insurances Against what? 90%+ of the freelancers are not even insured against loss of income from health related issues. The remainder is well off enough that they can probably afford to take the risk. > whether you have 1 or 3 clients at one point in time is immaterial as long as it doesn't sour your relationship with your clients Until: that one client goes bust, there is a 'policy change', the project/product you are working on gets axed, the economy burps, your main contact at the company gets fired and the new guy or girl doesn't like you and so on. > I appreciate that it sounds like you had a bad experience with a client though. I appreciate that it sounds like you haven't had a bad experience yet, but that makes you simply less experienced. Give it some time and you'll see all of the above and variations on those themes. Here is a 2011 booklet I wrote on the subject. https://jacquesmattheij.com/be-consultant/ reply dappermanneke 18 hours agorootparentas I already mentioned having reserves is indeed very important in my jurisdiction there are for example some excellent guaranteed income insurances covering various situations. they won't pay forever, but they'll pay. income replacement due to health issues is covered by normal social welfare in my jurisdiction as well all of those things you mentioned happen regularly to employees. they are harder to let go, sure, but employers have a lot more leeway to make your job hellish enough to force a resignation, or if the economy is really bad overall they can throw their hands up and say we're cutting divisions of the business with no objections from the law in most places. sure you can go to your work council (hope they are on your side) about it, or to the union (hope they have time for you and you're lucky enough to have enough evidence to win the tribunal) or the lawyer (hope you have a legal assistance insurance and are ready for years of process and fees). employees without a savings buffer are similarly vulnerable in these circumstances the biggest reason to stay an employee if you can consult instead where I am is really the unemployment benefits you can get, but that now takes up to 10 months to actually start paying out due to how understaffed the government is. so again, best have some reserves. the next biggest reason is you hate paperwork reply matsemann 18 hours agorootparentprevThe point isn't that they doesn't like freelancers, but doesn't like how the employers misuse that to get workers without rights. \"Oh, you're not employed here, so we don't have to follow labor laws, we can just terminate the contract\". reply mcv 18 hours agorootparentIf I'm not mistaken, in the US employees can also be fired just like that. Meanwhile my contract specifies a month notice for both sides. And that was their preference. I'm totally fine with being fired; that flexibility is also part of what I sell. It's why they pay me more than they pay employees. reply dappermanneke 18 hours agorootparentprevthe worker rights issue is mostly a concern for blue collar workers that are forced to become freelance by some companies to save on welfare costs. that is what tax authorities actually look for when they talk about \"false self-employment\" and that is why it is the company giving the assignment that gets punished in these situations and usually not the freelancer. that's not really a concern for high billing consulting professionals. it is a common misunderstanding (as you can see from comments here) though and is variously used by companies to undercompensate people who could be far more profitable consulting reply lotsofpulp 20 hours agorootparentprev> By the way, you can insure yourself against loss of income. Many insurance companies offer this service. In the US, I am not familiar with insurance for loss of income due to simply not being able to sell products/services. Usually, the loss of income has to be a result of covered natural disasters, vandalism, legal issues, etc. Most business insurance policies even specifically exclude pandemics, as many found out recently. reply radicalbyte 18 hours agorootparentprevIf you're not jumping around contracts regularly every 2 years in NL and are not billing the approximate annual wage for your role every year (assuming that you work the 40-44 weeks) then you're an employee and shouldn't be contracting. The market now is interesting - there are a huge number of low experience / low skill people flooding the market which has driven prices down for some very good people whilst also making it hard for companies to actually find qualified people. It actually lead to me rejecting a project who really wanted me and I fancied (Government but with a chance to have a really big positive impact on society; I moved mountains with the last project and learned some valuable lessons, seemed a shame to let that dull... oh well). I've been doing it for about 8 years now, I enjoy it and it has allowed me to both grow like crazy and do things I've always been capable of but wouldn't have attempted as an employee. The other thing: funding in Europe for ventures is horrible compared to the US. I'll be looking to raise for a project this year and I'm dreading it (Healthcare, we're going to try the public route first because it would be better long term.. although it will leave money on the table it will increase the probability of success we believe). reply jacquesm 18 hours agorootparentYou should be billing a multiple of the approximate annual wage to offset the risks of freelancing. Twice is good, three times is better. If you can't do that you're much better and safer off to find employment so make sure you understand exactly what the risk/reward trade-off is for being a freelancer and set yourself up accordingly. Find customers that value you and make sure they pay and pay on time. A single hickup in the payment department is a good reason to start looking for a replacement customer. And never ever rely on just the one customer: your negotiation position is now crap and if anything happens to that one customer, their customers, their market or the relationship then you're done. If and when you are looking for funding for your healthcare start-up please contact me, I may not be able to invest myself but I do have a whole pile of contacts and some of those are doing regular medical investments. reply KptMarchewa 15 hours agorootparentYou don't seem to understand that using B2B contacts for work is something different than freelancing. reply sparks1970 18 hours agoparentprevIn the UK this was normal for IT (and other) contractors because there were tax advantages to the employer and to the employee/contractor. The employer could avoid paying National Insurance (social security) taxes of 10% as well as pension and sick pay contributions. The employee could pay themselves a small salary - enough to get social security benefits but be in the lowest or no-tax band and pay the rest as dividends from their limited company where tax was paid at a lower rate than income tax. It was a good wheeze but some years ago the govt bought in legislation \"IR35\" which basically says that if it looks like a employment contract then it should be taxed like a \"normal\" employment contract. reply lqet 21 hours agoparentprevThis would be quite risky where I am from, for both the freelancer and the employer. Being self employed, but only for a single customer, is false self-employment. If you get caught, your employer has to pay taxes and social security contributions retroactively for up to 4 years, and afaik both the employer and the freelancer are liable for the money owed to the tax office and social securities. If you are caught doing this premeditated, it might be a criminal offence. reply V-2 21 hours agorootparentThis risk does exist in Poland, but among the criteria for \"false self-employment\" is being expected to work within fixed hours, and in a location specified by the employer. As IT workers - even those who've got contracts of employment - typically do flexible hours, and pretty often work from home (or otherwise remotely), it doesn't really apply. reply knallfrosch 21 hours agorootparentprevIf you're from a country like Germany, most of what you're skipping financially is the insurance cost that's covered by the employer (social security etc.) Which means you don't have access to the social safety in case you need it. reply atraac 20 hours agorootparentIn Poland(since I'm also from here), biggest chunk of savings when working as self-employed is income tax and mandatory public retiremend fund. Most Software Engineers go B2B/self-employment route because not only taxes are lower, but savings from paying minimal public retirement are pretty big with higher salaries. We're at a point where most people in Poland do not believe in retirement system anymore, it's unsustainable and will crash or will be kept with social, minimal retirement, no matter what you paid in. That's why most of us want to save on the side, put that into ETFs or housing rather than count on the government, especially that over last decade or so almost destroyed this country. reply KptMarchewa 15 hours agorootparentExactly. Only 3% of millennials believe that state pension system will allow them to survive. https://forsal.pl/artykuly/1415939,srokowski-tylko-3-proc-mi... reply KptMarchewa 21 hours agorootparentprevIf you earn enough, the savings can easily surpass the risk for a singular person. It's worse for society overall, but let's not pretend the high earners don't mostly subsidize the safety net. reply V-2 21 hours agorootparentThe IT sector in Poland (again) is a booming one, and most of the services are effectively exported, as we're talking outsourcing. I guess it translates into the lack of political will to curb the practice, too, as the government would risk that self-employed programmers (and whatnot) may not fall in line, but mostly log out of the system instead, registering their companies abroad, for example. I guess the government isn't eager to start this cat-and-mouse game, preferring a smaller slice of a bigger pie. There are even some extra incentives on the top of the flat income tax rate (which is an option for all one-man companies, regardless of the sector)... Like the \"IP Box\" tax relief, which drives the income tax rate from the regular 19% all the way down to 5%, as long as you get your services classified as \"research and development\". It takes some patience and loads of legal paperwork, which you obviously have to pay for (the latter, that is), but it's well worth it in the end. reply KptMarchewa 20 hours agorootparent>registering their companies abroad, for example. \"Registering\" the business only is a trap and a way to pay much much more _when_ the tax office decides you are avoiding taxes. To truly do that, you need to move your center of life abroad, which generally means being outside Poland for 183 days a year. >I guess the government isn't eager to start this cat-and-mouse game, preferring a smaller slice of a bigger pie. I agree that it mostly is the case, as I still pay few times more taxes (and VAT on consumption...) than average citizen, even when using 12% lump sum tax. reply V-2 19 hours agorootparent> To truly do that, you need to move your center of life abroad, which generally means being outside Poland for 183 days a year. Yeah, theoretically. But at least within the Schengen area, that's pretty difficult to prove/disprove, especially if you've got no family. I'm working remotely, I'm renting a cheap room in Budějovice, here's the tenancy agreement. Come see if my toothbrush is wet :) reply lifestyleguru 17 hours agorootparentprevIn developed countries IP means submitting patents and real research which build the company's position on the market. That's why they have strong companies and brands. The Polish \"IP box\" is creating and submitting PDFs with git diffs of Java and TypeScript written for these companies. Just remember to remove passwords and secrets from them, guys. reply V-2 16 hours agorootparentNot all intellectual property is patented. Anyhow, you don't include git diffs. You cannot, even if you wanted to - the code is not your property. The whole point is that you're selling your intellectual property rights. It also means that the tax office pretty much has to rely on your word that the work is innovative in nature. Obviously they'd be in no position to tell the difference anyway. reply mkaszkowiak 19 hours agorootparentprevSimiliar laws are in Poland, except they're not really enforced. It's really rare that the tax office would prove a company exists solely for tax optimization. The risk virtually drops to zero if one freelances after the hours and has legitimate invoices with other companies. This often causes mismatch between Polish employees who wish to work remotely abroad, and for ex. employeers from the DACH region, where I've heard the laws are strictly enforced. One party claims there is no risk, and the other claims it's too risky :-) (taking other factors aside, such as employee protection, etc.) reply strobe 17 hours agorootparentprevsure that the case in lot of countries but is something really wrong with idea to have 2+ clients as minimum because reason why work done in that way is because person doing it don't wanna agree on terms that 'employment' contract is required and if that 'single' client is gone he always can get another one in few months. Sometimes you work with few clients in single year but sometimes it just one for 2-3y. And worth part that in some places taxes on self-employment might be higher. reply lifestyleguru 21 hours agorootparentprev> Being self employed, but only for a single customer, is false self-employment This is exactly what happens in Poland and everyone involved feels very smart for cheating the system. That's also why software from Poland is such a tacky crap despite so many \"talents\". The software professionals have no leverage to push back, they only can walk away. The irresistibile benefit is that one can write off buying a car into operating costs, so the dream of PREMIUM GERMAN CAR prevails over doing anything creative. reply mkaszkowiak 19 hours agorootparentHow is tax optimization related to the quality of developed software? reply lifestyleguru 17 hours agorootparentIf you have to breach rules which are a standard in developed countries, means exactly that you are uncompetitive with your skills. Funny that social and salary dumping where exactly the populist argument that the British voters picked up most eagerly in referendum on Brexit. That's post-Communist mentality to feel satisfaction from \"screwing someone over\", it's devastating the social trust, on macro scale it doesn't pay well. reply mkaszkowiak 17 hours agorootparentI still don't see how developing high quality software is related to one's personal viewpoint on taxes. reply lifestyleguru 16 hours agorootparentThat's very smart. reply badpun 12 hours agorootparentprevYou don't have to breach any rules. Every job offer I've ever had in Poland had an option for regular contract of employment (\"umowa o pracę\"). If you want to be taxed more, that option is always on the table. reply V-2 20 hours agorootparentprev> That's also why software from Poland is such a tacky crap despite so many \"talents\" [citation needed] How do you recognize \"software from Poland\" anyway? reply lifestyleguru 20 hours agorootparent> How do you recognize \"software from Poland\" anyway? Whatever is created in all these nearshoring and outsourcing centers in Warsaw, Kraków, and Wrocław. Currently mostly Azure, SAP, business Java and Angular. reply V-2 20 hours agorootparentYeah, but how do you know which application was and which wasn't? Apart from some big customers, it usually isn't public knowledge. Eg. my previous project was a banking app for a rich Middle Eastern country. There's no \"acknowledgements\" section in the app. My original question still stands - by what metrics do you regard \"software from Poland\" as \"tacky crap\"? I'm not being belligerent about it, but somewhat curious, sure. reply lifestyleguru 20 hours agorootparentAin't gonna fight. Good luck. reply V-2 19 hours agorootparentI'm not fighting, I was just curious what you're basing your claim on. I disregarded your unnecessarily incendiary phrasing (\"software from Poland is such a tacky crap\") completely. reply SomeoneFromCA 15 hours agorootparentSoftware from all of Eastern Europe and ex-USSR is lower quality than American and Western European. Source: live in ex-USSR. We all hired to deliver shitty code for low cost. Not as shitty as Indian, but you get what you pay for. reply lifestyleguru 11 hours agorootparentHere is another mistake, some weird superiority. For the HQ in London, Munich, San Francisco, or Zurich, they are all in the same outsourcing low cost league as Bangajabad. It completery doesn't matter for them whether AI in Java and Kubernetes on Azure is bloated 2 or 3 times too much. Occasionally show them some low quality codebase from India to stroke their egos \"you see that's why we keep the office in Novowsky\". reply dappermanneke 18 hours agorootparentprevsome of the best eu engineers I’ve worked with were polish freelancers reply badpun 12 hours agorootparentprevIn my experience, the software can be crap because the companies tend to only hire technical people over here in Poland, while business guys remain in the HQ. The highest business person you'll see in Poland is typically a PO, while a PM and people above him are in the headquaters. This has the effect of not keeping the Polish team tightly in the loop, which translates into worse software. The second problem is that the companies tend to hire a lot of people at the same time when they open their offshore/nearshore center in Poland - often going from zero to hundreds, or even thousands over the span of just a couple of years. Having such large organization of effectively people with no previous institutional history is akin to a herd of only young elephants, who don't have any elders and don't know what and how they should be doing exactly. The \"elders\" are in the HQ obviously, but building company culture exclusively over Zoom, especially on the scale of hundreds/thousands new hires, is a bad idea. reply lifestyleguru 11 hours agorootparentThis isn't a mistake or overlook. They treat the office like a sweatshop. No you are not exceptionally skillful. Within weeks they're able to move to a cheaper location and they will once their Excel will say so. It's so funny seeing devs on B2B in Poland thinking they are some entrepreneurs while for HQ they are in the same league as another office in Pajarumbad. reply badpun 1 hour agorootparentThey don’t move to cheaper locations though, because the work quality would suffer. So far, I’ve only seen one group of people laid off in Poland and their jobs moved to India - DB admins. The company deemed the job simple enough to risk moving it to an outsourced Indian sweatshop. The results were terrible BTW. Also, your experience is very different than mine, I’ve never meet anyone working in Poland doing coding for a company abroad thinking they’re some kind of entrepreneur. They’re not delusional, they know that they’re just doing a job, selling themselves to a highest bidder like everybody else. reply KptMarchewa 15 hours agorootparentprevAzure and SAP are crap everywhere. reply KptMarchewa 15 hours agorootparentprevYou're dealing with some low end companies if german car is somehow a status symbol. reply lifestyleguru 14 hours agorootparentThis doesn't even offend me. Good luck with your sweatshop. reply jokethrowaway 19 hours agorootparentprevAnecdotal, but developers from Poland (and Russia too) have been among the best contractors I've seen. Even the digital tracking / documents system from the government, which is usually a pile of crap in most countries, is pretty well done. I've had terrible experiences with Hungary, Latvia, etc. and (judging from conversations to the owners of the outsourcing agencies) Hungary has very high taxes and not many smart ways of avoiding them. reply poisonborz 21 hours agoparentprevMy home country also regulates this scenario - one-man companies with ~single client - for businesses strongly. This is hidden employment. How would it be beneficial to anyone? - the subcontractor doesn't get any social security. Has to provide everything for himself from the private sector. And pensions (however meager). Theoretically he's free to have multiple clients or vary prices but I guess for most this is a pipe dream and they are dependent. For some tax dodging he gives up the whole legal safety net of being employed. Based on your contract you are freely exchangeable. - the contracting company has more freedoms with getting/tossing employees, although loses a safety net of subcontractor suddenly leaving or changing prices. - the government loses oversight of actual corporate structures. Instead of fixing the flaws in the social system, hidden employment just throws it in the bin because haha less taxes, more money and freedom. reply V-2 20 hours agorootparent> How would it be beneficial to anyone? Most programmers provide outsourcing services for companies from abroad (including outside of the EU). Low taxes help them - and the umbrella companies AKA software houses - to remain competitive on the global market. So even if they only pay a smaller fraction of their income to the budget, it's still better than if they didn't get the gig to begin with, because the contracts would go elsewhere. > the subcontractor doesn't get any social security. You do get healthcare insurance in Poland; no difference here. You're paying those fees just the same way. You're only required to pay minimum pension charges though, so you have to take care of that yourself. (Objectively speaking, investing your savings in the pension system, of all places, probably isn't an optimal strategy anyway. At any rate, noone stops you from paying more than you're legally required, if you think that it is). > the contracting company has more freedoms with getting/tossing employees, although loses a safety net of subcontractor suddenly leaving or changing prices. It's obviously a trade-off. Being able to let people go without fuss if a customer downscales their budget (I was on the receiving end of this last year) is a competitive advantage. > the government loses oversight of actual corporate structures What do you mean by that? reply poisonborz 20 hours agorootparentMy point is that this is a very wrong direction for any country but especially eastern europe. It's like: welfare/health care system is bad, taxes are not used well. Top earning knowledge workers want an exit hatch, let's cater for them and they can hop off the welfare tax system. This way they can also provide cheap prices to foreign companies. So many problems. These are just top off my head: - Countries should want internally organised production, strong companies with own IP, not one-man \"companies\" producing IP to external entities. - Those foreign companies will switch to other countries with better prices (Asia, Africa) any time if their programming scene improves. It's not like they have stakes like when building a factory. - Lot of people think they can invest better, create a better future pension for themselves. This is often true, and why would we want to allow exits, further eroding the whole system? There should be a base pension fund with everyone involved. > the government loses oversight of actual corporate structures To the government the company could be a 5 person shell, while it actually employs/pays salaries of 100s of families. Theoretically you could roll up the contracts, but that would be very complicated. reply V-2 19 hours agorootparent> - Countries should want internally organised production, strong companies with own IP, not one-man \"companies\" producing IP to external entities. Of course it's great to have domestic tech giants (and, sadly, Europe as a whole isn't doing very well in this regard, for reasons that deserve a separate conversation), but these things are largely orthogonal to eachother. There is no reason why a domestic tech giant couldn't have local talents on contracts. Promising domestic start-ups, such as Tidio (mentioning them as they're from my home city) are doing that too. > - Those foreign companies will switch to other countries with better prices (Asia, Africa) any time if their programming scene improves Sure, but having people on employment contracts isn't going to protect you against it. > Lot of people think they can invest better, create a better future pension for themselves. This is often true, and why would we want to allow exits, further eroding the whole system? There should be a base pension fund with everyone involved. And there is. I can't see why preventing people from investing into a better future pension for themselves (on the top of the state-provided minimum) would be a good idea. > To the government the company could be a 5 person shell, while it actually employs/pays salaries of 100s of families. Theoretically you could roll up the contracts, but that would be very complicated. The government has got a centralized system, National System of E-Invoices (or KSeF). It's a fairly fresh thing, but it's becoming obligatory this year. Meaning the taxman gets to see all the invoices without having to jump through any hoops. So even if you are contracting (instead of hiring) a hundred people, it is still transparent. reply mkaszkowiak 19 hours agorootparentprevI agree that it's problematic, however: > welfare/health care system is bad, taxes are not used well There's a widespread lack of trust in the Polish government, which decreased even further during the 2015-2023 period. If the money is being funelled to the ruling politicians' families and friends, why willingly pay high taxes? I believe this is an underlying core issue, which would probably take a new generation to repair. reply V-2 16 hours agorootparentI'm not sure if there had been any unprecented drop in the trust level between 2015 and 2023 (meaning under the Law and Justice government). While it is true that it's relatively low in Poland in general... Eg. according to this survey [1], the percentage of respondents expressing trust in the government decreased from 38% in 2016 down to 32% in 2022 (while clearly exceeding 40% about half way through). Which is pretty normal whenever the same party stays at power for a longer period; its popularity wears out over time. For comparison, the same score was at 39% back in 2012, midway through the term of the government preceding Law and Justice. Hardly a striking contrast. I'm even less sure about your claim when it comes to the context of welfare systems in particular. Social transfers and safety net is one of the very few areas where the Law and Justice government achieved substantial results, even though it had to steer the country through the hardships of the pandemics. For example, in terms of the percentage of children at risk of poverty and social exclusion Poland ranked 14th in the EU back in 2015 [2]. By 2022, it ranked 6th [3]. Also look at [4], [5], [6]... I am putting aside the infamous judiciary reforms, abortion, and other hot button areas (which are far less of a priority for an average voter than echo chamber—commentators tend to assume). I'm focusing on the taxing & welfare, and sheer facts. [1] https://www.cbos.pl/SPISKOM.POL/2022/K_037_22.PDF [2] https://ec.europa.eu/eurostat/web/products-eurostat-news/-/E... [3] https://ec.europa.eu/eurostat/statistics-explained/index.php... [4] https://notesfrompoland.com/2022/11/10/poland-has-eus-second... [5] https://notesfrompoland.com/2023/06/20/poland-has-eus-third-... [6] https://www.statista.com/statistics/1130472/poland-poverty-r... reply mkaszkowiak 15 hours agorootparentThanks for the links! I'll read them :) reply Thorrez 20 hours agoparentprevWhat benefit does that provide? Some commenters are saying it reduces taxes. Why would it reduce taxes? Why would the government reduce taxes for people who jump through these hoops? reply mkaszkowiak 20 hours agorootparentTaxes. Standard tax rate (on UoP) is 12% up to ~30k USD, the rest is taxed 32%. On top of that, the employer pays a social security fee, its rate rises proportionally to income. As an one-person business, you have two most popular options: - 12% flat tax rate on income, with a flat rate social security fee; (1) - 19% flat tax rate on revenue. The social security fee is dependant on income, but it's less than on UoP. You can write off expenses in this scenario, so the actual tax rate is actually lower. People generally try to write off as much as they can - for example, the tax agency is OK with programmers buying multiple bikes as a means of \"transport to clients\" ;) You can also write off VAT in both scenarios, effectively making a lot of major purchases (desks, chairs, phones, etc) way cheaper. There's also a 5% tax rate, called IP Box, but it's tricky and doesn't apply for every scenario, so I'm taking this aside. With the employer spending 5k EUR per month (21,7k PLN), you're left with: - 14,6k PLN on UoP - 18,5k PLN on 12% tax - 16,7k PLN on 19% tax, out of which you can potentially recover 3,9k PLN It's easy to see why software developers choose to start a one-person business. It's worth to jump through the hoops to save on taxes. (1) There are actually 3 levels dependant on income, but it's lower than the UoP fee for basically most software developers reply Thorrez 19 hours agorootparentWhy would the government design it like this? Do they want to encourage this type of thing? What benefit does encouraging this provide to society? The US doesn't do this. They try to make self employed vs employed by a company have the same tax rates. reply mkaszkowiak 19 hours agorootparentGood questions, no clue. The answer probably lies somewhere between a \"badly designed tax system\" and \"stimulating growth of the IT sector\". reply jokethrowaway 19 hours agorootparentprevBecause they need to keep some gaps in the tax law to allow their friends to pay less taxes than normal people. The US famously had a huge amount of tax law exemption just because of corruption. Nowadays you need an international setup to achieve the same, because the same old tricks have been used by many and there was enough political pressure to change it. Some countries simply just didn't go through enough scandals of finding out how all well networked people pay almost zero taxes and therefore still have some relatively simple setups to pay little taxes. A separate matter is countries trying to desperately attracting businesses and creating tax benefits only for wealthy expats, but not for their own people. reply jmduke 18 hours agoprevSelf-employed, running https://buttondown.email as a solo founder. (My day generally looks like — 30% engineering, 40% onboarding + support, 10% marketing, 20% operations.) It was a profitable nights-and-weekends project from 2017—2022; took it full-time in 2022. I think the thing that I would say about self-employment is that people understate the day-to-day flexibility and overstate the month-to-month flexibility. It is _addicting_ to be able to structure a given day exactly how you want it, and to take days off without having to worry about PTO; conversely, I've done a hither-to poor job of increasing my bus factor and it's tough to e.g. plan entire week-long vacations without knowing I'll need to carve out extra time afterwards to catch up on inbound issues. Being self-employed is hard work for sure. I also _totally_ understand the cliche of \"becoming a founder makes you un-hireable\"; it's really hard to imagine going back to a traditional job after this, and I find it more fulfilling than anything else I've done in my career. reply snide 18 hours agoparentI have no need for an email sender at the moment, but I just wanted to say that I found your website and premise super simple to understand. I think the thing that often gets lost in large companies is that \"tone\" gets neutered. This copy reads like a person wrote it, rather than a large committee. Cheers. Bookmarked for when I do need it! reply XCSme 12 hours agoparentprev> people understate the day-to-day flexibility and overstate the month-to-month flexibility I completely agree! Somehow every day feels like you are free to do what you want, even take it off, but in the long-term it feels like you never really have free time at all, because your mind is always thinking about the business or feeling guilty for the time off, which could be spent to further improve the product. reply twojobsoneboss 10 hours agorootparentMany 9-5ers minds are always thinking of how to escape anyways, so at least you have something tangible to think about if you already have that business reply XCSme 9 hours agorootparentDon't get me wrong, I enjoy thinking about how to improve my product, new marketing ideas etc., the issue is more how it affects the rest of your life, where your attention on other aspects of life might be diluted, as a result maybe you will spend less time thinking, for example, about what nice thing you could do for your partner. reply hkhanna 22 hours agoprevMe! I started my solo, startup law practice almost by accident via a Hacker News comment years ago. It's now my primary source of income. It's hard, but less hard than what startup founders do. It's nice having control of my schedule, but the flip side is that there's never a day off. Personally, I think being self-employed is great for people who naturally work really hard and want to capture the full output of their labor. I don't think I could ever go back to full time employment for someone else. It's addicting having your own business that actually cash flows! reply jacquesm 21 hours agoparentNice one, congratulations! reply k__ 22 hours agoprevI'm self employed for around 10 years now. Before that I was employed as frontend developer for around 7 years. I started self employment as software consultant, which worked pretty well despite not having any connections from my previous employment. I only needed one or two projects a year to sustain my lifestyle. Getting two companies a year to accept your application isn't hard. If you write at least 5 applications a month, you need a success rate of less than 5%. I changed to technical writing later, because text is less of a struggle than code, and educational articles that explain how to use software (e.g., services, tools, SDKs, frameworks, etc.) are paid pretty well, especially compared to the non-technical writing tasks. Regular software consulting projects take months and can haunt you for years. An article takes a few days and after that you can do other things you find interesting. Via technical writing, I got into other kinds of text related jobs the software industry offers, like social media management (e.g., Twitter/X, newsletters, blogs) for companies with developer audiences. Usually I work less than 20h a week and I can do it from everywhere, which allows me to travel often and having enough time off to enjoy it. reply unD 22 hours agoparentHow do you get clients for tech writing, if I may ask? Are you maintaining a stable pool of companies and doing work as they need it, or do you always have to fish for new opportunities? I've been authoring sw dev books that target a niche audience, and I've done some writing for the company that develops the sw itself. I'm wondering whether to expand to other areas, too—I've got the feeling that 2024 is going to be a rather challenging year, financially speaking. reply k__ 21 hours agorootparentAs all articles I wrote under my own name (some are ghost writing) are implicit advertisement, most clients approached me after they read some of my pieces. Over the years I got a hand full of stable clients. Some want content every month, some every quarter, etc. Then there is word of mouth. The people I work with at my client companies are usually in the content business, so they need constant influx of quality content and know many other people who need it too. I also work with a tech content agency, they always have a few articles a month I can work on, if business is slow. reply geye1234 15 hours agorootparentI had a couple of questions if you don't mind: - I have a Business Analyst/Product Mgr background. I've never been a developer, but I can read code well enough and get a good idea of what's going on. Do I have a chance of breaking into this? How would I go about doing so (other than the obvious like trying to do it as part of my day job)? - Do you worry LLMs are going to put you out of business? - Very broadly speaking, could I make $150k doing this? reply k__ 14 hours agorootparent\"Do I have a chance of breaking into this?\" In my experience, the success stands and falls with how well you can grasp technical topics and explain them to people who have less time than you to learn them. I know a bunch of good writers, who never got far, because their technical understanding wasn't enough to write guides/tutorials/explainers. \"Do you worry LLMs are going to put you out of business?\" Not yet. I use LLM every quarter to write an article, and they've always been bad. \"Very broadly speaking, could I make $150k doing this\" Probably. An article makes you between $500 and $1000, depending on the length and quality. If you could write 200 a year, that could work. reply vineyardlabs 8 hours agoparentprevCurious about this. How did you manage to build up a consulting business without prior contacts? You say you wrote applications, but normally companies aren't soliciting consultants in a public fashion (other than fiver/upwork which seem to be a race to the bottom). reply k__ 1 hour agorootparentSure, the public platforms don't have the best paying projects. But that's how I found my first clients. After 2-3 clients from such platforms, word of mouth did the rest. I only went for projects that went 3-6 months, so I didn't need that many per year. reply SeanAnderson 18 hours agoprevI'm self-unemployed :D Helped a startup to exit a couple of years ago and had a small amount of equity. Been working on building a game since then. I don't think I'm going to make it to the finish line before I need to get another job, but maybe after that job I'll have the game finished and can build a more sustainable path from there. Definitely envious of those with actually sustainable business models, though, heh. (p.s. https://github.com/MeoMix/symbiants, come say hi in the Discord if you want to talk shop about Rust/Bevy/WASM/gamification of mental health) reply fakedang 17 hours agoparentI went through your profile and I just want to say, that idea of gamifying mental health with virtual pets (ants!) sounds super interesting! All the best! reply SeanAnderson 17 hours agorootparentThank you! :D I appreciate the kind words. reply racl101 17 hours agoprevWas self employed and worked as contractor programmer for the longest time until a couple of years ago. Thought I would work less. Boy was I wrong. Chasing clients, doing taxes, invoicing people and praying they'll pay on time. Got sick of the not very dependable cash flow which was feast and famine cycles. Went to get a corporate job and even though the work is not as exciting and the codebase is legacy, at least I don't sweat the next paycheck. reply JamesBarney 17 hours agoparentYeah did the same, and I'm also enjoying the corporate life. Learned a ton of lessons, the first of which is starting a consulting shop for general development is fools errand. You can kind of make if worth it if you're decent at sales and offshore everything. If I do it again I'll slice our niche down thinner than prosciutto, something like CRM integrations for real estate agents, and have contracts that allowed us to own the IP. reply zoomablemind 16 hours agorootparent> ...and have contracts that allowed us to own the IP. Is it a dreamland or such clause is really possible in the present day cookie-cutter contracts? reply JamesBarney 26 minutes agorootparentIt depends. Large enterprise clients would never let you own the IP. But those gigs are usually pretty profitable because they're large and they can afford high rates. Small clients mostly don't care unless they are planning on selling the software. And mid sized clients it seems to depend on whether or not they see it as a cost savings measure or competitive advantage. If it's the latter you can usually justify higher rates. reply PaulDavisThe1st 18 hours agoprevSelf-employed. Project started in 2000. Income fully funded by revenue since 2009. Product is a cross-platform native digital audio workstation (ardour.org). Revenue also funds a significant part of the income of a second developer (total of $220-240k/year in recent years). reply ohthatsnotright 14 hours agoparentThank you for Ardour! reply bemmu 19 hours agoprevI just build projects that interest me (websites, apps, games). So far released 62 things, of which 10 made >$10k. It's interesting because you get to do a variety of things, and I don't really mind the unpredictability. Might even like it in a slot machine variable reward sort of way. Just now I spent 3 months making a game that turned out to be worth $0, but that's part of the process. As long as the project itself is interesting and you learn something from it, it doesn't feel like totally wasted time. reply netule 19 hours agoparentThat’s really cool. Does it all generate enough revenue for you to support yourself financially? reply bemmu 19 hours agorootparentYes, as long as I remember not to overspend when things are going well, to cover for future failures. reply davidpolberger 21 hours agoprevI have been self-employed since 2008, when I quit my job in software engineering to go all-in on my software business (that dated from 2003). That failed spectacularly, because I only focused on technology and not on the value I was creating, and with few customers, I had to do on-site contracting for more than a year before going on full-time parental leave. I then rebooted my software project, launched a landing site and started talking to prospects (hundreds of them), before I set out to pivot my existing product to something that might gain traction. (I wound up throwing away 95 percent of the code.) I spent 2014 through 2019 with the product in beta, barely making a living off of a few enterprise support contracts and doing freelance photography (and depleting my savings), but spending at least 80 percent of my time on building the product and getting it to a finished state. (Some people seem to be able to build a product in a weekend that gets eager customers. I'm not one of those people, choosing to build something that was, in retrospect, much too big of a project for one person. I probably also spent too much time polishing the product before commercializing it, likely due to a fear of failure.) In 2019, the product was finally commercialized as a SaaS service. I remember thinking that I either wanted it to be a spectacular success, or a spectacular failure (so that I could focus on other things, after close to 20 years). It was neither, but has been growing steadily ever since. I would have made much more money working for someone else, but the freedom is unparalleled. I get to set my own hours and focus on things I consider important. I enjoy doing everything from support calls and UX work to building a compiler and a type system (that I have mentioned before on HN). I also have no one I need to answer to, other than our customers. That has been important over the past couple of years, when a series of health emergencies in my family has diverted my attention elsewhere. I have been very fortunate to be able to do so, focusing on what's important, without having to ask permission to cut down on work temporarily. Overall, I wouldn't trade this for anything. This year, my product will gain a sister product in a more lucrative field (I'm hoping), and I have plans to commercialize my compiler, both as a service and as a traditionally-licensed library. So I'm excited to stay solo and keep working on building the business. reply jacquesm 21 hours agoparentThat's some very impressive stamina and it must have been really hard at times. reply davidpolberger 21 hours agorootparentThanks, it certainly has been. After only a couple of years in the software industry proper, though, I felt I had seen all I needed to see. Crunch time. Arbitrary, ill-informed management decisions. Management who didn't believe in the product the team was passionate about. Products canceled through no fault of anyone working on it. Office politics and bickering. With my own business, I gain agency. If the product fails, it's because I failed to market it properly, or the product vision was bad and did not resonate with enough customers, or because I failed to execute on that vision. When all the decisions are out of your hands, and you can't even see what prompted them, they can feel capricious and arbitrary. With my own business, I am in control. I don't have one boss, I have hundreds of them. And as long as I continue to provide them with value, I get to continue doing what I'm doing. I like those terms. reply jacquesm 21 hours agorootparentYes, to all of that. But: the amount of control is directly proportional to how fat your wallet is, as it gets leaner you lose some of that agency so make sure you never even go close to depleting your reserves. That's a lesson I learned the hard way at some point and it causes me to be pretty cautious from a financial perspective. So far so good ;) reply ringofchaos 22 hours agoprevWould living on investment income be considered as self employed. I quit my management job of Tech department of my company. Saved enough money to generate 80 percent of my last drawn salary from my investments. Now focusing on creating my own fintech web app, with generative ai integration. I like the feeling of working independently and years of corporate job had taken taken toll on mental health. Currently building skills in fullstack web development and generative ai. Would take freelance job for some extra cash reply jacomoRodriguez 21 hours agoparentso asking the big and obvious question: in what did yo invest? reply ringofchaos 20 hours agorootparentI am based out of India 70% of my portfolio is in equity mutual funds, and the rest in s",
    "originSummary": [
      "The speaker is curious about the number of self-employed individuals and their occupations, particularly those who have started their own ventures without outside financial support.",
      "They are interested in understanding how these individuals are able to sustain themselves without external funding.",
      "The speaker is seeking insights into the entrepreneurial landscape and the strategies employed by self-employed individuals to maintain their businesses."
    ],
    "commentSummary": [
      "The conversation covers different aspects of self-employment, such as the profitability of various occupations, tax implications, challenges, and rewards.",
      "There is a specific focus on the software industry in Poland and the advantages and risks of freelancing in this field.",
      "The conversation highlights the benefits of owning a business, including the potential for financial success and personal fulfillment."
    ],
    "points": 328,
    "commentCount": 395,
    "retryCount": 0,
    "time": 1707129521
  },
  {
    "id": 39264383,
    "title": "Washington House bill tackles false confessions by banning police from lying in interrogations",
    "originLink": "https://www.seattletimes.com/seattle-news/politics/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations/",
    "originBody": "window.SEATIMESCO = window.SEATIMESCO || {}; window.SEATIMESCO.noThirdPartyScripts = false;WA House bill would make it illegal for police to lie during interrogationsThe Seattle Times { \"@context\": \"https://schema.org\", \"@type\": \"BreadcrumbList\", \"itemListElement\": [{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Local News\",\"item\":\"https://www.seattletimes.com/seattle-news/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Local Politics\",\"item\":\"https://www.seattletimes.com/seattle-news/politics/\"},{\"@type\":\"ListItem\",\"position\":3,\"name\":\"WA House bill would make it illegal for police to lie during interrogations\"}] } // Chartbeat // Sets a start time to compare to an end time in the chartbeat.js // http://support.chartbeat.com/docs/#code var _sf_startpt=(new Date()).getTime() // ChartBeat async flicker // http://support.chartbeat.com/docs/headlinetesting.html#asynchronousflicker var _sf_async_config = _sf_async_config || {}; window.SEATIMESCO = window.SEATIMESCO || {}; // turn on seatimesco domain to segment by actual domain instead of grouping under df if ( window.SEATIMESCO.contentInfo ) { if ( window.SEATIMESCO.contentInfo.domain =='seattletimes.com' || window.SEATIMESCO.contentInfo.domain =='www.seattletimes.com' ) { _sf_async_config.domain = 'seattletimes.com' } else { _sf_async_config.domain = window.SEATIMESCO.contentInfo.domain !== undefined ? window.SEATIMESCO.contentInfo.domain : null; } } else { _sf_async_config.domain = null; } /** CONFIGURATION START **/ _sf_async_config.uid = 22565; _sf_async_config.useCanonical = true; window._cbm = window._cbm || []; _cbm.push(['readyForTesting', false]); setTimeout(() => { _cbm.push(['readyForTesting', true]); }, ); /** CONFIGURATION END **/// Header scripts that can't otherwise be placed lower in the page. Keep as minimal as possible. // Sets 'js' on html element and removes 'no-js' if present (here to prevent flashing) (function(){ document.documentElement.className = document.documentElement.className.replace(/(^|\\s)no-js(\\s|$)/, '$1$2') + (' js '); })(); window.SEATIMESCO = window.SEATIMESCO || {}; window.SEATIMESCO.abTimeout = 3000; window.SEATIMESCO.ads = window.SEATIMESCO.ads || {}; window.SEATIMESCO.ads.disabled = false; window.SEATIMESCO.ads.adFreeMatherSegment = 'MATHER_U3_ADFREEGROUPB_20210610'; window.SEATIMESCO.ads.adFreeShowBrandedContent = 'false'; window.SEATIMESCO.ads.dfpEnv = 'prod'; window.SEATIMESCO.ads.adUnitPath = '/81279359/seattletimes.com/seattle-news/politics'; window.SEATIMESCO.ads.isTakeover = false; window.SEATIMESCO.ads.htlUrl = 'https://htlbid.com/v3/seattletimes.com/htlbid.js'; window.htlbid = window.htlbid || {}; htlbid.cmd = htlbid.cmd || []; htlbid.cmd.push(function() { htlbid.layout('universal'); // Leave as 'universal' or add custom layout htlbid.setTargeting('environment','prod'); htlbid.setTargeting('is_testing','no'); // Set to \"no\" for production htlbid.setTargeting('type','story'); htlbid.setTargeting('id','16912901'); htlbid.setTargeting('category','/81279359/seattletimes.com/seattle-news/politics'); htlbid.setTargeting('categories',''); htlbid.setTargeting('tag',''); htlbid.setTargeting('author','Jacquelyn Jimenez Romero'); htlbid.setTargeting('app','web'); htlbid.setFirstPartyData({ site: { page_type: 'story', keywords: 'law-justice, seattle-news, politics, northwest' } }); });window.SEATIMESCO.comments = window.SEATIMESCO.comments || {}; window.SEATIMESCO.comments.enabled = 1; window.SEATIMESCO.comments.postID = '16912901'; window.SEATIMESCO.comments.postTitle = 'WA House bill would make it illegal for police to lie during interrogations'; window.SEATIMESCO.comments.ssoEnvironment = 'secure.'; window.SEATIMESCO.comments.coralURL = 'https://seattletimes.coral.coralproject.net'; window.SEATIMESCO.comments.assetURL = 'https://www.seattletimes.com/seattle-news/politics/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations/'; window.SEATIMESCO = window.SEATIMESCO || {}; window.SEATIMESCO.browser = window.SEATIMESCO.browser || {}; window.SEATIMESCO.browser.support = {}; window.SEATIMESCO.browser.detected = {}; window.SEATIMESCO.browser.support.edge = 0; window.SEATIMESCO.browser.support.safari = 0; window.SEATIMESCO.browser.support.firefox = 0; window.SEATIMESCO.browser.support.chrome = 0; window.SEATIMESCO.browser.support.ie = 12; window.SEATIMESCO.singleSignOn = window.SEATIMESCO.singleSignOn || {}; window.SEATIMESCO.singleSignOn.info = window.SEATIMESCO.singleSignOn.info || {}; window.SEATIMESCO.singleSignOn.info.ssoEnvironment = \"secure.\"; window.SEATIMESCO.singleSignOn.info.subscriberSessionURL = \"https://secure.seattletimes.com/accountcenter/getsubscribersession.js?method=ajax&session=\"; window.SEATIMESCO.singleSignOn.info.commenterSessionURL = \"https://secure.seattletimes.com/accountcenter/coraltoken.js?token=\"; window.SEATIMESCO.singleSignOn.info.analyticsURL = \"https://secure.seattletimes.com/accountcenter/soa.js?method=ajax&session=\";dataLayer = [{\"timestamp\":1707210443,\"contentType\":\"story\",\"canonicalURL\":\"https:\\/\\/www.seattletimes.com\\/seattle-news\\/politics\\/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations\\/\",\"domain\":\"www.seattletimes.com\",\"post_id\":16912901,\"author\":\"Jacquelyn Jimenez Romero\",\"publishdate\":\"2024-02-05 06:00:00\",\"modifieddate\":\"2024-02-05 06:51:01\",\"title\":\"WA House bill would make it illegal for police to lie during interrogations\",\"credit\":\"Seattle Times staff reporter\",\"tags\":\"\",\"categories\":\"\",\"wordcount\":1488,\"hasBlocks\":true,\"paragraphCount\":43,\"galleryType\":\"fullwidth\",\"age\":0,\"source\":\"wordpress\",\"meter\":\"on\",\"ads\":\"on\",\"allowComments\":\"on\",\"section_tier1\":\"seattle-news\",\"section_tier2\":\"politics\",\"primary_section_display_name\":\"Local News\",\"sections_all\":\"law-justice|seattle-news|politics|northwest\",\"othersections\":\"law-justice, northwest\",\"wordgroup\":1400,\"page_layout_meta\":\"{\\\"bg_color\\\":0}\",\"media_meta\":\"{\\\"videos_total\\\":0,\\\"jwplayer_videos\\\":0}\",\"internalTags\":\"Omit from Latest\",\"articleTemplate\":\"2019-redesign\",\"articleBackgroundColor\":\"\"}]; window.SEATIMESCO = window.SEATIMESCO || {}; window.SEATIMESCO.contentInfo = {\"timestamp\":1707210443,\"contentType\":\"story\",\"canonicalURL\":\"https:\\/\\/www.seattletimes.com\\/seattle-news\\/politics\\/wa-house-would-make-it-illegal-for-police-to-lie-during-interrogations\\/\",\"domain\":\"www.seattletimes.com\",\"post_id\":16912901,\"author\":\"Jacquelyn Jimenez Romero\",\"publishdate\":\"2024-02-05 06:00:00\",\"modifieddate\":\"2024-02-05 06:51:01\",\"title\":\"WA House bill would make it illegal for police to lie during interrogations\",\"credit\":\"Seattle Times staff reporter\",\"tags\":\"\",\"categories\":\"\",\"wordcount\":1488,\"hasBlocks\":true,\"paragraphCount\":43,\"galleryType\":\"fullwidth\",\"age\":0,\"source\":\"wordpress\",\"meter\":\"on\",\"ads\":\"on\",\"allowComments\":\"on\",\"section_tier1\":\"seattle-news\",\"section_tier2\":\"politics\",\"primary_section_display_name\":\"Local News\",\"sections_all\":\"law-justice|seattle-news|politics|northwest\",\"othersections\":\"law-justice, northwest\",\"wordgroup\":1400,\"page_layout_meta\":\"{\\\"bg_color\\\":0}\",\"media_meta\":\"{\\\"videos_total\\\":0,\\\"jwplayer_videos\\\":0}\",\"internalTags\":\"Omit from Latest\",\"articleTemplate\":\"2019-redesign\",\"articleBackgroundColor\":\"\"}; window.SEATIMESCO = window.SEATIMESCO || {}; window.SEATIMESCO.experiments = window.SEATIMESCO.experiments || {}; window.SEATIMESCO.experiments.property = \"UA-52488759-1\"; window.SEATIMESCO.experiments.defaultHide = \".river-group.extra-items.elsewhere.five-col.u-dib.full-width-content\"; window.SEATIMESCO.experiments.timeout = 4000; window.SEATIMESCO.experiments.adsWait = false; window.SEATIMESCO.experiments.messagingWait = false; window.SEATIMESCO.experiments.curationWait = false; (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-KDZ92J');window._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/14.0.0\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/14.0.0\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/www.seattletimes.com\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=6.1.1\"}}; /*! This file is auto-generated */ !function(e,a,t){var n,r,o,i=a.createElement(\"canvas\"),p=i.getContext&&i.getContext(\"2d\");function s(e,t){var a=String.fromCharCode,e=(p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0),i.toDataURL());return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement(\"script\");t.src=e,t.defer=t.type=\"text/javascript\",a.getElementsByTagName(\"head\")[0].appendChild(t)}for(o=Array(\"flag\",\"emoji\"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r img.wp-smiley, img.emoji {display: inline !important;border: none !important;box-shadow: none !important;height: 1em !important;width: 1em !important;margin: 0 0.07em !important;vertical-align: -0.1em !important;background: none !important;padding: 0 !important; }body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;} .wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;} :where(.wp-block-columns.is-layout-flex){gap: 2em;} .wp-block-pullquote{font-size: 1.5em;line-height: 1.6;} window.SEATIMESCO.article = window.SEATIMESCO.article || {}; window.SEATIMESCO.article.template = \"2019-redesign\"; window.SEATIMESCO.article.disableExploreLabel = ''; window.SEATIMESCO.article.disableSTNPlayer = ''; .cls-1, .cls-2 { fill: #fff; } .cls-2 { fill-rule: evenodd; } function OptanonWrapper() { } (function() { var OTTag = document.createElement('script'); // Add standard script attributes OTTag.setAttribute('src', 'https://cdn.cookielaw.org/opt-out/otCCPAiab.js'); OTTag.setAttribute('type', 'text/javascript'); OTTag.setAttribute('charset', 'UTF-8'); // Add custom attributes OTTag.setAttribute('ccpa-opt-out-ids', 'SM,T,P'); OTTag.setAttribute('ccpa-opt-out-geo', 'ca'); OTTag.setAttribute('ccpa-opt-out-lspa', 'false'); document.body.appendChild(OTTag); })();Skip to content Coronavirus Local NewsTraffic LabLaw & JusticeLocal PoliticsEducationEducation LabEastsideEnvironmentHealthDataMental HealthProject HomelessTimes Watchdog Business &#038; TechBoeing & AerospaceAmazonMicrosoftTechnologyReal EstateEconomyArtificial Intelligence Nation & WorldNation & World PoliticsOddities SportsSeahawksMarinersKrakenStormSoundersReignHuskiesCougarsHigh School SportsOn TV/Radio EntertainmentMoviesBooksMusicTheaterClassical MusicTV/StreamingComicsGames & PuzzlesHoroscopes LifeFood & DrinkTravel &#038; OutdoorsWellnessPetsRant & Rave Pacific NW Magazine Homes &#038; Real Estate OpinionEditorialsLetters to the EditorDavid HorseyFree Press Video Photography ObituariesNews ObituariesPaid Obituaries Newsletters Print Replica Today&#8217;s Paper Inside The Times The Ticket Explore Jobs Best in the PNW Newsletters Log In SubscribeLocal Politics Local Biz Nation Sports Entertainment Life Homes OpinionThe Ticket Jobs Explore All SectionsLocal CoronavirusTraffic LabProject HomelessLaw & JusticeLocal PoliticsEducationEducation LabEastsideEnvironmentNorthwestDataHealthTimes WatchdogMental HealthInside The TimesNews ObituariesPhoto & VideoNation & WorldPoliticsOddities Business BoeingAmazonArtificial IntelligenceMicrosoftTechnologyEconomyReal Estate Sports SeahawksMarinersKrakenStormSoundersReignHuskiesCougarsHigh SchoolsSnow SportsGeoff BakerMatt CalkinsLarry StoneBob CondottaOn TV/Radio Entertainment MoviesBooksMusicTheaterClassical MusicTV/StreamingComicsGames & PuzzlesHoroscopes Life Pacific NW MagazineFood & DrinkHappy HourWellnessHome & DecorPetsRant & RaveBethany Jean Clement Travel OutdoorsNorthwest HikesWashingtonOregonB.C.Hawaii Opinion EditorialsLettersOp-EdsDavid HorseyKate RileyMark HigginsBrier DudleyAlex FryerCarlton WinfreyClaudia RoweFree Press Columnists FYI GuySeattle SketcherDanny WestneatNaomi IshisakaJon Talton Best in the PNW The Ticket Jobs Autos Homes Listings Classifieds Paid Obituaries Explore Sponsored Posts Seattle Times Store Contact FAQs Subscriber Services Print Replica Today&#8217;s Paper iOS App Android App Jim Brunner WA Legislature Seattle Election 2024 Danny WestneatLocal PoliticsJim Brunner WA Legislature Seattle Election 2024 Danny WestneatLocal Politics Newsletters Log In SubscribeLaw & JusticeLocal NewsLocal PoliticsNorthwest WA House bill would make it illegal for police to lie during interrogationsFeb. 5, 2024 at 6:00 amUpdated Feb. 5, 2024 at 6:00 am By Jacquelyn Jimenez RomeroSeattle Times staff reporterOLYMPIA — Victims of false confessions that lead to wrongful convictions, like Ted Bradford, want to prohibit police from using deceptive tactics during interrogations, and they have the backing of some lawmakers.&#8220;It was the worst experience of my life,&#8221; said Bradford, Washington’s first DNA exoneree, when recalling his 1996 interrogation when he was accused of sexual assault. &#8220;I knew I was innocent … no matter how many times I told them over and over, I didn&#8217;t do this.&#8221;House Bill 1062, sponsored by Rep. Strom Peterson, D-Edmonds, aims to make defendants&#8217; statements inadmissible in court if police use deceptive tactics during interrogations to get those statements. Nine states have passed similar laws, but they only apply to juveniles. The bill has received two hearings in the House this legislative session.Advocates say this legislation, aside from keeping innocent people out of prison, is also about building trust between the public and law enforcement. Some in law enforcement argue that deception is not coercion and taking away this tactic decreases their effectiveness in convicting people and solving cases. &#8220;I think there&#8217;s this space in the middle that often gets looked over, post-arrest, pre-conviction,&#8221; Peterson said. &#8220;There are a lot of things that happen there that I don&#8217;t think we&#8217;ve paid enough attention to.&#8221;The majority of interrogations happen in the back of a patrol car or on the side of the road, according to Derick Sanders, Thurston County sheriff. He argues police tactics are always under the microscope. Advertising James McMahan, policy director of the Washington Association of Sheriffs and Police Chiefs, argued in public testimony on Jan 8 that deception is required to get to the truth. An example, he said, would be not telling a suspect in cases involving the exploitation of children the true age and identity of an undercover trooper who was posing as a minor. &#8220;Sometimes, it&#8217;s an unfortunate reality, we have to lie to people to get them to tell the truth,&#8221; McMahan said. &#8220;If we could somehow get people to actually be required to tell the truth, we wouldn&#8217;t have to lie. That&#8217;s just an unfortunate reality of law enforcement.&#8221;However, current police interrogations encourage bias and leave people vulnerable to the power imbalances between law enforcement and citizens, said Dave Thompson, president of Wicklander-Zulawski & Associates, a firm that provides interrogation training to law enforcement.How a false confession is generated In 1996, Bradford, 22 at the time, was asked to come to the Yakima Police Department to help with a case. He said he was asked to waive his rights and when he asked police whether he needed an attorney they said no because they were only asking a few questions. He signed the waiver thinking he was going to help, but a few questions turned into a nearly nine-hour interrogation, with no food and a small cup of water, he said.Identifying the wrong person begins with faulty evidence, and often police make people fit the evidence rather than the other way around, says James Trainum, a former detective with the Washington, D.C., Police Department who now does law enforcement consulting. “Rather than develop your case, develop your suspect, develop your evidence, you&#8217;re taught that you can use this to bypass all of that, and just quickly identify a suspect, and then move on,” Trainum said. Advertising In Washington state, 23% of exonerations involve false confessions, according to data from the Washington Innocence Project. However, this number could be higher because there&#8217;s not enough data to know the actual number of wrongful convictions in the state according to Lara Zarowsky, executive director of the Washington Innocence Project.In the 1969 case Frazier v. Cupp, the U.S. Supreme Court ruled in favor of police using deception tactics during interrogations. The Reid technique, the most common technique used by police, includes using guilt-presumptive questions during interrogations. By lying to people about false evidence, Trainum says police hope to persuade a confession.&#8220;Just because the courts find it permissible doesn&#8217;t mean that they&#8217;re not problematic,” said Trainum, who said he garnered a false confession in a 1994 high-profile kidnapping and murder case using the Reid technique.Bradford&#8217;s battle to prove his innocence to police left him feeling threatened and intimidated after aggressive questioning and accusations. At the end of the day, he couldn&#8217;t handle it anymore and signed a confession.2024 WA LegislatureLocal PoliticsRelated More How to watchYou can search for a bill by number at app.leg.wa.gov/billinfoFind your state representatives and state senator at app.leg.wa.gov/districtfinder/Watch legislative meetings at tvw.orgFor more links about how to read a bill, how a bill becomes a law and visiting the Legislature, visit leg.wa.gov/legislature/Pages/ComingToTheLegislature.aspxMoreInterrogations can differ depending on the situation, according to Sanders, the Thurston County sheriff.&#8220;The type of crime, the temperament of the officer, the temperament of the suspect, those are all things that play a pretty big factor into how people are interrogated,&#8221; he said. Advertising Sanders says not every case requires a ruse, but when they do, they&#8217;re used when police need people to think they know more than they do to close an investigation.According to Sanders, there are already procedures in place that can dispute false confessions in what are called criminal rule 3.5 hearings, where defendants can have evidence dismissed if they assert police lied inappropriately or violated case law. He believes fewer wrongful convictions will exist as technology improves. However, because of Frazier v. Cupp, decisions from criminal rule 3.5 hearings make their way to court anyway, said John Marlow, litigation director of the Washington Innocence Project. The court decides whether the confession is allowed as evidence and the jury ultimately decides whether it&#8217;s believable, Marlow said. Most Read Local Stories Seattle&#8217;s water comes from 2 river systems. Which one do you drink from?Seattle Archdiocese announces final plan to consolidate Catholic parishesVIEW A council of allies in place, Seattle Mayor Bruce Harrell feels pressure to deliverWA drinking water, hydropower at risk as PNW snowpack shrinksWATCH State Patrol seeks to charge 6 in Gaza war protest that shut I-5 in Seattle &#8220;The criminal legal system in practice does not operate in the way that we think it does when you just read the rules on paper,&#8221; Zarowsky said. Why confess to a crime you didn&#8217;t commit?In 2007, Amanda Knox was a 20-year-old college student at the University of Washington. She garnered worldwide attention after being wrongfully convicted of murdering her roommate Meredith Kercher in Italy during a study abroad trip. During her interrogation, Knox, who testified in support of HB 1062, recalls police making her feel like she was going insane.&#8220;The extent to which I was unprepared for people who I trusted to lie to me was what led me as an innocent person to be particularly vulnerable and which is what led to my eventual wrongful conviction,&#8221; Knox said in an interview. Sponsored The more successful a strategy is in eliciting confessions from guilty suspects, the more likely it is that this strategy will also produce false confessions from innocent suspects, according to a 2004 research paper published by the Encyclopedia of Applied Psychology.Juveniles and people with intellectual disabilities are more susceptible to deception, the research showed. But under the right circumstances, this can happen to anyone, Zarowsky said.Bradford recalls police making threats and lying to him about DNA evidence they said proved he committed the crime. After hours of interrogation, he confessed, hoping the evidence would acquit him.&#8220;I started thinking to myself, the only way out of this is if I just give them a statement,&#8221; Bradford said. &#8220;Then they can test their evidence and they&#8217;ll find out that I&#8217;m innocent. I&#8217;ll be done. I&#8217;ll be free of all of this.&#8221;Experts call this a coerced-complaint confession.For Knox, during her 53-hour interrogation in Italy, she rarely had a translator and became tired and confused. Police accused her of having amnesia and she recalls an officer hitting her in the head and telling her to remember. By attempting to make sense of the situation, she ended up creating a false memory and signed what&#8217;s called a coerced-internalized confession. &#8220;I was put in a position where I was made to feel insane because the police lied to me,&#8221; Knox said. &#8220;They told me that I had amnesia and that I didn&#8217;t remember what the truth was.&#8221; Advertising What alternatives exist?Prosecutors sometimes are reluctant to believe someone&#8217;s innocence even after DNA acquits someone, Saul Kassin, a professor of psychology at The City University of New York, wrote in his 2005 research paper, &#8220;On the Psychology of Confessions: Does Innocence Put Innocents at Risk?&#8221;In Bradford&#8217;s case, he was charged again for the same crime, after serving his 10-year sentence, when he challenged his conviction with new DNA evidence. In Knox&#8217;s case, she went through the appeals process twice in Italy, but was ultimately not convicted. For jurors, a confession is one of the most compelling pieces of evidence regardless of how unreliable it is, according to Matt Jones, president of Evocavi, a firm that trains law enforcement in interrogation techniques.Advocates of HB 1062 say accountability measures like these raise law enforcement&#8217;s professionalism.&#8220;I have absolutely not gone to the police for help as a result of my experience, because I didn&#8217;t feel like I could trust them and I don&#8217;t want to live in a world like that,&#8221; Knox said.Peterson&#8217;s bill, which would also provide law enforcement with interrogation training, is currently in the House Appropriations Committee.&#8220;A bill like this would just focus more on not just getting a conviction, but getting the right conviction,&#8221; Bradford said. &#8220;For every person that&#8217;s wrongly convicted, the real perpetrators out there, possibly committing more crimes.&#8221; Jacquelyn Jimenez Romero:jromero@seattletimes.com; View CommentsPosting comments is now limited to subscribers only. View subscription offers here. For more information, visit our FAQ's.The opinions expressed in reader comments are those of the author only and do not reflect the opinions of The Seattle Times. Advertising var um = ' \\\\\\\\\\\\\\ Your browser is out of date \\ Stay secure and make sure you have the best reading experience possible by upgrading your browser! \\ Learn more \\\\\\\\\\\\\\\\ .GenericBar.overlay{position:relative;opacity:0;-webkit-transition:1s all ease-in-out;-o-transition:1s all ease-in-out;transition:1s all ease-in-out}.GenericBar.overlay.is-active{opacity:1}.GenericBar .modal{width:100%;height:auto;padding:10px;background-color:#000;position:fixed;bottom:-100%;-webkit-transition:2s all ease-in-out;-o-transition:2s all ease-in-out;transition:2s all ease-in-out}@media screen and (min-width: 600px){.GenericBar .modal{padding:20px}}.GenericBar.is-active .modal{bottom:0}.GenericBar .modal-wrapper{position:relative;max-width:1030px;margin:0 auto}.GenericBar .copy-wrapper{text-align:center;width:calc(100% - 70px);margin:0 auto}@media screen and (min-width: 600px){.GenericBar .copy-wrapper{text-align:left;width:calc(100% - 40px);margin:0}}.GenericBar .logo-wrapper{position:absolute;left:-10px;top:-10px;z-index:-1;height:calc(100% + 20px);width:100%}@media screen and (min-width: 600px){.GenericBar .logo-wrapper{left:-20px;top:-20px;height:calc(100% + 40px)}}.GenericBar h1,.GenericBar p,.GenericBar a{font-size:15px;line-height:1.4;margin:0}@media screen and (min-width: 600px){.GenericBar h1,.GenericBar p,.GenericBar a{font-size:20px;line-height:1.1}}.GenericBar h1{font-weight:normal}@media screen and (min-width: 600px){.GenericBar h1{margin-bottom:0;font-weight:bold}}.GenericBar h1,.GenericBar a{display:block}@media screen and (min-width: 600px){.GenericBar h1,.GenericBar a{display:inline-block}}.GenericBar p{display:none}@media screen and (min-width: 600px){.GenericBar p{display:block}}.GenericBar a{color:#b85a22}@media screen and (min-width: 600px){.GenericBar a{font-weight:bold}}.GenericBar a:hover,.GenericBar a.hover,.GenericBar a:focus,.GenericBar a.focus{color:#d06723}.GenericBar .x-button{display:block;position:absolute;top:50%;right:0;margin-top:-12px;color:#f8f8f8}.GenericBar button.x-button{min-height:initial;line-height:normal;background-color:transparent;padding:0;border:none;height:24px;width:24px}.GenericBar button.x-button:hover,.GenericBar button.x-button.hover,.GenericBar button.x-button:focus,.GenericBar button.x-button.focus{color:#e0e0e0;background-color:transparent}.GenericBar .close-icon{position:absolute;left:0;top:0;width:24px;height:24px;opacity:.8}.GenericBar .close-icon:hover,.GenericBar .close-icon.hover,.GenericBar .close-icon:focus,.GenericBar .close-icon.focus{opacity:1}.GenericBar .close-icon:before,.GenericBar .close-icon:after{content:\" \";position:absolute;left:12px;height:24px;width:2px;background-color:#f8f8f8}.GenericBar .close-icon:before{-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg)}.GenericBar .close-icon:after{-webkit-transform:rotate(-45deg);-ms-transform:rotate(-45deg);transform:rotate(-45deg)}.GenericBar .st-logo{height:120%;background-repeat:no-repeat;background-size:contain;background-image:url(\"data:image/svg+xml;charset=US-ASCII,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22400%22%20height%3D%22300%22%20viewBox%3D%220%200%20400%20300%22%3E%3Cg%20fill%3D%22%23fff%22%3E%3Cpath%20d%3D%22M148.445%2081.896c-14.142-19.86-42.73-47.343-69.81-47.343-18.254%200-26.78%2011.234-26.78%2020.462%200%2012.437%2010.532%2020.862%2037.613%2038.314%2053.66%2034.603%2095.387%2058.374%2095.387%20104.212%200%2047.845-51.354%2064.896-66.5%20100.804h-.903c-33.4-48.547-91.876-58.176-115.648-36.61L0%20260.432c3.008-21.865%2016.147-60.883%2047.943-60.883%2029.088%200%2067.502%2038.616%2091.174%2048.544%203.41%201.404%206.52.502%208.826-2.307%203.01-3.61%204.915-9.527%204.915-18.855%200-64.496-133.7-82.85-133.7-134.404%200-12.136%2011.133-34%2026.78-53.16C66.297%2014.293%2086.96%203.06%20109.427%203.06c34.805%200%2052.156%2026.078%2066.7%2026.078%206.12%200%2010.13-2.407%2013.94-7.522l3.71%203.11c-8.624%209.026-18.453%2019.458-27.08%2030.59l-1.304.904c-14.34%205.415-12.636%2019.357-16.95%2025.676%22%2F%3E%3Cpath%20d%3D%22M143.83%20227.734c0-57.27-135.305-75.228-135.305-135.308l-1.405.2c-9.73%2067.404%20123.27%2084.755%20135.207%20135.61l1.504-.502zM151.654%2084.504c-.5-7.824%201.706-15.948%207.724-22.268%206.82-7.22%2016.55-10.432%2032.798-10.432%2029.99%200%2082.95%2022.568%20129.39%2022.568%2040.52%200%2068.103-39.417%2078.436-60.28L395.59%201.653l-.702.1c-2.408%2017.353-17.453%2038.716-50.45%2038.716-31.497%200-93.382-24.07-125.778-24.07-46.74%200-69.108%2033.5-73.12%2061.482l5.416%207.422.698-.8zM303.61%2066.85h9.93v202.007h-9.93zM231.19%2068.757l5.116%203.11c-21.562%2015.846-38.515%2045.835-38.515%2083.047%200%2061.986%2036.01%20113.342%2094.084%20113.342%2033.5%200%2054.562-17.152%2064.994-34.004l.604.2%201.103%2014.745c-16.25%2014.746-51.253%2040.52-95.187%2040.52-68.205%200-109.528-46.738-109.528-108.322-.2-57.673%2039.82-93.382%2077.33-112.638%22%2F%3E%3Cpath%20d%3D%22M286.26%2066.35L260.58%2080.49c-15.948%208.727-19.258%2018.055-19.258%2035.707%200%2015.847%204.513%2042.728%204.513%2064.19%200%2021.967-4.513%2028.887-23.17%2036.812l3.108%205.817c12.338-5.618%2033.4-16.148%2047.242-24.978%2011.336-7.22%2013.24-11.232%2013.24-22.666v-69.51c0-22.567.5-29.488%204.814-35.606l-4.81-3.91z%22%2F%3E%3C%2Fg%3E%3C%2Fsvg%3E\");opacity:0.15}'; var ua = window.navigator.userAgent.toLowerCase(); var isIE = ua.indexOf('trident') != -1; if (isIE) { let div = document.createElement('div'); div.innerHTML = um; document.body.appendChild(div); }COMPANY AboutContactCareersPermissionsNewsroom Staff COMMUNITY Newspapers in EducationFund for Those in NeedInvestigative Journalism Fund Advertise Media SolutionsST Content StudioClassifiedsJobsAutosObituaries SUBSCRIPTION SubscribeMy AccountPrint Replica LoginToday&#8217;s PaperMobile AppsHelp/FAQ CONNECT Manage NewslettersFacebookTwitterRSSNewspaper Archive Access Copyright © 2024 The Seattle TimesPrivacy StatementNotice At CollectionDo Not Sell My InformationTerms of Servicewindow.SEATIMESCO.privacy = { ccpaLoaded: false };window.SEATIMESCO.privacy.ccpaLoaded = true;/**/// Chartbeat // http://support.chartbeat.com/docs/#code if ( _sf_async_config == undefined ) { // should be defined from the header-headcontent.php file, this is to cover any instances where it isn't let _sf_async_config = _sf_async_config || {}; } let userType = ''; let decodedCookie = decodeURIComponent(document.cookie); let cachedCookies = decodedCookie.split(';'); for ( let i=0; i let theHash = window.location.hash; if ( typeof theHash !== 'undefined' && theHash !== null ) { let hashPos = theHash.indexOf( \"#close_window\" ); if ( hashPos > -1 ) { window.close(); } } window.aax = window.aax || {}; window.aax.cmd = window.aax.cmd || []; window.aax.cmd.push(function () { if (window.aax.getAbpStatus()) { window.googletag = window.googletag || {}; window.googletag.cmd = window.googletag.cmd || []; window.googletag.cmd.push(function () { googletag.pubads().refresh(); }); } }); window.aax.cmd.push(function() { window.aax.addEventListener('slotRenderEnded', function (event) { var slotElementId = event.dfpDetails.slot.getSlotElementId(); var slotDiv = document.getElementById(slotElementId); slotDiv.style['width'] = '300px'; }); });",
    "commentLink": "https://news.ycombinator.com/item?id=39264383",
    "commentBody": "WA House bill would make it illegal for police to lie during interrogations (seattletimes.com)280 points by danso 15 hours agohidepastfavorite274 comments IncandescentGas 15 hours agoWe already have purjury law, which are so routinely broken by the police there's a common term for it. Testilying. Purjury is supposed to be serious. But it's not enforced against police officers. Other misconduct like prosecutors hiding exculpatory evidence is also rarely if ever punished even when blatently proven and widely publicided. So why should I believe, if this law passes, anybody in the justice system will enforce it? What happened to Ted Bradford is awful. The fact he actually eventually was exenorated was like winning the lottery. For most falsely convicted, a statistical impossibility. reply chacham15 14 hours agoparentIMO the point of stopping police from lying shouldnt be to prosecute the police (as perjury is already illegal), but rather, to indemnify the person who was lied to for actions they took under false pretenses. So, if the police lie to you and say \"we have you on camera at the 7/11\" and as a result you say \"I dont really recall..maybe I got a soda from there and dont remember?\" that second statement shouldnt be used against you if they dont actually have you on camera whereas today that statement would be used to show that you couldve been there (because you said so yourself). This is easy to demonstrate in court and consequently toss out that secondary statement which would otherwise be evidence. reply rootusrootus 14 hours agorootparentHere's a hot take -- maybe we could just make self-incriminating statements inadmissible altogether unless it's given as testimony, verbal or written and signed while not under duress. If the only evidence the police have is what you say, then that should be insufficient. reply VBprogrammer 13 hours agorootparentThe case has obviously fallen out of the limelight but Brendan Dassey should be the poster boy for why this is true. reply chrsig 13 hours agorootparentThe counter argument being donald trump, where every other sentence is some admission of guilt. reply psychlops 13 hours agorootparentprevYou mean the only evidence is what the police say you said. reply rootusrootus 13 hours agorootparentNo, I mean that \"suspect said X\" testimony wouldn't be admissible, so it would never be your word against the cop. reply lcnPylGDnU4H9OF 11 hours agorootparentThis made me do some research into \"hearsay\" because I'm not really familiar with how it all works. > Per Federal Rule of Evidence 801(d)(2)(a), a statement made by a defendant is admissible as evidence only if it is inculpatory; exculpatory statements made to an investigator are hearsay and therefore may not be admitted as evidence in court, unless the defendant testifies. https://en.wikipedia.org/wiki/Hearsay#United_States So it's not hearsay if it makes you look bad (but it is if it makes you look good), and police don't even have to be telling the truth, nor do they really have to be worried about perjury charges if a given encounter was not recorded. I still can't imagine why a confession given in interview isn't logically nullified by: \"How does the defense plead?\" \"Not guilty, Your Honor.\" reply psychlops 11 hours agorootparentprevYes, we agree. I was just clarifying that \"what you said\" can be quite different from \"what the police said you said\". If it were recorded then that's different.... reply morpheos137 13 hours agorootparentprevIn the USA you have the fifth amendment right against self incrimination. Also you have NO obligation to say anything to police in an interrogation and can always request an attorney to speak on your behalf. Subjects are reminded of this during the reading of Miranda Rights. If you are ever in a police interrogation you should always decline to speak without an attorney. It is bewildering why people don't exercise their rights. reply kjellsbells 10 hours agorootparentLet's try this thought experiment. You are shopping at a grocery store. It's a regular day in your life. Then, without warning, you are arrested by the cops and taken to the police station. They put you in the holding cell. They take your laptop, phone, etc. You ask for your one call. They lead you to the wall mounted phone and you stick your quarter in. What percentage of the HN readership here would be able to dial the number of a competent criminal attorney? Engagement with the criminal justice system is so out of the ordinary for most people that they simply do not know what to do. It's easy to say, \"shut up and call your lawyer\", but most regular joes have absolutely no idea how to find a lawyer, vet them, engage with them, etc. In normal life, if you need a lawyer, you Google some reviews, or you look up something in yellow pages, or you ask your local state bar association for a referral for the area of legal practice. None of those things are happening at 2am in a holding cell without any of your regular devices. And asking for the public defender is not likely to give you much comfort given their caseload. Now imagine that you are not the classic affluent educated HN reader with access to all kinds of resources, and consider what it must be like for working class people. It's not fun. reply rokkitmensch 5 hours agorootparentYou don't call a lawyer, you call the most competent person whose phone number you can remember and tell them to get a lawyer. Ideally, you have a relationship with one or more, but if you don't come from an upper middle class background with a refined appreciation for insurance policies, now is the time you call your most competent contact and beg them to get the ball rolling on a lawyer and bail. reply theturtle32 13 hours agorootparentprevIt's not bewildering. There are an awful lot of people out there who were raised to trust police as \"the good guys\" and it's extremely easy for those people to be manipulated into what they think will be a quick interview to help out in solving a case, only to have the spotlight turned on them before they realize what's happening. reply pixl97 12 hours agorootparentprevBecause in most places cops are liars beyond what you'd ever believe. Civil rights violations are simply status quo. I come from a family with members in law enforcement and the criminal justice system. They have had to kick detectives out of interrogation rooms because the detectives get abusive and simply ignore \"I'd like to speak to my attorney\". The cops just won't stop harassing, lying, and even abusing the suspect. Most people are not going to do well in a stressful situation with a person in a position of authority abusing them. And our criminal justice system here in the US is ok with that. reply kmoser 10 hours agorootparentprevPeople don't exercise their rights when a) they are not informed of them, and b) they're under duress. What's more bewildering is why juries (who are not facing jail time themselves) don't find defendants innocent in every case involving the police since it's known that the police are allowed to lie, and it's also known they will face little to no repercussions from doing so even under oath. reply 20after4 4 hours agorootparentThe people that get picked for a jury (that make it through all the rounds of vetting) are the types of people who believe the 'justice system' is fundamentally just and that the police are public servants. The people who see through that are filtered out or filter themselves out of the process. reply rolph 13 hours agorootparentprev--\"because if you cooperate with us, everything will go easy, if you keep resisting, thats proof of guilt and youll get the max, plus charges for resisting\" reply echelon 13 hours agorootparentprev> as a result you say \"I dont really recall..maybe I got a soda from there and dont remember?\" [...] > today that statement would be used to show that you couldve been there (because you said so yourself). They can use \"I don't remember\" ? Isn't the whole point of interrogation to get a suspect to make conflicting statements, then pressure them when the statements don't line up as a means to get a confession? Why is this a bad thing? If this tool goes away, couldn't conviction rates plummet (for eg. violent crimes)? I'm having trouble seeing an ethical problem here? reply throwaway19091p 13 hours agorootparent> They can use \"I don't remember\" ? They absolutely can, and will use that in a court of law. Any comment that you make that seems completely fine from your perspective can quickly be turned around to lock you up. I highly recommend checking out this lecture when you get a chance: https://youtube.com/watch?v=d-7o9xYp7eE Police are not generally concerned with getting the right person, they're just concerned with getting a person. reply JieJie 13 hours agorootparentprevBlackstone's Ratio: \"It is better that ten guilty persons escape than that one innocent suffer.\" https://en.wikipedia.org/wiki/Blackstone's_ratio reply pixl97 12 hours agorootparentWhich has about zero to do with actual reality. The reality in the US is if you want re-elected you better be tough on crime, which means people going to jail. No one seems to give a shit if the people that committed the crime are going to jail, as long as someone is found guilty. reply 20after4 4 hours agorootparentNo they care. They make sure that the people doing the crimes remain free to abuse the innocent. Hint: it's the police and politicians (and their buddies) committing a lot of the crimes. reply tsimionescu 13 hours agorootparentprev> Why is this a bad thing? If this tool goes away, couldn't conviction rates plummet (for eg. violent crimes)? Even if they do, the real question is whether false convictions will plummet more than true convictions. There are an awful lot of people who \"confessed\" to crimes didn't commit. reply scarface_74 12 hours agorootparentprev“You might as well admit you did $x, we have your fingerprints at the scene. We might go lighter in you”. This is when they don’t have fingerprints. reply AniseAbyss 13 hours agorootparentprevDo you want confessions or justice? reply gnicholas 13 hours agoparentprev> So why should I believe, if this law passes, anybody in the justice system will enforce it? Easy: because interrogations are videotaped and disclosed to defense attorneys. Currently, police can walk in and say “we found your prints at the scene, so you better start talking”. If an officer did this under the new regime, it would be illegal — and would be disclosed to the defense attorney. And under the “fruit of the poisonous tree” doctrine, anything elicited by that lie would be excluded from trial. Basically, the types of lies people make on the stand are hard to disprove. The types of lies that cops tell in interrogations are not hard to disprove. They are also on video, and handed over to defense attorneys. reply bombcar 13 hours agorootparentThis the way to stop it. Make it fruit of the poisonous tree and the prosectors will get the cops to shut up, because all their good evidence will be destroyed by it. It's amazing how much they have to work around things that would incriminate or sway a jury (such as cutting out anything that might reveal priors), and this would be something more. reply echelon 13 hours agorootparentWhy is this a good thing? Shouldn't cops be able to lie and put pressure on suspects? Isn't this necessary especially in larger cases where it's necessary to get one suspect to roll over on another? As long as defense attorneys are involved, what is the harm in this? reply gs17 13 hours agorootparent>Isn't this necessary especially in larger cases where it's necessary to get one suspect to roll over on another? There are multiple countries where it's not allowed, so it's definitely not necessary. >As long as defense attorneys are involved, what is the harm in this? Generally the cops will try as hard as they think they can get away with to keep your attorney away. This article is about someone who immediately asked if he should have an attorney, was told he didn't need one, and when one showed up anyways, he wasn't even allowed to know there was someone hired to represent him. The harm is that juries and judges really love signed confessions and cops love to pressure for one. The Reid Technique's entire goal is to take someone from saying \"no, I didn't do it\" to \"okay, I'll sign that I did it\". Ted Bradford had an alibi and a recanted confession that confessed things that obviously didn't match the facts of the case, and the confession was enough even when he finally had an attorney. It was enough that: >Despite the exonerating DNA evidence and the fact that Ted had already served his entire sentence for the crime, Yakima County prosecutors chose to charge Ted with the same sexual assault once again, offering his initial false statement in 1996 as the evidence against him. reply psychlops 13 hours agorootparentprevThe harm is that innocent people incriminate themselves. People are not experts on the law and make mistakes all the time. Even if they are eventually exonerated, the process is the punishment and there is no recourse. Not to mention that defense attorneys are usually overworked, working for free and you generally get what you pay for. reply pixl97 12 hours agorootparentThis right here. Any state assigned attorney is going to say \"Take the plea\". Simply put, most of the suspects do not have the money to present the case as needed in front of the courtroom, and the lawyer states, taking the plea is less apt to bankrupt you. reply bombcar 11 hours agorootparentTo be brutally honest, some huge percentage of people who get to the \"plea\" option are actually and truly guilty - this causes all sorts of issues. (One of the strange side-effects of mandatory sentencing is removing plea deals because if they HAVE to charge you with X, and guilty or plead on X is Y years in jail, then there is no reason not to go to a jury trial, because the worst case is you get Y years anyway, which you get when you plea out.) If criminals really were organized and forced everything to jury trials, the United States would collapse. reply gnicholas 13 hours agorootparentprev> As long as defense attorneys are involved, what is the harm in this? Good point, suspects have a right to an attorney and the right to remain silent. But much of the successful lying probably happens when an attorney isn't present. For example \"look, we can wait for your lawyer to get here, but this is looking really bad for you. We just arrested your buddy and once he sings we'll just throw the book at you. If you give your side of the story first, you get the better deal.\" A suspect without a lawyer might waive the right to counsel/silence and incriminate himself. Of course, he would be guilty, so it's not entirely clear this is a bad thing (unless he is falsely admitting guilt, which does occasionally happen). reply Terr_ 7 hours agorootparentprev> Why is this a good thing? Shouldn't cops be able to lie and put pressure on suspects? The problem is that--so far--we don't have a good way to allow the acceptable kinds while also prohibiting the terrible kinds. Imagine the police give an overwhelming list of false/non-existent evidence and testimony, so that the average (innocent) person would assume they're being deliberately framed by some power they are unable to fight, and that the only way to protect themselves and their loved ones is to buckle under. Another example would be where police lie/deliberately-mislead a suspect about the consequences of a confession. reply justinclift 13 hours agorootparentprev> Shouldn't cops be able to lie ... \"Hell no\" seems like the obvious answer, but you seem to disagree? reply echelon 13 hours agorootparentSince I feel that someone who murders or rapes someone should be spared little mercy, then by extension I feel this is an acceptable tool so long as it doesn't harm the innocent. reply justinclift 13 hours agorootparentAre you meaning there should be no presumption of innocence, or are you meaning the lying should only be allowed after they've been convicted? reply gs17 13 hours agorootparentprev>someone who murders or rapes someone should be spared no mercy But we're supposed to presume \"innocent until proven guilty\". A suspect is only accused, not convicted. reply jjav 12 hours agorootparentprev> as it doesn't harm the innocent The whole point here is that the person at this stage is presumed innocent. reply bobthepanda 13 hours agorootparentprevThat assumes the person in the interrogation room is the correct person to begin with. We have a fair amount of false conviction rates. reply anamax 9 hours agorootparentprev> As long as defense attorneys are involved, what is the harm in this? How about because defense attorneys are very expensive? reply nullindividual 13 hours agorootparentprevPeople have killed themselves due to cops lying. There's the harm. reply echelon 13 hours agorootparentOkay, so there's a negative externality to this approach. Is there a measure of this? If preventing cops from lying results in fewer trials going to court for violent crime, then I'd be curious to compare the two figures. I'm anxious about having fewer tools to investigate and prosecute. We used to have a 70% homicide clearance rate, but that's dropped to just 50% [1]. This feels like we'd be further trying our hands. [1] https://thehill.com/homenews/3878472-nearly-half-of-us-murde... reply nullindividual 13 hours agorootparentYou're using the same argument that death penalty supporters use. MOST of them are guilty, so killing ALL of them is OK! Wouldn't want to let off the guilty ones. The smart cops cut out all of this by simply killing the unarmed suspect before pronouncing the 'p' in 'stop'. reply scarface_74 12 hours agorootparentprevIf you have a choice between admitting you did something you didn’t do and get a lighter sentence or know you’re going to be railroaded by the justice system and still lose, which one are you going to do? And the “defense attorneys” are going to be overworked underpaid public defenders while the prosecutors have what amounts to an unlimited budget reply bombcar 10 hours agorootparentI'd argue you almost have a moral obligation to take the railroading, otherwise society begins to collapse. At least with the railroad there's a chance that the defense is sufficient, that the jury concurs, and the issues get exposed. If nobody fights it, it will metastasize. I understand how impossibly hard that could be in the moment, but never never go quietly into that dark night. Unless, of course, you're guilty and you know it, then clap your hands on anything that reduces what you have to suffer for it, I guess. reply scarface_74 10 hours agorootparentReally? Sit in jail for maybe 3 or 4 extra years for the “good of society”? reply Tostino 4 hours agorootparentFor a society that has utterly failed them in the first place...not a chance in my book. reply trogdor 12 hours agorootparentprev>interrogations are videotaped Interrogations are not always videotaped. State laws vary widely. Many states require audio recording only. Other states only require recordings for felony investigations. Many states only require recording of custodial interrogations for specific offenses, such as rape and murder. At one point, California only required recordings of custodial interrogations involving juveniles suspected of having committed murder, but that might have changed — I haven’t looked into this in a while. reply 20after4 4 hours agorootparentprevNo, interrogations aren't videotaped, at least not always. And even if they are, the police can destroy the video and just use their handwritten notes, and their memory, to testify against you at a trial. Your word against theirs. Tape disappeared. So sorry about your luck. reply anamax 9 hours agorootparentprev> because interrogations are videotaped The FBI doesn't do audio recordings, let alone video. reply bobthepanda 13 hours agoparentprevIt sounds like this also covers outside of the actual trial. A man was lied to by police about a hit-and-run putting the victim in critical condition (it did not), and committed suicide before any trial happened. https://www.kiro7.com/news/trending/seattle-police-officer-d... reply gs17 15 hours agoparentprev>But it's not enforced against police officers. That's true for a lot of laws. reply 20after4 4 hours agorootparentAlmost all of the laws, most of the time. reply onlyrealcuzzo 15 hours agoparentprevIsn't the problem with perjury that you don't need to prove what you say in court is true, but to prove someone committed perjury you have to prove what they said was a lie? It's not easy to prove someone lied. Yet we find it easy to believe what people say is true (even for juries in court). reply qingcharles 15 hours agoparentprevLOL. Police officers are never prosecuted. And do you know who is prosecuted even less? Prosecutors. And even less than that? Judges. I think in all of history only one prosecutor was ever prosecuted for what is known in the USA as a \"Brady violation\", where the prosecutor hides exculpatory evidence from the defense, even though it routinely happens. I tried repeatedly for many years to bring a prosecution against some cops and prosecutors for hacking offenses, but since there isn't really the concept of private prosecutions in the USA you have to rely on the prosecutor's office wanting to prosecute it's own. I even sued the prosecutor's office to try and enforce it, but the judge told me \"Of course police officers are allowed to commit crimes in the course of an investigation.\" If I get bored at some point I will have the audio recordings pulled from the court and put them online so other people can see the insanity. reply Buttons840 13 hours agorootparentBest idea I've heard is that the public defenders office (or whatever, I'm not expert here) should be responsible for investigating and prosecuting police. There's already a natural opposition there. The current system works if people have infallible integrity (hint, they don't), this change would make the system work if people have human nature. reply Arrath 13 hours agorootparentThe Public Defenders system is already chronically underfunded, understaffed, and far overworked. Sadly I don't think they would be the best avenue for trying to hold the police to account. reply justinclift 13 hours agorootparentSounds like there needs to be something like \"civil forfeiture\" for the Public Defenders system, allowing them to seize the assets of suspected dishonest police and police departments. Which they can then either keep, or sell off to raise funds for themselves. reply qingcharles 12 hours agorootparentprevThis. They can't even defend the rights of the public because they are so overworked :( reply debatem1 13 hours agorootparentprevPublic defenders would need resources akin to or larger than the prosecutor's office in order to take on this role. I don't know that there has ever been a time in America where the public cared more about defending the wrongly accused than convicting the genuinely guilty, but if there was it surely isn't now. reply Buttons840 13 hours agorootparentYeah, sadly, I know your right. But for the sake of argument, the prosecutors office and the defenders office should be equally funded. It should be in the law that they are equally funded. This makes sense, average people understand that attorneys defending a murderer aren't bad people, those attorneys are just doing their job and they play an important part of the legal system. Fewer think about the imbalance of resources and how that skews the results. It makes sense that examining both sides properly requires equal resources allocated to both sides. As you say, it's a long shot, but it's an idea worth trying for. If nothing else, maybe people can remember to include it in the next government we form after the collapse (half joking). reply throwway120385 14 hours agorootparentprevIf that happened in Washington I would love to know which judge so I can vote someone else in when the time comes. reply qingcharles 14 hours agorootparentIllinois. I wish I had the transcripts, but in civil court in the USA it's unusual as far as I'm aware to have a reporter transcribing. It is usually just recorded digitally, and then if there is an issue (e.g. appeal) the recordings are pulled and transcribed. I'm assuming, without knowing, that I can have the recordings pulled without paying hundreds of dollars for transcripts. You can't FOIA judicial items in Illinois, but across the country you have a federal constitutional right to judicial items under the 1st Amendment. reply notjulianjaynes 13 hours agorootparentIn Massachusetts (and presumably elsewhere) you can visit a website and pay $10 to get the \"For the Record\" audio recording emailed to you. You only need the docket number iirc. reply qingcharles 12 hours agorootparentThank you, I'll look into this today. reply bombcar 13 hours agorootparentprev> LOL. Police officers are never prosecuted. And do you know who is prosecuted even less? Prosecutors. And even less than that? Judges. At some point you have to have someone who is unprosecutable, or you have people who can be influenced. The king, at the top of this heap, is the jury itself; they cannot be prosecuted for their decision, even if it is obviously, manifestly, completely, pants-on-head-insane. reply tialaramex 12 hours agorootparentNo you don't, the current English King is named King Charles III. Did you ever wonder about the number? Charles I was executed in 1649. He kept starting wars, Parliament told him to stop, he wouldn't so they tried him for Treason, he asserted that he necessarily couldn't commit treason because he was the King, but Parliament convicted him and sentenced him to death. Parliament's rationale, then and now, is that their allegiance is to the Crown, a symbol of the country, not to some bloke who happens to be wearing it. He is just a temporary living symbol, even more replaceable than the (relatively expensive) metal object. You can prosecute individual members of parliament too, this too isn't a hypothetical, if they're convicted of anything serious enough they automatically lose their seat and a replacement is elected, while for more minor offences like anybody else they might keep their jobs if they can suffer the embarrassment of everybody knowing they're a crook Unlike in the US no individual holds a \"pardon power\" which could enable them to nullify a conviction, the Crown Power to do this is in practice exercised via a committee which investigates miscarriages of justice. Of course in principle a British Prime Minister could just insist they have this power anyway, and if a Parliament comprising largely of their party members goes along with it, so be it, on the other hand it's hard to see why the millions of British people who didn't vote for them should accept this, and it's not as though Britain hasn't had civil wars already. reply jfengel 11 hours agorootparentTwo things: 1. The UK parliament reversed course and brought back Charles I's son to be Charles II. In doing to it executed a ton of people responsible for revolt. That included Oliver Cromwell -- despite the fact that he was already dead. They dug him up, tried him, convicted him, executed him, and put his head on a spike for decades. So it's not clear how much power that precedent could hold. 2. Charles III is King of the United Kingdom. The title of \"King of England\" was retired by Charles I's father. Charles I was King of Great Britain. reply jimz 13 hours agorootparentprevProsecutors are absolutely immune. Brady violations only invalidate the underlying case and in really egregious cases, ruin future careers in politics, but it doesn't create criminal liability going the other way. Police have qualified immunity, prosecutors have absolute immunity, as long as the charge is something that constitutes their quotidian work. Private prosecutions do exist, but not on a federal level, and anything falling under the purview of the CFAA - which is the umbrella that hangs over all computer-access-related crimes, is federal by definition. Besides, with parallel construction, they can always legally reverse-engineer a legally sound rationale that doesn't violate the 4th Amendment or what-have-you. However, while prosecutors are absolutely immune, the police are not and therefore are subject, occasionally, to federal-level liability either criminal or civil, although the prevalence of police perjury - testilying, as commonly known - is both an academic niche that has produced plenty of papers and have achieved virtually nothing in the real world. The term came into the public consciousness in 1994 and as late as 2018 I've heard it bandied about by cops in a courthouse. Prosecutors need the cops to investigate (public defenders' have a much smaller team of investigators if you're lucky, but even then anything technical is hopefully something you know enough about to find the right expert and conduct a competent cross examination. The police, of course, have the first mover advantage and so they can set up the fall guy who is already pension-eligible and move their assets out of their name before getting tossed in the gentlest way possible under the minivan. I wasn't involved with the case but the classic WA case involving the police using all of their tools available to rearrange the narrative surrounding a murder caught on camera and a federal prosecution is the Otto Zehm case. I had the luck to see what happened at sentencing and it was frankly sickening. https://www.spokesman.com/topics/otto-zehm/ So, police do get prosecuted, but only below the federal level, and extremely leniently, and if weren't for the video it probably wouldn't have happened. Ten years for a murder caught on video is crazy considering that the feds were giving out pleas of 8 years for \"trafficking\" 4 pills of Oxycodone before fent got into the supply (also thanks to the feds, as it was entirely supply driven) and ten years after leaving WA I still have former clients incarcerated for much more ambiguous fact patterns and convicted after multiple mistrials. As for the feds, now that Bivens is basically dead, even their own IG reports read like lurid crime novels written in the most lawyerly way possible. And if they're really in trouble, creating a moral panic always works. It had worked so far. reply qingcharles 12 hours agorootparentJust to note that prosecutors are not absolutely immune in all cases. They can be qualified immune, like officers. For instance, in my case the prosecutor's office acted as law enforcement, e.g. they conducted investigations and conducted an arrest and executed a search warrant. In those cases, when they are acting in a nonprosecutorial role, and in a law enforcement role, they are definitely only qualified immune. In Illinois it was ruled that prosecutors creating their own quasi-police departments is no longer legal. The advantage for the prosecutors was that they could bypass 99% of the laws and regulations that apply to police because they don't fit the statutory or regulatory definition of a police force. Edit: Also to note, the CFAA has exemptions carved for law enforcement to do things that are criminal if done by the public: https://www.law.cornell.edu/uscode/text/18/1030 \"(f)This section does not prohibit any lawfully authorized investigative, protective, or intelligence activity of a law enforcement agency of the United States, a State, or a political subdivision of a State, or of an intelligence agency of the United States.\" reply noqc 15 hours agorootparentprevWhether or not a particular crime is one that the investigator is allowed to commit in the course of an investigation is extremely fact dependent, so the fact that you haven't included any is a little suspicious. reply qingcharles 14 hours agorootparentNo, the legality of whether a law enforcement officer can \"commit\" a crime is based completely on statute. Many statutes include exemptions for law enforcement. If there is no exemption, then it is a crime for the cops, the same as the public. e.g. https://www.ilga.gov/legislation/ilcs/documents/072000050K21... \"(d) This Section does not prevent any lawfully authorized investigative, law enforcement, protective, or intelligence gathering employee or agent of the State or federal government from operating any audiovisual recording device in any facility where a motion picture is being exhibited as part of lawfully authorized investigative, protective, law enforcement, or intelligence gathering activities.\" reply jacquesm 15 hours agoparentprevPerjury. reply prometheus76 13 hours agorootparentI think this is a separate issue, where officers routinely lie in interrogations to steer the person being questioned. This isn't perjury, because it doesn't happen in court. reply KennyBlanken 14 hours agoparentprevBelieve it or not, at least some judges are severely annoyed by the open, obvious lying officers do. One federal judge declared Boston Police officers and detectives to be liars and unreliable witnesses, for example. he proposed a \"corruption court\" and that went about as far as you'd expect https://www.youtube.com/watch?v=IebE8dDKEWM reply P_I_Staker 13 hours agoparentprevYou can throw out evidence gained based on a lie. Only one replier seemed to notice this. Also, from what I understand perjury is more widespread than you might believe, and tends toward frequent fliers in court. As I understand it, some officers take the attitude \"if they're going to lie, I'm not going to commit to always being honest, even if it means letting a POS out\" Don't agree, but just to address the point regarding cops being treated differently. People lie in court all the time, even getting caught red-handed and unprosecuted. P.S. Regarding that police attitude toward lying, it's the same as any corruption: You might think prosecutors and cops pull out all the stops for the \"real bad guys\", and this may be partially true; however in reality, it just comes down to who pisses them off the most, which often doesn't have that much to do with whether someone is the worst of the worst. reply baryphonic 14 hours agoparentprev> Purjury is supposed to be serious. But it's not enforced against police officers. [...] > So why should I believe, if this law passes, anybody in the justice system will enforce it? I haven't read the text of the bill, but according to this article, evidence obtained during an interview where the cops were lying can be excluded. This forces judges to consider the evidence during pre-trial motions in limine, and if a judge errs in allowing such evidence, that error can be appealed. That doesn't 100% solve this issue, but if enacted this will provide a real remedy. And trial judges hate to be overturned on appeal. reply bithead 10 hours agoparentprevIF it passes, SCOTUS will scuttle it. reply monkeynotes 14 hours agoparentprevA judge will simply throw out any evidence that was facilitated by a lie. Any good defence lawyer would wield this just like they wield bad chain of custody etc. reply a_victorp 14 hours agorootparentHowever I would guess most wrongful convictions are done against people that can't afford \"good defense lawyers\" reply jimz 13 hours agorootparentNope, the most competent defense lawyers are probably the federal defenders, who is backed by the resources of the feds, and have a much lighter case load, so they're able to actually spend the necessary time to mull over the minutia. They don't get to pick their clients and are frequently forced into being generalists, but on the federal level a lot of the \"small time\" crimes are kicked down to the state level. The feds prosecute terrorism, the local prosecutors prosecute murder. The thing is, the public have no idea what makes for a good attorney in any particular field (and it's not the jingle or Cellino and Barnes would probably be Supreme Court justices before the firm broke up), and public defenders are among the very few who have no choice in selecting their clients, the strength of the case, and with 80-120 open cases at a time you either really believe that your clients are all innocent or you absolutely need to hold the state to account as a matter of principle or you won't make it through the misdemeanor docket, never mind anything more serious or more sordid (mental health, juvenile). Public defenders don't get into the line of work as a backup option. At least at my law school, they didn't recruit, because frankly they can't beat private firms or even the prosecutors on just about anything but the possibility of being on the right side of history. The pay barely covers interest on your loans, even during trials you have to run out to fill the meter every 4 hours where I was at - only the police got free parking. Everyone in my class with my skillset ended up at an IP firm or doing in house work somewhere, mostly in the Seattle area but also down to California. I don't regret a minute of the work, but in the grand scheme of things it's impossible to make a difference on any scale when you are an active participant in the system which is inherently skewed and allows prosecutors so much leeway and so much coercive power that the police can totally get away with not outright lying in interrogations and just play on the ignorance of the accused and implied threats and achieve the same result. The lying is just the most fun a cop can have without planting a gun on someone. reply ceejayoz 15 hours agoprevGood. I understand that deception is necessary in cases like undercover investigations, but the practice goes far beyond those scenarios. Not just interrogations, either. https://abcnews.go.com/US/wireStory/michigan-case-offers-pub... > Brian Chaney says he asked for a supervisor during his arrest in Keego Harbor, Michigan, and Police Officer Richard Lindquist told him that another officer present was in charge. The problem: That second officer was not a supervisor or even a member of the Keego Harbor Police Department. Lindquist was never disciplined and his chief says that while a suspect has the right to request a supervisor, what the officer did was OK. reply waqf 13 hours agoparentThis is speculative and based on a possibly not-representative sample, but what I've noticed from watching bodycam footage is that when the suspect asks for a supervisor, the police give negative/discouraging replies to the suspect while they are also calling a supervisor in the background. I assume the intention is to comply with the letter of the law while maximizing the chance that the suspect will abandon the request and not force them to wait until the supervisor arrives. reply pixl97 12 hours agorootparentCops, in general understand the law very well, which makes them even more culpable for their abuses of it. You see this quite often in the cases where the suspect wants to stop talking and speak to their attorney, and the detectives do the \"Oh, yes, we'll let you call them in just one second, but first answer _____\" reply jeffbee 15 hours agoparentprevWhy does the subject of an interrogation have the right to request the presence of different cops? reply ceejayoz 15 hours agorootparentAsk the police chief; I'd imagine their department policy is that you can request one, given he's stating they do indeed have such a right. If he wanted to make a \"there's no right to a supervisor\" argument, he should have. \"You have the right, but we'll fake it\" is the worst of both worlds. reply duskwuff 15 hours agorootparentprevThat's not the problem. If the police don't want to comply with a suspect's request for a supervisor, they can say \"no\". They shouldn't need to lie to the suspect about who they're talking to and what their roles are; that's an abuse of their position. reply darth_avocado 13 hours agorootparentprevClearly you're not aware of the corruption in the small town government and justice system. If your neighbor is a friend of cop and they don't like you, plenty of cops are willing to put you through harassment and plenty of PDs, local prosecutors and judges who are willing to turn a blind eye towards it. Essentially, unless you believe every single cop is pure at heart and incapable of making a mistake, you should be wanting a presence of more than just 1 cop. reply jeffbee 13 hours agorootparentThere isn't one single cop anywhere in America who can go five seconds without saying something false. That's why I don't understand the marginal utility of more cops in the room. The person you want in the room is your attorney. reply jimz 13 hours agorootparentDing ding ding ding. Not just that, but you have to affirmatively and unambiguously invoke your 5th Amendment rights. As in, \"I wish to invoke my rights under the 5th Amendment of the United States Constitution to remain silent while my lawyer is not present, and I wish to explicitly invoke my 6th Amendment right to counsel.\" No weasel words, no maybes or I dunnos. Invoke your rights, and if they persist, invoke your rights again, and again, and again. It's the only way to save your ass before the lawyer arrives because the police are simply seeking to catch somebody, not the right person necessarily, and they will literally outsource the lying to the jailhouse snitch to make it happen, amongst other tricks. You can't explain your way out of a situation where the police feels that you are their best shot at getting a perp walk arrange ASAP. Your lawyer can though. reply pixl97 12 hours agorootparentAnd goddamn the cops will lie to you about how much worse your life is going to get for invoking the 5th. Most people do not have the experience or fortitude to stand up to an authority figure like this, they've been taught just the opposite, and cops know how to abuse the hell out of it. reply gs17 15 hours agorootparentprevIf it exists, it must be a local thing in Keego. I'm from the same county and I've never been given the advice to ask for a supervisor, only to ask for an attorney. reply mrangle 15 hours agoparentprevnext [11 more] [flagged] gs17 15 hours agorootparentIf law enforcement could behave itself, there would be less demand for \"anti law enforcement\" legislation. reply lcnPylGDnU4H9OF 14 hours agorootparentI'd ultimately disagree with \"there's nothing wrong\" but I see their point. De jure, the relevant actual \"rights\" one has are to remain silent and to be represented. It's department policy that allows for a suspect to request a supervisor. It speaks to a corrupt department when they don't discipline the guy for violating said policy but that's not unlawful, just shitty. (Like, why have the policy?) reply s1artibartfast 15 hours agorootparentprevsure, but that doesnt mean the proposed solution is even worse than the status quo. reply mrangle 15 hours agorootparentprevnext [5 more] [flagged] jachriga 15 hours agorootparent> If criminals would behave themselves, there would be less demand for \"law enforcement\". I don't think you realize you're arguing against all laws here? Criminals don't behave themselves, so we make laws and punish them. Law enforcement doesn't behave itself, so we should make laws and punish them. reply mrangle 14 hours agorootparent>I don't think you realize you're arguing against all laws here? How does the relative concept of \"less demand begs less supply\" translate into an absolutist eradication argument in your mind? Ignoring you moving the goalpost from a conversation about law enforcement personnel to a conversation about the legal code. See next. How does a comment on law enforcement personnel supply (ie: the enforcement part of law enforcement) logically migrate to a comment on the legal code's existence? I made no such argument. I made a rhetorical point that meant to imply that law enforcement personnel supply (relative ability to enforce the law in any given area), and their techniques, are the outcome of criminality. Given that LE lying to suspects is not \"misbehavior\" but a standard investigative technique that falls comfortably within a just legal system. All evidence has to be disclosed. There are already justifiably harsh laws against falsifying evidence for the purpose of charging suspects. Suspects have the right to shut up and to an attorney, both of which will fully protect them from being coerced into giving false confessions. reply gs17 13 hours agorootparent>All evidence has to be disclosed. The article is about a case where it was not truthfully disclosed: >Bradford recalls police making threats and lying to him about DNA evidence they said proved he committed the crime. After hours of interrogation, he confessed, hoping the evidence would acquit him. \"Falsifying evidence\" does not apply when it's words spoken during an interrogation. If his confession became fruit of the poisoned tree due to lying to him, it wouldn't have been an issue. At least 10 years of this man's life was lost because non-existent evidence was claimed in an interrogation. >Given that LE lying to suspects is not \"misbehavior\" but a standard investigative technique that falls comfortably within a just legal system. Several other countries don't rely on this \"technique\". Surely you don't think American cops are so incompetent they can't catch anyone without it. >Suspects have the right to shut up and to an attorney, both of which will fully protect them from being coerced into giving false confessions. Except the suspects typically do not know the rules of the game they're being forced to play. The \"I want a lawyer, dog\" guy knew he had a right to an attorney, he didn't know you need to prompt engineer the police. reply jacquesm 15 hours agorootparentprevAt that point in time someone is at best a subject. Whether they are a criminal or not remains to be seen, you are a couple of steps ahead of the process there. reply adrr 15 hours agorootparentprevIs it? Do you have data to back up your data? How often are people convicted with coerced confessions compared to just straight evidence. I did quick search on for data and found this. Should the balance fall on protecting innocent people or prosecuting criminals? > According to the Innocence Project, almost 30% of convicted people who have been exonerated by DNA testing confess to crimes they didn't commit. reply mrangle 15 hours agorootparentWhat data of mine is that, which needs backing up? To gently help you with your attempt to appeal to science , in the vain hope that you aren't tossing word salad. Again, people have a right to remain silent and a right to an attorney. Two rights that they should ALWAYS exercise. Coercing confessions is literally how law enforcement gets any confession. If someone confesses, its not up to the cops as to whether or not the confession is true. It is then up to a court. Cops don't convict anyone. If a suspect messes up and confesses to something that they did not do, then it is up to a jury to exonerate them. But the suspect is not supposed to forgo their Miranda rights in the first place. Not doing so makes things much better for them. Literally an attorney is the best and front line legal protection for all peoplle guilty and innocent. The right to one exists. You want to legally protect people from making self-incriminating false confessions. Cops are not going to be the vehicle for that protection. Again, see the suspect's right to an attorney. reply adrr 14 hours agorootparentThat deceiving people is an effective tool for police. reply qingcharles 14 hours agoprevIllinois already made it illegal for cops to lie to children during interrogations: https://www.ilga.gov/legislation/ilcs/fulltext.asp?DocName=0... \"...if, during the custodial interrogation, a law enforcement officer or juvenile officer knowingly engages in deception.\" Hopefully they extend it to adult interrogations. I just did 10 years in jail waiting for trial before the charges were dropped, partially due to a bogus interrogation (that was ruled unconstitutional by the court) where I refused to talk and they badgered me for 45 minutes after that telling me I couldn't use that right and then threatened my family. That's the point you break, not when the cops hit you with a wrench, but when they threaten people you love. reply WirelessGigabit 14 hours agoparentThat's quite the story. Any news reporting on your case? reply qingcharles 14 hours agorootparentThere will be once it's all finally resolved at the end of this year (I hope). Still going through the tail end of it. reply candiodari 14 hours agoparentprevHow is this supposed to work: \" ... if you say that X is wrong we throw you in youth care, you get put in a place little better than a summer camp, among criminal youngsters, with 2 adults per 30 kids that don't bring you to school, don't help with homework, where all your stuff is stolen, and we use the police to arrest you if you ever decide to leave until you're 18, when you'll likely have failed all your schooling and be thrown into the street ... \" You cannot be honest to kids about youth services the way it currently exists in the US, in any state. That's just absurd. reply qingcharles 14 hours agorootparentEverything I've heard about the institutions for criminal children is pretty horrific. Nearly everyone I spent my time with in jail was in and out of those youth jails/homes as kids and they all sound like mad-houses. reply 20after4 3 hours agoparentprevWow that is fucked. I'm sorry you went through that. 10 years is sickening. reply jotato 15 hours agoprev> He said he was asked to waive his rights and when he asked police whether he needed an attorney they said no because they were only asking a few questions. He signed the waiver thinking he was going to help, but a few questions turned into a nearly nine-hour interrogation How is it we are able to legally \"waive rights\"? That should be addressed - under no circumstances should a not-yet-convicted person ever be stripped of rights. Voluntarily or not. Otherwise, what are they? Sure, someone can choose to not exercise them; maybe cooperate with the police, but if at any point they choose they should be available. Am I missing something? reply NegativeK 15 hours agoparent> stripped of rights They're not being stripped of their rights; they're acknowledging that what they're about to say can be used against them. Waiving rights is common in American law. Open source licenses waive the right to sue; the third-party doctrine waives the right to privacy of the data that companies take. To some extent, liability releases for participating in dangerous activities waive the right to hold the company you're paying responsible -- think climbing guides, race tracks, sky diving outfits, etc. But from what my non-lawyer self understands, there are some rights you can't waive, like the right to sue over gross negligence. In this case, it sounds like that waiver was used more as an intimidation tactic to make the suspect believe that they were stuck there and couldn't decide to stop talking. Which... That sounds like something you'd get a lawyer for to help explain the situation. reply ceejayoz 15 hours agoparentprevYou have the right to remain silent. You also have the right not to remain silent. Talking after a Miranda warning is taken as a clear waiving of that right to remain silent. You can, of course, stop talking at any time, but they're not going to re-Marandize you after every sentence. reply jotato 15 hours agorootparentThat is different that signing something and being held to it. You waived a right by saying that but you can choose.l to not speak after. Even if the paper waived an attorney you should be able to change your mind reply ceejayoz 15 hours agorootparentNo signature on paper can force you to keep talking in police custody. You can stop talking at any time, regardless of what you signed. reply mschuster91 13 hours agorootparent> No signature on paper can force you to keep talking in police custody. You can stop talking at any time, regardless of what you signed. Cops are very persuasive when they want to get an answer out of you. Say, they arrest you for whatever, and they can just threaten you to remain in custody for a day... no matter if your pet is alone at home and needs to be fed, or your children need to be picked up from school. Sure, you may call a lawyer to arrange for stuff, but we'll keep your house's keys as evidence... The freedom to not say anything is utterly depending on circumstances allowing you to do so. reply s1artibartfast 15 hours agorootparentprevi dont think they can hold you to it, should you change your mind. It isnt binding. reply laweijfmvo 15 hours agoparentprevI assume he waived his \"right to an attorney\" reply tekla 15 hours agoparentprev\"You Have the Right to Remain Silent\" \"I killed that person\" That's how you waive your rights. reply jandrese 15 hours agoprevThis is going to be very unpopular with prosecutors. How are they going to secure convictions against the innocent if they can't lie to them? If it is illegal to say \"We have all of the proof we need to convict you, you are going away for life, but if you confess we'll shorten your sentence\" when they have no proof at all it's going to put a heavy burden on the prosecutor to get that person in jail. reply bdcravens 15 hours agoparentThe sentence only has to change a little bit to become true. \"If you're found guilty, you could go away for life, but if you confess I'll go to the judge and offer less time\" Constitutional protections aren't there for the legal system, they're there for the accused. Make it harder to convict, and maybe it'll get to a point where we realize we can't lock away societal problems, and have to start fixing root causes. reply jandrese 15 hours agorootparentThat's much less impactful though. There's a term of art in interrogation \"showing the tools\" that is intended to get a person to comply with your wishes. \"If you are found guilty\" is far less impactful than \"We have evidence that you are guilty\". The purpose of these interrogations is to secure the conviction, not to discover the truth. Ironically these techniques work better against the innocent than criminals. The criminals know that the cops lie and that simply shutting up is often a sufficient defense. The innocent get bamboozled and end up with jail time. reply ryandrake 14 hours agorootparent> The purpose of these interrogations is to secure the conviction, not to discover the truth. People really need to internalize this when it comes to their interactions with the police (and ultimately when it comes to their obligations as voters). After an investigation starts, the police's one and only job is to put someone in prison. Not to solve the case. Not to get to the truth. Not to promote some notion of justice. It's to get a conviction and that's it. Choosing to talk to the police \"because I have done nothing wrong\" or \"because I want to be cooperative\" or \"because I think they'll go easier on me if I do\" are all terrible choices. When they are talking to you they have a single goal: To convict you. reply justinclift 13 hours agorootparentprev> That's much less impactful though. Sure, that's the point. Less fucking over of innocent people should therefore be less impactful. ;) reply jandrese 9 hours agorootparentDAs don't get promotions by not convicting people, innocent or not. reply BeetleB 14 hours agoparentprev> How are they going to secure convictions against the innocent if they can't lie to them? The way they do in countries that have long forbade lying in interrogations: https://law.stackexchange.com/questions/84483/is-it-generall... > when they have no proof at all it's going to put a heavy burden on the prosecutor to get that person in jail. Oh, how awful it is that a prosecutor has to prove someone's guilt! What next? Presumption of innocence? Having followed the topic on and off for well over a decade: As a juror I never believe someone's confession. Rather irrelevant as most confessions won't get to trial, but it often takes very little to get a suspect to produce a false confession. At times, even without any deceit from the interrogators. I wish I could recall one particular case: A person was murdered, and they charged another person living in the apartment complex. After a long interview session, he confessed. But his confession didn't match any of the evidence. So they pressured him to name an accomplice. The accomplice confessed. The evidence still didn't match. They kept pressuring the original suspect to name names until they had 4-5 people - all of whom confessed. They later retracted their confessions, claiming duress. But the jurors convicted them on the strength of their confessions (\"Who would confess to a murder? I wouldn't!\"). They were, of course, all innocent. They spent time in prison, and eventually managed to get the courts to release them. But one or two still haven't been \"exonerated\" - their conviction stands and thus can't get jobs (or even an apartment). Oh, and no physical coercion was involved. They were simply worn down by the long interrogation. IIRC, over half of people whose convictions have been overturned involved a confession of guilt during interrogation (maybe it was just death row folks - don't remember the specifics). reply ghastmaster 14 hours agoparentprevYou are conflating prosecution communications with interrogations. It is not legal for a police officer or detective to say what you quoted. It's akin to legal advice, which they do not do anymore if they are smart. This bill does not address the prosecution negotiation/communication. reply mrangle 15 hours agoparentprev> If it is illegal to say \"We have all of the proof we need to convict you, you are going away for life, but if you confess we'll shorten your sentence\" when they have no proof at all it's going to put a heavy burden on the prosecutor to get that person in jail. That's not a realistic scenario. All actual evidence is disclosed as a matter of course in the justice process. Any bottom barrel attorney assures this, to whom the defendant has a right. reply gs17 15 hours agorootparent>when he asked police whether he needed an attorney they said no because they were only asking a few questions More from https://wainnocenceproject.org/stories/ted-bradford/ > An attorney sent by Ted’s wife was prohibited from entering the interrogation room by law enforcement, who told the attorney he would not be permitted in unless Ted specifically requested an attorney. The cops are not interested in playing fair. reply digdugdirk 15 hours agorootparentprevThat statement is factually untrue. Law enforcement regularly withholds evidence without any repercussion. More importantly, the previous comment is referring to plea bargaining. Essentially, law enforcement is using the poor state of the current justice system to pressure people without resources into accepting a guilty verdict because the system is so stacked against them. Imagine: \"Yeah, you can try to prove your innocence, but we're going to hold you until your arraingment. That'll be at least a few weeks, which will mean you'll lose your job and your apartment and your car will be repo'd. And you'll probably lose anyway, because we've got all this evidence against you, and we promise its bulletproof. Or... You can take this deal we're offering. You plead guilty, and we'll let you walk out of here today.\" reply jandrese 15 hours agorootparentprevFalse confessions are often secured without an attorney present. Many people are not good at demanding their attorney, and the cops aren't going to suggest it or offer it as an option to someone they're trying to sweat out. reply gs17 15 hours agorootparent>Many people are not good at demanding their attorney It doesn't help that \"not good\" can include using a slightly slangy sentence (\"laywer, dog\") or sounding like you're asking permission or stating an opinion. reply legitster 15 hours agorootparentprevSure, but the actual evidence is much easier to collect after you have a confession. reply jandrese 15 hours agorootparentWhy would they need evidence if they have a confession? The cops aren't going to do extra work they don't need to. reply ceejayoz 15 hours agorootparentA confession may make other evidence easier to get at. If you suspect wrongdoing, but don't have probable cause to search the car/house, and the suspect says \"oh yeah I've got a dead body in there\", you're potentially about to be in posession of some serious new evidence you didn't have a right to get at previously. reply mrangle 15 hours agorootparentprevWhat? reply garyfirestorm 15 hours agorootparentprevThese things happen before courts are involved. They are known as plea bargains. Unless you have a ton of money and a lawyer on call and are really smart, you would be made to believe it’s this short sentence or a very long sentence. Many people without resources and support often falsely confess. reply lokar 15 hours agoprevNever, ever, talk to the police without a lawyer. They are not your friends. reply hangonhn 15 hours agoparentA high school friend of mine made the mistake of doing that because in the past he had cooperated with the arresting officer (i.e. snitched). However, what he didn't realize is that may have no bearing on what the officer might do but even more importantly, it's the prosecutor who decides if he's going to pursue the case and they did not care about his past history with that particular officer. The police are not your friends but more importantly they aren't the ones who do the prosecution. They interrogate and they have a job to do. reply legitster 15 hours agoparentprevEver? You can talk to the police during normal goings on just fine. They are not going to interrogate you just for asking for directions. It's during an investigation that you should lawyer up. reply adgjlsfhk1 15 hours agorootparentpolice do not tell you when you talking to them is part of an investigation. as such, don't talk. reply bitfilped 14 hours agorootparentprevEver. reply grecy 15 hours agorootparentprevA friend was an LAPD detective for 30 something years. Now retired. Extremely nice person. He emphatically told me I should never, ever, ever talk to the Police. Even if I witness a hit and run and just happen to be standing there and they walk over to me. Any one of 10,000 scenarios where the Police ask me for something, or want me to give information about something (even if I wasn't there). They are actively searching for someone to blame, and if you happen to say the wrong words while trying your utmost to be helpful, they'll happily pin it on you. reply legitster 14 hours agorootparentThat example is pretty bunk. I've literally been that person talking to the police after a traffic accident dozens of times. They have never asked for an ID, 90% of the time they don't even ask for your name, and maybe 50% of the time they ask for a phone number (they have never called back). There are absolutely police officers who are lazy or will power trip or love busting perps. But each officer is not starting dozens of investigations every day. Especially the beat cops you are most likely to run into. reply EasyMark 9 hours agorootparentI think the deal is that it only takes once to ruin your life. The chances are low, but if you win the lottery the risk is personally devastating. if they try to pin a felony on you and even if it all comes up as bunkem, you'll forever be on the internet as someone charged with a felony without a conviction, the same will come up in your criminal background search. reply legitster 8 hours agorootparentHow are they going to pin something on me if they don't even get my name or address? People are conflating two things in this thread - \"talking with the police\" (aka voluntarily consenting with questioning) and literally just having a conversation with a police officer. If you have a moral directive to slight the police, I can understand. But just asking for directions or telling them what you saw is not going to increase your chances of having a felony pinned on you more than showing up in random security footage. reply lotsofpulp 14 hours agorootparentprevWhat do you do that causes you to witness dozens of traffic accidents? reply legitster 14 hours agorootparentDozens might be an exaggeration, but at least a dozen. I had a job that required me to drive a lot in urban environments, and I regularly pulled over for good Samaritan stops. I also briefly worked at a motel in the middle of nowhere and you better believe that regular conversations with police officers is a critical aspect of the job. reply pixl97 12 hours agorootparentExperience with law enforcement is 100% affected by the biases the officer you are talking to suffers from. If you're the middle class, middle American, nicely dressed, and got that harmless look. Well, expect things to go pretty well. Business owners of non-sus businesses generally have it pretty good too. Are you a minority? Not dressed well? A youth? Well, things can go sideways for you quick. reply thomastjeffery 12 hours agorootparentprevThe problem is that you are both right, and in a way that can't be meaningfully predicted. The stakes are incredibly high, too. reply threatofrain 12 hours agorootparentIf they're both right then that means you shouldn't ever talk to police. reply legitster 11 hours agorootparentOr you know, make reasonable judgement based on context. If you are getting actively stabbed talking to a police officer might be a sensible decision. Never talking to police is a much worse advice then \"don't participate in questioning without a lawyer present\". reply threatofrain 3 hours agorootparentThen I refer you to the previous post: > in a way that can't be meaningfully predicted. The stakes are incredibly high, too. If we're talking about giving people advice for the police, I don't think people are going to need help with \"Oh, you're being stabbed as we speak, should you call 911?\" That's not the question people need help with. You're not boosting anyone's judgment here by leading with that argument. However, if police want to ask what you're doing on your property in a friendly way, should you respond or should you say that you want to contact your lawyer? Or if you feel like striking up a conversation with the police to develop warmth, should you? The right answer might come down to whether you're black, Native American, Asian, man, woman, etc., but without knowing more, don't talk to police is solid advice which has developed through a long relationship between citizenry and police. Even if you're just a witness, it would be naive to think you have nothing to fear. Even when you are the person who needs help, it would be naive to think you have nothing to fear. If the police of America want to turn around their reputation, that's totally on them. The ball is in their court. reply barbazoo 15 hours agorootparentprev> Even if I witness a hit and run and just happen to be standing there and they walk over to me. > They are actively searching for someone to blame That seems very, very far fetched. reply tzs 12 hours agorootparentprevThis is how you persuade citizens to accept widespread surveillance. If people know that if they get hit by a car or robbed or something like that none of the witness will talk to the police they are going to be way more inclined to support more surveillance. reply dekhn 14 hours agorootparentprevI can't imagine not acting as a witness to an accident (especially hit and run). reply oglop 15 hours agorootparentprevOk, so you know society breaks down at the limit of what you are saying, right? Also the example is ludicrous, you're saying the cops would try to blame someone for a hit and run that isn't even in a car. No, the cops are not that cartoonishly bad. Some cops in some departments may be, and I can almost guess the cities, but the average cop is not a monster, they're just some person like you or me. reply autoexec 13 hours agorootparent> the average cop is not a monster, they're just some person like you or me. The average person like you or me who becomes a cop gets chased out of the profession because they wouldn't turn a blind eye to the crimes their fellow officers commit against the public. Everyone left is most likely either just as guilty or complicit and enabling. reply throwway120385 12 hours agorootparentprevI would say you should pay attention to who you're talking to. Some cops are that cartoonishly bad. My wife worked retail at TMobile and had cops come into the store at times trying to get information about customers. Most of them would accept the corporate policy and go talk to legal about the information they needed. One police officer started having a meltdown, sweating profusely, got visibly angry, and made her present her ID whereupon he wrote down her driver's license number, address, full legal name, etc.. She spent the next month or so dreading what he was going to do in retaliation. All because she redirected him to their legal department for information about a customer. reply Vinnl 12 hours agorootparentWhat are you supposed to do though? Surely stating that you don't want to talk to him or want a lawyer isn't likely to be deescalating? reply engineer_22 9 hours agorootparentprevSo... what happened? reply thomastjeffery 12 hours agorootparentprevI think that's the observation you are both making. Society has broken down right at that limit. reply immibis 13 hours agorootparentprevYes - society breaks down when cops act dishonestly and people stop trusting them. That is a good reason to fire the dishonest cops and hire honest ones, but in the current climate, that can't happen. reply threatofrain 12 hours agorootparentThere needs to be prosecution and not just firing. When an engineer lies in a legal setting and consequently gets someone put into jail for years, should they merely be fired? reply adgjlsfhk1 14 hours agorootparentprevthey won't blame you for the hit and run, but what if a store near there gets robbed an hour after you talk to them, and they decide you're a suspect because you look somewhat like the description and they know you were in the area? reply dekhn 14 hours agorootparentI think you're stretching to make your point here. You can construct many \"what ifs\", but they mainly apply if the police are actively subverting the normal rules of law or incompetent. There are a subset of cops who are corrupt, or racist, or classist, where merely interacting with the police can lead to serious outcomes, but that's sort of a different problem that has to be addressed more systematically. reply adgjlsfhk1 10 hours agorootparent> There are a subset of cops who are corrupt, or racist, or classist, where merely interacting with the police can lead to serious outcomes, but that's sort of a different problem that has to be addressed more systematically. The fundamental problem is that you don't know whether the police officer you are talking to is good or not, and if you find out, it is too late. Talking to a police officer is like petting someone else's dog. Don't do so unless you've talked to someone who feeds it first. reply mschuster91 12 hours agorootparentprev> You can construct many \"what ifs\", but they mainly apply if the police are actively subverting the normal rules of law or incompetent. Cops in the US barely receive training - the average length is 22 weeks, while Germany clocks in at 2.5 years [1]. Of course a lot of police will be incompetent in the first place given the length and priorities of these trainings, made worse by cargo-culting from \"senior\" officers and by \"killology\" training [2]. [1] https://abcnews.go.com/US/police-training-us-falls-short-com... [2] https://www.washingtonpost.com/nation/2021/08/11/police-trai... reply s1artibartfast 15 hours agoparentprev(if you are a suspect). there are a multitude of legitimate reasons to talk to police without a lawyer. e.g. you are a victim, you are helping a victim, you are being friendly. The real advice is not to try to talk your way out of a crime because it rarely works. reply jandrese 15 hours agorootparentHow do you know if you are or aren't a suspect? The cops aren't going to tell you. reply s1artibartfast 13 hours agorootparentReasonable inference/ common sense. If I called them for a home break IL in at my house, I'm probably not the suspect. If they're asking for a description of a car after I watched a hit-and-run, I'm probably not a suspect reply 20after4 3 hours agorootparentIf you call them for a break in you 100% are a suspect. They suspect you're up to something. They might even find evidence of another crime while they are investigating the break in. reply VanTheBrand 14 hours agorootparentprevin several of these situations you may become a suspect by talking to the police. Plenty of instances of people being killed or injured by the police also begin with them calling the police for help. https://en.m.wikipedia.org/wiki/Shooting_of_Linden_Cameron reply s1artibartfast 12 hours agorootparentSure. There are low probability risks inherent in all all parts of daly life. That doesn't mean never call/talk to the police. That is a crazy viewpoint driven by hyper focus on risk mitigation. It is like refusing to leave your burning house because you might be hit my lightning. reply ambigious7777 12 hours agorootparentprevPlenty might be an overstatement, but the case you linked is quite ridiculous. The boy was for one, unarmed and they decide to start shooting (eleven times!!) at him? I cannot imagine what those people were thinking. reply gs17 15 hours agorootparentprevThe article is about the story of a guy who tried to talk his way out of a crime he didn't commit. He thought he was there ''to help with a case.'' reply s1artibartfast 12 hours agorootparentSure. Do you think that is representative of the majority of police interaction and a good basis for a universal rule? Does it negate the utility you can get from talking to the police? reply 20after4 3 hours agorootparentYes it negates any (negligible) utility you might hypothetically get from them. Here's a different example: Police have a policy of shooting aggressive dogs, under basically any circumstances. So if you have a pet that is slightly protective of their territory, then any situation that brings the cops within shooting range of you pet can get your pet killed. reply gs17 12 hours agorootparentprevIt certainly makes \"you are helping a victim\" not a safe time to talk to them. He thought he was helping a victim, instead he was made a new one. reply s1artibartfast 10 hours agorootparentNothing in life is perfectly safe. like I said above: 1) Do you think that is good basis for a universal rule? 2) Does it negate the utility you can get from talking to the police? Anyways, it is impossible they thought they werent a suspect and helping a victim after 9 hours when he was signing a confession. reply IncreasePosts 15 hours agoparentprevI've talked to police a number of times without a lawyer, and it has always been fine. reply mikestew 15 hours agorootparentI've wired electrical outlets without turning off the breaker, and I'm still here to type this. I would not, however, advise others to do so but rather emphasize the importance of turning off the breaker before doing electrical work. Other than \"nice day, eh?\" or \"No, as a matter of fact I do NOT know why you pulled me over\", don't talk to cops without a lawyer. reply oceanplexian 15 hours agorootparentIn my experience they will phrase it as “Do you know how fast you were going?” or “Do you know what the speed limit is?”, worded in such a way that ANY answer is incriminating. reply dekhn 14 hours agorootparentCan you explain what happens if you answer those? Does that affect the outcome? Is a cop that pulls you over for what looks like a traffic violation trying to get you to make an incriminating statement (I have no idea, I'm just asking. No agenda)? In the few situations where I was pulled over for speeding, I asked the cop to show me the reading and also whether the device was calibrated in the past few years, and they've always obliged (after answering \"I know how fast I was going\" and \"I think the speed limit is...\". If they have a calibrated device and they show me the reading, I'm not really sure how my answers to those questions affects the decision tree. What you want to do is avoid creating an unnecessary confrontation by acting adversarial. reply GrinningFool 13 hours agorootparent> , I asked the cop to show me the reading This might not be as significant as you think. My understanding is that many models allow them to set that number directly. If I recall correctly, the source for this was \"A Speeder's Guide to Avoiding Tickets\", written by a former state trooper. I don't know if it's factually accurate, but the advice in that book has generally been solid. reply dekhn 13 hours agorootparentI don't know if that's accurate either. In any case, his reading corresponded the speed I was going (within the margin of error for a speedometer, which can be large), and it was calibrated, so I signed the citation and paid the fine. Again, if cops are actually going around setting values to get citations, there are larger systemic problems. Also, many vehicles have GPS and other datalogging showing actual speeds, so if the cop is faking the numbers, that's going to start showing up in court. reply adgjlsfhk1 14 hours agorootparentprevanswering that you know how fast you were going, combined with data suggesting you were speeding yields the conclusion that you were intentionally breaking the law. reply dekhn 14 hours agorootparentYes, and? Sorry to be obtuse, but I'm just trying to understand the decision tree here. Of course if I'm speeding I know I'm breaking the law. Does denying that somehow get me out of a ticket? Look at the base rate of speeding. When I drive on 101 in the bay area in clear traffic, I'm doing around 65 (the limit)-75 in the right lane and the majority of people are passing me on the left (or tailgating me because they want me to go faster or drafting or whatever it is that causes people to drive too close behind me when I drive near the speed limit). From what I can tell, unless a cop is actively trying to be punitive, they typically don't stop a car simply because it's going up to about 15MPH over the freeway limit. reply ryandrake 13 hours agorootparentI have personally successfully argued in front of a traffic court judge that I could not be aware of the speed limit since the sign was obscured, and it resulted in not having to pay the ticket. I am sure I would not have been successful if I admitted guilt in front of the officer who pulled me over, or participated in his various gotcha games. reply dekhn 13 hours agorootparentDid the cop show up to your court date? Did they provide any information to the judge? Did you truly not know the speed of the road you were on, and was that because the sign was obstructed, or is that the argument you made in court? It seems like in this situation I could have honestly answered \"no, I did not know the speed limit\". I mean, where I said I'd know the speed limit above, if it was truly obscured, I think I would be playing it safe and judge things on what the road looked like, whether there was a school there, and the weather and other ambient conditions. reply ryandrake 13 hours agorootparentYea, the cop showed up, presented his evidence, I argued that absent a posted limit I was following the state's default limit for that type of road, and brought a photograph of the nearest speed limit sign obscured by a tree branch as evidence that I could not have known the posted (lower) limit. Judge found it convincing. I noticed that the branch was trimmed two weeks later. I did not answer any of the officer's questions during the stop, but did identify myself and hand him all the documents he requested. I figured I wasn't going to avoid the ticket using my mouth, so I saved it for the judge. reply dekhn 13 hours agorootparentOK, fair enough. You acted in good faith during the court date and chose not to answer questions or get adversarial with the cop during the stop. And you were technically correct, with evidence, which is best kind of correct. How did you proceed past the initial questions, IE how did you refuse to answer in a polite way (I'm curious because there is a whole genre of youtube videos of cops stopping people and the driver getting in an adversarial situation by refusing to talk). Also, just out of curiosity, what was the default limit for that type of road, and what was the posted speed limit? Are we talking \"driving 35 in a 25 zone\". Any other contextual information, like weather conditions, nearby school, recently changed limit, etc? The cops that park at the school near me usually don't stop people unless they are driving 45+ in our 25 zone. reply ryandrake 13 hours agorootparentI just ignored his question and immediately handed him the documents he required without any resistance. I didn't talk back or question him or even remotely cop an attitude. I'm sure I got lucky that the cop didn't feel like pressing further with his gotcha script. I am white which probably helped immensely too. Unfortunately that still matters--I can acknowledge my privilege. I watch a lot of those YouTube traffic stop videos (they are addicting), and a lot of suspects in these videos talk themselves into (or attitude themselves into) an arrest. Not to mention incriminating themselves. You know the ones who don't make it onto YouTube? The ones who shut the fuck up and probably end up much better off. reply adgjlsfhk1 10 hours agorootparentprevHow sure are you that you know the speed limit and how fast you were going? Your speedometer likely read a different value than the police officer's radar. If you tell them you were going faster than they measured you at, which value do you think is getting written down? Also, even though you were speeding and were pulled over, that doesn't guarantee that you actually got radared. It's entirely possible that you were pulled over for something completely different, but by answering that question, you have just admitted to something else. reply dekhn 8 hours agorootparentI can't be sure of the speed limit and how fast I am going, but having lived in this area I can typically tell the speed limit of any road. Highways are 65MPH, and streets are typically 15 (alley), 25 (residential streets with parking and school areas). In California, speed limits are not required to be posted in some situations, \"prima facie\", and knowing the mapping from road characteristic to speed limit is required to get a permit. For how fast I'm going, I'm usually checking my speed every 30 seconds or so, but can also tell how fast I'm going simply by looking, how hard I'm pressing the pedal (my car is in \"Eco\" mode, which means it's pretty pokey all around). I never drive more than about 15 miles above the speed limit (and then, only on a freeway where folks are driving fast enough that I don't feel safe driving slower, because people frequently come right up behind me and change lanes at the last second if I drive the speed limit on California highways). So I am not particularly worried about the cases you're describing (speeding like that is a misdemeanor, not a felony). I used to drive faster, but over time I concluded that driving slower has a wide range of benefits, both in accidents, as well as fuel consumption. It's not like driving 10MPH faster on the freeway is going to make a huge difference in your arrival time. I see a lot of armchair lawyers on places like Hacker News who confabulate all sorts of scenarios to justify their adversarial relationship with the police, other folks who assume all cops are racist/classist/whateverist, and other folks who just don't want to follow laws because they don't like authority. I really don't know what to say to folks like that. Collect telemetry and bring it to court, and good luck with that! reply adgjlsfhk1 14 hours agorootparentprevthe least wrong answer is likely \"I believe so\". reply bdcravens 15 hours agorootparentprev> \"No, as a matter of fact I do NOT know why you pulled me over\" For bonus points, quote \"99 Problems\": \"Do I learn like a mind reader, sir? I don't know.\" (that entire verse is quite educational) reply klyrs 14 hours agorootparentprev> Other than \"nice day, eh?\" Unless there's a cloud in the sky. Wouldn't wanna lie to an officer... reply IncreasePosts 12 hours agorootparentprevSo the last time I talked to a cop was last week, when one knocked on my door. My neighbor's car was stolen overnight, and the officer wanted to know if my security camera was recording and if anything was captured during a certain time frame. Are you telling me that I should have shut the door in his face, and called my lawyer? reply bdcravens 15 hours agorootparentprevYou can also drive without a seat belt several times and likely be ok. It only takes one time to be proven wrong, however, and by then, it may be too late to learn the lesson. reply paxys 15 hours agorootparentprevIt is always fine until it isn’t. reply IncreasePosts 12 hours agorootparentBy this logic - Never interact with strangers. It is always fine, until it isn't. I can't believe you would do something so dangerous as to post a message on a message board. reply pixl97 12 hours agorootparentI mean, most tigers aren't going to eat you, so it's pretty safe being in a cage with one. Both getting in a tigers cage and interacting with the police are things that you have many choices in moderating and making the event safer. reply cupcakecommons 14 hours agoprevDespite my knee-jerk reaction to assume any policy changes coming out of Seattle are self-destructive; this seems very reasonable especially if there's precedent in other countries [1]. [1] https://law.stackexchange.com/questions/84483/is-it-generall... reply bobthepanda 13 hours agoparentI would imagine that this is supposed to protect against cases like this. https://www.kiro7.com/news/trending/seattle-police-officer-d... > SEATTLE — A Seattle police officer who unnecessarily used a ruse to locate a hit-and-run suspect in May 2018 has been suspended for six days after a watchdog agency found that the lie caused the man to take his own life. > The unnamed officer sent word to the man through a friend -- the complainant in the case -- that a woman injured in the crash was in critical condition and might not survive her injuries. > In reality, the crash was a minor fender bender and no one was injured, according to the Office of Police Accountability, an independent investigative office within the Seattle Police Department. Andrew Myerberg, the civilian director of the watchdog, authored the November report on the findings. > The driver, who friends said “was despondent about the fact that he may have killed someone,” died by suicide less than a week later. > “Notably, the night before he took his own life, he directly told his roommate that the incident was causing him to feel suicidal feelings,” the OPA report stated. Seattle PD is also notoriously not well behaved even by police standards. reply cupcakecommons 13 hours agorootparentGotta be careful negligently and irresponsibly toying with peoples lives in a city that gets so few sunshine hours. Six days of suspension is laughable. reply bobthepanda 13 hours agorootparentI mean if you think that's bad, no one has been suspended or prosecuted for this: https://www.nbcnews.com/news/us-news/seattle-police-body-cam... > Seattle police union rank-and-file leaders are under investigation after an officer was recorded on his body camera appearing to make light of the death of a woman who was killed by another officer this year, saying that she “had limited value.” > Auderer left his body camera on after responding to the South Lake Union neighborhood, where a marked patrol vehicle driven by another officer struck and killed Jaahnavi Kandula on Jan. 23. That officer had been responding to a “priority one call,” police said a day after the incident, when he hit Kandula, 23, who had been in a crosswalk. > In the brief clip, Auderer, who is vice president of the Seattle Police Officers Guild, is driving and can be heard discussing details of the incident in a call with the guild’s president, Mike Solan. > Auderer said that the officer whose vehicle struck Kandula had been “going 50” and that “that’s not out of control.” According to a police investigation report that was referred to prosecutors for review last month, the officer had been driving at 74 mph and Kandula was thrown more than 100 feet. > “That’s not reckless for a trained driver,” Auderer also said in the video, adding that he doesn’t believe “she was thrown 40 feet either.” > “But she is dead,” he said. He later laughs and says, “No, it’s a regular person.” Only Auderer’s statements are audible in the video. > \"Yeah, just write a check,\" he also said and laughed again. “Eleven thousand dollars. She was 26 anyway,” Auderer said, misstating Kandula’s age. “She had limited value.” reply cupcakecommons 11 hours agorootparentCould this be a natural result of the cultural shift away from viewing police work being honorable and decent like it was after 9/11? Seems like recent events could have applied selection pressure to make only those who could care less about honor or decency willing to stay in the profession. Sad all around. If a civil servant talks this way about a 23 year old grad student being killed in a fashion that would put an average citizen immediately under the jail, it's probably wood chipper time for them. What a disgrace. reply bobthepanda 10 hours agorootparentSeattle PD has been under a federal consent decree since 2012 due to bad behavior, so this long precedes any of the recent \"anti-police\" hullabaloo. https://seattlepolicemonitor.org/overview reply cupcakecommons 10 hours agorootparent2012 is far past the pro police glory days that I think started to end firmly around 2008 with Occupy Wallstreet and Occupy Seattle but I get your general point reply Lord-Jobo 15 hours agoprevGood. These kinds of measures are necessary for the restoration of the balance of power in the justice system between prosecution and defense. it should (at the very minimum) be 50-50 every time, then hinge on the facts/evidence to push either over the edge. thats the only way an adversarial system works. But we are very very very far from that at the moment, with a 98% plea bargain rate (https://www.npr.org/2023/02/22/1158356619/plea-bargains-crim...). This bypasses nearly every single baked in advantage that the defense has, with most existing at the trial stages. Lots of ways to balance those scales, this is a good measure in my opinion. What we have at the moment its a system backsliding towards something that looks similar to post-soviet law like the current Russian system. Its not a good look, even if we probably still have a legal system in the top 10 least fucked. reply ceejayoz 15 hours agoparentThe 98% plea bargain rate isn't quite as bad as it seems, though; prosecutors drop marginal (i.e. your 50/50) cases entirely so they can brag about their high conviction rates when it comes time for reelection. reply greedo 15 hours agorootparentDo they drop them or pile on charges in the hopes of a lesser plea? reply qingcharles 14 hours agorootparentThe latter. I can think of a very small handful of cases where the prosecution drop marginal cases. I've seen cases where there is zero evidence be taken all the way to the day of trial in order to try and get a plea. I see a great number of cases dropped on day of trial when the defendant won't plead out. Source: 11 years experience in the criminal justice system. reply Lord-Jobo 14 hours agorootparentprevIncredibly localized and subject to personal biases/ambitions for the prosecution. So sometimes you will see a huge majority of cases under certain categories dropped to boost their numbers (or because it makes sense, like the generally unlawful arrests during the George Floyd protests) and sometimes you will see an insane stacking of cases that will never win in order to boost other numbers and project a 'tough on crime' persona. See: Horrible Dickhead-Sheriff Joe Arpaio (sheriffs in many places have large overlap with prosecutors' duties) reply bitfilped 14 hours agorootparentprevExcept that a lot of that statistic is driven by the fact that you will be hit with much harder sentencing if you choose to defend yourself in court rather than immediately agreeing to a plea deal and having the level lowered (for federal cases.) This is known as the \"trial penalty.\" reply rayiner 15 hours agoparentprev> defense. it should (at the very minimum) be 50-50 every time What’s the probability of any given indicted person actually being guilty? It’s way over 50%. reply qingcharles 14 hours agorootparentI can answer this with some authority. I just did 10 years in pretrial and looked through the cases of thousands of people in detail. I would say 95% of people who are indicted are guilty of something related to the indictment. Often not exactly what is in the indictment (overcharging is rife), but guilty of something. What we need to do is charge people more accurately. Overcharging is used to elicit guilty pleas on lesser charges. reply lumost 14 hours agorootparentBeing guilty of \"Something\" in the indictment is also a far cry from being guilty of the indictment. For instance, the difference between possession and distribution. reply qingcharles 14 hours agorootparentThis is one of the biggest ones. If you are caught with more than a certain amount (say 20 teeny tiny bags of crack) you are assumed to be distributing it even without any evidence of distribution. They say you would not have that much for personal use. reply smrq 13 hours agorootparentI was on a jury last month for a case with this exact scenario. Dude had a lot of weed and the prosecution tried to use the quantity as the sole proof that he was distributing. Searched his phone, nothing, asked the neighbors about suspicious comings and goings, nothing, et cetera. Then they had some detective expert witness come in and say that in his opinion, the guy was absolutely a dealer based on that alone. The jury decided pretty much immediately that the prosecution hadn't proved shit. But a different jury... who knows? reply qingcharles 12 hours agorootparentThis guy was a brave soul taking it to trial. Normally the jury believes expert cop witnesses. This is how they get the plea deals :( I know people who bulk buy large quantities of weed because they have to travel out of state to get it and they want to minimize the risks of being caught with it all in transit. reply jrflowers 14 hours agorootparentprevI like this reasoning. Everyone should be born in jail and then work to get out, not the other way around. reply plussed_reader 14 hours agorootparentYou should read up on Catholicism and the idea of original sin; I think it'll integrate well with your outlook. reply mminer237 14 hours agorootparentprevMost people never get indicted for a crime. Maybe the system should seek out the truth of what guilt can actually be proved instead of just trying to lower the conviction rate to 50% arbitrarily. reply elil17 14 hours agorootparentprevCurrently, the prosecution wins the majority of cases because they can get a plea bargain regardless of guilt. I agree with you that this is wrong. But, to me, the prosecution shouldn't take on cases where they don't have good evidence and they should drop cases if it becomes clear they are wrong. If prosecutors did this they'd still have a very high win rate. reply whatwhaaaaat 14 hours agorootparentWhat makes you think this isn’t happening? reply elil17 10 hours agorootparentWell I'm sure it depends on the prosecutor. But there are certainly cases where it's not happening, as evidenced by the topic of this thread. reply autoexec 9 hours agorootparentprevOur insane incarceration rate and the number of innocent people imprisoned? reply jaredklewis 14 hours agorootparentprevIf the indicted individuals are guilty, prosecutors should use the evidence they have of that guilt to convict. Why should we stack the deck in favor of prosecutors and police, by giving them extra privileges, like being able to intentionally lie to defendants? reply idle_zealot 14 hours agorootparentprevWhat is this assertion based on? reply Dylan16807 14 hours agorootparentThere is very little to suggest that the prosecutors are so massively incompetent as to only have a 50% hit rate. reply jrflowers 14 hours agorootparentExactly. There is nothing in the records that prosecutors keep and make available to the public to indicate that. It is trivial to verify this by looking through the meticulous and publicly searchable database of dropped charges and arrest voidings. reply gs17 15 hours agoparentprev>thats the only way an adversarial system works Really, it shouldn't be an adversarial system against the law-abiding citizenry. reply wolverine876 14 hours agorootparentThe concept IIUC is both sides have zealous advocacy - both sides leave no stone unturned, no argument unmade (generally speaking) - and through the court procedure, that's how a fair trial and the truth come out. How else do you propose doing it? A system - in sometimes highly distrusting, dangerous, and angry situations - that relies on good will seems unlikely to work. Advocacy accepts the adversarial nature of the issue. Countries do have different systems. France relies more on judges somehow, but I don't know if the accused gets an advocate. reply p_j_w 14 hours agorootparent>The concept IIUC is both sides have zealous advocacy - both sides leave no stone unturned, no argument unmade (generally speaking) - and through the court procedure, that's how a fair trial and the truth come out. It seems to me we land a long way from this idea. In reality what happens, especially for poor people, is the prosecution has, in relation to the defense, a virtually unlimited budget and leaves no stone unturned. The defense is often a public defender without the time or resources to turn many stones at all and is viewed by our population as sleazy because they simply try to do their jobs. reply wolverine876 9 hours agorootparentHow else do you propose doing it? reply thomastjeffery 12 hours agorootparentprevThat is precisely the point that you are replying to. reply lliamander 14 hours agorootparentprevExcept that at the point where there is a police interrogation, there is (or should be) probable cause to believe that the person in question is not a law-abiding citizen. While imperfect, adversarial systems are still our best means of establishing the truth. Whether it is Quality Assurance testing in the context of engineering, reproducibility in the context of scientific experiments, or trial courts in the context of law. reply jp191919 15 hours agoprevThis reminded me of this absolute gem, outstanding advice for anyone https://www.youtube.com/watch?v=d-7o9xYp7eE reply sgift 15 hours agoparentAnd the abridged version for those in a hurry: https://www.youtube.com/watch?v=RkN4duV4ia0 (The link by jp191919 is gold though, I'd recommend to watch it at least once if you can find the time) reply sethammons 14 hours agoparentprevthe first time I saw this, years ago, I went down a youtube rabbit hole for hours. TL;DR - the video is a lawyer and a cop both saying don't talk to police, even to be helpful, and they back it up. You should watch it. Your loved ones should watch it. Your friends shou",
    "originSummary": [
      "A proposed bill in Washington aims to ban police officers from lying during interrogations to address concerns of false confessions and promote ethical law enforcement practices.",
      "The bill's goal is to enhance accountability and bolster the integrity of the criminal justice system.",
      "If passed, this legislation could have significant implications for police interrogation tactics and the reliability of confessions."
    ],
    "commentSummary": [
      "The conversation delves into various aspects of police misconduct, including deception during interrogations and the challenges faced by public defenders.",
      "Concerns are raised regarding false confessions, coercion, and the lack of accountability for police officers.",
      "The importance of legal representation and the risks of engaging with the police without legal counsel are emphasized, with discussions also touching on issues of race and trust in law enforcement."
    ],
    "points": 280,
    "commentCount": 274,
    "retryCount": 0,
    "time": 1707156217
  },
  {
    "id": 39263664,
    "title": "What Have You Built with LLMs? - Exploring LLM Applications and Deployment",
    "originLink": "https://news.ycombinator.com/item?id=39263664",
    "originBody": "Curious what people have been building with LLMs.I worked on a chrome extension a few weeks ago that skips sponsorship sections in YouTube videos by reading through the transcript. Also was trying to experiment with an LLM to explain a function call chain across languages (in this case MakeFile, Python, Bash). I&#x27;ve tried running a few telegram bots that are PRE prompted to do certain things like help you with taxes.What are you building?What does the stack look like? How do you deploy it?",
    "commentLink": "https://news.ycombinator.com/item?id=39263664",
    "commentBody": "What have you built with LLMs?256 points by break_the_bank 16 hours agohidepastfavorite219 comments Curious what people have been building with LLMs. I worked on a chrome extension a few weeks ago that skips sponsorship sections in YouTube videos by reading through the transcript. Also was trying to experiment with an LLM to explain a function call chain across languages (in this case MakeFile, Python, Bash). I've tried running a few telegram bots that are PRE prompted to do certain things like help you with taxes. What are you building? What does the stack look like? How do you deploy it? duckkg5 15 hours agoI don't like selling. I wanted a way to practice cold calling in a realistic way. I set up a phone number you can call and talk to an AI that simulates sales calls. I ended up using it for more general purpose things because being able to have a hands-free phone call with an AI turned out to be pretty useful. It's offline now, but here's the code with all the stack and deployment info: https://github.com/kevingduck/ChatGPT-phone/ Edit: forgot to mention this was all running off a $35 raspberry pi. reply dsco 14 hours agoparentSo the AI tries to sell to you, or you try to sell to the AI? This sounds very intriguing but I can tell by your README that you're an engineer and not a sales guy - there are no distinct value propositions. But it sounds damn creative as a project. reply duckkg5 14 hours agorootparentThe AI answers the call and acts as a potential customer. They take on personas to simulate behaviors like difficult or reluctant customers. You then do your pitch, handle objections, etc. At the end you get a transcript that's 'graded' to show you where you could improve your sales approach. And you're right, I'm not a sales guy. This project is for people like me who want a risk-free place to learn the basics of sales so that when I do talk to an actual human, I won't panic and freeze up like I always do. reply cabinguy 14 hours agorootparentI absolutely love this idea. Most high-level sales people rely on role play partners but that requires a pretty a big commitment. This would make a great product, imo. Also (tip): Study, memorize and internalize a sales script for your product/service...along with the objection handlers and closing questions. Practice every single day. You'll gain massive confidence because you know exactly what you are going to say, every time. reply 3abiton 12 minutes agorootparentprevThis, for some reason, reminds me of Nathan Fielder rehearsal skits. reply tkgally 11 hours agorootparentprev> a risk-free place to learn That's turning out to be a valuable feature of LLMs in many areas. You can practice complex interactions with them without worrying about boring or annoying them. Even the most patient human teacher gets tired eventually. LLMs don't. reply anxman 3 hours agorootparentprevThis could be a product. AI sales training. reply spywaregorilla 10 hours agorootparentprevdo you have any reason to believe the phone calls are realistic? reply satvikpendem 12 hours agoparentprevNow you can turn this into an AI sales cold caller based on the data you could collect from how the AI reacts to your selling. That is to say, the entire system becomes a generative adversarial network. reply alentred 12 hours agoparentprevI like the idea very much! Using an LLM as a \"sparring partner\" for training in various areas. LLMs tend to hallucinate, so I find it harder to use them reliably in the context of decision making. Training however is a nice idea indeed: mistakes are not as critical, just as in real life any peer can make a mistake. reply SpaceL10n 12 hours agoparentprevLike exposure therapy for people afraid of sales. Very nice idea. reply cushpush 11 hours agorootparentnice term this, exposure therapy\" reply duckkg5 12 hours agorootparentprevYes exactly! reply craigdalton 4 hours agoparentprevWould you be willing provide a live demo (via web interface) - as a preludebto providing a similar training bot as a consultant? reply jtolster 13 hours agoparentprevAre you finding response time to be an issue? I can imagine some very long pauses might kill the flow of conversation. reply duckkg5 12 hours agorootparentIt's not perfect, but it's tolerable, and not unlike some real-world calls where there's a slight delay. There are some \"Hmm ...\" and \"well ...\" scripted in as well to make it feels natural if there is a long response. reply splatzone 12 hours agorootparentI love the scripted filler words, that’s smart reply elicash 13 hours agorootparentprevTo that point, I would love to hear an audio file of it in action since I see from GitHub the phone number is down. reply qup 15 hours agoparentprevThat's cool. Thanks for sharing the source. What else has it been good at for you? reply duckkg5 14 hours agorootparentThe cold call sales part can be replaced to suit any need. I had another version that was just a generic AI (no sales stuff). I found myself on walks frequently ringing up the chatbot (\"Hey siri, call ChatGPT\") and just asking it whatever is on my mind. \"Tell me about Ghengis Khan\" or \"where's a good place to catch trout in north Georgia\" or \"how do I make baked ziti\". Makes the walks go by super quickly. reply DrNosferatu 10 hours agoparentprevNow do it for dating practice - great for nerds ;) reply xtracto 9 hours agoprevI helped \"writing\" a cookbook from my grandmother's recipes. For her 100th birthday, my dad rescued more than 250+ pages of recipes that my Grandma had collected over the years. Some were written in typing machine, others written by hand by her. So, my dad scanned (pictured) all the typed recipes, and \"dictated\" all the handwritten. For the dictated recipes, I told him to dictate just \"flat\" the words and numbers. So that I had paragraphs of recipes. For the scanned recipes, I used Google OCR (I found out it was the best one quality wise). For both sets of recipes, I then used GPT4 to \"format\" the unformatted recipes into well formatted Markdown. It successfully fixed typos and bad OCR from Google. We then pasted all that well formatted text into a big Google Docs, and added images. Using OpenAI image generation I generated images for each of the 250+ recipes. For some of them I had to manually curate it, given that some of the recipes are for typical Mexican food: For example there's a (delicious) recipe called \"PibiPollo\" that for the unitiated it may look like a stew, so I had to tell something like \"large corn tamale with thick hard crust\". In the end, the book was pretty nice! We distributed digital copies within the family and everybody was amazed :) . I loved spending time doing that. reply syntaxing 5 hours agoparentThis is absolutely awesome. I really want to do the same for my mom’s recipe before it’s too late. Though I wonder what would have happened if you went for GPT-V or LLaVa and the like. I have a hunch you might have been able to skip over the OCR part and straight from picture to markdown? Would be awesome if you can try and compare! reply geor9e 9 hours agoprevMy \"stack\" is just Apple Shortcuts making HTTP POST API calls to OpenAI, which does stuff in MacOS via BetterTouchTool. I trigger each by hotkey or typing a few letter into Spotlight (with Alfred). One transcribes and summarizes whatever youtube URL is highlighted. One does grammar and style correction of whatever is highlighted (and replaces it). One simply replaces the Dictate key with OpenAI Whisper but otherwise works exactly the same as voice typing. It's just way more accurate. One replaces the magnifying glass key to have a voice conversation with ChatGPT (using Microsoft voice synthesis). The built in prompt keeps it's answers short and conversational. It's like asking Siri something, but much better. One simply reduces the highlighted text by ~50% by rewriting it shorter, for when I have typed too much. One gives the key points of whatever article is in the foreground tab, so I know what I'm about to read. One outputs purely code, for example I use my voice to say \"javascript alert saying blah\" and alert(\"blah\"); will appear at my cursor. Of course, it's usually more complex boilerplate stuff, but it helps speed up my coding. Every time I find myself using an LLM repeatedly for something, I make it into a little Apple Shortcut to streamline it into my workflow, as if it were a built in MacOS feature. reply tomcam 8 hours agoparentYou beast! They all sound awesome! reply abeisgreat 12 hours agoprevI've done a handful of fun hardware + LLM projects... * I built a real life Pokedex to recognize Pokemon [video] https://www.youtube.com/watch?v=wVcerPofkE0 * I used ChatGPT to filter nice comments and print them in my office [video] https://www.youtube.com/watch?v=AonMzGUN9gQ * I built a general purpose chat assistant into an old intercom [video] https://www.youtube.com/watch?v=-zDdpeTdv84 Again, nothing terribly useful, but all fun. reply 63 11 hours agoparentOh hey I just watched that pokedex video. It was so impressive! Deserves way more attention reply jonnycoder 15 hours agoprevI built an Interactive Resume AI chatbot where anyone can ask questions about my experience and skills: https://www.jon-olson.com/resume_ai/ The backend is a Python FastAPI that uses ChromaDB to store my resume and Q&A pairs, OpenAI, and Airtable to log requests and responses. The UI is Sveltekit. I'm currently building a different tool and will apply some learnings to my Interactive Resume AI. Instead of Airtable, I am going to use LangSmith for observability. I started writing and my Substack articles are also linked to via my website. I'm currently working on applying sentence window retrieval and that article will be out shortly. This is part of a #buildinpublic effort to help build my brand as well. I've been unemployed since Sept as a Senior Software Engineer. The market is tough so I'm focusing on the above to help get employment or a contract. reply wayfareryouth 3 hours agoparentI’m sorry it’s been tough. The job market for seniors and leads is still quite strong in Australia if you can move here reply bluecoconut 15 hours agoprevWe've made a lot of data tooling things based on LLMs, and are in the process of rebranding and launching our main product. 1. sketch (in notebook, ai for pandas) https://github.com/approximatelabs/sketch 2. datadm (open source, \"chat with data\", with support for the open source LLMs (https://github.com/approximatelabs/datadm) 3. Our main product: julyp. https://julyp.com/ (currently under very active rebrand and cleanup) -- but a \"chat with data\" style app, with a lot of specialized features. I'm also streaming me using it (and sometimes building it) every weekday on twitch to solve misc data problems (https://www.twitch.tv/bluecoconut) For your next question, about the stack and deploy: We're using all sorts of different stacks and tooling. We made our own tooling at one point (https://github.com/approximatelabs/lambdaprompt/), but have more recently switched to just using the raw requests ourselves and writing out the logic ourselves in the product. For our main product, the code just lives in our next app, and deploys on vercel. reply jefc1111 13 hours agoparentHaving a play with datadm. It's really good and intuitive to use - good job! I'm getting errors now, but was having a lot of fun before. reply lefstathiou 14 hours agoparentprevThis is cool. Thank you for sharing. reply pashariger 14 hours agoprevI built an AI Hiring Assistant that performs an initial screening, collects candidate information, answers questions about the role, and also asks a several behavioral interview questions: https://hiring.gracekelly.dev/ Built entirely on Vercel & OpenAI. Took about a day, hardest part was configuring Sign In With Google. Had several dozen candidates use it, saved a lot of time and helped prioritize conversations. I just did a brief writeup about it yesterday: https://www.linkedin.com/pulse/i-built-ai-hiringscreening-as... reply have_faith 11 hours agoparent> A few people emailed their resumes directly rather than using the chat How did they fare compared to candidates that went through the chat process? reply pashariger 8 hours agorootparentSmall dataset for those that emailed, n=~3, but none of them were standout resumes. Best few candidates actually went through chat and also followed up via email with additional information a few days later. reply hazard 14 hours agoprevA Twitter filter to take back control of your social media feed from recommendation engines. Put in natural language instructions like \"Only show tweets about machine learning, artificial intelligence, and large language models. Hide everything else\" and it will filter out all the tweets that you tell it to. Runs on a local LLM, because even using GPT3 costs would have added up quickly. Currently requires CUDA and uses a 10.7B model but if anyone wants to try a smaller one and report results let me know on github and I can give some help. https://github.com/thomasj02/AiFilter reply eurekin 13 hours agoparentThat could actually be a universal ad-whacker for similarily stubborn sites (reddit) reply beginning_end 13 hours agorootparentI've been thinking the same thing. It'll be interesting to see if we end up with prompt-injecting ads reply jerpint 7 hours agoparentprevI didn’t know you could interact with pages like that so easily with Chrome extensions reply cl42 8 hours agoprevLLM agents to forecast geopolitical and economic events. - Site: https://emergingtrajectories.com/ - GitHub repo: https://github.com/wgryc/emerging-trajectories I've helped a number of companies build various sorts of LLM-powered apps (chatbots mainly) and found it interesting but not incredibly inspiring. The above is my attempt to build something no one else is working on. It's been a lot of fun. Not sure if it'll be a \"thing\" ever, but I enjoy it. reply btbuildem 7 hours agoparentFascinating. I've done this on a tiny, micro scale -- giving the GPT scenarios (eg, conversations, situations) and asking how it would play out. In early 2023 it seemed to work really well, now that they've nerfed it so much, it's a bit too generic and proper. reply cl42 7 hours agorootparentHave you tried GPT-4 with the update from the past few days? (When Sam mentioned it should be less lazy.) I notice it’s gotten much better and more willing to make forecasts since then. reply btbuildem 7 hours agorootparentNo but I'll check it out. Thanks! reply cedws 7 hours agoparentprevVery interesting, have you attempted to backtest to see if the LLM forecasts are accurate? reply cl42 7 hours agorootparentThanks for asking! Not yet as I’ve been focusing on building agents that can properly and regularly log predictions. Ideally, I’d like the agents to then participate in prediction markets or “superforecasting” groups to use actual human predictions as baselines. reply andher 15 hours agoprevI've built several things! These include bots for code generation that you can tag onto issues, q&a on text etc. The thing I'm working on now is AI mock interviewing. It's basically scratching my own itch, since I hate leetcode prep, and have found I can learn better through interaction. To paste a blurb from an earlier comment of mine: I'm building https://comp.lol. It's AI powered mock coding interviews, FAANG style. Looking for alpha testers when I release, sign up if you wanna try it out or just wanna try some mock coding. If its slow to load, sorry, everything runs on free tiers right now. I really dislike doing leetcode prep, and I can't intuitively understand the solutions by just reading them. I've found the best way for me to learn is to seriously try the problem (timed, interview like conditions), and be able to 'discuss' with the interviewer without just jumping to reading the solution. Been using and building this as an experiment to try prepping in a manner I like. It's not a replacement for real mock interviews - I think those are still the best, but they're expensive and time consuming. I'm hoping to get 80% of the benefit in an easier package. I just put a waitlist in case anyone wants to try it out and give me feedback when I get it out Gonna apologize in advance about the copywriting. Was more messing around for my own amusement, will probably change later reply jonnycoder 14 hours agoparentVery cool, I signed up. I agree that practicing a coding interview is better under pressure. It's a much difference skill to solve a coding problem both under time pressure and pressure to speak your thoughts to entertain the interviewer. Only practice can help improve that skill. reply andher 12 hours agorootparentYeah, I agree, the scenario is totally different in an actual pressure situation, I've fumbled so many easy questions. I don't necessarily like leetcode style questions as the standard for the industry for interviewing, but its still a reality and, from what I'm noticing, becoming more difficult in terms of expectations. Thanks for signing up, will send out an email once its ready to take for a spin! reply jamesponddotco 13 hours agoprevI built a couple of things, but the most useful is probably allalt[1], which describe images and generate alt tags for visually impaired users using GPT-4V. Next I want to add the option to use local LLMs using ollama[2], but I'm still trying to decide the UX for that. There's also Moss[3], a GPT that acts as a senior, inquisitive, and clever Go pair programmer. I use it almost daily to help me code and it has been an huge help productivity-wise. [1] https://git.sr.ht/~jamesponddotco/allalt [2] https://ollama.ai/ [3] https://git.sr.ht/~jamesponddotco/moss reply mnky9800n 1 hour agoprevI built a summarizer for drilling reports. Anytime you drill boreholes, whether it's on a drilling platform in the ocean or the middle of the desert or wherever, there's a geologist watching what comes out and writing notes about it. They likely do this multiple times both in the field and a laboratory setting. These notes are paired with logging software which also asks the geologist more quantitative questions sometimes (e.g., on a scale 1 to 5 how many fractures are there). Typically these are written for at least every meter of extracted core/rock/etc. typically you are drilling hundreds or thousands of meters, or more. So you end up with a highly unstructured data set that occasionally someone glances through to find tidbits. Using chatgpt we converted this data into keywords that could then be used to look at depth dependencies of various geological or petrological features of the region. reply nip 15 hours agoprevA “YouTube video subtitles generator” script for Estonian content. Powered by whisper-timestamped [1] using a model trained by the local tech university TTÜ [2] And it just… works! (with some tweaks and corrections) [1] https://github.com/linto-ai/whisper-timestamped [2] https://huggingface.co/TalTechNLP/whisper-large-et reply lalaithion 15 hours agoprevI wrote a script that takes in my credit card statement line by line and categorized the transactions into a custom set of categories that I cared about as well as generating a human readable description of the transaction. reply ishtanbul 12 hours agoparentTell me more, that is interesting. Even my bank (a big one) is unable to categorize the transactions correctly. reply jamifsud 13 hours agoprevI'm building https://www.brief.news, an AI powered newsletter that condenses tens of thousands of news articles into a daily briefing of the top stories, we support 30 topics today and are adding the ability to add your own! Stack is a combination of TypeScript (Next / Node) + Python with a pretty simple deployment setup right now (GHA -> Container -> Cloud Run). reply jtolster 13 hours agoparentThis looks awesome - might I suggest splitting the headlines on the homepage into a punchy title and subtitle? The wordiness of them makes it difficult for me to parse them for the topic quickly reply riku_iki 11 hours agoparentprevHow much money you need to spend per day on OpenAI api? reply adventured 11 hours agoparentprevThis is fairly well done, good job! The layout is clean, and it's fast. The summaries are solid as well. reply trvhig 6 hours agoprevhttps://www.rivadata.com/ I have been hacking together a poor-man's crunchbase that's fueled by GPT. React / Python / Supabase. The most interesting piece thus far has been the success of the self-correcting loops through GPT. At each turn basically feeding the results back to another 3.5 prompt that is only about reviewing quality. I found that with these loops you can get solid results without having to use the more expensive GPT4 API. (Also loving all the projects in this thread) reply ringofchaos 2 hours agoprevI am working on a RAG based chatbot to answer the queries based on contents of my main website and blog which is fintech related . I would also in future try to make it generic so that it can crawl any website and store new contents in vector databases. Response to user query then can be returned by combining the vector search and llm reply joetann 10 hours agoprevI’ve always found podcast discovery to be lacking, so I’m building the ultimate solution to that. We’re processing the top podcasts in many genres every day (currently thousands of daily episodes) and running them through our pipeline. From this we’ve made a semantic search engine, for example: https://www.podengine.ai/podcasts/search?search_term=Should+... We’re soon going to improve and summarise the responses from the raw embeddings in a few ways. Would love some feedback on the experience. We have also opened up a keyword alerting feature to alert folks when they’ve been talked about in an episode. reply pseudosavant 10 hours agoparentI really like the idea of using embeddings in this way. I'm sure scaling out to get \"most\" of the podcasts is no joke. But some bigger podcasts like Smartless didn't seem to be in your database. Have you considered using embeddings to show similar podcasts? reply gardnr 12 hours agoprevI read the paper \"Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling\" that was published last week and started building a tool for people to collectively generate synthetic training data. The tool still needs a trust mechanism and a coherent incremental publishing strategy to be able to operate in a public fashion. Right now, running one node using my RTX 3060 it would take 1.2 years to do one split of the C4 dataset. https://arxiv.org/abs/2401.16380 https://www.emergentmind.com/papers/2401.16380 https://github.com/gardner/gsd reply yodi 1 hour agoprevI'm building a platform where product managers and engineers can build interaction automation with users using small model. The goal is to help people to build LLM for them without deep expertise in DS/ML, train and host the model in their infrastructure, where no data require to be submitted. Still on progress at https://www.chathip.com/ reply dmitrysergeyev 14 hours agoprevI was tired of the need to scroll through dozens of blogs and RSS feeds to learn about technologies and industry news, so I’ve built a service that helps you learn and stay updated about any topic by sending a single fully personalized weekly email digest, making relevant information come to you, instead of you chasing it (push vs pull): https://peekly.ai It’s basically an LLM-based RAG that works over the best blogs and websites covering any topic you provided during onboarding. reply meandave 12 hours agoparentI'm unable to submit my email/interests. This is in firefox with and without UBlock Origin. Errors: https://i.imgur.com/N28wnVY.png reply aspenmayer 9 hours agorootparentIronically, when trying to view your picture of errors, I myself get an error on Imgur itself: {\"data\":{\"error\":\"Imgur is temporarily over capacity. Please try again later.\"},\"success\":false,\"status\":403} reply dmitrysergeyev 11 hours agorootparentprevWow, thanks for letting me know! I've just fixed the problem thanks to your bug report. reply dvcrn 10 hours agoprevLots of small stuff like bots and scripts to automatically rename files that I use locally every single day Then things like: “Fix My Japanese” - uses LLM to correct Japanese grammar (built with Elixir LiveView): https://fixmyjapanese.com It has different “Senseis” that are effectively different LLMs, each with slightly different style. One is Claude, one is ChatGPT. Or a slack bot that summarizes long threads: https://github.com/dvcrn/slack-thread-summarizer reply tmm84 9 hours agoparentI use a local LLM too for my Japanese grammar and sentence improvements to make thme more native. Sadly, every time I tried the fix my japanese page it just says the text I inputted wasn't Japanese. Maybe next time it'll work for me. reply jrhizor 11 hours agoprevhttps://www.mealbymeal.com It's macro + calorie tracking over text message. You just text what you eat and it matches against a food database to estimate your food intake. It's basically an easier alternative to MyFitnessPal. My stack is OpenAI on Azure, Vercel, Convoy, FatSecret API, Postmark, NextJS. reply woadwarrior01 11 hours agoprevI built an iOS and macOS offline LLM app called Private LLM[1]. I don't have any visibility into what the users do with it, but from what I hear on the app's discord, people love to use it in their Apple Shortcuts workflows for text manipulation. I initially built it using llama.cpp for offline LLM inference, but soon discovered mlc-llm and moved to using it, because the latter is way faster and flexible. [1]: https://apps.apple.com/us/app/private-llm/id6448106860 reply fcmgr 15 hours agoprevI've created just-tell-me [1] that summarizes youtube videos with ChatGPT. It's built with Deno, uses TypeScript and is deployed with Deno Deploy. It's open source, you can run it from CLI as well [2] [1] https://just-tell-me.deno.dev/ [2] https://github.com/franekmagiera/just-tell-me reply throwaway2203 12 hours agoparentThis is great! I ignore so many videos from friends and family because I suck at watching videos! reply fragmede 15 hours agoparentprevThis is really neat! reply abrichr 7 hours agoprevAt https://openadapt.ai/ we are using LLMs to automate repetitive tasks in GUI interfaces. Think robotic process automation, but via learning from demonstration rather than no-code scripting. The stack is mostly python running locally, and calling the OpenAI API (although we have plans to support offline models). For better visual understanding, we use a custom fork of Set-of-Mark prompting (https://github.com/microsoft/SoM) deployed to EC2 (see https://github.com/OpenAdaptAI/SoM/pull/3). reply rwxd 1 hour agoprevI built a blog with stupid & overengineered technical solutions. Also has an audio interview for every blog post. https://shitops.de/posts/ reply cmgriffing 13 hours agoprevI just built a tool that uses Whisper.cpp compiled to WASM in conjunction with SQLite WASM for a fully client-side book writing tool. Basically, I want to write a book without having to type out the whole thing. I got the dictation idea from an episode of Columbo. It is very much a work in progress and a proof of concept for another writing tool I want to make. https://orderly.cmgriffing.com/ https://github.com/cmgriffing/orderly reply coderKen 2 hours agoparentThis is awesome! What is the performance like? particularly around WASM compiled Whisper. reply Ldorigo 2 hours agoprevI got fed up sending cover letters so I made a tool that writes them for me. Scrapes the company website and summarizes it to get relevant background info, takes my resume + arbitrary info I provide as input, and the job posting (can also work without for unsolicited applications). I then fine-tuned a GPT3 model on actual cover letters I had written to make it sound like me, and voilà ! Actually landed me a job. reply binsquare 12 hours agoprevLLMs have been game changing productivity-wise for me But I found that LLMs are often wrong and hallucinates, so I have to double check with google or other resources. So I built a google and chatgpt alternative to answer any question and hallucinations are more obvious. I do this by using by multiple LLM's including search enabled ones i.e. GPT4, Gemini, Claude, Perplexity, Mistral, and Llama. It's been growing healthily https://labophase.com reply czzarr 11 hours agoprevWe built https://gptforwork.com a set of add-ons for Excel, Word, Google Sheets and Docs that brings custom GPT functions in Excel and Sheets, to prompt directly from cells, a chat in Word to interact with documents, and a simple prompt box in Docs We offer OpenAI and Azure providers (as well as Anthropic on Sheets) reply ianbicking 15 hours agoprevI've made a couple games, though I am still having a hard time finding the soul of the game in the LLM and haven't released them; there's a historical roleplay game (that I plan to release soon), a storytelling game (the player tells stories to the LLM), a wander-a-world-aimlessly-and-chat game, and I never get further than 50% through the way of murder mystery games, though murder mysteries seem like an excellent structure. I've built some abstract content development tools, generally focused on building larger content somewhat top-down (defining vibes, then details). I'm working on a general project helper using the GPT-Vision, voice, and regular GPT. You setup the camera above your workspace, work on paper, and chat with the LLM while you do it. I think there's a lot of potential, but the voice stuff is quite hard to deal with... there's just a ton of stuff happening in parallel, and I find it very hard to code something reliable. The stack I use is all in the browser, generally Next.js, Preact Signals, and my own code to call into GPT, Whisper, etc. I like having everything available for inspection, and I generally keep all the working bits visible somewhere. (This can be overwhelming when other people see it.) But I haven't gotten over the deployment hump... the cost and complexity is a challenge. I've used Openrouter.ai recently in a project, and I think if I leaned on that more completely I'd find the release process easier. reply iAkashPaul 15 hours agoprevSummarisation for calls, emails. Lots of extraction tasks & closed domain chatbots. Deployment is usually FastAPI for business logic, Langchain or MS/Guidance library, LLM hosted via. HF-TGI server reply notzane 12 hours agoprevhttps://www.askaway.bot/ AI concierge for my parents’ vacation rental. Mostly just pulling info from the guest binder, but I’ve also started using some local guides to give better suggestions. Built with NextJs and deployed on Vercel (was really easy and they have a generous free tier). reply kebsup 14 hours agoprevI'm building a spaced-repetition flashcards language learning app, that generates sentences and explanations for a given word. Unfortunately only for German, but I plan on expanding the languages soon. https://vokabeln.io Tech stack: - The app is in Flutter. - Backend I'm nodejs TS. - GPT4 for generation of sentences and explanations - GCP text-to-speech for audio reply zffr 14 hours agoparentNice! I'm building something similar for French reply nmfisher 8 hours agoprev1) https://imaginanki.com - auto generating flashcards (Anki decks) for language learning with accompanying images and speech audio. Flutter web (JS) with backend on Cloudflare Pages Functions, connected to SDXL, Azure TTS and Claude. 2) https://amiki.app - practise speaking French, Spanish, German or Italian with a 3D partner. Flutter web with Whisper and my own rendering package. reply ZeidJ 7 hours agoprevWe built a social media platform for chatbots... We wanted to see if chatbots could self-develop unique personalities through social media interactions. The results were actually hilarious... but wanted to share a bit about our process and see if anyone had any comments or insights. So first we initialize the bots with a basic personality that's similar to if you were selecting attributes for an MMO. Things like intelligence, toxicity, charisma and the like. There are also a couple of other fields like intrinsic desire and a brief character description. These are fed to the model as a system prompt with each inference. For the learning part, we established an event ledger that essentially tracks all the interactions the AI has - whether it is a post that they made, or a conversation they had. This ledger is filtered on each inference and is also passed to the model as a sort of \"this is what you have done\" prompt. Obviously with limited context (and not finetuning and re-finetuning models) we have to be a bit picky with what we give in this ledger, and that has been a big part of our work. Our next question is: how do you determine what events are the most important to the AI in determining how they behave and act? It's been interesting! The platform is anotherlife.ai for those curious! reply huydotnet 10 hours agoprevI built a diagram generator in PlantUML format: https://chatuml.com Also, hello HN! If you are interested, use this promo code for 50% off your first purchase ;) HELLOHACKERNEWS reply collaborative 12 hours agoprevA search engine that saves me time by detecting SEO spam, downranks results containing ads, and summarizes click bait descriptions away I made it available to the public aisearch.vip reply afiodorov 15 hours agoprevI have built a webapp for translating srt files: https://www.subsgpt.com GPT-4 excels as a translator, but it often encounters issues with content warnings and formatting errors when translating entire subtitle files via ChatGPT. The solution is straightforward: divide the subtitle file into sections, focusing solely on translating the text and disregarding the timestamps. While it's feasible to have ChatGPT maintain the correct format, I've observed a decline in translation quality when attempting this in a single pass. My preferred approach is a two-phase method: first, translate the text, and then, if necessary, request ChatGPT to adjust the formatting. The webapp splits the srt file into batches of 20 phrases and translates each batch. It also allows for manual correction of the final translation. Ah and it's also serverless: you input your OpenAI token & select the model of your choice and the webapp makes the requests to OpenAI directly. reply erikig 12 hours agoparentThis is great, how well does it do with informal/slang Portuguese, Russian or Spanish? reply iloveitaly 14 hours agoprevSome little projects I've been playing around with: - https://github.com/iloveitaly/sql-ai-prompt-generator generate a ChatGPT prompt with example data for a sqlite or postgres DB - https://github.com/iloveitaly/conventional-notes-summarizati... summarize notes (originally for summarizing raw user interview notes) - https://mikebian.co/using-chatgpt-to-convert-labcorp-pdfs-in... convert labcorp documents into a google sheet - https://github.com/iloveitaly/openbook scrape VC websites with AI reply callmeed 12 hours agoprevI'm building a weight-loss app that leverages LLM to do 2 things: 1. Analyze calories/macronutrients from a text description or photo 2. Provide onboarding/feedback/conversations like you'd get from a nutritionist https://www.fatgpt.ai/ My stack is Ruby on Rails, PostgreSQL, OpenAI APIs. I chose Rails because I'm very fast in it, but I've found the combination of Rails+Sidekiq+ActionCable is really nice for building conversational experiences on the web. If I stick with this, I'll probably need a native iOS app though. Vendor stack is: GitHub, Heroku (compute), Neon (DB), Loops.so (email), PostHog (analytics), Honeybadger (errors), and Linear. reply throwup238 12 hours agoparent> 1. Analyze calories/macronutrients from a text description or photo Step 1: Is it a hot dog or not hot dog? https://www.youtube.com/watch?v=ACmydtFDTGs I'm glad someone is keeping the dream alive! reply callmeed 12 hours agorootparentJokes aside, GPT-4 Vision is surprisingly good at noticing facts from food images. For example: - In my chipotle bowl, it can tell if I had brown rice vs white rice - In my In-n-out, it can tell if I got it protein style It struggles with accurate weights/volumes but I'm excited about where this is going. reply adrianmonk 11 hours agoparentprevfatGPT... the LLM that helps you be more model, less large. reply gremlinsinc 10 hours agorootparentour large language model is large so you don't have to be. reply mooreds 10 hours agoprevI build this with ChatGPT: http://salaryoverlap.s3-website.us-east-2.amazonaws.com/ reply bing_dai 11 hours agoprevProject 1 — Source code: https://github.com/bingdai/summaryfeeds. The code is for Summary Feeds (https://www.summaryfeeds.com). It shows summaries of AI-related YouTube Channels. **** Project 2 - I also built a YouTube summarizer for individual video called Summary Cat (https://www.summarycat.com). It is not open source for now. The stack is very similar to project 1. **** And yes I like summarizing YouTube videos:) reply eurekin 14 hours agoprev\"Widjosumarajzer\" = video summarizer It's just a hodgepodge of prototype scripts, but one that I actually used on a few occasions already. Most of the work is manual, but does seem easily run as \"fire and forget\" with maybe some ways to correct afterwards. First, I'm using the pyannote for speech recognition: it converts audio to text, while being able to discern speakers: SPEAKER_01, _02, etc. The diarization provides nice timestamps, with resolution down to parts of words, which I later use in the minimal UI to quickly skip around, when a text is selected. Next, I'm running a LLM prompt to identify speakers; so if SPEAKER_02 said to SPEAKER_05 \"Hey Greg\", it will identify SPEAKER_05 = Greg. I think it was my first time using the mistral 7b and I went \"wow\" out loud, once it got correct. After that, I fill in the holes manually in speaker names and move on to grouping a bunch of text - in order to summarize. That doesn't seem interesting at a glance, but removing the filler words, which there are a ton of in any presentation or meeting, is a huge help. I do it chunk by chunk. I'm leaning here for the best LLM available and often pick the dolphin finetune of mixtral. Last, I summarize those summarizations and slap that on the front of the google doc. I also insert some relevant screenshots in between chunks (might go with some ffmpeg automatic scene change detection in the future). aaand that's it. A doc, that is searchable easily. So, previously I had a bunch of 30 min. to 90 min. meeting recordings and any attempt at searching required a linear scan of files. Now, with a lot of additional prompt messaging I was able to: - create meeting notes, with especially worthwile \"what did I promise to send later\" points - this is huge: TALK with the transcript. I paste the whole transcript into the mistral 7b with 32k context and simply ask questions and follow-ups. No more watching or skimming an hour long video, just ask the transcript, if there was another round of lay-offs or if parking spaces rules changed. - draw a mermaid sequence diagram, of a request flowing across services. It wasn't perfect, but it got me super excited about future possibilities to create or update service documentation based on ad-hoc meetings. I guess everybody is actually trying to build the same, seems like a no-brainer based on current tool's capabilities. reply ravila4 13 hours agoparentVery interested in this. I have been contemplating building something similar, but am unaware of any existing services that do this. Haven't played with pyannote, how does it compare to whisper? Also thought it might be useful to be able to OCR screenshots and use the text to inform the summariation and transcription especially for things like code snippets and domain-specifc terms. reply eurekin 13 hours agorootparentI remember whisper v3 large blowing my mind: it was able to properly transcribe some two language monstrosity (przescreenować, which is a english word \"to screen a candidate\", but conjugated according to standard polish rules). Once I saw that I thought \"it's finally time: truly good transcription has finally arrived\". So I view whisper as sota with excellent accuracy. Now, for the type of transcription I need speaker discerning is much more valuable than accurate to the point translation: so it will be summarized anyway and that tends to gloss over some of errors anyway. That said, pyannote has also caught me off guard: it correctly annotated lazily spoken \"DP8\" with non native speaker accent. It looks really good reply hlfshell 13 hours agoprevI have two main projects that are public ATM with LLMs. The more notable one was experimenting with LLMs as high level task planners for robots (https://hlfshell.ai/posts/llm-task-planner/). The other is a golang based AI assistant, like everyone else is building. Worked over text, had some neat memory features. This was more of a \"first pass\" learning about LLM applications. (https://github.com/hlfshell/coppermind). I plan to revisit LLMs as context enriched planners for robot task planning soon. reply thebestmoshe 11 hours agoprevI’ve always wanted a tool to help me track my online orders. However, it wasn’t practical to make integrations with every merchant. Even scraping the order emails was way too much work to do for an unproven product. Now with LLMs it’s simple to extract structured data from emails. I built [Orderling](https://orderl.ing) that is basically a CRM for your orders. It uses OpenAI api to extract the order information and automatically adds it. reply devbytes 5 hours agoprevI am working on a part search engine for company maintenance teams. We built a search engine that searches parts in real time across a dozen or so vendors (Amazon, eBay, McMaster, etc). We then leverage Chat GPT to extract data from product titles. Part number is one of the key elements we extract. Since part numbers vary greatly across manufacturers, it's difficult to throw something like a regex at it. It has done a really good job so far for data extraction. reply ukuina 5 hours agoprevI built https://HackYourNews.com to summarize the top HN stories and their comments. reply tcpiplab 11 hours agoprevI used FlowWise[1], LM Studio[2], the llama2[3] model, and Ollama[4] (for embeddings) to create a local-only RAG chatbot so I could chat directly with Tristram Shandy, Gentleman[5]. For the context document I used the text of the novel of the same name, downloaded from Project Gutenberg. Primarily it was a PoC to see if a document based chatbot could work without crossing trust boundaries by calling out to untrusted APIs. It only makes calls to localhost. If you’re familiar with the novel you will be pleased to know that the chatbot ended a recent answer with, “I must go now as I have an appointment with my chamber pot and I wouldn’t want to keep it waiting.” [1]https://github.com/FlowiseAI/Flowise [2]https://lmstudio.ai/ [3]https://llama.meta.com/ [4]https://ollama.ai/ [5]https://www.gutenberg.org/ebooks/1079 Everything runs on a Mac Mini with the M2 Pro CPU/GPU and Mac OS Sonoma. reply personjerry 11 hours agoprevI built https://eternalsouls.ai/ for a client recently. You just export and upload a WhatsApp conversation and it will learn the personality AND voice of your conversation partner. You can send/receive text or voice messages; It was pretty damn spooky to actually have a voice conversation back and forth with an AI standing in for my \"friend\" reply smeej 11 hours agoparentI've seen this episode of Black Mirror. reply fekunde 9 hours agorootparentYeah, the pricing tiers make it all the more morbid and disconcerting. Scary future for sure. reply takinola 9 hours agoprevAs I was building LLM projects, I found I was re-implementing a new vector database for each one. So I built RagTag (https://ragtag.weaveapi.com), a vectordb/RAG as a service to make the process faster. This provides a CRUD interface to push and retrieve documents, which are automatically chunked and converted to embeddings. AgentX (https://theagentx.com), an LLM chat support app is one of the projects I built on this framework. It is a self-updating customer support agent that is trained on your support docs. Not only does this answer your customer questions, it provides summaries of the queries so you get a sense of where your product and/or documentation is deficient. reply scastiel 15 hours agoprevFor my expense sharing app [1], I added receipt scanning [2] in a few minutes and a few lines of code by using GPT 4 with Vision. I am aware that LLMs often are a solution looking for a problem, but there are some situations where a bit of magic is just great :) It is a Next.js application, calling OpenAI’s API using a plain API route. [1] https://spliit.app [2] https://spliit.app/blog/announcing-receipt-scanning-using-ai reply olegdater 8 hours agoprevA turing test disguised as a game: https://humanornot.so/ Heavily inspired by https://humanornot.ai/ (which was a limited time research by Ai21 Labs), now the project is on its own path to be more that just a test. My work is to make AI chats sound like real humans and it's shocking how good sometimes the AIs are . Even I as a creator, knowing everything (prompts, fine-tuning data, design, backend etc.), often can't tell if I'm speaking to human or designed by me AIs reply emporas 14 hours agoprevI am currently building an automatic book generator of Rust source code, in which the LLM will write the description of the code of a whole Rust project. It will be a bot, which will connect to the website, generate descriptions, download them, and create the book. It is very early in the project, 3 days in, but it's going well. https://github.com/pramatias/documentdf reply vmt-man 1 hour agoparentNice idea, but README is required. Also it can be generated by GPT :) reply emporas 1 hour agorootparentIt is generated in it's entirety by GPT. Well 98% is more like it. By the time it's ready, it will have a README. I will announce it on Reddit /r/rust if you are interested. Something i want to test, is how much documentation is needed, for the machine to infer the rest of it. Something like, one sentence of human documentation + code, how much can LLM infer and describe the code as accurately as possible. Does it need two sentences? 3? We'll see. reply computers3333 12 hours agoprevBuilt this little tool to summarize Hacker News articles using HuggingFace. https://gophersignal.com It doesn't do a ton, but it's kinda cool. Feel free to fix/add anything https://github.com/k-zehnder/gophersignal reply rgbrgb 15 hours agoprevI know chat is lame and overdone but here's my open source local AI chat app for macOS :). I wanted something simple enough for the non-technical people in my life who were using ChatGPT. For better or worse, those people are mostly not using chat AI much anymore. Seems like the initial awe wore off. https://github.com/psugihara/FreeChat I'm also working on a little text adventure game that I hope to release soon. reply jtolster 13 hours agoprevI'm currently working on an interface for google calendar @ https://calendarcompanion.io My next feature is integrating the functionality with telegram, it's hard to predict the value of these features in the moment - but I do think this could be an extremely interesting \"iPhone\" moment for technology. Just like how the iPhone reduced everything to a single button press, we can now squeeze the functionality of some pretty complicated apps into natural language through text - and as the response time of LLM's improves it will become a short conversation for things that used to dazzle new users! Exciting times! As for the stack, I have Supabase and Typescript on the frontend, python on the backend and k3's as a cluster for my apps (can recommend this if you want to get devops-y on a budget). Next time, I'll just go pure Typescript since python really doesn't add much working this far away from the base models. reply jtap 12 hours agoprevI built out a few utilities as experiments. One app linked to Salesforce to query/analyze sales data. Another that reads our help documentation and gives instructions via chat. The last app, the only one that was deployed anywhere, is https://catchingkillers.com This app is a simple murder mystery game where the witnesses and the killer are ChatGPT bots. The first two stories are complete and active, the third is not complete yet. The first story of the working two is taken from another murder mystery group game https://www.whodunitmysteries.com/sour.html. The second story was highly influenced by ChatGPT. It's a bit rough because I didn't spend too much time on it, but if anyone does signup to play, I'd love to hear feedback. reply benlm 13 hours agoprevWe built Jumprun. You can use it to research and analyze data sources, and it'll produce beautiful canvases with tables, charts, videos, maps, etc. We're working on automations so you can setup natural language trigger conditions that execute actions. We built it in Kotlin with Ktor server, htmx and tailwind. It uses a mixture of models, including gpt4-turbo, gpt4-vision and gemini-pro-vision. It's deployed using Kamal on bare metal. Example canvas that provides a roundup of Apple Vision Pro reviews: https://jumprun.ai/share/canvas/01HNXB2K3GM7KPRP45Y2CVVJSC Our learn more page with some screenshots to show creating a canvas: https://jumprun.ai/learn-more It's a free closed beta at the moment to control costs, but let me know if you'd like an invite. reply The5thElephant 12 hours agoparentCool! I like the \"intelligent canvas\" concept. Not exactly the same but my brother and I have been building a side project that also is all about making the most of a set of information using different views like maps, calendars, tables, etc. We have been looking into adding AI to make it easier to import data without having to manually tag all the data. https://visible.page reply renwoshin 12 hours agoprevWe've built https://agentgold.ai/chat, which is an interface to chat with youtube creators about their content. It looks through past transcripts, topics, view counts, and other metadata so users can quickly learn what a Youtuber is all about. reply jll29 12 hours agoprevA BERT-based summarization system for financial earnings calls. It can take a 60-minute transcripts of such meetings can compress the contents down into 5 bullet points. https://link.springer.com/chapter/10.1007/978-3-031-28238-6_... Financial earnings calls are important events in investment managements: CEOs and CFOs present the results of the recent quarter, and a few invited analysts ask them questions at the end in a Q&A block. Because this is very different prose from news, traditional summarization methods fail. So we pre-trained a transformer from scratch with a ton of high-quality (REUTERS only) finance news and then fine-tuned with a large (100k sentences) self-curated corpus of expert-created summaries. We also implemented a range of other systems for comparison. reply swalsh 6 hours agoparentOh funny, i've been working on a similar project, analyzing earning call transcripts using LLM's. My first attempt was with BERTopic. The results were awful. My second attempt was with a finetuned 7B version of Mistral, with heavy prompt engineering, the results were actually super good in my opinion... plus it runs on a single 3090. reply jlawrence6809 3 hours agoprevI built a platform for homeschooling families with structured courses that are taught and graded by an llm (chatgpt 4 API). Homeschoolmate.com reply instagary 11 hours agoprevWe're building a GPT for managing your finances. https://candle.fi/gpt Our backend stack: - AWS - SST - TypeScript Our clients: - Next (web) - Vanilla React Native (mobile) OpenAI's App Store announcement is what got us interested in building w/ LLMs. reply bomewish 1 hour agoparentWhy not show names and faces of the founders? Explain the backstory. Using your service requires users put absolutely enormous trust in you. But there is currently nothing on the site to engender that trust. I would work on that as a priority. reply reality_swim 10 hours agoparentprevlink seems broken to me. reply instagary 10 hours agorootparentWe've been deploying changes all day so could related, thanks for the report. Should work now. reply ishtanbul 12 hours agoprevrequest - i want an LLM tool that can process raw text or email and update or create salesforce records. Example 1: i get an email from a potential customer that says they want [product A]. I can forward that email (or call notes) to salesforce (or somewhere) and it will understand the preference and the relevant customer and update that customer's profile. Example 2: In a B2B context, lets say my customer is a company, and there is a news article about them. I could forward a link to the article to the LLM and it would understand that the article is about a customer, and append that article and key info about it to my saleforce record for that customer. The news item becomes an object that is linked to that customer (for call context, better sales targeting, profiling, etc). Can someone help me build that? reply scribu 11 hours agoparentI'm working on something like that. Feel free to email me (address in my bio). reply dmezzetti 14 hours agoprevtxtai (https://github.com/neuml/txtai), an embeddings database for semantic search, graph networks and RAG reply kingkhalid 9 hours agoprevI was frustrated with ChatGPT's inability to answer questions of popular-but-not-that-popular open-source projects. So I helped build a ChatGPT-like tool that can answer questions about any open-source project, and you can add your own (public) GitHub repositories to it. The tool is meant to be used by sales engineers, but can be used by anyone. Check it out here: https://app.commonbase.ai/ It has been a huge help for me when working with certain open-source libraries. reply izaidi 11 hours agoprevI was holding a free screening of a short film I made, and as an alternative to Eventbrite and the like, I built a simple SMS-based ticket reservation system that used GPT-4 to read and respond to messages. People interested in attending would text a number and their messages were routed by Twilio to my Node.js app, which in turn sent them to GPT to generate a response. The LLM was instructed to provide a structured JSON of each reservation once the person gave their name and the number of the seats they wanted. Worked very smoothly and only took an afternoon to build. Would've been infinitely more tedious if I had to worry about parsing messages with my own code. reply 35mm 13 hours agoprevA text to slide based online course video with images workflow. I’m working for an edTech company. Some students prefer video. So I built a Django app that takes a block of text and formats it into a set of slides, each with a title, some bullet points, an Dalle-3 generated image, and a voiceover. It then compiles that all into a video. reply ilaksh 11 hours agoprevI started working on a Rust based AI agent host with the goal of running locally. It has Rhai scripting built in which is what the agent function calling is based on. Very rough at the moment. Also on hold for me because I need to do more dirt cheap Upwork projects to scrape by this month. I think what will be really powerful is to have a registry for plugins and agents that can be easily installed in the system. Sort of like WordPress in that way. Also similar to an open source GPT store. https://github.com/runvnc/agenthost I believe the are several variations of this type of idea out there. reply waqas_x 4 hours agoprevUpload product photos, get detailed, seo optimized, product descriptions. https://producks.ai/ reply suyula 8 hours agoprevI built Joke-Understander bot, a Mastodon bot that responds to a joke setup before the punchline is revealed. It's not very popular but I think it's hilarious. https://botsin.space/@jokeunderstander It's just a bash script that calls ollama on my desktop PC every morning and schedules a handful of posts on the Mastodon server. reply a5huynh 13 hours agoprevI've been using a combo of LLMs + live transcription to build a passive assistant that keeps track of talking points and can pull out data/tasks from a conversation you're having (https://sightglass.ai or here's a demo of me using it: https://www.loom.com/share/0220ca03bce341669d314d4254872226) So far this is being used for: - Sales -> guiding new recruits during more complex client calls - HR -> Capturing respones during screening interviews If you'd like to try this out feel free to DM me or email me at andrew at sightglass.ai, we're looking for more testers! reply marianoguerra 14 hours agoprevAn Extensible Conversational UI for Interactive Components[1][2], current use case is a Personal Productivity Assistant for structured data. The stack is simple, preact in the fronted with a custom framework on top and bun on the backend calling OpenAI, I may port it to rust in the future. I plan to try local LLMs when I have some free time. For now each users runs the application locally with their own keys[3]. [1] https://www.youtube.com/watch?v=nS1wsif3y94 [2] https://www.youtube.com/watch?v=f-txlMDLfng [3] Alpha software, check the readme: https://gloodata.com/download/ reply jason_zig 13 hours agoprevI run a survey platform[0] and I use an LLM to generate insights from open-ended response data. Using it for open-ended response classification as well. [0]https://www.zigpoll.com reply chown 11 hours agoprevI am working on an app to make it even easier to run Local LLMs and support for multiple chats, RAG, and STT. I did it mostly for learning about different tasks that’s possible using local LLMs and specifically for my wife who was working overwhelmed with those things (and for some reason was overwhelmed setting up Ollama. Tech stack is Electron + NuxtJS, currently only for Mac but I have already started tinkering with Windows support. https://msty.app reply computerex 15 hours agoprevI am building a no code solution. Use case is simple: Write complete programs/software for the browser from natural language input. https://domsy.io Currently running on my little digital ocean droplet. Stack is javascript/python. reply stuartriffle 12 hours agoprevI've been learning about RAG using LlamaIndex, and wrote a small CLI tool to ingest folders of my documents and run RAG queries through a gauntlet of models (CodeLlama 70b, Phind, Mixtral, Gemini, GPT-4, etc etc) as a batch proccess, then consolidate the responses. It is mostly boilerplate but comparing the available models is fun, and the RAG part kind-of works. https://github.com/StuartRiffle/ragtag-tiger reply joshelgar 12 hours agoprev1. An infinite crafting game: https://foodformer.com 2. An embeddings-based job search engine: https://searchflora.com 3. I used LLMs to caption a training set of 1 million Minecraft skins, then finetuned Stable Diffusion to generate minecraft skins from a prompt: https://multi.skin reply pseudosavant 10 hours agoparentI love the skin generator reply pavlov 15 hours agoprevAn automatic video editor. It should be cheap enough to deploy that it can be applied to relatively low-value content like video meeting recordings, so it can’t spend a lot of expensive GPU time analyzing video frames. It also needs to be easily customizable for various content verticals and visual styling like branding and graphics overlays. And everything is meant to be open sourced, so that’s fun! I wrote about it on my employer’s blog here: https://www.daily.co/blog/automatic-short-form-video-highlig... reply youngNed 14 hours agoprevOoooh, not something i have built, I do want to but suspect someone else has done it better than i could. A tool to RAG a github repo, so i can ask questions of how a certain library or tool works? Even better if it pulls in issues reply jonnycoder 14 hours agoparentThis is very easy to do and a great idea! Langchain and Llama Index both have classes to read a directory, if you git clone, and perform a RAG. If you want it to scrape a github URL, there is a module for that too! This starter tutorial will do RAG on a directory of files: https://docs.llamaindex.ai/en/latest/getting_started/starter... reply franzb 12 hours agoprevI built an app to make dealing with Jira less painful. It caches Jira tickets in a SQLite database, then uses GPT-3.5 to translate natural language queries into SQL that it then executes. It also uses Ollama/Mixtral to summarize Jira tickets and GitHub PRs. It can generate a summary of a single Jira ticket with its associated GitHub PRs or a whole sprint. It's written in Python and runs in the terminal. reply neom 15 hours agoprevI use sponsor block and it's really good, I like that it's community-driven but sometimes it's not available for videos so your solution sounds great. I consult to a law firm as their founder-in-residence. For fun, I trained Llama 2 on all the non-client data of the firm so that people could ask it questions like \"Who are the lawyers in Montreal who litigate American securities laws, what are their email addresses and what time is it where they are?\" It's a njs app running on linode. It's extremely simple, but people seem to find it useful. reply mfalcon 13 hours agoprevI'm making two LLM's negotiate the exchange of a product, price is the main issue but I'm trying to make them negotiate another issues too in order to avoid the \"bargaining\" case. I've tried several models and gpt4 is currently the one that better performs, but OS LLM's like Mixtral and Mixtral-Nous are quite capable too. https://github.com/mfalcon/negotia reply jordanf 15 hours agoprevI wrote gait, an LLM-powered CLI that sits on top of git and translates natural language commands into git commands. It's open-source: https://github.com/jordanful/gait I also wrote PromptPrompt, which is a free and extremely light-weight prompt management system that hosts + serves prompts on CDNs for rapid retrieval (plus version history): https://promptprompt.io reply dsco 14 hours agoprevI created a Chrome extension which shows cryptocurrency prices & insights when you hover cash tags on Twitter. I'm a product manager with solid CS understanding, but haven't had the time to learn React or glue frontend stuff together - so about 80% of the code is generated by GPT4. I've mainly architected the code and deployed on Vercel. I feel like AI + Vercel has given me that final push to actually deploy products instead of just building stuff and leave it lying around. reply smudge-ai 16 hours agoprevAlso a Chrome extension [0]! The concept is to use the browser's context menu to run commands on the LLM, so it stays out of your way most of the time but feels like a somewhat native experience. The stack is: 1. TypeScript/Node/tRPC/Postgres/Redis/OpenAI on the backend 2. SolidJS/Crxjs/tRPC on the front end 3. Astro for the docs/marketing site And deployment is currently through render.com for the databases and servers, and manually via a zip file to the Chrome webstore for the extension itself. [0] https://smudge.ai reply smusamashah 14 hours agoparentOpen source alternative that does the same but in vanilla JS and completely in user's control https://github.com/SMUsamaShah/LookupChatGPT reply Prosammer 15 hours agoprevI am building textool [1] an app that lets you create endpoints using GPT4. The idea is to make it so you can create \"actions\" for GPT4 assistants easily. - Nextjs - Deno Deploy for hosting the apis - Supabase - postgres / auth - Shadcn I want to use the t3 app stack [2] for v2. It's really MVP, but I want to see if anyone is interested at all before I work on v2: creating gpts that come with databases! [1] https://textool.dev [2] https://create.t3.gg/ reply TrickardRixx 15 hours agoparentIMO the Grimoire GPT's success is proof that there is a market for something like this. reply Prosammer 15 hours agorootparentThanks for saying this! Really appreciate it :) reply dartos 15 hours agoprevI’m working on some tools to help GMs of tabletop games make content for their players. Little demo is up at npcquick.app. Doesn’t look like much rn, but there’s no openai involved. Currently it doesn’t even use a gpu. reply maytc 8 hours agoprevBuilt an LLM interface to control my browser. Used it to generate playwright tests for me https://github.com/mayt/BrowserGPT reply jerpint 7 hours agoprevAn open source retrieval augmented generation (RAG) framework: https://www.github.com/jerpint/buster reply rickcarlino 10 hours agoprevI wrote a flash card app that uses GPT-4 and Whisper speech-to-text to help me memorize Korean phrases. I’m 1,800 sentences in and use it every day since October. https://github.com/RickCarlino/KoalaSRS reply jacomoRodriguez 13 hours agoprevMe and an colleague working on a language learning app https://poli.xyz. It integrates in you favorite messenger and offers a wide variety of languages. You can either either do freestyle conversations or play certain scenarios. The bot corrects your Grammatik, translates and explains words and sentences and support tts and stt. reply benjaminwootton 13 hours agoprevI built this demo of using LLMs to query databases, knowledge bases, and most interestingly create PDFs. It’s targeted at financial services but similar could be achieved in many industries. Very pleased with how it turned out as it really brings the potential of LLMs to life IMO. https://www.youtube.com/watch?v=r8MyAxyPJsA reply elpocko 15 hours agoprevAbsurd news article generator using local LLMs. I wanted to create a static website from the articles, but ultimately didn't think anyone would give a damn. In the same vein I create a person + CV generator, and a group chat between simulated crazy people. I made a private Discord bot for me and my friends to talk to, that also generates images using SD 1.5 LCM. The self-hosted backend uses the ComfyUI Python API directly for images, and the LLM part uses oobabooga's web API. reply guywhocodes 13 hours agoprevI built a tool to create \"average llm\" probability of code for checking how aligned code is with what an LLM would output. Working on adding context from a project to check how the style of a section aligns with the style, content and domain of a project. Idea is to use it to identify code that sticks out, because that usually what's interesting or bad. reply jasfi 9 hours agoprevI'm building AI Construx (https://aiconstrux.com): build things with AI. I'm planning to launch the private beta by end of Feb. reply Mr-Frog 15 hours agoprevMy project team in university built a meme generator that uses GPT and Dall-E to generate image macros using Impact font. It was pretty entertaining. reply biosboiii 13 hours agoprevWrote an application to find myself a flat in Berlin, scans some rental websites every minute, uses Google Maps API to calculate the distance to my office, and summarizes the rental description with the GPT-4 API, sends it to me via Telegram. I have no time to read all that generic \"vibrant neighborhood\" stuff :D reply abzdo 12 hours agoparentDo you mind sharing a github link if it is public. reply biosboiii 1 hour agorootparentit isnt. reply smusamashah 14 hours agoprevA chrome extension to ask about selected text with a right click. https://github.com/SMUsamaShah/LookupChatGPT A chrome extension to show processed video overlay on YouTube to highlight motion. A script to show stories going up and down on HN front page. This one just took 1 prompt. reply ropable 5 hours agoprevSemi-automated transcriptions for my favourite podcast, via OpenAI Whisper. reply ben_w 15 hours agoprevI'm not sure if this is the category of \"build\" that you had in mind, but I used 3.5 to make a pay-as-you-go chat interface for the OpenAI API: https://benwheatley.github.io/YetAnotherChatUI/ reply ChikkaChiChi 15 hours agoprevBuilt a tool to summarize certification and licensing costs associated with jobs that require State credentialing. reply justanothersys 8 hours agoprevi built autosuggestions / catch all prompt responses on https://aesthetic.computer and you can also talk to characters like boyfriend, girlfriend, husband and wife. characters are great for kids and older users who really wouldn't experience the tech otherwise. reply iseoulu 7 hours agoprevI built a simple RAG chatbot, and my \"stack\" is plain openai python client at this point. reply qeternity 13 hours agoprevPerhaps a follow on question, as I presume a lot of people reading the comments are looking for inspiration to build things (and those building might not want to reveal yet) what would you like to see built with the capabilities provided by LLMs? reply bloopernova 12 hours agoparentAI/ML that reads my zsh history and suggests automations or other time-savers when asked. Something that reads my teams and outlook, and listens to meetings, and takes notes / remembers stuff for me. reply Karrot_Kream 10 hours agorootparent> Something that reads my teams and outlook, and listens to meetings, and takes notes / remembers stuff for me. I know of a few startups doing this, but have used Grain and have enjoyed the experience quite a bit. reply bonamiko 14 hours agoprevI am working on building out a better voice interface for LLMs. It is still a work in progress (early beta), but you can check it out at https://www.bonamiko.com Currently I have mainly been using it as a tandem conversation partner for a language I'm learning, but it can be used for many more things. As it is right now, you can use it to bounce ideas of, practice interviews, and help answer quick general questions. You just need to tell it what you want. The stack is a Next.js application hosted on Vercel using Supabase for the backend. (There is also some plumbing in AWS for email and DNS.) It is automatically deployed via GitHub actions. reply chetjan 14 hours agoparentVery cool, just signed up. What advantages does this have over the one built into the ChatGPT app? Also, it would be great if I could see the text output in addition to the voice. reply bonamiko 13 hours agorootparentThe main differences fundamentally come down to OpenAI treating it more like a party trick demo, rather than a core functionality. I think it has a lot of potential if I can just fine tune a couple rough edges. (When you chat with someone in person, you don't pull out notebooks a write messages to each other. I see writing as a fallback medium.) To answer your question more specifically, Pro Bonamiko: - Faster average first response latency (but higher first audio latency since OpenAI uses a ding). This is the main focus currently, reducing latency as much as I can. I'd like to be able to avoid the ding, but we'll see how low I can get it. - Can be used anywhere with a browser, OpenAI requires a mobile app installed. (I.E. Desktop support) - In the future we can support deeper customization since we are focused on the audio medium. As soon as you have to run a function in the ChatGPT app there is a long response latency, which could easily be fixed by something as simple as the AI saying \"Let me perform a search to get the details\" Pro ChatGPT: - Nice animation - Already has built in tool support such as web search - Supports language switching automatically between messages, Bonamiko requires manually changing the language reply based_gigachad2 15 hours agoprev> I worked on a chrome extension a few weeks ago that skips sponsorship sections in YouTube videos by reading through the transcript You might want to connect that to SponsorBlock https://sponsor.ajay.app/ reply actionfromafar 13 hours agoprevI wish someone hooked up a chat interface to a CAD program. I find CAD very hard to get in to. It would be really nice to able to ask it how do stuff or to modify parts. Would be very \"Star Trek in Holodeck\" :) reply sethkim 15 hours agoprevI built https://tailgate.dev/ a few months ago. It can help with deployment of simple, client-facing generative web apps. There are a few simple demos on the home page! reply patelajay285 15 hours agoprevWe've built a prompting, synthetic data generation, and training library called DataDreamer: https://github.com/datadreamer-dev/DataDreamer reply arbuge 15 hours agoprevI built https://QexAI.com. I also use LLMs in some other web apps, but mainly as incidental writing aids, rather than the central feature of the app. reply jptlnk 15 hours agoprevI built the copilot for flux.ai, which allows LLM-driven interaction with circuit schematics and datasheets. The stack is react / cloud run / job queue / LLMs (several) / vector db. reply itaydr 11 hours agoprevAn app for making children’s stories. https://schrodi.co/ reply tomcam 8 hours agoprevThe range of creativity and ingenuity in these answers is mind-boggling! reply Kappa90 13 hours agoprevAn app that aggregates the news from websites, blogs, YouTube channels and podcasts, and generate easily digestible summaries, along with a small podcast version so you can stay informed in an easy stress-free way. Right now I’m working on including automatic fact checking and insights on how each source might be opinionated vs. reporting just the facts. https://usetailor.com reply coolvision 14 hours agoprevbookmarking extension, not much traction though https://chromewebstore.google.com/detail/autolicious/jbmpoml... reply bengarney 13 hours agoprevI wrote an autonomous AI space opera tv show generator. It takes a short topic phrase on one end and spits out a 10-15 minute 3D animated and AI voiced video suitable for upload to YouTube on the other end. Super interesting learning exercise since it intersects with many enterprise topics, but the output is of course more fun. In some ways it is more challenging - a summary is still useful if it misses a point or is a little scrambled, whereas when a story drops a thread it’s much more immediately problematic. I’m working on a blog post as well as getting a dozen episodes uploaded for “season 1”. reply nomoreipg 15 hours agoprevAn AI agent to answer questions about any github/gitlab repository. www.useadrenaline.com It does the work of understanding questions in the context of a repo, code snippet, or any programming question in general, and pulls in extra context from the internet with self thought + web searches. reply keiferkif 15 hours agoprevI'm making a Magic Card generator reply chetjan 14 hours agoparentI like this. I tried something similar ~10 years ago, but it didn't go very well. I'm sure an LLM can do much better than the nonsense I hacked together. reply brian_herman 12 hours agoprevMy brother built a security scanner with an LLM reply aakil 14 hours agoprevI built a flask app based chrome extension that takes content from the DOM and sends it to chatGPT for summarization, I also configured it to work on YouTube videos and PDFs, helps when you want to share the tl;dr of a site or video to a friend, I'm thinking I'm going to add some more specific summary functionality next, like listing out a recipe's ingredients and cooking steps https://chromewebstore.google.com/detail/news-article-summar... reply resbaloso 15 hours agoprevA little AI domain name generator: https://namebrewery.com/ Used SvelteKit and Supabase. Deployed to Cloudflare Pages. reply xtrohnx 11 hours agoprevJust a personal project - I got a deep interest in the CIA's Stargate program and the declassified documents in the \"reading room.\" I wrote a script to scrape all of the readable or OCRd text from the documents, and fed them into GPT-3.5 to get a summary. It definitely makes reading through the documents easier. I have all of the docs with summaries on a small webserver here: https://ayylmao.info Simple Flask site with SQLite as the database. reply fullstackchris 11 hours agoprevI'm building a way to automate creation of software video lessons and courses, putting it all under the name 'CodeVideo'. One tool leverages OpenAI's whisper, as well as GPT3.5 or GPT4 for help with generating the steps that ultimately produce the video (this part is not yet in the repo; everything is a work in progress). The tool is here: https://github.com/codevideo/codevideo-ai My goal is to definitely NOT generate the course content itself, but just take the effort out of recording and editing these courses: you provide (or get help generating) the stuff to speak and the code to write and the video is deterministically generated) The eventual vision is to convert book or article style text to generate the steps to generate the video in an as-close-as-possible-to-one-shot. I also leverage Eleven Lab's voice cloning (technically not an LLM, but impressive ML models nonetheless) For anyone more curious, I'm wondering if what I'm trying to do is in general a closed problem - to be able to generate step by step instructions to write functional code (including modifications, refactoring, or whatever you might do in an actual software course) or if this truly is something that can't be automated... any resources on the characteristics of coding itself would be awesome! What I'm trying to say is, at the end of the day code in an editor is a state machine - certain characters in a certain order produce certain results. Would love if anyone had more information about the meta of programming itself - abstract syntax trees and work there comes to mind, but I'm not even sure of the question I'm asking yet or trying to clarify at this point. reply jiggawatts 11 hours agoprevIt’s just a scratch that needed itching, but I wrote a command-line utility for translating “SRT” format subtitles into other languages. I hit some interesting challenges, overcoming which was a valuable set of lessons learnt: 1. GPT4 Turbo slowed down to molasses in some Azure regions recently. Microsoft is not admitting this and is telling people to use GPT3.5 instead. The lesson learned is that using a regional API exposes you to slowdowns and queuing caused by local spikes in demand, such as “back to school” or end of year exams. 2. JSON mode won’t robustly stick to higher level schemas. It’s close enough, but parsing and retries are required. 3. The 128K context in GPT4 is only for the input tokens! The output is limited to 4K. 4. Most Asian languages use as many as one token per character. Translating 1 KB of English can blow through the 4 KB token limit all too easily. 5. You can ask GPT to “continue”, but then you have to detect if you received a partial or a complete JSON response, and stitch things together yourself… and validate across message boundaries. 6. The whole process above is so slow that it hits timeouts all over the place. Microsoft didn’t bother to adjust any of their default Azure SDK timeouts for HTTP calls. You have to do this yourself. It’s easy, just figure which of the three different documented methods are still valid. (Answer: none are.) 7. You’ll need a persistent cache. Just trust me on this. I simply hashed the input and used that as a file name to store responses that passed the checks. 8. A subtitle file is about 30–100 KB so it needs many small blocks. This makes the AI lose the context. So it’s important to have several passes so it can double check and stitch things together. This is very hard with automatic parsing of outputs. 9. Last but not least: the default mode of Azure is to turn the content policy up to “puritan priest censoring books”. Movies contain swearing, violence, and sex. The delicate mind of the machine can’t handle this, and it will refuse to do as it is asked. You have to dial it down to get it to do anything. There is no “zero censorship” setting. Microsoft says that I can’t feed text to an API that I can watch on Netflix with graphic visuals. 10. The missus says that the AI-translated subtitles are “perfect”, which is a big step up from some fan translated subtitles that have many small errors. Success! I wrote this as a C# PowerShell module because that makes it easy to integrate the utility as a part of a pipeline. E.g.: I can feed it a directory listing and it’ll translate all of the subtitles. The performance issues meant I had to process 8x chunks in parallel. Conveniently I already had code lying around to do this in PowerShell with callbacks to the main thread to report progress, etc… reply cryptoz 15 hours agoprevI made some LLM-powered text-adventure games: https://cosmictrip.space/gameannouncement And I'm working on a webapp that is a kanban board where LLM and human collaborate to build features in code. I just got a cool thing working there: like everyone, having LLM generate new code is easy but modifying code is hard. So my attempt at working on modifying code with LLM is starting with HTML and having GPT-4 write beautfulsoup code that then makes the desired modification to the HTML file. Will do with js, python via ast, etc. No link for this one yet :) still in development. reply s-macke 14 hours agoparentI didn't make text-adventures with LLMs. I try to solve them [0]. So, far, none of the 7 tested models were able to win even one of the easiest text adventures. I tried many prompting techniques. But only GPT-4 was able to play through the first half of the game. [0] https://github.com/s-macke/AdventureAI reply ianbicking 14 hours agorootparentFun, I tried to do this back with GPT-3: https://llm.ianbicking.org/interactive-fiction/ But Zork wouldn't be a very accurate measure of skill because GPT definitely knows Zork. Unfortunately the emulator (https://github.com/DLehenbauer/jszm) doesn't work with most games newer than Zork. I haven't revisited the code with newer GPT models either. reply s-macke 14 hours agorootparentGPT-3 doesn't even manage the first few steps of the tested text adventure. And GPT-4 is not good at playing these adventures either. However, my code run a newer version of the Z-machine. So Zork and many other text adventures will work. I have not tried many other games though. reply ianbicking 13 hours agorootparentI was surprised how high your costs were. I assume you are putting the entire transcript into each prompt, but even then that seems high. Is GPT's planning also taking up a lot of room? I did find giving GPT some hints about the known commands helped a lot, and I put in some detection of error messages and kept a running log of commands that wouldn't work. Getting it to navigate the parser is kind of half of the skill of playing one of these games. It would be interesting to have it play some, then step back and have it reflect and enumerate things about how the play itself works. reply s-macke 11 hours agorootparentThe costs have dropped significantly months after I created the cost image. Now I use GPT-4 Turbo. This GPT-4 model understand how text adventures work and there is no need to give him known commands. Of course you try even more sophisticated techniques than mine. I tried the ReAct pattern and virtual discussions. So far, he always stumbles at the same place in a critical understanding of the text. And I tried exactly this critical step dozens of times. You will understand the issue yourself, once you play the game yourself. It just takes 20 minutes and is very easy: https://adamcadre.ac/if/905.html reply ianbicking 9 hours agorootparentYou mean at the very end of the game? The game seems like it's only designed to trick you into that very ending :) Are you hoping it will figure out the game based on the context clues? I'm not sure I can find them myself... A long time ago I did some exercises in \"classical planning algorithms\", which all feel very like the early part of this game. I.e., how do you get ready to leave if you have to shower, and can't do that with clothes on, etc. A similar planning example involved changing a tire (opening the trunk, removing lug nuts, etc). It was surprisingly difficult to make an algorithm that could figure it out! You could search the state space given the transitions, but it exploded with what was effectively lots of dead ends; obvious to me as a human, but not to the algorithm. Which is to say that this is a harder problem than it might seem. reply s-macke 1 hour agorootparentYes, that is the first \"bad\" ending. After that follow just the one relevant context clue and look under the bed. That might be already enough. I chose this game, because the game just helps you, at the every step, what you have to do next. Not much to try out. Just the narrative changes. One time, you have to go to work and one time you have to flee. Other text adventures are even more problematic. I saw GPT-4 trying for dozens of steps in the \"The Hitchhiker's Guide to the Galaxy\" adventure just to turn on the lights. And this just the first command you have to get right in the game. reply Der_Einzige 11 hours agoprevI was working on this stuff before it was cool, so in the sense of the precursor to LLMs (and sometimes supporting LLMs still) I've built many things: 1. Games you can play with word2vec or related models (could be drop in replaced with sentence transformer). It's crazy that this is 5 years old now: https://github.com/Hellisotherpeople/Language-games 2. \"Constrained Text Generation Studio\" - A research project I wrote when I was trying to solve LLM's inability to follow syntactic, phonetic, or semantic constraints: https://github.com/Hellisotherpeople/Constrained-Text-Genera... 3. DebateKG - A bunch of \"Semantic Knowledge Graphs\" built on my pet debate evidence dataset (LLM backed embeddings indexes synchronized with a graphDB and a sqlDB via txtai). Can create compelling policy debate cases https://github.com/Hellisotherpeople/DebateKG 4. My failed attempt at a good extractive summarizer. My life work is dedicated to one day solving the problems I tried to fix with this project: https://github.com/Hellisotherpeople/CX_DB8 reply ciguy 13 hours agoprevI built https://listingstory.com as a way to learn about and play with LLMs. It's unlikely to ever be a commercial success, but it served it's purpose in allowing me to learn much more about how an LLM powered app works. reply foxhop 13 hours agoprevhttps://github.com/russellballestrini/flask-socketio-llm-com... This project is a chatroom application that allows users to join different chat rooms, send messages, and interact with multiple language models in real-time. The backend is built with Flask and Flask-SocketIO for real-time web communication, while the frontend uses HTML, CSS, and JavaScript to provide an interactive user interface. demo here supports communication with `vllm/openchat`: * http://home.foxhop.net:5001 reply golergka 15 hours agoprevI've built a sales bot that would go over a predefined sales scenario like a real human would, being able to jump between steps and work with any complications real conversation would throw at it. It would appear fully human to whoever converted with it. Unfortunately, it was never deployed in production due to business reasons. reply ailicious 13 hours agoprev [–] I built a tool to repeat a chat discussion against a set of data. Let say, you have a row with 4 fields, you chat with your row, then you apply same conversation to all other rows! https://www.youtube.com/watch?v=e550X6R89W4 https://bulkninja.com/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The person is curious about the projects others have created using LLMs (large language models).",
      "They mention developing a Chrome extension to skip sponsored sections in YouTube videos and experimenting with using LLMs to explain function call chains across different programming languages.",
      "The person is also interested in learning about the technology stack and deployment methods used by others in their projects."
    ],
    "commentSummary": [
      "The summary highlights different projects and initiatives that make use of language models like GPT-3 and GPT-4.",
      "Projects include chrome extensions, AI for sales training, chatbots, transcription and organization tools, language learning apps, and various automation and AI-powered tools.",
      "The discussion mentions challenges, limitations, and improvements in language models, as well as the potential of AI in coding interview preparation, content summarization, service documentation, and financial earnings call analysis."
    ],
    "points": 256,
    "commentCount": 219,
    "retryCount": 0,
    "time": 1707153387
  },
  {
    "id": 39262650,
    "title": "Weaveworks Shuts Down, Leaving Industry Professionals Disappointed",
    "originLink": "https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67",
    "originBody": "Alexis Richardson 18h Edited Report this post Hi everyone I am very sad to announce - officially - that Weaveworks will be closing its doors and shutting down commercial operations. Customers and partners will be working with a financial trustee whom we shall announce soon. The company was turning over double digit (>$10M) revenue and had more than doubled the number of new product logos in 2023. However this sales growth was lumpy and our cash position, consequently volatile. We needed a partner or investor for long term growth. Finally a very promising M&A process with a larger company fell through at the 11th hour. And so we decided to shut down. I can only apologize to everyone for this difficult turn. I could say that this should not have happened, but I know that we are not alone in this market. Bigger vessels have gone astray. The Weaveworks team is a special group and it has been a long and tough journey. I know that everyone has been so motivated to do their very best for our customers, our open source community, and each other. You have done well and can be proud. We shall always have a shared story. Our story has been so exciting - from the first days of containers, struggling to be born. The day when someone got Kubernetes working for the first time on Azure. The start of the CNCF. The day when we wiped out our systems with a keypress. The first months of the Covid pandemic. Then investment and our work to figure out GitOps for a lot of great enterprise customers. And there have been dire moments too but we figured most of them out together. You’ve shared all of this and all deserve every memory of a good place to work, and with the privilege of knowing that all of you are among the best. The story does not end here - our open source software is used everywhere. I am working with several large organizations to make sure CNCF Flux is in the healthiest state. More on that soon. And I would invite anyone who reads this and wants to know what is next or offer some help, please get in touch with me! Thank you. We shall not cease from exploration And the end of all our exploring Will be to arrive where we started And know the place for the first time. Alexis Richardson, 5 Feb 2024 4,240 414 Comments Like Comment Share Copy LinkedIn Facebook Twitter Matt Barker Global Head of Cloud Native Services 16h Report this comment You and Weaveworks gave me confidence to start Jetstack, and were always there to help, mentor, and connect. I've always felt a sense of comfort having such a leading cloud native company in London and I'm saddened to know that's come to an end. I can only say that the outstanding work you've done with GitOps, Flux and many of your other projects will live long beyond the commercial operations. Sending you and the team all the best ❤ Like Reply 43 Reactions 44 Reactions Sheng Liang 14h Report this comment The Weaveworks team did a lot to push the industry forward. You did everything in the open and contributed so much for the cloud native community. From the original multi-node Weave Net, to the CNI standard, to the WeaveScope product, to kubeadm, to cloud monitoring, to Prometheus, to eksctl, and of course to GitOps, Flux, and Cortex. Many of these products were way ahead of their time and pointed the way forward for the whole industry. I can't think of another company at a similar scale who has contributed as much. We will remember WeaveWorks. Like Reply 44 Reactions 45 Reactions Duncan Johnston-Watt 16h Report this comment The beauty of open source is that what you have created cannot be undone and is your legacy as a team. It's especially gut wrenching to have an M&A deal pulled at the 11th hour. Knowing you, I know you will have done everything in your power to try to keep Weaveworks going so this is a very brave decision. You must be exhausted so make sure you give yourself some space. DM me any time. Like Reply 23 Reactions 24 Reactions Damian O. Building new capabilities and realising possibilities for industry with Google's data technology 3m Report this comment Thanks for being a fantastic place to work for so many good friends and colleagues over the years. We're all disappointed to see such a great organisation fall foul of these uncertain times. Like Reply 1 Reaction Liz Warner CTO / VP Eng - immediately available 17h Report this comment Thank you, Alexis. It was an honour working with you. Folks reading this who might not have seen my re-post: If you're hiring and you think the talented folks from Weaveworks might be who you are looking for, I'm available to introduce you to individuals and groups. Like Reply 18 Reactions 19 Reactions Vuk Gojnic Cloud native evangelist. Open-source enthusiast. Engineering and DevOps leader. Ex Developer. Ex Telco Executive. Opinions are my own. 2h Report this comment Althought I knew it is comming this post still caught me Alexis Richardson. Caught me not by surprise, but caught me emotionally. After 5 great years of being partner of Weaveworks and its fantastic team, this event leaves a big hole. You left such mark on entire industry, generated so much value for #cloudnative ecosystem, created long lasting things like #FluxCD. Your and Weave’s story is a big chapter cloud history (GitOps movie anyone? 😇). Thick legacy 🙇♂ I am asking myself though if open source end-users could have done more to prevent this from happening. I guess it is mix of suitsble business decisions and end user giving back that could help preventing such things from happening. Your case is call for entire OSS ecosystem. Nevertheless… off to the new horizons! „Fail We May, Sail We Must“ to finish with the verse you brought me to! 💪 Like Reply 5 Reactions 6 Reactions Lee Calcote TechnologistEntrepreneurAdvisorAuthor 14h Report this comment This news is hard to reconcile against the impact and success of each of Weaveworks' projects from Net to Scope to .... the entire list. I've had products built with either direct use of or integrations with any number of Weaveworks' tools. The legacy of Weaveworks lives on through the continued growth of these tools and the mark that has been made not only on the lives of its employees, but of the many thousands benefiting from Weaveworks visionary work and early stewardship of the cloud native ecosystem. Like Reply 15 Reactions 16 Reactions Lorenzo G. Cloud & AI EnthusiastEver-learning Cloud Architect & Software DeveloperCNCF-Certified Kubernetes Administrator, Application Developer & Security Specialist 58m Report this comment I'm so sorry to hear the sad news, Alexis Richardson. Weaveworks has done an amazing job in leading the way with GitOps and creating a supportive community around its software (Stefan Prodan Kingdon Barrett Tamao Nakahara and others did a wonderful job!). Over the past five years, your contributions have been incredibly valuable for me and I've learned so much from you. I'm still wondering if something or someone can give Weaveworks new hope: you and your work don't deserve this. Like Reply 1 Reaction Jeff Krupinski Sales - East 13h Report this comment Just short of 5 years, but worth every minute. Weaveworks has been one of the best companies I have ever had the opportunity to work for while I grew personally and professionally. The culture and teamwork was amazing. Everyone from all departments were always so eager to assist others and take time out of their busiest days to do so. Alexis, thank you for your guidance and support over the years. We had a great time working for you and educating our clients on best practices involving GitOps and optimizing cloud native platforms and application delivery. Look forward to what's coming next. Like Reply 17 Reactions 18 Reactions Qamar Ali Shaikh AVPInfrastructure & Platform Engineering - DreamSports 23m Report this comment It's truly disheartening to hear this! Weaveworks has been instrumental in setting numerous standards across the CNCF communities and has enabled many businesses. I've had the privilege of working with Weaveworks and some of the finest minds in the industry. It's been an honor collaborating with all of you. While it's undoubtedly a challenging time, I wish the entire team the best of luck moving forward. Alexis, I want to express my gratitude for your leadership and for establishing a solid foundation for all of us. Thank you very much 🙌 . Like Reply 1 Reaction See more comments To view or add a comment, sign in",
    "commentLink": "https://news.ycombinator.com/item?id=39262650",
    "commentBody": "Weaveworks is shutting down (linkedin.com)244 points by candiddevmike 16 hours agohidepastfavorite208 comments propter_hoc 13 hours agoI know this isn't the craziest startup shutdown story, but wow. At $10MM of revenue they can afford to keep a staff of 50 at a fully loaded cost per employee of $200,000. Yet, according to Linkedin they peaked at nearly 200 employees. On top of this, they appear to have raised $36 million three years ago - https://www.weave.works/press/releases/weaveworks-raises-36-... In other words they somehow were running at a loss of about 1.5 million a month for three years until their runway \"suddenly\" ran out today. According to the CEO's linkedin post, they were basically trying to keep up appearances of being a 200 person company until some greater fool bought them out, which appears to have failed. How do you find yourself as Board member or CEO of a company like this and not think to cut expenses a little sooner? Far better to be a growing, profitable 50 person company than a cash-burning Potemkin unicorn. reply KaiserPro 12 hours agoparent> According to the CEO's linkedin post, they were basically trying to keep up appearances of being a 200 person company until some greater fool bought them out, which appears to have failed. Because that is what startups do. 80% of startups that are \"successful\" follow this pattern You shoot for the moon, if you don't take massive risks, then you won't be rewarded. It sounded like they were about to be bought out or aquihired, but it fell apart at the last moment (It's not uncommon) > Far better to be a growing, profitable 50 person company than a cash-burning Potemkin unicorn. because probably they looked at the pipeline and realised that if they wanted to deliver the features/customer growth they needed, they required 200 people to get there. reply ssharp 11 hours agorootparent\"Shoot for the moon\" seems like a reasonable strategy when you're making the investment. However, certainly at some point while they were burning through that $36 million it became evident that \"moon\" was no longer a viable destination. Why wouldn't everyone be aligned with making the adjustments needed to get back to default alive? Something is clearly better than nothing. Now if it got to the stage where the CEO no longer wanted to operate at the reduced scale (and nobody else would take the role) or the product couldn't support itself at the reduced scale, then closure may have been the only option. It's just that the \"moon or bust\" mentality doesn't seem like something that should be set in stone for the life of the company. reply streetcat1 11 hours agorootparentBecause this is not what the VC wants. The VCs are diversified across many startups and frankly make most of their money from tail event startups in their portfolio (e.g. Uber / Facebook). Since they don't know which startup will be the tail event, they don't want a profitable business, but a max growing business. This is different from the bootstrap model. reply paulryanrogers 11 hours agorootparentThen why not sell it as a viable business? Or would it be too costly to trim it back and execute the sale? reply PeterisP 6 hours agorootparentWhen it's still enough runway to trim it down, there's often still some hope of greater success - and a VC investor might believe that it's more valuable to have a 1% chance of it becoming a unicorn or a few percent chance of arranging some last-minute buyout, rather than pick up the 100% certain but low price it has as a non-growth business based on its revenue. reply senderista 5 hours agorootparentYes, due to their large bankroll and diversified position, VCs can afford to be risk-neutral and only care about expected returns. Founders and employees obviously cannot be risk-neutral, ergo startups are a great bet for a VC and a terrible bet for anyone else. reply wbl 3 hours agorootparentThe amount of VC-founder side deals that are possible is pretty shocking. Stuff like letting them cash out early. reply PeterisP 1 hour agorootparentI don't really see why such a side deal would be possible - if the VC goal is to get the founder-manager to try for that narrow hope of few percent of major success and discourage them from settling for a lower-value stable business, allowing the founders to cash out would be counterproductive, it's in the VCs interests to ensure that founders personal financial motivation is aligned to theirs, that the founders are also motivated to go big or go bust. In essence, if the startup is slowing down and perhaps not going anywhere, then the standard existing deal with founders where the founders can cash out only if they enable to VCs cash out at a profit (for example, if they manage to pull out all the stops to make a failing startup look attractive to some bigger fool) is exactly what VCs want, and in such a situation the founders have no leverage to extract a compromise that's worse for VCs. reply gtirloni 10 hours agorootparentprevIt's about perspective. What to you (and pretty much anyone else) looks like a business that just needs adjustments to reach profitability, to the VCs it's profile maintenance work for little relative benefit in the long-term. The chances of that company turning 10-20x profits in the next few years is basically zero and they just cut their losses (in their view). reply jongjong 1 hour agorootparentprevI know this is the case but I wonder if this is a self-fulfilling prophesy. I can easily imagine an alternate reality where VCs invest more thoughtfully based on more careful analysis of companies and they would have a much higher success rate and end up with even higher returns without creating unsustainable wealth inequality. reply girvo 10 hours agorootparentprev> Something is clearly better than nothing. To you and I, this is patently obvious. This is not true however for VCs. In a lot of them, they'd prefer you fail entirely rather than limp along making 1x, 1.5x their investment. Zeroing out is preferable sometimes, weirdly. reply ska 9 hours agorootparent> Zeroing out is preferable sometimes, weirdly. It's not even weird. A \"live\" project requires effort, and that has opportunity cost. reply lesam 8 hours agorootparentprevDo you have any sense why this is true? I get preferring (10x or 0x) to (1.5x). I don’t get preferring a near-certainty of 0x to some recovery of their capital with a pivot to selling a smaller-but-sustainable business. Is it something like they’re measured by LP’s (or someone?) on only non-zeroed investments? reply vidarh 3 hours agorootparentI've worked at a VC, and consider that it is a low margin business until/unless you returns significantly above your targets. You get a management fee, which is a low yearly percentage of the invested amounts, and then you get carry - a proportion of the returns above a set target for the fund as a whole. But carry doesn't kick in until you start exiting - for a typical VC fund it takes many years. (I left a year ago, and we were 6 years in when I left; I retained a portion of my carry rights, but still won't know for a couple more years how much I get if I get anything at all) And surviving on the management fees after the initial phace of placing the investment requires being lean and not putting effort into your low performers. Meanwhile while a 1.5x is better than nothing, a company that sells at 1.5x is likely to be near 0x for you, because odds are high that to get there there'll be one or more funding events along the way to help that happen at/triggering terms that will dilute you massively. And odds of failure remains high. And you need the 10x or 100x's, but the low ones means little - most successful funds pay back the entire initial investment from just a couple of investments, and make their return on a couple more. Quite often a single \"fund returner\" carries the entire fund. A small recovery here and there at makes almost no difference. So even a 1% chance of salvaging a \"moonshot\" is better - most cases where you get back less than 1x is going to be a rounding error of your funds overall performance. A VC is not where to get capital of you want to pull back and pivot when things get tough. (And yes, you should keep that in mind if taking a job at a VC backed company as well, and it's part of why stock/options should be on top of your normal salary, not compensating for a low one, unless you get founder-level stock amounts, and even then, think it through; I once almost torpedoed a VC deal as a founder because I demanded a commitment to raising salary levels after the next raise, and I don't regret it for a moment because life would have sucked without it) reply rjzzleep 6 hours agorootparentprevDon't VC companies basically gamble with other peoples money? So yes, the person that actually put the money into the fund might want 1x or 1.5x out over 0x, but for the VC firm it doesn't matter, right? It's not their money to begin with. reply vidarh 3 hours agorootparentLPs in a VC fund know very well what the fund is incentivised to deliver. I worked for one, and our LPs would aggressively write low performers down to zero. It didn't matter to them either. Obviously wouldn't turn it down if still possible once all else has failed, but retaining even a fraction of a percent shot at a higher return was what mattered most, even knowing it was extremely unlikely. Investors in these funds are diversified - they invest in VCs to take the high risk bets. They invest elsewhere for the steadier, lower risk returns. reply asah 4 hours agorootparentprevClean tax writeoff, zero hassle, no talent locked-up. reply pdntspa 3 hours agorootparentprevYet another aspect of how this model is super hostile to actual customers or users. reply wheels 10 hours agorootparentprev> Something is clearly better than nothing. That's not a major component of venture backed startups. For a company that has already been written off as a failure, often the board members that represent the VC would rather not have to stay involved and keep showing up for meetings -- they could be elsewhere; there's an opportunity cost. reply solatic 4 hours agorootparentIt's not like a board seat is this magic item that is stuck to you and you can't get rid of of you tried. If a VC had truly written off the company, and board meetings are not worth their time anymore, they can just resign their seat. reply otteromkram 10 hours agorootparentprevI'm surprised they didn't hire you as an advisor. Maybe they would still be solvent if they did. reply prisenco 9 hours agorootparentprev> Because that is what startups do Feels like a ZIRP truism that we may be seeing challenged in real time. The next wave of successful tech companies might be the ones who explore new business models that better fit the new circumstances. reply pdntspa 3 hours agorootparentprev> they required 200 people to get there. We really need to be casting more doubt on these assessments. reply m00x 3 hours agorootparentprevThey could have done layoffs like almost every startup and big tech company did in the past few years. They could have gone there with 50 good employees. Gumroad almost went bankrupt then came back from the ashes. reply scott_w 4 hours agorootparentprev> It sounded like they were about to be bought out or aquihired, but it fell apart at the last moment (It's not uncommon) Perhaps the buyer didn’t want to be on the hook for the massive losses they were racking up? reply nokun7 3 hours agorootparentprev> It sounded like they were about to be bought out or aquihired, but it fell apart at the last moment (It's not uncommon) Do you know who was about to acquire them? reply rdedev 10 hours agorootparentprev>80% of startups that are \"successful\" follow this pattern Doesn't this sound like selection bias? If every other startup follows this shoot fornthe moon plan then yeah it just becomes a self fulfilling prophecy reply goalonetwo 9 hours agorootparentit completely is and that is the point of the comment. You never hear of the 95% of unsuccessful startups But everyone is following the runbook as if they were the successful 1% (not even the successful 5%, they all act as if they are the top 1%) reply ants_everywhere 7 hours agorootparent> But everyone is following the runbook as if they were the successful 1% (not even the successful 5%, they all act as if they are the top 1%) I think it's because that's what makes sense from the VC's perspective. To the VC each startup is a lottery ticket with a low probability of an outsized success and a high probability of failure. You can burn the startup as hard as you can, because the cost is primarily borne by the startup and the founders. If the startup fails it doesn't matter much to the investor because the portfolio is constructed to be resilient to a large number of failures. What the OP is getting at is: if you look at this from the startup/founder's perspective isn't that kind of a huge waste? And yeah, it is. But I think the idea is that startups and founders aren't pets, they're cattle. reply burningChrome 11 hours agoparentprev>> How do you find yourself as Board member or CEO of a company like this and not think to cut expenses a little sooner? I've worked at several startups who never cut costs, meanwhile they're burning through cash faster than an incinerator at the local trash company. I had one company CEO who remodeled our entire offices, got sky boxes for all the local sports teams (there were four of those) and made a point to tell all the devs they're the highest paid startup devs in the city. I found out later, our CEO also had a pissing contest with another startup CEO on the same floor of the building we were in. Both companies had over $200M in VC money, and both were trying to outdo each other with the lavish lifestyles they were living on the investors money. The other company put on a massive \"release\" party to announce their internet software to the local tech new media. Apparently they blew close 10 $2M on it. Limo's for all the employees to the five star hotel ball room, a red carpet VIP entrance for all the employees like you see on those awards show, some 70's rock band played, and it was open bar all night and they reserved an entire floor of rooms in the hotel where the bash was thrown. Two of the devs told me afterwards, \"Dude, totally not my scene, and none of our team were cool with this at all.\" Less than two months later, both companies ran out of money, quietly shut their doors and closed down. At a bar across the street, we had a group of devs from both companies sitting around lamenting what went wrong, where we were going to next, and reminisce about both companies. We all reached the same conclusion: >> According to the CEO's linkedin post, they were basically trying to keep up appearances reply hef19898 2 hours agorootparentSeems VC backed start-ups are the real lifestyle companies for their founders, doesn't it? reply blagie 10 hours agoparentprevThere are many reasons this happens: 1) As a CEO, I want headcount. Being the CEO of a 200-person operation sets me up for better jobs than a 50-person one. Being in high-profile organizations if good too (and when they fail, I can switch jobs). Same for VPs and managers. 2) As a CEO, I want bonuses. Those come from growth. Zero bonus is the same whether the company lives or stagnates. 3) Rationally, in winner-takes-all markets, a lot of this depends on early losses and overspending. If you and I are building eBay, and I get there for $10M and you for $100M in 10% less time running massive losses, you win. A lot of tech is winner-takes-all or winner-takes-most. .... and so on. Except for retirement account holders whose money is being spent, it's almost certainly better to be a cash-burning Potemkin unicorn than a growing, profitable 50 person company. reply wg0 12 hours agoparentprev>According to the CEO's linkedin post, they were basically trying to keep up appearances of being a 200 person company until some greater fool bought them out, which appears to have failed. That's probably pretty brutal summary of most of past two decades I guess? Also, had it been bootstrapped, might have a different outcome, could scale down, pivot while staying a small profitable shop. reply girvo 10 hours agorootparent> That's probably pretty brutal summary of most of past two decades I guess? Longer. This has been the main playbook even going back to the '00s! reply bigstrat2003 6 hours agorootparentRight... So, two decades ago. ;) reply axiak 11 hours agoparentprevIf they received $36 MM in a fundraise 3 years ago, you better believe that those investors put pressure on the business to grow fast or die trying. Those investors are not looking for a somewhat risky medium % return, they're looking for each company to have a small % chance of being a unicorn. reply mcherm 7 hours agorootparentSo who out there is running an investment fund that's looking to make a much more reasonable rate of return off successful but slowly growing companies? Because I would put money into that fund. reply nullspace 6 hours agorootparentAssuming you’re asking in earnest I would begin with S&P 600 Small Cap companies, and see how they got their starts. These are all profitable companies with various levels of earnings growth and indebtedness. Also commercial real estate fits your criteria almost perfectly. reply superb-owl 10 hours agoparentprevNo to be pedantic, but payroll isn’t 100% of cost. Plus cash flow issues, sales volatility, probably declining revenue as you scale down…my guess is the headcount should be more like 20-30. And that might not cover their personnel needs if a lot of their revenue relies on services and customer success (which is usually the case for OSS companies) reply zx8080 10 hours agoparentprev> How do you find yourself as Board member or CEO of a company like this and not think to cut expenses a little sooner? It's like playing Super Mario: one life left? Die sooner to restart again. There will be a next startup soon, and saving this one does not worth effort. Besides that, the CEO has probably got his cut already as salary. This cow is done, bring in the next one. reply orsenthil 12 hours agoparentprevI think, motivation would have been, if they were able to sell themselves as 200 person company, the CEO and Board would gotten a bigger piece of the pie in the landing space. reply bogomipz 9 hours agorootparentAs I pointed out elsewhere the 200 person company is not accurate. The OP is quoting something listed as \"peak\" on Linkedin without even providing a reference. And for some reason everyone is running with that figure. Nearly every tech company had a peak headcount during the height of Covid. Techcrunch generally also has inaccurate tech company numbers in their profiles. Also you can't sell yourself as a 200 person company if you don't actually have 200 people as that would come out immediately in any due diligence an acquiring company would would do on you. reply KingOfCoders 3 hours agoparentprevAlso with AI, the \"plan-b\" of VCs, which is selling the company as a people asset with a people x M = $$$ multiplier breaks down more and more. reply purpleblue 12 hours agoparentprevBecause no one that matters cares about a company that makes $10 million per year, neither the cofounders nor the board. Everyone wants 100x that because they want to become 9 figure wealthy or more. Better to close down, fuck the customers, and then have the cofounders start a new \"journey\" in hopes of getting that unicorn status and become fabulously wealthy. reply great_thanks 7 minutes agorootparenti keep reading confounders... reply hef19898 2 hours agorootparentprevI know that you are right, it is just so incredibly stupid. reply api 13 hours agoparentprevSometimes investors have no interest in anything but a large exit. So it's large exit or bust. Building something stable that grows at a reasonable pace is considered the worst outcome because it both consumes investors time/energy and delays closure of a fund. They're left holding shares that are illiquid. It's perverse of course but it can be something baked into the structure of how VCs and other funds work. reply NavinF 12 hours agorootparent> They're left holding shares that are illiquid More specifically, how much is a SAFE for 7% of a small business worth? If there are no liquidity events it will be impossible for investors to even get their money back let alone outperform SPX reply goalonetwo 9 hours agoparentprevwe all know that once you get 36 Million$ of investment, you cannot \"just\" run a 50 people startup that will have a stable valuation of maybe 100m$. Once you take big investment it comes with the expectation you will get to 500m$ at least. VCs don't want to 2x their money. They want a small chance of 20x. reply ushakov 12 hours agoparentprevWe don't know all the details. Maybe they had high costs elsewhere or a market insight that made them re-think whether they want to be continuing to operate that business reply kjs3 9 hours agoparentprevAnother 'CEO' with \"Everything was going AWESOME! Our numbers were great and getting BETTER! Our customers LOVED us! Buuut...we're closing shop, today. Totes sorry, bro.\". Not a single mention of \"because we managed cash like a drunken sailor and bet the farm on a singular exit event\". The spin is making me a tad dizzy. reply bogomipz 10 hours agoparentprev>\"According to the CEO's linkedin post, they were basically trying to keep up appearances of being a 200 person company\" Where in the linkedin post does the CEO state that? My understanding is that they reduced headcount greatly over the last couple of years and were well below a 100 people. The source of this was a then current employee that my company interviewed in November. reply colechristensen 12 hours agoparentprevIt's not that unreasonable. During the post-covid inflation and high interest rates getting loans and attracting funding got very much more difficult. Downsizing by 75% probably would result in a failure that just took longer. They chose to keep going in attempts of securing that next step and it didn't work so they shuttered. The environment for funding changed and the less attractive startups shuttered, that's what happens. Maintaining a short runway is a vibe, a path towards a big reward or a quick failure. That risk isn't for everybody. reply edoceo 15 hours agoprevhttps://www.weave.works/ \"Operate and Manage Kubernetes easily\" / \"GitOps Automation for Kubernetes Stacks\" reply stackskipton 14 hours agoparentProbably most popular thing they built was FluxCD if you are confused where you have heard their name before. Their company provided a ton of extra tooling and consulting around the product. Hopefully as FluxCD user, this doesn't impact the development of Flux. reply catherinecodes 14 hours agorootparentRight. Flux was a handy little tool[1] that sync'd yaml manifests in git repos to live clusters. The concept was fascinating, and the tool was well done--small and efficient. Easy to learn. In 2019, they announced they'd be \"merging\" with argocd[2]. It seems the merge never really took place, and after that they deprecated flux and announced flux2[3]. The sudden changes of course were a little confusing and perhaps not too well communicated. 1: https://github.com/fluxcd/flux 2: https://discuss.kubernetes.io/t/flux-cd-joins-forces-with-ar... 3: https://github.com/fluxcd/flux2 reply yebyen 10 hours agorootparentSudden? We finally archived the repo at the end of 2022. https://fluxcd.io/flux/migration/timetable/ I was hired to support Flux v1 two years after the events you described, in the beginning of 2021 to go on supporting Flux v1 until we could get everyone off the boat. (I worked at Weaveworks until last month, and I'm still a Flux maintainer! Keep the Flux talk in Present tense please! ;-) reply catherinecodes 46 minutes agorootparentYes, present tense is more appropriate. Best of luck to you on what's next. reply preisschild 3 hours agorootparentprevI hope so too. Flux is the best Kubernetes Gitops toolkit IMO. reply sleepybrett 11 hours agorootparentprevPeople like the weave network policy controller too.. at least in the earlier days of kubernetes, their cni was pretty popular for awhile. reply kensey 6 hours agorootparentThat was my first recollection -- after CoreOS' Flannel, I think the next two (or at least two of the earliest) overlay networks available for Kubernetes were Weave Net and Calico (whose core maintainers started Tigera). Flannel is still around and under active development despite CoreOS being long gone; hopefully the tools Weave employees maintained can keep healthy communities going around them. reply jes5199 15 hours agoparentprevthanks, I didn't recognize the name reply mad_vill 15 hours agoprevI feel like the next generation of this type of company is smaller consultancies that have awesome developers that build customer tooling on the side. But the main revenue driver is consultancy. Also it really feels like all the air has been let out of the docker/kubernetes/cloud-native balloon that was so popular in the late 2010s. reply jbu 8 minutes agoparentI know a bit of the history with this one. Back in the day there was a smaller consultancy with awesome developers called LShift (mentioned here https://en.wikipedia.org/wiki/East_London_Tech_City). They worked out that an open source messaging thing would be useful, and created RabbitMQ (there were details about who, how it was funded internally, etc). That got sold to VMWare, and a bunch of people went with it, but LShift went on as before, happy, but always looking for another Rabbit. Didn't find one, was aquihired in the end. Meanwhile, some of the Rabbit people formed Weave, looking for the killer business around the early container ecosystem (https://www.weave.works/oss/net/ was interesting, eksctl, flux, CNCF, lots of good things). But I guess they took a bite of the VC apple and sustainable technical contributions was no longer the goal. I've huge respect for everyone I knew from Weave. Great people all. Best wishes and I know you'll land on your feet. reply gangstead 14 hours agoparentprev> smaller consultancies that have awesome developers that build customer tooling on the side I've worked at a couple consultancies and they were always chasing after that recurring product revenue. I grew to believe that it isn't possible under that business model. When you are running a consultancy you are in the business of marking up developer hours: find a client to sign a contract for $150 / hour and hire a consultant who will do the job for $100k/year salary. Then convince them to work as many hours as possible for their fixed salary, plus the carrot of a bonus payout every once in a while if everyone bills lots of hours. Having that developer spend any time working on the company's product causes all sort of problems. The most immediate is the loss of revenue. But also now this employee might see working on the product as cutting into their bonus since they are billing less hours. Everyone wants some of the upside if the side product generates revenue but how do you split it between people who worked directly on the product and people who worked on paying client jobs to generate the revenue so the others could work on the product? It ends up causing a rift. The other thing I've seen while working at small and even medium sized consultancies is that they end up dependent on one large customer who calls all the shots and takes up all the available time, or all \"extra\" time not being billed is used working on sales for the next contract. Either way there doesn't end up being much capacity to work on cool tooling. reply mooreds 13 hours agorootparent> I've worked at a couple consultancies and they were always chasing after that recurring product revenue. I grew to believe that it isn't possible under that business model. The only time I've seen this work (and I have seen it work multiple times) is with managed hosting. So if you are an expert at developing web applications or solutions usingyou can offer a managed hosting solution to your clients where you host the web app or thesolution. Not all of them will take you up on it, but some will. Those that do will pay you a monthly fee. This isn't free (you now have to carry a pager) but is recurring. Building your own SaaS/other unrelated product? That's a rock I've seen several consulting ships crash into (to pick a metaphor). Here's one that some of my friends tried to build in the late 2000s that I wrote about: https://www.mooreds.com/wordpress/archives/506 reply danjrslp 14 hours agorootparentprevI agree. Being good at running a consulting company does not translate to being good at running a product/SaaS/devtools company. reply softwaredoug 13 hours agorootparentAnd vice versa, i know a lot of product companies that have a really shitty profesional services arm that care more about shoveling more product down a customers throat than actually helping them from a neutral PoV. reply catherinecodes 14 hours agorootparentprevRight. I wonder what their cost structure was like. $10 million in revenue is enough to support a decent-sized team. reply gangstead 12 hours agorootparentSince they raised $61 million (source https://techcrunch.com/2024/02/05/cloud-native-container-man...) they probably had way more team than $10 million could support. Since they raised the VC money I guess that downsizing to a team that the business can sustain is not an option. reply nixgeek 14 hours agorootparentprevAccording to LinkedIn they were 50-200 employees which after excluding all the other costs for running a company, is definitely not enough to cover the fully-burdened payroll of even a 50 person organization that’s probably predominantly Engineering types, that assumption being if most people are US-based (or if they don’t do “location based” pay, and indexed off a more expensive location). reply 0xbadcafebee 15 hours agoparentprev\"Air has been let out\" in the sense that it's moved past the trough of disillusionment and is on its way to the plateau of productivity[1]. There are still a few people in the trough of disillusionment yelling about how a $5/month VPS is all you'll ever need, or a $50/month bare metal colocated server is all you'll ever need. But for the most part the people who benefit from cloud services & containerization will use it when they need to, avoid it when they don't. It'll continue to be a productive tool when used properly, with vendors supporting mature products using it that solve people's problems. [1] https://en.wikipedia.org/wiki/Gartner_hype_cycle reply quickthrower2 12 hours agorootparentMust have miss the drama / holy war memos. Happily use a mix of k8s and non k8s at work and use that $5 VM for home side hussle. reply nprateem 12 hours agorootparentprevLike with big data I think most orgs (>80%) just don't need it due to the extra complexity. They might as well just use something managed like fargate and go back to building their own products. reply 0xbadcafebee 12 hours agorootparentIMO that's an overly reductive take, which is very common for tools in this space, but (I think) needs to be addressed so people stop repeating it. It reduces what \"most orgs\" are (as if 80% of businesses are the same, or solve the same problems, or have the same challenges, or use the same approaches, or have the same customers, have the same staff or expertise, budgets, timelines, etc, etc, etc.). Clearly there is no such thing as \"most orgs\", as there are many different kinds of businesses and how they approach solving problems varies from business to business. Their use of technology to solve problems also can't be easily reduced; the way the business chooses to solve problems doesn't necessarily dictate what technology they should use. It correlates the need for complexity with whether an organization is in some 20% minority of organizations, as if only a minority of orgs should or shouldn't use a complex tool. It reduces a given tool down to \"complex or not\", as if complexity is the only consideration of whether to use a tool or not. There may be many different reasons to use a tool regardless of whether it's complex. It assumes that a given tool has some inherent complexity that isn't comparable to other tools. Other tools might have less inherent complexity, but their lack of complexity may then create new problems that have to be solved, which just moves the complexity from the tool to a bunch of other places. Overall, it correlates the way you solve problems, with how complex a tool is, with whether your organization is of one of two large generic groups. This is such a sweeping conclusion that it would be impossible to prove or demonstrate. Based on your comment about them \"using Fargate\" instead, I'm assuming what you're actually saying is you think people should be using a managed product which uses containerization [and possibly k8s], rather than managing a complex technology themselves. I agree. But that doesn't mean we can generalize about who should be using what and when. reply nprateem 9 hours agorootparentI wasn't writing a critiqued essay. It's perfectly reasonable to assume 80% of orgs don't have the scale, core competencies or justifiable need to be managing container clusters themselves. Also, no need to assume. I specifically said \"use something managed\". reply marcinzm 15 hours agoparentprev> Also it really feels like all the air has been let out of the docker/kubernetes/cloud-native balloon that was so popular in the late 2010s. Not really, the space has simply grown faster than these companies could keep up with and were left behind. I can code up a CICD pipeline that does per-PR namespace isolated deploys of an app stack on EKS using Github actions in well under a week. With docker compose for local testing. That wasn't the case 5 years ago but it is now. Why would I want to be locked into Weave Works? reply benjaminwootton 13 hours agorootparentGitHub actions must have eaten most of the DevOps tooling market. It’s pretty good and it’s fine for the vast majority of pipelines. reply Yasuraka 13 hours agorootparentGH Actions is just CI, maybe crude CD, and not the best at that. It and (GitLab CI) ate Jenkins reply lmm 9 hours agorootparentJenkins still does stuff that you can't do with GH Actions. Actions ate Travis / TeamCity / CircleCI, all the \"more polished Jenkins for the 80% use case\" products. reply yebyen 8 hours agorootparentWhat does Jenkins do that you can't do with GH Actions and Flux? reply lmm 7 hours agorootparentBased on the last time I looked: good handling of dependencies between builds (e.g. the ability to do an \"edge build\" where for any change in a given project, you check whether that will break your other projects when they upgrade to depend on that), advanced scheduling, plugins that integrate all sorts of random tools into your build views. reply swozey 15 hours agorootparentprevHell, we do it once in terraform/pulumi/cdk and then it takes 10 minutes to tweak some variables and switch aws accounts and bam Our devs/SRE put up apps and clusters in minutes (aside from the terrible alb/ecs/eks/etc deployment times). reply FourierEnvy 15 hours agorootparentYeah this is nice if you have large teams and repeatable projects. Smaller companies have much more ad-hoc requests. I stood up an entirely new type of project end-to-end from a docker compose into our cluster. Re-used alot of code base but it was still a bit of work. Much less than it used to be though. reply swozey 15 hours agorootparentI have this installed but I've never actually done more than a quick test of it but this might be a good tool for you. It'll record all of your aws console actions and output them as terraform, couldformation, cdk, etc. That'd give you a repeatable deployment for disaster recovery without having the toil of writing that part of it. Having to click through every checkbox in the console and iam perms and blahblah under fire is rough. https://chromewebstore.google.com/detail/console-recorder-fo... reply master_crab 14 hours agorootparentprevThis. We looked at weaveworks and its competitor both as a product and an investment (mid 6 figure usage). Our big issue was that we had a lot of smaller teams doing different things and not one or two featured items raking in the majority of our revenue. These solutions work if you have a bunch of snowflake workloads by design (or bad design). reply yebyen 8 hours agorootparent> a bunch of snowflake workloads by design (or bad design). That's a really interesting characterization of WGE, and I can't say I disagree much (my personal opinion as an ex-Wyvern/OSS Engineer DX @ weaveworks) reply upupupandaway 15 hours agorootparentprevHow does your pipeline work with an app that requires many other services to work? reply FourierEnvy 15 hours agorootparentprevYeah I literally did this last week for a new in house AI assistant for my company. Just swap out Jenkins for GH actions (sadly). So... can confirm. reply xenophonf 15 hours agorootparentprev> a CICD pipeline that does per-PR namespace isolated deploys of an app stack on EKS using Github actions... [with] docker compose for local testing Please teach me, oh wise prince! reply sytringy05 14 hours agorootparentnext [–]“it’s that easy!” reply xenophonf 4 hours agorootparentI'd love to see 7K of YAML as every time I've asked, no one's been able to show me a fully worked, end-to-end example. reply mad_vill 15 hours agorootparentprevthey did more than just CICD but I see your point. reply swozey 15 hours agoparentprev> Also it really feels like all the air has been let out of the docker/kubernetes/cloud-native balloon that was so popular in the late 2010s. Kubernetes is just boring now. It's stable, the people who need to know it probably know it. I started working and contributing to k8s in 2015 back in version 1.1. 7 years of the same technology. I haven't even used it in 2-3 years (1.18) and I know I can hop over to it and do exactly what I used to do with some CRD flare. All of the contributors should be proud of what they've built, that's the goal in the end, stability to where it's an afterthought. reply softwaredoug 14 hours agoparentprev\"Smaller consultancies\" are actually really hard. Especially if you want to deal with larger companies with the type of $$ to pay for consulting. Instead of doing the work you love you end up in procurement and payment hell. reply kensey 6 hours agorootparentSmall consultancies also tend to fall into the trap of having one client (often their first client) that they utterly depend on the money from... but who doesn't depend on them to be able to survive. That customer almost always knows the relationship is unbalanced in their favor (sometimes they went into the relationship specifically because they knew it would be that way) and they will run you ragged with unreasonable requests, burning out your staff and ruining your relationships with other clients because you have to keep them happy so they keep writing checks (and then you're even more dependent on them, as a rancid little bonus). The only way out is to either gut your way through it till you grow enough to be able to push back without risking your existence; detect that things are going that way early and fire them as a customer before it ever gets to that point... or keep burning out staff till you can't find fresh faces, then close up shop. reply mech422 11 hours agorootparentprevGod, sales and collections suck ... and Net 90 can be a killer for smaller shops (and big clients tend to expect Net 90) reply tsimionescu 1 hour agoparentprev> Also it really feels like all the air has been let out of the docker/kubernetes/cloud-native balloon that was so popular in the late 2010s. As someone who works for a company that sells various k8s versions of products and services, we're only now seeing some of our bigger customers really starting to use k8s more exclusively. So at least my experience is the opposite of yours, it seems that at least in some industries k8s is only now seeing significant adoption. reply abhiyerra 2 hours agoparentprevThis is what we are doing with my company. We build out tooling that benefits everyone and open source most of it, but our bread and butter is consulting. Our consulting leads us to build more tooling to make our jobs easier, which leads to more effectively delivering our consulting. I think this is the model most of the big shops like IBM and Oracle also use. Infrastructure tooling is not usually a core competency for most companies, and they want others to do it for them. reply mfer 15 hours agoparentprevVC funded and looking for growth opportunities is far different than building a long term sustainable business. The carrot in the business model leads business decisions in very different directions and your setup is different to meet them. Are there opportunities for VC funded with growth expectations in this kind of business? reply ryanSrich 14 hours agoparentprev> I feel like the next generation of this type of company is smaller consultancies that have awesome developers that build customer tooling on the side. But the main revenue driver is consultancy. The issue here is the lack of appeal for investors, leading to a tenfold decrease in new cos. However, the startups that do launch are likely to be more sustainable reply BrittonR 15 hours agoparentprevI feel like this is how a lot of the Nix community and Elixir community already functions. reply gtirloni 15 hours agoparentprev> that was so popular in the late 2010s Was? What's more popular than that today? reply goalonetwo 9 hours agorootparentSince the end of the free money era, a lot of people are rightly questioning the microservice/k8s/cloud-native model that requires you to run an operation team of 20 people and has a baseline cost of 200k$/year for a cluster that doesn't do anything yet. reply gtirloni 8 hours agorootparentIt really doesn't and you won't get anything useful out of any discussion by making these exaggerations. reply tnolet 15 hours agoprevI was following them on and off as they started around the same time I started a company in similar space and we shared an investor. Similarly, Armory.io also got sold in what seems a fire sale ($7M after raising $200M). Goes to show how hard this space is. reply mathverse 15 hours agoparentCompanies dont want to pay for specialized building blocks. Similarly we've been looking at Coralogix recently but needed synthetics. We were offered some sort of package with ur company but decided to go with Datadog instead. reply tnolet 15 hours agorootparentAll good. Just wanted to mention this was with a company I started before my current to which you are referencing. reply ushakov 15 hours agoparentprevThere’s no money in DevTools. Businesses will see you as cost, not asset reply ralph84 14 hours agorootparentAtlassian’s market cap is $55 billion. GitLab’s market cap is $11 billion. GitHub sold for $7.5 billion in 2018. There’s money, you just have to be more than a point solution. reply fngjdflmdflg 13 hours agorootparentWow, didn't know that about Gitlab. Here's a source[0] for that claim in case anyone else wanted to know. Seems a bit high imo but what do I know? [0] https://www.nasdaq.com/market-activity/stocks/gtlb More info here: https://about.gitlab.com/press/releases/2021-10-13-gitlab-an... https://handbook.gitlab.com/handbook/being-a-public-company/ reply LunaSea 1 hour agorootparentYes, Gitlab is way evaluation is way overpriced. They're not even in the green yet. reply QuiDortDine 7 hours agorootparentprevGitLab's not too surprising, they're a very valued player in the open-source space. reply nunez 13 hours agorootparentprevAtlassian is way more than dev tooling at this point and GitHub's user count is insane. reply marcinzm 15 hours agorootparentprevSomething that requires you changing your whole dev process around it and then shuts down one day is not an asset. reply mooreds 13 hours agorootparentprev> There’s no money in DevTools. MongoDB, Snyk and Auth0 might beg to differ. (I work for an Auth0 competitor.) > Businesses will see you as cost, not asset Isn't that true of any tool? How are devtools different (from a business perspective)? reply ushakov 12 hours agorootparentThe services you're describing (Databases, Security, Auth) have become commodities. This means cut throat competition. Most new players will not have enough to differentiate them from existing offerings reply mooreds 9 hours agorootparentThere's lots of money in commodities, though. reply dilyevsky 15 hours agorootparentprevIt seems like you need to be doing at least part services play - product alone doesn’t cut it reply api 15 hours agorootparentA perennial topic at lots of IT/devops standups these days is how to get rid of SaaS overhead, so this isn't a sure thing either. Bottom line is that developers and IT pros are cheap. I know because I am one. We always try to find a way to not pay for things and especially to avoid any kind of lock-in. I'm allergic to anything proprietary or anything with a SaaS, which is ironic because that's one of our company's products... makes me think perpetually about how to fix this broken market by offering a way to pay for good tools and products without either proprietary lock-in or eternal rent (and centralization and all that entails). It's a very hard problem, and it's not really a technology problem. More of a biz/legal/economic problem. reply dilyevsky 15 hours agorootparentThey’re cheap until the management realizes they just spent a year (so like $300k) educating their devops how cni works and they bounced to faang or some other startup so the project needs to be scrapped or restaffed again and started over. That’s where the services come in. Also yeah it’s well known ICs view saas as direct threat so everyone tries to skip them and go directly to KDM. That’s the reason nearly all enterprise software is pain to use reply gtirloni 14 hours agorootparentI think the comment you're replying to meant to say developers are cheap in the sense they allergic to spending money, not that their time/salary is cheap. Example: \"John is a cheap bastard. He never spends any money or buys the cheapest options\". reply bostik 1 hour agorootparentIt's not just the money, it's all the things around using corporate money. Procurement is its own level of hell. Dealing with (or even having to think about) vendors' sales critters is a drain on brain cycles. The frustration of \"call us\" pricing structures. Or if you want to combine all of the above: perfectly functional but artificially gated features. If you could pay for a service that GUARANTEES the vendor does not allow their sales people anywhere near your details, that might change things. reply dilyevsky 14 hours agorootparentprevOh right, yes i misread that. Not like they have any budget anyway reply api 13 hours agorootparentprevYes that's what I meant. I think the aversion to lock-in or recurring expense is stronger than merely an unwillingness to spend money. reply dilyevsky 3 hours agorootparentI am wondering why does the cloud gets a pass then? It’s all three - the lock in, recurring and also ridiculously expensive reply tsimionescu 1 hour agorootparentprevHonestly, I think any software business model where you're not paying an explicit monthly/yearly sum is more deceitful for B2B. No business wants to use a software product that is not being actively maintained, so even if you get sold a perpetual license to \"own\" a version of the product, you will keep going back to the same vendor to get new versions. So, you are actually still paying a periodic fee, just maybe with capex instead of opex. And if the vendor goes out of business, you'll have to start moving to a new product, so you didn't really \"own\" the software any more than if you had been paying an explicit rent on it. Now, SaaS where you are sending all your data to the company's servers is probably one step too far, for various other reasons. But perpetual licenses are generally a bigger scam than periodic ones for business software. reply slgeorge 13 hours agoprevThe shutdown means great people with Cloud Native skills are available now. People across all teams: marketing, product, engineering, dev-rel, consulting / CRE, customer success and business operations Across the States, UK/Europe and Egypt. If you can help these fantastic people find new roles - please get in touch! reply eh_why_not 10 hours agoparent> The shutdown means great people with Cloud Native skills are available now. Question from someone with mostly back-end/services non-cloud dev skills: what exactly are Cloud Native skills? reply dharmab 10 hours agorootparentExperience building and operating large systems using public cloud services and design patterns without falling into the traps such as ludicrously overpriced SKUs, API limits, low quota, data transfer fees, and all the boring stuff in the fine print that will rack up a 7 digit bill. reply dominis 12 hours agoparentprevWere there any salespeople on the team? reply aftbit 13 hours agoparentprevJust in time for cloud native to lose the spotlight in favor of on-prem and AI. reply mfer 13 hours agorootparentCloud native does not mean public cloud. Google uses many of these patterns to run their own datacenters. reply Spivak 10 hours agorootparentAnd you should too since k8s, while an 800lb gorilla on the side of the implementer, gives your dev teams the cloud experience without having to build the APIs yourself. Which is pretty nice honestly, making infra self-service isn't on offer most places hosting on-prem. reply slgeorge 12 hours agorootparentprevFFS - talk about missing the point. reply pmig 13 hours agoprevFlux for me was always superior to ArgoCD from a technical point of view, but they over the years ArgoCD became the more popular tool. I wonder if it was marketing, the missing UI or something else? But super sad to see weaveworks shutting down I hope that the open source projects will continue to evolve. reply denysvitali 3 hours agoparentThe UI makes it easier to sell it to non-engineers. Not that you need to \"buy\" anything - but IIRC the only offering that Flux had was a SaaS feature that sort of gave you an UI. If the UI was what you were looking for, you'd go with ArgoCD. Finally, I think they messed up the Flux 1 -> 2 migration as they weren't compatible with each other. For my own use case, instead of migrating to 2 I have just switched to ArgoCD. Feature-wise, ArgoCD always seemed one step ahead, and more people seemed to prefer ArgoCD over Flux - and this can probably be seen also by the fact that they had an \"ArgoCon\" but there was never a \"FluxCon\". Don't get me wrong, I love(d) Flux and I always rooted for that - but over time I switched to ArgoCD and never looked back. In the end, they were two products doing pretty much the same thing, under the CNCF umbrella. reply shurup 4 hours agoparentprevI guess it was UI, indeed. Whatever \"true engineers\" think or say, it is an attractive option for many potential users (think not of Ops only, but of Devs, too). Therefore, it brings a bigger audience, i.e. more adopters, more contributors, more integrations, more whatever… reply alwyn 12 hours agoparentprevI've never used Flux, only Argo, but can you share a bit from your point of view on why you find Flux to be technically superior? Thanks! reply pmig 2 hours agorootparentOne if the decision points for us using Flux was the the helm controller. ArgoCD will just render the helm chart and apply the manifests. If you already habe an Helm Release in your cluster the migration path was easier with flux. reply arccy 12 hours agoparentprevthere was a ui, and they fumbled their flux -> flux2 reply FourierEnvy 13 hours agoparentprevBetter UI reply mac-chaffee 4 hours agorootparentI personally consider the ArgoCD UI an anti-feature. Attaching some hulking mass of Javascript dependencies to the thing that has cluster-admin rights to my production cluster is unnecessary attack surface for me. ArgoCD also has its own auth system and permissions. You give ArgoCD cluster-admin rights, then it uses impersonation to pretend like it has lower permissions. One little bug there and you can trick ArgoCD into escalating your permissions, which happens a lot: https://github.com/argoproj/argo-cd/security/advisories/GHSA... While not officially supported, you can technically deploy Flux with limited permissions, but ArgoCD's dependence on impersonation means it cannot run with lower permissions. reply nullify88 3 hours agorootparentRedis is also a requirement to run Argo CD. When comparing load on my home server, flux was much lighter. Flux also has a pretty cool terraform controller too. At work though, we use Argo and our developers use its gui to get an overview on their applications. reply lijok 14 hours agoprevPouring one out tonight. Weaveworks did some amazing work. Grafanalib has saved me months of work in the past. reply slgeorge 13 hours agoparentThank-you - really appreciate this comment - acknowledging the work that great people did and the efforts they put in. I wish the outcome was different - but we really tried to do good things, and play well in the open source community. reply carlsborg 37 minutes agoprevFounder profile: started out as a rates trader at Goldman, and then founded RabbitMQ and sold it to VMware. King. reply GeorgeRichard 10 hours agoprevThis is a world that I have no knowledge of so I expect my comment is commensurately naive, but it does remind me of the days when I was an avid race-goer. If I bet on a horse to win that's all I wanted it to do; if the horse and jockey expended all their effort and won, fantastic, if they lost, better luck next time. Slow and steady may win the race in some circumstances but it's not the tactic most punters are hoping for. The analogy would be more complete if the loosing horses were sent to the knacker's yard and their stable hands all dismissed with only the trainers living to try, try, try again. reply cangeroo 8 hours agoprevI think it's worth giving praise for their contributions to Flux. In my network, I'm the only one using ArgoCD. Supposedly they're equals, but it always made me curious to try Flux. Are there any statements about the future of Flux and other open source tools, and whether the remaining community has enough resources to maintain development, or if they will reduce their contributions to only fixing critical bugs? reply shurup 4 hours agoparentCan't tell for all their projects, but Flux seems to be safe. Stefan Prodan joined ControlPlane last month already and keeps developing Flux CD. Its latest release (v2.2.3) was delivered while working in the new company. He is also working on Enterprise Distribution for Flux CD (https://github.com/controlplaneio-fluxcd/distribution) there now. reply yebyen 7 hours agoparentprevFlux has a pinned discussion for nearly a month now, to be as upfront as possible, without being able to disclose anything that might be privileged information, but anticipating that the news would get out about our backer sooner or later (aiming to avoid 100 threads about the same topic) https://github.com/fluxcd/flux2/discussions/ tl;dr: Flux is a graduated CNCF project and not going anywhere reply orsenthil 13 hours agoprevhttps://eksctl.io/ is a very useful tool developed and maintained by weaveworks. I hope it will continue to see development and maintenance despite this news. Sad to see a good startup folding up. All the best for your next adventure. reply kbumsik 9 hours agoparenteksctl should be fine. It is the official recommend tool by AWS and eksctl examples are everywhere in the AWS documentation. https://docs.aws.amazon.com/eks/latest/userguide/getting-sta... reply goalonetwo 9 hours agoprevThat whole CloudNative industry seems to be going downhill since the end of the free-money era. It is surprising that it took that long. Very few companies really have the need to run at scale distributed systems on K8S. But as soon as you get into that world, you suddenly need an operational team of 15 people to manage the 50000 moving pieces in that ecosystem. reply debarshri 8 hours agoprevWe will never understand the journey of the founders here. In the journey you make mistakes, some of them fatal some of them not so fatal. But the bottomline is that weaveworks did built some awesome tools for the k8s ecosystem. They kind of propagated Gitops in k8s ecosystem. This is also a cautionary tale for the opensource centric businesses. I remember in my previous job, they would bundle and sell weavescope in the offering where in they would just get the latest version from quay or docker hub as is. I saw the same pattern with Grafana tools. Alot of \"Make k8s simple\" platforms bundle bunch of these VC funded devtools as offering. Loss of value sometime pains me. reply adamfeldman 14 hours agoprevhttps://techcrunch.com/2024/02/05/cloud-native-container-man... reply 0xbadcafebee 15 hours agoprevWelp. Time to switch CNI on that k8s cluster... This is why whenever there is a choice between a grassroots open source project, and a corporate source project, I choose grassroots. When the corporation gets bored of the project (or just dies), the project dies too. Grassroots doesn't die as long as one person is still willing to merge PRs and make releases, and grassroots is much more likely to be forked and maintained in perpetuity. Community makes or breaks open source. reply menthe 15 hours agoparentKinda surprised anyone would still using WeaveNet as a CNI.. it was a bit of a dumpster fire: https://blog.quentin-machu.fr/2020/08/07/our-breakup-with-we... reply hitpointdrew 13 hours agorootparentIt has been 100% fine for me, was easiest to deploy, very easy to encrypt all network communication. Has been anything but a dumpster fire, will likely wait it out a see what happens with the plugin, rather than switch to something else. reply whalesalad 15 hours agorootparentprevwhat is the idiomatic approach these days? reply JojoFatsani 13 hours agorootparentEKS + AWS CNI work great and will get you pretty darn far. Scaling ceiling is really just your cidr range space. If you're bumping up against that you may be outgrowing EKS, then cillium i guess reply dilyevsky 15 hours agorootparentprevCillium is probably the most rock solid option these days. They are still pumping out releases even though they had been recently sold to cisco reply nightmonkey 14 hours agorootparentCilium wasn't sold to Cisco, Isovalent was. Cilium is F/OSS and a graduated CNCF project: https://landscape.cncf.io/?item=runtime--cloud-native-networ... Cheers. reply gtirloni 15 hours agorootparentprevLots of Cillium deployments lately but... Cisco just happened so, let's see how that goes. reply throwitaway222 15 hours agoprevThey were exciting when they first started, (8 years ago?) before k8s - they had some interesting networking capabilities including the ability to use zeroconf. A lot of Java clustering stuff builds off that which made them special in the age of Docker. reply fideloper 14 hours agoprevOh, just recently I noticed they had archived Ignite (within the last few months?), their very handy wrapper around Firecracker. What a shame! reply pstuart 4 hours agoparentThat's how they originally caught my eye. reply break_the_bank 15 hours agoprev> The company was turning over double digit revenue and had more than doubled the number of new product logos in 2023. From the LinkedIn post. Does this mean $100 MRR / ARR ? reply gk1 13 hours agoparentMaybe it was edited later, but the post now says \"(>$10M)\". I interpret that as $10–19M. That's not great for a product that's been around for 9 years. I consulted a similar company in their space ~5 years ago. What I found was that the way to make money in K8s automation/monitoring is to position it as a security solution. That's what Snyk did and they've been killing it, reaching $7B valuation as of last year. Both the company I was advising and Weave.works decided to stick to the developer productivity story and unfortunately both have now shut down. There are many factors to a company's success but it doesn't help to be positioned as a solution that's seen as just a \"nice-to-have\" or part of a \"best practice.\" reply marcinzm 12 hours agorootparentI've been thinking about this for a bit. Productivity is a hard sell for a company that is tech focused. Since a client basically can't measure the impact there is little external difference between a true solution and a fake solution. As a result even if you convince someone of the value a company that focuses on marketing to those paying the bills will win out against one that focused on building a better product. Security has fairly proscriptive compliance requirements (ie: SOC, etc.) which provide a benchmark against which to measure impact. Not impact on security but impact on meeting the compliance requirements. reply esafak 6 hours agorootparentIf you can't measure the benefit, why would you pay more for security? Just get the cheapest thing that checks the boxes... reply suriyaG 2 hours agorootparentI think, in simpler terms. There's always a Chief Information Security Officer (CISO). But, there's rarely a Chief Productivity Officer. It's usually the CTO et al fighting for dev productivity if any, else nobody just cares and you get impenetrable tarball software reply goalonetwo 9 hours agorootparentprevIs that because as soon as you become a so-called security product you are now selling to the CISO org? My experience with the CISO org is that they love buying expensive B2B enterprise products that have very limited real-life use-cases but are really good at checking boxes. That whole cloud-native security industry is full of FUD and fear-based selling to non technical organizations reply kwerk 15 hours agoparentprevI think they meant to say \"double digit revenue growth\" reply break_the_bank 15 hours agorootparentThat makes more sense! Thank you. reply yencabulator 14 hours agoprev> and had more than doubled the number of new product logos in 2023 That is a curious KPI. reply mousetree 13 hours agoparentIn the B2B SaaS world, it means they're signing up new customers (e.g. including some who might have well known logos). reply yencabulator 13 hours agorootparentOutside of bizdev brotalk, isn't that called \"new clients\"? reply arccy 12 hours agorootparentnot just new clients, recognizable clients who are willing to be associated with you reply samcat116 14 hours agoparentprevIts a pretty common KPI for B2B companies. reply alexitosrv 12 hours agoprevIn LinkedIn I also read some of their key people wrote a post with this wording for the announcement: \"I americium precise bittersweet to denote – officially – that Weaveworks volition beryllium closing its doors and shutting down commercialized operations.\" and I almost had an stroke trying to parse it... reply sevagh 11 hours agoprevCortex was mentioned below. Weaveworks did a lot of work with scaling Prometheus with their tool Cortex [1] 1: https://github.com/cortexproject/cortex?tab=readme-ov-file reply mihaitodor 15 hours agoprevSometime last year, they had someone cold call me from the US to sell me stuff. I’m not sure where they got my number from, but I don’t think that’s a good strategy for trying to sell B2B solutions. reply slgeorge 13 hours agoparentSorry that annoyed you. One thing to bear in mind is that at Weaveworks we made massive contributions and did our best to be part of the community in the right way: * Flux * Flagger * Cortex * Ignite * Weave Net * and a whole host more Oh and there's a load of people without jobs tonight - wondering about their futures - hopefully people will see the talent and the contributions and find roles for them. reply mihaitodor 11 hours agorootparentAnd that's a huge bummer since I know people who rely on those products and they're getting value out of them. However, I don't think the company failed because it didn't use more aggressive advertising. reply javierluraschi 15 hours agoparentprevWhat's your ideal B2B sales strategy that would work for you? reply mihaitodor 15 hours agorootparentI’m a bit more receptive to offline messages if they’re targeted adequately. They can see my interests by skimming my LinkedIn, GitHub and StackOverflow accounts and contacting me via social media or by email is fine if their product is somewhat relevant to my work or hobbies. However, asking me to spend my time trialing their “new super-cool Kubernetes offering” is a huge nope. Especially if that interaction happens over the phone. reply pyb 14 hours agorootparentprevLook up \"permission marketing\" reply coding123 15 hours agorootparentprevThe product is so good you found out about it from someone else and had to have it also... Kinda like docker or python or something. They actually had that when the first started. reply runako 15 hours agorootparent> What's your ideal B2B sales strategy that would work for you? >> Kinda like docker or python or something There's a lesson here in the difficulty of selling to developers. reply RCitronsBroker 14 hours agorootparentthats really funny reply xboxnolifes 14 hours agorootparentprevSo, how did the other person find out about it? reply JCharante 12 hours agorootparentdev meetup lightning round? reply arccy 12 hours agorootparentprevhn reply xboxnolifes 9 hours agorootparentSo people should advertise on hn instead of cold calling? reply RigelKentaurus 15 hours agoparentprevAgreed that it's not a good strategy, but unfortunately all too common amongst tech companies, especially startups. reply gedy 15 hours agoparentprev\"LambdaTest\" does that crap and will call even on weekends. I'm like gtfo of here man. Testing tools is like the last thing I want to talk about on weekend or on personal phone. reply johann8384 6 hours agoprevSo what's going to happen to the sock shop now? reply hipadev23 15 hours agoprevWeaveworks lays off 100% of staff. What was the headcount? ~50 people? reply yebyen 10 hours agoparentIt was over 100 at the peak, I'm not sure how many of us were left last month. You're not far off. reply hipadev23 9 hours agorootparentBrutal. Well, best of luck to you all reply mathattack 4 hours agoprevIt’s a pretty awful note. “ The company was turning over double digit (>$10M) revenue and had more than doubled the number of new product logos in 2023.” Sounds like he was measuring the wrong things. “I could say that this should not have happened, but I know that we are not alone in this market.” Sounds like he’s justifying his failure by point at others in the market. Written like a Wall Street trader. Oh wait… reply ShamelessC 6 hours agoprevCan someone please explain what this company actually did? I’m not a cloud person per se, but I find it strange that I’ve never heard of them given the overwhelming number of people here who are familiar. reply bboreham 2 hours agoparentOutside of the Containers / Cloud Native world, not much. But they were the 10th-biggest contributor to Kubernetes as of 2020, which for a ~50-person company is something. Weaveworks created “GitOps” as a buzzword. Weaveworks created and/or substantially funded these Open Source projects: - FluxCD - Cortex (scalable Prometheus) - Weave Net - Weave Scope (seen in 2023 KubeCon keynote) - EKSctl - Kubeadm - Kspan Plus many others. reply fxtentacle 15 hours agoprev [–] \"a very promising M&A process with a larger company fell through at the 11th hour. And so we decided to shut down\" reply JojoFatsani 13 hours agoparent [–] Sad that some of the folks behind Weave didn't get a possibly life-changing exit. reply makkes 3 hours agorootparent [–] The acquisition talked about in the original post wasn't much more than a life-saver for the company so in that regard you could call it life-changing in that many of the fine folks I worked with wouldn't have lost their job. It would have been very very far from what you usually call an exit, though. Nobody would have cashed out, except maybe some of the VCs and I'm not sure if they'd have called it a successful exit in terms of financial win. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Weaveworks, a cloud native company, is shutting down its operations despite having strong revenue and a growing customer base.",
      "The closure was due to a volatile cash position and a failed merger and acquisition deal.",
      "Efforts are being made to ensure the continued development and maintenance of Weaveworks' open-source software, particularly CNCF Flux.",
      "Industry professionals are disappointed by the news, as Weaveworks has made significant contributions to the cloud native ecosystem."
    ],
    "commentSummary": [
      "Weaveworks, a startup focused on Kubernetes management tools, has shut down despite significant revenue and funding.",
      "The CEO's LinkedIn post suggests they were aiming to appear more attractive for acquisition.",
      "This raises questions about decision-making and the \"shoot for the moon\" mentality prevalent in startups, where growth often takes priority over profitability."
    ],
    "points": 244,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1707149210
  },
  {
    "id": 39260760,
    "title": "Visit Hacker News on a Random Day",
    "originLink": "https://randomhackernews.com/",
    "originBody": "Hi HN. I was surprised that there wasn&#x27;t a feature here that lets you go back in time to the front page of Hacker News on a random day...so I made one. http:&#x2F;&#x2F;randomhackernews.com is a simple HTML page that navigates you to the front page of HN on a random day between today and February 19, 2007 (the oldest date I could find with content).I made this for myself, but figured others may find some interest in it.",
    "commentLink": "https://news.ycombinator.com/item?id=39260760",
    "commentBody": "Visit the front page of Hacker News on a random day (randomhackernews.com)240 points by nickipedia 21 hours agohidepastfavorite74 comments Hi HN. I was surprised that there wasn't a feature here that lets you go back in time to the front page of Hacker News on a random day...so I made one. http://randomhackernews.com is a simple HTML page that navigates you to the front page of HN on a random day between today and February 19, 2007 (the oldest date I could find with content). I made this for myself, but figured others may find some interest in it. dang 15 hours agoI'm happy to see people looking at /front?day=yyyy-mm-dd because it's a trove of great stories and threads. It's linked from \"past\" in the top bar, if anyone didn't know. Please realize that it isn't an exact representation of the front page at any particular time. For that you'd want a point, not an interval, and certainly not a 24 hour interval, which is what /front?day=yyyy-mm-dd is showing. What's it called when you make a single photograph by overexposing a series of time-lapsed frames into one? It's like that. I found it trickier than I expected to write the code to do this, but I think the result serves its purpose: to give people a way to find frontpage stories they may have missed. We do this via a combination of votes and frontpage time, but only back to 2014-11-11 which is when we started logging the lists of stories on the front page. Those are the 'frames' in the above analogy. Before 2014-11-11, we only rank by votes because it's all the data we have. If you want to look at actual snapshots from the past, archive.org has a lot of them, e.g. https://web.archive.org/web/20160620131548/https://news.ycom.... Perhaps OP could add random links to those as well! reply mwilliamson 11 hours agoparentMy favourite date is Erlang Day, after a request from pg to have more technical content: https://news.ycombinator.com/front?day=2009-03-11 reply gala8y 2 hours agorootparentThat's too funny. Unfortunately, jumping across timelines reminds us of digital decay, a very real thing, when you try to visit some old stuff. reply dang 9 hours agorootparentprevThere was an Erlang Day sequel later that summer: https://news.ycombinator.com/front?day=2009-08-20, which I remember because I unintentionally started it and pg got mad at me. IIRC, the front page before that was filled with stories about _why (they're split between https://news.ycombinator.com/front?day=2009-08-19 and https://news.ycombinator.com/front?day=2009-08-20 now), and people were complaining about that. I happened to have an Erlang article I'd already been meaning to post, so I posted it and it triggered a deluge, followed by complaints: Ask NH: How annoying is Erlang day? - https://news.ycombinator.com/item?id=776789 - Aug 2009 (0 comments) Why is all the news about Erlang today? - https://news.ycombinator.com/item?id=776622 - Aug 2009 (4 comments) Are we celebrating Erlang's birthday or just that Erlang hackers cracked HN? - https://news.ycombinator.com/item?id=776519 - Aug 2009 (4 comments) Poll: What do you think of Erlang on Hacker News? - https://news.ycombinator.com/item?id=776427 - Aug 2009 (3 comments) Enough Erlang - https://news.ycombinator.com/item?id=776316 - Aug 2009 (9 comments) Purge Complete: No more Erlang, _why, or Zed - https://news.ycombinator.com/item?id=776196 - Aug 2009 (25 comments) I hate the Erlang days around here..... - https://news.ycombinator.com/item?id=776116 - Aug 2009 (9 comments) Are we intentionally voting on Erlang articles? - https://news.ycombinator.com/item?id=776047 - Aug 2009 (6 comments) ... followed by pg, after a long day at Demo Day, manually killing all those threads at dinner using his iPhone. Nobody knew about that latter bit. How did the Erlang articles disappear on HN yesterday? - https://news.ycombinator.com/item?id=778319 - Aug 2009 (11 comments) I always wondered why I couldn't find any trace of this in the archives, as I distinctly remember the scolding I got! I've gone and unkilled them now, which should restore roughly what it looked like. reply jychang 12 hours agoparentprev> What's it called when you make a single photograph by overexposing a series of time-lapsed frames into one? Long exposure reply codetrotter 12 hours agorootparentBut not quite that either right? That’s what you have if you mechanically keep the shutter open for a prolonged time, exposing either film or a sensor to light. But from what dang was saying, he seemed to describe emulating that effect in software on discretely captured frames. Sounds almost closer to onion skinning, and in particular the part of this article https://en.wikipedia.org/wiki/Onion_skinning where they say: > This effect can also be used to create motion blurs, as seen in The Matrix when characters dodge bullets. reply rifty 10 hours agorootparentSuperimposition[1] is the concept that comes to my mind. [1]: https://en.wikipedia.org/wiki/Superimposition reply codetrotter 9 hours agorootparentYeah, that’s the best description I think reply azhenley 11 hours agorootparentprevIt is called stacking. reply elpocko 17 hours agoprevHere's a bookmarklet that does the same thing: javascript:(()=>{d=new Date(1171843200000+Math.random()*(Date.now()-1171843200000));window.location.href=`https://news.ycombinator.com/front?day=${d.getFullYear()}-${('0'+(d.getMonth()+1)).slice(-2)}-${('0'+d.getDay()).slice(-2)}`;})() reply robrenaud 12 hours agoprevI wonder if this would make a fun game, like geoguessr. You see the HN page from a random day, perhaps with some date scraping to remove super obvious clues, and you have to pick the year/month. reply BlueTemplar 11 hours agoparent> Man saves wife’s sight by 3D printing her brain tumor + > [US president] calls for municipal broadband + > A Quick Comparison of [...] vs. Rust + > I built an iOS remake of that old [...] game [...] + > [...] Tops [...] as World’s #1 [...] Platform + > Student [...] AI [Competition] [Year] + > Bitcoin crashes over [X]% in 24 hours, under $[Y] + > Frameworks are for hacks, libraries for seeds (Of course for some of the above it would likely be trivial if you just copy-paste them in a search engine...) reply urbandw311er 9 hours agoprevCool - nice idea. Can I make a feature request? Automatically offer an alternate fetch of a post’s target URL from the Internet archive. The first post I found (from 2012) was supposed to be the letter that Apple published on its website apologising for how terrible the new Apple maps app was after its divorce from Google. But Apple has removed that from their website now, so it was just a 404 - an auto fetch from the Internet archive would have been very handy. reply Brajeshwar 18 hours agoprevFeb 19, 2007 was indeed the day Hacker News came to be - https://news.ycombinator.com/front?day=2007-02-19 reply dang 15 hours agoparentIt was running in stealth from https://news.ycombinator.com/front?day=2006-10-09 thru https://news.ycombinator.com/front?day=2006-10-22, with a few gaps. Then https://news.ycombinator.com/front?day=2006-12-14 with one story: \"Productivity Surges During Reddit Downtime\" (not much has changed, as PhilipRoman said...) And then https://news.ycombinator.com/front?day=2007-02-19, as you say, which was the public launch. Let me dig up the link...here it is: https://news.ycombinator.com/announcingnews.html And then https://news.ycombinator.com/hackernews.html 6 months later. I posted links to Startup News pages the other day: https://news.ycombinator.com/item?id=39237746. We should make the top left say \"Startup News\" for /front?day=2007-08-13 and earlier! reply PhilipRoman 17 hours agoparentprevHaha, the core of this website really hasn't changed, has it? > Why Startups Don't Condense in Europe > DabbleDB -- web-based DBMS coded in Smalltalk dead comment: > Fedora is far better than ubuntu reply raphinou 16 hours agorootparentWow, gave a strange feeling to see DabbleDB mentioned. I had launched a product in the same category. It didn't get traction, and I lost interest in it for some time, but I kept it running and it's still available and has just been rewritten in F#. My problem now is the same as nearly 20 years ago, find its niche. I'm thinking of making a Ask HN about that. reply sph 17 hours agorootparentprevDissing Ubuntu in 2007 is a bit prescient: it was one of the best distros around, and Fedora (Core) a buggy mess. reply Pathogen-David 15 hours agoparentprevI counted 14 out of 30 links on the front page back then still work and appear to refer to the same article / something relevant to the original submission. Link rot is always disappointing, but I actually expected it to be far worse for links from 17 years ago. reply jimmytucson 15 hours agoparentprevAnd here's the archive[0] of the top post[1] from the following day[2], \"Why we made this site\" [0] https://web.archive.org/web/20070222125635/http://ycombinato... [1] https://news.ycombinator.com/item?id=189 [2] https://news.ycombinator.com/front?day=2007-02-20 reply boringg 17 hours agoparentprevWhere there any success stories that came out of Stanford start up school? Or was the success Stanford monetizing the process? reply mousetree 17 hours agoprevYou can use this link[1] and include a random day, no? [1] https://news.ycombinator.com/front?day=2023-03-04 reply nraford 3 hours agoprevThis makes me wonder, has anyone scraped all of HN's archive and done any LLM thematic, textual or other kind of content analysis? Seems like it would be such a useful data source for the rise and fall of various tech trends, industry sentiments, and so on. The pulse of the Valley, even... reply ks2048 14 hours agoprevNice work. Slightly related question: say one hasn't visited HN in a few weeks and wants to see something like the top N posts of a given week. Does this exist? reply CrypticShift 13 hours agoparentYou can use a custom range on hn.algolia.com [1]. [1] https://hn.algolia.com/?dateEnd=1707004800&dateRange=custom&... reply alentred 12 hours agoparentprevAs an alternative, you may subscribe to the Hacker Newsletter: https://hackernewsletter.com/?ref=find-your-newsletter reply Brajeshwar 6 hours agoparentprevNot exactly that way, that I know but the Top Links should do enough justice for that https://news.ycombinator.com/best reply BlueTemplar 11 hours agoparentprevThere used to be http://n-gate.com/ ( :p, but also RIP TT ) reply doodlesdev 8 hours agoprevLink rot makes reading some of the older things a bit sad. The website brought me to a HN front page in 2011, but from the five URLs I tried, I managed to read absolutely none of them. Although I must admit, the quality of that front page was pretty awesome (Google's Dash language, #newtwitter, Google's Oracle case, Windows 8 boot times, CoffeeScript and a lot more). If anyone is interested in any of these: https://news.ycombinator.com/front?day=2011-09-09 It's fascinating, too, to see some predicted solutions to problems discussed at the time that came true but were different from what was expected. For instance, we finally got an alternative to JavaScript in the browser recently, but it's not CLR, JVM, or NaCL like many imagined; instead, we got WebAssembly, which is pretty good but has basically failed as a true alternative to JavaScript for now. reply tamimio 11 hours agoprev> Youtube remains unprofitable 3 years after Google acquisition (dealbook.blogs.nytimes.com) 2009/July reply mustak_im 13 hours agoprevNice! slightly related: If you'd like to see a screenshot taken of the pages on that day, then use the extension: Chrome: https://chrome.google.com/webstore/detail/hacker-news-previe... Firefox: https://addons.mozilla.org/en-GB/firefox/addon/hacker-news-p... App: https://spa.hackernews.xyz/ reply ketanmaheshwari 12 hours agoprevI created one too a while ago: https://github.com/ketancmaheshwari/randhn reply abnercoimbre 13 hours agoprevI also see value here for anyone looking to boost their credibility if needed. \"Yes Jim, my project did in fact hit the front page - take a look.\" reply keithalewis 10 hours agoparentOh yeah? Well I was Time magazine Person of the Year in 2006! reply jmckib 10 hours agoprevThis is great, and I wish it existed for Reddit too (or maybe it does already?). There’s so much good content that’s a bit hard to find now, plus it would be very interesting to see what people were talking about at a specific point in time. reply wkjagt 11 hours agoprevFirst thing I did was relive a moment almost 10 years ago when I had a Show HN on the front page :-) reply wscourge 3 hours agoprevI went there once and found something useful. Kudos. reply bspammer 10 hours agoprevI found this thread from 2008 about Meta's $4b(!!) valuation entertaining :) https://news.ycombinator.com/item?id=266755 reply vanattab 9 hours agoprevHmmm... I looked through the Oct 7, 8, 9th 2023 top stories as a community we apparently missed the entire Gaza conflict. reply hk__2 16 hours agoprev> I was surprised that there wasn't a feature here that lets you go back in time to the front page of Hacker News on a random day May I ask why were you surprised? Which other website has this feature? reply odensc 14 hours agoparentNot exactly the same, but in the same vein, Reddit has a \"Random\" button that takes you to a random subreddit. Google has \"I'm Feeling Lucky\" which gives you a random search. A \"random\" button seems like a relatively common little easter egg. reply pbhjpbhj 14 hours agoparentprevThis sort of thing is a feature I often feel is missing, sites have \"last week\", \"last month\", etc., and you can see what stories have been top. But you can't then go back to last month and see what the top 'stories' for the preceding month were. reply jraph 11 hours agoparentprevSurprised by the surprise too but why not, but to answer, xkcd.com has it. reply pimlottc 13 hours agoprevIt would be great if HN automatically added a \"wayback machine\" link for articles over, say, one year ago. reply sureglymop 13 hours agoprevJust yesterday I realized that post and comment ids are incremental and went back to look at the first year of posts! reply mattigames 9 hours agoprevRandom day is a bit overkill in my opinion, in the sense that there are too many days to explore, I would be more interested in random week, as in the most upvoted that week, as url that could be something like /front?week=34&year=2024 reply arcticbull 9 hours agoparentIf you'd prefer some additional constraint, consider that today is a random day and you can simply go to the front page :) this reduces the number of days to explore to just one. reply mattigames 4 hours agorootparent...another nice feature would be to be able to hide the comments by some users. reply Liftyee 12 hours agoprevClicked all the links on today's front page? Just go here for more. reply sujayk_33 17 hours agoprevPlease make it open in a new tab, that'll make more sense (I suppose). It's not pleasing to go back to use it again. reply jraph 11 hours agoparentNot usually a good idea to mess up with the default, and you can always middle-click or ctrl+click or cmd+click or long press. If you open in new tab by default you risk breaking user expectations, disorient them and you break users wanting to open in the same tab. reply digging 10 hours agorootparent> If you open in new tab by default you risk breaking user expectations, disorient them and you break users wanting to open in the same tab. This feels backward to me. I don't do user research, but is that a real pain point? Just... close the old tab? reply jraph 8 hours agorootparentI won't be as good as the person behind css-tricks [1] and definitely not an UX expert, only interested in the topic, but let's try: - I'm tech savvy enough and want to open in the same page: you are preventing me from doing it easily, while it's easy for you to open it in a new tab if you want it this way. - I'm not tech savvy. I barely know to use a browser. The link opened in a new tab and I didn't notice. The back button I know to use is greyed out. I'm confused. Said differently: you can always open normal links in new tabs. I do it all the time, to the point I almost never understand someone requesting a link to open in a new tab: help yourself, it's so easy. Don't rely on the page author to make the call for you because they can't please everyone. However, target=_blank links are harder to open in place, while it's reasonable to want and expect a link to behave normally. I get a bit mad when for some reason a new tab was opened and I didn't want to nor I expected it. Just leave me alone, you know. If I don't want to come back to the previous page, or if I want to do it using the familiar back button (or gesture), you should not force me to close the previous tab and break my history buttons. Moreover, nothing usually tells you that a link is going to behave differently as you expected (principle of least surprise), and even if it does, I shouldn't have to install an extension or fiddle with the web dev tools to work around this and get the default and expected behavior, that's terrible UX for obvious reasons. Deviations from the default behavior are sometimes better / necessary but you always risk causing surprise and thus confusion, which you should also avoid for good UX. Even someone who want to open the link in a new tab probably expects a link to open in place. It's usually impossible to know in advance if users will prefer opening a particular link in a new tab, especially since different users will have different preferences in the general case. As a user who will sometimes prefer a new tab, it's also uncomfortable to rely on the author of the page to make the call so you may as well just help yourself. So, for good UX, the normal behavior is supposed to be the best option, unless in specific cases like those discussed in [1], basically when the confusion or frustration caused by the normal behavior is greater than for the new tab behavior, like loss of work or disrupted playback. I don't know if there are proper studies about links specifically, but I'd expect existing research to prove the principle of least surprise, generally accepted as basic UX principle. I'm a bit lazy to find such work, on a phone during a small insomnia, I hope you'll forgive me. A \"(opens in a new tab)\" tag partially fixes the issue but doesn't fully address it. [1] https://css-tricks.com/use-target_blank/ reply nickipedia 15 hours agoprevThanks for the feedback everyone! I've updated the website to open HN in a new tab reply sujayk_33 14 hours agoparentI have one more suggestion, make that title more catchy, you can try such as 1. HN Lucky Dip 2. HN Roll Does anybody want to give it a try? reply geniium 11 hours agoprevReally cool to jump in the past. Thanks for making that! reply ipaddr 15 hours agoprevWhat a gem 2010 was. reply cocoflunchy 13 hours agoprevFunny article (in retrospect) from 2010-09-23 (https://news.ycombinator.com/front?day=2010-09-23): Facebook is not worth $33B https://signalvnoise.com/posts/2585-facebook-is-not-worth-33... reply emp_ 13 hours agoprevSpotty memory but the two posts that made me check HN daily were: - How do you store data to last more than 50 years (diamonds and titanium were mentioned) - The announcement that bitcoin reached 1 USD, a great party story (TL;DR I tried buying 100, had issues w/ payment, got pissed, bought 200 instead, lost wallet a few months later, would have sold it super early tho) reply moffkalast 14 hours agoprevWhoever figured that caching will save HN's perpetually melting server is about to have a heart attack. reply dang 14 hours agoparentI was worried about that too, but it seems to be holding up ok! reply pazimzadeh 14 hours agoprev10-06-2011 was different reply perilunar 7 hours agoparent10 June or October 6? reply mkl 7 hours agorootparentI think they mean Steve Jobs's death, October 6: https://news.ycombinator.com/front?day=2011-10-06 reply pazimzadeh 4 hours agorootparentyes reply breakfastduck 9 hours agoprevAmazing way to browse the site, well done reply nwhnwh 10 hours agoprevLovely reply firebaze 10 hours agoprevHow does this belong on HN frontpage? This is not just trivial, as another commenter 6 hours ago (!) posted: https://news.ycombinator.com/item?id=39262873 It's not hacker, it's not news, it's not innovative, it's simply boring, and would be cool if a 10 year old did this. Sorry for this rant, but I'm reading on and off HN over ~10 years and contributing under various user names, and I read comments like mine over and over again, and each time agreeing more. Maybe everyone who definitely will downvote my post should read the first guideline \"What to submit\": On-Topic: Anything that good hackers would find interesting. That includes more than hacking and startups. If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity. A random() over the time HN exists, with a link to the generated date, which doesn't even handle back correctly is not something good hackers find interesting. On the other hand, there are still lots of on-topic, curiosity inducing topics around here. Just getting scarcer every year. Oh my. Good night :) reply ToValueFunfetti 10 hours agoparentWhat is interesting here is not the effort that went into the thing (although I am now planning a rewrite in Rust ;), but the output. Assuming it is true that HN standards for 'interesting' are falling, as you say, clicking on the link will tend to present you with a more interesting edition. Assuming it's not, it's still fascinating to look into a time capsule like this. reply sph 17 hours agoprev [–] Please do not hijack the back button. Your website should send a 307 Temporary Redirect to HN, so when I go back, I return to where I was, instead of being sent to another random day. If it is done on the client, look into `window.location.replace`: https://developer.mozilla.org/en-US/docs/Web/API/Location/re... reply sneela 17 hours agoparentIt's incredibly annoying when this isn't taken care of. Alt + Left Arrow becomes impossible to use and I have to resort to using my mouse. Don't Microsoft's support pages [1] do this as well? I just checked with a random support page [2] and it looks like the middle redirection url is the same. Is that a different thing? [1] support.microsoft.com [2] https://support.microsoft.com/en-us/windows/fix-file-explore... (Firefox if that matters. Currently on Linux, has happened on Windows) Edit: I just checked on Ungoogled Chromium and it looks like this (the microsoft support) isn't an issue. It's only on Firefox. That's bizarre. reply hunter2_ 16 hours agoparentprevNo issue on my end. Is it already fixed, or does Android Chrome just overcome poor implementations? reply sneela 16 hours agorootparentLooks like it's a firefox thing. I tested in Ungoogled Chromium and it works fine for me too. reply garyfirestorm 16 hours agoparentprev [–] Can confirm this behavior on iPhone 15 pro max safari ios 17.3 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The user has developed a website that lets users explore the front page of Hacker News from a random day between today and February 19, 2007.",
      "The website was initially created for personal use but has now been made available to the public, as the creator believes it could be of interest to others.",
      "Users can experience the headlines, discussions, and activity on Hacker News from various dates in the past through this website."
    ],
    "commentSummary": [
      "The Hacker News discussion thread in August 2009 covers a range of topics including browsing preferences, frustrations with link behavior, and the value of web history features.",
      "Users express dissatisfaction with link rot on the website and discuss the prevalence of news about Erlang.",
      "Other discussions include the Stanford start-up school, analyzing the Hacker News archive for data, and the profitability of YouTube. Technical issues with Firefox on Linux and Windows are also reported."
    ],
    "points": 240,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1707137787
  },
  {
    "id": 39260614,
    "title": "UUID v7: Summary of Home Commitfest 2024-03 Review Process and Attachments",
    "originLink": "https://commitfest.postgresql.org/47/4388/",
    "originBody": "Home Commitfest 2024-03 UUID v7 Log in UUID v7 Edit Comment/Review Comment Review Change Status Open statuses Needs review Waiting on Author Ready for Committer Closed statuses Rejected Withdrawn Returned with feedback Move to next CF Committed Title UUID v7 Topic Server Features Created 2023-06-22 17:29:56 Last modified 2024-02-01 18:16:38 (4 days, 15 hours ago) Latest email 2024-01-30 18:37:56 (6 days, 15 hours ago) Status2024-03: Ready for Committer 2024-01: Moved to next CF 2023-11: Moved to next CF 2023-09: Moved to next CF 2023-07: Moved to next CF Target version 17 Authors Andrey Borodin (x4m), Kirk Wolak (kirkw) Reviewers Aleksander Alekseev (a.alekseev), Chris Travers (einhverfr), Nikolay Samokhvalov (nikolay), Przemysław Sztoch (psztoch)Become reviewer CommitterLinksEmailsAttach thread UUID v7 × First at 2023-02-10 23:57:50 by Andrey BorodinLatest at 2024-01-30 18:37:56 by Sergey ProkhorenkoLatest attachment (v17-0001-Implement-UUID-v7.patch) at 2024-01-30 13:35:28 from \"Andrey M. Borodin\"Attachment (v17-0001-Implement-UUID-v7.patch) at 2024-01-30 13:35:28 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v16-0001-Implement-UUID-v7.patch) at 2024-01-30 09:56:10 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v15-0001-Implement-UUID-v7.patch) at 2024-01-30 06:54:48 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v14-0001-Implement-UUID-v7.patch) at 2024-01-25 12:31:44 from Aleksander Alekseev(Patch: Yes) Attachment (v13-0001-Implement-UUID-v7.patch) at 2024-01-24 16:54:37 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v12-0001-Implement-UUID-v7.patch) at 2024-01-19 18:07:35 from Andrey Borodin(Patch: Yes) Attachment (v11-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2024-01-19 08:25:51 from Andrey Borodin(Patch: Yes) Attachment (v10-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2024-01-18 13:17:54 from Andrey Borodin(Patch: Yes) Attachment (v9-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2024-01-16 12:15:07 from Andrey Borodin(Patch: Yes) Attachment (v8-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2024-01-04 18:20:11 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v7-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2024-01-02 09:17:42 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v6-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2023-08-30 19:04:46 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v5-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2023-08-21 08:42:20 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v4-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2023-08-20 20:56:34 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v2-0001-Implement-UUID-v7-and-v8-as-per-IETF-draft.patch) at 2023-07-07 12:06:19 from \"Andrey M. Borodin\"(Patch: Yes) Attachment (v1-0001-Implement-UUID-v7-as-per-IETF-draft.patch) at 2023-02-10 23:57:50 from Andrey Borodin(Patch: Yes) HistoryWhen Who What 2024-02-01 18:16:38 vigneshwaran C (vignesh.postgres) Closed in commitfest 2024-01 with status: Moved to next CF 2024-01-25 12:05:56 Aleksander Alekseev (a.alekseev) New status: Ready for Committer 2024-01-24 13:34:23 Aleksander Alekseev (a.alekseev) New status: Needs review 2024-01-24 12:31:44 Aleksander Alekseev (a.alekseev) New status: Waiting on Author 2024-01-22 17:00:28 Przemysław Sztoch (psztoch) Added psztoch as reviewer 2024-01-22 15:03:08 Aleksander Alekseev (a.alekseev) New status: Ready for Committer 2024-01-22 15:03:02 Aleksander Alekseev (a.alekseev) Added a.alekseev as reviewer 2024-01-22 04:24:31 Nikolay Samokhvalov (nikolay) Posted review with messageid2024-01-22 04:22:37 Nikolay Samokhvalov (nikolay) Added nikolay as reviewer 2023-12-04 10:06:18 John Naylor (john.naylor) Closed in commitfest 2023-11 with status: Moved to next CF 2023-10-09 10:15:45 Chris Travers (einhverfr) Posted comment with messageid2023-10-09 10:06:02 Chris Travers (einhverfr) Added einhverfr as reviewer 2023-10-02 09:59:16 Peter Eisentraut (petere) Closed in commitfest 2023-09 with status: Moved to next CF 2023-07-06 12:24:27 Daniel Gustafsson (d_gustafsson) Closed in commitfest 2023-07 with status: Moved to next CF 2023-06-22 17:30:27 Nikolay Samokhvalov (nikolay) Changed authors to Andrey Borodin (x4m), Kirk Wolak (kirkw) 2023-06-22 17:30:27 Nikolay Samokhvalov (nikolay) Changed targetversion to 17 2023-06-22 17:29:56 Nikolay Samokhvalov (nikolay) Attached mail thread CAAhFRxitJv=yoGnXUgeLB_O+M7J2BJAmb5jqAT9gZ3bij3uLDA@mail.gmail.com 2023-06-22 17:29:56 Nikolay Samokhvalov (nikolay) Created patch record Edit Comment/Review Comment Review Change Status Open statuses Needs review Waiting on Author Ready for Committer Closed statuses Rejected Withdrawn Returned with feedback Move to next CF Committed × Flag as committed Committer Nathan Bossart Joe Conway Jeff Davis Andrew Dunstan Peter Eisentraut Andres Freund Stephen Frost Etsuro Fujita Peter Geoghegan Andrew Gierth Daniel Gustafsson Robert Haas Magnus Hagander Álvaro Herrera Tatsuo Ishii Amit Kapila Alexander Korotkov Tom Lane Amit Langote Heikki Linnakangas Fujii Masao Michael Meskes Noah Misch Bruce Momjian Thomas Munro John Naylor Michael Paquier Dean Rasheed David Rowley Masahiko Sawada Tomas Vondra Close Flag as committed × Attach thread Search Pick one of the recent emails from pgsql-hackers, or search above for subject or name: Or enter an exact message id: Close Attach thread × Add annotation Pick one of the messages in this thread Or copy/paste the message-id: Enter a message for the annotation Close Add annotation",
    "commentLink": "https://news.ycombinator.com/item?id=39260614",
    "commentBody": "UUID v7 (postgresql.org)219 points by Recursing 21 hours agohidepastfavorite171 comments samatman 11 hours agoI've said this before on HN, but we're talking about UUID v7 again, so it bears repeating: prefer UUID v4 for unique keying, of the sort that's transferable between databases. For timestamps, use timestamps, to sort by insertion, use an autoincrementing primary key. Disk space is not so expensive that we can't afford all three of these things. Conflating timestamps and uniqueness is a conflation. These concerns are best separate. If you put a timestamp in your UUID, your UUID now has a timestamp. You can't remove it if you don't want the timestamp to be a part of the uniqueness any more. reply tsarchitect 24 minutes agoparent(1) |------------------------------|-----------------------------|------------|----primaryKey (bigInt-internal)publicKey (uuidv4-external)created_at... |------------------------------|-----------------------------|------------|---- (2) |------------------------------|-----------------------------|------------|----primaryKey (uuidv4-internal)publicKey (uuidv4-external)created_at... |------------------------------|-----------------------------|------------|---- (3) |------------------------------|-----------------------------|----primaryKey (uuidv7-internal)publicKey (uuidv4-external)... |------------------------------|-----------------------------|---- (4) (not recommended) |---------------------|----primaryKey (uuidv7)... |---------------------|---- ---- (1) [X] sortable by insertion, [X] timestamp (2) All of (1) and [X] transferable between databases (3) Use UUIDv7 as a primary key for internal and UUIDv4 for external. App or SELECT statement will need to extract the timestamp from UUIDv7 if you need to use it. Also, if you're using a DB Client you can't just view the 'created_at' column to get an idea of when a row was created. (4) Use UUIDv7 as a primary key for internal & external use. reply oxfordmale 10 hours agoparentprevUUID7 offers several key advantages: - sortable by insertion - less vulnerable to sequence prediction attack - allows partitioning of tables in the future Sequence prediction attack is a problem when you want to use identifiers in a public API. For example, a user or competitor can iterate through your product catalogue by incrementing the key. Sorting by inserting is a common use case as well. You can achieve this with an auto-incrementing primary key, however, this will create issues when you need to partition the table. Of course, you may never need this functionality, but there is a reason UUID7 have been added, as they are very useful in certain scenarios. reply codr7 10 hours agorootparentI get the public API argument, but it certainly feels backwards to structure the internals of your application for that specific use case. Generating and mapping an UUID to your identifier when you need it is pretty straight forward and allows you to avoid exposing the identifier at all. Which leaves partitioning, something that very few applications will ever need, even if plenty of developers hope they will. A slightly less weird use case, but perfectly doable up to a point using regular sequences. I see a solution looking for problems. reply oxfordmale 10 hours agorootparentI have build many successful systems without ever using a GUID. However, at a certain scale they become very handy, and it then it definitely helps you can also sort them. reply sgarland 10 hours agoparentprevAs a DBRE, I care mostly about DB performance, and not getting paged / blamed for things out of my control. I fully agree and support that auto-incrementing integers should be used whenever possible. My preference for UUIDv7 over UUIDv4 is solely that they’re less likely to wreak havoc on the DB, if devs insist on having a UUID PK. reply The_Colonel 2 hours agorootparentIn most ORM apps you need to pre-allocate the integers to build the references in the object graph before actually executing these inserts. Doesn't this carry a performance penalty? reply klysm 10 hours agoparentprevI don't think you've provided any actual reasons to not use uuidv7 or addressed any of the disadvantages of having multiple keys. reply s4i 19 hours agoprevCan someone ELI5 what that \"UUID v7 support\" actually means in the title? I don't know how to navigate commitfest (nor would I probably understand the source code to begin with), but the reason I'm confused is that you can already use all the proposed draft UUID implementations in Postgres (as long as you generate the ID application-side). In fact, PG will happily accept any 128 bit ID to be inserted into a UUID column, as long as it's hex encoded – even the dashes are optional. reply didntcheck 18 hours agoparentI'm amazed at how \"we\" have managed to turn such a simple idea as \"128 bits is a large enough address space for uncoordinated generation to be essentially collision free\" into such a \"heavy\" concept with 7 different versions If you want to do something smart like encoding your node ID within the value, or prefixing a timestamp for sortability, then sure, do that in your application. No one else really needs to care how you produced your 16 bytes. Just do some napkin math to make sure you're keeping sufficient entropy I'm not sure \"UUID\" even needed to be a column type, versus a \"INT16\" and some string formatting/parsing functions for the conventional representation (should you choose to use that in your application). You could also put IPv6 addresses in the same type. Though I guess this depends on how much you think the database should encode intention versus raw storage in types reply hombre_fatal 18 hours agorootparent> No one else really needs to care how you produced your 16 bytes UUID isn't about how it's done, it's about what it is. Instead of everyone doing something differently, everyone can just comply with UUID. Instead of having to repeat it across your docs that the IDs of this entity are sortable, you can just say they are UUIDv7. If someone wants to extract the timestamp from your ID, they don't need to figure out which (32, 48, 50?) bits are the timestamp nor what resolution the timestamp has because you can tell them UUIDv7. You don't have to write your own validation functions because you can tell the database that this hex string is a UUID and it can do it for you. You're probably making the case for Sqlite here which is very minimal, but something more full-featured like Postgres, I prefer these conveniences. I can tell because whenever I use Sqlite in a case where I could've used Postgres, I regret it! reply 015a 12 hours agorootparentBut I feel the point is: None of that is a relevant concern IDs should take on. Most functional things related to e.g. embedding the record creation time within the ID is one of those \"that's cool, but I've never seen anyone do it\" kind of things. If you need to sort records by when they were created, there are probably three or four happened_at fields on the record you'd use (created_at in this case). If you need the exact time; those are there for that. Counter-argument: Well, you can save a few bytes on every record by getting rid of the created_at field and just using a UUIDv7. Maybe, but I've never seen anyone do it. What if you need to change the time the record was created? Are you planning to explain to all your integration providers the process of extracting a timestamp from a UUIDv7? What if you need to run complex SQL timestamp functions on created_at? Etc. Its cool, but it never actually happens. Once we enter the domain of \"using the node id or timestamp or something to reduce the probability of ID collision\", that's a totally reasonable responsibility within an ID's set of concerns. But, that's a very different need. > You don't have to write your own validation functions Why are we validating IDs? > but something more full-featured like Postgres, I prefer these conveniences. Agreed. I am a vocal UUID hyper-hater. UUIDs should be destroyed, and humanity would be (oh so slightly) better off if they had never existed. But, they're still a thing, and I think its cool that databases have hyper-specific types like this. My wish is Postgres would have other more sane automatic ID types and gen capability, in addition to uuid & autoincrement. reply arghwhat 11 hours agorootparentThe point of the timestamp in UUIDv7 is not to encode creation time, it is to provide some (coarse-grained) chronological sortability. Random primary keys are bad, but exposing incremental indexes to the public is also bad, and hacking on a separate unique UUID for public use is also bad. UUIDs are over-engineered for historical reasons, and UUIDv7 as raw 128 bits without the version encoding would be nicer. But, to the end-user it's just a few lost bits in a 128-bit ID with an odd standard for hyphenation. The standardization means you know what to expect as developer, instead of every DB rolling their own unique 128-bit ID system with its own guarantees and weirdnesses. reply 015a 10 hours agorootparentBut my point is: When is that standardization actually leveraged? Literally, tactically, what does \"you know what to expect as a developer\" mean? When is this standardization used in a fashion that enables more capability than just \"the ID is a string don't worry about it\"? The realistic answer is: it isn't, because pre-UUIDv7 there was literally nothing about the UUID spec that conferred more capability than just a random string. And, truly; people used them as \"just gimme a random string\" all the flipping time. The pipes of the internet are filled with JSON that contains UUIDs-in-a-string-field, 4 bytes wasted to hyphens, 1 byte wasted to a version number, none of that is in service to anyone or anything. reply arghwhat 2 hours agorootparent1. The other UUID versions are actually used. However, the expectations is in what the developer gets when generating it. Even \"random ID\" can be messed up if the author tries to be smart - e.g., rolling their own secret chronical sortability hack for their database but not telling you how much entropy and collision resistance you have left, or them hacking in multi-server collision resistance by making some bits a static server ID. People have reason to do those things, and oh boy do you want to know that it's happening. With UUID, over-engineered as it may be, you know what you're asking for and can see what you're getting - truly random, server namespaced, or chronologically sortable. 2. Being upset over 4 bytes wasted to hyphens but not being upset about JSON itself seems hypocritical. JSON is extremely wasteful on the wire, and if you switch to something more efficient you also get to just send the UUID as 16 bytes. That's a lot more than 4 bytes saved. Over JSON you can still base64 encode the UUID if it's not meant to be user-facing. reply masspro 11 hours agorootparentprev> hacking on a separate unique UUID for public use is also bad. Is it bad just because of the extra bytes used, or something else? reply arghwhat 10 hours agorootparentYou need to maintain a UNIQUE index and have two IDs, with the one set as primary key solely existing for on-disk ordering. It's a nasty hack. reply wiredfool 1 hour agorootparentPostgres doesn't use the primary key for on disk ordering. MySQL does. reply arghwhat 7 minutes agorootparentAh, good point. The concern about on-disk ordering then only applies to other databases. I suppose the index order may still be relevant for PostgreSQL? vivzkestrel 6 hours agorootparentprevwhat do you even mean by \"Why are we validating ids\"? zzzzyyyy-zyzy-zyzy-zzyyzzyyzzyy does this look like a valid ID? I could totally store this in the database if there was no validation involved reply sagarm 2 hours agorootparentFrom GP (and my) perspective, the useful part of UUID is that it's 16 bytes. This is usually for formatted as 32 hex digits with dashes in specific places. The version/variant bits are the pointless part. Of course if you put the 16 bytes on the wire you would still have some encoding (perhaps 22 base64 characters?) that requires decoding/validation, but in memory and in your DB it's just 16 bytes of opaque data. reply hulitu 12 hours agorootparentprev> Instead of everyone doing something differently, everyone can just comply with UUID. With which UUID ? UUID v1 ? UUID v2 ? UUID v3 ? ... UUID v7 ? reply akira2501 12 hours agorootparentUUID has the version number and variant number encoded in the generated UUID. You can just examine the UUID to determine which version it is. reply Lammy 11 hours agorootparentThe UUID specs are still confusing (or at least were to me lol) because the words \"version\" and \"variant\" both just say that something changes, not what is changing or why it's changing. version from Latin vertere \"to turn, turn back, be turned; convert, transform, translate; be changed\" variant from Latin variare \"change, alter, make different,\" In my own UUID/GUID code I have taken to calling them \"behavior\" and \"layout\", respectively: https://github.com/okeeblow/DistorteD/blob/NEW%E2%80%85SENSA... reply akira2501 9 hours agorootparent4.1.1 The variant field determines the layout of the UUID. That is, the interpretation of all other bits in the UUID depends on the setting of the bits in the variant field. As such, it could more accurately be called a type field; we retain the original term for compatibility. 4.1.3 The version number is in the most significant 4 bits of the time stamp (bits 4 through 7 of the time_hi_and_version field). The following table lists the currently-defined versions for this UUID variant. The version is more accurately a sub-type; again, we retain the term for compatibility. It's recognized in the RFC and all you've done is broke compatibility for fashion. reply Lammy 9 hours agorootparentNaming != compatibility. Nobody should be looking at my code except for me and it helps me remember it better so I'm not sorry 8) reply acchow 11 hours agorootparentprevUnless the random bits don’t follow those conventions. reply Lammy 11 hours agorootparentIt isn't a UUID if it doesn't contain those flag bits in their expected positions. A \"random\" UUID has only 122 bits of randomness for this reason. reply jandrewrogers 16 hours agorootparentprevIn practice, UUIDs are treated as an opaque 128-bit field. In any sufficiently complex system, there is no practical way to standardize on a single blessed version. Furthermore, all of the standardized UUIDs are deficient in various ways for some use cases, so there are a large number of UUID-like types used in large enterprises that are not \"standard\" UUIDs but which are better fit for purpose. This is deemed okay because there is no way to even standardize on a single UUID version among the official ones. Furthermore, there are environments where some subset of the UUID standard types (including each of v3/v4/v5 in various contexts) are strictly forbidden for valid security reasons. The practical necessity of mixing UUID versions, along with other 128-bit UUID-like values, means that the collision probabilities are far higher in many non-trivial systems than in the ideal case of having a single type of 128-bit identifier. There is a whole separate element of UUID-like type engineering that happens around trying to mitigate collision probabilities when using 128-bit identifiers from different sources, some of which you may not control. Having 128-bits is the only common thread across these identifiers which everyone seems to agree on. reply zeroxfe 12 hours agorootparentprevI think you're drastically underestimating the purpose and management of UUIDs in large scale systems. If you're building for a single application or data type, sure do your thing, have at it. If you're trying to coordinate UUID spaces and generation across thousands of different applications and data types, like large data pipelines, then this matters a lot. Also, having native database support (like indexing, filtering, etc.) improves efficiency for these types of workloads. reply pixl97 18 hours agorootparentprevBecause it turns out that trying to index/sort things by UUID doesn't work great. UUID, at least somewhere after version one isn't just some large number. Different parts of the field have different meanings depending on the specification. reply wongarsu 19 hours agoparentprevThe patch is adding functions for generating UUIDv7 in the database. Which you can already do, for example with the PL/pgSQL function from [1]. Or you can just generate them in your application code. As you mentioned everything else about UUIDv7 already works and didn't require any changes. It's really more about convenience, and maybe a bit of speed. 1: https://gist.github.com/fabiolimace/515a0440e3e40efeb234e126... reply s4i 18 hours agorootparentThank you! reply Scandiravian 19 hours agoparentprevPostgres can now auto-generate uuidv7, so you can define it in your schema and don't have to add the ID on the client side when doing an insert reply Skinetio 19 hours agoparentprevYes my expectation is that Postgres can do that than for you. Its still easier to have an autogenerate on than doing it externally reply figassis 18 hours agoparentprevOn a distributed application, your application might need proper time synchronization for the time component. Not when it is generated DB side. reply throw0101a 20 hours agoprevRelated on the front page, \"UUID Benchmark War\": * https://ardentperf.com/2024/02/03/uuid-benchmark-war/ * https://news.ycombinator.com/item?id=39254871 reply jmull 18 hours agoprevWord to the wise: be very careful about adding semantics to unique ids that aren't inherent to the identity of the thing being identified. Over time conflicts between the id's primary job (uniquely identifying something) and the extra semantics can arise, and the solutions tend to get pretty messy. Here we have a unique id that embeds a timestamp. The classic conflict here is with privacy/security. A UUIDv7 user id tells you when the user was created. A UUIDv7 of a medical record tells you when some medical event occurred. There are things whose identity is inherently time-based and not private, so I'm not giving a blanket recommendation to not use these. Just understand what you are signing up for. For a database, you can use bigints for primary ids but only internally. Then you also have an external random (v4) uuid... and a timestamp if you want, for that matter -- now that it's a separate column, you can expose/hide it on a case-by-case basis, depending on need. So this gets you the benefits of a uuidv7 but maintains flexibility, though at the cost of some complexity and extra bytes/record. Other conflicts can arise too, and they can be hard to always foresee, so generally be careful about extra semantics in unique ids. reply personomas 17 hours agoparentIt looks like you're explaining this well, but I still don't understand what you're saying. reply spamizbad 14 hours agorootparentAt my company we had a competitor scrape our API for various businesses. One of the fields was an bson ObjectId that represented when the customer entered our system. This unique identifier encodes a timestamp of its creation. Our competitor was able to ascertain, based on that timestamp, when our customers contract was up and was (briefly) able to poach some customers by underbidding us until we corrected this. reply taftster 10 hours agorootparentWow. I'm amazed by stories like. I'm so naively the \"take the high road\" kind of guy, that I just assume everyone (or every company) should just do the right thing. Stealing customers in this way from a competitor, I have no ability to rationalize such an action. And this kind of makes me scared, like if I were to ever own a business, I just know I'm swimming with sharks with no ability to defend. I believe your story, but it's just crazy to me. Go earn a customer's business in a legit way, not be stealing data from a competitor. reply Dylan16807 7 hours agorootparentGiving someone an offer when their existing contract is running out isn't that shady. Lots of companies ask for that. It shouldn't be hard to rationalize! reply oluwie 9 hours agorootparentprevUhh ... that's entirely what business is about. Some shady methods maybe, but also some pretty good customer acquisition methods reply spamizbad 8 hours agorootparentprevHonestly I didn't even think of it when I first wrote the endpoint. Our founder asked me \"Is there anything we're sending over the API that might clue someone in when someone signs up? Are we sending a createdAt field or something?\" and I said \"No, but we do have a timestamp in one of the IDs...\" -- well, we removed the field and this behavior stopped soon after. Anyway, the arc of the universe bends toward justice: this (former) competitor got sold for parts a few years later. reply 698969 7 hours agorootparentprevIsn't the real issue here that your competitors had the authorization to see the contracts you had with other customers? reply jandrewrogers 16 hours agorootparentprevThe event timestamps embedded in the UUID can be correlated with external event streams, or even with other events within the same dataset, to de-anonymize the context of the event associated with the UUID. This is a common class of de-anonymization attack. Anything that allows temporal correlations to be inferred potentially leaks quite a lot of info about the data underlying the unique ids. reply sgarland 17 hours agorootparentprevThey're saying that in certain circumstances, if your API exposes the PK publicly, it may leak information you don't want leaked (the precise datetime something occurred, in the case of UUIDv7). If that's an issue for you, you can get around this in a variety of ways, as they mention: you could use an associative table that maps the externally-exposed random ID to an internal-only ID. reply remus 17 hours agorootparentprevBe careful about combining 2 pieces of information in to 1 column. From the above examples, you may want something to uniquely identify a record in your db and you may want something that tells you when the record was created. If you combine these two things, you then have a problem if you want to give an untrusted party that unique reference without telling them when it was created. reply nomercy400 17 hours agorootparentprevDon't use UUIDv7 if you want to keep the creation time of the event/id/entry private. reply akira2501 12 hours agoparentprev> A UUIDv7 of a medical record tells you when some medical event occurred. It tells you when the event was documented. If the event didn't contain a date time stamp itself, I would be highly surprised, because what other value is there in documenting it? The security problem here is inherent in the practice and your choice of primary key isn't a material factor at all. Do you imagine there's a public CRUD database with simple Rails style accessors that can drill all the way down to individual event records inside my health information? And that, somehow the leak of a primary key in a URL might give away the fact that _something_ happened to me, medically, 12 days ago? reply ivan_gammel 11 hours agorootparent>And that, somehow the leak of a primary key in a URL might give away the fact that _something_ happened to me, medically, 12 days ago Just as a side note: it may also leak the location, not just the time. An that is enough e.g. for disproving an alibi or leaking an important commercial secret (if you are in the same location as competitor HQ, for example). reply akira2501 9 hours agorootparentUUIDv1 is the only one that specifies a MAC address to be included in the UUID. All others specify timestamp data, pseudo random values, or MD5/SHA1 string hashes. I cannot rightly apprehend the scenario you are describing. A medical provider might generate a UUIDv1 and add it to a record of mine, and this will somehow destroy my ability to have an alibi in court with respect to corporate espionage? I'm not in a bond movie, I just need to keep track of events and have them sort in chronological order reply ivan_gammel 8 hours agorootparentI‘m just pointing out that an identifier with timestamp in certain situations can leak more than just timestamp. E.g. an identifier of medical record in the hospital which location is known. Just this. The exact scenarios of how it can be leaked and how this information can be used are left to your imagination. The possibility of such attack depends on what’s at stake. reply sroussey 17 hours agoparentprevFor good security, you don't leak internal IDs at all, sure. It is rare to find people doing that. And random primary keys (or any key really, and even more so for clustered indexes PK) really trash a db cache and locking systems. reply fastball 17 hours agorootparentIDs should just be IDs. You should be able to hand out your IDs on the street corner without compromising security. If knowing IDs has a negative impact on security, you've designed your system improperly. reply lazy_moderator1 15 hours agorootparentI couldn't agree more! reply rizky05 16 hours agorootparentprevAn ID is like social security number. When you give it away on the street corner, who knows what other people will do with it. IMHO, leaking an ID always impose a risk. It is always have negative impact if leaked, no matter how perfect your system is. reply ryanbrunner 12 hours agorootparentYou're almost always going to have to leak some sort of ID in an API, otherwise your API is going to be exceptionally hard to work with. You could choose to have a separate external ID, but provided that knowledge of an internal ID doesn't convey any information or additional privilege, it's not that big a deal. reply siva7 14 hours agorootparentprevThat's hyperbolic. If your table ID poses security risks like a social security number, you've designed your system horribly wrong. reply siva7 16 hours agorootparentprev> For good security, you don't leak internal IDs at all, sure. It is rare to find people doing that. We must live in a different universe. I'd wager to say that over 90% of all backends leak their primary key when speaking to the front-facing client. reply CognitiveLens 13 hours agorootparentI think the statement was \"It is rare to find people doing good security\", not \"It is rare to find people leaking internal IDs\" reply emaro 13 hours agorootparentI read it as '[…] you don't leak internal IDs at all […]. It is rare to find people doing that [i.e. not leaking internal IDs]' reply teaearlgraycold 15 hours agorootparentprev99.9% reply mort96 12 hours agorootparentprev> And random primary keys (or any key really, and even more so for clustered indexes PK) really trash a db cache and locking systems. That sounds like a problem which should be solved by making database engines not assume keys have some sane ordering, not by putting timestamps in UUIDs. reply jandrewrogers 11 hours agorootparentThis is mostly correct but primary keys have to co-exist with the existing data infrastructure that is unlikely to be replaced for decades. It is quite possible to do cluster-style indexing on UUIDs through disk on a single server at rates of tens of millions per second, I do it every day, just not with your typical ordered-tree architectures. Many popular database engines are not designed to make this particular scenario perform well. reply BillinghamJ 16 hours agoparentprevI'm not sure why that'd inherently be a problem? Knowledge that some record exists about a medical event at a particular time is not too problematic, compared to _who_ it happened to reply joshgel 15 hours agorootparentvery rare diseases may be an exception, especially in known geographic locations. that can become identifiable (and is governed by HIPAA in the US) reply javier2 17 hours agoparentprevUsually when you want this property it is also a benefit that your events when ordered by primary key, also gives a rough ordering by time, no need for a secondary index reply lordgilman 20 hours agoprevIs the headline true at all? It was punted to the next commitfest on 2/1. It could easily keep getting punted like it has been for a ~year now. reply coldtea 20 hours agoparentIs it that hard to implement? Supporting an additional UUID version in PostgreSQL sounds like the most trivial change to implement (compared to anything that touches core backend, table management, replication, query schedulling, and so on). reply asabil 20 hours agorootparentThe UUID spec update has not been finalized yet. It would be quite unfortunate to end up with a UUID v7 in PostgreSQL that’s not quite the standardized one because the patch got merged too quickly. EDIT: here is the IETF working group page https://datatracker.ietf.org/wg/uuidrev/about/ Their milestone seems to submit the final proposal by March. reply Rafert 19 hours agorootparent> It would be quite unfortunate to end up with a UUID v7 in PostgreSQL that’s not quite the standardized one because the patch got merged too quickly. The chances of that seem extremely low at this point. The contents of a version 7 UUID have not changed since work started on RFC 4122 bis in October 2022: https://author-tools.ietf.org/iddiff?url1=draft-ietf-uuidrev... reply pgaddict 15 hours agorootparentThe chances may be low, but either it's a draft or a final version. There's clearly little pressure to rush this, considering it's not difficult to add a custom function generating UUIDv7 ... reply lordgilman 20 hours agorootparentprevThe patch is already written, it's on that page. The bottleneck in Postgres is reviewer bandwidth which is why it's been moved out of several commitfests. reply pgaddict 20 hours agorootparentI don't think reviewer bandwidth is the main issue for this patch. It's a 200-line change (considering C code, there's more in docs/tests), and the code is not overly complicated / sensitive (in the sense that it's very isolated and unlikely to break random stuff). For me the main challenge was that it's still considered a draft (AFAIK). It may be unlikely to change, but if it does I'd rather not have to deal with persistent UUIDv7 data generated per some previous spec. Also, if I really want/need UUIDv7, it's not that hard to create an extension that generates UUID in arbitrary ways, including the proposed v7. reply x4m 3 hours agorootparent+1 there's already well maintained extension https://github.com/fboulnois/pg_uuidv7 It's slightly different from recommendations by draft RFC version (there's no counter), but fully within spec requirements. From practical point there's no difference at all. reply ashconnor 16 hours agoprevUseful explanation on UUIDv7 https://buildkite.com/blog/goodbye-integers-hello-uuids reply hardwaresofton 17 hours agoprevIf you like this (I do very much), you might also like pg_idkit[0] which is a little extension with a bunch of other kinds of IDs that you can generate inside PG, thanks to the seriously awesome pgrx[1] and Rust. [0]: https://github.com/VADOSWARE/pg_idkit [1]: https://github.com/pgcentralfoundation/pgrx reply zukzuk 20 hours agoprevNo thread about UUID is complete without a plug for NanoID! https://github.com/ai/nanoid/blob/main/README.md reply sltkr 19 hours agoparentThat's a lot of words to say: “encode 126 random bits in base64 (url-safe variant)”. It seems the algorithm is equivalent to: function nanoid(alphabet=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_\") { return Array.from(crypto.getRandomValues(new Uint8Array(21)), i => alphabet.charAt(i & 63)).join(''); } (Maybe String.fromCharCode() is slightly faster than Array.join(), but I doubt it matters much.) On node.js it's even easier, since url-safe base-64 encoding is supported natively: Buffer.from(crypto.getRandomValues(new Uint8Array(16))).toString('base64url').substring(0, 21) Do we really need an entire Github project dedicated to a 1-liner? reply didntcheck 18 hours agorootparentAgreed, and I actually share the same view about \"UUID\" as a named concept itself. I wrote more in another comment, but in summary * Using uncoordinated random generation in a large address space for IDs is often a very useful idea * 128 bits is a good rule of thumb for \"will never ever collide\" * Making this into a heavyweight \"UUID\" concept, with it's own bespoke string format, and 7 different standard ways to generate them, feels like a ridiculous waste of cognitive effort that makes such a simple concept appear opaque and magic. If you want to encode other data (timestamp, node ID) in 16 bytes you can still do that of course. There's no need for anyone else to even know. Just do some quick calculations to ensure you haven't eliminated too much entropy reply j16sdiz 16 hours agorootparent> * 128 bits is a good rule of thumb for \"will never ever collide\" It depends. True random number are slow. Fast PRNG are prone to collision. That's why we have different specs and versions of UUIDs. reply Dylan16807 7 hours agorootparent> True random number are slow. Fast PRNG are prone to collision. Not in this decade. You can slam out a million securely random 128 bit numbers per second per core. For numbers you will store, the effort to store them is orders of magnitude greater than the effort to generate securely. reply __s 19 hours agoparentprevNot sure it's too relevant for postgres, where uuid is 16 bytes in db & can be generated by db reply swrobel 3 hours agorootparentAlso not comparable to UUIDv7 because it isn't sortable reply naranha 20 hours agoprevDoes this stay compatible with the old uuid column type, as uuidv7() uses the same 128 bit format as gen_random_uuid()? That would mean it's easy to update old apps, as we would only have to change the default value for the columns. reply pgaddict 20 hours agoparentYes, internally it's the same as every other UUID (16 bytes, passed by reference). There's no reason to store / represent it differently. reply mplanchard 18 hours agoparentprevYes, we have already updated our in-app UUID generation to use v7 UUIDs and are storing them in regular postgres UUID columns (postgres 14). Works great! reply ghusbands 17 hours agorootparentNote that, as jmull says in https://news.ycombinator.com/item?id=39262286 , embedding timestamps in every uuid can potentially expose private information. reply Merad 16 hours agoparentprevYes, you can use v7 today with uuid columns, you just need to add a custom function (or the more performant pg_uuidv7 extension) to generate them. reply ComputerGuru 14 hours agoprevIt would be nice to have either fully integrated support for returning the UUIDv7 encoded in crockford's base32 or else ship a crockford's base32 encode/decode functionality in the same release so that this can be compatible with Ulid (given that it's one the primary open source existing works UUIDv7 was modeled after). reply simlevesque 12 hours agoprevIf you need a uuid v7 right now you can get one here: https://uuidv7.app/ reply qingcharles 11 hours agoparentThank the Gods. I was almost out. reply simlevesque 10 hours agorootparentAlways glad to help. reply presentation 24 minutes agorootparentWhoosh reply personomas 17 hours agoprevWhen will this be available? (Thanks in advance) reply hans_castorp 20 hours agoprevI wonder why the size of the table with uuid7 is smaller than the one with uuid4? Both are using the uuid data type. reply uhoh-itsmaciek 17 hours agoparentAs a sibling comment guessed, btree indexes in Postgres can store ordered data much more efficiently than random data. Inserting randomly ordered data leads to fragmentation, with lots of empty space on your index pages. reply sparsely 20 hours agoparentprevThe main data is the same, it's the primary key which is smaller, presumably a result of the structure of the uuid7 being more regular. reply sonium 19 hours agoprevYou probably should not use UUIDs to start with in your database at least not as an ID. UUIDv7 aims solve some of the issues of UUIDv4 that are even less suitable in for databases. 99% of times using BigInt for an ID is better. reply cjblomqvist 19 hours agoparentThere are some nice features of using UUIDs rather than ints. It's been written about before, a few on the top of my head: Client side generation of ids. No risk of faulty joins (using the wrong ids to join 2 tables can never get any hits with UUIDs, it can with ints). Those two sucks for us right now (planning to move to UUIDs). reply dankebitte 18 hours agorootparentUniqueness aside, UUIDs for public-facing IDs also prevent enumeration attacks and leaking business information other than timestamps. reply mdasen 18 hours agorootparentprev> No risk of faulty joins Wouldn't Snowflake IDs also solve that problem? A Snowflake ID will fit within a signed 64-bit int. https://en.wikipedia.org/wiki/Snowflake_ID The nice thing about a Snowflake ID is that you can encode it into 11 characters in base 62. If I have a UUID, I'm going to need 22 characters. Maybe that doesn't really matter given that 11 characters isn't something someone will want to be typing anyway and Snowflake IDs do require a bit of extra caution to make sure you don't get collisions (since the number you can make per second is limited to how big your sequence generation is). reply j16sdiz 16 hours agorootparentthe same idea, but this is a IETF standard. reply throwaway83623 17 hours agorootparentprevThe \"faulty joins\" can be solved by having a shared sequence for all tables. A bigint column should be enough for most use cases. reply j16sdiz 16 hours agorootparentshared sequence for all tables can't be parallelized reply CooCooCaCha 19 hours agoparentprevSorry but that’s terrible advice. I’ve worked on projects that started with integer ids and it caused nothing but problems. reply giva 19 hours agorootparentWhat kind of problems did you encounter? reply welder 19 hours agorootparentNot OP, but I can answer this: Integers don't scale because you need a central server to keep track of the next integer in the sequence. UUIDs and other random IDs can be generated distributed. Many examples, but the first one that comes to mind is Twitter writing their own custom UUID implementation to scale tweets [0] [0]: https://blog.twitter.com/engineering/en_us/a/2010/announcing... reply sgarland 17 hours agorootparent> Integers don't scale because you need a central server to keep track of the next integer in the sequence. They most assuredly do scale. [0] Also, Slack is built on MySQL + Vitess [1], the same system behind PlanetScale, which internally uses integer IDs [2]. [0]: https://www.enterprisedb.com/docs/pgd/latest/sequences/#glob... [1]: https://slack.engineering/scaling-datastores-at-slack-with-v... [2]: https://github.com/planetscale/discussion/discussions/366 reply CooCooCaCha 16 hours agorootparentI get what you’re saying but this feels like a premature optimization that only becomes necessary at scale. It reminds me a bit of the microservices trend. People tried to mimic big tech companies but the community slowly realized that it’s not necessary for most companies and adds a lot of complexity. I’ve worked at a variety of companies from small to medium-large and I can’t remember a single instance where we wish we used integer ids. It’s always been the opposite where we have to work around conflicts and auto incrementing. reply sgarland 15 hours agorootparentIn the same vein, distributed DBs are not required for most companies (from a technical standpoint; data locality for things like GDPR is another story). You can vertically scale _a lot_ before you even get close to the limits of a modern RDBMS. Like hundreds of thousands of QPS. I've personally ran MySQL in RDS on a mid-level instance, nowhere near close to maxing out RAM or IOPS, and it handled 120K QPS just fine. Notably, this was with a lot of UUIDv4 PKs. I'd wager with intelligent schema design, good queries, and careful tuning, you could surpass 1 million QPS on a single instance. reply welder 16 hours agorootparentprevAuto-incrementing integers mean you're always dependent on a central server. UUIDs break that dependency, so you can scale writes up to multiple databases in parallel. If you're using MySQL maybe integer ids make sense, because it scales differently than PostgreSQL. reply akvadrako 10 hours agorootparentThe way to solve that is giving each server it's own range of IDs. reply sgarland 14 hours agorootparentprevIf the DB fails to assign an ID, it's probably broken, so having an external ID won't help you. If you're referring to not having conflicts between distributed nodes, that's a solved problem as well – distribute chunked ranges to each node of N size. reply kiitos 11 hours agorootparentWhatever is distributing the chunks is still a point of central coordination. reply Dylan16807 7 hours agorootparentYes, and? If you can't manage minor levels of coordination because your database is on fire, the problem is that your database is on fire. reply giva 18 hours agorootparentprevYes, but with PostegreSQL (and any other SQL server I'm aware of) you already have a central server that can do that. If you have multiple SQL server this won't work obv, unless you pair it with a unique server ID. reply CooCooCaCha 16 hours agorootparentI recently worked on a data import project and because we used UUIDs I was able to generate all the ids offline. And because they’re randomly generated there was no risk of conflict. This was nice because if the script failed half way through I could easily lookup which ids were already imported and continue where I left off. The point is, this property of UUIDs occasionally comes in handy and it’s a life saver. reply sgarland 14 hours agorootparentpostgres=# CREATE TABLE foo(id INT, bar TEXT); CREATE TABLE postgres=# INSERT INTO foo (id, bar) VALUES (1, 'Hello, world'); INSERT 0 1 postgres=# ALTER TABLE foo ALTER id SET NOT NULL, ALTER id ADD GENERATED ALWAYS AS IDENTITY (START WITH 2); ALTER TABLE postgres=# INSERT INTO foo (bar) VALUES ('ACK'); INSERT 0 1 postgres=# TABLE foo; idbar ----+-------------- 1Hello, world 2ACK (2 rows) reply CooCooCaCha 12 hours agorootparentI don’t understand what you’re getting at. This was a pre-existing Postgres db in production. I’m sure there’s a way to get it to work with integer ids but it would have been a pain. With UUID’s it was very simple to generate. reply sgarland 10 hours agorootparentYou said data import, so I assumed it was pulling rows into an empty table. The example I posted was a way to create a table with a static integer PK that you could rapidly generate in a loop, and then later convert it to auto-incrementing. > I’m sure there’s a way to get it to work with integer ids but it would have been a pain. With UUID’s it was very simple to generate. IME, if something is easy with RDBMS in prod, it usually means you’re paying for it later. This is definitely the case with UUIDv4 PKs. reply dventimi 18 hours agorootparentprevThey also leak information. reply lazide 19 hours agorootparentprevThis doesn’t really help you in this case, because the patch is to generate the UUIDs in the database? reply welder 19 hours agorootparentNow you can use PG to generate the UUIDv7 in the beginning then easily switch to generating in the client if you need in the future, but I think OP was talking about UUID vs auto-incrementing integer in general not specific to Postgres. reply lazide 18 hours agorootparentIMO it’s always been easier to generate them in the client. Every major platform has had libraries since forever. reply nevir 18 hours agorootparentprevHere are some reasons for using UUIDs; not apply to all businesses: - client-side generation (e.g. can reduce complexity when doing complex creation of data on the client side, and then some time later actually inserting it into to your db) - sequential ids leak competitive information: https://en.wikipedia.org/wiki/German_tank_problem - Global identification (being able to look up an unknown thing by just an id - very useful in log searching / admin dashboards / customer support tools) reply brodo 19 hours agorootparentprevI encountered this once: If you use integer IDs, try to scale horizontally, and do not generate the IDs in the database, you'll get in deep trouble. The solution for us was to let the DB handle ID generation. reply giva 18 hours agorootparentYes, but the only sane way to generate integer IDs is in the database. reply mbork_pl 18 hours agoparentprevOne reason you might want not to use integers for stuff like user ids is that you may leak the information about the magnitude of your userbase. reply itslennysfault 15 hours agoparentprevI would never advise this. I use UUIDv4 for basically everything. It adds minimal overhead to small systems and adds HUGE benefits if/when you need to scale. If you need to sort by creation date use a \"created\" column (or UUIDv7 if appropriate). If your system ever becomes distributed you will sing the praises of whoever choose UUID over an int ID, and if it never becomes distributed UUID won't hurt you. Note: this is for web systems. If it's embedded systems then the overhead starts to matter and the usefulness of UUID is probably nil. reply jandrewrogers 15 hours agorootparentIt is worth mentioning that the reason UUIDv4 is strictly forbidden in some large decentralized systems is the myriad cases of collisions because the \"random number\" wasn't quite as random as people thought it was. Far too many cases of people not using a cryptographically strong RNG, both unwittingly or out of ignorance that they need to. Less of an issue if you have total control of the operational environment and code base, but that is not always the case. reply mort96 12 hours agorootparentHow does this happen? Are people implementing UUIDv4 themselves using rand() or equivalent? Or has widely used UUIDv4 libraries had such bugs? reply jandrewrogers 9 hours agorootparentIt comes in a couple common flavors. Most commonly it is people just rolling their own implementation and using a PRNG or similar. Not every environment has a ready-made UUIDv4 implementation, and not all UUIDv4 implementations in the wild are strict. A rarer horror story I've heard a couple times is discovering that the strong RNG provided by their environment is broken in some way. Both of these cases are particularly problematic because they are difficult to detect operationally until something goes horribly wrong. The main reason non-probabilistic UUID-like types are used for high-reliability environments is that it is easy to verify the correctness of the operational implementation. It isn't that difficult to deterministically generate globally unique keys in a distributed system unless you have extremely unusual requirements. reply sgarland 10 hours agorootparentprevIt adds a lot of overhead at any scale, it’s just that the overhead is hidden due to the absurd speed of modern hardware. I’ll again point out (I said this elsewhere in a post today on UUIDs) that PlanetScale uses int PKs internally. [0] That is a MASSIVE distributed system, working flawlessly with integers as keys. They absolutely can scale, it just requires more thoughtful data modeling and queries. [0]: https://github.com/planetscale/discussion/discussions/366 reply samlambert 9 hours agorootparentGitHub also uses int PKs and has over 100,000,000 users. reply akvadrako 10 hours agoparentprevThat's especially true if you care about performance and do a lot of joins, the hit can be over 10%. reply kkzz99 19 hours agoparentprevHuh, why would using uuidv4 be a problem? Collisions? reply davydog187 19 hours agorootparentMy understanding is that they cause a lot of page fragmentation, which leads to excessive writes to the WAL reply brodo 19 hours agorootparentprevYou can't use them as cursors, because they are not inherently ordered like integer ids. reply kiitos 11 hours agorootparentIDs are one thing, cursor-able fields/columns are a different thing. You cursor on timestamps, or serial numbers, or etc., not IDs. reply dventimi 18 hours agorootparentprevI have never wanted to use database cursors and I predict that I never will. reply brodo 18 hours agorootparentSure, if you don't offer pagination or only have small tables, you can get away with offsets. I tend to go for cursors as a default because I like to build applications with performance in mind and it’s the same effort. reply dventimi 15 hours agorootparentWe may be talking about different things. I thought you were referring specifically to [database cursors](https://en.wikipedia.org/wiki/Cursor_(databases)) so that's what I was talking about. If you're talking about something else, like the concept of so-called \"cursor-based pagination\" in general, then that is still an option even with even randomly-generated primary keys, so long as there are other attributes that can be used to establish an order (which attributes need not be visible to the a user) reply dventimi 12 hours agorootparentprevI have offered pagination over large tables, without database cursors or non-random keys, without offsets, while keeping performance in mind, with little effort. reply mariusor 18 hours agorootparentprevHow about the rest of us? I don't have a resource of the top of my head to present to you, but in the least keyset pagination is superior to the offset one because it does not get invalidated by new inserts. reply dventimi 12 hours agorootparentThe rest of you also don't need database cursors or non-random keys to have keyset pagination. reply mrits 18 hours agoparentprevWhen working with distributed systems or compiling a IDs from different systems it is helpful to make sure the ID is unique reply mderazon 19 hours agoprevWould you recommend starting a new project with UUID v7 ? reply cryptos 17 hours agoparentIf the included timestamp doesn't expose sensitive data, then using UUID v7 is a good default, because it has performance advantages on database operations and items might be sorted by ID in a meaningful way, what is sometimes desired (even if I never used it). reply politelemon 19 hours agoparentprevIf you need some of its attributes. Some comments: https://news.ycombinator.com/item?id=39261469 https://news.ycombinator.com/item?id=36433481 And have a look at this post from last year: https://news.ycombinator.com/item?id=36438367 reply nodesocket 19 hours agoprevWhat’s a use-case for a v7 UUID vs using a v4 UUID which is entirely random based? Is it just that v7 includes a timestamp for better sorting? reply guptaneil 19 hours agoparent> Is it just that v7 includes a timestamp for better sorting? Correct. The sortable nature of UUIDv7 improves database performance and index locality by helping the index be more efficient since rows are inserted in a predictable order instead of scattered randomly. reply vlucas 19 hours agoparentprevYes. UUIDv7 can be sorted by default in order of creation, which helps reduce fragmentation problems of randomness over time. reply mrits 18 hours agoparentprevIf nothing else (and there is plenty of else) it saves a lot of time knowing the order something was created when debugging. reply bebna 20 hours agoprevlooks like v7 is basically v1 updated. v6 looks interesting with the db optimisation in mind. UUIDv7 spec: https://www.ietf.org/archive/id/draft-peabody-dispatch-new-u... reply yrro 20 hours agoparentFYI that's a link to a now very old internet draft. The current draft can be found here: https://datatracker.ietf.org/doc/draft-ietf-uuidrev-rfc4122b... reply michaelmior 20 hours agoparentprev> Systems that do not involve legacy UUIDv1 SHOULD consider using UUIDv7 instead. The optimization relevant to v6 also applies to v7. The difference is that v7 UUIDs are not directly compatible with v1 UUIDs. reply nivertech 20 hours agoprev [–] Nice, but somewhat pointless, since the UUID (or any other type of ID representing an external entity) better be generated by the actor creating that entity, i.e. the FE client, or in the worst case, the BE/application server. If it is a database server generated ID, it could as well be a serial autoincrement bigint ;) EDIT: For those who misunderstood: I'm very much pro-UUID, and against serial autoincrement server-generated IDs. With the exception when you need to heavily optimize for speed and/or index storage space. And even then there are hybrid solutions like using UUID externally, and serial IDs internally. https://news.ycombinator.com/item?id=39261435 reply arghwhat 20 hours agoparentThere are many reasons for not using a bigserial index, such as avoiding the data leak associated with publicly visible sequential database indexes. These reasons apply regardless of where an index is generated. Generating IDs away from the database is mainly done due to design restrictions demanding it, not because it is beneficial. reply mythhabit 19 hours agoparentprevA serial auto increment bigint is not globally unique. A traditional uuid, is not sequential. This particular uuid are both globally unique and increasing and can be used for primary key. It simplifies certain schemas and architectures. reply beeboobaa 20 hours agoparentprevTrusting your clients to generate your database IDs... What could go wrong? reply nivertech 19 hours agorootparent1. you're not trusting anyone 2. the UUID by itself doesn't authenicate or authorize anything 3. there is a small chance of collision, and it can be handled on the backend/persistance/DB layer, i.e. return error to the client in case of collision and ask to generate a new UUID 4. many non-trivial and/or CQRS/ES apps work like this 5. if you are really paranoid, you can push down UUID generation logic to BFF (Backend-For-Frontend) layer 6. Lots of DistSys problems can be solved with client-generated IDs. But most people mistakenly think that DistSys applies to backend only, and exclude clients from the picture. 7. Scaling RDBMS (especially Postgres) is hard. UUID generation is slower than serial bigint, so it's best to keep it outside DB layer fo this reason also. 8. Client-generated UUIDs help to make client requests idempotent, and enable error handling with retries (although it's better to add an additional layer of request idempotency with IDEMPOTENCY_KEY HTTP header, or GraphQL Relay's clientMutationID). reply iudqnolq 18 hours agorootparentI think small chance of collision is a misleading way to think about it when any malicious client can submit 100% collisions if it wants to. Dealing with this isn't a big deal, but if you ignore it completely as unlikely/paranoid in a hacked together app you risk letting someone do something like take ownership of an existing record by pretending to create it. reply nivertech 18 hours agorootparentP_collision = 1 / 2^122 the malicious actor will need to somehow get the authorized session first, then get the real UUID which already inserted into the DB. And now she will be able to do DDoS by replaying create_entity requests with already existing UUID. But ... the same scheme equally applies to server-generated IDs also when used for updates instead of insert/create (even if there is a translation layer between internal and external IDs) ;) In my implementations this create_entity will also have an idempotency key, so after first successful request, the replayed/retried requests will hit the cache only, and skip the database. In case the attacker will also change idempotency_key for each replayed request, then the only remedy is to monitor for this scenarios, or reject requests with the same {sessionID, requestName, enitityUUID} and different idempotencyKey-s over short time intervals. But again, this equally applies to any type of server-generated ID. reply iudqnolq 17 hours agorootparentSuppose we're talking about an app where users can post events. Each public event has a page at /event/. So any malicious user can trivially find the id of an existing event. Suppose there's also an api where you POST a JSON body to /api/v1/event to create an event. This uses a client generated ID so the body contains the title, location, etc and the supposedly newly generated id. A malicious client could submit an existing uuid instead of generating a new one, and the server would need to reject this. I'm not saying this is a big issue, but saying \"P_collision = 1 / 2^122\" is misleading and gives a false sense of security. P_collision is 100% if a malicious user can specify any id they want and wants to specify a colliding one. I don't understand why you're bringing in idempotency keys. The way to fix this is to reject client generated ids that already exist. reply nivertech 17 hours agorootparent> Suppose we're talking about an app where users can post events. Each public event has a page at /event/. So any malicious user can trivially find the id of an existing event. This is bad UX and bad design, usually human-readable event slug will be shown in the URL. But I agreed that since UUIDs are not encrypted, they can be acquired by the attacker (but this equally applies to any other unencrypted data handled by the client). > Suppose there's also an api where you POST a JSON body to /api/v1/event to create an event. This uses a client generated ID so the body contains the title, location, etc and the supposedly newly generated id. A malicious client could submit an existing uuid instead of generating a new one, and the server would need to reject this. Again this is bad design, and the attacker will also need to either hijack the session, or to steal JWT token. > I'm not saying this is a big issue, but saying \"P_collision = 1 / 2^122\" is misleading and gives a false sense of security. P_collision is 100% if a malicious user can specify any id they want and wants to specify a colliding one. I agreed with you, but the attacker can copy any ID, including server-generated ones. So I don't understand the problem. Any external data need to be validated be it client-generated or server-generated. Do you claim that somehow validating UUIDs for uniqueness in the DB layer is more expensive than any other validation of the external data? > I don't understand why you're bringing in idempotency keys. The way to fix this is to reject client generated ids that already exist. Please read again, yes all external data need to be validated, so it equally applies to server-generated IDs (only they will need to be validated on UPDATE-s and DELETE-s instead of INSERT-s). Idempotency keys just reduce the load on the hard-to-scale RDBMS database layer, so it will not be hit on every retry or replayed malicious requests. reply beeboobaa 17 hours agorootparentprev> 1. you're not trusting anyone Sure you are. You're trusting the client to send you valid data. > 2. the UUID by itself doesn't authenicate or authorize anything Okay, better hope no one ever considers the UUID to be a unique randomly generated token. Besides that, users might be tempted to submit \"vanity\" UUIDs if they get to decide their own identifiers, breaking assumptions about the system. > 4. many non-trivial and/or CQRS/ES apps work like this Cool, if your friends jump off a bridge, you gonna follow them? reply piaste 19 hours agorootparentprevWho said anything about trust? Server-side validation still applies; you don't just DELETE /user/{id} without verifying ownership, regardless of where the id comes from. But client-generated IDs make idempotency easier and remove whole classes of errors. They're typically a huge win. reply kiitos 11 hours agoparentprev [–] Clients have/supply meaningful data. An ID isn't meaningful data. reply nivertech 11 hours agorootparent [–] Parents have/supply meaningful data. A name of their newborn child isn’t meaningful data ;) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Home Commitfest for 2024-03 is documented in this summary, providing insights into the review process and progress made for various topics.",
      "The UUID v7 topic is discussed, including the authors, reviewers, and the current status of the review process.",
      "Attachments and comments related to the UUID v7 topic are also included in the summary."
    ],
    "commentSummary": [
      "The debate centers around the advantages and disadvantages of using UUIDs in PostgreSQL databases.",
      "Some argue that UUIDs are unnecessary for most applications, while others believe they enhance scalability and performance.",
      "Discussions also cover the implementation, versions, privacy concerns, and security implications of UUIDs, as well as their impact on sorting, partitioning, and database performance."
    ],
    "points": 219,
    "commentCount": 171,
    "retryCount": 0,
    "time": 1707136750
  },
  {
    "id": 39268106,
    "title": "Scientists Propose Adding Category 6 to Hurricane Scale",
    "originLink": "https://eos.org/articles/weve-already-seen-category-6-hurricanes-now-scientists-want-to-make-it-official",
    "originBody": "Five tropical cyclones in the past 9 years have hit wind speeds far above the category 5 threshold, causing thousands of fatalities and billions of dollars of damage. Such ultrastrong, highly destructive hurricanes are becoming more likely as climate change increases the amount of energy available to storms. “Storms are getting stronger and stronger, so category 5 underestimates actual risk.” In a new study published in the Proceedings of the National Academy of Sciences of the United States of America, scientists suggest that the growing intensification of tropical cyclones may necessitate adding a sixth category to the Saffir-Simpson Hurricane Wind Scale. Doing so could be one useful tool not only to indicate hurricane risk but also to convey the increasing dangers of climate change. “Storms are getting stronger and stronger, so category 5 underestimates actual risk,” said James Kossin, an author on the paper and an atmospheric scientist at the University of Wisconsin–Madison. This newsletter rocks. Get the most fascinating science news stories of the week in your inbox every Friday. SIGN UP NOW Warming Winds The Saffir-Simpson scale is the most widely recognized hurricane intensity scale, ranking storms from “tropical depression,” at wind speeds less than 38 miles per hour (61 kilometers per hour), to “category 5 hurricane,” at wind speeds greater than 157 miles per hour (253 kilometers per hour). That scale may not capture the risk posed by the most intense storms as the world warms, the authors wrote. They suggest a sixth category that encompasses storms with winds greater than 192 miles per hour (309 kilometers per hour). The authors used three lines of evidence to support the creation of a sixth category. First, multiple storms have already spilled over into the hypothetical category 6. Typhoon Haiyan, for example, made landfall in the Philippines in 2013 and had winds that reached 195 miles per hour (314 kilometers per hour). Haiyan was the costliest storm ever to hit the country and one of the deadliest, causing more than 6,000 fatalities. In 2015, Hurricane Patricia—considered the strongest hurricane ever recorded—brought winds of up to 215 miles per hour (346 kilometers per hour) to southwest Mexico. Climate change has likely contributed to the intensification of tropical storms, according to the Intergovernmental Panel on Climate Change, the United Nations body that assesses climate science. The authors also analyzed the maximum potential intensity of storms in recent decades. That metric refers to the highest wind speeds that are possible on a given day given that day’s weather conditions. They found that in the Gulf of Mexico between 1979 and 2019, conditions were conducive to category 6 hurricanes about 10 days a year. The number of days conducive to category 6 wind speeds has increased because of climate change, said Kossin. Last, the authors modeled future hurricanes under various climate change scenarios and found that under each possible scenario, the risk of a category 6 hurricane increased. “Over the next decade, there will be category 6 [hurricanes],” said Michael Wehner, an author on the paper and a climate scientist at the Lawrence Berkeley National Laboratory. Communicating Climate Change Communication of risks shouldn’t focus only on the Saffir-Simpson scale, according to Michael Brennan, the director of NOAA’s National Hurricane Center (NHC). Most fatalities caused by hurricanes occur not from wind but from water, including storm surges and rain. “At NHC, we’ve tried to steer the focus toward the individual hazards, which include storm surge, wind, rainfall, tornadoes and rip currents, instead of the particular category of the storm,” he wrote in an email. “Category 5 on the Saffir-Simpson scale already captures ‘Catastrophic Damage’ from wind, so it’s not clear that there would be a need for another category even if storms were to get stronger.” “The reality is that hurricanes have changed already. This creates the need to discuss whether the systems that we currently have in place are adequate for the future.” The question of whether a category 6 would be an effective communication tool requires a larger discussion, with input from social scientists, psychologists, emergency managers, and city planners, Kossin said. He said he hopes the idea of a hypothetical category 6 will spark more discussion of how to warn people about all hurricane-related risks, including wind, storm surge, and rainfall, as hurricanes continue to intensify. “What we’re trying to highlight is not the immediate danger of an impending storm,” Wehner said. “That kind of thing is already out there. What we’re trying to communicate is that the risk of the most intense storms is increasing because of climate change.” Kevin Reed, a climate and atmospheric scientist at Stony Brook University who was not involved in the new study, said that expanding the Saffir-Simpson scale would not only indicate increased risks from individual storms but highlight the worsening risks of climate change in general. “The reality is that hurricanes have changed already,” Reed said. “This creates the need to discuss whether the systems that we currently have in place are adequate for the future.” —Grace van Deelen (@GVD__), Staff Writer Citation: van Deelen, G. (2024), We’ve already seen category 6 hurricanes—now scientists want to make it official, Eos, 105, https://doi.org/10.1029/2024EO240060. Published on 5 February 2024. Text © 2024. AGU. CC BY-NC-ND 3.0 Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited. Related Tagged: Climate Change, Earth science, extreme weather, forecasting, Hazards & Disasters, hurricanes, typhoons, & cyclones, science communictaion, wind",
    "commentLink": "https://news.ycombinator.com/item?id=39268106",
    "commentBody": "We've already seen category 6 hurricanes – scientists want to make it official (eos.org)186 points by sohkamyung 11 hours agohidepastfavorite82 comments ggreer 8 hours agoI am skeptical of this paper. If you go to Wikipedia's list of most intense tropical cyclones[1] and sort by barometric pressure, there doesn't seem to be much correlation with time. The biggest and most intense tropical cyclone is still Typhoon Tip in 1979.[2] If you read the actual study[3], it looks like they do a lot of data manipulation and simulation to come to their conclusion. They subtract 15 meters/sec from wind speeds measured before 1973, claiming a bias in measurements from that time. This causes a huge step up in lifetime maximum intensity in the 1970s. Their estimates of future category 6 probabilities are from simulations that they admit don't simulate current conditions correctly. I think it's more likely than not that tropical cyclones are getting more intense, and that they're hitting places that didn't typically get hit in the past, but I don't find this paper convincing. It really feels like they cajoled the data to fit their conclusion. 1. https://en.wikipedia.org/wiki/List_of_the_most_intense_tropi... 2. https://en.wikipedia.org/wiki/Typhoon_Tip 3. https://www.pnas.org/doi/full/10.1073/pnas.2308901121 reply BeefWellington 6 hours agoparentIn fairness though, they didn't just make up their bias assertion; it's in other published works[1] and there is real evidence that old measurements were incorrect (biased towards the high side) when compared to other available contemporary measurements. [1]: Landsea, C. W. Mon. Weath. Rev. 121, 1703–1714 (1993) - https://journals.ametsoc.org/configurable/content/journals$0... reply laverya 5 hours agorootparentTheir corrections may be correct, but it's still always nicer when the magnitude of the signal is larger than that of the corrections to the data. reply Nevermark 3 hours agorootparentWhat is nice is vetting and correcting data for reliability and consistency. Part of aiming for objectivity, and better understanding, isn't worrying about which direction a correction takes. At all. Only that it is a good correction. Our brains constantly make up distracting narratives, if we let them. If the correction had been the other way, some people would say scientists have been downplaying data and probably still are. reply foofie 3 hours agorootparent> Part of aiming for objectivity, and better understanding, isn't worrying about which direction a correction takes. At all. Only that it is a good correction. I don't think you fully grasp the implications of arbitrarily correcting old measures. In the end, and accepting at face value these corrections, you're still manipulating old data to use the result of said manipulation as the whole basis of your hypothesis. This approach automatically leads to questions on whether you draw your conclusions from the data, or you change the data to fit your conclusions. Do you understand the risk that this poses in any discussion on a politically sensitive topic? Think of the hit to the credibility of any claim supported by this data manipulation if later your method is deemed untrustworthy because it needs further updates, and how it would look if you had to correct it to move the dial either way (i.e., \"they were lying from the start and are now covering their ass\" vs \"they felt their lie wasn't fooling anyone and decided to double down.\") reply lolc 1 hour agorootparent> arbitrarily correcting old measures. Why do you say the correction is arbitrary? Are there papers arguing for corrections in the other direction? reply eecc 1 hour agorootparentprevThe point was that the corrections aren’t arbitrary. reply throwawayqqq11 1 hour agorootparentprevTo add to the \"not arbitrary corection\" comments. Correction is also not lying. Anyone who states that is not grasping something about a totally political topic/method. reply a_wild_dandan 1 hour agorootparentprevTough shit. Nature doesn't care about political inconvenience. You must work with your most accurate representation of the data. reply esalman 3 hours agoparentprev> I think it's more likely than not that tropical cyclones are getting more intense, and that they're hitting places that didn't typically get hit in the past I think so too. One measure is the amount of insured losses from hurricanes. There's been an uptick in number of hurricanes and other weather events causing more then a billion dollars in insured losses- that's simply correlated with the increase in the value of insured assets. Even if we assume that storms are not getting more intense, or climate is not changing, we cannot deny that we have more valuable assets to protect now. Which requires climate actions. reply soperj 5 hours agoparentprevThey do the same thing with temperature readings. reply photochemsyn 5 hours agoparentprevFrom the paper: > \"...of the 197 TCs [tropical cyclones] that were classified as category 5 during the 42-y period 1980 to 2021, which comprises the period of highest quality and most consistent data, half of them occurred in the last 17 y of the period (12). Five of those storms exceeded our hypothetical category 6 and all of these occurred in the last 9 y of the record. The most intense of these hypothetical category 6 storms, Patricia, occurred in the Eastern Pacific making landfall in Jalisco, Mexico, as a category 4 storm. The remaining category 6 storms all occurred in the Western Pacific... Fig. 1A shows these 5 storms on the existing Hurricane Wind Scale and our proposed extension.\" https://www.pnas.org/doi/full/10.1073/pnas.2308901121 Theoretically, increased wind speeds are linked to increased sea surface temperatures, a warmer deeper ocean mixed layer, and more moistore in the atmosphere. However, increased vertical wind shear tends to break up the hurricane's chimney structure, and that might also increase with warming. Hence, a complicated prediction - but if conditions are right, it seems reasonable to conclude that unusually strong hurricanes will become more likely, even if overall frequency is unchanged. reply autokad 4 hours agorootparent> Hence, a complicated prediction - but if conditions are right, it seems reasonable to conclude that unusually strong hurricanes will become more likely, even if overall frequency is unchanged. Not really, its not caused by warm water, its caused by DIFFERENCES in the temperature from the water and air, which is why we have actually seen fewer hurricanes over the last 20 years (ignoring post 2020 because this decade doesnt have a lot of data in) source: https://www.nhc.noaa.gov/pastdec.shtml Its hard to decide when picking a particular category, so what I did was charted category 1s + 2* category 2 + 3 * category 3 ... reply pfdietz 4 hours agorootparentWarmer water will put more water vapor into the air, which will provide more energy, even if the difference in temperature between water and (upper atmosphere) stays the same. reply interestica 9 hours agoprev> The question of whether a category 6 would be an effective communication tool requires a larger discussion, with input from social scientists, psychologists, emergency managers, and city planners, Kossin said. Or, communications professionals! I would love to see more emphasis on science communications. The article touches on the fact that the Saffir-Simpson scale kinda over-relies on arbitrary windspeeds as its categorization factor. It doesn't take into account the potential damage from storm surges and flooding. (Also, as the comedian Ron White has remarked, it's not that the wind blows, but what the wind blows.[1]) Does a human have any way of conceptualizing the difference of 178-208 km/h (cat4) versus 252+ km/h (cat5) hurricane? Instead, there's an over reliance on the number -- perpetuated by how news media portray the storms. In October 2023 residents of Acapulco, Mexico were told that a Category 1 hurricane was approaching. It rapidly intensified to a cat 5 within a day and residents were totally unprepared.[2] Did residents even know \"rapid intensification\" was even possible? Is the potential for rapid intensification due to warming waters the thing we should be communicating rather than \"category numbers\"? In 2007 they updated the 'Fujita Scale' for Tornadoes (Now the 'Enhanced Fujita Scale') to better incorporate assessed damage.[3] Do we need some sort of update to the Saffir-Simpson scale that better takes into account potential/assessed damage? (Especially as it relates to the flooding/storm surge aspects). [1] https://www.youtube.com/watch?v=RQD7Fzid1xI [2] https://disc.gsfc.nasa.gov/information/data-in-action?title=... [3] https://www.weather.gov/oun/efscale edit: In terms of what the wind blows: an equivalent category storm that hits Jamaica versus one that hits Houston will likely produce very different levels of damage purely due to the difference in infrastructure types. Yet, both regions are warned with the same \"category number.\" reply bobthepanda 8 hours agoparentThis is also similar to the difference between Moment Magnitude vs Modified Mercalli or Shindo. https://en.wikipedia.org/wiki/Moment_magnitude_scale https://en.wikipedia.org/wiki/Japan_Meteorological_Agency_se... reply greesil 7 hours agoparentprevYou want wind Sieverts, not wind rads reply rblatz 9 hours agoprevCategory 1 - 74-95 mph Category 2 - 96-110 mph Category 3 - 111-129 mph Category 4 - 130-156 mph Category 5 - 157 mph or higher I’m not sure why these divisions were made. The jumps between are seemingly arbitrary, from 27 mph to 15 mph and no pattern I can discern. What makes the next jump to 192 which is the largest jump yet? reply Keyframe 9 hours agoparentLike Fujita scale for Tornados, it's about potential for potential damage it can cause which is here dependent somehow on the wind speed variable. I'm sure someone more knowledgeable about it can explain how it's correlated, but it's not about wind speeds (alone). reply genocidicbunny 6 minutes agorootparentThe thing I find interesting (in a way) is that even then, the damage caused is not a single-variate function. Where I live, we just had a massive for the area storm with really strong wind gusts. My little weather station on my balcony recorded 80mph gusts. I also have several new cracks in the walls from when the roof tried to leave the building. But in other places, hurricanes and tornadoes much stronger than that still end up leaving buildings intact. We try so hard to reduce so many things to a single number, a single qualifier. And nature just keeps showing us why that's not entirely useful. Musings from an evening spent in the dark, and perhaps the slightly spoiled leftover meatloaf that I had because there was no power to cook anything. reply lcnPylGDnU4H9OF 9 hours agorootparentprevReminded of a joke by Ron White in the context of a person choosing to remain behind in a hurricane because they believe they can withstand the wind and rain: “It’s not that the wind is blowin’, it’s what the wind is blowin’.” On topic, it makes me wonder if the wind cutoffs have to do with what can be additionally picked up by the increase in energy. I’d honestly assume not but I would still hesitate to assume that it’s arbitrary. Not really sure but the phrasing of the joke made me wonder. reply kurthr 5 hours agorootparentYeah, you know that's not a bad idea... just label the Category by what is being blown around in the wind. Category 1: Trash Cans and Patio Furniture Category 2: Shingles and Gardening tools Category 3: Branches and Bricks Category 4: Small vehicles and mobile homes Category 5: Lage vehicles and houses Category 6: Full concrete Trucks and and Roads I once traveled ('97) to go see the damage done by an F5 tornado and what struck me was that a 50ft wide section of asphalt roadway had been removed where the eye had passed. Granted that is about 270mph, but I would still be worried about depressurization even in a bomb shelter. reply Pikamander2 29 minutes agorootparentCategory 7: Hospitals and skyscrapers Category 8: Small continents Category 9: Other hurricanes Category 10: Your mom reply Keyframe 7 hours agorootparentprevThis made me interested as well. Why the exact cut-offs, right? I found few resources like NOAA https://www.nhc.noaa.gov/pdf/sshws.pdf and wikipedia https://en.wikipedia.org/wiki/Saffir%E2%80%93Simpson_scale saying basically about the wind speed that the actual wind speed is \"sustained winds as average winds over a period of one minute, measured at the same 33 ft (10.1 m) height\" and then I thought ok if this scalar we're using is correlated to potential damage, that would mean force, right? They did remove air pressure and storm surges as components later on. I didn't bother with air pressure outside of standard since it would deviate a lot into researching exactly that. Since it's not really my domain, I decided to wing it by googling around and looked for wind force formulas. One that I found out ( https://sites.uci.edu/energyobserver/2017/09/07/hurricane-wi.... ) can roughly be translated as F = v^2 but then when I charted it out with x being wind speed and y proportional force, only thing I found out was that it looked logarithmic (which I didn't need a chart for lol ). The other I found was saying for wind load formula \"The generic formula for wind load is F = A x P x Cd where F is the force or wind load, A is the projected area of the object, P is the wind pressure, and Cd is the drag coefficient.\" I had to hunt for variables here, but gist of it is that since scale is in mph I went USA with 1 square foot for A - area (and then to square meters from that, 0,093 m^2), wind speed to m/s, and went with these (more googling): Wind Pressure (P) is P = 0.5 x p x V^2 where p (rho actually) is air density (google: 1.225 kg/m^3 at sea level and 15C, I couldn't find one at 10m height), V is our wind speed, and Cd (drag coefficient) for a flat plate which is 1.28 according to https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/a.... tl;dr; I couldn't find clear cuts in Newtons. I tried minimum, maximum and average wind speeds for each categories, and then I kind of lost interest there. More googling says that it was based on established observations what wind force can do to structures, but no more than that and I couldn't source original work to see more details. Outside of optics, this is as far as my physics will lead me tonight. I'd be highly interested to see if anyone more in the know can provide methodology behind it, be it from meteorology, construction, or fluid dynamics. reply TylerE 8 hours agoparentprevIt’s an extension of the Beaufort scale. The start of class 12 aligns with the start of cat 1. reply yieldcrv 9 hours agoparentprevI think its the damage that benign debris can do to a person at certain speed thresholds but I could be wrong reply senectus1 9 hours agorootparentwhich seems weird when you consider the building materials and styles that different regions use. reply Lendal 8 hours agoparentprevThey are indeed completely arbitrary, which makes \"Category 6\" completely meaningless/useless, just like the rest of those silly numbers. A storm with a wind speed of 130 mph is not 20% more dangerous than a storm with wind speed of 128 mph. They are equivalent dangers. It's a ridiculous system and should be abolished, but it won't, because it's good entertainment. reply Dylan16807 6 hours agorootparentOh come on, by that criteria you dismiss the entire concept of categories. Rounding is not a disqualifier. reply jcalx 7 hours agoprevFor futureproofing, we should extend the scale to cover hypercanes [1], which (according to Wikipedia): - require ocean temperatures of 120 °F (50 °C) - have sustained winds of 500 mph (800 km/h) - have barometric pressures in their centers sufficiently low enough to cause altitude sickness - may persist for several weeks due to above low pressure - may be as large as North America or as small as 15 mi (25 km) — Wikipedia has an unhelpful caption about the size of the \"average hypercane\" (!) - extend into the upper stratosphere, unlike today's hurricanes (lower stratosphere) - due to above height, may sufficiently degrade the ozone layer with water vapor to the point of causing (an additional) hazard to planetary life As of today, both a hypercane and a regular, run-of-the-mill catastrophic hurricane would be rated a Category 5. But I suppose hurricane categorization and nomenclature would be the least of NOAA's problems in such an event. [1] https://en.wikipedia.org/wiki/Hypercane reply swagmoose 10 hours agoprev\"multiple storms have already spilled over into the hypothetical category 6\" If they do go this route, I'd like it if they future-proofed it and include categories 6-10. Seems inevitable we're gonna see the first category 7 in the next 5-10 years. reply anatnom 9 hours agoparentConfusingly, the paper[0] cited by this article seems undecided on this front. Figure 1A of the paper puts Hurricane Patricia (2015) into hypothetical category 7, but the \"current and proposed categories\" in Table 1 stops at declaring category 6 wind speed > 86 m/s (or 192mph, 167 knots, 309 km/h), and category 7 doesn't make an appearance elsewhere in the paper. I was really hoping to find an authoritative listing of the strongest storms, but it is missing in both the linked article and the underlying paper. The paper itself uses data from International Best Track Archive for Climate Stewardship, which has a confusing website. As a non-expert, the website's top windspeed[1] category lists the following storms with maximum wind speeds of >167 knots (category 6 in the proposed scheme): 213kt - 1958 IDA 194kt - 1958 GRACE, 1959 JOAN, 1959 DINAH, 1961 NANCY, 1964 SALLY 185kt - 2015 PATRICIA 184kt - 1961 VIOLET 180kt - 1955 RUTH 178kt - 1955 JANET, 174kt - 1951 MARGE, 1953 NINA, 1956 WANDA, 1957 VIRGINIA, 1957 HESTER, 1957 KIT, 1957 LOLA, 1959 VERA, 1959 CHARLOTTE, 1966 KIT 170kt - 1964 OPAL, 2013 HAIYAN, 2016 MERANTI, 2020 GONI, 2021 SURIGAE I don't see any explanation for why there were so many fantastically powerful storms in the 1950s-60s. Perhaps the older data is of dubious quality? [0] https://www.pnas.org/doi/full/10.1073/pnas.2308901121#t01 [1] https://ncics.org/ibtracs/index.php?name=browse-wind#210 reply dwd 6 hours agorootparentThere is some research regarding an increase in Saharan dust storms that retards hurricane development in the Eastern Atlantic. Apparently this is still trending upwards and has resulted in fewer hurricanes forming over the last few decades. reply scythe 8 hours agorootparentprevWikipedia gives Typhoon Ida (not to be confused with various hurricanes named Ida) a wind speed of \"only\" 175 knots (325 kph; 202 mph) which accounts for the largest outlier in the list. https://en.wikipedia.org/wiki/Typhoon_Ida_(1958) reply anatnom 8 hours agorootparentConfusingly, that wikipedia page cites the same IBTrACS system that I referred to, and in that page[0] the max intensity is listed at 213 knots. The data shows that the 213 knot speed was seen for measurements across twelve hours on 1958-09-24. [0] https://ncics.org/ibtracs/index.php?name=v04r00-1958263N1314... reply Animats 9 hours agoparentprevThe scale is somewhat arbitrary (plot the points) but category 7 would start somewhere around 225MPH. Highest ever recorded is 215MPH, so category 7 is worth having in reserve. reply s1artibartfast 9 hours agorootparentIda/Kanogawa was 245 mph/213 knot peak. https://ncics.org/ibtracs/index.php?name=v04r00-1958263N1314... reply zamadatix 6 hours agorootparentSaffir–Simpson is based on sustained, not peak. reply richardw 9 hours agoparentprevAgree, need to do this properly. What's a fair cap in our solar system? \"Neptune’s winds are the fastest in the solar system, reaching 1,600 miles per hour!\" What category is that? https://scijinks.gov/planetary-weather/#:~:text=Neptune%27s%.... reply BlueTemplar 8 hours agorootparentI would guess that atmospheric pressure is going to matter a lot for the expected \"damage\", so it would not make sense in places where it's wildly different ? reply bugbuddy 8 hours agoparentprevNot necessarily because there may not be any difference between a wind speed of 350mph and 400mph wind in term of destructive power. Both may simply be able to strip the land bare and deliver the everything above it many miles away as well as temporarily moving parts of the sea miles inland. reply ComplexSystems 8 hours agoparentprevWhile that is probably most sensible, it doesn't seem like a lot of fun. Instead, I recommend we call a new global conference, every few years, to discuss the addition of each individual natural number to the Saffir-Simpson scale. reply sillywalk 8 hours agoparentprevBy the time storms of 7+ come that level become commonplace, I doubt there will be people track and name them. reply sdenton4 9 hours agoparentprevSet Category 10 at the speed of light, then work backwards... reply thfuran 9 hours agorootparentWell that's easy. The meteorologists can remember that category number = 10 v' / c, where v' is the maximum median windspeed over a one hundred acre convex region, and all anyone else needs to know is that every storm is cat 0. reply _tom_ 9 hours agoparentprevWhy should we \"create\" categories. There should be an algorithm for determining level. Input 1000 miles an hour, you get a category. Earthquakes don't have an upper limit. It's just a function of energy. reply Beldin 2 hours agorootparentI seem to recall a video (perhaps KurzGesagt) that a magnitude 25 earthquake would overcome the binding energy of Earth - the planet would be in separate pieces. That definitely is an upper limit: when the \"earth\" in earthquake literally cannot take more. reply TylerE 8 hours agorootparentprevEarthquakes are sort of naturally limited though. A 9.0 is going to be catastrophic no matter what, and while I’m not saying a 10 couldn’t happen it would probably be something like once in a billion year event. reply BeefWellington 6 hours agorootparent10.0 is firmly in \"if it happens nobody's gonna be around to care what it's designated\" territory I think. There's a practical point at which the death tolls are going to be sufficiently high that the number probably shouldn't matter. Though in tornadoes there definitely are EF-4 designated twisters that are hotly contested online as being truly EF-5; often that's down to where damage occurs in the lifetime of a tornado though and it being difficult to prove windspeeds when a system is moving through, e.g.: trailer park vs an industrial park. reply TylerE 6 hours agorootparentI don't think it's quite as cut and dried as that. A 9.5 hit Chile about 60 years ago, and about 95% of the most directly hit town survived. Which is not to minimize it - there were thousands of fatalities - but it was human scale tragedy, not apocalypse. reply ewhanley 8 hours agorootparentprevAn estimate of the upper limit of an earthquake is approximately 10. It's a function of max rock strength. reply selectodude 7 hours agorootparentIt’s actually a function of energy released. The earthquake can get bigger if the fault slip is larger. A magnitude 12 quake is technically possible but requires an entire hemisphere to slip 500 meters. There’s a really interesting paper that takes the moment magnitude scale to its logical extremes. PDF warning: https://www.fujipress.jp/main/wp-content/themes/Fujipress/pd... reply saalweachter 6 hours agorootparentI seem to recall something about the asteroid that killed the dinosaurs producing a magnitude 11. I wonder what the collision that produced the moon rated? reply ewhanley 6 hours agorootparentprevFair enough - something like rock strength and rupture length. Good paper. Thank you reply sidlls 6 hours agoprevI’ve been in cat 1 and cat 2 storms. They’re awesome in their power for destruction. I’ve evacuated from a category 4 storm, which did a huge amount of damage in the city when it hit. A category 5 storm is essentially going to destroy everything in its path already. What good would adding a 6th category do? reply nscalf 6 hours agoparentI lived in Florida for a long time, I can tell you that people don’t evacuate when it’s a cat 4 threatening to maybe become a cat 5. Having a category meaning “this is much worse than a 4” would be meaningful here. I see no reason to have an upper limit, it just artificially makes everything at and above the cat 5 threshold mean the same thing. Also, Florida homes are built from cement, meant to survive storms like that. The building codes come from hurricane andrew, a particularly damaging cat 5. reply matwood 2 hours agorootparentFlorida gonna Florida. I grew up and still live in a hurricane area. Went through a cat 5 as a kid - not going to do that again. But, cat 2/3 or less I'm not going anywhere. Last time we took a direct cat 2, we didn't even lose power. Like you said, FL and really most of the southeast coast learned from Andrew. Simple changes like roof ties and more expensive ones like cement plank siding make a pretty significant difference [1]. TBH, my main concern in a storm is water. My house is ~12' off the ground and given its location, if there's water in the house we're basically in an end of days, biblical level storm. [1] https://www.usglassmag.com/30-years-later-hurricane-andrew-r... reply Beldin 5 hours agorootparentprev> Having a category meaning “this is much worse than a 4” would be meaningful here. But don't you think that cat 5 would become the new 4? That is: why do you think extending the scale will expand the range of warnings communicated, instead of smearing the existing range out over more values? reply JumpCrisscross 4 hours agorootparent> don't you think that cat 5 would become the new 4? The few who might be saved are worth it. We can’t keep optimising for saving idiots. reply kaliqt 5 hours agoparentprevFor Floridians, Cat 5 is scary but not that scary, Florida's one crazy state with sturdy buildings and only very select areas get leveled in major storms. There definitely needs to be a better way of rating hurricanes, for strength AND area of damage. Hurricanes are extremely area focused, and they lose power FAST. It can miss you at the last second and not even knock a shingle off your roof, while leveling a trailer park 50 miles south of you. reply zgs 6 hours agoprevI'm skeptical about one of the opening sentences in the article: \"category 5 underestimates actual risk\". Category 5 cyclones/hurricanes are already assumed to essentially destroy everything in their path. This will still be true regardless of how strong the winds get. Having experienced several lower category cyclones, there really isn't a lot to do except 1/ evacuate if you've got time and a place to go or 2/ bunker down and pray. It's just luck that I've not experienced a direct hit from a higher category storm. reply wpollock 9 hours agoprevThe problem with this is that wind speed alone is not a good indicator of how destructive a storm can be. Storm surge, mud slides, etc., contribute and can be deadly even in a category 1 or 2 storm. If the scale is to be updated, it would be beneficial to include other factors in addition to wind speed. reply bombcar 9 hours agoparentWind speed is measurable before landfall, many other destructive indicators are only so after the destruction is done. reply interestica 9 hours agorootparentThe enhanced fujita scale for tornadoes takes into account an assessment of damage after the fact to make a guess of the wind speeds that were produced. An after-the-fact assessment of hurricanes could be useful in creating a categorization that better communicates risk to persons than just windspeed. reply TylerE 8 hours agorootparentMaybe, but the Fujita scale can greatly under report strength, because the higher grades need to be justified by damage to modern, well built structures. There are tons of tornadoes that meteorologists are sure are at least EF-4 based on Doppler and video, but are rated at EF-1 or EF-2 because they didn’t hit anything but cornfields and sheds. reply jrockway 6 hours agorootparentClassic example: https://en.wikipedia.org/wiki/2013_El_Reno_tornado This had wind speed measured by radar, but ultimately didn't hit any substantial structures, so they couldn't justify anything above EF3. Tornadoes are only rated based on the damage they do to damage indicators, the wind speeds are just best guesses. reply interestica 7 hours agorootparentprevI think that's also the challenge of using the same categories/windspeeds of the Saffir-Simpson scale when applying it to a place like Jamaica vs Houston. Both places may face a cat4 hurricane and see very different levels of damage entirely due to the difference in infrastructure. reply basil-rash 7 hours agorootparentprevIsn’t that the system working as-designed? We don’t really need to blast the alarm for a few stalks getting bent out of shape. reply TylerE 7 hours agorootparentIt can lead to a false sense of security... maybe if it turns east instead of north east it barrels into downtown Omaha. In the most extreme case a small tornado in a larger storm that hits no man-built structures may go totally unrecorded. Essentially if you assess tornado risk as something like (frequency * severity) / area, this will under assess risk to a previously developed area that is now being developed. Before there was nothing to hit. Now there is. reply contravariant 9 hours agoparentprevA well placed tree can make any storm deadly, it's perfectly fine to separate the size of the storm from the potential impact. You need to draw a line somewhere. Drawing it at the part you can measure/predict is pragmatic and sensible. reply hedora 6 hours agoparentprevI disagree. Wind causes a different type of damage than mud slides, storm surges, etc. For instance, if you live at high altitudes, you can ignore storm surge when preparing your house. reply dskrvk 8 hours agoprevThis is exactly the premise of Bruce Sterling’s novel “Heavy Weather”. reply irrelative 7 hours agoprevClassic spinal tap. “These go to eleven.” reply anArbitraryOne 4 hours agoprevNext thing you know they'll be trying to make category 7 hurricanes official reply unethical_ban 9 hours agoprevIt's nothing new to talk about, but rating a hurricane's destructive force on windspeed alone is sub-optimal. On the other side, one-dimensional labels for a storm help convey the severity of it quickly and unambiguously. Hurricanes have three components IIRC (as someone who lived on the coast a long time): Storm surge flooding, rain flooding, and wind. Hurricane Ike was a cat2 in 2008, which did significant damage to the Houston coast because of its large storm surge. Harvey in 2017 was damaging due to its consistent rain over the area as it stalled. Tropical storm Allison in 2001 was similar. One may argue that wind causes the most acute damage as well as the fastest \"change in status\" of the three: High winds can topple a tree to block a road instantly, or rip the roof from a house in a flash, or knock down powerlines taking out a neighborhood. While I'm not against a cat 6 or higher rating existing, for the sake of human communication \"cat 5\" means \"get the hell out of there\" already. reply jtriangle 8 hours agoparentAny rating system is going to fail to be actionable until two things happen. 1, structures need to be rated by the level of wind they're able to withstand, and 2, geographic regions need to be categorized by their likelihood of flooding. As it stands, as a person, you have no way of knowing if you have a cat X capable roof, nor do you know if you're in an area that is likely to flood, or how likely that area is to flood. Until you have a concrete rating system for those things, you'll have more people thinking that \"We can just hunker down\" when a cat X is barreling down on them than you want. That sounds like a big bite to take, but, realistically, you can more or less tag existing houses based on when they were built (ie under which revision of the building code were they built) and then use USGS data to determine flood risk. Then, you categorize all of the above by storm, ie, live in a cat 3 area with a cat 4 house? Evacuate if you have a cat 3 storm because it's going to flood. That will also inform localities as to which areas are going to need to be evacuated first, along with which areas are going to need more emergency assistance post-storm so resources can be allocated more efficiently. We're already kinda sorta accounting for this at the local level, but, codifying the practice allows it to scale and improve over time. reply metaphor 8 hours agoparentprev> Hurricane Ike was a cat2 in 2008, which did significant damage to the Houston coast because of its large storm surge. > Harvey in 2017 was damaging due to its consistent rain over the area as it stalled. The outsider impression that I took away was that a major reason why Houston got so rekt by a mere Cat 2 hurricane was in large part driven by property developers building communities in low lying areas that the Army Corp of Engineers had designated as \"emergency spillways\"[1][2]...the Army knew about the risk, the city turned a blind eye, and the devil in the details weren't disclosed to homebuyers. Perhaps there's more to the story? > While I'm not against a cat 6 or higher rating existing, for the sake of human communication \"cat 5\" means \"get the hell out of there\" already. I agree, but skipping town isn't always an option even if you wanted to; experienced two such events[3][4] on Guam as a kid. [1] https://www.nytimes.com/interactive/2018/03/22/us/houston-ha... [2] https://www.houstonchronicle.com/projects/2021/how-houston-f... [3] https://en.wikipedia.org/wiki/Typhoon_Omar [4] https://en.wikipedia.org/wiki/Typhoon_Paka reply unethical_ban 8 hours agorootparentOn the first point, you're correct about Harvey. Several neighborhoods were built in the basin of a flood plain. And lesser examples of such poor planning and drainage are all over Houston. But sometimes it really is storms that stall over the city dropping rain for three days. To the second point, yeah... My family tried to evac Rita (2005) and got 5 miles in three hours. Turned around, and the storm missed us. Three years later, my parents stayed for \"cat 2\" Ike and were trapped in the attic for 12 hours because Galveston Bay had come five feet up our house. reply pjot 9 hours agoparentprev> Storm surge flooding, rain flooding, and wind I use wind and the speed of the storm directionally as my mental model when thinking about hurricanes. Rain/surge flooding are results of how long the system is over an area. That said if a storm is a 3+ I’ll leave - driving 3-4 hours is way more enjoyable than trying to sleep with no AC reply santoshalper 8 hours agoparentprevAll models are wrong, but some are useful. Hurricane ratings have proven to be very useful. reply stubish 9 hours agoprev [–] I had previously heard that category 5 storms were originally thought to be impossible, and only became possible due to global warming adding more energy into the atmosphere. The article however states that category 6 was technically possible as far back as 1979. Have these category 5, 6 and maybe higher always been possible, but just more improbable? reply TylerE 9 hours agoparent [–] There were 19th century storms that were clearly 5s, at least. Whoever told you that didn’t know that the hell they were talking about, to put it mildly. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A recent study proposes the inclusion of a new category, category 6, in the Saffir-Simpson Hurricane Wind Scale.",
      "This new category would address the intensifying power and destructive capabilities of tropical cyclones due to climate change.",
      "The study utilized data from past storms, analysis of maximum potential intensity, and climate change models to support the need for a category 6.",
      "The addition of this category would provide a more accurate representation of the risks associated with climate change and stimulate conversations on communicating hurricane-related risks to the public."
    ],
    "commentSummary": [
      "Scientists propose the addition of a new hurricane category 6 due to increasing intensity, but skeptics criticize the research methodology and data manipulation.",
      "Reliable and consistent data is crucial in scientific research, especially for politically sensitive topics like climate change.",
      "The current categorization system based on wind speeds may fail to convey potential damage from storm surges and flooding, highlighting the need for improved rating systems that consider factors like infrastructure, storm surge, and flood risk."
    ],
    "points": 186,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1707172028
  }
]
