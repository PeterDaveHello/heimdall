[
  {
    "id": 39729057,
    "title": "Optimizing Web Performance for All Devices",
    "originLink": "https://danluu.com/slow-device/",
    "originBody": "In 2017, we looked at how web bloat affects users with slow connections. Even in the U.S., many users didn't have broadband speeds, making much of the web difficult to use. It's still the case that many users don't have broadband speeds, both inside and outside of the U.S. and that much of the modern web isn't usable for people with slow internet, but the exponential increase in bandwidth (Nielsen suggests this is 50% per year for high-end connections) has outpaced web bloat for typical sites, making this less of a problem than it was in 2017, although it's still a serious problem for people with poor connections. CPU performance for web apps hasn't scaled nearly as quickly as bandwidth so, while more of the web is becoming accessible to people with low-end connections, more of the web is becoming inaccessible to people with low-end devices even if they have high-end connections. For example, if I try browsing a \"modern\" Discourse-powered forum on a Tecno Spark 8C, it sometimes crashes the browser. Between crashes, on measuring the performance, the responsiveness is significantly worse than browsing a BBS with an 8 MHz 286 and a 1200 baud modem. On my 1Gbps home internet connection, the 2.6 MB compressed payload size \"necessary\" to load message titles is relatively light. The over-the-wire payload size has \"only\" increased by 1000x, which is dwarfed by the increase in internet speeds. But the opposite is true when it comes to CPU speeds — for web browsing and forum loading performance, the 8-core (2 1.6 GHz Cortex-A75 / 6 1.6 GHz Cortex-A55) CPU can't handle Discourse. The CPU is something like 100000x faster than our 286. Perhaps a 1000000x faster device would be sufficient. For anyone not familiar with the Tecno Spark 8C, today, a new Tecno Spark 8C, a quick search indicates that one can be hand for USD 50-60 in Nigeria and perhaps USD 100-110 in India. As a fraction of median household income, that's substantially more than a current generation iPhone in the U.S. today. By worldwide standards, the Tecno Spark 8C isn't even close to being a low-end device, so we'll also look at performance on an Itel P32, which is a lower end device (though still far from the lowest-end device people are using today). Additionally, we'll look at performance with an M3 Max Macbook (14-core), an M1 Pro Macbook (8-core), and the M3 Max set to 10x throttling in Chrome dev tools. In order to give these devices every advantage, we'll be on fairly high-speed internet (1Gbps, with a WiFi router that's benchmarked as having lower latency under load than most of its peers). We'll look at some blogging platforms and micro-blogging platforms (this blog, Substack, Medium, Ghost, Hugo, Tumblr, Mastodon, Twitter, Threads, Bluesky, Patreon), forum platforms (Discourse, Reddit, Quora, vBulletin, XenForo, phpBB, and myBB), and platforms commonly used by small businesses (Wix, Squarespace, Shopify, and WordPress again). In the table below, every row represents a website and every non-label column is a metric. After the website name column, we have the compressed size transferred over the wire (wire) and the raw, uncompressed, size (raw). Then we have, for each device, Largest Contentful Paint* (LCP*) and CPU usage on the main thread (CPU). Google's docs explain LCP as Largest Contentful Paint (LCP) measures when a user perceives that the largest content of a page is visible. The metric value for LCP represents the time duration between the user initiating the page load and the page rendering its primary content LCP is a common optimization target because it's presented as one of the primary metrics in Google PageSpeed Insights, a \"Core Web Vital\" metric. There's an asterisk next to LCP as used in this document because, LCP as measured by Chrome is about painting a large fraction of the screen, as opposed to the definition above, which is about content. As sites have optimized for LCP, it's not uncommon to have a large paint (update) that's completely useless to the user, with the actual content of the page appearing well after the LCP. In cases where that happens, I've used the timestamp when useful content appears, not the LCP as defined by when a large but useless update occurs. The full details of the tests and why these metrics were chosen are discussed in an appendix. Although CPU time isn't a \"Core Web Vital\", it's presented here because it's a simple metric that's highly correlated with my and other users' perception of usability on slow devices. See appendix for more detailed discussion on this. One reason CPU time works as a metric is that, if a page has great numbers for all other metrics but uses a ton of CPU time, the page is not going to be usable on a slow device. If it takes 100% CPU for 30 seconds, the page will be completely unusable for 30 seconds, and if it takes 50% CPU for 60 seconds, the page will be barely usable for 60 seconds, etc. Another reason it works is that, relative to commonly used metrics, it's hard to cheat on CPU time and make optimizations that significantly move the number without impacting user experience. The color scheme in the table below is that, for sizes, more green = smaller / fast and more red = larger / slower. Extreme values are in black. Site Size M3 Max M1 Pro M3/10 Tecno S8C Itel P32 wire raw LCP* CPU LCP* CPU LCP* CPU LCP* CPU LCP* CPU danluu.com 6kB 18kB 50ms 20ms 50ms 30ms 0.2s 0.3s 0.4s 0.3s 0.5s 0.5s HN 11kB 50kB 0.1s 30ms 0.1s 30ms 0.3s 0.3s 0.5s 0.5s 0.7s 0.6s MyBB 0.1MB 0.3MB 0.3s 0.1s 0.3s 0.1s 0.6s 0.6s 0.8s 0.8s 2.1s 1.9s phpBB 0.4MB 0.9MB 0.3s 0.1s 0.4s 0.1s 0.7s 1.1s 1.7s 1.5s 4.1s 3.9s WordPress 1.4MB 1.7MB 0.2s 60ms 0.2s 80ms 0.7s 0.7s 1s 1.5s 1.2s 2.5s WordPress (old) 0.3MB 1.0MB 80ms 70ms 90ms 90ms 0.4s 0.9s 0.7s 1.7s 1.1s 1.9s XenForo 0.3MB 1.0MB 0.4s 0.1s 0.6s 0.2s 1.4s 1.5s 1.5s 1.8s FAIL FAIL Ghost 0.7MB 2.4MB 0.1s 0.2s 0.2s 0.2s 1.1s 2.2s 1s 2.4s 1.1s 3.5s vBulletin 1.2MB 3.4MB 0.5s 0.2s 0.6s 0.3s 1.1s 2.9s 4.4s 4.8s 13s 16s Squarespace 1.9MB 7.1MB 0.1s 0.4s 0.2s 0.4s 0.7s 3.6s 14s 5.1s 16s 19s Mastodon 3.8MB 5.3MB 0.2s 0.3s 0.2s 0.4s 1.8s 4.7s 2.0s 7.6s FAIL FAIL Tumblr 3.5MB 7.1MB 0.7s 0.6s 1.1s 0.7s 1.0s 7.0s 14s 7.9s 8.7s 8.7s Quora 0.6MB 4.9MB 0.7s 1.2s 0.8s 1.3s 2.6s 8.7s FAIL FAIL 19s 29s Bluesky 4.8MB 10MB 1.0s 0.4s 1.0s 0.5s 5.1s 6.0s 8.1s 8.3s FAIL FAIL Wix 7.0MB 21MB 2.4s 1.1s 2.5s 1.2s 18s 11s 5.6s 10s FAIL FAIL Substack 1.3MB 4.3MB 0.4s 0.5s 0.4s 0.5s 1.5s 4.9s 14s 14s FAIL FAIL Threads 9.3MB 13MB 1.5s 0.5s 1.6s 0.7s 5.1s 6.1s 6.4s 16s 28s 66s Twitter 4.7MB 11MB 2.6s 0.9s 2.7s 1.1s 5.6s 6.6s 12s 19s 24s 43s Shopify 3.0MB 5.5MB 0.4s 0.2s 0.4s 0.3s 0.7s 2.3s 10s 26s FAIL FAIL Discourse 2.6MB 10MB 1.1s 0.5s 1.5s 0.6s 6.5s 5.9s 15s 26s FAIL FAIL Patreon 4.0MB 13MB 0.6s 1.0s 1.2s 1.2s 1.2s 14s 1.7s 31s 9.1s 45s Medium 1.2MB 3.3MB 1.4s 0.7s 1.4s 1s 2s 11s 2.8s 33s 3.2s 63s Reddit 1.7MB 5.4MB 0.9s 0.7s 0.9s 0.9s 6.2s 12s 1.2s ∞ FAIL FAIL At a first glance, the table seems about in that the sites that feel slow unless you have a super fast device show up as slow in the table (as in, max(LCP*,CPU)) is high on lower-end devices). When I polled folks about what platforms they thought would be fastest and slowest on our slow devices (Mastodon, Twitter, Threads), they generally correctly predicted that Wordpress and Ghost and Wordpress would be faster than Substack and Medium, and that Discourse would be much slower than old PHP forums like phpBB, XenForo, and vBulletin. I also pulled Google PageSpeed Insights (PSI) scores for pages (not shown) and the correlation isn't as strong with those numbers because a handful of sites have managed to optimize their PSI scores without actually speeding up their pages for users. If you've never used a low-end device like this, the general experience is that many sites are unusable on the device and loading anything resource intensive (an app or a huge website) can cause crashes. Doing something too intense in a resource intensive app can also cause crashes. While reviews note that you can run PUBG and other 3D games with decent performance on a Tecno Spark 8C, this doesn't mean that the device is fast enough to read posts on modern text-centric social media platforms or modern text-centric web forums. While 40fps is achievable in PUBG, we can easily see less than 0.4fps when scrolling on these sites. We can see from the table how many of the sites are unusable if you have a slow device. All of the pages with 10s+ CPU are a fairly bad experience even after the page loads. Scrolling is very jerky, frequently dropping to a few frames per second and sometimes well below. When we tap on any link, the delay is so long that we can't be sure if our tap actually worked. If we tap again, we can get the dreaded situation where the first tap registers and then causes the second tap to register after things have started changing, causing us to tap some random target, but if we wait, we realize that the original tap didn't actually register (or it registered, but not where we thought it did). Although MyBB doesn't service up a mobile site and is penalized by Google for not having a mobile friendly page, it's actually much more usable on these slow mobiles than all but the fastest sites because scrolling and tapping actually work. Another thing we can see is how much variance there is in the relative performance on different devices. For example, comparing an M3/10 and a Tecno Spark 8C, for danluu.com and Ghost, an M3/10 gives a halfway decent approximation of the Tecno Spark 8C (although danluu.com loads much too quickly), but the Tecno Spark 8C is about three times slower (CPU) for Medium, Substack, and Twitter, roughly four times slower for Reddit and Discourse, and over an order of magnitude faster for Shopify. For Wix, the CPU approximation is about accurate, but our `Tecno Spark 8C is more than 3 times slower on LCP*. It's great that Chrome lets you conveniently simulate a slower device from the convenience of your computer, but just enabling Chrome's CPU throttling (or using any combination of out-of-the-box options that are available) gives fairly different results than we get on many real devices. The full reasons for this are beyond the scope of the post; for the purposes of this post, it's sufficient to note that slow pages are often super-linearly slow as devices get slower and that slowness on one page doesn't strongly predict slowness on another page. If take a site-centric view instead of a device-centric view, another way to look at it is that sites like Discourse, Medium, and Reddit, don't use all that much CPU on our fast M3 and M1 computers, but they're among the slowest on our Tecno Spark 8C (Reddit's CPU is shown as ∞ because, no matter how long we wait with no interaction, Reddit uses ~90% CPU). Discourse also sometimes crashed the browser after interacting a bit or just waiting a while. For example, one time, the browser crashed after loading Discourse, scrolling twice, and then leaving the device still for a minute or two. For consistency's sake, this wasn't marked as FAIL in the table since the page did load but, realistically, having a page is so resource intensive that the browser crashes is a significantly worse user experience than any of the FAIL cases in the table. When we looked at how web bloat impacts users with slow connections, we found that much of the web was unusable for people with slow connections and slow devices are no different. Another pattern we can see is how the older sites are, in general, faster than the newer ones, with sites that (visually) look like they haven't been updated in a decade or two tending to be among the fastest. For example, MyBB, the least modernized and oldest looking forum is 3.6x / 5x faster (LCP* / CPU) than Discourse on the M3, but on the Tecno Spark 8C, the difference is 19x / 33x and, given the overall scaling, it seems safe to guess that the difference would be even larger on the Itel P32 if Discourse worked on such a cheap device. Another example is Wordpress (old) vs. newer, trendier, blogging platforms like Medium and Substack. Wordpress (old) is is 17.5x / 10x faster (LCP* / CPU) than Medium and 5x / 7x faster (LCP* / CPU) faster than Substack on our M3 Max, and 4x / 19x and 20x / 8x faster, respectively, on our Tecno Spark 8C. Ghost is a notable exception to this, being a modern platform (launched a year after Medium) that's competitive with older platforms (modern Wordpress is also arguably an exception, but many folks would probably still consider that to be an old platform). Sites that use modern techniques like partially loading the page and then dynamically loading the rest of it, such as Discourse, Reddit, and Substack, tend to be less usable than the scores in the table indicate. Although, in principle, you could build such a site in a simple way that works well with cheap devices but, in practice sites that use dynamic loading tend to be complex enough that the sites are extremely janky on low-end devices. It's generally difficult or impossible to scroll a predictable distance, which means that users will sometimes accidentally trigger more loading by scrolling too far, causing the page to lock up. Many pages actually remove the parts of the page you scrolled past as you scroll; all such pages are essentially unusable. Other basic web features, like page search, also generally stop working. Pages with this kind of dynamic loading can't rely on the simple and fast ctrl/command+F search and have to build their own search. How well this works varies (this used to work quite well in Google docs, but for the past few months or maybe a year, it takes so long to load that I have to deliberately wait after opening a doc to avoid triggering the browser's useless built in search; Discourse search has never really worked on slow devices or even not very fast but not particular slow devices). In principle, these modern pages that burn a ton of CPU when loading could be doing pre-work that means that later interactions on the page are faster and cheaper than on the pages that do less up-front work (this is a common argument in favor of these kinds of pages), but that's not the case for pages tested, which are slower to load initially, slower on subsequent loads, and slower after they've loaded. To understand why the theoretical idea that doing all this work up-front doesn't generally result in a faster experience later, this exchange between a distinguished engineer at Google and one of the founders of Discourse (and CEO at the time) is illustrative, in a discussion where the founder of Discourse says that you should test mobile sites on laptops with throttled bandwidth but not throttled CPU: Google: *you* also don't have slow 3G. These two settings go together. Empathy needs to extend beyond iPhone XS users in a tunnel. Discourse: Literally any phone of vintage iPhone 6 or greater is basically as fast as the \"average\" laptop. You have to understand how brutally bad Qualcomm is at their job. Look it up if you don't believe me. Google: I don't need to believe you. I know. This is well known by people who care. My point was that just like not everyone has a fast connection not everyone has a fast phone. Certainly the iPhone 6 is frequently very CPU bound on real world websites. But that isn't the point. Discourse: we've been trending towards infinite CPU speed for decades now (and we've been asymptotically there for ~5 years on desktop), what we are not and will never trend towards is infinite bandwidth. Optimize for the things that matter. and I have zero empathy for @qualcomm. Fuck Qualcomm, they're terrible at their jobs. I hope they go out of business and the ground their company existed on is plowed with salt so nothing can ever grow there again. Google: Mobile devices are not at all bandwidth constraint in most circumstances. They are latency constraint. Even the latest iPhone is CPU constraint before it is bandwidth constraint. If you do well on 4x slow down on a MBP things are pretty alright ... Google: Are 100% of users on iOS? Discourse: The influential users who spend money tend to be, I’ll tell you that ... Pointless to worry about cpu, it is effectively infinite already on iOS, and even with Qualcomm’s incompetence, will be within 4 more years on their embarrassing SoCs as well When someone asks the founder of Discourse, \"just wondering why you hate them\", he responds with a link that cites the Kraken and Octane benchmarks from this Anandtech review, which have the Qualcomm chip at 74% and 85% of the performance of the then-current Apple chip, respectively. The founder and then-CEO of Discourse considers Qualcomm's mobile performance embarrassing and finds this so offensive that he thinks Qualcomm engineers should all lose their jobs for delivering 74% to 85% of the performance of Apple. Apple has what I consider to be an all-time great performance team. Reasonable people could disagree on that, but one has to at least think of them as a world-class team. So, producing a product with 74% to 85% of an all-time-great team is considered an embarrassment worthy of losing your job. There are two attitudes on display here which I see in a lot of software folks. First, that CPU speed is infinite and one shouldn't worry about CPU optimization. And second, that gigantic speedups from hardware should be expected and the only reason hardware engineers wouldn't achieve them is due to spectacular incompetence, so the slow software should be blamed on hardware engineers, not software engineers. Donald Knuth expressed a similar sentiment in I might as well flame a bit about my personal unhappiness with the current trend toward multicore architecture. To me, it looks more or less like the hardware designers have run out of ideas, and that they’re trying to pass the blame for the future demise of Moore’s Law to the software writers by giving us machines that work faster only on a few key benchmarks! I won’t be surprised at all if the whole multiithreading idea turns out to be a flop, worse than the \"Itanium\" approach that was supposed to be so terrific—until it turned out that the wished-for compilers were basically impossible to write. Let me put it this way: During the past 50 years, I’ve written well over a thousand programs, many of which have substantial size. I can’t think of even five of those programs that would have been enhanced noticeably by parallelism or multithreading. Surely, for example, multiple processors are no help to TeX ... I know that important applications for parallelism exist—rendering graphics, breaking codes, scanning images, simulating physical and biological processes, etc. But all these applications require dedicated code and special-purpose techniques, which will need to be changed substantially every few years. Even if I knew enough about such methods to write about them in TAOCP, my time would be largely wasted, because soon there would be little reason for anybody to read those parts ... The machine I use today has dual processors. I get to use them both only when I’m running two independent jobs at the same time; that’s nice, but it happens only a few minutes every week. In the case of Discourse, a hardware engineer is an embarrassment not deserving of a job if they can't hit 90% of the performance of an all-time-great performance team but, as a software engineer, delivering 3% the performance of a non-highly-optimized application like MyBB is no problem. In Knuth's case, hardware engineers gave programmers a 100x performance increase every decade for decades with little to no work on the part of programmers. The moment this slowed down and programmers had to adapt to take advantage of new hardware, hardware engineers were \"all out of ideas\", but learning a few \"new\" (1970s and 1980s era) ideas to take advantage of current hardware would be a waste of time. And we've previously discussed Alan Kay's claim that hardware engineers are \"unsophisticated\" and \"uneducated\" and aren't doing \"real engineering\" and how we'd get a 1000x speedup if we listened to Alan Kay's \"sophisticated\" ideas. It's fairly common for programmers to expect that hardware will solve all their problems, and then, when that doesn't happen, pass the issue onto the user, explaining why the programmer needn't do anything to help the user. A question one might ask is how much performance improvement programmers have given us. There are cases of algorithmic improvements that result in massive speedups but, as we noted above, Discourse, the fastest growing forum software today, seems to have given us an approximately 1000000x slowdown in performance. Another common attitude on display above is the idea that users who aren't wealthy don't matter. When asked if 100% of users are on iOS, the founder of Discourse says \"The influential users who spend money tend to be, I’ll tell you that\". We see the same attitude all over comments on Tonsky's JavaScript Bloat post, with people expressing cocktail-party sentiments like \"Phone apps are hundreds of megs, why are we obsessing over web apps that are a few megs? Starving children in Africa can download Android apps but not web apps? Come on and \"surely no user of gitlab would be poor enough to have a slow device, let's be serious\" (paraphrased for length). But when we look at the size of apps that are downloaded in Africa, we see that people who aren't on high-end devices use apps like Facebook Lite (a couple megs) and commonly use apps that are a single digit to low double digit number of megabytes. There are multiple reasons app makers care about their app size. One is just the total storage available on the phone; if you watch real users install apps, they often have to delete and uninstall things to put a new app on, so the smaller size is both easier to to install and has a lower chance of being uninstalled when the user is looking for more space. Another is that, if you look at data on app size and usage (I don't know of any public data on this; please pass it along if you have something public I can reference), when large apps increase the size and memory usage, they get more crashes, which drives down user retention, growth, and engagement and, conversely, when they optimize their size and memory usage, they get fewer crashes and better user retention, growth, and engagement. On the bit about no programmers having slow devices, I know plenty of people who are using hand-me-down devices that are old and slow. Many of them aren't even really poor; they just don't see why (for example) their kid needs a super fast device, and they don't understand how much of the modern web works poorly on slow devices. After all, the \"slow\" device can play 3d games and (with the right OS) compile codebases like Linux or Chromium, so why shouldn't the device be able to interact with a site like gitlab? Contrary to the claim from the founder of Discourse that, within years, every Android user will be on some kind of super fast Android device, it's been six years since his comment and it's going to be at least a decade before almost everyone in the world who's using a phone has a high-speed device and this could easily take two decades or more. If you look up marketshare stats for Discourse, it's extremely successful; it appears to be the fastest growing forum software in the world by a large margin. The impact of having the fastest growing forum software in the world created by an organization whose then-leader was willing to state that he doesn't really care about users who aren't \"influential users who spend money\", who don't have access to \"infinite CPU speed\", is that a lot of forums are now inaccessible to people who don't have enough wealth to buy a device with effectively infinite CPU. If the founder of Discourse were an anomaly, this wouldn't be too much of a problem, but he's just verbalizing the implicit assumptions a lot of programmers have, which is why we see that so many modern websites are unusable if you buy the income-adjusted equivalent of a new, current generation, iPhone in a low-income country. Thanks to Yossi Kreinen, Fabian Giesen, John O'Nolan, Joseph Scott, Loren McIntyre, @acidshill, Alex Russell, Tobias Marschner, Matt Stuchlik, @gekitsu@toot.cat, and David Turner for comments/corrections/discussion. Appendix: gaming LCP We noted above that we used LCP* and not LCP. This is because LCP basically measures when the largest change happens. When this metric was not deliberately gamed in ways that don't benefit the user, this was a great metric, but this metric has become less representative of the actual user experience as more people have gamed it. In the less blatant cases, people do small optimizations that improve LCP but barely improve or don't improve the actual user experience. In the more blatant cases, developers will deliberately flash a very large change on the page as soon as possible, generally a loading screen that has no value to the user (actually negative value because doing this increases the total amount of work done and the total time it takes to load the page) and then they carefully avoid making any change large enough that any later change would get marked as the LCP. For the same reason that VW didn't publicly discuss how it was gaming its emissions numbers, developers tend to shy away from discussing this kind of LCP optimization in public. An exception to this is Discourse, where they publicly announced this kind of LCP optimization, with comments from their devs and the then-CTO (now CEO), noting that their new \"Discourse Splash\" feature hugely reduced LCP for sites after they deployed it. And then developers ask why their LCP is high, the standard advice from Discourse developers is to keep elements smaller than the \"Discourse Splash\", so that the LCP timestamp is computed from this useless element that's thrown up to optimize LCP, as opposed to having the timestamp be computed from any actual element that's relevant to the user. Here's a typical, official, comment from Discourse If your banner is larger than the element we use for the \"Introducing Discourse Splash - A visual preloader displayed while site assets load\" you gonna have a bad time for LCP. The official response from Discourse is that you should make sure that your content doesn't trigger the LCP measurement and that, instead, our loading animation timestamp is what's used to compute `LCP. The sites with the most extreme ratio of LCP of useful content vs. Chrome's measured LCP were: Wix M3: 6 M1: 12 Tecno Spark 8C: 3 Itel P32: (FAIL) Discourse: M3: 10 M1: 12 Tecno Spark 8C: 4 Itel P32: (FAIL) Although we haven't discussed the gaming of other metrics, it appears that some websites also game other metrics and \"optimize\" them even when this has no benefit to users. Appendix: the selfish argument for optimizing sites This will depend on the scale of the site as well as its performance, but when I've looked at this data for large companies I've worked for, improving site and app performance is worth a mind boggling amount of money. It's measurable in A/B tests and it's also among the interventions that has, in long-term holdbacks, a relatively large impact on growth and retention (many interventions test well but don't look as good long term, whereas performance improvements tend to look better long term). Of course you can see this from the direct numbers, but you can also implicitly see this in a lot of ways when looking at the data. One angle is that (just for example), at Twitter, user-observed p99 latency was about 60s in India as well as a number of African countries (even excluding relatively wealthy ones like Egypt and South Africa) and also about 60s in the United States. Of course, across the entire population, people have faster devices and connections in the United States, but in every country, there are enough users that have slow devices or connections that the limiting factor is really user patience and not the underlying population-level distribution of devices and connections. Even if you don't care about users in Nigeria or India and only care about U.S. ad revenue, improving performance for low-end devices and connections has enough of impact that we could easily see the impact in global as well as U.S. revenue in A/B tests, especially in long-term holdbacks. And you also see the impact among users who have fast devices since a change that improves the latency for a user with a \"low-end\" device from 60s to 50s might improve the latency for a user with a high-end device from 5s to 4.5s, which has an impact on revenue, growth, and retention numbers as well. For a variety of reasons that are beyond the scope of this doc, this kind of boring, quantifiable, growth and revenue driving work has been difficult to get funded at most large companies I've worked for relative to flash product work that ends up showing little to no impact in long-term holdbacks. Appendix: designing for low performance devices When using slow devices or any device with low bandwidth and/or poor connectivity, the best experiences, by far, are generally the ones that load a lot of content at once into a static page. If the images have proper width and height attributes and alt text, that's very helpful. Progressive images (as in progressive jpeg) isn't particularly helpful. On a slow device with high bandwidth, any lightweight, static, page works well, and lightweight dynamic pages can work well if designed for performance. Heavy, dynamic, pages are doomed unless the page weight doesn't cause the page to be complex. With low bandwidth and/or poor connectivity, lightweight pages are fine. With heavy pages, the best experience I've had is when I trigger a page load, go do something else, and then come back when it's done (or at least the HTML and CSS are done). I can then open each link I might want to read in a new tab, and then do something else while I wait for those to load. A lot of the optimizations that modern websites do, such as partial loading that causes more loading when you scroll down the page, and the concomitant hijacking of search (because the browser's built in search is useless if the page isn't fully loaded) causes the interaction model that works to stop working and makes pages very painful to interact with. Just for example, a number of people have noted that Substack performs poorly for them because it does partial page loads. Here's a video by @acidshill of what it looks like to load a Substack article and then scroll on an iPhone 8, where the post has a fairly fast LCP, but if you want to scroll past the header, you have to wait 6s for the next page to load, and then on scrolling again, you have to wait maybe another 1s to 2s: As an example of the opposite approach, I tried loading some fairly large plain HTML pages, such as https://danluu.com/diseconomies-scale/ (0.1 MB wire / 0.4 MB raw) and https://danluu.com/threads-faq/ (0.4 MB wire / 1.1 MB raw) and these were still quite usable for me even on slow devices. 1.1 MB seems to be larger than optimal and breaking that into a few different pages would be better on a low-end devices, but a single page with 1.1 MB of text works much better than most modern sites on a slow device. While you can get into trouble with HTML pages that are so large that browsers can't really handle them, for pages with a normal amount of content, it generally isn't until you have complex CSS payloads or JS that the pages start causing problems for slow devices. Below, we test pages that are relatively simple, some of which have a fair amount of media (14 MB in one case) and find that these pages work ok, as long as they stay simple. Appendix: articles on web performance issues 2015: Maciej Cegłowski: The Website Obesity Crisis Size: 1.0 MB / 1.1 MB Tecno Spark 8C: 0.9s / 1.4s Scrolling a bit jerky, images take a little bit of time to appear if scrolling very quickly (jumping halfway down page from top), but delay is below what almost any user would perceive when scrolling a normal distance. 2015: Nate Berkopec: Page Weight Doesn't Matter Size: 80 kB / 0.2 MB Tecno Spark 8C: 0.8s / 0.7s Does lazy loading, page downloads 650 kB / 1.8 MB if you scroll through the entire page, but scrolling is only a little jerk and the lazy loading doesn't cause delays. Probably the only page I've tried that does lazy loading in a way that makes the experience better and not worse on a slow device; I didn't test on a slow connection, where this would still make the experience worse. Itel P32: 1.1s / 1s Scrolling basically unusable; scroll extremely jerky and moves a random distance, often takes over 1s for text to render when scrolling to new text; can be much worse with images that are lazy loaded. Even though this is the implementation of lazy loading I've seen in the wild, the Itel P32 still can't handle it. 2017: Dan Luu: How web bloat impacts users with slow connections Size: 14 kB / 57 kB Tecno Spark 8C: 0.5s / 0.3s Scrolling and interaction work fine. Itel P32:0.7s / 0.5 s 2017-2024+: Alex Russell: The Performance Inequality Gap (series) Size: 82 kB / 0.1 MB Tecno Spark 8C: 0.5s / 0.4s Scrolling and interaction work fine. Itel P32: 0.7s / 0.4s Scrolling and interaction work fine. 2024: Nikita Prokopov (Tonsky): JavaScript Bloat in 2024 Size: 14 MB / 14 MB Tecno Spark 8C: 0.8s / 1.9s When scrolling, it takes a while for images to show up (500ms or so) and the scrolling isn't smooth, but it's not jerky enough that it's difficult to scroll to the right place. Itel P32: 2.5s / 3s Scrolling isn't smooth. Scrolling accurately is a bit difficult, but can generally scroll to where you want if very careful. Generally takes a bit more than 1s for new content to appear when you scroll a significant distance. 2024: Dan Luu: This post Size: 25 kB / 74 kB Tecno Spark 8C: 0.6s / 0.5s Scrolling and interaction work fine. Itel P32: 1.3s / 1.1s Scrolling and interaction work fine, although I had to make a change for this to be the case — this doc originally had an embedded video, which the Itel P32 couldn't really handle. Note that, while these numbers are worse than the numbers for \"Page Weight Doesn't Matter\", this page is usable after load, which that other page isn't beacuse it execute some kind of lazy loading that's too complex for this phone to handle in a reasonable timeframe. Just as an aside, something I've found funny for a long time is that I get quite a bit of hate mail about the styling on this page (and a similar volume of appreciation mail). By hate mail, I don't mean polite suggestions to change things, I mean the equivalent of road rage, but for web browsing; web rage. I know people who run sites that are complex enough that they're unusable by a significant fraction of people in the world. How come people are so incensed about the styling of this site and, proportionally, basically don't care at all that the web is unusable for so many people? Another funny thing here is that the people who appreciate the styling generally appreciate that the site doesn't override any kind of default styling, letting you make the width exactly what you want (by setting your window size how you want it) and it also doesn't override any kind of default styling you apply to sites. The people who are really insistent about this want everyone to have some width limit they prefer, some font they prefer, etc., but it's always framed in a way as if they don't want it, it's really for the benefit of people at large even though accommodating the preferences of the web ragers would directly oppose the preferences of people who prefer (just for example) to be able to adjust the text width by adjusting their window width. Until I pointed this out tens of times, this iteration would usually start with web ragers telling me that \"studies show\" that narrower text width is objectively better, but on reading every study that exists on the topic that I could find, I didn't find this to be the case. Moreover, on asking for citations, it's clear that people saying this generally hadn't read any studies on this at all and would sometimes hastily send me a study that they did not seem to have read. When I'd point this out, people would then change their argument to how studies can't really describe the issue (odd that they'd cite studies in the first place), although one person cited a book to me (which I read and they, apparently, had not since it also didn't support their argument) and then move to how this is what everyone wants, even though that's clearly not the case, both from the comments I've gotten as well as the data I have from when I made the change. Web ragers who have this line of reasoning generally can't seem to absorb the information that their preferences are not universal and will insist that they regardless of what people say they like, which I find fairly interesting. On the data, when I switched from Octopress styling (at the time, the most popular styling for programming bloggers) to the current styling, I got what appeared to be a causal an increase in traffic and engagement, so it appears that not only do people who write me appreciation mail about the styling like the styling, the overall feeling of people who don't write to me appears to be that the site is fine and apparently more appealing than standard programmer blog styling. When I've noted this, people either become further invested in the idea that their preferences are universal and people who think they have other preferences are wrong and reply with total nonsense. I would understand this kind of anger about how much the web has been made unusable for people who aren't, by global standards, fairly well off, but it's curious that so many people find a site that is accessible but accedes to other people's preferences to be a topic worth sending so many angry rants about, as well as one where it's worth fabricating \"objective\" evidence for their opinion. Appendix: empathy for non-rich users Something I've observed over time, as programming has become more prestigious and more lucrative, is that people have tended to come from wealthier backgrounds and have less exposure to people with different income levels. An example we've discussed before, is at a well-known, prestigious, startup that has a very left-leaning employee base, where everyone got rich, on a discussion about the covid stimulus checks, in a slack discussion, a well meaning progressive employee said that it was pointless because people would just use their stimulus checks to buy stock. This person had, apparently, never talked to any middle-class (let alone poor) person about where their money goes or looked at the data on who owns equity. And that's just looking at American wealth. When we look at world-wide wealth, the general level of understanding is much lower. People seem to really underestimate the dynamic range in wealth and income across the world. From having talked to quite a few people about this, a lot of people seem to have mental buckets for \"poor by American standards\" (buys stock with stimulus checks) and \"poor by worldwide standards\" (maybe doesn't even buy stock), but the range of poverty in the world dwarfs the range of poverty in America to an extent that not many wealthy programmers seem to realize. Just for example, in this discussion how lucky I was (in terms of financial opportunities) that my parents made it to America, someone mentioned that it's not that big a deal because they had great financial opportunities in Poland. For one thing, with respect to the topic of the discussion, the probability that someone will end up with a high-paying programming job (senior staff eng at a high-paying tech company) or equivalent, I suspect that, when I was born, being born poor in the U.S. gives you better odds than being fairly well off in Poland, but I could believe the other case as well if presented with data. But if we're comparing Poland v. U.S. to Vietnam v. U.S., if I spend 15 seconds looking up rough wealth numbers for these countries in the year I was born, the GDP/capita ratio of U.S. : Poland was ~8:1, whereas it was ~50 : 1 for Poland : Vietnam. The difference in wealth between Poland and Vietnam was roughly the square of the difference between the U.S. and Poland, so Poland to Vietnam is roughly equivalent to Poland vs. some hypothetical country that's richer than the U.S. by the amount that the U.S. is richer than Poland. These aren't even remotely comparable, but a lot of people seem to have this mental model that there's \"rich countries\" and \"not rich countries\" and \"not rich countries\" are all roughly in the same bucket. GDP/capita isn't ideal, but it's easier to find than percentile income statistics; the quick search I did also turned up that annual income in Vietnam then was something like $200-$300 a year. Vietnam was also going through the tail end of a famine whose impacts are a bit difficult to determine because statistics here seem to be gamed, but if you believe the mortality rate statistics, the famine caused total overall mortality rate to jump to double the normal baseline1. Of course, at the time, the median person in a low-income country wouldn't have had a computer, let alone internet access. But, today it's fairly common for people in low-income countries to have devices. Many people either don't seem to realize this or don't understand what sorts of devices a lot of these folks use. Appendix: comments from Fabian Giesen On the Discourse founder's comments on iOS vs. Android marketshare, Fabian notes In the US, according to the most recent data I could find (for 2023), iPhones have around 60% marketshare. In the EU, it's around 33%. This has knock-on effects. Not only do iOS users skew towards the wealthier end, they also skew towards the US. There's some secondary effects from this too. For example, in the US, iMessage is very popular for group chats etc. and infamous for interoperating very poorly with Android devices in a way that makes the experience for Android users very annoying (almost certainly intentionally so). In the EU, not least because Android is so much more prominent, iMessage is way less popular and anecdotally, even iPhone users among my acquaintances who would probably use iMessage in the US tend to use WhatsApp instead. Point being, globally speaking, recent iOS + fast Internet is even more skewed towards a particular demographic than many app devs in the US seem to be aware. And on the comment about mobile app vs. web app sizes, Fabian said: One more note from experience: apps you install when you install them, and generally have some opportunity to hold off on updates while you're on a slow or metered connection (or just don't have data at all). Back when I originally got my US phone, I had no US credit history and thus had to use prepaid plans. I still do because it's fine for what I actually use my phone for most of the time, but it does mean that when I travel to Germany once a year, I don't get data roaming at all. (Also, phone calls in Germany cost me $1.50 apiece, even though T-Mobile is the biggest mobile provider in Germany - though, of course, not T-Mobile US.) Point being, I do get access to free and fast Wi-Fi at T-Mobile hotspots (e.g. major train stations, airports etc.) and on inter-city trains that have them, but I effectively don't have any data plan when in Germany at all. This is completely fine with mobile phone apps that work offline and sync their data when they have a connection. But web apps are unusable while I'm not near a public Wi-Fi. Likewise I'm fine sending an email over a slow metered connection via the Gmail app, but I for sure wouldn't use any web-mail client that needs to download a few MBs worth of zipped JS to do anything on a metered connection. At least with native app downloads, I can prepare in advance and download them while I'm somewhere with good internet! Another comment from Fabian (this time paraphrased since this was from a conversation), is that people will often justify being quantitatively hugely slower because there's a qualitative reason something should be slow. One example he gave was that screens often take a long time to sync their connection and this is justified because there are operations that have to be done that take time. For a long time, these operations would often take seconds. Recently, a lot of displays sync much more quickly because Nvidia specifies how long this can take for something to be \"G-Sync\" certified, so display makers actually do this in a reasonable amount of time now. While it's true that there are operations that have to be done that take time, there's no fundamental reason they should take as much time as they often used to. Another example he gave was on how someone was justifying how long it took to read thousands of files because the operation required a lot of syscalls and \"syscalls are slow\", which is a qualitatively true statement, but if you look at the actual cost of a syscall, in the case under discussion, the cost of a syscall was many orders of magnitude from being costly enough to be a reasonable explanation for why it took so long to read thousands of files. On this topic, when people point out that a modern website is slow, someone will generally respond with the qualitative defense that the modern website has these great features, which the older website is lacking. And while it's true that (for example) Discourse has features that MyBB doesn't, it's hard to argue that its feature set justifies being 33x slower. Appendix: experimental details With the exception of danluu.com and, arguably, HN, for each site, I tried to find the \"most default\" experience. For example, for WordPress, this meant a demo blog with the current default theme, twentytwentyfour. In some cases, this may not be the most likely thing someone uses today, e.g., for Shopify, I looked at the first thing that theme they give you when you browse their themes, but I didn't attempt to find theme data to see what the most commonly used theme is. For this post, I wanted to do all of the data collection and analysis as a short project, something that takes less than a day, so there were a number of shortcuts like this, which will be described below. I don't think it's wrong to use the first-presented Shopify theme in a decent fraction of users will probably use the first-presente theme, but that is, of course, less representative than grabbing whatever the most common theme is and then also testing many different sites that use that theme to see how real-world performance varies when people modify the theme for their own use. If I worked for Shopify or wanted to do competitive analysis on behalf of a competitor, I would do that, but for a one-day project on how large websites impact users on low-end devices, the performance of Shopify demonstrated here seems ok. For the tests on laptops, I tried to have the laptop at ~60% battery, not plugged in, and the laptop was idle for enough time to return to thermal equilibrium in a room at 20°C, so pages shouldn't be impacted by prior page loads or other prior work that was happening on the machine. For the mobile tests, the phones were at ~100% charge and plugged in, and also previously at 100% charge so the phones didn't have any heating effect you can get from rapidly charging. As noted above, these tests were formed with 1Gbps WiFi. No other apps were running, the browser had no other tabs open, and the only apps that were installed on the device, so no additional background tasks should've been running other than whatever users are normally subject to by the device by default. A real user with the same device is going to see worse performance than we measured here in almost every circumstance. Sizes were all measured on mobile, so in cases where different assets are loaded on mobile vs. desktop, the we measured the mobile asset sizes. CPU was measured as CPU time on the main thread (I did also record time on other threads for sites that used other threads, but didn't use this number; if CPU were a metric people wanted to game, time on other threads would have to be accounted for to prevent sites from trying to offload as much work as possible to other threads, but this isn't currently an issue and time on main thread is more directly correlated to usability than sum of time across all threads, and the metric that would work for gaming is less legible with no upside for now). For WiFi speeds, speed tests had the following numbers: M3 Max Netflix (fast.com) Download: 850 Mbps Upload: 840 Mbps Latency (unloaded / loaded): 3ms / 8ms Okta Download: 900 Mbps Upload: 840 Mbps Latency (unloaded / download / upload): 3ms / 8ms / 13ms Tecno Spark 8C Netflix (fast.com) Download: 390 Mbps Upload: 210 Mbps Latency (unloaded / loaded): 2ms / 30ms Okta Okta web app fails, can't see results Itel P32 Netflix Download: 44 Mbps Upload: test fails to work (sends one chunk of data and then hangs, sending no more data) Latency (unloaded / loaded): 4ms / 400ms Okta Download: 45 Mbps Upload: test fails to work Latency: test fails to display latency One thing to note is that the Itel P32 doesn't really have the ability to use the bandwidth that it nominally has. Looking at the top Google reviews, none of them mention this. The first review reads Performance-wise, the phone doesn’t lag. It is powered by the latest Android 8.1 (GO Edition) ... we have 8GB+1GB ROM and RAM, to run on a power horse of 1.3GHz quad-core processor for easy multi-tasking ... I’m impressed with the features on the P32, especially because of the price. I would recommend it for those who are always on the move. And for those who take battery life in smartphones has their number one priority, then P32 is your best bet. The second review reads Itel mobile is one of the leading Africa distributors ranking 3rd on a continental scale ... the light operating system acted up to our expectations with no sluggish performance on a 1GB RAM device ... fairly fast processing speeds ... the Itel P32 smartphone delivers the best performance beyond its capabilities ... at a whooping UGX 330,000 price tag, the Itel P32 is one of those amazing low-range like smartphones that deserve a mid-range flag for amazing features embedded in a single package. The third review reads \"Much More Than Just a Budget Entry-Level Smartphone ... Our full review after 2 weeks of usage ... While switching between apps, and browsing through heavy web pages, the performance was optimal. There were few lags when multiple apps were running in the background, while playing games. However, the overall performance is average for maximum phone users, and is best for average users [screenshot of game] Even though the game was skipping some frames, and automatically dropped graphical details it was much faster if no other app was running on the phone. Notes on sites: Wix www.wix.com/website-template/view/html/3173?originUrl=https%3A%2F%2Fwww.wix.com%2Fwebsite%2Ftemplates%2Fhtml%2Fmost-popular&tpClick=view_button&esi=a30e7086-28db-4e2e-ba22-9d1ecfbb1250: this was the first entry when I clicked to get a theme LCP was misleading on every device On the Tecno Spark 8C, scrolling never really works. It's very jerky and this never settles down On the Itel P32, the page fails non-deterministically (different errors on different loads); it can take quite a while to error out; it was 23s on the first run, with the CPU pegged for 28s Patreon www.patreon.com/danluu: used my profile where possible Scrolling on Patreon and finding old posts is so painful that I maintain my own index of my Patreon posts so that I can find my old posts without having to use Patreon. Threads threads.net/danluu.danluu: used my profile where possible On the Itel P32, this technically doesn't load correctly and could be marked as FAIL, but it's close enough that I counted it. The thing that's incorrect is that profile photos have a square box around then However, as with the other heavy pages, interacting with the page doesn't really work and the page is unusable, but this appears to be for the standard performance reasons and not because the page failed to render Twitter twitter.com/danluu: used my profile where possible Discourse meta.discourse.org: this is what turned up when I searched for an official forum. As discussed above, the LCP is highly gamed and basically meaningless. We linked to a post where the Discourse folks note that, on slow loads, they put a giant splash screen up at 2s to cap the LCP at 2s. Also notable is that, on loads that are faster than the 2s, the LCP is also highly gamed. For example, on the M3 Max with low-latency 1Gbps internet, the LCP was reported as 115ms, but the page loads actual content at 1.1s. This appears to use the same fundamental trick as \"Discourse Splash\", in that it paints a huge change onto the screen and then carefully loads smaller elements to avoid having the actual page content detected as the LCP. On the Tecno Spark 8C, scrolling is unpredictable and can jump too far, triggering loading from infinite scroll, which hangs the page for 3s-10s. Also, the entire browser sometimes crashes if you just let the browser sit on this page for a while. On the Itel P32, an error message is displayed after 7.5s Bluesky bsky.app/profile/danluu.com Displays a blank screen on the Itel P32 Squarespace cedar-fluid-demo.squarespace.com: this was the second theme that showed up when I clicked themes to get a theme; the first was one called \"Bogart\", but that was basically a \"coming soon\" single page screen with no content, so I used the second theme instead of the first one. A lot of errors and warnings in the console with the Itel P32, but the page appears to load and work, although interacting with it is fairly slow and painful LCP on the Tecno Spark 8C was significantly before the page content actually loaded Tumblr www.tumblr.com/slatestarscratchpad: used this because I know this tubmlr exists. I don't read a lot of tumblers (maybe three or four), and this one seemed like the closest thing to my blog that I know of on tumblr. This page fails on the Itel P32, but doesn't FAIL. The console shows that the JavaScript errors out, but the page still works fine (I tried scrolling, clicking links, etc., and these all worked), so you can actually go to the post you want and read it. The JS error appears to have made this page load much more quickly than it other would have and also made interacting with the page after it loaded fairly zippy. Shopify themes.shopify.com/themes/motion/styles/classic/preview?surface_detail=listing&surface_inter_position=1&surface_intra_position=1&surface_type=all: this was the first theme that showed up when I looked for themes On the first M3/10 run, Chrome dev tools reported a nonsensical 697s of CPU time (the run completed in a normal amount of time, well under 697s or even 697/10s. This run was ignored when computing results. On the Itel P32, the page load never completes and it just shows a flashing cursor-like image, which is deliberately loaded by the theme. On devices that load properly, the flashing cursor image is immediately covered up by another image, but that never happens here. I wondered if it wasn't fair to use this example theme because there's some stuff on the page that lets you switch theme styles, so I checked out actual uses of the theme (the page that advertises the theme lists users of the theme). I tried the first two listed real examples and they were both much slower than this demo page. Reddit reddit.com Has an unusually low LCP* compared to how long it takes for the page to become usable. Although not measured in this test, I generally find the page slow and sort of unusable on Intel Macbooks which are, by historical standards, extremely fast computers (unless I use old.reddit.com) Mastodon mastodon.social/@danluu: used my profile where possible Fails to load on Itel P32, just gives you a blank screen. Due to how long things generally take on the Itel P32, it's not obvious for a while if the page is failing or if it's just slow Quora www.quora.com/Ever-felt-like-giving-up-on-your-dreams-How-did-you-come-out-of-it: I tried googling for quora + the username of a metafilter user who I've heard is now prolific on Quora. Rather than giving their profile page, Google returned this page, which appears to have nothing to do with the user I searched for. So, this isn't comparable to the social media profiles, but getting a random irrelevant Quora result from Google is how I tend to interact with Quora, so I guess this is representative of my Quora usage. On the Itel P32, the page stops executing scripts at some point and doesn't fully load. This causes it to fail to display properly. Interacting with the page doesn't really work either. Substack Used thezvi.substack.com because I know Zvi has a substack and writes about similar topics. vBulletin: forum.vbulletin.com: this is what turned up when I searched for an official forum. Medium medium.com/swlh: I don't read anything on Medium, so I googled for programming blogs on Medium and this was the top hit. From looking at the theme, it doesn't appear to be unusually heavy or particularly customized for a Medium blog. Since it appears to be widely read and popular, it's more likely to be served from a CDN and than some of the other blogs here. On a run that wasn't a benchmark reference run, on the Itel P32, I tried scrolling starting 35s after loading the page. The delay to scroll was 5s-8s and scrolling moved an unpredictable amount, making the page completely unusable. This wasn't marked as a FAIL in the table, but one could argue that this should be a FAIL since the page is unusable. Ghost source.ghost.io because this is the current default Ghost theme and it was the first example I found Wordpress 2024.wordpress.net because this is the current default wordpress theme and this was the first example of it I found XenForo xenforo.com/community/: this is what turned up when I searched for an official forum On the Itel P32, the layout is badly wrong and page content overlaps itself. There's no reasonable way to interact with the element you want because of this, and reading the text requires reading text that's been overprinted multiple times. Wordpress (old) Used thezvi.wordpress.com because it has the same content as Zvi's substack, and happens to be on some old wordpress theme that used to be a very common choice phpBB www.phpbb.com/community/index.php: this is what turned up when I searched for an official forum. MyBB community.mybb.com: this is what turned up when I searched for an official forum. Site doesn't serve up a mobile version. In general, I find the desktop version of sites to be significantly better than the mobile version when on a slow device, so this works quite well, although they're likely penalized by Google for this. HN news.ycombinator.com In principle, HN should be the slowest social media site or link aggregator because it's written in a custom Lisp that isn't highly optimized and the code was originally written with brevity and cleverness in mind, which generally gives you fairly poor performance. However, that's only poor relative to what you'd get if you were writing high-performance code, which is not a relevant point of comparison here. danluu.com Self explanatory This currently uses a bit less CPU than HN, but I expect this to eventually use more CPU as the main page keeps growing. At the moment, this page has 176 links to 168 articles vs. HN's 199 links to 30 articles but, barring an untimely demise, this page should eventually have more links than HN. As noted above, I find that pagination for such small pages makes the browsing experience much worse on slow devices or with bad connections, so I don't want to \"optimize\" this by paginating it or, even worse, doing some kind of dynamic content loading on scroll. Woo Commerce I originally measured Woo Commerce as well but, unlike the pages and platforms tested above, I didn't find that being fast or slow on the initial load was necessarily representative of subsequent performance of other action, so this wasn't included in the table because having this in the table is sort of asking for a comparison against Shopify. In particular, while the \"most default\" Woo theme I could find was significantly faster than the \"most default\" Shopify theme on initial load on a slow device, performance was multidimensional enough that it was easy to find realistic scenarios where Shopify was faster than Woo and vice versa on a slow device, which is quite different from what I saw with newer blogging platforms like Substack and Medium compared to older platforms like Wordpress, or a modern forum like Discourse versus the older PHP-based forums. A real comparison of shopping sites that have carts, checkout flows, etc., would require a better understanding of real-world usage of these sites than I was going to get in a single day. Another kind of testing would be to try to configure pages to look as similar as possible. I'd be interested in seeing that results for that if anyone does it, and maybe I'll try doing that on another day if no one else does it. This estimate puts backwards-looking life expectancy in the low 60s; that paper also discusses other estimates in the mid 60s and discusses biases in the estimates. [return]",
    "commentLink": "https://news.ycombinator.com/item?id=39729057",
    "commentBody": "How web bloat impacts users with slow devices (danluu.com)640 points by jasondavies 13 hours agohidepastfavorite371 comments ericra 12 hours agoAs someone with recent experience using a relatively slow Android phone, it can be absolutely brutal to load some web pages, even ones that only appear to be serving text and images (and a load of trackers/ads presumably). The network is never the bottleneck here. This problem is compounded by several factors. One is that older/slower phones cannot always use fully-featured browsers such as Firefox for mobile. The app is takes too many resources on its own before even opening up a website. That means turning to a pared-down browser like Firefox Focus, which is ok except for not being able to have extensions. That means no ublock origin, which of course makes the web an even worse experience. Another issue is that some sites will complain if you are not using a \"standard\" browser and the site will become unusable for that reason alone. In these situations, companies frequently try to force an app down your throat instead. And who knows how much space that will take up on a space-limited device or how poorly it will run. Many companies/sites used to have simplified versions to account for slower devices/connections, but in my experience these are becoming phased out and harder to find. I imagine it's much harder to serve ads and operate a full tracking network to/from every social media company without all the javascript bloat. reply swiftcoder 1 hour agoparent> In these situations, companies frequently try to force an app down your throat instead. And who knows how much space that will take up on a space-limited device or how poorly it will run. And honestly, that app is going to be a browser shell with a (partially) offline copy of the website in it, 9 times out of 10... reply MaxBarraclough 4 minutes agorootparent> that app is going to be a browser shell with a (partially) offline copy of the website in it, 9 times out of 10 If you're lucky. The main UI may just be a website, but as a native app is has a greater ability to spam you, track you, accidentally introduce security vulnerabilities, etc. reply pixl97 10 hours agoparentprev> That means no ublock origin Talk about a catch-22 situation. The modern web is useless without adblocking. Especially when you get forever scrolling pages with random ads stuffed in there. reply nox101 1 hour agorootparentI just choose not to use it. if I follow a link and there is an ad per paragraph and video starts playing I close the tab. it's rare the page I was about to look at was actually important reply squarefoot 9 hours agorootparentprevAs a web developing illiterate, I wonder how hard would be writing a browser extension that loads a page, does infinite scroll in memory and in background, then while it is still loading the infinite stuff, splits the content in pages and shows them instead, so that the user can go back and forth to page numbers. This wouldn't reduce the network and system load, however navigating the results would be much more friendly. reply freedomben 8 hours agorootparentProblem is, \"infinite scroll\" often is infinite, meaning it will load an ass load of data in the background and take up a ton of memory, and the user may never even end up looking at that data. I really hate the load on scroll (especially Google Drive's implementation which is absolute trash, and half the time I'll scroll too fast and it will just miss a bunch of files and I'll have to refresh the page and try again), but a better hack might be an extension that scrolls a page or two ahead for you and stores that in memory. If it was smart enough to infinitely scroll websites that are actually finite (like google drive) that would be amazing though. reply jwells89 8 hours agorootparentIn these situations what’s eating up your resources usually isn’t the data being represented but instead the representation. This is why native apps use recycler views for not just infinite scroll, but anything that can display more rows/columns/items/etc than can fit on screen at once. Recycler views only create just enough cells to fill the screen even if you have tens of thousands of items to represent, and when you scroll they reuse these cells to display the currently relevant segment of data. When used correctly by developers, these are very lightweight and allow 60FPS scrolling of very large lists even on very weak devices. These are possible to implement in JavaScript in browsers, but implementation quality varies a lot and many web devs just never bother. This is why I think HTML should gain a native recycler widget of its own, because the engineers working on Blink, Gecko, and WebKit are in much better positions to write high quality optimized implementations, plus even if web devs don’t use it directly, many frameworks will. reply kcrwfrd_ 3 hours agorootparentThere was a proposal for a browser-native virtual scroller: https://wicg.github.io/virtual-scroller/ Apparently it was abandoned (for now?) in favor of content-visibility / CSS containment primitives: https://web.dev/articles/content-visibility reply Sn0wCoder 7 hours agorootparentprevI find this idea interesting ‘These are possible in JavaScript in browsers, but implementation quality varies a lot and many web devs just never bother.’ Do you have any examples that you consider good implementations? I ask because tables seem to be the biggest offenders of slow components in say Angular / PrimeNG. I am going to a legacy app soon that is being updated (Angular but not PrimeNG). Would like to see if we can build a feature rich table that is more performant than the PrimeNG one that I know looks amazing but is the cause of many headaches. NOTE: its not Angular or PrimeNG specifically that make the tables slow/hogs, but the amount of DOM elements inside and some of the implementation details that I disagree with (functions that are called withing the HTML being evaluated every tick). Would be great to see if this idea of a ‘recycler widget’ can help us. Cheers. reply nmjenkins 4 hours agorootparentWe do this at Fastmail and, if I say so myself, our implementation is pretty damn good. We’ve had this for over a decade, so it was originally built for much lower powered devices. reply jwells89 6 hours agorootparentprev> its not Angular or PrimeNG specifically that make the tables slow/hogs, but the amount of DOM elements inside Yep, this happens even with nothing but a 10-line vanilla JS file that adds N more items every time the user scrolls to the bottom of the page. Performance degradation increases with every load due to the growing number of DOM elements which eventually exceeds whatever margin is afforded by the machine the browser is running on, causing chug. Web is not my specialty so I don’t have specific recommendations, but plenty of results turn up when searching for e.g. “angular recycler” or “react recycler”. reply d1sxeyes 48 minutes agorootparentprevYou don’t actually need to load everything, just the previous, current, and next pages. reply thaumasiotes 3 hours agorootparentprev> Problem is, \"infinite scroll\" often is infinite, meaning it will load an ass load of data in the background and take up a ton of memory, and the user may never even end up looking at that data. It's also an infinitely worse user experience and prevents you from holding your place in whatever is being scrolled. Are there advantages? Why is infinite scroll used in any context? reply _flux 1 hour agorootparentPersonally I prefer infinite scroll, versus the alternative of finding the \"next page\" button at the bottom, waiting for the content to load (preloading could help here) and sometimes navigating to the beginning of actual beginning of the content I was viewing. I even used a browser extension that matched \"next\" buttons from pages and loaded the next page content automatically, but the extension (can't recall its name) is not available anymore. Granted there are some downsides, such as having the browser keep extra-long pages in its memory, but overall I prefer working infinite scroll mechanisms over paged ones. As far as I see, the ability to remember the current location in the page could be easily implemented by modifying page anchor and parameters accordingly, though personally I've rarely needed it. Perhaps if there was a standard way (so in the HTML spec) to implement infinite scrolling, it would work correctly in all cases and possibly even allow user to select a paged variant according to their preference. Not all the paged views work correctly either. In particular systems that show threaded discussions can behave strangely when you select the next page. Worst offender is Slashdot. reply kmacdough 1 hour agorootparentprev1 batch of content = 1 batch of add space = more money. Each next page click is a moment for you to reflect and notice the waste of time. Simple as that. reply wolpoli 8 hours agorootparentprevIt'll give a nicer experience and will eliminate situation where an element changes location just as you try to tap on it. The extension just needs to handle GDPR notice and Email subscription overlays. reply gmokki 3 hours agoparentprevI wrote code to main nokia.com site 10 years ago where it used few ways to detect slow loading of resources and set a flag to disable extra features from the site. This was done because the site had to work in every country and many of the slowest phones sold were from said company. reply dijit 2 hours agorootparentI also worked for Nokia 13 or so years ago, though not on Nokia.com Thanks for your work, one of the things that I really liked about Nokia was the passion for performance. On the flip side: I was on the Meego project and we joked that we had the most expensive clock application ever created, because it kept being completely recreated. reply SturgeonsLaw 40 minutes agorootparentI liked Meego and Maemo, I always felt that they were an expression of the idea that general purpose computing can work in the mobile form factor, which is something that tremendously appeals to me (I wish I still had my N900). reply anon373839 6 hours agoparentprevI've got an old MacBook Pro from 2013 that I still keep around because the keyboard is the best Apple ever made. It's not fast by any means, but I haven't encountered any difficulty with websites whatsoever. They're not as snappy as I'd expect on new hardware, but perfectly usable. I do use uBlock Origin, however. Are these Androids actually less powerful than an 11 year-old, base-spec MacBook? reply ericra 6 hours agorootparent> Are these Androids actually less powerful than an 11 year-old, base-spec MacBook? Yes. Definitely. a Macbook Pro from 2013 has between 4-16GB of memory for one thing. The lowest spec phone in the article (Itel P32) has 1GB. A 2013 Macbook Pro has a 4th gen i5 processor. This phone has a MediaTek MT6580. It's not even in the same ballpark. This is a bit of an extreme example, but the fact is that a very large number of people in many areas of the world use phones like these. reply jwells89 5 hours agorootparentAdditionally, weak Android devices are not necessarily old Android devices. New underpowered Android stuff is sold every day. Cheap tablets are particularly bad about this — I have a Lenovo tablet that I bought maybe a year ago which uses a SoC that benches a bit above a 2015 Apple A9. reply mattl 7 hours agoparentprevCan you run all your traffic through a self-hosted pihole to avoid such things? reply ericra 6 hours agorootparentCertainly an option for me. But not a scalable solution for the large number of non-tech people with older devices. reply bombcar 3 hours agorootparentWasn’t there an old browser that would render the page on the server and just send down the result or something like that? reply kreddor 2 hours agorootparentThe old Opera for mobile did that. I think Chrome had something similar at one point. reply jamiek88 2 hours agorootparentprevOpera! reply mattl 6 hours agorootparentprevI’d love something like it for all my older devices where I can set it and forget it. reply SkyArrow 6 hours agorootparentNextDNS is pretty good for this - just change the DNS in your network settings. reply NicoJuicy 1 hour agorootparentYou'll also need to add bundles to block dns names ( free fyi) reply em3rgent0rdr 6 hours agorootparentprevHaving a decent internet experience shouldn't require going through your own self-hosted server. reply mattl 6 hours agorootparentAbsolutely not but then I never thought I’d need a 20,000 entry hosts file either. reply porcoda 3 hours agoprevI like how most people blame bosses or scary big companies. No developers appear willing to admit that there is a large cohort of not that great web programmers who don’t know much (and appear to not WANT to know much) about efficiency. They’re just as to blame for the sad world of web software as the big boss or corporate overlord that forced someone to make bad software. reply bezbac 2 hours agoparentThat's not fair. Sure, if there's an experienced dev who _values_ efficiency on the team, who pushes for the site to be more efficient or builds it more efficiently to begin with, the page would be better off. But it's mostly about incentives. If management doesn't care, they will likely not react well to programmers spending time making the site more efficient instead of spending half the time to just get it running and then crunching through their backlog. reply zilti 1 hour agorootparentIt usually requires less time, not more, to create a slim and efficient page. reply rokkamokka 47 minutes agorootparentDefinitely not true in my experience, and I would think if it were true, most pages would be \"slim and efficient\". Where is the business value in doing anything else at that point? reply zelphirkalt 30 minutes agorootparentThe GP might not always be true, but no, we would not have slim and efficient sites, because of push web developers get to include all kinds of unnecessary tracking and in general bloat on websites. reply ksec 9 minutes agoparentprevProbably a bit of both. Client Side Rendering ( Regardless of Frameworks ) is hip, and gets more media attention. Sometimes backed by VC. It is new, it is complex. And fits both the hype cycle, software engineers complexity attraction, and Resume Driven Development model. And just like the article stated, it is suppose to bring so many good things in its idealogy to the table. Since majority of software developers wants to works on it, so their Resume gets a tick and could jump to another job later. Management now faces lots of application for these technology and zero for old and boring tech. >great web programmers who don’t know much (and appear to not WANT to know much) about efficiency. Remember when Firefox OS developers thought $35 dollar Smartphone will one day take over the world and CPU will be so much faster due to Moore's law, performance will soon becomes irrelevant. I mean that is like Jeff hates Qualcomm, without actually understanding anything about Mobile SoC business nor the CPU behind it. And how ARM's IP works. A lot of people dont want to know \"why\" either. A more accurate description and also a general observation. Most software developers and especially those on Web Development have very little understanding of hardware or low level Software engineering. Cloud Computing makes this even more abstracted. reply dijit 2 hours agoparentprev\"it's better for the company that I don't try, my time is expensive and any minute not spent on a feature is a waste of my salary\" - is a common justification that I hear all too often. reply autoexec 2 hours agorootparent\"It's better for the company that I don't try\" seems like a convenient take for a dev without the skills to have. I'd argue that performance is a feature, and if someone can't deliver it their salary is being wasted already. reply TheAceOfHearts 52 minutes agorootparentPerformance is a feature and management often doesn't care to optimize for it. If the market valued performance more then we would probably see competitive services which optimize for performance, but we generally don't. I'm sure there's plenty of developers that could deliver improved performance, it's just a matter of tradeoffs. Maybe the people who care this much about performance should start competing services or a consulting firm which optimizes for that. Better yet, they could devote their efforts to helping create educational content and improved frameworks or tooling which yields more performant apps. reply zelphirkalt 21 minutes agorootparentOne issue is, that the caring about performance is often not visible. How does management accout for or measure how annoyed people get visiting their bloated websites? How many people do not know better, how fast and snappy a not bloated website can be, because they apend all their time on Instagram, FB, and co? Even if a company does measure it somehow via some kind of truly well executed A/B test, other explanations might be reached for, to explain why a user left the website, than the performance. reply tdudhhu 1 hour agoparentprevYou are right. I browse the web on Firefox with uBlock Origin, 3rd party cookies disabled, and so on. So I am missing the bloat most people talk about. But still apps like Clickup are really slow. It's just bad software. reply holri 2 hours agoparentprevUsually bad web software correlates with bad content. Therefore having a slow device is an excellent filter helping to avoid garbage. reply bluquark 11 hours agoprevDan's point about being aware of the different levels of inequality in the world is something I strongly agree with, but that should also include the middle-income countries, especially in Latin America and Southeast Asia. For example, a user with a data plan with a monthly limit in the single-digit GBs, and a RAM/CPU profile resembling a decade-old US flagship. That's good enough to use Discourse at all, but the experience will probably be on the unpleasantly slow side. I believe it's primarily this category of user that accounts for Dan's observation that incremental improvements in CPU/RAM/disk measurably improve engagement. As for users with the lowest-end devices like the Itel P32, Dan's chart seems to prove that no amount of incremental optimization would benefit them. The only thing that might is a wholesale different client architecture that sacrifices features and polish to provide the slimmest code possible. That is, an alternate \"lite/basic\" mode. Unfortunately, this style of approach has rarely proved successful: the empathy problem returns in a different guise, as US-based developers often make the wrong decisions on which features/polish are essential to keep versus discarded for performance reasons. reply zozbot234 9 hours agoparent> That's good enough to use Discourse at all, but the experience will probably be on the unpleasantly slow side. ... an alternate \"lite/basic\" mode Why does this need to be the \"alternate\" choice though? What does current Discourse provide that e.g. PhpBB or the DLang forum do not? (Other than mobile friendly design, which in a sane world shouldn't involve more than a few tweaks to a \"responsive\" CSS stylesheet). reply AJ007 8 hours agorootparentI was thinking about this when I saw this post earlier today. Why shouldn't the default be: does this website work in Lynx? I think that's a damn good baseline. And in response to the other parent post, on a (almost) new iPhone, both news sites & Twitter continuously crash and reload for me. I'm not sure what the state of these other popular sites are because I don't use them. reply mardifoufs 8 hours agorootparentprevI like the scroll view in discourse. Makes it super easy to follow a thread. The subthreads and replies are also easier to use. The search is better, the ability to upvote makes it better for some use cases, and in general phpbb is a mess in terms of actually being able to see what's useful and what threads are relevant. I think flipping the question makes more sense, why do you think some forums switched to or started using discourse instead of just using phpbb? I can guarantee you that it's not just to follow a fad or whatever, most niche or support forums don't care about that. reply ParetoOptimal 3 hours agorootparentI do think trendiness and modern feeling uis are requirements for most forums these days from most perspectives. I say this as someone that frequently uses and enjoys both rue brutalist design of a text web browser and the emacs mastodon client. reply Cacti 9 hours agorootparentprevVoice, video, realtime interaction, a devoted user base, an incredible amount of money… reply zelphirkalt 9 hours agorootparentWhat do you mean by voice and video? Why would I want to have voice in a forum? I think that would be akin to receiving voice messages in messengers. Or do you mean, that for these kinds of things a widget can be displayed? That certainly is possible in old style forums. It is just HTML, an embed code away. reply a_bored_husky 9 hours agorootparentprevDiscourse, not Discord. reply jhanoncomm 11 hours agoparentprevIf all the sites tot more efficient it may also increase longevity of laptops and PCs where unsavvy people might just “need a new computer it is getting slow”. Also applies to bloatware shipped with computers. To the point where I was offered a $50 “tune up” to a new laptop I purchased recently. Imagine a new car dealer offered you that! reply genewitch 10 hours agorootparentI worked at a now-defunct electronics store (not fry's in this instance) in the early 2000s that offered this \"tune-up\" - it was to remove the stuff that HP and Dell got paid to pre-install, and to fully update windows and whatever else. Remove the mcafee nuisance popups and any browser \"addons\" that were badged/branded. and IIRC we charged more than $50 for that service back then. reply fbdab103 9 hours agorootparentFor the performance boost it could offer the unsavy user stuck on a HDD, it was probably worth it to many. Gross to be the middleman, but it is what it is. reply genewitch 1 hour agorootparentAnother computer shop i worked in charged $90 for virus removal, but we also eventually made it policy to just reformat/reimage the drive and remove all the crap and fully update the OS. Prior to that the policy was \"remove viruses, remove crapware, update OS\", but we had a few customers that had machines with 30,000 viruses. I forget what the record was, but it was way up there in count. Trying to clean those machines had a marginal failure rate, enough that it was costing the owner money to have us repeatedly clean them without payment. No one wants to tell a customer that they need to find better adult content sites, and that we won't be cleaning their machines without payment anymore! reply goalieca 10 hours agoparentprev> For example, a user with a data plan with a monthly limit in the single-digit GBs, and a RAM/CPU profile resembling a decade-old US flagship I’m in Canada and have a single digit plan and I just upgraded from an almost decade old flagship. Most websites are torture. reply II2II 7 hours agorootparentI'm in Canada and have a triple-digit plan, in MBs. It's for emergency use only. It would be nice if something as simple as checking on power outages didn't chew up a good portion of the data plan. reply doubled112 6 hours agorootparentI had a 200MB plan for $35/month until early 2022. It was an old Koodo plan. I never used it. I don't do a lot. WiFi at home, drive to work, WiFi at work, drive to home. Travelling with the kids I've found the new plan makes life easier. reply 123yawaworht456 9 hours agorootparentprevin mid 00's, I had ADSL with iirc ≈300 MB included in the monthly payment, with an extremely predatory rate over the limit. I used to stretch it for 3 weeks out of a month browsing with images disabled (and bulk of my bandwidth spent on Warcraft 3). that would last for a few hours of lightweight (not youtube/images/etc) browsing now. reply prisenco 10 hours agoparentprev> an alternate \"lite/basic\" mode. In another world this mode dominated UI/UX design and development and the result was beautiful and efficient. Where design more resembles a haiku than an unedited novel. We don't get to live in that world, but it's not hard to imagine. reply bee_rider 9 hours agorootparentI think it is sort of hard to imagine; a world populated mostly by humans that appreciate that sort of simplicity is pretty different! If we had modern computers in 200X, we wouldn’t just have music on our myspaces, we’d put whole games there I bet. reply csande17 8 hours agorootparentPeople did, in fact, embed games on MySpace, mostly using Flash if I recall correctly. reply Telemakhos 8 hours agoparentprevIt's not even just the middle-income countries—I have an iPhone 13, so only three years old, on a US wifi connection with high speed broadband, and it can't handle the glitzy bloat of the prospectus for one of my ETFs. I don't understand why a prospectus shouldn't just be a PDF anyway, but it baffles me that someone would put so much bloated design into a prospectus that a recent phone can't handle it. reply eviks 3 hours agorootparentIt shouldn't be a PDF because they don't reflow text, especially important for phones reply yawaramin 9 hours agoparentprev> The only thing that might is a wholesale different client architecture that sacrifices features and polish to provide the slimmest code possible. That is, an alternate \"lite/basic\" mode. Unfortunately, this style of approach has rarely proved successful But it is gaining popularity with the unexpected rise of htmx and its 'simpler is better even if it's slightly worse' philosophy. reply golergka 9 hours agorootparentIsn't that 'worse is better' philosophy? reply LoganDark 7 hours agorootparentI think it's rather a \"performance is more important than functionality\" philosophy. reply yawaramin 6 hours agorootparentIn the case of the devices we're talking about, performance is effectively functionality. reply LoganDark 6 hours agorootparentMy point exactly. By making your website fast and light, you make it easier and more pleasant to use. HTMX has a limited set of actions that it supports, so it can't do everything that people typically want. It can do more than enough though. (remember websites that actually used the `` element?) reply bombcar 3 hours agoparentprevMost of those users have the advantage of not using English - and so there are often sites in their native language that cater to lower power devices. But if you’re in that middle world country AND your official language is English, you’re gonna have a hell of a slow time. reply gxs 11 hours agoparentprevSome of these sites are un-fucking-bearable on my gen old iPhone. And the if I’m in a place with a shitty signal, forget about it, this problem is 10 times worse. I’m not even talking about the cluttered UI where only a third of the page is visible because of frozen headers and ads, I’m talking about the size of the websites themselves that are built by people who throw shit against the wall until it looks like whatever design document they were given. A website that would have already been bloated had it been built correctly that then becomes unusable on a slow internet connection, forget slow hardware. All that is to say, I can’t imagine what it must be like to use the internet under the circumstances in which you described. I can only hope these people use localized sites built for their bandwidth and devices and don’t have to interact with the bloated crap we deal with. reply ryukoposting 13 hours agoprevI only recently moved from a 6-year old LG flagship phone to a shiny new Galaxy, and the performance difference is staggering. It shouldn't be - that was a very high-end phone at release, it's not that old, and it still works like new. I know it's not just my phone, because the Galaxy S9s I use to test code have the same struggles. I would like to have seen Amazon in the tests. IME Amazon's website is among the absolute worst of the worst on mobile devices more than ~4 years old. Amazon was the only site I accessed regularly that bordered on unusable, even with relatively recent high-end mobile hardware. reply eric__cartman 12 hours agoparentI have noticed with two 7 year old Snapdragon 835 devices that RAM and running a recent Android version makes a huge difference. I daily drive a OnePlus 5 running Android 14 through LineageOS and the user experience for non-gaming tasks is perfectly adequate. This phone has 6GB of ram, so it's still on par with most mid-range phones nowadays. My only gripe is that I had to replace the battery and disassembling phones is a pain. Meanwhile a Galaxy S8 with the same SoC, 4GB of memory and stock Android 9 with Samsung's modifications chugs like there's no tomorrow. I can understand that having two more gigabytes of memory can make a difference but there is a night and day difference between the phones. Perhaps Android 14 has way better memory management than Android 9? Or Samsung's slow and bloated software is hampering this device? Either way it's irritating to see that many companies don't test on old/low-end devices. Most people in the world aren't running modern flagships, especially if they target a world-wide audience. reply hinkley 12 hours agorootparentThis is what I miss from the removal of serviceable components on MacBooks. Was a time I would buy the fastest processor and just okay memory and disk, then the first time I got a twinge of jealousy about the new machines, buy the most Corsair memory that they would guarantee would work, and a bigger faster drive. Boom, another 18 months of useful lifetime. reply lotsofpulp 11 hours agorootparentIs the total useful lifetime more than MacBooks with non serviceable components? I see people around me easily using Airs for 5+ years. reply stavros 10 hours agorootparentYes, but that's the slow-boiled frog syndrome. I use my computers for years as well, and whenever I get a new one I think \"wow, why didn't I switch sooner, this is so much snappier\". reply ghaff 9 hours agorootparentAs a counterpoint, I have a 2015 MacBook, a 2015 iMac, and a recent Apple Silicon MacBook. Of course I do Photoshop, Lightroom, Generative AI, etc. on the Apple Silicon system. But I basically don't care which system I browse the web with and, in fact, the iMac is my usual for video calls and a great deal of my web document creation and the like. I suspect that people who have somewhat older Macs (obviously there's some limit) who find their web browsing intolerably slow probably have something else going on with either their install or their network. reply BolexNOLA 10 hours agorootparentprevI’ve been a Mac user since 2003 or so and I can confidently say my machines last 6-7 years as daily drivers then sunset over 2-3 years when I get a new computer. I always go tower, laptop, tower, laptop. They have a nice overlap for a few years that serves me well. reply kome 11 hours agorootparentprevMy MacBook Air (11-inch, Early 2014) is my only computer. I still don't feel like changing it so far... reply zer00eyz 10 hours agorootparentMy air isnt that old, and I'm eyeing a new one... I find that a lot of my work is \"remote\" at this point. Im doing most things on Servers, VM's, and containers on other boxes. The few apps that I do run locally are suffering (browser being the big offender). Is most of what you're doing remote? Do you have a decent amount of ram in that air? reply Baguette5242 10 hours agorootparentprevAmateur… I am using a 2009 15’ MacBook Pro Unibody, with a swapped SuperDrive to SSD, another main SSD and RAM boosted to 8Gb. OpenCore Legacy to update to a relatively recent version of MacOS. The only thing that is so annoying is the webcam that doesn’t work anymore, and a USB port is dead also. So sad this kind of shenanigans are not possible anymore. reply sockbot 6 hours agorootparentI have one of these with a MacBook Pro 6,2 that I did the same upgrades to. However I finally decided to retire it when 2nd replacement battery swelled and Chrome stopped supporting OSX 13. It didn't look like a good candidate for OpenCore Legacy because of the dual video cards, but it feels so gross recycling a perfectly working computer. reply hagbard_c 10 hours agorootparentprevPfah, showoff. My 2005 Thinkpad T42p crawls circles around that thing - slowly. Maxed out to 2GB, Intel 120GB SSD with a PATA->SATA adapter (just fits if you remove some useless bits from the lid) and - what keeps this machine around - a glorious keyboard and 1600x1200 display. It even gets several hours on the battery so what more could you want? reply genewitch 10 hours agorootparentprevi have an Air from 2011 or 2012 that is out of storage with just the OS installed. I can't update or install any other software because the most recent update installed on it capped out the storage. Low-end windows laptops (the $150-$300 at walmart type) have this same issue. 32GB of storage and windows takes 80% of the space, and you can no longer fit a windows update on it. I still have the air with whatever the macos is, but as soon as i have a minute i'm going to try and get linux or BSD on it. I'm still sore at how little use i got out of that machine - and i got it \"open box\" \"scratch and dent\", so it was around $500 with tax. I got triple the usage out of a 2009ish eeePC (netbook) reply knowaveragejoe 3 hours agorootparentprevThe main thing that convinced me to get on the ARM macs is the heat and battery life(which kind of go together). It's never uncomfortable on the lap. reply zuhsetaqi 12 hours agoparentprevInteresting that you have such problems with Amazon. I‘m using an iPhone XR (5,5 years old) and don’t have any problems using Amazon in the browser (Safari). And I’m on the latest iOS (17.4). reply kalleboo 5 hours agorootparentThe iPhone XR was 4x as fast as the Galaxy S9 in web browsing https://images.anandtech.com/graphs/graph13912/95169.png reply ryukoposting 7 hours agorootparentprevOS version may have an impact. The Galaxy S9s both run Android 9. That LG phone is stuck on Android 8 because AT&T sucks and never got around to updating their shitware-riddled Android fork. If they had, I wouldn't have needed to spend spend $800 on a new phone. I'm not bitter about it at all, though. reply ww520 1 hour agorootparentpreviPhone has exceptional long lasting performance. I have a 5 year old iPhone and it still runs smooth like silk. reply callalex 2 hours agorootparentpreviPhone browser performance has run circles around android browser performance on equivalent hardware for like the last 10 years or so. It’s really the secret sauce of iOS. reply Accacin 11 hours agoparentprevDid you try disabling JavaScript on Amazon? It actually doesn't function too badly. I know, I know, you shouldn't need to do it and I agree. reply ryukoposting 7 hours agorootparentI fiddled with NoScript but I must have done something wrong because I broke the site entirely. reply EVa5I7bHFq9mnYK 10 hours agoparentprevI recently visited Brazil and had my shiny new phone snatched from my hand ... now with my spare 4 years old phone, frankly dont see any difference. But I use Firefox with all the ad blockers, maybe that helps. reply ryukoposting 7 hours agorootparentI run Firefox with uBO and NoScript. Based on the other replies, OS version may play a role. reply MiddleEndian 9 hours agoparentprevI have a Palm Phone. I generally consider web browsing to be almost impossible no it at this point lol reply seam_carver 11 hours agoparentprevI have no issues with Amazon on my iPhone 8 running latest iOS 16 reply Ruq 7 hours agoprevRelated: Too much of technology today doesn't pay attention or even care to the less technologically adept, either. Smartphones in my opinion are a major example of this. I can't tell you the number of people I've meet who barely even or don't even know how to use their devices. It's all black magic to them. The largest problem is the over-dependence on the use of \"Gesture Navigation\" which is invisible and thus non-existent to them. Sure, they might figure out the gesture bar on an iPhone, but they have no conception of the notification/control center. It's not that these people are dumb either, many of them could probably run circles around me in other fields, but when it comes to tech, it's not for a lack of trying, it's a lack of an intuitive interface. reply crabmusket 7 hours agoparentIt appears to me, as an outsider, that interfaces are designed with a \"one size fits all\" approach, at least at the prestige end of town. Instead of allowing the user to choose design and interaction that works for them, the designer (or product owner) acts as if they know what's best for all users. reply idle_zealot 5 hours agorootparentWhat would the alternative look like? Applications shipping as a bag of arrangeable buttons and widgets that the user assembles into pages? reply rustcleaner 3 hours agorootparentActually, I find this highly ideal. I wish there was a button to press which would switch the interface into an almost Visual BASIC GUI editor like thing, permitting me to edit the arrangements. Also, I would like it if such an OS was more strict on forcing its interface objects (think: SimCity 2000 for Win95 with GDI-integrated GUI good, SimCity 3000 with Fisher-Price full screen toy interface bad). Also throw out much of the post- Windows 2000/KDE 3.5 desktop user interface 'innovation' but make all things editable in layout. I WANT MY COMPLICATED BUTTON GRIDS! :^( reply rustcleaner 3 hours agorootparentSiemens PLM NX 10 is another example of what I like in an interface. The GIMP big time as well for its customizability. You know what I don't like? Gnome. I curse Gnome 3 (namely, the design cancer Gnome fell to early on) for why KDE has yet to recover to the comfiness of KDE 3.5. Apple is another hate. I want a computational environment, I am a cyborg! I build my environments to my specifications. I am a privacy and control absolutist with these devices, because they are cybernetic extensions of my mind. SV: Stop being over-opinionated pricks trying to monetize every last drop of attention for every bottom-pocket penny in microtransactions. What we develop here is far and beyond more spiritual than we can all imagine. The utter lack of owner/user sovereignty shown lately, basically since iPhone and Facebook, captured in the term Enshittification, is absolutely appalling. Anyway, thank you for reading my unspellchecked schizo-ramblings. Now carry on with the great monetization, metatron hungers! reply eimrine 3 hours agorootparentprevThe smartphone world is too crooked to have an alternative IMO. Just keep eating everything the vendor gives you on the top of shovel. reply eviks 3 hours agorootparentprevOr the user picks from a set of assembled by someone else reply genewitch 10 hours agoprevas a data point youtube is unusable on raspberry pi 3. This happened within the last year, because prior to that you could \"watch\" videos at about 10-15FPS which is enough, for instance, to get repair videos in a shop setting (ask me how i know). When the raspberry pi model B - the first one released - came out, you could play 1080p video from storage, watch youtube, play games. I'm not sure what youtube is doing (or everyone else for that matter.) If we're serious about this climate crisis/change business, someone needs to cast a very hard look at google and meta for these sorts of shenanigans. eating CPU cycles for profit (ad-tech would be my off the cuff guess for why youtube sucks on these low power devices) should be loudly derided in the media and people should use more efficient services, even if the overall UX is worse. reply LM358 10 hours agoparentCould it just be due to lack of hardware video decoding? The Pi3 has x264 HW acceleration and youtube started using other codecs a while ago. reply Retr0id 10 hours agorootparentI have no idea if it still works, but the \"h264ify\" browser extension used to be great for working around this issue (by forcing youtube to serve h264) https://github.com/erkserkserks/h264ify reply genewitch 10 hours agorootparenti did a full apt dist-upgrade to try and get the h264ify plugin to install and if i remember correctly i never was able to get it to install. I upgraded from \"chromium\" to \"chromium-browser\" and set all the compositing and other settings recommended for the RPI. and to reply to another sibling, \"yt-dlp\" isn't workable, this is for a senior citizen that does small motor repairs. I got an HP elitedesk that's a few years old coming in monday to replace the RPI; hopefully that will last another 3 years before google et al decide to \"optimize\" again. reply antisthenes 7 hours agorootparentRPI 3 for a senior citizen seems like a poor solution in the first place. I would have opted for a small business-pc that is x86 based and 3-4 years old. reply extra88 10 hours agorootparentprevProbably. I remember when YouTube switched to H.264 (it might have been some Flash-based video before that). I had an older Mac mini hooked up to my TV at the time and suddenly video framerates dropped to an unwatchable level because they saved their bandwidth (and mine but I didn't have to care about my Internet service was not metered) at the expense of client-side processing. reply gerdesj 10 hours agorootparentprevIs YT so impoverished they can't manage some sort of negotiation mechanism that includes x264 and makes it work? reply hinkley 10 hours agorootparentThey encode videos ahead of time and they likely decided that whatever hardware you’re judging them by is only .9% of the market so fuck those guys. Big companies use percentages in places they shouldn’t and it gets them in trouble. .1% when you have a billion users is a million people you’re shitting on. For me that might be a dozen people. Very different. reply wonnage 7 hours agorootparentEncoding and storing billions of videos in a format used by 0.1% of users feels like a waste though reply hinkley 6 hours agorootparentThe context above was exclusion of people based on income level. reply treflop 10 hours agorootparentprevThat might be more on the browser that you’re using. It might be saying “yes I can play this format” to a format it can barely play. reply ogurechny 8 hours agorootparentprevSupposedly, the whole point of Google financing “open codecs” was for them to break free from MPEG codec licensing. I imagine the total amount of fees had a lot of zeros. So, yes, each time they don't serve H.264 (unless absolutely required) results in saving a lot of money. reply userbinator 5 hours agoparentprevI use Invidious for browsing the site, and watch the actual videos via a script that deobfuscates and gets the actual stream URL and then passes that to VLC. As another data point, YouTube a decade ago would've been perfectly fine on that hardware too. The culprit is web bloat in general, and more specifically the monstrosities of abstraction that have become common in JS. Even for those who don't believe at all in \"climate crisis\", there is something to be said for the loss of craftsmanship and quality over time that's caused this mess, so I think it's something everyone across the whole political spectrum can agree with. reply zelphirkalt 13 minutes agorootparentCan you share that script? Also using invidious, but passing to vlc sounds good for saving cpu cycles. reply gruez 3 hours agoparentprev>If we're serious about this climate crisis/change business, someone needs to cast a very hard look at google and meta for these sorts of shenanigans By all accounts client devices' energy consumption is a rounding error in terms of contribution to climate change. Going after them to solve climate change makes as much sense as plastic straw or bag bans. reply maigret 2 hours agorootparentIT is emitting around as much as aviation, and that was a surprise to me, most of it are due to client devices. Don’t have the source at hand at the moment though. And of that, most emissions are upfront until you buy it. Buying a new device because it’s not fast anymore causes emissions, not running it. Think about e-waste as well. reply gruez 1 hour agorootparent>IT is emitting around as much as aviation What counts as \"IT\"? It's most certainly a superset of \"client devices\", which is what my and the parent comment was talking about. reply MrVandemar 2 hours agorootparentprevIt has a cumulative effect and drives the continual \"upgrade\" cycle. When you consider the life-time of an average mobile device, and the resources required to manufacture and ship them, it's a not insignificant problem. reply gruez 1 hour agorootparentRandom source from google[1]: >Berners-Lee writes that in 2020, there were 7.7 billion mobile phones in use, with a footprint of roughly 580 million tonnes of CO2e. This equates to approximately 1% of all global emissions Of course, not everyone is replacing their phones yearly. Another source[2] says the average consumer phone is 3 years old. That works out to 0.33% of global emissions, assuming the phones aren't recycled/reused to developing countries. Even if assume people are upgrading their phones for app/web performance reasons, the impact is far less than 1%. [1] https://reboxed.co/blogs/outsidethebox/the-carbon-footprint-... [2] https://www.statista.com/statistics/619788/average-smartphon... reply pimlottc 7 hours agoparentprevYouTube is definitely getting heavier. My early 2021 MacBook Air (Intel) now gets random video pauses under moderate load, something that never used to happen. reply hinkley 10 hours agoparentprevWe need some watchdog group that watches page weight across sites and users and names and shames them. Maybe they could do that Consumer Reports style, or maybe it’s an add on the works a bit like Nielsen ratings. reply nolist_policy 10 hours agoparentprevIts worth trying out different browsers. In my experience Chromium based browsers are a bit faster than Firefox on really low end devices (Pinephone, ...) as long as you have enough ram (>1Gb?). E.g. On the OG Pinephone a 720p video on Youtube is running smoothly in Chromium, but not Firefox. reply ogurechny 8 hours agoparentprevYouTube was not tested because monitors can't handle CMYK, and we need a lot of that extra coal black to color the results. reply flir 10 hours agoparentprevI've got an old Roku box that has started rebooting after a few minutes of playing youtube videos. In your case, maybe pulling the video with yt-dlp then playing it works... reply nicbou 6 hours agoparentprevI had to upgrade my 12\" Macbook because Youtube Music brought it to a crawl. I could play music or work, but not both. reply bombela 2 minutes agorootparentThat's absurd. I remember using winamp (and the skin compatible Linux clone, I forgot it's name) streaming internet radios while programing a toy OS in 2004. I could listen to music while compiling and running the BOSHS emulator on my AMD Atlon CPU with a whooping 256MiB of RAM. reply lelanthran 10 hours agoprevThis article is basically unreadable for me 48 y/o on desktop). In the dev tools I added the following to the body to make it readable: font-size: 18px; line-height: 1.5em; max-width: 38rem; Now look how readable (and beautiful) it is. I read a lot of Dan Luu's posts, and each time I have to do this sort of thing to make it readable. Seriously, techies, it's an extra 64 Bytes to make your page more readable. reply gerdesj 10 hours agoparentI'm 53 and I'm at least five years behind getting my specs sorted out - they are currently perched right on the end of my nose now and I have to get the angle right sometimes (astigmatism). That page is nearly fine for me but I just hit CRTL + to scale up. That works for me. That page is pure text with no or at least minimal fiddling. You have your solution for your use case and I have mine. A blind reader will also have their solution, so they can even access it. Thanks to the simplicity of the source: all solutions to accessibility are also going to be reasonably simple. I think that Dan understands how to communicate effectively - keep it simple and don't assume that eyes will read your words. You can trivially (and you do) fiddle with the presentation yourself for your own purposes. I think that if you don't like the presentation of something like this then you could reformat it yourself, prior to engagement. Dan has kindly provided his message as a simple text stream that can be trivially fiddled with. reply progval 2 hours agoparentprevYou can change your browser's default font size if you find it too small. It's in Firefox's main settings page. Websites shouldn't force \"font-size: 18px;\" because it then makes the font smaller for users who picked a larger font in their browser. reply zzo38computer 9 hours agoparentprevI disagree. The user can change the window size, font size, colours, etc according to their own preferences. > I read a lot of Dan Luu's posts, and each time I have to do this sort of thing to make it readable. You shouldn't have to. You should be allowed to add a CSS file which can apply to multiple files, and then use that, instead of having to do it for each file individually. reply extra88 10 hours agoparentprevI agree that they should add some minimal CSS. But using your browser's Reader View also works, a click rather than multiple steps in DevTools. reply blehn 10 hours agoparentprevI think your mods are sensible, however if Dan Luu added those CSS rules himself, there would be comments on here lamenting the low density and \"excess whitespace\". Luu's audience, on the whole, probably prefers the relatively unstyled approach. reply userbinator 5 hours agoparentprevThen adjust your browser settings to your preference, because that certainly isn't mine either. I've had to remove \"max-width\"'s from a ton of sites using my filtering proxy. My window is this big, I expect your content to fill it! reply gnicholas 10 hours agoparentprevThe first time I saw this blog posted on HN I wondered how it could possibly be popular with such horrendous layout. The conclusion I came to is that the audience is very tech-savvy and is used to activating Reader Mode when they encounter pages like this. reply chmod775 10 hours agorootparentI went with the other techie solution: resizing my browser window. reply gnicholas 7 hours agorootparentSince I have a ton of tabs open and jump between them, this ends up not being a solution I use anymore. reply mardifoufs 8 hours agorootparentprevHow do you do that on mobile? reply skydhash 7 hours agorootparentWho read article like this on mobile? In a pinch, I'd just activate Reader Mode (Safari, iOS), or more likely save it for reading on a bigger screen (tablet, laptop,…) reply ParetoOptimal 3 hours agorootparentI just read it on Firefox mobile without reader mode. reply dxdm 2 hours agorootparentprevFirefox on Android has a button to activate Reader Mode right in the URL bar. reply chmod775 6 hours agorootparentprevFlip the phone into portrait mode. reply lstamour 10 hours agorootparentprevActually when I hit pages like this, I use the increase font size buttons. I tend to do this on phones too, especially. Yes, reader mode is also an option, but just bumping up the font size works too. You could also go back to the days when we had 800x600 monitors and 16px tended to be just the right size for that. ;-) reply mardifoufs 8 hours agorootparentprevIt's more of a hipster thing imo. For some people since it's minimalist and looks \"old\" , it must be good. Like I get keeping it simple but man it's CSS.. reply anon373839 6 hours agorootparentYep, exactly. It's fashion. FOUC-chic. reply joeblubaugh 6 hours agorootparentDan’s site has been like this for over a decade. If it’s a fashion, then he’s one of the creators of it. reply anon373839 6 hours agorootparentBrutalist web design has been a thing for a while: https://www.washingtonpost.com/news/the-intersect/wp/2016/05... Some of it can be appealing, when basic ergonomic needs are met (readable text size and line length, adequate margins, and so forth). Most is just brutally pretentious, IMO. reply hmottestad 10 hours agoparentprevIt’s pretty terrible on my phone too. Almost no margins and small font. Thankfully Reader Mode works in Safari, which fixes everything. reply ordu 7 hours agoparentprev> In the dev tools I added the following to the body to make it readable For cases when you don't agree with styles there is Reader Mode. Your way works also, but Reader Mode just simplier, it is just one click away. reply gnicholas 6 hours agorootparentTrue, although not all browsers have Reader Mode. Chrome didn't have it until last year, and the version they built is a sidebar, unlike most Reader Modes. This is probably because they want to make sure ads are shown alongside the Reader Mode. reply gitaarik 6 hours agorootparentprevIn reader mode the colors in the table disappear. Ironical the author does style that. reply dchest 4 hours agoparentprevIf you can't read font-size: 14px, you got your resolution/scaling/screen size wrong. The default text size is similar to the standard text size of OS UI controls. If you can't read them, I'd suggest to reconfigure your setup: change resolution, change scaling, or configure the default zoom level. reply XorNot 10 hours agoparentprevI'd prefer to see the grey text trend die honestly. I think my number one style-rewrite is just setting `font-color: black` on things. reply jagged-chisel 10 hours agoparentprevDo you have any idea of the layers of tooling you must use these days to produce those 64 bytes, and how each of those layers change and remove was was fed from all the other layers? To get exactly those bytes out the other end of the tools would be a herculean effort. Because we can’t just go around trying to understand basic web-based development without the frameworks … can we? reply grishka 9 hours agoprevThat Discourse guy is a classic example of someone designing their product for the world they wished existed instead of the world we actually live in. Devices with Qualcomm SoCs exist in billions, and will keep existing and keep being manufactured and sold for the foreseeable future. No amount of whining will change that. Get over it and optimize for them. People who use these devices won't care about your whining, they'll just consider you an incompetent software developer because your software crashes. reply Karrot_Kream 13 hours agoprevI'm normally a fan of Dan Luu's posts but I felt this one missed the mark. The LCP/CPU table is a good one, but from there the article turns into a bit on armchair psychology. From some random comments coming from Discourse's founder, readers are asked to build up an idea of what attitudes software engineers supposedly have. Even Knuth gets dragged into the mud based on comments he made about single vs multi-core performance and comments about the Itanium (which is a long standing point of academic contention.) This article just felt too soft, too couched in internet fights, to really stand up. reply goalieca 10 hours agoparent> what attitudes software engineers supposedly have I don’t think I’ve ever seen a company take performance seriously. No one scoffs when a simple API service for frontend has 500ms response time! How many engineers even know or care how much their cloud bill is? reply nolist_policy 10 hours agorootparentI'm sure Google invests a lot of resources in making Google Search load fast. AFAIK they serve a specialized version for each user agent out there. reply maigret 2 hours agorootparentOne the best counter examples to the rule. I tried running Lighthouse on a few Google services that are less prominent and had a few good laughs. reply yawaramin 9 hours agoparentprev> ...which is a long standing point of academic contention. What contention? If anything, Luu is being rather generous–Knuth was just whining that the decades-long free lunch program was being cancelled. reply moonchild 5 hours agorootparentVLIW (Itanium is a VLIW arch) is what's contentious, not multiprocessing. reply yawaramin 4 hours agorootparentOK I missed that. Thanks. But it looks like Itanium was only tangential to this discussion, in that Knuth thinks multicore programming may be an even worse mistake than Itanium. reply troupo 12 hours agoparentprev> readers are asked to build up an idea of what attitudes software engineers supposedly have. But they do, don't they. Discourse's founder's words are just very illustrative. Have you used the web recently? I have. It's bloated beyond any imagination to the point that Google now says that 2.4 seconds to Largest Contentful Paint is fast now: https://blog.chromium.org/2020/05/the-science-behind-web-vit... (this is from 4 years ago, it's probably worse now). You don't have to go far to see either Youtube loading 2.5 megabytes of CSS on desktop to the founder of Vercel boasting its super fast sites that take 20 seconds to load the moment you throttle it just a tiny bit: https://x.com/dmitriid/status/1735338533303259571 reply Karrot_Kream 12 hours agorootparentYou're making the same mistake the post did. It depends on the reader already having sympathy for the idea that bloat is bad in order to make its case. I can read nerd site comments all day that lament bloat. For an article to stand on its own on this point it has to make the case to people who don't already believe this. Dan's articles have usually been very good at that. The keyboard latency one for example makes few assumptions and mostly relies on data to tell its story. My point is that this article is different. It's an elevated rant. It relies on an audience that already agrees to land its point, hence my criticism that it's too couched in internet fights. reply liveoneggs 11 hours agorootparentState your case that bloat is good. I currently have a client who will do literally anything except delete a single javascript library so I'd like to understand them better. reply jodrellblank 11 hours agorootparentJoel Spolsky on Excel bloat, 2001: https://www.joelonsoftware.com/2001/03/23/strategy-letter-iv... reply liveoneggs 10 hours agorootparentThe web doesn't scale like desktops - not even close. Furthermore - this philosophy has made Windows worse and less responsive in all cases. I understand that this \"pays the bills\" but my charge is (currently) to make things faster so I am against slowness. reply deathanatos 9 hours agorootparentprevThat was 2001. Core frequencies aren't going up at 2001 rates anymore. (And although Moore's law has continued, it is only just. Core freqs have all but topped out, it feels like.) Memory prices seem to have stalled, and even non-volatile storage feels like it's stalled. My computer in 1998, compared to it's predecessor, storage was going up in size at ~43% YoY. It was an amazing time to be alive; the 128 MiB thumbdrive I bought the next decade is laughable now, but it was an upgrade from a 1.44 \"MB\" diskette. Today, I'm not sure I'd put more storage in a new machine than what I put in a 2011 build. E.g., 1 TiB seems to be ~$50; cheaper, yet. Using the late 90s growth rates, it should be 17 TiB… so even though it's about half the price, we can see we've fallen off the curve. reply jodrellblank 7 hours agorootparent> \"And although Moore's law has continued, it is only just.\" https://en.wikipedia.org/wiki/Transistor_count has a table of transistor count over time. 2001 was Intel Pentium III with 45 million transistors and nVidia NV2A GPU with 60 million. 2023 has Apple M2 Ultra with 134 billion transistors and AMD Instinct CPU with 146 billion, and AMD Aqua Vanjaram CDNA3 GPU with 153 billion. That's some ~3,000x more, about a doubling every two years. Core frequencies aren't going up, but amount of work per clock cycle is - SIMD instructions are up, memory access and peripheral access bandwidth is up, cache sizes are up, branch predictors are better, multi-core is better. > \"E.g., 1 TiB seems to be ~$50\" You can get a 12TB HDD from NewEgg for $99.99, Joel's blog said $0.0071 per megabyte and this is $0.0000083 per megabyte, ten thousand times cheaper in 23 years. Even after switching to more expensive SSDs 1TB for $50 is $0.00005 per megabyte, a hundred times cheaper than Joel mentioned - and that switch to SSDs likely reduced the investment in HDD tech. And as you say \"I'm not sure I'd put more storage in a new machine than what I put in a 2011 build\" few people need more storage unless they are video or gaming enthusiasts, or companies. reply jiggawatts 11 hours agorootparentprevThe latest version of Excel loads faster on my laptop than most websites do. I’ve timed this. I can load the entire MS Office suite and open a Visual Studio 2022 project in less time then it takes to open a blank Jira web form. What’s your point? reply skydhash 10 hours agorootparentDue to prevalence of native apps in the macOS world, the difference are often stark. I use Things and Bear, and it’s fast, then try to load gmail (dump account, so it’s not in Mail) and it’s so slow. Youtube too. Fastmail, in comparison, loads like it’s on localhost. You block JavaScript and the amount of sites that is broken is ridiculous, some you would not expect (websites, not fullblown interactive apps). reply jodrellblank 10 hours agorootparentprevMy point is to reply to \"State your case that bloat is good\" with a famous blog stating a case that bloat is good. Bloat makes the company more money by allowing them to develop and ship faster, bloat makes the company more money by being able to offer more features to more customers (including the advertisers and marketers and etc. side of things), and - well, read the article. I, too, dislike slow websites and web apps, but I don't think they are some mystery - natural selection isn't selecting for idiot developers, market selection is selecting for tickbox features and with first-mover-advantage they are selecting against \"fast but not available for another year and has fewer features and cost more to develop\". reply DinaCoder98 10 hours agorootparentprevThe reason we have bloat is it's easier to satisfy stakeholders if you don't give a damn. There's really no reason to discuss this at all once you realize this. But of course, ranting and reading rants is satisfying in its own right. What's the problem? reply troupo 2 hours agorootparentprevThe article you diss has actual benchmarks in it. The article I linked has actual numbers in it. At this point you're willingly ignoring it because you dislike that this is additionally illustrated by quotes from specific people. reply bitwize 5 hours agorootparentprevUsually the directive \"don't worry about bloat\" comes from above, or outside, the software engineering team. I'm a software engineer and I would love to fix performance problems so that everything runs Amiga smooth. But that takes time and effort to find, analyze, and fix performance issues... and once The Business sees something in more or less working order, implementing the next feature takes priority over removing bloat. \"Premature optimization is the root of all evil\" and that. I know that's not what Knuth meant, he meant don't be penny-wise and pound-foolish when you do optimize. But much like \"GO TO considered harmful\", something approaching the stupidest possible interpretation of the maxim has become the canonical interpretation. And that's before getting into when The Business wants that sweet, sweet analytics data, or those sweet, sweet ad dollars. reply GIFtheory 9 hours agoprevUsing https://www.mcmaster.com/ makes me wish I were a hardware engineer. Makes every other e-commerce site feel like garbage. If amazon were this fast, I’d be broke within days. Why haven’t other sites figured this out? reply samstave 9 hours agoparentnext [2 more] [flagged] samstave 4 hours agorootparentIf you are upset that I posted obv GPT output, then here is a reason why you're failing at your disgruntlement: I am able to post my prompt in whatever crazy alarmist fashion I would like and massage it into producing an output that I agree with, represents my arguments and doesnt inflame or trigger... aside from the 12 monkeys anti GPT reponse, because they couldnt imagine that it not a generic GPT-barf, as opposed to the machinations of the OP to get a more salient point without crossing lines.... oops.. reply myself248 10 hours agoprevWhere \"users with slow devices\" equals \"anyone trying to keep hardware running more than a few years\", it seems. It's enforced obsolescence. I've said for a long time, devs should be forced to take a survey of their users' hardware, and then themselves use the slowest common system, say, the 5th-percentile, one day a week. If they don't care about efficiency now, maybe they will when it's sufficiently painful. reply logtempo 9 hours agoparentthing is, boss is not a dev. He is a business man. reply mik1998 12 hours agoprevI often use a Thinkpad X220 (which still works for a lot of my usage and I'm not too concerned about it being stolen or damaged) and the JS web is terrible to use on it. Mostly resulted in my preference of using native software (non-electron), which generally works perfectly fine and about as well as on my \"more modern\" computer. reply jwells89 12 hours agoparentWhenever I pull out old machines I’m a little shocked at how responsive they are running a modern OS (Win10 or Linux), so long as the modern web is avoided. Anything with a Core 2 Duo or better is adequate for a wide range of tasks if you can find non-bloated software to do them with. Even going back so far that modern OS support is absent, snappiness can be found. My circa 2000 500Mhz PowerBook G3 running Mac OS 9.1 doesn’t feel appreciably slower than its modern day counterpart for more than one might expect, and some things like typing latency are actually better. reply nicbou 6 hours agorootparentMy 12\" Macbook was my main computer for 2022 and part of 2023. It ran smoothly for my workflow, even with a 4k monitor. However YouTube and Gmail brought it to a crawl. I had to sell it because Youtube Music slowed down my work. reply ogurechny 8 hours agorootparentprev“True UNIX way” solution to this would be getting the data from the Web non-interactively and redirecting it into some regular expressions to produce the only thing you want. Random example: https://github.com/l29ah/w3crapcli reply skydhash 10 hours agorootparentprevI have a mac mini 2011 and it works great with Linux Mint. But load youtube and you’re in a world of pain. reply anthk 11 hours agorootparentprevA Core Duo it's perfectly fine with an ad blocker: git://bitreich.org/privacy-haters reply amlib 22 minutes agoparentprevI remember going trough a similar situation when using a netbook. At first they were ok for doing light work and even accessing websites, but as time went on websites and browsers became more and more heavy. Youtube was a struggle, even Google felt laggy. Want to browse a map? You are better off getting a physical one! But, no worry, it was still fine for other low intensity things and some programming projects I worked on. About two years later and both KDE and GNOME would struggle to run on it, it was painful. Maybe I should have switched to an all CLI/terminal workflow but eventually I bought a used thinkpad X220 which was like taking a breath of fresh air after holding it for years. But now I do see the same pattern emerging, much slower mind you, but it is surely happening. Some websites feel sluggish, some gnome apps also feel sluggish and I have to avoid electron apps like the plague. But at least it has enough brawn (16GB of RAM and an SSD) to cut trough the bullshit and work ok on most things. Maybe I should have embraced that terminal lifestyle after all... reply zbrozek 10 hours agoprevThere's also a huge tendency to design for fast, high quality connectivity. Try using any Google product on airplane wifi. Even just chat loads in minutes-to-never and frequently keels over dead, forcing an outrageously expensive reload. Docs? Good luck. I wish software engineers cared to test in less than ideal conditions. Low speeds, intermittent connectivity, and packet loss are real. reply genewitch 10 hours agoparentThe last decade of my life has been a speedrun in \"less than ideal conditions\" for computing. CGNAT, 5mbit dsl, spotty \"fixed wireless\" and my latest debacle: starlink, although that seems to be getting better slowly; used to drop 15/60 seconds, now it drops more like 4/200 seconds. Constant power issues and lightning strikes - i only have 1 computer that has a working NIC, because evidently tiny power fluctuations are enough to send most chipsets into the graveyard. I had to switch to full fiber between all compute sites on my property, and a wifi backup, because copper is too risky. reply zer00eyz 10 hours agorootparentDo you have earth return on your power? reply genewitch 1 hour agorootparentYes, and it works, too. But i have outbuildings with servers and networking gear in them and metal conduit between buildings on/underground. Voltage potentials don't care, if there's a wet extension cord or something that's a less resistive path to start flowing and some gear is on that circuit or adjacent, it'll go. Overall switching to fiber is cheaper than aggressive lightning protection, and i moved all the network gear to a commercial UPS, and the interconnect between the \"modems\" and the switches is media converted to fiber for 3 feet. any time i have to run networking further than 6' or so i run fiber and put a media converter or a single gbic switch there. I'm hoping i futureproofed enough to upgrade to 10gbit in a year or so. My backup NAS has 10gbit but nothing else is connected at that speed yet. edit: One time lightning hit a pine tree in the back of the house, and it used my dipole antenna to reach a tree 80' away, and apparently there was an extension cable near there, which went back into the house, and it went all the way around the house, to reach the telco CPE box where DSL lived. the telco box and my mains earth are roughly 1 meter apart. That surge took out my main desktop computer, a washing machine (singed the dryer where it arced between it and the washer), the toaster oven, a microwave, my NAS, and my router connected to telco. It went two different paths inside the house, along both outside walls, one via mains copper and the other via cat5e copper. That was quite an expensive misadventure. reply pixl97 10 hours agoparentprevDevelopers are expensive, so we give them fast connections and fast computers. Then we act shocked when modern software/web requires fast computers. Unless it's somehow regulated that people test less than ideal conditions it won't happen, yet most people (myself included) don't really want that either. reply timeon 10 hours agoparentprevWhat I find interesting is that design of websites is often 'mobile first' but rarely 'mobile connection first'. reply dan-robertson 10 hours agoprevIf one cares about accessibility of a website to people with much slower devices, particularly living in less developed parts of the world, I guess there are more considerations: - using more clear English with simple sentence structures should make the content more accessible to people who don’t read English with the fluency of an educated American - reducing the number of requests required to load a page as latency may be high (and latency to the nearest e.g. cloudflare edge node may still be high) reply zozbot234 10 hours agoparent> reducing the number of requests required to load a page In practice this pretty much requires pure SSR and \"multiple page\" design, given the amount of network roundtrips on typical SPA sites. (Some lightweight SPA updates may nonetheless be feasible, by using an efficient HTML-swapping approach as seen in HTMX as opposed to the conventional chatty-API requests and heavy DOM manipulation.) reply pompino 2 hours agoprevI think it would be useful to separate data & code here. What if you kept the code the same, and downgraded the assets so the overall package is smaller/easier to process/execute? Or maybe tweaked the renderer so the same code & data can render quicker and slightly worse image quality consuming fewer CPU cycles? Basically I'm envisioning something like a game where the same game data+code can support multiple performance targets (except in this case the different CDN hookups to get the assets out, rather than everyone getting the bloated data download) reply hotdailys 6 hours agoprevWhen websites pack in too many high-res images, videos, and complex scripts, it’s like they’re trying to cram that overstuffed suitcase into a tiny space. Your device is struggling, man. It’s like it’s running a marathon with a backpack full of bricks. So, what happens? Your device slows down to a crawl, pages take forever to load, and sometimes, it just gives up and crashes. It’s like being stuck in traffic when you’re already late for work. And let’s not even talk about the data usage. It’s like your phone’s eating through your data plan like it’s an all-you-can-eat buffet. Now, if you’re on the latest and greatest tech, you might not notice much. But for folks with older devices or slower connections, it’s a real pain. It’s like everyone else is zooming by on a high-speed train while you’re chugging along on a steam engine. So, what can we do? Well, we can start by being mindful of what we put on our websites. Keep it lean, mean, and clean, folks. Your users will thank you, and their devices will too. And hey, maybe we’ll all get where we’re going a little faster. reply lmz 6 hours agoparentMaybe we'll see the return of the proxy + lightweight browser model like Opera Mini. reply hotdailys 6 hours agorootparentAnd lightweight APPs, one tap to load all... reply tdudhhu 12 hours agoprevNot only the user is affected by this. The difference between a 2MB and a 150KB CSS file can be a lot of bandwidth. The difference between a bad and good framework can be a lot of CPU power and RAM. Companies pay for this. But I guess most have no clue that these costs can be reduced. And some companies just don't care as long as money is coming in. reply supertrope 11 hours agoparentA lot of companies don't care about end user performance experience. Companies will burden issued PCs with bloated anti-virus, endpoint monitoring, TLS interception, Microsoft Teams, etc. If there's no explicit responsiveness goal, then performance dies by a thousand cuts. reply pixl97 10 hours agorootparent>Companies will burden issued PCs with bloated anti-virus, Ugh, bane of my day job. I work with two companies in particular that have high security requirements in their environments and very similar total workloads with our software. One spends around $250k (ish) a year in self hosting costs, the other over a million to get the same throughput. The less costly one worked with us as a vendor to get anti-virus/endpoint exclusions on the file io intensive part of our application and put anti-virus scanning before that point, then harden those machines in other ways. The other customer is \"policy demands we scan everything everywhere and the policy is iron law\". reply Nemo_bis 2 hours agorootparentWorst is, nowadays such bloated \"security\" software is being forced onto Linux servers too... every time I check why something feels slow, Microsoft Defender is hogging resources. reply jillesvangurp 1 hour agoparentprevIt's a numbers game. Mostly the difference doesn't matter at all to the vast majority of users. Optimizing for the bottom 1 or 2 percent that don't have any disposable income to update their phones, or pay for your wonderful products or services is not a big priority. And not all companies have rockstar developers working for them. That's why things like wordpress are so popular. I actually pulled the plug on a wordpress site for my company last week. We now have a static website. It's a big performance improvement. But the old site was adequate even though it was a bit slow to load. So, nobody really noticed the improvement. Making it faster was never a requirement. What is worth optimizing for is good SEO. There's of course a correlation between responsiveness and people giving up and abandoning web sites. That's why big e-commerce sites tend to be relatively fast. Because there's a money impact when people leave early. What I find ironic is that the people complaining about this stuff are mostly relatively well off developers with disposable incomes and decent hardware. If they use crappy/obsolete hardware it's mostly by choice; not necessity. Some people are a bit OCD about performance issues as well. They notice minor stutters that nobody cares about and it ticks them off. 2MB is nothing. I'm saying this as somebody who used cassettes, and later floppy disks with way less capacity. But that's 35 years ago. The only time when this matters to me is when I'm on a train in Germany and my phone is on a really flaky mobile network that barely works. Germany is a bit of a third world country when it comes to mobile connectivity. So, that's annoying. But not really a problem web developers should concern themselves with. reply afavour 11 hours agoparentprevEh. Cloudfront pricing starts at 8.5c per GB and goes down to 2c. I think you’d struggle to use that pricing as a justification when compared to the software engineer hours required to shrink down a CSS bundle. (don’t get me wrong, 2MB is insane and ought to be a professional embarrassment. But I think you’re going to struggle using bandwidth bills as the reason) I agree with you about frameworks, though. So much waste in creating everything as (e.g.) a React app when there’s no need. Sadly the industry heavily prioritises developer experience over user experience. reply Valord 10 hours agorootparentThis, although I often feel near modern web frameworks (React, similar) do not provide better developer experience. reply hexage1814 9 hours agoprev>Many pages actually remove the parts of the page you scrolled past as you scroll There is a special place in hell for every web developer who does that. reply teg4n_ 7 hours agoparentIt’s a performance optimization for rendering a large amount of html. If the DOM had all the items in memory it would perform much worse. Thankfully browsers are working on a feature where you can keep the markup in the DOM for things like CTRL-F without hurting performance. Granted the main reason such a technique is needed is designs that avoid pagination. reply majewsky 10 minutes agorootparentI am usually just a backend developer, but for a little reporting application that I built, I couldn't get the UI team to do a UI in the short time that I had to build it, so I had it output some basic HTML. About 10000 list items. Rendered imperceptibly fast on my browser. Then because of $mandate, the report was moved to the team's standard React UI frontend. Now it takes 5 seconds to load and only gives you like 100 items at a time, so Ctrl-F is broken. Also, filter dropdowns somehow did not work until they fixed it, so it appears like the select tag was not fit for their design and they rolled their own. reply anonymoushn 6 hours agorootparentprevWe had web pages with big lists and tables in the DOM 20+ years ago, they were fine. The difference is that now we use web frameworks that do work proportional to DOM size many times per second. reply hexage1814 3 hours agorootparentCall me a conspiracy theorist, but I think it's all a plane to make it harder for people to save stuff. If the content just stays there after you loaded, you could just save the page as HTML and, if there wasn't a lot of javascript shenanigans, it should save it okay. When you add this element, this doesn't work anymore. I'm pretty sure instagram, for example, does that with the intention of making it harder for people to save profiles. reply bradgessler 3 hours agoprevIt also impacts users with fast devices. When I load a bloated website on an iPhone 15 Pro Max over a Unifi AP 7 Pro access point connected to a 1.2Gb WAN, it’s still a slow bloated website. If you build websites, do as much as you possibly can on the server. As an industry, how can we get more people to understand this? reply efields 12 hours agoprevHow web bloat impacts users: negatively. Better do your best to fix it. This stuff is simpler than we let it be sometimes, folks. reply withinboredom 12 hours agoparent> This stuff is simpler than we let it be sometimes, folks. Meanwhile watches a team build a cathedral when all they needed was a shack. reply ponector 10 hours agorootparentWhy not to build a cathedral if someone else is paying? I've never seen companies where developers are rewarded for performance improvement or any kind of improvement. Did an improvement? Nice! Good job! And that's it. reply julianlam 5 hours agoprevIt's a shame that NodeBB was not included in the list of forums tested. We worked really hard to optimize our forum load times, and it handedly beats the pants off of much we've tested against. But that's not much of a brag, the bar is quite low. Dan goes on and lambasts (rightfully so) Atwood for deriding Qualcomm and assuming slow phones don't exist. Well, let's chat, and talk to someone whose team really does dogfood their products on slower devices... reply Devasta 12 hours agoprevIf you don't have a good phone and a high speed connection, you don't have any money to spend on either the sites products or the products of their advertisers. When looked at from that angle, bloat is a feature. It's not reasonable to have an expectation of quality when it comes to the web. reply Uehreka 11 hours agoparentWell that take sure goes from 0 to 60 real fast. Can you really be sure that only people with good phones and connections have money to spend? Just to poke some obvious holes: what about old rich people who have a distaste for modern phones but spend lavishly on vacations every year? Or outdoorsy rich people who are frequently in areas with poor cell coverage but are constantly purchasing expensive camping/climbing equipment? How about people who aren’t rich, but work for companies where their input is part of a purchasing process with millions of dollars of budget? Those people are all super-lucrative advertising targets, I don’t think advertisers are intentionally weeding them out. reply jhanoncomm 11 hours agoparentprevI think you are close to the truth there. But I doubt companies purposely increase their hosting costs as some kind of firewall to only include the rich. More like they just don’t care. Same reason for technical debt, everyone wants to grow and move needles. If a company could magically make their site more available and efficient for free I am sure they would jump at the chance. But spending a million on that vs. a million on ads wont seem worth it. reply pixl97 10 hours agorootparentAh, the modern AAA games take on MTX. Who cares about gamers, fish for whales. reply politelemon 11 hours agoparentprevThis is addressed in TFA and is not true. The bloat is a symptom of what I've seen referred to as the \"laptop class\" and is unrelated to any feature adjacent. reply genewitch 10 hours agoparentprevVirtually all pharmaceutical advertising is targeted at prescribers, yet we all have to watch/view them. reply YoshiRulz 1 hour agorootparentThat's mostly an American thing. reply genewitch 1 hour agorootparentAs an american by accident, i apologize, you're right. More civilized countries have outlawed that sort of advertising. reply LAC-Tech 11 hours agoparentprevHuh? I have a 5 year old, mid range android, and I still buy things online. Not everyone cares about phones. reply blauditore 11 hours agorootparentAlso, there are some websites targeting users with little money as well. reply apatheticonion 1 hour agoprevThis is why I'm excited for Web Assembly. Writing an efficient high performance, mutli-threaded GUI in Rust or Go would be awesome. Just waiting on it to be practically usable reply aragonite 8 hours agoprev> Another example is Wordpress (old) vs. newer, trendier, blogging platforms like Medium and Substack. Wordpress (old) is 17.5x / 10x faster (LCP* / CPU) than Medium and 5x / 7x faster (LCP* / CPU) faster than Substack on our M3 Max ... It's a persistent complaint among readers of SlateStarCodex (a blog which made a high-profile move to Substack from an old WordPress site). Substack attributes the sluggishness to the owner's special request to show all comments by default, but the old WordPress blog loads all comments by default and was fine even on older devices. https://www.reddit.com/r/slatestarcodex/comments/16xsr8w/sub... https://www.reddit.com/r/slatestarcodex/comments/1b9p55g/any... reply ordu 7 hours agoprev> Surely, for example, multiple processors are no help to TeX But TeX was designed to run on a single CPU-core, so no surprise here. I wonder what TeX could become if all Knuth had at the time a multicore machine with cores managing maybe 0.1 MIPS each (or even lower). Like what the world would become if we lived in a counterfactual world where Intel and its buddies starting in 1970s boosted not the frequency and instruction per second per core but number of cores? My take we'd switched to functional-style programming at 1980s with immutable data, created tools to describe multistage pipelines with each stage issuing tasks into a queue, while cores concurrently picking tasks from the queue. TeX would probably have a simplified and extra fast parser that could cut input into chunks to feed them into a fullblown and slow parser which would be a first stage of a pipeline, and then these pipelines somehow would converge into an output stream. TeX probably would prefer to use more of lexical scoping, to reduce interaction between chunks, or maybe it would make some kind of a barrier for pipelines where they all stop and wait for propagation of things like `\\it` from its occurrence to the end. This counterfactual world seems much more exciting to me than the real one, though maybe I wouldn't be excited if I lived there. reply anticensor 53 minutes agoprevThis is a manifestation of Wirth's law, again. reply masa331 1 hour agoprevMy own recent experience with this - i run a small sass web app and about a year ago i decided to partner with advertising company to help with the grow. Part of the plan was that they will remake our static homepage in Wordpress bc it will be easier to manage it for them and also easier to add a blog, which was part of the new plan. I know Wordpress is slow and i would say unnecessary also but i said yes bc i did not want to micromanage them. A year later we parted our ways and i was left with WP where the page load was abysmal(3-5 seconds) and about 10Mb of bs. There was something called \"Oxy\" or \"Oxy builder\" which would add a tons of style,js and clutter to the markup and kind of SPA page load style but horribly failing. So now i migrated the site to Jekyll, got rid of all the bs and it's back fast. And for me also again possible to really improve. So for my businesses i'm not touching WP ever again and that will be a huge bloat reduction in itself reply askonomm 56 minutes agoparentSeems like your issues were not with WP itself, but with whatever plugins and themes were added to it. Avoiding WP entirely for this is like avoiding a programming language because the 1 developer you had experience with sucked at it. WP itself can be very fast, as is evident by a ton of high profile sites running it (CSS-Tricks, TechCrunch, New York Times, Time Magazine, etc). I'm not a fan of WP myself, but that's just because I don't like how its built and how it entirely avoids modern programming standards, not because it is slow, which it most definitely doesn't have to be. reply maxloh 11 hours agoprevYouTube is one of the slowest websites I have ever used. It takes several seconds to load, even with moderate hardware and fast internet connections. reply jhanoncomm 11 hours agoparentReddit for me is the slowest site. And while old.reddit fixes this they try to steer you back to main reddit at any opportunity! reply genewitch 10 hours agorootparentRES fixes this, i think. It's a browser extension that forces everything to stay the way it was when reddit worked fine - before publishers bought it. I don't have any issue with reddit usability, although i do use it a lot less since they nuked my cellphone app from orbit as a cash grab. reply lazypenguin 7 hours agoparentprevYouTube doesn’t feel zippy as a website but the reliable and speed of videos have been very good for me. I remember the days when buffering videos was hell. reply daft_pink 9 hours agoprevI really wish he compared an m3 Mac to a 6 year old intel chip and not some random processor I’ve never seen or experienced that I’m not sure is even available in the usa reply illusive4080 7 hours agoparentI can vouch that my 2017 MacBook Pro struggles with all kinds of tasks, especially web ones. reply avodonosov 6 hours agoprevSome years ago I tested real world web sites, turned out only about 30% of the javascript they load was actually invoked by the user's browser (even for sites optimied with Closure Compiler, that has some dead code elimination): https://github.com/avodonosov/pocl The unused javascript code can be removed (and loaded on demand). Although I am not sure how valuable that would be for the world. It only saves network traffic, parsing time and some browser memory for compiled code. But js traffic in the Internet is neglidgible comparing to, say, video and images. Will the user experience be signifiqanty better if browser is the saved from the unnesessary js parsing? I don't know of a good way to measure that. reply avodonosov 6 hours agoprevI think bloat could be prevented if it was noticed the moment it is introduced. After application evolves bloated, it's difficult to go back and un-bloat it. Bloat is often introduced accidential/y, without need, and unnoticed just because developers test on modern and powerful devices. If developer's regular test matrix included a device with minimal hardware pewer that was known to run the product smoothly in the past, the dev could immediately notice the newly introduced bloat and remove it. A bloat regression testing. I call this \"ecological development\". We should all do this. No need to aim for devices that already have trouble running your app / website. But take a device that works today and test that you do not degrade with respect to this device. reply cuu508 3 hours agoparent> After application evolves bloated, it's difficult to go back and un-bloat it. It will be hard to get to pristine quality, but there ought to be some amount of low hanging fruit, where minimal changes bring noticeable improvement. reply avodonosov 2 hours agorootparentMaybe, but determining it will take some investigation. If the regular testing is done on a low profile device, developer knows as soon as possible that his recent changes introduced a bloat regression. reply keernan 8 hours agoprevA problem that recently started in Feb 2024 for me is probably unrelated to the topic, but close enough that I'm posting in the hopes someone has an idea of what is happening. I am running on a relatively new Lenovo Legion (~ 18 months old) with 64kb of ram running windows 11. About 6 weeks ago I began getting the BSOD every time I streamed a live hockey game (I watch maybe 3 games a week from Oct to Jun via Comcast streaming or 'alternative' streams). The crashes happened multiple times every game. After maybe 10 games of this, I began closing and reopening the browser during every game break. I've experienced zero crashes since doing that. When the crashes started, I was using Chrome - but I still experienced BSOD crashes when I switched and tested Fox and Brave. Just very odd to start happening suddenly without any changes to my machine that I could pinpoint - no upgraded bios or nvidia that I can recall. reply coolcoder613 5 hours agoparent> with 64kb of ram running windows 11 I hope you mean GB. reply bsdpufferfish 6 hours agoprevThe most interesting part of this is the comments about software shifting from a normal career to a prestige target for wealthy families, and that this demographic shift has massive consequences on technology design and services. reply dan-robertson 10 hours agoprevRelating to the aside about opportunities in different countries: the comparison between potential programming career prospects between a poor American and middle class Pole feels reasonable for someone born around the same time as the OP (early ’80s I guess) but I suspect it’s since shifted in Poland’s failure. I think the relative disadvantages of a poor American compared to their wealthier peers have increased as there’s more competition (as the degree is seen as more desirable by motivated wealthy parents) and the poor student likely won’t even have a non-phone computer at home where all their wealthier peers probably will. Possibly they could work around the competitiveness of computer science by going via some less well-trodden path (eg mathematics or physics) except that university admission isn’t by major. They may also be disadvantaged by later classism in hiring. Meanwhile a middle class Pole will have access to a computer and, provided they live sufficiently near one of the big cities, access to technical schools which can give them a head start on programming skills (and on competitive programming which is a useful skill for passing the current kind of programming interview questions). To get the kind of good outcome described in the OP, they then need to get hired somewhere like Google in Zurich (somewhat similar difficulty to in the US except the earlier stages were easier (in the sense of being more probable) for the hypothetical Pole) and progress from there (maybe impeded by initially not being at the headquarters / fewer other employment opportunities to get career advancement by changing jobs). Class will be less of a problem as the hypothetical middle class pole isn’t so different in wealth from other middle class Europeans and you get much less strong class-selection than when (e.g.) Americans are hiring Americans. reply nolist_policy 11 hours agoprevNext try out the search engines. Anecdotally, Google Search loads ~500ms faster than DuckDuckGo on the OG Pinephone. reply jhanoncomm 11 hours agoparentThat is one performance metric. What about energy use and loading search results not just the home page. I find DDG faster from a perception point of view. I imagine on sone metrics it is faster. reply nolist_policy 11 hours agorootparentSorry, should have been more precise. I was measuring loading search results. E.g.: https://www.google.com/search?client=firefox-b-e&q=test9999 vs. https://duckduckgo.com/?t=ftsa&q=test9999&ia=web reply ponector 10 hours agorootparentDid you measure time user needs to scroll and click reject google cookies? reply 118 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Web bloat impacts users with slow connections as bandwidth outpaces CPU performance, causing usability issues on low-end devices.",
      "The article underscores the need to prioritize accessibility and usability on all platforms to address disparities in performance between low-end and high-end devices.",
      "Optimizing websites for improved performance across all devices is crucial for enhancing user experience and driving revenue growth."
    ],
    "commentSummary": [
      "Web bloat negatively affects user experience, especially for those with slow devices or internet connections, sparking a discussion on optimizing website performance and prioritizing efficiency over unnecessary tracking.",
      "The conversation includes the environmental impact of technology, challenges for software engineers, and business priorities impacting software development, highlighting user frustrations with modern websites and the importance of optimization in web development.",
      "Users' experiences with slow devices underscore the need for performance improvements and optimization in web development, emphasizing the significance of addressing these issues."
    ],
    "points": 641,
    "commentCount": 371,
    "retryCount": 0,
    "time": 1710619710
  },
  {
    "id": 39728146,
    "title": "Hackintosh Scene Decline Amid Apple's Driver Support Removal",
    "originLink": "https://aplus.rs/2024/hackintosh-almost-dead/",
    "originBody": "Home Archives My apps Open source hardware Hackintosh is (almost) dead It was a good run, though. Mar 16, 2024 by Aleksandar Vacić 6 minute read While I knew about and even tried various very early attempts to run macOS on non-Apple hardware, it wasn’t until early 2020 that I’ve built my first proper one. Then I built several more which are still seeing daily use. I explained my reasoning why it was worthwhile to attempt it. The technology was mostly there thanks to a group of dedicated hackers and timing was just right: But if ever there was a time to do it, it’s now. Apple is transitioning to their own CPUs/GPUs over the next two years. Several years from now, I see myself purchasing whatever desktop Apple Silicon-based machine is there. I also offered a prognosis which turned out partially true: Many will tell you that buying Intel-based hardware from Apple is buying obsolete models. I don’t really agree with that since it’s a given that those Intel-based Macs will be supported for 7-10 years of future macOS updates. It’s true that latest macOS 14 (Sonoma) still supports the latest generations of Intel Macs and it’s very likely that at least one or two major versions will still be compatible. But there’s one particular development that is de-facto killing off the Hackintosh scene. In Sonoma, Apple has completely removed all traces of driver support for their oldest WiFi/Bt cards, namely various Broadcom cards that they last used in 2012/13 iMac / MacBook models. Those Mac models are not supported by macOS for few years now thus it’s not surprising the drivers are being removed. Most likely reason is that Apple is moving drivers away from .kext (Kernel Extensions) to .dext (DriverKit) thus cleaning up obsolete and unused code from macOS. They did the same with Ethernet drivers in Ventura. Those particular cards were the key ingredient to many fully functional Hackintosh builds for simple reason: they worked out of the box with every single (so-called) iService Apple has: Messages, FaceTime, AirDrop, Continuity, Handoff - you name it. Everything worked. Despite the valiant efforts of OCLP crew to make workarounds, those cards can work in Sonoma only if you seriously downgrade the macOS security. There was some hope that OpenIntelWireless could replace those cards due to amazing work zxystd did in the last 4 years. I mean, the WiFi speeds in macOS with Intel’s WiFi6 cards are nothing short of spectacular. But Apple’s continued cleanup and rewrite of their driver stack has pretty much killed-off any reliable support for Message and FaceTime despite iCloud sync still working great. zxystd describes the new mountain to climb: From Sonoma, Apple drops IO80211FamilyLegacy, I build AirportItlwmV2 on the top of IO80211Family, but using some hacks, you can simply interpret it as me implementing a set of IO80211FamilyLegacy myself. This implementation may have side effects such as the iService not working etc. Since IO80211Family uses skywalk API instead of original Ethernet API (Also we can foresee that the Ethernet API will also be dropped in macOS 15), without these hacks we should follow the Apple’s API and rewrite the whole driver, that’s what I would never do. In 14.4, Apple seem to have made changes in how USB subsystem works too. This was always a tedious challenge but if minor updates can almost brick the build it becomes a headache. Still…USB is a known problem with known solution thus it’s annoying but solvable. WiFi with iServices is sadly not. I’ve long held the opinion that it would not be CPU nor GPU changes that kill the Hacks — it would be lack of reliable WiFi drivers. And now, ~4 years later, Hackintosh hits a brick wall of no easy WiFi options available, at all. Given how much of the macOS useful features is dependent on presence of particular WiFi chips — a decision of Apple developers I really can’t understand — I can’t really consider builds without those features to call themselves Mac. I did not come to this conclusion just by reading the forums. I have a rag-tag build sitting on my desk for several months now. It was supposed to be a quick proof-of-concept Sonoma build with Intel AX200 WiFi/Bt, AMD CPU and GPU, NVMe SSDs - everything that modern Mac should work with. It’s everything that my current Hackintosh is, with SIP intact, incremental updates working on their own etc — a perfect Mac. But pretty much since day one I encountered one problem after another. Things were so volatile and random that it was hard to believe, at times. Like — One day Ethernet controller (Intel I225-V) would work great, the next day it would just hard-crash the entire machine. No freaking idea why. Tried multiple ways and custom drivers to make it work but nothing was perfectly stable. WiFi works fantastic, iCloud is perfect but Messages/FaceTime wouldn’t connect at all. In either Monterey, Ventura or Sonoma. That same card worked perfectly on another motherboard with Monterey and Ventura, no issues with Messages / FaceTime at all. Again — no idea why. Bluetooth would work great for days but if I turn it off and restart the machine, something would become so messed up that it starts being recognised as BCM_4350C2 chip instead of Intel AX200. Only a round-trip to Windows 11 would somehow bring the chip into a state that IntelBluetooth driver can work with it. Sonoma 14.3.1 works great on this build. But 14.4 update won’t install. It starts booting the installer and just reboots back almost immediately. Hence — Hackintosh is on its death bed. Some things will work for few more months or maybe even years, depending on what you use it for and wether lack of WiFi bothers you or not. But not for me. I can live without AirDrop, Continuity and Handoff but Messages and FaceTime must work. There’re also some other things Sonoma brings that are important to me thus I want to update to it. Coupled with described lack of reliability and fretting if next minor or major update would leave me dry — nah, not worth it. I don’t really complain. I had a good run which helped me skip over the worst price/performance Mac lineup that I remember. There’re now plenty good choices within the current crop of M1 / M2 / M3 machines and I’ll be following eBay closely for a good used Mac mini / studio models. Or maybe even splurge on something new. Lest I forget — if macOS Ventura works for you, stay on it! That’s still perfectly stable without a single issue across a variety of build options. Just to clarify one thing, to preempt someone saying Apple did this on purpose to kill off Hackintosh: they didn’t. Apple never cared about Hackintosh scene, it’s entirely irrelevant to their business. They did what they should be doing, improving the macOS codebase. It’s always a good thing to remove obsolete and deprecated code thus Apple is doing the right thing for their product. All code shown in posts is licensed under MIT license. For everything else – all rights reserved unless otherwise noted. © Copyright 2003–2024, Aleksandar Vacić. Powered by Hugo.",
    "commentLink": "https://news.ycombinator.com/item?id=39728146",
    "commentBody": "Hackintosh Is Almost Dead (aplus.rs)432 points by ingve 15 hours agohidepastfavorite441 comments bruce511 15 hours agoBack in my youth, when I was time rich and cash poor, this kind of tinkering was fun and a good way to improve the machine I was using. Now that I have more disposable cash, but waaay less time, I couldn't imagine \"wasting my time\" doing this sort of thing. These days I want to -use- the computer, not spend time trying to convince it to work. Incidentally it's the exact same journey with my cars. 35 years ago I was fixing something on my car most weekends. Now I just want to turn the key and go somewhere. Hackintosh served the purpose for its time. It'll be fondly remembered. But I think the next generation of tinkerers will find some other thing yo capture the imagination. reply rpdillon 14 hours agoparentPeople have been making this argument to me about Linux for more than 25 years. The most cutting version that I ran across was: > Linux is only free if your time is worthless! Something never quite sat right with me about this argument, and your comment finally made me understand what it is: the understanding you gain from tinkering is priceless, and it's exactly the experience that you use to help everyone around you: it turns you into an expert. So yes, I may just want to turn the key and have my car work. But when it doesn't, I often wish I was that guy that had tinkered with my car, so I can better understand what was wrong, and whether I can fix it myself or if I needed a professional. I run Linux on all my machines, and my family generally uses Mac (both sides), but all those years tinkering with Linux, they still come to me for help with their Mac machines that they insisted would Just Work. All that out of the way, I agree with your fundamental premise: hackintosh is likely in the rear view mirror for the next generation of tinkerers. reply Gracana 13 hours agorootparentI think there's a difference with Linux, because it's something you own and control and can dive into and see every part of. I hate investing time in proprietary technologies, because I know I can be stopped or locked out. With open source software, simple electronics, old cars, fabrication and woodworking, the time I spend learning feels worthwhile. reply WanderPanda 5 hours agorootparentEven this \"I hate investing time in proprietary technologies, because I know I can be stopped or locked out\" is a hard-gained insight. Hackintosh is one of those things that made me understand this. Nothing like spending weeks to get your hackintosh working smoothly with all the hardware just to find out that the next update breaks everything. I've come to see it as a necessary part of the journey reply normaler 16 minutes agorootparentThis is my current state of thought. Proprietary software perceives me as an enemy who needs to be locked out of as many features as possible to allow for more money to be extracted out of me while also investing the least amount possible back into the product. The only timeframe where proprietary software is groundbreaking and at the forefront of technology is when they have not yet captured and locked in a large market share. reply rpdillon 13 hours agorootparentprevThis is a great point. I sort of detest becoming an expert at proprietary stuff, because I know they'll just change it before long. I've lamented about this elsewhere as modern software creating \"permanent amateurs\". Even those that want to invest in expertise often find their knowledge outdated in a handful of years, and those that don't want to invest can easily justify it by pointing out this effect. reply lupire 8 hours agorootparentMicrosoft, at least before Cloud happened, supported their tech stacks with backward compatibility for decades. reply xattt 13 hours agorootparentprevProprietary or not, tinkering help you develop an intuition of what might be wrong. reply i_am_a_peasant 11 hours agorootparentYeah I mean, whoever made the original statement is just not an OS engineer. reply mandeepj 10 hours agorootparent> just not an OS engineer. Or not just an engineer reply vel0city 8 hours agorootparentI know plenty of people with stamps who don't care to fiddle with their OS or change their own oil. People who work on putting things in orbit and beyond, people who build bridges, people who design undersea robots and airplanes. They're most definitely engineers. reply i_am_a_peasant 9 hours agorootparentprevNah I can believe they'd be a chemical engineer or even a software developer that writes iOS apps or something like that. reply xattt 8 hours agorootparentI wanted to say steam/power engineer, but even they understand the value of tinkering. reply dataflow 12 hours agorootparentprev> I think there's a difference with Linux, because it's something you own and control and can dive into and see every part of. I hate investing time in proprietary technologies, because I know I can be stopped or locked out. The problem with this approach is then you get a generation of engineers with tunnel vision thinking the One True Way to achieve your goal is the same way your GNU (or whatever) software did it. Invest time in learning your technologies, whatever they are. There's valuable knowledge in proprietary stuff just as there is in OSS. reply ryukoposting 11 hours agorootparentI agree with your point in principle, and yet I installed Ubuntu on my work laptop this January after using Windows professionally for my entire (5 year) career. I've found myself moving in the opposite direction from the person in the root comment, because I find that it's getting harder and harder to find tolerable proprietary software. It feels like everything is glacially slow, laden with ads and tracking, reliant on an internet connection for basic functionality, or some combination of the above. reply resource_waste 3 hours agorootparentFYI, Ubuntu is a heavily advertised distro. Its pretty bottom barrel for quality. If you want a modern linux distro, try Fedora Cinnamon or something that isnt on Debian branch. reply throwaway2037 1 hour agorootparentIt is not surprising that you posted this flame bait from a throwaway account. What is wrong with Debian? reply dataflow 11 hours agorootparentprev\"There is valuable knowledge worth learning in the technology\" != \"this is strictly better software on every axis and you should switch to it for your daily work\" reply WWLink 2 hours agorootparentAs someone that learned to program on BSD and shortly thereafter, Mac OS X and Linux.... I honestly don't know how people use Windows machines as a dev environment 24/7. It would drive me mad. Everything's so wonky and weird. Everything from symlinks to file permissions is just backwards and fucky. reply cqqxo4zV46cp 9 hours agorootparentprevI mean this in the nicest possible way: 5 years is likely not long enough for the “just work, stupid” desire to really, really, really set in. Nor is a couple of months enough time for the potential rough edges of desktop Linux to set in. reply timlod 1 hour agorootparentI’ve been using Windows throughout my childhood and start of my CS career - now I use Windows for specific software (audio/music) and Linux for developing (about 8 years I guess). I had a 1-year stint with macOS because I was developing an iOS app, and have been the troubleshooter for people with macs at my previous job, so I consider myself somewhat ‘multilingual’ when it concerns OSs. As a power user, Linux is just so much nicer. I constantly get frustrated, especially with macOS, about stuff that I can’t easily. In Linux my stuff works and if it doesn’t it can be made to work (usually). In Windows/Mac it’ll often take considerable effort to make the system work the way I want, or it’s just not possible. I think with proprietary software ‘it just works’ is only a thing if you’re happy with the basic experience that is tuned to the average person. If you have more complex needs, you should be using Linux (and if you know your stuff or use the right distro, things will likely also ‘just work’). reply ryukoposting 7 hours agorootparentprevGiven that I've been using Ubuntu on the desktop since I was 11, I'm not worried. The reason I switched was because Windows didn't work. Win11's desktop makes early-2010s KDE look like a smooth, bug-free experience. My laptop (a 10th gen X1 thinkpad) was plagued with driver problems. At least twice a month, I'd have to reboot when I joined a meeting and discovered my mic wouldn't un-mute. Switching to Ububtu solved both of these problems, and I don't have to deal with an awkwardly bifurcated environment where a couple of my CLI tools run in WSL while everything else is native. Oh, and my Zephyr build times are a good 25% faster now. reply jacoblambda 11 hours agorootparentprevFrankly there is no value in learning user-hostile proprietary technologies in a way that the owner of said technologies actively wants to discourage and prevent. Like learn the proprietary tech in the environments it's intended to be used in but if you can't use it in that environment I personally wouldn't waste my time with it. With FOSS tech at least you can make the argument that you can learn stuff by maintaining it properly but with a proprietary stack in an unsupported and actively user hostile environment the best you are going to do is learn how to maintain a fragile truce with the software gods. reply cqqxo4zV46cp 9 hours agorootparentPeeling all the way all the politics / idealism from your comment and the value proposition between these two options is basically the same, with the difference being that on a proprietary stack there’s a higher chance of things breaking in a way that you low/no likelihood of fixing. It’s all good and well that it seems like this makes you personally want to throw up in your mouth a bit or whatever, but you are claiming objectivity that clearly isn’t here. reply exe34 11 hours agorootparentprevYeah I'll learn as much as I absolutely have to in order to get my paycheck. Any more and you need to give me a raise. reply astrange 7 hours agorootparentThat's not a good way to make money. It's not how FAANG pays people, and if it is how your employer pays people then you should always be learning so you can change to better jobs. A funny thing about \"never work for free\" advice is that a lot of highly paid jobs (investment banking, high end escorts) are about doing tons of client work for free in a way that eventually gets them to pay you way too much when they do pay you. reply exe34 1 hour agorootparentI learn the interesting stuff, I just don't learn proprietary tech that I really don't ever want to be dependent on for my wages. In fact most of the essential skills for my job I've learnt in my own time, and continue to learn. I invest my own money in equipment and training courses. I love learning. But only when it's interesting to me, not because it'll make more money to somebody else. If it'll make you more money, pay me. reply musicale 10 hours agorootparentprev> Frankly there is no value in learning user-hostile proprietary technologies in a way that the owner of said technologies actively wants to discourage and prevent. Security research. And, uh, applied security research. reply umbra07 13 hours agorootparentprevI fully empathize - and yet, there are benefits from tinkerers/hackers messing around on proprietary hardware/software. Hackintosh - and similar communties - led to projects like Asahi Linux, Nouveau, Panfrost, etc. reply dylan604 8 hours agorootparentprevThis is a gross misunderstanding of the GP's point though. It's not that they are against doing any of these things. In fact, they said they were more than happy to do it in their youth. I am in full agreement with the GP's sentiment as well. Mucking about and tinkering with things while one has the time, desire, and stuff to learn is a young \"man's\" game. I did all of that and absolutely learned a helluva lot. It did everything I needed from it. I got cheaper/better computer than what I could afford. I learned a hell of a lot about not just the hardware pieces I chose, but also why/how certain things about the OS that I never would have. But now, I too just don't care. It was interesting, but I'm not that interested about maintaining an OS or how it works. I just want it to work. So for all of those that are willing to do all of that today, I'm all for it. your comment came across to me as just another one of those \"if you don't feel the same way i do, you're wrong\". that's not true. people can just be in different places in their life. been there, done that does not mean you can't go there and do it too. we're just focused on different things now reply joshspankit 7 hours agorootparentThere’s another perspective: even if OP is done, if we shut the door (or let it be shut by companies like Apple) then the currently-young won’t be able to tinker and won’t grow to gain the same knowledge. reply dylan604 6 hours agorootparentThey are free to continue that kind of work, it just gets harder. Look at Asahi Linux. While it might not be Hackintosh in the same sense, it is the same spirit. Hackintosh worked because the systems were built on commodity hardware. Now that Apple is using custom chips, they've definitely made it a bit more difficult, but in my experience that just brings out the really talented that step up to the plate to take a swing. reply bruce511 13 hours agorootparentprevI agree that tinkering is a side effect of curiosity, and that curiosity leads to expertise, which has value. I parleyed my curiosity in hardware into my first job. (My car-fixing skills alas didn't take me anywhere.) Hardware was fun for the first 10 years of my career, but now, well, it's just not interesting. I played with Linux as well along the way, but I confess that too has dulled. Building your first machine is fun, building your 10th is less so. The past couple years I've gone down the solar energy rabbit hole, and I'd love a wind turbine (but I just can't make the economic argument for having one.) If I do end up getting one, it'll be to prove to myself that it was a dumb idea all along. In some ways we never stop tinkering. But the focus moves on to the next challenge. reply macintux 10 hours agorootparent> Building your first machine is fun, building your 10th is less so. Building a Linux box led me back to Apple. I had been using UNIX at home, school and work for several years, and decided it was time to build my 3rd Linux box. Went to CompUSA out of idle curiosity to see what equipment they had, and the only computer in the store with Internet access was a Mac. I hadn't used a Mac since the SE/30 days, and I suddenly realized that the NeXT acquisition which I'd mostly ignored had changed everything. Why build a Linux box and be locked out of tools like Photoshop when I could have UNIX workstation that ran commercial software (for, admittedly, significantly more money). Never looked back. reply viraptor 5 hours agorootparent> Why build a Linux box and be locked out of tools like Photoshop That's what VMs are for. You're never really locked out. It may not make sense to go that way if Photoshop is THE thing you work with of course. > when I could have UNIX workstation that ran commercial software Because for lots of software MacOS is a second class system. Partially because there's just no way to test things on it without investing lots of money in hardware, so many people don't. If you're doing lots of sysadmin / software maintenance style work, MacOS just provides unnecessary pain. reply pjmlp 24 minutes agorootparentIndeed, why get a lesser experience with Linux laptops, when I can use Apple and Microsoft platforms, and use Linux in a VM when I really need to. The Year of Linux Desktop is delivered on a desktop VM. reply viraptor 5 minutes agorootparentIf that works for you, great. My default works better with Linux with only occasional other system. Makes me least angry. (Also because Linux is the only system that handles sleep/hibernation for me without issues, ironically...) sbuk 2 hours agorootparentprev> If you're doing lots of sysadmin / software maintenance style work, MacOS just provides unnecessary pain. Amazingly a significant amount of the software that you use on a daily basis, perhaps unwittingly, is developed and maintained with macOS and Windows! reply secstate 13 hours agorootparentprevI think the awkward part of your first post is that you appear to start with a value judgement that tinkering is for poor people who's time is worthless. That's not remotely fair to either poor people, or rich people who like to tinker. No one's time is worthless. Not your time. Not mine. It's all just time. reply bruce511 7 hours agorootparentFair enough, and no I didn't mean to impinge time is worthless. It's not the value of time that changes, but the amount of it you have. In a work context a shortage of time (more customers than you can handle) means you need to discriminate, which means you can't make everyone happy. Which usually means differentiating based on value. (Aka, you get more expensive. ) For personal time you also become more discerning. Spend time with spouse, or build another computer, or lie under a car etc. Life has more demands, so there are more choices. Incidentally, one of those choices is to work less. The tinkering never goes away, but I prefer to tinker in profitable areas now. (I get to tinker for work.) reply pjmlp 26 minutes agorootparentprevOn my days we used to tinker in proprietary 8 and 16 bit home computer systems, The Way of Linux (TM) is not the only path to enlightment. reply Aeolun 9 hours agorootparentprevAt this point I feel like Linux may be more likely to just work than a windows machine. I just had the unfortunate experience of setting up windows 11, and the number of ‘please wait while we get things ready for you’ was truly astonishing. reply asyx 1 minute agorootparentIt's not. You can go and pick up any computer that is currently on the market, doesn't matter if it's 300 or 3000 dollars as long as it is a (n IBM) PC and it will run Windows. Will it always be flawless? No. Will it always work perfectly out of the box? No. But it will work and generally you have a good chance of it working as you wish assuming you are fine with Windows and what MS does with it. I bought an Asus Zephyrus G15 (2022) specifically because it was recommended to me because it is supposed to be great for Linux and it's probably the worst Linux experience I have ever had. As the first piece of hardware that I specifically picked for Linux support. Because most DEs don't do fractional scaling but all high end laptops have too much DPI to not have fractional scaling. Nvidia is still not providing proper Linux drivers. Asus can't program to save their lives but the tools that replace the Asus stuff on Windows are still better than the stuff that is replacing the Asus stuff on Linux (asusctl/ supergfxctl vs G-Helper). I once had a machine where the nvme drive was simply not working. That was when Kernel 5 came out. It broke on Fedora but worked in Mint until Mint got Kernel 5. During my last Linux adventure, KDE just died when using WhatsApp as a PWA (where I live, WhatsApp is essential software to have a social life). And even after years of Wayland being around, it's still impossible to have apps that aren't blurry in most DEs because X11 is still around. You're complaining about software updates and user friendly loading screens. The issues that drive people away from Linux and to Windows are literally unfixable to 99% of the techies that try Linux. I'm not fixing an nvme driver in the Kernel. That's not my area of expertise. But I still need my machine to work and on Windows, it does. Rufus let's you create an ISO that skips most of the windows 11 nonsense btw. reply ghoover1978 9 hours agorootparentprevI think that everyone knows that's a pretty ridiculous statement. Installing Windows 11 is basically putting in a USB stick, waiting about 8 minutes, clicking a few things and typing out your login and password. I love Linux, first started playing with it about 20 years ago now. There's not a single dist I've ever seen that is that simple. Just a basic fact, sorry. reply soraminazuki 3 hours agorootparentNow, that is a ridiculous statement. Installing Windows has never once been a smooth experience you describe. It's been long wait times, dozens of reboots, and never ending cycles of Windows Updates. Always has been for the last 20+ years. Today, it's even made worse by the fact that MS is intentionally driving Windows UX to the ground in exchange for short term profits. Installing Windows isn't \"clicking a few things.\" It's going out of your way to disable piles upon piles of anti-features MS throws at you, whether it be spyware, bloatware, or the hyper-aggressive nags to get you work against your will. The length die-hard Windows users go to to \"de-bloatify\" their Windows installation these days is absurd. It's true that Windows had a superior end user UX over Linux 2 decades ago. But that has changed with improvements on the Linux side and poor, poor decisions on behalf of MS. reply Aeolun 7 hours agorootparentprev> There's not a single dist I've ever seen that is that simple. Just a basic fact, sorry. You having that experience does not make it a basic fact. I didn’t even have to do the actual installation, as it was a prebuild machine. The only thing I had to do was the ‘clicking a few things and typing out username and password’ part. Comparing the two between Ubuntu and Windows, I’m forced to conclude that Ubuntu has the easier version, or at least faster. And windows has the advantage/disadvantage of needing my MS account to set up an operating system. reply skydhash 7 hours agorootparentprev> Just a basic fact, sorry. Ubuntu, Linux Mint and Elementary OS and I guess a few others will beg to differ. And it takes way less than 8 minutes. reply xcv123 4 hours agorootparentprev> There's not a single dist I've ever seen that is that simple. It is that simple with Ubuntu and similar distros. It has been that simple for many years. reply mattl 8 hours agorootparentprevAs I found out this week, making the Windows 11 USB stick is far harder than it ought to be if you don’t have Windows already. reply josteink 2 hours agorootparentIf you use UEFI, all you need is to copy the files from the ISO over to the USB stick. Am I missing something? (And the same applies to UEFI capable Linux-distros) reply zozbot234 13 hours agorootparentprev> Linux is only free if your time is worthless! This argument is quite out of date. You'll lose a whole lot more time on forced Windows 10/11 updates than you'd spend managing a reasonable Linux installation. (\"Reasonable\" meaning avoid things like Arch or Ubuntu, and pick decent, natively supported hardware.) reply audunw 13 hours agorootparentThat argument doesn’t sound very convincing to me. How would I know an avoiding Ubuntu is reasonable? That still seems to be the go-to distro for many people I know that like to use Linux but aren’t Linux experts. How do I know which hardware is natively supported? With Windows 10/11 I’ve never had any problems, either with pre-built computers or my home-built PC. Hell, running Ubuntu in WSL has been relatively smooth as well. My experience with Linux as an OS has been fairly good for many years, regardless of the distro. It’s the applications that could be an issue. Feels like it’s only very recently (post Steam deck in particular) that gaming seems to be viable at all. And it’s hard to beat the MS Office package for work. I recently got the idea to have two user accounts on my home computer where I have an account dedicated to working from home, logged into my office 365 account from work.. and it was honestly amazing how suddenly everything was just perfectly synced between my work and home computer. reply chasil 11 hours agorootparentIf you have recently endured Windows Update for Patch Tuesday, you know that you are forced to reboot during this process. This activity will deny you \"the five 9s,\" i.e., 99.999% availability in uptime. If you have recently performed the analog activity on a Linux distribution, which is likely either apt update/upgrade or yum update, you will notice that a reboot is not required. These update approaches cannot alter the running kernel, but ksplice and kernelcare offer either free or low-cost options to address that. Windows update is enormously painful compared to Linux. There can be no argument of this fact. reply afavour 10 hours agorootparent> This activity will deny you \"the five 9s,\" i.e., 99.999% availability in uptime. Which is something 99% of personal computers don’t care about even slightly. These days restarting your machine is a very inconsequential event, your browser can effortlessly reopen all the tabs you had active, macOS will even reopen all the windows for your native apps. I don’t mean to defend Windows Update, I just think “you have to restart your computer!” is not a particularly good reason to damn it. reply dylan604 8 hours agorootparent> Which is something 99% of personal computers don’t care about even slightly to the point that I know people that still turn their computers off when they are not using them. reply chasil 9 hours agorootparentprevWindows update is agony compared to apt/yum. A complete patch Tuesday session is twenty minutes of reduced performance, followed by a \"don't reboot your computer\" of unknown time both before and after the reboot. Anything is better than that, especially when some updates either reboot immediately or kindly give you five minutes to close everything down (was tmux made precisely for Windows update?). Exposure to apt/yum really makes Windows intolerable, just for this alone. reply mrcsharp 8 hours agorootparent> especially when some updates either reboot immediately or kindly give you five minutes to close everything down I have been a Windows user since XP. Never, not even once did Windows decide to reboot without asking first. Never. The only way this could've have happened is if Windows kept asking you over the span of a week or 2 to restart to apply the updates and you kept postponing it. Either way, \"Hot Patching\" will soon be a thing on Windows so restart won't be required every month [1]. [1] https://www.windowscentral.com/software-apps/windows-11/micr... reply mrcsharp 8 hours agorootparentprevLet's get this out of the way first: \"the five 9's\" is not a requirement for personal computers. That argument therefore is invalid. But even then, Microsoft is testing \"Hot Patching\" windows installation so critical updates install without requiring a reboot [1]. When that comes out, I wonder where the goalposts will be? [1] https://www.windowscentral.com/software-apps/windows-11/micr... reply jonathankoren 6 hours agorootparentprevWhat are you doing on a desktop computer that can only be off for five minutes a year? A laptop is even dumber to complain about, because they're (suppose to be) suspended every time you close them. reply TylerE 12 hours agorootparentprevThat would be a firing offense at my company. Company files stay on company hardware. Personal files stay on personal hardware, and never should the two meet. reply indymike 9 hours agorootparentI would never work at your company. I use my own tools, thank you. reply baq 1 hour agorootparentMy personal vim config on a company laptop? No problem whatsoever, neither for me, nor the company. A bittorrent client without preauthorization with IT and security? It's basically asking to get fired. My vacation photos on a company laptop? Tricky - not a huge deal but not recommended. Better upload them to your cloud backup quickly. reply TylerE 9 hours agorootparentprevAre you required to maintain PCI compliance? Do you touch customer personal info? reply jonathankoren 6 hours agorootparentprevYou're own tools are your own personal files? Interesting. How do your vacation pictures help you do your job? reply suslik 2 hours agorootparentNot the OP, but personal files are not just vacation pictures. I work in R&D and I have my org-mode/roam on various scientific and technical topics going back 15 years or so. I use these for work to benefit my current company, and maintaining two parallel versions of these is rather inconvenient. reply TylerE 2 hours agorootparentIsn’t that exactly what a cloud drive is for? There’s a difference between using your personal notes for business purposes on the one hand, and keeping company property and data on a machine totally outside IT control. That’s just a massive lawsuit waiting to happen, and it’s bad for the employee too - why would you want the liability? reply suslik 2 hours agorootparentI would't store company data or code outside of approval services, but one might say that my notes, including notes on the people I meet and projects I work on, can constitute proprietary information - so yeah, it is a bit of a grey area still. reply musicale 10 hours agorootparentprevThat may be sensible if you want or need stronger security and isolation. However, many companies do support BYOD, especially on mobile where it's a pain to carry two phones around. There is some support for this. For example, Apple supports dual Apple IDs and separate encrypted volumes for personal and corporate data. Microsoft apps (Outlook) also have some support for separating personal and corporate data. The benefits of BYOD can include lower equipment costs, lower friction, and potentially higher employee happiness and productivity. reply TylerE 4 hours agorootparentMobile is a totally different story, to me. The security model allows them to be compartmentalized in the way a desktop never could be. reply fsflover 13 hours agorootparentprev> How do I know which hardware is natively supported? You buy preinstalled. Works for me. reply lanstin 12 hours agorootparentYeah preinstalled. And I never had issues with Ubuntu breaking in ways like arch or gentoo. Breaking includes trying to install some new thing or uograde and having random other stuff have to be googled. reply starky 7 hours agorootparentprevThat is patently wrong. I run Fedora on my Framework because it is the most supported and recommended distro for it and I mostly just need a web browser for most of the things I do on it. I've had kernel upgrades break wifi completely, the fingerprint reader doesn't work properly out of the box, 6GHz Wifi isn't supported (though neither is it supported in Windows 10), VLC (which I hate using) is the only media player that supports playing from SMB shares on Linux, Wayland isn't compatible with Synergy type software (and my web browser doesn't work well with xorg), etc. Most of these things worked without any fuss in Windows and I can't think of any notable Windows issues I had to deal with on the laptop before I installed Fedora. reply jrflowers 13 hours agorootparentprevThis is a great linux post because while taking the time to type out distros to avoid is worth it, saying what distros to try is not. reply mmcnl 13 hours agorootparentprevThis is absolutely false. I run dual-boot Windows and Linux on hardware that has 100% Linux support. Windows just works, the same cannot be said for Linux unless all you do is use a browser and listen to Spotify. reply resource_waste 2 hours agorootparentLet me take a guess: You have exclusively used Debian-family distros. Try a desktop distro like Fedora. Debian-family is a server distro that got famous after Conical/Ubuntu did marketing really hard. Ubuntu is the Apple of Linux, they are famous from marketing, not quality. reply t-3 13 hours agorootparentprevThere are pain points on both. Audio on Linux is still annoying if your system isn't very vanilla, while Windows sucks at bluetooth, configurability, and has a lot of annoying anti-user \"features\". reply yoyohello13 10 hours agorootparentprevWindows does not “just work”. On my work computer my programs randomly rearrange themselves after lunch, windows always has trouble switching between my audio devices, random slowdowns. Windows is pretty shit these days tbh. It’s pretty much like Linux was 10 years ago. However, I rarely have issues on Linux anymore, mostly because of something is broken on Linux, I can fix it. Frankly, I hate that I’m forced to use windows as work. I feel like I need to constantly deal with BS windows annoyances. When I go home and work on Linux it like breathing a sigh of relief. My desktop actually feels fast and efficient. reply afavour 10 hours agorootparent> On my work computer my programs randomly rearrange themselves after lunch, windows always has trouble switching between my audio devices, random slowdowns > I rarely have issues on Linux anymore, mostly because of something is broken on Linux, I can fix it. Perhaps your Windows knowledge is not up to the level of your Linux knowledge? It might be that a Windows expert could fix every issue you’ve listed and more. reply Twisell 11 minutes agorootparentI'm a long time macOs user at home (pre-X). I've worked daily in Windows enterprise environment for 15+ year (which mean that when it won't work I usually \"just have\" to get help from a colleague. I've been in charge of a debian/postgresql cluster for 10+ year which I managed to keep upgraded on a reasonable schedule. But Yet, since for some utterly opaque random reasons Windows updates on my home gaming PC stoped working two months ago I feel totally clueless about how to even begin to debug this crap. There seems to be absolutely no clear working procedure out there to fix that, only people with the same problem shouting out to the void. All them poor souls trying byzantine procedures that have been duplicated ad nauseam from stack overflow to windows help forums through reddit and back. The consensus seems to reinstall windows from scratch (by choosing amongst a handful of ways for which risks/benefice looks unclear). That really piss me off and but I guess it's user fault because \"my Windows knowledge is not up to the level...\" reply yoyohello13 9 hours agorootparentprevThat’s very possible, but I don’t want to invest time gaining knowledge in a proprietary platform. Microsoft already owns most of the default stack programmers use these days. I don’t want to contribute my energy to entrenching them further. reply fsflover 13 hours agorootparentprev> unless all you do is use a browser and listen to Spotify So what exactly isn't working? reply Rebelgecko 10 hours agorootparentThese have been pain points for me. Not saying they're impossible to solve on Linux, but it's nontrivial especially compared to Windows Change trackpad scrolling speed Set up suspend-then-hibernate GPU drivers (I have a box with an AMD APU and no idea how to actually utilize it) Many games (Proton is amazing and a huge leap forward, but om average it's still more work than gaming on Windows. eg fiddling with different versions of Proton or finding out that a game's anti cheat will ban you for using Linux) Higher res video streaming (I think this is usually a DRM issue?) Full disclosure: I'm posting this list because I'm hoping that someone will tell me I'm wrong and that Gnome actually has an easy way to set the trackpad scroll speed reply WJW 11 hours agorootparentprevNot OP, but the fact that I have an easily accessible text file on my desktop with the exact commands to run in my terminal to recompile the graphics driver when upgrading packages breaks graphics again should speak volumes. I don't really mind, because running 3 commands in the terminal a few times per year is not particularly difficult for me. I could see it being difficult for non-devs though. What does get annoying is when such an OS upgrade breaks the wifi drivers and I have to setup a bluetooth hotspot on my phone to access the github repo and fetch the latest driver version for the wifi dongle. reply matkoniecz 12 hours agorootparentprev> avoid things like Arch or Ubuntu which one you would recommend? reply theodric 10 hours agorootparentWell I'm just a rando, and you didn't ask me, but I agree with the sentiment, so: Fedora. Or openSUSE. I'd be more comfortable giving a newbie Fedora. I was a Debian devotee for nearly 25 years, but I've found it to be less foolproof and fault-free lately, and it has always lagged behind current package versions in Stable, forcing you to run Testing (or -backports) or even Unstable to get newer versions-- with corresponding potential for breakage. reply Fnoord 9 hours agorootparentDebian Stable was very out of date 25 years ago, but ever since mid '00s (after Ubuntu got popular) it improved by miles. Debian Stable is akin to Ubuntu Stable LTS. Ubuntu Stable non-LTS is a 6 month snapshot from Debian Testing, does not get supported for long. If you run Debian Unstable, you're probably running something akin to a rolling distribution. What is best all depends on your goal and purpose of the task. Personally, I very much like the Debian ecosystem and would prefer any Debian(-based) OS. However these days, Docker can trivialize a lot (and also mitigates your mentioned issue), ZFS and other filesystems allow to rollback in case of issues (useful on a rolling distribution, but also on Debian Unstable), and hypervisors allow snapshotting, multiple OSes, and all that, too. For a server I'd recommend Proxmox (especially since ESXi is now only for enterprise). From there, have fun with different OSes. Proxmox on a desktop is a bit meh, but possible. There's a lot of useful Linux desktop OSes out there. For example if you want to perform pentesting you can use Kali Linux. The one which interests me most from a security standpoint however, is Qubes OS (Fedora-based, sadly, but you can run anything on top of it). For gaming, SteamOS is neat (Arch-based, these days) and could even be fun to have a kid play around with Linux, too. As for macOS, I played around with Hackintosh a couple of times in the past with success. But I never liked it much because you'd lag behind on security patches, and every new update would be praying it'd work. I did get it to work under Proxmox though, that was fun, but had to install a second (dedicated) GPU for that. I latest M-series ARM-based Macs work very well, only disadvantage is the fat price upgrade for RAM and SSD (often even soldered!). That part is terribly sad. reply chx 9 hours agorootparentprevThis is 100% false. I have been running Ubuntu then Arch as my daily driver 2004-2017. As I started a consultant working for Western companies I thought they will care about me being clean copyright wise so I went 100% Linux. This was obviously not so but what did I know? I deeply regret doing this now. (I was dual booting before.) With Ubuntu, upgrades every six month or so meant you were better off reinstalling and reconfiguring -- no matter which way you went, it was 2-3 days of work lost to tinkering the system. With Arch, the whole system doesn't shatter, it's just this and that doesn't work and it's frustrating. Bluetooth, multifunction scanner-printers being in the forefront. In fact, I needed to sell a perfectly working Samsung MFC at one point because Samsung ceased to make drivers, the old ones didn't work with newer Linux and while open source drivers surfaced that only happened years later. Let's not even talk multimedia. https://xkcd.com/619/ is ancient but the priorities are still the same. Neither systems were great on connecting to weird enterprise networks, be it enterprise wifi or strange VPN. At one point I was running an older Firefox as root (!) to be able to connect to the F5 VPN of my client because the only thing supporting 2FA for that VPN was a classic extension -- and the binary helper disappeared in the mists of time. The only Linux related discussion was ... the IT head of my client asking how to connect Linux to his VPN now that he turned 2FA on and being told it doesn't work. https://community.f5.com/discussions/technicalforum/linux-ed... well I made it work but faugh. I have been running Windows 10 + WSL since 2018 January and all is well. It reboots sometimes while I am asleep and that's about it. You need to run O&o shutup like once in a blue moon. Right now I am on Win 11 as my primary laptop is being repaired, you need to run ExplorerPatcher but that's it. It's been indeed six years and there was never an update where the OS just didn't start up or a hardware driver decided to call it quits after an upgrade. Also, updates are not forced, I control my machine thanksmuch via Group Policy. https://xkcd.com/619/ is ancient but the priorities are still the same. reply sergeykish 20 minutes agorootparentI am Linux user since 2006, Ubuntu then Arch. Bluetooth mouse, keyboard, headphones, controller works. Intel iGPU works, including hardware accelerated video in browsers. VPN: Pritunl worked without issues, Perimiter 81 initially failed, works with update. Wayland, Pipewire, Wine, Proton - Steam Deck is widely successful multimedia device. Priorities are same, NVK joined open source drivers. Linux does not connect to \"enterprise wifi or strange VPN\" - ok. reply theshackleford 11 hours agorootparentprev> You'll lose a whole lot more time on forced Windows 10/11 updates Utter fantasy. They complete whilst I sleep, taking zero of my time at all. reply Aurornis 13 hours agorootparentprev> Something never quite sat right with me about this argument, and your comment finally made me understand what it is: the understanding you gain from tinkering is priceless, and it's exactly the experience that you use to help everyone around you: it turns you into an expert. I have plenty of other things I’d rather tinker with and become an expert on, though. My computer is a tool to let me work with those things. It’s not fun when I have to debug and fix the tool for hours or days before I can even start working on the things I want to work on. reply matwood 11 hours agorootparentThis is me. The range of things I want to tinker with has grown. Various house projects, jiu-jitsu, cooking, etc... are all things I tinker with and learn from. Building computers, I've done and don't feel the need to do again. I even built a Gentoo install long ago when I was learning the nuts and bolts of linux. reply TylerE 12 hours agorootparentprevExactly. Why do I want to be neck deep in some XML config hell when I could be playing music? reply blfr 12 hours agorootparentprevI also use Linux on all my machines but that's because (perhaps after years of tinkering) it is currently the most turn-key laptop/desktop OS. Things just work, they don't break without a good reason, and weird limitations don't randomly pop up. Windows at work, despite being maintained by professional helpdesk staff, or Macs my family have, with all the ease of use designed by Apple in California, are not like that. Just the other day I tried to download an mkv file over https on a Mac and I couldn't get it to exceed 2.5 MB/s. Same network, same server, my laptop breezed at over 20 MB/s and Apple took out that walker for a stroll at a very leisurely pace. It didn't come with `wget` either. reply willdr 11 hours agorootparentIf you sincerely believe this, you've tinkered enough that the massive knowledge barrier that is Linux seems like nothing to you. I would never sit my 70 year old mother down in front of a Linux machine. We're not at \"caring that video files download too slowly\" - we're at \"how do I put a file on a USB\". reply WJW 11 hours agorootparentPut USB stick into computer, click on \"Files\" in the program chooser, select the USB drive (helpfully listed as \"USB drive\" even), drag your files there? Same as on Windows and MacOS really. I don't dispute that Linux has rough edges, but putting files on a USB stick is not one of them tbh. reply akho 2 hours agorootparentprevI do sit my 75-y.o. mother in front of a Linux machine, and it's fine. reply acomjean 6 hours agorootparentprevI have very little Linux sys admin knowledge and have been using it on my home notebook for 5years and my work one two years now. Really no issues with the OS. I was using the very excellent 2015 Mac book pro before, but despite hardware that isn’t quite as nice (not bad though) that hardware I can’t go back to Mac OS. I know I pay a premium to get it pre installed over windows, but it’s not bad. reply john-radio 9 hours agorootparentprev> hackintosh is likely in the rear view mirror for the next generation of tinkerers. Part of this might be that making Hackintoshes is so much harder now, but part of it might also be that OOTB desktop Linux is luxuriously good these days compared to where it used to be. Ubuntu and Pop!_OS linux are absolutely on par with MacOS for a user who meets the (admittedly higher) entry requirements for using Linux. reply chewz 4 hours agorootparentprev> People have been making this argument to me about Linux for more than 25 years. The most cutting version that I ran across was: > > Linux is only free if your time is worthless! But it is exactly why I quit Linux and returned to macOS. I used to run Linux on cheap 2nd hand ThinkPads and for 3 years on Macbook as main system. But after another upgrade destroyed gain all network connectivity I have quit. macOS isn't perfect but it works in most imposrtant areas and I can tinker with small stuff when I feel like it. reply resource_waste 3 hours agorootparentprev> Linux is only free if your time is worthless! Just a guess, you only used Debian-family and everyone who said this only used Debian-family distros. reply rmbyrro 8 hours agorootparentprevUbuntu is so easy to use. I enjoyed using Arch before, but got to a point where I also just wanted my PC to work without any tinkering. Ubuntu is very good at that. reply jstummbillig 12 hours agorootparentprev> the understanding you gain from tinkering is priceless You pay with time. It's priceless, if you are a romantic or lack foresight (because what you did with your total will be way more important than what is left). Otherwise it will always be the most expensive thing you have (and we must still be able to spend it without care, because what would life be otherwise). > But when it doesn't, I often wish I was that guy that had tinkered with my car Don't. Instead build a network of experts you trust and make more money doing what you do best to pay them with. Trying to solve the world on your own is increasingly going to fail you. It's too complicated. reply doubled112 11 hours agorootparentDisclaimer: This became more of a rant than I intended. I've become pretty unhappy with the general quality of the \"professionals\" I've interacted with lately. I just can't agree with this take. It sounds that simple, but it's not. I happen to enjoy learning and fixing. It would take me a long time to build that trust. Nobody cares about my things and my family's safety like I do. Most people are a long way from making as much money as an expert would charge them. In the last couple of years, I have had some terrible times when I call for help. When the dealership is charging $200/hr to have a kid plug in the car and follow a flowchart, I'll just take a look myself. Plus one time they left my fuel pump loose and I had to pay (in time and money) for an extra round trip with Uber, and the fuel it sprayed onto the road. They didn't fix the original problem, which cost me another round trip. Another time, I had technicians (experts) out to look at my leaking hot water tank 4 times before they decided it was time to replace it. I wasted the time calling, babysitting, coordinating, figuring out how to shower without hot water, etc. If this is the average \"expert\" count me out. I'll do it myself. Plus, throwing money at a problem isn't near as fun. reply jstummbillig 10 hours agorootparent> When the dealership is charging $200/hr to have a kid plug in the car and follow a flowchart, I'll just take a look myself. Regrets about not becoming more of investing the time to be an intuitive handy man is a very different category from \"let's see if there's a video on yt to help me fix that in 5 minutes\". My message is definitely not \"don't get your hands dirty\" but \"be practical\". Doing the yt/google/chatgpt thing to get an idea is mostly practical. > If this is the average \"expert\" count me out. You disclaimed, no problem — but I did write \"build a network of experts you trust\". Just calling someone and being annoyed that they are not good (and I agree, most of them are not) is not that. It's going to take time and money, but decidedly less so, because you get into the habit if doing it, you learn, you see red flags, network effects are real (people know people) and relationships on average last long enough. That is my experience, at least, but I have no reason to believe I would be special here. > Plus, throwing money at a problem isn't near as fun. That's true, in my case, only for very few problems. Most problems I would rather not solve myself. I'll admit: All of this is a concession to reality, at least my perception of it. Learning is fun. I would really love to be good at a great many things. It's just increasingly unreasonable to invest the time necessary, because things get more complicated and change more quickly. Staying good at a few things, learning whatever is most important next, and getting better at throwing money at the rest, will have to do. reply EarthLaunch 9 hours agorootparentI'm enjoying this thread. I want to add that building a network of experts has other costs too. Sticking to a network will limit the variety of people you get to meet, everything else the same. Local maxima. It also isn't practical in some circumstances; if I travel for work or move cities every few years, the local network for mechanics gets lost. The cost of keeping the network would be staying in one place. So, these are all options. reply bruce511 6 hours agorootparent>> The cost of keeping the network would be staying in one place. One man's bug is another man's feature:). You describe staying as a bug, I've lived in the same house for 24 years, and, for me, it's definitely a feature. I'd positively hate moving to another suburb, never mind city. And yes, I've developed relationships with local service providers. My plumber, my electrician, my mechanic, all know me by name. I've found the people I can trust and they eliminate those hassles from my life. But, and this is my point, I'm not you. My context, my goals my desires, are all different to yours, and that's fine. We're all in different places, being different people, and that's OK. It doesn't have to be \"us versus them\". We might enjoy different thinks, and have different perspectives, but that's OK. reply throwaway22032 6 hours agorootparentprevTo be honest, none of that stuff has been true for 15+ years anyway. Linux just works now. You put in the Ubuntu/Debian/Arch/whatever USB, you install it, it just works. I can't remember the last time anything broke on any of my desktop machines and it wasn't my fault for intentionally doing breaky things. reply riquisimo 5 hours agorootparentprevI really like the way you put that. reply teh_infallible 13 hours agorootparentprevYour comment makes me think of my 3d printing journey. A lot of printers require maintenance and tinkering just to keep them functional. To an extent, since they are targeted towards “makers” who like to play with these things, that’s fine. But sometimes the thing you’re trying to build is of central importance, and you want the machine to stay out of your way.Tinkering with the machine takes away time you could be exploring your ideas with a machine that’s already fully functional. reply bruce511 13 hours agorootparentSometimes the holiday is the destination. Sometimes the fun is in the getting there, not being there. Tinkering can be fun. But these days I mostly want results, achievements etc. I want to tinker to a successful goal, not just tinker for tinkers sake. reply shirro 6 hours agorootparentprevYou need to understand the bias of many HN commenters. They are running businesses, aspire to run businesses or employed by businesses that are monetizing the work of tinkerers and packaging it for a mass market where they can sell higher volumes or mine more personal data. There are a lot of people who will recommend spending massive amounts of time and money learning and renting proprietary services over learning fundamental concepts and owning your own stack. I just ignore them along with the crypto bros before them and the AI pumpers now. Renting proprietary closed services to people who don't know better is their bread and butter. reply teaearlgraycold 9 hours agorootparentprevLinux is for work. I wouldn’t consider running anything else (Windows, MacOS, FreeBSD, etc.) for my services. reply nesarkvechnep 3 hours agorootparentConsider FreeBSD, because it’s great. reply datavirtue 11 hours agorootparentprevThese days, if you have the skills and tools to swap a transmission you have to tow it into a dealership and beg them to flash the transmission so it will work in your truck. If you want to avoid that you better know where to find the strategy code and match it up before purchasing another transmission. Same goes for touch screens and a whole slew of essential parts. While we weren't looking the rug was completely pulled out from underneath us. Now your family mechanic is beholden to the dealership. reply eastbound 11 hours agorootparentprevYour argument is excellent and made me evolve my point of view about Mac. I use Mac for efficiency, and yet, I was wrong about what kind of efficiency I’ve been developing. Tinkering is so important, even if just for the fun of it. reply yieldcrv 8 hours agorootparentpreva frustrating freely accessible experience being priceless is not mutually exclusive from your time being worthless but I’m sure your point will inspire someone reply golergka 13 hours agorootparentprevFor you, me, other people on HN who generally make a living by understanding computers, definitely. For a layman who just needs to connect to WiFi, edit some documents and print them without having to update a kernel? No. reply matkoniecz 12 hours agorootparent> For a layman who just needs to connect to WiFi, edit some documents and print them without having to update a kernel? No. when it was needed to do it last time, in way more troublesome than Windows system updates? reply Nab443 12 hours agorootparentprevEven as a dev with 3 environment I've not had to tinker my kernel since I left gentoo something like 15 years ago, Ubuntu takes care of it.. reply jonathankoren 9 hours agorootparentprev>Something never quite sat right with me about this argument, and your comment finally made me understand what it is: the understanding you gain from tinkering is priceless, and it's exactly the experience that you use to help everyone around you: it turns you into an expert. Yeah, but an expert in what? There are only so many hours in a day. Like if you care about learning about some rando soy d driver, or why all you photos come out pink under Linux, but not Windows[], that’s great. Go knock yourself out. But if you want to do something that’s not rando debugging, then maybe it’s not for you. Like, I like Unix. It’s lets me do my work with the least amount of effort. What I don’t like is being a sysadmin. Some folks do, and that’s awesome. But that’s the reason why I got rid of desktop Linux 20 years ago. [] Both of these are actual lived experiences. I do not care about you chiming in about either of these. reply stavros 14 hours agoparentprevI don't know about you, but for me it was never about the money. I did this stuff (and still do) because I find it fun, not because I can't afford to buy it. I have my desktop, and I want that to just work, and I have a bunch of computers, hardware, 3D printers, etc etc that I constantly tinker with, because I like it. I suspect it's the same for you, and it may be the lack of time, but not so much the access to money. reply nemosaltat 14 hours agorootparentAs a teen in the mid-oughties. I played heavily with the OSx86 project/Hackintosh. I learnt about writing kexts and kernel patche and I fondly remember getting a Linksys USB-to-ethernet adapter working on an HP workstation, running Tiger. My financial circumstances have improved somewhat in the intervening years. Today, I own quite a bit of Apple hardware, most recently Vision purchase overton-shifted my definition of “disposable” into very unfamiliar territory. Even still, about once a year I ensure I can still triple-boot” - just now I do it with ProxMox and Virtual Passthrough. The first iMessage sent from my virtualized “iMac pro” at 2AM and was almost as gratifying as the first Apple Bootscreen on a a Sony Vaio. May we never lose whatever that is. reply endymi0n 11 hours agoparentprevSpot on for me, but there's a different argument at play: At the beginning of the OSX on x86 times, Apple had an OS with a stellar user experience, but the hardware was just completely overpriced, so Hackintosh made complete sense. Fast forward to today and I think Apple managed to pivot this almost to the complete opposite end. I think the hardware is incredible value (that's debatable for sure, but my M1 aluminum machined Macbook with Apple Silicon is blazing fast, completely silent, super sturdy and runs forever — I wouldn't trade it for any other laptop I could buy with money), while the Operating System has really taken a backseat, with hugely annoying bugs unfixed since 10 years: https://news.ycombinator.com/item?id=39367460 To me, in a world like that, Hackintosh simply doesn't make much sense anymore. Asahi Linux is really the star on the horizon, by doing exactly the opposite: Letting a free and better maintained operating systems run on strictly awesome hardware. reply jwells89 8 hours agorootparentValue was the driving factor for some of my early hackintoshing (Core 2 Duo era), but what pushed me to do it from 2015-2020 was the abysmal state of higher powered Mac hardware. The Mac Pro was still the un-updated 2012 trash can, the 15” MBPs were too thin for the CPUs they housed (perhaps Intel’s fault for getting stuck on 14nm for so long, but still) and were hot with terrible battery life, and while the 27” iMacs weren’t terrible and probably the best of the lineup, they still weren’t cooled quite as well as they should’ve been. My 6700k + 980Ti tower in a Fractal Define case with a big quiet Noctua cooler was just flat better and made a far better Mac than anything Apple sold at the time. That said, I did eventually grow tired of the tinkery-ness of it all and in 2020 picked up a refurbed base model iMac Pro, one of the few Macs in that timespan that wasn’t a mistake, for about half its MSRP. It was about as powerful as that tower, surprisingly even more quiet, and of course just worked without the tinkering. reply accrual 14 hours agoparentprev> Incidentally it's the exact same journey with my cars. 35 years ago I was fixing something on my car most weekends. Now I just want to turn the key and go somewhere. This resonates with me as well. As a teenager with my first car I spent a lot of time tweaking its appearance, sound, performance, etc., buying what little I could from local auto parts stores. I couldn't wait to get older to have more money so I could do more mods and really make the vehicle how I wanted it. In the back of my head I wondered why older folks didn't do this though. They have these nice vehicles but they're bone stock! Why not new wheels, tint, a tasteful lower, etc.? Then I myself got older and found it just isn't as important as it used to be. I still have a slightly modified car, but I'm not rooting around inside the dash with a soldering iron like I once did, haha. reply dinkleberg 14 hours agorootparentHaha that is a very similar mindset I had when I bought my first house. I was excited about all of the nice improvements I could make and wondered why so many people I knew who were well off never really put much work into their home. Then I quickly realized that its such a big hassle and also you almost instantly get used to things how they are. reply suslik 3 hours agoparentprevWhile tinkering for the sake of tinkering is as good of a hobby as any other, the process of tailoring your OS's does not have to be infinite. Maybe it is different for others, but while I did spent a lot of time on writing my Linux dotfiles until they were nearly perfect, for the last 5 years or so, when I have a fresh OS install, it's really just 'git clone; chezmoi apply' and I get a system where every keybind is exactly where it needs to be. When work banned Linux machines and I had to transition to OS X, I had to do just as much, if not more, tinkering to make it work for me. Perhaps it does 'just works' for those who think exactly like Steve Jobs - but if you want it your way and on your terms, there'd be a lot of tinkering to do, from yabai configs to Karabiner json configs and custom plists, to replacing most of the gelded Apple apps. reply mysteria 14 hours agoparentprevThis is the classic \"money is time, time is money\" conundrum. A teenager doesn't have the money to buy a fancy car or computer but they have the time to tweak and experiment to get the most out of it. Meanwhile an adult has the money but not the time, assuming they have a full time job, kids, etc. So they're willing to spend the money to get products that work and would rather spend their limited time with their family instead. In my teens I had a group of friends who loved to tinker, from hackintoshes to custom ROMs to homelabbing to electronics repair. Now I'm like the only one left who does this stuff :( reply _puk 14 hours agorootparentWhen you're young you have all the time, all the energy, but none of the money. When you're an adult you have all the energy, all the money, but none of the time. When you're a retiree you have all of the money, all of the time, but none of the energy. A generalisation of course, but quite apt! reply mysteria 13 hours agorootparentThe only way out of this is an early retirement in a LCOL area or a job with a very good WLB (which is likely pretty rare for most HNers in the tech industry). Even ignoring overtime I'm typically tired when I get home from work and have other commitments alongside my hobbies and tinkering. reply raincole 5 hours agorootparentprevTechinically when you're retired you don't have all of the time. For most people they only have 1/5 or less or their time left. reply submeta 26 minutes agoparentprevSame here with Emacs. Tinkering-vs-doing. Opportunity costs too high. reply hparadiz 15 hours agoparentprevIt's really not much of a time commitment. You can just lookup hardware with full compatibility and build a desktop that \"just works\". reply derefr 15 hours agorootparentThe primary demographic of people interested in Hackintoshing are people who, like the GP in their youth, couldn't afford to just buy \"hardware with full compatibility\", let alone buy the equivalent-specced Mac. The secondary demographic of people interested in Hackintoshing are people who have an existing PC (or enough extra parts to build a second PC) and want to figure out how to \"make something that can run macOS\" out of it, while spending as little money replacing/upgrading parts as possible. People who buy parts, to build machines from scratch, just to run macOS on them, are a very tiny fraction of the Hackintosh community. (Which is why you so rarely hear stories of Hackintosh builds working the first time with no added tinkering — they can, if you do this, but ~nobody does this.) reply shzhdbi09gv8ioi 14 hours agorootparentI have a need to be able to run macos binaries and xcode from time to time, and it used to be non-trivial to run macos in a unsanctioned vm so I had a mac laptop around. But these days you can spin up a qemu macos vm without too much effort and that's my virtual hackintosh. reply EVa5I7bHFq9mnYK 13 hours agorootparentprevI remember I needed Hackintosh to build an iPhone app on my PC. You must possess a Mac to make apps for iPhones, don't know why. reply tengbretson 8 hours agorootparentprevThis really brings me back. My first hackintosh as a kid was on a 1.4ghz Pentium 4 with a ATI Radeon 9600. reply shantara 14 hours agorootparentprevI started my developer career on Hackintoshes many years ago. No matter how much time I invested into building my desktop, it never \"just worked\". There were always inevitable problems with software updates, which often meant you had to re-image the system from scratch to install a new OS version. Which happened quite often, when you needed it to run the latest Xcode. Then there were a lot of minor annoyances over the years, like crashes and graphical glitches with certain apps, like Photos or Preview, problems with monitor resolutions and refresh rates, and many, many others. Ultimately, they were a useful tool for a time, but they suffered from death by a thousand cuts in terms of practical usability. So, I bought a basic Mac Mini as soon as I was able to, and never looked back. reply jwells89 8 hours agorootparentThe first hackintosh I built back around 2008 I was able to get working actually perfectly. Somehow the hardware and software bits all aligned and everything worked great. It’d run for months on end without issue. Nothing since that one were quite as good. Had a Dell laptop for a while that was almost perfect, but would lock up and require a reboot once every couple of weeks. A tower I built in 2016 was also almost perfect, except I never could get USB working 100% right and later on the Nvidia drivers got flaky. reply taude 14 hours agorootparentprevI built a hackontosh in 2016, bought all the right mobo with the right driver sets, etc. Used the buyer's guides on tonymacx86.com and purchased the exact hardware, downloaded the drivers, flashed things, etc. It was far from \"just working\". I had a stable and solid system for about 18 months (after a weekend of tweaking), and then it needed to be reconfigured, and I didn't have the time to spend the weekend getting it to work again....so that machine went back to windows. Even with the proper supported Nvidia card, I had issues, and went through some pains with the wifi. reply vehemenz 14 hours agorootparentprevCost of ownership of an M3 MacBook Pro is like $300-400 a year. Even if you have the time, it's just not worth it anymore like it used to be. reply bluescrn 13 hours agorootparentI wouldn't count on 10 years of real-world life from a non-upgradeable and 'repair-resistant' device with a glued in battery, even if the hardware specs are good enough to last that long. reply xcv123 13 hours agorootparentThat's 5 years of ownership. $2500 USD for a 16\" then you get something back on the second hand market. reply hparadiz 13 hours agorootparentI'm happy with the M1 air pro for 700. Could use 256 more SSD but it's not worth $500 extra that apple wants to charge. reply suddenclarity 14 hours agorootparentprevI assume people would do this to get a powerful machine and not comparable with one of the cheaper Macbooks? reply j33zusjuice 14 hours agorootparentprevIt seems reasonable when you consider TCO, but you still have to pay 100% up front. Not everyone can drop $2k on a laptop, most people don’t need to. reply shagie 14 hours agorootparentBuying a new MacBook Air https://www.apple.com/shop/buy-mac/macbook-air/13-inch-m2 $999.00 or $83.25/mo.per month for 12 mo. With a footnote: > Monthly pricing is available when you select Apple Card Monthly Installments (ACMI) as payment type at checkout at Apple, and is subject to credit approval and credit limit. Financing terms vary by product. Taxes and shipping are not included in ACMI and are subject to your card’s variable APR. See the Apple Card Customer Agreement for more information. ACMI is not available for purchases made online at special storefronts. The last month’s payment for each product will be the product’s purchase price, less all other payments at the monthly payment amount. ACMI financing is subject to change at any time for any reason, including but not limited to, installment term lengths and eligible products. See https://support.apple.com/kb/HT211204 for information about upcoming changes to ACMI financing. ---- You do not have to drop $2000 on a new laptop up front. reply duskwuff 14 hours agorootparentDon't forget the $700 Walmart special: https://www.walmart.com/ip/609040889 reply internet101010 8 hours agorootparentprev8gb model doesn't count as a usable computer. It's absurd that it is even being offered in 2024. reply skydhash 7 hours agorootparentAnd that's how you know someone has not used the 8GB MBA model. 8GB is more than enough for the light usage you'd buy a 8GB model to begin with. Which means not running 3 IDEs and 5 VMs at the same time. reply Nullabillity 6 hours agorootparentprevSure, then just add $100 each for a decent amount of RAM and storage. Oh, wait... forgot that these are designed to be landfill fodder. reply zozbot234 14 hours agorootparentprev> Not everyone can drop $2k on a laptop That's what most laptops used to cost back in the 1990s or so (after adjusting for inflation). If you look further back in time, hardware was even more expensive - and it couldn't even do 10% of what a modern MacBook does. Modern hardware is ridiculously cheap. reply wkat4242 14 hours agorootparentIn the 90s most people didn't have a laptop for that very reason. They just owned desktops which were way cheaper. I studied computer science then and I knew 1 student out of 50 that had an actual laptop. Even at the uni we had to use their computer rooms full of desktops and X terminals. reply zozbot234 14 hours agorootparentCheaper for sure but not \"way cheaper\", at least nowhere near as cheap as desktop hardware is today. reply ponector 13 hours agorootparentprevIn the 90s no one I know had a computer at home. Nintendo/Sega maybe, rich guys had Play Station, but no one had PC. reply Fnoord 9 hours agorootparentI had a Gameboy, parents had a PC. Friends all had a game console. NES, SNES, SEGA, Amiga, C=64, etc. PC went booming in 90s though. Because here you could buy a PC tax deductible via a law called 'pc-privé'. This was to stimulate citizens to learn to use a computer in their private time. Still, even with tax deduction a PC was very expensive. Not like a car, but expensive still. reply wkat4242 12 hours agorootparentprevOh here people did. Internet was booming and I set up so many PCs. It was great business. reply greedo 12 hours agorootparentprevNot really sure they were much cheaper in the 90s. My first PC was a Dell P90 in 1994, IIRC it cost about $2500. There was kind of a mantra at the time that no matter the improvements, you'd always spend about $2500. And adjusted for inflation, that \"way cheaper\" desktop was over $5K in today's dollars. reply adamomada 14 hours agorootparentprevInflation calculator says the Core 2 Duo MacBook Pro I bought in 2007 is something like $4400 now. Bought a small intel ssd for the sata3 port in it too for probably another $500 now reply duskwuff 14 hours agorootparentprevEntry-level price for a new Mac, right now, is $700 (M1 Macbook Air at Walmart). It doesn't get you the best or the fastest, but it's a perfectly usable laptop. Or, if you're okay with something lightly used, a refurbished M1 Mac Mini is ~$500. reply bluescrn 13 hours agorootparentBut Apple's entry-level Macbooks aren't intended to be bought. They have almost comically low amounts of storage and RAM for 2024 (8GB/256GB). It's all about the upsell on those non-upgradeable parts. reply greedo 12 hours agorootparentThe M1 MBA being sold by Best Buy and Walmart are perfectly fine for 99% of the computing world. Maybe not for gamers (most laptops suck for this), or for someone needing to crunch large datasets, but when this first came out, tons of developers were perfectly happy using it, even with small storage. Hell, my iMac I used up until buying a Mac Studio only had 256GB. reply duskwuff 9 hours agorootparentYep. 8 GB RAM isn't great, but for basic use -- web browsing, word processing, some light photo/video editing, etc -- it'll be perfectly adequate. Not everyone needs a supercomputer. reply pjmlp 14 minutes agorootparentDepends on how much browser tabs they dare to keep open, and how many pictures and videos they want to keep around on their computer stored in high resolution. hparadiz 12 hours agorootparentprevVSCode remote to my Linux desktop on LAN. The upsell is obvious but I'm not gonna drop $500 on 256 gb of disk space reply goosedragons 9 hours agorootparentprevThat's a pretty time limited sale. I doubt the stock of unsold M1s is huge. It's also $700 for a new but essentially 3+ year old machine. reply duskwuff 7 hours agorootparentI think this is a longer-term sales deal, not just a clearance sale of old stock: https://corporate.walmart.com/news/2024/03/15/walmart-brings... As far as the processor goes, the M1 is in active production (e.g. for the iPad Air), and is still a very capable CPU. It may not be the fastest laptop CPU on the market anymore, but it's hardly slow. reply FredPret 14 hours agorootparentprevThey have lots of monthly payment plan options here in Canada, and probably in the US too. It even used to be zero interest. Not sure about the rest of the world. reply kayg04 14 hours agorootparentAlso many no interest options in India but the prices are higher here, somewhat so for the Macs but significantly higher for the iPhone as it is such a social status thing here in the north. reply matwood 14 hours agorootparentprevApple Card offer this in the US, but you have to get the card. I buy all my Apple gear this way. 0% loans are great. reply wkat4242 14 hours agorootparentprevAnd you can drop it and lose the $2k in one single second. You can insure against that but it costs another small fortune. TCOs are great calculations for companies but don't work for individuals. reply nerdawson 14 hours agorootparentAppleCare+ on the $2k 14\" MBP is $279 or +14% for 3 years of coverage. That seems pretty reasonable to me. reply izacus 12 hours agorootparentSo now you made it a 2.3k$ MBP didn't you? Funny how the 999$ MacBooks tend to explode in price when you configure them to make them useful. reply raydev 12 hours agorootparentI don't understand how this relates to paid warranty or insurance. Your TCO for a non-Apple laptop can also include a protection fee or cost to repair with no insurance. reply nerdawson 12 hours agorootparentprevCorrect. It’s an insurance product. Whether you take it is all about your risk tolerance and in no way impacts the usefulness of the machine. I believe 14% is worth it. reply zozbot234 14 hours agorootparentprevBuild a Hackintosh out of a rugged laptop case, problem solved. reply lijok 10 hours agorootparentprevLower specced macs don’t cost 2k. Go for a generation or two old refurb and you’re looking at 600-800~ reply prmoustache 14 hours agorootparentprevBut more people can certainly afford a second hand mac mini which doesn't cost more than the sum of the parts of a typical hackintosh. reply umbra07 13 hours agorootparentprevDid you factor in repair costs? A 14in MBP with an M3 Pro/36GB/1TB is $2800. Add 10% sales tax, and that's about 3k. reply hparadiz 13 hours agorootparentI've never needed to actually repair a Mac. reply jonathankoren 5 hours agorootparentprev> It's really not much of a time commitment. You can just lookup hardware with full compatibility and build a desktop that \"just works\". Oh JFC. This canard has been floating around the about linux for 30 years, and it's always been a half truth at best. Inevitably, it always comes down to \"Cards with 2361YSE rev 5 chipset\" or some other nonsense. Like that makes total sense for a kernel developer, but most people don't know what chipset they have in some peripheral. So now you're left with assholes saying, \"WeLL yOu ShOuLd gEt InFoRmEd. JuSt GoOgLe iT!\", and it ain't that easy. If you can even find a brand name to chipset list, it's going to be out of date, or it's going to be something that says \"2361Y\" or \"2361YSE rev 3\" or something. Is that close enough to \"2361YSE rev 5\"? Who knows! Then the best part? Even when you lookup the hardware with \"full compatibility\", you'll find that it actually isn't. Then when you ask about it, you'll get, \"I just don't use that feature, and you shouldn't use it either.\" reply type_Ben_struct 15 hours agoparentprevI was also that kid. I remember an OSX upgrade breaking my mouse and I couldn't figure out how to get it working again. I was desperate for a Mac, but it was financially unattainable. reply treflop 2 hours agoparentprevIt really depends if you're tinkering because you have no choice versus tinkering because you like it. People will absolutely tinker on cars for their entire life, but upgrade to more interesting jobs like doing engine swaps rather than just changing their oil. But it sounds like you were tinkering because you had no other choice, not because you enjoyed it. reply afavour 14 hours agoparentprevI feel the same way with phones. I pre-ordered a Nexus One the day it opened, installed a dozen custom ROMs, etc etc. Upgraded to a Nexus 4, 5. These days I use an iPhone. Don’t miss it, though I’m nostalgic for the excess free time! reply smoyer 14 hours agoparentprevI have one running in a virtual machine but on hardware that would natively support a Hackitosh which I use only for testing Mac distributions. It's too old to use now but when I built it you could buy Mac OS at Best Buy. reply johnwalkr 14 hours agoparentprevSame for me. I spent countless hours recompiling my kernel in slackware, configuring enlightenment window manager. These days I don't even change the desktop wallpaper. reply pram 11 hours agorootparentYeah I spent literally dozens of hours of my life compiling different kernels with OSS and ALSA variations to get my sound card working lol. Really a 'you had to be there' thing. reply TylerE 12 hours agoparentprevI had a similar revelation a few years ago. My giant PC gaming rig blew up again (specifically my 3080 shit itself), a year after having to replace the power supply and requiring the whole thing. I was just done with faffing around with that kind of thing. So I bought a (then fairly recently released) Mac Studio, just the plain jane base 32GB model, and couldn’t be happier. So nice to have something virtually silent and energy efficient, instead of jet turbine that drew about 300w at idle. I 100% do not want a laptop for my primary personal machine, but the big workstation towers are too much. The Studio is that wonderful Goldilocks zone - performant, bring-your-own input devices, but merely “a bit pricey” and not extravagantly so. reply lostlogin 4 hours agoparentprev> this kind of tinkering was fun and a good way to improve the machine I was using. You know you’re alive when you log into iCloud from a hackintosh and then Apple notices, you get the ‘unauthorised hardware’ message (I can’t remember the exact phrasing) and your various iCloud services begin to cease functioning. It’s not often your OS is exciting. reply ktosobcy 14 hours agoparentprevSame story but with custom Android ROMs reply accrual 14 hours agorootparentAgree. I used tweaked BlackBerry ROMs for a couple years before getting my first Android device, an HTC One M7 with Android 4.4 KitKat. Spent loads of time getting all the tools working to modify ROMs, bootloaders, recovery/TWRP, and squeeze every drop of performance out of that phone. Then went \"backwards\" to an iPhone 4S and have been rocking stock iPhones ever since. reply KeplerBoy 14 hours agorootparentprevthose were the days. Nowadays it alls feels same-ish and boring. Can't wait for a new kind of device where not everything has been figured out yet. reply accrual 14 hours agorootparentThe Steam Deck sort of occupies this space today. I'm not in the scene myself but I've read about users modding them, running unsupported OSs, liquid cooling them, etc. Seems like any sufficiently broad technology will garner a community of hackers and modders around it. reply ktosobcy 13 hours agorootparentThis! I'm not into modding but I got SD because of it's openness and all sorts of things I can make with it (also to support gaming on Linux and kudos do Valve for the work on pushing it ;) ) reply ktosobcy 13 hours agorootparentprevI played with jolla/sailfish for a while and the device was awesome but I couldn't get myself to like gesture/swipe navigation (I hate it on the current flock of iOS/Android with same passion)... For the device I'm pondering new OP which is more open than the rest but still, as you said - it's mostly the same OS and the changes are not that significant to spend all that time on flashing... reply dkjaudyeqooe 13 hours agoparentprevWith a little preparation setting up a Hackintosh is not much more difficult than setting up an actual Mac. What you're describing is a myth or just out of date. reply geon 11 hours agoparentprevI had the same experience with windows 98/2k and my franken pc of randomly upgraded parts. I used to have to reinstall win98 every other month or so because it was so unstable. I had the installer on a separate partition, so I could just wipe the system disk and have a clean install up in 12 minutes. reply enra 14 hours agoparentprevTo me it was having just one powerful upgradable desktop computer with Windows and MacOS. So I don't have to have devices on my desk. Now I have solved with PC desktop, MacBook Air, and Apple Display. PC also has usb-c display output so I can just switch which cable connects to the display. Downside is still that M1 is not as fast, especially something that is GPU intensive as the PC I have. reply roxil 11 hours agoparentprevI find these days the Steak Deck has become a great device for tinkering. I've seen people do some nice unexpected stuff with it, for example making an opening in the back to connect an dedicated GPU or using it to pilot drones in Ukraine. reply LegitShady 15 hours agoparentprevI don't understand. Do you imagine there isn't a young generation of time rich cash poor tinkerers now? Why would the idea of a hackintosh suddenly become obsolete because you can afford one now and don't have time? Nothing about your statement logically follows. reply peruvian 15 hours agorootparentHe’s just parroting a usual HN-ism of ignoring the topic and talking about themselves. I’ve seen the “I used to tinker but now I don’t” line a hundred times as well as the “this doesn’t apply to me so I don’t care - let me tell you how”. reply nullwarp 14 hours agorootparentIsn't that the truth. For a site with the word \"hacker\" in it there seem to be so few of them. I can't imagine letting all that curiosity die out of me like the parent comment implies. I don't have the amount of time I used to to do that stuff either but the curiosity of it has never died and if I had more time I'd still do it. If I ever lost that drive I think I'd rather be dead. reply bruce511 14 hours agorootparentThe funny thing about growing older is that we change, and the things that were once \"I'd rather be dead than not do this\" just naturally fade away, and other new exciting things take their place. I say thus not to dampen your enthusiasm, but rather to encourage you to enjoy it to the maximum while it lasts. Everything has a season and in that season it can seem terribly important. Perhaps an activity, or a favorite sports team, or a group of friends. Some of that remains forever, some of it gets deferred as other things happen. It's part of life, we grow, we change, the world around us changes. It's not that the drive is lost, it's just that it manifests in different ways, different activities, different challenges. When you see a post like yours in 30 years time, remember this moment, and raise a glass :) reply raydev 12 hours agorootparentprev> If I ever lost that drive I think I'd rather be dead. I wonder how many others had this exact same thought, before they lost their \"hacker\" drive while also preferring to continue living. This may shock you, but people's interests and desires can evolve over time, even when those people don't expect them to evolve. reply mturmon 13 hours agorootparentprevI’m going to gently pile on to the sibling comment here, and note that the “hacking” we find interesting should and does change over time. I used to spend time hacking PDP-11 assembly code to make games. That got old, and if I play a game now it’s purchased. The stuff I hack on now is more like applied math. This is all good and natural, if it’s organic and not growing it’s probably not alive. reply derefr 14 hours agorootparentprevIn what sense is this an \"HNism\"? Ever since blogs have had comments sections, the set of people who are too lazy to make their own blogs, have been holding forth (writing, essentially, their own blog posts) in other people's blogs' comment sections. Heck, I'm sure people were doing it on Usenet and all-subscribers-can-post mailing lists, too — using the \"Reply\" button on a message to mean \"I want to create a new top-level discussion that quotes/references this existing discussion\" rather than \"I want to post something that the people already participating in this existing discussion will understand as contributing to that discussion.\" In all these cases, the person doing this thinks that a comment/reply is better than a new top-level post, because the statement they're making requires context, and that context is only provided by reading the posts the statement is replying to / commenting on. Of course, this being the internet, there is a thing called a hyperlink that could be used to add context just as well... but what there is not, is any kind of established etiquette that encourages people to do that. (Remember at some point in elementary school, learning the etiquette around writing a letter? Why don't schools teach the equivalent for writing a blog post/comment? It'd be far more relevant these days...) Also, for some reason, social networks all have \"reply\" / \"quote\" actions (intended for engaging with the post/comment, and so showing up as \"reactions\" to the post/comment, or with your reply nested under the post/comment, etc); but no social network AFAIK has a \"go off on a tangent\" action (which would give you a message composer for a new top-level post, pre-filled with a cited quote of the post you were just looking at, but without your post being linked to that post on the response-tree level.) Instead, you always have to manually dig out the URL of the thing you want to cite, and manually cite it in your new post. I wonder why... reply canucker2016 14 hours agorootparent\"...but no social network AFAIK has a \"go off on a tangent\" action (which would give you a message composer for a new top-level post, pre-filled with a cited quote of the post you were just looking at, but without your post being linked to that post on the response-tree level.) ... \" On Usenet, if you were altering the general SUBJECT of a post, you'd reply to a comment BY PREPENDING the NEW TITLE/SUMMARY of your post to the PREVIOUS TITLE of the post to indicate that you HAD changed the GENERAL SUBJECT of the post to something else AND end your NEW TITLE with \"Was...\" to prefix the previous title, e.g. \"Hackintosh is Almost Dead\" => \"My Changing Hobby Habits Was: Hackintosh is Almost Dead\" reply bruce511 14 hours agorootparentprevOn the contrary, I was relating the article to my own experience. The thrust of the article was explaining the end of an age. I was merely saying that we shouldn't see this as bad, it is the natural way of things. Everything that has a beginning has an end. Raise a glass to remember hackintosh, but don't mourn it. reply pessimizer 13 hours agorootparentPeople are asking how the fact that you make more money now is evidence of that. That's your natural ending, but it's not evidence of a natural ending. reply Klonoar 14 hours agorootparentprevThey’re not that far off topic - the site would be far less interesting if we didn’t have tangential discussions in the comments. They are also, as you noted, expressing a very common opinion. Now I’m off to spend my Saturday not tinkering, because there’s a bigger world out there and I’ve done my time. reply Solvency 14 hours agorootparentprevHN community selects for these kinds of posts, in the same way that subreddits like /r/amitheasshole love overwrought girlfriend-is-evil stories. Most often the highest rated posts on HN are from 40+ year olds who don't discuss the post at hand, they'll post a hyper-specific nostalgic story from their youth on something that is tangentially related to the post. In fact, the older the better. If your childhood anecdote is from the 70s or 80s you're a god. reply shagie 14 hours agorootparentprevThere are other things that are more interesting to build and make now than a hackintosh (with the added difficulty that trying to make a silicon compatible device may not be feasible). Combine this with that a Mac mini that might be at the target for a hackintosh device is $600 USD ... and has the advantage that it isn't hacked together and so has better support. The part of me that wanted to tinker with a hackintosh in my younger days is more satisfied by Raspberry Pi and Arduino projects. I've even got an Onion IO over there that could use some love. Its not that people don't want to tinker, but rather the utility that one gets for hacking together a Mac (again, note the silicon transition) is less than one gets for hacking on single board computers. reply prmoustache 14 hours agorootparentprevI guess the commercial success of the platform has increased the offering in the second hand market. Also, the MacOs desktop has pretty much stagnated and is behind the competition. What is strong is the seamless integration of the whole Apple ecosystem so it makes sense to run MacOs if you already own iOS devices. I doubt people using iphones and ipads are struggling to finance the purchase of a mac. reply bruce511 14 hours agorootparentprevAs I said in my post, the next generation will find something new to tinker on. The idea of a hackintosh is obsolete because there are new worlds to conquer, the time of hackintoshes has come and gone. The new generation will find their own challenges, not re-hash challenges of the past. reply hk1337 13 hours agoparentprev> These days I want to -use- the computer, not spend time trying to convince it to work. I have said this same thing about Android vs iPhone. Also, if I cannot tinker with Android then I might as well have an iPhone. reply zerr 14 hours agoparentprevThere are new generations of cash poor tinkerers though, including the 3rd world. reply disiplus 14 hours agoparentprevfrom around 2008 to 2012 I ran hackintosh, on desktop, it was great and fun in 2012 I bought a first MacBook. The good experience on the hackintosh made me get the MacBook. So I like to think hackintosh helped apple. reply david38 13 hours agoparentprevI agree your first three paragraphs, but why won’t they want to continue to hack? It was my obsession with worthless endeavors that got me the kind of job that made my time valuable in the first place reply lannisterstark 10 hours agoparentprev>These days I want to -use- the computer, not spend time trying to convince it to work. This but with LLMs lol. reply technothrasher 15 hours agoparentprev> 35 years ago I was fixing something on my car most weekends. Now I just want to turn the key and go somewhere. See, that 35 years for me didn't make me stop working on my cars, it just allowed me to have enough money to have a reliable car as well as \"toy\" cars that I can still tinker with. I drive the Audi, but I still wrench on the Triumph. I used to tinker with Hackintosh stuff as well, and I haven't stopped tinkering, just moved on to other things, like this Rubidium frequency source I just bought to build a high accuracy NTP server from a Raspberry Pi. (Yes, of course, there are already cheap and easy solutions for this, but I want to tinker). reply forgotpwd16 14 hours agorootparentEither OP doesn't consider tinkering an enjoyable past-time activity or they've no free time to do something they enjoy. Both quite sad to be honest. reply afavour 14 hours agorootparentI wouldn’t go as far as “sad”. Free time is always a finite resource you have to prioritise. I used to tinker, these days I’d much rather spend time with my kids. I’m definitely not sad about it. I’ll have plenty of time for tinkering in the future. reply bruce511 14 hours agorootparentYes, time is limited, and these days I have new hobbies. For cars, and computers, it's a bit of been-there-done-that. reply Almondsetat 14 hours agorootparentprevCan people simply have priorities? reply forgotpwd16 13 hours agorootparentOf course. And people enjoy spending their free time on various things not necessarily due to some restriction. For those people time spend on those things isn't wasted. For example, can have fun fixing cars even if have money to have a mechanic do it. reply grishka 13 hours agoparentprevThere was a time when hackintosh was practical for everyone who needs macOS and/or can't stand other desktop OSes. It was the tail end of Apple's Intel hardware. It was pathetic in terms of performance (underpowered CPUs and buggy GPU drivers), quality (butterfly keyboards) and thermal design (things would overheat all the time), yet expensive. I myself was contemplating building a ridiculously overpowered hackintosh machine around 2019. Then the ARM transition was announced. And then the M1 came out with overwhelmingly good reviews from literally everyone. So I decided to wait for the beefed up \"professional\" version, which did come later, so here I am, typing this on an M1 Max MBP, the best computer I've owned so far. Also, for me personally, hackintosh was an introduction to macOS. I was a poor student at the time and couldn't afford a real Mac. Of course I bought one about as soon as I could. reply Unfrozen0688 13 hours agoparentprevYea but thats how you learn. These ipad kids dont know anything because it all works now for games and netflix. No need for drivers, windows installs etc reply carlosjobim 15 hours agoparentprevMacs are very expensive in some parts of the world, where other computer brands are affordable. A hackintosh could be a good option, and when somebody learns to do it well they could do it for others for money. Not only installing MacOS on PCs, but also installing newer versions of MacOS on Macs that are officially not supported anymore. reply sangnoir 14 hours agorootparent> A hackintosh could be a good option, and when somebody learns to do it well they could do it for others for money Apple thoroughly screwed over Mac developers that the only compelling software that's exclusive to MacOS is developed by Apple themselves[1], IMO. Even those packages have equivalent (or better) alternatives on Windows. Macs used to be the platform for DTP, audio and video production - now all the 3rd party developers have pivoted away to other operating systems. One of the reasons professionals resorted to Hackintoshes in the past was because Apple had periods of neglecting the Mac Pro hardware on and off. Why would anyone go through the paid of setting up a Hackintosh in 2024, outside of being a fan of MacOS aesthetics? 1. Logic Pro likely has the biggest pull; Final Cut isn't the halo app it once was. reply samatman 13 hours agorootparentMacs continue to absolutely dominate audio and video production, and desktop publishing. You're just making stuff up. reply pjmlp 11 minutes agorootparentOnly on the countries where Apple brand dominates, the remaining of the 80% desktop market share makes do with Windows and eventually some custom Linux distros supported by the hardware vendors themselves. VFX Reference platform includes Windows and Linux for a reason. https://vfxplatform.com/ reply sangnoir 11 hours agorootparentprevNice strawman! You completely demolished a market share argument I never made. My point is that audio and video professionals now have viable alternatives to Apple software. Running MacOS is now optional, which wasn't the case in the past, so there's less of an impetus for running MacOS on an non-Apple hardware. As for making stuff up - I don't know if you remember the years of neglecting Mac Pros, or the clusterfuck that was Final Cut Pro X. I do. I remember a lot of dyed-in-the-wool Apple users switching to Adobe on Windows. How many 3rd party DTP, audio or video production packages are still exclusively available on Apple? reply H1Supreme 13 hours agorootparentprevI'd run a Linux desktop if it wasn't for audio production. Mac's Core Audio / Core Midi are the top of the heap. reply carlosjobim 14 hours agorootparentprevI use many third-party apps on MacOS that are top of the line in their niche, regardless of OS. People have many different uses for computers and workflows that you are unfamiliar with. When you discover how programs on MacOS can connect and interact with each other and with the OS as a whole, it becomes a completely different experience. reply throwaway290 14 hours agoparentprevwent from hackingtosh to mac, never had enough to afford a car. (I think) reply matthewfcarlson 13 hours agoprevAs a long time lover of hackintoshes (couldn’t afford a real Mac as a youth but tried to make the netbook macOS dream come true), I’m quite sad to read this. The author has a very valid point that drivers are going to become increasingly complicated and difficult. I appreciate the call out that Apple (the engineering) isn’t explicitly trying to kill hackintoshes. As an Apple engineer who deals with ACPI bugs, hackintoshes are a unique source of frustration. I’ll spend hours digging through crash logs only for things to not add up. It says it is an i7 MacBook pro but it has way too many cores. It way more memory than it should. The kext versions are a weird mismash that shouldn’t be possible. The firmware is a version that we never released. Etc etc. I do my best to fix these sorts of issues but hackintoshes make it hard to reproduce the crash conditions. Which means being confident about a root cause and hard to verify that I’ve fixed it. Now I’ve spent hours chasing something and I can’t help. (Opinions are my own, etc etc). reply yardie 11 hours agoparentSorry, that must have been me. LOL. I had a Hackintosh and felt that any crash was 99% my fault and probably an edge case for MacOS. But in my defense, CrashReporter is way too permissive and will send a report even when the user doesn't want it done. After a app or hard crash I'll get the window that a bug report was sent and I know damn well some engineer is going to look at it and it won't make any sense that a MacBook has this particular GPU. reply dkjaudyeqooe 13 hours agoparentprevI've been using a Hackintosh as my daily driver for nearly 15 years and they have always been rock solid, with months of uptime consistently. It's just a matter of starting with the right hardware. People are free to look to support the hardware they have but 've always though it's stupid not buying well supported hardware in the first place, of which there is plenty. reply philistine 9 hours agorootparentWhat are you going to do once Intel is no longer supported ? reply dkjaudyeqooe 7 hours agorootparentNothing, I'll just stick the last usable version, just like I'm stubbornly sticking to 10.14.6. I'll fight moving up each and every version by narrowing the software I use. Already happening and it's fine. reply Teever 7 hours agorootparentHow long do you",
    "originSummary": [
      "The Hackintosh scene is dwindling due to Apple discontinuing driver support for older WiFi/Bt cards, as explained in the article.",
      "The author shares their struggles and instabilities encountered while constructing and upkeeping Hackintosh systems, leading to the conclusion of its decreasing viability.",
      "Despite the difficulties, the article mentions the positive elements of the Hackintosh journey and hints at potential alternatives like newer Apple devices."
    ],
    "commentSummary": [
      "The article and discussions emphasize the waning interest in Hackintosh due to users having limited time for technology tinkering.",
      "There is a debate between open-source software and proprietary technologies, with users expressing frustration towards the latter.",
      "The conversations explore the advantages and difficulties of experimenting with various operating systems like Linux and Windows, reflecting a shift in interests and priorities with age, emphasizing the importance of personal preferences and objectives in choosing an operating system."
    ],
    "points": 432,
    "commentCount": 441,
    "retryCount": 0,
    "time": 1710612977
  },
  {
    "id": 39725303,
    "title": "Cloudflare Suffers 22% Domain Loss in Freenom .tk Shutdown",
    "originLink": "https://www.netcraft.com/blog/cloudflare-loses-22-of-its-domains-in-freenom-tk-shutdown/",
    "originBody": "March 15, 2024 Paul Mutton Cloudflare loses 22% of its domains in Freenom .tk shutdown A staggering 12.6 million domains on TLDs controlled by Freenom (.tk, .cf and .gq) have been shut down and no longer resolve, leading to a significant reduction in the number of websites hosted by Cloudflare. The disappearance of these websites was spotted during our monthly Web Server Survey and represents a 98.7% drop from the number of Freenom domains that were resolvable last month. Nearly all .tk, .cf and .gq domains have effectively disappeared. The .tk, .cf and .gq TLDs are country code top-level domains (ccTLDs) for Tokelau, Central African Republic, and Equatorial Guinea. They were officially intended to be used by entities connected with these countries, but this was very rarely the case. The huge drop is likely the culmination of a series of events that started last year, when Freenom was sued by Meta for ignoring abuse complaints. Freenom subsequently paused new domain registrations in March 2023, and Netcraft noticed a dramatic reduction in the amount of cybercrime across two TLDs that later moved away from the provider (.ga and .ml). Finally, on 12 February 2024, Freenom announced that it had decided to exit the domain name business, including the operation of registries. The same press release (which has since been removed but is archived here) also announced that Freenom had resolved the Meta lawsuit on confidential monetary and business terms. Cloudflare losses The affected domains represent a big loss for Cloudflare, with .tk, .cf and .gq previously accounting for 23.1% of all domains hosted on its platform – and nearly all of these have now gone. The combined amount of .tk, .cf and .gq domains hosted by Cloudflare has fallen by 99.8% since our March 2024 Web Server Survey, leading to a noticeable 22.0% drop in the total number of all domains hosted by Cloudflare. All domains hosted by Cloudflare. (Note sites like foo.example.tk and bar.example.tk would be counted as a single domain) The .tk top level domain was the most popular of those operated by Freenom. Last month it accounted for 16.2% of all domains hosted by Cloudflare, but very few of these were used by popular websites. Amongst Netcraft’s top million websites dataset, there were only 59 sites across 57 .tk domains. 36 of these still resolve, which suggests they are paid-for domains. But to the vast majority who registered these domain names for free, their sudden disappearance came as a bit of a surprise. Amongst the debate in the Cloudflare and Reddit communities, some customers reported being able to get their domain names back up and running by having their domains marked as “paid domains”. The Freenom website claims new registrations are temporarily out-of-order due to “technical issues”. When did the shutdown happen? The number of SSL certificates successfully issued to .tk domains provides a good indication of when the shutdown took effect, particularly as the two largest certificate authorities – Google and Let’s Encrypt – only issue domain validated certificates. The issuance and renewal process for a domain validated certificate involves sending an HTTP request to the website it will be issued for, and so each subject domain must be resolvable for the process to succeed. Certificates issued to .tk domains (hourly). This graph shows the shutdown taking noticeable effect between 8 – 10 February 2024, crucially a few days before Freenom issued the 12 February press statement where it announced its exit from the domain name business. This lack of notice clearly caught lots of people by surprise. The small trickle of issuances thereafter represents the small number of .tk domains that are still active, including those marked as “paid domains”. The free and easily acquired domain names that Freenom used to provide were unsurprisingly attractive to criminals and were used to host many phishing sites, malware, and other types of cyberattacks. Consequently, one positive side effect of the shutdown is that the number of malicious URLs that we block on the affected TLDs has fallen by 86.9% since December 2023. You can read more about the impacts on cybercrime in the aftermath of Freenom’s original announcement on the Netcraft Blog.",
    "commentLink": "https://news.ycombinator.com/item?id=39725303",
    "commentBody": "Cloudflare loses 22% of its domains in Freenom .tk shutdown (netcraft.com)292 points by speckx 21 hours agohidepastfavorite205 comments thangngoc89 20 hours agoUnrelated to the article but seeing .tk brings back many memories. As a kid without a bank account let's alone an international credit card (VISA/Mastercard), dot.tk is the only way to put a website online with your name. I created countless of websites with .tk for classmates, school and families. reply 101008 20 hours agoparentSame here. .tk was the only one back then that allowed you to have your own domain name without subdomains. My memory is that: 1. freeserver.com/~userna kid >2017 fucking hell reply umbra07 13 hours agorootparentI know right! I feel so young. there are people on this site that were born in the previous millennium! :O reply fragmede 12 hours agorootparentoof. We didn't even have the Internet, nevermind Google. Kids these days will never even know what it was like pre ChatGPT. programming and even just computers alone was hard back in the day. reply mindslight 9 hours agorootparentHard?! You'd generally have one or two medium size books that documented the whole environment including corner cases, very few or no third party libraries, no frameworks, no autoupdates, just programmers living their best lives. If anything ChatGPT is filling the hole created by poorly documented \"open source\" churn. reply fragmede 7 hours agorootparentfrom my perspective, I can just ask ChatGPT to give me code to whatever and it gives it to me. way easier than figuring it out for myself. hell, with openinterpreter, I can just tell my computer to fix my python shit for me. sure, there weren't me frameworks every week, so knowing C++ and MFC was a sure thing, but it's so much easier today. python points at the character of the exact line of code that's throwing the error. no more spending hours of your life to find a missing semicolon, unless you try using rust (seriously, the difference between OK() and OK(); is material? I mean I understand it now after the fact but ungh). you can't grep paper books, at best you can look things up in the index. even without ChatGPT I can ask Google and get stack overflow and just copy and paste without having to think deeply within minutes. if I'm just trying to get something out there, why do it the hard way? there's still need for the hard way (eg, I'm currently fighting Ida pro for a thing), but there's just less of a call for that. reply brnt 9 hours agorootparentprevPeople born after 1990 aren't real. reply Tijdreiziger 12 hours agorootparentprevHow do you do, fellow kids? (reference: https://cdn.vox-cdn.com/thumbor/mO8UICqmeSd97l09w_FgSP1TDPQ=...) reply thangngoc89 18 hours agorootparentprevI remember there was scripts that remove the ads .tk injected reply lnxg33k1 19 hours agoparentprevIn italy we had 3000.it https://web.archive.org/web/20010331143129/http://www.kliman... SPOILER: I didn’t become a webdesigner reply rightbyte 17 hours agorootparent\"Copyright © by klimato ® All Right Reserved\" Heh. I remember thinking '©' and '®' being cool letters. I put it on every page since it looked pro. I guess you didn't actually register the \"brand\"? reply lnxg33k1 15 hours agorootparentNaaah i changed dozens of nicknames since then :D reply UnlockedSecrets 17 hours agorootparentprevBut did you become a webmaster? reply lnxg33k1 15 hours agorootparentYep webhighmaster :D im a software developer now reply zer00eyz 15 hours agorootparentLOL! On a good day sure, most days I would settle on me being a house elf, or dozer... reply lnxg33k1 14 hours agorootparentDobby! :D reply xyst 15 hours agoparentprevsame - I remember hosting a small web server from a crappy pc at my parents house and using a .tk to serve the site. Probably not the smartest thing to do at the time since I may have opened up all ports on the router to get it to work, lol. No https. No security. No moderation. Copy and pasted some html from a site that I thought was cool, search and replaced text to make it my own. It was kind of like a microblog before twitter, fb, ig, blogspot, tumblr. reply xeromal 18 hours agoparentprevI remember in the early 90s telling Mom that I built my own website. Mom was like noway that's impossible. I can't remember exactly where it was but it was like zoogatyler1.go.com or something. I think it was owned by Disney? I must have been around 7 or 8 but I remember being so excited. I think it was more of a homepage than anything. I started delving into those .tk sites when I was around 11 or 12 probably. reply stef25 12 hours agorootparentI launched one on a compuserve domain (I think) around the same time. Built it with FrontPage Express that came for free on a cd with a magazine my dad bought. Day after I launched it I had like 20 emails from random people with questions & comments about the site, crazy. Build it and they will come was def a thing. Later on in the UK I put a site on a madasafish domain. reply dpacmittal 51 minutes agoparentprevDid you also use 000webhost.com with .tk domains like me? reply captn3m0 20 hours agoparentprevI used .co.nr alongside .tk for a while, before moving to .co.cc, and then finally managing a way to buy my domain. reply jszymborski 19 hours agorootparentI definitely had a .co.nr domain before a .tk. I think I also remember (I was likely 13, so its been a while) that they had an \"English\" test question on the sign up form that read something like \"A Britney Spears is a:\" and one of the options was \"Hamburger\". Looking back this could have been to slow robots down, but I distinctly remember one if the terms being you speak and host English content. Another service I used a lot was \" dominosfree\" which had a bunch of .gs domains that looked like CC-tlds. I used .ca.gs a lot. reply creatonez 12 hours agorootparentprev.co.nr was strange because it put your page inside of an iframe and required advertisement of the service. reply captn3m0 3 hours agorootparentYeah, the cloaking was annoying - navigation across pages wouldn’t update the URL. reply tamimio 18 hours agorootparentprevAh, co.cc, the tld that was full of php reverse shells! reply giancarlostoro 19 hours agorootparentprevI think I had co.nr too! I just dont remember if it was like .tk or if it was one of those webhosts. reply syuil 19 hours agoparentprevOh man, this brings back memories from high school! .tk was a blessing for us. reply DaSHacka 1 hour agorootparentSame here! I remember registering a .tk domain for a school project I was working on at the time, my friends were all so impressed when I showed them it was available as a website they could visit in their browser reply wnevets 16 hours agoparentprevI remember switching to cjb.net because you could get free wildcard email accounts for your domain. reply a1o 16 hours agorootparentNow that is a name I haven't heard in a long time. I had a Dragon Ball Z website using that domain, feels so long ago. reply p3rls 16 hours agorootparentprevIt's interesting seeing it parallels the problems with .tks today-- I remember using cjb.net to make my own LOVE@AOL websites and phish AOL users telling them that a crush liked their account. Easiest money a 12 year old ever made. reply miki123211 7 hours agoparentprevWhat are kids using these days? Serious question, Heroku and .tk were such amazing services if you weren't old enough to get a credit card. reply atum47 18 hours agoparentprevI used to host my websites wherever and then having a redirect to it. Two I remember was pagina.de/dr.enima (roughly translates to site of dr.enigma, my nickname back then) and i.am/supermatrix - a website dedicated to the movie the matrix which I love. I think both of those pages were hosted in geocities and had pretty long urls... reply atum47 18 hours agorootparentIf i recall correctly, i use frames with size 0 on the top and 100% on the bottom, making that annoying banner invisible reply tamimio 18 hours agoparentprevI remember flexing on my friends that the google site I had got a proper name with .tk! reply accrual 14 hours agoparentprevMy favorite was .uni.cc, I had a couple of those free domains back in the day. reply cqqxo4zV46cp 18 hours agoparentprevGod. I’d forgotten all about .tk until reading this comment. What an amazing time. reply overstay8930 19 hours agoprevThe people complaining that Cloudflare hosts these criminals would be the first ones complaining that Cloudflare has too much power when taking down websites it doesn’t like. You can’t win with these people, I personally think this is the best outcome and shows our systems work (albeit slowly). Sure it took a while, but now there doesn’t have to be a precedent of Cloudflare acting as the internet police more than it has to. reply lolinder 19 hours agoparent> You can’t win with these people This is the classic fallacy of assuming that because you see comments of type A and comments of type B on the same forum that means they're the same people. They're usually not. A more accurate way to phrase this is \"you can't win with ... people\". Whatever you do will end up ticking off some subset of the population. reply philsnow 8 hours agorootparentThere’s a similar problem I encounter from time to time: when I self-identify as “conservative” and express opinion C, many people assume I also hold opinions D, E, and F, because “that’s how all conservatives are”. There are multitudes in every group. reply mypastself 18 hours agorootparentprev“These people” is presumably a set of people quick to find fault in anything a corporation does, which could be a superset of those two groups. Not sure what kind of fallacy that’s supposed to be. reply mathgradthrow 17 hours agorootparentYour evidence for the non-emptiness of this set of people is the fallacy above reply __s 17 hours agorootparentprevintersection, not superset reply kortilla 18 hours agorootparentprevThose people are in the noise and nobody cares what they think once they realize they just criticize for the sake of it. That doesn’t change that people seem to think the top upvoted comments being contradictory from day to day represents some kind of inconsistency in the views of the commenters on this site. reply 0x0000000 17 hours agoparentprev> The people complaining that Cloudflare hosts these criminals would be the first ones complaining that Cloudflare has too much power when taking down websites it doesn’t like. It'd be interesting if you could point to a single example of someone taking both sides. I strongly doubt these are the same people. reply overstay8930 14 hours agorootparentIf you're asking me to personally identify someone, no I'm not going to do that. However if you want to see some hilarious hypocrisy, go ahead and see who said what when Cloudflare banned 8chan. reply mardifoufs 8 hours agoparentprevWell CloudFlare already does exactly that. It already set the precedent you are referring to. That's why it feels odd that they don't shut down literal criminals too. They have no issues with shutting down stuff, but they are famously very lax when it comes to actual criminal stuff. I'm not trying to say that they were wrong or right for engaging in content policing, what I'm saying is that the precedent isn't new. reply ogurechny 9 hours agoparentprevThere is no contraposition. In both cases, big company simply does something it wants. This comparison actually highlights that there is no “system”, because some (imaginary) impersonal entity decides that those bad actors are allowed, and those bad actors are not allowed. Some public sensibilities are given as a reason, but no one is actually asking anyone's opinion on anything. Still, there are people who believe that Santa Claus brings presents for free, and that the whole thing is not governed by typical hypocrisy and typical politics behind closed doors. The thing is, you've built a turnpike, you can now bargain with people interested in sharing control over that turnpike. reply explain 19 hours agoparentprevNot the same people at all. reply akira2501 14 hours agoparentprev> You can’t win with these people People who want to live in a just world often get in the way of things. I'm just not sure why you're mad at those who want justice and not those who put profits above all else? > that Cloudflare hosts these criminals Oh.. it's not that they host them, it's that they go out of their way to protect them, and the profit streams associated with them. reply lxgr 18 hours agoparentprevWhat criminals are you referring to? The operators of .tk, or their users? reply mobilemidget 17 hours agorootparentThere are tons of shady websites hiding behind cloudflare's services. Some used .tk domains too but just in general, many shady websites are hiding behind Cloudflare and at least I know from personal experience if you contact cloud flare about it, they pretend not to be home. \"We do not host the website\" was always there response, while that is perhaps technically true, arguing if they shut down the reverse proxying for that website it would be at least offline, never worked. reply lxgr 16 hours agorootparentCloudflare is a US company. If they provide hosting (or reverse proxying; I don't think there's a material legal difference) services for anything illegal under US law, shouldn't it be possible to compel them to stop doing that through the legal system? And if this is about not-illegal-but-objectionable content, I'm actually glad that as an infrastructure company, they're choosing to not get into the business of content moderation. reply internetter 14 hours agorootparent> if this is about not-illegal-but-objectionable content, I'm actually glad that as an infrastructure company, they're choosing to not get into the business of content moderation. Agreed. There's one other subset you didn't mention: \"Clearly illegal but not yet handled in the court of law\". Cloudflare again has a pretty hardline stance that \"the courts need to come to us and force us to take it down\" reply caskstrength 12 hours agorootparent> Cloudflare again has a pretty hardline stance that \"the courts need to come to us and force us to take it down\" \"Hardline\"? To me it seems like quite reasonable approach as opposed to \"we will just take down anything someone on Twitter didn't like\". reply newaccount74 11 hours agorootparentIt's not reasonable. 99% of scams, frauds and harassment will never be subject of legal action, because there just aren't enough prosecutors out there to charge every fraud attempt. If you require a court ruling before blocking a fraud, it means you will keep hosting 99% of frauds. reply lxgr 14 hours agorootparentprevIf it's clearly illegal, what prevents it from being handled in any court of law? If it's not actually as clear, preemptive/overzealous compliance can lead to all kinds of undesirable (in a liberal democracy) effects. I also doubt that Cloudflare lets every single analogous issue bubble up to a full court case every single time, but for new/unclear/borderline scenarios, I'm glad that courts don't get to outsource their duty, i.e. determining the legality of actions, to a for-profit organization without public oversight. reply diggan 14 hours agorootparentprev> Clearly illegal but not yet handled in the court of law Isn't that somewhat of an oxymoron? What are some examples of something that is against the law but not handled by the courts of law? reply internetter 8 hours agorootparentI mean not handled yet. Like say I'm hosting pirated content. Yes it's illegal, but it's not Cloudflare's place to say that. reply dingnuts 13 hours agorootparentprevMaybe that commentator lives in a country without common law, so precedent doesn't matter, but in a country like the US a law without precedent is considered \"untried\" and a lot of the details are worked out when the law is first enforced. If the legislature doesn't like the court's interpretation, they can then amend the law and the process restarts. So basically, at least in the US, nothing is clearly illegal until it is handled by a court -- so yes I think you're right reply costco 13 hours agorootparentprevThey can. You can also subpoena them for information on an account, there are literally lawyers with blogs talking about how to do this. The people complaining essentially think that they should have the right to take anything they want down with an abuse report. reply stef25 12 hours agorootparentprevA while back there was an interview with someone at Cloudflare and they were asked what about these Al Qaeda sites you guys are in front of, dude just answered \"no comment\". Seems that at the time they didn't ask many questions at all, like you said cause they don't want to go in to content moderation. reply AlienRobot 18 hours agoparentprevThis seems like such a weird problem to me. If they're criminals, just send the cops? If you can't send the cops, then they aren't criminals? How do you end up in this limbo where you need critical infrastructure to play judge? reply lolinder 18 hours agorootparentThe internet is a global system that spans ~all jurisdictions, and most internet criminals live in jurisdictions that don't prosecute internet crimes as long as the bad actors leave citizens of their own country alone. So they're criminals as far as the US and allies are concerned, but de facto not criminals where they live. If they're going to be locked out of the system, it has to be by the infrastructure, because their government has no interest in stopping them. reply AlienRobot 18 hours agorootparentI see. Perhaps there should be a legal framework to get the government to demand companies like cloudflare stop serving these international criminals, then. That way it wouldn't depend on a private entity making the judgement. Do you ever think it's weird that we have gone through web 1.0, web 2.0, semantic web, intertubes clogged with spam bots, web 3.0: crypto edition, and the dawn of AI scraping, and we still haven't figured out these issues? reply Caligatio 17 hours agorootparentWhich government do you mean when you say \"the government\"? Any national government? Only the US government? Only governments in which the US is friendly and/or has agreements with? Would you want authoritarian governments to be able to demand Cloudflare stop serving those they consider criminals that are outside their borders? International law is messy. reply toast0 16 hours agorootparentThe rule of thumb is governments where Cloudflare has equipment, personel, or banking. There is a procedure to get a foreign case recognized in the US, too, but it has to be serious, and it's not an easy process. reply Caligatio 14 hours agorootparentCloudFlare has equipment in 120+ countries, including China: https://www.cloudflare.com/network/ I again ask: is it desirable for any of those countries to be able to unilaterally force a company to enforce its laws regardless of where the individual in question is? reply toast0 13 hours agorootparentIf the equipment is in country X, it seems reasonable to enforce the rules of country X. Plenty of companies refuse to operate in specific countries, including China, because they don't want to follow rules of that country. If CloudFlare chooses to do business in China, that's a choice they're making and it comes with consequences. Maybe they can offer service where customers will only be served from equipment outside of China, maybe that's not something they choose. reply immibis 14 hours agorootparentprevFor starters, Cloudflare is a USA company so it has to do whatever the USA government tells it. See National Security Letters. They can easily order it to reveal the origin server of a website, or the sign-up IP address of the account, or to stop providing services to one. reply stef25 12 hours agorootparentprevWho you going to send to an online pharmacy hosted say in Egypt? reply caskstrength 12 hours agorootparentWhy do you need to take down Egyptian pharmacy in the first place? reply iopq 11 hours agorootparentBecause they send controlled substances to the US and falsely label them as \"supplements\" I know, because I bought RX stuff from India and it did not get labelled as medication reply caskstrength 2 hours agorootparentSomeone bought roids from India and didn't get busted by DEA in the process?! The horror! reply hnbad 14 hours agorootparentprevAre you American? Because that sounds like such an American idea of how the world works. To answer your question: most malware actors can be traced back to Russia, what exactly do you think \"sending the cops\" after them will accomplish and if the answer is \"nothing\", then does that mean you don't think they can be called criminals? reply AlienRobot 14 hours agorootparentIt doesn't need to be physical cops. What I mean is that if crimes are being committed, the legal system should initiate a process that either puts them in jail (which as you say may not be possible) or ends up with cloudflare banning and other internet companies blacklisting them. That way, the burden of judging criminality isn't on random companies but on the appropriate authorities. reply wlonkly 6 hours agorootparentLegal systems. And getting the Russian and American legal systems to cooperate is about as hard as getting Russia and America to cooperate. reply newaccount74 17 hours agorootparentprevCloudflare shields criminals from cops. They do so because of \"free speech\" or whatever. There was recently a story about a swatting victim, who tried to get the forum the swatters use to shut down. Cloud flare refused to give the identity of the criminals, the case even went to court and the victim lost and now apparently has to pay court costs. Our legal system is unfortunately not perfect, which is why it matters what infrastructure providers do. Do they enable criminals by shielding them from the police? Or do they have policies in place that prevent abuse of their service? With Cloudflare, I'm pretty sure they lean towards the former. reply ehutch79 16 hours agorootparentI'm reasonably sure cloudflare would comply with any subpoenas / warrants sent their way. reply derefr 14 hours agorootparentWhich is a catch-22, because subpoenas / warrants for collection of digital information have to name a specific intended target (a real legal identity under suspicion, not some pseudonym) — and \"the real legal identity of the suspect\" is exactly the thing that Cloudflare's proxy-shielding prevents you from learning. Courts won't act until they have some specific individual to act toward. (This is also why, whenever you hear about e.g. police stings on Tor forums, they never mention requesting courts to issue warrants to ISPs for collection of e.g. traffic-analysis-correlation info about locations of servers hosting illegal content. Instead, this de-anonymization step is something they always have to achieve extra-judicially, usually by contracting a private network threat intelligence firm.) reply struant 10 hours agorootparentOr you don't hear about the methods they are using for deanonymizing because they would get the cases thrown out of a court. Warrantless wiretapping and the like... And the private firm is just lying for them so law enforcement can do parallel construction. reply mcfedr 15 hours agorootparentprevObviously with no context but what I hear Is the website illegal? Or maybe the police need to deal with spam calls more sensibly. Presumably they can trace where the calls are coming from in real life reply internetter 14 hours agorootparentprevwait, are you mad cloudflare decided not to be an active participant in a doxxing campaign? Swatting is awful but I'm inclined to side with cloudflare here. reply newaccount74 11 hours agorootparentI'm mad that they offer anonymity to criminals. If you offer a service that lets people hide their identity, you ought to perform a bit of due diligence. reply jacurtis 13 hours agoprevI'm sure CloudFlare is just reeling from this \"loss\" of 12.3 Million unpaid customers. I hope the CEO doesn't drink too much tequila tonight during the celebrations reply chomp 20 hours agoprevThank god, .tk caused so many headaches for us, truly a cesspit of a tld. The rate of fraud and abuse on our platform was staggeringly high from it, it was close 99%. reply eszed 20 hours agoparentIt would follow that Cloudflare is tacitly admitting they have been / are hosting a large number of domains used for fraud and abuse. That surprises me, given the time and effort they spend mitigating fraud and abuse. Anyone care to explain what I'm missing? reply KomoD 19 hours agorootparent> That surprises me, given the time and effort they spend mitigating fraud and abuse What time? What mitigations? Cloudflare will proxy anything and then tell you \"we're just a proxy, so we wont do anything lol\" when you report anything other than cf pages. Doesn't matter if it's terror groups, animal torture, piracy, doxing, far right groups, etc. I have personally submitted abuse reports and seen that absolutely nothing happens. Oh and also the amount of abuse I see from people using Cloudflare Warp is also very high. reply derefr 14 hours agorootparentDepends on what you're trying to achieve, I think. Cloudflare's policy is that if there's ToU-violating content being served through a Cloudflare-proxied domain, you can report it to request de-anonymization of the domain, so that you can then reach out to the actual host. I've reported Cloudflare-proxied phishing-site clones of my company's website to Cloudflare, and they've usually come back to me with a pointer to the upstream-origin's ASN/ISP to reach out to within a few hours. reply lxgr 18 hours agorootparentprev> the amount of abuse I see from people using Cloudflare Warp is also very high. More so than from \"traditional\" VPNs (i.e. the ones claiming to keep \"no logs and never selling your data\")? That's quite surprising, since Cloudflare makes no such promises and markets Warp as a security/performance improvement tool, not an anonymity-providing one. I think at least for a while, Cloudflare-hosted sites would even bypass it entirely and they'd get the real underlying client IP. reply KomoD 17 hours agorootparent> More so than from \"traditional\" VPNs (i.e. the ones claiming to keep \"no logs and never selling your data\")? Yes, because it is a free service, an easy and free way to just hide your ip address. You don't even need an account. > I think at least for a while, Cloudflare-hosted sites would even bypass it entirely and they'd get the real underlying client IP. Correct, this used to be the case, but no longer is as far as I can tell. But even with that, it was an issue for non-Cloudflare websites and services that are being attacked that aren't HTTP(S) (e.g. SSH) reply lxgr 14 hours agorootparentAh, I haven't been following it closely. Thank you! Just found a blog post on that architectural change: https://blog.cloudflare.com/geoexit-improving-warp-user-expe... Are they responsive at all to abuse notifications about their VPN users? Presumably the only thing they could even do is to block an upstream IP address, given that it doesn't require an account. reply gadders 19 hours agorootparentprevThey've definitely refused to help far right sites and sites like Kiwi Farms. reply KomoD 19 hours agorootparentYeah, because of the pressure after it all blew up. They even said in their own blog post that it was an \"extraordinary\" decision and did not believe terminating them was appropriate. Kiwi Farms used their services for at least 6 years before anything happened. reply chx 19 hours agorootparentAnd all that pressure was for naught because it's still available right on the clearweb :'( reply immibis 14 hours agorootparentIs it? Currently giving 502 Bad Gateway. Seems like they're having hosting troubles. reply KomoD 14 hours agorootparentYes, outage right now. reply Zpalmtree 9 hours agorootparentprevit wasn't. reply eszed 19 hours agorootparentprevI was thinking particularly about the DDoS protections they advertise (and explain in lovely technical posts on this site). So you're saying that they protect their network from others, whilst disregarding harms their clients cause to others. That was something I was missing, so I thank you. reply michaelt 19 hours agorootparentBefore cloudflare, it was difficult to run a DDoS-for-hire service because competing services would all DDoS each others' websites. Back when CDNs were all \"call for pricing\" affairs. Cloudflare had the insight that the more DDoS-for-hire services there were out there, the greater the demand for their services. Offering free DDoS protection to DDoS-for-hire services helps keep customers coming back for more. reply derefr 14 hours agorootparent> Before cloudflare, it was difficult to run a DDoS-for-hire service because competing services would all DDoS each others' websites. I mean, you don't need websites to advertise. Most DDoS-for-hire services back before 2009 advertised on IRC, NNTP, via ads in .NFO files found in warez releases found on Kazaa and BitTorrent, and so forth. (Some of the very tech-headed ones ones had Freenet sites.) reply Alifatisk 19 hours agorootparentprevShouldn't be a surprise, there is a tight relationship between Cloudflare and the booter community. I remember every booter site or similar was always behind Cloudflare, I think it was a common practice because it didn't seem like Cloudflare cared about these abusive sites. reply Retr0id 18 hours agorootparentprevCloudflare's business model is largely reliant on the internet being filled with abuse. reply saghm 16 hours agorootparentprevIt seems at least plausible to me that either there would be even more fraud and abuse than there already is without the time and effort to mitigate it, or that maybe their mitigation is not as effective as they'd like. This isn't meant to contradict the other theories being posted here; I don't really have any experience specific to this area, so it's possible I'm just being naive. reply Tijdreiziger 12 hours agorootparentYeah, I find this whole thread a bit odd. Cloudflare has been a highly regarded service for years, and suddenly people are blaming them of running a protection racket, without providing a single source or piece of evidence (or a presumably more ethical alternative, for that matter)? As they say, extraordinary claims require extraordinary evidence… reply LinuxBender 9 hours agorootparentprevI believe their primary focus is protecting the customers / proxied web servers, not the clients of said site. I suspect if one day the free accounts on CF went away there again we would lose a lot of scam sites assuming they don't accept Monero or similar and like .tk we would also lose some cool sites. reply jlarocco 16 hours agorootparentprevI've heard people bring up that problem before. On one hand they protect sites from DDOS attacks and bad actors, but on the other hand they help keep the bad actors online. If there's no abuse, nobody will pay their protection money. reply beanjuiceII 18 hours agorootparentprevsell the problem and the solution, good business reply refulgentis 10 hours agorootparentprevCloudflare's market play has consistently reminded me of Facebook to Google's from the perspective of Googlers I know who moved to Facebook in early 2010s. Let's do Akamai, but cheaper. Trying to stop everything bad is impossible anyway. reply johnklos 17 hours agorootparentprevIf you try to find evidence that Cloudflare mitigates fraud and abuse, you'll mostly find anecdotal evidence (sites that have been attacked and moved to Cloudflare, mostly) plus information and claims provided by Cloudflare, which is unverifiable. The problem is that nobody protects us, the Internet, from Cloudflare. Cloudflare will happily take money from and host (yes, host - they host, in spite of their rather stupid and completely disingenuous assertions that they don't) spammers and scammers. They do all the time, and they have no intention of changing that any time soon. If you forward phishing spam to abuse@cloudflare.com, guess what? Nothing happens. You get an automated response, but they do nothing about it. They expect you to visit a web page that has all sorts of intentional problems (intentional because they've been pointed out to Cloudflare and Cloudflare hasn't addressed them for years) that make the process arduous and time consuming. For one, they don't have \"spam\" as an abuse type. For another, even though they now literally host web content, and even though they're a domain registrar, if you don't paste in a URL pointing to a site hosted by their proxying product, then you can't submit your form. This means there's literally no way to complain to Cloudflare about domains for which Cloudflare is in WHOIS and SOA records, and for whom Cloudflare hosts DNS. The fields are limited to some particular size (2,000 characters? I forget exactly), and have issues where if you paste more than a certain amount of content but less than the hard limit, you can't submit the form. If you try to use the form more than once a minute or two, IT'S RATE LIMITED and you can't submit the form. Imagine that - they need to protect themselves from human-speed abuse reporting. In other words, it's REALLY hard to use their site to report abuse to them, and they know this, and it's intentional, unless we want to believe that they just suck at understanding how to make a web page that works. If they get enough complaints about a given phishing domain, they eventually take action, but it'd be after several days, which is more than the lifetime of a typical phishing campaign. In essence Cloudflare is one of the most popular phishing and spam-promoted hosting platforms because of Cloudflare's intentional foot dragging and claims to want to \"protect free speech\". They got on my shit list years ago when they told me - not kidding - that they couldn't just take down a Bank of America phishing site when it was pointed out to them because of \"free speech\". In other words, they don't want to set a precedent where they can apply the tiniest modicum of common sense and take down phishing sites which any reasonable human on the planet can unambiguously recognize as fraud. Bottom line: Cloudflare tells the world that there's SO much bad stuff out there, and you'll get in trouble if you don't use their products, and that's mostly true if you want to run phishing and spam-promoted web sites, so scammers and spammers use Cloudflare and are protected from those of us who would report those spammers and scammers. For all the companies and individuals who use Cloudflare, many are fooled in to thinking they need Cloudflare when they don't and are just making their sites problematic for much of the non-western world while helping a wanna-be monopoly re-centralize the Internet around a for-profit company that has a history of profiting from scammers and spammers. If anyone thinks Cloudflare legitimately protects the Internet by mitigating fraud and abuse, I'd be very interested to see evidence that doesn't come from Cloudflare that shows this. reply RyeCombinator 16 hours agorootparentWhat are some other viable options? reply johnklos 12 hours agorootparent1) not using DoS / DDoS protection, or using any number of hosting services that have this built in, or using a service that doesn't marginalize large parts of the world in the name of \"security\". DoS / DDoS attacks are not as common as Cloudflare would want you to believe. 2) use literally any other registrar / DNS service / hosting platform. You then won't need to worry about whether people all over the world will be getting CAPTCHAs on ever visit because of where they live or what browser they choose to use. reply Tijdreiziger 12 hours agorootparentThey don’t only offer DDoS protection, but also a WAF (Web Application Firewall), and if you run commodity software, attacks are very common. I know this because I manage a WordPress site fronted by a different WAF, and I can see in the logs that malicious bots are trying to pwn the site basically 24/7. (and before you say ‘patches’ – yes, but defense in depth is a thing, and you don’t always have the luxury of vendors with good security practices.) reply johnklos 11 hours agorootparentYes, Wordpress is attacked incessantly. It's designed to be actively hostile to security, so yes, a firewall that helps ameliorate is a good thing. However, if you really care about Wordpress security, a WAF is just covering things up, and yes, you need to patch (but that's not really the fix). The proper fix is to reconfigure things to not follow Wordpress' absolutely ridiculous security. While patching depends on vendors, securing Wordpress from its own hubris doesn't depend on vendors. But even where Cloudflare's products are arguably good, they still do too much in my opinion to marginalize non-mainstream visitors and to re-centralize the Internet around one big company. Every time they have issues, huge parts of the Internet are affected. If I wanted a WAF, I'd get it from elsewhere. reply Tijdreiziger 10 hours agorootparentWP core isn’t bad, the problem is when you’re the ops guy and you get handed an installation with 30 plugins. Anyway, WP was just an example. Are you 100% certain that all your software is 100% on the ball when it comes to modern security practices? We all know that not everyone takes security seriously. > Every time they have issues, huge parts of the Internet are affected. If I wanted a WAF, I'd get it from elsewhere. Which ‘elsewhere’ would you suggest? Every time AWS, Azure or GCP have issues, the internet is affected too. reply NicoJuicy 17 hours agorootparentprevThey don't host the domain. Hosting happens somewhere else. Which is where the crackdown should happen. reply creatonez 12 hours agoparentprevIf .tk was such a clear signal for abuse, isn't it a bad thing that signal no longer exists? I'd rather ICANN finally introduce .free, give a few years to alert everyone, and those developing spam filters can treat it how they want. reply refulgentis 10 hours agorootparent> If .tk was such a clear signal for abuse, isn't it a bad thing that signal no longer exists? No, this is (obviously) contrarianism for contrarianisms sake. It's good when entities facilitating crime stop facilitating it. No debate necessary. Additionally, it's completely unclear what you mean by your proposal. reply creatonez 9 hours agorootparentSpam and scams will happen no matter what. It will just be spread across the cheapest domain registrations that are still available now. The narrow and self-serving aspect that Facebook investigated, cybersquatting, should not justify killing off legitimate free domain registrations forever, at least in a better world where we more directly tackle these problems. reply refulgentis 9 hours agorootparentNobody cut off \"legitimate free domain registrations\" forever. Airquotes aren't sarcastic, just, idk exactly what that combination of words means so I want to leave myself an out. You are free to hand out domains for free to strangers, if you so desire. Nobody stopped anyone from anything. reply creatonez 4 hours agorootparent> You are free to hand out domains for free to strangers, if you so desire. > Nobody stopped anyone from anything. This is impossible, as we have just seen with the ICANN termination of Freenom. Turns out, the legal threats will kill it, even if other TLDs also have plenty of cybersquatting going on. There's realistically no way to repeat Freenom's success in giving out free domains without greatly heightened legal expenses now. It's gone, the fun is over. Likewise, because of this legal pressure they will likely never allow a .free proposal -- which is to assign .free to an organization wishing to provide free domain names and foot the bill themselves, essentially becoming the LetsEncrypt of domain name registrars. reply refulgentis 56 minutes agorootparentThe article claims Freenom shut down of its own free will. Are you reporting otherwise? reply creatonez 33 minutes agorootparent> Are you reporting otherwise? Essentially, yes. Freenom lost its registrar accreditation a few months ago, so all domain names will be forced by ICANN to go to another registrar. I'm assuming they saw no path towards getting it back, due to the difficult nature of complying with reporting correct registrant information for free users. https://domainnamewire.com/2023/11/10/icann-terminates-opent... They also just finished a $500 million settlement with Meta. reply moralestapia 9 hours agorootparentprevA TLD per se is not a facilitator for crime. reply refulgentis 7 hours agorootparentCorrect - and either a strawman or nonsequitor. Someone said \"Wow. It's bad they banned cars\" I said \"No they didn't. It's good that seedy car dealership, the one that couldn't stop selling armored cars to Al Capone's crew for years, gave up and shut down.\" You added \"Cars don't kill people. People kill people.\" reply TheAdamist 10 hours agoparentprevInteresting, .xyz was by far higher on my list of disreputable spam domains. I'd be happy with that one shut down too. reply jackblemming 20 hours agoparentprevYou think that fraud is just going to go away because .tk is gone? reply jamespo 20 hours agorootparentprobably not, but very little of value has been lost reply dlachausse 19 hours agorootparentI would disagree, I remember as a kid in the late 90s being able to host a website on one of the free hosting providers and then pairing it with a free domain name just made the whole thing that much more special. $10 or so a year for a paid domain name isn't a ton of money, but it can be for a kid with no credit cards and parents that aren't convinced as to why you \"need\" a domain name. reply bombcar 19 hours agorootparentThe problem is that \"free for kids\" is also \"free for scammers\" and it's hard to square that circle. reply kdmccormick 19 hours agorootparentWould be really cool if public schools provided a free domain and basic hosting for any interested middle/high school student. reply where-group-by 18 hours agorootparentI don't think that would be a good idea. It would introduce an admin burden on the schools related to moderating/monitoring the sites. And they would more than likely overstep in one way or another, when enforcing their rules. reply kdmccormick 18 hours agorootparentI was thinking state-administered. Public school enrollment would just be the precondition to access the program. But sure, yeah, there'd be some admin time spent managing it. As with anything, there are plenty of reasons not to do it. It struck me as a low cost-to-impact ratio thing that could get kids into tech, but reasonable minds could disagree. reply bombcar 18 hours agorootparentprevThe only way it would work is if it was literally handled by the government, and the associated 1st amendment rules applied (so it wouldn't be moderated unless it was actually shut down by a court case). It would result in rampant wildness and people complaining, but if you didn't do it that way the burden would be too high. reply cube00 19 hours agorootparentprevGood luck considering we can't even pay teachers properly. reply kdmccormick 19 hours agorootparentCost would be negligible compared to a teacher's salary. (1 teacher / 20 students) * ($50k / teacher-yr) = $2500 per student per year to fund teacher salary. Compare that to $40/yr domain+hosting, which maybe 10% of students will use. $4/student-yr will not be the diffence between paying teachers probably or not. reply lxgr 18 hours agorootparentThat budget only works if you don't care about content moderation or abuse management at all – or did you expect teachers to just do that on the side? reply lxgr 18 hours agorootparentprevAnother way of looking at this is that scammers can probably afford to spend $5-10 on a TLD since it's just a cost of doing \"business\" to them, but many kids can't. I was very happy about free TLDs back in the day as a teenager, since I could just try things out before having to convince my parents to let me use their credit card to register a proper domain name. reply Caligatio 17 hours agorootparentIt's infinitely easier to spend $0 vs $0.01 if you're trying to be anonymous online. The criminals can certainly afford it but that also almost certainly means interacting with financial systems that leave a paper trail. reply lxgr 16 hours agorootparentI doubt that that's any kind of obstacle to criminals. At a quick glance, many registrars and hosters seem to accept crypto, and anyone can buy prepaid Visa and Mastercard cards anonymously for cash for the ones that don't. reply knodi 19 hours agorootparentprevwe're not in the 90s anymore. Many free subdomains options such as gitpages or full on free app (heroku) exists now. reply mastazi 9 hours agoprevIs it safe to assume that these were overwhelmingly on Cloudflare's free tier? I don't expect that someone who gets a domain for free is going to pay for hosting; if that's the case I don't see this as a big loss for Cloudflare, or am I missing something? reply creatonez 4 hours agoparentI would guess the same, that these are not Cloudflare customers but rather domains that happened to be configured on Cloudflare. CF probably just increased their profit margin a little by no longer handling all those free users. reply bastawhiz 18 hours agoprev> The affected domains represent a big loss for Cloudflare, with .tk, .cf and .gq previously accounting for 23.1% of all domains hosted on its platform – and nearly all of these have now gone. I'm not sure in what way this is a \"loss\". I doubt cloudflare is losing money (or revenue) here. Especially if many of these domains are spammy, it seems like this is probably not much of anything for them. reply jacurtis 13 hours agoparentThis was my thought while reading this. Overall I think this is a net-win for CloudFlare. I suspect that exactly 0.00% of the 12.6 million domains they just \"lost\" were paying customers. Considering the people didn't want to pay for a domain, they probably weren't paying for a CDN either. I'm sure Cloudflare will be able to wipe away their tears of this loss using the extra dollar bills they have from reducing their bandwidth costs. reply dlachausse 19 hours agoprevAnother prominent .tk domain is for the Tcl programming language (tcl.tk) and I just checked, that is one of the paid .tk domains that are still up. reply overstay8930 19 hours agoparentWhy do orgs feel the need to use these whacky TLDs I’m still of the fence with rust using .rs in important places which is fundamentally in control of the Serbian government. You’re going to have to trust the Serbian government with signing .rs DNSSSEC at minimum and I don’t. reply dlachausse 19 hours agorootparentIn TCL’s case it’s a fun play on Tcl/Tk, which is how it is often referred to when including its famous GUI toolkit. reply api_or_ipa 11 hours agorootparentprevTo be perfectly fair, the list of DNSSEC cock-ups is staggering. .nz ccTLD was taken down, IIRC, for 4 days after a bad KSK rollover just last year. I’ve seen prominent registrars with ‘automated’ DNSSEC fail to upload correct NSEC and RRSIGs. It’s not uncommon to see .gov domains go down because of DNSSEC. You’d think all these entities should get it right, but they don’t. Probably why many major tech domains such as google.com don’t use DNSSEC. But to your point, using a ‘off-brand’ can really hurt sometimes. `.af` might be a cute marketing tactic, but it’s actually Afghanistan, and the Taliban play by a different rulebook. I believe it was `gay.af` that found that out the hard way. Tons of other stories. reply pmdr 14 hours agorootparentprevI think .so is an even whackier choice and people are rushing to it. Why notion.com redirects to notion.so is beyond me. Probably couldn't buy it and pay only for a redirect? reply rvnx 18 hours agorootparentprevBecause all .com are already taken and available only after you pay ransom money. reply bdcravens 15 hours agorootparentThen use descriptive product names, not cute single words that are being used by 47 other products. reply Fnoord 19 hours agorootparentprevRemnant of a time when the Internet was new and geeks would buy all kind of fun domains with odd TLDs. reply bdcravens 15 hours agorootparent\"new\"? I don't remember seeing many of the \"odd TLDs\" for sale until the web had been around 10-15 years. reply Fnoord 13 hours agorootparentNot the TLDs themselves the creative use of them. I started on the Internet in the (mid) 90s. Back then, it was already common among security conscious folks. A bit later, end 90s, you could buy a shell account for a couple of USD per month. You could run a BNC on it, or IRC client. It had various IPv4 with reverse DNS, this was called vhost. For example, you could end up with I.pwned.the.whole.eu.org and plays where TLD was part of word. Goatse.cx for example reads 'goatsex', Slashdot.org reads 'slashdotdotorg' or 'httpcolonslashslashslashdotdotorg', the founder of first Dutch consumer ISP Xs4all Rop Gonggrijp had gonggri.jp for ages (guess his email address). There are countless of examples. reply yau8edq12i 17 hours agorootparentprevWho do you trust? reply DaSHacka 1 hour agorootparent.moe, as it's clearly the classiest and most professional TLD out there reply overstay8930 14 hours agorootparentprevAny of the OG TLD's, I wouldn't tie my domain to anything political at all outside of the US. You already have to implicitly trust the US government when it comes to anything internet-related as all of the critical infrastructure is, whether you like it or not, American, so you might as well set up shop within US control. reply mcfedr 15 hours agorootparentprevNot a bunch of pro Russia mafia reply blacksqr 16 hours agoparentprevThe TCL maintainers switched their main URL to tcl-lang.org a while back because Freenom was so unreliable, although they've continued to serve tcl.tk as well with crossed fingers. I really hope Tokelau chooses a reputable registrar going forward, and .tk becomes usable for serious people. reply smrtinsert 16 hours agoparentprevAh nostalgic for tcl. reply estebarb 20 hours agoprevOh, that is why I wasn't able to renew some domains I have used for 10+ years. I'm not even able to upgrade to paid domain. I don't think it will help reducing malware/scams/phishing. But it will hurt students and young people that want to start in en development and aren't able to pay for a domain. reply dazld 15 hours agoparentFor students, a few of the GitHub Education Student Pack partners offer free domains for a year. https://www.name.com/partner/github-students https://get.tech/github-student-developer-pack https://nc.me/ reply wizzwizz4 19 hours agoparentprevWe still have https://nic.eu.org/ and https://freedns.afraid.org/ . reply iopq 11 hours agorootparentI applied for a domain at nic.eu.org in 2023 and I have never gotten a response reply 8organicbits 19 hours agorootparentprevThere's a couple more options too: https://free.wdh.gg/#/?id=domains reply thih9 19 hours agoprevThe article presents this as a loss - but cloudflare has a free tier, do we know if these were paid accounts? If cloudflare weren’t going to convert these users then this could be a gain. reply PokestarFan 18 hours agoparentIf the users were using free domains instead of paying for a domain do you think they'd use paid cloudflare? The cost of a domain is so much lower than the cost of Cloudflare. reply sltkr 14 hours agorootparentI could at least imagine a scenario along the lines of: penniless college student creates a site at a .tk domain. Later, the student gets a job so he is no longer penniless, and meanwhile, his site actually becomes popular, so he signs up for cloudflare, maybe even registers a .com domain, but keeps the .tk domain alive because that's where most his traffic is coming from. Not sure how common that is. But I don't think it's a given that all sites hosted on .tk domains are unwilling to pay, especially not if you consider that they must be somewhat popular if they need a CDN. (The sort of personal homepage that most of us had back in the 90s would never need a CDN because it would get 5 hits per week.) reply thih9 18 hours agorootparentprevI don’t know and that’s why I’m asking. Not paying for a domain is not a reason enough to expect not paying for cloudflare - these are different services. Also note that even not paying for cloudflare is not enough - I asked whether cloudflare intended to convert that segment. reply toddmorey 19 hours agoprevI get .tk was popular because it was free and you do need a home for your website that’s portable across providers (not like a .netlify.app sub). But like we learned from .af, any of these TLDs technically meant for a country need to be considered ephemeral. You are sort of borrowing it without explicit (or lasting) permission. reply samtho 19 hours agoparent> You are sort of borrowing it without explicit (or lasting) permission. To be fair, this is true of all domains. The broader concern with ccTLDs is this borrowing dynamic layered with whatever geopolitical situation the country is in, how stable the administering authority is with respect to the current regime, or just the political forces at work within the country that may lead to changes or requirements for the ccTLD within the country are registered. There is often a concern of DNS infrastructure and local bandwidth considerations for the data center in which the root nameservers are housed, assuming they are not outsourcing that. reply CydeWeys 16 hours agorootparentIt's not true of gTLDs though. You actually own those domains, and they can't be taken away from you (barring extreme circumstances) so long as you pay the registration fees every year. But domains on ccTLDs can be taken away from you by the government at any time for any reason. reply genewitch 11 hours agorootparentI gotta say i find it extremely hard to believe that one can \"own\" a domain. This sounds like hand-waving. We don't own software, we barely own computers (to do with what we want), we don't own media. Is this like \"one can own land\" but really that's asterisked with Eminent Domain (no pun intended)? reply rurban 3 hours agoprevYeah, I've lost my cannes-ratings.tk around that time without any explanation. Lucky I decided to finally pay for the .org a year before. reply ChrisArchitect 19 hours agoprevIs there any other connection to Cloudflare? I thought maybe they were using the .cf domain for their own stuff or something. ;) reply nicrtt 18 hours agoprevAhhh, the memories :) Understandable, but a loss all the same. I'll never forget how proud I felt as a kid when I first had a URL I could give to people. reply ncruces 18 hours agoprevI had a free website on .tk When it because moderately successful, they didn't renew, and then wanted 50€/year. reply dancemethis 17 hours agoprevTangentially, Cloudflare REALLY needs to start supporting transferring .moe domains already. reply znpy 14 hours agoprevUh… if anybody has a legitimate .tk domain, how does one keep it alive? reply qingcharles 11 hours agoparentI used to pay for mine. They were sold through resellers if you wanted to keep it. One advantage of .tk is that they supported emoji domains. reply zoklet-enjoyer 12 hours agoprev [–] My friends and I used cjb.net for our anime website reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cloudflare faced a significant 22% loss of domains on March 15, 2024, due to the closure of Freenom's top-level domains (.tk, .cf, .gq), causing a 98.7% decrease in resolvable domains.",
      "Freenom's departure from the domain business was influenced by a lawsuit and reduced abuse complaints, impacting Cloudflare's domain hosting with a 22% reduction in total domains.",
      "The shutdown of Freenom TLDs resulted in a decrease in cybercrime, notably reducing malicious URLs linked to the affected domains."
    ],
    "commentSummary": [
      "Cloudflare has experienced a 22% decrease in its domains following the closure of Freenom .tk domains, evoking nostalgia among users who previously utilized these free domains.",
      "Debates are ongoing regarding website security, content moderation, anonymity, and the responsibility of infrastructure companies like Cloudflare in monitoring potentially illegal or objectionable content.",
      "Discussions encompass the history of free domain hosting services, the influence of top-level domains (TLDs) on internet infrastructure, alternative domain options, and the implications for students and budding developers."
    ],
    "points": 292,
    "commentCount": 205,
    "retryCount": 0,
    "time": 1710591894
  },
  {
    "id": 39731824,
    "title": "The Importance of Frame Pointers in Linux Kernel Profiling",
    "originLink": "https://www.brendangregg.com/blog/2024-03-17/the-return-of-the-frame-pointers.html",
    "originBody": "Brendan's site: Start Here Homepage Blog Sys Perf book BPF Perf book Linux Perf eBPF Tools perf Examples Perf Methods USE Method TSA Method Off-CPU Analysis Active Bench. WSS Estimation Flame Graphs Heat Maps Frequency Trails Colony Graphs DTrace Tools DTraceToolkit DtkshDemos Guessing Game Specials Books Other Sites Systems Performance 2nd Ed. BPF Performance Tools book Recent posts: 17 Mar 2024 » The Return of the Frame Pointers 10 Mar 2024 » eBPF Documentary 28 Apr 2023 » eBPF Observability Tools Are Not Security Tools 01 Mar 2023 » USENIX SREcon APAC 2022: Computing Performance: What's on the Horizon 17 Feb 2023 » USENIX SREcon APAC 2023: CFP 02 May 2022 » Brendan@Intel.com 15 Apr 2022 » Netflix End of Series 1 09 Apr 2022 » TensorFlow Library Performance 19 Mar 2022 » Why Don't You Use ... 26 Sep 2021 » The Speed of Time 06 Sep 2021 » ZFS Is Mysteriously Eating My CPU 30 Aug 2021 » Analyzing a High Rate of Paging 27 Aug 2021 » Slack's Secret STDERR Messages 05 Jul 2021 » USENIX LISA2021 Computing Performance: On the Horizon 03 Jul 2021 » How To Add eBPF Observability To Your Product 15 Jun 2021 » USENIX LISA2021 BPF Internals (eBPF) 04 Jun 2021 » An Unbelievable Demo 29 May 2021 » Moving my US tech job to Australia 23 May 2021 » What is Observability 09 May 2021 » Poor Disk Performance Blog index About RSS Brendan Gregg's Blog home The Return of the Frame Pointers 17 Mar 2024 Sometimes debuggers and profilers are obivously broken, sometimes it's subtle and hard to spot. From my flame graphs page: CPU flame graph (partly broken) (Click for original SVG.) This is pretty common and usually goes unnoticed as the flame graph looks ok at first glance. But there are 15% of samples on the left, above \"[unknown]\", that are in the wrong place and missing frames. The problem is that this system has a default libc that has been compiled without frame pointers, so any stack walking stops at the libc layer, producing a partial stack that's missing the application frames. These partial stacks get grouped together on the left. Click here for a longer explanation. Other types of profiling hit this more often. Off-CPU flame graphs, for example, can be dominated by libc read/write and mutex functions, so without frame pointers end up mostly broken. Apart from library code, maybe your application doesn't have frame pointers either, in which case everything is broken. I'm posting about this problem now because Fedora and Ubuntu are releasing versions that fix it, by compiling libc and more with frame pointers by default. This is great news as it not only fixes these flame graphs, but makes off-CPU flame graphs far more practical. This is also a win for continuous profilers (my employer, Intel, just announced one) as it makes customer adoption easier. What are frame pointers? The x86-64 ABI documentation shows how a CPU register, %rbp, can be used as a \"base pointer\" to a stack frame, aka the \"frame pointer.\" I pictured how this is used to walk stack traces in my BPF book. Figure 3.3: Stack Frame with Base Pointer (x86-64 ABI) Figure 2-6: Frame Pointer-based Stack Walking (BPF book) This stack-walking technique is commonly used by external profilers and debuggers, including Linux perf and eBPF, and ultimately visualized by flame graphs. However, the x86-64 ABI has a footnote [12] to say that this register use is optional: \"The conventional use of %rbp as a frame pointer for the stack frame may be avoided by using %rsp (the stack pointer) to index into the stack frame. This technique saves two instructions in the prologue and epilogue and makes one additional general-purpose register (%rbp) available.\" (Trivia: I had penciled the frame pointer function prologue and epilogue on my Netflix office wall, lower left.) 2004: Their removal In 2004 a compiler developer, Roger Sayle, changed gcc to stop generating frame pointers, writing: \"The simple patch below tweaks the i386 backend, such that we now default to the equivalent of \"-fomit-frame-pointer -ffixed-ebp\" on 32-bit targets\" i386 (32-bit microprocessors) only have four general purpose registers, so freeing up %ebp takes you from four to five. I'm sure this delivered large performance improvements and I wouldn't try arguing against it. Roger cited two other reasons for this change: The desire to outperform Intel's icc compiler, and the belief that it didn't break debuggers (of the time) since they supported other stack walking techniques. 2005-2023: The winter of broken profilers However, the change was then applied to x86-64 (64-bit) as well, which had sixteen registers and didn't benefit so much from a seventeenth. And there are debuggers/profilers that this change did break, more so today with the rise of eBPF, which didn't exist back then (typically system profilers, not language specific ones). As my former Sun Microsystems colleague Eric Schrock (nickname Schrock) wrote in November 2004: \"On i386, you at least had the advantage of increasing the number of usable registers by 20%. On amd64, adding a 17th general purpose register isn't going to open up a whole new world of compiler optimizations. You're just saving a pushl, movl, an series of operations that (for obvious reasons) is highly optimized on x86. And for leaf routines (which never establish a frame), this is a non-issue. Only in extreme circumstances does the cost (in processor time and I-cache footprint) translate to a tangible benefit - circumstances which usually resort to hand-coded assembly anyway. Given the benefit and the relative cost of losing debuggability, this hardly seems worth it.\" In Schrock's conclusion: \"it's when people start compiling /usr/bin/ without frame pointers that it gets out of control.\" This is exactly what happened on Linux, not just /usr/bin but also /usr/lib and application code! I'm sure there are people who are too new to the industry to remember the pre-2004 days when profilers would \"just work\" without OS and runtime changes. 2014: Java in Flames Broken Java Stacks (2014) When I joined Netflix in 2014, I found Java's lack of frame pointer support broke all application stacks (pictured in my 2014 Surge talk on the right). I ended up developing a fix for the JVM c2 compiler which Oracle reworked and added as the -XX:+PreserveFramePointer option in JDK8u60 (see my Java in Flames post for details [PDF]). While that Java change led to discovering countless performance wins in application code, libc was still breaking some portion of the samples (as pictured in the example at the top of this post) and preventing off-CPU flame graphs. I started by compiling my own libc for production use with frame pointers, and then worked with Canonical to have one prebuilt for Ubuntu. For a while I was promoting the use of Canonical's libc6-prof, which was libc6 with frame pointers. 2015-2020: Overhead As part of production rollout I did many performance overhead tests, which I've described publicly before: The overhead of adding frame pointers to everything (libc and Java) was usually less than 1%, with one exception of 10%. That 10% was an unusual application that was generating stack traces over 1000 frames deep (via Groovy), so deep that it broke Linux's perf profiler and Arnaldo Carvalho de Melo (Red Hat) added the kernel.perf_event_max_stack sysctl just for this Netflix workload. It was also a virtual machine that lacked low-level hardware profiling capabilities, so I wasn't able to do cycle analysis to confirm that the 10% was entirely frame pointer-based. The actual overhead depends on your workload. Others have reported around 1% and around 2%. Microbenchmarks can be the worst, hitting 10%: This doesn't surprise me since they resolve to running a small funciton in a loop, and adding any instructions to that function can cause it to spill out of L1 cache warmth (or cache lines) causing a drop in performance. If I were analyzing such a microbenchmark, apart from observability anaylsis (cycles, instructions, PMU, PMCs, PEBS) there are also an experiment I'd like to try: To test the theory of I-cache spillover: Compile the microbenchmark with and without frame pointers and find the performance delta. Then flame graph the microbenchmark to understand the hot function. Then add some inline assembly to the hot function where you add enough NOPs to the start and end to mimic the frame pointer prologue and epilogue (I recommend writing them on your office wall in pencil), compile it without frame pointers, disassemble the compiled binary to confirm those NOPs weren't stripped, and now test that. If the performance delta is still large (10%) you've confirmed that it is due to cache effects, and anyone who was worked at this level in production will tell you that it's the straw that broke the camel's back. Don't blame the straw, in this case, don't blame the frame pointers. Adding anything will cause the same effect. Having done this before, it reminds me of CSS programming: you make a little change here and everything breaks, and you spend hours chasing your own tail. Someone recently told me that Python can hit 10% overhead with frame pointers. That also needs to be debugged to see what's going on. My experience is that it's the exception and not the rule. And don't forget what this is changing: It gives the compiler an extra seventeenth register, and adds some highly-optimized instructions to every function. It shouldn't be 10%, unless it's cache effects. As I've seen frame pointers help find performance wins ranging from 5% to 500%, the typical \"less than 1%\" cost (or even 1% or 2% cost) is easily justified. But I'd rather the cost be zero, of course! We may get there with future technologies I'll cover later. In the meantime, frame pointers are the most practical way to find performance wins today. What about Linux on devices where there is no chance of profiling or debugging, like electric toothbrushes? (I made that up, AFAIK they don't run Linux, but I may be wrong!) Sure, compile without frame pointers. The main users of this change are enterprise Linux. Back-end servers. 2022: Upstreaming, first attempt Other large companies with OS and perf teams (Meta, Google) hinted strongly that they had already enabled frame pointers for everything years earlier. (Google should be no surprise because they pioneered continuous profiling.) So at this point you had Google, Meta, and Netflix running their own libc with frame pointers and able to enjoy profiling capabilities that most other companies – without dedicated OS teams – couldn't get working. Can't we just upstream this so everyone can benefit? There's a bunch of difficulties when taking \"works well for me\" changes and trying to make them the default for everyone. Among the difficulties is that end-user companies don't have a clear return on the investment from telling their Linux vendor what they fixed, since they already fixed it. I guess the investment is quite small, we're talking about a single email, right?...Wrong! Your suggestion is now a 116-post thread where everyone is sharing different opinions and demanding this and that, as we found out the hard way. For Fedora, one person requested: \"Meta and/or Netflix should provide infrastructure for a side repository in which the change can be tested and benchmarked and the code size measured.\" (Bear in mind that Netflix doesn't even use Fedora!) Jonathan Corbet, who writes the best Linux articles, summarized this in \"Fedora's tempest in a stack frame\" that is so detailed that I feel PTSD when reading it. It's good that the Fedora community wants to be so careful, but I'd rather spend time discussing building something better than frame pointers, perhaps involving ORC, LBR, eBPF, and other technologies, than so much worry about looking bad in kitchen-sink benchmarks that I wouldn't trust in the first place. 2023, 2024: Frame Pointers in Fedora and Ubuntu! Fedora revisited the proposal and has accepted it this time, making it the first distro to reenable frame pointers. Thank you! Ubuntu has also announced frame pointers by default in Ubuntu 24.04 LTS. Thank you! While this fixes stack walking through OS libraries, you might find your application still doesn't support stack tracing, but that's typically much easier to fix. Java, for example, has the -XX:+PreserveFramePointer option. There were ways to get Golang to support frame pointers, but that became the default years ago. Just to name a couple of languages. 2034+: Beyond Frame Pointers There's more than one way to walk a stack. These could be separate blog posts, but I want to comment briefly on alternates: LBR (Last Branch Record): Intel's hardware feature that was limited to 16 or 32 frames. Most application stacks are deeper, so this can't be used to build flame graphs, but it is better than nothing. I use it as a last resort as it gives me some stack insights. BTS (Branch Trace Store): Another Intel thing. Not so limited to stack depth, but has overhead from memory load/stores and BTS buffer overflow interrupt handling. AET (Archetectural Event Trace): Another Intel thing. It's a JTAG-based tracer that can trace low-level CPU, BIOS, and device events, and apparently can be used for stack traces as well. I haven't used it. (I spent years as a cloud customer where I couldn't access many HW-level things.) I hope it can be configured to output to main memory, and not just a physical debug port. DWARF: Binary debuginfo, has been used forever with debuggers. Doesn't exist for JIT'd runtimes like the Java JVM, and I don't really see any practical way to ever fix that. The overhead to walk DWARF is also too high, as it was designed for non-realtime use. Polar Signals did some interesting work using an eBPF walker to reduce the overhead, but...Java. eBPF stack walking: Mark Wielaard (Red Hat) demonstrated a Java JVM stack walker using SystemTap back at LinuxCon 2014, where an external tracer walked a runtime with no runtime support or help. Very cool. This can be done using eBPF as well. The performmance overhead could be too high, however, as it may mean a lot of user space reads of runtime internals depending on the runtime. ORC (oops rewind capability): The Linux kernel's new lightweight stack unwinder by Josh Poimboeuf (Red Hat) that has allowed newer kernels to remove frame pointers yet retain stack walking. You may be using ORC without realizing it; the rollout was smooth as the kernel profiler code was updated to support ORC (perf_callchain_kernel()->unwind_orc.c) at the same time as it was compiled to support ORC. Can't ORCs invade user space as well? SFrames (Stack Frames): ...which is what SFrames does: lightweight user stack unwinding based on ORC. There have been recent talks to explain them by Indu Bhagat (Oracle) and Steven Rostedt (Google). I should do a blog post just on SFrames. Shadow Stacks: A newer Intel and AMD security feature that can be configured to push function return addresses onto a separate HW stack so that they can be double checked when the return happens. Sounds like such a HW stack could also provide a stack trace, without frame pointers. (And this isn't even all of them.) Daan De Meyer (Meta) did a nice summary as well of different stack walkers on the Fedora wiki. So what's next? Here's my guesses: 2029: Ubuntu and Fedora release new versions with SFrames for OS components (including libc) and ditches frame pointers again. We'll have had five years of frame pointer-based performance wins and new innovations that make use of user space stacks, and will hit the ground running with SFrames. 2034: Shadow stacks have been enabled by default for security, and then are used for all stack tracing. Conclusion I could say that times have changed and now the original 2004 reasons for omitting frame pointers are no longer valid in 2024. Those reasons were that it improved performance significantly on i386, that it didn't break the debuggers of the day (prior to eBPF), and that competing with another compiler (icc) was deemed important. Yes, times have indeed changed. But I should note that one engineer, Eric Schrock, claimed that it didn't make sense back in 2004 either when it was applied to x86-64, and I agree with him. Profiling has been broken for 20 years and we've only now just fixed it. Fedora and Ubuntu have now returned frame pointers, which is great news. People should start running these releases in 2024 and will find that CPU flame graphs make more sense, Off-CPU flame graphs work for the first time, and other new things become possible. It's also a win for continuous profilers, as they don't need to convince their customers to make OS changes to get profiles to fully work. Thanks The online threads about this change aren't even everything, there's been many discussions, meetings, and work put into this, not just for frame pointers but other recent advances including ORC and SFrames. Special thanks to Andrii Nakryiko (Meta), Daan De Meyer (Meta), Davide Cavalca (Meta), Ian Rogers (Google), Steven Rostedt (Google), Josh Poimboeuf (Red Hat), Arjan Van De Ven (Intel), Indu Bhagat (Oracle), Mark Shuttleworth (Canonical), Jon Seager (Canonical), Oliver Smith (Canonical), and many others (see the Fedora discussions). And thanks to Schrock. Appendix: Fedora For reference, here's my writeup for the Fedora change: I enabled frame pointers at Netflix, for Java and glibc, and summarized the effect in BPF Performance Tools (page 40): \"Last time I studied the performance gain from frame pointer omission in our production environment, it was usually less than one percent, and it was often so close to zero that it was difficult to measure. Many microservices at Netflix are running with the frame pointer reenabled, as the performance wins found by CPU profiling outweigh the tiny loss of performance.\" I've spent a lot of time analyzing frame pointer performance, and I did the original work to add them to the JVM (which became -XX:+PreserveFramePoiner). I was also working with another major Linux distro to make frame pointers the default in glibc, although I since changed jobs and that work has stalled. I'll pick it up again, but I'd be happy to see Fedora enable it in the meantime and be the first to do so. We need frame pointers enabled by default because of performance. Enterprise environments are monitored, continuously profiled, and analyzed on a regular basis, so this capability will indeed be put to use. It enables a world of debugging and new performance tools, and once you find a 500% perf win you have a different perspective about the 1%) production regression we saw, and it was a microservice that was bonkers for a variety of reasons, including stack traces that were over 1000 frames deep (and that was after inlining! Over 3000 deep without. ACME added the perf_event_max_stack sysctl just so Netflix could profile this microservice, as the prior limit was 128). So one possibility is that the extra function prologue instructions add up if you frequently walk 1000 frames of stack (although I still don't entirely buy it). Another attribute was that the microservice had over 1 Gbyte of instruction text (!), and we may have been flying close to the edge of hardware cache warmth, where adding a bit more instructions caused a big drop. Both scenarios are debuggable with PMCs/PEBS, but we had none at the time. So while I think we need to debug those rare 10%s, we should also bear in mind that customers can recompile without FPs to get that performance back. (Although for that microservice, the developers chose to eat the 10% because it was so valuable!) I think frame pointers should be the default for enterprise OSes, and to opt out if/when necessary, and not the other way around. It's possible that some math functions in glibc should opt out of frame pointers (possibly fixing scimark, FWIW), but the rest (especially pthread) needs them. In the distant future, all runtimes should come with an eBPF stack walker, and the kernel should support hopping between FPs, ORC, LBR, and eBPF stack walking as necessary. We may reach a point where we can turn off FPs again. Or maybe that work will never get done. Turning on FPs now is an improvement we can do, and then we can improve it more later. For some more background: Eric Schrock (my former colleague at Sun Microsystems) described the then-recent gcc change in 2004 as \"a dubious optimization that severely hinders debuggability\" and that \"it's when people start compiling /usr/bin/* without frame pointers that it gets out of control\" I recommend reading his post: [0]. The original omit FP change was done for i386 that only had four general-purpose registers and saw big gains freeing up a fifth, and it assumed stack walking was a solved problem thanks to gdb(1) without considering real-time tracers, and the original change cites the need to compete with icc [1]. We have a different circumstance today -- 18 years later -- and it's time we updated this change. [0] http://web.archive.org/web/20131215093042/https://blogs.oracle.com/eschrock/entry/debugging_on_amd64_part_one [1] https://gcc.gnu.org/ml/gcc-patches/2004-08/msg01033.html Click here for Disqus comments (ad supported). Site Navigation Systems Performance 2nd Ed. BPF Performance Tools book Recent posts: 17 Mar 2024 » The Return of the Frame Pointers 10 Mar 2024 » eBPF Documentary 28 Apr 2023 » eBPF Observability Tools Are Not Security Tools 01 Mar 2023 » USENIX SREcon APAC 2022: Computing Performance: What's on the Horizon 17 Feb 2023 » USENIX SREcon APAC 2023: CFP 02 May 2022 » Brendan@Intel.com 15 Apr 2022 » Netflix End of Series 1 09 Apr 2022 » TensorFlow Library Performance 19 Mar 2022 » Why Don't You Use ... 26 Sep 2021 » The Speed of Time 06 Sep 2021 » ZFS Is Mysteriously Eating My CPU 30 Aug 2021 » Analyzing a High Rate of Paging 27 Aug 2021 » Slack's Secret STDERR Messages 05 Jul 2021 » USENIX LISA2021 Computing Performance: On the Horizon 03 Jul 2021 » How To Add eBPF Observability To Your Product 15 Jun 2021 » USENIX LISA2021 BPF Internals (eBPF) 04 Jun 2021 » An Unbelievable Demo 29 May 2021 » Moving my US tech job to Australia 23 May 2021 » What is Observability 09 May 2021 » Poor Disk Performance Blog index About RSS Brendan's site: Start Here Homepage Blog Sys Perf book BPF Perf book Linux Perf eBPF Tools perf Examples Perf Methods USE Method TSA Method Off-CPU Analysis Active Bench. WSS Estimation Flame Graphs Heat Maps Frequency Trails Colony Graphs DTrace Tools DTraceToolkit DtkshDemos Guessing Game Specials Books Other Sites Copyright 2024 Brendan Gregg. About this blog",
    "commentLink": "https://news.ycombinator.com/item?id=39731824",
    "commentBody": "The return of the frame pointers (brendangregg.com)235 points by mfiguiere 6 hours agohidepastfavorite62 comments dsign 10 minutes agoI remember when the omission of stack frame pointers started spreading at the beginning of the 2000s. I was in college at the time, studying computer sciences in a very poor third-world country. Our computers were old and far from powerful. So, for most course projects, we would eschew interprets and use compilers. Mind you, what my college lacked in money it compensated by having interesting course work. We studied and implemented low level data-structures, compilers, assembly-code numerical routines and even a device driver for Minix. During my first two years in college, if one of our programs did something funny, I would attach gdb and see what was happening at assembly level. I got used to \"walking the stack\" manually, though the debugger often helped a lot. Happy times, until all of the sudden, \"-fomit-frame-pointer\" was all the rage, and stack traces stopped making sense. Just like that, debugging that segfault or illegal instruction became exponentially harder. A short time later, I started using Python for almost everything to avoid broken debugging sessions. So, I lost an order of magnitude or two with \"-fomit-frame-pointer\". But learning Python served me well for other adventures. reply rwmj 9 minutes agoprevI'm glad he mentioned Fedora because it's been a tiresome battle to keep frame pointers enabled in the whole distribution (eg https://pagure.io/fesco/issue/3084). There's a persistent myth that frame pointers have a huge overhead, because there was a single Python case that had a +10% slow down (now fixed). The actual measured overhead is under 1%, which is far outweighed by the benefits we've been able to make in certain applications. reply ReleaseCandidat 1 hour agoprevThat's one thing Apple did do right on ARM: > The frame pointer register (x29) must always address a valid frame record. Some functions — such as leaf functions or tail calls — may opt not to create an entry in this list. As a result, stack traces are always meaningful, even without debug information. https://developer.apple.com/documentation/xcode/writing-arm6... reply zzbn00 2 minutes agoprevNiX (and I assume Guix) are very convenient for this as it is fairly easy to turn frame pointers on or off for parts or whole of the system. reply adsharma 5 hours agoprevI was at Google in 2005 on the other side of the argument. My view back then was simple: Even if $BIG_COMPANY makes a decision to compile everything with frame pointers, the rest of the community is not. So we'll be stuck fighting an unwinnable argument with a much larger community. Turns out that it was a ~20 year argument. I ended up writing some patches to make libunwind work for gperftools and maintained libunwind for some number of years as a consequence of that work. Having moved on to other areas of computing, I'm now a passive observer. But it's fascinating to read history from the other perspective. reply starspangled 4 hours agoparent> So we'll be stuck fighting an unwinnable argument with a much larger community. In what way would you be stuck? What functional problems does adding frame pointers introduce? reply rwmj 4 minutes agorootparentYou do get occasional regressions. eg. We found an extremely obscure bug involving enabling frame pointers, valgrind, glibc ifuncs and inlining (all at the same time): https://bugzilla.redhat.com/show_bug.cgi?id=2267598 https://github.com/tukaani-project/xz/commit/82ecc538193b380... reply adsharma 4 hours agorootparentprevI wasn't talking about functional problems. It was a simple observation that big companies were not going to convince Linux distributors to add frame pointers anytime soon and that what those distributors do is relevant. All of the companies involved believed that they were special and decided to build their own (poorly managed) distribution called \"third party code\" and having to deal with it was not my best experience working at these companies. reply starspangled 4 hours agorootparentOh, I just assumed you were talking about Google's Linux distribution and applications it runs on its fleet. I must have mis-assumed. Re-reading... maybe you weren't talking about any builds but just whether or not to oppose kernel and toolchain defaulting to omit frame pointers? reply adsharma 3 hours agorootparentGoogle didn't have a Linux distribution for a long time (the one everyone used on the desktop was an outdated rpm based distro, we mostly ignored it for development purposes). What existed was a x86 to x86 cross compilation environment and the libraries involved were manually imported by developers who needed that particular library. My argument was about the cost of ensuring that those libraries were compiled with frame pointers when much of the open source community was defaulting to omit-fp. reply tempay 4 hours agorootparentprevIt “wastes” a register when you’re not actively using them. On x86 that can make a big difference, though with the added registers of x86_64 it much less significant. reply charleshn 4 hours agorootparentIt's not just the loss of an architectural register, it's also the added cost to the prologue/epilogue. Even on x86_64, it can make a difference, in particular for small functions, which might not be inlined for a variety of reasons. reply starspangled 4 hours agorootparentprevRight, but I was asking about functional problems (being \"stuck\"), which sounded like a big issue for the choice. reply nlewycky 4 hours agorootparentprevIt caused a problem when building inline assembly heavy code that tried to use all the registers, frame pointer register included. reply jart 3 hours agoparentprevPlease name the individuals who are blocking progress on frame pointers. It's such a clear and obvious win that the rest of us should have the opportunity to persuade them. https://news.ycombinator.com/item?id=34660813 reply quotemstr 23 minutes agorootparentThe clear and obvious win would have been adoption of a universal userspace generic unwind facility, like Windows has --- one that works with multiple languages. Turning on frame pointers is throwing in the towel on the performance tooling ecosystem coordination problem: we can't get people to fix unwind information, so we do this instead? Ugh. reply rwmj 0 minutes agorootparentYes, although the universal mechanisms that have been proposed so far have been quite ridiculous - for example having every program handle a \"frame pointer signal\" in userspace, which doesn't account for the reality that we need to do frame unwinding thousands of times a second with the least possible overhead. Frame pointers work for most things, and where they don't work (interpreted code) you're often not that interested in performance. Joker_vD 3 hours agoprevOf course, if you cede RBP to be a frame pointer, you may as well have two stacks, one which is pointed into by RBP and stores the activation frames, and the other one which is pointed into by RSP and stores the return addresses only. At this point, you don't even need to \"walk the stack\" because the call stack is literally just a flat array of return addresses. Why do we normally store the return addresses near to the local variables in the first place, again? There are so many downsides. reply astrobe_ 20 minutes agoparentYou may be ready for Forth [1] ;-). Strangely, the Wikipedia article apparently doesn't put forward that Forth allows access both to the parameter and the return stack, which is a major feature of the model. [1] https://en.wikipedia.org/wiki/Forth_(programming_language) reply naasking 2 hours agoparentprevIt simplifies storage management. A stack frame is a simple bump pointer which is always in cache and only one guard page for overflow, in your proposal you need two guard pages and double the stack manipulations and doubling the chance of a cache miss. reply Joker_vD 2 hours agorootparentYes, two guard pages are needed. No, the stack management stays the same: it's just \"CALL func\" at the call site, \"SUB RBP, \" at the prologue and \"ADD RBP, ; RET\" at the epilogue. As for chances of a cache miss... probably, but I guess you also double them up when you enable CFET/Shadow Stack so eh. In exchange, it becomes very difficult for the stack smashing to corrupt the return address. reply dan-robertson 1 hour agoparentprevNote the ‘shadow stacks’ CPU feature mentioned briefly in the article, though it’s more for security reasons. It’s pretty similar to what you describe. reply dap 5 hours agoprevGood post! > Profiling has been broken for 20 years and we've only now just fixed it. It was a shame when they went away. Lots of people, certainly on other systems and probably Linux too, have found the absence of frame pointers painful this whole time and tried to keep them available in as many environments as possible. It’s validating (if also kind of frustrating) to see mainstream Linux bring them back. reply claytonwramsey 3 hours agoprevThat's very interesting to me - I had seen the `[unknown]` mountain in my profiles but never knew why. I think it's a tough thing to justify: 2% performance is actually a pretty big difference. It would be really nice to have fine-grained control over frame pointer inclusion: provided fine-grained profiling, we could determine whether we needed the frame pointers for a given function or compilation unit. I wouldn't be surprised if we see that only a handful of operations are dramatically slowed by frame pointer inclusion while the rest don't really care. reply naasking 2 hours agoparent> 2% performance is actually a pretty big difference. No it's not, particularly when it can help you identify hotspots via profiling that can net you improvements of 10% or more. reply pm215 23 minutes agorootparentSure, but how many of the people running distro compiled code do perf analysis? And how many of the people who need to do perf analysis are unable to use a with-frame-pointers version when they need to? And how many of those 10% perf improvements are in common distro code that get upstreamed to improve general user experience, as opposed to being in private application code? If you're netflix then \"enable frame pointers\" is a no-brainer. But if you're a distro who's building code for millions of users, many of whom will likely never need to fire up a profiler, I think the question is at least a little trickier. The overall best tradeoff might end up being still to enable frame pointers, but I can see the other side too. reply inglor_cz 25 minutes agoparentprevThe performance cost in your case may be much smaller than 2 per cent. Don't completely trust the benchmarks on this; they are a bit synthetic and real-world applications tend to produce very different results. Plus, profiling is important. I was able to speed up various segments of my code by up to 20 per cent by profiling them carefully. And, at the end of the day, if your application is so sensitive about any loss of performance, you can simply profile your code in your lab using frame pointers, then omit them in the version released to your customers. reply loeg 2 hours agoparentprevIt’s usually a lot less than 2%. reply sesm 12 minutes agoprevglibc is only 2 MB, why Chrome relies on system glibc instead of statically linking their own version with frame pointers enabled? reply tdullien 2 hours agoprevAs much as the return of frame pointers is a good thing, it's largely unnecessary -- it arrives at a point where multiple eBPF-based profilers are available that do fine using .eh_frame and also manually unwinding high level language runtime stacks: Both Parca from PolarSignals as well the artist formerly known as Prodfiler (now Elastic Universal Profiling) do fine. So this is a solution for a problem, and it arrives just at the moment that people have solved the problem more generically ;) (Prodfiler coauthor here, we had solved all of this by the time we launched in Summer 2021) reply weinzierl 36 minutes agoparentAlso I've heard that the whole .eh_frame unwinding is more fragile than a simple frame pointer. I've seen enough broken stack traces myself, but honestly I never tried if -fno-omit-frame-pointer would have helped. reply tdullien 27 minutes agorootparentYes and no. A simple frame pointer needs to be present in all libraries, and depending on build settings, this might not be the case. .eh_frame tends to be emitted almost everywhere... So it's both similarly fragile, but one is almost never disabled. The broader point is: For HLL runtimes you need to be able to switch between native and interpreted unwinds anyhow, so you'll always do some amount of lifting in eBPF land. And yes, having frame pointers removes a lot of complexity, so it's net a very good thing. It's just that the situation wasnt nearly as dire as described, because people that care about profiling had built solutions. reply quotemstr 19 minutes agorootparentForget eBPF even -- why do the job of userspace in the kernel? Instead of unwinding via eBPF, we should ask userspace to unwind itself using a synchronous signal delivered to userspace whenever we've requested a stack sample. reply Tomte 2 hours agoparentprevYou mean we don‘t need accessible profiling in free software because there are companies selling it to us. Cool. reply tdullien 1 hour agorootparentParca is open-source, Prodfiler's eBPF code is GPL, and the rest of Prodfiler is currently going through OTel donation, so my point is: There's now multiple FOSS implementations of a more generic and powerful technique. reply brancz 2 hours agorootparentprevParca's user-space code is apache2 and the eBPF code is GPL. reply searealist 7 minutes agoparentprevI'm under the impression that eh_frame stack traces are much slower than frame pointer stack traces, which makes always-on profiling, such as seen in tcmalloc, impractical. reply int_19h 51 minutes agoparentprevPolarSignals is specifically discussed in the linked threads, and they conclude that their approach is not good enough for perf reasons. reply tdullien 26 minutes agorootparentOh nice, I can't find that - can you post a link? reply pajko 5 hours agoprevThere's another option: https://lesenechal.fr/en/linux/unwinding-the-stack-the-hard-... reply loeg 4 hours agoparentBrendan mentions DWARF unwinding, actually, and briefly mentions why he considers it insufficient. reply haberman 4 hours agorootparentThe biggest objection seems to be the Java/JIT case. eh_frame supports a \"personality function\" which is AIUI basically a callback for performing custom unwinding. If the personality function could also support custom logic for producing backtraces, then the profiling sampler could effectively read the JVM's own metadata about the JIT'ted code, which I assume it must have in order to produce backtraces for the JVM itself. reply loeg 3 hours agorootparentThis also seems like a big objection: > The overhead to walk DWARF is also too high, as it was designed for non-realtime use. reply menaerus 19 minutes agorootparentFrom https://fzn.fr/projects/frdwarf/frdwarf-oopsla19.pdf DWARF-based unwinding can be a bottleneck for time-sensitive program analysis tools. For instance the perf profiler is forced to copy the whole stack on taking each sample and to build the backtraces offline: this solution has a memory and time overhead but also serious confidentiality and security flaws. So if I get this correctly, the problem with DWARF is that building the backtrace online (on each sample) in comparison to frame pointers is an expensive operation which, however, can be mitigated by building the backtrace offline at the expense of copying the stack. However, paper also mentions Similarly, the Linux kernel by default relies on a frame pointer to provide reliable backtraces. This incurs in a space and time overhead; for instance it has been reported (https://lwn.net/Articles/727553/) that the kernel’s .text size increases by about 3.2%, resulting in a broad kernel-wide slowdown. and Measurements have shown a slowdown of 5-10% for some workloads (https://lore.kernel.org/lkml/20170602104048.jkkzssljsompjdwy@suse.de/T/#u). reply kouteiheika 1 hour agorootparentprevNot a problem in practice. The way you solve it is to just translate DWARF into a simpler representation that doesn't require you to walk anything. (But I understand why people don't want to do it. DWARF is insanely complex and annoying to deal with.) Source: I wrote multiple profilers. reply eqvinox 1 hour agoprevThis doesn't detract from the content at all but the register counts are off; SI and DI count as GPRs on i686 bringing it to 6+BP (not 4+BP) meanwhile x86_64 has 14+BP (not 16+BP). reply benreesman 1 hour agoprevBrendan is such a treasure to the community (buy his book it’s great). I wasn’t doing extreme performance stuff when -fomit-frame-pointer became the norm, so maybe it was a big win for enough people to be a sane default, but even that seems dubious: “just works” profiling is how you figure out when you’re in an extreme performance scenario (if you’re an SG14 WG type, you know it and are used to all the defaults being wrong for you). I’m deeply grateful for all the legends who have worked on libunwind, gperf stuff, perftool, DTrace, eBPF: these are the too-often-unsung heroes of software that is still fast after decades of Moore’s law free-riding. But they’ve been fighting an uphill battle against a weird alliance of people trying to game compiler benchmarks and the really irresponsible posture that “developer time is more expensive” which is only sometimes true and never true if you care about people on low-spec gear, which is the community of users who that is already the least-resourced part of the global community. I’m fortunate enough to have a fairly modern desktop, laptop, and phone: for me it’s merely annoying that chat applications and music players and windowing systems offer nothing new except enshittification in terms of features while needing 10-100x the resources they did a decade ago. But for half of my career and 2/3rds of my time coding, I was on low-spec gear most of the time, and I would have been largely excluded if people didn’t care a lot about old computers back then. I’m trying to help a couple of aspiring hackers get started right now it’s a real struggle to get their environments set up with limitations like Intel Macs and WSL2 as the Linux option (WSL2 is very cool but it’s not loved up enough by e.g. yarn projects). If you want new hackers, you need to make things work well on older computers. Thanks again Brendan et al! reply 5- 2 hours agoprevso what is the downside to using e.g. dwarf-based stack walking (supported by perf) for libc, which was the original stated problem? in the discussion the issue gets conflated with jit-ted languages, but that has nothing to do with the crusade to enable frame pointer for system libraries. and if you care that much for dwarf overhead... just cache the unwind information in your system-level profiler? no need to rebuild everything. reply brancz 1 hour agoparentThe way perf does it is slow, as the entire stack is copied into user-space and is then asynchronously unwound. This is solvable as Brendan calls out, we’ve created an eBPF-based profiler at Polar Signals, that essentially does what you said, it optimized the unwind tables, caches them in bpf maps, and then synchronously unwinds as opposed to copying the whole stack into user-space. reply yxhuvud 1 hour agoparentprevThe article explains why DWARF is not an option. reply menaerus 49 minutes agorootparentExtremely light on the details, and also conflates it with the JIT which makes it harder to understand the point, so I was wondering about the same thing as well. reply WalterBright 4 hours agoprevGuess I'll add it back in to the DMD code generator! reply ngcc_hk 4 hours agoprevIt said gcc. I noted the default of llvm said to default with framepounter from 2011. Is this mainly a gcc issue? reply bawolff 2 hours agoparentIt doesn't really matter what the default of the compiler is, but what distros chose. reply userbinator 4 hours agoprev [9 more] [flagged] dap 4 hours agoparentI’m not sure what use case you’re coming from but it sounds like you’re saying something like: most end users don’t use a profiler or debugger so why should they pay the cost of debuggability? That’s fine I guess if you’re throwing software over a wall to users and taking no responsibility for their experience. But a lot of people who build software do take some responsibility for bugs and performance problems that their users experience. This stuff is invaluable for them. End users benefit (tremendously) from software being debuggable even if the users themselves never run a profiler or debugger that uses the frame pointers (because the developers are able to find and fix problems reported by other users or the developers themselves). reply userbinator 3 hours agorootparentnext [2 more] [flagged] ivlad 2 hours agorootparentWhile I somewhat support the idea of avoiding debug-mode applications shipped to end customers, it seems in this particular case Brendan argues about the need to debug binaries in runtime on the server side. If there is a binary component running in production, the choice of running it with debug enabled (and/or with an ability to activate debug in runtime) is purely choice of the system owners (who nowadays are both the developers and the operators of components). “Observability” primarily refers to ability to view system state beyond of what blackbox monitoring does. Again, the term primarily refers to server side operations and not to software shipped to end users. As much as spying on users is ugly, it’s not related to debugging server side. reply dataflow 4 hours agoparentprev> Let's make software more inefficient (even if it's tiny, it all adds up!) I'm not sure if you know who the author of that blog is, but if there's anyone in the world who cares about (and is knowledgeable about) improving performance, it's him. You can be pretty darn sure he wouldn't do this if he believed it would make software more inefficient. reply userbinator 3 hours agorootparentI'm sure those who decide to insert invasive telemetry believe they're making things better too. reply dataflow 3 hours agorootparentYou're confusing things with the analogy. The invasiveness of telemetry is collateral damage, not failure to meet its primary objective (gathering useful data for debugging, spying on people, whatever you think it is). In this case his primary objective literally is to improve performance... which aligns with your own goal, and which he has successfully demonstrated in the past. reply rhinoceraptor 4 hours agoparentprevWe have an embarrassment of riches in terms of compute power, slowing down everything by a negligible amount is worth it if it makes profiling and observability even 20% easier. In almost all cases you cannot just walk up to a production Linux system and do meaningful performance analysis without serious work, unlike say a Solaris production system from 15 years ago. reply supriyo-biswas 4 hours agoparentprevhttps://news.ycombinator.com/newsguidelines.html > Be kind. Don't be snarky. Converse curiously; don't cross-examine. Edit out swipes. > Please don't fulminate. Please don't sneer, including at the rest of the community. reply ribit 2 hours agoparentprev [–] You seem to be stuck in the 90-ties. Computing is 64-bit nowadays, not 32-bit, and modern architectures/ABIs integrate frame pointers and frame records in a way that’s both natural and performant. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Brendan Gregg's blog delves into performance analysis tools such as BPF and eBPF, challenges with frame pointers in libc, enhancements in Fedora and Ubuntu releases, and continuous profilers' advantages.",
      "The text debates the significance of eliminating frame pointers for performance, difficulties in enabling them universally, and their relevance in enterprise environments, proposing frame pointers as the default choice in corporate operating systems.",
      "It explores alternative stack traversal methods like eBPF, ORC, SFrames, and Shadow Stacks in Linux kernel profiling, advocating for a review of the decision to exclude frame pointers made 18 years ago."
    ],
    "commentSummary": [
      "The author emphasizes the significance of frame pointers for debugging and performance optimization in Linux systems, highlighting the struggle to retain them in Fedora.",
      "A comparison of diverse methods for stack unwinding is presented, alongside discussions on stack walking and profiling tools to ensure efficient software and user accessibility.",
      "The debate addresses the equilibrium between debuggability, telemetry, and enhancing performance in computing systems."
    ],
    "points": 237,
    "commentCount": 62,
    "retryCount": 0,
    "time": 1710647947
  },
  {
    "id": 39726781,
    "title": "Flash Attention CUDA Implementation for Beginners",
    "originLink": "https://github.com/tspeterkim/flash-attention-minimal",
    "originBody": "flash-attention-minimal A minimal re-implementation of Flash Attention with CUDA and PyTorch. The official implementation can be quite daunting for a CUDA beginner (like myself), so this repo tries to be small and educational. The entire forward pass is written in ~100 lines in flash.cu. The variable names follow the notations from the original paper. Usage Prerequisite PyTorch (with CUDA) Ninja for loading in C++ Benchmark Compare the wall-clock time between manual attention and minimal flash attention: python bench.py Sample output on a T4: === profiling manual attention === ... Self CPU time total: 52.389ms Self CUDA time total: 52.545ms === profiling minimal flash attention === ... Self CPU time total: 11.452ms Self CUDA time total: 3.908ms Speed-up achieved! I don't have a GPU Try out this online colab demo. Caveats No backward pass! To be honest, I found it a lot more complex than the forward pass, which was enough to show the use of shared memory to avoid large N^2 read/writes. In the inner loop, I assign each thread to a row of the output matrix. This differs from the original implementation. This thread-per-row simplification makes the matrix multiplications very slow. This is probably why for longer sequences and larger block sizes, this gets slower than the manual implementation. Q,K,Vs are in float32, unlike the original implementation which uses float16. The block size is fixed at compile time to 32. Todos Add backward pass Speed up matmults Dynamically set block size",
    "commentLink": "https://news.ycombinator.com/item?id=39726781",
    "commentBody": "Flash Attention in ~100 lines of CUDA (github.com/tspeterkim)211 points by tspeterkim 18 hours agohidepastfavorite36 comments treesciencebot 17 hours agoPretty neat implementation. In general, for these sort of exercises (and even if the intention is to go to prod with custom kernels) I lean towards Triton to write the kernels themselves. It is much more easier to integrate to the tool chain, and allows a level of abstraction that doesn't affect performance even a little bit while providing useful constructs. reply queuebert 9 hours agoparentAs a person who finds CUDA extremely easy to write and integrate, what does Triton have to offer? reply whimsicalism 7 hours agorootparentblock level rather than thread level programming, automatic optimization across hyperparameters, makes it much easier to write fast kernels reply whimsicalism 16 hours agoparentprevyeah even the official flashattention is moving many implementations from cutlass to triton except for the main mha backward/forward pass reply jart 11 hours agorootparentIt was written with cutlass? No wonder Peter Kim found it valuable and worthwhile to de-obfuscate. Adopting a new programming language invented by OpenAI doesn't sound like a much better alternative. I'd be shocked if either of them were able to build code for AMD GPUs, where it's easy to adapt CUDA code, but not if it's buried in tens of thousands of lines of frameworks. I like open source code to have clarity so I can optimize it for my own production environment myself. When people distribute code they've productionized for themselves, it squeezes out all the alpha and informational value. Just because something's open source doesn't mean it's open source. I think people mostly do it to lick the cookie without giving much away. reply synquid 51 minutes agorootparentTriton has an AMD backend, although work is still ongoing. reply ixaxaar 16 hours agoparentprevYou mean triton the inference server or triton the DSL for cuda? reply p1esk 16 hours agorootparentThe DSL: https://openai.com/research/triton reply whimsicalism 16 hours agorootparentprevthey mean the dsl (not just necessarily for cuda) reply treesciencebot 15 hours agorootparentprevtriton the DSL. reply fpgamlirfanboy 15 hours agoparentprev> allows a level of abstraction that doesn't affect performance even a little bit The second part of this sentence is true because the first part is false. reply treesciencebot 15 hours agorootparentzero cost abstractions exist. doesn't mean all abstractions are zero-cost. or being zero-cost somehow invalidates their abstractness/genericness. but maybe we differ on the definition of abstractions. reply fpgamlirfanboy 15 hours agorootparent> zero cost abstractions exist So does perpetual motion :shrug: but my point is Triton is not an abstraction in the least. Source: 1) I spent 6 months investigating targeting other backends 2) Phil himself said he doesn't care to support other backends https://github.com/openai/triton/pull/1797#issuecomment-1730... reply araes 17 hours agoprevFor those who have no idea what's being discussed, quick background. Discussing: Transformer [1] memory issues and approximate attention [2] in machine learning training. Specifically: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness. [3] As a side comment, this entire industry is sorely in need of at least intros. The entire space has moved so fast in the last year I need an entire new dictionary and thesaurus for all the terms they've created. Notably, because of this, found out Google has a glossary of machine learning terms. Actually somewhat handy. [1] Google Machine Learning Glossary (Transformer): https://developers.google.com/machine-learning/glossary/#tra... [2] Same (Attention): https://developers.google.com/machine-learning/glossary/#att... [2] arXiv: https://arxiv.org/abs/2205.14135 reply robrenaud 16 hours agoparentRegarding your comment about how fast the research and industry is moving, would HN readers be interested in relevant one or two paragraph summaries that are basically \"explain it like I am a machine learning engineer from 2020\" but also knows the power of these models from a perspective of using ChatGPT or MS Copilot? That is, assume a fair amount of technical knowledge about the fundamentals, but don't assume that the reader is paying any attention to have whitebox knowledge of the current state of the art. reply jprete 16 hours agorootparentI personally have been looking for \"explain it like I'm a CS PhD with lots of experience and the ability to look stuff up\". But I suspect your summary would be pretty handy as well. reply jhanoncomm 11 hours agorootparentI reckon you need tacit knowledge. Experience. Luckily in the order of 100 hours not 10000. Build a GPT using Python and Pytorch. For a good course: Andrej Karpathy is your keyword. At $1000 his course is great value. But actually it is free which is even better ;-) It wont take you to flash attention but will ramp you to the point you could probably read papers about it. I almost got that far then life lifed me. But I was able to implement changes to the architecture of GPT and do some “hey mum I am doing SOTA (2021) machine learning”. reply araes 15 hours agorootparentprevThat sounds at least somewhat helpful. Honestly, a gradient for some of this stuff would be nice. Explain to me like I'm: \"five\", \"a high schooler\", \"a college grad (not CS/ML/Eng)\", \"a CS/Eng not ML\". Although in a couple years, kids in restaurants will probably telling me how they're leveling up attention on their neuro-pet. The singularity is steep. reply imjonse 14 hours agorootparentsingularity implies AI increases exponentially, not human intelligence. Kids will not talk about neural nets any time soon. reply andoando 8 hours agorootparentprevI would love an explanation for software enginners / CS majors who aren't familiar with ML. Last I studied ML was 2016 and that was stuff like decision trees, k nearest neighbors... reply whimsicalism 15 hours agorootparentprevfrankly i don’t really feel like all that much has changed since 2020 except for scale reply godelski 15 hours agoparentprevZero shot is wrong, but that definition is commonly used. Zero shot is testing out if distribution, not just \"a task\" not trained on. The later is ill defined. The original definition comes from a few papers. But the classic example is a clarifier recognizing zebras but having never been trained in zebras (but may have been trained on horses). There's are out of distribution. But importantly, out of the implicit distribution, not the target distribution. The common improper usage usually confuses these two. A simple example might me training in 256x256 images and testing on 1024x1024. That's still in the implicit distribution (as long as the classes are identical). A very common example is training on a large dataset like LAION and then testing on coco or image net 1k. This is not zero shot because the classes in ImageNet are in LAION (and in Coco). Basically, this is a useless definition because then any validation or test set is zero shot because those were never seen in the training data and thus out of the training distribution. But remember that data sets are proxies for larger distributions. Where is can get sometimes tricky is tasks (emergence has entered the chat). For example, you may not intend to train a generative model to do clarification but you probably did (it's very clear -- in the math -- if you're training density models (KLD, score, etc)). This can get hairy because it's very easy to train a model to do things that you aren't realizing you are and later find out. Some people can get upset about this but it's the nature of frameworks that have low interpretability. There's still a lot of mathematics we need to learn and it tends not to be an explicit focus in ML but there are plenty in the community focused on this. reply dcanelhas 1 hour agoprevIf CPU/GPU execution speed is the goal while simultaneously code golfing the source size, https://halide-lang.org/ might have come in handy. reply danielhanchen 7 hours agoprevFantastic work! Extremely neat and clear implementation! Interesting note on the backward pass - what do you think are the main blockers for a backward pass? reply tspeterkim 2 minutes agoparentThanks Daniel. The main blocker is me not able to fully grasp the backward pass. (trying to understand Appendix B.2 in the original paper) I need to get more comfortable with matrix derivatives before I can confidently reimplement it in the same minimal way as I did with the forward pass. reply saiojd 16 hours agoprevWhat does __syncthreads() do here exactly? I'm new to CUDA, could get the overall idea of the FlashAttention paper but not the details. reply cavisne 16 hours agoparentCauses every thread in the block to wait until they have reached this point. Worth reading a cuda primer for more details on blocks/warps. Since the threads are relying on each other to fill the SRAM with all needed data if you didn’t wait then values would be missing. reply xrd 13 hours agorootparentAny CUDA primer you recommend in particular? I had this same question. reply winwang 12 hours agorootparentHere's an article on syncing in CUDA via cooperative groups: https://developer.nvidia.com/blog/cooperative-groups/ There's also explicit warp synchronization, i.e. __syncwarp(). More on warp primitives here: https://developer.nvidia.com/blog/using-cuda-warp-level-prim... reply cavisne 11 hours agorootparentprevProbably https://www.youtube.com/watch?v=nOxKexn3iBo (or just skimming the attached colab). reply xrd 10 hours agorootparentThis is terrific, thanks! reply einpoklum 11 hours agoprevMy GPU work is not in ML (deep or otherwise); but ... 1. \"100 lines of CUDA\" + PyTorch; maybe this is useful and maybe it isn't, but counting lines of code on top of a huge codebase is not very meaningful. 2. Launching separate kernels, synchronously, on the default stream, for various operations, is typically not the right way to utilize a GPU. reply chillee 8 hours agoparent> maybe this is useful and maybe it isn't, but counting lines of code on top of a huge codebase is not very meaningful. In this case it's pretty reasonable imo, since the kernel itself is fairly independent - the usage of torch is just for some bindings for the data structures. > Launching separate kernels, synchronously, on the default stream, for various operations, is typically not the right way to utilize a GPU. This is actually the standard way to do things in ML. Assuming you're from a HPC background (where this may seem quite strange), the biggest change is that \"More or less everything in ML runs on the GPU\", so there is very rarely any device to host synchronizations. In addition, each individual kernel is typically run on fairly large chunks of data (a million elements would be on the smaller side), so maximizing occupancy with streams is not as necessary as in HPC. reply zer0zzz 15 hours agoprev [–] This is fantastic. I am just starting in the ML space (compile from compilers) and I love short kernels that I can use to understand things better with. reply lagrange77 15 hours agoparent [–] > compile from compilers What does that mean? reply zer0zzz 11 hours agorootparent [–] Typo, meant to write “coming from compilers” reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A simplified version of Flash Attention using CUDA and PyTorch is created to be beginner-friendly, with a faster forward pass than manual attention, especially on a T4 GPU.",
      "However, it currently lacks a backward pass and exhibits slower matrix multiplications for extended sequences, though upcoming updates aim to address these limitations.",
      "Future enhancements entail implementing a backward pass functionality and optimizing matrix operations further."
    ],
    "commentSummary": [
      "The GitHub discussion focuses on integrating Flash Attention in CUDA, with users suggesting Triton for creating custom kernels due to its block-level programming and automatic optimization features.",
      "Users also highlight challenges with backward pass implementation and utilizing CUDA synchronization functions.",
      "Flash Attention is briefly explained as a memory-efficient exact attention technique in machine learning."
    ],
    "points": 211,
    "commentCount": 36,
    "retryCount": 0,
    "time": 1710603119
  },
  {
    "id": 39728519,
    "title": "Industry-Ready GnuCOBOL: 20 Years of Development",
    "originLink": "https://thenewstack.io/20-years-in-the-making-gnucobol-is-ready-for-industry/",
    "originBody": "ARCHITECTURE Cloud Native Ecosystem Containers Edge Computing Microservices Networking Serverless Storage ENGINEERING AI Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security OPERATIONS Platform Engineering Operations CI/CD Tech Careers Tech Culture DevOps Kubernetes Observability Service Mesh CHANNELS Podcasts Ebooks Events Newsletter TNS RSS Feeds THE NEW STACK About / Contact Sponsors Sponsorship Contributions PODCASTS EBOOKS EVENTS NEWSLETTER ARCHITECTURE ENGINEERING OPERATIONS FINOPS / OPEN SOURCE / SOFTWARE DEVELOPMENT 20 Years in the Making, GnuCOBOL Is Ready for Industry GnuCOBOL \"has reached an industrial maturity and can compete with proprietary offers in all environments,\" boasted contributor Fabrice Le Fessant, in a FOSDEM talk. Mar 15th, 2024 6:22am by Joab Jackson VOXPOP Try our new 5 second poll. It's fast. And it's fun! WASM as a Personal Project? Very frequently, almost every day Relatively frequently, a few times a week Infrequently, a few times a month Very infrequently, a few times a year Never I HAVE AN OPINION We'd love to hear what you think. Get those punch cards back out! After 20 years of development, the open source GnuCOBOL “has reached an industrial maturity and can compete with proprietary offers in all environments,” said OCamlPro founder and GnuCOBOL contributor Fabrice Le Fessant, in a FOSDEM talk about the technology. GnuCOBOL turns COBOL source code into executable applications. It is very cross-platform, running Linux, BSD, many proprietary Unixes, macOS, and Windows, even Android. And the latest version, v.32, is being used in many commercial settings. Who Still Uses COBOL? The COBOL (Common Business-Oriented Language) was launched in 1959, a high-level language primarily to serve the finance and human resources department of large organizations. Now an ISO Standard, the latest version (v 35.060) was posted in 2023. COBOL was the first modern language in one crucial respect: It was designed to be cross-platform. The U.S. Defense Department, which funded the development of COBOL, wanted to get away from the practice of supporting different programming languages for each vendor’s brand of computer. Portability was the key to COBOL’s early success. Although oft-considered a legacy language, Cobol still enjoys LOTS of use, with as many as 80 billion lines of the stuff still out there, one estimate goes. The most amazing part is that it is still growing, by 15% a year. When you use your ATM card, a lot of what happens behind the scenes, when it is not Java, is probably COBOL, said Simon Sobisch, project leader of GnuCOBOL, in the same FOSDEM talk. TRENDING STORIES Many an organization has a voluminous COBOL code base too unwieldy to migrate from. And why would they? It’s fast and reliable. COBOL deployments are now dominated by commercial vendors. IBM bundles COBOL into its mainframes. Micro Focus offers COBOL for PCs. And Fujitsu NetCOBOL runs on both PCs and mainframes. Nonetheless, Sobisch noted that the GnuCOBOL is seeing a lot of commercial deployments, such as for banking back-end apps, many of which are being migrated from Micro Focus, with users reporting performance improvements as a result. The French DGFIP federal agency moved from a GCOS mainframe to GnuCOBOL, with the help of Le Fessant’s firm. ‘Hello World’ in COBOL Originally called OpenCOBOL, the project was started in 2002 and renamed GnuCOBOL in 2013. In the past three years, it has received attention from 13 contributors with 460 commits. Most Linux package managers have a copy of GnuCOBOL for the program for downloading. Below is “Hello World” in COBOL The program is broken into three parts: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 IDENTIFICATION DIVISON PROGRAM-ID. prog DATA DIVISION WORKING-STORAGE-SECTION 01 var-string PIC X(20) VALUE \"Hello World\" PROCEDURE DIVISION DISPLAY var-string END PROGRAM prog The identification division identifies the name of the program. The data division holds the data (“Hello World”) and the procedure division contains the function. What GnuCOBOL Offers for the Enterprise Naturally, GnuCOBOL is intuitive to those familiar with the Unix environment. It can compile to C code (C89+), making it extremely portable, from mainframes to Raspberry Pi’s, Sobisch said. There have been implementations of GnuCOBOL code that run thousands of processors, which gave the developers of the project the chance to tune for performance and memory usage in large use cases. Compliance-wise, it passed 97% of COBOL 85 conformance tests, a success rate not yet achieved by proprietary vendors, Sobisch boasted. It’s got 19 dialects, including extensions of IBM and Micro Focus. There’s no support yet for objects or messages in GnuCOBOL. Objects was “a nice feature from COBOL 22, which isn’t used that much,” Sobisch said. Messaging just got reimplemented recently, and is still a new feature for the COBOL crowd to grapple with, Sobisch said. So, no support in GnuCOBOL yet. Also new is SuperBOL, a development studio for GnuCOBOL developed by Le Fessant’s OCamlPro. It runs as a VSCode Extension and features a full COBOL processor (written in OCaml). This software is still in the early stages of development, however. Finally, GnuCOBOL will be one of the languages featured in the upcoming Google Summer of Code, so a whole new generation of coders will be able to say “It’s not just COBOL. It’s GnuCOBOL.” Joab Jackson is a senior editor for The New Stack, covering cloud native computing and system operations. He has reported on IT infrastructure and development for over 25 years, including stints at IDG and Government Computer News. Before that, he... Read more from Joab Jackson SHARE THIS STORY TRENDING STORIES IBM is a sponsor of The New Stack. TNS DAILY NEWSLETTER Receive a free roundup of the most recent TNS articles in your inbox each day. SUBSCRIBE The New Stack does not sell your information or share it with unaffiliated third parties. By continuing, you agree to our Terms of Use and Privacy Policy. ARCHITECTURE Cloud Native Ecosystem Containers Edge Computing Microservices Networking Serverless Storage ENGINEERING AI Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security OPERATIONS Platform Engineering Operations CI/CD Tech Careers Tech Culture DevOps Kubernetes Observability Service Mesh CHANNELS Podcasts Ebooks Events Newsletter TNS RSS Feeds THE NEW STACK About / Contact Sponsors Sponsorship Contributions roadmap.sh Community created roadmaps, articles, resources and journeys for developers to help you choose your path and grow in your career. Frontend Developer Roadmap Backend Developer Roadmap Devops Roadmap © The New Stack 2024 Disclosures Terms of Use Advertising Terms & Conditions Privacy Policy Cookie Policy FOLLOW TNS FOLLOW TNS TNS DAILY SUBSCRIBE",
    "commentLink": "https://news.ycombinator.com/item?id=39728519",
    "commentBody": "20 Years in the Making, GnuCOBOL Is Ready for Industry (thenewstack.io)145 points by cglong 15 hours agohidepastfavorite77 comments NikolaNovak 13 hours ago>>Get those punch cards back out! I get that's (probably!) a joke, but it misrepresents COBOL as something completely stuck in the 70s. And, y'know, it isn't exactly the fanciest language in the world, but we still have several programmers on our project and they're spitting out new code every day of their life, no punchcards:). (And it's not on a mainframe either - it's running primarily on AIX, with some of Windows and Linux). reply ajxs 11 hours agoparentI've spent some time working in finance, so I've actually worked with COBOL developers personally in multiple different roles. In all those cases they were maintaining legacy applications that ran on IBM mainframes. Why would a company choose to use COBOL if they weren't restricted to what ran on IBM's mainframe infrastructure? Serious question, not an attack. I get that many of these legacy applications are some of the most battle-tested things in existence, and do what they do very well. I've seen them in action personally. However I'm also under the impression that COBOL is just not that amazing compared with modern alternatives: It's not easy to write, or maintain, and (as far as I understand) the things that make it 'fast' have more to do with the platform than COBOL itself. I'd love to know more about why someone would choose COBOL today, if anyone can fill me in. reply chasil 11 hours agorootparentWe actually rely upon two different operating environments for COBOL that do not originate from IBM. The first is OS2200. Our final major application on this platform was complete by 1970, and links COBOL into assembler that accesses the hierarchical DMS database. The first SMP port of UNIX was to this hardware: https://en.m.wikipedia.org/wiki/OS_2200 The second is VMS, specifically the VAX variety. VMS bundled a COBOL compiler, which we used to write ACMS applications. https://en.m.wikipedia.org/wiki/OpenVMS We continue to produce new COBOL code for both. reply _huayra_ 11 hours agorootparentAre you able to find COBOL programmers to hire, or is it like Rust where a lot of jobs are \"know C++ and we'll train you\"? reply 7thaccount 9 hours agorootparentMy buddy's wife has a business degree and her first company had her learn Cobol for a couple of months (never had programmed before). I'm not sure where that went after the training, but apparently it's still a thing (this was only a few years ago). reply chasil 10 hours agorootparentprevWe have several. Hiring is possible. Hiring people with experience of the respective OS is more difficult. reply nxobject 2 hours agorootparentprevIs your org considering transitioning to OpenVMS on x86? reply skissane 10 hours agorootparentprev> I'd love to know more about why someone would choose COBOL today, if anyone can fill me in. I doubt anybody is choosing to start a new greenfield system in COBOL in 2024. But, if you have an existing COBOL code base, and the business is asking for new features, you have two basic choices (1) write new modules for the existing system in COBOL (2) write the new modules in a more mainstream language (Java, C#, whatever) and have the existing COBOL modules integrate with those new modules (e.g. using REST) Both options have their pros and cons. If you aren't already doing (2), then (in the short-term at least) (1) is the easier path. reply mooreds 1 hour agorootparentTIL, COBOL has been able to make rest calls for almost 20 years: https://stackoverflow.com/questions/52136482/how-can-i-call-... reply cwbriscoe 9 hours agorootparentprevCOBOL is very easy to learn and write if you use it for what it was intended for. If you try to make a crud app or read from a web service, you are going to have a bad time. Trust me, I know. It can be done, but it is not pretty and was kind of shoe-horned in. We have been trying to get rid of all of our COBOL and get off of the mainframe (many apps have been) for the past 20+ years. We are getting closer but priorities keep changing which keeps delaying that goal. I love doing backend and db work so I would gladly switch to Go for my new projects. But, I would still need to use DB2, which (surprise surprise) is on the mainframe. reply chasil 9 hours agorootparentDb2 actually implements SQL/PSM, which is more than can be said for Sybase/Microsoft SQL Server. I'm not sure if this extends to all three Db2 variants, namely Mainframe, AS/400 derivatives, and UDB for Linux and Windows (I hope so). https://en.m.wikipedia.org/wiki/SQL/PSM IBM supposedly got the PSM code from EnterpriseDB/Postgres. https://www.enterprisedb.com/news/enterprisedb-and-ibmr-coll... https://www.internetnews.com/blog/ibm-gets-compatible-with-o... reply cwbriscoe 2 hours agorootparentThis is actually the first time I have heard of SQL/PSM. From Wiki, looks like it is for stored procedures. We do not do stored procedures at all on our DB2 instances. Heck, we don't even use triggers either. All our mainframe/DB2 business logic is in COBOL. reply lmz 8 hours agorootparentprevWhat they got from EnterpriseDB is the Oracle (PL/SQL) compatibility. SQL/PSM was built by IBM themselves. reply p_l 10 hours agorootparentprevA lot of COBOL in finance runs on x86 servers running MicroFocus Cobol on RHEL. reply vram22 6 hours agorootparentAnd on Xenix earlier, and on SVR4 and SVR3. reply NikolaNovak 9 hours agorootparentprevI cannot speak for all the COBOL implementations, but what I've seen is that a company will purchase and implement a new COTS (\"Commercial Off The Shelf\") back-office application such as ERP - Financials, HR, CRM, EPM, etc. Something that's boring to techies but critical bread and butter for a company. That application may well have some COBOL in it. It's sold as new, but such big applications will have bits that were written 3 months ago and bits that were written 20 years ago. Now the company has a shiny new application that has some COBOL. ERPs are living applications. Legislation changes, markets change, company's needs change, so ERPs are both customized and updated and expanded. So you need some COBOL expertise depending how active you want to be about it. (note: a typical techie, including myself a decade ago, will typically see insanity in this and think something like \"Payroll???? How hard can THAT be??\". Like being a parent or living through a civil war, nobody can truly explain this to another human being that hasn't been through it :-) reply lupire 9 hours agorootparentprevI understand that old programs are extremely stable, but I don't understand why they are relevant. The world changes so much, why are these programs still useful? reply NikolaNovak 9 hours agorootparentThat's a very techie view (and I speak as, largely, one:) Core accounting principles don't change so much. Core payroll principles don't change so much. Core finance principles don't change so much. We have a technology-oriented view that \"world changes so much\", but there are domains where that's true, and domains where that's not true. Several times in my life I had the luck to have a mentor ask me, when I propose some obvious technological change and improvement, \"what's the business advantage? If I let you spend X amount of hours over Y days to accomplish technical change Z, in which way will the business be better?\" In the world of startups and ___-tech, technology stacks matters and change and it's a whirlwind world of frameworks and languages and webapps stuff. But in the core, back-office, cost-centre business of the company... the rules are complicated and numerous but in a way stable enough that solid stable complex software from 30 years ago still has value. reply miki123211 8 hours agorootparentprevThe world changes little-by-little, not all at once. Let's say your application (100k LoC of Cobol) handles payroll. Your government introduces some new rules about how paternity leave should be handled. You have two options, rewrite the 100K lines into Java and add the new rule, or just add the new rule in the Cobol app. The latter is cheaper, at least in the long term, so that's what you do. Now you have 101k lines of Cobol. 20 years, four tax reforms, three mergers, five international expansions and fifty lawsuits later, you have migrated 100k lines of Cobol to Java, but your app grew and is now 3 million lines. reply inkyoto 5 hours agorootparentprev> Why would a company choose to use COBOL if they weren't restricted to what ran on IBM's mainframe infrastructure? COBOL has nothing to do with just IBM mainframes even though that is what it mostly runs on. The second big platform that runs COBOL programmes (heh, not apps!) on is OpenVMS (whatever hardware it runs on today) although the number of OpenVMS installations has seriously dwindled in the recent decade. The reason why companies no longer choose COBOL is the mostly dead ecosystem and the lack of the fresh meat on the job market as a consequence of that. If we imagine a parallel reality where COBOL is still thriving, many companies would almost absolutely choose COBOL for new projects because of its safe memory model at the very least – there is no memory corruption, no buffer overflows, no null pointer exceptions. If there are bugs in a COBOL programme, the bugs are related either to the logic or to the data handling. With most programming languages of today, you have all of that too, plus compounding memory related issues even in considered «safe», garbage collected programming languages. The business generally does not care about the art of fine programming unless it will provide a substantial ROI (e.g. vastly reduced running and operational costs or it will yield a higher revenue), so the business would absolutely choose (or consider) COBOL in such a parallel reality. reply santoshalper 11 hours agorootparentprevNobody chooses COBOL as a language for creating new systems today. It is maintenance of existing systems, primarily but not exclusively, running on IBM mainframe and midrange servers. reply stevenally 11 hours agoparentprevCOBOL is my next career move. I'm tired of these modern languages. reply airstrike 12 hours agoparentprevLet us join hands in a moment of silent prayer for those unfortunate souls reply NikolaNovak 9 hours agorootparentEh. There are ways in which their lives are easier and more zen :) reply Zenst 7 hours agoparentprevThe punched card reference is most apt for COBOL, reason being the formatting and those limits dictated the column restrictions - hence COBOL historically had 80 columns max, and code sure does legacy when it's that mature. reply riffraff 4 hours agoparentprevIt's ironic that the article later on mentions nonchalantly that there's an IDE built as a VS Code extension. reply iopq 10 hours agoparentprevAnd some of those programmers are quite lively for being in their 70s! reply NikolaNovak 9 hours agorootparentThat's just thing. I think there's this view/assumption that they're all in their 70s, and in some shops that may be the case; but this is an active system actively managed and enhanced/developed. These are normally aged developers :-) (Heck, I did about 18 months of \"some COBOL\" along other stuff for a job right out of university. It's... fine? It's a language:) reply mardifoufs 4 hours agorootparentIs it hard to recruit younger devs? Also, I heard that the hard part of using Cobol is that almost every one uses a different \"flavor\" of Cobol, with different tool chains and most of the ecosystem is proprietary. Is that still true? reply Borborygymus 10 hours agoprevIn the late 90s I worked for a vendor of CRM software. A fair bit of billing and payment-handling code was written in COBOL. Wasn't mainframe - ran on a couple of flavours of proprietary Unix. The COBOL compiler vendor was Microfocus. I didn't have any training in COBOL, but found it pretty easy to read and understand - at least for the fairly simple business logic in a billing system. I didn#t have to write anything - just do some debugging when it didn't output as expected. Wouldn't want to do anything too mathsy or heavy string processing with it, but it seemed a good fit for the application. I did some more work for the same company later. A descendent of that software is still running today. At some point between 2000 and the late 20-teens they migrated to Linux, and I think at that point used some sort of COBOL-to-C transliteration software, and the Microfocus compiler was jettisoned. Not sure if the decision was because Microfocus was very expensive (I have heard that, but have no personal experience of it), or just didn't support Linux at that time. That transliterated code is still running today, but a bit of a nightmare to maintain. If GNU Cobol has been mature enough whenever that migration happened, I suspect it would have been a much better approach than transliteration. Too late for that code base though. reply chasil 9 hours agoparentThe \"mathsy\" situation can be more difficult than most think. GNU COBOL uses GNU MP by default for calculations, instead of IEEE-754, which came decades later. Not understanding the math of COBOL has led to many failed porting attempts. https://medium.com/the-technical-archaeologist/is-cobol-hold... reply vesinisa 35 minutes agorootparentI hate that it's spam-walled but that Medium article sure was a riveting read. Basically the conclusion is that for mainframe systems that need to process lots of transactions fast the performance of COBOL is hard to beat. Languages like Java are not even very well suited for these type of calculations since BigDecimal is not part of the core programming idiom. With the additional cost that migration would carry, it's actually less risky and more cost effective to keep maintaining the COBOL system, even if it means paying in-house to train programmers in this ancient technology. reply fredsmith219 13 hours agoprevThe vast majority of COBOL in production runs on IBM mainframes in conjunction with JCL (Job Control Language). If you are looking to offload COBOL from a mainframe to a cheaper platform JCL is a must. I love that this project exists but it’s only one half of a solution to migration off of a mainframe. reply guestbest 11 hours agoparentTalking with mainframe guys for the last half decade, they seem to avoid JCL when they can and treat REXX like a super power. reply cwbriscoe 9 hours agorootparentAre these mainframe developers or system level guys. I wouldn't use REXX to run production batch processes. I would use REXX for TSO utilities and ISREDIT macros. JCL is pretty much a must for running batch processing. It is waaaaay more simpler and re-startable than trying to do the same thing with REXX. reply YeGoblynQueenne 8 hours agorootparentYes, but you use the REXX to generate the JCL. reply cwbriscoe 4 hours agorootparentHmm. I guess I am just not seeing the use case but not saying there isn't one. JCL, isn't hard to do. You usually just copy 80% of it from other jobs and change dataset names, etc... reply macintux 12 hours agoparentprevI’m unfamiliar with JCL, but from a quick search it sounds like most scripts don’t use much of the language. Still, I’d bet that most of the JCL functionality is used if you look at a decent-sized collection of scripts. How much of the full JCL do you think would be necessary to reimplement in order to get, say, 30% of the existing scripts to work? reply smackeyacky 11 hours agorootparentFrom memory of working with mainframe programmers back in the 1990s, it isn't just JCL you need. Cobol programs typically used databases and transaction monitors as well. If you're lucky the database will be one of IBM's SQL databases. If you're unlucky it will be something like IMS. reply macintux 10 hours agorootparentYou just reminded me that in the mid-90s I took a TCP/IP workshop where the other attendees worked on mainframes. The chasm between what I was familiar with and what they were was impressively wide. reply cwbriscoe 9 hours agorootparentprevI have heard horror stories about IMS but have been fortunate to never have to use it. DB2 is pretty decent and very reliable. reply chasil 9 hours agorootparentIMS is a hierarchical database. Under OS2200, DMS is also a hierarchical database, and (unfortunately) we use it. My developers have described it as the Fort Knox of databases, being very difficult to get data out. reply nxobject 2 hours agoprev> There’s no support yet for objects or messages in GnuCOBOL. > Objects was “a nice feature from COBOL 22, which isn’t used that much,” Sobisch said. > Messaging just got reimplemented recently, and is still a new feature for the COBOL crowd to grapple with, Sobisch said. So, no support in GnuCOBOL yet. COBOL 2022. My god. reply seanhunter 14 hours agoprevBut you need a modern enterprise-quality framework. Can it run Cobol on Cogs? http://www.coboloncogs.org/INDEX.HTM reply mise_en_place 1 hour agoprevIt’s interesting but will anyone actually use it? z/OS for example doesn’t have a hierarchical file system. The version of COBOL they bundle supports data sets I’d imagine. Legacy folks will be hesitant to switch to it as well. When I worked at a bank they couldn’t even use the latest Java, due to compliance and regulatory reasons. reply zulban 5 hours agoprevThat hello world program is brutal. Truly, the language is the first of its kind. Hopefully this helps fleets of developers bring their legacy code (more legacy than most of us can imagine) into a modern stack, and start applying modern SWE principles to it. reply magpi3 4 hours agoparentIt's logical and it makes sense. I would argue, at first glance, that C's hello world (#include , int argc, char ** argv, etc) would be more confusing to a total newbie. Java's even more so. reply musicale 9 hours agoprevCOBOL's boilerplate doesn't seem that much worse than what Java programmers lived with for decades. reply 7thaccount 9 hours agoparentThe big difference is I think Cobol typically (but not always) requires knowledge of the mainframe as well, while Java more or less requires some basic OS knowledge, JVM, and all the boilerplate. Edit: mainframes seem neat, but I wouldn't want to code in either personally. reply ngcc_hk 6 hours agoparentprevThey are both verbose. But cobol is more data definition oriented. reply Zenst 6 hours agoprev\"Compliance-wise, it passed 97% of COBOL 85 conformance tests, a success rate not yet achieved by proprietary vendors, Sobisch boasted.\" Thinking about that if you step back is amazing, to think a standard written in 1985 (I was doing COBOL back then into the 90s) has yet, even today not had any of the big names/players meet full compliance nearly 40 years later. I'd love to read more about that aspect reply chungy 4 hours agoparentFrom an SQL background, this doesn't really surprise me at all. PostgreSQL is the closest anyone's ever got to being fully ANSI SQL compliant, with most of the proprietary vendors having rather paltry compliance numbers. reply vram22 6 hours agoparentprev>I'd love to read more about that aspect See the DATA DIVISION. FILE SECTION. reply globalnode 2 hours agoprevone of my subjects at uni in the 90's (IT degree) required me to learn cobol. god i hated that class. thankfully i dont remember much of it. it was actually before we learn't c/c++, also VB was a big thing then too. reply rhaps0dy 12 hours agoprev> the past three years, it has received attention from 13 contributors with 460 commits. That doesn’t sound like very many commits. Pretty mature! reply ddgflorida 14 hours agoprevWell that's exciting :) reply proneb1rd 14 hours agoprevVery exotic. Does it support multi threading? What kind of things can be done with it? reply foobarian 12 hours agoparentI'm guessing it does money math in a certain way vetted by this field that would be very difficult to recertify on some replacement. reply slt2021 10 hours agorootparentnot the COBOL language, but the IBM mainframes have five nines of availability, duplication of every component, how swappable everything from power supplies to CPU and RAM. Can get to more than five nines if used parallel sysplex, but the big iron is incredibly reliable. This is the reason why all banks, airlines, and other old-school businesses have been running mainframes and cannot ever migrate off of them. this stuff was engineered like it was an airplane full of people reply Affric 9 hours agorootparentlol… this comment just makes me remember that how likely you are to die is determined by an estimate of what a company can get away with by an actuary. reply foobarian 9 hours agorootparentAnd your comment just made me wonder if the two recent Boeing crashes actually mean the IBM hardware is even *more* reliable reply slt2021 9 hours agorootparentrecent scandals with Boeing and United is the result of trump deregulating airlines. https://www.npr.org/2020/12/03/942345240/trump-administratio... a lot of regulation just became \"self-certify\" and companies obviously cut costs and outsourced everything including fleet maintenance. this article is from 2015 - but things got way worse since then https://www.vanityfair.com/news/2015/11/airplane-maintenance... European airlines and Airbus are flying just fine, it is Americans that have a problem due to over politicized and polarized society and corrupt politicians reply ralph84 8 hours agorootparentThe MAX was certified less than 2 months after Trump took office. He had nothing to do with it. reply miki123211 8 hours agorootparentprevAnd yet my bank very regularly goes down for (scheduled) technical maintenance. Most mom-and-pop stores running Wordpress on shared PHP hosting are more reliable than that. reply YeGoblynQueenne 8 hours agorootparentIt's the servers that go down! Not the 'frames. Those will go down maybe once a year for maintenance, if that. The mainframe engineers will brag your ears off about that and about the unreliability of the \"distributed\" systems (a.k.a. servers, a.k.a. what everyone else uses). When you log on to your online banking you're interacting with servers, not with the mainframes directly. The servers are the interface, the mainframe is the, let's say far back end. That will be handling millions of transactions a second while the servers are down for maintenance- like handling payments and transfers etc, not just online banking. Which is why it can't keep failing every few months or so. reply miki123211 8 hours agorootparentI definitely remember my bank warning me about credit and debit card unavailability, so it's definitely not just the online systems. If cards don't work and the online systems don't work, I don't know what else does. Those maintenance periods usually happen at night, so branches aren't open and wire transfer systems don't work. reply slt2021 5 hours agorootparentMaybe your bank goes down, but the Visa and Mastercard systems have been processing card payments 24/7 non stop and I dont even remember hearing a single incodent when system was down even partially reply inkyoto 1 hour agorootparentprev> […] my bank warning me about credit and debit card unavailability […] Your bank might have meant card balances being unavailable in the online banking which is more plausible than cards being generally unavailable for payments. It is not indicative of the mainframe actually being down (although not entirely improbable, either), and it is more likely that an intermediary (a service or a server) was undergoing maintenance. Payment processing involves multiple tiers and multiple routing layers built into it – to ensure very high availability and that a payment is almost always guaranteed to process (successfully or otherwise – does not matter). Payment networks also impose stringent technical requirements onto the banks connecting to them. A Raspberry Pi running Slackware Linux from 1993 and powered by a dangling street pole wire would not be allowed to connect, for example. Your bank (or mine, for the sake of the conversation) is the terminal point in this whole payment processing chain, with the payment network (Visa, Mastercard but not AmEx[0]) being the port of entry for a payment. Depending on the country, a country may have its own local payment Visa / MC processing centre and if that is the case, local payments will be routed to the local card payment processor. Otherwise, a global Visa/Mastercard will assume the payment. Then the payment network contacts your local bank to authorise the payment. Depending on the nature of the failure + other factors, the Visa/Mastercard can authorise certain payments on behalf of your bank if they fail to reach your bank and will forward the payment particulars onto your bank so that your bank could correctly process your card payment later. It is more common in overseas payment scenarios, i.e. you are travelling overseas and especially so when travelling outside the first world countries. Payment networks and banks do not like such situations and actively loathe non-real time payment authorisations, yet they allow them for a narrow number of use cases at their own discretion. [0] AmEx own their own global payment network and do not allow other financial institutions to gain access into it. reply jamwil 7 hours agorootparentprevThat sounds like a shit bank. I can recall only a single system-level outage at my bank in 20 years. reply lupire 9 hours agorootparentprevModern cloud backend data processing is 5 9s reliable too, for very core stuff, not all the app frontends and minor features. reply asp_hornet 8 hours agorootparentModern cloud “5 nines” isnt a promise of availability but a promise to get some store credit each month when it inevitably fails (adjusted down for usage because you dont use all that capacity you pay for so we just credit for the percentage you do). The trick is to make sure when you promise 5 9s to your customer that you build in the same bullshit clauses so you dont get left holding the bag. Its gross reply shrubble 8 hours agorootparentprevYou don't even have the assurance that the RAM is ECC on cloud... reply airstrike 12 hours agorootparentprevFor some value of \"very difficult\" reply michaelsbradley 7 hours agoprevDon’t miss the GnuCOBOL FAQ and How To, perhaps one of the largest such documents ever compiled: https://gnucobol.sourceforge.io/faq/index.html (may cause mobile browsers to crash while loading) reply xunil2ycom 8 hours agoprevI award them no points, and may God have mercy on their souls. reply asp_hornet 7 hours agoparentThis exists because most modern rewrites of COBOL systems have been rewritten several times over despite the rewrites never finishing all the functionality of the original. Modern day software engineers need to eat a huge slice of humble pie. reply mseepgood 9 hours agoprev [–] What took so long? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GnuCOBOL, an open-source programming language, is well-developed and ready for industry use, competing with proprietary options in various settings.",
      "Originally named OpenCOBOL in 2002, GnuCOBOL is now cross-platform, fast, reliable, and widely utilized in commercial applications, especially in the banking sector.",
      "GnuCOBOL is user-friendly for Unix programmers, can be compiled into C code, and adheres well to COBOL standards. It will be highlighted in the upcoming Google Summer of Code program, attracting a new cohort of developers to engage with this language."
    ],
    "commentSummary": [
      "GnuCOBOL, a modernized version of the COBOL programming language, is now available for industry use after two decades of development.",
      "Despite misconceptions, COBOL remains actively utilized in various industries, especially in legacy applications on platforms such as IBM mainframes, OS2200, and VMS.",
      "Although hiring COBOL programmers can be challenging, opportunities exist for those skilled in the language, with businesses continuing to leverage COBOL for backend, database work, especially in finance, while aiming to transition to more popular languages."
    ],
    "points": 145,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1710615728
  },
  {
    "id": 39730962,
    "title": "Enhance Android Performance Safely with Universal Debloater GUI",
    "originLink": "https://github.com/0x192/universal-android-debloater",
    "originBody": "Universal Android Debloater GUI DISCLAIMER: Use at your own risk. I am not responsible for anything that could happen to your phone. This software is still in an early stage of development. Check out the issues, and feel free to contribute! Summary This is a complete rewrite in Rust of the UAD project, which aims to improve privacy and battery performance by removing unnecessary and obscure system apps. This can also contribute to improve security by reducing the attack surface. Packages are as well documented as possible in order to provide a better understanding of what you can delete or not. The worst issue that could happen is removing an essential system package needed during boot causing then an unfortunate bootloop. After about 5 failed system boots, the phone will automatically reboot in recovery mode, and you'll have to perform a FACTORY RESET. Make a backup first! In any case, you CANNOT brick your device with this software! That's the main point, right? Features Uninstall/Disable and Restore/Enable system packages Multi-user support (e.g. apps in work profiles) Export/Import your selection in uad_exported_selection.txt Multi-device support: you can connect multiple phones at the same time All your actions are logged, so you never forget what you've done NB : System apps cannot truly be uninstalled without root (see the FAQ) Universal Debloat Lists GFAM (Google/Facebook/Amazon/Microsoft) AOSP Manufacturers (OEM) Mobile carriers Qualcomm / Mediatek / Miscellaneous Manufacturers debloat lists Archos Asus Blackberry Gionee LG Google iQOO Fairphone HTC Huawei Motorola Nokia OnePlus Oppo Realme Samsung Sony Tecno TCL Unihertz Vivo/iQOO Wiko Xiaomi ZTE Mobile carriers debloat lists Country Carriers France Orange, SFR, Free, Bouygues USA T-Mobile, Verizon, Sprint, AT&T Germany Telekom UK EE How to use it Read the FAQ! Do a proper backup of your data! You can never be too careful! Enable Developer Options on your smartphone. Turn on USB Debugging from the developer panel. From the settings, disconnect from any OEM accounts (when you delete an OEM account package it could lock you on the lockscreen because the phone can't associate your identity anymore) Install ADB (see the intructions by clicking on your OS below): LINUX MAC OS WINDOWS Download the latest release of UAD GUI for your Operating System here. Take the opengl version only if the default version (with a Vulkan backend) doesn't launch. NOTE: Chinese phones users may need to use the AOSP list for removing some stock apps because those Chinese manufacturers (especially Xiaomi and Huawei) have been using the name of AOSP packages for their own (modified & closed-source) apps. IMPORTANT NOTE: You will have to run this software whenever your OEM pushes an update to your phone as some uninstalled system apps could be reinstalled. How to contribute Hey-hey-hey! Don't go away so fast! This is a community project. That means I need you! I'm sure you want to make this project better anyway. ==> How to contribute Special thanks @mawilms for his LotRO plugin manager (Lembas) which helped me a lot to understand how to use the Iced GUI library. @casperstorm for the UI/UX inspiration.",
    "commentLink": "https://news.ycombinator.com/item?id=39730962",
    "commentBody": "Debloat non-rooted Android devices (github.com/0x192)142 points by zikohh 8 hours agohidepastfavorite63 comments morsch 3 hours agoI bought -- full price, retail -- a midrange Samsung phone for a relative recently. The amount of bloatware was incredible. Various social networks and shopping apps were preinstalled. In addition to all the Samsung apps that more or less duplicate the Google stack, poorly. The entire setup process was full of dark patterns designed to extract as much data from you as possible. No way a regular person gets through that without missing something. reply autoexec 3 hours agoparentThe first time I had a samsung phone I noticed after about two weeks that every single word I typed into any application was being collected and sent to a third party whose privacy policy said it was used to collect data about my interests, my social life, to make guesses about my intelligence level and education, and that the data would be sold for \"market research\" among other things. No user would ever suspect that the keyboard that came with their cell phone would be letting third parties read all their texts and emails to do those things. I'd assumed the keyboard was just a part of the OS. I only found out after I just happened to long press a key long enough to get an \"about samsung keyboard\" window and clicking around to find a privacy policy that said which company they were sending keystrokes to, and then reading that company's privacy policy. I immediately found an open source keyboard to replace samsung's with. I'll say one thing for them, collecting everything everyone types into their devices meant that the samsung keyboard had really good spellchecking/predictive text capabilities. I'd never go back to using it, but there are times I wish the keyboard I replaced it with had a better spellchecker. reply MaxBarraclough 2 minutes agorootparent> I noticed after about two weeks that every single word I typed into any application was being collected and sent to a third party How did you discover this? Has it been written about? Seems pretty scandalous. reply rightbyte 51 minutes agorootparentprevOh dear. I had disabled the Samsung keyboard for some other, but it seems it got reenabled again. Maybe Google broke some API endpoint and the old keyboard didn't do the update grind. No warning what so ever for their spyware taking over the keyboard functionally. The need for some FOSS mobile is really over due by now. Edit: > I immediately found an open source keyboard to replace samsung's with Which keyboard did you pick? reply autoexec 15 minutes agorootparentAnySoftKeyboard I've been using it ever since. It's got a lot of customization options and all the keys I need. reply silversmith 2 hours agoparentprevCould it be that it's a US-specific thing? My last three phones have been EU-sold Samsung S series, and the only things I'd consider \"third party bloat\" were pre-installed versions of Facebook and MS Office, both easily removable. The Samsung replacement apps is down to personal preference, I find them easier to use than Google \"originals\". Having casually interacted with phones from other brands, I consider Samsung among the best Android options as far as software and UX goes. reply morsch 1 hour agorootparentThis was in Germany, so no. It's probably a midrange vs flagship thing, or it has gotten worse over time. I had an S10 and I don't remember it being so bad. reply Flex247A 1 hour agorootparentprevI don't think it's US specific. Have faced a similar situation with the last two budget phones I bought in India. reply daniel_reetz 3 hours agoparentprevI was furious when I found out that the default keyboard was infested with Grammarly, sending all my keystrokes without consent. Embarrassing for a $1200 flagship device. reply resource_waste 2 hours agorootparentThis is a user/psychology problem. No one in their right mind is suggesting Samsung. Heck, similar to Apple, you have swaths of people warning you about Samsung. Samsung lives and dies off their huge marketing budget. Buying their phone is more of a psychology thing, than 'I did lots of research and I bought a high quality phone'. reply morsch 1 hour agorootparentI've had multiple Samsung Android devices before buying the midrange phone. The hardware, I found, was universally pretty good. They were one of the few manufacturers with a moderately sized flagship device (the new Pixel 8 also qualifies, which is great). I bought the midrange device because it was one of a few phones priced around 300 EUR with more than two or three years of updates. reply blfr 2 hours agorootparentprevI have a Samsung tablet (Galaxy Tab S9+) and I not only suggest but downright recommend it. Sure, right away I switched away from their default apps (launcher, notes, keyboard, etc) but it wasn't difficult. Maybe they got me with their clever marketing but there doesn't seem to be competitive hardware in this class (fast, oled screen, 5g, overall build quality) available from another manufacturer. reply Semaphor 1 hour agorootparentprevIsn’t it more that Samsung, almost like apple, has great cameras? At least that’s what I often heard, I don’t go near flagship devices and root everything, so no personal experience. reply tayo42 49 minutes agorootparentprevWhat android brand are people going with? I thought Samsung was the biggest alternative to pixels reply hughesjj 1 minute agorootparentI'm real tempted to go asus because of how good their other devices have been, will see what happens this time. Tired of my pixels constantly overheating when trying to take pictures after navigating to a place i want to take pictures with the 4a+5a. It's not just a bad phone, I've inevitably broken a screen or submerged one and had to replace it (apparently the ip68 isn't fool proof either..) Symbiote 54 minutes agoparentprevMy phone is Sony, and came pre installed with the Microsoft SwiftKey keyboard. > First, please note that unless you have opted in to use a Microsoft SwiftKey Account on your Android device, all personal and language data generated by Microsoft SwiftKey is stored locally on your device and is never transferred. I use it since it seamlessly swaps between enabled languages. I can write something like \"meet me at Østerport Station\" smoothly. reply resource_waste 3 hours agoparentprevI'm amazed people buy Samsung anything. I only had 1 poor quality phone that cost $400, 10 years ago, and I was traumatized. Occasionally I get a work Samsung phone and they really are the Apple of Android. reply judiisis 6 hours agoprevThis project is unmaintained since a year. For an up-to-date and maintained fork see https://github.com/Universal-Debloater-Alliance/universal-an... reply r4nd_f 2 hours agoparentThanks! reply nairboon 9 minutes agoprevI guess, the ultimate solution is to ditch Android and just use a proper Linux on the phone, once some more devices are properly supported: https://wiki.postmarketos.org/wiki/Devices reply numpad0 8 minutes agoprevRelated Android equivalent commands used in this project: `dpkg --get-selections`: `adb shell pm list packagessort` `dpkg -r `: `adb shell pm uninstall -k --user 0 ` reply bonki 4 minutes agoprev+1, I've used UAD with great success on a OnePlus. reply captn3m0 3 hours agoprevI tried one of these lists on a (just factory reset) Xiaomi. Ended up breaking on reboot - immediate crash after login, and it was unusable. Managed to fix it, but learned to be careful - what might be critical for one model might be bloat for another. reply No0op 2 hours agoparentCould you share logs with uninstalled packages led to this, please? reply captn3m0 1 hour agorootparentProbably something on https://drive.google.com/file/d/1OSw05IqGrIJSEi4xcEMiV56xw4t.... I'll try to reproduce if I get time. reply No0op 41 minutes agorootparentThank you, quickly checked. There is a bunch of risky to uninstall/disable packages here. No wonder it broke. reply wooptoo 1 hour agorootparentprevProbably the Security center or the Mi account app. It will send the phone into a reboot loop. Here's a writeup about packages which are safe to remove in MIUI: https://wooptoo.com/blog/safe-to-remove-packages-miui/ This is from a few years ago but it should still apply today. reply No0op 1 hour agorootparentThanks. Both com.miui.securitycore and com.xiaomi.account are marked as unsafe for deletion. So it was somewhat expected to break. If we are talking about right packages, of course. https://github.com/Universal-Debloater-Alliance/universal-an... reply protoman3000 46 minutes agoprevWhy is it not possible to compile and install a complete clean Android directly from the sources on your phone? What are the things that prevent that? reply kelnos 13 minutes agoparentIn general it is possible to do that (assuming the phone has an unlockable bootloader), but you can't do that for the exact same image from the manufacturer, because they don't provide the source for a lot of it. You might be able to install a third-party, community-maintained OS, like LineageOS, though, if your hardware is supported. The downside is that I believe apps like Google Pay won't work anymore, since they require Google's SafetyNet attestation system to pass. Sometimes there are ways around that, but they always seemed like unreliable hacks to me. reply bonki 7 minutes agoparentprevHardware support. reply butz 1 hour agoprevWhere one can find an up to date list of obscure packages on an Android device with short description what it actually does and the impact if it was disabled/uninstalled? I'm especially interested in possible dependencies between such packages, when uninstalling one seemingly unrelated package might break something else. reply thatloststudent 1 hour agoparentThis [1] is the list that UAD uses. [1] - https://github.com/Universal-Debloater-Alliance/universal-an... reply cf100clunk 6 hours agoprevSimilar GUI tool for debloating and customizing non-rooted Amazon Fire tablets via ADB: https://xdaforums.com/t/windows-linux-tool-fire-toolbox-v33-... reply squarefoot 2 hours agoprev+1. ADB, either directly or indirectly is the only choice to debloat Android devices. This was the case of one of my old tablets (a cheap 10'' Mediacom crap) that resisted every rooting attempt, no matter which tool I could try. Removing unneeded services and stuff became a breeze, although the process is quite dangerous and I ended up with something that can't run Google services anymore, but does run Whatsapp for the 7-8 contacts I couldn't convince to use email, and download from F-Droid, which is enough for me. reply Unbiased8678 1 hour agoparentYes, I have been using canta with shizuku that enables wireless debugging for this. https://shizuku.rikka.app/ https://github.com/samolego/Canta reply jamesy0ung 6 hours agoprevThanks for this! I was able to uninstall Horizon Feed and Social from my Quest 3 using this tool! reply KingOfLechia 1 hour agoprevThanks, but I'm still sticking with CalyxOS. reply feverzsj 2 hours agoprevIt will either make your phone unstable or do nothing significant. reply oliwarner 1 hour agoparentTell us you've never run this on a Samsung without telling us you've never run this on a Samsung. reply Repulsion9513 5 hours agoprevWhy? You can disable apps from right there on the phone, what does this add over doing that? The FAQ makes some mention of further \"uninstalling\" them from the user profiles (and deleting cache/data, which you can also do in the settings), but it's not clear to me what that means. reply cmeacham98 5 hours agoparentSome OEM bloatware apps cannot be disabled in the Android UI but can be disabled via ADB. reply pooper 5 hours agorootparentMetro by T-Mobile has some strange bloatware that I was able to disable with adb. I can't imagine living with this garbage day in and day out. Makes me wonder if this is why some people in the US believe iPhone is better than android — they've only experienced carrier bloatware infested android devices. reply hackernewds 4 hours agorootparentthis is why you get stock Android with a Pixel and Fi; although this shouldn't be necessary :( reply cwbriscoe 3 hours agorootparentYeah, this is what I have had for my past 3 phones. No bloatware issues at all. Not to mention FI is cheap as hell if you use internet mostly over wifi. reply pooper 4 hours agorootparentprevInterestingly enough, it has gotten better in the sense that I used the phone for a couple of weeks before I put in the carrier sim and the bloat wasn't there (besides some OnePlus apps but those don't pollute my notifications). Edit: bloat, not boost reply add-sub-mul-div 4 hours agorootparentprev> I can't imagine living with this garbage day in and day out. What tangible harm is it doing that makes you think you can't live with it? If there's a Facebook binary on my phone that I've never logged into, is it doing anything? Is Candy Crush playing itself in the background if I never launch it? reply pooper 4 hours agorootparentFull screen ads out of nowhere in the middle of you using other apps, Click bait \"news\". I don't think you could imagine half of what I saw. reply autoexec 3 hours agorootparentprev> If there's a Facebook binary on my phone that I've never logged into, is it doing anything? Couldn't it? Apps can start without ever being launched by the user, or continue running in the background after they are \"closed\", and that means that they can collect data then send it home or to third parties. There's a ton of things an app can do without any permissions or indicating to the user that anything is happening. It's been used for things like listening for audio beacons and reporting them when overheard. I wouldn't want to trust a company like facebook to not abuse every option available to them to collect data. There's also a problem with vulnerabilities. That \"unused\" facebook binary might contain a flaw that could be exploited. Getting rid of installed applications you don't need/want is a good way to reduce your attack surface. reply graphe 4 hours agorootparentprevNope, it is just worst. Want a smart-phone? Get an iPhone. Want a mobile Linux computer you can make calls from? Android. Android does not do the 'phone' part right. I constantly complain of a friend with his new expensive s23 or whatever that acts like a cheap phone whenever he gets in a group call and my whole group complains of the ear shattering noise and artifacts from his side immediately (nothing at all wrong with all of our iphones). It was bad enough we couldn't do higher quality facetime audio together, but the expensive phone's hardware on wasn't even good for various apps we tried to talk through. From another thread they aren't even good at web browsing. https://news.ycombinator.com/item?id=39729397 the entire ecosystem of Android is a mostly poorly cobbled together mobile Linux computer aiming to lower costs as much as possible to sell you ads. Notice how older iphones with worst specs are still working fine? Still my Samsung S3 with it's forward thinking 2gb of ram in 2012 (4x the 512 in the iPhone 4s) is still sometimes being used as a Linux computer for me in 2024. Awful mic on it then as well. reply realusername 2 hours agorootparentI have the opposite opinion. If we want to talk about bugs, I literally left the iPhone world just because of the bugs and the poor quality of the software in general. I had error loops when installing apps and the one of my wife has keyboard freeze for 4 seconds at a time. The internet is full of threads of people with this exact problem but there's never any documented way to fix anything in an iPhone, it either fully works or good luck. Sure the hardware might be better but the software though... Anything related to icloud, the appstore and the accounts themselves looks like it's holding up together with duck tape. reply graphe 2 hours agorootparentNever heard of it or seen it documented anywhere. What is an \"error loop installing apps\" and where did you see that documented? > The internet is full of threads of people with this exact problem but there's never any documented way to fix anything in an iPhone, it either fully works or good luck. Is that hyperbole? There's a video of a guy putting a headphone jack in an iphone 7. reply realusername 2 hours agorootparent> What is an \"error loop installing apps\" and where did you see that documented? I can't remember the exact error text but any attempt to install or update an app said something about an error setting up payments (even a free app) and the only way to stop this modal loop was to reboot the device. It's just in a drawer now. That kind of sums up the general experience I had with the device. For my wife's keyboard issue it's pretty random, you are typing and then the whole screen freezes for 4 seconds, when whatever you typed while frozen unbuffers all at once. I guess it's some bug in the Vietnamese IME since the keyboard needs to buffer diacritics (I'm just guessing) > Is that hyperbole? There's a video of a guy putting a headphone jack in an iphone 7. No it's just how it works in iPhone, full of random suggestions in case anything sticks because nobody has an idea on how it works and there's never any debug info. Another example, I had another error setting up the dev account, nobody knew what to do, even their own support at Apple! reply graphe 2 hours agorootparentI've never heard of it, but it sounds like a very easy fix. You can get debug info. I have copied my crash logs. If your wife's using a 3rd party keyboard they are treated worst and may crash. Android has always gotten better with their interface but they are locking more and more stuff. I would use Android if i didn't always get audio issues, I would rather use a computer with a phone, but not if the phone makes me unlistenable. Hope your Android issues are nonexistent or manageable. reply realusername 2 hours agorootparent> You can get debug info. I have copied my crash logs. Maybe you can, it just seems harder than adb since I only have Linux machines now. > If your wife's using a 3rd party keyboard they are treated worst and may crash No this is the standard iphone keyboard which is freezing the screen, I didn't even know you could have third party ones on iphones, I thought they were not allowed by Apple. I guess that changed. > I've never heard of it, but it sounds like a very easy fix. Yeah sure it can be done technically, I would have to factory reset the iPhone again and it might fix it but I really didn't want to fiddle with it anymore to make it work though, I was already tired of it. > Android has always gotten better with their interface but they are locking more and more stuff. I would use Android if i didn't always get audio issues, I would rather use a computer with a phone, but not if the phone makes me unlistenable. Personally I never encountered audio issues on Android. Except if we're talking about Bluetooth but I'm convinced it's impossible to make a Bluetooth device that works, I had Bluetooth bugs on Windows, Linux, Android and iOS. reply oliwarner 1 hour agoparentprevIt's quicker, can be run pre-setup and as others have said, can remove things that you cannot remove through the standard package interface. reply smusamashah 5 hours agoparentprevOn Android TV you can not disable/uninstall the default ad filled launcher without adb. reply userbinator 2 hours agoprevIMHO better to root if you can, since then you do get full control as the rightful owner. reply Symbiote 49 minutes agoparentSome banking apps detect this, or might detect it in the future, and refuse to work. In some countries (Scandinavia...) not having the banking app is inconvenient, as it's used for authentication with many other services. reply bonki 5 minutes agorootparentThat's a bold understatement, you're pretty much fucked without BankID on your phone. reply Unbiased8678 1 hour agoparentprevYou can't easily root your phone these unless the device is popular and has some community support. Immediately after buying I tried to root my realme gt 2 device and it got bricked. Fortunately it was under warrenty, I went to to customer support and told them it isn't booting up after an update. They fixed it with an internal tool. I haven't tried since. reply LoganDark 6 hours agoprev [–] > you CANNOT brick your device with this software! Disable Knox on a Samsung device and it will brick itself. Luckily when this happened to me I was still connected over ADB, able to re-enable it and the device unbricked reply ycombinatrix 4 hours agoparent [–] if you were able to reboot the device, was it really ever bricked? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Universal Android Debloater GUI is a tool designed to enhance privacy, battery life, and security on Android devices by eliminating unnecessary system apps.",
      "Users should use it cautiously to avoid potential bootloop issues if critical packages are deleted, as the software is still in its early stages of development.",
      "It provides options like uninstalling/disabling system packages, supporting multiple devices, and offering debloat lists for different manufacturers and mobile carriers, with recommendations to backup data, review FAQs, and keep abreast of OEM updates for smooth operation."
    ],
    "commentSummary": [
      "Github users are deliberating bloatware on non-rooted Android devices, specifically Samsung phones, highlighting privacy worries with default apps and discussing building a clean Android OS from source.",
      "Discussions cover experiences with different brands, software setups, debloating techniques, caution against disabling apps, and compare iPhones with Androids, including freezing screens, keyboard glitches, and debugging challenges.",
      "The debate also touches on the risks of rooting devices, emphasizing the necessity of a banking app for authentication."
    ],
    "points": 142,
    "commentCount": 63,
    "retryCount": 0,
    "time": 1710637745
  },
  {
    "id": 39728994,
    "title": "IBM 360 Project in UK Seeks New Home",
    "originLink": "https://www.ibm360.co.uk/",
    "originBody": "The 360’s are searching for a new home Adam Bradley / March 16, 2024 Hello! If you’re still here reading this blog, I’m impressed. We haven’t posted anything of note for some years now and frankly, thats because we haven’t done anything of note with the project. The machines have been sitting in their home, virtually untouched, for 4 years now. Chris & I (Adam) are just too busy with our respective professional and personal lives to give them a second look, and we’ve come to the difficult decision that it’s time to look at letting the systems go. When we originally moved the systems to Creslow, part of our agreement was to provide PR visibility for the services offered by ecom. Whilst this initially obviously garnered some visibility, our lack of progress with the project has obviously had… Continue Reading→",
    "commentLink": "https://news.ycombinator.com/item?id=39728994",
    "commentBody": "IBM 360 in UK need a home (ibm360.co.uk)138 points by ngcc_hk 14 hours agohidepastfavorite15 comments chasil 11 hours agoDoes the Hercules emulator have all the firmware from these systems (and peripherals) in their collection already? http://www.hercules-390.eu/ I know there was specific microcode here: https://news.ycombinator.com/item?id=30073973 reply monocasa 8 hours agoparentThe 360 model 20 isn't actually a 360 compatible system. It's a 16 bit subset 'inspired by' the 360. reply ngcc_hk 8 hours agorootparentYou are right it is a subset. Not sure it is totally true it is incompatible though, but do have some incompatible instruction. It is the most numerous 360 computer installed, more than 7000. See https://en.wikipedia.org/wiki/IBM_System/360_Model_20 . It is sad to let these go as part of computer history. reply monocasa 8 hours agorootparentIt is incompatible. For one example, it doesn't have registers R0-R7, using those as encodings as additional address bits. It also doesn't have the top half of registers R8-R15. reply KerrAvon 4 hours agorootparentprevThe original intent IIRC was the programs for the model 20 would be upwards compatible with the rest of the series, but that the higher level models would not be downward compatible with the 20. No idea if that ended up being achieved. reply pinewurst 11 hours agoparentprevHercules doesn’t emulate at the microcode level. It implements the appropriate instruction set(s). reply chasil 10 hours agorootparentReading a little deeper into the previous HN post, this one does: https://static.righto.com/360/ reply kens 10 hours agorootparentTo clarify, that is an emulator specific for the IBM 360/50 that runs the microcode. It is a demo, not a useful system. It has nothing to do with Hercules. reply chasil 9 hours agorootparentAnd thank you for writing it. reply tivert 3 hours agoprev> 1x 2152 System Console (possibly the last remaining example of this in the world, though in poor condition) > 2x 2415 II Tape Drives (One master, one slave) (Possibly only remaining examples of this model globally) Any pictures/info on those things? \"Last example in the world\" is pretty interesting and I guess urgent to see. I hope the Computer History Museum buys it, and fixes it up for live demos. The IBM 1401 they have is cool, but I kind of think an IBM 360 would be cooler, given its historical importance. reply darreninthenet 25 minutes agoparentIn case they hadn't seen the article, I sent it to the senior curator... fingers crossed reply spzb 12 hours agoprevhttps://archive.is/5Uqf8 reply FLT8 5 hours agoprevI wonder if Sam of \"look mum no computer\" fame from YouTube might be interested for his museum (\"this museum is not obsolete\"). He's shown a fascination with and aptitude for all kinds of old tech, although he does tend to focus a bit more on equipment that he can make music with. reply _V_ 11 hours agoprev [–] I would love to take atleast one of these & try to restore it... Such a beatiful piece of engineering (and history)! reply neom 9 hours agoparent [–] Looks like they ran a Puma factory/office of some descriptions, would be very interesting to see what the software they made for them does. https://www.ibm360.co.uk/?page_id=22 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The creators of the 360 project, Adam and Chris, are looking for a new home for the machines that have been idle for four years due to their busy personal and professional schedules.",
      "Their inability to advance the project has impacted their commitment to promoting ecom's services through PR visibility.",
      "Adam and Chris are contemplating parting ways with the systems due to their prolonged inactivity."
    ],
    "commentSummary": [
      "The HN forum is debating the availability and compatibility of the IBM 360 Model 20, sparking interest in acquiring and restoring these historical systems.",
      "Some users are hopeful that the Computer History Museum will purchase them, sharing resources and discussing potential uses in music production and exploring the software they once ran."
    ],
    "points": 138,
    "commentCount": 15,
    "retryCount": 0,
    "time": 1710619213
  },
  {
    "id": 39731195,
    "title": "Reassessing the Role of Testing",
    "originLink": "https://registerspill.thorstenball.com/p/a-few-words-on-testing",
    "originBody": "Share this post A Few Words on Testing registerspill.thorstenball.com Copy link Facebook Email Note Other A Few Words on Testing Or: Losing Faith Thorsten Ball Mar 16, 2024 14 Share this post A Few Words on Testing registerspill.thorstenball.com Copy link Facebook Email Note Other 4 Share First, my credentials. More than half of all the code I wrote in my life is test code. My name is attached to hundreds of pages of TDD. In my first internship as a software developer I wrote tests and did TDD while pair programming in my first week. I’ve written unit tests, integration tests, tests for exploration, tests to stop problems from reappearing, tests to leave a message, tests using testing frameworks and BDD and no framework at all, tests in Ruby, JavaScript, C, Go, Rust, Scheme, Bash. After two drinks, I’m willing to say that I know more about testing than many others. Right now — no drinks — I’m willing to say that I love testing and that writing tests has brought me a lot of joy. Yet I can no longer say that I’m free of doubt. To stick with the theme: I’m much more sober about testing today than I was ten years ago. Recently, in the past few months, the doubts have grown. Too many flaky tests. Too much time spent getting the tests to pass after making a tiny change that I knew was correct but the tests didn’t. Too many integration tests that made people wait 20, 30, 40 minutes until they could merge their change, only to reveal — months later — that they never tested anything. Too many times have I fixed a bug and knew it was fixed because I tested it manually, thoroughly, and was 100% sure that I know how the code works and that this can’t happen again, but then spent hours — 10 times longer than it took me to fix the bug — to write a test only to prove what I knew all along, that the bug is fixed. It’s not that I was ever a capital-b Believer in tests. I never believed in testing coverage as a metric, never really cared whether someone wrote their tests first or last (although I think too few people have seriously tried TDD), came to think that most discussions around functional vs. intergration vs. whathaveyou tests are a big misunderstanding and that people who say you should never hit the database in tests should get real and probably haven’t written enough tests yet. Still, I’ve always thought of tests as good and untested code as bad. Whenever I merged something that didn’t have a test I felt guilty, even when deep down I knew that the test might not be worth it. Tests, I thought, are a sign of quality and the better tested something is, the higher the quality of the product. Enter Ghostty and Zed. Both are among the highest-quality software I have ever used and hacked on. Both have less tests than I expected. Both do have tests, of course. Ghostty has extensive tests for its core: the terminal state, the font rendering, the parser of escape and control sequences, and so on. Zed also a lot of tests for its foundational data structures — the rope, the SumTree, the editor, and so on — and tests for big features, and very smart, very cool property tests for async code. But neither codebase has tests, for example, that take a long-ass time to run. No tests that click through the UI and screenshot and compare and hit the network. Zed’s complete testsuite takes 136 seconds to run 1052 tests in CI. Ghostty’s takes 38 seconds, including compilation. Many tests, but less than I thought. In both codebases I’ve merged PRs without any tests and frequently see others do the same. And the world didn’t end and no one shed any tears and the products are still some of best I’ve ever used and the codebases contain some of the most elegant code I’ve ever read. So now I’m writing this and it feels like a confession to say that I’m beginning to think that maybe there’s no correlation between software quality and tests. Maybe the tests are only a symptom. A symptom of something else that causes the quality. Maybe the wisest thing about testing that’s ever been said and maybe the only thing that you need to know about testing — forget about the testing pyramids, and the mocks vs. stubs debates, and the dependency injectors, and the coverage numbers — is what Kent Beck said 16 years ago in an answer on Stack Exchange: I get paid for code that works, not for tests, so my philosophy is to test as little as possible to reach a given level of confidence […]. If I don’t typically make a kind of mistake (like setting the wrong variables in a constructor), I don’t test for it. Maybe that’s all you need. That and people who give a damn. Thanks for reading. Subscribe here if you don’t think it’s weird when someone writes about the automated testing of software and uses a word like confession when doing so: Subscribe 14 Share this post A Few Words on Testing registerspill.thorstenball.com Copy link Facebook Email Note Other 4 Share",
    "commentLink": "https://news.ycombinator.com/item?id=39731195",
    "commentBody": "Losing Faith on Testing (thorstenball.com)134 points by ben_s 8 hours agohidepastfavorite82 comments throwaway74432 4 hours ago>I get paid for code that works, not for tests A blog post could be written about just this statement and how it contributes to a low trust workplace where those who cut corners are favored by stakeholders and everyone else is left scrambling to clean up the messes left in their wake. If you're writing code for yourself, sure, be targeted and conservative with your tests. But when you're working with others, for goodness sake, put the safety nets in place for the next poor soul that has to work on your code. reply makeitdouble 2 hours agoparentThat quote is totally true though. Ultimately, tests are there to make sure code works, not for tests' sake. The rest of the sentence you're quoting being \"so my philosophy is to test as little as possible to reach a given level of confidence\" Overall the approach in the OP looks to me like a decently balanced take, trying to aim for enough tests without excess. reply MaxBarraclough 28 minutes agorootparent> tests are there to make sure code works, not for tests' sake. It works is awfully imprecise. Are you talking about perfect code? Some specific use-case? Some project-specific level of quality? Ordinary (non-fuzzing) tests are generally there to help protect against regressions when changing existing functionality, or to offer baseline quality assurance for new functionality. They can also be helpful in, say, determining whether the code behaves as expected when using a different compiler. They aren't normally how you discover a long-standing bug. There's always more to software quality than just testing. reply godelski 2 hours agorootparentprevIt's impossible to prove that code works. But tests are a strong indicator and at least put bounds on where the program does work. If you're paid to write code that works, you're paid to write tests. This is fairly standard in every other engineering field. reply saurik 1 hour agorootparentYou can at least try to prove the code works, and you can get a lot further than people seem to bother. Hell: even just using a language with types--which many people don't do--is a form of invariant that proves away a lot of potential bugs you would otherwise have to test. And like, we absolutely have proof assistants and model checkers and more advanced languages with dependent types (even C++ can do a lot more than many languages due to how it can template over values, which includes stuff like the sizes of buffers on which it can do math at compile time, but we should be spending more time coding in the like of Coq/Idris/Lean)... let's not normalize a world in which people entirely give up on formal correctness. The problem with tests is that people use them as a crutch to not have to even just prove to themselves in their head -- much less to someone else or in a way that can be checked by a machine -- why their code does or doesn't work... they just throw together a ton of tests and if they hammer the code and when the tests stop failing they proudly announce \"I guess it works now\" and move on. My challenge: try to code for a while with the mentality that every every time you stop typing to test it or run and it doesn't work (including \"my tests failed\"), that is a serious problem that should be avoided. Instead, try your best to make it so the first time you get around to testing your code it works because you are that confident in how it works. reply makeitdouble 2 hours agorootparentprevThis is the kind of shortcut that gets easily forgotten after a while IMHO. Why you write tests is important, and for instance coverage numbers are not that. Most automated coverage assessments still won't guarantee you're testing all the critical patterns (you just need enough to touch all the paths) and a low number doesn't always mean it's not enough. I understand the use as an heuristic's, but as it gets widely adopted it also becomes more and more useless. I mean, today we see people eyeing at LLMs to boost their coverage numbers automatically, and that trend of writing low effort tests has been going all for a while IMO. reply ffsm8 1 hour agorootparentIt's like that common misconception about the testing pyramid. The reason it's smaller at the top isn't because you should have numerically more tests at the bottom then at the top. It just shows that if you're doing a higher level test, you're also testing the layers below this. As an unrealistic example: if you'd have 1 IT and 1 UT, you'd still have double coverage at the bottom. You're probably still gonna create more UT then ITs though, as they're easier to write... so this is probably more academic pedantry then anything insightful reply godelski 2 hours agorootparentprev> I understand the use as an heuristic's, but as it gets widely adopted it also becomes more and more useless. I too am a big fan of Goodhart's Law. It seems many took this as advice and not a warning. reply mkl95 2 hours agoparentprevAt my current company we have pretty high test coverage. The test suite also happens to be full of mocks plus some cargoculted antipatterns that make many tests useless. The engineers who actually test their stuff can be counted with one hand. reply stouset 1 hour agorootparentI see this so often. Mocks and stubs get used all over the place because nobody understands what it means to write code that’s easily testable. They’re great when used correctly (e.g., remote services or inherently stateful APIs like time). But they almost never are. You end up with tests that ensure one and only one thing: the code is written the way it’s currently written. Tests should do two things: find unexpected out-of-spec behavior, and prevent regressions during the course of editing and refactoring. These overly-mocked tests by definition can’t do the first one and they actively inhibit the second. They have negative value insofar as they constantly trigger failure while making completely benign edits. reply th3byrdm4n 1 hour agoparentprevThis assumes useful tests. There's a false equivalency drawn between writing tests means you wrote good code. In reality, those who can write good tests can also write good code. My rules of thumb: \"Be a goldfish\" - Forget everything you know about your project, is it complicated, non-intuitive? Tests + clear documentation. But don't test for stupid stuff. AI's already generate+test the stupid stuff for us anyway ... why are we writing it reply kmac_ 1 hour agorootparentExactly this. Most of the tests reimplement the implementation using mocks. Such tests are useless, as they always prove the code is correct. Worse, such tests make refactoring much slower. On a low level, only black-box interface tests make sense, and on a high level, use scenario testing. The implementation has to be tested indirectly, otherwise, it leaks. reply godelski 2 hours agoparentprevI think another blog could be similarly written on \"don't fix it if it ain't broken.\" Fixing things before they are broken is substantially cheaper and takes far less time. But it is far easier to push off. Maintenance and fixing things BEFORE they are broken is key. Of course, not everything needs to be fixed. But many sayings are often taken too literally. reply peteforde 5 hours agoprevI'm shocked by how many developers check in code that passes the tests but they have not actually tested to make sure it works. Also, I'm tired of people not factoring in (and not honestly reporting) the time and frustration spent yak shaving to keep testing infrastructures working. I believe that it's because folks convince themselves that to acknowledge time lost to the ritual preparation for testing is a kind of weakness because other people aren't having those problems because surely you'd hear more about it. In reality, you can only write tests to cover the cases you anticipate. Correlating test coverage with reliability can be deadly; instead of losing sleep, periodically make sure that you can restore your backups to a production state and maybe even run some drills to see how your team responds when an unanticipated problem arises. reply Gigachad 5 hours agoparentTests are unbelievably useful for updating libraries. Every time I update rails I see a ton of specs fail all over the app highlighting breaking changes not mentioned in the docs. Stuff that is impossible to anticipate otherwise. reply bschwindHN 5 hours agorootparentThis is where a nice type system and compilation checks in CI are very useful to have. reply Gigachad 4 hours agorootparentI agree a type system does wipe out 80% of the tests you need, but I still feel like the 20% is useful. You can just write tests that verify the output looks right without having to run every single line of code to make sure there are no typos or type issues. reply 1propionyl 4 hours agorootparentprevTypes don't replace tests. Tests don't replace types. For either statement to be true, they would have to be entirely equivalent, at which point it would be a distinction without a difference to complain about. And last I checked no type system automatically generates and minimizes failure cases. And last I checked no test system can be used to formally prove anything about the behavior of code. reply MrJohz 3 hours agorootparentThe two are definitely not equivalent, but they overlap. Types can replace tests - if an edge case exists but I can define it out of existence with my type system, then I no longer need tests for that case. And likewise, tests can replace types - I can use dependent type systems to define invariants in my system but at a certain point it becomes so unwieldy that it's easier to use tests to define those invariants less formally. In the end, they're just two different tools that both serve the overall aim of software correctness. Demonstrating correctness with one tool may be easier but less thorough, or more complicated but more precise, or whatever else. In this context, if you can get the type system to help you, you'll be able to get away with a lot fewer tests because you don't need to test things like \"does this function call a method that actually exists?\" or \"what happens when this function is passed bad data?\". reply JoeyJoJoJr 2 hours agorootparentprevWhy does the statement need to be either true or false, and why would tests versus a type system have to be entirely equivalent? The parent comment mentioned that 80% of tests can be eliminated with a good type system, not that a good type system can entirely replace tests. IMO working with a good type system for a decent length of should absolutely make it apparent that a whole host basic but pervasive errors are practically eliminated, or at the very least heavily mitigated. Silly errors like thinking an array of numbers is just a number, or an Id is a string instead of an int. Every developer I have ever worked with makes these mistakes all the time, especially the developers that say they have never needed a type system or that type systems somehow limit the expressiveness of their code. I would really like to know if there is an efficient way to write tests that can adequately cover these silly errors without over burdening the codebase with heaps of extra test code that causes rigidity and friction for refactoring. reply godelski 2 hours agorootparent> Why does the statement need to be either true or false, They never said that btw. They said for a logical system you'd need \"types replace teststests replace types.\" While I don't agree from a mathematical point, their meaning is clear enough. It's clear that you can have typed systems and still need tests and well... tests obviously don't enforce types. Plus, how does everyone in CS not know that logic systems are not binary but tertiary? reply kaashif 2 hours agoparentprev> passes the tests but they have not actually tested Surely this is a problem with the tests then? Whatever manual steps you're referring to with \"actually tested\" should be automated and part of the test suite. Much easier said than done in some cases obviously, but I've seen some cases where people were manually doing things to \"actually test\" their code that could obviously and easily be automated. reply masklinn 2 hours agorootparent> Surely this is a problem with the tests then? Whatever manual steps you're referring to with \"actually tested\" should be automated and part of the test suite. As far as I know there is no real way to automate ensuring that the code being submitted is tested. Coverage gates are the closest, and coverage is routinely decried on this here site. The only thing that actually comes close is a very strong type system obviating most tests… but not all, and we’re back to square one. Then there’s the issue of tests testing something useful, yet not over-testing. reply makeitdouble 2 hours agorootparentprevI can relate to the issue: tests work with specific check conditions, and there might other side effects that are not critical to the test but still impacting the user. For instance a page that properly loads, but surprisingly slowly. If you had no requirement of speed and it still loads within the test timeouts, it will pass fine, but a manual check would have raised the issue and perhaps underlying well hidden bugs. reply misternugget 2 hours agoparentprev> I'm shocked by how many developers check in code that passes the tests but they have not actually tested to make sure it works. That's actually one of the other topics I wanted to write about yesterday. Chose to write the article above instead. Yes, 100%. I've seen it many times: manually testing reveals more in 1min than hours of previous discussions/reviews/test-writing. reply godelski 2 hours agoparentprevI'm with you in spirit but I'm not shocked given how many people say that they don't need to write docs because their code is so well written that it is self documented. Which tells me your code is any combination of 1) spaghetti 2) highly unoptimized 3) a holy piece of text. What's the saying? 30 years of improvements in programming has completely undone 30 years of improvements in hardware? Moving fast and breaking things is great to get going, but eventually someone has to come around and clean up all the mess. reply makeitdouble 1 hour agorootparentI never heard people say their code was well written (I wouldn't personally), but many of us have stopped reading docs and comments outside of specifically added ones in surprising locations and vendor provided doc. Many orgs have mandatory docs and comments, yet the devs find nothing specific to write about (they already wrote design documents), and deeply down in their heart don't want to maintain it either. So you get bland and sometimes inane docs and comments, with a bunch of it going stale for a combination of reasons. To the point where you feel you lost your time reading that prose 9 times out of 10, when it wasn't straight misleading/factually wrong. It takes real dedication, discipline and talent to have good documentation, and I wouldn't expect any random dev org to be able to pull it off. reply godelski 46 minutes agorootparent> I never heard people say their code was well written It's shockingly common...[0] TBH there's very few people I've worked with that document, comment, or any form of help. You can see in that thread that much of my frustration in work (including big tech) is that people hand be aliases and call them scripts or hand be hard coded spaghetti and expect me to figure it out without handing over any of the files. But I'm also a researcher, but I have worked on some projects in big tech and this happens more. > It takes real dedication, discipline and talent to have good documentation, and I wouldn't expect any random dev org to be able to pull it off. I don't disagree, but I think writing docs makes a better programmer. You have to think more about your code and methods. It's like the Feynman technique of learning: teach others. I generally write docs for myself because I need to remember. Because writing comments helps me not rush and think a bit more about what I'm doing and where I'm going or could go. As a researcher I'm changing what I'm doing all the time so the latter is quite useful, thinking what I'm going to come back and hack on and making it easier or providing myself hints to come back and rethink. You're right, it takes more time, but often it is faster too. I definitely think it has made me a substantially better programmer and why shouldn't it? A professional athlete reviews their performance, analyzes, criticizes, and rethinks their plan of attack. Are we not doing the same to better ourselves? I hope the pay we get is enough to not just check out and coast but I don't want to be average. I want to be better than I was a month ago. [0] https://news.ycombinator.com/item?id=39476290 reply Jach 5 hours agoparentprevIt amazed me when a dev on one of my teams put up a code review, no tests (to be added \"during the QE pass later\" (a practice that itself has issues but in this case was at least plausible)), but from my quick inspection couldn't possibly work. So I download the patch, built it into my local app, test it.. and yeah, it doesn't work. At that point it was faster for me to actually make it work and just submit the new diff instead of do the back-and-forth dance over code review. My team did pretty good on reporting the time spent (sunk) to BS like infrastructure, flaky tests (especially those involving complex selenium automation which additionally suck for speed because they require the whole app to be running), and out-of-our-team's-hands problems in the wider company. I think it helped that the most senior devs ran into the same problems and felt fine complaining about them as a way to explain why something is taking longer than might otherwise be expected. We also had interns every summer to run into problems that hadn't been fixed and we had just grown accustomed to or found our own mitigations. Sometimes it's just a knowledge issue, being honest about it means someone might be able to help. Even new members with \"lead engineer\" in their title can learn new things that were taught to the last crop of interns and be more productive. There is a downside risk in that the excuses can be taken advantage of and someone can get away with doing pretty much no code work for days. The excuses can also be taken advantage of to get some various work in that doesn't nicely fit into its own work ticket, though... Some slack in orgs is important and comes in various forms. Property testing helps cover some cases you don't fully anticipate. It's worth integrating a library (https://hypothesis.works/articles/quickcheck-in-every-langua... is old but at least points to a bunch for different languages) into the automation infrastructure even if it's not used all that often. reply lowbloodsugar 3 hours agoparentprevThey've written tests, but not verified that the tests work. Specifically, not verified that the tests can detect the failure mode they claim to. reply brabel 1 hour agorootparentYou must always verify the tests pick up whatever it is they're testing, you do that by intentionally asserting a wrong value, or running tests before the bug was fixed, for example... it's not hard. reply rpigab 55 minutes agoprevAt home, I only test parts of code where I think I need it, like regexes. At work, as a web developer in Java Spring, I am required to have at least 80% coverage, enforced by Jacoco and tracked in Sonar. This means that if I write a method in an adapter that accepts a single parameter and only makes a single call to another method on some repository passing the parameter to it without transformation and returning the result, I must write a test for it, with Mockito. At this point I'm not testing my code, I'm testing the Java API itself and the JVM it's running on, which I find hilarious. I'm hoping one day this kind of test fails, which will mean that Java does not garantee that reaching a method call will result in a method being called. reply tracerbulletx 6 hours agoprevAgreed, writing a core system component that isn't going to change and be called from thousands of different places? By all means heavily test and fuzz and cover the entire API surface. Writing some product feature that is probably going to be changed 1000 times and is at the edge of the system, waste of time. You'd be better off just having really good metrics and alerting for system degradation that measure actual business metrics, staggered canary roll outs, and easy rollbacks. reply norir 5 hours agoprevI have maintained a widely used (250-500k+ unique ip dl/month consistently over the last 6 years) interactive terminal program that had essentially no tests of its interactive behavior. Building and restarting the program took a minimum 15 seconds no matter how trivial the change. It became an absolute nightmare to work with and I eventually stopped contributing because it was so frustrating to work with. Writing good automated tests for interactive programs has to be done from the beginning or it will be almost impossible to effectively add later. To test an interactive program, you need to be able to simulate input and analyze the output stream. This can be done efficiently and effectively but again only if the program is designed this way from the beginning. At some point, if they continue on this trajectory, I would expect zed will end up in a similar state to the program I described above. It will become extremely difficult to reason about the effects of ui changes and very painful to debug and troubleshoot. Regressions will happen because relatively common cases (say 1-5% of users) that the developers themselves don't regularly use will not be noticed. Bug fixing becomes a game of whack a mole as manual changes to fix one case break another without your noticing. I hope they're able to avoid this fate because it was hellish for me. reply canucker2016 1 hour agoparentOne of the scariest stories I've read on HN - the amount of technical debt must be staggering... see https://news.ycombinator.com/item?id=18442941 - a day in the life of an Oracle DB developer. reply Anon_451 4 hours agoparentprevAh, my sweet summer child. I work for a division of a Fortune 500 company with a multi-billion dollar per year marketshare. A rebuild requires at least 15 minutes. A clean build takes up a full hour. But it gets even better. Since it's firmware we have two types of builds, a \"simulator\" build needed to run the unit tests and an \"emulator/engine\" build to see what the change actually does. Any change requires testing both. The latter requires checking out a device (in the rare event one is available) (and entering one's credentials for the 10th time for the day) and going through an arcane telnet ritual to get the firmware on the device, which easily eats up at least 10 minutes. Then one must connect to the device's on-board HTTP server to verify the changes, but it takes a good while for the server to come up, requires another password and slowly chugs between page changes. Once one has verified both builds, it's time to create a PR, but before a human will look at it one must queue up a preintegration test which will build the changes on every single product and run every single unit test, a process which easily takes hours and will invariably come back with failures because nobody knows how to write correct multi-threaded code. After getting the results and human approval, then it's off to integration, which again builds on every product and test, but with a handful of other peoples' PRs, so if somebody screws up you get to start again. Gods how I wish I was on a codebase that took 15 seconds to build and run. reply throwup238 4 hours agorootparent> multi-billion dollar per year marketshare At some point you have to wonder if it's worth it. reply natmaka 3 hours agorootparentIndeed, as we usually focus on economy of scale and neglect the law of diminishing returns. reply jonathankoren 5 hours agoparentprev>Building and restarting the program took a minimum 15 seconds no matter how trivial the change. It became an absolute nightmare to work with and I eventually stopped contributing because it was so frustrating to work with. Wait. You’re complaining about a 15 second compilation and startup loop? Don’t take this the wrong way, but I don’t think compiled languages are for you. reply preommr 5 hours agorootparentThat's very unhelpful. I abhor long compile times and I exclusively use staticly typed, compiled/transpiled languages. The solution isn't to just shrug it off, but seriously evaluate how difficult it would be to refactor to smaller modules and if the benefits would be worth it. Sometimes, it's not worth the hassle. But if it's getting to a point where velocity is a concern, and a potential major version is on the horizon, a refactor to reduce code debt, and make things modular can be a real possibility if explained correctly to the right stakeholders. reply jonathankoren 2 hours agorootparentIt’s not meant to be helpful. It’s simply the truth. They’re literally talking about 15 seconds. I’m sorry, but if you’re looking for subsecond compile times, you’re simply not going to get it in C, C++, Java, or really any statically typed compiled language for any project that isn’t trivial —- no matter how many dynamically linked libraries you break your project up into. They want a REPL, and they’re just not going to get one while dealing with these technologies. Even your idea of creating a million tiny libraries to achieve less than 15 second compilation and launch time is insane, because now you’ve just “solved” developer efficiency by creating a deployment and maintenance nightmare. It’s not a serious solution. reply lelanthran 45 minutes agorootparent> m sorry, but if you’re looking for subsecond compile times, you’re simply not going to get it in C, C++, Java, I always get subsecond compile times when actively working in C, until headers are changed. Single files take milliseconds to compile, and you ordinarily aren't changing multiple files at a time. A 2000 line module I was working with was compiling in about 20ms, with a clean performed beforehand. My last project, around 10k sloc in about 6 modules compiled and linked in under 1s. The exception to this is embedded environments which run cmake more often than required (specifically the ESP32 IDF) or similar. reply brabel 1 hour agorootparentprev> Don’t take this the wrong way, but I don’t think compiled languages are for you. You just need an adequate build system that can perform incremental compilation and does not run a whole lot of unnecessary steps on every build no matter what changes. Where I work, our system is huge and includes code written in multiple languages. A change to a \"leaf module\" (one which is not depended on by many modules) takes a second or two. You only get into 10s of seconds if you change code that affects the external API of a module which triggers the re-build of many other modules (a \"core\" module) - because in such case there's no escape and many LoC must be re-compiled to verify they still work. To keep it this way is not easy: you must constantly fix mistakes people make often, like add a new build step which runs unconditionally - everything should run conditionally (normally on whether its inputs or outputs were touched), and optimise things that take too long (e.g. slow tests and moving code that changes often from core to a leaf module). reply vegetablepotpie 6 hours agoprevThere’s a flip side. A culture that thinks end-to-end testing is the only legitimate way to test a system and that TDD is an unnecessary expense that is neither necessary nor sufficient for success. That culture is right, but it’s also wrong [1]. Although it is true that you can spend most of your time testing, providing little value, it’s equally true that with any software system, that by developing it, you will break it in subtle ways; ways in which you could spend weeks fixing bugs you introduced and fixed before, therefore creating little value. Unfortunately there is no substitute for critical thinking when engineering. This piece says we need to practice critical thinking with tests and that having a test that moves a mouse and clicks to confirm functionality, with suites that take 40 minutes to run, is going too far. Ball cites two examples of projects that strike a balance in testing speed and coverage. But how do we achieve this? I used “culture” in a specific way to describe working environments. Culture, not process, politics, or incentives, drives how you do testing. A culture is an environment that has preferences. A culture that will generate good tests is a culture that values technical rigor. Rigor is important for forging tests, but it’s also important for removing tests. To make these good test suites, we need to be comfortable with removing tests, but more importantly understand why a test is needed and remove it when we can’t explain it. [1] I’m not going to say there’s a “balance” to be struck, because that’s the language of people who say we should not write any tests. reply ChrisMarshallNY 20 minutes agoprev> people who give a damn. That’s the money shot, in my own opinion. I write a lot of tests[0], but I am also constantly testing my work, even after shipping (in my latest app, it has been out since January, and is already at 1.2.0, mostly due to fixes for corner cases and UI improvements). I don’t think there’s any substitute for Giving A Damn. [0] https://littlegreenviper.com/miscellany/testing-harness-vs-u... reply forgotusername6 26 minutes agoprevI don't do TDD. Tests help me write code. I write the code, iterate on it, then write tests to confirm the assumption I made in the code. The act of writing then uncovers misunderstandings I had, careless bugs etc. When the tests are complete, they protect my code from someone else changing the code such that the things I wanted the code to do no longer happen. Is every test I've ever written useful? No, absolutely not. But I don't have time/am not best placed to determine which would be useful at the point of writing, so I write them all. reply gavmor 5 hours agoprev> Both are among the highest-quality software I have ever used and hacked on. > Both have less tests than I expected. Interesting bit of context: Zed's Nathan Sobo and Max Brunsfeld are both alumni of Pivotal Labs, a firm _notorious_ for its zealous adherence to, among other things, TDD. I don't, therefore, find it surprising that \"neither codebase has tests, for example, that take a long-ass time to run,\" because the more stringently one test-drives, the less patiently one tolerates slow test suites. Besides that, after a serious investment in test-driving, one starts to learn which sorts of tests have paltry or even negative ROI; \"tests that click through the UI and screenshot and compare\" were right there at the top of the chopping block for most Pivotal devs, and tests that \"hit the network\" were explicitly taboo! I think that Kent Beck quote is great, but it's good advice for people who test too much, rather than devs in general or, god forbid, junior developers! The way I think about TDD, it's just like how after a while, one gets tired of copy+pasting code into the terminal, and reluctantly writes it to a file. One gets tired of emailing files, and checks them into version control. One gets tired of manipulating state--of clicking through the UI, of newing up a bunch of collaborators in the REPL, of smashing tab while blanking on the name of the method one has only just written--and writes a test. And maybe one who wakes up tired writes the test first. ;) reply seer 4 hours agoparentI dunno, in my career I’ve found that UI e2e tests were the ones that actually found bugs. All the unit tests that I’ve written ware mostly ceremony, to increase code coverage, etc, and were the first to need refactoring after some code change. A lot of refactoring. The tests that stayed true were the UI tests that almost always pointed to real problems with real code. It took a while to figure out how to write them though - trying to rely as little as possible on the internal ids / html / css and write them with what the user sees - e.g. instead of clicking on the button with “testid=login” we would “click on the button with the text login in it”. Identifying fields by the labels to them or tables by their column headers. It was inspired by rails’ capibara testing lib. And making sure the tests were not flaky, fast to execute and isolated took some time. But it was so worth the investment - it’s surprising how little those tests would change, as it allowed us to fearlessly refactor stuff without changing any tests. They felt a lot more like a friendly QA helping out rather than an annoyance you had to deal with after you’ve finished writing your code. And writing them was actually fun, since you didn’t have to understand how the app worked, fiddle with brittle css identifiers etc, you just wrote the steps you thought the user should do and saved it into a file. Being UI tests kinda meant they tested the whole system with the various micro services involved, databases and other infra. And I think this is where most problems in software arise, at the edges of systems when they try to interact with each other. Static types, immutability automatic API schemas and validators usually make sure the code one writes executes reasonably well, its where the code one writes starts interacting with all the other systems where people usually can’t anticipate things. And thats where the integration / e2e / UI tests help the most I think. reply Supermancho 3 hours agorootparentI was a big fan of the unit testing done at JP Morgan. I found 1 exploitable bug when writing Unit Tests, for an untested swath of code that was of minor concern. Ofc this was one day out of a ticket that took a few days. After a year, when I left, it was the only bug that I found with a unit test, there. I wrote unit tests for everything during my time, and I found it to be a good practice. Do I always do it at other workplaces? No. Do I do it for my own projects? Yes. It's not that I don't care as much at work, but the time pressure is constant and I sometimes skip them if I can. reply xiwenc 1 hour agoprevPerhaps the key with testing strategy is to define what to test. As pointed out, code coverage is not a good metric when followed blindly. I believe there are at minimum 2 levels that need testing. First is unit testing. It should ensure complex functions work as intended as a unit. Second, for your core functionalities, have e2e test cases. This ensures your product actually works for the end user. Unit testing should make up the biggest part of the test suites. E2e should be kept at minimum but yet satisfies the quality requirements. Few years back i wrote a bit about this based on the AAA method: https://cinaq.com/blog/2019/05/05/simple-high-value-tests-wi... The core idea is to determine what are high value tests. reply kookamamie 1 hour agoprev> maybe there’s no correlation between software quality and tests Bingo. The underlying assumption that tests are some god-given faultless spec is flawed. In fact, the tests themselves shouldn't be considered to be of any higher quality than the poor code they test. Good teams produce good software, regardless of the approach or ideology. reply jonahx 6 hours agoprev1. There is no substitute for simplification and good design. You cannot test yourself out of a mess. 2. What you actually want is confidence in the code, and your ability to make changes. Sometimes tests are a good tool to achieve that, sometimes they are not. 3. The previous two points can and will be used to justify sloppy code by bad programmers, but it doesn't make them less true. reply rsyring 3 hours agoparent> You cannot test yourself out of a mess. My dev shop has taken over two dumpster fire web app projects, both many years old, passing through many unskilled/inexperienced hands, atrocious architecture and implementation, and no tests. But, actively being used and a full rewrite not being in the cards for some time. The very first thing we did for both was start writing integration tests at the http (wsgi client) layer to cover the majority of client facing functionality. We learned a lot about the apps in the process, fixed bugs where we could, documented and fixed lots of security issues, but generally didn't refactor anything that wasn't very broke. Once that was done, we could start refactoring which, for one project, included a migration off Mongo to tabled Postgres. The refactoring included significant unit and other testing so that we had very good and helpful test coverage when we were finished. I do believe there are times when testing yourself out of a mess is the only reasonable option. reply xlii 2 hours agoprevI was never a huge TDD believer and I’m not one today. It’s not about tests but about managing complexity. When working with highly dynamic languages like JavaScript, Python, Ruby (at least couple years ago) tests were the only tools we had to handle it. Today some of the most common issues are caught by popular static typed languages (Rust, TypeScript). There are some very smart tools like prop tests and if someone is really deep into modeling it’s also possible to test concepts with TLA+ (fun if you need to explore infinite possibilities of reality bending scenarios). Also qualities of certain languages also make code easier and stabler in domains - e.g. Erlang/Elixir, Clojure or Haskell (and there are much more but those are in my monkey zone). But in the end for me testing is just that: Managing ever growing complexity. And since tracking and maintaining change due to distributed development effort is hard the smallest common denominator I know is… write it twice. reply throwaway2037 2 hours agoparentThis is a great post. I feel the same on many topics. > I was never a huge TDD believer and I’m not one today. I'll never forget this savage takedown of TDD by Cedric Beust: https://www.beust.com/weblog/the-pitfalls-of-test-driven-dev... The best rebuttal to TDD that I ever heard from a developer that I respected: \"I don't care if you use TDD or whatever. When you commit code, tests need to be included.\" That's it. And yet, the TDD evangelicals are like the vegans of diet or calisthenicians of fitness -- always annoying, no matter what they say. (Side note: I was a vegan for many years, and I still thought the loud ones were annoying!) > write it twice This is what I hate so much about unit tests -- you chisel the statue once from stone, then, by writing unit tests, you essentially chisel the inverse to fit your new statue. So exhausting. reply hvis 6 hours agoprevSpeaking of text editors and tools like that, you can often avoid having tests (or postpone adding them for a long time), if the logic is on the main execution path, meaning you'll execute it every time you run the program, and whatever failures that can happen, are reasonably easy to pinpoint (i.e. the program shows error backtraces or somehow traces problems otherwise). This is from my experience hacking on Emacs, naturally. At the same time, projects that you might ship for an employer or a client, are more critical to check for correctness before deploying, and are often more complex to run and check manually on the regular than writing at least one \"happy path\" integration test at least for the main scenario (or several). reply userbinator 6 hours agoprevAn interesting correlation that I have observed over the years is that the more one is \"religious\" about writing tests, the less actual understanding of the code one seems to have. \"Beware of bugs in the above code; I have only proved it correct, not tried it.\" - Donald Knuth reply hibikir 4 hours agoparentI've faced that problem before: Someone claimed their autoscaling algorithm had to be working correctly, as he had written a proof and had a working simulator behaving perfectly. And yes, the code matched the algorithm as written, and the proof was correct... as long as latency was zero. Once I added lags to the right places in the simulator, we got the exact same problems than in production. reply 1123581321 5 hours agoparentprevI've seen a correlation between caring about the application code and the test code. That makes sense because writing, reading and running specs help you think about what you're intending to do and what you've accidentally done. reply BurningFrog 5 hours agoparentprevIf you have good tests, you don't need to know the code as well. reply eddd-ddde 5 hours agorootparentThe more I program the more I feel this way. Do I really care how the code looks like or does something? Not really, all I know is this set of specifications are held true as I make changes, as long as I'm happy with those specs, I'm happy with the code. reply Jach 4 hours agorootparentOn the small I wholly agree, like how much energy do some teams or even companies still waste on style document types of disagreements? But other aspects, I do often care how the code \"looks\" or more precisely \"does\" something. Like, it shouldn't be needlessly wasteful of resources, but I don't want to pigeonhole myself as \"the performance guy\". It shouldn't be using under-educated idioms that increase the likelihood that someone's gotta come back to this later to fix something stupid like a null pointer exception. At the same time certain things that sometimes get derided as ivory tower complex (or just \"clever\") code constructions, I don't think should necessarily be avoided all the time, but should be tastefully balanced with an aim towards broader understanding and not showing off cleverness for the sake of cleverness. I've replaced so many hundreds of lines of code with some relatively simple tens of lines type theory constructions in plain old Java 8, just because a dev who stopped learning around Java 1.4/5 doesn't understand doesn't make them \"complex\" or \"clever\". I don't even particularly like static typing, but a tool is a tool. But often I just don't care about even those details, and sometimes feel guilty about it. Carmack says to fill your products with give-a-damn, but I'm sorry, for so many things, a lot of the time I just don't/didn't. Work must be done anyway though, and not just by me. So practices that are broader, like enforcing tests, do help deliver a good enough product even under the guidance of devs and management and management's management etc. who seem to care even less than I do and don't even feel bad about it. It's particularly crazy when you talk to a customer who is gushing about something you know could have been even better with slightly different prioritization and tradeoffs; an important lesson is that many people are stoked merely that something exists. It's sad when tests catch something that really should have been caught, if not during code authoring time by an author who actually cares a bit more than just doing the job however and going home, then by code review time, but in large companies you sometimes have to just accept things for long periods and at least with more tests we can be more likely to catch things at all. (Not to mention they're pretty valuable when the original author who best understood the code is long gone, they help you make minor tweaks without having to tradeoff new feature development time with time getting a deep enough understanding of that old code that still mostly works most of the time.) reply lelanthran 1 hour agorootparent> have been caught, if not during code authoring time by an author who actually cares a bit more than just doing the job however and going home, I have to ask, what's the alternative type of author to one who does the job however and goes home? Because doing the job properly takes more time, where does this extra time come from? In any agile setup the dev who goes slower but better is going to get dinged in every single standup and metric, so the only other alternative to doing the job however is unpaid overtime, which I think is even worse for a Dev team than shitty code. IOW... Good, cheap, fast... Pick two and don't judge those who don't give you all three. reply SPBS 1 hour agoprevTests are very much a \"if you liked it then you shoulda put a test on it\" thing. If some end-user property is desirable to you, make sure a test covers it so that you can be sure it still works that way. This is a godsend when doing extensive refactors on the codebase, which lets you move fast. https://twitter.com/simonw/status/1701764953114546664: \"The single biggest productivity enhancement I've ever found for my own personal projects is writing comprehensive tests for them. I don't mean TDD - I rarely write tests first - I mean trying to never land a feature or fix a bug without a test that proves that it works\" > No tests that click through the UI and screenshot and compare and hit the network. That's fair, I think testing UI is just hard in general and it's easier to rely on users to submit bug reports especially if the UI rarely breaks. reply wilkystyle 6 hours agoprevI'm not going to comment on unit tests (of which we have many), as that seems to be where the biggest divide is, but I will say that our integration tests are worth their weight in gold. reply mellutussa 2 hours agoprevThere was this sailor who always did extra knots and shit on his ropes and lines. Because he wanted it to be extra safe. Then in a storm the ship sank because he couldn't undo that shit quickly enough. I guess you can tank your software project too by too much or wrong testing. reply zachmu 4 hours agoprevOver the lifetime of a code base, most of the value of a test is not in verifying functionality. It's keeping you or someone else from accidentally breaking it when you change something. reply andrewl 5 hours agoprevTests are valuable, but of course they’re never perfect. Certain kinds of programs require them more than others. And no development approach, method, or tool is the best in all cases. The program with the most tests that I’m aware of is SQLite. I have a feeling Hipp and his team know their code extremely well and that they do a lot of thinking before they change anything. Then they run their massive test suite, which they built because they’re good enough to know that they’re not good enough to think everything through without making errors. Tests have saved me from a few blunders over the years. reply shcheklein 4 hours agoprevThere was an interesting discussion recently on (somewhat) opposite perspective https://antithesis.com/blog/is_something_bugging_you/ - how good testing systems makes everything way faster reply wavemode 4 hours agoprev> Enter Ghostty and Zed. You're taking two desktop applications, written in Zig and Rust respectively, and extrapolating their lack of testing rigor as evidence that \"there’s no correlation between software quality and tests\"? Really? Have you tried maintaining quality in enterprise software without tests? If you ever manage to do so, I'd be very interested to read about it. reply misternugget 2 hours agoparentHey, author here. Yeah, I worked at Sourcegraph and I do think we built some high-quality stuff and we did write tests. I also think a lot of them were necessary. But, like I wrote here, I think that maybe we/I sometimes overdid it with tests and I'm not so sure about the use of /some/ of them anymore. reply gustavpaul 6 hours agoprevWrite the tests you need to sleep at night and avoid you and others you care about burning out when everything starts falling apart and even the smallest changes inspire dread. reply osigurdson 4 hours agoprevI don't know. When working in an unfamiliar codebase, tests are very helpful (even when some percentage of them will always be annoying). The problem is, the industry has focused on having lots of tests instead of having good code. reply TylerE 5 minutes agoparentOne problem I don't see talked about enough - to the point where I don't even have a name for it - goes something like this, You have a giant, long lived system, like decade plus. You've got huge number of both unit and integration tests. You're cruising along, implementing a new feature. Everything's looking good from your local manual tests and the tests you wrote over the new behavior. Then you ship the branch up to the test runner to let the full suite cook, and you get it back, and there's like 9 random test fails that aren't in master. Has your change had unintended consequences? Is the test just out of date? If the test is out of date, how do we update it such that it both passes and we are at least reasonably confident that the test is still actually testing what it was intended to test? Where it gets real obnoxious is when the test isn't testing anything even vaguely related to your change so it can turn into a real snipe hunt. Five minutes here, ten minutes there, it adds up. What's frustrating is that the number of times this has found an actual issue that I can personally remember.. I won't swear it's zero, but I'm struggling to recall a specific example. reply ThalesX 1 hour agoprevtl;dr; be careful with your testing strategy, it might break your company. There's some aspects that stand to gain from automated testing, it's important that developers test their work, but in my opinion manual testing is super valuable especially for an early stage start-up. I was working for a startup that first had the strategy of testing everything, at a point when we didn’t even start working on the product. We spent a horrible ammount of time getting the test system up and running (microservices, browser add-ons), with the UI testing being the most challenging. But then they also wanted to \"move fast and break things\", which we did, so we spent an annoying ammount of time fixing breaking tests. This is when the “let’s just delete the test” expression started popping up. So we ended up with an unmaintained testing system that no one cared about anymore, keeping our build on red because we always had the testing system in the backlog so it was going to be done at one point. Then, the quality of the codebase started degrading to the point where we’d wake up with features that have been broken for a while and no one noticed it, even though each individual developer was testing their own flows. We had no one / nothing testing the entire system. At this point, I suggested we hire 1 – 2 manual testers, as our testing strategies are obviously failing, the product is suffering in terms of quality and we could get them for relatively cheap compared to dev-time. I’ve had great success working with manual testers for very complex products with real world repercussions, compared to this tiny start up in dev tooling. They refused. So they decided we’d do cross functional testing and then test the entire system whenever we’d do a merge. So developer velocity fell from a cliff because we became the manual testers. We still had no customers at this point. Runway got shorter and shorter. And the start-up became a statistic. reply pydry 1 hour agoprevThe whole article can be boiled down to tests are an investment and you should make sure your investments have a return. It sounds obvious but it's a valid point. It's more common for people to have a dogma based attitude to testing to an investing approach. reply crdrost 5 hours agoprevRich Hickey once said something in the midst of my “TypeScript, Haskell, la la la la la” phase: > I like to ask this question, what's true of every bug ever found in the field? (It got written?) Pff. It got written, yes. What's a more interesting fact? (pause) It passed the type checker! What else did it do? (the tests?) It passed all the tests. So now what do you do? The basic problem is that we really want tests to somehow specify the contract of the software, but when you are writing “given, when, then” the “givens” pin down too much of how it is done and the “when/then” is scoped to distinct sub-contracts of different parts so it pins down how the work was broken-down... It hits like a syllogism, right? All tests are software, all software has scope creep, scope creep in testing is contract creep. reply fyrn_ 1 hour agoparentBugs all passed the tests sounds like survior bias. Like how all the fighter planes that returned with damage had damage to the wings. Point is, damage anywhere else was fatal, the takeaway should not have been to armor the wings more, which was the first thing which was tried. Likewise thinking about bugs this way discounts potential bugs that _were_ stopped by tests. reply osigurdson 5 hours agoprev>> Maybe the tests are only a symptom. A symptom of something else that causes the quality. Love this comment! reply valcron1000 6 hours agoprev> In both codebases I’ve merged PRs without any tests and frequently see others do the same. I would never accept such PR. This kind of policies then end up biting you in the long run (experience talking) reply samatman 6 hours agoprevEditorializing the title to something grammatically-incorrect? Please don't. I consider it significant that both of the examples he cited are interactive programs. Thorough testing is low-payoff for those, for two reasons: it's common to tweak behaviors a bit, and if something is broken, you'll notice in the process of using it. Not no tests, but fewer tests, makes sense. At the opposite end, I'm working on a VM, and you better believe it's got tests. Not enough, it needs more, it always needs more, but they're a godsend. When I add an optimization to the compiler, I want confidence that it hasn't broken other behaviors, which frequently it does at first. They've enabled several refactors, with at least one more big one on the roadmap. Change one end of the pipeline, change the middle, change the end: half the tests fail, figure out why, the tests are green, all is well. It's almost a tautology but: write tests for a reason. Good reasons change over the lifecycle of a program. Early on, fixing simple invariants and preventing regression is a good motive, but with the recognition that things are going to change. Dogmatic TDD can lock in a design too early, if literally everything has a test right from the beginning the effort of every change is multiplied. For a mature systems program designed to be robust and load-bearing, complete coverage could be a good goal. For something like a text editor or terminal emulator, that's probably overkill outside of the core components. Tests aren't free, but no tests can get pretty expensive too. reply mellutussa 2 hours agoprev [–] > was 100% sure that I know how the code works and that this can’t happen again. No, no, no and nope. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Thorsten Ball, reflecting on his testing experience in software development, questions the effectiveness and significance of extensive testing, pointing out instances of successful software with minimal testing.",
      "Ball doubts the correlation between software quality and the extent of testing, advocating for minimal testing to prioritize functional code over rigorous testing.",
      "He suggests shifting the focus from extensive testing to ensuring that the code functions correctly to enhance software quality."
    ],
    "commentSummary": [
      "Testing in software development is crucial for ensuring code correctness and functionality.",
      "The debate covers areas like the misuse of testing, the effectiveness of type systems versus tests, and challenges in rebuilding codebases.",
      "Prioritizing technical rigor and adapting testing strategies based on the program context are crucial for maintaining software quality and preventing errors."
    ],
    "points": 134,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1710640096
  },
  {
    "id": 39727529,
    "title": "Bullshitters More Prone to Fake News: Study",
    "originLink": "https://uwaterloo.ca/news/media/research-shows-people-who-bs-are-more-likely-fall-bs",
    "originBody": "Skip to main Skip to footer University of Waterloo Admissions About Waterloo Faculties & academics Offices & services Support Waterloo COVID-19 Search Menu This site Home Real Research UWaterloo Admissions About Waterloo Faculties & academics Offices & services Support Waterloo COVID-19 Waterloo News Media March 8, 2021 Research shows that people who BS are more likely to fall for BS People who frequently mislead others are less able to distinguish fact from fiction, according to University of Waterloo researchers By Media Relations Arts Research Share People who frequently try to impress or persuade others with misleading exaggerations and distortions are themselves more likely to be fooled by impressive-sounding misinformation, new research from the University of Waterloo shows. The researchers found that people who frequently engage in “persuasive bullshitting” were actually quite poor at identifying it. Specifically, they had trouble distinguishing intentionally profound or scientifically accurate fact from impressive but meaningless fiction. Importantly, these frequent BSers are also much more likely to fall for fake news headlines. “It probably seems intuitive to believe that you can’t bullshit a bullshitter, but our research suggests that this isn’t actually the case,” says Shane Littrell, lead author of the paper and cognitive psychology PhD candidate at Waterloo. “In fact, it appears that the biggest purveyors of persuasive bullshit are ironically some of the ones most likely to fall for it.” The researchers define “bullshit” as information designed to impress, persuade, or otherwise mislead people that is often constructed without concern for the truth. They also identify two types of bullshitting— persuasive and evasive. “Persuasive” uses misleading exaggerations and embellishments to impress, persuade, or fit in with others, while ‘evasive’ involves giving irrelevant, evasive responses in situations where frankness might result in hurt feelings or reputational harm. In a series of studies conducted with over 800 participants from the US and Canada, the researchers examined the relations between participants’ self-reported engagement in both types of BSing and their ratings of how profound, truthful, or accurate they found pseudo-profound and pseudo-scientific statements and fake news headlines. Participants also completed measures of cognitive ability, metacognitive insight, intellectual overconfidence, and reflective thinking. “We found that the more frequently someone engages in persuasive bullshitting, the more likely they are to be duped by various types of misleading information regardless of their cognitive ability, engagement in reflective thinking, or metacognitive skills,” Littrell said. “Persuasive BSers seem to mistake superficial profoundness for actual profoundness. So, if something simply sounds profound, truthful, or accurate to them that means it really is. But evasive bullshitters were much better at making this distinction.” The research may help shed light on the processes underlying the spread of some types of misinformation, which could have important implications for the fight against this growing problem. The study, You can’t bullshit a bullshitter (or can you?): Bullshitting frequency predicts receptivity to various types of misleading information, authored by Littrell and Waterloo’s Faculty of Arts professors Evan Risko and Jonathan Fugelsang, appears in the British Journal of Social Psychology. Tags Arts Research Related stories Read more How parents can help prevent the development of ADHD symptoms ADHD can be stemmed through specific parenting behaviours Read more From a hashtag to real social impact Dr. Naila Keleta-Mae champions #BlackAndFree project with private and public sector partnerships to support Black artists Read more Q and A with the experts: How does self-esteem affect relationships? Someone with low self-esteem might assume rejection or neglect, leading to conflict in the relationship Read more Waterloo News Media? Contact media relations to learn more about this or other stories. TOP Share Waterloo news Find an expert Find a COVID-19 expert Contact Media Relations University of Waterloo University of Waterloo 43.471468 -80.544205 200 University Avenue West Waterloo, ON, Canada N2L 3G1 +1 519 888 4567 Contact Waterloo Maps & Directions WatSAFE Accessibility Privacy Copyright Media Careers Feedback @uwaterloo social directory The University of Waterloo acknowledges that much of our work takes place on the traditional territory of the Neutral, Anishinaabeg and Haudenosaunee peoples. Our main campus is situated on the Haldimand Tract, the land granted to the Six Nations that includes six miles on each side of the Grand River. Our active work toward reconciliation takes place across our campuses through research, learning, teaching, and community building, and is co-ordinated within the Office of Indigenous Relations. We use cookies on this site to enhance the user experience. Select 'Accept all' to agree and continue. You consent to our cookies if you continue to use this website. Accept all",
    "commentLink": "https://news.ycombinator.com/item?id=39727529",
    "commentBody": "Research shows that people who BS are more likely to fall for BS (2021) (uwaterloo.ca)129 points by mgh2 17 hours agohidepastfavorite80 comments robocat 14 hours agoAssociated problem: salespeople seem to be gullible when buying - they get taken in by slick salespeople. Given their skills you would think they could spot someone pulling the wool over their eyes. I haven't yet worked out whether it is just admiration for a good snow job or falling for some status game. reply camhart 14 hours agoparentGood sales people are genuine. Its easier to genuinely believe in the product you're selling if you're gullible. reply roenxi 8 hours agoparentprevOne other hypothesis would be that salespeople really like it when a sale gets made, and don't differentiate whether they are a buyer or seller. Although what does \"gullible\" even mean when buying? They are non-experts in most goods, it is hard to see why they would be sophisticated buyers. Being a sophisticated buyer surely involves an understanding of the market and quality signals of a specific good. reply eru 6 hours agorootparent> They are non-experts in most goods, it is hard to see why they would be sophisticated buyers. Being a sophisticated buyer surely involves an understanding of the market and quality signals of a specific good. You might think they are at least experts in (seeing through) sales tricks? reply barfbagginus 5 hours agorootparentHypothesis: They don't think that the sales tricks are tricks. They think sales tricks are adding genuine value to the head of the value chain. reply noufalibrahim 4 hours agorootparentAlso, they have some internalised sympathy for a good salesman and are forgiving. I think this tendency was alluded to several times in the series Mad Men where the lead character Draper who's an excellent salesman talked to other salesman. reply advael 13 hours agoparentprevSales is a great example of how moralizing about tools rather than uses of them creates incoherent beliefs which lead to dysfunctional policy. Most sales people I've met generally believe they're not bullshitting people. Now, their profession selects for persuasion and exerting frame control over social reality, and teaches it, but they use this skillset in a more \"legitimate\" context than the central examples that get the mean names, so the notion that they are using a skill for good purposes quickly morphs into the belief that it's in fact a different toolkit, because this is the only way we can coherently tell them that they are legitimate but continue attacking grifters not just on their actions but on their competencies and methods reply foobarbecue 14 hours agoparentprevThis is so true. My ex's dad was a successful medical device salesman, and a complete rube when it came to buying cars or whatever. reply JKCalhoun 14 hours agoparentprevPossible that they are unable to distinguish between bullshit and reality? It would somewhat excuse their own bullshit: they may not know they are bullshitting. reply MenhirMike 14 hours agorootparentThat's the problem with some of the best sales people: They are technically not lying because they _actually believe the bs they're telling you_. reply Arun2009 12 hours agorootparentI've often seen this phenomenon at play in religions. They are not intentionally lying even when they put forward outrageous claims; they genuinely believe what they say. reply Fnoord 11 hours agorootparentI once went to a conference about a company selling MLM products (I didn't know they were selling MLM products and I was young enough to not know about MLM). They were eating their own dogfood there, and lunch was free. It was at an expensive hotel in my country. There were loads of yuppies there. Everyone wore a suit. Despite that, the conference felt as if I was at a cult. And the CEO knew I had a couple of questions about his products. He gave me the death gaze / cold stare during a speech. I was in my early 20s, scared shitless. Now, remember I wrote the conference was as if I was at a cult? I got invited to this conference via a brother of an aunt (cold side). He used to be in a cult. Now he was a hardcore Christian. He got very rich from these MLM products because he was high up in the chain. As they say: the apple doesn't fall far from the tree. reply miked85 6 hours agorootparentprevIt's not a lie if you believe it. reply hilux 5 hours agorootparentprevRelated - google: David Sinclair fraud He's not a salesperson; he's a Harvard Med School professor. But he made a fraudulent $700 million dollar sale (of his company), and escaped having it reversed because he managed to convince the court that he really believed his false claims and bogus research. This is also the claim that SBF's lawyers are (still) making, now in the sentencing phase. Absolutely f-ig infuriating. reply pixl97 14 hours agorootparentprevHoly shit, salespeople are hallucinating LLMs. reply wholinator2 13 hours agorootparentWell, can we really ascribe belief to the machine? And they don't usually have a bias in hallucination other than what you're feeding, salespeople absolutely do have a bias reply ben_w 50 minutes agorootparent> can we really ascribe belief to the machine? Sure, just so long as you don't require beliefs to have qualia. I'm fine with that myself, my beliefs only have qualia when I actively introspect them, but I'd still call them \"beliefs\" even before I examine them for the first time. > And they don't usually have a bias in hallucination other than what you're feeding, salespeople absolutely do have a bias The motivation may be different, even alien, but I'm not sure it matters. You can also tell an LLM to take on the role of a motivated salesperson, and it will role play that just as \"happily\" (if you'll excuse the anthropomorphisation) as any other. reply api 8 hours agorootparentprevI’ve said for a while that we created AI in our own image, and it’s a bullshitter. reply Buttons840 13 hours agorootparentprevSounds like cognitive dissonance. It's easy to believe that BS is bad, but hard to recognize BS in others without also recognizing it in yourself. When those beliefs are in conflict the easiest resolution is to stop recognizing BS. As they say: it's hard for a man to understand something when his paycheck depends on not understanding it. reply 0x0203 9 hours agoprevOne of the most common assumptions people make when dealing with other people is that everyone else thinks like they do. So many problems with communication, instruction/teaching/learning could be better resolved if each person understood that different people process information in different ways and made sure to present information in a way that the receiver is capable of following. reply pseudocomposer 8 hours agoparentI agree with you wholeheartedly! Of course… not everyone thinks the way we do… reply lelanthran 13 hours agoprevCould be the other way around. \"People who are more gullible are more likely to try a bluff\" makes more sense: they aren't aware enough to read the situation and react accordingly. That makes them more gullible as well as more likely to attempt a bluff. reply mrxd 8 hours agoparentThis is what I think it is too. A gullible person draws on their personal experience and overestimates other people’s susceptibility to deception. reply Anotheroneagain 12 hours agoparentprevI think it's more likely that people judge if there is an opportunity to lie by thinking if they would themselves fall for it. So, morals aside, somebody gullible sees the opportunity to lie all the time, while somebody very skeptical may think that they would only embarrass themselves by trying to lie. Or possibly lie unintentionally, giving an evasive reply, incorrectly believing it will be understood that they don't want to answer. reply ShamelessC 8 hours agorootparentIt’s hard to know but I doubt there’s that much reflection happening. Perhaps it’s as simple as “people with low emotional intelligence lie more often because they think they’re getting away with it more than they are. Also they are fairly insecure but don’t know how to manage it in a healthy way” reply Lalabadie 15 hours agoprevI've been working with my first client who, I've come to recognize, is _very_ susceptible to believing exaggerated claims. This is someone who would enthusiastically dive into a cult if the right person told him it's nicer there, but instead he's tech entrepreneurship, so AI is always three weeks away from allowing him to replace all his employees. In the meantime, everyone in the design team keeps sending back content that he's requested from ChatGPT instead of an actual copywriter. Because everyone here, like everyone on HN, can easily tell the difference, but he can't/won't. What seems to be very difficult with someone like this is, they participate in hype cycles because not doing so leaves them feeling like _everyone knows something_ and they don't. They don't want to be the idiot left behind when something good happens, so they dive into every enthusiastic movement or belief that comes in range. They don't have the ability or will to suss out that each wave is made up of people exactly like them. TLDR: High energy, low critical thinking. reply asdff 14 hours agoparentThere are enough people like this where for better or worse, keeping up with these hype trains has become a solid investment strategy. Imagine getting in early enough on BTC, or DOGE, or AMC, or GME, or NVDA, or whatever comes next instead of cynically scoffing it off (for valid reasons) on its fundamental merits. You'd be singing a different tune I'm sure after it explodes and you've cashed out leaving the zealots on whatever subreddit holding the bag. reply 10000truths 14 hours agorootparentRelying on the greater fool theory to make your money only works until it doesn't. reply andrewflnr 12 hours agorootparentI don't know, if you get out early enough and only invest a portion of your previous winnings into the next cycle, it only has to work long enough for you to build a decent nest egg. But I suppose the average cycle chaser doesn't think like that... reply pixl97 14 hours agorootparentprevThe boom/bust cycle. As they say, the hardest part of the market is timing. reply VelesDude 6 hours agorootparentExactly. Also for that half dozen successes listed before, there could have been thousands of options available at the time that only look silly in retrospect. reply wavemode 4 hours agorootparentprev\"Solid investment strategy\" implies one could make money applying this idea consistently. There's a hundred new \"next big thing\" ideas every year - most of them amount to nothing. reply dotnet00 10 hours agorootparentprevI don't think NVDA fits in with those, their rise makes typical business sense, and has made sense most of their existence, unlike the others. reply JKCalhoun 14 hours agorootparentprevI've wondered from time to time why I never could find it within myself to become a street preacher. reply 082349872349872 12 hours agorootparentSurely you could find it within yourself to become the Life of Brian boring prophet? https://www.youtube.com/watch?v=QqaQ_Bhgmrc reply cushpush 15 hours agoparentprev>AI is always three weeks away from allowing him to replace all his employees. Well isn't that a temporal oddity reply ozymandias1337 14 hours agorootparentThey are constantly shifting the goal posts. reply passion__desire 15 hours agoparentprevthe best way to spot a bullshitter is to ask them A series of 5-7 why drill down questions expanding on a particular word you don't understand or do understand. And if they aren't quick to respond or don't answer don't know or aren't out of their depth , you know they are bullshitting. technique borrowed from Feynman's \"why magnets work video\" reply JKCalhoun 14 hours agorootparentI assume this video: https://youtu.be/MO0r930Sn_8 Even from within the first few seconds you can tell Feynman is already annoyed with the interviewer. It's possible that there is some history here: there may have already been a long run of questions and he's now become tired of it. reply gwervc 14 hours agorootparentprevThat works with almost every topic. Two-three questions you're in the bachelor degree level depth, 4-5 master one, 5-6 phd, 7 only God knows. reply antisthenes 13 hours agorootparentYou can definitely get to the God level if you start with the question of why are elementary forces and constants the values that they are ;) reply euroderf 13 hours agorootparent\"Tell me what are your three favorite dimensionless constants, and why.\" reply Scubabear68 9 hours agorootparentprevYes! This is what I use on technical interviews. I generally ask candidates to describe systems they have worked on in depth from an architecture perspective. This very rapidly spots the BS hand wavers from those who know how their systems work. As a side effect it can also serve as a gauge on how mature or junior they may be. reply frickinLasers 8 hours agorootparentI don't interview well. I wrote a program from scratch, tweaked it throughout my PhD, used it to get results for my thesis. I am quite confident in the robustness and accuracy of the program. I couldn't explain my code to an interviewer (partially because it wasn't production-ready code, but mostly because I don't interview well). I'm glad I didn't get the job. Moved on to work with people who know I'm not a hand waver. reply jsight 5 hours agorootparentTBH, I've found there are people that can give great sounding answers that don't correspond all that well to reality. There are also people who struggle to answer, because reality is more complex than what they can easily convey to someone who doesn't already know the domain. There are pros and cons to both groups. reply scrollaway 44 minutes agorootparentprevHey if you want a mock interview in some as-real-as-possible scenario, find my post on whoishiring and email the careers@ email with your cv, I’ll make sure to get you an interview and get feedback to you. reply JanisErdmanis 12 hours agorootparentprevFeynman did not bulshit the answer as the interviewer does not have a capacity to understand the phenomena any deeper and he gives all valid reasons why. If instead he would have jumped to writing down a Hamiltonian and constructing a partition function from which magnetization could be derived for a magnet it would have killed the interviewer in obscurity. reply nuancebydefault 14 hours agorootparentprevI _think_ I can very easily spot BS. That has its downsides... I very easily get very annoyed with BS. I know a few people who as good as constantly BS. It's a puzzle to me what drives them, and why it seems like they even don't know they are BSing. Is there some psychological explanation, I'm curious. I was thinking about giving examples to state my point, but in fact every somewhat sane person must have had those 'WTF are they saying' moments. reply sufficer 11 hours agorootparentOne example I can easily recall is some guy bsing about his arena rank in wow. I wasn't good, but I asked enough questions to determine he was absolutely bsing to the point of laughter. Like the kind of kid that says he has a GF that lives in another city or state or even Canada lol reply pixl97 14 hours agorootparentprevI think part of it is that BS is commonly quite effective. Good BSers are commonly good at getting information out of people and feeding it back to them as a kind of echo chamber. Most people will not pose adversarial information (that is say something purposefully wrong) to see if the BSer agrees with it and parrots it back. The BSer confirms the other persons worldviews at the same time spouting whatever crap it is they are selling. Very common tactic in grifters. reply mistermann 14 hours agorootparentprevThey can simply counter with \"bad faith\", \"you're being pedantic\", etc. Wins literally every time. reply hilux 5 hours agoparentprev> TLDR: High energy, low critical thinking. During Silicon Valley boom cycles, these fast movers ted to do a lot better than people who stop to weigh the pros and cons, moral and ethical considerations, environmental impact, etc. etc. reply wolverine876 12 hours agoparentprevIt could be that their agenda is different from yours. Their agenda, as leader, is to keep all the balls in the air, keep everyone energized, everyone feeling trusted, the whole enterprise moving fast. A way to do that is to just keep charging forward with enthusiasm, at any target that's available. The movement and energy and trust is the thing. The what and how is not for your client; it's not for the CEO (or not for a certain kind of CEO). That's for you and the employees. The CEO's job is to lead, inspire, motivate, provide resources. reply smugglerFlynn 11 hours agorootparentI am yet to find a highly skilled person who gets excited by “moving fast” aka charging towards bullshit targets backed by unrealistic time/quality expectations. And getting highly skilled people bored or demotivated is the best way to drop all the balls that “leader” tries to juggle. Seriously, I think this whole Marvel movie style leadership will be seen as a huge red flag and anti-pattern in 10-15 years, just like we now look down on those Henry Ford style managers of the 20th century. reply droptablemain 11 hours agoprevThe way they've defined \"persuasive bullshitting\" sounds like would capture 90% of human-to-human interaction. People almost always have an angle. I suspect this research itself has an angle as well, making it meta persuasive bullshitting. reply Fnoord 11 hours agoprevDoesn't this contradict that people who believe they're too clever to get scammed are the easiest marks? It seems like a complex topic where multiple factors are a force. reply mgh2 9 hours agoparentSomething tells me the reverse doesn’t work that way. Ex: how do you recognize a fake dollar bill? By knowing what a real one should look like. “Truth is so obscure in these times, and falsehood so established, that, unless we love the truth, we cannot know it.” - Blaise Pascal reply d-z-m 15 hours agoprev> They also identify two types of bullshitting— persuasive and evasive. “Persuasive” uses misleading exaggerations and embellishments to impress, persuade, or fit in with others, while ‘evasive’ involves giving irrelevant, evasive responses in situations where frankness might result in hurt feelings or reputational harm. > the researchers examined the relations between participants’ self-reported engagement in both types of BSing and their ratings of how profound, truthful, or accurate they found pseudo-profound and pseudo-scientific statements and fake news headlines. By their own definition, it seems like the people most inclined to impress and mislead in situations where frankness might result in reputational harm(in other words a real BSer) wouldn't admit to engaging in BS behavior at a rate above a non-bullshitter. reply Animats 15 hours agoparentThat's a useful distinction. From the press release: \"Ratings of how profound, truthful, or accurate they found pseudo-profound and pseudo-scientific statements and fake news headlines.\" Does that mean the people being tested were just shown the headline? Usually, that's not enough information to decide if something is bullshit. So, were they basically asking their subjects to guess? The actual paper [1] is paywalled. US$12.00. The press release does not link to the paper, nor does it give a full citation, but it does give enough info that the paper can be found. A useful metric is that if something makes a strong but unusual claim, and the supporting data is hard to access, it's usually bullshit. [1] https://bpspsychub.onlinelibrary.wiley.com/doi/epdf/10.1111/... reply nonrandomstring 13 hours agoprevObligatory: Harry Frankfurt's \"On Bullshit\" [0] is a must-read for everyone interested in some stronger definitions. The full essay is easily found online. Long as short: BS has not got a lot to do with depth of knowledge or truth value so much as the attitude of the bullshitter. It's a moral not a knowldge defect. The Bullshitter is neither a liar nor self-aggrandising as we commonly think, but simply has contempt for the very concept of truth and falsehood. It's like epistemological sociopathy. Some bullshitters can be very knowledgable too. They pass the five-why questioning but then defect and talk absolute rubbish as it suits them. I think all LLMs are in essence bullshitters, and I hope something good to help us understand not just consciousness but morality too, will probably come of studying why LLMs are not really \"thinking\" and holding an interlocutor \"in mind\". Not Frankfurt now, but my own observation, if you wire that to the idea that power is the capacity to paint social reality in ones own interests, then unsurprisingly bullshitters are much more common in traditional power roles. LLMs are therefore (rather obviously) dangerous in any role that involves power or decision making. [0] https://en.wikipedia.org/wiki/On_Bullshit reply renonce 8 hours agoprev> the researchers examined the relations between participants’ self-reported engagement in both types of BSing and their ratings of how profound, truthful, or accurate they found pseudo-profound and pseudo-scientific statements and fake news headlines If I understand correctly, they simply asked the participants themselves if they are BS’ing and drew the conclusions solely from that? How do you expect people BS’ing others would admit doing that? reply htoierjwerwer 9 hours agoprevSounds like half the startup-bros I meet who tell me Quantum-Crypto-AI will take over the world. reply lalith_c 7 hours agoprevIt’s a vicious cycle. reply luxuryballs 14 hours agoprevI feel like it follows because they had first to overvalue “impressive sounding information” in order to decide it was worth lying about. Like someone being star struck by a snake oil salesman. reply vlovich123 15 hours agoprevWouldn’t it be ironic if this research turned out to be BS? reply foobarbecue 14 hours agoparentThere's certainly precendent! See Francesca Gino. reply trollerator23 10 hours agoparentprevYou bet. reply pcloadletter_ 13 hours agoprevIt is cutesy to use the word \"bullshit\" but it seems too colloquial to glean any real information from. What do they mean by \"bullshitting?\" Any sort of misleading? Pretending you know something when you don't? I guess I'm just tired of reverse-engineering your information to make a good clickbaity headline. reply puzzledobserver 12 hours agoparentFrom a cursory glance at the article, they appear to use the word bullshit in the same sense as Frankfurt's essay on bullshit. Frankfurt's essay goes into a lot of detail about what is and isn't bullshit. If I remember correctly, he differentiates between deception / fraud and bullshit, which he characterizes as lack of concern for the truth. A liar has an untruth they want you to believe, a bullshitter wants you to believe something, they just don't care whether it is an untruth or not. Now of course, one might complain that Frankfurt hijacked a colloquial word for his idea, but he does spend a lot of time trying to understand the everyday use of the word bullshit. reply richrichie 8 hours agoprevI think people want such things to be true. Makes catchy one liners. This probably biases research methods. reply danscan 4 hours agoprevAh, so you can bullshit a bullshitter reply trollerator23 10 hours agoprevAfter the whole replication crisis debacle it's clear all of these studies are ... BS. reply sandspar 10 hours agoparentQuoting \"A study says...\" has gone from a signal that you're intelligent to a signal that you're not. reply bicijay 15 hours agoprevMaybe its ignorance then... reply marcodiego 13 hours agoprevI call BS. reply ls612 13 hours agoprevPeople who BS (researchers in psychology) are more likely to fall for BS (this sort of social psych research). reply rightbyte 15 hours agoprevIsn't this some sort of Dunning–Kruger effect? I.e. BS:ers don't think the listeners understand they are full of BS, so they are more likely to push BS. reply Rury 11 hours agoparentMore like, people who are incompetent cannot determine BS from non BS as well as someone who is competent. People who are incompetent are also more likely to engage in bluffing strategies (ie BS) in order to gain status than someone that can simply rely on their competence. reply heisenbit 16 hours agoprevThis explains BS bubbles. reply time4tea 14 hours agoprev [–] And hilarious that the article about BS is behind a BS, illegal in the EU, cookie banner. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Research from the University of Waterloo indicates that individuals who frequently engage in \"persuasive bullshitting\" are prone to being deceived by fake news and misinformation.",
      "The study reveals that these individuals struggle to differentiate between fact and fiction, making them more vulnerable to believing inaccurate but grand-sounding information.",
      "This research highlights the connection between persuasive bullshitting and the challenge individuals face in discerning the truth, emphasizing the significance of combating misinformation."
    ],
    "commentSummary": [
      "The discussion focuses on the connection between engaging in deceptive practices and being deceived, especially among salespeople, highlighting issues related to morality in sales and the difficulty of identifying deceptive strategies.",
      "It explores the psychology of 'bullshitting,' emphasizes the significance of critical thinking, and warns about the dangers of establishing unattainable objectives in personal and professional settings.",
      "The conversation also analyzes the widespread presence of BS across different scenarios and how it influences decision-making processes, aiming to enhance comprehension and management of deception in interpersonal, commercial, and academic realms."
    ],
    "points": 129,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1710608494
  },
  {
    "id": 39727458,
    "title": "Efficient URL Parsing in Python: Introducing can_ada vs. urllib",
    "originLink": "https://tkte.ch/articles/2024/03/15/parsing-urls-in-python.html",
    "originBody": "Parsing URLs in Python tl;dr - Try can_ada if you need to parse URLs in Python. URLs Parsing URLs correctly is surprisingly hard. Who even defines what a \"correct\" URL is? URLs have evolved drastically since they were originally defined in 1994. The WHATWG has a URL specification that is comprehensive and has helped standardize the behavior of URLs across browsers, but this specification still isn't universal and ambiguities like \"how many slashes are you allowed\" can definitely get on your nerves: So browsers accept URLs written with thousands of forward slashes instead of two. That is not a good reason for the spec to say that a URL may legitimately contain a thousand slashes. I’m totally convinced there’s no critical content anywhere using such formatted URLs and no soul will be sad if we’d restricted the number to a single-digit. So we should. And yeah, then browsers should reject URLs using more. However, if you're creating something new and want to handle URLs, the WHATWG's URL specification probably is the best place to start. URLs in Python If you're working in Python, you'd probably start with the built-in urllib module. It's been around forever, but unfortunately it's not compliant with any URL specification, either the much older rfc3978: RFC 3986 is considered the current standard and any future changes to urlparse module should conform with it. The urlparse module is currently not entirely compliant with this RFC due to defacto scenarios for parsing, and for backward compatibility purposes, some parsing quirks from older RFCs are retained. The testcases in test_urlparse.py provides a good indicator of parsing behavior. ... or the WHATWG URL Parser spec: The WHATWG URL Parser spec should also be considered. We are not compliant with it either due to existing user code API behavior expectations (Hyrum's Law). It serves as a useful guide when making changes. Having existed for over 16 years, so many projects depend on the urllib module parsing URLs in exactly the way it does that it's unlikely to ever change in any significant fashion. Ada The Ada project is a new (2024) attempt to create a URL parsing library that adheres to the WHATWG URL specification and works really, really fast, parsing 7 URLs for every 1 parsed by cURL. Written in C++, it now has bindings to several other languages, including Python, and has become the URL parsing library used by Node.js as of version 18 to great success: Since Node.js 18, a new URL parser dependency was added to Node.js — Ada. This addition bumped the Node.js performance when parsing URLs to a new level. Some results could reach up to an improvement of 400%. The ada-python binding is perfectly functional, and the official binding for the project. However, the ada-python bindings are built on CFFI, an approach that has the binding between C and Python written in Python itself, which loses some of the performance benefits of using Ada in the first place when most of the time is spent just making the function call. can_ada Daniel Lemire, one of the developers behind the Ada project asked me to take a look at the ada-python bindings and out of that was born can_ada, a new Python binding that uses pybind11 and template magic to generate the binding code, which is then compiled into a Python extension module. This approach has the potential to be much faster than the ada-python bindings, and indeed when comparing the two bindings, the new can_ada binding is about 2x faster than the ada-python bindings which in turn is about 2x faster than urllib.parse! --------------------------------------------------------------------------------- Name (time in ms) Min Max Mean --------------------------------------------------------------------------------- test_can_ada_parse 54.1304 (1.0) 54.6734 (1.0) 54.3699 (1.0) test_ada_python_parse 107.5653 (1.99) 108.1666 (1.98) 107.7817 (1.98) test_urllib_parse 251.5167 (4.65) 255.1327 (4.67) 253.2407 (4.66) --------------------------------------------------------------------------------- At the same time, using the pybind11 approach allows for a very succinct and readable binding definition, coming in at just 60 lines of code and almost a 1:1 with the underlying C++ API. Binary builds are available now for CPython 3.7 to 3.12, and PyPy 3.7 to 3.9 on many OS's and architectures. Install it with pip or get the source: pip install can_ada Example import can_ada urlstring = \"https://www.GOoglé.com/./path/../path2/\" url = can_ada.parse(urlstring) # prints www.xn--googl-fsa.com, the correctly parsed domain name according # to WHATWG print(url.hostname) # prints /path2/, which is the correctly parsed pathname according to WHATWG print(url.pathname) Compare this to the urllib version, which is not WHATWG compliant: import urllib.parse urlstring = \"https://www.GOoglé.com/./path/../path2/\" url = urllib.parse.urlparse(urlstring) # prints www.googlé.com print(url.hostname) # prints /./path/../path2/ print(url.path)",
    "commentLink": "https://news.ycombinator.com/item?id=39727458",
    "commentBody": "Parsing URLs in Python (tkte.ch)127 points by ibobev 16 hours agohidepastfavorite73 comments kmike84 11 hours agoA great initiative! We need a better URL parser in Scrapy, for similar reasons. Speed and WHATWG standard compliance (i.e. do the same as web browsers) are the main things. It's possible to get closer to WHATWG behavior by using urllib and some hacks. This is what https://github.com/scrapy/w3lib does, which Scrapy currently uses. But it's still not quite compliant. Also, surprisingly, on some crawls URL parsing can take CPU amounts similar to HTML parsing. Ada / can_ada look very promising! reply TkTech 11 hours agoparentcan_ada dev here. Scrapy is a fantastic project, we used it extensively at 360pi (now Numerator), making trillions of requests. Let me know if I can help :) reply VagabundoP 13 hours agoprevOkay so some googling found me that the \"xn--\" means the rest of the hostname will be unicode, but why does é become -fsa in www.xn--googl-fsa.com. Google failed on the second part. reply js2 13 hours agoparentBecause that's the Punycode representation: https://en.wikipedia.org/wiki/Punycode https://www.punycoder.com/ reply andy99 9 hours agorootparentI wasn't aware of this, I'd seen those URLs before but only in the context of Chinese ones and thought it was Chinese-specific. It's interesting because I just went down an apparent rabbit hole inplementing Byte-level encoding for using language models with unicode. There each byte in a unicode character is mapped to a printable character that goes up to 255Ada is a WHATWG-compliant and fast URL parser written in modern C++ Why would you do that, Daniel? reply TkTech 12 hours agorootparentHah :) It's named after Yagiz Nizipli's (Ada dev) newborn daughter, Ada. reply yagiznizipli 7 hours agorootparentprevAda developer here, Ada is the name of my daughter, and this project is my gift to her, to remember me. reply pyuser583 4 hours agorootparentCongrats on having a daughter! I hope and day she’ll need to parse a url, and be able to see your love for her in her code! reply EmilStenstrom 14 hours agoparentprevAt least the can_ada (canada!) makes it a little bit more unique. reply Solvency 14 hours agoparentprevIt is mindboggling to me how often developers create project names without even trying to search for precedent names in their own domain/industry. Calling this Ada is just ridiculous. reply pyuser583 14 hours agorootparentAda needs to fight back. Java templating library! Python dependency resolver! Zag image manipulation library! SQL event logging persistence framework! I can’t believe Amazon wasn’t violating some anti-competition rule by using “AWS” for “Amazon Web Services” when it already meant “Ada Web Server.” Wow when I search for “Ada GPS” I get global position system support libraries before GNAT Programming Studio. reply yagiznizipli 7 hours agorootparentprevAda developer here. Ada URL parser is named after my daughter Ada. We chose this name in particular as a reference to Ada Lovelace. reply gjvc 11 hours agorootparentprevyes but they think it's punny/funny/clever reply nine_k 9 hours agorootparentIt's usually a poor reason. Calling the GNU Image Manipulation Program \"GIMP\" was kinda funny and punny, and maybe humble, but not wise. Inkscape or Krita have less poignant, but more reasonable name. (But yes, such an approach removes some of the teenage fun from doing a project.) reply Areading314 15 hours agoprevHard to imagine the tradeoff of using a third party binary library developed this year vs just using urllib.parse being worth it. Is this solving a real problem? reply masklinn 14 hours agoparentAccording to itself, it's solving the issue of parsing differentials vulnerabilities: urllib.parse is ad-hoc and pretty crummy, and the headliner function \"urlparse\" is literally the one you should not use under any circumstance: it follows RFC 1808 (maybe, anyway) which was deprecated by RFC 2396 25 years ago. The odds that any other parser uses the same broken semantics are basically nil. reply woodruffw 12 hours agorootparentI agree that the stdlib parser is a mess, but as an observation: replacing one use of it with a (better!) implementation introduces a potential parser differential where one didn’t exist before. I’ve seen this issue crop up multiple times in real Python codebases, where a well-intentioned developer adds a differential by incrementally replacing the old, bad implementation. That’s the perverse nature of “wrong but ubiquitous” parsers: unless you’re confident that your replacement is complete, you can make the situation worse, not better. reply Spivak 11 hours agorootparent> unless you’re confident that your replacement is complete And that any 3rd party libs you use also don't ever call the stdlib parser internally because you do not want to debug why a URL works through some code paths but not others. Turns out that url parsing is a cross-cutting concern like logging where libs should defer to the calling code's implementation but the Python devs couldn't have known that when this module was written. reply Areading314 13 hours agorootparentprevIt seems unlikely that this C++ library written by a solo dev is somehow more secure than the Python standard library would be for such a security-sensitive task. reply masklinn 13 hours agorootparentNot in the sense of differential vulnerabilities, since the standard library refuses to match any sort of modern standard. It's also 1. not a solo dev 2. Daniel Lemire 3. a serious engineering and research effort: https://arxiv.org/pdf/2311.10533.pdf reply Areading314 13 hours agorootparentThis is the commit history: https://github.com/TkTech/can_ada/commits/main/ I guess you are right that there are 2 commits from a different dev, so it is technically not a solo project. I still wouldn't ever use this in production code. reply masklinn 12 hours agorootparent... can_ada is just the python bindings. The actual underlying project is at https://github.com/ada-url/ada reply bqmjjx0kac 12 hours agorootparentprevThe can_ada repo threw me off, too. It looks super amateurish because of the lack of tests, fuzzers, etc. But it appears that they've just exported the meat of the Ada project and left everything else upstream. reply TkTech 12 hours agorootparentprevHi, can_ada (but not ada!) dev here. Ada is over 20k lines of well-tested and fuzzed source by 25+ developers, along with an accompanying research paper. It is the parser used in node.js and parses billions of URLs a day. can_ada is simply a 60-line glue and packaging making it available with low overhead to Python. reply Areading314 6 hours agorootparentAh, that makes more sense -- it might be a good idea to integrate with the upstream library as a submodule rather than lifting the actual .cpp/.h files into the bindings repo. That way people know the upstream C++ code is from a much more active project. Despite my snarky comments, thank you for contributing to the python ecosystem, this does seem like a cool project for high performance URL parsing! reply yagiznizipli 7 hours agoparentprevAda was developed in eoy 2022, and included in Node.js since March 2023. Since then, Ada powers Node.js, Cloudflare workers, Redpanda, Clickhouse and many more libraries. reply pyuser583 14 hours agoparentprevurlib.parse is a pain. We really need something more like pathlib.Path. reply Ch00k 14 hours agorootparentThere is https://github.com/gruns/furl reply AMCMneCy 13 hours agorootparentAlso https://github.com/aio-libs/yarl reply 4ec0755f5522 8 hours agorootparentI use yarl as my default for this as well, it's been great to work with. reply VagabundoP 13 hours agorootparentprevThis library is very pythonic. reply pyuser583 13 hours agorootparentprevYes! That’s the one I like! reply masklinn 14 hours agorootparentprevThat used to be werkzeug.urls, kinda (it certainly had a more convenient API than urllib.parse), but it was killed in Werkzeug 3. reply pyuser583 14 hours agorootparentI remember and miss that. But I’m not going to install werkzeug just for the url parsing. reply d_kahneman7 11 hours agorootparentIs it that inconvenient? reply joouha 13 hours agorootparentprevYou might be interested in https://github.com/fsspec/universal_pathlib reply bormaj 12 hours agoprevWhy not just use `httpx`? If you're not bound to the stdlib, it's a great alternative to `requests` and url parse reply kmike84 11 hours agoparentThe URL parsing in httpx is rfc3986, which is not the same as WHATWG URL living standard. rfc3986 may reject URLs which browsers accept, or it can handle them in a different way. WHATWG URL living standard tries to put on paper the real browser behavior, so it's a much better standard if you need to parse URLs extracted from real-world web pages. reply gjvc 11 hours agoparentprevhttpx is great, and \"needs to be in base\" reply orf 10 hours agorootparentNo it doesn’t, absolutely not. It’s ironic that you say this after the post you’re commenting on spells out quite explicitly why things “in base” are hard to change and adapt. reply gjvc 50 minutes agorootparentwhere do you draw the line with this approach? reply ojbyrne 12 hours agoprevLooking at the github site for can_ada, I discovered that the developers live in Montreal, Canada. Nice one. reply TkTech 11 hours agoparentI do! :) I should probably also never be allowed to name things. reply ulrischa 14 hours agoprevParsing an url is really a pain in the a* reply SloopJon 14 hours agoparentAnother post in this thread was downvoted and flagged (really?) for claiming that URL parsing isn't difficult. The linked article claims that \"Parsing URLs correctly is surprisingly hard.\" As a software tester, I'm very willing to believe that, but I don't know that the article really made the case. I did find a paper describing some vulnerabilities in popular URL parsing libraries, including urllib and urllib3. Blog post here: https://claroty.com/team82/research/exploiting-url-parsing-c... Paper here: https://web-assets.claroty.com/exploiting-url-parsing-confus... If you remember the Log4j vulnerability from a couple of years ago, that was an URL parsing bug. reply masklinn 13 hours agorootparent> If you remember the Log4j vulnerability from a couple of years ago, that was an URL parsing bug. I don't think that's a fair description of the issue. The log4j vulnerability was that it specifically added JNDI support (https://issues.apache.org/jira/browse/LOG4J2-313) to property substitution (https://logging.apache.org/log4j/2.x/manual/configuration.ht...), which it would apply on logged messages. So it was a pretty literal feature of log4j. log4j would just pass the URL to JNDI for resolution, and substitute the result. reply SloopJon 13 hours agorootparentI didn't look into this in detail at the time, but the report's summary of CVE-2021-45046 is that the parser that validated an URL behaved differently than a separate parser used to fetch the URL, so an URL like jndi:ldap://127.0.0.1#.evilhost.com:1389/a is validated as 127.0.0.1, which may be whitelisted, but fetched from evilhost.com, which probably isn't. reply chirau 15 hours agoprevnext [5 more] [flagged] williamdclt 15 hours agoparent> Parsing urls is not difficult at all I’d like to have 100 developers each write a url parser, and see how many bugs per implementation we can find. I’d guess an average in the double-digits reply zzo38computer 8 hours agorootparentI did write a URL parser (including converting relative URLs into absolute) in C (I also wrote a simple HTTP client, and other protocols). However, it is only intended for use with a limited set of URI schemes (including \"hashed\" and \"jar\", both of which are unusual in the way they are handled). (See the function called \"scogem_parse_url\" in the https://raw.githubusercontent.com/zzo38/scorpion/trunk/scoge... file.) Now, we can find bug in that one, and then if other people mention theirs too, and find bug in other one, then we can see how accurate your guess is. However, there are other considerations. For one thing, WHATWG is not the only specification of the working of URLs, so not everyone will comply anyways. And, some features might be necessary or not necessary in specific applications. reply otherme123 13 hours agorootparentprevMaybe this is a case of \"I could write curl in a weekend\", proceeds to use libcurl one way or the other. reply simonw 15 hours agoparentprevI thought the linked article did a good job of explaining how deceptively hard it is to parse URLs correctly and handle all edge cases. reply bqmjjx0kac 14 hours agoprevWriting a new parser in C++ is a mistake IMO. At the very least, you need to write a fuzzer. At best, you should be using one of the many memory safe languages available to you. I retract my criticism if this project is just for fun. Edit: downvoters, do you disagree? Edit2: OK, I may have judged a bit prematurely. Ada itself has fuzzers and tests. They're just not exported to the can_ada project. reply yagiznizipli 7 hours agoparentAda developer here. Ada has more than 5000 tests, is included in oss-fuzz project and battle tested in Node.js and Cloudflare workers. reply bqmjjx0kac 6 hours agorootparentI apologize for the misjudgment. I just followed the link to can_ada and saw really minimal tests, e.g. https://github.com/TkTech/can_ada/blob/main/tests/test_parsi... I didn't understand that can_ada is not where the parser is developed. reply nerdponx 8 hours agoprev [–] No mention of prior art? The Hyperlink library has stated correctness as its goal for a long time: https://pypi.org/project/hyperlink Of course there is always room for new projects, but it still feels weird to act as if this is the first time anybody has ever tried this. It seems like a lot of people are under this same mistaken impression, at least according to the sample of HN users who commented in this thread. reply TkTech 6 hours agoparent [–] Hyperlink (which I didn't know existed, by the way) is not a parser for the WHATWG spec, it's for RFC3986. You seem to be getting things confused. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article addresses the parsing challenges of URLs in Python, emphasizing the differences between the urllib module and the WHATWG URL spec.",
      "Introduces the Ada project as a high-speed URL parsing library that follows the WHATWG spec, offering Python bindings.",
      "The can_ada Python binding is presented as a quicker option than ada-python bindings, showcasing superior efficiency in URL parsing compared to urllib.parse."
    ],
    "commentSummary": [
      "The conversation revolves around parsing URLs in Python, stressing the necessity of an improved URL parser in Scrapy for efficiency and alignment with WHATWG standards.",
      "The Ada URL parser, inspired by Ada Lovelace, is introduced, sparking discussions on the security risks of swapping the default parser with a third-party option.",
      "Challenges of URL parsing, such as discrepancies in standards and security issues in common libraries, are outlined, offering alternative solutions and factors to ensure precise parsing."
    ],
    "points": 127,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1710608014
  },
  {
    "id": 39725678,
    "title": "Y Combinator's Seibel Steps Down to Mentor",
    "originLink": "https://www.wired.com/story/plaintext-y-combinator-michael-seibel-startup-whisperer/",
    "originBody": "STEVEN LEVY BUSINESSMAR 15, 2024 11:00 AM Y Combinator's Chief Startup Whisperer Is Demoting Himself As the influential startup incubator downsizes—and navigates political pushback—managing director Michael Seibel is taking a new role to spend more time working with founders. Y Combinator's 2024 W24 retreat group.COURTESY OF Y COMBINATOR When Michael Seibel lost his position at the startup incubator Y Combinator, he didn’t find out in typical tech industry fashion, which might entail an email calling him to a Zoom meeting where the bad news would be delivered. He did it to himself. Today Seibel is announcing that he’s stepping down as YC’s managing director, a job that entailed running the heart of the business: selecting startup founders for the three-month program and running the boot-camp-style operation that hones the vision and execution of their ideas so they can raise money, release products, and attempt to become the next Airbnb or Stripe (both YC alumni). Considering how important YC has been to the tech startup ecosystem, Seibel’s exit will have more resonance than your average corporate reshuffle. For one thing, the person who runs YC’s blue-chip accelerator has a significant hand in shaping the next generation of tech companies. And in recent months, YC has found itself in the crossfire of a war between tech and progressives. Whether intentional or not, Seibel, a well-liked entrepreneur and investor himself, is deftly stepping out of the line of fire. This is an edition of Steven Levy's Plaintext newsletter. SIGN UP for Plaintext and tap Steven's unique insights and unmatched contacts for the long view on tech. Seibel explains the move as a more personal decision. Sometime last year he began to take stock, spurred in part by reading Strength to Strength, a book about career arcs, particularly pivots made late in life. He’s only 41, but precociousness is part of the founder mindset, and he’d been a startup CEO at 23. “I do everything early,” he says. Michael SeibelCOURTESY OF Y COMBINATOR He realized that he had been running batches for as long as the person who first imagined YC into being, Paul Graham. After Covid waned, YC had returned to an in-person experience, and the software that it had developed to smooth the remote Covid-era program made an IRL operation easier to manage. Now the program works by splitting each batch of new startups into four groups, none larger than Dunbar’s Number of 150, estimated to be the maximum number of relationship’s a human brain can properly maintain. Each group has its own leader, so YC had less need for someone to oversee each cohort as a whole. And though Seibel enjoyed managing the overall program, he much preferred direct contact with company founders. So he will now become one of those four group leaders, who each mentor a quarter of the batch. It’s a particularly exciting time to do that, Seibel says, as many of the companies hinge on the AI boom. Close observers of YC—and many in the startup ecosystem monitor the accelerator with the diligence of a behavior-tracking ad network—might wonder whether Seibel’s move might have something to do with his being passed over for the leadership of the entire operation. Forbes has reported that he was disappointed not to be tapped as CEO after the incubator’s president, Geoff Ralston, who had taken over when Sam Altman went full time leading OpenAI, left at the end of 2022. Ralston was replaced by YC’s former design guru, Garry Tan. Seibel tells me he did not feel dissed, though he would have accepted the job if offered. “If it was something that people thought was going to be the right thing, I was happy to do it. If not, I was more than happy to not,” he says. “My whole goal was to do whatever YC needed for me.” Seibel’s self-demotion seems to be in keeping with a recent rethinking at Y Combinator: a refocusing toward a scrappy, boots-on-the-ground startup accelerator as it was under its initial leader and cofounder Graham. His successor, Altman, started a sprawling research operation that, among other things, launched OpenAI. Ralston had his own dreams, and YC started a continuity fund to enable it to make later-stage investments into maturing startups. Ralston was also enamored with scale. The Winter 2022 batch included 412 companies, each funded by the traditional seed investment from YC. Ralston boosted that initial slug of capital from $125,000 to $500,000 per company, for a 7 percent stake. When I last asked him whether there was a limit to how many startups YC could accommodate in each batch, Ralston said there wasn’t. It was possible, he believed, for a batch to number “thousands” of startups. Under Tan, who took over in January 2023, there’s been a refocus on the founders themselves. Tan says YC had become kind of an umbrella company saying yes to a lot of things. “I asked, ‘How do we focus on what made YC awesome in the first place?’” The answer was mentoring cool founders, chosen through an exacting application process. The continuity fund was discontinued. YC had already separated itself from Altman’s research division, which is now called Open Research. The only remaining trace of Altman’s research operation within the company now is a financial stake in OpenAI. Most notably, batch sizes have been cut almost in half. Beginning Summer 2022, they numbered in the mid 200’s, with the current batch inching up to 260. This isn’t due to demand—27,000 companies applied for those slots. MOST POPULAR POLITICS New Far-Right Conspiracy Claims Boeing’s Accidents Are Intentional DAVID GILBERT CULTURE The Kate Middleton Photo’s Most Glaring Photoshop Mistakes REECE ROGERS SCIENCE States Are Lining Up to Outlaw Lab-Grown Meat MATT REYNOLDS SECURITY There Are Dark Corners of the Internet. Then There's 764 ALI WINSTON That’s more intense competition than gaining entry to an elite university like Harvard or Stanford, which Y Combinator is often likened to. While Seibel resists the comparison, I suspect that, as with Harvard, many of those 27,000 applicants to YC are just as interested in the halo that comes from being accepted and in getting access to its network of alumni as they are in the education that they will get. When I ask Tan whether YC might now be part of the establishment, his pushback is tepid. “It was probably entering that realm,” he says. “I like to still think of this as entrepreneurs trying to figure it out—like Rage Against the Machine.” Speaking of rage, it’s a good word to summarize how a lot of progressives feel about the tech industry. There’s an ongoing battle in San Francisco between techies demanding the city adopt tougher policies in the pandemic-blighted downtown area and liberals who cherish the city’s antiauthoritarian heritage. In May 2023, YC moved its headquarters from Mountain View to a large pier facility in San Francisco, steering itself into the teeth of this controversy. And one of the loudest voices in the conflict has been Tan, a participant of the movement to recall the city’s progressive district attorney and a source of intemperate tirades against the civic leaders. In an era of tech scrutiny, the ethic of Y Combinator—which sees mentoring founders as akin to a social good to wider society—is being questioned. In the early days of YC, the fabled interviews that determine entry to the program had a vibe of American Idol to them. Founders were underdog talents reaching for the brass ring of glory. Now it’s more like being tapped for a secret society like Skull and Bones: Simply getting accepted means you will be not only well-funded, but cosseted by a network of 10,000 founders eager to help you out. Not exactly underdogs. Though Seibel disagrees: “When you’re a startup the whole ecosystem is the underdog,” he says. “Here in the Bay Area, we're surrounded by the big tech giants.” That stance is pure Seibel. If nothing else, his conscious self-demotion puts a spotlight on an entrepreneur whose modest public profile belies a powerful impact on the startup world. I first met him in 2007, when he was a recent graduate of YC, a cohort then in low double digits. Seibel’s company was a wacky project called Justin.tv, devoted to livestreaming people’s lives 24/7, starting with that of eponymous cofounder Justin Kan. These looney videographers prowled a San Francisco highrise where so many YC founders rented space that it was nicknamed the “Y-scraper.” One might argue Justin.tv was a precursor to the influencer economy—after several pivots it morphed into streaming platform Twitch, purchased by Amazon for almost a billion dollars. Seibel had a talent for sharing the essentials of foundership. He was also African American, relatively rare in a field overly dominated by privileged, white Stanford grads. His upbeat demeanor and canny knowledge of the inside game of growing a company has benefited hundreds of startups. And since he is a personal investor in dozens of companies, and is on the boards of Reddit and Dropbox, the association with YC has been very good to him as well. MOST POPULAR POLITICS New Far-Right Conspiracy Claims Boeing’s Accidents Are Intentional DAVID GILBERT CULTURE The Kate Middleton Photo’s Most Glaring Photoshop Mistakes REECE ROGERS SCIENCE States Are Lining Up to Outlaw Lab-Grown Meat MATT REYNOLDS SECURITY There Are Dark Corners of the Internet. Then There's 764 ALI WINSTON While becoming the CEO of Y Combinator might have been a capstone to his career, he says he’s a huge fan of Tan’s and is feeling great about his decision to move away from management to become more hands-on with future founders. “I always knew I wanted to kind of teach as my last job,” Seibel says. “Could you imagine teaching anywhere better than here?” Maybe … a university? I hear that there’s some teaching at those places as well. Time Travel I’ve embedded inside two different Y Combinator batches. The first was for Newsweek, when all of 12 startups were in the game. Four years later I returned to track the much larger Winter 2011 batch for WIRED. That cohort was transformational for YC, as midway through the process a surprise announcement dramatically changed the terms for every wannabe unicorn: Instead of an initial investment of around $20,000 for each company, every participant was staked $150,000. (These days, each startup gets $500,000.) Here’s a description of the moment that happened in late January 2011. A couple of days after Prototype Day, the class convenes for a special Friday-night session at YC headquarters. Nobody knows why they are there; when Graham announced the mandatory meeting, he gave no clue as to what he had planned. There has, however, been plenty of speculation. Is there going to be a big party for [YC cofounder] Jessica Livingston’s 40th birthday? Is Steve Jobs going to speak? Is Barack Obama? Now Graham stands before the class. In an early sign of the evening’s significance, he is actually wearing long pants. He introduces the group to Ron Conway, the noted angel investor. Then Graham introduces a special guest, Yuri Milner. Milner has been conducting a relentless campaign to become a prominent Silicon Valley investor, putting hundreds of millions into Facebook, Groupon, and Zynga. Milner is not in Mountain View; he’s attending the World Economic Forum in Davos. But [YC partner Trevor Blackwell] has set him up with one of the Anybots, which Milner can control remotely from Europe. A tiny screen atop the wheeled robot’s saucer-shaped “head” carries a projection of Milner’s face, allowing him to talk to the group. MOST POPULAR POLITICS New Far-Right Conspiracy Claims Boeing’s Accidents Are Intentional DAVID GILBERT CULTURE The Kate Middleton Photo’s Most Glaring Photoshop Mistakes REECE ROGERS SCIENCE States Are Lining Up to Outlaw Lab-Grown Meat MATT REYNOLDS SECURITY There Are Dark Corners of the Internet. Then There's 764 ALI WINSTON “So, the surprise,” Graham says, gesturing to Conway and the Milner-bot, “is that they want to invest in all of you.” For a few seconds there is stunned silence as 99 founders try to process this news. It’s like a denial-of-service attack on their brains. Finally, there’s a collective exhale and a round of applause. This is good. Then Graham explains the terms that Milner is offering in collaboration with Conway’s firm, SV Angel: “$150,000 on a convertible note,” he says. “No cap.” Translation: Instead of demanding a relatively large share for their ground-floor stake, Conway and Milner are agreeing to invest at whatever valuation the next round of investors sets. In other words, they get no advantage from taking such an early position. These are the most founder-friendly terms imaginable, with no downside. The room erupts into applause, hoots, and shouts. The budding entrepreneurs look like an Oprah audience after learning that everyone is getting a free Pontiac. Ask Me One Thing Lesley asks, “Why has Apple abandoned their not-so-secret car project?” Thanks for the question, Lesley. I suspect Kevin Lynch, the brilliant engineer who moved from heading the Apple Watch franchise to Apple’s auto venture codenamed Titan, might be asking the same question. Then again, he might be among the few that really know the answer. I don’t! Surely among the reasons are factors that outside pundits have cited. Cars have lower margins than digital products. Weakening government resolve to push for electric vehicles means that automakers would get fewer tax breaks and an insufficient battery-charging infrastructure. Fully autonomous driving, which was allegedly the original idea for an Apple Car, has proven to be incredibly difficult to realize. With those thoughts in mind, Tim Cook might well have balked at spending the hundreds of billions of dollars necessary to ramp up manufacturing for an auto company significant enough to make Tesla look like Tinkertoy. MOST POPULAR POLITICS New Far-Right Conspiracy Claims Boeing’s Accidents Are Intentional DAVID GILBERT CULTURE The Kate Middleton Photo’s Most Glaring Photoshop Mistakes REECE ROGERS SCIENCE States Are Lining Up to Outlaw Lab-Grown Meat MATT REYNOLDS SECURITY There Are Dark Corners of the Internet. Then There's 764 ALI WINSTON But let me suggest another reason that Cook unplugged this decade-long project. I find it significant that many of the engineers on the project have been transferred to work on generative AI. Maybe Apple realized that the very survival of a major tech company depended on being a major player in this hot area. Instead of trying to lure outside talent—a difficult task in this ultra-competitive arena—it instead opted to reassign a handy internal stock of machine-learning acumen, the engineers futilely banging away on Titan. You can submit questions to mail@wired.com. Write ASK LEVY in the subject line. End Times Chronicle Driven by power-hungry data centers, power plants are overwhelmed. And new ones to replace them will be fossil-fuel burning climate killers. Last but Not Least Seibel is on the board of Reddit, part of YC’s first batch. Could its impending IPO be a threat to the platform’s survival? The judge has spoken: Craig Wright is not Satoshi. MOST POPULAR POLITICS New Far-Right Conspiracy Claims Boeing’s Accidents Are Intentional DAVID GILBERT CULTURE The Kate Middleton Photo’s Most Glaring Photoshop Mistakes REECE ROGERS SCIENCE States Are Lining Up to Outlaw Lab-Grown Meat MATT REYNOLDS SECURITY There Are Dark Corners of the Internet. Then There's 764 ALI WINSTON The horrifying story of 764, a network of child predators operating on Discord, Minecraft, Roblox, and other sites popular with young people and teens. Here are our favorite pillows. Wake me when this year is over. Don't miss future subscriber-only editions of this column. Subscribe to WIRED (50% off for Plaintext readers) today.",
    "commentLink": "https://news.ycombinator.com/item?id=39725678",
    "commentBody": "Y Combinator's chief startup whisperer is demoting himself (wired.com)120 points by bookofjoe 18 hours agohidepastfavorite113 comments JCM9 16 hours agoI find the “demoting” term amusing / inaccurate. He’s in a career position to do basically whatever he wants and is doing just that. That seems like the ultimate role / achievement that’s far higher than any position on an org chart. Like a startup founder that realizes being CEO isn’t all it’s cracked up to be and they just want to go back to building, which is what they truly enjoy in life. Congrats and more power to you. reply Fomite 6 hours agoparent\"I'm demoting myself to Chief Do Whatever I Please Officer\" hits a little different than most demotions. reply arthurcolle 4 hours agorootparentyeah, looking at this from this lens makes it much more of a no-op I wish I could do the same lmao reply sytelus 9 hours agoparentprevExactly. These people are centi-millionaires and beyond employment, promotions, bonuses and all that usual drudgery. I guess the article is funded purely not to injure egos. But, hey, what is all that downscaling of YC? The article is clearly official press release and paid for. reply PhasmaFelis 7 hours agorootparent> These people are centi-millionaires They have $10,000? reply lstamour 7 hours agorootparentThe dictionary suggests this means they have $100 million. Likewise centibillionaire means $100 billion. reply chillingeffect 6 hours agorootparentWhat dictionary is that? Im American and even here we learned hecto means 100 in 1st grade. Centi means 1/100th. (1) e.g. centifoot = 1/100th of a foot. (1) https://dictionary.cambridge.org/dictionary/english/centi reply cshimmin 6 hours agorootparentcentifoot... You had centimeter right there! \"Americans will do anything to avoid using the metric system\" lol reply smcnally 4 hours agorootparent“American Football is a game of centiyards, not feet.” — Official Hand-egg rulebook reply eredengrin 6 hours agorootparentprevYeah would've made way more sense. Either that or centigrade. reply runlaszlorun 5 hours agorootparentprevcentipounds? reply lolinder 5 hours agorootparentprevHecto- is the Greek root for 100, centi- is the Latin root for 100. The metric prefixes up to 1000 use Greek roots for the large prefixes (10^+n) and Latin for the small (10^-n), but there are also words that are derived directly from the respective Latin roots and therefore don't necessarily carry the metric system's fractional meaning. Someone already linked to the definition of centimillionaire, but here are a few more: * centipede (100 legs, not 1/100 of a leg) * centenarian (100 years old, not 1/100 of a year old) * millennium (1000 years, not 1/1000 of a year) reply brianfitz 6 hours agorootparentprevhttps://www.merriam-webster.com/dictionary/centimillionaire reply HPsquared 5 hours agorootparentReminds me of how financial newspapers often use a small \"m\" when describing millions of something. \"$500m\", or even worse \"500m USD\"... The engineer in me says that's 50 cents! reply a_gnostic 4 hours agorootparentprevCentiliter = 0.01L Hectoliter = 100 L reply DirkH 4 hours agorootparentYou: logic The English language: \"allow me to introduce myself!\" reply Nevermark 4 hours agorootparentprevCentennial = 100 years Centurion = Commander of 100 legionaries reply lolinder 4 hours agorootparentprevCentipede = 100 legs Etymology is more complicated than \"look up the prefix in the metric system tables\", and OP is correct about the definition of centimillionaire. https://www.merriam-webster.com/dictionary/centimillionaire reply a_gnostic 1 hour agorootparentCentipede is Entomology reply clpmsf 11 hours agoprevIt's truly hard to believe that Michael Seibel wasn't appointed as CEO, and equally hard to believe that Garry Tan was. reply appplication 10 hours agoparentI don’t know anything about either of these people or the nuance of their professional qualifications, and I think that probably also holds true for 99% of other people who will see your comment. A bit more context might be helpful. reply gurchik 4 hours agoparentprevWasn't he the CEO in the past? I see him referred to as \"CEO\" in some places, like [1], but I can't find any announcement or news article about when this changed. 1: https://techcrunch.com/2020/03/16/yc-ceo-michael-seibel-open... reply reducesuffering 9 hours agoparentprev\"For an institution that had historically promoted from within, first with Sam Altman, now CEO of OpenAI, then Ralston, the Tan era came as a shock. Within YC, many staff had wanted Michael Seibel, the cofounder of Twitch and YC’s longtime batch leader, to get the job. Multiple sources remembered longtime partner Dalton Caldwell vocalizing what others were feeling, too: we’re all just employees who work here, message received. Seibel, meanwhile, wrote a letter to YC’s board to explain his disappointment at being passed over, despite broad internal support. He vowed to support Tan moving forward, anyway. Caldwell and Seibel declined to comment on those incidents through a YC spokesperson.\" https://www.forbes.com/sites/alexkonrad/2024/03/08/inside-ga... https://archive.is/a4Tno#selection-615.0-623.266 reply hnthrow01 9 hours agorootparentPG has thrown his weight behind boosting questionable builders (50% supportive tweets were about Austen Allred's Lambda School and Suhail's Mighty). Now Tan, who is throwing tantrums on Twitter (\"die slow motherfucker\"), while passing on someone like Seibel? I suppose all of them were still sadly supportive of the SVB bailout, \"government cronyism for me, capitalism for thee\". So much for any illusion of libertarian ethos. If Garry Tan stays long as YC CEO, I'm betting we have a mutiny and a fork form. It looks like Seibel isn't going to do all the work of leading the batch while Tan reaps the larger share of rewards. reply jejeyyy77 10 hours agoparentprevwhat has Michael Seibel done? reply ryandamm 6 hours agorootparentTwitch? reply fuzztester 9 hours agoparentprevWhy is truly hard to believe a fact, or two? Last I heard, facts don't have to be believed; they just exist. reply zaphirplane 9 hours agorootparentIt’s an expression reply fuzztester 8 hours agorootparentDude. Think I don't know that? I got my Master's in English at the Shipbuilders' College of Arizona ;) Mine was a humorous expression about a pseudo-boolean expression. reply swyx 17 hours agoprevsiebel’s podcast youtube series with dalton caldwell of founder advice has been great recently, in case anyone hasnt been following reply neom 17 hours agoparentDalton & Michael - https://www.youtube.com/playlist?list=PLQ-uHSnFig5Nd98Sc9I-k... reply asim 16 hours agoparentprevIt's a gem. What I'm curious about is how these two ended up at YC as partners and not founding another company. I think I know the answer but always interested to know other people's journeys. reply light_triad 16 hours agorootparentAs Michael has said in one of the shows getting to PMF is a miracle. If you’re already set for life it’s less risky to play the odds by investing in hundreds of startups rather than starting one. Also there’s altruistic motives in giving back to the community etc. reply arbuge 7 hours agorootparent> If you’re already set for life it’s less risky to play the odds by investing in hundreds of startups rather than starting one. Risky is not the word I would use to phrase that, at least not in the financial sense. There's little such risk there, \"if you're already set for life\" as you said. More comfortable, for sure. Easier. PG has said as much himself on X several times when asked whether starting a company or investing was harder. reply jjtheblunt 15 hours agorootparentprevWhat is PMF ? reply prasoonds 15 hours agorootparentProduct Market Fit. Basically, can you find through iteration something that people really want and are willing to pay for reply fuzzy_biscuit 15 hours agorootparentprevProduct Market Fit reply phantompeace 15 hours agorootparentprevProduct Market Fit reply romeros 16 hours agorootparentprevI think pg said it best in one of his tweets/essays ?? not sure. Essentially starting a startup is super hard. You can't just chill/half ass and still do well even if you had already succeeded before. reply 7e 16 hours agorootparentprevEveryone at YC knows exploiting naive founders is more profitable and less risky than doing a startup. The key is to perpetuate a mythical cult around the startup and convince huge swaths of kids to give you equity for almost nothing. The chumps are the founders, not the investors. reply simonw 15 hours agorootparent\"The key is to perpetuate a mythical cult around the startup and convince huge swaths of kids to give you equity for almost nothing\" I found that amusing seeing as the second most recent video in their series, \"Should Your Startup Bootstrap or Raise Venture Capital?\", spends most of its time making a strong case for why VC isn't right for the vast majority of founders: https://www.youtube.com/watch?v=D81y-kh11oI reply WalterSear 8 hours agorootparentIMHE as part of multiple YC-backed founding teams, this is a new tone from YC. In the past they have been very condescending of anything that doesn't involve trying to be a unicorn as fast as possible. There's even a video in their catalog deriding 'lifestyle' (ie - non-vc, non-unicorn, non-blitz-scaling) startups. It makes sense given their business model, but I found it distasteful that they were advising young, impressionable entrepreneurs to take on more risk and to move away from their core competencies: greatly reducing the entrepreneurs' own chances of success in order to give YC and their associates another lottery ticket for a billion dollar payoff. reply svnt 10 hours agorootparentprevGatekeeping/exclusivity is part of the play. Strategic self-anticonformity. reply latency-guy2 8 hours agorootparentI think you've assembled words in an orientation that might make sense to you, but it doesn't to me. Can you expand? How does this relate to the parent comment? reply fakedang 12 hours agorootparentprevTbf that video came pretty late (post the ZIRP era). Before that, YC was one of the strongest proponents for raising VC because that's ingrained in their business model. I've heard that YC before would be quite disappointed at founders choosing not to raise money, because that meant a lower upside for them via the SAFE model. Not to mention, most YC exits are usually via acquisitions, and often between YC companies. reply simonw 9 hours agorootparentRight, YC are a VC firm themselves - so if you don't want to do the VC rocketship thing they're probably not the right match for you. reply coffeemug 10 hours agorootparentprevWhat would a version of YC that doesn't exploit naive founders look like? reply password4321 8 hours agorootparentI think that's the sales pitch for https://tinyseed.com/ reply riehwvfbk 9 hours agorootparentprevGoogle (in its heyday) reply intelVISA 14 hours agorootparentprevBootstrapping > VC reply ren_engineer 9 hours agorootparentprevthe worst case scenario for being a YC founder is probably a 500K+ job at FAANG or another YC startup if you fail reply molsongolden 9 hours agorootparentThis isn’t really true though. Plenty of founders are early career and don’t have the experience or chops to pull that kind of salary. Many founders are not very impressive but what they have is confidence (however blind) in their ability to do the thing. reply idiotsecant 15 hours agorootparentprevEffort and result are not synonyms. YC investors take a big risk - a lot of these startups will have well intentioned and hard working founders and they will fail anyway. VCs provide a valid service. They make money (if they are good guessers and are also lucky) and founders make money (if they work hard and smart and are also lucky). Everyone wins. reply joshxyz 10 hours agorootparentprevits quite wild how sam altman left and did it again though, these guys are crazy good reply 7e 16 hours agorootparentprevEveryone at YC knows exploiting naive founders is more profitable and less risky than doing a startup. The chumps are the founders, not the investors. reply TimPC 11 hours agorootparentIf you have a great team going to YC helps lower your downside. The most successful companies in your cohort are likely to acquihire you when they need to grow quickly. reply seizethecheese 13 hours agorootparentprevExploiting by giving half a million dollars and taking no control? Right. reply robocat 11 hours agorootparentYC tag teams to VCs who definitely game the system. YC sells a good founder friendly story and it seems believable and YC is a repeat player so they care about their reputation: however the financial incentives of YC are not well aligned with founders (for example YC gets preferential shares, and founders get common stock). The best writing on this is: https://siliconhillslawyer.com/2019/02/18/relationships-and-... https://siliconhillslawyer.com/2019/05/01/startups-shouldnt-... https://siliconhillslawyer.com/2019/03/03/standard-term-shee... The issues of control only really matter for the few unicorn winner companies. YC can afford to be very founder friendly to loser companies or to founders before the company becomes a clear winner. Founders of winning companies are not going to publicly complain if YC is less than fair. reply dilyevsky 10 hours agorootparentIf vc doesn’t get preferred shares, someone can just turn around and immediately sell the company for $400k and keep 90% of the money so that would seem like a silly thing to complain about reply robocat 10 hours agorootparentDon't be \"silly\": that is just the standard bullshit argument. It is a poor argument because it is entirely possible to come up with terms that could be written into the contracts to prevent that obvious scenario. I wouldn't be surprised if tag-along or preferential rights or other clauses don't already prevent that scenario. Anybody know? Founders often invest $100000's of their time - yet they are not given equivalent value in preferential shares. The game is rigged! reply echelon 13 hours agorootparentprevAlmost every major tech company took capital. Almost every major company period took capital. Money is energy and time. You can do it without these, but the gradient is steeper. reply robocat 12 hours agorootparent> major Selection bias. The median return for a founder is about $0. If you want to be a billion+ market cap company, sure, use capital to get there. But chances are that the startup will fail. VC investing is diversified - a founder is not. reply aleph_minus_one 8 hours agorootparent> VC investing is diversified - a founder is not. Founders are free to make agreements to swap equities of their companies with each other. For simplicity assume that there exist three startups with a similar estimated company value. Each founders gives two 10 % equities (and keeps 80 %) of his startup to each of the two founders of the other two startups. This way, the risk of founding a startup becomes a little more diversified. reply patrickhogan1 16 hours agoparentprevTheir chemistry is perfect. As funny as the Silicon Valley show. With practical advice. They keep it real. Building a company is hard. reply swyx 13 hours agorootparent> As funny as the Silicon Valley show hey now. jury is out until I see them derive middle out from first principles reply bengale 12 hours agoparentprevThose are really great videos. reply Simon_ORourke 17 hours agoparentprevIt's awesome, like it lots too. reply ackbar03 17 hours agoparentprevmy favorite out of their YC videos. I really like the way those two think through things. reply bookofjoe 18 hours agoprevhttps://archive.ph/2m3YN reply happytiger 3 hours agoprevIf the focus is on doing what’s best for founders, and doing a job that’s closer to founders helps them more than a high prestige but less effective position, that’s what you do. Hats off to him. He’s living by principle and acting like the absolute gem of a human being he is. reply grensley 11 hours agoprevThis is how it should be to be honest, and in tech everything gets compressed because of how fast it moves. - Energy of the young -- doers - Leadership of the middle aged -- management - Wisdom of the elderly -- advisors It feels like so often we put the elderly in this executive roles, when really they should have a seat at the table, but not be the preeminent decision makers. reply gsk22 10 hours agoparentSounds like an exercise in futility -- why would the young \"doers\" listen to the elder \"advisors\"? History shows they'll roll their eyes at the (supposed) outdated advice from the advisors and ignore their wisdom. reply grensley 6 hours agorootparentOversimplification but often I think it's: Elderly wisdomMiddle-aged evaluationYouthful application The problem occurs when this doesn't line up with management structures and you get Elderly dictation => Middle-aged helplessness => Youthful disillusionment reply dibujaron 8 hours agorootparentprevWisdom of the elders usually comes in the form of reasons not to do X. If the young doers heeded all of our elders' advice all of the time, we would be cautioned and red-taped into not accomplishing anything in a meaningful timeframe. As a young doer, I politely listen to the advice of my elders, accept about half of it as truth, and privately roll my eyes at the other half. As an elder, the best you can do is try to deliver your advice effectively so it lands in the first half. reply mandeepj 11 hours agoprev> navigates political pushback can someone please share some context around that? Thanks. reply Exuma 11 hours agoprevIs that photo the Y Combinator office? That looks super quiant and nice to work in... reply xandrius 3 hours agoparentStill an office to commute from and to though. reply jwilber 10 hours agoprevI’m very fortunate to have had Michael as a partner during YC and can’t say enough good about him. Great guy who really seems to care and wants to give back. reply ldjkfkdsjnv 15 hours agoprevThis guy probably made atleast 100 million. Can we just call it retiring reply joshxyz 11 hours agoprevi just fucking love this guy. the Dalton & Michael series at their youtube, i learn a lot!! reply dancemethis 17 hours agoprevnext [2 more] ...A what? reply neom 16 hours agoparenthttps://www.merriam-webster.com/dictionary/whisperer reply kosolam 17 hours agoprevnext [11 more] [flagged] dang 13 hours agoparentPlease stop posting generated comments. They're not allowed here. reply kosolam 12 hours agorootparentWhere is this stated? And who decided that generated content is not allowed? reply pvg 12 hours agorootparentA site moderator just told you and I linked you a bunch of previous comments to that effect, so it's stated there. It's 'decided' by the community of HN participants - generated comments are some of the fastest flagged comments around. Few things on HN reach that kind of hive mindmeld that quickly. reply kosolam 11 hours agorootparentLol “the community of HN participants”. Do you understand how this looks like? And you are doing it completely in public view… reply joshxyz 10 hours agorootparentthose generated comments are trash man. if i ever see my kid doing that, there's gonna be some decent ass whoopin for not preserving the humanity left in this corner of the internet. reply kosolam 10 hours agorootparentprevWhat the hell is wrong with you to beat your own kid for using ai? Wow reply dexwiz 17 hours agoparentprevIs this an AI summary? reply kosolam 17 hours agorootparentYes reply icepat 17 hours agorootparentPlease don't do that, it's no-effort posting. If everyone started posting AI generated comments, this site would become worthless really quickly. Part of why I come here is to avoid the AI and botspam junk that's taking over everywhere else. reply 17 hours agorootparentprevnext [2 more] [dead] pvg 17 hours agorootparenthttps://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply alsetmusic 17 hours agoprev [21 more] Meh… I don't know why I would care about this. Apologies for being dismissive, but if this wasn't HN, a subdomain of YC, I don't think this would be here. It's not tech or science or any of the other pursuits of knowledge that drive this site. This is better suited to the Financial Times. reply Phiwise_ 17 hours agoparentHN has regularly featured startup news since the beginning, and Ycombinator is probably the most newsworthy player in the space on a significance-to-spammyness scale. I don't love this article but something about the news should be here. reply tracerbulletx 16 hours agoparentprevBusiness news especially start up news has always been here. I'd like to make a wider point that tech workers should embrace business and the understanding of how business works and make it a central part of their worldview, it is essentially the technology of civilization. Otherwise you abdicate leadership to the exact type of people that make a lot of other people rightly irritated or downright spiteful at the business side of tech in the first place. It doesn't actually have to be so bad. reply solardev 16 hours agorootparentIt's a fair point, but I actually wish we had a hacker community like this without the business/startup side at all. It's just not that interesting to me. As for abdicating leadership, I don't know that simply following in their footsteps is going to make better organizations either. That's just \"if you can't beat em, join em\" thinking... but that's a separate discussion, I suppose. reply ghufran_syed 14 hours agorootparentas a hacker, couldn’t you write a browser plug-in to filter out the subjects you don’t want to see? reply solardev 13 hours agorootparentWell, I can just skip the topics I'm not interested in. It's just that there's a pretty clear bias here for startup-capitalist mentality (which is fine, just not really for me), and it's harder to find people discuss the things that challenge that status quo system (politics, socialism, tech coops, etc.). I think the moderators here do a great job, but at the end of the day it's still a service of YCombinator, and that draws a certain crowd. I prefer to gently step away from the financial side of that Venn diagram, personally, but there are also many people here who come here specifically FOR that, which I have no problem with. I just miss the old Slashdot, probably, with high-quality tech discussions but less of an emphasis on the business side of things and the startup hustle culture. reply simonw 15 hours agorootparentprev\"I actually wish we had a hacker community like this without the business/startup side at all\" Sounds like you want https://lobste.rs reply solardev 13 hours agorootparentWhat's that? Is it invite-only (and why)...? reply lukan 11 hours agorootparentInvite only, yes. Probably because so it stays the way it is and they do not want to discuss all their style again and again and again. reply kstrauser 16 hours agoparentprevEven if this weren’t somehow tech news - which it is - I get a lot of value out of reading things posted here. If YC, the org paying the bills so I can read this for free, wanted to talk about themselves on occasion, I wouldn’t begrudge them. They definitely haven’t abused it. reply joshxyz 10 hours agoparentprevidk about chu but as a yc fanatic this is a breathe of fresh air from most of the news out there. these yc partners really put a lot of effort in their work. reply hluska 17 hours agoparentprev [–] I’m sorry, but have you heard of Y Combinator? reply detourdog 16 hours agorootparent [–] This may seem funny but at least some of this sites demographic only know of ycombinator from HN. My attitude is that anything on HN that I'm not interested I don't bother thinking about. reply macintux 16 hours agorootparent [–] I’m only aware of YC from here, and I couldn’t tell you more than 2 or 3 facts about it, and I suspect at least one of them is wrong. reply rfrey 16 hours agorootparent [–] That's interesting. I wonder how the current population of HN splits between people who heard of HN because of YC (that describes me), and people who heard of YC because of HN. reply Retr0id 15 hours agorootparentI'm in the latter camp. I'm largely uninterested in startup culture etc., but HN is one of the better sources of \"interesting tech and associated discussion\". Given that, I'm not sure why I clicked on this article... reply Icathian 15 hours agorootparentprevI'm definitely in the latter bucket, though I've been here a long time now. I found HN as technical subreddits started to no longer satisfy my curiosity about tech, and fell in love. I originally learned about the startup ecosystem from lurking around here. reply bookofjoe 15 hours agorootparentprevI'm the latter. reply simonbarker87 15 hours agorootparentprevI’ve had my account here since 2012 and I only know about YC because of HN. That also seemed to be in YC’s golden years as well as far as I can tell. At this point YC is a bit of a nothing burger best I can tell so HN is, I would imagine, far and away the bigger brand. reply ahstilde 5 hours agorootparent> YC is a bit of a nothing burger How do you figure that? Looking at their homepage, it says the companies they've invested in are worth a sum $600B. reply chasd00 15 hours agorootparentprev [–] I only know of YC because of HN. I know nothing about YC except it seems to be one of the many incubators where you pay them handsomely one way or the other in the hopes they can get you off the ground. I guess like the self help section of an old bookstore. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Y Combinator managing director Michael Seibel steps down to mentor startup founders directly amid the organization's restructuring.",
      "Former CEO now focuses on mentoring a quarter of each batch, emphasizing founder mentoring and smaller group sizes at YC.",
      "The article discusses YC's evolution, intense competition for entry, Seibel's successful career, and various tech topics but includes a WIRED magazine subscription offer."
    ],
    "commentSummary": [
      "The discussion delves into Y Combinator's role, leadership changes, conflicts, and founder exploitation in startups, emphasizing control, financial incentives, and a technology-focused hacker community.",
      "It addresses the importance of diversity in decision-making, generational leadership gaps, and worries about AI-generated comments dominating the platform.",
      "Furthermore, there is an exploration of the significance of business news, content preferences, and limited awareness of Y Combinator as an organization."
    ],
    "points": 120,
    "commentCount": 113,
    "retryCount": 0,
    "time": 1710595452
  },
  {
    "id": 39724966,
    "title": "The Challenges of Power Consumption in Advanced Chip Design",
    "originLink": "https://semiengineering.com/the-rising-price-of-power-in-chips/",
    "originBody": "Submit Subscribe Chinese (Simplified) English Home Systems & Design Low Power - High Performance Manufacturing, Packaging & Materials Test, Measurement & Analytics Auto, Security & Pervasive Computing Special Reports Business & Startups Jobs Knowledge Center Technical Papers Home '; AI/ML/DL Architectures Automotive/ Aerospace Communication/Data Movement Design & Verification Lithography Manufacturing Materials Memory Optoelectronics / Photonics Packaging Power & Performance Quantum Security Test, Measurement & Analytics Transistors Z-End Applications Events & Webinars Events Webinars Videos & Research Videos Industry Research Newsletters & Store Newsletters Store MENU Home Special Reports Systems & Design Low Power-High Performance Manufacturing, Packaging & Materials Test, Measurement & Analytics Auto, Security & Pervasive Computing Knowledge Center Videos Business & Startups Jobs Technical Papers Events Webinars Industry Research Newsletters Store Low Power-High Performance The Rising Price Of Power In Chips More data requires faster processing, which leads to a whole bunch of problems — not all of which are obvious or even solvable. March 14th, 2024 - By: Ed Sperling Power is everything when it comes to processing and storing data, and much of it isn’t good. Power-related issues, particularly heat, dominate chip and system designs today, and those issues are widening and multiplying. Transistor density has reached a point where these tiny digital switches are generating more heat than can be removed through traditional means. That may sound manageable enough, except it has created a slew of new problems that require the entire industry to solve — EDA companies, process equipment makers, fabs, packaging houses, field-level monitoring and analytics providers, materials suppliers, research groups, etc. Underlying all of this activity is a continued focus on packing more transistors into a fixed area, and an associated and accelerating battle with leakage power. FinFETs solved leaky gate issues at 16/14nm, but the problem resurfaced just two nodes later. At 3nm, a totally different transistor structure is being introduced with gate-all-around FETs (a.k.a. nanosheets), which make design, metrology, inspection, and test significantly more challenging and expensive. At 2nm/18A, power delivery will begin flipping from the frontside of a chip to the backside to alleviate routing issues for even getting sufficient power to transistors, and beyond that the industry is likely to change its transistor structure once again to compound FETs (CFETs). These are a lot of process and structural changes in a short time window, and each new node will include more issues that need to be tackled. For example, a growing concern in high-density chips and packages is transient thermal gradients. They can move in unpredictable ways, sometimes very quickly and other times not, and they can vary based upon the workload. At 40nm, using thicker dielectrics and substrates, and more relaxed pitches, these were considered annoyances. With today’s leading-edge process technology, all of this needs to be taken much more seriously. “The base leakage is lower than the previous technology, but the overall total power is higher,” said Melika Roshandell, product management director at Cadence. “So at the end of the day, your thermal is going to be worse because you’re packing a lot more transistors into one IC and you’re pushing the performance. You want to go to higher and higher frequencies, and to do that you’re increasing the voltage, you’re increasing the power. And now your total power is more than the previous generation, so your thermal is going to be worse. Not only that, when you go to a lower node, your area is also shrinking. That area shrinkage and increase in total power is going to be a recipe sometimes for disaster for your thermal, and you’re not going to meet your performance because your thermal is going to hit a lot faster than what you were expecting.” Fig. 1: Thermal-mechanical co-simulation of 3D-IC design under operation. Source: Cadence Heat is becoming every hardware engineer’s shared nightmare, and it sets up some vicious cycles that are difficult to break and to model up front: Heat accelerates the breakdown of dielectric films (time-dependent dielectric breakdown, or TDDB) used to safeguard signals, and it adds mechanical stress, which can cause warping. It accelerates electromigration and other aging effects, which can shrink data paths. That adds more heat due to higher resistance in circuits and an increase in energy required to drive those signals, until they are re-routed (if possible). It can impact the speed at which memory operates, slowing overall performance of a system. It creates noise, which impacts signal integrity. That noise can be transient, too, which makes partitioning much more difficult. All of these factors can shorten the lifespan of a chip, or even a portion of a chip. “Thermally degrading transistors can easily make or break a chip or IP,” said Pradeep Thiagarajan, principal product manager for analog and mixed-signal verification solutions at Siemens EDA. “Fortunately, self-heating analysis of most devices can be done to assess the impact of localized heating on a design by means of a transient measurement for every MOS device, followed by loading that temperature delta data and assessing the impact of the waveforms. Now, novelty is required across the board, given increasing data transfer rate requirements. So the better every thermal interface material is modeled, the higher the chances of addressing those effects and making any appropriate design changes to avoid a short-term or long-term hardware failure. The net is that you need novel thermal solutions, but you also have to model it properly.” Power issues abound Many chipmakers are just starting to wrestle with these issues, because most chips are not developed at the most advanced processes. But as chips increasingly become collections of chiplets, everything will have to be characterized and operate under conditions that are foreign to planar chips developed at 40nm or higher. What is not always obvious is that increasing transistor density, whether in a single chip or inside an advanced package, isn’t necessarily the biggest knob to turn for boosting performance. It does, however, increase the power density, which limits the clock frequency. As a result, many of the big improvements are peripheral to the transistors themselves. Those include hardware-software co-design, faster PHYs and interconnects, new materials for insulation and electron mobility, more accurate pre-fetch with shorter recovery times for misses, sparser algorithms, and new power delivery options. “The understanding of the full system stack is really important,” said Vincent Risson, senior principal CPU architect at Arm. “The computer, of course, has an important contribution to the power, but the rest of the system is also very important. That’s why we have different levels of cache, and the size of the cache is different. We have increased that over the last generation because it’s better to have something local so that the power downstream sees compute as local. And as we scale to 3D, we can imagine having 3D stacked caches, which is an opportunity to basically reduce data movement and improve efficiency.” The key is to add efficiencies into every aspect of the design cycle, and not just for the hardware. While the chip industry has been talking about hardware-software co-design for the past couple decades, systems companies have prioritized that approach with their custom-designed micro-architectures, and mobile devices are looking to extend battery life significantly further for competitive reasons. “There is a lot of tuning to extract more, and that’s a big focus for the CPU,” said Risson. “We are continuing to make improvements in all the pre-fetch engines, for example, to improve the accuracy of that and to reduce the downstream traffic. So we have better coverage, but we also initiate less traffic on the interconnect.” That’s one piece of the puzzle, but more are required. Consider the breakdown of dielectric films over time, for example. It can be accelerated by different workloads or operating conditions, particularly inside a package filled with chiplets. “TDDB is a problem because we have so many signals and so many polygon nets running on different voltages,” said Norman Chang, fellow and chief technologist for Ansys’ Electronics, Semiconductor, and Optics business unit. “If you have a net next to a signal net with a different voltage, then the dielectric will see different voltages. As time goes on, you will see a time-dependent dielectric breakdown. This is a new problem, and we need to come up with a solution for it.” Inconsistencies Thermal gradients are another challenge, particularly when they are transient, varying greatly from one workload to another. This problem is particularly acute in 2.5D, where it can cause warpage, and in 3D-ICs, which are expected to roll out sometime in the next couple years. In both cases, heat can become trapped, creating a snowball effect. Fig. 2: Thermal and mechanical analysis results showing temperature gradients on 2.5D IC, including warpage at 245°C. Source: Ansys “If you look at the power consumption in a 3D-IC, it’s very much related to temperature,” said Chang. “When the temperature increases, the leakage power will increase, and the thermal gradient distribution is the center of the multi-physics interaction in a 3D-IC. Temperature will affect power, but it also will affect the resistance. The resistance will increase when the temperature increases, and that also will affect the dielectric constant. That will affect the signal integrity and the power integrity, and it will affect the stress. And when you are mixing digital and analog in a 3D-IC, the analog is more sensitive to stress. You have to know where is the thermal gradient, where is the thermal hotspot, because you have to move the analog components away from the hotspot. If you see a thermal cycling for the analog component, you will speed up the aging of the device, you will start seeing a transistor mismatch, and the efficiency of the analog circuit will decline rapidly compared to the digital logic.” And this is just getting started. Kenneth Larsen, senior director of product management at Synopsys, noted that getting the placement wrong for various elements in stacked die can create unexpected issues such as thermal cross-talk, which also can degrade overall performance. “We’ve gone from monolithic to chiplet-based design, which is disaggregated, and now these devices are getting closer and can influence each other. When you put one device on top of another, how does the heat escape? This is a big challenge. With 3D-ICs, the first concern is can you build systems with structural integrity. But you also have other mechanical, thermal, and power concerns — the whole shebang.” In the past, the simplest approach to managing heat was to lower the voltage. That approach is starting to run out of steam, because at extremely low voltages the slightest irregularity can cause problems. “Noise is a topic for very low power technologies, like near-threshold or sub-threshold devices, as well as for high-power devices,” said Roland Jancke, design methodology head in Fraunhofer IIS’ Engineering of Adaptive Systems Division. “It’s also a topic that is hardly understood because it typically does not appear in simulation. It appears later on in the real world, and then you have to understand it and cope with it.” Cross coupling, for example, can create noise in the substrate, but that isn’t always obvious in the design phase. “We started some years ago with a substrate simulator to figure out what are the cross couplings across a substrate,” said Jancke. “You’re thinking about a single device and the neighboring devices. You don’t think about the cross coupling at the input stage, which is far away, but it’s coupled through the substrate.” These types of issues can cause problems in DRAM, as well, particularly as bit cell density increases, which also makes it more susceptible to noise. “There’s definitely thermal noise,” said Onur Mutlu, professor of computer science at ETH Zurich. “Also, when you access a cell, you’re creating a noise in the structure because of the electrical interference caused by the toggling of wires, for example, or the access transistor. That activation causes noise, and this leads to some reliability issues. We call it cell-to-cell interference. The row hammer problem is just one example of that. You’re activating one row and causing disturbance in adjacent rows. RowPress is another example, where you keep one row open for a longer period of time, and this disturbs what’s happening in other rows adjacent to it. This sort of cell interference is getting more prevalent as we reduce the size of each cell and put cells closer to each other and increase density. You can get silent data corruption, and that may be what’s happening in the field.” With power, there are always unexpected issues. “For whatever clock frequency you’re running at, you’d like to run it at the lowest voltage possible, because that’s where you’re going to use the least amount of energy,” said Barry Pangrle, power architect at Movellus. “There’s a certain amount you can model, but as with any models, sometimes you have surprises. I can take a chip, run it under different conditions, and I can play around with the voltage and frequency and get an idea of where it will work under different workloads. ‘Okay, I can use these points, and if I want to be a little bit more conservative, I can always back off a bit and put in a little bit of margin.’ But people aren’t going to do that for every chip. So do you create bins and say, ‘Okay the ones that fall in this category we’ll run at this clock and this voltage?’ Then, some of the granularity will be left up to whoever is selling that chip.” Other issues There also is a monetary aspect to power, and that spans everything from the resources required to create a complex design, to the amount of power consumed in a data center. The higher the transistor density, the more energy it takes to power up and cool down a rack of servers. And with various flavors of AI, the goal is to maximize transistor utilization, which in turn consumes more power, generating more heat and requiring more cooling. “These applications are drawing huge amounts of power, and they’re exponentially rising,” said Noam Brousard, vice president of engineering solutions at proteanTecs. “Efficient power consumption will eventually translate into significant savings in the data center. That’s number one. Aside from that, we also have the environmental impact. And, we want to extend the lifetime of the electronics.” Fig. 3: Impact of power on chips. Source: proteanTecs Nor are power-related effects confined just to a chip. “With 2.5D, thermal stress is going to cause warpage, and because of that you run the risk of breaking the balls that connect the substrate to the PCB,” said Cadence’s Roshandell. “If it cracks, you get a short, and then your product is not going to work. So how you address that, and how you model it, is important. It has to happen in the earliest stages of the design where can envision it and do something about it.” Things get even more complex in 3D-ICs. Once again, the emphasis is on sizing up the problems early in the design cycle, but in 3D-ICs there are additive effects. “Dynamic switching power is really tricky for 3D-ICs compared to an SoC,” said Ansys’ Chang. “We have to consider the physical architecture as early as possible, because if you have 15 chiplets in a 3D-IC, how do you partition the power among the 15 chiplets for dynamic workflow and time dimension? At a different time you may have a different workload on that chiplet, and that may create a thermal hotspot. But if the top die has a local hotspot and the bottom die also has a local hotspot, if the two local hotspots line up at a certain time, then that hotspot will become a global thermal hotspot. It may be 10 or 15 degrees hotter than the local hotspot if the other die is not switching. This caught 3D-IC circuit designers completely off guard, because when you run emulation for a chiplet in a 3D-IC, you probably cannot run an emulation for the whole 3D-IC with a realistic workflow.” The problem is that there are so may dependencies that everything needs to be understood in context of something else. “There is no way you can optimize these devices independent of each other,” said Niels Faché, vice president and general manager for Keysight’s design and simulation portfolio. “You might have an objective around thermal, such as maximum temperature, heat dissipation, but you need to understand that in the context of mechanical stress. You have to be able to model these individual physical effects. If they are very tightly coupled, you have to do it in the form of a co-simulation. We do that, for example, with an electro-thermal simulation. So when you look at the current that flows through a transistor, it’s going to have an effect on heat. Then, heat has an impact on electrical characteristics, which changes the electrical behavior, and you have to model those interactions.” Solutions There is no single, comprehensive solution for power-related issues, but there are plenty of partial ones. One approach, and probably the simplest, is to limit overdesign. “It all starts with focusing on the target use cases and defining the necessary features to address them,” said Steven Woo, Rambus fellow and distinguished inventor. “It’s tempting to add features here and there to address other potential markets and use cases, but that often leads to increased area, power, and complexities that can hurt performance for the main applications of the chip. All features must be looked at critically and judged in an almost ruthless manner to understand if they really need to be in the chip. Each new feature impacts PPA, so maintaining focus on the target markets and use cases is the first step.” This can have a significant impact on the overall power consumption, particularly with AI. “In AI there are many options to consider, especially for edge devices,” Woo said. “Some options include how the chip will be powered, thermal constraints, if it needs to support training and/or inference, accuracy requirements, the environment in which the chip will be deployed, and supported number formats just to name a few. Supporting large feature sets means increasing area and power, and the added complexity of gating off features when they aren’t in use. And with data movement impacting performance and consuming large amounts of the power budget, designers need a good understanding of how much data needs to be moved to develop architectures that minimize data movement at the edge.” Another approach is to run real workloads on a design. “What some customers are doing is saying, ‘Let’s run representative workloads because we don’t know what we don’t know,” said William Ruby, senior director of product management for low power solutions at Synopsys. “It’s like power coverage. ‘What do we believe is a sustained worst case? What do we believe is a good idle type of workload?’ But what they don’t know is how a new software update may change the entire activity profile. Hopefully it’s an incremental change and they’ve somehow budgeted for that, as opposed to being pessimistic and a little bit more conservative. But how do you predict what’s going to happen with a firmware update?” Backside power delivery is another option, particularly at the most advanced nodes. “At some point you hit diminishing returns because you’ve got the stuff from the top layers down to the bottom, and a lot of time the stuff in the top layers is your power and ground routing,” said Movellus’ Pangrle. “If you can deliver that from the backside, and you don’t have to go through 17 metal layers up top, that’s a lot of layers you don’t have to go through. Being able to bypass that whole metal stack and come in the back door so you can be closer to the transistors and not have to worry about going through all those vias is like manufacturing magic.” Using sensors inside of chips and packages to monitor changes in power-related behavior is yet another approach. “In the field there are many things that can degrade performance, so we have to bake in voltage guard-bands,” said proteanTecs’ Brousard. “We know there will be noise. We know there will be excessive workloads. We know that the chip will go through aging. All these factors force us to apply more voltage than is necessary in best-case VDDmin.” On top of that, copper wires can be used to conduct heat to where it can be dissipated. “You can do simple things like optimizing TSV placement with stacked die, and you may be able to use thermal vias, as well,” said Synopsys’ Larsen. “It’s very complex, but we have always dealt in exponentials in EDA. It’s things we will go and solve. But when you want to mitigate something, you add something that takes away some of the values you’re looking for, and that has to be addressed. For reliability, you may add in redundancies, which could be TSVs or hybrid bonds in the stack.” Conclusion Power has been a problem for leading-edge chipmakers for the past couple decades. A smart phone will send out a warning that it is running too hot and shut down until it cools off, and a rack of servers may shift a load to another rack for the same reason. But chips increasingly are decomposed into various components and packaged together, and as industries such as automotive begin developing chips at 5nm and below, power issues will fan out in all directions. Architecture, place-and-route, signal integrity, heat, reliability, manufacturability, and aging are all tightly coupled with power. And as the chip industry continues to combine different features in unique ways to address unique markets, the entire industry will need to learn how to work with or around power-related effects. Unlike in the past, when only the highest-volume chipmakers were concerned with power, it will be the rarer design that can ignore it. —Ann Mutschler and Karen Heyman contributed to this report. Related Reading Next-Gen Power Integrity Challenges Dealing with physical and electrical effects in advanced nodes and stacked die. Backside Power Delivery Adds New Thermal Concerns Lack of shielding, routing issues, and new mechanical stresses could have broad impact on standard cell design. 3D-ICs May Be The Least-Cost Option Advanced packaging has evolved from expensive custom solutions to those ready for more widespread adoption. Tags: advanced packaging ANSYS ARM backside power delivery Cadence CFETs DRAM dynamic power density ETH Zurich finFETs Fraunhofer IIS/EAS GAA FETs Keysight low-power design memory Mentor Movellus physical effects power noise proteanTecs Rambus Siemens EDA Synopsys Ed Sperling (all posts) Ed Sperling is the editor in chief of Semiconductor Engineering. Leave a Reply Comment * Name* (Note: This name will be displayed publicly) Email* (This will not be displayed publicly) Knowledge Centers Entities, people and technologies explored Learn More Related Articles The Rising Price Of Power In Chips More data requires faster processing, which leads to a whole bunch of problems — not all of which are obvious or even solvable. by Ed Sperling The Future Of Memory From attempts to resolve thermal and power issues to the roles of CXL and UCIe, the future holds a number of opportunities for memory. by Karen Heyman SRAM Scaling Issues, And What Comes Next While it will remain a workhorse memory, using SRAM at advanced nodes requires new approaches. by Karen Heyman Glitch Power Issues Grow At Advanced Nodes Problem is particularly acute in AI accelerators, and fixes require some complex tradeoffs. by Ann Mutschler Rethinking Memory Von Neumann architecture is here to stay, but AI novel architectures and 3D structures create a need for new testing tools. by Karen Heyman SRAM’s Role In Emerging Memories Tools and optimizations are needed for SRAM to play a role in AI hardware; other memories make inroads. by Karen Heyman Chip Industry Silos Are Crimping Advances Development teams constantly wrestle with new technologies and tools, but often it's the associated corporate structures that cause the greatest challenges. by Brian Bailey Startup Funding: December 2023 Funding boosts photonics for AI, flexible chips; $1.3 billion for 72 companies. by Jesse Allen Sponsors Newsletter Signup Popular Tags 2.5D 5G 7nm advanced packaging AI ANSYS Apple Applied Materials ARM automotive business Cadence EDA eSilicon EUV finFETs GlobalFoundries Google IBM imec Infineon Intel IoT IP Lam Research machine learning memory Mentor Mentor Graphics MIT Moore's Law Nvidia NXP Qualcomm Rambus Samsung security SEMI Siemens Siemens EDA software Synopsys TSMC UMC verification Recent Comments Maury Wood on Examining The Impact Of Chip Power Reduction On Data Center Economics Erik Jan Marinissen on Chiplet IP Standards Are Just The Beginning Peter Bennet on Design Tool Think Tank Required Dr. Dev Gupta on Chiplet IP Standards Are Just The Beginning Jesse on Hunting For Open Defects In Advanced Packages Matt on Chip Ecosystem Apprenticeships Help Close The Talent Gap Leonard Schaper IEEE-LF on 2.5D Integration: Big Chip Or Small PCB? Apex on Nanoimprint Finally Finds Its Footing AKC on Gearing Up For Hybrid Bonding Allen Rasafar on Backside Power Delivery Gears Up For 2nm Devices Nathaniel on Intel, And Others, Inside Chris G on Intel, And Others, Inside Richard Collins on Too Much Fab And Test Data, Low Utilization Jerry Magera on Why Chiplets Are So Critical In Automotive Jenn Mullen on Shattered Silos: 2024’s Top Technology Trends Valerio Del Vecchio on Security Becoming Core Part Of Chip Design — Finally Lucas on Hybrid Bonding Basics: What Is Hybrid Bonding? Robin Grindley on Expand Your Semiconductor’s Market With Programmable Data Planes V.P.Sampath on RISC-V Micro-Architectural Verification Thermal Guy on Is UCIe Really Universal? Colt Wright on Shattered Silos: 2024’s Top Technology Trends Nicolas Dujarrier on The Future Of Memory Tony on Challenges Of Logic BiST In Automotive ICs Raymond Meixner's child on Visa Shakeup On Tap To Help Solve Worker Shortage Michael Alan Bruzzone on How Is The Chip Industry Really Doing? Art Scott on How Is The Chip Industry Really Doing? Liz Allan on Rethinking Engineering Education In The U.S. Telkom University on Rethinking Engineering Education In The U.S. Ramesh Babu Varadharajan on SRAM’s Role In Emerging Memories jake_leone on Visa Shakeup On Tap To Help Solve Worker Shortage d0x on How Secure Are FPGAs? Mike Bradley on RISC-V Micro-Architectural Verification Charles E. Bauer ,Ph.D. on Visa Shakeup On Tap To Help Solve Worker Shortage AMAN SINGH on Power Aware Intent And Structural Verification Of Low-Power Designs jake_leone on Visa Shakeup On Tap To Help Solve Worker Shortage Ed Trevis on Visa Shakeup On Tap To Help Solve Worker Shortage AMAN SINGH on Get To Know The Gate-Level Power Aware Simulation Pitchumani Guruswamy on RISC-V Micro-Architectural Verification Manil Vasantha on AI Accelerator Architectures Poised For Big Changes Ramachandra on Packaging Demands For RF And Microwave Devices garry on New Insights Into IC Process Defectivity Brian Bailey on The Good Old Days Of EDA Ann Mutschler on AI Accelerator Architectures Poised For Big Changes Ann Mutschler on AI Accelerator Architectures Poised For Big Changes John Derrick on AI Accelerator Architectures Poised For Big Changes allan cox on AI Accelerator Architectures Poised For Big Changes Madhusudhanan RAVISHANKAR on Curbing Automotive Cybersecurity Attacks Eric Cigan on The Good Old Days Of EDA Peter Flake on The Good Old Days Of EDA Mike Cummings on MEMS: New Materials, Markets And Packaging Brian Bailey on The Good Old Days Of EDA Bill Martin on The Good Old Days Of EDA Gretchen Patti on 3D-ICs May Be The Least-Cost Option Carlos on An Entangled Heterarchy Ann Mutschler on Flipping Processor Design On Its Head Gil Russell on Flipping Processor Design On Its Head Ed Sperling on China Unveils Memory Plans David on The Limits Of AI-Generated Models Bill on The Limits Of AI-Generated Models Dr. Dev Gupta on Gearing Up For Hybrid Bonding Faizan on China Unveils Memory Plans Jan Hoppe on Streamlining Failure Analysis Of Chips Riko R on Why Curvy Design Now? Manufacturing Is Possible And Scaling Needs It Derrick Meyer on Higher Automotive MCU Performance With Interface IP Kevin Cameron on Why Silent Data Errors Are So Hard To Find Rale on How Secure Are RISC-V Chips? Ed Sperling on Patterns And Issues In AI Chip Design Chip Greely on Building Better Bridges In Advanced Packaging Art Scott on Setting Standards For The Chip Industry Muhammet on Higher Creepage And Clearance Make For More Reliable Systems Andy Deng on Quantum Plus AI Widens Cyberattack Threat Concerns Dr. Rahul Razdan on The Threat Of Supply Chain Insecurity Roger on Patterns And Issues In AI Chip Design David Leary on Improving Reliability In Chips Ann Mutschler on The Threat Of Supply Chain Insecurity Cliff Greenberg on Setting Standards For The Chip Industry Kevin Parmenter on The Threat Of Supply Chain Insecurity Esther soria on Automotive Complexity, Supply Chain Strength Demands Tech Collaboration Kumar Venkatramani on Predicting The Future For Semiconductors Spike on Is UCIe Really Universal? David Sempek on Power Semis Usher In The Silicon Carbide Era Dp on Specialization Vs. Generalization In Processors Eric on Addressing The ABF Substrate Shortage With In-Line Monitoring Karl Stevens Logic Designer on Software-Hardware Co-Design Becomes Real Jim Handy on MRAM Getting More Attention At Smallest Nodes Nicolas Dujarrier on MRAM Getting More Attention At Smallest Nodes Lou Covey on Are In-Person Conferences Sustainable? Cas Wonsowicz on AI Transformer Models Enable Machine Vision Object Detection Nancy Zavada on Are In-Person Conferences Sustainable? Fred Chen on High-NA Lithography Starting To Take Shape Dave Taht on Wi-Fi 7 Moves Forward, Adding Yet Another Protocol Robert Boissy on Rethinking Engineering Education In The U.S. Allen Rasafar on High-NA Lithography Starting To Take Shape Mathias Tomandl on Multi-Beam Writers Are Driving EUV Mask Development K on High-NA Lithography Starting To Take Shape Adibhatla krishna Rao on How Do Robots Navigate? Doug L. on Getting Rid Of Heat In Chips Ken Rygler on DAC/Semicon West Wednesday Mark Camenzind on Why IC Industry Is Great Place To Work Peter Bennet on The True Cost Of Software Changes ALLEN RASAFAR on Balancing AI And Engineering Expertise In The Fab Ron Lavallee on The True Cost Of Software Changes Alex Peterson on Welcome To EDA 4.0 And The AI-Driven Revolution Allen Rasafar on Managing Yield With EUV Lithography And Stochastics Art Scott on Rethinking Engineering Education In The U.S. Paul Clifton on Week In Review: Semiconductor Manufacturing, Test Mark L Schattenburg on A Highly Wasteful Industry Gordon Harling on Rethinking Engineering Education In The U.S. Santosh Kurinec on Rethinking Engineering Education In The U.S. Brian Bailey on Rethinking Engineering Education In The U.S. CdrFrancis Leo on Will There Be Enough Silicon Wafers? Riccardo Vincelli on How Safe Is Safe Enough? Jem on 3D Structures Challenge Wire Bond Inspection Nikolay on Nanoimprint Finally Finds Its Footing Ed Korczynski on Thermal Integrity Challenges Grow In 2.5D Allen Rasafar on What Data Center Chipmakers Can Learn From Automotive Christopher Wendt on The Race Toward Mixed-Foundry Chiplets Ragnar on A Minimal RISC-V David Kneedler on Thermal Integrity Challenges Grow In 2.5D Erik Jan Marinissen (imec) on Chiplets: More Standards Needed Predicting Warpage in Different ... Technical Paper Link Band-To-Band Tunneling And Negat... Technical Paper Link About About us Contact us Advertising on SemiEng Newsletter SignUp Navigation Homepage Special Reports Systems & Design Low Power-High Perf Manufacturing, Packaging & Materials Test, Measurement & Analytics Auto, Security & Pervasive Computing Videos Jobs Technical Papers Events Webinars Knowledge Centers Industry Research Business & Startups Newsletters Store Connect With Us Facebook Twitter @semiEngineering LinkedIn YouTube Copyright ©2013-2024 SMGTerms of ServicePrivacy Policy This site uses cookies. By continuing to use our website, you consent to our Cookies Policy ACCEPT Close Privacy Overview This website uses cookies to improve your experience while you navigate through the website. The cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We al... Necessary Necessary Always Enabled Necessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information. Non-necessary Non-necessary Any cookies that may not be particularly necessary for the website to function and is used specifically to collect user personal data via analytics, ads, other embedded contents are termed as non-necessary cookies. It is mandatory to procure user consent prior to running these cookies on your website. SAVE & ACCEPT",
    "commentLink": "https://news.ycombinator.com/item?id=39724966",
    "commentBody": "The Rising Price of Power in Chips (semiengineering.com)102 points by rbanffy 22 hours agohidepastfavorite29 comments datameta 19 hours agoIn Figure 2 depicting 2.5D warping, why is 246C a relevant temperature? In my experience with IBM Power and Z systems, north of 85C is considered the high end already. What am I missing? Interesting article overall. reply mikewarot 19 hours agoparentThe picture shows temperatures up to 316K, which is 42 C.... so likely it's a typo for 46 (or 45?) centigrade. It's the repeating of an earlier mistake.[1] Which apparently partially arises from [2] which is behind a paywall. [1] https://www.prnewswire.com/news-releases/ansys-receives-2021... [2] https://www.semanticscholar.org/paper/Heterogeneous-Integrat... reply datameta 17 hours agorootparentAh yes, that's it right there. Excellent sleuthing, thanks. reply bevekspldnw 14 hours agoprevI’ll replace my i9 workstations with an ARM equivalent as soon as I can. The power draw on i9 sucks, more so with the A6000 running. reply ezst 4 minutes agoparentIf I was to pick a new CPU right now (and I won't, because I don't feel limited by my 2017 CPU still..., anyhow), I would just pick _not Intel_. AMD is also doing a great job on the perf per Watt department without throwing away decades of compatibility. Intel slowly catching up is something to be looking forward to as well. reply error_logic 13 hours agoparentprevThe idea that ARM solves power issues seems a bit overblown and driven by Apple purchasing the most advanced nodes sooner than competitors, causing people to associate the efficiency gain with the architecture even though a lot of it is the silicon process. Edit: Also Apple can and does do away with legacy support which is less about the architecture and more about expectations of what is included vs. deprecated. The push to ARM seems like it will result in a loss of support and control in the users' hands (converting expectations of PCs into those of smartphones) but now I'm really into speculative territory... reply qball 7 hours agorootparent>causing people to associate the efficiency gain with the architecture even though a lot of it is the silicon process. They also cause people to associate higher performance with the architecture, when high-performance ARM is something more or less unique to Apple. Qualcomm (as in, best case for performance that you can actually order a tray of 1000 CPUs from) is several years behind what Apple/Intel/AMD currently offers and as such is simply not competitive with x86 (even in performance/watt); that is one of three reasons why there are very few ARM laptops (the second one is that Qualcomm refuses to do drivers properly, and the third is that their price/performance ratio is positively abysmal). Sure, they're getting better with the acquisition of ex-Apple engineers through Nuvia, but there's still quite a ways to go before they're actually competitive. ARM isn't a magic \"make my computer faster\" button; chip designers are doing the heavy lifting for any architecture. reply DinaCoder98 10 hours agorootparentprevIs there any evidence that x86 can compete with arm on per-watt computation? reply error_logic 2 hours agorootparentI don't have numbers, just a hint-motivated question of how much improvement Apple's silicon has seen post-M1 compared to the competition. I've been lead to believe x86 has improved more in the same time period, but I'm too far removed from the details to back it up. reply robocat 9 hours agorootparentprev> most advanced nodes That's overly simplistic. It is the whole ecology of optimising for low-power usage on mobile that makes ARM so efficient. An advanced node does make a difference of course, but it is all the other choices made for efficiency that stack up e.g. big.LITTLE and the OS support for it. You can still get power efficient ARM on older nodes. reply error_logic 2 hours agorootparentYeah this is sort of what I was trying to allude to with legacy support but I guess I should've generalized to their control over the ecosystem and efficient interaction between components. reply lend000 12 hours agorootparentprevThis is probably largely accurate -- not to mention the fact that Apple has been using efficiency cores longer than x86 competitors. reply LoganDark 7 hours agorootparentThe efficiency cores actually aren't the primary thing that makes M-series chips so power efficient, even though they help. Even when you're ripping big data apart the chips do it faster than nearly anything else on the consumer market, while managing to be far more efficient as well. It's not just the process node, it's stuff like decoding multiple instructions in parallel being simpler due to the architecture. reply godzillabrennus 19 hours agoprevGreat breakdown of current challenges. reply moffkalast 12 hours agoprev> “The base leakage is lower than the previous technology, but the overall total power is higher,” said Melika Roshandell, product management director at Cadence. “So at the end of the day, your thermal is going to be worse because you’re packing a lot more transistors into one IC and you’re pushing the performance. So why not match the previous gen's TDP and just use whatever gains you get from more efficiency? Back in the 90s 300W was considered extreme for an entire system, today just a single 4090 can pull a full kilowatt. This constant increase manufacturers have been pushing to compensate for diminishing returns is unsustainable and completely absurd. reply Vecr 8 hours agoparentAMD lets you do that, and it's probably recommended in some cases. They don't force you to (except in some laptops?) because would give the user less freedom and because it would leave performance on the table. It does mean that the default boost settings have the chip running at a bit less than 100 Celsius on any standard air cooler. reply RetroTechie 16 hours agoprevWhat hardware advances giveth, today's beyond-ridiculous-overweight software stacks taketh away. reply sliken 15 hours agoparentI think of that as a win. Heavy software stacks create a demand for faster hardware and the market provides. Those of us with use cases that represent a tiny marketshare, but actually need the performance can do so with light software stacks. So the question is, how can we make the overweight software stacks even slower? reply Out_of_Characte 15 hours agorootparentBy going back to using interpreted languages. No more precompiled binaries where changing/adding patches and flags require full builds, just stream compiled/compressed source code directly to the target. You could also extern the software to a webserver and only cache small parts of the software on the client. Instead of gigabytes of install sizes you'll be required to have a 1 or 10 gbit network link to run and stream features as you're acessing them. reply pilgrim0 8 hours agorootparentCoordinating that would be a nightmare. Interesting idea, though reply mmoskal 12 hours agorootparentprevOh come on! No one would ever do that!... Oh wait reply LoganDark 7 hours agorootparentwhistles in javascript reply taneq 6 hours agorootparentprevMake it “industry standard best practice” to provide devs with absolute top end cutting edge hardware “for productivity and efficiency gains”. Repeat this at every opportunity at conferences and industry events until it becomes ubiquitous. Profit as devs slather abstraction layers, trivial libraries, emulation layers etc. on because “developer time is worth more than CPU time” and “it’s not slow on MY computer”. :D reply dtgriscom 8 hours agoparentprevThere's a strong rationale for making software developers work on older, limited machines, rather than the latest and greatest flamethrowers. (Of course, that doesn't apply to me.) reply VelesDude 13 hours agoparentprevPffft!!! No it doesn't. By the way, here is my new 'Hello World' app, it is only 380MB + dependencies. reply milesvp 11 hours agoprev [–] I’m curious about what is happening in the field of reversable computing. I haven’t heard much about it at all in the last 20 years. Basic information theory tells us that it takes energy to destroy information, so building ALUs that limit destroying information seems like a bit of a no brainer for attempting to create lower power (and heat) computing. The basic premise is that for any operation that loses info you store enough bits to allow the operation to run backwards. If you were clever about it, you could design your chips to only destroy bits in places that can be effectively as well. I’m sure reality gets in the way of pure theory, but I was sure that people were spending enough effort on the concept to have heard more about it. reply zozbot234 11 hours agoparentReversible computing doesn't help wrt. static or leakage power, which is an increasing fraction of power draw in recent device nodes. It does help wrt. dynamic power, and can be implemented via charge-recovery logic - but this comes at a cost in area which increases static power. reply sgdpk 9 hours agoparentprevI have worked on this aspect on quantum computation [1]. The main problem is that reversibility is a feature of isolated quantum systems. In practice, they are not isolated. Why? It's not just because of small interactions with the environment that we cannot control. It's that even the apparatuses that we use to control/drive the logical instructions (lasers, electrical transmission lines) should be taken into account if the computer is to be considered isolated. But usually they aren't, and this leads to inevitable losses of reversiblity in the data register. In other words, unitary (reversible) operations do not come for free. I think that in quantum computers it is more likely that energy-efficiency will come from some sort of algorithmic advantage. [1] https://arxiv.org/abs/2210.10470 reply pillusmany 10 hours agoparentprev [–] Our power problems today are far away from the theoretical limits you described. But reversible computing is inevitable in quantum computers, so it's researched in that context. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article highlights challenges in power consumption and thermal management in chip design, focusing on advanced technologies such as 3D-ICs and chiplets.",
      "It emphasizes the impacts of power issues on performance, reliability, and cost in the semiconductor industry, underlining the significance of innovative solutions like backside power delivery and new transistor structures.",
      "Experts discuss EDA, MEMS, AI, security, and advanced packaging, stressing the importance of collaboration, standards, and technological advancements to tackle these challenges efficiently."
    ],
    "commentSummary": [
      "The debate centers on the increasing power usage in chips, with a spotlight on ARM chips versus x86 chips and their efficiency.",
      "Reversible computing is considered a possible solution to reduce power consumption, particularly concerning quantum computers.",
      "The conversation also addresses the difficulties of balancing performance with power efficiency when designing chips."
    ],
    "points": 102,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1710588939
  }
]
