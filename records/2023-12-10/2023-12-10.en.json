[
  {
    "id": 38586767,
    "title": "Gooey: Transform Your Python Command Line Program into a GUI App with Ease",
    "originLink": "https://github.com/chriskiehl/Gooey",
    "originBody": "Gooey Turn (almost) any Python 3 Console Program into a GUI application with one line Table of Contents Gooey Table of contents Latest Update Quick Start Installation Instructions Usage Examples What It Is Why Is It Who is this for How does it work Internationalization Global Configuration Layout Customization Run Modes Full/Advanced Basic No Config Menus Dynamic Validation Lifecycle Events and UI control Showing Progress Elapsed / Remaining Time Customizing Icons Packaging Screenshots Contributing Image Credits Quick Start Installation instructions The easiest way to install Gooey is via pip pip install Gooey Alternatively, you can install Gooey by cloning the project to your local directory git clone https://github.com/chriskiehl/Gooey.git run setup.py python setup.py install Usage Gooey is attached to your code via a simple decorator on whichever method has your argparse declarations (usually main). from gooey import Gooey @Gooey Hello world! Lorem ipsum dolor sit amet, consectetur''' } A full example: Two menu groups (\"File\" and \"Help\") with four menu items between them. @Gooey( program_name='Advanced Layout Groups', menu=[{ 'name': 'File', 'items': [{ 'type': 'AboutDialog', 'menuTitle': 'About', 'name': 'Gooey Layout Demo', 'description': 'An example of Gooey\\'s layout flexibility', 'version': '1.2.1', 'copyright': '2018', 'website': 'https://github.com/chriskiehl/Gooey', 'developer': 'http://chriskiehl.com/', 'license': 'MIT' }, { 'type': 'MessageDialog', 'menuTitle': 'Information', 'caption': 'My Message', 'message': 'I am demoing an informational dialog!' }, { 'type': 'Link', 'menuTitle': 'Visit Our Site', 'url': 'https://github.com/chriskiehl/Gooey' }] },{ 'name': 'Help', 'items': [{ 'type': 'Link', 'menuTitle': 'Documentation', 'url': 'https://www.readthedocs.com/foo' }] }] ) Dynamic Validation ⚠ Note! This functionality is experimental and likely to be unstable. Its API may be changed or removed altogether. Feedback/thoughts on this feature is welcome and encouraged! ⚠ See Release Notes for guidance on upgrading from 1.0.8 to 1.2.0 Before passing the user's inputs to your program, Gooey can optionally run a special pre-flight validation to check that all arguments pass your specified validations. How does it work? Gooey piggy backs on the type parameter available to most Argparse Argument types. parser.add_argument('--some-number', type=int) parser.add_argument('--some-number', type=float) In addition to simple builtins like int and float, you can supply your own function to the type parameter to vet the incoming values. def must_be_exactly_ten(value): number = int(value) if number == 10: return number else: raise TypeError(\"Hey! you need to provide exactly the number 10!\") def main(): parser = ArgumentParser() parser.add_argument('--ten', type=must_be_exactly_ten) How to enable the pre-flight validation By default, Gooey won't run the validation. Why? This feature is fairly experimental and does a lot of intense Monkey Patching behind the scenes. As such, it's currently opt-in. You enable to validation by telling Gooey you'd like to subscribe to the VALIDATE_FORM event. from gooey import Gooey, Events @Gooey(use_events=[Events.VALIDATE_FORM]) def main(): ... Now, when you run Gooey, before it invokes your main program, it'll send a separate pre-validation check and record any issues raised from your type functions. Full Code Example from gooey import Gooey, Events from argparse import ArgumentParser def must_be_exactly_ten(value): number = int(value) if number == 10: return number else: raise TypeError(\"Hey! you need to provide exactly the number 10!\") @Gooey(program_name='Validation Example', use_events=[Events.VALIDATE_FORM]) def main(): parser = ArgumentParser(description=\"Checkout this validation!\") parser.add_argument('--ten', metavar='This field should be 10', type=must_be_exactly_ten) args = parser.parse_args() print(args) Lifecycle Events and UI control ⚠ Note! This functionality is experimental. Its API may be changed or removed altogether. Feedback on this feature is welcome and encouraged! As of 1.2.0, Gooey now exposes coarse grain lifecycle hooks to your program. This means you can now take additional follow-up actions in response to successful runs or failures and even control the current state of the UI itself! Currently, two primary hooks are exposed: on_success on_error These fire exactly when you'd expect: after your process has completed. Anatomy of an lifecycle handler: Both on_success and on_error have the same type signature. from typing import Mapping, Any, Optional from gooey.types import PublicGooeyState def on_success(args: Mapping[str, Any], state: PublicGooeyState) -> Optional[PublicGooeyState]: \"\"\" You can do anything you want in the handler including returning an updated UI state for your next run! \"\"\" return state def on_error(args: Mapping[str, Any], state: PublicGooeyState) -> Optional[PublicGooeyState]: \"\"\" You can do anything you want in the handler including returning an updated UI state for your next run! \"\"\" return state args This is the parsed Argparse object (e.g. the output of parse_args()). This will be a mapping of the user's arguments as existed when your program was invoked. state This is the current state of Gooey's UI. If your program uses subparsers, this currently just lists the state of the active parser/form. Whatever updated version of this state you return will be reflected in the UI! Attaching the handlers: Handlers are attached when instantiating the GooeyParser. parser = GooeyParser( on_success=my_success_handler, on_failure=my_failure_handler) Subscribing to the lifecycle events Just like Validation, these lifecycle events are opt-in. Pass the event you'd like to subscribe to into the use_events Gooey decorator argument. from gooey import Gooey, Events @Gooey(use_events=[Events.ON_SUCCESS, Events.ON_ERROR]) def main(): ... Showing Progress Giving visual progress feedback with Gooey is easy! If you're already displaying textual progress updates, you can tell Gooey to hook into that existing output in order to power its Progress Bar. For simple cases, output strings which resolve to a numeric representation of the completion percentage (e.g. Progress 83%) can be pattern matched and turned into a progress bar status with a simple regular expression (e.g. @Gooey(progress_regex=r\"^progress: (\\d+)%$\")). For more complicated outputs, you can pass in a custom evaluation expression (progress_expr) to transform regular expression matches as needed. Output strings which satisfy the regular expression can be hidden from the console via the hide_progress_msg parameter (e.g. @Gooey(progress_regex=r\"^progress: (\\d+)%$\", hide_progress_msg=True). Regex and Processing Expression @Gooey(progress_regex=r\"^progress: (?P\\d+)/(?P\\d+)$\", progress_expr=\"current / total * 100\") Program Output: progress: 1/100 progress: 2/100 progress: 3/100 ... There are lots of options for telling Gooey about progress as your program is running. Checkout the Gooey Examples repository for more detailed usage and examples! Elapsed / Remaining Time Gooey also supports tracking elapsed / remaining time when progress is used! This is done in a similar manner to that of the project tqdm. This can be enabled with timing_options, the timing_options argument takes in a dictionary with the keys show_time_remaining and hide_time_remaining_on_complete. The default behavior is True for show_time_remaining and False for hide_time_remaining_on_complete. This will only work when progress_regex and progress_expr are used. @Gooey(progress_regex=r\"^progress: (?P\\d+)/(?P\\d+)$\", progress_expr=\"current / total * 100\", timing_options = { 'show_time_remaining':True, 'hide_time_remaining_on_complete':True, }) Customizing Icons Gooey comes with a set of six default icons. These can be overridden with your own custom images/icons by telling Gooey to search additional directories when initializing. This is done via the image_dir argument to the Gooey decorator. @Gooey(program_name='Custom icon demo', image_dir='/path/to/my/image/directory') def main(): # rest of program Images are discovered by Gooey based on their filenames. So, for example, in order to supply a custom configuration icon, simply place an image with the filename config_icon.png in your images directory. These are the filenames which can be overridden: program_icon.png success_icon.png running_icon.png loading_icon.gif config_icon.png error_icon.png Packaging Thanks to some awesome contributors, packaging Gooey as an executable is super easy. The tl;dr pyinstaller version is to drop this build.spec into the root directory of your application. Edit its contents so that the APPPNAME and name are relevant to your project and the pathex value points to your applications root, then execute pyinstaller -F --windowed build.spec to bundle your app into a ready-to-go executable. Detailed step by step instructions can be found here. Screenshots Flat Layout Column Layout Success Screen Error Screen Warning DialogCustom Groups Tabbed Groups Tabbed Navigation Sidebar Navigation Input ValidationWanna help? Code, translation, documentation, or graphics? All pull requests are welcome. Just make sure to checkout the contributing guidelines first.",
    "commentLink": "https://news.ycombinator.com/item?id=38586767",
    "commentBody": "Gooey: Turn almost any Python command line program into a full GUI applicationHacker NewspastloginGooey: Turn almost any Python command line program into a full GUI application (github.com/chriskiehl) 483 points by lsferreira42 11 hours ago| hidepastfavorite70 comments goostavos 9 hours agoHey, what the -- this is my thing. ^_^ What&#x27;s it doing at the top of HN?A quick reply to some of the comments about argparse. Gooey is super old at this point. Argparse was a solid choice at the time when Gooey started. These days, Gooey itself speaks in JSON and is decoupled from argparse itself. However, argparse remains the main \"blessed\" interface (mostly because nobody else has built a different one).Some fun FYIs: You can also invoke any arbitrary executable[0], not just python, which is pretty handy.Re: last commit being 2 years ago. It gets harder to justify working for free on niche software as you get older and priorities change :( If it&#x27;s any consolation, I DO feel guilty all the time. I have no idea why, but where I live, there&#x27;s \"GOOEY\" graffiti tagged all over the place, so it&#x27;s a nice ever-present reminder of the issue tracker that&#x27;s currently going unloved. haha.[0] https:&#x2F;&#x2F;chriskiehl.com&#x2F;article&#x2F;gooey-as-a-universal-frontend reply linsomniac 8 hours agoparentArgparse is still a pretty solid choice, because it&#x27;s so ubiquitous and well documented and fairly easy. Typer and Click are both very nice, with some good ergonomics, but I find Typer&#x27;s \"tutorial\" style documentation to be rather hard to search to find answers to things like \"What arguments does Typer.App() take?\"I have a program I&#x27;m working on right now that does user-initiated argument parsing, and argparse is a great fit for it. I&#x27;d love to have a text-based UI as an option to drop users into, but Textualize requires Click (IIRC), and using Textual directly in my code to create the UI I&#x27;ve spent hours on and had absolutely no luck even getting started. reply seeknotfind 9 hours agoparentprevThis is a really cool idea. I love interface disconnected from APIs. We have so many annoyances these days because applications can&#x27;t be programmatically controlled. Honestly, I&#x27;d like to see legislation saying all application functionality needs to have APIs. reply rocqua 29 minutes agorootparentI think legislation demanding most tools have an API would be a good thing. Not &#x27;tho shalt expose a REST endpoint&#x27;. But instead something like &#x27;every operation a user can do with this tool, they also need to be able to trigger with an interface that is programable, and that interface needs to be documented&#x27;.Saying &#x27;our programable interface is the gui, use autohotkey&#x27; is fine, as long as you properly document all click regions.This would be a massive productivity boost to anyone using such tools. It would also be great for disabled people. reply sezna 6 hours agorootparentprevI would not like to have to concern myself with exposing government-compliant APIs when coding any arbitrary tool...the free market can reward good development. reply dimask 5 minutes agorootparent> the free market can reward good developmentha haNo way, especially because all the people taking most market-business-related decisions (eg which software to buy) are not tech-oriented. If we had more power on these decisions, that would mean that development, and even advertising of products, would be closer to what the parent comment suggest. But alas. reply elbear 1 hour agorootparentprevMaybe think of incentives rather than legislation reply cdogl 1 hour agorootparentprev> Honestly, I&#x27;d like to see legislation saying all application functionality needs to have APIs.The security implications of this give me heart palpitations. reply elteto 8 hours agoparentprevHey! Cool project! I have a question: why do you dump out sys.argv to a local file in the CWD? [0] tmp.txt is hardly a unique name… or am I missing something?[0] https:&#x2F;&#x2F;github.com&#x2F;chriskiehl&#x2F;Gooey&#x2F;blob&#x2F;be4b11b8f27f500e732... reply hiatus 7 hours agorootparentSeems like it&#x27;s potentially used for debugging, especially given that pycharm apparently appends additional params when invoking a new process (as noted in the comment at the top of the file). reply SOLAR_FIELDS 11 hours agoprevShouldn&#x27;t this be qualified with \"argparse-based\"?Argparse is good for simple stuff but there are many Click based CLI&#x27;s and a lot of popular CLI libraries build on top of Click. There are also other Python CLI tools that aren&#x27;t built on argparse or Click, though I will say that these two are probably the most popular ones.Is this confirmed to work with Click? I only see references to argparse. I would go so far to say, if the answer is no, that \"almost any\" is a flat out lie, and a much more accurate title would be \"Turn almost any argparse-based Python command line program into a full GUI application\".Also, the last substantial commit was over two years ago. This isn&#x27;t itself a bad thing, but given the open issue count does not really signal confidence in the project.Otherwise it is a cool project. I would like to see more of this - it&#x27;s one of those neat force multipliers, as referenced in the README, that some enterprising person could implement as a CLI and then share their automation for the rest of the nontechnical office in an easy way. Kind of like how Access did the same thing for DB&#x27;s. Like Access, you would butt up against limitations once you started to introduce some level of size or complexity, but it could be \"good enough\" for a lot of small office use cases. reply LtWorf 20 minutes agoparentWhat can&#x27;t you do with argparse exactly? reply jonnycomputer 6 hours agoparentprevI&#x27;m curious about the deficiencies you see in argparse... my bias is to minimize 3rd party dependencies ... reply pjacotg 10 hours agoparentprevI used it for exactly this in my previous role. I automated a lot of tasks and built tools for my previous team. Most of them weren&#x27;t Python programmers so I used gooey to create simple GUI&#x27;s on top of my scripts. It worked really well. reply gverrilla 7 hours agorootparentMind you give some examples? curious. reply tourist2d 8 hours agoparentprevIt does work with non-argparse. Why would you just assume that from quickly skimming through the code?I wish we could export HN users like you to another site. reply paulddraper 8 hours agorootparentIt does? Could you explain why you think that? reply selcuka 7 hours agorootparentSee the author&#x27;s comment: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38587791 reply SOLAR_FIELDS 7 hours agorootparentThe author’s comment actually confirms that it doesn’t currently support anything else other than argparse though. The author says they wrote it to be generic enough to extend to other libraries easily, which is great, but that is not the same at all as currently supporting said libraries. They provided a link that said it supports any cli, but when you follow the link, the instructions tell you to implement an argparse compatible wrapper for your cli in Python, which of course, is supporting argparse reply selcuka 6 hours agorootparentSure, I was talking about the workaround mentioned here:> You can also invoke any arbitrary executable [https:&#x2F;&#x2F;chriskiehl.com&#x2F;article&#x2F;gooey-as-a-universal-frontend], not just python, which is pretty handy.Rhetorics aside, you can use Gooey for any CLI tool using a small Python glue (pardon the pun) code, so it was not a flat out lie. reply SOLAR_FIELDS 5 hours agorootparentI know we are in semantics land now but most people would probably say that shelling out to another process doesn’t really constitute an integration. Put another way, you could just say that you could easily turn any CLI into a simple Python CLI with only a few lines of code with argparse itself, and that argparse supports any other CLI by just wrapping it, removing mentioning the Gooey part entirely. You’re essentially describing just the benefits and drawbacks of Python’s subprocess and argparse libraries at this point and not really saying anything about Gooey aside from the fact that it is argparse compatible.In other words: “Hey look at this cool thing argparse can do, and because Gooey is basically api compatible with argparse, it can do it too!” And don’t get me wrong, I think Python’s expressiveness with the argparse library and in general its ability to make CLI’s in very few lines of code is great. But really the magic is argparse and Python in that regard. reply selcuka 2 hours agorootparent> I know we are in semantics land now but most people would probably say that shelling out to another process doesn’t really constitute an integration.Most people would be an exaggeration. Purists may think that, but the reality is most GUI wrappers use subprocessing.While I agree that click integration would be nice, how would you turn any CLI tool to a GUI application without shelling out?> But really the magic is argparse and Python in that regard.True, but this is simply semantics. If I submit a PR to the Gooey project that lets you write a YAML configuration file to declaratively document the interface of a CLI tool, then automatically convert that config file to Python source, would that be any different? Is it because it&#x27;s YAML you manually write and not Python? Or even something that uses ChatGPT to convert a man page to an argparse wrapper? The argparse is the trivial part. The real magic is Gooey. reply paulddraper 5 hours agorootparentprev... That comment proves you wrong.There is no extant non-argparae integration replydang 10 hours agoprevRelated:Gooey: Turn almost any Python command line program into a GUI application - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27490291 - June 2021 (115 comments)Gooey: Turn command line programs into GUI applications - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8218785 - Aug 2014 (74 comments) reply dietr1ch 8 hours agoprevI wish that the OS and shell had better insight on how to run programs without need for specific library parsing libraries.I&#x27;d love to see programs communicate through a typed JSON&#x2F;proto format that shed enough details to make this more independent, and get useful shell command structuring&#x2F;completion or full blown GUIs from simply introspecting the expected input and output types.Today it seems that the best you can get is still made out of carefully placed straws as programs need to export completion files to many shells, there&#x27;s vastly different styles for flags across programs and parsing libraries, and obviously, there&#x27;s no GUIs around. reply Cloudef 1 hour agoparentNow you have a thing called powershell. Though as more serious answer plan9 was probably the only OS that really tried this. reply SOLAR_FIELDS 7 hours agoparentprevKind of like some generic gRPC interchange&#x2F;CLI API with native OS support? Something like that could be neat. I conjecture the main problem with gRPC is that a lot of developers (myself included) find dealing with it a bit unwieldy compared to more native (by native I mean in-language) solutions. reply Too 3 hours agorootparentIf you look into IPC primitives in each OS you can find goodies that do expose structured metadata about what interfaces are available and how they can be called. D-Bus, sd-bus, COM, Binder, to name a few.It’s just that the tooling around it isn’t as easily exposed and they aren’t tailored for on-demand launch via command line. If the shell treated such as a more first class citizen, good results may come out.Another big problem is portability, if you designed your app with sdbus, it’s not going to work on a non systemd distro, even less on Windows. What’s needed is a standardized abstraction layer on top. reply warangal 1 hour agoprevI sometimes find GUIs equivalent to comfort-food as you can just stroll through a gui interface without lot of cognitive overload that may come from a rarely used CLI.A bit tangential to current discussion, but i came across CUDATEXT editor a few months ago here which provides a single file python API to let me use arbitrary GUI elements like MENU, INPUTS etc which editor is itself using. I currently generate my blog from editor itself with configuration done through these simple GUI elements. reply Cloudef 1 hour agoprevDid something similar with my pokemon emerald randomizer. This parses output of wasm&#x2F;wasi program&#x27;s --help output and generates a web interface https:&#x2F;&#x2F;cloudef.github.io&#x2F;pokeemerald-randomizer&#x2F; the aruments are then passed to the wasi&#x2F;wasm binary to generate the final rom. reply amai 1 hour agoprevWould be nice to combine this with Google Fire: https:&#x2F;&#x2F;google.github.io&#x2F;python-fire&#x2F;guide&#x2F; reply blamazon 10 hours agoprevSee also:\"Textual: lean application framework for Python. Build sophisticated user interfaces with a simple Python API. Run your apps in the terminal and a web browser.\" [1][1]: https:&#x2F;&#x2F;github.com&#x2F;textualize&#x2F;textual&#x2F; reply asicsp 7 hours agoparentThey have something similar to Gooey as well: https:&#x2F;&#x2F;github.com&#x2F;Textualize&#x2F;trogon \"Easily turn your Click CLI into a powerful terminal application\" reply dgellow 10 hours agoparentprevWow, how is that even possible? The terminal examples are way more detailed than I would have imagined possible. reply tayo42 9 hours agorootparentYeah that&#x27;s interesting. I didn&#x27;t think handling mouse clicks was possible. Wonder how it&#x27;s done. reply joombaga 8 hours agorootparentA lot of popular terminal apps support mouse clicks. Off the top of my head vim, emacs, htop, and links2 all have mouse support. reply eichin 9 hours agorootparentprevfor most xterm-compatible terminals, you send an escape sequence that enables mouse tracking, and then mouse clicks turn into escape sequences. reply tayo42 9 hours agorootparentThat&#x27;s cool! Thanks reply acaloiar 9 hours agoparentprevAdding Textual support to camply [1] was apparently very easy. I didn&#x27;t to the implementation; I just contribute to the project sometimes: https:&#x2F;&#x2F;juftin.com&#x2F;camply&#x2F;command_line_usage&#x2F;#tui[1] https:&#x2F;&#x2F;juftin.com&#x2F;camply&#x2F; reply theoogway 4 hours agoprevWow, what a nice coincidence to see this on HN! Just two days ago, I was hacking up a similar project. https:&#x2F;&#x2F;github.com&#x2F;livetheoogway&#x2F;python-uime This one is a much smaller hack to spruce up your local scripts. Although it&#x27;s still a work in progress with features pending, I&#x27;d really appreciate any initial feedback or thoughts. Thanks for checking it out![0] https:&#x2F;&#x2F;github.com&#x2F;livetheoogway&#x2F;python-uime reply cztomsik 11 hours agoprevThis reminds me naked objects. The idea was that you only define Java classes with some annotations + theme and the whole GUI (or web frontend) application will be generated for you.Very cool idea but it never worked out (to my knowledge). reply DeathArrow 40 minutes agoprevSo is it a kind of Swagger for command line apps? reply nathanfig 11 hours agoprevI would love something that could do the reverse. reply andy99 10 hours agoparentI would like to be able to use a gui to set up parameter sweeps based on info pulled from argparse and then convert back to a shell script that runs and saves the output sensibly. reply nathanfig 4 hours agorootparentNot quite; turn any GUI application into a Python command line program. reply rocqua 23 minutes agorootparentThis feels maybe possible with QT. Since the inputs are all defined in code. reply SOLAR_FIELDS 10 hours agoparentprevA WYSIWYG editor that spits out a CLI you mean? That would pretty neat, though I think would necessarily be kind of constrained. I wonder who has tried that approach, I can&#x27;t think of any examples reply andy99 10 hours agorootparentActually, something like a \"zotero for argparse\" would be cool. Where you enter arguments, their type, help string, defaults etc in a gui and then you can check the ones you need for a given python script and copy the relevant python code into your paste buffer.I don&#x27;t think it would be a massive time saver however what I usually do now is find some previous script that had similar arguments and copy them, and then copy-paste-edit to add new arguments.The other advantage is you could enter the arguments agnostically and export as whatever language you&#x27;re working in. reply exe34 10 hours agorootparenthttp:&#x2F;&#x2F;docopt.org&#x2F;Not quite what you asked for, but close: type example invocations to generate the CLI, and just pull the arguments from a dictionary at runtime. reply jmfldn 9 hours agoparentprevChatgpt soon probably! reply inetknght 1 hour agoprevI&#x27;ve wondered about doing something like this in C++ with imgui and boost program_options.I&#x27;m very happy to see an example of it already done in Python! reply hoten 7 hours agoprevHow would one integrate this with a CLI tool that expects some user input during execution?Would love to package this around a bisect script I use to debug issues for my game engine. Giving it a GUI would make it possible to share it with users such that they too can help bisect problems. reply metadat 10 hours agoprevI wonder if Gooey could be made to target generating a React or even JS-free vanilla web app, instead of a native GUI?In spirit, Gooey reminds me of one of my favorite low-code tools for technically savvy individuals to put a web frontend in front of arbitrary CLI programs:Python Script Serverhttps:&#x2F;&#x2F;github.com&#x2F;bugy&#x2F;script-server reply agumonkey 9 hours agoprevthere&#x27;s a near complete isomorphism between cli&#x2F;tui arg parse and web url routingsomeone is surely doing a smalltalkish metaclass trick to turn any object into a local tty or http or rest or else interfaced thing reply timeagain 9 hours agoparentAnything that can be handled by a compiler can be hacked to interface with anything that can be handled by an interpreter. That’s the kind of fundamental daoist “code is data is code” that underlies the power of computing. reply bqmjjx0kac 9 hours agorootparentIt also turns out that code is mathematical proofs and proofs are code, thanks to the Curry-Howard isomorphism. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Curry%E2%80%93Howard_correspon... reply agumonkey 8 hours agorootparentprevyeah but so far these are all separate microcosms with no clear common model reply rodneyzeng 6 hours agoprevIs there an counterpart tool for ffmpeg with those parameters in GUI? That would be an omnipower app... reply defrost 2 hours agoparentThe Handbrake suggestion is a good one if your only interest is transcoding ... which barely scratches the breadth of what ffmpeg as a tool can do.Try: https:&#x2F;&#x2F;amiaopensource.github.io&#x2F;ffmprovisr&#x2F;for a &#x27;better&#x27; ffmpeg CLI documentation, your mileage may vary, it&#x27;s task and example focused.Try: https:&#x2F;&#x2F;github.com&#x2F;topics&#x2F;ffmpeg-guifor 66 variations on a GUI for ffmpeg of which I have no comment, I&#x27;m an old school CLI user through and through. reply poisonborz 1 hour agoparentprevThere are gajillions of ffmpeg UIs like Handbrake. But for me, more oftan than not GPT is the fastest way. reply hiAndrewQuinn 2 hours agoparentprevTry Handbrake! reply hesnuts 10 hours agoprevDoes this only build Windows applications, or can it do the same for MacOS&#x2F;Linux?be great if you could build&#x2F;package python code easily to run on native OS&#x27;s without having the user install python, etc first. reply djha-skin 10 hours agoparentIt works a treat on those other operating systems and pairs well with pyinstaller to make a single executable. reply emmet 10 hours agoprevVery happy to see something like this! Wish it had been around years ago to save me the hours I spent wrangling gui2py reply Uptrenda 9 hours agoparentPython getting a lot of love on HN recently.>Feels good man reply zikohh 10 hours agoprevDoes this work with any OS? reply 29athrowaway 10 hours agoprevSee also: Zenity, KDialog and GNU Dialog. reply dragonwriter 10 hours agoprev [–] \"Almost any Python command line program\" seems to be an exaggeration. It relies on the command-line program using argparse, and explicitly doesn&#x27;t work for any that rely on optparse, which, sure, is older, but also means that things which rely on the popular Click command-line library won&#x27;t work either. reply Spivak 10 hours agoparent [–] > which, sure, is olderAnd deprecated for going on 11 major versions of Python. reply dragonwriter 10 hours agorootparent [–] Which is arguably a good reason Click should look for an alternative basis (though, OTOH, the reasons Click remains on optparse are, arguably, a reason that optparse, while it perhaps should not be further developed but for bug fixes, should not be considered deprecated), but in fact a lot of Python command-line programs depend on Click, so something that only works on argparse-based programs does not, in fact, support \"almost any Python command line program\".Interestingly, there is a gooey-inspired GUI generator for Click-based programs: https:&#x2F;&#x2F;github.com&#x2F;szsdk&#x2F;quick replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gooey is a Python library that allows developers to convert console programs into GUI applications with a single line of code.",
      "It offers various features such as internationalization, customizable layouts and menus, dynamic validation of user inputs, lifecycle events, and progress tracking.",
      "Gooey can be installed through pip or by cloning the project from GitHub, and it provides options for custom icons and packaging.",
      "The library is designed for Python developers who want to create user-friendly GUI interfaces for their console programs.",
      "Contributions in the form of code, translations, documentation, or graphics are encouraged."
    ],
    "commentSummary": [
      "The discussion explores the use of Python libraries and tools for creating GUI applications, integrating command line interfaces, and improving accessibility and productivity.",
      "The limitations and benefits of argparse and other CLI libraries are discussed, including the compatibility with Gooey.",
      "The challenges of implementing legislation mandating API functionality for all applications, as well as the need for better integration and communication between programs, are also explored."
    ],
    "points": 483,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1702161002
  },
  {
    "id": 38580742,
    "title": "W4 Games Secures $15M to Fuel Godot Engine Video Game Development",
    "originLink": "https://w4games.com/2023/12/07/w4-games-raises-15m-to-drive-video-game-development-inflection-with-godot-engine/",
    "originBody": "W4 Games raises $15M to drive video game development inflection with Godot Engine December 7, 2023 December 7, 2023 OSS Capital leads the Series A funding alongside Naval Ravikant (Founder of AngelList) and a group of angels including Justin Hoffman, Larry Augustin, Alex Atallah, Thomas Dohmke, Diogo Mónica, Scott Williamson. 3 billion people play video games – that’s nearly half the planet! Despite this already massive market size, the video game industry is at an inflection point where its already strong growth rate will increase even further, and exponentially so. Shifting demographics, widening Internet access, emerging technologies, and ever-growing adoption by non-gaming industries will completely transform demand for video game developers, platforms, and games themselves. 25,000+ studios. 22 million+ gaming jobs. These illustrate just the tip of the iceberg. We at W4 Games are going all-in on the creation of an ecosystem with the Godot Engine at its center. The free, open-source technology of the Godot Engine empowers developers to create stunning 2D and 3D games, and we believe it will become the most used game engine in the world within the decade, driving video game development to new heights. It is already the preferred game engine for new generations of game developers and will scale exponentially further thanks to its fast learning curve, intuitive design, and a fast-growing and welcoming community. To help drive our continuing growth, we are thrilled to announce a new $15M Series A funding round led by OSS Capital and Naval Ravikant (AngelList and AirChat co-founder). Other investors include Justin Hoffman (Ex Elastic), Larry Augustin (Ex SugarCRM), Alex Atallah (Co-founder of OpenSea), Thomas Dohmke (CEO of GitHub), Diogo Mónica (Founder of Anchorage Digital), Scott Williamson (Ex GitLab) and more notable founders and executives in the commercial open-source ecosystem. W4 Games will strengthen our role within the Godot ecosystem by supporting its open-source development and continuing to build products and services to facilitate Godot’s expansion, such as W4 Consoles (an approved middleware console porting solution for Godot games) and W4 Cloud (multi-tenant service to support millions of users). Moreover, we will target international expansion across North America, Europe, and Asia, and the development of a new Godot education program. With this new funding, W4 Games aims to more than double its headcount in the coming 18 months to capture the fast-growing demand for its products and services. “W4 and the Godot community mark the first time in history that the now $300B+ gaming industry is seeing fundamental disruption and acceleration of innovation thanks to open source. OSS Capital is proud to deepen our partnership with W4 towards an open future in gaming.” Joseph Jacks (Founder and General Partner at OSS Capital) About W4 Games (w4games.com) Founded in 2021, W4 Games is an Irish startup formed by Godot veterans Juan Linietsky, Rémi Verschelde and Fabio Alessandrelli, and veteran entrepreneur Nicola Farronato. The company plans to revolutionize the game industry by bringing the Commercial Open Source Software (COSS) business model to an ecosystem that has traditionally relied on proprietary solutions from an ever-shrinking number of independent vendors. By providing a commercial services offering anchored in the entirely open and community-developed Godot platform, W4 Games believes that companies will be able to reclaim control of the technology powering their games, with a level of freedom and flexibility they never had before. In 2021 W4 Games raised its seed investment round led by OSS and Lux Capital, with the participation of SISU Ventures and Bob Young, the co-founder of Red Hat.",
    "commentLink": "https://news.ycombinator.com/item?id=38580742",
    "commentBody": "W4 Games raises $15M to drive video game development with Godot EngineHacker NewspastloginW4 Games raises $15M to drive video game development with Godot Engine (w4games.com) 417 points by j_maffe 23 hours ago| hidepastfavorite83 comments Vespasian 22 hours ago1. Congratulations to them. Godot is some great piece of open source software and everything that strengthens it is beneficial to the market segment as a whole.2. Given the list and impact of 3rd party contributors and the absence of a CLA I think there is little ability for them to change the licensee in the future to something proprietary (nor is there any indication that the current key people at W4&#x2F;Godot would want to do something like this)3. That said, how do the venture capital companies hope that W4 makes them back their investment and a healthy profit on top. To be crystal clear, there is nothing wrong with that but I would like have it out in the open before. \"Console support\" seems a little bit thin although I&#x27;m ready to admit that I may not know enough about the industry.If anyone could provide some additional information I&#x27;d be very thankful.Edit: personally I prefer the open stewardship model like Blender or the Linux foundation where it is clear that Major financial contributors expect to get software for their own businesses out of it and support an open project in order to share costs and have a say in the direction it takes. reply Hamcha 21 hours agoparentConsole support and porting effort in general is the main biz of some companies, the most popular being M2 (mostly emulators) and MP2 Games (handles Clickteam Fusion ports to console like Freedom Planet, Baba is You), but there are many other smaller studios. They mostly seem to have their own proprietary tech. That kinda work also can&#x27;t be open source as official console SDKs are expensive and covered by NDAs.If the next Undertale&#x2F;Minecraft gets built in Godot, W4 Games would be the easiest way to get that game to consoles and rack in tons of royalties, so I think the investment is justified (though hoping it doesn&#x27;t poison Godot in some way) reply starkparker 13 hours agorootparentConsole porting is essentially why the Godot co-founders formed W4: https:&#x2F;&#x2F;w4games.com&#x2F;2023&#x2F;02&#x2F;28&#x2F;godot-support-for-consoles-is...> W4 Games is working on a complementary offering that is simpler in nature. We are developing and plan to offer fully middleware approved console ports for all platforms (Nintendo, Microsoft and Sony). This will place Godot in the same category (and offer the same assurances) as the large commercial game engines.> Instead of offering porting services (which are still required by many developers and publishers), W4 Games will offer fully working console ports. These ports are intended to be middleware approved, meaning that the console manufacturer approves the port and certifies that it meets the required standards of quality, as well as supporting the full (or as close as possible) feature set of the console, including full integration to the console SDKs (for ease of development and deployment). reply tormeh 21 hours agorootparentprevIt&#x27;s a decent consulting business, but where&#x27;s the moat? I don&#x27;t see the case for VC money. This seems more appropriate for a bank loan or something. reply 255kb 21 hours agoparentprevReading the FAQ it seems they are not affiliated with Godot, nor control any of it aspects. https:&#x2F;&#x2F;w4games.com&#x2F;faq&#x2F; It seems they plan (https:&#x2F;&#x2F;w4games.com&#x2F;products&#x2F;) to make money by creating a BaaS&#x2F;SaaS platform and selling tools to make the Godot games easier to port to consoles. reply janosdebugs 20 hours agorootparentThey are affiliated in as far as one of the original Godot authors is the one of the founders of W4 (Juan Linietsky). However, I think it would help avoid misunderstandings if W4 communicated clearly how much they are dedicating to open source development and how much is closed source stuff only related to Godot. reply Vespasian 21 hours agorootparentprevThank you for pointing that out. That seems like it could be a profitable idea.It seems like 2 of the 4 founders are also members ins the Godot board of directors and if I recall W4 has a strong voice in the Godot development team.Maybe I&#x27;m just to pessimistic these days. (That speaks for Godot being a good project people care about). reply 255kb 21 hours agorootparent> It seems like 2 of the 4 founders are also members ins the Godot board of directors and if I recall W4 has a strong voice in the Godot development team.I missed that. I&#x27;m glad if Godot remains independent. VC funded OSS projects do not have a track record of remaining open-source. reply blensor 18 hours agorootparentprevI don&#x27;t have any up to date information on the path W4 will go, but Juan and Remi have always been very clear that they have no plans to change anything in how Godot is licensed nor would they be able to.I did not expect W4 to get that much funding, but at it&#x27;s current trajectory I could imagine it becoming a kind of publisher of Godot games. This is completely without any evidence, just my gut feeling.I could also see them provide the kind of SaaS backend tools one needs to publish a game ( Network backend, payments, content delivery ) reply doctorpangloss 17 hours agorootparentprevThat would be putting the cart before the horse, no games yet worth porting, so obviously so, it couldn’t be the reason for the investment.They just like the guy.He’s now raised $23m publicly for the entity. Improbable said they raised $500m, I don’t know what reality was, but I’m sure it was similar.It’s a lot of money for sure, I wonder what risky stuff they will spend it on. We have a lot of options for game development and we also had a lot of options for multiplayer engineering.If you were a brilliant engineer, would you sign up for “port games to consoles?” I don’t know. So I’m sure there’s something really visionary behind the fundraising that hasn’t been said publicly. reply dazaidesu 16 hours agorootparentChicken and egg problem, no games worth porting because games look at the engine and are like \"oh you can&#x27;t do console? i&#x27;m out\". Part of making godot an industry standard is first making sure it has industry standard capabilities. reply nicoburns 21 hours agoparentprevGodot seems to be MIT licensed. So anyone is free to create a proprietary fork if they want to. I can’t imagine this will be a problem as I suspect that the community is large enough that development of the OSS version would continue anyway, but the lack of CLA doesn’t seem relevant here. reply Vespasian 21 hours agorootparentYeah that&#x27;s true. reply blagie 17 hours agoparentprevI have no insider information, and I know little about this transaction.However, I have done COSS business models before. This sort of thing is ridiculously easy to monetize. You can look at Red Hat, MongoDB, and many other platforms to see how this works. The key is usually services.Broadly, there are two types of service contracts:- Low-cost. Find developers &#x2F; support people &#x2F; admins &#x2F; ... in India for $10-$100&#x2F;day.- High-quality &#x2F; money is not a issue. Find the best people (think BCG, McKinsey, law firms, boutique UX consultancies) and pay them $500&#x2F;hour.Something like Godot is used a lot in places you wouldn&#x27;t expect. Major video games and kids learning are the high-visibility uses, but there&#x27;s a lot of game-like systems used in corporate, military, and government settings built on systems like Godot, Unity, and Unreal Engine.If you&#x27;re developing an experimental airplane which _must_ work, costs hundreds of millions of dollars, and hinges on a pilot training system being developed, or you&#x27;re making a marketing tool in a winner-takes-all-market worth a billion, you&#x27;re very much in the later category of shops you&#x27;ll outsource to.If you&#x27;re the major developer or contributor to an open ecosystem, you become the go-to shop for the latter. If something needs fixing in the core tool to make the app you&#x27;re developing work, you have people in-house who can fix it.A lot of these are also places with less than impressive competence to vet vendors (most specialize in another industry), and \"major developer of Godot\" is an easy way to not screw it up. It&#x27;s the same reason people hire name-brand law firms or management consulting firms: it&#x27;s not the best choice, but if you don&#x27;t know better and need a problem solved, it&#x27;s a safe choice. reply Buttons840 21 hours agoparentprev> \"Console support\" seems a little bit thinLook at it this way: There&#x27;s a good chance that more console games will be published using Godot than any other engine. reply kdamica 14 hours agoparentprevAn asset store might be the fastest way to build a platform that makes money for them. reply jayceedenton 22 hours agoprevI don&#x27;t know anything about game engines, but always assumed that Godot was limited to simpler games. A lot of people seem to be pushing for Godot to replace Unity after the recent licensing shambles.Is it really possible to build games line Cities Skylines, Subnautica, Rust, Outer Wilds, KSP, Ori... in Godot? Is this more of a long term ambition at this point, or is it possible for this kind of game to be built in Godot today? reply Macha 21 hours agoparentUnity itself was once seen as the \"mobile and hobbyist platform\" compared to \"big kid engines\" like frostbite, cryengine and unreal.I think Godot is there, and they are seeing the start of adoption by AAA devs even before the Unity licensing shenanigans. But as Unity&#x27;s own rise shows, it&#x27;s not going to be a matter of flipping a switch and having comparable share amongst big games tomorrow.It&#x27;s probably also worth mentioning that it&#x27;s possible to build pretty much any game in any framework, or without, it&#x27;s just a matter of time and effort. Like LWJGL still is seen as a \"toy\" framework despite being in one of the most successful video games of all time (Minecraft). Factorio used just Allegro as a layer on top of SDL before migrating to bare SDL2. Conversely, many of the technical problems for KSP1 or Cities Skylines 2 have been attributed to Unity being a poor fit, despite being widely recognised as having \"made it\" into the \"real engines\" tier. There were also some EA developers with not very nice things to say about frostbite for games that don&#x27;t look like Battlefield in the era where EA was pushing for all their devs to adopt it. reply zenbowman 16 hours agorootparentExactly. I used Unity starting from almost the first release, and attended Unite in 2007.Unity was seen as a hobby engine then, we used it for the web, but for desktop used Unreal. Godot today is way ahead of where Unity was in 2007ish. reply Vespasian 21 hours agorootparentprevI wonder whether that is because most games are projects with a clear endpoint after which development mostly stops.That allows developers to experiment a little bit (internally or with smaller projects) and hedge their bets.If there is language compatibility (e.g. C# ) and your reusable components are somewhat sensibly designed (if only to mitigate update risks in your initial engine) it&#x27;s feasible to think about switching for your next game (unless say in with service product that is expected to run indefinitely) reply Macha 21 hours agorootparentThe counterpoint to this is many studios are sequel factories, or producing games that are at least broadly in the same genre continuously, and each game starts as a fork of the last, which is how you end up with things like the COD engine or Source 2 having a direct lineage to engines from 90s quake games. So \"Assassins Creed: Odyssey\" may not be an ongoing service, but \"Assassins Creed\" is, and tech carries forward from one to the next. reply KronisLV 20 hours agoparentprev> Is it really possible to build games line Cities Skylines, Subnautica, Rust, Outer Wilds, KSP, Ori... in Godot? Is this more of a long term ambition at this point, or is it possible for this kind of game to be built in Godot today?This might be a bit silly, but when it comes to engines and tools in regards to graphical fidelity and larger projects, I like to think of it in 3 broad categories: * Impossible - you&#x27;re not making the next Crysis in GameMaker, Construct, or RPG Maker. Period. * Unviable - you could technically rip out and replace 50% of jMonkeyEngine or NeoAxis with something more performant and better, if you had near-unlimited resources; except we both know it&#x27;s not happening. * Viable - you could take an off-the-shelf engine like Unity or Unreal and with a large amount of work achieve your goals, with varying degrees of success.Godot was strictly in the \"unviable\" group during its 2.X and 3.X releases, but is getting better now (new renderer, nice LOD functionality, good C# support in addition to GDScript when you don&#x27;t want to program gameplay in C++) and thanks to community efforts missing functionality is also getting added (like the terrain plugins, the older of which were sometimes quite broken): https:&#x2F;&#x2F;godotengine.org&#x2F;asset-library&#x2F;asset It still doesn&#x27;t have that big of a commercial ecosystem around it (like Unity does) and still feels a bit half baked at times and getting the same things you could get out of Unity or Unreal working would take more work for larger projects... but it feels more and more doable.Then again, currently Godot is hands down better for smaller projects, a lot of indie games, game jam games and quick prototyping, both Unity and Unreal feel too sluggish and heavyweight for that (and Unity in particular is a mess because of the whole legacy pipeline&#x2F;URP&#x2F;HDRP situation, DOTS, multiple input systems, multiple UI solutions and just so much fragmentation). Not every game needs to have the scale of the ones previously listed, actually most don&#x27;t and should better manage their scope and could still be wildly successful.Overall, it feels trending upwards and I&#x27;m curious to see where Godot will be in 5-10 years. If you tried right now, you&#x27;d just have all the normal early adopter struggles. reply Kelteseth 21 hours agoparentprevTo replace Unity? Yes, and if there is something missing, you just clone Godot and fix it yourself. I can compile the whole engine in 2 minutes. There are currently some limitations for AAA games in the rendering pipeline, see Clay John&#x27;s nice talk about this, from the last Godot con[1]. For example, at the company I work for we use Godot 4 to recreate Google Earth with OSM data :)[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=MW3IFMvDTCY reply dash2 21 hours agorootparent> if there is something missing, you just clone Godot and fix it yourself\"just\"? reply Kelteseth 21 hours agorootparentWell, I mean source code is easier to read that Unreal. And Unity does not even provide source code, so you have to wait until they fix the issue for you. In addition, the Godot community is really helpful, if you provide an example project with your problem. reply Karliss 19 hours agorootparentUnity sells source code access, it&#x27;s in the \"contact us for quote\" category. But that&#x27;s how many B2B services work, including some of the most widely used commercial game middleware.Also large portion of first party Unity subsystems which you install through builtin package manger (I am not talking about third party asset store stuff) is available in source code form under relatively nonrestrictive Unity Companion License to anyone. Don&#x27;t need the Enterprise plan or additional payments for that. For those modules you can not only read and modify the source code, but you can even openly distribute your modified versions. The biggest restriction of this license is that you can only use that source code in combination with Unity, you can&#x27;t port it to different engines. And in many cases where I read it, to better understand how to correctly use the library or avoid a bug, it was quite readable.So overall access to source code isn&#x27;t the main obstacle for game developers to fix the problem in Unity, spending time fixing things and afterwards maintaining a modified version is. reply lukeschlather 17 hours agorootparentI have personally had issues where I wanted to read the Unity source code but couldn&#x27;t. And I suspect it wouldn&#x27;t have been worth the cost in my case. There&#x27;s really no substitute for shared source. Truly open source isn&#x27;t necessarily better; modifying it is not often realistic, but having to pay just to read it is a big stumbling block. reply gkbrk 20 hours agorootparentprevMuch easier than waiting for a suitable job opening at Unity, getting a job at Unity, and then just cloning Unity and fixing things yourself. reply IshKebab 18 hours agorootparentprevOh yeah, haven&#x27;t you heard? All open source software is intrinsically flawless because you can just fork it. reply fbdab103 16 hours agorootparentI think patching a game engine is fairly common in the industry. Games are not on a dependency update treadmill. They pick a version, and barring some external crisis, there is no reason to upgrade anything ever. If there is one bug affecting rendering or speed from the underlying engine, it can be worth finding it yourself. reply mattlondon 21 hours agoparentprevAs far as I am aware, there is nothing intrinsically preventing people using it.I have no experience in building big titles or even commercial games, but I see no obvious \"blockers\" to building a large and complex 3d game. It&#x27;s not like Godot itself limits you to only doing basic 2d platformers or whatever - it seems as flexible and power as unity.Sure you might not have all the same eye candy as the very latest unreal engine or whatever, so AAA quality titles might be out, and I am not sure what the multiplayer stack is like, but it seems like the fundamentals are there and so there is nothing to hold people back. reply Applejinx 19 hours agoparentprevI would guess medium term, short term if there&#x27;s a specific roadblock that happens to get a lot of attention. My understanding is that Unity&#x27;s got certain things in a more sophisticated but less elegant form, where Godot seems to want to do everything &#x27;correctly&#x27; even if it imposes performance penalties.Making Godot, less &#x27;klugey&#x27; but less performant.The trouble with maximizing Unity the way professional devs do, is that you have to know which kluges to use and which to avoid. It&#x27;s somewhat impractical and the end result still isn&#x27;t that awesome: some of those games you mention are hitting a performance wall even though they&#x27;re in Unity.I don&#x27;t think Godot is really on par with Unity in the 3d performant space in all respects, but I think that could change quickly, and what will happen is that it&#x27;ll catch up over the medium term without going totally klugey. I&#x27;d give it a couple years to get there. Right now I think you&#x27;d have to design around what&#x27;s not currently performant enough. reply rowanG077 22 hours agoparentprevFrom a cursory search it seems there are large games build in Godot. Sonic Colors: Ultimate seems to be an example. reply username256 18 hours agorootparentIt&#x27;s the only example so far (if we consider this poor remake a \"large\" game). And the team behind (Blind Squirrel) didn&#x27;t use Godot as-is, they had to rewrite most of the core graphics area.It will be a while until we see AA &#x2F; AAA games in Godot, it&#x27;s missing too much right now to be viable in the 3D space (again, for AA&#x2F;AAA. For indies, sure, why not). One day, certainly, I hope so, but not today nor tomorrow. reply rowanG077 12 hours agorootparentI think no large games use an engine as-is, they will always extend and change it in some ways to make it fit their game. Besides the question was not about AA&#x2F;AAA games. Unity also did not fill that segment. The question was whether Godot will be able to fill the space Unity has. And I don&#x27;t think it can currently. But with more development it definitely could. The last time I used unity I was very appalled by how bad it actually was, I admit this is something like 5 years ago but I doubt it has changed. reply dgellow 19 hours agoprevCongratulations, that’s a pretty impressive feat. It’s fantastic to see how fast things are developing. I may be wrong but the current momentum to develop viable alternatives to the big proprietary engines feels real and not just based on hype. We may reach a point in a few years where Blender + Godot are basically the go-to option for small to medium size studio, which is crazy to think about given the state of game dev just 10-15 years ago.At the same time I find it hard to not feel cynical when I see that much money invested by a VC firm into an open source project.I wish the best to the Godot team, so far they have a been pretty good at leading the project. reply wg0 20 hours agoprevI&#x27;m not affiliated with the channel and they probably don&#x27;t even know I&#x27;m posting here but this[0] is a great entry point into Godot Engine although I think the instruction style leads for it to be more general and applicable to other engines or what a game engine actually facilitates.Great stuff.[0]. https:&#x2F;&#x2F;youtu.be&#x2F;nAh_Kx5Zh5Q reply 255kb 21 hours agoprevI find the title rather confusing, as, after reading their FAQ (https:&#x2F;&#x2F;w4games.com&#x2F;faq&#x2F;) it is clear that they don&#x27;t own Godot. They are building a traditional BaaS for gaming, specifically targeted at Godot developers (and they may contribute to Godot development, which doesn&#x27;t make a real difference rearding ownership). reply Macha 21 hours agoparentThe W4 founders are the project founders and many of the top contributors to Godot Engine. Godot has always done what for me is the right thing for the continued open source nature of the project, including limiting any organisation&#x27;s members on the leadership committee, assigning trademark rights to a foundation and not naming their company Godot Engine, LLC (unlike, say, Gitea).So structurally it&#x27;s the safest open source project against a future source available pivot, but there are some concerns such as the separation of the Godot foundation from it&#x27;s parent organisation or a \"de facto control\" fork.I think on the other hand, they do have a more clear selling point vs do it yourself on the open source projects. For IP reasons, console manufacturers don&#x27;t permit the console integration part to be open source, so that&#x27;s the bit that W4 has that the open source project can never compete with (though other companies building on the open source project could of course build their own). reply 255kb 21 hours agorootparentThank you for the precision. I guess the important part is how Godot is currently organized and remains independent. reply dazaidesu 16 hours agoparentprevThey donate a lot of code back to the engine, w4 has already contributed an entire directx renderer to the engine that they needed to build out for their console porting efforts anyway. reply numlock86 19 hours agoprevGodot is great. I am afraid it&#x27;s still a very long way before they become for game development what Blender is for 3D modelling these days. If it will even happen at all. So any improvement and funding is more than welcome. reply capableweb 18 hours agoparent> I am afraid it&#x27;s still a very long way before they become for game development what Blender is for 3D modelling these daysMakes sense. Blender is coming up to being 30 years old soon, and it still isn&#x27;t heavily embedded into the mainstream pipelines, but it&#x27;s getting closer every day.By contrast, Godot is about 10 years old, but still has eaten some of Unity&#x27;s pie. Cannot wait to see how Godot is in about 20 years, surely they will have surpassed Unity at that point :) reply Thaxll 18 hours agorootparentGodot has not eaten anything significant from Unity, like nothing at all. reply capableweb 16 hours agorootparentYes, it has. But game engine adoption takes time, it&#x27;s not immediately clear that it is eating some of Unity&#x27;s lunch, as games have to be developed, launched and appreciated before it&#x27;s obvious for the average (developer) person.Look at some of the games that made Unity popular in the first place, and the people&#x2F;companies that made them. Lots of them are moving to Godot now, but again, it&#x27;ll take time before those people&#x2F;companies launch the games. reply Thaxll 8 hours agorootparenthttps:&#x2F;&#x2F;steamdb.info&#x2F;tech&#x2F; how many years do you think it&#x27;s going to take?Godot is behind engine I don&#x27;t even heard of. reply blagie 17 hours agoparentprevSerious &#x2F; non-leading &#x2F; non-rhetorical question: What are the gaps? reply PrivateButts 16 hours agorootparentFrom the perspective of a hobby unity dev who&#x27;s making a jam game in Godot to feel it out, Godot has a lot of rough edges, weird choices, and stuff that&#x27;s just missing.Stuff that I&#x27;ve encountered so far:- A very annoying issue where the editor will lock up after my Linux laptop wakes up from sleep. I&#x27;ve lost work because I&#x27;ve closed the laptop without remembering to close Godot first.- Performance issues with large assets or too many assets. A single pixel art asset pack ([LimeZu&#x27;s Modern Interiors](https:&#x2F;&#x2F;limezu.itch.io&#x2F;moderninteriors)) brought Godot to its knees until I pruned it. The large tilemaps in there will also slow the tilemap editor to a crawl.- I&#x27;ve been struggling with getting the dynamic tilemap rules to behave as expected. YMMV- I&#x27;m not a fan of Godot&#x27;s single-window UI approach, especially when it comes to scripting. You can futz with editor settings to make this slightly better, though.- You can&#x27;t mix 2d and 3d stuff like you can in Unity, and the 3d side of things is way rougher than 2d.- They&#x27;re still working out what direction to take with an Asset store.- The shift from Unity&#x27;s GameObject>Component model to Godot&#x27;s single script per node approach has been an awkward adjustment for me. I keep replicating the old model by making prefab nodes that are basically just components.- I miss Unity&#x27;s play mode scene inspector. Godot is halfway there. You can poke around in the scene tree, but you don&#x27;t see that update in the editor.- The collision system isn&#x27;t as straightforward as Unity- It&#x27;d be nice if we had a bit of a slot system like we have with Vue Components for when we nest things under packed scenes.The good stuff:- There&#x27;s only one type of signal&#x2F;callback instead of the three different systems Unity can use. The signaling system is well-implemented instead of feeling bolted on.- Godot doesn&#x27;t differentiate between a Scene and a Prefab like Unity does. It avoids the don&#x27;t destroy on load juggling you have to do and gives you a bit more control- Some neat shortcuts for boilerplate stuff are built into the editor. For example, if you&#x27;re adding SFX, you often want to provide several similar SFX clips to provide variety. When you set the SFX in the editor, you can assign a Randomizer to it, which takes a list of SFX and plays them randomly based on the weights and mode you set. You can even set pitch and volume adjustments to add even more variety.- The fire-and-forget tween system is very convenient.A lot of people compare Godot to Blender. It&#x27;s not at the level that Blender is at now, but it does give me Blender pre-2.5 vibes- A solid base for enthusiasts that can be honed into polished software for the masses. I hope that Godot glows up the same way. reply blagie 15 hours agorootparentThank you!As relevant to Godot, most of my work is with kids (as relevant here on both ends -- teaching kids to code, and making educational activities). I haven&#x27;t used either Godot or Unity much, and was trying to decide. For a variety of reasons, open-source is a huge win*, so I was leaning that way.I don&#x27;t expect much 3d or to be doing too many things which are overly fancy. Much more on the \"weekend hack\" or \"kids afterschool activity\" side of things, and much less on the serious game development side.From your list, it doesn&#x27;t sound like there are (m)any showstoppers to just picking Godot.* (1) Avoids licensing issues installing &#x2F; uninstalling on classrooms full of computers (2) Advanced kids can learn more, since they can look under the hood (3) Guaranteed long-term support (kids activities are sometimes not updated for a while) (4) Automatic FERPA &#x2F; COPPA compliance and proper handling of student data. ...and the list goes on for quite a while longer. reply tetha 14 hours agorootparentFrom my own adventures into Godot, for that use case, I&#x27;d recommend using Godot very much.If you know some basics, you can whip up a simple platformer, top down game, old-school top down shooter and such very, very quickly. A decent tutorial can have you at at something functional on the screen in half an hour or so. And then you can start playing around to make it cooler.All while teaching kids some basics of programming. reply blagie 13 hours agorootparentThank you!I haven&#x27;t used it much, but that was my first impression. It&#x27;s good to see it confirmed. reply PrivateButts 7 hours agorootparentprevOh yeah, Godot is perfect for that. GD Script is very approachable (it&#x27;s like if Python got Typescript-ified).I&#x27;m sure that as the GDExtension project develops, it&#x27;ll only be a matter of time until someone builds a visual programming language for it. replyomneity 22 hours agoprevI hope for Godot to remain true to itself over time. Unity was the indie upstart at one point, just like Godot is now.Penpot&#x2F;Figma story all over ... I hope not. reply CodeSgt 21 hours agoparentUnity was never FOSS. Nor was Figma, to my knowledge reply Andrex 17 hours agoprevGodotBlenderOpenToonzGIMPI hope all these major open source projects reach their potential. Blender is already basically there, and I&#x27;m expecting the rest to catch up eventually. Even GIMP -- it really just needs some TLC and actual funding and it could easily start on the notoriety&#x2F;attention path Godot&#x27;s been on for a few years now. reply fbdab103 16 hours agoparentGIMP seems actively hostile to giving people what they want: a Photoshop clone. Even projects which would revamp the interface to be more Photoshop like were given the cold shoulder.At this point I have fully switched to Krita. I am not a real artist and am only ever making little doodles for my apps, but the developers seem more in tune with what users need. reply teddyh 15 hours agorootparent> giving people what they want: a Photoshop cloneIf that was really what people wanted, wouldn’t there be a successful fork by now? reply Andrex 14 hours agorootparentThere have been a lot of forks. Cinepaint, Gimpshop and Glimpse (RIP) come to mind.Unfortunately the reality is if people can barely pay attention and contribute to Gimp, what chance do any forks have?Gimp moves slowly but they do listen to their users. Lack of funding is more responsible for any complaints people have with Gimp, not some assumed \"anti-Photoshop\" idealism. reply ksclarke 14 hours agorootparentprevBecause people (i.e., users) aren&#x27;t the same thing as developers. Most people just want to use a tool, rather than develop it. reply teddyh 14 hours agorootparentDevelopers are most often also users. This is especially true for free software. replyfamahar 21 hours agoprevHoping for Godot to be the Blender of game development engines one day. reply Sirikon 21 hours agoprevGreat, now Godot has a time bomb as well. reply wg0 20 hours agoparent\"Investors\" reply pg5 14 hours agoprevMy issue with Godot is that I am bad at art. With Unity, I could affordably get pretty much ready to go assets and build a game, but with Godot, I don&#x27;t know of any equivalent marketplaces. reply NekkoDroid 12 hours agoparentIIRC the standard Unity Assets store license does allow using assets in other engines. And maybe you also wanna check out KenneyNL if you are looking for open assets for various small stuff. reply definitelyhuman 20 hours agoprevGreat to see more support for Godot! The lead VC and the company pledges bode well for keeping the bulk of the new tech open I think.Biggest red flag is the lack of anyone with games pedigree. If the goal is to crack the duopoly with a great FOSS engine supported by paid BaaS + enterprise support plans, you’re going to need strong connections, partners, and knowledge of the real product requirements. First sales will be pretty challenging, but if they can get traction and ship great games there’s certainly an opportunity reply johnwoods 18 hours agoprevCongratulations to the Godot team! I have used Godot a lot in the past and can&#x27;t wait to replace my Unity junk. reply anonylizard 22 hours agoprevIs this some VC&#x27;s pouncing on Unity&#x27;s missteps? How serious was the damage to Unity&#x27;s credibility after the installation fee disaster? How big is the moat for unity? reply broken_clock 21 hours agoparentGodot currently doesn&#x27;t even have good support for things like in-app purchases for iOS&#x2F;Android. No one is willing to work on stuff like that for free&#x2F;open-source fun.I think the big moat is that for studios, games are so risky to make, that there&#x27;s no reason to take on tech risk by possibly running into issues like this. You know Unity will work for basically any non AAA game you want to make.Hopefully this $15m closes that gap. reply nightowl_games 19 hours agorootparentGoogle Play IAP: https:&#x2F;&#x2F;github.com&#x2F;godotengine&#x2F;godot-google-play-billingiOS IAP: https:&#x2F;&#x2F;github.com&#x2F;godotengine&#x2F;godot-ios-plugins reply username256 18 hours agorootparentThe iOS one is unmaintained and has been for a while (it still doesn&#x27;t officially support Godot 4.x). Supposedly it should be maintained again by EOY but we&#x27;ve yet to see any progress on it. reply nightowl_games 13 hours agorootparentMaintaining this yourself is trivial. We sell IAPS on Android, iOS, Steam & XSolla in the Godot game engine. Android and iOS are the easiest. This is really, really minor stuff we&#x27;re talking about here. reply broken_clock 12 hours agorootparentMaybe you can write a blog post or a reddit thread?There were a bunch of people asking about it on Discord for Godot 4, and some confused reddit threads offering to pay people for a tutorial:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;godot&#x2F;comments&#x2F;11vxeo7&#x2F;can_i_please...https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;godot&#x2F;comments&#x2F;13ka6qc&#x2F;will_pay_to_... replytruegoric 22 hours agoparentprevIt kinda does sound like EEE.„W4 Games will strengthen our role within the Godot ecosystem by supporting its open-source development and continuing to build products and services to facilitate Godot’s expansion, such as W4 Consoles (an approved middleware console porting solution for Godot games) and W4 Cloud (multi-tenant service to support millions of users).” reply Vespasian 21 hours agorootparentGetting game engines in console and providing support for developers is certainly a business. I&#x27;ve met some people who brought their custom (more simple ) engines&#x2F;games to consoles and there is money in providing a ready made solution which, by the nature of it, cannot be open source or permissive.The main question is it the \"10x in 3 years\" kind of business or the \"steady stream of a small medim profit\" variety. reply SXX 16 hours agorootparentprevIt&#x27;s not EEE because W4 Games actually founded by some of top Godot contributors who continue to work on FOSS version as well. There just some things you can&#x27;t have open source like console platform support code. reply arjonagelhout 22 hours agoparentprevUnity still has a more mature product compared to Godot, so for many projects it won’t be feasible to switch to Godot.Unity is easier to use, has more fully featured and higher quality rendering pipelines, more integrations with other software, a larger asset store and the ability to quickly add advertisements to a game using Unity Ads. (etcetera)That said, we stopped using Unity because of the term changes and are now focusing on building a custom game engine, but our use case is way different than game studios.In game studios it’s a numbers game. e.g. How much does it cost to retrain our staff to switch to a different engine versus the benefits. From what I can see, Unity has not yet made its product so unattractive that it won’t be used for future productions. reply npinsker 21 hours agoparentprevTheir moat is massive for mobile apps.For PC + console, I think their clock is ticking. Godot has many disadvantages (fewer features, large performance problems, asset store, poor UI) but they&#x27;ll eventually fix them and perhaps become the dominant engine. The only question is how much further ahead Unity will be. reply nightowl_games 19 hours agorootparentThe moat is massive for console games, mobile games on Godot work great. We have 2 high quality Godot based mobile games in production on iOS&#x2F;google play&#x2F;steam right now.Unity has very few advantages over Godot on mobile. reply pjmlp 21 hours agoparentprevIt is business as usual for big studios, maybe a couple of indies decided to port their games to GDScript or do not care about the platforms where C#&#x2F;Godot isn&#x27;t available. reply TheMagicHorsey 19 hours agoprev [–] Godot is awesome, but I wish that when people start ambitious new projects that are meant to last for decades they’d choose a language that has more modern conveniences than C++. The compile times suck. The language is such a complicated mess you have to basically ban whole parts of the language from being used in the project to make development palatable. I would even prefer C to C++. I know Rust is probably a hard sell though. reply dualogy 16 hours agoparentI&#x27;m guessing once Zig is at 1.x (breaking changes before then), \"real contenders\" for C++ engines might shape up to on-par within the first few years of that point. (I mean the subset of such projects without prior or subsequent abandonment.)> I would even prefer C to C++Assuming you want to game-dev not engine-dev, the above is quite the doable rule for your \"C++\" codebase under your own oversight and maintenance even though including some C++ engine and calling its APIs, right? (Apart from the fact that some-not-all of them expose some capi `.h`s from what I&#x27;ve seen.)Most of them might (assuming here I know) anyway tend toward the lean-and-mean none-too-OOP way of doing things, data-oriented designs etc.My (newbie) C++ is C (structs + funcs) but with struct methods and occasional light inheritance, aka Go-like (methods and embeds). The std::string too seems alright-enough right now (vs. a hand-rolled slice-of-T-being-uint8_t struct-making macro) as long as there&#x27;s no mass string handlings going on, in which case it&#x27;ll have to be evaluated more seriously. reply bbkane 15 hours agoparentprev [–] I think Godot started before Rust took off, so they didn&#x27;t have better alternatives then. The jury is still out on whether other C++ competition has any staying power, and even Rust still has some deficiencies compared to C++ replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Irish startup W4 Games has secured $15 million in Series A funding to support video game development using the open-source Godot Engine.",
      "The funding round was led by OSS Capital, with participation from prominent investors including Naval Ravikant and Justin Hoffman.",
      "W4 Games plans to expand globally, introduce new offerings, and increase its workforce by over 100% within the next year and a half, leveraging the open-source model to revolutionize the gaming industry."
    ],
    "commentSummary": [
      "W4 Games secures $15 million in funding to support video game development using the Godot Engine, with a focus on console porting efforts.",
      "Improbable, a gaming technology company, raises a substantial $500 million in funding.",
      "The Godot Engine is deemed suitable for smaller projects but is seen as improving and potentially viable for larger and more visually advanced games in the future. Some users believe it can even be used for AAA games.",
      "Concerns arise regarding the separation from the parent organization and potential control forks, as well as encountered issues and limitations. However, there is still optimism for improvements.",
      "The discussion also highlights the use of Godot for teaching kids coding and creating educational activities.",
      "Various software tools for artistic and game development purposes, such as Photoshop and Krita, are compared and discussed."
    ],
    "points": 417,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1702119317
  },
  {
    "id": 38586773,
    "title": "A380 Engine Failure: Qantas Flight 32's Miraculous Landing",
    "originLink": "https://admiralcloudberg.medium.com/a-matter-of-millimeters-the-story-of-qantas-flight-32-bdaa62dc98e7",
    "originBody": "A Matter of Millimeters: The story of Qantas flight 32 Admiral Cloudberg · Follow 42 min read · 18 hours ago -- 4 Officials observe damage to the engine of a Qantas A380 after it made an emergency landing in Singapore. (Reuters) On the 4th of November 2010, a Qantas Airbus A380 was rocked by a catastrophic engine failure minutes after takeoff from Singapore, hurling fragments of a turbine disk through its wings and fuselage in multiple locations. The explosion damaged almost every major system on the airplane, from the flight controls and fuel tanks to hydraulics and pneumatics. Faced with a barrage of diverse failure warnings and an airplane of uncertain integrity, the flight crew worked together to make a series of critical decisions that would get their enormous airplane back on the ground. And in the end, despite one curveball after another — including landing gear problems, loss of braking power, and an engine that refused to shut down — they not only landed the plane, but did so without putting a scratch on any of the 469 passengers and crew. The cause of the incident would ultimately be traced deep inside the number two engine to a single oil pipe that had been manufactured with a wall that was slightly too thin. How this seemingly tiny defect came about, and how it nearly brought down the world’s largest passenger plane, represent a story equally as fascinating as that of the flight itself, tracing back years to encompass questionable drawing board decisions, hidden flaws in the machining logic, and faulty assumptions about engine behavior. Time and time again, the problem slipped through the gaps in the system, tumbling down the long slope toward disaster — only to be stopped at the last moment, not only by the pilots themselves, but by a number of explicit protections built into the design of the A380, each of which played a crucial role in containing the fallout from a failure that exceeded the manufacturer’s worst expectations. The story of Qantas flight 32, as told herein, is therefore not only the tale of a dramatic emergency, but a testament to the safety of aviation today — a story that should make every reader feel a little less fearful of flight. ◊◊◊ A brand new Airbus A380 takes to the skies. (Pascal Le Segretain) Introduced to service in 2007, the double decker, four-engine A380 is by far the largest passenger aircraft in the world, exceeding the vaunted Boeing 747 in almost every measurement. Awesome to behold and pleasant to fly, there’s not much to dislike about the A380 — unless you’re an airline, in which case most major carriers dismissed the behemoth as too large for their operating models. Indeed, analysts’ assessment today is that the A380 was built for a market that had shrunk considerably by the time it actually entered service, and as a result, production ended in 2021 with only 254 built, some of which have already been scrapped. For an extraordinarily expensive aircraft equipped with some of the most advanced technology of any airliner, the collective result of immense effort and imagination, such a fate is unfortunate, but the reasons behind it, and the future of the type, are topics for a different article. Despite the above, some airlines did find the A380 suitable for their operations, including Qantas, the flag carrier of Australia. Qantas ordered 10 A380s to be delivered in 2008, of which eight are still flying today. It was the very first of these, registered as VH-OQA and nicknamed Nancy-Bird Walton after the pioneering Australian aviator, that would come to be involved in the events of the 4th of November 2010. VH-OQA, the aircraft involved in the accident. (Andrei Dimofte) On that date, VH-OQA arrived in Singapore for a scheduled stopover on a marathon London-to-Sydney trip, where it took on fuel, passengers, and a new flight crew for the last leg to Australia. The plane was essentially full, with 440 of 450 passenger seats filled, plus a massive complement of 29 crewmembers, including no less than five pilots. Although the A380 is normally flown by only two pilots, Qantas had also rostered a second officer as a relief crewmember; a check airman was conducting a line check on the captain; and another check airman was training the first check airman, so the cockpit was certainly crowded. In command, and under examination, was 53-year-old Captain Richard Champion de Crespigny, a veteran airman with over 15,000 hours of experience and 32 years in aviation. The other crewmembers consisted of First Officer Matt Hicks, Second Officer Mark Johnson, Check Captain Harry Wubben, and Senior Check Captain David Evans. The five crewmembers had a combined 140 years in aviation and 71,000 hours of flying experience, an incredible total that is rarely equaled. At 9:56 a.m. local time, with Captain de Crespigny at the controls, Qantas flight 32 departed Singapore and proceeded southeast across the strait toward Indonesia, passing over the densely populated island of Batam. All parameters still appeared normal as the A380 climbed through 7,000 feet, four minutes after takeoff. There was no indication that a catastrophic failure was in fact just seconds away. ◊◊◊ A Rolls-Royce Trent 900 engine with a man for scale. (Wikimedia user Tangopaso) The Airbus A380 is powered by four massive Rolls-Royce RB211 Trent 900-series high-bypass turbofan engines, each producing up to 84,000 lbf of thrust. Designed specifically for the A380, the Trent 900 was produced at several locations in the United Kingdom and was sold in competition with the American-built GP7200 jointly developed by Pratt & Whitney and General Electric. Understanding what happened aboard Qantas flight 32 requires that I subject you to a description of the structure of certain very specific parts of the engine. Like all high-bypass jet engines, the Trent 900 consists of four main sections: the fan, the compressors, the combustion chamber, and the turbines. During normal operation, air is forced backward and pressurized by a series of increasingly powerful compressors before being fed into the combustion chamber, where it is mixed with fuel and ignited. The combustion creates mechanical energy that spins a series of turbines, which in turn power the compressors, as well as the fan at the front of the engine, which accelerates large quantities of so-called bypass air around the outside of the engine core to generate most of the thrust output. Locations of turbines and compressors on the Trent 900. (FAA) Most turbofan engines examined in my articles have a high pressure compressor and a low pressure compressor, which correspond to high- and low-pressure turbines. These turbines are connected to their respective compressor sections by concentric drive shafts. However, the Trent 900 differs from this layout slightly, because it also has an intermediate pressure compressor with a corresponding intermediate pressure turbine, in between the high and low pressure sections. It also differs in that the fan itself doubles as the low pressure compressor. (From now on, for brevity’s sake, the abbreviations LP, IP, and HP will be used for low pressure, intermediate pressure, and high pressure, respectively.) In this cutaway diagram of the IP turbine area, I’ve drawn blue boxes around the components mentioned in the following paragraph. (ATSB) On the Trent 900, the HP and IP turbine sections at the rear of the engine each consist of a single-stage turbine disk. Blades around the circumference of each disk capture mechanical energy from hot combustion gases flowing through what is known as the “annulus gas path.” These gases spin the disk, which is attached by a drive arm to its associated drive shaft. The shaft then transfers the turbine’s rotational energy forward to the corresponding compressor at the front of the engine. This clip from an FAA video helps visualize the cutaway of the HP/IP bearing assembly. Note the location of the bearing chamber, which is depicted full of oil, and the pipe leading into it. Watch the full video here: https://www.youtube.com/watch?v=sYxVin_FFxQ In order to support the turbine disks and shafts while still allowing them to rotate freely, the engine features a complex system of bearings. The HP and IP turbine sections have a common bearing assembly, called the HP/IP bearing hub, which encircles the drive shafts and holds them in place while allowing free rotation of the shafts within. To prevent wear on the bearings, the space inside the bearing hub, called the bearing chamber, is constantly filled with pressurized oil that keeps everything gliding smoothly. This oil is supplied primarily by an oil feed pipe that runs from the main engine oil supply, past the annulus gas path, and down into the HP/IP bearing hub, where it injects oil through a filter and into the bearing chamber. The structure of the bearing hub consists of an inner and outer hub section, such that an empty buffer space exists between the bearing chamber and the rest of the engine. The oil feed pipe runs through both sections in order to reach the bearing chamber. The last segment of this pipe, a few centimeters in length, is welded in place during manufacture of the bearing hub, and the main portion of the pipe is fitted to it later. This fixed final segment that passes through the buffer space between the inner and outer sections of the HP/IP bearing hub is called the “stub pipe.” For reasons that will be examined in detail later, this tiny oil feed stub pipe triggered an escalating sequence of events within the space of mere seconds as Qantas flight 32 climbed away from Singapore. Within the №2 engine, located in the inboard position on the left wing, a crack in the oil feed stub pipe caused it to begin leaking oil less than four minutes after takeoff. The leak was small, but the oil within the pipe was highly pressurized, resulting in an atomized spray into the buffer space between the inner and outer sections of the HP/IP bearing hub. The temperature inside this buffer space was likely between 365 and 375˚C, well above the 280-degree auto-ignition temperature of the engine oil, so the spray immediately ignited. An FAA animation of the failure sequence leading up to the explosion aboard Qantas 32, annotated by me. This should be really helpful for visualizing the following paragraph. (FAA) At the forward end of the bearing hub, a triple seal is attached to the hub structure to isolate the buffer space, which has a low internal pressure, from the area behind the high pressure turbine disk, where pressure is higher. But as the fire in the buffer space expanded, it impinged upon this seal, causing it to fail. With the low-pressure area no longer sealed off, highly pressurized air from the annulus gas path was drawn toward it, bursting down past the high pressure turbine disk and into the buffer space. This rush of air coming in through the forward end of the buffer space blasted the fire aft, propelling it like a blowtorch against the corresponding seal at the other end, which also failed. The burning oil “blowtorch” was then able to make direct contact with the drive arm connecting the IP turbine disk to its drive shaft, located directly behind the HP/IP bearing hub. Already under considerable stress as a result of normal engine operation, the drive arm failed under the withering heat within a matter of seconds. This entire sequence, from the initiation of the oil leak to the failure of the drive arm, lasted considerably less than one minute. The turbine disk disintegrates. (ATSB) Now, with the drive arm broken, the IP turbine disk was not directly connected to anything, which is (to use the technical jargon) a really big problem. A turbine disk is subjected to considerable mechanical energy from the annulus gas path, and that doesn’t go away when the drive arm breaks, but what does go away is any ability to transfer that energy somewhere other than the turbine disk itself. During normal operations, this energy is used to turn the intermediate compressors, which requires considerable force. But this load path only exists when the turbine disk is connected to the drive shaft, so when the drive arm broke, the only way for the disk to absorb all that energy was to spin faster… and faster… and faster… Within the space of four seconds, the energy from the annular gas flow accelerated the IP turbine past its critical speed, until centrifugal forces exceeded the ultimate strength of the nickel alloy disk. The red-hot, wildly spinning disk instantly fractured into several sections, which rocketed outward in multiple directions at incomprehensible speed. The disk fragments neatly ripped out everything within the disk’s plane of rotation. (ATSB) Engine designers do their best to make sure that the engine structure can contain flying debris like individual fan and turbine blades, but the amount of energy contained within those types of projectiles is a fraction of that within a piece of a burst disk. For engineering purposes, disk fragments are assumed to have infinite energy at the moment of release; they will cut through any reasonable material and cannot be contained. When the IP turbine disk on Qantas flight 32 suddenly burst, nothing could stop the resulting fragments, which cut through the engine case and cowling like butter, cleaving a neat circumferential fissure all the way around the engine within the plane where the disk used to be. Within a fraction of a second, one of these disk fragments exited the engine downward and to the left, propelled toward the distant ground, but several more traveled in the opposite direction. One fragment shot to the right, entered the belly area below the cargo hold, plowed through several structural stringers and wire bundles, then exited out the other side, never to be seen again. Two more fragments rocketed upward, carving paths of destruction through the interior of the left wing before emerging from its upper surface, at which point they too disappeared into space. Numerous smaller pieces, such as dislodged turbine blades and fragments of engine structure, also peppered various parts of the aircraft, including the wings and fuselage. The trajectories of the various fragments. (ATSB) On board the plane, the pilots and passengers heard two distinct bangs in very short succession, which were followed in the cockpit by a sudden, overwhelming cascade of warnings. The plane yawed slightly to the left and the autothrust system disconnected. Recognizing that a serious malfunction had occurred, Captain de Crespigny pressed the altitude hold button on the autopilot to level the plane, and then everyone’s attention turned to the ECAM. The Electronic Centralized Aircraft Monitoring system, or ECAM, presents the crew with warnings, cautions, and advisories related to the degradation or failure of a huge range of aircraft systems, along with the associated abnormal or emergency procedures. A feature of most modern airliners, ECAM displays have transformed the way pilots deal with in-flight emergencies, helping ensure swift and correct action in response to almost any conceivable mechanical failure. Today, this system would be put to the test. The first message to appear on the ECAM screen was an ENG 2 TURBINE OVERHEAT warning, which was followed within the next 20 seconds by another 34 messages of varying alert levels. The highest priority messages, displayed at the top of the list, all indicated a major problem with the №2 engine, but strangely enough, not its outright failure, because the engine — minus the IP turbine disk and everything in line with it — was in fact still turning. Following the indicated ECAM actions, Captain de Crespigny reduced power to the damaged engine, but instead of correcting the problem, an “ENG 2 FIRE” warning flashed on the screen for one or two seconds, then disappeared. A flight crewmember took this photo of the instrument panel during the flight, showing several messages, including a red “warning” level message, on the ECAM display. (ATSB) As First Officer Hicks made a pan-pan call to air traffic control, one level short of “mayday,” the crew decided that the engine was likely severely damaged and elected to shut it down. As they moved to reduce power, an ENG 2 FAIL message finally appeared on the ECAM. The pilots also attempted to actuate both of the engine’s two built-in fire extinguishers, but only one of them actually fired, and neither of the confirmation lights illuminated. However, as they scrolled through the seemingly unending list of ECAM alerts, only one or two of which could be displayed at one time, it became clear that the engine and its fire extinguishers were hardly the only systems having issues. When the fragments of the IP turbine disk passed through the wing and belly of the A380, they caused considerable secondary damage along the way, not only to the №2 engine but also to the left wing fuel tank, which sprang a leak; the leading edge wing slat extension mechanism, which took a direct hit; and the aircraft’s electrical system. Additionally, two wire looms in the leading edge of the wing and in the belly area were completely severed, collectively affecting about 650 wires that carried critical information to and from almost every conceivable aircraft system. A brief and hardly exhaustive summary of the damage to the aircraft included impact damage to the left wing upper and lower skin, front spar, internal ribs, and wing-to-fuselage joint; loss of control over the green (left) hydraulic pumps; degradation of the yellow (right) hydraulic system; loss of AC electrical power from engines 1 and 2; loss of one of four AC power distribution systems; loss of functionality of all leading edge slats; partial loss of functionality of the spoilers and ailerons; degradation of control over all remaining engines, resulting in loss of the autothrust system; loss of functionality of the left wing landing gear brakes and anti-skid on the right wing gear brakes; severe disruption of the pneumatic system; loss of both the №1 and №2 low fuel pressure shutoff valves; degradation of the fuel quantity indicating system; reduction in fuel transfer capability; loss of the fuel jettison system; loss of fire protection capability on engines 1 and 2; and much more besides. A map of operational flight controls surfaces [green] and inoperative surfaces [red]. (ATSB) One of the most serious malfunctions was the loss of the green hydraulic system. Although the system itself was not breached, the severed wires stopped all the green hydraulic pumps, resulting in a loss of pressure that rendered inoperative all systems reliant upon it. Unlike some other wide body aircraft, the A380 has only two hydraulic systems — green and yellow — which mainly supply the left and right sides of the aircraft, respectively. Instead of more redundant hydraulic systems, the A380 has independent backup hydraulic actuators on each individual flight control surface, ensuring that even a total loss of both hydraulic systems will result in minimal flight control difficulties. Nevertheless, direct damage had degraded the plane’s roll control, eliminating the left middle aileron (the A380 has three on each wing) and left wing spoilers 4 and 6. The loss of green hydraulic pressure also caused the failure of the outboard ailerons on both wings, spoilers 2 and 8 on each wing, and spoiler 4 on the right wing. However, the built-in redundancy in the A380 was so great that the remaining spoiler and aileron panels were sufficient to maneuver the airplane despite what amounted to a 65% loss of roll control capability. Initially, the hydraulic system indications confused the crew. Their initial impression was that the damage was confined to the left side of the airplane, so they were surprised to see an indication related to the yellow (right) hydraulic system mixed in with all the other ECAM messages, and they briefly considered whether the messages might be spurious. The same possibility was considered by Qantas technicians on the ground, who were receiving live telemetry data from the aircraft. But by accessing detailed electronic status pages for each aircraft system and cross-checking what was not working, the pilots were able to come to the conclusion that all the failures were most likely real. A passenger took this photo in flight, showing turbine fragment exit holes in the upper surface of the wing. (ATSB) At that point the crew needed to make a decision: should they land immediately, or should they wait to action all of the abnormal procedures associated with the dozens of ECAM messages? Assessing that the aircraft was controllable with the autopilot both on and off, they eventually came to an agreement that it was safe to remain airborne, and that they would rather make sure all crewmembers had a complete understanding of the health of every aircraft system before coming in for a landing. The last thing they needed was a surprise on final approach that would force them to go around. Having chosen this course of action, the crew requested clearance to enter a holding pattern, and ATC granted them permission to circle over the ocean northeast of Singapore. The crew estimated that it would take at least 30 minutes to work through all of the ECAM actions. In the meantime, the cabin crew had been attempting to get the pilots’ attention using the emergency call button, but all the pilots were so focused on the failures that they initially didn’t notice. Only now did they send Second Officer Mark Johnson to assess the situation in the cabin, whereupon a Qantas pilot riding as a passenger in the upper deck drew his attention to the in-flight entertainment system, which featured a live view of the aircraft from a tail-mounted camera. The digital stream clearly showed a much more literal stream of fuel pouring from the left wing and into the aircraft’s wake, which was also visible with the naked eye from the lower deck. Johnson proceeded down to check for himself, at which point he also observed for the first time that there were two gaping holes in the top of the left wing, surrounded by jagged metal, where the turbine disk fragments had exited. According to Check Captain David Evans, the cabin crew were concerned that so many passengers were watching the live feed from the tail camera, but in a collective decision, the pilots elected not to turn it off because, in their view, the feed suddenly cutting out would probably be more alarming than anything that could be seen on it. ◊◊◊ Part of the turbine disk caused serious damage to a building. (ATSB/Posmetro newspaper) Meanwhile on the ground, events were taking an unexpected turn. On Batam Island in Indonesia, debris from the №2 engine plunged into a populated area shortly after the failure, resulting in surprise and alarm. Among the debris was a large portion of the failed IP turbine disk, which fell with such force that it cleaved straight through a building, razing a brick wall. Thankfully, no one on Batam was hurt by the debris. However, photographs of locals holding airplane wreckage in what appeared to be Qantas livery were soon posted to Twitter, where they were taken as indications that a Qantas airplane had actually crashed somewhere over Batam. Qantas engineers already knew that the plane was still flying, but they were unable to contact the crew to find out more information. And outside that bubble, the news that a Qantas A380 had possibly gone down spread so quickly that even investors reacted while the plane was still in the air. In fact, the first time Qantas’s CEO learned of the situation was when he received a call asking why the company’s stock price was dropping. People collect pieces of the fallen engine cowling on Batam. (Reuters) Up in the air, such concerns were far from the minds of the crew. Working through one ECAM procedure after another, they slowly stabilized various disrupted systems, but as they did so, one problem in particular was getting worse: their fuel situation. With fuel leaking prodigiously from the left wing tank, an imbalance had developed between the left and right wings, prompting an ECAM alert instructing them to open the fuel transfer valves to equalize the fuel levels. However, with a leak clearly occurring and other ECAM messages indicating damage to the fuel transfer system, after a detailed discussion the pilots concluded that following the computer’s instructions would be inadvisable — a great example of why experience and judgment are still necessary even on an aircraft as highly automated as the A380. In the end, it took 55 minutes to clear all of the ECAM messages, an unprecedented length of time that was certainly far beyond anything any of the pilots had previously imagined. But even then, more considerations remained before they could land. Most notably, the airplane was still more than 40 tons over its maximum landing weight, and among the failures that had occurred was the loss of the fuel jettison system, so it would be impossible to reduce their weight by dumping fuel. The possibility of remaining in the air until they had burned the extra fuel was considered, but with an increasing fuel imbalance between the right and left wings and a 65% loss of roll control, the pilots determined that this would be irresponsible. Their conclusion was that they had to land soon, even if they were over the maximum weight. But would any of the runways at Singapore be long enough to accommodate a significantly overweight A380 with degraded brakes, several faulty spoilers, and no reverse thrust on engine 2? There was certainly reason to doubt. The complete flight path of flight 32, including its extensive hold. (ATSB) In order to find out for sure, Captain de Crespigny instructed the two Check Captains to determine their required landing distance using the Airbus performance software installed on laptop computers stored in the cockpit. The detailed software allowed them to enter various parameters including the weather, runway condition, and any systems failures, and then calculate whether it was possible to land. But when everything had been entered, the program spit out an unhelpful answer: “no result.” When calculating the landing distance, the software applied a generic “operational coefficient” to account conservatively for variations in pilot techniques that could result in less efficient deceleration. The problem, as investigators would later discover, was that the software applied the coefficient again whenever another system failure was added. With so many system failures on the aircraft, the coefficient was applied a total of 9 times, resulting in a calculated landing distance considerably greater than the length of the available runway. However, Check Captain Evans was able to fix the problem by manually entering their actual landing weight, overriding the program’s assumption of a maximum landing weight. By specifying an landing weight in excess of the maximum, the system logic changed to apply the operational coefficient only once — for unrelated and obscure reasons — and lo and behold, when he ran the numbers this time, the computer said they could just barely land on any of the 4,000-meter runways at Singapore Changi Airport, with only 100 meters to spare. It wasn’t much, but with no better runways anywhere nearby, it would have to do. Indonesian police pose with a fallen piece of the airplane. (AP) Finally ready to commit, Captain de Crespigny now removed the aircraft from its holding pattern and began maneuvering for approach. The crew requested fire trucks on landing due to the fuel leak, and advised the cabin crew to prepare for an on-ground emergency if they overran the runway. They aligned with the runway from considerably farther away than usual in order minimize maneuvering, since the controls felt rather sluggish — mainly the result of the degraded roll control. Captain de Crespigny subsequently carried out further manual control checks during the approach to make sure that the controllability characteristics remained consistent as First Officer Hicks progressively extended the flaps. The pilots also decided to leave engines 1 and 4 at a constant thrust level and adjust their airspeed using only engine 3, because that engine was least affected by the various electronic control system failures. The problems only continued, however. Due to the failure of the green hydraulic system, the landing gear did not drop when the gear lever was selected “down,” forcing the pilots to use a backup system that gravity drops the gear instead. Fortunately, this was successful. Captain de Crespigny also had to maintain a very narrow airspeed band, because there was only a fine margin between the slowest safe speed in the air, below which they would stall, and the highest safe speed on touchdown, above which they would overrun the runway. De Crespigny later recalled that the safe band between these speeds was probably only three or four knots. At one point, the airplane even generated an automatic low energy alert, warning that their airspeed was dropping too low for their present configuration — so de Crespigny increased power slightly on engine 3, and the alert went away. Nevertheless, with the help of the Airbus’s still operational fly-by-wire system and mostly undamaged controls, de Crespigny was able to thread the needle, greasing it onto runway 20C at Changi Airport at 11:46, just shy of two hours after the flight took off. A stall warning briefly sounded just before touchdown, but a split second later they were on the ground and the matter was moot. The pilots applied those brakes that were still working, activated reverse thrust on engine 3 — the A380 only has reversers on its inboard engines — and hoped that it would be enough. The deceleration was not exactly exuberant, but considering how much it takes to stop something the size of an A380 even on a good day, it was impressive enough. Nevertheless, it was not until fairly late in the rollout that the pilots felt certain that they would stop on the runway, and ultimately the performance software was not far off the mark: by the time the plane ground to a halt, only 150 meters remained of the 4,000-meter runway. Firefighters spray foam on the airplane after its emergency landing. (Reuters) And yet at that point, even if some of the passengers thought their ordeal was over, it turned out that there was more to come. As the pilots shut down the engines, they observed that the brake temperature on the left body gear brakes had risen alarmingly. These had been the only working brakes on the left side of the aircraft and were subject to considerable strain during the landing, causing them to overheat; the overheating in turn caused four tires to deflate. To make matters worse, fuel was still leaking from the wing, and there was genuine concern that a fire could erupt if spilled fuel contacted the hot brakes. And on top of that, when engines 3 and 4 were shut down, the plane lost electrical power, and when they tried to start the auxiliary power unit, it wouldn’t hook up the electrical system because of damage to the distribution infrastructure. Operating solely on emergency electrical power, the plane now had only one working VHF radio, and it took a few moments for the crew to figure out which one that was so that de Crespigny could contact the airport fire services. People disembark from flight 32. (Richard de Crespigny) Upon making contact with the fire crew, de Crespigny urged them to cool down the brakes, but the firefighter in charge replied with surprising news: the №1 engine was still running, even though the crew had already carried out the shutdown procedure. Damage to systems in the wing had rendered the №1 fuel shutoff valves inoperative, preventing the crew from shutting the engine down by normal means. Both fire extinguisher bottles in engine №1 were also inoperative, preventing the crew from shutting it down by pulling the emergency fire handle. Unable to resolve the issue, de Crespigny instead urged firefighters to approach the brakes while staying as far as possible from the inlet and exhaust ends of the №1 engine. If firefighters got too close to the inlet, they could be sucked into the fan; alternatively, approaching too close behind would result in severe burns, not to mention the jet blast. Nevertheless, the fire crews managed to get close enough to douse the brakes with foam, averting a conflagration. Throughout this period, the crew also debated whether or not to evacuate the passengers. An evacuation is not always an easy call: statistics show that around 5 to 10% of passengers who evacuate by the emergency escape slides sustain serious injuries, and with 440 passengers on board, including elderly and disabled, that was potentially a rather large number of people. Considering that the fire risk had been tamped down, the crew ultimately agreed that the safest place for the passengers was on the plane — at least for the moment. The flight attendants were asked to move to their stations on the right side of the aircraft to be ready for an emergency evacuation, should the calculus suddenly change, while the pilots attempted to call for a set of stairs to be brought to the aircraft. But with the only working radio being used to liaison with the firefighters, the only other working communications systems aboard the powered-down airplane were the pilots’ cell phones. It took quite some time, and several abortive attempts, before they managed to get through to someone at Qantas who could call the airport services company at Changi Airport and tell them to send a set of boarding stairs. Firefighters attempt to drown the still-running №1 engine. (Reuters) After 50 minutes aboard the increasingly sweltering airplane — without power, there was no air conditioning — the stairs finally arrived, and the disembarkation began. It ultimately took an hour to get everyone off through a single exit in an orderly manner, but in the end, all 440 passengers walked away without a single injury. As for the still-running №1 engine, Qantas engineers eventually concluded that the only way to shut it down was to drown it with firefighting foam. Firefighters then poured huge amounts of water and foam into the intake, which proved successful, as the engine finally spooled down and stopped at 14:53, more than three hours after the aircraft landed. ◊◊◊ The crew of flight 32; from left to right: Mark Johnson, Matt Hicks, Richard de Crespigny, David Evans, and Harry Wubben. (Richard de Crespigny) The news that the crippled Qantas A380 had landed safely in Singapore came as a great relief to all, especially those who were on board the airplane, who immediately heaped praise on the crew. Captain de Crespigny, in an exemplary act of professionalism, even handed out his personal phone number and stayed for two hours in the Qantas lounge in Singapore to answer passengers’ questions about the flight. He and his crew were hailed as heroes, and not without reason. The sheer number of failures aboard the A380 eclipsed almost any other incident, at least on an aircraft with modern failure monitoring technology. Levelheaded decision-making, teamwork, and crew resource management helped the crew collectively determine the course of action least likely to result in injury or loss of life, with perfect results. The aircraft itself, however, helped quite a lot. The design of the flight control system ensured that the impact on controllability was limited, even with serious damage to the ailerons and the loss of one of two hydraulic systems. Despite its size, the A380 is known to respond very gracefully to control inputs thanks to the design of its fly-by-wire system, which during the incident remained fully intact, allowing the pilots to focus primarily on decision-making rather than handling the airplane. The ECAM and the detailed systems pages also helped the pilots take full stock of the extent of the failures in a way that was not necessarily possible two decades earlier. Without minimizing the actions of the crew in any way, it’s also fair to say that the design of the A380 incorporated such redundancy and such high safety margins that the risk of a catastrophic crash was probably very low, even with so much damage to the airplane. Dark colored residue inside the fuel tank near the breaches testified to a brief flash fire. (ATSB) However, there were a couple of places where the potential for worse damage existed. It goes without saying that if any of the turbine fragments had entered the passenger cabin, there would have been injuries, if not fatalities, even if the plane later landed safely. And perhaps even more worrying, investigators later found signs of a very brief flash fire inside the left wing fuel tank, which likely occurred when an extremely hot turbine fragment contacted fuel vapors in the tank ullage. Research conducted as part of the investigation into the 1996 crash of TWA flight 800, which was caused by an explosion of the center fuel tank, found that the wing tanks on commercial airliners contained flammable fuel-air mixtures around 7% of the time. However, on Qantas flight 32, the temperature in the tank was too low for the fuel-air mixture to reach a flammable concentration, and investigators determined that the brief ignition of vapors during passage of the turbine fragment likely failed to raise the temperature of the rest of the fuel sufficiently to sustain combustion. Had this fuel continued to burn, causing an explosion or sustained wing fire, then the outcome could have been very different. Severed wires in the wing leading edge. (ATSB) Even though these worst case scenarios didn’t happen, the level of damage was still far beyond anything Airbus or Rolls-Royce had anticipated, and both companies were keen to know why — as were investigators with the Australian Transport Safety Bureau (ATSB), who were charged with finding out. Initial efforts established that an oil leak caused an internal fire that led to the failure of the IP turbine disk drive arm, as described previously. But that didn’t answer one of the manufacturers’ most burning questions, which was why the disk was allowed to overspeed until it burst — because according to the engine’s design philosophy, this should never have happened. The risk posed by a burst engine disk, whether it’s a fan, compressor, or turbine, is well known in the industry. Numerous catastrophic accidents have occurred as a result of burst disks, either due to overspeed or material defects. Demonstrated side effects of burst disks include severe flight control damage (see United flight 232, Sioux City, Iowa, 1989, in which fan disk debris resulted in the failure of all hydraulic systems, a loss of control on landing, and 111 deaths); direct fatal impacts to passengers (see Delta flight 1288, Pensacola, Florida, 1996, in which a compressor disk entered the passenger cabin on takeoff, killing two passengers); and in-flight fires (see LOT Polish Airlines flight 5055, Warsaw, Poland, 1987, which crashed after a fragment of a burst turbine disk started a fire in the baggage compartment, killing 183). Accidents such as these inform aircraft certification guidelines, which classify a disk failure as a “hazardous” event whose probability must be “extremely remote” (defined as one event or less per 100 million operating hours). And just in case such an event were to happen anyway, rules introduced following the United accident in Sioux City also require manufacturers to minimize the potential secondary failures that could occur as a result, which was part of why the A380 had individual backup hydraulics for all critical control surfaces. Officials inspect the damaged №2 engine. (Reuters) In general, the accident aboard flight 32 demonstrated that the requirements for damage minimization were met, with the exception of the resultant inability to cut fuel to the №1 engine, which was explicitly defined in certification guidelines as undesirable. This success alone distinguished it from previous, fatal disk release accidents. But Rolls-Royce was concerned that the disk burst at all. During development of the Trent 900, the company calculated that in the event that the IP turbine disk became disconnected from the drive shaft, the disk would not accelerate fast enough to burst. Essentially, it was believed that without the turbine to drive it, the IP compressor would decelerate until air no longer flowed smoothly over its blades, causing a compressor stall that would subsequently spread to the HP compressor behind it. This should lead to an engine surge, in which the disruption of airflow through the compressor section allows pressurized air from the combustion chamber to surge forward toward the front of the engine. In theory, this would reduce the amount of air flowing rearward through the annulus gas path and over the IP turbine, relieving the load on the turbine and preventing it from accelerating beyond its critical speed. A key assumption here was that the IP compressor stall would happen faster than the advanced electronic engine control system could detect the surge and reduce fuel flow, which would bring down the combustion chamber pressure to clear the surge and restore normal airflow. In the actual event, investigators found that although the IP compressor stalled and a surge occurred, the automatic reduction in fuel flow came swiftly enough to enable the partial recovery of the HP compressor, which resumed forcing pressurized air into the combustion chamber and thence over the turbine. This unexpectedly robust airflow provided the mechanical energy required to accelerate the IP turbine disk beyond its critical speed. Rolls-Royce engineers were unable to conclusively determine why this occurred. Nevertheless, to prevent it from happening again, the company developed an IP turbine overspeed function for the electronic engine control that directly monitors the IP turbine disk and instantly cuts fuel flow to the engine if the disk starts spinning too fast. ◊◊◊ A visualization of the thin wall of the oil feed stub pipe.( ATSB) Of course, if you’ve gotten this far, then you’re probably aware that one critical question remains. This entire chain of events began when the oil feed stub pipe — remember that? — developed a leak. If you need a refresher, this was the short segment of pipe that passed through the outer and inner sections of the bearing hub to deliver oil to the bearing chamber. So why did this happen? The answer, as it turns out, was visible to the naked eye. When investigators removed the faulty pipe, they found that one wall of the pipe was simply too thin. Unable to withstand the stresses of normal operation, it began suffering from metal fatigue and failed after only 677 flights. How the oil feed stub pipe and its fittings were constructed. (ATSB, annotations mine) The oil feed stub pipe was designed to have a slightly wider inner diameter at the bottom end in order to accommodate a filter. This required widening the interior diameter of the pipe by drilling a “counter bore” in from one end, as shown above. The center of the counter bore should be aligned with the center of the main bore. But on the stub pipe recovered from the failed Qantas engine, the counter bore was displaced to one side by approximately half a millimeter, resulting in an irregular wall thickness that varied from 1.42 mm on one side to only 0.35 mm on the other. It was this extra thin part of the pipe wall that failed on flight 32. The story of how the counter bore became offset by half a millimeter has implications that far outstrip the physical size of the error. The following section is going to involve some fairly complex discussions of the design and manufacturing process, but I hope you’ll bear with me. How the bores for the stub pipe were defined according to the design drawings. (ATSB, annotations mine) When the designs for the HP/IP bearing hub assembly were drawn up during the early 2000s, the design engineers followed standard practice by defining the position and dimensions of the oil feed stub pipe and associated features relative to a fixed point, referred to as a “datum.” This point, designated datum AA, was defined as the hole in the outer section of the bearing hub through which the oil feed stub pipe passes on its way to the bearing chamber. This hole will henceforth be known as the “outer clearance hole.” All other aspects of the stub pipe fitting were positioned with respect to the centerline of this hole. In line with the outer clearance hole, the designs also called for an “interference bore” in the inner hub into which the bottom end of the stub pipe would fit. The interference bore was designed to be very slightly narrower than the stub pipe so that the pipe end, once tapped firmly into place within it, would be held inside by friction. This bore was required to be centered on datum AA so as to keep it perfectly aligned with the outer clearance hole. Next, an “inner hub counter bore” would be drilled in from the inside of the inner hub, meeting in the middle with the interference bore. This was the hole through which the oil from the stub pipe would enter the bearing chamber. Then, once these holes were machined, the oil feed stub pipe itself would be inserted through the outer clearance hole and into the interference bore, then welded in place. How to interpret the relationship between a tolerance value, the datum, and the offset. (ATSB, annotations mine) Finally, working from the inside through the inner hub counter bore, the stub pipe counter bore would be drilled to a specified depth to accommodate the filter. (This was the bore that was later found to be offset by half a millimeter.) According to the design specifications, the stub pipe counter bore should be in line with datum AA, with a tolerance of Ø 0.10 mm. In plain English, that means that the center of the counter bore should lie within a 0.10-mm-diameter circle centered on datum AA. It does not mean that the bore can be 0.10 mm from the datum, but rather that the bore can lie within 0.05 mm of the datum in any direction, for a total range of possible positions measuring 0.10 mm across. (Hereinafter, the term “offset” refers to the distance of a given point from the datum, while the terms “tolerance” and “non-conformance,” indicated with the “Ø” symbol, refer to the diameter of a circle centered on the datum with its edge at the given point. As confusing as this may be for some readers, this is how tolerances are measured in real life engineering, so if engineers can deal with it, so can you (hopefully).) How the stub pipe and its fittings were defined according to the manufacturing stage drawings. (ATSB, annotations mine) In any case, when it came time to plan the actual manufacture of the bearing hub assembly, some changes had to be made to this process. The basic problem was that once the oil feed stub pipe was inserted into the hub assembly, it would no longer be possible for the machining computer to find the location of datum AA, because the outer clearance hole by which it was defined would be too full of stub pipe. That meant that it would be impossible to determine exactly where the oil feed stub pipe counter bore should subsequently be drilled. In order to fix this problem, Rolls-Royce manufacturing engineers decided to redefine the position of the stub pipe counter bore with relation to a new datum, named datum M, which corresponded to the center of the inner hub counter bore. At the same time, the tolerance for the stub pipe counter bore was changed from Ø 0.10 mm to Ø 0.20 mm for unknown reasons. But the bigger problem was that the position of the stub pipe itself was determined by the position of the interference bore, which was still defined by datum AA. Because the position of the inner hub counter bore did not have a specified tolerance relative to datum AA — in fact, in the original design plan, its position didn’t matter much at all — there was no direct assurance that datum M would line up with datum AA, and thus it could not be assured that the stub pipe would line up with its own counter bore either. At this point you might already be starting to see the problem. How the series of bores was actually drilled. (ATSB, annotations mine) The actual manufacturing process, based on the above specifications that were written into the manufacturing stage drawings, proceeded as follows. First, the basic hub assemblies were delivered to the Rolls-Royce machining plant in Hucknall, UK, with the outer clearance hole already drilled (and datum AA thus defined), but without the interference bore or the inner hub counter bore (datum M). Instead, a reference hole was drilled, with reference to datum AA, in the location that would later become the inner hub counter bore. A temporary timing pin was inserted into this reference hole, which was then used by the computerized machining equipment to orient the hub so that the machining arm aligned with datum AA. So far so good. Subsequently, the interference bore was drilled, with reference to datum AA. Then came the most dastardly part: in order to drill the inner hub counter bore, the timing pin had to be removed, but the machine also needed to remember its location in order to know where to drill. Therefore, the machining computer used specialized probes to measure and record the position of the timing pin within three-dimensional space, allowing subsequent removal of the pin. At that point the only thing ensuring the correct alignment of the inner hub counter bore — and thus datum M, and thus the stub pipe counter bore — was the assumption that the recorded position of the timing pin remained accurate. Can you see the offset in the drilled position of the inner hub counter bore? (ATSB) Unfortunately, that assumption proved incorrect. The problem was that while the interference bore had been drilled from the outside, the inner hub counter bore had to be drilled from the inside, which necessitated the reconfiguration of the clamps holding the hub assembly in place, in order to make room for the machining arm. During this process, the hub assembly sometimes — but not always — shifted imperceptibly. If the hub shifted, then when the machining process resumed, the recorded location of the timing pin (and thus datum AA) would by slightly offset from its actual, new location, and the machine would subsequently drill the inner hub counter bore offset by an equal amount. That meant that datum M — again, defined as the center of the inner hub counter bore — would also be offset from datum AA by that amount. Subsequently, the stub pipe was inserted through the outer clearance hole and into the interference bore, where it was welded in place. The stub pipe counter bore was then drilled into the end of the pipe with reference to datum M, which, again, would be offset if the hub had shifted. In the case of the components involved in the accident, the hub presumably shifted by just under half a millimeter, resulting in an equal offset of both the inner hub counter bore and the stub pipe counter bore relative to the pipe itself. As a side effect, one wall of the pipe was too thin. The final product is created with a thin stub pipe wall. The best way to notice this offset of the stub pipe counter bore is by measuring the position of the interference bore relative to datum M. Measuring the interference bore relative to datum AA will not reveal the error. (ATSB) In the original design, no stub pipe wall thickness was specified; instead, adequate wall thickness was ensured by the alignment of both the pipe (via the interference bore) and its counter bore with the same datum (AA). The fact that this assurance could be lost when using the reworked manufacturing process was not recognized at the time, nor were the subsequent inspections tailored to find such a defect. In this regard, two inspections are of note, both of which involved the use of a computerized coordinate machine, or CMM. One of these, known as OP 230, involved only the measurement of the stub pipe counter bore position relative to datum M, which provided no useful information as to its position relative to the pipe itself. A visual inspection was also conducted at this stage, but it was not possible for an inspector to observe the stub pipe wall thickness at the counter bore because this end of the pipe was welded inside the interference bore, completely out of sight. Another inspection, called OP 70, occurred prior to OP 230 and presented a better opportunity to notice the error. During this inspection, the CMM measured the position of the interference bore relative to datum M, even though it was machined with reference to datum AA. If datum M and datum AA were offset by more than the specified tolerance for the interference bore, this should have caused the CMM to report an error in the position of the interference bore. The tolerance for this bore was supposed to be Ø 0.05 mm according to the design drawings, but was changed to Ø 0.5 mm in the manufacturing drawings without explanation. Even so, the non-conformance on the accident hub was between Ø 0.90 and Ø 0.98 (an offset of 0.45–0.49 mm), which should have been flagged by the machine. The CMM records from the accident hub were not retained, so it was not possible for investigators to confirm that the error was actually registered. However, even if it was, a follow-up inspection might have concluded that the error was false — because the manufacturing drawings specified the position of the interference bore relative to datum AA, and inspectors were generally unaware that the CMM was actually measuring the position of the bore relative to datum M. Therefore, if inspectors saw that the position of the interference bore was flagged as out of tolerance, they could refer to the manufacturing drawings, check the bore’s position with reference to datum AA, find everything to be normal, and give the hub a clean bill of health. A coordinate measuring machine used at the Hucknall facility. (ATSB) For the above reasons, numerous HP/IP bearing assembly hubs were released for service with oil feed stub pipe walls that may or may not have been too thin. No one was aware of this until 2009, after the accident hub was manufactured, when Hucknall Casings and Structures decided to change the datum for the oil feed stub pipe counter bore in order to simplify the manufacturing process. The change called for the use of datum AF, which was defined as the center of the pipe’s main bore, to position the pipe’s counter bore. Subsequently, two previously manufactured stub pipe counter bores were measured against this new datum and found to have a non-conformance of Ø 0.5 mm (or an offset of 0.25 mm, about half that of the accident pipe). As a reminder, the tolerance for the stub pipe counter bore was supposed to be Ø 0.20 (for a maximum permissible offset of 0.1 mm). This problem was soon called to the attention of a design engineer, who escalated it up the chain of command in order to figure out what to do about the approximately 100 oil feed stub pipes that had already been released for service. At issue was whether the error would have safety implications. If there were no safety implications, then the plant could issue what it termed a “retrospective concession,” allowing the improperly manufactured products to remain in service. But if there were safety implications, then there would need to be corrective actions, perhaps even a recall. In order to find out, a manufacturing engineer was assigned to conduct a statistical analysis of the likely distribution of oil stub pipe counter bore non-conformances based on measurements taken on nine previously manufactured hubs that were still at the facility. Using a statistical analysis program, the engineer found that the likely maximum non-conformance of any stub pipe counter bore was Ø 0.7 mm (an offset of 0.35 mm). Engineering calculations showed that the resulting wall thickness would not seriously alter the service life of the stub pipe, which meant that there was no safety implications. The revised manufacturing datum was much more robust, but the implications for previously produced hub assemblies were not adequately appreciated. (ATSB) In reality, this statistical analysis was flawed because of the low number of data points, and the lack of assurance that the dataset of nine hubs was representative of hubs manufactured in previous years. Therefore, the result should really have been read as “a maximum likely non-conformance of Ø 0.7 mm plus or minus an uncertainty factor of unspecified magnitude.” However, the engineer was unfamiliar with the statistical analysis program and failed to clearly convey this uncertainty in the report that was submitted to the Non-Conformance Authority, the engineer empowered to make decisions about the acceptability of non-conformances. The Non-Conformance Authority took the report to mean that there were no safety implications, and signed off on the retroactive concession allowing the affected pipes, including the accident pipe, to remain in service. Investigators noted that according to Rolls-Royce’s internal procedures, a retrospective concession also required the signatures of the Business Quality Director and more importantly the Chief Engineer, who had the power to decide whether any fleet-wide actions were warranted. Neither of these signatures were obtained for the retrospective concession that was granted to the oil feed stub pipes. The ATSB observed that the Hucknall facility was using the same paperwork for retrospective concessions as it used for concessions on non-conforming parts that were caught in-house, which did not require these extra signatures, so no signature field for them was provided. There was also nothing on the paperwork to indicate whether a concession was retrospective or not. As such, the Non-Conformance Authority might have been unaware that they lacked the right to unilaterally approve the concession without the consent of a higher-ranking engineer. ◊◊◊ Another view of the damaged engine. (ATSB) After the accident, measurements were taken on all in-service HP/IP bearing oil feed stub pipes to determine the alignment of their counter bores. The majority were outside the Ø 0.20 mm tolerance on the manufacturing drawings, and several of them had non-conformances greater than the Ø 0.7 mm predicted by the statistical analysis. Four of the stub pipes had non-conformances even greater than the accident pipe, and two were found to have a staggering non-conformance in the vicinity of Ø 1.2 mm. These pipes likely would have failed in service, potentially causing repeats of the Qantas incident, had they not been caught. Investigators also criticized the culture within the Hucknall facility that manufactured the HP/IP bearing hubs, identifying signs of complacency and widespread procedural non-compliance. A paperwork review showed that the required signatures were missing from 131 out of 138 retrospective concessions issued between 2009 and 2011, and a large number of minor non-conformances had not been properly handled through the normal chain of command. An internal review in 2007 had also previously found that the Hucknall facility lacked a “strong focus on quality within the business.” This appeared to extend to the creation of the original manufacturing drawings, which had been altered from the design drawings without the consent of the design engineers. Furthermore, initial inspections at the start of the production run were supposed to verify that the manufacturing process was creating products that satisfied the “design intent,” but the initial products were checked against the manufacturing drawings, not the design drawings. This verification was circular in nature and did nothing to ensure that the design intent was actually met. Had the design drawings been used, as procedures demanded, engineers likely would have been discovered that the process was not producing stub pipes with the required tolerances. ◊◊◊ Another passenger view of the upper wing surface damage. (Reuters) Following the accident, a long list of safety actions were taken to prevent a recurrence and incorporate lessons learned. A non-exhaustive list of these safety actions includes the following: · Qantas temporarily grounded its A380 fleet between November 4 to November 27, 2010. · The European Aviation Safety Agency issued an airworthiness directive mandating inspections of all Trent 900 oil feed stub pipes. · Rolls-Royce developed an IP turbine overspeed protection system. Airbus issued a mandatory service bulletin requiring its installation on All A380s within 10 flights. · The entire original production run of HP/IP bearing hubs was removed from service and scrapped. All other HP/IP bearing hubs with an oil feed stub pipe wall thickness less than 0.7 mm were also removed from service. · Rolls-Royce revised its procedures to ensure consultation between manufacturing and design engineers over the design intent of newly introduced parts. · A number of efforts were initiated to change the culture around non-conformances at the Hucknall facility. · Rolls-Royce ended the practice of retrospective concessions and instituted a new program for dealing with non-conforming parts that escaped into service. · Airbus modified the landing performance software to more accurately predict the actual performance of the airplane at all landing weights. Collectively, these reforms have done much to ensure that Rolls-Royce continues to produce quality products, and to maintain the perfect safety record of the Airbus A380, which to date has never suffered an accident resulting in injury to passengers. ◊◊◊ Large sections of the airplane’s wing had to be replaced, among other repairs, but it eventually flew again. (Qantas) If you have made it this far, I first of all commend your patience, and/or your nerdiness. And second, I will speculate that everything you’ve read thus far has probably left a positive impression of modern aviation safety. The sequence of events required to merely wound, not kill, this Airbus A380 was absurdly long, passing numerous gates at which the progress toward disaster could have been stopped. And yet the system still held its ground. According to the swiss cheese model of safety, an accident happens when the holes in the stacked swiss cheese slices align, allowing a hazard to pass straight through unhindered. The hazard in this case penetrated countless swiss cheese slices, from the drawing board to the manufacturing floor to the inspection room and beyond. But the industry has put up so many slices of cheese that even this impressive run was insufficient to put a scratch on so much as a single passenger. Even the airplane itself ultimately survived: after a marathon repair that lasted 535 days and cost $139 million, the A380 Nancy-Bird Walton triumphantly returned to the skies in 2012. A number of intangible lessons can be drawn from both the successes and failures along the road to Qantas 32, from the continued importance of experience and judgment in the cockpit, to the negative consequences of believing that a tiny non-conformance couldn’t possibly be consequential. The fact remains that a deviation of less than half a millimeter nearly brought down the world’s largest passenger airliner. Aviation is, and has always been, unforgiving of even the smallest flaws. The devices, designs, and decisions that kept Qantas flight 32 in the air didn’t appear from nothing, but are rather the collective result of rules, regulations, and forward-thinking policies imposed by people upon that unforgiving substrate. In that sense, the upshot of the drama aboard flight 32 is that at the end of the day, the system is working. _______________________________________________________________ Don’t forget to listen to Controlled Pod Into Terrain, my new podcast (with slides!), where I discuss aerospace disasters with my cohosts Ariadne and J! Check out our channel here, and listen to our latest episode, in which we break down the incredibly poor decision-making aboard Pinnacle Airlines flight 3701. Alternatively, download audio-only versions via RSS.com, or look us up on Spotify! _______________________________________________________________ Join the discussion of this article on Reddit Support me on Patreon (Note: I do not earn money from views on Medium!) Follow me on Twitter Visit r/admiralcloudberg to read and discuss over 250 similar articles",
    "commentLink": "https://news.ycombinator.com/item?id=38586773",
    "commentBody": "A Matter of Millimeters: The story of Qantas flight 32Hacker NewspastloginA Matter of Millimeters: The story of Qantas flight 32 (admiralcloudberg.medium.com) 360 points by xenophonf 11 hours ago| hidepastfavorite144 comments modernpacifist 7 hours agoI don&#x27;t know about others, but I can&#x27;t help but smile when I read the detailed series of events in aviation postmortems. To be able to zero in on what turned out to be a single faulty part and then trace the entire provenance and environment that led to that defective part entering service speaks to the robustness of the industry. I say that sincerely since mistakes are going to happen and in my view robustness has less to do with the number of mistakes but how one responds to them.Being an SRE at a FAANG and generally spending a lot of my life dealing with reliability, I am consistently in awe of the aviation industry. I can only hope (and do my small contribution) that the software&#x2F;tech industry can one day be an equal in this regard.And finally, the biggest of kudos to the Kyra Dempsey the writer. What an approachable article despite being (necessarily) heavy on the engineering content. reply WalterBright 5 hours agoparentAs a former Boeing engineer, other industries can learn a great deal from how airplanes are designed. The Fukushima and Deepwater Horizon disasters were both \"zipper\" failures that showed little thought was given to \"when X fails, then what?\"Note I wrote when X fails, not if X fails. It&#x27;s a different way of thinking. reply f1shy 2 hours agorootparentAs an engineer I think a lot about tradeoffs of cost vs other criteria. There is little I can learn from nuclear or aviation industry, as the cost structure ist so completely different. I’m very happy that the costs of safety in aviation are very good accepted, but I understand that few people are willing to pay similar costs for other things like, say, cars. reply uselpa 1 hour agorootparentCars might not be the best example, since human lives are at stake, as in aviation. Unless you work on Teslas autopilot, it seems. But yes, backups and restores are often good enough. reply masklinn 1 hour agorootparentAs it turns out (and as much as we wouldn’t want them to) human lives are still subject to cost&#x2F;benefit analysis.An airliner is a lot of lives, a lot of money, a lot of fuel, and a lot of energy. Which is why a lot has been invested in training, procedure, and safety systems.Cars operates in an environment which is in most ways a lot more forgiving, they’re controlled by (on average) low-training low-skill non-redundant crews, they’re much more at risk of “enemy action”, the material stresses are in a different realm, and they’re much, much more sensitive to price pressure.Hell, the difference is already visible in aviation alone, crop dusters and other small planes are a lot less regulated amongst every axis than airliners are. reply bboygravity 28 minutes agorootparentprevAny substantiation for \"Unless you work on Teslas autopilot, it seems\"?I mean you&#x27;re implying that there are more accidents with autopilot than without it, right? Seems like quite the claim... reply uselpa 17 minutes agorootparentNo, I&#x27;m implying that the autopilot code has not been as thoroughly tested as it should have been.Example: https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2023&#x2F;nov&#x2F;22&#x2F;tesla-aut... reply laydn 42 minutes agorootparentprevWhat&#x27;s fascinating about airplane design for me is not the huge technical complexity, but rather, the way it is designed such that a lot of its subsystems are serviceable by technicians so quickly and reliably, not just in a fully controlled environment like a maintenance hangar, but right on the tarmac, waiting for takeoff. reply cedivad 2 hours agorootparentprev> When my AoA sensor fails, then what?crickets, let&#x27;s just randomise which sensor we use during boot, that ought to do it! reply rytis 49 minutes agorootparent\"AoA sensor\" - Angle of Attack sensor.And the reference is presumably to 737 MAX accident. https:&#x2F;&#x2F;www.afacwa.org&#x2F;the_inside_story_of_mcas_seattle_time... reply uselpa 2 hours agorootparentprevEpic fail indeed, costing many lives. reply mzi 3 hours agoparentprevIt took hundreds of subject experts from ten organizations in seven countries almost three years to reach that conclusion.Here at HN we want a post mortem for a cloud failure in a matter of hours. reply modernpacifist 2 hours agorootparent> Here at HN we want a post mortem for a cloud failure in a matter of hours.I&#x27;ll go one further - I&#x27;ve yet to finish writing a postmortem on one incident before the next one happens. I also have my doubts that folks wanting a PM in O(hours) actually care about its contents&#x2F;findings&#x2F;remediations - its just a tick box in the process of day-to-day ops. reply sylens 7 hours agoparentprevI think many of us are so used to working with software, with its constant need for adaptation and modification in order to meet an ever growing list of integration requirements, that we forget the benefits of working with a finalized spec with known constants like melting points, air pressure, and gravity. reply abid786 7 hours agorootparentCompletely agree - I think it can go one of two ways. Software is more malleable than airplanes are and that also comes with downsides (like how much time and effort it takes to bring a new plane to the market) reply RajT88 5 hours agorootparentI was just thinking of this metaphor today.Try drawing the software monstrosity you work on &#x2F; with as an airplane. 100 wings sticking out all different directions, covered with instruments and fins, totally asymmetrical and 5 miles long. Propellers, jets, balloons, helicopter blades.Yep, it flies.When it crashes, just take off again. reply WalterBright 5 hours agorootparentprevAirliners face constantly changing specifications. No two airliners are built the same. reply spenczar5 5 hours agorootparentDo you mean no two individual planes? Like two 767s made a month apart, do you mean they literally would have different requirements? reply WalterBright 5 hours agorootparentYes. There are constant changes to the design to improve reliability, performance, and fix problems, and the airlines change their requirements constantly. reply ponector 1 hour agorootparentprevI think they means that airplanes are made in different versions, catered to particular airline. Also planes are constantly updated.Two 767 made few months apart will have initial difference, like two different versions of java 8 SDK. reply MBCook 5 hours agorootparentprevI think they meant a 737-400 is different from a 737-500 is different from a 787 and a AirBus 320 and a MD-80 and…Every single model is somewhat bespoke. There’s common components but each ends up having its own special problems in a way I assume different car models in a common platform (or two small SUVs from competing manufacturers) just don’t. reply crabmusket 6 hours agoparentprev> To be able to zero in on what turned out to be a single faulty part and then trace the entire provenance and environment that led to that defective part entering service speaks to the robustness of the industry.And to be able to reconstruct the chain of events after the components in question have exploded and been scattered throughout south-east Asia is incredible. reply Gare 5 hours agorootparentMy impressiom was that the defective part was still inside the engine when it landed. reply EdwardDiego 3 hours agorootparentProbably a reference to other incidents. Shout out to the NTSB for fighting off alligators while investigating this crash... https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ValuJet_Flight_592 reply bambax 55 minutes agoparentprevThe Checklist Manifesto (2009) is a great short book that shows how using simple checklists would help immensely in many different industries, esp. in medical (the author is a surgeon).Checklists of course are not the same as detailed post-mortems but they belong to the same way of thinking. And they would cost pretty much nothing to implement.Also CRM: it&#x27;s very important to have a culture where underlings feel they can speak up when something doesn&#x27;t look right -- or when a checklist item is overlooked, for that matter. reply jstanley 1 hour agoparentprev> robustness has less to do with the number of mistakes but how one responds to themIt must have something to do with the number of mistakes, otherwise it&#x27;s all a waste of time!It&#x27;s all well and good responding to mistakes as thoroughly as possible, but if it&#x27;s not reducing the number of mistakes, what&#x27;s it all for? reply krisoft 4 minutes agorootparent> It must have something to do with the number of mistakes, otherwise it&#x27;s all a waste of time!Not really. Imagine two systems with the same amount of mistakes. (Here the mistakes can be either bugs, or operator mistakes.)One is designed such that every mistake brings the whole system down for a day with millions of dollars of lost revenue each time.The other is designed such that when a mistake happens it is caught early, and when it is not caught it only impacts some limited parts of the system and recovering from the mistake is fast and reliable.They both have the same amount of mistakes, yet one of these two systems is wastly more reliable.> if it&#x27;s not reducing the number of mistakes, what&#x27;s it all forFor reducing their impact. reply nextos 6 hours agoparentprevAviation is great because the industry learns so much after incidents and accidents. There is a culture of trying to improve, rather than merely seeking culprits.However, I have been told by an insider that supply chain integrity is an underappreciated issue. Someone has been caught selling fake plane parts through an elaborate scheme, and there are other suspicious suppliers, which is a bit unsettling:\"Safran confirmed the fraudulent documentation, launching an investigation that found thousands of parts across at least 126 CFM56 engines were sold without a legitimate airworthiness certificate.\"https:&#x2F;&#x2F;www.businessinsider.com&#x2F;scammer-fooled-us-airlines-b... reply EdwardDiego 2 hours agorootparentAdmiral Cloudberg has covered a case where counterfeit or EOL-but-with-new-paperworks components were involved in a crash.https:&#x2F;&#x2F;admiralcloudberg.medium.com&#x2F;riven-by-deceit-the-cras... reply solids 1 hour agoparentprevI agree, and also I enjoy the attitude. While in my profession the postmortems goal is finding who to blame, here the attitude is towards preventing it to happen again, no matter what. Or at least that’s how I feel. reply Horffupolde 6 hours agoparentprevIf 200 people died after a db instance crashed, software would be equal in that regard. reply girvo 6 hours agorootparentTo prove this, software that deals with medical stuff is somewhat more like aviation. reply conradev 6 minutes agorootparentYep. Insulin pumps can kill their owner and the software updates need to be FDA approved:https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC4773959&#x2F; reply cwalv 2 hours agorootparentprevAlso, aviation and software aren&#x27;t orthogonal. E.g., the article mentioned that part of the reason the pilot was able to sustain a very narrow velocity window between stall and overrunning the runway was because of the A380&#x27;s fly by wire system. reply switch007 1 hour agoparentprev> I can only hope that the software&#x2F;tech industry can one day be an equal in this regardI’d love to be an engineer with unlimited time budget to worry about “when, not if, X happens” (to quote a sibling comment).But people don’t tend to die when we mess up, so we don’t get that budget. reply colechristensen 6 hours agoparentprevAerospace things have to be like this or they just wouldn’t work at all. There are just too many points of failure and redundancy is capped by physics. When there’s a million things which if they went wrong could cause catastrophic failure, you have to be really good at learning how to not make mistakes. reply WalterBright 5 hours agorootparent> you have to be really good at learning how to not make mistakes.Not exactly. The idea is not not making mistakes, it&#x27;s whatcha gonna do about X when (not if) it fails. reply gumby 8 hours agoprev30 years ago I was in an emergency landing due to engine failure situation (flight attendants take away your shoes, practice crash position, rearrange the passengers etc) and the thing that stuck out the most for me was that everybody did as they were told. No self righteous people; it was clear to everyone why there are flight attendants aboard and that they were key to your survival. The evacuation was orderly, though the follow up was lengthy (e.g. everybody’s passport was still on board).More recently I’ve seen pictures of people evacuating down the slides with their luggage! Seems incredibly dangerous, not just for the slide experience but in slowing down evacuation. We had no fire in the cabin but what if we had?Oh yeah, you know the stereotype of the press sticking their camera in your face to see how freaked out you are? It does happen in real life. reply MBCook 5 hours agoparentYou’re not supposed to take anything on the slides. No luggage. No shoes. Just you.But it is ignored. Which is sad, people could really get hurt.Your right though the fact as many people comply as they do is kind of incredible given how people act in other situations. reply gumby 1 hour agorootparentThey took out per shoes away so that was that. According to a parallel reply, they no longer do that. reply jshier 4 hours agorootparentprevYeah, according to the linked article 5 - 10% of people are injured using the escape slides, which is why they waited for the stairs in this case. reply dataflow 5 hours agorootparentprevWhy in the world do you have to take your shoes off before going down the slides? I could understand jackets or jewelry, but shoes? reply defrost 5 hours agorootparentAs silly as it might seem, you do something enough times and oddball rare things happen .. this is an instruction intended to reduce:* shoesboots with sharp objects embedded in soles (glass, bent nails)* extra spikey high heels,* work boots with hard edged metal hooks for laces,(etc) causing damage to both inflatable slipways and to other passengers.How often has a passenger going down an emergancy slide caused a rip that deflated that slide?Not very often .. and aircrew are taught to issue instructions that make that as an unlikely occurence as possible. reply polonbike 2 hours agorootparentAlso, try to swim&#x2F;stay afloat with shoes ... Apart from young athletes, most people will drown within a minute reply Gibbon1 2 hours agorootparentprevAnd if something gets caught on the slide as you go down you could fall a dozen or more feet onto hard asphalt. Friend fell on a slide and got a compound leg fracture. reply thelibrarian 4 hours agorootparentprevMany shoes have hard, sharp parts that could damage the slide, even to the point of complete deflation. There is no time to assess whose shoes would be safe and whose not, so the blanket rule is \"no shoes\". reply resolutebat 5 hours agorootparentprevHigh heels are not OK, for obvious reasons. Regular shoes are fine. reply gumby 4 hours agorootparentThey confiscated all our shoes. Crashing into someone at the bottom with shoes could be a problem too. reply MBCook 4 hours agorootparentprevHuh. That sounded wrong so I googled it. I thought it was all shoes.You’re right. What I said above used to be true. That seems to have been questioned in the 90s and in 2000 the FAA finalized a rule changing it.The current recommendation (https:&#x2F;&#x2F;www.faa.gov&#x2F;travelers&#x2F;fly_safe&#x2F;information) say you can keep your shoes on but to remove high heels, as you said.A bit of googling says it was changed because of passengers injuring their feet on the terrain&#x2F;debris after crashes. Additionally modern slides are much tougher than they used to be and won’t tear from shoes and probably even high heels.But I bet high heels are probably not a smart thing to be wearing on possibly uneven debris covered terrain in an emergency when you need to move fast and safely.Learn something new every day. reply thelibrarian 4 hours agorootparentprevNot just high heels, but also many boots have sharp protrusions (e.g. lace hooks on some hiking boots and work boots, metal decorations on goth and cowboy boots) reply dataflow 5 hours agorootparentprevAhh that makes way more sense. Thanks. reply woutr_be 53 minutes agoparentprevI’ve always wondered what happens after an emergency landing. Do you just kinda sit there and wait for bags and personal belongings to be offloaded? And then wait for another flight out? reply abrookewood 2 hours agoparentprevHonestly, each and every one of those people should either be charged with reckless endangerments, put on an no-fly list or both. It really pisses me off when I see that. F**ing entitled idiots. reply woutr_be 52 minutes agorootparentI remember there was this video of a plane in Russia that was on fire, multiple people died. And you see people walking away with their luggage, can’t help it think people would still be alive if it wasn’t for those who so urgently needed their suitcases. reply aunty_helen 8 hours agoprevMy first job was working at a mro that overhauled engines a bit smaller than the Trent 900s but same principles apply.I built qa software to digitize the forms and signature process like what’s mentioned in the article as having not correctly been signed off on.I ate lunch with repair engineers that had dark wells of knowledge about the engines they worked on. They could talk so deep on a subject that lunch break was over and we’d resume conversation over weeks.There’s a paragraph in this post that hits a few points that are very subtle. The missing sign offs and engineers not knowing the process and and and. I think the criticism of RR is valid here. The qa manager at the mro I worked at was a force of nature. He was feared and uncompromising. He was also the signature that could cause an engine shutdown in flight. I admired this person and still do.There’s small issues like this that go on every day on every engine model all over the world. There’s thousands of engines flying right now that have little defects that could cause a shutdown. There’s issues that have been identified, signed off as low risk and will be checked next time the engine comes in for overhaul.There’s engineers out there that see the same fault, a premature cracked pipe, carbon buildup, abnormal corrosion, after a while of seeing this problem, they’ll raise the paperwork which will go up the chain and sit. It may be ignored, taken for information for future designs, identified as something that should be fixed or monitored or the frequency of monitoring increased. Maybe the part life will be reduced or you will be forced to NDT the part at each overhaul.The cheese wheel concept is great as these systems are so complex there’s always going to be some issues.As for Qantas, near the end it mentions the plane was repaired at great cost. It’s a source of company pride that they’ve never lost an airframe. They repair planes which are BER (beyond economic repair) just to keep this record. reply jnsaff2 56 minutes agoparentI had a small experience with RR as a company through a contract. Including some time spent in Derby.The things I saw left me question how any innovation could happen at all in there or why we did not have a much higher rate of fuck-you-shima per year or how the hell plane engines are not exploding daily.IIRC the B777 engine controllers are still m68k. Discontinued in 1995. reply grecy 7 hours agoparentprev> As for Qantas, near the end it mentions the plane was repaired at great costIndeed. Qantas has been ranked the safest airline int he world almost every year since forever [1]I clearly remember when QF32 happened and everyone was utterly shocked. That simply DOES NOT happen to Qantas.[1] https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;laurabegleybloom&#x2F;2023&#x2F;01&#x2F;03&#x2F;ran... reply dabiged 2 hours agorootparentQANTAS has, for the last 10+, had a CEO who was not part of this culture and did everything he could to drive costs down. He laid off huge swaths of engineers, outsourced key maintenance contracts to the lowest bidder and left the airline with an aging fleet that needs billions spent to replenish. He was recently fired by the board for essentially destroying the reputation of the airline within Australia, with their practice of cancelling flights at short notice, illegally sacking thousands of staff during COVID and taking 100&#x27;s of millions of dollars from the Australian government to keep staff employed during the airline&#x27;s grounding during COVID and handing it all to shareholders.It is a situation very similar to the downfall of Boeing. reply rswail 1 hour agorootparentThe destruction of Qantas as a quality airline is entirely driven by exactly the same MBA&#x2F;shareholder-value bullshit that destroyed Boeing and others.Financial engineers should be banned from operating businesses. They are not focused on the quality of the business, from which profits are derived. They work backwards from their financially engineered results to drive down \"costs\", even if those \"costs\" are entirely essential to the operation of the business.Qantas (and its subsidiary Jetstar) are having to recover their engineering, customer service, and other \"costs\" to actually achieve the operating business that their expensive tickets require. Currently they are being priced out of operating in Asia, not because they have too expensive operations, but because their board and CxOs were entirely driven by shareholders, not the ongoing operation of the business. reply Stratoscope 8 hours agoprevIt may be a cliché to call someone a \"national treasure\", but I would take it a step further for Admiral Cloudberg: she is a world treasure.Kyra has written so many great articles under her nom de cloud. Trust me, just pick any of them and you will learn something.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;from?site=admiralcloudberg.medi... reply genewitch 2 hours agoparentthere&#x27;s a video podcast, too, which they should put on TV instead of whatever is on there now, overdramatized claptrap reply ren_engineer 10 hours agoprevthere are some crazy talented pilots out there who are able to perform under massive amounts of pressure, United Flight 232 is a more extreme version of this articlehttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_Airlines_Flight_232>Despite the fatalities, the accident is considered a good example of successful crew resource management. A majority of those aboard survived; experienced test pilots in simulators were unable to reproduce a survivable landing. It has been termed \"The Impossible Landing\" as it is considered one of the most impressive landings ever performed in the history of aviationplane lost all hydraulics and had to be steered and crash landed using only the engines reply mopsi 9 hours agoparentErrol Morris made an exceptional documentary about UA232. One of the pilots just looks into the camera and tells the story. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nf33RDu_D6M reply oh_sigh 7 hours agorootparentNot just any camera - an Interrotron! reply macintux 8 hours agoparentprevThat is an amazing story, thanks for sharing it. This part leapt out at me:> Rescuers did not identify the debris that was the remains of the cockpit, with the four crew members alive inside, until 35 minutes after the crash.I can&#x27;t imagine spending a half hour waiting to be rescued, not knowing whether any of your passengers had survived. reply Sebguer 4 hours agoparentprevArticle by the same author as the submitted one on this: https:&#x2F;&#x2F;admiralcloudberg.medium.com&#x2F;fields-of-fortune-the-cr... reply Syzygies 9 hours agoprevI am addicted to a fault to Mentour Pilot&#x27;s studies of flight incidents. Again, here, he goes into greater depth:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=JSMe1wAdMdg reply MBCook 5 hours agoparentI was going to mention him! I found his channel in the last year and have loved watching his coverage, especially from the point of view of a pilot.If you like this article you’ll also likely like the show Air Disasters too (also known as Air Crash Investigations and Mayday, depending on where you are). It goes into a lot of detail based on crash reports without sensationalizing things too, though not quite as far as this article. reply tgbugs 3 hours agoprevMy internal alarm bells started going off as soon as I read about datum AA and datum M. Shouldn&#x27;t it be possible if not standard practice for the design software to issue a giant warning if you have a part that is defined by two datums that are almost but not quite the same? If they aren&#x27;t the exact same datum then something like this will inevitably happen. reply Kosirich 1 hour agoparentThere is nothing wrong with 2 datums, the issue is that during machining this is not \"a part\" but an assembly that moves. There are so many failings from my POV in the manufacturing process and verification of the part, which is summarized nicely by the following quote:. Furthermore, initial inspections at the start of the production run were supposed to verify that the manufacturing process was creating products that satisfied the “design intent,” but the initial products were checked against the manufacturing drawings, not the design drawings. reply brutusborn 2 hours agoparentprevIt’s definitely possible, but the checking system was probably built under the implicit assumption that the sources of truth for the checks (datums, dimensions) were correct.2 datums might need to be very similar but not quite the same, so checking for it might present a lot of hard to handle false positives and make the system very complex. reply pdonis 8 hours agoprevOne thing that jumped out at me was the narrow range of safe airspeeds on the landing approach--only three or four knots between stall and max speed not to overrun the runway. Quite a good piece of flying to get the plane down safely, not to mention all the other things the crew had to do. reply sundvor 6 hours agoparentYep, they were very heavy and needed to land essentially at stall speed - which they basically did seeing as the stall warning chimed in moments before touch down - in order to allow for as much space as possible to stop the plane. I took from the article that their calculations were kind of hacked together with a number of overrides, so I guess they erred on the side of caution in case any of the assumptions needed a margin of error.Amazing article. So well written. Kudos to the Qantas flight team, especially the pilot - they know their stuff for sure. And also kudos to the Airbus engineering team, that was such an epic win for redundant systems.(It was interesting to see how stopping calculations were improved as part of the post mortem, for one.) reply hugh-avherald 5 hours agorootparent> especially the pilotWorth noting that there was an unusual flight crew: 3 captains (one to check the captain&#x27;s proficiency, and another to check the checker&#x27;s proficiency) plus the first and second officers. reply Grimburger 57 minutes agorootparentPlus the off-duty one upstairs watching the tail camera on the entertainment console. Article says 140 years of combined experience between them which is more than impressive. Airbus really couldn&#x27;t have hoped for a better crew for this to eventually happen to.One of my favourite things about the A380 is that in-flight live feed from the tail, surprised more planes don&#x27;t do it. Offers visual detail of the entire topside and a lot of information that might not otherwise be available. reply Grimburger 1 hour agoprev> By specifying an landing weight in excess of the maximum, the system logic changed to apply the operational coefficient only once — for unrelated and obscure reasons — and lo and behold, when he ran the numbers this time, the computer said they could just barely land on any of the 4,000-meter runways at Singapore Changi Airport, with only 100 meters to spare. It wasn’t much, but with no better runways anywhere nearby, it would have to do.Hacking overflows in an emergency, topnotch. reply unbindableisaac 9 hours agoprevCoincidentally I just finished reading the self-authored book (\"QF32\") of the pilot&#x27;s own recount of the day. The book leads in with many interesting life experiences that led him to make so many good life-and-death choices that day. reply jandrese 9 hours agoprev> Meanwhile on the ground, events were taking an unexpected turn. On Batam Island in Indonesia, debris from the №2 engine plunged into a populated area shortly after the failure, resulting in surprise and alarm. Among the debris was a large portion of the failed IP turbine disk, which fell with such force that it cleaved straight through a building, razing a brick wall. Thankfully, no one on Batam was hurt by the debris. However, photographs of locals holding airplane wreckage in what appeared to be Qantas livery were soon posted to Twitter, where they were taken as indications that a Qantas airplane had actually crashed somewhere over Batam. Qantas engineers already knew that the plane was still flying, but they were unable to contact the crew to find out more information. And outside that bubble, the news that a Qantas A380 had possibly gone down spread so quickly that even investors reacted while the plane was still in the air. In fact, the first time Qantas’s CEO learned of the situation was when he received a call asking why the company’s stock price was dropping.Information flies so fast in the modern world. There is a classic XKCD about learning about an earthquake via Twitter moments before the ground starts shaking. reply choilive 7 hours agoparentThe crypto markets responded to Russia&#x27;s invasion of Ukraine even faster than Twitter did. That was an interesting day reply loloquwowndueo 9 hours agoparentprevOh you mean https:&#x2F;&#x2F;xkcd.com&#x2F;723&#x2F; reply quickthrower2 10 hours agoprevVery lucky they had that mastermind crew. The facts they had to keep within 3 knots of an ideal landing speed indicates how hard this was to get out of. They landed 150m from end of runway (perfect for the scenario). Amazing. reply ulfw 9 hours agoprevI was on the flight and took the picture referenced as \"A passenger took this photo in flight, showing turbine fragment exit holes in the upper surface of the wing. (ATSB)\" Forced myself on another A380 flight shortly after so I won&#x27;t lose faith in it&#x27;s engineering safety. reply gumby 8 hours agoparentWow. I was (long ago!) in an engine fire emergency landing situation and though I did take a connecting flight to get home I didn’t fly for a while afterwards. Psychologically, your choice was probably the smarter one. reply ghaff 4 hours agorootparentI&#x27;ve been in a couple situations.- The main one was that I had a flight from Vancouver to Victoria and the weather was too bad for the helicopter to fly. So we took a prop. On takeoff, some cross-wind hit the plane and we tipped over. My colleague and I who were sitting across from each other thought that was it.- The other one was my plane was reported crashed when I was visiting my parents for some holiday or other. I got panicked call on drive back from airport. reply matwood 2 hours agorootparent> On takeoff, some cross-wind hit the plane and we tipped over.I had a near tip-over coming out of a DIA years ago. DIA gets very windy. We were nearing speed to lift off and a gust of cross wind hit the plane. Looking out the window I thought for sure the wing was going to hit the ground, but in that moment the pilot seemed to shift from a standard take off to something that felt much more vertical. Once we were airborne the flight attendant came by who looked a little shaken and offered me a free drink. reply saagarjha 9 hours agoparentprevHopefully without incident that time? reply ulfw 9 hours agorootparentThankfully yes! I lived in Singapore at the time and thought... my goodness. It&#x27;s a small island. If you end up afraid of flying, what do you do!?Kudos to the Qantas crew on board as well as Captain de Crespigny and his co-pilots and two check captains. We happened to have a lot of experienced pilot power on board.A video from that time: https:&#x2F;&#x2F;youtu.be&#x2F;U8Un2boLZD8 reply yukkuri 9 hours agoparentprevGood on you! reply yukkuri 9 hours agoprevSo did he pass his check flight? ;) reply metadat 9 hours agoprevAn amazing recovery, there&#x27;s even an Air Crash Investigations episode about it:https:&#x2F;&#x2F;imdb.com&#x2F;title&#x2F;tt3234896&#x2F; reply MBCook 5 hours agoparentLove that show. Makes me wish we dealt with software even a tiny bit like that. Checklists alone for troubleshooting common customer problems would save so much hassle.But so many companies (including mine) still work on more of the “heroic” model where it’s up to individuals to just learn the hard way through helping lots of customers and noticing patterns. reply rswail 1 hour agorootparentI&#x27;m trying to introduce SRE as a practice in to my organization. We don&#x27;t have anywhere near the safety requirements of aviation or medical or power generation software, but our operations do affect thousands of people around the world.Getting people to understand that SRE is a code of practise and an overall approach has been very difficult, even with the so-called \"QA\" team, who think their job ends when the latest upgrade is deployed.We do work in public transport, and the best solution I&#x27;ve found so far, is when they say they&#x27;re \"done\", I ask them whether they are willing to stand at the railway station at peak hour and explain to passengers why they can&#x27;t get home on time (or to work).The usual result is that they go away and think about it and there is more testing done. But getting that to be a standard approach and way of thinking is very difficult, especially when product owners and project managers are only focussed on the next milestone&#x2F;payment. reply ghaff 5 hours agorootparentprevThe thing is that you end up having to be very process heavy. From an efficiency, rather than safety perspective, I had an offer from (and interviewed with--in that order) Boeing many moons ago. The thing I remember from a long-ago dinner after that interview was a guy who had spent a couple of years on some design tweak that saved some fraction of a percent on fuel consumption. That&#x27;s the sort of thing that most engineers do in aviation (where it&#x27;s perfectly appropriate). reply ghaff 10 hours agoprevWhat an extraordinarily detailed writeup. reply rvnx 5 hours agoparentIt&#x27;s a rewrite done by ChatGPT, you can see it by some of the adjectives used (that no humans would use), and some of the non-natural sentence structures, but the underlying content behind it is great. reply sammy2255 4 hours agorootparentAre you seriously accusing Admiral Cloudberg of writing articles with ChatGPT? reply jshier 4 hours agorootparentIt&#x27;s an especially ironic accusation given she&#x27;s currently dealing with YouTube channels stealing her write-ups and reading them into a video using AI. She even had a \"if you read this you&#x27;re an AI bot\" section in an article a few weeks ago. reply Agingcoder 10 hours agoprevIncredible. That’s a fault tolerant system, operated by a highly knowledgeable crew. Congrats to all those involved, from system designers to pilots and crew. reply nojs 4 hours agoprevFantastic write up, and amazing testament to the engineering in the A380. It’s extremely impressive that the pilots were able to safely land the plane with such extensive damage to so many separate systems. reply camkego 8 hours agoprevThis article highlights the dangers from fake&#x2F;illegitimate&#x2F;non-oem aircraft replacement parts that are being used to repair aircraft.https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;aerospace-defense&#x2F;engine-ma...Doesn&#x27;t make me feel comfortable about flying. reply brutusborn 2 hours agoparentIt doesn’t really specify the risk though, the parts may not be critical. I would hope regulations require independent certification for critical parts, but I’m scared to look. reply ChickeNES 1 hour agorootparentSometimes non-critical parts can cause a disaster though, as in Swissair 111, where arcing in the in-flight entertainment system led to a fire that quickly doomed the plane. reply sho_hn 10 hours agoprevA turbine disc fragment ripped through the entire plane cross-section and exited on the other side. Stunning. reply olex 9 hours agoparentI like the pragmatic engineering point of view described in the article:> For engineering purposes, disk fragments are assumed to have infinite energy at the moment of release; they will cut through any reasonable material and cannot be contained. reply cleansingfire 8 hours agorootparentAlso demonstrated by the picture in the op of the brick wall. Note that it wasn&#x27;t smashed or knocked down, but looks as if it was cut. reply V__ 8 hours agoprevI&#x27;m wondering why the tolerances for the oil pipe were so small in the first place. Why not make the pipe one or two mm thicker? reply Game_Ender 6 hours agoparentIt would add up weight wise, and it’s one of the simpler parts. Jet engines are high performance precise machines with many quickly spinning parts. If you can’t bore a tube correctly how are you going to machine a high efficiency, balanced turbofan system?That said it seems like did have a poor process where a part could be out of spec and they had no good way to check it. As they mentioned about Swiss cheese, you want as many layers as possible, and checks like that are needed. reply WalterBright 5 hours agoparentprevBecause there are a zillion important parts on the airplane, if you make each one heavier than it needs to be, the airplane will be nailed to the tarmac. reply MBCook 5 hours agorootparentThat makes sense. Here’s the question I left the article with:Why not counterbore the pipe before installation, so it’s a trivial process?Would it then not survive welding perhaps? reply peteradio 6 hours agoparentprevBecause its dead simple to machine a center and the designer did not factor in machinist&#x2F;engineer&#x2F;qa&#x2F;facility incompetence. reply SkyPuncher 5 hours agorootparentI know very basic machining, but I know that part looks almost so simple I could manufacture it.It’s very interesting that there were not wall thickness measurements. That would have solved this whole issue. reply nradov 9 hours agoprevAnd this is why fully autonomous flight control systems won&#x27;t be certified for airliners in our lifetimes. While autonomous systems are capable of taking off, navigating to a destination, and landing they are largely incapable of handling major emergencies. It&#x27;s impossible for engineers to foresee every possible failure mode and program for it. reply cesarb 8 hours agoparent> It&#x27;s impossible for engineers to foresee every possible failure mode and program for it.Playing devil&#x27;s advocate: you don&#x27;t have to. It just has to be better than a pair of experienced airplane pilots working together. Which is still very hard, and there&#x27;s still a good chance we won&#x27;t see it in our lifetimes, but at least it&#x27;s not impossible. reply lovemenot 8 hours agorootparentAlso, let&#x27;s not completely discount remote pilots reply nradov 8 hours agorootparentLet&#x27;s completely discount remote pilots. There is no technology on the horizon which would solve the network latency or sensor fidelity problems that prevent remote piloting from being adequate for handling in-flight emergencies. reply lovemenot 7 hours agorootparentI don&#x27;t claim to be knowledgeable. It&#x27;s just a hypothetical question.Surely, it depends on the nature of the emergency. As I understand it, in this Qantas example, the pilots did not need to fly the plane with real-time responses, just to make good decisions.Let&#x27;s not completely discount remote pilots, while recognising they are not a universal panacea. reply mkl 7 hours agorootparentThey needed to make a lot of real-time responses when coming in to land, as they had a very narrow window of viable speeds and limited control. reply lovemenot 7 hours agorootparentThat seems to be correct.A partial mitigation of these issues could be high bandwidth &#x2F; low latency networks just in take-off &#x2F; landing corridors? reply MBCook 5 hours agorootparentThere are plenty of times the thing that happens and the bits that save the plane are in remote areas of up high.They may still need help at landing, or by then it could be relatively normal.But if you can’t provide that level of help everywhere (including over oceans) the design of the system is choosing to lose planes in a trade off for needing fewer human pilots. reply foobazgt 7 hours agorootparentprevThere are probably hundreds of ways a plane could fail that would require constant low latency supervision by a pilot. For example, in this specific circumstance, the pilots had to manually maintain speed within a narrow range of 3-4 knots with a bunch of blown control surfaces.Let&#x27;s do completely discount remote pilots, please. replyrgmerk 6 hours agoparentprevIt’s worth pointing out that there are also plenty of airliner crashes that are attributed to pilot error. reply atemerev 1 hour agoprevGiven the sad state of the world in general, I am in awe of aviation industry because it actually works as designed, where all millions of potential points of failure are handled gracefully (and airlines are still profitable somehow).A true miracle. reply dynjo 5 hours agoprevAbsolutely astonishing and riveting read. reply RcouF1uZ4gsC 9 hours agoprevI wonder if there is any correlation with having been in the Air Force and handling these high stress civilian airline near disasters.Both this captain and the Sullenberger of thMiraclenon the Hudson were Air Force (RAF and USAF respectively). Since, you will be going against an enemy who may damage your aircraft, there is likely more training on how to assess and recover from damage as well as how to handle these types of situations. reply MBCook 5 hours agoparentFrom watching Air Disasters pilots with military training has helped out a number of times.However such pilots being very authoritarian or having bad crew resource management and not listening&#x2F;refusing to let the copilot help has caused a number of accidents (or been a contributing factor) numerous times too. reply zubairq 4 hours agoprevReally interesting read reply XorNot 9 hours agoprevThe one thing which sticks out to me is the ECAM system including a baked corrective message of \"open fuel transfer valves\" due to the imbalance.That seems like an odd message to include in an emergency action system, which by definition is only active in unexpected situations. Is there really no system to confirm if a fuel leak is happening? reply stevepeg 7 hours agoparentA320&#x2F;330&#x2F;340&#x2F;350 driver here (can&#x27;t get away from Airbus apparently).Nope, there is no system to confirm a leak apart from a camera around the tail if you&#x27;re lucky enough to have one, my previous airline had a flight where an engine leak was detected this way. Think about it, how would you design such a system? So this falls on the crew.The procedure to determine if you have a leak is pretty much the same across types: add the fuel on board (FOB) to the fuel used (FU) and make sure that the number you get is the same as what you started the flight with. If it&#x27;s less by some margin then you probably have a leak. You can confirm further by looking at tank quantities (but they take time to reduce depending on the size of the hole). If you get an engine or pylon leak then you might also see increased fuel flow on that engine. If the leak is elsewhere in the system then you might notice a smell. If you can&#x27;t work it out then the procedure (at least on Airbus types) usually involves turning an engine off to see if the leak stops (yep, really).As for the ECAM \"open fuel transfer valves\" message, I don&#x27;t know for sure on the 380 but all the other Airbus types I&#x27;ve flown have something like:.IF NO FUEL LEAKFUEL IMBALANCE....MONITORSo it doesn&#x27;t really instruct you to open the transfer valves but leads you into the fuel imbalance procedure if you think you need it. The very first line of the fuel imbalance procedure says something like \"Don&#x27;t apply this procedure if fuel leak is suspected\". reply SkyPuncher 5 hours agorootparentYou could absolutely design a system that could detect a leak. I’m guessing that it’s just not common enough, or at least catastrophically common enough, to warrant.At its simplest you measure estimated volume delivered to the engines against estimated volume remaining in the tank. Both are things that should be digitally measurable.The problem seems to be that the only case it really matters is in a catastrophic accident where such measurements are going to be broken anyways. reply stevepeg 4 hours agorootparentIt’s a good idea, some aircraft have quite complex fuel systems though so it would have to account for fuel moving between tanks.E.g. the A330 has an inner tank in each wing (which itself can be split into two compartments if damaged), an outer tank in each wing and fuel in the horizontal stabiliser which is used for CG control in the cruise. All of that plumbing can leak too. You’d be adding significant weight and complexity implementing leak detection across all that.Regardless of all of this, the aircraft is still fully controllable even with a total asymmetry (one side empty the other full) so balancing the tanks isn’t a massive priority. reply mannykannot 4 hours agorootparentprevThank you for bringing your expertise here. I was wondering if you could give some insight on something that occurred to me while reading this: at first sight, transferring fuel to the leaking tanks might seem to be a substitute for the failure of the fuel jettison system, while also doing something about the increasing lateral imbalance. reply stevepeg 4 hours agorootparentThat’s good lateral thinking :)Given that the aircraft can be landed over max landing weight (needs a maintenance inspection) and is still controllable with total imbalance I’d say that balancing just wasn’t as pressing of a concern.Also, with that much damage you never really know where else it could be leaking. Leaking fuel into critical spaces of the aircraft could be bad so turning on the fuel crossfeed might add extra issues. reply wkipling 7 hours agoparentprevFor Boeing aircraft you compare the totaliser fuel quantity with the calculated quantity based on engine fuel burn to determine a leak. reply wyldfire 10 hours agoprevRaymond Babbit would be pleased to hear the passengers landed safely. reply Cyberdog 10 hours agoprevReading articles and seeing videos about airline disasters tends to increase my faith in flying rather than making me more afraid of it. Terrorism or sabotage aside, so many failures have to compound to put a modern airliner in a truly irrecoverable state that it&#x27;s effectively impossible to happen and not worth my time to even worry about. What times we live in that we can hurtle ourselves across oceans at hundreds of miles per hour and be in substantially no more danger than we would be walking down a sidewalk in our home town (in before HN commenters reply with information about all the dangers associated with sidewalks). reply RetroTechie 9 hours agoparentThat assumes the environment the aircraft flies in, behaves predictable. Sometimes it does not.Turbulence is an obvious one. Downdrafts another. You can have a perfectly functional aircraft, but if the whole air column it&#x27;s in goes down faster than the aircraft can climb, the aircraft will go down with the air column no matter what.Reminds me of an Air Crash Investigation episode: some volcano had erupted, ash was high up in the air, air traffic control wasn&#x27;t aware of this, and iirc it didn&#x27;t show up on weather radar or similar systems (or on the planes&#x27; systems).So it looked all clear. Meanwhile the whole plane was getting ash-blasted. To the point that paint was stripped, cockpit windows went from clear to matte, and ash attached itself to engine fan blades. Obviously trouble followed...Bottom line: the environment a vehicle moves through, is always a factor. Sometimes an unpredictable, uncontrollable and&#x2F;or hazardous one. reply wkipling 7 hours agorootparentToday we have VA monitoring satellites and aircraft aren&#x27;t routed through VA. reply MBCook 5 hours agorootparentThat flight is why, IIRC. reply Cyberdog 8 hours agorootparentprevI&#x27;m not familiar with the volcano incident you referred to, but a bit of searching seems to indicate it was British Airways Flight 009 in 1982, where a 747-200 had all four engines fail due to volcanic ash… then glided safely out of the ash cloud and was able to restart three of the engines and land safely at a major airport. From a complete loss of power to all engines to on the ground with zero deaths, zero injuries. That&#x27;s exactly the kind of story I&#x27;m talking about that gives me such faith in flying! reply RetroTechie 7 hours agorootparentSounds like the one! Engine after engine going out. Without (at first) any obvious cause.> From a complete loss of power to all engines to on the ground with zero deaths, zero injuries. That&#x27;s exactly the kind of story I&#x27;m talking about that gives me such faith in flying!Understood (and agreed). But you missed my point: fate of that flight didn&#x27;t result from safety engineering. It depended entirely upon the ash-laden air it flew into, and its effect on the aircraft & its engines. No amount of systems redundancy could have made it a safe flight.So yes: flying is very safe these days. But there are limits to what safety engineering can provide. reply tempestn 5 hours agorootparent> No amount of systems redundancy could have made it a safe flight.But it did! One obvious example being the redundancy that allowed the plane to fly safely despite one of the engines not restarting.The plane encountered an entirely unpredicted situation that caused damage, but thanks to its design was still able to land safely. reply MBCook 5 hours agorootparentThey got lucky because when they descended after the engines died, the engine cooling caused small physical size changes and the caked&#x2F;burned ash just fell off the rotor bits allowing the engine to work again.To RetroTechie’s point, they got lucky. No design decision saved them. Without that they’d have been a glider until they hit 0ft and it likely would have been far worse.We’ve clearly gotten very good at flying, managing most weather conditions we’re likely to fly through, the mechanics&#x2F;maintenance of the planes, and pilot training.I’ve gained a ton of appreciation for how detailed our preparations are from watching Air Disasters. But we just can’t control everything, some danger is inherent. replyWalterBright 8 hours agoparentprevI was a nervous flyer until I worked on the Boeing 757 design and found out how all the redundancy, etc., worked. reply tekla 10 hours agoprev [–] Engineering at its finest. Lots of problems but multiple layers and layers of redundancies that prevented a major issue from becoming a bigger issue involving souls replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Qantas Flight 32, operated by an Airbus A380, suffered a major engine failure in 2010 due to a small defect in an oil pipe.",
      "The engine exploded, causing significant damage to the aircraft, but the flight crew skillfully landed the plane safely without any injuries.",
      "This incident showcased the effectiveness of aviation safety measures and emphasized the overall safety of flying. Despite the incident, the A380 model remained in service until 2021, even though it was not widely favored by many airlines."
    ],
    "commentSummary": [
      "The discussion covers a range of topics related to aviation safety and engineering, highlighting the robustness and reliability of the aviation industry.",
      "It emphasizes the ability to trace and identify faulty parts, regulation and testing of autopilot code, and the importance of responding to mistakes for improvement.",
      "The conversation compares aviation and software industries in terms of safety focus and touches on incidents, concerns, and preparedness related to airline safety and maintenance."
    ],
    "points": 360,
    "commentCount": 144,
    "retryCount": 0,
    "time": 1702161035
  },
  {
    "id": 38581852,
    "title": "Murder Engine: A Promising Pixel Art ECS Game Engine in C#",
    "originLink": "https://github.com/isadorasophia/murder",
    "originBody": "Welcome to Murder Engine! This is the source for Murder Engine, a pixel art ECS game engine built on top of MonoGame. 🚧👷 Warning Proceed at your own risk. This is an in-development engine, which is another way of saying that it will change quite a lot. We do our best to keep release branches stable, but expect a lot of breaking changes and things that are not perfect (yet!). How to build it? If you're good at just digging examples and figuring things out, I recommend starting out with our game jam project or the Hello World project. These projects show what to expect from the Murder architecture and how to create a world, entities and components, which ECS is all about. ...I realize this is quite redundant because the Hello World references this repository as a documentation source, but hang with me. This is what the architecture looks like: └── root └── resources └── src ├── game │ ├── bin (final game) │ ├── packed │ └── resources └── game.editor ├── bin (game editor) └── resources You may notice that there is no external editor.exe, only your own project. This is so you can have full control of your project! Very similar of what you expect developing a MonoGame project, for example. The idea of a separate project for the editor is that editor code never touches your beautiful and efficient game code, and you can do whatever you want on the editor side. There is no nuget package for Murder yet, so the recommended way is to keep a git submodule to reference in your .csproj, see example. For more information on how the ECS applies to the engine, I recommend checking out the documentation for Bang, the framework that Murder uses. Requirements We support developing (which means, running the editor) on Linux, MacOS, Windows and even SteamDeck. All you really need is .NET 8 SDK installed. The game obviously also ships to all these architectures. Console support is still on progress. Contributing This is still super early, but feel free to contact me or saint11 if you have any suggestions. I am very interested in people trying it out and any feedback you may have! ✨ Editor examples",
    "commentLink": "https://news.ycombinator.com/item?id=38581852",
    "commentBody": "Murder is a pixel art ECS game engine in C#Hacker NewspastloginMurder is a pixel art ECS game engine in C# (github.com/isadorasophia) 288 points by ibobev 20 hours ago| hidepastfavorite101 comments mysterydip 18 hours agoWhen I saw saint11&#x27;s name with it, I knew it would be good. Their pixel art tutorials are so well presented: http:&#x2F;&#x2F;saint11.org&#x2F;blog&#x2F;pixel-art-tutorials&#x2F; reply im_down_w_otp 15 hours agoparentI’ve never seen this before, but having perused through it for a bit I’m convinced this is the absolute best blog on the entire internet. reply chii 7 hours agorootparentOne reason i think these tutorials are great is because the writing is concise and to the point. No extraneous words.It follows the style of writing outlined in https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style almost to a T: Vigorous writing is concise. A sentence should contain no unnecessary words, a paragraph no unnecessary sentences, for the same reason that a drawing should have no unnecessary lines and a machine no unnecessary parts. This requires not that the writer make all his sentences short, or that he avoid all detail and treat his subjects only in outline, but that he make every word tell. — \"Elementary Principles of Composition\", The Elements of Style reply runevault 17 hours agoparentprevOh wow I didn&#x27;t realize this was the same guy. I&#x27;ve seen this tutorial before and the way he lays everything out is fantastic. reply umvi 7 hours agoparentprevI think saint11 is the guy who did the art for the game Celeste reply SamPatt 5 hours agoparentprevThey worked on Celeste and Towerfall, both have excellent pixel art. Very talented. reply ilkke 2 hours agorootparentI know no disrespect was meant, but calling an artist talented disregards the hard work that went into developing their skills. Unless you are talking about someone&#x27;s unrealised potential. reply bigtunacan 3 hours agoparentprevThis is the pixel art tutorials I&#x27;ve been looking for for years! Thanks for your comment! reply skitter 16 hours agoprevNew game engines and ECS frameworks are cool to see. Taking a look at the ECS part, Bang, here&#x27;s an example of a component abridged&#x2F;adapted from their Ludum Dare entry: internal readonly struct CarComponent : IComponent { public readonly float Speed = 100f; [Slider(1,20f)] public readonly float Mass = 1; public CarComponent() {} }and of a system: [Filter(typeof(CarComponent), typeof(AgentImpulseComponent))] [Filter(ContextAccessorFilter.NoneOf, typeof(DisableAgentComponent), typeof(CarEngineStoppedComponent) )] internal class CarMoverSystem : IFixedUpdateSystem { public void FixedUpdate(Context context) { foreach (var e in context.Entities) { var car = e.GetComponent();Vector2 startVelocity = e.TryGetVelocity()?.Velocity ?? Vector2.Zero; var result = DoSomeCalculations(car, startVelocity); e.RemoveFriction(); e.SetVelocity(result); } } }Looks a bit like DOTS (but I haven&#x27;t really tried that one either). A system is a class, and which interface it implements determines when it runs. Haven&#x27;t seen yet where systems are get added to the game &#x2F; how systems of the same kind get ordered. I&#x27;m also curious how a system that does multiple different querries (e.g. one for cars and one for obstacles) looks like.Bang seems to use source code generators – unlike the generic GetComponent above, TryGetVelocity, RemoveFriction and SetVelocity seem to be generated based on the existence of the Velocity and Friction components. I&#x27;m not sure why that is, maybe to cache the component id?This isn&#x27;t an archetype-based framework, instead each entity stores a dictionary of component id => component and each system tracks what entities match (also, each entity stores hooks for e.g. when a component gets added, which is used update which systems know about this entity). I don&#x27;t know how good that&#x27;s for performance, but for plenty of games performance isn&#x27;t as important as ease of development.Also looks like changes are applied immediately. Does this mean that if a system add&#x2F;remove a component to an entity that affects whether the entity matches the systems filter, it depends on the entity id whether the system processes the entity the same tick? reply cowboyscott 16 hours agoprevItch page (with downloads) of a jam game made with the framework: https:&#x2F;&#x2F;saint11.itch.io&#x2F;neo-city-expressedit: Impressive for a 72 hour jam game. Great art, writing, and mechanically interesting in a way that I wasn&#x27;t expecting. reply magicmicah85 16 hours agoprevVery nice. The editor is very stylized, I like it. I’ve always liked monogame because it’s performant and cross platform, though I’ve never made huge games with it, just a demo here and there when I get the itch. reply tmountain 17 hours agoprevThis looks great! I’m curious if C# game dev has issues with GC pauses. reply bob1029 15 hours agoparentI&#x27;ve had strong success with trivial object management & explicitly invoking GC on a delay that is some small multiple of the simulation delay. The sweet spot seems to depend on scene content and style of gameplay (how the scene objects are mutated). For Q3A-style scenes and gameplay, it is extremely robust. Very few scene elements change tick by tick, so GC pauses are mostly irrelevant.More specifically with .NET6+, I am seeing GC pauses measured in the 1~5ms range in my DIY engines when I strategically call GC.Collect() on a rapidly-recurring basis. Another tweak I made was to disable concurrent&#x2F;server&#x2F;background GC in the project config. Foreground+workstation GC appears to provide the lowest jitter in this arrangement. My engine&#x27;s main loop operates on batches of events pulled from a ring buffer abstraction, and if one of those events just so happens to be a scheduled GC, then I deal with it right there in-line on the same thread. I do not attempt to defer it to a GC thread or some other weirdness.The only strategic options seem to be to either explicitly manage all the memory 100%, or take out the trash as often as possible. You could also entertain the cruise missile GC strategy, but Microsoft has made it nearly impossible to completely disable GC in latest .NET without employing black magic low level DLL hackery. I can definitely see a situation where you don&#x27;t care about GC because you can just recycle the process between business events, rounds of gameplay, etc. Process.Exit() is a viable GC technique in some domains. reply neonsunset 15 hours agorootparentCruise missiles can fly for a long time! Now, ballistic ones... Either way, almost spilled the coffee over this haha. reply zengid 16 hours agoparentprevYes and here is a really great talk from Miguel de Icaza about some of the history of adding C# to game engines, and why he&#x27;s excited about using Swift in Godot because he claims that Swift&#x27;s reference counting avoids the issues of GC pauses.https:&#x2F;&#x2F;youtu.be&#x2F;tzt36EGKEZo?si=WNxwcTPGFbJABKez reply cyber_kinetist 3 hours agorootparentNote that GDScript (the primary scripting language for Godot) also uses reference counting for its memory management, so it doesn&#x27;t have the GC pause issues.This isn&#x27;t just a language-specific feature and is actually one of the core design decisions made in the C++ engine. Almost every object in Godot inherits the RefCounted base class - as a consequence even in C# scripting mode Godot-specific objects generally have reference counting semantics (and therefore also provides the WeakRef type to deal with reference cycles yourself.) reply pjmlp 12 hours agorootparentprevBased on his experience with Mono, less so with .NET proper.Also given the state of Swift outside Apple ecosystem, I guess he only plans to target developers on their platforms. reply TillE 9 hours agorootparentDe Icaza suggests that the GC hasn&#x27;t improved sufficiently even in the modern .NET era, and maybe that&#x27;s true in certain cases. But in practice, dozens of big-budget 3D games have been made with Unity, using a janky old Mono runtime that performs far worse than .NET 8.Swift is a really interesting language, and Apple does distribute official toolchain binaries for Linux and Windows. But yeah it&#x27;s still a bit of an awkward choice if you&#x27;re not using Xcode, hopefully that improves. reply pjmlp 2 hours agorootparentC# is now following the same adoption patterns as C and Pascal dialects when games were in Assembly, C++ when games were mostly C.CAPCOM has their own engine based on a fork from .NET Core, used it on Devil May Cry for the PlayStation 5.Good luck getting similar adoption for Swift outside Apple platforms, specially game consoles.If not C# alongside C++, studios would rather use Rust not Swift, e.g. Embark and Activision.Metal has now C++ bindings, as Apple had to cede Objective-C and Swift bindings weren&#x27;t being welcomed by major studios.I like Swift, however I don&#x27;t see SwiftGodot going anywhere outside iDevices.That isn&#x27;t bad if that is the goal though, plenty of companies are doing quite well being single platform. reply neonsunset 8 hours agorootparentprevThere is no such thing as a free lunch :)Modern GC implementations offer an important advantage - very cheap allocations and batched deallocations which allow to sustain high allocation traffic that goes through the heap.This comes at a cost of non-deterministic memory usage and object de-allocation. Further tradeoff is made between GC pause times, allocation throttling (Go) and even higher memory footprint (ZGC).My knowledge on the exact overhead of Swift&#x27;s reference counting is very limited but there&#x27;s a good chance it comes with significant upfront cost that you don&#x27;t have to pay in languages with GC or with compile-time-defined allocation semantics (Rust and C++ RAII). There&#x27;s a reason why Apple invested in atomics being as cheap[0] as they are on their ARM64 cores.Overall, every time I find Swift benchmark numbers on the internet, they turn out to be far[1][2] from near-Rust performance despite being a language built on top of LLVM.[0] https:&#x2F;&#x2F;dougallj.github.io&#x2F;applecpu&#x2F;firestorm-int.html (e.g. CAS, CASAL, DMB)[1] https:&#x2F;&#x2F;github.com&#x2F;ixy-languages&#x2F;ixy-languages[2] https:&#x2F;&#x2F;github.com&#x2F;jinyus&#x2F;related_post_gen#multicore-results reply neonsunset 16 hours agoparentprevGC issues pretty much exist in Unity land only. Other game engines which use vanilla .NET like Stride work without a hitch. reply runevault 16 hours agorootparentI wonder how much of the extra issues Unity has is because it is a very old version of Mono, since more modern versions of .NET have become so much more performant (especially Core 3.1 into 5+). I was sad when .NET 8 came out too late for Godot to fit in the update for Godot 4.2, so I believe they intend to make the update for 4.3. reply DannyWebbie 1 hour agorootparentUnity is leaving quite a bit on the table by not being on a modern version of .NET. Unity&#x27;s C++ side seems to have (or had) assumptions about the garbage collection. Progress and challenges on .NET in Unity can be seen in this frequently updated forum thread https:&#x2F;&#x2F;forum.unity.com&#x2F;threads&#x2F;unity-future-net-development...Unity&#x27;s long term plan appears to become more tightly integrated with .NET and to avoid maintaining their own .NET stuff. reply VHRanger 16 hours agorootparentprevDoes the C# GC have guarantees about when it will&#x2F;won&#x27;t run?Dlangs GC for instance guarantee that it will only run on allocation of new memory so it&#x27;s possible to architect the game to avoid meaningful pauses reply neonsunset 16 hours agorootparentIn .NET, GC is triggered when a user thread runs out of memory in an allocation budget and needs more, similar to what you described [0].Generally speaking, indefinitely preventing GC from running is not possible (you always end up putting some data on the heap) therefore an optimal strategy is similar to any other language - limiting allocations and reusing memory through object and array pooling. This will ensure that GC pauses are as infrequent and as short as possible. It&#x27;s important to note that if there is sufficient allocation budget - the GC will not run.This way, in a well written code the GC may only ever trigger every few hundred frames and only take a millisecond to run. In fact, OSU! has been able to get consistently good frame times even back on .NET Framework.[0] https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;blob&#x2F;main&#x2F;docs&#x2F;design&#x2F;core...[1] https:&#x2F;&#x2F;maoni0.medium.com&#x2F;dynamically-adapting-to-applicatio... reply kirankp89 5 hours agoparentprevMy experience with Unity on consoles is that it is very much an issue but can be avoided with some careful architecture choices very early on in development. If you are not careful about allocations, the reserved managed heap size grows and GC pauses quickly deteriorate the experience. There’s also no way to reclaim memory and very soon you’ll have a giant C# heap with not enough memory for native code in engine to load textures etc. This is very hard to recover from, hence to need to be vigilant from the start. reply MattRix 5 hours agorootparentThis is true but it’s worth noting it’s because Unity used Mono’s garbage collector which was, well… garbage. reply gentleman11 16 hours agoparentprevYes. You have to allocate at the start and use object pooling, in unity and even unreal (unreal has garbage collection too) reply unclad5968 16 hours agoparentprevYou can write C# to avoid allocations like most other languages reply Thaxll 8 hours agoparentprevGC pauses are one thing but you have to keep in mind thata large part of your cpu time is going to be garbage collection. reply TheGrkIntrprtr 14 hours agoprevsaint11 mentions on his about page: “Murder Engine: 2D Pixel art C# ECS Game Engine made by Isa! I usually help on the render and physics side of it.”Isa: https:&#x2F;&#x2F;isadorasophia.com&#x2F;projects&#x2F; reply nopetrides 9 hours agoprevI&#x27;ve a bit of ECS experience in Unity, and I found ECS in Murder much easier. The devs have done an awesome job. I made a small arcade game project with Murder https:&#x2F;&#x2F;nopetrides.itch.io&#x2F;bombs-away that is available to play reply skitter 7 hours agoparentCould you elaborate on the differences? reply ctoth 17 hours agoprevUnrelated to the game engine, but I just love how someone unscrupulous could say \"the people on that hacker website are discussing murder.\"I&#x27;ve been thinking a lot recently about what a dedicated adversary could do with totally innocuous material like this. reply Cpoll 16 hours agoparentSeems a bit far-fetched, but then again people have taken The Onion articles at face value.Still, with something this easily debunked, is there much difference between \"the people ... discussing murder\" and an outright lie? reply bear141 10 hours agoparentprevThinking this way, but in the reverse, is the only to consume mass media news. It’s incredible how biased and ridiculous everything is anymore. reply abetusk 6 hours agoprevEntity Component System [0].[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Entity_component_system reply sufficer 18 hours agoprevWhat is ECS? reply ch71r22 18 hours agoparentGuessing Entity Component System - a common game engine architecture reply 6581 18 hours agoparentprevEntity component system. reply lstodd 17 hours agorootparentAnd here I was thinking it&#x27;s about Amiga 600 reply mortenjorck 16 hours agorootparentThe example game graphics that appear to plausibly fit in a 32-color palette did not help my confusion! reply vardump 16 hours agorootparentprevSame.I thought pixel graphics within limitations of Amiga 600&#x2F;3000 Enhanced ChipSet. reply gentleman11 16 hours agoparentprevA trendy high performance architecture. Unity is trying to popularize it a lot lately reply capableweb 14 hours agorootparentNot just about performance, but about getting a very well decoupled code base as well when using ECS. reply freecodyx 14 hours agoprevC sharp is pleasure to read reply owenpalmer 14 hours agoprevWay to go team, you&#x27;re killing it reply pjmlp 19 hours agoprevLooks great! reply gentleman11 16 hours agoprevWhat is monogame ? reply haunter 16 hours agoparenthttps:&#x2F;&#x2F;monogame.net&#x2F; reply gentleman11 14 hours agorootparentBut is it widely used? Stable? Popular? Really nice to use? Actively developed? Is it infrastructure that other higher level tools build on, or is it like unity? reply actuallyalys 13 hours agorootparentIt’s a reimplementation of Microsoft‘s popular XNA framework that was used for a number of successful games. Monogame itself has been around for a while and my impression is that it’s a mature and stable project. I would put it in between libraries like SDL that are often used as infrastructure and full engines like Unity. reply misschresser 13 hours agorootparentprevCeleste, Stardew Valley, Bastion are some famous games built on it. reply starkparker 13 hours agorootparentprevYes. reply dathinab 18 hours agoprevCreative names are all fun of fine but this- is not easy to google- is quite tasteless, less so if murder is mainly something you see on tv, but for some people murder is sadly much less of an fictional rare thingit it would be a game, story etc. which has that name and covers that topic it would be fine but naming something pretty unrelated to that murder is just quite a bit of tasteless and unnecessary edge; if it had a flock of crows as a log it would at least be a funny joke reply DeIlliad 17 hours agoparent> - is not easy to googleNobody is googling \"Murder\" looking for a game engine and being disappointed that they can&#x27;t find it. If you search \"Murder Engine\" this is the first thing that pops up.> - is quite tasteless, less so if murder is mainly something you see on tv, but for some people murder is sadly much less of an fictional rare thingI have an immediate family member that was brutally murdered. I also have no problem with the name of the engine. Of the things to take issue with, this seems silly. You would hate LOVE2D which has libraries famously named ANAL and LUBE. reply dathinab 16 hours agorootparentTo clarify I find it tasteless and edge, i.e. a bad choice. This doesn&#x27;t mean I have a problem with it, nor does it mean I&#x27;m offended by it or think others would be offended by it or hate it or anything like that.I also am not sure why you think I would find LOVE2D tasteless. The name has a clear connection to what it names, it paints a clear and positive picture and has a slightly less obvious joke in it onto which they then double down by how they name some of their libraries. That has style and taste.But murder is lacking all of that, or at least it&#x27;s too non obvious. This disconnect between the name and what it is&#x2F;the picture it paints is why I called it tasteless and edgy. It feels like there was either a lack of ideas or it wants to edge on and provoke but the picture this paints isn&#x27;t beneficial&#x2F;good for a 2d game engine in any way as far as I can tell. Even comes with a (small) to cause harm and require a renaming later one. reply alex_lav 13 hours agorootparent> To clarify I find it tasteless and edge, i.e. a bad choice. This doesn&#x27;t mean I have a problem with it, nor does it mean I&#x27;m offended by it or think others would be offended by it or hate it or anything like that.If it doesn&#x27;t bother you and you don&#x27;t think it will bother others, how is it tasteless?> The name has a clear connection to what it namesSo Murder Engine is fine then.The desire to clutch one&#x27;s pearls in disgust over any little thing is showing up a lot in this thread, I think. reply dathinab 12 hours agorootparent> one&#x27;s pearls in disgust over any little thing is showing up a lot in this thread,not really, but I guess arguing with you about it is pointless as you are either ignoring or not understanding the points I am making and instead try to exaggerate things by implying that finding something tastless means much more then it does reply alex_lav 12 hours agorootparentIf you&#x27;re unable to articulate why something is tasteless beyond \"because I think it is\", it sounds like you&#x27;re sort of just making things up.Which is fine. Clutch those pearls. But maybe examine your behavior as well? reply dathinab 11 hours agorootparentexcept that I did explain, but you just pretend that part doesn&#x27;t existand somehow after I did you started becomming all provocative and manipulative in how you phrased sentences so that it seems I sayed&#x2F;mean&#x2F;think things I do noso idk. by I don&#x27;t think I&#x27;m the person with the problem here reply DeIlliad 10 hours agorootparentprevYou&#x27;re being weirdly aggressive about this. I think they explained themselves pretty well. I don&#x27;t agree with them at all but they have said how they felt and why. reply alex_lav 10 hours agorootparentI asked a clarifying question and then made an assertion about a behavior. I personally wouldn’t call that “aggressive”, but to each their own I suppose. replynkozyra 18 hours agoparentprev> is not easy to googleI guess one could have said the same about \"unity\" or \"unreal\" or even \"Godot\" at one point. reply dathinab 18 hours agorootparentgodot is a pretty unique name, tho reply esrauch 16 hours agorootparentBefore the engine I&#x27;m sure all ten search results would have been about Waiting for Godot though. reply robertlagrant 17 hours agorootparentprevApparently hard to search for. reply TrueGeek 18 hours agorootparentprev“.net” reply morkalork 18 hours agorootparentSounds like the title of a 90s horror b-movie \"Murder.net\" reply DonHopkins 17 hours agorootparentprevWhich is at least easier to google for than Microsoft COM. reply osigurdson 12 hours agoparentprevMurder murder murder murder. Sorry, you aren&#x27;t the boss of us. reply dathinab 11 hours agorootparentyep, I&#x27;m also never said anything beyond me not liking it in a specific way. Through given how the internet tends to be I could have been more clear that I&#x27;m not offended, neither think it will offend other, neither hate the name etc. etc. people just love to jump to conclusions.It&#x27;s just that it looks like a very promising project and bad names can easily come back and hunt a project iff it has become much larger and more successful. So it having in my opinion a bad name felt like something which isn&#x27;t irrelevant. reply usrnm 18 hours agoparentprevI wonder what you think of other stupid names, like \"parsley\", \"cucumber\" or \"apple\"? reply tomalaci 17 hours agoparentprevI think that the name is too generic and popular. You see \"murder\", the word, in most news outlets, vast majority of movies&#x2F;games&#x2F;etc. - any media.Sure, you have \"Unity\", \"Unreal\", \"Godot\", \".NET\" and etc. but I would argue that they are distinct and unique because they have some heavy-weight organizations and popularity behind them. I also think that they are not on the same level of generic use as \"murder\".This engine&#x27;s name, however, will have to compete with the generic \"murder\" that is already used in various different contexts. Surprisingly, you can still find it as top result if you search \"murder engine\" so they got that going for them.Still, would of preferred if it was maybe some variation of \"murder\" word if they want to stick with that. reply ilkke 2 hours agorootparentAgree it&#x27;s terrible SEO but eventually \"Murder engine\" might be decent enough. At least it&#x27;s edgy or lol or punk or or whatever box it ticked. The beauty of having the freedom to do whatever and see what it does for you. reply Mystery-Machine 16 hours agoparentprevThis is why we can&#x27;t have nice things. reply DonHopkins 17 hours agoparentprevAt least it&#x27;s better than \"GIMP\". ;) reply bdhcuidbebe 16 hours agorootparentNobody complained about git yet reply DonHopkins 15 hours agorootparentAnd doesn&#x27;t a \"debugger\" imply the existence of a \"bugger\"? reply furyofantares 12 hours agorootparentThat&#x27;s the programmer reply honeybadger1 16 hours agoparentprevcome on reply blondin 14 hours agoparentprevfully agree. this is a very tasteless name. i wouldn&#x27;t even go as far as the easy to google argument with this. reply karmakaze 17 hours agoparentprevWhen I read the title, I was thinking it was like saying \"Hell is...\" and wondering what would be so bad about making an ECS game engine in C#. reply DiggyJohnson 16 hours agoprevVery cool project.Man I hate to make this sort of comment, but is this a good name for this engine? I’d hate for a demo to get pushed down because a YouTube &#x2F; Google algorithm doesn’t like it. reply dazaidesu 16 hours agoparentehhh its a cute name playing off of the \"murder\" of crows theme, I like it, makes the theme feel cohesive. Also I don&#x27;t get the focus on making sure you have the perfect SEO for every side project, seems like a good way to not get anything done. reply thuuuomas 16 hours agoparentprevSounds like a good reason to promote the merits of your own project, instead of the tools you use. reply pvg 16 hours agoparentprevI hate to make this sort of commentEasier to just not make it, especially since there&#x27;s a (equally-better-never-made) subthread about it. reply PcChip 11 hours agoparentprevI feel like I’m the only one here that actually agrees with you reply Rexxar 7 hours agoparentprevIf they change name, I vote for \"Mulder\". reply skrebbel 18 hours agoprevWoa, how the hell can C# run on an ECS? It has 2MB of RAM reply clintfred 16 hours agoparentNot sure if I&#x27;m supposed to laugh, groan, or shake my head. Nicely played, sir! reply skrebbel 16 hours agorootparentI like the occasional HN troll as much as the next guy, but I’m afraid that it wasn’t a joke. The page has screenshots with big fat pixels and says it’s an ECS game engine so I assumed it was, well, a game engine for the ECS. I since learned that ECS has another meaning that I wasn’t yet familiar with.I might’ve realized this wasn’t for the Amiga if I had read the page (or looked at the screenshots) better though. reply maxvu 15 hours agorootparentI think ECS here is \"entity-component system\", a design pattern that seems related to data-oriented design. replyxmichael999 18 hours agoprevwow! reply Xeamek 15 hours agoprev [–] Since engine is targetting pixel art, isn&#x27;t ECS a bit of an overkill...?And yes, technically artstyle has nothing to do with game architecture.But in practice, most games of this style are pretty small, and thus don&#x27;t really have any real performance requirements, so ecs&#x27;ing everything is overengineering compared to oop-style, coupled architecture, no?Also related: https:&#x2F;&#x2F;youtu.be&#x2F;JxI3Eu5DPwE reply ElectricalUnion 3 hours agoparent> But in practice, most games of this style are pretty small, and thus don&#x27;t really have any real performance requirements, so ecs&#x27;ing everything is overengineering compared to oop-style, coupled architecture, no?I would call out that \"performance requirements\" those days aren&#x27;t just \"it runs smooth enough for me\". It&#x27;s also about \"it doesn&#x27;t waste all my game device battery\". I appreciate when you can run games for 7 hours instead of 2 hours on a mobile device.More that pure CPU&#x2F;GPU use, the main battery life villain for your average software is horrible memory access patterns.Doing logic or math (even including FP math) is basically energy free compared to fetching data from DRAM or SRAM. reply skitter 15 hours agoparentprevOne of the commonly mentioned performance advantages of ECSs is the structure of arrays style, which Murder isn&#x27;t using, so I&#x27;m guessing that they&#x27;re using ECS less for performance reasons and more because they favor the programming style. reply TillE 15 hours agoparentprevHugely popular little indie game Vampire Survivors, for example, requires some thoughtful optimization to have a zillion objects on screen without lagging to death. ECS isn&#x27;t the only answer, but it is a valid one. reply ElectricalUnion 4 hours agorootparentI think Factorio is a better example; items still exist when you don&#x27;t see them on the map, and assuming you have a somewhat optimized base the performance is very acceptable until you are around 383k items&#x2F;s being created and destroyed (50kSPM in the in-game parlance). reply Xeamek 52 minutes agorootparent>Items still exist when you don&#x27;t see themI was always wondering about that:Do they have to? Couldn&#x27;t you come up with some chunking based system where the game only monitors the &#x27;inputs&#x27; for given area and as long as those are stable, skip simulating entire chunk and only generate the output? reply mattgreenrocks 15 hours agoparentprev [–] I find ECS easier to think about and use. It’s effectively controlled mutation. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Murder Engine is an in-development pixel art ECS game engine based on MonoGame.",
      "The engine follows the Murder architecture and offers examples for world, entity, and component creation.",
      "Murder Engine supports development on Linux, macOS, Windows, and SteamDeck, with .NET 8 SDK installed."
    ],
    "commentSummary": [
      "This post introduces \"Murder,\" a pixel art ECS game engine written in C#.",
      "Users in the comments praise tutorials on pixel art by saint11 and their work on the game Celeste.",
      "The post includes code examples of components and systems in the ECS framework, sparking discussions on garbage collection strategies, the adoption of C# in game development, and the use of the Monogame project."
    ],
    "points": 288,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1702129372
  },
  {
    "id": 38583399,
    "title": "Empowering Developers: Creating Apps for Linux to Drive Innovation and Growth",
    "originLink": "https://makealinux.app",
    "originBody": "Make a Linux App Make Apps for Linux Desktop and mobile Linux users have a healthy appetite for new software. Linux app stores and repositories lack applications compared to their proprietary counterparts. Technical enthusiasts are encouraged to direct their passion and creativity towards creating fresh apps for Linux users. Too often they fall into the trap of creating more Linux distributions. We don’t need more Linux distributions. Stop making Linux distributions, make applications instead. Why create more applications Scratch an Itch Ever had an idea for an application you personally need? You may find others have a similar desire for your application idea. Scratch that itch. Broaden the ecosystem New applications can inspire new developers on Linux. Building applications in the open allows developers even newer than yourself to learn and get started. Help build the next Linux app generation. Be creative Developing applications is a naturally creative endeavour. The sense of fulfilment gained when completing a project can be very rewarding. Exercise that half of your brain. Collaborate Building applications fosters communities. Linux communities often want to help developers succeed. Make something people want, and build a group of fans and contributors around it. Learn new skills Developing applications is a sought-after skill. There are many free training resources to help you learn to develop software. Level up your résumé! Earn a wage Build popular paid applications and services. It’s a myth that Linux users don’t support developers financially. Use this as an opportunity to create a new source of income for yourself. Target all the Linux distributions Unlike other platforms, Linux is a very diverse target. There are hundreds of Linux distributions, some more popular than others. Once published though, applications can generally work everywhere. There are well documented software packaging and distribution systems which enable developers to get their applications into the hands of users. Each developer framework and Linux distribution will have their own recommended route to users. When you’re ready to share your creation, the development documentation will signpost their suggested packaging guides. Where to start GNOME The GNOME project builds the popular GNOME Shell desktop, and enables development based around Gjs and Gtk. Popular programming languages may be used with Gtk, including Python, C, C++, Rust, and even Javascript. GNOME Developer Center KDE Frameworks KDE produces the widely-used Plasma desktop and the tools and frameworks to create applications. The KDE Frameworks have enabled the development of many diverse desktop applications. KDE Frameworks primarily leverage the Qt toolkit and C++ programming language. KDE Frameworks Getting Started elementary OS elementary OS is a fast, open, and privacy-respecting replacement for Windows and macOS. The developers have built a desktop and ecosystem in which developers build applications. Their developer guide recommends Vala and Gtk for application development. elementary OS Developer Guide Electron Electron enables developers to build cross-platform desktop apps with JavaScript, HTML, and CSS. Electron developers can leverage the vast library of node modules to build their own applications on web technologies. Electron Documentation Ubuntu Touch Ubuntu Touch is an open source operating system designed to run on a variety of devices from phones to tablets and PCs. Native Ubuntu Touch applications are made using QML or HTML with their behavior defined in JavaScript, C++, Python, Rust or Go. Ubuntu Touch Documentation Developer opinion We need to ensure a thriving app ecosystem to bring Linux to the masses. Our dream of an open desktop, accessible to all can only be achieved by enabling everyone to develop for Linux. Neil McGovern Executive Director of the GNOME Foundation To make Linux the operating system we all want, we need great apps. Join us, you will find the tools to create everything you ever imagined! Aleix Pol President of the KDE e.V. and hacker There’s a unique opportunity with desktop Linux to not only build great apps, but to help shape platform APIs and influence the overall direction of the desktop you’re publishing on. Daniel Foré Founder, elementary Working on Linux apps is a completely different experience from developing for a closed ecosystem. Though we’re technically competitors, in the end, we’re all collaborating on the same bigger vision. Jan Sprinz Member of the Board of the UBports Foundation Sharing Your Creation AppCenter Publish and monetize your app on AppCenter, the open, pay-what-you-want app store and build service for indie developers. Publish without disrupting your workflow—the AppCenter Dashboard integrates with GitHub for releases and issue tracking. AppCenter Dashboard AppImage Distribute your desktop Linux application in the AppImage format and win users running all common Linux distributions. Package once and run everywhere. Reach users on all major desktop distributions. AppImage Packaging Guide Flatpak Flatpak is a framework for distributing desktop applications on Linux. It has been created by developers who have a long history of working on the Linux desktop, and is run as an independent open source project. Flatpak Documentation Open Build Service The openSUSE Build Service is the public instance of the Open Build Service (OBS) used for development of the openSUSE distribution and to offer packages from same source for Fedora, Debian, Ubuntu, SUSE Linux Enterprise and other distributions. openSUSE Build Service Help Snapcraft Snapcraft is a powerful and easy to use command line tool for building snaps. Snaps are app packages for desktop, cloud and IoT that are easy to install, secure, cross-platform and dependency-free. Snapcraft Documentation Make a Linux App GitHub This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.",
    "commentLink": "https://news.ycombinator.com/item?id=38583399",
    "commentBody": "Make Apps for LinuxHacker NewspastloginMake Apps for Linux (makealinux.app) 267 points by jay-barronville 17 hours ago| hidepastfavorite313 comments zer0zzz 14 hours agoI think the premise is wrong when there still doesn’t exist a core set of frameworks that are abi stable on Linux. On competing platforms there are way more frameworks out of the box (CoreImage, CoreAudio, CodeML, SceneKit, AppKit, etc) and they don’t break as often.I know in Linux they have fun things like snap and flatpak but it is really solving the problem using a bit of infrastructure and package management instead of doing it in the frameworks and programming languages themselves (which are what you are asking people to write apps in). reply eternityforest 8 hours agoparentThe Linux enthusiast community actively fights against anything like this because they want everything to be modular and made to fit specific applications.Linux does have a de facto set of standards, they&#x27;re not quite as stable because they change them and deprecate old stuff, but it&#x27;s better than it looks, and with Snaps you can at least partially solve the issue.But people choose distros that don&#x27;t have those standards, and then you lose half your potential users if you don&#x27;t support all the niche configurations. reply xkekjrktllss 8 hours agorootparentThe so-called \"Linux enthusiast community\" is better described as the Linux corporate enterprise community. Understanding this makes your comment make a lot more sense. The \"specific applications\" are in fact merely the priorities of the giant corporations who fund the overwhelming majority of Linux development for the purpose of accumulating profit. reply dralley 6 hours agorootparentThat&#x27;s certainly not my experience. Practically every rant about systemd includes the idea that evil corporations are trying to force it on everyone rather than letting them use some random login daemon whose last commit was in 2008.Corporate interests are generally biased in favor of avoiding hyper-specific modifications that mess with their own economies of development scaling, not seeking them out. reply eternityforest 7 hours agorootparentprevThe corporate enterprise community is who appears to create most of the attempts at user friendly, one size fits all, stable standards, because.... that&#x27;s what seems to sell, and what saves development budgets not having to support lots of different OSes, as Windows has shown.Many of the non corporate hobbyists are fine with everything needing tweaking and maintenance, they chose Linux specifically because they want to tweak stuff. reply xkekjrktllss 7 hours agorootparentNot sure what point you&#x27;re trying to make but the \"non corporate hobbyists\" are ineffective to the point of irrelevance when it comes to Linux core development. Everything they do is downstream from the influence of giant corporations. reply abhinavk 13 hours agoparentprevI had read somewhere that Win32 (via Wine or Proton) is the most stable target for Linux right now. reply FirmwareBurner 13 hours agorootparent>Win32 (via Wine or Proton) is the most stable target for Linux right nowTangential, Winamp 2.xx from the &#x27;90s runs and plays MP3s just fine on Windows 11 today. There are better apps for that today, but I still use it because nostalgia really whips the llama&#x27;s ass.Pretty wild that the same thing is not the norm in other OSs.Even wilder is that I still have my installed copy of Unreal Tournament 99 from my childhood PC copied over to my current Win 11 machine, and guess what, it just works out of the box, 3D graphics, sound, everything. That&#x27;s nearly 25 years of backwards compatibility at this point.If that&#x27;s not stable, I don&#x27;t know what is. reply zer0zzz 12 hours agorootparentThe most underrated feature of windows probably ever. reply Dalewyn 11 hours agorootparentIt really is mindblowing that Windows 11 is still capable of running 32-bit programs written for Windows 95, that&#x27;s 28~29 years of backwards compatibility and environmental stability.If we look back to programs written for Windows NT 3.1, released in 1993, and assume they run on Windows 11 (because why not?) then that&#x27;s 30 years of backwards compatibility.Did I say mindblowing? It&#x27;s downright mythological what Microsoft achieves and continues to do. reply johannes1234321 8 hours agorootparentThe most fascinating example for that is SimCity: They noticed it didn&#x27;t run under Windows 95 as Windows 95 reused freed memory pages, but SimCity did a lot of use-after-free. This would have been aborted by Win95. Microsoft developers however knew that people would blame Microsoft not Maxis, thus added an extra routine I. The memory manager, which detected SimCity and then didn&#x27;t reuse memory as much.I don&#x27;t want to estimate how much such hacks they accumulated over time to keep things as compatible as they could. reply FirmwareBurner 11 hours agorootparentprevThere&#x27;s no guarantee that all the older apps from the Windows 9x&#x2F;XP days will work today, as some apps back then, especially games, made use of non-public&#x2F;undocumented APIs or just straight up hacked the OS with various hooks for the sake of performance optimizations. Those are the apps guarantee not to work today even if you turn on compatibility mode. reply SubjectToChange 10 hours agorootparentprevPersonally I&#x27;ve had little luck with even running XP applications on Windows 7. More generally, going by the difficulties experienced by many companies and organizations in the transition from XP->7, it&#x27;s hardly an isolated problem. Perhaps Windows maintains the best backwards compatibility of any mainstream OS, however I would hardly describe it as \"mythological\". reply arp242 4 hours agorootparentprevLinux can do this; binaries from the 90s work today.Something like xv (last release: 1994, although the binaries were built against Red Hat 5.2 from 1998) still work today, and the source still builds with one very minor patch last time I tried it.The problem running the binaries is: % ldd .&#x2F;usr&#x2F;X11R6&#x2F;bin&#x2F;xv linux-gate.so.1 (0xf7f82000) libX11.so.6 => &#x2F;usr&#x2F;lib32&#x2F;libX11.so.6 (0xf7e22000) libjpeg.so.62 => not found libpng.so.2 => not found libz.so.1 => &#x2F;usr&#x2F;lib32&#x2F;libz.so.1 (0xf7e08000) libm.so.6 => &#x2F;usr&#x2F;lib32&#x2F;libm.so.6 (0xf7d0b000) libc.so.6 => &#x2F;usr&#x2F;lib32&#x2F;libc.so.6 (0xf7a00000) libxcb.so.1 => &#x2F;usr&#x2F;lib32&#x2F;libxcb.so.1 (0xf7cde000) &#x2F;lib&#x2F;ld-linux.so.2 => &#x2F;usr&#x2F;lib&#x2F;ld-linux.so.2 (0xf7f84000) libXau.so.6 => &#x2F;usr&#x2F;lib32&#x2F;libXau.so.6 (0xf7cd8000) libXdmcp.so.6 => &#x2F;usr&#x2F;lib32&#x2F;libXdmcp.so.6 (0xf7cd1000)And Windows has exactly the same problem, but the tradition is to ship these things with the application rather than just assume they&#x27;re present on the system. And you can \"fix\" it by getting old versions, or even: % ln -s &#x2F;usr&#x2F;lib&#x2F;libjpeg.so.8 libjpeg.so.62 % ln -s &#x2F;usr&#x2F;lib&#x2F;libpng16.so.16 libpng.so.2You&#x27;ll probably run in to trouble with PNG and JPEG files, but e.g. loading&#x2F;saving GIF and whatnot works fine. Note how libc and libX* work out of the box.tl;dr: much of the \"Windows compatibility\" is just binaries shipping with all or most dependencies.Try it yourself: http:&#x2F;&#x2F;www.trilon.com&#x2F;xv&#x2F;downloads.html reply mkup 11 minutes agorootparentMuch of the Windows compatibility is \"just\" stable API for Windows controls, GUI event handling loops, 3D graphics and sound (DirectX). Linux has stable API for files and sockets (POSIX), but that&#x27;s all. reply EvanAnderson 11 hours agorootparentprevNTVDM could have been ported to 64-bit Windows, but MSFT declined to do so. Leaked Windows source code shows it would have worked[0].That would have given 16, 32, and 64 bit compatibility.[0] https:&#x2F;&#x2F;github.com&#x2F;leecher1337&#x2F;ntvdmx64 reply FirmwareBurner 10 hours agorootparentI don&#x27;t get it. Would NTVDM have been better than say, using DOS-box? reply mkup 10 minutes agorootparentYes, it would allow to create pipes between 16-bit NTVDM processes and native 64-bit processes. userbinator 4 hours agorootparentprevYes, because it&#x27;s integrated far more closely with the system. reply Zambyte 7 hours agorootparentprev> It&#x27;s downright mythological what Microsoft achieves and continues to do.This seems like it was meant in a positive way, but I really don&#x27;t think that if compatibility with your system requires \"mythological\" efforts, that should be seen as a good thing for your system.It&#x27;s also worth noting that backwards ABI compatibility only masters when people limit their software by not distributing the source. Early UNIX software can run fine on modern GNU by just compiling it.API Compatibility Is All You Need ;) reply penteract 3 hours agorootparent> It&#x27;s also worth noting that backwards ABI compatibility only masters when people limit their software by not distributing the source. Early UNIX software can run fine on modern GNU by just compiling it.Have you ever tried building decades old programs from source? It&#x27;s not as easy as you claim.Here&#x27;s source for grep from v6 unix. I&#x27;d be interested to know the smallest set of changes (or flags to gcc) needed to get it to compile under gcc on linux and work.https:&#x2F;&#x2F;github.com&#x2F;takahiro-itazuri&#x2F;unix-v6&#x2F;blob&#x2F;0316b457acb... reply userbinator 4 hours agorootparentprevEarly UNIX software can run fine on modern GNU by just compiling it....providing you can find a suitable compiler that isn&#x27;t obsessed with exploiting undefined behaviour. reply pizza234 11 hours agorootparentprev> If that&#x27;s not stable, I don&#x27;t know what is.What is? An immense amount of resources (developers) poured into developing live patches to make applications work on each newer version of Windows (or helping the application developers fix their applications). It&#x27;s an interesting conceptual grey area - I don&#x27;t consider it backward compatibility in a strict sense.This is documented in the book \"The old new thing\" by Raymond Chen (it&#x27;s possible also to read the blog, but the book gives an organic view).It&#x27;s fascinating how far-sighted Microsoft was; this approach, clearly very expensive, has been fundamental in making Windows the dominant O&#x2F;S (for desktop computers). reply justin66 9 hours agorootparent> I don&#x27;t consider it backward compatibility in a strict sense.Just in the sense that 100% of the people who use the phrase \"backward compatibility\" mean. reply pizza234 28 minutes agorootparentSure, from a user perspective, but not from an operative perspective: in the cases of live binary patching, Microsoft required to call the application developer to be legally clear; in orther cases, APIs behave differently based on the executable being run. There&#x27;s a lot more than just keeping the API stable. reply Dalewyn 10 hours agorootparentprevIt&#x27;s because Microsoft understands and respects that computers and operating systems exist to let the user achieve things.The user ultimately doesn&#x27;t care if his computer is an x86 or an ARM or a RISC-V, or if it&#x27;s running Windows or Mac or Linux or Android. What the user cares about is running Winamp to whip some llama&#x27;s ass, or more likely opening Excel to get work done or fire up his favorite games to have fun.Microsoft respects that, and so strives to make sure Windows is the stepping stone users can (and thusly will) use to get whatever it is they want to do done.This is fundamentally different to MacOS, where Apple clearly dictates what users can and cannot do. This is fundamentally different to FOSS, where the goal is using FOSS and not what FOSS can be used for.It&#x27;s all simple and obvious in hindsight, but sometimes it&#x27;s the easiest things that are also the hardest. reply pizza234 25 minutes agorootparentThis has very severe drawbacks, so it&#x27;s not unambiguously desirable.Windows APIs are probably a mess because of this (also ignoring the fact that only company with extremely deep pockets can afford this approach). There is at least one extreme case where Windows had to keep a bug, because a certain program relied on it, and couldn&#x27;t be made to work otherwise. reply eternityforest 8 hours agorootparentprevIt&#x27;s amazing how people don&#x27;t want Linux to \"Be like Windows\"... but as far as I&#x27;m concerned windows is close to ideal, just with a few flaws and places where FOSS can do better... reply m463 2 hours agorootparentprevThis might be true.Another abi I see games target are ubuntu... 14.04, 16.04, 18.04, etcUbuntu seems to be stable enough for the corporate world.I think things like flatpack or snap add bloat and behave in ways you don&#x27;t want. reply nmz 10 hours agorootparentprevWhich is quite something considering I can&#x27;t have foobar running for more than an hour before it crashes. reply zer0zzz 13 hours agorootparentprevYeah exactly! reply pjmlp 13 hours agoparentprevThat core would be GNOME or KDE frameworks, coupled with the FreeDesktop standards, at least that was the plan about 20 years ago.However as the site says doing distributions is what most folks keep doing, and naturally there isn&#x27;t a single stack that can keep up with snowflake distributions.In the end, Google took the Linux kernel, placed two core set of frameworks, one in Java, and the other in JavaScript, and naturally those are the winning Linux distributions for regular consumers. reply anonyme-honteux 4 hours agorootparentYou are talking about Android and Chrome OS right? I agree, those are the top two Linux distributions, and everything else is behind by an absolutely huge margin reply pjmlp 1 hour agorootparentYep. Just browse their documentation, that is the kind of development experience GNOME and KDE were expected to provide, 20 years ago, yet fail short due to Linux distributions fragmentation, the devs using other environments, or still stuck with plain window managers and xterms workflows. reply sph 1 hour agorootparentIf only GNOME and KDE were backed by one of the largest companies in the world, with tens of billions of dollars at its disposal. reply zer0zzz 13 hours agorootparentprevNone of that core is standardized across even a hand full of distros. reply pjmlp 12 hours agorootparentNaturally, you missed the part I mentioned it was the plan 20 years ago, not how it looks like today. reply zer0zzz 12 hours agorootparenttldr reply fragmede 13 hours agorootparentprevChrome&#x2F;Chromium is quite standardized, across many distros. reply zer0zzz 13 hours agorootparentName one distro that ships with chrome out of the box? I dont even think ubuntu comes with a chromium browser. That means devs cant write apps against it and just hand out exes like they do on Mac and windows. reply fragmede 11 hours agorootparentChromium is the default browser on Raspberry Pi OS. reply charcircuit 11 hours agorootparentprevPlay Protect Certified Android and ChromeOS are popular ones among consumers reply zer0zzz 11 hours agorootparentNice. Maybe more desktop distros should build on android as a core. That could solve a lot of problems. reply charcircuit 10 hours agorootparentI agree. With how much resources are invested into Android for offering an OS for consumers, desktop Linux distros using the freedesktop stack are missing out. It is not easy for distros to acknowledge the sunk cost. replyjwells89 13 hours agoparentprevIf I could have that spread of frameworks that macOS offers on Linux, I’d be targeting Linux with my side projects yesterday. Having such a wide selection of tools to readily reach for with zero consideration about how long it’ll be supported, which fork is best, how well it meshes with a pile of other third party libraries, etc is amazing. It reduces friction massively and you just build stuff.The KDE Qt ecosystem and its GNOME&#x2F;GTK analogue are closest but still aren’t quite there. reply isodev 7 hours agoparentprevEnsuring an app looks and feels the same across various distributions seems quite challenging when it’s not only different flavours of the OS but also different desktop environments.At the same time, the OS flavours don’t seem to offer a unified way for handling payments, subscriptions and in-app purchases which is a significant burden to implement from scratch by every app developer. reply tristan957 5 hours agorootparentWhy do distributions need to offer this when SDKs exist for services like Stripe and PayPal? reply isodev 2 hours agorootparentBecause a Linux distributions are used all over the world. Stripe and PayPal are good, but insufficient as a choice - one can&#x27;t be expected to pick SDKs that work equally well in all regions, preferring local payment options, registering with local tax authorities etc.Also, Stripe and PayPal don&#x27;t offer tools to check if an app is running with a valid license&#x2F;subscription, it&#x27;s not pirated etc. (the equivalent of the App Store receipt signature). reply michaelmrose 4 hours agorootparentprevThe \"feel\" of the app is identical across distributions because the app controls everything inside its window and the look only varies slightly in terms of colorscheme and window decoration if that.There is absolutely no legit purpose for in app purchases on a desktop OS. Its not hard to pay for substantial software suites and most of what would be an app on platforms which at one point would have had an anemic browser experience is simply a website on platforms where fast cpus and 14-28\" screens are normal.Nobody needs a bunch of adware apps you can pay $3 to decrapify or games that are a slog if you don&#x27;t buy fake potions for real money.There are enough good free basic apps for virtually any use case and the more complex use cases need up front investment and users not in app purchases.What use case do you imagine for this feature? reply isodev 2 hours agorootparent> Nobody needs a bunch of adware appsYou can&#x27;t stop people from making crap apps, they exist even today.> The \"feel\" of the app is identical across distributions because the app controls everything inside its windowTo make an app feel at home, it needs to \"blend\" with the rest of the OS. To achieve this, one can use OS-components to build an interface. Just a simple example, GTK apps are so different from KDE apps in their look and feel - you can always tell if an app is native GNOME or KDE app. Now consider all the other desktop environments - it&#x27;s just way too many to account for in one&#x27;s code and testing.Then comes the question of system integrations - how do you offer a unified photo picker experience, how do you ensure you always ask for the right permission to access the camera, the clipboard or network APIs - all these should be provided from the OS so they don&#x27;t confuse the user and prevent abuse by naughty apps.> no legit purpose for in app purchases on a desktop OSI strongly disagree - what if you want to offer a \"try before you buy\", or you&#x27;d allow users to purchase additional content&#x2F;credits for a service bundled with your app? What if you want to adapt your pricing for a specific event or holiday period...etc, the sheer scope of possibilities is not practical to include in one comment. reply tempodox 12 hours agoparentprevAnd on a lower level, `fgetwc()` gets crashed deliberately in `libc` when applied to a stream created with `fopencookie()`. It should be incredible, but Linux `libc` is not Unicode-capable in 2023. reply zlg_codes 12 hours agorootparentWhich libc?There&#x27;s glibc, musl libc, etc. Also consider you may be using the functions incorrectly. reply tempodox 4 hours agorootparentSeriously? “You&#x27;re holding it wrong”? Read the comment at the crash site (line 584) yourself:https:&#x2F;&#x2F;elixir.bootlin.com&#x2F;glibc&#x2F;glibc-2.38&#x2F;source&#x2F;libio&#x2F;gen... reply sylware 13 hours agoparentprevCuplrits are mostly glibc devs with their manic abuse of version names (and very recently, a GENIUS who added a new ELF relocation type): this is a pain for game developers to provide binaries which span a reasonable set of distros in time. Basic game devs install one of the latest mainstream and massive distros, build there, and throw the binaries on steam... but that recent distro had a glibc 2.36 and now their binaries have version names requiring at least a glibc 2.36 (often, rarely not). They have to force the right version names with... the binutils gas symver directive (see binutils manual) until all their version names are compatible with a glibc reasonably \"old\" (I would go for a reasonable 5 years... 7&#x2F;8 years?):https:&#x2F;&#x2F;sourceware.org&#x2F;glibc&#x2F;wiki&#x2F;Glibc%20TimelineOf course normal game devs have not the slightest idea of those issues, and even so, they won&#x27;t do it because it is a pain, that for 1% of their market. Not to mention they better statically link libgcc (and libstdc++ if they use c++) to avoid the ABI issues of those abominations (the word is fair) which have been plagging game binaries for TEN F.... YEARS ! (getting better has more and more game binaries default to -static-libgcc and -static-libstdc++, if c++, gcc&#x2F;clang options).There is light at the end of the tunnel though as godot engine is providing build containers which are very careful of all that (unity seems clean there too, dunno for UT5.x though).But you have engines really not ready, for instance electron based games: you don&#x27;t have the right version of the GTK+ toolkit installed on your enlightenment&#x2F;Qt&#x2F;raw X11&#x2F;wayland&#x2F;etc distro? Nah, won&#x27;t run. And packaging properly a full google blink engine for binary distribution targetting a wide spectum of elf&#x2F;linux distros? Yeah... good luck with that.elf&#x2F;linux is hostile to anything binary only, that due to manic ABI breakage all over the board, all the time (accute in the SDK and core libs).If it is already that hard for game binaries, good luck with apps. I can hear already their devs saying: \"we don&#x27;t care, just use and install microsoft suze gnu&#x2F;linux, every else is unsupported\"... I think you get the picture where all that is going. reply zer0zzz 13 hours agorootparentI agree. I recall a talk from Linux Torvalds on how bad the glibc folks break things and why he won&#x27;t ship a binary version of his scuba tool. If the binary breakages start with the darn C lib, you&#x27;re gonna have recurring problems all the way up the stack on a regular basis I feel. reply SubjectToChange 10 hours agorootparentIf the binary breakages start with the darn C lib, you&#x27;re gonna have recurring problems all the way up the stack on a regular basis I feel.In general glibc maintains an extremely stable ABI[1]. Forwards compatibility in both glibc and libstdc++ is something many companies depend on for their mission critical applications, and it&#x27;s the entire reason Red Hat pays developers to maintain those projects.[1]: https:&#x2F;&#x2F;abi-laboratory.pro&#x2F;index.php?view=timeline&l=glibc reply sylware 13 hours agorootparentprevThis has the case for 10 years with games on steam. The worst being libstdc++ ABI issues still around because many devs forget to statically link their c++ libs with -static-libstdc++. Because in windows, ABI stability is really good and then devs are used to that. reply jcelerier 8 hours agorootparent?? on windows you always have to ship the libc&#x2F;libc++ along with your app, as part of the VS redistributables. That&#x27;s pretty much the same than static linking, the symbols are just not in the same binary. reply zer0zzz 13 hours agorootparentprevAs far as I understand, Windows solves this libc++ versioning issue using the side by side cache. I guess this is a little bit like flatpack. reply okanat 12 hours agorootparentWindows standard C and C++ ABI is stable since 2017. So the last 3 releases of the Visual C Compiler and C runtime hasn&#x27;t changed the ABI.However Windows also has a lower level system API &#x2F; ABI i.e. Win32 that&#x27;s always stable all the way to Win 95. WinSXS sometimes helps for certain legacy apps too. This allows apps using different C libraries to work together. Win32 contains everything about the OS interface. Creating windows, drawing things, basic text, allocating pages from the OS, querying users, getting info about files is all stable. Win32 is the lower level of the C library. There is also a better separation of the functions in different DLLs. Win32 has multiple DLLs that has different jobs and they are mostly orthogonal. Kernel32 contains core almost system call stuff. Shell32 contains interactions with the OS shell i.e. creating windows, message boxes, triggering different UIs.The surrounding libraries like DirectX &#x2F; DirectPlay &#x2F; DirectWrite that are also used by the games are also part of the system libs starting from 7. They are also stable.On Linux world there is no separation of the system level libraries and normal user libraries. Glibc is just another library that one depends on. It contains the entire lower level interface to kernel, all the network stuff and POSIX user access stuff. It also contains a component that has no job in a C library: the dynamic executable loader. Unlike Windows on the Unix systems the C library is at the lowest level and Glibc being the default libc for Linux and making itself the default provider of the dynamic executable loader makes writing stable ABI almost impossible. Since other libraries depend on Glibc and executables depend on Glibc&#x27;s dynamic loader everything is affected by the domino effect. reply sylware 10 hours agorootparentI agree.The elf loader should be extracted from the glibc... but there is price to pay, and it is where those guys could do their manic ABI breaking again.Some very low level interfaces will have to be defined between the external elf loader and the posix&#x2F;c runtime. For the moment those interfaces are private, just look at how intimate they are about threading and TLS. reply p_l 12 hours agorootparentprevWindows solves this issue by not making language runtime part of the OS libraries in a way that pollutes other libraries.That means that you can have your application linked with library A version X, and load another library that is linked with library A version Y, and so long as certain practices are followed, everything works because you&#x27;re not getting cross-contamination of symbols.Meanwhile on Linux the defaults are quite different, and I can&#x27;t load OpenGL ICD driver that depends on GLIBC_2.38 symbol on application that was loaded with glibc-2.37. Moreso, a lot of APIs will use malloc() and free() instead of language-independent allocator, unless the allocation comes from kernel. And no, you can&#x27;t mix and match those. reply zlg_codes 12 hours agorootparentWhat language independent allocator? I&#x27;m unaware of any memory interfaces in programming languages that aren&#x27;t specific to that language.What would you use instead of malloc and free? reply p_l 9 hours agorootparentThe OS provided memory allocators - HeapAlloc, its wrappers GlobalAlloc and LocalAlloc (remainders of 16bit era), VirtualAlloc (page granularity, can be compared to MAP_ANONYMOUS with mmap(), and CoTaskMemAlloc which can be shared across COM processes + their respective \"free\" functions. malloc() is explicitly called out in documentation as \"runtime dependant\".Similarly other OSes used to have memory allocation services that weren&#x27;t linked in any way to a language runtime - VMS has several calls, all language independent, ranging from low-level equivalents of mmap() to malloc-alternative.And yes, a big chunk of Windows portability is that various APIs use those language-independent calls internally, and so can developer in order to avoid creating issues - and documentation promotes those language independent methods.At no point you get into situation with Windows API that you call free() on memory allocated by malloc() from a different libc.In comparison, the available language-independent APIs without using any special libraries on Linux, are to directly call mmap() and sbrk() through inline assembly (beware the glibc wrappers!). reply SubjectToChange 10 hours agorootparentprevI suppose they meant a \"libc independent\" allocator, e.g. jemalloc&#x2F;tcmalloc&#x2F;mimalloc&#x2F;etc. Although, using such allocators comes with complications of their own: https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;761502&#x2F; reply sylware 12 hours agorootparentprevThis what the \"pressure-vessel\" container from collabora (used by valve on dota2&#x2F;cs2), is trying to solve... but now the issue is the container itself as it does _NOT_ follow fully the elf loading rules for all elf binaries and does ignore many configuration parameters of many software packages (data files location, pertinent environment variables, etc), basically presuming \"ubuntu\" to be there.Basically, I have my vulkan driver requiring fstat from 2.33 but the \"pressure-vessel\" (sniper version), has a glibc 2.31, then it does parse partially my global elf loading configuration and the configuration of some packages to import that driver and all its dependencies... including my glibc elf loader... ooof! That level of convolution will have a very high price all over the board.I have arguments often with one of \"pressure-vessel\" devs because of some shortcuts they took which do break my distro (which is really basic and very vanilla, but not \"ubuntu\"). It took weeks to get the fixes in (I guess all of them are in... until the glibc devs manage to do something which will wreak havock on \"pressure-vessel\"). Oh... that makes me think I need to warn them about that super new and recent ELF relocation type they will have to parse and detect in host drivers...On my side, I am investigating some excrutiatingly simple modern file format which should help a lot fighting those issues, there will be technical trade-offs obviously (but would run-ish on \"old\" kernels anyway with elf \"capsules\" and an orthogonal runtime). Like json is for xml, but for elf&#x2F;pe.It seems only the linux ABI can be trusted... til Linus T. is able to hold the line. reply charcircuit 8 hours agorootparent>It seems only the linux ABI can be trusted...The ABI is not stable. Google has to do extra work monitoring for ABI breakages to make sure that pushing out an update of an LTS branch of the kernel does not break people&#x27;s drivers.https:&#x2F;&#x2F;source.android.com&#x2F;docs&#x2F;core&#x2F;architecture&#x2F;kernel&#x2F;sta... reply p_l 8 hours agorootparentLinux kernel userland ABI is stable. Nothing else is on linux. reply piperswe 7 hours agorootparentprevThe module ABI is not stable, but that&#x27;s not the ABI typically referred to when someone says \"Linux ABI\". That would be the userland ABI, which is stable. reply sylware 13 hours agorootparentprevI think there are very few c++ ABI versions on windows and it is easy to select the one you want until it is installed, they can be there side by side. reply jancsika 12 hours agorootparentprev> But you have engines really not ready, for instance electron based games: you don&#x27;t have the right version of the GTK+ toolkit installed on your enlightenment&#x2F;Qt&#x2F;raw X11&#x2F;wayland&#x2F;etc distro? Nah, won&#x27;t run.Hm, not sure what you mean here.At least with the nw.js toolkit (from which Electron was forked IIRC) I&#x27;ve never gotten a report of a distro where it would refuse to run because of an incompatible GTK version. reply sylware 10 hours agorootparentWhy would a distro have GTK in the first place?More reasonably, binary GUI apps should not expect more than the window system, on elf&#x2F;linux, wayland with a legacy fallback to x11. It means, the GFX toolkit is an application choice on top of the windowing system. Binary GUI apps have to distribute it... they have to distribute their own version which would not conflict with the version installed on the user system... if any... reply zlg_codes 12 hours agorootparentprev> If it is already that hard for game binaries, good luck with apps.Video games are some of the most complex and most difficult pieces of software both to build and to get right. Modern games are coded so poorly that driver makers have to release patches for specific games.It&#x27;s the gamedev world that can&#x27;t get its shit together. Valve settled on an Arch-based distro for the Deck. The specific distro doesn&#x27;t matter since Steam already establishes its system requirements and comes with a runtime.Beyond that, I really don&#x27;t see the issues you&#x27;re talking about. Generally, any issues you have are fixed by symlinking the correct .so files. This is a side effect of targeting a specific version of software instead of keeping to its more base features. That&#x27;s on the dev, not the user or distro.You act like Windows has never had ABI breakage or versioning problems. I&#x27;d like to see the specific issues you ran into; maybe there&#x27;s an easy fix like a symlink. reply ydlr 10 hours agorootparentprevIsn&#x27;t the solution to this problem to just distribute the source code. Let package maintainers worry about creating binaries for their distros. reply em-bee 10 hours agorootparentnot when you actually want to sell the games for money. reply phone8675309 5 hours agorootparentprevIf they&#x27;re going to put the game on Steam then they should be using the Steam Runtime which is available here[1]. Otherwise they&#x27;re shooting themselves in the foot.[1] https:&#x2F;&#x2F;github.com&#x2F;ValveSoftware&#x2F;steam-runtime reply realusername 1 hour agoparentprev> On competing platforms there are way more frameworks out of the box (CoreImage, CoreAudio, CodeML, SceneKit, AppKit, etc) and they don’t break as often.I would not use MacOS as an example of stability, each version breaks and deprecates a massive amount of API and old apps will require changes.Windows is the only OS with serious backward compatibility. reply smoldesu 14 hours agoparentprevStuff like Flatpak and Snap exists because the framework side kinda is built-out. Isolation technology had matured, newer desktops emphasized per-window security and needed APIs to portal in and out of each instance. The desktops needed a packaging&#x2F;infrastructure solution to tie that together and make it presentable to the user. reply zer0zzz 13 hours agorootparentYet I still can&#x27;t compile an app on some arbitrary release of some arbitrary distro and just run the darn exe on another and be 100% sure it will work. reply eternityforest 7 hours agorootparentOn other platforms people don&#x27;t even try to support anything but one \"distro\".You could make an AppImage or snap that would work across pretty much any mainstream non-hobbist-oriented distro, and Snap&#x2F;AppImages is pretty much the Linux equivalent of EXE.Raspberry Pi OS just moved to NetworkManager and they have PipeWire, which was the last reason I had to deal with less common software stacks, so it seems like stuff is getting more standardized. reply night-rider 6 hours agorootparent+1 AppImages. And the beauty is you can make them portable by creating a folder with the same name as the AppImage and append .home to the end, and boom: portable software. For example image-editor.AppImage image-editor.AppImage.home (folder, all settings are stored there) reply zer0zzz 2 hours agorootparentActually, I don&#x27;t think I&#x27;ve tried AppImage. Does it do static linking or does it do something more similar to flatpak? reply smoldesu 12 hours agorootparentprevOn a large enough timescale I don&#x27;t think you can reasonably expect this on any of this big 3 OSes. From a less macro perspective, I think tools like Appimage and Flatpak will fill that role. reply zer0zzz 12 hours agorootparentOn a long enough time scale we are all dead, and Linux doesn&#x27;t exist. That doesn&#x27;t mean that in the decades that computer software has to be useful to actual people that things have to suck this badly right now. reply smoldesu 12 hours agorootparentThe \"actual people\" using Linux on the desktop are not running .so files off the internet. I get what you&#x27;re saying, but you know it&#x27;s facetious to pretend that packaging is simple on Mac and Windows too. reply zer0zzz 12 hours agorootparent> The \"actual people\" using Linux on the desktop are not running .so files off the internet.They do this all day every day when they use a little something called Steam or when they install Google Chrome.> I get what you&#x27;re saying, but you know it&#x27;s facetious to pretend that packaging is simple on Mac and Windows too.It is... reply api 12 hours agorootparentprevPackaging is fairly simple on Mac and Windows if you use the dev tools for the platform and are not doing things like installing services or drivers or changing OS configuration.Your packaged app will almost always work too. There are not 50 distributions of these OSes. reply zer0zzz 12 hours agorootparentexactly replyAnthonyMouse 10 hours agorootparentprevThe trouble is you&#x27;re trying to distribute it as a binary yourself. The there are two traditional ways for distributing software for Linux:1) The system package manager. It will download a binary from the repository which is the right one for that system.2) make && make install. This is mostly for software in development that hasn&#x27;t made it into the package manager yet. It will compile from source and produce a binary for the target system.All the problems are from people trying to do something other than this. reply zer0zzz 7 hours agorootparentThat&#x27;s the problem. The Linux way of distributing apps is wrong for trying to compete with the other consumer platforms. The ChromeOS or electron style of doing things is another story though. reply chefandy 13 hours agoparentprevPeople like to shit on tools like Electron, but there&#x27;s a reason they&#x27;re popular. If you need to reach a broad audience with a native tool, using heavy-handed web-based plumbing is a bigger win for Linux users than supporting only windows and macos where like 97% of desktop users are. reply FirmwareBurner 12 hours agorootparentHold on mate, isn&#x27;t that what Java was supposed to solve. I remember before the days of electron when I was a wee lad in the 2000s, all cross platforms apps were Java.Look at Ghidra, it&#x27;s a Java app for Windows, Linux and Mac. The \"holy trinity\" of operating systems, covered with one language and framework.So what happened? Did devs forgot Java exists and felt like reinventing the wheel but worse this time? reply creesch 12 hours agorootparentJava simply has a much higher barrier of entry. Not only in regards to figuring out the language and resources available but also the fact that creating a GUI still requires external dependencies.Electron isn&#x27;t just cross platform, it is cross platform based on technologies (html, css and javascript) that also by a huge margin have the largest amount of developers available. reply whartung 12 hours agorootparentnext [–]> Not only in regards to figuring out the language and resources available but also the fact that creating a GUI still requires external dependencies.What external dependencies does Java need that&#x27;s not in the JDK itself? I have an app with Mac and Windows installers (and thus bundles JDKs), it also runs on Linux (via a fat jar), I tested it on Ubuntu, but for the life of me I couldn&#x27;t figure out how to package it properly. It was more complicated that I cared to invest it at the time.As for the barrier to entry, I feel the same way about the web. I find the JS and Web ecosystem to be utterly overwhelming, one reason I stuck with Java over something like Electron, and the installers&#x2F;footprint of the app are smaller to boot. reply anthony88 9 hours agorootparentFor Linux, I&#x27;m using jpackage to package my Java software to .deb (x64 architecture) file. For all the other Linux variants, I&#x27;ve a .tgz file that contains the jar file, libraries and icons of the applications.The problem I have with Linux is named at the end of the website: \"Sharing your creation\". It&#x27;s pages and pages of documentation that is not relevant to the packaging of your application where you can spend hours of work without finding what you want of finding out that it doesn&#x27;t work for you because for example it&#x27;s not on GitHub. Hopefully jpackage was able to fix it for the .deb format. Instead of working on more documentation, working on better and easier to use packaging tool would help. reply creesch 11 hours agorootparentprev> What external dependencies does Java need that&#x27;s not in the JDK itself?I mean that it doesn&#x27;t come with Java itself, but you as a developer need to pick a UI framework and not all of them actually work all that well cross platform or will get you an actual modern interface.Edit: I should also note that the threshold for entry I am talking about is for people just generally starting out. There simply are way more resources available for web related development than there are for java.Also, when you start bundling your JDKs I am not sure you can talk about a smaller footprint anymore. reply whartung 10 hours agorootparentWell, Swing is still bundled with Java. Netbeans uses the \"Flat Look and Feel\" and looks ok to me. I find Swing a lot more work compared to FX.JavaFX used to be bundled with Java, but was removed. Some JDK distributions bundle FX like it was before, and adding FX to a new project is simple and straight forward. Maven packages it nicely, and it includes the platform specific binary parts. If you can use Log4j, you can use Java FX. Onboarding onto FX is not a high bar.I can not speak to SWT.There&#x27;s several examples of \"modern\" UIs in FX, I can&#x27;t speak to any of them, I don&#x27;t pay much attention to that space. It&#x27;s imperfect compared to the web, but not impossible. reply chefandy 8 hours agorootparentJava FX seems better than swing, but it&#x27;s an external dependency now though, isn&#x27;t it? I thought it got removed from the jdk a few years ago. reply whartung 6 hours agorootparentIt was. Even before it was more \"bundled\" with the JDK than \"part of Java\".But, to be honest, that&#x27;s a real nit. It&#x27;s a standalone dependency, it&#x27;s 4 lines in a POM file, it doesn&#x27;t drag the internet with it, and it only relies on the JDK. So, while it&#x27;s a large subsystem, it&#x27;s a \"low impact\" dependency in terms of side affects and complexity. reply ausbin 6 hours agorootparent> it&#x27;s a \"low impact\" dependency in terms of side affects and complexity.I wish that were true in my experience. But we have struggled to support {macOS, Windows, Linux} x {x86_64, arm64} with JavaFX and one .jar for our application.This is a 250-line diff, not a 4-line diff: https:&#x2F;&#x2F;github.com&#x2F;ra4king&#x2F;CircuitSim&#x2F;pull&#x2F;93&#x2F;files. We have to manually manage .dlls and .sos by hand.If you know a solution that is 4 lines, we would be very grateful. All we want is one .jar with JavaFX in it that supports many OSs and architectures. reply ElectricalUnion 11 hours agorootparentprev> Also, when you start bundling your JDKs I am not sure you can talk about a smaller footprint anymore.What, do you bundle Electron source and Electron build environment with your Electron app?Why would you do the same and bundle Java source code + Java compilers in your Java app?Why would you do the same and bundlesource code +compilers in yourapp?If you need to create a \"just works without dependency b.s.\" experience in Java, you use the correct tooling for that, jlink. reply em-bee 10 hours agorootparentprevwhen i see a java application i think, hmm, this is likely going to be bloated (but not necessarily) but for sure it&#x27;s going to run.if i want to create a cross platform application where i don&#x27;t even have to think about testing on multiple operating systems, then java is going to be a serious contender.and if i have to choose between an app written in java or electron, i&#x27;d probably pick the one in java.so yeah, i don&#x27;t understand what happened here either. reply chefandy 11 hours agorootparentprevJava is great for making huge well-organized codebases with a lot of developers, especially if you&#x27;ve got good tooling support or a rich ecosystem of existing code to work with. Outside of that... If it was a good development ecosystem for native gui-based apps targeted at end users, why wouldn&#x27;t the preponderance of native user-facing apps be written in Java, anyway? Ask nearly any experienced mobile app developer if they&#x27;re more productive in Java on Android or Swift on iOS-- it&#x27;s not even close. Sure, some of that is the OS itself, but a whole lot of it isn&#x27;t. On the desktop, the one time I tried to make something with Swing I wanted to Fling my computer out the window. Clunky. reply skydhash 5 hours agorootparentIt’s about branding. Swing and JavaFX looks like other desktop app (aka not cool to a lot of designers). And it has a high barrier of entry (ever tried QT, AppKit or Win32). Electron is easy, but it’s shoehorning a document process to software interfaces. reply zer0zzz 12 hours agorootparentprevJava is objectively terrible for writing good apps on modern personal computers. The one platform that did adopt it (android) had to practically rework the entire byte code and VM as well as the set of APIs for writing apps to make it work. reply FirmwareBurner 12 hours agorootparentWhy is it terrible? Asking for real. reply LeoNatan25 12 hours agorootparentBecause it’s not “sexy” anymore. Now “sexiness” lies with web crap, so Electron is a “great tool”, while Java is “terrible”. reply zer0zzz 12 hours agorootparentprevWell, so I can only tell you as much as I know and understand. Some of this pulls in some outdated information too.So, JVMs and languages that abstract the underlying machine are always going to have overhead. The original interpreted stack-based JVM model is really bad for performance because you can&#x27;t do great optimizations on the code because you can&#x27;t have a great view of the operands that are being defined and then subsequently used, on top of that you have to either JIT or interpret code which also has overhead. This is why Android&#x27;s original Dalvik VM originally started by converting the Sun byte code format to a register based format. So, now you have a format you can do some optimizations on: great. But you still depend on a VM to generate and optimize for native code: that means code-caches and that means using excess memory to store the fast optimized code you want to run (which could have been evicted, so more overhead when you have to regenerate). Next you have frameworks like the classic Swing in Java that were frankly implemented with priorities that did not include having a really great and responsive experience even though its platform agnostic as far as the way it draws widgets. These days we can take GPUs for granted to make this approach work, but a lot of the Java UI stuff came from another era.I am not really sure if I am right here, but to me all this means that to have made the Java system work well for modern PCs and mobile it would have required a ton of investment. As it turns out, a lot of that investment went into the web and android instead of polishing Sun and Oracle&#x27;s uh... product.Java&#x27;s also kinda been sidelined because for years Oracle threatened to sue anyone that dared fork it as Google had, and Microsoft kinda spent a decade making C# and .NET more confusing than it already was so theres that too. reply FirmwareBurner 12 hours agorootparent> The original interpreted stack-based JVM model is really bad for performance And we addressed that today by launching a copy of Chrome with every app? reply zer0zzz 12 hours agorootparentyesI think it&#x27;s hard to beat the tide that is the web as a content and app delivery system. The web is also getting all the billions in investment from every massive faang. reply ElectricalUnion 10 hours agorootparentprev> So, JVMs and languages that abstract the underlying machine are always going to have overhead.Well, so JavaScript and WebAssebly isn&#x27;t that great either in the end?> The original interpreted stack-based JVM model is really bad for performance because you can&#x27;t do great optimizations on the code because you can&#x27;t have a great view of the operands that are being defined and then subsequently used, on top of that you have to either JIT or interpret code which also has overhead.What a paragraph. But it&#x27;s kinda false.WebAssembly, you know, is also a stack-based virtual machine.Javascript might not be a stack-based virtual machine, but you&#x27;re interpreting it every time you run it for the first time. How is that faster that bytecode? It isn&#x27;t.In fact, modern Javascript is fast specifically because it copies the same workflow of the Java HotSpot JIT optimizer - detect and compile code hot spots in native code, run that instead of VM code.> This is why Android&#x27;s original Dalvik VM originally started by converting the Sun byte code format to a register based format. So, now you have a format you can do some optimizations on: great. But you still depend on a VM to generate and optimize for native code: that means code-caches and that means using excess memory to store the fast optimized code you want to run (which could have been evicted, so more overhead when you have to regenerate).Nope, that is totally not the reason. Dalvik was done because it was believed that you needed something that starts faster, not something that runs faster.Those are 2 different optimization targets.It was pretty known since the start of Dalvik that Dalvik had very poor throughput performance, from 10x to 2x worse that HotSpot.The reason why we don&#x27;t have Dalvik anymore on Android is that it also didn&#x27;t start that much faster either.That of course is not because register machines are worse either, but because nowhere near enough optimization work was done for register type VMs compared to stack type VMs in general.> Next you have frameworks like the classic Swing in Java that were frankly implemented with priorities that did not include having a really great and responsive experience even though its platform agnostic as far as the way it draws widgets. These days we can take GPUs for granted to make this approach work, but a lot of the Java UI stuff came from another era.Ok, but does your favorite, non-web GUI framework use the GPU, and use the GPU correctly at all?Even on the web it&#x27;s easy to \"accidentally\" put some extremely expensive CSS transformations and animations and waste a whole bunch of GPU power on little things.> I am not really sure if I am right here, but to me all this means that to have made the Java system work well for modern PCs and mobile it would have required a ton of investment. As it turns out, a lot of that investment went into the web and android instead of polishing Sun and Oracle&#x27;s uh... product.You&#x27;re mixing things here. \"Sun products\" were very expensive UNIX workstations and servers. Not things for your average Joe. Those very expensive Sun workstations and servers ran Java fine.Java itself is a is very weird \"Commoditize Your Complement\" ( https:&#x2F;&#x2F;gwern.net&#x2F;complement ) attempt to commoditize this exact very expensive hardware that Sun was selling.From Sun. Marketed at very high expense by Sun. A self-inflicted self-own. No wonder Sun no longer exists.> Java&#x27;s also kinda been sidelined because for years Oracle threatened to sue anyone that dared fork it as Google had, and Microsoft kinda spent a decade making C# and .NET more confusing than it already was so theres that too.C# not having nice GUI is another story, that of Windows-land never having anything above pure Graphics Device Interface being stable since forever. reply zer0zzz 10 hours agorootparentFantastic demonstration of Cunningham’s law, but I think you missed the point. reply mikrotikker 11 hours agorootparentprevIt&#x27;s got more security holes than Swiss cheese. reply samus 3 hours agorootparentYou&#x27;re living in the past. Applets and Flash lost against the HTML&#x2F;JS&#x2F;CSS stack and Oracle owned up to it. Applets are terminally deprecated now.Edit: admittedly, one of the reasons for that was that the sandbox was indeed prone to security holes. Also, the developer ergonomy of the SecurityManager was unsatisfying for both JDK and app developers. Good riddance. reply zlg_codes 12 hours agorootparentprevIt&#x27;s the JS kiddies. They got Node and then decided the whole world should be written in Javascript, lol. reply zlg_codes 12 hours agorootparentprevAs someone who uses Linux as a daily driver, I can recognize these gargantuan apps a mile away and stay away from them. They are absolute hogs of system resources, and for something simple like Etcher there&#x27;s no excuse.Things like Electron are good for devs but bad for users. We have more computation power than ever and yet programs still run slow. reply FirmwareBurner 12 hours agorootparentOh, it gets better. Even the default Weather app shipping with Windows 11 is also an Electron pile of trash that uses ~520 MB of RAM. Just let that sink in. 500MB of RAM just to show you the weather forecast for the day and week. That was my entire system RAM of my Windows XP gaming rig.Same for the Widgets app, it&#x27;s not only bad because it shows you news and ads when you open it, it&#x27;s worse because it&#x27;s also, you guessed it, an Electron app.Some VP in Redmond must be off their meds.I assume Microsoft just can&#x27;t find devs to write C#, their own damn programing language for their own OS, and one of the dozens of frameworks they have for Windows GUI, that they need to resort to using Electron for what are just Windows-only apps. reply ziml77 11 hours agorootparentThe Weather app in Windows 11 a UWP .NET Native wrapper around WebView2 controls. It&#x27;s exceptionally silly that it&#x27;s basically just a web browser with predefined tabs and that it uses so much RAM, but it&#x27;s not Electron. reply FirmwareBurner 11 hours agorootparentOh my bad. I think I saw it call some Edge system components in task manager and I assumed it must be Electron. reply zlg_codes 10 hours agorootparentprevGood lord, that&#x27;s crazy, haha. You&#x27;d think with all of their different frameworks, one would have been more suitable than starting from scratch with a browser tab, jeez.I recently upgraded to 10 because of Steam requiring it in a few weeks, and it&#x27;s been an adventure. Lots of crashes and restarts that I didn&#x27;t ask for. I really don&#x27;t know who exactly modern Windows is for, because I&#x27;m a gamer and programmer and it&#x27;s not been good for either of those tasks...Windows 7 was solid and I almost never had issues out of it. It booted and got out of the way. reply chefandy 11 hours agorootparentprevWorse for users than nothing? IT shouldn&#x27;t be a default, but if it&#x27;s that or nothing-- as it often is when it comes down to limited resources-- I think it&#x27;s better than nothing. If you&#x27;re looking to make a useful tool for a broad audience that must run locally, you have to support windows because that&#x27;s where 80% of the users are. You should support OSX because that&#x27;s where 15% of the users are. That&#x27;s two codebases with dramatically diminishing returns. You need a damn good reason to justify adding ANOTHER codebase on there to scoop up the remaining handful of users on Linux.Also, aside from startup time, I don&#x27;t have any trouble with electron apps running slow on my machines. I think many developers are conceptually annoyed with the absurd, bloated architectural underpinnings rather than the experience that translates into when using them. Perception means a lot when judging performance, and I&#x27;ll bet with most end users using, say, slack, the speed of their internet connection affects the speed of their work more than the speed of the application. reply zlg_codes 10 hours agorootparentI&#x27;m really not swayed by \"we must use this turd because the alternative is nothing\". \"Nothing\", to me, is a technical challenge and a sign I should probably start writing the thing myself.Yes, not everyone has the skill or time to do that, but it&#x27;s also no reason to accept half-baked solutions that don&#x27;t take the user&#x27;s system resources into account. Compute may be cheap but it&#x27;s still a resource we need to use wisely. Not everyone is running a system like the developer&#x27;s Macbook Pros on 5GHz wifi hooked up to fiber. reply chefandy 8 hours agorootparentIf you only care about the best technical solution, and don&#x27;t care about economics, then you almost, by definition, only care about what existing FOSS users are doing, and I don&#x27;t find that scope limitation useful in any way. I love FOSS. I&#x27;ve been a regular contributor to FOSS for decades. But the impact user-facing FOSS apps have on the overwhelming majority of users is miniscule, as is the comparative number of regular FOSS users. Server apps? Apps developers use to make the apps everyone else uses? Absolutely. A music player? A chat app? Nope. Software that makes a visible impression on users is commercial. That&#x27;s just reality. And companies that don&#x27;t consider ROI on the products they create aren&#x27;t companies very long.The most popular as-is FOSS app for users is probably Firefox with a browser market share neck-and-neck with Opera and Samsung Internet, and everything less popular might as well not exist among probably 99% of users. Why? It&#x27;s certainly not performance, I assure you. It&#x27;s because it&#x27;s poorly designed and users find it infuriating to use. Sure, you can find people complaining about their bloated slack client being slow on their machine. You think that&#x27;s bad, find a professional photographer and ask them about the one time they tried to use Gimp.I spend a lot of time talking about how FOSS could be a lot more usable to end users, and technical supremacy isn&#x27;t it. If you showed your average end user an electron app with an intuitive, professional design that gets the job done well enough, and then you show them the blazing fast linux native version with a typically awkward homespun interface, I will eat my hat if they don&#x27;t choose the electron version. Sure, in a perfect world, all tools would be forged specifically for their intended purpose. In reality, you are in a miniscule percentage of people that would rather have nothing than something which doesn&#x27;t perform optimally because of it&#x27;s bonkers architecture. But if you actually want to maximize the usability of any giving tool, the only reason developers automatically go to performance is because to a hammer, everything looks like a nail. reply prmoustache 11 hours agorootparentprevYour postulate that it is electron or nothing is wrong from the very start. reply chefandy 11 hours agorootparentYou postulate that I said that, which is wrong.> IT shouldn&#x27;t be a default, but if it&#x27;s that or nothing-- as it often is when it comes down to limited resources-- I think it&#x27;s better than nothing.Sometimes it is. Sometimes it&#x27;s not. It&#x27;s certainly an option that&#x27;s very efficient for dev resources, which is often the primary limiting factor. It&#x27;s certainly the only real option if you&#x27;ve already got a team of web developers, which is very common.The current state of commercial software supporting linux with native apps is a pretty good indicator of how companies are viewing this equation. The amount of resources it takes to make a native java app is vastly different than the amount of resources it takes to make a native electron app. If you don&#x27;t understand how that would be something that would open the possibility of supporting linux in many cases, I&#x27;m not sure what to tell you. reply zlg_codes 10 hours agorootparentLook, business is about maximizing profits and minimizing costs. Business should absolutely not be looked to as an example of an entity that makes sane or suitable tech decisions over the long term. Their goals are different from everyday users, and both are different from power users and programmers.Why should normies suffer through worse software than those that know what they&#x27;re doing? Web-based \"native apps\" are that worse thing. reply chefandy 9 hours agorootparentReread what I wrote. I&#x27;m not saying they&#x27;re sane technical decisions and I&#x27;m definitely not saying that electron is an objectively good architecture for user-facing apps, and I&#x27;m definitely not saying that profit is a good way to determine an ideal engineering strategy. But trying to discuss the viability of an option in real-word software creation without acknowledging that profits are often the driving factor in these decisions means you&#x27;re not really discussing it. reply zlg_codes 1 hour agorootparentPart of that is because profit should not take precedence when making a technical decision unless you are a business.The other part is that if we accept only things that lead to easy profit, we&#x27;ll avoid all sorts of things that take more initiative but become better products. Short-term stock price chasing is not a way to make tech decisions. It&#x27;s a way to make profit decisions.I seem to be on a website where nobody can picture doing anything without taking money from someone else. replynmz 10 hours agorootparentprevI like to shit on electron because plain old tcl&#x2F;tk is a better&#x2F;leaner alternative. Apart from the myriad of other[0] alternatives that exist.[0]: https:&#x2F;&#x2F;github.com&#x2F;sudhakar3697&#x2F;awesome-electron-alternative... reply chefandy 8 hours agorootparentI think that anyone who recommends Electron to a young developer interested in learning native application GUI programming should be slapped. It&#x27;s the wrong tool for a specific job. That&#x27;s a pretty niche use case to judge overall worthiness against, though. reply zer0zzz 8 hours agorootparentprevI suspect the biggest issue with electron is that it leads to lots of devs packaging various V8 versions individually with their app. On windows they have been trying to get devs to switch to something called WebView2 where the OS provides an electron compatible chromium where unlike electron the resources are centrally managed by the OS. reply znpy 13 hours agoparentprev> and they don’t break as often.Meh, kinda.It&#x27;s not a case that proprietary software vendors only target RHEL, Suse and Ubuntu.RHEL is a perfect target for stable software and Ubuntu might be as well if you decide to only support LTS releases. reply zer0zzz 13 hours agorootparentTargeting only a hand full of frozen releases is not abi stability. Abi stability is when any app can be compiled off any release and run on any future release (and ideally older releases too). reply yjftsjthsd-h 13 hours agorootparent> Abi stability is when any app can be compiled off any release and run on any future release (and ideally older releases too).Hang on, if that&#x27;s the standard why is MacOS getting a pass? I&#x27;d believe that Windows meets that bar, but I see posts on a routine enough basis about Apple forcing rewrites, unless I really misunderstood something there. reply zer0zzz 12 hours agorootparentApple&#x27;s actually quite good at this, but they do break things on purpose from time to time for reasons which they announce pretty publicly at WWDC when they do (32->64bit, deprecating GL, etc).So, for example a dev can target an app at iOS 8 and it still works fine on iOS 17. Thats almost a decade of OS updates that didn&#x27;t affect an app. Here&#x27;s an example:https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;bebot-robot-synth&#x2F;id300309944 reply jwells89 4 hours agorootparentSimilarly, it’s possible to compile a Mac app that targets PowerPC, x86, and ARM supporting all of the versions of macOS implied by that spread of CPUs.X Lossless Decoder[0] is one such app, supporting all three archs and Mac OS X 10.4 up through macOS 14.x (current) in a single binary. It’ll work just as well on that circa 2000 400Mhz G3 iMac you picked up from a local yard sale as it will on a brand new M3 Pro MBP.[0]: https:&#x2F;&#x2F;tmkk.undo.jp&#x2F;xld&#x2F;index_e.html reply zlg_codes 12 hours agorootparentprevSuch a platform is doomed to never take a step forward because \"oh no, something changed and now I have to increment my dependencies\". reply zer0zzz 10 hours agorootparentThe Apple ecosystem of platforms take steps forward all the time, and they do a pretty good job at keeping binary compatibility with releases decently well while they are at it. They partly do this by only shipping C, ObjC and Swift platform frameworks though. replyzjp 14 hours agoprevMaybe I&#x27;m just too ignorant to know the pattern that determines whether I need to specify &#x27;dev&#x27; and &#x27;version&#x27; on a package or some random trailing &#x27;1&#x27; or &#x27;0&#x27;, but the first linux distro with a sensible and consistent naming scheme for packages is the one that wins my heart.`libgnutls-dev` `libgtk-3-0` `libwayland-server0` `libxcb1` `libx11-6` `libffi-dev` `libncurses5-dev` reply everforward 14 hours agoparent-dev contains the headers, that ones pretty easy.The number is a version for when they provide more than one that can be installed at once (excepting where it&#x27;s part of the library name, presumably like xcb1).I.e. at some point you could probably install libgtk-3-0 and libgtk-2-$something at the same time. They likely leave it that way when they get rid of libgtk-2 so that existing tutorials that reference libgtk-3-0 don&#x27;t fail because the package is now libgtk.The libwayland-server0 one does get me, I don&#x27;t know why there&#x27;s a 0 at the end. I do know that in &#x2F;var&#x2F;lib there is often the same library with various .$number endings, but I&#x27;ve never looked into what that accomplishes. reply seba_dos1 14 hours agorootparent> but I&#x27;ve never looked into what that accomplishesABI versioning. reply tesdinger 13 hours agorootparentABI stands for application breakage interface reply everforward 6 hours agorootparentprevOh, that makes perfect sense. I assumed there was a valid reason, and that makes far more sense than anything I could think of offhand. reply juunpp 14 hours agoparentprevSeparating binaries from sources is a Debian convention. If you&#x27;re just using a library, non-dev is sufficient. If you&#x27;re developing with that library, you&#x27;ll also want -dev, which will install the headers.Nothing special about the trailing 1 or 0; that&#x27;s just part of the package name&#x2F;version. reply tasn 14 hours agoparentprevArch and its derivatives (mostly) don&#x27;t have any of that.Though -dev means stuff only needed when developing against it.Number means major version number (so compatibility number). This way you can easily install multiple major versions as dependencies for different packages without clashing or breaking. reply sph 1 hour agorootparentArch Linux packaging is the only one that makes sense.If I install openssl, I want everything that upstream ships, which means command line tools, headers, libraries, man pages.The Debian&#x2F;Ubuntu convention is terrible, and anachronistic. Disk space is cheap, my time is not. reply o11c 14 hours agoparentprevIf you are building a program, install the -dev package. Numbered -dev packages are usually not relevant; there should be an unnumbered one that forwards if needed.During the build of a program, you record which numbered suffix (= ABI version, should be the same as the .so.N suffix but that&#x27;s not how you look it up; this allows you to install multiple incompatible copies of the library and they will be used by the appropriate, though distros usually prune these after each major release) is used. This should be automatic. (if there&#x27;s more than one number, all but the last are part of the library name itself. There might be exceptions for BSD-style libraries?)When installing, you should be automatically using the dependency you recorded during the build. reply nmz 10 hours agoparentprevThere&#x27;s gobolinux, which in my view solves everything and isn&#x27;t as complicated as nix... nobody cared. reply emptysongglass 11 hours agoprevThere&#x27;s a lot of complaints that there isn&#x27;t much in the way of tooling to create cross-OS compatible apps but I disagree. Just looking at solutions which aren&#x27;t Electron:- Telegram uses Qt and ships a performant native app across all three OSes- Flutter compiles down to native code across all three (and mobile)- Kirigami is a QtQuick framework that will give you an executable app across all mobile and desktop targetsGo and build your app. There&#x27;s no reason this needs to an excuse to flame on Linux. reply Longhanks 9 hours agoparentExcept Flutter is a subpar experience on every platform because of just how slightly different it behaves and Kirigami &#x2F; Qt Quick is just not a viable thing, there&#x27;s barely any community and&#x2F;or \"serious\" project on Windows, macOS or mobile. I&#x27;m not trying to discredit the KDE folks, but that is reality. Also, Qt Quick licensing is not so easy (or very expensive if you go commercial) for iOS.Whereas electron has a) big major corporations betting on it shipping extremely polished, Production-ready tools and b) a gigantic community and library ecosystem, plus not any obscure programming language (such as Dart).Telegram really goes the extra mile, though. Their client is amazing. reply jwells89 3 hours agoparentprevWhile the Qt Telegram app runs fine on macOS, most Apple users opt the Swift&#x2F;Cocoa client for macOS and iOS[0].[0]: https:&#x2F;&#x2F;github.com&#x2F;overtake&#x2F;TelegramSwift reply squarefoot 14 hours agoprevMore software? Wonderful! I&#x27;m all for it, but before starting something from scratch why not contribute to something that already exists, or possibly pick some project that was abandoned or simply needs to be worked on for example to be built with newer compilers, run on newer hardware, etc. Which makes me wonder if there is somewhere a database of dormant&#x2F;dead projects that would deserve to be resurrected. reply nmstoker 14 hours agoparentYes, I would echo this. In most categories there are loads of subpar efforts when putting all that effort behind the top few would yield a handful of excellent apps.Collaboration can seem daunting and hard work, but it&#x27;s work that will yield results which is time better spent than that devoted to projects that end up abandoned. reply zlg_codes 12 hours agorootparentWho gets to take the credit?I&#x27;m not convinced these efforts to put everyone&#x27;s ideas in one place and one software are good. Often, design disagreements arise which are incompatible. Under this model of \"everybody love everybody\" lameshit, if you can&#x27;t get the group to accept your idea, it doesn&#x27;t happen.You don&#x27;t run into this problem when you write alone. reply zlg_codes 12 hours agoparentprevThat something that already exists may not be built in the way you are aiming for.That other something might be led by a dickhead that you can&#x27;t get along with, or a community that&#x27;s not receptive to your suggestions or patches.Social processes and blockages can lead to losing motivation to contribute. Not everyone is cut out to be this happy-go-lucky team player that has no personality.As for myself, I&#x27;d rather start from scratch because 1) I&#x27;ll control every variable, 2) I don&#x27;t have to mess around with some existing social and tech infra, 3) I don&#x27;t have to talk to anyone and convince them my ideas are good, 4) who wants to spend more time arguing or discussing than writing code?The solodev experience is just better. You&#x27;re not hamstrung by politics and social process. Being a team player has only led to misery for me. reply 0xDEAFBEAD 8 hours agoparentprevI wonder if any of the major Linux package repos collect statistics that let you search for apps that are both (a) widely used and (b) unmaintained&#x2F;feature-incomplete. reply rubymamis 14 hours agoprevThe problem is OSS software not even trying to compete with the market. People using OSS software taking it for granted that the UX is going to be subpar, and it really is. Regular propriety software faces the risk of their users not paying, therefore adapting to make end user experience great. OSS usually doesn&#x27;t have that risk. Open source needs to be exposed to risk from end users.I tried to change that with Notes[1] but I find it hard to live on solely on ads. I tried to incorporate paying for some premium features (like Kanban) but the app is still fully FOSS therefore everyone can compile it from source easily.I think I&#x27;ll close-source my next app[2] before it launches. I just can&#x27;t risk not being paid for my hard work. I also believe the Linux community will benefit from that, since getting paid will allow me to invest more in making UX-focused apps on Linux. I might open source some parts of it tho (or maybe all of it in the far future).[1] https:&#x2F;&#x2F;github.com&#x2F;nuttyartist&#x2F;notes[2] https:&#x2F;&#x2F;www.get-plume.com reply alwayslikethis 14 hours agoparentThere is a large intersection of Linux users and people who cherish their freedoms. For many people, using non-open source note taking software is a non starter because of the vendor lock-in and privacy concerns. Thus, you&#x27;ll probably lose out more by not open sourcing the program than by open sourcing it and risk having some people not pay. I wager a lot more people is willing to pay than use proprietary software. Also note that open sourcing doesn&#x27;t require you to distribute the code to everyone, you can give source code only to paying users if you are charging them money, though they will have the right to modify and redistribute. If they don&#x27;t care about open source, they might as well just use Notion or Evernote. If someone is looking for an open source state of the art note taking program, I recommend Logseq. reply rubymamis 13 hours agorootparentI&#x27;m a big believer in open source software. I&#x27;ve had wonderful contributors and I&#x27;m using qutie a few open source libraries&#x2F;components in my own apps. That&#x27;s why I open sourced my own app.I&#x27;ve tried many different options so I could make a living with it (ads, donations, premium features). There are definitely more ways to explore. But for now, I need to ensure that my financial situation is stable before anything else. Then, maybe in the future I&#x27;ll be able to afford tinkering with a sustainable way of open sourcing.I&#x27;ve also started to notice many VCs starting to invest in open source software (just today saw Godot featured on HN). So that can also be a potential route. reply solarkraft 9 hours agorootparentIt&#x27;s great that you generally believe in FOSS. You deserve to profit from your work. I wouldn&#x27;t be opposed to paying (the app looks interesting). But I&#x27;d definitely want the security that, should you abandon the project, someone will be able to perform some maintenance. This is why I&#x27;m fairly okay with releasing the code late or licensed as \"FOSS if unmaintained\". Ardour&#x27;s model of charging for binaries doesn&#x27;t seem too bad either. reply rubymamis 2 hours agorootparentWell, your data will always be just plaintext. So you&#x27;ll be safe whatever happens.> This is why I&#x27;m fairly okay with releasing the code late or licensed as \"FOSS if unmaintained\"That seems reasonable. reply lupusreal 14 hours agorootparentprevThere are some programs that sell binaries but also give away the code.The premier pixel art editor Aseprite is free (source available, not open source) if you&#x27;re willing to build it from source yourself, but most users buy the prebuilt binaries. I think this way you satisfy both the privacy conscious &#x2F; cheapskates, and also the developer&#x27;s economic needs. RMS doesn&#x27;t approve I&#x27;m sure, but you can&#x27;t please them all. reply sph 1 hour agorootparentRMS totally approves, and selling binaries (as long as they are accompanied by source code) is explicitly approved by the FSF.Open-source has never been about hating money or working for the glory. reply em-bee 10 hours agorootparentprevif the license is GPL you can give away the source and sell binaries. you can even restrict giving the source to those that buy your binaries.red hat is doing that.the only limitation is that you can&#x27;t prevent anyone who has the source from building it themselves and giving away those binaries. but most people who do pay for the binaries won&#x27;t do that. so whether this strategy works depends on who is your target audience.if you are targeting developers you probably won&#x27;t sell much. but other audiences may be fine. i don&#x27;t know. reply throw10920 14 hours agoparentprevI think you&#x27;re making the right decision. Open-source is extremely difficult to make even a living wage off of - the number of people who do is orders of magnitude smaller than those who make a living off of commercial software. reply rubymamis 13 hours agorootparentIt&#x27;s definitely possible to make a decent living with FOSS software. One of the main contributors to my note-taking app is @bjorn[1] who developed the awesome Tiled editor[2] and managed to figure out a sustainable way to earn a living from donations&#x2F;sponsorships. There are probably more instances of that. I tried to go the same route, but other than a $5 monthly payment on Patreaon (thank you awesome contributor!) I couldn&#x27;t figure it out.I hate serving shitty Google ads. They are also not a stable source of income and the revenue is low in my case. It&#x27;s time for me to move on.[1] https:&#x2F;&#x2F;github.com&#x2F;bjorn[2] https:&#x2F;&#x2F;github.com&#x2F;mapeditor&#x2F;tiled reply throw10920 13 hours agorootparentOh, yeah, it&#x27;s totally possible - just do a HN search and you&#x27;ll find people who are doing it (e.g. Andrew Kelley, the Zig designer - and he&#x27;s making a programming language, which nobody will pay for in this day and age!).However, like being a social media \"influencer\" (e.g. Twitch streamer), it requires a lot of both hard work and luck, has a limited amount of \"capacity\", and isn&#x27;t a viable source of income for most people. reply lovelyviking 14 hours agorootparentprev>Open-source is extremely difficult to make even a living wage off of…So are you saying it’s even possible? I wish to learn at least one option to do it. Few is even better. How at all you can realistically make living this way?Ok, not living , just partial income. Ok not partial. Some income?I am not making fun of I honestly look some way .I understand that if you maintain 10 years some essential part of essential software project then people eventually come to you for consulting or will pay you to shift this part toward their requirements.But other then that? Like can you write useful free software program and really have some money from it ? reply throw10920 14 hours agorootparentThe main options that I&#x27;m aware of are: selling support (RedHat), donations (I can&#x27;t recall examples but they do exist), open-core (GitLab), and paid hosting (WordPress). In the past, there was also the option of selling physical media (which the FSF did for GNU projects, for instance) but that&#x27;s been killed by the Internet.All of these models are very hard to get working (e.g. the donations model requires that you have a very large number of people interested in your work who are generous with their money, kind of like Twitch streaming), but they can work. They&#x27;re not an option for the majority of programmers, though. reply shwouchk 14 hours agorootparentprevJoey Hess (https:&#x2F;&#x2F;joeyh.name&#x2F;) did, at least partially. I remember him raising money to develop git annex. reply hnlmorg 13 hours agoparentprevPersonally I think KDE is light years ahead of macOS and Windows.In fact I find macOS to have been be of the worst window managers of all the popular platforms (sure it’s pretty and easy to use, but trying to do anything beyond the basics requires magical incantations that are impossible to discover organically).Each to their own though. reply kcb 5 hours agorootparentKDE is the definition of all UI and no UX. Like there&#x27;s no one actually planning out how a user would&#x2F;should actually use the thing. That&#x27;s why I generally prefer Gnome despite it&#x27;s faults. Even if I don&#x27;t agree with every decision and lack of customization at least it feels like there&#x27;s some vision on how it should be used. reply rubymamis 13 hours agorootparentprevWell, I&#x27;m a Qt programmer (and love it!), so I know a bit about this ecosystem. Unfortunately in terms of UX and aesthetics, KDE apps don&#x27;t come even close to the macOS ecosystem.But that&#x27;s alright. I&#x27;m here to change that. reply lovelyviking 13 hours agorootparentCan you share some of this ‘love’ to me? Because my experience with QT so far was : it does ‘who knows what’, ‘who knows when’ and ‘who knows why’ And if you wish it to work the best tactic is “do not change anything, it will surprise you and there will be no way to go back” :)May be I am missing something important in understanding? I was trying to tweak some projects for my needs. I successfully did it but it was a nightmare. reply rubymamis 13 hours agorootparentIf you learn how to separate your logic in C++ and your views (GUI) in QML you can achieve the best of both worlds. C++ is fast and I love programming with it. QML is easy and powerful you can create slick looking apps with it with beautiful (and easy!) animations.I bought the Udemy course of Bryan[1] and learned QML in one day. The next day I already had a prototype for a Kanban[2] that is based on Markdown.[1] https:&#x2F;&#x2F;www.udemy.com&#x2F;course&#x2F;qml-for-beginners&#x2F;[2] https:&#x2F;&#x2F;rubymamistvalove.com&#x2F;notes&#x2F;kanban.mp4 reply tfinch 8 hours agorootparentThat second link is the the sort of thing I wish I saw more being pushed as an example of QT. Looks great! reply rubymamis 2 hours agorootparentThanks! I know, it&#x27;s totally possible to create beautiful apps using Qt. The problems are:1. Most people in OSS don&#x27;t care about UX and aesthetics (most of the people using Qt) 2. The Qt Company&#x27;s examples are absolutely ugly (with the exception of one). If that&#x27;s what you show developers they would either not believe it&#x27;s possible to create beautiful apps with it or that it&#x27;s too hard. replyaskonomm 12 hours agorootparentprevKDE _functions_ well, but my god does it need someone with an actual design education to help out. reply hnlmorg 10 hours agorootparentPeople with actual design education created macOS and Windows 11. Both of which strip back features in the name of design purity.I see KDE more like a professional piece of equipment. And when viewed through that lens, I think it’s designed rather well. reply sph 1 hour agorootparentIt is very naive to believe that professional equipment do not benefit from well-thought design and UX.Design does not have to be fancy colours and flashy animations. Design does not mean Fisher-Price UI and massive amounts of whitespace. Ask Dieter Rams. reply askonomm 9 hours agorootparentprevTo be fair, the upcoming KDE release cleans up a lot of my UI annoyances (like having frames within frames), so it is definitely getting better. reply lovelyviking 13 hours agorootparentprevCan you elaborate more? What features you are talking about?I can criticise Mac OS endlessly and was even actively downvoted here when reported facts of my personal experience with bugs on newly purchased M1 (you can dig the history if you wish). I was shocked how quality degraded in my opinion.People here were even claiming that it’s my specific faulty machine was to blame. This ‘faulty’ machine by the way works to this very day without any hardware problems except flickering of the monitor which is idiotic in my opinion design decision (to use PWM).So as you can see I am very critical of macOS and consider using Windows after macOS like completely unbearable. And yet your comment have puzzled me.When I was learning macOS after years with Windows I remember that certain things were like you say “impossible to discover”. Yet with all that being said I find other GUI implementations in GNU&#x2F;Linux not any better.Perhaps I’ve missed something in KDE? What did I miss? What “doing anything beyond basic” means in your usage? What kind of tasks&#x2F;workflows are those ? How KDE better in those? reply bachmeier 13 hours agoparentprevA few thoughts:1. I&#x27;ve never heard of your app, and I follow this space closely. It&#x27;s extremely competitive.2. I clicked to check how much you&#x27;re asking for premium. It&#x27;s reasonable on an annual basis, but I only saw an option for a monthly subscription. That&#x27;s not happening.3. I&#x27;d be more likely to give you a donation than to pay for a premium version for an app like this. That model has worked well for Obsidian. I don&#x27;t think getting early access to features is worth much, but a lot of people have paid them to support their work.4. My observation is that a closed core product with a large open source ecosystem around it gives folks a reason to pay. reply rubymamis 12 hours agorootparentHi! Thanks for your comment.> but I only saw an option for a monthly subscription.What do you mean? The annual subscription doesn&#x27;t work? Or something else?> I&#x27;d be more likely to give you a donation than to pay for a premium version for an app like this.Well, for my Notes app, I can understand. Hopefully you will find my new app as a breath of fresh air in this space. Sign up to get an update please! I would love to hear what you think when the app is out.> My observation is that a closed core product with a large open source ecosystem around it gives folks a reason to pay.Overall, I think people will pay if an app gives them enough value. reply vcg3rd 12 hours agoparentprevI understand your frustration, but I have a couple of counter-examples, and I don&#x27;t offer them in any derogatory way.1) Notes looks a lot like Standard Notes. If you built Notes using copy-left, OSS it&#x27;s hard to complain unless you pay \"royalties\" to all the programmers whose work was incorporated into yours.2) I am probably atypical. I have used Linux for over 20 years, but I can&#x27;t write so much as a Bash script or a Perl one-liner. Yet I have spent a whole lot more money on software than I would have (or most individuals do) on other platforms. Because I can&#x27;t code and appreciate the work of others and the freedom it gives me I support the following (not exclusive):* Kaisen (my distro) and Debian (the distro Kaisen is built on) both* tFSF for both core utilities and Emacs* My DE (KDE), and even if I prefer the UI of other applications I mostly try to use those provided by KDE,tFSF, Debian, or Kaisen (e.g Akregator over RSSGuard) unless I donate, like:* Mozilla (for Firefox), but* Betterbird for my email client* Syncthing* LaGrange (gopher&#x2F;gemini)* Joplin* ClipTo* and more, including services (e.g. SoulSeek, envs.net)Some annually, some monthly, some one-time.In fact, when Standard Notes first came out I paid for a seven year subscription, and then ended up using it for about 2 months before becoming dissatisfied. There are some, like Alacritty, that I use extensively but which I have found no way to donate to, but I try to keep it to a minimum. reply rubymamis 12 hours agorootparentThere are some amazing people that valued what I&#x27;m doing. One person even donated $1000 years ago. But that doesn&#x27;t make it sustainable.I think it&#x27;s time for me to compete on the market. I believe Plume is going to be a good addition to the pool of productivity apps today, but I&#x27;ll let people judge that when it&#x27;s released. I hope you will sign up to get an update[2] and let me know what you think of it when it is released.BTW, are you suggesting I copied Standard Notes? Not really, I don&#x27;t like their design. Notes is in active development since 2014 (first commit on GitHub in 2015), back then I didn&#x27;t even know about Standard Notes and the core design barely changed.[1] https:&#x2F;&#x2F;github.com&#x2F;nuttyartist&#x2F;notes&#x2F;releases&#x2F;tag&#x2F;v0.8.0-bet...[2] https:&#x2F;&#x2F;www.get-plume.com&#x2F; reply devaiops9001 10 hours agoparentprevI am in an interim CTO position and the year before the title of a role I acted as had \"Principal\" in its title. I still write Commonmark files to render them to HTML and PDF with Pandoc.There are dozens of Markdown note taking apps out there. There are half a dozen Notion clones out there. I know which one will overwhelmingly win mindshare due to a special feature but I won&#x27;t give away why (the feature itself is more valuable than a Notion clone or even Notion itself).You might be able to get paid for providing something valuable to others. Sometimes hard work is involved in providing value to others, but performing hardwork doesn&#x27;t necessarily mean you have provided value to others. reply rubymamis 2 hours agorootparent> but performing hardwork doesn&#x27;t necessarily mean you have provided value to others.Very much agree. I guess only time will tell (when I launch). reply freedomben 13 hours agoparentprevThere are definitely some challenges with getting people to pay for OSS, but I wouldn&#x27;t be so quick to blame that all on what happened in this situation. I think you&#x27;d be experiencing the same (or worse) if your app was closed source for reasons I&#x27;ll mention in a minute.I&#x27;m the exact type of person who would be in your target market and likely to pay, but aside from having never heard of your app (which may be your biggest problem), these are the reasons I&#x27;m not buying. I&#x27;m only sharing this in the hopes that it helps you, not trying to make you feel bad or anything like that. Overall I think you&#x27;re awesome for making your app open source, and I have a mountain of respect for you for doing that.1. You&#x27;re targeting a very crowded and competitive market where top-quality options are 100% free. This would be a huge challenge regardless of whether you&#x27;re open source or not.2. Your app is still very young&#x2F;new. Winning in such a saturated area is going to take some time to even build awareness, let alone get mature&#x2F;feature complete enough to get people to change.3. With something like notes, you&#x27;re looking at people with substantial pre-existing sources. Migration is not trivial either, so there&#x27;s a big barrier of entry there for people to use your software.I wish you the best, but I think you&#x27;d only be harming yourself by closing your next app. You definitely lose people like me for whom my notes are incredibly important and I won&#x27;t risk losing them to a proprietary tool. Open is mandatory for me to even consider it.I&#x27;m pretty happy (maybe even in love) with Logseq, but the performance is definitely a downside and the idea of a C++ app is highly appealing to me, so I&#x27;m going to give your app a try.Side note: If your GUI was compatible with logseq&#x27;s on-disk format, that would make your app quite compelling to me reply rubymamis 13 hours agorootparentI appreciate your opinion.Notes has been quite a success for me. With over 1,300,000 downloads[1], and being featured in awesome tech websites[2]. Just on Ubuntu alone there are 7000 weekly active users (that have downloaded it from the Ubuntu Store).My new app Plume is going to be a big improvement over Notes. First, your data is and will always be as simple as Markdown&#x2F;plaintext. My new block editor is based completely on plain text while still offering advance views (with a minimalistic syntax). It&#x27;s also faster than any other in its category, even faster than native apps on macOS! I&#x27;ll soon put benchmarks on the website.All I can say is, sign up to get an email update and check it out when it&#x27;s ready. Most of the features will be free with only some advance features paid.BTW, what do you mean by \"logseq&#x27;s on-disk format\"? That it&#x27;s local-first? If so, Plume is also.[1] https:&#x2F;&#x2F;tooomm.github.io&#x2F;github-release-stats&#x2F;?username=nutt...[2] https:&#x2F;&#x2F;www.omgubuntu.co.uk&#x2F;2022&#x2F;09&#x2F;open-source-qt-notes-app... reply freedomben 8 hours agorootparentWell dang! I didn&#x27;t realize it was that big. That is impressive and definitely changes my opinion a bit. It&#x27;s quite unfortunate to have such low paid numbers with that many downloads.By logseq&#x27;s on-disk format, it is local first but it&#x27;s a stricter subset of markdown with a handful of extensions. The strictness is because Logseq parses all the markdown into an in-memory graph database, and in order to make that work with markdown the top-level has to be a list and needs some IDs and other identifiers in order to properly link&#x2F;embed blocks and pages and such. reply rubymamis 2 hours agorootparentThanks! With Plume I use a tree data structure (just with parent child relationships), although in the future I would probably use Boost::ptree.The things is, the underlying data structure is just plaintext, so having an ID for each block will make the plaintext look out of place (say, if you wanna move your files to another app).But I&#x27;ll add some special syntax to allow this feature for specialized blocks. reply binkHN 9 hours agoparentprev> People using OSS software taking it for granted that the UX is going to be subpar...After using the abomination known as Windows 11, I&#x27;d argue that the UX of Linux is well beyond par, especially when par for Windows 11 is showing Microsoft ads at you while you&#x27;re using almost every application. reply weikju 8 hours agoparentprevNotes is a beautiful app! Wow.Regarding Plume: just from that landing page, it looks 100% like Notes. Anyway, I&#x27;m interested to learn more about it when it launches! reply kilolima 13 hours agoparentprevI really like the functionality of your notes app, but I don&#x27;t think emulating Apple UI design is the solution to subpar UI on Linux.Linux users expect basic desktop conventions like toolbars, dropdown menus, and not mobile design concepts like cramming everything into a hamburger menu. reply rubymamis 12 hours agorootparentHave you even tried using my app? It doesn&#x27;t have any of the \"mobile design concepts\" that you&#x27;re talking about.> cramming everything into a hamburger menu- Import&#x2F;Export- Check for updates- Start automatically- Hide to tray- Change database path- About Notes- QuitIs that EVERYTHING?No. It&#x27;s not. I don&#x27;t like using hamburger menus for everything myself. This is why the options are minimalistic. Look at other Gnome apps using hamburger menus, no need to go as far as \"Apple UI\" (which actually discourages hamburger menus for desktops apps). reply SushiHippie 14 hours agoparentprevWhat&#x27;s the difference between \"notes\" and \"plume\"? reply rubymamis 14 hours agorootparentPlume&#x27;s editor is a block-editor I wrote completely from scratch using C++ (model) and QML (view). This allows me to create an advance editor that can have complex elements (like Kanban, Columns, advance image components, etc) within the text. The performance using Qt C++ compared to Electron is a mssive improvement over current web apps (like Notion and the likes), and actually, i&#x27;s even faster than native apps on macOS (Craft, Bike) and apps made in Flutter (AppFlowy).Example: https:&#x2F;&#x2F;imgur.com&#x2F;wajSjbn (I&#x27;ll implement the Kanban feature next week (:) reply SushiHippie 10 hours agorootparentOkay that&#x27;s actually cool, that you switched to something else than electron, but it looks nearly identical from the screenshots, that&#x27;s why I asked. reply godelski 14 hours agorootparentprevHows it different from Obsidian or any other note taking app that has a larger community. I&#x27;m sure OP put in lots of hard work and it looks good, but it&#x27;s not apparent to me why I should abandon my existing platform (stickiness) for another one. There are a lot of note apps out there already which probably makes it hard to sell. reply tomcam 14 hours agoparentprevThanks for sharing. Appreciate your fighting the good fight, and sorry for the results so far. Maybe apply for a Futo scholarship for one? But definitely close source for Plume. reply rubymamis 13 hours agorootparentNo need to be sorry, really. I&#x27;m just learning how to navigate this world. I&#x27;ve been pretty lucky so far. Notes is one of the top results in Google (for the keyword \"notes\"). So I get a lot of traffic and a nice passive income. But it&#x27;s not something I can fully live on (plus it&#x27;s unstable and I hate serving ads). reply tomcam 7 hours agorootparentHosting? reply rubymamis 2 hours agorootparentWhat do you mean by hosting? reply lovelyviking 13 hours agoparentprevon your ‘com’ site mentioned in github page download button does not offer (near by) payed options. Why? Why it is only in the separated Pricing link? Why not to present the same choice in download ? reply rubymamis 12 hours agorootparentThanks for your remark! I never thought about it. I suspect it will drive down the number of downloads? How do you think it will be beneficial? reply lovelyviking 10 hours agorootparentI think it could be beneficial because it would be easier for those who wish to pay. They would not have to do extra step looking for that opportunity.I personally do not like (in soft words) when button says one thing and delivers something else. So I think renaming Download into ‘Download options’ were you give choice download ‘ free’, ‘donate’, ‘pay for pro’ etc as you like is acceptable and feels good enough. I do not see why in that case it should reduce number of downloads but every prediction is always a prediction and nothing is better then the real life test. reply thebigspacefuck 14 hours agoparentprevWhat does this have that Joplin doesn&#x27;t have? reply 360MustangScope 14 hours agorootparentFor one thing, it’s a lot prettier than Joplin reply thebigspacefuck 13 hours agorootparentPersonally I think Joplin looks better and this looks like a poor macOS clone that lacks many of the features like markdown support or synchronizing across devices including mobile. IMO if Joplin’s problem is the UI, or even just something OP is passionate about, why not contribute and open a PR? Why is the pattern “I care about this one thing so I reimplemented it in a new app from scratch”? reply rubymamis 13 hours agorootparent- Plume supports Markdown (plus additional plaintext syntax).- Plume is a block editor, unlike Joplin. Therefore plume can have advanced views inside the editor itself (like Kanban, image handling, columns, etc)- Plume is faster than Joplin&#x27;s non-native editor (the one that renders your Markdown)- IMO Plume is way prettier with far more attention to detail. reply beebmam 14 hours agoparen",
    "originSummary": [
      "The summary emphasizes the need for more applications on Linux and encourages developers to create new apps instead of focusing on creating more Linux distributions.",
      "It highlights the benefits of app development, such as fulfilling personal needs, inspiring new developers, building communities, learning new skills, earning income, and targeting diverse Linux distributions.",
      "Developers are provided with resources and platforms, such as GNOME, KDE, elementary OS, Electron, and Ubuntu Touch, to start creating Linux apps.",
      "Industry professionals stress the importance of a thriving app ecosystem for Linux.",
      "Various tools and platforms for publishing and distributing Linux apps, including AppCenter, AppImage, Flatpak, Open Build Service, and Snapcraft, are mentioned."
    ],
    "commentSummary": [
      "The discussion highlights the challenges of app development in Linux, including issues with stability, compatibility, and fragmentation in distributions.",
      "It addresses the need for unified solutions in Linux, particularly in selecting SDKs and handling payments.",
      "Other topics covered include the lack of Unicode support in Linux's libc, the impact of the glibc library on software stability, and the use of Electron for app development."
    ],
    "points": 267,
    "commentCount": 313,
    "retryCount": 0,
    "time": 1702140649
  },
  {
    "id": 38586512,
    "title": "Mozilla's Efforts Pay Off: Firefox Speed Boosted by 50%",
    "originLink": "https://blog.mozilla.org/en/products/quick-as-a-fox-firefox-keeps-getting-faster/",
    "originBody": "Products Quick as a Fox: Firefox keeps getting faster October 31, 2023 Perla Duenas Web browsing is a pervasive part of modern life, and the quality of the experience directly affects the quality of your day. When your tasks are disrupted by slow or unresponsive pages, it is frustrating and distracting. As such, performance is a key component of Mozilla’s vision for the web. To deliver against our vision and enable a better online experience for everyone, we’ve been working hard on making Firefox even faster. We’re extremely happy to report that this has resulted in a significant improvement in speed over the past year. Improvements on benchmarks One way to judge browser performance is by using industry benchmarks. We have seen measurable improvements here, specifically around the popular benchmark Speedometer 2.1. This benchmark measures browser responsiveness by simulating user interactions (such as manipulating a list of to-do items). Since January 2023, Firefox’s Speedometer score has improved by 50%, a significant performance improvement for our users. Performance on the web Yes, benchmarks matter, but it’s worth pointing out they only simulate what a user could experience. It was important for us to verify that the performance improvements were actually being felt by users. We’ve observed improvements on performance metrics that matter. In particular, pages are appearing 15% faster on average: It is extremely gratifying to see that the improvements in benchmark scores are actually being felt by Firefox users everywhere. If you’re interested in getting more technical details, check out our recent blog post on Mozilla Hacks. It’s been an exciting year for the Firefox Performance team – and we’re not stopping any time soon. This is a preview of the work we’ve been doing, and we’ll be sharing more technical detailed posts in the next few weeks on Mozilla Hacks. Get Firefox Get the browser that protects what’s important",
    "commentLink": "https://news.ycombinator.com/item?id=38586512",
    "commentBody": "Firefox Keeps Getting FasterHacker NewspastloginFirefox Keeps Getting Faster (blog.mozilla.org) 257 points by goplayoutside 12 hours ago| hidepastfavorite215 comments jetrink 11 hours agoI&#x27;d like to see better stability. My biggest issue with Firefox on Windows right now is that it hangs if I leave it open for several days. Mozilla does have a suggestion on their support site: don&#x27;t do that[1]:> Firefox hangs after using it for a long time> Firefox may hang if left open for long periods of time. To fix the issue, restart Firefox.So I can choose between closing all of my open tabs at the end of each workday or randomly losing them during the workday. Since having my tabs open when I start work helps me jump back in, I&#x27;ve settled on randomly losing my tabs.They also suggest using their session restore feature after a hang, but with this type of crash, Firefox is never able to restore your tabs. It also doesn&#x27;t record the crash report in about:crashes. Overall, not great and it has me thinking of trying Brave.1. https:&#x2F;&#x2F;support.mozilla.org&#x2F;en-US&#x2F;kb&#x2F;firefox-hangs-or-not-re... reply MrJohz 10 hours agoparentYou can get Firefox to open all the tabs you last had open when it starts up, this way you can close and open Firefox whenever you want, and you&#x27;ll always be right back where you started.This doesn&#x27;t save the page state, so if you were filling in a form, you&#x27;ll lose that information, but it does mean that wherever you reopen Firefox, you end up pretty much exactly where you were when you closed it.I guess you&#x27;d still need to regularly close and reopen the browser as a whole (I do that at end of the day anyway when I turn my machine off), but it may be more convenient than losing state. reply calamari4065 4 hours agorootparentFirefox has had this feature for over a decade, and it has never worked reliably. It&#x27;s slightly better now, but still one time in five or ten, it starts up in a blank session or with an error page prompting you to press a button to restore state.I lived through the days where force closing Firefox was the only way to preserve sessions. Things honestly aren&#x27;t that much better. I&#x27;d take a zero percent chance of success over 80. At least then failure is known and predictable instead of just reliable enough to get you to trust it. reply oarfish 4 hours agorootparentCurious. I&#x27;ve used Firefox for many years and never experienced this problem, not on macOS at least. reply davidgerard 52 minutes agorootparentprevI have literally never had it fail, in years. reply SilasX 10 hours agorootparentprev\"Where you were\", except for waiting for every page to reload. reply abhinavk 10 hours agorootparentIt only loads the page when you switch to it. reply josefx 8 hours agorootparentYou know that this makes it only worse unless you go through all tabs manually after starting to make sure they are actually loaded when you need them?Having to wait half a minute on every tab switch to wait for that gigantic mess of enterprise grade websites served from an ancient box on the other side of the solar system to load is not conductive towards concentrated work. reply SECProto 8 hours agorootparentprev> except for waiting for every page to reload.When I lose firefox (usually when power outage) I just cycle through all the tabs with ctrl+tab, by the time I get back to the first one it has reloaded (and the others do so in the background). It&#x27;s not a big deal. reply MrApathy 6 hours agorootparentRight click on a single tab > Select all tabs > Reload tabs. reply SECProto 6 hours agorootparentThanks for the advice - hopefully it helps others. For me, it happens infrequently enough that I am unlikely to remember anything specific for the situation. I never select multiple tabs otherwise. reply unloco 9 hours agorootparentprevare you on dial-up? reply squeaky-clean 8 hours agorootparentJira takes 10s for certain pages to load for me on a gigabit connection with an M1 Mac. I doubt a dial-up connection could even load a Jira backlog page in under an hour. reply cycomanic 7 hours agorootparentFunny you mention Jira, so you&#x27;re saying there is no information after a day that requires you to reload? reply PhasmaFelis 8 hours agorootparentprevSame, but I&#x27;m not sure if that&#x27;s because there&#x27;s too much data or just because Jira is slower than a dead snail. reply eek2121 9 hours agorootparentprevI have a 10gb connection and I still see that. Browsers, despite being excellently threaded, are also poorly threaded. Who knew? reply calamari4065 4 hours agorootparentprevModern websites are simply enormous and slow. reply ksec 3 hours agoparentprevAs someone who used to have hundreds if not thousands of Tabs, Firefox is the only browser that is stable enough and has the best Tab Session restore. So my guess is that something went wrong if you have to constantly restart Firefox.Firefox has a sessionrestore.js and also a sessionrestore.bak. ( And also sesstionrestore.bak2 if I remember correctly )[1] It is the only browser that took session restore seriously because around ~16 years ago an idiot constantly went on Mozillazine and Bugzilla to file crash report of lost sessions that could have thousands of tabs.If your sesstionrestore crashed or get wiped, i.e you restart your browser and those tabs were not there, you could also copy and past the .bak files and rename it as .js. It wont be everything you had since the bak file may have been a few hours old. But at least you got something back.As to crashing. In the old days it was some tabs in the background doing JS with memory leakage. But if I remember correctly Firefox now pause Tabs that is unused for long period of time. If it isn&#x27;t background Tabs that is causing problem. I would suggest similar to what I wrote to Animats, make a new Firefox profile and migrate all your History, Cookies etc to the new profile and see if it improve things. This used to be a manual process but I believe recent Firefox has made this easier with Firefox Retune or Refresh ( Sorry all of this are on top of my head you will have to do some Google search for the actual name)If I were to rate Browser stability, it would be Firefox > Chrome > Safari. On both MacOS and Windows. The same ranking for session restore function where I have lost multiple sessions on Safari over the years. And in case anyone wondering why Safari is not stable and that may not be their experience, it is that something on MacOS ( the OS itself ) sometimes triggers Safari to reload all the Tabs even if they were originally sitting idle. This create huge I&#x2F;O spike and generally leads to crashing or halt for a long period of time. Other than that it is pretty much on par with others.[1] Those file and extensions names were something on top of my head so you have to google it to double check reply josephcsible 9 hours agoparentprevThis might be a Windows issue rather than a Firefox issue. I have a lot of tabs open in Firefox on Linux, for days to weeks on end, with no issues. The only time I restart it is to upgrade to a new version of Firefox or after installing a system update that requires a reboot to fully take effect. reply SECProto 8 hours agorootparent> This might be a Windows issue rather than a Firefox issueI leave multiple tabs open for weeks+ on Windows (and android), I have never experienced any issue (except when windows decides to update - but firefox always restores itself without issue, or I can press ctrl+shift+t to reopen previous tab&#x2F;session). There must be something specific to the other commenter&#x27;s setup, whether it be specific addons or specific pages that are causing the crash. reply Animats 9 hours agorootparentprevIt hangs on Linux, too. It&#x27;s seriously annoying.Plus, there&#x27;s a delay of up to 2 minutes at launch, when Firefox reads something from disk for minutes, with minimal compute.Bug reports on this result in denial. reply capitainenemo 8 hours agorootparentIt could be you are using different apps from them so they never noticed. I&#x27;ve noticed some web \"apps\" have leaks that over time can bloat out memory usage leading to swap thrashes. gmail.com for example.It was quite visible in top or about:memory or about:processes reply Animats 8 hours agorootparentIt&#x27;s not computing or swapping. Plenty of memory and CPU time available. It&#x27;s just Firefox doing its own disk I&#x2F;O. I cleared history, and that didn&#x27;t help. reply capitainenemo 8 hours agorootparentAh.. No idea then. Windows debugging not my thing. I do know from a discussion w&#x2F; a Windows user that loading the same app (Microsoft Teams) took over a minute to load on his windows machine on an HD (and locked up most of the machine while doing so) - I did exact same comparison on my Linux machine and MS Teams loaded with all caches flushed inIt only works on the last window you have closed though.Alt+F, Q exits all windows at once and also restores them the next time you launch firefox. reply tempestn 10 hours agorootparentOr Exit under the hamburger menu, if you don&#x27;t want to remember the keyboard shortcut. reply mixmastamyk 10 hours agorootparentprevCtrl+Q or Cmd+Q for Mac. reply simcop2387 10 hours agorootparentprevIt will work on all open windows if you close them at the same time. File->Quit, ctrl+q or cmd+q are all ways to do that. reply inferiorhuman 10 hours agorootparentprevYeah it does the same for me (macos) after a few days. Open previous windows and tabs should restore all windows though (at least it does for me). reply IAmGraydon 9 hours agoparentprevI can&#x27;t remember ever having a Firefox crash in the last few years. Running it on one machine with Win 10 and another with Win 11. Only extension is uBlock Origin. I often will leave it open for many days. reply lostmsu 8 hours agoparentprevGood chances are Firefox is not at fault here as many people run it without issues for months in a row.Maybe you should check it for suspicious DLLs using Process Exporer or outright attach a debugger and see what the UI thread is blocked on when it stops responding. reply tux3 10 hours agoparentprevDo you have any weird plugins or addons by any chance (maybe even antimalware or other malware that you might not have installed explicitly)?It&#x27;s strange that it wouldn&#x27;t report this as a crash. They&#x27;re normally pretty good at telemetry (sometimes to a fault..) reply jetrink 10 hours agorootparentI only have Bitwarden, uBlock Origin, RES and Vue Devtools installed right now. reply RamRodification 9 hours agoparentprevI&#x27;d be surprised if this is not caused by an extension. Have you tried disabling all of them, or one at a time until you&#x27;ve ruled them all out? reply SkyMarshal 10 hours agoparentprevSession manager plugins solve this in my experience. It&#x27;s a little annoying that FF doesn&#x27;t already have this and you have to use a plugin for it, but only a little. reply davidgerard 10 hours agorootparentGo to Settings. The very first thing I see is:GeneralStartup[X] Open previous windows and tabs reply squeaky-clean 8 hours agorootparentFrom their comment:> They also suggest using their session restore feature after a hang, but with this type of crash, Firefox is never able to restore your tabs. It also doesn&#x27;t record the crash report in about:crashesAlso the setting you suggested doesn&#x27;t work if you have multiple windows that close. It only saves one window session. reply davidgerard 54 minutes agorootparent> Also the setting you suggested doesn&#x27;t work if you have multiple windows that close. It only saves one window session.?? It does? I have like 20 windows on the go with multiple tabs each and it brings them all back.There&#x27;s people in this thread repeating claims that are literally not true. reply SkyMarshal 9 hours agorootparentprevYes but OP is saying that built-in ability doesn&#x27;t work for him for whatever reason.In my case I like to be able startup the browser without opening all the prior tabs, but then be able to selectively reopen the prior tabs by window or by individual tab. That&#x27;s what session managers do. reply addandsubtract 9 hours agorootparentprevAlso, you can go to History > Restore last open tabs reply mixmastamyk 10 hours agorootparentprevIt does have it. reply cobalt60 6 hours agoparentprevI rarely reboot my workstation; it&#x27;s often in hibernation for days or even weeks until a security update is waiting for a cycle. Despite this, my Firefox on both Windows&#x2F;macOS consistently maintains my tabs, each running smoothly in their own containers without any issues. reply cptskippy 9 hours agoparentprevHow many tabs do you have open? I use a Windows VM hosted on my server and Firefox sits open on it for weeks at a time with 20+ tabs open.It only ever lasts 3-4 weeks because Windows has to reboot for patches at least once a month. reply JadeNB 10 hours agoparentprev> So I can choose between closing all of my open tabs at the end of each workday or randomly losing them during the workday. Since having my tabs open when I start work helps me jump back in, I&#x27;ve settled on randomly losing my tabs.I know it&#x27;s just paper over the real problem, but couldn&#x27;t you restart at the end of the day rather than at the beginning? reply andrepd 10 hours agoparentprevFor what&#x27;s worth, I have my Firefox open since June. reply addandsubtract 9 hours agorootparentDon&#x27;t you need to restart Firefox for it to update? Did you not update since June? reply redder23 7 hours agoparentprevWhy would you need to have your PC you browse the web on for days? Why would you be bothered with restarting a browsers at least once every 24 hours. I also call this dubious at best, I NEVER had any stability issues with FX and I pretty much used it since day 1.You probably one of those people who confuse tabs with bookmarks and think you should have 500 tabs open with only 4 gigs ram and having not shutting your PC or Browser down for weeks. It that causes issues I think Mozilla should have that on low priority.I use Brave on Linux mainly because I cant justify testing my webdev stuff not con Chromium and I tend to use the same Browser for everything, its also faster.Mozilla like so brag about speed but I think the lost objectively measured to Blink a looooong time ago. Servo was given to the Linux Foundation and is far from ready. When its ready it will probably be pretty fast. reply raybb 11 hours agoprevMy phone is a bit old (Pixel 4a) but it drives me crazy that so many times I type something into Firefox and it just shows a blank screen. Then I have to restart the app or open a new tap and type again. Feel it happens at least 20% of the time. No idea why and its not an internet issue. There is no loading. There is nothing. reply skullone 11 hours agoparentMy pixel5 is doing good with Firefox. I credit as blockers for keeping the browser performant reply raybb 11 hours agorootparentYeah the blockers are awesome. Also having a few greasemonkey scripts to automate login on a few pages that require too many clicks. reply SoKamil 11 hours agorootparentTry clean install. Maybe extensions and userscripts are messing with you. reply raybb 10 hours agorootparentI&#x27;ve tried a few times and tried FF beta but no difference. reply cycomanic 7 hours agorootparentI used to have this issue on nightly (not annoying enough to make me consider switching though), but it dissappeared several months ago, haven&#x27;t seen it since. Are you sure it&#x27;s still happening reply Murfalo 10 hours agorootparentprevI have the same issue quite frequently... If I knew any decent alternative with uBlock (or equivalent) I&#x27;d switch on the spot! On a Pixel 6. reply treetalker 11 hours agorootparentprevRespectfully: doing well. reply andwaal 10 hours agoparentprevSame issue for years, fist on a huawai p30 and now in the Samsung s21. Been so long now that I have accepted it as a feature. reply sphars 11 hours agoparentprevI had the same problem on my 4a. I&#x27;ve since upgraded to a Pixel 8, and I still have the blank screen problem. Notably with a PWA, has to be killed and restarted. This is on Fennec (so FF dev basically). Annoys so much, chromium-based browsers don&#x27;t have any issue. reply flas9sd 8 hours agoparentprevdo you still actively see this or is it a behaviour that occured a few months ago? I remember https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1840665 reply ivanjermakov 11 hours agoparentprevIs it possible to dump logs and about:support to create a bug ticket? I&#x27;m sure this will be looked at pretty quickly.Tracker: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;home reply Borgz 10 hours agorootparentHow do you dump logs? reply neoromantique 11 hours agoparentprevOddly enough I had same experience on an iPhone too, despite it only being an interface wrapper over safari reply dmacvicar 10 hours agoparentprevI haven&#x27;t seen this problem on a Pixel 4a running Calyxos. reply Jap2-0 10 hours agoparentprevI have not seen this problem on my 4a. reply ptrrrrrrppr 11 hours agoparentprevHave the exact same issue on my 1+ reply Sakos 11 hours agoparentprevBeen getting that too. No idea why. Interestingly, I&#x27;ve experienced it a handful of times on desktop too. 99% of the time it&#x27;s the Android app doing it though. reply JadeNB 10 hours agoparentprevI had this happen repeatedly but relatively rarely on a Galaxy A51, and now on a Galaxy A54. I don&#x27;t browse on my phone much, but it felt like much less than 20% of the time. At least, it was rare enough that I&#x27;d always forget it happened until it smacked me in the face again. reply dingusdew 11 hours agoparentprevIn my experience, this only happens when I type in a new address in a tab that is already open with a different website.When I try to navigate somewhere else, it hangs, looks like it&#x27;s loading, but gets... stuck?However, always works with new tab.Also on Pixel 4a. It&#x27;s not that old, jesus. reply Almondsetat 10 hours agoprevFirefox keeps competing on the wrong things.See ARC browser. It&#x27;s developed by a minuscule team but what they do is turn the experience of browsing the web into pure smooth pleasure. They will never in a million years gather enough talent to outcompete the V8 engine, but what they can do is develop better user workflows to empower them.Firefox could be such a workhorse of a browser. They could add so many features to make the lives of academics, researchers, journalists and professionals in general better. Who cares if it&#x27;s a bit slower than Chrome if it allows to efficently write my article or keep together the sources for my thesis? reply yardstick 10 hours agoparentI like the plugin approach for this.I don’t have a need to efficiently write an article in a browser - or code within a browser which is more my thing. I have a dedicated IDE for that, and leave browsing to browsing.Browsers imo should just be browsers and leave the end user applications to the web app developers, plugin developers, etc. So in that sense I’m happy with where they are, and very happy they are doing their own stuff rather than being another Chrome-based browser. reply Almondsetat 10 hours agorootparentPlugins are terrible though. If I truly want vertical tabs Edge allows me to use them. Firefox? Need a third party plugin that adds the vertical tabs but cannot remove the horizontal ones on top, creating an ugly and wasteful freak.Also I didn&#x27;t say I should write in the browser, I said the browser should let me collect information from the internet in such a way to make my job easier reply drtgh 8 hours agorootparentJust in case you do not know, or you are interested, the Firefox&#x27;s UI is mere CSS, one can customize it through \"chrome&#x2F;userChrome.css\" in the profile folder of the user. I put for example my tabs under the bookmarks, just above the page content (As FF used to be at past), with the template from the CustomCSSforFx[1] project, and modified some colors and icons.Firefox have also the \"Browser Toolbox\"[2], homologous to the web development tools, that one can use for to explore the css of the UI, select elements, etc, and modify them for to see how would look the modifications before to put them within the userChrome.cssThe tabs I think that are under the id=TabsToolbar, so an #TabsToolbar{ display: none !important; } or similar should work, in addition to correct with other css params the space that it leaves.Note: What happens is they change things from time to time, and after an update one have to correct the css again, I warn.[1] https:&#x2F;&#x2F;github.com&#x2F;Aris-t2&#x2F;CustomCSSforFx[2] https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;devtools-user&#x2F;browse... reply jwells89 10 hours agorootparentprevFirefox also doesn’t let you hide the gigantic sidebar header without usercss hacks. reply soraminazuki 7 hours agorootparentHow can Firefox possibly improve if every solution gets labeled a hack? reply jwells89 7 hours agorootparentI’m not sure I follow? The clear improvement here is to add a checkbox representing a supported option to hide that header.Hiding it in usercss isn’t supported and is liable to disappear at any point (say, the developers decide they’re tired of maintaining some part of the code that makes the custom usercss flag work). It serves the purpose for now, but cannot be relied upon in the long term and as such is a hack. reply BeautifulSynch 5 hours agorootparentNot a Firefox user, but this feels like a culture gap. I use multiple applications where configurability through user-code is part of the SLA, and dropping support would be as utterly unacceptable as, say, dropping the toolbar. Considering the contrast Mozilla is trying to make with Chrome&#x27;s more restrictive and non-user-conscious nature I see no reason they wouldn&#x27;t share that same philosophy.Unless there&#x27;s something I&#x27;m missing re: Mozilla&#x27;s history&#x2F;market-positioning? reply jwells89 4 hours agorootparentIn the past they’ve not hesitated to reduce customizability when doing so was perceived to bring some benefit to ease of development.Aside from that I just think it’s a good idea to push for implementation of basic functionality like hiding bars that don’t pair nicely with popular vertical tab extensions. I shouldn’t need to resort to usercss mods to do something that simple. replybastawhiz 10 hours agorootparentprev> Browsers imo should just be browsers and leave the end user applications to the web app developers, plugin developers, etc.The problem here, though, is that the core browser becomes the lowest common denominator. When I set up a computer, I don&#x27;t want to have to spend all day getting my browser into a usable state. I don&#x27;t want to have to recommend Firefox with the asterisk that you need half a dozen plugins to make it good. I don&#x27;t want to wake up and find that the tab management plugin I like has been bought out by a sketchy company that&#x27;s now using my browser as a proxy server for scrapers.And having a browser that&#x27;s not minimalist is known to work. We have tabs today, for instance, because of the fine folks at Opera pushing the boundaries of what the browser can be. Not every browser needs every feature, but some things are just good quality of life improvements that plugins should be able to disable (versus requiring plugins to add all nonessential features). reply Kinrany 10 hours agorootparent> When I set up a computer, I don&#x27;t want to have to spend all day getting my browser into a usable state. I don&#x27;t want to have to recommend Firefox with the asterisk that you need half a dozen plugins to make it good.You want a browser that can preload plugins on install with a config. reply bastawhiz 8 hours agorootparentNo, I don&#x27;t. I don&#x27;t want my browser to be cobbled together from plugins that may or may not work well together. I&#x27;ve played enough modded video games to know that this is hell. I want it to work because it was created and tested by a single person and not a dozen independent people stepping on each other&#x27;s toes. reply cycomanic 6 hours agorootparentWell I guess you have to write your own browser then, because I&#x27;m quite certain that the configurations that you like are not the same as mine.It&#x27;s also funny how you bring up innovation. The thing is plugins enable much more innovation because a plugin can be made by a single person with a great idea and relatively little knowledge. Just imagine everyone who wanted to try out some innovative new feature would have to build their own browser first. replyautoexec 9 hours agoparentprevI think firefox focusing on performance, customization, and security&#x2F;privacy is smart. Being the browser for tech savvy people is a great niche that sets it apart from others.Performance has always been a metric that drove people to&#x2F;away from browsers (at least for those of us who know what browsers are, know that alternatives exist, and are willing to try them). Add-ons can provide whatever weird workflow empowering gimmicks people want to set up for themselves rather than being limited to what the browser itself provides. Every OS I&#x27;ve used a browser on provides things like note&#x2F;screenshot taking, and not everyone wants vertical tabs, ARC doesn&#x27;t give you any choice. It&#x27;s ARC&#x27;s way or nothing. Firefox is still the browser that gives people the most control over how they work. Firefox truly empowers users. reply avazhi 9 hours agorootparentFirst, FF is less secure than Chromium-based browsers so not sure what you meant there. Just have a look at the results of the various browser hacking competitions. This has been a consistent result for decades. FF security out of the box has also been inferior to Chrome’s. In some cases it’s been more readily exploited than Safari, which is saying something.And as for customisation, that’s actually been eroded over the past 3-5 years in FF compared to, say, 10 or 15 years ago. For example, I can remember a time when the interface itself had the option (a checkbox) that miniaturised the icons of the entire search bar UI - this has been gone for years and there is now no way to change that without installing an entire theme. Now every user is stuck with the same general interface&#x2F;UI spacing.I’ve used FF since maybe 2008 and in my experience it’s never been worse than it is now in terms of performance, its interface customisability, and its benefits vs its largest competitor. If I end up using it as my primary browser it will be because of Google’s insanity with adblockers, not because FF itself is a good alternative (indeed it’s just that FF is the ONLY alternative). reply autoexec 8 hours agorootparent> FF security out of the box has also been inferior to Chrome’s.Privacy with Firefox out of the box isn&#x27;t that much better than Chrome’s either, but what sets Firefox apart is that it can be very effectively hardened. At work I deal with all kinds of compromised and malicious websites and nothing beats Firefox once you&#x27;ve got it locked down.> I’ve used FF since maybe 2008 and in my experience it’s never been worse than it is now in terms of performance, its interface customisability, and its benefits vs its largest competitor.It&#x27;s gotten more difficult to customize firefox over the years for sure, but what competitor offers better interface customizability? What can you customize in Chrome that you can&#x27;t in firefox? What&#x27;s chrome&#x27;s equivalent to userChrome.css? Check out https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;FirefoxCSS&#x2F; for examples of what you can accomplish. reply avazhi 7 hours agorootparentYou are absolutely correct that Firefox is more customisable than Chrome, but my point wasn’t to compare the two on that front, but to make the point that the original comment - which spoke of FF’s ‘commitment’ to ‘customisability’ - is nonsensical. That commitment may have been a real thing a decade ago, but it hasn’t been around for awhile. reply autoexec 7 hours agorootparentI do wish they&#x27;d lean into it a bit more these days. Updates tend to break a lot things for people who have taken the time to set things up how they like them. I know that can&#x27;t always be avoided, but it&#x27;d be good if they tried and kept the ability to make such customizations in mind as they add new features. reply huytersd 7 hours agorootparentprevYou can’t leave it at that. What do you do to lock down FF? reply autoexec 5 hours agorootparentWe&#x27;ve got a document that outlines easily over 100 changes in about:config that need to be changed and locked (new ones are being added all the time), Nearly everything with a URL gets pulled out of the settings. Pocket is disabled, default plugins and the extensions that get installed for you automatically like screenshots@mozilla.org.xpi and pictureinpicture@mozilla.org.xpi get deleted, and we add noscript&#x2F;ublock originThe idea is to reduce attack surface as much as possible, and disable features like searching&#x2F;calculating from the address bar, service workers, wasm, prefetch, webgl, redirects, the PDF reader (no files ever just auto-download or open in anything by default), Firefox View, webrtc, network prediction, the social API, reader mode, there&#x27;s some stuff about certificates, TLS and SSL etc.There&#x27;s also a section for preventing fingerprinting, disabling telemetry&#x2F;reporting&#x2F;safebrowsing, all the stuff here: https:&#x2F;&#x2F;support.mozilla.org&#x2F;en-US&#x2F;kb&#x2F;how-stop-firefox-making... and to keep changes from being made so no auto-updates, and experiments&#x2F;normandy&#x2F;shield studies are disabled.There are a bunch of guides to harden firefox online, and ours seems to be some combination of several of them. The Tor browser guys do some great work keeping an eye on some of the changes that get made.In the end basically no active content of any kind is allowed by default. Some sites don&#x27;t work at all with this stuff turned off or removed and it&#x27;s a bit too locked down for day to day use but I&#x27;m surprised and how often things work well enough to get what you need at least. For example, an article might load just fine, but site navigation will be broken which isn&#x27;t really an issue if you just wanted to read the article.Most of the sites that will get you infected just by visiting them require JS, so disabling that alone helps a ton. For something you know is really evil it&#x27;s often best to just download and analyze the site offline, but for poking around even in highly questionable places it&#x27;s pretty nice. reply huytersd 52 minutes agorootparentThanks for the reply! reply soraminazuki 7 hours agorootparentprevChromium is the only browser that has security and privacy nightmares including Web USB [1], Web Bluetooth [2], and the Battery Status API [3].I&#x27;d rather stick with Safari or Firefox.[1]: https:&#x2F;&#x2F;caniuse.com&#x2F;webusb[2]: https:&#x2F;&#x2F;caniuse.com&#x2F;web-bluetooth[3]: https:&#x2F;&#x2F;caniuse.com&#x2F;battery-status reply avazhi 6 hours agorootparentYou just quoted 3 purely hypothetical exploitable features vs, say, Chrome consistently being the last browser standing at PWN2OWN over the past 10+ years (and Firefox is usually the first to fall). I’ll take real world practical protection over theoretical attack surfaces every time. reply autoexec 5 hours agorootparentChrome serves you up on a platter to Google and advertisers while admittedly being pretty good at protecting you from everybody else. reply avazhi 2 hours agorootparentAdvertising has nothing to do with security exploits.Clearly we’re talking about browser exploits in this particular line of comments, not privacy, and with exploits so defined Chrome is far superior to FF.Most people here who use a Chrome based browser would almost certainly use a Chromium derivative anyway, like Brave. replykshahkshah 10 hours agoparentprevVery insightful. I think people would, maybe, argue that a lot of the features in these niche browsers are actually plugins in disguise. Thoughts? I think the issue with plugins is people don&#x27;t actually use them save ad blockers. reply The_Colonel 10 hours agoparentprev> They could add so many features to make the lives of academics, researchers, journalists and professionals in general better. Who cares if it&#x27;s a bit slower than Chrome if it allows to efficently write my article or keep together the sources for my thesis?They don&#x27;t want to settle for a niche for academics, their mission is to be a popular mainstream browser (even if they&#x27;re failing at that ATM). reply Almondsetat 10 hours agorootparentWhy did you only extrapolate 1 category off the list? reply kageiit 10 hours agoparentprevHuge fan of the Arc browser. The UX is really smooth and intuitive. It also declutters UI and provides some nice hints.I usually go to the url box to copy the url. one day, it suggested me to use a keyboard shortcut instead based on how often I did it. Little things like this that are built-in to the experience without having to install plugins and make sure they work together is a breath of fresh air. reply agumonkey 9 hours agoparentprevI second this. I hope ffx team get some inspiration. reply rodlette 10 hours agoprevGood to see the benefits of telemetry, which the FOSS is typically skeptical of: https:&#x2F;&#x2F;hacks.mozilla.org&#x2F;2023&#x2F;10&#x2F;down-and-to-the-right-fire... .I&#x27;ll make sure FF telemetry is enabled for me. I typically disable them because I don&#x27;t trust vendors to not include something I consider sensitive. reply rpgbr 10 hours agoprevI really wish Firefox were a better citizen on macOS. Its weird text treatment, basic stuff such ignoring snippets substitutions, text navigation conventions (Option + arrow, for instance), are deal breakers to me. I’d gladly use Firefox as main browser if all these little details worked as expected for any macOS app.For now, I’m sticking to Safari, which is fine as well, and (not surprisingly) works like every app should word on macOS reply avazhi 9 hours agoparentFirefox’s handling of fonts, both within the browser itself and with its rendering of webpages, is my biggest issues with it. In Windows the difference in font representation in the address bar between FF and Brave&#x2F;any Chromium browser is enough to put me off using it. reply clumsysmurf 9 hours agoparentprevMy main peave using FF on macOS is full-screening it is a terrible experience - unlike Safari, etc, moving the mouse to the top of the screen causes all the chrome (tabs, URL bar, etc) to shift down (and reveal some useless gap). That&#x27;s not normal behavior, and should have been fixed 5 years ago.Also, once you use Safari tab groups + tab preview its hard to go back to FF. reply unloco 9 hours agorootparent>full-screening it is a terrible experienceThe extra bar from the mouse-over is kind of silly but, a TERRIBLE EXPERIENCE?Yes, it should be fixed though. reply clumsysmurf 7 hours agorootparentIts very terrible, because the UI actually shifts away from your mouse when you are about to click on something. reply squidbeak 9 hours agorootparentprevYou&#x27;re still using Safari when you use Firefox on Mac. Mozilla could perhaps give more attention to bugs in the chrome, but it&#x27;s understandable they allocate fewer resources to a platform that will never see Firefox&#x27;s rendering. reply StrLght 9 hours agorootparentYou&#x27;re confusing macOS and iOS. Only Firefox on iOS uses WebKit due to App Store rules. reply squidbeak 7 hours agorootparentThanks for the correction. reply weikju 9 hours agorootparentprev> You&#x27;re still using Safari when you use Firefox on Mac.That&#x27;s true of iOS, not of macOS. reply sillyalbatross 9 hours agoparentprevThey finally fixed the spacing issue with the default San Francisco font, which was left completely broken and disgusting looking for over two years. But it still renders differently than Safari and Chrome, which you&#x27;ll notice if you open a Github page for example and quickly flip between the two windows.For whatever reason Firefox likes to make everything a little bolder and more spaced out, and on top of that doesn&#x27;t seem to support the most widely used anti-aliasing CSS properties.I resorted to injecting -moz-osx-font-smoothing in userContent.css on websites I visit frequently that look particularly bad. reply sertbdfgbnfgsd 9 hours agoprevMaybe I&#x27;m the crazy one here, but I can&#x27;t remember last time firefox speed was an issue.You want your software to be really snappy, we all agree on that. But past some point, it&#x27;s physically impossible for a human to tell the difference. I believe a human can&#x27;t detect if a tab takes 10ms or 1ms to open.Firefox has been past the point where \"fast\" matters for a very long time (and that&#x27;s a great thing!) reply weikju 9 hours agoparentAgreed -- however many people still remember Firefox from the days they switched to Chrome and have this perception that Firefox is slow. This blog post is probably for them, to let them know \"hey we&#x27;re not slow!\". reply chongli 9 hours agoparentprevNo, it still matters at the margins. When you get into extreme situations like having too many tabs open or a website with really inefficient JavaScript, it’s really nice to have a fast browser that can deal with that. Sure, there are always ways to design software better in order to preserve responsiveness in extreme situations, but better performance never hurts! reply notme43 7 hours agoprevI&#x27;ve noticed that performance of Firefox on Linux can vary quite a bit from distro to distro. Mozilla uses aggressive compile, link time, and profile guided optimizations in the default Firefox binary they distribute, whereas distributions like Debian compile with very safe options and little optimizations enabled. You can see these with about:buildconfig. It&#x27;s such a big difference sometimes that it makes sense why they previously branded unofficial releases as Pale Moon. reply gtirloni 10 hours agoprevFirefox should be the obvious choice or at least a very close second to Chrome, considering the millions Mozilla gets.That or a browser is a billion dollar project nowadays and Mozilla doesn&#x27;t have the resources to compete? reply binkHN 10 hours agoparentWith the exception of Linux, Firefox is not installed by default anywhere. You have Edge on Windows, which is based on Chromium, and Chrome pushing its installation when you visit any Google property. So no wonder Firefox has the market share that has. reply rc_mob 9 hours agorootparentUs technology leaders should be sneakily installing it on all of our grandma&#x27;s computers and swapping icons to make it look like Chrome reply binkHN 9 hours agorootparentUntil something doesn&#x27;t work, because it hasn&#x27;t been tested on Firefox, and Grandma calls complaining. :( reply paulryanrogers 9 hours agorootparentThis is the tyranny of the majority. Devs often won&#x27;t even test Safari. They check one browser. Once that was IE. Now it&#x27;s Chrome.I run into site quirks on Firefox from billion dollar companies and government sites at least weekly. reply 0x073 9 hours agorootparentprevWould always choose chrome for grandma&#x27;s computer. Firefox is great but for a non technology person worse than chrome.Most sites work as expected. And I had more update issues with Firefox than chrome (chrome was never outdated, firefox sometimes was versions behind until I manually opened the about dialog) reply cptskippy 9 hours agorootparentprevMy mom has been running Firefox for probably a decade at this point without complaint. reply ilrwbwrkhv 10 hours agoprevFirefox is great! It is my daily driver. However a lot of small things irritate me. For example, make Firefox fullscreen and open a long page. Move your mouse to the far right of the page and drag down. The page will not scroll. You need to carefully put your mouse on the tiny scrollbar to make it work. Chrome, Safari on the other hand work as expected. reply gerdesj 10 hours agoparentI&#x27;ve tried that and its fine with or without F11 really full screen. reply tempestn 10 hours agorootparentYeah, same here. Maximize the window, can scroll with mouse on far right. Though I&#x27;ve never tried to scroll that way before as I use three monitors and generally have the browser in the middle. (Which does make these trendy new thin scrollbars a bit irritating. But it seems everyone is doing that.) reply ilrwbwrkhv 8 hours agorootparentprevIs this on a mac or windows? reply yc-kraln 7 hours agoprevThe only thing that keeps getting faster is the abandonment of Firefox. It doesn&#x27;t matter how fast Firefox is, or how private it is, or any of the other garbage the Mozilla foundation has been wasting their time on. If Firefox continues to slip in usage, and eventually into obscurity, it is all for nothing.A technically superior, or safer, or more private, or whatever the current line of argumentation and marketing is, does not matter. Mozilla VPN does not matter. reply tristan957 5 hours agoparentThe Mozilla Foundation doesn&#x27;t develop Firefox, so I don&#x27;t understand your point. reply spiritplumber 9 hours agoprevI&#x27;ve stuck with Firefox since 2008ish and .... it works well? reply ghostpepper 9 hours agoprevMy biggest annoyances in Firefox are stuff like Pocket, VPN, Colorways etc.Also I don’t have specifics but get the sense the security sandboxing is not in the same league as chrome. reply hesnuts 10 hours agoprevDoes anyone have a good way to auto export FF bookmarks on some cadence to a folder for backup purposes (e.g. a location in ones dropbox folder)?Thats one thing I like about Brave, the bookmarks are auto synced somewhere reply Vinnl 10 hours agoparentYou can set up Firefox Sync in the main menu? reply starkparker 10 hours agorootparentIncluding self-hosting the sync server, if preferred: https:&#x2F;&#x2F;github.com&#x2F;mozilla-services&#x2F;syncstorage-rs reply pacifika 9 hours agoparentprevYou can use SQLite utility to export it to csv reply EVa5I7bHFq9mnYK 2 hours agoprevWhat use is 1 millisecond improvement in page load time, if every second page on today&#x27;s internet requires me to click on cookie consent form, or to solve a difficult captcha, or to pay to continue reading, or turns out to be a 30-screens AI chez d&#x27;oeuvre? Enshittification of the web is real and painful. reply anizan 8 hours agoprevStrangely theres a huge speed difference using speedometer 2.1 benchmark on mac reporting from m2 pro.467 on chrome vs 372 on firefox reply krackers 10 hours agoprevAlmost 2007+17 and Firefox still doesn&#x27;t set a bit to prevent sleep while downloading files. reply binkHN 9 hours agoparentThe last thing I want is any application preventing my computer from sleeping when I specifically told it to do so, even automatically. reply lostmsu 8 hours agorootparentThe bit in question only prevents automatic sleep, not the explicit order to sleep AFAIK. reply briantakita 10 hours agoprevI enjoy using Firefox as my primary browser...but it&#x27;s animation performance significantly lags Chrome reply Unfrozen0688 10 hours agoprevYup, I can tell.Now, I just want native vertical tabs.It&#x27;s annoying that Edge and Brave and Vivaldi does it better.AND an F2 style command line like Vivaldi, PLEASE!!Copy this https:&#x2F;&#x2F;help.vivaldi.com&#x2F;desktop&#x2F;shortcuts&#x2F;quick-commands&#x2F; reply 29athrowaway 11 hours agoprevIt regularly gets stuck on Linux for minutes at a time. Even if you disconnect your Internet connection. reply starkparker 10 hours agoparentThere was a gnarly driver issue that wasn&#x27;t limited to Firefox, but which Firefox could trigger pretty easily: https:&#x2F;&#x2F;bugzilla.redhat.com&#x2F;show_bug.cgi?id=2193110Ended up being a Qualcomm ath11k bug reportedly fixed in kernel 6.4: https:&#x2F;&#x2F;bugzilla.kernel.org&#x2F;show_bug.cgi?id=217528 reply SV_BubbleTime 11 hours agoparentprevI’m using Linux Mint (Ubuntu based) and have never had anything remotely similar to that. reply 29athrowaway 10 hours agorootparentI am not making this up, and it&#x27;s an issue reported by other users as well. Although I don&#x27;t have the ticket URLs right now.For me, after restart, some websites hang for about 5 min and then load.The recommended solution is to \"refresh firefox\" or use \"troubleshoot mode\" which disables all extensions. reply the8472 10 hours agorootparentIf this is a per-site issue then maybe just use the devtools to profile what&#x27;s happening.If it&#x27;s a whole-browser issue then use the firefox profiler and configure it to profile from startup: https:&#x2F;&#x2F;profiler.firefox.com&#x2F;docs&#x2F;#&#x2F;.&#x2F;guide-startup-shutdownMaybe something obvious pops out. reply 29athrowaway 9 hours agorootparentIt&#x27;s not a per-site issue. It doesn&#x27;t reproduce on other browsers such as Epiphany, Chromium&#x2F;Chrome, etc. reply gerdesj 10 hours agorootparentprevNot many indications&#x2F;contras to go on!A roughly five min timeout is not indicative to me but someone with more intimate knowledge of IP and FF may recall one or more.\"Some\" websites might help - examples please.OS and FF versions etcGet the dev tools out. You should be able to narrow it down somewhat. reply gerdesj 10 hours agoparentprevI use a lot of Linux, from Ubuntu to Arch (actually) via Debian, Rasbian and more.That&#x27;s not my experience. (edit) and why disconnect from the internet anyway and how do you actually do that? I think you are confused about internet and ethernet. reply _u2yk 10 hours agoprevSpeedometer performance has improved; it&#x27;s almost as fast as Chrome was last year! Chrome is still 13% faster.JetStream performance is still miserable though; 50% slower than Chrome.Worst of all Firefox doesn&#x27;t support PWAs, so I&#x27;ll be using Brave until it does. reply Jap2-0 10 hours agoparentNo, actually it&#x27;s as fast as Chrome is now,[0] and substantially faster than Chrome was two years ago.[1]-[0] https:&#x2F;&#x2F;arewefastyet.com&#x2F;win10&#x2F;benchmarks&#x2F;overview[1] https:&#x2F;&#x2F;treeherder.mozilla.org&#x2F;perfherder&#x2F;graphs?series=auto... reply lostmsu 8 hours agorootparentI just run it on my Windows PC and it is 1.5x times slower on JetStream vs Edge. reply gausswho 10 hours agoparentprevWhile Mozilla deserves some heat for abandoning official support of PWAs, for my use this add-on has filled the role just as well: https:&#x2F;&#x2F;github.com&#x2F;filips123&#x2F;PWAsForFirefox reply binkHN 9 hours agorootparentThanks for this. It is pretty surprising that this is one of the most requested Firefox features and they haven&#x27;t done anything here; all the world is moving to web apps and Firefox is not helping. reply noir_lord 10 hours agoparentprevSuspect that may vary based on host system and OS.~455 on Chrome, ~452 on Firefox (fully patched windows 10, 7950X3D).3 runs including a cold start for both, variance on FF was +&#x2F;-9.6, Chrome was +&#x2F;- 6.0.I&#x27;d say they are there (on that specific benchmark). reply badrabbit 11 hours agoprevI love firefox but i don&#x27;t have as much faith in mozilla as an org. IMHO, they should consider firefox a loss leader (despite search engine deals) and focus on unrelated projects that make money and attract users due to the firefox brand.Or...hear me out: Firefox gets into the adblocker business and lets the big boys paya fortune to be exempted by default. This includes using ML to block ads (i have ideas on how to implement unblockable ads using traditional means).I really wish they would invest more in servo. Imagine a memory safe browser!But beyond all that, EU and US govs mandating it as the only default browser would be huge for mozilla.They&#x27;re catching up now in some areas like GPOs but mozilla has nothing on chrome enterprise.They don&#x27;t realize that corporate types are eager to spend money or random shit so long as b2b marketing is done right (makes the buyer look good internally). And I cna sort of see the conflict because they are pro-privacy and chrome enterprise is very much about giving security&#x2F;system admins control. For example, if a user clicks through a failing https warning or downloads a file despite safe browing (phishing&#x2F;malware) warning you would know. So long as you make sure it is only sold to enterprise and gov customers, giving them such insights (and much more, even browsing history) can be a good money maker, help dominate the market share and maintain moral leadership (don&#x27;t do personal stuff at work or shit where you eat). reply jakkos 10 hours agoparent> Firefox gets into the adblocker business and lets the big boys paya fortune to be exempted by default.This would completely alienate Firefox&#x27;s core userbase.> i have ideas on how to implement unblockable ads using traditional meansIf a way to serve unblockable ads existed, it would already be implemented and widely used reply ants_everywhere 9 hours agorootparent> If a way to serve unblockable ads existed, it would already be implemented and widely usedI don&#x27;t think this is necessarily true. It&#x27;s clear that any tech that literally forces users to look at something is coercive. Forcing your users to wear a Clockwork Orange style eye gadget is clearly not acceptable. Playing ads and asking your users not to switch to another channel is clearly acceptable. The game is largely about gaining or ceding ground between those extremes about what&#x27;s socially acceptable rather than what&#x27;s technologically possible.Many users are okay with some level of ads. It&#x27;s easier to ratchet up the ads those users are willing to watch than it is to get increasingly authoritarian with the small number of users who insist on not seeing any ads. For example, YouTube didn&#x27;t attempt to fight ad blockers for years. They&#x27;re only really starting now because it&#x27;s trying to hit revenue targets. reply badrabbit 5 hours agorootparentprevI am surprised by your comment and the reaction to mine. Why would firefox&#x27;s users be alienated? They get an adblocker by default that will be supported and maintained by mozilla. If you want to block all ads that would be changing a setting, what google and pals pay for is the default setting that benefits them, they will still get blocked if users want them blocked. This mindset of making an emotional ideologic reaction isn&#x27;t helping anyone!> If a way to serve unblockable ads existed, it would already be implemented and widely usedIt would require a change in how ads are served and bids are made in realtime. The main reason it isn&#x27;t happening already is that most people are not blocking ads, especially on mobile where engagement has most value.I&#x27;d say ad blocking users are not more than firefox users even. reply sergiotapia 10 hours agorootparentprev>This would completely alienate Firefox&#x27;s core userbase.How&#x27;s that core userbase working out for them? Sub 2% very nearly. Time to shake things up and figure it out. What they&#x27;ve been doing don&#x27;t work no more. reply rc_mob 9 hours agorootparentHi Satan. reply sergiotapia 8 hours agorootparentMozilla will have the most beautiful, pure FOSS browser on the planet. But who is going to use it? reply aetimmes 10 hours agoparentprev> Firefox gets into the adblocker businessThis would be an abysmal decision all around. Firefox doesn&#x27;t have enough market share to command any sort of price for this, and selling ad-blocker access would immediately destroy all trust in Firefox as a product. reply badrabbit 5 hours agorootparentThey already make hundreds of millions just for allowing google as default search engine, they can make more with this.I re-read what I said and it is in plain english, why are you and others not understanding that I didn&#x27;t say selling ad blocker access? Ad blocker default exempt list is what is sold which users can change. And you can still use ad blocking extensions.Basically a ton of people get an adblocker by default and you people have your pitchforks out because mozilla sells the default setting of an adblocker? Your emotions and open source religion aside what exactly offends you about this? reply Cyberdog 10 hours agoparentprev> Or...hear me out: Firefox gets into the adblocker business and lets the big boys paya fortune to be exempted by default.That will make Firefox a very attractive browser to people who want to block as many ads as possible, and they will then install an add-on which also blocks the ads that Firefox whitelists, perhaps using Firefox&#x27;s own whitelist as a source if it&#x27;s easily available. Then if Firefox tries to pull a Google and be evil and lock down their add-on API so that ad blocker add-ons can no longer be made, these people will just switch to a fork with no such limitations. And in the first place I don&#x27;t think Firefox has enough usage for them to be able to charge a \"fortune\" for such an ad blocking exemption in the first place.By \"EU and US govs mandating it as the only default browser\" I assume you mean for government employees and not for the entire populace (which would be straight up despotic), but either way it would probably be unenforceable. reply NegativeK 10 hours agorootparent> but either way it would probably be unenforceable.A healthy IT organization shouldn&#x27;t allow the average user to install their own browser of choice. But government orgs tend to be underfunded to the point that Firefox mandates are nowhere near their top tech priority. reply badrabbit 5 hours agorootparentprev> By \"EU and US govs mandating it as the only default browser\" I assume you mean for government employees and not for the entire populaceYes, for their own gov pcs not the people in general.> and they will then install an add-on which also blocks the ads that Firefox whitelistsYou are the third commenter I had to explain this to, so maybe my fault in not making this clear but there is no need for that, the whitelist is just a default \"moderare\" adblock setting which you can change to \"aggressive\" to block everything. And exisiting adblockers will continue to work if you prefer them.This is similar to how you can set your search engine to duckduckgo but google pays a fortune to be the default. reply SV_BubbleTime 11 hours agoprevCongrats Mozilla! You made improvements to a product you allow dwindle to 2-3% market share.Forest and trees… who cares that you made it faster if continually less and less people use it. The extreme majority do not care about tiny improvements to speed.If they were interested in growing market, they would be integrating ublockOrigin and other anti-ad software. They literally have nothing to lose anymore. reply gmiller123456 10 hours agoparent2-3% of all internet users is an enormous number of people, and more than the overwhelming majority of apps will ever see. reply slig 10 hours agorootparentBut it&#x27;s such a small number of users that some web apps and sites aren&#x27;t bothering to test on FF. Also, it seems like even \"power users\" are not using and recommending it like they used to do. Their mobile presence is ruby. It&#x27;s alarming and they must move fast. reply bdlowery 10 hours agorootparentprevApple used to have a 4% market share (and declining) of the PC industry before Jobs came back, and was seen as a joke and failure of a company because of it.But, it’s okay for Firefox to own 2-3% market share? reply protastus 10 hours agoparentprevRudely stated yet true. I&#x27;ve used Firefox as my main browser for as long as it has existed (and Netscape before). It&#x27;s very concerning to see it slip into irrelevance, putting more users every year under the control of big tech. reply bbarnett 11 hours agoparentprevDon&#x27;t worry! They&#x27;ll continue to change the GUI for no reason each release, continue to remove features, customizability, and more as well.Then add on stupid things, so all their users, each release, have to fight to turn off dumbassery, and restore functionality.They&#x27;ve literally done everything they could to destroy market share. reply russelg 5 hours agorootparentI feel one issue is that the people who are Firefox power users are also disabling telemetry, so the developers aren&#x27;t getting any usage data from the people who care the most about Firefox. So the only usage data they receive is from the normal user, who want different things and use the browser differently. reply bbarnett 1 hour agorootparentIt&#x27;s not about telemetry, most people just use the data to support whatever they want.For example, firefox users of all sorts customized things. People loved it. Themes, plug-ins, add-ons.Firefox devs consistently fail to realize that \"configurability\" is a category, not \"this tiny configurable thing\".So they&#x27;ve removed configurable after configurable option, each option only having .1% market share usage or what not, not considering that overall... they&#x27;ve now alienated 20% of their user base.Telemetry shows them a tiny percentage for each feature, but it is the collective feature set which matters.And that has a cumulative effect. 20% upset users, all saying \"Don&#x27;t use firefox!\", doesn&#x27;t help.Then they add useless, in your face, obtrusive and annoying features, and people scramble to diaable them.\"Oh so sorry, disable that?!\". Sometimes years go by, and all the instantly closed bug reports add up, and they finally relent, fix it. Of course, everyone who cared is now gone, and will never come back, and now campaigns against firefox.Just like the infamous tab detach issue, which took half a decade to resolve, by finally adding an about:config option to turn that off.And who cares for telemetry, when hundreds of users complain, and bugs are ignored, or just hostile closed?Mozilla is broken. Firefox is on the wrong path.It is sad. reply grizzles 11 hours agoprev [–] I&#x27;m a firefox user on Ubuntu. They need to improve the cold start time badly. It currently takes me 4-5 minutes from launch to page load. Once loaded I have no issues with the performance but Chrome is vastly superior in this area.EDIT: I rely highly on the Restore Previous Session feature. That might be why. reply callahad 11 hours agoparentSlow cold starts on Ubuntu are a known issue with Canonical&#x27;s Snap application format, as acknowledged in official blog posts like https:&#x2F;&#x2F;ubuntu.com&#x2F;blog&#x2F;improving-firefox-snap-performance-p...If you can install a Flatpak or .deb package of Firefox, you should regain that performance. Found a post recommending a \"Mozilla Team\" PPA at https:&#x2F;&#x2F;ubuntuhandbook.org&#x2F;index.php&#x2F;2022&#x2F;04&#x2F;install-firefox..., but I last used Ubuntu 15 years ago, so I can&#x27;t speak to the specific recommendations therein. reply INTPenis 11 hours agoparentprevYou can&#x27;t possibly think that all Firefox and Ubuntu users sit around for 4 minutes waiting for their browser to open. It&#x27;s clearly something specific to your setup.If you want to report this issue I suggest first trying a fresh install of another OS on the same device just to ensure it&#x27;s not hw. And of course the standard troubleshooting is to start Firefox in troubleshooting mode, that runs it without any plugins enabled. reply bdd8f1df777b 9 hours agorootparentI have the same issue. But I know the cause—-snap. reply starttoaster 11 hours agoparentprevThat&#x27;s a local issue for sure. Not sure how, might be Firefox&#x27;s fault in some way. But it&#x27;s not just a combination of Firefox and Ubuntu. (I use Firefox on Ubuntu 22.04 and it&#x27;s a couple seconds, maybe.) reply bbarnett 11 hours agorootparentProbably firefox is ridiculously in a snap. Normally, it takes a second to load tops. reply starttoaster 7 hours agorootparentThat&#x27;s the default install method for Firefox on Ubuntu, last I checked. I think they only recently had an apt repo too. I don&#x27;t think it&#x27;s specifically an issue with Snap either, nor do I think Snap is a terrible tool besides it being a centralized package store that you can&#x27;t create 3rd party repositories for, though I understand people also complain about the block devices Snap packages add to your system.Anyway, the intent of my original comment was just to say that they should do some more investigating on their issue because it&#x27;s not as simple as Firefox in a Snap package on any Ubuntu installation. reply rreyes1979 11 hours agoparentprevUsing Firefox on Fedora 39. It takes 1-2 seconds to start with lots of tabs reopening. I have had issues with videos not playing from time to time but other than that, I am really liking it (coming from MacOS and Chrome). reply Ridj48dhsnsh 11 hours agoparentprevHave you tried deleting your profile and starting fresh? Something is clearly messed up. Launching takes a fraction of a second for me on NixOS with a years-old profile. reply e-khadem 11 hours agoparentprevMaybe due to the snap situation there? Will you try firefox using flatpak or Mozilla&#x27;s native builds? reply binkHN 9 hours agoparentprev> It currently takes me 4-5 minutes from launch to page load.Something is definitely not working right on your end. I&#x27;m on Debian and it takes seconds to restore 4 Firefox windows with 60 or 70 tabs. reply the8472 10 hours agoparentprev> EDIT: I rely highly on the Restore Previous Session feature. That might be why.As do I, and it doesn&#x27;t take as long on my machine. Perhaps your hardware is unusually slow or you&#x27;re using extensions that do something on every tab after startup, even the lazy-loaded ones. Firefox restarts in seconds for me. reply robinsonb5 10 hours agoparentprevIs the Firefox snap perhaps on a spinning rust drive?(I boot from SSD but have spinning rust for &#x2F;home - so I can hear when Firefox is hammering the drive. It seems that any time it updates or fails to quit cleanly it thrashes the HD for maybe 10 to 20 seconds the first time I visit something like facebook or youtube.) reply botanical 5 hours agoparentprevI&#x27;m on the Ubuntu Firefox snap, and it definitely doesn&#x27;t take 5 minutes to load. Create a new profile and see if that helps, but it shouldn&#x27;t take that long. reply quirino 11 hours agoparentprevI had a similar issue on Arch Linux some time ago. I debugged it by running it with strace, seeing what it was waiting for and googling it. Uninstalling some package solved it. reply seszett 11 hours agoparentprevI&#x27;ve had this problem on an Arch machine after no use and no update for a long time. Thunderbird was affected as well, and both unfreezed at the exact same moment a few minutes after launching the first one.I never had time to investigate this but this was obviously a system problem, Firefox and Thunderbird are fast on all the other machines I use. reply andrepd 10 hours agoparentprevI routinely have >3000 tabs open. It never takes more than a second or two to open. reply abhinavk 10 hours agorootparentI’m not going to ask you why. But how. How do you manage or organize those many? Tree tabs? reply lightlyused 6 hours agorootparentI use container tabs and tab search. I too have lots of tabs open. reply chipsrafferty 10 hours agorootparentprevWhy? reply SAI_Peregrinus 8 hours agorootparentNot them, but tree tabs + auto tab discard is a great way to browse documentation when working on a project. That can easily use up dozens of tabs.3000 seems excessive, but tabs are better than bookmarks since they save page state like scroll position, so many people use tabs instead of bookmarks. That&#x27;s more a lack of useful functionality in existing bookmarks than an inherent advantage of tabs IMO. reply NegativeK 10 hours agoparentprev4-5 minutes is clearly insane, but Firefox in Ubuntu taking 10s of seconds for a fairly simple profile to start is why I went back to Debian after a few months of Ubuntu. reply ranting-moth 11 hours agoparentprevI&#x27;m on Ubuntu and Firefox. Cold start to page load is seconds.Try creating a new blank profile in Firefox. reply ra_men 10 hours agoparentprevI&#x27;d rather run IE on Windows 8 in a VM than go through a 4-5 min initial load. reply nextaccountic 11 hours agoparentprevwhat&#x27;s your firefox version? what&#x27;s the size of your restore previous session? how much ram do you have?i also highly rely on restoring the previous session but it never took 4 mins to load reply tekla 10 hours agoparentprevHoly shit what are you doing? Firefox loads within seconds on my x220. reply catlover76 11 hours agoparentprev [–] > It currently takes me 4-5 minutes from launch to page load.o_O replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mozilla has focused on improving the speed and performance of Firefox, leading to a 50% boost in performance based on the Speedometer 2.1 benchmark.",
      "Users have noticed a 15% increase in the speed at which web pages load on average.",
      "Mozilla will be releasing more technical information about their progress in the near future."
    ],
    "commentSummary": [
      "The discussions on the Mozilla Firefox browser cover various topics, such as stability issues, slow loading times, customization options, performance comparisons, revenue-generating projects, and declining market share concerns.",
      "Users participate in these discussions by sharing their experiences, offering suggestions, and expressing frustration with different aspects of Firefox's functionality and performance.",
      "This provides insights into the challenges and areas of improvement for the Mozilla Firefox browser."
    ],
    "points": 257,
    "commentCount": 215,
    "retryCount": 0,
    "time": 1702159202
  },
  {
    "id": 38583881,
    "title": "Doug Engelbart's 1968 Demo: Videos, Photos, and More",
    "originLink": "https://dougengelbart.org/content/view/209/",
    "originBody": "News Donate Site Map Home hide header Welcome LEGACY VISION ACTION Library News About TABLE OF CONTENTS [Top] Doug's Great Demo: 1968 0 Intro 1 Experience the Demo 2 Watch the Footage 2a And More 2b Part of a Larger Vision 3 Reflecting on the Demo 4 Doug and His Team 4b Colleagues, Press, and Presidents 4c Inspired Artistic Creations 4d See Also 5 On the Web 5a From Doug's Lab5b More 5c This week The Demo turns 55! How to celebrate? Right here - is rich with story, fun facts, archive footage (test drive our interactive version!), retrospectives, past anniversary events, and more. Share your favs on social media! NEW! Watch the Trailer (6min) FUN! Experience the demo interactively Doug's Great Demo: 1968 0 Welcome to theDemo.org – our main portal into Doug's great demo of 1968 where you will find stories, archive footage and photos, and links to other fabulous resources at Stanford Libraries Special Collections, SRI International, Computer History Museum and more. Experience the demo, and watch retrospectives by Doug and his team recounting their experience. Now a 'milestone event' in the history of computing! NEW! Remastered footage from original film! Intro 1 On December 9th, 1968 Doug Engelbart appeared on stage at the Fall Joint Computer Conference in San Francisco's Civic Auditorium to give his slated presentation, titled \"A Research Center for Augmenting Human Intellect.\" He and his team spent the next 90 minutes not only telling about their work, but demonstrating it live to a spellbound audience that filled the hall. Instead of standing at a podium, Doug was seated at a custom designed console, where he drove the presentation through their NLS computer residing 30 miles away in his research lab at Stanford Research Institute (SRI), onto a large projection screen overhead, flipping seamlessly between his presentation outline and live demo of features, while members of his research lab video teleconferenced in from SRI in shared screen mode to demonstrate more of the system. Masterminding the whole production was lead engineer Bill English. As the session came to a close, the audience erupted into a standing ovation. This seminal demonstration came to be known as \"The Mother of All Demos.\" Experience the Demo 2 What you are about to see - watch futurist Paul Saffo que up the demo for a live audience at the 30th anniversary event (more below). Watch Highlights of the Demo (24min) WATCH THE FOOTAGE 2a ALL-NEW! Highlights Version (30 minutes in 12 clips, nice selection!) just the highlights, from SRI International, birthplace of the demo. Or watch selected highlights. ALL-NEW! Interactive Version (100 minutes, chapterized) a navigable, skimmable, browsable guided tour of the demo puts you in the driver's seat (learn more). Annotated Version (100 minutes, 35 parts, excellently annotated!) a detailed guided tour of the demo at the Stanford MouseSite. ALL-NEW! 1968 Demo in Full (100 minutes, hi res, in 3 parts) watch from start to finish, courtesy of Stanford Mousesite, also archived at the Internet Archive. AND MORE 2b Click to see photo gallery of the Demo project at Facebook Session Poster MORE! Check out the 1969 SEQUEL to The Demo Memorabilia: See the Session Poster announcing Doug's presentation, his go-to archive photos at his History in Pix, and our photo gallery of the Demo project on Facebook. Conference Proceedings: Read the paper by Doug and his team that accompanied their presentation: A Research Center for Augmenting Human Intellect, published in the Proceedings of the 1968 Fall Joint Computer Conference. Check out the conference proceedings Table of Contents to see who all was presenting what [browseable at ACM Library]. What were they thinking?: The story of the demo is as fascinating as the demo itself. Why did they do it, how did they do it, what was it like behind the scenes, who was in the audience, how was it received? Check out Reflecting on the Demo below to hear Doug and his team's reflections, and read Adam Fischer's How Doug Engelbart Pulled off the Mother of All Demos. See Colleagues, Press, and Presidents for more. Online Exhibits: Explore the MouseSite at Stanford for stories, archive video, photos, and key technical papers from the Douglas C. Engelbart Collection at Stanford Libraries Special Collections. See SRI's Timeline on Innovation: Computer Mouse and Interactive Computing for concise background and overall significance of the demo. Browse the virtual exhibits showcasing Doug's work at the Computer History Museum. NEW! Learn about Doug's collaboration with Herman-Miller Research, pioneers of the office of the future, who produced the custom swivel console and Eames chair used in the demo. See also the 1968 Demo Table of Contents which links to specific sections of the Demo, the Detailed Onscreen Outline, and a draft transcript of the Demo. Part of a Larger Vision 3 Most of what Doug and his team presented in 1968 was developed literally \"from scratch\" by a handful of researchers in the space of roughly 2 years. The system, called NLS, was used day in and day out by the research team for almost every aspect of their work – they were living and breathing the organization of the future and the future of work as an advanced pilot expedition, pushing the envelope of intelligence augmentation and collective IQ with transformative practices and paradigms alongside the rapidly evolving technology, using a special evolutionary bootstrap approach (watch Doug describe the approach during the demo). He reasoned that organizations would have to get alot more effective at tackling wicked problems, especially as we moved into a future of accelerated change and disruption at a scale never before experienced by business or society (yes, he predicted this in 1960 and adapted his strategic vision accordingly). The demo was essentially a snapshot in time on a continuum of cross-cutting breakthrough innovation in which they were rigorously prototyping the fast, fluid organization of the future, while co-evolving the technology in the service of that. See Historic Firsts for more, as well as the Engelbart Academy for his prescient call to action. 3a ❝ The demo was essentially a snapshot in time on a continuum of cross-cutting breakthrough innovation, in which they were prototyping the fast, fluid organization of the future, while co-evolving the technology in the service of that. ❞ — Christina Engelbart, Executive Director Reflecting on the Demo 4 Learn more about the making of the demo, the system being demonstrated, the team that made it happen, how and why it was conceived and evolved, its significance, and what it was like working in Doug's innovative lab at that point in time. 4a Doug and His Team 4b Watch Doug's 1986 reflections Doug Presenting at the ACM Conference: January 1986 3b1 Event: ACM Conference on the History of the Personal Workstation (1986) Watch Doug's 1986 presentation and accompanying paper Workstation History and The Augmented Knowledge Workshop in the conference proceedings, telling the story of his 1968 demo, the work surrounding it, and the vision it represented, with historic photos and personal anecdotes woven throughout. Doug is introduced by Charles Irby, who joined his team in 1968 after seeing the demo live at the conference in San Francisco. See event page Doug's Historic Talk: The Augmented Knowledge Workshop for all the details. CONTENTS: Intro by CharlesDoug's Talk: Leading up to DemoDemo PrepSelected Footage (15min)Post DemoOverarching FrameworkQ&A Anniversary Events Some fabulous anniversary events were later held to commemorate the demo, with panel discussions by Doug, members of his research team who participated in the 1968 demo, and invited guests discussing what it took to put on the demo that day, what it was like behind the scenes, and the significance of the work they were doing then and now. Watch the 1998 panel 30th Anniversary Event: December 9, 1998 3b2 Event: Engelbart's Unfinished Revolution (1998) Watch the 1998 Panel Discussion with (left to right) moderator Paul Saffo, Doug Engelbart with members of his research team Bill English, Charles Irby, and Jeff Rulifson, plus special guest Stuart Brand. CONTENTS: Welcome by PaulDemo Footage (15min)Back to PaulIntroducing PanelistsPanel Discussion. Contemplating the event's title \"The Unfinished Revolution,\" futurist Paul Saffo remarked: \"because the extraordinary thing is, even with the events that were demonstrated 30 years ago, more remains unfinished than has been completed.\" Visit the 30th Anniversary event website for more. Watch the 2008 Stanford News report for key takeaways (3min) ❝because the extraordinary thing is, even with the events that were demonstrated 30 years ago, more remains unfinished than has been completed. ❞ — Paul Saffo, Futurist Watch the 2008 panel 40th Anniversary Event: December 9, 2008 3b3 Event: Engelbart and the Dawn of Interactive Computing (2008) Watch the 2008 Panel Discusssion [Part 1Part 2] with members of Doug's research team Jeff Rulifson, Bill English, Don Andrews, Bill Paxton, together with special guest Andy van Dam and moderator Bob Sproull discussing the demo and its significance. Watch the Stanford News Report on the Event (3 min. video) - an excellent compilation. Visit the 40th Anniversary event website for more. The 50th Anniversary of Doug Engelbart's landmark Demo was celebrated on 3+ continents! Visit theDEMOat50.org for details Watch the 2018 panel 50th Anniversary Event: December 9, 2018 3b4 Event: Demo @50 Symposium (2018) Watch the 2018 Panel Discusssion with members of Doug's research team Jeff Rulifson, Don Andrews, Martin Hardy, Charles Irby, and Christina Engelbart in session titled \"The Making of The Demo: The ARC Team Remembers\". Introduced by MC Paul Saffo. See also: • Alan Kay's keynote at a sister event Why We Need to Understand What Doug Engelbart Was Trying To Do [slides,transcript], plus • Gardner Campbell's 'prequel' to the Demo Doug’s 1962 Framework: Augmenting Human Intellect (14min) Visit the 50th Anniversary event website for more. Oral Histories Watch Bill and Doug discuss the demo White Rabbit Interview with Doug Engelbart and Bill English Moderated by John Markoff Sep 13, 1999 3b5 Occasion: John Markoff interviews Bill and Doug re: the Mouse, the Demo, and Misc Other (1999) Watch them discussing the Demodiscussing the Mousere: flying thru information spacemore on the mouse and keyset See our Archive showcase under Story of a True Pioneer for more. Colleagues, Press, and Presidents 4c Watch President Obama cite Engelbart and the 1968 demo Watch the other speakers and panelists reflecting on the 1968 Demo at the above events, luminaries such as Tim Berners-Lee, Vint Cerf, Ted Nelson, Alan Kay, Andy van Dam, Bob Taylor, Curt Carlson, Howard Rheingold, John Markoff, Paul Saffo, Bob Sproull, Denise Caruso, Chuck House, and more [30th Anniv. Sessions40th Anniv Sessions50th Anniv. Sessions]. 4c1 See also this mid-1990s description of the demo by Brown University Center for Graphics and Visualization, Douglas Engelbart and 'The Mother of All Demos'. Andy van Dam, a principal investigator at the Center, attended the 1968 demo and was a guest speaker at all our Anniversary events. 4c3 PRESS: The big 50th anniversary events inspired some great press -- see Demo Press for a sampling. NEW! A Machine for Thinking: How Douglas Engelbart Predicted the Future of Computing, by Steven Johnson for Netguru's Hidden Heroes series. Watch the Stanford News report (3 min). See also top picks from 50th Anniv. Press, 40th Anniv. Press, and 30th Anniv. Press. Browse our Press Newsroom for a more comprehensive collection of articles dating back in time. 4c2 AWARDS: For his \"most unusual contribution\" to the success of the 1968 conference program, Doug Engelbart was awarded by the conference program organizers a hand carved tribute to his Demo, pictured at left. In recognition for achievements first showcased at the 1968 Demo, Doug Engelbart later received the National Medal of Technology and Innovation, the IEEE John Von Neumann Medal Award, the Benjamin Franklin Medal, the A.M. Turing Award, the Lemelson-MIT Prize, and the American Ingenuity Award. See Honors Awarded to Doug Engelbart for more on these and other awards. Inspired Artistic Creations 4d The Mother of All Demos: An Animated Commentary In 2009 a Freshman at Baylor University by the name of Philip Heinrich produced an impressive 5 minute video capturing the essence of Doug's goals and vision, combining audio from the 1968 demo with his own animation, which he titled \"The Mother of All Demos: An Animated Commentary\". Read about the project, the student, and the course and professor he produced it for on our Student Showcase page which includes links to the video on YouTube and to other projects he has authored. 'The Demo' now an avant garde opera at Stanford Stanford Live presents an avant garde opera 'The Demo', a musical/video/lightshow reimagining the 1968 \"Mother of All Demos\" originally presented by Doug Engelbart and his team just down the road at Stanford Research Institute for the Fall Joint Computer Conference in San Francisco, December 1968. [Details|Press|Reviews]. See Also 5 On the Web 5a Click for more Historic Firsts Visit Historic Firsts - for more of Doug Engelbart's many groundbreaking firsts. 5a1 Visit the Stanford MouseSite - a definitive website on the 1968 Demo hosted by Stanford University. 5a2 \"The Mother of All Demos\" (90 min Video/Film) Doug's 1968 debut of NLS (Augment's precursor) including hypermedia, the mouse, collaborative work, interactive computing, human computer interface, and overarching guiding principles. See especially Clip 12 where Doug, sitting in San Francisco, brings in a coworker sitting in his lab in Menlo Park, to demonstrate the mouse, and Clip 13 where Doug introduces the keyset. 5a3 From Doug's Lab5b A Research Center for Augmenting Human Intellect. (the paper written for the conference where they gave the demo, describing the work they were demoing). Douglas C. Engelbart and William K. English, AFIPS Conference Proceedings of the 1968 Fall Joint Computer Conference, San Francisco, CA, 33, December 1968, pp. 395-410 (AUGMENT,3954,). Republished with articles No. 4, 21, and 23 in \"Computer Supported Cooperative Work: A Book of Readings,\" Irene Greif [Ed.], Morgan Kaufmann Publishers, Inc., San Mateo, CA, 1988, pp. 81-105. See also Engelbart's videotaped presentation from this historic 1968 conference \"A Research Center for Augmenting Human Intellect.\" 5b1 Augmenting Human Intellect: A Conceptual Framework. (Doug's seminal report documenting his strategic vision that drove the work) Douglas C. Engelbart, Summary Report, Stanford Research Institute, on Contract AF 49(638)-1024, October 1962, 134 pages (AUGMENT,133182,). 5b2 Workstation History and The Augmented Knowledge Workshop. Douglas C. Engelbart, Proceedings of the ACM Conference on the History of Personal Workstations, Palo Alto, CA, January 9-10, 1986, pp. 73-83 (AUGMENT,101931,). Republished as The Augmented Knowledge Workshop in \"A History of Personal Workstations,\" Adele Goldberg [Ed.], ACM Press, New York, 1988, pp. 185-236. 5b3 More 5c Engelbart Archive Virtual Exhibits - the historic legacy of Doug Engelbart and his team 5c1 Doug's Bibliography - read about the innovative breakthroughs in his lab that led to the 1968 demo and beyond. 5c2 >>>>>>>>>>>>>>>>>>>>>>> Copyright © 2008-2023 Doug Engelbart Institute. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=38583881",
    "commentBody": "Doug Engelbart’s 1968 demoHacker NewspastloginDoug Engelbart’s 1968 demo (dougengelbart.org) 245 points by gjvc 16 hours ago| hidepastfavorite90 comments smurpy 15 hours agohttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231209174528&#x2F;https:&#x2F;&#x2F;dougengel... teddyh 15 hours agoprevThe reason for the downfall of SRI, the company led by Engelbart to develop NLS, can be discovered in The Network Revolution – confessions of a computer scientist (1982) by Jacques Vallée, specifically in chapter 5, “Knowledge Workers of the World, link up!”: It contains a partial and anonymized (all names have been changed) retelling about the initial decline of SRI. To summarize, they all became entranced with the cult-like Erhard Seminars Training, except the smart people, who left because they didn’t like it. reply mikewarot 14 hours agoparent>Erhard Seminars TrainingMy understanding of EST training was that it gave people permission to be self centered assholes, and had no redeeming value.No wonder SRI went downhill. 8([1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Erhard_Seminars_Training reply leoc 11 hours agorootparentThe well-funded (and comparatively highly sane) Xerox PARC also specifically set out to scoop up people from SRI from its beginning.EST seems to have been influenced by other, slightly older post-war groups with their own kinds of struggle session such as the drug-rehab community gone bad Synanon https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Synanon and our old friend Scientology, and in turn to have influenced later \"large group awareness training\" https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Large-group_awareness_training orgs like the \"wilderness training\" camps. At least Synanon helped to make the name of one fairly-big jazzman, Joe Pass: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sounds_of_Synanon reply kragen 11 hours agoparentprevengelbart was never the head of sri, and sri didn&#x27;t have a downfall; they&#x27;re still around and extremely highly respected. i worked on a darpa contract last year where sri was another performer on the contract, delivering http:&#x2F;&#x2F;spw20.langsec.org&#x2F;papers&#x2F;parsley-langsec2020.pdf and related work reply jacobolus 9 hours agorootparentEngelbart was the head of SRI&#x27;s Augmentation Research Center. My understanding is that after the ARC was sold off in the mid 70s, the new corporate owner tried to commercialize the work, stopped funding new research, and most of the researchers left. Disclaimer: I know very little about this story. reply seltzered_ 5 hours agorootparentThis comment jogged my memory of a Ted Nelson video subtitled &#x27;It all went wrong at Xerox PARC&#x27; : https:&#x2F;&#x2F;youtu.be&#x2F;c6SUOeAqOjU reply dav 5 hours agorootparentTangent, but since there are mentions of history books in these comments, I highly recommend Ted Nelson’s autobiography. https:&#x2F;&#x2F;www.goodreads.com&#x2F;book&#x2F;show&#x2F;10673124 reply wisemang 15 hours agoparentprevInteresting! This is the same as the “EST” sessions depicted in the TV series The Americans, for those familiar with it. Didn’t realize it went back so far. reply KerrAvon 13 hours agoparentprevInteresting. The seminal personal computer history book __Fire in the Valley__ blames IMSAI’s downfall on EST. Basically substituting wishcasting for business sense. reply api 8 hours agorootparentVirtually all this type of nonsense goes back to a few places: New Thought, Norman Vincent Peale, and spinoffs like the I AM cult and prosperity gospel. The latest iteration is “The Secret” and all that woo you hear about “manifesting.”Fun fact: Trump is a devotee of Norman Vincent Peale. This is why he constantly repeats superlatives and refuses to admit any form of failure or loss. He’s basically “manifesting.” You could sort of say he was our first New Age president. The mass conversion of a bunch of New Agers to the Q cult makes more sense if you look at it that way.Also I highly recommend finding a good history of the I AM cult. It’s some of the most bonkers shit. This intellectual lineage gave birth to a bunch of looney cults like Church Universal and Triumphant, Synanon, EST, and some alien channeling cult I forget, but I AM was the OG. I think NXIVM belonged to the same family too.It’s all this will creates reality stuff, sort of like a religion that worships con artistry as a holy path.Doesn’t surprise me one bit to hear that this stuff was around SRI. It had a big moment in the 70s. reply spacechild1 8 hours agorootparentOh wow, this is some really interesting stuff! Apparently, Trump used to regularly attend Peale&#x27;s sermons as a child and Peale even was the priest at Trump&#x27;s first wedding. reply bmitc 14 hours agoparentprevThank you. I wasn&#x27;t aware of that particular book and will check it out. reply jart 9 hours agoparentprevThe same thing happened at Google. Company started falling apart around the time the SWEs got obsessed with Braco. reply drno123 1 hour agorootparentThis is interesting? Can you share more information on that? reply api 9 hours agorootparentprevBraco? Not the guy who heals by staring at you…? reply engfan 14 hours agoprevSomeone once said to Doug: “I don’t know what Silicon Valley will do when it runs out of your inventions.”I had the pleasure of working with him. He was brilliant and kind. The world just wasn’t ready for him. reply planewave 12 hours agoparentI met Mr. Engelbart once as a child when my mother worked at SRI in the 90s&#x2F;early 2000s. At the time I had seen the mouse prototype while wandering the halls and on some open house day I was introduced to him. He listened to me, a young kid, talk excitedly about technology for what must&#x27;ve been awhile and was very encouraging and kind. While I was excited about computers at the time I had no idea the significance of his ideas until I was an adult.Looking back on it, I am awed by the kindness he showed to some random kid. reply sriku 7 hours agorootparentThis is a trait of many great people. I guess they realise at some level that inspiring another generation helps carry the work forward than being dismissive and focusing on one&#x27;s own work. This is also why I admire Andrew Ng. reply leoc 11 hours agoparentprevIt&#x27;s an alan-kayism: https:&#x2F;&#x2F;www.smithsonianmag.com&#x2F;innovation&#x2F;douglas-engelbart-... “I don’t know what Silicon Valley will do when it runs out of Doug’s ideas.” reply bmitc 14 hours agoparentprevThere are so many systems thinkers from that time that basically understood how the world works and how it could or should work that basically no one today knows of or considers. It&#x27;s a shame.This demo us one of the most mindblowing things I&#x27;ve seen and especially so if you consider its date of arrival. I truly think the audience didn&#x27;t really understand it. reply zamadatix 13 hours agorootparentWho&#x27;s to say there aren&#x27;t just as many such people know but we still have trouble recognizing them until well after the fact. reply bmitc 12 hours agorootparentMy point was more that these people wrote about things that predicted where we were headed but no one listened to them then, and no one listens to them now. reply tomcam 14 hours agoparentprevUsername truly checks out. And yes, a prophet far ahead of his time. reply cliffwarden 14 hours agoprevOften, i will go to science fiction (Rudy Rucker) to \"drink from the well\" and generate some inspiration for new ideas, projects, etc. This is one of the real-life sources that gives me that same feeling.It&#x27;s just amazing and awe inspiring to see something that felt truly \"out of the future\". You can probably draw lines to existing inventions and research but to me, this felt like he lived in the world where this technology already existed and was giving us a glimpse. reply pcurve 15 hours agoprevI had seen the video before but completely missed the video conference capability. I wonder what network line they used for that. Simply amazing reply jazzyjackson 14 hours agoparentThere&#x27;s a great book that details this event in one of the chapters, \"What the dormouse said\", iirc they used a television broadcast van sitting at the top of a hill to bounce the signal from where the machine sat and where the conference was.Stewart Brand was also behind this demo and it was his idea to pipe audio from the machine to the conference, so that any UI lag was accompanied by all the disk seeking noise instead of awkward silence. reply ftio 14 hours agorootparent+1 for What the Dormouse Said. Truly fantastic. reply LAC-Tech 14 hours agoprevOne of my favourite bits is how embarrassed he sounds about calling it the \"mouse\". reply memset 9 hours agoprevI&#x27;m not able to see this link, but I&#x27;m assuming it is this: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yJDv-zdhzMYGoogle \"The Mother of All Demos\"One fascinating thing to me is that he is explaining things with clarity that we take for granted - for example, the mouse - for the first time. He explains the mouse here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yJDv-zdhzMY#t=31m07s\"The tracking spot [cursor] moves in conjunction with the mouse. As it moves up and down and sideways so does the tracking spot.\" reply dang 13 hours agoprevHere are the past threads I found - seems like there should be others (anyone?):The Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36704885 - July 2023 (1 comment)50th Anniversary of the Mother of All Demos (2018) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31676445 - June 2022 (82 comments)The Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24467751 - Sept 2020 (1 comment)The Mothers of the Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24059231 - Aug 2020 (12 comments)Doug Engelbart’s 1968 demo - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23535853 - June 2020 (47 comments)The Mother of All Demos (1968) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20717835 - Aug 2019 (2 comments)50 years on, we’re living the reality first shown at the “Mother of All Demos” - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18646445 - Dec 2018 (2 comments)How Doug Engelbart Pulled Off the Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18640784 - Dec 2018 (2 comments)Celebrate the 50th Anniversary of Doug Engelbart&#x27;s Great Demo - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18640656 - Dec 2018 (13 comments)The 50th Anniversary of Doug Engelbart&#x27;s Great Demo - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18626215 - Dec 2018 (42 comments)Mother of all demos: Life as we know it turns 50 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18605185 - Dec 2018 (1 comment)Watching and Re-Watching “The Mother of All Demos” - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9366039 - April 2015 (24 comments)&#x27;The Mother of All Demos&#x27; Is 45 Years Old, Doesn&#x27;t Look a Day Over 25 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=6875879 - Dec 2013 (59 comments)The programming languages behind \"the mother of all demos\" - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5996695 - July 2013 (2 comments)The Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5996246 - July 2013 (4 comments)The Demo - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5987780 - July 2013 (36 comments)The Mother of All Demos, presented by Douglas Engelbart (1968) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5337425 - March 2013 (1 comment)Douglas Engelbart : The Mother of All Demos (1968) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=3011864 - Sept 2011 (2 comments)1968, Douglas Engelbart gives the Mother of All Tech Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1942687 - Nov 2010 (3 comments)The Mother of All Demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1939458 - Nov 2010 (10 comments)The mother of all demos - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1138879 - Feb 2010 (16 comments)The programming languages behind \"the mother of all demos\" - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=393653 - Dec 2008 (1 comment)1968: Engelbart demonstrates the mouse, email, collaborative work, hypertext, video conferencing - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=116121 - Feb 2008 (1 comment) reply AnimalMuppet 13 hours agoparentI think that&#x27;s the most entries I&#x27;ve ever seen in such a list. reply pvg 11 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37921113 reply Solvency 11 hours agorootparentprevIt&#x27;ll get posted again by Monday. reply layer8 15 hours agoprevAnd the associated YouTube channel: https:&#x2F;&#x2F;youtube.com&#x2F;@engelbartinstitute&#x2F;videos reply bdcravens 8 hours agoprevI&#x27;ve seen this several times, but what always struck me was how Doug&#x27;s presentation style felt quite contemporary, as if he was at a modern-day conference. reply swagempire 14 hours agoprevAh yes -- the Mother Of All Demos. Impressive! reply dr_dshiv 13 hours agoprevI met Doug once at a Singularity event at Stanford where I showed him how to ride a Segway. What a boss. reply gjvc 4 hours agoprev\"on this day\" reply ReactiveJelly 15 hours agoprevJust as telephones were a step backwards from telegrams, every other HCI mode has been a step backwards from the Xerox Alto :P reply AnimalMuppet 14 hours agoparentIn what sense were telephones a step backwards from telegrams? That seems completely wrong to me.Unless your whole post was sarcasm... reply satvikpendem 13 hours agorootparentThey probably mean synchronous vs async communication as well as the compactness of text versus audio in terms of information density. reply ThalesX 13 hours agorootparentprevSignal to noise ratio maybe. reply russellbeattie 10 hours agoprevIt&#x27;s interesting the amount of time technologies take to propagate. It seems to take about 5 years.The Xerox Alto appeared in 1973. The first integrated microchip CPUs were created in 1969 and the Altair launched in 1974. The Web was created in 1989 and Netscape Navigator launched in 1994. GPT based LLMs began in 2017 and hit the mainstream last year...Maybe these are cherry picked examples, but it seems like a pattern. reply quickthrower2 4 hours agoparentYes, you need time for hackers to hack on the new thing. 5 years from concept of the core thing, to production ready of the thing that depends on the core thing is pretty good. reply skibz 14 hours agoprevI&#x27;d absolutely love to have a small chorded keyboard for macros like Doug is using with his left hand here... reply melling 14 hours agoparentHow many chords did he have? I’d prefer going with body gestures. Google Soli looked promising:https:&#x2F;&#x2F;youtu.be&#x2F;r-eh2K4HCzI?si=aIVasKkvm5wtO3tu reply hackernews1134 6 hours agorootparentI had never heard of this before. It looks fascinating. Thank you for sharing!You say it “looked” promising - past tense - did Google kill it?Is anyone else working on anything similar (Apple, MS)? reply userbinator 15 hours agoprevI was expecting something about the demoscene. reply qwertox 15 hours agoparentNo reason to downvote. For many of us this demo is well known, but there&#x27;s no reason for us to expect that everyone must be aware of its existence.You&#x27;re one of today&#x27;s lucky 10,000. reply II2II 10 hours agoparentprevYou could also think of the early development of computers as the ultimate expression of the demoscene.The thing to keep in mind is that computers originated as very experimental calculating machines for the military about twenty five years earlier. It would take years for people to imagine the true potential of these machine. The successive developments were not simply a matter of waiting until the underlying technology was good enough to implement preexisting ideas.To put it in concrete terms: the concept of programming languages would have to wait until the development of the concept of stored program computers, since the notion of a programming language doesn&#x27;t have much meaning in the world of plugboards (literally wiring subsystems together to tell the computer what to do). More relevant: the notion of interactive user interfaces would have been inconceivable when the sole means of interacting with a computer was via a teletype. Even once graphical displays were introduced, it would take time to go from simply representing something visually to conceiving of how the technology could facilitate HCI.Even then my examples are highly simplified. We like to view the history of computers as a mostly linear progression. It wasn&#x27;t. There were many twists and turns and abandoned paths as we learned how to make useful machines. (For fun, try researching computer memories.) A lot of the early work in computers was presented in demos that reflected the figuring out of things. While those demos may not appear as fun and the scene wasn&#x27;t as culturally cohesive as the modern idea of the demoscene, the underlying spirit seems to be quite similar. reply unleaded 15 hours agoparentprevDont think that existed in the 60s mate reply ClearAndPresent 15 hours agorootparentWhile not technically a demo scene demo, in 1952 Sandy Douglas pushed the EDSAC to play a game of noughts and crosses (OXO) on its cathode ray tubes.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;OXO_(video_game) reply mikewarot 14 hours agorootparentprevThe DemoScene has existed forever... well before computers, lathes, etc... all the way back to \"Look at the way these pictures come to life and dance around when the torch flickers inside this cave\" reply vidarh 14 hours agorootparentprevThe \"scene\", no, but demos? Arguably, yes. The demo scene was little but the evolution of demonstrations of tech or art from doing it as e.g. part of a product demonstration or research to doing it as art or for reputation.E.g. the IBM 7094 \"singing\" Daisy Bell in 1961https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=41U78QP8nBk reply userbinator 15 hours agorootparentprevThe name doesn&#x27;t necessarily need to be the date it was created on. reply TheRealPomax 15 hours agorootparentprevWe had oscilloscopes in the 60&#x27;s. It could have. reply JKCalhoun 15 hours agorootparentDon Lancaster talks about \"quadrature art\" in his Active Filter Cookbook from 1975 — so it was a thing by then.https:&#x2F;&#x2F;www.radiolocman.com&#x2F;shem&#x2F;schematics.html?di=151800 reply codetrotter 15 hours agorootparentAlso, in the scene events they often have ANSI art competitions on the program but even before colors and computers people were using typewriters to make character based artwork. So in a sense, the ANSI art art form predates computers. Somewhat. reply cf100clunk 15 hours agorootparentprevIn a &#x27;&#x27;For All Mankind&#x27;&#x27; sorta way, I suppose. reply ck2 15 hours agoprevhug of deathhttps:&#x2F;&#x2F;google.com&#x2F;search?q=cache:https:&#x2F;&#x2F;dougengelbart.org&#x2F;... reply orangepurple 15 hours agoparentDoesn&#x27;t work. Try https:&#x2F;&#x2F;archive.is&#x2F;dLvnF reply cf100clunk 15 hours agorootparentAlso many other submissions here over the years about Doug Englebart and the famous 1968 demo. Use this HN search link:https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que... reply idkdotcom 15 hours agoprevnext [12 more] [flagged] idkdotcom 15 hours agoparentnext [12 more] [flagged] codetrotter 15 hours agorootparent> many in tech vilify him.He did that to himself. reply idkdotcom 15 hours agorootparentnext [11 more] [flagged] shadowgovt 15 hours agorootparent... And advertisers and revenue stream. reply idkdotcom 15 hours agorootparentElon is smart enough and will make this work. Had it not been because of his purchase of Twitter, we would not have a free speech oriented social media in the world.SolarCity ended up integrated in Tesla and the same could happen with Twitter. reply slater 15 hours agorootparent> Had it not been because of his purchase of Twitter, we would not have a free speech oriented social media in the world.What? There&#x27;s Gab, Truth Social and a host of other places where crypto-fascists can spew their inane nonsense. Elon&#x27;s purchase of Twitter may be many things, but \"freedom of speech\"-anything, it ain&#x27;t. reply shadowgovt 14 hours agorootparentIf anything, censorship on the platform increased after the purchase.https:&#x2F;&#x2F;www.aljazeera.com&#x2F;economy&#x2F;2023&#x2F;5&#x2F;2&#x2F;twitter-fulfillin... reply idkdotcom 12 hours agorootparentThat&#x27;s not what we are talking about here. We are talking about Twitter&#x27;s policies or community standards favoring certain points of view over others.Under Elon Musk, while no moderation method is ever going to be perfect, more people can express their sincerely held views without fear of censorship than under the leadership of Parag Agrawal. That&#x27;s just reality. reply shadowgovt 10 hours agorootparent... As long as their governments are cool with it. Pre-Musk Twitter fought overreach; Musk Twitter is rubber-stamping government takedowns.That... Actually sounds like pre-Musk Twitter defended people&#x27;s First Amendment rights more thoroughly. replyidkdotcom 12 hours agorootparentprevYou don&#x27;t have to take my word for it. The former CEO of Twitter, Parag Agrawal, said he didn&#x27;t believe in the First Amendment,https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2icsx9U8M8UThe First Amendment is one of America&#x27;s distinctive feature vis a vis other countries. It guarantees the freest expression regime there is in the world.Elon Musk, in acquiring Twitter and firing Parag Agrawal, restored the balance in the force. reply shadowgovt 12 hours agorootparentUm... Twitter isn&#x27;t bound by the First Amendment. That&#x27;s a constraint on government, not corporations nor individuals. Which is fine.I own a mastodon node. If I authorize a member to post from my node, and they start spewing pro-Nazi shit? I can and will cut them off my node. It&#x27;s mine, not theirs. They can go start their own if they want to spew that shit. Otherwise, people can and will assume I&#x27;m comfortable with that signal coming from something with my name on it, and they will be right. If you, personally, think that&#x27;s wrong of me, you are under absolutely no obligation to appear to my node or relay my content. It&#x27;s a very free country.We constrain the government from stopping speech because it has the power of violence to do so. Individuals and corporations do not. Indeed, the case can be made that when somebody who owns a forum or message board moderates the community, they&#x27;re exercising their freedom of the press. Same amendment, cuts both ways.... And your conclusion doesn&#x27;t follow from the previous statements. Regardless of the beliefs of the previous ownership, musk claimed he was \"liberating\" Twitter, but that didn&#x27;t prove out. He basically just replaced one idea of what content isn&#x27;t allowed with another idea of what content isn&#x27;t allowed. Meet the new boss, same as the old boss. reply idkdotcom 11 hours agorootparentDon&#x27;t get lost in technicalities and don&#x27;t impute me what I never said. I never claimed that Twitter is, from a legal standpoint, bound by the First Amendment. What I said is that Parag Agrawal and team made the conscious decision to institute censorship policies incompatible with the First Amendment.Obviously, the First Amendment case law only applies to public entities -originally only to federal entities and since the passage of the 14th amendment due to https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Incorporation_of_the_Bill_of_R... also to states and municipalities- and certain private entities that receive public money such as universities.There are also limitations to broadcasters that use properties, such as the allocation of frequencies, regulated by government https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fairness_doctrine .While how these latter policies apply to social media companies such as X&#x2F;Twitter is part of ongoing debate and litigation, private social media companies, irrespective of the law cases, can decide what kind of censorship regimes they like to have.Under Parag Agrawal and team, Twitter was a far left platform.Under Elon Musk and team, Twitter&#x2F;X is a centrist platform, meaning that neither the far right nor the far left have a free reign and the big middle is pretty much free to say anything they want as long as the First Amendment is not violated. reply shadowgovt 10 hours agorootparent> What I said is that Parag Agrawal and team made the conscious decision to institute censorship policies incompatible with the First Amendment.You actually said they don&#x27;t believe in the First Amendment, but I&#x27;ll take you at your word regarding what you meant. And I&#x27;d agree. They didn&#x27;t run the platform in a way that gave people as much liberty as the First Amendment guarantees them (qua government).They were running a social media platform. It&#x27;s best practice when running one to not grant 1A-level privileges; doing so makes it way more likely you&#x27;ll hit an actual legal snag like \"this site was complicit in planning an insurrection.\"Your claim basically boils down to \"I like the new censorship regime; it&#x27;s better than the old one.\" Sure; everyone has a preferred flavor of online community. But as I noted in a peer thread: Twitter does, if anything, more censorship now than it used to.It just no longer actively pushes Nazi shit off the platform as often, and my opinion of it reflects that new reality. So does its advertising base.(Hey, while we&#x27;re on the subject: how do you feel about what it says regarding Musk&#x27;s version of the First Amendment that he&#x27;s suing reporters for reporting true facts?) reply ArtTimeInvestor 15 hours agoprev [–] I think this is about the stage we are at in regard to decentralized finance at the moment.I often think about how strangely archaic our financial system is.For example when you start a new job and the first payment comes in after 4 weeks on the job. In the future, the payments will flow realtime.Or when I want to check the price of some stock and the stock market is closed, like it is most of the time. In the future, prices will be set on a global market with no downtime.Or when I talk to people who run online businesses and the plethora of problems they have with credit card payments. Because a credit car payment is not a payment. It&#x27;s a something where the receiver of the money is held responsible when the one who pays plays dirty tricks on them. In the future, an electronic payment will be simply a payment.Let&#x27;s hope we don&#x27;t need over 40 years from theory to reality like it took for the internet. reply ldjkfkdsjnv 13 hours agoparentPlease dont pollute this video demo with the degeneracy of \"crypto\" reply gemstones 14 hours agoparentprevDo you think that most businesses have the consistent cash flows needed to pay out wages every hour?I’m not sure this is a technical problem, I guess. Maybe a financial engineering problem but is the demand there? reply fragmede 14 hours agorootparentMost businesses have loans from banks and have some sort of line of credit (a business credit card, if not an actual line of credit at a bank) to draw from that could be used to pay employees from. reply themerone 15 hours agoparentprevI thought we are at the stage of DeFi where most people realized it has flaws that can only be fixed with centralization.Most crypto users are already using online exchanges and wallets, so from their perspective it already is centralized.True decentralized crypto only has niche applications outside a small number of enthusiasts. reply nyolfen 14 hours agorootparentspeaking more broadly than defi, there is an intrinsic tradeoff between decentralization and efficiency that is probably something like natural law or tautology. the promise of decentralized tech built on cryptography, to me at least, is that it offers a working alternative where there previously was none at all; almost everyone will probably end up using centralized and custodial systems due to their benefits, but the breakthrough is that you don&#x27;t have to. you can always choose to trust in the presence of trustless system, but you can&#x27;t choose trustlessness in its absence. reply ArtTimeInvestor 15 hours agorootparentprevnext [–]only has niche applications outside a small number of enthusiastsLike the internet in 1968. reply themerone 13 hours agorootparentThe internet didn&#x27;t exist then, and it&#x27;s still an Apples and oranges. Billions of people have access to crypto technology now, and there are no gatekeepers preventing them form participating.Arpanet was started 1969 and you had to be part of a small number of institutions to have access. reply legendofbrando 5 hours agorootparentprevYou me and everyone else on this thread are here getting value out of it. That’s more than the number of people who get value out of crypto. reply usefulcat 13 hours agoparentprev> In the future, the payments will flow realtime. Aside from not having to wait four weeks before the first payment, what would be the advantage of that? reply brazzy 13 hours agoparentprev [–] >Or when I talk to people who run online businesses and the plethora of problems they have with credit card payments. Because a credit car payment is not a payment. It&#x27;s a something where the receiver of the money is held responsible when the one who pays plays dirty tricks on them. In the future, an electronic payment will be simply a payment.That last sentence indicates you have failed to understand the problems. A payment that is \"simply a payment\" is a huge step backwards from those credit card systems. If fraud prevention and legal recourse to undo fraudulent payments is not baked directly into your system, that system is worthless. reply ArtTimeInvestor 13 hours agorootparent [–] You mean worthless like those trillions of dollars worth of cash out there?Worthless like anything people used to trade for thousands of years before credit cards arrived?Oh, and there is no fraud prevention baked into credit cards. That&#x27;s what I said. Sellers hate credit cards because they have to deal with all that fraud:https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=credit+card+fraud reply Tor3 43 minutes agorootparent\"Sellers hate credit cards ...\" That&#x27;s news to me. The truth is that sellers hate cash. So much so that around here several establishments display \"card only\" at the entrance, even though cash is legal tender - i.e. they can&#x27;t by law refuse cash. And still: They do. (And \"card\", in this context, includes debit as well as credit cards, but as credit cards are so extremely common.. I, for one, haven&#x27;t dealt in my native country&#x27;s cash in some twenty years, and that&#x27;s pretty common.). reply inglor_cz 22 minutes agorootparentAt least where I live, legal tender means that you cannot refuse cash for settlement of an already existing debt, but you can definitely say you don&#x27;t want to accept cash for transactions that haven&#x27;t yet occured.So a \"card only\" announcement at a shop is perfectly legal. reply legendofbrando 5 hours agorootparentprevCrypto thinking is always basically some version of how modern finance is broken, yet the solution is basically “hey consumers, whenever you buy something you’re at risk that you could have no recourse.”Of course individual merchants dislike cards, they create a wedge between consumer and merchant -&#x2F; but that wedge also enables people to freely spend more than they’ll ever extract from falsifying things, thereby benefiting all merchants.Crypto logic ignores that the modern banking system is actually far more logical than it sounds at first blush when you just take the perspective that not everyone should be trusted all the time. reply brazzy 11 hours agorootparentprev [–] > You mean worthless like those trillions of dollars worth of cash out there?...which is getting used less and less in the developed world. In an increasing number of countries, carrying cash is a thing of the past, or done as a rarely-used backup.> Worthless like anything people used to trade for thousands of years before credit cards arrived?And which have fallen or are falling out of use when competing with systems that better serve the needs of the users. And safety from fraud and theft is a pretty big need.> Oh, and there is no fraud prevention baked into credit cards.Admittedly it&#x27;s more bolted on than baked into (since the system is so old), but it most certainly is there.> Sellers hate credit cards because they have to deal with all that fraudWhich doesn&#x27;t mean there&#x27;s not fraud prevention, just that it often fails. As it always will in every system, because it&#x27;s a really hard problem. And a human problem, not a technical problem. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The document contains valuable information and resources about Doug Engelbart's 1968 demo, such as videos, photos, conference proceedings, and online exhibits.",
      "It emphasizes the continued importance and impact of Engelbart's work, as well as the various events and recognition he has received.",
      "The document also provides online resources for those interested in learning more about Engelbart's contributions."
    ],
    "commentSummary": [
      "The collection of discussion threads explores various topics including the decline of SRI, Doug Engelbart's groundbreaking technology demonstration, the significance of demos in the computer industry, Elon Musk's influence on Twitter, and the debate between centralized and decentralized financial systems.",
      "These discussions offer valuable insights into the evolution of computer technologies and the role of visionary thinkers in driving innovation.",
      "The threads also touch on the contentious issues of censorship and the impact of technology on society."
    ],
    "points": 245,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1702143906
  },
  {
    "id": 38583489,
    "title": "Vulnerabilities in TETRA Radio Network Encryption Algorithms Exposed",
    "originLink": "https://www.cryptomuseum.com/radio/tetra/burst.htm",
    "originBody": "Homepage Crypto Spy radio Burst encoders Intercept Covert Radio Index Glossary SINCGARS ZODIAC TITAAN BAMS Clansman Bowman TETRA Morse Morse keys Crystals CHX-200 RT-1439 RT-3600 SE-6861 PRC-319 SPIDER R-142 Selex PRR FuG-8 Countries PC Telex Telephones People Agencies Manufacturers DONATE Publications Standards For sale Kits Shop News Events Wanted Contact About us Links TETRA TEA1 → TAA → 9 August 2023 — We are now able to share the reverse-engineered C-source code of the TAA1, TEA1, TEA2 and TEA3 algorithms. This clearly shows the weakness in TEA1. Also published is a paper on TETRA:BURST, written by the Midnight Blue researchers Carlo Meijer, Wouter Bokslag and Jos Wetzels. ➤ More TETRA:BURST Vulnerabilities in TETRA radio networks On 24 July 2023, researchers of the Dutch security firm Midnight Blue revealed that they had found five vulnerabilities in the authentication and encryption algorithms of the TETRA radio network, which is used in the critical infrastructure of more than 100 countries. Two of the vulnerabilities are deemed critical. One of them appears to be an intentional backdoor [1]. The vulnerabilities were discovered during the course of 2020, and were reported to the NCSC in the Netherlands in December of that year. It was decided to hold off public disclosure until July 2023, to give emergency services and equipment suppliers the ability to patch the equipment. Reverse-engineering RE:TETRA Several algorithm suites and cryptographic primitives are used at the core of the TETRA protocol, in particular TAA for authentication, and TEA for encryption. As these algorithms are secret, they have never been publicly disclosed and, hence, have never been subjected to in-depth public scrutiny. In order to find any vulnerabilities in the code, the researchers therefore first had to reverse-engineer the TAA and TEA algorithms, which appeared to be not trivial at all. The reverse-engineering project — codenamed RE:TETRA — was started on 1 January 2020, with funding from the non-profit NLnet foundation, as part of the latter's European Commission supported NGI0 PET fund. Once the reverse-engineering was completed, the researchers were able to isolate and analyse the cryptographic functions. Platform For reverse-engineering, a Motorola MTM-5400 commercial off-the-shelf (COTS) mobile radio was used, along with associated firmware upgrades obtained through amateur radio forums. Reading the contents of a firmware upgrade is not trivial though, as it is heavily encrypted and relies on a Trusted Execution Environment (TEE), embedded in the core processor of the radio. The MTM-5000 series is built around a Texas Instruments OMAP-L138 System on Chip (SoC), which contains an ARM core and TI C6748 DSP. It offers secure boot by means of TEE, as a result of which confidential code can be loaded and executed without revealing its implementation. This is how the TETRA algorithms are protected. In order to execute arbitrary code on the ARM core, the researchers first had to exploit another series of known vulnerabilities, using a serial AT command interface as the attack surface and performing a cache-timing side channel attack.With the ARM core and the DSP now firmly under control of the attackers, the MBM-5000 series can be used as a development platform for researchers, allowing in-depth security research into TETRA, which will hopefully improve overall TETRA security. The Midnight Blue researchers have announced that they will publicly release the tools for unpacking Motorola firmware upgrade packages, as well as utilities for instrumenting, debugging, monitoring and packet injection. Vulnerabilities TETRA:BURST Once the software had been reverse-engineered, the researchers were able to do in-depth security research with the aim to find vulnerabilities and ultimately mount an attack. Over the course of one year, the following vulnerabilities were discovered: Dependence on network time The Air Interface Encryption (AIE) keystream relies on network time, which is publicly broadcast in an unauthenticated manner. This allows for decryption oracle attacks and may lead to loss of confidentiality and authenticity. This vulnerability is deemed critical. CVE-2022-24401 · This problem can be fixed by installing a firmware upgrade. ★★★★★ Backdoor in TEA1 The TEA1 algorithm has a backdoor that reduces the original 80-bit key to a size which is trivially brute-forceable on consumer hardware in minutes. This is a critical flaw that leads to loss of confidentiality and authenticity. The researchers believe that this is a deliberately created weakness to provide intelligence services access to the traffic. CVE-2022-24402 · This problem can be fixed by using E2EE on top of TEA1. ★★★★★ Lack of ciphertext authentication The lack of ciphertext authentication of AIE allows for malleability attacks. This may eventually lead to loss of authenticity. CVE-2022-24404 · This problem can be fixed by installing a firmware upgrade. ★★★★ Weak anonymisation The cryptographic scheme used to obfuscate radio identities, has a weak design that allows attackers to deanonymize and track users. CVE-2022-24403 · This problem can be fixed by using E2EE on top of TEA1. ★★★ DCK can be set to 0 A flaw in the authentication algorithm allows attackers to set the Derived Cipher Key (DCK) to 0. This may lead to loss of authenticity and partial loss of confidentially. CVE-2022-24400 · This problem can be fixed by migrating to TAA2 (long-term). ★ ETSI's reply 24 Aug 2023 The TETRA encryption algorithms were implemented in 1996 and 1997 by or on behalf of the Security Experts Group of the European Telecommunications Standards Insitute (ETSI-SAGE). It is ETSI's policy not to disclose their cryptographic algorithms and not to submit them to public in-depth security research, other than validation by the other ETSI-SAGE members, claiming that obscurity is also a form of security [7]. Researchers often see this as a violation of Kerckhoffs's Principle however [5], which in the long run can potentially lead to weak exploitable systems. On the day of the TETRA:BURST disclosures, ETSI issued a press statement in which the findings of the researchers were largely downplayed, claiming that improvements were already underway and that no actual exploitations of operational networks were known at the time [6]. The Midnight Blue researchers have since demonstrated real-life exploitations of some of the vulnerabilities, for example at the 2023 Blackhat Conference in Las Vegas (USA). They have shown that TETRA communications secured with the TEA1 encryption algorithm can be broken in one minute on a regular commercial laptop and in 12 hours on a classic laptop from 1998 [III]. Demonstrations 1. Dependence on network time ★★★★★ CVE-2022-24401 In the video below, the first critical vulnerability (CVE-2022-24401) is demonstrated. It shows a decryption oracle attack that is based on the fact that the Air Interface Encryption (AIE) keystream relies on network time, which is publicly broad­cast in an unauthenticated manner. The video shows a lab setup in which an instrumented base station is used as an attacker platform. 2. Backdoor in TEA1 ★★★★★ CVE-2022-24402 Midnight Blue researchers discovered a backdoor in the TEA1 encryption algorithm, which had clearly been added deliberately, probably to give inteligence services access to the system. In the video below, the TEA1 backdoor is demonstrated on a real network. After breaking the initial key — one minute on a regular laptop — the rest of the traffic can be read without any problems. 3. Breaking TEA1 on a 1998 laptop ★★★★★ CVE-2022-24401 After the TETRA:BURST vulnerabilities were dis­closed on 24 July 2023, the European standards body ETSI downplayed the discoveries, saying that the short TEA1 key is not a real backdoor, and that a key length of 32 bits was appropriate when the standard was issued in the late 1990s. To bust these claims, the researchers have run their TEA1 cracking tool on an old 1998 Toshiba laptop, running Microsoft Windows 95 on a Pentium II at 266 MHz. The key was found after 12.5 hours, which demonstrates that even in the late 1990s an attack would have been realistic. TETRA Encryption Algorithms TEA TEA is a set of encryption algorithms that can be used for Air Interface Encryption (AIE) in the TETRA communications system. It consists of four variants (TEA1, TEA2, TEA3 and TEA4), with differing levels of security, depending on the application. The algorithms are simple yet strong, and can easily be implemented in both hard- and software. All TEA variants use an 80-bit key. The structure of the TAA and TEA algorithms, including the HURDLE block cipher used in TAA, is described in detail in a paper by Carlo Meijer, Wouter Bokslag and Jos Wetzels — all involved in the TETRA:BURST vulnerability research at Midnight Blue [I]. ➤ Read the paper ➤ Reverse-engineered source code ➤ Overview of TEA algorithms TEA1 algorithm The TEA1 algorithm was intended for commercial applications and restricted export. Its structure is very similar to TEA2, but the 80-bit key is manipulated in such a way that it becomes a 32-bit key, which can be broken with a brute-force attack on a regular commercial laptop in around one minute. The source code snippet below shows how the key length is reduced. int32_t tea1_init_key_register(const uint8_t *lpKey) { int32_t dwResult = 0; for (int i = 0; i > 24) ^ lpKey[i] ^ dwResult) & 0xff]; } return dwResult; } The key consists of 80 bits, which is equal to 10 bytes. In the above code, the 10 bytes are processed one at a time, and then shifted into the result (dwResult) register. However, as the dwResult register is only 32 bits wide, the first 48 bits are shifted out and the key consists of the last 32 bits only, which is trivially short for a brute-force attack. Although the short key length can be seen as a backdoor — it is a deliberate weakening — this is disputed by the original developer, as it was done in plain sight and not hidden in some complex code, function or table [3]. The short key length was simply an ETSI requirement. Any company that had to implement the algorithm in its equipment, had access to the design specification and must have been aware of the limitation [3]. This is corroborated by Gert Roelofsen in an interview with De Volkskrant on 29 July 2023, in which he states that the government had been aware of it for the past 30 years [2]. At the time, Roelofsen was on the ETSI experts team on behalf of KPN. ➤ More about TEA1 TEA2 algorithm TEA2 was developed for European emergency services, and is arguably the strongest of the four algorithms. It uses the full 80-bit key length. If we assume that a 32-bit key can be broken in one minute – as with TEA1 above – we can calculate how long it would take to brute-force an 80-bit key. As each bit doubles the required time, the total time needed is: 60 × 248 [sec] ≈ 535 milion years If there is no known way to break the cipher other than by means of a brute-force attack, this algorithm can be assumed secure. ➤ More about TEA2 TEA3 algorithm TEA3 is intended for emergency services outside Europe. It is similar to TEA2 and does not have the weakness of TEA1 (i.e. the reduced key length). Although it is likely that TEA3 is stronger than TEA1 and TEA4, it is also likely that it is weaker than TEA2. So far, the researchers have not found any weaknesses in this cipher, but acknowledge the need for further research. ➤ More about TEA3 TEA4 algorithm The TEA4 algorithm is intended for commercial use and restricted access, just like TEA1, which suggests that it also has a built-in weakness. However, as no implementation of this cipher was available on the Motorola target MTM-5400 platform, the researchers were unable to review the algorithm. It seems likely though, that it has similar weaknesses to TEA1. ➤ More about TEA4 Exploitation Although there is no direct proof of actual exploitation of a TETRA network, it seems likely that malicious parties are interested in reading or interfering with TETRA traffic. The simple fact that no exploitations are known [6], does not mean that they do not exist. The TETRA:BURST project shows that reverse-engineering of the cryptographic primitives is feasible with limited resources. A weakness like the reduced key length of TEA1 is so obvious that it will certainly have been noticed and exploited. Apart from the possibility of reverse-engineering, an adversary would not be hampered by legal restrictions, and might use leaked or stolen documentation instead. Responsible disclosure Below is a timeline of events since the start of the reverse-engineering project RE:TETRA on 1 January 2021 and the first public disclosure on 24 July 2023. The Dutch NCSC (NCSC-NL) was informed in December 2021, after which meetings were held with the law enforcement and intelligence communities, as well as with ETSI and the vendors. Shortly afterwards, on 2 February 2022, preliminary advice was distributed to the various stakeholders and CERTs. The remainder of 2022 and the first half of 2023 were used for coordination and advisory sessions with stake­holders, allowing manufacturers to come up with firmware patches, updates or workarounds. The time between the first contact with NCSC-NL and the public disclosure of the vulnerabilities, is a carefully chosen tradeoff between giving asset owners as much time as possible and the right of the public to know. The 1.5+ years inbetween were used to find as many stakeholders as possible and inform/advice them, so that software updates and mitigations could be devoloped. Events The Midnight Blue researchers will present their finding at the following events and conferences: 2023 Aug 9Blackhat 2023, Las Vegas (USA) 2023 Aug 11Usenix Security, Anaheim (Germany) 2023 Aug 13DEF CON, Las Vegas (USA) 2023 Aug 15-19CCC summer camp, Berlin (Germany) 2023 Oct 3ONE conference, The Hague (Netherlands) 2023 Nov 14ISC, Copenhagen (Denmark) Publications Carlo Meijer, Wouter Bokslag and Jos Wetzels, All cops are broadcasting: TETRA under scrutiny Paper submitted to Crypto Museum. 9 August 2023. Full source code of TAA1, TEA1, TEA2 and TEA3 algorithms in C Reverse-engineered and used for analysis and real life tests. Midnight Blue, 9 August 2023. All Cops Are Broadcasting, Breaking TETRA after decades in the shadows Presentation by Jos Wetzels, Carlo Meijer and Wouter Bokslag at Black Hat 2023. Midnight Blue, 9 August 2023 Further source codes on GitHub Midnight Blue, TETRA burst sources Datasheets OMAP-L138 processor documentation Texas Instruments website. TMS320 DSP documentation Texas Instruments website. References TETRA:BURST Midnight Blue, 24 July 2023. Huib Modderkolk, Overheid weet al dertig jaar van 'achterdeur' in beveiliging radiocommunicatie De Volkskrant, 29 July 2023. Cees Jansen, TEA co-developer at Philips Crypto BV Personal correspondence. Crypto Museum, 2 August 2023. Royal Holloway, University of London, Impact case study (REF3b) Design of a block cipher used in TETRA secure radio. REF2014. Undated but probably 2014. Wikipedia, Kerckhoffs's principle Retrieved 5 August 2023. ETSI and TCCA Statement to TETRA Security Algorithms Research Findings Publication on 24 July 2023 ETSI/TCCA. Sophia Antipolis, 24 July 2023. Kim Zetter, Interview with the ETSI Standards Organisation That Created TETRA \"Backdoor\" Interview between Kim Zetter and Brian Murgatroyd, Chairman ETSI TC TETRA. Zero Day website, 25 July 2023. ETSI and TCCA Statement to TETRA Security Algorithms Research Findings Publication on 24 July 2023 ETSI/TCCA. Sophia Antipolis, 24 July 2023. Further information TAA algorithm TEA algorithms TETRA radio network About Midnight Blue Other websites TETRA Kit, open source TETRA decoder for RTL-SDR Any links shown in red are currently unavailable. If you like the information on this website, why not make a donation? © Crypto Museum. Created: Tuesday 08 August 2023. Last changed: Saturday, 26 August 2023 - 07:00 CET.",
    "commentLink": "https://news.ycombinator.com/item?id=38583489",
    "commentBody": "Vulnerabilities in TETRA radio networksHacker NewspastloginVulnerabilities in TETRA radio networks (cryptomuseum.com) 199 points by porsupah 16 hours ago| hidepastfavorite76 comments neilv 15 hours ago> Two of the vulnerabilities are deemed critical. One of them appears to be an intentional backdoor [...] Reading the contents of a firmware upgrade is not trivial though, as it is heavily encrypted and relies on a Trusted Execution Environment (TEE), embedded in the core processor of the radio.*I don&#x27;t know whether the backdoor allegation is correct, but unfortunately we should treat opaque ostensible security with skepticism.By their nature, such things often can be used for our protection at the same time they are secretly used against us. reply creer 6 hours agoparentIsn&#x27;t the time for the generous qualifiers long past? Such, often, can, our protection, unfortunately, skepticism... There is a good track record by now. Something like:\"under the guise of protecting trade secrets and swear words in the code, the code encryption actually protects crappy code stuffed with vulnerabilities (i.e. future entry points available to the right friends and foes) and backdoors (some forgotten and some very much not)\". And in this case \"future\" was a while ago. reply jordanmoconnor 14 hours agoparentprevnext [3 more] [flagged] lostlogin 14 hours agorootparentThat’s your interpretation? I read it as ‘show source, distrust the opaque and while this might be unintentional, don’t assume it is.’ reply generalizations 14 hours agorootparentThe last paragraph is probably what they were referring to. reply wyck 15 hours agoprevThe newsworthy item here is that this is an intentional backdoor. The wikipedia pages list the specific uses per country and department. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Terrestrial_Trunked_Radio#Usag... reply H8crilA 15 hours agoparentDo you remember when cryptography export was controlled? It was implemented by limiting key size to certain number of (effective) bits (of security). This suite is just a victim of that law, as it is a 1990s design. reply tptacek 14 hours agorootparentIt&#x27;s not \"just\" a victim of that law unless they disclosed that the export cryptography protocol was trivially breakable. Export cryptography in the 1990s US was documented. reply jeroenhd 5 hours agorootparentTo quote https:&#x2F;&#x2F;www.cryptomuseum.com&#x2F;crypto&#x2F;algo&#x2F;tea&#x2F;1.htm:> The algorithm was developed in 1996&#x2F;97 at Philips Crypto BV in Eindhoven (Netherlands) as a consultancy job for ETSI-SAGE. As the algorithm is secret, it has never been submitted for peer-review or in-depth security analysis. Instead it was evaluated by other ETSI-SAGE members before being submitted as a formal ETSI standard. All members of the TEA family, use an 80-bit key, but in the case of TEA1 it is effectively reduced to 32 bits, which makes it vulnerable to a brute-force attack. According to one of the developers, this was mandatory to get the algorithm approved for export. It was part of the ETSI specification and was clearly visible in the code [3]. reply wkat4242 15 hours agorootparentprevAnd when people were saying it was a stupid thing? This is one of the many examples that prove it. reply creato 14 hours agorootparentprevReading the wiki page, it seems to be a European standard. The law you are referring to sounds like a US law. reply jeroenhd 5 hours agorootparentAmerican encryption laws did not exist in a void. According to this website, one person who was working on the standard indicated that the key space had to be reduced to allow for export.Take, for example, this old article discussing French law in the late 1900s: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20000118230559&#x2F;http:&#x2F;&#x2F;www.opengr...French cryptography exports required authorisation if the key strength was higher than 40 bits. With its 80 bit keys, the TETRA key space would&#x27;ve been too big to qualify for free exports.As TETRA is part of an ETSI standard, it seems pretty likely to me that one of the European countries had a 32 bit restriction, and TETRA might as well pick the lowest common denominator when it comes to selecting a backdoor. reply LocalH 15 hours agoprevSounds like they took the \"roll your own and don&#x27;t tell anyone how it works\" approach. Security by obscurity is never security. History has shown that the open encryption standards are the most secure. reply ok123456 15 hours agoparentIt&#x27;s more of intentionally reducing the keyspace when generating keys. You can use weakly generated keys with industry-standard encryption algorithms. When your 4096-bit key is only 32 bits, it doesn&#x27;t matter how well-trusted the algorithm is. reply tptacek 14 hours agorootparentI just skimmed the paper but it looked to me like the key generation is the same in all profiles, but the TEA1 case has a key setup that compresses the generated key down to 32 bits. reply jnwatson 14 hours agorootparentprevThe researchers found several problems. The backdoor seems intentional, but the others do not. They broke the TAA protocol. reply londons_explore 14 hours agoparentprevAnd yet this one lasted 30 years. That&#x27;s far longer than most open encryption algorithms continue to be deemed secure.Obviously you can debate wether having it &#x27;appear&#x27; secure for longer before someone publishes details of the flaw is more important or not... reply jjav 13 hours agorootparent> And yet this one lasted 30 years.What do you mean lasted? If it is an intentional backdoor, it was vulnerable (to those who knew the backdoor) from day 1, so it was never secure let alone 30 years. reply inopinatus 13 hours agorootparentprevThe TEA1 key compression weakness may have been known to intelligence agencies as early as 2006. See https:&#x2F;&#x2F;www.cryptomuseum.com&#x2F;radio&#x2F;tetra&#x2F; under section \"Compromise\". reply perlgeek 13 hours agorootparentprevIt lasted 30 years in the sense it hasn&#x27;t been publicly broken before.We don&#x27;t know how many intelligence agencies have found some of these and are happily listening in on \"secure\" communication, concealing that fact successfully. reply nicce 12 hours agorootparentThis argument holds for any non-disclosed vulnerabilities, however. reply michaelt 13 hours agorootparentprevAren&#x27;t these encrypted radios mostly for cops?I mean, this is embarrassing - but who cares if the secret police are spying on the regular police? reply creer 6 hours agorootparentSeems this was a general export item resulting from the 1990&#x27;s crypto restrictions. The article mentions 100 countries using them. That would be agencies for whom it didn&#x27;t matter, yes, (ambulance, corp security, etc) - but also everyone else who could not afford anything better but for whom security actually mattered. Not every country can afford to roll their own for this kind of stuff. reply perlgeek 11 hours agorootparentprevDoes the FBI use these? The FBI is tasked with counter intelligence, and for a spy it could be highly relevant to learn if they are being targeted. reply dghlsakjg 13 hours agorootparentprevWhose secret police are spying on the civilian police.Is it more concerning if it’s the Russian secret police spying on the Kyiv police? reply snvzz 11 hours agorootparentprevThe publicly known attacks are recent, yes.I know some group had it pwned at least 2010-ish. But won&#x27;t elaborate.And I&#x27;m sure they weren&#x27;t the first, nor the only ones. reply nicce 14 hours agorootparentprev> And yet this one lasted 30 years.Main goal of security through obscurity is the hindrance. Make it slower and harder to to detect possible vulnerabilities.So indeed, there is something to debate.But I guess it helps only against those with limited resources, not against nation states. reply swells34 14 hours agorootparentThis is analogous to physical security doors. They are considered passive security, since they are a deterrent, and are rated by the numbers of hours they are expected to hold up against hand tools. reply xmprt 13 hours agorootparentprevIs it still true that nation states are at the forefront of innovation and the largest security threats? At least in the United States, I&#x27;d be surprised to learn that their best and brightest minds are working in three letter government agencies when they can work in industry for more money and less bureaucracy. reply londons_explore 5 hours agorootparentDoes one need the best and brightest minds to break crypto? Or does it just take a lot of full-time regular minds?Because the academic&#x2F;opensource communities famously don&#x27;t have many hours to dedicate to the cause. reply nicce 8 minutes agorootparent> Because the academic&#x2F;opensource communities famously don&#x27;t have many hours to dedicate to the cause.People in academics dedicate their lifes for this. Who has more time? reply tptacek 13 hours agorootparentprevYes. Additionally, there are extensive public&#x2F;private partnerships. reply fmajid 13 hours agorootparentprev> Main goal of security through obscurity is the hindranceNo, the main goal is to obfuscate just how incompetent the authors of the spec are, and how clearly they illustrate Dunning-Kruger. reply nicce 12 hours agorootparent> No, the main goal is to obfuscate just how incompetent the authors of the spec areIf you agree that it obfuscates the meaning of the author’s work, then it also slows down other things recursively… reply umvi 15 hours agoparentprevObscurity should never replace security, but it can and does augment security by increasing the cost to even study the security. reply stavros 15 hours agoparentprevThe bigger issue here is that there&#x27;s an intentional vulnerability. reply denysvitali 15 hours agoparentprevYou can&#x27;t easily put backdoors in cryptographic algorithms that can be audited reply tptacek 15 hours agorootparentYou certainly can. reply anonym29 15 hours agorootparentprev^ this post brought to you by RSA, ANSI, ISO, NIST, the NSA, and the authors of DUAL_EC_DRBG&#x2F;s reply gpderetta 15 hours agorootparent... Which iirc was immediately identified as suspicious during auditing. reply a1369209993 14 hours agorootparentAnd yet became a official standard anyway, and was occasionally actually used, despite the fact that is was obviously backdoored to anyone who knew anything about (elliptic-curve) cryptography. (It&#x27;s literally a textbook-exercise leaky RNG, of the sort that you would find under \"Exercise: create a elliptic-curve-based RNG that leaks seed bits within N bytes of random data.\" in a actual cryptography textbook.) reply tptacek 14 hours agorootparentYou don&#x27;t really need to understand elliptic curves to understand Dual EC. It&#x27;s a public key RNG. The vulnerability is that there&#x27;s a matching private key. reply a1369209993 12 hours agorootparentTrue, but my parenthetical was covering the opposite issue: it&#x27;s possible to not realise DUAL_EC_DRBG is broken (rather than impossible to realise it) if your only knowledge of cryptography is, say, hash functions and stream ciphers (so you don&#x27;t recognise public key cryptography from looking at it). It&#x27;s unlikely, because DUAL_EC_DRBG is really obviously broken, but I wouldn&#x27;t fault someone who knew nothing about elliptic-curve cryptography for missing it, even if they were familiar with other types of cryptography. (I would fault them for claiming that it&#x27;s secure, rather than recognizing that they don&#x27;t know enough to evaluate its security, but you can&#x27;t conclude something&#x27;s backdoored just from that.) reply anonym29 13 hours agorootparentprevThe assertion I was refuting was that they couldn&#x27;t be easily inserted into an audited library, not that they wouldn&#x27;t be detected. reply xyzzy4747 15 hours agoparentprevSecurity has many layers. Obscurity can be one of them. reply barsonme 12 hours agorootparentObscurity can certainly be part of defense in depth, but it unequivocally does not make anything more (meaningfully) secure.For example, hiding the fact that your data is encrypted with AES doesn’t make an attacker any more likely to be able to break AES. Similarly, hiding the fact that you use a weak encryption algorithm doesn’t keep an attacker from breaking it. reply notfed 1 hour agoprevIn 2023 you&#x27;re telling me that some emergency vehicles are happily rocking encryption protocols with 80-bit, wait actually, 32-bit keys? These are all cases of systemic procrastination. We&#x27;re talking about emergency vehicles here though, so: neglect.Nobody is surprised these protocols have been broken, it should not be a surprise, and having some kind of panic reaction should be considered either a charade or a case of abysmal management. reply Roark66 17 minutes agoprevThe fact many armies use this (including my own country&#x27;s) is mind boggling. Didn&#x27;t they request the technical details of the encryption and the source code and have it vetted properly before awarding the tender for these devices? &#x2F;sarcasm reply marcus0x62 15 hours agoprevThe interview that is linked[0] in the footnotes of the article with the person from ETSI is absolutely wild... Some excerpts:> kz (interviewer): How did it go about meeting those requirements, because that&#x27;s the one they&#x27;re saying has a backdoor in it. Was that the condition for export?> BM (ETSI): Backdoor can mean a couple of things I think. Something like you&#x27;d stop the random number generator being random, for instance. [But] what I think was revealed [by the researchers] was that TEA1 has reduced key-entropy. So is that a backdoor? I don&#x27;t know. I&#x27;m not sure it&#x27;s what I would describe as a backdoor, nor would the TETRA community I think....> KZ: People ... believe they&#x27;re getting an 80-bit key and they&#x27;re not.> BM: Well it is an 80-bit long key. [But] if it had 80 bits of entropy, it wouldn&#x27;t be exportable....> kz: You&#x27;re saying 25 years ago 32 bit would have been secure?> BM: I think so. I can only assume. Because the people who designed this algorithm didn&#x27;t confer with what was then EP-TETRA [ETSI Project-TETRA is the name of the working group that oversaw the development of the TETRA standard]. We were just given those algorithms. And the algorithms were designed with some assistance from some government authorities, let me put it that way....> bm: That&#x27;s what we now know yeah - that it did have a reduced key length.> KZ: What do you mean we now know? SAGE created this algorithm but the Project-TETRA people did not know it had a reduced key?> BM: That&#x27;s correct. Not before it was delivered. Once the software had been delivered to them under the confidential understanding, that&#x27;s the time at which they [would have known]....You&#x27;ve really got to wonder who at ETSI gave the thumbs up on doing this interview.0 - https:&#x2F;&#x2F;www.zetter-zeroday.com&#x2F;p&#x2F;interview-with-the-etsi-sta... reply sillysaurusx 14 hours agoparentThe researchers added a footnote explicitly refuting the claim that 32 bit keys were secure 25 years ago, too.> The Midnight Blue researchers have since demonstrated real-life exploitations of some of the vulnerabilities, for example at the 2023 Blackhat Conference in Las Vegas (USA). They have shown that TETRA communications secured with the TEA1 encryption algorithm can be broken in one minute on a regular commercial laptop and in 12 hours on a classic laptop from 1998 [III]. reply marcus0x62 13 hours agorootparentIn the mid-late 90s, 40-bit encryption was common due to US export control restrictions, and even then, that was thought to be insecure against a nation state attacker.In 1998, the EFF built a custom DES Cracker[0] for around $250k that could crack a 56-bit DES message in around 1 week. As was the custom at the time, they published the source code, schematics, and VHDL source in a printed book to evade (and, I guess, mock) export restrictions.0 - https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;EFF_DES_cracker reply clankyclanker 13 hours agorootparent(If that&#x27;s the case I&#x27;m thinking of) it was actually documented as a challenge to export restrictions, mocking them was merely a pleasant byproduct.The EFF&#x27;s legal challenge was essentially that if crypto is a munition, then this printed book explaining the crypto is also at least as much of a munition, if not more so. They gave the judge the choice between deciding that a printed book is some sort of deadly tool, or deciding that crypto wasn&#x27;t conceptually a munition. Strangely, the judge ruled in the EFF&#x27;s favor. reply marcus0x62 12 hours agorootparentThat was Phil Zimmerman’s book containing the PGP source whixh was published a few years before the Deep Crack book. https:&#x2F;&#x2F;philzimmermann.com&#x2F;EN&#x2F;essays&#x2F;BookPreface.html replyk8svet 15 hours agoprevWhat exactly were TETRA radios used for? I assume they were government&#x2F;infra related, but then I don&#x27;t understand why they&#x27;d need to backdoor the keying reply mcpherrinm 15 hours agoparentThey are used for many things, like fire, ambulance, railways, harbour operations, police, military, coast guard, and so on.The weaker cipher mode, TEA1, is used when selling the radios to anyone who may not necessarily be an ally or highly trusted. This is the legacy of strong crypto being export-controlled.It was public that these ciphers were weaker, but they were actually much weaker than advertised. This is the backdoor. reply tptacek 15 hours agoparentprevThey don&#x27;t so much backdoor the keying as that they have 4 different cipher profiles, and the one approved for global rather than European use (TEA1) compresses the key from 80 to 32 bits.It&#x27;s essentially a surreptitious version of what the US did in the 1990s with \"export ciphers\". reply gwbas1c 15 hours agorootparentWhich makes me question describing this as a \"deliberate backdoor.\" reply tptacek 14 hours agorootparentIt&#x27;s pretty clearly a deliberate backdoor. reply swells34 13 hours agorootparentAnd that is supported by the known past actions of \"some government authorities\". This is definitely not the first time the US government has deliberately sabotaged crypto. reply tptacek 13 hours agorootparentThis isn&#x27;t an American product. reply wkat4242 14 hours agorootparentprevIt&#x27;s deliberate in making the crypto so weak that our guys can decrypt their guys&#x27; radio traffic.How&#x27;s that not a backdoor? replyqwertox 14 hours agoparentprevI think the most relevant use in the context of deliberate backdoor is its use by police and military forces. Apparently some energy providers also use it for remote controlling tasks (no voice). reply timthorn 13 hours agoparentprevThere was also the Dolphin network in the UK, offering a public national subscription TETRA network. It didn&#x27;t prove commercially viable.https:&#x2F;&#x2F;www.rcrwireless.com&#x2F;19980309&#x2F;archived-articles&#x2F;dolph... reply ajsnigrutin 5 hours agoprevI heard about this some time ago... the timeline shows the sources should be available from august this year, but nothing yet on github ( https:&#x2F;&#x2F;github.com&#x2F;MidnightBlueLabs&#x2F;TETRA_burst ) reply freeopinion 15 hours agoprev> The vulnerabilities were discovered during the course of 2020, and were reported to the NCSC in the Netherlands in December of that year. It was decided to hold off public disclosure until July 2023, to give emergency services and equipment suppliers the ability to patch the equipment.Interesting discussion about responsible disclosure. It seems a strange belief that you can tell all the radio operators about the vulnerability without also telling exploiters. Aren&#x27;t they often one and the same? What&#x27;s a reasonable approach here? reply gwbas1c 15 hours agoparent> It seems a strange belief that you can tell all the radio operators about the vulnerability without also telling exploitersI suspect that there was an update (or replacement) to the radios that was generally described as an ordinary update &#x2F; maintenance. reply freeopinion 14 hours agorootparentDo you also suspect that the patch was generally ignored because nobody knew it was important?Should the vendor be allowed to continue to sell models they know are compromised while their competition loses those contracts? Shouldn&#x27;t there be some consequence for such fraud? reply tptacek 15 hours agoparentprevImmediate public disclosure. reply freeopinion 14 hours agorootparentI&#x27;m inclined to agree. I&#x27;m not comfortable with the way this unfolded.> The Dutch NCSC (NCSC-NL) was informed in December 2021, after which meetings were held with the law enforcement and intelligence communities, as well as with ETSI and the vendors. Shortly afterwards, on 2 February 2022, preliminary advice was distributed to the various stakeholders and CERTs. The remainder of 2022 and the first half of 2023 were used for coordination and advisory sessions with stake­holders, allowing manufacturers to come up with firmware patches, updates or workarounds.This reads to me as if malicious parties were notified some 18 months before users were notified. reply actionfromafar 13 hours agorootparentDepends on who the stakeholders were. reply freeopinion 13 hours agorootparentDoes it? Intelligence agencies were among the first informed. Those are the bad guys.I know \"bad guys\" is a harsh phrasing, but when it comes to encrypted communication, they are literally the definition of the adversary. Anybody in intelligence that doesn&#x27;t play for my team is a \"bad guy\". And since everybody belongs to multiple conflicting teams, even a person who plays on one of my teams is a \"bad guy\" from the perspective of my other teams.If the first place you go with a disclosure is to the intelligence community, you are hurting users. replydenysvitali 15 hours agoprev [–] TL;DR: The only newsworthy vulnerability is the breaking TEA1 - which is anyways the least secure of them all and only intended for commercial use (that is, no emergency services).https:&#x2F;&#x2F;www.tetraburst.com&#x2F; reply pixl97 15 hours agoparentThe question is, did things like emergency services actually use the higher levels, or did they just use TEA1?It&#x27;s kind of like saying...Vendor: \"We support up to 1 zillion bit encryption!\"User: \"What&#x27;s the default out of the box?\"Vendor: \"10 bit\" reply opless 4 hours agoparentprevSome installations have additional cryptography.Which alone implies that the Tetra crypto security theatre is well known in that industry, and isn&#x27;t a surprise to vendors in the slightest. reply riedel 15 hours agoparentprev> TL;DR: The only newsworthy vulnerability is the breaking TEA1This is IMHO a very unfair TLDR; . The news is that the researchers claim that there is deliberate backdoor, which ETSI denies. If it is true, there cannot be any further trust in other proprietary parts as well. reply matthewdgreen 14 hours agoparentprevIt appears to be used for infrastructure, including things like power and transportation signals here in the US. reply riversflow 15 hours agoparentprev [–] Hogwash, I think it&#x27;s worth noting that this European system was intentionally backdoored.Everybody plays the espionage game, Europe really is no exception, they just like to use the US to keep their hands (mostly) clean. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers at Midnight Blue have discovered vulnerabilities in the authentication and encryption algorithms used in the TETRA radio network, which is widely used in critical infrastructures worldwide.",
      "The vulnerabilities, including a deliberate backdoor, have been reported to the NCSC in the Netherlands and publicly disclosed to encourage patch implementation.",
      "Midnight Blue has reverse-engineered and released C-source code of the encryption algorithms to shed light on the vulnerabilities, as ETSI (responsible for TETRA algorithms) does not disclose or subject them to public research."
    ],
    "commentSummary": [
      "The TETRA radio network has vulnerabilities, including a critical backdoor exploit and outdated encryption that can be targeted with brute-force attacks.",
      "The TEA encryption algorithm used in the network has a reduced key size, making it susceptible to attacks, raising concerns about the interception of secure communication.",
      "The article discusses the role of academics and open-source communities in discovering encryption weaknesses and the debate surrounding responsible disclosure of vulnerabilities and vendor responsibilities. It also mentions the use of TEA1 encryption in the US and Europe's involvement in espionage."
    ],
    "points": 199,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1702141349
  },
  {
    "id": 38587340,
    "title": "Increase in Air Traffic Control Incidents Due to Shortage of Controllers",
    "originLink": "https://www.nytimes.com/2023/12/02/business/air-traffic-controllers-safety.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT FLIGHT RISKS Drunk and Asleep on the Job: Air Traffic Controllers Pushed to the Brink A nationwide shortage of controllers has resulted in an exhausted and demoralized work force that is increasingly prone to making dangerous mistakes. Share full article 1868 From left, Neil Burke, Michelle Hager and Ashley Smith, who recently left jobs as air traffic controllers, voiced concerns about staffing shortages and safety. Credit... Mohamed Sadek for The New York Times By Emily Steel and Sydney Ember Dec. 2, 2023 One air traffic controller went into work drunk this summer and joked about “making big money buzzed.” Another routinely smoked marijuana during breaks. A third employee threatened violence and then “aggressively pushed” a colleague who was directing airplanes. The incidents were extreme examples, but they fit into a pattern that reveals glaring vulnerabilities in one of the most important protective layers of the nation’s vaunted aviation safety system. In the past two years, air traffic controllers and others have submitted hundreds of complaints to a Federal Aviation Administration hotline describing issues like dangerous staffing shortages, mental health problems and deteriorating buildings, some infested by bugs and black mold. There were at least seven reports of controllers sleeping when they were on duty and five about employees working while under the influence of alcohol or drugs. The New York Times obtained summaries of the complaints through an open-records request. Air traffic controllers, who spend hours a day glued to monitors or scanning the skies with the lives of thousands of passengers at stake, are a last line of defense against crashes. The job comes with high stakes and intense pressure, even in the best of conditions. Yet the conditions for many controllers are far from ideal. A nationwide staffing shortage — caused by years of employee turnover and tight budgets, among other factors — has forced many controllers to work six-day weeks and 10-hour days. The result is a fatigued, distracted and demoralized work force that is increasingly prone to making mistakes, according to a Times investigation. The findings are based on interviews with more than 70 current and former air traffic controllers, pilots and federal officials, as well as thousands of pages of federal safety reports and internal F.A.A. records that The Times obtained. While the U.S. airspace is remarkably safe, potentially dangerous close calls have been happening, on average, multiple times a week this year, The Times reported in August. Some controllers say they fear that a deadly crash is inevitable. In the fiscal year that ended Sept. 30, there were 503 air traffic control lapses that the F.A.A. preliminarily categorized as “significant,” 65 percent more than in the prior year, according to internal agency reports reviewed by The Times. During that period, air traffic increased about 4 percent. A database of aviation safety issues is peppered with recent mistakes by exhausted controllers. A controller at the air traffic control center in the Jacksonville, Fla., area instructed one airliner to turn into the path of another, later blaming being overworked and fatigued. A controller at a facility that monitors the skies above Southern California told a plane to fly too low, attributing the lapse to being “extremely tired” after working “continuous” overtime. “If I can make a small mistake like that, I can make a bigger one,” the controller wrote in a submission included in the database, which is maintained by NASA. Many controllers are aviation enthusiasts who are drawn to the job because it can pay six figures. Some relish the opportunity to earn more by working overtime. But The Times found that the combination of six-day workweeks and round-the-clock schedules has caused controllers to develop physical and mental health problems. Many avoid seeking professional help because doing so might jeopardize the medical clearances they need to work. Some turn to sleeping pills or alcohol to cope. Others resign or retire. One was Ashley Smith, a longtime controller in Atlanta who said she had witnessed her overworked colleagues engaging in physical fights and making dangerous errors. The F.A.A. estimated that more than 1,400 controllers — or about 10 percent of the total work force — would depart this fiscal year. Video Neil Burke, who worked as a controller in the New York metropolitan area, witnessed numerous mistakes by overly tired controllers. Credit Credit... Photographs and Video by Mohamed Sadek Neil Burke worked as a controller for more than a decade, including at the facility that directs air traffic in and out of airports in the New York metropolitan area. It is widely regarded as one of the country’s most complex control rooms. For years, controllers there have worked six days a week and 10-hour days. Mr. Burke, who left the F.A.A. last year because of a medical issue, said he had caught himself and other overly tired controllers making mistakes. “What happens when you stretch a rubber band too much?” Mr. Burke asked. “It breaks.” Jeannie Shiffer, an F.A.A. spokeswoman, said the agency “maintains the safest, most complex and busiest airspace in the world.” She added, “The nation absolutely needs more air traffic controllers, and growing the work force will result in better working conditions and more flexibility.” Ever since the Reagan administration replaced thousands of striking controllers, the agency has struggled to keep pace with waves of retirements. The problem grew worse during the Covid-19 pandemic, when the F.A.A. slowed training of new controllers. For the current fiscal year, the F.A.A. sought $117 million to train controllers and hire 1,800 new ones. Yet training is difficult; many aspiring controllers fail. The F.A.A.’s hiring plan is expected to have “a negligible improvement over today’s understaffed levels,” with a net increase of fewer than 200 controllers by 2032, the National Airspace System Safety Review Team, a group of experts appointed by the agency, said in a November report. Swarmed by Insects From 2011 to 2022, the number of fully certified controllers declined more than 9 percent, even though traffic increased. Based on targets set by the F.A.A. and the union representing controllers, 99 percent of the nation’s air traffic control sites are understaffed. (Under a looser standard that the agency prefers, Ms. Shiffer said, 63 percent of facilities are considered inadequately staffed.) To help fill that gap, controllers at 40 percent of the facilities worked six-day weeks at least once a month last year, according to the controllers’ union. Several locations required controllers to do so every week. The number of overtime hours clocked by controllers nearly tripled over the past decade, according to F.A.A. data. There Are Fewer Air Traffic Controllers A chart showing that from 2011 to 2022, the number of air traffic controllers fell by 9.1 percent. +2% CHANGE FROM 2011 Percent change in the number of air traffic controllers since 2011 –2% –4 –6 –8 –9.1% 2011 to 2022 –10 –12 2012 2014 2016 2018 2020 2022 (FISCAL YEAR) Source: National Air Traffic Controllers Association By Ella Koeze In interviews as well as safety complaints to the F.A.A. and NASA, controllers reported deteriorating workplace conditions. Elevator malfunctions forced employees to climb hundreds of stairs to reach the towers. Bees and biting flies harassed controllers who were directing traffic. Faulty air-conditioners left control rooms alternately broiling or freezing. One employee at a facility in Texas had to take in lightbulbs from home. “The age and condition of F.A.A. facilities and equipment are elevating system risk to unsustainable levels,” the National Airspace System Safety Review Team wrote in its November report. Controllers said the unrelenting schedules and unpleasant working conditions left them wiped out. “These are humans,” said Michelle Hager, who retired in June after 26 years as a controller. “They get tired, and they make mistakes.” Ms. Hager, who spent most of her career in Denver, had the option to work six more years before reaching the mandatory retirement age of 56. But the schedule had become “not only exhausting but depressing.” “There is no time to mentally recover away from the required work,” she added. “I couldn’t continue to live like that.” Video Michelle Hager, who retired in June after 26 years as a controller, said the schedule had become “not only exhausting but depressing.” Credit Credit... Photographs and Video by Mohamed Sadek Ten Cups of Coffee In a series of interviews this year, a controller in the Northeastern United States explained how the job was affecting his life. (The Times agreed to not publish his name because he feared professional repercussions.) The controller worked in a dark radar room, radioing commands to pilots and monitoring a screen with moving dots that represented planes flying across the region. He had occasional breaks, often less than half an hour, in which he had to eat, refill his water bottle, go to the bathroom and complete other work before returning to his position. On Thursdays and Fridays, his shifts typically began in the afternoon. For the rest of his workweek, they began earlier: 8 a.m. on Saturdays and 6:30 a.m. on Sundays, followed by a 10:30 p.m. shift that ended around dawn on Mondays. Only eight or nine hours separated the end of some shifts from the beginning of others. He was supposed to have Tuesdays and Wednesdays off, but he was almost always called in for overtime on one of those days. “So much for a two-day weekend,” he said this summer, on what was supposed to be a day off. “I just got scheduled a 2 p.m. to 10 p.m. shift today.” During the first part of his workweek, he tried to get to sleep by 2 a.m. Later in the week, he went to bed at 7:30 p.m. to prepare for his 4 a.m. alarm. Despite being exhausted, he often found it impossible to sleep. He eventually went to a doctor, who diagnosed him with sleep apnea and told him to quit his job because the schedule was endangering his health. Quitting wasn’t realistic. As his family’s breadwinner, he couldn’t afford to give up the pay and generous pension. Plus, he loved controlling planes. It was the overtime that made the job intolerable, even though the extra hours added 25 percent to his roughly $150,000 salary. To fall asleep, he sometimes took over-the-counter sleeping pills. (He didn’t report this to the F.A.A., which bars controllers from working soon after taking medications that cause drowsiness.) To stay alert, he relied on energy drinks and coffee. He routinely showed up to work groggy and found himself unable to recall words during conversations. Sometimes he was so tired and hopped up on caffeine — he calculated one day that he had consumed the equivalent of 10 cups of coffee by noon — that he felt he might vomit. Other times, he caught himself nodding off on the overnight shift. After more than 10 years in the job, he recently made what he considered his first big mistake, nearly allowing two jets to get too close together. There was no collision. He wondered if he would be so lucky the next time. Panic Attacks at Work The Jacksonville air traffic control center is one of the country’s busiest, directing planes over parts of Florida, Georgia, Alabama and the Carolinas. Yet it has only 207 controllers, below the target of 298 set by the F.A.A. and the controllers’ union. The toll on safety has become apparent. There was the close call caused by the fatigued controller, which occurred in April. And in a confidential safety report last year, a Jacksonville controller described hyperventilating and struggling to stand after two hours of directing heavy plane traffic. “We have recently had a heart attack, multiple panic attacks (including my own), people losing their medicals due to depression and some that just outright quit the F.A.A. because it has gotten so bad,” the controller wrote. “Who knows how many other stress-induced physical and mental issues are happening that we don’t even know about yet,” the controller added. “This place is breaking people. We need help. I’ll say it again, SOS!!” At a Senate hearing in November, Jennifer L. Homendy, the chairwoman of the National Transportation Safety Board, said the shortage of air traffic controllers, coupled with mandatory overtime, had become a threat to aviation safety. “We are putting the psychological stress of the entire aviation safety system on the shoulders of our A.T.C. work force,” she testified, referring to air traffic controllers, “and this is unacceptable.” In interviews and complaints submitted to the F.A.A., air traffic employees warned that they and their colleagues were buckling. (Names and locations were redacted from the complaint summaries provided to The Times.) One complaint described a controller “caught sleeping on operational positions numerous times.” Another described two controllers falling asleep “while providing air traffic services.” An employee “physically assaulted one controller, verbally assaulted another controller,” who began to cry, and then shoved a chair at someone. Other hotline reports also detailed physical and verbal attacks. Several controllers reported that co-workers appeared unstable, with one “showing extreme signs of mental problems.” Controllers in one location were reported for “using alcohol and illegal drugs while on position” directing traffic. Another described the “strong odor of alcohol” on multiple air traffic employees. One controller who worked in Colorado and elsewhere said she consumed up to nine vodka drinks a night to deal with trouble sleeping and recurrent panic attacks that her doctor attributed, in part, to her job. Ms. Shiffer, the F.A.A. spokeswoman, said the agency investigates all hotline complaints and acts on credible ones. Controllers said they had been reluctant to seek help for physical and mental health problems because of the F.A.A.’s rules requiring medical clearances. The guidelines, which are designed to ensure that controllers are mentally and physically sound, prohibit them from taking certain medications that can cause drowsiness or other side effects. The rules also disqualify controllers with certain medical conditions from working. One unintended consequence, numerous controllers said, is that they avoid taking necessary medications or resort to alcohol or drugs. Ms. Shiffer said the agency took controllers’ health seriously, including by offering free counseling. “When they have issues, we work with them to resolve it,” she said. It is not only controllers confronting this dilemma. In October, an off-duty pilot in the cockpit of an Alaska Airlines flight tried to shut off the plane’s engines after consuming psychedelic mushrooms. He said he had been struggling with his mental health for years but avoided medication, fearing he would be grounded. He was charged with 83 counts of attempted murder and pleaded not guilty. Image San Diego International Airport is one of hundreds of locations with a shortage of air traffic controllers. Credit... John Francis Peters for The New York Times Alarms in the Control Tower A series of recent close calls in San Diego show how the combination of overworked controllers and thin staffing can create dangerous situations. In August, an air traffic controller cleared a private plane to land on the same runway from which a Southwest Airlines flight was preparing to depart. As the Cessna jet descended, another plane distracted the controller. She noticed the potential crash only at the last minute. Collision alarms sounded in the control tower, and she ordered the Cessna to abort its landing. It came less than 50 feet from crashing on top of the Southwest plane. The controller later confided to a colleague that she had been fatigued at the time and lost focus, the colleague said in an interview. The controller’s supervisor had been dealing with a jammed printer, according to an internal F.A.A. safety report reviewed by The Times. The close call was one of at least seven in San Diego over the past two years, according to F.A.A. records and the NASA database. Those followed two serious incidents in May and June 2021 that involved Southwest, Delta Air Lines and SkyWest Airlines flights. In response, the F.A.A. sent investigators to San Diego. Controllers reported feeling “rusty” and distracted, according to the agency’s subsequent report, which also cited staffing issues. There have been more problems since. In March, an airline pilot said he had nearly collided with a corporate jet while taxiing in San Diego after a controller failed to warn him about the other plane, according to a report in the NASA database. In June, a controller died by suicide. Another soon quit. In October, a controller was directing planes when she experienced chest pain and trouble breathing. An ambulance rushed her to a hospital. She hasn’t been back to work since, according to a controller. The F.A.A. said 21 fully trained controllers were assigned to San Diego. The targets set by the F.A.A. and the controllers’ union call for 28. Video Ashley Smith, a longtime controller in Atlanta, saw her overworked colleagues have physical fights and make mistakes. Credit Credit... Photographs and Video by Mohamed Sadek ‘Kicking the Can’ Ashley Smith had worked for more than a decade as a controller in the Atlanta area, where she monitored radar and directed planes from inside a dark room. Last year, there were 77 fully certified controllers at Ms. Smith’s location, below the target of 110. Morale deteriorated. Embittered controllers shouted at one another and sometimes had physical fights, she said. Between the perpetual overtime and three young children at home, Ms. Smith felt that she was in a constant daze. She said she had witnessed an increase in mistakes by fatigued controllers. She found the pattern especially unnerving because her husband was an airline pilot. In January 2022, an error by a controller in Atlanta caused two Delta airliners to get dangerously close, according to internal F.A.A. safety reports. A cockpit collision alert prompted one plane’s pilots to quickly climb. In a review, the F.A.A. acknowledged that fatigue might have been a factor, given that the controller’s schedule had included two overtime shifts in each of the previous three weeks. A few weeks after the close call, Ms. Smith sent an email to Tim Arel, a senior F.A.A. air traffic official. She detailed how multiple recent near misses in Atlanta had involved controllers who had repeatedly pulled overtime shifts. “The staffing is ridiculous and getting worse,” she wrote. “What level of fatigue is the agency trying to get this work force to before they recognize a serious safety issue?” Mr. Arel responded the next day, acknowledging that the agency faced staffing issues. Three months later, Ms. Smith resigned, convinced that nothing would ever improve. “They are kicking the can down the road,” she said. Kirsten Noyes contributed research. Photo and video editing by Renee Melides Do you work in aviation? Tell us about safety issues. We may use your contact information to follow up with you. We will not publish any part of your submission without your permission. If you have information that you want to share with The Times using tools that can help protect your anonymity, visit: https://www.nytimes.com/tips How are you connected to the world of aviation? What is your job?* What aspects of aviation safety do you think deserve more attention? 0 words Do you have specific examples that illustrate your concerns? 0 words What is your name?* What is your email address?* What is your phone number? Where do you live?* By clicking the submit button, you agree that you have read, understand and accept the Reader Submission Terms in relation to all of the content and other information you send to us (“Your Content”). If you do not accept these terms, do not submit any content. Of note: Your Content must not be false, defamatory, misleading or hateful, or infringe any copyright or any other third-party rights or otherwise be unlawful. We may use the contact details that you provide to verify your identity and answers to the questionnaire, as well as to contact you for further information on this story and future stories. Submit Emily Steel is an investigative reporter covering business for The Times. She has uncovered sexual harassment at major companies and recently has focused on aviation safety issues. More about Emily Steel Sydney Ember is an economics reporter. Previously, she covered Bernie Sanders's presidential campaign and the 2020 election, including living in Iowa for three months during the run-up to the state's caucuses. More about Sydney Ember A version of this article appears in print on , Section A, Page 1 of the New York edition with the headline: Control Tower Vacancies Compromising Air Safety. Order ReprintsToday’s PaperSubscribe 1868 Share full article 1868 ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=38587340",
    "commentBody": "65% increase in \"significant\" Air Traffic Control incidents in 2023Hacker Newspastlogin65% increase in \"significant\" Air Traffic Control incidents in 2023 (nytimes.com) 167 points by ren_engineer 10 hours ago| hidepastfavorite192 comments ren_engineer 10 hours agonon-paywall link: https:&#x2F;&#x2F;archive.is&#x2F;ld9Bm reply mortos 2 hours agoparenthttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231203014618&#x2F;https:&#x2F;&#x2F;www.nytim... reply sxyuan 1 hour agoprevThere&#x27;s an increase in incidents because ATCs are overworked and understaffed. The knee-jerk reaction is to try to automate the work away. A few problems with that kind of thinking:- Automation already exists - e.g., the collision detection warning mentioned in the article. I don&#x27;t know much about air traffic control but I imagine there&#x27;s some element of defense in depth. ATCs dozing off or running on fumes won&#x27;t cause collisions right away (these incidents are mostly close calls) but it sounds like it&#x27;s only a matter of time before all the other defenses fail and a major accident happens.- There&#x27;s always going to be work that&#x27;s hard to automate. Plenty of software teams have on-call rotations to cover production services. You&#x27;d think that if any field would have their operations be fully automated, it&#x27;s software, but nope. We need to stop thinking that the physical world is easier to deal with - it&#x27;s often much harder.- Automation costs money to develop and deploy. Apparently one of the early outcomes of union action back in the 70s was faster automation rollout. [1] For an executive, why spend money on automation if you could just squeeze more out of your workers and compromise on safety instead?[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Professional_Air_Traffic_Con... reply PhobosSkunk 1 hour agoparentAutomation in ATC exists a little yes, as you said for collision detection, ground proximity warning and runway infringement. That&#x27;s mostly it.We have some cool toys to make life easier like CPDLC to communicate via data-link instead of voice, multi layer radar screens with tons of functions, ATIS generation etc but those are not automation, just QOL improvement and if anything goes wrong we go back to old school ATC by voice and maths.There is a lot of automation in the data part of ATC, so flight plans processing, radar correlation, meteo data etc etc. But this is just normal IT stuff in 2023.Some cool project are getting there, like virtual towers with augmented reality by using cameras instead of looking out a window. My company did recruit an expert in big data and ML to develop new tools and automate stuff, but always data related, nothing to do with controlling and aircraft on a radar screen. reply amzthrow 1 hour agoparentprev> Plenty of software teams have on-call rotations to cover production services.There are plenty of valid criticisms of the cloud but this is what you are really paying for. The value proposition of the cloud is infrastructure-oncall-as-a-service. reply asmor 1 hour agoparentprevRAAS (Runway Awareness and Advisory System), the equivalent system installed on aircraft, also needs to become standard equipment. It is for some airlines, but it is by no means mandatory. reply PaulKeeble 9 hours agoprevCar accidents are up as well, less so this year than last. Both Air traffic and Car accidents have been up since 2020. Its not unique to Air traffic control.https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;tanyamohn&#x2F;2023&#x2F;09&#x2F;28&#x2F;road-crash...Its also happening worldwide, more air traffic near misses in the EU alongside road accidents as well. I suspect its world wide. reply verteu 6 hours agoparent> Traffic fatalities declined for the fifth straight quarter. About 19,515 people died in motor vehicle traffic crashes in 2023, a decrease of about 3.3% compared to 20,190 fatalities in the first half of 2022.I don&#x27;t see much correspondence with:> In the fiscal year that ended Sept. 30, there were 503 air traffic control lapses that the F.A.A. preliminarily categorized as “significant,” 65 percent more than in the prior year, according to internal agency reports reviewed by The Times. During that period, air traffic increased about 4 percent.Especially since the NYT blames the latter on \"A nationwide staffing shortage — caused by years of employee turnover and tight budgets, among other factors — has forced many controllers to work six-day weeks and 10-hour days.\" reply screye 2 hours agorootparentTraffic fatalities decrease because cars are getting safer.But the number or accidents per capita might not be. Pedestrian deaths have certainly been on the rise.https:&#x2F;&#x2F;www.ghsa.org&#x2F;sites&#x2F;default&#x2F;files&#x2F;publications&#x2F;files&#x2F;... reply rplnt 1 hour agorootparentPedestrian deaths also increase because cars are getting bigger - reduced visibility, much more energy, and worse impact zones.Cities should really start to regulate what kind of cars under what conditions they let mix in with people. reply Roark66 3 minutes agorootparentSadly, we&#x27;re going in the other direction. For example yesterday the capital city of Poland (Warsaw) decided, despite a lot of protests, to restrict \"old cars\" from entering a number of central districts. \"Old cars\" will mean diesels older that 18 years initially, 13 years later and petrol cars older than 20 years. The protesters proposed the rules are amended to block cars based on their emissions instead (which would allow most of the small old cars people still have, but it would block many modern SUVs). Of course the ruling faction (still enjoying majority support in Warsaw) decided otherwise. So much for the policy to be driven by \"health concerns\" and not car dealership lobby. reply raffraffraff 1 hour agorootparentprevPeople are driving spaceship-sized SUVs while using their phones, hitting pedestrians who are walking around looking at their phones, jumping out of the path of an oncoming 12yo doing 40kmh on a battery powered scooter while looking at porn on their phones and using Whatsapp to schedule a meet up with their Fastgas supplier. Their parents think that a scooter is a toy, the phone is so that they can call home, and the money was for lunch.Yeah, kinda half joking, in the sense that these 3 hypothetical people don&#x27;t actually crash into each other every day, but they all exist. I see them every day.I&#x27;ve also seen a huge rise in cyclists on the footpath (sidewalk), and it&#x27;s so normalized that I had a guy in his 50s zoom up behind me and the wife and actually tell us to get out of the way. To say that he got called all the things I could possibly call him is an understatement. reply Roark66 1 minute agorootparentHow does a technical gas supplier factor into the life of today&#x27;s teenagers? I&#x27;m genuinely curious. Is our hypothetical 12yo person learning tig welding on a side? onetimeusename 3 hours agoparentprevI followed road traffic safety since 2020 closely (and have submitted and posted about it here) and traffic fatalities is slowly coming down since 2020. My hypothesis about it was that the empty roads in 2020 caused drivers to degenerate in terms of road manners. For example, deaths per mile actually increased in 2020 despite people driving fewer miles which suggests people drove less safely.On the other hand this article says there was a 65% increase in significant incidents from the year prior to Sept. 30. So I think these are two different issues. reply dawnerd 2 minutes agorootparentI’ve noticed a pretty drastic decline in driving behavior around here. We’re seeing a LOT more just absolutely insane drivers doing things you’d only see in the worst of compilations a few years ago. Something happened during Covid that made people just not care anymore. Also doesn’t help that cops are not pulling people over as much as they should. Watched someone just yesterday fly through a red right in from of a cop that did nothing about it. reply xkqd 3 hours agorootparentprevMy pet theory has been that extended lockdowns caused regressions in people’s ability to drive safety, whether it was the actual skills to operate a vehicle, or people’s risk assessment skills.Operating a vehicle is a skill like any other, and if you’re not performing reps you’ll regress like any other activity. Empty roads might even permit crappier driving. reply withinboredom 2 hours agorootparentI disagree. However, I&#x27;m used to going long stretches without driving and then suddenly driving hundreds of km&#x2F;miles. I suspect, based on my wife&#x27;s behavior and her driving, that before 2020, people were used to and happy with simply listening to music, a podcast, or something. After&#x2F;during 2020, many people were no longer satisfied with that. They turned to listening to YouTube, movies, or even face-to-face calls while driving (hell, even my mom does this one), and holding the phone while trying to operate the vehicle.It&#x27;s almost like people forgot the most important part of driving: minimizing distractions. If I&#x27;m in a high-stress part of a drive (unfamiliar roads, high density, etc), I always turn off all media and ask all passengers to be quiet for a bit because I need all my senses. I don&#x27;t know how many times I&#x27;ve been saved by hearing a car that I can&#x27;t see yet. reply fifteenforty 2 hours agorootparentprevPerhaps, maybe, mass infection by a virus that affects the brain and vascular system has consequences for society. reply onetimeusename 2 hours agorootparentprevya that makes sense. we&#x27;ll probably never know what happened :| reply ikekkdcjkfke 2 hours agorootparentprevAnd mine is that the lockdowns felt like an overreach and there was some kind of infantile rebellion reply soupfordummies 9 hours agoparentprevI don&#x27;t really see how that&#x27;s related though reply astrostl 8 hours agorootparentACT test scores have plummeted too. Combined with what we know about the physical brain changes that can be observed after a single mild infection, it all paints a potentially concerning relationship with COVID. reply gpt5 8 hours agorootparentOr maybe ACT test scores have plummeted because these students have experienced 1-2 years of remote teaching, which might have been less effective than in-person school? reply stringsandchars 2 hours agorootparent> Or maybe ACT test scores have plummeted because these students have experienced 1-2 years of remote teaching, which might have been less effective than in-person school?As I mentioned in another post, you can check this theory against the pandemic control-group that kept schools open:https:&#x2F;&#x2F;www.thelocal.se&#x2F;20231205&#x2F;swedish-students-maths-and-... reply woodruffw 6 hours agorootparentprevPer the comment thread, this doesn&#x27;t have perfect explanatory power: drivers and ATC have also recorded statistically significant declines over the same time period.In other words: remote schooling may have had a negative effect on ACT scores, but all evidence points to it not being the only (or even primary) effect. reply dangus 4 hours agorootparentRegarding this thread, I really want to caution on the desire to automatically assign worse car crash rates to covid-19 infections, or any other specific cause.Car crashes and ATC mistakes are two different sets of data. Just because they are going up or down at the same time and you can overlay some other event on top of it means absolutely nothing on its own.There are a lot more reasons that car crash rates can be getting worse. For one thing, they have been trending upwards since smartphones have become prevalent. Car crashes weren&#x27;t trending down for some time before covid-19. Also, the number of screens installed on automobile dashboards is increasing every year.Still, I won&#x27;t automatically assign blame to smartphones or automotive screens unless someone at least attempting to use the scientific method weighs in on the subject, because our intuitions about statistics are often really, really wrong. reply lostlogin 2 hours agorootparent> Regarding this thread, I really want to caution on the desire to automatically assign worse car crash rates to covid-19 infections, or any other specific cause.People’s tolerance levels and general concern for other humans plummeted in the post covid times. The warning signs about acceptable behaviour in supermarkets, medical practices and restaurants proliferated. I don’t know how you measure that effect though. reply dawnerd 0 minutes agorootparentRight just look at the number of people having to be restrained on airplanes and just outright acting out. arcanemachiner 3 hours agorootparentprev> Car crashes and ATC mistakes are two different sets of data. Just because they are going up or down at the same time and you can overlay some other event on top of it means absolutely nothing on its own.A good time to dust off this classic:https:&#x2F;&#x2F;www.tylervigen.com&#x2F;spurious-correlations reply aredox 1 hour agorootparentExcept that COVID is known to be brain invasive and to affect cognition.This looks more like refusing to ever entertain the idea that letting COVID rip was a bad idea and lockdowns and vaccinations and masks were justified because you don&#x27;t like it, than actual scientific rigor. reply cratermoon 3 hours agorootparentprevAlso https:&#x2F;&#x2F;commons.wikimedia.org&#x2F;wiki&#x2F;File:Pirate_Global_Warmin... reply 10u152 3 hours agorootparentprevDistractions might be going up in cars, but I’d guess that’s offset by automatic crash avoidance systems that’s also going up in cars. reply orbit7 2 hours agorootparentI had a new car for a month (mine got damaged whilst parked). Simply adjusting the aircon fan required screen navigation followed by a fidly touch screen control.The crash avoidance systen was a distracting alert that took my attention away from the road for none risks but instead increased there likelyhood to become a risk.Glad to get my own car back with physical switches and dials without all this crap, having to operate a tablet behind the wheel is a dumb idea and no different to operating a smart phone behind the wheel. reply aurareturn 3 hours agorootparentprevnext [–]students have experienced 1-2 years of remote teaching, which might have been less effective than in-person schoolYou can&#x27;t say that on HN. Executives have investments in commercial real estate. reply sinuhe69 4 hours agorootparentprevThe same as the PISA scores. PISA, which might not be well known is the US, is the International Student Assessment for the 15 years old students in the OECD (and non-OECD) countries. The PISA measures their ability to use their reading, mathematics and science knowledge and skills to meet real-life challenges. The PISA scores for 2022 is the lowest in the history of PISA and show a clear trend downward since 2012. The huge drop in 2022 scores can be explained through the longer school closure period during the pandemic lockdowns. But only partly. The increasing prevalence of mobile phone amongst children and their distractions certainly play a significant part in contributing to the huge drop in PISA scores.Not necessarily related to the increasing number of air traffic controls incidents, though. reply ghodith 8 hours agorootparentprevCould also be the consequences of schooling during a lockdown. reply stringsandchars 2 hours agorootparent> Could also be the consequences of schooling during a lockdown.Luckily we have the control-group of Sweden, that spent a large part of the pandemic proclaiming that not closing schools was going to have a fantastic positive effect on children&#x27;s learning.The actual result: Sweden&#x27;s PISA results declined much more steeply than countries who used distance-learning during the pandemic. reply xattt 7 hours agorootparentprevPeople continued to drive. reply toast0 4 hours agorootparentA lot of people changed their driving habits significantly, and there was a period of significantly less driving. Many people commute much less than before. At some points, traffic was so much below the usual that several record breaking Cannonball runs were had that are unlikely to be broken unless there&#x27;s a significant relaxation of speed limits nationwide. reply infamouscow 6 hours agorootparentprevnext [2 more] [flagged] phendrenad2 6 hours agorootparentPeople did continue to drive though. At least where I was. Please continue trying to rewrite history. reply siquick 4 hours agorootparentprevOr spending years being overwhelmed by smartphones mainlining information to us for multiple hours a day is finally catching up with us? reply dangus 4 hours agorootparentprevThis might be the worst real example of a jump to conclusions based on a casual correlation I have seen in my entire life.I don&#x27;t even know how to properly deconstruct how irresponsible this style of thinking is, it&#x27;s just so flabbergasting.In science you can&#x27;t just draw lines on the wall between random shit like you&#x27;re Charlie Day in It&#x27;s Always Sunny in Philadelphia.ACT scores are very obviously not a product of your raw brain power as an isolated variable, they include a number of other factors like how much sleep you got last night, your family life, the quality of your curriculum and teachers, your socioeconomic status of yourself and your peers, and, of course, whether you spent a year in a global pandemic emergency while your school district scrambled to switch to a fully online curriculum with zero notice.There is a very well-documented labor shortage for air traffic controllers. Fewer people are covering the same shifts - that is fact. If we are going to ignore the scientific method and start pointing fingers, this is so much more obviously the type of thing to start scapegoating. reply 10u152 3 hours agorootparentNot sure of the specifics, but often shortage of labour leads to lowering of standards of training&#x2F;min experience required as well. reply xyst 5 hours agorootparentprevcolleges still care about ACT? I thought SAT was the golden standard.I remember taking the ACT many years ago and it was definitely much easier. Also not many colleges accepted it at the time. SAT was preferred. reply Brybry 5 hours agorootparentThe preference is regional. [1] When I took the ACT, many years ago, it was the test the university I was applying to listed first in their requirements.And that&#x27;s still true.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;File:SAT-ACT-Preference-Map.... reply saghm 5 hours agorootparentWhen I was in high school (graduated 2012), my school recommended we take both, since not only do certain schools prefer one to another, but if you happened to score relatively well on one versus the other, you could choose to only send that one instead. reply withinboredom 2 hours agorootparent> if you happened to score relatively well on one versus the otherThis should be reasonable proof that the test doesn&#x27;t test things very well, IMHO, because there are so many factors that go into getting a good score.I was one of these people -- I got one point below perfect on ACT, but the morning of my SAT, I got into an argument with my mom and got a below-average score. reply mikrotikker 4 hours agorootparentprevWhat about the effects of an extremely wide and extremely quick deployment of a novel vaccine (under threat of being fired)? reply aredox 1 hour agorootparentWhat about the effects of repeat infections by a very contagious and neuro invasive novel virus? Hmmm? reply throwawayq3423 3 hours agorootparentprevWhat does \"novel vaccine\" mean? reply zmgsabst 3 hours agorootparentThat we haven’t used mRNA gene therapies to treat a virus before. reply lostlogin 2 hours agorootparentMaybe not that widely, but the technique seems to have had prior usage.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;MRNA_vaccine reply defrost 3 hours agorootparentprevA vaccine that had a significant impact on a notable percentage of the population 24 months before widespread uptake.The Thiotimoline of vaccines.https:&#x2F;&#x2F;commons.wikimedia.org&#x2F;wiki&#x2F;File:Historical_Average_A...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thiotimoline reply defrost 19 minutes agorootparentSpelling this out slowly for the reflexive downvoters, ACT test scores began their decline well before any widespread use of mRNA COVID vaccines which would make them extremely novel in their endochronicity if they had an effect before they were used.Otherwise, as pointed out by lostlogin, mRNA vaccines have been used in humans since 2013 and studied in animals since 1989 which makes them less novel than widely claimed. replyxkekjrktllss 5 hours agoparentprevTrains are running more safely, efficiently, elegantly, and reliably than both cars and airplanes, and they have consistently done so with a much longer track record. reply SoftTalker 5 hours agorootparentNot Amtrak. Worst excuse for a railroad ever. reply medstrom 5 hours agorootparentNo experience myself, but from past comments on HN, I understand the company Amtrak provides pretty good service within the areas it can control. It&#x27;s just that the US rail network prioritizes freight every time (even though legally it&#x27;s not supposed to). reply gnicholas 3 hours agorootparentprevI don&#x27;t love Amtrak on the East Coast. But on the West Coast, it can be really nice. Coach on the West Coast is like Acela on the East Coast. Even the cheapest seats have nice tables with outlets, and the views on the Pacific Surfliner can&#x27;t be beat! reply thaumasiotes 2 hours agoparentprev> Car accidents are up as well, less so this year than last. Both Air traffic and Car accidents have been up since 2020. Its not unique to Air traffic control.What&#x27;s the connection between car accidents and ATC incidents that would make one a sensible comparator for the other? They aren&#x27;t caused by the same things, unless the extra car accidents are all occurring in intersections where someone is directing traffic. reply DiscourseFan 9 hours agoprevVery scary indeed. I think for the first time in my life I will be a little on edge flying in the US. You always hear that flying is the safest mode of public transport--well, if this is the state of the ATC, we&#x27;re definitely in trouble. And you know there won&#x27;t be any real change until hundreds of people die needlessly...I just hope it won&#x27;t be my flight. reply HPsquared 9 hours agoparentIt&#x27;s the safest per mile, but not per journey.A nice comparison to other transport methods, including taking the bus, and the Space Shuttle: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aviation_safety#Transport_comp... reply thanatosmin 5 hours agorootparentThese numbers are from 1990-2000. Airlines have gotten much safer since then, so I believe they would now be much safer per-journey, too. https:&#x2F;&#x2F;www.airlines.org&#x2F;dataset&#x2F;safety-record-of-u-s-air-ca...(The difference between per-mile and per-journey is still interesting!) reply iteria 9 hours agorootparentprevIt is utterly fascinating to me that technically walking is just as safe as a car on a journey by journey basis. I definitely didn&#x27;t need to know the danger per journey for flights though. I liked the lie I had before reply ghayes 9 hours agorootparentPer that chart, flying is about 3x as deadly per journey as a car. Many people take a car to and from the airport, which means it nearly nets out already. reply someplaceguy 8 hours agorootparentWhat do you mean, it nets out?Shouldn&#x27;t the car trips from&#x2F;to the airport mean that an airplane journey is even more dangerous, as you can&#x27;t really fly without those additional car trips? reply Gud 5 hours agorootparentYes you can. I usually take the train to the airport. reply dayjaby 1 hour agorootparentI take a car to the train to get to the airport. reply thecopy 2 hours agorootparentprev>can&#x27;t really fly without those additional car tripsHm, i almost never take a car to the airport. reply chrisbolt 2 hours agorootparentprevThere are so many disclaimers after that table that I feel that citing it as a \"nice comparison to other transport methods\" is absurdly simplistic and disingenuous. Especially since a sibling comment says \"It is utterly fascinating to me that technically walking is just as safe as a car on a journey by journey basis.\" reply hypercube33 7 hours agorootparentprevIt really blows my mind that the space shuttle was really so sound and safe even though I want to argue that it could have been far better. I mean this compared to SpaceX stuff blowing up a bunch before it gets the kinks worked out - I don&#x27;t remember seeing or hearing about any prototype shuttles blowing up but it was before my time. reply adhesive_wombat 4 hours agorootparentThey did blow up 2 Shuttles out of 5, both crewed, so maybe they didn&#x27;t get the all the kinks worked out in the first place.Plenty of rockets did blow up on the launchpad or at various stages.For example, the Titan I failed 17 launches, the Titan 2 failed 10 (and one exploded in the silo, while attached to a nuclear warhead), and the Atlas E&#x2F;F failed 9. Even more recently, into the 90s and 00s, the Atlas I lost 3 and every Ariane variant has lost at least one.I&#x27;m hardly a Musk fan, but although SpaceX seems particularly gung-ho about testing things they know aren&#x27;t finished in order to iterate the design faster, the results after that are pretty good so far: Falcon 9 is 281 \"real\" flights for 2 failures, plus that one that went bang on the launchpad.It&#x27;s not 100% success rate like the Saturns, but out of 21 launches between the 1B and V, there were several near misses there. And probably quite a few A-4&#x2F;V2s were harmed in the making of them and their predecessors too! reply pama 6 hours agorootparentprev17000000 Deaths per billion flights for the space shuttle is not safe. This is more than 2,000 times more dangerous than skydiving, which is also not very safe. reply ddeck 3 hours agorootparentIt was significantly worse than that.There were 2 failures over a total of 135 flights, with 14 fatalities. So that&#x27;s about 103 fatalities per 1000 flights.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Space_Shuttle reply mannykannot 4 hours agorootparentprevOthers here have addressed the question of whether it was safe even by space flight standards, but as to whether it could have been far better, the refractory-surfaces problem alone seems to have put an upper limit on that. reply oatmeal1 6 hours agoprevPeople are seriously concerned with aircraft near misses when we let cars kill 45,000 Americans a year. Absurdity. reply akira2501 3 minutes agoparent50% of accidents are single vehicle accidents that involve drugs or alcohol. It&#x27;s more if you add in youth an inexperience. So, _most_ vehicle deaths are self-inflicted.16% are pedestrians. They usually get hit from behind, and even if they don&#x27;t, almost always at night.16% are motorcycles. I ride. I love riding, but the reason for that statistic is obvious. There&#x27;s zero safety margin when you&#x27;re on one.Finally, the average death count from a vehicle accident is like 1.2. The average death count from two planes having an accident is like 600. The reason this all matters is because there are several orders magnitude _more_ car journeys than there are airplane journeys in any given year.You can&#x27;t compare them 1:1 and the relative differences matter more than the relative similarities. reply pizza 4 hours agoparentprevIt&#x27;s reasonable to monitor risk at an individual level. Considering one person&#x27;s fuckup can affect hundreds of people directly, this is reasonable. The two concerns are not mutually exclusive. reply rdtsc 5 hours agoparentprevOnly if the people who are concerned could be channeling their concern into solving the problem. Here, I am guessing, not many people can actually solve the problem, so we can safely be very concerned about both things simultaneously!It would be different if it were the same exact group of people and the same budget who are in charge of plane safety, as those in charge of the car safety. We can then scold them for wasting time on planes and told them to shift focus to cars instead. reply gretch 1 hour agorootparent>It would be different if it were the same exact group of people and the same budget who are in charge of plane safety, as those in charge of the car safetyThis is exactly the case. In the US we have the Department of Transportation that governs automobile transportation as well as air travel (and also trains and boats). reply 1letterunixname 5 hours agorootparentprevStop making sense!It would be useful if the readily mechanizable aspects of ATC-piloting and driving were done by machine but with human-in-the-loop. The fixations with completely human, manual processes and the leap to full automation are both too risky. There is plenty of middle-ground to derisk and remove points where human-error is mostly likely to occur. TCAS has been an excellent aid. Perhaps an automotive \"TCAS\" would also be useful. reply toast0 4 hours agorootparent> Perhaps an automotive \"TCAS\" would also be useful.Forward Collision Warning systems and automatic emergency braking are becoming common in new cars. The problem and solution spaces are pretty different, so I don&#x27;t think applying TCAS directly would be helpful --- I don&#x27;t think there&#x27;s a chance of cars having transponders anytime soon, and certainly deer, cyclists and pedestrians are unlikely to participate in an active transponder system, and there&#x27;s no opportunity for cars to pull up or sink. At the same time, TCAS does not instruct to reduce or increase horizontal speed. reply mikrotikker 4 hours agorootparentAutomatic emergency braking is fucking horrifying tho... It has false positives and can be dangerous. reply lotsofpulp 1 hour agorootparentIs it more dangerous than people not braking because they are watching something on their phone? replyswagempire 1 hour agoparentprevI think a better question is why the \"car accident\" people are always hijacking threads to push their agenda. Like the topic is Air Traffic Control. Why are you bringing up car accidents? reply vore 5 hours agoparentprevWould you like people to not be concerned with aircraft accidents? reply kevinmchugh 4 hours agorootparentCertainly the concern is why air travel is so safe. reply syndicatedjelly 6 hours agoparentprevIt’s possible to be concerned about two things? reply oatmeal1 4 hours agorootparentAbsolutely, but one is a trifling concern compared to the other. Yet the trifling concern gets the media attention. reply tqi 4 hours agorootparentWhat is your point, that newspapers should lay out A1 with \"concerns\" ordered whatever arbitrary metric you personally have decided is the \"right\" measure of importance? reply jamilton 1 hour agorootparentNewspapers already are applying their own metrics for what&#x27;s fit to print, seems reasonable to prefer one&#x27;s own metric (if not reasonable to expect that to happen without action). replylogicchains 3 hours agoprevInterestingly, in 2022 the FCC changed the range of acceptable EKG requirements for heart health required for pilots; previously the PR had to be between 0.12 to 0.2, and they widened it to 0.12 to 0.3. That would have allowed pilots with mild cardio injury (who are more likely to suddenly pass out) to fly. reply atleastoptimal 6 hours agoprevAir traffic control seems like something that should be at the top level surveyed by humans but has many layers of automated computational safety built in. I imagine there is, but the idea that the safety of a plane is up to a single person at some point is unsettling. Having existed for many decades, the entire field should be far past the point of there being even a 0.000000001% chance of hazard. reply woodruffw 6 hours agoparentATC makes extensive use of automation for scheduling, queuing, etc. The hard manual parts are what remain: communicating with pilots over unreliable channels, handling unpredictable scenarios and emergencies, and maintaining spatial awareness for the airport and the tower&#x27;s area of control. reply matwood 2 hours agoparentprevThe US Navy presumably has a near unlimited budget and aircraft carriers are still very analog in this regard. There have been some attempts to make the ouija board digital, but still have it be manually updated.https:&#x2F;&#x2F;coffeeordie.com&#x2F;ouija-boards-aircraft-carriers reply shermantanktop 5 hours agoparentprevYour expectations don’t seem to match any other field of human endeavor I can think of. Nuclear plant safety doesn’t; rocket launches, no; pharmaceutical trials, nope. Perhaps we’ll be better and smarter in the future, but…I doubt it. reply atleastoptimal 5 hours agorootparentWhen was the last time Nuclear plants in the US significantly endangered human lives. 1979?With regards to rocket launches, pharma, etc. those are all somewhat novel domains: experiments where risk is a natural part of being the first time trying a set of variables. The variables in air traffic have been the same for decades, thus the thresholds for accepted risk should be much lower. reply ejiblabahaba 47 minutes agorootparentThe US literally stopped issuing new reactor permits in 1979 (down from on-average about 12 per year), and didn&#x27;t begin issuing new ones until 2012. Out of 177 reactors issued construction permits up through 1979, at most 112 were ever online at once, in 1991, up from 69 in 1979 when the Three Mile Island failure happened - implying over half of already permitted construction was abandoned or never even started. The facilities under construction were subject to an exponentially increasing gauntlet of new safety assessments, failsafe systems, and in many cases reconstruction of things already built and approved just years prior; eventually, the expense of such facilities radically outstripped the expected ROI of nuclear facilities altogether. Most facilities overran on costs, and took decades longer than expected to see their first real returns, if they even stayed open long enough to see real returns.If US nuclear plants haven&#x27;t significantly endangered human lives since 1979, it&#x27;s because the thresholds for accepted risk became so low as to render new enterprise impossible.Regulating air traffic control (and thus air traffic) into impossibility isn&#x27;t a realistic option. Unlike nuclear energy, which has functionally equivalent alternatives, there is no functional equivalent to the speed, reach, and cost of air travel. We likely already hit the practical floor on incidents in ATC a long time ago, thanks to (as you have observed) the variables involved being very stable for decades.Hence the cause for alarm: what if, all of a sudden, those reliable variables are changing? reply shermantanktop 4 hours agorootparentprevCall me a techno-pessimist, but we humans have a way of building imperfect machines regardless of theoretical perfectibility. Boeing 737 max? reply eganist 1 hour agorootparentIn fairness, perfect and simple almost never go hand in hand in life critical applications because simple is almost entirely incapable of accounting for and mitigating impacts from the entropy of the universe.Couple that with capitalism (the 737 max&#x27;s design, oversimplified, resulted in two disasters due to a for-profit company trying to maximize profit and minimize time to market by hacking an existing platform to compete with a new and ostensibly better one) and it&#x27;s a surprise we&#x27;re doing well with air travel at all.That air travel is as good as it is is a great case for techno optimism. In spite of all the garbage we get ourselves into, we manage to make it work. replyclaar 9 hours agoprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;@VASAviation posts ATC audio and a visualization a day after such incidents happen. Fantastic channel, if a bit too addictive. reply ra7 3 hours agoparentI just discovered this channel a few days ago and I’ve been hooked to it since then. Another channel I’ve been enjoying is https:&#x2F;&#x2F;youtube.com&#x2F;@YouCanSeeATC reply Buttons840 5 hours agoprevDo pilots have any tools detect conflicting runway use?Like, I would imagine light patterns would mark a runway as take-off, landing, or neither (plane crossing, etc). A pilot told to land on a runway not lit for landing would know something&#x27;s wrong, and planes would know not to line up on a runway lit for landing, etc. reply rdtsc 5 hours agoparent> I would imagine light patterns would mark a runway as take-off, landing, or neither (plane crossing, etc)It&#x27;s often both, and the direction depends on the wind. It&#x27;s better for planes to take off into the wind, so as the weather changes runway usage also changes accordingly during the day.Or were you thinking the lights would change minute by minute based on the next designated usage. That might work! \"Now it&#x27;s a landing runway so it&#x27;s blinking blue\" kind of a thing. So nobody tries to take off or cross it. Or, then when someone is supposed to take off it&#x27;s blinking yellow so planes landing on it won&#x27;t be confused. reply Buttons840 5 hours agorootparentThat&#x27;s what I mean. Change the lights minute by minute.There have been incidents where one plane is cleared to cross while another is landing on final approach. There&#x27;s no fault on the pilots I think. With the right signaling on the runways all pilots involved could double check the clearances and one of them can speak up if things are weird. reply matwood 3 hours agoparentprevOver the summer a near miss happened in Austin and I looked into this a bit. It seems that some airports do have lights that change in real-time, but not all. Austin does not have the system. reply otherme123 3 hours agoparentprevYou mean like this: https:&#x2F;&#x2F;skybrary.aero&#x2F;articles&#x2F;runway-status-lights-rwsl ? Or https:&#x2F;&#x2F;skybrary.aero&#x2F;articles&#x2F;runway-awareness-and-advisory... ? reply brettproctor 5 hours agoparentprevInteresting idea but no, the lights never change based on usage like this. reply spaceman_2020 6 hours agoprevAlso been an 18% increase in road accidents.Just post pandemic recklessness? reply Havoc 8 hours agoprevThe YouTube channels for ATC incidents have certainly been rather busy too. reply anonymousiam 8 hours agoprevNo mention of it in the NYT article, and I make no claim about the accuracy of the reporting below, but at least a few sources have claimed that this decrease in safety is traceable to changes in FAA hiring practices aimed at increasing diversity.https:&#x2F;&#x2F;blog.aci.aero&#x2F;diversity-equity-and-inclusion-in-the-...https:&#x2F;&#x2F;icanflytoo.org&#x2F;home&#x2F;dei-in-aviation&#x2F;https:&#x2F;&#x2F;www.dailysignal.com&#x2F;2018&#x2F;06&#x2F;27&#x2F;the-disastrous-initia...https:&#x2F;&#x2F;freebeacon.com&#x2F;biden-administration&#x2F;heres-what-the-f...https:&#x2F;&#x2F;johnalucas6.substack.com&#x2F;p&#x2F;bidenbuttigieg-dei-polici...https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qh9SxqsQdpo reply belltaco 7 hours agoparentIf so, why do we see a sudden increase in just one year worldwide, including Europe?The most plausible explanation is brain fog from COVID and long COVID compounded by employee shortage and overwork. reply grogenaut 6 hours agorootparentThe most obvious answer is people flew, drove, and studied less and so all the things people are bringing up are showing up worse than average after due to lack of practice. I definitely drive way less now &#x2F; thenm reply grok24 8 hours agoparentprevIf you didn’t think there was some validity to the reporting, you wouldn’t be posting it. reply consumer451 8 hours agoparentprev> I make no claim about the accuracy of the reporting belowThen you appear to knowingly spreading unfounded rumors? reply anonymousiam 6 hours agorootparentPerhaps, but I did review the material before I posted it. Did you? reply sparcpile 6 hours agorootparentBlaming DEI is a dog-whistle for &#x27;people should know their place&#x27; The Free Beacon, Fox News, and the other last four you listed are in the business of telling old white people to be afraid of everything.It&#x27;s the same as denying someone a job because they are not culture fit for a company. It&#x27;s because the people doing the hiring only want to hire people from their background, college, etc.The safety issues and staffing levels have been an issue since Reagan fired the PATCO ATC workers. It&#x27;s getting worse because traffic loads are increasing and it is getting harder to staff for a stressful safety-critical job. reply atleastoptimal 5 hours agorootparentAir traffic is up this year only 4%, would that naturally correspond to a 65% increase in significant incidents?The issue isn&#x27;t whether or not people are tacitly insisting certain people \"deserve\" to be in certain positions due to their race&#x2F;background, and those against DEI are lamenting the loss of the soft apartheid we had in the US that gradually eroded with the civil rights movement. The issue is: in chasing demographic targets, are jobs lowering their standards for employment, and are those lowered standards causing a hazard for those impacted by the performance of those who work those jobs? reply sparcpile 5 hours agorootparentThe load on the National Airspace System (NAS) has been growing each year, with slight a dip due to COVID. The FAA has provides 20-year outlooks for a set of metrics, including the number of operations performed with the NAS. https:&#x2F;&#x2F;www.faa.gov&#x2F;sites&#x2F;faa.gov&#x2F;files&#x2F;2022-06&#x2F;FY2022_42_FA... See Page 33 and 34 for a breakdown in the numbers. We&#x27;re looking at 50 million to 62 million operations per year within the NAS.The question asking if DEI is lowering standards is bunk because it is pre-loading the assumption that the best qualified workers are the what was there traditional (straight white males) and that somehow allowing others in requires lowering some standards.For the purposes of the FAA air traffic control specialists, everyone who applies must go to the FAA Academy in Oklahoma City, OK and pass the the courses and tests provided there. They are then transferred to their home facilities where they must become certified for the position that they have been hired in. This requires additional tests, training, simulations, shadowing, and fully supervised workloads. If you become certified for a position and sector, it means that you can safely manage air traffic. Failure at any step along the way means that you wash out. The FAA does not lower standards for ATCS. See the following research paper on ATCS failure rates, rationales, and percentages. https:&#x2F;&#x2F;corescholar.libraries.wright.edu&#x2F;cgi&#x2F;viewcontent.cgi... reply robertlagrant 5 hours agorootparentprev> Blaming DEI is a dog-whistle for &#x27;people should know their place&#x27;This is a very common trope: claim to have dog-level hearing for detecting what people really mean. Very often, including likely this time, it&#x27;s totally inaccurate, and just means no discussion can be done as one of the parties relentlessly ad hominems the other.> since Reagan fired the PATCO ATC workersCan you cite this? reply sparcpile 5 hours agorootparenthttps:&#x2F;&#x2F;www.govexec.com&#x2F;workforce&#x2F;2023&#x2F;11&#x2F;overtime-staffing-...It took 10 years after Reagan fired the controllers to get the workforce back to pre-1981 levels. This caused a ripple effect because the people that were hired were around the same age. The result was the FAA had to deal with large sections of the ATSC workforce retiring at 56(the legal maximum for an air traffic controller) in bunches. The FAA has struggled since this to maintain adequate staffing levels due to high stress nature of the job. replyPseudoThought 3 hours agoprevAutomated aircraft for routine cargo and passenger travel controlled by an automated ATC system seems like the future. reply cratermoon 2 hours agoparentHow would it handle emergencies like https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38586773 ? reply Geisterde 24 minutes agoprevUsually I like to just read comments, get a feel for where society is. I love the comments in this, it can be summarized as \"throw AI at it\" and \"more tax dollars will fix it\".Lets all forget that we have put the airline industry on government life support through regulation and bailouts, thats turned the biggest companies into tumors that survive off their (literal) monopoly rights. We can all pretend we didnt dehumanize the staff on&#x2F;off-board with vaccine mandates that simultaneously violated their human rights and failed to stop infection or transmission (as they were promised).Yep, fat, lazy, unprincipled american voters to the rescue, throw in some rhetoric about how we are going to tax the rich (then tax poor&#x2F;middle class people who dont have their own LLC), replace the workers woth AI, and incoherently froth about your political opponents.Or, you know, we could start privatizing it. Calm down, its OK, I was a nuclear reactor operator in the navy, I can assure you it will only ever get worse. reply sillysaurusx 5 hours agoprevIt’s possible this is statistically expected. In the same way the stock market randomly fluctuates, it would be implausible that the ATC incident rate should only ever go down.The question is whether this is outside the variance we should expect. Is it?I see a lot of people coming up with reasons and explanations, implying that the incident rate can be controlled. To an extent it can. But it can’t be decreased forever, especially as the fleet increases. Is there a graph of the incident rate with respect to fleet size over the last few decades? reply sixQuarks 5 hours agoparentTrue, and a 68% increase in something that rarely happens isn’t as scary when you look at the actual total number of incidents. reply resolutebat 5 hours agoprevUS air traffic also increased 20-30% compared to 2022, depending on whose numbers you believe (the year isn&#x27;t over yet). reply Unfrozen0688 9 hours agoprevPushing Tin is a pretty good film about ATC reply alexey-salmin 2 hours agoprevI guess lessons weren&#x27;t learned after the lake Constance collision reply PhobosSkunk 1 hour agoparentIt&#x27;s not really the same problem but a good example of the end result (spoiler alert: dead peoples). Lake Constance was mostly due to faulty procedures, technical intervention and bad habits (letting a colleague work alone during night shift coffee breaks) and those lessons have been well learned as Skyguide is now one of the safest ANSP, refusing to increase capacity because of all those safety measures.FAA is another really scary story. 6 days of 10h shifts with 8 to 9h of rest is just insane. As a euro ATCO I know for a fact that we would never accept that, we have way more days off, a minimum of 11h rest time and are never called to work more nor work more than the contracted hour. As a matter of fact it is the opposite, we usually work less hours a day than what is planned. Maybe it is a different work culture between US and EU but we won&#x27;t sacrifice ourselves for the company. If we are understaffed we will let it happen, reduce capacity or even close some airspace and let the company lose money and credibility.Anyway, as we often say, everybody working in the aviation industry is tired because of the shifts. Just don&#x27;t let the PAX know about it. reply tayo42 9 hours agoprevWell that was worrying to read since I flight through San Diego coming up.Why are the budgets low and why is our government running atc like a best buy durring holiday season? reply losteric 9 hours agoparent- ATC is a difficult job both in terms of training required and day-to-day work- There are high health requirements to hold the job, which should be revisited- The federally mandated retirement age is relatively low.- Pay is not attractive- Overall FAA funding is largely set by the finicky Congress, which swings between extreme austerity and moderate fiscal pragmatism- Airports can supplement federal funding, but it&#x27;s difficult to get someone that cares. The right port authorities would need to be elected, then raise rates at risk of airlines pushing back... only to improve the safety of their one airport (likely still taking the full PR&#x2F;trust-hit if a tragedy happens at a different airport anyway)- COVID19 led to a higher rate of people exiting the field (due to reduced labor demand + natural retirement), and few entering the field.- Hiring&#x2F;pay was not managed in alignment with the return of travel demand.- These ATC articles have been circulating for a couple years now. That&#x27;s probably dampened interest in these jobs. reply gred 9 hours agorootparent> Pay is not attractiveThat&#x27;s not my impression at all, based on discussions with FAA employees.From a quick online search:> ATC 2022 median pay: $132,250 per yearhttps:&#x2F;&#x2F;www.bls.gov&#x2F;ooh&#x2F;transportation-and-material-moving&#x2F;a... reply jjulius 9 hours agorootparentIs $132,250 attractive relative to the constant high stress and everything else involved with the job? reply dghlsakjg 9 hours agorootparentprevDid you read the part about 10 hour days and 6 day workweeks? I wouldn&#x27;t do that for $132k.Add in the fact that the FAA is about 50 years behind the times in understanding mental health, so you might lose your entire career if you are diagnosed with depression (even if it is a result of stress at work).Plus, you have to be younger than 31 to start an ATC career, and are required to retire no later than 56. So for good, not great, pay: you have to pick your career before the age of 31. Pass rigorous training. Have a plan for starting a new career if you ever have health issues, or when you turn 56, whichever comes sooner.In a vacuum, the pay is attractive. In context, it doesn&#x27;t seem much more than \"above average\", at best, for a VERY hard job.In any case, the proof is in the pudding. If people thought the pay was generous and worth it, would there be a shortage? reply gred 8 hours agorootparent$132k is great pay. You get to retire at 56 with a nice federal retirement package, plus an extra supplement to top things up until you are eligible for social security (which you&#x27;re not initially, since you get to retire so damn early). Is it a hard job? Certainly. But I&#x27;m sure a significant number of retail jobs are nearly as stressful. And the union has your back, making sure you get a decent number of decently-sized breaks, overtime pay for overtime work, etc. reply vlovich123 1 hour agorootparent> a significant number of retail jobs are nearly as stressfulA significant number of retail jobs involve the risk of a mass casualty event if you make a mistake and the opportunity for such mistakes happens many times through a day, each day for years on end? reply syndicatedjelly 6 hours agorootparentprev> But I&#x27;m sure a significant number of retail jobs are nearly as stressful.Ok you lost me there. Which part of retail work has you responsible for the lives of 200 people at a time? reply kredd 6 hours agorootparentprevFor the responsibility they’re undertaking, I would be happy for them to get paid even more and retire at 45. reply lotsofpulp 1 hour agorootparentprevYou neglected to respond to the important question:> In any case, the proof is in the pudding. If people thought the pay was generous and worth it, would there be a shortage?The rest of your comment is irrelevant. The “great”-ness of a price is evident by the number of sellers willing to accept it. replymensetmanusman 6 hours agoparentprevSo many people quit the industry during covid, you can&#x27;t ramp that back up in even 5 years without major compromise. reply Unfrozen0688 9 hours agoparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Public_ManagementPolicy is to run government entities like a corporation. reply NautilusWave 4 hours agoprevI wonder whose fault that is, 𝙍𝙤𝙣𝙖𝙡𝙙 𝙍𝙚𝙖𝙜𝙖𝙣. reply m3kw9 5 hours agoprevMaybe there is 65% more flights since the Covid times reply timeagain 7 hours agoprevFrom what to what? What counts as “serious?” What percentage of flights? Which kind of flights? How many of them are commercial passenger (as opposed to cargo)? Can the variance be ascribed to noise?Sorry if some of these questions can be answered from the paywalled article. But my gut says that this is making news out of nothing important. reply verteu 6 hours agoparent> In the fiscal year that ended Sept. 30, there were 503 air traffic control lapses that the F.A.A. preliminarily categorized as “significant,” 65 percent more than in the prior year, according to internal agency reports reviewed by The Times. During that period, air traffic increased about 4 percent. reply jongjong 5 hours agoprevI&#x27;ve been warning of software deterioration for the past few years and this seems to be an extension of the same effect. Likely the result of increasingly non-meritocratic employee selection processes and non-meritocratic incentive structures. Due to government interference in the economy (especially due to money printing), we&#x27;ve basically turned our capitalist system into a very poorly implemented communist system. People are broke, have low self esteem, can&#x27;t afford to own a house and only anticipate further deterioration. Heck, average people can&#x27;t even find a romantic partner because rich people are monopolizing the supply by dating 10 people at a time. I&#x27;m surprised things are not worse than they are. I guess it will take another decade to feel the full effects of the problems we&#x27;re creating today. reply tester756 9 hours agoprevI don&#x27;t know why, but archive.is is not loading for me reply tux3 9 hours agoparentThey&#x27;re in a fight with Cloudflare over technical details, if you use CF as DNS that&#x27;s why reply o11c 9 hours agorootparentThere&#x27;s plenty broken with both .is and .ph even if Cloudflare is not in the picture. reply rainbowzootsuit 9 hours agorootparentprevThis is a relevant explanation from the perspective of cloudflarehttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19828702 reply tester756 8 hours agorootparentprevI have Google&#x27;s DNS and DoH turned off reply anonhn1231231 7 hours agoparentprevI had to disable DNS over HTTPS to get archive to work again.In Firefox it&#x27;s enough to add archive.is&#x2F;.ph&#x2F;.today to the exception list, and keep using default settings otherwise. Not sure about other browsers. reply a1o 9 hours agoparentprevIt didn&#x27;t work for me either but the ph one workedhttps:&#x2F;&#x2F;archive.ph&#x2F;EV9WP reply macinjosh 9 hours agoprevnext [2 more] [flagged] s1artibartfast 8 hours agoparentWhat strange reasons. Is this a joke? reply nemo44x 9 hours agoprevnext [22 more] [flagged] IAmGraydon 9 hours agoparentIt&#x27;s sad that this is getting downvoted. What you posted is a fact and it should be addressed. We shouldn&#x27;t bury our heads in the sand just because it&#x27;s an issue of race. reply DiscourseFan 9 hours agorootparentI think if it were a fact, it would be supported by argument and evidence. What we have here is simply a claim, which was not supported by any evidence. I am perfectly willing to accept that poorly thought out diversity policies can have adverse effects on organizations, which is especially troubling if that organization manages vital infrastructure. But I would need to see good evidence, and argument with that evidence, to prove it, and not just a claim standing alone. reply slibhb 6 hours agorootparenthttps:&#x2F;&#x2F;archive.is&#x2F;lDyOBI have no idea whether affirmative action in Air Traffic Control has anything to do with increased incidents. Either way, I think affirmative action as applied here is a travesty. reply AdrianB1 8 hours agorootparentprevSo if you don&#x27;t agree with a claim, instead of asking for evidence you flag and terminate the discussion? This is what happened here. reply defrost 7 hours agorootparentThe very person you are asking did ask for evidence right here in a peer comment 34 minutes before your comment, see:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38587616There&#x27;s still a lack of any hard evidence beyond a speculative Fox NewsTucker CarlsonSean Hannity dog whistle article.The primary article of this submission indicates more that overall systemic changes from the top are the root cause rather than being entirely the workers fault; less staff, more hours, reduced training, etc. reply AdrianB1 0 minutes agorootparent1. Lack of response is not lack of proof.2. People don&#x27;t leave on HN, demanding an answer and waiting 34 minute before nuking from orbit is illogic.3. There was a source and some information to support the claim. Also part of the claim is self-explanatory (lowering the standards for new hires to meet some hiring targets).4. There is ample evidence in so many other places about the effects of lowering standards to meet diverse hiring targets. I cannot publish the results in my own company with close to 100,000 employees because they are not public, but they exist and they are embarrassing at least.I am not the one that made the claim and I am not interested to support or explain it, but I am disappointed by the reaction: cancel any discussion that does not fit your views. Burn Giordano Bruno at stake, he did not present proof enough and fast enough. DrFunke 5 hours agorootparentprevHN&#x27;s flagged comments are the most interesting. reply DiscourseFan 9 hours agoparentprevThis would be very interesting to look into if you cited a source. reply z7 8 hours agorootparentHere&#x27;s an academic publication from 2018, but it doesn&#x27;t seem to make any explicit claims about diversity related reasons for the changes in the hiring process:>The hiring process for aspiring federal air traffic controllers from approved Air Traffic Collegiate Training Initiative (AT-CTI) institutions has undergone several revisions in recent years. Prior to 2014, graduates from AT-CTI programs were given preferential hiring from the FAA. In 2014, the FAA announced that AT-CTI graduates would equally compete with thousands of people the FAA calls “off the street hires”--anyone can literally walk in off the street without any previous training and apply for a federal air traffic control job. To apply, the FAA requires that a candidate has United States (U.S.) citizenship, a high school diploma, speaks English, and passes the FAA’s new Biographical Questionnaire (BQ).>Another concerning perspective from AT-CTI administrators is that CTI graduates are at an employment disadvantage with the new hiring initiatives. One of the responding administrators expressed concern that off the street applicants have increased odds of employment over CTI applicants because CTI students are combined in track one with Veteran’s Readjustment Appointment (VRA) applicants putting CTI students second while all off the street applicants are grouped as one and have an equal opportunity for selection.>The new FAA hiring protocol for federal air traffic controllers that was implemented in February 2014 included several significant changes. In particular, the FAA reduced the role of the CTI-approved program; therefore, the only remaining advantage for CTI graduates is that they are eligible to bypass the Air Traffic Basics Course, which is the first five weeks of qualification training at the FAA Academy in Oklahoma City (FAA, 2018). In addition, the FAA introduced the Biographical Questionnaire which was envisioned to predict controller performance through a process of asking individuals to recall their typical and&#x2F;or specific behaviors from earlier times in their lives. But due to the lengthy process of hiring and training an air traffic controller which can take several years, it is too soon to conclude whether the FAA’s new hiring policies improved the ability to hire individuals who are more likely to successfully become federal controllers (FAA, 2017b).https:&#x2F;&#x2F;ojs.library.okstate.edu&#x2F;osu&#x2F;index.php&#x2F;CARI&#x2F;article&#x2F;v... reply Dalewyn 9 hours agorootparentprev\"Affirmative Action Lands in the Air Traffic Control Tower\", Wall Street Journal (June 2, 2015): https:&#x2F;&#x2F;archive.is&#x2F;lDyOB>A recently completed six-month investigation by Fox Business Network found that the Federal Aviation Administration has quietly moved away from merit-based hiring criteria in order to increase the number of women and minorities who staff airport control towers. The changes come despite the fact that the FAA’s own internal reports describe the evidence for changing the hiring process as “weak.”>Until 2013, the FAA gave hiring preference to controller applicants who earned a degree from one of its Collegiate Training Initiative schools and scored high enough on an eight-hour screening test called the Air Traffic Selection and Training exam, or AT-SAT, which measures cognitive skills. The Obama administration, however, determined that the process excluded too many from minority groups. reply DiscourseFan 9 hours agorootparentThis is very troubling if it is true, but the reporting felt a bit thin. If there was an article with interviews and more concrete evidence I would be more satisfied. reply stevenae 9 hours agorootparentprev\"Fox Business (officially known as Fox Business Network, or FBN) is an American conservative business news channel and website publication owned by the Fox News Media division of Fox Corporation.\" ~ https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fox_Business reply AdrianB1 9 hours agorootparentprevA few weeks ago I heard about this from another pilot; I found several sources with a minimum of effort. I only fly in Europe, so I have zero personal experience with what is going on in US, but the narative makes sense to me as I saw it personally in other areas. reply nemo44x 9 hours agorootparentprevnext [4 more] [flagged] DiscourseFan 9 hours agorootparent>NYT cites overworked employees as the cause but leaves out the ongoing and dangerous agenda in the FAA to prioritize diversity over merit.I was looking for more info on your claim, not another claim from someone else that only says something was being left out, without actually showing the very thing that was purported to have been elided. reply a1o 9 hours agorootparentMaybe the problem is diverse employees have less power to negotiate changes and improvements in the workplace like the issues cited in the NY piece - building and infrastructure issues and the short staffing. reply defrost 9 hours agorootparentprevJust to be clear,your source for your opinion expressed in your comment on this forum is another opinion expressed on Xitter?Do you have any kind of more primary source, data on hiring changes, studies that correlate incidents with more recent hires, etc.Or just the strong opinions of some fellow travelling RestoreUSA types? reply Racing0461 9 hours agoparentprevAgreed on this (the DEI part, not the obama part. It&#x27;s much bigger than that.). Previously it was a mutual understand that ATC wouldn&#x27;t get snarky with pilots in th air until they are on the ground as pilots have the final say.Lately on youtube, i&#x27;ve seen nothing but bad behavior from ATC. And let&#x27;s just say, there were certain qualities that were common between the incidents. reply brigade 9 hours agorootparentWhat, that 90% of them are from contracted towers, whose contractor can get away with understaffing and overworking their controllers, and the controllers know they won&#x27;t face consequences, because the FAA has no better solution (money, personnel) for staffing said towers and there&#x27;s no political drive to force the issue? reply tom_ 9 hours agorootparentprevAnd what were those certain qualities? We aren&#x27;t mind-readers. reply DamnYuppie 9 hours agorootparentThey were black reply tennisflyi 9 hours agorootparentprevATC has always been terse and made you feel like a bother reply talldatethrow 5 hours agoprevnext [13 more] [flagged] PromKwing 5 hours agoparentYikes. What a weird thing to try to make it about race. So to clarify, if you&#x27;re not white and male, then obviously you&#x27;re just not serious about a job because you&#x27;re a \"diversity\" hire and not a serious person. Got it. reply throwme_123 5 hours agorootparentIf you&#x27;re (much) less competent but the only reason why you get the job is \"diversity\", then yes we have a problem.There can be diverse good candidates of course, there&#x27;s no racism here. reply PromKwing 5 hours agorootparentRight, so if you&#x27;re not the hiring manager, how do you know someone is a \"diversity hire\" though? Isn&#x27;t it racist to just assume someone was hired as a \"diversity hire\"? Most importantly, people tend to hire people like themselves, if the hiring manager is white it&#x27;s most likely they&#x27;ll hire someone who is white regardless if they&#x27;re more qualified, but I doubt anyone ever questions those hires. reply throwme_123 5 hours agorootparentThat&#x27;s the point.You should not know and should not take it in consideration but in the USA this is part of the application. I understand the whole point is to make sure diverse candidate are not discriminated against (and of course that would be a ridiculous thing to do), but it seems to have been perverted into caricaturical discrimination _for_, even favoring a diverse incompetent candidate over a non-diverse competent one. reply PromKwing 4 hours agorootparent> but it seems to have been perverted into caricaturical discrimination _for_, even favoring a diverse incompetent candidate over a non-diverse competent one.That&#x27;s a crazy claim told without any proof. I don&#x27;t see any studies, sources linked in your comment. That just sounds like your own anecdotal perspective. reply mcphage 5 hours agorootparentprev> You should not know and should not take it in considerationThen how do you suppose we ended up with fields where nearly everyone was a white male, if race was never taken into consideration? reply jimbob45 2 hours agorootparentBecause whites were 85% of the US population for a long time and being a SAHM used to be a viable strategy. replysixQuarks 5 hours agorootparentprevSounds like you’re the one making it about race. Are you saying there is not a single non white male among the veteran group?The point is, people in this position should be hired based on merit regardless of their race, sex, or anything else. reply PromKwing 4 hours agorootparent> Are you saying there is not a single non white male among the veteran group?I am not saying that and yes that would be obvious. That doesn&#x27;t negate anything about how it&#x27;s on the \"diversity hires\" and not the veterans pointed out in this thread, lolIt&#x27;s all just speculation.> The point is, people in this position should be hired based on merit regardless of their race, sex, or anything else.What&#x27;s your proof that people aren&#x27;t hired based on merit regardless of their race, sex, or anything else though? Just wild speculation on your part? lol reply throwme_123 5 hours agoparentprevMore details on this:https:&#x2F;&#x2F;x.com&#x2F;restoreorderusa&#x2F;status&#x2F;1731058275720831262?s=2... reply PromKwing 5 hours agorootparentWhy not throw the veterans under the bus as well though? Nope, it&#x27;s just the \"diversity hires\" that are the problem lol. reply mcphage 5 hours agoparentprevI’d love to hear your explanation on why diversity is so detrimental to being an air traffic controller. reply ytdytvhxgydvhh 8 hours agoprevWhat do we think, within 5 years pilots will be talking to AI chatbots that handle air traffic? reply tbihl 8 hours agoparentIs there a plane about to crash? Say 1 for not sure, 2 for normal business hours, 3 for no, or 4 for I&#x27;M SORRY I didn&#x27;t catch that, say 1 for not sure... reply syndicatedjelly 6 hours agoparentprevOf all the things to use an AI chatbot for, this might be the worst one. reply atleastoptimal 5 hours agorootparentThat&#x27;s assuming AI still stay as it is forever. In 3-5 years every job that can be done on a computer will be able to be done better by an AI designed for that job. The only issue will be adoption, not the tech itself. reply mensetmanusman 6 hours agoprev [–] Post-covid ripples through time... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The United States is currently experiencing a nationwide shortage of air traffic controllers, leading to a fatigued and demoralized workforce.",
      "Controllers are hesitant to seek help for physical and mental health issues, further exacerbating the problem.",
      "The Federal Aviation Administration (FAA) is facing challenges in training and hiring new controllers, resulting in understaffed control sites and increased overtime hours. This has led to safety concerns and resignations among controllers."
    ],
    "commentSummary": [
      "The discussion covers various topics such as air traffic control incidents, car accidents, pandemic effects on driving behavior and student performance, safety in air travel and space flights, hiring practices in air traffic control, concerns about automation, and diversity hiring.",
      "There are disagreements regarding the causes of incidents and accidents, the impact of diversity in the hiring process, and the effectiveness of certain safety measures.",
      "The conversation emphasizes the importance of careful analysis, avoiding quick conclusions based on correlations, and the need for continuous improvement in safety across different modes of transportation."
    ],
    "points": 167,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1702164913
  },
  {
    "id": 38587052,
    "title": "Introducing SecureAI Tools: Open-source Chat with AI Models and PDFs",
    "originLink": "https://github.com/SecureAI-Tools/SecureAI-Tools",
    "originBody": "Hey everyone,We have been building SecureAI Tools -- an open-source application layer for ChatGPT and ChatPDF-like AI tools.It works with locally running LLMs as well as with OpenAI-compatible APIs. For local LLMs, it supports Ollama which supports all the gguf&#x2F;ggml models.Currently, it has two features: Chat-with-LLM, and Chat-with-PDFs. It is optimized for self-hosting use cases and comes with basic user management features.Here are some quick demos: * Chat with documents using OpenAI&#x27;s GPT3.5 model: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Br2D3G9O47s * Chat with documents using a locally running Mistral model (M2 MacBook): https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UvRHL6f_w74Hope you all like it :)",
    "commentLink": "https://news.ycombinator.com/item?id=38587052",
    "commentBody": "Open source alternative to ChatGPT and ChatPDF-like AI toolsHacker NewspastloginOpen source alternative to ChatGPT and ChatPDF-like AI tools (github.com/secureai-tools) 166 points by d7y 10 hours ago| hidepastfavorite40 comments Hey everyone,We have been building SecureAI Tools -- an open-source application layer for ChatGPT and ChatPDF-like AI tools.It works with locally running LLMs as well as with OpenAI-compatible APIs. For local LLMs, it supports Ollama which supports all the gguf&#x2F;ggml models.Currently, it has two features: Chat-with-LLM, and Chat-with-PDFs. It is optimized for self-hosting use cases and comes with basic user management features.Here are some quick demos: * Chat with documents using OpenAI&#x27;s GPT3.5 model: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Br2D3G9O47s * Chat with documents using a locally running Mistral model (M2 MacBook): https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UvRHL6f_w74Hope you all like it :) vunderba 9 hours agoGreat job. This is a relatively crowded area, particularly RAG style chat systems. It might be nice for SecureAI to call out what makes their product different from other open source players in the same space, specifically Khoj and Danswer, both of which allow you to chat with your documents, offer network authentication, and allow you to plug in your own LLM.Danswerhttps:&#x2F;&#x2F;github.com&#x2F;danswer-ai&#x2F;danswerKhojhttps:&#x2F;&#x2F;github.com&#x2F;khoj-ai&#x2F;khoj reply SubiculumCode 7 hours agoparentDo you happen to know of some that have been integrated into a slack chatbot? reply vunderba 4 hours agorootparentI&#x27;ve definitely seen a few that can do this, they&#x27;re mainly positioned as automatic assistance for technical support.Danswer has a slack connector, so it might be what you&#x27;re looking for. reply teruakohatu 1 hour agoprevCan a directory of PDFs be queried or does it only support a single document? reply abnry 9 hours agoprevIs there a good ML tool for renaming PDFs? There are some tools out there but they assume a journal format. reply Reptur 9 hours agoparentI tend to just select all the files and then paste their filenames into a Chat AI and tell it to write mv commands to rename them however I need. May be more complicated if you need it to open the PDF to get content for the rename though. reply d7y 9 hours agoparentprev> renaming PDFsSorry, I didn&#x27;t understand. Why do you need ML tool for renaming PDFs? or did you mean rephrasing or rewriting in a different format? reply mattsan 9 hours agorootparentMaybe they mean walking a file tree and cleaning up file names to match the titles on the covers of them more accurately? reply abnry 9 hours agorootparentExactly. You download something from arxiv and the filename has no meaningful content in it. Generally speaking, you want the filename to be descriptive in some way, extracting the title of the document is a good start. reply bravura 5 hours agorootparentYou can just import them all into paperpile, which has good ways of inferring the metadata like title author year etc. and then connect to your google drive. Which will download them with nice filenames. replyhifreq 4 hours agoprevI couldn&#x27;t find this info in the readme... does this tool anonymize ChatGPT requests? What does it mean that it&#x27;s a private an secure tool in the context of using ChatGPT? reply glerk 3 hours agoparentMy understanding is that this doesn&#x27;t use ChatGPT at all for the \"private and secure\" case. It is running LLM models locally using ollama and just provides a ChatGPT-like interface. reply willi59549879 3 hours agoparentprevit runs an llm in a docker container. doesn&#x27;t send any requests to chatgpt reply hifreq 20 minutes agorootparentThe demo video is using ChatGPT. reply caseyf7 9 hours agoprevHow do you get value from chatting with documents? I can scan and read a pdf faster than I can chat with an AI about it. There must be more to it than I realize. reply capableweb 8 hours agoparent> There must be more to it than I realize.PDF material comes with different information density. If you have a lose collection of 100 manuals, and you need to find a snippet of information that could be in 10 different ones, I&#x27;m guessing something like this can help you navigate and locate what you need. reply freedomben 8 hours agoparentpreva one-page PDF, sure. But if it&#x27;s a 500 page pdf of a law and&#x2F;or regulation, then definitely not. reply bravura 5 hours agorootparentYou can screenshot the first page and use gpt vision reply arthurcolle 5 hours agorootparentYou could just load up the doc, take first 1024 tokens, and almost always get the right authors&#x2F;title&#x2F;year, etc, assuming its there.But going further, for large bills you might need (|n|..|m|) pages to capture full indexfor research papers you also want to look at last (|n2|..|m2|) pages for bibliography, etc.. reply jrpt 7 hours agoparentprevI run https:&#x2F;&#x2F;Docalysis.com&#x2F; and there’s a few use cases. The first is getting information out of various reports and papers by chatting with it, which is faster than reading an entire document. Another is automating data extraction out of files, which is part of many business processes. reply abraae 7 hours agoparentprevResponding to RFPs springs to mine. Knowing you have already answered the question on some previous response but a nightmare to lay your hands on it. reply netcraft 8 hours agoparentprevwhat if you want to extract certain information from 100 pdfs? reply naiv 8 hours agoparentprevAlso if they are in spanish? reply katrinarodri 7 hours agorootparentyou mean ability to translate PDFs into english? reply cheema33 10 hours agoprevI am very new to this field, so forgive my ignorance when I ask super basic questions.1. Does chat-with-pdfs function work with scanned PDFs? 2. In the video example for chat-with-pdfs you show uploading a document interactively. The part of processing is quite slow. Can the tool be fed these documents offline as well?My use case for each user, there are many, to have their own list of documents that they upload. They come back later, after the LLM has had a chance to process all documents and can ask questions about their own documents only.Is something like this possible? reply d7y 10 hours agoparentGreat questions.> 1. Does chat-with-pdfs function work with scanned PDFs?Not yet. We don&#x27;t do OCR or anything to extract text from images yet. But that would be an awesome feature, so we would love to add it in the future.> 2. In the video example for chat-with-pdfs you show uploading a document interactively. The part of processing is quite slow. Can the tool be fed these documents offline as well?Not as of right now. But we do have plans to make that an offline&#x2F;background job so that we can feed a larger corpus of documents into it and query against it later. reply smeej 9 hours agorootparentIf I&#x27;ve already run OCR on my PDFs and that&#x27;s added now as an invisible layer, would it work then?I&#x27;ve had a workflow digitizing my incoming paper documents, running OCR, and tagging them, all locally, and it would be great to have an easy front-end to talk to them. reply lhuser123 7 hours agorootparentprevI haven&#x27;t found an OCR tool reliable enough when it comes to scanned PDFs containing financial data where accuracy of amounts in the document is very important. reply catlifeonmars 5 hours agorootparentPeople spend an inordinate amount of time and money solving this problem rather than spending the same amount of money in lobbying and standardization efforts for financial institutions. I’ll throw this out there: when all you know is a hammer, everything looks like a nail. reply rolisz 4 hours agorootparentprevHave you tried Azure Document Intelligence? I&#x27;ve had very good results with it. reply mikeytown2 4 hours agoprevWhat LLM is best for giving it your entire code base and database structure and then using it to help with your project? reply oaththrowaway 2 hours agoparentMaybe Refact? They have a self hosted version that can index your repos. They have their own LLM or you can use others. Nice tooling for VS Code as well reply 10 hours agoprev[deleted] jart 9 hours agoprev [–] I&#x27;m not able to use this locally on Alpine Linux because ollama needs glibc. reply rolisz 4 hours agoparentCan you get it running using Cosmopolitan? :D reply yreg 8 hours agoparentprev [–] I&#x27;m not able to use this on TempleOS, please fix. reply jart 6 hours agorootparentYes but they claim it runs on Linux when it runs on Systemd. reply number6 4 hours agorootparentWhat you guys are referring to as Linux, is in fact, GNU&#x2F;Linux, or as I&#x27;ve recently taken to calling it, GNU plus Linux plus Systemd. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities, and vital system components comprising a full OS as defined by POSIX.Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called \"Linux\", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project, and now increasingly integrated with Systemd, the init system that brings everything together - or apart, depending on who you ask.There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine&#x27;s resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system and now, almost inseparably, with Systemd: the whole system is basically GNU with Linux and Systemd added, or GNU&#x2F;Linux&#x2F;Systemd. All the so-called \"Linux\" distributions are really distributions of GNU&#x2F;Linux&#x2F;Systemd reply suslik 9 minutes agorootparentCutting off \"I’d just like to interject for a moment\" from this pasta is herecy. reply testernews 7 hours agorootparentprev [–] this doesn’t work on Nix, pls fix reply stuzenz 1 hour agorootparent [–] I also use NixOS, but if the target was not NixOS, I don&#x27;t think you should be requesting the set up as needing fixing by the author. It just doesn&#x27;t sound right - or maybe it is just me. NixOS isn&#x27;t the defacto standard, and breaks the Linux FHS to achieve all the good stuff it does do.Either try to package it or use a docker image or maybe raise an issue noting the blocker and request it as a feature for some changes to give an easier path for to having it build more easily for NixOSApart from that, as expected, the docker image that is produced following the instructions is working fine with NixOS as host. All it needed for the build was the openssl packaged on the host. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SecureAI Tools is an open-source application layer for interacting with AI language models (LLMs) and OpenAI-compatible APIs.",
      "It currently offers two features: Chat-with-LLM and Chat-with-PDFs.",
      "The tool is designed for self-hosting and includes basic user management features."
    ],
    "commentSummary": [
      "SecureAI Tools has created an open-source application layer that serves as an alternative to ChatGPT and ChatPDF AI tools.",
      "The tool supports running locally hosted Language Model (LLMs) and is compatible with OpenAI APIs, offering features like Chat-with-LLM and Chat-with-PDFs.",
      "Users have inquired about the integration of the tool into Slack and its capability to handle scanned PDFs."
    ],
    "points": 166,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1702162927
  },
  {
    "id": 38584230,
    "title": "Amazon's Honesty Problem: Failed Refund on Undelivered Item Sparks Criticism, Prompts Legal Action and Credit Card Provider Change",
    "originLink": "https://www.bentasker.co.uk/posts/blog/opinion/amazon-parcel-contents-get-stolen-and-then-amazon-tries-to-keep-payment.html",
    "originBody": "Amazon Has An Honesty Issue Ben Tasker 2023-12-09 14:38 Amazon has been our retailer of first-resort for years: ordering on Amazon is quick, convenient and (on average) tends to have lower prices. Even our TV was originally bought via Amazon Prime. Over the course of that time, there's inevitably been the odd issue with ordered items, but they were all resolved quickly and easily via the customer-service text chat (although finding that chat can be a bit of a pain). Even as recently as a couple of months ago, if asked, I'd have said that it's generally been a fairly positive experience. In November, though, my opinion of Amazon changed pretty significantly. We experienced an issue with a high-value item not being delivered and, since that, have been left stuck in a state of financial limbo. Despite initially accepting that there was an issue with the delivery, Amazon have not issued a refund and have even contested credit card charge-backs. With the benefit of hindsight and a bit of searching online, it seems that this is something that others have been experiencing too, so I thought that it might be helpful to post about our experience (so far) as well as what I think that the underlying issues at Amazon actually are. Contents This has turned into quite a long post, although hopefully it's relatively easy to read through. All the same, for ease of navigation, here's a table of contents: Background Ordering and \"delivery\" Raising with Amazon Where's my refund? Chargeback Chargeback Failed Analysis Amazon Like Playing Dumb Advertising High*Value Packages Management Driven? Current Status The Future Closing Thoughts Background Ordering and \"delivery\" Before writing about the broader issues that I think Amazon have, I'll lay out the course of events: On Nov 1, I ordered an Xbox Series X bundle, along with an additional controller (and charging pack) for delivery the next day (because, you know, Amazon Prime) Two sets of packages were dispatched: the Xbox in one, the rest of the stuff in another Because it's a high value item, Amazon sent me an email noting that I needed to provide a one-time code to the driver on receipt The My Orders page suggested that everything would be delivered \"by\" 14:30 At about 14:15 the doorbell went. I was downstairs so only took a few seconds to get to the front door, just in time to see a white van speeding off There were several boxes (turns out my other half had also ordered some stuff), but no Xbox Given I hadn't been asked for a code, I figured the Xbox was going to be delivered separately so looked in My Orders again: nothing showed as having been delivered and the tracking showed the driver as being 9 stops away. Weird, but maybe he was out of coverage? About 18:30, whilst I was cooking dinner, the doorbell went again Stood in our (now dark) porch was a driver, with a package clearly visible next to him - he wanted a code before he'd hand the parcel over I provided the code, took the package and went back inside. I initially went back to cooking dinner (because leaving food to burn on the hob isn't a great idea), but then figured I should check the Xbox before stashing it ahead of Christmas (which was very lucky - otherwise I wouldn't have found any of this out until weeks later). When I opened the box though, I didn't find an Xbox, I found this: Clearly someone had nicked it and filled the box with crap to make up the weight! Personally, I felt (and still feel) that it was probably the driver - the way that the delivery of the other parcels had occurred was just plain weird. Drivers shooting off quickly isn't all that unusual, but this was fast even by their standards and the online tracking was way out . Looking in my inbox, the \"Your package has been delivered\" mails for those earlier parcels didn't arrive until 16:41. Normally they arrive more or less immediately after delivery: Is that the result of delays in Amazon's systems, or did the driver not mark them as delivered until later to give himself cover for the time spent swapping the parcel out? For those who are wondering, the driver requesting a code before handing over the parcel is consistent with the instructions that Amazon send to customers: Even if it occurred to the customer that they might need to, it's not possible to check the contents of the parcel first, because you have to give the code to even receive it. Raising with Amazon I hopped straight into the customer service chat, expecting that - like previous experiences - this would be dealt with reasonably easily. Amazon's customer service, though, really needed things spelling out for them. I got transferred 4 times, sometimes immediately after the previous transfer. Eventually though, I was told that Amazon needed a couple of days to investigate before they could replace or refund the item: Although I'd have liked a resolution there and then, a couple of days wasn't a huge ask. At the time, I (somewhat naively) took that as a sign that Amazon were actually interested in identifying and dealing with the thief. Unfortunately, a few days later, I'd heard nothing more from Amazon. I checked my access logs and found that no-one had even visited the link I'd provided for the photo of the box's contents. So, I hopped back onto their live-chat. This time, when I mentioned the photo, I was given a customer services email to send it to. A few minutes later, after the rep had checked my mail, they came back to me in the chat to confirm that they'd initiate a return I did have some concern about this though - that box was my evidence - I didn't want it returned only for Amazon to say \"your return didn't contain an Xbox\", so I asked explicitly if that was going to be an issue I didn't have much choice but to take a leap of faith and, after all, Amazon are a multi-national retailer who care about customer service and their reputation, right? My one remaining concern was how long it was going to take for the refund to come through - after all Christmas was approaching and I was currently short one (very expensive) present. Although a gift-card refund would be processed quicker, the timeline for refund to my card was reasonable. I didn't really want to buy the replacement from Amazon, after all, can you imagine the difficulties if the same thing happened a second time? The adviser triggered the return process and I received an email with a QR code to take to the post office along with the parcel. The next morning, the parcel was on its way back to the mothership. Upon dispatch, Royal mail provide a tracking code, so I can show that the package was delivered to Amazon on the 8th of November 2023. Where's my refund? A week later, I still hadn't received a refund, so I checked My Orders and saw that it hadn't yet been approved (but the interface suggested that it would be in the next few days). That date came and went and every time that I checked, the projected date slipped back until, eventually, the interface flipped over to claiming they hadn't received the return at all. It's since switched back to acknowledging receipt, but providing no estimation for the refund to be issued. So, back into the chat I went. At this point I was beyond frustrated, but it isn't right to abuse support staff, so I opened by explaining that I knew that it wasn't the advisers fault personally, but that I was absolutely furious with Amazon: it was 3 weeks since their delivery chain had stolen our item and I was still without refund, leaving me facing the prospect of having to settle a credit card bill containing something that I hadn't received. The adviser apologised but said that the refund needed to go through additional approvals and wouldn't be authorised until 6th December: Worse than that, the 6th wasn't even when we'd get the refund, just when it'd be processed. They still wanted 14 days after that for issuance of the refund So, just to put Amazon's proposed timeline into context: 01 Nov: order placed 01 Nov: money taken 02 Nov: box delivered 02 Nov: Amazon delay things 06 Nov: Return initiated 30 Nov: Credit card statement issued/paid 06 Dec: Refund to be approved 20 Dec: Refund to be paid In fact, the date of the 20th of December is actually me being being generous, because the adviser said 14 business days, so, in practice, we might not even have seen a refund this year. Put simply, following on from one of their staff stealing our purchase, Amazon wanted us to remain in a state of financial limbo for the better part of 2 months, spending Christmas wondering whether we'd ever see our money again. Chargeback As much as I wanted to tell Amazon to GFY, I instead politely explained to the adviser that the timeline was unacceptable and that I'd be contacting my credit card provider to invoke a chargeback under Section 75 of the Consumer Credit Act. I'd paid for the order using an American Express card, so I contacted them: Amex are fairly notorious for backing their customers, so I figured we'd be made right relatively quickly. I logged into Amex's portal and found that filing a dispute is really simple: Find the relevant transaction Click the Dispute payment link Fill out a multiple choice form Upload any evidence (I uploaded copies of my chat with Amazon etc) Once I'd submitted the dispute, Amex suspended the line item from my statement (so I wouldn't have to pay for something I hadn't received that month) and contacted Amazon to let them know the transaction had been disputed. Two days later, on 23 Nov, I received an email from Amazon, with the following: We are writing to let you know that the credit or debit card issuing bank has raised a dispute regarding the transaction below. To help us resolve this matter, please reply to this email and explain the reason for disputing this charge. You will find the transaction details below. I'm sure they could have looked up my chat history if I directed them to it, but at this point I was feeling a little cynical and decided that it'd be better to lay everything out again, allowing it to later be referred back to if the need arose. I sent Amazon a fairly concise email re-providing timelines as well as explaining that I'd filed a chargeback because Amazon's proposed timelines would have left me at a significant financial disadvantage over Christmas: The response that I received from Amazon later that day was short and to the point: We received your email. We are currently working with your card issuer to resolve this dispute. Card issuers usually resolve chargeback disputes within 30 days, but sometimes it can take longer. If you need more information or wish to cancel any disputes, please contact your card issuer. Although I was still feeling cynical, I took this to mean that Amazon would probably go back to Amex and accept the dispute apart from the £72.25 that I'd authorised them to take for the controller and battery pack. I heard nothing from either Amazon or Amex for nearly two weeks, but such was my trust in Amex's reputation that I felt quite comfortable popping out to a trustworthy retailer and collecting, in person, an Xbox Series X to ensure that we could give the intended present (I did, however, make that retailer open the box whilst we were still in store, just to be safe). Chargeback Failed On the 6th of December 2023 I received a snail-mail letter from Amex, which noted that: Amex were intending to re-apply the charge to my statement, putting me back on the hook to pay for an Xbox that I hadn't received. What possible evidence could Amazon have provided in order to prove delivery of an Xbox that hadn't been in the box? Essentially, they hadn't - they'd simply suggested that delivery to our address has always been fine before and that maybe I'd messed up somehow? It was astonishingly clear that Amazon's chargeback department either hadn't read my reply or had decided to ignore it. What really concerned me, though, was that American Express clearly hadn't read the provided information either. If they had, it would have taken them all of 3 seconds to realise that what Amazon had said was completely irrelevant to the dispute, not to mention that Amazon had accepted that there was an issue in the customer service chats. I picked up the phone, called Amex customer services and instructed them to re-open the dispute. I explained that it was obvious that they hadn't actually investigated, that Amazon's chargeback department had emailed me after the chargeback was raised and that their response to Amex wasn't consistent with either my reply or the complaint itself. As a result, I was asked to upload copies of the email chain with Amazon. At this point, I was really quite annoyed, so as well as uploading copies of the Amazon emails I uploaded a file called Attention_Amex.pdf containing a note to them explaining my displeasure at the closing of the dispute, pointing out why Amazon's response was obviously bunk and suggesting that they pull their finger out: Still annoyed, that night, I also emailed Jeff Bezos ('cos why not?) to ask if he was aware that his chargeback department seemed to be in the habit of misleading credit card providers. Which, brings us round to today. Currently, I'm still waiting to hear back from Amex on the chargeback or (if by some miracle it happens) from Bezos on having set his team straight. In the meantime, I've been preparing for the possibility of taking legal action because I am not paying for an Xbox that wasn't delivered. Analysis: The Real Problems Moving onto the analysis then. It'd be easy to think that the biggest problem is that things are getting nicked from within Amazon's supply chain. As we'll quickly explore, though, I think Amazon's problems are much more severe and run much more deeply than that. Amazon Like Playing Dumb When I first contacted Amazon's customer support, I had to lay out in no uncertain terms that the item had clearly been nicked by someone on Amazon's side. They were intent on treating it as a wrong-item received claim, which I didn't want: On the day, I was full of righteous indignation and ideally wanted the driver to be nailed to the nearest wall I was concerned that it being treated as a wrong-item return would lead to Amazon later trying to dispute the refund (don't I feel vindicated...) In my second chat with customer services, I didn't push so hard on the \"it's been nicked\" front because I'd reached the point that I just wanted my money back and it seemed to be the path of least resistance. The thing is, though, I should not have needed to explain it to Amazon's staff in the first place. I'm no particular fan of Chat-GPT but even Bing's chat can figure out what likely went on: It's not like this form of theft is even particularly new to Amazon, it's even previously been covered by large publications: Forbes: Amazon's one-time codes backfire on customers Which?: Amazon one-time passwords: customers report item thefts & parcels being switched Scamwatch: An Amazon Delivery driver tricked me and stole my parcel A quick search online shows that social media is awash with customers complaining of stuff being stolen and Amazon's subsequent reluctance to issue refunds. It follows, then, that Amazon cannot be unaware of the rot that exists within their own system, suggesting that they have consciously chosen to try and let customers carry the financial consequences of their corporate impotence. Anecdotal reports suggest that this year is particularly bad for thefts of Amazon parcels, with drivers reportedly even being so bold as to photograph packages on people's doorstep before stealing them. By not acting decisively to address the theft occurring within it's delivery organ, Amazon has fomented an environment where thieves believe that they can act with impunity. This billionaire-owned behemoth's sloping shoulders and general ineptitude leaves their customers suffering through no fault of their own. Advertising High-Value Packages Amazon presumably implemented one-time passwords out of concern that high value items were going missing (and, presumably, to address some incidence of consumer fraud). The problem is, those packages are now clearly marked as being of value - the need for a OTP screams to everyone in the delivery chain that \"this\" might be worth nicking. That could never end well in an environment where taking packages is seemingly almost risk free for logistics staff. I wouldn't be surprised, at all, if the introduction of OTP coincided with an increase in overall theft. I'm sure that Amazon will have statistics, but given their apparent reluctance to record occurrences of theft as such, I suspect that their numbers don't accurately reflect reality. Even if they do, there's still the risk that some level of management is focused only on one metric (a reduction in recorded incidences of consumer fraud) to the exclusion of all else. Management Driven? It's not unusual, when dealing with a company, to find that your experience differs a bit based on the customer service agent that you get - people in front-line roles tend to each have their own approach to exploring and resolving issues (those differences are what tends to make people good at their jobs). Reading about other's experiences with Amazon online, it's quite clear that Amazon would like us to believe that it's the customer service agents who are at fault. News stories often note that, when challenged by the media, Amazon explain that a customer service agent had misinformed you and has received further training. However, I don't believe that this is likely to truly be the case: My own interactions with their customer service teams do not support this contention: the staff did not come across as obstructive in the least and a return was even arranged - the holdup came when the refund had to be sent for approval. Amazon's chargeback department clearly have been, at best, obstructive. It seems unlikely that chargebacks are handled by frontline customer-service staff, being more of a finance function. It's abundantly clear from reports online that this issue is quite widespread. If a large number of customer service agents are, in fact, misinformed this would suggest that there's an issue with Amazon's training and/or internal policies - ergo, there's a systemic issue that Amazon is failing to address and is choosing to scapegoat agents instead (something that would be entirely consistent with our understanding of their attitude to employees). Personally, I consider it far more likely that someone within Amazon's management chain is trying to achieve an arbitrary set of figures or targets. They're pushing for this, at all costs, with the result that customer welfare and what's right isn't considered at all. Putting it bluntly, I'm not sure whether Amazon have considered a move into agriculture, but I'd say they're quite adept at shovelling a certain something. The Current Situation At time of writing, my case is still unresolved - sooner or later I'll get a letter from American Express detailing their conclusions and will have to take it from there. About the time that I emailed Bezos (who, obviously, was busy with more important things), I realised that I'd started using the word \"contempt\" in relation to the way that Amazon had been treating us. It turns out that I'm not alone and the word \"contempt\" turns up elsewhere: Amazon shows ‘contempt’ for UK law over parcel thefts. Now, Amazon haven't asked me for a crime number and if they did, I'd argue that it's not actually on me to acquire one in the first place: the Xbox was not stolen from me, it was stolen from Amazon. The criminal action was against the retailer and my dispute is entirely civil: Amazon have not fulfilled their side of the contract by delivering the Xbox that I paid for. I am extremely privileged in that I'm not relying on that money for food and heat. That doesn't make Amazon's behaviour any less contemptible though: I could equally well be a single-parent who'd saved all year for a special present and was now facing the choice of a present-less Christmas, or having to sacrifice something else to free up money to purchase a replacement Xbox. The fact that Amazon could equally be doing, or do, the same to someone who is in that position was a big motivator in writing this post. Whilst I am very fortunate not to be in that position, it doesn't make me immune from stress and certainly doesn't make me any less annoyed. The pack of johnnies that Ross is holding are a little more pertinent than you might think: I've never been afraid to stand on principle and, given the opportunity, I'd be more than happy to f..k Amazon's day up as much as possible. Unfortunately, however, that's not quite how all of this works. I made the purchase with a credit card and, as a result, the law holds that my contract is with American Express and not Amazon. It's American Express who have the legal duty to make me whole. So, if this does get to the point that I need to start legal action (and, I absolutely will), Amex are the unfortunate middle-man who will end up taking Amazon's well-deserved breach-of-contract kicking. Of course, at time of writing, American Express aren't entirely without fault themselves. I'm hugely disappointed at their handling of the chargeback so far: They were supposed to be one of the good credit-card providers but, presumably, have made cutbacks, with levels of customer service suffering as a result. The Future I don't know exactly what the future holds for this case, other than that I've every intention of fighting harder than a honey-badger with a sore-head. Beyond that though, the rules of the future are relatively straightforward Never buy anything of any meaningful value (if anything at all) from Amazon ever again Assume that Amazon absolutely do not act in good faith, do not give them the benefit of any trust If something does turn up needing an OTP, refuse the delivery and repurchase elsewhere If we reach the point of legal action, I suspect that I'll also need to look for a new credit card provider - I can't imagine that Amex won't respond by disinviting me from using their services. Closing Thoughts Amazon's handling of the case aggrieves me far more than the initial theft does. In a supply chain the size of Amazon it's inevitable that there are sometimes going to be some bad apples. As with all things customer facing, the bit that matters is not the initial incident so much as how you respond to it. Clearly, Amazon have utterly failed in that respect. Until the response to the chargeback came through, I was quite willing to give Amazon the benefit of Hanlon's Razor (Never attribute to malice that which is adequately explained by stupidity). However, with the response that they sent to Amex, it became hard not to conclude that any signs of ineptitude are not, in fact, deliberate. I'm disappointed in Amex's initial handling of the chargeback, but if I were being generous, I'd say that a significant part of the problem is their web portal over-simplifying the process. It's very easy to file a chargeback, but it's all done with multiple choice answers: there is no means to provide context or detail other than uploading files of evidence. I suspect that what's happened, is that Amex have seen the \"Item not received\" selection in the multiple choice and followed a script without reviewing any of the rest of the dispute. It doesn't excuse it, but if the root of it is bad UI, then there is hope that Amex could fix things for future customers. Casual readers of my site may have noticed, by now, that I've gone to some lengths to avoid my usual... uh... application of language in this post: I wanted to make sure that the post could get past corporate web filters, hopefully one day even being seen within Amazon itself. However, it would be remiss of me not to also honestly communicate my current feelings towards the relevant levels of Amazon's management, which I shall do via the medium of meme: I'd also suggest turning it sideways and repeating. As a closing note, if you do find that you are affected by similar then please, please, try not to take it out on the front-line staff: it's not their fault that they work for a shower of morally corrupt nobs. amazon amex analysis blog consumer rights opinion Previous post Mentions Click to display comments",
    "commentLink": "https://news.ycombinator.com/item?id=38584230",
    "commentBody": "Amazon Has an Honesty IssueHacker NewspastloginAmazon Has an Honesty Issue (bentasker.co.uk) 163 points by _Microft 15 hours ago| hidepastfavorite130 comments iamcalledrob 14 hours agoAmazon (US) has really gone downhill in the past ~5 years.I signed up for Prime a over decade ago because of the reliable 2 day shipping. It worked pretty much as described. It was great.Shipping is no longer 2 days on most items - \"Prime\" shipping can now take 7 days. Amazon advertise same or next day shipping, but it&#x27;s really only for big ticket, occasional purchase items. Most everyday purchases now take 3-7 days, the same as without prime. They show the prime badge, but if you log out you can see that non-prime members get the same shipping.This feels really dishonest. Amazon pretend that you get huge shipping benefits from Prime, but it turns out you don&#x27;t anymore.For the first time, I&#x27;ve cancelled my prime renewal. What, exactly, am I paying for these days? Walmart offer next-day free shipping on the big ticket items too, without the membership. reply flir 11 minutes agoparentI signed up for Prime when it was just shipping, and it was a great deal that made the platform sticky - I always looked there first. When they bundled in all the other Prime functionality and upped the price it left a very bad taste in the mouth.And yet, here I am, years later, still with a Prime account. I really need to make more of an effort to get off Amazon.Maybe after Christmas... reply ohdannyboy 14 hours agoparentprevMaybe it varies by location because in Chicago it&#x27;s extremely rare for things to take more than 2 days. In fact they&#x27;ve been stepping up next and same day delivery for a lot of items.That being said, I&#x27;m actually moving in the opposite direction since that creates a lot of waste. Unless I really need the item quickly I use Prime Day delivery so it all comes in one box. If my whole family didn&#x27;t share the account I wouldn&#x27;t pay for Prime. reply Gorbzel 14 hours agorootparentThe theft problem doesn’t vary at all in Chicago. I’m in a North (west) Side neighborhood and receive about 83% of Amazon packages, with the rest being stolen or just not delivered. Compare this with a 100% success rate for items delivered by UPS, USPS, or FedEx.I figure at some point I’ll fall below whatever metrics Amazon has internally, they’ll stop resending&#x2F;refunding packages, and I’ll have to fight the same battle as in the article. If anything, OP unfortunately&#x2F;correctly teaches that empathy, common sense, and treating level 1 workers as human have no place with Bezos…you have to assume the worst and treat everything as a cost&#x2F;blame situation. reply ohdannyboy 10 hours agorootparentI live in a high-rise which has a mail room so maybe I&#x27;m insulated from whatever factors lead to that (porch piracy obviously, but something about Amazon specifically). I didn&#x27;t realize it was that bad, only getting 83% is insaneEdit: though my family in Rogers Park and the suburbs have never complained about this issue so I&#x27;m not sure it&#x27;s that common. reply aylons 3 hours agorootparentI live in a single-family unit in Uptown and would be surprised if my rate is anywhere below 95%, I&#x27;d be shocked and demand a recount. I order several times a week, often several times a day (yeah, a lot of items I need are same-day delivery, most are next-day), and I recall two or three packages missing this year. And those were likely never delivered of to the wrong address, as they had no picture. reply cafard 8 hours agorootparentprevI live in Washington, DC. Two or three times a week on the neighborhood listserv there is an email asking whether anyone got the sender&#x27;s package. Some of the problem is certainly theft, but I doubt all of it is. reply crazygringo 14 hours agoparentprevThat&#x27;s not my experience at all.Shipping is 1-2 days for nearly everything that is sold&#x2F;shipped by Amazon, in my experience. Occasionally it&#x27;s a day late.The idea that most shipping takes 3-7 days isn&#x27;t my experience at all. Maybe you live somewhere more inaccessible?I always thought paying for Prime was about free shipping on small items anyways, not about faster speed. reply aaomidi 14 hours agorootparentTo be fair, Amazon did have 2 day shipping to anywhere in the 48 states. That promise has now been removed.If you’re in a metro area you’ll still have it. reply QuantumGood 12 hours agorootparentYeah, have to be in the service area of an Amazon warehouse. If you are, it&#x27;s great. reply THENATHE 14 hours agoparentprevI literally never experience this issue. Except for a couple of actually lost packages, my prime has had EVERY package come in 2 days or less except holidays. I live in a 250k town tho, so I am not sure if there is some level of size that plays into it. Perhaps I am the perfect size to have enough infrastructure to get reliable deliveries, but small enough that I don&#x27;t have to worry about all that comes with a massive city. reply bragr 14 hours agoparentprevCurious about where you live. How far are you from a major Amazon shipping hub? Here in the broader LA area, it is mostly all next day, and even same day shipping. It&#x27;s all Amazon&#x27;s in house delivery service too. reply iamcalledrob 14 hours agorootparentOne of the biggest cities in the US.The shipping ETA problem seems to be very hit-or-miss. I&#x27;ve spent more time than I&#x27;d like to admit sifting through pages of \"prime\" results trying to find something that can arrive sooner than 3-7 days out.And then sometimes every search result shows same&#x2F;next day--but you absolutely can&#x27;t rely on it because the packages have a ~50% chance of \"running late\" and get assigned a new ETA of what the non-prime shipping would have been. For order after order. reply SkyPuncher 14 hours agoparentprevWe cancelled prime this year. I was surprised that shipping cost and timeframes haven’t changed. In fact, on many items it seems like it’s faster to not use prime. reply barake 14 hours agorootparentWe&#x27;ve had the same experience. Prime shipments were 5-7 days regardless of order size, now most items show up in 1-2 days.Not sure the logic in that. reply upon_drumhead 14 hours agorootparentIf you&#x27;re getting FBA, it&#x27;s just an optimization of throughput. If there&#x27;s enough folks in your area with Prime, trucks are going around your neighborhood daily anyway, so it&#x27;s better to send a full truck, even if it means things get there early, then to send a partially empty truck twice. reply bonton89 13 hours agorootparentprevAmazon likely does not have separate Prime and Non-Prime lanes in their warehouses. It would be a redundancy and add additional complexity that would increase costs&#x2F;reduce profits. Since customers never see the warehouse there really wouldn&#x27;t be any benefit to doing this. reply eastbound 13 hours agorootparentprevAre we in the game where an event happens randomly, and we’re trying to guess whether any of our actions, if not worshipping Bezos directly, might have an effect on delivery times? reply araes 13 hours agorootparentThere&#x27;s a lot of existence that really feels like we just live in a hash code now. And its all malevolent for some reason. It feels like there&#x27;s \"supposed\" to be something you did wrong, yet it&#x27;s all malevolent hash randomness. Maybe all the focus on cryto money?That, or we&#x27;re being experimented on. \"What will the mice do if we poke them this way? The ants really hate it when we shake them this way.\" reply phil21 12 hours agoparentprevIt&#x27;s very location dependent. Where I live most stuff beats the 2 day estimate and it&#x27;s not unheard of to order something in the afternoon and have it at the front door when I get back from dinner.Friends in other locations seem to have more of your experiences. I actually dread ordering from anyone but Amazon since the shipping is such a crapshoot for usually the same money. reply shepherdjerred 14 hours agoparentprevWhat I dislike the most is how unreliable \"Amazon Day Delivery\" is.Several times I&#x27;ve bought something that I don&#x27;t need that week, so I chose Amazon Day delivery, which allows all of my packages get delivered during the same day the next week.I expected those packages to arrive, e.g. buying something for a gathering I&#x27;m hosting that weekend, but they are often days late and don&#x27;t arrive in time.Amazon was great for a few years, but it looks like something happened. They still claim they are customer obsessed and \"Day 1\" thinkers, but anyone can see the delusion. I wonder if Jeff Bezos sees that Amazon has gotten worse; it seemed like he truly believed in the company until his departure a few years ago, but maybe it was always just about the money. reply xkekjrktllss 14 hours agorootparentOh no! It&#x27;s almost as if Karl Marx and Adam Smith were exactly right about the tendency of the rate of profit to decline!And it&#x27;s almost as if startup culture is not a benevolent savior but just more bourgeoise propaganda bullshit!https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tendency_of_the_rate_of_prof... reply shepherdjerred 14 hours agorootparentWhat do you think the answer is?I&#x27;m not familiar with this, but it certainly does seem like the startup world is completely backwards, and anything VC funded should be considered toxic. reply xkekjrktllss 14 hours agorootparentSocialism, which is to say something that has never even remotely existed and cannot yet be described or even conceived, but is so important that we must continue to try to figure out.Capitalism is unsustainable and so will not sustain. The question is what will replace it. reply bsuvc 13 hours agoparentprevHmm. My experience with prime shipping is exactly the opposite, but I think I must live near a distribution center.In fact, just yesterday I ordered some vitamins for overnight delivery and they actually showed up in 3 hours, so sooner than promised.That has happened on several occasions, and I can&#x27;t recall every not getting something on time.That&#x27;s shipping.But I do think Amazon has a serious problem with fake, incentivized reviews, and I have heard of, but not yet experienced (to my knowledge) counterfeit products. reply losteric 14 hours agoparentprevI suspect you live in an area of lower Amazon customer density? I regularly still buy and receive items sameb-day. reply blagie 14 hours agoparentprevNot ≈5 years. Three years and 9 months. Amazon&#x27;s retail division was broken by Covid and will probably never fix itself.I have no inside knowledge, but I suspect what happened is a bunch of crooks were hired during the massive hiring spree to keep up with Covid demand, and there wasn&#x27;t capacity to investigate every fraud, theft, and scam. Internal fraud went from zero to prolific almost overnight. Prime also stopped being able to deliver in two days, and never recovered.It&#x27;s been three years, and it seems a permanent culture change at this point. The only CEOs I&#x27;ve seen recover a business from this sort of shitshow were Steve Jobs and Satya Nadella. Most businesses can&#x27;t recover from this. I hope Amazon can, but realistically, I&#x27;m very sceptical.On the upside, there&#x27;s a huge opening for a competitor, if anyone wants to do a startup :) reply eastbound 13 hours agorootparentI was despairing that those big internet companies were settled for 80 years, but I see that there might be movement.However, it takes 25 years and unprecedented investment to build Amazon, warehouses, delivery schemes… Unless Amazon sells some of them with the automation, it’s extremely hard to enter the field. reply blagie 11 hours agorootparentI actually don&#x27;t think so. A few points:(1) We are in an era of massive investments, much more so than when Amazon started. The billion dollar plus fundraising round is increasingly common over time.(2) An entrant does not need to operate the same as Amazon. The sharing economy provides a lot of alternative models. To give a fictitious example, connecting with existing rideshare vendors for delivery and a network of local stores for fulfilment could give a lot of the same product without the same investment. Ditto for existing logistics players like FedEx (who do a lot more than delivery).(3) It&#x27;s possible to start in different markets, and especially foreign markets. A company which could do this play easily might be something like Aliexpress which already has a leg in.There are many more models possible too, but the point is that building Amazon today does not need to the same as building Amazon in the nineties. Even building the same Amazon would be cheaper today, since we can learn the lessons of the existing Amazon. reply noncoml 14 hours agoparentprevWhat’s dishonest is that they say the 2-day applies only after they ship the item, but they don’t count their “internal logistics” shipping in this time.How do I know that? Amazin charges your card only when they actually pack and ship the item. But the tracking on UPS will not appear until 3-4 days laterAnother annoying thing about Amazon is the subscribe and save. They see it as one way contract. Many times I have subscribed to a product only to get a notification when it’s fulfillment time that was saying that the product was out of stock and I should choose a replacement.That’s not how it is supposed to work Amazon. I take up the obligation to buy a product monthly and you should take the obligation to make sure it’s available.It ended up being death by a thousand cuts for me and Amazon. I barely use it anymore reply FireBeyond 9 hours agoparentprev> Amazon advertise same or next day shippingWhat&#x27;s more is if you filter for \"arrives tomorrow\" you&#x27;ll get a bunch of results, but there&#x27;s no guarantee they will arrive tomorrow - you have to double and triple check at every step of the order flow. reply himinlomax 14 hours agoparentprevIn Paris I get next day delivery on most items. reply PaulDavisThe1st 14 hours agoparentprevI live in rural new mexico. When we moved here 5 years ago, even the most available item shipped using Prime would take 3-5 days to arrive (and more typically 5). Over the last year, that has shifted to the point where some items arrive next day and nothing takes more than 2 days.I would not generalize from my experience. I would suggest that you do not generalize from yours. reply anonymouskimmer 14 hours agoprev> On the day, I was full of righteous indignation and ideally wanted the driver to be nailed to the nearest wallThe guy keeps on making this out to be the driver&#x27;s fault, when only circumstantial evidence points to that. Everytime he was mentioning reasons to think it was the driver I, as a person who has worked in shipping and delivery as a hoi polloi, thought of reasonable reasons why the driver would act that way.- The driver probably isn&#x27;t even there when his van is loaded, so easy for a package handler to swap things out.- A package with mandatory code instructions may have been in another part of the van, and could have been missed the first go-around by a busy driver. (edit: assuming it wasn&#x27;t loaded into another van entirely.)- Online tracking being off happens all of the time. reply inopinatus 13 hours agoparentThe author is a case study in sloppy thinking. Sure, they were wronged; they are certainly a victim here. But property was stolen and the retailer is negligently complicit in the theft. When this happens, you call the police, and your insurance company. reply anonymouskimmer 13 hours agorootparentI agree in general, but I think he&#x27;s right in claiming that this isn&#x27;t a criminal matter on his end, as the console was technically stolen from Amazon prior to delivery, not from him after delivery. What he&#x27;s doing with Amazon customer service and Amex are the pertinent things from his end. reply inopinatus 13 hours agorootparentThe point at which Amazon denies this is the moment where they became negligently complicit. reply anonymouskimmer 13 hours agorootparentStill a civil matter instead of a criminal matter. Amazon has the lawful right to both protect their interests and perform their process of refund (whatever errors and pauses they may make during this process). As such the state of mind necessary for criminal complicity has yet to be shown. reply inopinatus 12 hours agorootparentSo what? You&#x27;re not personally responsible for prosecuting Amazon. For that matter, neither are the cops. This tunnel-vision mode of thinking is how people talk themselves out of calling the police and the insurance company. The claims unit will want a police report number to start their process, and the fact both are now involved will exert direct pressure. So do it. The point is to be maximally assertive of any rights you have or may have, not playing legal billiards and negotiating against yourself in your head. reply anonymouskimmer 12 hours agorootparentYou&#x27;re just asking to waste your own time, and theirs, with that approach.The police department will ask whether it was stolen from your porch. No? It was stolen from Amazon? Not a crime against you.The insurance company will ask when it was switched. Switched before delivery? Not on us. We don&#x27;t insure for that, only for what happens on your premises. reply inopinatus 11 hours agorootparentThis is still the bizarre but all-too-common line of thinking in which someone talks themselves out of marshalling available resources. It’s negotiating against yourself, and a recipe for failing at life. reply anonymouskimmer 11 hours agorootparentWhen you know before hand that it will 100% just waste time, then the value is in not making you and others more aggrieved and annoyed. reply inopinatus 11 hours agorootparentSince I have over the decades made several insurance claims that were paid out, I feel qualified to say that is a sack of lies, and the OP has exacerbated their aggravation and annoyance by failing to contact the police and their insurance company.Instead of asserting their rights, they’ve allowed themselves to be subordinate to Amazon and Amex corporate internal processes. I struggle not to label that as vassal thinking. reply anonymouskimmer 11 hours agorootparent> they’ve allowed themselves to be subordinate to Amazon and Amex corporate internal processesNo, he&#x27;s told Amex that he will take legal action against them under section 75 if they do not fulfill their obligations.> Since I have over the decades made several insurance claims that were paid outBy which kind of insurance and for what? It&#x27;s important to note that for this transaction Amex is the primary insurance company (providing purchase insurance for things bought with it). Why would homeowners insurance provide coverage?> I feel qualified to say that is a sack of liesProve it then.Are you from the UK? I&#x27;m not. reply rutierut 14 hours agoprevI cannot think of a _single_ low-margin global corporation that can get away with it that hasn’t made the trade-off where they accept some of their customers will be treated horribly in order to save _a lot_ of money.I’ve currently got a DHL package in limbo that’s worth about the same and the main function of their customer service department seems to be to indicate that trying to consume customer service resources is not going to help you. Employees will give you completely contradictory and verifiably incorrect information. reply blagie 14 hours agoparentI don&#x27;t think this saves Amazon money. They have a huge problem with internal, for lack of a better word, corruptions.* Packing people who don&#x27;t care if high-value items are broken* Delivery people who fake deliveries and steal* Co-mingling of fake items with sellers... and so on.Because the delivery person wasn&#x27;t investigated, they&#x27;ll steal again and again, and that will spread to others in Amazon culture. Good companies do investigate issues like this one, and keep the business clean. Once a culture of theft creeps in, it&#x27;s a lot harder to fix, and it oozes $$$ at a crazy rate.This costs them a massive amount of money. My guess is there is no one in the corporate hierarchy who cares enough about their employer to fix it (everyone I&#x27;ve met who works for Amazon is a disgruntled employee).There is a slight bit of short-term savings, but around two years back, I stopped ordering anything from Amazon which might be subject to fraud or safety issues (e.g. high-cost items, food, medicine, SD cards, SSDs, brand-name clothing items, etc.). This year, I cancelled Prime. There&#x27;s just too much fraud going on.I can&#x27;t imagine Amazon is saving money when XBoxes and similar items get stolen, and I can&#x27;t imagine long-term success if they&#x27;re bleeding customers and brand value.If AWS wasn&#x27;t tied to the retail division, I&#x27;d be shorting Amazon retail right now. reply cjaybo 13 hours agorootparentYou posted the same theory above, except there you included the important disclaimer that you have no inside information — is this just a hunch that you have? Because it seems like a Hanlon’s razor type of situation to me. Without some sort of evidence of the fraud you speak of, it seems far more likely to be them simply struggling with challenges of scale. Every business deals with bad employees but the majority of people with jobs tend to want to keep their job. It’s hard for me to imagine that fraud is the dominating cause here. reply kmeisthax 8 hours agorootparentAmazon systematically underpays all their employees. They do this by encouraging employee churn, like to the point where warehouses occasionally realize \"shit, we&#x27;re running out of new people to hire in the entire metro area\". This means they have a high tolerance for a lot of things that would be considered disqualifying. For example, in a lot of workplaces, random drug testing is mandated by insurance, which means people who smoke weed are unemployable. Amazon will hire them anyway[0].That&#x27;s not to say Amazon has no limits - they do background-check for felony convictions, and having one would make it harder to get hired by an Amazon warehouse. However, they&#x27;ve still built a hiring system that optimizes for hiring the precariat[1] and underpaying them so they stay precarious. They&#x27;ve built all the economic incentives for them to be stolen from. We don&#x27;t necessarily need to prove specific allegations of theft in the same way we don&#x27;t need to prove that specific cracks in the road are caused by water getting in and freezing.[0] For the record, this is a good thing, but Amazon is doing it for incredibly terrible reasons.[1] The class of people in permanent precarity - i.e. people who you can get to do anything, including run a marathon across a poorly-organized warehouse filling boxes for eight hours for little pay. reply blagie 11 hours agorootparentprevNo, I posted a much more specific theory above with a disclaimer.Here, none was necessary, since I wasn&#x27;t going out on a limb. I also do know enough people who work at Amazon to know that many of their SWEs despise their employer. Reporting (in newspapers) about warehouses is horrific. That strongly supports that Amazon is not tending towards the happy end of the \"employees acting in employer best interest\" curve. My own experience, my friends, and anecdotally on posts like this, has been very negative about the honesty and customer service from Amazon starting around 2020.Now:Corporate corruption is complex.To give an extreme example, if one is at an Enron, one keeps their job by keeping their mouths shut and participating in the fraud. It&#x27;s the likely whistleblowers who get fired.This is not at all uncommon in organizations. It&#x27;s a stereotype that working too hard at some union shops is not good for one&#x27;s long-term job prospects.One step down from that is employees who don&#x27;t care about their employer. They want to keep their job, have decent salary, future options, work-life balance, and enjoy work as much as possible. If an employer doesn&#x27;t fire people who don&#x27;t work, no one works. If an employer has no means to check if items are correctly packed, very quickly no items are correctly packed. This is not uncommon at the CEO level either (at least for external CEOs), who mostly want to pump up short-term profits to get bonuses and prepare for their next gig.Acting in corporate interest is only occasionally correlated with keeping ones job. In general, you need to keep your stakeholders happy (probably your boss), and the extent to which that correlates with business success is... mixed.This impacts a majority of large businesses.At scale of over ≈20-1000 people, organizations are dominated by incentive structures and dynamics you can model with game theory (ref: Bruce Bueno de Mesquita). The hypothetical business where everyone is aligned is, well, almost hypothetical beyond some scale.It&#x27;s not uncommon that in a large organization, zero people care about that organization. If there&#x27;s a problem, no one fixes it. It survives in the free market simply because their competitors are no better (and how well large businesses manage this largely determines their success). reply oooyay 13 hours agoprevThis isn&#x27;t just an Amazon problem. I requested a refund from Expedia because their search listed a hotel from another state with a city by the same name when I made a specific city & state search. Their search functionality clearly had a bug and we reserved a hotel in the wrong city. Upon realizing this an hour later we phoned Expedia who told us to phone the hotel; when we talked to the hotel the person that answered said only a manager could refund my purchase and to call in the morning. When I called in the morning the manager told me they held the room for me so I had to pay for it anyway. I realized that I had been gaslit, willingly, but the people who worked there. I talked to Expedia who offered me a partial refund, which I refused. I called my credit card company and they filed a dispute, eventually citing that I&#x27;d had several successful bookings with Expedia before (totally unrelated to my case).To me, the issue is that credit card companies no longer exist to protect and defend consumers the way they used to. They&#x27;re deep in the pockets of vendors, massaging their backs for a kick of the churn. There&#x27;s room here for a very heavy handed, national agency in each country that makes these companies lives hell when they lie or drag their feet. reply phil21 12 hours agoparentThe problem is chargeback fraud has become rampant since COVID, at least from friends stories in the payments and retail spaces.The word got out you can just call your bank and they will back you very few questions asked. This was abused by many, and now it&#x27;s no longer a sure thing. Anything outside of outright fraud is very much a coin flip likely depending on how profitable you are to the issuing bank. reply oooyay 12 hours agorootparentI&#x27;m sympathetic having worked in anti-fraud adjacent fields before, but this extreme pendulum swing - if that&#x27;s what this indeed is - is at least inappropriate and at worst nefarious. All of my transactions go through this card; they owe me to represent me well when I&#x27;m a customer like that. When they fail to, someone needs to deliver some ire with sticking power. Same way that there&#x27;s ire that can be felt by a consumer facing charges of fraud. reply johngossman 14 hours agoprevFwiw...this reminded me I had a package ($90) not show up this week. I used their completely automated system and got refunded in 5 minutes. Message even says \"if you find the package you can keep it.\"I think you need a lot of examples to draw any conclusions and self-reporting is going to be almost entirely negative experiences. reply shepherdjerred 14 hours agoparentI&#x27;ll share my anecdote: a few weeks ago I ordered hooks for hanging up lights ($25). The package was marked as delivered, but nowhere to be seen. I don&#x27;t have a problem with package theft, so my guess is that it was delivered to the wrong address or something.I went to Amazon&#x27;s site and tried to report the issue, but, at least for that item, there was no automated way to report a package as \"not delivered\". reply johngossman 14 hours agorootparentGood point. There was a very non-obvious \"Get Help\" button which led to a non-obvious \"Get More Help\" link which led to a \"Call me\" button. But they called instantly once I got there reply wahnfrieden 14 hours agorootparentprevIt’s there they just trick you. Don’t go looking for the option starting from your order details. Instead start from the general support chat and say the automated response didn’t help you and you need more help. reply ksec 14 hours agoparentprevUnfortunately a lot of these benefits ( So to speak if you do received the package ) are never really being told publicly.One of thing that most on people on the planet, including those on HN dont realise is just how hard logistics are in real world. reply happytoexplain 13 hours agoparentprevThis is a result of their lax quality (flooded with ad hoc businesses selling garbage, counterfeits, inaccurate listings, etc). When you go that route and you&#x27;re the size of Amazon, it actually makes more sense to completely side-step having to deal with the flood of customers unhappy with all these problems. Just give them their money back. Don&#x27;t even bother trying to get the product back if it&#x27;s missing. As a bonus, you get an image boost. It&#x27;s more efficient than having a process to case-by-case deal with the results of their completely abandoning quality&#x2F;trust at the point of sale. reply EA-3167 14 hours agoparentprevThey have some real upsides, the Amazon return policy being one of them. They also have a huge problem with counterfeits, abusive resellers, rigged voting and so on.The existence of their best point doesn&#x27;t obviate the existence of the sort of behavior that should lead to sanction, regulation, and reform. reply gnicholas 13 hours agoparentprevI have had some amazing experiences with Amazon CS, but mostly meh ones. Usually I have to spend 10-20 mins sorting out an issue that was not my fault (package never arrived, return never arrived at their warehouse after I dropped it at UPS), and at most they give a $5 credit for the trouble.But then there was one time where I literally got hundreds of dollars in refunds for a screw up on their end. I didn’t even ask for it — their guy volunteered it and I couldn’t believe he was serious. But he was: he refunded me for a dozen or so purchases to make up for one (expensive) item that was delayed past a birthday that it was supposed to be for. I got the item for free, and then some. reply blibble 8 hours agoparentprevif you hit a situation where the automated system handles your case then you&#x27;re fineif not, you are screwed, because the customer support is worse than useless, it&#x27;s infuriating reply neilv 13 hours agoprev> and have even contested credit card charge-backs.Personally, I&#x27;d never do a CC chargeback against certain companies. Too much risk of being cut off from a crucial vendor by a \"customers who do chargebacks aren&#x27;t worth the trouble\" automation&#x2F;SOP.(For household consumer issues... if customer service was exhausted, I&#x27;d escalate to the CEO&#x27;s office \"?\" email address, and if even that didn&#x27;t work, but I really needed it solved, I&#x27;d consult a lawyer about whether they could negotiate a solution with a letter or phone call.) reply tester756 11 hours agoparentHow they can cut you off?Aren&#x27;t there various payment methods? reply josephcsible 8 hours agorootparentThey don&#x27;t just blacklist the credit card number you used, but also your name, address, email, and phone number. And it wouldn&#x27;t surprise me if they also had some heuristic involving IPs, cookies, and device fingerprinting. reply not_your_vase 14 hours agoprevThis reads more like a rant unfortunately. While I agree with the closing statements, I think you realized it too late. You already made Amazon an almost undestroyable behemoth with the previous 83 purchases of yours (sure, you didn&#x27;t do it alone. But your patronage was essential while it lasted). You can&#x27;t really make that not-happened, it&#x27;s late for that.On a different note, it is not Amazon&#x27;s interest to scam you. But unfortunately it is one rando&#x27;s word (yours) against another rando&#x27;s word (the driver, or whoever), without a lot of proof that could be sent to the police. reply dboreham 14 hours agoprevAmazon code that renders tracking seems obviously broken in places. They shipped a thing to me (MT) from NY, and the post office mistakenly routed it to Puerto Rico. At some point in this saga the Amazon order tracking page went from \"it&#x27;s running late and if it isn&#x27;t there tomorrow you can get a refund\" to \"likely it was delivered on or around Dec 1 and you can&#x27;t get a refund\". Meanwhile the tracking (number copied from that same page) shows it meandering around FL on its way back from its Carribean vacation. reply bragr 14 hours agoparentYou can probably still get a refund if you open the support chat, experience of the blog writer not withstanding. They always have more options than the shipping page will give you. reply stoorafa 14 hours agoprevAmazon took something like 30 days to deliver me an iPad (Pro, so $900) that was supposed to be “Prime” delivered.I asked them to cancel the order after seven days, and repeatedly asked them to cancel, but they wouldn’t.They seem to follow the old Ferengi adage of “Once you have their money, you never give it back”Edit: I returned it for a refund, but was out a decent amount do money for a while. reply r00fus 14 hours agoparentI simply refuse to buy high value items from Amazon these days. Especially Apple products.In fact I tend to buy most goods via local same-day delivery or pickup. reply kibwen 13 hours agorootparentI don&#x27;t dare buy technology from Amazon, the commingling of products from random sources means the risk of counterfeits is just too high. Micro Center or Best Buy would have to be actively malicious for something like that to happen, while Amazon can just be passively malicious and say \"system working as designed, wontfix\". reply gnicholas 13 hours agoparentprevWere they the shipper or seller? I can understand them saying they can’t cancel the order midstream, but once it’s been over a week from the order time, they can’t exactly stand by that default rule. You can’t take someone’s money and leave them with nothing for a month. reply AlotOfReading 13 hours agorootparentAmazon and Apple have had an agreement since ~2018 that limits third party sellers of Apple products on the platform in return for Amazon having access to new devices on the market. It&#x27;s very likely that the seller was Apple directly and the device already in the warehouse. reply blibble 14 hours agoprevamazon has become total unadulterated garbageI ordered a present last year, it was \"delivered\" to the side of my house when I was outI found it a few days later, completely ruined by the winter weatherI explained to what they call customer service that their delivery had ruined it, they said send it back, which I didfew days later they&#x27;re blaming me for returning damaged goods and trying to charge me for the damageI contacted jeff@ too and the \"executive support\" were just as bad as the idiots on the websiteI had an account for 20 years, now closed and I now happily pay more not to use amazon reply blagie 14 hours agoparentYou pay less. I did the math on other sellers versus Amazon, factoring in cost of dealing with fraud@Amazon. Paying a little bit more sticker is much cheaper than getting cheated once in a while. reply iamleppert 13 hours agoprevAlways film yourself opening high value packages. For the author, it really boils down to circumstantial evidence. A photo of a box not containing the item isn’t proof of anything.I’d even go further and make sure there’s uninterrupted video evidence showing delivery and opening of the package. Open them on your front porch in view of your doorbell camera.If you’re a victim of a fraud like this, first make a police report of the theft. Then contact the merchant. If you aren’t given a refund or replacement within the same time period of the original delivery, start the dispute process with your bank. If that fails, take the matter to small claims court against the original merchant. This is where you can take your evidence to someone who is local and who doesn’t work for the merchant. They don’t care about whatever terms of service, procedures of the company and operate under the law.Most of the time the company won’t even show up and if they do it likely will be one of their juniors from their legal staff.As long as you have evidence and a police report, you’ll get a judgement in your favor. Once you get the judgement, if still within 90 days of the purchase, send it to your bank to have the chargeback redone.If not within 90 days, you will need to collect from the merchant themselves. Send a copy of the judgement and a demand letter certified mail to the merchant. You need to check your local laws on how long they have to pay it.If they don’t pay, you’ll need to go back to the judge in most cases and follow the process of civil seizure. Normally this involves the sheriff or local law enforcement. One of the easiest ways to collect is to show up to a local branch of a bank where the merchant has money and have the bank execute the seize money from their account.If you can’t find their bank, or they have no money, you can show up with the judgement and law enforcement (call them when you get there or follow the process outlined by the judge, sometimes this involves the local sheriff). You can then seize any property that might be at the location. reply raincom 14 hours agoprevThree years ago, a friend of a friend told me that he knows people inside UPS&#x2F;Fedex&#x2F;etc who steal expensive items, and sell them to fencers. Now it is time to pick up your expensive stuff from local stores, even if you place orders online. reply whatshisface 14 hours agoparentI had something stolen out of the USPS system. I don&#x27;t know whether it was the mailing center or the USPS itself but it disappeared in a way that logically couldn&#x27;t have been a mistake. reply raincom 14 hours agorootparentUSPS is considered safer, because of federal charges. Some wise people suggested to use priority&#x2F;express mail, along with insurance, if one wants it more secure in the USPS system. reply coredog64 14 hours agorootparentI have had 3 watches stolen out of my secure neighborhood parcel locker. Each time the package was scanned to show delivered, and each time it was not there. It’s just watches (which are marked as such on the customs form), and despite numerous complaints, USPS refuses to do anything about it. I’ll believe Federal charges when I see them. reply raincom 14 hours agorootparentI agree with you here. One time, I didn&#x27;t receive a check for $8k for two months for work I did. I complained to the sender, who sent me the image of the cashed check. So, I filed a complaint with USPS about stolen mail, and that too was supposed to be delivered to a PO Box. No response whatsoever from USPS postal inspectors, who are busy with priorities of their political masters. So, it took another three months to sort out this mess through alternative means. At least, USPS should have contacted me about my complaint; no, they didn&#x27;t care. reply handedness 13 hours agorootparentprevI have relevant industry experience, and I would advise anyone to never, ever use Priority or Express Mail for a high-value item, under any circumstances. Even with third-party insurance.Theft is much more likely than with UPS&#x2F;FedEx overnight services, and it&#x27;s nearly impossible to arrange the delivery so that the parcel is on camera for its entire journey, something easily accomplished with some other carriers. And if the package lost, prosecution is almost an impossibility, as is therefore recovery.In the event of a loss, Postal Inspectors are typically useless for pursuing package theft committed by USPS employees, even with very high value because they live in perpetual fear of the APWU (their explanation, not mine). They also hilariously attempt to pass the investigative buck to local authorities, who rightly note that it was a Federal crime committed by a Federal employee on Federal property.The Postal Inspectors recently had a high-visibility thread on another site that very much overstated their value, and ever since that thread went up that&#x27;s been the narrative. It&#x27;s wholly unjustified.Registered Mail is the only USPS service worth considering for such items, and it&#x27;s actually incredibly good, and tightly controlled. It&#x27;s arguably the most secure service of the major carriers, and probably where that recommendation comes from. As bad as the USPS is at delivering everything else securely, they&#x27;re excellent at getting Registered Mail items where they belong. Insurance up to $50K can be purchased (and sometimes over that amount).For someone with no experience doing a one-off, high-value shipment, that is what I would strongly recommend. The insurance also comes without the endless hidden caveats one finds with UPS that requires a complex decision tree to validate, or the BTW-it&#x27;s-not-actually-insurance aspect of FedEx&#x27;s declarations (for which they&#x27;ll happily charge).Third-party insurance services are worth their (very reasonable) cost, but can be difficult for the average person to secure. Services like Brink&#x27;s enter the picture when you start talking about moving items above that level.But Priority&#x2F;Express is the absolute wild west in terms of secure package delivery. Temporary employees working with no oversight, with a union that will reflexively and aggressively defend people even when it&#x27;s fully aware it&#x27;s defending criminals (sound familiar?), and unmotivated inspectors. It&#x27;s a recipe for high rates of package loss, which is exactly what it has. reply raincom 13 hours agorootparentThanks for sharing your experience. USPS says &#x27;Registered Mail is kept highly secured and is processed manually, which naturally slows the speed at which it travels.Registered Mail is not recommended if speed of delivery is important.&#x27;So, UPS&#x2F;Fedex overnight is better. reply handedness 12 hours agorootparentThat&#x27;s a good point. Registered Mail isn&#x27;t fast. In fact, it is, at times, very slow. reply User23 14 hours agorootparentprevPostal inspectors take this sort of thing very seriously. reply handedness 14 hours agorootparentLately I&#x27;ve been seeing comments like this surprisingly often, but my firsthand experience tells me otherwise. reply gnicholas 13 hours agorootparentA relative had mail stolen from an outgoing mailbox. She filed a complaint and was contacted months later when they caught the guy. They found her checks (to charity) in his house. She was shocked to hear back so much later. Apparently they were on the case the whole time, since it was affecting a lot of people. reply handedness 13 hours agorootparentI don&#x27;t doubt they solve cases of serial theft by ordinary citizens.They are, however, habitually unwilling to investigate Postal employees in all but the most exceptional cases (and the value of the thefts is not sufficient to be exceptional). reply gnicholas 13 hours agorootparentIn this case, it was actually an inside job, since some of the mail had been deposited in slots at the post office itself! reply raincom 14 hours agorootparentprevOnly when they want to investigate your case. Most of the time, postal investigators don&#x27;t care. Maybe, they care if the package is insured&#x2F;priority&#x2F;express mail. reply lupusreal 14 hours agorootparentprevMake sure to let the postal inspector know. reply anonymouskimmer 14 hours agoparentprevI worked as a FedEx package handler for a bit. One item that was shipped was rolled up mattresses, another item that was shipped was cell phones. These arrived on trucks in large quantities. The shipping labels didn&#x27;t stick well to the mattress packaging, and occasionally came off of the cell phone boxes as well. Sometimes it was obvious which packages the labels had come off of, other times not. reply dboreham 14 hours agoparentprevGuitars are notorious for vanishing in the shipping pipeline. They look obviously like guitars when shipped. reply mmh0000 13 hours agoprevWow, I read this whole article and it’s amazing how similar of an experience I had.I ordered a fairly fancy mechanical keyboard and instead got a used motorcycle cover. I did a proper return through Amazon, they even said via live chat that they were processing the refund. But the refund never came.After two months of back and forth with I filed the dispute with AMEX. Amazon disputed the charge back. I had to dispute the Amazon dispute. finally, Amex did end up refunding the money even though Amazon did not. reply RajT88 14 hours agoprevBuying stealable big ticket stuff like this on Amazon is something I just realized I have never done. I haven&#x27;t had issues with Amazon drivers stealing my packages, but I sure as hell have gone through issues with my fucking neighbors stealing my packages. Apartment living is hell. &#x2F;rantGame consoles and guitars I generally buy in person. Sure, there&#x27;s corner cases, like buying used (generally retro) consoles on eBay, but these won&#x27;t be clearly marked as a game console. reply anonymouskimmer 14 hours agoparentThe Amazon delivery driver doesn&#x27;t know it&#x27;s a game console either, as it was in a regular brown box. The driver just knew it required a special code prior to delivery. The only Amazon people who know it&#x27;s a console are those responsible for packing it. reply raincom 5 hours agorootparent&#x27;Knowing it required a special code priority to delivery&#x27; itself is a signal for stealing, and replacing it with junk. Drivers can do it; even people at distribution centers do it [1][1] https:&#x2F;&#x2F;www.newsweek.com&#x2F;amazon-workers-steal-140k-goods-dep... reply thelittleone 14 hours agoprevDang I&#x27;m no fan of amazon&#x27;s ethics but it seems bad ethics is the norm among corporates, governments not the exception. Corruption, abuses of power... occurring with such regularity and at worst a slap on the wrist or forced to retire with a huge payout. reply upon_drumhead 13 hours agoprev> Never buy anything of any meaningful value (if anything at all) from Amazon ever againHonestly, a single chargeback will cause Amazon to cancel your account and block you from the platform forever. It&#x27;s the cost of getting your money back :( reply josephcsible 8 hours agoparentDo they also delete all of your previous Kindle purchases and all of your data in AWS? reply upon_drumhead 6 hours agorootparentI would believe so, anything tied to that account goes poof. reply wizb 15 hours agoprevI tried to return a couple of things within 30 days last month, they offered me less than purchase price plus ridiculously expensive shipping. Total refund would have been around 70% of purchase price.Not what I expected when I signed up as a Prime customer. reply wdb 14 hours agoprevLately I have been recording the opening of expensive parcels received from Amazon with one-time code to avoid these issues.Recently they have been causing issues with a return they lost after receiving it and want me to recharge the amount. reply kmeisthax 9 hours agoprevSix years ago, I had my computer compromised by a remote access trojan. The hacker accessed my machine while I was asleep, used Chrome password manager extraction tools to get my Facebook password, then credential-stuffed it into Amazon[0] to buy as many PSN cards as they could before Chase&#x27;s fraud detection tripped and started texting me for verification, which woke me up.You would think that fixing this would be simple: revoke the PSN cards and reverse the credit card transactions. Turns out, they don&#x27;t do that. At all. Amazon insisted that they wouldn&#x27;t do shit without a bank chargeback. I of course had already started that process with Chase. About a month later, I get a call from Chase saying they need to \"move the transactions to the new account\"[1], which sounds like a stupid technical thing, so sure, whatever. A few weeks later I get a letter in the mail saying the dispute was closed because \"it was a dispute with the merchant\" - no explanation what that means. They give a phone number to call that goes to voicemail - I called at least five times and never got a call back, and all $400 worth of fraudulent transactions were right back on my statement.I gave up trying to fight shit because I don&#x27;t want to sue my bank, nor do I want to fight Dread Pirate Bezos. I&#x27;m not suicidal[2]. However, it did teach me two things that have stuck with me:- Amazon has a blanket opt-out with the credit card companies and issuing banks. I don&#x27;t know how, it could be as simple as \"don&#x27;t waste time investigating likely false accusations of fraud\", but they are able to win[3] chargebacks with credit card companies using explanations that look like someone just picked the first option on the form that denies the dispute.- PlayStation Network cards are apparently as immutable and uncensorable as Bitcoin[4]. If you want to do crimes, do them with PlayStation.[0] Yes, I was reusing passwords. Yes, I did change every password I had over the next few days. Yes, I completely wiped the machine and reinstalled everything. No, I don&#x27;t think I should have been liable for fraud because of any of this.[1] They had sent me a new card and card number at this point.[2] I&#x27;m pretty sure the \"slow and horrible\" option in the suicide booths involves burying yourself in legal fees.[3] Keep in mind that not-monopolistic merchants almost never win chargebacks or disputes.[4] For an extra layer of irony, a few days prior, I&#x27;d written a long screed at a Bitcoin fanatic on Reddit about how credit card chargebacks are a feature, not a bug, and that immutable transactions are a design defect. reply anonymousiam 12 hours agoprevIt&#x27;s been nearly two years since Jeff Bezos stepped down as CEO of Amazon. I&#x27;m surprised that Mr. Tasker would not be aware of this.https:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;jeff-bezos-leaves-seattle-miami-a... reply crazygringo 14 hours agoprevI don&#x27;t think the conclusions presented are true. It seems to be a pretty \"standard\" case of theft that, unfortunately, yes these things often take time to resolve. And all of the \"analysis\" is just speculation.Does it suck that it took extra messages for the return to be acknowledged, and extra weeks for the refund to finally get approved and go through? For sure. Does this mean \"Amazon has an honesty issue\"? No. Dealing with a package where the expensive contents were swapped out for other content is probably going to take weeks to resolve with any major retailer.Trying to shortcut the process by filing a chargeback isn&#x27;t going to help anything. You only do that if Amazon ultimately denies the return.Of course it sucks it ties up that money. But they can also just leave the balance on the credit card for an extra month and pay, what, $8 in interest? Everything about:> remain in a state of financial limbo for the better part of 2 months, spending Christmas wondering whether we&#x27;d ever see our money again.feels overly dramatic. Anyone who can put a $600+ Xbox bundle on a credit card isn&#x27;t going to be left in \"financial limbo\". In the end, they can rest assured that a chargeback with Amex will work even if it didn&#x27;t on their first attempt.Yes this is all annoying. But it&#x27;s not some conspiracy. These cases are hard for companies to deal with, because for every delivery person who&#x27;s a thief, there&#x27;s a customer who lies and gets a free Xbox out of it. So they do take time and effort to resolve. reply alibarber 14 hours agoparentTrying to shortcut the process by filing a chargeback isn&#x27;t going to help anything. You only do that if Amazon ultimately denies the return.Maybe - but as he correctly mentions, in the UK, he&#x27;s effectively buying the console from American Express because they gave him credit for it. reply crazygringo 13 hours agorootparentI don&#x27;t see what that has to do with anything. You still wait for the Amazon return process to conclude one way or another. reply blibble 8 hours agorootparentyou don&#x27;t have to, a prompt refund is guaranteed by UK law within 14 days regardless of amazon&#x27;s shitty processesif they don&#x27;t do it in time, chargeback is a perfectly reasonable reply notyofriend 14 hours agoprevRecently I had them fail to deliver a 10$ item, flag it in their system as a delivery failure notify me that the failure occurred and then still not give me a refund and tell me that they are doing me a favor by refund it. The service quality really Turing to poop. In December they basically done guarantee delivers either anymore so between that and the sea of counterfeits I only make 5-10$ item orders from them where the delivery costs more than the item. reply zizee 11 hours agoprevThat was a good reminder to cancel my prime membership, ta! reply alibarber 14 hours agoprevHuh - I&#x27;ve had Amazon prime &#x27;guaranteed&#x27; n-day delivery fail twice in succession for a 90GBP textbook. I&#x27;ll put this down to incompetence rather than malice, but imagining the disappointment of any potential thief of it served as some compensation. reply RecycledEle 14 hours agoprevSomeone stole am Xbox. I&#x27;m not sure it&#x27;s Amazon. reply raincom 14 hours agoparentWell, who is responsible for the theft? Whoever handled this piece stole it. So many hands from shipping to delivery. It is my hunch that either the driver or some folks in the local distribution center stole it. A secret code doesn&#x27;t solve the problem, unless the receiver opens the box in front of the delivery driver. reply codetrotter 14 hours agoparentprevI think it’s about high time that Amazon disrupts the “leave it on the porch” method. Too many packages are stolen by thieves.And I mean, they’ve already started to some extend to deal with it. There are many cities I’ve been to that has Amazon delivery boxes where you can pick up your stuff.I think that when drones get powerful enough, and regulation allows it, Amazon will adopt drone delivery everywhere. You get a notification on your phone telling you that your package is at the local distribution center. When you get back home, or some other day later where you are not busy, you tell the app to deliver now and within short time a drone drops the package off at your home any time that is convenient to you 24x7&#x2F;365, even if it’s like 3am on a Sunday.And for the rest of the journey up to that point, rigorous tracking and auditing to make sure packages don’t go “missing” on the way. reply desas 13 hours agorootparent\"leave it on the porch\" isn&#x27;t even a thing in the UK, unless you specifically nominate it as your acceptable secure place.Amazon knock on the door, if you&#x27;re not in then they&#x27;ll come back tomorrow, and if you&#x27;re not in, then they&#x27;ll try the next day. If you&#x27;re not in three days in a row they&#x27;ll hold the package for three days, to give you time to arrange one final delivery attempt to your home, Amazon locker or pick-up point (neighbourhood shop). Eventually they&#x27;ll just take the package back and refund you automatically. reply daveoc64 13 hours agorootparentAmazon leaves stuff on my porch most days in the UK. reply Gorbzel 13 hours agorootparentprevThey have no idea how to disrupt last mile delivery without corruption and theft. They’ve tried. My apartment building’s doorbox has Amazon Key, such that drivers have the ability to let themselves in and drop off packages in a secure area. I’ve confirmed with one of the better Amazon delivery drivers that it works like a charm.The vast majority of them don’t (think&#x2F;care to) use it. At this point I’m actually glad, lest they let themselves into the secure area and steal other packages. reply adamckay 14 hours agorootparentprevDoesn&#x27;t matter in this case.An Xbox was ordered that&#x27;s classed as a \"high value\" item so requires a OTP being given to the driver to release the package.The package was hand delivered to the customer when the customer provided the OTP, but it turns out the contents of the package were swapped out with junk. reply fweimer 14 hours agoparentprevNot sure about that. One of the screenshots mentions AMZNMKTPLACE AMAZON CO UK. If it was indeed an Amazon Marketplace vendor, then it&#x27;s not entirely unheard of that it was a scam from the start. reply sanitycheck 13 hours agorootparentYep, I spotted the same thing. Third party seller.I&#x27;ll still occasionally buy stuff from Amazon that&#x27;s actually sold by Amazon, but I&#x27;d pick almost any other retailer over an \"Amazon Marketplace\" seller. Scam city.(I&#x27;ll search for stuff directly on camelcamelcamel these days, as the \"sold by amazon\" filter is gone from Amazon&#x27;s own website.) reply aprilthird2021 13 hours agoprevI&#x27;ve found my use of Amazon declining over time. Temu has basically replaced lots of consistent small-value buys that I&#x27;d go to Amazon for: cables, plastic things, simple tools, kitchen stuff, etc.High ticket items I usually shop around a lot to get the best deal and that&#x27;s rarely on Amazon.And I&#x27;ve found myself buying more and more from independent shops.Anyone else notice similar trends in their habits? reply charcircuit 14 hours agoprevWeb retailers being slow is nothing new. Especially during December. reply baz00 13 hours agoprevCancelled my Prime this month. I will never use Amazon again.3rd package in a month that has gone missing. Posted in apartment letter box in mail room. Each time it is missing. No sign of any amazon packages. Neighbours reporting the same with their stuff.On top of the shit show that has been the support situation during Re:Invent I&#x27;d rather use any other retailer or cloud provider.Amazon are a fucking shit show race to the bottom and we should stop giving them money and let them burn. reply xkekjrktllss 14 hours agoprev [–] Amazon is a private enterprise and its profit is soaring, which means this is simply a non-issue. I thought HN knew how free markets worked but I guess not. reply blagie 14 hours agoparent [–] Amazon&#x27;s market cap soared when profits were negative. Amazon was building up reputation, logistics, and customer relations. As far as I can tell, they&#x27;ve been torching all of that long-term value for about the past three years.That&#x27;s a huge loss of value. reply xkekjrktllss 14 hours agorootparent [–] When were profits negative? AFAIK Amazon.com may lose money but AWS more than makes up for it. Amazon.com is a long game to monopolize retail logistics, which they are just now starting to offer as a service to other retailers, meaning Amazon.com is of less importance. reply blagie 13 hours agorootparentAmazon was losing money for nearly the first decade of its existence. It was a bit of a laughing stock among the traditional business community: \"Lose money on every sale, but make it up in volume!\" The loses were considered astronomical at the time; in 2000, it lost over a billion dollars.The strategy was the right one, though. To put all of that in perspective, in 2018, it earned over 10 billion, and many businesses have since followed the Amazon model.It&#x27;s sort of a classic case study in business schools now. reply xkekjrktllss 12 hours agorootparentYou are conflating Amazon with Amazon.com, and vice versa at your convenience. It&#x27;s much too sloppy of analysis to sustain a worthy discussion. reply blagie 11 hours agorootparentI agree a discussion is unwarranted. Your comment is a personal attack with no substance.(For reference, AWS was founded in 2002, and took some time before it made any sort of dent in much of anything.) reply jsnell 6 hours agorootparentprev [–] Most recently? In 2022, when Amazon (yes, the entire company) lost about $3 billion during the year. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts a negative experience with Amazon where a high-value item was not delivered and no refund was issued, raising concerns about theft within Amazon's delivery system and criticizing their handling of the situation.",
      "The author expresses dissatisfaction with American Express's response to a chargeback and plans to pursue legal action.",
      "The author advises against using one-time passwords for high-value items and suggests finding a new credit card provider."
    ],
    "commentSummary": [
      "Amazon Prime members are experiencing slower delivery speeds, with some reporting shipping times of up to 7 days instead of the promised 2-day delivery.",
      "Dissatisfaction with these delays has led to cancellations of Prime subscriptions and consideration of alternative shopping options.",
      "Customers are expressing frustration with package thefts in certain areas, as well as dissatisfaction with Amazon's customer service and refund processes. There are also discussions about employee theft and the need for stricter regulation in the market."
    ],
    "points": 163,
    "commentCount": 130,
    "retryCount": 0,
    "time": 1702145923
  },
  {
    "id": 38581373,
    "title": "Fintech Startup Raises $8M to Revolutionize Charitable Giving with AI and Blockchain",
    "originLink": "https://unoriginal.blog/introducing-dwlaas/",
    "originBody": "Introducing Deadweight Loss as a Service I’m excited to announce our fintech startup Deadweight Loss as a Service is coming out of stealth after receiving $8M in seed funding from Emergent Ventures and Thiel Capital. Our platform makes charitable giving more efficient using the latest AI and blockchain technology. Our platform has two major innovations: OmniMatch™ will match any funding through our platform up to fifty cents on the dollar. Antidollars™ remove $1 of funding from an organization of your choosing. Antidollars™ Frustrated that the only avenues for disagreement with an organization’s decisions or worldview are ineffective and inefficient protests, petitions, boycotts, and social media campaigns? Tired of cardboard protest signs wasting valuable economic resources, then being reduced to litter in the street? The Antidollar™ is for you. Patent-pending and only available through Deadweight Loss as a Service, each Antidollar™ donation either annihilates a dollar donated to your target or donates a dollar to its antithesis. Here’s how it works: We’ve identified hundreds of pairs of organizations which directly oppose each other (e.g. Clean Air Task Force / American Coalition for Clean Coal Electricity, Electronic Frontier Foundation / Heat Initiative). For each pair, we’ve created a smart contract providing a “market” for this pair. Each market has a balance which starts at $0 and can become either negative or positive. Each January 1st at 00:00, the absolute value of the balance is donated to one of the organizations. If the balance is negative, it is donated to the first in the pair; if positive, it is donated to the second. On our platform, you can send money (plus an OmniMatch™ subsidy) to a supported organization of your choosing. Behind the scenes, this works by increasing or decreasing the relevant market’s balance. If $1 is sent to the first organization, the balance decreases by a dollar; if the second, the balance increases by a dollar. The Antidollar™ does the exact opposite: sending an Antidollar™ to the first organization increases the balance by a dollar, and sending an Antidollar™ to the second decreases the balance by a dollar. If the balance currently favors the organization sent an Antidollar™, the Antidollar™ will simply subtract $1 from the amount donated; if not, the Antidollar™ is sent to the opposing organization, which, for well-chosen markets, should have a similar effect. Sending dollars or Antidollars™ on our platform is completely free. OmniMatch™ If Antidollars™ aren’t motivation enough to use our platform, OmniMatch™ will be. $0.20 per Antidollar™ sold is directed towards an OmniMatch™ pool. This pool is used to match a fraction of each dollar or Antidollar™ directed towards an organization on our platform. Our proprietary OmniMatch™ algorithm determines this fraction using factors such as market activity. We guarantee these OmniMatch™ subsidies will never go below 10 cents per dollar. Funding organizations through our platform is a no-brainer: your donation will be worth 10%-50% more at no cost. Thanks to OmniMatch™, in our closed beta lasting only a few months, several of our markets have already seen more than $10,000 in volume: Cato Institute / Democratic Socialists of America (current balance -$12) Brady Campaign / National Rifle Association (current balance +$536) Planned Parenthood Federation of America / National Right to Life Committee (current balance -$4165) United States Treasury / Democratic People’s Republic of Korea Central Planning Committee (current balance -$3484) People for the Ethical Treatment of Animals / National Cattlemen’s Beef Association (current balance $6645) Biden for President / Donald J Trump for President (current balance -$8392) Testimonials Tired of political quarrels at the Thanksgiving table? Buy anti-gift cards for the whole family! Can’t make it to a (counter-)protest? Whether you’d have been at Planned Parenthood or on Wall Street, Deadweight Loss as a Service has got you covered. …. This startup … is … good. — WIRED Magazine, “Forget Political Activism. ‘Deactivism’ Is Sweeping Silicon Valley” [The] Hatch-Waxman [Act] was our wakeup call at Eli Lilly to start making connections inside the Beltway. They’ve been worth every penny, but were starting to impact our image. We partnered with Deadweight Loss as a Service to redirect our lobbying spend towards [Patients For Affordable Drugs Now] Antidollars™. It’s much more efficient, and our ESG scores have never been better. — David A. Ricks, CEO of Eli Lilly and Company Pro Mode™ Stay tuned for a future update to the platform, Pro Mode™. For power users, Pro Mode™ further increases liquidity on our markets using advanced AI technology. We embed the mission statements of thousands of humanitarian aid groups, religious organizations, PACs, and more into a high-dimensional “cause-space” which accurately represents divergence in goals between any two supported organizations. The Pro Mode™ smart contract unifies Antidollar™ markets, replacing many distinct prices with a single Praxis Vector™ within cause-space. At the end of the year, the Pro Mode™ contract allocates its funds proportionally to each charity’s cause-space distance from the final Praxis Vector™. In Pro Mode™ with patent-pending Praxis Vector™ technology, every dollar pushes the market’s Praxis Vector™ towards your own PPV (Personal Praxis Vector™), set manually or inferred with state-of-the-art LLMs. With Pro Mode™, you can be confident your funds increase the cosine similarity of your and the market’s Praxis Vectors™ as efficiently as possible, without wasting an Anticent™ on causes literally and figuratively orthogonal to your beliefs. And best of all, Pro Mode™ comes at no additional cost.1 What’s next Our “PvP mode” experiment was extremely successful in closed alpha. We’ll go GA as soon as a lawyer stays long enough to sign off on it. In the long term, you can expect even more from us. A certain seed investor has encouraged us to expand into the vote swapping market with the help of Dr. Bryan Caplan. Meanwhile, Dr. Robin Hanson has been instrumental in the design of the Jury Nullification Market Beta—early adopters can join the waitlist starting today! We don’t expect to go public any time soon, but what’s a few unregistered securities between friends: invest in Deadweight Loss as a Service by sending Antidollars™ to our enemies. 1 Proceeds from Pro Mode™ Antidollars™ are used to compensate our shareholders and do not contribute to the OmniMatch pool. 2023-04-01 #fiction",
    "commentLink": "https://news.ycombinator.com/item?id=38581373",
    "commentBody": "Deadweight Loss as a ServiceHacker NewspastloginDeadweight Loss as a Service (unoriginal.blog) 151 points by codon 21 hours ago| hidepastfavorite72 comments shpx 19 hours agoThe organization pairs won&#x27;t be exactly 1-to-1 because building is harder than destroying, different organizations are more efficient and money is non-linear. If you had a \"dump oil in national parks\" and a \"clean up oil dumped in national parks\", you&#x27;d need $1000 for every $1 of effort dumping oil. So at best this system is a discovery mechanism for comparatively valuing organizations, but it&#x27;s not really set up that way because there&#x27;s a big difference between an Antidollar™ donated to cancel out a dollar and a dollar donated after you&#x27;ve reached 0 dollars difference from the counter party. reply j4yav 19 hours agoparentIt&#x27;s satire. reply nostrademons 19 hours agorootparentThe comment might be too, but you never know on the Internet. Poe&#x27;s Law. reply j4yav 18 hours agorootparentTurtles all the way down. reply reactordev 21 hours agoprevI believe you may have something with Anti-dollar. Joking aside, there’s almost always a company on the other side of the coin. Boycotting or otherwise public outcry’s and cancel culture would look a whole lot different if it were a value-based voting platform where competing interests vie for the value. Add reporting for government agencies on what’s “hot” and it sends a clear picture on what the national sentiment is. reply codingdave 20 hours agoparentI know this is a joke, too, but I worry that you aren&#x27;t seeing the joke if you think there is something here. This is a setup to take in dollars from everyone and arbitrage the sentiment difference across the userbase, effectively meaning they don&#x27;t have to pay anything and just take the dollars home. That&#x27;s the joke. And anyone who actually would put in dollars are who the joke would be being played upon were it real. reply orangecat 17 hours agorootparentThe joke is that there is something there. For example in a presidential election, I&#x27;m indifferent between my preferred candidate having $1 more and the opposing candidate having $1 less. If it were possible to honestly negotiate with my counterpart who supports the other candidate, we could either save our money or agree to both donate to a mutually agreeable charity, and everyone would be better off. reply jnwatson 14 hours agorootparentThe US certainly spends a lot on elections, and one might debate whether that&#x27;s too much or not. But what is certain is that campaign money contributes to the GDP. It funds a lot of salaries.I&#x27;d rather that money go to people instead of a faceless cryptofund. I think that&#x27;s the joke. reply orangecat 13 hours agorootparentBut what is certain is that campaign money contributes to the GDP. It funds a lot of salaries.This is the broken window fallacy. If you have two groups with diametrically opposed goals, giving them each more money to spend \"increases GDP\" in a local sense, but the result is that a bunch of people spend a lot of effort for a net result of zero, when it could have gone toward something useful.I&#x27;d rather that money go to people instead of a faceless cryptofund. I think that&#x27;s the joke.Yeah, the crypto piece is just for additional silliness. For a real version of this you&#x27;d need, like, a spreadsheet with two columns. reply stevage 20 hours agorootparentprevYeah but imagine if there was something like this for real, only the dollars weren&#x27;t greedily kept, but spent in some way that people on both sides support. Like, maybe pro-choice and anti-abortion supporters would both support the excess money going to support new mothers or adoption programs. reply notahacker 20 hours agorootparentThen imagine the incentives for campaigners to skip the two-sided prediction market and just spend their money on advertising directly to voters and lobbying politicians.Or the implications of implementing the only way to make this actually work by taking the pesky voters out of the decision process altogether and just letting the money decide the outcome... reply gosub100 19 hours agorootparentor they&#x27;d just shift the debate to why you shouldn&#x27;t give money to the opposing party&#x27;s cause: \"they say the money is for ___, but really they do ____ with it\". reply priprimer 19 hours agorootparentprev> letting the money decide the outcomesome people call that data driven decision making and they like itothers call it “skynet” and they fear it reply PaulHoule 17 hours agorootparentprevThere is a similar game that distributes more of the money to causes where people vote with their dollars and antidollars and the winning side gets 1-epsilon of it because the operator of the game requires vigorish.It&#x27;s like poker with no cards. Ideally the winner puts in just a dollar more than the loser and they nearly double their donation. If the winner can&#x27;t get enough information to do that and has to spend too much for the pot they end up making a huge unmatched contribution.The game makes sense to play if you&#x27;re sure you will win but you don&#x27;t want to start it if you think you won&#x27;t. reply reactordev 14 hours agorootparentI believe I know this game. Strange how wording it this way makes way more sense. reply JonChesterfield 18 hours agorootparentprevThat&#x27;s a business model, not a joke. reply codingdave 18 hours agorootparentA business model includes a transaction where one side gets value in exchange for returning value to the other side. When it is a one-sided transaction like this, where one side gives money and the other just pockets it... that is more often referred to as a \"scam\" reply bogtog 18 hours agorootparentNo, both parties get value. Suppose a user would receive 1 utility for donating $1 to some cause in a traditional fashion (e.g., giving the charity money directly). Using this platform and with an OmniMatch of 25%, the user will effectively donate $1.25 for the cost of $1 and accordingly get 0.25 extra utility. The user gets surplus utility no matter what. The platform, on the other hand, needs to be careful in what markets it creates and how it sets OmniMatch, in order to make money. reply JonChesterfield 16 hours agorootparentprevOne side gives money, and a fraction of that money goes to the intended cause, is referred to as \"fundraising\". One of the more dubious aspects of donating to a charity is that some of their resources are spent persuading other people to donate to them, in what looks like a strongly zero sum game for the sector as a whole. I think there&#x27;s a credible chance the system outlined here would end up at a higher effective efficiency than the current state of the art of charity fundraising. reply reactordev 20 hours agorootparentprevI know but I was referring to just the concept of dollar vs anti-dollar. Not the payout or anything but just the idea that companies get X dollars where X is the sum of users who voted for them. Let the people decide.The reality is humans will find a way to make this corrupt. reply codingdave 19 hours agorootparentBut that doesn&#x27;t let the people decide. That lets the people with spare dollars decide. reply reactordev 17 hours agorootparentSure, fair point, replace dollar with vote point… reply skybrian 20 hours agoparentprevIf all proceeds went to charity, it could work as a snarky way to raise money for some other charity that’s boring but uncontroversial. It reminds me of the publicity stunts that Cards Against Humanity would do. reply orangecat 17 hours agorootparentIn all seriousness, this is an excellent idea. reply codon 20 hours agoparentprev> Add reporting for government agenciesWay ahead of you—we&#x27;re licensing Praxis Vector™ technology to Palantir. Thiel didn&#x27;t buy a board seat for nothing. reply koliber 20 hours agoparentprevThis is what lawyers are for. Instead of two companies actually competing, each spends a bunch of dollars on lawyers to fight in court. The one who spends the most dollars on lawyers wins.Just to be clear, there is a lot of sarcasm here. But I think there is a bit of truth too. reply cyanydeez 20 hours agoparentprevcancel culture is a meaningless phrase , it&#x27;s just culture. reply genewitch 19 hours agorootparentI suppose it&#x27;s more that a culture that encourages actions that result in someone deemed unworthy experiencing negativity.Read as: don&#x27;t say anything, ever*, anywhere that isn&#x27;t droll corp-speak, because somebody, somewhere will have an issue with it and try to take you to task. If that somebody has a lot of followers, you could be out of a job&#x2F;home&#x2F;country&#x2F;freedom.*trawling through post history et al to find narratives they don&#x27;t agree with, too reply cyanydeez 19 hours agorootparentyes, and they used to behead kings.it&#x27;s culture. culture shuns what it rejects and lifts up.Shame is even ritualistic in some cultures.it&#x27;s definitely just a phrase used by the short end of the stick.I&#x27;m sure there&#x27;s a nuanced view of a culture that doesn&#x27;t dive deep enough and mistakes some virtue and accidentally avoids something of value.but ultimately, it&#x27;s a term that&#x27;s just respinniing what cultures do. they select memes and their purveyors and reject the to advance.evolution works both as species and as culture. we, the advanced scientific community have dropped the idea that evolution moves towards some greater good and just acknowledge evolution is adaptation to environment.lastly, culture is what people both adapt to and mold by their actions. with social media that&#x27;s now basically an infinite fractal. reply username332211 18 hours agorootparentThey used to behead kings. And very often what followed was beheading the people who behead kings. And then we&#x27;d behead those that would behead the people that beheaded the king.A culture doesn&#x27;t progress just because it changes. It is not uncommon for complex systems to undergo changes that make them self-destructive. You talk about evolution, but the reproductively dominant cell in a complex organism is the cancer cell.It is entirely plausible that western culture would become non-viable because of \"cancel(&#x2F;r) culture\". And that cultures of the future would look in it the same way we look at organisms with poor tumor suppression mechanisms. And that too shall be evolution. reply ImPostingOnHN 18 hours agorootparentprev> I suppose it&#x27;s more that a culture that encourages actions that result in someone deemed unworthy experiencing negativity.This sounds like most cultures in history. The majority of them have some sort of social shunning for people who act like a jerk (read: acts in ways society and culture have decided are jerkish)> Read as: don&#x27;t say anything, ever, anywhere that isn&#x27;t droll corp-speak, because somebody, somewhere will have an issue with it and try to take you to task. If that somebody has a lot of followers, you could be out of a job&#x2F;home&#x2F;country&#x2F;freedom.this sounds like an exaggerated victim complex. Try it with \"kittens are cute\" and not something jerk-ish, and let&#x27;s see if someone pops out of the woodwork to destroy your job&#x2F;home&#x2F;country&#x2F;freedom. reply genewitch 13 hours agorootparent\"In my opinion, i don&#x27;t believe that narrative is complete or correct\" is enough to instigate a nasty backlash.\"kittens are cute\" is droll corp-speak. reply jerf 19 hours agorootparentprev\"Cancel culture\" may have been meaningless in the past, but now with the new Antidollars™, it literally exists. #include Life moves fast. reply reactordev 17 hours agorootparentCulture 2.0 invokes meaningful change and collaboration on a scale never seen before. Protocols are faster, more robust, efficient by up to 35% versus previous generations. It’s the fastest we’ve ever produced and we didn’t stop there. We went deep to heart of the product to enhance even the most subtle of inefficiencies, rearchitecting the core from the ground up… reply virtualritz 19 hours agoprevReads to me like: even more power to people with deep pockets, if this was for real. reply aconbere 19 hours agoparentfiled under “#fiction” reply mcherm 19 hours agoprevSatire at its finest, I was 2&#x2F;3 of the way through the article and still trying to tell whether it was a spoof, or the public unveiling of a terrible, TERRIBLE startup. reply ryukoposting 13 hours agoparentThe gratuitous use of the TM emoji instead of ™ seemed like a giveaway to me. reply rf15 19 hours agoparentprevThe company name alone already tipped me off. It&#x27;s all very ridiculous, and yet posted here. reply mnmalst 19 hours agoparentprevI didn&#x27;t realize until I read the comments. I am not smart... reply passion__desire 17 hours agorootparentI consider this to be Trust Pollution. When you trust something, you will believe it without much thinking, caught off-guard.Is this the best April Fool&#x27;s ever? Witness - BBC Newshttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=MEqp0x6ajGE reply JonChesterfield 21 hours agoprevDespite being satire, I think that could work in the US. It plays off the my team &#x2F; their team dynamic and sends some fraction of the donated money onwards. Very like an inefficiently run fundraising organisation. There&#x27;s an outside chance of the setup making a loss for the organisers but only if a pair is very unevenly matched (and that&#x27;s fixable by letting the &#x27;onmimatch&#x27; run down to 0%). I&#x27;m not even sure it qualifies as fraudulent. reply plagiarist 19 hours agoparentI think it is literally a satire of US FPTP voting. Tons of money go in and the winner receives a pittance. Compare to something like proportional representation or score voting. reply dmurray 16 hours agorootparentWhat? Other voting systems still end up with a winner. If you had score voting for the US President, people would still spend a fortune on it, and the winner would get the same as he does now.\"No matter who you vote for, the Government always gets in\" reply plagiarist 15 hours agorootparentIf we had score voting we wouldn&#x27;t have to choose between an artificial two choices, the winner of which having barely any resources to actually accomplish anything. I&#x27;m interpreting the small amount of money as representing fear to do what the majority of their voters want, lest they lose a crucial 1-2% from the middle. reply m3kw9 18 hours agoprevIf my money can be destroyed like that why would I donate through this plat form even though I get 50% more? It doesn’t enough for me to overcome the risks of some group diverting all my funds to an opposite cause reply wand3r 21 hours agoprevI know this is satire, but this is effectively how lobbying in America is really done. reply wodenokoto 21 hours agoparentI didn’t even catch it was satire. I was like “that sounds like a funny bedroom project rather than an 8million funding startup.I don’t know if that makes me gullible or the world I live in crazy. reply plagiarist 21 hours agoparentprevPart of the satire is how they are trying to present an idea where they just take stacks of money as an innovation that is great for users. reply jonstewart 20 hours agoprevLost opportunities: Tyler Cowen on Advisory Board; Powered by Stripe. reply notahacker 20 hours agoparentYou should start a prediction market on which companies and individuals should be included in the next draft!(but seriously, it&#x27;s pretty on point already. I was primed to post that I looked forward to seeing the Overcoming Bias entry taking this idea seriously, but they got around to namechecking Robin Hanson in the penultimate paragraph) reply jtbayly 18 hours agoprevI had no idea this was fake until I came here to figure out what I was missing&#x2F;why anybody would be stupid enough to give money to this.You could say that reveals something about me. I disagree. It says something about the crypto scene and things being promoted even here over the last few years. reply xyst 18 hours agoparentBesides the name of the product. This is what convinced me it was satire:“… efficient using the latest AI and blockchain technology. “ reply phiresky 21 hours agoprevReminds me of antistocks [1]:\"We sell antistocks.”“Antistocks? Is that like . . . shorting a stock?”“Shorting is barbaric. Think how nice and simple going long is. And then with shorting you have to borrow from some specific person for some specific amount of time, and deal with margin calls and short squeezes and all that garbage. We asked ourselves - how can we make shorting as simple as going long? Antistocks are the answer. A Tesla antistock is a certificate which obligates you to pay us the value of a Tesla stock dividend each year.”“Why would anyone ever buy that?”“They don’t! We pay them X dollars to take it! Then when Tesla goes down, they pay someone else less than X dollars to take it from them, and keep the profit.”“What if they don’t pay the reverse dividend?”“I mean, that’s the counterparty risk you take with everything, isn’t it? Home loans, car loans, credit default swaps. If it helps, we’re limiting the product to accredited investors, so they can’t, like, pay a homeless guy $1 to take it off their hands.”“And you think people will prefer this to just shorting Tesla the normal way?”“It’s not just about shorting Tesla. This is the beginning of a whole new antifinance revolution. Lots of people want to invest in SpaceX, but they can’t, because Elon Musk selfishly refuses to go public. No one else can get around that. But we can! We print a million shares of synthetic SpaceX stock and a million shares of antistock, each antistock share requires you to pay one one-millionth of SpaceX’s yearly profits to the holder of one stock share. Or, you know how millions of ordinary people can’t afford homeownership anymore because Blackrock keeps buying up all the homes as investment properties? We just print a million synthetic houses and a million antihouses, where the antihouse owners have to pay the average rent in a certain area to the synthetic house owners each month. Blackrock gets to invest in real estate without having to worry about all those boring contingent things like mold or termites, and we can leave the real physical houses for ordinary families.”“Sorry, but this sounds like a terrible idea.”“I’m glad you think so! Would you like to be a seed anti-investor in our startup? If you’re right, then our antistock prices will never be this high again!”[1]: https:&#x2F;&#x2F;www.astralcodexten.com&#x2F;p&#x2F;even-more-bay-area-house-pa... reply paulgb 20 hours agoparentIt’s a joke but it’s also essentially how binary prediction markets work: you have two contracts, each of which resolves to $1 or $0 depending (oppositely) on whether X happens. You then solicit bids on both. When the sum of the offer price of both exceeds $1, you sell one of each, and put the dollar you collect aside to pay out to whichever bet comes true. reply ben_ipsen 20 hours agoprevBeing Rickrolled just doesn&#x27;t have the same feels now that Youtube will immediately blast an add in your face before you can enjoy the classic. reply smashah 19 hours agoparentif you have YT premium you can get rickrolled in peace reply sneak 18 hours agorootparentIf you pay the Danegeld to the Dane, I think “in peace” should be in quotes. reply Icathian 17 hours agorootparentPaying for a service someone is providing and appeasing ransacking murderers doesn&#x27;t really seem equivalent to me. reply sneak 17 hours agorootparentOh, you’re right. I’ll go and sign up for the alternative to YouTube instead.If you pay the ad company, don’t ever expect fewer ads. reply sentrysapper 19 hours agoparentprevI hadn&#x27;t noticed that before but you&#x27;re right, YT has ruined Rickrolling. reply mcny 18 hours agorootparentI like how different people have different perspectives of the same event. I use Mozilla Firefox with uBlock Origin. YouTube videos do not play automatically when I click on YouTube links from other websites.Personally, my conspiracy theory is that somehow the YouTube team twisted Google Chrome team&#x27;s arms to force them to make a byzantine system so that YouTube videos would pretty much always auto play. I cannot imagine how any self-respecting programmer(TM) would agree to such nonsense unless they were being paid very handsomely. reply ForkMeOnTinder 18 hours agorootparent> Personally, my conspiracy theory is that somehow the YouTube team twisted Google Chrome team&#x27;s arms to force them to make a byzantine system...You&#x27;re not far off. https:&#x2F;&#x2F;developer.chrome.com&#x2F;blog&#x2F;autoplay#media_engagement_... reply felipemnoa 18 hours agorootparentMakes sense. Youtube kept blocking me because it detected ad blocking mechanisms. Being stubborn I would simply reload the page and clicked the x button before it had a chance to load up the blocking code and then the video would play fine.After a while youtube gave up and no longer tries to force me to uninstall the ad blocking mechanisms.That or the ad blocking mechanisms got better. reply unshavedyak 17 hours agorootparentI have a similar experience. Though for me i didn&#x27;t evade them, i just didn&#x27;t visit for a ~week. When i eventually tried again, suddenly it wasn&#x27;t a problem again.Wondered if i was part of some a&#x2F;b and they rolled back? no idea. Either way i&#x27;ll happily drop YT if they try that shit without giving me a sane \"no ad\" tier lol. replyfallingknife 17 hours agoparentprevFirefox + ublock origin still has me rick rolling just like back in the good old days reply jancsika 17 hours agoparentprevI just don&#x27;t get the entitlement around Youtube. It costs money to maintain the servers and keep it running, 24&#x2F;7 so you can enjoy the content. It certainly doesn&#x27;t owe you a free Rickroll.If for whatever reason Youtube wants to enshittify its service to destroy its UX it is 100% within its rights to do so.If you want it to (temporarily) work again, just get everyone within 6 degrees of separation from you to sign up for Youtube Premium. reply riversflow 17 hours agorootparentHow is this entitlement? They are just stating a fact, a surprise video isn’t really a surprise when you have ad roll first. They make no value judgement about youtube, you projected that. reply rglullis 17 hours agorootparentprevIt also cost them money to run it when they had competition. Why didn&#x27;t they charge then? Their dumping tactics worked and they are the only global platform now, do you think they are entitled to extort us and profit from our attention?And to top it off, you think we should reward this behavior? reply aaron695 20 hours agoprev [–] There&#x27;s at least one learning tool where you pick a charity you hate and it donates your money if you don&#x27;t do your weekly lessons.More to this idea, paying micropayments to remove money from articles would be interesting.It would flatten bias. Reporters don&#x27;t want to piss people off, reporting true facts would minimise this.It&#x27;d be interesting to see what style of article would emerge.(And people can&#x27;t be bother paying micropayments to support authors but they sure as hell will be bothered to hurt them) reply YurgenJurgensen 19 hours agoparent [–] Sadly, the name ‘hatreon’ appears to have already been taken by a defunct Patreon alternative, because otherwise that&#x27;s exactly what this ‘business model’ could be called. reply genewitch 19 hours agorootparent [–] grudgepay replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fintech startup Deadweight Loss as a Service has raised $8 million in seed funding and is launching a platform to optimize charitable giving using AI and blockchain technology.",
      "The platform introduces two key features: OmniMatch™, which matches funding up to 50 cents on the dollar, and Antidollars™, which can remove or donate $1 to an organization's antithesis.",
      "Users can send money or Antidollars™ to supported organizations, and the platform guarantees a minimum subsidy of 10 cents per dollar. The startup has seen promising volume in closed beta and plans to introduce Pro Mode™ in the future to enhance liquidity with AI technology."
    ],
    "commentSummary": [
      "The article discusses several interesting concepts such as deadweight loss as a service, campaign money contributing to GDP, cancel culture, a satirical startup idea, investing in antistocks, YouTube's autoplay feature and ads, and potential business models involving donations and micropayments.",
      "The discussion provides a range of perspectives, from satire and amusement to critique and concern, offering a well-rounded examination of these concepts.",
      "This article is special because it covers a variety of thought-provoking topics, appealing to readers interested in the intersection of technology, economics, and social issues."
    ],
    "points": 151,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1702124545
  },
  {
    "id": 38581959,
    "title": "Spotify's Enhanced Shuffling Algorithm: Fibonacci Hashing for Even Artist Distribution",
    "originLink": "https://pncnmnp.github.io/blogs/fibonacci-hashing.html",
    "originBody": "If you like this blog post, do subscribe to my RSS feed Scrambling Eggs for Spotify with Knuth's Fibonacci Hashing First Published: 08/12/23 He was very late in returning -- so late, that I knew that the concert could not have detained him all the time. Dinner was on the table before he appeared. \"It was magnificent,\" he said, as he took his seat. \"Do you remember what Darwin says about music? He claims that the power of producing and appreciating it existed among the human race long before the power of speech was arrived at. Perhaps that is why we are so subtly influenced by it. There are vague memories in our souls of those misty centuries when the world was in its childhood.\" \"That's rather a broad idea,\" I remarked. \"One's ideas must be as broad as Nature if they are to interpret Nature,\" he answered. - A Study in Scarlet, Arthur Conan Doyle A few weeks back, while browsing Hacker News’ second chance pool, I came across a 2014 blog post from Spotify discussing how to shuffle songs. Now, at first glance, you might think, “How challenging could it be to shuffle songs in a playlist? Can we not randomly shuffle them out?” You see, that’s precisely the approach Spotify initially took. They used the Fisher–Yates shuffle to do this. Say you have five songs from three artists, as illustrated in the figure below: Figure 1: 5 songs from 3 artists in a playlist The modern implementation of Fisher–Yates shuffle is an 𝑂 ( 𝑛 ) time algorithm and can be described as follows: To shuffle an array 𝑎 of 𝑛 elements (indices 0. . 𝑛 − 1 ): For 𝑖 from 𝑛 − 1 down to 1 do 𝑗 ← random integer such that 0 ≤ 𝑗 ≤ 𝑖 exchange 𝑎 [ 𝑗 ] and 𝑎 [ 𝑖 ] Using the figure above, we can visualize the algorithm: Figure 2: Fisher Yates Shuffle Now, this was all fine for the Sweden-based team till they faced a fascinating issue. In their words: ..... We noticed some users complaining about our shuffling algorithm playing a few songs from the same artist right after each other. The users were asking “Why isn’t your shuffling random?”. We responded “Hey! Our shuffling is random!” At first we didn’t understand what the users were trying to tell us by saying that the shuffling is not random, but then we read the comments more carefully and noticed that some people don’t want the same artist playing two or three times within a short time period. ..... If you just heard a song from a particular artist, that doesn’t mean that the next song will be more likely from a different artist in a perfectly random order. However, the old saying says that the user is always right, so we decided to look into ways of changing our shuffling algorithm so that the users are happier. We learned that they don’t like perfect randomness. Fascinating indeed! To create an illusion of randomness - randomness with artists evenly spread throughout the playlist - the engineers drew inspiration from a 2007 blog-post by Martin Fiedler. Fiedler’s algorithm is divided into two parts: the merge algorithm and the fill algorithm. Initially, the songs to be shuffled are categorized based on their artist. For instance, assume that we now have three artists and ten songs in our playlist. Then, Figure 3: Categorization step in Fiedler’s algorithm using 10 songs from 3 artists. The fill algorithm aims to distribute dummy tracks evenly among shorter categories to match the length of the longest one. This step is followed by the merge algorithm, which combines tracks from different categories to form a single playlist in a column-wise fashion. For example, with the categories mentioned earlier, the fill algorithm would: Figure 4: Fill algorithm in Fiedler’s algorithm Subsequently, the merge algorithm would create a final playlist as follows: Figure 5: Merge algorithm in Fiedler’s algorithm While this method distributes the songs quite efficiently, as mentioned by Spotify, it is complicated and potentially slow in certain scenarios, particularly due to the numerous randomization operations. Spotify suggested drawing inspiration from existing dithering algorithms, like Floyd–Steinberg dithering, to spread each artist as evenly as possible. Although they don't provide specific details of their algorithm, the basic concept they describe is as follows: Let’s say we have 4 songs from The White Stripes as in the picture above. This means that they should appear roughly every 25% of the length of the playlist. We spread out the 4 songs along a line, but their distance will vary randomly from about 20% to 30% to make the final order look more random. We introduce a random offset in the beginning; otherwise all first songs would end up at position 0. We also shuffle the songs by the same artist among each other. Here we can use Fisher-Yates shuffle or apply the same algorithm recursively, for example we could prevent songs from the same album playing too close to each other. After reading Spotify’s blog post, an idea struck me! You see, a year ago, I wrote a small library to generate aesthetically pleasing colors in the HSV (hue, saturation, value) space. Figure 6: HSV color space. This image is licensed under CC BY-SA 3.0. But how do we define \"aesthetically pleasing colors\"? And what's the connection to shuffling algorithms? Let's consider an example where we need to pick five colors to label a chart. Choosing these colors randomly from the RGB space can be quite problematic. Some colors, especially on darker backgrounds, can make text hard to read. Moreover, it is possible to end up with colors that are too similar to each other. Addressing the issue of dark or light backgrounds turns out to be relatively straightforward – avoid the RGB space and instead, use the HSV space with fixed saturation and value. However, even then, there's a high chance of selecting colors that are too close on the color spectrum. In other words, the selection can be too random, and we might prefer colors that are distributed as evenly as possible across the entire color spectrum. To achieve this, my library employed Fibonacci hashing. The algorithm I implemented was proposed by Martin Leitner‑Ankerl. It utilizes the reciprocal of golden ratio: Φ − 1 = 5 − 1 2 ≈ 0.618033988749895 As Martin explains in his blog, one of the intriguing properties of the golden ratio is that each subsequent hash value divides the interval into which it falls in accordance with the golden ratio! To better understand Fibonacci hashing, let us explore it through the perspective of Donald Knuth’s The Art of Computer Programming, Volume 3. The foundation of Fibonacci hashing is based upon the three-distance theorem. This theorem states: Suppose 𝜃 is an irrational number. When the points 𝜃 , ( 2 ∗ 𝑡 ℎ 𝑒 𝑡 𝑎 ) , ….., ( 𝑛 ∗ 𝑡 ℎ 𝑒 𝑡 𝑎 ) are placed on a line segment ranging from 0 to 1 (inclusive), the 𝑛 + 1 line segments formed will have at most three distinct lengths. Furthermore, the next point ( ( 𝑛 + 1 ) ∗ 𝑡 ℎ 𝑒 𝑡 𝑎 ) will fall into one of the largest existing segments. Consider the largest existing segment, spanning from 𝑎 to 𝑐 (inclusive), being divided into two parts: 𝑎 to 𝑏 and 𝑏 to 𝑐 . If one of these parts is more than twice the length of the other, we call this division a bad break. Using the three-distance theorem, it can be shown that the two numbers Φ − 1 (the reciprocal of golden ratio!) and 1 − Φ − 1 lead to the most uniformly distributed sequences among all numbers 𝜃 between 0 and 1 . In other words, a break break will occur unless Φ − 1 or 1 − Φ − 1 are used. Using the theory described above, we can now define Fibonacci hashing. However, before diving into that, it is important to first understand multiplicative hashing. Multiplicative hashing involves multiplying a key 𝐾 by a constant 𝛼 . The fractional part of this product is then used to determine the index in a hash table. Fibonacci hashing is a specific variant of multiplicative hashing where the constant 𝛼 is set to be the reciprocal of the golden ratio Φ − 1 . And that’s it! We can start at a random hue value between 0 and 1 (this will be our initial key 𝐾 1 ) and use the Fibonacci hashing from that point to evenly select colors on the color spectrum. Figure 8: Colors generated using Fibonacci hashing. So how can we apply all of this to shuffle songs? Well, the algorithm I came up with is as follows: Categorization Function: Let 𝑆 be the set of all songs in the playlist. Define a categorization function 𝐶 : 𝑆 → 𝐴 , where 𝐴 is the set of artists. This function assigns each song in 𝑆 to an artist in 𝐴 . Shuffle Songs per Artist: For each artist 𝑎 ∈ 𝐴 , shuffle the subset of 𝑆 where 𝐶 ( 𝑠 ) = 𝐴 for all 𝑠 in the subset. Shuffle Artist List: Let 𝐴 ′ be the list of all artists. Apply a random permutation 𝜋 to 𝐴 ′ . Initialize Playlist 𝑃 : Let 𝑃 be an empty list that will store the final shuffled songs. Set Parameters: Initialize 𝐾 = 1 and let 𝑁 =𝐴(the total number of artists). Select Artist Index: Compute the index 𝐼 = ⌊ ( ( 𝐾 ∗ 0.618033988749895 ) % 1 ) ∗ 𝑁 ) ⌋ . Add Songs to 𝑃 : Remove the first song from the list of songs corresponding to the artist at 𝐴 ′ [ 𝐼 ] and append it to 𝑃 . Update Parameters: Increment 𝐾 by 1. Update Artist List: If the artist at 𝐴 ′ [ 𝐼 ] has no remaining songs, decrement 𝑁 by 1 and remove the artist from 𝐴 ′ . Loop Through: Repeat steps 6 to 9 until 𝐴 ′ is empty. When empty, return 𝑃 . Figure 9: An illustration of the above algorithm for shuffling songs using Fibonacci hashing. If we use a hash table in the categorization function and an array to store the list of all artists, then the overall time complexity of the algorithm would be 𝑂 ( 𝑆 ) . To compare this algorithm against the naive Fisher-Yates shuffle, I used a measure that calculates the ratio of the count of adjacent song pairs by the same artist to the total number of songs in the playlist minus one. That is, def measure(shuffled_songs): clusters = sum( 1 for i in range(len(shuffled_songs) - 1) if shuffled_songs[i][‘artist’] == shuffled_songs[i + 1][‘artist’] ) return clusters / (len(shuffled_songs) - 1) When the playlist contains songs only from one artist, this measure will be 1. Conversely, when no adjacent song pairs are by the same artist, the measure will return 0. Using fuzzy testing on a maximum of ten artists, with each having up to ten songs, I generated a million playlists and calculated the statistics for the above algorithm (A) and the fisher-yates shuffle (B). The results were as follows: A - Mean: 0.11831, Median: 0.05263, Mode: 0.0, p25: 0.02040, p75: 0.14814, p90: 0.33333, p95: 0.5 B - Mean: 0.23296, Median: 0.18181, Mode: 0.33333, p25: 0.12121, p75: 0.29629, p90: 0.46666, p95: 0.58333 At first glance, the p95 result might seem surprising. However, this occurs in cases where the fuzzy testing populates a playlist predominantly with songs from a single artist, rendering optimal shuffling infeasible. When a minimum of four songs per artist were used, the results were: A - Mean: 0.05948, Median: 0.03703, Mode: 0.0, p25: 0.01694, p75: 0.07843, p90: 0.14285, p95: 0.2 B - Mean: 0.17223, Median: 0.15555, Mode: 0.2, p25: 0.10909, p75: 0.21875, p90: 0.29268, p95: 0.34482 The results look decent. I’d expect Fiedler’s algorithm to have a near-zero mean, however, the simplicity and speed of the above algorithm does look appealing to me. And that’s it folks! I hope you enjoyed this little journey. Happy exploring! Addendum Recently, I was exploring the “History” section in Knuth’s TAOCP volume 3 to trace back the history of hashing. In it, Knuth states that: The idea of hashing appears to have been originated by H. P. Luhn, who wrote an internal IBM memorandum in January 1953 that suggested the use of chaining; in fact, his suggestion was one of the first applications of linked linear lists. Unfortunately, I couldn't locate the memo. It seems they never made it public. However, I stumbled upon a nice paper from 1953 in which he discusses enhancing search engines by refining sets. Knuth also references Arnold I. Dumey, who appears to be the first to describe hash tables in open literature. I was able to retrieve his paper . Dumey initiates with an 𝑂 ( 𝑙 𝑜 𝑔 𝑛 ) solution using the \"twenty questions\" game, subsequently explaining how we'd be better off if we could do computation before we access the memory. I found his introduction to the hash function rather intriguing: A certain manufacturing company had a parts and assemblies list of many thousands of items. A mixed digital and alphabetic system of numbering items was used, of six positions in all. Eight complex machines or assemblies were sold to the public. These had item numbers taken from the general system. In setting up a punch card control system on these eight items it was first proposed to record the entire six digit number for each item. However, examination of the eight assembly numbers disclosed that no two were alike on the fourth digit. It was therefore sufficient, for sorting purposes, merely to record the fourth digit, thereby releasing five badly needed information spaces for other purposes. This rather extreme case indicates that an examination of the item description may disclose a built-in redunancy which can be used to cut the field down to practical size. He further discusses handling duplicates and introduces chaining: Adjust the addressing scheme, according to a method which will be described later, to reduce the number of direct addresses, and use the excess locations to store overflows. Put the overflow address at the tail end of stored item information. What the best reduction is varies from case to case. Note that the expectation of the number of accesses to be made goes up when these methods are used. At each access we check by using the complete item description, usually. And discusses how a somewhat efficient hash address can be constructed by dividing a prime number and using the remainder: Consider the item description as though it were a number in the scale of 37 or whatever. Or write it as a binary number by using the appropriate punched tape coding. Divide this number by a number slightly less than the number of addressable locations (the writer prefers the nearest prime). Throw away the quotient. Use the remainder as the address, adjusting to base 10, as the case may be. ← © 2023 Parth Parikh.",
    "commentLink": "https://news.ycombinator.com/item?id=38581959",
    "commentBody": "Scrambling eggs for Spotify with Knuth&#x27;s Fibonacci hashingHacker NewspastloginScrambling eggs for Spotify with Knuth&#x27;s Fibonacci hashing (pncnmnp.github.io) 135 points by pncnmnp 20 hours ago| hidepastfavorite43 comments bazzargh 17 hours agoThe fibonacci hashing mentioned here looks to be just Kronecker low-discrepancy sequences https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Low-discrepancy_sequence#Addit... which is used for dithering too (see eg https:&#x2F;&#x2F;extremelearning.com.au&#x2F;unreasonable-effectiveness-of...). It&#x27;s quite likely already what Spotify were obliquely referring to. But I think the author missed a trick: tracks by an artist occur close together if your collection is already arranged by artist&#x2F;album. Picking tracks far apart from the globally sorted list is what this sequence will do, and do you don&#x27;t need to do anything at all to split by artist&#x2F;album&#x2F;category etc:1. for the Kth track in a sorted collection of N with seed S in [0,1), pick track number floor(N((K(phi-1)+S)%1)).2. There is no step 2.Since Spotify suggest their algorithm is only a couple of lines, I&#x27;d guess this is what they did.edited to add: the above would get pretty boring because songs would always follow one another in sequence, no matter what the seed was. But since the chance of picking an irrational number at random in a real interval is a near certainty (because rationals are countable and reals are uncountable) you can just pick any new random number as the stepsize in the sequence when you start to shuffle play and it should be good enough; picking in [.25, .75) avoids steps that take you back too close to the same artist. reply pncnmnp 16 hours agoparentThis is fantastic! I still need to carefully study it all, but I implemented the idea you described in the original comment. It seems the error lies somewhere between the algorithm I mentioned and the Fisher-Yates shuffle, based on one million playlists: Mean: 0.13, Median: 0.11, Mode: 0, p25: 0.06, p75: 0.18, p90: 0.26, p95: 0.31.It&#x27;s possible I&#x27;m missing something here. Regarding your edit about &#x27;picking any new random number as the stepsize,&#x27; wouldn&#x27;t it be affected by a &#x27;bad break,&#x27; as mentioned by Knuth? I still need to work out the &#x27;bad break&#x27; proof.Edit: If it helps, here is the code I used to test it out - https:&#x2F;&#x2F;gist.github.com&#x2F;pncnmnp&#x2F;8afb7903f61ec69a157287435a63... reply bazzargh 15 hours agorootparentI don&#x27;t have Knuth to hand...but yeah it is possible you can accidentally pick a number that is too close to a rational, so you get short repeats of tracks instead of long ones. What you&#x27;re after is a number with a high approximation coefficient https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Liouville_number#Irrationality... but in practice you just need to know that it is irrational \"enough\", eg you might want to avoid repeats in the first 1000 plays.You can get that by rejection sampling on the random number and using the Farey sequence to find nearby low-denominator fractions https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Farey_sequence#Applications - if I pick a number between 0 and 1 I can use 0&#x2F;1, 1&#x2F;1 as the starting point for the usual iteration. (and then scale to .25,.75 at the end). You pick your approximation bound mu and reject if log(abs(p&#x2F;q - x)) > - mu log q, repeat the farey iteration until q is large enough. (just making this up as I go on an ipad, I may have a sign wrong in there or whatever)It is actually much simpler than this ^ to just explicitly check the first 1000 numbers for a loop. It&#x27;s simpler than tortoise and hare: you know there is no run-in, so the first number is in the loop, and you want that number to not reappear in the first min(N,1000) items. reply HelloNurse 16 hours agoparentprevThe problem is separating tracks in the same group. If the globally sorted reference list of N songs has M consecutive entries that we want to spread evenly, they should be \"shuffled\" at increments of floor(N&#x2F;M) or 1+floor(N&#x2F;M): easy to guarantee with tortured recursive constructions like the one that opens the article, less obvious with a hash function that is affected by floating point approximations.An integer formula that is more obvious to work: starting from any number between the maximum group size and (if larger) N&#x2F;phi, pick an increment D as the next larger or smaller integer that has no common factors with N (to ensure full period) and map index K to index (S+K*D)%N. reply jameshart 9 hours agoparentprevTo avoid the fixed cycle problem, for each shuffle, choose a seed, then sort by hash(artist + seed) + hash(album + seed) instead of just artist + album before you start jumping through the list using fibonacci hashing. Album tracks and artists still end up colocated, but their position in the list is randomized. reply jorjordandan 16 hours agoprevI was a tile installer in a previous life, and occasionally a customer would make the dreaded request to have an accent tile placed &#x27;randomly&#x27; throughout a backsplash. They were never happy with the placement, and clearly had no understanding of randomness. Generally what they actually wanted was &#x27;evenly distributed&#x27;. I remember one particular customer kept changing the accent tiles and moving them until they converged upon a very specific pattern throughout the back splash except for one tile that was out of the pattern, that they kept &#x27;wrong&#x27; out of some ego driven desire to justify their request for randomness. reply plagiarist 12 hours agoparentThe perfect pattern with one wrong tile is so awful. It&#x27;s a fair punishment that they have to live with that.I want those non-repeating pattern tiles, how awful would those be to tile? reply j4yav 17 hours agoprevI have a playlist with 150 hours of music on it and it seems to play the same five or six songs every day, no matter what. I wish I could choose \"actually random\", I wouldn&#x27;t mind unexpected clustering. reply crazygringo 17 hours agoparentSame. Out of 5,000 songs, am I really supposed to be hearing certain songs 3+ days in a row, when I&#x27;m only listening to 20 songs a day...?I can&#x27;t tell if it&#x27;s:- Certain artists are paying Spotify to favor them in randomization?- There&#x27;s some kind of shared random seed across devices that results in picking a tiny subset of songs to randomize from in the first place?- Other?I do notice that the effect seems to persist for maybe a week, then I&#x27;ll never hear those songs again, but now it&#x27;ll be different songs that keep popping up repeatedly.There&#x27;s a related effect when you launch a radio station based on an artist or track. If you launch it multiple times in the same day or week, you get the exact same list of tracks. But maybe a week later the tracks have changed, like the radio has been recalculated based on a different random seed. reply cvoss 14 hours agorootparentThere&#x27;s maybe some counterintuitive math going on here.If you have 100 songs and listen to 1 song per day (which is 1% of the library), on any given day your odds of hearing the same song as yesterday are 1 in a 100.If you have 1000 songs and listen to 10 per day (still 1%), the odds of hearing a song that was also played yesterday are a little less than 1 in 10, right?So what matters is not only what fraction of your library&#x27;s play time you sample daily, but also how finely subdivided the time is into individual tracks for sampling. reply crazygringo 12 hours agorootparent> If you have 1000 songs and listen to 10 per day (still 1%), the odds of hearing a song that was also played yesterday are a little less than 1 in 10, right?No. It&#x27;s 10*(1&#x2F;1000)=1%.It&#x27;ll happen a few times a year only. reply nemetroid 8 hours agorootparentThe odds of hearing a specific song that was played yesterday is ~1%, the odds of hearing any song that was played yesterday is ~10%. reply brasetvik 14 hours agorootparentprevA bit of birthday paradox too? :) reply candiddevmike 16 hours agorootparentprevThis article is pretty insightful on the ways artists can improve their presence on Spotify, including images of the backend tools available to artists: https:&#x2F;&#x2F;blog.groover.co&#x2F;en&#x2F;tips&#x2F;spotify-streams&#x2F; reply hifreq 15 hours agorootparentI was excited to get an insight into some hidden backend tools but it seems like this post is just about playlists (creating your own playlists, paying for placements in other people&#x27;s playlists), and ads? reply mrkeen 17 hours agoparentprevOut of curiosity, does it happen on some clients and not others?I remember hearing of a bug where if you played on a remote device, it would transfer the first part of your playlist (10? 100 tracks?), and then shuffle would only choose from among them.But it&#x27;s been 5+ years so things may have changed and&#x2F;or I could be remembering completely wrong. reply hifreq 15 hours agorootparentThat might be true, but my impression is that the algorithm is weighted, so some artists (more popular in general, recommended, played more often by that individual user, would get picked more frequently by the \"random\" algorithm). reply mcmoor 4 hours agoparentprevThe effect is so strong that 3 of those songs become my top 5 listened despite me not actually wanting to listen to those songs THAT much reply hifreq 15 hours agoparentprevAs far as I can tell all Spotify&#x27;s playlists (in all forms, e.g. including \"random\" and \"track radio\") use weighted algorithms based on several factors like user&#x27;s play history, Spotify&#x27;s recommendations (probably includes paid promotions), general artist&#x27;s popularity, etc.When I still used Spotify, I would get a dozen of my favorite artists mixed into basically any \"playlist\" I pick. Was one of the reasons I quit Spotify - they are too opinionated on what I should listen to. reply Solvency 17 hours agoparentprevIt&#x27;s absolutely wild. I have over 50 playlists I&#x27;ve made, some over 10 hours long with no repetitions anywhere. I have extremely thorough and diverse music interests and habits dAnd yet, when Spotify&#x27;s shit tier algorithm takes over, it kicks me into a similar 5 to 6 meme set of songs every single time. It&#x27;s an absolute joke. reply varispeed 17 hours agoparentprevI wonder if this is market manipulation and not a honest mistake. To make certain labels and artists more money. reply esafak 16 hours agoparentprevIt might think you really like those songs. I listen to my favorites every day, among others. reply at_a_remove 12 hours agoparentprevEh, unexpected clustering is sort of okay but again, it&#x27;s what people respond to versus what they think they will. I&#x27;ve written some scripts so I can dredge playlists off of some radio stations that are hooked up to the Internet as part of a quixotic little project of mine and I&#x27;ve gone through, looked for dupes, etc. Let&#x27;s say we&#x27;re doing new wave (sure to start an argument there). What people seem to dislike is ABC, The Buggles, the Cure, Duran Duran, Ebn Ozn, Fra Lippo Lippi, Duran Duran, etc. Just having a gap between there feels insufficiently random.Clustering apparently ought to feel deliberate. Now think back to when you had actual DJs selecting tracks on the radio. One of the techniques was \"Two from a particular band.\" Not two from a band with some tracks between them.Similarly, one can do a \"Four tracks from 1994\" to provide a cluster in time, another technique I&#x27;ve heard.If anything, the more metadata you have, the more you can provide short runs of something. Microgenres, for example. reply ruuda 1 hour agoprevI was nerd-sniped by shuffling playlists a while back too and came up with this algorithm: https:&#x2F;&#x2F;ruudvanasseldonk.com&#x2F;2023&#x2F;an-algorithm-for-shuffling.... I&#x27;ve been using it since, my experience at this point is that the interleaving — although it does an optimal job of not playing the same artist twice in a row — is maybe a bit too non-random. reply galdosdi 16 hours agoprevThis entire HN thread reads like some fiction made up by a free software activist 15 years ago, as a dystopian cautionary tale. It&#x27;s all complaints and speculations about stuff that just worked back then.Back then we had our music locally and we chose our own players, of which there were many and easy to make another one. Actually, hacking on music playback was easy and not uncommon. We had full control of our musical lives. reply pncnmnp 11 hours agoparentTangentially, I encourage everyone to check out Ken Thompson&#x27;s talk on his jukebox: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kaandEt_pKw reply Tao3300 12 hours agoparentprevScrambx0red 3ggs by Cory Doctorow (2002) reply 2143 2 hours agoprevI&#x27;m convinced something&#x27;s wrong with Spotify&#x27;s randomization.When I press the big green play button in a playlist&#x27;s page, it tends to start playing from a specific song, in a weirdly familiar order. So I manually pick a song at random and let it play from there.But even so, some songs almost never get played, but others get played fairly frequently. reply justsayinginnt 17 hours agoprevShame we can’t choose the type of shuffle, based on your mood&#x2F;what you’re listening too (not to add even more complexity).e.g. For classical music I’d prefer stringing together pieces from the same orchestra&#x2F;composer. But for some contemporary music would like mix the artist&#x2F;album up more. reply morkalork 17 hours agoparentI&#x27;d like one that on random and uses each song as an experiment to determine your mood. If you listen through that&#x27;s positive, instantly skip? That&#x27;s a negative signal. Just adapt on the fly at the beginning of each listing session. reply passion__desire 14 hours agorootparentBased on your comment, I would love to see a feature just as we have a prompt travel in image generations, how about genre travel? A playlist of 10 songs taking me from rock to french house. reply passion__desire 14 hours agoparentprevI am not sure if the situation I describe is currently in production in Instagram.But here&#x27;s what I noticed when I went to the explore section of Instagram.At display, there would be distinct choices of images and reels, varied and related to my interests. But if I select a particular reel&#x2F;image type (e.g. animation or comics or 3d render), it would take that as a signal and would expand the feed based on that selection. I love that feature.I guess Spotify Radio do that to some extent, not sure. reply esafak 16 hours agoparentprevThe song radio does that. Really well in my experience. reply jdontillman 15 hours agoprevThere was a delightful Usenet post way back around 1990, where someone described how they had just purchased a new multi-CD player. They very excitedly filled it up with their collection of Prince CDs, and set it to random shuffle play mode.Great for a while, but then they complained that all the slow songs were bunched together. And perhaps the random shuffle play mode was sampling the songs, deriving the tempo of each, and adjusting the shuffle accordingly.Very funny.---Heh-heh, I independently came up with Fibonacci hashing for color many years ago.My web app was drawing a diagram of N rectangular items, color-coded to tell them apart, with a table listing the details of each below.(Normally I would use EIA standard colors, with a nod to my EE brethren.)But I didn&#x27;t want the colors to bias anything. So you&#x27;d normally try random colors. But random colors can come out weird and some can be close together.So I used a Golden Angle around the hue circle, with a constant brightness and saturation. And sure enough, the generated colors were nicely differentiated.BUT... not as nice as I&#x27;d like. Something was wrong.It turns out that our perception of color is more complex. And when we&#x27;re differentiating between colors, it really, really helps if the colors are familiar, and describable.So simple colors like blue and purple are much easier to differentiate than a new weird blueish color and a new weird purplish color.So my Golden Angle colors were technically superior, but not as good a user experience. reply crazygringo 17 hours agoprevMy biggest desire for Spotify would be the ability to randomize a playlist but give massive priority to your least-listened songs.So if you have a playlist with 10 songs A-J that you&#x27;ve listened to 10 times each. And then you add 10 new songs K-T that you&#x27;ve listened to 1 time each... Then every time I shuffle the playlist, I want songs K-T to be the first 10 songs in random order until I&#x27;ve played them 10 times each.I mean, things can be mixed up a little more than that... but generally speaking, I want to listen to my least-listened songs much more than the ones I&#x27;ve been listening to forever. But I don&#x27;t want to have to separate them out into special playlists \"newest\", \"newer\", \"kinda new\", \"old\", \"oldest\" which is annoying. reply world2vec 15 hours agoprevSlightly unrelated but just learned about Hacker News pool. Very interesting. reply darepublic 10 hours agoprevI wouldn&#x27;t mind the same artist a couple of times in a row. It&#x27;s what I would arrange for myself, just that the mood of the song being consistent with the theme is important reply fetzu 17 hours agoprevSpotify’s shuffling is so god-tier bad that I would be flabbergasted if it wasn’t biased towards songs with less royalties to pay out.. reply brcmthrowaway 11 hours agoprev [–] What did the ipod shuffle use? reply pncnmnp 11 hours agoparent [–] Hi, author here! Interesting question!Martin Fiedler briefly addresses this topic in a comment on his blog post about shuffling algorithms (https:&#x2F;&#x2F;keyj.emphy.de&#x2F;balanced-shuffle&#x2F;)> Apple has a so-called “smart shuffle” algorithm, but this merely puts higher-rated tracks in front of lower-rated ones. So basically, it’s just random shuffle, followed by a sort-by-rating operation. I don’t know of any product (software or hardware) that uses some kind of smart, balanced or whatever-you-like-to-call-it shuffle based on the principles I described in the text.I&#x27;m not sure what they are using today. reply batch12 9 hours agorootparent [–] What kind of categorization did they use to keep it from just becoming a sort? By artist? reply pncnmnp 8 hours agorootparent [–] I just found this 2009 research paper written by a group of statisticians titled &#x27;Does Your iPod Really Play Favorites?&#x27; (https:&#x2F;&#x2F;www.researchgate.net&#x2F;profile&#x2F;Jessica-Culhane&#x2F;publica...).In this paper, they test different probability models to detect bias in iPod&#x27;s shuffling algorithm and eventually conclude that:> Our statistical tests show the long-term occurrences of these events are within expectations under the assumption of a random shuffle.\"Regarding sorting by artists or groups, they found that:> We failed to find any evidence to support the claim of users like Steven Levy of favoritism of certain groups in the shuffle. reply batch12 4 hours agorootparent [–] No, I mean if you order from most to least popular it&#x27;s always the same. Did they pick a random artist then sort the artist&#x27;s tracks by popularity? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This blog post delves into Spotify's initial approach to shuffling songs in a playlist, and the problem they encountered with consecutive songs by the same artist.",
      "Spotify modified their shuffling algorithm to evenly distribute artists throughout the playlist by implementing dithering algorithms.",
      "The author explores a method for selecting colors using the HSV space and applies the Fibonacci hashing algorithm to evenly distribute colors.",
      "The post discusses an algorithm for shuffling songs based on artists and compares it with the Fisher-Yates shuffle.",
      "Fiedler's algorithm, the history of hashing, and the use of hash functions to reduce stored item information are also covered.",
      "The post concludes by suggesting the conversion of a number into binary format and dividing it by a prime number to determine an address."
    ],
    "commentSummary": [
      "Users are frustrated with the lack of randomness and repetition in music playlists on Spotify.",
      "Suggestions are made for improving the playlist algorithm, such as using different shuffling techniques, clustering options, and customization features.",
      "Speculation arises about the motivations behind song repetition and the possible influence of financial interests."
    ],
    "points": 135,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1702130417
  },
  {
    "id": 38585213,
    "title": "Sneakers Film Promo Kit: Password-Protected Floppy for Media",
    "originLink": "https://archive.org/details/Sneakers_Film_Promotional_Floppy",
    "originBody": "Sneakers Computer Press Kit Emulation Item Preview remove-circle Share or Embed This Item Share to Twitter Share to Facebook Share to Reddit Share to Tumblr Share to Pinterest Share via email EMBED EMBED (for wordpress.com hosted blogs and archive.org itemtags) Want more? Advanced embedding details, examples, and help! Favorite Share Flag Flag this item for Graphic Violence Explicit Sexual Content Hate Speech Misinformation/Disinformation Marketing/Phishing/Advertising Misleading/Inaccurate/Missing Metadata software Sneakers Computer Press Kit by Universal City Studios Publication date 1992 Topics Sneakers Promotional Floppy Language English Released in conjuction with the computer hacking movie \"Sneakers\" (1992), this floppy-based \"computer press kit\" contained many of the aspects of regular movie press kits, including cast bios, plots, and information on all aspects of production. It was intended for press, and as such is both \"locked up\" (via passwords) but also endeavored to help the same press get through the barriers as quickly as possible. The balancing act between technical complexity and simplicity to ensure promotion is quite notable. The program in question is DOS-based, and was released in 1992 as part of a package of both written and computer-based information. This floppy is from the collection of Marcin Wichary. Addeddate 2017-07-12 23:12:12 Emulator dosbox Emulator_ext zip Emulator_start SNEAKERS.EXE Identifier Sneakers_Film_Promotional_Floppy Identifier-ark ark:/13960/t7qp1w262 Scanner Internet Archive HTML5 Uploader 1.6.3 Year 1992 plus-circle Add Review comment Reviews There are no reviews yet. Be the first one to write a review. 3,374 Views 18 Favorites DOWNLOAD OPTIONS download 1 file ANIMATED GIF download download 2 files EMULATOR SCREENSHOT Uplevel BACK 505.1K Sneakers_Film_Promotional_Floppy_screenshot.gif download 203.2K press_package.jpg download download 1 file ISO IMAGE download download 1 file ITEM TILE download download 3 files JPEG Uplevel BACK 192.8K DD_N0NGV0AAJ52O.jpg download 123.7K DD_NyIbUQAA1cOU.jpg download 203.2K DD_NzOnVYAApt6Z.jpg download download 16 files PNG Uplevel BACK 26.1K 00_coverscreenshot.png download 22.0K screenshot_00.png download 22.7K screenshot_01.png download 22.7K screenshot_02.png download 23.7K screenshot_03.png download 24.0K screenshot_04.png download 26.1K screenshot_05.png download 24.2K screenshot_06.png download 8.0K screenshot_07.png download 7.9K screenshot_08.png download 4.7K screenshot_09.png download 2.6K screenshot_10.png download 3.1K screenshot_11.png download 3.4K screenshot_12.png download 17.5K screenshot_13.png download 19.7K screenshot_14.png download download 1 file TORRENT download download 1 file ZIP download download 48 Files download 29 Original SHOW ALL IN COLLECTIONS Software Library: MS-DOS Games The Software Library: MS-DOS Software Library Uploaded by Sketch the Cow on July 12, 2017 SIMILAR ITEMS (based on metadata) Terms of Service (last updated 12/31/2014)",
    "commentLink": "https://news.ycombinator.com/item?id=38585213",
    "commentBody": "Sneakers Film Promotional FloppyHacker NewspastloginSneakers Film Promotional Floppy (archive.org) 129 points by dcminter 14 hours ago| hidepastfavorite36 comments ranting-moth 11 hours ago1992. It was relatively safe to run an .exe from a reputable company. Surely a reputable company wouldn&#x27;t mess with your computer.2005. I&#x27;m playing this music CD in my computer. Sony: hang on, I&#x27;m install a rootkit on your computer without your knowledge. reply sillywalk 8 hours agoparent2023. HP: Our printers are made to be less hated reply nullc 4 hours agoparentprevBecause you didn&#x27;t have an internet connection there was little they could to that would benefit them, not so much anymore.(FWIW, in the 90&#x27;s there were a few instances where commercially produced software managed to go out carrying viruses. :( ) reply Kye 1 hour agorootparentViruses propagated just fine through BBSes and stuff like AOL and CompuServe. Also: sharing disks. reply KennyBlanken 8 hours agoparentprev2017: Open source web browser company silently to users, not even any discussion on bugzilla or anywhere else - installs a plugin made by an advertising company for a media conglomerate&#x27;s TV show about hackers into everyone&#x27;s Firefox installations.The project manager responsible who used to work in the advertising industry tries to damage-control things and locks&#x2F;hides the ticket. Another mozilla staffer unlocks&#x2F;unhides it and states it was improperly hidden&#x2F;locked.The ticket is then made uber-double-super-secret so that not even mozilla staff can view it: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1423003Other tickets about it are locked because of \"off topic comments.\"Coverage: https:&#x2F;&#x2F;www.theverge.com&#x2F;2017&#x2F;12&#x2F;16&#x2F;16784628&#x2F;mozilla-mr-robo...Then there was the Cliqz incident:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;firefox&#x2F;comments&#x2F;74yo19&#x2F;cliqz_and_m...They actively worked to hide the plugin&#x27;s true nature: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1392855#c5Cliqz was a division of Burda Media. reply wslh 12 hours agoprevOne of the best hacker movies ever. The involvement of Leonard Adleman (the A in RSA) in the movie [1].He said: \"I would do the scene if my wife Lori could meet [Robert] Redford\"[1] https:&#x2F;&#x2F;molecularscience.usc.edu&#x2F;sneakers&#x2F; reply lll-o-lll 11 hours agoparentThanks for that, it’s interesting. It seems that his involvement was just for the one lecture scene though? The movie itself is chock full of references to nerd, hacker, conspiracy, and security knowledge. Anyone know how they did all the research for this film? reply rhplus 3 hours agorootparentThe screenwriters Lawrence Laskar and Walker Parkes talk about the research for Sneakers and War Games on a recent episode of Star Talk with Neal DeGrasse Tyson:https:&#x2F;&#x2F;startalkmedia.com&#x2F;show&#x2F;how-storytelling-prevented-nu... reply djbusby 11 hours agorootparentprevMany writers&#x2F;studios get a technical consultant. Sometimes your writer friend will ask for help, other times you&#x27;ll get an introduction from some VFX house you&#x27;re working for and others it&#x27;s your wife&#x27;s-friends-husbands-boss. reply sillywalk 2 hours agorootparentTwo Chiefs of Staff of the United States Air Force guest starred in Stargate SG-1, General Michael E. Ryan and General John P. Jumper,while SG-1 was getting technical advice from Air Force Entertainment Liaison Office. reply nullc 2 hours agorootparentprevHow much they listen to their consultants differs a lot, and it shows in the production output. reply lll-o-lll 11 hours agorootparentprevI’d love to watch the directors commentary, but it looks like I need to get some legacy media for that. reply NoLsAfterMid 9 hours agorootparentI have a pretty high quality blu-ray, it&#x27;s not just on legacy media.EDIT: it occurs to me that \"legacy media\" means \"not available through streaming&#x2F;rental services&#x2F;stores\", my bad. reply pimlottc 8 hours agorootparentYou could argue it&#x27;s legacy media if you can pass it on to your descendants... reply toast0 6 hours agorootparentAs always, legacy means \"it makes money and it works and it has customers\", as opposed to the new thing that may or may not work or make money. reply lll-o-lll 2 hours agorootparentlol. I sent that post and didn’t think twice about it, but of course you are right! I’ve started to think of physical media as “legacy”, but it is not of course! replypatcon 9 hours agorootparentprevFor example, Silicon Valley, had a handful of co-producers who went to niche tech conferences like dweb camp and got attendees on consulting contracts for the upcoming seasons they were writing.I presume the conference circuit was still where they picked up the contacts in 1992Coincidentally, staff of the internet archive co-produced and sponsored dweb camp :) reply nullc 4 hours agoparentprevI transcribed the great number theory jargon from the film-- which your link describes but fails to include in its entirety-- in this post: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31379273 reply ddingus 8 hours agoprevI love this movie. Frankly, it holds up pretty well.Yes, the tech is dated, but it is the right tech to support the story, which is not dated much at all.And what a cast!Epic film, and one I tend to watch a few times per year. reply somat 1 hour agoparentThat first scene in the phone trunk is still probably the best hacking scene in any movie. reply pbj1968 6 hours agoparentprevShould I call you or nudge you?I had to get a wiser roommate to explain that one. So naive. reply kstenerud 4 hours agoprevKinda reminds me of https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hacker_(video_game)The game has no instructions, and starts off with a password that you have to guess to continue. reply ecornflak 2 minutes agoparentYou don’t happen to remember the name of an Amiga game where you navigated a little robot around via CCTV while avoiding security guards, in order to break into a safe? reply seism 10 hours agoprevThis gem alone deserves a sizeable donation to the upkeep of the Internet Archive <3 reply wdr1 4 hours agoprevOne of the few movies with a mathematical consultant, Len Adleman.If the name sounds familiar, he&#x27;s the A in RSA. reply forgotmypw17 4 hours agoprevThe \"Print Full Press Kit\" button helpfully offers to print to LPT1, but I don&#x27;t have one. Has anyone succeeded in extracting that document? reply beej71 12 hours agoprevAwesome! Love this movie, and had no idea this existed. reply dcminter 12 hours agoparentSame - I just now discovered it existed; it was mentioned on the Sneakers wikipedia page and I just love that stuff like this has been archived. reply vlark 7 hours agoprevMy voice is my passport. Verify me. reply tanepiper 52 minutes agoparentHow prescient that scene is in some way - it&#x27;s so easy to clone voices now. reply sillywalk 2 hours agoparentprevCattle mutilations are up. reply sbarre 10 hours agoprevI remember downloading this from a BBS I think...I didn&#x27;t have an official floppy, I&#x27;m sure those were limited quantity, but the contents got around... reply pengaru 9 hours agoprevAre there any more modern film analogs of Sneakers with similar quality? Such a hard hitting cast... I still watch this movie at least once a year. reply ionwake 7 hours agoprevWeirdly I decided to download this to watch today reply bitwize 3 hours agoprevOh, man. It&#x27;s basically a diskmag. Very much in keeping with the theme of Sneakers, right down to its relative technical and communitarian realism in depicting hackers&#x2F;hacking. reply metabagel 10 hours agoprev [–] Love this movie. Great cast! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Sneakers Computer Press Kit is a promotional tool released in 1992 for the movie \"Sneakers\".",
      "It is a floppy-based \"computer press kit\" designed for press use, containing information on the cast, plot, and production.",
      "The program is password-protected and DOS-based, assisting the press in quickly accessing the provided information."
    ],
    "commentSummary": [
      "The post explores the movie \"Sneakers\" and its connection to real-world instances of unauthorized software installations by companies without user consent.",
      "It discusses the movie's technical accuracy, features, and makes references to other hacking-related movies and games.",
      "The post highlights the involvement of Leonard Adleman, a mathematician and co-creator of RSA encryption, as a consultant for the movie."
    ],
    "points": 129,
    "commentCount": 36,
    "retryCount": 0,
    "time": 1702151130
  },
  {
    "id": 38582000,
    "title": "Apple Shifts iPad Engineering to Vietnam, Reduces Dependence on China",
    "originLink": "https://asia.nikkei.com/Spotlight/Supply-Chain/Apple-to-move-key-iPad-engineering-resources-to-Vietnam",
    "originBody": "Your Account Account details Newsletters Group subscription Log out Log In Subscribe World China Japan India South Korea Indonesia Taiwan Thailand U.S. East Asia China Hong Kong Macao Taiwan Mongolia Japan South Korea North Korea Southeast Asia Indonesia Thailand Malaysia Singapore Philippines Vietnam Myanmar Cambodia Laos Brunei East Timor South Asia India Pakistan Afghanistan Bangladesh Sri Lanka Nepal Bhutan Maldives Central Asia Kazakhstan Uzbekistan Turkmenistan Tajikistan Kyrgyzstan Oceania Australia New Zealand Papua New Guinea Pacific Islands Rest of the World Middle East Russia & Caucasus North America Latin America Europe Africa Trending Israel-Hamas war COP28 Taiwan elections China debt crunch Inflation Supply Chain Ukraine war Taiwan tensions Explainer Business Business Semiconductors Automobiles Energy Transportation Retail Travel & Leisure Media & Entertainment Food & Beverage Finance Electronics Startups Markets Markets Market Spotlight Currencies Commodities Property IPO Bonds Wealth Management Tech Tech #techAsia China tech Startups 5G networks Cryptocurrencies DealStreetAsia 36Kr/KrASIA Politics Politics China Japan India South Korea Indonesia Taiwan Thailand U.S. East Asia China Hong Kong Macao Taiwan Mongolia Japan South Korea North Korea Southeast Asia Indonesia Thailand Malaysia Singapore Philippines Vietnam Myanmar Cambodia Laos Brunei East Timor South Asia India Pakistan Afghanistan Bangladesh Sri Lanka Nepal Bhutan Maldives Central Asia Kazakhstan Uzbekistan Turkmenistan Tajikistan Kyrgyzstan Oceania Australia New Zealand Papua New Guinea Pacific Islands Rest of the World Middle East Russia & Caucasus North America Latin America Europe Africa Economy Economy China Japan India South Korea Indonesia Taiwan Thailand U.S. East Asia China Hong Kong Macao Taiwan Mongolia Japan South Korea North Korea Southeast Asia Indonesia Thailand Malaysia Singapore Philippines Vietnam Myanmar Cambodia Laos Brunei East Timor South Asia India Pakistan Afghanistan Bangladesh Sri Lanka Nepal Bhutan Maldives Central Asia Kazakhstan Uzbekistan Turkmenistan Tajikistan Kyrgyzstan Oceania Australia New Zealand Papua New Guinea Pacific Islands Rest of the World Middle East Russia & Caucasus North America Latin America Europe Africa Features The Big Story Asia Insight Business Spotlight China up close Market Spotlight Datawatch Special Reports Infographics Opinion Opinion Editor-in-Chief's Picks The Nikkei View Life & Arts Life & Arts Life Arts Tea Leaves Obituaries Books Podcast Subscribe Account details Newsletters Group subscription Log out Log In Your Account Account details Newsletters Group subscription Log out Log In Subscribe Supply Chain Apple to move key iPad engineering resources to Vietnam China's BYD helps American giant with shift to alternative tech hubs Vietnam is emerging as an increasingly important production hub for Apple as the iPhone maker seeks to reduce its dependence on China. (Nikkei montage/Source photos by AP) CHENG TING-FANG and LAULY LI, Nikkei Asia tech correspondentsDecember 8, 2023 13:39 JSTVietnam CopyCopied TAIPEI -- Apple is for the first time allocating product development resources for the iPad to Vietnam, sources briefed on the matter said, a major step toward strengthening the Southeast Asian country's position as an alternative manufacturing hub outside of China. Apple is working with China's BYD, a key iPad assembler, to move new product introduction (NPI) resources to Vietnam. NPI involves a tech company like Apple collaborating with suppliers on the design and development of new products to make sure the blueprints are doable. This is the first time Apple has shifted NPI resources to Vietnam for such a core device. Read Next Business deals Former iPhone display plant to make chip material for Japan's Toppan Technology Taiwan's Foxconn seen boosting India iPhone output with $1.5bn plant Transportation Vietnam bets on new airports to boost tourism and supply chains Latest On Supply Chain Supply Chain Japan clothier Aoyama to screen Indonesian plant for abuse risk Supply Chain Chinese carmakers rush to build own semiconductor supply chains Supply Chain China's graphite export curbs take effect with uncertainty for EVs Sponsored Content About Sponsored Content This content was commissioned by Nikkei's Global Business Bureau. Discover the all new Nikkei Asia app Get Insights on Asia in your inbox Register for our newsletters Connect With Us About us Contact us Sitemap Help Terms of use Copyright Privacy & cookie policy Information Transmission Advertising Nikkei Inc. No reproduction without permission. Nikkei Asian Review, now known as Nikkei Asia, will be the voice of the Asian Century. Celebrate our next chapter Free access for everyone - Sep. 30 Find out more",
    "commentLink": "https://news.ycombinator.com/item?id=38582000",
    "commentBody": "Apple to move key iPad engineering resources to VietnamHacker NewspastloginApple to move key iPad engineering resources to Vietnam (nikkei.com) 121 points by firstSpeaker 19 hours ago| hidepastfavorite99 comments vkdelta 18 hours agoThis looks more of manufacturing resources to work with Vietnam based contract manufacturers.It is not moving US based core engg (software, cpu design, etc) to Vietnam. reply FirmwareBurner 15 hours agoparent>It is not moving US based core enggManufacturing is also becoming a core engg. Just ask the semiconductor industry. That was also offshored to Asia from the west by the metric boatload because it was not considered high value and prestigious enough, and now we depend on Asia for the most high value cutting edge chips which power our ... everything, as the western companies have fallen behind and are left with the manufacturing of low value chips. How ironic.Reminds me of that scene form &#x27;Back to the future&#x27; where 1955 Doc finds a faulty chip in the DeLorean&#x27;s time travel circuit and says \"No wonder it failed, it says Made in Japan\", then Marty explains to him that in 1985 all the best stuff is made in Japan. That scene aged like wine.It&#x27;s all fun and games until you have another global supply chain disruption because some component you thought is irelevant but you now find out is only made in one country that now decides not to play ball or is vulnerable to an aggressor or a natural calamity, and you can&#x27;t fix it because there&#x27;s no equivalent manufacturing capacity or even know-how left in the west anymore, as it was all offshored 20+ years ago so everyone who knew that field well, is now retired or doing some other job. But hey, at least some execs got some fat bonuses and career changing promotions out of it. reply mschuster91 13 hours agorootparent> Just ask the semiconductor industry. That was also offshored to Asia from the west by the metric boatload because it was not considered high value and prestigious enoughIt was and still is also incredibly dirty. Silicon Valley is among the top Superfund site collections for that reason - tons of semiconductor companies were very lax regarding pollution, and while the EPA cracked down on that pretty hard in the US, most Asian countries don&#x27;t give a shit about the environment as long as the short-term profits are high enough. reply orhmeh09 11 hours agorootparentDespite all EPA efforts, the semiconductor industry in the US still imposes itself on the environment in nasty ways.https:&#x2F;&#x2F;www.austinmonitor.com&#x2F;stories&#x2F;2022&#x2F;02&#x2F;environmental-...> Samsung’s semiconductor facility spilled a large amount of acidic wastewater into its stormwater pond and into a tributary of Harris Branch Creek in Northeast Austin, killing virtually all aquatic life within the 1.5-mile stretch. As much as 763,000 gallons of the acidic waste was discharged into the waterways for a period of up to 106 days. reply Sakos 11 hours agorootparentI don&#x27;t understand why the only instance monitoring this stuff \"regularly\" is Samsung itself. The ones with little incentive to actually care about the consequences or accurately monitoring this. reply lostlogin 5 hours agorootparentOutsourcing compliance monitoring and accreditation seems to have been a massive things across governments and countries. It’s got quite the track record of carnage too. We learn slowly. reply makeitdouble 9 hours agorootparentprev> EPA cracked down on that pretty hard in the USThis is sadly an ongoing battle that never fully settles, be it in the US or the other developed countries.There will always be more money made by cutting ecological corners, and where there&#x27;s money there&#x27;s politics. Fracking, regular industrial waste chemical, agricultural waste, any new spot where regulation isn&#x27;t set yet, gets relaxed or there&#x27;s an opportunity to push the issue under the rug it&#x27;s almost guaranteed to be abused. reply FirmwareBurner 12 hours agorootparentprev>It was and still is also incredibly dirty.Humanity&#x27;s entire industrialization process to date has been incredibly dirty and damaging to this planet. It would be silly to think it has all slowed down. It just moved from your back yard. reply user_named 6 hours agorootparentprevWait, so even though US industry created superfunds, murica still better than Asia who is bad bad? reply jfghi 17 hours agoparentprevYet reply theGnuMe 16 hours agorootparentdon&#x27;t worry software and cpu design will be AI driven. reply Muromec 14 hours agorootparentEverybody knows that by 2000 we will finally reach Communism end game and nobody will have to work that much.Or at least that’s what my grandpa believed. replyRCitronsBroker 15 hours agoprevi feel like this is largely motivated by growing qualms over being highly dependent on China. They are not alone by far, but Apple truly is an extraordinary case of being enitrely at the mercy of china playing their role. COVID was the event that lowered the tide enough to, painfully so, expose whos swimming naked. Now, add growing concerns over IP protection plus political volatility, and you have a situation that makes shareholders and executives queasy when rethinking their current position. China also isnt as cheap as it used to be, has economic troubles and faces an impending population collapse. Thats one hell of an uncertain future, soon-to-be superpowers dont tend to suddenly stop providing key metrics regarding their population and economy. Lets see how they handle their own personal 2008, Evergrande aint lookin too good either. reply biztos 15 hours agoparentGiven Apple’s profit margin I doubt the costs per se are much of a factor. But I think there have been two administrations in a row that probably (hopefully?) reached out to “Tim Apple” and suggested he imagine a future in which stuff doesn’t come from China.And if you’re looking for industrious, ambitious people who will definitely not be in China’s pocket, Vietnam is a great place to look. reply yieldcrv 15 hours agoparentprevVietnam is a single party state capitalist system nominally called the Communist Party that teaches the same Marxist ideology as China.Vietnam&#x27;s head of state and head of party can serve just as many terms as Xi Jinping has so far.Vietnam&#x27;s system as all the same trappings as China&#x27;s when it comes to political dissent or anything that can \"undermine the territorial sovereignty and unity\", an idea that can be used to control all facets of life. There are major human rights violations and concerns occurring there as well.The general lack of trepidation about Vietnam, from the West, is solely due to Vietnam&#x27;s irrelevancy, and Vietnam playing their own irrelevancy as friendliness for their own protection, it makes sense and they have no reason to do otherwise.My only point here is that the primary issues we have with China is not their system, just their market power. reply biztos 15 hours agorootparentIf by “market power” you mean a desire to invade Taiwan, debt-trap diplomacy, the open pursuit of totalitarian norms replacing Western ones globally, and territorial acquisitiveness in opposition to international law (just to name a few things) then yeah, sure, that’s what it is.But even then, if you want a partner who is close to China but not beholden to China, and for historical reasons will probably never be, then Vietnam is a great choice.Is there any evidence that Vietnam would be as belligerent as China, were it only a little richer? reply modernpink 14 hours agorootparentChina is the greatest civilisational threat to the West we have seen since Persia or the Umayyad Caliphate. The fact that the West has allowed letting China grow as much as it has done will be seen as one of the most fatal mistakes in grand strategy in history. That strategy had a purpose for defeating the Soviet Union, but after it had collapsed China had served its purpose for us and should have been isolated by the international community again. reply user_named 6 hours agorootparent\"allowed\" found the murican reply resolutebat 13 hours agorootparentprev> Vietnam&#x27;s head of state and head of party can serve just as many terms as Xi Jinping has so far.They can, but to date, they don&#x27;t: the Politburo holds the power and the head of state rotates regularly. Aside from Ho Chi Minh (who&#x27;s long dead), there is no cult of personality in Vietnam, you won&#x27;t find a single poster of the current leader anywhere.That said, China also tried very hard to prevent another Mao by building in all sorts of safeguards, only for Xi to come along and stomp all over them. reply FirmwareBurner 15 hours agorootparentprevYour last two paragraphs are bang on the money.Manufacturing is moving to Vietnam because it is politically, economically and militarily weak enough that it can easily be bullied into compliance&#x2F;submission by the US in case it ever decides to go rogue and threaten US investments, or have the audacity to spin it&#x27;s own domestic champions to compete with US players.China was also like that 30 years ago but has now become strong and influential enough that it can not longer be bullied into just being the submissive sweatshop of the world it once was.I recommend you watch the video that aged like fine wine: &#x27;Meet King Joe - 1949 - Cold War Era American Propaganda Cartoon&#x27;: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=j-6YQQ779YM reply Muromec 14 hours agorootparentWhy bully foreign governments you can buy? reply FirmwareBurner 14 hours agorootparentIn case buying doesn&#x27;t work. Then you wakeup with a coup in your back yard. reply astrange 13 hours agorootparentKissinger&#x27;s dead. You don&#x27;t have to sit around patting yourself on the back about him anymore.You can tell none of this is going to happen because of the zero times it&#x27;s happened. reply modernpink 14 hours agorootparentprevExactly, the West can bring to bear its might on Vietnam if they step out of line, especially since they themselves are not much fans of the Chinese and will be more than happy to work with the West.For Western consumers and companies we have learnt the lesson that if we want to keep the flow of cheap products, we need to diversify the pool of labour we draw upon and to keep them dependent instead of building them up to be competitors in the supply of products as well as competitors as consumers of those products.The crucial moment in the China strategy was in 2008 when we should have started on&#x2F;friend shoring rather than leaving it until now. Instead with the West facing economic calamity at the time, we wanted the economically easy solution of letting China continue its integration into the global supply chain. reply astrange 13 hours agorootparentThis is a typical case where cynical answers are wrong. The good thing about Chinese manufacturing isn&#x27;t that it&#x27;s cheap - it hasn&#x27;t been cheap for a while now. It&#x27;s that they&#x27;re really good at it.Nothing&#x27;s as expensive as a product that doesn&#x27;t work. reply berserk1010 15 hours agoparentprevThere are also a few recent developments that should frighten any foreign companies that are still operating in China- China&#x27;s government&#x27;s unprecedented and nationally coordinated audit on Foxconn&#x27;s taxes and real estates in China. You could say that it is politically motivated, given the ceo of Foxconn was at one point running for president in Taiwan. However, he has since stepped out of the race, yet the audit is still ongoing. No doubt this has scared many Taiwanese firms to quickly move out of China, since this is just part of recent trend to try to squeeze money out of any capitalists (foreign or homegrown) since China is very very broke. (no, their now dwindling $800B dollar reserves is smaller than the dollar debt they owe abroad)- a ton of recent arrest and prevention of foreign executives from leaving China. For example Japanese https:&#x2F;&#x2F;www.reuters.com&#x2F;world&#x2F;asia-pacific&#x2F;how-an-executives... and American https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;03&#x2F;24&#x2F;business&#x2F;china-business-c.... This has prompted many companies to pull their employees out of China. Recently Moody downgraded China&#x27;s rating, and Moody issued warnings to its employees in China https:&#x2F;&#x2F;www.businessinsider.com&#x2F;moodys-staff-in-china-wfh-du...- Russia&#x27;s recent nationalization of foreign company assets. Being that China is allied with Russia in war against Europe and US, supplying Russia, and has the same dictatorship quality, it is very likely China will walk down the same path of nationalizing Apple&#x27;s assets reply gscott 13 hours agoparentprevI wonder what Tim Cook was thinking when the CCP sent in their \"disinfection\" crews and threw all of Foxconns employees personal items out.There are a lot of straws breaking the camels back but Tim Cook juiced profits centralizing in China but eventually, and it did take a while, having all of Apples fruit in one basket became untenable. reply Erratic6576 12 hours agorootparentIt’s still cheaper than hiring American workers reply userbinator 15 hours agoprevIronically, many sites for the repair of phones, laptops, and other consumer electronics --- including Apple products --- are hosted in Vietnam. reply andrewstuart 14 hours agoprevCompanies all over the world have discovered that the cheap labor authoritarian nation where they did they manufacturing turned out in the end to be a real political problem and business risk, so they&#x27;re moving their operations to countries that don&#x27;t have such risks. reply drdaeman 13 hours agoparent> so they&#x27;re moving their operations to countries that don&#x27;t have such risksDid you mean: different cheap labor authoritarian nation? reply Manuel_D 13 hours agoparentprevIt&#x27;s not the authoritarianism that&#x27;s the issue with China. It&#x27;s the geopolitical rivalry with the US and Taiwan. reply andrewstuart 13 hours agorootparent>> geopolitical rivalry with the US and Taiwan.The other geopolitical rivalries play a role too, including with Japan, Australia, the Philippines, Malaysia, Vietnam, South Korea, Philippines, Brunei, India, reply KRAKRISMOTT 14 hours agoparentprev> Companies all over the world have discovered that the cheap labor authoritarian nation where they did they manufacturing turned out in the end to be a real political problem and business risk, so they&#x27;re moving their operations to countries that don&#x27;t have such risks.So they moved from one cheap labor authoritarian nation to the other cheap labor authoritarian nation next door. reply gonzaloalvarez 14 hours agoparentprevthat don’t have such risks… yet reply andrewstuart 13 hours agorootparentWhat are you suggesting? reply thorncorona 13 hours agoparentprevSuch as: Vietnam. A communist country. reply MuffinFlavored 18 hours agoprevSlightly related genuine question: Why do Apple&#x2F;Meta&#x2F;Microsoft pay $300k-$1m&#x2F;yr for American engineers (salary + stock compensation) from an international perspective? Capitalism states (sort of) that there&#x27;s competition and an inherit race to the bottom. Companies have a motive to spend as little and get as much for their buck as possible. Globally, how is paying somebody $300k&#x2F;yr in America (expensive) the best option in terms of getting development done? Is the answer really \"quality\"? Aren&#x27;t engineer salaries much lower in Europe? What about Asia? South America (Brazil)? reply aworks 17 hours agoparentI was a sofware director at a Fortune 500 company. I had engineers in Silicon Valley, Santa Cruz, Canada, the Netherlands, Russia, UK, Taiwan, and Wuhan (!) China. I also had individual engineers in Romania, Ireland, Portugal and Germany. Since it was already a global company, it was feasible to hire wherever we could find talent. Some of the Russia team moved to Armenia last year when the office in St. Petersburg was closed. We considered other countries like Vietnam since we had Vietnamese-American engineers but this is where we ended up.Cost was one of multiple variables determining which site we hired at. At the extremes, it was a 10x difference. The higher the salary, the more senior the team. The competition to hire and retain software engineers caused salaries to go up everywhere, but at a faster rate in the low-cost countries. And low-cost countries were our go-to source for new grads. The profiles of say Russia and China universities varied significantly e.g. experience with open source, mathematical rigor, English skills, credentials, initiative, teamwork, and relevant courses.The core product develpoment was done in the US but over time, other sites took on more product responsibility. In some of the countries, we also wanted to be closer to our customers, in expanding markets.It&#x27;s hard to measure quality, productivity and contribution on an individual basis but it was reasonably correlated with salary. There were outliers though.So geographically-based staffing was complicated. reply orzig 17 hours agorootparentAs a senior IC formerly in a similar situation, I’ll affirm this is brilliantly written and even deeper than it looks.I’ll add: Many of the Indian ICs I worked with were fine, but there was at least one manager who was an absolute disaster and the American executives had very little ability to fix the situation. Given that financial capital is here, executives will be here, and so some part of the org chart has to bridge across cultures, which is going to be a slight friction that compounds over the years of the project. reply moneywoes 16 hours agorootparentprevultimately, are the days of a blue collar engineer in the west limited?you mentioned the new grad pipelines have already movedwhat advice would you give to a engineer in the west hcol, pivot to product? reply blagie 15 hours agorootparentPersonally, I see the opposite trend: decreased differences in salary and cost-of-living. As developing countries develop, they&#x27;ll look more and more like the US.Put another way: Since WWII, we&#x27;ve been moving from US engineers (used broadly) with US as the only country who can afford our products to global engineers with everyone buying products.There&#x27;s no magic \"US is a superpower fairy\" which guarantees US salaries, cost-of-living, etc. will be 10x higher than everywhere else forever.I can&#x27;t predict the future, so I don&#x27;t know what that will do for jobs outlook, but it&#x27;s not as simple as \"they&#x27;re coming for our jobs.\"My biggest worry is that the US is increasingly training incompetent engineers (again, used broadly). Much of the rest of the world has much better math and science in K-12. In winner-takes-all markets, 7-figure salaries can make sense sometimes to get the best over low 5-figure ones in the developing world, but if we&#x27;re not the best.... reply MuffinFlavored 7 hours agorootparent> As developing countries develop, they&#x27;ll look more and more like the US.A one bedroom apartment in my city rents for $1,800&#x2F;mo - $2,200&#x2F;mo and it&#x27;s very \"nothing burger\" in terms of what you get. I&#x27;d imagine the rest of the world has a lot of catching up to do in that department? reply t8sr 15 hours agorootparentprevThe US is a huge market with rules and culture completely different from the rest of the world. If you&#x27;re building a product for the US market, you just can&#x27;t beat a local team, who understand the customs, regulations and don&#x27;t need user journeys explained to them in too much detail.Are we always going to need millions of javascript developers? Possibly not, productivity gains might outpace demand. But people can retrain on things that are in high demand. reply t8sr 18 hours agoparentprevThere are many more feedback loops than meets the eye and not only corporations are rational economic actors. The in-demand talent tends to move to high CoL locations. Former low CoL locations become high CoL when successful. Especially when a high and low CoL location are adjacent, this tends to happen quickly (e.g. Germany and Switzerland, Malaysia and Singapore, US and Mexico.)The reverse is also true - people in high CoL locations tend to move out when their skillset no longer commands top compensation.In other words, I think the available workforce, to at least some degree, sorts itself into expensive and cheap locations based on what skills are in demand.To give a concrete hypothetical: you hire an ML research team in Poland. While ML is in demand, those people can easily get a job offer in London or Zurich and get paid 2-3 times as much. They don&#x27;t even need a work permit, and it&#x27;s a 90 minute flight. Why wouldn&#x27;t they take it? reply berdario 17 hours agorootparent> To give a concrete hypothetical: you hire an ML research team in Poland. While ML is in demand, those people can easily get a job offer in London or Zurich and get paid 2-3 times as much. They don&#x27;t even need a work permitThey actually need a work permit for London (it&#x27;s not EU anymore).I believe that for Switzerland there might also be requirements for the employer to state that they couldn&#x27;t find talent in the country, before extending an offer to foreign nationals (including EU: Switzerland is not EU, though it&#x27;s part of Schengen... And thus EU citizens have freedom of movement)But your point stands... I think that fiefdom building, and needing teams close to where the execs (and&#x2F;or investors) work and live is the other big reason why companies hire in high COL areas reply mahkeiro 13 hours agorootparentNo there is no limitation in Switzerland for EU citizen, only specific domains (like waiter, hairdresser) where unemployment is above 5% must be first announced at local job agency, but you are still free to hire whoever you want. Btw free movements is not linked to Schengen but to bilateral agreements between CH and EU that entered in force before Schengen.https:&#x2F;&#x2F;www.eda.admin.ch&#x2F;missions&#x2F;mission-eu-brussels&#x2F;en&#x2F;hom... reply wallon_brux 16 hours agorootparentprevI get your point, but you actually need a work permit for both london and switzerland reply t8sr 15 hours agorootparentYou&#x27;re right about London, although I explored it not long ago, and having an EU&#x2F;EFTA passport and a job in tech seemed to basically guarantee it.As for Switzerland, you don&#x27;t need it. As the Swiss government itself says: \"Thanks to freedom of movement, citizens of EU&#x2F;EFTA member states can enter, live and work in Switzerland.\".[1]: https:&#x2F;&#x2F;www.ch.ch&#x2F;en&#x2F;foreign-nationals-in-switzerland&#x2F;workin... reply theGnuMe 16 hours agorootparentprevWell you have to live in London which may not be feasible regardless of the pay. reply t8sr 15 hours agorootparentHah, indeed. Before Brexit, I used to take the Northern line in rush hour and it cured me of any desire to live in London, unless I can walk to work. reply jandrewrogers 16 hours agoparentprevAn important element of this is that there is strong and self-reinforcing geographical clustering effects around high-value skills. Engineers do not generically make $300k-$1M, it is engineers with specific domain expertise. I&#x27;ve had teams all over the world, the market is more efficient than I think some people expect. Focusing on wage arbitrage ignores that companies are optimizing for ROI, not cost per se.I think it is also important to recognize that the engineers top American tech companies hire are often not American, they just happen to be in America. It is a geographical bias, not an American-as-nationality bias.Engineers with unusually high skill in any particular area are geographically diffuse. You can&#x27;t hire a \"team\" in some distant inexpensive country, there might only be one or two such engineers in the entire country and they are difficult to find. The moment a company invests in creating a concentration of domain skill where none really exists, that clustering of expertise has a natural gravity not only for engineers with those skills but for other companies that want to hire those skills. Why search for a particular engineering expertise in Bolivia when you know there are a hundred top engineers in some specific city? Even if the wages are higher, the risk is lower, hiring velocity higher, and the engineers more experienced, which has a large real ROI on its own. So people with those skills gravitate toward that concentration because that is where the money and jobs are. Wash, rinse, repeat.There are many large cities in the world with a reputation for having a proper tech presence, albeit on a lower tier, where it is nearly impossible to hire certain expertise and experience even for Silicon Valley money.You see the effects of this throughout tech, and not just software, where specific skill sets are oddly concentrated in one or two regions, including ones that are not particularly known for being tech or where the company that originally created the concentration became irrelevant decades ago. This expertise flywheel is how new globally leading tech hubs are created in practice e.g. Taiwan for silicon fabrication or Seattle for cloud.This is the tech hub bootstrapping problem. You have to heavily invest in a valuable technical domain that is currently being ignored by existing tech hubs. Taking advantage of these opportunities requires vision and an appetite for risk, since it is a contrarian position almost by definition. I think this explains much in the European context, where you have large concentrations of excellent engineers but minimal investment in genuinely bold visions. reply t8sr 15 hours agorootparentWell put. It&#x27;s a shame that the domain a lot of European countries decided to bootstrap tech hubs around was crypto and not AI. reply irrational 17 hours agoparentprevTime zones. The business people don’t want to have meetings very early in the morning or very late at night. And they need more than one meeting a day and those meetings are taking place during nighttime in most of the rest of the world.The reasoning is different for Latin America - there the issue is more of a language barrier. While a great many people in Asia and Europe already know or seek to learn English, the same isn’t as true in Latin America. reply monocasa 17 hours agorootparentPretty much all devs in Latin America speak English. It&#x27;s the lingua franca of software dev. reply clbrmbr 17 hours agorootparentThe level of English varies, and salaries usually correlate with English proficiency just as well as with technical ability. I believe this is because devs with strong English can compete as remote workers on the global market, whereas those who are not professionally competent in English are relegated to work in firms that speak their language, or at least to have a bilingual management layer above them. reply aworks 17 hours agorootparentprevI regularly had 7am PST calls with Europe and Russia and 7pm PST calls with China and Taiwan. Calls with both at the same time were particularly difficult to schedule. reply irrational 16 hours agorootparentLike I said, way early and way late. 7am I am still getting my kids up and ready for school. 7pm we are cleaning up dinner and getting kids ready for bed. reply Teever 16 hours agorootparentprevNow do Canada. reply FredPret 15 hours agoparentprevSome companies do love the race to the bottom, but these don’t last long.Others seek instead to make remarkable things, and for these it makes sense to throw money at the best talent. What does it matter if an engineer costs 1m&#x2F;yr if they make something worth 100m - 1000m? In fact, it’s a bargain.This phenomenon doesn’t exclusively exist in America, but the environment there is more conducive to entrepreneurs swinging for the fences than most other countries. They’ve also been playing at a high level for much longer than most, so investors there have lots of wealth to fund startups.So that’s where you find the big salaries as well. reply MuffinFlavored 7 hours agorootparent> What does it matter if an engineer costs 1m&#x2F;yr if they make something worth 100m - 1000m?I think it would be very difficult to take the ~100 or some engineers who do make $1m&#x2F;yr at Google and draw the direct line to \"this specific engineer is responsible for $1,000,001 worth of profit (aka paying for himself&#x2F;herself&#x2F;themself + some)\", let alone $10m, $100m, etc. reply opportune 14 hours agoparentprevThis might be a controversial opinion here and I don&#x27;t mean to offend anybody, but the distribution of engineers&#x27; effectiveness is not the same around the globe.Thought exercise: what kind of profile would you expect of someone going into software engineering in a country where the good jobs pay 5x median wage (and ~25x global median wage) vs a country where the good jobs pay 2x median wage (and ~6x global median)?Thought exercise: what kind of skills and experience would you expect of a 90%ile senior engineer in a country that gets lowest-bidder outsourced contract development work, vs a country that is directly employing engineers in \"cutting-edge\" development? reply yuppie_scum 18 hours agoparentprevQuality just isn’t there with offshoring due to the time zone difference and distance. Accountability isn’t there. The development savings will be offset by onshore QA, PM, Project management and rework by onshore devs. Been seeing that play out again and again for 20 years.I have seen slightly better results with offshoring from Latin America - fast feedback makes a huge difference - being able to meet frequently and provide feedback in the same time zone makes a huge huge difference.I think that AI will rapidly slot into this niche of “indirect programming” however. As soon as token sizes allow large codebases to be be parsed and modified, it’s all over. reply rafaelmn 18 hours agorootparent> I think that AI will rapidly slot into this niche of “indirect programming” however. As soon as token sizes allow large codebases to be be parsed and modified, it’s all over.Context size is the least of an issue - current models suck in capability.I&#x27;ve been building stuff on top of openai API for months and getting it to do trivial stuff with instructions reliabily is incredibly hard. These are things like \"if a user asks a question about an individual but only specifies first name ask for last name before invoking a search function\" - even with examples of what to do you&#x27;ll get GPT 4 ignoring instructions and calling search with just a first name.Like I understand that the potential they are showcasing is a breakthrough, and people are right to be excited about that - but we are extrapolating way to much based on breakthrough improvement pace.We&#x27;ve seen similar claims about self driving cars being a year away since 2016.Unless there&#x27;s some breakthrough, I don&#x27;t see AI affecting developer demand in the next two years at least. reply flutas 18 hours agorootparentprev> Quality just isn’t there with offshoring due to the time zone difference and distance. Accountability isn’t there. The development savings will be offset by onshore QA, PM, Project management and rework by onshore devs. Been seeing that play out again and again for 20 years.Yupp, it pretty much turns a quick conversation at standup or a quick huddle about a change into a 16+ hour turn around time at minimum. reply lokar 18 hours agorootparentprevAlso, these companies tend to be lead by engineers. They identify with the engineers and believe that this work (and thus themselves) is special. Not the case with say auto manufacturers. reply MuffinFlavored 18 hours agorootparentWho is to say the future will \"remain this way\" for engineers? When will it become more of a commodity? reply lokar 18 hours agorootparentMore and more these companies are lead by groups of people who have never worked as an engineer. reply MuffinFlavored 7 hours agorootparentI think most CTOs of smaller companies make $500k&#x2F;yr or more, don&#x27;t write code, and are just really good at driving delivery&#x2F;working with others&#x2F;having good instincts on trusting others (like enterprise architects, dev leads, etc.) reply stardom5761 17 hours agorootparentprevIsn&#x27;t the current AI level already good enough to offload a big chunck of the work? I feel like the technology is already there and it&#x27;s just a matter of adoption reply poisonborz 16 hours agoparentprevThe same reason why middle and upper management is not outsourced. Communication and effective control over continents is hard. Core engineer salary costs are a drop in the bucket for global companies.And anything that is not core product, they do outsource. reply maxwell 17 hours agoparentprevBecause they earn enough per head to hire on-site in expensive locations. \"Remote\" seems to usually just mean not doing that, i.e. avoiding the costs of North American metro areas, seemingly usually out of financial necessity. reply aprilthird2021 17 hours agoparentprevThe best and brightest of Asia and Europe move to the US because of the salaries. Thus, the talent pool in the US becomes far stronger than the talent pool in other regions.But it&#x27;s also true that FAANG all have global offices and teams fully in places with lower salaries. They are aware of the pay differences and take advantage of them. But they can&#x27;t completely have all development done in a separate time zone or even same time zone separate region (like LATAM). That slows down dev cycles, invites gaps in product understanding, and allows you to miss out on top talent who will move to get paid top dollar. reply pdpi 16 hours agoparentprevThere&#x27;s competition for high-end engineers everywhere, and you can&#x27;t really afford to lock yourself out of the markets where those engineers congregate. reply gedy 18 hours agoparentprevSalaries are not big of a cost compared to revenue, so the \"savings\" only are valuable to struggling companies. reply MuffinFlavored 18 hours agorootparentTo me this translates to \"it&#x27;s worth it to pay somebody $300k&#x2F;yr - $1m&#x2F;yr because companies can earn X% ROI on their cost of employees\" but and I just struggle to believe where... from what I understand, there are like people who assemble iPhones for very very low cost in Asia, etc.Now I&#x27;m not saying iPhone assembly and architecting cloud computing are the same skillset. I just find it \"unlikely\" that America really has that large of a quality gap internationally? I work for a company that has a remote team of developers in Shanghai. I don&#x27;t know for sure but I&#x27;m going to guess they do the same work&#x2F;probably better work than the US team for less pay. reply adw 17 hours agorootparentAmerica’s superpower is immigration. The core teams at the biggest and best players are recruited globally; the high end of software engineering is, economically, the NFL or the Premier League. reply vlovich123 17 hours agorootparentprevThey are probably closer when evaporated as a % based on the amount of value and profit in the supply chain that is being extracted. People making iPhones are working for companies that have their margins squeezed to razor thin margins so that Apple can make its 30% cut.The other thing is the amount of skill required. There are more people who can be hired to assemble iPhones than to design all the parts that go into the product.Finally, there’s an arbitrage effect going on. A company can more easily go into a low CoL and pay the predominate local wage than a person from a low CoL can move to a high CoL and get paid a fair wage (aside from legal barriers there are also social ones involved with leaving your family) reply aprilthird2021 17 hours agorootparentprevThe money creates a bigger quality gap. At Meta&#x27;s US offices, most devs are foreign origin. They moved for the money. So those devs wouldn&#x27;t just accept paltry sums if Meta hired them overseas and they didn&#x27;t need to come to the US to work. But Meta would have added friction the more and more of their teams are separate from product owners and business owners. reply gedy 17 hours agorootparentprevIt&#x27;s likely not based on logical accounting and counting every dollar - just like how companies blow money on fancy buildings or projects they know will likely be cancelled or never go anywhere. reply foolfoolz 17 hours agoparentprevthere’s not enough good engineers to sustain a business the size of apple in any one geo location. this will change in the next 25 years reply badpun 14 hours agoparentprevThe engineering is their core competency and the source of competetive advantage. Given that it currently works well, and those companies are massively profitable - they see little point in doing risky cost-cutting. reply cqqxo4zV46cp 18 hours agoparentprevBecause capitalism the theory and capitalism the reality are vastly, vastly different.I just thought I’d jump in before someone talks about how [insert Ivy League school here] is the best thing since sliced bread. reply hughw 17 hours agoprev\"Country risk\" is a term used in the oil industry. Is it common elsewhere? reply oblio 17 hours agoparentI imagine it&#x27;s common for all strategic resources. reply selectodude 17 hours agoparentprevI imagine with the interesting geopolitical situation we all find ourselves in, if it wasn&#x27;t before it sure as shit will be now. reply sneak 18 hours agoprevRight now, everyone at Apple and everyone in the USG knows that an all out trade war (or, heaven forbid, war war) between the US and China means that the head and body of the sometimes-largest US company get severed.It behooves Apple and everyone on Team USA to do everything possible to make Apple be able to survive a corporate beheading ifwhen they become unable to manufacture in China.They’ve started moving AirPods (India and Vietnam), some iPhones (India), and now iPads (Vietnam). Apple’s scale is immense, and a full replacement strategy is maybe the largest project they have ever undertaken, and certainly the largest that doesn’t get announced as some cool new product. reply Morte42 16 hours agoparentI doubt it has much to do with any impending war, after all Apple is moving to Vietnam with the assistance of a Chinese company that has been established in Vietnam for decades.China&#x27;s relations with Vietnam go back millennia, they even provided Vietnam with weapons and training during the their wars against France and the US. If anything China is trying to establish itself in Vietnam before anybody else can.Vietnam, Bangladesh, Mexico and Brazil are all increasingly entwined with China when it comes to offshoring cheaper and simpler manufacturing. Expect the above nations to rapidly replace Made in China for many goods like batteries, toys, clothing and much more.In 2018 China&#x27;s trade balance accounted for 0.66% of their GDP. In 2019 it was 0.93%. In 2022 it leapt to 3.21%. In the next couple of years it will likely return to around 2% meaning that the domestic Chinese economy is responsible for adding around 98% of the value to China&#x27;s GDP every year, the sum of all of China&#x27;s international trade balance adds 2%. Being the Worlds factory really isn&#x27;t all its made out to be, China needs to reform itself to make profitable goods not cheap ones if it wants its international trade to be as lucrative as the rest of its economy. They had a plan for 2025 but covid happened so its hard to see how much they were able to offshore, I believe clothing manufacturing has been reduced dramatically in China and they are making fewer batteries but otherwise they are probably still in the cheap industry rut. reply theGnuMe 16 hours agoparentprevIt could be cost, China might be more expensive than Vietnam. I would think cost may play a role. reply treprinum 11 hours agorootparentChinese workers are now more expensive than Eastern European ones, Indian swengs are more expensive than Eastern European devs as well. reply ngcc_hk 18 hours agoprev [–] I wonder given Vietnam is also a communist country why there. How about Thailand or India … reply vidarh 18 hours agoparentBecause whatever you want to label Vietnam, in terms of business what matters is that it&#x27;s fairly deregulated and open for international companies, and has been for decades, offers significant tax breaks for hitech manufacturing, and has a cheap workforce and an established supply chain. India or Thailand might well also be competitive, but it&#x27;s not a given they&#x27;re any more attractive.If you mean to suggest there&#x27;d be the same risks as China, consider that Vietnam has consistently kept a certain distance to China, and have shared concerns with the US over Chinese expansionism. They&#x27;re not particularly ideologically close, and politically there are few potential situations where deteriorating relationships between the US and China will negatively affect US-Vietnam relations, and some where it might improve them (e.g. if the issues in the South China sea escalates). reply wtmt 15 hours agoparentprevThe news reports here in India say that there’s a lot of red tape and delays in India. Ease of doing business is lower compared to Vietnam. The policies are protectionist and restrictive. The labor laws are, to some extent, protective of employees. This is something Apple has been reported as not being happy about (but things are changing).Apple already has a growing iPhone assembly base in India, which is set to go to 25% of its total iPhone production within a few years. While Apple is still looking for low cost production, I’m sure it doesn’t want a repeat of China by concentrating a lot on one or two countries. I think the current moves are a temporary aberration, since concentrating iPhones in India, iPads and Macs in Vietnam and so on doesn’t diversify the risk as much as ensuring that every product is assembled in more than one country. I’m sure Tim Cook is spending a lot of time working on such measures to de-risk manufacturing and maintaining the company’s profit margins.All the countries that support low cost assembly and manufacturing in Asia have different kinds of problems as far as governments, policies and stability are concerned. Apple or any other company has to figure out the right mix and plans. reply Ridj48dhsnsh 18 hours agoparentprevHave you ever visited Vietnam? The people I&#x27;ve met there are highly motivated to build successful businesses, even more so than in many western countries. reply latchkey 15 hours agoparentprevThe government is communist, but the people are not.If you&#x27;ve ever spent any time in Vietnam, you&#x27;d understand that. reply resolutebat 13 hours agorootparentTBH even the government is Communist in name only. Vietnam is furiously entrepreneurial and the government mostly gets out of the way, unless it feels threatened and then it comes down like a ton of bricks. reply latchkey 13 hours agorootparenthttps:&#x2F;&#x2F;www.politico.com&#x2F;story&#x2F;2017&#x2F;02&#x2F;clinton-ends-vietnam-... reply zarzavat 18 hours agoparentprev [–] Many of the countries in the region are communist. What sets China apart is that it is a world power competing with the US. Nothing to do with communism. reply petesergeant 16 hours agorootparent [–] None of the other communist countries in the region are anything like Vietnam, and the idea of moving high-tech manufacturing to Laos, Cambodia, or North Korea is ludicrous. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple is shifting its product development resources for the iPad to Vietnam to decrease reliance on China for manufacturing.",
      "The company is collaborating with China's BYD, a major iPad assembler, to transfer new product introduction (NPI) resources to Vietnam, marking a significant move.",
      "This highlights the growing importance of Vietnam as a production hub for Apple and reflects the trend of tech companies exploring alternative manufacturing locations beyond China."
    ],
    "commentSummary": [
      "Apple is planning to shift some of its manufacturing operations from China to Vietnam and India to decrease dependence on China and minimize risks.",
      "Tech companies confront difficulties in finding skilled talent, highlighting the significance of diversifying production locations.",
      "The potential impact of AI on programming and worries about offshoring for development work are mentioned, emphasizing the importance of investing in technical domains and avoiding overconcentration of manufacturing in specific countries."
    ],
    "points": 121,
    "commentCount": 99,
    "retryCount": 0,
    "time": 1702130757
  }
]
