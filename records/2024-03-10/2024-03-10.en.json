[
  {
    "id": 39653718,
    "title": "Bruno: Next-gen Git-friendly API client",
    "originLink": "https://www.usebruno.com/",
    "originBody": "bruno Manifesto Bru Sponsors Blog About Pricing Support Download Re-Inventing the API Client Bruno is a Fast and Git-Friendly Opensource API client, aimed at revolutionizing the status quo represented by Postman, Insomnia and similar tools out there. Bruno stores your collections directly in a folder on your filesystem. We use a plain text markup language, Bru, to save information about API requests. You can use git or any version control of your choice to collaborate over your API collections. Bruno is offline-only. There are no plans to add cloud-sync to Bruno, ever. We value your data privacy and believe it should stay on your device. Read our long-term vision here. Golden Edition Pre-Orders available at $19 $9 ! Pre Order Now! View On GitHubWatch DemoIndiaFOSS 3.0 Talkvs Postman Run across multiple platforms Collaborate via Git Or any version control system of your choice Testimonials",
    "commentLink": "https://news.ycombinator.com/item?id=39653718",
    "commentBody": "Bruno: Fast and Git-friendly open-source API client (Postman alternative) (usebruno.com)932 points by ulrischa 15 hours agohidepastfavorite281 comments Piisamirotta 4 hours agoLately Postman suddenly required creating an account to their cloud, to use my five different rest requests from scratchpad. I got annoyed so bad that deleted that piece of cr*p immediately. Never looking back. Then I found Bruno and fell in love. Thanks for the great work! reply fifilura 1 hour agoparentWe used Postman but it got forbidden in our org for that reason, so no more. Can't say I really miss it. I personally prefer just using a jupyter notebook for these kinds of tasks. With a custom tool like this it becomes a dead end with the data. Maybe you want to decode it if it is on a binary format. Or you want to plot some basic stats? reply throwaway56391 1 hour agorootparentI've always preferred Insomnia over Postman. The interface fits me better. But now they also started requiring cloud login, so maybe I'll give Bruno a try if it degrades further reply giovani 1 hour agorootparentInsomnia has an open source fork from before all the cloud bulls*t: https://github.com/ArchGPT/insomnium reply tdudhhu 53 minutes agoparentprevInsomnia did the same. There was an option to migrate to an offline account but the migration did not work. So I turned to Bruno. I have been happy with it but there are some strange issues. Sometimes it does not save settings when I press Ctrl s. I still don't know when this happens but I lost some work a couple of times because of this. reply yard2010 49 minutes agoparentprevImagine this cloud enshitification reaches everything else. You need a cloud account to curl or wget, use ffmpeg or simply sed lol reply FlyingSnake 14 hours agoprevLooks great! Postman dug its own grave after selling out itself for VC money. The “File over app” philosophy is a direction that we should be supporting after the Post-ZIRP VC money world. 1: https://stephango.com/file-over-app reply pjmlp 2 hours agoprevI find interesting on how on a startup related forum, anything related with not paying is always celebrated. reply Merik 1 hour agoparentGenerating revenue through the creation of value via innovation is great; using dark ux patterns to extract revenue from a captive user base, not so much. I think in cases like postman, people don’t like when features they previously had used for free suddenly comes with a price tag; rather than innovate and create new value that is worth paying for, some companies are opting to take away features user previously had. Yes, they own/control the software and want to make money , which fine, but they created a dissatisfying user experience as they tried to coercively move users into their cloud offering, wether they wanted to or not, and regardless if it provided user value. After they did that, they shouldn’t be surprise a portion of their user base decide to ditch the product and complain about the experience. This is compounded by the fact that they leveraged the contributions of an open source community, and at the same time there are other options freely available that aren’t locked into a proprietary cloud login. reply onion2k 52 minutes agoparentprevStartups are often all about disrupting an industry by lowering the cost of a product. If you can lower it to zero that demonstrates the incumbent businesses are obviously not providing a valuable service that's worth paying for. reply ianberdin 1 hour agoparentprevOnce CEO asked me: \"why are you spending months of your valuable time to create a tool to solve a thing, instead paying $10/month?\" \"I know developers never pay, but why?\" reply otabdeveloper4 56 minutes agorootparentIt's not the money, it's the control you relinquish in the process. The potential costs of the risks involved are much, much greater than $10/month. reply throwaway220033 1 hour agoparentprevGreat to see most people are smart enough to not apply same model on all problems in their life. Productivity tools better to be lean, simple, free & open source in some cases. This is one of those. Of course, you can keep throwing money at bulky software continuously making things slower and more complicated, just because you never have to worry about money thanks to the VC money. I’m old enough to not buy that this is how startups operate in general though. reply skydhash 14 hours agoprevI myself use Paw [0] because it's native to MacOS, but I'm a little bit worried for it's longevity as it being supported by a SaaS business. But so far it's been great to document API for my personal projects. [0]: https://paw.cloud/ reply ho_schi 2 hours agoparentI’m envy? I’m hoping for a native GUI application for Linux. Electron looks ugly, it doesn’t integrate, fails to handle HiDPI usually, in best case it eats a ridiculous amount of memory (factor 5x compared to native) and in worst case it has security issues due to Blink and lot of JS. Electron is Flash for the Desktop. reply reddalo 1 hour agorootparentI agree. Whenever I can choose between a webapp/Electron or a native app, I'll always go with the native app. reply aPoCoMiLogin 13 hours agoparentprevthe extensions and ability to write your own extensions, or chain request/response values is crazy. when i've switched to linux box from macos last year, paw.cloud (rapidapi) was one of few stoppers for me, that good of a software it is. also not to mention the integration with keychain for credentials encryption was nice. postman is really bad, nobody should use it. same goes for similar solutions, even this one. reply thijsvandien 4 hours agoparentprevNever \"upgraded\" from 3.4.0 and never going to. For now it works fine, but at some point I'm going to need to switch... reply mberning 11 hours agoparentprevQuickly turning into abandonware. I tried moving my paw library from one computer to another and it crashes opening the file. Had to start from scratch. reply jurassicfoxy 14 hours agoparentprevSecond vote for Paw. I also was not happy about the buyout. It has some quirks, but pretty awesome overall. reply helloanoop 5 hours agoprevHey everyone, this is Anoop - creator of Bruno. Happy to see Bruno at the top of HN! I will try to address some common questions in this comment. > Well based on historical experience with Postman and Insomnia most probably Bruno will go the same way once they get enough users hooked in. Especially once a VC gets into the fold. We will never take VC funding. We received around 10 inbound reach outs from VCs till date and have denied funding from all of them. We will remain independent and I have written about it in detail here https://www.usebruno.com/blog/bootstrapping > I didn't stick with Bruno. I think it was due to not having an equivalent to Postman's pre-request scripts. Bruno has come a long way, we support pre-request scripts and a lot more > But can it handle oauth2? I had to write a httpie script recently just to test an oauth2 api. We have released oauth2 support, some rough edges are being polished > Good thing it's open source. Money being involved, I don't have long term hopes for it's openness. I understand this is a hard problem. We are fully bootstrapped and independent. We earn money via selling the Golden Edition. We will build more developer products in the long term, and the goal is to make even the golden edition features also open source in the future. I am committed to this cause. > History goes in circles. New API client appears, adds features, userbase grows. Forced login is added, users are angry and look for alternative. New API client appears. I have felt this pain. That's one of the reasons why I denied VC funding and chose to remain independent. Having seen 10 years of this cycle, its enough. We don't want to repeat the same saga. Some good links where I have discussed about opensource, freedom and monetization - https://www.usebruno.com/blog/bootstrapping - https://github.com/usebruno/bruno/discussions/269 - https://www.youtube.com/watch?v=7bSMFpbcPiY We are also working on standardizing and improving the Bru Lang to bring more features in Bruno. See: https://www.brulang.org/ If you'd like to pre-order the golden edition: https://www.usebruno.com/pricing Thank you for all the love and kind words, HN! reply freedomben 2 hours agoparentThank you for the information and the commitment to open source. I know the Gold edition isn't open source under an OSI license, but is it source available for people who purchase it? I'm strongly considering buying it because it's not a subscription, and is open source. As a general rule, I don't buy proprietary software anymore after having been burned in the past. I have no issues with open source software that has proprietary features as a way to make the project sustainable, if they are source available for paying customers, and personal modifications are allowed. Obviously redistributing any of that code, even my own modifications, would not be acceptable and would violate the license. You mentioned that the goal is to make the Gold edition features open source eventually, so would you consider going source available? reply nitinreddy88 5 hours agoparentprevThanks for the awesome work. Pre-ordered one to support reply BlueFalconHD 3 hours agoparentprevDid you design the logo? I saw it and immediately wanted to buy a license! Great product! reply helloanoop 3 hours agorootparentLogo is from openemoji: https://openmoji.org/library/emoji-1F436/ The real Bruno looks like the logo too :) https://www.usebruno.com/about reply Crowberry 11 hours agoprevWe recently moved over to bruno (from postman) for integration tests, and have had a great experience so far! Pros: - DevEx is great, the experience moving between writing tests through text vs the client is seamless (allows different expertise to collaborate more easily) - Fast and has all the basic features you’d expect - Offline first - Continuous improvements being made Cons: - Somehow, if the test fails connecting with the server its a passed test. So watch out for that one! I really hope it gets fixed soon!! - Would be great to be able to dump the variables after a run through CLI - Failed outputs from assertions and expects could be a bit more verbose, but it’s mostly likely the result of a dependency I assume reply majkinetor 11 hours agoprevI am using bruno on all my REST projects and the entire team is more than happy. We have bruno file for most endpoints demonstrating basic usage and as soon as something is problematic, someone creates bruno file in the repo and link to it so others can interactively discover what the problem is about. Since its cross platform and doesn't require any kind of on-boarding its joy to use and nobody complained. Previously, people used postman, thunder, curl and whatnot, but now everybody is on the same page. People created all sorts of scripts, such as automatic token refresh, so you jump straight to action. The fact that I can edit it in vscode is also amazing. Thank you. reply jonotime 10 hours agoparentCare to share any scripts? Automatic token refresh is a feature I am waiting for in Bruno. reply majkinetor 9 hours agorootparenthttps://gist.github.com/majkinetor/2a67c78af393865e4fa7daaa9... reply superfrank 11 hours agoprevFunny. I just found Bruno two weeks ago after getting fed up with Insomnia and am loving it. It feels like what Postman and Insomnia were when they started. Simple and to the point. There are a few minor features I miss (being able to bulk edit headers is the main one), but overall I highly recommend it. reply fuzzy2 1 hour agoparentJust curious, what’s your gripe with Insomnia? I find its UX a little clunky at times but haven’t found anything limiting my use cases. reply manquer 8 hours agoparentprevYou can do that by editing the collection file directly , Bruno watches for file system changes on the collection folder reply superfrank 3 hours agorootparentAh, that's good to know. I'm definitely going to use that trick. I'd still love to have a first class way to do that though. reply masa331 14 hours agoprevCan someone explain what Postman or Bruno is for? I know it's something for interacting with apis but why would i use it. I interact with apis a lot with curl or wrapper in my languages but never really needed something else? reply serial_dev 13 hours agoparentOne more thing I don't see mentioned is that you can share requests with your team easily, so if you worked on an API integration, you can document it, share it with your team, and when the next time someone else needs to fix something, they can find something that worked at some point and has all the required fields. Of course you could also just check in to version control these requests as curl commands, so if your team has the technical knowhow, that's about almost the same. Or even better, you write some tests in your language to make these requests, then you have an integration test, too. reply fuzzy2 1 hour agoparentprevTo put it simply: Postman is for everything but what curl is for. Sure it also performs the actual request somewhere under the hood but that’s mostly irrelevant. Having a single integrated user interface (it could also be a text UI) to craft a request, sometimes sending JSON, sometimes a file, then sending it to inspect the result, then modifying the request then doing it again is very powerful. Not to mention OAuth/OIDC support and the like. Sometimes, you have to find out how an API works, exactly. Sometimes you want to test your own APIs in ways the regular clients do not allow. reply jmopp 13 hours agoparentprevAs someone who uses curl and postman regularly, both tools have their places: I've found curl most useful for quick ad-hoc requests, or if I need to figure out why my service is no longer working. Postman I've found most useful to create a library of requests that are available on-hand: If I need to call services but I don't want to have to remember what the exact URL is or what the exact payload is. reply leosanchez 13 hours agorootparentHave you tried hurl ? It's kind of a mix between curl and Postman reply ericyd 13 hours agoparentprevFor me it's more convenient than curl for three reasons mainly: 1. Easier to organize collections of requests in a visual hierarchy 2. Environments mean you can use the same collection to easily execute against local, dev, staging, production, etc. 3. Pre- and post-execution scripts mean you can programmatically extract values and chain into other requests (think grabbing an access token from an oauth request then using that token for an authenticated request) It's basically just convenience features, nothing you can't get with other tools. reply midasz 1 hour agoparentprevFor me a big usecase is the ability to save specific requests and categorize / name them. It's a good way to document test data. If someone creates a feature which I want to test or debug I'd have to dig into the database to find which parameters I'd need to use, or I just find the right request in the tool. reply abledon 14 hours agoparentprevAlot of people in tech/tech-adjacent cant use CLI, need an easier alternative. Also, instead of having a huge .txt/.md recursive directory of curl commands, programs like these bundle up request workflows into 'collections' etc.. reply epolanski 13 hours agorootparentAlso it helps with documenting/testing. reply konaraddi 13 hours agoparentprevIt’s a rich GUI for calling APIs, including rudimentary load testing. reply dt3ft 13 hours agoparentprevCan be used to for api testing. Collections, token handling etc. Mostly for api testing, and collections can be shared among team members and source controlled. reply DotaFan 13 hours agoparentprevI really like to use Insomnia (Bruno alike) to import all project API's and debug API's over Insomnia. Does the job much faster for me. reply kirubakaran 13 hours agoprevIf you use Emacs, restclient is awesome https://github.com/pashky/restclient.el reply progre 12 hours agoparentIf you use VS Code REST Client is awesome https://github.com/Huachao/vscode-restclient reply S04dKHzrKT 12 hours agorootparentIf you use IntelliJ based products, the builtin HTTP Client is awesome. https://www.jetbrains.com/help/idea/http-client-in-product-c... reply gamache 11 hours agorootparentIf you use computers, Curl is awesome. https://curl.se/ reply BlueFalconHD 3 hours agorootparentIf you use a router, manually connecting wires to send data is awesome reply mordae 1 hour agorootparentprevFor JSON based REST APIs httpie is somewhat easier to use. reply bdcravens 11 hours agorootparentprevIn the same sense that no one needs a graphics editor when imagemagick is available via the command line. reply meonmyphone2 7 hours agoparentprevThis is what I use, my main complaint is that it doesn't format json well when using restclient mode. reply madduci 32 minutes agoprevDoes anyone know if it supports mTLS and maybe multiple certificates per domain? That would be great reply elric 2 hours agoprevGood to see some more open source competition in this space. SoapUI had most of those features some 15 years ago. I never understood why Postman became so popular, my current team even throws money at them. reply pjmlp 2 hours agoparentBasically because of \"blah but it is Java!\" kind of argument. SoapUI is great. reply throwaway56391 1 hour agorootparentAnd the \"SOAP\" part of the name is not helping either. reply antxxxx 1 hour agorootparentI found it uncomfortable to watch it making a request once someone pointed out to me that it highlighted letters in the order SOPA when waiting for a response reply agrippanux 7 hours agoprevI needed something like this today - was going to download Insomnia but I happened to check HN. I tried it out; it's exactly what I wanted. Postman, as echoed in previous comments, has gotten out of control with the upsell and the confusing UI. I bought the pre-order, seems like a good deal at $9, that's nearly the cost of a latte around here and if this works out I'll get a lot more use out of it than a latte. reply bennyp101 12 hours agoprevThere was a discussion a while back when the whole insomnia thing happened, where the dev points out how he aims to not go the same route https://github.com/usebruno/bruno/discussions/269 reply burnett2k 12 hours agoprevThis looks amazing. Postman is a great tool overall, but definitely seems to have gotten clunky and overly engineered. I don't need so many damn features. 99% of use cases are just hit an api. Will be trying this out immediately! reply hackernoteng 12 hours agoprevGood. Postman and Insomnia have shot themselves in the foot with overly complex UI and a mess of managing your collection of API calls in some horrible format and messing up the whole sync process and the simple ability to run everything offline without login, etc. I would also add that streaming (SSE) support would be great. reply corytheboyd 2 hours agoprevI’ve been happy with Postman, but it has gotten ridiculous lately, and I would ditch it in a heartbeat. It’s so painfully obvious that postman has turned into a money generating corpse. A good API testing tool isn’t rocket science, go forth and eat their lunch :) $9 for a perpetual license is a pretty damn good deal, and a total slap in the face to postman and insomnia, you have my pre-order! reply MBCook 10 hours agoprevDoes anyone know of any good guides to getting the most out of these kind of tools? I’m mostly interested in Postman since that’s what we have to use a work. I make requests with it, have things organized in collections, and use a variable for JWT handling but that’s as fancy as I’ve gotten and I know these tools have a lot more depth than I’m using. reply cliffwarden 8 hours agoprevIf you use and enjoy Bruno, please consider purchasing the \"golden\" edition that should be released in a few days. https://www.usebruno.com/pricing reply lovasoa 13 hours agoprevI am currently looking for a solution to run automated tests on a sql website generator I am working on ( https://sql.ophir.dev ) I wanted to use hurl (https://hurl.dev/), but Bruno's UI seems to be useful while developing the tests... Has someone tried both ? Which is better for automated testing, including when the response type is html and not json? reply ushakov 9 hours agoparentMaybe try Step CI (https://stepci.com) reply thih9 13 hours agoprevOne thing I like doing when working with APIa is to have an echo server at hand. I.e. something that I can query via curl or via a network library that I’m using, and see in response what kind of request it actually received. It helps me verify that I’m making correct requests (and not misusing curl or a network library). Currently I google for that and use the first online result that comes up. Is there an open source local equivalent, or does Bruno offer some solution for that? reply lelanthran 4 hours agoparent> One thing I like doing when working with APIa is to have an echo server at hand. > I.e. something that I can query via curl or via a network library that I’m using, and see in response what kind of request it actually received. It helps me verify that I’m making correct requests (and not misusing curl or a network library). Did you consider using a proxy during development. A man-in-the-middle server that does nothing but relay and record all communications between client and server? I made one specifically for this use-case. See it in action (3m video): https://www.youtube.com/watch?v=kpsFSY-G5F0 reply cyunker 12 hours agoparentprevI've been using https://httpbin.org/ to so some client testing and so far it has been great. They provide a docker image which makes it easy to run locally. reply ricekot 12 hours agoparentprevI use ZAP [1] with the OAST add-on for this at the moment. I admit the UX isn't perfect, but it serves my purpose. If I also want control over the responses (e.g. return a 401 status code for every fifth request), I have a custom extender script [2] for that. [1]: https://www.zaproxy.org/ [2]: https://www.zaproxy.org/blog/2022-09-13-zap-extender-scripts... reply notRobot 12 hours agoparentprevnext [–]86400 ]; then rm refresh_token; fi $ if [ ! -f refresh_token ]; then ./get_refresh_token.sh; fi reply pulkitsh1234 2 hours agoprevCan someone help me understand the difference between the .bru file and an OpenAPI spec (Swagger), aren't they representing the same thing with different syntax? reply karpovv-boris 7 minutes agoparentnext [–]aren't they representing the same thing with different syntax? - yes, they are reply nokeya 10 hours agoprevHistory goes in circles. New API client appears, adds features, userbase grows. Forced login is added, users are angry and look for alternative. New API client appears... reply 8bitme 2 hours agoprevIt may already be the case but it's not clear. If Bruno supported importing Postman collections it would be an easy decision moving across reply helloanoop 1 hour agoparentYes! Bruno supports importing postman collection’s reply jonotime 10 hours agoprevBruno is great. I'm in the process of moving my team to it. Cli, gui, human readable files. They are hitting all the right points. And it's open source so I don't care if they close up later down the line. It can always be forked like insomnium. I do admit it is rough around the edges (bugs and a bunch of missing features) but there is a lot of momentum right now and devs are working hard. Not long before postman parity. reply n00bskoolbus 12 hours agoprevBeen using Bruno for a while now and it's done what I need, I'm not doing any thing crazy just testing endpoints with maybe a small bit of scripting afterwards. Very pleasant to use. reply midasz 2 hours agoprevI've been using it for a month or so at work and I love how simple and fast it is. I need to dig into the advanced features but it's already useful. reply yashasolutions 11 hours agoprevBruno is awesome. The import from postman thing is really what make the difference - it makes adoption instant (because yes everyone is still running on postman). Regarding long term strategy, they seems to have a valid (non subscription based) where you can get some very nice premium feature for a one-off licence price (which is the kind of business model we need to support - instead of the madness we have going today with everything is subscription) reply wzulfikar 13 hours agoprevI've replaced Postman with Bruno (dekstop app), works great so far! It's nice to put the collection folder in git so I can collaborate with others and commit the changes to the repo. reply okr 4 hours agoprevWhile we are at it, is there a nice tool to document (foreign) APIs in a collaborative way? Maybe using Markup Language? Shared via Git? There are so many undocumented APIs there, that i use daily and it is good to put my annotations anywhere. reply israrkhan 4 hours agoparentI think you may want to look at OpenAPI specs. It is yaml description of API and can be consumed by many tools. reply okr 3 hours agorootparentNo, these APIs have mostly generated docs from code, they are just bad, and i want something, that is documented around it. Like a wiki. reply jameshart 10 hours agoprevThe complaints about postman collection files being hostile to Git collaboration is valid, but I will just say: we managed to cobble together a reasonable workflow, persisting our postman collections in source control, by writing a utility that strips out all the guids that postman needlessly changes every time you do a collection export. We use Newman to run the collections in our CI pipelines, and as the main way to run tests locally. It’s painful having to do an import/export of the collection from a file every time you want to modify the collection or debug a test, though, and the JSON files are still not entirely diffable/code reviewable even with the guids stripped. But it works - you can collaborate as a team with postman without using their cloud. But the idea of switching to a tool that actually wants you to work that way is definitely tempting. reply blah-yeah 11 hours agoprevIf you want to: store REST API requests as files, such that you can git version-control them may I recommend: https://marketplace.visualstudio.com/items?itemName=humao.re... super simple. just requires VS Code. Im checking out Bruno as well though, looks like a great tool reply dphuang2 2 hours agoprevThis is awesome, the postman collection format is not version-control friendly. I love what Bruno is doing! reply cube2222 14 hours agoprevThat looks nice! I stopped using Insomnia after they introduced the forced login to save your collection and wiped all my stored requests… reply adhamsalama 13 hours agoparentHave you tried Insomnium? reply cube2222 8 hours agorootparentHuh, I didn’t even know Insomnia was originally open-source. Thanks for this! reply zikohh 11 hours agoprevI've had my eye on Bruno for a while but this issue with path parameters is somewhat annoying. https://github.com/usebruno/bruno/pull/484 reply helloanoop 5 hours agoparentHey there! Thank you for the patience. We have been occupied with adding File Uploads and OAuth2 support in Feb and prepping for the Golden Edition release. This issue is priority. Hoping to get the PR merged soon. reply vsnf 10 hours agoprevIt's nice, but variable import from OpenAPIv3 needs a bit of work, compared to Postman and Insomina. Our OpenAPI spec has something like this: servers: - url: https://{host}/api/v2 variables: host: default: someserver.example Insomnia and Postman import the collection with the host as a variable, centrally editable, while Bruno imported it resolved with no variable, so I have to edit every one of my endpoints whenever I change the host, which happens often in our setup. reply jrks11o 8 hours agoparentSo there are no env variables? reply synthc 12 hours agoprevI prefer curl and bash for testing API's, it's less polished, but very flexible and it will never break or require an account. But for sharing requests in a team an app is nice. I had a good experience with Bruno. Bonus point for easy to store configs. reply v3ss0n 8 hours agoprevCheck lama2 https://github.com/HexmosTech/Lama2 reply tuananh 7 hours agoparentthis looks very good. i'm not sure why it's not more popular reply tobase 2 hours agoprevSwitched from Insomnia around one year ago! Really like Bruno :) reply INTPenis 13 hours agoprevBut can it handle oauth2? I had to write a httpie script recently just to test an oauth2 api. reply grounder 6 hours agoprevThe Insomnium (fork of Insomnia) might be a good alternative to compare. https://github.com/ArchGPT/insomnium reply dgan 13 hours agoprevFunny, i literally wrote an API tester a week ago for my job. It doesn't have a pretty syntax (in fact, it is the opposite of pretty, tests must be written in XML), but it does understand our authentication flow, and is able to not only assert the status codes and the returned json, but also the contents of Excel files, since we do lots of reporting. I haven't seen anything being able to compare excels. Also, usually test frameworks are aimed at developers (unsurprisingly), not at testers who might not be comfortable in writing scripts (looking at you, Katalon) reply mikaelsouza 14 hours agoprevDamn, I wasn't sure if I cared about another postman/insomnia like tool, but I saw the cute dog logo, and it sold the tool to me. Maybe I am just silly, but that got me. Congrats to the team for developing it! reply quercusa 13 hours agoparentThere appears to be an actual dog as well: https://www.usebruno.com/about reply bloopernova 10 hours agorootparentAww Bruno looks like a Very Good Boy. reply BlueFalconHD 3 hours agoprevLove the cute puppy logo! reply shinzui 10 hours agoprevHurl is better than any of those GUIs. You can version your Hurl files and use them for CI/CD. reply sureglymop 14 hours agoprevVery tempting! But, will there be a lifetime version/license? Would rather pay upfront instead of ending up potentially not really using it much for 2 years. reply throwitaway222 14 hours agoparentIt looks like the pricing page has lifetime licenses only. reply sureglymop 14 hours agorootparentIt says \"one time payment\" but then it says \"2 years of updates\". I interpreted that as having to pay a second time two years into the future if I will want another two years of updates then. A bit misleading. reply spiderfarmer 13 hours agorootparentIt doesn’t require you to upgrade so I don’t see the “misleading” part. reply imafish 13 hours agorootparentprevNot misleading - you understood it. Lifetime license does not necessarily equal lifetime updates. 2 years of updates is generous enough for $19. reply throwitaway222 12 hours agorootparentIt's similar to a lot of pricing plans out there. For example I purchased Home Designer Pro 2022 a couple years ago for $450 and I can use the HDP 2022 forever. They have, of course, HDP 2024 but I can't use that one. I can upgrade for an upgrade price. However I don't need to upgrade and am happy to just use 2022 for the rest of time. reply _kidlike 2 hours agoprevWhy not the .http files that IntelliJ and VSCode have implemented for years now? This should've become the standard by now. reply 1vuio0pswjnm7 11 hours agoprevWhat, if anything, differentiates an \"API client\" from an \"HTTP client\" (HTTP client includes TCP client) What is required to be considered an \"API client\" Perhaps \"API client\" is \"HTTP client\" + \"JSON parser\" Could \"JSON parser\" be a separate program reply thunderbong 11 hours agoparentAPI clients mostly expect JSON responses. So, test assertions have to be able to parse the responses and validate them. reply vsgherzi 12 hours agoprevThis is exactly what I was looking for, never understood why postman decided to monetize that way reply emrehan 14 hours agoprevI created a cli postman test runner 8 years ago due to the pains involved in API testing: https://github.com/hantuzun/jetman It seems like the API QA developer tooling has still room for disruption. reply ponector 12 hours agoparentThere is an official cli tool called Newman for running the postman collections. reply emrehan 7 hours agorootparentJetman was enabling writing and managing tests and it was using newman to run the tests. reply naizarak 9 hours agoprevI just block Postman servers in my hosts file and run an old version that still allows offline/anonymous mode. Works perfectly for my needs. reply benrutter 14 hours agoprevLooks awesome! Having version controlled api collections is a good enough idea that it makes all other ideas seem a little crazy. Any idea if the CLI app is available as a standalone? Looks like its a \"desktop app + cli” or nothing deal from what I can find. reply wadewatts 9 hours agoprevI tried Bruno not long ago. Have they added request “examples” like Postman has? If those make it into the codebase, I’m switching! reply alecsm 14 hours agoprevI'm tired of Postman freezing when sending JSONs over a MB in size. I had to purge it from the system a couple times because the tab wouldn't even load on start up making the whole thing unresponsive. I hope Bruno works better in that regard. reply adra 11 hours agoprevI just started to use the intellij built-in http client for my quick and dirty curl debugs and I gotta say it's pretty good for my limited needs so far. reply rgblambda 8 hours agoprevI looked into using Bruno ever since Postman enshittened the free client. I ended up just installing the version of Postman pre collections being removed and ignoring the prompt to update. I'm struggling to remember the reason I didn't stick with Bruno. I think it was due to not having an equivalent to Postman's pre-request scripts. If that could be added, I'd certainly give Bruno another try. Edit: Another comment has mentioned that Bruno now has (or maybe always had and I just didn't see) pre request scripts. reply hk1337 7 hours agoprevI am quite partial RapidAPI (previously Paw) but this looks really nice! reply udkl 7 hours agoparentPaw is the best tool UI wise. Postman/Bruno/insomnia all suffer from the 'curse' of web design making it's way into professional tools leading to lower information density and higher 'white space'. I feel so strongly on the matter is why I started a project that is unfortunately in comatose for the past year : https://nokori.surge.sh/ The design isn't there yet, but I'm aiming for a professional looking information dense UI. reply James_K 13 hours agoprevI would love to see more UI done in this style. That is to say treating your business logic as an API and then exposing it publicly to clients on different platforms. reply spdustin 13 hours agoprevMQTT is in the pipeline? That’s gonna be a huge deal for those of us working on IoT projects that also use REST for service data. I’ll be watching this for sure. reply pkulak 14 hours agoprevI’m the principal maintainer at work of a couple hundred bash scripts that use httpie and jq. I don’t have a huge appetite to redo that work… but this certainly seems nicer! reply tomhallett 9 hours agoprevDo you plan on supporting SQL queries? My top 2 would be postgres and snowflake. reply dmart 14 hours agoprevI like this a lot. Happy to support any project willing to reject the usual “success story” of selling out to VCs and turning your product into subscription-based SaaS junk. reply michaelcampbell 7 hours agoprevThe ability to SCM your \"scripts\" is so nice. reply jhoechtl 13 hours agoprevInsomnia was great. Than they more or less put of 90% of their users by forcing them in their cloud. Did that get any better? reply daniel-grigg 13 hours agoprevThe IntelliJ http client is pretty great too (after using both postman and insomnia) if you use IntelliJ already. reply throwitaway222 14 hours agoprevGolden Edition in the pricing page is listed twice, it looks like the middle column should read \"Individual plan\" reply darylteo 6 hours agoprevThis would complete the e2e DX if you could generate SDKs from .bru. Even if it's through a openapi export, I'm sure it will happen eventually. I'm sure Bruno is still in the 1st phase of enshittification, but at least with local .bru files we can ensure longterm maintainability. On the other hand, devs are most likely the stingiest individuals on the planet that expect all of their tools to be free. So I respect the team for even releasing it open source in the first place. reply Zelphyr 12 hours agoprevJust one minor note about your website: it breaks the back button. reply midnitewarrior 13 hours agoprevCan this read OpenAPI (Swagger) specs and generate calls based on the service description? reply JanisErdmanis 12 hours agoprevI just finished watching the introductory video and found the whole concept of PostMan and Bruno disappointing. It's baffling that one has to dive into the code to unearth the appropriate routes—a completely unnecessary and time-consuming endeavour. This process should be automated, ensuring that documentation and code are always perfectly aligned, eliminating any out of sync issues. The endpoints themselves should be directly accessible from automatically generated documentation using tools like Swagger. This isn't just a convenience; it's a necessity for efficient and effective development. So, what is the utility of tools like PostMan, Bruno and others when one has automatically generated docs with Swagger with which one can interact? As an example, you can check my current project where I have set docs like that (still need to add an endpoint field): https://peacefounder.org/PeaceFounder.jl/dev/schema reply ponector 12 hours agoparentImagine you have a scenario where you need to get a token first, then with GET retrieve an id of the item, then with POST create a new entity related to that id. And then you need to call another microservice with created id from post request. How you going to do it in swagger? And more serious question is how you going to force developers keep swagger up to date so I can execute such scenario? reply JanisErdmanis 11 hours agorootparent> Imagine you have a scenario where you need to get a token first, then with GET retrieve an id of the item, then with POST create a new entity related to that id. And then you need to call another microservice with created id from post request. This is a good explanation. I would however be inclined to do that within a script. > And more serious question is how you going to force developers keep swagger up to date so I can execute such scenario? The swagger is created automatically from the routes themselves so it is always up to date. To maintain endpoint an integration test can be written which executes the scenario. reply knallfrosch 12 hours agoparentprevWe use Swagger for internal APIs and Postman for 3rd party APIs. It's not like these sites serve swagger. reply HNArg024 12 hours agoprevLooks nice! Will give it a try, so I can ditch Insomnia reply AHTERIX5000 12 hours agoprevI've been looking for an alternative to Postman since its enshittification. Postman does not even work anymore if it can't reach internet. This looks actually useful and seems to have support for OAuth2 (which is the main reason I use something separate app instead of python/curl + sh etc) reply DustinBrett 9 hours agoprevGood thing it's open source. Money being involved, I don't have long term hopes for it's openness. reply hota_mazi 11 hours agoprevI really like IDEA's .http files [1] Very similar idea as Bruno: everything is configured in text, which I always find myself more productive in that full blown GUI where I need to tab from edit text to edit text to get anything don. [1] https://www.jetbrains.com/help/idea/http-client-in-product-c... reply Atotalnoob 11 hours agoparentSeveral ides support .http files reply YouAreADork 7 hours agoprevIs this native or an electron app? reply anonymous344 14 hours agoprevbruno seems really easy and good, but then.. it doesn't support cookies.. reply adhamsalama 13 hours agoprevDoesn't seem to support advanced stuff like GraphQL, gRPC, WebSockets... reply lazypenguin 13 hours agoparentSeems it does under the premium version reply cynicalsecurity 11 hours agoprevInsomnium. reply nothrowaways 14 hours agoprevLooks great reply everettwilson 12 hours agoprevWell this is fun to see. After Postman deleted my local data after I declined a cloud account, I started working on my own tool: https://github.com/EvWilson/sqump Some similar ideas - actually treats the file system as authoritative, runs locally, can share collections via source control with teammates. Difference in this case is that I used Lua as a lightweight scripting layer that I gave all my necessary tools to. So now I have a HTTP toolkit, and some for Kafka as well (which I use a good bit). I’ve been able to use it to replace all my API testing and development, as well as perform some more involved migrations and some dashboard-like actions (e.g. can list out resources and then check failures for each of their IDs). It’s also just a single binary with the web UI and CLI bundled in, which works more for me. Still early days for the little tool, but hoping it could be helpful for someone else. reply throwitaway222 14 hours agoprevPostman story: Layoff happened, and we didn't yet have our postman software in our list of services to remove employees from. This is not Postman's fault. One person had \"deleted\" all his collections and workspaces after the layoff to clear his laptop of all things related to our company. After we got an email from Postman saying our workspaces were deleted, I removed the laid off users. Since I removed the laid off user, the \"trash bin\" associated with them was also deleted. Postman support restored all the collections but the \"environment\" was gone. Which was all of our QA test keys, etc... Our Postman collections are still in shambles after that, and we don't have any employees to manage it anymore. While I totally don't hold Postman accountable - there is definitely a reason why \"no-cloud\" is a good way to go with these kinds of tools. reply sureglymop 14 hours agoparentIt makes no sense in the first place for such a tool to even need a login functionality and cloud saves... What's really needed to store information about a few http requests? Maybe a few kilobytes. I never understood it and I particularly don't understand how any company could fall for that. If they instead invested in teaching their engineers how to use curl even that would have paid off more. reply gardenhedge 14 hours agorootparentThe benefit of using postman is that you can open the app, see your (shared) collections, easily change the params and hit send. Can curl be used like that? reply leosanchez 13 hours agorootparentYou can use hurl which uses libcurl. You can save it to git and commit your hurl testa in the same repo. reply soraminazuki 13 hours agorootparentprevOf course you can. You can use any tool that lets you write down commands, run it, and edit it. Shells, editors, interactive notebooks like Org Mode, etc. The beauty is that it's just text that you can copy and paste between your tool of choice. You're not locked in to a single tool. reply throwitaway222 12 hours agorootparentIt's not very fun to run the auth call, then copy and paste the access token to the next call, and have to update all of your curl cmds all the time... Even if you use env variables, that's a horrible way to use env variables. reply soraminazuki 11 hours agorootparentYou’re making the case for automation, which happens to be something the shell excels at. Use unexported shell variables or command substitution (e.g., “$(pbpaste)”). Directly use the result of the auth call without going through the clipboard if possible. Create a shell script if shell history isn’t enough. Use interactive notebooks if you need something more advanced. The possibilities are infinite. reply throwitaway222 3 hours agorootparentAt this point, just write a script Or perhaps write a script that has some kind of GUI. Or maybe make the gui run the URL You're right the possibilities are endless. And this Bruno and postman or permutations of that endlessness. reply eviks 6 hours agorootparentprevYou're describing the same tool with a much worse UI of recreating the tool yourself (by everyone). There is much value in avoiding that, hence people use integrated tools even with the risks of lock in reply jonS90 5 hours agoprevThis makes me think of an alternative that no one seems to be mentioning: http/rest files. They're git-friendly and there are community plugins to operate them from every major IDE. I believed the standard was created by jetbrains. https://www.jetbrains.com/help/idea/http-client-in-product-c... reply helloanoop 5 hours agoparentWhat sets Bruno apart? Nice GUI Clients: Postman, Insomnia, Paw (ease of use) Nice CLI Clients that use plain text files: Jetbrains Http Client, Hurl, Httpie (privacy) Bruno: The only GUI client with a Nice UI that works on top of plain text files It's the best of both worlds. reply devsda 4 hours agorootparent> Nice CLI Clients that use plain text files: Jetbrains Http Client, Hurl, Httpie In what way is Jetbrain's http client a CLI tool ? There's also vscode rest client. There's no need to shortsell other clients. I think Bruno has sufficient differentiators to standout on its own. reply helloanoop 4 hours agorootparentSorry if it came across as trying to shortsell. I was just trying to point out the key thing that makes Bruno unique in the ecosystem reply jicea 4 hours agorootparentI'm the maintainer of Hurl and was really graceful to be cited by you! reply wenbert 5 hours agoparentprevOh yes. This one is Jetbrains only but there is also a VScode alternative for this. There is a plugin called httpyac and I believe it also supports the same kind of configuration (???) and variable syntax. It's great not switching to other apps for making an http request. reply divbzero 11 hours agoprevI really like the idea of serializing requests to a Git-friendly text format. But if we want a Git-friendly text format, why not mimic HTTP/1.1 request syntax as much as possible? Maybe with Jekyll-like YAML front matter for metadata that doesn’t fit? So for Get Users.bru instead of the current example of: meta { name: Get Users type: http seq: 1 } get { url: https://reqres.in/api/users body: none } headers { Content-Type: application/json } We could adopt a format like: --- name: Get Users type: http scheme: https seq: 1 --- GET /api/users HTTP/1.1 Host: reqres.in Content-Type: application/json reply schoenobates 9 hours agoparentIntellij (and all the other variations) has something very similar to this called [0]HttpClient. Being able to commit and basically just read the file is very useful. You can also do validation and scripting with it too. [0]https://www.jetbrains.com/help/idea/http-client-in-product-c... reply Cthulhu_ 10 hours agoparentprevI've used a plugin in both VS Code and IntelliJ that is just that, I just saw someone else post it too: https://marketplace.visualstudio.com/items?itemName=humao.re... Example: GET https://example.com/comments/1 HTTP/1.1 ### POST https://example.com/comments HTTP/1.1 content-type: application/json { \"name\": \"sample\", \"time\": \"Wed, 21 Oct 2015 18:27:50 GMT\" } reply Karupan 10 hours agorootparentSecond this. One of the first VSCode extensions I install and recommend for non-devs in the team as well (BAs, QAs, etc). Kind of insane how human friendly HTTP 1.1 is. reply lb4r 8 hours agoparentprevJust out of curiosity, why is the below example more git-friendly than the above? Smaller deltas? (and if so: why?) reply manquer 8 hours agoparentprevThere is reason they didn’t go with YAML like syntax the author talks about it extensively here https://github.com/usebruno/bruno/discussions/360 reply Aeolun 9 hours agoparentprevI think hurl does this? reply 7fYZ7mJh3RNKNaG 10 hours agoparentprevWould love this reply sergioisidoro 13 hours agoprevI found Bruno after Insomnia adopted the Postman strategy of being cloud first, with a disastrous migration - I momentarily lost all my local projects after an update. I've been using it for a while and I really like the offline first + git collaboration aspect of it. Only missing Websockets functionality at the moment. reply d0gsg0w00f 14 hours agoprevThank you. As soon as Postman asked for a login I uninstalled it and have been curling from text files ever since. My younger coworkers won't drop Postman though. Maybe this will help them switch. reply hn_throwaway_99 13 hours agoparentCan't echo this enough. Thank you! Beyond just the login reqs from Postman, the whole Postman UI has become an overcomplicated mess in my opinion. I just want something simple to make remote HTTP calls. I can understand adding some useful extra things like variable interpolation and separate environments, but beyond that, Postman went way off the \"enterprisey\" deep end. reply myaccountonhn 7 hours agorootparentI use hurl, works absolutely great and the scripts end up reusable by others. reply amirathi 5 hours agorootparentprevWhen you raise $$$ - the nice little API client needs to become \"Enterprise API Platform\" reply parkerrex 5 hours agorootparent^this reply Alifatisk 11 hours agorootparentprevYou should try insomnia reply winphone1974 10 hours agorootparentInsomnia and postman are pretty similar these days. I like the REST extension for VS Code and hurl reply Reptur 7 hours agorootparent100%, its awesome. Link for those interested: https://marketplace.visualstudio.com/items?itemName=humao.re... reply vorticalbox 10 hours agorootparentprevThis also requires a login I believe reply piyh 8 hours agorootparentThey locked users data behind a login screen a week after postman, then had a half assed \"sorry you misunderstood our corrupt intentions, we'll back out the change\" apology reply paulryanrogers 10 hours agorootparentprevNot at first but as of late, yes. :( reply vladvasiliu 10 hours agorootparentprevYou can still use it without an account, although it tries quite hard to get you to use one. reply bisby 14 hours agoparentprevThe irony that I switched to Insomnia after Postman started demanding a login... and now I've been actively looking for alternatives (Bruno being on the list) now that Insomnia has done the same thing. reply margorczynski 13 hours agorootparentWell based on historical experience with Postman and Insomnia most probably Bruno will go the same way once they get enough users hooked in. Especially once a VC gets into the fold. reply helloanoop 12 hours agorootparentHey there, this is Anoop - creator of Bruno. Happy to see Bruno at the top of HN We will never take VC funding. We received around 10 inbound reach outs from VCs till date and have denied funding from all of them. We will remain independent and I have written about it in detail here https://www.usebruno.com/blog/bootstrapping reply biglyburrito 11 hours agorootparentThank you for posting here, and also for Bruno... I'll be giving it a shot in the coming days, as I only learned about it when I read this post. reply hyperthesis 4 hours agorootparentprev> An API client is not venture scale. Your link makes sense, and I believe you. Have struggled with similar issues. But who knows what the future will bring? Google once said \"don't be evil\"; Oracle bought Sun. Is there any way you can guarantee your future actions? Contracts, articles of association/company constitution? Maybe setup a trust or charity? I don't think there is. reply ARandomerDude 9 hours agorootparentprevRecommend you copy/paste this as its own top-level comment on this article, so it doesn’t get buried. reply 7fYZ7mJh3RNKNaG 10 hours agorootparentprevThank you for clarifying. Just made me download it. reply bloopernova 10 hours agorootparentprevPlease give the real Bruno a hug from this Internet stranger? He looks like a very good boy. reply Sn0wCoder 8 hours agorootparentprevHi Annop. Thanks for sharing this looks like a good alternative to Postman. I see the company is based out of India (awesome) but wanted to know if the company has gone through the steps needed to sell to teams in the healthcare industry in the US/UK i.e.) HIPPA, SOX2, PCI, GDPR, etc.… reply jasonjayr 5 hours agorootparentIf they never take possession of the user's data into their environment, then most, if not all of those don't even come into play? Like, that's kinda the whole point of offline-first, local-only tools, you can 100% use them in a an environment you control and take responsibility for. Once you take control of customer's data, there's a whole litany of due diligence that must considered, and often at considerable cost. reply Sn0wCoder 1 hour agorootparentWhile I agree with you and understand that the data is local only, we can only use tools approved by the company. I would like to suggest that my team take Bruno for a 3 – 6 month test drive (since Postman was unable to check the boxes) but cannot without approval…. reply unmole 6 hours agorootparentprev> if the company has gone through the steps needed to sell to teams in the healthcare industry in the US/UK i.e.) HIPPA, SOX2, PCI, GDPR, etc. They haven't. reply josephcsible 13 hours agorootparentprevI foresee this happening too. For me to not worry about this, three things would have to happen: 1. Open source everything, including the parts of the code that are currently premium 2. Switch to a copyleft license like the GPL 3. Start accepting substantial contributions from the community without a CLA Then they'd be legally unable to do that kind of rug pull. reply dumbo-octopus 12 hours agorootparentprevDownload Insomnia 2023.5.8 and disable automatic updates. Though Insomnia doesn't work with streaming responses at all, which is a bit of a non-starter in the age of AI. Anyone know a good streaming HTTP UI? reply 1vuio0pswjnm7 11 hours agorootparentDoes this describe the \"streaming HTTP\" to which you refer https://gist.github.com/CMCDragonkai/6bfade6431e9ffb7fe88 If not, is there an example of \"streaming HTTP\" you could provide that illustrates the limitation reply dumbo-octopus 8 hours agorootparentYes, that is that I mean. All the modern \"ChatGPT\" style API's use this, so if you're building anything that invokes them you can choose between buffering the entire response and modifying/relaying it once complete, or building up a toolchain of streaming-capable utilities. Of all the http-client applications I tested (Curl, Postman, Insomnia, Bruno), somewhat hilariously Curl has the best support. It will output all 'Transfer-Encoding: chunked' with line-by-line buffering, whereas Postman only supports responses precisely following the `Content-Type: text/event-stream` format (strictly less powerful than curl, as this format requires newlines in between events, and a bunch of overhead on top of that). The others buffer the entire response before displaying anything. The `Content-Type: text/event-stream` format is fine enough, but I personally prefer to just plainly chunk the responses and let the client choose whether to buffer them into memory and operate on the entire value at once, or interpret them live as the chunks come in. With tools like gjp-4-gpt (Gradual JSON Parser 4 GPT's) you can even interpret partial JSON objects live as they come in and display complex/nested data structures in a generative manner. reply 1vuio0pswjnm7 6 hours agorootparentWhat if instead of JSON, i.e., strings of unknown length, used something more like netstrings. https://cr.yp.to/proto/netstrings.txt Personally I use a lame but effective simple 85.9 KiB static binary filter, a small C program, that removes the chunk sizes so the response is ready for use by other programs, e.g., in a pipe. Buffer is set at 8 KiB. Is there a way to experiment with one of these streaming JSON GPT APIs non-interactively by just sending an HTTP request, without need for a third party program, an account, use of a Javascript engine, etc. reply dumbo-octopus 6 hours agorootparentThe unknown length isn't much of a problem for me in practice: GPT's are slow enough that getting a large chunk is almost impossible. I like the idea of the C filter, but in the end you're just piping the data to the program, why add the middle step? Is it to protect against too-large chunks in some way? I don't know a public API that returns JSON slowly, but you could simulate it by just taking a JSON string, splitting it into 3-5 char chunks, and sending each of those in a `Transfer-Encoding: Chunked` response at ~100ms intervals. Actually, now that I look at the underlying mechanism behind `Transfer-Encoding: Chunked`, it looks like it's already basically the same as the netstrings. What I'm referring to is the (variable length) contents of the netstring/chunk being sequential slices of a JSON object. reply 1vuio0pswjnm7 4 hours agorootparent\"I like the idea of the C filter, but in the end you're just piping the data to the program, why add the middle step?\" Only for the flexibility to use more programs. Otherwise every program I use to process HTTP responses needs to be able to accomodate chunked transfer encoding. Plus only a minority of sites send chunked responses. Instead, have one program that does one thing: remove chunked transfer encoding. IIUC, what you want is uniform chunk sizes where you know the size before you send the request. GPTs sound annoying if they are so slow that they only output a few characters every ~100ms.. reply dumbo-octopus 2 hours agorootparentAh I see, I'm working a bit further up the stack from you so the JS runtime handles making the transfer encoding of the response more or less irrelevant, for any response with any encoding you can access `response.text()` and get the entire contents when they're ready, or do something like `for await (const chunk of response.body) { ... }` to work with the pieces as they roll in. > IIUC, what you want is uniform chunk sizes where you know the size before you send the request. I don't think so... I don't really want anything! Just a GUI that displays existing HTTP chunked responses as they come. > GPTs sound annoying if they are so slow that they only output a few characters every ~100ms.. That's perhaps an exaggeration, but in general the speed and \"smartness\" of the model are inversely correlated. reply 1vuio0pswjnm7 2 hours agorootparentI'm not really a GUI person nor do I use JS. I'm happy to see HTTP responses in textmode. I tried playing around with Postman and some other similar programs a while back in an attempt to understand how they could be superior to working with HTTP as text files. But I failed to see any advantage for what I need to do. One problem with GUIs/TUIs IMHO is that generally few people write them or modify them. And so users must look around to try to find one written by someone else that they like. Then they are stuck with it, and whatever \"options\" its author chooses to provide. Whereas with textmode programs, I can easily control all the aesthetics myself. Even when using other peoples' software, if there is something that annoys me, I can usually edit the source and change it. Best of luck. Hope you can find the right program for viewing HTTP. reply ponector 12 hours agorootparentprevWhy not to do the same with postman? I still use it without the login. reply dotancohen 12 hours agorootparentFrom where do you download old Postman versions? More importantly, which was the last version recommended? reply dumbo-octopus 5 hours agorootparentThe \"Lite API\" mode of current Postman is actually decent, it's the only GUI client I know that supports streaming responses, but you have to use `Content-Type: text/event-stream`. You can't save/share queries, but the local history is decent enough for local development. I prefer it to the Insomnia mutable fixed length saved query implementation for \"hacking around\" with many different APIs. reply dotancohen 12 hours agorootparentprevIt's not open source, but it's in my workflow anyway. The JetBrains HTTP tool is excellent, and has been getting better and better for quite some time. reply leosanchez 14 hours agorootparentprevHave you tried hurl ? reply winphone1974 10 hours agorootparentHurl is great, especially for testing but I fear it's not acceptable by a huge segment of developers because of the lack of a UI reply adhamsalama 13 hours agorootparentprevTry Insomnium. reply parentheses 6 hours agoparentprevI will usually take curl commands i end up calling a lot and use a function or script to make those calls easily. I find this to be way better for me personally. I feel using Postman teaches you only Postman. Whereas making shell tools and learning curl are so much more valuable. Plus, you can combine them with fzf, jq, fx, yq and friends to easily customize. reply jicea 4 hours agorootparentShameless plug for Hurl [1]: it's a cli tool, based on plain text and curl to run and test HTTP requests. It's just libcurl + the possibility to chain and test response. You may like it! (I'm one of the maintainers) [1]: https://hurl.dev reply rozenmd 13 hours agoparentprevI started using Yaak after Insomnia and Postman both decided to become user-hostile, it's decent: https://yaak.app/ You'll never guess who makes it. reply staticshock 11 hours agorootparentHeyo, looks like it's Gregory Schier, the maker of Insomnia: https://schier.co/ reply gschier 10 hours agorootparentprevYes, it's me! Thanks for the mention reply staticshock 9 hours agorootparentDo you have any plans to open source the thing? reply gschier 9 hours agorootparentNot at the moment. If I decide to pursue it full time then probably reply roskoez 11 hours agorootparentprevJeff Minter? reply ben_w 8 hours agorootparentWas thinking about him earlier (due to a bad pun on my part). Glad he's still around making games. reply asabla 13 hours agoparentprevI did something similar as well. But instead curling from files I've been using http-files. Depending on which project I'm working on (and customer), I'll be using different tools to run em. But to show you an easy example to follow, you could check out this jetbrains cli tool https://blog.jetbrains.com/idea/2022/12/http-client-cli-run-... reply d0gsg0w00f 10 hours agorootparentI think it's just the nature of how I use APIs. I do discovery with curl then just write a golang CLI for long term use. I'd probably save a lot of boilerplate using something like http-files though. reply Eji1700 11 hours agoparentprevI know people don't love VS Code, but is there a reason Thunder Client isn't more popular? I know it's feature lacking compared to postman, but more so than curling? reply CharlesW 11 hours agorootparentThis looks nice too, thanks for sharing! I can also recommend RapidAPI for macOS users. reply icandoit 8 hours agorootparentprevIt limits collections to 50 endpoints. I also couldn't immediately see how to plug tokens into variables. Bruno is intuitive and has no pay-to-remove limits. reply majkinetor 11 hours agorootparentprevTeam options are behind the paywall. Besides, bruno is simply better. reply MissTake 11 hours agorootparentNot necessarily so. We don’t pay but our small team still shares projects with the tool. reply majkinetor 1 hour agorootparentSure, its possible, not exactly great experience though. reply jimbokun 6 hours agoparentprevI tend to collect little Ruby one or two liners for common REST calls, and now Go. Takes care of things like getting a JWT token and including it in the right header, as reusable code. Takes slightly longer the first time than curl or Postman. But much more powerful in terms of using in scripts for operations tasks. reply _flux 13 hours agoparentprevI use httpie's CLI tool for testing application/json endpoints. That and some jq really can make some things nice. (Apparently it has a GUI version as well, but I'm not interested in trying it.) reply hackernoteng 12 hours agorootparentI also have fallen back to just using curl + jq and a set of saved commands since both postman and insomnia have decided to make my life harder not easer. good old plain unix command line tools never fails you. reply quickthrower2 12 hours agoparentprevI did the same switch. Then went to the Chrome extension YARC https://chrome.google.com/webstore/detail/yet-another-rest-c... which I like for the simplicity. It does remember past queries. reply duxup 5 hours agoparentprevI just liked when I could start postman and it would just start fast. As it is the things I test start up faster than postman who is … I don’t know what it was doing when I quit on it. reply ivan888 10 hours agoparentprevvim-rest-console[0] has been my Postman alternative for years. It basically wraps curl and makes it super easy to make different requests from a single text file. Can even write YAML and have it converted to JSON before being sent in the body. Really great tool 0: https://github.com/diepm/vim-rest-console reply d0gsg0w00f 8 hours agorootparentThis looks right up my a alley. Thanks for sharing! reply gitaarik 13 hours agoparentprevHehe, always the same. Popular non-FOSS software always dies in these kinds of ways. That, and that it's Chrome-only, is why I never wanted to use Postman. I've been using RESTED [1] in Firefox happily for quite some time. Although I don't use it that much since unit tests and Django Rest Framework's web UI is usually sufficient for testing and debugging. [1]: https://github.com/RESTEDClient/RESTED reply interbolt_colin 13 hours agoparentprevGreat point. I almost wrote, \"why use a bru file when more established scripting languages and libs exist for this\". But it seems the point here is to bridge the gap between some devs (maybe more junior) on a team that prefer a GUI while also providing a more vc/cli driven experience for the rest of the team. Not to mention, that bru syntax looks really nice. reply 4death4 8 hours agoparentprevDo you just store the entire curl command in a text file or do anything more complicated? reply Poliorcetes 13 hours agoparentprevhere's the thing, developers probably like to eat, so the program has to eventually make money somehow. how does this program plan to make money? reply croes 12 hours agorootparenthttps://www.usebruno.com/buy-golden-edition reply YetAnotherNick 13 hours agoparentprevWhile I do hate Postman because its overcomplicated in everything. But attitude like yours has shifted people and money away from developer tools. Instead of all the possible tools we could have from many developers, we are now totally dependent on big tech to sponsor it, like VSCode etc. And over time it would move in direction that will promote another service from the same company like copilot and vscode. reply ben_w 8 hours agorootparent\"A GUI for a command line tool\" is, these days, at the level where you can get the first 80% of the value by asking ChatGPT to write it for you by copy-pasting in the bits of the man page for the options you want. (The second and third 80%'s still need human intervention). reply ryandrake 9 hours agorootparentprevDeveloper Tool Developers are hurting themselves. I think it is reasonable to not want to have to log in to every darn thing you use on the internet. Especially developer tools. Someone needs to invent a hat that developers have to wear: when the developer starts to write signup, login or authentication code, a hand pokes out of the hat and slaps him. reply nyanpasu64 9 hours agorootparentDefault-on telemetry as well. I'm reminded of Balena Etcher phoning home with the names of ISO files you flash, which leaks the IPs etc. of which users are creating Tor/Tails bootable USBs: https://gitlab.tails.boum.org/tails/tails/-/issues/16381#not... reply ryandrake 9 hours agorootparentYes, telemetry too! And automatic updates. They are all symptoms of companies’ obsession with having some kind of ongoing post-purchase “relationship” with their users. As a user, I don’t want this relationship! I just want to buy the tool and use it, without ever interacting with the manufacturer ever again. If I buy a circular saw, I don’t want a relationship with Makita. I don’t want to have to log in to use it. I don’t want it telling Makita how many boards I cut and how well the saw is working. No offense, but I’m just not that into you, Manufacturer. reply YetAnotherNick 5 hours agorootparentprevJudging by vscode's or copilot's or postman's popularity, login is not the issue. The issue is the quality of the tool and number of developers they can hire. reply fragmede 9 hours agoparentprevnext [6 more] [flagged] gamepsys 8 hours agorootparentYou can't continue to make a product worse over time without expecting to lose some customers. When someone tells you why they stopped using your product, don't brush off the feedback as whiny entitled complaints. reply triyambakam 9 hours agorootparentprevNo, Bruno offers paid but with Postman it burns: they removed your personal data after upgrade and you can't store your own data locally. I will likely buy Bruno because it is a one time fee and I control my data. It should work forever after that. reply hn_throwaway_99 9 hours agorootparentprevBaloney. As other's have mentioned, Bruno also has a paid option. Postman's problem is they took hundreds of millions of funding that somehow thinks an API request tool is worth $5.6 billion (though I'm sure that's waaaaaaaaaaaaaay down from the 2021 ZIRP frenzy). So now Postman has long since gone down the full enshittification path with a totally unnecessarily complicated UI and authentication and cloud features that hardly anybody really wants. I like Bruno simply because I believe their approach is much better: simpler UI and, importantly, as their demo video points out, collections of API requests can be saved in an easy-to-understand format in git. Much better than some proprietary cloud storage. reply coldtea 9 hours agorootparentprev>How dare they try and run a business and get paid for their work They can run whatever they want. I, and the parent, wont be using it. Bruno has a paid option too, btw, and I'm fine with that. I'd be fine even if it was the only option. Login and extra BS features to tie me in? No, thanks. reply zarathustreal 8 hours agorootparentprevRunning a business is perfectly acceptable. Paid tools, likewise, as perfectly acceptable. Granted, most of software is built directly or indirectly on free work either of the intellectuals that discovered the foundational knowledge required to build it or of the engineers that built the tools. What’s not acceptable is the rug-pull of presenting something as free and trying to claw back money from the endeavor after you’ve got users locked in. If you need money, don’t offer a free product. If you offer a free product, make sure you can afford it. No one is going to judge you for charging the worth of your offering. However, you’re also not going to get free goodwill and advertising for no reason. Spend your time and energy wisely, that is your personal responsibility. reply 13 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Bruno is a rapid and open-source API client challenging tools like Postman and Insomnia.",
      "It utilizes a text markup language to store API request data on the filesystem, enabling collaboration through Git and similar systems.",
      "The focus is on data privacy, offering an offline-only approach without cloud-sync, with pre-orders open for the discounted Golden Edition."
    ],
    "commentSummary": [
      "User frustrations center on API clients like Postman mandating a cloud account, while others like Insomnia have limitations.",
      "Bruno, an open-source API client, is lauded for speed and Git compatibility, in contrast to monetization pressure from companies.",
      "Discussions cover the advantages and disadvantages of API testing tools like Bruno, Postman, and Insomnia, highlighting challenges in collaborating on API documentation."
    ],
    "points": 933,
    "commentCount": 282,
    "retryCount": 0,
    "time": 1710008996
  },
  {
    "id": 39651796,
    "title": "Monodraw: Mac ASCII Art Editor with Advanced Features",
    "originLink": "https://monodraw.helftone.com/",
    "originBody": "Blog @Monodraw Powerful ASCII art editor designed for the Mac. Free Trial Buy License — $9.99 Requires macOS 11 Big Sur or later. Educational Pricing Follow @Monodraw Harness the Power and Simplicity of Plain Text Plain text has been around for decades and it's here to stay. Monodraw allows you to easily create text-based art (like diagrams, layouts, flow charts) and visually represent algorithms, data structures, binary formats and more. Because it's all just text, it can be easily embedded almost anywhere. Of course, exporting as images is also supported (PNG and SVG). Diagrams A picture is worth a thousand words. A diagram is probably worth twice as much. Enhance your technical documentation (code, specs) with easy to comprehend textual art. Visualisation of data structures, algorithms and data formats plays a crucial role in understanding. You will be reading the code more often than writing it, so why not make it much easier to grasp. Mind Mapping Combine the simplicity of plain text with the power of mind mapping. Monodraw gives you the freedom to manage your textual data exactly the way you want. Move text around anywhere in the infinite canvas – no need to be constrained by the linear structure of a text file. ER Diagrams Do you deal with databases? Then you know how useful entity-relationship diagrams can be. Visually describe your data model with a simple ER diagram. Monodraw supports Crow's Foot notation in three different variants to suit your personal preference. Banners Easily create text banners with just a single click. FIGlet is built into Monodraw and we bundle 148 fonts as standard (custom ones are supported, too). You can interactively resize the text box, change the font and adjust the alignment – no need for a terminal. Text Tool Monodraw is powered by a custom CoreText-based text engine giving you precise control over the layout. You can adjust the alignment, position, line sweep direction and line movement. Adding a border around your text is only a click away, too. Line Tool The line tool makes connecting shapes as easy as pie. Orthogonal and staircase lines are supported with the ability to set a line dash pattern. Attachment points allow you to dynamically attach your lines to other shapes so that you don't have to re-arrange them each time you move things around. Rect Tool The rectangle tool can be used to create all kinds of boxes which are the most commonly used element in text art. Specify border or a background with just a few clicks. Oh, you can add shadows, too! Last but not least, custom attachment points will help you attach your lines at exactly the right place. CLI Included Monodraw includes a command-line interface (Direct version only). For example, you can use it to automatically generate docs when committing by leveraging version control hooks. The tool can also output JSON, for easier programmatic manipulation. Drawing Tools The basic drawing tools that you would expect make their usual appearance. The Pencil, Eraser, Bucket Fill and Picker are all indispensable when it comes to producing textual art. You can also easily overlay any images on the canvas for tracing purposes. Powerful Features When it comes to creating text art, Monodraw helps you out by providing the tools you need. Groups Shapes can be grouped for effortless management. By composing multiple elements to form a single group, duplication and movement become very easy. Guides Alignment guides are a life-saver when arranging and sizing your content – no longer do you have to stare at the screen and count the number of characters. Focus When you need to focus on a particular part of the canvas, the rest of the shapes can be locked or hidden away. You can then zoom in to concentrate on the currently visible elements. Shortcuts All functionality can be efficiently accessed via shortcuts, so there is no need to take your hands off the keyboard. Tools are quickly accessible with a single keystroke, without the need for a modifier. ◎ │ │ ┌─────────────────────┐ ┌──────◇──────┐ │ │ │ │ │ │ ┏■──┘━━━━━━━━━━━━━└──■┓ │ │ ┃*━━━━━━━━━━━━━━━━━━━*┃ ◍ Hello, dear friend! │ ┃┃ ■■■■■ ■■■■■ ┃┃ ╱ │ ┃┃ ■■■■■ ■■■■■ ┃┃ ╱ │ ┃┃ ■■■■■ ■■■■■ ┃┃ ╱──◍ │ ┃*━━━━━━━━━━━━━━━━━━━*┃ └─────────────────────┘ ◆─────◆─────◆─────◆─────◆ │╲***╱*╲***╱*╲***╱*╲***╱│ │*╲*╱***╲*╱***╲*╱***╲*╱*│ └──◆─────◆─────◆─────◆──┘ ┗━━━━━━━━━━━━━━━━━━━━━┛ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┏━━━━━┃///////////////////////////////////┃━━━━━┓ ┃ ┌─┐ ┃.▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫▫.┃ ┌─┐ ┃ ┃ │ │ ┃.▫ ╔═════════╗ ▫.┃ │ │ ┃ ┗━│ │━┃.▫ ║ ┌┐ ●─○║ ▫.┃━│ │━┛ │ │ ◎─▣──────────▣ ││ ┌─▣──────────▣─◎ │ │ │ │ ┃.▫▨▨▨▨▨▨▨▨▨▨└┐ ┌┘└┐┌┘ ║▨▨▨▨▨▨▨▨▨▨▫.┃ │ │ │ │ ┃.▫◹◹◹◹◹◹◹◹◹◹║└─┘ └┘ ║◸◸◸◸◸◸◸◸◸◸▫.┃ │ │ │ │ ┃. ╚═════════╝ .┃ │ │ ┏━━━┓┃..┃┏━━━┓ ┗━━━┛┃. M O N O D R A W .┃┗━━━┛ │ │ ┃..┃ │ │ │ │ ┗━━━━━━///////////////////////━━━━━━┛ │ │ │ │ ┃◦ ◦┃ │ │ │ │ ┃ ┏━━━━━━━━━━━━━━━┓ ┃ │ │ │ │ ┃◦ ┃▤▤▤▤▤▤▤▤▤▤▤▤▤▤▤┃ ◦┃ │ │ │ │ ┃ ┗━━━━━━━━━━━━━━━┛ ┃ │ │ ┌──◎──┐ ┃◦ ◦┃ ┌──◎──┐ │ ┌─┐ │ ┏━━━━━━━━━━━━┓◬◬◬◬◬┏━━━━━━━━━━━━┓ │ ┌─┐ │ └─┘ └─┘ ┃ ┃━━━━━┃ ┃ └─┘ └─┘ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃\\\\\\\\\\\\\\\\\\\\\\\\┃ ┃\\\\\\\\\\\\\\\\\\\\\\\\┃ ┌──────────────┐ ┌──────────────┐ │ │ │ │ └──────────────┘ └──────────────┘ ┃////////////┃ ┃////////////┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┃ ┌────────────────┐ ┌────────────────┐ │ │ │ │ ┏━━━━━━━━━━━━━━━━┓ ┏━━━━━━━━━━━━━━━━┓ ┗━━━━━━━━━━━━━━━━┛ ┗━━━━━━━━━━━━━━━━┛ Designed for Mac Monodraw is designed for the Mac from the ground up – everything from the text layout engine to the interface is made to take advantage of macOS. Like all native apps, it just works the way you expect. When you make a mistake, undo is always ready to come to the rescue. Exporting your text art could not get any easier – just copy and paste it into your favourite text editor. Not displaying correctly? What are the system requirements? The app requires macOS 11 Big Sur or later. If you're running an older version of macOS, you can download Monodraw v1.3 which requires macOS 10.10 Yosemite or Monodraw v1.5 which requires macOS 10.14 Mojave. Which versions include the command line tool? Only the versions which you download directly from our website and purchase from our store. Due to restrictions imposed by the App Sandbox on the Mac App Store, the tool cannot be included there. How do I provide feedback? We would love to hear from you — the best way would be to drop us an email. Alternatively, just tweet us @Monodraw. How are you going to use my email? I hate spam. We hate spam, too. We would not share your email with any 3rd parties, period. We would only email you if we have important news about Monodraw and our upcoming products, that's it. Do you have a Press Kit? Of course — you can download it from here. Do you offer Educational Pricing? Yes, we do — just get in touch. Privacy Policy We take your privacy very seriously. Monodraw does not collect any data whatsoever. All Rights Reserved © Helftone Ltd Twitter Blog Contact Press kit",
    "commentLink": "https://news.ycombinator.com/item?id=39651796",
    "commentBody": "Monodraw (helftone.com)719 points by saikatsg 18 hours agohidepastfavorite150 comments smusamashah 9 hours agoI maintain a list [1] of main web based text to diagram tools including ascii drawing tools like these. Web alternatives for this are probably https://fsymbols.com/draw/ or https://textik.com/ or https://asciiflow.com/#/ or https://web.archive.org/web/20210503172024/https://fatiherik... or https://app.monosketch.io [1]: https://xosh.org/text-to-diagram/ reply 8ig8 8 hours agoparentPikchar is another to consider for your list. From the creator of SQLite… https://pikchr.org/home/doc/trunk/doc/userman.md reply smusamashah 7 hours agorootparentIt's the second item on the list already. reply lebean 6 hours agorootparentYes but you only listed it once! reply peacebeard 6 hours agoparentprevYears ago I made a simple one that I still host at https://letterbrush.com reply jskherman 7 hours agoparentprevHave you also checked out some of the lists on https://fmhy.net? Some there might be of interest. reply trusz 14 hours agoprevI always end back with monodraw. Other apps have too many features and style possibilities that you forget about the content. With monodraw I never get distracted. However, it still has enough functionality that you can achieve a lot of things. One of my favorites are the anchors. I have even created a small demo/tutorial: https://tamasruss.com/articles/monodraw-anchors reply seer 16 hours agoprevOMG this is one of my favorite tools paid for it all the way back when it went out. Have used it so many times just to write documentation for things like: https://github.com/ivank/potygen/blob/main/packages/potygen/... ASCII is just so versatile and allows you to put nice graphics in places where one does not expect, making things more easily understandable. reply eichin 14 hours agoparentHmm, the \"With Expression\" diagram on line 656 looks fine in emacs, but in chrome at that actual link, everything on the right is mangled. (The characters look fine, it looks like github's font choices do poorly with the \"load bearing whitespace\" for the extended bits...) reply Thorrez 11 hours agorootparentI think it's the ◀ character. It looks like Chrome (I'm on Windows) makes it wider than other Characters. I think ▶ has this same problem. But from a quick scan, I don't see any other place in the file where one of those characters is used in a way that it being extra wide would be noticable. reply simonjgreen 0 minutes agorootparentJust observing, I think this is the first time I’ve seen Unicode symbols outside of basic Latin rendering on HN. tracker1 6 hours agorootparentprevFor web it'll really vary by font family availability and fallback. Personally I like the nerd don't variant for Inconsolata, Cascadia Coffee and Firs Code for fixed width usage. I wish self packaging similar to how Google Fonts does it was easier to do. IE breaking up the don't into glyph segments to reduce unused characters for languages not used. reply mixmastamyk 16 hours agoparentprevThose corners look like Unicode block chars. reply tzot 11 hours agorootparentI believe here ASCII was used not as in ASCII-the-standard but as “ASCII” in ASCII-art. I also believe that ASCII art should actually be called “monospaced Unicode text” since people doing ASCII art have been using as many codepoints as were available in their platform of choice. reply eichin 14 hours agorootparentprevYeah, \"BOX DRAWINGS LIGHT UP AND LEFT\" and \"BOX DRAWINGS LIGHT DOWN AND LEFT\". (If this were ASCII, it would have used(\"VERTICAL LINE\") instead of \"BOX DRAWINGS LIGHT VERTICAL\".) reply diggan 15 hours agorootparentprevASCII means more than just characters from the ASCII character standard today, for better or worse. The \"modern\" translation would be something like \"text\". I don't agree or disagree with it, so don't argue with me, just trying to explain how people use it today. reply mixmastamyk 15 hours agorootparentAnyone can write that a word no longer has its defined meaning. That can’t even be refuted, as it’s certain someone is confused somewhere. However, ASCII is not a random ancient word, it’s a ratified standard. Would be like calling any datetime format “ISO8601”. reply samatman 4 hours agorootparentContext is important, ya know? If we're talking about text encodings, that's one thing, but we're talking about drawing. \"ASCII text\" drawing was never entirely limited to ASCII even in the days of single-byte encodings. There were code pages which used the high bit for more useful drawing glyphs, people took advantage of that when they could. The concept of an extended ASCII encoding goes way back: https://en.wikipedia.org/wiki/Extended_ASCII, and UTF-8 is just another extended ASCII encoding, albeit a very clever one, with a lot of codepoints. reply jvanderbot 16 hours agoparentprevYou should select the lines you'd like to show off and link that. reply diggan 15 hours agorootparentYou should do a quick scan of the file, it's filled with graphs in the comments, not just one. reply jvanderbot 14 hours agorootparentI did. Sorry, linking seemed like a good idea so it was just a suggestion. Maybe OP didn't know that was possible. reply echelon 14 hours agoparentprevThis is a fantastic illustration that sells the software for me. Thanks for sharing! I'll have to look into this. reply sebastianconcpt 17 hours agoprevI love this tool! I've used it to do diagrams for Mapless: https://sebastianconcept.github.io/Mapless/guides/2024/01/28... And to document this Pharo VM Plugin builder setup: https://github.com/sebastianconcept/PharoPluginBuilder reply James_K 17 hours agoparentSo you used an ASCII drawing tool to draw these diagrams in text then took a screenshot of them and uploaded to your website? That seems like such a convoluted way to draw a few rectangles. Isn't there an easier way? reply mjochim 16 hours agorootparentDoesn't seem more convoluted than any other drawing tool to me. The UI of Monodraw appears to be pretty similar to \"regular\" drawing software. reply subjectsigma 16 hours agorootparentprev1. You can just “Save as” to PNG, it takes no time or effort. 2. I use to use Monodraw exclusively for making diagrams in source code, but over time I’ve become so comfortable with the tool, keyboard shortcuts, etc. that now I just use it for all diagrams. It’s a very nice tool. reply James_K 15 hours agorootparentIf you feel the need to embed giant ASCII diagrams into a source file, I think you should just use a picture. Like a .png or .svg or something and write the documentation in another file. Or even maybe try out rich text source code. reply subjectsigma 14 hours agorootparentThe diagrams I am pasting in are usually like 80 x 40 chars and keep you from having to tab out into documentation. They don’t change often so they don’t create messy diffs. I don’t think that’s unreasonable. Nobody on my team seems to mind. I don’t think this is a problem and I’m having trouble understanding why you think it is. If you’re wondering why I need diagrams in source code, then the answer is I usually don’t need them but it helps. The only project where they were game changing was where we were using Neo4j as a backend and being able to clearly diagram the data model was really helpful. reply James_K 10 hours agorootparentI don't really have much of an issue with it. It's got bad vibes by association. I find it a little annoying how much stuff is done with text, and this is just a small part of that. reply aidenn0 15 hours agorootparentprevPlease don't do things like this that make it harder for people to read your comments. reply James_K 14 hours agorootparentWriting documentation is typically an addition to writing comments. They serve different purposes. That said, adding a diagram to a comment will only make it easier to read. It is an addition. It cannot make things harder. reply zelphirkalt 13 hours agorootparentIf only it were true, that additions cannot nake things harder to read. reply James_K 13 hours agorootparentIn this case, it is absolutely true. It is the difference between: // some comment and // some comment // additionally see ./diagram.png Diagrams are often useful tools for communicating information. reply aidenn0 11 hours agorootparentThat's not the difference I'm talking about; I'm talking about the difference between // some comment // ... 25 lines of a diagram and // some comment // additionally see ./diagram.png reply misnome 15 hours agorootparentprevThanks! I’m sure they never thought of that! Or maybe they did, and there are advantages and tradeoffs to any approach. I’m sure your unique insight must be right, though. reply James_K 14 hours agorootparentYou don't need to get so annoyed on someone else's behalf. I am just putting my opinion out there – specifically that I would prefer just an image file that is referenced from a comment. I'm sure this person knows what an image is; I was not trying to imply that they didn't. reply Terretta 14 hours agorootparentprevAt least for the README, the diagram remains text in three backticks. reply k12sosse 17 hours agorootparentprevThink different. reply lsllc 16 hours agoparentprevLove this too -- I use this to document source code, being able to visualize a buffer or structure layout in the code is so nice! reply tracker1 6 hours agoprevReally wish this was cross platform. Would love to use this in Linux. I appreciate the effort that it takes to deliver a polished application. I just wish more tooling did better to target Linux, Windows and Mac for desktop apps. Probably a larger driver behind web based apps. reply huydotnet 17 hours agoprevAwesome tool! Also, for the web version, my friend made an alternative written in Kotlin https://github.com/tuanchauict/MonoSketch I also have a half baked version in Rust too https://github.com/huytd/ascii-d reply paulirish 16 hours agoprevLooks nice. https://asciiflow.com/ is a web-based alternative that's been my go-to for a decade. reply russellendicott 16 hours agoparentI use ASCIIFlow all the time. I still haven't figured out how to get browsers to render the monospace fonts correctly see example diagram on this page: http://uggly.bytester.net/#how-it-works reply tracker1 6 hours agorootparentFirst is using a monospace font, second is aligning line height to font height. Third includes a bit of tweaking and trying different sizes. Your best bet is to use a good fixed width don't with broad character support. Some are better or worse than others. Cascadia Code and Fira Code work pretty well with differing characteristics and both have nerd don't variants. Emoji alignment is another problem. reply Retr0id 15 hours agorootparentprevLooks fine on my machine - my guess is that your primary font does not contain all the glyphs used (e.g. the box-drawing chars), so its falling back to another font just for those glyphs, causing inconsistencies. reply russellendicott 14 hours agorootparentIt seems to only mess it up on mobile. Desktop Chrome seems fine. Mobile Chrome is all I've tested on. reply Retr0id 14 hours agorootparentAh, in that case you might want: text-size-adjust: none; -webkit-text-size-adjust: none; (it's infuriating that these options need to exist!) reply golem14 14 hours agorootparentHow do you set options for chrome on iPhone and android? Sorry for the naive question, I never figured this out. reply jasonm23 6 hours agorootparentYou could use a browser that supports extensions on Andriod, iOS will protect you from such nefarious things though. reply Retr0id 5 hours agorootparentiOS supports browser extensions, and has done for some time - e.g. https://apps.apple.com/us/app/makeover-custom-css/id16023611... (which demonstrates custom HN CSS in the demo screenshots!) reply Retr0id 13 hours agorootparentprevThese are in-page CSS controls, not browser config options (no idea how those works, I avoid mobile platforms) reply Veuxdo 14 hours agoparentprevDoesn't look like screen readers can read the text on these. reply Retr0id 14 hours agorootparentI believe you can treat it as if it were an image by putting it an element with attributes role=\"img\" aria-label=\"description of the diagram goes here\" https://developer.mozilla.org/en-US/docs/Web/Accessibility/A... reply Veuxdo 14 hours agorootparentThe problem is, having to describe a diagram using text defeats the purpose of the diagram. Must better is to use diagrams that render as SVG, so screen readers can read them. [0] [0] https://accessibility.princeton.edu/how/design/images-text reply Retr0id 13 hours agorootparentA flowchart involving labeled boxes with arrows between them is going to be more accessible as an SVG than a PNG, sure, but you're still going to need to explain what the arrows are doing, otherwise a screenreader user will be quite lost. reply Brajeshwar 18 hours agoprevI love this tool. This is one of those that you buy it and keep it, even if you use it once a while. reply dfee 17 hours agoparentHave you had this for a long time, or are you speculating that it’s the type of software you like? This looks very cool to me, though. If you have used it, can you share how you’ve used the generated diagrams? I can imagine a screenshot of the diagram, but the raw text would probably be too big in (e.g. a terminal). reply dorian-graph 12 hours agorootparent> Have you had this for a long time .. Similar to the OP, I've had it for years, and used it every and now then through those years. > .. can you share how you’ve used the generated diagrams? The website mentions exporting in text and images. I use the text importing (to clipboard), with \"Trim trailing whitespace\". > .. but the raw text would probably be too big in (e.g. a terminal). It's as big or small as you want it to be? With the obvious constraints of the different banner styles. People have had ASCII banners in consoles for decades, there's nothing new about the ASCII banners from Monodraw. reply jasonm23 6 hours agorootparentprevTry installing figlet, for banner text. At its simplest: figlet \"Text\" or use fonts figlet -f small \"Small Text\" ___ _ _ _____ _ / __|_ __ __ _|| |_ _|____ _| |_ \\__ \\ ' \\/ _`|| |/ -_) \\ / _| |___/_|_|_\\__,_|_|_| |_|\\___/_\\_\\\\__| reply ryanschneider 17 hours agorootparentprevAs other have mentioned I’ve used it for diagrams in code comments and READMEs (before GH added mermaid integration). Making readable diagrams with 80 character width can be a challenge. I bought it back in either late 2017 or early 2018 and used it a fair amount at first but will admit it’s been a couple years since and haven’t tried reinstalling since my last clean OS wipe. reply Brajeshwar 17 hours agorootparentprev1Passwords shows that I bought a license on April 6, 2017. reply loganlinn 16 hours agorootparentprevI bought license to Monodraw in 2018 and have used it off and on since, so I can attest to GP reply saikatsg 17 hours agoparentprevThe website design is also neat. reply joshlemer 17 hours agoprevThis went into \"maintenance mode\" in 2018, has anything changed? https://blog.helftone.com/monodraw-maintenance-mode/ reply milen 17 hours agoparentDeveloper of Monodraw here. Thank you all for the kind words regarding the app. Unfortunately, my time is extremely limited which is why I haven’t had the chance to push more updates out. I’ve got a few highly requested features in the works but I cannot promise when they’ll see the light of day (I usually get to make progress during my holidays). I’m still committed to fixing any breakages due to OS upgrades and ensuring the product continues to work. reply accessvector 17 hours agorootparentThanks for your work in making an excellent tool; I, and many of my coworkers, use this. The price point is entirely fair and it’s a pleasure to use every time. But - above this - thank you also for prioritising personal life above development. It’s great as it is and we’ll be happy to see new features when you’re ready. I would be really proud if I were in your position. Cheers! reply milen 16 hours agorootparentThank you for the kind words! reply nikolay 12 hours agorootparentprevThank you, Milen! It's nice to see Bulgarians being behind a popular desktop app! I've been a paid user for years and Monodraw is among the first apps I install when I get a new MacBook machine! reply dorian-graph 12 hours agorootparentprevThank you so much for Monodraw! I've used it on and off for _years_. reply hanniabu 17 hours agorootparentprevCurious what some of the requested features are since it seems feature complete to me reply milen 16 hours agorootparentThe main requests have been for: - Plaintext format (in progress) - Dark mode support for the main canvas (in progress) - Auto/Dynamic Layout - Table support - ANSI export reply supertron 15 hours agorootparent> Dark mode support Hell yeah! I'm a long time user of Monodraw (thanks for the awesome work!) and this would be an instant upgrade for me :) reply marcellus23 13 hours agorootparentprevWhat does \"plaintext format\" mean? Isn't it already plaintext? reply jasonm23 6 hours agorootparentto offer a guess, I assume plantext probably means plain ASCII or maybe extended US ASCII (adds IBM box drawing chars, etc.) As opposed to full unicode text charset. reply marcusjt 17 hours agoparentprevhttps://x.com/Monodraw suggests there have indeed been updates reply graypegg 17 hours agorootparentTo be fair, the last tweet is from 2 years ago. However, I’ve made pretty good use of it, and it’s really a “complete” product. Not much more to update than the occasional mandatory platform upgrade. reply airstrike 17 hours agoparentprevFrom the FAQ at the bottom > Why not open source the app? > > Maintaining an open-source project can be a significant amount of work and I'm not going to have the time to take on such responsibilities. Furthermore, open-sourcing full products tends to result in many clones being sold directly to unsuspecting customers which is not something I want to enable. It's strange how both of those statements are incorrect... open-sourcing a project allows for contributors to pick up some of the workload and certain licenses would prevent clones from being sold to unsuspecting customers reply dorian-graph 12 hours agorootparentContributors don't magically appear. Maintaining a community, reviewing changes, steering, etc. all take time and energy. Again, contributors don't magically appear who can do those things, who are aligned with the creator. Licenses don't magically stop bad actors. Both statements by the author are correct. reply thenanyu 14 hours agorootparentprevAs someone who has worked on an open source product with a commercial version, the FAQ matches my experience. I think you're letting you're mixing up is and ought. reply arccy 17 hours agorootparentpreva license doesn't magically stop bad things from happening. reply airstrike 16 hours agorootparentit doesn't, but it's a deterrent. the very fact that this app had limited commercial success is reason to believe there likely won't be \"many clones\", especially if they're forced to go against the license reply hit8run 10 minutes agoprevI remember that I bought it through the App Store just to find out that they offered a CLI that is only non App Store. Wrote them a mail and asked if they could change me to non App Store. Never got a reply lol reply joehogans 1 hour agoprevI love monodraw, I buyed it and use it for other developers to show complex functions. You can also ask GPT to render Unicode diagrams and past it in monodraw if you like. reply aramndrt 1 hour agoprevThis reminds me of the old text file format walkthroughs for video games. I fondly remember using the The Legend of Zelda: Wind Waker walkthrough hosted on IGN. Good times. :') reply grimgrin 17 hours agoprevwhat's the native linux alternative? aka not a webapp edit: hm, maybe https://github.com/nkh/P5-App-Asciio reply fbdab103 16 hours agoparentFor anyone who is willing to use a webapp, I like drawio[0]. You can download locally[1] and self host (I just use the python webserver). While finding the Github, I see they now actually package an Electron application, so that is probably worth exploring[2]. [0] https://www.drawio.com/ [1] https://github.com/jgraph/drawio [2] https://github.com/jgraph/drawio-desktop reply rihards__ 8 hours agorootparentDrawIO feature to save editable PNGs (embedded diagram source code) is absolutely magical. The tool is quite basic, until you realize, you can create reusable blocks (in scratchpad) with predifened style. From that point on you just publish editable PNGs to git and draw them rather quickly by dropping in predefined blocks. reply flylikeabanana 17 hours agoparentprevOne way would be to use emacs’ artist-mode to draw ascii lines and boxes then use ditaa[1] to transform them into images. It’s not a pretty packaged GUI app but it’s certainly an option [1] https://ditaa.sourceforge.net/ reply amlib 17 hours agoparentprevFairly new and barebones for now, but it is available as a flatpak: https://github.com/Nokse22/ascii-draw reply strobe 16 hours agoparentprevemacs artist mode also suitable for something like that https://www.youtube.com/watch?v=1JZ6ljIRGus reply yla92 7 hours agoparentprevhttps://asciiflow.com/#/ works pretty well. reply internetter 12 hours agoparentprevAlso not native, but huydotnet mentioned this in another comment and it looks great https://github.com/tuanchauict/MonoSketch reply MithrilTuxedo 16 hours agoparentprevI've been using PlantUML, having come from using GraphViz. I can't tell is has any relation to this. I use it to generate SVGs in Maven documentation site builds. reply z5h 17 hours agoprevOwned this for years, and regularly use it to brainstorm, and sometimes I’ll add ascii diagrams to code comments. reply bayindirh 15 hours agoprevI use Monodraw since the first day it came out. I use it to draw software architecture, diagrams, and most importantly login banners to the systems I manage personally. It's a nice, to the point tool. reply thom 16 hours agoprevI've used this in the past and enjoyed it. My one complaint, if I recall, is that you have to use its own built in file format to maintain all the cool features like anchors and resizable boxes and stuff. You can't just point at at an ASCII drawing in a markdown document and get all the functionality for free. I suspect if someone really wanted to they could crack that through clever algorithms and LLMs - and I've extensively used the latter to work on first drafts of ASCII diagrams to some success. But I've never found a good balance of maintainability (i.e. a box is a box and I can move it and have its connections follow it around) and portability (everything really is just pure text). If I'm wrong about recent versions of Monodraw or something else achieves this I'm all ears! I certainly had more success with Monodraw than artist mode in Emacs, at least. reply xp84 16 hours agoparentInteresting take. Do you have a lot of existing diagrams you'd like to manage? If I'm starting from scratch, I would sort of expect/want to have the abstract file format like this, seeing it as like a PSD, and the output as a rendered, flat image like PNG. Or source code vs. binary. Parsing an output artifact back into a more semantic and abstract form is hard to get perfect, I would imagine. reply thom 9 hours agorootparentThere are times when I've wanted architecture diagrams to be ASCII in markdown, meant to be consumed through GitHub or in a Backstage portal or something. For me, the ideal workflow would be to just be able to edit those inline but still have cool editor features. Maintaining a separate file is just hassle, and it's hard enough trying to keep diagrams alive as part of documentation as it is. reply supertron 16 hours agoprevMonodraw is great. I occasionally use it to document system architecture in code comments and project READMEs etc. [0] Also handy as a quick way to document CSS styles to help visualise which parts of a layout a given style targets [1] [0] https://gist.github.com/supertr0n/f006a5f61b60160862ec13024e... [1] https://gist.github.com/supertr0n/462325ec3f7fbea02780039150... reply nico 12 hours agoprevLooks amazing It would be cool if they had an img2asciidiagram that would convert something drawn on paper to an ascii, and that could run from my phone (similar how GeniusScan works) Then I could just draw on paper, and scan the diagrams from the phone :) reply guestbest 13 hours agoprevWhen I worked in telecom, this is how people used spreadsheets reply richardw 13 hours agoprevLove it. Triggers memories! I wrote my own similar-ish version of this for a school project in 1991. Although mine wasn’t mono, so I could draw in foreground colour, preserving the existing text, background colour or text. Eg draw a filled in square made up only of background colour changes. Obviously this is very different but I love the sense of surprisingly good output despite a lot of restrictions. reply felideon 11 hours agoprev> A picture is worth a thousand words. A diagram is probably worth twice as much. Or (sometimes) worth ten thousand words: https://onlinelibrary.wiley.com/doi/10.1111/j.1551-6708.1987... reply zekenie 16 hours agoprev*Love* monodraw. The last 2 times i was on the job market I used monodraw extensively for little inline diagrams for my take-home projects. It always was a big hit with the reviewers. reply ThinkBeat 17 hours agoprevFunny. The front page (still) states: \"We're a small studio that loves to make delightful apps. We just launched Monodraw.\" The blog says: Maintenance Mode With immediate effect, Monodraw is entering maintenance mode. This means that there will be no more updates in the future. While I'll be aiming to provide OS compatibility updates, if required, those are not guaranteed. Accordingly, the price has been reduced from $19.99 to $9.99. Why? Monodraw was released in May 2015, about three and a half years ago. Unfortunately, it did not achieve commercial success and it meant I had to get a job. In the years that followed, I could only work on Monodraw in my spare time. Due to recent changes in my life, I can no longer devote any meaningful time to the app. \"\" https://blog.helftone.com/monodraw-maintenance-mode/ reply milen 17 hours agoparentDeveloper of Monodraw here. I haven’t updated the official website (priorities and lack of free time). I’ve pushed out some updates after the maintenance mode announcement but the frequency is not guaranteed since my free time is extremely limited. I’m still committed to fixing any breakages due to OS upgrades and ensuring the product continues to work. While I have some new features in the pipeline, I cannot commit to any timelines as I don’t know when I will ship them. I want to thank everyone who’s supported the product throughout the years, it means a lot to me. Happy to answer any further questions. reply commandersaki 9 hours agorootparentIt may not have reached commercial success, but to me it's the best commercial application on MacOS. Nothing comes close in value. reply andai 17 hours agoparentprevAnd thanks to being proprietary, no one else can devote time to it, either. reply milen 17 hours agorootparentI’ve toyed with the idea of open sourcing the product. I reached the conclusion that it’s not the approach for two main reasons: - I believe in a strong, centralised product vision and execution - The code will be packaged up and sold by unscrupulous people who will not contribute back I’m a strong advocate of interoperability and open data formats. The Monodraw data format is not proprietary and I do have plans for a plain text format (currently, it’s just zipped JSON which doesn’t play nice with VCS). Interoperability is key to competition and avoiding lock-in, so I’ll push in that direction as my time permits. reply lumb63 15 hours agorootparentI understand your concerns about open-sourcing the codebase and won’t try to convince you otherwise. It’s your code. That said, I would like to share my perspective on the subject, having given some thought to if/how I should open source my code. I don’t feel that I have any ground to stand on if I were to choose not to open source my code. That same code would be uploaded to the internet using a web browser or other tool that is open source. That code is probably compiled or interpreted by a tool that’s open source. For me, it all runs on an operating system that’s open source. Nearly everything that I am able to do as a software developer is built on the shoulders of giants who, out of kindness and conviction in their beliefs, chose to make an entire ecosystem of software available to the world, with source code available, free of charge. I feel that I owe it to the world to pay that legacy forward. reply andai 12 hours agorootparentprev> I believe in a strong, centralised product vision and execution Fair point! I'm reminded of this quote from Jaron Lanier: > Why are so many of the more sophisticated examples of code in the online world—like the page-rank algorithms in the top search engines or like Adobe’s Flash—the results of proprietary development? Why did the adored iPhone come out of what many regard as the most closed, tyrannically managed software-development shop on Earth? >An honest empiricist must conclude that while the open approach has been able to create lovely, polished copies, it hasn’t been so good at creating notable originals. Even though the open-source movement has a stinging countercultural rhetoric, it has in practice been a conservative force. I love free software, yet most of the software I use is proprietary. (I consider my own apathy as contributing to the problem...) As for this point, - The code will be packaged up and sold by unscrupulous people who will not contribute back an interesting example is Jason Rohrer, who has open sourced all (?) his games. The way he got around this is that he made a multiplayer game, where the $20 in effect gave you access to the main server. People indeed repackaged his game, sold it on other platforms etc. Yet last I checked, he was doing better than ever. (Probably cause he keeps pushing out updates to keep the game interesting.) Not sure how well this works for \"single-player software\", although Aseprite seems to be doing all right. (Though technically not free software anymore, despite being open-source...) reply techn00 16 hours agorootparentprev> The code will be packaged up and sold by unscrupulous people who will not contribute back Choose a good license then reply milen 16 hours agorootparentA license wouldn't stop the unscrupulous people, they'll keep making clones of it and ignoring the license. This means I have to start chasing any clones, engage legally and try to take them down. It's just not worth the time - I would rather spend the time on improving Monodraw instead. reply synthmeat 15 hours agorootparentTo voice support for current state - do what you're already doing, and I agree on focusing on opening up the format. Don't hesitate to charge for v2, if improvements pile up and you have affordances to do so. Will gladly pay. It's pretty great already as-is. Thank you. reply josephcsible 13 hours agorootparentprevIf unscrupulous people are willing to ignore the license anyway, wouldn't they just hex edit to change the branding to sell clones even while it's closed source? reply jorts 17 hours agorootparentprevIt’s perfectly fine that it’s proprietary. Just because it exists doesn’t mean other people are entitled to the source code. reply andai 12 hours agorootparentI agree. Nobody owes anyone anything! I was merely pointing out that it's a shame that (1) it has apparently been abandoned for years, (2) people are not able to do anything about that. (Bus factor == 1, etc.) Based on the other comments in the thread, I'm sure there are people who would love to contribute. (Worth pointing out that making something open source isn't zero-maintenance by any means, especially since GitHub still doesn't let you disable pull requests...) reply lsllc 16 hours agoparentprevPlease not more app-store abandonware. I have a decent amount on both my phone and my MBP. Sad to see, I really liked Monodraw for creating ASCII illustrations for source code (e.g. buffer layouts etc). Of course, probably it'll be ok for a while, but then some App Store API or updated processor requirements will render it unusable like so many others (particularly on iOS). So now I've got several abandonware apps that I paid for: Things (v1), Quiver, Artboard and now Monodraw. I can't say any of them really had any non-minor updates since I got them certainly not features (yes, I realize Things did a separate V2 app ... but I wasn't happy about that happening so soon after buying V1). I do realize some of this is Apple's fault in the way the store is structured. Too bad Apple doesn't enact some sort of source-code escrow such that if an app is abandoned, the source gets published, but with owner-copyright retained so no-one can resell -- as part of the T&C of submitting an app. Maybe after 1 year of abandonment for a \"big\" company and 2 years for indie-dev apps. *EDIT*: Happy to see Milen's sibling comment about fixing breakage!! I realize you have to make a living -- is there a way to contribute for these new features (or is it a totally new app -- which is fine!). reply milen 16 hours agorootparent> EDIT: Happy to see Milen's sibling comment about fixing breakage!! I realize you have to make a living -- is there a way to contribute for these new features (or is it a totally new app -- which is fine!). I've considered the idea of letting other developers have access to the source code and help with the development. Unfortunately, I couldn't figure a way to make it fair - e.g., if someone starts contributing, do they start receiving a percentage of the proceeds? What's a fair percentage and what about multiple external contributors? I could never come up with a workable model, so it's either fully open-source or proprietary. As I mentioned in another comment, I believe the way to go is an open data format which allows interoperability. This way there's no lock-in and competing apps (open or closed) can exist. For what it's worth, the Monodraw data format is not secret, it's just compressed JSON. I haven't documented it because it's more of an implementation detail and I'd rather spend my very limited time on improving the product. Hope that provides a bit more context. reply lsllc 15 hours agorootparentThank you for the comment, apologies if I came off a bit antagonistic! It's just a little frustrating when you see really great apps potentially ending. It's really too bad there's not a better indie-dev model for the App Store, if I am buying an app (I think maybe I maybe paid $19 for Monodraw -- totally worth it btw), am I buying the app as-is? or do I get updates ... if so how long should I expect to get them and are the updates minor fixes or bigger whizbang features. I can see that once an app gets to a steady state, there's probably diminishing returns in putting a lot of effort into new features esp. if your market is small. On the other hand, if the app has some sort of subscription, now there is an expectation for updates (not unreasonable, but possibly the numbers might not work for the developer). I think Pixelmoter sort of got this right, although they did release a Pro version separately (which I also bought). However, I suspect they're a much larger company and probably have quite a large market share and can afford to continue to release updates to keep it fresh (and for someone like me, the app is exactly what I need vs. say photoshop and the price point is reasonable). reply andai 12 hours agorootparentprevAt this point, the only apps worth using were released 10 years ago, and have all been removed from Play Store. I have to either use my own backups or download sketchy APKs. I'm not exaggerating, today I tried a number of shoddy disk space analyzers full of bloat and ads, until giving up and just using one from 2014... (except it'd been deleted, so I had to do a bit of digging.) reply thenanyu 14 hours agoprevI got 20% done prototyping an implementation of this for myself. Gonna just pay the $10. Thank you! reply easeout 13 hours agoprevI used this often for diagrams before repository sites' Markdown renderers started to support Mermaid. Nice tool; easy and fast. Can be a bit fiddly to make changes, depending on how much you care about neatness. reply jvanderbot 16 hours agoprevWhy isn't there a good CLI tool for specifying and rendering these? I'm imagining something like dot -Tascii reply crooked-v 11 hours agoprevMonodraw has been invaluable to me for creating UX workflow mockups that sidestep all the bikeshedding by way of having no fine details that people can nitpick. reply mergy 16 hours agoprevInteresting. I have been spending a lot of time with Mermaidjs for the last year or so and love it but not around ERDs because of the inability to map field relationships the way I want. I will check this out. reply ukd1 15 hours agoprevI've been using this since 2015 - and just found out today they have a cli tool! But, I bought through the App Store so it's not available for me. For any users, is the cli tool useful? reply mechanicker 16 hours agoprevAwesome tool I purchased when I stumbled upon it. I draw flowcharts for complex implementations in ASCII using Monodraw and embed them in source code. reply tooltechgeek 9 hours agoprevI get it, but what about mermaid for diagrams? and free reply constantinum 15 hours agoprevOne of the first few tools I install on a new machine. Absolutely no subscription nonsense. reply adamzerner 14 hours agoprevHm. I'm interested in hearing more about the specific scenarios where this sort of tool is useful. I skimmed through the HN comments and see that it can be used for adding diagrams to code comments. But what else? Slack, Jira, READMEs, SMS, Signal etc all allow you to include pngs. reply eichin 13 hours agoparentWhat do you mean by READMEs here? Markdown readmes support embedding images from external files, which isn't really useful if you're looking at the readme directly (or do you use data: uris there? Last I looked they had too-severe length limits.) (I'm also curious what you mean by SMS, or are you conflating it with RCS?) reply abdullahkhalids 12 hours agoparentprevMessaging apps don't have fixed width apps, I think. You would need to pick one app's specific font (idk if Monodraw lets you do that), and draw using that. reply ksherlock 13 hours agoparentprevYou can use it for mocking up a text user interface. reply notnmeyer 16 hours agoprevmonodraw has been one of my favorite diagramming tools, but never seemed to be popular with the folks i worked with. reply russellendicott 16 hours agoparentYeah, I'm known as the ASCII diagram guy at work because I use ASCIIFlow a lot. Still not sure if people think I'm a joke. https://asciiflow.com/#/ reply OneOfTheMicahs 16 hours agoprevHow accessible are these diagrams to screen readers? reply zokier 17 hours agoprevStretching the idea of \"plain text\" quite far imho. reply sigma5 15 hours agoprevhow does it compare to excalidraw ? reply Solvency 17 hours agoprevThese used to be called Macro Shops back in the 90s AOL prog/punter scene. There used to be thousands of truly incredible ASCII macro artworks. This is barely scratching the surface. https://i0.wp.com/justinakapaste.com/wp-content/uploads/2014... reply methuselah_in 14 hours agoprevNo Linux or windows? reply petepete 14 hours agoparentNo, but Asciiflow is very good. https://asciiflow.com/ reply coffeemug 13 hours agoprevAmazing tool, thank you for building this. One piece of feedback: let me pay you without having to fill out a 20 field form. I would have happily bought a license through PayPal, but having to enter all the info really makes me want to press the back button. reply anigbrowl 10 hours agoprevASCII art, so great we built a GUI for it reply Julesman 16 hours agoprevnext [3 more] [flagged] thenanyu 14 hours agoparentthe reason I want this is because I can inject a diagram anywhere, specifically code files reply durandal1 16 hours agoparentprevBecause beautiful diagrams that can be edited and viewed anywhere and any developer tool and platform on the planet. reply jhoechtl 13 hours agoprevnext [2 more] [flagged] patja 13 hours agoparentespecially confusing since for many people using Mono in the name of software triggers associations with cross-platform capabilities reply fortyseven 12 hours agoprev [–] I'll never understand willingly restricting yourself to one desktop platform. Especially with a paid app. Oh well. Looks nice reply m1keil 7 hours agoparentI share similar caution with tools and multi-platforms (specifically Mac, Win & Linux). However, the format is interchangeable with other Ascii drawing apps and it isn't too expensive. So I'm totally fine with it. reply LoganDark 8 hours agoparentprev [–] Sketch, Rogue Amoeba apps, Panic, etc. plenty of Mac-only businesses. They make decent money. As Mac users actually tend to pay for their software rather than expecting everything to be free. If you released the same software for the same price on Windows, not only would it be more difficult to develop (due to Windows lacking the same abstractions as macOS), you'd probably have way less users, as Windows users don't typically buy apps like this. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Monodraw is an ASCII art editor for Mac, facilitating the creation of various designs with plain text, such as diagrams and banners, offering both a free trial and a purchase option for $9.99.",
      "The software provides drawing tools, features like grouping and alignment guides, and a command-line interface, compatible with macOS 11 Big Sur onwards, and ensures user privacy by abstaining from data collection.",
      "Users can benefit from an educational discount, and feedback is welcome via email or Twitter, enhancing user engagement and support options."
    ],
    "commentSummary": [
      "Hacker News users are discussing web-based text to diagram tools, highlighting Monodraw's popularity for its simplicity and functionality in creating ASCII art to improve documentation and explain complex concepts.",
      "Conversations cover topics like font rendering, Unicode symbols, and the limitations of ASCII characters in drawings, with some users favoring ASCII for documentation, while others debate the effectiveness of using image files for diagrams.",
      "Monodraw developer plans to shift to maintenance mode with limited updates, contemplating open-sourcing the code, sparking debates on tool alternatives like Mermaid and Sigma5, as well as concerns about app abandonment and existing app quality."
    ],
    "points": 719,
    "commentCount": 150,
    "retryCount": 0,
    "time": 1709994782
  },
  {
    "id": 39651710,
    "title": "Revolutionary 4D Knit Dress: A Fusion of Technology and Fashion",
    "originLink": "https://selfassemblylab.mit.edu/4d-knit-dress",
    "originBody": "4D Knit Dress Previous Next 4D Knit Dress: Transforming Style MIT Self-Assembly Lab x Ministry of Supply MIT Self-Assembly Lab Team: Sasha Mckinlay, Danny Griffin, Sofia Chen, Lavender Tessmer, Natalie Pearl, Susan Williams, Agnes Parker, Jared Laucks, Skylar Tibbits Ministry of Supply Team: Jarlath Mellett, Alessandra Vasi, Ryan Connary, Gihan Amarasiriwardena Typical garment construction requires a designer to build a 2D pattern, then cut and sew from 2D fabric – yielding excess waste, additional cost/labor and bulky seams that don’t always follow human anatomy. New innovation in 3D knitting – akin to 3D printing - has allowed fabric variation and standardized 3D shaping - however customized shaping of knitted garments to fit anyone’s unique body or style hasn’t been possible. 4D Knit Dress, combines several technologies – heat-activated yarns, computerized knitting and 6-axis robotic activation to create a garment that is sculpted to create a personalized fit or style. Heat-activated yarns are embedded within a unique knit structure to create controlled transformation, while maintaining softness, stretch and resilience. Using an efficient tubular knitting technique, a 6-axis robotic arm (commonly used in automotive manufacturing) heats specific areas to take-in – mimicking the design process of pinning & tucking used in traditional dress tailoring – transforming the dress in real-time to create a perfect fit or a unique look. All Growing Islands 4D Knit Dress 3D Knit BioSuit™ Haptiknit Liquid Metal Printing Personalized Knit Masks Climate-Active Textiles Active Textile Tailoring Active Patterned Scarves Liquid to Air: Pneumatic Objects Liquid Printed Pneumatics Liquid Printed Products Rapid Liquid Printing Liquid Printed Natives Active Shoes Liquid Printed Textile Shoes Active Textile Jamming Bodies Slip-Form Rock Jamming Modular and Morphable Jamming Rock Printing Programmable Materials Transformable Meeting Spaces Transformable Screen Wall Active Auxetics Programmable Table 4D Printing Fluid Crystallization Self-Replicating Spheres Fluid Lattices Aerial Assembly Fluid-Assembly Chair Self-Assembly Cell Phone Hyperform Self-folding Proteins Autonomous Mass Assembly BioMolecular Self-Assembly Self-Assembly Line DNA Printing C-Strands Macrobot & Decibot Logic Matter Growing Islands 4D Knit Dress 3D Knit BioSuit™ Haptiknit Liquid Metal Printing Personalized Knit Masks Climate-Active Textiles Active Textile Tailoring Active Patterned Scarves Liquid to Air: Pneumatic Objects Liquid Printed Pneumatics Liquid Printed Products Rapid Liquid Printing Liquid Printed Natives Active Shoes Liquid Printed Textile Shoes Active Textile Jamming Bodies Slip-Form Rock Jamming Modular and Morphable Jamming Rock Printing Programmable Materials Transformable Meeting Spaces Transformable Screen Wall Active Auxetics Programmable Table 4D Printing Fluid Crystallization Self-Replicating Spheres Fluid Lattices Aerial Assembly Fluid-Assembly Chair Self-Assembly Cell Phone Hyperform Self-folding Proteins Autonomous Mass Assembly BioMolecular Self-Assembly Self-Assembly Line DNA Printing C-Strands Macrobot & Decibot Logic Matter",
    "commentLink": "https://news.ycombinator.com/item?id=39651710",
    "commentBody": "4D Knit Dress (selfassemblylab.mit.edu)207 points by geox 19 hours agohidepastfavorite69 comments Animats 13 hours ago\"heat-activated yarns\" That's how much tight-fitting clothing is made. Raw spandex has about a 10x stretch. But hot air will re-set the neutral point of the stretch. So stocking, etc. are made by weaving a partially-shaped garment. That's then slipped over a metal form that's the size of the garment when un-worn. The form and garment are hit with hot air for about a minute, and that re-sets the zero point of the spandex. Here's a pantyhose production line.[1] Forms and heat transform it from a crumpled mess to a formed garment. [1] https://www.youtube.com/watch?v=wlzj9dy5PhA reply fsmv 19 hours agoprevI feel like adding heat shrink fabric doesn't add a dimension and make it go from 3D to 4D. I was expecting a klein bottle or hypercube projection or something. reply Anotheroneagain 2 hours agoparentI don't think that you get how revolutionary this is. It has the potential to wholly take over all clothing production, for the sole reason that it can be fully automated. reply jstanley 42 minutes agorootparentThat's fine but it doesn't make it a 4-dimensional object. reply kahunalu 18 hours agoparentprevBoth of those items are 3D - while the dress transforms over a 4th time dimension. reply lavela 10 minutes agorootparentDoes it really though? The heat setting process doesn't seem reversible so it's just one step in the initial manufacturing and after that it doesn't seem to be expected to change. reply master-lincoln 18 hours agorootparentprevNo, a Klein bottle is an object that can not exist in 3d. The one you probably know is an \"immersion\" into 3d (making the object intersect itself, which it wouldn't do in it's original shape in 4d) reply dullcrisp 12 hours agorootparentI don’t suppose it’ll help at all if I say that a Klein bottle is a two-dimensional surface and four is the smallest dimensional Cartesian space into which it can be embedded. reply wiml 7 hours agorootparentA question for people who know more topology(?) than I do: what determines this? Is it possible to construct a surface that requires an arbitrary number of dimensions for its embedding? reply dullcrisp 5 hours agorootparentGood question. Based on googling [0] it looks like any surface can be embedded in four dimensions (and any n-manifold can be embedded in n+2 space). But I don’t know enough to explain the construction. Might have something to do with the tangent bundle, it sounds like? [0] https://math.stackexchange.com/questions/2960093/why-do-we-n... reply MichaelZuo 18 hours agorootparentprevDon't all dresses transform over time? Eventually 100% of all possible dresses will transform into dust. reply dclowd9901 3 hours agorootparentThis applies to everything so it’s moot. reply dambi0 17 hours agorootparentprevWhat about dresses repurposed into non-dresses prior to their dusty demise. reply MichaelZuo 12 hours agorootparentEventually those will too. reply Razengan 17 hours agorootparentprevI mean everything transforms over time. reply omoikane 17 hours agorootparentReminds me of https://xkcd.com/209/ \"So the kayak travels through time?\" \"Sure! Just like everything else!\" reply icegreentea2 18 hours agoprevFinding more detailed information has been annoying. From https://www.dezeen.com/2024/02/09/4d-knit-dress-mit-ministry... it says that the heat shrinking material is nylon, while the rest of the yarn is a viscose + polyester blend. reply smeej 17 hours agoparentDoes that mean the transformation is permanent? Because if they created a dress that could be shaped, unshaped, and reshaped in different ways using, say, a hair dryer, they'd really be on to something! reply hammock 14 hours agorootparentNylon is thermoplastic so in theory it could be reshaped but the filament would lose a lot of strength and durability in the process reply tbrownaw 17 hours agorootparentprevNeed to include a few strands of something like https://www.asme.org/topics-resources/content/metal-that-rem... . reply jijijijij 16 hours agorootparentThere are also memory alloys which can remember two states. A similar concept is supertwisted nylon fishing line \"muscles\" which contract upon heating. I think starfish muscles are contracted in the default/energy-off mode, so maybe we could make smart fibers which are actively elastic/\"plastic\". reply icegreentea2 17 hours agorootparentprevI think it means that it's basically permanent - it cannot be unshaped. You can of course keep \"tucking it in\". reply demondemidi 17 hours agoparentprevI’m curious how the flexibility of the reformed fabric lasts over dressing/undressing cycles, garment care, and long term storage in a closet. If I’m not careful I can easily stretch out a well made alpaca wool sweater if I remove it too carelessly (from experience!). I wonder how fussy this is. Also would like to know more about the machine. Many garments are knitted as tube-like structures just look at circular knitting needles, where does this differ and how? reply anon84873628 14 hours agorootparentIt doesn't seem like this is intended to be reusable or even useful. It's just a college design project that gets the attention of MIT branding. reply spaceguillotine 6 hours agorootparentprevits like making nylon stockings but a dress, there is a video that shows the process that would answer a lot of your questions on the site near the bottom of the page reply demondemidi 3 hours agorootparentAh very cool thanks! reply jijijijij 16 hours agoparentprevHow disappointing. Today it's all polyester, polyester and more stinky polyester. Tomorrow the washing machine has it ground to dust already, forever. Lucky us, this single-use dress is of bespoke fit! reply gilbetron 19 hours agoprevThe \"4d\" refers to the knit, which finishes knitting itself after a bit of time. I thought it was like some klein bottle dress or something at first. Still cool. reply esquivalience 18 hours agoparentMy reading of this was that the fourth dimension was time. First, a loose dress is 3D-knit; then, when the owner buys it, it's possible to apply heat to cause parts of the fabric to tighten up, overall making a bespoke fit without significant manual labour. reply SiempreViernes 15 hours agorootparentI'm not entirely sure how much labour is saved vs making it custom cut from the start, having to stand in the reach of an industrial robot and get blasted with a heat gun doesn't seem like a great customer experience... presumably all the relevant measurements had been taken ahead of time so a tool-path for the robot could be created reply hammock 14 hours agorootparentSeems less about saving labor and more about proving technology. You could take this concept a step further and 3d-scan the subject body with a laser, then 3d print a model, and the clothing draped on the model and heat-shrunk (rather than using a software to decide where to heat shrink and how much) reply hammock 14 hours agorootparentprevIt’s shrink-to-fit denim, with a 3d pattern. Instead of wearing your dress in the bathtub, you hang it up and a robotic arm blow dries it reply a012 18 hours agoprevSo you _must_ wash it with cold water, I guess reply stubish 8 hours agoparentWash it? Toss it into the recycler and print a fresh one tomorrow morning :) The video show a heat gun at fairly close range shrinking the fabric, which would be over 80 degrees. You might be able to get away with hot water, but I suspect the label will say 'dry clean only'. reply tmitchel2 18 hours agoparentprevAlong with your 4D woolly jumpers reply shermantanktop 10 hours agorootparentWatch out for tetrachromatic colors, they can bleed. reply Yusefmosiah 14 hours agoprevsynthetic fabrics in clothing are a major source of microplastics exposure. In the future we will look back in horror at this whole industry. reply smegger001 14 hours agoparentI wonder if the plastic we deposit into the environment will form oil/coal deposit layers in a few million years? Or will microbes develop means to digest all those energy rich hydrogen carbon bonds those polymers are composed of. Much like our coal/oil deposits date back to before evolution a means to metabolize cellulose. reply jamiek88 9 hours agorootparentI guess it’s my turn to point out the lignin indigestibility hypothesis is no longer current and indeed has been disputed since the 1990’s. This article from 2016 goes into the details: https://www.earthmagazine.org/article/lack-fungi-did-not-lea... >To form coal you need two basic conditions: wet tropics and a hole to bury organic matter in for a long period of time,” Boyce says. During the formation of Pangea, collisions between continents raised mountain ranges while downwarping adjacent crust, which created massive basins. These basins became ideal depositories for wet organic plant matter, which was buried, compressed and cooked over geologic time to form coal. Similar conditions likely also produced coal deposits during the Mesozoic Era, and the Paleocene and Eocene epochs, often in conjunction with mountain-building episodes such as the formation of the Rocky Mountains. reply QuesnayJr 2 hours agorootparentThis is the first time I've heard this, so I'm glad you're taking turns. reply dclowd9901 2 hours agoparentprevAlso a major source of clothes falling apart. My ever since Levi’s made their pants stretchy, they’re absolute shit. reply James_K 17 hours agoprevThe text contrast on this website is awful. reply graiz 15 hours agoprevMinistry of Supply has always had great products, more people need to know about them. reply jasonm23 6 hours agoprevhmm 4D clickbait reply YetAnotherNick 17 hours agoprevDid they talk about cost anywhere? Depending on it, it could transform the industry or it could be totally irrelevant. reply shrx 15 hours agoparentSpoiler: it will be the latter reply samstave 18 hours agoprevThe haptic sleeve is more interesting!!! reply 082349872349872 18 hours agoparentit needs to be crossed with: https://news.ycombinator.com/item?id=39649184 reply samstave 17 hours agorootparentNOT A FAN. Its both terrifying and amazing. Im going with terrifying. But, also, this is how Mecha works... but in anime the pilot is inside the robot. Teleportation is Avatar... but yeah, now its a reality is super FN scary --- WAIT: what was that movie with Dexter where they controlled prisoners though such as a game... its a brilliant movie... reply empiricus 17 hours agoprevWe are still making clothes like savages, with the only improvement being the economy of scale. We should enter a store, take a instant 3d scan, then get clothes that are custom made to size, seamless knitted, of our choice materials, properties, colors. reply yeutterg 17 hours agoparentBonobos has physical \"Guideshops\" [0] that do not carry all inventory, but should carry a majority of the fits and sizes offered by the brand. The idea is that you go in to find the right fit, then you order your preferred color online. This reduces physical inventory in stores. Made-to-Measure is also becoming increasingly popular. While costly compared to brands like Gap and Uniqlo, often you can get well-fitted made-to-measure garments for similar prices to mid-tier brands. For example, SuitSupply [1] offers made-to-measure dress shirts, trousers, and suits for only slightly more than their off-the-rack offerings, and FITTED Underground [2] offers made-to-measure jeans that are still in the price ballpark of premium selvedge jeans. Usually, these brands also let you customize things like button colors, cuffs, collars, monograms, etc. at little-to-no extra charge. Even some shoe brands like Beckett Simonon [3] and BLKBRD [4] operate on made-to-order models, reducing inventory, and sometimes allowing customization. All these options still rely on traditional manufacturing, but just the fact that you can get the fit right allows people to consume less. [0] https://bonobos.com/guideshop [1] https://suitsupply.com/en-us/ [2] https://fittedunderground.com/ [3] https://www.beckettsimonon.com/ [4] https://www.blkbrdshoemaker.com/ reply stubish 8 hours agoparentprevYou are describing many low end tailor shops. You walk in, get 3d scanned (by the 'tailor'), choose your fabrics, and the order gets sent to the printer (the nearby sweatshop). It could be same day turn around if they didn't know you would pay more to wait a week. reply spaceguillotine 6 hours agoparentprevThere are places that do that in Hoi An, Vietnam and can allegedly retain your 3d scan for custom made clothing later without needing to visit. The fashion space is full of tech innovations like that we never see or know about unless you follow the clothing industry which is not hacker new's forte by any means, gonna bet the majority is looking for hoodies and jeans here. reply monkeydust 17 hours agoparentprev3D scanning is getting there, e.g. https://www.aistetic.com/ in UK which is being by a few online retailers. At least helps with fit and reduces returns burden. Getting from that to custom printed clothing is certainly and interesting idea if the economics ever work out. reply kwhitefoot 15 hours agoparentprevThe ultimate in fast fashion. The result might be a massive pile of discarded clothes that fit no one unlike now when discarded clothing is bought and sold sometimes several times over. Plus you have to bear in mind that for many people having to make decisions about style, fit, material, colour, pattern is a burden not a pleasure. People just want a new pair of jeans to replace the ones that got damaged so next time they are in Tesco's or Sainsbury's they just grab one off the rail and throw it in the trolley. reply namibj 16 hours agoparentprevI am still searching for reasonably priced T-Shirts that only have seams from the armpits to the hips (one such seam per side), and optionally at the 4 holes for edge reinforcement. Critically, this means no seams on top of shoulders by any reasonable definition of what \"on top of shoulder\" means. You could knit it on a tube knitting machine capable of adjusting loop count/circumference freely. But for a T-Shirt you have very fine knitting, so regular knitting machines can at best do newborn-sized T-Shirts. If anyone happens to know where I could order a dozen shirts knitted to spec based on knit design rules and published-by-them loop-pitch-after-first-wash from cotton, I'd love to hear. reply yeutterg 16 hours agorootparentWhat is the reason for not wanting the seams on the top of the shoulders? Aesthetics? Weightlifting? Not seamless, but: There are a lot of brands that offer t-shirts with \"raglan\" sleeves where the seam runs from the collar to the bottom of the armpit, instead of along the top of the shoulder. Or: I personally have a number of the Durable Shirt from Ten Thousand [0], which has 2 seams on the front and back of the shoulder instead of 1 directly on top. This is so you can put a barbell on your shoulders comfortably, but I also like the aesthetic. It also looks like they are currently out of stock on these, but maybe they'll have more in the future. [0] https://www.tenthousand.cc/products/durable-shirt?variant=39... reply fsckboy 9 hours agorootparentI had to look up raglan sleeve (it refers to the pieces of fabric and where they are stitched together, not the 2-tone colors which do make it easier to see) https://gothaesthetics.com/wp-content/uploads/2020/12/RAGLAN... reply balls187 14 hours agoparentprevWho is going to pay $500 for a t-shirt? reply TheRealPomax 15 hours agoparentprevThe amazing part is that you're so close, but you're still thinking like a savage: why would you go into \"a clothing store\" for this? You take a 3d scan at home, and send that over to the print-on-demand store that does spin-on-demand, for pickup whenever you're out next, or delivery at a surcharge. reply empiricus 14 hours agorootparentA civilized person sometimes leaves the home. reply TheRealPomax 13 hours agorootparentWhich was already baked into the last sentence, yes. The point is that \"going to a clothing store\" makes no sense if we're scanning for print-on-demand anyway. The scanning and fabrication don't need to happen in the same place, and once we're in a future where products are made on demand, it definitely doesn't make sense to still have \"a clothing store\". That's just something that any print-on-demand store that also does fabrics can handle. reply VoodooJuJu 17 hours agoprevSubtly paying homage to the classic Silicon Valley dress psyop [1] with the different lit photos. Cute. [1] https://en.wikipedia.org/wiki/The_dress reply noman-land 17 hours agoparentHow was this a psyop? reply brvsft 17 hours agorootparentNo one sees anything other than blue/black. So there are paid crisis actors out there lying about seeing other colors. reply peterpost2 17 hours agorootparentwhy would someone be paid to lie about the colors? reply brvsft 16 hours agorootparentI'm being facetious in speculating how it would be a \"psyop.\" reply shermantanktop 10 hours agorootparentfwiw, i got it. reply m47724 16 hours agoprev [–] Andate a fare in culo reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The 4D Knit Dress is a collaboration between MIT Self-Assembly Lab and Ministry of Supply, combining heat-activated yarns, computerized knitting, and robotic tech for a customizable garment fitting any body shape or style.",
      "This innovative project standardizes 3D shaping in clothing construction, overcoming traditional garment limitations for a more personalized and efficient fit, showcasing the fusion of technology and fashion.",
      "The collaboration demonstrates the potential to revolutionize clothing creation and customization through the integration of advanced technology in the fashion industry."
    ],
    "commentSummary": [
      "A groundbreaking clothing production method utilizes heat-activated yarns for innovative garments like a 4D knit dress and a polyester dress that can be ground down and recycled.",
      "Environmental impact, customization, and coal formation are key concerns surrounding this revolutionary process.",
      "Industry discussions involve mid-tier brands providing made-to-measure choices, seamless shoulder construction, 3D scanning for on-demand clothing, and potential color perception deception."
    ],
    "points": 207,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1709993959
  },
  {
    "id": 39653431,
    "title": "Bypassing Safari 17's audio fingerprint protection",
    "originLink": "https://fingerprint.com/blog/bypassing-safari-17-audio-fingerprinting-protection/",
    "originBody": "Did you know that browsers can produce audio files you can’t hear, and those audio files can be used to identify web visitors? Apple knows, and the company decided to fight the identification possibility in Safari 17, but their measures don’t fully work. Identifying with audio The technique is called audio fingerprinting, and you can learn how it works in our previous article. In a nutshell, audio fingerprinting uses the browser’s Audio API to render an audio signal with OfflineAudioContext interface, which then transforms into a single number by adding all audio signal samples together. The number is the fingerprint, also called “identifier”. The audio identifier is stable, meaning it doesn’t change when you clear the cookies or go into incognito mode. This is the key feature of fingerprinting. However, the identifier is not very unique, and many users can have the same identifier. Audio fingerprinting is a part of FingerprintJS, our library with source code available on GitHub. Fingerprinting is used to identify bad actors when they want to remain anonymous. For example, when they want to sign in to your account or use stolen credit card credentials. Fingerprinting can identify repeat bad actors, allowing you to prevent them from committing fraud. However, many people see it as a privacy violation and therefore don’t like it. How Safari 17 breaks audio fingerprinting Apple introduced advanced fingerprinting protection in Safari 17. Advanced fingerprinting protection aims to reduce fingerprinting accuracy by limiting available information or adding randomness. By default, the advanced protection is enabled in private (incognito) mode and disabled in normal mode. It affects both desktop and mobile platforms. Advanced fingerprinting protection also affects Screen API and Canvas API, but we’ll focus only on Audio API in this article. An audio signal produced with the Audio API is an array of numbers representing the signal amplitude at each moment of time (also called “audio samples”). When fingerprinting protection is on, Safari adds a random noise to every sample individually. A noised sample lies between sample*(1-magnitude) and sample*(1+magnitude), and the distribution is uniform. This is how it’s implemented in Safari: void applyNoise(float* values, size_t numberOfElementsToProcess, float magnitude) { WeakRandom generator; for (size_t i = 0; i{ width = Math.sqrt(12 * variance) shift = mean - width / 2 return () => Math.random() * width + shift } const normalRandom = (mean, variance) => { // https://en.wikipedia.org/wiki/Box–Muller_transform const pi2 = Math.PI * 2 const sigma = Math.sqrt(variance) return () => Math.sqrt(-2 * Math.log(Math.random())) * Math.cos(pi2 * Math.random()) * sigma + mean } const averageMeanFind = samples => samples.reduce((a, b) => a + b) / samples.length const midRangeMeanFind = samples => { let min = samples[0] let max = samples[0] for (let i = 1; imax) { max = samples[i] } } return (min + max) / 2 } const findAdequateSampleCount = (makeRandom, findMean) => { const mean = 0 const variance = 1 const random = makeRandom(mean, variance) sampleCountLoop: for (let sampleCount = 2; sampleCountdesiredMaxError) { continue sampleCountLoop } } return sampleCount } return 'Too much time to compute' } console.log('Normal needs samples', findAdequateSampleCount(normalRandom, averageMeanFind)) console.log('Uniform needs samples', findAdequateSampleCount(uniformRandom, midRangeMeanFind)) // Normal: 524288, uniform: 4096 The old audio fingerprint is more computation-demanding and requires 100 times more fingerprint samples to reduce the noise. So, to reduce the noise in a reasonable time, we changed the fingerprinting algorithm to collect only one audio sample, which has a uniform noise distribution. The exact number of randomized samples needed depends on the rounding precision we need, which will be demonstrated later. The algorithm change also means new fingerprints aren’t compatible with old fingerprints. Because of the rounding, the audio fingerprint will change, so sticking to the old fingerprint identifiers is useless. Note that you need to use a special approach to switch from the old fingerprint to the new one without losing the visitor identities. Getting many noised copies of the same audio sample One approach for getting multiple noised copies is calling getChannelData on the AudioBuffer instance many times. Remember that getChannelData returns the audio samples that the fingerprint is calculated from. This approach doesn’t work because noise is applied once per each AudioBuffer instance, and getChannelData returns the same signal. This can be circumvented by creating many AudioBuffer instances by running the whole audio signal generation process many times. For 6,000 noised samples, the fastest time is 7 seconds on an M1 MacBook. For 60,000, Safari can’t even finish the process. This is way too long for a fingerprint. Therefore, this approach is not viable. A better approach is to make an AudioBuffer instance with the same audio signal on repeat: Render an audio signal as usual, but don’t call getChannelData, because it will add noise to the signal. Create another OfflineAudioContext instance, much longer than the original instance. Use the original signal as a source using an AudioBufferSourceNode. Make the AudioBufferSourceNode loop the needed piece of the original signal using loop, loopStart, and loopEnd. The piece can be as narrow as a single audio sample. Render the second (looped) audio context and call getChannelData. The resulting audio signal will consist of the original signal followed by the piece repeating until the end. Safari adds a noise after the looping, so the repeating copy has the same audio samples with different noise applied. Here’s how to implement this approach: const sampleRate = 44100 getClonedPieces() async function getClonedPieces() { const pieceLength = 500 // Can be as little as 1 const cloneCount = 1000 // Rendering the original audio signal const baseSignal = await getBaseSignal() const loopStart = baseSignal.length - pieceLength // A new audio context that loops an ending part of the original audio signal const context = new OfflineAudioContext(1, loopStart + cloneCount * pieceLength, sampleRate) const sourceNode = context.createBufferSource() sourceNode.buffer = baseSignal sourceNode.loop = true sourceNode.loopStart = (baseSignal.length - pieceLength) / sampleRate sourceNode.loopEnd = baseSignal.length / sampleRate sourceNode.connect(context.destination) sourceNode.start() // Rendering the new audio context and extracting the looped part const signalBuffer = await renderAudio(context) const clones = signalBuffer.getChannelData(0).subarray(loopStart) console.log(clones) } async function getBaseSignal() { const context = new OfflineAudioContext(1, 5000, sampleRate) // Any audio signal... return await renderAudio(context) } function renderAudio(context) { // See the implementation at https://github.com/fingerprintjs/fingerprintjs/blob/c411aff111e5c79cdc37608d42632d4a66a8c1dc/src/sources/audio.ts#L147 } Any number of noised sample copies can be produced in 2 audio renderings. The code below combines the methods to denoise a single selected audio sample: const sampleRate = 44100 console.log(denoiseAudioSample(10000)) async function denoiseAudioSample(cloneCount) { // Rendering the original audio signal const baseSignal = await getBaseSignal() // A new audio context that loops an ending part of the original audio signal const context = new OfflineAudioContext(1, baseSignal.length - 1 + cloneCount, sampleRate) const sourceNode = context.createBufferSource() sourceNode.buffer = baseSignal sourceNode.loop = true sourceNode.loopStart = (baseSignal.length - pieceLength) / sampleRate sourceNode.loopEnd = baseSignal.length / sampleRate sourceNode.connect(context.destination) sourceNode.start() // Rendering the new audio context const signalBuffer = await renderAudio(context) // Restoring the mean (the audio sample before the noising) return getMiddle(signalBuffer.getChannelData(0).subarray(baseSignal.length - 1)) } async function getBaseSignal() { const context = new OfflineAudioContext(1, 5000, sampleRate) // Any audio signal... return await renderAudio(context) } function renderAudio(context) { // See the implementation at https://github.com/fingerprintjs/fingerprintjs/blob/c411aff111e5c79cdc37608d42632d4a66a8c1dc/src/sources/audio.ts#L147 } function getMiddle(samples) { let min = samples[0] let max = samples[0] for (let i = 1; imax) { max = samples[i] } } return (min + max) / 2 } At this point, the noise is suppressed, not removed completely. The resulting number is still not stable, but the variance is smaller than that of a raw audio sample. This table shows how the denoising precision and time in the above code snippet depend on the number of samples (cloneCount): Number of copies Result range: (max-min)/min in 100 runs Time on an M1 MacBook 2,048 0.194% 2.0ms 4,096 0.190% 2.3ms 8,192 0.000387% 2.6ms 16,384 0.0000988% 2.9ms 32,768 0.0000411% 4.0ms 65,536 0.0000123% 4.1ms 131,072 0.00000823% 5.2ms 262,144 0% (the ultimate precision) 7.5ms 524,288 0% 11.9ms 1,048,576 0% 20.5ms Step 2: Push browser identifier numbers farther apart The times shown in the previous table can be 100 times longer on low-end devices or heavy webpages. The performance of the fingerprinting is important, so the fewer copies there are, the better. However, fewer copies mean bigger result dispersion, so it’s necessary to increase the difference between the audio samples in browsers too. These differences can be achieved by changing the base signal. Audio nodes with heavy distortion After hours of experimenting with all the built-in audio nodes, we found an audio signal generator that gives a much bigger audio sample variance between browsers. The generator is a chain of audio nodes: The initial signal is produced by a square OscillatorNode. Then, the signal goes through a DynamicsCompressorNode. Finally, the signal is processed by a BiquadFilterNode of type “allpass”. It is not necessary to know what the audio nodes do in detail. They can be treated as black boxes. The audio sample number 3396 of the signal has the biggest difference between browsers. The number 3396 was found by simply comparing all samples of the audio signals in different browsers. This is how the signal is implemented in code: async function getBaseSignal() { const context = new OfflineAudioContext(1, 3396, 44100) const oscillator = context.createOscillator() oscillator.type = 'square' oscillator.frequency.value = 1000 const compressor = context.createDynamicsCompressor() compressor.threshold.value = -70 compressor.knee.value = 40 compressor.ratio.value = 12 compressor.attack.value = 0 compressor.release.value = 0.25 const filter = context.createBiquadFilter() filter.type = 'allpass' filter.frequency.value = 5.239622852977861 filter.Q.value = 0.1 oscillator.connect(compressor) compressor.connect(filter) filter.connect(context.destination) oscillator.start(0) return await renderAudio(context) } function renderAudio(context) { // See the implementation at https://github.com/fingerprintjs/fingerprintjs/blob/c411aff111e5c79cdc37608d42632d4a66a8c1dc/src/sources/audio.ts#L147 } // The audio sample number 3396 (if counted from 1) const audioSample = (await getBaseSignal()).getChannelData(0).at(-1) The following table shows the resulting audio sample in different browsers: Browser Audio sample Difference from the closest browser MacBook Air 2020, Safari 17.0 0.000059806101489812136 0.0014% iPhone 13, Safari 15.4 (BrowserStack) 0.00005980528294458054 0.0014% MacBook Pro 2015, Safari 16.6 0.00006429151108022779 0.046% MacBook Pro 2015, Chrome 116 0.0000642621744191274 0.046% MacBook Air 2020, Chrome 116 0.00006128742097644135 2.42% Galaxy S23, Chrome 114 0.0000744499484426342 11.8% Acer Chromebook 314, Chrome 117 0.00008321150380652398 10.53% iPhone SE, Safari 13.1 0.00011335541057633236 26.6% BrowserStack Windows 8, Firefox 67 0.00016917561879381537 0.0063% MacBook Air 2020, Firefox 118 0.00016918622714001685 0.0040% MacBook Pro 2015, Firefox 118 0.00016919305198825896 0.0040% Now the smallest difference is 0.0014%, which is much bigger than the original fingerprint (0.0000023%). It means that a much coarser denoising is possible. Step 3: Round the result The final step is stabilizing the sample to be used as a fingerprint. The sample range is small but still unstable, which is not suitable for FingerprintJS, because even a tiny change to the sample causes the whole fingerprint to change. Rounding is a way to stabilize the audio sample. Usually, rounding preserves a specific number of digits after the decimal point. This is not a good choice in this case because, as mentioned at the beginning, the noise is not absolute; it’s relative to the audio sample number. Therefore, some number of significant digits should be preserved during rounding. Significant digits are all digits after the beginning zeros. You can see a rounding implementation on GitHub. The table above shows that 5 significant digits are enough to tell the selected browsers apart. But since we can’t check all browsers in the world and can’t predict how they will change in the future, we use a few more digits, just in case. The table below shows the number of audio sample copies needed to make the denoising result stable in private mode of Safari 17 after rounding with the given precision: Significant digits # of copies Time in Safari 17 on an M1 MacBook (warm) Time in Chrome 116 on an M1 MacBook (warm) Time in Chrome 114 on Pixel 2 (warm) 6 15,000 3ms 4ms 13ms 7, but the last is the nearest multiple of 5 30,000 4ms 5ms 15ms 7, but the last is the nearest even digit 70,000 6ms 7ms 16ms 7 and more 400,000 12ms 13ms 34ms A ”warm” browser is a browser that has run the given code before. A browser becomes “cold” when it’s restarted. A warm browser produces more stable time measurements. We chose “7, but the last is 0 or 5” as a good balance between the performance and uniqueness. We also increased the number of copies to 40,000 to increase stability. The rounded number is the final new audio fingerprint that doesn’t change, even when Safari 17’s advanced fingerprinting protection is on. Uniqueness is an important property of fingerprinting. The new fingerprint has the same uniqueness as the old audio fingerprint. Performance The following table shows the fingerprinting time on a blank page in warm browsers: Browser Old fingerprint New fingerprint MacBook Air 2020, Safari 17.3 2ms 4ms MacBook Air 2020, Chrome 120 5ms 8ms MacBook Air 2020, Firefox 121 6ms 8ms MacBook Pro 2015, Safari 16.6 4ms 6ms MacBook Pro 2015, Chrome 120 5ms 7ms MacBook Pro 2015, Firefox 121 5ms 7ms iPhone 13 mini, Safari 17.3 8ms 12ms iPhone SE, Safari 13.1 9ms 17ms Acer Chromebook 314, Chrome 120 7ms 13ms Galaxy S23, Chrome 120 6ms 8ms Galaxy J7 Prime, Chrome 120 33ms 45ms Pixel 3, Chrome 120 8ms 15ms BrowserStack Windows 11, Chrome 120 5ms 7ms BrowserStack Windows 11, Firefox 121 10ms 18ms Compared to the old fingerprinting algorithm, the performance of the new one degrades 1.5–2 times. Even so, the new fingerprint algorithm takes little time to compute, even on low-end devices. The browser delegates some work to the OfflineAudioRender thread, freeing the main thread. Therefore, the page stays responsive during most of the audio fingerprint calculation. Web Audio API is not available for web workers, so we cannot calculate audio fingerprints there. To improve the performance, the new fingerprint can be used only in Safari 17 while keeping the old algorithm in other browsers. Check whether the current browser is Safari 17 or newer using the user-agent string. Based on that, run either the old or the new fingerprinting algorithm. How it Works in Privacy-Focused Browsers Privacy-focused browsers like Tor and Brave also make attempts to restrict audio fingerprinting. Web Audio API is completely disabled in Tor, so audio fingerprinting is impossible. Brave, however, follows an approach like Safari 17 and adds noise to the audio signal. Our previous article explains more about Brave’s audio fingerprinting protection. The Brave noise has an important difference. While Safari adds a random noise for each audio sample individually, Brave makes a random multiplier (called “fudge factor”) once and uses it for all audio samples. That is, all audio samples are multiplied by the same number. The fudge factor persists within a page. It changes only in a new regular or incognito session. // A pseudo-code to illustrate the difference const audioSignal = new Float32Array(/* ... */) const magnitude = 0.001 // Safari for (let i = 0; i < audioSignal.length; i++) { audioSignal[i] *= random(1 - magnitude, 1 + magnitude) } // Brave const fudgeFactor = random(1 - magnitude, 1 + magnitude) for (let i = 0; i < audioSignal.length; i++) { audioSignal[i] *= fudgeFactor } No matter how many audio sample copies we make, the noise addition will be the same in every copy. The copies won’t be dispersed around the true (before noising) audio sample. Therefore, the mathematical denoising method doesn’t work. Nevertheless, the Brave denoising method described in the previous article still works. The method for increasing the difference between fingerprints produced by browsers can also increase the error tolerance. Usage in FingerprintJS The new audio fingerprinting algorithm replaced the old one in FingerprintJS. It was first published in version 4.2.0. You can see the full code for the audio fingerprint implementation in our GitHub repository. Audio fingerprinting is one of the many signals our source-available library uses to generate a browser fingerprint. However, we do not blindly incorporate every signal available in the browser. Instead, we analyze the stability and uniqueness of each signal separately to determine their impact on fingerprint accuracy. For audio fingerprinting, we found that the signal contributes only slightly to uniqueness but is highly stable, resulting in a slight net increase in fingerprint accuracy. If you want to learn more about Fingerprint join us on Discord or reach out to us at oss-support@fingerprint.com for support using FingerprintJS. All article tags Apple safariFingerprintingEngineering FAQ What is audio fingerprinting and how is it used in browser identification? Audio fingerprinting is a technique used to identify browsers based on the unique characteristics of their audio output. It works by analyzing the way a browser processes and outputs audio signals, using differences in the audio stack across devices, such as the Audio API implementation and hardware interactions, to create a unique identifier. How has Safari 17's updates impacted audio fingerprinting techniques? Safari 17's update introduces random noise to audio samples generated by the browser, intentionally distorting the audio output to obscure its unique characteristics. This addition of noise disrupts the consistency of audio fingerprints, as the deliberate fluctuations make it challenging to generate a stable and repeatable browser identifier.",
    "commentLink": "https://news.ycombinator.com/item?id=39653431",
    "commentBody": "Bypassing Safari 17's advanced audio fingerprinting protection (fingerprint.com)183 points by valventin 14 hours agohidepastfavorite139 comments redbell 9 hours agoAnother interesting technique to fingerprint users online is called GPU Fingerprinting [1] (2022). Codenamed 'DrawnApart', the technique relies on WebGL to count the number and speed of the execution units in the GPU, measure the time needed to complete vertex renders, handle stall functions, and more stuff ________________ 1. https://www.bleepingcomputer.com/news/security/researchers-u... reply chii 6 hours agoparentbrowsers should come with a default software renderer, and behave like the mic and camera where the site will require user permission to release the hardware GPU render path. reply sweetjuly 2 hours agorootparentbut nobody wants to use software rendering, that's the whole reason WebGL and WebGPU exist. reply TylerE 4 hours agorootparentprevDo you have any concept of how many gigawatts per day that would waste? reply avoid3d 4 hours agorootparentVery pedantic but I’d want to know. A watt is a unit of power, which means gigawatts per day is a rate of change of power. If you want a unit of energy you need power multiplied by time not divided, so “gigawatt days” not “gigawatts per day”. reply Faaak 2 hours agorootparentMaybe they meant \"gigawatt-hours per day\" reply protomolecule 1 hour agorootparentWhich gives you power again, not work. \"gigawatt-hours per day\" = gigawatt/24 reply stephen_g 1 hour agorootparentIf you consider that watt hours is just a convenience unit for (3600) joules, then “1 gigawatt hour each day” correctly should be “3600 GJ/day” which works. reply geon 1 hour agorootparentprevWhich is a reasonable metric. reply IAmGraydon 4 hours agorootparentprevI’m not following. Why would disabling the GPU use more power? If anything, I would think it would reduce power consumption. reply TylerE 4 hours agorootparentHardware implantations of things like graphics routines can be hundreds of time more efficient than software implementations running on general purpose CPUs. Try to decode mpeg video at HD resolution in software sometime. reply lukan 1 hour agorootparentThe native GPU video decoding (and CSS and canvas GPU acceleration) can work without problems, if only webGL gets deactivated, what this was about here. But you can probably also use those to fingerprint, but probably not as precise. reply chii 3 hours agorootparentprevsurely, the user will be taught to enable the hardware for video if they start seeing stutter. Or the browser can prompt the user to switch to \"high-end graphics\" if it detects prolonged video decoding. If a website that has no obvious case for using the GPU, but is instead using it to fingerprint, then the user won't experience any slow downs from a software renderer (as it is usually done relatively quickly). If a website needs the GPU for their videos/graphics, but also incidentally wants to fingerprint you, you're shit out of luck in that case. But this is no worse than what we have current day. reply TylerE 3 hours agorootparentOh expect users to understand this? The same people who have spent the past 40 years getting confused and worked up about cookies? reply subtra3t 3 hours agorootparentprevIf the user experiences stuttering while decoding a video, they won't learn to enable special permissions for the website but instead switch to a different browser that hasn't yet implemented this \"feature\". And most websites most users visit will need the GPU to be remotely usable. For them enabling specific permissions for every website they visit is very inconvenient. reply Dalewyn 2 hours agorootparentprevPerhaps a middle ground: Default to software acceleration when in Private Browsing mode, because obviously you want to be private, default to hardware acceleration otherwise. reply Dudhbbh3343 2 hours agorootparentprevLibreWolf (a privacy focused modification of Firefox) disables WebGL by default for this reason. reply danbolt 5 hours agorootparentprevI feel like the constraints could open up an interesting demoscene too. reply h4x0rr 13 hours agoprevCan anyone explain why the results are different to begin with? E.g. why is this audio fingerprinting even possible in the first place? reply dmazzoni 12 hours agoparentThe essence seems to be that the web audio API has a lot of algorithms that do a lot of math, and every browser has a slightly different implementation, and the exact results depend on the operating system and cpu too. So if you use the web audio API to generate a small signal all browsers will generate something that's really close, but the tiny differences can be used to help tell them apart. reply jameshart 4 hours agorootparentBut why would it vary in ways that are consistent run to run on one machine, but not consistent with the same process executed on another similar machine? reply ralphist 15 minutes agorootparentEvery datapoint reduces the number of people it could belong to. CPU + browser + browser version + OS + major OS version can narrow it down by a lot. Then add resolution, IP address location (which VPN they use is also a datapoint), which time they are active at, etc. and you can get a good almost-unique identifier. reply nox101 12 hours agorootparentprevthat wouldn't help. you already know the browser and os through easier means reply unglaublich 12 hours agorootparentLike what? The voluntarily provided User-Agent? The browser is in control of that. reply meandmycode 9 hours agorootparentThe browser in this adversarial scenario is also in control of the audio context too reply bdd8f1df777b 7 hours agorootparentYet it is incredibly difficult to hide the underlying hardware or low level library differences. Not without slowing things down significantly. reply hiatus 6 hours agorootparentprevDo you, as an end user, know how to change these settings compared to changing your user agent? reply a-dub 12 hours agoparentprevi think it comes from similar tricks that are played with webgl where there is a lot of entropy that comes from pc videocard drivers and the hardware itself. it's a shame that browser people have to add noise to audio buffer handling to try and thwart it. reply Retr0id 12 hours agoparentprevThis was my first thought too, and they cover it in more detail here https://fingerprint.com/blog/audio-fingerprinting/#why-the-a... TL;DR different codepaths even within the same codebase (e.g. SIMD variants) can result in subtly different floating point results (iiuc, likely related to to the fact that floating point math is unexpectedly sensitive to order of operations etc.) reply TylerE 4 hours agorootparentFunny how when I posted more or less exactly this comment in another context recently a lot of people refused to take me seriously! https://news.ycombinator.com/context?id=39633730 reply Retr0id 4 hours agorootparentFloats are deterministic, though (if they weren't, this wouldn't be a workable fingerprinting vector). Reordering of operations (etc.) in a way that would actually change the results needs to be done by human edits, or with compiler options like ffast-math that explicitly allow the compiler to \"break the rules\" and make such changes. In either case, the concrete instructions emitted by the compiler will have deterministic behavior (and if they don't, that's a hardware bug) reply TylerE 2 hours agorootparentWhat word would you use if sin(x) returns a different value on different platforms, or even different OS or librsry version? Sure smells like a fiction that depends on external state rather than simply its input. reply echoangle 12 hours agoparentprevProbably implementation details and compiler optimizations, float addition is not commutative for example. Implementing the same algorithm with the same formulas correctly can still lead to slightly different results reply Angostura 4 hours agorootparentI would have thought it might have yielded a machine and OS identifier - but more user specific than that? reply echoangle 1 hour agorootparentThat’s what it does, users on the same browser and same hardware should have identical fingerprints. It’s just one way of multiple to narrow down your fingerprint. reply saagarjha 6 hours agorootparentprevFloating point addition is not commutative, but it is still consistent. Getting different results is usually the result of using alternative algorithms or relaxing standards (that may, for example, reorder terms). reply echoangle 1 hour agorootparentI don’t think the web spec implemented by the browser specifies the order of every operation, only the algorithm. If safari and chrome devs implement the audio api based on the spec, there can still be minor floating point differences because of the way they implemented the same calculations. That’s why they can fingerprint your browser versions with this. reply jancsika 9 hours agoprevSomeone definitely correct me if I'm wrong, but the success of the fingerprinting workarounds here seem to boil down to the following choice wrt handling oscillator anti-aliasing in the Web Audio API spec: \"There are several practical approaches that an implementation may take to avoid this aliasing. Regardless of approach, the idealized discrete-time digital audio signal is well defined mathematically. The trade-off for the implementation is a matter of implementation cost (in terms of CPU usage) versus fidelity to achieving this ideal. It is expected that an implementation will take some care in achieving this ideal, but it is reasonable to consider lower-quality, less-costly approaches on lower-end hardware.\" AFAICT this means that the OscillatorNode output they are exploiting here is almost guaranteed to not be deterministic across browsers (or even in the same browser on different hardware). The non-determinism is based on whatever anti-aliasing method is chosen by the browser (or, possibly, multiple paths within the same browser which could get chosen based on the underlying hardware). This includes changes/fixes to the same anti-aliasing algos. I don't really understand this choice of relegating anti-aliasing to the browser given that: a) any high-quality audio app/library will want full control over how the signals they generate avoid aliasing and will not use these stock oscillators anyway, or b) the kinds of web applications that would accept arbitrary anti-aliasing algos (and the consequent browser-dependent discrepancies therein) probably wouldn't care whether the aliasing algo is hardcoded SIMD instructions or some 20MB javascript web audio helper framework 1: https://webaudio.github.io/web-audio-api/#OscillatorNode Edit: clarification Edit 2: more clarifications. :) Edit 3: I wonder if the same kind of solution could be used here as was used by Hixie to standardize the HTML5 parser. Namely, just have some domain expert specify an exact, deterministic algo for anti-aliasing that works well enough, then have all the browsers use that going forward. I'd bet the only measurable perf hit would be to tutorials that show how to use the web audio api to generate signals from the stock anti-aliased oscillators. :) reply saagarjha 6 hours agoprevI feel like these days (especially given the recent focus on side channel attacks) it is basically a given that adding uniform noise to something that leaks data does not work, because you can always take more samples and remove the noise. Why did Safari add this? I understand that needing more samples is definitely an annoyance to fingerprinting efforts, but as this post shows it's basically always surmountable in some form or the other. reply lapcat 5 hours agoparent> Why did Safari add this? A lot of Apple's \"privacy\" features nowadays are marketing. It's privacy theater. What matters is whether they can tell a plausible story to the public, not whether is technically effective. reply simondotau 2 minutes agorootparentThat's an wild accusation to make without citations. It doesn't even apply in this instance, since Apple's work on fingerprint resistance still results in real privacy improvements even after they've been shown to be imperfect. It means Apple has to improve what they've already done, not that what they've already done is mere \"marketing\" or \"theatre\". reply shuckles 5 hours agorootparentprevIs iCloud Private Relay theatre? 3rd party cookie blocking? What specific features do you allege exist just to mislead the general public? reply iamleppert 3 hours agoprevCouldn’t you just replace the prototype of the Audio API to return back whatever you wanted? The difficulty would be in getting enough fingerprints for your desired imitation but the article itself seems to have that information. reply chrisbrandow 8 hours agoprevThis is gross. reply IceHegel 14 minutes agoparentIt raises the question of whether the current networking stack is the one we want to have for the next 100 years. The internet in its current form has ruined a lot of the dream of personal computing because companies (and the state) are so asymmetrically powerful versus individuals. Should it be possible for my technology to send data to a server without my explicit approval? reply mavamaarten 2 hours agoparentprevExactly my thoughts. Interesting, but gross. I wonder why audio API's are even available without giving a website permission? It feels like this could easily be fixed with a simple \"This site would like to use your sound devices\"-dialog. reply gorgoiler 55 minutes agoparentprevI assumed a level of irony here, from fingerprint.com. It’s like if a website popped up popularising loopholes to get around tax burdens as an attempt to disgust the world into closing those loopholes. Even if that’s wishful thinking, there’s still immense virtue in publishing this research and getting it out in the open. If an article gets published explaining how a particular brand of green backpack helps with shoplifting do we worry that everyone’s going to shoplift more? I’d err more on the side of knowing shops are more likely to catch on to the tactic. reply FabHK 5 hours agoparentprevYeah. Can't believe these guys are proud of it! On the other hand, I did clear my browser cache and switched on the VPN, and they mis-identified me as a new visitor. Still, despicable business model. reply sshumaker 10 hours agoprevIt seems like rather than adding a random amount to each sample (which lets them compute a mean by recreating the same audio and extracting out the differences), Safari could instead add randomness that is based on a key that rotates every hour. (Function of audio sample and key, so the noise would be the same in a given session, but useless for tracking an hour later). reply Borealid 10 hours agoparentIf you averaged together ten such samples, you'd get something that approaches the true values from the device. The more samples you have, the closer it would get. Fixing this would require removing the information leak entirely, not just masking it under a layer of random deviations. reply tagCollector 5 hours agorootparentWeI’ll give him some oid @ reply exabrial 6 hours agoprevI'm really ready to just be \"that guy\" that browses with JS disabled. reply rgmerk 4 hours agoparentThe problem is that that by being \"that guy\" you're probably giving them 10 bits or more of identification. If they can just scrape a few more bits from somewhere they'll have you uniquely identified. But, yeah, these guys can get on Golgafrinchan Ark B with the rest of the adtech industry as far as I am concerned. reply DaSHacka 5 hours agoparentprevGood luck, I recently gave up that fight after needing to disable it to view the content of nearly every single website I visited. It's not even just cloudflare and similar DDOS checks, but now even things that should just be in the HTML of the page are loaded with JS. reply FabHK 5 hours agoparentprevGood luck. It's amazing how little of today's web is good old HTML. A while ago I visited a website that used Markup - but that wasn't compiled into HTML and then statically served, oh no - it was rendered in JS client side. WTF. reply chii 5 hours agoparentprevIt's exactly such reasons why TOR browsers would have JS disabled. As the internet gets more and more hostile, this will become more and more correct. reply modeless 13 hours agoprevPutting a node graph audio API in the browser was silly. It should have been just audio worklets. reply capitainenemo 13 hours agoparentWasn't Mozilla's proposed audio API simpler? AFAIK it was beaten out by Google's because people wanted a richer API and lower latencies. https://web.archive.org/web/20120505042746/https://developer... reply jsheard 9 hours agorootparentIIRC it turned out that way in large part because realtime audio is very sensitive to performance hitches, and idiomatic JS is hitchy by nature due to relying on garbage collection, so they wanted to hoist as much as possible up into native code provided by the browser. If WASM had existed at the time it would have been easier to make the case for just exposing a simple raw audio interface instead. reply capitainenemo 7 hours agorootparentWell... Mozilla had ASM.js at the time. In part to showcase their superior performance with certain portions of JS compared to V8 - at the time I remember the things like console emulators preferring Mozilla's JS engine due to it offering more reliable performance than V8 on the tight loops and large switches. Mozilla was also demonstrating how their engine could offer comparable performance to Google NaCl in an image processing demo which was conceived to show how NaCL could cover limitations in V8 at the time. I wonder if we might well have had more traction with Mozilla's approach and ASM.js if V8 had had similar features. Oh well. Is what it is, and Mozilla (and Microsoft and Apple) did at least manage to get WASM which has been super useful even outside of browsers. reply spookie 9 hours agorootparentprevDid people want lower latencies though? It seems a bit absurd given other compounding factors that have a play on that. reply docEdub 12 hours agoparentprevWhy's that? reply gary_0 13 hours agoprevDoes this technique fingerprint based on hardware/driver/OS differences with audio processing, or just the browser software? I believe there are (or were, hopefully) similar techniques usingthat exposed differences between the underlying graphics devices. reply dmazzoni 12 hours agoparentThis is similar. Audio algorithms often call OS functions and make use of CPU optimizations. One example they mentioned is the fast-fourier transform (FFT). All OS's include a version of that function but it tends to be optimized over time, and tends to behave differently on different CPUs depending on what SIMD instructions are available. reply demondemidi 3 hours agoprevI really don’t see how this can come up with more than a few thousand unique combinations. Browser type x browser version x os version x accelerator version x … what else? That doesn’t seem like enough variation to create anything remotely unique. I don’t get it. reply knodi 12 hours agoprevDoes disabling web audio beat this fingerprinting? reply arijun 11 hours agoparentI always assume that any difficult/annoying anti-fingerprint techniques make you more identifiable instead of less, since very few people do them. reply spookie 9 hours agorootparentThis is why the Tor Browser attempts its best to only have one fingerprint. The more people use it, the more this argument looses its edge. Or so they say. reply Einenlum 10 hours agorootparentprevThis. That's why I feel we are all doomed regarding privacy. The only way we could maybe protect ourselves would be to all send manipulated but looking like plausible average data. reply ryan-c 10 hours agoparentprevDisabling it would be weird and therefore make you more identifiable. reply tagCollector 5 hours agoprevM I’m reply Einenlum 10 hours agoprevI expected this article to be published by some hackers or defenders of privacy like EFF, not by a company whose goal is to fingerprint people. Such dystopian times. reply dannyw 5 hours agoprevI look forward to the day the EU makes fingerprinting illegal. reply wdr1 5 hours agoparentDefining fingerprinting in a legal terms is fairly difficult. Most regulators would also likely consider fingerprinting for certain use cases as acceptable. E.g., detecting abuse, fraud, CP, etc. reply balls187 13 hours agoprevFingerprint states that this service is for fraud detection, but they are actively discussing how they are circumventing browser privacy protections. So as a user my preference not to be fingerprinted or tracked takes a back seat in the name of fraud detection? So we should allow police to wiretap in the name of crime prevention? reply mostlysimilar 13 hours agoparentTale as old as time. Think of all of the legislative attacks on encryption in the name of protecting people. reply A4ET8a8uTh0 13 hours agorootparentMy charitable take is that it does take both ends of the spectrum to arrive at a solution that does not exactly satisfy everyone, but is an acceptable place to stop the impossible arms race. The unfortunate reality is that we are nowhere the end of that race. Admittedly, that was the first time I read about fingerprinting in this manner and bypassing explicit privacy protections is definitely not something I would want for my future self ( or that my of my family ). In other words, I think you are right. Privacy probably needs to be codified. It may seem hard to do given existing entrenched interests, but you have to start somewhere. Not that long ago people thought buying people is 'just the way world works'. Things can change. Slowly, but they do. reply kmlx 9 hours agoparentprev> So as a user my preference not to be fingerprinted or tracked takes a back seat in the name of fraud detection? the issue is murky for certain use cases. take payments for example. fingerprinting is used at scale in that field, and for good measure. you want to be able to know the risk associated with a user (chargebacks, fraud, etc). reply neilv 12 hours agoparentprev> they are actively discussing how they are circumventing browser privacy protections. I'd love to see a successful prosecution as something like a US CFAA violation, setting a precedent that puts the fear of god into the widespread slimy side of our field. But I suspect it will have to be a non-US country leading that, because a lot of the US economy and power is now tied up in widespread slimy behavior of our field. reply omnicognate 12 hours agoprevWhy am I supposed to want any website I visit to be able to render audio offline anyway? reply ninkendo 12 hours agoparentThere’s a push to make every single last thing a normal application can do, available to web apps through some half-standardized JavaScript API or another. Generally google comes up with use cases, implements it in chrome, and tries to call it a standard. Then everyone complains when Apple doesn’t implement these standards fast enough, and that Safari is “holding back the web” or “the new IE” because it’s not keeping up with every last feature Chrome implements. I would prefer websites just be websites and that we don’t have every single damned API available to whatever trashy site I accidentally click on, but I guess you and me are outliers here. Most people on HN seem to welcome every single JS API because web development is the only platform anyone seems to care about any more. reply jwells89 12 hours agorootparentThings like this seem niche enough to safely put behind a permission dialog. 99.9% of sites/web apps have no legitimate need for this functionality. reply ninkendo 12 hours agorootparentThat’s how location services and notifications work today, and all it means is that websites just constantly nag me to enable them. Things like this make for a more annoying web all around, because now it’s just one more tool sites can use to track me and increase engagement. (Edit: sibling poster chuckles said it way better than I can.) If I had my way, JavaScript on the web would be limited to XMLHttpRequest and basic DOM manipulation and couldn’t do anything else. A totally separate “rich” JavaScript engine could be opted into by the user for any website that presents itself as an “application” like ones that legitimately want audio API’s like these. All these half-baked web app “standards” that google is forcing down our throats can be confined to that leper colony. Then the most important bit: browsers could let me completely disable the “rich” engine, and I can go back to having a sane web experience again. reply latexr 12 hours agorootparent> That’s how location services and notifications work today, and all it means is that websites just constantly nag me to enable them. It also means you can tell the browser to outright deny every request, thus avoiding even getting prompted. If a website detects the request was denied and still prompts you any other way, that’s an undeniable signal to close the tab and never return. reply ninkendo 10 hours agorootparentRight, I think the fact that these features exist at all means sites are gonna ask for them… even if your browser denies it, the site can easily pop up a dialog saying “hey you should give us notification access!”. The result is that the web just keeps getting incrementally worse and worse. It’s all good intentions in creating these API’s but the result is that everything just gets more terrible. reply jwells89 12 hours agorootparentprevI’m kinda surprised that no fork of Firefox has added both global and domain-scoped toggles for web feature support. I know there’s flags in about:config but that only covers some things and isn’t very user friendly. That’d let users turn support for all the fancy bits off by default and enable them in the tiny handful of cases that they’re actually desired. This way as far as sites are concerned your browser simply doesn’t support those features and thus can’t nag you. reply shuckles 12 hours agorootparentprevPermissions dialogs solve for a problem product creators have and create more problems for users. reply mindslight 12 hours agorootparentprevWhen a surveillance company (in this case Google) is leading the push, security against surveillance isn't on their list of requirements. In fact it's more of an anti-requirement, which escapes human judgement via design by committee or other anti-scrutiny technique. So then we end up with yet another insecure API that we've got to suffer for years as the browser makers who actually care about security painstakingly figure out how to mitigate the vulnerabilities in the original standard. And I'm all for focusing on technical security, but it's worth mentioning that the biggest most concentrated win would be making commercial digital surveillance illegal (ie the path the GDPR tries to head in). Imagine if large public companies had to make their revenue by honest means instead of working as advanced persistent threats. reply dnissley 10 hours agorootparentprevI think fewer people would be in favor of this if apple just let you download native apps and run them on your iPhone like any other computing device. reply StressedDev 5 minutes agorootparentApple lets you run native apps on the iPhone. You get them through the App store. reply nox101 12 hours agoparentprevhttps://wavacity.com/ ? reply omnicognate 12 hours agorootparentAudacity's an awesome piece of software that I've used many times. Never once have I thought \"by golly this thing should be a website, and my web browser should be made to expose an audio graph API to every website I visit to that it can be so!\" reply nox101 9 hours agorootparentI'm the opposite. I think website = sanboxed, native = pownage so whenever I can use a website version I often prefer it over a native app. I use photopea all the time now. it's available on every machine, even machines I don't have permission to install software on reply spookie 9 hours agorootparentYou can sandbox native apps too. Hell, even run them in an airgapped virtual machine. I wouldn't trust a browser sandbox all that much given the high interest in subverting it. reply dannyw 5 hours agorootparentWhat’s an easy way to sandbox apps on Windows? Sorry, I’d prefer to stick with my operating system, not install QubesOS. reply goodSteveramos 12 hours agorootparentprevGet with the times. Your privacy must be sacrificed so some random web app you have never heard of can do something no website should be able to do at all. Or maybe that’s just a pretense and not the real reason Google keeps adding all these APIs. People seem to forget that ChromeOS is literally Google trying to turn every computer into a thin client for their services. reply jauntywundrkind 12 hours agorootparentprevWe'll make sure we stop building software you could imagine then. /s There's value here. Other people are allowed to want more than you want. reply spookie 9 hours agoprevThese predatory practices are getting out of hand. Props for them to expose this, even though they're the \"bad actors\" from my point of view. reply sph 1 hour agoparentThey're not exposing anything, they're advertising their services. It was also posted by one of their employees. Funny how no one seems to notice that, and they're all praising the article. reply stockhorn 13 hours agoprevDid I read this correctly and audio fingerprinting is mainly about identifiying the used browser version and OS or laptop, but it cant identify end-users in a stable way? reply dmazzoni 12 hours agoparentYeah, it doesn't tell a website who you are. Instead, it allows them to recognize you again when you come back to visit again, even if you clear cookies. This is particularly a problem with big advertiser networks because they can track you across many sites you visit, even if you disable third-party cookies. It has positive uses too, like preventing click fraud and concert ticket arbitrage. reply Thorrez 10 hours agorootparent>Instead, it allows them to recognize you again when you come back to visit again, even if you clear cookies. I don't think that's what stockhorn said. stockhorn said it can only identify a what browser and OS and laptop model you're using. Someone else with the same browser, OS, and laptop model would have the same fingerprint. So audio fingerprinting couldn't precisely recognize you again when you come back again. reply kmlx 9 hours agorootparent> Someone else with the same browser, OS, and laptop model would have the same fingerprint. the collision rate of their ids is stated to be 0.05% what they do is basically collect a lot of signals from the browser (audio processing stuff being only a part of it) and then compute an id on the server. reply azmodeus 10 hours agorootparentprevBrowser, OS, laptop joined with IP looks like a pretty good ID reply ryan-c 10 hours agorootparentIP is a pretty good ID... reply fragmede 8 hours agorootparentNAT really. reply sgerenser 7 hours agorootparentI see what you did there… reply azinman2 9 hours agorootparentprevNot if you’re behind something NAT’d, which is especially true on mobile. reply spookie 9 hours agorootparentprevStill, parent does state a pretty big concern when looking at this from a higher vantage point. These practices and their repercussions aren't self contained. reply mikepavone 13 hours agoparentprevMy phone running Firefox for Android produced the same results as the sample data for Firefox on Windows which does seem to fit with this largely being a browser identification scheme reply fbdab103 13 hours agoparentprevI think that is correct, but it still seems like an amount of leakage that could be further correlated with other another trick. There was previously a site which could indicate how globally unique your environment was (some combination of screen size, user-agent, fonts?, etc). Locking down to a specific hardware+browser configuration probably does a lot to remove anonymity. reply Crespyl 12 hours agorootparentYou may be thinking of https://www.amiunique.org/fingerprint reply fbdab103 12 hours agorootparentNot the one I used, but this one actually looks better. Just being Linux + Firefox is terrible for blending into the herd. Let alone everything else that leaks (having a desktop + GPU + good monitor basically destroys all remaining hope). reply lloeki 11 hours agorootparentProbably was EFF's panopticlick, which has evolved into https://coveryourtracks.eff.org The about page has some history https://coveryourtracks.eff.org/about reply tagCollector 5 hours agorootparentprevM You o No you you. And look like !9? Cam mm.@l lnl l. Pm Wilder8@was was I’m It reply brookst 13 hours agoprevTl;dr: Apple’s implementation adds random, uniformly distributed noise, so running many samples one can back out the noise. Kind of a naive design but easily fixed. reply neilv 12 hours agoprev> Fingerprinting is used to identify bad actors when they want to remain anonymous. For example, when they want to sign in to your account or use stolen credit card credentials. Fingerprinting can identify repeat bad actors, allowing you to prevent them from committing fraud. However, many people see it as a privacy violation and therefore don’t like it. This doesn't seem to acknowledge the use of fingerprinting in intentional violation of the privacy of ordinary people, for marketing profiling and just selling them out because someone is willing to pay. On https://demo.fingerprint.com/ , they do start to hint at non-anti-fraud purposes, but the use case seems to be full of poo. (Logins or cookies are the way to do this. Anything else is trying to circumvent privacy mechanisms. And if they don't distinguish users perfectly, they're doubly violating privacy by then leaking private information between people.) > Personalization -- Improve user experience and boost sales by personalizing your website with Fingerprint device intelligence. Provide your visitors with their search history, interface customization, or a persistent shopping cart without having to rely on cookies or logins. Popup warning on \"https://demo.fingerprint.com/personalization\": > Heads up! -- Fingerprint Pro technology cannot be used to circumvent GDPR and other regulations and must fully comply with the laws in the jurisdiction. You should not implement personalization elements across incognito mode and normal mode because it violates the users expectations and will lead to a bad experience. -- This technical demo only uses incognito mode to demonstrate cookie expiration for non-technical folks. Sounds a bit like a disingenuous bad actor doing CYA while demonstrating their capabilities, nudge, nudge, wink, wink. reply austinpena 12 hours agoparentTheir tool is priced too expensive to be used for marketing purposes in most cases. reply pdntspa 13 hours agoprevThe author's casual dismissal of privacy concerns for activating your microphone, for a method that they admit lacks accuracy, is concerning if not offensive. reply travisd 13 hours agoparentBased on the article, it sounds like this doesn't activate a device's microphone at all. If it did, most (all?) browsers would give a pop-up requesting permission for that. reply marcellus23 13 hours agoparentprevThis has nothing to do with the microphone... reply pdntspa 12 hours agorootparentThen where are these audio samples coming from? reply SloopJon 12 hours agorootparentFrom the article: \"In a nutshell, audio fingerprinting uses the browser’s Audio API to render an audio signal with OfflineAudioContext interface.\" It links to a previous article with more details: https://fingerprint.com/blog/audio-fingerprinting/ Here's an example from that article of a sound source: const oscillator = context.createOscillator() oscillator.type = \"triangle\" oscillator.frequency.value = 1000 reply tempodox 12 hours agorootparentprevThe browser's Audio API. https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_A... reply echoangle 12 hours agorootparentprevThis is using differences in the audio processing pipeline of the browser, they just use some input sound which could be taken from a file. The fingerprint is the slightly different output signal when applying filters to the input signal. reply pdntspa 12 hours agorootparentHow is it possible that this produces enough variations to be usable without sampling some sort of audio source? The entire pipeline is digital, there is not any room for interference. reply saurik 12 hours agorootparentPlease stop wasting everyone's time with your random assumptions as to why this does or doesn't work and just click on the link in the article to the detailed explanation of exactly how this works. > The technique is called audio fingerprinting, and you can learn how it works in our [previous article]. https://fingerprint.com/blog/audio-fingerprinting/ reply echoangle 12 hours agorootparentprevIt’s doing signal processing using floats, that can lead to differences in the result even if the implemented algorithm is identical. Float addition is not commutative so reordering some calculations, either in different implementations or with different compiler options, can lead to slightly different results. This just detects browser version and maybe OS/Architecture, the same browser binary should still give the same results between different devices with same hardware. reply rpdillon 12 hours agorootparentprevIt's about variations in the implementation of the digital pipeline that are traceable to the output. It has nothing to do with analog processing or interference. reply dmazzoni 12 hours agorootparentprevThey just generate a sine wave and do some processing on it. The results are very similar but because the processing depends on functions like fast fourier transform, plus the exact algorithm in the browser code, tiny differences emerge. reply Saris 12 hours agoparentprevI missed where the microphone is used, it looks like it's only using the output pipeline? reply diebeforei485 12 hours agoprevBut all iPhones of the same model have the same processor. Every iPhone 15 Pro Max, of which Apple sells hundreds of millions, all have the same processor. Why do they have different results? reply om2 10 hours agoparentThey don’t. If you read this post carefully, it just claims to be able to tell Intel Macs from ARM Macs. It can also distinguish from older Safari versions that don’t have the fingerprinting protection. reply astrange 8 hours agoparentprevThey have different performance at different heat and battery levels. reply saagarjha 6 hours agorootparent(This would of course require a different technique to uncover.) reply lotsofpulp 10 hours agoparentprev> Every iPhone 15 Pro Max, of which Apple sells hundreds of millions They sell ~200M iPhones per year, but I doubt most are the most expensive model. reply Asmod4n 11 hours agoparentprevBuy the same CPU 10 times and benchmark them, they all score differently. reply FragmentShader 10 hours agoprev [–] I think web browsers should implement already an API that allows developers to track any user in a \"private\" way, by generating a unique hash using your computer specs or something, and make it different for each website. So, if you visit Google, your hash would be something like \"h38kflak\". If you're visiting twitter, the API would generate something different, so you won't be tracked across websites. That way, even if you clean your cookies, you can still be identified as the same user. The use case? Fraud detection and that kinda stuff. For example, you may create a web game where you allow users to play instantly without \"creating\" an account. So, an anonymous account would be created in the background, in order to log in. Any bad actor can just clear their cookies/storage to bypass a ban. IP banning isn't reliable, as multiple users may share an adress. It's a shame that we have to rely on web api hacks in order to fingerprint users for legitimate reasons, and that ends up in an eternal cat and mouse game, because anything you try today may be broken tomorrow. reply 14 9 hours agoparent [–] Because users do not want to be tracked or fingerprinted. I don't care about fraud detection and I am not a fraudster so why do I have to be tracked? There is no way that a feature like that would not get abused in one way or the other. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple implemented enhanced fingerprinting protection in Safari 17 to counter audio fingerprinting by incorporating random noise in audio samples for accuracy reduction.",
      "The article explores optimizing an audio fingerprinting algorithm, efficiently creating multiple noised samples, and developing a novel algorithm for stability and uniqueness.",
      "Safari and Brave approach audio fingerprinting differently, with Safari employing noise and Brave introducing unique noise, while FingerprintJS works on boosting browser fingerprint precision by accentuating differences in audio fingerprints."
    ],
    "commentSummary": [
      "The focus is on bypassing Safari 17's audio fingerprinting protection using techniques like GPU fingerprinting, raising concerns about privacy, power usage, and effectiveness.",
      "Discussions highlight web tracking strategies, privacy breaches, and ethical dilemmas related to fingerprinting, proposing solutions for online tracking problems, fraud prevention, browser safety, and finding a balance between user security and privacy.",
      "The dialogue also explores the complexities of web performance enhancement, utilizing distinctive hash codes for tracking, and managing the trade-off between user identification and privacy considerations."
    ],
    "points": 183,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1710006863
  },
  {
    "id": 39653517,
    "title": "Unlocking the Power of Focus: Insights from Monks",
    "originLink": "https://www.millersbookreview.com/p/jamie-kreiner-how-to-focus",
    "originBody": "Share this post What Monks Know about Focus www.millersbookreview.com Copy link Facebook Email Note Other Discover more from MILLER’S BOOK REVIEW 📚 Classics, Memoir, History, More Over 4,000 subscribers Subscribe Continue reading Sign in What Monks Know about Focus It’s Never Been Easy to Battle Distraction. Reviewing Jamie Kreiner’s New Translation of John Cassian in ‘How to Focus’ Joel J Miller Mar 9, 2024 60 Share this post What Monks Know about Focus www.millersbookreview.com Copy link Facebook Email Note Other 9 Share Books are a waste of time. So says Richard Hanania in “The Case Against (Most) Books.” He allows that books of historical interest and those by contemporary thought leaders might be valuable, but the vast majority of everything else on the shelf is worthless, especially old books. That’s correct: The classics are garbage. I’ve addressed Hanania’s argument before but return now to note that the best rebuttal are the classics themselves. To that end I offer you How to Focus: A Monastic Guide for an Age of Distraction, which serves up several choice selections from John Cassian’s fifth-century monastic guide, the Conferences, as edited and translated by Jamie Kreiner. John Cassian, How to Focus: A Monastic Guide for an Age of Distraction, translated by Jamie Kreiner (Princeton University Press, 2024). The subject of monks struggling to maintain focus represents familiar ground for Kreiner, a professor of history at the University of Georgia. Last year I reviewed her book, The Wandering Mind: What Medieval Monks Tell Us about Distraction. In that book, Kreiner explores the monastic enterprise from late antiquity through the Middle Ages across Europe and the Near East to see how monks managed intense concentration while battling interruptions and distractions. In contrast, with How to Focus she narrows the scope to just one remarkable text, refreshed for modern readers. Ask the Desert Cassian wrote his Conferences as an older man looking back to a period of youthful experimentation and adventure. In his twenties, he and his friend Germanus joined a monastery in Bethlehem. The two became fast friends, “inseparable bunkmates,” of such shared intensity and interest “everyone remarked on the equality of our companionship and our sense of purpose. They said that we were one mind and soul in two bodies.” The pair wanted to know all the ins and outs of their discipline and decided to travel beyond their local confines to hear from reputed monastic masters. So, for the next decade and a half they traveled the Nile Delta, interviewing the men known as the Desert Fathers, those in monasteries as well as hermits living on their own. They asked a million questions. The final word count of Cassian’s Conferences stands at 150,000 words, a remarkably large book for the time. How to Focus, as Kreiner notes, represents less than 10 percent of that total with her selections geared toward, as the title suggests, the conversations dealing with attention and distraction. And just what would monks know about that? Minds Always Moving We’re so attuned to our own crises and challenges, we tend to think of them as purely contemporary concerns—especially when we externalize our difficulties and blame our tools, the times, and the like. Desert monastics didn’t have Instagram; ergo, they didn’t have attentional problems. Au contraire. While technology has evolved in the last fifteen hundred years, the human brain has not. And few people in the ancient world cared as much about the challenges of attention and distraction as monks. Our reasons might differ today, but we have much to learn nonetheless. “Father, give us a word.” Men visiting monastic pioneer Anthony the Great in the desert. Illumination from Armenian manuscript by the monk Tadeos Awramenc. A repeated complaint from Cassian and Germanus is the difficulty maintaining focus on their prayers. “The mind is always moving and meandering, and it’s torn apart in different directions like it’s drunk,” says Germanus at one point. “It doesn’t even have the power to hold onto or stick with things it finds entertaining!” Unfortunately, knowing focus matters fails to engender concentration. “What we know hasn’t helped us attain the steady and stable clarity we’ve been seeking,” he says. “Even when we feel our heart heading straight toward its goals, the mind imperceptibly turns the other way. . . .” Germanus directed this second comment to Abba Serenus of Scetis, who responded, “The nous or mind is defined as aeikinētos kai polykinētos, always and very much on the move.” You might recognize our word kinetic in the Greek. This bubbling, jumping, flitting mind can only be tamed by training through meditation, memorization, fasting, and other forms of ascetical effort by which “it will become strong enough to drive off the enemy’s stimuli. . . .” It’s a bit of a relief to realize, no? Why does the mind meander? Because that’s what minds do. Thinking about Thinking Monks attempted the radical and difficult practice of pure prayer, to bring their entire mind to bear on the act. Given their intense interest in concentration, and also being prone to endless disruptions in the effort, monks became experts in what we today call metacognition—thinking about thinking. “It is impossible for the human mind to empty itself of all thoughts,” says Abba Nestorus, a hermit interviewed by Cassian and Germanus. The question is what kind of thoughts to entertain? Nestorus advises the pair to immerse themselves in sacred reading. “Do it continually—or better, nonstop!—until that constant recitation and reflection saturates your mind and shapes it into a kind of likeness of itself.” Nestorus offers three reasons, the third the most profound. First, when a person is engrossed in literature, the mind can stay attuned to its content instead of “toxic thoughts.” Second, an understanding of the text comes not only while reading, but also when we take those thoughts with us into other mental states. We’re able to reflect on what we’ve read when we’ve turned out attentions elsewhere, even when we go to sleep. Another interviewee, Abba Isaac, also talks about this tricky feature of mental latency, though regarding prayer, not reading. “We should,” he says, “be the sort of person we are in prayer before it’s time to pray. After all, our state of mind during prayer is unavoidably shaped by the situation prior to the moment.” Attention researcher Gloria Mark—a modern scientist, not a monastic—would affirm Isaac’s point. When we approach any task, as Mark notes in her book, Attention Span, we do so by constructing cognitive frames that marshal the various mental resources required for the activity. When distractions occur, we change frames mid-action. The frustration we feel in getting back on task involves the difficulty in reassembling the cognitive frame we enjoyed prior to the interruption. Since our mental states persist from one moment to the next, Isaac encourages Cassian and Germanus to hold onto their desired state by preparing for it in advance. It’s a way of ensuring our cognitive frame is strong enough to resist distraction and an approach that applies to a wide variety of intellectual activities. I mentioned three reasons from Nestorus for immersive reading but have so far only covered two. What of the third and most mysterious of his reasons? “Scenes from the Lives of the Desert Fathers” (as busy as a monk’s mind), painting by Fra Angelico. Changing Our Minds Nestorus’s third and most mysterious reason for immersive reading is that sustained engagement deepens our understanding of what we read by the changes wrought in ourselves through the very process of reading. “How the scriptures look depends on what the human senses are capable of,” he says. “As our mind is gradually remade through this sustained effort, the shape of the scriptures begins to be remade, too, and it’s as if the beauty born of this more sacred perceptiveness grows as we grow.” Our investment in reading changes the book because the book has changed us. And this is where Hanania’s argument fundamentally falls short. If books are merely a means of transferring information, then perhaps, yes, a book is a waste of time. If a summary of its thesis and key points could be presented in a brief article or Substack post, why not just save the hours and read the Substack post? All the more if the information is outdated or questionable for one reason or another. But that mistakes what a book is for. A book is a tool. It’s a machine for thinking. And “all machines,” as Thoreau once said, “have their friction.” The time it takes to engage with ideas—whether factual or fictional, emotional or intellectual, accurate or inaccurate, efficient or inefficient—might strike some as a drag. But the time given to working through those ideas, adopting and adapting, developing or discarding, changes our minds, changes us. It’s not about the wisdom we glean. It’s about what wisdom we grow. What about that more basic plane upon which we engage a book, the information itself? After all, if the book is ancient, is the information even useful? Can the ideas shared in distant philosophical or spiritual contexts translate with any value to our present, secular world? Though the answer depends entirely on the ends to which we put the information, Cassian’s book offers us an answer here as well. The Goal of Reading In the first chapter of the Conferences, Cassian and Germanus visit Abba Moses of Scetis, known to the faithful as St. Moses the Black or St. Moses the Ethiopian, whom they regard as “the sweetest of all those extraordinary flowers” in the desert. They ply Moses with the same sorts of questions they later asked of other fathers: Why is the monastic life so difficult? Curiously, Moses addresses their pleas by talking about short- and long-term goals. Abba Moses. Fundación La Buena Noticia. “Every acquired skill and every discipline,” says Moses, “has a scopos and a telos, some immediate goal and some ultimate goal that is particular to it. Practitioners of any skilled craft will gladly and good-naturedly work through all their fatigue and risks and costs as they keep those goals in mind.” Moses develops the idea from there and, as someone who professionally spends a lot of time reading modern goal-achievement literature, I can say that his treatment is every bit as useful as the work of scholars working today. Moses’s argument can even help resolve the question of whether we should read the classics. If you’re Richard Hanania, no. You don’t possess a telos that would justify the effort. But if you see classics such as John Cassian’s Conferences as valuable, then most definitely yes. And Jamie Kreiner’s presentation in How to Focus represents the perfect scopos. Pick it up and enjoy the thoughts it helps you conjure. Thanks for reading! If you enjoyed this post, please hit the ❤ below and share it with your friends. Share Not a subscriber? Take a moment and sign up. It’s free for now, and I’ll send you my top-fifteen quotes about books and reading. Thanks again! Subscribe Make sure you also read . . . ‘Lead Us Not into Distraction’ Joel J Miller · May 27, 2023 Read full story Dear Abbot: Monastic Advice for Modern Living Joel J Miller · October 8, 2022 Read full story 60 Share this post What Monks Know about Focus www.millersbookreview.com Copy link Facebook Email Note Other 9 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=39653517",
    "commentBody": "What Monks Know about Focus (millersbookreview.com)182 points by ingve 15 hours agohidepastfavorite51 comments fernly 4 hours agoAll those words about focus, concentration, taming the wandering mind -- and never even a passing reference to Buddhism, whose central practice is exactly that. Certainly a Christian hermetic deals with the same problems as does a Buddhist monk, but I note one profound difference in their approaches. The Christian faces a dualistic world, and trains the mind to, as the article quotes one monk saying, \"become strong enough to drive off the enemy’s stimuli.” The \"enemy\" being Satan, trying to divert the faithful. The Buddhist does not see the world as divided between warring good and evil influences, but rather views the wandering mind non-judgementally, as needing only constant gentle correction. reply tdudhhu 15 minutes agoparentWell it's a book review about a specific book. So I don't see why bringing in Buddhism would be relevant in this case. But related to this: the oldest Bible books are older than Buddhism. And they also contain references to meditation. So it is seems that meditation was already very common in the very old ages. reply korginator 11 minutes agorootparentThe topic is on what monks know about focus, so I'd say that any relevant monastic practices are relevant to the discussion, that includes Buddhist monks' practices on focus and mindfulness. As to the second point - the Bible is older than Buddhism? What now?!? I'm surely in a different universe. reply tdudhhu 1 minute agorootparentThe Bible is obviously not older than Buddhism but some texts are. And they contain references to meditation. Maybe the author could have used Buddhism as reference, but wouldn't he than have to reference Hinduism too? I mean: it seems the focus of the author was a book review. reply cammil 25 minutes agoparentprevI suspect the reason is because Buddhism is lumped in with the other major world religions, and therefore considered a form of faith or belief. If the author knew Buddhism well then they would realise that couldn't be further from the truth. Another possibility has occurred to me: they know Buddhism but don't want to scare away readers that have the above misconception. Actually I often find myself avoiding Buddhist terminology when I'm asked about my meditation practices. reply korginator 30 minutes agoparentprevIn a discussion about what monks know about focus, I too find it strange that other schools and practices are ignored. The core of the Buddhist practice is about cultivating the mind for insight and clarity. In the linked article, I find the reasons offered by Nestorus to engage in reading rather specious and elementary, hardly scratching the surface of a vast and well practised domain. His first point - that reading helps avoid toxic thoughts - is avoiding instead of getting to the root of the problem and fixing it. His third and \"most mysterious\" reason for immersive reading - that it deepens our understanding of the reading material because our minds are changing - is how education works in the first place. The basic Buddhist teachings and practices even for lay people cover this vast domain concisely, with clear prescriptions to practice and try it out for ourselves, iterate and progress. In fact, the very first of the seven factors of awakening that we're advised to cultivate is mindfulness which underlies everything else. This commentary [1] provides an overview. The practices are covered in more detail in one of the core teachings, MN10 - Satipatthana Sutta [2]. While reading/listening/remembering are valued as aids (it's called suta-mayā pañña - knowledge based on learning), pretty much every Buddhist monk and practising upāsaka / upāsika (layperson) are taught to practice the techniques and realise this clarity, focus, mindfulness, etc., for themselves. The instruction mentioned above - MN10 - instructs you on attention and mindfulness wherever you are and whatever you're doing, in the section on clear comprehension - you're cultivating the skill (bhāvana) where you're clear about what you're doing, why you're doing it, the consequences of your actions, etc., whether you're defecating, urinating, reading, lying down to sleep, whatever - a constant practice of mindfulness and a full-time job. [1] https://www.accesstoinsight.org/lib/authors/piyadassi/wheel0... [2] https://www.accesstoinsight.org/lib/authors/soma/wayof.html reply gloryjulio 3 hours agoparentprevThere are mythic branches of the Christianities. In fact, most of the religions have mythic branches and the ideas about these topics on self are strikingly similar and convergent. On the other direction, Buddhism is not so 'spiritual directed' in the prescientific history. The difference is just that Buddhism is very malleable. People can easily pick and choose the text and practices and even treat it as non religion. You can easily practice Buddhism in the modern context without the baggage. reply Lyngbakr 1 hour agorootparent> You can easily practice Buddhism in the modern context without the baggage. An excellent book on this exact topic is Buddhism Without Beliefs by Stephen Batchelor[0]. Very readable & super short. Recommended! [0]https://www.amazon.com/Buddhism-Without-Beliefs-Contemporary... reply doc56 13 hours agoprevA superb writeup. Thanks for posting. Reminded me of Herbert Simon saying Learning required \"Drill and Kill\". And how our education systems were tending more towards entertainment by undervaluing rote or practice. Had to dig up the quote - \"The criticism of practice (called \"drill and kill,\" as if this phrase constituted empirical evaluation) is prominent in constructivist writings. Nothing flies more in the face of the last 20 years of research than the assertion that practice is bad. All evidence, from the laboratory and from extensive case studies of professionals, indicates that real competence only comes with extensive practice... In denying the critical role of practice one is denying children the very thing they need to achieve real competence. The instructional task is not to \"kill\" motivation by demanding drill, but to find tasks that provide practice while at the same time sustaining interest.\" reply creer 6 hours agoparentThat would be very useful but I don't think the current style of school practice is doing it. \"Sustaining interest\" is missing. Both the textbook or class are abstract (they have enough trouble describing a math concept and don't spend much or any time showing where that concept is headed for example - what it will later be useful for). And the exercises are narrow: they make no reference to real world problems. Granted that created exercises grounded in real world problems is far more time consuming than isolated questions. Would still be more useful. reply iainctduncan 11 hours agoprevThe linked article on the value of old books is a really nice read too. Great writing. https://www.millersbookreview.com/p/vital-necessity-of-very-... reply dandanua 12 hours agoprevFocusing on solving hard problems, like in programming, is a good option too. Because when we solve something we keep our minds in motion on fixed tracks. reply quickthrower2 12 hours agoparentExercise too. The question is how long. Doing intense stuff needs breaks. reply twelfthnight 11 hours agoprevArticle sets itself up a rebuttal against another post. The other post argues you shouldn't read books because they are too long and mostly filler. This article then suggests the classics themselves are a demonstration that disproves that anti book sentiment. Personally, I disagree with both points of view, I think reading books is valuable, but I don't think \"the classics\" are a good argument why. For me, reading is good because it is _both_ enjoyable and informative. The antibook argument suggests you read the most information dense material you can, but like, that's not going to stick because it's boring and minds work on narrative / spaced repetition. Likewise, many folks find the classics boring, so they aren't a good example of why reading is good either. The best argument for why reading books is good is to help someone find a book they like! Once you get started reading, you'll likely do more of it and learn a lot more than (a) just reading blogs and (b) trudging through classics that aren't appealing to you (although there are very like classics you will like) reply carlossouza 12 hours agoprev> But that mistakes what a book is for. A book is a tool. It’s a machine for thinking. Best quote in the article. Taking the time to read, absorb and apply a book changes us in a way no summary or audiobook could ever change. reply dbtc 31 minutes agoparentI disagree somewhat - a book can also be (or at least contain) a work of art; a consciousness-altering, mind-expanding, experience-inducing thing. reply makeitdouble 8 hours agoparentprevI wasn't expect a \"audiobooks aren't real books\" argument coming in. What's your beef against \"reading\" in audio format ? reply serial_dev 7 hours agorootparentWhile I'm certainly not making the argument that \"audiobooks aren't real books\" (and I think nobody did), it's naive to think that audiobooks are in every way the same or better than reading it yourself, in the end it's always about different trade offs. Listening to audiobooks is reading the book in someone else's pace. Reading the book on your own, you are reading at your own pace. You can look up from your book and reflect on what you read, think about how this new information explains things you observed in the past, think about how it could be used in the future. You didn't get something, you just read it again. You realized you didn't get things in the last two pages, you just go back two pages. A sentence is so deep, you need to walk around and think about things for ten minutes? You just stand up and do it. (I know you can do the same with audiobooks but it's more inconvenient) Listening to an audiobook and following someone else's pace also has its advantages (remember different tradeoffs), for example if you are easily distracted, the audiobook continuously playing can help you refocus and read through the book faster, not to mention being able to \"read\" while in motion, driving, cycling, working out. reply furyofantares 5 hours agorootparent> I know you can do the same with audiobooks but it's more inconvenient I don't find it inconvenient. I also don't follow the logic about it being someone else's pace. I pick playback speed depending on both the content and the performance. reply macintux 5 hours agorootparentPerhaps it's a question of learning style, or listening style, but with a printed book I can change the pace in the middle of a sentence, heck, the middle of a word, based on how distracted I am, how much I understand the context, etc. With an audiobook I'm constantly missing something because I'm thinking through what I've just heard. reply cinntaile 1 hour agorootparentRewind to where you lost track. Several times if necessary. reply makeitdouble 4 hours agorootparentprevI think it boils down to a matter of preference and personal covenience. While I get you're more comfortable with books, that would be the same argument against them for people with poor vision or high eye strain, don't want a physical object nor stare at a screen etc. It's sometimes interesting to be listening to a podcast for litteraly days worth of time, and then be offered that same content in an edited book form. I wouldn't believe someone telling me I need to read the book to have the deeper understanding of the subject. IMHO books as a support aren't magical and ideas can be communicated in better ways depending on the recepient. I feel this gets lost in many \"people should be reading\" discussions. reply bdjsiqoocwk 7 hours agorootparentprevHe's not saying they're not real books, he's saying they have a different effect. reply makeitdouble 2 hours agorootparentI saw that as a point worth digging into. If we push it to the deep end, reading a printout of an archived book or the version that has been past down in the family and is the last physical reminder of grandpa who we never saw alive won't have the same effect. But we're not talking about content or ideas anymore. reply pluc 6 hours agorootparentprevReading vs hearing is akin to tasting vs smelling. The signal reaches the brain but the path it takes is different. reply dbtc 27 minutes agorootparentI disagree somewhat. I really like audiobooks, but they actually bypass a huge amount of the creative effort that is required when reading a book. I'm still imagining scenes and settings, but no longer the voices. reply ilrwbwrkhv 10 hours agoparentprevAbsolutely. That's why people who use blinkist and stuff are doing it wrong. For a book to be useful it needs to work on you, you have to let yourself marinate in it. The time spent is in itself the biggest part of a book being useful. Just plucking the main ideas by themselves into bullet points do nothing. reply evross 2 hours agorootparentBlinkist and skimming a book have their place for getting some of the key points, it's hard to find the time to read all useful books. But I agree that to really get the most out of a book, reading cover to cover is likely most immersive, impactful, maybe followed by listening to the auduibook from start to finish. reply cyberpunk 11 hours agoprevnext [9 more] [flagged] scooke 11 hours agoparentLike twelfthnight above, I think a major point you miss is: not to do this _for_ something, but that in doing it you will experience a transformative effect. Or, reading, or meditating, is a worthy activity because in doing so the opportunity for insight and transformation increases; _not_ that this transformation is guaranteed or formulaic. I think it differs from staring or focusing on a blank wall in that one populates or fertilizes what is already there, for it to be understood or comprehended beyond it's surface application; these percolate until a mental/ emotional coffee is ready to drink! A blank wall draws on... blankness, which is, as I understand, a goal for Buddhist meditation - to empty ones mind of any fertilizer or coffee grains of thought. Different goals. reply cyberpunk 11 hours agorootparentI can’t even begin to explain Zen Buddhism in response to such a comment; even if I could what would be the point? We aren’t recruiting… however as some kind of answer — what I’m about is shikantaza as prescribed by dōgen, and there is absolutely no fucking goal, as mad as that sounds… reply CrzyLngPwd 11 hours agoparentprevTen years is a long time to repeat the same mistake. I hope you now spend your hour a day with no expectations, and I also hope you spend it outside of the cult of achy legs and standing in nature instead. reply cyberpunk 11 hours agorootparentHaha, I loved this. Thanks :) reply VelesDude 11 hours agoparentprevThere are some folks now pushing the idea of wall meditation. Literally just grab a chair, take 10 minutes at first to just stare at a wall. See where the mind goes. I like the idea in its simplicity to define. Chair + wall + time. But eventually in many meditative traditions like Buddhism, a little context can be allocated as needed. reply carrolldunham 11 hours agoparentprevI thought you had rules against indulging in mindless entertainments (social media (hn)) and fraternizing with laypeople? reply cyberpunk 11 hours agorootparentEh? I’m not sure who the you you are referring to is but it sure doesn’t sound like me… we have no such thing.. I am a layperson… reply virtualwhys 10 hours agorootparent> However as an ordained Buddhist monk... Then perhaps you meant to say you've taken the precepts, as ordaining and a layperson taking the precepts are obviously entirely different levels of commitment. reply mellutussa 12 hours agoprevnext [4 more] [flagged] angel- 12 hours agoparentI think you might be misunderstanding the statement. He's summarizing what Richard Hannia is saying, not the author's opinion. He's actually against the idea that old books are worthless. reply mellutussa 12 hours agorootparentHe sums it up and then he confirms it. But yes, he might have missed out a word. reply Dr_Birdbrain 12 hours agoparentprevRead paragraph 2: the best counter argument is the classics themselves. reply mewpmewp2 14 hours agoprevThe suggestion is to escape from toxic thoughts, immersing yourself in prayers instead? reply duncan-donuts 14 hours agoparent> It’s not about the wisdom we glean. It’s about what wisdom we grow. I think the author does a good job of actually testing the original point—questioning if all but a handful of books are a worthless distraction. I think the entire piece has almost nothing to do with prayer. The monks are used as a thought experiment around the value of thought for the sake of thought. reply mewpmewp2 10 hours agorootparentOkay, I guess I misunderstood the article. What is the takeaway? reply theptip 9 hours agorootparentSpending time and energy to engage in reading a book can change the way you think, and subsequently change your interpretation of the text. A good book is not just a bag of facts, but a tool to change your cognitive processes. reply coldtea 9 hours agorootparentprev>What is the takeaway? That we should not take shortcuts and expect we'll gain anything by exchanging an extended treatment of a subject with a distilled short talking point. reply jamiek88 1 hour agorootparentBravo! reply scooke 11 hours agoparentprevMost likely these were set prayer phrases, like recitations of the Psalms, and not a meandering, \"Dear God/Santa, here is my Christmas list and help my dog and heal granny\" kind of prayers. So the content is already set to lead ones focus to \"heavenly\" thoughts above the toxicity of the worldly plane. reply devjab 9 hours agoparentprevI think the easiest way to think of it is having a single word mantra that you repeat while you meditate to keep your focus on meditation and not let your mind wander in different directions. If you try the single word mantra thing you’ll probably find that it’s not exactly enough to keep your focus. But it’s an easy way to explain that it’s less like “praying” than about the recitation of the prayer because focusing your mind on the recitation will help you focus. reply makeitdouble 8 hours agoprev [–] It's worth pointing out that it's an article from a book reviewer, arguing based on a classical book about monks (who spend their life basically reading and copying books) that reading is really great all around. There might be a kernel of truth in there, but there's a very clear lack of distance between the subject and the author, and the writing style exacerbates this point. I feel it's the very definition of preaching to his choir, with little to no light coming from a different side with at least some ressemblance of neutrality towards the subject. Arguably reading people's rambly praises about their passion can be nice, but there's a weird grandiose tone here that hurts the enjoyment. reply bdjsiqoocwk 7 hours agoparent [–] What would \"neutrality\" look like in this case? Should this person start their discussion from \"should we read? It's 50-50 we don't know\"? reply makeitdouble 5 hours agorootparentNeutrality would look like putting upfront that some people enjoy reading and others don't as much, and we should be ok with it. He can then dig all he want about how reading is great to him and his peers. This is not a post in a vacuum, he is answering a specific argument made elsewhere, yet dwelves in his bubble until basically the last few paragraphs to throw some plausible deniability in the end: > If you’re Richard Hanania, no. You don’t possess a telos that would justify the effort. But if you see classics such as John Cassian’s Conferences as valuable, then most definitely yes. Perhaps I'm just frustrated to have read the whole thing expecting something more. reply barbazoo 7 hours agorootparentprev [–] Jury is still out. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article emphasizes the significance of focus and concentration, drawing from historical examples of monks facing distractions in their routines.",
      "It underscores the transformative power of immersive reading, suggesting that interacting with books can influence our thoughts and viewpoints.",
      "Reflecting on the advantages of exploring classic and ancient texts, the author urges readers to cherish the enlightenment and personal development gained from such engagements."
    ],
    "commentSummary": [
      "The article compares the focus and concentration techniques of Christian and Buddhist monks, emphasizing the advantages of immersive reading and mindfulness.",
      "It debates the pros and cons of physical books versus audiobooks, stressing the significance of reading and meditation for cognitive growth.",
      "Criticizes the biased nature of the debate and underscores the disappointment in expecting higher quality content."
    ],
    "points": 182,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1710007326
  },
  {
    "id": 39651926,
    "title": "Paving the Way for All-Optical Computing: A General-Purpose CPU and Architecture",
    "originLink": "https://arxiv.org/abs/2403.00045",
    "originBody": "Computer Science > Emerging Technologies arXiv:2403.00045 (cs) [Submitted on 29 Feb 2024] Title:An All-Optical General-Purpose CPU and Optical Computer Architecture Authors:Michael Kissner, Leonardo Del Bino, Felix Päsler, Peter Caruana, George Ghalanos Download PDF HTML (experimental) Abstract:Energy efficiency of electronic digital processors is primarily limited by the energy consumption of electronic communication and interconnects. The industry is almost unanimously pushing towards replacing both long-haul, as well as local chip interconnects, using optics to drastically increase efficiency. In this paper, we explore what comes after the successful migration to optical interconnects, as with this inefficiency solved, the main source of energy consumption will be electronic digital computing, memory and electro-optical conversion. Our approach attempts to address all these issues by introducing efficient all-optical digital computing and memory, which in turn eliminates the need for electro-optical conversions. Here, we demonstrate for the first time a scheme to enable general purpose digital data processing in an integrated form and present our photonic integrated circuit (PIC) implementation. For this demonstration we implemented a URISC architecture capable of running any classical piece of software all-optically and present a comprehensive architectural framework for all-optical computing to go beyond. Comments: 14 pages, 10 figures Subjects: Emerging Technologies (cs.ET); Optics (physics.optics) ACM classes: C.1.3 Cite as: arXiv:2403.00045 [cs.ET](or arXiv:2403.00045v1 [cs.ET] for this version)https://doi.org/10.48550/arXiv.2403.00045 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Leonardo Del Bino [view email] [v1] Thu, 29 Feb 2024 15:49:25 UTC (2,392 KB) Full-text links: Access Paper: Download PDF HTML (experimental) TeX Source Other Formats view license Current browse context: cs.ETnewrecent2403 Change to browse by: cs physics physics.optics References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=39651926",
    "commentBody": "An all-optical general-purpose CPU and optical computer architecture (arxiv.org)160 points by PaulHoule 19 hours agohidepastfavorite80 comments Animats 12 hours ago\"we will be implementing a 2-bit variant of SUBLEQ for demonstration purposes\" What they actually built was a 2-bit wide machine with one instruction. No, they can't run Doom, which they mention a lot. There's a lot of hand-waving about memory, around page 10. They seem to have used a delay line, which is very slow; you have to wait for the bits you want to come around. That's been a classic problem with photonics. You can build gates, which is nice for switching packets, but how do you store data? Much of the architectural discussion is about what you can do if memory is mostly ROM. They talk about fast-read, really slow write memory. Here's an article about building something like that.[2] It's a clunky technology. Writing involves on-chip heaters and switching memory cells back and forth from amorphous to crystalline. There's a long history of forgotten devices like that - photochromic memory, UV-erasable EEPROMS, rewritable DVDs, Ovonics, etc. All were superseded by something with better read-write properties. The underlying device technology is not theirs. It's from the Cornerstone project.[1] [1] https://www.mdpi.com/2076-3417/10/22/8201 [2] https://www.nature.com/articles/s41377-023-01213-3 reply drpixie 9 hours agoparent> You can build gates, which is nice for switching packets, but how do you store data? Logic gates can be the fundamental building block. So if you can build logic gates, then you can use those to build flip flops (the basis of static RAM) which store data. Might not be the most efficient way (depending on your requirements) but it can be done. https://en.wikipedia.org/wiki/Flip-flop_(electronics)#D_flip... reply atq2119 9 hours agorootparentNit pick: SRAM is not built out of flip flops. It's carefully sized inverters and a whole lot of analog magic (writing a bit involves overpowering the inverters of the bit with larger drivers). You may be thinking of latch arrays. reply adrian_b 3 hours agorootparentThe overpowering of the inverters is just an area efficient trick to make gates (the so-called wired-OR or wired-AND). The SRAM memory cells are simpler than flip flops, they are just S-R latches (i.e. equivalent with a half of an M-S flip-flop) made from two gates (either NAND or NOR). In any technology where static gates are possible SRAM memories are also possible. However there are technologies where only dynamic gates are possible, i.e. gates that provide an output that is valid only during a clock pulse and which cannot remain valid indefinitely. Only in such technologies you cannot make SRAMs, but you can still make dynamic memories, which must consume energy all the time, for refreshing their content. All the \"analog magic\" that you mention has only the purpose of making an SRAM array much denser than when implemented with the standard gates of a technology, but an implementation with standard gates is always possible and it may be chosen for certain register files, where high speed may be more important than the occupied area. reply TheDudeMan 5 hours agorootparentprevThe main point is that that you CAN build storage out of gates. reply mjevans 9 hours agoparentprevImagine this in a hypothetical setting such as Science Fiction. Where instead of an optical delay loop it's a fold in space or some other mechanism. Photonics and some sort of 'subspace' or toggled shift in reality? Maybe. I agree though, I've never seen anything explain how to make this work well as a general computer with contemporary tech. reply naasking 8 hours agoparentprev> They seem to have used a delay line, which is very slow; you have to wait for the bits you want to come around. Macroscopic delay lines sure, but microscopic ones presumably can be on the order of a wavelength, if that's all that's needed. Not much time needed to come around in that case. reply bilsbie 10 hours agoparentprevOk I’m sure this is stupid but could memory be a glow in the dark chemical? reply was_a_dev 9 hours agorootparentThere's photoswitchable molecules and fluorophores. https://en.m.wikipedia.org/wiki/Photoswitch reply throwaway69123 11 hours agoparentprevWhat about things like ai surely if gates are possible that means you could encode and entire model in photonic gates, surely that’s worth it reply datameta 9 hours agorootparentPhotonic in-memory AI inference would be a holy grail imo. reply aj7 16 hours agoprevAll optical computing surfaces again! Warning. There is NO opportunity for large scale integration, the MOST IMPORTANT ASPECT in computing. This is because the de Broglie wavelength of the information carriers, typically 1.5um, is so HUGE. reply Salgat 13 hours agoparentThere's some factors to consider here. For visible light yes, the smallest feature probably won't be smaller than several hundred nanometers, however, optical computing comes with several major advantages over traditional electrical circuits. The first is that light beams can cross paths without interfering with each other, allowing for a level of parallelism and density of signal paths without the concern of crosstalk/interference or shorting. Additionally, the information density of an optical signal is vastly higher than an electrical signal, and multiple optical signals can share the same pathways simultaneously. Also, energy usage is greatly reduced, so the constraints due to heat waste are much less. Having said all that, the idea of optical circuits in a VLSI is still a very foreign and exotic concept for us, so it's hard to say how far we can take it if we invest at the level we have for electrical ICs. It's naive though to say it's not feasible due to some oversimplification of feature size limitations. reply aj7 10 hours agorootparentUnless computation can be accomplished on differing overlapping frequencies, wdm devices, which resemble train switchyards, are huge, on the order of mm. So optical computing would have to take place at multi THz switching rates using very short pulses. reply musicale 10 hours agorootparentAs I understand it, microring resonators can be very small, µm rather than mm. reply musicale 10 hours agoparentprevSince you can carry 100+ frequencies around 1500 nm, the feature-size per data stream is more like 15 nm/stream, which is closer to electronics, and the heat dissipation of optical waveguides may be much lower than with equivalent electronics. Photonics also have the advantage of better signal propagation over longer distances, for efficient interconnection of multiple devices. So there is a likely opportunity for large-scale integrated photonics, as long as you have enough parallelism. reply aj7 10 hours agorootparentReferring to computing, not data transmission. Perhaps some day, using quantum computing, all those differing ‘portly’ photons, superimposed, could yield advances in density. To mix different wavelength streams on chip involves wdm devices, which are huge. reply musicale 10 hours agorootparentOptics/photonics can potentially perform analog as well as digital computation. One trendy thing at the moment is accelerators for neural networks. Some potential benefits of optics include high data rate, parallel processing of multiple streams, transmission over longer distances, and lower heat dissipation. reply nwiswell 10 hours agoparentprev> There is NO opportunity for large scale integration What about vertically? CMOS logic is still \"mostly planar\". With sufficiently low heat dissipation, you could make a cube and easily overcome the planar density problem. The main challenge seems like it would be lithography cost for each of the many layers, but if the minimum feature size is 1.5um, there might be a clever way to make this work cheaply (DLP projection + gradual extrusion?) reply glitchc 15 hours agoparentprevNot sure what this means. De Broglie waves are defined for matter (mass is required). While photons have relativistic mass, this isn't the same thing. reply aj7 10 hours agorootparentThe deBroglie wavelength of the photon IS its wavelength. That’s why it can’t squeeze into nm features and optical waveguides are still not used on-chip, after 35 years of effort. reply LoganDark 14 hours agorootparentprev\"Information carrier\" means the actual medium the light is travelling through, doesn't it? Which has to be matter of some sort. reply orlp 13 hours agorootparentLast time I checked the sun transfers its light through the vacuum of space to us. reply LoganDark 12 hours agorootparentSorry, I must've missed that these optical CPUs contain vacuums of space for the light to travel through. reply glitchc 13 hours agorootparentprevIndeed, as orlp mentioned, light is self-propagating and does not require a medium. This is broadly true for all EM waves. reply aj7 10 hours agorootparentBut it needs SPACE, on the order of a few um minimum, that cannot be occupied by other devices. reply Dylan16807 11 hours agorootparentprevWe're talking about a CPU, not light traveling in a straight line forever. reply goatlover 10 hours agorootparentprevWhy isn't the EM field the medium? Or even spacetime? reply aj7 10 hours agorootparentYou are confusing geometry, and the excitation traveling through that geometry. reply aj7 15 hours agoparentprevHundreds of of millions of dollars have been raised from naive investors by ignoring this fact. Often, board-member and founder physics PhD’s aid in the deception by omission. reply p1esk 13 hours agorootparentWhy can’t we reduce the wavelength? reply adgjlsfhk1 8 hours agorootparentshorter wavelength light really doesn't like existing. It takes more energy to produce, there are way fewer possible materials to make mirrors out of etc. Just look at how much trouble the industry had doing EUV lithography. reply naasking 9 hours agorootparentprevEven UV wavelengths aren't terribly small, and the shorter the wavelength, the more energy it has and the more likely it is to destroy whatever material your optical CPU is made of. reply p1esk 9 hours agorootparentSounds like an engineering problem, not a fundamental one. reply naasking 8 hours agorootparentNot sure what gives you that idea. It seems unlikely that there are materials that can withstand billions of x-ray pulses per second and continue to function without being altered. They might exist, but the higher the energy to get to low wavelengths for fast and information dense computing, the increasingly implausible it gets that a suitable material is physically possible. reply Panoramix 15 hours agoparentprevIf I was designing one of these things my goal would not be to replace present day computers - which at this point is nearly impossible given the millions of man hours spent optimizing them - but to carve a niche where you outperform them in specific tasks. I have the vague impression that should be possible. reply enslavedrobot 15 hours agorootparentPlasmonics may solve this problem. The interaction of light at an interface can lead to what essentially amounts to photon confinement. This allows for what's called near field optics which overcomes the limitations of wavelength and unlocks nanometer scale optoelectronics. For examples, see the solar sail for the \"starshot\" project. reply throwaway14356 11 hours agorootparentprevRight, Modern computers don't know what their purpose is, that makes it such a mind boggling challenge. Nothing is ever good enough. If you define the purpose it can be better and much cheaper. reply volemo 15 hours agorootparentprevThat's why most optical computers lean into quantum computing. reply bigbluedots 15 hours agoparentprevPlease elaborate? reply dvh 15 hours agorootparentCurrent electron based computers are 10s of nanometers per transistor. Optical equivalent of transistor cannot be smaller than 1um. Equivalent optical CPU to your smartphone would be the size of several football fields. reply simne 7 hours agorootparent> Optical equivalent of transistor cannot be smaller than 1um For classics optics. Exists superlens optics, which using metamaterials and monochromatic light source, and could \"see\" artifacts of size much less then wave length. reply nazgul17 11 hours agorootparentprevAsking from a position of total ignorance. The energy savings mean you can increase clock speeds, right? Assuming a big enough jump, won't that relieve a CPU from the need to have most specialised instruction sets and potentially also that many cores? In that case, wouldn't it be acceptable that transistors grow (back) in size? reply Dylan16807 11 hours agorootparentEnergy savings on what basis? If your gate gets 50x50x50 times bigger, you need some pretty extreme savings per area/volume of circuit if you want to reduce the per-gate usage. Can they save that much? reply skykooler 11 hours agorootparentprevIsn't part of the point that you don't need as many transistor equivalents because you can run them thousands of times faster? reply throwaway69123 11 hours agorootparentprevWhile this is true doesn’t ignore the difference in clock rate capacity ? If the photonic cpu can run 10,000x the clock rate without the extreme heat build up that would melt the smartphone reply nextaccountic 11 hours agoparentprevDo optical computing need to use visible light? reply varjag 14 hours agoparentprevOne potential of optics is teraherz frequencies. reply bevekspldnw 17 hours agoprevClaims like this require peer review, not to mention this is a private company not a university lab. I’m worried over this trend of private companies putting press releases into LaTeX templates. reply mistercow 16 hours agoparentI think there are two ways to look at it, both of which are true: 1) scientific literature is being polluted with non-peer-reviewed PRs which makes it harder to figure out what is actually well validated, and 2) press releases are being nudged into being a hell of a lot more technically substantive and rich in relevant citations. The first one isn’t great, but as consolation prizes go, (2) isn’t bad. reply rokkitmensch 13 hours agorootparentThe peer review community has torched its reputation over the last decade, so it should surprise precisely nobody paying attention that profit-motivated publishers are crawling over what remains of that barrier. reply llm_trw 9 hours agorootparentOutside of academia I don't think anyone realizes just how broken the system is. Citation extortion rings are part of every journal. I had a reviewer from Nature give feedback that I should cite her co-authors work on a topic that had nothing to do with my paper. It got rejected because I wouldn't. It went into archive and has been cited nearly a hundred times now. To add insult to injury Nature News asked to interview me about my work. Some more info on the subject, and a vast underestimation of how prevalent it is: https://www.science.org/content/blog-post/cite-my-papers-els... At this point if you can figure out how to make a pdf paper using latex I consider your work to be on par with anything in a journal. reply aj7 15 hours agorootparentprevAre you sure? Are you expert enough to read those papers? How do you achieve large scale integration in waveguides transparent to available laser sources? How does 250nm compare to the integration in your cell phone’s cpu? And we are decades away from modulatable miniaturized 250nm laser sources. It is typically 1.5um with today’s devices. reply mistercow 15 hours agorootparent> Are you expert enough to read those papers? Not in this case, no. But in cases where I do have more knowledge, the additional detail makes it much easier to tell if there's anything of substance there, compared to traditional press releases which just make superficial marketing claims with minimal technical detail. And if this were something more relevant to me, but where I didn't have expertise necessary to look at it, I could reach out to someone with the expertise needed to take a look. The point here is that it's very difficult talk at great length and in great detail about BS without making it apparent to experts that you're talking BS, whereas with a more traditional PR, the best you can often say is \"well, if this is anything, these are very big claims.\" reply bevekspldnw 15 hours agorootparentprevI disagree, people who are not expert consumers of information, but do think “arXiv is science stuff” are easily misled, and I trust citations from private companies without strong academic pedigree as worthless at best, harmful at worst. It’s pretty easy to con investors if you have the same “look” as a real lab. reply mistercow 14 hours agorootparent> I disagree, people who are not expert consumers of information, but do think “arXiv is science stuff” are easily misled I think you are talking about an extremely small segment of the population, so I don't think we're talking about a very large social impact. I'm also unconvinced that that segment doesn't generally take ordinary tech press releases at face value anyway. > I trust citations from private companies without strong academic pedigree OK, but the first two authors on this have doctorates in ML and applied photonics respectively. They don't have peer review on this paper, but I don't think you can say they're lacking in academic pedigree. > It’s pretty easy to con investors if you have the same “look” as a real lab. I don't know. My feeling is that the \"conning investors who are terrible at due diligence\" game is largely unavoidable and mostly a zero-sum competition between con artists. So while it's obviously bad, I'm not convinced that the specifics matter all that much. Fools and their money, and all that. reply bevekspldnw 5 hours agorootparentFair points all, but the fact that this made it to the front page of HN is itself problematic vis-a-vis the points raised. reply staunton 17 hours agoparentprev> I’m worried over this trend of private companies putting press releases into LaTeX templates. People need to realize once and for all that templates no longer represent quality or truthfulness, if they ever did. Maybe that lesson has to hurt a bit. reply bevekspldnw 15 hours agorootparentPeople have forgotten the whole point of “preprint” is you’re still supposed to, ya know, print! reply moffkalast 11 hours agorootparentMost people don't have printers anymore, they'd rather read it online /s reply bee_rider 16 hours agoparentprevI wonder if there’s room for a section on Arxiv that is exclusively for papers that are on a peer-review track. Or maybe “peer or open review,” or something like that. reply mometsi 17 hours agoparentprevPeer review for commercial press releases is an interesting idea! reply bevekspldnw 15 hours agorootparentNow that is a job for GPT if I ever heard one. Garbage in garbage out. reply morphle 15 hours agoprevThe arguments from the abstract of this paper have been refuted by Attojoule Optoelectronics for Low-Energy Information Processing and Communications: a Tutorial Review [1] and several other papers. [1] https://arxiv.org/abs/1609.05510 reply hilbert42 14 hours agoprevI'm still digesting this interesting paper but the Figure 3 chart is particularly informative as it puts the whole aspect of electronic and optical computing into perspective. I cannot recall ever having seen Power Dissipation versus Compute Performance together with Total global power generation, Total global data center electricity consumption, Electronic thermal noise limit and the Landauer Limit all graphed together before. Presenting the data in this fashion provides a stark and very clear overview of what's actually possible together with the theoretical limits. Graphing the Landauer Limit is a masterstroke because we can instantly see computation vs power efficiency for any given tech. I think the visual impact of this chart is important enough to see it expanded further and the authors and/or others should think about doing so. It would make an excellent poster-sized lab wall chart if the graticule lines were subdivided from 10³ to 10 (leaving 10³ lines bold) to provide finer granularly and allow more detail of the tech together with the dates of their introduction and phase out, etc. reply wiz21c 12 hours agoparentFigure 3 is intriguing to me: I thought GPU's where order of magnitude faster than CPU (because of parallelism) and although the chart is log-scale, I don't see that. I wonder why... reply luyu_wu 13 hours agoprevA lot of people seem to be mentioning the 'size' of electrical transistors, but this seems to fail to include complexity scaling (which is non-linear)? The lower complexity of optical chips (due to large switch sizes) can be made up by the faster switching speeds, which boast a linear increase in performance if I'm not mistaken? Really interesting paper! Edit: Advantages of multiplexing are very real too! reply cycomanic 12 hours agoprevIt's ironic that they cite Millers work, but don't address the main conclusions from that work, i.e. that optical computing is horribly inefficient. Photons are bosons and therefore are very reluctant to interact, essentially requiring nonlinearities. The issue with nonlinearities is that they fundamentally require comparatively high optical intensities. The authors mainly address the issue of integration density (which is also an issue), but not in sufficient detail the problem of efficiency. They handwavy this away by referring to 2d materials, but 2d are not a pancea. It's true that they exhibit very strong nonlinear coefficients (although I'm unsure if even that would be sufficient to overcome the efficiency challenges), however the overlap between the optical field and the 2d material is fundamentally very small (a single sheet of 2d material in the plane of propagation), so the observed enhancements have been very modest. reply jkafjanvnfaf 8 hours agoparentFirst of all, you are correct that nonlinear optics usually requires high field strengths. But... >Photons are bosons and therefore are very reluctant to interact, essentially requiring nonlinearities. Please don't throw out random sciency terms. First of all, interaction is pretty much by definition nonlinear. Second, photons are not reluctant to interact. Photon-photon scattering is negligible (which has nothing to do with them being bosons, as gluons and mesons readily demonstrate), but nonlinear optics doesn't rely on photon-photon scattering. reply simne 7 hours agoprevI like idea of optical delay line for registers. For other parts, great amount of work need to be done to achieve something working, so unfortunately, extremely risky project for now, need some time (years?) to implement all parts alone. reply projectileboy 13 hours agoprevThe optical equivalent of transistors have useful applications, but there are many shipwrecks on the shore of general-purpose optical computing, going back decades. I need more than a paper to get excited. reply p1esk 13 hours agoparentAt least they built a PoC. Many others just do simulations. reply ur-whale 16 hours agoprevI was kind of expecting the first paragraph of this paper to explain first and foremost how they solved the switching problem (i.e. a transistor) using optical only components. After wading through the paper for 10mn, I still haven't found the answer. If someone spotted it, please point where they talk about it, I would be grateful. Or I could go ask an AI to find the answer for me I guess. reply DarkmSparks 15 hours agoparentI believe this: The almost canonical way of performing all-optical switching and logic is to use semiconductor optical amplifiers (SOA) and exploit their cross-gain modulation (XGM) or cross-phase modulation (XPM) capabilities[21]. With very reliable devices having been shown over the past 20 years[22], SOAs have proven useful for various types of all-optical operation, including decoder logic[23, 24] and signal regeneration[25, 26, 27]. The recovery time of the SOA limits its performance, but it has been shown that more than 320 Gbit/s[28]all-optical switching is possible, with some implementations enabling even the Tbit/s domain[29]. reply aj7 15 hours agorootparentAnd at 1.5 um. Compare that to a 3nm electron architecture. reply thfuran 15 hours agorootparentAre you talking 3 actual nanometers or a \"3nm\" process? It's difficult to compare. reply p1esk 13 hours agorootparentAlso, I remember when 20 years ago people said building transistors smaller than 45nm will be impossible. reply frozenport 9 hours agoprevThis article teaches optics people about compute arch. Which is maybe fine, but its not still not clear how to implement these components. reply peter_d_sherman 13 hours agoprevThis is the best paper I've read in a long time -- this has to go in my \"Top 10\" favorite posts of all time on HN... (To PaulHoule: Another truly excellent post of yours to HN, thank you very much, the HN community and myself appreciate it greatly!) Anyway, let's delve into it -- here's the key quote, IMHO: >\"As the previous discussion showed, SUBLEQ is, of course, not the target realization for optical computing. Its purpose is to showcase the simplest form a general-purpose optical computer could take and an intermediary step we take. It can be implemented with less than 100 logic gates and, given enough memory, able to emulate a full x86 with a graphics card running Windows and Doom™ loaded, while crunching AI models as a background task (admittedly all extremely slowly).\" Now that is truly awesome! Also, it should be pointed out that if SUBLEQ could be implemented optically, it could also be implemented digitally, say, on the smallest of small gate count FPGA's... While such a FPGA Soft CPU would not be fast -- it would definitely be interesting, and probably very simple (comparatively!) to implement! (Also, it might be implementable on a tiny IC, for example, Sam Zeloof's \"Z2\" 1,000 gate IC: https://www.youtube.com/watch?v=IS5ycm7VfXg) Anyway, 5+ Stars for this excellent paper! Upvoted and favorited! reply BandButcher 16 hours agoprev [–] Don't have time to read it all but the abstract states, \"With our research, however, we are focused on the phase thereafter. Once optical interconnects and interposers have been fully established and are the main mode of inter-chip and intra-chip communication, solving the 6× inefficiencies... \" Therefore this paper is more about a computer architecture that will be in place AFTER general purpose hardware swaps from electrical to photonic communication, but we aren't there yet. Also seems the paper is more about tackling the next phase of `energy efficiency` problems that will arise after the swap. Still useful info to consider but i agree with most here that these click-bait titles in research are abused. But I can't really argue it got me to click ;) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper explores all-optical computing as a solution to energy efficiency issues in electronic processors, utilizing optics for interconnects and computing tasks.",
      "Authors suggest an efficient general-purpose CPU and architecture that eliminates the need for electro-optical conversions, showcasing a photonic integrated circuit (PIC) implementing a URISC architecture for all-optical data processing.",
      "The research aims to drive progress in the field of all-optical computing, looking to surpass current electronic limitations."
    ],
    "commentSummary": [
      "The discussion on arxiv.org examines a 2-bit version of SUBLEQ in an all-optical CPU, debating optical computing feasibility, advantages like parallelism and energy efficiency, size restrictions, and wavelength challenges.",
      "The conversation delves into storage, logic gates, memory structures, and AI models in optical computing, highlighting concerns over peer review quality and misinformation in academic publications.",
      "SUBLEQ is proposed as a basic optical computer with under 100 logic gates, illustrating its application in optical computing systems."
    ],
    "points": 160,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1709995793
  },
  {
    "id": 39652262,
    "title": "AI Content Contamination Threatens Future Models",
    "originLink": "https://www.scientificamerican.com/article/ai-generated-data-can-poison-future-ai-models/",
    "originBody": "July 28, 2023 5 min read AI-Generated Data Can Poison Future AI Models As AI-generated content fills the Internet, it’s corrupting the training data for models to come. What happens when AI eats itself? By Rahul Rao Credit: Jackie Niam/Getty Images Artificial Intelligence Thanks to a boom in generative artificial intelligence, programs that can produce text, computer code, images and music are readily available to the average person. And we’re already using them: AI content is taking over the Internet, and text generated by “large language models” is filling hundreds of websites, including CNET and Gizmodo. But as AI developers scrape the Internet, AI-generated content may soon enter the data sets used to train new models to respond like humans. Some experts say that will inadvertently introduce errors that build up with each succeeding generation of models. A growing body of evidence supports this idea. It suggests that a training diet of AI-generated text, even in small quantities, eventually becomes “poisonous” to the model being trained. Currently there are few obvious antidotes. “While it may not be an issue right now or in, let’s say, a few months, I believe it will become a consideration in a few years,” says Rik Sarkar, a computer scientist at the School of Informatics at the University of Edinburgh in Scotland. On supporting science journalism If you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today. The possibility of AI models tainting themselves may be a bit analogous to a certain 20th-century dilemma. After the first atomic bombs were detonated at World War II’s end, decades of nuclear testing spiced Earth’s atmosphere with a dash of radioactive fallout. When that air entered newly-made steel, it brought elevated radiation with it. For particularly radiation-sensitive steel applications, such as Geiger counter consoles, that fallout poses an obvious problem: it won’t do for a Geiger counter to flag itself. Thus, a rush began for a dwindling supply of low-radiation metal. Scavengers scoured old shipwrecks to extract scraps of prewar steel. Now some insiders believe a similar cycle is set to repeat in generative AI—with training data instead of steel. Researchers can watch AI’s poisoning in action. For instance, start with a language model trained on human-produced data. Use the model to generate some AI output. Then use that output to train a new instance of the model and use the resulting output to train a third version, and so forth. With each iteration, errors build atop one another. The 10th model, prompted to write about historical English architecture, spews out gibberish about jackrabbits. “It gets to a point where your model is practically meaningless,” says Ilia Shumailov, a machine learning researcher at the University of Oxford. Shumailov and his colleagues call this phenomenon “model collapse.” They observed it in a language model called OPT-125m, as well as a different AI model that generates handwritten-looking numbers and even a simple model that tries to separate two probability distributions. “Even in the simplest of models, it’s already happening,” Shumailov says. “I promise you, in more complicated models, it’s 100 percent already happening as well.” In a recent preprint study, Sarkar and his colleagues in Madrid and Edinburgh conducted a similar experiment with a type of AI image generator called a diffusion model. Their first model in this series could generate recognizable flowers or birds. By their third model, those pictures had devolved into blurs. Other tests showed that even a partly AI-generated training data set was toxic, Sarkar says. “As long as some reasonable fraction is AI-generated, it becomes an issue,” he explains. “Now exactly how much AI-generated content is needed to cause issues in what sort of models is something that remains to be studied.” Both groups experimented with relatively modest models—programs that are smaller and use fewer training data than the likes of the language model GPT-4 or the image generator Stable Diffusion. It’s possible that larger models will prove more resistant to model collapse, but researchers say there is little reason to believe so. The research so far indicates that a model will suffer most at the “tails” of its data—the data elements that are less frequently represented in a model’s training set. Because these tails include data that are further from the “norm,” a model collapse could cause the AI’s output to lose the diversity that researchers say is distinctive about human data. In particular, Shumailov fears this will exacerbate models’ existing biases against marginalized groups. “It’s quite clear that the future is the models becoming more biased,” he says. “Explicit effort needs to be put in order to curtail it.” Perhaps all this is speculation, but AI-generated content is already beginning to enter realms that machine-learning engineers rely on for training data. Take language models: even mainstream news outlets have begun publishing AI-generated articles, and some Wikipedia editors want to use language models to produce content for the site. “I feel like we’re kind of at this inflection point where a lot of the existing tools that we use to train these models are quickly becoming saturated with synthetic text,” says Veniamin Veselovskyy, a graduate student at the Swiss Federal Institute of Technology in Lausanne (EPFL). There are warning signs that AI-generated data might enter model training from elsewhere, too. Machine-learning engineers have long relied on crowd-work platforms, such as Amazon’s Mechanical Turk, to annotate their models’ training data or to review output. Veselovskyy and his colleagues at EPFL asked Mechanical Turk workers to summarize medical research abstracts. They found that around a third of the summaries had ChatGPT’s touch. The EPFL group’s work, released on the preprint server arXiv.org last month, examined only 46 responses from Mechanical Turk workers, and summarizing is a classic language model task. But the result has raised a specter in machine-learning engineers’ minds. “It is much easier to annotate textual data with ChatGPT, and the results are extremely good,” says Manoel Horta Ribeiro, a graduate student at EPFL. Researchers such as Veselovskyy and Ribeiro have begun considering ways to protect the humanity of crowdsourced data, including tweaking websites such as Mechanical Turk in ways that discourage users from turning to language models and redesigning experiments to encourage more human data. Against the threat of model collapse, what is a hapless machine-learning engineer to do? The answer could be the equivalent of prewar steel in a Geiger counter: data known to be free (or perhaps as free as possible) from generative AI’s touch. For instance, Sarkar suggests the idea of employing “standardized” image data sets that would be curated by humans who know their content consists only of human creations and freely available for developers to use. Some engineers may be tempted to pry open the Internet Archive and look up content that predates the AI boom, but Shumailov doesn’t see going back to historical data as a solution. For one thing, he thinks there may not be enough historical information to feed growing models’ demands. For another, such data are just that: historical and not necessarily reflective of a changing world. “If you wanted to collect the news of the past 100 years and try and predict the news of today, it’s obviously not going to work, because technology’s changed,” Shumailov says. “The lingo has changed. The understanding of the issues has changed.” The challenge, then, may be more direct: discerning human-generated data from synthetic content and filtering out the latter. But even if the technology for this existed, it is far from a straightforward task. As Sarkar points out, in a world where Adobe Photoshop allows its users to edit images with generative AI, is the result an AI-generated image—or not? Rights & Permissions Rahul Rao is a London-based freelance science writer covering physics, space, technology and their intersections with one another and everything else. He likes snakes, old genre fiction, trains and classic Doctor Who, in no particular order. More by Rahul Rao",
    "commentLink": "https://news.ycombinator.com/item?id=39652262",
    "commentBody": "AI-Generated Data Can Poison Future AI Models (scientificamerican.com)139 points by meany 18 hours agohidepastfavorite82 comments sophrocyne 17 hours agoSome perspectives from someone working in the image space. These tests don't feel practical - That is, they seem intended to collapse the model, not demonstrate \"in the wild\" performance. The assumption is that all content is black or white - AI or not AI - and that you treat all content as equally worth retraining on. It offers no room for assumptions around data augmentation, human-guided quality discrimination, or anything else that might alter the set of outputs to mitigate the \"poison\" reply jtriangle 15 hours agoparentAs someone also working in the imaging space, ai generated data is useful solong as it's used carefully. Specifically, we're implementing AI culled training sets which contain some generated data that then gets reviewed manually for a few specific things, then pushed into our normal training workflows. This makes for a huge speedup versus 100% manual culling and the metrics don't lie, the models continue to improve steadily. There may be a point where they're poisoned and will collapse, but I haven't seen it yet. reply MacsHeadroom 15 hours agoparentprevThis is exactly right. Model collapse does not exist in practice. In fact, LLMs trained on newer web scrapes have increased capabilities thanks to the generated output in their training data. For example, \"base\" pretrained models trained on scrapes which include generated outputs can 0-shot instruction follow and score higher on reasoning benchmarks. Intentionally produced synthetic training data takes this a step further. For SoTA LLMs the majority of, or all of, their training data is generated. Phi-2 and Claude 3 for example. reply Bjorkbat 15 hours agorootparentIronically Claude 3 appears to have certain \"quirks\" arguably caused by the fact that its training data contains synthetic data. In one instance (https://twitter.com/DimitrisPapail/status/176477229891207585...), it kept referring to itself as ChatGPT. Granted, one could argue that this only happened because the API version of Claude doesn't appear to use a system prompt. If that's the case, then the LLM lacks any identity otherwise defined by the initial system prompt, and thus, kind of makes one up. Nonetheless, point remains, it's kind of interesting to see that in the years since the launch of ChatGPT we're already seeing a tangible impact on publicly available training data. LLMs \"know\" what ChatGPT is, and may even claim to be it. reply catchnear4321 13 hours agorootparentthat is the meat the article tries to cook. the impacts so far aren’t all that negative. but time flows like a river, and the more shit that gets into it… poison does not need to be immediately fatal to be fatal. some take a frighteningly long time to work. by the time you know what’s happening, not only is it too late, you have already suffered too much. does this sound like anything more than a scary story to tell around campfires? not yet. reply rdedev 15 hours agorootparentprevClaude 3 does use publically available data. Not everything is synthetically generated. Look at the section for training data in the below link. It has an quote from the paper which states that it uses a mix of public data, data from labelers and synthetic data https://www.lesswrong.com/posts/JbE7KynwshwkXPJAJ/anthropic-... I can't find a link to the actual clause paper to verify the above link but a few other places mention the same thing about the training data. We don't know if this improved performance is because of synthetic data or something else. I'm guessing even antropic might not be knowing this too. reply coffeebeqn 13 hours agorootparentprevWouldn’t reinforcement learning just weigh any nonsense data very low and then spammy garbage doesn’t really affect the model in the end much ? If the model and human experts can’t tell the difference then it’s probably pretty good AI generated data reply __loam 11 hours agorootparentTruth and what humans think is true are different things. Synthetic data was created by models that were trained to be convincing. reply catchnear4321 13 hours agorootparentprevthe ideal poison tastes like nothing, or at the very least doesn’t taste bad. you wouldn’t want to alert the victim. reply pavel_lishin 15 hours agorootparentprevWhat happens if you train a model on nothing but AI-generated output, recursively? Does it eventually get inbred? reply visarga 14 hours agorootparentWhy would you limit a model to be like a brain in a vat? Instead let the model out so people use it, then use the chat logs to fine-tune. A chat room is a kind of environment, there is a human, maybe some tools. The LLM text will generate feedback and right there is a learning signal. Even without a human, if a LLM has access to code execution it can practice solving coding tasks with runtime feedback. There are many ways a LLM could obtain useful learning signals. After all, we got all our knowledge from the environment as well, in the end there is no other source for knowledge and skills. reply astrange 7 hours agorootparentprevDepends how good the AI output is, just like it depends how good the natural output is. If most of it is bad but you can get a better AI to tag it as bad, then it's not necessarily a problem. reply Kuinox 15 hours agorootparentprevWithout human input, yes. reply gwern 6 hours agorootparentprevDoes AlphaZero get inbred? reply Der_Einzige 8 hours agorootparentprevI want to observe that one of my favorite youtubers did exactly this with making the \"uppest case\" and \"lowest case\" letters. https://www.youtube.com/watch?v=HLRdruqQfRk I love this guy so much and wish he made far more videos. reply wredue 13 hours agorootparentprev>model collapse does not exist in practice Dude what? That’s a pretty absurd claim. Most generally available models specifically curate their inputs for the express purpose of avoiding AI garbage induced collapse. It’s literally on their cited reasons for avoiding ai generated data as inputs. reply Aerroon 13 hours agoparentprev>human-guided quality discrimination This is the part that I don't really understand. Isn't this basically an evolutionary algorithm, where the fitness function is \"whatever people like the most\" (or at least enough to post it online)? People rarely generate 10 pieces of content with AI and then share all 10 with the world. They usually only share the best ones. This naturally filters for better output. Are they saying that evolutionary algorithms don't work? reply paulddraper 5 hours agoparentprev> human-guided quality discrimination Precisely. Whether content is AI-generate, ghostwriter-generated, monkey-on-keyboard-generated, etc...presumably it is implictly filtered by value/quality. Garbage AI outputs won't be as popular as good AI outputs. (And the same is true of human ones!) reply data-ottawa 16 hours agoparentprev> Use the model to generate some AI output. Then use that output to train a new instance of the model and use the resulting output to train a third version, and so forth. With each iteration, errors build atop one another. The 10th model, prompted to write about historical English architecture, spews out gibberish about jackrabbits. That this happens doesn't surprise me, but I'd love to see a curve of how each organic vs machine content mixe ratio results in model collapse over N generations. reply nestorD 15 hours agoprevI believe that this is a non-problem pushed forward by small-scale experiments that are not representative of what people actually do with AI generation. A lot of new content, while AI generated, has been hand picked and polished by a human (for example, while you might commit AI generated code to your codebase, you ensure that it is correct and follows your preferred style). Content farms will push gibberish out, but they did so, and worse, before and the first generation of models was able to train on the internet anyway. reply x86x87 9 hours agoparenti think it's pretty much a problem and it's going to ruin any chance of high quality, original content. look at the original internet content and what seo has done to it. google and search in general results are trash nowadays. this is what genAI is going to do over long term. garbage in garbage out. reply beeboobaa 16 hours agoprevIt shouldn't be a problem if you only train on legally acquired data. You will know the authors name and can contact them if you so wish. reply astrange 7 hours agoparentThere aren't any laws that require \"acquiring\" something in a way that \"knows the author's name\". reply theferalrobot 14 hours agoparentprevI don't think any of the major players could do that for all their data and they are acquiring it legally. reply buo 17 hours agoprevI think it's interesting that human minds generally (though not always!) improve when exposed to the output of other human minds. It seems to be the opposite for current LLMs. reply diggan 17 hours agoparentMaybe it's less about \"Human VS Robot\" and more about exposure to \"Original thoughts VS mass-produced average thoughts\". I don't think a human mind would be improving if they're in a echo-chamber with no new information. I think the reason the human mind is improving is because we're exposed to new, original and/or different thoughts, that we hadn't considered or come across before. Meanwhile, a LLM will just regurgitate the most likely token based on the previous one, so there isn't any originality there, hence any output from a LLM cannot improve another LLM. There is nothing new to be learned, basically. reply bluefirebrand 16 hours agorootparent> I don't think a human mind would be improving if they're in a echo-chamber with no new information If this were true of humans, we would have never made it this far Humans are very capable of looking around themselves and thinking \"I can do better than this\", and then trying to come up with ways how LLMs are not reply diggan 16 hours agorootparent> Humans are very capable of looking around themselves and thinking \"I can do better than this\" Doesn't this require at least some perspective of what \"better than this\" means, which you could only know with at least a bit of outside influence in one way or another? reply Jensson 7 hours agorootparentEvery human has feelings and instincts, they answer what \"better than this\" means. Yes, even in math and science, those were built on top of our feeling of \"better than this\" iterated over thousands of years. reply esafak 15 hours agorootparentprevParsimony, explanatory power, and aesthetics. These are things that could be taught to a computer, and I think we will. We had to evolve them too. reply ausbah 17 hours agoparentprevhumans haven’t been had the same set of all encompassing “training experiences” like LLMs have. we each a subset of knowledge that may overlap with some other’s knowledge, but is largely unique. so when we interact with each other we can learn new things, but with LLMs I imagine it is a group of experienced but antiquated professors developing their own set of out of touch ideas reply ben_w 15 hours agoparentprevReproductive analogy: A sequence of AI models trained on each other's output gets mutations, which might help or hurt, but if there's one dominant model at any given time then it's like asexual reproduction with only living descendant in each generation (and all the competing models being failures to reproduce). A photocopy of a photocopy of a photocopy — this seems to me to also be the incorrect model which Intelligent Design proponents seem to mistakenly think is how evolution is supposed to work. A huge number of competing models that never rise to dominance would be more like plants spreading pollen in the wind. A huge number of AI there are each smart enough to decide what to include in its training set would be more like animal reproduction. The fittest memes survive. Memetic mode collapses still happen in individual AI (they still happen in humans, we're not magic), but that manifests as certain AI ceasing to be useful and others replacing them economically. A few mega-minds is a memetic monoculture, fragile in all the same ways as a biological monoculture. reply nonrandomstring 15 hours agorootparentA different biological analogy occurred to me which I've mentioned before in a security context. It isn't model degeneration but the amplification of invisible nasties that don't become a problem until way down the line. Natural examples are prions such as Bovine spongiform encephalopathy [0] or sheep scrapie. This seems to really become a problem in systems with a strong and fast positive feedback loop with some selector. In the case of cattle it was feeding rendered bonemeal from dead cattle back to livestock. Prions are immune to high temperature removal so are selected for and concentrated by the feedback process. To really feel the horror of this, read Ken Thompson's \"Reflections on Trusting Trust\" [1] and ponder the ways that a trojan can be replicated iteratively (like a worm) but undetectably. It isn't loss functions we should worry about. It's gain functions. [0] https://en.wikipedia.org/wiki/Bovine_spongiform_encephalopat... [1] https://tebibyte.media/blog/reflections-on-trusting-trust/ reply NortySpock 17 hours agoparentprevI do get to choose what I read, though. reply KolmogorovComp 17 hours agoparentprevA more appropriate analogy would be isolating someone from the rest of the world and only being able to read their own writings from now on. While some persons can strive in these kind of environment (think Kant for example), many would become crazy. reply throwaway74432 17 hours agoparentprevDifferent loss function reply mewpmewp2 16 hours agoparentprevHave you ever heard of the telephone game? This is what is going on here. Or imagine an original story of something that really happened. If it goes by 100 people in a chain, how much do you think the story will resemble the original one? reply analog31 14 hours agoparentprevThis might be my biases speaking, but I have a hunch that there's still more potential for human generated content to poison our minds, than AI. reply BobaFloutist 16 hours agoparentprevI mean it makes sense that (even impressively functional) statistical approximations would degrade when recursed. If anything I think this just demonstrates yet again that these aren't actually analogous to what humans think of as \"minds\", even if they're able to replicate more of the output than makes us comfortable. reply orbital-decay 15 hours agoparentprevHumans exhibit very similar behavior. Prolonged sensory deprivation can drive a single individual insane. Fully isolated/monolithic/connected communities easily become detached from reality and are susceptible to mass psychosis. Etc etc etc. Humans need some minimum amount of external data to keep them in check as well. reply ipython 17 hours agoprevThis reminds me of how fascinated I was as a kid of the artifacts you get from recursively photocopying a piece of paper. reply sshine 17 hours agoparentI watched someone in the printer room at the computer science department gradually photocopy from white to black, and back again, over the span of 300 pieces of paper, by altering the thresholds of the photocopyer. They didn’t graduate to become computer scientists, but did indeed get admitted to the royal school of art the year after. I found it strangely therapeutic. reply randcraw 15 hours agoprevIt's fascinating that error can accumulate through repeated trainings that 1) is undetected by humans and 2) can degrade LLM or diffusion models (or any transformer model?) so completely. This implies that not only do we not understand how latent knowledge is actually representated in deep nets, we don't know it forms or how it changes during training. If we did, we could have predicted the destructive impact of recycling of output as input. IMO, this suggests we should demand rigorous validation of deep nets (especially generative ones) before relying on them to behave responsibly. reply x86x87 9 hours agoparentThe effect is not new. We have known about it ever since we've had basic machine learning. The way to look at it is somewhat novel but not surprising at all. reply coldcode 15 hours agoprevI think AI-generated images are worse for training AI generative models than LLMs, since there are so many now on the internet (see Instagram art related hashtags if you want to see nothing but AI art) compared to the quantity of images downloaded prior to 2021 (for those AI that did that). Text will always be more varied than seeing 10m versions of the same ideas that people make for fun. AI text can also be partial (like AI-assisted writing) but the images will all be essentially 100% generated. reply ToucanLoucan 15 hours agoparentThat's far from unique to instagram. I loathe Stable Diffiusion and co solely because they've utterly FLOODED every cool art-adjacent website with endless mediocre derivative shit. Like there was always low-effort content of course, but holy fuck, there is SO MUCH MORE now. And some of these people are trying to CHARGE for this uninspired junk!!! reply 7moritz7 13 hours agorootparentI agree with this despite using SD a lot myself. It's fun to use until you realize the majority of people posting stuff generated with it have almost no creativity, all generating the same things over and over again, mostly without any manual work involved. that uncanny realism style with the generic Stable Diffusion face and one of 5 different poses. The number of people putting any sort of effort into it is way, way lower than the number of users thinking they are making art. It's more of a slot machine in the majority of cases reply vunderba 12 hours agorootparentUnfortunately, yeah 99.9% of images you're going to see generated from stable diffusion models are going to be either selfies, portraits, or porn. What's you're not going to see is things like \"a divine gigantic textile loom sewing together a white horse and a black horse in an interlaced pattern to create a zebra.\" for example. reply ToucanLoucan 9 hours agorootparentprevHonestly, if you want to make art, AI is a hindrance not a tool. You have to engineer what you say to maximum exactness, and even then it'll still just ignore certain words, or skip them over, or get basic details wrong. Way back when all this stuff first popped off, I did try it out. I was unimpressed. It was like playing a game of telephone with my ideas, having to describe them into one end and have a thousand people repeat it to one another and make little contributions till it came out the other end, most of the time looking absolutely nothing like I expected. People who say this makes art accessible... I dunno, I've never gotten it. I've seen people with all manner of disabilities, deformities, etc. all manage to express themselves creatively with practice and accessibility tools far more reliably than trying to make an AI pop out what you actually want. It seems to be the accessibility claims really only hold water if the accessibility feature is \"I don't want to learn any skills\" which... I mean, okay. But as with all art, your end product will reflect that level of care. reply __loam 11 hours agorootparentprevI definitely think the flooding of art spaces is hugely problematic, but it is pretty funny to watch people try to \"be an artist\" by putting essentially no effort in. It definitely points to a lack of understanding in the field when all these people are basically generating a ton of images that are all derived from the same models. There's a lack of understanding of supply and demand, when the expectation is that your ai illustration that you made in like an hour with the same software as every other ai artist is that it's somehow going to be competitive on engagement with an original piece from an artist who has an audience. There's a lot of demand for artists like Mika Pikazo and Frank Frazetta, not the 100,000 ai artists out there. reply ToucanLoucan 9 hours agorootparentI mean it's hard to fault those people when that was essentially how these were sold way back. \"Automating art\" and all that. All the most insufferable people on twitter jumping from shilling crypto scams to shilling AI and telling real artists in their ivory towers that their days were numbered. Guess put it on the pile with all the other broken promises. reply esafak 15 hours agoprevComputers need to be able to learn from the world at large, not just their own output. World models are needed to make progress. reply astrange 7 hours agoparentThere's no such thing as a world model. People do not have world models. This is a confused term made up by 70s AI researchers, who had the continual problem that they didn't know any philosophy and kept making up their own metaphors for how intelligence might work, and then deciding that because they'd made it up it must be true, and also that if they wrote a computer program that had the same metaphors it must work. \"World model\" just vaguely points at something people might do and assumes that if you make up a new thing it vaguely points at it'd help. reply Jensson 7 hours agorootparentOn what basis are you saying that? I have a model in my head mapping out the world around me, so I know where things are etc and what I can do with all those things. How is that not a world model? Are you using a very strange definition of \"world model\"? reply astrange 6 hours agorootparent> On what basis are you saying that? This is a longstanding critique of GOFAI; see Hubert Dreyfuss and Phil Agre. https://pages.gseis.ucla.edu/faculty/agre/critical.html > I have a model in my head mapping out the world around me, so I know where things are etc and what I can do with all those things. No you don't; a map is not the territory, and is necessarily wrong, which means that if you had such a model and were actually relying on it you wouldn't be able to do things you obviously can do in real life. You have an inaccurate memory of the world and you update it, only as much as you need to[0], as you go, in order to do a specific task. [0] probably a little less than you need to, because you want to save thinking energy reply Jensson 2 hours agorootparent> No you don't; a map is not the territory, and is necessarily wrong, which means that if you had such a model and were actually relying on it you wouldn't be able to do things you obviously can do in real life. What are you talking about, a world model doesn't need to be perfect, nobody said humans has a perfect world model just that we have a world model. Yes we update the model and adjust when it is wrong, but we still have a world model we use to plan out actions before we do them. I can very accurately predict all the events that will happen when I cook food, how the water will flow etc, sometimes things go wrong and I adjust and fix, but there is no way I could cook food if I didn't have that world model to plan out actions. > This is a longstanding critique of GOFAI; see Hubert Dreyfuss and Phil Agre. They don't even mention world model there, I think you are talking about something completely different. No, the mental model humans have of the world isn't the real world, we know that, it is a model of the world, ie a world model. A model isn't the real thing, that is why we call it a model. reply ein0p 16 hours agoprevI also wonder what search engines are going to do about all this. Sounds to me, actually, traditional, non-intelligent search might be on its way out, although of course it'll take time. Future search engines will have to be quite adept at trying to figure out whether the text they index is bullshit or not. reply add-sub-mul-div 16 hours agoprevYou'd think we'd be concerned about it poisoning the culture, well before any concerns that it would start to interfere with the rich continuing to be able to profit from it doing so. reply p5v 14 hours agoprevIs there a standard objective metric that can help determine that the quality of a model has degraded over time. In that case, much like source code, you just revert to the old version. reply doubloon 17 hours agoprevreminds me of sheep and cows being fed their bretherens own brain matter developing spongiform encepalopathy (brain disease) or of course cannibals developing kuru. except a purely 'software' form. reply Bjorkbat 15 hours agoprevI'm not sure how much of a risk this is to LLMs in particular, but I feel like we're already seeing the impact on image AI models. Even though they're getting better at generating hands that make sense and other fine details, you can generally tell that an image is AI generated because it has a certain \"style\". Can't help but wonder if this is partly due to generated images contaminating the training data and causing subsequent AI image generators to stylistically converge over time. reply astrange 7 hours agoparentIt's because the models don't have an optimal aesthetic policy. Which would be difficult, but if they did have one, it wouldn't matter how much bad input data you added during pretraining. reply cortesoft 16 hours agoprevHuman created content is also filled with gibberish and false information and random noise… how is AI generated content worse? reply feoren 16 hours agoparentArsenic naturally occurs... how are automatic factories that dump millions of tons it in the nearby river worse? reply heresie-dabord 16 hours agoparentprev> how is AI generated content worse? This is a crucial question. In human society, a feedback loop of nonsense is usually defeated by practical effects in physical reality and experience. The objective of education, for example, is to transmit knowledge and apply reason to important questions. In manipulated social media, there is no check on the nonsense loop. The technology that we currently call A.I. could be used for educational good. How it will be used, however, is likely to further distort discourse and generate nonsense. reply ejb999 16 hours agoparentprevIt is worse, because it is faster - how many incorrect blog articles can a sigle typical writer publish and post on the internet - maybe 1-2 a day if you are a prolific writer? How many can an AI agent do? Probably hundreds of thousands a day. To me, that is going to be a huge problem - but don't have a solution in mind either. And then those 100K bad articles posted per day by one person, are used as training data for the next 100K bad/incorrect articles etc - and the problem explodes geometrically. reply Libcat99 16 hours agoparentprevImagine you have a calculator that outputs a result that is off by one percent. That's ai right now. If you use the results of each calculation in additional calculations, the result will skew further and further from reality with each error. That's ai training on itself. reply richk449 16 hours agorootparentIn many areas of communication and information, this exact problem is dealt with through error correction codes. Do AI models have built in ECC? reply nyrikki 15 hours agorootparentNo, LLMs with soft attention use compression, and actually has no mechanism for ground truth. They are simply pattern finding and matching. More correctly, they are uniform consent depth threshold circuits. Basically parallel operations on a polynomial number of AND, OR, NOT, and majority gates. The majority gates can do the Parity function, but cannot self correct like ECC does. The thing with majority gates is that they can show some input is in the language: This the truthiness of 1,1,1,0,0 being true, but 1,1,0,0,0 would be failure as negation, but doesn't prove that negation, it isn't a truthy false. With soft attention will majority gates they can do parity detection but not correction. Hopefully someone can correct this if I am wrong. Specifically I think that the upper bound of deciding whether X = x is a cause of m) in structures is NP-complete in binary models (where all variables can take on only two values) and Σ_2^P -complete in general models. As TC_0 is smaller than NP, and probably smaller than P, any methods would be opportunistic at best. Preserving the long tail of a distribution is a far more pragmatic direction as an ECC type ability is unreasonable. Thinking of correctional codes as serial turing machine and transformers as primarily parallel circuits should help with understanding why they are very different. reply Libcat99 16 hours agorootparentprevThe trouble is \"truth\" and math are different. You can verify a mathematical result. You can run the calculations a second time on a separate calculator (in fact some computers do this) to verify the result, or use a built in check like ecc. There's no such mathematical test for truth for an ai to run. reply richk449 12 hours agorootparentError correction doesn’t insure truth. At least in communication, it insures that the final version matches the original version. For AI, you wouldn’t be doing EC to make sure the AI was saying truth, you would be doing EC to ensure that the AI hasn’t drifted due to the 1% error rate. Of course I have no idea how to actually do it - if it isn’t being done now, it is probably hard or impossible. reply ben_w 15 hours agorootparentprevThere's no fully general test for truth for an AI to run. In some specific domains such tests exist — and the result is, generally, computers wildly outperforming humans. But I get the impression from using them that current LLMs didn't take full advantage of this during training. reply jxdxbx 16 hours agoprevHow does this relate to synthetic data? reply richk449 16 hours agoprevKessler syndrome for the internet? reply chmike 16 hours agoprevAnd human generated data may not ? reply RecycledEle 11 hours agoprevSynthetic data is a disaster. If you want foom (fast self-improvement in AI) use AIs to filter the training data for the next generation of AIs. reply hermitcrab 17 hours agoprevSee also: https://news.ycombinator.com/item?id=39422528 reply ur-whale 16 hours agoprev> AI-Generated Data Can Poison Future AI Models Looks like we didn't learn anything from the mad cow disease! reply GaggiX 17 hours agoprevUnless the internet is no longer useful because there is no way to find anything reliable, there would be enough signal to train and align models. reply Iulioh 17 hours agoparentDead internet theory is closer and closer I don't remember wich YouTuber made a interesting video about it but basically communities are moving away from the free web in private communities (think discord or even sites that you are forced to register to to read the content) It's an interesting thing but I think queries on searche engines are becoming worse for this reason too. reply hackerlight 16 hours agoparentprevI question whether it'll matter. There is so much language data already, unlocking a little more isn't going to be the difference maker for AGI. reply Der_Einzige 17 hours agoprev [–] Certain words, like \"groundbreaking\", have been totally ruined for me by LLMs which are too often trained to sound like each other. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AI-generated content is saturating the internet, impacting future AI models' training data and potentially causing \"model collapse.\"",
      "Researchers have identified \"model collapse\" in different AI models, raising worries about bias, diversity, and future AI model performance.",
      "Engineers are seeking solutions to safeguard training data from AI-generated content to mitigate these concerns."
    ],
    "commentSummary": [
      "The article explores the risks associated with using AI-generated data to train future AI models, including concerns like model collapse, unintended consequences, and a potential lack of creativity and diversity in generated content.",
      "It emphasizes the importance of not solely relying on AI-generated output for training, touching on its impact on model evolution, innovation, cognitive processes, and decision-making.",
      "The discussion also highlights challenges in error correction, the significance of diverse perspectives in AI training, and the limitations of internet data in AI development, ultimately emphasizing the critical need to carefully assess data sources for AI model training to maintain integrity and performance."
    ],
    "points": 139,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1709998452
  },
  {
    "id": 39653625,
    "title": "React Geiger: Identify Performance Issues with Audio Clicks",
    "originLink": "https://github.com/kristiandupont/react-geiger",
    "originBody": "React Geiger React Geiger is a tool for \"audiolizing\" React performance issues. You can have it running in the background and makes little clicks which will point your attention to excessive (slow) component rerenders. Play with it in this playground Installation npm i react-geiger Usage You wrap whatever you want to track in thecomponent, and re-renders inside will cause a click if they take longer than the threshold set (default: 50ms). The most basic setup is wrapping your entire app:You can also use it on a sub-tree wherever. The options are: profilerId?: string; renderTimeThreshold?: number; phaseOption?: PhaseOption; enabled?: boolean; profilerId is an id that will be passed on to the React.Profiler component. You probably don't need to change this. renderTimeThreshold is the time in milliseconds that will trigger a click. Default is 50ms. Set to 0 to make any re-render click phaseOption is the phase of the render you want to track, either 'mount', 'update' or 'both' (which is the default) enabled defaults to true, but you can use this to disable it. Note that it relies on React.Profiler under the hood, which is disabled in production builds per default.",
    "commentLink": "https://news.ycombinator.com/item?id=39653625",
    "commentBody": "React Geiger – performance profiling using sound (github.com/kristiandupont)137 points by kristiandupont 15 hours agohidepastfavorite30 comments jakobloekke 14 minutes agoNice :) I built the same thing a few years back for RxJS debugging. Turned out to be really useful! reply Zetaphor 33 minutes agoprevI had a similar idea for Linux inspired by my longing for the sound of mechanical hard drives: https://github.com/Zetaphor/SysTone reply DennisL123 2 hours agoprevThe idea is at least ten years old: https://blog.mapbox.com/audiolizing-server-query-rate-749d5a... reply awestroke 2 hours agoparentSo what? reply madjam002 2 hours agoprevThere's also https://github.com/tomhicks/react-audible-debug which has been around for some time, I think it has a clearer sound for identifying excessive re-renders, but it's definitely a little more annoying :) https://stackblitz.com/edit/react-9vb6xn?file=src%2FApp.js reply ydant 15 hours agoprevCool idea. This makes me wonder if there's something similar for log files. I sometimes find myself doing adhoc analysis of live logs using visual cues, but auditory ones are really powerful - just never think of using sound for diagnosis/debugging purposes. reply fragmede 11 hours agoparentA plugin for graphana or datadog/similar would be amazing. a ping at one frequency for a request hitting the load balancer, a ping at a different frequencies for a request hitting a given endpoint, a bloop for a request hitting Kafka/the queue, a tone that lasts for as long as the job takes to process the job. a bong for a request hitting the db lasting as long as the query takes. the combined cacofony of sound would grow to feel comfortable when the site is properly operational. and then, with it just sitting open in the background, if something is off, someone could immediately tell without sitting there watching graphs when their brain subconsciously says something happened to the usual pitter patter of the machine operating. reply nextaccountic 4 hours agorootparentSomething like this for Wikipedia http://listen.hatnote.com/ https://en.wikipedia.org/wiki/Listen_to_Wikipedia reply leeoniya 6 hours agorootparentprevwe had one hackathon project a couple years ago at Grafana that used audio for tracing trendlines for a11y :) reply thwarted 14 hours agoparentprevYes, for network related activity. Peep. https://github.com/the-real-neil/peep Previously discussed on HN https://news.ycombinator.com/item?id=33017337 reply jafarlihi 13 hours agoparentprevRelevant to the auditory monitoring is my project called sysm: https://github.com/jafarlihi/sysm It gives you a framework for configuring such audio pieces. reply pcloadletter_ 11 hours agoprevThis is a pretty funny idea. Love seeing this kind of creativity. reply pcthrowaway 15 hours agoprev> Geiger: AudioContext did not start. To enable Geiger, you need to give permission to play audio on this page. anyone know how to do this in chrome? reply __float 15 hours agoparentThere's a small \"settings\" button to the left of the URL. Click it, and if it shows Sound already, enable it. Otherwise, click \"Site settings\" and enable it from that list. reply skykooler 11 hours agorootparentIs there a way to do this in Firefox? reply kristiandupont 3 hours agorootparentI am having trouble making it work on Firefox. I guess I could add an option to show a little button. Playing audio is allowed, it's the autoplay aspect that isn't. reply oceanparkway 5 hours agoprevHilarious/great. How did you think of this? reply kristiandupont 2 hours agoparentThank you! It was just thinking of ways to get notified of unnecessary re-renders in a way that would be tolerable to have enabled most of the time. Polluting the console or showing visual cues didn't really fit that, so this came up. reply demarq 14 hours agoprevworks like a dream, also surprisingly bearable to just leave it running during development not just when debugging. Great work! reply kristiandupont 13 hours agoparentThank you! The only concern is that it adds overhead as well, but it doesn't seem to be too bad. reply ipsum2 14 hours agoparentprevA more pleasant sound (not replicating a literal Geiger counter) would be more useful imo. reply GuB-42 13 hours agorootparentMaybe the unpleasant sound is a feature, not a bug. reply solardev 13 hours agorootparentI wonder if you can make a song out of it by using juuuuuust the right performance profile, tailoring your async loops and such just right. reply ColonelPhantom 9 hours agorootparentLike Kraftwerk? https://www.youtube.com/watch?v=pyuxz9R2XiY (It's actually the build-up to Radioactivity, but it's often listed as a separate track for some reason.) reply btbuildem 13 hours agoprevBack in the day when computers were slow (like, megahertz slow) you could do this with code execution to help with debugging. If you played with a piece of code long enough you'd get very familiar with the patterns (they were tones, not just ticks) and it was easy to tell when something was off / different. reply seabass-labrax 10 hours agoparentAnd later, when computers weren't so slow but still required multiple fans and HDDs (using real metal discs!) you got an auditory indication of resource utilisation. I do wonder what we'll say in the future when we look back at computers from this time - perhaps it won't be so much an auditory clue, but the subtle feel of one's phone getting warm in your hand when it is running all cores at full clock? reply CapsAdmin 7 hours agoparentprevWith my speaker setup I always had slight gpu coil whine from gpu usage. This has helped me a few times to figure out if the gpu is doing any work at all when trying to figure out why something in ie pytorch is slow. reply jitl 15 hours agoprevGoing to install this and see how much faster we get reply mhh__ 9 hours agoprev [–] I had something like this going for L2 cache misses a while ago reply a1o 8 hours agoparent [–] That's pretty cool! Do you still happen to have it somewhere? How did you do the detection? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "React Geiger is a tool that identifies React performance issues by creating audio cues for frequent component rerenders.",
      "It can be easily installed using npm and helps by tracking render times of components when wrapped.",
      "Users have the flexibility to customize settings like threshold time and rendering phase to focus on particular performance aspects, but keep in mind React Geiger requires React.Profiler, disabled by default in production builds."
    ],
    "commentSummary": [
      "React Geiger is a performance profiling tool utilizing sound to detect unnecessary re-renders in code, garnering praise and prompting discussions about similar projects like network activity monitoring.",
      "Users have proposed enhancements to the sound design and mentioned the idea of crafting a song around performance profiles.",
      "The tool is perceived as both creative and beneficial for developers, offering a new perspective on optimizing code efficiency."
    ],
    "points": 137,
    "commentCount": 30,
    "retryCount": 0,
    "time": 1710008125
  },
  {
    "id": 39653895,
    "title": "Exploring the Power of Call-by-Push-Value",
    "originLink": "https://thunderseethe.dev/posts/bet-on-cbpv/",
    "originBody": "I'm betting on Call-by-Push-Value March 9, 2024 10-minute read Programming Languages You come upon a function argument at a fork in the road. If it takes the left road, it’ll evaluate itself and then be passed to its function. If it takes the right road, it’ll pass itself to the function to be evaluated somewhere down the road (🥁🐍). Let’s bet on which road will be faster. We might suspect this is a rather boring bet. All we have to do is look down each road and see which one is shorter. Fortunately for our wager (and to the dismay of theorists everywhere), this is not the case. We can always construct a situation where evaluating either eagerly or lazily is better. Our gamble touches on an age-old question in programming language semantics, to call-by-value (CBV) or to call-by-name/call-by-need (CBN). They are both evaluation strategies that determine the order in which expressions are evaluated. CBV always evaluates a function argument before passing it to a function (aka eager evaluation). CBN waits to evaluate function arguments until they are used in the function body (aka lazy evaluation). Languages pick one and use it for all their function applications. Rust, Java, JavaScript, Python, and C/C++ use CBV as their evaluation strategy. Haskell and…uh… Haskell use CBN for their evaluation strategy. Alas, whichever call you make, the grass is always greener on the other side. Our CBV languages introduce little spurts of lazy evaluation (closures, iterators, etc.). Our CBN language(s) introduce eager evaluation; Haskell extended its language to make data types eager by default. Call By Push Value Link to heading Given both CBV and CBN languages end up wanting both eager and lazy evaluation, why are we forced to pick one and forgo the other entirely? It turns out we’re not, we just didn’t know that yet when we designed all those languages. …Whoops. Levy’s ‘99 paper Call by Push Value: A Subsuming Paradigm introduces a third option, Call-by-Push-Value (CBPV), to the CBV/CBN spectrum. ‘99 is basically the Cretaceous era if we’re releasing JavaScript frameworks, but it’s quite recent for releasing research. CBPV has just started to penetrate the zeitgeist, and it’s by far the most promising approach to calling-by. Before we can talk about why CBPV is cool, we have to talk about what it is. The big idea of CBPV is to support both CBV and CBN with one set of semantics. It accomplishes this by distinguishing between values and computations. The paper provides a nice slogan to capture the intuition: “a computation does, a value is”. Great, but what does that actually mean? Let’s look at a traditional lambda calculus, to provide contrast for our CBPV lambda calculus: data TypeIntFun Type Type data Term = Var TextInt IntFun Text TermApp Term Term Depending on how we execute our App term, this can be either CBV or CBN (but not both). If we evaluate our argument and apply it to our function, that’s CBV. If we apply our argument to our function unevaluated, that’s CBN. However, we have to pick one: either CBV or CBN. This is due to our values being all mixed up with our computations under one term. CBN wants App to take a computation, but CBV wants App to take a value. Because the two are indistinguishable we’re forced to pick one. Our CBPV lambda calculus fixes this by sundering value and computation in two: -- Type of values data ValType = IntThunk CompType -- Type of computations data CompType = Fun ValType CompType -- !!Return ValType -- A value term data Value = Int IntVar TextThunk Comp -- A computation term data Comp = Fun Text CompApp Comp ValueReturn Value With that CPBV has cut the Gordian Knot, cementing its place as ruler of all Applications. And we love that for them, but wow, it took a lot more stuff to do it (we doubled our line count). It’s now exceedingly clear what’s a value and what’s a computation. One surprising thing is that variables are a value. What if our variable is bound to a computation? CBPV has decreed: “we don’t have to worry about it” (although to be frank I’m a little worried about it). If we look at our new App node, it can also only apply a value. What a relief, that means we can still pass variables to functions. But CBN has us pass around unevaluated arguments, the whole point is that they’re computations we haven’t evaluated to a value yet. How are we going to do that if all our variables are values and all our function arguments are values? The answer lies in a new Value node: Thunk. A Thunk turns a computation into a value. When we want to apply a computation to a function, we first have to turn it into a value using Thunk. This detail is what makes CPBV so useful. Being forced to be explicit about packaging our computations into values increases our ability to reason about work. We can see another example of this in our new Comp node: Fun. Fun can only return a Comp. We can nest Fun nodes (since they are computations) to create multi argument functions. But what if we want to return a function from a function? For that we make use of our final new node Return. Return is the compliment of Thunk. It turns a Value into a Computation. Using Return we can create a function that returns a function like so: (Fun \"x\" (Return (Thunk (Fun \"y\" (Return (Var \"x\")))))) This might seem like pageantry, and for a surface language humans write I’d have to agree. But in a compiler IR, this distinction allows us to generate much more efficient code. The Bet Link to heading Now that we know what CBPV is, we can finally talk about why CBPV is…the future. We know one big advantage is being explicit about where we turn computations into values (and back). To help put that in perspective, look at this monstrosity from Making a fast curry required to apply arguments to a function at runtime: Not only do we have to look up the arity of the function, we have to look up whether we’re calling a function or a closure. Even worse this all has to be done at runtime. All these headaches go away with CBPV. If we see a: (Fun \"x\" (Fun \"y\" (Return (Var \"x\")))) we know we have to apply two arguments. If instead we see: (Fun \"x\" (Return (Thunk (Fun \"y\" (Return (Var \"x\")))))) we can only apply 1 argument, and then we have a value we have to handle before we can do anymore. It’s not even a valid term to apply two arguments to this term Being explicit about values and computations isn’t solely a helpful optimization. It opens the door to do new things we couldn’t before. This is what actually led me to write this article. I kept seeing otherwise unrelated papers employ CBPV to make their work possible. Let’s look at those papers to see the different things CPBV can do: Algebraic Effects (This one is actually covered in Levy’s paper) Implicit Polarized F: Local Type Inference for Impredicativity Kinds Are Calling Conventions Algebraic Effects Link to heading Algebraic effects are concerned with tracking side effects in types. An issue you encounter immediately upon trying to do this is: where can effects happen? Functions can do effects sure, that’s easy. What about records, can they do effects? Well that seems kind of silly, records are values, so let’s say no. But what if the record contains a function that does an effect, what then? CBPV deftly dispatches these quandaries. Effects can appear on any computation type, and only on computation types. Functions return a computation, so they can do effects. But our records are values, so they can only store other values, not effects. If we want to put a function in a record we first have to turn it into a Thunk. So then our record can’t do effects. If we want to perform our record’s function’s effects, we first have to turn it back into a computation with Return. CBPV makes it explicit and clear where (and where not) effects can occur in a program. Implicit Polarized (System) F Link to heading This one has a daunting name, but it’s really cool. It’s talking about type inference (a subject we’re well versed in ). A timeworn tradeoff for type infer-ers is generic types. If you allow a generic type to be inferred to be another generic type, your type inference is undecidable. This puts us in a bind though. A lot of cool types happen to involve these nested generics (called Rank-2, Rank-N, or Impredicative types), and if we can’t infer them we’re forced to write them down by hand. Truly, a fate worse than death, so the types go sorely under-utilized. This paper makes a dent in that problem by allowing us to infer these types, sometimes. Sometimes may seem underwhelming, but you have to consider it’s infinitely better than never. It does this with, you guessed it, CBPV. As we’ve seen, Call by push value makes it explicit when a function is saturated vs when it returns a closure. This turns out to be vital information to have during type inference. Saturated function calls have all their arguments, and these arguments can provide enough information to infer our function type. Even when our function type includes nested generics. That’s quite exciting! All of a sudden our code requires fewer annotations because we made a smarter choice in language semantics. Kinds Are Calling Conventions Link to heading Kinds Are Calling Conventions is a fascinating paper. It employs kinds to solve issues that have plagued excessively generic languages since the first beta redux: Representation - is my type boxed or unboxed Levity - is a generic argument evaluated lazily or eagerly Arity - how many arguments does a generic function take before doing real work To solve these issues, types are given more sophisticated kinds. Instead of type Int having kind TYPE, it would have kind TYPE Ptr. Similarly, we ascribe the type Int -> Int -> Int the kind TYPE Call[Int, Int]. Denoting that it is a function of arity 2 with its kind. This is where CBPV enters the story. To be able to provide the arity in a type’s kind, we first have to know a function’s arity. This can be tricky in CBV or CBN languages that freely interchange functions and closures. Thankfully, CBPV makes it abundantly clear what the arity of any function is, based purely on its type. Kinds Are Calling conventions utilizes this to great effect to emit efficient calling code for higher order functions. The paper also makes use of the fact that CBPV admits both eager and lazy evaluation to track how an argument is evaluated in the kind. All in service of generating more efficient machine code. Who could’ve guessed such a theoretical approach would serve such pragmatic goals. If I had a nickel for every time CBPV shows up in the wild, I’d have 3 nickels. That’s not a lot, but it’s weird that it happened 3 times. Personally, I believe this is because CBPV hits upon a kernel of truth in the universe. Being explicit about what’s a computation and what’s a value allows us to reason about more properties of our programs. Not only does it let us optimize our programs better, but it lets us do new kinds of polymorphism and decide fancier types in finite time. Given how recent CBPV is in terms of research, I think we’re just seeing start of things you can do with CBPV, and we’ll continue to discover more things moving forward. I’m doing my part. You better believe my language will be built atop call-by-push-value.",
    "commentLink": "https://news.ycombinator.com/item?id=39653895",
    "commentBody": "I'm Betting on Call-by-Push-Value (thunderseethe.dev)136 points by todsacerdoti 15 hours agohidepastfavorite47 comments Mathnerd314 9 hours agoI got really excited about call-by-push-value about 15 years ago, when I first encountered it, but at this point I think it is overhyped, particularly the presentation of \"values\" and \"computations\" as duals. For example see http://www.itu.dk/people/mogel/papers/eec.pdf, it is a CBPV-style lambda calculus except computations are a subset of values and there is no duality. Similarly in Levy's book, he discusses \"complex values\" like 1+2 which allow pure computations to happen inside the \"value\" type, more evidence that they are not duals at all. If you squint at CBPV, there is exactly one primitive that sequences computation, `M to x. N`. In Haskell this is just the monadic bind `M >>= \\x -> N` or `do { x The difference is that a fexpr arguments are not evaluated before it's called What's funny is that the actual lambda calculus allows multiple reduction strategies, including lazy evaluation. So I guess the only reason to introduce this distinction is to facilitate impure code, which cares about the difference. reply tonyg 19 minutes agorootparentKernel-style fexprs give macros plus a bunch of reflective abilities that even macros don't provide. Lazy evaluation (alone) doesn't do that. reply kaba0 1 hour agorootparentprevI mean, there are observable differences between the two. An obvious one is to have an infinite recursive function application as a parameter to a function. Depending on whether CBV or CBN is used, you either get non-halting code, or a meaningful result. reply aranchelk 2 hours agoprevPersonally I like how PureScript has done it, as essentially an eager Haskell, they just implemented laziness in a library, you loose some of the elegance of laziness by default, but most of the time I want eager expressions anyway, and when I don’t it’s clear what I’m doing and easy enough to make stuff lazy. https://pursuit.purescript.org/packages/purescript-lazy/3.0.... reply userbinator 4 hours agoprevWho else looked at the title and thought \"isn't that __cdecl?\" and was expecting an article about calling conventions, but got something related yet completely different? For an article about efficiency, there seems to be a noticeable absence of actual instruction sequences for comparison. reply burakemir 11 hours agoprevIt is nice to see CBPV on HN. It is a calculus that deal with a fundamental choice in PL of how to approach evaluation. For a different take, here is the first part of a mini series of posts on CBPV that aims at working out the connection to logic (\"polarised natural deduction\"): https://burakemir.ch/post/cbpv-pt1-small-steps/ reply zozbot234 10 hours agoparentInteresting to see (in the followup posts) that the structure of CBPV seems to lead to \"lazy\" records as a natural choice, contrasting with \"strict\" primitive values and sum types, and \"lazy\" function types. The connection to polarity and focusing is also worthy of note. reply gatlin 8 hours agoprevShameless self promotion: I made a toy CBPV language in TypeScript. It's purely for pedagogy. The idea is that the implementation is essentially an executable small step semantics, and the interop between language and machine is real purdy. https://niltag.net/code/precursor reply dfgdfg34545456 4 minutes agoparentIs the toy language all self contained in that repo? I can see it pulls in some deps, wasn't sure if everything I need to see is in that precursor.controller.ts file or elsewhere. reply jayd16 6 hours agoprevSo in practice using a parameter could be surprisingly very expensive? Are you supposed to thunk all your parameters before grabbing a resource? It seems like it would end up quite cumbersome. C# has object properties that can be values or functions. Etiquette dictates you don't query a database in an object property but I've seen it happen. I'm not even sure what the etiquette here would be. The entire point is to lazily evaluate slow things, right? But I guess its all just for IRs and the idea is a compiler is handling it all anyway? reply falcor84 12 hours agoprevI really want to like this more, but need a better notation reply skybrian 9 hours agoprevI’m wondering what’s gained over writing your thunks as zero-argument functions (etc) in an eager language. reply p4bl0 9 hours agoparentIf I understand correctly, here it is transparent. In an eager language a function needs to know whether it is given a value or a thunk, but here it can be both interchangeably (the thunk only need to have a type that says it returns a value of the same type as what could have been passed directly). reply soulbadguy 9 hours agorootparentIn theory, yes i would agree that they might be a different somewhere. But it's not clear (at least to me that) is this distinction maters in practice. I think the main point here would that a thunk is also a value. And most type system can already express \"a computation which return Type X\" by a value of type \"() -> X\". Adding side effect annotation, it seems to be that a pure function of type \"() -> X\" gives you very close to the same semantic. It's also unclear to me that one should want to allow both value and computation producing values to be used interchangeably. If the goal of CBPV is about better performance, then being able to mix and match both \"kind\" of value is probably not wise (at least without good compiler error messages), same as mixing type of values would break a type system. reply jayd16 6 hours agorootparentprevIs it transparent? It seems like the goal is to be deliberate through explicit calls to thunk(). I guess you mean that a function parameter can be both a value or lambda. reply tel 9 hours agoparentprevThere are a few differences, depending on how you evolve from the CBPV core, but basically other types may be eager or lazy. Functions can be eager (and thus statically know to represent an eager call tree) and sum types can be lazy (deferring choice). These distinctions are all available at the type level. To have thunking only arise from single unit-arg functions kind of depletes the logic of useful structure. But it’s not wrong to see it as an approximation. reply samus 8 hours agoparentprevAren't thunks caching the result? reply erik_seaberg 9 hours agoprevNot sure I see a difference between thunks and futures. reply iso8859-1 9 hours agoparentThunk is a general concept of a small function which is used only to adapt the call or prepare/modify it in some way and then redirect to the proper function. Things like promises, futures, closures, wrappers, stubs or implementations of the concept of virtual function tables in some OO languages (like C++) are just special use cases of thunks (thunks are often used to implement them). Source: https://stackoverflow.com/a/22548372/309483 reply soulbadguy 9 hours agorootparentThe definition that the source is using seems wrong to me. Promise,futures and closures are not used to redirect to anything or wrapper around something else... They are proper compationational object with they own behaviors... reply AtlasBarfed 6 hours agoprevSo you abstract a function argument behind an interface: .get() will evaluate the argument when the specific value is needed. It might be a literal wrapper. .set() will be called when the argument value is set. It either does nothing in the case of a wrapper that is call-by-value, or back-persists the mutation if the set() actually does something. I get that doesn't have the sexy lazy eval / late binding of functional langs, but in the imperative model, is that the basic idea? ------ as an aside, I've found that in my (I'm a groovy programmer preferentially) scripts, where I'm doing bash-ish things with a lot of CLI execution, I do things like this: \"cd somedir; ls -la\". with { } \"df -k\". with {} and I find it very nice to structure the readability, since the meat of these scripts is the command: I define the data, then \"push\" it to the processing I want to do to it. Is there any programming language name for this sort of \"value first\" model? I find it also flows well for chaining operations, whereas something like: saveResults(parseOutput(runCommand(\"df -k\"))) forces you to mentally pop the stack. As you read from right to left you have to push the operations in your mental model until you get to the core of what you're working on, while \"df -k\". with{ runCommand(it) }. with{ parseOutput(it) }. with{ saveResult(it) } is more like the natural order reply Izkata 3 hours agoparentI don't know groovy, but it looks a bit like method chaining, except using an external object/method \"with\" to chain standalone functions? reply kaba0 1 hour agoparentprevI think what you are getting at is usually called piping. Some languages have it inbuilt (usually as a |> operator). reply rezonant 12 hours agoprev [–] Can someone TLDR this? It's pretty thick, and I can't help but think this is a solved problem with the ability to pass functions as arguments. What's the new insight here? reply amluto 11 hours agoparentI can’t. I think it would have been nice if the article defined the terminology it used to describe its toy languages. But it really seemed like it was describing a language like C++ or Rust where a “computation” is a value that happens to be a callable function (std::function or Fn() -> int, for example). A thunk is a value of callable (computable? is this really different?) type, and Return is the magic operation that wraps a value into a trivial closure, like: [val]() { return val; } in C++. Maybe there’s more to it than that. reply Dylan16807 10 hours agorootparentIt feels like half the text is dealing with arity confusion that only comes up because of a particular way of implementing functions. Because I agree, if you take a statically typed call-by-value language and \"introduce little spurts of lazy evaluation\" then don't you get the same flexibility? And you'll also know the arity at all times. There's something in the syntax I don't understand in the middle about unifying things, but then it later says you have to explicitly use \"Return\" on thunks in records to evaluate them, which sounds like the same thing a CBV language does. Are there other benefits I'm not understanding? Does the unification apply only to function parameters? reply amluto 5 hours agorootparentI found it almost impossible to understand. The syntax used for their examples was lisp-like, and the function arity seems unambiguous. There is no implicit currying in lisp as far as I know. Extra-confusingly, the definitions at the start were in a syntax resembling Haskell, but I think it has multiple mistakes. reply crq-yml 11 hours agoparentprevIf you're in eager evaluation land, everything evaluates as you come to it, so you can handle all arguments at runtime by using a stack and no problem is felt. Once we say, \"actually we don't evaluate until it's used\" ambiguity arises. So the context of this is to solve a problem-in-practice with arguments in a lazy evaluation environment, which is that you don't know how many arguments you need to supply without doing the evaluation. reply amluto 9 hours agorootparentI’m very far from an expert in these styles of programming languages, but I’m pretty sure I’m missing something, and it’s not well explained in the OP. The OP uses a lisp-y syntax, fully parenthesized, for its code examples. But function arity isn’t so much an issue in these languages — you can infer it from the parentheses, and there’s no implicit currying. (The OP uses a Haskell-like syntax for its definitions, but I think it contains multiple mistakes, making it very hard to understand.) A language with implicit currying and eager evaluation specifically of function arguments just seems overcomplicated to me. It sounds like a stack machine in which you pop an element off the stack, evaluate it enough to determine its arity, then pop that many more elements, evaluate them, and then apply the function. This sounds unpleasantly dynamic and quite hard to implement efficiently. Am I missing something here? reply analognoise 11 hours agorootparentprevIs that what they mean by “calculating the arity”? reply crq-yml 11 hours agorootparentYes, arity is \"number of arguments\". I don't have expertise in lazy evaluation myself, I've just been exposed to enough of it to explain the motivations. reply charcircuit 10 hours agoparentprev [–] Imagine if functions were polymorphic over the ability to pass in a function as an argument. So both f(1) and f(() => 1) would be valid for a function that takes a number. It would also apply to variables and such too. So \"const a = () => 1; const b = a + a;\" would be possible to do. reply Izkata 4 hours agorootparentAhh k. So like Rebol and Red have worked for decades: >> F: func [A][print type? :A print join \"Arg: \" A] >> F \"Foo\"string Arg: Foo >> F func [][return \"Bar\"] function Arg: Bar I really got spoiled learning Rebol as my first language, I'd already internalized a ton of concepts long before they were introduced during school and college. Higher-order functions were the first time I really realized it, I guess here's another to add to the pile. Even knowing this though, that post really is really obtuse. Definitely could have been better written. Basically in these languages, functions don't have a special syntax to be called, like F(), they just get called when used. So usage of a no-argument function is identical to a variable, and what happens depends on its datatype (function, string, whatever). The special :A syntax is to get the value without evaluating it if it is a function. reply rezonant 10 hours agorootparentprev [–] This is a good explanation. So effectively it's making the lazy/eager distinction controlled by the caller and not the callee. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Call-by-Push-Value (CBPV) is a novel evaluation strategy that merges features from both Call-by-Value (CBV) and Call-by-Name/Need (CBN), offering more efficient code generation and expanded programming language capabilities.",
      "CBPV differentiates values from computations, enhancing type inference, managing side effects, and optimizing higher-order functions, thereby introducing fresh perspectives for program analysis and language enhancement.",
      "The explicit separation of values and computations in CBPV paves the way for improved program comprehension and innovation in language design."
    ],
    "commentSummary": [
      "The post discusses call-by-push-value (CBPV) in lambda calculus, comparing it to lazy evaluation and its application in languages like Haskell and PureScript.",
      "It covers topics such as thunking, function chaining, and function arity, highlighting the advantages and challenges associated with these concepts in programming languages.",
      "The exploration provides insights into the implementation of CBPV and its significance in functional programming paradigms."
    ],
    "points": 136,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1710010616
  },
  {
    "id": 39653125,
    "title": "FDA Grants Breakthrough Status to MM120 for Anxiety Disorder",
    "originLink": "https://www.businesswire.com/news/home/20240307733599/en/MindMed-Receives-FDA-Breakthrough-Therapy-Designation-and-Announces-Positive-12-Week-Durability-Data-From-Phase-2B-Study-of-MM120-for-Generalized-Anxiety-Disorder",
    "originBody": "MindMed Receives FDA Breakthrough Therapy Designation and Announces Positive 12-Week Durability Data From Phase 2B Study of MM120 for Generalized Anxiety Disorder -A single oral administration of MM120 100 µg met its key secondary endpoint and maintained a clinically and statistically significant HAM-A reductions compared to placebo at 12 weeks with a 65% clinical response rate and 48% clinical remission rate- -MindMed plans to hold an End-of-Phase 2 meeting with the U.S. Food & Drug Administration (FDA) in the first half of 2024 and initiate its Phase 3 clinical program in the second half of 2024- -MindMed will host a webcast to discuss data from its Phase 2b study at 8:00 am ET- March 07, 2024 06:00 AM Eastern Standard Time NEW YORK--(BUSINESS WIRE)--Mind Medicine (MindMed) Inc. (NASDAQ: MNMD), (Cboe Canada MMED), (the “Company” or “MindMed”), a clinical stage biopharmaceutical company developing novel product candidates to treat brain health disorders, today announced that FDA has granted breakthrough designation to its MM120 (lysergide d-tartrate) program for the treatment of generalized anxiety disorder (GAD). The Company also announced that its Phase 2b study of MM120 in GAD met its key secondary endpoint, and 12-week topline data demonstrated clinically and statistically significant durability of activity observed through Week 12. “I’ve conducted clinical research studies in psychiatry for over two decades and have seen studies of many drugs under development for the treatment of anxiety. That MM120 exhibited rapid and robust efficacy, solidly sustained for 12 weeks after a single dose, is truly remarkable” Post this MindMed previously announced rapid, clinically meaningful, and statistically significant improvements on the Hamilton Anxiety rating scale (HAM-A) compared to placebo at Week 4, which was the trial’s primary endpoint. MM120 was administered as a single dose in a monitored clinical setting with no additional therapeutic intervention. “I’ve conducted clinical research studies in psychiatry for over two decades and have seen studies of many drugs under development for the treatment of anxiety. That MM120 exhibited rapid and robust efficacy, solidly sustained for 12 weeks after a single dose, is truly remarkable,” stated David Feifel, MD, PhD, Professor Emeritus of Psychiatry at the University of California, San Diego and Director of the Kadima Neuropsychiatry Institute in La Jolla, California and an investigator in the MM120 study. “These results suggest the potential MM120 has in the treatment of anxiety, and those of us who struggle every day to alleviate anxiety in our patients look forward to seeing results from future Phase 3 trials.” MM120 100 µg – the dose with optimal clinical activity observed in the trial – demonstrated a 7.7-point improvement over placebo at Week 12 (-21.9 MM120 vs. -14.2 placebo; p<0.003 Cohen’s d=0.81), with a 65% clinical response rate and a 48% clinical remission rate sustained to Week 12. Clinical Global Impressions - Severity (CGI-S) scores on average improved from 4.8 to 2.2 in the 100-µg dose group, representing a two-category shift from ‘markedly ill’ to ‘borderline ill’ at Week 12 (p<0.004). This clinical activity was rapid, observed as early as study day 2, and durable with further improvements observed in mean HAM-A or CGI-S scores between Weeks 4 and 12. Based on the significant unmet medical need in the treatment of GAD – especially in patients who do not respond to or tolerate currently available medications – along with the initial clinical data from Phase 2b and other research conducted by MindMed, the U.S. Food & Drug Administration (FDA) has designated MM120 for GAD as a breakthrough therapy. The Company plans to hold an End-of-Phase 2 meeting with the FDA in the first half of 2024 and initiate a Phase 3 clinical program in the second half of 2024. “The FDA’s decision to designate MM120 as a breakthrough therapy for GAD and the durability data from our Phase 2b study provide further validation of the important potential role this treatment can play in addressing the huge unmet need among individuals living with GAD,” said Robert Barrow, Chief Executive Officer and Director of MindMed. “We are committed to bringing MM120 to people living with GAD and delivering on the potential of our pipeline to treat serious brain health disorders.” In the Phase 2b study, known as MMED008, MM120 was generally well-tolerated with most adverse events rated as mild to moderate, transient and occurring on dosing day, and being consistent with expected acute effects of the study drug. The most common adverse events (at least 10% incidence in the high dose groups) on dosing day included illusion, hallucinations, euphoric mood, anxiety, abnormal thinking, headache, paresthesia, dizziness, tremor, nausea, vomiting, feeling abnormal, mydriasis and hyperhidrosis. Prior to treatment with MM120, study participants were clinically tapered and then washed out from any anxiolytic or antidepressant treatments and did not receive any form of study-related psychotherapy for the duration of their participation in the study. “As a clinician and clinical researcher, I applaud the way this study was designed by MindMed to isolate the effect of MM120 by removing confounding variables like additional medications and psychotherapy,” said Reid Robison, MD, Psychiatrist and Chief Clinical Officer at Numinus (TSX:NUMI) who has served as adjunct faculty at the University of Utah for the last 12 years and was an investigator in the MM120 study. “It gives me confidence in the data and the positive results give me hope that this may translate into meaningful benefits for my patients.” The primary data analyses from MMED008 have been accepted for presentation at the American Psychiatric Association’s annual meeting, which will be held in New York on May 4-8, 2024. The study is also being submitted for publication in a leading medical journal. Conference Call and Webcast MindMed management will host a webcast at 8:00 am ET today to discuss the Phase 2b results of MM120 in GAD. The webcast and slides will be accessible live under “News & Events” on the Investors page of the Company’s website at https://ir.mindmed.co/ or by clicking here. A replay of the event will be available on MindMed’s website. The webcast will be archived on the Company’s website for at least 30 days after the conference call. About Generalized Anxiety Disorder (GAD) GAD is a common condition associated with significant impairment that adversely affects millions of people. GAD results in fear, persistent anxiety and a constant feeling of being overwhelmed. It is characterized by excessive, persistent, and unrealistic worry about everyday things. Approximately 10% of U.S. adults, representing around 20 million people, currently suffer from GAD, an underdiagnosed and underserved indication that is associated with significant impairment, less accomplishment at work and reduced labor force participation. Despite the significant personal and societal burden of GAD, there has been little innovation in the treatment of GAD in the past several decades, with the last new drug approval occurring in 2004. About MMED008 MMED008 was a multi-center, parallel, randomized, double-blind, placebo-controlled, dose-optimization study. The trial enrolled 198 participants who were randomized to receive a single administration of MM120 at a dose of 25, 50, 100 or 200 µg or placebo. The full analysis set (FAS) for the trial included 194 subjects, those that had at least one valid post-baseline Hamilton Anxiety rating scale (HAM-A) score. Subjects enrolled in the trial presented with severe GAD symptoms (average baseline HAM-A scores of approximately 30). The study's main objective was to determine the dose-response relationship of four doses of MM120 versus placebo as measured by the change in HAM-A from Baseline to Week 4. The key secondary objective of the study was to determine the dose-response relationship of four doses of MM120 versus placebo as measured by the change in HAM-A from Baseline to Week 8. Secondary objectives, measured up to 12 weeks after the single administration, include assessments of anxiety symptoms, safety and tolerability, and other measures of efficacy and quality of life. More information about the trial is available on the MindMed website (mindmed.co) or on clinicaltrials.gov (NCT05407064). About MM120 Lysergide is a synthetic ergotamine belonging to the group of classic, or serotonergic, psychedelics, which acts as a partial agonist at human serotonin-2A (5-hydroxytryptamine-2A [5-HT2A]) receptors. MindMed is developing MM120 (lysergide D-tartrate), the tartrate salt form of lysergide, for GAD and is exploring its potential applications in other serious brain health disorders. About MindMed MindMed is a clinical stage biopharmaceutical company developing novel product candidates to treat brain health disorders. Our mission is to be the global leader in the development and delivery of treatments that unlock new opportunities to improve patient outcomes. We are developing a pipeline of innovative product candidates, with and without acute perceptual effects, targeting neurotransmitter pathways that play key roles in brain health disorders. MindMed trades on NASDAQ under the symbol MNMD and on the Cboe Canada (formerly known as the NEO Exchange, Inc.) under the symbol MMED. Forward-Looking Statements Certain statements in this news release related to the Company constitute “forward-looking information” within the meaning of applicable securities laws and are prospective in nature. Forward-looking information is not based on historical facts, but rather on current expectations and projections about future events and are therefore subject to risks and uncertainties which could cause actual results to differ materially from the future results expressed or implied by the forward-looking statements. These statements generally can be identified by the use of forward-looking words such as “will”, “may”, “should”, “could”, “intend”, “estimate”, “plan”, “anticipate”, “expect”, “believe”, “potential” or “continue”, or the negative thereof or similar variations. Forward-looking information in this news release includes, but is not limited to, statements regarding anticipated upcoming milestones, and progress of trials and studies; results and timing of and reporting of full data from the Company’s Phase 2b clinical trial of MM120; timing of a potential End-of-Phase-2 meeting with the FDA; timing of the initiation of a potential Phase 3 clinical trial of MM120; and the potential benefits of the Company’s product candidates. There can be no guarantees regarding the results of the potential Phase 3 clinical trial or that, following any such trial, MM120 will receive the necessary regulatory approvals. There are numerous risks and uncertainties that could cause actual results and the Company’s plans and objectives to differ materially from those expressed in the forward-looking information, including history of negative cash flows; limited operating history; incurrence of future losses; availability of additional capital; lack of product revenue; compliance with laws and regulations; difficulty associated with research and development; risks associated with clinical trials or studies; heightened regulatory scrutiny; early stage product development; clinical trial risks; regulatory approval processes; novelty of the psychedelic inspired medicines industry; as well as those risk factors discussed or referred to herein and the risks described in the Company’s Annual Report on Form 10-K for the fiscal year ended December 31, 2023, under headings such as “Special Note Regarding Forward-Looking Statements,” “Risk Factors” and “Management’s Discussion and Analysis of Financial Condition and Results of Operations,” and other filings and furnishings made by the Company with the securities regulatory authorities in all provinces and territories of Canada which are available under the Company’s profile on SEDAR at www.sedar.com and with the U.S. Securities and Exchange Commission on EDGAR at www.sec.gov. Except as required by law, the Company undertakes no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise. Contacts For Media Inquiries, please contact: media@mindmed.co For Investor Inquiries, please contact: ir@mindmed.co",
    "commentLink": "https://news.ycombinator.com/item?id=39653125",
    "commentBody": "FDA Designates MM120 (LSD) Breakthrough Therapy for Generalized Anxiety Disorder (businesswire.com)120 points by beefman 16 hours agohidepastfavorite61 comments cpncrunch 13 hours agoIt's just a press release, and it looks like they haven't released anything beyond what was published in another press release in December: https://www.clinicaltrialsarena.com/news/mindmed-trial-anxie... Still no study published, no information about blinding effectiveness. It does say that adverse events include hallucinations, which doesn't bode well for effective blinding. So far there isn't really any strong evidence that hallucinogens including ketamine are more effective than placebo at relieving anxiety or depression (see for example the recent study showing no difference to placebo for ketamine under anaesthetic), even though we all strongly wish they were. reply swatcoder 13 hours agoparent> see for example the recent study showing no difference to placebo for ketamine under anaesthetic That's not counterevidence to ketamine's efficacy, it's evidence that the efficacy, if prior studies soundly demonstrated it, relies somehow on the user not being anesthetized during the treatment. I don't think that surprises many advocates of psychodelic or hallucinogenic therapies. And these are not the first class of treatments where blinding isn't practical. It does confound some forms of analysis when you can't acheive real blinding, but we've devised many alternative forms of analysis that we take as scientifically \"good enough\" to treat something as medicine. reply WhitneyLand 13 hours agorootparentKetamine is an anesthetic. Seems like the study raises serious questions about efficacy. reply sterlind 13 hours agorootparentKetamine is a dissociative that's used as an anesthetic. General anesthesia is a different beast. The precise mechanism GAs use isn't understood, but they cause slow waves of electrical activity to wash over the brain, constantly resetting neural networks and preventing communication, leading to coma. This includes breathing, which is why the patient needs to be intubated. Ketamine doesn't stop respiration. It causes profound dissociation and hallucinations, but I don't think it causes coma. It's definitely doing different things than GAs, at least. So it doesn't seem unreasonable that ketamine wouldn't work if you're in a coma. I'd be surprised if LSD did either. Or anything, for that matter. There's not a lot metabolically happening in a neuron under coma. reply pas 12 hours agorootparentPropofol works even on Venus flytrap plants. That's how deep this particular 'off' switch seems to be wired in. (It's blocking the presynaptic sodium and calcium channels.) reply jdietrich 13 hours agoparentprev>(see for example the recent study showing no difference to placebo for ketamine under anaesthetic) Ketamine is an anaesthetic and has the same mechanism of action as inhalational anaesthetics. A trial of ketamine+anaesthetic vs placebo+anaesthetic might indicate that ketamine is no better than placebo, but equally it could indicate that general anaesthesia is an effective antidepressant. Your NMDA receptors don't particularly care whether they're being antagonised by ketamine, nitrous oxide or isoflurane. https://www.nature.com/articles/s44220-023-00140-x reply WarOnPrivacy 12 hours agoparentprev> It's just a press release [and seemingly not] beyond what was published in December Stock spike on Thru but not Dec (toMM120 is a tartrate salt form of lysergide, a semi-synthetic hallucinogen commonly known as LSD reply DenisM 14 hours agoparentI wonder what is the significance of it being a salt rather than a pure lsd? For d-amphetamine making it a salt produces an effect similar to delayed release. The result is sold as a “more modern” ADHD treatment Vyvanse. So is this achieving similar effect? Flattening the curve, so to speak? Or maybe it’s just to distance itself from the recreational LSD culture? reply isoprophlex 14 hours agorootparentUsually these salts remain chemically stable for longer periods of time. In the case of alkaloids, they become protonated (here LSD-with-a-proton, a positively charged particle; the tartrate being the negative counterion) and as such are thus less susceptible to oxidation. Can't steal negative charge from something that doesn't have it. And with LSD freebase that's not an unnecessary luxury, as it isn't the most stable against decomposition. To answer the question... probably this is the most stable formulation to get it into a pharmacy? I guess like you say, not blatantly calling it LSD helps image building too. With vyvanse, that's actually something else: not a salt but an amino acid covalently bound to amphetamine. This gives a much stronger bond than between tartrate and lsd ions in the salt, one that can be hydrolysed slowly in the gut to produce the active drug. LSD tartrate doesn't have a similar slow release property. reply Scoundreller 12 hours agorootparentprevThe API in Vyvanase isn't a salt of straight amphetamine though. It has a covalent bond to a group that your body/metabolism needs to (I guess enzymatically) break down to release the amphetamine. More of a prodrug. reply jdietrich 13 hours agorootparentprev> I wonder what is the significance of it being a salt rather than a pure lsd? The salt is patentable. reply sterlind 13 hours agorootparentNo, Sandoz produced LSD tartarate back in the '50s. It's the common salt form of LSD. The freebase is lipophilic, and is typically dissolved in ethanol, while the salt form is water-soluble, and can be soaked into blotter paper or sublingual tablets. Amazingly, I found a Swiss clinical trial from 2021 (!) comparing the pharmacokinetics of the freebase vs. tartarate in human subjects: https://classic.clinicaltrials.gov/ct2/show/NCT04865653 Switzerland is (free)based. reply jdietrich 9 hours agorootparentMM-120 is proprietary, because they've isolated the d isomer. reply philwelch 12 hours agorootparentprevAdderall and Dexedrine are already amphetamine salts. Vyvanse has an extra delayed release mechanism beyond that. reply 0cf8612b2e1e 14 hours agorootparentprevIf nothing else, by being chemically distinct from LSD, it remains a crime to have LSD, but not the salt prescription form. reply pazimzadeh 14 hours agoparentprevprobably allows it to be patented reply csdvrx 15 hours agoparentprevI'm afraid it will be sold at a price most will not be able to afford, especially without health insurance. I'd support decriminalization efforts instead: we let people with cancer get weed from a dispensary. Why not let veterans and other people with a generalized anxiety disorder get LSD the same way? reply sva_ 15 hours agorootparentI'm generally in favor of letting (healthy) adults decide what they consume (in particular hallucinogens), but I'm not sure it is a good idea to just hand them out to people with real psychiatric disorders without any therapeutic guidance. reply evilDagmar 8 hours agorootparentI wouldn't even hand it to normal, \"stable\" people without some guidance. Not everyone handles losing their marbles with grace and aplomb. It's not in the average person's skillset to be able to say, \"it's just the drugs\" and keep their cool. reply fnordfnordfnord 15 hours agorootparentprevSame as Ketamine. Ketamine therapy is available now but, the cost very high so, it is practically unavailable to most. reply radicaldreamer 16 hours agoprevTruly excellent news… we’re now at 3 psychedelics given breakthrough designation by the FDA for different mental health indications: MDMA (ptsd), psilocybin (depression, anxiety), LSD There are startups testing 2CB, DMT and some more exotic psychedelics for various indications as well. reply canadiantim 15 hours agoparentDon't forget Ketamine. It's truly remarkable for depression and PTSD, arguably better than mdma or psilocybin because it's not as psychadelic but produces profound effects regardless. I took my mom to a ketamine clinic recently and up till then my biggest concern for her health was that she was always stuck in fight or flight, constant 11/10 stress levels, what I would call PTSD or complex PTSD. Anyway, after just 1 visit to ketamine clinic (2 low-medium dose sessions only), she's completely cured of her stress disorder. It's remarkable. This was a long-standing pattern for my mom and ketamine (with the help and guidance of an incredible therapist too) fixed it in a weekend, basically. reply noman-land 15 hours agorootparentHow does it actually work? Ketamine is a tranquilizer, right? Is it like a therapy session you do using Ketamine to turn off your stress so you can think clearly? How does it have lasting effects? reply xk_id 8 hours agorootparentKetamine has three distinct effects which are a function of dose. At medium doses it’s a recreational psychedelic and at large doses it’s an anaesthetic. Its highest efficacy against depression is seen in the micro-dose range, before any perceptual (psychedelic) effects start. At that dose, it causes a rapid release of neurotrophic factors, which restores the function of neuronal spines. Those spines are typically damaged by chronic exposure to stress. It may not necessarily be supported by a verbal insight into your emotional difficulties, although the brief period of neuroplasticity can lead to that. There is usually complete relief from depressive symptoms within 24-48h, but it only lasts for as long as chronic exposure to stress doesn’t start again. In some patients this means that symptoms can return within a couple of weeks, unfortunately. reply noman-land 5 hours agorootparentFascinating, thank you. reply fragmede 14 hours agorootparentprevI can't speak for GP, but when it's combined with talk therapy, the ketamine allows the body to lower its defenses so that talk therapy can more successfully be administered, and the combination of the two is what leads to long lasting effects, long after the ketamine has worn off. Ketamine let's the patient open up so talk therapy can get at the underlying issue and resolve that, in ways that talk therapy alone can't solve because the patient's flight /fight response/anxiety won't let them let their guard down to really talk about it. reply xk_id 8 hours agorootparentCompletely wrong, what you wrote is true for MDMA, not ketamine. reply fragmede 8 hours agorootparentwhy not both? reply xk_id 8 hours agorootparentBecause it’s literally wrong and has nothing to do with how Ketamine works or with how it’s used therapeutically according to any and all sources. reply fragmede 8 hours agorootparentInteresting! Can you link some? I'd love to read them. reply xk_id 7 hours agorootparentCheck out the other comments in this thread, i wrote a summary and someone else wrote a personal account. If you want to read more you could search on g scholar for a recent review paper on ketamine infusion therapy. reply canadiantim 14 hours agorootparentprevBasically how it worked was, during the session, my mom would lie down on a couch. I was there with her, therapist on a couch opposite her. She would have a blanket over her (she discovered on the trip also the amazing benefits of weighted blankets, which she now uses to great effect for helping her sleep too). Then the therapist would administer the ketamine via intramuscular injection, it would be a pre-agreed upon dosage based on feedback between you and the therapist. But then yeah, after the injection occurs, there's just some calm relaxing music playing, my mom has an eye cover on and she just lays back and rests. During the initial few minutes generally quite quiet, but she would also share a couple words here and there what she was feeling or seeing, but not really as a way to share more just that was part of her processing it. Generally the therapist and I would not say anything or interfere at all. While I do think my mom was able to kind of get a sense or feeling of / or better sense of proprotion of some psychological things going on inside of her, I suspect a lot of it is simply biochemical. Yes the talk therapy helped and the therapist was amazing, but it wasn't psychotherapy, it was very gentle and I guess helped my mom develop a better sense of proportion. A couple takeaways she had was how certain things weren't as important as others, for example. reply noman-land 5 hours agorootparentReally interesting. Thanks for sharing. reply zoklet-enjoyer 15 hours agoparentprevMDMA isn't psychedelic. Or maybe I never took enough reply drooby 15 hours agorootparentIn my experience, it fits the definition. On higher doses of MDMA I experience mild to moderate closed eye hallucinations when listening to music (morphing shapes). Though I have never had open-eyed hallucinations to any degree. And I would absolutely define it as \"consciousness expanding\" in the sense that having conversations with friends while under its influence opens up aspects of my emotional mind that are very difficult for me to uncover while sober. reply canadiantim 15 hours agorootparentprevIt can be, for sure, but there's also so many different kinds that are sold as MDMA when it's actually a very similar but slightly different molecule. reply zoklet-enjoyer 12 hours agorootparentBack in the day, I could get pure MDMA and several cathinones. I preferred methylone over MDMA reply devin 12 hours agorootparentprevNot sure why you were downvoted. It’s well known that MDA is frequently sold as MDMA. reply j4hdufd8 16 hours agoparentprevwhich startups? reply radicaldreamer 16 hours agorootparentGood list here: https://psychedelicalpha.com/data/psychedelic-drug-developme... reply tsoernes 15 hours agorootparentThere's no mention of 2-CB in that list reply DoodahMan 9 hours agorootparenthttps://psychedelicalpha.com/wp-content/uploads/2023/02/Psyc... may be a better reference. for example, though not specified as 2C-B, Arcadia Medicine's AM-1002 (PTSD) is a phenethylamine. reply tomComb 15 hours agorootparentprevIn this case it is a company called mind medicine. reply DenisM 16 hours agoprev> did not receive any form of study-related psychotherapy for the duration of their participation in the study This is remarkable - IIRC previous studies (X) involved additional psychotherapy, and quite extensively. (X) Huberman Labs. https://youtu.be/fcxjwA4C4Cw?feature=shared (X) “how to change your mind” documentary (Netflix) reply AnthonBerg 15 hours agoparentAs I understand it, the reasons for it working by itself are described here: “Psychedelics and Immunomodulation: Novel Approaches and Therapeutic Opportunities“, A. Szabo (2015). https://doi.org/10.3389%2Ffimmu.2015.00358 Central nervous system inflammation does not feel good. There are many, many known links between mental or emotional ills and inflammation. All the classical serotonin receptor 5-HT2A-activating psychedelics as well as MDMA are profoundly immunomodulatory. They reduce inflammation. reply LoganDark 14 hours agoparentprevThis is great news. I believe in the possible utility of LSD without requiring professional/clinical supervision. I've used it at home quite a bit in the past and it's been extremely useful for processing emotions and trauma, as well as helping calm me down in general. I'm neurodivergent, so it most definitely doesn't work this way for everyone, but it's extremely helpful for me and I hope that one day the law recognizes that. reply croemer 15 hours agoprevWhat is the impact of something being designated a breakthrough by FDA? What changes as a result? reply elektor 14 hours agoparentThe drug gets expedited review and increased assistance from the FDA. It's a good thing to have if you're trying to get it on the US market. reply bufferoverflow 6 hours agoprev\"The most common adverse events (at least 10% incidence in the high dose groups) on dosing day included illusion, hallucinations, euphoric mood, anxiety (LOL), abnormal thinking, headache, paresthesia, dizziness, tremor, nausea, vomiting, feeling abnormal, mydriasis and hyperhidrosis\" reply nukeyoular 15 hours agoprev [–] I can get LSD25 on a casual walk on Haight st. on a Tuesday. Excuse my French here, but fuck the FDA. reply akira2501 14 hours agoparent\"Oh, you have Generalized Anxiety Disorder? Just take a casual walk down Haight street and try to purchase one specific drug from the random 'vendors' there.\" Thanks, Doctor! reply nukeyoular 10 hours agorootparentI can decide to do LSD on my own without asking for permission from another man. reply CPLX 15 hours agoparentprev [–] What could possibly go wrong with this approach to drug distribution? It seems perfect from a policy perspective. reply nukeyoular 15 hours agorootparentA lot could go wrong but in San Francisco I'm not really worried about it. If you're really concerned, just make sure your DNM vendor has consistently good user reviews. I unironically trust random weirdos on Haight st and DNM vendors than the federal government. While grandpa Joe's recent campaign speech was very inspiring, there's a very very long way to go before I can ever remotely trust the FDA again. reply chpatrick 15 hours agorootparentYou know LSD was discovered by big pharma right (Sandoz)? reply nukeyoular 14 hours agorootparentYou post like FDA and \"big pharma\" are one and the same. reply heisenbit 14 hours agorootparentThis is a good question. Is a paperwork oriented regulatory regime supportive of formation of mega corps? reply philwelch 12 hours agorootparentprevWith psychedelics in particular, I honestly think a lot more can go wrong by trying to shoehorn them into the medical system as it exists today. You’re talking about something that’s close to a spiritual experience and you think you’re going to do it justice by forcing it through the machine of HMO’s and corporate medical practices? reply LoganDark 14 hours agorootparentprev [–] I would love for it to be better, but isn't LSD a chief victim of the war on drugs (other than fentanyl)? There's no way that there are going to be clean, quality-controlled sources of it any time soon. After all, it's a dangerous hallucinogen, and it's equally dangerous for everyone. Just like how alcohol and nicotine are equally safe for everyone. I say this as someone who's had high doses of LSD25 before and failed to hallucinate much if at all. I don't doubt that people can, but not everyone does. (I support decriminalization, but I want safe regulated sources to be freely available. People shouldn't have to resort to the dark web or to random dealers on the street. People should have sources that are guaranteed safe, just like other supplements.) reply 11 hours agorootparent [2 more] [dead] LoganDark 10 hours agorootparent [–] The post isn't satire but this statement of mine was indeed incredibly sarcastic: > After all, it's a dangerous hallucinogen, and it's equally dangerous for everyone. Just like how alcohol and nicotine are equally safe for everyone. I was indeed poking fun at the fact that LSD is considered unsafe while alcohol and nicotine are allowed to run rampant. I think LSD should not be illegal, and you should be able to source it safely, from regulated sources. I don't want it limited to clinical trials or prescribed treatments - I want to be able to pick it up at a store (or drug store, whatever) and trust that it's not NBOMe or whatever, without having to pay for and handle expensive and dangerous chemical reagents. Then I want to use it at home, in a safe environment, and spend time with my friends and pets. However, LSD is a bit unpredictable. It's not necessarily safer than alcohol or nicotine for everybody. I know that for myself only, and in a strict physical sense (i.e. not really possible to die by LSD25 overdose), but the mental effects can be quite profound for certain people or for certain neurotypes. Whether these effects are positive or negative varies by individual. Of course, a similar thing could be said for alcohol and nicotine. Alcohol can often result in self-destructive behavior and nicotine typically causes some pretty bad addiction and dependence. Which is why I think it's unfair that LSD is treated the way that it is. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MindMed's MM120 program for Generalized Anxiety Disorder (GAD) received FDA Breakthrough Therapy Designation and reported positive durability data from a Phase 2B study, showcasing sustained clinical improvement over 12 weeks with a 65% response rate and 48% remission rate.",
      "Plans include an End-of-Phase 2 meeting with the FDA in the first half of 2024 followed by Phase 3 clinical trials initiation in the second half of the same year.",
      "The study results will be presented at the American Psychiatric Association's annual meeting in May 2024, offering potential new treatment options for the millions affected by GAD."
    ],
    "commentSummary": [
      "The FDA recognizes MM120 (LSD) as a breakthrough therapy for Generalized Anxiety Disorder, despite skepticism about the effectiveness of hallucinogens like ketamine in treating anxiety and depression.",
      "Concerns are raised about blinding issues, adverse events, and efficacy regarding ketamine and other substances used for mental health disorders compared to placebos.",
      "The article covers the mechanism of action, cost, accessibility, and potential benefits of ketamine as an anesthetic and antidepressant, along with personal anecdotes on psychedelic therapy and advocacy for decriminalization and regulated access to psychedelics."
    ],
    "points": 120,
    "commentCount": 61,
    "retryCount": 0,
    "time": 1710004784
  },
  {
    "id": 39656657,
    "title": "Amazon S3: More than an Object Store",
    "originLink": "https://calpaterson.com/s3.html",
    "originBody": "S3 is files, but not a filesystem March 2024 \"Deep\" modules, mismatched interfaces - and why SAP is so painful My very own \"object store\" Amazon S3 is the original cloud technology: it came out in 2006. \"Objects\" were popular at the time and S3 was labelled an \"object store\", but everyone really knows that S3 is for files. S3 is a cloud filesystem, not an object-whatever. I think idea that S3 is really \"Amazon Cloud Filesystem\" is a bit of a load bearing fiction. It's sort of true: S3 can store files. It's also a very useful belief in getting people to adopt S3, a fundamentally good technology, which otherwise they might not. But it's false: S3 is not a filesystem and can't stand in for one. What filesystems are about, and module \"depth\" The unix file API is pretty straightforward. There are just five basic functions. They don't take many arguments. Here are (the Python versions of) these five basic functions: # open a file open(filepath) # returns a `file` # read from that file (moving the position forward) file.read(size=100) # returns 100 bytes # write to that file (moving the position forward) file.write(\"hello, world\") # move the position to byte 94 file.seek(94) # close the file file.close() Well, perhaps I should add an asterisk: I am simplifying a bit. There are loads more calls than that. But still, those five calls are the irreducible nub of the file API. They're all you need to read and write files. Those five functions handle a lot of concerns: buffering the page cache fragmentation permissions IO scheduling and whatever else Even though the file API handles all those concerns, but it doesn't expose them to you. A narrow interface handling a large number of concerns - that makes the unix file API a \"deep\" module. Deep modules are great because you can benefit from their features - like wear-levelling on SD cards - but without bearing the psychic toll of thinking about any of it as you save a jpeg to your phone. Happy days. But if the file API is \"deep\", what sorts of things are \"shallow\"? A shallow module would have a relatively large API surface in proportion to what it's handling for you. One hint these days that a module is shallow is that the interface to it is YAML. YAML appears to be a mere markup language but in practice is a reuseable syntax onto which almost any semantics can be plonked. Often YAML works as the \"Programming language of DevOps\" and programming languages provide about the widest interface possible. Examine your YAML micro-language closely. Does it offer a looping construct? If so, it's likely Turing complete. But sometimes it is hard to package something up nicely with a bow on top. SQL ORMs are inherently a leaky abstraction. You can't use them without some understanding of SQL. So being shallow isn't inherently a criticism. Sometimes a shallow module is the best that can be done. But all else equal, deeper is better. What S3 is about (it is deep too) The unix file API was in place by the early 1970s. The interface has been retained and the guts have been re-implemented many times for compatibility reasons. But Amazon S3 does not reimplement the unix filesystem API. It has a wholly different arrangement and the primitives are only partly compatible. Here's a brief description of the calls that are analogous to the above five basic unix calls: # Read (part) of an object GetObject(Bucket, Key, Range=None) # contents is the HTTP body # Write an (entire) object PutObject(Bucket, Key) # send contents as HTTP body # er, that's it! Two functions versus five. That's right, the S3 API is simpler than the unix file API. There is one additional concept (\"buckets\") but I think when you net it out, S3's interface-to-functionality ratio is even better than the unix file API. But something is missing. While you can partially read an object using the Range argument to GetObject, you can't overwrite partially. Overwrites have to be the whole file. That sounds minor but actually scopes S3 to a subset of the old usecases for files. Filesystem software, especially databases, can't be ported to Amazon S3 Databases of all kinds need a place to put their data. Generally, that place has ended up being various files on the filesystem. Postgres maintains two or three files per table, plus loads of others for bookkeeping. SQLite famously stores everything in a single file. MySQL, MongoDB, Elasticsearch - whatever - they all store data in files. Crucially, these databases overwhelmingly rely on the ability to do partial overwrites. They store data in \"pages\" (eg 4 or 8 kilobytes long) in \"heap\" files where writes are done page by page. There might be thousands of pages in a single file. Pages are overwritten as necessary to store whatever data is required. That means partial overwrites are absolutely essential. A heap file is full of pages (and empty slots). Pages are overwritten individually as necessary. Some software projects start with a dream of storing their data in a 'simple' way by combining two well tested technologies: Amazon S3 and SQLite (or DuckDB). Afterall, what could be simpler and more straightforward? Sadly, they go together like oil and water. When your SQLite database is kept in S3, each write suddenly becomes a total overwrite of the entire database. While S3 can do big writes fast, even it isn't fast enough to make that strategy work for any but the smallest datasets. And you're jettisoning all the transactional integrity that the database authors have painstakingly implemented: rewriting the database file each time throws out all that stuff. On S3, the last write wins. What S3 is good at and what it is bad at The joy of S3 is that bandwidth (\"speed\") for reads and writes is extremely, extremely high. It's not hard to find examples online of people who have written to or read from S3 at over 10 gigabytes per second. In fact I once saturated a financial client's office network with a set of S3 writes. But the lack of partial overwrites isn't the only problem. There are a few more. S3 has no rename or move operation. Renaming is CopyObject and then DeleteObject. CopyObject takes linear time to the size of the file(s). This comes up fairly often when someone has written a lot of files to the wrong place - moving the files back is very slow. And listing files is slow. While the joy of Amazon S3 is that you can read and write at extremely, extremely, high bandwidths, listing out what is there is much much slower. Slower than a slow local filesystem. But S3 is much lower maintenance than a filesystem. You just name the bucket, name the key and the cloud elves will sort out everything else. This is worth a lot as setting backups, replicating offsite, provisioning (which, remember is for IO ops as well as capacity) is pure drudgework. Module depth is even more important across organisations In retrospect it is not a surprise the S3 was the first popular cloud API. If deep APIs are helpful in containing the complexity between different modules with a single system (like your computer) they are even more helpful in containing the complexity of an interaction between two different businesses, where the costs of interacting are so much higher. Consider a converse example. Traditionally when one business wants to get it's computers working with those of another they call it \"integration\". It is a byword for suffering. Imagine you are tasked with integrating some Big Entreprise software horror into your organisation. Something like SAP. Is SAP a deep module? No. The tragedy of SAP is that almost your entire organisation has to understand it. Then you have to reconcile it with everything you're doing. At all times. SAP integration projects are consequently expensive, massive and regularly fail. There isn't much less complexity in S3 than there is in a SAP installation. Amazon named it the \"Simple Storage Service\" but the amount of complexity in S3 is pretty frightening. Queueing theory, IO contention, sharding, the list of problems just goes on and on - in addition too all the stuff I listed above that filesystems deal with. (And can you believe they do it all on-prem?) The \"simple\" in S3 is a misnomer. S3 is not actually simple. It's deep. Contact/etc Please do send me an email about this article, especially if you disagreed with it. If you liked it, you might like other things I've written. Find out when I write something new - by email or RSS . Or follow me on Mastodon. 🇫🇮 I have moved to Helsinki and am working to resurrect the Helsinki Python meetup. If you know someone willing to give a talk or lend us space to meet, please do get in touch. Our first meeting is probably going to happen in early April. Join the group on meetup.com to get an alert when we announce it. 🇫🇮 If you enjoyed this article and as a result are feeling charitable towards me: please try out my side-project, csvbase, or \"Github, but for data tables\". Other notes I don't mean to suggest in any way via this article that S3 is not overpriced for what it is. To rephrase a famous joke about hedge funds, it often seems like The Cloud is a revenue model masquerading as a service model. The concept of deep vs shallow modules comes from John Ousterhout's excellent book. The book is effectly a list of ideas on software design. Some are real hits with me, others not, but well worth reading overall. Praise for making it succinct. A few databases are explicitly designed from the start to us the S3 API for storage. Snowflake was. So it's possible - but not transparently. But snowflake is one of the few I'm aware of (and they made this decision very early, at least by 2016). If you know of others - let me know by email. It isn't just databases that struggle on S3. Many file formats assume that you'll be able to seek around cheaply and are less performant on S3 than on disk. Zipfiles are a key example. Other stuff about S3 that is a matter for regret I genuinely like S3 so did not want to create the wrong impression by including a laundry list of complaints in the middle of the post but anyway here are the other major problems I didn't mention above: The S3 API is only available as XML. JSON was around in 2006 but XML was still dominant and so it's probably not a surprise that Amazon picked XML originally. It is a surprise that Amazon never released a JSON version though - particularly when they made the switch from SOAP to REST, which would have been a good time. It's also a matter for regret that Amazon gave up on maintaining the XSD schema as this is one of the key benefits of XML for APIs. The canonical documentation is just a website now. Criminally, Amazon - like many cloud service providers - have never produced any kind of local test environment. In Python, the more diligent test with the moto library. moto is maintained by volunteers which is weird given that it's a testing tool for a commercial offering. Amazon S3 does support checksums. For whatever reason they are not turned on by default. Amazon makes many claims about durability. I haven't heard of people having problems but equally: I've never seen these claims tested. I am at least a bit curious about these claims. For years Amazon S3 held one other trap for the unwary: eventual consistency. If you read a file, then overwrote it, you might read it back and find it hadn't changed yet. Particularly because it only happened sometimes, for short periods of time, this caused all manner of chaos. Other implementors of S3 didn't copy this property and a few years ago Amazon fixed it in their implementation.",
    "commentLink": "https://news.ycombinator.com/item?id=39656657",
    "commentBody": "S3 is files, but not a filesystem (calpaterson.com)109 points by todsacerdoti 5 hours agohidepastfavorite84 comments leetrout 4 hours agoMy big pet peeve is AWS adding buttons in the UI to make \"folders\". It is also a fiction! There are no folders in S3. > When you create a folder in Amazon S3, S3 creates a 0-byte object with a key that's set to the folder name that you provided. For example, if you create a folder named photos in your bucket, the Amazon S3 console creates a 0-byte object with the key photos/. The console creates this object to support the idea of folders. https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-... reply wkat4242 13 minutes agoparentHmm well there's no folders but if you interact with the object the URL does become nested. So in a sense it does behave exactly like a folder for all intents and purposes when dealing with it that way. It depends what API you use I guess. I use S3 just as a web bucket of files (I know it's not the best way to do that but it's what I could easily obtain through our company's processes). But in this case it makes a lot of sense though I try to avoid making folders. But other people using the same hosting do use them. reply riehwvfbk 4 hours agoparentprevIs that really so different from how folders work on other systems? A directory inode is just an inode. reply klodolph 3 hours agorootparentYes. It is, in practice, incredibly different. Imagine you have a file named /some/dir/file.jpg. In a filesystem, there’s an inode for /some. It contains an entry for /some/dir, which is also an inode, and then in the very deepest level, there is an inode for /some/dir/file.jpg. You can rename /some to /something_else if you want. Think of it kind of like a table: +-------+--------+----------+-------+inodeparentnamedata+-------+--------+----------+-------+1(null)some(dir)| 21dir(dir)| 32file.jpgjpeg+-------+--------+----------+-------+ In S3 (and other object stores), the table is like this: +-------------------+------+keydata+-------------------+------+some/dir/file.jpgjpeg+-------------------+------+ The kind of queries you can do is completely different. There are no inodes in S3. There is just a mapping from keys to objects. There’s an index on these keys, so you can do queries—but the / character is NOT SPECIAL and does not actually have any significance to the S3 storage system and API. The / character only has significance in the UI. You can, if you want, use a completely different character to separate “components” in S3, rather than using /, because / is not special. If you want something like “some:dir:file.jpg” or “some.dir.file.jpg” you can do that. Again, because / is not special. reply Demiurge 3 hours agorootparentLet’s start with the fact that you’re talking to an HTTP api… Even if S3 had web3.0 inodes, the querying semantics would not make sense. It’s a higher level API, because you don’t deal with blocks of magnetic storage and binary buffers. Of course s3 is not a filesystem, that is part of its definition, and reason to be… reply klodolph 3 hours agorootparentI think if you focus too narrowly on the details of the wire protocol, you’ll lose sight of the big picture and the semantics. S3 is not a filesystem because the semantics are different from the kind of semantics we expect from filesystems. You can’t take the high-level API provided by a filesystem, use S3 as the backing storage, and expect to get good performance out of it unless you use a ton of translation. Stuff like NFS or CIFS are filesystems. They behave like filesystems, in practice. You can rename files. You can modify files. You can create directories. reply riehwvfbk 3 hours agorootparentprevThank you, now I understand what the special 0-byte object refers to. It represents an empty folder. Fair enough, basing folders on object names split by / is pretty inefficient. I wonder why they didn't go with a solution like git's trees. reply klodolph 3 hours agorootparent> Fair enough, basing folders on object names split by / is pretty inefficient. I wonder why they didn't go with a solution like git's trees. What, exactly, is inefficient about it? Think for a moment about the data structures you would use to represent a directory structure in a filesystem, and the data structures you would use to represent a key/value store. With a filesystem, if you split a string /some/dir/file.jpg into three parts, “some”, “dir”, “file.jpg”, then you are actually making a decision about the tree structure. And here’s a question—is that a balanced tree you got there? Maybe it’s completely unbalanced! That’s actually inefficient. Let’s suppose, instead, you treat the key as a plain string and stick it in a tree. You have a lot of freedom now, in how you balance the tree, since you are not forced to stick nodes in the tree at every / character. It’s just a different efficiency tradeoff. Certain operations are now much less efficient (like “rename a directory” which, on S3, is actually “copy a zillion objects). Some operations are more efficient, like “store a file” or “retrieve a file”. reply afiori 32 minutes agorootparentI think it is fair to say that S3 (as named files) is not a filesystem and it is inefficient to use it directly as such for common filesystem use cases; the same way that you could say it for a tarball[0]. This does not make S3 a bad storage, just a bad filesystem, not everything needs to be a filesystem. Arguably is it good that S3 is not a filesystem, as it can be a leaky abstraction eg in git you cannot have two tags name \"v2\" and \"v2/feature-1\" as you cannot have both a file and a folder with the same name. For something more closely related to URLs than filenames forcing a filesystem abstraction is a limitation as \"/some/url\", \"/some/url/\", and \"/some/url/some-default-name-decided-by-the-webserver\" can be different.[1] [0] where a different tradeoff is that searching a file by name is slower but reading many small files can be faster. [1] maybe they should be the same, but enforcing it is a bad idea reply umanwizard 1 hour agorootparentprevI think what you’re describing is simply not a hierarchical file system. It’s a different thing that supports different operations and, indeed, is better or worse at different operations. reply inkyoto 2 hours agorootparentprev> […] what the special 0-byte object refers to. It represents an empty folder. Alas, no. It represents a tag, e.g. «folder/», that points to a zero byte object. You can then upload two files, e.g. «folder/file1.txt» and «folder/file2.txt», delete the «folder/», being a tag, and still have the «folder/file1.txt» and «folder/file2.txt» file intact in the S3 bucket. Deleting «folder/» in a traditional file system, on the other hand, will also delete «file1.txt» and «file2.txt» in it. reply dchest 1 hour agorootparentIt's a matter of a client UI implementation. You can't delete a non-empty folder with POSIX API on common filesystems or FTP too. However, there are file managers, FTP clients, and S3 clients that will do that for you by deleting individual files. reply fiddlerwoaroof 3 hours agorootparentprevExcept, S3 does let you query by prefix and so the keys have more structure than the second diagram implies: they’re not just random keys, the API implies that common prefixes indicate related objects. reply klodolph 3 hours agorootparentThat’s kind of stretching the idea of “more structure” to the breaking point, I think. The key is just a string. There is no entry for directories. > the API implies that common prefixes indicate related objects. That’s something users do. The API doesn’t imply anything is related. And prefixes can be anything, not just directories. If you have /some/dir/file.jpg, then you can query using /some/dir/ as a prefix (like a directory!) or you can query using /so as a prefix, or /some/dir/fil as a prefix. It’s just a string. It only looks like a directory when you, the user, decide to interpret the / in the file key as a directory separator. You could just as easily use any other character. reply hiyer 3 hours agorootparentOne operation where this difference is significant is renaming a \"folder\". In UNIX (and even UNIX-y distributed filesystems like HDFS) a rename operation at \"folder\" level is O(1) as it only involves metadata changes. In S3, renaming a \"folder\" is O(number of files). reply fiddlerwoaroof 3 hours agorootparentprev> That’s something users do. The API doesn’t imply anything is related. Querying ids by prefix doesn’t make any sense for a normal ID type. Just making this operation available and part of your public API indicates that prefixes are semantically relevant to your API’s ID type. reply afiori 27 minutes agorootparentby this logic the file \"foo/bar/\" correspond to the filename \"f:o:o:/:b:a:r:/\" (using a different caracter as separator) reply klodolph 3 hours agorootparentprev“Prefix” is not the same thing as “directory”. I can look up names with the prefix “B” and get Bart, Bella, Brooke, Blake, etc. That doesn’t imply that there’s some kind of semantics associated with prefixes. It’s just a feature of your system that you may find useful. The fact that these names have a common prefix, “B”, is not a particularly interesting thing to me. Just like if I had a list of files, 1.jpg, 10.jpg, 100.jpg, it’s probably not significant that they’re being returned sequentially (because I probably want 2.jpg after 1.jpg). reply tuwtuwtuwtuw 2 hours agorootparentprev\"filesystem\" is not a name reserved for Unix-style file systems. There are many types of file system which is not built on according to your description. When I was a kid, I used systems which didn't support directories, but it was still file systems. It's an incorrect take that a system to manage files must follow a set of patterns like the ones you mentioned to be called \"file system\". reply afiori 23 minutes agorootparentTerms evolve and now filesytem and \"system of files\" mean different things, I would argue that not supporting folders or many other file operations make something not a filesystem today. reply keithalewis 3 hours agorootparentprevEven youngsters are yelling at clouds now. Just a different kind of cloud. reply 8organicbits 1 hour agorootparentprevAnother challenge is directory flattening. On a file system \"a/b\" and \"a//b\" are usually considered the same path. But on S3 the slash isn't a directory separator, so the paths are distinct. You need to be extra careful when building paths not to include double slashes. Many tools end up handling this by showing a folder named \"a\" containing a folder named \"\" (empty string). This confuses users quite a bit. It's more than the inodes, it's how the tooling handles the abstraction. reply hnlmorg 1 hour agorootparentCoincidentally I ran into an issue just like this a week ago. A customer facing application failed because there was an object named “/foo/bar” (emphasis on the leading slash). This created a prefix named “/“ which confused the hell out of the application. reply erik_seaberg 3 hours agorootparentprevYou can create a simulated directory, and write a bunch of files in it, but you can't atomically rename it--behind the scenes each file needs to be copied from old name to new. reply ithkuil 1 hour agorootparentprevIn S3 each file is identified with a full path. Not only you cannot rename a single file, but you also cannot rename a \"folder\" (because that would imply a bulk rename on a large number of children of that \"folder\") This is the fundamental difference between a first class folder and just a convention on prefixes of full path names. If you don't allow renames, it doesn't really make sense to have each \"folder\" store the list of the children. You can instead have a giant ordered map (some kind of b-tree) that allows you for efficient lookup and scanning neighbouring nodes. reply lukeh 40 minutes agorootparentUMich LDAP server, upon which many were based, stored entrys’ hierarchical (distinguished) names with each entry, which I always found a bit weird. AD, eDirectory, and the OpenLDAP HDB backend don’t have this problem. reply daynthelife 3 hours agorootparentprevThe payload still contains a list of other inodes though reply highwaylights 19 minutes agoparentprevThis! I’m fine with it, I actually appreciate the logic and simplicity behind it, but the amount of times I’ve tried to explain why “folders” on S3 keep disappearing while people stare at me like I’m an idiot is really frustrating. (When you remove the last file in a “folder” on S3, the “folder” disappears, because that pattern no longer appears in the bucket k/v dictionary so there’s no reason to show it as it never existed in the first place). reply solumunus 4 hours agoparentprevWhat exactly do you think a folder is? It’s just an abstraction for organising data. reply klodolph 3 hours agorootparentS3 doesn’t have that abstraction. The console UI shows folders but they don’t actually exist in S3. They’re made up by the UI. reply 3weeksearlier 3 hours agorootparentIt sounds like they have that abstraction in the UI. But if the CLI and API don't have it too, that's weird. reply klodolph 3 hours agorootparentYeah, the UI and CLI show you “folders”. It’s a client-side thing that doesn’t exist in the actual service. Behind the scenes, the clients are making specific types of queries on the object keys. You can’t examine when a folder was created (it doesn’t exist in the first place), you can’t rename a folder (it doesn’t exist), you can’t delete a folder (again, it doesn’t exist). reply throwitaway222 3 hours agorootparentThat's just an implementation detail of well known filesystems. reply dathery 2 hours agorootparentYes, which is why it's not ideal to reuse the folder metaphor here. Users have an idea how directories work on well-known filesystems and get confused when these fake folders don't behave the same way. reply throwitaway222 3 hours agorootparentprevSimilarly the UI in linux is making up the notion of folders and files in them. But we don't say it doesn't exist. reply kelnos 2 hours agorootparentNo, they're not made up. A folder (or directory) is a specific type of inode, just a file is. S3 doesn't have folders. The UI fakes them by creating a 0-byte object (or file, if you will). It's a kludge. reply dathery 2 hours agorootparentprevDirectories actually exist on the filesystem, which is why you have to create them before use and they can exist and be empty. They don't exist in S3 and neither of those properties do, either. Similarly, common filesystem operations on directories (like efficiently renaming them, and thus the files under them) are not possible in S3. Of course it can still be useful to group objects in the S3 UI, but it would probably be better to use some kind of prefix-centric UI rather than reusing the folder metaphor when it doesn't match the paradigm people are used to. reply DonHopkins 1 hour agorootparentprevSpeaking of user interfaces with optical illustions about directory separators: On the Mac, the Finder lets you have files with slashes in their names, even though it's a Unix file system underneath. Don't believe me? Go try to use the Finder to make a directory whose name is \"Reports from 2024/03/10\". See? But as everyone knows, slash is the ONLY character you're not allowed to have in a file or directory name under Unix. It's enforced in the kernel at the system call inteface. There is absolutely no way to make a file with a slash in it. Yet there it is! The original MacOS operating system used the \":\" character to delimit directory names, instead of \"/\", so you could have files and directories with slashes in their names, justs not with colons in their names. When Apple transitioned from MacOS to Unix, they did not want to freak out their users by reaming all their files. So now try to use the Finder (or any app that uses the standard file dialog) to make a folder or file with a \":\" in its name on a modern Mac. You still can't! So now go into the shell and list out the parent directory containing the directory you made with a slash in its name. It's actually called \"Reports from 2024:03:10\"! The Mac Finder and system file dialog user interfaces actually switche \"/\" and \":\" when they show paths on the screen! Try making a file in the shell with colons in it, then look at it in the finder to see the slashes. However, back in the days of the old MacOS that permitted slashes in file names, there was a handy network gateway box called the \"Gatorbox\" that was a Localtalk-to-Ethernet AFP/NFS bridge, which took a subtly different approach. https://en.wikipedia.org/wiki/GatorBox It took advantage of the fact (or rather it triggered the bug) that the Unix NFS implementation boldly made an end-run around the kernel's safe system call interface that disallowed slashes in file names. So any NFS client could actually trick Unix into putting slashes into file names via the NFS protocol! It appeared to work just fine, but then down the line the Unix \"restore\" command would totally shit itself! Of course \"dump\" worked just fine, never raising an error that it was writing corrupted dumps that you would not be able to read back in your time of need, so you'd only learn that you'd been screwed by the bug and lost all your files months or years later! So not only does NFS stand for \"No File Security\", it also stands for \"Nasty Forbidden Slashes\"! https://news.ycombinator.com/item?id=31820504 >NFS originally stood for \"No File Security\". >The NFS protocol wasn't just stateless, but also securityless! >Stewart, remember the open secret that almost everybody at Sun knew about, in which you could tftp a host's /etc/exports (because tftp was set up by default in a way that left it wide open to anyone from anywhere reading files in /etc) to learn the name of all the servers a host allowed to mount its file system, and then in a root shell simply go \"hostname foo ; mount remote:/dir /mnt ; hostname `hostname`\" to temporarily change the CLIENT's hostname to the name of a host that the SERVER allowed to mount the directory, then mount it (claiming to be an allowed client), then switch it back? >That's right, the server didn't bother checking the client's IP address against the host name it claimed to be in the NFS mountd request. That's right: the protocol itself let the client tell the server what its host name was, and the server implementation didn't check that against the client's ip address. Nice professional protocol design and implementation, huh? >Yes, that actually worked, because the NFS protocol laughably trusted the CLIENT to identify its host name for security purposes. That level of \"trust\" was built into the original NFS protocol and implementation from day one, by the geniuses at Sun who originally designed it. The network is the computer is insecure, indeed. [...] From the Unix-Haters Handbook: https://archive.org/stream/TheUnixHatersHandbook/ugh_djvu.tx... Don't Touch That Slash! UFS allows any character in a filename except for the slash (/) and the ASCII NUL character. (Some versions of Unix allow ASCII characters with the high-bit, bit 8, set. Others don't.) This feature is great — especially in versions of Unix based on Berkeley's Fast File System, which allows filenames longer than 14 characters. It means that you are free to construct informative, easy-to-understand filenames like these: 1992 Sales Report Personnel File: Verne, Jules rt005mfkbgkw0 . cp Unfortunately, the rest of Unix isn't as tolerant. Of the filenames shown above, only rt005mfkbgkw0.cp will work with the majority of Unix utilities (which generally can't tolerate spaces in filenames). However, don't fret: Unix will let you construct filenames that have control characters or graphics symbols in them. (Some versions will even let you build files that have no name at all.) This can be a great security feature — especially if you have control keys on your keyboard that other people don't have on theirs. That's right: you can literally create files with names that other people can't access. It sort of makes up for the lack of serious security access controls in the rest of Unix. Recall that Unix does place one hard-and-fast restriction on filenames: they may never, ever contain the magic slash character (/), since the Unix kernel uses the slash to denote subdirectories. To enforce this requirement, the Unix kernel simply will never let you create a filename that has a slash in it. (However, you can have a filename with the 0200 bit set, which does list on some versions of Unix as a slash character.) Never? Well, hardly ever. Date: Mon, 8 Jan 90 18:41:57 PST From: sun!wrs!yuba!steve@decwrl.dec.com (Steve Sekiguchi) Subject: Info-Mac Digest V8 #3 5 I've got a rather difficult problem here. We've got a Gator Box run- ning the NFS/AFP conversion. We use this to hook up Macs and Suns. With the Sun as a AppleShare File server. All of this works great! Now here is the problem, Macs are allowed to create files on the Sun/ Unix fileserver with a \"/\" in the filename. This is great until you try to restore one of these files from your \"dump\" tapes, \"restore\" core dumps when it runs into a file with a \"/\" in the filename. As far as I can tell the \"dump\" tape is fine. Does anyone have a suggestion for getting the files off the backup tape? Thanks in Advance, Steven Sekiguchi Wind River Systems sun!wrs!steve, steve@wrs.com Emeryville CA, 94608 Apparently Sun's circa 1990 NFS server (which runs inside the kernel) assumed that an NFS client would never, ever send a filename that had a slash inside it and thus didn't bother to check for the illegal character. We're surprised that the files got written to the dump tape at all. (Then again, perhaps they didn't. There's really no way to tell for sure, is there now?) reply winwang 3 hours agorootparentprevI'm having a lot of fun imagining this being said to a kid who's trying to buy some folders for school. reply nostrebored 3 hours agoparentprevWeird that it says folders now. I remember it being very strictly called a prefix when I was at AWS. reply paranoidrobot 3 hours agorootparentI think it's just the Web console, It's still prefix in the APIs and CLI. https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObje... reply Izkata 2 hours agorootparentThe web console even collapses them like folders on slashes, further obfuscating how it actually works. I remember having to explain to coworkers why it was so slow to load a large bucket. reply halayli 3 hours agoparentprevI don't know why you are being downvoted, what you said is true and confuses many newcomers. reply klodolph 3 hours agoparentprevI see you getting downvotes, but you’re speaking the honest truth, here. reply zmmmmm 1 hour agoprevThe limitations of S3 (and all the cloud \"file systems\") are quite astonishing when you consider you're paying for it as a premium service. Try to imagine your astonishment if a traditional storage vendor showed up and told you that their very expensive premium file system they had just sold you: - can't store log files because it can't append anything to an existing files - can't copy files more than 5GB - can't rename or move a file When challenged on how you are supposed to make all your applications work with limitations like that, they glibly told you \"oh you're supposed to rewrite them all\". reply Cthulhu_ 55 minutes agoparentThey're not filesystems though, they're object storage or key/value storage if you will. It's intended to store the log files for long term once they're full. You can rename / move a file, but it involves copying and deleting the original; I don't understand why they don't have a shortcut for that, but it probably makes sense that the user of the service is aware of the process instead of hiding it. I'm not sure about the 5GB limit, it's probably documented somewhere as to why that is; possibly, like tweets, having an upper limit helps them optimize things. Anyway there too there's tools, you can do multipart somethings and there's this official blogpost on the subject: https://aws.amazon.com/blogs/storage/copying-objects-greater... Interesting to note maybe in the context of the post; copy, rename, moving large files, all that could be abstracted away, but that would hide the underlying logic - which might lead to inefficient usage of the service - and worse, make users think it's just a filesystem and use it accordingly, but it's not intended or designed for that use case. reply inkyoto 1 minute agoparentprevS3 is an object storage, not a file system. The file system in AWS is called EFS. S3 is not positioned as a substitute for file systems, either. reply umanwizard 1 hour agoparentprevAmazon doesn’t market S3 as a replacement for file systems, that’s why EBS exists. Also, is S3 really “very expensive”? Relative to what? reply vbezhenar 47 minutes agorootparentS3 usually is the cheapest storage, not only for Amazon, but for other clouds. I don’t understand why. reply ozim 28 minutes agoparentprevThese “file systems” are not file systems and I don’t understand why people expect them to be. Some people are creating tools that make those services easier to synch with file systems but that is not intended use anyway. reply throwaway290 1 hour agoparentprevIt's for building things on top. If you want to rename/move/copy data, implement a layer that maps objects to \"filenames\" or any metadata you like (or use some lib). If you want to write logs, implement append and rotation. But I for example don't and won't need any of that and if it helps keep the API simpler and more reliable then I benefit. being a conventional filesystem for S3 would be either a very leaky abstraction or completely different product reply Twirrim 3 hours agoprevS3 is a key value store. Just happens to be able to store really large values. reply YouWhy 3 hours agoprevThe article is well written, but I am annoyed at the attempt to gatekeep the definition of a filesystem. Like literally any abstraction out there, filesystems are associated with a multitude of possible approaches with conceptually different semantics. It's a bit sophistic to say that Postgres cannot be run on S3 because S3 is not a filesystem; a better choice would have been to explore the underlying assumptions; (I suspect latency would kill the hypothetical use case of Postgres over S3 even if S3 had incorporated the necessary API semantics - could somebody more knowledgeable chime in?). A more interesting venue to pursue would be - what other additions could be made to the S3 API to make it more usable on its own right - for example, why doesn't S3 offer more than one filename per blob? (e.g., a similar to what links do in POSIX) reply 8n4vidtmkvmk 40 minutes agoparentIt's important to gatekeep words or they become meaningless. reply zX41ZdbW 3 hours agoparentprevClickHouse can work with S3 as a main storage. This is possible because a table is a set of immutable data parts. Data parts can be written once and deleted, possibly as a result of a background merge operation. S3 API is almost enough, except for cases of concurrent database updates. In this case, it is not possible to rely on S3 only because it does not support an atomic \"write if not exists\" operation. That's why external, strongly consistent metadata storage is needed, which is handled by ClickHouse Keeper. reply afiori 18 minutes agorootparentIs a \"write if not exists\" atomic operation enouhg as a concurrency primitive for database locks? reply bilalq 3 hours agoparentprevThis might be of interest to you: https://neon.tech/blog/bring-your-own-s3-to-neon. There's also the OG Aurora whitepaper: https://www.amazon.science/publications/amazon-aurora-design... reply wodenokoto 14 minutes agoprevIs there a generic name for these distributed cloud file storages? AWS is S3, google is buckets, Azure is blob storage, the open source version is … ? reply dexwiz 8 minutes agoparentObject Storage reply 3weeksearlier 4 hours agoprevI dunno, are features like partial file overwrites necessary to make something a filesystem? This reminds me of how there are lots of internal systems at Google whose maintainers keep asserting are not filesystems, but everyone considers them so, to the point where \"_____ is not a filesystem\" has become an inside joke. reply CobrastanJorji 2 hours agoparentThey are necessary because as soon as someone decides that S3 is a filesystem, they will look at the other cloud \"filesystems,\" notice that S3 is cheaper than most of them, and then for some reason they will decide to run giant Hadoop fs stuff on it or mount a relational database on it or all other manner of stupidity. I guarantee you S3's customer-facing engineers are fielding multiple calls per week from customers who are angry that S3 isn't as fast as some real filesystem solution that the customer migrated from because S3 was cheaper. When people decide that X is a filesystem, they try to use it like it's a local, POSIX filesystem, and that's terrible because it won't be immediately obvious why it's a stupid plan. reply albert_e 1 hour agorootparentIf a customer makes an IT decision as big as running Hadoop or RDBMS with S3 as storage ... but does not consult at least a Associate level AWS Certified architect (who are doke a dozen) for at least one day worth of advice which is probably a couple of hundred dollars at most ... Can we really blame AWS? I am sure none of official AWS documentations or examples show such an architecture. ---- Amazon EMR can run Hadoop and use Amazon S3 as storage via EMR FS. \"S3 mountpoints\" are a feature specifically for workloads that need to see S3 as a file system. For block storage workloads there is EBS and EFS and FSx that AWS heavily advertises. reply karmasimida 25 minutes agoparentprevExactly, especially when the concept of filesystem really is defined before the whole internet scale becomes a thing or reality. Maybe S3 isn't a filesystem according to this definition, but does it really matter to make it one? I doubt it. The Elastic Filesystem is also an AWS product, but you can't really work as one as you have locally, any folder over 20k files basically will timeout if you do a ls. Does it make EFS a filesystem or not? reply fiddlerwoaroof 3 hours agoparentprevYeah, it’s sort of funny how “POSIXish semantics” has become our definition of these things, when it’s just one kind of thing that’s been called a filesystem historically. reply mickael-kerjean 3 hours agorootparentFun experiment I made with my mum, building a storage independent dropbox like UI [1] for anything that implement this interface: type IBackend interface { Ls(path string) ([]os.FileInfo, error) Cat(path string) (io.ReadCloser, error) Mkdir(path string) error Rm(path string) error Mv(from string, to string) error Save(path string, file io.Reader) error Touch(path string) error } My mum really couldn't care less about the posix semantic as soon as she can see the pictures of my kid which happen to be on S3 [1] https://github.com/mickael-kerjean/filestash reply wwalexander 3 hours agorootparentReducing things to basically the interface you laid out is the point of 9p [1], and is what Plan 9’s UNIX-but-distributed design was built on top of. Same inventor as Go! If you haven’t dived down the Plan 9 rabbit hole yet, it’s a beautiful and haunting vision of how simple cloud computing could have been. [1] https://9fans.github.io/plan9port/man/man9/intro.html reply DonHopkins 53 minutes agorootparentprevCan S3 murder your wife like ReiserFS and Reiser4? https://en.wikipedia.org/w/index.php?title=Comparison_of_fil... reply nickcw 38 minutes agoprevGreat article - would have been useful to read before starting out on the journey of making rclone mount (mount your cloud storage via fuse)! After a lot of iterating we eventually came up with the VFS layer in rclone which adapts S3 (or any other similar storage system like Google Cloud Storage, Azure Blob, Openstack Swift, Oracle Object Storage, etc) into a POSIX-ish file system layer in rclone. The actual rclone mount code is quite a thin layer on top of this. The VFS layer has various levels of compatibility \"off\" where it just does directory caching. In this mode, like the article states you can't read and write to a file simultaneously and you can't write to the middle of a file and you can only write files sequentially. Surprisingly quite a lot of things work OK with these limitations. The next level up is \"writes\" - this supports nearly all the POSIX features that applications want like being able to read and write to the same file at the same time, write to the middle of the file, etc. The cost for that though is a local copy of the file which is uploaded asynchronously when it is closed. Here are some docs for the VFS caching modes - these mirror the limitations in the article nicely! https://rclone.org/commands/rclone_mount/#vfs-file-caching By default S3 doesn't have real directories either. This means you can't have a directory with no files in, and directories don't have valid metadata (like modification time). You can create zero length files ending in / which are known as directory markers and a lot of tools (including rclone) support these. Not being able to have empty directories isn't too much of a problem normally as the VFS layer fakes them and most apps then write something into their empty directories pretty quickly. So it is really quite a lot of work trying to convert something which looks like S3 into something which looks like a POSIX file system. There is a whole lot of smoke and mirrors behind the scene when things like renaming an open file happens and other nasty corner cases like that. Rclone's lower level move/sync/copy commands don't bother though and use the S3 API pretty much as-is. If I could change one thing about S3's API I would like an option to read the metadata with the listings. Rclone stores modification times of files as metadata on the object and there isn't a bulk way of reading these, you have to HEAD the object. Or alternatively a way of setting the Last-Modified on an object when you upload it would do too. reply type_Ben_struct 1 hour agoprevTools like LucidLink and Weka go a way to making S3 even more of a “file system”. They break files into smaller chunks (S3 objects) which helps with partial writes, reads and performance. Alongside tiering of data from S3 to disk when needed for performance. reply hnlmorg 1 hour agoparentI don’t know a whole lot about LucidLink but Weka basically uses S3 as a dataplane for their own file system. reply hn72774 1 hour agoprev> Filesystem software, especially databases, can't be ported to Amazon S3 Hudi, Delta, iceberg bridge that gap now. Databricks built a company around it. Don't try to do relational on object storage on your own. Use one of those libraries. It seems simple but it's not. Late arriving data, deletes, updates, primary key column values changing, etc. reply albert_e 1 hour agoparentThere is specifically block storage service (EBS) and falvirs of it like EBS multi-attach and EFS that can ne used if there is a need to port software/databases to the cloud with low level filesystem support. Why would we need to do it on object storage which addresses a different type of storage need. Nevertheless there are projects like EMRFS and S3 file system mount points that try to provide files stem interfaces to workloads that need to see S3 as a filesystem. reply 8n4vidtmkvmk 42 minutes agoparentprevI still don't understand why you'd want to do it in the first place. Just by some contiguous storage. reply hiAndrewQuinn 1 hour agoprevI feel like I understand the lasting popularity of the humble FTP fileserver a bit better now. Thank you. reply globular-toast 1 hour agoprevA filesystem is an abstraction built on a block device. A block device just gives you a massive array of bytes and lets you read/write from them in blocks (e.g. write these 300 bytes at position 273041). A block device itself is an abstraction built on real hardware. \"Write these 300 bytes\" really means something like \"move needle on platter 2 to position 6... etc\" S3 is just a different abstraction that is also built on raw storage somehow. It's a strictly flat key-object store. That's it. I don't know why people have a problem with this. If you need \"filesystem stuff\" then implement it in your app, or use a filesystem. You only need to append? Use a database to keep track of the chain of appends and store the chunks in S3. Doesn't work for you? Use something else. Need to \"copy\"? Make a new reference to the same object in your db. Doesn't work for you? Use something else. S3 works for a lot of people. Stop trying to make it something else. And stop trying to change the meaning of super well-established names in your field. A filesystem is described in text books everywhere. S3 is not a filesystem and never claimed to be one. Oh and please study a bit of operating system design. Just a little bit. It really helps and is great fun too. reply dmarinus 3 hours agoprevI talked to people at AWS who work in RDS Aurora and they hinted they use S3 internally as a backend for MySQL and PostgreSQL. reply readyman 3 hours agoparentBig if true. That was definitely not in the AWS cert I took lol. reply multani 2 hours agorootparentSeparating compute and storage is one of the core idea behind Aurora. They talked about it in several places, for instance: * https://www.amazon.science/publications/amazon-aurora-design... * https://d1.awsstatic.com/events/reinvent/2019/REPEAT_Amazon_... reply gjvc 50 minutes agoprevJFC the people on this thread missing the difference between object storage and a blocks-and-inodes filesystem is alarming reply throwaway892238 2 hours agoprev> The \"simple\" in S3 is a misnomer. S3 is not actually simple. It's deep. Simple doesn't mean \"not deep\". It means having the fewest parts needed in order to accomplish your requirements. If you require a distributed, centralized, replicated, high-availability, high-durability, high-bandwidth, low-latency, strongly-consistent, synchronous, scalable object store with HTTP REST API, you can't get much simpler than S3. Lots of features have been added to AWS S3 over the years, but the basic operation has remained the same. reply inkyoto 4 hours agoprevS3 is a tagged versioned object storage with file like semantics implemented in the AWS SDK (via AWS S3 API's). The S3 object key is the tag. Files and folders are used to make S3 buckets more approachable to those who either don't know or don't want to know what it actually is, and one day they get a surprise. reply readyman 3 hours agoprevnext [2 more] [flagged] smcin 2 hours agoparentTheir writing seems okay to me; which specific parts do you find atrocious? reply danrob 3 hours agoprev [–] Is this guy from the 90s? reply gjvc 19 minutes agoparent [–] sure seems like it reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Amazon S3 is not merely an object store but rather a cloud filesystem for file storage, as discussed in the article.",
      "Contrasting deep Unix file API with the simple S3 API, the article highlights the limitations of S3, like the inability for partial overwrites and slow file listing operations.",
      "The article stresses the complexity of Amazon S3, debunking the simplistic perception created by its name."
    ],
    "commentSummary": [
      "Amazon S3 is an object storage system, not a traditional file system, posing challenges when used as such in app development.",
      "The article delineates disparities in semantics, folder organization, and querying methods between S3 and standard file systems.",
      "It mentions tools, services, and workarounds to improve functionality while using S3 for file storage, underscoring the importance of grasping the variances between object storage and traditional file systems in application development."
    ],
    "points": 109,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1710043886
  },
  {
    "id": 39652422,
    "title": "Schedule iMessage Texts from Text Files Using Python Script",
    "originLink": "https://github.com/reidjs/schedule-texts-from-txt",
    "originBody": "Annoyingly, iPhones don&#x27;t have a great way to schedule messages. This around 100 lines of python to schedule iMessage texts from .txt files on your computer.If this is useful to you, please give it a try and let me know what you think. Thanks.",
    "commentLink": "https://news.ycombinator.com/item?id=39652422",
    "commentBody": "Schedule iMessage Texts from .txt Files (github.com/reidjs)109 points by reidjs 18 hours agohidepastfavorite60 comments Annoyingly, iPhones don't have a great way to schedule messages. This around 100 lines of python to schedule iMessage texts from .txt files on your computer. If this is useful to you, please give it a try and let me know what you think. Thanks. xyst 15 hours agoIf you don’t have an Apple computer but have an iOS device, you can also do something similar with the “Shortcuts.app” + “Calendar.app”. I have a daily shortcut that runs at X time. Shortcut checks a calendar for events, if today contains one or more events. It will parse the text from these events (comma separated fully qualified phone numbers or iMessage accounts), and send the message contained in the body of the event. Added bonus here is that I can also send group messages. If I need to have the message sent on repeat, then I put the cal event on repeat. I could possibly even have templated messages (ie, insert month and year into message), but I haven’t deep dived into that rabbit hole. Downside here though is that you need an iOS device to always be on. reply thedays 8 hours agoparentThis sounds like a good solution. Can you provide an example or two of how you format the events in your calendar to allow them to be sent at a scheduled time by the Shortcuts app? reply dambi0 11 hours agoparentprevI believe you can run shortcuts on an Apple computer too. reply tootahe45 3 hours agoparentprevLast time i checked you need to swipe to confirm every time your automation attempts to send a message? kinda kills the automation part. I was shocked that there was almost nothing to be automated with messages on IOS as third party apps can't even read or send them. The Tasker app for android is great for this kind of thing. reply latexr 11 hours agoprevI like reviewing my scheduled messages before sending (maybe the person has said something in the meantime), so the solution I came up with is a shortcut which first asks for text input, then a contact, then the time. All in the best possible interface in context, no need to worry about special syntax or formatting. The message text is URL encoded, the phone number is auto-retrieved from the contact, then an sms: URL is generated and added to my reminders app. When the time comes, I simply click the link and it auto-populates in Messages, ready to send or tweak. reply reidjs 11 hours agoparentI like your solution a bit more because it doesn’t require scheduling this script to run on a cron or something. How do you URL encode the message? Could you share the whole shortcut reply Zircom 11 hours agorootparentSend Message reply dsalzman 13 hours agoprevI’ve built something similar with ios shortcuts. One shortcut that uses prompts and data jar to schedule and store messages. It also creates a cal event as a reminder to myself. It supports group texts. Then I have three automations that run in the morning, noon, and afternoon that check for scheduled messages and send them. Works well. Happy to share if interest. reply anonymous344 13 hours agoparentwhat's the purpose for this? reply jitl 13 hours agorootparentSometimes I’m up at 4am and want to send a message to someone at a reasonable hour when they’re not going to be in Do-not-Disturb mode, seems like a good enough way to accomplish. I use Slack “schedule tomorrow for 9am” pretty frequently for the same use case. reply dsalzman 13 hours agorootparentprevI use it more as a reminder system. Someone tells me to checkin next week or in a couple days and I can just schedule the text right then so I dont forget. reply pavel_lishin 10 hours agoprevThis is cool. I like code like this that bandaids over someone's problems. I think all of us have things like this laying around, and it's always cool to be reminded of that fact. reply jpalawaga 9 hours agoprevI love scheduled send. I find it amazing iphones still do not have that extremely basic functionality. reply seoulbigchris 5 hours agoparentI remember when all the basic non-smart phones, like the few Samsung flip phones I had when I first moved to Seoul has this very basic ability. This feature was been dropped in the transition to smart phones for some reason. reply jbaber 5 hours agoprevI'm honestly shocked that with all the ways iphone users are supposed to live in a better world than me, they lack this simple, obvious useful ability that the lowliest SMS/MMS user has. reply smt88 4 hours agoparentI loathe being forced to use Apple products because there are so many of these simple missing features. reply sentientslug 3 hours agorootparentI’m not sure how you are in any way forced to use Apple products reply cookie_monsta 5 hours agoparentprevI have honestly never felt the need for this and had to click on a menu that I am ashamed to say I never thought of clicking on but yes, there it is. Scheduled send for SMS. You can even edit the time/ content right there in the UI. Thanks! reply alchemist1e9 16 hours agoprevThis could be insanely useful for me. Thank you! It means I could have a private monitoring approach that send myself a message on events I want notifications on? I didn’t even know iMessage allowed sending a self message. reply daed 15 hours agoparentTelegram bots API works well for this FYI, unless there’s a reason you need it in Messages.app reply baxtr 16 hours agoprevThanks for sharing. What do you use it for mostly? reply reidjs 16 hours agoparentI just built it this morning! I was planning to use it to send myself reminders. reply latexr 12 hours agorootparentWhy not use the Reminders app instead? reply reidjs 8 hours agorootparentWas also planning on using it for sending happy birthday texts reply baxtr 15 hours agorootparentprevAwesome! I wish iMessage had an api so that you didn’t need to go through a computer to do these things. reply Solvency 15 hours agorootparent? Everything goes through a \"computer\"... reply raybb 9 hours agorootparentThey probably meant computer as in a desktop OS instead of from their iPhone. reply asciii 16 hours agoprevVery useful, thanks for sharing! reply Krasnol 7 hours agoprevSignal has this feature build in, btw. I use it mostly with my SO as a reminder we send to each other at certain times. reply Solvency 16 hours agoprevOut of curiosity couldn't one recreate Twilio just by running an extended version of this from a Macbook? You could read all inbound messages from the Messages app and reply as well. You could even hook it up to a local LLM and run a small support agent. Is there ANY reason a small business owner couldn't do this and avoid paying SaaS fees? reply marxisttemp 12 hours agoparent“For a Linux user, you can already build such a system yourself quite trivially by getting an FTP account, mounting it locally with curlftpfs, and then using SVN or CVS on the mounted filesystem. From Windows or Mac, this FTP account could be accessed through built-in software.” People (and corporations) will pay a lot of money to have someone else manage and maintain their infrastructure. reply anonymouse008 15 hours agoparentprevUnfortunately no, Apple has usage limits on iMessage / SMS relaying. Many people hack around this, SendBlue.co being the only long running service, but it's full of the graveyard of folks trying to do this. reply Solvency 15 hours agorootparentWhat does this mean in practice? I leave my Messages app on my laptop open all day and correspond entirely through it with family. Since I'm typing I send messages rapidly at volume. I've never once hit a limit. Think hundreds of responses a day. If an app running on my machine has subclassed the Messages app and is reading strings and sending hit strokes to the (Send) button on my behalf, how can Apple possibly rate limit this? reply anonymouse008 15 hours agorootparentIt means test on prod and find out (lose your main iCloud account... 'bold move Cotton') reply mrweasel 15 hours agorootparentprevIt's probably like those email providers that allows you some number of outbound emails per, but it's like 200 - 1000. High enough that most users won't ever notice, but low enough that there's no way to use the service commercially. reply password4321 13 hours agorootparentprevBy number of different recipients? reply reidjs 16 hours agoparentprevIt only works for iMessage texts, unfortunately. reply dimask 15 hours agorootparentIt can also work for SMSs with some changes in the applescript. We made a very similar tool that use to send automated SMSs to experiment participants 2 times per day. The setup is similar and there is a bash script that is called using cron twice per day and calls a matlab script (similar to the python script here) that calls an applescript. This is the applescript that, in practice, sends iMessage to those with iphone and SMS to those without https://github.com/earlychildcog/automate_sms_to_participant... reply FredPret 16 hours agorootparentprevMight work in areas with huge iMessage market share like North America - I know probably two people with the \"green texts\" reply Solvency 16 hours agorootparentprevBut the Messages application can send texts to non-iPhone numbers... reply reidjs 15 hours agorootparentI tried sending to a non iMessage number, it failed to send, but there may be a way. reply digiconfucius 6 hours agoprevThis is awesome! I think a certain friend of mine would really like it lol. reply anonymouse008 15 hours agoprevHere's an Apple Script moving through iMessage to SMS if required. Make sure to add helpers to update the recipients contact to default to SMS, otherwise you're just cluttering your Messages history with failed messages. -------- tell application \"Messages\" set phoneNumber to \"+15555555555\" set messageToSend to \"This is a test!\" try set iMessageService to (1st account whose service type = iMessage) set iMessageBuddy to participant phoneNumber of iMessageService if exists iMessageBuddy then set theMessage to send messageToSend to iMessageBuddy delay 2 -- Wait for a short time to allow the message status to update if status of theMessage is not \"delivered\" then error \"iMessage not delivered\" else log (\"sent as iMessage to: \" & phoneNumber) end if else error \"Not an iMessage user\" end if on error try set SMSService to (1st account whose service type = SMS) set SMSBuddy to participant phoneNumber of SMSService send messageToSend to SMSBuddy log (\"sent as SMS to: \" & phoneNumber) on error log (\"ERROR: COULD NOT SEND TO: \" & phoneNumber) end try end try end tell reply reidjs 14 hours agoparentAwesome!!!! Thank you reply nlawalker 16 hours agoprevThe use of “computer” throughout got me excited. Requires a Mac, yes? reply anonymouse008 16 hours agoparentYep, is AppleScript Still don’t know how they get around auto send, iMessage required user input last time I tried this [Edit] Shortcuts still require user interaction, apparently mac does not, that's interesting reply HnUser12 14 hours agorootparentOn iOS shortcuts you don’t need user interaction if you disable “show when run” on the shortcut. reply ersamsa 16 hours agorootparentprevnext [8 more] [flagged] aaronbrethorst 16 hours agorootparentI’m surprised you went to the trouble of creating an account on here just to post warmed over, 30 year old “Crapple” insults. reply FirmwareBurner 15 hours agorootparentWhere did you read a crapple insult in his comment? reply ddtaylor 14 hours agorootparentComment is removed but my guess is that he's talking about the general very old flame war style stuff like \"M$\" and \"Microshill\" and \"Crapple\" etc. The \"us vs them\" mentality of computing. reply FirmwareBurner 12 hours agorootparentNo, I read it as son as it got posted, before it was removed and there was nothing about \"crapple\" in it or anything objectively ofensive or that broke HN rules. The removed comment was basically along the lines of \"when people say the word computer, they generally don't think of Apple\" referring in this context to the fact that the app written by OP said it requires a \"computer\", giving the impression it's cross platform on all computers specifically, PCs which are still the majority marketshare in the computer space, yet it only works on macs, therefore it should be more specific about that restriction, which OP later corrected in the readme. That's why I asked, since it seemed like he brought up a fair point that got unnecessarily attacked by someone going off topic and attacking him with false accusations about some imaginary crapple joke, plus a mob flagging it for no reason, which made me disappointed to see on this community. Sometimes I feel like posts that are even remotely critical about Apple or Macs Apple on HN, get flagged and generally attacked in replies with hateful comments. I keep hoping people would be more objective and moderate here and less defensive about a favorite brand. reply marcellus23 12 hours agorootparentI think there's just as much unreasonably anti-Apple activity on HN as there is pro-Apple -- if you think otherwise (in either direction), it's probably your bias showing. reply FirmwareBurner 12 hours agorootparent>I think there's just as much unreasonably anti-Apple activity on HN as there is pro-Appl No there isn't. Pro-Apple comments don't get downvote bombed and flagged for no reason as much as those anti-Apple. If you don't see this it's your bias showing. And what was \"unreasonably anti-Apple\" in that comment that it needed be flagged? By market share it's true, for most people saying \"a computer\" is gonna mean a PC, not just a Mac only. reply marcellus23 10 hours agorootparentSince neither of us actually have any data to show, it's more reasonable to assume that the anti- and pro-Apple behavior is equal than that one is more common. To proclaim, lacking any actual data, that one is more common and that it just happens to be the one that matches up with your preconception, suggests confirmation bias. > And what was \"unreasonably anti-Apple\" in that comment that it needed be flagged? Please show me where I said that comment was unreasonably anti-Apple, or that it deserved to be flagged. reply reidjs 16 hours agoparentprevI'll edit the readme for clarity reply mrweasel 15 hours agoprev [–] So not to be that guy, but why the Python code? You could just use launchctl and AppleScript and forego the Python code? reply joshmanders 15 hours agoparentProbably because they felt more comfortable working in Python than more AppleScript than what was needed. reply ddtaylor 14 hours agoparentprev [–] If given the choice between writing AppleScript or Python I'm picking Python. Maybe Python can generate my AppleScript is really as close as I want to be to AppleScript. reply jitl 13 hours agorootparentYou can write AppleScript with JavaScript syntax these days, it’s not as Python as Python but it’s substantially less AppleScript than AppleScript. reply alwillis 6 hours agorootparentprev [–] Not me—give me AppleScript. I get that it’s fashionable to rag on AppleScript. But for this particular use case—a scriptable app on macOS—AppleScript is the way to go. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author highlights the absence of a built-in feature to schedule messages on iPhones.",
      "They propose a solution using a Python script to schedule iMessage texts from text files on a computer.",
      "Readers are encouraged to experiment with the solution and share their feedback."
    ],
    "commentSummary": [
      "The post explores different methods to schedule and automate messages on iOS devices, such as utilizing a Python script on GitHub, Shortcuts.app + Calendar.app, AppleScript, and the Data Jar tool.",
      "Users exchange their experiences with message scheduling and address workarounds for constraints related to iMessage/SMS relaying.",
      "The discussion also mentions biases towards Apple products and favoring Python scripting over AppleScript on macOS, leading to a resolution to enhance the readme for a better understanding and extended conversation."
    ],
    "points": 109,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1709999412
  },
  {
    "id": 39651356,
    "title": "Unveiling Skiplists in Big Data Systems",
    "originLink": "https://arxiv.org/abs/2403.04582",
    "originBody": "Computer Science > Databases arXiv:2403.04582 (cs) [Submitted on 7 Mar 2024] Title:What Cannot be Skipped About the Skiplist: A Survey of Skiplists and Their Applications in Big Data Systems Authors:Venkata Sai Pavan Kumar Vadrevu, Lu Xing, Walid G. Aref Download PDF Abstract:Skiplists have become prevalent in systems. The main advantages of skiplists are their simplicity and ease of implementation, and the ability to support operations in the same asymptotic complexities as their tree-based counterparts. In this survey, we explore skiplists and their many variants. We highlight many scenarios of how skiplists are useful and fit well in these usage scenarios. We study several extensions to skiplists to make them fit for more applications, e.g., their use in the multi-dimensional space, network overlaying algorithms, as well as serving as indexes in database systems. Besides, we also discuss systems that adopt the idea of skiplists and apply the probabilistic skip pattern into their designs. Subjects: Databases (cs.DB) Cite as: arXiv:2403.04582 [cs.DB](or arXiv:2403.04582v1 [cs.DB] for this version)https://doi.org/10.48550/arXiv.2403.04582 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Lu Xing [view email] [v1] Thu, 7 Mar 2024 15:29:04 UTC (6,629 KB) Full-text links: Access Paper: Download PDF view license Current browse context: cs.DBnewrecent2403 Change to browse by: cs References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=39651356",
    "commentBody": "What Cannot be Skipped About the Skiplist (arxiv.org)107 points by todsacerdoti 18 hours agohidepastfavorite15 comments fancy_pantser 13 hours agoSection 2.3, \"Analysis of p\" is incomplete. The ideal value is 1/e. In most practical applications, you want to start with setting it to 1/e, which is a good speed/memory tradeoff. I tried for years to get Redis and some widely-used libraries to update their default values for everyone's benefit, as this one of my favorite data structures. Ref: http://www.sciencedirect.com/science/article/pii/03043975940... reply anfelor 15 hours agoprevAnother interesting data structure related to skiplists but not mentioned here are zip trees: https://arxiv.org/abs/1806.06726 The are a tree-based version of skiplists and thus more suited to functional programming / immutable datastructures. reply rtheunissen 13 hours agoparentZip trees are novel but their performance (and therefore also skip lists, since they are isomorphic) lacks behind other linked structures like Treaps and especially LBSTs. [1] I personally find skip lists to be overhyped binary search trees in disguise. [1] https://rtheunissen.github.io/bst reply bonzini 11 hours agorootparentAbsolutely trees in disguise, in fact there are deterministic versions of skip lists that are equivalent to B-trees. An 1-2 skip list (where each pointer to next can skip from 1 to 2 pointers on the level below) is isomorphic to a 2-3 tree. reply jpfr 2 hours agoparentprevZip trees are great! For a project I made a version that uses the memory location of the entries to construct the (random) rank on the fly. So it’s a binary tree structure that requires the same memory as a linked list (two pointers) only! https://github.com/open62541/open62541/blob/master/deps/zipt... reply jstanley 1 hour agorootparentI don't know anything about zip trees, but I'd think in a common scenario the memory addresses are reasonably consecutive. Would that be a problem? If not, why not just assign consecutive ranks in the first place? reply kragen 17 hours agoprevthe title makes this review sound a lot less comprehensive than it really is. it covers basically every variant of pugh's skip list ever published, so you can in fact skip most of them but this is the paper you want if you need to look up what variants exist of, say, the interval skip list, and how they compare. as it happens, that's exactly what i needed today gold reply ajross 8 hours agoprevFirst sentence of the abstract: \"Skiplists have become prevalent in systems.\" They have? I've always viewed them as a curiosity. They're a ton easier to understand than balanced trees and have the same performance behavior, which sounds great. But the allocation mess[1] makes them lose to RB or AVL trees in, basically every system I can think of. Is any major software using skiplists as a standard ordered container or map? [1] You either need to pay for Log2(N) pointers per item, or allocate them from a heap with variable header sizes. Both of those choices are really pessimal when compared with fixed-size metadata. Skiplists pretty much can't be intrusive, for example. reply evdubs 7 hours agoparent> Is any major software using skiplists as a standard ordered container or map? Java for concurrent navigable maps. https://docs.oracle.com/en/java/javase/21/docs/api/java.base... > All Known Implementing Classes: ConcurrentSkipListMap Balancing binary search trees suffer from lock contention more than skip lists. reply ajross 6 hours agorootparent> Balancing binary search trees suffer from lock contention more than skip lists. Hm... I guess the argument would be that the various list insertions can be independently synchronized? Certainly lookup is going to be a r/w lock or whatever and basically a wash. I vaguely buy that but would want to see numbers. But that said, the hash made of the heap due to the variable size nodes and lack of intrusivity is going to have exactly the opposite effect for any high performance implementation. Maybe Java doesn't play in that sandbox, I guess. reply fourthark 5 hours agoparentprevPretty sure I learned about skip lists as a lock-free data structure that is relatively easy to reason about (but it was a while ago and I’m not finding confirmation in a quick search). reply senderista 4 hours agorootparentSkip lists are relatively simple to make lock-free, while lock-free (even unbalanced) binary search trees are an absolute nightmare. https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/... reply JadeNB 17 hours agoprevThe full subtitle is \"A Survey of Skiplists and Their Applications in Big Data Systems.\" reply ComputerGuru 17 hours agoprev [–] I thought arXiv papers were all (experimentally) available as HTML for accessibility reasons now, but I can’t find the html link here. Ref: https://blog.arxiv.org/2023/12/21/accessibility-update-arxiv... reply mananaysiempre 17 hours agoparent [–] From your link: > [...] arXiv is now generating an HTML formatted version of all papers submitted in TeX/LaTeX [...] This paper has been submitted as a PDF blob rather than buildable TeX source, it seems. (Otherwise there’d also be a “TeX Source” link on the left.) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper surveys skiplists and their applications in big data systems, known for their simplicity, ease of implementation, and equivalent complexity to tree-based structures.",
      "Various skiplist variants are explored, highlighting their utility in diverse scenarios like multi-dimensional space, network overlaying algorithms, and database indexes.",
      "Systems incorporating skiplists and integrating probabilistic skip patterns are discussed, showcasing their practical implementation in real-world designs."
    ],
    "commentSummary": [
      "Skiplists are praised for their simplicity and efficiency, especially in Java for concurrent navigable maps, amid discussions about their implementation and analysis.",
      "The debate surrounding skiplists includes comparisons to related data structures like zip trees and binary search trees, questioning their practicality and performance in different software systems."
    ],
    "points": 107,
    "commentCount": 15,
    "retryCount": 0,
    "time": 1709989396
  },
  {
    "id": 39655783,
    "title": "Pilots Sleep in Cockpit: A320 Deviates, Lands Safely",
    "originLink": "https://airlive.net/reports/2024/03/09/report-both-pilots-of-an-a320-fall-asleep-in-the-cockpit-for-28-minutes/",
    "originBody": "Mar 9 2024 Reports Both pilots fall asleep on Batik Air Airbus A320 for 28 minutes in a report published by Indonesian authorities. On 25 January 2024, the Airbus A320 was being operated as scheduled passenger flight from Soekarno-Hatta International Airport (WIII), Jakarta to Halu Oleo Airport (WAWW), Kendari and return. The aircraft was operated by two pilots and four flight attendants. As the aircraft reached the cruising altitude of 36,000 feet, both pilots took their headsets off and the cockpit loudspeaker volume was increased. The PIC then asked permission to rest from the SIC and was granted. A few seconds later, the PIC slept and the SIC then took over the PIC duty as PM. The PIC woke up and at 0122 UTC, asked whether the SIC wanted to rest. The SIC responded that he did not want to rest. Both pilots then had a non-related-duty conversation for about 30 seconds and then the PIC continued to sleep. Around 20 minutes later, the SIC readback a Jakarta ACC instruction. A few moments later, the SIC then inadvertently fell asleep. 12 minutes after the last recorded transmission from the SIC, the Jakarta ACC asked BTK6723 how long the aircraft need to fly on the current heading (250°). There was no reply from the pilots. 28 minutes after the last recorded transmission from the SIC, the PIC woke up and was aware that the aircraft was not in the correct flight path. The PIC then saw the SIC was sleeping and woke him up. About the same time, the PIC responded to the call from another pilot and Jakarta ACC. The PIC advised the Jakarta ACC that BTK6723 experienced radio communication problem and currently the problem has been resolved. The flight then continued and landed at Jakarta uneventfully. Category: ReportsBy AIRLIVEMarch 9, 2024 Share this post Share on Facebook Share on X Share on WhatsApp Share on LinkedIn Related posts The NTSB preliminary report about engine fire on Atlas Air Boeing 747 at Miami says there was a loose plug February 10, 2024 NTSB preliminary report shows that 4 bolts holding the door plug of Alaska Airlines Boeing 737 MAX 9 were missing February 7, 2024 REPORT An easyJet A320 descended too low during approach to Geneva Airport January 28, 2024 The BEA releases final report on the serious incident of Air France Boeing 777 difficulties controlling the flight path January 21, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39655783",
    "commentBody": "Both pilots of an A320 fell asleep in the cockpit for 28 minutes (airlive.net)96 points by mfcc64 9 hours agohidepastfavorite90 comments ApolloFortyNine 8 hours ago>The PIC advised the Jakarta ACC that BTK6723 experienced radio communication problem and currently the problem has been resolved. Did they self report after or was there a review triggered somehow? Their excuse actually was pretty impressive honestly, almost like this has happened before. reply seanmcdirmid 8 hours agoprevIt’s actually harder to do nothing and just watch things, it’s its own special kind of fatigue. I wouldn’t be surprised if this doesn’t happen more often. reply gnyman 2 hours agoparentA small anecdote, I learned/realised this when visiting CERN (many years ago) and seeing someone in the control room playing a computer game on a laptop next to his big displays. So I asked and they said something along the lines that yes, it's allowed because otherwise the people would fall asleep, especially during the night shifts when their job is just to sit there and let the experiment run an be ready to react if necessary. This seems like a useful solution, but I guess it's hard to do as a policy as there is a fuzzy line between the game taking too much attention and not being interesting enough. reply dataviz1000 7 hours agoparentprevFor context, I was a private yacht chef for 7 years. On long legs of a trip I had to hold watch at the helm for 3 or 4 hour shifts while everyone else rested for their watch. Staying awake while using auto pilot was a special type of mental anguish. reply wlesieutre 7 hours agorootparentLike the “mostly self driving” car systems where the driver is expected to pay attention well enough to take over if needed reply theoreticalmal 7 hours agorootparentThis is the worst of both worlds, I would (and do) rather just drive “manually” reply throwawaaarrgh 2 hours agorootparentDriving cross country in a car is actually the worst when you're in stop and go traffic, or cars keep slowing down and then speeding up. I can't wait to get my hands on adaptive cruise control because I get so aggravated and tired from having to shift and adjust speed. If I can just sit in one position and listen to comedy podcasts and audio books I do so much better reply dzhiurgis 3 hours agorootparentprevHaving done both, there’s just no going back to boat or car without autopilot. Definitely slept a bit while doing night passage (alcohol). Would be impossible in a car given how much driver monitoring is out there. reply taf2 7 hours agorootparentprevI did delivers up and down the Atlantic in 2000s I remember it being awesome. Granted I was 20 and like the time we got too close to a us aircraft carrier and they launched a helicopter that did a fly over to check us out that was pretty great. We also always had lines out to catch fish and let me tell you when that line caught something didn’t matter if it was your shift or not it was “fish on” everyone jumping out of their bunks to help. Best fish tacos ever. I do remember the captain could be pass out drunk and still dock the 70 footer without issue and then stumble below to pass out. But yeah we slept a lot too but underway maybe 6-7 so plenty of time to fix or react big difference from an airplane or even autopilot car reply auselen 57 minutes agorootparent> captain could be pass out drunk and still dock the 70 footer without issue Brings up memories… This was same with my father, he stopped drinking later but when I was a teenager and stuck somewhere after midnight I would call home and he would say “sure buddy” and come pick me up. On the way back his eyes were almost closed and sometimes we would joke about how the car knows about the roads and can go way back home itself. He is too old now and actually has a 12 meter boat which can’t dock himself alone. reply dataviz1000 3 hours agorootparentprevWe passed an aircraft carrier going up the East Coast while they were doing exercises. They radioed us and made it clear not to come close to the ship. I have video of fighter jets doing low passes over our yacht every 15 minutes or so using us as a practice target. Going South once, as we came towards the inlet at Fernandina Beach on the Florida, Georgia line, a nuclear submarine was leaving port. I was at the helm in the afternoon while everyone else was sleeping. Good thing I was awake because we were met with the Coast Guard helicopter with a mounted machine gun pointed at me and a Coast Guard response (defender class) boat with a .50-caliber machine gun also fixed on me while they sat off our bow. I communicated with them on the radio; they said I should hold my position and not move. The sub came out with two large ships on each side with blast shields on the each ship. reply tasuki 5 minutes agorootparentThis is all very interesting and completely foreign to me! > Coast Guard helicopter with a mounted machine gun pointed at me and a Coast Guard response (defender class) boat with a .50-caliber machine gun also fixed on me while they sat off our bow. Why'd they do that? > they said I should hold my position and not move. Why? > The sub came out with two large ships on each side with blast shields on the each ship. ...why? reply svat 7 hours agoparentprev> I wouldn’t be surprised if this doesn’t happen more often. From context I guess you meant either \"I wouldn’t be surprised if this happens more often\" or \"I would be surprised if this doesn’t happen more often.\" (https://languagelog.ldc.upenn.edu/nll/?cat=273 has many fun examples of this sort of thing) reply seanmcdirmid 5 hours agorootparentOops. And this is what happens when you accidentally double your negatives, thanks for the point out even if it’s too late to edit. reply aaomidi 8 hours agoparentprevOne of the reasons the current \"Self Driving\" cars kinda suck. Majority of the time you're just not doing anything, but still have to be 100% attentive. reply lupire 7 hours agorootparentIt really is comically reversed. Robots are far better than humans at watching for a long time and jumping in to help instantly with an acute problem when needed (like braking or swerving to avoid an obstacle). Humans are better at interpreting a complex scene and making a high level plan. reply lambdasquirrel 7 hours agorootparentprevI've found the self-steering of new cars to be not at all useful for the stated use case. In my car, the self-steering pushes back a bit and deviates from the course ever so slightly so that you have to keep your hands on the wheel. I'd rather steer it myself. But in those moments where I'm trying to find the UI for adjusting some climate setting, and I don't have my eyes on the road, that's when the self-driving is useful. Maybe technology creates its own problems. To be fair, the radar cruise control is nice for long drives. reply fragmede 7 hours agorootparentprevIn the case of Waymo, you're sitting in the back seat and don't have to pay attention to the driving if you don't want to. reply dzhiurgis 3 hours agorootparentprev> still have to be 100% attentive. Starting absolutes is poor. This just an oxymoron. Highways are designed to take attention off. On a chill highway drive I’d guess most drivers are no more than 50% attentive, driver assist or not. reply eesmith 36 minutes agorootparentPerhaps you could interpret \"100% attentive\" as \"at the same level of attentiveness as being without the current generation of 'self driving' technology\"? reply bombcar 8 hours agoprevFirst question - how do we tie this to Boeing? (A joke, of course) Second, interesting to note planes don’t have deadman switches. reply HPsquared 8 hours agoparentUnlike trains, there isn't one action that is basically always safe (stop the train). A dead man switch activating at the wrong time, could itself cause an accident. reply amluto 8 hours agorootparentThat’s true, but there are plenty of other options. For example, a dead-man switch could: Send an alert via transponders that it has been activated. Maintain level flight but avoid terrain. (After a waiting period in which a pilot can deactivate this feature.) Or descend to a safe altitude if cabin pressure is lost. Activate a mode in which the plane could be remotely flown or directed to land itself. Alert flight crew that the pilots are incapacitated. Or the most basic: make some noise to wake up the pilots. reply lazyasciiart 7 hours agorootparentThe existing action is to maintain current settings. A flight in Australia flew across the continent that way, after (theory says) somehow depressurizing during takeoff so everyone passed out. https://en.wikipedia.org/wiki/2000_Australia_Beechcraft_King... IMO that story shows that unless you do the remote control option (which I see as unlikely) it doesn't matter what happens...what can anyone outside the plane do except crash it earlier? reply amluto 5 hours agorootparentThe “descend to a safe altitude if cabin pressure is lost” option may have had a chance of saving those lives. reply pompino 8 hours agorootparentprev>That’s true, but there are plenty of other options. Well we can't settle it in the comments, nor should we. So which of those options can successfully survive a detailed engineering review on its merits? reply JumpCrisscross 8 hours agorootparentprev> Maintain level flight but avoid terrain Your other ideas are good. But this could kill people if it misfires and takes the plane off course and too far from an airfield. reply qingcharles 4 hours agorootparentNot having anyone flying the plane when it is on manual control can also kill people... reply JumpCrisscross 4 hours agorootparent> Not having anyone flying the plane when it is on manual control can also kill people Not as quickly. Routes are programmed into an airliner before takeoff. Those routes are planned with emergency landing in mind. Left to its own devices, a plane flying its flight path is safer than one simply holding FL (while avoiding terrain). reply cloud_line 7 hours agorootparentprevI recall reading that certain aircraft manufacturers do offer more robust security features if the airlines are willing to pay for them. I don't have a link or source handy, but it's entirely possible that these features have been discussed, but through the lens of how much more would it cost to implement them. reply travisjungroth 7 hours agorootparentprevThere are fighter jets that will take over for an incapacitated pilot. I think it just goes to straight and level. reply Johnny555 8 hours agorootparentprevIt doesn't have to stop the plane, it could just trigger a cockpit alarm. reply throwawaaarrgh 8 hours agorootparentOr alert air traffic control, and maybe they can send an alert into the cockpit. But there must be a way to raise an alarm. My guess is basically nobody cares that much about this rare condition. It's much more likely the pilots are incapacitated rather than asleep, in which case the alarm is pointless. But I guess it's not that rare: - https://www.newsweek.com/pilots-boeing-737-both-doze-off-overshoot-airport-two-hour-flight-1735435 - https://jalopnik.com/tale-of-both-pilots-sleeping-during-flight-reminds-us-t-1849014190 - https://www.cnn.com/travel/article/pilots-sleep-cockpit-airline-safety/index.html - https://www.bbc.com/news/uk-24296544 - https://www.cbsnews.com/news/both-pilots-fall-asleep-during-british-airbus-flight-incident-report-reveals/ - https://www.aero-news.net/index.cfm?do=main.textpost&id=A9AAFE58-18F4-40B5-B59A-EBE316BBE878 - https://content.time.com/time/nation/article/0,8599,1932040,00.html reply sand500 8 hours agorootparentprevSome planes can land themselves now: https://discover.garmin.com/en-US/autonomi/#autoland reply zettabomb 8 hours agorootparentAutopilot and autoland have been around for a while, but they still need to be set up by the pilot, only operate under certain conditions, and autoland in particular only works at some airports. This is probably not a solution, not for quite a while at least. reply jxcole 8 hours agorootparentprevEach pilot can have a button they must always press, if both are released loud tritones alarms and flashing will fill the cockpit, something no one can sleep to. reply viraptor 8 hours agorootparentWell... You can. Sleep deprivation is one hell of a drug. After ~23h on a plane without sleep, I slept through a fire alarm at a hotel. It's unlikely that both pilots and other staff would ignore it, but \"no one can sleep to\" threshold is not that low. reply pompino 8 hours agorootparentprevThat doesn't work at all. There are often times like takeoff, landing, dealing with adverse weather events, re-routing, mechanical failure, etc where they're going through a detailed checklist. The last thing you want is some random device that takes attention away from them dealing with a serious problem. reply schoen 8 hours agorootparentprevThat's not impossible, but the pilots' limbs are already largely \"spoken for\" by other controls and tasks, so it would be a harsh tradeoff. reply jamesrom 8 hours agorootparentIf other controls are being actively engaged by the pilot, the need for the button press would be delayed only until there's some continuous period of non-engagement. reply bombcar 7 hours agorootparentExactly - something like positive activation every minute of some control or another or it starts hooting. reply samtho 8 hours agorootparentprevSorry but this a bit ill-informed. First off, you cannot just put an alarm on everything. The sonic experience inside a cockpit is very carefully designed to give pilots the correct information at the correct time. False alarms are not only not appreciated, they are actively dangerous. If a flight experiencing an emergency situation, a blaring alarm that is incorrectly going off can prevent pilots from getting timely information. Airbus have side-sticks (like a game controller), not yokes and you really shouldn’t be inputting on them unless you’re hand flying for whatever reason. In all two-pilot aircraft (all commercial jet aircraft), there are two separate roles that each one assumes: Pilot Monitoring (PM) and Pilot Flying (PF). The PM’s job is usually to run checklists, communicate/operate the radio, check various indicators, and support the PF to fly the aircraft. The captain and first officer swap between these roles en route. The PM should NOT be inputting controls unless there is a good reason to do so, but for safety/redundancy, one side’s controls are never disabled unless a lockout/override is active. Most airlines have a policy to cruise with the autopilot on, which keeps the aircraft on its plotted course at it’s cleared altitude. The time where “flying” comes into play most often is during takeoff and using various levels of ILS from just indications of glide slope to a full autoland. While not fantastic, a cruising airbus will keep its current course and stay airborne if the pilots snooze off. reply k12sosse 8 hours agorootparentCharlie Victor Romeo was a very interesting watch for that cockpit fly-on-a-wall experience reply zettabomb 8 hours agorootparentprevA proper deadman's switch can't just be a button - you could weight it down, or just fall asleep on top of it. Trains commonly use a pedal you have to hold down halfway. Not sure this is really the best idea though, as pilots typically need both hands (and usually feet) free to actually, you know, control the plane. reply lupire 7 hours agorootparentIf the pilots are controlling the plane, they are doing detectable actions and pre-empting the dead person switch. reply ceejayoz 8 hours agorootparentprevA button press could be required, though. reply TaylorAlexander 8 hours agorootparentprevSimple, cut the engines. /s reply a-r-t 8 hours agorootparentDo a barrel roll :) reply readyman 8 hours agorootparentprevAnother of seemingly infinite reasons why trains > planes. reply adrianmonk 7 hours agoparentprev> deadman switches Seems like they could address this by just changing procedures. If one pilot wants to take a nap, require a third crew member to come sit in the cockpit and make sure the other pilot doesn't doze off. When two pilots are awake, they can monitor each other, but if one is (intentionally) asleep, they can't do that, so have someone take over that function. reply apantel 7 hours agorootparentBut you’ll need a fourth person to watch in case all three fall asleep. reply jukea 7 hours agorootparentThe two would have to fall asleep at the same time though. Otherwise, as soon as the SIC falls asleep, the third one would trigger some special protocol (like a kick in the tibia) reply lupire 7 hours agorootparentprevProcedures don't work well when people are incentivized to violate them. Confessing to sleeping on the job is a career threatening move. reply Sayrus 8 hours agoparentprevFollowing flight plan and ensuring the plane doesn't crash is already a great deadman switch for a plane mid flight ! This[1] StackExchange thread does give some pointers as to why that may be. [1] https://aviation.stackexchange.com/questions/81234/is-there-... reply readthenotes1 8 hours agoparentprev\"how do we tie this to Boeing?\" One of the Boeing 737 Max safety features is that the pilots are so anxious flying it that they are too scared to fall asleep reply firebaze 8 hours agoparentprevEasy: * No wheels fell off (https://www.independent.co.uk/travel/news-and-advice/united-...) * No doors departed the plane (https://www.cnn.com/2024/02/06/business/ntsb-boeing-alaska-d...) * No anti-ice ignited the engines (https://www.flightglobal.com/airframers/faa-proposal-targets...) * No gear failure (https://news.ycombinator.com/item?id=39644341) * No unintended pitch-down (https://en.wikipedia.org/wiki/Maneuvering_Characteristics_Au...) * Pilots well rested :) reply adamm255 8 hours agorootparentWell rested now! Sounds like they may have needed extra time on the ground. Sounds like ATC and a nearby plane was trying to get hold of them while they were napping. Wonder how this would have been handled in another part of the world. Unresponsive aircraft for 28 mins… reply nubinetwork 5 hours agorootparentWhile not the exact same situation, it seems the response is to keep trying and to ask nearby planes to find them and get their attention. https://www.youtube.com/watch?v=027yV9p7W5I reply zabzonk 7 hours agoprevi can beat this. my dad was an RAF Vulcan captain and he and his entire crew fell asleep overflying Indonesia going from Australia to UK (they had being delivering to Australia a rocket component in the Vulcan's capacious bomb bay). the flight over Indonesia was completely illegal, but the crew figured that the Indonesian radars could not track the Vulcan (early stealth) and their fighters could not intercept it. anyway, everyone woke up (reason for sleep never identified, afaik - i suspect hangovers) this would be mid-60s. reply hindsightbias 6 hours agoparentLate 50’s, Dad’s F-86 didn’t have a real autopilot but you could slave it to the vor-dme. It dinged when you went over it and heading went to/from. And now you know why I’m here. reply dave333 6 hours agoprevHave a countdown that has to be actively reset by the pilot before it gets to zero or it makes an audible alarm. Can allow it to be turned off manually for busy times or just make any pilot action reset the counter. Can research the optimal counter length but maybe a couple of minutes. reply coumbaya 5 hours agoparentThere is exactly that on high speed trains (at least in France), I wonder why it's not on airplanes. reply edward28 5 hours agoparentprevDeadman switch for pilots. reply kalleboo 7 hours agoprevThe Guardian article [0] mentions > One of the pilots had not rested adequately on the night before the flight, according to the report. > “The second-in-command had one-month-old twin babies. His wife took care of the babies and he assisted while at home,” the report said. More evidence of the importance of mandatory paternal leave. [0] https://www.theguardian.com/world/2024/mar/09/indonesia-open... reply randmeerkat 7 hours agoparent> More evidence of the importance of mandatory paternal leave. With negative population growth being such a concern I’m really surprised that there’s not far reaching, comprehensive, pro-family policies being enacted. Society seems stuck in the “productivity” graveyard spiral. reply theogravity 7 hours agoprevNot familiar with any of this - I'm guessing it's ok for one pilot to be asleep as long as there's another active one? reply thsksbd 7 hours agoparentHappens all the time. Both asleep, though, is a big problem. About ten years ago there was a (Delta?) flight to Vegas (?) with both pilots asleep. They flew past their destination and went on their merry way until a flight attendant check up on them. reply potatoman22 7 hours agoparentprevSounds like it: \"The PIC then asked permission to rest from the SIC and was granted. A few seconds later, the PIC slept and the SIC then took over the PIC duty as PM.\" reply bufferoverflow 6 hours agoprevSo we need an automatic AI system that will watch pilots and sound an alarm if it detects sleeping. reply jwsteigerwalt 7 hours agoprevUntil airlines cease to need a scapegoat, they will keep pilots in the cockpit. reply sva_ 7 hours agoparentI dont really know much of anything about aviation, other than being a passenger, but I feel like taking off and landing is still something that needs a pilot. I've been on some rough landings, and I don't think ML is quite there yet to do it. reply cgeier 26 minutes agorootparentYou don't need ML to do this, there are already auto landing (and auto take off) systems that work very well. The hardest part is taxiing on the airport and taking part in air control procedures doesn't work at all AFAIK. reply ibejoeb 8 hours agoprevI don't know much about the cockpit monitoring systems that Airbus has, but I know every cheap toyota in the past 10 years yells at me if I so much as glance at a billboard. reply freitzkriesler2 8 hours agoprevwhoop whoop Wake Up I know it's an Airbus but I can see this happening in the not so distant future. reply baron816 8 hours agoprev [–] Can someone explain to me why we still need pilots? Could we at least have pilots serve as a backup to a fully autonomous system? reply defrost 8 hours agoparentTakeoffs, landings, and navigating dense air traffic in controlled spaces are all still \"not smooth enough\" for autonomous sytems if human life is valued. Yes, planes can take off and land on auto pilot - but real world conditions throw curve balls, ditto approaches and departures from high traffic airports. Even \"boring\" 10 hour point to point legs that might normally be fully autopilot can be a problem in case of mechanical failures or other unexpected events. reply samtho 8 hours agoparentprevThis is such an “armchair expert” take on this. Planes are not fully autonomous. They will not be for a very long time due to the regulatory environment aviation is entrenched in. reply LM358 7 hours agorootparentFrankly it seems more like an \"SWE take\" more than a regular armchair take. reply syndicatedjelly 4 hours agorootparentSo it’s even more uninformed than a normal armchair take? reply pompino 8 hours agoparentprevBecause the people who own those planes, and people who regulate the airline industry don't want human casualties under their watch - a fairly reasonable concern. Status-quo is not something you typically argue for, its what you need to argue against. At which point you need to make a positive argument with data that can convince them otherwise. reply no_op 6 hours agoparentprevThis is likely achievable in theory now, at least between major airports with ILS-equipped runways, but fully automated systems couldn't handle present traffic coordination procedures. You'd need a series of new standards to replace human-oriented air traffic control with a scheme in which ground computers could directly interface with aircraft flight management systems. Developing something like this and rolling it out on a global basis, in such a safety-critical application, would likely take two or three decades. Not clear it's really worth the trouble, since you'd want backup pilots for unexpected situations anyway. What would probably make more sense is to just add a single-button auto-land feature, that sends an emergency destress call and configures and invokes existing automatic navigation, approach, and landing features to find the nearest appropriate airport and land. Given how rarely this would be used, there wouldn't be a need for the system to navigate complex traffic patterns, as ATC could just clear other aircraft out of the way. Something like this has recently become available for general aviation aircraft, but I haven't heard about anyone working on it for airliners yet. reply stemlord 7 hours agoparentprevThere is no fucking way I'm stepping onto a commercial airliner without highly trained human beings at the helm. That is my SWE/\"stemlord\" take-- complex software systems, or at least the organizations that produce them, are generally not to be trusted with your life. reply smt88 8 hours agoparentprevPilots already serve as a backup to an autonomous system. They're also useful for takeoff and landing. reply wiml 7 hours agoparentprevIn addition to the other reasons - if someone is going to be qualified to fly the plane as backup, they need regular hours of practice. They could get that in a simulator perhaps, or flying practice flights, or ... by flying the actual plane. reply tiagod 2 hours agoparentprevYou would end up in a world where no human pilots remain to land aircraft where the automation isn't ready to do so. reply taspeotis 8 hours agoparentprevYou propose replacing pilots with … pilots? reply tomschwiha 8 hours agoparentprevIANAP. I think a lot people enjoy flying airplanes. I think most landings are manual. Thus pilots highly skilled to land safely also in difficult situations. And instruments can fail. What do you hope for with removing humans in the loop? reply IAmGraydon 8 hours agoparentprevEven if unassisted takeoff and landing were possible, no airline is going to accept the risk of operating such a system. reply barbazoo 8 hours agoparentprevYou’re ignoring the hard part that they don’t yet use 100% autopilot for. reply dkasper 8 hours agoparentprev [–] Edge cases reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Both pilots on a Batik Air Airbus A320 flight from Jakarta to Kendari reportedly fell asleep for 28 minutes, taking turns to rest, leading to a deviation from the flight path.",
      "Despite the pilots' unintended nap causing the aircraft to veer off course, the plane managed to land safely in Jakarta.",
      "-"
    ],
    "commentSummary": [
      "Pilots falling asleep in the cockpit underscores the struggle of staying alert during long shifts, leading to suggestions like using autopilot and deadman switches to prevent fatigue-related incidents.",
      "The debate examines the drawbacks and risks of entirely autonomous aviation systems, with proponents proposing semi-autonomous functions as a middle ground.",
      "Furthermore, discussions encompass the significance of mandatory paternal leave and robust family-friendly policies for pilots, emphasizing their role as backups to autonomous systems."
    ],
    "points": 96,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1710030786
  }
]
