[
  {
    "id": 39575803,
    "title": "New HSR Thresholds and Fees for 2024 Announced",
    "originLink": "https://www.ftc.gov/business-guidance/blog/2024/03/price-fixing-algorithm-still-price-fixing",
    "originBody": "Competition Matters New HSR thresholds and filing fees for 2024 February 5, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39575803",
    "commentBody": "Price fixing by algorithm is still price fixing (ftc.gov)607 points by nabla9 12 hours agohidepastfavorite384 comments thelastgallon 11 hours agoYieldStar software helps landlords set prices for apartments across the U.S: https://www.propublica.org/article/yieldstar-rent-increase-r... \"To arrive at a recommended rent, the software deploys an algorithm — a set of mathematical rules — to analyze a trove of data RealPage gathers from clients, including private information on what nearby competitors charge. For tenants, the system upends the practice of negotiating with apartment building staff. RealPage discourages bargaining with renters and has even recommended that landlords in some cases accept a lower occupancy rate in order to raise rents and make more money. One of the algorithm’s developers told ProPublica that leasing agents had “too much empathy” compared to computer generated pricing.\" reply SoftTalker 9 hours agoparentSay I own a house, and want to rent it out. I'm naturally going to go onto rental search sites and look at what similar houses in the area are renting for, and probably ask something pretty close to that. I would assume this is not illegal because it's using public information and not colluding with any competitors on price. But subscribing to a service that uses an algorithm that does basically the same thing is (might be) illegal? Does it cross the line when I explicitly agree with competitors that we'll all use the same algorithm? Or if we're all just independently using the popular pricing service could that become illegal? Or if the service agreement requires me to not rent for less than their algorithm calculates? reply letmeinhere 8 hours agorootparentThe algorithm is not operating on public info, it is soliciting proprietary pricing and vacancy data that is not available to renters or regulators. That secretive information sharing is the basis of the whole scheme. And the collusion doesn't stop with this information hoarding; the pricing recommendations are as profitable as they are precisely because many property owners in a market are enacting them with the knowledge that a known quantity of their peers have no intent to undercut. Sure, someone can renege on that, but collusion doesn't require that you have an airtight legal contract to bind all parties; after all, such contracts are inherently illegal! reply Terr_ 2 hours agorootparent> Sure, someone can renege on that, but collusion doesn't require that you have an airtight legal contract to bind all parties; after all, such contracts are inherently illegal! Small nitpick, collusion in a general sense is not illegal, but a price-fixing contract/conspiracy would be a crime under the Sherman Antitrust Act. reply jessriedel 8 hours agorootparentprev> That secretive information sharing is the basis of the whole scheme. can you recommend a link that this describes this in detail? reply letmeinhere 8 hours agorootparentThe propublica article linked at the beginning of this thread is how I learned about these parasites. Definitely recommend. https://www.propublica.org/article/yieldstar-rent-increase-r... reply refurb 6 hours agorootparentWhere? All I see is this: \"A company representative said in an email that RealPage “uses aggregated market data from a variety of sources in a legally compliant manner.”\" The only non-public data are it's own customers. But if I'm a massive landlord with multiple units, I have the same advantage? reply trifurcate 6 hours agorootparent> But if I'm a massive landlord with multiple units, I have the same advantage? The entire point is that monopolization confers the same advantage that this scheme does. reply olliej 4 hours agorootparentprevThe whole idea of anti-monopoly laws is to prevent price fixing by market, and there are numerous (illegal) ways to do that: being a monopoly and using that position to set prices that are not representative of market value (both buying and selling. Iirc antitrust in the us started as a result of standard oil setting the price oil would be bought from suppliers). Another illegal option is collusion. That is a group of competitors get together and set a price that they will all use, again independent of actual Market value, just because the colluders have sufficient control of a market that when they set a price people have no choice but to pay it. This is super effective when the market it not fundamentally “free” like housing, gas, power, healthcare, etc. What these companies are doing is providing a tool to launder the collusion between competitors in a market, by having every “competitor” in the market get an “algorithmic” price that is fundamentally tied to the “algorithmic” price they provide every other “competitor”. If these landlords got together in a room and decided the prices as is happening here, it would be more or less immediately subjected to scrutiny. By doing the same thing via a third party and calling it an “algorithm” it is somehow not subject to the same restrictions. reply karmajunkie 8 hours agorootparentprevthe link at the top of this thread does so. reply 1vuio0pswjnm7 1 hour agorootparentprevFor folks who want to learn how these software developers operate: Armas v RealPage (ND California) https://ia801506.us.archive.org/35/items/gov.uscourts.cand.4... Boelens v RealPage (WD Washington) https://ia801504.us.archive.org/27/items/gov.uscourts.wawd.3... Cherry v RealPage (WD Washington) https://ia601403.us.archive.org/33/items/gov.uscourts.wawd.3... Corradino v RealPage (SD Florida) https://ia804709.us.archive.org/0/items/gov.uscourts.flsd.62... Haynes v RealPage (ND Georgia) https://ia801203.us.archive.org/14/items/gov.uscourts.gand.3... Kramer v RealPage (DC) https://ia904705.us.archive.org/0/items/gov.uscourts.dcd.250... Lazarte v RealPage (ND California) https://ia804701.us.archive.org/20/items/gov.uscourts.cand.4... Marchetti v RealPage (SD Florida) https://ia801602.us.archive.org/27/items/gov.uscourts.flsd.6... Morgan v RealPage (WD Washington) https://ia804709.us.archive.org/25/items/gov.uscourts.wawd.3... Navarro v RealPage (WD Washington) https://ia601407.us.archive.org/5/items/gov.uscourts.wawd.31... Parker v RealPage (SD Florida) https://ia804709.us.archive.org/15/items/gov.uscourts.flsd.6... Schmidig v RealPage (ED California) https://ia601603.us.archive.org/30/items/gov.uscourts.caed.4... Silverman v RealPage (SD New York) https://ia601506.us.archive.org/19/items/gov.uscourts.nysd.5... White v RealPage (Massachusetts) https://ia601603.us.archive.org/30/items/gov.uscourts.caed.4... Duffy v Yardi Systems (WD Washington) https://ia800508.us.archive.org/30/items/gov.uscourts.wawd.3... Chirino v Yardi Systems (ED Virginia) https://ia801307.us.archive.org/3/items/gov.uscourts.vaed.54... reply colechristensen 8 hours agorootparentprevhttps://www.propublica.org/article/doj-backs-tenants-price-f... Contains links to an investigation and lawsuits where you can read DOJ complaints reply bostik 1 hour agorootparentprevSubscribing to a pricing data service: legal. Using data feed to guide pricing and set initial figures: legal. Agreeing, either implicitly or explicitly, to let the pricing data feed set the price floor: collusion. Leaving units unsold and refusing to lower the price despite insufficient demand: usually a bad business decision, possibly indicator of a market failure. Leaving units unsold to maintain agreed-upon price floor despite insufficient demand: collusion, market manipulation. Congratulations, you are a cartel. reply 10000truths 9 hours agorootparentprevWhat makes it collusion is the fact that others are using it as well, so the answer to your questions is yes. My understanding is that there's nothing wrong with building your own software that crawls public information and computes a price for you - the key thing is that it has to be your own, you can't distribute that software to others. reply casualscience 4 hours agorootparentMy understanding is that further than just using software, the software is optimizing to increase maximum profits for the industry by causing a cartel block of people who won't lower prices. Any individual can go out there and build a model for the rent price, the issue comes in when that model is able to coordinate everyone to keep the prices high and discourage competition/undercutting. reply jkic47 9 hours agorootparentprevate you sure it is that? after all, we all independently use the Kelley Blue book value of a car before we sell. I think there has to be some intentional and provable link that you and I agreed (colluded) to use a particular value and set a floor below which we wouldn't sell. reply vineyardmike 6 hours agorootparentWhat’s missing here is that landlords agree to use the algorithm or leave the unit empty. It’s part of the TOS. So when many marker participants do this, it’s colluding. reply AnthonyMouse 30 minutes agorootparentWow, that's brazen if true. I don't know why anybody is even talking about algorithms. That's a contract to fix prices. It also implies that all of the landlords using it are idiots. Not only is price fixing illegal, joining the cartel is optional and costs you money for no personal advantage because you'd have to leave your units vacant instead of immediately renting them out at the higher price induced by the \"selfless\" idiots in the cartel. reply dkjaudyeqooe 9 hours agorootparentprev> ate you sure it is that? after all, we all independently use the Kelley Blue book value of a car before we sell. That book doesn't price individual cars, only types and the price of the actual car is open to interpretation and usually negotiation. reply slrainka 8 hours agorootparentThe key distinction lies in how YieldStar approaches setting rental prices compared to other systems. YieldStar not only recommends rental prices by analyzing the entire inventory it oversees but also incorporates a strategy that effectively eliminates the possibility of rent negotiation with potential tenants. This approach mirrors the dynamics of the prisoner’s dilemma, a situation in game theory where individuals may not cooperate, even if it’s in their best interest to do so. However, YieldStar transcends the Nash equilibrium—the point at which no participant can benefit by changing strategies if the others remain unchanged—by stripping tenants of any bargaining power. This ensures that the rent pricing strategy is firmly controlled, without the usual back-and-forth negotiation process. reply samatman 8 hours agorootparentThis is a strange claim. How is it that software can eliminate the possibility of rent negotiation? A tenant can negotiate, or try to. How does software eliminate the possibility that this will succeed? reply cogman10 7 hours agorootparentIt's the scope and breadth of deployment and the algorithm/business pressures. > RealPage discourages bargaining with renters and has even recommended that landlords in some cases accept a lower occupancy rate in order to raise rents and make more money. This is the key to why it's price fixing. Everyone playing ball and means that the raising rent rates increases everyone's take home even if a few operate with lower occupancy. The software calculates rent rates that make sure occupancy isn't too low to keep everyone in line. It removes bargaining with the promise that \"if you play ball, you'll be rich\". Tenants can negotiate prices just like you can theoretically haggle with amazon. reply tsimionescu 2 hours agorootparentThe haggling part is not that relevant to whether this is price fixing or not. If RealPage had the effect that all advertised rents in some area were 1000$ but 90% of renters actually negotiated that down to 800$, it would still be price fixing. Conversely, if landlords in some area all independently decide not to budge from advertised prices and as a result occupancy rates are 10%, that would not be illegal price fixing. Most markets for consumers don't allow any kind of price negotiation, and yet they are not guilty of price fixing. The key problem is that RealPage facilitates and even encourages explicit collusion between competitors, by showing the same non-public price recommendations to competing lamdlords. Whether that's successful or not and whether they try to make it contractually binding or not is ultimately irrelevant. As the FTC says, unsuccessfully trying to do price fixing is still illegal price fixing. reply Aunche 4 hours agorootparentprev> RealPage discourages bargaining with renters and has even recommended that landlords in some cases accept a lower occupancy rate in order to raise rents and make more money. Of course they would discourage them from deviating from Realpage's recommendation. Why are you paying for a software that recommends the most profitable rent if you aren't going to follow it? Realpage doesn't want property managers to complain that the software isn't working when they're ignoring the software's recommendations. I have yet to see any evidence that there are any actual consequences of ignoring the recommendations. I'm assuming that Realpage will always accept payment for their services. This suggests that price fixing is unlikely. In the case of a cartel, members are incentivized to sell more than their quota allows, and you need active enforcement to maintain compliance. See the history of OPEC. reply tsimionescu 2 hours agorootparentIt doesn't matter if there are consequences for not following the illegal price fixing scheme (the recommendation algorithm). The fact that they are creating a price fixing scheme in the first place is illegal. It's the same thing as if I were to call for a meeting of all landlords in my area to discuss rents. Anyone who owns property in the area is invited. At the meeting, I would propose that we all keep rents above 1000$ per room. People would argue and finally there'd be some broad agreement that 900-1100$ dollars per room is a better idea. We don't sign anything and don't imply any repercussions for those who ignore it. Then, 90% of those present would undercut the agreed numbers and offer their rooms for 800$. The end result is that rooms in the area go for 750-900$, so we utterly failed. What everyone present at that meeting did, even those who undercut the agreed prices, is illegal price fixing. Competitors are simply not allowed to discuss and agree on prices in any way. If we replace the meeting with a third party offering a recommendation algorithm that everyone independently follows, knowing that others do the same, nothing materially changes. The algorithm need not be binding, and need not be adopted fully, for this to be illegal to do. reply FireBeyond 3 hours agorootparentprevConsequences involve being kicked off the service with no refund for the (significant) fees. reply Aunche 3 hours agorootparentWhere does it say that? If it's something on the contract, you'd think that the FTC would open with that rather than vaguely imply this this happening. reply dkjaudyeqooe 8 hours agorootparentprevBecause the software has set the price and the landlords are using the software's price exclusively. That is why it's price fixing. reply treis 5 hours agorootparentprevThis sounds like denying the existence of price fixing altogether. Sure, buyers can try to negotiate against a price fixing scheme but it won't work. The price is fixed. The software isn't really doing anything. It's simply the means of communication by which the prices are fixed amongst the suppliers. reply FireBeyond 3 hours agorootparent> The software isn't really doing anything. It's simply the means of communication by which the prices are fixed amongst the suppliers. The software literally includes the algorithm that says \"this week, you will set the rate for this apartment at $X\" based on its data. And if you want to deviate from that, without being kicked off, and losing your substantial fee payment, you will do that rate (and they will check), or you can \"request an override\" from RealPage, that they may allow or deny at their discretion (and RP agents are formally trained that override approvals may not exceed 5% of requests). reply tsimionescu 2 hours agorootparentEven if they didn't kick you off, they would still be engaging in price fixing. They would be worse at actually changing prices with their scheme, but badly executed, ineffective price fixing is still illegal. reply dkjaudyeqooe 8 hours agorootparentprevThe only way you can productively refuse negotiation is by knowing the price is fixed (or you have the only supply), otherwise others will take your business. reply jprete 8 hours agorootparentIf it's widely believed that other landlords use the same pricing system as you, then that's exactly how landlords can refuse to negotiate. reply nerdponx 9 hours agorootparentprevIt's an interesting area because the line might be fuzzy. It's not reasonable to expect every landlord to become a data analyst or statistician! So naturally there's a market for a product that helps landlords make data-driven pricing decisions. I'm sure the big landlords know exactly what they're doing, but I suspect that the smaller landlords don't even realize they are participating in a price-fixing cartel. As an interesting point of comparison, consider that the Zillow \"zestimate\" is also an algorithmic price recommendation, shared by all market participants. What's the difference there? Is it that buyers and sellers can both use the same algorithm freely? I want to make very clear that I think price-fixing is bad and that I believe extremely high real estate prices are at the root of a large and growing amount of misery in Western economies and societies. But I'm also cautious of pursuing thoughtless regulation that hurts small businesses, to the advantage of the big businesses that are causing all the problems in the first place. reply vineyardmike 6 hours agorootparent> It's not reasonable to expect every landlord to become a data analyst or statistician! And it’s not reasonable for every business to succeed. Good businesses get good at being a business and learn skills necessary to succeed. I had a corporate landlord where the leasing agents would go on tours of neighboring buildings in their spare time to build comps. You don’t need a price fixing algorithm or a pay-rolled data analyst. I think Americans have a soft spot for landlords because it’s a common business for the middle class to use to move up in the world. Which is nice, but most Americans also have stories of parasitic landlords that left them in terribly unmaintained homes with big rent increases. Regulation will absolutely hurt middle-class landlords but will increase the average sophistication of the industry. reply nerdponx 3 hours agorootparentSerious question: Would it be illegal to hire a human \"price consultant\" who was very popular among your landlord friends? Does it matter if the price consultant only serves 5% of the landlords in an area? What if they serve 20%? 50%? Where does the line get drawn between \"seeking advice from an expert\" and \"engaging in price-fixing\"? I wouldn't be surprised if that was tried at some point in the past, so there might already be legal precedent for the non-algorithmic variant of this. > Regulation will absolutely hurt middle-class landlords but will increase the average sophistication of the industry. Sophistication is a tool used deliberately and maliciously by large incumbents to suppress competition and to crush smaller firms. And I'm not convinced that middle-class landlords who own a handful of units are the big bad guy we should be going after here. I can only hope that the FTC agrees and is willing to focus their attention to where it will actually help people. reply tsimionescu 2 hours agorootparent> Would it be illegal to hire a human \"price consultant\" who was very popular among your landlord friends? Does it matter if the price consultant only serves 5% of the landlords in an area? What if they serve 20%? 50%? Where does the line get drawn between \"seeking advice from an expert\" and \"engaging in price-fixing\"? The answer is most likely that it would be illegal, yes, at least if your friends are offering properties in the same area. Even discussing pricing decisions with your friends is likely illegal. Imagine it like this: Coca Cola and Pepsi executives are not going to meet for brunch and casually start discussing what margins they think are reasonable and how they set pricing in different markets and how low they are willing to go with their price. These are some of the most closely guarded secrets of a company. Decision makers who are aware of these aren't even easily allowed to leave one company and join the other, because of the risks of leaking this information. And if they do discuss this things, they would easily be seen as guilty of collusion to fix prices. The fact that two landlords who happen to be friends are not the CEOs of multi-billion dollar companies doesn't fundamentally change the law. You are not allowed to discuss pricing decisions with your competitors. If you want to collobrate, you need to incorporate and pool your resources into a common enterprise. And you can hire a price consultant, but that price consultant can't be working for other landlords in the same area. You could hire different consultants from the same firm, but the firm would have to be very careful to ensure that the consultants don't discuss their clients with each other in any way. reply AnthonyMouse 16 minutes agorootparent> These are some of the most closely guarded secrets of a company. This seems like a weird argument. For some companies their pricing is super secret because it's often negotiated and they don't want Customer A to know that Customer B is getting a bigger discount, and if a competitor knew Customer A was overpaying they'd send them an offer. But for others the price is just the price. Nobody is going to Walmart to haggle. All of Walmart's competitors know exactly what Walmart's customers are paying because it's written right there on the sign. So how could it be illegal to tell them? reply tsimionescu 5 minutes agorootparentThat's not what I mean by pricing decisions. You of course know how much Walmart asks for tomatoes. What you don't know, and is a closely guarded secret, is how Walmart arrived at that price. Is the current price close to their minimum possible, and would they remove tomatoes from the shelves rather than drop this price if the demand wasn't high enough? Are they expecting to increase it or decrease it in the next six months? And this information is important, because if Whole Foods knew it, they could either (a) try to undercut Walmart to steal their customers, but also could (b) safely increase their price knowing that Walmart plans to do the same, and so not fear losing tomato customers to Walmart. In contrast, landlords working with RealPage know that at least a large percentage of other landlords follow the exact same pricing strategy, and thus be secure that, if they also refuse to lower prices as the algorithm is recommending, they won't lose tenants to other landlords. Of course, some of them might chose option (a), undercutting all the others, but that's not a real problem in a cartel with so many small members (one cheating member won't significantly affect prices). So, it's not illegal to say \"you know, Walmart charges 2$ for a tomato\". But it is illegal to say \"you know, I'm in talks with Walmart to convince them to charge 2.5$ per tomato starting tomorrow\". kllrnohj 8 hours agorootparentprev> It's not reasonable to expect every landlord to become a data analyst or statistician! Why not? It's what they did just fine for thousands of years. What fundamentally changed in the last 20 years that makes it impossible for landlords to determine their own price? reply damontal 8 hours agorootparentSounds like they’re determining their own price with the technology that’s available. reply kllrnohj 8 hours agorootparentThey aren't, they're outsourcing pricing to a 3rd party knowing that the same 3rd party is doing everyone else's pricing decisions as well. reply colechristensen 7 hours agorootparentprevIt’s not fuzzy. When a group of people get together to determine a common price for goods, that’s collusion… price fixing. They are literally selling price fixing as a service openly in public. Yes indeed setting prices is difficult. If you use a service to do it for you, it should be quite illegal, and arguably already is. Also the “big” businesses clearly outsource this too, having lived in many large apartment complexes where it was obvious a third party algorithm was doing it. reply bluGill 2 hours agorootparentThe service itself is legal, but you have the difficult task of not using one client's data when working with a different client. reply tsimionescu 2 hours agorootparentI don't think it's legal at all. If you're making official pricing recommendations, you're essentially trying to convince competing businesses to agree on price fixing, by definition. It doesn't really matter how you arrive at that recommended price. The only way this could work is if you give individualized pricing recommendations based solely on public information + the information of the specific landlord, and if your marketing and contractual agreements and so on make it very clear that different landlords will see completely unrelated prices. Otherwise, even agreeing on the same pricing formula is an illegal form of price fixing (say, if everyone agrees to sell at public average price + 10%, dropping down to public average price + 5% if unoccupied for one month), per the FTC briefs. reply trimethylpurine 8 hours agorootparentprevAnalyst or not, the issue is knowing who is willing to underprice you. You can't know that unless you have insider information, in this case provided by a shared database. Scraping public listings doesn't give you that. reply ThrustVectoring 7 hours agorootparentprevYou're over-emphasizing the methods by which these people are price-fixing, rather than the result. The result is a price higher than the market-clearing price that is low enough to find tenancy for all housing. Any scheme to generate excess profit by raising rent above this price is (or ought to be) illegal, whether it's colluding to do price fixing, using some algorithm to price-fix, or monopolizing the market. reply tsimionescu 2 hours agorootparentThe FTC is claiming the exact opposite, basically. Colluding to fix prices, by any means, is illegal. It is still illegal even if the scheme is only followed by a handful of those who \"agreed\" to it. It is still illegal if it utterly fails to control the price and thus has no material impact. It's like trying to scam people. You're not allowed to try to defraud people. It doesn't matter if your scam is so bad that it would cost you more money to execute than you would get out of it, and it doesn't matter if no one engages with your scam at all: what you were doing is still illegal. reply closeparen 3 hours agorootparentprevAll store owners should be jailed, then, since the presence of inventory on their shelves is proof of a scheme to generate excess profit by charging higher than market-clearing prices - or it would have sold already. reply bluGill 2 hours agorootparentWe only know current inventory. As I write this in early March stores are starting to order their halloween candy (the orders need to be in by somethime in april). You do not know what candy your competitor will order, but this is relavant to sales since you will price match their ads and in turn lower priced candy will sell in greater quantities. reply nkrisc 6 hours agorootparentprevI won’t belabor the point others have made, but if the end result is price fixing, it’s price fixing. The law isn’t code and it is open to interpretation and intent and outcomes matter, sometimes more than the methods. reply dkjaudyeqooe 9 hours agorootparentprev1. I'm going to use this pricing service. 2. I'm not going to deviate from what it tells me. 3. I know everyone else (who matters) is using this service in the same way. reply hnburnsy 6 hours agorootparentWhat amazed me was that sometimes the recommendation from the software was to not lease a unit to anyone. reply bluGill 2 hours agorootparentyou should always have a unit not leased so that you can lease it to someone who needs it now and is willing to pay. If you only have a few units though you will never hit that point where the theory is worth the risk the desperite person comes along. reply turquoisevar 8 hours agorootparentprevThis is why nuance and details are key in legal matters and where the sum is greater than the parts. Where the line gets drawn is often unclear and is often a matter of “I know it when I see it”. Just individually comparing prices isn’t an issue. What does become an issue is if (at least) all of the following are met. - You use an algorithm service does automates all of this - This algorithm uses both public and private data - The algorithm is ubiquitous and widely used by almost every relevant market player - The algorithm tells all users to not negotiate and the users abide by this recommendation - All of the above has a noticeable effect on the market to the detriment of a big demographic of market participants reply tsimionescu 1 hour agorootparentPer the FTC filing, many of these are not relevant for deciding if illegal price fixing has occurred. It doesn't matter how the algorithm operates. If all landlords in an area publically agree that they will set rent prices at 400xx the price of a coke can, they are only using public information, but still engaged in price fixing. It doesn't matter how many people actually use the algorithm. If you try to start a cartel to do price fixing and only succeed in convincing two of your 50 competitors to participate, you've still engaged in illegal price fixing. It doesn't matter if individual price negotiation happens or not. If a bunch of companies agree to set the same list price, but also agree that they can offer deals to their customers, they are still engaging in illegal price fixing. It doesn't matter if the scheme actually succeeds in changing the prices. If two companies meet and agree to set prices at a certain value, but then they backstabber each other and undercut the agreed price, or simply other companies in the space who were not part of the scheme have too much market power to allow prices to change, the original companies still agreed to an illegal price fixing scheme and are guilty. All of the above will probably have a massive impact on the amount of damages and so on. But they have no bearing on the verdict, as the FTC lays out at length in the filing they link from the article. And this is not speculation, it is established case law. reply HumblyTossed 7 hours agorootparentprev> I'm naturally going to go onto rental search sites and look at what similar houses in the area are renting for, and probably ask something pretty close to that. Or, Say I own and house, and I want to rent it out. I would calculate how much I would have to charge for rent for it to be worthwhile to me. Why would I care what anyone else is charging? reply tsimionescu 1 hour agorootparentYou can of course advertise at any price you want. But, if the price you calculate this way is too large, no one will rent your house. And, if the price you set this way is too low, you're leaving money on the table, which you may or may not be fine with. If the difference is high enough, someone might even pay you the rent you asked for, but then rent it out themselves to someone else for the higher price, and pocket the difference, which you may feel cheated by. reply BlueTemplar 1 hour agorootparentContracts often forbid sub-renting. reply pylua 7 hours agorootparentprevBecause you want to maximize your profit and get the most from your investment. You also want to see, generally speaking, if it is even reasonable that anyone would to rent out your house at that price reply closeparen 3 hours agorootparentprevIt’s generally good to have an economy where you can just exchange the market price for the thing, vs. the “price” is low but the actual criteria for getting access to stuff is connections, bribes, waiting, luck, conformity, etc. reply bluGill 2 hours agorootparentprevGenerally when you first build / buy a property the market rent is below your calculated needed rent. however with time you pay the property off and inflation raises the amount the market allows you charge. Thus you need to follow the market price and invest for the long term. In year 40, you can charge below market rent and be fine, but until then you haxe to charge as much as the market allows to break even vs other investments. reply zymhan 7 hours agorootparentprev> Why would I care what anyone else is charging? Then you probably shouldn't be participating in this discussion. reply refurb 6 hours agorootparentprevBecause the rental market is detacted from the prices in the ownership market. Rents can be much higher or much lower than the carrying costs of owning. If you just charge what you need to cover costs you may find yourself with a vacant apartment. reply bikezen 7 hours agorootparentprevYou have a duty to your family/pets/shareholders to extract maximum value clearly. /s I added /s because dear lord this thread is full of people who think its true. Housing shouldnt be an investment venue when we have millions unhoused. reply codexb 7 hours agorootparentThat's like saying people shouldn't invest in farms, or pharmacies, or water pumps because there are poor or mentally disabled people who have trouble securing and affording those products. reply hnburnsy 6 hours agorootparentprevPrices on rental search sites are wishes not actually leased costs and would be missing things like the term, pets, and incentives. reply lowbloodsugar 7 hours agorootparentprevIf you own a house and it sits empty for a year because an algorithm told you you could get more for it, you’re an idiot. If you use an algorithm to effectively collude with others and you fail to rent your house but keep rents artificially high, then you an idiot and a criminal. reply bluGill 2 hours agorootparentIf you own 100 houses to rent it is already known you should have a few empty at all times. reply aaomidi 9 hours agorootparentprevThe issue is, you're one person doing this manually. That means there's also a ton of people who don't. This algorithm, unlike a single person, ends up taking over entire cities, which means now there is no supply & demand. There is supply, and all that supply is effectively the same number. Demand has no other choice other than meet the supply where they are. It's either that or being without a house. reply theragra 9 hours agorootparentWhat if there are multiple vendors selling algorithms? Open source bots doing this? How many bots is a collusion? reply polygamous_bat 8 hours agorootparentEven if you’re talking to your next door landlord and coming up with a joint price, it’s collusion. reply dragonwriter 5 hours agorootparentprev> What if there are multiple vendors selling algorithms? Then each vendor’s customers may constitute a small price fixing conspiracy, which is still illegal (price fixing doesn’t have a market threshold before it is illegal) but also a lot less effective, so it probably would be a transitory condition even if it didn’t get punished. reply FireBeyond 3 hours agorootparentprevThe service also requires you to go with their recommendation 95% of the time, and at a certain point requires you to go with their recommendation, and you can only \"request an override\" that RP can allow or deny at their discretion (of course, they can't enforce it, other than to kick you off their service, with no refund). reply FireBeyond 3 hours agoparentprev> RealPage discourages bargaining with renters It's more than 'discourage'. RealPage considers (their own words) landlords to be \"cheating\" when they deviate from the recommended rates. Landlords are contractually obligated to follow RP recommendations 95%+ of the time: > Consistent with their agreement to impose rents generated by RealPage RM Software nearly all the time, Defendants agreed to limit overrides. For example, a RealPage LRO training document states: “Overrides should be few and far between.” Similarly, internal RealPage LRO training documents teach cartel members’ regional managers to beware of “Override Overload” or “rogue” leasing agents who too frequently override the LRO-generated pricing. > An internal presentation created by Defendant Greystar explicitly acknowledges that RealPage RM Software users should each seek to accept at least 95% of the RealPage-generated prices, emphasizing that “Discipline [o]f using revenue management increases more consistent outcomes.” > Former Greystar employees have similarly confirmed that negotiating rents other than those set by the RealPage RM Software was unacceptable. > Even where Participating Landlords do not enable auto-accept, most landlords cannot, on their own, charge rents other than those generated by RealPage’s RM Software— landlords can only “propose an override.” The landlord must then provide a written business justification for why they wish to depart from the RealPage-generated rent. RealPage is simple fucking cartel software. reply dkjaudyeqooe 9 hours agoparentprev> One of the algorithm’s developers told ProPublica that leasing agents had “too much empathy” compared to computer generated pricing.\" That's true by definition. What's shocking is that the developers want to replace leasing agents with a sociopath. reply Espressosaurus 9 hours agorootparentWhy is that shocking? It's not just laundering the price fixing, it's laundering the guilt. reply dkjaudyeqooe 8 hours agorootparentShocking that he figures that the right amount of empathy is zero (see toomuchtodo's comment). reply ClumsyPilot 8 hours agorootparentSeems fairly typical of software developers drunk on cool aid reply voidfunc 6 hours agorootparentprevThis is shocking? You're kidding right? reply toomuchtodo 9 hours agorootparentprevThe developer in this case is the sociopath. Not uncommon. reply Espressosaurus 8 hours agorootparentIt's a banality of evil situation for the developer and their entire chain of command. reply refurb 6 hours agoparentprevBut YieldStar is just automating what every landlord does anyways - looks at comparables. And large rental corporations can get pretty sophisticated in data analysis. So the FTC says \"price fixing by algorithm is still price fixing\". If I scrap rental data from a website and then determine my own rental price, is that price fixing? Doesn't seem to me. reply bcrosby95 4 hours agorootparentIf you scrape rental data, then send an email to every person renting a unit saying \"I recommend you allow your unit to sit vacant rather than renting below this price\", that would be price fixing. reply vineyardmike 6 hours agorootparentprevWhat’s missing from your view is the scope. yield star is provided the same data to a large chunk of the market (in some rental markets). Going online and looking at comparables isn’t one company setting the price for every market participant. reply tsimionescu 1 hour agorootparentThe scope isn't exactly what's important. Whether their selling to 80% of the market, 1% of the market, or even just to 2 competing landlords, what they're doing is still price fixing. The only thing that's legal is doing your own pricing research, using your own methods. You can hire a consultant to do this for you, but this burden then transfers to them: they can't consult for multiple competing businesses. reply heroprotagonist 6 hours agorootparentprevWell, yes, if you continuously adjust your prices to match your competitors, rather than basing your changes on other factors (changes in maintenance expenses, inflation, property values as a whole, changes in area demographics like crime rate, school quality, walkability, availability of services, etc), and you do this at the same time they do, then that can be an indicator to the law that you're engaging in price fixing. But it's not the only indicator, and likely is insufficient on its own if you don't have significant enough share of the local market for changes in the prices you make to ripple outwards to smaller players. It's hard enough to get them to go after the big players, so they won't go after you. Usually price fixing requires multiple indicators. The law doesn't have to prove that Bob is talking with Alice and prove that they're discussing how to raise rents with each other. Prosecutors just need to demonstrate that Bob and Alice are both doing the same things, around the same time, which contribute towards artificial increases. As players get larger, their policies and procedures have greater impact over an area. Their practices get more scrutiny because of this greater impact. That's one (of many) reasons we see large companies spread themselves to multiple cities. While nobody bothers when someone who rents a dozen units uses algorithms to set their prices, they start to notice more when it's thousands of units all concentrated in a single area. When you get to a position where 4-5 companies can significantly inflate prices for a city with millions of people, how they behave is important. There are other tricks they use beyond third party algorithmic engagement. Consider this: If only 30% of the rental market engage in a laddered renewal scheme where they push renters towards always renewing within the same 2 month period of the year (via 10 or 14 month renewals that are more financially viable than 12 month renewals, or are simply the only option for renewal until the renter is within that two month period) and also add significant lease penalties for breaking out of that schedule, it takes less than a decade to reach a point where 90+% of rentals are renewing within the same two months every year. And what does that do? It artificially constricts supply (nobody releases their lease until they've found a new apartment, so many units are not displayed as available or need to be accepted sight-unseen) and artificially inflates demand (everybody is looking during this same time period). The result is artificially increased rent. Which has a side effect of inflating bubbles in the housing market. That may _seem_ good for property owners, as they can sell their houses for more. For a time, until the next pop that everyone blames on lenders with dodgy loan acceptance criteria or other criteria. Until then, homeowners pay inflated property taxes. They might overextend their mortgage with the new perceived value of their home that may eventually drop, etc. The point is: rental price fixing is real and deliberate, large players with greater impact know better but do it anyway, and this is not the only trick they use. It's just the one they've currently stepped far enough over the line on to get caught at. reply tsimionescu 1 hour agorootparent> The law doesn't have to prove that Bob is talking with Alice and prove that they're discussing how to raise rents with each other. Prosecutors just need to demonstrate that Bob and Alice are both doing the same things, around the same time, which contribute towards artificial increases. While you're right about how regulators typically approach this, it's also important to note that the converse is also true. That is, if they happen to get clear proof that Alice and Bob agreed together to raise rents, then it doesn't matter if they actually succeeded in increasing rents in the area, and it doesn't even matter if they didn't follow through with the agreement: the agreement itself was illegal, and they would get an easy win in court (though damages may be low if the material impact was low, so the case may still not be worth pursuing). It is typically very rare for such direct evidence of collusion to exist, and thus indirect evidence like you suggest is normally how this is investigated. However, RealPage and the others here have provided this evidence directly: the way their price recommendation service is structured, the terms and conditions and so on, constitute direct evidence of an explicit attempt at price fixing. So, even if it turned out that all of landlords participating in this scheme actually \"cheated\" the price recommendation algorithm, and even if it turned out that rents went down or stayed the same when RealPage moved in, they would still be guilty of price fixing, per the FTC. reply miiiiiike 10 hours agoprevI lived in a building that was owned by a hedge fund and used algorithmic pricing. It was frustrating to know the vacancy rate in the building, how desperate the sales people were for residents, and still be told that rent was going up hundreds of dollars a month because of demand in the region. Another thing they did was to offer lower rent if you moved into a unit that was vacant. They ”incentivized” people to move every year instead of just increasing the rent a reasonable amount. I’m talking rent going up $500-$1,000/month unless you moved into the identical unit next door. Most of the people in the build paid the increases but we were young so we moved. Our first year we lived in a small 1br. When the lease came up they wanted to increase our rent by $600/month. We opted to move into a huge 2br with limited light that had been vacant for a year or two. When our lease on that one came up they wanted to more than double our rent because there was such high demand for the unit. We were the demand. reply sheepybloke 7 hours agoparentThis is literally what I'm facing right now. We were hoping to stay in our place for one more year, but the company is raising our rent by 10% while at the same time are running a special for a free month's rent. Every place I've rent from has done this, raising rent at least 5% to 10%. I just want one place where I can stay and try to save up money for a house. reply kurthr 5 hours agorootparentIf both of you aren't on the lease, alternate between the two of you. At least you won't have to move very far. When I was just out of school I did this in a large complex with my wife more than once (we had different last names and used her parents address for mail). The first time, we didn't even have to move, because she got the pick of open apartments... one of which was ours. We worried they would want to paint it, but I guess since I'd only had a it a year, they didn't bother. The Sales person was happy because they got commission anyway, and we got a free months rent rather than paying an extra month's rent in increases. reply ikekkdcjkfke 3 hours agorootparentprevDo like the EU, group up and collective bargain. Strike, lock-out etc. are all concepts explored over hundred years ago reply rocqua 3 hours agorootparentI hope it would work, but fear evictions and police intervention would be brutal enough to quash the will to fight. reply ClumsyPilot 8 hours agoparentprev> how desperate the sales people were for residents, and still be told that rent was going up hundreds of dollars a month because of demand in the region This literally sounds fraudulent I have a hypothesis, that the reason for many ailments in Western economies is that in the past 20-30 years we have created a lot of parasitic, highly-sophisticated economic fraud, and regulators have not caught up to it yet. reply scotty79 10 hours agoparentprevI don't know how regulators can look at this number of vacancies and conclude that yes, the taxation on property with vaccancies is as high as it should be. reply screenobobeano 9 hours agorootparentI am really a proponent of the Chinese system. I’m a real estate investor and this “free market” isn’t going to last much longer since owning vacant homes will net you more than virtually anything else you could do legally. Real Estate is a free money machine, and it won’t stop until we adopt realistic government controlled system. reply oatmeal1 7 hours agorootparent> Real Estate is a free money machine, and it won’t stop until we adopt realistic government controlled system. Real Estate will stop being a free money machine when the government stops artificially restricting housing supply with single-use, single-family zoning. reply rocqua 3 hours agorootparentIt won't. Zoning is stupid and harmful in the US. But real-estate will always be rising in value. There is no way to make more land. And land you do nothing to gains value from others around you improving their own land. A land value tax that ignores the value of improvements on the land would make a dent. Freeloaders who buy a lot just to sell it later would see their gains evaporate. So land holders would seek to actually improve their land. reply bluGill 2 hours agorootparentLand generaly should increase in value with Inflation. There is a lot of land to develop if zoning doesn't get in the way- reply __loam 4 hours agorootparentprevI agree that we should relax residential zoning laws but it does feel pretty naive to think the free market alone will solve this. I doubt everyone being adequately housed is even the optimal state of the free market. reply kaashif 7 hours agorootparentprev> it won’t stop until we adopt realistic government controlled system. Are you aware that the government is the entity preventing housing from being built in many cities? I don't think zoning should be abolished or anything but clearly the regulations the US has now, at least, are incorrect and restrict supply far too much. reply Georgelemental 7 hours agorootparentprevDidn't the Chinese real estate market collapse recently, with several major bankruptcies? reply carom 8 hours agorootparentprevWhat is the Chinese system? reply trimethylpurine 8 hours agorootparentThe Chinese system restricts foreign nation state actors from buying everything so they will not be able to do what China is doing to the US. The US has only just started writing policies to address that (for example: [1]), probably because for so many decades Americans wanted to believe that China was an ally, or at least a well meaning business partner. China proves that capitalism doesn't work by destroying it. [1] https://www.faegredrinker.com/en/insights/publications/2024/... reply xbmcuser 7 hours agorootparentChina is not doing anything to the US, western countries were willing to hide the black money of countries before as it helped their economies. As China and other countries got richer the amount of money those people started bringing and putting into the real estate of western cities in the world exploded. The property market crash of 2008 and low interest rates made the situation worse. Now people in the west are crying about property prices but if they stopped allowing in black money from countries they would not face the problem they do. If they can find out about terror financing etc then they for sure can find all the corruption and black money coming into their countries/cities. reply trimethylpurine 5 hours agorootparent>China is not doing anything to the US In many cases the ownership has been traced to government funding. The suspicion is that these are just the tip of the iceberg. So, at least in the eyes of the US Congress, based on some damning evidence, China is doing something to the US. That said, \"black money\" is also a problem. But I suspect that's the case in China as well. There's no way to eliminate all corruption, even in China. reply AuryGlenz 8 hours agorootparentprevReal estate will continue to be a good investment as long as demand outstrips supply. reply importantbrian 6 hours agorootparentprevObligatory Georgism callout, but a high land value tax would solve this issue. Landlords would be forced to put the property to productive use, and it discourages the kind of speculative land holding that these companies are engaging in. reply leereeves 5 hours agorootparentBut that tax would be passed on to renters, increasing rent for everyone. Unless you're talking about a tax on vacant properties. reply antonok 4 hours agorootparentIt wouldn't get passed on. Without land value tax, holding real estate is a good enough investment on its own that rent prices can be left artificially inflated. LVT puts pressure on landlords to actually earn back the value of the property to avoid losing money. In practice, that means offering competitive pricing. This is a solid in-depth explanation, if you're interested: https://www.gameofrent.com/content/can-lvt-be-passed-on-to-t... reply leereeves 3 hours agorootparentBut all landlords would pay the tax, and none of them would want to lower prices below their own costs. If it becomes impossible to rent properties profitably, then eventually there would just be fewer rentals available. reply djokkataja 2 hours agorootparent> But all landlords would pay the tax, and none of them would want to lower prices below their own costs. This is true ... > If it becomes impossible to rent properties profitably, then eventually there would just be fewer rentals available. But this is a leap that doesn't apply to the Georgist scheme. A key feature of the scheme is that taxes on buildings (possibly among other taxes) are removed in favor of the land value tax. It's true that if the tax on some piece of land increases sufficiently, it will eventually become impossible to profitably charge rents on existing buildings on that land--but improving existing buildings or building some superior building (for example, a new building with more units than a pre-existing building) allows landlords to continue profiting. If the current landlords don't want to improve buildings there, they can sell the land to someone who will. And it's clear that someone will, because if there's enough demand for the land that the land value tax makes it unprofitable to sit on it without improving it, someone is going to want to do something more with it. The reason we don't already have a Georgist-style economy is quite obvious, of course: the homo sapiens landlordicus is a very soft, squishy, vulnerable subspecies. If they had incentives to improve their properties and thereby possibly even work as hard as the rest of the human species, they might well go extinct. And no one wants that. reply scotty79 1 hour agorootparentprev> If it becomes impossible to rent properties profitably, then eventually there would just be fewer rentals available. That's the point. They'd be forced to sell instead of hoarding increasing supply of houses on the market tremendously. You wouldn't rent. You'd just buy. reply importantbrian 4 hours agorootparentprevLand value tax can't be passed on to tenants. Whether or not a tax can be passed on depends on the elasticity of supply. The supply of land is fixed, so land value taxes reduce the price of land, and generally also reduce the price of rent as a result. reply db48x 5 hours agorootparentprevYes, but adopting Georgism would mean eliminating income taxes as well. In principle most people should end up paying less in taxes (because they don’t live in a densely–populated area, or because they live in a dense area but are in an apartment instead of a house on a whole acre), while the overall tax revenue stays the same. reply ikiris 57 minutes agorootparentprevBecause a large percentage of them have a fundamental belief that any taxation is theft. reply pitaj 6 hours agorootparentprevHigher vacancy rates are associated with lower rents and lower house prices. Vacancies are at the lowest rate in years in high demand areas. reply lotsofpulp 10 hours agorootparentprevShould be a formula that keeps increasing the tax liability per empty month, so eventually the owner has to dump it for zero or give it back to the government. reply bluGill 2 hours agorootparentYou want a number of empty units in your city so that if you want to move there is a place to move to. No empty units means someone does without. You don't want too many empty units of course. some is needed. this price fixing is partially about units not even for rent which is a different problem you don't want. (but you want some units not for rent while they remodel) reply pas 7 hours agorootparentprevwhat vacancy numbers are we talking about exactly? and how high are they, and how did they change over time? reply vineyardmike 6 hours agorootparentNot OP but I had a similar experience. I lived in floor 30 of a “luxury” skyscraper in Seattle built after ~2015. We had an algorithm for pricing according to the landlord and the class action letter we received. Amazing water views and city views. Clearly desirable housing in a city flush with rich people and a massive housing shortage. I was the only occupant on the floor and the only tenant at the time ever to live in that unit. They tried to raise my rent like $1000/m when lease was up. We paid it since we had just gotten a raise. Next lease renewal was about $1000 again and we moved out because $2k extra was just too far above comparable units nearby. They literally offered us a Starbucks gift card to stay. We could see the other vacant units listed on the buildings website and they were always priced way above comparable units in neighboring buildings. Oh and to directly answer your question, I’m guessing the building was never more than half full. The mail room was never full, and the parking garage had about 20/100 spots in use. reply globalnode 9 minutes agoprevthese services are a form of collusion that basically bypass normal supply and demand and are effectively anti-free market. i can see it being ok if all the properties were owned by one person (which they aren't) but then the gov't would be within its rights to go break it up as an unfair monopoly. which i might add, is a monopoly on a basic human need for shelter. a right even? this is corrupt greed at its worst, market manipulation at best. reply ummonk 8 hours agoprevI don't understand how it's possible that every single biglaw firm offers the exact same starting salary but that isn't considered illegal collusion, while landlords using a market-estimation service as a starting point for pricing their units (but sometimes pricing below or above the algorithm's recommended price) is considered illegal collusion. reply killingtime74 8 hours agoparent(studied competition law in law school). Everyone having the same starting salary can be arrived at by non-illegal means, such as seeing what the others are offering and matching. To successfully prosecute for price fixing you need actual evidence of collusion. That is usually obtained by whistleblowing, as the first person usually gets a reduced sentence (example: https://www.accc.gov.au/media-release/cartel-immunity-policy...). Price fixing in buying/hiring is not monopoly btw, it's monopsony. reply aerhardt 39 minutes agorootparentSorry to nitpick on this tangential detail, but what does “reduced sentence” entail? On paper it sounds like many people would rather take the secret to their graves. reply tdb7893 6 hours agoparentprevSo the thing with lawyers is that there is no communication (i.e. it's only \"tacit collusion\"). In this case there is communication via the company with the pricing algorithms. My brother studied tacit collusion as part of his econ PhD (and new lawyers was one of the markets he looked at) but it would be a hard thing to actually legislate against and isn't illegal. You can't just be like \"you guys can't pay the same\". reply pottertheotter 3 hours agoparentprevWhen I worked in investment banking 1st year analysts made pretty much the same base at every big bank. They all used the same compensation consultant, which seemed iffy. reply rocqua 2 hours agorootparentI doubt 1st year analysts have much salary complaints. reply d0gsg0w00f 8 hours agoparentprevProbably because legal defense outside of public defender is considered a luxury good. And it's rare to need a public defender if you're living a \"normal\" life. With housing, everybody has to live _somewhere_. reply advael 9 hours agoprevI think the only reason this should be surprising is that we've let it be the status quo for so long, despite being pretty obviously illegal. Nonetheless it's good that the FTC has explicitly made a commitment to start enforcing the law reply nerdponx 9 hours agoparentIt's nice when federal agencies are funded and led by people who aren't trying to sabotage them from the inside. Ignoring all other considerations, the current incumbent political party in the US presidency on average tends to produce effective & functioning federal agencies, and the other party on average tends to produce corrupt & dysfunctional federal agencies. I try to point this out frequently because voters tend to ignore this kind of thing until it affects them personally, or they read about some isolated grievance in the news. But it really should be considered a more important topic. reply gotoeleven 4 hours agorootparent>and the other party on average tends to produce corrupt & dysfunctional federal agencies the federal agencies are mostly employees have been there through many administrations. How do they suddenly become corrupt and dysfunctional besides these employees (90% of the current incumbent political party) suddenly becoming corrupt and dysfunctional? reply goda90 3 hours agorootparentEmployees still have to follow their politically appointed bosses at the top or risk being fired. reply rocqua 2 hours agorootparentprevEmployees will often internalize past actions they took, whether forced to by their bosses or not, as good actions. they will even build up a worldview to support those actions. For the alternative is to accept that you were bad, or even evil. That means leadership can change the course of an organization by ruthlessly making them do other things until people internalize those things as the right thing, or leave. That only explains decay though, not the magical idea that under the right party things spring back. The best to hope for is a democratic president to slow down the decay. But it is simply so much easier to tear things down than to build things up, that it will take a lot of democrats to see actual improvement. reply staplers 6 hours agorootparentprevvoters tend to ignore this kind of thing until it affects them personally And when it finally becomes a problem that cannot be ignored, scapegoats will be found and used, even if they have to be invented in a fairy tale (internet conspiracy). reply advael 6 hours agorootparentOften it suffices to blame the agencies themselves, citing the very failures caused by mismanagement, corruption, and underfunding as evidence of the foolishness of using government agencies to do things. This in turn is the kind of nonsense you can get people to believe if you've systematically misinformed them while also convincing them they can't trust other sources, which is another well-known strategy of the same political faction reply gorgoiler 3 hours agoprevLots of tech companies use Ravio, Pave, etc to track the compensation their competitors are offering employees at similar levels. These tools plug straight into your payroll to give all the participants “live” market data. Isn’t this also price fixing? reply rocqua 3 hours agoparentIs it recommending salaries? The issue with the rent thing is that the algorithm sets a price, so collusion could easily be offloaded onto the algorithm. Something similar should also happen with salaries before this becomes a real problem right? reply csa 11 hours agoprevI would like to see that this action will lead to meaningful change in (imho) an unhealthy rental market. Unfortunately, I think the genie is out of the bottle, and the actions by the ftc will be reduced to whack-a-mole attempts to bust transgressors who make the effort to have plausible deniability while still using price-fixing algos. reply nurtbo 11 hours agoparentAdding to that: once you’ve shown that keeping rates high while allowing greater vacancies works, no one is going to lower rates afterwards. So we are stuck with this higher rent environment. reply indecisive_user 5 hours agorootparentIt's only profitable because of price fixing. You don't have to worry about vacancies when all your competition has agreed not to undercut you. Without the price fixing though, apartment complexes will actually have to compete against each other on rent. reply ClumsyPilot 8 hours agorootparentprevWhat do you mean? Of course price-fixing and market manipulation works, that’s why criminals do it! There is no limit to Price fixing for inelastic good like food, housing and medicine. reply josh-sematic 11 hours agoprevIIUC it’s still valid to use an algorithm to recommend prices, but you’re not allowed to make an agreement with a competitor that you will both use the same alg? Or is this saying that any algorithm which takes competitor prices into account is out-of-bounds? reply bobthepanda 11 hours agoparentThere were antitrust suits filed against RealPage after a ProPublica piece > In one news release, Realpage offered its property management clients the ability to outsource daily rent-setting and revenue oversight. “We believe in overseeing properties as though we own them ourselves,” the company said in a presentation that plaintiffs’ lawyers referenced in the lawsuit. > The lawsuit quoted one unnamed witness, a RealPage pricing advisor, saying that some pricing advisors told property management employees that they had to follow the software’s recommendations. A leasing manager at a RealPage client said, “I knew [RealPage’s prices] were way too high, but [RealPage] barely budged” when the manager asked to deviate from the suggested rent. > An update to the software tracked not only clients’ acceptance rate, but also the identity of the landlords’ staff members who had requested a deviation from RealPage’s price, the lawsuit said. Compensation for some property management personnel was even tied to compliance with the company’s recommendations, it said. So if this is true, this also means that managers are being compelled to adopt the recommendations more than as mere suggestions. https://www.propublica.org/article/doj-backs-tenants-price-f... reply advisedwang 11 hours agoparentprevThe law doesn't work on hard and fast rules like that. It's more like \"If the effect is that you are working together to set prices, that's illegal\", regardless of whether you use algorithm A or B, regardless of whether you share prices in advance or watch how other companies set prices, regardless of any details of the mechanism. If you use the same algorithm it's not necessarily illegal, but it will be if it results in price fixing. If you take into account competitors prices its not necessarily illegal, but it will be if it results in price fixing. reply lazide 9 hours agorootparentWhat is the definition of price fixing in this world? reply StewardMcOy 7 hours agorootparentWe can start with what is definitely price fixing and work our way up to why algorithmic pricing is price fixing. To keep things simple, let's say a city has two landlords, Alice and Bob, who each own around half of the residential rental properties in the city. Textbook definition of price fixing is if Bob and Alice agree to never rent for less than $5 per square foot. Next scenario: Instead of a minimum price, let's say that Bob and Alice agree a formula on how to price their properties based on vacancies. The formula can be as simple or as complicated as you like. But in this scenario, if the formula never gives them a result less than $5/square foot, it has the exact same outcome as the textbook scenario. And since there is direct coordination between Bob and Alice, this is definitely price fixing. In fact, it's even worse than the textbook scenario, because now they're coordinating on exact prices, and not just a minimum. Forgetting formulas for a minute, let's say Charlie, who is unrelated to Alice and Bob, approached them separately and offered to sell them information on how to set their prices. In this case, there's no algorithm involved. They each pay Charlie a small fee per month, and he tells them not to rent for less than $5 per square foot. There's no direct communication between Bob and Alice, but because they both know that the other is acting on the same advice from Charlie, the result is the same as the textbook scenario. You could even argue that there is indirect communication between them, and that Charlie is running some kind of price laundering service. Finally, you can combine the two. Bob and Alice both tell Charlie how many vacancies, delinquent payments, etc. they have. Charlie feeds all the data into his computer, which contains a really complicated formula, and that computer tells them how much to charge. And wouldn't you know it, that formula never produces a result less than $5/square foot. Again, because Bob and Alice know that the other is using this service, and because they have an exact price, rather than a minimum, they know they don't have to negotiate with potential customers. The other landlord won't give that customer a better deal. reply makeitdouble 8 hours agorootparentprevReducing consumer choice by artificially setting sinilar prices as comptitors. reply dragonwriter 5 hours agorootparentprevIts worth noting in US federal law, there isn't a distinct statutory prohibition or definition of price fixing. “Price fixing” is a description of one general pattern of violation of a very broad statutory language in the Sherman Act (15 USC § 1) prohibiting “Every contract, combination in the form of trust or otherwise, or conspiracy, in restraint of trade or commerce among the several States, or with foreign nations”. State competition laws may have separate rules for price fixing and other specific kinds of behavior or have similarly broad language to the Sherman Act. reply ClumsyPilot 8 hours agorootparentprevTaking competition our from the market mechanism reply spamizbad 11 hours agoparentprevThe former (you can’t collude with a competitor to use the same algorithm to set prices) reply lazide 9 hours agorootparentHow can you collude with someone you don’t communicate with in any way? reply dkjaudyeqooe 9 hours agorootparentBy using a third party software or service that sets a price, knowing that your competitors are doing the same. reply SoftTalker 9 hours agorootparentIs it collusion to go to a rental search site and survey the asking rents, then asking similar for your property, knowing that your competitors are (probably) doing the same? Is it collusion when a gas station manager drives around the neighborhood, looks at the competitors posted price for gas, and sets his prices the same? reply dkjaudyeqooe 9 hours agorootparentNeither of those examples are what I described and are perfectly fine. You have to use a third party that is setting a price and stick to that, knowing others are doing the same. You're describing individuals determining their own price using their own judgement. reply dugite-code 8 hours agorootparentprevI think the argument in this case is the algorithm is effectively acting as a single agent that will always come to a fixed price and is actively recommending having vacancies to prevent competition. Where as if individuals are assessing the prices they are in a sort of prisoners dilemma, if they leave a property vacant someone may lower the average price meaning they can't recoup the lost earnings when it is occupied. So their best bet is to keep a property occupied as much as possible. reply makeitdouble 8 hours agorootparentprevIANAL but it probably would it you did it whatever the circumstances. If you were the cheapest gas station in the neighborhood with prices appropriate to your operation but one day decide to align your price to your competitors and keep adjusting your price to whatever they set while nothing changed for you, that feels like the very definition of price fixing. reply fragmede 6 hours agorootparentprev\"in any way\" is doing a lot of work there though. The way they're using a 3rd party algorithm is effectively communication and the FTC isn't standing for it. reply dragonwriter 5 hours agorootparentprevCommunicating with a common intermediary is, or at least can be, indirect communication. This was, e.g., the case in the major ebook price fixing case where Apple was the common intermediary between the publishers. reply rocqua 2 hours agoparentprevA situation where you could offload pricefixing to the algorithm is bad. Any algorithms that can't do the price fixing for you are fine. reply __s 11 hours agoparentprevReading linked doc, sounds like first But yeah, your latter case sounds easy to fall into gray territory, since it seems illegal to agree on prices even if intermediary makes it unclear with whom exactly you're agreeing with reply jhanschoo 11 hours agoprev> Such software can allow landlords to collude on pricing by using an algorithm—something the law doesn’t allow IRL. When you replace once-independent pricing decisions with a shared algorithm, expect trouble. Enjoyable to watch norms about language (IRL) change. reply berniedurfee 7 hours agoparentI was thinking the same thing. I had to double check that was an article on a .gov website. I think it’s refreshingly well written and accessible. Not an 800 page blob of legalese. Nice job to the authors. reply tz18 8 hours agoprevCould this change how tech salaries are set? I know many companies base their salary grades on an algorithm that amounts to looking at what \"comparable\" companies are doing and aiming for the middle of that. reply silisili 7 hours agoparentThey're seemingly already doing that for benefits. I've had benefits reduced at two separate places 'because our research shows we were a little over for similar companies.' If that's not collusion, I don't know what is. reply cperciva 6 hours agorootparentCollusion is if they, well, collude. Copying is not the same thing as colluding. reply acuozzo 4 hours agorootparentAt some point copying does become tacit collusion, though. reply WirelessGigabit 8 hours agoparentprevThat would be nice. It's such an easy defense for companies to say: this is what the market pays. reply exabrial 8 hours agoprevI'd like to see thousands of apartments hand back the increases to renters they illegally collected. reply hnburnsy 5 hours agoprevArizona AG sued RealPage and a number of apartment owners over this. The AG said RP covers 70% of the market. Complaint here... https://mcusercontent.com/cc1fad182b6d6f8b1e352e206/files/25... reply maerF0x0 5 hours agoprevFirst off. I dont like collusion or rental pricing software that colludes across companies. However, now this means really big companies can use their own internal data to get advantages that littler players cannot. I also do not like laws that favor big companies over little ones. With the collusion software then littler companies could at least band together to get similar competitive effects that larger companies can. I'm open to discussion of how to resolve that though, any ideas? reply amath 4 hours agoprevMaybe this is a stupid question, but how would airbnb be looked at using this as precedent. If I sign up for airbnb and use their automatic price optimization engine would this fall under the same algorithmic collusion? reply mizzao 5 hours agoprevIs every FTC article usually written in this accessible and readable language? reply trimethylpurine 8 hours agoprevLots of people are saying it's the same as doing it manually with public data. I don't think that's the issue. The article is explaining that the focus is the shared pricing database. Public information doesn't tell you if competitors will underprice to sink you, or if they are likely to hold a high price even against lower occupancy. This software tells you and your competitors whether or not to do that, and bases that guidance on its inside knowledge of its own customer base. That is what the FTC and DoJ are calling collusion, based on my reading of the article. reply EchoReflection 3 hours agoprev\"rent is up nearly 20% since 2020\" but is that taking into account the change in the value of the dollar and changes in the consumer price index? https://www.in2013dollars.com/us/inflation/2020?amount=1 $1 in 2020 is equivalent in purchasing power to about $1.19 today, an increase of $0.19 over 4 years. The dollar had an average inflation rate of 4.48% per year between 2020 and today, producing a cumulative price increase of 19.17%. This means that today's prices are 1.19 times as high as average prices since 2020, according to the Bureau of Labor Statistics consumer price index. A dollar today only buys 84.034% of what it could buy back then. gas was $3.22 in 2020 but is 42.17% higher in 2024, so by that metric rent is proportionally lower (than the 20% increase in rent) Things changed rather dramatically, theoretically,because of different presidential puppet-string-pulling in terms of the FTC: https://www.skadden.com/insights/publications/2021/06/lina-k... https://www.bbc.com/news/world-us-canada-55738746 After less than 24 hours in office Biden signed 15 executive orders whereas Trump had signed 8 after two weeks (Obama had signed 9 after two weeks). https://www.bbc.com/news/world-us-canada-55738746 information that comes from government agencies is almost always data that has been arranged in such a way as to make those in power look like they're the good guys. reply hnburnsy 6 hours agoprev>The Department of Justice has previously secured a guilty plea related to the use of pricing algorithms to fix prices in online resales. This is no idle threat. Be sure to click on that link and find out that in 2018 the FTC stopped the greedy corporate profiteers in the wall poster industry from price fixing back in 2013. Algorithmic price fixers beware. reply justinclift 11 hours agoprevWeirdly, the FTC site seems offline: NOTICE: The FTC website is currently unavailable. Thank you for your patience while we work to restore service. reply lifeisstillgood 11 hours agoprevWait. If landlords gather information about all other rents in the country, and then use that to set a price for their rents, that, cannot surely, be price fixing. So is the problem the “RENTmaximizer” software and other services that basically gather price information ? Because if perfect price information is available, and yet there is no competition in the market driving prices down, well, that’s rentier markets for you. There must be an economics PhD or two in that reply chefandy 10 hours agoparentFrom the blog post: Algorithms that recommend prices to numerous competing landlords threaten to remove renters’ ability to vote with their feet and comparison-shop for the best apartment deal around. From the brief: To participate in the service, landlords must share in “real-time” their “non-public,” “competitively sensitive” data, including actual rents paid, occupancy rates, and records of lease transactions. [Multifamily Compl. ¶¶ 227, 380.] RealPage then feeds “this data into a common algorithm.” [Student Compl. ¶ 5;] [Multifamily Compl. ¶ 380.] The common algorithm uses these common data for a single, common purpose: to generate “forward-looking, unit-specific pricing and supply recommendations” for all participating landlords. [Student Compl. ¶ 5.] To ensure that the landlords abide by these “recommendations,” RealPage puts significant “pressure” on them “to implement RealPage’s prices,” including by requiring clients to submit requests to deviate to the “corporate office” and tracking the “identity of the client’s staff that requested a deviation.” [Multifamily Compl. ¶¶ 17-20, 261-86.] As a result, landlords using RealPage adopt RealPage’s recommendations 80-90% of the time. [Id. ¶ 15.] The complaints allege that RealPage was clear about the purpose of its common pricing scheme: to increase prices above competitive levels through collaboration. Doesn't sound like the natural ebb and flow of the market to me. reply ummonk 8 hours agorootparentYeah the brief seems to be describing a much more clearcut example of collusion than the intentionally vague and broad blog post is trying to imply. reply scrps 9 hours agorootparentprevThat sounds like a dark pool for the rental market. reply kristjansson 7 hours agorootparentThe rental market analogue of a dark pool is the rental market. All transactions are secret by default, allowing higher-information parties (landlords) to set prices that are advantageous to them, and prevent transactions from moving the market. These algorithmic pricing systems extend that information advantage by pooling information across landlords (maybe not illegal by itself) and leveraging their position as market-wide price-setter to push rents higher, with the promise that so many units are following their recommendations that renters have ~no alternative (very illegal price fixing) reply scrps 4 hours agorootparentThe rental market is a decentralized network, with companies like these the network gets routed through a central node and the operator of that node has pefect visibility while the connections being routed have no idea what every other connection is doing like a dark pool, it's the centrality that makes it an analogue. I could think of several advantageous moves like artificially inflating rents then favoring a well paying client by keeping their rents lower than the market. Investing in property spread out across shell companies and then have the algo favor them in a non-intuitive way. reply mcmoor 10 hours agoparentprevYeah I see the app just as a \"public stock market\" of real estate. If information is free, this is what it'll look like. We don't call stock market a price fixing scheme aren't we? But the other comment says something about coercion. Now that's what price fixing is. reply HaukeHi 9 hours agoprevIsn't Airbnb doing the same? reply wolverine876 9 hours agoparentHow so? Is Airbnb colluding with competitors? reply aaomidi 9 hours agorootparentI think Airbnb recommends a price to set your place to? I know there's also some external software that do that too. Based on the understanding of the post, I think both of those would be considered price colluding. reply petesergeant 8 hours agoparentprevNo, because Airbnb is sharing market information with you, and is quite happy for you to undercut the market to drum up demand, or raise prices if you think you’ve got a winner, which keeps market efficiencies intact. What’s described in the article is a bunch of estate agents agreeing to use a price recommended by 3rd party software and minimize cheating on that price, which is price fixing. reply SergeAx 2 hours agoprevIs there a way to keep rent prices in check without strong market regulations? Every business will do everything legal to max out the profit, this is a nature of business. Freezing prices in some places will only rise it everywhere around. Building more is not an answer: most large cities has no adequate lots for new buildings, and where they do - it is undeveloped areas, where no one wants to live. We thought that cars is answer, but cars only deferred the market saturation, plus we need more roads and parkings. Remote work may be an answer, but people still need schools, shops and restaurants. reply xbar 9 hours agoprevMaximum prison sentences, please. reply buzer 9 hours agoprevIf this lawsuit is successful, would renters have standing to sue for damages? And how far would the liability go, just their landlord + RealPage (who is probably bankrupt by that point)? Or would everyone who colluded to keep prices high be liable, possibly even to renters whose landlord was not part of collusion but rents in the area increased due this? reply dclowd9901 10 hours agoprevThere’s no other way around this but to shut down industries that provide this kind of service make it illegal to have automatic price setting. reply jeffbee 9 hours agoprevI don't get how this FTC position is compatible with the existence of things like commodity futures markets. A second point that bothers me about the blog post. It's immaterial to the brief, but the blog says the rent is up 20% since 2020, citing CPI-U. But it fails to account for increasing incomes. Median household incomes, nationwide, have kept pace with rents. reply arming9513 8 hours agoparentIf income has raised by 20%, why should you expect rent to also increase by the same amount? reply jeffbee 8 hours agorootparentBecause it's a market operating point set by supply and demand. Increasing incomes support demand and raise prices. reply Dylan16807 7 hours agorootparentIf \"support demand\" means people want better homes, then that's fine. If people are spending more real money to get the same housing, something has gone wrong. reply bluGill 2 hours agorootparentThe landlords costs hake also gone up 20% reply Eisenstein 7 hours agorootparentprevWhy do increasing incomes support demand? I am not going to move to another place exactly the same just because I make more money. In order for prices to increase, I would have to be moving into a better place than I am in now, which means it would cost more anyway. Me moving laterally gives me no utility. reply jeffbee 6 hours agorootparentIn the American rental market, for most lessees, the lessor can raise the price an arbitrary amount periodically. This is true for virtually all tenancies in this country. reply Eisenstein 1 hour agorootparentSounds like that isn't a market force if they do it without demand changing. reply kristjansson 6 hours agoparentprev> commodity futures markets What? Commodity futures are viciously competitive open markets, where do you see the connection? reply ilikehurdles 11 hours agoprev> an agreement to use shared pricing recommendations, lists, calculations, or algorithms can still be unlawful even where co-conspirators retain some pricing discretion or cheat on the agreement. Someone explain how this is different from pricing vehicles based on KBB or other data? Genuinely curious because I don’t know what these agreements look like. If multiple seller/landlord parties all agree to have a single algorithm set prices I understand the FTC’s point. If however they all reference an algorithmic data point and freely choose to set prices I don’t see how that’s collusion. reply rahimnathwani 11 hours agoparentIf multiple seller/landlord parties all agree to have a single algorithm set prices I understand the FTC’s point. If however they all reference an algorithmic data point and freely choose to set prices I don’t see how that’s collusion. You've hit the nail on the head. It's the former, which is why it's collusion. reply tyingq 11 hours agorootparentI imagine it's tricky to really prove. Airlines, for example, have been doing somewhat similar things for decades, but there's no simplistic path to showing collusion. reply ghaff 9 hours agorootparentPretty much all companies, especially large ones, rely on a series of intermediary sources for things like pricing, salaries, etc. They're not constrained by those sources for individual products, services, and people but they're absolutely aware of them. And it's probably a fairly short distance from there to \"We're not going to pay you more than an equivalent level at Google\" whether or not that's explicitly stated. reply ilikehurdles 11 hours agorootparentprevBut based on the post, this really seems to not be the case? \"Price deviations don’t immunize conspirators. Some things in life might require perfection, but price-fixing arrangements aren’t one of them. Just because a software recommends rather than determines a price doesn’t mean it’s legal. Setting initial starting prices or recommending initial starting prices can be illegal, even if conspirators deviate from recommended prices.\" Would be better to see an argument from the FTC grounded in evidence and analysis, because I don't get what this is based on. Software recommends a price, sure, but so does any appraisal in any industry. For how long can I use an appraisal service before the FTC says I'm committing a crime? I just feel like the lines are not drawn very clearly with this argument. Aside, if anyone from the FTC is here right now, for God's sake do not use \"IRL\" in official writing. reply rahimnathwani 10 hours agorootparentBut based on the post, this really seems to not be the case? I don't understand how you came to that conclusion. From the post: an agreement to use shared pricing recommendations, lists, calculations, or algorithms can still be unlawful even where co-conspirators retain some pricing discretion or cheat on the agreement. Also from the post: The agencies filed a joint legal brief explaining... From that legal brief (emphasis mine): ... when competitors *agree to fix* end prices, ... *the agreement* is the violation, and unsuccessful price-fixing schemes are as unlawful as successful ones. Another commenter asked how this is different from car dealers using the KBB values. If a deal uses KBB values to inform themselves of the approximate value of a car, before deciding their opening bid/offer in a negotiation, that's fine. If they agree with a neighbouring dealer that they'll always start their negotiation with the KBB price, this is illegal price fixing. From the brief: In Plymouth Dealers’ Association, 279 F.2d 128, for instance, a defendant convicted of price fixing for agreeing with competing dealers on a “fixed uniform list price” for Plymouth cars argued that the conviction could not be upheld because the government’s case required “proof of something more—that [the uniform list price] was adhered to; that it was utilized to fix prices; or that it did actually fix prices.” Id. at 130. The Ninth Circuit rejected this argument, stating that “the fact that the dealers used the fixed uniform list price in most instances only as a starting point[] is of no consequence.” Pages 23-24 (PageID #6982 and PageID #6983) of the PDF explain how the collusion was orchestrated: https://www.ftc.gov/system/files/ftc_gov/pdf/YardiSOI-filed%... reply Rapzid 10 hours agoparentprev> some pricing discretion That's the key. The problem is the agreement; that results in price fixing. Even if someone is allowed \"some pricing discretion\"(ie maybe they can deviate 8%) it can still be illegal. Maintaining full pricing discretion is what referencing KBB on your own and making a determination outside a pricing agreement would be; not illegal. From what I can tell. Not legal advice. reply refurb 6 hours agoprevOne interesting things that Singapore does is that it collects and shares all rental data. When you lease a place to a tenant, there is a stamp duty ($100+) that the tenant pays. Then the landlord submits details about square footage, number of rooms, and the price it was rented at. Then the government shares the data in an aggregate manner: https://www.ura.gov.sg/Corporate/Property/Property-Data/Priv... reply kirse 11 hours agoprevAfter pricing auto insurance recently it's pretty obvious this is happening in that industry as well. While shopping around multiple quotes across 7-8 providers and calling at least 5 separate insurance agents to try to gather quotes, all of these companies are providing similar quotes within a few cents/dollars of each other. I vent my frustration to a few agents about the yearly rate increase insanity and they all shrug, give their non-empathetic \"I understand\" telephone script and blame it on the \"system\" calculating the prices and make some useless excuse about inflation. I've got a clean driving record, a fully paid-off cheap vehicle, in a reasonably responsible age bracket, and the cost of decent auto insurance these days is essentially another car payment. Within 5 years I'll have paid back the insurance company 60-70% the value of the vehicle. The Gov/FTC needs to take a look at these companies, especially if they're forcing us to hold the insurance to reasonably participate in society. reply ejb999 10 hours agoparentThe fact that you car is 'cheap', is not the driving force behind the cost - you may drive a $10K used car, but you can still crash into someone else's $120K car and also put the other driver in the hospital with 100's of thousands of dollars of medical expenses. Once your car is paid off, you can usually drop the collision damage on your own car - but don't be surprised if you are still paying thru the nose. Curious though: what state are you in, and how much are you paying? As comparison, we own three cars (2015, 2013 and 2011), for three drivers (youngest is 21) and have pretty decent level of coverage, including coverage for damage to our cars even though they are paid off - and only pay ~$1600/year in total for all three cars/drivers in Mass, which to me seems pretty reasonable. reply Retric 9 hours agorootparentThe national annual average for car insurance is $2,545 per year for full coverage and $741 per year for minimum coverage. Massachusetts is a severe outlier in terms of car insurance and your well below the norm. MA averages 1646/person/year vs 3950/person/year in Florida. https://www.bankrate.com/insurance/car/states/#average-car-i... reply MaKey 9 hours agorootparentHow come car insurance is so expensive in the US? In Europe it's vastly cheaper and the policies themselves are much better. reply Retric 9 hours agorootparentI don't know the exact calculations but people in Europe have nationalized healthcare, more easily lose their license, drive less, and generally have smaller and cheaper vehicles. reply ejb999 9 hours agorootparentprevYikes! That is quite expensive compared to what I pay. reply orwin 9 hours agorootparentprevI think the average cost per year per person in my country is 1500€, so it is actually way cheaper than what i expected for the US. reply tomrod 9 hours agorootparentprev> not the driving force behind the cost Great. Socialize healthcare as the current non-single-payor market is forcing all sorts of market distortions in unrelated markets, AND fix the price fixing. Win win win. ED: adding clarity for the call for socializing healthcare to dampen the massive price distortions in other markets. reply maxboone 9 hours agorootparentHealthcare is socialized in Europe and car insurance is still similarly priced (750 - 1500 per year, average in NL is 950 per car for only liability) mostly due to liability costs. Required insurance covers € 7.5 million for personal injury, € 2.5 million for property damages. Edit: P.S. I am in favor of single-payer healthcare, I just don't think that is the particular cause of expensive liability car insurance - rather personal injury and property damages would seem a larger driver to me. reply margalabargala 9 hours agorootparentThis is interesting to me, an American unfamiliar with European systems. > Required insurance covers € 7.5 million for personal injury So in Europe (or at least some parts of Europe with otherwise socialized healthcare?), if someone is injured in a car accident, their medical bills are paid for by the insurance of the person who hit them, and not that country's single-payer system? reply InsomniacL 9 hours agorootparentThe injured party may decide to receive treatment though a private facilitate and recoup the cost from the insurer. Regardless, if I loose my leg through the negligence of someone else, paying for the amputation isn't going to make me 'whole' again. you'd have to put a literal price on my leg. reply tomrod 7 hours agorootparentI believe the phrase of art for this is value of statistical life. reply maxboone 9 hours agorootparentprevNo, those are not billed to the person who caused the injury. The personal injury part is meant to compensate for personal injury, such as \"compensation\" for becoming unable to work, or live the same way as before. reply orwin 8 hours agorootparentprevI think in my country, the single-payer system is still linked to an individual, by his social security number, so the culprit's insurance will \"pay\", even though what will be paid in healthcare will mostly be aestethics or other non-reimbursable. But mainly, it will pay for damages. In my country, f you are hurt in a car accident, you can be paid depending on your average salary and invalidity percentage, called an \"invalidity rent\". If docotr estimate you're invalid at 80%, you'll get paid 80% of your last month salary until they check on you again, then if you're 40% invalid its 40% of your salary (before the accident, even if it was years before)... up until you're fine. I think they have to give you at least 10% as long as you have sequellas, even minor ones. That, plus fixed damages (between 5k and like 40k). It isn't perfect. It doesn't take into account missed career oportunities, inflation, the pain, or mental issues. But you can work besides the money they give you, and oftentime, you'll get the 10% for a long time, because paresthesias (whatever that thing is spelled in english) and small sequellas can stay for a long time (I know soemone who earn roughly 200€ per month, but she has trouble working in most kitchens now. She used the main check to get into academia though, and will probably end up with a master's degree for her troubles). reply Retric 9 hours agorootparentprevCar insurance in Europe averages ~1050 USD/year, US averages edit: $2,545 USD/year that's a huge difference IMO. reply maxboone 9 hours agorootparentEven when you put it next to the average (or better, modal) wages? reply Retric 9 hours agorootparentYea, though wages and rates vary enough it's worth looking at individual countries. England is an outlier. Average wage works out to 44,252.67 USD (£34,963/year) vs US is at 70,248.63. Average car insurance in England is 710.06 USD (£561/year) vs 2,545 USD in United States. reply tomrod 9 hours agorootparentprevYep. Median wage in Belgium is ~3.5k euro / month, equivalent to ~3.8k USD / month. Median US wage is ~4.9k/month, about 30% higher, certainly not 150% higher. reply orwin 8 hours agorootparentBelgium is definitely an outlier. It's 2k after taxes and contribution in France (so like 2.9k/3.1k if you are working for the state or a private company) reply tomrod 8 hours agorootparentThe other comment thread walked through the UK example as well. American insurance is over priced. reply timy2shoes 9 hours agorootparentprev> Socialize healthcare as it is forcing all sorts of market distortions I don't understand how you come to this conclusion. Can you explain? reply margalabargala 9 hours agorootparentIf a large portion of the cost of auto insurance is to pay for potential injuries to someone that you hit, then we can conclude 1) single-payer healthcare would significantly lower the cost of auto insurance, and conversely, 2) the lack of single-payer healthcare is a significant contributor to the current state of auto insurance markets/pricing. reply timy2shoes 9 hours agorootparentI completely agree with your assessment and logic, but the parent posted suggested that socialization of healthcare (e.g. ObamaCare) is contributing to auto rates. That I don't understand. reply margalabargala 9 hours agorootparentLooking again, I think their comment can be parsed in multiple ways. > Socialize healthcare as it is forcing all sorts of market distortions in unrelated markets I interpreted that as a call to socialize healthcare, not a description of market effects that \"socialized healthcare\" has to the extent that exists in the US. reply tomrod 9 hours agorootparentYour interpretation of what I posted is correct. My apologies for the lack of clarity. Comment has been edited. reply SoftTalker 9 hours agorootparentprevNo, because injury claims also include lost income",
    "originSummary": [
      "New HSR thresholds and filing fees for 2024 have been announced, emphasizing competition in the marketplace.",
      "The changes will be implemented on February 5, 2024."
    ],
    "commentSummary": [
      "The discussion delves into algorithms like YieldStar by RealPage, used to determine rental prices, raising concerns about potential price fixing and collusion among landlords, which could breach antitrust laws.",
      "Ethical and legal implications of algorithmic pricing on rental rates, tenant bargaining power, market competition, and industry oversight are scrutinized, emphasizing issues regarding price fixing, collusion, regulatory scrutiny, tax considerations, and market influence.",
      "Comparisons to other sectors, like car insurance, are made to illustrate the wider effects of price-fixing strategies on consumer options and market behavior."
    ],
    "points": 607,
    "commentCount": 385,
    "retryCount": 0,
    "time": 1709413835
  },
  {
    "id": 39576974,
    "title": "SoundThinking's Surveillance Raises Civil Rights Concerns",
    "originLink": "https://computer.rip/2024-03-01-listening-in-on-the-neighborhood.html",
    "originBody": ">>> 2024-03-01 listening in on the neighborhood (PDF) Last week, someone leaked a spreadsheet of SoundThinking sensors to Wired. You are probably asking \"What is SoundThinking,\" because the company rebranded last year. They used to be called ShotSpotter, and their outdoor acoustic gunfire detection system still goes by the ShotSpotter name. ShotSpotter has attracted a lot of press and plenty of criticism for the gunfire detection service they provide to many law enforcement agencies in the US. The system involves installing acoustic sensors throughout a city, which use some sort of signature matching to detect gunfire and then use time of flight to determine the likely source. One of the principle topics of criticism is the immense secrecy with which they operate: ShotSpotter protects information on the location of its sensors as if it were state secret, and does not disclose them even to the law enforcement agencies that are its customers. This secrecy attracts accusations that ShotSpotter's claims of efficacy cannot be independently validated, and that ShotSpotter is attempting to suppress research into the civil rights impacts of its product. I have encountered this topic before: the Albuquerque Police Department is a ShotSpotter customer, and during my involvement in police oversight was evasive in response to any questions about the system and resisted efforts to subject its surveillance technology purchases to more outside scrutiny. Many assumed that ShotSpotter coverage was concentrated in disadvantaged parts of the city, an unsurprising outcome but one that could contribute to systemic overpolicing. APD would not comment. I have always assumed that it would not really be that difficult to find the ShotSpotter sensors, at least if you have my inclination to examine telephone poles. While the Wired article focuses heavily on sensors installed on buildings, it seems likely that in environments like Albuquerque with city-operated lighting and a single electrical utility, they would be installed on street lights. That's where you find most of the technology the city fields. The thing is, I didn't really know what the sensors looked like. I've seen pictures, but I know they were quite old, and I assumed the design had gotten more compact over time. Indeed it has. An interesting thing about the Wired article is that it contains a map, but the MapBox embed produced with Flourish Studio had a surprisingly high maximum zoom level. That made it more or less impossible to interpret the locations of the sensors exactly. I'm concerned that this was an intentional decision by Wired to partially obfuscate the data, because it is not an effective one. It was a simple matter to find the JSON payload the map viewer was using for the PoI overlay and then convert it to KML. I worried that the underlying data would be obscured; it was not. The coordinates are exact. So, I took the opportunity to enjoy a nice day and went on an expedition. The sensors are pretty much what I imagined, innocuous beige boxes clamped to street light arms. There are a number of these boxes to be found in modern cities. Some are smart meter nodes, some are base stations for municipal data networks, others collect environmental data. Some are the police, listening in on your activities. This is not as hypothetical of a concern as it might sound. Conversations recorded by ShotSpotter sensors have twice been introduced as evidence in criminal trials. In one case the court allowed it, in another the court did not. The possibility clearly exists, and depending on interpretation of state law, it may be permissible for ShotSpotter to record conversations on the street for future use as evidence. This ought to give us pause, as should the fact that ShotSpotter has been compellingly demonstrated to manipulate their \"interpretation\" of evidence to fit a prosecutor's narrative---even when ShotSpotter's original analysis contradicted it. But pervasive surveillance of urban areas and troubling use of that evidence is nothing new. Albuquerque already has an expansive police-operated video surveillance network connected to the Real-Time Crime Center. APD has long used portable automated license plate readers (ALPR) under cover of \"your speed is\" trailers, and more recently has installed permanent ALPR at major intersections in the city. All of this occurs with virtually no public oversight or even public awareness. What most surprised me is the density of ShotSpotter sensors. In my head, I assumed they were fairly sparse. A Chicago report on the system says there are 20 to 25 per square mile. Density in Albuquerque is lower, probably reflecting the wide streets and relative lack of high rises. Still, there are a lot of them. 721 in Albuquerque, a city of about 190 square miles. At present, only parts of the city are covered. And those coverage decisions are interesting. The valley (what of it is in city limits) is well covered, as is the west side outside of Coors/Old Coors. The International District, of course, is dense with sensors, as is inner NE bounded by roughly by the freeways to Louisiana and Montgomery. Conspicuously empty is the rest of the northeast, from UNM's north campus area to the foothills. Indian School Road makes almost its entire east side length without any sensors. The reader can probably infer how this coverage pattern relates to race and class in Albuquerque. It's not perfect, but the distance from your house to a ShotSpotter sensor correlates fairly well with your household income. The wealthier you are, the less surveilled you are. The \"pocket of poverty\" south of Downtown where I live, the historically Spanish Barelas and historically Black South Broadway, are predictably well covered. All of the photos here were taken within a mile, and I did not come even close to visiting all of the sensors. Within a one mile radius of the center of Barelas, there are 31 sensors. Some are conspicuous. Washington Middle School, where 13-year-old Bennie Hargrove was shot by another student, has a sensor mounted at its front entrance. Another sensor is in the cul de sac behind the Coors and I-40 Walmart, where a body was found in a burned-out car. Perhaps the deep gulch of the freeway poses a coverage challenge, there are two more less than a thousand feet away. In the Downtown Core, buildings were preferred to light poles. The PNM building, the Anasazi condos, and the Banque building are all feeding data into the city's failing scheme of federal prosecutions for downtown gun crime. The closest sensor to the wealthy Heights is at Embudo Canyon, and coverage stops north of Central in the affluent Nob Hill residential area. Old Town is almost completely uncovered, as is the isolationist Four Hills. Highland High School has a sensor on its swimming pool building. The data says there are two at the intersection of Gibson and Chavez, probably an error, it also says there are two sensors on \"Null Island.\" Don't worry about coverage in the south campus area, though. There are 16 in the area bounded by I-25 to Yale and Gibson to Coal. KOB quotes APD PIO Gallegos saying \"We don't know, technically, where all the sensors are.\" Well, I suppose they do now, the leak has been widely reported on. APD received about 14,000 ShotSpotter reports last year. The accuracy of these reports, in terms of their correctly identifying gunfire, is contested. SoundThinking claims impressive statistics, but has actively resisted independent evaluation. A Chicago report found that only 11.3% of ShotSpotter reports could be confirmed as gunfire. APD, for its part, reports a few hundred suspects or victims identified as a result of ShotSpotter reports. APD has used a local firearms training business, Calibers, to fire blanks around the city to verify detection. They say the system performed well. But, if asked, they provide a form letter written by ShotSpotter. Their contract prohibits the disclosure of any actual data.",
    "commentLink": "https://news.ycombinator.com/item?id=39576974",
    "commentBody": "ShotSpotter: listening in on the neighborhood (computer.rip)329 points by kogir 10 hours agohidepastfavorite249 comments jcrawfordor 8 hours agoHello all, occasionally I write what I consider \"Albuquerque content\" and I do not expect it to become broadly popular. This article is something I put together very quickly and it probably assumes a certain degree of familiarity with the political context around policing in Albuquerque (which either side will tell you is very contentious) and, more broadly, policing and civil justice. Even without the currently evolving bribery scandal, the level of public trust in APD (and even the city council's confidence in APD) is very low. APD's transparency and accountability, or lack thereof, has been a common locus of the debate. On the other hand, another major issue has been APD's chronic understaffing, and APD contends that ShotSpotter and other elements of their real-time program help to close the gap that results from their limited personnel. With gun crime as one of the foremost issues in the city, whether you view APD positively or negatively, ShotSpotter is a big part of the discussion right now. Historically, APD's use of pervasive surveillance technology has been a flashpoint in the debate. APD has live access to perhaps 3-4 thousand cameras across the city (they aren't very transparent about this and it depends on how far along the APS integration project is), they have used facial recognition against driver's license photos and other sources since 2014, they have installed ALPR throughout the city and recently expanded retention to one year, etc. This is all fed into the Real-Time Crime Center, which uses a data fusion product from a vendor called Genetec to provide sort of a futuristic point-and-click data system that combines ShotSpotter detections with video feeds with service call records etc. to produce sort of a dossier on any given person or location. Unfortunately, there are a lot of things going on in city politics, especially with regard to crime and policing, and so the topic of surveillance has mostly fallen out of public attention. Still, APD's refusal to say in any detail what parts of the city were covered by ShotSpotter has been one of the big ongoing frustrations, particularly among those who favor police reform. I mostly wrote this article to highlight that there is finally information on the matter available. The concerns about how distribution of sensors and, more broadly, use of surveillance technology impacts civil rights and quality of life in the city are mentioned mainly as an aside and I do not attempt to articulate the pros and cons. That would require a rather lengthy piece as the topic is complex, and currently the greater part of the controversy isn't even about the wisdom of deploying ShotSpotter, but rather over whether or not ShotSpotter even works (and, consequently, whether or not it's simply a waste of city money, at a rate of around $5 million). reply jcrawfordor 7 hours agoparentLet me follow up, and maybe I should write this up on CAB but I don't really want to get too much into police reform there, what I know factually about the ShotSpotter system. Most of this comes from discussions with APD leadership and officers in the context of the police oversight role I used to hold, and they are very much limited in what they can say. Some of this is specific to APD SOP and other police departments may vary in their approach. Some sort of software analysis performed by SoundThinking identifies a possible gunshot. The audio recordings are sent to a human analyst, a SoundThinking employee, who reviews the recording and enters an assessment of what it contains (e.g. if it is gunfire, and how many rounds). If the analyst confirms the report, an alert is sent as a text message (I believe in an app they furnish) to staff in APD's dispatch center, called the Emergency Communications Center (ECC). The contract includes an SLA on this process of I think 1 or 2 minutes, but I was told that they routinely performed as well as 30 seconds. Some APD personnel, I think usually area commanders but it may have been all field division sergeants, also receive the alerts on their phones. The ECC dispatches the call as a priority 2. P2 is high enough that a ShotSpotter report will \"bump\" most calls for service except for a caller on the line violent crime in progress. When the officers arrive at the reported location, they make a brief assessment and search the area for suspects or victims. If no suspects or victims are found, a Crime Scene Technician is dispatched (often later as they will wait for daylight) to search the area for evidence such as spent shell casings. My recollection is that I was told they were able to find definitive evidence of actual shots fired in less than five percent of cases, but take that with a grain of salt as I do not believe it was ever put in writing (I don't think they're allowed to by their contract) and I could be remembering wrong. However, it's believable that the accuracy of the system is higher than that suggests, as Albuquerque has a lot of wide open spaces that are difficult to search thoroughly if the ShotSpotter location estimate is at all inaccurate. I was told that, when the system was tested by firing blanks, it was not completely effective but that they were satisfied with how effective it was. I was never given a number and I think they had been very specifically prohibited from discussing the testing in detail when they coordinated it with SoundThinking. One of the major criticisms of the ShotSpotter system in Albuquerque is that it results in a relatively large volume of P2 calls that delay police response to most other calls for service. During the worst of the understaffing, I was told that some officers in high-crime areas like the International District spent a large portion of their total shift following up on ShotSpotter activations while there were multiple P3 calls queued. This has probably improved as staffing levels have increased, but in my mind it is the greatest single concern about the system. SoundThinking's evasiveness, refusal of independent research, and clear motive to sell their product creates an alarming possibility that they are deceiving police leadership and elected officials into overprioritizing ShotSpotter. It may be a waste of money, which is already a problem, but the much greater concern is that police departments are putting off responding to nonviolent crimes in progress to go to ShotSpotter reports instead, because they have been told by SoundThinking that the accuracy rate of the system is very high. reply hcfman 2 hours agorootparentI developed a TDOA based sound localization system for the Raspberry Pi https://medium.com/@kim_94237/tdoa-sound-localization-with-t... and with manual input you can greatly improve the accuracy from what an automatic system could do due to noise and signal degradation. However it’s very time consuming. The service level response would not be met if doing this on many cases I’m sure. Meaning the default accuracy of localization is likely to be a bunch less accurate than what it could be in theory. What is absolutely needed is to start a validation process. Start legal proceedings to force the disclosure of co-ordinates and exact event time information as recorded by each recorder so the math can be checked. My software will provide that side. reply mszcz 1 hour agorootparentThis looks awesome. I’ve been wondering if it would be practical/feasible to create something similar but portable, self-contained for quieter, „local” sounds, like for instance locating a termite-like bug(s?) that’s been terrorizing my sanity for years now hiding in wooden beams. reply dmoy 6 hours agorootparentprev> less than five percent of cases Wow that's even worse than what I had read from reports about the deployment in Chicago (which I read up on when Seattle was considering it). I think the value was like 10%. Chicago also ditched it recently I think. reply resolutebat 5 hours agorootparent\"Definitive evidence of shots fired\" is a higher bar than shots actually being fired. I agree it's still very low though, especially since it means that at least 95% of the time responding to the call was a complete waste of time (= even if shots were fired, there was no evidence of crime). reply duped 4 hours agorootparentprevHere's a decent article because this happened in recent weeks (1). The numbers they cite there are 89% of alerts lead to no reports of gun crime and 86% lead to no crime reports at all. All that being said, the metrics are horribly flawed because they assume police will actually investigate anything after dispatch and that the investigation will turn anything up. Believing that CPD is going to case a neighborhood looking for GSR and shell casings with a forensics team is a tall order. If there isn't someone bleeding out in the street there probably isn't going to be a police report filed. And even that said - ShotSpotter is useless because it requires police to do their job to be useful. When Reddit is better at tracking gang violence than cops, no fancy audio forensics tool is going to help. (1) https://www.npr.org/2024/02/15/1231394334/shotspotter-gunfir... reply bliteben 5 hours agorootparentprevI mean brass can be crazy hard to find, I'd bet if you did a geocaching experiment with brass picking a random spot within shotspotter's accuracy tolerances, you'd find the casing less than 50% of the time. Add in an hourly employee that is in no way motivated to find the casing and you'd prob drop to 10%. reply nonrandomstring 2 hours agorootparentprevPreviously done a lot of research into firearm and explosive acoustics (and the DSP to locate and categorise) and can say this is a _hard_ problem. Military versions for use in wide open spaces have a much better chance than in urban areas. Less than five percent seems unlikely, but I wouldn't be surprised to hear \"less than half the time\". reply nonrandomstring 8 minutes agorootparentThe frustrating problem with people down voting without any explanation is that simply ignoring the knowledge of experts and hiding whatever has emotionally enraged you does not further the discussion. reply hcfman 1 hour agorootparentprevCategorisation will certainly be error prone as there is so much similarity because fireworks and gunshots. The main difference I expect is the speed of the shockwave resulting in steeper spectrograms for gunshots. However, a steep spectrogram is essentially showing a large amount of high as well as low frequencies. The higher frequencies degrade very quickly over distance reducing the difference of a gunshot from a firework the more this degrades. Not finding evidence is a different problem, it could be as simple as using a revolver rather than a semi-auto that ejects the cartridges. In any case, it would be great to see independent testing of this problem by the sort of people in this forum and you can use the software I developed last year (https://github.com/hcfman/sbts-aru) to do so. That software sets the time on the Raspberry Pi to have less than 1 microsecond of error, which is more than enough for any validation efforts. reply nonrandomstring 16 minutes agorootparentCategorisation is one problem. Localisation is the other. reply verteu 8 hours agoparentprevWhy didn't you mention that the only \"conversation\" recorded by ShotSpotter admitted in court was a guy saying \"[shooter's name], why did you shoot me!\" two seconds after the sound of gunfire? It seems an important piece of context if you are concerned about surveillance. reply Retric 6 hours agorootparentThere are multiple conversations from shot spotter admitted into court. New Bedford, Connecticut and Oakland had court cases off the top of my head, but a much wider range of conversation ends up being listened to by police and parallel construction is a thing. Further, the concern is unequal policing biases statistics resulting in more uneven policing. A grid of microphones covering a full city is unbiased, placement based on past data isn't. Drug crime is known to be fairly evenly distributed across different incomes, arrests are extremely biased. reply jjallen 3 hours agorootparentIsn’t this whole article about shooting though and not drug crime? How would you hear drug crime? Are shooting crimes known to be fairly evenly distributed across different incomes? reply verteu 6 hours agorootparentprevNo, in New Bedford, the \"conversation\" was not admitted into court [1]. Oakland is the \"one\" case I mentioned [2]. Do you have a source for the Connecticut case? [1] \"New Bedford utilized ShotSpotter, and the following was recorded by the gunfire detection system: “‘Oh my God! You're crazy!’ and then ‘Jason don‘t!’ several times, followed by a number of gunshots. After the gunshots, a female was heard yelling ‘You . . . missed and they shot him!’ ‘You're going to jail!”’. A motion to suppress this evidence was granted in Denison’s case, as the judge ruled that the ShotSpotter recording violated the Massachusetts Wiretap Act\" https://readingroom.law.gsu.edu/cgi/viewcontent.cgi?article=... [2] https://casetext.com/case/people-v-johnson-5116 reply BriggyDwiggs42 7 hours agorootparentprevAre these things public microphones that pick up street conversations or are they specialized microphones without stored recordings? The capability of these things is the only important question, since if they can be used for mass surveillance we shouldn’t trust cops with them. reply Renaud 4 hours agorootparentMy guess would be that since they need to record a shot without knowing when it happens, and then forward the sound of the shot to an expert to confirm it was gunfire, they must have the capability to locally listen and record continuously, and we can hope that they only keep a few seconds of recording before/after the event. reply notatoad 6 hours agorootparentprevthat doesn't really change the fact that they have microphones that are capable of recording voices, they have storage of the recordings, and are able to retrieve recordings and are willing to provide them to the police. reply jacurtis 7 hours agorootparentprevYes it is very important. Shotspotter is like a DVR. It's always \"recording\", but it is running on a very very short recording loop. The detection of gunshots is based on an algorithm. When triggered, it saves a few seconds before the sound and several seconds afterward. It is different than police just being able to pull up the recordings for a certain street corner from 2 weeks ago or even a day ago and listen in on people's conversations. The case in question came from a shotspotter recording gunshots, and the short clip also happened to include speech within it since it directly followed the sound of shots. reply jcrawfordor 7 hours agorootparentShotSpotter's own public statements say that audio is retained for 30 hours, see e.g. https://www.soundthinking.com/faqs/shotspotter-privacy-faqs/. In the past they provided Albuquerque with a document that said 72 hours, but I believe they have been reducing that period over time. It may also depend on their specific contract with the law enforcement agency. Still, we know that they must retain recordings, because they do take requests from customers to reanalyze data that did not result in an alert. For convenience, the most relevant text: \"If the system misses a gunfire incident, police may contact the company to see if there is any audio or location evidence. In this case, only authorized ShotSpotter personnel with proper credentials can access sensor audio to search. Their search is limited to the 30- hour sensor storage timeframe.\" ShotSpotter used to have significantly fewer privacy protections, and retention was indefinite early in the product's life. Fortunately, a combination of legal challenges and statutory privacy policies among their customers have lead to them significantly improving their privacy controls over time. reply bikezen 7 hours agorootparentprevIs that, like provable though, thats my biggest issue. Cities are allowing a private company to mass deploy microphones all over (mostly lower income) areas and just _trusting_ them to not be keeping recordings. reply bhaney 7 hours agorootparentprev> it is running on a very very short recording loop I'm curious what your source for that information is reply wahnfrieden 4 hours agorootparentThey made it up reply 9935c101ab17a66 3 hours agorootparentprevI mean, yah, it makes sense the one they admitted was pertinent to the case? I don’t see how that context is meaningful. I actually strongly disagree with you — the context doesn’t matter. We have a private quasi-law enforcement entity installing thousands of surveillance devices in American cities without any external oversight or knowledge of where they are installed. These surveillance devices that were pitched as tools to locate gun crimes all of a sudden record audio? And this quasi-law enforcement company with no oversight is storing that data and then furnishing it to the police? We have no idea what’s recorded, we have no idea where these devices are, we have no idea who is listening to the recordings, we have no idea what access LEOs have to these recordings, we don’t know how they are stored, and we don’t know how long they are stored for. You’re seriously okay with a non-government entity operating like this? reply throwaway9917 3 hours agoparentprevThe tone of your article makes me honestly, really angry. You know damn well that the reason the sensors are in those neighborhoods are because that's where people are getting shot. You even talk about how a school where some little kid got shot has a sensor, as if it's some sort of punishment for the lower income people there. Perhaps it's because the police and the city government want to deter or solve murders that happen. The way your article is framed, the main concern is that low income or minority perpetrators of shootings might get caught and put in jail. The fact that minority or low income victims of major violent crime might have their assailants deterred or at least brought to justice does not even factor into your calculus. reply mcmcmc 13 minutes agorootparentDid we read the same article? The main concern is that millions are being pumped into a surveillance program of dubious efficacy with zero accountability and clear biases. Budget that could be allocated to social programs that have a dollar for dollar higher impact on reducing violent crime is instead going into the police industrial complex, increasing surveillance on underprivileged communities instead of actually trying to do anything to address the root causes of gun violence. Shouldn’t that make you mad? reply nceqs3 2 hours agorootparentprevI wholeheartedly agree. reply delichon 9 hours agoprev> It's not perfect, but the distance from your house to a ShotSpotter sensor correlates fairly well with your household income. The wealthier you are, the less surveilled you are. To give ABQ police the benefit of the doubt, that pattern could also be compatible with more gun crime equaling more surveillance. It would be nice to have enough gun crime and sensor location data to see how true that is. When the sensors are as dense as they are, it's not clear that knowing the sensor locations is an advantage to offenders, at least in the gunshot spotting role. reply bombcar 9 hours agoparentIt sounds like shotspotters are likely to be near where shots are; and that the wealthier you are the more likely you’d NOT want to be where the shots are. reply Aurornis 8 hours agorootparentPutting surveillance for gun crime in areas with the highest rates of gun crime is obviously what’s happening. I think the author and some commenters are nervous about claims that gun crime is inversely correlated with neighborhood wealth, which creates some of these strange accusations that some other bias is at play. If you pull up a map of crime in most cities the inverse correlation with home prices is obvious. If nothing else, high crime rates rapidly crush property values as everyone wants to leave those areas. reply kstenerud 7 hours agorootparent> Putting surveillance for gun crime in areas with the highest rates of gun crime is obviously what’s happening. This is in fact the crux of the problem. By significantly increasing monitoring of areas with higher crime rates, you inadvertently create a vicious cycle feedback loop: The more you monitor an area, the more samples you get, biasing the stats (because your sampling is no longer uniform). Then these stats are used to justify more monitoring and policing in the area, further biasing your data. reply Aurornis 5 hours agorootparent> The more you monitor an area, the more samples you get, biasing the stats So by monitoring an area with high crime rate, you catch more crime, which results in more policing for the area with a confirmed high crime rate? And that's a bad thing? reply ryandrake 4 hours agorootparentBy monitoring any area more, you find more crime, which results in that area being considered as \"high crime\" and in turn increasing monitoring--that's the cycle OP is talking about. reply scheme271 4 hours agorootparentprevIt's biasing the sample. For example, drug usage among teens are roughly the same between white, hispanic and african americans but african americans are more likely to be arrested and charged for drug possession or usage. Here the difference is probably because african americans are stopped and searched more even though their usage is about the same as whites. reply Tabular-Iceberg 2 hours agorootparentIt’s probably a cultural factor. Most criminal enterprises want to be discreet in order to avoid detection by law enforcement and rival enterprises. Whereas the black criminal community has made an entire industry of advertising their criminality through music and fashion. reply pillusmany 3 hours agorootparentprevAre the rates of drug dealing the same through? reply jakelazaroff 3 hours agorootparentLet me put it this way. The biggest drug epidemic of this century was the opioid crisis. Half a million Americans died. The primary people responsible are white billionaires, and we know exactly who they are — yet they were never even arrested. reply thereisnospork 6 hours agorootparentprevThe point is supposed to be that the monitoring and increased policing makes at least certain crimes impossible therefore improving the area for the rest of us. The farce is the utter failure of the 'survalience state' to actually catch and prosecute people. reply resolutebat 4 hours agorootparentPerhaps in the US. Some surveillance states like Singapore and China are quite effective at catching criminals (thoughtcrime and otherwise). reply Tabular-Iceberg 42 minutes agorootparentprevIncluding the businesses that don’t want to be robbed, looted or have to pay into a protection racket. So those who are forced to stay have no way of making an honest living. The notion that poverty causes crime rather than crime causes poverty is a great disservice to the poor. reply bandrami 6 hours agorootparentprevIf you let inequality and unofficial segregation fester long enough eventually every map is the same map reply jakelazaroff 7 hours agorootparentprev> If you pull up a map of crime in most cities the inverse correlation with home prices is obvious. If the police department spends the majority of its resources on certain areas, it will respond to the majority of incidents and make the majority of arrests in those areas. You can truthfully say \"look, these numbers are higher than anywhere else!\" but that doesn't necessarily mean there's more crime happening there — it could also mean the residents are overpoliced relative to other neighborhoods. With regard to the article, why is it obvious that police are putting surveillance in areas with the highest rates of gun crime? reply thereisnospork 6 hours agorootparent>With regard to the article, why is it obvious that police are putting surveillance in areas with the highest rates of gun crime? Because there are nicer neighborhoods and less than nice neighborhoods? In so far as I can tell this is true to various degrees in every place I've ever lived or visited. Colloquially, some neighborhoods have manicured lawns, other neighborhoods have cars on blocks - it's 'obvious'[0] that the latter warrants more policing. [0]The truth of it is arguable, perhaps, but it is very obvious. reply jakelazaroff 5 hours agorootparentIt’s actually incredibly unclear why houses with cars on blocks would warrant more policing than houses with manicured lawns. Why don’t you elaborate? reply ryandrake 4 hours agorootparentWhat seems more obvious to me is that the more surveillance you do in any area (regardless of whether the lawns are manicured), the more crime you're going to find there. If you put 5 cops patrolling the wealthiest, nicest areas of your city, and 1 cop patrolling a less wealthy less nice area, the 5 cops will find more crime than the 1 cop. Even if you don't assume crime is uniformly distributed (which it probably isn't), it's logical that more surveillance -> more crime found. reply jakelazaroff 4 hours agorootparentYeah, that’s the original point I made which is currently being downvoted. reply ryandrake 4 hours agorootparentI think there's a lot of quiet classism going on in this thread, and it's easier for these guys to just drive by and hit the downvote button than to actually speak their mind and tell us why they think poor people -> criminals. The causation more likely goes the other way: When an area gets the reputation of being higher crime (because of reality or because of bias from more police saturation), that area becomes cheaper to live in, and poorer people can then afford to live there. reply seanmcdirmid 4 hours agorootparent> The causation more likely goes the other way: When an area gets the reputation of being higher crime (because of reality or because of bias from more police saturation), that area becomes cheaper to live in, and poorer people can then afford to live there. Isn’t that called de-gentrification, or maybe ghetto-ization? However, I think it’s the opposite with property crime (richer neighborhoods attract property crime because their is lots of property to steal). reply WalterBright 4 hours agorootparentprevIn Seattle, the bank tellers are behind bulletproof glass. In the surrounding communities, there's no bulletproof glass. I don't think it's more police presence that causes banks to install the armor. More likely it's the lack of police presence that results in armored banks. reply seanmcdirmid 4 hours agorootparentUhm, I’ve only seen one bank in Seattle like that (in pioneer square), maybe there are more south Seattle? Definitely my Bank of America branch in Ballard doesn’t have bullet proof glass. reply WalterBright 3 hours agorootparentCapitol Hill. reply WalterBright 4 hours agorootparentprevI'm not sure there are lot of murders, carjackings, breakins, etc., in wealthier neighborhoods going undetected. Why would wealthier victims be less likely to report crime? reply resolutebat 4 hours agorootparentprev\"Incredibly unclear\"? Really? Not the OP, but let's spell it out: Manicuring a lawn is expensive and serves no useful purpose, so most practitioners have disposable income and/or spare time, and care about keeping up appearances. Putting a car up on blocks implies it's being used for spare parts, which is generally not something the well-off need to engage in (they buy new and use professionals for repairs as needed), and having one on your front lawn in particular implies that you value spare parts more than appearances. So both are reasonable proxies of wealth, and wealth correlates inversely with the kind of violent crime you could detect with gunshots. reply jakelazaroff 4 hours agorootparentThe reason it’s unclear is that nothing either of you have said has anything to do with policing. Edit: you added the correlation bit after I replied, but why do you believe that to be the case? If you have more police in an area, of course they’ll hear more gunshots there. That doesn’t necessarily mean there actually are more gunshots. What you’re actually saying is “poor people need more policing”, which is A) offensive and B) counterproductive. reply resolutebat 4 hours agorootparentWhy? Let's imagine a city divided in two halves of equal population. West City is poor and has a high crime rate, East City is rich and has a low crime rate. Should police resources be allocated equally to both? How about public health facilities or welfare payments? reply jakelazaroff 4 hours agorootparentIn the real world, wealth is relatively easily measured and crime rate is not. The question no one seems to be willing to answer is: why do you believe poor people commit more crime? reply resolutebat 3 hours agorootparentIt's not a matter of belief, there's a well known link between poverty and crime. The ultimate reason is that if you are poor, the proceeds of crime (theft, burglary, robbery etc) are comparatively more meaningful than to somebody who is wealthy, while the cost of getting caught is comparatively less. A rich professional does not steal loaves of bread to feed their family, because they don't need to and they risk losing their entire livelihood if they do. If you're poor, unemployed and your kids are hungry, the risk/reward calculus is very different. reply jakelazaroff 3 hours agorootparentThe most costly form of theft — by far — is not burglary or robbery but wage theft. That is a crime overwhelmingly committed by rich professionals and rarely enforced. So if we really want to get serious about stopping theft, we should allocate much more resources to investigating businesses than putting beat cops on the street. There’s not actually a well known link between poverty and crime in the way you imply. We’ve just decided that we only care about some people committing some crime some of the time. reply resolutebat 2 hours agorootparentAh, so this is what you were so keen to steer the conversation to. Alas, despite the name, wage theft is not considered a criminal act (misdemeanor/felony) in most US states, so enforcement is left to the Department of Labor and the IRS, not police. Now I'd agree with you that society should be putting more resources into combating this, but I'm still going to ask you to respond to my earlier question: for the hypothetical city with high-crime and low-crime halves, which should the police focus on? reply WalterBright 3 hours agorootparentprevSome crimes, like shoplifting, are hard to measure because it often goes unreported because the defunded police don't respond to them. But the murder rate is easy to measure. When people put bars on their windows on the ground floor, it is not the police causing them to be willing to spend the money on that. Crime can also cause poverty. For example, if the family breadwinner goes to jail, the family slips into poverty. reply jakelazaroff 3 hours agorootparentIs the murder rate easy to measure? As best we can tell, “stand your ground” laws in states like Florida result in hundreds of deaths each year. How many of those would be considered murder in other states? Police killed over 1,300 people last year. How many of those people truly posed an immediate danger to others, and how many were murdered by a trigger-happy cop who was not held accountable by his colleagues? Crime, even serious crime like murder, is socially constructed. It’s not objective; society decides what’s illegal and who gets to do it anyway. reply WalterBright 1 hour agorootparent> Is the murder rate easy to measure? Yes. The medical examiner decides if a death is homicide or not. > result in hundreds of deaths each year Lacks context - the number of homicides in the same year. > How many of those would be considered murder in other states? They're still considered homicide. > Police killed over 1,300 people last year That figure is for all deaths where police were involved. A subset of that would be the police killing. Furthermore, if someone points a gun at a policeman, and the policeman kills him in response, that is self-defense, not murder. There are officers killed while on duty, too: https://en.wikipedia.org/wiki/List_of_law_enforcement_office... Less than 10% of homicides result from police action. > how many were murdered by a trigger-happy cop who was not held accountable by his colleagues? In Washington state, each death from a police encounter are investigated by law, and charges get filed if the officer broke the law. That would include being trigger-happy. > It’s not objective It's objective enough. My larger point is there aren't a lot of (or even any) homicides that go undetected in wealthy communities. Furthermore, your figures lack context as you didn't compare with the total amount of homicides. Your figures are not enough to claim that the higher homicide rates in poor communities are the result of police murders. reply WalterBright 4 hours agorootparentprevWhen I was little, the family a couple doors down had cars up on blocks in front. My mom lamented that, she thought it was awful. Enter my teen years. I had cars up on blocks in the driveway. My poor mom! reply Blahah 5 hours agorootparentprev> it's 'obvious'[0] that the latter warrants more policing. Is it? I don't see it as at all obvious. It seems utterly ridiculous to me to increase policing in sync with socioeconomic deprivation. The blindingly obvious thing is to invest in solving the problems that cause the disparity, not to criminalize people who are living in poverty. reply lotsofpulp 8 hours agorootparentprev> and that the wealthier you are the more likely you’d NOT want to be where the shots are. The way this is phrased sounds like “the poorer you are, the more likely you would want to be where the shots are”. Which is obviously false. reply bombcar 8 hours agorootparentOne person wants to be where the shot is (he pulled the trigger) but yeah, most of the poor people would rather be away but lack the ability. reply fasthands9 9 hours agoparentprevI'm curious if the author lives in the wealthier or non wealthy region. I do not own a gun. I currently live in a city and would be happy to learn they were installing shot spotter near me. It's maybe the least intrusive type of surveillance there is. It just says a signal if there is a loud noise in public. edit: previous statement not correct but leaving it up as it's been responded to reply mandevil 8 hours agorootparentShotspotter is trash. https://www.pbs.org/newshour/nation/chicago-watchdog-harshly... https://twitter.com/greg_doucette/status/1512138327205589004 (criminal defense attorney) https://boingboing.net/2022/04/12/shotspotter-wastes-million... I supported units with them while I was a contractor to the US Army, and the soldiers I talked to didn't think much of it either. reply whimsicalism 7 hours agorootparentIt works very well where I live (DC) and I and people I know have seen police respond to actual things with shotspotter Many shootings where nobody calls it in and cops respond with shotspotter reply smt88 6 hours agorootparentHow would you know no one called it in? Also ShotSpotter has false positives. You have no way of knowing if you (or it) even heard a gun or one of many other things. reply wl 8 hours agorootparentprevYou’re probably thinking of Boomerang, not ShotSpotter if you’re talking about military use. reply mandevil 8 hours agorootparentMaybe? I thought it was the same system of microphones just mounted on a vehicle, maybe it was different. Anyway, they found it unhelpful. \"Wouldn't even notice our own gun shots\" and stuff like that. reply wl 8 hours agorootparentYeah, you’re thinking of Boomerang. ShotSpotter did some limited body-worn stuff for the military back in the day, but the vehicle mounted stuff is all Boomerang. Entirely different approaches (distributed microphones vs. a single microphone array at the expected target) done by different companies. reply bastawhiz 9 hours agorootparentprev> It just says a signal if there is a loud noise in public. This is probably false. There have been two convictions as a result of recordings of conversations that happened through the devices. I, for one, do not want microphones capable of recording my conversations placed near me by the government. Not because I'm paranoid the government is conspiring against me, but rather because I have zero confidence they're storing those recordings securely, being handled by only authorized persons, and being deleted within a timely manner. reply sneak 8 hours agorootparent“paranoid” is a symptom of a disease involving delusions (ie false beliefs) and is not a synonym for “anxious about”. It’s also not paranoia if the government does actively conspire to imprison as many people as possible on flimsy evidence. Both possible usages are incorrect here. reply SoftTalker 8 hours agorootparentJust because you're paranoid doesn't mean they're not after you reply assimpleaspossi 8 hours agorootparentprevIt sounds like you are paranoid. Why would the government be listening to a conversation you might be having near a device used for tracking gunshots? Is there some little man somewhere just waiting to pounce on you or anyone just for that purpose? I don't know how effective these devices are but any tool that helps the police go after criminals is a good thing and no one should be fighting against good things. reply humanistbot 6 hours agorootparentOver a two year period in the US, there were over 600 cases where police officers and civilians with access to law enforcement databases violated internal policies and safeguards to access private data about \"romantic partners, business associates, neighbors, journalists and others for reasons that have nothing to do with daily police work\". This is certainly an undercount, as this is just who got caught and the department didn't cover it up. These are the cases they admitted to doing it and were charged, so the records are public. \"Among those punished: an Ohio officer who pleaded guilty to stalking an ex-girlfriend and who looked up information on her; a Michigan officer who looked up home addresses of women he found attractive; and two Miami-Dade officers who ran checks on a journalist after he aired unflattering stories about the department.\" https://apnews.com/general-news-699236946e3140659fff8a2362e1... reply zemo 8 hours agorootparentprev> It just says a signal if there is a loud noise in public. as a community we really ought to be suspicious of claims like this. There's another word for \"acoustic sensor\" and it's \"microphone\". When a corporation says \"trust us, we only use the data for good\", we should collectively raise our eyebrows, knowing that when data is collected for one stated purpose and stored, that the data at rest will always be used for additional purposes. Once data is collected, the number of things it may be used for is always unbounded; any claims to the contrary should not be taken at face value. reply modriano 7 hours agorootparentIs there any evidence of shotspotter using the data that it collects for something other than good? Even if shotspotter collected audio that didn't contain gunshot-like sounds (which they don't; without a triggering event, the sensors never write the audio out to a file or send it over the network for review), how could they monitize it or do anything malicious with it? How could they tie loose audio of people walking around to the identities of those people (besides the method in the two court cases cited by the article, where homicide detectives listened to the audio of the shootings and heard verbal exchanges incident to the shootings where the victim verbally identified the shooters)? It it's so amusing to me that people who carry around a phone 24/7 spend time imagining these intricate Rube Goldberg surveillance systems to be afraid of. reply refulgentis 6 hours agorootparentThis isn't intricate or Rube Goldberg. When I joined Google I started thinking to myself \"geez, we care so much. why does HN hate us?\" It clicked for me when someone pointed out that even if you trust group of employees X with a mountain of data, nothing prevents group of Y from eventually selling it. And after what I saw my last couple years, I'm utterly convinced some McKinsey-ite will be telling 2050's CEO that's a great idea and in fact the moral option. Maximize shareholder value => stonk go up => Americans have safe retirements. Why am I talking about Google? People talk past eachother on this stuff. The problem isn't that \"have they ever done anything bad?\", it's that the incentive structure is set up such that something that crosses the line will eventually happen. They have an incentive to keep the customer happy. And as the article, and comments below from 1.5 hours before you posted point out, there's no room for argument on that: this already happened. A court threw out info because it was illegally obtained. reply modriano 6 hours agorootparentThese devices don't send audio over the network unless a shooting-like noise is detected. I get it, if the state can listen to all of our communications that are immediately coincident with shootings, what privacy will any of us have? But in all seriousness, you should actually read the section for that court case. Here's all of the text for that case from the link: \"\"\" Commonwealth v. Denison, No. BRCR2012-0029 (Mass. Super. Ct. Oct. 7, 2015) \"ShotSpotter is a listening and recording system that runs 24/7, attuned to the sound of gunfire. When the system hears gunfire, or what it recognizes as gunfire, it locates it, reports it, preserves the recording, and send the recording to the customer within seconds.” The defendant, charged with first degree murder, moved to suppress a recording made by ShotSpotter of an verbal exchange among numerous individuals before and after the fatal gunshots. The court rejected that the argument that the defendant had a reasonable expectation of privacy under the Massachusetts Declaration of Rights because the exchange was “audible by anyone passing and was in fact heard by a crowd of neighbors and other witnesses.” However, the court found that the exchange was an “oral communication” and that the recording was a prohibited “interception” under the Massachusetts Wiretap Act because the defendant had no knowledge that the exchange was being recorded. The court also found that the interception was “willful” because the police had “purposefully directed the placement of the sensors.” The court granted the motion to suppress: “the continuous secret audio surveillance of selective urban neighborhoods ** is the type of surreptitious eavesdropping as an investigative tool that the Legislature sought to prohibit.\" \"\"\" [0] The verbal exchange was recorded because it was incident to the shooting that triggered the recording. In addition to recording the shooter(s) shoot the victim(s), it also recorded the shooter(s) and victim(s) speak before the shooting. This was in public so there wasn't an expectation of privacy, and I can't imagine this is the kind of recording that the Massachusetts's legislature \"sought to prohibit\". [0] https://www.mass.gov/files/documents/2018/01/08/CRIMINAL%20E... reply hamburglar 5 hours agorootparent> These devices don't send audio over the network unless a shooting-like noise is detected. How does this jibe with the fact that the police can apparently request a ShotSpotter operator review of audio recordings for up to 30 days if a known shooting is missed by the system? How does this jibe with the fact that the system has apparently at least twice recorded voice conversations that were used (and thrown out in one case due to violating wiretap laws) in court cases? Edit and even if we trust ShotSpotter to do the right thing, how do we know their systems are secure enough to keep those recordings away from less-honorable actors? reply modriano 18 minutes agorootparentThe website says the audio buffer on the sensor holds the last 30 hours before overwriting. So police have less than 30 hours to flag a missed shooting so shotspotter staff can check sensors for audio around the shooting time. Regarding the court cases, I literally included the entire linked info for one of those Court cases in the post you're responding to. For both of the cases, the verbal exchange was at the same time as the shooting. In the other case, the victim verbally identifies the person about to murder them just before they were murdered. The argument that shotspotter is a wiretap falls apart under the slightest bit of scrutiny and there's no way the legislature meant to protect the right of people to be free from audio recording while shooting someone in public. reply modriano 13 minutes agorootparentprevAnd regarding your last question, the first of the two court cases where verbal communications were captured (because they were at the same time as the shooting), was in 2007. So shotspotter has been around for a while. Have there been any breaches where less-honorable actors have managed to hack into sensors and exfiltrate data? Have there been any breaches of the actual recordings of shootings? reply fasthands9 5 hours agorootparentprevBeing skeptical of face value claims makes sense if they have never been used before. But, they've been in place in some cities since before 2000 and after searching I'm still not aware of any incident audio from it was used that didn't have to do with a gunshot. Looking into it more all the cases of audio being used in court, that was not audio of gunshots, was audio immediately after a gunshot. Spotshotter is open about recording that and it seems completely reasonable to me this audio should be used. What's most boggling to me about the criticism is Albuquerque apparently has 10,000 cameras law enforcement has access to. I know we likely disagree on the usefulness of those, but if you are privacy concerned why would shotspotter even be on the same level of concern as cameras that don't need a gunshot to start filming? https://apnews.com/article/albuquerque-crime-cameras-technol... reply JoshTriplett 9 hours agorootparentprevFrom the article: > Conversations recorded by ShotSpotter sensors have twice been introduced as evidence in criminal trials. In one case the court allowed it, in another the court did not. The possibility clearly exists, and depending on interpretation of state law, it may be permissible for ShotSpotter to record conversations on the street for future use as evidence. reply fasthands9 9 hours agorootparentFair enough. My previous statement was incorrect. Edited above. I understand the hypothetical case they could be misused but I'm still not aware of any cases they actually were. >On June 8, 2007, the Shotspotter acoustic gunshot detection and location system recorded two gunshots from the corner of 83rd Avenue and Birch Street in Oakland, California. The first one, at 11:10:22 p.m., was at 8236 Birch Street, and the second one, 24 seconds later at 11:10:46 p.m., was at 1775 83rd Avenue. Those addresses are less than 10 feet apart. The recording of the second shot also captured the voice of Tyrone Lyles, apparently addressing the person who shot him: \"Ar, Ar, why are you going to do me like that, Ar.\" I am happy shotspotter helped in the prosecution of this person who needlessly killed someone. I realize there could be ways to abuse this for things having nothing to do with gun violence, but you could also say DUI traffic stops or DNA collection could be misued. That doesn't mean they are misused. reply kortilla 7 hours agorootparentBut that’s not how shotspotter is supposed to work. It’s supposed to detect gunshots, not be used for evidence of voice recordings. If that was the point they could just put microphones recording everyone and play them back whenever there was a crime. reply modriano 7 hours agorootparentThe voice recordings were only picked up because they were incident to shootings. Without the shooting, the audio wouldn't have been written out to file or ever be heard by anyone. reply soraminazuki 2 hours agorootparentSays who? The people behind these invasive systems who push back hard on the slightest attempt at basic accountability? reply modriano 7 hours agorootparentprevYeah, but the only reason anyone listened to those sections (or was even able to listen to these sections) of tape was because they contained shootings. These systems work on a rolling buffer storage system; they're constantly recording to a buffer that contains the last N minutes of audio and if a triggering event occurs, it gets written out to a file that is reviewed by a person and if it contains a gunshot, that person confirms there was a gunshot (ie that it wasn't a firework or something) and a notification goes out to the relevant police district/precinct/whatever for that area. If there's just people talking but no gunshots, the buffer never writes out and it's overwritten before too long. reply bandrami 5 hours agorootparentprevDo I have an expectation of privacy in a conversation I have in public? reply yojo 8 hours agorootparentprevThe author’s neighborhood is mentioned in the article. “The \"pocket of poverty\" south of Downtown where I live, the historically Spanish Barelas and historically Black South Broadway, are predictably well covered.” reply jasonjayr 9 hours agorootparentprevAlso, that there is a veil of secrecy of the system's installation and exact capabilities suggest that incorrect or excessive reports could provide pretense for more invasive policing. reply redeeman 8 hours agorootparentprevjust remember, the shotspotter may well make police come.... AFTER you were shot... why the aversion to getting a gun?? reply BHSPitMonkey 2 hours agoparentprev> To give ABQ police the benefit of the doubt, that pattern could also be compatible with more gun crime equaling more surveillance. It would be nice to have enough gun crime and sensor location data to see how true that is. The very point of the article is that, absent leaks like this one, there could be no way for anybody to independently study or verify the fairness of the sensor distribution, or even the real efficacy of the reports the system produces—which is a troubling situation to be in when the state has an outsized amount of power to prosecute people based on potential junk science that will be hard for defendants to challenge in court. The answer isn't to give police departments the benefit of the doubt (which they so rarely earn), but to demand better transparency and citizen oversight of the technology poised to be used against us. reply h0l0cube 8 hours agoparentprev> It would be nice to have enough gun crime and sensor location data to see how true that is. The main thread of the article is that ShotSpotter operate without scrutiny. The problematic aspects of their deployment are the false positives... > APD received about 14,000 ShotSpotter reports last year. The accuracy of these reports, in terms of their correctly identifying gunfire, is contested. SoundThinking claims impressive statistics, but has actively resisted independent evaluation. A Chicago report found that only 11.3% of ShotSpotter reports could be confirmed as gunfire. .. and false charges > This ought to give us pause, as should the fact that ShotSpotter has been compellingly demonstrated to manipulate their \"interpretation\" of evidence to fit a prosecutor's narrative---even when ShotSpotter's original analysis contradicted it. Linked article: https://www.vice.com/en/article/qj8xbq/police-are-telling-sh... .. and as highlighted in another comment (https://news.ycombinator.com/item?id=39577403), cops shooting kids playing with fireworks https://chicago.suntimes.com/crime/2024/02/27/chicago-police... reply qingcharles 2 hours agoparentprevThere is a ShotSpotter on the lightpole outside my door. My household income is about $2400/yr. My hood is a warzone though (South Side Chicago), so not unexpected lol reply standardUser 9 hours agoparentprevI don't think the article is suggesting there is a conspiracy wherein the police decided to target lower income areas because they are poor. It is certainly because incidences of those crimes are higher in those areas. What I think the article is suggesting is that policies like these, particularly when implemented without sufficient transparency or oversight, can cause dystopian-sounding outcomes, such as poor people's conversations being constantly recorded by the government while wealthier people remain un-surveilled. reply bastawhiz 9 hours agoparentprev> more gun crime equaling more surveillance But if you're not listening for the guns then you're not going to find the crime that does happen, will you? It's either saying \"we don't care about it because it's less frequent\" (which is stupid—you still build a fire station in places where buildings burn down less frequently) or \"it's easier to keep ourselves busy when we fish in a barrel\". reply curtisblaine 9 hours agorootparentIf you were to design a system to spot a certain kind of crime in real time, would you place it in zones historically more plagued by that kind of crime or in zones that experienced it scarcely? It's hard to buy into the rhetoric of \"it's only fair if you monitor the crime equally\" if you have already independently sampled it for decades and by now know the zones where it's much likely to happen. Would you patrol a desert in the same way you patrol a busy road intersection if you're trying to prevent car accidents? reply User23 8 hours agorootparentThe problem is Bayesian priors look an awful lot like racism to the unaided eye, enough so that it's really hard to justify them. Or maybe it's racism masquerading as a Bayesian prior. I don't see how to know for sure either way. reply smt88 6 hours agorootparentAlso if such devices (and law enforcement) worked well to reduce crime, the crime would move to less-surveilled areas. We don't see that happening anywhere. reply User23 5 hours agorootparentI didn't realize that there's a conservation law for crime. Is this some kind of ingenious application of Noether's theorem that I haven't heard of? reply smt88 4 hours agorootparentIf you're going to be sarcastic, you should to make a point that makes sense. Criminals react to successful surveillance and law enforcement. It's idiotic to suggest that they wouldn't. reply cratermoon 8 hours agorootparentprev> would you place it in zones historically more plagued by that kind of crime You mean these zones? https://whitecollarcrime.zone/ reply kortilla 7 hours agorootparentFor shotspotter? No. If someone made a system for detecting fraud, embezzlement, or insider trading, you bet your ass it would be deployed there. reply dkarras 8 hours agorootparentprevyou can definitely tell gun crime has happened without listening to the sounds of it. people die, get hurt, police reports are made etc. we don't typically determine if gun crime has happened by... listening do we? reply itishappy 9 hours agoparentprev> Many assumed that ShotSpotter coverage was concentrated in disadvantaged parts of the city, an unsurprising outcome but one that could contribute to systemic overpolicing. Also > Conversations recorded by ShotSpotter sensors have twice been introduced as evidence in criminal trials. reply Scoundreller 8 hours agorootparent> Conversations recorded by ShotSpotter sensors have twice been introduced as evidence in criminal trials. More importantly, how many times were collected conversations used and acted upon in an investigation and not been introduced as evidence? reply lucubratory 8 hours agorootparentExactly, instituting pervasive audio surveillance is bad even if it's rarely used in court, because it can and will still be used for parallel construction. reply dmamills 7 hours agoparentprevThis is just another example of how American Police budgets have gotten out of hand. A budget that allows for a municipal police force to install 721 \"AI powered\" recording devices. That are purchased from a publicly traded company, and deployed in areas guaranteed to funnel people into the for profit privatized prison system. What a wonderful use of tax dollars. Protecting and serving the path to a better society. reply jonahx 9 hours agoparentprev> that could also be compatible with more gun crime equaling more surveillance Not just could -- without more information, it's the far more likely and economical explanation. The phrasing in the article imo is intentionally inflammatory. reply nerdponx 8 hours agorootparentIt's not inflammatory, it's a statement of fact. Of course the public surveillance is located in the areas where crime is most likely to occur! But an important side effect is that innocent people in those areas now are more surveilled than other people. So it becomes yet another injustice inflicted on people who already tend to suffer more greatly from injustice than others. Maybe there are offsetting factors. If the surveillance makes neighborhoods significantly safer, then maybe local residents will be happy to be surveilled in exchange. The article is stating a fact of correlation, not causality. But the particular outcome of \"greater surveillance\" clearly happens, regardless of why it occurs, and regardless of other offsetting considerations. reply defrost 9 hours agoparentprevThere's an interesting control system feedback complaint with a lot to it; * historically there's been a lot of \"black crime\" in the US due to the US police watching black neighbourhoods excessively and being absent elsewhere .. take this all the way back in time to Tulsa and before. * Subsequently there's been a lot of \"black crime\" as neighbourhoods have been destroyed by occasional mobs (Tulsa), frequent division by freeways and toxic waste dumps, and the removal of many adult males to the prison system as a result of all the \"observed crime\" leading to an excess of young males with few prospects. * Based on that data the modern survellience goes to where all the crime has been created^H observed. Meanwhile entire areas of US cities get on by considerably less police present and oversight and a great deal less observed crime. reply dmurray 8 hours agorootparent\"The police disproportionately focus on poor areas for drug possession / traffic offences / white collar crime\" is an important criticism, and the kind of thing awareness of which leads to reform and fairness in policing. \"There's just as much gun crime in rich areas as poor ones, but the police focus on the poor areas because of historical racism\" is an extraordinary claim that should require extraordinary evidence, and the kind of thing that holds back improvements in police work. reply bombcar 8 hours agorootparentI guess you could believe that when rich people are murdered it is not reported and quietly hushed up, but when poor people are the full force of the state swings into action. reply prophesi 7 hours agorootparentHasn't that historically been the opposite? If a rich/white person is murdered, it's a headline-grabbing tragedy. Even serial killers are more likely to evade detection if their targets are minorities, though the reasons for that are more complicated than just systemic prejudice. reply torstenvl 7 hours agorootparentThat's the point. Believing the things that would have to be true for GGGP's viewpoint to be even plausible, let alone true, requires a complete divorce from reality. reply prophesi 7 hours agorootparentGotcha! The comment parent of mine makes a lot more sense now. reply bombcar 6 hours agorootparentExactly. If it had been drug crime, I’d be totally prepared to believe everyone in a rich area is coked beyond reason and gets away with it. But gun crimes are different (unless they’re saying something like “possession” but in most states that’s some variation of legal unless a felon). reply RcouF1uZ4gsC 8 hours agorootparentprev> historically there's been a lot of \"black crime\" in the US due to the US police watching black neighbourhoods You can control for this by just looking at homicides. Dead bodies are pretty objective. And the homicides also follow the same trend as the general crime rate. reply whatwhaaaaat 9 hours agorootparentprevKeep telling yourself all that nonsense while the cities crumble around you. Wealthy areas absolutely have a higher police per capita presence than even the most well funded low income neighborhood. Why are those areas not “observing” all this dreamed up extra crime? Hell sometimes these places pay for their own security. How about a culture of violence and crime being glorified? reply SoftTalker 8 hours agorootparent> Wealthy areas absolutely have a higher police per capita presence than even the most well funded low income neighborhood. As a test, you can call the police from an address in a wealthy area, report a crime in progress, and do the same from an address in a poor area, and time how long it takes before they show up. reply twoWhlsGud 2 hours agorootparentprevI lived in Menlo Park for a number of years in the late 80s and early 90s - in group house a few blocks away from the border with East Palo Alto. At the time, East PA was poor and had a massively underfunded police department. This resulted in drug dealers realizing the city was a great place to deal from - as the probability they'd get caught was really low. In 1992, East PA had the US's highest per capita murder rate. (We'd hear small arms fire many nights and I remember listening to the radio and hearing a BBC reporter calling in a report from less than a mile away from my house (talking from a phone booth in the since demolished Whiskey Gulch neighborhood) - talking about a war zone like atmosphere with dealers openly carrying Uzi's.) Anyway, in spite of all this nothing ever happened on our street. We walked around without any fear of crime at all. Correlation isn't causation, but it's hard to shake an impression that having an actual police department had something to do with that. Incentives matter and culture tends to follow if they change hard enough. reply nerdponx 8 hours agorootparentprevTheir statement about observed crime was an historical claim (as in: \"historically there's been a lot of ...\"). reply whatwhaaaaat 8 hours agorootparenthis point was that he thinks low income areas are being targeted with a higher police presence. That is so wrong it’s hard to believe oc has ever been to a city in the us. I actually doubt he has for any serious amount of time. High tax areas are covered with police in US cities at a rate far above poor inner city areas. reply aCoreyJ 8 hours agorootparentprevBig cities are pretty safe. For instance you more likely to be a victim of a crime in rural northern Wisconsin, like Barron County, than you are in Milwaukee. Don't let your narrative be shaped by stats that aren't proportional. reply nkurz 8 hours agorootparentI'm familiar enough with Barron County, WI to doubt this. I grew up in neighboring Rusk County and my mother spends about half her time in Cumberland. While there are some disturbing incidents of violent crime, very few people there would feel that are at high risk of being a crime victim. My quick attempt at searching suggests violent crime is 220/100K for Barron (https://www.areavibes.com/barron-wi/crime/) versus 1,509/100K for Milwaukee (https://www.areavibes.com/milwaukee-wi/crime/). That site gives Barron an \"A\" for crime versus an \"F\" for Milwaukee. These stats aren't quite perfect, since this is for Barron the town versus Barron the county, but it really doesn't seem to support your view. The other small towns in Barron County that I checked were rated even better than Barron itself and rated as \"A+\". I'm willing to believe that there is some axis on which your statement is correct but I doubtful it's the one that most people would use. Can you offer any more support for your position than just your say so? Edit: As a quick gauge for others, I'll mention that most cars are still kept unlocked. The joke was that they were only locked in the fall, to prevent people from \"gifting\" you their excess zucchini. My father always left the keys in his cars as well, in case someone needed to borrow it. Our house was locked only if we left for long vacations. The key was lost sometime after I left home, and no attempt was made to replace it. I'm not nearly as familiar with Milwaukee, but I'd be surprised if this is the norm there. reply bombcar 8 hours agorootparentThose could all be true and still the statement true. For example if all crime in Barron county was entirely random as to selection of victim, and in Milwaukee it 100% only happened to poor blacks, then infinite crime in Milwaukee could never affect you unless you were poor and black, whereas Barron county could affect anyone. But I suspect that there’s a sleight of hand on “crime” - people usually mean crime by force against another, but technically suicide by meth overdose is two or three crimes. reply nkurz 7 hours agorootparentI agree it's possible with some definition of crime, and I'd be interested to see what that definition is. I also think there's an interesting effect where it's possible for there to be less of some kinds of crimes in \"high crime areas\" because people take greater precautions. I also agree with OP's comment that drug related problems in Northern Wisconsin have gotten much worse since I last lived there. Still, I'd like to see the stats rather than just the assertion. reply Amezarak 8 hours agorootparentprevPeople say this but I'm skeptical. I regularly leave valuables in my car. My windows have never been broken. I've never had anything stolen. Nor do I know anyone who has. All the stores have free-to-use, unlocked public bathrooms. All the product is available on the shelf for anyone to grab. When I go on travel to more urban locations, that's not what I see. Unfortunately the urban blight is creeping closer every year, and judging by the crime reports, in a few years or decades I too will be experiencing these joys. I have heard in especially bad-off areas desperate meth addicts are a theft issue. Usually they target people they know, so small comfort as it may be to their friends and relatives, it's usually not a random crime. reply aCoreyJ 8 hours agorootparentDouble checking I think I'm wrong. I may have been thinking of some specific crime. But Milwaukee is specifically bad due to historical segregation issues. Anyway drug and addiction issues have hit rural issues really bad reply wahnfrieden 8 hours agorootparentprevCity centers have far, far more theft crime objectively from a dollar value perspective. The vast majority of this crime comes from two sources: employers and police. This is widely documented fact. reply whatwhaaaaat 8 hours agorootparentprevIsn’t Milwaukee one of the most segregated cities in the country with low income higher crimes areas juuust outside city lines? Great example. reply torstenvl 8 hours agorootparentprevPlease don't engage in ideological warfare, it's boring and against site guidelines. No reasonable person could look at any meaningful measure of violent crime rates and come to your conclusions. reply wonnage 8 hours agorootparentnext [2 more] [flagged] torstenvl 8 hours agorootparentYou accept the standards you walk past. A community's values must be held by the community. If you only allow a few overworked moderators to maintain those values, then they aren't community values anymore, and the quality of HN will plummet. reply hattmall 8 hours agorootparentprevAh yes so it's police presence that makes crime the number one cause of death for young black males. reply simonw 9 hours agoprevIf anyone wants the raw data, it's available in window._Flourish_data variable on https://flo.uri.sh/visualisation/16818696/embed Which means you can extract it with my https://shot-scraper.datasette.io/ tool like this: shot-scraper javascript \\ 'https://flo.uri.sh/visualisation/16818696/embed' _Flourish_data \\ > /tmp/data.json That's a 25MB file. I loaded it into SQLite like this: cat /tmp/data.jsonjq .events\\ sqlite-utils insert /tmp/shots.db locations - Then opened it up in Datasette with https://datasette.io/plugins/datasette-cluster-map to see them on a map. reply prophesi 7 hours agoparentThanks! And alternatively you can create an anchor element in the console with `href` set as a JSON stringified representation of `window._Flourish_data`. Then set a download attribute with the filename you'd like, and simulate a click to download it. To use it in leaflet, you'll need to iterate over the `events` array and change `lon` to `lng` before adding each point to the leaflet map. reply blatherard 6 hours agorootparentAn even simpler option to get the data, at least in firefox, is to open the console, enter `window._Flourish_data` then right-click the result and select \"Copy Object\" which will put the json in your paste buffer and you can then paste it into a file. reply simonw 2 hours agorootparentOr use the copy() function to copy it straight to your clipboard. reply prophesi 4 hours agorootparentprevThis is when HN is at its peak. Duly noted! reply wferrell 9 hours agoparentprevThank you! reply incanus77 8 hours agoprevTimely, as a boy was shot at last week in Chicago while setting off fireworks that triggered a ShotSpotter alert: https://chicago.suntimes.com/crime/2024/02/27/chicago-police... reply fennecbutt 6 hours agoparentAmerican cops are such a joke. reply eBombzor 5 hours agorootparentThe cops made a big mistake but why is there some juvenile sitting in the dark, middle of the night, lighting up fireworks the moment the police start getting close. That's what I don't understand. There is some weird stuff going on in this story and the article jumping to conclusions isn't helping. reply Jcowell 4 hours agorootparentWhat lethal force is necessary when responding to a phenomenon that regular in mass occurs at least once a year in this country? Lightning up fire works is something I would expect a juvenile to do. reply eBombzor 2 hours agorootparentI like how all 3 replies ignored the part where I put in context \"the moment police were getting close\", as if to assume I was asking why fireworks were ignited at night in general. I saw the body cam footage, and the cops legitimately thought someone was shooting at them, because when they got close, they heard, what literally sounded like gunshots. Should they have just blind fired? Absolutely not, terrible training by those officers, but it's not hard to see why there would be some confusion. reply lanternfish 4 hours agorootparentprevIf you were a juvenile, and wanted to light off fireworks, when else would you do it but at night? reply bilbo0s 4 hours agorootparentprevwhy is there some juvenile sitting in the dark, middle of the night, lighting up fireworks Huh? Genuinely confused by that question? When does anyone light fireworks? I've never seen them any time but at night. reply sbierwagen 4 hours agoparentprevHe was setting off fireworks on January 25? Is there a holiday on that day I'm not aware of? reply 9935c101ab17a66 3 hours agorootparentCan I ask why you’re concerned about the legitimacy of the kids reasoning for setting off fireworks? Like, if he was shot and killed on a holiday, it’s not his fault, but it’s perfectly reasonable to be shot and killed by a police officer when a opaque surveillance system reports gunshots on non-holidays? reply sbierwagen 2 hours agorootparentCops are Bayesian reasoners. If you set off fireworks inside the White House, right now, would you be surprised to suddenly meet the acquaintance of many armed men? Fireworks don't often go off in the Oval Office. Loud banging noises are therefore assumed to be gunfire, not fireworks. If you set off fireworks on the South Pole on July 4th, would you meet police? No, and for two reasons: July 4th is a well known day for setting off fireworks, and the South Pole is far away from basically everything. If you set off fireworks shortly before midnight, on a random Thursday in January, in a city that's famous for having large numbers of murders, should policemen assume it's fireworks, or gunshots? reply bilbo0s 3 hours agorootparentprevYou're stretching man. We're a nation of laws, not of your awareness. It's just the words on the page. Was there a law being broken or not. In this case the answer was no. The police then proceeded to write up multiple claims of illegal activity that were all demonstrable falsehoods, and your defense of the illegal activity on the part of the police is that you aren't aware of a holiday? This is just the sort of thing we need to stamp out before these thugs kill either some other innocent kid, or cause a real police officer to be hurt or killed while trying to control the inevitable community reaction to their bird brained behavior. These cops need to be off the force yesterday. Yes they are liabilities waiting to happen. Yes they are dishonest. But the real reason we need to get rid of them is because they are unpredictable. We have no idea what anyone who will shoot at innocent kids and lie about it today will do tomorrow. Honest cops are predictable. Dishonest cops are just loose cannons and we need to cut them out at every opportunity. reply sixothree 8 hours agoparentprevThis is entirely grotesque. But the systematic deception is especially appalling. reply reaperman 7 hours agorootparentShotSpotter has (used to?) manually changed the location of detected gunfire to placate police who needed the evidence to point to their primary suspect. Then they could go to court and say “this system showed the gunshots came from the suspect’s location”. But “the system” didn't show that, until ShotSpotter employees manually changed the data. They spent a lot of effort hiding that as well. reply hcfman 1 hour agorootparentWhich is why we need public counter validation. (https://github.com/hcfman/sbts-aru) :-) reply wl 7 hours agorootparentprevThey don’t change the data. They change their interpretation of it. The police say the classifier got something wrong, so the classification gets updated, both for the record and to improve the classifier. The police say that the location is wrong. The company looks at the data, maybe finds that the system automatically located on an echo at one or more sensor and then recomputes the location using the primary pulse. reply reaperman 3 hours agorootparentThe “data” which gets presented in court is the classification. So they changed the “data”. The underlying algorithm wasnt subject to examination by defense teams until a rules change like, last week. reply itishappy 9 hours agoprevWhat are the potential downsides to police oversight? > But, if asked, they provide a form letter written by ShotSpotter. Their contract prohibits the disclosure of any actual data. A potentially dystopian surveillance apparatus is installed citywide, and the police can't discuss about it's efficiency because the company that sold it to them won't let them? reply TaylorAlexander 8 hours agoparentThe police know what’s good for them. They have extraordinary powers and the more they can keep the public in the dark about what they do, the more freedom they have to act with impunity. reply nerdponx 8 hours agoparentprevSome bumbling police chief might say something stupid that would draw media attention to ShotSpotter and their massive data collection operation. You definitely wouldn't want that to happen. reply fargle 7 hours agoprevi broadly agree with the sentiment in this article, especially the \"no public oversight\" part. but this: > The reader can probably infer how this coverage pattern relates to race and class in Albuquerque. It's not perfect, but the distance from your house to a ShotSpotter sensor correlates fairly well with your household income. is facetious and is almost certainly argued in bad faith. well, duh. the distance to the nearest \"shot spotter\" box also correlates with the incidence of crime and gunfire in the area. to bring up racism or classism is unhelpful. that correlation is unfortunate, likely true, and also not the problem at hand. reply BriggyDwiggs42 7 hours agoparentActually this is a direct example of how systemic racism works. The goal isn’t to surveil minorities more, it’s just that the system watches places where crimes occur. Consider that, when an area has more surveillance, more people who commit crimes are caught. All of a sudden, you’re disproportionately catching minority criminals. Better put in more surveillance to cover the higher crime rates in those minority communities. I get they can’t necessarily do anything about this, since they’re gonna put microphones where it’s most efficient, but maybe it’s yet another argument against mass surveillance. reply whatshisface 2 hours agorootparent>Consider that, when an area has more surveillance, more people who commit crimes are caught. All of a sudden, you’re disproportionately catching minority criminals. Turn the coin over to the other side - you're catching criminals victimizing minorities. Nothing is simple, is it. reply fargle 6 hours agorootparentprev> hey’re gonna put microphones where it’s most efficient, but maybe it’s yet another argument against mass surveillance. BINGO! reply KennyBlanken 5 hours agoparentprevThe vast number of reports are false, which if you read the rest of the article as serious consequences. It: * results in many high-priority calls tying up the patrols in that area so residents who have serious issues, but not \"active shooting\" serious, get poorer service than people in predominantly white/wealthy neighborhoods. I think you'd be pretty annoyed if something of yours was stolen and police never show because a huge backlog of calls develops while they chase down shotspotter reports, but someone in a wealthier neighborhood reports a suspicious vehicle and police show up in minutes * results in a lot of aggressive police action with police swarming an area looking for a \"shooter.\" Given how discriminatory and hostile police are toward the poor and minorities, this has serious consequences....ranging from residents feeling like they're constantly being harassed, to death - a boy was shot and killed by police after setting off a firecracker that the shotspotter system reported. reply loteck 9 hours agoprevI would request that a crowd as technically sophisticated as HN move past marketing claims when discussing this system. \"Gunshot detection\" is pure marketing. The devices are hot mics — public audio surveillance. The software layer triggers alerts on loud noises, which are sent off to a facility that is little more than a call center, for characterization by a human worker there. This system detects door slams and popped volleyballs just as well as it detects gun fire (which is to say, imperfectly on all counts). reply Aurornis 8 hours agoparent> This system detects door slams and popped volleyballs just as well as it detects gun fire (which is to say, imperfectly on all counts). Sound classification moved far beyond what you’re claiming years ago. If you set the threshold at “imperfectly” then no system will ever meet your bar, because perfect is an unreasonable threshold. However, the claim that we’re unable to differentiate between gunshots and car doors is extremely incorrect. reply loteck 8 hours agorootparentShotspotter falsely classifies popped volleyball as gunshot: https://www.wtol.com/article/news/local/false-shotspotter-al... Slamming doors: https://www.axios.com/2022/04/07/campaign-zero-against-shots... This list can go on. Jackhammer, nail gun, normal hammers. https://voiceofsandiego.org/2020/09/22/shotspotter-sensors-s... reply jacurtis 8 hours agorootparentYes there are false positives. This is an alert system and doesn't have to be perfect. This is the difference between a sensor in a self-driving car and a sensor for something like Shotspotter. If a self-driving car sensor has a 1% fail rate, then it is useless and would cause crashes and death. It couldn't be used. But if shotspotter is 1% inaccurate, then it just sends police to a street corner where there is actually just road construction or a volleyball popped. The consequences are pretty low to nil. Many people might not know this all calls have priorities in a policing system, they are not treated equal. So Shotspotter alerts are very low priority to officers. The same is true for home alarm systems. Home alarm systems trigger false alarms constantly. Police treat them as very low priority as a result. So if a 911 call comes in or an eyewitness reported shooting, or even a wreckless driver or suspected DUI, the police will treat that first. In fact if they are on the way to a shotspotter alert and encounter something else, they will stop for it. This is to say, that the false positives aren't as important as everyone makes them out to be. If a false positive happens, it means that a cop that's sitting on a random street corner gets moved to a street corner where the false alarm from Shotspotter fired. There's not really any harm being done here. reply lifeformed 7 hours agorootparent> The consequences are pretty low to nil. Having American cops rush to your door thinking violence is happening is not inconsequential. Just a few days ago they shot at a kid who was playing with fireworks, due to a false positive. Also, see swatting and its fatal consequences. reply Jcowell 4 hours agorootparentExactly this. When it comes to American Police the consequences are not deterministically nil reply astrea 4 hours agorootparentprevAs much as I hate to participate in political discussions, I have to agree here. No US cop would ever respond to gunshots in a casual manner. Think about Swatting. reply photochemsyn 7 hours agorootparentprevSound classification under fairly well-controlled conditions could be very different from a real world streetcorner situation, where sound can bounce off surfaces and generate different signals depending on direction and distance of origin relative to the collecting microphone. High-quality omni-directional microphones can be expensive and I imagine there would be theft concerns if they used really good ones. reply hcfman 1 hour agorootparentI recommend primo EM272 microphone capsules for use with https://github.com/hcfman/sbts-aru. They are high quality, very sensitive with high signal to noise ratio, lauded for nature recording use cases. They can be bought assembled for around 65 euros in the Netherlands. However these capsules are often found in much more expensive equipment. reply petee 9 hours agoprevI had no idea ShotSpotter was recording conversations, always assumed the nature of analyzing for a sound signature would be throwing much of the data away immediately reply hcfman 1 hour agoparentWell, yeah... that's what an acoustic sensor is. It would get more objection if they called them microphones. reply verteu 8 hours agoparentprev> assumed the nature of analyzing for a sound signature would be throwing much of the data away immediately (INACCURATE, SEE EDIT) It does. The \"conversations recorded by ShotSpotter sensors\" were a few seconds before/after the shooting, and consisted of people saying things like \"[shooter's name] Why are you going to [shoot] me like that, [shooter's name]\"? [1] [1] 'The recording of the second shot also captured the voice of Tyrone Lyles, apparently addressing the person who shot him: \"Ar, Ar, why are you going to do me like that, Ar.\"' https://casetext.com/case/people-v-johnson-5116 edit: I was wrong. Apparently \"the detectors keep hours or days of continuous audio\": https://www.aclu.org/news/privacy-technology/shotspotter-ceo... reply wahnfrieden 9 hours agoparentprevThat’s because it’s generalized surveillance tech marketed to the public as personal safety tech (which it is not per the data) reply chasd00 8 hours agoprevIn Dallas I hear the pop-pop-pop of gunfire virtually every night in my oakcliff neighborhood. Even when the Cowboys score a touchdown you hear gunfire. The police have basically given up. reply grugagag 8 hours agoparentAre people shooting blanks? reply chasd00 5 hours agorootparentNo just random gunfire. People in their cars shooting in the air and then speeding off. They’re definitely not shooting at people otherwise it would be national news every night. I think the local police have resorted to a “just please aim in a safe direction” stance instead of trying to stop them. New years is especially annoying. Something like shotspotter wouldn’t work for this because by the time you get the info and call it in the people doing the shooting are miles away and there isn’t a crime scene per se to investigate. reply sbierwagen 3 hours agorootparent>otherwise it would be national news every night. Well, Dallas had 246 murders last year. https://www.dallasnews.com/news/crime/2024/01/11/1-year-246-... That's a killing every other day, and obviously does not include nonfatal shootings. While it is true that there is lots of death in the news, most murders are not newsworthy. For instance, did you know there were 21 school shootings in 2020? https://en.wikipedia.org/wiki/List_of_school_shootings_in_th... Surprising, right? You certainly didn't hear about a shooting every other week that year. (Granted, 2020 was an unusual year, news wise.) But look at the descriptions of the shootings: \"A large group of men jumped a fence to gain access to Atascocita High Schools football field, when an argument escalated and a 19-year-old was killed.[503]\". \"At Sonora High School in downtown Sonora, a student named Eric Aguiar, 17, was shot and killed in the High School's parking lot.[507]\". \"A 20-year-old University of Alabama at Birmingham student was shot and killed in a campus parking lot outside the student center. Investigators believed the shooting occurred during an arranged meeting to sell headphones.[513]\". Parking lots, dangerous places! Dallas could have a thousand murders a year, or five thousand, and you'd never hear about them-- if the murders were boring enough. reply demondemidi 8 hours agorootparentprevI've never actually seen \"blanks\" at any sporting goods or gun store in the 15 years I was really into guns. Reloaders typically reload rifle bullets, so I find it highly unlikely anyone is shooting blanks. Especially during drunken sportsing celebrations. reply sbierwagen 3 hours agorootparentIf you're buying ammo online and sorting by cost per round, it's easy to make an expensive mistake: https://twitter.com/westernunion2k/status/141712299595750604... reply tjpnz 4 hours agoparentprevSounds like a good place to install ShotSpotter. reply crtified 9 hours agoprevI can't help but think how easily such a system - which is hardly sophisticated, in technical principle - could be used to pinpoint things that are 'problematic' in my neighbourhood. Loutish vehicle behaviour of various kinds. The loud Harley Davidson and dirt-bike signatures associated with the comings-and-goings of local gang members. Squealing tyres of deliberate burn-outs on the road. The occasional fool loudly blasting down the road at twice the speed limit. Things which the current system of \"wait until someone gets annoyed enough or gets the courage to call the police to complain, and one might arrive 15 minutes later, by which time the coop has been long flown\" allow to run mostly unchecked. But those thoughts go hand in hand with a vague but distinct discomfort. reply hcfman 1 hour agoparentIndeed, from a playing around perspective it can be a lot of fun. You do need to be able to identify the start time of a particular sound event though on 3 or more microphones (Technically 4x mics, there are two solutions to a 3 mic localization). reply ryukoposting 5 hours agoparentprevSome of the illegal things you listed aren't things that benefit much from a hastily dispatched response. If you want to catch people on cars or dirt bikes driving down the street, you kinda have to already be there. Also, a couple of the things you listed are nuisances, but not illegal activity in their own right. ShotSpotters don't repel crime, let alone prevent it. They're intentionally covert, as shown in the OP, which gives credence to the notion that they aren't intended to deter criminal activity from the surrounding area. If anything, repelling/deterring crime would defeat the purpose of the technology. At best, ShotSpotter merely detects crime, and its effectiveness in that capacity is kept a secret. The world of police tech is a knee-deep in snake oil. A bit of transparency would go a long way for ShotSpotter. reply crtified 2 hours agorootparent> Some of the illegal things you listed aren't things that benefit much from a hastily dispatched response. If you want to catch people on cars or dirt bikes driving down the street, you kinda have to already be there. Yes and no. Intelligence (in the data sense of the word) can accrue usage patterns. You might not catch them that time, but you know where they'll be next time. What routes they travel. Where to focus. If it's a live event, the police officer is not having to stand there fruitlessly questioning a witness about which direction the offender hooned off in 5 minutes ago - the system is already telling them, by tracking the relevant data. It's a form of telemetry. And it's also quite a disturbing (to use an overused phrase!, but which I hope is justified here) slippery slope. reply hcfman 2 hours agoprevI have a project for the Raspberry Pi that provides for sound localization via time difference of arrival (TDOA). In a similar manner I suppose as shotspotter. There was a case recently in America where a grandfather was jailed for a significant part of a year based on a shotspotter localization and no other physical evidence such as gunshot residue. If citizens in such areas run their own systems they would have a means to provide counter evidence to that provided by shotspotter. Currently they have no means to do that. Even the times of the shots they have to take shot spotters word for it. Recordings by citizens themselves is an inherently safer approach because their sphere of influence is considerably smaller. Recordings are written to a separate partition on an SD card, it’s pretty simple to encrypt this partition as well if you like, I’ve done that. For those who are interested each node can be made very cheaply. It will run on a Raspberry Pi zero with a 7 euro GPS. It can also run portably on batteries. Here are relevant links: https://github.com/hcfman/sbts-aru https://hackaday.com/2023/12/30/localizing-fireworks-launche... https://medium.com/@kim_94237/tdoa-sound-localization-with-t... reply xeckr 8 hours agoprev>Many assumed that ShotSpotter coverage was concentrated in disadvantaged parts of the city, an unsurprising outcome but one that could contribute to systemic overpolicing. The author presents this as a negative but it is obviously a good thing. If there was an increase in gunfire in my neighbourhood I would hope that police increases their presence, lest the \"disadvantages\" begin to accumulate. reply TaylorAlexander 8 hours agoparentYour argument assumes that the devices are only used as marketed. My understanding is that this assumption doesn’t hold, and that police regularly use these systems as an excuse to harass people in poor neighborhoods. The reports I have read suggest that police will enter a neighborhood they want to patrol, and if they see someone they don’t like they can claim they were called in by shotspotter, then shake down the person and if they find something, arrest them for that. This is textbook over-policing, which I assure you would not want to have done to you, and that is the precise concern mentioned in the quote. reply xeckr 7 hours agorootparentYou are suggesting that police regularly invent false positives for ShotSpotter. Is there any evidence to support this? This would seem like something that would easily show up on an audit. reply TaylorAlexander 6 hours agorootparentSourcing this for you, I see that there has indeed been a great deal of rigorous investigation, reporting, and lawsuits regarding the ways ShotSpotter leads to overpolicing, though I had misremembered one thing - the false detections come from the system itself, though this does also lead police to perceive areas as more dangerous and then patrol them more often, leading to measured increases in stop and frisk pat downs. The ACLU has a thorough article breaking down reporting from the City of Chicago Inspector General, Northwestern School of Law’s MacArthur Justice Center, Vice news and the Associated Press. ACLU article with links to the other reports here: https://www.aclu.org/news/privacy-technology/four-problems-w... Key takeaways from the reporting linking ShotSpotter to over policing listed here: 1) ShotSpotter false alarms send police on numerous trips (in Chicago, more than 60 times a day) into communities for no reason and on high alert expecting to potentially confront a dangerous situation. Given the already tragic number of shootings of Black people by police, that is a recipe for trouble. 2) Indeed, the Chicago IG’s analysis of Chicago police data found that the “perceived aggregate frequency of ShotSpotter alerts” in some neighborhoods leads officers to engage in more stops and pat downs. 3) The placement of sensors in some neighborhoods but not others means that the police will detect more incidents (real or false) in places where the sensors are located. That can distort gunfire statistics and create a circular statistical justification for over-policing in communities of color. reply xeckr 5 hours agorootparentThe summary here seems to be that no, police do not regularly invent false positives for ShotSpotter. Regarding: 1) How do you know you are dealing with a false alarm? Given the seriousness of gun violence, isn't it perfectly reasonable to send someone to investigate the situation rather than to ignore it? 2 and 3) Isn't it also the case that black neighbourhoods in Chicago have the highest gun violence and murder rate? What else would you expect from ShotSpotter other than for it to confirm that those neighbourhoods are indeed the ones with the most shots fired? reply TaylorAlexander 5 hours agorootparent> The summary here seems to be that no, police do not regularly invent false positives for ShotSpotter. Right. That was the part I referred to as misremembering in my above comment. The false alarms come from the system itself, not necessarily police lying about it. However the reports from multiple sources do say that false alarms occur at an alarming rate, and this leads to over policing. I wanted to provide a citation for the article's claims of over policing, and I believe I have done so (the ACLU article has multiple high quality sources clearly linked in the first few paragraphs). Your comment mentioned that shotspotter leading to a high police presence is \"obviously a good thing\" and that if you lived there, you would want this too. But if the residents were happy with what was happening, there would be no controversy. The problem with over policing is that it leads to unfair treatment of marginalized communities, and this is what people are unhappy about. It seems like you are trying to reason away these concerns, or get me to answer your follow on questions, but I am not an expert here, just someone who remembered seeing articles about issues with the system. I would encourage you to review those sources and check their methodology regarding false positive detection rates, and seek additional information about over policing. reply nimbius 8 hours agoprevHard to imagine this can discern between things like engine backfires, fireworks and garbage trucks effectively enough to be anything more than a really expensive checkmark on some captains yearly performance review. reply jacurtis 8 hours agoparentThey can't. There are a lot of false positives. That has always been one of the biggest criticisms of Shotspotter. reply goldenshale 8 hours agoprevIt just makes sense to put the sensors near the phenomena being sensed, and if people know where they are they could be manipulated. If guns are going off and people are getting caught, that seems like effective policing, not over or under policing. reply IceHegel 6 hours agoprevThis phrase \"systemic overpolicing\" and ShotSpotter both come from the same mind - the mind of the state. The state - which like most organizations is concerned mostly with preserving itself - has an interest in the surveillance of the population and in shifting blame from it's failures to deal with poverty and crime to skapegoats: the police, racism, property taxes, etc. The west is run by priests (professors, advisors, journalists, students, diplomats) with the support of the merchants. Priests always pretend it is flipped, but it's not. One \"tell\" is that the priests are never the villains in Hollywood movies. The other groups (warriors, merchants, and peasants) all do even villain duty. Bias shot-spotter placement is a classic case of priests blaming merchants. There might even be something to the substance, but the priests run the show - not SoundThinking Inc. reply skim_milk 5 hours agoparentHmm - preservers, creators, and destroyers doing their jobs. Is this not what a healthy, functional society looks like, at least in any philosophy grounded in (albeit painful) reality? Or would you rather the preservers stop doing their job and let the others discover the consequences of their self-destructive fantasy? We might learn how pathetically dependent everyone is on each other for the N+1th time in recorded history. reply brikym 7 hours agoprevI have some noisy neighbours and I've thought of the same idea for controlling noise in neighbourhoods. You could have a microphone on every lamp post and send people fines for violating the rules. reply llm_trw 7 hours agoparentI've been having a nightmarish time trying to track down intermittent low frequency industrial noise. It's over the EPA regulations, it's neighborhood wide, and it is on for 2 hours between 11pm and 1am on random days. The EPA did monitoring of the house and site but couldn't pinpoint where it was coming from because of how low frequency it was. This isn't surveillance, this is the equivalent of finding who is dumping raw sewage in your drinking water. reply chris_va 7 hours agorootparentNow I am curious For 20Hz noise, are there too many reflections to use an oscilloscope with 3 mics on a 25ft baseline to triangulate it (you'd have to elevate the mics)? reply holonsphere 6 hours agoprevSpoiler alert: with a secondary audio source you can map out physical spaces as easily as one might with lidar reply jjallen 3 hours agoprevDo these record audio constantly or only after shootings? Seems like societally we would want audio to be recorded after shootings? reply heywire 5 hours agoprevSomething along these same lines — I feel like I’m seeing those “Flock” cameras everywhere now. So between Shotspotter and Flock, you’re pretty much always under surveillance. reply ALittleLight 8 hours agoprevI've also been blogging about ShotSpotter and review the evidence that the system is good or bad. https://quickthoughts.substack.com/p/shotspotter-good-or-bad There's a lot of evidence that ShotSpotter detects almost all gunshots and that's been validated by multiple third party groups. ShotSpotter also seems to alert to things that are either false positives (construction sounds, fireworks, etc) or are not useful. Chicago IG says 9/10",
    "originSummary": [
      "A leaked spreadsheet in 2024 exposed that ShotSpotter (now SoundThinking) deployed acoustic sensors in cities to detect gunfire for law enforcement, sparking criticism over secrecy and civil rights implications.",
      "The concentration of sensors in Albuquerque suggests a link between income levels and surveillance, raising concerns around privacy and misuse of surveillance tech amidst ShotSpotter's evidence manipulation and lack of public accountability.",
      "Despite assertions of precision, there are limited independent assessments on the system's efficacy, highlighting the need for transparency and oversight in surveillance technologies."
    ],
    "commentSummary": [
      "The article delves into the controversy surrounding the Albuquerque Police Department's use of ShotSpotter technology for combating gun crime, highlighting concerns about effectiveness, transparency, privacy, and accountability.",
      "Issues include the system's high volume of priority calls, potential data manipulation, privacy worries, surveillance data misuse, policing biases, and civil rights impact.",
      "Criticism focuses on deploying ShotSpotter in low-income areas without proper supervision, along with doubts about data accuracy, privacy breaches under the Wiretap Act, and potential overpolicing and racial biases in surveillance application."
    ],
    "points": 329,
    "commentCount": 250,
    "retryCount": 0,
    "time": 1709423762
  },
  {
    "id": 39573093,
    "title": "Wintergatan's Mesmerizing Marble Machine Music",
    "originLink": "https://www.youtube.com/watch?v=IvUU8joBb1Q",
    "originBody": "[this video only contains music and sounds] [light switch sounds] [light shutters opening] [footsteps] [machine starts up] [marbles rolling sound] [clack] [vibraphone plays] [♪ Wintergatan: Marble Machine ♪] [clack] [snare starts playing] [clack x 3] [cymbal crash] [bass guitar, kick drum, and hihat start playing] [♫] [cymbal crash] [marble rolling sound] [clack x 2] [machine braking sound] [single vibraphone notes] [manual vibrato control] [clack x3] [machine restarts] [bass note sounds] [melody slowly starts] [clack] [hihat starts playing] [clack] [snare drum starts playing] [clack] [kick drum plays] [clack x4] [soft cymbal crash] [only vibraphone and bass play] [clack] [snare starts playing] [marbles bouncing and rolling sound] [soft clack x2] [music pauses] [clack x4] [cymbal crash] [all instruments resume playing] [♫] [cymbal crash] [♫] [music slows down] [♪ Wintergatan: Marble Machine ♪] [music ends] [wood creaking] [marbles come to a stop] [light switch-off sounds] [silence] // Subtitled by Wintergatan Writers. Join our team on discord. //",
    "commentLink": "https://news.ycombinator.com/item?id=39573093",
    "commentBody": "Wintergatan Marble Machine (2016) [video] (youtube.com)316 points by kaycebasques 17 hours agohidepastfavorite104 comments calibas 16 hours agoAccording to the artist himself, this video is a bit misleading as the majority of what you hear in this video is not from the machine. There were some fundamental flaws in the first designs, he almost gave up on the whole project, but he's recently come back with plans for a whole new version: https://www.youtube.com/watch?v=AbmMnu-NpaI He's very open about the whole process, it's quite interesting from an engineering perspective. Designing the marble divider: https://www.youtube.com/watch?v=Y83I8mLKufo Testing the new fly wheel: https://www.youtube.com/watch?v=8ouH21npL58 reply datadrivenangel 14 hours agoparentHe's on his third iteration of the machine because he keeps over engineering parts and starting over, in a way which is simultaneously impressive and heartbreaking. reply guhcampos 12 hours agorootparentI follow him and coincidentally (or not, maybe there's some correlation with this coming back to HN?) he posted a video last week with sort of an epiphany. According to him, he realized he's been trying to engineer a functionally perfect machine this whole time, and that's pointless, because it's never been about the machine function, but about the artistic expression of creating such machine. From this, he derived that instead of optimizing the machine for function, he'll begin optimizing for fun, looks and generally the \"cool\" of the machine. I'm excited to see what's going to happen from now on. reply starky 8 hours agorootparentI'm happy to hear he is finally realizing the error of his previous decision, but this should not be an epiphany. So many of us that followed the project told him exactly that when he decided to throw out the MMX and start over. I still worry that he hasn't learned the lesson that \"perfection is the enemy of good\" and will use yet another change of direction/method to avoid actually finishing something. reply nagonago 9 hours agorootparentprevI've lost count of the number of \"epiphanies\" he's had. reply danpalmer 12 hours agorootparentprev> he posted a video last week with sort of an epiphany He does this every year or so. He always has some big takeaway – engineering for fun, getting back to enjoying his work, getting anything finished so he can go on tour which he enjoys... I followed the channel for a few years because I wanted to see a machine come together, but I realised over time that the machine is not the point. It's a self-help channel, it's about productivity, burnout, and the process of engineering and design. If that's what you want, great. But I get enough pontificating about engineering process in my job, and I was there for the machine, so I gave up. If he ever goes on tour I'll be there, but I'm not holding my breath. reply pests 11 hours agorootparentThe best time period was when the entire YouTube maker community was building parts for it and making their own videos for the process - felt like something really special. reply danpalmer 10 hours agorootparentYeah this was good, which then made it even more sad when each part got cast aside as having been the wrong solution in some way. I'm sad to think of all the effort that went into the project from others. It seemed like a team came in to support him at one point, but then he dropped off YouTube in favour of live streaming (at inappropriate times for many), only to return later, without the team. reply jncfhnb 8 hours agorootparentprevI remember him saying something similar like a year ago or more. I like his pursuits. I would personally rather he make more music though reply bspammer 9 hours agorootparentprevFunny that he’s only realising this now when he’s had comments telling him for years pretty much exactly this. reply bborud 39 minutes agorootparentprevThis is why I can't watch him anymore. He has really painted himself into a corner and allowed this to become an obsession. He would have been happier if he had just given it the three months he initially thought the MMX project would take, and when that got out of hand cut his losses and dumped the project. He's a good composer and musician. He has hardly made any music for years and his band members are probably not going to wait around. Sure, he might actually get there in the end, but at what cost? Both monetary and in terms of mental health. Yeah, it has been fascinating, I've learned a lot from watching him, and I really want him to succeed, but this is painful to watch. reply fho 13 hours agorootparentprevThere is that one shot where his marble divider tips over and 100 marbles fall out. You can see the tears welling up in his eyes... my guess is that he was at the brink of depression if not full on depressive at that point. He addresses that in a later video, but that shot really hit too close too home for me. reply Aloha 12 hours agorootparentprevWatching him has been watching the second system effect in real time. reply Aardwolf 11 hours agorootparentprevIt got a bit strange when he suddenly got into web 3.0. Not sure what happened to that but I don't hear much about it anymore fortunately. reply Rapzid 10 hours agorootparentThat's most people's web 3.0 experience lol. reply pests 11 hours agorootparentprevI literally can not watch another video about the gate mechanism. I'll still watch one of his videos here or there, but the instant any gate discussion comes up I have to close it. reply rallemoose 14 hours agorootparentprevPain is temporary. Glory is forever. reply dodslaser 14 hours agorootparent*bittersweet angle grinder noises* reply nextaccountic 13 hours agorootparentprevI love his mad scientist project (I liked the characterization from some comments below \"slow descent to madness\") and I'm glad he got enough funding from patrons Is it practical? No, but he had real progress (he's not just walking in circles) and he has acquired real engineering chops in meantime Also there are other marble engineers in Youtube and he checks out their progress as well, see this https://www.youtube.com/watch?v=JLD_Nl12oacv he left a comment. I think this kind of cross-polination is important So I think he will eventually ship something (and this something might mean a music video on Youtube but I hope it also mean a live concert) edit: if I had to criticize him, it would be only about his worship of the likes of Elon Musk. But, it's pretty tame/harmless (if a bit cringe) and if it inspires him to do better engineering, all the better reply donor20 6 hours agoparentprevMy understanding was more that the machine was not reliable and he basically had to piece the piece together / so each shot was the perfect run of potentially a number of attempts reply calibas 6 hours agorootparentHe mentioned two main problems, the marbles would get jammed and the timing was off so the beat wasn't very tight. Both of those things should be fixed, or at least greatly improved, in the next version. reply beAbU 3 hours agorootparentThis has been his \"problem\" for almost a decade. He's trying to build something that's midi-tight. As a musician, somehow he forgets that real musicians also lost the beat now and then, and it makes the music more interesting. The number of times he's postulated that some design would fix these problems is too damn high. reply zerr 12 hours agoparentprevHow does he convert a variable speed hand motion to a constant speed rolling? Some spring mechanism? reply pests 11 hours agorootparentA problem solved by old music machines. Here's his recent video on it. https://www.youtube.com/watch?v=i63t7ekNFoY TLDR: speed governor reply zerr 13 minutes agorootparentCool! Another question: how are those actual song drums/cylinders made? i.e. how are songs programmed? Especially interested in those old machine drums. reply beAbU 3 hours agoprevThis video was incredible when it came out. The song itself, and the intersection between art and engineering was mind blowing for me back then. The creator released some videos later about making that machine that was also great. Then he started building the second version of the machine. It was supposed to fix all the \"issues\" he had with the first, and be something that can tour the world with. Super exciting! About 90% done, he abandoned the project to start with a /third/ version for reasons I _still_ don't understand. I think he allowed \"perfect\" to be the enemy of \"done\" and he frequently went down rabbit holes of design and \"innovation\" that left me frustrated because it was clear to me his original concept was \"good enough\" Sadly I stopped watching around this time. I'm sure his content is still interesting, and he definitely innovates in the marble machine space. But he stopped making music, and now only focuses on 3D printed marble gate designsto my eyes. reply luplex 1 hour agoparentSo he said that he misrepresented how good the MMX was in order to make good content. Apparently, it was still too unreliable to actually be usable. So for the MM3, he decided to do more engineering and less good content. His videos are less interesting since, and contain less music. reply barnabask 16 hours agoprevIf you enjoy Wintergatan’s clever marble videos, check out Ivan Miranda’s marble clock project: https://youtu.be/JLD_Nl12oac. Ivan relies on 3d printing vs. Martin’s emphasis on machining and welding, but they are both charming and instructive creators. reply shooshx 28 minutes agoparentThough these two guys could not be more different from each other. Ivan actually has a toy marble machine video which he seemingly build over the course of a few weeks. I feel like he could design and build from scratch a fully featured MMX in not much more than that. reply itronitron 12 hours agoparentprevAlso, marble video aficionados might also enjoy this >> https://www.youtube.com/watch?v=Lso6OSfKrrk reply ruk_booze 11 minutes agoprevI have been hoping for long that he would finalize this machine of his and start working on a new album. Please get me right, the machine is marvellous but I love their music even more. reply nextaccountic 13 hours agoprevI love love love love love his other instrument, the modulin https://www.youtube.com/watch?v=mFfe4ZRQOH8 (just the original music it played) https://www.youtube.com/watch?v=MUdWeBYe3GY (explains how it works) https://www.youtube.com/watch?v=QaW5K85UDR0 (playing music from mega man) Selected comment from the last video > I love how it's an instrument with the aesthetic style of \"functionally a mess\" reply Trellmor 17 hours agoprevHe is currently working on the 3rd evolution of the marble machine and posts build updates on this YouTube channel. Interesting intersection of music and machining content. reply kzrdude 17 hours agoparentWhat happened to his 2nd evolution of it, that one was being built for a long time too? reply kibwen 17 hours agorootparentIt's a bit of a touchy subject. It's clear that he's a brilliant musician and self-motivated to the brink of mania, but he struggles with perfectionism and his insistence on reinventing the entire field of mechanical engineering from scratch precludes him ever actually finishing the project to his own impossible standards. If he didn't have a huge community of experienced, fascinated, and often frustrated engineers and manufacturers pointing out his most egregious missteps, he'd be sunk. The past near-decade has involved being sucked into fractal rabbit holes due to unknown-unknowns while obsessing over imperceptible details. The second machine was thrown out entirely and he started from scratch in an attempt to fix what he saw as fundamental flaws with it, and while his process with the third machine seemed promising at first, at this point it doesn't seem like he's really any closer to success. His videos are often entertaining (he's very charismatic and enthusiastic), and you'll learn a decent amount about engineering. But the most important thing that you'll learn are the unstated lessons: the necessity of compromise and the importance of setting measurable and realistic goals if you ever hope to actually achieve a given result. Though if nothing else, I applaud him for being so open with his efforts, especially when things don't pan out like he was expecting. reply barnabask 16 hours agorootparentI enjoyed watching his videos for a few years, but I eventually had to stop because it was so hard to watch what you describe. You put it very kindly; I would have called it a channel documenting a slow descent into madness. Maybe it was my own latent perfectionism that made me so uncomfortable watching him obsess, repeatedly restart, second-guess, overanalyze, self deprecate, etc. It’s a hard thing to relive vicariously. reply magnat 13 hours agorootparentOne might say he lost his marbles. reply softjobs 11 hours agorootparentUpvoted for the pun, with the sad caveat that also it feels like a human tragedy unfolding. :-/ reply Sharlin 11 hours agorootparentprevI shouldn’t upvote this, but I’ll do so anyway. reply neontomo 15 hours agorootparentprevExactly how I feel about it. When he made his video about engineering principles from Elon Musk (who I admire as an engineer), my heart just sank. I recognised that he'd begun setting standards for himself that are necessary for mission critical projects like space flight and driving, but lost touch with why we are interested in his Marble Machine - which is fun. reply an1sotropy 15 hours agorootparentHe actually just posted a video in which he admits he lost the plot, and forgot that the real goal is something that is fun. I hope he finds his way back to that! https://youtu.be/BpJYqC4PWEw reply krisoft 15 hours agorootparentprevHe was always clear on his expectations. He wants to make a machine he can take on a world tour. That's his stated goal. The consequence of that is that it has to be reliable enough to play through a full concert without maintenance or breakdown, and it has to be robust enough that it can be transported from place to place. These are his hard requirements. Then there are some less well defined requirements. Which is that the machine has to play nice music and has to be a marble machine as Martin understands it. This last is the real constraint. Otherwise he could just buy a midi keyboard which would fulfil all the requirements about reliability, robustness and quality of music, but would fail the spirit of the endeavour. reply okamiueru 14 hours agorootparentAll the things you describe, are all reasonable constraints and goals. However, the issue is in chasing sub millisecond standard deviations. Which is amusingly the point at which you might as well buy a midi keyboard. reply kristofferc 14 hours agorootparentprevWhere does \"tight music\" come into those constraints. reply krisoft 13 hours agorootparentI count that under the first of the two fuzzy constraints I wrote about: “the machine has to play nice music” I agree that there Martin seems to be aiming for a very high degree of repeatability in timing, but it also seems that he has designs which meet those expectations of his and this was not the reason why he abandoned the second attempt. (Ad far as i can tell based on the videos.) reply sbuttgereit 11 hours agorootparentI have to admit, I find this a bit ironic. Many of the digital sequencing and notation products I've worked with went out of their way (arguably) to play \"less-tight music\" through various \"humanizing\" features. Yes, we want music that is sufficiently accurate and \"tight\"... but within the confines of human capability. The slight errors of both time and intonation in some cases give music a much more human feel. Now to be fair, I don't want to suggest that this sort of human inaccuracy is mere randomness either: it's typically not just random error... there's usually a bias and it definitely within limits (unless you're a bad musician of course :-) ). reply andersa 6 hours agorootparentprevI remember watching his videos on this topic and never being able to hear any difference between the supposed \"good\" and \"bad\" examples. reply pbronez 9 hours agorootparentprevHe actually partnered with an agency and released a virtual marble machine as an app and VST reply whereismyacc 15 hours agorootparentprevIt's not just perfectionism, he struggles to get the machine functional at all. Afaik the original video (this post) is cut together from different runs and generally hides a lot of the scrappy issues with the first machine. He wants to get the new one actually working well enough to play consistently, and to be moved around. reply gabesullice 16 hours agorootparentprevI try to remember that I've learned my engineering lessons in small doses, over many years, and often in an environment where I wasn't the most senior engineer, without the full scope of the design under my control. As I've grown as an engineer, more of those things have come into my purview, and I still have many more lessons to learn. Martin is speed-running the game, in public, and deserves a lot of leeway. reply kibwen 14 hours agorootparent> Martin is speed-running the game, in public, and deserves a lot of leeway. This is how I felt at first, and I appreciated (and still appreciate) the frankness of his verve for experimentation. But by this point I wouldn't use the word \"speedrunning\" to describe his progress; he appears to have found the practical limits of autodidactism. If his only goal in life was to produce the machine (which, to be clear, it isn't), then it would have been much faster to go to school for a few years and get a degree in engineering, while apprenticing as a machinist on the side. His publicly-broadcast education, while entertaining, is anything but efficient. reply jacobolus 12 hours agorootparentThe people who go to engineering school for a few years generally get engineering jobs, rather than making crazy art projects. There's plenty of room in the world to also fit some autodidacts following their dreams in apparently inefficient ways. reply SAI_Peregrinus 17 hours agorootparentprevI think in the last video or 2 he finally had the revelation he needs to have a chance at success; he's found that the engineering must support the design, not control it. We'll see if it holds up. reply themoonisachees 10 hours agorootparentHe has had this realization several times over the years. Good luck to him, but at this rate I don't believe he'll ever manage to finish it, and if he ever does he still won't be happy with it. reply Zondartul 15 hours agorootparentprevI won't say anything about the viability of the design #2 vs #3, but from purely entertainment point of view, it was fun and relaxing to watch his regular tinkering videos while he was working on the second machine, but once he stopped, his channel became an emotional rollercoaster. It's just too emotionally draining to watch the later videos involving machine #3, so I stopped. reply AceJohnny2 16 hours agorootparentprevYou are 100% on the mark. I really loved his series building the second one, but when he decided that it was fundamentally flawed and he needed to rebuild from scratch, I stopped watching in frustration. He's really talented, but I'm just... sad for him. reply windowshopping 15 hours agorootparentprevYou know, I always remembered the Wintergatan Marble Machine and occasionally idly wondered why I never again saw anything new from someone who must surely be incredibly talented. This explains that. reply kibwen 14 hours agorootparentHere's something of his that's entirely unrelated to marbles, it's a handheld modular synthesizer of his own design with an analogue fretboard that he calls a \"modulin\": https://www.youtube.com/watch?v=QaW5K85UDR0 reply mock-possum 12 hours agorootparentReminds me of an Otamatone! reply Eji1700 13 hours agorootparentprevThe “reinventing” issue is so huge in all fields. I’ve watched many smart people try to reinvent or discover things that are well known and tested because they’re not “perfect”. You really need to be able to evaluate if something is worth your time and it’s often best to just try what exists and only iterate if needed. Especially when you actually need to deliver a product reply tibbydudeza 13 hours agorootparentprevReminds me of my first coding job - I obsessed over writing the best code and as a result I never delivered anything on time and it was full of bugs because I never finished anything and refactored and restarted. A kind old hand took me aside and taught me about KISS (Keep it Simple) and it must be good enough. reply spamatica 17 hours agorootparentprevThe second one is being completed (as far as I understand) by a team in germany at a music machine museum (Musikkabinett). Their channel: https://www.youtube.com/@Musikkabinett reply DrSiemer 17 hours agorootparentprevThe second machine turned out to be unfit for one of the main goals: live performances. Following Martin's journey has been a privilege. His honest insights on the struggle of trying to balance hard design requirements with keeping that which made the original project fun and playful have been insightful and fascinating. reply proteal 17 hours agorootparentprevI haven’t followed it too closely, but he posted a video saying that previous iterations of the machine didn’t make good music. They were really loud (mechanical noise drowned out musical noise) and didn’t play music in time. In fact, the video from the submission has had its audio significantly edited to sound pleasing. I believe he posted the raw audio a few months ago in a video. His current design looks much more promising. reply vintermann 17 hours agorootparentI think it was also throughput and reliability issues. He gave up on it in connection with a marble tube bursting. reply DrSiemer 17 hours agorootparentThe guys that actually finished it also agreed that it would not have been possible to tour with this iteration of the machine. reply fl7305 17 hours agorootparentprevIt is up and running in a music museum in Germany. reply Waterluvian 16 hours agorootparentprevHis MMX video blog is the textbook go-to example for letting perfect be the enemy of good. reply gexaha 16 hours agoparentprevwas there any other music done except for this track? reply boxed 16 hours agorootparentDon't know about the original, but there are some music on the channel with unfinished versions of the v2 machine. reply SOLAR_FIELDS 9 hours agoprevEveryone is chatting about the engineering aspects of this project which is to be expected, but putting aside that for a second since it’s been discussed to hell: I really enjoy Molin’s music, when he does release some. He is well known for the marble machine but before that he had a band called Detektivbyrån - minimalist electronica that got famous performing on the streets of Göteborg. IMO his work around that is just as interesting as the marble machine - it really brought a breath of fresh innovation to street performing when Detektivbyrån’s album’s were released nearly two decades ago. reply HNArg024 10 hours agoprevI was so hooked to his videos a couple years ago... he was making real progress to what was his 2nd iteration of the marble machine, then he suddenly decided he had to start from scratch and got into some crypto/web3.0 thing. That was the last video I watched. reply GuB-42 10 hours agoparentI have watched many of his videos, including recent ones and I don't remember anything about crypto/web3.0. He kind of an Elon Musk fan, but far from the most obnoxious one. The \"start from scratch\" part is annoying to many, including myself, but he explained his reasons. And a group took back the 2nd iteration (MMX), trying to fix it, and mostly agreed. The goal was to have a machine playable on stage, and there was too many problems with that. reply moogly 1 hour agorootparent> I don't remember anything about crypto/web3.0 He had a phase for a while where he tried to run the project as a DAO. Didn't make any sense to me, but that's web3 for you. reply paradox460 9 hours agoprevIt's been rather sad watching him fail and fail again, often due to a misplaced sense of perfectionism. I can't really stand to watch his videos anymore, as they're like watching a mad artist defeat themselves For similar, yet grounded and successful projects in this vein, I've been watching Ivan Miranda's videos. He recently built a massive marble clock, and it's really fun watching him realize when it's good enough, and declare it finished reply adzm 17 hours agoprevThis is cool but have you seen barcode scanner music? https://youtu.be/2CvnajExX-A reply kaycebasques 17 hours agoparentActually I did stumble across it on my \"weird music instruments\" rabbithole last night! They also figured out how to somehow play TVs and a space heater as guitars?? https://youtu.be/A0VYsiMtrNE?si=8SUpClphR2f1hBFf reply seabass-labrax 8 hours agorootparentThe sound of that piece reminds me a lot of Emerson, Lake and Palmer's rendition of 'Fanfare for the Common Man'[1]. Progressive as Progressive Rock is though, I'm not sure ELP would have been let into the Toronto Olympics stadium with an assortment of electric fans and televisions! [1]: https://www.youtube.com/watch?v=c2zurZig4L8 reply arrakeen 9 hours agorootparentprevei wada is immensely talented, see also his open reel ensemble[1] [1] https://www.youtube.com/watch?v=i-6WfT8RAh4 reply seabass-labrax 8 hours agoparentprevThat'll be Lindt's most cost-effective product placement yet! reply iseanstevens 15 hours agoprevRobotic fun instrument I worked on this back in the day. flying balls and wine glasses and drums. I did the lighting and later redid the real-time low latency streaming: https://bea.st/absolut-quartet reply IggleSniggle 15 hours agoparentAwesome!! reply dzink 10 hours agoprevThe music is beautiful and the machine looks like a true labor of love. Looking up the machine, it looks like they sell apps that mimic the machine sounds and sound packs worth hundreds of dollars per license, so the video is a great viral sales tactic for their real products. The closest thing to the sound of the machine I found is a Kalimba instrument. The more notes the better. I was able to replicate the song from the machine on a kalimba at home. reply u320 17 hours agoprevI think music machines like this would be a perfect application of digital computers. reply shagie 14 hours agoparentHave you watched the Animusic series ( https://www.youtube.com/@animusic ) ... especially Pipe Dream - https://www.youtube.com/watch?v=hyCIpKAIFyo Be sure to watch the \"Creating the Animusic DVDs\" pair of videos. https://animusic.fandom.com/wiki/Pipe_Dream reply fellerts 14 hours agorootparentMartin has said that those videos were his inspiration for the first marble machine. Those, and Matthias Wandel's gear template generator! reply iamtedd 10 hours agorootparentIn fact, his comment is at the top of the list on the Pipe Dream video. reply rzzzt 11 hours agorootparentprevOne of the early Radeons were advertised with a real-time demo that plays Pipe Dream: https://youtu.be/uG1XkEnYyUc reply shlubbert 17 hours agoparentprevPerhaps one could even apply AI and put it on the blockchain! reply ysofunny 16 hours agoparentprevthe programable part of the machine, the tracks themselves are comparable to a midi file I think part of the point of this project is to avoid electronics and digital tech in the final machine. personally I think it's what makes it so interesting, he's interested in the mechanical design and engineering aspects, not the digital ones reply QuackyTheDuck 17 hours agoparentprevCould you please explain? reply whereismyacc 15 hours agorootparentThe whole machine is just an overgrown midi player in a sense, but also that's not the point. reply mock-possum 12 hours agorootparentprevIt’s a lot cheaper to set up something like this in a virtual space - it also takes up a lot less space. VCV Rack 2 is a free way to very closely replicate the experience of building eurorack module synthesizers - without the cost of buying all the rack gear, and without needing to devote space IRL to assembling and organizing all the parts. I could imagine a similar approach for designing and operating musical marble machines like this (in fact I’d almost be surprised if something doesn’t already exist, akin to roller coaster tycoon’s coaster design tools!) reply zabzonk 14 hours agoprevalso, a marble clock: https://www.youtube.com/watch?v=8IF4esSNA3k reply Exoristos 9 hours agoprevTo those lamenting Martin's \"descent into madness,\" I'm not sure I'd agree. In fact, I assumed, starting a couple of years ago, that he's drawing out the process deliberately as a steady source of income. As long as people remain fascinated, then, well, why not? We still watch a video of his from time to time, but I'm not expecting a finished machine and world tour soon, or ever. reply quasarj 14 hours agoprevI watch it every once in a while. He's done a lot more, but somehow this one is still the one that really excites me. reply gclawes 15 hours agoprevHey, it's the DarkHorse Podcast music! I forgot that was Wintergatan, cool! reply tibbydudeza 13 hours agoprevThe marble machine song and video of the Rubik's cube contraption was whimsical and so good but he released no music since the 2013 album and that song in 2016. He is seemingly obsessed with building something for a couple of years right now - would prefer he just stick to using synthesizers and make music. It is reminds me a chap I met at uni - he sat in the Applied Maths computer lab every time when I was there and one day I asked him what he was doing as he was not goofing around like the first years playing games or destroying dot matrix printer ribbons making greeting cards but writing some serious code in TrueBasic. He was writing his own programming language called \"Tree\" and he even showed me a programming manual he had written for it - it had a Tree on the cover - serious mad scientist vibes. reply LegitShady 12 hours agoparenthe's had a handful of singles out in 2018 and 2019. He's also released a VST too I think, although I didn't get it. His passion is his passion. He's a talented and inquisitive and seriously interested in this project. If he can afford to devote his life to his passion and not be broke he's winning life, in my eyes. reply hettygreen 10 hours agoprevI started following this guy making the MMX (second verison of this machine) around the same time I was designing and prototyping the most complicated project I've ever worked on. Tuning in every week and seeing him make progress, or run into a failure and then eventually overcome it kept me motivated with my own personal project. In fact I was even racing him, trying to finish mine before the MMX was completed. The internet is full of b.s. influencers telling you to be motivated, but Martin and the Marble Machine definitely kept me going and kept it fun. reply pfannkuchen 11 hours agoprev [–] How much is hacker news discussion topic focus second order steered by recommendations algorithms? I just had this one recommended and now it’s here, seems to happen a lot lately! reply pvg 11 hours agoparentIt goes both ways all the time, things from the Greater Internet Hive Mind get posted on HN or HN posts get regurgitated by the Greater Internet Hive Mind. Occasionally, the cud goes back and forth multiple times (as cuds do), for instance there've been cases of HN->social media->media coverage->HN posts about the media coverage. The order and the participants can also vary, of course. reply rzzzt 11 hours agoparentprevI had this in my Facebook memories, it is the anniversary of when the original video started to make its rounds. reply ani-ani 7 hours agoparentprev [–] This particular machine has been on HN a few times before (and with good reason!) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The video showcases a marble machine playing Wintergatan's music, combining different sounds and instruments to produce a distinctive piece.",
      "It begins with the machine starting, marbles rolling, instruments playing, and the music evolving, culminating in a gradual conclusion.",
      "The video ends with the marbles halting, the machine shutting down, and a moment of silence."
    ],
    "commentSummary": [
      "The Wintergatan Marble Machine, a musical instrument project by creator Wintergatan, has faced challenges due to over-engineering and perfectionism, impacting the creator's mental health.\"",
      "Wintergatan's shift towards designing marble gates highlights the toll taken on creativity, inspiring the maker community despite varying opinions on progress.\"",
      "The project stimulates discussions on balancing innovation, perfectionism, and enjoyment in creative pursuits, along with comparisons to other creative endeavors and the impact of recommendation algorithms on online platforms.\""
    ],
    "points": 316,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1709392827
  },
  {
    "id": 39578501,
    "title": "Optimizing Code in Go for One Billion Row Challenge",
    "originLink": "https://benhoyt.com/writings/go-1brc/",
    "originBody": "BEN HOYT Home Resume/CV Projects Tech Writing Non-Tech Email The One Billion Row Challenge in Go: from 1m45s to 4s in nine solutions March 2024 Go to: BaselineSolutionsTable of resultsFinal comments I saw the One Billion Row Challenge a couple of weeks ago, and it thoroughly nerd-sniped me, so I went to Go solve it. I’m late to the party, as the original competition was in January. It was also in Java. I’m not particularly interested in Java, but I’ve been interested in optimising Go code for a while. This challenge was particularly simple: process a text file of weather station names and temperatures, and for each weather station, print out the minimum, mean, and maximum. There are a few other constraints to make it simpler, though I ignored the Java-specific ones. Here are a few lines of example input: Hamburg;12.0 Bulawayo;8.9 Palembang;38.8 St. John's;15.2 Cracow;12.6 ... The only catch: the input file has one billion rows (lines). That’s about 13GB of data. I’ve already figured out that disk I/O is no longer the bottleneck – it’s usually memory allocations and parsing that slow things down in a program like this. This article describes the nine solutions I wrote in Go, each faster than the previous. The first, a simple and idiomatic solution, runs in 1 minute 45 seconds on my machine, while the last one runs in about 4 seconds. As I go, I’ll show how I used Go’s profiler to see where the time was being spent. The run-down of solutions is as follows, slowest to fastest: r1: simple and idiomatic r2: map with pointer values r3: parse temperatures by hand r4: fixed point integers r5: avoid bytes.Cut r6: avoid bufio.Scanner r7: custom hash table r8: parallelise r1 r9: parallelise r7 I wanted each of the solutions to be portable Go using only the standard library: no assembly, no unsafe, and no memory-mapped files. And 4 seconds, or 3.2GB/s, was fast enough for me. For comparison, the fastest, heavily-optimised Java solution runs in just under a second on my machine – not bad! There are several other Go solutions out there already, and at least one nice write-up. Mine is faster than some solutions, but slightly slower than the fastest one. However, I didn’t look at any of these before writing mine – I wanted my solutions to be independent. If you just care about the numbers, skip down to the table of results. Baseline Here are a few different baseline measurements to set the stage. First, how long does it take to just read 13GB of data, using cat: $ time cat measurements.txt >/dev/null 0m1.052s Note that that’s a best-of-five measurement, so I’m allowing the file to be cached. Who knows whether Linux will allow all 13GB to be kept in disk cache, though presumably it does, because the first time it took closer to 6 seconds. For comparison, to actually do something with the file is significantly slower: wc takes almost a minute: $ time wc measurements.txt 1000000000 1179173106 13795293380 measurements.txt 0m55.710s For a simple solution to the actual problem, I’d probably start with AWK. This solution uses Gawk, because sorting the output is easier with its asorti function. I’m using the -b option to use “characters as bytes” mode, which makes things a bit faster: $ time gawk -b -f 1brc.awk measurements.txt >measurements.out 7m35.567s I’m sure I can beat 7 minutes with even a simple Go solution, so let’s start there. I’m going to start by optimising the sequential, single-core version (solutions 1-7), and then parallelise it (solutions 8 and 9). All my results are done using Go 1.21.5 on a linux/amd64 laptop with a fast SSD drive and 32GB of RAM. Many of my solutions, and most of the fastest solutions, assume valid input. For example, that the temperatures have exactly one decimal digit. Several of my solutions will cause a runtime panic, or produce incorrect output, if the input isn’t valid. Solution 1: simple and idiomatic Go I wanted my first version to be simple, straight-forward code using the tools in the Go standard library: bufio.Scanner to read the lines, strings.Cut to split on the ';', strconv.ParseFloat to parse the temperatures, and an ordinary Go map to accumulate the results. I’ll include this first solution in full (but after that, show only the interesting bits): func r1(inputPath string, output io.Writer) error { type stats struct { min, max, sum float64 count int64 } f, err := os.Open(inputPath) if err != nil { return err } defer f.Close() stationStats := make(map[string]stats) scanner := bufio.NewScanner(f) for scanner.Scan() { line := scanner.Text() station, tempStr, hasSemi := strings.Cut(line, \";\") if !hasSemi { continue } temp, err := strconv.ParseFloat(tempStr, 64) if err != nil { return err } s, ok := stationStats[station] if !ok { s.min = temp s.max = temp s.sum = temp s.count = 1 } else { s.min = min(s.min, temp) s.max = max(s.max, temp) s.sum += temp s.count++ } stationStats[station] = s } stations := make([]string, 0, len(stationStats)) for station := range stationStats { stations = append(stations, station) } sort.Strings(stations) fmt.Fprint(output, \"{\") for i, station := range stations { if i > 0 { fmt.Fprint(output, \", \") } s := stationStats[station] mean := s.sum / float64(s.count) fmt.Fprintf(output, \"%s=%.1f/%.1f/%.1f\", station, s.min, mean, s.max) } fmt.Fprint(output, \"}\") return nil } This basic solution processes the one billion rows in 1 minute and 45 seconds. A definite improvement over 7 minutes for the AWK solution. Solution 2: map with pointer values I’d learned doing my count-words program that we’re doing a bunch more hashing than we need to. For each line, we’re hashing the string twice: once when we try to fetch the value from the map, and once when we update the map. To avoid that, we can use a map[string]*stats (pointer values) and update the pointed-to struct, instead of a map[string]stats and updating the hash table itself. However, I first wanted to confirm that using the Go profiler. It only takes a few lines to add CPU profiling to a Go program. $ ./go-1brc -cpuprofile=cpu.prof -revision=1 measurements-10000000.txt >measurements-10000000.out Processed 131.6MB in 965.888929ms $ go tool pprof -http=: cpu.prof ... Those commands produced the following profile of solution 1, run over a cut-down 10 million row input file: Map operations are taking a full 30% of the time: 12.24% for assign and 17.35% for lookup. We should be able to get rid of most of the map assign time by using a pointer value. As a side note, this profile image also shows us where all the rest of the time is going: Scanning lines with Scanner.Scan Finding the ';' with strings.Cut Parsing the temperature with strconv.ParseFloat Calling Scanner.Text, which allocates a string for the line In any case, my second solution is just a small tweak to the map operations: stationStats := make(map[string]*stats) scanner := bufio.NewScanner(f) for scanner.Scan() { // ... s := stationStats[station] if s == nil { stationStats[station] = &stats{ min: temp, max: temp, sum: temp, count: 1, } } else { s.min = min(s.min, temp) s.max = max(s.max, temp) s.sum += temp s.count++ } } In the common case where the station exists in the map, we now only do one map operation, s := stationStats[station], so that hashing the station name and accessing the hash table only has to be done once. If it’s in the map already – the common case in one billion rows – we update the existing pointed-to struct. It doesn’t help a ton, but it is something: using pointer values in the map takes our time down from 1 minute 45 seconds to 1 minute 31 seconds. Solution 3: avoid strconv.ParseFloat My third solution is where things get a bit more hard-core: parse the temperature using custom code instead of strconv.ParseFloat. The standard library function handles a ton of edge cases we don’t need to support for the simple temperatures our input has: 2 or 3 digits in the format 1.2 or 34.5 (and some with a minus sign in front). Also, strconv.ParseFloat took a string argument, and now that we’re no longer calling that, we can get away with using the byte slice directly from Scanner.Bytes, instead of allocating and copying a string with Scanner.Text. Now we parse the temperature this way: negative := false index := 0 if tempBytes[index] == ' { index++ negative = true } temp := float64(tempBytes[index] - '0') // parse first digit index++ if tempBytes[index] != '.' { temp = temp*10 + float64(tempBytes[index]0') // parse optional second digit index++ } index++ // skip '.' temp += float64(tempBytes[index]0') / 10 // parse decimal digit if negative { temp = -temp } Not pretty, but not exactly rocket science either. This gets our time down from to 1 minute 31 seconds to under a minute: 55.8 seconds. Solution 4: fixed point integers Back in the olden days, floating point instructions were a lot slower than integer ones. These days, they’re only a little slower, but it’s probably worth avoiding them if we can. For this problem, each temperature has a single decimal digit, so it’s easy to use fixed point integers to represent them. For example, we can represent 34.5 as the integer 345. Then at the end, just before we print out the results, we convert them back to floats. So my fourth solution is basically the same as solution 3, but with the stats struct field as follows: type stats struct { min, max, count int32 sum int64 } Then, when printing out the results, we need to divide by 10: mean := float64(s.sum) / float64(s.count) / 10 fmt.Fprintf(output, \"%s=%.1f/%.1f/%.1f\", station, float64(s.min)/10, mean, float64(s.max)/10) I’ve used 32-bit integers for minimum and maximum temperatures, as the highest we’ll probably have is about 500 (50 degrees Celsius). We could use int16, but from previous experience, modern 64-bit CPUs are slightly slower when handling 16-bit integers than 32-bit ones. In my tests just now it didn’t seem to make a measurable difference, but I opted for 32-bit anyway. Using integers cut the time down from 55.8 seconds to 51.0 seconds, a small win. Solution 5: avoid bytes.Cut To make solution 5 I recorded another profile (of solution 4): Okay, now it’s getting harder. The map operations dominate, and moving to a custom hash table will be a bit tricky. So will getting rid of the bufio.Scanner. Let’s procrastinate and get rid of the bytes.Cut. I thought of a simple way to save time. If we look at a line, for example: New Orleans;11.7 It’s going to be faster to parse the temperature from the end and find the ';' there than to scan through the whole station name to look for the ';'. This rather ugly code does just that: end := len(line) tenths := int32(line[end-1] - '0') ones := int32(line[end-3] - '0') // line[end-2] is '.' var temp int32 var semicolon int if line[end-4] == ';' { // positive N.N temperature temp = ones*10 + tenths semicolon = end - 4 } else if line[end-4] == ' { // negative -N.N temperature temp = -(ones*10 + tenths) semicolon = end - 5 } else { tens := int32(line[end-4] - '0') if line[end-5] == ';' { // positive NN.N temperature temp = tens*100 + ones*10 + tenths semicolon = end - 5 } else { // negative -NN.N temperature temp = -(tens*100 + ones*10 + tenths) semicolon = end - 6 } } station := line[:semicolon] Avoiding bytes.Cut cut the time down from 51.0 seconds to 46.0 seconds, another small win. Solution 6: avoid bufio.Scanner Now we’re going to try to get rid of the bufio.Scanner. If you think about it, to find the end of each line, the scanner has to look through all the bytes to find the newline character. Then we process many of the bytes again to parse the temperature and find the ';'. So let’s try to combine those steps and throw bufio.Scanner out the window. In solution 6 we allocate a 1MB buffer to read the file in large chunks, look for the last newline in the chunk to ensure we’re not chopping a line in half, and then process each chunk. That looks like this: buf := make([]byte, 1024*1024) readStart := 0 for { n, err := f.Read(buf[readStart:]) if err != nil && err != io.EOF { return err } if readStart+n == 0 { break } chunk := buf[:readStart+n] newline := bytes.LastIndexByte(chunk, '') if newlinelen(items)/2 { panic(\"too many items in hash table\") } break } if bytes.Equal(items[hashIndex].key, station) { // Found matching slot, add to existing stats. s := items[hashIndex].stat s.min = min(s.min, temp) s.max = max(s.max, temp) s.sum += int64(temp) s.count++ break } // Slot already holds another key, try next slot (linear probe). hashIndex++ if hashIndex >= len(items) { hashIndex = 0 } } } readStart = copy(buf, remaining) } The payoff for all this code is large: the custom hash table cuts down the time from 41.3 seconds to 25.8s. Solution 8: process chunks in parallel In solution 8 I wanted to add some parallelism. However, I thought I’d go back to the simple and idiomatic code from my first solution, which uses bufio.Scanner and strconv.ParseFloat, and parallelise that. Then we can see whether optimising or parallelising gives better results – and in solution 9 we’ll do both. It’s straight-forward to parallelise a map-reduce problem like this: split the file into similar-sized chunks (one for each CPU core), fire up a thread (in Go, a goroutine) to process each chunk, and then merge the results at the end. Here’s what that looks like at a high level: // Determine non-overlapping parts for file split (each part has offset and size). parts, err := splitFile(inputPath, maxGoroutines) if err != nil { return err } // Start a goroutine to process each part, returning results on a channel. resultsCh := make(chan map[string]r8Stats) for _, part := range parts { go r8ProcessPart(inputPath, part.offset, part.size, resultsCh) } // Wait for the results to come back in and aggregate them. totals := make(map[string]r8Stats) for i := 0; i < len(parts); i++ { result := <-resultsCh for station, s := range result { ts, ok := totals[station] if !ok { totals[station] = r8Stats{ min: s.min, max: s.max, sum: s.sum, count: s.count, } continue } ts.min = min(ts.min, s.min) ts.max = max(ts.max, s.max) ts.sum += s.sum ts.count += s.count totals[station] = ts } } The splitFile function is a bit tedious, so I won’t include it here. It looks at the size of the file, divides that by the number of parts we want, and then seeks to each part, reading 100 bytes before the end and looking for the last newline to ensure each part ends with a full line. The r8ProcessPart function is basically the same as the r1 solution, but it starts by seeking to the part offset and limiting the length to the part size (using io.LimitedReader). When it’s done, it sends its own stats map back on the channel: func r8ProcessPart(inputPath string, fileOffset, fileSize int64, resultsCh chan map[string]r8Stats) { file, err := os.Open(inputPath) if err != nil { panic(err) } defer file.Close() _, err = file.Seek(fileOffset, io.SeekStart) if err != nil { panic(err) } f := io.LimitedReader{R: file, N: fileSize} stationStats := make(map[string]r8Stats) scanner := bufio.NewScanner(&f) for scanner.Scan() { // ... same processing as r1 ... } resultsCh <- stationStats } Processing the input file in parallel provides a huge win over r1, taking the time from 1 minute 45 seconds to 24.3 seconds. For comparison, the previous “optimised non-parallel” version, solution 7, took 25.8 seconds. So for this case, parallelisation is a bit faster than optimisation – and quite a bit simpler. Solution 9: all optimisations plus parallelisation For solution 9, our last attempt, we’ll simply combine all the previous optimisations from r1 through r7 with the parallelisation we did in r8. I’ve used the same splitFile function from r8, and the rest of the code is just copied from r7, so there’s nothing new to show here. Except the results … this final version cut down the time from 24.3 seconds to 3.99 seconds, a huge win. Interestingly, because all the real processing is now in one big function, r9ProcessPart, the profile graph is no longer particularly helpful. Here’s what it looks like now: As you can see, 82% of the time is being spent in r9ProcessPart, with bytes.Equal taking 13%, and the file reading taking the remaining 5%. If we want to profile further, we have to dive deeper than the function level that the graph view gives us, and use the source view. Here’s the inner loop: I find this report confusing. Why does if items[hashIndex].key == nil show as taking 5.01s, but the call to bytes.Equal shows as only 390ms. Surely a slice lookup is much cheaper than a function call? If you are a Go performance expert and can help me interpret it, I’m all ears! In any case, I’m sure there are crazier optimisations I could do, but I decided I’d leave it there. Processing a billion rows in 4 seconds, or 250 million rows per second, was good enough for me. Table of results Below is a table of all my Go solutions in one place, in addition to the fastest Go and fastest Java solutions. Each result is the best-of-five time for running the solution against the same billion-row input. Version Summary Time Times as fast as r1 r1 simple and idiomatic 1m45 1.00 r2 map with pointer values 1m31 1.15 r3 parse temperatures by hand 55.8s 1.87 r4 fixed point integers 51.0s 2.05 r5 avoid bytes.Cut 46.0s 2.27 r6 avoid bufio.Scanner 41.3s 2.53 r7 custom hash table 25.8s 4.05 r8 parallelise r1 24.3s 4.31 r9 parallelise r7 3.99s 26.2 AY fastest Go version 2.90s 36.2 TW fastest Java version 0.953s 110 I’m in the same ballpark as Alexander Yastrebov’s Go version. His solution looks similar to mine: break the file into chunks, use a custom hash table (he even uses FNV hashing), and parse temperatures as integers. However, he uses memory-mapped files, which I’d ruled out for portability reasons – I’m guessing that’s why his is a bit faster. Thomas Wuerthinger (with credit to others) created the fastest overall solution to the original challenge in Java. His runs in under a second on my machine, 4x as fast as my Go version. In addition to parallel processing and memory-mapped files, it looks like he’s using unrolled loops, non-branching parsing code, and other low-level tricks. It looks like Thomas is the founder of and a significant contributor to GraalVM, a faster Java Virtual Machine with ahead-of-time compilation. So he’s definitely an expert in his field. Nice work Thomas and co! Final comments Does any of this matter? For the majority of day-to-day programming tasks, simple and idiomatic code is usually the best place to start. If you’re calculating statistics over a billion temperatures, and you just need the answer once, 1 minute 45 seconds is probably fine. But if you’re building a data processing pipeline, if you can make your code 4 times as fast, or even 26 times as fast, you’ll not only make users happier, you’ll save a lot on compute costs – if the system is being well loaded, your compute costs could be 1/4 or 1/26 of the original! Or, if you’re building a runtime like GraalVM, or an interpreter like my GoAWK, this level of performance really does matter: if you speed up the interpreter, all your users’ programs run that much faster too. Plus, it’s just fun writing code that gets the most out of your machine. I’d love it if you sponsored me on GitHub – it will motivate me to work on my open source projects and write more good content. Thanks!",
    "commentLink": "https://news.ycombinator.com/item?id=39578501",
    "commentBody": "The One Billion Row Challenge in Go: from 1m45s to 4s in nine solutions (benhoyt.com)293 points by nalgeon 5 hours agohidepastfavorite117 comments hoten 2 minutes ago> I find this report confusing. Why does if items[hashIndex].key == nil show as taking 5.01s, but the call to bytes.Equal shows as only 390ms. Surely a slice lookup is much cheaper than a function call? If you are a Go performance expert and can help me interpret it, I’m all ears! These two lines are both conditionals, so the time reported is sensitive to branch mispredictions. If the timings are not intuitive based on the complexity of the associated lines, then it may be explained by the data being not very predictable and the branch predictor having a bad time. reply bbkane 4 hours agoprevI found this super interesting - especially as all the data I've written code to manipulate has been small enough that I haven't needed to optimize my code, so I've never had to think in this direction. I think my favorite part was the very first section, where he got baseline measurements with `cat`, `wc`, and friends. I wouldn't have thought to do that and its such an easy way to get a perspective on what's \"reasonable\". reply timetopay 42 minutes agoparentA few months ago, I had to quickly bang out a script to output about 20 million lines of text, each the output of a hash function. My naive solution took more than a few minutes - simple optimizations such as writing every 10k lines cut the time significantly. Threading would have helped quite a bit as well. reply latchkey 3 hours agoparentprevI hate to \"me too\", but you also nailed that analysis. reply yau8edq12i 11 minutes agorootparent> I hate to \"me too\" Then why do you do it? reply worldwidelies 0 minutes agoprevI’d like to see a 1 trillion row challenge. reply camgunz 1 hour agoprevI love the nerdery around 1BRC. My axe to grind is that unless you do dangerous stuff DBs are just as fast, less complicated, and more resilient to data updates than application code [0]. Do more in the database! 0: https://geraldonit.com/2024/01/31/1-billion-row-challenge-in... reply faizshah 2 hours agoprevI was curious how long it would take with Polars (for scale), apparently 33s: https://github.com/Butch78/1BillionRowChallenge/tree/main I’m kind of interested in the opposite problem, what is the simplest solution using a well known library/db that approaches the fastest hand optimized solution to this problem? reply jsmith99 0 minutes agoparentI’m surprised at the poor performance of python here. For reference there are several very brief R examples which are just 2-3 seconds. Eg http://blog.schochastics.net/posts/2024-01-08_one-billion-ro... reply geysersam 51 minutes agoparentprevSounds very reasonable. In the blog post about 20s were shaved off by assuming we don't need complicated string parsing. An of the shelf library can't make that assumption so they will always have to pay the extra cost. reply sharno 2 hours agoparentprevThat’s the question worth asking imo. I was wondering how fast is the idiomatic Java solution reply KingOfCoders 20 minutes agorootparentJava is often slightly faster than Go, has similar (perhaps, older, better optimized Map) constructs, perhaps better GC (older, more optimized), though I don't think the GC is a challenge, has slower startup times - so I'd say roughly the same as the idiomatic Go version? reply lucianbr 1 hour agorootparentprev71 seconds https://questdb.io/blog/billion-row-challenge-step-by-step/ reply kaba0 1 hour agorootparentIs that the same hardware? Otherwise it doesn’t say much. reply gigatexal 2 hours agoparentprevWhere’s the source data I’d like to attempt ingesting this and processing it with DuckDb. reply schu 1 hour agorootparentInstructions on how to create it can be found here: https://github.com/gunnarmorling/1brc?tab=readme-ov-file#run... The Python version: https://github.com/gunnarmorling/1brc/blob/main/src/main/pyt... reply nhinck3 1 hour agorootparentprevIn the original 1BRC, it's a python script that generates the data. reply thangalin 3 hours agoprevBack in 2010, I used PostgreSQL for a web app that queried 270 million rows of climate data from Environment Canada: https://www.youtube.com/watch?v=10KEr3sEG80 I wanted to see how the temperature was changing over time for specific regions using a map-based interface. The following chart was particularly eye-opening: https://www.youtube.com/watch?v=iEtvf9xzRB4&t=164s The software won a couple of awards and was heavily optimized to produce reports in under a minute. Kudos to the author for getting a parse time of a billion records down to mere seconds. reply heavenlyblue 31 minutes agoparentThe chart was not eye openning and you're just fishing for views reply fizx 2 hours agoprevIt's worth noting that if you're messing around with large text files from the CLI, awk, grep, etc will be an order-of-magnitude faster if you opt out of unicode parsing. I'm pretty confident adding LC_ALL=C to the awk solution would get it easily under a minute. reply michae2 2 hours agoprevFor anyone looking for more examples of 1BRC in Go, we had a friendly competition at work and collected the results here: https://github.com/dhartunian/1brcgo/ In addition to the loop-unrolling and bit-twiddling tricks that also show up in the fastest Java and C++ versions, some Go-specific things I learned were: - unsafe.Pointer can be used to read memory without bounds checks - many functions in the bytes and bits packages in the standard library are written in assembly - debug.SetGCPercent and SetMemoryLimit to turn off GC - runtime.LockOSThread to lock a goroutine to a thread - print is slightly faster than fmt.Printf (but writes to stderr) reply benhoyt 2 hours agoparentOh, I'd missed those solutions, thanks. You guys got way more hard core than I did -- nice work! Looking forward to reading the code for those solutions this week. Update: for reference, Jason Chu's solution (https://github.com/dhartunian/1brcgo/blob/494eabd6ea958cc193...) seems to be the fastest on my machine, and runs in about 1.3s! reply michae2 1 hour agorootparentI think we all ended up using unsafe, though there were some solutions without mmap. It would have been interesting if we had adhered to the same constraints you did! reply markoman 1 hour agorootparentprevCould you say why you find using memory-mapped files to be a portability issue? Thanks. reply benhoyt 1 hour agorootparentWell, I guess it's more that the standard library doesn't have a cross-platform way to access them, not that memory-mapped files themselves can't be done on (say) Windows. It looks like there's a fairly popular 3rd party package that supports at least Linux, macOS, and Windows: https://github.com/edsrzf/mmap-go reply WesolyKubeczek 21 minutes agorootparentprevNot all filesystems support memory-mapped files equally, and for some that do, the support comes with caveats and could be slower than non-memory-mapped access. reply michalsustr 49 minutes agoprev> the fastest, heavily-optimised Java solution runs in just under a second on my machine I don’t understand how this is possible. The file in question has 13GB, while the fastest commonly available SSDs are 12400 MB/s. Am I missing something? reply mainde 40 minutes agoparentI think this bit in the baseline section applies to the Java one too >Note that that’s a best-of-five measurement, so I’m allowing the file to be cached. Who knows whether Linux will allow all 13GB to be kept in disk cache, though presumably it does, because the first time it took closer to 6 seconds. reply nsteel 11 minutes agorootparentYea, I assumed that. Which makes the parallel version improvements still interesting but surely it's very artificial. You can't processes all the data at the same time if you don't have it all yet. reply dietr1ch 42 minutes agoparentprevBenchmarking this gets tricky once you realize that the file might be entirely cached if the computer has enough RAM. reply codegladiator 10 minutes agoparentprevthere are no disk file read times in the original rules. file is in memfs. reply whyever 43 minutes agoparentprevMy guess: If you run the benchmark several times, the OS will cache the file in RAM. reply gozzoo 45 minutes agoparentprevmost of the file remains in the OS disk cache after the first run reply chii 42 minutes agoparentprevthat might be a sustained single threaded read performance. What if the method of access was concurrent from different parts of the file, and was operating system cached? reply nottorp 3 hours agoprevI have a feeling that a naive implementation in Java would be a lot worse than a naive implementation in Go so optimizing matters more there. Had to parse csvs in Java on a very memory constrained system once... we ended up cutting out a feature because it wasn't worth it. reply masklinn 1 hour agoparentDepends what you call “naive”, but the “idiomatic Java solution” from last week’s post (https://questdb.io/blog/billion-row-challenge-step-by-step/) clocked in at 71 seconds, or 1:11. And just running it on graal was down to 66. “Very memory constrained” would be a massive factor here, 1BRC is not really constrained (let alone very much so), it has 1 billion rows on a 32GB machine. reply nottorp 53 minutes agorootparentGigabytes? It was a while ago and i had megabytes for the whole OS :) Anyway, it's just a fun memory now. reply speedgoose 38 minutes agoparentprevGolang is actually not as efficient as Java in quite a few benchmarks. Using LLVM isn’t a magic solution to perform better than something relying on the JVM. Here is a source: https://sites.google.com/view/energy-efficiency-languages reply TwentyPosts 4 minutes agorootparentHuh? Go doesn't use LLVM though, where did you get the idea that it does? That's part of why its compile times are so fast. reply pjmlp 2 hours agoparentprevDepends on which Java implementation is used. People keep forgetting Java is like C and C++, plenty of implementations to choose from, each with its own approach to JIT, AOT, GC and escape analysis. reply cangeroo 2 hours agoparentprevRegarding Java, It probably could be done with arrays and object reuse (arenas). But it's slightly less ergonomic. And the ecosystem isn't designed for it, so you'd have to implement your own memory-efficient parser. reply nottorp 1 hour agorootparentYep, but it wasn't a critical feature and we were in a rush, so the feature was killed instead. > Depends on which Java implementation is used. ... if you have a choice. It was a port of AOSP, so we didn't. In any case it wasn't the jvm's fault, the device just had very little ram. reply JensRantil 4 hours agoprevSecond article I'm reading on implementing this in Go. Since the temperatures are in the range [-99.9, 99.9] with a tenth of precision (~2k values), I am surprised why no one has implemented a parsing of the numbers using a prepopulated lookup table. Should probably speed things up. I submitted a github issue on this for the other implementation I looked at here[1]. [1] https://github.com/shraddhaag/1brc/issues/2 reply KingOfCoders 16 minutes agoparentWouldn't you need a fixed length of the temps? 00.1 -10.3 or 0.1 (with an ending space) so you can look up 5 bytes in the map? (+/i, two digits, dot, one digit) reply codegladiator 5 minutes agorootparentyou can create a perfect hash based on the presence of at least 4 characters. perfect hash is pre calculated based on possible inputs (-99.9 to 99.0 in bytes). the hash is usual byte*seed+hash. \"seed\" is chosen so that there is no clash (you can find a static seed in a single brute force from 1 to 1m inThe Java version is really optimized and is an interesting read. is there any similar blog post on the Java optimisations? reply lucianbr 1 hour agorootparenthttps://questdb.io/blog/billion-row-challenge-step-by-step/ reply cempaka 3 hours agorootparentprevCliff Click did a walkthrough of his solution on YouTube: https://youtu.be/NJNIbgV6j-Y?si=Wj97f-Imw5nfIzF7 reply o11c 4 hours agorootparentprevhttps://news.ycombinator.com/item?id=39467885 but it looks like there have been improvements since. reply dsff3f3f3f 4 hours agorootparentprevNot that I know of. I just looked at the code and the commit history but a more in depth article would certainly be interesting. reply neonsunset 2 hours agorootparentprevThe more accurate statement would be is Go implementatation is incapable of accessing optimizations that exist in Java and then Java is incapable of optimizations performed by C# and C++ implementations. See https://hotforknowledge.com/2024/01/13/1brc-in-dotnet-among-... reply dsff3f3f3f 2 hours agorootparentGo is perfectly capable of all of the additional optimizations that are in the fastest Java implementation that is linked in the article. reply AtlasBarfed 1 hour agorootparentprevWell the Go guy probably didn't read it because \"java doesn't interest him\" reply threatofrain 3 hours agoparentprevI don't think Go has ever demonstrated that it deserved to be thought of as casually faster than Java. reply Comma2976 1 hour agorootparenthttps://github.com/attractivechaos/plb2/blob/master/README.m... Synthetic benchmarks aside, I think as far as average (spring boots of the world) code goes, Go beats Java almost every time, often in less lines than the usual pom.xml reply iraqmtpizza 1 hour agorootparentAnyone judging Java performance based on starting up a JVM, running for 30 seconds, and shutting down is brain damaged. I'm 99 percent certain this benchmark doesn't use Epsilon GC either lol >not using GraalVM for Java LOL k >no implementations use multithreading ah, the cherry on top. this benchmark is literally perfectly useless reply parkcedar 4 hours agoparentprevThe fastest Java version is even beating his baseline of `cat` to `/dev/null` reply JohnBooty 2 hours agorootparentYes, though it's also worth noting that the fastest solutions are all doing their work in parallel which is not a thing for `cat`. reply timeagain 3 hours agorootparentprevMore proof that the JVM is space-age future technology. reply neonsunset 3 hours agoparentprevStill loses to .NET. On reference host Java still closer to 1.7-2s ballpark (and has to use awkward SWAR to get there) while the fastest solution in C# is 1.2s, beating C++ (code can be ported however). But yes, \"I expected Go to win...\" is exactly the core of the problem here. Same as with e.g. Swift, which people expect to perform on the level of Rust, when it is even slower than Go. The intuition caused by common misconceptions just does not correspond to reality sadly. reply pjmlp 1 hour agorootparentIt only goes to show how much cargo cult is there in adopting these languages in hipster circles. reply hnlmorg 53 minutes agorootparentNo. What it actually demonstrates is that people didn’t read the source material properly. The Java and Go versions use different optimisations. There’s nothing stopping either language from using the same optimisations as the other. It just wasn’t something their respective authors cared to try in their respective exercises. reply kaba0 55 minutes agorootparentprev> beating C++ Source for that? reply neonsunset 52 minutes agorootparenthttps://hotforknowledge.com/2024/01/13/1brc-in-dotnet-among-... reply threeseed 3 hours agoparentprevJVM has always been on par if not often faster than hand-written C code. Go's advantage has always been that it is good enough at a lot of things. reply ffsm8 3 hours agorootparentI think the reason why this misconception is so widespread is because there is a grain of truth in it, because almost everyone sees Java synonymous with gigantic framework like spring, quarkus etc. In go you've got your standard libraries, these are generally quicker than the Java equivalent simply because they do less in the lifecycle of the operation. This lets Java do funky stuff like enabling full jvm/code tracing just by adding a jar file at runtime. But it does come with a performance penalty. reply pjmlp 1 hour agorootparentWhich is a reason why dynamic loading of agents now requires being enabled explicitly. reply _ph_ 1 hour agorootparentprevOne has to differentiate here a bit. Java JIT technology has become really great. Highly optimized native code generation which hugely benefits from the ability to use live profiling data to optimize the code. This is why it often beats static compilers at generating faster code. The static compilers can only optimized on the range of possible data, the JIT can optimize based on the data presented to the program. On the down side, there are quite a few features of the Java language and the JVM, which often make programs slow. Like a lot of details of the object model, lack of value classes, JIT compiling which takes time on startup etc. Also, a lot of Java libraries are pretty heavy weight. Go is quite different here. It is statically compiled, which allows for fast program startup and the language model makes it quite easy to rather naively write programs which perform reasonally fast. The down side is, that the compiler is static and not so heavily optimizing as other static compilers for fast compilation speed. However recently the ability was added to use profiling data for optimizing the compilation. reply Mawr 3 hours agorootparentprevPlease, you've been reading too much PR from the Java side and not looking at benchmarks and real-world performance enough. What you're claiming is inherently not possible, cherry-picked benchmarks notwithstanding. reply threeseed 2 hours agorootparentCan you explain why it's not technically possible. JVM has had decades of experience at optimally translating bytecode to machine code and can take advantage of SIMD, AVX etc when needed. Most hand-written C code is far from optimal. reply 10000truths 2 hours agorootparentC compilers also have decades of experience optimally translating C code into machine code, and they are arguably more capable of emitting SIMD (good luck trying to use cutting edge AVX-512 intrinsics like vpopcntdq with the JVM). The fact is that there is nothing a JIT compiler can do that an AOT compiler can't do, but in the case of AOT, the resources spent compiling the code are amortized to effectively 0, whereas that resource cost is borne upon every program startup for a JIT engine. reply pjmlp 1 hour agorootparentC compilers only have one opportunity to do that once, at compile time, if the developer was lucky with their data set used to train the PGO output, maybe the outcome is greatly improved. Modern JVMs, not only have the JIT being able to use actual production data, they are able to cache PGO data between execution runs, and reach an optimimal set of heuristics throughout execution time. And on Android, those PGO files are even shared between devices via Play Store. reply neonsunset 52 minutes agorootparentprevThat's not necessarily true, on JIT vs AOT split. I'm mostly going off of how the divergence in available optimization is starting to look like in .NET after introduction of Native AOT with light research into LLVM and various optimization-adjacent Rust crates. In particular, with JIT, you are able to initialize certain readonly data once, and then, on recompilation to a more optimized version, bake such data as JIT constants right into emitted machine code. This is not possible with AOT. Same applies for all kinds of in-runtime profiling/analysis and recompilation to incorporate a collected profile according to this exact run of an application. JIT also offers the ability to load modules dynamically in the form of bytecode without having to have a strict machine-level ABI, only the bytecode one, which allows for efficient generics that cross modules, as well as cross-module function inlining. And last but not least - there is no need to pick the least common denominator in supported hardware features as the code can be compiled to use the latest features provided by hardware like AVX512. On the other hand, pure AOT means a frozen world which allows the compiler to know exact types and paths the code can take, performing exact devirtualization and much more aggressive preinitialization on code that accepts constant data. It also means bigger leeway in the time the compiler can spend on optimizing code. Historically, GCC and LLVM have been more advanced than their JIT counterparts because of different tradeoffs more favouring to absolute performance of the emitted code as well as simply higher amount of man hours invested in developing them (e.g. .NET punches above it's weight class despite being worked on by a smaller team vs OpenJDK or LLVM). reply vanviegen 2 hours agorootparentprevSure it's possible. The JVM can do guided optimizations at run time. There is no such thing for native executables. reply pjmlp 1 hour agorootparentAnd as I mentioned in another comment, you can even cache PGO data between executions, not needed to start always from zero. reply avinassh 4 hours agoprev> I’m in the same ballpark as Alexander Yastrebov’s Go version. His solution looks similar to mine: break the file into chunks, use a custom hash table (he even uses FNV hashing), and parse temperatures as integers. However, he uses memory-mapped files, which I’d ruled out for portability reasons – I’m guessing that’s why his is a bit faster. I am curious, can it be made even faster than this? reply krallja 4 hours agoparentThere's a layer of pointer indirection when using slices in Go, you may be able to eke out some time by moving to arrays on the stack. reply makotech221 4 hours agoparentprevDunno about Go, but most c# solutions are around 2s and under https://hotforknowledge.com/2024/01/13/1brc-in-dotnet-among-... reply junto 2 hours agorootparentWow that’s pretty damn fast. C# has made some improvements in the past years or they have some other advantages? reply pjmlp 2 hours agorootparentYes to both. .NET team has been doubling down on performance improvements, people forget CLR also has features to support C like languages (hence Managed C++ and C++/CLI), and many of those capabilities are now surfaced into C# as well. reply Anon4Now 2 hours agorootparentprevStephen Toub wrote a book-length blog post about all the performance improvements made in .NET 8 [1]. Add the option to compile to native. [1] https://devblogs.microsoft.com/dotnet/performance-improvemen... reply pjmlp 1 hour agorootparentHis blogs posts go back all the way to .NET 5, for those curious to some deep dive on performance improvements done on each release. reply scotty79 37 minutes agoparentprevInstead of hash table I'd try sort of \"eager\" trie inside stack allocated memory. So I can find the slot for the stats of given station after parsing minimal number of characters that differentiate this station from others. reply pram 4 hours agoparentprevFrom looking at the final code it’s probably the performance of copy() as the biggest hurdle. reply afiodorov 2 hours agoprevMy first instinct would be to spin up a local Postgres and keep station data there. A lot of the solutions assume we have enough ram to keep the stats per station, however that's a bad assumption when dealing with a lot of data. reply masklinn 1 hour agoparentThis is not a general solution, it’s a specific problem with a specific data shape, and processes specifically 1 billion rows on a 32GB machine. reply sireat 1 hour agoprevThose super optimized solutions are fun to read about. However, in real life I would never assume a millions rows of text all have all valid data in a specific format, much less a billion rows. Thus a slower but more robust solution would be more realistic. reply nicois 4 hours agoprevIt would be interesting to know how effective Profile Guided Optimisation is here. reply benhoyt 2 hours agoparentUnfortunately it doesn't seem to help at all, I think mainly because (at present) Go's PGO basically inlines hot functions, and the important code here is all in one big function. reply neonsunset 2 hours agoparentprevIt is only mildly effective because how anemic Go compiler is. And even then it's extremely limited. If you want to see actual good implementations - look into what OpenJDK HotSpot and .NET JIT compilers do with runtime profiling and recompilation (.NET calls it Dynamic PGO). reply WesolyKubeczek 29 minutes agoprevI love the author’s step-by-step approach as very often it so happens that a hyper-optimized solution may be overfitted to the exact dataset it’s operating on. In each step, the tradeoffs are being explained: what we gain, but also what we lose by stripping the functionality away. reply satvikpendem 1 hour agoprevNice. I wonder how Rust would fare, given that it has no garbage collector. reply tjpnz 45 minutes agoparentYou can disable GC for Golang but don't think it will improve on 4s. reply fullstackchris 33 minutes agoprevperformance is great but i would imagine the paralellized version requires a significantly higher minimum amount of RAM than the non paralellized ways... he claims that each more perfomant solution is less compute cost than the one before it, but in the case of paralellization its just the same amount of compute in just a shorter amount of time, right? reply 1vuio0pswjnm7 2 hours agoprevHow about kdb+ or shakti reply tonymet 4 hours agoprevi saw the custom hashtable, but why was Map slow? reply m3kw9 4 hours agoprevI’d just pay my way to 4s by upgrading hw reply JohnBooty 2 hours agoparentYou can't just throw hardware at this one to get to 4s. At least not in 2024. The author's naive single-threaded Go solution took 1m45s on an \"amd64 laptop with fast SSD drive and 32GB of RAM.\" So, you'd need something 25x faster than his setup in terms of single-threaded performance. Let us know when you've upgraded your hardware to the equivalent of a 75ghz AMD processor with memory and SSD bandwidth to match! reply lmeyerov 2 hours agorootparentThe nice thing about a GPU soln (ex: python dataframes in cudf, just a few loc) is these generally come down to your IO bandwidth, like a single 2GB/s SSD to a 16-32 GB/s PCIe to 1-2 GPUs running crazy fast. And then buy more cheap SSDs to chain together before buying more/better GPUs :) reply jiggawatts 2 hours agoparentprev... how? There aren't any generally-available CPUs that are substantially faster today than were available ten years ago. Maybe double the speed per core, triple at best. After that, throwing more cores at it also rapidly runs out of steam because parallel code has its own overheads. Any shared state instantly kills performance, no matter the language. Very clever tricks have to be used to get decent scaling past 64 hardware threads (32 cores), and going past 256 is surprisingly difficult. You start having to worry about NUMA, IRQ steering, and core pinning. Bandwidth gets to be an issue, even to L3 and L4 cache, let alone out to main memory. This notion that you can just \"dial up\" hardware performance to infinity as a fix for any amount of developer laziness needs to die. reply neonsunset 3 hours agoprev [–] The effort and long time it took Go to get to something that 3-6x times slower than other, better languages should be an important reminder to everyone assuming it belongs to the same weight class as Rust, C# or Java. reply kitd 1 hour agoparentIf you read the article, you'll see he doesn't attempt the optimizations that helped those other languages get to 3-6x faster. Your snark is wasted. reply Mawr 3 hours agoparentprevThat you put Rust among those languages says it all. Do some basic research. reply neonsunset 2 hours agorootparentOh, and what the basic research you speak of constitutes? Surely you looked at ASM emitted by compilers for these languages and HPC-adjacent APIs each of them offers? No? Then let me tell you - Go is pretty much consigned to having to use its special flavour of non-portable bespoke hand-written ASM which is the only way to access SIMD instructions necessary to achieve optimal hardware utilization in the benchmark. This takes a lot of effort and skill, so, as you may have noticed, if you can't do it, Go simply cannot come close to better options you can see on the benchmark chart. And yet, this is something that can be trivially done in C#, C++ and Rust (albeit C# has the best UX with crossplat SIMD API introduced in .NET 7, with C++ close second with its own take on this being in preview). Java OTOH manages to be in the same category by having extremely advanced JIT that allows it to have comparable codegen quality even though it lacks comparable SIMD API for now (Panama vectors are problematic currently), so benchmarks implementations using it are forced to do SWAR. My main gripe is of course an extremely common misconception about Go's speed which it just does not have the moment you write anything sufficiently advanced or want to express a particular problem in a terser way than writing thousands of open coded loops. reply donor20 3 hours agoparentprev [–] But isn’t the Java version unrolling loops? This seems like some effort on the Java side. reply dsff3f3f3f 3 hours agorootparent [–] The fast Java version is using all the same optimizations as this Go version and then some. It's significantly more complicated. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ben Hoyt optimized Go code to tackle the One Billion Row Challenge, reaching a notable processing time of 3.99 seconds for weather station data, by minimizing memory allocations and enhancing parsing techniques.",
      "His approach outperformed traditional UNIX tools, showcasing the benefits of custom methods, parallelization, and selective avoidance of standard library functions for enhanced efficiency.",
      "The emphasis on code optimization not only boosts user experience but also leads to cost savings in data processing workflows, as highlighted by Hoyt's experience."
    ],
    "commentSummary": [
      "Participants are discussing performance optimization for handling large datasets, focusing on the One Billion Row Challenge in Go.",
      "They compare Java, Go, Python, and .NET, considering memory constraints, file processing, goroutine performance, and using databases for speed.",
      "Emphasis is placed on language structure, libraries, and compiler technology impact on performance, highlighting the significance of code optimization over hardware upgrades for better performance."
    ],
    "points": 293,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1709441544
  },
  {
    "id": 39572858,
    "title": "Crafting a Minecraft Server in Bash: Overcoming Challenges and Creative Solutions",
    "originLink": "https://sdomi.pl/weblog/15-witchcraft-minecraft-server-in-bash/",
    "originBody": "sdomi's webpage Main Weblog Kurisu Keygen Radio Pick-a-font: IBM VGA8 Monospace Chinacat Sans-serif My thoughts on writing a Minecraft server from scratch (in Bash) For the past year or so, I've been thinking about writing a Minecraft server in Bash as a thought excercise. I once tried that before with the Classic protocol (the one from 2009), but I quickly realized there wasn't really a way to properly parse binary data in bash. Take the following code sample: function a() { read -n 2 uwu echo \"$uwu\"xxd } This would read two bytes into a variable, and then pass them to `xxd`, which should show the hexdump of the data. Picture 1 - bash's lack of support for nullbytes Everything's great, until we pass a nullbyte (0x00). Not only does Bash ignore nullbytes in strings, it also doesn't present any way to detect that a nullbyte has occured. Considering that the protocol I'm trying to implement is strictly binary, this can severely mangle the data. One rainy evening in late January, I've had a revelation. What if I reversed the order of that function? If the binary data never reaches a variable (or, more precisely, a substitution), and just stays inside a pipe, can it pass nullbytes around? Picture 2 - reading nullbytes with xxd The answer is yes! After some iterations, I decided to use `dd` passed to `xxd` instead of just `xxd`, because this way I can finetune how many bytes to read. # the $len variable is assigned earlier, basing on a similar read function a=$(dd count=$len bs=1 status=nonexxd -p) This gave me a hex string, on which I could do pattern matching, pattern replace, data extraction... and more. Sending out responses could be done analogically, using xxd's Reverse switch. `ncat` is used for listening on Minecraft's default TCP port. It launches the main shell script (`mc.sh`) after it receives an incoming connection. The Protocol Is Not Really Good, Actually Note: the following section contains mostly my ramblings about implementing number conversion routines in Bash; If this does not interest you, feel free to skip it. The first thing one should implement for a Minecraft server to function would be the Server List Ping packet - not because it's required (heck, your server can just not reply to it properly, and you'd still be able to join the game), but because it's the easiest to tackle first. It helps to familiarize yourself with core protocol concepts, such as data types types: VarInts and VarLongs Most data types were trivial to implement, but some gave me more of a fight than others - notably the IEEE754 floating point numbers (more on them later), and so-called VarInt/VarLong numbers. Those may be familar to those acquainted with the MQTT protocol, as they're just a modified version of the LEB128 encoding. LEB128 is a compression scheme for integers. By splitting a byte into 1 signalling bit and 7 data bits, the scheme stores the number length. If the 1st bit is 0, then this byte is the last one; else, then there's another byte after this one. Great scheme if most of your numbers are either between 0 and 127 or 256 and 16383, otherwise it's `buy one byte, get one free` situation, because numbers that would otherwise fit in a byte get pushed out to the next one by a single bit. Picture 3 - explanation of basic LEB128 in a drawing form; red bits are signalling bits, green bits are data bits. Input value is 0xFF (256), output value is 0xFF01 # from src/int.sh # int2varint(int) function int2varint() { local a local b local c local out out=$(printf '%02x' \"$1\") if [[ $1 -lt 128 ]]; then : elif [[ $1 -lt 16384 ]]; then a=$(($1%128)) b=$(($1/128)) out=$(printf \"%02x\" $((a+128)))$(printf \"%02x\" $b) elif [[ $1 -lt $((128*128*128)) ]]; then a=$(($1%128)) c=$((($1/128)%128)) b=$(($1/16384)) out=$(printf \"%02x\" $((a+128)))$(printf \"%02x\" $((c+128)))$(printf \"%02x\" $b) fi echo -n \"$out\" } I've had problems translating the reference implementation to Bash, so instead I played with the protocol enough to write my own from scratch. I figured out that it was basically a modulo and a division in a trenchcoat, which I used to my advantage in the code snippet above. I took a more contemporary approach on the decoder, using an AND, and then multiplying the result - similarly to how the reference did it. LEB128 definitely wasn't the hardest or the most annoying to implement (that one goes to IEEE754 floating point); I still don't like how it is sprinkled in random places inside the protocol, interleaved with regular ints (and longs), and in some cases even signed shorts. IEEE 754 Floating Point numbers I'm not a math person. When I see the exponential notation spewed out by Python, I scream and run. This may be the main cause of why I hated implementing these floating point converters. I won't be going too deep into specifics of how this format works - instead, I recommend you check out this wikipedia page. The basic implementation requires a loop, inside of which there's a negative power applied to the result; Bash doesn't natively support negative powers, which sent me on a trip to find a utility that does. A suggestion I found while duckduckgoing was to use perl, but I consider that cheating. Alternatively, tried using `bc`, but it seems that either it doesn't support powers at all, or the busybox version does not. Bummer. When I was about to give up, I got reminded that Kate once made a plot program in awk. Surely, awk has powers? ~~Maybe even super cow powers?~~ It turns out that it does! $ echo ''awk '{print (2**-1)}' 0.5 With this knowledge, I scribbled a working implementation and attached it to data decoded from the Player Move packet. In a trial run, the client sent around 50-100 packets like that, each one with three doubles (X, Y, Z). It turned out that the conversion function was so slow, that the server wasn't done with that workload after multiple minutes - something rather unacceptable for a real-time game. The easiest solution to lowering the response time would be lowering the amount of calls to external binaries, such as awk. As most of my workload was already inside a bash `for` loop, I just moved the loop inside `awk`, which has saved me literally tens of calls to awk. # (...) asdf=$(cut -c 13-$TEMP/world/0000000000000000 pkt_chunk FFFFFFFF FFFFFFFF 00 pkt_chunk FFFFFFFF 00000000 00 pkt_chunk FFFFFFFF 00000001 00 pkt_chunk 00000000 FFFFFFFF 00 pkt_chunk 00000000 00000000 pkt_chunk 00000000 00000001 00 pkt_chunk 00000001 FFFFFFFF 00 pkt_chunk 00000001 00000000 00 pkt_chunk 00000001 00000001 00 } Picture 7 - output of the code displayed above Another demo worth taking a look at is digmeout - it's a simple highscore based game, which throws you onto a chunk with randomly placed stone and ores. Dig out the most valuable ores until the timer runs out! Picture 8 - you know the game and, you're gonna play it Witchcraft's (that's the project name!) Quirks Bash is notoriously bad at handling decimal numbers. It's *ok* with Integers (as long as you don't do too advanced maths on them), but the only way to handle a decimal number is by multiplying it on input, and somehow placing a dot in the correct place for output. Because of this, most (if not all?) numbers handled by Witchcraft are ints. The multiplayer doesn't really work? I mean, it kinda does, but I never really took time to finish it and polish it up. Witchcraft is technically a multi-threaded server! ... which means that it has to use terrible hacks to communicate between threads. Currently, most global data is stored under `/dev/shm/witchcraft`, internally referenced to as `$TEMP`. Witchcraft is slow, especially in terms of data exchange between multiple threads. Don't expect to be able to send massive amounts of data, generating and sending 16 solid chunks can take as long as a second. Witchcraft currently runs *only* if you have the latest BusyBox (1.35.0) installed. I haven't tested it with GNU coreutils, but I expect it won't work. FAQ Q: Why? A: Because I could. And it was fun! Q: Where do the block IDs come from? A: Witchcraft-internal IDs are defined in src/palette.sh, and can be redefined in \"plugins\". The external IDs to which the internal ones are mapped can be acquired from the vanilla server. Check out this reference page on Data Generators. Q: Why \"WitchCraft\"? A: selfisekai came up with that name, possibly because I'm a (bash) witch, and I thought it was *great* Resources Witchcraft repository wiki.vg Protocol docs Big thanks to Lauren, Mae and cadence for proofreading this post! :3 Comments: Everyone at 15.02.2022, 16:40:40 Liked that helpful person at 15.02.2022, 16:59:22 This project is wicked cool but your font choices make it super hard to read. And this black-on-dark-gray comment box is insane! :D Saphire at 15.02.2022, 17:10:48 Oh dear, that is cursed. Much more so than the HTTP(s) server in bash that I have seen around... I love it~! ...wait is the font for this the minecraft font. And agree with previous comment, the black-on-gray is hard to read q-q new reader at 15.02.2022, 17:48:56 as someone that knows very little bash, this was extremely fun to read. love the website too! :) awesome stuff at 15.02.2022, 17:49:01 awesome stuff josé at 15.02.2022, 18:06:37 I've had this idea a few months ago and I didn't think it was possible. This is awesome! good work. Artur at 15.02.2022, 18:15:27 Awesome stuff lily at 15.02.2022, 18:17:05 i hate it here prefetcher at 15.02.2022, 18:22:08 This is absolutely awesome! Great work!! Rafael at 15.02.2022, 18:49:27 Amazing work! Daniel at 15.02.2022, 18:49:40 That's amazing! Good job! keldu at 15.02.2022, 19:20:46 That's crazy. I wrote a small MC network implementation in C++ and gave up after I started to see how they randomly change packets in different versions. I didn't want to keep up with that. But do this in bash for MC is crazy. I went back and wrote a small reverse proxy server for MC though. Theo at 15.02.2022, 19:36:33 Your website is great. Your posts are great. Your everything is great. Keep up the work, It's definitely worth it... bigking at 15.02.2022, 19:39:06 ilove this. gonna play with it, if i manage to make something worthwhile i let you know. thanks for this interesting unconventional project. Mikael at 15.02.2022, 20:03:07 Cool project! May I ask how much time went into it? I don't really know how complex the protocol is or how long time each test takes, like if you need to restart the client and stuff. anon at 15.02.2022, 20:53:12 nice Triggernometry at 15.02.2022, 21:16:27 this is a glorious write-up of the process tho. one of the best ways to learn coding is to do or see \"what if i did this stupid pointless thing\" then seeing aaaaaall the pitfalls eggmtf at 15.02.2022, 21:19:43 this is insane but really cool, nice work! hyperupcall at 15.02.2022, 21:25:36 I do a lot of Bash and lemmie tell you, this is pretty badass! Some people would say it's cursed, but I think its just cool - Thanks for sharing ^w^ egg at 15.02.2022, 22:03:16 Wow for the hackery of the \"in Bash\", and nice font reminds me of some VGA stuff. anon at 15.02.2022, 22:17:18 neato j3s at 16.02.2022, 01:34:09 dope af a nat you don't know at 16.02.2022, 02:19:17 delightfully cursed, i love it chip at 16.02.2022, 02:49:23 Hardcore :D ayo at 16.02.2022, 06:12:39 noice trekkie1701c at 16.02.2022, 06:16:55 You can hackily handle floating point numbers in a bash script by piping the equation through BCMath. In the case that I've had to do it, it's pretty much: var=$(echo \"scale=9;$num1/$num2\"bc) Where the 9 is the number of decimal places and / is the operand and can be replaced by whatever. This is probably highly inefficient but hey it works. punk xfce at 16.02.2022, 08:19:20 I didn't read that annow at 16.02.2022, 11:11:57 i've never think about it, congrats M at 16.02.2022, 11:21:37 This is exactly the kind of insane (in a good way) stuff I love to read about! Looking forward to more of this! :3 Charles Duffy at 16.02.2022, 13:13:19 You can absolutely read and write streams containing NULs in bash -- the trick is to store them as arrays (with the terminal element containing everything after the last NUL) instead of as strings. Also, echo is an abomination in general, and even the POSIX spec describing it says that printf should be used instead -- search for the excellent answer by Stéphane Chazelas to \"Why is printf better than echo?\" on unix.stackexchange.com RJM at 16.02.2022, 19:12:40 I respect your work so much! Awesome job! RSEA at 16.02.2022, 20:00:24 Great piece. Terminus font in the screenshots also, the best terminal font by far. LeigerGaming at 16.02.2022, 22:23:12 Interesting! Wensz at 16.02.2022, 22:42:09 I got rickrolled at the ending. Francois Scheurer at 17.02.2022, 10:43:56 nice work! I was puzzled with the line: a=$(dd count=2 bs=$len status=nonexxd -p) as dd cannot will hangs here on an empty stdin. or maybe it's lacking context and your script stdin is filled already with data...? or are you using some function like this? function a() { dd count=$len bs=1 status=nonexxd -p; } anyway it is a clever idea to use dd to deal with null chars! Another way would be to use tempfiles (in ram) instead of strings variables, but that would probably perform slower. Drygord at 19.02.2022, 18:40:39 Cool project - what is the font and color scheme of this webpage? A at 03.03.2022, 01:10:46 SO mine at 04.03.2022, 21:41:59 craft chfour at 10.03.2022, 19:11:45 that is, quite literally, witchcraft. I'm amazed. I mean I made an HTTP server in browser Javascript, and that's NOTHING compared to this. this is a fully functional, real time minecraft server. a full-on online 3D game. Wow. also, lovely font choice ;) me at 10.03.2022, 19:17:31 My BRAIN IS BOGELED NotNite at 04.05.2022, 23:21:31 wow this is horrifying some guy on the interweb of tubes at 25.12.2022, 23:42:35 This is sooo cool! I once tried to write an http server in bash and gave up on it after writing file serving code became too hard for me test at 29.12.2022, 16:01:13 test juh at 06.02.2023, 17:36:51 inspires fear in friends and enemies alike :D nigga at 02.03.2024, 17:13:16 nig Bot at 02.03.2024, 17:27:23 Ah yes, a comment section with no captcha. I hope bots don't evade it. Bobby Tables at 02.03.2024, 20:04:46 cool post, i loved it'); DROP TABLE comment_section -- 🤪 at 02.03.2024, 20:41:05 🤪 Lit at 02.03.2024, 20:49:23 This is a beautiful abomination. I hope you're proud of yourself. 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥 keratoconus at 02.03.2024, 20:58:13 Please add a light theme :( Slug at 02.03.2024, 22:36:54 Agree that the font makes this super hard to read. If i zoom in or out at all in Chrome it becomes blurry. BUT - persevered to read the content of the article which was super cool! Awesome work anonymouse at 03.03.2024, 02:25:04 function stdin2hexdump() { local LC_ALL= LC_CTYPE=C LC_COLLATE=C LANG= local IFS=\"\" c b h o=0 hs= cs= i1=$'\\033[7m' i0=$'\\033[27m' while read -r -s -d \"\" -n 1 c; do printf -v b \"%d\" \"'${c}\" printf -v h \"%02X\" \"${b}\" case \"${c}\" in $'\\000' ) c=\"${i1}@${i0}\";; $'\\001' ) c=\"${i1}A${i0}\";; $'\\002' ) c=\"${i1}B${i0}\";; $'\\003' ) c=\"${i1}C${i0}\";; $'\\004' ) c=\"${i1}D${i0}\";; $'\\005' ) c=\"${i1}E${i0}\";; $'\\006' ) c=\"${i1}F${i0}\";; $'\\007' ) c=\"${i1}G${i0}\";; $'\\010' ) c=\"${i1}H${i0}\";; $'\\011' ) c=\"${i1}I${i0}\";; $'\\012' ) c=\"${i1}J${i0}\";; $'\\013' ) c=\"${i1}K${i0}\";; $'\\014' ) c=\"${i1}L${i0}\";; $'\\015' ) c=\"${i1}M${i0}\";; $'\\016' ) c=\"${i1}N${i0}\";; $'\\017' ) c=\"${i1}O${i0}\";; $'\\020' ) c=\"${i1}P${i0}\";; $'\\021' ) c=\"${i1}Q${i0}\";; $'\\022' ) c=\"${i1}R${i0}\";; $'\\023' ) c=\"${i1}S${i0}\";; $'\\024' ) c=\"${i1}T${i0}\";; $'\\025' ) c=\"${i1}U${i0}\";; $'\\026' ) c=\"${i1}V${i0}\";; $'\\027' ) c=\"${i1}W${i0}\";; $'\\030' ) c=\"${i1}X${i0}\";; $'\\031' ) c=\"${i1}Y${i0}\";; $'\\032' ) c=\"${i1}Z${i0}\";; $'\\033' ) c=\"${i1}[${i0}\";; $'\\034' ) c=\"${i1}\\\\${i0}\";; $'\\035' ) c=\"${i1}]${i0}\";; $'\\036' ) c=\"${i1}^${i0}\";; $'\\037' ) c=\"${i1}_${i0}\";; $'\\177' ) c=\"${i1}?${i0}\";; esac (( b > 127 )) && c=\"${i1}.${i0}\" hs+=\" ${h}\" cs+=\"${c}\" (( o++ )) (( o % 16 )) || { printf \"%08X |%s%s |\" \"$(( ${o} - 16 ))\" \"${hs}\" \"${cs}\"; hs=; cs=; } done (( o % 16 )) && printf \"%08X |%-48s%s |\" \"$(( ${o} - ( ${o} % 16 ) ))\" \"${hs}\" \"${cs}\" } By commenting, you agree for the session cookie to be stored on your device ;p © sdomi 2010-2024, licensed under CC BY-SAdonate at my ko-fi",
    "commentLink": "https://news.ycombinator.com/item?id=39572858",
    "commentBody": "Writing a Minecraft server from scratch in Bash (2022) (sdomi.pl)278 points by LorenDB 19 hours agohidepastfavorite38 comments TeaVMFan 18 hours agoAs someone who's done a lot of work with scriptable Minecraft servers for both Java and Bedrock (ScraM), this is impressive. Bonus points for using \"duckduckgoing\" in a sentence. reply pvg 18 hours agoprevDiscussion at the time https://news.ycombinator.com/item?id=30347501 92 comments reply dang 12 hours agoparentThanks! Macroexpanded: My thoughts on writing a Minecraft server from scratch in Bash - https://news.ycombinator.com/item?id=30347501 - Feb 2022 (90 comments) reply BearOso 17 hours agoprevA negative power, i.e. 2^(-n) is just 1/(2^n). I'm surprised the author didn't remember that with their own 2^-1 = 0.5 example and eventually reached out to awk for it. reply tryauuum 12 hours agoparentI don't understand how this would help the author. Since the bash doesn't support floating point numbers anyway reply taviso 17 hours agoprevThey should have used my (dumb?) library, ctypes.sh: https://github.com/taviso/ctypes.sh Then they can access libm, poll(), select() and so on from bash :) reply MrBuddyCasino 14 hours agoparentI‘m not sure you should have done that, but it is impressive for the sheer chuzpa of it. Like reanimating Frankenstein. reply jethro_tell 11 hours agoparentprevLol, holy shit what did I just read? Amazing, installing now. I want to be part of the problem. reply lagniappe 16 hours agoparentprevwoah that's cool :) also hello tavis reply Brian_K_White 10 hours agoparentprevAwesome, but beside the point of writing something in bash that never needed to be in bash for any technical reason. Meaning if it requires bash plus some specially installed compiled c code, then it might as well require c or python or anything else and there is no point in calling it \"written in bash\", or writing it in mostly-bash-plus-special-plugin. I do know who I'm speaking to so please assume I say this respectfully. :) I have no problem with a \"pointless\" project like that as I'll show in a second. That said, this minecraft project itself relies on externals like xxd when it doesn't need to, so using ctypes.sh would be no worse in this case, so you are right, in this case they might as well have. But for the record it is possible to read, store, manipulate, do math on, and output binary in pure bash without anything like dd or xxd. The only byte that is a problem is null, and there is a way to deal with that. You can't directly store a null, but you can detect that you read one and store that info, and reconstruct it on output later, or do math on it, use it's numerical value as an array index or byte offset or whatever the byte is for. For a minimal example, just copying a binary file: while LANG=C IFS= read -d '' -r -n 1 x ;do printf '%c' \"$x\" ;done bin2 That's a bit too minimal since it doesn't show what other kinds of things you can do that are more useful than cat-without-cat. A bit more generic and useful: https://gist.github.com/bkw777/c1413d0e3de6c54524ddae890fe8d... The LANG=C, IFS= , and -d'' all combine to render all bytes accessible except 0x00, and then the return value from read() tells you the difference between \"we read a 0x00\" and \"we didn't read anything\" and \"input ended\" And it doesn't have to useon the overall while() comand either. You can exec 3file_or_fifo_or_tty and read -u3 / printf >&3 etc inside the loop instead. An example reading from a serial port: https://gist.github.com/bkw777/ddde771cc85fdd888c7ec74953193... Used in anger: https://github.com/bkw777/pdd.sh see tpdd_read, tpdd_write, file_to_fhex, str_to_shex reading and writing both a serial port and local files and doing all kinds of processing on the data. And these loops are not even subshells let alone externals. You can manipulate variables inside the loop and you are still in the same original context. I'd say parent shell but there are no childern. Those all read a single byte at a time with read -n 1, but they don't have to. You can read without the -n1 and each iteration of the loop will collect as much as it can between nulls instead of always one byte. That would consume less ram and less loop iterations. But the things I'm using them for want to slice & dice the individual bytes and byte-ranges at numerical offsets anyway and the data is always small (by todays standards) so the array-of-hex-pairs is just too convenient where a[n] == byte n, and all bytes are treated the same whether printable, non-printable, or null, and aside from merely storing and regenerating the bytes with printf you can also use the numerical values directly as well by simply prepending 0x, so 0x$n or 0x${a[n]} almost anywhere you would normally have a simple integer. So you can do math on them and use them as array indexes and byte offsets etc. Read the 2nd byte of h[] as a length of the payload to follow, and clip out that payload: ${h[@]:2:0x${h[1]}} reply osigurdson 9 hours agoprevWhile I am not good at bash programming, I am surprised how capable / non horrible it actually is. reply dinkleberg 18 hours agoprevNow this is a proper hacker site. This is great. reply lanthade 17 hours agoparentnext [6 more] [flagged] monitron 17 hours agorootparentThere is a set of radio buttons in the top right corner you can use to choose a different one :) reply lagniappe 16 hours agorootparentprevWeird, the older I get the better that font is for me. I wonder if that's because of nostalgia as all of the terminals at that age looked like this. reply love2read 17 hours agorootparentprevThis website is the one of the rare times where safari’s reader mode that changes the font was super nice to read. reply unnouinceput 15 hours agorootparentprevYou can always use reader mode of your browser. reply lanthade 15 hours agorootparent100% right. I completely forgot about that. Thanks. reply SunlitCat 17 hours agoprevJust wondering, but is writing custom servers for commercial games still a thing? reply madeofpalk 16 hours agoparentFor Minecraft, very much so. Minecraft, especially the Java version, is in a comparatively odd place in that it receives significant free content updates AND officially supports running any historical version AND has an extremely vibrant modding community. Minecraft (Java) is as much of a game engine for others to build on as it is a game itself. reply themoonisachees 15 hours agorootparentThis is because in addition to being the most sold video game of all time, minecraft is effectively open source. It's not literally open source, but you can decompile java bytecode with standard tooling, and symbols are available, either community-reversed, or official. reply teaearlgraycold 15 hours agorootparentFrustrating how game studios can see Minecraft's success here and not change a thing about their development practices. reply Aurornis 13 hours agorootparentThere’s actually a very large and vibrant community for modding Unity games like this. More competitive games can’t afford any type of easy reverse engineering due to the cheating factor. reply darknavi 12 hours agorootparentMods are the (amazing) end game for Lethal Company. So many fun, new tweaks and content. reply noah91734 12 hours agorootparentFor the curious: https://thunderstore.io/c/lethal-company/ Click on any mod, and you can see the decompiled source. The mods use function hooking to run before or after certain functions are called rather than the event based system you see in Minecraft plugins. reply LtWorf 7 hours agorootparentprevminetest is open source for real though reply Filligree 15 hours agorootparentprevThe four great game engines: Unreal, Unity, Minecraft and Godot. I don’t think Minecraft is number four on the list. It might be number two. reply jasonjayr 15 hours agorootparentRoblox is somewhere on that list too .... reply Filligree 10 hours agorootparentHow many thousand mods does it have? reply BalinKing 10 hours agorootparentIsn't each server its own mod, in effect? reply LtWorf 7 hours agorootparentprevMinetest is much more of a game engine. I've heard from someone I know that played both extensively that minetest is less prone to losing everything for data corruption (never happened once in minetest, regularly in minecraft after a while. But sample size is 1). reply tehbeard 1 hour agorootparentIs that sample size of one from the java edition or bedrock edition of minecraft? reply haunter 15 hours agoparentprevNot just servers but for some games clients too https://runelite.net/ reply static_motion 14 hours agorootparentI find RuneLite a fascinatingly well-built piece of software. The lead dev, Adam, did a fantastic job with it, and good on Jagex for allowing its use, even as far as advertising it on their own front page. reply hoten 14 hours agorootparentIt really papers over (some of) the tedium of the game and let's you enjoy the rest easier. Love it. reply petee 16 hours agoparentprevI think it will always be a thing for those who play games & like to dabble with tech, either to fix a bug, learn a language, or just see how the sausage is made. reply firtoz 16 hours agoparentprevAFAIK yes, the RE scene is still active. reply fddrdplktrew 8 hours agoprevMinecraft, one of greatest game since Quake reply bilekas 10 hours agoprev [–] So that happened... Jesus. I've read a lot of articles about the way they implement stuff but this takes the cake. Hands down one of, if not the best write up of something wild I've ever read. Top shelf. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their experience creating a Minecraft server in Bash, addressing challenges like binary data parsing and optimizing performance.",
      "The project, Witchcraft, faces limitations with decimal numbers and multiplayer functionality, requiring the latest BusyBox version for operation.",
      "The post has garnered praise for its innovative use of Bash scripting in Minecraft, sparking discussions on handling floating point numbers, NULs, and real-time server setup in various forums."
    ],
    "commentSummary": [
      "The post highlights creating a Minecraft server from scratch using Bash, sparking discussions on the technical aspects and potential of such a project.",
      "Comments delve into the significance of Minecraft in the modding and game development community, as well as related topics like modding Unity games and the open-source nature of Minecraft.",
      "There is also mention of the role of custom servers in gaming, adding depth to the discussion on game servers and customization options."
    ],
    "points": 278,
    "commentCount": 38,
    "retryCount": 0,
    "time": 1709390563
  },
  {
    "id": 39572106,
    "title": "Mathematicians Prove Pólya's Conjecture on Disk Eigenvalues",
    "originLink": "https://phys.org/news/2024-03-mathematicians-plya-conjecture-eigenvalues-disk.html",
    "originBody": "March 1, 2024 Editors' notes This article has been reviewed according to Science X's editorial process and policies. Editors have highlighted the following attributes while ensuring the content's credibility: fact-checked trusted source proofread Mathematicians prove Pólya's conjecture for the eigenvalues of a disk, a 70-year-old math problem by Béatrice St-Cyr-Leroux, University of Montreal Credit: Inventiones mathematicae (2023). DOI: 10.1007/s00222-023-01198-1 Is it possible to deduce the shape of a drum from the sounds it makes? This is the kind of question that Iosif Polterovich, a professor in the Department of Mathematics and Statistics at Université de Montréal, likes to ask. Polterovich uses spectral geometry, a branch of mathematics, to understand physical phenomena involving wave propagation. Last summer, Polterovich and his international collaborators—Nikolay Filonov, Michael Levitin and David Sher—proved a special case of a famous conjecture in spectral geometry formulated in 1954 by the eminent Hungarian-American mathematician George Pólya. The conjecture bears on the estimation of the frequencies of a round drum or, in mathematical terms, the eigenvalues of a disk. Pólya himself confirmed his conjecture in 1961 for domains that tile a plane, such as triangles and rectangles. Until last year, the conjecture was known only for these cases. The disk, despite its apparent simplicity, remained elusive. \"Imagine an infinite floor covered with tiles of the same shape that fit together to fill the space,\" Polterovich said. \"It can be tiled with squares or triangles, but not with disks. A disk is actually not a good shape for tiling.\" The universality of mathematics In an article published in the mathematical journal Inventiones Mathematicae, the researchers show that Pólya's conjecture is true for the disk, a case considered particularly challenging. Though their result is essentially of theoretical value, their proof method has applications in computational mathematics and numerical computation. The authors are now investigating this avenue. \"While mathematics is a fundamental science, it is similar to sports and the arts in some ways,\" Polterovich said. \"Trying to prove a long-standing conjecture is a sport. Finding an elegant solution is an art. And in many cases, beautiful mathematical discoveries do turn out to be useful—you just have to find the right application.\" More information: Nikolay Filonov et al, Pólya's conjecture for Euclidean balls, Inventiones mathematicae (2023). DOI: 10.1007/s00222-023-01198-1 Provided by University of Montreal Citation: Mathematicians prove Pólya's conjecture for the eigenvalues of a disk, a 70-year-old math problem (2024, March 1) retrieved 3 March 2024 from https://phys.org/news/2024-03-mathematicians-plya-conjecture-eigenvalues-disk.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
    "commentLink": "https://news.ycombinator.com/item?id=39572106",
    "commentBody": "Mathematicians prove Pólya's conjecture for the eigenvalues of a disk (phys.org)225 points by rbanffy 20 hours agohidepastfavorite48 comments ganzuul 11 minutes agoI want a program that reconstructs the landscape from the sound of rolling thunder. https://en.wikipedia.org/wiki/Impulse_response reply perihelions 17 hours agoprevWhat do the eigenfunctions look like? I didn't know the circular disk was such an exotic problem for Laplace's equation. edit: Ah, I misunderstood the problem. The eigenfunctions are exactly solved; the problem of sorting and ordering their eigenvalues is apparently not! From their page 4, - \"Although all the eigenvalues of the Dirichlet and Neumann Laplacians on the unit disk are explicitly known in terms of zeros of the Bessel functions or their derivatives, see §2 below, in each case the spectrum is given by a two-parametric family, and rearranging it into a single monotone sequence appears to be an unfeasible task.\" https://arxiv.org/abs/2203.07696 reply mikhailfranco 18 hours agoprevThe title words remind of an unrelated fact, Gershgorin Disks: The eigenvalues of any N x N matrix, A, are contained in the union of N discs in the complex plane. The center of the i_th disc is the i_th diagonal element of A. The radius of the i_th disc is the absolute values of the off-diagonal elements in the i_th row. https://blogs.sas.com/content/iml/2019/05/22/gershgorin-disc... It's rather remarkable, unexpected, and perhaps shocking, when you first hear it. There does not seem to be enough information to make it true. But it is. I used it in a real project to cancel noise. reply jonathan_landy 17 hours agoparentMatrix theory by Franklin is a great, affordable book containing many interesting results such as this — can highly recommend for those interested in linear algebra. https://www.amazon.com/Matrix-Theory-Dover-Books-Mathematics... reply kwkelly 11 hours agorootparentMatrix Analysis by Horn and Johnson is another great book, though it is a bit pricier than a Dover book. reply homerowilson 11 hours agorootparentprevYou may enjoy this: https://bwlewis.github.io/cassini/ reply packetlost 17 hours agorootparentprevIf I have an atrophied high school level understanding of linear algebra, will I get anything out of that book? reply jonathan_landy 16 hours agorootparentCertainly a useful reference, if you might deal with the topic for some project … but not the best refresher out there for the basics. reply doubloon 14 hours agorootparentprevor https://store.doverpublications.com/products/9780486411798 reply stabbles 17 hours agoparentprevIt's not that remarkable at all? The proof requires the definition and triangle inequality, that's all? Given Ax=λx, take i for which |xᵢ| is largest. Look at the i'th equation: sum aᵢⱼxⱼ = λxᵢ, move the aᵢᵢxᵢ term to the rhs, take absolute values, divide by |xᵢ|, apply triangle inequality, and you have |aᵢᵢ - λ| ≤ sum |aᵢⱼ| over j≠i. So for every eigenvalue you can find such a disc. That's by column, for row use Aᵀ. reply kmm 15 hours agorootparentBeing easy to prove doesn't make it unremarkable. Lots of theorems, including this one, have straightforward proofs once you are given the exact formulation. The tricky part is coming up with the idea for the theorem itself. I remember being (mildly) shocked when I was taught this in undergrad, it just seemed too good to be true. reply stabbles 15 hours agorootparentI think that's just how textbooks present it. A fact is stated but you're lacking intuition. If you had played around a bit with Laplacian matrices, like tri-diagonal matrices with stencil [-1, 2, -1], and found that its eigenvalues are within 2 ± 2, and if you also realized that A + τI has the same eigenvalues shifted by τ, then it's a small step to consider that the magnitude of the off-diagonal may have something to do with the spread of eigenvalues. It's likely that Gerschgorin stumbled upon it like this. reply llmzero 14 hours agorootparentprevJust thinking about some intuition for the result of the theorem: If the off diagonal elements are zero then the diagonal element is an eigenvalue, by continuity of the determinant, if the off diagonal element are small then $det(A-a_{ii}\\lambda)$ is almost zero, that is the new eigenvalue is near aii. So it suggests that the off diagonal elements measure how far is aii from being an eigenvalue. reply nine_k 15 hours agorootparentprevThe Euler's identity is also trivial to deduce, but this doesn't diminish its beauty. reply xanderlewis 15 hours agorootparentThe Yoneda lemma is another great example of (once you've got the right setup) trivial but beautiful reply jonahx 13 hours agorootparentprevremoved reply tsimionescu 12 hours agorootparentThey are saying that the Greshgorin theorem that the OP is talking about is simple to prove, not the Polya conjecture that took 70 years from the article. reply moralestapia 14 hours agorootparentprevHuh? Math 101, simple is better. reply abetusk 18 hours agoparentprevWhat was the noise cancelling project? How did you use this fact to cancel noise? reply sdenton4 16 hours agorootparentJust guessing, but.... A common noise cancellation technique is to throw away small eigenvalues, as in PCA. This result relates eigenvalues to the structure of the matrix, so might be helpful for reducing ev's without bothering with diagonalization? [Edit] This would presumably involve just zeroing out the rows with small diagonal elements and small-ish off-diagonal norm... Center the eigenvalue estimate disk at zero, and then zero out the rest of the row to make the estimate exact. reply sdenton4 12 hours agorootparent(and after one more thought about it, one would zero out the row /and column/ to preserve the symmetry of the matrix, if applicable, and thus keep the eigenvalues real. and one would probably want to think a bit about whether this kind of deletion actually makes sense for the problem... doing real PCA isn't /that/ hard in most cases - I think I would do something this janky only for extremely large matrices or for realtime operation on a microcontroller or something, and then only after thinking hard about it.) reply frutiger 18 hours agoparentprevSounds very cool. One thing I didn’t understand though: > The radius of the i_th disc is the absolute values How can a radius of a single disc (i.e. a single value) correspond to multiple values? reply Infinity315 11 hours agorootparentAn intuitive explaination is imagine a nearly diagonal matrix where the values along the diagonal are much larger than values on the off diagonal. We know the eigenvalues of a diagonal matrix is simply the values on the diagonal, so for nearly diagonal matrices you can be pretty sure that the true eigenvalues are going to be pretty close to those diagonal entries, but a natural question to ask is how far we'd deviate from those diagonal entries. The answer to the above question is Gerschgorin disks and it's closely related cousin Brauer's Oval of Cassini. For matrices with real eigenvalues it's moreso along the real number line, only for cases where the eigenvalues are imaginary do we imagine disks. reply ximeng 17 hours agorootparentprevIf you look at the link there’s a formula showing it’s the sum. reply abetusk 17 hours agorootparentSpecifically: r_i = \\sum_{i e j} |A_{i j}| reply reactordev 17 hours agorootparentprevI’m assuming, but could be wrong as my matrix math ended with GameDev, that the radius of the disk = the absolute values of the other things. +\\- depending on which side of the disk they fall? That line got me as well. reply Sharlin 17 hours agorootparentIt's missing the word \"sum\". Which apparently my brain auto-deduced for me because I didn't notice anything off in the sentence on the first reading. reply _zoltan_ 16 hours agorootparentMy brain also automatically added sum and also haven't noticed anything, but I have a math degree, maybe it's just assuming things :-) reply frutiger 16 hours agorootparentI have a physics degree and did not assume it, that might explain the difference :) reply tomrod 17 hours agorootparentprevSum the absolute values of a row for all the off diagonal elements reply Tommah 9 hours agoparentprevbee_rider already touched on this in another comment, but the theorem makes sense if you consider a matrix with large diagonal values and small off-diagonal values (in magnitude). If I have a matrix with 1,000,000 on the diagonal and 1 everywhere else, I'd expect the eigenvalues to be 1,000,000 plus or minus some small error. The Gershgorin disk theorem proves this and puts an upper bound on the error. The diagonal elements of matrices have a lot of rather \"magical\" properties if you think about it. Their sum is also the sum of the eigenvalues of the matrix. And if you have a matrix A that is singular, you can choose any value x that is not an eigenvalue, and then A - xI is invertible but still mostly behaves like A. reply bee_rider 15 hours agoparentprevIt has an intuitive element to it; we’re looking for the eigenvalue, the vector/scalar pair where the scalar has the same effect on the vector as multiplying by the matrix. And we’re comparing against something that looks vaguely like the magnitude of the matrix (shifted by the diagonal, and of course if you had a diagonal matrix, the eigenvalues would just be the diagonal). Not a proof or anything, of course the proof is on Wikipedia and nice and elegant. Just a thought on the gut feeling. I agree that it is a very nice result. reply Infinity315 11 hours agoparentprevSee also Brauer's oval of Cassini which give an equivalent or even better approximation of the eigenvalues of a matrix. reply VyseofArcadia 19 hours agoprevarXiv link: https://arxiv.org/abs/2203.07696 reply mikeiavelli 10 hours agoprevFrom the paper \"Pólya’s conjecture for Euclidean balls\" https://dms.umontreal.ca/~iossif/polya.pdf \"The celebrated Pólya’s conjecture (1954) in spectral geometry states that the eigenvalue counting functions of the Dirichlet and Neumann Laplacian on a bounded Euclidean domain can be estimated from above and below, respectively, by the leading term of Weyl’s asymptotics. Pólya’s conjecture is known to be true for domains which tile Euclidean space, and, in addition, for some special domains in higher dimensions. In this paper, we prove Pólya’s conjecture for the disk, making it the first non-tiling planar domain for which the conjecture is verified. We also confirm Pólya’s conjecture for arbitrary planar sectors, and, in the Dirichlet case, for balls of any dimension. Along the way, we develop the known links between the spectral problems in the disk and certain lattice counting problems. A key novel ingredient is the observation, made in recent work of the last named author, that the corresponding eigenvalue and lattice counting functions are related not only asymptotically, but in fact satisfy certain uniform bounds.\" reply esafak 18 hours agoprevI haven't read the paper, but does it apply to arbitrarily shaped drums? And if the basis can be arbitrarily large, is this an exciting result? It just says that the spectral domain is isomorphic? reply eigenket 17 hours agoparentThis result only applies to circular disks, spherical balls and their generalisations in higher dimensions. Previously it was known for shapes which tile the plane or tessellate the space in higher dimensions. reply snitty 19 hours agoprevMathematicians prove that you can deduce the shape of disk based on the frequencies it produces when you hit it with a stick. reply gus_massa 16 hours agoparentThe first sentense is very misleading: > Is it possible to deduce the shape of a drum from the sounds it makes? That's a known problem with a (very nice) negative answer https://www.ams.org/publicoutreach/feature-column/fcarc-1997... IIUC this article is about the problem in the other direction, i.e. from the shape (a disk!) to the frecuencies of the sound (eigenvalues).It's not about an exact calculation, but about an aproximation of them. > The conjecture bears on the estimation of the frequencies of a round drum or, in mathematical terms, the eigenvalues of a disk. From the research paper: > The celebrated Pólya’s conjecture (1954) in spectral geometry states that the eigenvalue counting functions of the Dirichlet and Neumann Laplacian on a bounded Euclidean domain can be estimated from above and below, respectively, by the leading term of Weyl’s asymptotics.The Weyl's asymtotics is probably a good estimation of the very high frecuencies/eigenvalues, and the conjeture is probabbly that you can use the estimation as upper or lower bounds instead of just an aproximation. [Sorry, not my area and I have not enough time to read the paper.] reply kadoban 18 hours agoparentprevI can deduce the disk's shape without even hitting it. It's a disk. reply m3kw9 18 hours agoparentprevUseful as a magic trick, guessing the shape of your disc when you hit it reply grapescheesee 18 hours agoparentprevnext [2 more] [flagged] mdekkers 18 hours agorootparentI’m sorry. As a machine model, I cannot condone acts of violence against disks. Have you tried discussing your differences between you, perhaps with the assistance of some professional mediator? reply colesantiago 15 hours agoprev [–] Nice, what are the potential use cases for this? Can I use this for my business? reply bubblyworld 4 hours agoparentProbably not - in applications, heuristics/approximations and \"probably true\" are king. And in this case the relevant approximations have been known for decades at least. That's a very different beast to the game mathematicians play, which demands rigorous proof (or at least a fairly close social version of it, it's turtles all the way down). reply VyseofArcadia 6 hours agoparentprevThis is the sort of thing that comes up in simulations for various engineering subfields. So if your business is computer aided engineering tools or perhaps CAD, then probably yes. reply userbinator 2 hours agoparentprevThese days, you'd probably want to know the eigenvalues of an SSD instead. /s reply colesantiago 11 hours agoparentprev [–] This is a valid question???? reply yreg 7 hours agorootparent [–] Doesn't seem so. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mathematicians at the University of Montreal have resolved Pólya's conjecture for the eigenvalues of a disk, a 70-year-old math problem that was previously unsolved.",
      "They utilized spectral geometry to delve into wave propagation, offering a theoretical solution with implications for computational mathematics.",
      "This breakthrough underscores the importance and versatility of mathematical findings across different disciplines, emphasizing the elegance and significance of mathematics in practical applications."
    ],
    "commentSummary": [
      "Mathematicians have proven Pólya's conjecture for the eigenvalues of a disk, focusing on sorting and ordering the eigenvalues.",
      "The Gerschgorin Theorem states that each eigenvalue of a matrix is within a disk in the complex plane, with implications for determining eigenvalues in matrices with real values and discussing matrix symmetry.",
      "Discussions include Pólya's conjecture for Euclidean domains, Brauer's oval of Cassini for eigenvalue approximation, and the practical applications of eigenvalues in simulations and computer aided engineering, with a humorous remark about SSDs and their eigenvalues."
    ],
    "points": 225,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1709382442
  },
  {
    "id": 39571439,
    "title": "Introduction to Data Science: HarvardX Class Notes (2019)",
    "originLink": "http://rafalab.dfci.harvard.edu/dsbook-part-1/",
    "originBody": "Introduction to Data Science Data Wrangling and Visualization with R Preface This is the website for the Introduction to Data Science. The website for Advanced Data Science is here1. We make announcements related to the book on Twitter. For updates follow @rafalab2. This book started out as the class notes used in the HarvardX Data Science Series3. The Quarto files used to generate the book is available on GitHub4. Note that, the graphical theme used for plots throughout the book can be recreated using the ds_theme_set() function from dslabs package. This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International CC BY-NC-SA 4.05. A hardcopy version of the book is available from CRC Press6. A free PDF of the October 24, 2019 version of the book is available from Leanpub7. Acknowledgments This book is dedicated to all the people involved in building and maintaining R and the R packages we use in this book. A special thanks to the developers and maintainers of base R, the tidyverse, data.table, and the caret package. A special thanks to Jenna Landy for her careful editing and helpful advice on this book; to David Robinson for generously answering many questions about the tidyverse and aiding in my understanding of it; and to Amy Gill for dozens of comments, edits, and suggestions. Also, many thanks to Stephanie Hicks who twice served as a co-instructor in my data science classes and Yihui Xie who patiently put up with my many questions related to markdown. Thanks also to Karl Broman, from whom I borrowed ideas for the Data Visualization and Productivity Tools parts. Thanks to Peter Aldhous from whom I borrowed ideas for the principles of data visualization section and Jenny Bryan for writing Happy Git and GitHub for the useR, which influenced our Git chapters. Also, many thanks to Jeff Leek, Roger Peng, and Brian Caffo, whose onlile classes inspired the way this book is divided, to Garrett Grolemund and Hadley Wickham for making the markdown code for their R for Data Science book open, and the editors, John Kimmel and Lara Spieker, for their support. Finally, thanks to Alex Nones for proofreading the manuscript during its various stages. This book was conceived during the teaching of several applied statistics courses, starting over fifteen years ago. The teaching assistants working with me throughout the years made important indirect contributions to this book. The material was further refined during a HarvardX series coordinated by Heather Sternshein and Zofia Gajdos. We thank them for their contributions. We are also grateful to all the students whose questions and comments helped us improve the book. The courses were partially funded by NIH grant R25GM114818. We are very grateful to the National Institutes of Health for its support. A special thanks goes to all those who edited the book via GitHub pull requests or made suggestions by creating an issue or sending an email: nickyfoto (Huang Qiang), desautm (Marc-André Désautels), michaschwab (Michail Schwab), alvarolarreategui (Alvaro Larreategui), jakevc (Jake VanCampen), omerta (Guillermo Lengemann), espinielli (Enrico Spinielli), asimumba(Aaron Simumba), braunschweig (Maldewar), gwierzchowski (Grzegorz Wierzchowski), technocrat (Richard Careaga), atzakas, defeit (David Emerson Feit), shiraamitchell (Shira Mitchell), Nathalie-S, andreashandel (Andreas Handel), berkowitze (Elias Berkowitz), Dean-Webb (Dean Webber), mohayusuf, jimrothstein, mPloenzke (Matthew Ploenzke), NicholasDowand (Nicholas Dow), kant (Darío Hereñú), debbieyuster (Debbie Yuster), tuanchauict (Tuan Chau), phzeller, BTJ01 (BradJ), glsnow (Greg Snow), mberlanda (Mauro Berlanda), wfan9, larswestvang (Lars Westvang), jj999 (Jan Andrejkovic), Kriegslustig (Luca Nils Schmid), odahhani, aidanhorn (Aidan Horn), atraxler (Adrienne Traxler), alvegorova,wycheong (Won Young Cheong), med-hat (Medhat Khalil), kengustafson, Yowza63, ryan-heslin (Ryan Heslin), raffaem, tim8west, jooleer, pauluhn (Paul), tci1, beanb2 (Brennan Bean), edasdemirlab (Erdi Dasdemir), David D. Kane, El Mustapha El Abbassi, Vadim Zipunnikov, Anna Quaglieri, Chris Dong, Bowen Gu, and Rick Schoenberg. http://rafalab.dfci.harvard.edu/dsbook-part-2/↩︎ https://twitter.com/rafalab↩︎ https://www.edx.org/professional-certificate/harvardx-data-science↩︎ https://github.com/rafalab/dsbook-part-1↩︎ https://creativecommons.org/licenses/by-nc-sa/4.0↩︎ https://www.routledge.com/Introduction-to-Data-Science-Data-Analysis-and-Prediction-Algorithms-with/Irizarry/p/book/9780367357986?utm_source=author&utm_medium=shared_link&utm_campaign=B043135_jm1_5ll_6rm_t081_1al_introductiontodatascienceauthorshare↩︎ https://leanpub.com/datasciencebook↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=39571439",
    "commentBody": "R: Introduction to Data Science (2019) (dfci.harvard.edu)180 points by tosh 23 hours agohidepastfavorite120 comments chollida1 21 hours agoi'm an old R user, now migrated fully to python. For those of you who us R still what is your use case? We found R has a really hard time integrating into data pipelines and was best used as a standalone tool by individuals, which doesn't really work in our particular professional setup where everyone works collaboratively together. What we found was that R had alot of packages but most haven't been touched in years and when you contact the owner you find they've often moved onto the python/pandas/scikit eco system reply nomilk 21 hours agoparentAbout half our team can wrangle and plot as fast as we can think of ideas. It creates an incredibly tight cycle time between us having ideas and getting answers; sometimes many (e.g. 10-20+) of those cycles in a single meeting. Before we used R, it would require someone jotting down things to investigate and reporting back in the next meeting. But we can do ~80% of whatever people can think of on the spot (more involved research questions can take more time). The unique qualities of R that allow this are that it's so easy to use, extremely reliable for package installation (problems occur approximately never), and the tidyverse makes it incredible easy to translate ideas into code, not only in its broad, easy to understand and powerful vocabulary, but in there being little 'nesting' required; instead working left to right and top to bottom (via the magrittr pipe) - i.e. your code, for the most part, is like reading a page in a book. reply j7ake 9 hours agorootparentFor exploring data, plotting data, and fitting complex models like GLMs and GAMs, using R is essentially as fast as thought at this point. So if you have tabular data, it’s a no brainer to use R. Getting the data into table form is often better suited for python. Fitting models that leverage autograd are also better with python. reply jgalt212 6 hours agorootparent> Getting the data into table form is often better suited for python. Fitting models that leverage autograd are also better with python. Totally agree. If it's in a dataframe, I prefer R. If I get involved pre-dataframe, I prefer Python. reply hadley 20 hours agoparentprevIf you tell me what makes R hard to integrate into data pipelines I will do my best to fix it :) reply chollida1 19 hours agorootparentWow, I really appreciate the reply. As I said in another comment here, I wish tidyverse was big when I was using R. I was an R user from about 2003-2010. We didn't have DPlyr at the moment though ggplot2 was coming around about that time I think. That helped alot for easy to develop visualizations. But in our specific cases, the distributed libraries we used were written in python and integrated well with native python code. Pandas was just coming out around 2010, I think, and I think multi threading was also an issue then, but I can't really remember. So our issues was partially our infrastructure tooling was going to python, but also we had a far easier time hiring people who were proficient in python and harder to find the same for R. And once you start writing more code in python it starts to become harder to justify two separate code bases that can do the same thing so the R code got phased out and rewritten in python so we could have a single code base and not have to duplicate functionality in two languages. Also a slight push for python came from the programmers who thought python represented a better language to know for their careers. Which looking back it does seem like python is used more often these days in general. So I guess there isn't much you could have done in this case. And as a side note, thanks for all the work you've done with R!! reply mushufasa 19 hours agorootparentprevA few of the main issues I see, as a R user who built his company on python - when we wanted to build a web app that processes data, it was a lot more straightforward to build both in python, so we can process data within the web servers instead of having to manage multiple stages of infrastructure and different languages. There's no Django for R. - R will often do something instead of explicitly failing. This is the wrong tradeoff when running a production system, as if you're returning the wrong results to users you may not realize it unless there's an error - R reproducible builds are worse than python. That's saying something because python is a pretty low bar. But running production systems you can't have builds suddenly fail week over week because one of a hundred packages was updated reply doodledoodahs 18 hours agorootparent> R will often do something instead of explicitly failing. I mentioned exception handling above, but this is more specifically the problem. I think it's a hard problem to solve, because the behaviour of older libraries is so varied. I have sometimes thought that something like a try catch wrapper which pattern matched or tested the value returned would be useful. reply hadley 16 hours agorootparentI have noodled on this problem a bit in https://github.com/hadley/strict, which I'm contemplating bringing back to life over the coming year. It's certainly very difficult to cover 100% of all possible problems, but I suspect we can get good coverage of the most common failure points (specifically around recycling and coercion) with a decent amount of work. reply ekianjo 18 hours agorootparentprev> one of a hundred packages was updated There's renv that addresses that point already: https://rstudio.github.io/renv/articles/renv.html > There's no Django for R. Nowadays you can integrate R with WebR (WASM) in a web app: https://docs.r-wasm.org/webr/latest/ reply hadley 16 hours agorootparentA lighterweight alternative to renv is to use Posit Public Package Manage (https://packagemanager.posit.co/) with a pinned date. That doesn't help if you're installing packages from a mix of places, but if you're only using CRAN packages it lets you get everything as of a fixed date. And of course on the web side you have shiny (https://shiny.posit.co), which now also comes in a python flavour. reply mushufasa 11 hours agorootparentshiny is nice for one-off data dashboards and single-purpose mini-apps. I see the python equivalents are like dash/plotly. Shiny is not a full fledged web framework, and isn't a viable replacement for e.g. Django. Aside -- we tried using dash in our production app and then had to remove it after a month, because these types of frameworks that spit out front-end code are almost never flexible enough to do what you actually need to do in a full app context, and you end up doing more work to fight the framework versus the time-savings from the initial prototype. reply hadley 10 hours agorootparentI'd highly encourage you to look into shiny more. No, it's not django, but it's a much richer framework than dash, and you can always bring your own HTML if what it generates for you isn't sufficient. reply fastaguy88 14 hours agorootparentprev(1) The big problem I have is transitioning from RStudio to a pipeline (so I end up not using RStudio). A traditional pipeline is going to be a script with some set of arguments -- parameter values, fitting functions, and data file names, that I put into a shell script and say: my_plot_script.R --plot_col=g_max --output_type=pub_quality data_file1 data_file2 data_file3 It's possible to use optparse/OptionParser() to get that information (but you have an option for every argument, no --param1 X --param2 Y file1 file2 file3) but it is much more difficult to fit those arguments into the RStudio environment. I want an RStudio to be able emulate reading command line arguments (since they do not exist in RStudio). Right now, I have to check to see if there are commandArgs(), and, if not, do something else to get the information to the RStudio script. (2) There needs to be an option that says STOP if something doesn't make sense. I have dozens of beautiful data plots that look great, but in fact do not in fact plot what I think they do, because factors have not been properly assigned to colors, shapes, or linetypes. (And it can be really hard to recognize that the data has not been plotted properly.) Give me an option that says, if I did not explicitly declare a column a factor, and I did not specifically associate colors/shapes/lines with factors, then the data will not be plotted. reply hadley 10 hours agorootparent(1) You might want to check out https://github.com/t-kalinowski/Rapp by my colleague Tomasz (2) I think part of that is in scope for strict (https://github.com/hadley/strict). You might also be well served by adopting some more data validation tooling, e.g. pointblank (https://rstudio.github.io/pointblank/). reply bomewish 11 hours agorootparentprevOn point two, can’t you just use stopifnot(condition)? Then log it etc? reply doodledoodahs 18 hours agorootparentprevOK, since you're here! (this all prefaced with a massive thank you for tidyverse, without which R is very crusty). I love R for interactive work and quick analyses, but I'm currently trying to integrate various bits of R code into a large document-building pipeline and wishing I could use Python for it: - Exception handling and error processing seem a pain in R. Maybe I'm doing it wrong, but if feels like a mess and not nearly as ergonomic as python. Trycatch seems to have gotchas related to scope because the error handling is in a function. The distinction between warning, stop etc seems odd. The option to stop on warnings isn't useful because older packages seem to abuse warnings as messages. I have just discovered `safely` which is helpful, but then you have to unwrap lists in pipelines which feels clunky. - Related, I _really_ wish we could just drop model objects or other tibbles as single objects directly into a tibble cell rather than as list(df). Unpacking lists and checking objects inside them exist is much more of a pain (e.g. can't just do `filter(!is.na(df_col))`) - I really miss defaultdict from python, and dictionaries generally. - Passing variable names as strings to dynamically generate things seems clunky compared with python. Again, it may be because I'm doing to wrong but I end up having to wrap things in !!sym the whole time and the nse semantics seem hard to remember (I only use R about 20% of the time). I liked cur_data() for passing a df row to a function but this now seems deprecated. - String formatting -- fstrings are just great. Glue is OK, but escaping special characters seems more tricksy. Jinjar is OK, not quite jinja. - purrr is nice, but furrr just isn't a drop-in replacement. Making http requests in parallel seems non-trivial compared to doing it with python. Is there an easy way to do it without creating multiple processes? Why can't I just do something like `. %>% mutate_parallel(response=GET(url), workers=10) %>% ...`? reply laylower 18 hours agorootparentAmen to that. Can I add the following: - 5 different ways to do wide to long and long to wide over the years even in the tidyverse. - A lot of dependencies to connect to DBs and difficult programs. Rstudio/Posit does have some premium libraries but they should be made free and bundled with the tidyverse to really promote the ecosystem. - Shiny support to save interactive charts and tables. This is a massive problem for me. If I have a heavily stylized HTML table with a bunch of css, I need to rely on webshot, webshot2 which are both alpha or beta versions and they are poorly documented. How can I evangelize R if my deployments cannot be used properly by my community? reply hadley 16 hours agorootparentWhat are the premium packages you're talking about? As far as I know all of our R packages are 100% open source. I'd love to hear more why you're using webshot etc to talk screenshots of your shiny app. A more typical workflow would be to generate a separate HTML/PDF with quarto/RMarkdown. reply laylower 15 hours agorootparentThanks for responding and your amazing work with the tidyverse. I am the \"R-guy\" in my finservices company and we have a paid rconnect dev/qa/prod and rserver pro licences for a few hundred users. The packages I think are the dependencies of some DB connectivity libraries. https://www.rstudio.com/tags/databases/ - these are the ones I was referring to. Re webshot my use case is: I have a heavily modified DT table in a shiny app. Users log in, play around with the DT table, update ggplots etc and then download the snapshot and send it to a WORD file. I can't move away from word and use html or pdf because we need the word file formatted by editors for publication and they need to follow the corpo guidelines. So, I am having to use webshot to grab a screenshot of the tagged html instead of natively handling it. I tried using officedown and a few other methods and it just didn't work. ps: I hope the rebrand goes great and I am rooting for you. reply hadley 10 hours agorootparentOh, you mean the pro drivers? Unfortunately we can't give those away because we have to pay several $100k a year just to get access for our customers. Most of the pro drivers do have equivalent open source versions that you should be able to use instead. Hmmm, I'd still try generating the table with quarto (since you can output word documents), or try gt (https://gt.rstudio.com), which I know has much greater control over output, and supports RTF output (https://gt.rstudio.com/reference/as_rtf.html) which should import cleanly into word. reply hello2hello 7 hours agorootparentprevPDF in knitr is tied to TeX. Webshot and other capture is better because CSS styles work without translation to TeX. reply nutshell42 11 hours agorootparentprev> The distinction between warning, stop etc seems odd. The option to stop on warnings isn't useful because older packages seem to abuse warnings as messages. Use suppressWarnings() to silence misbehaving functions or withCallingHandlers() to stop or handle specific conditions. > Passing variable names as strings to dynamically generate things seems clunky compared with python. Can you give me an elegant example in Python? Because I don't understand what you want to generate dynamically. That said, I dislike the tidyverse solution as well. Too much abstraction for not enough benefit over a base solution with substitute() reply hadley 10 hours agorootparentFor the most common cases, the tidyverse now only requires {{ }}. This allows you to tell tidyeval functions that you have the name of a df-var stored in an env-var. Do you have specific cases that you find frustrating? reply mslip1 15 hours agorootparentprevHey Hadley!! Personally only issues for me with integrating R is making renv play nice in multistage docker builds. I found that I need to have my other pipeline software built in the same stage as my R env setup (building specific version from archive, system dependencies, then r package dependencies via renv) reply wodenokoto 19 hours agorootparentprevIt’s been more than a few years since I worked in an R shop. While I loved wrangling and plotting data in the tidy verse I did find that the dependency management story in R to be even worse than Python. Maybe that’s the problem? reply dash2 20 hours agorootparentprevThis guy is the man to ask ^^^^^^ reply civilized 20 hours agoparentprev> We found R has a really hard time integrating into data pipelines and was best used as a standalone tool by individuals In my org we have several 100% R teams (including mine) that have been developing and maintaining business-critical, data-intensive applications for a decade now. We don't find R difficult to integrate into data pipelines. We write our data pipelines in R, and we find it very efficient to do so. They talk to databases, APIs, command line tools, etc without issue. Doing what we do in Python is unimaginable, especially if pandas is the tabular lingua franca in the team. I vehemently agree with this article on the clunkiness of pandas from a sister comment: https://www.sumsar.net/blog/pandas-feels-clunky-when-coming-.... Compared to dplyr and the tidyverse, pandas very noticeably gets in your way rather than being a tool of thought. (For what it's worth, there are other teams in my org that use Python for entirely justified reasons, and they use polars these days, not pandas.) If I had to complain about anything in R these days, it would be the increasing complexity and illegibility of error messages. Tidyverse tracebacks are often dozens or hundreds of lines. This is made much worse if you have a web app in the Shiny framework, as Shiny seems to mangle and garble what little useful information you can get (my kingdom for an error with a file name and line number). Even outside of advanced packages like Shiny, the reporting of error messages suffers from some clunkiness and irregularity. As an expert user, I can usually squint at the error barrage and infer what is really going on, but it's probably quite confusing and off-putting to newer users. Overall though, I'm not seeing any competition for R in our space. My fondest hope is that in the coming decades there arises a new, thoughtfully designed language with the Lispy flexibility of R, but also optional type safety and static analysis affordances. I'm not sure if that's even possible, but I hope the computer science geniuses figure out a way. reply hadley 16 hours agorootparentIf you have specific issues around error messages and tracebacks please feel free to let me know directly or to file issues on Github. We really do care about the legibility of errors and tracebacks and me and my team have put a lot of effort into them in the last few years. But there's always room to do better and I'd love to know where the pain points are. (The intersection of tidyverse and shiny tracbacks are a known pain point that's hard to resolve. Unfortunately shiny and tidyverse did a bunch of parallel work that took us in slightly different directions and now it's hard to re-align.) One thing we are missing is a guide to reading traceback for newer users. Often experts can get a good sense of where the problem is, but we've failed to teach newer users how to get the most value from a traceback. reply civilized 14 hours agorootparentThere's clearly been a ton of progress in this area; the only issue is that feature development is even faster :) I'll keep an eye out for specific issues that seem helpful to raise. The biggest one I have right now is a little niche, but probably useful to address. Moderately complex dbplyr pipelines on wide tables have a tendency to generate very long queries, and if there's an error, the generated SQL returned tends to overflow some text or line limit allotted to show the error at the command prompt. My workaround is to use sink() to dump the error to a file, which is a little painful as the sink() API and documentation are not the most straightforward or intuitive. (Hmm, I wonder if a withr wrapper would help me make something simpler to use...) reply hadley 10 hours agorootparentHmmmm, I think that's something we could probably help with in dbplyr by providing something like `last_sql()` that would return the most recent SQL sent to the database. (By analogy to ggplot2::last_plot() and httr2::last_request()/last_response()). I filed an issue so I don't forget about this: https://github.com/tidyverse/dbplyr/issues/1471 reply ramblenode 12 hours agorootparentprev> My fondest hope is that in the coming decades there arises a new, thoughtfully designed language with the Lispy flexibility of R, but also optional type safety and static analysis affordances. I think many of us saw Julia as the successor to R. Unfortunately, the package ecosystem---one of R's strongest points---still has a long way to go. reply civilized 11 hours agorootparentI was excited about Julia too but it now seems to be a relatively niche HPC language. It's about saving CPU time more than user time. My sniff test for a successor language to R is whether it can replicate the tidyverse API with 100% fidelity. The API is already optimal for tabular data analysis, especially the dplyr core. It can be thought of as a specification for other languages to implement. There is a great deal about how R works that is negotiable. But if the language can't implement dplyr to spec, or somehow doesn't \"want to\", it's not the language for the audience served by the tidyverse. reply civilized 8 hours agorootparentFollow-up: I did a little legwork and found some Julia folks who were also inspired to implement tidyverse as faithfully as possible: https://github.com/TidierOrg Here's how dplyr-style chains look in their system: using TidierData using RDatasets movies = dataset(\"ggplot2\", \"movies\"); @chain movies begin @mutate(Budget = Budget / 1_000_000) @filter(Budget >= mean(skipmissing(Budget))) @select(Title, Budget) @slice(1:5) end Not a character-for-character match to dplyr, but gets much closer than most other attempts! reply hadley 10 hours agorootparentprevI love this framing :) reply xapata 15 hours agorootparentprevWhy Polars and not Dask? reply medstrom 21 hours agoparentprevBasically with tidyverse, R can let you write less code and keep it readable: https://www.sumsar.net/blog/pandas-feels-clunky-when-coming-... Can't speak to abandonment, but it seems a lot of recent devel is occurring inside the the tidyverse, which is deprecating a whole bunch of other stuff. reply chollida1 21 hours agorootparentI will agree that I left just as tidyverse was coming of age and I'm sometimes jealous i never got to use it. What Hadley Wickham has done is very impressive. reply rpier001 21 hours agoparentprevR is the better EDA language by far. Python has caught up a lot. Notebook diffs are now readable in git with the right tooling, that's huge. The drum about not fitting into data pipelines... if you're literally using a bash pipe its true most R programmers have no idea how to do that. Otherwise, that is where Docker and k8s shine. On packaging. R's package authority runs tests and ensures that all packages work with the latest version of their peers. The dependency heck is much less deep as a result. We use R at my employer still because we put statistical data science into production. Our experts come to us comfortable with R. Reimplementation would be absurd. reply vharuck 18 hours agoparentprevWhy I still use R for analysis at work: - R Markdown is just great for static reports. We use PowerBI or ArcGIS for interactive stuff. - GIS is a breeze. My work provides licenses for ArcGIS, which has a Python library for scripting. Despite that, it is so much easier to do stuff in R, which can read and create ArcGIS shapefiles. - Exploratory data analysis is easy. Often, before meetings, I'll connect to the database in R and make a few basic tables. Then I can query, aggregate, or plot data sitting the meeting. I have custom ggplot themes in a package, so even my happy hastily created plots look nice. - RStudio is amazing. What it lacks in editing tricks, it more than makes up for in simplifying R-specific tasks. Showing plots is automatic, rendering and viewing markdown reports (of any type) is two buttons, testing and building a package are each two buttons. - I spent a lot of time evangelizing R (team-wide presentations, being the \"R guy\" for troubleshooting, organizing an R User Group with members from different teams, creating an internal package repository). Some became happy converts, the rest begrudgingly accepted it as a tool we would use. I don't know if I could do it again with another language. I'll admit my work doesn't get incorporated into pipelines. We get the data, analyze it, create reports, and share the reports by email or on our public website. The statisticians are segregated from the developers here. State government resists change, especially role changes that don't match grants' or laws' wording. reply ekianjo 18 hours agorootparent> R Markdown is just great for static reports. Quarto (also supporting R) is a good replacement for rmarkdown (with a saner syntax) and I say this as someone who has extensively used rmarkdown over the years. reply tropical333 19 hours agoparentprev> What we found was that R had alot of packages but most haven't been touched in years and when you contact the owner you find they've often moved onto the python/pandas/scikit eco system As a \"bilingual\" R & Python user, I've found this to be true for the latter language as well :) I don't have much to add on top of what other useRs have mentioned, except another testimonial that our company has successfully used R in production for 6+ years, from data \"pipeline\" stuff you mentioned to dozens upon dozens of predictive models of varying complexities. When faced with a new data analysis ask, 99%+ of the time I reach for R (although without the tidyverse, that number would be much lower). Like another commenter said, the ease by which you can plot in R blows Python away. Seaborn seems like a decent compromise in my limited experience, but plotting in \"base\" matplotlib makes me want to die. reply disgruntledphd2 18 hours agorootparentPlotnine is a pretty rocking ggplot clone in Python. Just import star and you're golden. reply hadley 16 hours agorootparentWe (Posit) have hired Hassan (the maintainer of plotnine) so this is great to hear :) reply disgruntledphd2 12 hours agorootparentIt definitely is! If you could hurry up and destroy Jupiter notebooks that would be sweet ;) reply usgroup 21 hours agoparentprevI think its more intuitive for statistical applications where Python is grossly under-represented. This includes things like the design and analysis of experiments but also lots of domain specific statistics and algorithms such as in bioinformatics, chemistry, and so on. Typically those applications are not the sort of line-of-business enhancements ML in Python is more tuned to. I.e. recommender systems, NN models, and so on. reply doodledoodahs 18 hours agorootparentThe consistency of model specification across multiple libraries is really helpful (base lm, lme4, brms etc). Even though the syntax is sometimes extended, it seems consistent enough to mostly be comprehensible/guessable. reply zhdc1 20 hours agoparentprevI’ve transitioned a lot of my work over to Julia, but R is still the most intuitive language I’ve used for scripting out data collection, cleaning, aggregation, and analysis cases. The ecosystem is simply better. The folks who maintain CRAN do a fantastic job. I can’t remember the last time a library incompatibility led to a show stopper. This is a weekly occurrence in Python. reply klmr 19 hours agorootparent> I can’t remember the last time a library incompatibility led to a show stopper. Oh, it’s very common unless you basically only useBut in all honesty for the pharmaceutical industry it’s mostly momentum that keeps R on top I can’t agree with this: especially in PK/PD, R is only just now taking over from the previous (closed-source) systems. Momentum would keep R out, not in. reply nutshell42 11 hours agorootparentprev> Functions like sapply vs mapply are tricky to reason about from the documentation alone. Could you please expand on that? It's unclear what you're referring to. > The values NA vs Null vs integer(0) are all used as standins for real thrown errors and knowing which one to check for after calling a function can be tough. `checkmate::assert_numeric()` (or similar) with base R you want isTRUE(): `stopifnot(isTRUE(is.finite(x)))` (or is.na or anything else) will error on empty values. reply pama 21 hours agoparentprevMy main use case is making high quality visualizations for quick data exploration and sharing with a team. It is easy to guarantee that fonts are large enough, style is minimalist and clean, and filtering, transforming views or facets iteratively is only a couple characters change. reply minimaxir 15 hours agoparentprevThere is currently no Python equivalent for both the ease of use and output quality of ggplot2 for data visualization. Many have tried over the past decade, but none have gotten close. (Plotnine was the closest: per Hadley in another comment his company hired the maintainer) reply ildjarn 21 hours agoparentprevR is much better for REPL style development and functional programming. Python could be so much better with some minor syntax extensions. reply chollida1 21 hours agorootparentI find that with vscode and the immediate window I get a decent repl. What about R's language makes it better for Repl driven development? reply pama 20 hours agorootparentIf you haven’t used Emacs ESS it may be hard to explain what you’re missing with a true REPL, but if you had used it in the past and add tidyverse to it, you basically have super smooth interactive editing with the ability to quickly pool text from other REPLs, past notes or scripts. Contrary to the similar Python repl, you can easily pull and edit chains of multiple commands via R’s piping. reply lottin 18 hours agorootparentprevFor one thing, R code can be written more concisely, due to the fact that the language is vector-based and functionally-oriented. reply clatan 11 hours agoparentprevI'm an old R user forced to mostly use python because that's what the team uses. R is so much better than python in many areas concerning data pipelines: connecting with external database systems through an unified API, superior data munging utilities, as well as plotting, a more comprehensive (obviously) statistical analysis toolset. I even find rmarkdown vastly superior to jupyter. But IMO the best reason to use R rather tha python is that its tools will make you approach the problem as a statistician rather than a programmer. reply guccigav 21 hours agoparentprevExactly what you said, R is easy to get started for individuals in social science fields. Most people I know who want to dive deeper end up learning Python anyway. reply countrymile 19 hours agorootparentThis is true, I've found teaching r to get things done is very fast and readable fully achievable in a semester compared to teaching pandas (and also having to teach how to program in python) reply omaranto 10 hours agorootparentprevAnd people wishing to delve even deeper switch back to R? I don't use it, but I understood that most advanced techniques in statistics are implemented first, and sometimes only, as R packages, no? reply trts 8 hours agorootparentprevthis is kinda funny to me. practically every social scientist I’ve known that had to use R was appalled by how cryptic and unintuitive it was. I always understood that it was its open source nature being a successor to the S language that gave it traction reply dxbydt 11 hours agoparentprev>what is your use case? if you are doing Bayesian stats, fitting hierarchical models, or using Stan in any serious capacity, R/Stan is so much more ergonomic than Pystan. Here’s a long list of pros-cons: https://discourse.mc-stan.org/t/various-observations-on-rsta... reply trts 14 hours agoparentprevtwo reasons for me 1) tidyverse makes prodding and plotting my data faster and more enjoyable. when I am prototyping a model I'll sometimes do the groundwork in R and then migrate the production version to python 2) I can't seem to write data wrangling code in py that is as aesthetically pleasing and easy to reinterpret later. could just be that I started in R, but while the methods in pandas \"work\" I don't always totally understand why they work the way they do. with tidy it works the way I expect and feels easier to read back and iterate on reply sebastianavina 16 hours agoparentprevRStudio is a nice tool for making some quick graphs on data, descriptive analyisis and quickly exploring a dataset. Building some reports, or manipulating small datasets for beautiful graphs. For anything else, we use Python. reply axpy906 15 hours agoparentprevI stopped using it in 2015, when I began to learn how to code. At my FAANG company, there are teams that use it for econometrics. I think that’s Rs sweet spot, still in 2024. reply jslakro 20 hours agoparentprevWhat python learning material you recommend focused on data science? reply downrightmike 15 hours agorootparentI like this and they have a video course on o'reilly https://www.amazon.com/Python-Programmers-Artificial-Intelli... reply winwang 13 hours agoparentprevWas there any performance difference between R and Python in your case? reply wodenokoto 19 hours agoparentprevDid you work with Rstudio Server and still found it not collaborative enough? reply richrichie 19 hours agoparentprevI quit R a while ago - before data science became a thing - and switched to Julia for such tasks. R has lots of stats packages, but it is too esoteric and specialised a language to be useful IMO. reply nojito 19 hours agoparentprev>For those of you who us R still what is your use case? Still the best replacement for EDA and reproducible analysis that used to be done in Excel. reply samstave 20 hours agoparentprevim somewhat of an armchair data scientist myself. However - I'd love to learn your ways; specifically - what are your best recommendations for python over R? Specifically, even though my R skills are weak - I think that RStudio is pretty darn amazing - what do you recommend over Rstudio? I'd truly like to hear what a good toolbox looks like from your perspective these days (especially now this little GPT toddler is bonking into everything in my domain) reply ekianjo 20 hours agoparentprevtidymodels is miles ahead the toys you have in python for traditional machine learning. of course Python is much better in other areas but that is a big reason to use R, together with the super powerful tidyverse syntax. and package management is much, much more reliable in R than in python. reply disgruntledphd2 18 hours agorootparentIs tidy models better than sklearn? As honestly sklearn is one of the few things I was jealous of from the python ecosystem, historically. reply SoftTalker 16 hours agoprevI took a two or three day on-site intro to R class that my employer put together. Perhaps it was not a great class, but as a seasoned software developer familiar with a number of imperative and functional languages I was baffled by R. It felt like a bunch of little functions that had been developed by different people with no consistent framework, and thrown together in some kind of big wrapper. I know it's popular among statisticians and researchers, so I think a prerequsite must be a good fluency with statistics (I don't have that). Maybe it makes more sense if you think like a statistician. As a programmer I felt like nothing I learned about R contributed to developing an intuitive understanding of any of the rest of it. reply hadley 15 hours agoparentR definitely has its warts, but I strongly believe that underneath them lies a beautiful and quite elegant language that's extremely well suited to the challenges of data analysis. If you're already a programmer, you might find something like Advanced R (https://adv-r.hadley.nz) to be useful to get a sense of what R really is as a programming language. reply pinewurst 16 hours agoparentprevI think of R as a programming language designed by people who’d heard about programming languages but never actually used one before. It’s great for ad-hoc analysis without having to think about production systems. reply mint2 15 hours agoparentprevI get a similar impression but to contextualize, in terms of statistical programming what you’re saying is even more so true of what came before R, but a thousand fold worse. In that context R is fantastic. For example SAS makes R look beautiful and consistent. And that’s more a comment on SAS than R. And this isn’t to say python is perfect either, but I prefer it. reply AlbertCory 16 hours agoprevIn Google \"data science\" circa 2009 (although we didn't call it that), R was the weapon of choice. I consider it a bad relic of the 70's. It doesn't have a \"learning curve\" -- it has a \"learning straight line.\" Even when you're experienced and semi-competent at it, it's still difficult and surprising. reply haunter 15 hours agoprevCS50 will be also available with R starting this summer https://www.edx.org/learn/r-programming/harvard-university-c... reply benreesman 18 hours agoprevI'm looking at R seriously for the first time. I've got a decade in with Python numeric computing, and I'm interested in Julia and all of the cutting-edge stuff. I've only dabbled with R until now, and I haven't researched it enough to know if rumors of it's inevitable demise have any substance. There are a lot of interesting math problems other than training gigantic neural networks on NVIDIA gear, and I've got some Computer Algebra System / ergonomic linear modeling needs on a current project: I need the best tool for someone who is messing with Black-Scholes type stuff, who is still building the fidelity with tricky antiderivatives by hand, but I have enough fundamentals to check the computer's work. What role should R play here? reply laylower 18 hours agoparentI love R. You could do it R. But a lot of the derivations and Math Finance stuff you can and should be able to do in C/C++. R packages mostly depend on those as well for heavy duty calcs. So, if I wanted to dabble I'd easily use R and if I was in the quant developer world I'd be doing C/C++ reply helsinki 18 hours agorootparentI work with a trading team that manages $1B, exclusively with R. reply mamonster 18 hours agorootparentSecond this, seen lots of funds use whatever language their lead QR/QT feels comfortable with. At the end of the day, if you aren't running a strategy that requires colocation on the exchange, whatever speed improvement you get from the language will usually disappear from the network latency. Something like intraday momentum/sector rotations can easily be done entirely in Python/R, from what I've seen. reply benreesman 13 hours agorootparentLikewise interested if a pro has any consulting hours to spare :) reply mamonster 12 hours agorootparentSorry, unfortunately do not do consulting. In your other comment, you said you are looking to price \"weird derivatives\". How weird are we talking? If its OTC I won't be able to help anyway, if its standard then I can at least try to point you in the right direction. The fact you mention Black Scholes makes me think it might be something closer to \"vanilla\" than the other way around. reply benreesman 59 minutes agorootparentIt’s looking like the goal will be to create downward pressure on derivative beta (especially in the case of a rapidly increasing underlying: big pools of Hopper cards basically). I have a vague intuition that transaction costs will be sort of cumulatively symmetric: participants who get in quickly will pay a lot per unit time, but conversely, people who VWAP in will get zero-rated on the way out. There’s a legitimate underlying switching cost, there’s a stability premium thereby, making that equitable for all participants is an interesting problem. reply benreesman 13 hours agorootparentprevI have to price some weird derivatives. You do any consulting on non-adjacent areas. reply iainctduncan 18 hours agorootparentprevI've done some work for scientists where they used C++ extensions to R for heavy number crunching. For their workflow, R is really nice. Don't know how common this is though. reply nequo 15 hours agorootparentRcpp is pretty common in major performance sensitive packages. The CppCast did an interview with Dirk Eddelbuettel about it in 2022: https://cppcast.com/rcpp/ reply dxbydt 11 hours agoparentprevquite easy to price derivatives with R. I have a degree in finmath from uchicago, where derivative pricing was taught using Matlab and R. But in the last semester we were told - oh yeah when you go out there into the real world and start working for the banks you can’t use civilized tools like R and Matlab. So you have to take this mandatory class on cpp. There once was a guy named stroustrup and this shit here is called a makefile… after graduation i worked for BofA and yes, the quant world is completely C++. But there are small funds (few billion dollars) that do their own shit in R, Haskell, Q/kdb, others. Very doable in R. reply tagyro 18 hours agoprevI love the power of R, especially when used for \"stupid\" stuff [^0] + extra points for using quarto [0]: https://gist.github.com/mine-cetinkaya-rundel/03d7516dea1e5f... reply tea-coffee 14 hours agoprevWhat makes this book different from R for Data Science by Hadley Wickham, Mine Çetinkaya-Rundel, & Garrett Grolemund? reply clircle 20 hours agoprevUnfortunately there are 56 other data science with R books, so what is the differentiating factor here? reply countrymile 19 hours agoparentIt's the Harvardx course reply yaomingite 13 hours agoprevThat's a comprehensive guide. If anyone wants a similar introduction, with interactive exercises to try while they study this is also a good resource: https://www.codecademy.com/learn/learn-r reply SomeoneFromCA 17 hours agoprevIn my case, I found R a better tool for learning DS, as it is more or less, a DSL for statistics, and feels more low level and fores you to learn more fundamentals than python. For production it is probably worse tan python, true. reply Cosi1125 14 hours agoparentIt's not a DSL. reply SomeoneFromCA 13 hours agorootparentIt is de facto. reply Cosi1125 13 hours agorootparentWhy do you think that? (I'm legitimately curious.) reply nequo 4 hours agorootparentNot parent and I also consider R to be a surprisingly solid general purpose PL but the one reason that I can think of is that formulas are part of the language. Formulas are extremely well-suited for data analysis but odd outside of that. reply Cosi1125 1 hour agorootparentGood point. I'd add complex numbers and \"everything is a vector\" to that. Of course that doesn't make it a DSL. It simply means that R was designed with a particular application in mind. So was Perl (regular expressions as first-class citizens) or Javascript (DOM manipulation). Not to mention PHP. reply nequo 15 minutes agorootparentThat is true. Also Erlang with the actor model, and Go with its goroutines for network services. reply uptownfunk 17 hours agoprevNo better tool for EDA and data analysis than R and RStudio. Fell in love in stat 133 at Cal and now while I am doing software engineering I have very fond memories of writing R and tidyverse reply AndyMcConachie 18 hours agoprevI dipped my feet into R a few years back, but eventually stopped it because of the way it handles integers. At the time it treated all integers internally as signed 32-bit and if the number is too large for that it converted it to a float. I don't know what R does now, but this was a deal breaker for me at the time because I was dealing with really large integers that regularly broke this limit. reply armchairhacker 14 hours agoparentIntegers are still only 32 bits. There’s a class which effectively represents 64-bit integers (https://www.rdocumentation.org/packages/csvread/versions/1.2...) as well as arbitrary-sized (https://cran.r-project.org/web/packages/gmp/index.html, https://www.rdocumentation.org/packages/gmp/versions/0.7-4/t...). I will say there are a few pitfalls where the integer bits are unexpectedly converted to something else, but it’s workable. reply nutshell42 12 hours agoparentprevFinally a real reason. A lot of the stuff above was complaining about issues where Python is a lot worse than R, about non-issues or with a fundamental misunderstanding of the language. I'd given up hope of seeing a real weakness named as such :) There is bit64 and doubles being used as 53bit pseudo-integers - but if I needed 64bit integers, R wouldn't be my first choice, definitely. reply 29athrowaway 12 hours agoprevR is the PHP of data science. It is productive, it has a large ecosystem, lots of functionality, but it grew fast and organically and not in well planned manner, making it not consistent and a bit messy to work with. If you have to use R, use the tidyverse. https://www.tidyverse.org/ I like R and use it often as it find it more concise to work with than Python for simple statistical purposes. I forced myself to use R instead of spreadsheets and don't regret it. This is one the reasons why (thanks, Zed Shaw) https://web.archive.org/web/20110702162929/https://zedshaw.c... reply asicsp 22 hours agoprev [–] See also: \"R Programming for Data Science\" https://leanpub.com/rprogramming reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Introduction to Data Science originated as class notes for the HarvardX Data Science Series, now available on GitHub under a Creative Commons license.",
      "The book acknowledges the developers of R and other packages, contributors, teaching assistants, and support from NIH grant R25GM114818.",
      "Appreciation is expressed to all who contributed through GitHub pull requests or suggestions, with provided links to the book, updates, and additional resources."
    ],
    "commentSummary": [
      "A Reddit thread compares R and Python in data science, emphasizing R's strengths in quick data exploration and statistical analysis.",
      "Discussions include challenges in error handling, reproducible builds, and package management, with suggestions for improvements and premium packages.",
      "The potential of Julia as a successor to R is considered, praising R's advantages in exploratory data analysis (EDA) and statistical data science, raising debates over its effectiveness in data visualization, financial modeling, scientific research, and machine learning when compared to Python."
    ],
    "points": 180,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1709373781
  },
  {
    "id": 39577878,
    "title": "CS 6120: Advanced Compilers - Lesson 1 Overview",
    "originLink": "https://www.cs.cornell.edu/courses/cs6120/2023fa/self-guided/",
    "originBody": "Lesson 1: Welcome & Overview video",
    "commentLink": "https://news.ycombinator.com/item?id=39577878",
    "commentBody": "CS 6120: Advanced Compilers: The Self-Guided Online Course (cornell.edu)177 points by swatson741 7 hours agohidepastfavorite10 comments dunefox 3 minutes ago> CS 6120 is a PhD-level Cornell CS course by Adrian Sampson on programming language implementation. So, is it very advanced then? I don't think I'm at PhD level when it comes to CS. reply pjmlp 1 hour agoprevGreat to see that also have \"A Unified Theory of Garbage Collection\", at least these students will get the right picture on RC versus tracing GC. reply simonebrunozzi 1 hour agoprevCompilers is one of these field that didn't evolve much for ~30 years. I used to teach a course at Perugia University back in 2004-2006, and the material I could use was easily 15-20-25 years old, no sweat. Things seem to have changed recently. reply pfdietz 27 minutes agoparentThere's been a substantial change in compiler testing since then, with high volume randomized testing coming into vogue. reply grumpyprole 1 hour agoparentprevProbably because most programming languages haven't changed, imperative, loops, pervasive side-effects etc. Writing a compiler for a pure functional language would certainly need new material. reply dunefox 4 minutes agorootparent> Writing a compiler for a pure functional language would certainly need new material. I mean, Haskell is also over 30 years old at this point. reply riedel 1 hour agoprevI looks like this is still basically most of the stuff covered by the normal compiler construction course I attended held by Gerhard Goos 20 years ago. It links some newer papers, so I might have a look. I liked the book by Steven Muchnick 'Advanced Compiler Design and Implementation' . I have to admit that after 18 years not having looked at compiler source code, I feel not up to speed particularly with a lot of profiling and path based optimisations. Also I guess some more advanced SIMD stuff must be out there looking at all the ML. reply Delta231 54 minutes agoprevI wonder if there's a predecessor course to this reply ayhanfuat 51 minutes agoparentI am following Stanford's Compilers course and I like it: https://www.edx.org/learn/computer-science/stanford-universi... reply tripdout 2 hours agoprev [–] I favorited this last year and still didn't get around to it. But from what I saw of one of the videos, it looks really good, super interesting stuff. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "CS 6120 is a PhD-level online course by Cornell University on advanced compilers taught by Adrian Sampson, covering programming language implementation, garbage collection, compiler testing, and design.",
      "Participants engage in discussions on the evolution of the field, the necessity for fresh content for functional languages, and how newer technologies like SIMD influence compiler development."
    ],
    "points": 177,
    "commentCount": 10,
    "retryCount": 0,
    "time": 1709432728
  },
  {
    "id": 39574397,
    "title": "Minimal Phone Embraces Simplicity with E Ink Display & QWERTY Keyboard",
    "originLink": "https://newatlas.com/mobile-technology/minimal-phone-eink-keyboard/",
    "originBody": "Mobile Technology Minimal phone gets back to basics with E Ink display and real keyboard By Paul Ridden January 25, 2024 Facebook Twitter Flipboard LinkedIn Minimal phone gets back to basics with E Ink display and real keyboard A startup is aiming to free us from smartphone distractions with a minimalist handset rocking an E Ink screen and physical QWERTY keyboard The Minimal Company View 3 Images 1/3 A startup is aiming to free us from smartphone distractions with a minimalist handset rocking an E Ink screen and physical QWERTY keyboard The Minimal Company 2/3 The Minimal phone is expected to measure 120 x 72 x 10 mm, and will come with select third-party apps that are \"essential for modern living\" The Minimal Company 3/3 An attractive union of e-reader and Android phone with Blackberry-like text input The Minimal Company View gallery - 3 images We've seen a number of handsets over the years that have been designed to cut down on over-stimulating distractions present on smartphones. The latest looks like a happy marriage between a Blackberry and e-reader, and goes by the name of Minimal. Only very basic information has been shared on the startup's website so far, but founder and CEO of the Minimal Company Andre Youkhma recently took to Reddit to answer key queries. The Minimal phone is going to be constructed using eco-friendly materials, though no specifics have been revealed as yet. It will boast a backlit monochrome E Ink display topped with a capacitive touchscreen, which will doubtless make it a per-charge warrior as well as being eye-friendly. In fact, the 4,000-mAh battery is reckoned good for four days of usage and there's support for rapid charging. Under this sits a full QWERTY keyboard for a \"more satisfying and accurate typing experience.\" An attractive union of e-reader and Android phone with Blackberry-like text input The Minimal Company It's being designed to run on an operating platform called the MnmlOS, which is based on \"the latest version of Android\" and should allow access to the Play Store for downloading third-party apps. However, the point of the phone is to keep distractions to a minimum, so out of the box it will be able to call, text and email and will host a bunch of \"select third-party apps essential for modern living, such as ride-sharing or navigation apps, without overwhelming the user.\" Things like calendar, notes and other productivity tools will be included too. Entertainment will be kept simple as well, \"focusing on relaxation and mindfulness.\" The handset will feature Wi-Fi and Bluetooth, with 5G currently being explored, and be able to play music from YouTube (though E Ink refresh rates likely won't make video watching anything but frustrating) and from local storage via a headphone jack. There's expected to be support for Android Auto too, and contactless payments are in the works. A camera is being cooked in as well, though we'll have to wait for details. The Minimal phone is expected to measure 120 x 72 x 10 mm, and will come with select third-party apps that are \"essential for modern living\" The Minimal Company On the privacy front, the startup's founder states that user data will only be collected for phone functionality, not for advertising purposes. He also promises frequent security updates, with support for the phone promised for at least five years (which presumably will include OS upgrades). As of writing, all we have to look at are rather nice renders. Youkhma has confirmed that the design has been finalized, that it will come in at 120 x 72 x 10 mm (4.7 x 2.8 x 0.39 in), and that an unnamed \"leading manufacturer\" is currently looking into creating molds and such. Like many project's before it, the Minimal phone will be making a production bid on a crowdfunding platform that's due to kick off from early February. The expected retail price is currently pitched in the region of US$400, but discounts will be offered to tempt in early adopters. For now, those interesting in learning more can sign up to the waitlist via the source link. The video below has more. The Minimal Phone - Live More, Scroll Less. Source: The Minimal Company View gallery - 3 images",
    "commentLink": "https://news.ycombinator.com/item?id=39574397",
    "commentBody": "Minimal phone gets back to basics with E Ink display and real keyboard (newatlas.com)149 points by airhangerf15 15 hours agohidepastfavorite126 comments seam_carver 12 hours agoI recorded a video of another e ink phone running many common Android apps really well (in direct sunlight)! https://www.youtube.com/watch?v=dvO9ScTdwz8 It's the Hisense A9 with a beautiful and fast Carta 1200 e ink display. It's very capable, I would have preferred a phone more like that instead. It's biggest drawback is terrible USA cell reception. This company was initially going to make a phone like this but apparently keyboards were much more popular in polls. reply pcchristie 8 hours agoparentThanks for this. I've been thinking about pulling my phone use right back. I was really wanting to use the Light Phone, as I like how small and minimal it is. The only problem is it doesn't run Telegram/Whatsapp which is kind of essential these days. This phone looks like it would be exactly what I'm after. How do you rate it overall? Ideally I'd like something half way in between this and the Light Phone - small, stripped back phone that's less appealing to use (i.e e-ink with its grayscale and slow refresh rate introduce enough friction so it's not worth being on infinite scrolling apps), but still backed by an ecosystem like Android so that you can still access \"essential\" apps like Telegram/Whatsapp and Notion/PocketCasts and don't have to fully give up all the helpful progress we've made since 2005. I saw your other comment about the camera - it would also be nice to have high-end camera built in for taking photos and videos, even if I essentially can't look at them on the phone I'd still be happy to capture and sync them for use elsewhere. It's a fine balance. I'm hoping enough people start looking for this over the next few years to make the market worth targeting for manufacturers, but I'm not confident. reply seam_carver 7 hours agorootparentI absolutely love it compared to my current iPhone. Super comfortable eink display that looks like paper. Messenger works great with a monochrome theme. And great battery too since screen doesn't emit light. Love using it for reading, especially right before bed. If you want to learn more check out the r/eink subreddit. Good call, when I upload my camera test video I'll include a small section of viewing the photos taken as well on the eink screen. But for still photos it will look pretty similar to how b&w mode looks like on normal phones. reply MBCook 11 hours agoparentprevUnfortunately this confirms my fear. I think I’d want to throw an e-ink phone against a wall after a while from frustration with the lag. E-ink screen refreshes are just far too slow for something interactive. That’s one of the reasons they work great on e-readers. I wondered if they were doing something special or had a different kind of e-ink screen that was faster in trade for some other property but at least the one in your video doesn’t. reply seam_carver 10 hours agorootparentOut of curiosity which part of the video makes you think the lag is unacceptable? It’s more like a low refresh rate. Sure scrolling is a bit slow so it’s much better to fixed length “page turn” with the volume buttons instead but I’ve really gotten used to it. If you are talking about me missing the tap zones on the touchscreen to scroll that’s user error :P reply MBCook 8 hours agorootparentThat’s what I mean. The lag between my action and the updated screen. Caused by the low refresh rate. When you’re trying to tap the screen a bunch to get something accomplished if each step takes 250+ms extra just waiting on the screen it would add up to frustration fast. reply dotancohen 10 hours agoparentprevHow is the camera? I don't really care how the photos look on the device, but I would be sending them to family via Telegram and of course later on the desktop. I do have other E-Ink devices (Boox, Nook) and I love them, so I'd love to get an E-Ink phone. But I don't want to carry a separate camera. reply seam_carver 10 hours agorootparentIt’s not a great camera. Worse than my iPhone 8. Maybe somewhere around my iPhone 4 or 5S quality. So it's usable. I can upload a video later. reply dotancohen 6 hours agorootparentYes, I would love to see, thank you. GSMArena does not have the phone. reply fortytw2 7 hours agoparentprevI have a Hisense HiReader Pro and it's awesome + super usable for actual day to day phone things on wifi, but the cell reception overlaps with a single LTE band in the US that's not really usable around where I live. reply bookstore-romeo 13 hours agoprevI'm the owner of a Light Phone II [0] and (other than battery life), the biggest downside to the Light Phone I can envision for most people is the absence of apps like Uber, Apple Pay and Spotify. I think 5G isn't that necessary on a phone like that, except maybe for future-proofing. This phone seems to have a camera, though, and access to Play Store (although it will likely be messy) really sets it apart from most \"minimal\" phones out there. Plus, a real keyboard might attract the people who despise the on-screen one on the Light Phone. They're really devices of different classes at this point, though. The price does seem awkwardly low, however. [0]: https://www.thelightphone.com/ reply hn_throwaway_99 9 hours agoparent> the biggest downside to the Light Phone I can envision for most people is the absence of apps like Uber, Apple Pay and Spotify. You've hit it spot on. I got a light phone years ago to help cure my cell phone addiction, but it was too problematic. I still need to use the \"tools\" of my phone - things like Maps, Uber, authenticator apps, texting, etc., but I just wanted to block the \"dopamine dealers\" like social media and the browser. The best I've gotten to so far is to permanently enable \"focus mode\" on my phone. Of course I can still disable it, but I've noticed the number of times I just automatically start browsing the web or whatever when I'm even just a tad bored, and having those apps blocked is at least just a reminder to me of \"Do you really want to do this right now?\" reply pcchristie 8 hours agorootparentI'm with you. As I mentioned elsewhere, I'd have a Light Phone if it could use Telegram and a few other \"essentials.\" Throw in a good camera and it'd be incredible. At the moment I use greyscale mode on my Pixel and have uninstalled apps, only using them in the browser if I \"need to.\" It's not much, but adding that small friction helps somewhat. reply skydhash 7 hours agorootparentSome more friction, use a password manager and change the password to a really long string of characters, then don't install the password manager on the phone. reply toast0 12 hours agoparentprev> I think 5G isn't that necessary on a phone like that, except maybe for future-proofing. 5G is more than future proofing, at least where I am, 5G is deployed at new lower frequencies (taken from broadcast TV) that provide for more full coverage. With my new 5g phone, I have less dead zones than my old 4g phone. reply al_borland 7 hours agorootparentI've had 5G turned off on my phone since I got it. There is a dead spot near my house that really annoys me any time I go anywhere. You're making me thinking I should try turning 5G on to see if it helps... but I really don't want to take the hit to my battery. reply toast0 4 hours agorootparentIt's probably worth trying. I gather 5g on early phones is rough on batteries, but my phone is a 2023 and battery life seems fine with 5g on. (old phone was 2020 moto g power, new phone 2023 moto g stylus 5g). If 4g only makes your phone get stuck searching for signal and 5g would find a signal, turning on 5g will help reply fragmede 12 hours agorootparentprevThat is to say, you live in the future. I have the same experience with my phone. 5G is already here. reply simfree 8 hours agorootparent5G New Radio (5G-SA) at 600Mhz (band 71) can deliver useful signal about 20% further than LTE on 700Mhz (bands 12, 13, 14 & 17). We have seen this in action as many Cellspot and other signal booster users have retired these devices as the indoor and basement cell coverage improvements of 5G deliver better service than the DSL or satellite back hauled micro cells these users used to have at home. reply qgin 13 hours agoprevThese types of phones keep getting made and people keep not buying them in any significant numbers. I think people want to want this kind of phone. But it ends up being a kind of performance art thing / statement about modern society thing more than filling an actual demand in the market. reply PopePompus 10 hours agoparentI've signed up and sent contributions to a few \"let's build a phone!\" projects (like, for example, the neo900). I've come to the conclusion that building a phone is just not something a small group of people can do on a small budget. They won't get access to good processors, etc, because their projected volumes are too small to interest suppliers. The project inevitably ends up being very, very late. They can't build many prototypes and test them extensively, so if something actually gets shipped, it will be buggy. reply ummonk 12 hours agoparentprevThis seems more practical though, providing access to the full play store rather than crippling user functionality. reply MBCook 7 hours agoparentprevWhile I don’t disagree with you, I think you have to be heavily plugged into tech news to even know they exist in the first place. I’d guess 99.9% of people have no idea such things exist even if they did want one. reply btbuildem 11 hours agoparentprevMaybe price is a factor? If this thing cost $100 you'd see mass adoption. reply ianburrell 11 hours agorootparentMy guess is that the people who want minimal phones buy feature phones. They are less of investment for lifestyle change, can be used as secondary phones, and have nostalgia. I bet this phone would be more popular if it looked more like Blackberry. reply wkat4242 6 hours agorootparentAnd they're thin and light, have week long battery life, don't need a case and can often flip to avoid pocket dialing. reply MBCook 7 hours agorootparentprevI’d guess effectively no one knows they exist in the first place. reply jerlam 13 hours agoprevHere's the crowdfunding page with more pictures (renders?) and details: https://www.indiegogo.com/projects/the-minimal-phone-first-e... Their estimated shipping date is August 2024, which seems wildly optimistic. reply garyfirestorm 11 hours agoparentlol more like August 2026 reply bengale 11 hours agoprevYou can do a lot of this on an iPhone if you use focus modes and automations. I have a deep work mode that sets a blank Home Screen, turns off always on display, sets the phone to greyscale and only allows notifications from my wife. It feels like something like this gets you most of the way there and you can then have different focus levels that ramp up potential distractions. All without carrying two devices or giving up the modcons. reply dotancohen 10 hours agoparentI've been experimenting with greyscale on my Android phone, it is nowhere near the comfort level of real E-Ink. reply lostmsu 6 hours agorootparentHow did you do that? reply btbuildem 11 hours agoparentprevCould you share how you set that up? Sounds effective. reply romeoblade 10 hours agorootparentFor me I use the accessibility shortcut, three presses of the side button pops up a menu so I can select color filters (grey scale) and reduce white point (80% is my default). I enable both when I am reading. It's really helped eye strain when I'm reading. reply bengale 11 hours agorootparentprevMost of it is just in focus modes settings: alerts, notifications and things like that. For greyscale you use shortcuts. There’s an automation tab, you set up on a focus mode being enabled then “set color filters on” and then the opposite for that focus mode being disabled. reply pentaphobe 11 hours agoparentprevThis sounds pretty great, how do you achieve it? reply paulmd 11 hours agorootparentShortcuts, presumably reply MBCook 11 hours agorootparentNope. All features of focus modes alone, I think. reply bengale 11 hours agorootparentJust the greyscale needs a shortcut automation. reply MBCook 7 hours agorootparentOh I didn’t catch that part. It makes sense that wouldn’t be available by default as a focus option. reply d--b 12 hours agoprevNow that phones have turned into authentication devices for a lot of mainstream services, we’re screwed. reply noah91734 12 hours agoprev> Can I use apps on Minimal? > Yes, Minimal runs on Android, allowing you to download and use essential apps. However, the e-ink display and device optimization are geared towards minimizing unnecessary distractions. That answers the only question I had about this. You still get full access to every app you need, it just increases the friction (via the low refresh rate and the lack of colors) so you can't doomscroll. Unfortunately, it does not list Bluetooth among its many wireless features, so I don't think I'd be able to use it. Not having music or podcasts in the car or on a run is a dealbreaker. reply windowsrookie 9 hours agoparentIsn't bluetooth bundled with every wifi chip / mobile soc these days? reply MBCook 7 hours agorootparentI thought so too. reply xrd 11 hours agoparentprevThe article mentioned Android Auto. I assume it must have Bluetooth. reply DANmode 10 hours agorootparentAndroid Auto and Apple CarPlay both have wired functionality. reply barbs 10 hours agoparentprev> Entertainment will be kept simple as well, \"focusing on relaxation and mindfulness.\" The handset will feature Wi-Fi and Bluetooth, with 5G currently being explored, reply nonethewiser 13 hours agoprevI appreciate these basic phones but what I need is something different. I would prefer 2 phones: a regular smartphone and a basic feature phone. Then I’d take the one I need when I leave the house. The problem is you either need two lines with your carrier or swap physical sims. Swapping physical sims is inconvenient and means you cant use an esim. reply mrbombastic 13 hours agoparentNot exactly what you want but how about this setup: keep your minimal phone as your default phone with cell service. Whenever you head out use that. Your second distracting regular smartphone has no cell service. If you want to use that one either use wifi or bring both along and tether to your minimal phone. reply SoftTalker 12 hours agorootparentThe reality is that most people do not want to carry multiple devices around. Carrying some kind of minimalist phone for text and voice, and a tablet or other device for \"apps\" isn't really a great experience. reply daxfohl 10 hours agorootparentYeah, or charge every night, or look for when you're in a hurry to get out the door, etc. Or buy, for that matter. Probably what I'd rather have is a phone that has a low power low function mode, that I can configure what apps are available, and then a regular mode where everything is available. But to get to it, I need to convince a LLM equivalent of Seinfeld's soup nazi why I need it. reply SoftTalker 10 hours agorootparentYeah a phone with an easy toggle between \"dumb\" and \"smart\" would be handy, especially if \"dumb\" mode had greatly increased battery life, but I don't think it would appeal to enough people to motivate making one. reply daxfohl 8 hours agorootparentI mean, it could just be built into android, or maybe even an app with enough permissions. But agreed, even at that minimal level of friction, I'd probably turn it off most of the time, and deal with it via old fashioned self control. And for the times I'm out of control, just turn the phone off. reply filleduchaos 8 hours agorootparent> I mean, it could just be built into android Isn't this literally already built into Android? Extreme Battery Saver effectively turns your phone into a feature phone, disabling every app except Clock, Phone, Messages, Settings, the Play Store, and your camera. And you can add other essential apps to the whitelist (e.g. I have my note taking, ride sharing, banking/wallet, calendar and TOTP apps enabled, and my music player if I'm on the go). It even degrades the phone's performance to match lol, and the added battery life you get from it is fantastic. Might be a Pixel-only thing now that I think of it...then again I'm pretty sure other OEMs like Samsung would have their own versions reply johnchristopher 12 hours agorootparentprevI was under the impression most minimal phones don't have wifi hotspot feature/capability ? reply rjsw 9 hours agorootparentSome KaiOS ones do. I got a Nokia 6300 4G a week ago, not tested the hotspot functionality yet but am happy with the other features of it. reply jcul 11 hours agoparentprevThis is what I do. I have a agm m8 flip that I have at all times for calls and text. And I have a pixel running grapheneos that I use more like a laptop / when needed. Living without a smartphone isn't possible. But not using one for two or three days is. Most banking apps require a smartphone. If I'm out an about I will generally not have a smart phone unless I'm making an unfamiliar journey or something like that. I've got through quite a few dumbphones, including the nokie 8110 (banana phone, but rooted with app store removed), Nokia 2660, cat s22 flip, agm m6 But all were sub par in some way. The m8 is the first that has ticked all the boxes for me. I love it. reply dredmorbius 7 hours agoparentprevOne option that tends toward this is to have a cellular modem which tethers to the device of your choice. SIM is assigned to that device. Voice comms go over a VOIP service such as Jitsi or whatevs. Carry the VOIP device you want to use, whether a minimal comms-only device, or a more capable tablet or laptop which you can talk to. A device which talks to a headset or transport-based option (e.g., your car's Bluetooth system) might also be convenient. The idea that you need a full-compute device with a high-res screen just to make voice calls is ... somewhat silly. The main concern I have with this is the level of phone spam either now present or in the likely future. You'll want a comms system which filters out unknown and/or suspect calls. PSTN, of any stripe (POTS, mobile, VOIP) isn't cutting it any more. reply pcchristie 8 hours agoparentprevI've always thought this was a good solution too. I'm not sure how difficult it is to have a cloned eSIM and have your carrier call/msg both devices at once for a small extra fee? reply MBCook 7 hours agoparentprevCellular watch + earbuds would do that for the basic phone part, and it shares the number with your full smartphone. reply fragmede 11 hours agoparentprevUse a service like Google voice to multiplex across phone numbers. Configure it so hitting the Google voice number hits both of your devices, so it rings whichever you have with you at the time. reply volemo 11 hours agoparentprevI suggest taking a look at https://palm.com/pages/product. reply prmoustache 11 hours agoparentprevyou can have 2 sims with same carrier afaik (but you have to pay for it). reply Difwif 12 hours agoprevUgh another minimal phone that tries to sell me new hardware. I don't think there's anything wrong with current smartphone hardware. What I want is someone to reimagine the OS. My phone should be like a Startrek Tricorder - a very advanced tool that can assist me with anything. The key metric should be how much time it saves me... not how much time I waste using it. What I don't want is spyware, ads, and interactions designed to maximize my engagement. I need to be able to use feature rich apps sometimes, but I also want very hard limits that I set on my social media usage and other time wasting activities. Every single blocker app completely sucks and needs to be implemented as an OS feature. Screen time on iOS isn't enough and Digital Wellbeing on Android is a joke. Sometimes I don't have the willpower to overcome the digital crack at my finger tips. So bad I want a new OS to enter the market that reimagines my phone as just a tool and not the center of my life. Apple could do it and has the right incentives (kinda) but I don't understand why they don't make screen time more feature rich with an API. I've never owned an iPhone but I would finally switch if they did this. Edit: I'm being too harsh to the creators of this phone. Clearly I am not the customer. I just want a solution that doesn't involve giving up useful tools like Maps. reply nullderef 12 hours agoparentI actually really like that the hardware includes an E-ink screen instead. It makes it really interesting for reading on the go without needing an additional device. reply weikju 7 hours agoparentprevProblem is, most people so want that also don’t want to pay for it, let alone pay more for hardware or software than they do for the spystuff. So the vicious cycle continues reply jen729w 12 hours agoparentprev> What I don't want is spyware, ads, and interactions designed to maximize my engagement. Turn off notifications. > Every single blocker app completely sucks Install 1Blocker (indie dev) and turn on the on-device firewall. Works like magic. > Screen time on iOS isn't enough Have more self control. ;-) > Sometimes I don't have the willpower to overcome the digital crack But seriously, use Screen Time to disable Safari. Just remove the web browser from your device. Make the Screen Time password something like “i am weak”. It works. > I've never owned an iPhone You can 100% get what you want with an iPhone. Just don’t install all the garbage, and if an app is useful but spams you (hi, Uber), turn off its notifications. Use 1Blocker and you’ll never see an ad, not even in-app. Or do what my partner does: she basically lives in DND mode. Her phone hygiene is exceptional. She scarcely uses it. I never see her using it during the day. reply MBCook 7 hours agorootparent>> Screen time on iOS isn't enough > Have more self control. ;-) Focus modes are more powerful and customizable, sounds like what GP wants to me. Change wallpapers, notification preferences, show/hide apps, all sorts of stuff. reply barrysteve 9 hours agoparentprevYou have no idea how much it pleases people in charge to have complete surveillance. It's pathetic. reply btbuildem 11 hours agoprevIsn't the form factor a little odd, or is that just me? How would you even hold that? Make something with a wide enough screen (say, 2.5\" wide) and a height that maps to a common aspect ratio (maybe 4\"?), let it have some bulk (like... 1\" thick?) and suddenly you have a distinctive object that has enough space for all the electronics + a decent battery. reply ipv6ipv4 12 hours agoprevThe best minimal phone is a cellular smart watch. reply dorchadas 12 hours agoparentI'm leaning more and more towards this myself, except for the fact I hate the look of most of them, and love my traditional watches. Maybe I could just keep it in my pocket. But it's ideal for what I want - GPS, WhatsApp, telegram, Spotify. reply fragmede 11 hours agorootparentYeah. Something like https://a.co/d/a7wV4U7 instead of wearing it on your wrist. reply mckn1ght 11 hours agorootparentprevI’m waiting for the day I can have an Apple Watch without ever needing an iPhone to manage it, and an iPad to do real dev work (ie, Xcode for iPad) without ever having to fall back on a Mac/Book. I’ve been waiting for years already so now I’m not sure those days will ever actually arrive. reply fragmede 11 hours agorootparentDepends on your particular flavor of 'real' dev. https://vscode.dev/ and an SSH app and a web browser. reply mckn1ght 11 hours agorootparentMy bar is being able to execute a compiled binary produced with clang/gcc. reply MBCook 7 hours agorootparentLocally? Despite how powerful an iPad is I have no expectation you’re going to be able to do it anytime soon. reply dredmorbius 6 hours agorootparentprevTermux + Android gets you here. reply mschuster91 11 hours agoparentprevNow if these could operate in stand-alone mode... but both Wear OS and watchOS require a companion phone. reply MBCook 7 hours agorootparentYou could buy an older iPhone to use with it and just basically keep the phone at home in a drawer. There is a mode for the watch that is designed to let you give them to family members who don’t have phones (think small children or maybe the elderly) but from what I’ve heard it’s a buggy hassle. reply ddrmaxgt37 12 hours agoparentprevExactly reply browningstreet 14 hours agoprev> The handset will feature Wi-Fi and Bluetooth, with 5G currently being explored If this could be a wireless access point, I think that could be a differentiator. I would love a more minimal phone for daily carry -- but when travelling, it'd be nice to connect my iPad/laptop to an AP for those things that need modern apps. reply dangus 14 hours agoparentLack of 5G is a major oversight. The iPhone had that 4 years ago. Good condition iPhone 12 models go for under $300, and they want to sell this thing for $400. Seems like it's better to grab an iPhone 12, set the screen to greysfale in the accessibility settings, and then turn on screen time to block social media apps and other distractions. An OS settings preference selection isn't a product. reply AlecSchueler 13 hours agorootparent> Seems like it's better to grab an iPhone 12, set the screen to greysfale in the accessibility settings, and then turn on screen time to block social media apps and other distractions. Better to use rsync than bother with Dropbox? reply samatman 7 hours agorootparentThis phone is not the next Dropbox. reply dangus 7 hours agorootparentprevI mean, if you really think this thing is the next Dropbox…sure. reply RajT88 10 hours agoprevThis would make a great work phone if they promise 3 years of security updates as well as major Android upgrades. Otherwise this phone will be unusable in 6 months according to my company's BYOD security policy. reply tzm 5 hours agoprevI want this to be a success, but I really can't leave my iPhone. I love the design and simplicity.. just practically, I don't think it will fit my life. reply drekipus 10 hours agoprevThe problem with eink phones is that they're largely unsupported / using some OS that I don't trust. I tried using my phone in grayscale mode for a while, but the complete lack of colours makes it difficult to use. I'm working on making a \"desaturated\" mode that changes the android renderer to not go fully grayscale, but only a little, so there's still some colour information. reply moreofthis 9 hours agoparentI would guess that a phone designed with an eink display will have visual design and UX that is more thoughtfully designed for greyscale than iOS or Android. I was always taught that a design should be done first in greyscale to make sure that it works well using only alignment, hirearchy, balance etc, then you add colour; I still see that done frequently in print design, but less so in the digital world for whatever reason. reply mattkevan 9 hours agoprevLooks interesting. I’m fascinated by e-ink and the oddball devices which use it. I wish I had the cash to collect them all (though I did get a Remarkable tablet the other day). As far as I can see, there’s no mention of a backlight. An e-ink phone sounds great but if you can’t see the screen in the dark that’s a problem. reply moreofthis 10 hours agoprevI love the aesthetic of phones like this, but I'm not sold on comments like this (from the reddit ama in the article): > Its durability also means less frequent replacements, countering the disposable culture of modern electronics. My starting point is that the most eco-friendly phone avilable to me is the one I already have. That comment reads to me as saying that if you have a fault you need a replacement instead of being able to opt for repair. I simply do not believe that a phone that isn't built to be repaired can be considered more eco-friendly than not buying a new phone. The CEO has promised more information about repairability closer to launch and I hope they follow through; I would guess that compared to the average phone purchase the overlap of people who want a minimal phone and people who want a repairable phone is pretty high. reply AndyKelley 8 hours agoprevI don't know how you can call something minimal that is built on top of Android. This isn't going back to the basics, this is another complex abstraction layer added to the top of an abstraction skyscraper. reply butz 13 hours agoprevI wonder how it went for Mudita with their \"Mudita Pure\" minimal phone? It is out of stock on their website and main focus is on alarm clocks. reply squarefoot 11 hours agoprevI've read positive comments about BaldPhone. It's aimed at elderly people, but I don't see reasons why it couldn't be used to make regular smartphones interfaces more usable for everyone. https://baldphone.com/ reply stonogo 11 hours agoprevBe careful with your money. I'm still not convinced this is real. Neither are others: https://old.reddit.com/r/dumbphones/comments/198y1xi/minimal... https://old.reddit.com/r/TheMinimalCompany/comments/1aoq90q/... https://www.blackhatworld.com/seo/my-company-got-funded-mill... and https://old.reddit.com/r/eink/comments/1b35fuz/please_exerci... reply WalterBright 11 hours agoprevLooks a lot like my Kindle Keyboard. The KK also has a cell phone chip in it! reply throwaway81523 13 hours agoprevA minimal phone, with an e-ink display and an alphabetic keyboard, that costs $400? Umm, that is confused. Here is what I would call a minimal phone: https://www.gsmarena.com/nokia_3310-192.php Unfortunately those are all now bricked by the 2G/3G shutdown and nobody makes a phone with a similar feature set (i.e. absence of everything but voice calls) any more. The Jitterbug Flip 2 comes sort of close but it still has Alexa and other confusing stuff, and you can't buy it without an overpriced subscription. I've been looking for a phone simple enough to not confuse some of my elderly family members and those phones no longer exist. So I'm constantly the involuntary tech support for whatever phone they use. I think of buying a cheap Android phone and writing a kiosk mode app that has no access to anything except dialing the phone. Maybe someday. reply missedthecue 13 hours agoparentLook at the Raz Memory phone. $349 and it comes network unlocked. reply throwaway81523 12 hours agorootparent$349 minimal phone, um no, a minimal phone should be more like $20 ;). https://www.gsmarena.com/nokia_1661-pictures-2572.php Not really minimal but the above is the type of thing I have in mind. reply idle76 1 hour agorootparentThis one is the same phone type with 4G(my kids have them): https://m.gsmarena.com/nokia_105_4g-10966.php reply ummonk 12 hours agoprevThe mentioned price ($400) seems rather low for a new entry phone. I’d rather they charge a little more to give themselves financial to enable faster manufacturing and snag free deliveries. reply wkat4242 5 hours agoparentDon't forget it competes with $50 feature phones. They can't go too crazy. This is already too much imo. reply beretguy 7 hours agoprevAnd it’s most likely gonna cost $300-500 like Mudita, Punkt and Light Phone. reply running101 10 hours agoprevI bet the battery life would be awesome on this phone. reply dangus 14 hours agoprevI've got major doubts on a lot of these claims. Shimmying modern Android into an e-Ink display and physical keyboard is going to be a strange experience even if you truly want a zero-distraction phone. Supposedly it's going to protect your privcy but they also claim you can just download apps from the Play store. Seems like a bit of an unnecessary promise. Navigation with map apps in particular is going to be awful on the e-ink display. Really, a lot of \"basic\" non-social media non-addicting apps involve a lot of motion that plain and simple isn't designed for e-ink. Uber is highlighted as one of these apps that you might want to use without a distracting smartphone, but think about how much motion is involved with the Uber user interface when you use it. The whole interface plus the map is doing a bunch of smooth motions that do not take low refresh rates into account. The physical keyboard basically has to be there due to the shortcomings of the display, but I think when you go back to physical keyboards on phones you'll quickly realize that they are awful to type on compared to modern predictive autocorrect. They also can't adapt at all to the specific apps on the system. Say goodbye to emojis, stickers, and GIFs when you talk to your friends! Imagine what Slack will look like on this thing, and that's an app I have to use for work! Another odd claim is that the device will be $400 but be available with early bird discounts below that! That's an impossible price for an incredibly niche phone with heavily customized software. One last comment on this concept: when you think about the most mainstream smartphones in the world, what is the most physically distinguishing physical feature on them – the one cosmetic feature that identifies the phone with a brand? That's right, the cameras. That's no coincidence: it's the most important feature of the smartphone. It isn't mentioned at all with this phone, and questions about it on the AMA were ignored. At face value it seems like video calls and perhaps even sending simple photographs will be a major challenge on this phone. I think most people who want to curb smartphone addiction aren't looking to compromise healthy things like sending photos and videos to their family and friends. I just get a feeling from the AMA [1] that this company is biting off more than they can chew. Finally, it's plainly obvious that you can get all of the \"unique\" features of this phone by setting up simple OS settings, like setting your screen to greyscale and setting up screen time/disallowing social media app installs. Essentially, this company is trying to sell an OS preference pane as a standalone product. It will fail. [1] https://www.reddit.com/r/TheMinimalCompany/comments/19a6xr5/... reply Wowfunhappy 14 hours agoparentAt least for me, any phone which can't access either the Google Play Store or Apple App Store is simply a non-starter. I use apps to: • Operate and pay for the laundry machine in the basement of my apartment building. • Confirm all of my students (I'm an elementary school teacher) made it outside during a fire drill. • See the real-time location of a private bus which picks me up in the morning. • Change the times when my ice maker should automatically turn on and off. None of these apps have equivalents on PC. And, I didn't decide to use them, someone else chose for me. I don't use these apps all the time, and using them doesn't really need to be a good experience, but they must be accessible somehow! reply dangus 13 hours agorootparentI totally agree with you, I'm not saying there shouldn't be the Play Store on this device. What I mean here is that in the context of the questions about privacy, I think it's odd that the company is making broad privacy promises while still claiming to give you the full Play Store. They make it sound like it's a more privacy-concious device than a standard Android phone with Google Play Services, but in reality it's just an Android phone. reply Wowfunhappy 13 hours agorootparentI see where you're coming from, but I think it's meaningfully more privacy-conscious if you're unlikely to actually spend much time in Play Store apps. I realize it's a bit weird to say \"we're more privacy conscious because we made the UX worse\", but such is the inherent contradiction in all of these \"a phone to make you less addicted to your phone\" products. And although no one has cracked it so far, I do think there's a place in the market for a device like this. reply dpedu 13 hours agoparentprevE-ink has really come a long way, applications that involve lots of motion won't be that awful. I bought a Hisense A5C smartphone a couple years ago, which is an android smartphone with a (color!) e-ink display. I bought it as more of a toy/experiment, knowing it wouldn't support US carriers, to see what an e-ink smartphone would be like. I really ended up liking the concept. https://youtu.be/9vvhbPHFoio?t=20 reply bpye 9 hours agorootparentI knew about the HiSense eink phones before, but this one makes me particularly sad. This would be a great device for me if it was well supported in North America. Alas… reply 7e 7 hours agoprevThis will fall. So much of our life is online that a real handheld computing device is necessary. This will sell only to those in addiction treatment. reply dredmorbius 8 hours agoprevAddressing a few points that have been raised about e-ink, apps, and Android, I've been using an e-ink tablet as my daily driver for the past three years (Onyx BOOX Max Lumi, running Android 11), and have a pretty good idea of the capabilities and limitations. Overall, the device has been far superior to any earlier Android device I've owned for overall readability, usability, battery life, and satisfaction. For a demonstration of what e-ink displays are capable of, see this video, which starts basic (static signage systems), and progresses through video-capable displays (not, it's true, high quality, but serviceable):An Onyx BOOX Note displaying video, similar to my own device: . For e-ink tablets and mobile devices there are typically multiple display modes, which can be set on both a per-app and overall system basis. It's reasonably easy to switch between these where needed (e.g., on a Web browser). Higher-quality rendering comes with slower refresh, and there's a trade-off for visual quality vs. speed, but even basic animation is possible with only very modest quality degradation. \"X-mode\" for full video sacrifices a lot of quality, but you'd typically use that only for video-intensive apps (or occasional video viewing in a Web browser). The main side-effect is ghosting at higher refresh speeds. Android devices can use third-party app stores such as F-Droid (VERY strongly recommended), with an independent selection of apps, or the Aurora Store alternative interface to Google Play Store which provides any Android app available through Google Play. I minimise the apps I've installed, and have avoided virtually all authenticated services (one article-managing app excepted), to minimise distractions, but have several installed from both sources. E-ink itself does have its strengths and weaknesses. I like to say: Persistence is free; pixels are cheap; paints are expensive; refreshes are slow (1-8 Hz rather than 60--120); shades and colours are limited or nonexistent; line-art, dithered images, and half tones render quite well (raster and gradients far less so); paginated navigation is vastly better than scrolling; graphics are reflective rather than emissive; touch/Wacom may exist; and feature-detection capabilities are limited (e.g., CSS @media queries). It's a different medium, and rewards some adaptation of design principles. See: . I'd make one further addition: dark-on-light styles are hugely preferable to \"dark-mode\" (light-on-dark), which is far more difficult to read. Generally, e-ink prefers full black on full white styling. I'll note that apps which are designed for e-ink, most particularly EinkBro (an adaptation of the FOSS Browser) make for a much superior experience: . And yes, there are full e-ink monitors which are available for desktop systems:reply steelframe 12 hours agoprevWe need to reverse the trend of most people having a phone that's wired in with Google or Apple. I don't, and I can't tell you how often I try to do something only to be told, \"Okay, now download our app and...\" It happened just last week when I was buying a car. The sales rep kept insisting that I install the car company's app while I was trying to just write a check, grab the keys, and drive off the lot. \"You can use your Google or Facebook identity to make signup quicker!\" Not only can I not actually install the app, I don't even have a Google or Facebook account. Eventually he relented and showed me \"his wife's\" car -- which happens to be the most expensive car on the lot -- on his own phone so I could see how the app worked. (His wife's car had an odometer reading of 6 miles per what I saw in the app running on his phone, but I'm sure she just hasn't had a chance to drive it yet anywhere except home from the dealership yet.) For situations like that I usually have to tell them, \"I don't have a phone with me that can do that.\" Then they get really confused, convinced that I have no idea what I'm talking about that that all I have to do is open the App Store and search for the app. The problem is my \"App Store\" is F-Droid. Why on earth I wouldn't be cool with just handing over my privacy to Google or Apple is completely lost to them, and most of the time I have neither the time nor desire to try to explain it to them. So I just end up coming across as some weirdo asshole by refusing to \"just install the app.\" We need more people using phones that respect their privacy and that don't have an umbilical cord to Google, Apple, Facebook, Twitter, etc. reply electroly 11 hours agoparentI think car salesmen are particularly pushy about it because car manufacturers are starting to sell monthly subscriptions for things in the app. They can't sell it to you if you won't install the app. For instance, my Toyota came with some kind of trial subscription for a remote unlock/lock and GPS location service. Served, of course, through the Toyota app. They have an incentive to get you to install the app that goes beyond just not thinking it's a big deal. Email I got today: > Your access to Safety Connect and Remote Connect services will expire unless you access your Toyota app or call 1-833-914-0992 to extend your subscription. For as low as $8.00 per month, you can enjoy the convenience of Safety Connect or Remote Connect. For further savings, you can choose an annual plan. I won't be doing that, but it makes the reason for the push to install their app starkly clear. reply steelframe 10 hours agorootparentThe car I bought last week is a Toyota. Upon getting home I immediately followed the instructions on the sticker near the center console to hit the \"SOS\" button and request deactivation of their telematics services. The rep on the phone mentioned something about how she needed to create an account for me or something before she was able to process the opt-out and then, I guess, did so. Of course I have no idea what this opt-out does. The skeptical part of me suspects that the system still collects and transmits my location and such, but then they simply don't trivially attach that telemetry to my account. I'm also going to try pulling the DCM fuse that's supposed to cut the cut the gateway/telematics antenna. I also plan to wrap the transmitter in a Faraday cage. reply MBCook 7 hours agorootparentprevI would not be at all surprised if the salesman got a little bonus for every app that was confirmed installed on a sale. reply Muromec 11 hours agoparentprevWell, I’m just using a flip phone and keep the iPhone in a cupboard at home without a sim, so I can use that one app once in a blue moon instead of dancing around the problem for half a day. Works like a charm. reply vitalurk 11 hours agoparentprevIt's bewildering to me that you're the weird, odd one for doing this. reply hyperthesis 11 hours agorootparentIt's in the sales rep's interest. reply Syonyk 11 hours agoparentprevThis is a big part of the reason I carry a flip phone. Instead of explaining that your \"otherwise smartphone looking thing\" can't run Apple or Android apps, I just have to whip out the flip phone, flip it open, flip it closed, and say \"Sorry, my phone doesn't have apps.\" ... even though it's running Android 11 Go and I can sideload stuff, it doesn't matter because the number of apps that work on a 320x240 screen with keyboard input only are \"roughly zero.\" Even if there's no good reason it shouldn't work, nobody tests or designs for that case, so there I am. reply steelframe 10 hours agorootparentYup, that works too. Not a bad idea! By the way, the dimmers are working great. And I finally found BR30s that don't sing. It's amazing to me how many of them do. Have you tried Syncthing yet? reply Almondsetat 11 hours agoprevThese boutique pieces of tech are bound to fail because they don't stand upon the shoulders of giants. We see it everywhere in the phone world: phones aimed at the elderly have buggy horrible software and become quickly abandoned; modern feature phones are buggy, slow and incomplete because nobody in their right mind assigns their best engineers to the dumb phone division, not Nokia, not LG; plus small companies like Mudita, Punkt, Light and others don't have the know how to produce a complete device. The only real solution is the true \"hacker path\"of taking existing perfected and mass produced technology and achieve your goal with a few small modifications. If your goal is to have a basically \"dumb\" experience, why aren't you getting a bunch of 5yo Xiaomi phones, follow the extremely safe guides and flash LineageOS without Google Services on them? And maybe pair them with a SIM card with no data? This way you get a snappy phone with actually usable offline applications (and you can sideload the ones you truly need). reply nicoritschel 14 hours agoprevnext [2 more] [flagged] 2big2fail_47 13 hours agoparentwhich is not a bad thing reply UberFly 12 hours agoprev [–] These phones remind me (a bit) of the Windows vs Linux arguments. There are a lot of appealing aspects to these phones but switching to them is really impractical for most of the population. reply Y_Y 12 hours agoparent [–] \"The mass of men live lives of quiet desperation\" -Thoreau I understand caring about the huddled masses if you're trying to mass-market something. Here, as with so many other threads on hn, I feel like it's fine to acknowledge that most people won't be interested.ñ and then move on to discussing the subject at hand which invariably is going to be interesting to more significant portion of hackers. I love this product idea, but the device itself isn't the hard part. Already pine64 or random Shenzhen supplier could do this, getting a UI (android or otherwise) is going to be the challenge. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Minimal phone is a minimalist handset featuring an E Ink display and physical QWERTY keyboard to minimize distractions.",
      "Running on the MnmlOS platform, a modified version of Android, it will offer restricted access to third-party apps, emphasizing basic functions like calling, texting, and email for productivity and simple entertainment.",
      "User privacy and security take precedence in the design, with a planned crowdfunding campaign for production, priced at $400 retail, and long-term support with updates for over five years."
    ],
    "commentSummary": [
      "Minimalist phones with e-ink displays and physical keyboards are praised for simplicity and long battery life but face concerns over lag and limited functionality.",
      "Users discuss the trade-off between minimalism and practicality, debating the use of existing tech with offline capabilities versus boutique devices.",
      "Companies like Mudita, Punkt, and Light are criticized for not having the expertise to create fully functional devices, with suggestions to modify current technology for a simpler phone experience, emphasizing the need to balance minimalism, functionality, and privacy in handheld devices."
    ],
    "points": 149,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1709402785
  },
  {
    "id": 39573756,
    "title": "Audio Engineering Pioneer and Amateur Radio Icon, Bob Heil K9EID, Passes Away",
    "originLink": "https://www.arrl.org/news/bob-heil-k9eid-silent-key",
    "originBody": "ARRL Website Search Category Clubs Contests Exam Sessions Hamfest/Conventions Licensing Classes Member Directory News Special Events ARECC Field Class/Exam Call Sign / Name Search Login Register Account Login Help Home On The Air Licensing, Education & Training Membership Regulatory & Advocacy Public Service Technology Get Involved ARRL Store About ARRL News & Features News Bob Heil, K9EID, Silent Key 03/01/2024 The man who defined the sound of live rock ‘n’ roll music and brought audio engineering principals into mainstream amateur radio use, Dr. Bob Heil, K9EID, has passed away at the age of 83. He was an ARRL Life Member and in the ARRL Maxim Society. A Facebook post from Heil Ham Radio paid tribute to their founder: “Bob fought a valiant, yearlong battle with cancer, and passed peacefully surrounded by his family.” Heil founded Heil Sound in 1966, through which he created the template for modern concert sound systems for musicians like the Grateful Dead, The Who, Joe Walsh, and Peter Frampton. The talk box used on iconic live record Frampton Comes Alive! was of Heil’s design. His audio engineering products have been featured in the Rock & Roll Hall of Fame, and he was honored in 2007 with the Parnelli Audio Innovator Award for his impact on the live sound industry. “My life has been about achieving great sound, whether on the concert stage or in the amateur radio world,” Bob Heil recounted in 2022. “I’ve watched Heil Sound go from a regional sound company to a world-class microphone manufacturer. This company has been my passion,” he said. Parallel to his commercial and artistic success in live music, was his passion for amateur radio. He was active in ham radio from a young age and merged his expertise in audio engineering with his love for radio. Heil Ham Radio was founded to produce microphones, headsets, and other gear for radio amateurs with an emphasis on high-quality audio. Heil was known as a mentor who enjoyed helping others find success in ham radio. Recently, his grandson Charlie Hartley, KF0OOP, became a licensed ham to surprise Heil for his birthday. The pair attended the ARRL Midwest Convention/Winterfest in St. Louis, Missouri, on January 27, 2024. Heil was a generous donor to amateur radio organizations, including ARRL. Recently, he donated a host of new audio gear to the Hiram Percy Maxim Memorial Station, W1AW. His generosity and kind nature will be missed by many, including ARRL Director of Development Kevin Beal, K8EAL. “Bob was a titan in many areas. He was generous with his time, offered keen insights, and had the heart of a philanthropist in the ARRL Maxim Society,” Beal said. “He was a gentleman to his core, making friends easily and everywhere he went, from rock stars to captains of industry. I consider it a real privilege to have become a friend to him, too, all because of amateur radio.” Heil was known for his passion for AM operations. He served for many years as an on-camera host of the Ham Nation podcast. Tributes to Heil have been flooding social media, including from his co-hosts. ARRL President Rick Roderick, K5UR, said Heil’s passing is a significant loss. \"Bob Heil's technical achievements that brought high-quality audio to amateur radio pale in comparison to his generosity and willingness to help his fellow ham. He's long been known as someone eager to help mentor and teach. His legacy on our hobby will be long-lasting. Our thoughts are with his loved ones.\" Photo Gallery Bob Heil, K9EID. ... Back Back to Top Having Trouble? News & Features >> News News ARRL Audio News ARRL Periodicals Archive Search QST On the Air Magazine QEX NCJ ARRL Letter News Tips Doctor So Now What? ARRL Magazines EXPLORE ARRL ARRL The National Association for Amateur Radio® 225 Main Street Newington, CT, 06111-1400 USA Tel: 1-860-594-0200Fax: 1-860-594-0259 Toll-free: 1-888-277-5289 hq@arrl.org ARRL Donate Now Join / Renew Your Membership Advertise With Us Contact ARRL Terms of Use / Privacy Policy E-mail to a Friend Sign Up for Our Newsletter",
    "commentLink": "https://news.ycombinator.com/item?id=39573756",
    "commentBody": "Bob Heil, K9EID, Silent Key (arrl.org)148 points by Stratoscope 17 hours agohidepastfavorite10 comments teeray 14 hours agoOne of the coolest things about this legend was that he would happily meet with your local ham club no matter how small to share his expertise on radios, microphones, sound engineering, etc. I remember he jumped on a Zoom call with like 5 or 6 of us and we had a great time—really down to earth, solid engineer. Truly a loss. RIP. reply Stratoscope 16 hours agoprevBob was well known in the amateur radio community, of course. I owned one or two of his ham microphones. He may have been even better known for his work in concert sound systems for the Grateful Dead, The Who, Joe Walsh, Peter Frampton, and many others. Here is a previous HN discussion with some notes about the term \"silent key\": https://news.ycombinator.com/item?id=19674170 reply unsignedint 12 hours agoprevI remember encountering Bob many years ago at the Dayton Hamvention. He was an incredibly kind individual, and I vividly recall how he crafted an adapter cable overnight for my friend's then-new radio and microphone. His generosity and expertise left a lasting impression. Rest in peace, Bob. reply assimpleaspossi 16 hours agoprevhttps://en.wikipedia.org/wiki/Bob_Heil He was also the organist on the Mighty Wurlitzer for the Fox Theatre in St Louis https://en.wikipedia.org/wiki/Fox_Theatre_(St._Louis) reply kloch 15 hours agoprevI didn't know Bob but I was fortunate enough to work with another legend of live sound: Tommy Linthicum. The sound company he started with his highschool friend (National Sound) ended up doing the first 11 world tours for Rush. He pioneered \"flying\" PA speakers above the stage in the 1970's. Before that they were commonly just stacked on the front/sides of the stage. Later, National Sound merged with another company to form National Events, which did sound/light/staging for almost all of the major concerts and political rallies on the national mall in DC for several decades. I made a tribute video after his death in 2007: https://kevinloch.com/tommy/tommytribute-highres.avi reply ZoomZoomZoom 15 hours agoprevI have a bunch of Heil mics in my locker and they've been serving me exceptionally well over the years. PR40 and PR30 should be considered true dynamic classics. RIP. reply clbrmbr 9 hours agoprevI remember my grandfather speaking of Heil kind of like he spoke of Feynman. reply threeio 5 hours agoprevI met Bob twice, he was a honestly nice guy who wanted to further the hobby any way he could. reply rdl 5 hours agoprevOnce again, fuck cancer. reply imdsm 11 hours agoprev [–] RIP. 73 my friend reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dr. Bob Heil, K9EID, an audio engineering pioneer for live rock music and dedicated amateur radio enthusiast, passed away at 83 after battling cancer, leaving a lasting legacy in both industries.",
      "Founder of Heil Sound, he was renowned for his technical expertise and mentorship in the ham radio community, generously supporting organizations like ARRL.",
      "The amateur radio community is honoring Dr. Heil with heartfelt tributes, emphasizing his technical accomplishments and compassionate nature; the ARRL website showcases a photo gallery and news pieces commemorating his life."
    ],
    "commentSummary": [
      "The amateur radio community and sound engineering industry are mourning the passing of Bob Heil, a renowned figure known for his expertise in radios, microphones, and concert sound systems.",
      "Bob was celebrated for his generosity in sharing knowledge and supporting others in the industry, leaving behind a legacy of contributions that will not be forgotten.",
      "His impact on the field resonates through the heartfelt memories shared by many who admired and learned from his work."
    ],
    "points": 148,
    "commentCount": 10,
    "retryCount": 0,
    "time": 1709398119
  },
  {
    "id": 39578416,
    "title": "SpaceX reaches 17Mb/s speed from satellite to Samsung phone",
    "originLink": "https://twitter.com/elonmusk/status/1764032892663906313",
    "originBody": "SpaceX just achieved peak download speed of 17Mb/s from satellite direct to unmodified Samsung Android phone pic.twitter.com/JqPHmkriv0— Elon Musk (@elonmusk) March 2, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39578416",
    "commentBody": "SpaceX just achieved speed of 17Mb/s from satellite to stock Android phone (twitter.com/elonmusk)138 points by grecy 5 hours agohidepastfavorite51 comments dotnet00 4 hours agoWant to emphasize Elon's follow up that this is the peak for a beam, and the beams are very wide, so this is basically only possible in places far from ground based networks and probably also requiring the place to be sparse enough to only have the one device in the beam area. reply numpad0 21 minutes agoparent17Mbps UDP downlink to standard smartphones. Half a dozen sqkm/sqmi minimum cell size. Analog modem equivalent uplink theoretically possible. That's DVB. That's an executive summary for a digital TV standard. reply londons_explore 48 minutes agoparentprevIf future satellites have fold out antennas that are 45 meters diameter, spot sizes of half a mile are possible. With that, service will make sense everywhere except urban areas. 45 meter fold out antennas are very possible. Imagine you screen print antenna wires onto a mylar sheet, then double up the sheet and seal the edges to make it like a large airbed. Then, when in space, inflate it. reply simfree 4 hours agoparentprevElon's tweet also doesn't mention upload speed. Download speed isn't very useful when your trying to send a MMS showing where your trapped and it's taking tens of minutes to upload. reply xscott 3 hours agorootparentThis hypothetical case of sending a large multimedia message instead of 8 bytes for latitude and longitude and 3 more bytes for the letters \"SOS\" doesn't seem sincere. reply huppeldepup 1 hour agorootparentminor fyi. Had to look up how to get lat/long on an iphone without internet access. It’s in the default compass app. reply plugin-baby 51 minutes agorootparentWhere? Mine has zero options now - just displays the compass, with the level in the middle. reply watermelon0 30 minutes agorootparentSeems it's not available everywhere, for some reason. > Note: Your coordinates and elevation may not be available in certain countries or regions. https://support.apple.com/en-gb/guide/iphone/iph1ac0b663/ios reply Traubenfuchs 26 minutes agorootparentprevGoogle Maps and Apple Maps show it when you set a marker. You don‘t need internet. reply jeroenhd 1 hour agorootparentprevI would be less worried about bytes and more about the general TCP handshake/acks making it through. You can easily add height, heart rate, and all other kinds of information before you come close to the network overhead. You could also gamble UDP+overhead, but I assume you want some kind of assurance that your SOS made it through. You also need to be able to get a session within the beam. If you're stuck in the middle of a desert you'll be fine, but if you're within range of a minor town you may not be able to get any signal. reply david-gpu 29 minutes agorootparentNot an expert, but my understanding is that SMS text messages don't rely on TCP or UDP. Instead, they use their own protocol called SMPP with an overhead of less than 100B. reply cyberax 3 hours agorootparentprevTo achieve this kind of speed, you need at least around 600kbps at the barest minimum for TCP ACK packets (~50 bytes), assuming that downstream packets are full-frame 1500 bytes. reply bsdetector 2 hours agorootparentThe tweet's 17 Mb/s is UDP down from satellite, so no ack replies from the phone, and 15% packet loss. So it really doesn't say anything about upload speed. reply dmitrygr 2 hours agorootparentprevThat’s not really true since one ACK packet can acknowledge multiple RXed data packets. reply frankacter 2 hours agorootparentprevThe nuance of this news is that it is a for a standard consumer mobile device. It is not intended to replace coverage in areas where telcos exist, rather to supplement in times of spotty coverage or emergencies. >@Elon: This service works in partnership with wireless providers, like what @SpaceX and @TMobile announced. In your scenario you would likely be sending text/sms based communication as a primary priority (ie. coordinates, instructions) with MMS as a secondary luxury. If you are permanently or frequently in an area without telco service you would want to make use of specialized hardware which is optimized for starlink communication. For example, here is video of Elon using starlink for video conferencing which demonstrates not only high upload speeds, but also quick swapping between satellites without disconnect. https://youtu.be/tKqJ5-kkUGk?si=RVilCEke7J3zXoQK&t=367 reply lallysingh 2 hours agorootparentprevA map for how to get out, or a video for first aid procedures, or a guide on what's safely edible around you, or other survival information until help can get there can make a big difference. reply whatshisface 3 hours agorootparentprevAntennas couple the same both ways. reply ryandamm 3 hours agorootparentBut power doesn’t, right? Happy to be corrected (please, educate me!) but I think this is asymmetric, in practice. reply max_ 8 minutes agoprevCorrection: It's 16 Megabits/s which is 2 MB/s. Still impressive either way. reply max_ 4 minutes agoprevHow exactly is this possible? What is the technology receiver based on? Where can I learn more about this? What exact model of Samsung Phones have this? reply p1mrx 1 hour agoprev\"Give it a second! It's going to space. Can you give it a second to get back from space?\" Finally that joke is accurate. reply kamranjon 1 hour agoparentI thought this joke already was accurate because they were on a plane and the WiFi on a plane usually is powered by satellite internet. reply physicles 1 hour agoparentprevhttps://youtu.be/PdFB7q89_3U?feature=shared Classic. reply ycui1986 3 hours agoprevI suppose this is download speed. what about upload speed? reply greatjack613 4 hours agoprevWhile the bandwidth numbers seem terrible given this is from an entire beam at it's peak and beams are wide, this is super useful for things like sms where bandwidth is not a concern. At 17 Mb/s you can have thousands of simultaneous sms sends without issue reply Scoundreller 1 hour agoparentI hope there's some broadcast stuff planned (does cellular support multicast like that?). So I can just point my phone at the sky and get some news/weather/traffic updates \"off-line\". Maybe a radio station or two? It's pretty impressive what can fit into 32kbps (or less!) these days. reply Gare 1 hour agorootparentYes, that's how SMS emergency alerts work https://en.wikipedia.org/wiki/Cell_Broadcast reply Scoundreller 43 minutes agorootparent> is part of the 2G, 3G, 4G LTE (telecommunication) and 5G standards Interesting as Canada's system only works on LTE or higher (we still have 3G here). I camped on 3G for a while because they kept sending out Amber Alerts at the \"Presidential\" level for custody disputes. Gov repeatedly denied any issue but haven't sent any for a while. Either people stopped \"abducting\" their own kids or they changed their threshold-to-blast. reply gonesilent 29 minutes agorootparentprevViasats service supported this via USB plug in drive on the modem to load some content. Don't think it was released out of beta. reply blackoil 4 hours agoparentprevYeah, it could be god sent for natural disasters and truly remote locations. But it is not replacement for regular mobile service. reply usrusr 1 hour agorootparentFor emergencies in truly remote locations. In a natural disaster, you have everybody at once refreshing news and checking in on friends and family that even undamaged networks could struggle. When the network has broken down you'd better be prepared to have teams fixing what is fixable, and the ability to deploy pop-up cells on the ground. If you have skimped on that preparation betting on satellite cells to save the day the contribution of Starlink to disaster preparedness might end up being a net negative. That being said, pop-up cells on a startlink as their backhaul could become huge in disaster preparedness. Some contract scheme for standby basestations might actually become a big component of the Starlink business model. The good news is that all talk to regular phones can't overlap with regular starlink frequencies, so unless it blocks some other bottlenecks like SDR DSP capacity it won't compete with regular connections (certainly won't have a meaningful impact on orbital backbone load) reply vermilingua 37 minutes agorootparentSurely this is an ideal usecase for IP multicast? Given that SpaceX controls effectively the entire LEO retail internet at the moment they’re in an ideal position to push a standard for multicasting emergency or regional updates. reply bugbuddy 6 minutes agorootparentYou are talking about layer 3 while people are talking about layer 2. reply blackoil 1 hour agorootparentprevI am thinking true disasters, where a simple message with your location can save lives. I believe it should be possible to disable all communication except basic sms and emergency communication like 911 or similar can be accessed without SIM. reply BlueTemplar 1 hour agoparentprevHmm, but SMS rely on the cellular tower protocol, basically being carried on the status messages that cellphones already constantly send/receive anyway - they don't use the IP (at least until the tower). So I'm not even sure they can be sent/received by satellite ?? reply toomuchtodo 4 hours agoparentprevIridium should be worried. reply threeseed 3 hours agorootparentThere is a 3GPP standard for satellite to phone connectivity which Iridium is adopting: https://www.iridium.com/project-stardust/ reply toomuchtodo 3 hours agorootparentTheir 66 satellites are going to support a much lower aggregate constellation throughput and spot beam count vs StarLink. They’re fundamentally constrained by lift costs and low constellation satellite count. Iridium has 48 spot beams per satellite each covering 250 miles. Each StarLink cell covers ~15 miles with a similar spot beam count, with 5,442 satellites currently operational (as of this comment). https://planet4589.org/space/con/star/stats.html (Disclosure: StarLink customer, no other affiliation) reply wkat4242 2 hours agorootparentMost of those sats don't support direct to cell though. But more will come of course. And are the spot beams for direct to cell the same in size and quantity? reply toomuchtodo 2 hours agorootparentGood question. I could not find the cell size specifically for the LTE coverage, and agree it will take time for the constellation to turn over to maximize the direct to phone capability. Regardless, SpaceX launches more StarLink satellites in three flights (~69) than Iridium has in its entire constellation. reply scotty79 25 minutes agoprevHow? WiFi? LTE? Is there anything else? reply DeathArrow 2 hours agoprevWhen will we be able to watch 4k porn in remote areas? reply Scoundreller 1 hour agoparentSounds like you already can, they just proved it, but you're going to have to watch the same video as everyone else. reply hkt 5 minutes agorootparentI just realised that unless there's some capacity to upload, the title essentially describes.. TV. reply redox99 25 minutes agoparentprevYou've been able for years, with regular starlink. Of course you need a dish antenna. reply jsemrau 2 hours agoparentprevApplications for such type of tech are usually military (is China's Navy moving in the Pacific). commercial (where I my oil tanker in relation to the storm), or post-event (let's say tsunami or tornado. Electricity might be down, where to send ambulances and search for survivors) reply viraptor 53 minutes agorootparentThose scenarios are mostly covered. Military has its own communication systems. (And satellite tracking for the navy) Weather - you can already receive precise satellite view of storms wherever you want. reply seydor 2 hours agoparentprevThat assumes you 'll be carrying a 4k TV with you reply dorianmariefr 3 hours agoprev [–] What about stock iPhone? reply peheje 2 hours agoparent [–] 0Mb/s reply senectus1 2 hours agorootparent [–] You must be holding it wrong... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SpaceX accomplished a high download speed of 17Mb/s from a satellite to an unmodified Samsung Android phone, shared by Elon Musk on March 2, 2024."
    ],
    "commentSummary": [
      "SpaceX reached a speed of 17Mb/s transmitting from a satellite to a stock Android phone, boasting wide beam coverage ideal for remote regions.",
      "The technology incorporates 45-meter deployable antennas to ensure broad coverage, with a focus on complementing traditional mobile networks rather than replacing them, proving beneficial for emergencies and SMS communications.",
      "Starlink's advancements, exceeding rivals like Iridium, are being harnessed in various sectors such as military operations, commercial applications, and post-disaster situations, showcasing its potential for multicast emergency broadcasts and IP functionalities."
    ],
    "points": 138,
    "commentCount": 51,
    "retryCount": 0,
    "time": 1709440021
  },
  {
    "id": 39572441,
    "title": "Rogue Wikipedia Editors Create Roads-Exclusive Website",
    "originLink": "https://gizmodo.com/competing-wikipedia-editors-only-about-roads-aaroads-1851298769",
    "originBody": "By Thomas Germain PublishedFriday 10:10AM Comments (24) Illustration: Vicky Leta For 20 years, a loosely organized group of Wikipedia editors toiled away curating a collection of 15,000 articles on a single subject: the roads and highways of the United States. Despite minor disagreements, the US Roads Project mostly worked in harmony, but recently, a long-simmering debate over the website’s rules drove this community to the brink. Efforts at compromise fell apart. There was a schism, and in the fall of 2023, the editors packed up their articles and moved over to a website dedicated to roads and roads alone. It’s called AARoads, a promised land where the editors hope, at last, that they can find peace. “Roads are a background piece. People drive on them every day, but they don’t give them much attention,” said editor Michael Gronseth, who goes by Imzadi1979 on Wikipedia, where he dedicated his work to Michigan highways, specifically. But a road has so much to offer if you look beyond the asphalt. It’s the nexus of history, geography, travel, and government, a seemingly perfect subject for the hyper-fixations of Wikipedia. “But there was a shift about a year ago,” Gronseth said. “More editors started telling us that what we’re doing isn’t important enough, and we should go work on more significant topics.” The dispute came down to some of Wikipedia’s most sacred tenets. Anyone can edit Wikipedia, but that doesn’t mean you can write whatever you want. For one, a subject has to be notable. Your grandma’s “famous” cookie recipe can’t have an article unless it’s actually famous. The site isn’t a place for personal opinions, either. Original research is forbidden. In general, articles are expected to have multiple sources, and there are rules about what qualifies as a citation. Primary sources, where a person or an organization talks about themselves, are viewed with skepticism. Secondary sources, written by someone unrelated to the topic, are the gold standard. For some roads, these rules get complicated. “The New York Times isn’t going to write an article about maintenance on highways in the middle-of-nowhere Texas or Colorado,” said Ben M., a roads editor known as BMACS001 on Wikipedia, who asked to withhold their full name. “Sometimes a primary source is all you have.” Wikipedia is a fragile ecosystem. The Wikimedia Foundation pays for the website’s operating costs and handles administrative issues, but no one is in charge of the platform itself. Wikipedia is a democracy, a self-governing experiment built on decades of arguing, compromise, and rabbinical debate. That communal decision-making is what binds Wikipedia together, but here, it’s what drove it apart. There are whole books about Route 66 and even minor roads in metropolitan areas get coverage in the local papers. But you may have trouble finding secondary sources about the Cherokee Hills Scenic Byway in Oklahoma. So, if you want to write that the byway starts in Tahlequah and ends at West Siloam Springs, can you cite a map published by the Oklahoma Department of Transportation? You can see that with your own eyes, but the map doesn’t say it in words. After years of permissiveness, a growing contingent of Wikipedia editors started to argue that such a scenario counts as an interpretation of the map, and therefore, it’s illegitimate original research. What’s more, that’s technically a primary source, because the Oklahoma Department of Transportation builds and maintains the road. And without secondary sources, maybe the Byway isn’t notable enough for a dedicated article in the first place. There’s an irony to disagreements about what is and isn’t noteworthy on a website like Wikipedia. In some respects, that’s the point. The platform is home to over 6 million articles on everything from the Peloponnesian War to the paperclip, every one of them written by unpaid volunteers who do their meticulous work just because they care. “For me it’s the autism. You settle on a thing and then you’re like, ‘well, this is my thing now,’” Ben said. “But people get really into all kinds of stuff, and just because it’s not the thing you’re into doesn’t mean it’s not important. We do it because we love it and we can create community around it.” The Roads Project had a number of adversaries, but the chief rival is a group known as the New Page Patrol, or the NPP for short. The NPP has a singular mission. When a new page goes up on Wikipedia, it gets reviewed by the NPP. The Patrol has special editing privileges and if a new article doesn’t meet the website’s standards, the NPP takes it down. “There’s a faction of people who feel that basically anything is valid to be published on Wikipedia. They say, ‘Hey, just throw it out there! Anything goes.’ That’s not where I come down.” said Bil Zeleny, a former member of the NPP who goes by onel5969 on Wikipedia, a reference to the unusual spelling of his first name. At his peak, Zeleny said he was reviewing upwards of 100,000 articles a year, and he rejected a lot of articles about roads during his time. After years of frustration, Zeleny felt he was seeing too many new road articles that weren’t following the rules—entire articles that cited nothing other than Google Maps, he said. Enough was enough. Zeleny decided it was time to bring the subject to the council. “I don’t have a problem with roads,” Zeleny said. “There are lots of obscure subjects on Wikipedia, but you have to follow the guidelines. People see Wikipedia as a joke. They think it’s not serious. I’ve taken great, great pains to make sure articles are well written, well researched, and well cited.” Zeleny brought up the problem on the NPP discussion forum, sparking months of heated debate. Eventually, the issue became so serious that some editors proposed an official policy change on the use of maps as a source. Rule changes require a process called “Request for Comment,” where everyone is invited to share their thoughts on the issue. Over the course of a month, Wikipedia users had written more than 56,000 words on the subject. For reference, that’s about twice as long as Ernest Hemingway’s novel The Old Man and the Sea. In the end, the roads project was successful. The vote was decisive, and Wikipedia updated its “No Original Research” policy to clarify that it’s ok to cite maps and other visual sources. But this, ultimately, was a victory with no winners. “Some of us felt attacked,” Gronseth said. On the US Roads Project’s Discord channel, a different debate was brewing. The website didn’t feel safe anymore. What would happen at the next request for comment? The community decided it was time to fork. “We don’t want our articles deleted. It didn’t feel like we had a choice,” he said. The Wikipedia platform is designed for interoperability. If you want to start your own Wiki, you can split off and take your Wikipedia work with you, a process known as “forking.” It’s happened before for similar reasons. One of the more significant forks was a Pokémon battle. Pikachu and Squirtle are culture icons, and they get their own pages. But by 2005, Wikipedia had amassed articles about lesser characters, and the website came together and decided that only the best and brightest Pokémon warrant a dedicated article. Faced with a mass deletion of their hagiographies on Dragonite and Garchomp, the Pokémon editors forked their articles over to a new website, Bulbapedia, where their work continues. Over the course of several months, the US Roads Project did the same. Leaving Wikipedia was painful, but the fight that drove the roads editors away was just as difficult for people on the other side. Some editors embroiled in the roads fights deleted their accounts, though none of these ex-Wikipedian’s responded to Gizmodo’s requests for comment. Bil Zeleny was among the casualties. After almost six years of hard work on the New Post Patrol, he reached the breaking point. The controversy had pushed him too far, and Zeleny resigned from the NPP. “I realized that there was a large portion of very vocal people on Wikipedia who just really didn’t care about quality,” Zeleny said. “I just got tired of it.” He thought about leaving Wikipedia altogether, but his son convinced him to keep working. For now, Zeleny’s staying in the backseat and working on articles like a regular editor rather than dedicating his time to policing new posts. AARoads actually predates Wikipedia, tracing its origins all the way back to the prehistoric internet days of the year 2000, complete with articles, maps, forums, and a collection of over 10,000 photos of highway signs and markers. When the US Roads Project needed a new home, AARoads was happy to oblige. It’s a beautiful resource. It even has backlinks to relevant non-roads articles on the regular Wikipedia. But for some, it isn’t home. “There are members who disagree with me, but my ultimate goal is to fork back,” said Gronseth. “We made our articles license-compatible, so they can be exported back to Wikipedia someday if that becomes an option. I don’t want to stay separate. I want to be part of the Wikipedia community. But we don’t know where things will land, and for now, we’ve struck out on our own.” Show all 24 comments CONTINUE READING",
    "commentLink": "https://news.ycombinator.com/item?id=39572441",
    "commentBody": "Rogue editors started a competing Wikipedia that's only about roads (gizmodo.com)136 points by cainxinth 17 hours agohidepastfavorite125 comments bloopernova 15 hours agoReminds me of Everything2. It started as a freeform text linking site, where nodes (pages) could be linked just like a wiki these days. It was written by some of the slashdot crew, back around 2000. The site grew and attracted a fun crowd who really liked the freeform wiki-like interface. Unfortunately some of the admins wanted to compete with Wikipedia, so the fun, frivolous stuff was discouraged over purely factual nodes. This meant that some people stopped contributing. I left around that time. https://everything2.com/ Huh it's still going! It must be 25 years old now, not a bad achievement. reply Espressosaurus 10 hours agoparentHah. I remember joining it to write a bunch of stuff about a game, which immediately got removed. I of course immediately left. What is with these \"encyclopedias of everything\" that don't want frivolous information? reply ethbr1 4 hours agorootparentHumankind's inherent love of rules and order? >> “I don’t have a problem with roads,” Zeleny said. “There are lots of obscure subjects on Wikipedia, but you have to follow the guidelines. People see Wikipedia as a joke. They think it’s not serious. I’ve taken great, great pains to make sure articles are well written, well researched, and well cited.” Or maybe more precisely, people's desire to believe the thing they're volunteering vast amounts of their personal time to matters and is serious, and because it's serious there should be rules. reply Cipater 2 hours agorootparentI agree that people contributing to Wikipedia should take it seriously. I also believe that Wikipedia is important and the work contributers do there matters. Your comment makes it sound like you disagree. reply contravariant 10 hours agorootparentprevEasy, if you want an encyclopedia that contains truly everything you can just use the library of babel. reply Dylan16807 4 hours agorootparentSure, if you move the goalpost from \"information\" to \"has letters\". reply thoughtFrame 15 hours agoparentprevThat's interesting, because I checked out everything2 last year to see what I had missed out on, and found it a nice place with poetry and personal essays. Maybe at some point their culture changed again? reply bloopernova 14 hours agorootparentIt's entirely possible! I left sometime in the mid 2000s, so there's certainly a lot of time for cultures to have changed significantly even multiple times. reply creatonez 7 hours agorootparentprev> Maybe at some point their culture changed again? Supposedly Tumblr has done the same. They crashed and burned so hard that they actually came out of the ordeal with a reverse eternal September effect, where miraculously most people act respectfully towards each other and are not just trying to exploit the platform. reply unwind 15 hours agoparentprevFounded (as \"Everything1\") in 1998 according to the other site. reply bloopernova 14 hours agorootparentOh right! Yeah I completely forgot about its initial incarnation being named that. It was definitely a new frontier where we thought anything was possible. Just being able to easily link between nodes/pages was a very cool feature back then. reply yreg 14 hours agoprevThis is the system working as intended. It's great that they are putting their original research on AARoads. Wikipedia can quote the noteworthy parts. reply classichasclass 11 hours agoparentWould they? Wouldn't that be \"original research\"? reply JKCalhoun 11 hours agorootparentYeah, agree. Wikipedia's rules are being used as a club and it's too bad. We get it that people will abuse Wikipedia and it must suck to cull all of the ephemera people submit (not the best word for it but the only one that comes to my mind). But I think rules should allow for nuance. Perhaps Wikipedia should have allowed a kind of sub-Wikipedia: a sort of parallel wikipedia that deals in topics more akin to Urban Dictionary entries. Sort it's entries to the bottom of the search results, serve up a light yellow background for sub-pedia pages to make it clear these are not conforming articles. But it seems to me like a generally bad idea to be a ruthless gatekeeper for the enthusiastic and motivated contributors out there. reply joshuahutt 11 hours agorootparent> Perhaps Wikipedia should have allowed a kind of sub-Wikipedia: a sort of parallel wikipedia that deals in topics more akin to Urban Dictionary entries. It's an interesting idea. I imagine a sort of \"Official\" and \"Unofficial\" modes. You could flip a switch and see the articles and edits that didn't pass muster. That way, the ideas and info wouldn't be lost/censored, but wouldn't get to claim they're \"formally accepted.\" reply jacoblambda 9 hours agorootparentprevAlternatively you could federate it. Maintain wikipedia as the primary instance but allow users to add secondary, wikipedia community vetted wiki instances to their account so that they can seamlessly flow between them. Those instances can serve as \"incubators\" for not sufficiently notable pages and then if they reach notability they can be transferred from the local \"small\" wiki to \"big\" wikipedia without losing any of the internal page information (like discussions or old revisions) or local context (still linking back to the \"small\" wiki). That way you could have the default unlogged-in wikipedia which shows only the officially vetted pages but then also provide a \"wider wikipedia\" that includes pages that are of sufficient quality but not quite there yet. And then your local \"small wikipedia\" pages that don't meet the requirements to move up into the wider network yet. This would maintain coherency between the wikis for the users who care while also allowing the core wikipedia admins and mods to focus their energy on maintaining a tight selection of well established, notable articles. And then users could choose how wide their wikipedia experience is. reply zozbot234 9 hours agorootparent> Alternatively you could federate it. Maintain wikipedia as the primary instance but allow users to add secondary, wikipedia community vetted wiki instances Nowadays, Wikidata is playing that role already. Its concept of \"notability\" is flexible enough that labeled roads or individual Pokemons could handily fit there - if something is described to some minimal extent by a verifiable source, it can go in. Each Wikidata entry can contain links and \"identifiers\" that describe or refer to the same real-world entity in different namespaces, and you can use the Wikidata-specific browser extension Entity Explosion https://www.wikidata.org/wiki/Wikidata:Entity_Explosion to seamlessly browse to other descriptions of any given entity as you browse the web. So the vetted \"secondary\" sources you're talking about don't even need to be wiki-specific, they can be practically anywhere on the web. reply ENGNR 10 hours agorootparentprevI kind of like that it's a different org adjacent to the old one, rather than a subsidiary. \"Wiki\" was always supposed to be software for thousands of various boards on different topics with no hierarchy, it makes sense that some topics would branch out of Wikipedia into their own Wiki's reply yreg 10 hours agorootparentprevWhat do you mean? Wikipedians can cite primary sources. AARoads is such a source. Of course, the person who writes the Wikipedia article should preferably not be the same person who wrote the article being cited. reply classichasclass 9 hours agorootparentThe part that never made sense to me is that the exact same content on Wikipedia is proscribed, but if you put it somewhere else and someone else links to it, it somehow becomes OK. From where I'm sitting, the content is either fine or it's not. A variant of this: you do the research, cite your findings with presumably reliable sources and post it somewhere like a personal blog. Wikipedia doesn't like directly linking to it [0], but if an editor writes the same content and cites the same sources, that's also OK, even though I'd argue that's plagiarism. 0: https://en.wikipedia.org/wiki/Wikipedia:Verifiability#Self-p... reply yreg 9 hours agorootparentMakes perfect sense to me. You are not supposed to write Wikipedia articles on your original research. If you want to help Wikipedia, feel free to write articles based on work that other people did in your field. Don't add any conclusions of your own. Let someone else write the articles on the research that was done by you. I think that is a very reasonable tradeoff. —- > if an editor writes the same content and cites the same sources, that's also OK, even though I'd argue that's plagiarism. An editor should not copy your blog post. They can describe whatever you wrote about and cite your blog post as a source. Or, they can go after the same original sources you have cited and write their own summarizing article (but not copy the blog post, and they also can't add any of their own conclusions). reply classichasclass 8 hours agorootparent> Or, they can go after the same original sources you have cited and write their own summarizing article (but not copy the blog post, and they also can't add any of their own conclusions). That's my point: you've done the legwork, but you don't get credit for it, and as far as Wikipedia's policies are concerned, can't. They aren't supposed to cite your blog as a source, because it's self-published. I've seen many edits citing what I thought were well-researched entries get reverted because \"it's a blog.\" reply zozbot234 8 hours agorootparentThe Wikijournal effort https://en.wikiversity.org/wiki/WikiJournal_User_Group is supposed to plug that gap. If you think you have worthwhile primary research that is up to academic standards, it can be published in WikiJournal after review, and that information can then be referenced in a Wikipedia article. reply Supermancho 8 hours agorootparentprevI don't believe wikipedia considers blog posts published sources (probably because of bitrot). I believe the easiest way to get any specific conclusion/belief/opinion into wikipedia, is to get it published as a book. Then it can be cited as \"alternative\" theory or whatever. reply thriftwy 10 hours agorootparentprevIt's no longer original if it happened on some other website. reply KTibow 13 hours agoprevI find Wikipedia's frontend more enjoyable than AARoads. It's understandable as the community of editors probably wasn't as technical as some other communities, but it feels a bit slow, there's no search, and there are a number of broken links. reply notatoad 12 hours agoparentIt makes sense that the consumption side of the site isn’t as good, since super-niche sites like this are more for the benefit of the writers than the readers. The value and enjoyment is in collecting the information, not retrieving it. And that might sound like a criticism, but it’s really not. Niche interest sites where people spend their time collecting a huge level of detail on a topic few care about are awesome, and I love them. Just realistically, they’re not there for the readers. reply stock_toaster 10 hours agoparentprevAre you talking about the main site landing page? I found the link to the actual wiki[1] in the nav header. [1]: https://wiki.aaroads.com reply KTibow 7 hours agorootparentAh, that's much better. It's still confusing that they're separated. reply RheingoldRiver 14 hours agoprevI mean...this is precisely what's supposed to happen when you have a niche interest? And this is a better situation for them anyway because now they can use some structured data extension (SMW, Cargo,* WikiBase, DPL) specifically tailored to their needs and create a lot more advanced querying/filtering features that are super usable by the average person rather than requiring you to know SPARQL. Wikipedia doesn't support SMW or Cargo (for good reason) but on specific-subject wikis that aren't literally the scale of Wikipedia one of these is pretty much a must-have if the admins are tech-savvy enough to make good use of them. (My recommendation is Cargo but either can work) *no relationship to the Rust package manager, it's a SQL wrapper for MediaWiki I would say the headline here if anything is, \"WikiMedia doesn't support niche-interest wikis that run alongside Wikipedia\" and instead make you either self-host or use a farm (Fandom, Miraheze, Wiki.gg, etc). reply labster 9 hours agoparentI wish that was the headline, because then Miraheze would be notable enough to get an article on Wikipedia. At this point those of us on the board would even like bad press over no press at all. Shameless plug: miraheze.org offers free, ad-free wikis offered by a charitable foundation. reply nemomarx 15 hours agoprevWe already see this with niche things like gaming fandom details (every pokemon used to have a wiki page for a bit, but now that's all properly handled by Bulbapedia) so I wonder why we haven't seen it for more serious topics before? Math, Engineering, CS could all benefit from a good wiki, I'd think. reply dosshell 15 hours agoparentOne problem I encounter with math wiki is that I almost need to know what it is before reading to understand the wiki page. I think wikibooks is a good initiativ to solve this, and could be powerful when combined with a normal wiki. reply jacobolus 13 hours agorootparent> almost need to know what it is before reading to understand the wiki page There is a project page advocating more accessible technical articles, https://en.wikipedia.org/wiki/Wikipedia:Make_technical_artic... In some cases technical subjects just require some pretty steep prerequisite knowledge, but where possible it's nice to try to make them as accessible as can be done practically within the space constraint of a few introductory paragraphs. Usually that means trying to aim at least part of any article at approximately \"1 level below\" the level where students are expected to first encounter the topic in their formal study. (This isn't always accomplished, and feel free to complain on specific pages that fall far short.) Writing for a extremely diverse audience with diverse needs is a hard problem. And more generally, writing well as a pseudonymous volunteer collective is really hard, and a lot of the volunteers just aren't very good writers. Then some topics are politicized, ... How much time have you personally spent trying to make technical articles whose subjects you do know about more accessible to newcomers? If anyone reading this discussion has the chance, please try to chip away at this problem, even if it's just contributing to articles about e.g. high school or early undergraduate level topics – many of these are not accessible at the appropriate level. But if you are an expert about some tricky technical topic in e.g. computing or biology or mechanical engineering, go get involved in fixing it up. reply bee_rider 15 hours agorootparentprevI’m sure it is totally impossible because figuring out where to start (what’s “obvious” to the reader), but a wiki that also has some sort of graph and could work out the dependencies for a given theorem, what you need to know to understand it, and then a couple applications (for examples) could be really useful. Automatic custom textbook on one specific topic. reply jjmarr 15 hours agorootparentLook up Abstract Wikipedia. https://meta.wikimedia.org/wiki/Abstract_Wikipedia It's more or less Wikipedia but the articles are created using natural language generation on a functional programming base. The main goal is to generate content in any language from a common underlying structure, but one could also try recursive explanations of a given topic in that framework as well. reply armchairhacker 14 hours agorootparentprev> One problem I encounter with math wiki is that I almost need to know what it is before reading to understand the wiki page. Case in point, nLab: https://ncatlab.org/nlab/show/HomePage For instance, https://ncatlab.org/nlab/show/homotopy+type+theory Although this is partly inevitable because the content is really abstract, I know there are more approachable ways to define “monad” than https://ncatlab.org/nlab/show/monad reply rightbyte 12 hours agorootparentprevA benefit of knowing a non-english language is that my native language wiki entry usually is a good tldr of the english one. Many of the english math entries seem to be written for math students (as in math program students, not students studying math). reply IshKebab 11 hours agorootparentprevYes Wikipedia is really bad for maths articles. They're all written by people who just learnt about the topic and are showing off their pedantically detailed knowledge of it. I recommend Mathworld. Much much better. reply CM30 15 hours agoparentprevHmm a quick check of Google brought up at least a few wikis about maths: https://math.fandom.com/wiki/Math_Wiki https://encyclopediaofmath.org/wiki/Main_Page And a few about engineering: https://engineering.fandom.com/wiki/Engineering_Wiki Plus a few about computer related topics: https://dataengineering.wiki/Index And various languages and frameworks have wikis too, like Python, PHP, WordPress, etc. So there's definitely some interest in wikis outside of fandom topics. The Wiki listing pages on Wikipedia has at least 30% of the page listing wikis that don't involve a piece of media/fiction: https://en.wikipedia.org/wiki/List_of_wikis I suspect the disparity is probably because hobbies and fandoms could mostly only communicate via the internet, and naturally went from fansites and hobby sites to wikis. Meanwhile more academic subjects have an audience who seem to be unsure of the value of these sorts of free resources. reply alexb_ 13 hours agorootparentFandom is complete and utter SEO garbage - every single fandom with enough nerds to have sense has moved off of it into an actual independent wiki. IndieWikiBuddy is an extension that actually takes fandom websites, and redirects google searches to the actual community run page. https://getindie.wiki/ reply CM30 7 hours agorootparentOh I agree. I like to link to non Fandom wikis when their available, use that same plugin in most browsers, and support things like the Nintendo Independent Wiki Alliance. Sadly quite a few wikis still use the service, and haven't gone independent yet. reply movpasd 11 hours agorootparentprevFor maths, there is also ncatlab. reply jjmarr 15 hours agoparentprevBecause ultimately, Wikipedia's criteria for allowing articles is whether or not the subject of such has sufficient content in reliable secondary sources (like newspapers or academic articles) to base an article on. Otherwise, most of the article is going to be someone's personal opinions or their own research. Most minor American roads and Pokemon don't have that coverage beyond showing they exist and their route. Allowing those articles to be created is a signal that \"there's reliable newspapers or academics covering the history of this highway\" when in truth if a history section is ever added, it's not going to be based on anything beyond what the editor came up with. That is what distinguishes Wikipedia from large language models or Google which'll say they have information on a given topic even if their sources are questionable. The value-add of Wikipedia is curation, and when the quality of one's outputs is a function of one's inputs, it's sometimes better to just not give an output when the input doesn't exist. reply ghaff 15 hours agorootparent>has sufficient content in reliable secondary sources (like newspapers or academic articles) to base an article on Which is, of course, completely ironic. Wikipedia's notability criterion depends heavily on books in some library stack that essentially no one will ever actually check or appearances in other print form that no one will check either. I've found a couple of minor \"folk histories\" of things that appear to not have been true after looking at actual books (which may have not been actually accurate either though they seemed plausible). reply andrewaylett 13 hours agorootparentThere's an opposite irony, too: Wikipedia doesn't want to be a location for original research, but moving the pages out of Wikipedia means they could now be a suitable citation source for articles on Wikipedia. reply Fogest 9 hours agorootparentFrom my understanding this is also sometimes a method used to get fake info on Wikipedia. Get the fake info on a secondary source, then cite that on Wikipedia. reply wlonkly 8 hours agorootparentFor extra irony, get the fake info into Wikipedia long enough that someone uses it, and then use what they wrote as a source to put it into Wikipedia. (There's a WP: page about this problem that I think gives it a name, but I can't find it right now.) Aha, someone else mentioned it in these comments: \"citogenesis\", and it was indeed Randall Munroe's coining, and the meta page is https://www.wikiwand.com/en/Wikipedia:List_of_citogenesis_in... reply Fogest 7 hours agorootparentI've seen this kind of stuff used in some activist style groups as well before. Someone may be trying to push some kind of agenda. While in an argument with someone they link to a Wikipedia article. That Wikipedia articles source ends up linking to the activist groups own site. That site then links to some kind of sketchy or very broad conclusion piece of \"research\" that is unreproducable. So I feel like Wikipedia's rule don't necessarily make their content any more reliable. It just adds a step if you're looking to push some kind of biased/iffy opinion onto a page. reply ghaff 8 hours agorootparentprevAnd it's not just a Wikipedia thing. When I was researching a book a number of years back I found some fairly consistently repeated origin stories which, if you went back to some older books, basically weren't the whole story. reply ghaff 9 hours agorootparentprevThere's an XKCD cartoon in that vein. Best to get it in print somewhere but getting information onto what is a plausibly credible source is better than nothing with respect to getting it into Wikipedia via a citation. reply Angostura 15 hours agorootparentprevNot really ironic, because they can be checked. reply ghaff 15 hours agorootparentAs a practical matter however... Almost no one's going to visit the $SMALLTOWN historical society and do so. They're going to do a web search. reply tux3 14 hours agorootparentThat's part of why digital libraries are important! Wikipedia has its own \"Wikipedia Library\", which is a system to allow active editors access to high-quality sources. But if it has to be resorting to Sci-Hub or libgen to check sources for Wikipedia, that's also a form of public service. reply starkparker 9 hours agorootparentActive _non-anonymous_ editors. Anonymous editors can't access TWL. reply jjmarr 6 hours agorootparentIt relies on databases donating access to Wikipedia editors. There are other restrictions too. Most of the stuff in TWL can be accessed with a university library card that many alumni are eligible for. reply snowfield 14 hours agorootparentprevSomeone has probably checked them at some point. And that's good enough for me reply toyg 12 hours agorootparentNot if that someone was a neofascist with an agenda to rewrite relatively minor history. Sadly that happens, and it happens a lot more than most people realize. It's way too easy to fake a reputation on Wikipedia. reply ajkjk 15 hours agoparentprevI think about trying to start a math and physics wiki all the time. Basically it needs to keep track of as many major results and link them all to each other and map between their terminologies. It is so exhausting that so many results are hiding in papers from other subfields that use slightly different notations and terminology so you can't find easily find them. reply ryukoposting 15 hours agoparentprevIt seems to me that the line has been drawn at perceived academic interest. \"Notability\" is highly context-dependent, but I find that it's easier to identify Wikipedia's line of notability when you consider the potential academic usefulness of a particular article. Minutae of science, history, mathematics, etc seem more likely to be \"academically significant\" than a county road in Michigan, or a Pokemon. When I was a kid, I was taught to reject Wikipedia as an academic source. I know I'm not the only one. Part of me wonders if their present moderation is influenced by that. reply jacobolus 13 hours agorootparent> taught to reject Wikipedia as an academic source What ends up happening is people (including academics in published work) still use Wikipedia as a source, but just don't mention it. This is much worse than just citing Wikipedia, because it can lead to \"citogenesis\", whereby a claim that originated (without evidence) in Wikipedia is then given credibility by being republished elsewhere. Sorting out what happened later is a huge pain, and many examples slip through the cracks. Overall, Wikipedia should be taken for what it is: a moderately inconsistent tertiary source written by pseudonymous volunteers some of whom are dispassionate world-class experts and others of whom are incompetent amateurs, ideologues, or trolls. However, what I've found tracking down lots of Wikipedia claims over the years is that Wikipedia is on average no less reliable than many other kinds of sources that are taken more seriously, including paper encyclopedias and peer-reviewed journal articles (and don't get me started on newspaper articles). Every source and author should be carefully evaluated for credibility and read with at least some skepticism. reply kjkjadksj 15 hours agoparentprevFor a lot of these fields researchers already feel like they are contributing to the community by writing manuscripts. Making a wiki of that written for lay people is a fruitless waste of time, wikipedia entries are good enough for lay people and people in the field would probably rather read a legitimate review article with 150 sources. reply bawolff 15 hours agoparentprev> Math, Engineering, CS could all benefit from a good wiki, I'd think. There are some specialized ones like https://complexityzoo.net/Complexity_Zoo reply StevenXC 14 hours agoparentprevhttps://Topology.pi-base.org (a database of certain mathematical objects) started as a wiki, but transitioned to using GitHub pull requests and custom software to support automated deduction. Folks interested in open collaborative math content may find these interesting: - https://code4math.org/ - https://mathbases.org/ reply epivosism 14 hours agoprevI recently have been thinking about UGC site in general, and it seems like they generally go two ways: 1. Allow most legal content to be uploaded and control distribution with algos YouTube, Roblox, Twitter, Tinder, Flickr, Insta, FB, TikTok. This lets users practice and test things without risk to their work or account. 2. Sites that try to \"keep the db clean\" by nuking stuff they think is \"bad\" by some criteria. Sites like this: Wikipedia, most big subreddits Type 2 sites can be unsustainable because they tend to make new users feel judged, and don't give them the chance to iterate and improve their work until it's more ready to be shared and useful to a broader audience. You just find your content nuked, or removed from the subreddit, or downvoted a ton, often with a dismissive or aggressive comment. This is NOT the way to grow and survive as a company over a long period of time Obviously, there is no necessity to keep the db full of only high quality items. As the scope and number of niches a site covers, it's not possible to maintain that. On the other hand, using algos lets you do interactive tests with content, directly testing against various audiences to see if they like it, without having to do editorial work yourself. Of course, there has to be some limit - articles for every pokemon, or every version of every pokemon, etc at some point it does get too far. The thing for me is coming in and seeing your content completely deleted. reply starkparker 9 hours agoparent> 2. Sites that try to \"keep the db clean\" by nuking stuff they think is \"bad\" by some criteria. The problem on Wikipedia is less about having standards and more about having changing interpretations of fundamental standards re-classify large swaths of previously acceptable content as unacceptable. The trend away from subject-specific notability and sourcing guidelines to applying one notability guideline generically to every subject, regardless of the intent in doing so, mostly just gives editors who like to delete things a whole new buffet of articles to tear through. reply epivosism 3 hours agorootparentI'd definitely agree that changes like that intensify the issue! For me as an amateur contributor, though, even the normal experience was tough - suddenly I returned to find my content removed, with a short, aggressive note, left by what wasn't a committee, or a jury, but rather a single, annoyed and tired individual, who in his seniority was somehow justified in unilaterally acting alone to delete my work, without the careful attention to detail in documents, wording, and formality which helps make real-world justice palatable. The carelessness with which he wrote made it clear that at that site, I was to be considered a person of very little value at all. To speak more clearly, that was the social/psychological effect of it - which left me without much motivation to continue! And I think that's a wide effect - if you compare a typical 1st-time wikipedia editing experience to the more successful UGC sites, it's pretty clear they all make some effort to shield users from that (if they can) and let them feel successful, even if they aren't yet. (I know from the inside of one of these places that users get mad at for removing their creations for copyright or other reasons, all of us on the inside hated potentially frustrating a creator, and admired them for trying over and over to create something.) Moreover, from what I've heard, there used to be more freedom on wikipedia, so the argument that \"it's always been that way\" might not even work. reply ryandrake 11 hours agoparentprevUsing those definitions there are really no type 1 sites except maybe 4chan, which itself even lightly moderates. All the other sites you mention heavily moderate and most of them automate that moderation. You really can’t have a site that’s a free-for-all because of spammers, griefers, racists, and other various forms of jerks. reply epivosism 4 hours agorootparentYes, I didn't break them out but I do consider some types of basic filtering to be legitimate because they're both common across cultures, and their limits can be described fairly precisely. These are things such as prohibitions on political, ethnic or religious conflict, criminal activities, nudity, and of course, copyright. Actually, treating censorship of those things as the default global level of censorship makes the difference between restrictive sites like Wikipedia and the rest of the Internet even more stark. It's almost unimaginable that YouTube would remove a creators content simply because they thought the topic was irrelevant, or the quality too low. So I agree we can't have a true free for all online. But the distinction between the large group of UGC sites that really try to cultivate and protect their creators from those that don't is reflected in the popularity and growth rates of them all. reply itishappy 13 hours agoparentprevI may be missing your point, but Wikipedia and most big subreddits have proven quite effective at growing and surviving. I'd also suggest a major distinction between type 1 and type 2 sites are a focus on creation vs consumption. There's a lot more consumers than producers and, depending on your goals, it might improve the experience for more users by deleting the content of some. reply epivosism 12 hours agorootparentI have heard the editor count at Wikipedia has been shrinking for years. Might have been wrong though reply yorwba 11 hours agorootparentMonthly active editor count peaked in 2007 and then started declining, but has been quite stable since about 2014: https://stats.wikimedia.org/#/en.wikipedia.org/contributing/... reply epivosism 2 hours agorootparentThat matches what I would expect. My normal continuation would be to look at the growth from 2014 til now in global internet users, and at the competitors like youtube, insta, etc. I'd expect to find that many of these sites grew 100 or 1000x, and that the global online population whose device power and internet service levels surpass some threshold has also grown by at 10x since then. Those are all assumptions and memories from working during that time period - possibly wrong, would look up if you disagree. But if you don't, then my conclusion would be that staying flat during a period like that - when you could have grown and supported a deep, new, persuasive trend of literacy, fact-based reasoning and understanding, education and compromise - is a huge failure. reply yorwba 9 minutes agorootparentThere were 2.79 billion internet users in 2014 https://ourworldindata.org/grapher/number-of-internet-users?... so the number couldn't have grown 10x because there are no 27.9 billion humans yet. The latest data is from 2020, so maybe it's at least 2x what it was in 2014. Most of those new internet users are in Asia and do not use English as their primary language. If you look at editor counts of other Wikipedia editions; Hindi https://stats.wikimedia.org/#/hi.wikipedia.org/contributing/... , Indonesian https://stats.wikimedia.org/#/id.wikipedia.org/contributing/... , Thai https://stats.wikimedia.org/#/th.wikipedia.org/contributing/... , Persian https://stats.wikimedia.org/#/fa.wikipedia.org/contributing/... kept growing after the English Wikipedia saturated. reply devmor 12 hours agorootparentprev>most big subreddits have proven quite effective at growing and surviving. That depends on your criteria. If popularity and user engagement are the only important metrics, this is absolutely true. If however, clarity of purpose and effective moderation are important, I would strongly disagree. From my experience, most big subreddits that used to fulfill a certain niche have devolved into primarily meta-posting and stealth (or not stealth at all) advertisement. Of the exceptions to the above, many now just fill the exact same purpose. There are around 10 extremely large subreddits that regularly make the front page that are essentially just \"look at this picture of something I have/something I saw\" with no real boundary between them. reply kiba 12 hours agoparentprevModeration is a must or else there will be rampant misinformation and hate speech. Reddit is fine but it's not really operable as a business enterprise unless you are fine with making a small tiny profit over long period of time. Subreddits are a self solving problem over time. They grow big and shrink on their own merits and damage is self contained. reply arjie 15 hours agoprevThis is a great idea, I think. Mediawiki is very good about allowing multiple sites and since interwiki links are bundled in you can just link Wikipedia pages like they’re local to the wiki. I actually use Mediawiki for my blog. reply starkparker 9 hours agoprevI'll point back to a previous comment where AARoads came up: https://news.ycombinator.com/item?id=37957549 It's very G/O Media-clickbaity to call this \"going rogue\". The editors aren't subverting anything. This isn't the first and won't be the last fork of a Wikipedia community over the increasingly tightened, deletionism-favoring screws of notability and sourcing policies. The only people \"going rogue\" are the organized groups on Wikipedia moving across wildly different topics in order to hammer them all into one uniform shape that serves nobody as well as it had or could. EDIT: The Gizmodo article doesn't link to the US Roads group's own rationale for leaving, which fills in some gaps from the rather low-content article. https://en.wikipedia.org/wiki/Wikipedia:WikiProject_U.S._Roa... > Since August 2022, our project has faced several external challenges that made several members question the viability of editing on Wikipedia in ways that Covid-19 didn't. The notability of highway articles in general became a focus of New Page Patrollers. Additionally, the ability to continue using maps as sources was called into question. Since then, we initiated an RfC to clarify if there was support for long-standing citation practices, namely could we continue to cite maps as sources in our articles? The results of that RfC were mixed. While chatting amongst ourselves online, it became clear that continuing to hope that another RfC or deletion discussion would go our way was an exercise in futility. In the background to all of this, other categories of articles were on the chopping block. First it was articles on Olympic athletes, and then it was cricket and area code articles. reply Macha 14 hours agoprevTheir name might get them in trouble with the AA, a UK and Ireland insurance company who has products such as AA Roadwatch. Other than that potential future problem, this is pretty much the system working as intended, and they're following the path led by sites such as Wookiepedia. reply jkaplowitz 11 hours agoparentThe site these former Wikipedia editors are joining has existed since 2000, is primarily US-focused, and is named after two people in the US with first names beginning with A: https://www.aaroads.com/about/ So this new migration shouldn't affect that site's legal risk from the UK and Ireland company, which seems pretty low anyway given that context. reply bobthepanda 10 hours agoparentprevI feel like if there were to be a problem, it would be with the American AAA instead, which is probably more similar given that it offers roadside assistance and other road services. reply timthorn 10 hours agoparentprevIt's sad that you describe the AA as an insurance company - you're not wrong, but that throws the contrast between today's AA and its venerable past into sharp relief. reply ghaff 15 hours agoprevI mean, it makes sense. There's an incredible rabbit's hole of detail on certain topics that probably doesn't belong on what purports to be a general purpose encyclopedia. Honestly a lot of mathematics etc. that is more or less worthless to people who aren't already experts in the area could probably use their own space too. reply flomo 15 hours agoparentYeah, I'm a 'roadgeek' and I thought many of the highway pages were overly verbose trivia. Long route descriptions clearly just taken from a map, random citations about ditch work in 2014 etc. Very little history or substance. reply whatshisface 15 hours agoparentprevI don't understand why something being worthless to you makes it inappropriate to have on an encyclopedia we both read. reply ghaff 15 hours agorootparentAt some point, a general purpose reference can get overwhelmed by specialized minutiae. I'm generally in the inclusionist camp with respect to Wikipedia, but I also don't think it's really an appropriate vessel for all of possible human knowledge. Which implies there is some line. So an article on the Big Dig is probably appropriate but not the blow by blow history of some country road. reply im3w1l 15 hours agorootparentHiding irrelevant details from people that don't care about them is just a UI-puzzle that should be possible to solve imho. reply ghaff 15 hours agorootparentJust a simple matter of programming. And now you're asking for an algorithm to decide what you can see and not see. reply whatshisface 14 hours agorootparentHow about the people who click on \"homeomorphism\" see an article on homeomorphisms and the people who click on \"Route 48\" see an article on Route 48? reply thfuran 14 hours agorootparentIs the article on route 48 meant to be a 500,000 word treatise on its history including every work order involved in its construction and maintenance as well as discussion of the procurement process for the paints used for its lines, or can some of that maybe be elided? Would you expect the article on homeomorphisms to include a list of every homeomorphism every described, suggested, defined, or posited? reply whatshisface 14 hours agorootparentWikipedia has a couple of devices to solve this organizational problem: \"full article\" links that appear at the top of sections, and \"list of X\" pages. So in your examples, you'd have a three-sentence \"History\" section on the Route 48 page, with a link to the full article on the history of Route 48 at the top. For your second example, there would be a \"see also\" section at the bottom of the article, including a hyperlink to \"List of Homeomorphisms.\" reply vvillena 13 hours agorootparentprevA lot of that content that is deemed \"not Wikipedia worthy\" ends up in Fandom, a for-profit wiki host also started by Jimmy Wales. reply advisedwang 15 hours agorootparentprevRisks of too much low interest data in wikipedia include: * Not enough interest to update wiki when the subject changes; then wiki becomes out of date and unreliable. * Too few eyeballs allows false information to be added (accidentally or intentionally) * Becomes harder to do wiki-wide changes (of course it's inevitably too large for manual wiki-wide changes, but you can imagine more articles means more corner cases will be hit that will get automation mistakes or require more complex automation. Think info-boxes used in novel ways etc) reply whatshisface 15 hours agorootparentThe first two are arguments against letting an individual write a single article about a unique topic, not against allowing a vibrant community of people with special interests document them in a public reference. The third could be solved by only deleting pages that use the wiki language in unmaintainable ways. reply bawolff 15 hours agorootparentprevA lot of making a high quality resource comes down to editing. Making sure you don't just include what you need but also remove what you don't. It is impossible to satisfy everyone, which is why i think it is a good thing to separate out to different resources when different groups want different things. reply whatshisface 15 hours agorootparentDeleting text from a page I can understand, but the context of this discussion is the deletion of thousands of pages. reply lavajava 15 hours agorootparentprevI think the difficulty arises from finding a balance between a baseline that appeals to a general audience and an extensive repository for expert reference. Sifting through large Wikis can be daunting and discourage viewership. There is even an acronym for this: TL;DR https://en.m.wikipedia.org/wiki/Wikipedia:Too_long%3B_didn%2... reply kortilla 8 hours agorootparentWikipedia supports more than one article. It’s dumb to not have related articles about specific details. reply add-sub-mul-div 15 hours agorootparentprevIt's more the Wikipedia leadership that would have to be convinced. And looking at it that way, is it safe for all human knowledge to be gatekept by a single group? reply Waterluvian 15 hours agoprevIf anyone wants to produce digital work about anything, there should be a home for that. Perhaps it doesn’t belong in Wikipedia, but maybe there’s like a “Wikipedia Open” sibling website that clearly communicates a lower standard of quality, relevance, curation, but generally ignores those requirements. Where I can write up my grandma’s cookie recipe without having to manage my own website. “I think this is relevant. Here you go, world. Do with it what you may.” reply tomjakubowski 15 hours agoparentYou're free to add grandma's recipe to Wikibook's Cookbook. https://en.m.wikibooks.org/wiki/Cookbook:Table_of_Contents reply Waterluvian 15 hours agorootparentOooh this is exactly what’s on my mind. Awesome. reply tomjakubowski 15 hours agorootparentWikibooks is a looser environment than Wikipedia for sure. I think you could probably start a book about anything there. reply bawolff 15 hours agoparentprevThat sounds like everything2 https://everything2.com/ reply ghaff 13 hours agoparentprevYou can create your own website. reply ginko 14 hours agoprevI still think Wikipedia's focus on significance was a historic mistake. At the very least there should have been an \"extended\" Wikipedia+ that strived to include all human knowledge no matter how trivial. Not having this meant for-profit companies like Wikia (now fandom.com) could take over much of that space, pervasive tracking and ads included. reply chriskanan 13 hours agoparentI 100% agree. They also apply rules inconsistently, where the handful of times I've tried to make an article on well-known scientists (h-index 70+) years ago, the editors rejected it despite some secondary sources. On the other hand there are many articles being created by some editor on scientists who have almost no track record. Wikipedia is already one of the best data sources for training LLMs, and if they were less stringent, it could even be a better resource. reply racked 7 hours agoprevDutch speakers have enjoyed such a wiki for a long time already: WegenWiki https://www.wegenwiki.nl/Hoofdpagina The UK's got SABRE: https://www.sabre-roads.org.uk/wiki/index.php?title=Main_Pag... reply tomcam 9 hours agoprevI’m getting on in years and am deeply disappointed I was never characterized as a rogue in public reply _aleph2c_ 15 hours agoprevIf you think this is interesting, see what happens when you try and edit the page of Susan Gerbic; the leader of the Guerilla Skeptics. She runs a gang of over 150 Wikipedia members who have taken over 1500+ articles. They are like the deletionist described in the article, but operate as an open conspiracy advancing an atheist-materialist point of view. They actively recruit new members, run them through extensive training about the Wikipedia ecosystem and how to dominate it as a team. reply jumelles 11 hours agoparenthttps://www.wired.com/story/guerrilla-wikipedia-editors-who-... They seem to defend against conspiracy theories and falsehoods. Why are you calling them a \"gang\"? What are the \"dominating\"? Why is this bad? reply _aleph2c_ 9 hours agorootparentThat article was written in 2018, since then they have been trashing on a retired admiral: Timothy Gallaudet. They have been disparaging David Grusch, who spoke under oath to the American congress and have undone the work of Nobel laureates trying to edit pages about physics. And yes, they are dominating, a team of editors will beat out an individual contributor on Wikipedia. I don't really care about their position, but they are an open conspiracy, and it's an interesting story. reply layer8 15 hours agoprevJust to be pedantic: They started a separate wiki (that isn’t really in competition with Wikipedia), not a “competing Wikipedia” (which is the name of a specific wiki). reply john-radio 15 hours agoparentAnd while we're being pedantic: > The dispute came down to some of Wikipedia’s most sacred tenants. Anyone can edit Wikipedia... Tenets! reply dtgriscom 13 hours agorootparentPerhaps it was quickly fixed, but it says \"tenets\" now. reply aqme28 14 hours agoparentprevRight. If it's a field that Wikipedia refuses to engage in, then by definition it can't be a competitor. reply layer8 14 hours agorootparentAARoads is not a competitor to Wikipedia because it doesn’t try to be a general-purpose encyclopedia. Similar to how HN is not a Reddit competitor. They have different goals and thus complement each other. reply Sharlin 11 hours agoprevIsn’t \"a competing Wikipedia that’s only about X\" just called… a wiki? reply thih9 10 hours agoprevThe title seems a stretch; an encyclopedia about roads is hardly competing with Wikipedia. In fact that was the point, Wikipedia didn’t want that content in the first place. reply ern 11 hours agoprevWikipedia seems to have a growing contingent of editors from countries like India, the Phillipines and Sri Lanka who edit topics that seemingly have little to do with those countries. To establish their credentials, they get involved in arcane areas like Articles for Deletion or other areas that you’d expect would be of more interest to experienced editors. Now everyone has the right to edit anything on Wikipedia, but it’s starting to feel like paid editors have gained a foothold. reply thih9 10 hours agoprevWhat’s the point of not allowing that content on Wikipedia? I get that some topics are less important or have lower quality sources, but the cost of adding them seems relatively low. Personally I would enjoy seeing all kinds of fandom articles on Wikipedia, roads included. reply exitb 10 hours agoparentSomething that I see on OpenStreetMap - someone gets motivated and maps a neighborhood in an incredible detail down to the last tree, bench and trashcan, but not motivated enough to actually update the changes over the years, leading to the map being wrong and untrustworthy. reply quickthrower2 10 hours agoprevIs it reasonable to expect Wikipedia to index all the things? A road that has never been written about. Openstreetmap is a seperate entity, and that makes perfect sense. So is Github. Do you need an article for every file in the Linux kernel too? reply none_to_remain 14 hours agoprev [3 more] [flagged] dtgriscom 13 hours agoparent [–] /s? Wikipedia has plenty of money these days. reply Dylan16807 4 hours agorootparent [–] Are you honestly unsure whether it's sarcasm? It's hard for me to imagine how. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The US Roads Project, a group of Wikipedia editors focusing on US roads, split from Wikipedia to AARoads due to disagreements on sourcing standards.",
      "Conflict arose over defining valid sources, with some supporting stricter rules and others favoring more flexible guidelines.",
      "Departure of the US Roads Project from Wikipedia resulted in the resignation of some editors; members may consider returning to Wikipedia in the future."
    ],
    "commentSummary": [
      "The debate revolves around establishing a distinct platform on Wikipedia for less formal or less prominent content through ideas like parallel Wikipedia versions or federating the existing platform.",
      "Discussions encompass citing sources, segregating niche interest wikis from mainstream Wikipedia, hurdles for novice contributors, and utilizing Wikipedia as a tertiary source.",
      "Topics include censorship, moderation, handling extraneous specifics, and the impact of specific editors on content, emphasizing the importance of non-fandom wikis, precise digital libraries, and shedding light on Wikipedia's constraints."
    ],
    "points": 136,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1709386752
  },
  {
    "id": 39577164,
    "title": "Generating Transparent Images with Latent Transparency in SD WebUI",
    "originLink": "https://github.com/layerdiffusion/sd-forge-layerdiffusion",
    "originBody": "sd-forge-layerdiffusion (update Feb29: the name of this repo will change to \"sd-forge-layerdiffuse\" at Mar 3) Transparent Image Layer Diffusion using Latent Transparency This is a WIP extension for SD WebUI (via Forge) to generate transparent images and layers. The image generating and basic layer functionality is working now, but the transparent img2img is not finished yet (will finish in about one week). This code base is highly dynamic and may change a lot in the next month. If you are from professional content creation studio and need all previous results to be strictly reproduced, you may consider backup files during each update. Before You Start Because many people may be curious about how the latent preview looks like during a transparent diffusion process, I recorded a video so that you can see it before you download the models and extensions: screen_record.mp4 You can see that the native transparent diffusion can process transparent glass, semi-transparent glowing effects, etc, that are not possible with simple background removal methods. Native transparent diffusion also gives you detailed fur, hair, whiskers, and detailed structure like that skeleton. Model Notes Note that all currently released models are for SDXL. Models for SD1.5 may be provided later if demanded. Note that in this extension, all model downloads/selections are fully automatic. In fact most users can just skip this section. Below models are released: layer_xl_transparent_attn.safetensors This is a rank-256 LoRA to turn a SDXL into a transparent image generator. It will change the latent distribution of the model to a \"transparent latent space\" that can be decoded by the special VAE pipeline. layer_xl_transparent_conv.safetensors This is an alternative model to turn your SDXL into a transparent image generator. This safetensors file includes an offset of all conv layers (and actually, all layers that are not q,k,v of any attention layers). These offsets can be merged to any XL model to change the latent distribution to transparent images. Because we excluded the offset training of any q,k,v layers, the prompt understanding of SDXL should be perfectly preserved. However, in practice, I find the layer_xl_transparent_attn.safetensors will lead to better results. This layer_xl_transparent_conv.safetensors is still included for some special use cases that needs special prompt understanding. Also, this model may introduce a strong style influence to the base model. layer_xl_fg2ble.safetensors This is a safetensors file includes offsets to turn a SDXL into a layer generating model, that is conditioned on foregrounds, and generates blended compositions. layer_xl_fgble2bg.safetensors This is a safetensors file includes offsets to turn a SDXL into a layer generating model, that is conditioned on foregrounds and blended compositions, and generates backgrounds. layer_xl_bg2ble.safetensors This is a safetensors file includes offsets to turn a SDXL into a layer generating model, that is conditioned on backgrounds, and generates blended compositions. layer_xl_bgble2fg.safetensors This is a safetensors file includes offsets to turn a SDXL into a layer generating model, that is conditioned on backgrounds and blended compositions, and generates foregrounds. vae_transparent_encoder.safetensors This is an image encoder to extract a latent offset from pixel space. The offset can be added to latent images to help the diffusion of transparency. Note that in the paper we used a relatively heavy model with exactly same amount of parameters as the SD VAE. The released model is more light weighted, requires much less vram, and does not influence result quality in my tests. vae_transparent_decoder.safetensors This is an image decoder that takes SD VAE outputs and latent image as inputs, and outputs a real PNG image. The model architecture is also more lightweight than the paper version to reduce VRAM requirement. I have made sure that the reduced parameters does not influence result quality. Below models may be released soon (if necessary): A model that can generate foreground and background together (using attention sharing similar to AnimateDiff). I put this model on hold because of these reasons: (1) the other released models can already achieve all functionalities and this model does not bring more functionalities. (2) the inference speed of this model is 3x slower than others and requires 4x more VRAM than other released model, and I am working on reducing the VRAM of this model if necessary. (3) This model will involve more hyperparameters and if demanded, I will investigate the best practice for inference/training before release it. this model is confirmed to be released soon with joint layer generating and one-step bg/fg-condition, after we finish the final VRAM optimization The current background-conditioned foreground model may be a bit too lightweight. I will probably release a heavier one with more parameters and different behaviors (see also the discussions later). Because the difference between diffusers training and k-diffusion inference, I can observe some mystical problems like sometimes DPM++ will give artifacts but Euler A will fix it. I am looking into it and may provide some revised model that works better with all A1111 samplers. Sanity Check We highly encourage you to go through the sanity check and get exactly same results (so that if any problem occurs, we will know if the problem is on our side). The two used models are: https://civitai.com/models/133005?modelVersionId=198530 Juggernaut XL V6 (note that the used one is V6, not v7 or v8 or V9) https://civitai.com/models/261336?modelVersionId=295158 anima_pencil-XL 1.0.0 (note that the used one is 1.0.0, not 1.5.0) We will first test transparent image generating. Set your extension to this: an apple, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 5, Seed: 12345, Size: 1024x1024, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Make sure that you get this apple woman, messy hair, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 5, Seed: 12345, Size: 1024x1024, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Make sure that you get the woman with hair as messy as this a cup made of glass, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 5, Seed: 12345, Size: 1024x1024, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Make sure that you get this cup glowing effect, book of magic, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 1024x1024, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: True, layerdiffusion_bg_image: False, layerdiffusion_blend_image: True, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b make sure that you get this glowing book OK then lets move on to a bit longer prompt: (this prompt is from https://civitai.com/images/3160575) photograph close up portrait of Female boxer training, serious, stoic cinematic 4k epic detailed 4k epic detailed photograph shot on kodak detailed bokeh cinematic hbo dark moody Negative prompt: (worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3) Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Anime model test: girl in dress, high quality Negative prompt: nsfw, bad, ugly, text, watermark Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 7ed8da12d9, Model: animaPencilXL_v100, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b (I am not very good at writing prompts in the AnimagineXL format, and perhaps you can get better results with better prompts) Background Condition First download this image: then set the interface with then set the parameters with old man sitting, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: From Background to Blending, layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: False, layerdiffusion_bg_image: True, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Then set the interface with (you first change the mode and then drag the image from result to interface) Then change the sampler to Euler A or UniPC or some other sampler that is not dpm (This is probably because of some difference between diffusers training script and webui's k-diffusion. I am still looking into this and may revise my training script and model very soon so that this step will be removed.) FAQ: OK. But how can I get a background image like this? You can use the Foreground Condition to get a background like this. We will describe it in the next section. Or you can use old inpainting tech to perform foreground removal on any image to get a background like this. Wait. Why you generate it with two steps? Can I generate it with one pass? Two steps allows for more flexible editing. We will release the one-step model soon if necessary, but that model is 2x larger and requires 4x larger VRAM, and we are still working on reducing the computation requirement of that model. (But in my tests, the current solution is better than that model in most cases.) Also you can see that the current model is about 680MB and in particular I think it is a bit too lightweight and will soon release a relatively heavier model for potential stronger structure understanding (but that is still under experiments). Foreground Condition First we generate a dog a dog sitting, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: Only Generate Transparent Image (Attention Injection), layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: True, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b then change to From Foreground to Blending and drag the transparent image to foreground input. Note that you drag the real transparent image, not the visualization with checkboard background. Make sure tou see this then do this a dog sitting in room, high quality Negative prompt: bad, ugly Steps: 20, Sampler: DPM++ 2M SDE Karras, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: From Foreground to Blending, layerdiffusion_weight: 1, layerdiffusion_ending_step: 1, layerdiffusion_fg_image: True, layerdiffusion_bg_image: False, layerdiffusion_blend_image: False, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b Then change mode, drag your image, so that (Note that here I set stop at as 0.5 to get better results since I do not need the bg to be exactly same) Then change the sampler to Euler A or UniPC or some other sampler that is not dpm (This is probably because of some difference between diffusers training script and webui's k-diffusion. I am still looking into this and may revise my training script and model very soon so that this step will be removed.) then do this room, high quality Negative prompt: bad, ugly Steps: 20, Sampler: UniPC, CFG scale: 7, Seed: 12345, Size: 896x1152, Model hash: 1fe6c7ec54, Model: juggernautXL_version6Rundiffusion, layerdiffusion_enabled: True, layerdiffusion_method: From Foreground and Blending to Background, layerdiffusion_weight: 1, layerdiffusion_ending_step: 0.5, layerdiffusion_fg_image: True, layerdiffusion_bg_image: False, layerdiffusion_blend_image: True, layerdiffusion_resize_mode: Crop and Resize, Version: f0.0.17v1.8.0rc-latest-269-gef35383b",
    "commentLink": "https://news.ycombinator.com/item?id=39577164",
    "commentBody": "Generating transparent images using Stable Diffusion XL (github.com/layerdiffusion)135 points by tracyhenry 9 hours agohidepastfavorite8 comments vunderba 8 hours agoThe partial alpha blending support for translucent materials is really cool (glass, plastic, etc). I'd be curious to see how well this plays with inpainting. Apparently img2img is also on the authors todo list. reply jasonjamerson 6 hours agoparentGood AI rotoscoping is welcome any time. reply amluto 8 hours agoprevLooking at the “woman, messy hair, high quality” image, the hair farther from her head looks wrong in much the way that iPhone portrait mode messes up hair. I wonder if this is an example of an AI training on partially AI-generated data and reproducing its artifacts. reply GaggiX 8 hours agoprevPaper: https://arxiv.org/abs/2402.17113 The author Lvmin Zhang is the same person behind ControlNet. reply teapourer 8 hours agoparentAlso the creator of Fooocus, the open source version of Midjourney. It’s amazing how much one person can contribute to a field in such a short span of time. reply msp26 8 hours agoparentprevIt's amazing how much they've contributed to imagegen. I started using forge recently and it's a great speedup from regular sd-webui. https://github.com/lllyasviel/stable-diffusion-webui-forge reply swyx 9 hours agoprevreactions 1 - the way the dog at the end gets a reflection off the floor is pretty nice. 2 - i wonder how this compares in terms of latency/complexity with a comfyui pipeline that just does a typical edge detection/masking layer to achieve the transparency effect. however i dont think that method would work with the glass example as shown reply dannyw 9 hours agoprev [–] Apache 2.0, the beauty of open source. Nice. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The document introduces a work-in-progress extension for SD WebUI that produces transparent images and layers with latent transparency.",
      "It includes model releases for SDXL, instructions on generating transparent images using specific models, and plans to optimize and launch new models.",
      "Recommendations cover modifying samplers and model settings, along with updates on the sampler adjustments for the model."
    ],
    "commentSummary": [
      "Users are discussing the use of Stable Diffusion XL for creating transparent images, highlighting its effectiveness with translucent materials and its potential applications in inpainting and AI rotoscoping.",
      "The author, Lvmin Zhang, known for their work in image generation and AI, is behind the software, with previous projects ControlNet and Fooocus receiving mentions.",
      "The open-source aspect of the software is praised, with users drawing comparisons to other techniques and acknowledging its versatility in different image processing activities."
    ],
    "points": 135,
    "commentCount": 8,
    "retryCount": 0,
    "time": 1709425665
  },
  {
    "id": 39578248,
    "title": "US Health Payment Processor Hit by Ransomware, Prescription Market Impacted",
    "originLink": "https://arstechnica.com/security/2024/03/us-prescription-market-hamstrung-for-9-days-so-far-by-ransomware-attack/",
    "originBody": "RX CHAOS — US prescription market hamstrung for 9 days (so far) by ransomware attack Patients having trouble getting lifesaving meds have the AlphV crime group to thank. Dan Goodin - 3/1/2024, 9:59 PM Enlarge Getty Images reader comments 118 Nine days after a Russian-speaking ransomware syndicate took down the biggest US health care payment processor, pharmacies, health care providers, and patients were still scrambling to fill prescriptions for medicines, many of which are lifesaving. On Thursday, UnitedHealth Group accused a notorious ransomware gang known both as AlphV and Black Cat of hacking its subsidiary Optum. Optum provides a nationwide network called Change Healthcare, which allows health care providers to manage customer payments and insurance claims. With no easy way for pharmacies to calculate what costs were covered by insurance companies, many had to turn to alternative services or offline methods. The most serious incident of its kind Optum first disclosed on February 21 that its services were down as a result of a “cyber security issue.” Its service has been hamstrung ever since. Shortly before this post went live on Ars, Optum said it had restored Change Healthcare services. “Working with technology and business partners, we have successfully completed testing with vendors and multiple retail pharmacy partners for the impacted transaction types,” an update said. “As a result, we have enabled this service for all customers effective 1 pm CT, Friday, March 1, 2024.” AlphV is one of many syndicates that operates under a ransomware-as-a-service model, meaning affiliates do the actual hacking of victims and then use the AlphV ransomware and infrastructure to encrypt files and negotiate a ransom. The parties then share the proceeds. In December, the FBI and its equivalent in partner countries announced they had seized much of the AlphV infrastructure in a move that was intended to disrupt the group. AlphV promptly asserted it had unseized its site, leading to a tug-of-war between law enforcement and the group. The crippling of Change Healthcare is a clear sign that AlphV continues to pose a threat to critical parts of the US infrastructure. Advertisement “The cyberattack against Change Healthcare that began on Feb. 21 is the most serious incident of its kind leveled against a US health care organization,” said Rick Pollack, president and CEO of the American Hospital Association. Citing Change Healthcare data, Pollack said that the service processes 15 billion transactions involving eligibility verifications, pharmacy operations, and claims transmittals and payments. “All of these have been disrupted to varying degrees over the past several days and the full impact is still not known.” Optum estimated that as of Monday, more than 90 percent of roughly 70,000 pharmacies in the US had changed how they processed electronic claims as a result of the outage. The company went on to say that only a small number of patients have been unable to get their prescriptions filled. Further Reading Colonial Pipeline resumes operations after ransomware prompted closure The scale and length of the Change Healthcare outage underscore the devastating effects ransomware has on critical infrastructure. Three years ago, members affiliated with a different ransomware group known as Darkside caused a five-day outage of Colonial Pipeline, which delivered roughly 45 percent of the East Coast's petroleum products, including gasoline, diesel fuel, and jet fuel. The interruption caused fuel shortages that sent airlines, consumers, and filling stations scrambling. Numerous ransomware groups have also taken down entire hospital networks in outages that in some cases have threatened patient care. AlphV has been a key contributor to the ransomware menace. The FBI said in December the group had collected more than $300 million in ransoms. One of the better-known victims of AlphV ransomware was Caesars Entertainment and casinos owned by MGM, which brought operations in many Las Vegas casinos to a halt. A group of mostly teenagers is suspected of orchestrating that breach. reader comments 118 Dan Goodin Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene. Advertisement Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39578248",
    "commentBody": "US prescription market hamstrung for 9 days (so far) by ransomware attack (arstechnica.com)130 points by notamy 6 hours agohidepastfavorite87 comments IG_Semmelweiss 5 hours agoIts not just presciptions. Its eligibility , claim submission, prescriptions, etc. This is really affecting doctors and patients. Patients are not getting the drugs they need or the authorization for a critical procedure. Doctors' cash flow is interrupted. A lot of admin workers are backed up, and that itself is leading to problems too. Why the backup? Its not just electronic data exchange being offline. Its that everything is now \"going to paper\" (submitted hard copy) which requires humans. Those humans used to take care of the actual work. Now they are stuck shlepping paper from A to B instead. I submitted two links explaining this in more detail yesterday https://news.ycombinator.com/item?id=39561697 reply londons_explore 4 hours agoparentSometimes this kind of event is the trigger to design a more human-efficient process. For example, if it goes on longer, the FDA might allow the majority of drugs to be sold directly on online marketplaces like Amazon without a prescription. That would remove a huge amount of paperwork and doctors appointments for a massive number of people. Let's be honest, the majority of prescription drugs don't have an abuse risk. reply crotchfire 2 hours agorootparentThis is what Mexico does, and it works fine. There are no prescriptions in Mexico. Medications which are scheduled controlled substances (amphetamines, codiene, morphine, etc) are sold directly by hospitals. There really aren't many of these, and hospitals already have to stock most of them for surgical use. Everything else is cash over the counter. And pseudoephedrine is illegal because of pressure from the US. reply raffraffraff 2 hours agorootparentI'm glad pseudoephedrine is legal where I live. Once in a blue moon, if I need it, I can get it. Is it illegal in Mexico because meth comes from there in significant quantities? reply AnarchismIsCool 4 hours agorootparentprevThere might be some risk with idiots taking z packs for colds and creating more super bugs but there's definitely less stupid ways of doing this. People who take critical stuff regularly usually have to ration drugs so they have a store in case of emergencies. If you travel somewhere and you forget your life saving drugs you then have to spend a good chunk of your trip grovelling to the pharmacist and doctor (depending on the drug) to get an emergency refill if the drug is even available in that location. The whole system is bonkers. reply spaceguillotine 4 hours agorootparenti have to do this rationing, i skip a dose a couple times a month to slowly build up a reserve, it came in handy on multiple occasions where insurance was holding up meds. reply IG_Semmelweiss 4 hours agorootparentprevNah. We wont even allow people to import drugs from canada. Meanwhile, canadians are the nicest, most honest people you will meet. You have a positive outlook and that deserves kudos, but its not going to happen, at least in relation to the current fiasco. The pharmacy lobby is too strong. reply Beijinger 3 hours agorootparentprev\"Let's be honest, the majority of prescription drugs don't have an abuse risk.\" It is absolutely disgusting, that you need a prescription for pharmacy items. There is nothing better than going into a pharmacy and just being able to buy what you need. Never had any problems in Colombia, Brazil, Russia and rarely in China. What about people without health insurance? reply jart 4 hours agoparentprev> Its that everything is now \"going to paper\" Is it wrong of me to hope it stays that way? reply jclulow 2 hours agorootparentYes, frankly. It results in terrible outcomes for basically everyone, which ultimately hurts patients the most. reply IG_Semmelweiss 4 hours agoparentprevBrief summary of the situation (as of 3/1) Impacted services: -Electronic Prescriptions -Several Patient Record Sharing (PRS) systens -Claim Submission -Prior Authorization Appeals -Almost everything involving Fax + UHC Restored services: -Electornic Prior Authorizations (ePA) submissions -Real-time benefit checks reply Blahah 5 hours agoprevThe absurdity is painful. That in a wealthy nation people can be unable to access medicine because the system for deciding who will pay how much for it is unavailable. Absolutely grotesque. The hack isn't the problem. The system that privileges access to medicine is. reply caturopath 4 hours agoparentI'm not sure this is the message of this story. There are tons of computer systems involved under single-payer systems. reply miki123211 4 hours agorootparentPolish person here, this is very true. Our prescription system is extremely centralized, there's no such thing as a paper prescription any more. When a doctor gives you a prescription, you get a four-digit code. The prescription can be redeemed at any farmacy by giving them the code and your national identification (PESEL) number. If this system goes down, there's no access to prescription medication, to anybody, anywhere in the country, period. Even an emergency government authorization to use paper prescriptions wouldn't help here, as a lot of people are on \"long-term\" prescriptions. They go to a specialist once a year or so, get a prescription for a year's worth of drugs, and then go to the farmacy every month to get their monthly refill. There's no way we have enough doctors to get all the long-term prescriptions correctly and quickly re-issued on paper when the need arises. reply toast0 3 hours agorootparent> There's no way we have enough doctors to get all the long-term prescriptions correctly and quickly re-issued on paper when the need arises. In the US, prescriptions with refills have a label on the bottle indicating how many refills left. I imagine in a recognized crisis, you would be able to get those refilled with little trouble, maybe even if it said zero refills as long as it was a drug typically used long term and not a drug commonly abused. reply miki123211 1 hour agorootparent> label on the bottle We don't do that. You just get a box and that's it. reply kzrdude 1 hour agorootparentYou could print a label that is stickied onto the \"retail\" box. reply Blahah 4 hours agorootparentprevBut none relating to payment or ability to pay. In the UK, medications are dispensed without checking whether a person is eligible for free prescriptions. Anyone can collect a prescription medication without paying by claiming an exemption (e.g. being on low income, pregnant, etc.) without proof. The pharmacist can also waive the £9 fee for a prescription. There's never a situation where not being able to figure out the paperwork prevents medicine being available. The prescription system itself could be compromised, in which case everyone in society would face the same issue (which would be mediated by the fact that paper prescriptions are still produced, and a pharmacist can telephone a prescribing surgery). Only a supply chain attack would really cripple the system. reply BHSPitMonkey 1 hour agorootparentPresumably even in a single-payer system, you still need just as good of an accounting of costs and care provided. The data needs are all still there, just fewer parties are transacting. reply Blahah 13 minutes agorootparentAbsolutely. But in the UK, Ireland, Germany, New Zealand, etc... nobody would be refused their medicine because the payment system didn't work. Even if the computers didn't work. In the USA, people can and do die because there's a financial barrier to accessing medicine. Not so in countries that care about people. reply fragmede 4 hours agorootparentprevI agree that the hack is the problem, but a single-payer system would mean the moving parts of the distributed system are less complex which means it's easier to manage. Just having fewer corporations involved means fewer boundaries between systems which means it's less likely to break. reply mindslight 4 hours agoparentprevPerhaps it's possible for the public to outbid the parasite's owners and pay the ransomware group to just shred the entire operation. As companies become ever more virtual, the corporate death penalty ala Fight Club or Mr. Robot seems ever more plausible. reply bluGill 3 hours agorootparentThey will be pack if you pay. The only safe payment is in fbi tracked money. then track the guilty down and put them in prison (or what ever reform program). If the country they live in won't give them up that is an act of war and send NATO in. reply waihtis 1 hour agorootparentIn practice, cyber attacks dont seem to trigger even discussion of article 5. It will be interesting to see if we reach a state where they do reply rainbowzootsuit 4 hours agorootparentprevSomething between John Oliver burning $15M in medical debt and Tyler Durden with vans full of nitroglycerin. reply easyas124 5 hours agoparentprevI mean, even on a good day, the people who need drugs can't necessarily access them. Can't wait for the system to come back up so I can find out another important medication isn't covered. reply roenxi 5 hours agorootparentThat sounds like it is still part of the system that privileges access. In a sane world, you have the option of paying the seller for the thing you want, then they give it to you. That is a big part of what makes this crazy. People are in an insane system where they can't pay for drugs. Then the system goes down and they really get into trouble. reply easyas124 3 hours agorootparentIn a sane world, prescriptions cost no more than $20 for everyone (and by \"sane world\" I mean \"the rest of the world\"). Also, fuck right on off you flagging asshole children. reply Blahah 3 hours agorootparentRight, equitable access to medicine means everyone pays a zero, or trivially affordable price, that's the same regardless of who they are and regardless of what the medicine is. In the UK that is £9 maximum - free for many. P.S. vouched your gp comment back to life. reply refurb 3 hours agoparentprevEvery nation does this? When I lived in a universal healthcare system I had to show my healthcare card to get medicine. Prescriptions were transmitted electronically. None of this is unique to the US. reply lionkor 2 hours agorootparentIn germany I get a piece of paper and bring it to a pharmacy most of the time... It has worked when my phone was out of charge, when the pharmacy had Internet problems, etc. reply Blahah 3 hours agorootparentprevHaving to show identity documentation doesn't rely on a payment processor. Prescriptions in the UK (and other places - Germany for example) are electronic by default but can be made out on paper and verified without a computer. reply raffraffraff 2 hours agorootparentSame in Ireland. My doctor can send it electronically to a pharmacy but I can take my paperwork to any pharmacy to get it filled. reply raffraffraff 2 hours agorootparentprevHow many countries allow a single company to monopolise it? reply tempodox 4 hours agoprevI wonder how many more of these incidents will need to happen until everyone starts to take computer security seriously. How much longer will there be zero consequences for offloading the risk of shoddy security to your users? reply 14 3 hours agoparentWell it has always been a cat and mouse game. Even with best intentions you will get someone discovering some sort of exploit, or some employee going rogue or forced or tricked into installing something. When ever we talked about these issues it brings me right back to the xbox 360 days and the hacking scene. It was amazing to see the back and forth between MS and the hackers and what each side would do to countermeasure the other. The one that impressed me the most was MS started making games about 8gb in length. DVD's only were only sold in 7.5gb size. Hackers learned that the games were just being padded with random useless data so learned to truncate the games and burn to 7.5gb discs again. MS learned to detect truncated games. Hackers then figured out how to flash certain DVD burners so that they would burn to the outer most area of the 7.5gb DVDs, an area that would typically not be used due to chance of increased errors burning in that area. So then you could burn a game all the way to the edge of the disc and then hackers developed a scanner to check for game errors as burning to the edge didn't work well so you would have to burn at slow speeds and really use high quality DVDs as cheap ones didn't work well. The back and forth that kept happening was so impressive. I guess my point is no matter what you try as long as millions of dollars is on the line people will find a way. reply staplers 4 hours agoparentprevMulti-trillions in defense spending and for what? Our country is crippled with ineptitude and hogtied by the billionaire plutocracy. The systems the masses depend on will crumble long before the ruling class notices. Look to our national elections as a grotesque reminder. reply DinaCoder99 3 hours agorootparentGiven how poorly our defense spending effects literally anything related to our security, I'd rather not discover what havoc our government might wreak on the internet. reply 15457345234 4 hours agoparentprev> everyone starts to take computer security seriously Weren't the last big attacks literally carried out by hackers exploiting security software? As in, the solarwinds thing, which was carried out on systems which were 'textbook secure' ? If you want a secure system, my advice would be to fall back to using dumb hardware terminals, VT100 style. Anything more complicated than that will have a backdoor. reply jart 3 hours agorootparentReuters said, \"[t]he problems began last week after hackers gained access to Change Healthcare's information technology systems [...]\" so it was probably because some airhead gave their login to the hacker over the phone. Social engineering accounts for 98% of all cyber-attacks. Highly intelligent people who are only accustomed to employing software don't understand this, because the only thing they're afraid of is their software getting exploited. reply rolandog 2 hours agorootparentMy money is on some un-upgraded backend/frontend stuff due to \"compatibility\" and/or lack of budget to hire people to keep things patched and up-to-date. reply 15457345234 1 hour agorootparentBlah, when it comes to a target that large, hackers will insert a contractor into the role who can secure the relevant credentials. This is another reason the remote-work scenario is such an issue - it's so trivial when large numbers of people are working remotely to gain access to secure systems. reply mikewarot 3 hours agorootparentprev>using dumb hardware terminals, VT100 style Those VT-100 terminals actually have Z80 CPUs in them, but even so, they connected to VAX or other computer systems, which are generally networked. reply faeriechangling 3 hours agorootparentprevI wouldn’t characterize solarwinds as “security software”, the product that got hit was classic up/down monitoring software. reply tempodox 4 hours agorootparentprevFair enough, a no-bullshit discussion on how to actually achieve security should be part of the process. reply 15457345234 3 hours agorootparentThe issue is, actually having that discussion becomes very hard, because a lot of 'security consultants' basically rely on the commissions they get from selling that type of inherently-creating-a-single-point-of-compromise managementware. So all of the 'experts' you might draft in to give you helpful advice will be telling you exactly the opposite of what you should be doing, which is reducing your attack surface as much as possible; cutting down, not increasing, the number of apps installed. And don't get me started on MDMs, which are basically a rootkit that's only as benign as the guy sitting behind the operator panel. reply oogali 2 hours agoprevChange Healthcare is a transaction clearinghouse, or effectively an API, translation, and routing gateway. Think of it as a private SWIFT vendor. They were acquired by UHC, which is why you see the Optum name. But this is not specific to UHC/Optum patients. Providers (hospitals, doctors, software vendors) interface with CH’s REST+JSON APIs and in turn CH emits EDI records to the insurance company backends (and translate the responses from EDI to JSON/XML/etc). This affects general healthcare EDI messages (claims, benefits eligibility verification, ACH notices, etc). The people impacted do not have direct EDI implementations with the insurance companies. If they did, they could side step this. Or even a different clearinghouse. Edit: clarified some ambiguous terms reply raffraffraff 2 hours agoparent> The people impacted do not have direct EDI implementations with the insurance companies. If they did, they could side step this. Thank you. I was trying to figure out how this company seemingly handles most of this stuff in the US. reply ThisIsMyAltAcct 4 hours agoprevCyberattacks like these deserve the same kind of government response a terrorist attack gets. reply jart 3 hours agoparentRead https://rewardsforjustice.net/rewards/foreign-malicious-cybe... and notice how the USG only cares if the hackers are acting under the direction of a foreign government. Hacking for profit sadly gains more acceptance as a legitimate form of enterprise each year, similar to corporate raiding. You can buy insurance to cover ransom payments. There's also hackers who hack into consumer PCs, routers, and phones where instead of holding you to ransom they just MiTM HTTPS to inject ads, rent out access to DDOSers, or let companies like Cox actively listen to your microphone. A lot of devices like Lenovo have been known to come pre-hacked before they even leave the factory. It's all above the board at this point. Rather than being treated as terrorists, the worst consequences you'll see for them usually is just a lawsuit. reply birdiesanders 4 hours agoparentprevThis fits the bill for terrorism in my mind, it is an intentional act to directly affect the people of a nation, and if it causes even one death it becomes way more likely the law will see it as such. Who knows when (one of these events will eventually cause a response from fed) cyberattack becomes synonymous with terror attack, though. Could be this one, could be the future (hypothetical) attack on Fox News or CNN, could be someone turning off the sewage treatment plant for DC, one of them will ruffle the right feather, eventually. reply bpye 3 hours agorootparentThere have been other attacks in the past that would meet that bar, the first that comes to mind is WannaCry - seeing as it disrupted the NHS. reply bbor 2 hours agorootparentprev> it is an intentional act to directly affect the people of a nation I would define terrorism as something closer to “violence with the intent to intimidate political opponents”. This isn’t really violent, and even if it is (it’s certainly very dangerous!), there’s no political message. Unless this is a 4D chess play that somehow is supposed to weaken America by making us more stressed or something, this just seems like Russian privateering. Your definition is a bit too broad, as I think you would admit to - I’m guessing you didn’t intend it as a flawless philosophical definition, just a quick one reply dralley 4 hours agoparentprevCall / email your congressmen and tell them to stop stalling on the Ukraine defense bill. reply MandieD 3 hours agorootparentMine’s been too worried about losing the primary to someone who is crazy rather than merely craven like him to care what I think. reply ThisIsMyAltAcct 4 hours agorootparentprevHe already wants to but he's a small fish in a big pond. reply miki123211 4 hours agoparentprevTHe nice property of terrorist attacks is that the terrorist groups need somebody in the country where the attack actually happens. You might be too late to catch them, they might commit suicide etc, but in general, that property makes law enforcement work a whole lot easier. With ransomware, even if you can say with 100% certainty that Dmitrij Smith from St. Petersburg did it, this still doesn't get you any closer to putting said Dmitrij smith behind bars in the US. It's highly likely that you can't even interrogate / surveil the suspect, making it that much harder to see if they were acting on their own and out of pure greed or on government orders. And that's if you know who did it, cyber attack attribution is complex, and you often can't say anything with certainty. reply bluGill 3 hours agorootparentWe have a proxy war in Ukrain to escalate in that case. reply jMyles 4 hours agoparentprev> the same kind of government response a terrorist attack gets. Has that particular kind of response ever achieved anything? (Anything germane to the concern at hand, I mean - of course it has often achieved enriching well-connected contractors and such) reply raverbashing 3 hours agorootparentHas looking like a sitting duck ever achieved anything besides making you look like a good repeat target? reply syndicatedjelly 4 hours agoparentprevI don’t want to live in whatever world you’re dreaming of reply cipheredStones 4 hours agoparentprevWhat - invading an unrelated country? reply mise_en_place 1 hour agoprevMy doctor notified me of this ransomware attack a few days ago. I'd imagine it's quite frustrating to deal with. What I've noticed is that engineering/tech culture is non-existent in heavily regulated industries. IT is usually a cost center, so there is very little incentive to improve things. Until there is a paradigm shift in their existing culture, these type of issues will continue to happen. reply tvanhens 1 hour agoprevMy former employer Stedi, an EDI integrations startup, is working on a compatibility layer to help companies who are affected route messages to alternative clearing houses. The founder posted on Twitter to let people know they can also reach out directly for urgent support at change@stedi.com https://x.com/zackkanter/status/1764057780800094350?s=46 reply Projectiboga 3 hours agoprevThis is due to not having a single payer. In this situation we all loose. Lack of being single payer also poses risks to us all regardless of coverage with our emergency rooms all over crowded. reply redwall_hp 3 hours agoparentEven without single payer, insurers should never be able to stand in the way of a doctor practicing medicine. They should be strictly required to cover any procedure or medication a doctor deems necessary, and the practice of pre-approvals should be forbidden. reply refurb 3 hours agorootparentThat’s ridiculous because in a single per system the government stands in front anyways. There are plenty of drugs in Europe doctor might want to prescribe but the government says “nope, not going to pay for it” reply ejstronge 3 hours agorootparent> That’s ridiculous because in a single per system the government stands in front anyways. > There are plenty of drugs in Europe doctor might want to prescribe but the government says “nope, not going to pay for it” Not only does this happen with the current system, it’s worse, because there aren’t always explicit instructions about what will be covered - so your care depends on whether your doctor is willing to beg the insurer to provide a drug to you reply Wytwwww 5 minutes agorootparentInsurance companies can always hike premiums to compensate though. State run system could/would be a lot stricter with their funding and have less wiggle room. reply raffraffraff 2 hours agoprev> Optum provides a nationwide network called Change Healthcare, which allows health care providers to manage customer payments and insurance claims. Is the entire system in the US really using a single private company to handle this? reply throwaway892238 4 hours agoprevNo mention of how United and Optum are a racket that harms people and needs to be broken up https://www.healthcaredive.com/news/unitedhealth-antitrust-i... https://www.healthcare-now.org/blog/united-we-scam/ reply gustavus 5 hours agoprevThe problem is not that the ransomware attackers attacked. It's the fact that $10 says they've been systematically underinvesting in security and nows it's biting them in the a*. But it doesn't matter because they've basically managed to be come a monopoly through acquisitions and using the bludgeon of government regulation to ensure no competition occurs. The next step is to move to declare this critical national infrastructure and create all sorts of new obtuse rules and regulations that will be in the name of security, but will mostly be theater and whose only real effect will be to create tons of new \"compliance\" jobs by low skilled morons who couldn't cut it in a real security job and whose primary job will be preventing actual security and sapping energy from anyone who builds things, because \"it's not on the checklist\". Not to mention the dozens of new vendors who will pop up soliciting a product that will promise to ensure customers are in complaince with the new regulations. Meanwhile Joe blow will still be unable to get his prescription filled and have his personal health data stolen and sold all over the black market. reply Veserv 4 hours agoparentThere is literally no point to \"investing\" in modern commercial IT cybersecurity. It is all a bunch of useless junk that is incompatible with creating systems with any meaningful security. The big banks are spending hundreds of millions to billions of dollars a year on that junk and their cybersecurity teams know they can not even stop small teams with a million dollar budget. Literal kids fresh out of college at the banks manage more money than that. That is literally the case across all industries in every field in every area with big tech being no exception. Almost certainly everybody you have heard about does not and has never had the slightest clue on how to protect against economically motivated, professional criminals; the kinds of attackers that are now commonplace and are expected to attack every commercial system in the modern threat landscape. This is not a problem of underinvestment, it is a problem of structural incompetence. Systems need to verifiably survive red team pentests with multi-million dollar budgets with exactly zero discovered vulnerabilities before we are even in range of reasonable solutions. Any standard lower than that is inadequate to demonstrate resistance to commonplace attacks and is not even worth discussing. reply adamsb6 3 hours agorootparentThere are two kinds of security. Nearly all of corporate America practices security by checklist and certification. This is not real security, it’s just CYA for careerists and legal challenges. Actual security is hard and almost no one does it. The people capable of it are rare and expensive. They’re probably not jumping at the opportunity to work at Optum for $80,000. reply Veserv 2 hours agorootparentAnd who does actual security? Certainly not Google, Apple, Microsoft, Palo Alto Networks, Crowdstrike, etc. If that is who you were going to bring up, none of those companies has ever developed and deployed a usable system secure against even middling adversaries with only a few million dollars of budget. You will find exactly zero people at those companies who would be willing to bet their job that a small team of say 3-5 skilled offensive specialists specifically targeting them and willing to expend a year of fulltime work (i.e. a few million dollars worth of personnel cost) would not be able to completely compromise any usable system they designed. Exactly zero of the recognized names can protect against economically-motivated professional criminals targeting you. All they even claim to do is make you the ROI of attacking you go from the industry average of 100x to a still wildly profitable 10x under the \"You don't need to be faster than the hunters, you just need to be faster than the other dodos\" theory. Unfortunately, that theory does not work when the hunters keep bringing more of their friends to eat mouth-watering dodos. I mean, the cyberattacks have only been increasing by like, 500% YoY for the last 10 years. Exponential growth that slow means you can keep outrunning the hunters for like 5-10 more years until they eat everybody. reply ethbr1 4 hours agoparentprev> $10 says they've been systematically underinvesting in security and nows it's biting them in the a*. But it doesn't matter because they've basically managed to become a monopoly [...]. The next step is to move to declare this critical national infrastructure and create all sorts of new obtuseness rules and regulations [...] There really only need to be 3 for critical infrastructure. #1 - Patch your shit according to industry standards, and have documented audit records that you've done that in a timely manner. #2 - You're fair game for NSA and DoD offensive pen testing. Failed pen tests are responsibility disclosed, then reported to the market after delay. #3 - So goes CISO, so goes CEO. Along with a ban from leadership roles for a number of years (5?). The issue is that the CEOs of these companies hire fall-on-your-sword guy as CISO, ignore the issues / listen to their CISO glossing over deficiencies, then claim breaches came out of nowhere, fire the CISO, and repeat business as usual. It's not going to change until CEOs have a realistic expectation that deficiencies will be found and personal consequences when they are. reply FounderBurr 4 hours agoprevlol couldn’t happen to nicer people. Take their money then tell them it’s ’not Covered’ and just keep plowing away. reply anovikov 3 hours agoprevI think it just needs to reverse to old and tried all-paper, hard copy, no-electronics approach of yesteryear. There is no way institutions that are filled with non-technical people can prevent this if the entire system is electronic and networked. reply mikewarot 3 hours agoprevYet again we blame everyone and everything except the operating systems that have a massive design flaw baked in from the 1970s, they all rely on ambient authority to function. This isn't going to get better until this our fundamental OS security models get updated to reflect reality. reply ryanjshaw 2 hours agoparentI honestly don't get it. With the number of IT billionaires out there, why isn't there just one who wants to solve this problem? We already know how, in principle - capability-based, formally verified OS kernels like EROS and CapROS have shown us the way. The next step is building a real world OS and user environment that carry these principles through. Yes, if would take 10 years at a minimum. But it wouldn't even be a charity, even if you went the OSS route! There would be massive commercial opportunities arising out of the product. If you have the money, and it's profitable and world changing in 15-20 years, why not do it? reply Veserv 1 hour agorootparentBecause you can just lie and claim you make secure systems like Microsoft, Apple, and Google have been doing. Much easier and you get to have a billion features in your \"secure\" product so it supports more uses than actual secure systems. There was a small pile of systems sufficiently secure for actual high security work during the regime of the TCSEC Orange Book and the early era of the Common Criteria. But once Microsoft and the other consumer IT companies lobbied to get serious security certification requirements removed or reduced since their security was inadequate to bid on new projects and they found that unfair, they sucked all the air out of the room for actual high security commercial systems. And, even if they did decide to pursue it their every instinct is completely incorrect. They have all made their fortunes on entertainment and consumer software and principles like \"move fast and break things\" that are antithetical to the development of secure and reliable systems; they do not have the foggiest clue how to solve problems in security or even how to compose secure components into secure systems. That is not to say that nobody is doing so, you can just look to what is actually being deployed in domains that actually demand high security and high reliability systems and have the testing, auditing, and verification to establish conformance like aerospace and certification requirements like the Common Criteria Separation Kernel Protection Profile (SKPP) which required formal specifications, formal proofs of security, and a clean NSA penetration test (i.e. the literal NSA could not find any vulnerabilities). However, the market for things that actually work is not as large as you might think given how much people crow about security because again, you can just lie. The chickens have not come home to roost yet because cyberattacks are only just starting to be a serious problem. It takes a while for 18 year old kids to bootstrap worldwide criminal enterprises able to attack millions of companies. I mean, even Zuckerberg had VC funding and it still took them over a decade to saturate the world. You have to cut the cybercriminals some slack for taking a few years to become a actual crisis. Give it another 10 years. reply hiddencost 2 hours agorootparentprevThe billionaires aren't coming to save us. reply yieldcrv 4 hours agoprevThis is frustrating given the humans affected I always find it interesting how some Russians seem to understand our system better than we do, and we collectively seem to know so little about theirs for the same level of fun and profit reply kgeist 2 hours agoparentRussia's prescriptions, patient history etc. all still happen on paper. The Kremlin uses typewriters for sensitive data [0] etc. So there's often nothing to hack. [0] https://www.npr.org/sections/thetwo-way/2013/07/12/201492641... reply bluGill 3 hours agoparentprevThey only need to find one vulunerable part of the system to understand not the full system. reply aaomidi 4 hours agoparentprevExpect more of this with the heavy downward pressure on offshoring jobs too. Until there are hefty fines on these companies (to the point of forcing public ownership of it if they continue to fuck up) then these issues will continue. reply bbor 2 hours agoprev [–] > Optum first disclosed on February 21 that its services were down as a result of a “cyber security issue.” Its service has been hamstrung ever since. Shortly before this post went live on Ars, Optum said it had restored Change Healthcare services. “So far” seems like a stretch, unless they’re including ramp up time or something? It really sums up the whole article: great quality journalism, absolutely terrible exploitative publisher. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AlphV, a Russian-speaking ransomware group, targeted the largest US health care payment processor, leading to a nine-day struggle for pharmacies, health care providers, and patients to access life-saving medications.",
      "Operating as a ransomware-as-a-service model, AlphV has amassed over $300 million in ransom payments in the past.",
      "This incident underscores the severe consequences ransomware attacks can have on critical infrastructure, following previous attacks on entities like Colonial Pipeline and hospital networks, with law enforcement facing difficulties in disrupting AlphV's operations, posing a continued threat to US organizations."
    ],
    "commentSummary": [
      "A ransomware attack has significantly disrupted the US prescription market for 9 days, impacting eligibility, claim submissions, and access to prescriptions for doctors, patients, and admin staff.",
      "Discussions emphasize the importance of enhancing cybersecurity measures, addressing vulnerabilities in the healthcare system, and implementing more effective security protocols to tackle cyber threats in the future.",
      "There are debates on insurance companies' involvement in healthcare decisions and criticisms of industry monopolies, underscoring the necessity for stricter regulations, improved security models, and increased investment in security measures to prevent future cybercriminal activities."
    ],
    "points": 130,
    "commentCount": 87,
    "retryCount": 0,
    "time": 1709437480
  }
]
