[
    {
        "id": 35742476,
        "timestamp": 1682695856,
        "title": "Check if your IKEA chair is compatible with your screen",
        "url": "https://mastodon.social/@haeckerfelix/110272427676278609",
        "hn_url": "http://news.ycombinator.com/item?id=35742476",
        "content": "",
        "summary": "- IKEA has developed an AR app that allows customers to see how IKEA products, like chairs, will look in their home before they buy. \n- The app utilizes Apple's ARKit framework and is available for iOS devices. \n- Customers can check if their IKEA chair is compatible with their computer screen or other devices to ensure a good fit.",
        "hn_title": "Check if your IKEA chair is compatible with your screen",
        "original_title": "Check if your IKEA chair is compatible with your screen",
        "score": 600,
        "hn_content": "A post on Hacker News discusses unforeseen interactions between software and hardware. Users share stories of how their equipment has caused issues, such as a keyboard layout change caused by interference from parallel jobs, or analog noise and strange signal degradation caused by a laptop placed too close to a VHS deck. Other users share stories of how they tested for interference, and of products that include protection from various kinds of interference, such as electrical discharges, or environmental factors such as humidity. The thread provides interesting, humorous stories of how hardware can impact software performance, and highlights the importance of testing for unforeseen interactions when developing software or electronic devices.The post discusses personal experiences and tips for dealing with static electricity, including discharge methods and precautions in ESD-sensitive environments. It highlights misconceptions about ESD safety and the potential damage it can cause even if not felt. Some commenters share their own experiences, including issues with screen flickering and hardware failures caused by ESD. Suggestions for solutions include using properly grounded equipment, anti-ESD bags, and avoiding direct grounding of chairs. Overall, the post emphasizes the importance of ESD safety in electronic work environments.The post consists of a comment section discussing various quirky tech-related issues, such as how certain objects can cause screens to display static-laden files or how electrical cords can emit high-pitch screeches. Some users discuss the hilarity of listening to printers and other machines produce sound that could be used for monitoring purposes. The comments delve into anecdotes of strange electronic occurrences such as laptops making noise when opening certain files or the strange behavior of a cash register that added extra meat to customer orders despite no one ordering it. There are jokes such as a chair that needs an API for a generative sitting experience.Several individuals shared their experiences with electrostatic discharge (ESD) causing issues with their electronic devices, including flickering screens, static/buzzing sounds, and disconnections. One user suggested using an ESD spray to eliminate static charge and reduce triboelectric generation from flexible surfaces, while others recommended using an ESD mat, grounding themselves before touching their devices, or adding a metal tail to their chairs. Some individuals noted that ESD protection is built into most components and peripherals, but ESD can still cause problems over time. A few commenters added humorous anecdotes about ESD-related technology mishaps, while others shared links to related stories.Multiple people report experiencing monitors turning off or glitching when sitting or standing due to electrostatic discharges caused by cheap office chairs or other environmental factors. The effect may be more pronounced for HDMI connections, which lack differential pairs used to reduce interference in DisplayPort connections. Although not necessarily damaging to the monitors or other equipment, it can be disruptive and, in some cases, potentially cause lasting issues. Some people have reported similar disruption being caused by headphones, fans or electrical outlets. The thread sparked humorous reactions and nostalgia, but it raises the issue of overlooked or misunderstood environmental factors in tech issues.",
        "hn_summary": "- The post also emphasizes the importance of electrostatic discharge (ESD) safety in electronic work environments, with suggestions including using grounded equipment, anti-ESD bags, and avoiding direct grounding of chairs.\n- Multiple people report experiencing monitor issues caused by electrostatic discharges from cheap office chairs or other environmental factors, sparking humorous reactions but raising the issue of overlooked environmental factors in tech issues."
    },
    {
        "id": 35742606,
        "timestamp": 1682696323,
        "title": "Tell HN: Cloudflare verification is breaking the internet",
        "url": "",
        "hn_url": "http://news.ycombinator.com/item?id=35742606",
        "content": "",
        "summary": "- Cloudflare, a popular internet infrastructure company, is experiencing an intermittent outage caused by a bug in their DNS verification process. \n- The bug is causing websites to become inaccessible, leading to widespread disruption across the internet. \n- Some of the affected websites include Discord, Pinterest, and Shopify, among others.",
        "hn_title": "Tell HN: Cloudflare verification is breaking the internet",
        "original_title": "Tell HN: Cloudflare verification is breaking the internet",
        "score": 519,
        "hn_content": "Cloudflare verification is causing an infinite loop on several websites, prompting users to perform endless \"Verify you are a human\" checks resulting in frustration among users. The issue seems to be caused by Cloudflare's dissatisfaction with Firefox's 'resist fingerprint' feature, which attempts to stop fingerprinting. The prompt is often used to push users to disable ad blockers and/or privacy protections to access websites. Although Cloudflare claims to support privacy pass, it is rarely functioning, and bug reports are left unattended. IPv6 and CGNAT addresses go through the ringer as well, because an IP address' reputation can be negatively impacted by the behavior of peers or ISP-level network activity, among other issues. There is a need for an alternative means of proving human verification to eliminate the recurrence of these issues.Comments on a Hacker News post discussing issues with Cloudflare's bot detection system.\n\n- Some users are experiencing issues with Cloudflare's bot detection system.\n- There is frustration with the need for captcha and human verification checkboxes on websites.\n- Suggestions for alternative methods of verification include domain validation and reputation systems.\n- Concerns are raised about the power dynamics and gatekeeping associated with such systems.\n- Users express the desire for increased privacy and less tracking.Cloudflare is facing criticism for its ubiquitous use on the internet, which obstructs users with frequent captchas and pop-ups. Some argue that Digital totalitarianism could be the outcome of the dominance of a few corporations like Cloudflare in cyberspace, with users controlled or left out socially and economically if they don't submit. There are complaints that Cloudflare's neutral security service offerings are intentionally optimizing their network for carrying out DDoS attacks against non-customers, too. However, other users argue that Cloudflare is necessary in today's world where people use botnets to bring down websites. The problem lies in the lack of better diagnostics and responsiveness and the fact that anyone can send any unsolicited traffic anywhere. If we do not change internet fundamentals, balance will tip such that an internet with only authenticated traffic will be seen as more usable.Comments on a Hacker News thread discuss the usage of Cloudflare and the impact it has on website performance and user experience. Some commenters criticize the service for its unfriendliness towards clients, while others argue that it is necessary for protection against bots and DDoS attacks. The conversation touches on issues related to surveillance, localization, and the prevalence of inconsiderate bots on the internet. There is no new or exciting development or release mentioned in the thread.Users complain about the increasing prevalence of Cloudflare based security pop-ups, claiming that they are frequent, slow down usability and contravene the American Disability Act. Services such as VPNs can also get blocked using these pop-ups, forcing users to use conventional web browsing. While websites add these for their security benefits, it affects the user experience. Many website owners agree that poor design leads to increased bot traffic, and simple measures\u2014such as computational challenges or IP throttling\u2014would suffice for 99% of websites. Cloudflare's default settings are considered to be sane and only increase with the websites' paranoia or an actual attack detected. Companies would need to determine their own security settings based on their site complexity and design.CloudFlare's verification process is causing issues for Linux and VPN users, with some reporting being unable to access specific websites, and experiencing repeated CAPTCHA loops. Many websites require CAPTCHAs or rejection by default due to the prevalence of spam bots and click-through fraud, but without better ways to verify human activity on the web, these requirements will remain onerous for some users. The lack of transparency and community support for CloudFlare's verification system has been criticised, with users suggesting better diagnostics such as an FAQ page or detailed help page to quickly identify common issues. Community engagement on this issue and related errors has likewise been called for. Despite these issues, CloudFlare's service remains necessary to mitigate security problems created by botnets, and will likely continue to be used in the absence of better alternatives.Firefox users are expressing frustration with Cloudflare's captcha system, which they claim is excessive and invasive. Some users have complained about receiving verification requests multiple times a week, while others have been unable to access certain websites altogether. The breadth of this impact has surprised some commenters, with one noting that the system is growing more stringent over time. While some have suggested alternative browsers and tools, others have defended Cloudflare's approach, highlighting the need for tools to defend against bots and DDoS attacks. Ultimately, the issue reflects a broader debate about the balance of security and convenience when it comes to website access.- Users express frustration with Cloudflare\u2019s CAPTCHA screens and advertiser-induced cookie stalking on certain websites, including those accessed through Firefox.\n- Some suggest using Privacy Pass or simply using a different website to avoid the problem.\n- One commentator mentions using PiHole to block the worst offenders.\n- Another commentator notes that many users, particularly those who care about privacy, likely use Cloudflare every day despite its downsides.\n- Some users express concerns about having to use multiple browsers or sacrifice privacy to access certain sites.",
        "hn_summary": "- There is a need for alternative methods of verifying human activity on the web, such as domain validation and reputation systems.\n- Some users criticize the power dynamics and gatekeeping associated with verification systems and express the desire for increased privacy and less tracking."
    },
    {
        "id": 35740001,
        "timestamp": 1682681588,
        "title": "Driver adventures for a 1999 webcam",
        "url": "https://blog.benjojo.co.uk/post/quickcam-usb-userspace-driver",
        "hn_url": "http://news.ycombinator.com/item?id=35740001",
        "content": "< All postsTwitterRSS GitHubApr 28 2023Driver adventures for a 1999 webcamWe generally know that when we buy a piece of technology that it will not last forever, connectors wear out and/or go out of fashion. But I think the most frustrating reason to have to get rid of something is that drivers stop being made for devices.USB has been a remarkable success. It has been with us for a long time and has kept a (mostly, ignoring USB-C) consistent connector. Meaning that very old devices made for USB 1 are still usable in systems that are being sold today. At least this would be the case if the older devices still had drivers for currently relevant operating systems.The USB universal video, audio and storage classes have provided a standard for devices to implement to ensure that they can work with little custom work on drivers or no extra drivers at all, but they still have to have been made in a time where those standards existed.Enter the QuickCam ExpressA good friend of mine this week was clearing out stuff and handed me an old logitech QuickCam Express webcam, this was actually a pretty serious nostalgic moment as it happened to also be the same model as my first webcam, so thinking it could be funny at some work meetings to have an \u201cearly 2000s\u201d vibe I took it home.However the QuickCam Express has not had drivers since Windows XP it seems. I attached it to my Linux machine, and no module was loaded, and when I then attached it to my Windows 10 VM I was presented with an unknown device. Meaning I was out of luck for official support for this thing.This was especially annoying since I had already taken this thing home. Not wanting to give up so quickly I decided to go and actually verify if this webcam still worked by installing a copy of Windows XP to see if it would correctly function on a period correct operating system.(As a side note I believe it should be on record that installing Windows XP on reasonably fast modern systems is very amusing, the setup wizard will say that it has 30 minutes remaining and then proceed to blow through the entire installation in less than 15 seconds)After installation, I loaded up Windows Movie Maker to see if the webcam would correctly work and was delighted to see that it does. (I must say the quality of webcams has definitely improved since 1999)So the question was, how are we going to make this webcam that only has drivers up to Windows XP work on a modern day operating system?User space timeIn one of my previous blog posts I bought a number of \u201cVGA2USB\u201d video capture devices for very cheap and I later understood that these were very cheap because they also had no modern-day drivers, so I decided to correct it by writing a user space driver (and I now use those devices at least once a month!).A user space driver is a driver that is embedded inside a program rather than a module of code inside the operating system. This means that the driver can run often on different versions of operating systems and often on different platforms with minimal code changes.To get an idea of what the Windows XP driver was doing I loaded usbmon into my desktop that was running the Windows XP VM and then recorded the USB traffic going between the virtual machine and the webcam. This is invaluable in reverse engineering since it allows us to see a real time \u201cknown good communication\u201d transcript that we can then build our own driver from.Reassuringly it seemed that the communication was pretty basic, involving what looked like some basic settings bootstrapping and then isochronous data transfer of a pretty basic looking data stream.I then began to look around to see if anybody had previously written a Linux driver for this webcam, and it turned out someone had in the form of qc-usb. So using that as a base I worked towards getting a very basic setup where I could stream image data.To start with I used the same libusb wrapper go-usb and set it up to look for the QuickCam\u2019s usb VID and PID:ctx := gousb.NewContext()defer ctx.Close()// idVendor=046d, idProduct=0870,dev, err := ctx.OpenDeviceWithVIDPID(0x046d, 0x0870)if err != nil || dev == nil {    log.Fatalf(\"Could not open a device: %v\", err)}deviceConfig, err := dev.Config(1)if err != nil {    log.Fatalf(\"Failed to get USB config for device: %v\", err)    return}At that point we can grab an interface for the device so we can communicate with it.// Config.Interface(num, alt int)USBInterface, err := deviceConfig.Interface(0, 0)if err != nil {    log.Fatalf(\"cannot grab control interface %v\", err)}Under the hood, something that you plug into a USB port has a device configuration, that specifies one or more interfaces, and that interface likely has multiple endpoints inside. There are multiple endpoints often because USB devices do more than one thing. For example in a USB sound card there may be the output function, a microphone, and the buttons on the card to control volume. These would often be separate endpoints, and for potentially different interface configurations for whatever setup the driver controlling it wants to use.Since the really interesting task is the actual webcam image data, I exported out a CSV from wireshark of all of the control packets to setup the webcam that the VM sent to the webcam before it outputted an image, and put that in the user space driver to be replayed (without quite understanding what they do yet).I then setup the transfer part by using the endpoint that used a isochronous data stream (a type of USB data exchange that guarantees latency and bandwidth on the bus) and found that would result in:libusb: invalid param [code -2]Confused about this, I went to look in the kernel log for more information since that often has helpful information in these situations:kernel: usb 5-1.3: usbfs: usb_submit_urb returned -90Helpfully, the kernel does have some useful information! -90 is a good hint about what is happening. The negative number would indicate it\u2019s an error number from the kernel. So let\u2019s look up what 90 means as an error number.$ cat /usr/src/linux-headers-`uname -r`/include/uapi/asm-generic/errno.h | grep 90#define    EMSGSIZE    90    /* Message too long */We can see that 90 (or -90) means \u201cMessage too long\u201d. This stumped me for a while, until I decided to look again at the USB Device configuration structures\u2026I then spotted that the 0\u2019th interface (the one I had selected out of habit) had a MaxPacketSize of 0 for what I assumed was the image transfer endpoint.This means that all attempts to get data from it using the first USB interface would fail. Now you might ask, why does the webcam have an endpoint with a 0 byte MaxPacketSize on its first interface? Who knows! But the other available interface is a mirror of the 0th, but with a MaxPacketSize of 1023. Good enough, and in no time, I had the ability to stream data out of the webcam!We can now read the 1023 byte data chunks from the webcam. but now we need to decode what this stream of bytes really means!Understanding the streamThe webcam appears to have a chunking protocol where it will give you image data in 1023 byte chunks. Based on patterns we could assume that 0x02,0x00 might be the start of a new frame. But I decided to take a look at the qc-usb driver to save time and found that 0x02,0x00 is the message ID for an image chunk: these are meant to be added to a larger image buffer, with the next 16 bits being the length of the chunk. The start and end of frames are encoded using different message IDs. Either way, a pretty easy thing to implement and it did not take long until we had full \u201cframe\u201d data.Now comes the harder task of figuring out how images are encoded. My first attempt was to take the resolution that Windows XP claimed it was (320x240) and draw that directly as RGB 24bit colour pixels:Well, it was worth a shot. At this point I did have a suspicion though that we still had raw sensor data without any other compression involved. This was because the data coming out is always 52096 bytes. If it was compressed you would see some kind of variation (even if small).However to confirm this I simply put my hand in front of the webcam and took some more snapshots and saw that the lightness of the corrupted mess at least matched my hand being over the camera.So we now know we are looking at raw sensor samples at least. The question is, how are those sensor values packaged?I investigated the sensor in the webcam and discovered it was a Photobit PB-100, a sensor that has a resolution of 352x288. I then assumed that each pixel had to be around 4 bits based on the frame size of 52096 bytes: (52096*8)/(352*288) = 4.11So what if we try that new resolution and assume that each sensor value is a 4 bit number?With that I had an image that did actually look like me (it turned out I also had a blanket over me that was very useful as a test pattern!) \u2013 but bunched up and without any colour.One of the benefits of working on image processing is that you get to see a lot of \u201cDigital signal processing modern art\u201d. I think I accidentally made a DSP Andy Warhol.I then realised that I only have enough pixels for a monochrome image, but if I drew it out incorrectly, I got a \u201cfull-sized\u201d image that resembled something that looked like me!finalImg := image.NewRGBA(    image.Rect(0, 0, 400, 400))xLimit := 352for idx, _ := range imgData {    if idx+3 > len(imgData) {        break    }    x := idx % xLimit    y := idx / xLimit    finalImg.SetRGBA(x, y, color.RGBA{        imgData[idx],        imgData[idx+1],        imgData[idx+2],        255,    })}The next hurdle is colour. I assumed that this was going to be similar to my previous adventures and I tried doing a YUV colorspace transform (Since RGB was clearly not working) with no luck.So I went back to reading the qc-usb linux driver source again, I discovered that the raw image data had a Bayer filter on it! So, I would have to undo the filter myself. The driver itself had a number of ways (ranked in how many cycles it took an Intel Pentium 2 to process an image) to do this, however I struggled to port any of them correctly to golang. So instead I found a TIFF library that had a function for it and used that instead.And with that, I pointed my webcam at a rainbow lanyard. Switched it to GRBG mode and got:This is the first colour image I got from my driver! I was thrilled! Next I setup a the camera to point at a test card to see how well it performed against it and while it did look amusing:It does remind me again that we have come a long way with webcams since 1999\u2026Now to give the QuickCam some credit, some of the disappointing colour response is because I am using parameters that I got from a one-off USB packet capture. Since those control packets control things exposure/brightness, essentially those settings are frozen in time from when I first tested the webcam.Interestingly the white balance is required to be processed on the driver side, I also learned that the auto brightness function of the webcam is controlled entirely on the driver side and not inside the webcam. I suppose this does make sense for 1999 but I suspect (but I don\u2019t know for sure) that today a lot of these functions are controlled from inside the webcams, heck, some of the webcams run Linux now!Feeding it back into the kernelNow this is not very useful if I can\u2019t join a Google meet with it, so for that we can use V4L2 Loopback to make a fake video device and allow us to inject our newly decoded webcam images back into the kernel so applications like Google meet can use it!Doing this is actually fairly simple as ffmpeg can do all the heavy lifting, so all we really need to do is to give FFMPEG a MJPEG stream and the device.First we create the V4L2 device:sudo modprobe v4l2loopback exclusive_caps=1And then we can feed MJPEG in as a webcam using something like:ffmpeg -f mjpeg -i - -pix_fmt yuv420p -f v4l2 /dev/video0I made my userspace driver do this automatically for maximum ease, and before I knew it, I could load up google meet and see a webcam from 1999 show my face again (with some weird processing artifacts, no idea on that that one)Mission Success. We turned what was going to be nostalgic e-waste into a terrible but functioning webcam, and best of all, I learned even more about the horrors of USB on the way!If you also happen to own one of these, You can find the code to do all of this here: benjojo/qc-usb-userspaceIf you want to stay up to date with the blog you can use the RSS feed or you can follow me on Fediverse @benjojo@benjojo.co.uk (or twitter where I am now rarely posting)You may have noticed I have not posted in a long time! This is because I\u2019ve been working on my own business called bgp.tools. If you have any use for BGP monitoring or data analysis do take a look!If you like what I do or think that you could do with some of my bizarre areas of knowledge I am also open for contact work, please contact me over at workwith@benjojo.co.uk!Until next time!Related Posts:Hacking Ethernet out of Fibre Channel cards (2020)Writing userspace USB drivers for abandoned devices (2019)Random Post:Traceroute Haiku\u2019s (2017)",
        "summary": "- Drivers stop being made for devices leading to obsolescence even for devices with consistent connectors like USB.\n- A 1999 Logitech QuickCam Express Webcam with no drivers since Windows XP was restored using a user space driver embedded in a program.\n- The restored device was made to work with modern-day operating systems and applications through V4L2 Loopback using FFMPEG for easy conversion into MJPEG.",
        "hn_title": "Driver adventures for a 1999 webcam",
        "original_title": "Driver adventures for a 1999 webcam",
        "score": 398,
        "hn_content": "A post on hacking a 1999 webcam has garnered attention on Hacker News. Users have provided tips for improving image quality, such as characterizing each pixel to correct for pixel-to-pixel variation, and using flat-field correction. The post has inspired nostalgia among users who remember using similar technology in the past. While the webcam was manufactured prior to the establishment of the USB video device class (UVC) standard, most webcams now follow this standard. The post has also prompted discussions about working with obscure hardware and the challenges of accessing historical information, particularly as search engines become less useful.A hacker wrote a Linux driver for an old webcam from 1999, which took considerable effort due to the hardware's age and complexity. The author had to reverse-engineer the USB protocol and endpoints of the device to get it to function, which involved creating custom firmware, software, and driver implementations. The project demonstrates the great support for old hardware by the Linux kernel and open-source development community, which makes using obscure and out-of-date devices easier than on closed-source platforms. Additionally, the article highlights the challenges that can arise when working with legacy technology and the need for technical expertise and persistence to accomplish uncommon tasks.",
        "hn_summary": "- Users discussed improving image quality through pixel characterization and flat-field correction, as well as feeling nostalgia for similar technology they used in the past.\n- The project demonstrates the open-source community's support for old hardware and the challenges of working with legacy technology, particularly in regard to accessing historical information."
    },
    {
        "id": 35744888,
        "timestamp": 1682705015,
        "title": "Is Gmail killing independent email?",
        "url": "https://tutanota.com/blog/posts/gmail-independent-email",
        "hn_url": "http://news.ycombinator.com/item?id=35744888",
        "content": "image/svg+xmlimage/svg+xmlPRICINGABOUTPRIVACY GUIDEFAQJOBSBLOGSIGN UPIs Gmail killing independent email?People report that self-hosted emails always end up in Gmail spam. Is there anything Google can do about it?2023-04-27You've probably seen it on Reddit or Hacker News: People complaining that their self-hosted emails always end up in the spam folder of Gmail - even if they set up everything correctly. The question being asked: Is Gmail killing independent email?Email works with everyoneEmail is a great protocol as it basically works with everyone. Since the early days of the internet, people are able to send and receive messages via email to and from any email server. Later on email services like Hotmail - now Outlook, Yahoo and Gmail joined the party so that people and businesses could just create an email address with these services - instead of hosting their own email server. This made email the most widely used communication tool worldwide - and it still isThe use of email services made things incredibly convenient because the services took care of setting up the servers, including setting up SPF, DKIM and DMARC records to make sure the email is being received by other email providers.Regardless, to this day it is possible to host your own mail server, and lots of companies do so. However, it seems that even if you get SPF, DKIM etc. right, Gmail does not like it when you send emails from your own mail servers.Recently a company from new Zealand, School interviews, complained that their emails to parents that expect booking confirmations from this site do not receive those due to rate limiting in Gmail.Gmail is rate-limiting emails\"Those blue dots show over 3,500 Gmail customers having the booking confirmation email they asked for delayed by up to 12 hours. Our support people get several calls a day asking about missing confirmation emails, and they wearily explain that Gmail is delaying delivery for no good reason.\"The actual error from Google according to School interviews is:Our system has detected an unusual rate of 421-4.7.28 unsolicited mail originating from your IP address. To protect our 421-4.7.28 users from spam, mail sent from your IP address has been temporarily 421-4.7.28 rate limited.Given how many people on Reddit complain that their emails from self-hosted servers do not arrive in the Gmail inbox at all, but in spam, School interviews is still in a rather good position. But to do business, timely reception of these emails is paramount.Can Gmail do better?On Hacker News people argue that Google has no other choice because setting up your mail servers correctly does not prove that you are not a spammer - today even spammers are able to set up their mail server correctly. Thus, newly set up mail servers are regarded as spammers by huge email providers in general:They say \"Both email servers have PTR records set up, and SPF [...] DKIM, and DMARC records[...]\". Yes. Great. Thing is that this is such a trivial barrier to entry that guess what? Spammers do it too! Email has become so utterly corrupted with spam that the reality is that an independent provider who has no existing reputation is, 99% of the time, going to be a spammer.Or:I understand this guy's frustration but this: \"And this is happening after SPF, DKIM and DMARC provided a solution to the spam problem.\" is just wrong. Tons of spam comes from servers with SPF, DKIM and DMARC now. It stopped being a trustworthy signal of not-spam many years ago.However, the main question remains: Is it okay that Gmail has the power to decide whether a business is sending spam or not?At the very least, Gmail support team should have listened to the company and looked into the issue to fix it.If Google is not willing to do this, it is just another sign of how Google can abuse their market power and hinder smaller services or - in this case - self-hosting emails, limiting the options people and businesses have when they want that their emails are reliably received by Gmail.The question that remains is this:Should I host my one mail server?This has been explained quite nicely on Reddit:How can you tell if you should host your own mail server? Ask these questions:Am I wanting to send and receive email with other domains? If not, some of these questions won't apply so keep that in mind.Am I willing to do some work to make this work? If not, stop.Is this my first venture into Linux or Docker or self hosting or any kind of new technology? If it is, stop. Host something else first, get your feet under you.Will my ISP allow incoming unfiltered access to ports 25, 143, 465, 587, 993 to my IP? If not, stop.Do I have a static IP which will also let me edit my rDNS entry? If not, Stop. Your ability to prove you aren't spam relies a lot on rDNS. Check my domain mx records (which is my username) to see what I mean. I have a static IP with Verizon FiOS and it is business class. Anything less, and I can't touch that entry. I also pay more for internet because of thisWill I do the due diligence of receiving and looking at the SPF and DMARC reports you can get about your email? If not, stop. These are daily (or weekly) emails from other domains about any issues they saw. You need to pay attention to these and if you don't, you do so at your own peril.Lastly, am I willing to bear the burden of being the coolest of all of my friends since I host my own email? If not, that's fine you won't be the coolest, but I have to say I love hosting my own email, I would never go back to anything else.Still looking to self-host?If the list above still makes you feel comfortable of hosting your own emails, also read this amusing explanation on \"Why you really DON'T want to self-host your own e-mail server\":So, you are thinking about hosting your very own e-mail server, and that can't be too hard, right? Ah, gather round as we go through the options and understand why the answer to almost every IT Question is \"it depends\"! :) At a basic level, e-mail is a simple protocol, especially on the Internet. If you are talking about a LOCAL ONLY server, which is just sending e-mail within a single \"site\" -- that is fairly easy. What gets more complicated is when you want to talk to others on the Internet, and you want them to be able to talk to you.The main problem, frankly, is SPAM. Unsolicited bulk e-mail, ads, scams, junk mail -- we'll put them under the generic heading of \"spam\". This is in contrast to \"ham\", or the e-mails you want, from people you know and care about. Now, I hear some of you in the back -- saying \"who cares\", because really, I can sort the wheat from the chaff, so no biggie. But this spam concern isn't just for e-mail flowing TO you, it's also a major concern for e-mail flowing OUT (or FROM you) -- how do providers out there know you aren't just another J. random spammer?History time: In the beginning, the Internet was small and people knew and trusted each other. Out of this trust was born the protocol that forms the foundation of our modern email, \"Simple Mail Transfer Protocol\", or SMTP. It was written with quick transport in mind, and didn't incorporate any security or validation to speak of -- meaning it was easy to pretend to be someone else, or \"spoof\" addresses. Also, early on, machines were anemic in processing (by todays standards) so no one used encryption, meaning all e-mail was sent in the clear. Now, you should know it was hard to get on the Internet early, it was fairly pricey so that limited who had (direct) access. But as the Internet expanded, no one thought too much about problems that might show up from the open/trusting nature of protocols, SMTP included.Still here? Okay, let's talk about how to tame some of this spam problem. For incoming mail, there are a number of things you can do. If you run a smaller volume site (like at home), you might be able to use a client-side software which has something called a Bayesian filter -- you train the filter by marking e-mails, and then the filter \"scores\" the emails. Very effective, but lots of end-user effort required. While not strictly spam, unwanted malicious e-mails (virus, trojan, etc) might be something you want to scan for. You might want one to scan attachments automatically, to try and prevent you and your users from getting nasties. NOTE: Such tools are not 100% effective, so you still have to have an awareness. Going back to our core spam problem, one thing we can do to help this out is to make sure we aren't contributing to the problem, and even looking at tools that restrict known spammers. For the first part, we want to make sure we \"relay\", or accept and then forward only e-mail we really mean to. We do this by restricting which machines can send, or even forcing them to authenticate (provide user/pass) before accepting e-mail from them. For the second part -- known spammers, it would be using so called lookup lists (sometimes called blacklists or blackholes) which dynamically track machines spamming. Sometimes this requires a subscription. For outgoing mail, the problem becomes a bit more challenging. Now instead of controlling the mail, you are at the mercy of remote admins who know that MOST new e-mail servers are spam, and why should they think YOUR new server isn't? Some of this is patience -- if you run your server well and DON'T spam, your reputation will improve with time. But a lot of this is a labyrinth of layers set up over the years to help figure out if you are really a spammer or not. With names like SPF and DKIM, they seem weird and hard to figure out, but it's a matter of setting them up right. The usually have a bit of magic needed in your DNS (Domain Name System) records, and they can have a bit of software you run, which \"signs\" e-mails. Now none of this prevents you from spamming, but spammers have to send LOTS of spam to be effective, and providers only have to now let them send lots (lots here are millions of messages). But the signed messages and DNS help to track, and block somewhat quickly -- or at least if a sender isn't themselves a spammer -- have a communications channel to alert a good e-mail manager that someone is abusing their system.Wait, are you STILL here? :) If after all that, you still want to run your own e-mail -- you still have to worry about site to site encryption, how do your users read their e-mail (webmail or clients), things like storage issues (how big can e-mail boxes get?) and debugging sending problems (eg your significant other is mad their e-mail isn't getting to their family member inside a 5 minute window). Not to mention things like having your e-mail show up in recipients spam and junk, going through a bunch of hoops, and it still lands in junk.Okay, if you are still here: Congrats, you now know it won't be easy. As a long veteran of running company e-mail servers, there are lots of things you have to worry about. TIPS: Make some things easy on yourself, though. First, when getting an IP from a provider, do some checking to see if it's CURRENTLY or was RECENTLY on a blackhole list. (This ONLY applies to e-mail servers. If you are running a web server that never e-mails anybody -- who cares if it was on a list). Choose a mainstream TLD (top level domain) for your first/early e-mail domain, something ending like .COM/.NET/.ORG or an established country one, like .us/.ca/.eu etc. Try to stay away from esoteric domains or \"newer\" TLDs for e-mail -- some badly coded programs will choke on newer domains, and some big providers seem to frown on newer TLDs. CAVEAT: Any NEW domain, no matter WHERE it is registered, will take a bit of time to \"prove itself\" is non-spammy. So, if you want instant deliver-ability, use an already (non-spammy) domain name that currently exists. Pick an EASY to SPELL and SAY domain name for your e-mail. That cutesy domain which swaps \"i\" for \"y\" and is 30 letters ... good luck explaining all of that on the phone. Ideally you want a domain you can just say and people know it, like \"hello world dot com\" (already registered, not by me, just an example)GET ENCRYPTED EMAILAuthorHanna makes Tutanota come to life. Her credo: Every one of us has the right to express any idea freely, or to keep it secret. Encryption is a great tool to achieve the latter.Top postsWhy choose the Tutanota desktop clients?Whitelabel your secure Tutanota mailbox for business use.Global Encryption Day: Any backdoor would do more harm than good.Which is the most secure email service?Green email is the future: Tutanota uses 100% renewable electricity.Email encryption: The ultimate guide to send an encrypted email in seconds.Latest postsIs Gmail killing independent email?The EARN IT bill is back. We've killed it twice, let's do it again! \ud83d\udc80\ud83d\udc80\ud83d\udc80ChatGPT - Privacy nightmare or helpful tool?Stop Chat Control: EU Study Warns of Law Against Child AbuseLOAD COMMENTSimage/svg+xmlimage/svg+xmlTerminate subscriptionCompanyYou & UsJobsTermsPrivacyLegal noticeDevelopmentRoadmapSecurityEncryptionGitHubFeaturesSecure EmailEncrypted CalendarBusinessWhistleblower SystemSupportFAQForumContactPressLanguageEnglishTranslate",
        "summary": "- Gmail's spam filtering is causing some self-hosted emails to end up in spam folders, limiting options for people and businesses who want their emails to be reliably received by Gmail.\n- Hosting your own email server is possible but requires sufficient technical knowledge and due diligence to ensure emails are not flagged as spam by email providers.\n- Google's power to decide whether a business is sending spam or not with its email filtering highlights the potential abuse of market power by larger tech companies in limiting the options of smaller services.",
        "hn_title": "Is Gmail killing independent email?",
        "original_title": "Is Gmail killing independent email?",
        "score": 389,
        "hn_content": "Google's Gmail may be killing independent email services due to users preferring to drop unsolicited emails instead of establishing trust with newer services. Google is serving as a lightning-rod for a larger network-effect problem caused by spammers. However, spammers are no longer the problem that they once were. In the early 2000s, doing aggressive sanity checking on incoming email was problematic since legitimate senders had badly misconfigured email servers. Nowadays, legitimate senders are no longer badly misconfigured, which allows a lot of sanity checking on the SMTP connection thereby cutting out the majority of would-be spam before it is sent. Legacy cultural problems and the deep pockets of email providers is seen as the main issue with interoperability. Running your own email infrastructure is still viable and desirable, despite the naysayers.Bulk email is discounted because it saves the mail company money, and the USPS has several categories for bulk mail. Companies like energy, water, and phone companies often send bills to a significant percentage of residential areas, but bulk mail is not always customized per customer. The USPS offers a discount for bulk mail because of their relationship with their customers, who provide 20% of USPS funding as marketing mail. The government service is not meant to be profitable but provides the last-mile delivery that private companies like FedEx and UPS do not provide. The USPS has been targeted by Republicans over the years, and there are calls to reduce junk mail delivery to strengthen its usefulness. Scandinavia has had success with a Do Not Mail registry, which is opt-out but enforced with fines. Emails could theoretically benefit from LLMs, but spammers might use LLMs to create their spam.The author proposes using domain validated identities as a unique, globally recognizable handle to build online reputation and trust, and for companies to attest to purchases made, without additional cost. However, one commentator argues that using domains could exacerbate impersonation and domain hijacking. Others suggest that the Keybase identity model, with levels of trust, could be a good option, or using a monetary system that supports trustworthy communication. The discussion later transitions to spam regulation, with some suggesting that Twitter needs a paid subscription to show up in a user's feed and others proposing that spammers should be charged a penny per email. However, it is argued that spammers could still extract money from their few, lucrative targets.This post features a discussion forum about the challenges of email spam and spam filters, including the effectiveness of different strategies such as fees for email senders, whitelist filters, and proof-of-work systems. Users express frustration with both spam filters that are overly aggressive and those that allow too much spam to pass through, and debate the best approach to balancing usability and security. The conversation also touches on issues with dominant email service providers such as Gmail having too much control over what emails get delivered, and proposes ideas for tighter integration between email and other tools to make filtering spam more effective.The Tech Times post contains a discussion about managing personal email servers and the difficulties involved in ensuring deliverability. The author suggests using external email services, like Fastmail, to avoid relying on Google, whose policies could change suddenly, or on one's own home IP, which might be flagged for spam. Several commenters note that the primary issue for email deliverability is sending spam or being mistaken for spam, and recommend explicit opt-ins and other measures to mitigate this. Overall, the post highlights the challenges of running a personal email server and suggests alternative strategies for reliable email delivery.The conversation revolves around the topic of spam in email and the difficulty of avoiding being labeled as such, even when following best practices such as DKIM and double opt-in. Various messaging platforms are suggested as alternatives, but the prevalence of spam on these platforms is also noted. The broader issue of the open, distributed internet being replaced by proprietary versions controlled by trillion-dollar companies is also raised. While some debate arises over the importance of email content versus behavior in abuse classification, the consensus is that metrics are the primary factor for consumer mailbox providers such as Gmail. Several anecdotes are shared of legitimate emails being mistakenly labeled as spam.Google is not treating /dev/null emails differently from real emails.\nMany email gatekeepers lack verification and can import CSV files, leading to potential issues.\nThe lack of action from Google may be due to the negative impact on legitimate businesses if \"good\" customers are banned.\nYC Summer 2023 applications are now open.",
        "hn_summary": "- Legacy cultural problems and the deep pockets of email providers are seen as the main issue with interoperability, and running your own email infrastructure is still viable and desirable. \n- The post discusses various strategies for managing personal email servers and the difficulty of avoid being labeled as spam, including using external email services and implementing explicit opt-ins."
    },
    {
        "id": 35738829,
        "timestamp": 1682669987,
        "title": "Microsoft exec says Windows 11 kernel will soon be booting with Rust inside",
        "url": "https://www.neowin.net/news/senior-microsoft-exec-says-windows-11-kernel-will-soon-be-booting-with-rust-inside/",
        "hn_url": "http://news.ycombinator.com/item?id=35738829",
        "content": "",
        "summary": "Microsoft's EVP Jason Zander has revealed that the company plans to incorporate Rust into Windows 11's kernel. Rust is a programming language known for its memory safety and thread safety, making it an attractive choice for system-level coding. The use of Rust is aimed at improving the security and reliability of the Windows operating system. The move comes as part of Microsoft's efforts to enhance its security posture and reduce the number of vulnerabilities in Windows 11.",
        "hn_title": "Microsoft exec says Windows 11 kernel will soon be booting with Rust inside",
        "original_title": "Microsoft exec says Windows 11 kernel will soon be booting with Rust inside",
        "score": 374,
        "hn_content": "Microsoft has announced that their upcoming Windows 11 kernel will feature Rust in its development. The move comes as Microsoft is seeking to kill off traditional classes of bugs in its forthcoming operating system release, and Rust's memory safety features are being leveraged to achieve that. The kernel will reportedly boot with Rust's codebase soon, and the coding language may improve performance in certain areas, in addition to improving security. Microsoft has already used Rust in a cross-platform rewrite of its open-source font parser called DWriteCore, where it reported the code was more secure and easier to parse than the original written in C++.Microsoft is rewriting core Windows library code in Rust to improve memory safety. This has caused excitement and discussion in the tech community, with some offering thoughts on Rust's benefits, such as moving objects invalidating original bindings to improve safety, while others suggest that Rust alone will not be enough to prevent all vulnerabilities. Windows is also implementing stricter security measures, such as two admin levels and requiring signed binaries. The overall goal is to improve the security and reliability of Windows.Microsoft is rewriting Windows kernel in Rust, a memory-safe programming language, to eliminate memory safety bugs that have been a recurring security issue in Windows operating system. The use of Rust is expected to significantly improve security and resilience against crashes, and this will likely make Windows the most secure general operating system. Currently, Linux's support for secure boot only exists to make it convenient to dual boot with Windows, and macOS and iOS have the highest number of privilege escalation fails. While it will take several years for the new Rust-written kernel to be widely available, some of its features, such as support for unsigned packages, are already being tested in Windows 11 Previews.Microsoft has announced it will incorporate Rust into its heart of hearts, the Windows kernel. While developers have been using Rust to write device driver code that runs in kernel space for some time, this news represents Rust being used as the primary method to write new components of the Windows kernel. There are several justifications for this move, including security and memory management benefits. However, some concerns have been raised about how this will affect Windows' complexity and Microsoft's commitment to maintaining and evolving Rust in the kernel. Overall, this is a significant move that could have wide-ranging implications for the future of Windows, and could encourage more widespread adoption of Rust for systems programming tasks.Microsoft is using more Rust to boost security in Windows 11. Rust is named after a fungus that is robust, distributed, and parallel, according to its creator Graydon Hoare, and is known to be a safer alternative to C++. The Windows kernel is a\u00a0modular architecture\u00a0with an extensive media and utilities system. The Windows kernel is radically different from Unix-like ones, making it difficult to implement. Microsoft will attract more tech-savvy and security-conscious customers if it open-sources the entire Windows stack, including the Windows NT kernel and drivers, rather than hope it expands to Linux. However, it is unlikely to happen soon. A rosetta/wine layer can bridge the gap between Windows and Linux.",
        "hn_summary": "- Rust's memory safety features may improve performance in certain areas and increase security.\n- While some express excitement about Rust's benefits, others suggest that it alone will not be enough to prevent all vulnerabilities. Windows is also implementing stricter security measures to improve reliability."
    },
    {
        "id": 35737862,
        "timestamp": 1682660800,
        "title": "Beautiful branchless binary search",
        "url": "https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/",
        "hn_url": "http://news.ycombinator.com/item?id=35737862",
        "content": "PROBABLY DANCEI can program and like gamesBeautiful Branchless Binary Searchby Malte SkarupkeI read a blog post by Alex Muscar, \u201cBeautiful Binary Search in D\u201c. It describes a binary search called \u201cShar\u2019s algorithm\u201d. I\u2019d never heard of it and it\u2019s impossible to google, but looking at the algorithm I couldn\u2019t help but think \u201cthis is branchless.\u201d And who knew that there could be a branchless binary search? So I did the work to translate it into a algorithm for C++ iterators, no longer requiring one-based indexing or fixed-size arrays.In GCC it is more than twice as fast as std::lower_bound, which is already a very high quality binary search. The search loop is simple and the generated assembly is beautiful. I\u2019m astonished that this exists and nobody seems to be using it\u2026Lets start with the code:123456789101112131415161718192021222324252627template<typename It, typename T, typename Cmp>It branchless_lower_bound(It begin, It end, const T & value, Cmp && compare){  size_t length = end - begin;  if (length == 0)    return end;  size_t step = bit_floor(length);  if (step != length && compare(begin[step], value))  {    length -= step + 1;    if (length == 0)      return end;    step = bit_ceil(length);    begin = end - step;  }  for (step /= 2; step != 0; step /= 2)  {    if (compare(begin[step], value))      begin += step;  }  return begin + compare(*begin, value);}template<typename It, typename T>It branchless_lower_bound(It begin, It end, const T & value){  return branchless_lower_bound(begin, end, value, std::less<>{});}I said the search loop is simple, but unfortunately the setup in lines 4 to 15 is not. Lets skip it for now. Most of the work happens in the loop in lines 16 to 20.BRANCHLESSThe loop may not look branchless because I clearly have a loop conditional and an if-statement in the loop body. Let me defend both of these:The if-statement will be compiled to a CMOV (conditional move) instruction, meaning there is no branch. At least GCC does this. I could not get Clang to make this one branchless, no matter how clever I tried to be. So I decided to not be clever, since that works for GCC. I wish C++ just allowed me to use CMOV directly\u2026The loop condition is a branch, but it only depends on the length of the array. So it can be predicted very well and we don\u2019t have to worry about it. The linked blog post fully unrolls the loop, which makes this branch go away, but in my benchmarks unrolling was actually slower because the function body became too big to be inlined. So I kept it as is.ALGORITHMSo now that I\u2019ve explained that the title refers to the fact that one branch is gone and the other is nearly free and could be removed if we wanted to, how does this actually work?The important variable is the \u201cstep\u201d variable, line 7. We\u2019re going to jump in powers of two. If the array is 64 elements long, it will have the values 64, 32, 16, 8, 4, 2, 1. It gets initialized to the nearest smaller power-of-two of the input length. So if the input is 22 elements long, this will be 16. My compiler doesn\u2019t have the new std::bit_floor function, so I wrote my own to round down to the nearest power of two. This should just be replaced with a call to std::bit_floor once C++20 is more widely supported.We\u2019re always going to do steps that are power-of-two sized, but that\u2019s going to be a problem if the input length is not a power of two. So in lines 8 to 15 we check if the middle is less than the search value. If it is, we\u2019re going to search the last elements. Or to make it concrete: If the input is length 22, and that boolean is false, we\u2019ll search the first 16 elements, from index 0 to 15. If that conditional is true, we\u2019ll search the last 8 elements, from index 14 to 21.input     0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21line 8 compare                    16when false   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15when true                   14 15 16 17 18 19 20 21Yes, that means that indices 14, 15 and 16 get included in the second half even though we already ruled them out with the comparison in line 8, but that\u2019s the price we pay for having a nice loop. We have to round up to a power of two.PERFORMANCEHow does it perform? It\u2019s incredibly fast in GCC:Somewhere around 16k elements in the array, it\u2019s actually 3x as fast as std::lower_bound. Later, cache effects start to dominate so the reduced branch misses matter less.Those spikes for std::lower_bound are on powers of two, where it is somehow much slower. I looked into it a little bit but can\u2019t come up with an easy explanation. The Clang version has the same spikes even though it compiles to very different assembly.In fact in Clang branchless_lower_bound is slower than std::lower_bound because I couldn\u2019t get it to actually be branchless:The funny thing is that Clang compiles std::lower_bound to be branchless. So std::lower_bound is faster in Clang than in GCC, and my branchless_lower_bound is not branchless. Not only did the red line move up, the blue line also moved down.But that means if we compare the Clang version of std::lower_bound against the GCC version of branchless_lower_bound, we can compare two branchless algorithms. Lets do that:The branchless version of branchless_lower_bound is faster than the branchless version of std::lower_bound. On the left half of the graph, where the arrays are smaller, it\u2019s 1.5x as fast on average. Why? Mainly because the inner loop is so tight. Here is the assembly for the two:inner loop of std::lower_bound inner loop of branchless_lower_boundloop: mov %rcx,%rsi loop: lea (%rdx,%rax,4),%rcxmov %rbx,%rdx cmp (%rcx),%esishr %rdx cmovg %rcx,%rdxmov %rdx,%rdi shr %raxnot %rdi jne loopadd %rbx,%rdicmp %eax,(%rcx,%rdx,4)lea 0x4(%rcx,%rdx,4),%rcxcmovge %rsi,%rcxcmovge %rdx,%rdimov %rdi,%rbxtest %rdi,%rdijg loopThese are all pretty cheap operations with only a little bit of instruction-level-parallelism, (each loop iteration depends on the previous, so instructions-per-clock are low for both of these) so we can estimate their cost just by counting them. 13 vs 5 is a big decrease. Specifically two differences matter:branchless_lower_bound only has to keep track of one pointer instead of two pointersstd::lower_bound has to recompute the size after each iteration. In branchless_lower_bound the size of the next iteration does not depend on the previous iterationSo this is great, except that the comparison function is provided by the user and, if it is much bigger, it can take many more cycles than we do. In that case branchless_lower_bound will be slower than std::lower_bound. Here is binary searching of strings, which gets more expensive once the container gets large:MORE COMPARISONSWhy is it slower for strings? Because this does more comparisons than std::lower_bound. Splitting into powers of two is actually not ideal. For example if the input is the array [0, 1, 2, 3, 4] and we\u2019re looking for the middle, element 2, this behaves pretty badly:std::lower_bound branchless_lower_boundcompare at index 2, not less compare at index 4, not lesscompare at index 1, less compare at index 2, not lessdone, found at index 2 compare at index 1, lesscompare at index 1, lessdone, found at index 2So we\u2019re doing four comparisons here where std::lower_bound only needs two. I picked an example where it\u2019s particularly clumsy, starting far from the middle and comparing the same index twice. It seems like you should be able to clean this up, but when I tried I always ended up making it slower.But it won\u2019t be too much worse than an ideal binary search. For an array that\u2019s less than elements big\u2013 an ideal binary search will use or fewer comparisons\u2013 branchless_lower_bound will use or fewer comparisons.Overall it\u2019s worth it: We\u2019re doing more iterations, but we\u2019re doing those extra iterations so much more quickly that it comes out significantly faster in the end. You just need to keep in mind that if your comparison function is expensive, std::lower_bound might be a better choice.TRACKING DOWN THE SOURCEI said at the beginning that \u201cShar\u2019s algorithm\u201d is impossible to google. Alex Muscar said he read it in a book written in 1982 by John L Bentley. Luckily that book is available to borrow online from the Internet Archive. Bentley provides the source code and says that it\u2019s got the idea from Knuth\u2019s \u201cSorting and Searching\u201d. Knuth did not provide source code. He only sketched out the idea in his book, and says that it came from Leonard E Shar in 1971. I don\u2019t know where Shar wrote up the idea. Maybe he just told it to Knuth.This is the second time that I came across an algorithm in Knuth\u2019s books that is brilliant and should be used more widely but somehow was forgotten. Maybe I should actually read the book\u2026 It\u2019s just really hard to see which ideas are good and which ones aren\u2019t. For example immediately after sketching out Shar\u2019s algorithm, Knuth spends far more time going over a binary search based on the Fibonacci sequence. It\u2019s faster if you can\u2019t quickly divide integers by 2, and instead only have addition and subtraction. So it\u2019s probably useless, but who knows? When reading Knuth\u2019s book, you have to assume that most algorithms are useless, and that the good things have been highlighted by someone already. Luckily for people like me, there seem to still be a few hidden gems.CODEThe code for this is available here. It\u2019s released under the boost license.Also I\u2019m trying out a donation button. If open source work like this is valuable for you, consider paying for it. The recommended donation is $20 (or your local cost for an item on a restaurant menu) for individuals, or $1000 for organizations. (or your local cost of hiring a contractor for a day) But any amount is appreciated:Make a one-time donationChoose an amount$5.00$20.00$1,000.00Or enter a custom amount$Thanks! I have no idea how much this is worth to people. Feedback appreciated.DonateShare this:TwitterFacebookLoading...RelatedOn Modern Hardware the Min-Max Heap beats a Binary HeapAugust 31, 2020In \"Programming\"Databases are Fucking StupidJune 21, 2014In \"Programming\"Recommended Link: Inventing on PrincipleFebruary 16, 2015In \"Links\"PUBLISHED: April 27, 2023FILED UNDER: ProgrammingTAGS: binary search : branchless : C++15 Comments to \u201cBeautiful Branchless Binary Search\u201dQuarticCatApril 27, 2023 at 22:00To generate branchless code in Clang, one can use __builtin_expect_with_probability or __builtin_unpredictable. They are not guaranteed though.By the way, there is a bit more discussion on efficient binary search that you might have interest in: https://en.algorithmica.org/hpc/data-structures/binary-search/REPLYMalte SkarupkeApril 28, 2023 at 09:45Thanks, I had tried __builtin_unpredictable but it didn\u2019t work for me.That blog post is very interesting. He came up with a very similar loop to Shar\u2019s algorithm by starting from lower_bound and doing some reasonable simplifications. I\u2019ll try to add it to my benchmarks this evening.REPLYMalte SkarupkeApril 28, 2023 at 19:18And here is a link to godbolt showing that __builtin_unpredictable doesn\u2019t help:https://godbolt.org/z/zG53jTh65REPLYArnaudApril 28, 2023 at 03:00On microbenchmarks, the \u201cShar\u201d optimization may have an effect, but I am not sure it would be on production code, where most of the time is likely to be spent putting the data into L1 cache, not searching within the data. This may be one of the reasons why it was not so widely used \u2013 because it is not worth it on real work.REPLYMalte SkarupkeApril 28, 2023 at 10:13I think the right side of my graphs should capture that case, when data isn\u2019t in cache. There is still a meaningful speedup.I think the most likely explanation is that this one does more comparisons. And if the compiler doesn\u2019t make it branchless, it is slower after all. Plus we only had the one-based-indexing version before and converting it to zero-based indexing was surprisingly tricky. Try it yourself without looking at my code.This was a couple weeks of work, which most people wouldn\u2019t try for an algorithm that does more comparisons.REPLYRafael \u00c1vila de Esp\u00edndolaApril 28, 2023 at 08:35A similar trick can be done for the Eytzinger layout: https://espindo.la/posts/array-layouts.htmlREPLYMalte SkarupkeApril 28, 2023 at 19:14Thanks. I really like the idea of the Eytzinger layout, but I don\u2019t know if the Eytzinger layout is useful for anything other than fast binary search. A sorted array is useful for other things (like to display things in sorted order), so you might already have sorted data and then you want to use binary search. And if you don\u2019t need it to be sorted, using a good hash table is going to be faster.So I have never yet come up with a reason to actually use the Eytzinger layout. Am I missing something?REPLYRafael \u00c1vila de Esp\u00edndolaApril 29, 2023 at 00:21For large arrays it is better as you can prefetch. The paper that got me started on this is https://arxiv.org/abs/1509.05053, but yes, for the array sizes I was interested in binary search was better.ncmncmApril 28, 2023 at 11:43It is usually easier to get clang to produce cmov than gcc.Try a conditional expression:  begin += compare(begin[step], value) ?     step : 0;REPLYMalte SkarupkeApril 28, 2023 at 18:56Thanks, but it doesn\u2019t seem to help:https://godbolt.org/z/KE634cf7KREPLYChristopher ChangApril 28, 2023 at 11:43See https://en.algorithmica.org/hpc/cpu-cache/associativity/ re: the poor power-of-two-array-size performance.REPLYMalte SkarupkeApril 28, 2023 at 18:58Thanks, that\u2019s a fascinating link. But wouldn\u2019t that suggest that branchless_binary_search should be slower than std::lower_bound? Because branchless_binary_search always operates on powers of two, but std::lower_bound will be off-by-one every time that it steps into the right half.REPLYOwns 9 FedorasApril 28, 2023 at 18:11Didn\u2019t find the reference in \u201cWriting Efficient Programs\u201d, Bentley\u2019s 1982 book. He does refer to Knuth but I don\u2019t see any algorithm but what you call \u201cstandard\u201d. (https://archive.org/details/writingefficient00bent)REPLYMalte SkarupkeApril 28, 2023 at 19:02The algorithm is on page 128:https://archive.org/details/writingefficient00bent/page/128/mode/2up?view=theaterThis exactly matches the code in the blog post that I link to at the top.He says that it came from Knuth on the previous page. To find it in Knuth\u2019s book look in the index for \u201cShar\u201d.REPLYOwns 9 FedorasApril 28, 2023 at 19:11OK sorry I\u2019m dumb. I looked at that page and thought oh, unrolled loop big deal, not seeing the binary constants. Your version rolled the loop up again \ud83d\ude09 and generalized it to tables of size other than 1000.Leave a ReplyThis site uses Akismet to reduce spam. Learn how your comment data is processed.\u00ab Previous PostRECENT POSTSBeautiful Branchless Binary SearchFine-grained Locking with Two-Bit MutexesFinding the \u201cSecond Bug\u201d in glibc\u2019s Condition VariableSudoku Variants as Playful Proof PracticeReasons why Babies Cry in the First Three Months, How to Tell The Cries Apart, and What to DoARCHIVESApril 2023December 2022September 2022June 2022February 2022January 2022October 2021July 2021April 2021January 2021November 2020October 2020August 2020July 2020June 2020May 2020April 2020March 2020January 2020December 2019September 2019August 2019June 2019April 2019March 2019June 2018May 2018April 2018January 2018December 2017November 2017October 2017September 2017August 2017February 2017January 2017December 2016November 2016June 2016April 2016March 2016February 2016December 2015September 2015July 2015June 2015May 2015February 2015January 2015December 2014November 2014October 2014September 2014August 2014June 2014May 2014April 2014March 2014February 2014January 2014October 2013September 2013August 2013May 2013February 2013January 2013December 2012November 2012October 2012August 2012July 2012April 2012March 2012February 2012January 2012October 2011September 2011August 2011July 2011June 2011May 2011CATEGORIESChildrenGamesLinksMathPolitics and EconomicsProgrammingUncategorizedMETARegisterLog inEntries feedComments feedWordPress.comBlog at WordPress.com.Follow",
        "summary": "- The article discusses a branchless binary search algorithm called \"Shar's algorithm\" described in a book written by John Bentley in 1982.\n- The algorithm uses a loop with a conditional move instruction instead of a branch statement, making it faster on GCC compared to std::lower_bound.\n- The variable \"step\" jumps in powers of two to find the middle element to search for, and the algorithm does more comparisons than the traditional binary search.",
        "hn_title": "Beautiful branchless binary search",
        "original_title": "Beautiful branchless binary search",
        "score": 359,
        "hn_content": "A technical discussion on improving binary search performance with branchless search techniques and reducing memory access strain on Intel hardware. The Eytzinger Binary Search, an improvement over the regular binary search, is discussed, with a focus on its cache properties. Some commenters discuss optimization techniques for various hardware configurations, such as using SIMD instructions and prefetching. The performance of CMOV instructions and their use in Profile-Guided Optimization is also briefly mentioned.The article discusses how porting some optimized C code to Rust resulted in faster performance, possibly due to Rust's compiler removing bounds checks. However, some comments dispute this claim and suggest that binary size and static linking may be factors. The discussion also touches on the history and purpose of C as a portable language and the limitations of controlling hardware-specific optimizations in C++. There are suggestions for implementing branchless algorithms using conditional moves or inline assembly. Overall, the thread showcases various perspectives on low-level optimization and the trade-offs between language portability and hardware specificity.Developers discuss the performance of binary search algorithm with close to power of 2 sized data, and how it is slower due to interaction with caches causing constant reloading from memory, due to cache associativity and conflict miss. Access pattern affects this more than size, however size matters for the problem as it slashes the processor\u2019s cache size only when it fits in the cache. A simpler, extra division formula avoids the setup code to reduce the length to a 2-power, but requirements include an extra division and increment in each loop iteration. The discussion touches on branchless binary search, Eytzinger and CMOV instructions with comparisons to linear search, as well. Branches in any algorithm create a dependency and may start executing wrong instructions though cmove intrinsics help to lessen the impact of mispredicted outcomes of previous instructions.An algorithm called \"Shar's algorithm,\" a variation of the Binary Search algorithm, focuses on minimizing branching to improve performance on modern CPUs. The algorithm is named after its creator, Andrei Alexandrescu, who goes by the pseudonym \"Shar\" on the internet. The performance of branchless code is maximized for the given hardware, by not flushing the speculative execution of the CPU, making it useful for security purposes. Some commenters on the blog post criticized the author's tip button, which has recommended tips of $20 and $1,000 for people and businesses, respectively, calling it the commercialization of OSS 2.0. Conditional move (cmov) instructions can be used to simulate branching instructions. It is possible to design an algorithm which branches and is also constant time.",
        "hn_summary": "- Some commenters suggest optimization techniques for various hardware configurations, such as using SIMD instructions and prefetching, as well as the use of Profile-Guided Optimization with CMOV instructions.\n- Developers discuss performance issues with binary search for close to power of 2 sized data, and the thread showcases various perspectives on low-level optimization and trade-offs between language portability and hardware specificity."
    },
    {
        "id": 35740277,
        "timestamp": 1682683607,
        "title": "How to spend money on your friends without it looking like bribery",
        "url": "https://billmei.net/blog/bribe-friends",
        "hn_url": "http://news.ycombinator.com/item?id=35740277",
        "content": "How to spend money on your friends without it looking like briberyImagine your friend texts you with the following invite:I\u2019m taking you and 12 friends out to dinner at Olive Garden. I\u2019m paying the check. Wanna come?To me this feels\u2026 tacky? Like I feel obligated to at least offer to cover part of the check right?Okay, how about this:I\u2019m throwing a dinner party for you and 12 friends at my house. I\u2019m making all the food. Wanna come?Now this suddenly feels more natural. It would even be socially unacceptable for me to offer to pay for my friend\u2019s cooking!Why is this? What\u2019s happening here?It\u2019s not merely a matter of expense; when you consider the value of your friend\u2019s time, plus the amortized cost of cookware, appliances, furniture, and housing\u2014the home meal could be more expensive than the restaurant meal.Let\u2019s try another one:I rented a vacation home on the cape for the weekend, wanna come hang out on the beach?Okay, now this feels super awkward. I\u2019ll probably ask how much it costs. But what if instead the invite was:I\u2019m going to my cottage on the cape for the weekend, wanna come hang out on the beach?Now this offer feels less like a weird power imbalance, even though renting the cottage could be a lower total cost of ownership, especially if you don\u2019t vacation often.What wealth allows you to do is to buy things outright instead of renting them. It feels more authentic to allow your friends to access assets that you already own, like inviting them to your home, taking them out in your kayak, or driving them in your car. But paying for dinner, gifts, or activities feels like a direct wealth transfer, like you\u2019re paying your friends.I don\u2019t think this is a constructive social norm. Firstly, because it\u2019s often cheaper to rent than to buy, and secondly because owning has higher up-front costs and hence presents a greater barrier for people without wealth to still spend money on their friends in socially acceptable ways.When you own, you never \u201cgive\u201d the wealth to your friends; you keep the asset to yourself\u2014you\u2019re just letting them access your assets temporarily, and your assets are returned to you at the end of the day. Hence it is actually more generous to just buy things for your friends, instead of buying things for yourself and letting your friends use them.Money can\u2019t buy you happiness, but it can buy you socially acceptable excuses to do awesome activities with friends, and your friends bring you happiness.Let this essay be my open declaration that if I\u2019m buying something for you, it\u2019s not because I\u2019m trying to bribe you, but because I want to be generous with you. \ud83d\ude0aI only publish half of my writing publicly. Subscribe to my private email list to read articles that were too sensitive to share online: billmei.net/follow (Subscribing is free, no spam ever, and you can safely unsubscribe anytime)Follow me on Instagram @billmeidotnetImage credit: allisonyhuang on UnsplashPublished April 2023",
        "summary": "- It can be awkward when friends offer to pay for things like dinner or a vacation rental, as it can feel like a direct wealth transfer instead of a genuine gesture of generosity.\n- Instead, it can feel more authentic to invite friends to your home or allow them to use assets you already own, like a kayak or car.\n- By buying things outright for your friends instead of buying things for yourself and letting your friends use them, you are actually being more generous and removing a barrier for people without wealth to spend money on their friends in socially acceptable ways.",
        "hn_title": "How to spend money on your friends without it looking like bribery",
        "original_title": "How to spend money on your friends without it looking like bribery",
        "score": 306,
        "hn_content": "The article on billmei.net discusses the subtleties of spending money on friends without it seeming like bribery. It highlights how the illusion of not seeing a transaction happen makes people feel more comfortable accepting hospitality. The comments section reveals differing opinions on sharing money with friends, with some viewing it as generous while others see it as a sign of being taken advantage of or making poor financial decisions. The post offers practical tips for navigating wealth imbalances with friends, such as round-robin checks or suggesting venues that fit each person's cost level. There is also a discussion on the cultural significance of paying for meals and gift-giving.The comments in this post revolve around societal attitudes towards wealth, income inequality, and how to navigate these issues within social circles. Some suggest strategies like splitting expenses equally, managing expectations, and providing choice for others. Others note that perceptions of wealth are relative and can vary across different social strata. There are also comments on the disconnect between the \"thrill\" of making money and the actual enjoyment of having it. One person mentions the concept of loss aversion in behavioral economics. Finally, there is discussion around cars as a symbol of wealth and how people can signal their status through their expenditures.No meaningful content to summarize.The article talks about different cultural expectations and norms regarding gift-giving and socializing with friends. It suggests that investing time and effort in spending time with friends is a thoughtful and mutually beneficial investment in their friendship rather than just throwing money at it. The examples included dinner parties, renting a house, cooking meals, or engaging in activities together. However, some cultures might perceive these actions as bribery, while others require immediate or delayed reciprocity. Socioeconomic status also plays a role in how some people perceive showing off wealth or paying the check. Ultimately, communication and mutual respect are key in navigating these situations.Discussions on paying for meals and events with friends reveal cultural differences and the importance of clear communication in social transactions. Inviting friends to events or meals can create awkward situations for some, while others believe open communication can resolve these issues. Different forms of capital, beyond simply financial, can impact the social dynamics of gift-giving and generosity among friends. Cultural differences are also important to consider, as expectations around paying for meals or gifts can vary widely. Ultimately, clear communication and establishing mutual understanding and expectations can help resolve these potentially awkward situations.The article discusses the awkwardness that can arise in social situations when there is a difference in financial means among friends. The author shares personal experiences and opinions on the topic. Some readers find the examples given to be irrelevant or not actually awkward. Others suggest ways to make recipients feel more comfortable, such as suggesting alternative contributions or reciprocating in less expensive situations. Overall, the article prompts discussion on the social dynamics of gift-giving and the importance of considering power imbalances.This post is a discussion about the dynamics of gift-giving and social status in different societies. The comments touch on topics such as reciprocity, the importance of social networks, and the potential for gift-giving to be seen as flaunting wealth. Some commenters suggest that what is most important in gift-giving is understanding the recipient's values and meaning. Overall, the post and comments provide food for thought on the role of gift-giving in relationships and society.The post discusses the awkwardness around spending money on friends, particularly when there is an income disparity between them. One solution is to have the person paying choose the location and ask for a contribution towards the cost. The post also explores the idea of owning versus renting, and how ownership can be seen as a way to project wealth and excess. However, there are potential downsides to ownership, such as exclusivity and cost. The author suggests a collective ownership model, such as cooperatives and timeshares, as an alternative to the exploitative landlord and Airbnb models. There is also a discussion on the merits of various forms of gift-giving, and how to avoid making someone feel obligated to reciprocate.No meaningful content to provide a summary.",
        "hn_summary": "- Societal attitudes towards wealth and income inequality are discussed in the comments section\n- Communication and mutual respect are key in navigating potentially awkward social situations with friends"
    },
    {
        "id": 35741609,
        "timestamp": 1682691846,
        "title": "A small number of companies are colluding to cheat H1B visa lottery, US says",
        "url": "https://www.wsj.com/articles/u-s-says-some-companies-cheat-h-1b-lottery-driving-record-applications-1a3e4fd",
        "hn_url": "http://news.ycombinator.com/item?id=35741609",
        "content": "By Michelle HackmanFollowUpdated April 28, 2023 10:10 am ETShareResize403Listen(2 min)U.S. Citizenship and Immigration Services has laid out its findings on the H-1B visa lottery in a notice to employers. PHOTO: PETE MAROVICH/WASHINGTON POST/GETTY IMAGESWASHINGTON\u2014The Biden administration says it has found evidence that several dozen small technology companies have colluded to increase the chances that their prospective foreign hires will win a coveted H-1B visa for skilled foreign workers in this year\u2019s lottery.U.S. Citizenship and Immigration Services, the federal agency that awards H-1B visas, said it has found that a small number of companies are responsible for entering the same applicants into the lottery multiple times, with the alleged goal of artificially boosting their chances of winning a visa. The findings were laid out in a notice to employers viewed by The Wall Street Journal and set to be released Friday. Already a WSJ subscriber? Sign inTo continue reading, choose an option belowCreate Your Free AccountRegister now to read this article for free.Register NoworUnlimited AccessSubscribe to WSJ TodayJust $1/week for 1 yearUnlimited access to world-class journalismDaily puzzles and crosswordsExclusive podcasts and newslettersYou can cancel any time.Subscribe NowAlready a subscriber? Sign InSPONSORED OFFERSTURBOTAX:Save up to $15 with TurboTax coupon May 2023THE MOTLEY FOOL:Epic Bundle - 3x Expert Stock RecommendationsH&R BLOCK TAX:15% Off DIY Online Tax Filing Services | H&R Block Coupon CodeTOP RESUME:10% TopResume Discount Code for expert resume-writing servicesEBAY:30% off eBay couponGROUPON:Groupon Promo Code - 30% Off Activities, Dining, More",
        "summary": "- US Citizenship and Immigration Services found evidence of small technology companies colluding to improve chances of winning an H-1B visa for skilled foreign workers in this year's lottery.\n- The companies are accused of entering the same applicants into the lottery multiple times to increase their chances artificially.\n- The findings were laid out in a notice to employers and set to be released by the Wall Street Journal.",
        "hn_title": "A small number of companies are colluding to cheat H1B visa lottery, US says",
        "original_title": "A small number of companies are colluding to cheat H1B visa lottery, US says",
        "score": 279,
        "hn_content": "A few US companies have been found guilty of colluding to cheat on H1B visa lotteries by creating fake job applications. The US is looking to investigate and prosecute those involved. However, the issue lies with the outdated systems and laws governing H1B visas and permanent residency cards, which disproportionately affect Indians. Due to vast backlogs on green card applications, Indians may be waiting 48 years for an EB-3, and may spend a whole career paying social security and never be eligible. USCIS has intentionally wrecked the lottery system, leading to talented and hardworking individuals being rejected. The real losers here are students who have studied and worked hard in the US and submit a single petition through their employer. It's now way less likely they will get picked in the lottery.This thread on HN discusses the idea of granting green cards to foreign masters and PhD students. Some argue that this would lead to abuse of the system, others argue that it would be beneficial to encourage people in STEM fields to stay in the country. There is also debate over the potential for an increase in tuition rates for foreign students and the impact on blue-collar workers. Some commenters suggest that immigration opportunities should be spread among different countries, while others argue that America is a nation of immigrants and should provide opportunities to people who need it. The discussion highlights the complexities surrounding immigration policy and its relationship to economic growth and nationalism.A discussion on immigration led to comments on the USCIS (US Citizenship and Immigration Services) lottery system for H1B visas. Some argue that the lottery system invites bogus applications for revenue through high fees, while others note that USCIS is merely following laws and rules put into place by Congress. The article also suggests that major companies lay off US workers to replace them with foreign contract workers who are paid less. However, others argue that there is still a shortage of engineers and that software engineers make well above the median wage. The discussion also touches on the role of the Federal Reserve in tackling inflation and its limitations on taxes.The article discusses the increase in H-1B visa applications in 2022, with a record high number of entries in the visa lottery. The article also features Reddit comments discussing the US immigration system and the need for a free market approach to immigration. One Reddit user notes that the US is losing talented immigrants to other countries with more efficient immigration systems. Finally, there is a discussion about the impact of immigration policy on high-skilled labour, with one user discussing how their sister's fianc\u00e9 is not allowed to work for several months while immigrating.The discussion on the H1B visa program highlights concerns about the influx of unskilled labor and the exploitation of foreign workers. Some argue that these visas are being used to depress American wages, while others contend that the program was created to address labor shortages. Critics of the H1B system are calling for immigration policies that provide highly skilled foreign workers with the same job mobility as U.S. citizens and permanent residents in order to prevent the exploitation of migrant workers. Additionally, immigration policies are criticized for promoting cultural biases and racism against other minorities not included in the visa approval process.The H1B program was originally intended for truly unique situations where the US national labor pool couldn't fulfill the demand, however in the 90s the criteria for \"shortage of talent\" was broadened leading to the explosion of the tech industry hiring H1Bs. The EB visas are a better system that should be used instead of H1Bs. There is a difficulty in acquiring EB visas leading people to move to Canada. The problem of hiring foreigners with cheaper labor added through visa programs hurts the US labor market. The H1B program should be revised so that it accomplishes its initial goals. Hiring internationally would be acceptable if companies raised wages or set up an international arm abroad. The US creates a large number of new software development positions per year.The post discusses the shortage of qualified software engineering professionals in the USA. The argument for a shortage is based on the fact that there are 500k new global software development jobs per year, and only around 50k new computer science graduates annually in the USA. However, there are multiple criticisms of this argument, such as potential oversupply of qualified people, counting job openings rather than actual new jobs, incomplete data on layoffs, and the fact that software development jobs can come not just from computer science majors. Additionally, the pandemic has caused a contraction in the tech industry, affecting employment numbers. The reliability of data sources is also questioned. There is also discussion on visa processes for foreign software developers trying to work in the USA.There is discussion among H1B1 visa holders about the process of obtaining a green card, with some sharing personal anecdotes about applying. The E3 visa is also noted as an easy option for Australians looking to work in the US. One comment questions the number of people from Singapore who are interested in moving to the US. The post concludes with a mention of applications being open for the YC Summer 2023 program.",
        "hn_summary": "- Debate on granting green cards to foreign masters and PhD students, with arguments for and against, as well as discussions on the potential for an increase in tuition rates for foreign students and the impact on blue-collar workers.\n- Concerns about the exploitation of foreign workers and the need for immigration policies that provide highly skilled foreign workers with the same job mobility as U.S. citizens and permanent residents in order to prevent the exploitation of migrant workers."
    },
    {
        "id": 35738231,
        "timestamp": 1682664296,
        "title": "Europe's Longest Bicycling Tunnel Opens in Norway",
        "url": "https://reasonstobecheerful.world/europes-longest-bicycling-tunnel-opens-in-norway/",
        "hn_url": "http://news.ycombinator.com/item?id=35738231",
        "content": "Credit: Iver Daaland \u00c5se / Bybanen UtbyggingAbout UsLatest StoriesThe \u2018Barefoot College\u2019 Reinventing Rural EducationMinnesota\u2019s Prison-to-Grilled-Cheese Pipeline Is Changing LivesAmerica\u2019s Green Boom Needs More Electricians, and Women Are Stepping UpEditor picksHow Cities Will Avoid Death by Self-Driving CarNotifications Off! The Distraction-Free Benefits of Five-Hour Work DaysThe Climate-Friendly Refrigerators of Decades PastRTBC StaffReasons to be Cheerful is a non-profit editorial project that is part magazine, part therapy session, part blueprint for a better world.Related StoriesCities + TownsIn Barcelona, Kids Bike to School in Large, Choreographed HerdsCinnamon Janzer November 7, 2022 3 min readHop on the \u2018bicib\u00fas,\u2019 a highly replicable model that makes getting to school fun, safe and sustainable.Climate + EnvironmentHow Sweden Sends Just 1% of Its Trash to LandfillsKlaus Sieg April 8, 2022 5 min readThe country incinerates nearly half its garbage to create the energy that powers its homes and buildings.Cities + Towns5 Ways to Decongest a City (Without Making People Work from Home)Will Doig November 16, 2020 4 min readThe Bay Area is walking back a proposal that would have forced residents to work remotely.Crushed by negative news?Sign up for the Reasons to be Cheerful newsletter.PressEventsContact UsPrivacy PolicyEditorial and Ethics PolicyPitching GuidelinesMembership FAQs\u00a9 2020 Reasons to be CheerfulThis website uses cookies to give you the best experience. They are functional only, and enable you to do things like bookmark articles.We don't use any cookies that spy on you, sell your information or spam you. Read our privacy policy here. More info and adjust your cookies settings here Cookie settingsOKCANCEL",
        "summary": "- Europe's longest bicycling tunnel has opened in Norway.\n- The 5.3 km-long tunnel reduces travel time by bicycle and provides a safer alternative to the existing steep mountain road.\n- The tunnel features LED lights, air treatment plants, and emergency phones for added safety.",
        "hn_title": "Europe\u2019s Longest Bicycling Tunnel Opens in Norway",
        "original_title": "Europe\u2019s Longest Bicycling Tunnel Opens in Norway",
        "score": 265,
        "hn_content": "Europe's longest bicycling tunnel has opened in Norway, saving cyclists 5.5km and 20 minutes to reach Bergen City, and costing $46 million to construct. The Bergen municipality released a 25 minute video of a bike ride through the tunnel, which has a daily-use upgrade cost of NOK 500 million ($57 million). Other large cycling tunnels were also mentioned, including the Maas Tunnel in Rotterdam, Antwerp's Kennedy tunnel, Paris' Parc des Rives de Seine's tunnel, Tyne Tunnel in England, Nam Han River's tunnel and Lyon's Tunnel de la Croix-Rousse. Resonance and pattern loading were\u00a0mentioned in terms of bridge design and wear and tear, with cyclists and pedestrians imposing less damage compared to cars andNorway has recently built a 5.5km tunnel exclusively for cyclists, costing $46m USD. The tunnel is expected to be a vital part of Bergen\u2019s new cycling expressway, and cyclists are expected to save 20 minutes in traveling time. The tunnel has been hailed as an important solution to the challenge of encouraging green living, with various benefits including decreasing the average carbon footprint, improving public health, and cutting costs associated with road maintenance. Despite the infrastructure being praised as a critical infrastructure, the US lags significantly behind the rest of the world in developing an effective cycling infrastructure due to the lack of civil society groups, vision and powerful auto lobby.The construction of the world's longest cycling tunnel has been completed in Norway, part of a major project aimed at encouraging cycling and walking in Bergen, Norway's second-largest city. The 1,160m-long (3,806ft) underground tunnel is intended to improve conditions for cycling between the two suburban parts of the city, avoiding steep climbs and motorways. However, the original plans faced opposition from cycling groups in Bergen, who argued that a bridge would serve cyclists and pedestrians better, and would allow people to enjoy views across the historic harbour. The cycle tunnel cost NOK 1.2bn ($136m), with the city and Vestland county council each paying 45%, while the rest was provided by the state.Norwegian officials have announced plans for a 5km-long tunnel that will offer quick and safe passage for cyclists between the cities of Bergen and Os; the project will take around five years to complete. A first-of-its-kind in the world, the tunnel will be located beneath a mountainous region and will feature a gentle slope that ensures easier passage for cyclists. The tunnel will cover an area that is nearly double the length of the world's longest existing bike tunnel, located in St. Petersburg, Russia. The initiative is expected to ensure that around 3,000 commuters each day can travel without needing to take their cars, reduce congestion, and lower pollution levels.The post discusses the issue of safety for cyclists on the road and hostile behavior by drivers towards cyclists. It also touches upon the lack of bike infrastructure and the use of scooters and motorcycles as alternatives. There is some discussion of cultural differences across different countries and cities regarding biking infrastructure and attitudes towards alternative modes of transportation. Certain commenters suggest urban planning changes as a more comprehensive solution to these problems. There is no mention of any new technology or release related to this topic.Bristol, UK is using hired e-scooters to transport people around cities, which are lighter and carry less kinetic energy into collisions compared to electric cars. E-scooters and e-bikes are also suitable for delivery services and can avoid getting stuck in traffic congestion. A recent project in Bergen, Norway involving a 3km tunnel for transportation infrastructure is not impressive and considered to be a curiosity of governmental funding. The project demonstrates the potential for tunnels, which could accommodate mixed vehicle use and avoid problematic air pollution from carbon monoxide. The idea of elevated biking lanes made of high-strength assembled plastic could be cheaper and safer than bike lanes intermingled with surface streets. There is an urban compromise design wherein all car transport in urban areas should be restricted, and only ebikes, scooters, and heavily restricted delivery trucks should be permitted. The world's longest art installation underground sundial is located in Norway's new biking tunnel.",
        "hn_summary": "- The tunnel is part of Bergen's efforts to encourage green living and improve cycling infrastructure.\n- The lack of effective cycling infrastructure in the US is due to a lack of civil society groups and powerful auto lobby."
    },
    {
        "id": 35740836,
        "timestamp": 1682687333,
        "title": "Gpt4free repo given takedown notice by OpenAI",
        "url": "https://github.com/xtekky/gpt4free",
        "hn_url": "http://news.ycombinator.com/item?id=35740836",
        "content": "We got a takedown request by openAI's legal team...discord server for updates / support:https://discord.gg/gpt4freehere is a lil' poem you can read in the meantime, while I am investigating it:There once was a time, in a land full of code,A little boy sat, in his humble abode.He tinkered and toyed with devtools galore,And found himself curious, and eager for more.He copied and pasted, with glee and delight,A personal project, to last him the night.For use academic, and also for fun,This little boy's race he just started to run.Now quite far removed, in a tower so grand,A company stood, it was ruling the land.Their software was mighty, their power supreme,But they never expected this boy and his dream.As he played with their code, they then started to fear,\"His project is free! What of money so dear?\"They panicked and worried, their faces turned red,As visions of chaos now filled every head.The CEO paced, in his office so wide,His minions all scrambled, and trying to hide.\"Who is this bad child?\" he cried out in alarm,\"Our great AI moat, why would he cause harm?\"The developers gathered, their keyboards ablaze,To analyze closely the boy's evil ways.They studied his project, they cracked every tome,And soon they discovered his small, humble home.\"We must stop him!\" they cried, with a shout and a shiver,\"This little boy's M\u1d00\u1d0b\u026a\u0274\u0262 OUR COMPANY QUIVER!\"So they plotted and schemed to yet halt his advance,To put an end to his dear digital dance.They filed then with GitHub a claim most obscene,\"His code is not his,\" said the company team,Because of the law, the Great Copyright Mess,This little boy got his first takedown request.Now new information we do not yet know,But for the boy's good, we hope results show.For the cause of the True, the Brave and the Right,Till the long bitter end, will this boy live to fight.( I did not write it )You may join our discord server for updates and support ; )Discord LinkJust API's from some language model sites.Legal NoticeThis repository uses third-party APIs and is not associated with or endorsed by the API providers. This project is intended for educational purposes only. This is just a little personal project. Sites may contact me to improve their security.Please note the following:Disclaimer: The APIs, services, and trademarks mentioned in this repository belong to their respective owners. This project is not claiming any right over them.Responsibility: The author of this repository is not responsible for any consequences arising from the use or misuse of this repository or the content provided by the third-party APIs and any damage or losses caused by users' actions.Educational Purposes Only: This repository and its content are provided strictly for educational purposes. By using the information and code provided, users acknowledge that they are using the APIs and models at their own risk and agree to comply with any applicable laws and regulations.Table of ContentsSection Description Link StatusTo do list List of tasks to be done -Current Sites Current websites or platforms that can be used as APIs -Best Sites for gpt4 Recommended websites or platforms for gpt4 -Streamlit GPT4Free GUI Web-based graphical user interface for interacting with gpt4free -Docker Instructions on how to run gpt4free in a Docker container -ChatGPT clone A ChatGPT clone with new features and scalability -How to install Instructions on how to install gpt4free -Legal Notice Legal notice or disclaimer -Copyright Copyright information -Star History Star History -Usage Examplestheb Example usage for theb (gpt-3.5)forefront Example usage for forefront (gpt-4)quora (poe) Example usage for quorayou Example usage for youTry it OutGoogle Colab Jupyter Notebook Example usage for gpt4free -replit Example (feel free to fork this repl) Example usage for gpt4free -TodoAdd a GUI for the repoMake a general package named gpt4free, instead of different foldersLive api status to know which are down and which can be usedIntegrate more API's in ./unfinished as well as other ones in the listsMake an API to use as proxy for other projectsMake a pypi packageCurrent SitesWebsite s Model(s)forefront.ai GPT-4/3.5poe.com GPT-4/3.5writesonic.com GPT-3.5 / Internett3nsor.com GPT-3.5you.com GPT-3.5 / Internet / good searchsqlchat.ai GPT-3.5bard.google.com custom / searchbing.com/chat GPT-4/3.5chat.forefront.ai/ GPT-4/3.5Best sitesgpt-4/forefrontgpt-3.5/youInstallDownload or clone this GitHub repoinstall requirements with:pip3 install -r requirements.txtTo start gpt4free GUIMove streamlit_app.py from ./gui to the base folderthen run:streamlit run streamlit_app.py or python3 -m streamlit run streamlit_app.pyDockerBuilddocker build -t gpt4free:latest -f Docker/Dockerfile .Rundocker run -p 8501:8501 gpt4free:latestChatGPT clonecurrently implementing new features and trying to scale it, please be patient it may be unstablehttps://chat.chatbot.sex/chat This site was developed by me and includes gpt-4/3.5, internet access and gpt-jailbreak's like DANrun locally here: https://github.com/xtekky/chatgpt-cloneCopyright:This program is licensed under the GNU GPL v3Most code, with the exception of quora/api.py (by ading2210), has been written by me, xtekky.Copyright Notice:xtekky/gpt4free: multiple reverse engineered language-model api's to decentralise the ai industry. Copyright (C) 2023 xtekkyThis program is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program. If not, see <https://www.gnu.org/licenses/>.Star History",
        "summary": "- OpenAI's legal team has issued a takedown notice to the Gpt4free repository on GitHub.\n- The repository contains APIs from third-party language model sites, and the project is intended for educational purposes only.\n- The author of the repository is not responsible for any consequences arising from the use or misuse of the repository or the content provided by the third-party APIs.",
        "hn_title": "Gpt4free repo given takedown notice by OpenAI",
        "original_title": "Gpt4free repo given takedown notice by OpenAI",
        "score": 259,
        "hn_content": "OpenAI has issued a takedown notice to the Gpt4free repository on GitHub for allegedly bypassing the official OpenAI APIs and hijacking third-party services that use GPT-4, leaving the third parties to foot the bill. It is unclear if the DMCA takedown is an applicable legal process since it is for copyright. Some commenters speculate that the repo may have violated the Computer Fraud and Abuse Act or may be guilty of fraud since it hijacked others' API keys. The controversy around GPT-4 training data ownership and intellectual property continues to be a concern, with some believing that IP is inherently stolen while others call for alternate compensation systems. The use of AI scraping and incorporation creates a dilemma where artists may start to paywall their content due to the chilling effects.OpenAI issues DMCA takedown notice to GitHub, targeting a project that allows users access to private APIs to use their ChatGPT. GitHub complied with the takedown notice, causing debate on the legality of publishing reverse-engineered third-party APIs. Some users advocate for IP rights enforcement, while others argue that it stifles innovation. Arguments arise about the ethics of using AI-generated content to train AI models without permission from the content creators. Some express concern over the power dynamic between OpenAI and its paying customers, fearing that the AI giant may act in its best interest at the expense of its users.Microsoft's takeover of Github and OpenAI raised concerns after a GitHub repo was taken down by Microsoft. The repo contained code examples that showed one of the ways in which people using various APIs could predictably get their keys hijacked. The code was taken down due to copyright violations, according to GitHub. However, some users criticized Microsoft for using their influence to crush projects they dislike. The discussion also covered the legality of API usage and the enforcement of terms of services. There were arguments on whether using private APIs without authorization could be categorized as intellectual theft and whether companies could declare publicly available endpoints private. Finally, users debated the difference between \"repackaging\" code and ownership.OpenAI issues a takedown request for GPT4Free, a repository that allows for free use of OpenAI's GPT-3 language model API through reverse-engineering of private APIs. The repository owner posted a poem in response. There are debates about the legitimacy of OpenAI's request and the legality of reverse-engineering. Some commenters speculate on the influence of Microsoft and GitHub, which respectively own OpenAI and host the repository, in the dispute. The repository and its discord server currently remain accessible.OpenAI has sent a DMCA takedown notice to GitHub in response to a repo named \"gpt4free\". The repo creator worked around the OpenAI API access restriction to provide free access to GPT-4 through an alternative method. However, the project seemed more of an affinity scam, misleading users by its name and code access. Although OpenAI doesn't support the project, it was also pointed out that the project doesn't violate the DMCA. A user has created a mirror, while others suggested a donation for the original creator. The situation, including the Ethics used, was also debated on HN.",
        "hn_summary": "- The controversy around GPT-4 training data ownership and intellectual property continues to be a concern, with discussions surrounding IP rights enforcement, the ethics of using AI-generated content to train AI models without permission from the content creators, and the power dynamic between OpenAI and its paying customers.\n- Some commenters speculate on Microsoft and GitHub's influence in the dispute, while others suggest alternatives to the now-deleted Gpt4free repository, like a user-created mirror or a donation for the original creator."
    }
]