[
  {
    "id": 37272652,
    "title": "E-ink is so Retropunk",
    "originLink": "https://rmkit.dev/eink-is-so-retropunk/",
    "originBody": "rmkit a site about remarkable app dev ↵ back to index blog about roadmap downloads apps/ harmony remux minesweeper nao app store puzzles rpn calc wordlet dumbskull utils/ genie gestures lamp injector iago shapes libs/ rmkit.h simple script in the wild/ rebook rmgem regenesis follow on github subscribe via RSS E-ink is so Retropunk August 2023 I’ve long been struggling to describe why e-ink is so much fun for me, but I think I’ve finally realized what it is: e-ink is just so so so retropunk. An e-ink device is a hacker’s dream - or at least, this hacker’s dream. They are a return to the magical feeling of computers of the 80s and 90s. It’s a world where Microsoft Windows and Apple Mac OS X never existed and we don’t have to suffer with abstractions on top of abstractions. It’s DOS for the 2020s. It’s graphing calculators for grown-ups. Features The e-ink devices I favor are low powered ARM devices running linux without a display server or gigabytes of RAM. Let’s break down why that’s so awesome: e-ink: The display is visible in the light of day :-D Low Powered: They can last for weeks on a single charge ARM is a simple architecture with a low instruction count and even lower cost Linux: as much as I like it, Android is a complicated mess Apps are simple: they talk to the kernel to read input and draw directly to the framebuffer Low RAM and slow CPUs: There’s no room to build complicated stacks of software, which means no window managers, no browsers and definitely no electron apps As similar as they are to the computers of the early 90s, they are different in some tangible ways: The resolution is much higher than an old computer - The PPI is between 200 - 300 All devices supports touch events, some even support a pen stylus They are super portable, weighing between 200 - 400 grams, with displays ranging from 6” to 10” The Software Since the devices are niche, the software ecosystem is way more homebrew (as in the Homebrew Computing Club): people write and share their apps and the community is tight knit. The people who use eink devices are enthusiasts: they’ve given up the joys of color displays to work on these under-powered devices that are devoid of app stores, tracking pixels, pay to play features and constant distractions. There’s no email on these devices, there’s no chat or social networks, there’s only simple applications. Don’t be fooled though: the device constraints lead to interesting and quirky software. In the reMarkable eco-system, there’s dozens of applications, including: multi-tasking application launchers like oxide and remux terminal emulators an interactive fiction interpreter an experimental editor & shell that you can write into a procedural drawing app with layers alternative ebook readers like koreader and plato a simple app script for building applications that follows the unix philosphy a chess board even a port of doom and so much more - like much, much, more For the Kobo, that’s also some interesting things going on - with NiLuJE, pgaskin and others hacking away: InkBox - an alternative OS with many built in applications KoReader - koreader is supported on almost all eink platforms, no surprise it works on Kobo NickelMenu - an augment to the Kobo’s UI system that adds many features Since eink is currently niche, it also means green fields: there are lots of opportunities to write applications that fills out the ecosystem. In short, a hacker’s playground. How to get started Convinced that you should hack on eink devices? Grab a reMarkable or Kobo and get hacking ;) Join the reMarkable discord server or browse the Mobile Read Kobo Forums. For reMarkable, the toltec repository is a good place to get started - one of the maintainers, Eeems, has written a great tutorial. For the Kobo, the main piece of software to get started hacking is KoboStuff from NiLuJE which includes a tarball for getting SSH up and running instead of having to use telnet. If you want more specific advice, feel free to directly get in touch Caveats These devices are not all rosy fun times, though: the rM2 uses a proprietary display driver (SWTCON) that’s hosted within their UI (Xochitl). In order for applications to work on the rM2, a shim was built that lets us repurpose the driver within Xochitl. Unfortunately, the shim needs to be updated for every release to give it the correct binary addresses to hook. There’s an alternative display driver that is in development. the rM1 is preferable to the rM2 for that reason, but the rM1 battery life is not as good! It seems they didn’t connect the peripherals (wacom display) to regulators, so the device only gets a few days of idle battery life. the Kobo does not have strong package management: to install software, typically a KoboRoot.tgz is provided and that gets unpacked after the next reboot. To uninstall software: you better hope the dev supplied instructions or an uninstall script ;) Why write a post now? Several years ago, I started hacking on e-ink devices and had an enormous amount of fun writing applications and seeing what others have built. Unfortunately, I’ve had several false starts with writing about e-ink: whether it was about what I’ve actually done, or the lessons learned along the way or even a set of things to consider when developing e-ink apps, the posts would lay half finished because they just never felt compelling - my enthusiasm for e-ink just wasn’t coming through. Instead of trying to push any of those posts to completion, I’ve decided to try to articulate what is so cool about e-ink to me. Appendix: Hacker unfriendly devices Kindles The Kindle requires a jailbreak to use and is running a modified version of Android OS (Kindle Fire). Newer FW versions may be JB resistant. The Kindle Scribe is still secured, though. For this reason, I don’t particularly recommend the Kindle devices. Onyx In every eink thread that comes up, the Onyx is brought up as not following the GPL: they use a modified linux kernel and haven’t published the source for it. Pine The Pine Note is cool and open, but its software is still in development. Use only if you are willing to take on an early product aimed at early adopters and developers - In other words, maybe the Pine Note is too hacker friendly. Appendix: Respones to HN Comments Can you brick your RM2 by playing with this? I’m interested, but the device was a bit pricey for potentially destructive fooling around. sort of - you can soft brick it and cause the screen to not display something, but you will still have SSH and can undo that. If you lose SSH, you can always recover but it’s more work. I understand this is scary, but I’ve never bricked myself because I have my SSH keys installed. when you’re spending multiple hundreds of dollars for a new part, I don’t consider that the hacker realm. you can find rM1 for under $200 on ebay, a kobo clara is under $100, but regardless: hacking is orthogonal to price. i understand the concern, though Retro? Sure. Punk? Not when the patents are tightly held by a greedy patent troll who seems to do everything in their power to stop hobbyists and hackers a lot of comments are talking about what retro and punk mean and whether they are applicable. i like the back and forth going on. the thought i had in mind when i called it retropunk is: what if there was an alternative path that was taken for computing from the 80s to today? « News update: October 2022 News update: August 2023 »",
    "commentLink": "https://news.ycombinator.com/item?id=37272652",
    "commentBody": "E-ink is so RetropunkHacker NewspastloginE-ink is so Retropunk (rmkit.dev) 641 points by raisjn 20 hours ago| hidepastfavorite312 comments beefield 0 minutes agoI have a kobo libra. What would be the easiest way to get terminal app (with ssh client as a minimum) running on that? I&#x27;m thinking it would be a nice really thin client with low energy consumption. reply raisjn 18 hours agoprevOP here. thanks for all the comments. some more info:rmkit is a library (and group of devs) for creating apps on the rM (and now Kobo). outside of rmkit, people typically use Qt to write apps, but there&#x27;s many routes[0], including SAS[1]: a solution that uses unix pipes. the rM2 requires a bit more hacking to get working than the rM1 because their framebuffer driver[2] is embedded in their software for rM2 and requires updating rm2fb every time remarkable releases a new update. there&#x27;s alternative drivers[3] to drive the display in development.i will keep updating the article based on feedback, thank you and keep hacking[0]: https:&#x2F;&#x2F;remarkable.guide&#x2F;devel&#x2F;index.html[1]: https:&#x2F;&#x2F;rmkit.dev&#x2F;apps&#x2F;sas[2]: https:&#x2F;&#x2F;github.com&#x2F;ddvk&#x2F;remarkable2-framebuffer&#x2F;[3]: https:&#x2F;&#x2F;github.com&#x2F;matteodelabre&#x2F;waved reply konschubert 12 hours agoparentTo (maybe?) add to your list: The e-paper smart display that I am making and selling does also allow users to build their own content. There are two different ways:1. You can either just serve an image on a URL and the device will display it, refreshing whenever the image changes:https:&#x2F;&#x2F;www.invisible-computers.com&#x2F;invisible-calendar&#x2F;image...2. Or you go one step further and wrap it into an API with a settings page, which will also allow others to install and use your app:https:&#x2F;&#x2F;github.com&#x2F;Invisible-Computers&#x2F;image-gallery&#x2F;blob&#x2F;ma...To be fully transparent: I know that many people are using the first approach to display their own designs, but I haven&#x27;t had much uptake yet on the second option to build a public, installable app. So if anyone is interested in trying this out, please contact me! I am willing to cooperate closely and iterate on the API where necessary.(I hope that this is sufficiently relevant, even though I am tooting my own horn here.) reply bongobingo1 5 hours agorootparentI know this is probably extremely eye rolling to read, but I looked at the store page, was quite interested, saw the \"mobile app\" and immediately had second thoughts because it just puts the device in e-waste when:- You stop updating the app and my phone OS wont run it,- My phone stops updating its OS and cant run the app, or- The walled garden gates lock shut on you for whatever reason and I cant install the app, or- You stop supporting my version of the display.Is there any way to interact with the display without the companion app? Pushing raw bytes over the network is fine, just anything that doesn&#x27;t require some phone.In another eye rolling move, I also dont really consider a response of \"we promise to opensource the companion app, or unlock the device if we go out of business\" viable (what if you die unexpectedly?, or simply, dont care to follow through?). reply konschubert 2 hours agorootparentHi, founder of Invisible Computers here.I think your questions are valid and not eye-rolling at all.As for the app, you can find the Android APK here, so as long as you have or find an old Android device, you can sideload it anytime: https:&#x2F;&#x2F;drive.google.com&#x2F;file&#x2F;d&#x2F;1nnAHVm21FLKIAJ4kTmz6Q0D9Zk4...But there is another dependency that you haven&#x27;t mentioned: The device requires a running backend with an API.At the moment, my only answer to that is: \"I&#x27;ll keep it running even if it becomes uneconomical and I will then also open-source everything.\".But I am also intending to add a way to completely avoid the backend, which will require users to render the data in a specific format to the device.Supporting this is totally worth the effort for me. If only to put my own mind at ease a bit! But, and there I have to be honest, I have limited resources to work on things. There are other features that I feel are very pressing as well. And so I cannot promise when I will find the time to implement this. reply Qwertious 3 hours agorootparentprev>I also dont really consider a response of \"we promise to opensource the companion app, or unlock the device if we go out of business\" viable (what if you die unexpectedly?, or simply, dont care to follow through?).If the promise is real, they should make it legally binding. If you go bankrupt, you lose control over your IP and quite possibly can&#x27;t choose to follow through.Although, even then, open-sourcing the app can be expensive (you need lawyers to confirm you actually have the rights to open-source all parts of the relevant code, and if there&#x27;s something you can&#x27;t open-source then you need devs to write a shim, identify the relevant keys that need to be published, and hopefully write some documentation. reply crobertsbmw 9 hours agorootparentprevI have one of your displays. It’s really nice. I intend to do something with option one, but I just haven’t found the time. Right now, as your targeting computer minded folks, I think your customers can figure out how to set up an image url that changes periodically, but as you scale you might want to create more accessible options. Or maybe let third parties build apps to do it for you.. reply konschubert 2 hours agorootparentI am hoping to add third party apps, that&#x27;s why I have created the API for 3rd party apps:https:&#x2F;&#x2F;github.com&#x2F;Invisible-Computers&#x2F;image-gallery&#x2F;blob&#x2F;ma...But right now, I understand that building an app for my platform isa) more hassle than just pointing to a URLb) limited upside, because the audience that you can charge for a subscription isn&#x27;t very big yet.However, I think that a good app could generate its own audience (aka drive ppl to buy the displays) and then make money by charging them a small monthly subscription fee. reply yoavm 12 hours agoparentprevI don&#x27;t know about the rM, but for Kobo - why not just run Linux? it literally runs Debian (and others). I&#x27;ve written so apps for it (e.g. https:&#x2F;&#x2F;github.com&#x2F;bjesus&#x2F;pidif) using GTK. It would have been great if we had a more unified eco-system for e-ink supported apps. reply Eeems 11 hours agorootparentUsually the reason is that people want to continue using the built-in interface with just some additions, instead of replacing and maintaining a separate installation.It would be nice if someone were to start working on an aftermarket linux distribution&#x2F;ecossytem that targets eink devices. It&#x27;s a lot of work to do, though, so I&#x27;m not surprised that nobody has picked up that torch yet.Some notes on the reMarkable, it is running a custom linux distribution that is based on Openembedded Core[0]. The company publishes their modifications to the linux kernel[1], so one person has created their own linux distribution for the original reMarkable tablet [2]. The reMarkable 2 currently has no native framebuffer driver for the screen, due to it being software controlled by the UI application, which requires a workaround for custom applications[3].0. https:&#x2F;&#x2F;www.yoctoproject.org&#x2F;software-item&#x2F;openembedded-core... 1. https:&#x2F;&#x2F;github.com&#x2F;reMarkable&#x2F;linux 2. http:&#x2F;&#x2F;www.davisr.me&#x2F;projects&#x2F;parabola-rm&#x2F; 3. https:&#x2F;&#x2F;github.com&#x2F;ddvk&#x2F;remarkable2-framebuffer reply yoavm 3 hours agorootparent> It would be nice if someone were to start working on an aftermarket linux distribution&#x2F;ecossytem that targets eink devices. It&#x27;s a lot of work to do, though, so I&#x27;m not surprised that nobody has picked up that torch yet.That is what I&#x27;m trying to do with https:&#x2F;&#x2F;github.com&#x2F;bjesus&#x2F;air . Kobo runs mainline Linux quite fine, and specifically PostmarketOS works great. Assembling an interface that plays nicely with the device hasn&#x27;t actually been that difficult! reply jmspring 13 hours agoparentprevOn a scale of a PC to having to jail break an iPhone to do custom stuff - how invasive is what you are mentioning for the RM2? I have one, love it for notes&#x2F;etc. But haven&#x27;t tried 3rd party software&#x2F;etc on it. reply lallysingh 13 hours agorootparentThe settings page had the root password and you ssh in over (IIRC) usb reply Eeems 11 hours agorootparentprevhttps:&#x2F;&#x2F;remarkable.guide&#x2F; has a bunch of current information on the state of hacking your device. You have root access out of the box, which means how invasive it is depends on how you go about it. The community is trying their best to stick to a set of standards that keeps things from being too brittle, and \"just works\". reply gcanyon 6 hours agoparentprevMaybe a crazy question, maybe not, but you never know if you don&#x27;t ask: any eInk tablets capable of handling Notion? It seems like Slack, maybe? reply AlexCoventry 13 hours agoparentprevCan you brick your RM2 by playing with this? I&#x27;m interested, but the device was a bit pricey for potentially destructive fooling around. reply raisjn 12 hours agorootparentsee Eeems&#x27; comment about soft bricking: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37274460as long as you have SSH keys and you don&#x27;t blow away your home partition, you are mostly fine. you do need a slightly older version of Xochitl, though (3.2 and below) reply AlexCoventry 9 hours agorootparentThanks! reply idontwantthis 2 hours agoparentprevI got the (wrong?) impression that the rM2 was super locked down because you needed to buy a subscription to use any kind of cloud backup.Does that just require some hacking, or do they still some how lock that down even if you are a power user? reply gadrev 11 hours agoprevI love e-ink devices.Just back from a reading session in my Kobo, and I sent this article to it of course :) (through Firefox&#x2F;Pocket). I can even read in the swimming pool (it&#x27;s water resistant), nothing better than reading in sunglasses halfway in on a sunny day, awesome!!! And it doesn&#x27;t weigh as much as some books. While I still prefer paper for certain reads, it has definitely helped get back into the habit of reading real books&#x2F;reading more, so lost to smartphones and social media &#x2F; \"sugar\" information type content these days. So convenient in terms of size&#x2F;weight&#x2F;number of books you can carry, while being easy on the eyes. No distracting crap, either, as TFA mentions.Long live e-ink, whatever device you like most!! reply srndpty 10 hours agoparent“Long live e-ink”i’m always worried it’s just around the corner from outliving its usefulness&#x2F;profitability to most people. even within my tech&#x2F;gadget bubble it still feels like a relatively niche thing. this keeps me upgrading my Kindle pretty much anytime a new one comes out because i’m always worried the technology will be discarded. i really love the fact that i can fall asleep reading on it pretty naturally. this DOES NOT happen when i’m in bed on my phone or tablet. i’m glad to see devices like reMarkable and Scribe pushing it further, and i just hope research continues to get the tech to a point where it can refresh quickly without artifacting at near lcd quality. and yeah, it’s nice to have a device where i physically can’t distract myself with inane social media or other silly things. i’m generally of the Alton Brown thought that anything uni-task is unnecessary, but i’ll continue to make a happy exception here. reply devilbunny 8 hours agorootparentMy wife and I have Kindles for one purpose: reading outside. We use iPads inside (I’m posting from mine), but there is nothing like eInk for reading in the sun, because it looks like a book.In a world of uni-task devices, that is one worth owning. reply derbOac 9 hours agorootparentprevI&#x27;m someone who had them during the boom around 2010 or so, then found myself giving them away because they didn&#x27;t seem useful, and now find myself wanting them again. Mostly I&#x27;ve noticed how I like to read in bed at night rather than on my phone, am not happy with the illumination options with real books in that situation, and not happy with the screens on my phone either.I&#x27;d probably buy one immediately if I could be guaranteed I could put any pdf on it and have it display flawlessly, and if it were relatively open in terms of compatibility. reply berkes 3 hours agorootparentWRT PDF, if you want it rendered flawless, you want it rendered verbatim. No reflowing or columns removed.That means an e-ink device the size of the pages. So probably A4. A device of 21x30cm. (8.2x11.7inches). That is huge. Equivalent of the largest iPad. reply abawany 3 hours agorootparentI&#x27;m getting a lot of use out of my ancient Sony DPT-S1 for this purpose. It has a huge screen but is very light and well-balanced so holding it for long periods is not a problem for me, compared to holding a similarly-sized lcd tablet. I&#x27;ve converted most of my epub ebooks to pdf (thank you Calibre) just so I can enjoy reading them on this device. reply adriand 6 hours agoparentprevI love my Kobo as well. It’s pretty old now but durable and still works fine. Here in Canada it works with my local public library using Overdrive. I also use the Libby app on my iPhone. Libby is great for discovering stuff, it’s fast and beautiful.So I find books with Libby, check them out, then hit sync on the Kobo and they all show up. It’s brilliant. I used to torrent books and now I never do, I just borrow from the library constantly, and I love how having to make choices (because not everything is always available) widens the scope of what I’ll try reading. reply noobermin 24 minutes agoprevARM being a simple instruction set hardly makes it match say 286 or 386 asm as it was used in the era primarily for the fact it is not intended to be coded by hand but be compiled. reply fidotron 18 hours agoprevThe killer problem with e-ink is the pricing betrays that the yield absolutely tanks as the area increases, which is true of semiconductors and other display technologies, but in the case of e-ink seems to be that much worse.Part of the success of things like GPUs is their ability to degrade gracefully in the presence of one or two errors which would otherwise render the whole thing unusable. reply dredmorbius 12 hours agoparentIf this is the case, then it would seem to me that the ability to produce modular e-ink displays, where segments are individual, independent displays, would be an option.This is most tenable for large-scale displays (e.g., wall displays), and we&#x27;re already used to segmented \"television walls\" in which borders between individual displays is strongly evident. The trick would be for such compound devices to both match one another&#x27;s display characteristics (brightness &#x2F; shading &#x2F; hue), and for borders to be made as undetectable as possible (several possible mechanisms suggest themselves to me as I write this).Given the sweet spot of 8--10\" displays, compound devices made of multiples of these would seem to be at least a conceptual possibility. 16x8 displays would give 32\" diagonal measure, 300 dpi, and assuming 50% BOM cost might run less than the 25\" Onxy BOOX Mira Pro ($1,750). reply pclmulqdq 14 hours agoparentprevLCDs are incredibly simple to manufacture compared to e-ink displays. Also, the best cleanroom technology in the world goes to LCD manufacturing facilities thanks to the incredible economies of scale available. reply coder543 14 hours agorootparent> Also, the best cleanroom technology in the world goes to LCD manufacturing facilitiesBetter than cutting edge semiconductor fabs? Why would LCDs need such cleanroom facilities? reply pclmulqdq 13 hours agorootparentOne dust particle per 12\" square loses you 1 of 100 CPUs. It loses you 100% of your 50\" TVs.Also, CPU manufacturing facilities keep the insides of the machines cleaner than the facility, containing the wafers in transit between machines, and LCD manufacturers do not have the same luxury. reply justinclift 4 hours agorootparentThat lost CPU would still have potentially been worth several times as much as the 50\" TV though. Intel server CPUs especially. Entry level laptop CPUs not so much. ;) reply asddubs 1 hour agorootparentyou can&#x27;t just go by retail price though, it becomes a question of whether it&#x27;s cheaper to implement a better clean room or to just slightly scale up production to account for breakage replyimiric 18 hours agoprevI&#x27;d really like to have a large e-ink display on my wall showing various dashboards, but I can&#x27;t justify the exorbitant cost. It would be really elegant to have a low powered programmable setup with an Arduino and a battery, but I&#x27;m tempted to just buy a large LCD display and connect it to mains instead.It&#x27;s a shame that this technology is kept artifically out of reach to hobbyists.I&#x27;ve seen the Waveshare displays, but they&#x27;re too small and limited in features (monochrome or few colors, very high refresh rate, etc.). reply konschubert 17 hours agoparentIt’s true. Large eink displays get expensive really fast.I went with a 7.5 inch display for the eink calendar &#x2F; smart display that I am selling.I am definitely feeling the limitations, but there is still a lot you can do at that size.Have a look: https:&#x2F;&#x2F;shop.invisible-computers.com&#x2F;products&#x2F;invisible-cale...And maybe once the business grows, I’ll have the volumes needed to get better prices on the bigger displays. reply mmh0000 16 hours agorootparentI’ve looked at your product multiple times and every time I think I wanna buy one. Then I go to the webpage and I see that it only works with Google which is not what I use so then I get sad and leave.I’d buy one in a heartbeat if there was support for iCalendar or other common&#x2F;open standards. reply konschubert 16 hours agorootparentI have started working on more calendar integrations now.If you write me a short mail at info@invisible-computers.com and tell me what integration you need, I will make sure to let you know once it is out.In the meantime, there are often ways to sync other calendars (also iCalendar) with google calendar. It’s a bit of a detour but it might just work. reply ekianjo 7 hours agorootparentCalDAV is where the money is reply konschubert 2 hours agorootparentYou think so? More important than outlook? reply aranke 42 minutes agorootparentprevIs it possible to make a black or silver frame (ideally with thinner bezels)? If so, I&#x27;d gladly buy one (wood does not fit in my current theme). reply theK 16 hours agorootparentprevHow much of an effort is it to get this working with webcals? I love the idea but don&#x27;t use google at all... reply konschubert 16 hours agorootparentHi, I’m about to find out, since I am working on adding support for it :DIf you want I can let you know once it’s done if you send me a short email to info@invisible-computers.com reply anoncow 16 hours agorootparentprevLooks good. I made one using a waveshare screen and a raspberry pi zero. It cost almost the same as your retail price, but it didnt look this good. reply konschubert 16 hours agorootparentCool! What are you displaying on it? I am always adding for new use cases to add as apps to my device. reply anoncow 10 hours agorootparentI was displaying a list of tasks from a Todo App via API, clock and calendar, and times in different cities where my company had offices.Showing a clock ended up being bad for the display as it quickly degenerated. You calendar view is great. reply konschubert 2 hours agorootparentWhich todo app? Todoist? reply iglio 11 hours agorootparentprevHave you considered using multiple of the current displays together in a single product, presenting them as a single view to the user? Does that help with the pricing? reply konschubert 2 hours agorootparentI think that&#x27;s something the display OEM would need to do. Once I get the displays, they already have bezels. That won&#x27;t look good as a 2x2 grid. reply bennetthi 16 hours agorootparentprevDo you sell anything bigger? I only saw the 7.5, I’d be way more interested in something like 24. reply konschubert 16 hours agorootparentI just don’t have the volume right now to get good prices from manufacturers on any bigger displays.I’m looking into 10 inch displays right now, but they are already significantly more expensive.At some point it just drives the price of the end product up too much. reply dredmorbius 12 hours agorootparentThe largest devices I&#x27;m aware of are E-ink displays. Onyx produces the Onyx BOOX Mira Pro, 25.3\" diagonal, based on the E Ink Carta, 25,3\", resolution of 3200x1800 dots, 145 ppi, 16 shades of grey.Note that the pixel density is markedly lower than other e-ink devices. For smaller devices, e.g., the Poke 5, DPI is more than double at 300 dpi (comparable to a laser printer): 6\", E Ink Carta Plus, 16 shades of grey, 1072 × 1448 dots, pixel density - 300 ppiGranted: with increased viewing distance, resolution can fall somewhat, but given that areal density falls as the, well, square, this is 4x lower resolution.The Mira Pro runs an eye-watering $1,750, further impeding the viewing experience. Given price trends on other E-Ink devices, I&#x27;m pretty sure that&#x27;s all but entirely driven by the display cost itself. reply toastal 6 hours agorootparentUnfortunately AFAICT, Onyx BOOX still isn’t publishing their Linux kernel modification or sending source on request which is a violation of GNU GPL 2. reply dredmorbius 5 hours agorootparentYes, I&#x27;m aware of that, and it&#x27;s a strike against the company. replyQuinnyPig 14 hours agorootparentprevOoh. Purchased. Let’s see how this goes… reply starman12980 15 hours agorootparentprevwhat screen did you use for the e-ink part of the display&#x2F;who manufactures it? reply konschubert 15 hours agorootparentIt’s a model similar to the 7.5 inch screen by waveshare reply Max-q 16 hours agoparentprevThe screens are expensive for everybody. For devices with e-ink display, the screen is often more than the rest of the BOM combined. That&#x27;s why there are only premium device on the market, except Kindle, which is subsidized by Amazon.When they first appeared, I was sure the price would drop with increasing volumes, but that has not happened. Probably they can&#x27;t get good enough yield, and it&#x27;s not a product suitable to sell with dead pixels, like a TV, where cheap models have dead pixels while the premium models don&#x27;t. reply chrisfosterelli 16 hours agorootparentIt possibly hasn&#x27;t happened because, at least from what I&#x27;ve heard previously here on HN, the e-ink company has a monopoly on the patents needed to make them: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26143779It sounds like they might have just recently expired but I imagine there is a catchup phase. reply Qwertious 15 hours agorootparentIn the link you posted, please scroll down to the reply by Robinsoh - the \"patent thicket\" claim is bullshit, and people keep repeating the myth without a real source to back it up.E-ink is expensive because it&#x27;s a niche product that lacks economy of scale, and it&#x27;s a niche product because it does almost nothing that can&#x27;t be done by LCDs (which are incredibly flexible). E-ink is amazing, but it doesn&#x27;t have the best business case. reply chrisfosterelli 13 hours agorootparentTo be honest, that commenter probably knows more than I do about the tech. But on the business side, I think that would be a stronger position if there wasn&#x27;t just one single company that owns the entire market. OLEDs were originally very expensive, niche, and had yield problems but competition has driven development -- bringing prices down, improving yields, and solving many the issues that made them a niche application.The commenter said that a billion dollars are needed to make the technology scale but The EInk Corporation itself raised only 1&#x2F;10th of that and now they&#x27;re making a billion dollars per year off it -- why haven&#x27;t they brought prices down then?If you look at their annual reports, EInk sure seems to think their patents are important; they mention patents as part of their \"strategic roadmap\" every year. Their initial patents were in the late 90s, and the last few years the royalty revenue amounts on E Ink&#x27;s revenue breakdowns have been dropping every single year as they shift more and more into actually making the screens. The data lines up IMO. reply hakfoo 14 hours agorootparentprevThe big commercial selling point of E-ink is that it should be able to survive zero power.I assume that&#x27;s why its first killer app has been pricetags. A store with 5000 items each requiring a LCD pricetag would be constantly replacing little batteries or having to reprogram units if they popped out of a plug or rail-basewd power system.I think some of the interest from the hobbyist brows is less about that and more about other aspects of the technology-- it has a bit of a distinct look and excellent full-sun readability.A hypothetical nonbacklit high res grayscale LCD would have some similar properties and might be more viable at small scale; I know they&#x27;re making basically that in small sizes for use in resin 3D printers. reply Qwertious 3 hours agorootparentYes, e-ink pricetags are one niche of e-ink devices. The other niche is e-readers (which are a luxury version of installing an e-reading app on your phone). Maybe the niche of solar-powered billboards (e.g. bus-stop signs) will also take off, but that&#x27;s about it.E-ink is great, but it is niche and basically everything that you can do with an EPD, you can do with an LCD. E-ink screens are in the at best tens of millions, whereas LCDs are in the billions per quarter - there are over 6 billion smartphone owners in the world already, and LCDs are in everything from supermarket self-checkout kiosks to laptops to smart fridges, they utterly demolish E-Ink in scale.I love e-ink screens, but there&#x27;s no denying the tech&#x27;s business-case is rather marginal and that won&#x27;t change anytime soon. reply FirmwareBurner 13 hours agorootparentprev>A store with 5000 items each requiring a LCD pricetag would be constantly replacing little batteriesErrr, not really. LCD price tags existed before e-ink (and still do) and battery life was not much worse. It&#x27;s something like 1.5x-2x tops, so enough to make business sense, but not orders of magnitudes earth shattering as one might assume. reply AshamedCaptain 12 hours agorootparentIn fact, most retail shops that have anything other than paper use LCD price tags. If they are making the switch is because they expect to be frequently updating them... and then any eInk battery life advantage evaporates. reply FirmwareBurner 12 hours agorootparent> If they are making the switch is because they expect to be frequently updating them...Not necessarily that. They&#x27;re making the switch to digital price tags because it&#x27;s much quicker and easier to run promos on certain items to clear the shelves before closing time on perishable goods, but most importantly, they&#x27;re making the switch because when employee have to manually change paper price tags, mistakes happen far too often, and stores end up in situations where the price on the self doesn&#x27;t match the price on the cash register, angering customers who in certain jurisdictions are entitled to compensation for the store&#x27;s pricing mistake.Digital price tags ensure such mistakes are gone saving the store money over time. replyarp242 16 hours agorootparentprevI&#x27;m not sure I agree with that; I paid €120 for my PocketBook e-reader, which wasn&#x27;t the cheapest one, and I bought it in-store (could have gotten a better price online probably, but comparing devices in-store was useful).Now, while €120 isn&#x27;t nothing, it&#x27;s also not a whole lot, and it&#x27;s cheap enough that with a few books a year you&#x27;re saving money.Amazon&#x27;s 6\" Kindle sells for €110 by the way, but is missing some features my Pocketbook has, and the 6.8\" Kindle Paperwhite with comparable features sells for €170. Doesn&#x27;t seem that much cheaper to me. reply MayeulC 17 hours agoparentprevAre you sure it&#x27;s artificial and not related to yields? As in, it&#x27;s more likely you get a dead pixel on a larger screen.The answer would be \"chiplets\" of course, assembling bigger screens out of smaller ones. At the hobby leven, I think something decent could be built out of a few second hand kindle screens, if you plan the seams as part of the aesthetic. reply hwillis 16 hours agorootparent> As in, it&#x27;s more likely you get a dead pixel on a larger screen.Aside from the ink capsules and higher voltage (though still very low), E ink is almost identical to LCD and probably slightly easier to make. There&#x27;s a TFT (which can have a larger footprint, since it doesn&#x27;t need to be transparent) on the back, an LC or E ink capsule layer, and an ITO electrode. Dead pixels are almost always caused by damage or defects in the TFT.I wouldn&#x27;t say it&#x27;s artificially out of reach, though- setting a line up to produce large panels is a high opportunity cost. If anything is artificial about it, it&#x27;s that you presumably can&#x27;t buy E ink capsules yourself. With enough effort you might be able to separate the top glass from an LCD TV, dissolve the LC, and replace it with E ink, but I have no idea how you&#x27;d do that. No promises it wouldn&#x27;t burn out the TFT immediately. reply dredmorbius 13 hours agorootparentAcronym-expansion as a service:TFT: Thin-film transistorLC: Liquid crystalITO: Indium-tin oxideLCD: Liquid crystal display (though this one&#x27;s widely known).(Please expand acronyms on first use. Even, or especially, where they strike you as well-known or obvious.) reply DemocracyFTW2 3 hours agorootparentTINAPHHOHN [ti:nafo:n]This Is Not A Popular Habit Here On HNBut it should beYMMV reply FirmwareBurner 13 hours agorootparentprev>E ink is almost identical to LCD and probably slightly easier to makeFalse. E-ink film, especially color, is definitely more complex to get right than LCDs. Sure, e-ink displays have the same TFT layer underneath just like LCD displays, but the e-ink pigment and film is tricky to make. reply Qwertious 15 hours agoparentprev>It&#x27;s a shame that this technology is kept artifically out of reach to hobbyists.This is a myth. They&#x27;re not artificially expensive, they just have low economy of scale because they&#x27;re a niche product. As you yourself said, you&#x27;re tempted to just buy a large LCD display instead. reply echelon 18 hours agoparentprev> It&#x27;s a shame that this technology is kept artifically out of reach to hobbyists.This is still an issue where a single company controls the entire tech, right? When do the relevant patents expire? reply pclmulqdq 16 hours agorootparentThe patents on the original black and white displays have already expired. They are just really hard to make at large size without defects.Newer versions that are easier to manufacture or have color are still under patents for a while. reply Qwertious 15 hours agorootparentprevThey don&#x27;t - the Display Electronic Slurry (DES) is a competing &#x27;e-paper&#x27; tech that E-Ink corp haven&#x27;t patented. It has slightly different pros and cons (it has a more defined checkerboard pattern which isn&#x27;t as nicely grainy as E-Ink corp&#x27;s MED, but it let&#x27;s them pour the &#x27;ink&#x27; straight into the substrate which potentially has higher contrast and resolution as a result), but ultimately that&#x27;s irrelevant nitpicking if patents are causing the price of E-Ink screens to be crazily high as people keep falsely claiming. If DES could deliver screens at half the price, then Wiwood (?) would eat E-Ink&#x27;s lunch. reply 3pt14159 18 hours agorootparentprevExpiry isn&#x27;t the issue. In America (and Canada I&#x27;m pretty sure) you have the right to use a patent at a fair cost determined by a court. Or you can try to just use the patent anyway and wait for the court case to come to you. reply sjs382 18 hours agorootparentNope. A patent is an exclusive right yo an invention. They aren&#x27;t forced to license it to you or anyone else. reply giaour 17 hours agorootparentThere are a few exceptions in US law (e.g., provisions in the Defense Production Act) that can allow a patent owner to be compelled to license their IP. IANAL but I believe this generally requires an officially declared emergency of some kind. reply _delirium 17 hours agorootparentThere are additional exceptions short of a declared emergency, but rarely invoked. So in practice I agree this is unlikely to happen with e-ink displays. But for legal nerds I&#x27;ll elaborate anyway.Some exceptions are obviously inapplicable here, e.g. special rules for plant varieties [1] and nuclear energy [2]. The one most likely to apply to e-ink displays is that, under the Bayh-Dole act, if an invention was funded by government grants, and the patent holder fails to make it widely available, the government has so-called \"march-in rights\" to license it to third parties themselves. However this has never been successfully used. Wikipedia summarizes: \"Though this right is, in theory, quite powerful, it has not proven so in terms of its practical application\" [3].[1] Perhaps because it&#x27;s controversial to allow plant varieties to be patented in the first place, the statute for them has an explicit compulsory license clause (see the last subsection): https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;7&#x2F;chapter-57&#x2F;subchap...[2] https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;42&#x2F;2183[3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bayh%E2%80%93Dole_Act#Petition... reply sjs382 16 hours agorootparentprevYeah, I initially threw in some caveats but removed them for brevity and because they don&#x27;t really apply to the topic at hand (eink).I mean, someone can also compel you to license your IP using a hammer. reply generic92034 17 hours agorootparentprevThe exception would be standard essential patents, as far as I know. reply stonogo 16 hours agorootparentThe standards bodies can encourage FRAND licensing, but there is no legal requirement backing it beyond the patent holder agreeing to it. reply generic92034 15 hours agorootparentThanks for the correction, I misremembered that, it seems. On the other hand, an SEP holder not licensing the patent with FRAND terms will have a hard time to establish any kind of standard, in some scenarios. reply stonogo 13 hours agorootparentI agree with you, it would be counterproductive. The more common occurrance is that one of the patent-holding entities opts out of the FRAND agreement, holding all the implementors of the standard hostage. An example would be Forgent&#x27;s acquisition of a patent they interpreted to be essential to JPEG. The patent was eventually invalidated in the courts, but it caused a lot of headaches for a few years in the early 2000s. replyAnimats 13 hours agoparentprev> exorbitant cost.Is that fundamental to the technology, or is it just it being a low-volume niche product? reply pmarreck 16 hours agoparentprevI have had this bookmarked for a few years to do as a side project but the acquisition of a new son has put all this aside for the foreseeable future unfortunately, perhaps you can make use of it:https:&#x2F;&#x2F;alexanderklopping.medium.com&#x2F;an-updated-daily-front-...Would strongly recommend using another language than PHP to make it work, but the LLM du jour would probably translate it to any other language for you.Here was the original post that inspired that one: https:&#x2F;&#x2F;onezero.medium.com&#x2F;the-morning-paper-revisited-35b40... reply cinntaile 16 hours agorootparentOT but... Did you mean addition or can you actually say acquisition in English? reply pmarreck 16 hours agorootparentI was making a humorous reference to startup life. You don&#x27;t normally say that in English, I was playing with the language. My son is actually awesome, and yes, he is an \"addition\" (sum of one total). =)Thank you for learning English! As a speaker of (to some extent) 3 other languages, I for one appreciate anyone who has struggled to learn English as an (N+1)th language. reply onurcel 16 hours agorootparentprevsame. I have these exact urls bookmarked for years reply malfist 15 hours agoparentprevNot exactly what you&#x27;re looking for, but check out dakboard.They even have a pi version reply cimm 18 hours agoprevI got myself a https:&#x2F;&#x2F;paperd.ink: a 4.2″ screen with battery in a printed case for $90. I wrote a small calendar application for it to replace the paper calendar at home: https:&#x2F;&#x2F;suffix.be&#x2F;blog&#x2F;eink-calendar reply konschubert 16 hours agoparentFor others who see this and don’t want to build something themselves:I make and sell an eink calendar (and smart display) for $149, complete with mobile apps and google calendar sync.https:&#x2F;&#x2F;shop.invisible-computers.com&#x2F;products&#x2F;invisible-cale...The display is 7.5 inch.This is still a side project for me though I am thinking of ways to turn this into a self-sustaining business. reply joelthelion 3 hours agorootparentWhy does it need a power cable? To me the main selling point of e-ink displays is that they should be able to last weeks if not months on a single charge... reply konschubert 2 hours agorootparentI want to make a version with a battery. But I don&#x27;t know when I will get this done. My goal is to make it last at least half a year. 6 months I think is the minimum standard for a thing that is supposed to hang on the wall and not be a hassle to babysit.A battery adds a lot of complexity and cost for testing, certification and shipping. And it adds another failure mode. So I decided against it for the current version. reply OptCohTomo 17 hours agoprevE-ink is a fascinating display technology. Here is an account of a non-destructive “teardown” of an E-ink display by optical coherence tomography (OCT): https:&#x2F;&#x2F;arxiv.org&#x2F;ftp&#x2F;arxiv&#x2F;papers&#x2F;1605&#x2F;1605.05174.pdf reply gadgetoid 14 hours agoprevI’d be remiss not to mention that we (Pimoroni) sit right at the hacker end of the E-ink scale with stuff like Badger2040W [1] and Inky Frame [2], both of which pair (small and less small) E-Ink panels with the RP2040 microcontroller so you can BYO software.The biggest roadblock to these being super compelling is update rate. The black&#x2F;white screen on Badger can be driven pretty hard, but overdriving it (a friend built a continuous E-ink zoetrope [3]) has consequences.Inky Frame’s 7 colour display is awesome for dithered artwork (missing cyan and magenta notwithstanding) but very, very slow to refresh- ~30s after the panels were updated to incorporate an unskippable “clean” phase.Faster, cheaper and bigger all seem mutually exclusive right now, but I share the authors passion for the format.1. https:&#x2F;&#x2F;shop.pimoroni.com&#x2F;products&#x2F;badger-2040-w?variant=405...2. https:&#x2F;&#x2F;shop.pimoroni.com&#x2F;products&#x2F;inky-frame-7-3?variant=40...3. https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;raspberry-pi-digital-zoetr... reply krabizzwainch 19 hours agoprevI’m a little disappointed that this doesn’t go into the off the shelf screens from waveshare. That’s where the fun really is for me at least. I wrote an epub reader in Python and built an eReader with a raspberry pi. I guess it’s a little less hacking and more so developing. reply sigil 15 hours agoparentSounds cool! Did you publish code or a writeup somewhere? reply krabizzwainch 9 hours agorootparentAt one point I had a post on reddit about it, but I ended up deleting that. However my post did get scraped by hackster.io so here is the link to their post. https:&#x2F;&#x2F;www.hackster.io&#x2F;news&#x2F;diy-e-reader-incorporates-mecha... and here is my github. https:&#x2F;&#x2F;github.com&#x2F;bwkrayb&#x2F;37readerDoing a write up has been a plan of mine for a while now lol I bought a 3d printer to move on from the gutted airpods box and a case has been in a half printed state just waiting for me to design the rest of it. I&#x27;ve run into a creative wall and haven&#x27;t gotten much further. reply ShadowBanThis01 13 hours agoparentprevOr anywhere, really. This statement: \"Grab a reMarkable or Kobo and get hacking\" isn&#x27;t realistic to me. I don&#x27;t run out and buy current products that cost $300 to \"get hacking.\"Hacking on a panel scrounged from a discontinued product, or a bare one, sure. But when you&#x27;re spending multiple hundreds of dollars for a new part, I don&#x27;t consider that the hacker realm.Nothing against the author; I&#x27;ve been looking at E-ink for a long time and this page is inspiring. But in the end, the cost turns me away yet again. Also the pitiful refresh rates I&#x27;ve seen... reply II2II 10 hours agorootparentLook for a second hand device then? I don&#x27;t know what the situation is like for Remarkable, but Kobo has been around for over a decade and used ones are floating around the second hand market. (The Kobo Touch was introduced over a decade ago and is hackable.) If you&#x27;re willing to scavange just the screen, there are even more options since you don&#x27;t have to worry about the device itself being locked down. The drawback with scavenging screens is you have to figure out how to interface to the screen, which is quite the barrier to entry. reply fossuser 19 hours agoprevThere are some E-ink fans in the urbit community (disclaimer I work on this stuff) and it really lets you fully extend the retropunk feel.I’ve got my Urbit running on a native planet hardware box (https:&#x2F;&#x2F;martiancomputing.substack.com&#x2F;p&#x2F;product-review-nativ...) plugged into my router’s switch that I can access from anywhere. The UI for groups also looks good on e-ink (mostly white and black, nice design) one of the devs has an e-ink phone that shows it off. It’s cool to really own the entire stack.I had the original remarkable tablet mentioned in the post and it was really cool (someone was also using it as a browser to access urbit back then), the new tablet looks better too.There was someone at the first urbit assembly (probably here on HN) working on cool new e-ink style tech that had some advantages without having to engage with all the patent nonsense and vendor lock-in that has plagued (imo seriously stalled) e-ink as a technology. reply codethief 11 hours agoparent> I’ve got my Urbit running on a native planet hardware box (https:&#x2F;&#x2F;martiancomputing.substack.com&#x2F;p&#x2F;product-review-nativ...) plugged into my router’s switch that I can access from anywhere.This is the first time I&#x27;m hearing about Urbit and, having spent the past 5-10 minutes browsing their website(s), I still haven&#x27;t been able to figure out what it is exactly. Could you explain? And what do you use it for? reply fossuser 11 hours agorootparentIt’s a new OS design that runs in a runtime with baked in networking and PKI lookup for encrypted routes between users.I primarily use it today for chat (similar to IRC), and I locally host my own system. Every user is their own server.I wrote up a longer form description here: https:&#x2F;&#x2F;zalberico.com&#x2F;essay&#x2F;2022&#x2F;09&#x2F;28&#x2F;tlon-urbit-computing-...Hopefully that’s helpful. It’s a little outdated now though. We’re doing free hosting for now at tlon.io to help the network grow (so it’s easy to check it out).The (long) original technical intro to the ideas is here: http:&#x2F;&#x2F;moronlab.blogspot.com&#x2F;2010&#x2F;01&#x2F;urbit-functional-progra... reply ilaksh 5 hours agorootparentIf I ever join a cult, I hope it&#x27;s one like Urbit.Just kidding. Seems like a brilliant collection of ideas. reply happytiger 2 hours agoprevIn the sense that they still have 1990s prices absolutely… reply noduerme 3 hours agoprevI bought a Boox despite not trusting the OS - and never getting online with it - because I like to sketch in color. I would&#x27;ve rather bought any other platform, if there was one with sort-of-useful color e-ink. But I actually really like their interface. It&#x27;s one of the best overlay-interfaces I&#x27;ve ever seen over anything (and this is over full Android, slightly bent). It&#x27;s a pleasure to use, as long as you keep it airgapped and don&#x27;t trust it further than you could throw it. reply idontwantthis 2 hours agoparentWhy did you want e ink for sketching vs an iPad?I tried out the color boox and to me, it looked like the worst of eink and lcd. Bad colors, bad battery life, hard on the eyes, slow, and expensive. reply thelazyone 18 hours agoprevI wonder what kind of interesting applications could be done on e-ink harnessing the advantages of the long battery life and not suffering by the slow refresh rate. Sure, porting doom or implementing a terminal is an interesting and probably challenging feat, but still it&#x27;s applications that don&#x27;t shine on an e-ink device.Maybe some \"slow\" strategy game, that updates upon certain events but might remain unmodified for hours at a time? Or - more in general - an application that is required to be on for a long time but really doesnt&#x27; change often. reply wchar_t 16 hours agoparentA traditional roguelike, in the line of TGGW&#x2F;Cogmind&#x2F;Nethack&#x2F;Brogue&#x2F;DCSS, would probably be nice. Not really a \"slow strategy game\", granted, but the fact that animations&#x2F;colors aren&#x27;t necessary makes it a good fit IMO reply NeoTar 15 hours agoparentprevI think eInk price labels are now getting to be quite a common thing in some stores - while it&#x27;s probably not fair&#x2F;legal to change prices while the store is open, it means prices can be updated very easily overnight. reply southpawflo 2 hours agoprevit&#x27;s funny that this pops up a few days before I return the remarkable 2 (through their 100-day money-back guarantee, otherwise I wouldn&#x27;t have tried it).to anyone considering buying one, if you are left-hand dominant, skip it. what most people don&#x27;t understand is that being a lefty doesn&#x27;t mean that you can use a mirror image of what&#x27;s served to righties (in this case, the UI) and then everything is fine.don&#x27;t get me wrong, I&#x27;m returning it for several reasons - a few can be inferred from other people&#x27;s comments here. I&#x27;m only putting this out there for all my sinister siblings, &#x27;cause writing english is a pain for us. reply teleforce 5 hours agoprevThis article is talking about hacking existing E-ink ebook readers with custom made software&#x2F;OS but why stop there?Imagine an open ecosystem whereby we can have low power embedded systems running Linux OS or RTOS for plethora of computing&#x2F;sensing&#x2F;IoT useful applications on top low cost MPU that need rudimentary or sophisticated GUI e.g. dashboard, virtual buttons,etc [1].[1] STM32MP2: ST’s first Linux capable 64-bit MPU with NPU, GPU and TSNhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37247763 reply justinclift 4 hours agoparentHave you seen the \"Open Book\" project?https:&#x2F;&#x2F;github.com&#x2F;joeycastillo&#x2F;The-Open-Book reply teleforce 49 minutes agorootparentThis seems to be another efforts in ebook reader direction. It will be good if we can move beyond ebook paradigm, and create an open hardware and software ecosystem, with generic low power and low cost computing applications based on E-ink display. reply random3 12 hours agoprevI love e-ink and simple interfaces. I don&#x27;t believe in low-powered hardware, however.This said remarkable 2 is so underpowered it&#x27;s impractical. I love the paper-like experience, but I never use it for any important notes because I can&#x27;t find anything ever. For example copying and pasting more than a trivial amount can take minutes (i.e. it blocks for minutes) and scrolling is just painful. Writing is not always accurate and you can get weirdly thick lines, etc. All of this can be fixed with better hardware and more performance, but I suspect the experience vs cost ratio is logarithmic&#x2F;exponential.While scribbling in Goodnotes an iPad pro is not as \"rewarding\", actually working is so much better. reply joemi 18 hours agoprevSpeaking of e-ink devices, is there a more-open equivalent to the amazon&#x2F;kindle ebook store? Some site you can use to legally purchase and download ebooks for non-kindle devices? Or can you do that via Amazon now? reply II2II 10 hours agoparentThis seems to depend upon the author&#x2F;publisher more than anything else. It also seems to heavily depend upon the type of book (e.g. DRM free computer and science fiction books seem to be the most common). Even when you do find a store that sells DRM free ebooks, you have to be careful about buying books that are labelled as such.Kindle is probably not the best choice for DRM free books since ePub and PDF are the dominant formats (outside of Amazon). reply spondylosaurus 16 hours agoparentprevGoogle Play Books is pretty good on any device that runs it. You can also upload your own ebooks quite easily (and then sync progress&#x2F;annotations across devices), which is great for my collection of .epub files that mysteriously fell off a truck... reply wilsonnb3 15 hours agoparentprevYou can download books from the Kobo store. Most of them use Adobe Digital Editions DRM, which is trivial to remove using calibre, but some are DRM free. reply hiddencost 17 hours agoprevI wired a WavShare display to a firebeetle ESP32, with a 10 Ah battery.I run it with ESPHome connected to Home Assistant.Fits in a picture, I only update it every 8 hours. Battery is still alive after two months.I&#x27;m using Todoist to host a Todo list that I can update from my phone. It gets pushed to the eInk display on my office wall. reply konschubert 16 hours agoparentHow do you render the todo list? Does todoist provide an API?(I am trying to sell an epaper smart screen as a commercial product. Right now it only has a calendar app and I am looking for apps that I can add.) reply kepano 18 hours agoprevI really wonder what would have happened in the e-ink patents didn&#x27;t get locked up, and the technology had a chance to evolve for a couple more decades like LCD has.I&#x27;m working on an e-ink theme for Obsidian[1]. So far it&#x27;s working on Boox devices, but I wish I could get it running on reMarkable. I&#x27;m not as clued into the reMarkable ecosystem, does anyone know if they will eventually add an app store or better tools for developers?[1]: https:&#x2F;&#x2F;minimal.guide&#x2F;features&#x2F;eink reply Qwertious 14 hours agoparent>I really wonder what would have happened in the e-ink patents didn&#x27;t get locked upThis is a myth endlessly repeated without evidence. LCDs have patents up the wazoo (OLEDs etc, plenty of new screen techs), it didn&#x27;t stop them being developed. E-Ink just doesn&#x27;t ha e any economy of scale, and it hasn&#x27;t had an easy route toward economy of scale in the future, it&#x27;s fairly niche in it&#x27;s use-cases when it&#x27;s competing with LCDs.If ReMarkable ever adds an app store, I&#x27;ll eat my RM2*. They suffer from Apple syndrome and it goes against their \"digital paper\" schtick.*No I won&#x27;t. reply codethief 11 hours agorootparent> If ReMarkable ever adds an app store, I&#x27;ll eat my RM2*.Yeah, their whole product management is just downright obnoxious. Personally, I&#x27;m waiting for Supernote to open up their devices to 3rd-party devs. reply konschubert 16 hours agoparentprevHmmm, do you think your theme could potentially work as an app on the e-paper smart display that I am selling?The screen I am using doesn’t have touch input though, so it would only make sense if your app has non-interactive use cases.For now, the only out-of-the-box app that my display comes with is a calendar with google calendar sync. I am looking for ways to extend that.Maybe email me? (Email is in my profile.)And here is the eink smart screen I am talking about: https:&#x2F;&#x2F;invisible-computers.com&#x2F; reply shreyshnaccount 18 hours agoparentprevYou should check out hyperpaper, and maybe let&#x27;s build an obsidian plugin with similar functionality. The problem right now with obsidian is pen input lag atleast on my Onyx device. reply funksta 16 hours agorootparentHey, hyperpaper creator here! One of my long term dreams for the project is to make those pdfs usable as an input source for PKMs like Obsidian. I love the promise of full-featured PKMs (searchability, long-term retention) but I don&#x27;t want to be on a laptop for hours curating and typing into them. An eInk tablet is my preferred note-taking and thinking device.The idea I want to eventually pursue is set up a service where you could sync your pdf (or send specific pages via email), have them OCRed (including dates and titles specifically since they already live in well-defined parts of the pages), and then ingest them into your PKM for long-term storage and recallUnfortunately Obsidian Cloud doesn&#x27;t seem to have an API to support this at present, but I think it&#x27;s theoretically feasible with Notion at least. Let me know if you build something like this :) reply shreyshnaccount 4 hours agorootparentThat&#x27;s actually really similar to the digital infrastructure I&#x27;m building for myself. It&#x27;s deceptively hard. I also want automatic tagging and two way updating between PDFs and the filesystem on my laptop. You can contact me at shreyssecondbrain at gmail reply Evidlo 8 hours agoparentprevYou could package it in Toltec, but it requires you to ssh in to the device to install it. reply agentultra 16 hours agoprevA ReMarkable 2 with the Folio keyboard is almost a whole ass computer. An eMacs-like development environment where buffers also had layers that could intermingle strokes with text and it would be perfect.I’d hack my own but I’m a little paranoid of bricking it with only one hardware button. reply Qwertious 14 hours agoparentThe ReMarkable 2 needs the proprietary Xochitl binary to update the screen (there&#x27;s a shim, but it needs to be updated every time Xochitl updates), but the ReMarkable 1 doesn&#x27;t have this problem, and already has a port of Parabola Linux, Parabola-RM (no WiFi due to Linux-libre, although you can compile it with them included): http:&#x2F;&#x2F;www.davisr.me&#x2F;projects&#x2F;parabola-rm&#x2F;Plus, the ReMarkable 1 has a total of four hardware buttons, and is even 50g lighter! Plus it&#x27;s power button doesn&#x27;t get stuck. reply csixty4 9 hours agoparentprevI put code-server[1] on a Linux box of mine, which gives me a whole proper IDE in the browser. I use it a lot on my Boox tablet with a bluetooth keyboard and it works great.[1] https:&#x2F;&#x2F;github.com&#x2F;coder&#x2F;code-server reply starman12980 15 hours agoparentprevlmao I was just watching a video with this dude making it his whole ass computerhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xJIS_amo7TII think he used a boox tho reply eterps 19 hours agoprevIMO the Oberon operating system would be a really good fit for this type of hardware.http:&#x2F;&#x2F;www.projectoberon.net&#x2F; reply weinzierl 19 hours agoparentI love all the things from Niklaus Wirth I know, but I only casually know about Oberon. From a glance I don&#x27;t see the connection. Could you elaborate why this would be a good fit. reply ekidd 16 hours agorootparentI haven&#x27;t touched Oberon since the 90s. But it was a fun little system.The language is one of the nicer Pascal descendents. The windowing system was similar to tiling. The entire system was tiny in terms of code. Everything was black and white.One of the nicest features was universally embeddable widgets. You could make a simple clock and embed it in running text, for example. Kind of like what OpenDoc dreamed of, or Google Wave&#x27;s inline widgets, or what it might be like if you could extend Discord with custom UI in a few hundred lines of code.I wasn&#x27;t motivated to keep using Oberon—it was honestly too odd and too small to compete with my other desktop options.But I do agree it would be neat to try with an eInk display. It&#x27;s a small, interesting, black-and-white system with a minimalist UI. Particularly if you customized the UI input layer, it could be a neat tool for building small household dashboards. reply eterps 19 hours agorootparentprevIt&#x27;s a simple and small system that renders directly to a framebuffer (Project Oberon only supports black and white), it&#x27;s optimized for simple CPU architectures (and that&#x27;s an understatement), extremely small footprint and doesn&#x27;t have a lot of resource usage. reply cyberax 16 hours agorootparentprevThe members of the Oberon Cult just keep pushing it everywhere. reply eterps 16 hours agorootparentAh of course, the large number of platforms where the Oberon OS has been pushed to by the many Oberon cult members ;) reply wchar_t 16 hours agoparentprevA FORTH gui would be an interesting project as well reply jakswa 8 hours agoprevI still have my OG backlit kindle. It&#x27;s showing its age with a tiny tear that lets backlight through, but I&#x27;m still pushing through books on it. I&#x27;d be curious how these newer E-ink displays have improved, wonder what the refresh rate (hz?) is on them. reply fold3 4 hours agoparentFrom what I know the improvement is minor but noticable. There is less ghosting, a bit more contrast and it&#x27;s more reactive to the touch. The newer models can even play videos half decently (i.e. you can somewhat understand what&#x27;s going on on the screen) reply ddingus 9 hours agoprevI just started with two displays:One from Waveshare, a 10 inch display that I cannot seem to get a current rev data sheet for:https:&#x2F;&#x2F;www.waveshare.com&#x2F;product&#x2F;displays&#x2F;e-paper&#x2F;10.3inch-...I really want to run it via USB and understand the controller better. Currently using SPI on a Pi 400.And a smaller one, Papirus. I have that one on a Pi hat and have gotten quite a ways with it in python.Love these things and agree with OP on their appeal. reply GenericDev 11 hours agoprevE-ink devices are the best.I&#x27;ve been using a Boox device lately to read old comics and I LOVE it. https:&#x2F;&#x2F;shop.boox.com&#x2F;products&#x2F;novaaircThe thing is that it makes them feel so retro because of the limited colors they can supply, and it still looks great doing it.My only regret isn&#x27;t a regret, it&#x27;s just timing. I purchased the nova air c before the Tab Ultra C had come out. https:&#x2F;&#x2F;shop.boox.com&#x2F;products&#x2F;tabultracAnd its form factor is just so much more pleasant.I can&#x27;t wait for the coming years of e-ink advancements. reply bawolff 18 hours agoprevWow, the interactive fiction interpreter looks so cool. https:&#x2F;&#x2F;github.com&#x2F;bkirwi&#x2F;folly i think i want one reply k__ 16 hours agoprevWould be more punk if nobody would hog all the patents.It&#x27;s really a shame... reply yoavm 18 hours agoprevshameless plug: I&#x27;m loving my PostmarketOS powered Kobo and even built a small interface for it: https:&#x2F;&#x2F;github.com&#x2F;bjesus&#x2F;air and would highly recommend it to fellow hackers.I use it pretty much daily for reading, and occasionally for all sorts of hacking fun. reply V1ndaar 19 hours agoprevI was under the impression there were a few big issues with the openness of the reMarkable. Don&#x27;t remember the details, but at some point I decided it wouldn&#x27;t be for me. But this seems like I may be wrong?This seems like there should be good ways for a) easy sync and b) OCR without relying on their subscription (that&#x27;s required, no?). reply its-summertime 19 hours agoparentOpen-ness as in open source, I can&#x27;t comment on, but open-ness as in being able to get root, is almost easy enough to stumble intohttps:&#x2F;&#x2F;support.remarkable.com&#x2F;s&#x2F;article&#x2F;Help documents where to find the information, and the account details you are given afaik are for root reply Eeems 17 hours agorootparentSome of their stuff is open source[0], others, like the UI, are not.0. https:&#x2F;&#x2F;github.com&#x2F;reMarkable reply ethanbond 19 hours agoparentprevI would recommend looking at the Supernote. I did a ton of research and the ReMarkable seems very oddly limited. Supernote A5X is one of the best purchases I’ve made in 10 years easily.Idk about hackability and whatnot but as far as a useful e-reader, note book, sketchbook, planner, it’s amazing.Edit: Also unaffiliated with this product but it’s awesome: https:&#x2F;&#x2F;hyperpaper.me&#x2F;Configurable, highly linked PDF planner with a very responsive person behind it (I figure he must be around here somewhere :)) reply chrisweekly 19 hours agorootparentAlt perspective: my reMarkable 2 is awesome hardware, easy to hack (root is trivial), and hyperpaper.me works great on it.I recommend pairing it w&#x2F; a LAMY stylus. reply Qwertious 14 hours agorootparentThe RM2 can&#x27;t update the screen without Xochitl, though. That&#x27;s why Parabola-RM hasn&#x27;t been ported to it, AIUI. reply funksta 16 hours agorootparentprev> https:&#x2F;&#x2F;hyperpaper.me&#x2F; Configurable, highly linked PDF planner with a very responsive person behind it (I figure he must be around here somewhere :))Hey, that&#x27;s me :DThanks for the shout-out Ethan, I&#x27;m happy to answer any questions people have about hyperpaper reply adiM 13 hours agorootparentIs it possible to generate the planner for A6X. The customization options do not seem to mention page size. reply funksta 10 hours agorootparentYes, I can do that– the main change is just the amount of space available for the toolbar. Just mention it in the order form and I&#x27;ll follow up with a custom build reply TheFreim 19 hours agorootparentprevI have a supernote a5x, it&#x27;s amazing. Extremely useful for marking up pdfs.> Idk about hackability and whatnot but as far as a useful e-reader, note book, sketchbook, planner, it’s amazing.You can currently \"sideload\" apps. It&#x27;s not officially supported but the Supernote team appear to appreciate people tinkering. Adding an official means of installing apps has been in the road map for a while.> You guys are really exploring! A kind warning, installing third-party apps on your device may cause problems, as our kernel is optimized for E-Ink screens. We cannot guarantee a good experience with third-party apps if they are installed through unofficial methods. We are in the process of adding an official app store and support for sideloading, so please kindly wait.https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;Supernote&#x2F;comments&#x2F;wql9gm&#x2F;how_to_in... reply V1ndaar 19 hours agorootparentprevThanks for the recommendation, I&#x27;ll check it out! reply yayitswei 19 hours agoparentprevLooks like there are several self-hosted options, like this one: http:&#x2F;&#x2F;www.davisr.me&#x2F;projects&#x2F;rcu&#x2F;Probably because it&#x27;s easy to get root, like another poster mentioned. reply Eeems 17 hours agoparentprevYou can run your own reverse engineered implementation of their cloud: https:&#x2F;&#x2F;ddvk.github.io&#x2F;rmfakecloud&#x2F; reply snickerbockers 13 hours agoprev> ARM is a simple architecture with a low instruction countThis has not been my experience with ARM assembly. There are several RISC machines with far smaller and simpler instruction counts. reply snvzz 13 hours agoparentRelative to x86, ARM could be described like that.The standard open ISA RISC-V can be described like that relative to both legacy ISAs. reply croes 13 hours agoparentprevSimple and low don&#x27;t mean simplest and lowest. reply shreyshnaccount 18 hours agoprevOnyx devices are good, but would be so much better if I could run desktop linux on it :&#x2F; reply FouzR 16 hours agoparentIt would be better if they were GPL compliant reply starman12980 15 hours agoparentprevyou _can_ use some onyx devices as an external monitor.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xJIS_amo7TI reply 23B1 18 hours agoprevIt&#x27;s bonkers to me how the whole hardware&#x2F;software world seems to miss the actual best feature of e-ink: it&#x27;s visible in sunlight. It chaps my ass every day that it&#x27;s only possible to sit in a semi-dark room if for my working hours – during the day no less!YES I am aware there are ways to hook an e-ink screen to my laptop. But that&#x27;s such a kludge! How is it that there are so few options, how is it nobody is thinking about the health benefits of knowledge workers being able to spend half their day in the sun?Sorry for the rant, it&#x27;s just big tech brain that very few product developers think in this way. Humans are meant to be outside in the fresh air and sunshine, not locked to a damn screen all day. reply jlokier 6 hours agoparentSurprisingly, some laptop LCDs work fine for software development in bright sunlight outdoors. They switch to reflective mode so don&#x27;t depend on the backlight. My old laptop had one, and it wasn&#x27;t even an advertised feature. More detail: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37063449 reply alcover 12 hours agoparentprevThat is my dream too.I would be SO happy to sit outside and think and code for many hours without worrying on battery life.No need for a powerful CPU. I just need to edit my code, see if it works and take notes.I want to hack on my compiler while the cows graze around me ! reply soultrees 3 hours agorootparentTo be honest, that’s kind of what I already do. MacBook Air with a portable battery gives me about 12 hours. I live in BC so I’ll grab a coffee, drive up the mountain where I can get cell service (not needed in all cases) and just code away until I run out of battery, coffee or energy. The future is here. reply paulmd 5 hours agorootparentprevyes, I&#x27;ve been thinking about this too, and I&#x27;ve talked to other people who have had the same fever dream. the children yearn for the dumb terminal.this isn&#x27;t a hardware product (people here have mentioned an e-ink tablet that can sideload, that plus a keyboard plus a battery, or ESP32-S3 etc) but rather a software product.and that software is the glorious resurrection of vt320&#x2F;vt330 buffered&#x2F;paged terminals. because that&#x27;s what&#x27;s going to minimize your terminal&#x27;s power consumption. you need to brutally minimize the number of bytes you transmit, which means having relatively small working set for any assist features (eg things like debugging might be nicer with a local variable cache). A large persistent eMMC or flash storage (but optimized for doing some decent writes) might be nice for those things. 32GB or 64GB goes a long way in a dumb-terminal context, you can use that like a portion of your RAM load if you code carefully.btle can do some active data transmission in realtime and it has the basic \"beacon, I&#x27;m still here\" etc, and you can use the notification-push thing for server-side async ops. And ideally you&#x27;d use your phone as a BTLE client that routes packets&#x2F;data or provides your server-side api. This can be done even on apple with the Bluetooth Browser thingy, your self-hosted website can interact with your BT device and that&#x27;ll be your relay.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bluetooth_Low_Energy#Applicati...in an interactive scenario with an IDE-ish thing and a larger working set maybe you use more power but if you&#x27;re running a nano&#x2F;pico clone onboard that&#x27;s dirt simple and can be done with simple buffer flush etc. And most of the ESP32-S3s come with 8MB of external SRAM.The other major power draw is the USB, I think you could bring that down a lot with an actual hardware circuit wired right to the ESP32.Again like, the e-ink tablet with an external KB is simple and lets you get tinkering with the editing experience in that kind of form factor! but I also think you can cut power way below that if you use something like the ESP32-S3 and BTLE with aggressive onboard caching. Don&#x27;t forget to minimize power in idledown mode, and idledown as aggressively as possible. Running the keyboard as an interrupt-driven thing could cut power a lot if you can idle down between keypresses. reply phil294 13 minutes agorootparentInteresting thoughts, even though I don&#x27;t understand half of it. But really, check out: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28432921 reply MichaelZuo 15 hours agoparentprevIf you believe in it, then start your own company and make it? Your on HN after all. reply kylebenzle 17 hours agoparentprevWe have the technology we have, there is no conspiracy to keep e-ink down other than a conspiracy of dunces. reply t0bia_s 13 hours agoprevI really want phone with e-ink display. I mean something like Mudita phone without that hipster approach and overpricing. reply FirmwareBurner 13 hours agoparentSecond-hand Motorola F3[1]? Even brand new I paid something like 50 Euros for it.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Motorola_Fone reply t0bia_s 30 minutes agorootparentOutdated. I need sync for my contacts, notes and email. 2G is no longer possible to use in my country. reply clnq 18 hours agoprevI’ve been dreaming of a truly programmable (not just apps) e-ink watch with 4g or at least WiFi for a while.A week-long battery life, cellular connectivity, visibility in the sunlight, and it should be cheap if it’s cost+ priced.Oh the things I’d put on it. I could host an API on my server where I’d ask GPT to summarise recent events or my email metadata and calendar events. I could probably finally ditch my smartphone for good.Its hard to find anything like that, though. reply devbent 17 hours agoparentSoon as you add in connectivity, battery life dies. RF is expensive. reply clnq 16 hours agorootparentThere are some LoRa watches that last quite long. So I wonder if WiFi or 4g, at least at intervals, would make a week-long battery with low hundreds or slightly under a hundred of of mAh impossible. reply Moldoteck 13 hours agoparentprevOh god, somebody should bring pebble back to life. Such a shame pebble time 2 wasn&#x27;t delivered ( reply bullen 18 hours agoprevVision Five 2 is moving decently fast.The latest release handles most things without locking.I got my 3 MMOs working on it (Java, Java+LWJGL and C+), the impressive part is both OpenGL 1 and OpenGL ES 3 work as expected, but much too slow still.Raspberry 4 and Vision Five 2 are the contenders for relatively open and passively cooled 100% gaming.Even if the TH1250 and RK3588 promise more juice they also consume ~10W and make more heat that in most cases require fan or very large heat sink. reply quailfarmer 12 hours agoprevAnyone care to recommend one of the two devices (Kobo Elipsa or RM2) mentioned? It appears the RM2 may have gotten more expensive since release? How is the relative build quality? Any key hardware differences to note? reply abawany 2 hours agoparentI&#x27;ve used both for extensive periods and even with the rm2&#x27;s low storage, I vastly prefer it. The Elipsa&#x27;s hand-writing experience was just awful - not just laggy but non-deterministically so, their sync&#x2F;export was clunky, their updates were sometimes buggy (e.g. the recent addition of GDrive import and broken export, the works-now-won&#x27;t-work-again Overdrive and Pocket integration), and the ad-ridden home page. By contrast, the rm2 is heavenly and it just works well - I was never the journaling type but the rm2 manages to extract a lot of writing out of me daily because of how awesome it is. Re. the rm2 pricing, I believe it has gotten a lot cheaper since its release - 400+usd vs 300usd now, afaik; I use an aftermarket pen with it (staedtler noris jumbo). I use the rm2 for work and for personal stuff and I love it; the elipsa sits idle and powered off. reply codethief 12 hours agoparentprevHaving tested the Remarkable 2 for a few weeks, I&#x27;d actually recommend another device: The Supernote A5X. The hardware & writing experience are a tad better IMO and the software much more so.Also, the Remarkable devs are notoriously bad when it comes to software updates and sharing their plans for the future with the community. Meanwhile, the Supernote people even share their Trello boards over on Reddit -> https:&#x2F;&#x2F;Reddit.com&#x2F;r&#x2F;SupernoteThe Supernote, admittedly, is not as hackable yet as the Remarkable but 1) official software updates are much more frequent and 2) there are plans to open up the device to 3rd-party Android apps. reply emodendroket 18 hours agoprevI have to say I actually find it kind of frustrating how low the specs are because you sometimes find the stupid thing chugging. While trying to display plain text. In a way a tablet is better. reply vpribish 19 hours agoprevthat page lists a few devices they _don&#x27;t_ recommend (kindle) because they are not openly hackable. what are some ones that are more so? anyone here recommend a cheap, hackable, e-ink reader? reply extr0pian 19 hours agoparentThe author mentioned them already, but didn&#x27;t recommend for violating the GPL, but I have an Onyx Boox Poke 3 and Boox Leaf that run Android that I&#x27;ve rooted. They&#x27;re not very cheap (the Poke runs about $180). They&#x27;re pretty fun devices to tinker with. https:&#x2F;&#x2F;chuck.is&#x2F;rooting-onyx&#x2F;Edit: I also experimented with the Poke 3 by creating a sort of \"writerdeck\" setup with a bluetooth keyboard and termux, then attaching everything together with velcro and magnets: https:&#x2F;&#x2F;chuck.is&#x2F;writerdeck&#x2F; reply SalimoS 19 hours agoparentprevFrom the same page > Convinced that you should hack on eink devices? Grab a reMarkable or Kobo and get hackingBut kindle is The cheapest e-ink afaik reply ljf 19 hours agorootparentLast time I looked the Nook simple touch (6 inch android eink tablet) was about £30 delivered 2nd hand. Love mine. I spent a long time (a few years ago) setting it up with all sorts of android fun, but now I just use it as a epub reader and it fits that niche perfectly for me. reply Qwertious 14 hours agorootparentprevThe cheapest e-ink is a $5 2\" Waveshare EPD plus an ESP32. reply politelemon 15 hours agoparentprevI&#x27;ve switched to Kobo recently and their devices are very hacker&#x2F;sideloader friendly. There are also many community provided software and unlocks. reply Nashooo 19 hours agoparentprevThey also linked to the Remarkable and Kobo communities. reply joshe 16 hours agoprevAdd Visionect to hacker unfriendly devices. They forced a change to subscription service. Ask me how I know :-(. reply corrigible 13 hours agoprevI was super interested up until the Discord link :( reply abawany 2 hours agoparentThey have a mirrored room on Element&#x2F;Matrix as well but it&#x27;s just the general chat and not the technical etc. sub-rooms. I quit Discord a while ago, probably for reasons similar to yours, and interact with the community using Element instead. reply goodpoint 13 hours agoparentprevSo much for punk and hacker cultures... discord is the windows of chat platforms :( reply louison11 12 hours agoprevCan anyone give their feedback on eye strain with e-ink?I feel like my eyes have gotten really tired from over a decade working in the tech industry, and wondering if taking my notes&#x2F;reading emails&#x2F;articles on a reMarkable 2 or similar could give my eyes some rest. reply orangepurple 13 hours agoprevI love these throwbacks. It reminds me of my old Palm m500. There is something so comfortable about Palm OS. I can&#x27;t quite grasp it but the Palm experience is simply exquisite and I have never seen it replicated anywhere. reply foobarqux 19 hours agoprevIt&#x27;s a shame that Kindles aren&#x27;t hack-friendly, there are lots of old Kindles lying around that would be great as an always-on display. reply PascalW 15 hours agoparentSome Kindles can easily be jailbroken [1]. I have two jailbroken Kindle 4 devices and they&#x27;re still great. Both for reading (though you have to sideload books) and as e-ink dashboards [2]. A Kindle 4 can run for ~ 28 days on a single charge, refreshing the screen every hour.[1] https:&#x2F;&#x2F;wiki.mobileread.com&#x2F;wiki&#x2F;Kindle4NTHacking#Jailbreak[2] https:&#x2F;&#x2F;github.com&#x2F;pascalw&#x2F;kindle-dash reply Sunspark 19 hours agoparentprevIt is doable though. A bunch of years ago I followed some instructions and set up a dual-boot on one using a Chinese ebook platform firmware. This way if you wanted to read epubs or PDFs you would boot to the other OS. Worked pretty well! Had access to all of the hardware including wifi.So it would be the same basic principle here as what you envision.. boot into that other system, but have it instead launch some other app. reply Turing_Machine 18 hours agoparentprevThough I haven&#x27;t actually tried this, it probably wouldn&#x27;t be too hard to use the built-in Kindle web browser to display a constantly updating web page and&#x2F;or full-screen image from a remote web server. reply foobarqux 18 hours agorootparentAmazon recently disabled the ability to keep the screen always on so it doesn&#x27;t really work. It&#x27;s kind of finicky as well: I would have the network selector pop-up and stay there if there was a temporary disconnection in the WiFi (say if someone used the microwave). reply Turing_Machine 15 hours agorootparent> Amazon recently disabled the ability to keep the screen always on so it doesn&#x27;t really work.Too bad. There are probably other use cases for \"keep the screen on continuously\".> It&#x27;s kind of finicky as well: I would have the network selector pop-up and stay there if there was a temporary disconnection in the WiFi (say if someone used the microwave).Now this I&#x27;ve never seen. The WiFi is pretty solid here, though... there are 5 WAPs in different parts of the house (primarily so I can get signal out to the edge of the yard -- the house is only medium-sized).. reply ryandv 18 hours agoprevAs much as I love the hacker spirit of cracking open hardware and software and bending it to your will (whether or not it was designed towards that end), I enjoy my reMarkable precisely because I can get away from the ubiquity of computing and needing to constantly tinker with and repair software.I&#x27;ve fucked with Gentoo and Arch for so long that sometimes I just want a break from it all. No dependency hell, no bugs, esoteric stack traces, nor popups, advertisements, notifications, nor distractions. Just some pen and paper, except without the eraser shavings or ink blots. Not having to scan your notes to digitize them is a nice bonus as well.Especially since the pandemic and in the WFH era it&#x27;s nice to get away from the omnipresent touchscreen or mouse and keyboard interfaces and deal with something a little more tactile; something reminiscent of a less perpetually online era. I&#x27;m tired of being hyperconnected to everything. Not to mention all the problems from staring at LED monitors all day long.Sometimes I don&#x27;t want to troubleshoot software; I&#x27;ve done enough of that already. reply Teknoman117 17 hours agoparentI feel you on this.I started using Gentoo on my personal machines (Desktop, Laptop, NAS) after I needed to understand it for work. Eventually I fell in love with the developer workflow that it allows.That was seven years ago. These days I feel like I&#x27;ve spent so much time tinkering for little to no benefit. I&#x27;ve been through LFS a few times so I don&#x27;t feel that being a Gentoo user made me understand Linux any more than I already did.So much \"emerge --sync && emerge -1 sys-apps&#x2F;portage && emerge -auUDN @world\" and then fix USE flags problems and mask problems and keep rerunning the last command until it actually works.I somewhat self host everything right now - VPN into my home network to access my NAS. But the user experience of documents and media just feels so poor compared to existing cloud services that I&#x27;m tempted to just give up on homelab stuff.The upfront price of 10+ TB hard drives is hundreds of dollars a drive, you need to replace them every 5 years or so to \"trust\" them, you need redundant disks because you can never trust them, you need a backup solution, time investment to make backups, and the price of power in the Bay Area means you are spending several hundred a year on power to run the gear. Whereas I could just get 10 TB for $50&#x2F;month from a cloud provider. It&#x27;s not like I actually watch or listen to any of the blurays or music rips I&#x27;ve made, which represent most of my data...I bought a PineNote in early 2022 hoping to replace my reMarkable. I&#x27;ve worn out the battery but I don&#x27;t want to give money to a company that intentionally makes swapping the battery nearly impossible. Along with the fact they&#x27;re useless at work because you can&#x27;t directly use a cloud service, you have to proxy through reMarkable&#x27;s own service.I thought it&#x27;d be fun to tinker on but then I actually developed a healthy social life and exercise routine again and have found little motivation to stay inside when I&#x27;m not working. reply blowski 17 hours agoparentprevI&#x27;m with you. I want to buy things that don&#x27;t need constant fiddling to keep them working. I want them to silently do their thing, supporting me in the background while I focus on mine.But it&#x27;s great knowing that I _could_ drop down a layer at any time. It makes me feel a lot more comfortable about relying on an ecosystem to know that it has redundancy in the support layer. For example, if Remarkable themselves go out of business, will I still have access to my documents? Will they still receive updates? Will I still be able to buy replacement parts? reply ryandv 17 hours agorootparentYes, yes. It just works, but if I need to I can pop open the hood and shell in, and then I&#x27;m back at home with Linux. reply locusofself 17 hours agoparentprevPrecisely why I have not used Linux on my laptop&#x2F;desktop since like 15 years ago. I love to tinker and troubleshoot but I prefer to to be getting paid for it. reply freedomben 17 hours agorootparentA lot has changed in the last 15 years. Unless you&#x27;re doing something crazy (like trying to play sound, haha jk that&#x27;s a throwback joke to the old days), there&#x27;s nothing you need to tinker with these days (though of course it&#x27;s there if you change your mind). Fedora, Ubuntu, and some others are very stable and \"just works\". reply RosanaAnaDana 17 hours agorootparentI&#x27;ve done 3 new computer builds in the previous 6 months.Both Linux installs were an &#x27;it just works experience&#x27;.The windows box has been a total pain in the ass and I&#x27;ve had to reinstall multiple times.Linux is a better out of the box experience than Windows. reply slimsag 17 hours agorootparentprevThat wasn&#x27;t my experience ~11 months ago[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32891879 reply dehrmann 17 hours agorootparentprevA year or two ago, I remember HiDPI still being a hassle. reply swores 17 hours agoparentprev> As much as I love the hacker spirit of cracking open hardware and software and bending it to your will (whether or not it was designed towards that end), I enjoy my reMarkable precisely because I can get away from the ubiquity of computing and needing to constantly tinker with and repair software.Personally I completely agree with you, and could have written almost exactly that paragraph - I too have a ReMarkable (the 2nd &#x2F; current version), and love using it as it ships for both note taking and especially for reading ebooks&#x2F;PDFs (\"especially\" just because it&#x27;s what I use it for more, not because that&#x27;s what it&#x27;s better at - in fact, its UI for reading documents is among its weaker points and I hope they improve it in future software updates).However it is worth pointing out that you can SSH into it, and there are a fair few 3rd party tools and hacks for it - so far I&#x27;ve avoided trying any of them as there&#x27;s nothing that I want strongly enough to have even a 1% risk of bricking it to worry about. But I&#x27;m tempted to start playing around with it someday.This is the best list of stuff for the ReMarkable that I&#x27;m aware of, though I don&#x27;t know how complete it is &#x2F; how many released tools or guides there might be that aren&#x27;t included here:https:&#x2F;&#x2F;github.com&#x2F;reHackable&#x2F;awesome-reMarkable reply Eeems 17 hours agorootparenthttps:&#x2F;&#x2F;remarkable.guide is a good place to start reply swores 17 hours agorootparentThanks, bookmarked! reply teknico 17 hours agoparentprev> Not to mention all the problems from staring at LED monitors all day long.Not sure what problems you mean. Any reference? reply ryandv 16 hours agorootparenthttps:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC6020759&#x2F; reply pmarreck 17 hours agoparentprev> I&#x27;ve fucked with Gentoo and Arch for so long that sometimes I just want a break from it all. No dependency hell, no bugs, esoteric stack traces, nor popups, advertisements, notifications, nor distractions.OT, but FYI... I have all that on NixOS. Things install and run reliably and configurations stick reliably, all declaratively. It feels like \"the final distro hop\" for me.1) Getting back to known-good from any fucking-with that breaks something is 1 rollback away.2) It&#x27;s still Nix wizardry to do something as relatively simple as set up a systemd background process that gongs on the hour (I actually made this work, but it broke recently and I don&#x27;t know why yet because 2-year-old-son). This actually discourages \"distracted hacking\" while making you work for the changes you definitely want, which ends up being a nice compromise.FWIW, I&#x27;ve been the most productive on this Linux distro of all the ones I&#x27;ve tried (Ubuntu, ElementaryOS, Pop_OS, Manjaro, Arch). reply doublerabbit 17 hours agoparentprev> Sometimes I don&#x27;t want to troubleshoot software; I&#x27;ve done enough of that already.That&#x27;s why I switched to FreeBSD.Every OS kernel update, every package upgrade just works. Rock Solid. reply terminous 19 hours agoprevRetro? Sure. Punk? Not when the patents are tightly held by a greedy patent troll who seems to do everything in their power to stop hobbyists and hackers reply AshamedCaptain 18 hours agoparentSigh. Again with the story about \"evil eInk and their gazillion patents\". A story which :1. Does not make any logistic sense: eInk is rather a small company versus the likes of Qualcomm, Sony, Sharp, Fujitsu, Philips, Microsoft (thanks to Wacom) all of which have way more patents in the EPD area that eInk. EPDs are literally as old as the _GUI_, and even started at the same place (Xerox). Plus, eInk relies mostly on chinese manufacture... which is well-known to generally don&#x27;t give a damn.2. Could not possibly have any motive: eInk apparently is a suicidal company that likes to torpedo its already shrinking little market so that .... what exactly? LCD manufacturers have a field day?3. Ignores the fact that there are, indeed, multiple competitors to eInk whose panels are either indistinguishable from eInk or literally better. Many smartwatches like Pebble&#x2F;Garmin don&#x27;t use eInk _at all_, yet people even right here in HN still believe they are eInk. Qualcomm of all companies (an actual patent troll -- ask Apple -- and most definitely unlikely to be afraid of a minuscule company like eInk) owns a in my opinion _much_ better EPD technology called Mirasol which has zero of the slow refresh problems of eInk, much better color reproduction, much better contrast *, and is barely more expensive!The plain truth is that majority of customers just don&#x27;t care enough about these technologies, and therefore they will always be niche. At the end of the day, average customer can&#x27;t distinguish the latest EPD panel to a reflective LCD from decades ago. Customers will flock towards shiny glossy LCD watch over EPD all the time. That&#x27;s why Gyricon failed. That&#x27;s why Mirasol failed. That&#x27;s why every other electrophoretic startup folds.* eInk contrast is still a joke and for the last decade actually degrading rather than improving, thanks to touchscreen layers, color filter layers, etc. But you see it being parroted all the time that \"eink has infinite contrast\". The latest color panels this year are no better than the ones I have on WindowsCE devices from the late 1990s, eInk or not. Colors still look incredibly dull, there is a ridiculously limited palette, and resolution and contrast take a sharp hit (pun not intended). reply jjoonathan 17 hours agorootparentAlso: \"punk\" just means \"aesthetic\" now. The economic and political connotations have a long-term downtrend in mindshare. reply jmbwell 17 hours agorootparentGen X forgotten again? Figures. Whatever, I guess. reply paint 17 hours agorootparentprevMirasol sounds great, how come there are not more devices out there using it? The only one I could find was the \"Toq\", a 2013 proof of concept smartwatch by Qualcomm? reply criddell 18 hours agoparentprev> a greedy patent troll who seems to do everything in their power to stop hobbyists and hackersIs there evidence of this? On every HN e-ink thread this is repeated as if it is common knowledge, but I haven&#x27;t read much to back it up. Have you personally been shut down by lawyers when you try to use an eink display in a hacker kind-of-way?And yes, there are patents, but so what? How does the company wield them? Are the licensing terms terrible? My Raspberry Pi has a Broadcom CPU. Broadcom is no stranger to patents yet there&#x27;s plenty of hobbyist and hacker activity around their components. reply FirmwareBurner 19 hours agoparentprev>Not when the patents are tightly held by a greedy patent troll who seems to do everything in their power to stop hobbyists and hackersThat&#x27;s a bit disingenuous and short-sighted view from people not knowing or understanding the industry, market, technology and manufacturing challenges. Sure, like any successful tech company, e-ink owns patents and controls a large part of the market more-or-less, but patents aren&#x27;t the main reasons why the e-paper industry hasn&#x27;t moved forward.That&#x27;s kind of like saying \"ASML&#x27;s and Cymer&#x27;s patents are the reason the EUV lithography hasn&#x27;t moved forward and why they have no competition.\"No mate, that&#x27;s not true. Just like EUV lithography, making e-ink tech displays, affordably, and at scale with good yields and healthy margins to keep the industry afloat, is hard, very hard, bordering on magic, which is the main reason they have no competition.Turns out making minuscule pigment electrostatic particles that can quicky move around inside a fluid suspension and hold their position long enough at various ambient conditions, is a huge challenge, and manufacturing that at scale with very low defects and sustainable margins is even harder.Nothing in their patents currently is holding back competition, but competition can&#x27;t reach the scale and yields that would make enough profits to support a viable competitor consider even entering this field, versus OLED displays, as that&#x27;s where thew real money is in display manufacturing right now and that&#x27;s where the competition is heating up and where all the R&D money gets poured.That&#x27;s why there&#x27;s been various alternatives to e-ink-like tech popping up from university research labs and being displayed at trade shows, but going from a research lab one-off prototype being shown at trade shows, to mass production at scale with good yields and profit margins, is the real challenge and is where e-ink has their secret sauce that nobody can successfully replicate.Similarly how China has been showing off working home grown Xnm lithography prototype chips that can compete with TSMC, but reaching the yields and volumes of TSMC is where the impossible to cross cliff lies, and why people get confused and don&#x27;t understand that the major challenge lies in manufacturing at scale and not just the core tech that makes the widget unique.I&#x27;m not defending e-ink the company and their corporate practices, just wanted to shed some light on the technicalities of the subject and hopefully clear some of the FUD and conspiracies that get wrongfully spread around. reply orhmeh09 18 hours agorootparent> That&#x27;s a bit disingenuous and short-sighted view from people not knowing or understanding the industry, market, technology and manufacturing challenges.For clarification -- disingenuous is defined as:> not candid or sincere, typically by pretending that one knows less about something than one really doesIn your post, are you claiming there&#x27;s a shadowy group of people who at the same time are both unknowledgeable but also conspiring to hide their own knowledge? reply FirmwareBurner 18 hours agorootparentSorry, I&#x27;m not a native English speaker. \"disingenuous \" was the wrong word in that context. I meant to use it as a synonym for \"unfair\" and made a mistake.>In your post, are you claiming there&#x27;s a shadowy group of people who at the same time are both unknowledgeable but also conspiring to hide their own knowledge?No, that&#x27;s nowhere near close to what I claimed. I think my post was clear on what I meant despite my mistake: that people are too quick to blame e-ink the company for malice without understanding the technical challenges around industrialization of such technology and the economic factors of the e-ink-like products market (profit margins, supply&#x2F;demand) that drive competition and investments, or lack thereof, in this tech. reply kragen 16 hours agorootparentit is definitely not a synonym for \"unfair\"; it is a serious attack on the integrity of the person you were responding to, and you should apologize to them reply FirmwareBurner 16 hours agorootparentI do believe the first word in my previous comment was \"sorry\" for the mistake, and unfortunately I can&#x27;t edit that comment anymore to correct the mistake.Also, I have no reason to apologies to the commenter as he did not provide any evidence to support his claims that \"e-ink is evil\" in order for his integrity to be affected, to warrant an apology for my counter-arguments, nor do I think the original commenter is petty enough to be offended by my honest mistake, which I rectified later. reply kragen 11 hours agorootparentyou called them a liar who was pretending to be stupid, which is what &#x27;disingenuous&#x27; meansto me, that counts as a reason to apologize reply bemusedthrow75 11 hours agorootparentI&#x27;m not the person who apologised or the person who was apologised to, but the following, to me, reads like an appropriate apology in the context:> Sorry, I&#x27;m not a native English speaker. \"disingenuous \" was the wrong word in that context. I meant to use it as a synonym for \"unfair\" and made a mistake.This particular mistake (assuming disingenuous means a little less than it does) is not particularly uncommon among native english speakers (or on HN, at that).FWIW:> you called them a liar who was pretending to be stupidThe \"pretending to be stupid\" is not an essential part of the definition above (merely \"typically by\").Finally, Merriam-Webster offers up other definitions:lacking in candorgiving a false appearance of simple franknessThese don&#x27;t fit particularly with the strident definition you&#x27;re using.English words are complex, with contextual and flexible meanings. You&#x27;ve picked one definition. And then you&#x27;ve attacked someone&#x27;s integrity on the basis of it, which is exactly what you&#x27;re arguing has been done to someone else. Don&#x27;t be this guy. reply FirmwareBurner 11 hours agorootparentprevI have already before pointing it out, what more do you want? replyyellowapple 18 hours agorootparentprevThe \"typically\" in that definition would suggest that \"claiming there&#x27;s a shadowy group of people who at the same time are both unknowledgeable but also conspiring to hide their own knowledge\" is unnecessary to claim disingenuity.You&#x27;re on the right track, though; it&#x27;s worth asking if the people criticizing patents and their stranglehold on innovation are not being candid or sincere in doing so. (The answer IMO is \"no, they&#x27;re being very candid and sincere, in stark contrast to most defenders of contemporary patent law\", but it&#x27;s nonetheless the more relevant question). reply surgicalcolor 18 hours agorootparentprevGiven that the margins are so tight and the expenses so high as you&#x27;ve illustrated, explain to me how it&#x27;s possible that the extra costs involved with licensing patented hardware is not a significant factor?It doesn&#x27;t really make sense to say that on the one hand, it&#x27;s super tough and hard to make a profit, and on the other hand the costs of accessing patented hardware is an immaterial cost.Your post just really isn&#x27;t convincing that a patent here has little effect on the ability for others to compete.When margins are as tight as you say they are then obviously the costs of licensing are going to make the margins even thinner or next to impossible for another competitor to meet.Love when people come out here with unironic defense here of monopolies by simply defending them as some meritocratic output of success or something. reply FirmwareBurner 18 hours agorootparent>Love when people come out here with unironic defense here of monopolies by simply defending them as some meritocratic output of success or something.That wasn&#x27;t my point. You must have misunderstood. reply swores 17 hours agorootparentIn my opinion, saying that without explaining what they misunderstood &#x2F; what you disagree with them on is both snarky and unsubstantial enough to fall below the line of the HN guidelines. Especially as it&#x27;s not clear to me that their interpretation isn&#x27;t what you meant, and it&#x27;s clear that they are arguing in good faith rather than intentionally misunderstanding. Though their last paragraph was itself snarky enough that I can see why you might have wanted to react in kind (not that that means you should). &#x2F;my two cents reply FirmwareBurner 17 hours agorootparentI didn&#x27;t detail further why he misunderstood, because in my interpretation of his comment, he had his pitchfork out and falsely accused me of \"defending monopolies\" just to engage in flame-bait which I didn&#x27;t want to fuel, and I already went into enough details in my original comment to explain why he misunderstood and why my original explanation is not \"defending monopolies\" but presenting the facts, he just has to read it again carefully with an open mind and with his pitchfork down. reply swores 17 hours agorootparentFair enough to not want to engage, but in that case you could just not engage rather than adding more snark.But ideally, even if you think they don&#x27;t deserve your explanation, considering it&#x27;s a public forum you could still explain why you think there wrong for the benefit of the rest of us who m",
    "originSummary": [
      "The article explores the author's fascination with e-ink devices and compares them to the simplicity and magic of computers from the 80s and 90s.",
      "The benefits of e-ink devices are highlighted, including their low power consumption, simple architecture, and lack of unnecessary software and features.",
      "The unique software ecosystem surrounding e-ink devices is discussed, and readers are encouraged to participate in hacking and developing for these devices. Some limitations, such as the proprietary display driver of the reMarkable 2 and the lack of strong package management on the Kobo, are mentioned."
    ],
    "commentSummary": [
      "The discussion explores customization options, limitations, and high costs associated with e-ink devices.",
      "Users share their experiences, frustrations, and desires in relation to e-ink technology.",
      "There is a debate about the impact of patents on competition and the definition of certain terms."
    ],
    "points": 642,
    "commentCount": 312,
    "retryCount": 0,
    "time": 1693056076
  },
  {
    "id": 37279109,
    "title": "Block YouTube ads on AppleTV by decrypting and stripping ads from Profobuf",
    "originLink": "https://ericdraken.com/pfsense-decrypt-ad-traffic/",
    "originBody": "Latest Accomplishments StackOverflow Instagram GitHub About Block YouTube Ads on AppleTV by Decrypting and Stripping Ads from Profobuf EricJanuary 6, 2022 In a Nutshell I discovered that putting a man-in-the-middle proxy between my Apple TV and the world lets me decrypt HTTPS traffic. From there, I can read the Protocol Buffer data Google uses to populate YouTube with ads. It is too CPU-intensive to decode Protobuf on the fly, so instead, I found a flaw in the Protobuf format which allows me to reliably change one byte to obliterate ads. What follows is a reference guide for setting up a bare-metal network router to block malicious ads, obnoxious ads, tracking, clickbait, crypto-jackers, scam popups, Windows spying on you, etc. using blocklists to protect all networked devices. Goal: Let’s build a cryptographically-strong router with FreeBSD and pfSense to completely block YouTube ads using a flaw in the Google Protocol Buffer format to completely block pre-roll, mid-roll, and end-roll YouTube ads on Apple TV and iPhones, network-wide. GDPR Cookie Consent Hi there, this site uses analytics cookies in order to show me pretty graphs and gauge anonymous interest in the content I make for fun. These are the usual cookies from mainly Google Analytics that millions of other sites use. I hope that's okay with you. That's Okay Disclaimer: I want to support content creators, so to be fair, after a few months of blocking YouTube ads, I am now paying for YouTube Premium; Just because I can break something, doesn’t mean I need to. Sections Part 1 – Setup pfSense on Bare-Metal Why block Ads and Behaviour Tracking? Required Router Hardware Unboxing the Hardware Install pfSense on Bare Metal First pfSense Boot Enable the AES-NI Cryptographic Instruction Enable RAM Disk Dashboard Widgets Adblocking with pfBlockerNG Isolate LANs for Security Class B IPv4 172.31.1.0/24 Network for Untrusted Devices Add Firewall Rules Part 2 – Isolate Network LANs Setup the Untrusted Wi-Fi AP Automatic pfSense Configuration Backups Unable to Reach 172.31.1.x from 192.168.10.x Replace Stock Firmware on the AC1200 Wi-Fi Access Point Archer C5 v2 into the Refuse Bin, R7000 as the New Wi-Fi AP Set up the Trusted Wireless Network Network Devices Interconnectivity Check Windows File Sharing Gotchas Public Service Announcement: Edge Browser Part 3 – Setup DNS Adblocking Block Clickbait, Incessant Ads, and Dangerous Sites Intercept all DNS Requests, Even to Hardcoded DNS Servers Part 4 – Trick the YouTube Ad Algorithm How to Restrict Apple TV YouTube Ads? Trick the YouTube Ad Algorithm Instead Research into YouTube Advertizing Spend New Goal: Convince YouTube I’m 70 and in Italy Selectively Route Apple TV Over the VPN Selectively Route Apple TV YouTube Traffic Over the VPN Gotcha: DNS Race Condition Gotcha: Authentication Trouble, Forbidden 403 Error Gotcha: YouTube is Now Showing UK Ads, Not Italian Ads Find a VPN Exit Node with no ASN Leak Hijack Google Video DNS Queries New Goal: Programmatically add IPs to the Firewall Policy Rule Research Python Methods to Hijack DNS Queries i. Rsync Disk Backup ii. Install pfSense REST API iii. Explore the Unbound Python Module Smoke Test: A Python DNS Hijacking Script Part 5 – Decrypt HTTPS Traffic New Goal: Research and install a Squid-like proxy i. Fun fact: Jailbreaking iPhones in Japan Install a Fake-but-Trusted CA Cert on Apple TV and iPhone? Experiment with Squid and SquidGuard Self-Host the CA Certificate Abandoning Squid: Too Slow, Too Heavy i. Rsync Diff of Changes Install MITMProxy in a FreeBSD Jail Exploring MITMProxy Patch MITMProxy Source Code for Server SNI Interrogation Part 6 – Intercept Apple TV and iOS YouTube Ads Smoke Test: Intercept YouTube Ads with MITMProxy Examine uBlock Origin Regex Patterns for Inspiration Surgically Alter the JSON Response to Remove Ads The iOS YouTube App Uses Protobuf, not JSON Timing Analysis to Detect Ad Videos? Decode the YouTube Protobuf Responses Ad URL Polymorphism Smoke Test: Intercept and Decode Protobuf in Python i. Pure Python Benchmarks ii. Pure C++ Benchmarks Fuzzing the YouTube Video Ad Responses Enter Burp Suite Tools for Penetration Testing Exfil the Proto Schemas from the App, Cleanly? Part 7 – Reverse-Engineer Protobuf Messages Hardcore Deep-Dive into Protobuf and Wire Format Exploit a Protobuf Flaw to Easily Remove All Ads by Changing One Byte Smoke Test: Remove Ads from Protobuf in O(n)-Time Analysis of this Successful Adblocking Technique i. Summary ii. Timing Analysis iii. Knock-On Benefits iv. Future-Proof v. Should Google be Worried? The MITMProxy YouTube Adblocking Script Part 8 – Summary YouTube Premium i. Experiment in Ad Viewing ii. $0.15 as a Ballpark CPV iii. CPV from US Advertising Spend Divided by Total Views iv. Is YouTube Premium Worth It? DMCA, Sony, Viacom Summary of Accomplishments Why block Malicious Ads and Behaviour Tracking? You are a valuable commodity that is bought and sold without your knowledge or consent. You will be tricked with clickbait, distracted with large ads, and enticed to leave the site you are on at every opportunity. Plus, everything you do online is being monitored so your habits and searches can be remarketed and sold over and over again for years. Privacy – Knowing what you like to watch and read, what phone you have, what you watch on Netflix, what you shop for, what you ask Alexa about, yout taste in music, etc. is unbelievably valuable to advertisers. Spying on people is such a big problem that Europe passed the GDPR law so every site you visit asks if you are okay with cookies (and we blindly click “ok” to hide the banner). We must wrestle back privacy ourselves. Bandwidth – If privacy doesn’t concern you, how about this: it is well-known that between 25% and 40% of network traffic is ads, tracking, JavaScript to load trackers (fingerprint.js, googletagmanager.js), websocket traffic to collect how you scroll and what you type (Hotjar), and the like. Do you have a 100 Mbps internet connection? Consider it 60 Mbps! Clickbait – Then there is clickbait. “You won’t believe what Tom Cruise did. He…” and you may want to click. Then you are in the spider’s web. How about fake news? Or articles that don’t say “sponsored” in size-8 font, but now say “underscored” to be clever. What is even real anymore? As soon as you click on clickbait, you may end up on a page with a dozen more ads that aren’t approved by Google but lead to a dark world of maliciousness. Clickbait is so incredibly profitable to scammers. Cryptojacking – Some websites will load crypto-mining JavaScript (e.g. CoinHive.js) so while you read, they overheat and abuse your computer to try to make a few pennies. Some sites will load JavaScript that tries to steal from your crypto wallet or trick you into transferring cryptocurrency. Takeaway: It is highly lucrative yet detrimental to you to track and trick you, and only you can do something about it. Top ↩ Required Router Hardware A virtual machine, Docker image, or Raspberry Pi are not performant enough to protect a whole SMB network; We need dedicated hardware with a cryptographic instruction set so that its only function is to route, decrypt, and monitor packets in and out. Here is what I used. A mini PC with the AES-NI instruction set (e.g. J4125) Several gigabytes of DDR4 RAM (e.g. 32 GiB) A decent mSATA SSD drive (e.g. 128 GiB) A USB drive to transfer pfSense Top ↩ Unboxing the Hardware I’ve ordered a mini J4125 PC from AliExpress, ordered 32 GB of DDR4 RAM and a 128 GB mSATA from Amazon, and will assemble them for the first time now. Warning: Out of caution, I searched diligently for a barebones mini PC that did not include RAM or an SSD; there is nothing stopping an overseas seller from including some generic RAM and SSD but charging Samsung prices. Tip: 128 GB of disk space on a router? Yup. That should be plenty of space to hold logs and not wear down the SSD too quickly, and to allow beautiful packet capture (and maybe an edge cache for NPM and Docker?). A beautiful box, isn’t it? It only has 3 LAN ports, but it can be extended with network switches. The J4125 AES-NI quad-core fanless mini PC The pfSense router from a J4125 fanless mini PC Top ↩ Install pfSense on Bare Metal I’ve never used pfSense before, so we will explore this together. The compressed image is about 360 MB and can be flashed to a USB drive with an AppImage binary of Etcher (very cool). Decisions, decisions: VGA install or serial? Let’s serial into the new router. Why not? Let’s not serial into the router Well, that looks painful. It would also be a whole production to serial into the box in case of an emergency because the serial port is inside, and there isn’t even an RS232 or JTAG connector – just some narrow header pins. Yikes. Let’s go with VGA and plug a keyboard into the USB port – get ready to navigate with arrows and tabs. J4125 mini PC BIOS over a VGA cable I’ll follow this guide on YouTube. I’ll pass on encrypting the disk since I would like to avoid entering a passphrase each time the mini PC reboots. A stripe disk is fine since there is only one disk. I have no idea what to expect yet, so I will pass on dropping to a shell for a more advanced configuration. Top ↩ First pfSense Boot I ejected the USB containing the boot image (important) and rebooted the little box. It played a melody on the internal speaker (there is an internal buzzer and thankfully it isn’t very loud). Do I need to have a LAN connection already, or can I just start the thing? I’ll just start pfSense and let it complain to me if it wants… and according to the YouTube tutorial, I should guess which port is LAN 1. I’ll do that now. I figured out that I should set the LAN 1 to a static IP address that is not in my existing router’s DHCP range, so I went with 192.168.1.3. Now I can access an admin web portal (admin/pfsense). Hooray. Yikes, the mini PC beeped at me and informed me that ‘admin’ has logged in. That startled me a bit, but hey that is pretty neat. First time logging into pFsense admin UI Top ↩ Enable the AES-NI Cryptographic Instruction I played around with the wizard, used defaults, and got to the web configurator. The first thing that caught my eye was AES-NI CPU Crypto: Yes (inactive). I went out of my way to get a mini PC with AES-NI. What gives? Ah, this needs to be enabled in System > Advanced > Miscellaneous. Why not auto-detect this and use the best option? I’m glad I spotted that, or else this mini PC might as well be a Celeron J1900 of yesteryear. Top ↩ Enable RAM Disk Having 32 GiB of RAM, let’s take advantage of that and use a generous amount of RAM for /var and /tmp, and since hopefully this 128 GiB SSD has wear levelling, let’s take a RAM Disk backup every hour. Let’s take advantage of RAM disk Reboot! AES-NI is now active. Top ↩ Dashboard Widgets This dashboard is pretty slick. I’m just discovering that there are widgets that can be added to the Dashboard, including S.M.A.R.T to alert us if the SSD is going bad. Nice. Final pfSense dashboard after all setup Hang on, when I added the Services Status widget, something called PC/SC Smart Card Daemon shows up. What is that? Research shows it’s a daemon for hardware smart keys that we can probably do without(?). It can be disabled in the /etc/rc.bootup file like so: 1 2 3 4 5 /* pcscd daemon must be started before IPsec */ echo \"SKIPPING PC/SC Smart Card Services...\"; # echo \"Starting PC/SC Smart Card Services...\"; # mwexec_bg(\"/usr/local/sbin/pcscd\"); # echo \"done.\\n\"; Wait. After some time went by, I noticed the router slowed down, fatally. IPsec without the SD Card Service will cripple the router Warning: Do NOT try to disable the Smart Card Service as it is needed by IPsec; if you start experimenting with an IPsec VPN tunnel and the pcscd daemon is disabled, then your hard disk will fill up with logs and your CPU will run hot. Top ↩ Adblocking with pfBlockerNG This unboxing and setup has been fun, but I’d like to block all the bad traffic on my network. I’ve been using a workhorse of a DNS-level adblocker called Pi-Hole on a… yes, Pi, but it would be nice if I can reclaim that wee bit of hardware for something else and use a comparable add-on module in pfSense. Let’s explore that now. pfBlockerNG is a very powerful package for pfSense® which provides advertisement and malicious content blocking along with geo-blocking capabilities. Question: Do I install the first pfBlockerNG or the pfBlockerNG-devel which feels like a developer version? I’m a software developer, so this is for me, but am I a pfSense developer? No. Maybe it will show me advanced logs or I can mess about with LUA? Let’s Google this. From here, random people are saying to install the development version. Another blogger advocates using the dev version as well. Meh, I guess we can install jq, rsync, and Python 3.8. This doesn’t feel like a development version since it has exciting dependencies. Install pfBlockerNG-devel not the other one That was painless and only added an extra 20 MiB. It seems a lot of the dependencies are part of pfSense already. The knight at the end of Raiders would say that I have chosen wisely (hey, why did Indy age like a normal person up to Indy 4 if he drank the immortality water that the thousand-year-old knight also drank?). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 New packages to be INSTALLED: gmp: 6.2.1 [pfSense] grepcidr: 2.0 [pfSense] iprange: 1.0.4 [pfSense] jq: 1.6 [pfSense] libmaxminddb: 1.6.0 [pfSense] lighttpd: 1.4.59 [pfSense] lua52: 5.2.4 [pfSense] nettle: 3.7.2_2 [pfSense] pfSense-pkg-pfBlockerNG-devel: 3.1.0 [pfSense] py38-maxminddb: 2.0.3 [pfSense] py38-sqlite3: 3.8.10_7 [pfSense] rsync: 3.2.3_1 [pfSense] whois: 5.5.7 [pfSense] xxhash: 0.8.0 [pfSense] zstd: 1.5.0 [pfSense] Wizard time. The pfBlockerNG wizard had four steps but step three is like 50 steps in one There are a lot of options in step three. This is not like Pi-hole at all. I’m going to come back to this and set up my network instead so I accomplish retiring my Nighthawk R700 or giving it new life as a Wi-Fi AP. Fix: If the pfb_dnsbl service won’t start or the status tab states [ Missing CRON task ], try deleting the empty file /var/run/booting (ref). Top ↩ Isolate LANs for Security An opportunity has presented itself: I can create real networks on each of the three router Gigabit ports (not VLANs), and should I do so? Yes, yes I should. I would like a dedicated hardware network for all my home-phoning spy devices (Alexas and Apple TV) so they don’t flood my network with metrics info and “sure I’m muted and not listening to you” audio payloads back to their HQs. I can see it now: A Wi-Fi AP on a hardware LAN that is isolated from everything else and dedicated to these gadgets, and runs through the adblocker and traps hard-coded DNS queries to 1.1.1.1 and 9.9.9.9 and others (I’ll have to explore this) so YouTube on my TV doesn’t sneakily bypass Pi-Hole any DNS-level blocker. It’s so Utopian an outcome I may not be able to sleep. I’ve decided that my bottom-shelf TP-Link wireless router that is so old that AC1200 might as well be “A.D. 1200” is going to be my Wi-Fi AP for those IoT spy devices. In sum, there will be a dedicated hardware LAN with a wireless AP (AC1200) for Amazon/Apple gadgets and the TV. with a wired switch for all the beefy computers and clusters in my lab. with another wireless AP (R7000) just for iPhones and watches. As an aside, since doing an Offensive Security hacking course in my spare time, and I rare-earth-magnet-strongly suggest isolating Wi-Fi devices from any critical LAN segments connected to devices that touch daily banking or stock trading (or crypto wallets). Top ↩ Class B IPv4 172.31.1.0/24 Network for Untrusted Devices The class B IPv4 range 172.16/16 is a valid range of private IP addresses. I’m not uncomfortable with Alexa and Apple TV being even on the same class network as my main LAN segment, so I will banish them to the class B private network at the hardware level, and my more trusted LANs will be on the traditional class C network (192.168/16). This helps mitigate any misconfigured iptables rules by naturally having no routes between the two networks. Set up a physical network for the untrusted smart devices Be sure to enable the DHCP resolver on the physical NIC that will connect smart devices (which mainly just tell me the weather and creepily listen to me sleep). From this point, DHCP works on this new network, but by default, it assigns IP addresses but does no routing. All traffic is blocked by default. Top ↩ Add Firewall Rules We need to manually add rules so traffic on the physical NICs goe somewhere. Our first rule to allow eth3 to access the Internet There is a logging message. Let me reproduce it below. Hint: the firewall has limited local log space. Don’t turn on logging for everything. I read that to mean, “Congratulations on not cheaping out on your SSD. Now go forth and log everything, my son.” I’m not a new-age, fancy-jazz, coloured-light- or smart-plug-controlling guy who forgot how to turn on a light without his phone, so I do not need to have smart devices on the same network as my phone (why create dozens of wireless attack vectors into your home?). I’m classicly trained to actuate an electromechanical current interrupter on the wall and light let there be. Top ↩ Setup the Untrusted Wi-Fi AP How do I reach the admin UI of AC1200 Wi-Fi AP now? I factory reset it, plugged the WAN NIC into the ETH3 NIC of the pfSense router, but both devices are just blinking at me. I suppose I can just Wi-Fi into the factory-reset AC1200. Yikes, 2016 was a bad year for responsive web UIs I take it. This is horrible; I’ll pull out a netbook for this. One sec. It seems the Archer C5 has no AP Mode. This is my problem, not yours, but I’m still going to vent. Oh, and the “refresh” icon on the top of the DCHP Leases page in pfSense is not “refresh”, but “reload service”. Whoops. Well, I bricked the AC1200 router. I will have to run an Ethernet cable manually… but, wait, my thin notebook has no Ethernet ports and needs a USB-NIC adapter. Happy Friday. Tip: Connect LAN to LAN, not the AP’s WAN to pfSense’s LAN unless you want to do double NATing. There were shenanigans, but I set the LAN IP of the AC1200 to 172.31.1.100, the ETH3 NIC IP of the pfSense router to 172.31.1.1/24, and set the pfSense DHCP service on ETH3 to assign addresses 172.31.1.101~150. What failed was setting the AC1200 to 172.31.1.2 as it was unreachable (reason unknown). Oh yes, I had to turn off firewally things and NAT Boost, and basically drop the horsepower of this TP-Link router down to that of a potato battery. The above settings allow me to access the AC1200 remotely now. The other video ran its course, so I started following this YouTube video (set the speed to 1.5x). There are some good tutorials on advanced pfSense… if you can sit through the ads One more thing: I installed the nmap package for pfSense and scanned the AC1200 router, and found some sneaky ports open. 1 2 3 4 5 6 7 8 9 Running: /usr/local/bin/nmap -sT -P0 -e igb1 '172.31.1.100' Starting Nmap 7.91 ( https://nmap.org ) at 2021-11-15 17:40 PST Nmap scan report for 172.31.1.100 Host is up (0.0017s latency). Not shown: 969 closed ports, 28 filtered ports PORT STATE SERVICE 22/tcp open ssh 80/tcp open http 20005/tcp open btx Port 20005/tcp is a print server port that I’ve now closed. However, the Archer C5 AC1200 is vulnerable to all kinds of Kali mischief so it was wise to put it on its own network. I’m not sure how to close port 22 and the SSHd service on it the AC1200 because the stock firmware is ancient and crippled, so I’ll just have to block port 22 on the whole LAN segment. I’ve also taken care of disallowing private networks to ingress on the WAN (see the next section to set up DMZ). Top ↩ Unable to Reach 172.31.1.x from 192.168.10.x Ping and Traceroute are aiding me in my efforts to connect to the AC1200 Wi-Fi AP from my Trusted LAN. I went ahead and added the subnet to the Symantec Firewall rules just in case (Symantec has its place now and then, but yes, definitely have available PC CPU horsepower to spare). Configure Symantec to allow the Untrusted subnet Now, it seems ICMP packets are no longer blocked between networks, but I still cannot ping the AP web management UI even though I can see the pings in the traffic logs. I’ve even added an “any to any” firewall rule on the Untrusted network. No change. Warning: If you run nmap as I did, software firewalls may detect a port scan and kick your network connection for an hour by default. Let’s try a stealth scan instead: sudo nmap -sS -v 172.31.1.*. I think a port scan has still been detected Nope, pfSense doesn’t like that at all. And, the whole network stopped working. Nice security! Also, dang. The good news is that I’ve isolated the packet malaise to the TP-Link AC1200 box itself. I suspect that I need to add net.ipv4.ip_forward=1 to forward packets with no addresses in them, but I’d need root access to the AC1200. Let’s burn it to the ground and rebuild from its sprinkler-soaked ashes. Top ↩ Replace Stock Firmware on the AC1200 Wi-Fi Access Point Of course, I cannot actually stop Untrusted LAN devices from reaching the AC1200 as they all exist downstream from the pfSense box. DD-WRT open-source router firmware, meet my ancient Archer C5 and do your thing. DD-WRT supports the Archer C5 The Archer C5 did not accept the DD-WRT firmware. Hmm… how about OpenWRT? OpenWRT supports the Archer C5 The Archer C5 did not accept the OpenWRT firmware either. What the actual facepalm (WTAF)? Wait. My hardware is revision 2 using the Broadcom chipsets which are notoriously difficult networking chips. Careful: Devices with Broadcom Wi-Fi chipsets have limited OpenWrt supportability (due to limited FLOSS driver availability for Broadcom chips). (REF: OpenWRT.org) Alright, so OpenWRT, DD-WRT, and Tomato projects have no firmware for this AC1200 with unpopular Broadcom chipsets. Into the refuse bin it goes. Top ↩ Archer C5 v2 into the Refuse Bin, R7000 as the New Wi-Fi AP I’ve dismantled the AC1200 so I do not forget why I threw it out. It’s too bad because it’s so pretty on the inside, and they always say, “It is what is inside that counts… except if you are a router with Broadcom chips.” Inside the Archer C5 v2 with Broadcom chips The R7000 is factory reset, and here is the first problem: Tip: On factory reset, the Nighthawk R7000 is pretty uptight about the format of the password. One rule is that no more than two identical consecutive characters are allowed. Well, thanks Netgear for pretty much providing a Regex to password crackers. Let’s disable all those rules with a few keystrokes to delete the JavaScript “blocking” the form submission. Now my admin password does not conform to the Regex and is super long. Muhahaha to Netgear password crackers. The R7000 is in AP mode, but I can still access the pfSense web management page from the Untrusted network. Let’s lock down the web UI in pfSense under Firewall Rules. Untrusted network firewall rules Top ↩ Set up the Trusted Wireless Network The Untrusted network is now looking good. It’s time to make the other R7000 Nighthawk I have into a Wi-Fi AP as well so my phone and watch have a safe place to connect to, as well as a laptop when I want to RDP into my wired machines from the kitchen. I was saving that for a honeypot AP, but I can come back to that later. Let’s see if I can Wi-Fi into the Wireless LAN’s R7000… Tip: Remember to physically unplug the pfSense upstream router from the R7000 because the R7000 is too helpful and will enter into AP mode by sensing any upstream routers, then you cannot get into the web UI anymore. Since only my trusted devices should be on the Wireless LAN, I’ll turn off 2.4 GHz wi-fi because anything recent and wireless should support 5 GHz. That means those pesky AliExpress Pineapple wi-fi password stealers on the cheap side only use 2.4 GHz, so a neighbour is going to have to put in some effort to snoop on my network. Plus, 5 GHz is blocked more easily by walls and concrete, so I prefer it for averting medium-range snooping. But, I so am going to set up a honeypot and to brake check my faith in humanity. It is normally straightforward to put a Wi-Fi router into AP mode by disabling WAN and DHCP. Top ↩ Network Devices Interconnectivity Check Do all my dozens of computers, laptops, Pis, clusters, NAS drives, and the like still connect as before? Most important is my web-scraping bot in a hardened, RAIDed, dedicated machine with its own UPS. But alas, I cannot SSH into it even though the SSH handshake packets make it to the hefty box. Could this be our old frienemy IPv4 forwarding being disabled? Possibly. I’m able to SSH into the machine from my iPhone (seriously) when on the same network. Nope. Adding net.ipv4.ip_forward = 1 in the right place with a restart did not yield joy. According to dmesg -w (to tail dmesg logs), UFW (Uncomplicated Firewall) is not blocking ICMP requests or TCP requests on port 22. When I do something nutty like try to SSH on, say, port 23, then I can see the UFW block logs in dmesg. Confirmed: Packets can reach that machine. Running tcpdump src 192.168.10.100 where the IP is from the Trusted network on the target machine shows it is responding to pings. I’m even getting replies to SSH handshake requests. So now we know that return packets are being dropped. Interesting! Aside: tcpdump is awesome. Let’s follow the trail. Digging a little deeper I see replies to ICMP and SSH handshakes are being sent to some IP over HTTPS that I do not recognize. Bizzare. When I run the usual ipinfo tools I see that replies are going over a VPN that I completely forgot about. Ha. Replies to a different subnet are egressing over the VPN, but cannot return properly. Neat. VPN causes ACK packets to return over the wrong adapter Now that I remember what I did in 2019, I re-added NAT alias rules, and it’s showtime again. Top ↩ Windows File Sharing Gotchas Your path may be smoother, but I’ve always seem to make the Trench Run instead of remote-piloting a handful of lead-filled X-Wings at light speed right through the Death Star’s reactor to make it go boom: the easy way. I’ve added some rules to allow Static DHCP devices to talk to each other – Windows devices – but by default, the Private Network in the Windows Defender uses the local subnet as the rule scope. That means different subnets are isolated. We can’t just relax the pfSense DHCP subnet mask to say 192.168.20.0/16 because it conflicts with another subnet. Instead, just to get file sharing working, I relax the scope in Advanced Settings like below. Be sure to modify In and Out for SMB and ICMP. Windows file sharing across subnets Again, please add whatever subnets you desire instead of any. Top ↩ Public Service Announcement: Edge Browser Why does the Microsoft Edge browser start automatically and run in the background, and why can’t I kill it when I ctrl+alt+del? If you’ve asked yourself this, you’re not alone. It turns out Edge starts up when you log in and it keeps running in the background. Here is the fix: Prevent Microsoft Edge from starting or running in the background. Sneaky browser. I suggest downloading Winaero Tweaker and applying registry tweaks to cut down on the Redmond Spy Machine. Stop Microsoft from spying on you Top ↩ Block Clickbait, Endless Ads, and Dangerous Sites Thanks to web-browser and DNS-level adblockers (i.e. Pi-hole), it’s commonplace to block bad sites, crypto-miners, fingerprinters, trackers, remarketers, banners, pop-ups, fake tech-support scam alerts, and all manner of unscrupulousness designed to take advantage of you. Let’s take pfBlockerNG on pfSense for spin. pfBlockerNG blocking ad domains with graphs The pie chart looks great. I followed this pfBlockerNG tutorial. Tekgru.com pfBlockerNG tutorial blog This is mportant: If you have multiple network interfaces (the mini PC has four), then you need to enable the Permit Firewall Rules for multiple interfaces and select them. DNSBL Perfmit Firewall Rules for multiple interfaces Would you like to have discretion over blocklists? Let’s add a DNS blocklist related to gambling and reload pfBlockerNG to see if a poker site is blocked on the Trusted LAN. Some sketchy poker sites are now blocked If you would prefer the connection to just close instead of rendering a PHP page, create a new PHP script with the following code and select it in the pfBlockerNG settings page: 1 2 3 4DNS Resolver page, click “Display Custom Options”, and add the lines: 1 2 server: log-queries: yes Well, hello there, Microsoft Windows. What are you up to trying to reach Google Tag Manager? Naughty OS. That request is now black-holed to a non-existent IP at 10.10.10.1. Windows is trying to reach Google Tag Manager Let’s turn our attention to the TV and see how it fares under DNS interception. Top ↩ How to Restrict Apple TV and iPhone YouTube Ads? YouTube: Regarding YouTube, YouTube has been showing 7-second and 15-second ads, twice, back-to-back, nearly every few minutes. Why are the ads incessant and so long? I do not mind the occasional ad, similar to live TV, but these frequent ads would warrant FTC complaints it they were on live TV. YouTube is tricky because ads are also videos that come from the same domain, so domain-name blockers like pfBlockerNG cannot act on them. The best pfBlockerNG and Pi-hole can do is block googleadservices.com only after you watch an ad video and click on the ad. Many people opt to use a web browser like Firefox or Chrome with uBlock Origin that acts on JavaScript as a workaround. It might be enough to watch YouTube on a web browser and stream that to a smart TV. However, we cannot restrict ads on the iPhone (without jailbreaking and compromising it). What are our options? How can we safely restrict YouTube ads on all network devices? Top ↩ Trick the YouTube Ad Algorithm Instead Thought Experiment: Among friends, let’s say that English-speaking countries get ads for the most ridiculous things because their residents are assumed to have disposable income. Can we instead make YouTube think we are an undesirable advertising target? What do ads in other parts of the world look like? Are those living in Antarctica or Low Earth Orbit getting a lot of ads too? Xkcd.com: Mess with advertisers What would happen if we leverage the capabilities of this pfSense router to route YouTube Location Tracking information through a VPN that terminates in some remote part of the world with fewer YouTube viewers per capita? In other words, let’s make ourselves undesirable to advertisers and see if we get fewer ads. Scotty from TNG episode ‘Relics’ understands the plan Top ↩ Research into YouTube Advertizing Spend Let’s do some YouTube demographics research to find a part of the world avoided by advertisers. Mobile advertiser spend by country in 2020 Let’s also check some YouTube statistics about viewers by country for insights. Thinking about following some Reddit advice and VPN’ing into India? Think again. Total YouTube views by country in 2019 (REF: ChannelMeter) That was 2019. This is 2020: Top ten YouTube countries with population (REF: backlinko.com) I’m not a digital advertiser, but I can see that people in the UK and Canada watch a large number of videos per sitting. If I were an advertiser though, I’d pump those two countries with video ad after video ad because, statistically, those residents will take the eyeball kicking. All things being equal, I definitely need a VPN to terminate outside of Canada, the UK, and the United States (English-speaking countries) to enjoy YouTube more. Does age play a factor? Who don’t advertisers want? I want to be that guy on paper. YouTube age demographics as of 2020 (REF: backlinko.com) Top ↩ New Goal: Let’s trick YouTube into believing I am a 70-year-old male living in Italy. Yes, that should definitely cut down on the Nespresso and Starbucks ads, at least. How then to convince YouTube that I am a retired Sicilian living on a small chain island? I embellished that last part. Seventy and in Italy is sufficient. Let’s do this. In the YouTube account… I am Iron Man 71 years old I am in Italy It is doubtful that this is all it takes for our goal. Let’s find a VPN exit point in Italy. NordVPN has 60+ servers in Italy Nice. NordVPN has about 60 servers in Italy (that’s an affiliate link by the way). Top ↩ Selectively Route Apple TV Over the VPN Let’s go through some tutorials to set up OpenVPN in pfSense. Just kidding! We’re going to use WireGuard – we have the Intel AES-NI crypto instruction set because we didn’t go cheap and get a yesteryear J1900 mini PC that sellers are trying to offload. I’ll now install the FreeBSD WireGuard package. Install the WireGuard package in pfSense Next, add a tunnel and enable it. According to this thread and this thread on Reddit, we need to get some information for WireGuard and NordLynx from a sacrificial Linux VM to transpose the settings (i.e. private key) to the pfSense router. No problem. Connect to Italy over WireGuard WireGuard config information via wg show Run sudo wg showconf nordlynx to see your private key needed by the pfSense tunnel config. Here are various screenshots that show the steps in more detail. VPN > WireGuard > Tunnels VPN > WireGuard > Peers Tip: Enter 1.0.0.0 and then 0 as the subnet mask. Do not go for 0.0.0.0 as there is a glitch or bug in the UI or whathaveyou. The result will still be 0.0.0.0/0. VPN > WireGuard > Settings Interfaces > Interface Assignments That should be enough to allow Diagnostics to curl Italy. Successfully connected to NordVPN through WireGuard on pfSense Successfully connect to Italy and verified Now that the easy part is out of the way, let’s set some Policy rules to send the Apple TV traffic over the VPN to Italy as a baseline test. From Netgate, on the order of Firewall/NAT processing: Traffic from LAN to WAN is processed as described in the following more detailed example. Port forwards or 1:1 NAT on the LAN interface (e.g. proxy or DNS redirects) Firewall rules for the LAN interface: Floating rules inbound on LAN Rules for interface groups including the LAN interface LAN tab rules 1:1 NAT or Outbound NAT rules on WAN Floating rules that match outbound on WAN I’ll make an alias, for now, to hold some clients that have static DHCP entries and hostnames I gave them in pfSense. VPN clients in the Firewall > Aliases > IP page Floating rules in have high precedence, so I’ll add some rules below the automatic pfBlockerNG rules that were created, and I’ll add a nice little blue separator while I’m here. Floating rule to route select clients over the VPN to Italy And here is that rule as a very long screenshot: Firewall > Rules > Floating rule to route select clients over the VPN Apply. Wait. Let’s try it out using one of my notebooks connected to the Untrusted network. Google is entirely in Italian now Google is in Italian. Very cool. Now for the Apple TV. Apple TV’s YouTube reports I am in Italy Winner winner, chicken diner. All my YouTube is in Italian. I get some ads, not as many, but because Italians speak slowly and with a kind of sexy accent I do not mind the ads for Nutella at all. With this technique, I no longer feel manipulated by non-English ads. I have personalized ads off, but given my new status as a retired gentleman I should turn that back on to scare away advertising dollars, er, euros. I wonder if Netflix and Amazon Prime behave any differently… Some Netflix assets are being blocked Dang. Netflix is having problems. Amazon Prime is even worse. It looks like some CSS or font files are blocked as well, and the thumbnails aren’t loading. It’s time to move to Phase Two: Tunnel only YouTube traffic over the VPN. Warning: Do not try to send all the Apple TV traffic over a VPN because Netflix, Prime, and others are wise to VPN providers and have gotten great at geofencing. Top ↩ Selectively Route Apple TV YouTube Traffic Over the VPN Let’s start by adding Firewall Policy rules to send the most common YouTube domains over the VPN. As I’m about to add the rules, my hands hover over the keyboard not knowing what domains to tunnel. They need to be FQDN (fully-qualified domain names, no wildcards). Let’s open up a Chromium-based browser and see what traffic it generates in DevTools. Add the domains column to DevTools to see where YouTube calls Here are some candidate FQDNs to add: 1 2 3 4 5 6 www.youtube.com youtube.com googlevideo.com accounts.google.com googleapis.com gstatic.com But wait, I hear you ask, why accounts.google.com and gstatic.com? This is a preventative measure just in case one of those domains is geo-jacked (Geo-IP LowJacking). I wouldn’t put it past Google engineers to geo-jack the fonts domains like fonts.googleapis.com, but I’ll take a chance they don’t in the interest of scaling to billions of page views efficiently. Here are my new rules where I chain two of them using a tag so I can limit YouTube tunnelling to only the same untrusted machines (including Apple TV). YouTube domains to tunnel Use a match rule before the tunnel rule The first rule matches VPN clients and tags them The second rule tunnels tagged requests through the VPN And with that, YouTube thinks I’m in Milan, Netflix and Prime Video think I am still in Canada, and the ads… oh the ads… they are few and far between, and when they do come on, they are just a treat to listen to in that slow, lack-of-harsh-aspirants-or-yelling of a beautiful language Italian is. YouTube, Italy Top ↩ Time goes by… Gotcha: DNS Race Condition A day has gone by and I’ve noticed that I only get Nutella and Ferrero Roche ads in the middle of videos, not at the start. Odd. I did some research and this is what I found: Pertinent information about pfSense and hostname aliases This means that the hostnames are resolved to IP addresses once and those IPs are used in my VPN tunnelling policy rules. A hostname entry in a host or network type alias is periodically resolved and updated by the firewall every few minutes. The default interval is 300 seconds (5 minutes), and can be changed by adjusting the value of Aliases Hostnames Resolve Interval on System > Advanced, Firewall & NAT tab. – pfSense Ah-ha, so I suspect there is a DNS race condition. Let me explain: This happens if, say, the Alias Daemon updates the IPs of the FQDNs. Then, I turn on the Apple TV for the first time all day. Since the usual TTL (time-to-live) of DNS queries is 1440 seconds (30 minutes), all the YouTube DNS entries will be cache misses and will need to be updated. At this point, the IPs from the second DNS queries may be from a pool and are not guaranteed to be the same that the Alias Daemon has. When the Alias Daemon checks again in five minutes, it may resolve the FQDNs to yet different IPs! Let’s solve this by overwriting whatever TTL (time-to-live) YouTube has in its DNS entries: Do not abide by the minimum TTL of the target DNS entry And with that, no more DNS lookup race condition. Top ↩ Gotcha: Authentication Trouble, Forbidden 403 Error Sometimes videos will not play. For security, YouTube embeds your IP in the googlevideo.com request. I’ve known about this since my post about Download YouTube 4K Videos with PHP back in 2016. The new problem is that various JavaScript and “are you human?” assets are tunnelled over VPN, but those darn domains like r5---sn-hpa7kn76.googlevideo.com are not tunnelled and thus come from the wrong IP. Queue the 403 Forbidden error. YouTube authentication failure Let’s fail fast with a quick experiment: I’ve gotten the IP of the above second-level domain name (SLD), added it manually to the list of domains/IPs to VPN tunnel, applied the change, and refreshed YouTube: Success. We need to route the mangled domains over the VPN as well. Excellent. Now, we just need a way to tunnel that wildcard *.googlevideo.com domain. Unfortunately, the NAT and Firewall rules work with IPs, not wildcard domain names. Can we predict or enumerate these domains? Here is a Wireshark capture of DNS requests to *.googlevideo.com to show that the SLDs (second-level domains) are not eyeballably predictable: Random SLDs from googlevideo.com Let’s drop into a web browser with adblocking disabled and walk the HAR waterfall of my interaction with YouTube that led to ads showing up. Waterfall showing ad interactions coming from www.youtube.com What are GET requests like GET https://r7---sn-uxa0n-t8ge.googlevideo.com/generate_204 doing, exactly? I’ll give this problem some thought offline. Top ↩ Gotcha: YouTube is Now Showing UK Ads, Not Italian Ads Before I could even solve the previous gotcha, British ads started showing up with the same frequency as if we did nothing. Ads from the UK are even more incessant than those from Canada, trailing behind the USA and India according to my earlier stats. It would be a complete failure if we get UK ads. Why does this happen suddenly? I’ve opened a fresh browser in a VM and tunnelled all traffic through Italy. The only leak I can find is when I query ipinfo.io on my Italian tunnel and see a UK address in the ASN. Could this small leak be our undoing? It is possible the VPN is leaking unintended information Even with my browser’s language set to en_US and location data off, this is the only leak I can spot. Then, in addition to a VPN exiting in Italy, it has to be one that doesn’t leak ASN (Autonomous System Numbers – used for automated routing) that gives up a different country. Dang, Google, you’re good. I’m going to have to bring my A+ game to this one. Top ↩ Find a VPN Exit Node with no ASN Leak By visiting https://nordvpn.com/servers/tools/, I can see the VPN endpoint nodes in Italy. There are many Wireguard endpoints with NordVPN. Just to move things forward for this exercise, I’ll add an OpenVPN tunnel in pfSense and connect to several VPN nodes and examine the ASNs. It’s better than nothing, and more importantly, I’d like to eliminate the ASN as the leak of GeoIP information. Here is the guide I used. Through trial and error, I found a VPN node that is registered to an ISP in Italy as found in the Abuse and ASN info. Found an exit node with no ASN leaks Beautiful. Bellissimo. Italian content with Italian ads again Top ↩ Hijack Google Video DNS Queries To make any of this work, I need a technique to route the wildcard *.googlevideos.com domain through the VPN. Thought Experiment: Suppose I write a plugin for pfSense that periodically greps the DNS query log, keeps track of the *.googlevideo.com queries, and adds them to a unique list of aliases for Google Video domains; if backed by an LRU eviction policy, this could keep working indefinitely. However, if each video uses a unique, mangled domain, then this does not work unless I hit refresh on every single video. On the other hand, if I “hold up” the DNS query for the *.googlevideo.com domains, add the IPs to some alias list, then allow the DNS response to finish the round trip, we may be in business! pfSense DNS resolver has user Python support Where to even start? Here are some Python example scripts just to get some inspiration. A quick, mental reverse-engineering of a handful of scripts reveals that there are some event hooks available. Nice. Among friends, let’s say that I can build up the pool of Google video IPs in real-time. How then to add these IPs programmatically to the firewall alias list for YouTube without restarting the firewall? One person actually hacked the PHP scripts in pfSense. Tempting, but I’ll do more research. Another person created a REST API for pfSense. Jackpot! Top ↩ New Goal: We need to add IPs to the firewall policy rule to route YouTube videos over a VPN to avoid incessant and obnoxious North-American ads, but the IPs keep changing due to changing, mangled second-level domain names (SLDs). Using Python 3 and a REST API, we will monitor the appropriate DNS queries, note the IP(s) of the response, hold the response, add the IP(s) to the VPN tunnelling policy rule, then release the DNS query response. Research Python Methods to Hijack DNS Requests Why this approach? It’s future-proof, modular, elegant, maintainable, automated, and it lends itself to a future decision tree that could truly restrict YouTube ads outright. First, I will enable SSHd in pfSense and take a peek around. Enable SSHd in pfSense SSH into pfSense using the GUI credentials Rsync Disk Backup Let’s take this opportunity to make a disk backup. du -h or “duh” shows that only 800 MiB is in use on the SSD. Let’s rsync the whole box from our local machine in about four minutes. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Rsync the pfSense router locally, then compress to an archive. # Tell the remote rsync to preserve ownership information. # Fix brace expansion and execute (easy to read with tr and sed). cat = (12 * ALIAS_VPN_WILDCARDS_CAPACITY) - 2: log_info(\"Capacity reached. Starting eviction...\") evict_wildcard_ips() def get_wildcard_patterns(): patterns = set() res = request(API_ALIAS_URL, \"GET\", {\"name\": ALIAS_VPN_DOMAINS}) data: dict = res[\"data\"] if data: alias = data.popitem()[1] details = str(alias[\"detail\"]).split(\"||\") for detail in details: if \"*.\" in detail or \".*\" in detail: patterns.add(detail.replace(\"*.\", \".\").replace(\".*\", \".\")) # TODO: Make robust addresses = str(alias[\"address\"]).split(\" \") for address in addresses: patterns.add(address) log_info(f\"Found wildcard patterns: {patterns}\") return patterns if TEST_MODE: if __name__ == \"__main__\": log_info(\"Init start\") recreate_vpn_wildcards() add_wildcard_ips(\"1.2.3.4\") add_wildcard_ips([\"1.2.3.4\", \"1.2.3.5\"]) evict_wildcard_ips() get_wildcard_patterns() When I woke up, the Unbound DNS resolver service segfaulted. Here are the logs: We can see a full FQDN alias re-process on each firewall config update Failure: Capturing all the IPs from the DNS queries to *.googlevideo.com and *.google.com puts pfSense into a crawl as all the rules need to be reloaded on each addition. Top ↩ New Goal: Research and install a Squid-like proxy, create a fake-but-trusted CA certificate, host it, install it in a browser as a PoC, decode TLS traffic, and victory dance. Actually, it is not illegal to jailbreak most Apple TV boxes, so we could break in, add a root certificate valid for the pfSense box, MITM traffic from the Apple TV, and then Microsoft Bob is your uncle. That works because the pfSense box as the gateway can decrypt Apple TV traffic, inspect the request headers for the offending ad hostname, block the request, and re-encrypt other valid requests to Mountainview, California. But, then my iPhone would still show ads because it is harder to jailbreak, plus banking apps may detect this and not work anymore. Jailbreaking is too extreme, anyway. Fun fact: I used a jailbroken iPhone all the time in Japan because of a quirky cellphone law. You see, because of icky perverts who like to take photos inappropriately on elevators and escalators, Japan passed a law that made the camera shutter sound mandatory on all photos. Super unfortunate was that taking a screenshot of a web page also made the same loud, unmuteable shutter sound. Imagine you are on a train and you screenshot a Google map, it makes that loud shutter noise, and then you get dirty looks from the train riders. Yeah, I had to jailbreak and zero out the camera sound file. Let’s see what it takes to spy on the HTTPS traffic from the Apple TV and iPhone to see if we can block ad URLs that way. Top ↩ Install a Fake-but-Trusted CA Cert on Apple TV and iPhone? Not wanting to jailbreak and add self-signed certs to Apple TV and iPhone, how hard would it be instead to add fake-but-trusted Certificate Authority (CA) certificates to each device? The ‘A’ in CA means there is no one higher to vet such a certificate. The ‘A’ is so powerful, that back in 2001 only a Windows patch was able to revoke some dangerous Verisign certificates. As a thought experiment, new CAs must come into existence from time to time. Let’s Encrypt is relatively new, for example. There should then be an in-warranty way to get a fake, trusted CA cert into an Apple TV and iPhone. If that is possible, then an entire world of MITM spycraft is available to decrypt TLS packets in the clear and use good ‘ol URL blocking on requests like 1 2 https://www.youtube.com/pagead/viewthroughconversion/... https://www.youtube.com/pagead/conversion/... Let’s see how easy this would be. We can add fake, trusted CA certs to iPhone too In fact, there are many, many CAs. Here is a quick find / -name \"*.pem\" in pfSense: Many CAs exist already Top ↩ Experiment with Squid and SquidGuard I’m aware of mitmproxy, but it needs to be side-channel installed onto the pfSense router. Let’s see if the squid3 proxy that is available as a pfSense package can do what we need. First, I will take a bare-metal backup again so I can roll back in case mitmproxy is better. Install squid3 and ancillary packages I’ve installed those packages, and naturally, there are more buttons and options than in a space shuttle. I’ll find a guide. I’ve followed the steps in the guide, however, since I have a large SSD and generous RAM, I’ve made a dedicated folder /squid_cache (and chown squid:proxy) with 8 GiB of cache and a juicy allowance on the per-item cache size which should also help with Docker and NPM speed-up. Two birds, one stone. With Transparent HTTPS support, this should be pretty rad. Tip: If web traffic slows down while using Squid, here are some System Tunables that can make Squid faster (ref): vfs.read_max 128 kern.ipc.nmbclusters 32768 Also, for local disk cache, aufs is asynchronous ufs (great for Docker too) and uses POSIX-threads to avoid blocking the main Squid process on disk-I/O. We can actually generate a CA cert in pfSense itself. Generate a CA in pfSense Now, how to get it into the Apple TV and iPhone? It should be hosted somewhere, right? How about on the router? Top ↩ Self-Host the MITM CA Certificate Self-hosting with a single command is ridiculously easy. From the SSH shell into pfSense, I can create a web folder and server like so: 1 2 3 4 5 mkdir /www chown -R squid:proxy /www chmod -R 644 /www echo \"Hello\" > /www/index.php php -S 0.0.0.0:8000 -t /www When I visit //pfsense:8000 I should get a blank page with “Hello”. From here, clients behind the pfSense router can temporarily access static documents. To make like easier, here is a PHP script to cause the MITM cert to download. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16not found (0) libz.so.1 => not found (0) libpthread.so.0 => not found (0) libc.so.6 => not found (0) root@mitmproxy:~/mitm-7.0.4 # Apparently, there is a pkg install compat6x that can solve this for us (unavailable on pfSense), however, this is getting ridiculous! Let’s try a new tactic. Since we are in a jail, we are not bound to the crippled (read: secured) pfSense environment. Maybe we can install the mitmproxy package normally in a jail? pkg install mitmproxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... py38-urwid: 2.1.2 py38-werkzeug: 2.0.1 py38-wsproto: 1.0.0 py38-zstandard: 0.15.2 python38: 3.8.12 readline: 8.1.1 sqlite3: 3.35.5_3,1 zstd: 1.5.0 Number of packages to be installed: 50 The process will require 206 MiB more space. 33 MiB to be downloaded. Proceed with this action? [y/N]: And, Bingo was his name-o. After this, simply running mitmproxy in the jailed console opens the MITMProxy UI. Nice. Note, this version may be one or two minor versions behind the master branch. Let’s clean up with rm -rf ~/mitm* /lib64 and do another bare-metal backup. Top ↩ Exploring MITMProxy This is getting exciting. First, in pfSense, add a virtual IP for 127.0.1.1 attached to localhost. Then, add a NAT rule to temporarily forward port [Private IPs]:8080 to 127.0.1.1:8080 to access the proxy from the LANs. If not in the jail console, I’ll run 1 2 ezjail-admin console mitmproxy mitmproxy --listen-port 8080 --set console_focus_follow=true and add the proxy setting 192.168.20.1:8080 to my sacrificial notebook (that is auto-wiped daily). When the browser opens, we can already see colourful log entries in the MITMProxy UI. First logs of MITMProxy The next step is to get the auto-generated CA PEM file used by MITMProxy (~/.mitmproxy/mitmproxy-ca-cert.pem). Since any CA cert here is snake oil, I’ll use the provided one. TLS traffic from my devices is safe as long as I use my own proxies. Let’s put our experience from our previous attempt at self-hosting a CA into action. However, there is no PHP in the jail, so we can use a Python 3 web server instead. 1 2 3 4 5 6 set PYTHON='/usr/local/bin/python3.8' mkdir ~/www # Both Python and mitmproxy run as 'root' chmod 444 ~/.mitmproxy/mitmproxy-ca-cert.pem ln -s ~/.mitmproxy/mitmproxy-ca-cert.pem ~/www/cert.pem $PYTHON -m http.server --bind 127.0.1.1 --directory ~/www 8001 Tip: MITMProxy conveniently has onboarding settings to serve the same CA cert, as we did manually, just by visiting mitm.it. After installing the CA in the Trusted Root Store on my clean notebook (and rebooting), I am treated to this display: MITM TLS interception is working well Let’s see if we can get this cert on my iPhone. Successfully added a root CA to the iPhone This is incredibly exciting. Can we LoJack the Apple TV box next? Successfully installed a root CA on the Apple TV Excellent. But wait, the router is slowing down. mitmproxy is burning up the CPU… on idle. MITMProxy is burning up the CPU while on idle Of course: Python is a single-threaded paradigm with the GIL (Global Interpreter Lock) ensuring threads do not actually run concurrently – unless they are blocking on I/O, which is the case here(?). Except, most of the CPU work is to generate TLS certs on the fly for each request. Yikes. Running mitmdump forgoes the UI and extreme logging. The extreme logging of all the headers and full responses heavily slows down mitmproxy, but mitmdump by default only logs entries like classic Apache logs – much kinder on the CPU. Certificate Pinning Some advanced, high-security web servers have trouble with the MITMProxy certificates due to Certificate Pinning – this is a technique where the server or the client know the fingerprint of the expected certificate in advance so it cannot be forged. A workaround is to use the --ignore-hosts option to let them bypass the proxy. For my fun, I’ll go with this CLI command: 1 2 3 4 5 6 7 8 9 10 # Try to avoid compression to save CPU usage # Ignore some difficult sites mitmproxy \\ --listen-port 8080 \\ --listen-host 127.0.1.1 \\ --anticomp \\ --mode regular \\ --ignore-hosts '^(?:.+\\.)?apple\\.com:443$' \\ --ignore-hosts '^(?:.+\\.)?icloud\\.com:443$' \\ --set console_focus_follow=true While on YouTube, we can see the page ads clear as day with their unencrypted headers; can a simple regex now block them? They are exposed, and afraid, and their days have run out. MITMProxy can see the YouTube ad URLs We can even see details about each request. For example, all the SAN info is laid out for this wide-reaching certificate. There are curiously a lot of *-cn.com domains covered by this cert. We can see rich request and response details 1 2 3 4 5 6 7 8 9 10 # Try to avoid compression to save CPU usage # Use a script to block YouTube ads mitmdump \\ --listen-port 8080 \\ --listen-host 127.0.1.1 \\ --anticomp \\ --mode regular \\ --ignore-hosts '^(.+\\.)?apple\\.com(:443)?$' \\ --ignore-hosts '^(.+\\.)?icloud\\.com(:443)?$' \\ --scripts \"youtube.py\" # UTF-8 =================================================================== diff --git a/usr/local/lib/python3.8/site-packages/mitmproxy/addons/next_layer.py b/usr/local/lib/python3.8/site-packages/mitmproxy/addons/next_layer.py --- a/usr/local/lib/python3.8/site-packages/mitmproxy/addons/next_layer.py (date 1641187083049) +++ b/usr/local/lib/python3.8/site-packages/mitmproxy/addons/next_layer.py (date 1641187083049) @@ -59,7 +59,7 @@ re.compile(x, re.IGNORECASE) for x in ctx.options.allow_hosts ] - def ignore_connection(self, server_address: Optional[connection.Address], data_client: bytes) -> Optional[bool]: + def ignore_connection(self, server: Optional[connection.Server], data_client: bytes) -> Optional[bool]: \"\"\" Returns: True, if the connection should be ignored. @@ -70,8 +70,11 @@ return False hostnames: List[str] = [] - if server_address is not None: - hostnames.append(server_address[0]) + if server is not None: + if server.address is not None: + hostnames.append(server.address[0]) + if server.sni is not None: + hostnames.append(server.sni) if is_tls_record_magic(data_client): try: ch = parse_client_hello(data_client) @@ -122,7 +125,7 @@ return stack_match(context, layers) # 1. check for --ignore/--allow - ignore = self.ignore_connection(context.server.address, data_client) + ignore = self.ignore_connection(context.server, data_client) if ignore is True: return layers.TCPLayer(context, ignore=True) if ignore is None: With the above patch, I can now reliably intercept a few hosts and let all others pass through. Reliable server host interception in MITMProxy transparent proxy mode Top ↩ Smoke Test: Intercept YouTube Ads with MITMProxy After reading the docs and navigating the mitmproxy source code in the PyCharm IDE, I’ve written a little script to block ads and tracking URLs coming from YouTube from my clean notebook. I won’t reproduce the code just yet because it didn’t succeed in blocking ads as hoped, so instead, I’ll spend the time investigating why. Here are the smoke test filters I used where for a given top-level domain, URLs with the following partial strings are blocked: 1 2 3 4 5 6 blocked_partials: dict = { \"youtube.com\": [\"/pagead/\", \"/log_event?\", \"/stats/ads\", \"/stats/qoe?\", \"/ptracking?\", \"/generate_204\", \"el=adunit\", \"adformat=\", \"/activeview?\"], \"google.com\": [\"/pagead/\"], \"google.ca\": [\"/pagead/\"], \"ggpht.com\": [\".\"], } My initial results on blocking are positive. Everything I wanted to be blocked is faithfully blocked. Note, the (failed) entries are due to my script, and the 502 failures are due to pfBlockerNG black-holing the request. MITMProxy blocking script is working Even in the DevTools network panel, the requests are truly blocked. YouTube requests are truly blocked in DevTools network panel Then how come I am still seeing ads? I’ve disabled HTTP/2 so that subsequent requests on the same channel don’t slide by. Mind you, sometimes the ads skip on their own, or fail to play, but they still show up. Interesting. Could YouTube be using WebSockets? I need some inspiration, so I’ll look at uBlock Origin’s regex filters for some ideas. Tip: If you see the error OpenSSL Error([(‘SSL routines’, ‘ssl3_read_bytes’, ‘tlsv1 alert internal error’)]), then the DNS blocker (i.e. pfBlockerNG) is breaking the upstream TLS handshake for a given domain. Either whitelist it in pfBlockerNG (so the request goes through), or intercept it and block the connection in mitmproxy. This error happens to black-holed domains when the upstream TLS cert cannot be sniffed. The cleanest strategy is to use transparent MITM mode. Top ↩ Examine uBlock Origin Regex Patterns for Inspiration Here are some of the regex/filters that uBlock Origin uses on YouTube. uBlock Origin YouTube regex/filters from a web browser At first blush, it seems that a community of like-minded individuals is playing whack-a-mole with YouTube’s HTML and JavaScript. This has got me thinking: How does a video know to play an ad with JavaScript? How does YouTube know if the ad converts? They must target ads for individuals, so a given video must receive some unique information about an ad, such as the click link and alt text. WebSockets would be a pain to maintain, especially with all the mobile clients. They must be using stateless JSON to relay that pertinent information in an innocuous URL request that has no telltale signs of ad-ness. Let’s hunt for this info in the JSON replies captured by mitmproxy. Key advertizement information contained in a JSON response Snap, Crackle, and Pop. We have a new plan: surgically alter the JSON response body to eliminate or Byzantine-up the ad information. Top ↩ Surgically Alter the JSON Response to Remove Ads After a bit more playful exploration, a trove of blocklorne URLs is right there in the JSON payload. In fact, most of what I am trying to block shows up right here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 ... \"playerAds\": [ { \"playerLegacyDesktopWatchAdsRenderer\": { \"playerAdParams\": { \"showContentThumbnail\": true, \"enabledEngageTypes\": \"3,6,4,5,17,1\" }, \"gutParams\": { \"tag\": \"\\\\4061\\\\ytpwmpu\" }, \"showCompanion\": true, \"showInstream\": true, \"useGut\": true } } ], \"playbackTracking\": { \"videostatsPlaybackUrl\": { \"baseUrl\": \"https://s.youtube.com/api/stats/playback?cl=417308503&docid=IgF3...\" }, \"videostatsDelayplayUrl\": { \"baseUrl\": \"https://s.youtube.com/api/stats/delayplay?cl=417308503&docid=IgF...\" }, \"videostatsWatchtimeUrl\": { \"baseUrl\": \"https://s.youtube.com/api/stats/watchtime?cl=417308503&docid=IgF...\" }, \"ptrackingUrl\": { \"baseUrl\": \"https://www.youtube.com/ptracking?ei=KnzDYZv1B86ikwa0no7AAg&oid=MjD-gn49GocgAFypi8EDnQ&plid=AAXTwR1aNKG2iTgr&pltype=content&ptchn=HnyfMqiRRG1u-2MsSQLbXA&ptk=youtube_single&video_id=IgF3OX8nT0w\" }, \"qoeUrl\": { \"baseUrl\": \"https://s.youtube.com/api/stats/qoe?cl=417308503&docid=IgF3OX8nT...\" }, \"atrUrl\": { \"baseUrl\": \"https://s.youtube.com/api/stats/atr?docid=IgF3OX8nT0w&ei=KnzDYZv1B86ikwa0no7AAg&feature=g-high-trv&len=1213&ns=yt&plid=AAXTwR1aNKG2iTgr&ver=2\", \"elapsedMediaTimeSeconds\": 5 }, \"videostatsScheduledFlushWalltimeSeconds\": [ 10, 20, 30 ], \"videostatsDefaultFlushIntervalSeconds\": 40, \"youtubeRemarketingUrl\": { \"baseUrl\": \"https://www.youtube.com/pagead/viewthroughconversion/962985656/?backend=innertube&cname=1&cver=2_20211221&data=backend%3Dinnertube%3Bcname%3D1%3Bcver%3D2_20211221%3Bptype%3Df_view%3Btype%3Dview%3Butuid%3DHnyfMqiRRG1u-2MsSQLbXA%3Butvid%3DIgF3OX8nT0w&foc_id=HnyfMqiRRG1u-2MsSQLbXA&label=followon_view&ptype=f_view&random=37068419&utuid=HnyfMqiRRG1u-2MsSQLbXA\", \"elapsedMediaTimeSeconds\": 0 }, \"googleRemarketingUrl\": { \"baseUrl\": \"https://www.google.com/pagead/1p-user-list/962985656/?backend=innertube&cname=1&cver=2_20211221&data=backend%3Dinnertube%3Bcname%3D1%3Bcver%3D2_20211221%3Bptype%3Df_view%3Btype%3Dview%3Butuid%3DHnyfMqiRRG1u-2MsSQLbXA%3Butvid%3DIgF3OX8nT0w&is_vtc=0&ptype=f_view&random=838827488&utuid=HnyfMqiRRG1u-2MsSQLbXA\", \"elapsedMediaTimeSeconds\": 0 } }, However, YouTube has bobby-trapped their UI and there is more than one way their obfuscated JavaScript code can pull down the ad details. Let’s blow it all away right now. After a lot of fun taking apart the YouTube UI and HTTP workflow, taking into account cookies and naughty service workers, I am successfully able to strip away all the pre-roll, post-roll, mid-video, and, well, all the video ads. Here is a screenshot from mitmdump showing how select REST queries are intercepted, decrypted, modified, put back into the response, and the headers updated (content length, etc.). Success in removing YouTube ads via decrypted JSON responses With this new ability, we could even inject JavaScript into the main YouTube web page and subvert their JavaScript in a sort of ECMAScript arms race, possibly even leveraging some of the filters from uBlock Origin. However, we can hang our hats on this accomplishment for today. Success: We can strip out ads from the JSON payload for YouTube web ads using a router. Top ↩ The iOS YouTube App Uses Protobuf, not JSON I can see very similar data in the Protocol Buffer (Protobuf) version of the same API calls as the web version to that of the YouTube iOS app. That complicates things, somewhat: We cannot lean on JSONPath to hunt down advertisement sections of JSON because with Protobuf the keys are just numbers that can even change. The iOS version of the YouTube app uses Protobuf Fun fact: YouTube compiles a large list of all the ads you are going to see and sends that to you in a sneaky payload. In fact, it is easier to visualize this when reading Protobuf. If you manage to exhaust that list, then another large list will be coming your way. I can see strings like “Telus” and “Samsung TV” and “Boxing Week” and “Buy now”. Remember when YouTube was a fun place? A fable about a Golden Goose comes to mind, Alphabet. What is a Protocol Buffer? Here is an infographic from Data Science Blog. Protobuf introduction (Credit: Data Science Blog) As a consequence of being able to see unencrypted traffic from my iPhone, I’m taken aback by the sheer amount of tracking information laid bare; It’s like I have electrodes on my head and chest while I’m running on a treadmill and a bunch of scientists in white lab coats with clipboards are standing shoulder-to-shoulder recording everything about my internals. Privacy concern: Your apps are tracking you like crazy: what you do, how long you dwell, when you leave a given app, and so much more. The URL https://play.googleapis.com/log/batch shows up a lot in my logs. The next question is: Does the iOS app protocol behave like the web app? Top ↩ Timing Analysis to Detect Ad Videos? The iOS network traffic is not like the web traffic; Google has teams and teams of engineers dedicated to making sure blocking their ads isn’t computationally feasible. Daunted but undeterred, I was staring at network requests to let my mind zone out and wander when I noticed a pattern I had not noticed before. For the web version of YouTube, I can eyeball which URLs are ads and which are the videos I want to watch. Take a look: Which are ad videos and which are content videos? How am I able to eyeball which video URLs are ads in this chaos? Two ad videos between content videos Take a look at the query parameter range. For the web version, a chunk of the video I want is fetched from the 0th byte, then immediately another video is fetched with a range starting again at the 0th byte. Both happen near-simultaneously – faster than a human can click on a new video. It turns out this, as well as examining the clen parameter for the length of the full video (short videos are likely ads), can reasonably allow us to detect and doctor ad videos. However, the iOS YouTube protocol does not use the range query parameter or even the Range header; video chunks use a counter like &nr=2 and &nr=3 etc. We must reverse engineer the Protobuf responses. Top ↩ Decode the YouTube Protobuf Responses Here are some decoded Protobuf log files I created then opened in the PyCharm IDE. Let’s examine some Protobuf logs in the IDE After logging decoded Protobuf messages to disk for offline analysis, I did notice something that piqued my interest. 1 2 3 4 5 6 7 8 2 { 1: has_unlimited_entitlement 2: False } 2 { 1: has_premium_lite_entitlement 2: False } I wonder what would happen if I were to, say, toggle those? This is tantalizing, but it is cheating, and hence no fun. Back to heuristics. Thought Experiment: As with JSON, can I blow away the Protobuf sections that serve up ads? Could I instead detect the ad videos in the payload, then dynamically modify their responses to be, say, a cached 0.01s video file? The 30s ~ 300s of unskippable ads could be over in the blink of an eye without blocking all those URLs. Intercepted ad URLs from the Protobuf payload Let’s start by blocking the ads as intended. Top ↩ Ad URL Polymorphism The Protobuf responses are a hot mess of bytes, but there are human-readable URLs that can be grepped. You’d think a simple LRU cache that blocks soon-encountered ad URLs could be the way to go, but, alas, the ad URLs do not quite match the URLs sent over the wire. Also, who is to say that YouTube won’t randomize the position of query-string parameters one day? We need an O(1) lookup of flagged ad URLs that are polymorphic (and group homomorphic) to live ad URLs. Detected ad URLs vs intercepted ad URLs It might be tempting to split a query string into a sorted dictionary and reassemble it, but we have no way of knowing what the query string boundary is. Plus, a live ad URL could add a key and disrupt the sorting. Addionally, I’ve encountered URLs like this that purposely try to obfuscate the query params: https://r4—sn-vgqsrns6.googlevideo.com/videoplayback /expire/1640607416 /ei/WFrJYdWnFfyTsfIP4s2BsAk /ip/121.35.98.26 /id/o-AE7swWOPOwXu3GyRght /source/youtube /requiressl/yes /mh/wU/ mm/31,26/… Notice how /ip/121.35.98.26/ is just &ip=121.35.98.26? I propose heuristically scanning for query and path parameters of ad URLs with high entropy and using those as keys (fingerprints). For example, in https://rr6—sn-uxa0n-t8gz.googlevideo.com/initplayback?source=youtube &orc=1&oeis=1&c=IOS&oss=1&oda=1&oad=5500&ovd=5500&oaad=11000&oavd=11000 &ocs=700&oputc=1&oses=1&ofpcc=1&osbr=1&osnz=1&msp=1&odeak=1&odepv=1 &osfc=1&id=58cc678216d6aaca&ip=121.35.98.26&initcwndbps=2125000 &mt=1640373902 One could note the following candidates in descending order of length: rr6—sn-uxa0n-t8gz 58cc678216d6aaca 121.35.98.26 1640373902 2125000 Any or all of them could be lookup keys each pointing to the same dictionary of deconstructed query parameters. A lookup of a live URL would involve the same process of finding the highest entropy parameters and checking the URL dictionary for a match. The cache data structure can even be multi-level with the root keys being just the length of the high-entropy strings. Failure: Even with the ability to block polymorphic URLs, the video ads are still indistinguishable from content video without context from the Protobuf structure. Top ↩ Smoke Test: Intercept and Decode Protobuf in Python Python is Slow: Decoding ~500 kiB of raw Protobuf in pure Python is painfully slow. Decoding ~500 kiB of Protobuf in pure Python, especially the decoding step of converting it to over 1 MiB of human-readable text to parse the ad URLs, takes more time than the connection timeout most of the time. I’ll run some benchmarks using pure Python vs. the native C++ library. Pure Python Benchmarks 1 2 3 4 5 6 7 8 9 10 11 from timeit import repeat from mitmproxy.contentviews.protobuf import format_pbuf with open(\"proto.raw\", \"rb\") as f: data: bytes = f.read() print(repeat(lambda: format_pbuf(data), number=5)) # On a i7-6700 CPU @ 3.40GHz desktop # [2.10792827908881, 2.0718665630556643, 2.0739889848046005, 2.065321908099577, 2.070936748990789] # On the pfSense router: # [24.182968072011136, 22.833560551982373, 23.53838806191925, 22.842924927012064, 22.81738876597956] Pure C++ Benchmarks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # On a i7-6700 CPU @ 3.40GHz desktop TIMEFORMAT=%R for i in {1..5}; do time protoc --decode_raw/dev/null; done # 0.018 # 0.017 # 0.022 # 0.018 # 0.018 # On the pfSense router: printf 'foreach f ( 1 2 3 4 5 )\\n time protoc --decode_raw/dev/null \\n end \\n'tcsh # 0.030u 0.114s 0:00.14 100.0% 30+153k 2+0io 0pf+0w # 0.024u 0.104s 0:00.12 100.0% 8+132k 2+0io 0pf+0w # 0.022u 0.106s 0:00.12 100.0% 34+156k 2+0io 0pf+0w # 0.016u 0.114s 0:00.13 92.3% 8+143k 2+0io 0pf+0w # 0.023u 0.102s 0:00.12 100.0% 8+132k 2+0io 0pf+0w If you caught that, it takes about 23s in Python, and 100ms in C++! In this Never Ending Story, we have to find a way to parse the raw Protobuf payloads in Python using the C++ library libprotobuf.so. In the interest of time, I’ll use subprocess.Popen and communicate with the C++ protoc binary directly (since raw decoding is not supported in Python anyway). Top ↩ Fuzzing the YouTube Video Ad Responses How about fuzzing the ad video responses? Now being able to isolate ad videos, as a smoke test, I sent back 200 responses with empty bodies and the iOS app went bananas; it was as if there is an infinite loop with no delay just hammering YouTube’s own servers trying to get the next part of the video in panic mode. I felt bad for their servers, so I stopped. Then, what would a happy-path response payload look like? Infinite spin-lock loop of YouTube trying to get the next bytes of the ad video Try as I might, when I send back empty 200s, 404s, 503s, truncate response bodies, or just null-out part of the ad video, the iOS app crawls then crashes spectacularly with a dying breath of a messed up iOS UI. I now block some error reporting endpoint at /error_204/ that indicates a “dev assertion failed” so I don’t make some overworked QA pull out their hair. Failure: We’ve learned that blocking ad URLs causes the app to deploy countermeasures and even when defeated, the app hangs forever on the ad screen. We’ve also learned that fuzzing ad videos often causes the app to crash – there is even session meta data in the video response chunks. Let’s go back to what worked with JSON and obliterate the section of the Protobuf responses that contain the array of ad details. Top ↩ Enter Burp Suite Tools for Penetration Testing There is a library for Burp Suite called blackboxprotobuf (get the original Burp Suite version, not the PyPi fork, unless you like infinite recursion bugs) that is designed to decode raw Protobuf wire messages, inject something naughty, then re-encode them again to see how a Protobuf endpoint behaves. We are going to have so much fun together in this next section. 1 2 3 4 5 6 7 8 9 # Install blackboxprotobuf from source mkdir blackboxprotobuf_src && cd blackboxprotobuf_src git clone https://github.com/nccgroup/blackboxprotobuf.git . pip3 install poetry cd lib poetry install # pwd -> blackboxprotobuf_src/lib/ cp -r blackboxprotobuf your/project/folder # We only need this folder tree for the Py3 API You may encounter a small world of pain because some forks of blackboxprotobuf will cause a stack overflow due to deep recursion. You can see this by adding sys.setrecursionlimit(200). Compiling the original library source code for Burp Suite and using the C++ bindings will allow us to transcode ~500 kiB of raw Protobuf bytes in just a few seconds. Tip: At the top of your import chain before you import protobuf, add 1 2 import os os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"cpp\" to use the C++ libprotobuf.so implementation whenever possible. It is now possible to generate a best-guess .proto schema with a single function: 1 2 3 4 5 6 7 8 9 import os os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"cpp\" from mitmdump.blackboxprotobuf.lib import protobuf_to_json data: bytes = ... message, typedef = protobuf_to_json(data) # print(message) print(typedef) The schema isn’t perfect, and it is huge and deeply nested, and takes forever to pretty-print, and is probably wrong, but is just good enough to pull out the ad details like so (Protobuf to JSON in this sample): Sample Protobuf to JSON showing a section of ads The Python schema is huge and looks like this for about 250,000 more charcters: 1 2 3 4 5 6 OrderedDict([ ('1', OrderedDict([ ('type', 'message'), ('message_typedef', OrderedDict([ ('6', OrderedDict([ ('type', 'message'), ('message_typedef', OrderedDict([ ('1', OrderedDict([... Reverse engineering the Protobuf schema sounds good on paper, but our target is spectacularly complex and a moving target. Top ↩ Exfil the Proto Schemas from the App, Cleanly? As fun as it to reverse the Protobuf and generate a best-guess schema, wouldn’t it be more ninja-like to exfil the actual, working .proto or schema files from the smartphone app? Let’s pull out the Protobuf schemas from the Android version of the YouTube app and see if the schemas are the same or compatible. This is what I tried at first, but it went nowhere with the Protobuf Toolkit (PBTK). I reproduce it here so I remember what I tried: 1 2 3 4 5 6 sudo apt update sudo apt install libqt5x11extras5 python3-pyqt5.qtwebengine python3-pyqt5 pip3 install pyqt5 pyqtwebengine requests websocket-client mkdir pbtk && cd pbtk git clone https://github.com/marin-m/pbtk . ./gui.py After installing Qt dependencies (pronounced “cute”), I was treated to a GUI. PBTK – The Protobuf Toolkit Next, I got the most recent release of a 100 MiB Android APK file from apkpure.com. Excited in vain, the most PBTK could get was a 59-byte proto file. Another tool called Apktool also looked promising, but the best it can do is disassemble bytecode, not decompile it – this may be good enough for Pen Testers, however. What ended up working for APK decompilation is a combination of a dedicated person’s dex2jar tool and a Java Decompiler. A helpful guide can be found here. 1 2 3 4 5 6 # Follow the install steps at https://stackoverflow.com/a/4177581/1938889 cd dex2jar chmod -R +x *.sh sh d2j-dex2jar.sh -f -o ../output.jar ../YouTube_v16.49.37_apkpure.com.apk cd ../jd-gui java -jar jd-gui-1.6.6.jar You can see that Google went out of its way to complicate reverse engineering. YouTube APK reversed into obfuscated Java classes Google thoughtfully did leave some hints. All the Protobuf classes laid bare and human-readable Upon deeper inspection, the Protobuf classes are right here, in Java, decorated with getters and setters. Since we are using Python, and we cannot get the true schema files, I will leave this approach for now. Top ↩ Hardcore Deep-Dive into Protobuf and Wire Format After gazing into a sea of decrypted network traffic again, then triggering errors and assertion fails on my iPhone with Protobuf fuzzing, and taking a peek at the error logs being phoned home, I’ve noticed that ads register for “slots” in a given video. They can register for pre-roll, mid-roll, end-roll, full-page, and ad pods (back-to-back ads). Blocking an ad URL causes an error along the lines of “some ad that doesn’t exist booked a slot” and UI panic sets in. I’m going to Sun Tzu the Protobuf Wire Format and come back in a bit… I’m back. The Wire Format is surprisingly elegant, except for ZigZag encoding. Through trial and error, editing out chunks of Protobuf with a hex editor is just a no-go. While computationally expensive, decoding, editing, and re-encoding without the original schema leads to a modified encoding. This is likely because we cannot detect if ZigZag encoding is being used, or if a number is an int32, int64, sint32/64, varint, etc., plus the order of object fields is normally non-deterministic. Here is some Protobuf trivia on the matter: Protobuf serialization gotachas Top ↩ Exploit a Protobuf Flaw to Easily Remove All Ads by Changing One Byte Casually poring over the C++ source code, an interesting comment in the Protobuf code caught my eye: UnknownFieldSet is used to keep track of fields that were seen when parsing a protocol message but whose field numbers or types are unrecognized. This most frequently occurs when new fields are added to a message type and then messages containing those fields are read by old software that was compiled before the new types were added. (ref) Yes, what to do with unknown fields? What to do indeed. And, how easy would it be to say, change a 49399797 field key to, say, 49399796 thus making an entire substructure of advertisement and tracking information suddenly unavailable? Tantalizing. And, if we can calculate the field tags in bytes with bit-twiddling, then can we use a simple regex to AMF1 the section of ads in O(n) time? As a motivating example, I’d like to find the field key 49399797 which is not as simple as searching for 2F1C7F5. Here is an implementation of a tag-scanning algorithm so you can see the bit-twiddling: 1 2 3 4 5 6 7 8 9 10 11 12 13 def DecodeVarint(buffer, pos): mask = (1 > 3 = 49399797 And that, folks, is a taste of how Wire Format works. Fantastic. Now, all we have to do is scan the Protobuf bytes for classic ad URL signatures like /pagead/ to bound our field search, then move backward from there until we find the target(s) field tags and thus field keys we would like to denature (e.g. 49399797 –> 49399796). 1 2 3 4 5 6 >> Request(POST youtubei.googleapis.com:443/youtubei/v1/browse?key=...)str: \"\"\"Helper for viewing very long URLs\"\"\" msg = str(msg) if len(msg) > TRUNCATE_LEN: return f\"{msg[:TRUNCATE_LEN-3]}...\" else: return msg class KilledError(Error): \"\"\"Better logging messages than just 'Connection killed.'\"\"\" def __init__(self, reason: str) -> None: self._msg = Error.KILLED_MESSAGE self.reason = reason super().__init__(self._msg) @property def msg(self): caller = inspect.stack()[1].function # These are the only two methods that compare the msg # with KILLED_MESSAGE to perform business logic if \"killable\" in caller or \"check_killed\" in caller: return self._msg else: return self.reason # Needed to satisfy a flow setter @msg.setter def msg(self, msg): self._msg = msg class JSONPathReplacement: \"\"\"Helper class to organize JSON ad replacements\"\"\" def __init__(self, tag: str, target_path: str, replacement: any) -> None: self.tag: str = tag self.target_path = target_path self.target: jsonpath.Root = parse(target_path) self.replacement: any = replacement def update(self, obj: object): found = self.target.find(obj) if found: for index, item in enumerate(found): self.target.update(item, self.replacement) logger.warn(f\"Replaced `{self.target_path}[{index}]` with `{self.replacement}`\") if DEBUG_MODE: found_again = self.target.find(obj) replacement_json = json.dumps(self.replacement) for index, item_ in enumerate(found_again): item: DatumInContext = item_ if json.dumps(item.value) != replacement_json: logger.error(f\"Replacement of `{self.target_path}` did not succeed. Found `{json.dumps(item.value)}`\") else: logger.info(f\"-Skipping `{self.target_path}`\") class ProtobufDebugParser: \"\"\"Use the C++ protoc binary to parse raw Protobuf data. This is for debugging.\"\"\" cmd = [\"protoc\", \"--decode_raw\"] url_re = re.compile(r\"(https?://[^\\s\\\\]+)\", re.IGNORECASE) def format_response(self, data: bytes) -> list: protoc_proc = subprocess.Popen(self.cmd, shell=False, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) (stdout, stderr) = protoc_proc.communicate(data) if stderr: raise Exception(stderr) return stdout.splitlines(keepends=False) def parse_response(self, data: bytes) -> list: protoc_proc = subprocess.Popen(self.cmd, shell=False, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) grep_process = subprocess.Popen([\"grep\", \"https://\"], shell=False, stdin=protoc_proc.stdout, stdout=subprocess.PIPE) (_, stderr) = protoc_proc.communicate(data) (stdout, _) = grep_process.communicate() if stderr: raise Exception(stderr) urls = stdout.splitlines(keepends=False) matches = [] for url in urls: match = self.url_re.search(url.decode()) if match: matches.append(match.group(0)) return matches class YouTubeAdBlocker: \"\"\"Intercept certain YouTube domains and modify the JSON or Protobuf to remove ads from YouTube\"\"\" # Set this to the blackhole IP used by pfBlockerNG, or even a partial blackhole IP blackhole_ip_prefix: Final[str] = \"10.10.10.\" # Intercept only these wildcard domains and no others intercept_hosts = r\"\\.youtube\\.com|google\\.(com|ca)|googleapis\\.com|googleadservices\\.com|googlevideo\\.com\" intercept_hosts_re = re.compile(intercept_hosts, re.IGNORECASE) ad_url_search_string = b\"/pagead/\" ad_url_search_limit = 80_000 target_field_tag = 50195462 # This is just one of several field tags protobuf_parser = ProtobufDebugParser() # Block requests from wildcard domains with any of the follow URL strings blocked_partials: dict = { \"youtube.com\": [ \"pagead/\", \"log_event?\", \"stats/ads\", \"stats/qoe?\", \"ptracking?\", \"generate_204\", \"error_204\", \"adformat=\", \"activeview?\", \"_ad_\", \"ai?\", \"sw.js\", # Just say no to service workers ], \"google.com\": [\"pagead/\"], \"google.ca\": [\"pagead/\"], \"googleapis.com\": [\"pagead/\"], } # Strip sections of JSON that contain ad information (for web YouTube) json_replacements = [ JSONPathReplacement(\"yt_ad\", \"$.responseContext.serviceTrackingParams[*].params[?(@.key == 'yt_ad')].value\", \"0\"), JSONPathReplacement(\"adPlacements\", \"$..adPlacements\", []), JSONPathReplacement(\"adPlacementRenderer\", \"$..adPlacementRenderer\", {}), JSONPathReplacement(\"adPlacementConfig\", \"$..adPlacementConfig\", {}), JSONPathReplacement(\"adVideoId\", \"$..adVideoId\", \"\"), JSONPathReplacement(\"playerAdParams\", \"$..playerAdParams\", {}), JSONPathReplacement(\"showCompanion\", \"$..showCompanion\", False), JSONPathReplacement(\"showInstream\", \"$..showInstream\", False), JSONPathReplacement(\"useGut\", \"$..useGut\", False), JSONPathReplacement(\"gutParams\", \"$..gutParams\", {}), ] @staticmethod def in_allowed_ads_window(): \"\"\"Allow ads 5% of the time to support content creators which follows the CRTC rules for Student Radio. REF: https://crtc.gc.ca/eng/television/publicit/publicit.htm\"\"\" now = datetime.now() return 0None: \"\"\"Block ad URLs that pfBlockerNG and Pi-hole cannot detect\"\"\" # Skip inspecting certain requests if flow.response or flow.error or (flow.reply and flow.reply.state == \"taken\"): return # Occasionally skip blocking ads to support content creators if self.in_allowed_ads_window(): return test_url: str = flow.request.url test_host: str = flow.request.pretty_host.lower() for host, partials in self.blocked_partials.items(): if test_host.endswith(host): for partial in partials: if partial in test_url.lower(): msg = f\"✘ [{host} -> {partial}] blocking {trunc(flow.request.pretty_url)}...\" logger.info(msg) # Should be a connection refused error flow.kill() flow.error = KilledError(msg) return def response(self, flow: http.HTTPFlow): \"\"\"This is the main workhorse. Intercept JSON and Protobuf responses and modify them to remove or denature ad information\"\"\" # Skip inspecting certain responses if not flow.response or flow.error or not flow.response.headers: return logger.warn(f\">> {flow.request}\\n 0: target_pos = distance - 1 - target_pos - len(tag_bytes) logger.warn(f\"Found {self.target_field_tag} at position {target_pos}\") assert body[target_pos] == tag_bytes[0] assert body[target_pos + 1] == tag_bytes[1] assert body[target_pos + 2] == tag_bytes[2] for ind, b in enumerate(new_bytes): body[target_pos + ind] = b \"\"\"NOTE: There are other field keys in different sections, and there may be multiple ad sections to denature. What preceded is a PoC of the technique that already blocks 90% of ads.\"\"\" # Example Protobuf path: b\"4 {\" b\" 49399797 {\" # Damage this key b\" 1 {\" b\" ... /pagead/\" # Example Protobuf path b\" 1 {\" b\" 50195462 {\" # Damage this key b\" 1 {\" b\" 153515154 {\" b\" ... /pagead/\" # Put the contents back in the response body flow.response.set_content(bytes(body)) except Exception as e: _, _, exc_traceback = sys.exc_info() traceback_ = traceback.format_tb(exc_traceback) logger.alert(f\"{e!r}, {traceback_}\") elif \"json\" in test_content_type: logger.warn(f\"Intercepting {trunc(test_path)} JSON\") # Examine the JSON payload try: obj = flow.response.json() for replacement in self.json_replacements: replacement.update(obj) flow.response.set_content(json.dumps(obj, ensure_ascii=False).encode()) except (TypeError, JSONDecodeError): pass # Do not stop the show except Exception as e: _, _, exc_traceback = sys.exc_info() traceback_ = traceback.format_tb(exc_traceback) logger.alert(f\"{e!r}, {traceback_}\") # Register the addon addons = [YouTubeAdBlocker()] This script happens to work in Python for a TLS-decrypting man-in-the-middle proxy written in Python. As a working proof-of-concept, it’s pretty rad. Of course, it can be rewritten in Rust or Go or anything but single-threaded Python, but as an intellectual exercise to defeat ads that are served from the same domain as content, it’s elegant. Top ↩ YouTube Premium It’s unknown if CAD $9.99/mo $11.99/mo ($13.43/mo with tax) is even reasonable: Do I personally incur CAD $11.99 of cost to advertisers each month? Source Since ads are auctioned, the CPV (cost-per-view) varies. Also, many ad campaigns have a capped daily budget, so theoretically there should be fewer ads in the evenings as budgets run out during the day. Experiment in Ad Viewing I watched YouTube on and off for a day on a clean notebook computer with private browsing. My history showed that I only “watched” 10 videos: I fast-forwarded through a few of them to get past the “like and subscribe” runtime padding. I jumped to the end of one just to get to the “top three” from a “top twenty” list. Two were low quality so I left early. The rest were music videos. In all, for watching parts of 10 videos, I was exposed to 8 ads, and only two were skippable (which I skipped). $0.15 as a Ballpark CPV Let’s use USD $0.15 as a CPV. In one day, let’s say, I incurred 8 x $0.15, or $1.20 to advertisers. Extrapolated to one month, that is roughly USD $36/mo. Do I really cost advertisers USD $36/mo for very casual YouTube viewing? That sounds terrible for advertisers. CPV from US Advertising Spend Divided by Total Views From Statistica, in 2019, US YouTube advertisers spent $15.1 billion dollars. Also in 2019, US residents had 916 billion views (ref). That works out to an average of $15.1B / 916B, or USD $0.0165 per view. Then for me, that is only USD 13 cents. Extrapolated to one month, I theoreticaly cost advertisers only USD $3.96/mo. Is YouTube Premium Worth It? When I allowed ads for my experiment, I hit the hardware mute button. I also looked away because I have several computers with a lot going on. Ad spend is wasted on me, but I still want to support content creators. For me, CAD $13.48/mo is more than I incur on actual ads and more than I pay for a Netflix subscription. The only way to justify the cost is to have YouTube playing constantly in the background on a TV. However, I truly enjoy a handful of creators, so I may start watching them in the background on non-stop play. Let’s give the three-month YouTube Premium trial a chance, and I will still be monitoring what they track about me. YouTube Premium network traffic Top ↩ DMCA, Sony, Viacom Recently I learned that due to abuses of the DMCA Act of 1998, YouTube content creators who make reaction videos and “easter egg” videos may have their videos claimed by big companies like Sony and Viacom. That means that from when a claim is made, all ad revenue goes to those big companies, and not even to the creators. That means in all likelihood I unknowingly may not even be supporting my favourite YouTube creators. Did you know? Many fair-use and video-game-commentary videos may have automated copyright claims against them, meaning that ad revenue goes to big companies with deep legal pockets and your favourite creators may get nothing, so more and more creators leave YouTube for Twitch. Top ↩ Summary of Accomplishments I rarely give up, so this is an example of going into an extreme problem-solving mode to solve a fun problem loosely using cryptography and reverse engineering. In the end, a single byte turned it all around, so it was all worth it to come to an elegant and satisfying solution. Success: We were able to set up a hardware router from scratch, segment LANs into trusted and untrusted zones, set up traditional DNS adblocking, add a transparent MITM proxy, and ultimately block YouTube ads on networked Apple devices. Note: This was a hard problem – now solved – so I am paying for YouTube Premium to give the CPU a rest. Top ↩ Notes: Adios, My Friend ↩ Posted in: Hardware, Linux, Privacy, Security, Tips & TricksTags: Adblocking, MITMProxy, pfBlockerNG, pfSense, Protobuf, YouTube Post navigation Previous Next Recent Posts Advanced 3D Printing Tips & Tricks Compile Marlin (3D Printer Firmware) with Docker Unblock Google Analytics: Prevent AdBlockers from Blocking Site Analytics Safecracking: Open a Safe with Drained Internal Batteries How to tell if “N52” Neodymium Magnets are Real Categories Tips & Tricks (46) Problem Stories (31) Hardware (15) Linux (15) Quant (11) Programming (9) Testing (9) APIs (7) Server (7) Website Dev (7) Algorithms (7) Databases (7) Cluster Computing (6) Software (3) Security (3) Privacy (3) Just Thinking (2) Hosting (2) 3D Printing (2) Windows (1)",
    "commentLink": "https://news.ycombinator.com/item?id=37279109",
    "commentBody": "Block YouTube ads on AppleTV by decrypting and stripping ads from ProfobufHacker NewspastloginBlock YouTube ads on AppleTV by decrypting and stripping ads from Profobuf (ericdraken.com) 474 points by rolph 6 hours ago| hidepastfavorite192 comments userbinator 4 hours agoI&#x27;ve been MITM&#x27;ing my traffic to, among other things, strip ads and rewrite pages with things like custom CSS, ever since I discovered The Proxomitron over 2 decades ago. It does tend to get me profiled as a \"bot\" by CloudFlare and such, but there are not-so-trivial ways around that too. It also shows why things like remote attestation are hazardous for user freedom. reply ttctciyf 3 hours agoparent> The ProxomitronGoogling this, development ended in 2004? An informed summary of the current state of play would be interesting, since a lot of different \"continuations\" of it seem to be around. Also, is it Windows-only? (I&#x27;ve been casually looking for a simple proxy that would enable injection of local links into remote content.) reply greyface- 3 hours agoparentprev> It does tend to get me profiled as a \"bot\" by CloudFlareSince Cloudflare employees are known to lurk here, I&#x27;d like to know: is this considered a false positive, or working as intended? reply rs_rs_rs_rs_rs 3 hours agorootparentNot a CF employee but I am pretty sure it&#x27;s working as intended as they built and use this:https:&#x2F;&#x2F;github.com&#x2F;cloudflare&#x2F;mitmengine reply fulafel 2 hours agorootparentHere&#x27;s hoping that, if they do it, they&#x27;ll start blocking corporate TLS mitm regimes too. reply michaelt 1 hour agorootparentBlocking? Cloudflare provides corporate TLS MITM regimes. reply rightbyte 24 minutes agorootparentprevEver since Google started pushing HTTPS I understood that non-encryption would be a future privacy problem. reply faraggi 3 hours agoparentprev> among other thingswhat else do you MITM for? reply 1vuio0pswjnm7 47 minutes agorootparentMITM is kind of a silly term for what the user is doing when using a forward proxy. If the computer owner binds the proxy to a localhost address, the unencrypted requests need only go over the loopback. There need be no encrypted requests travelling over the LAN. The computer owner, the \"MITM\", is on their own computer sitting in between an application and the network interface. That is exactly where they should be, IMHO. Corporations do it. They own the computer and they own their internal networks. It&#x27;s no different for home users. And WFH is blurring the distinction anyway.Once the requests leave the computer and travel onto the internet destined for another computer, then of course \"MITM\" makes sense as a concept.The computer owner controls the proxy and it&#x27;s the proxy, not the untrusted application, like a \"modern\" web browser for example, that handles authentication of the remote peer. Compiling and fully controlling a \"modern\" browser is a PITA. Almost no one does it, even software developers. Instead people beg for an advertising company or their partner to make changes to a browser. That does not seem to work. Sometimes when people complain it stops the company from making undesired changes. But only temporarily.Whereas compiling a proxy is easy and the user can fully control it.Having used many different applications that implement support for TLS, I actually trust the proxy&#x27;s implementation more than most applications. It&#x27;s arguably easier to audit one program, the proxy, than it is to check every application to make sure the developer didn&#x27;t make a mistake when adding TLS support. I recall the incident with socat as one example. That mistake when undetected for a long time. Elinks was another. reply sneak 58 minutes agoparentprevPresumably this involves installing new CA certs on your devices, no? reply userbinator 11 minutes agorootparentYes, and this also answers the other comment about what else I MITM for: blocking devices that I can&#x27;t inspect the traffic of is another reason, since the proxy is the only way out of the network. reply 1B05H1N 3 hours agoparentprevYou should be okay as long as you solve the challenge(s). reply 1vuio0pswjnm7 1 hour agorootparentI also run a forward proxy and found adding a user-agent header was all that was necessary. reply jjallen 1 hour agoprevI just subscribe to YouTube premium to support my favorite application out there.I learn so much from the people who spend hours and hours making videos every month that I am more than happy to pay a measly $13 or whatever it is every month to YouTube. reply sneak 1 hour agoparentIf you continue to give Google money you&#x27;ll continue to get things like AMP, Manifest V3, Web \"Integrity\", and whatever else they think up to track you across the web.They&#x27;re an ad company. They pay the creators per impression even if you block the ads. Blocking ads harms Google, not the content producers. reply jjallen 10 minutes agorootparentI&#x27;m giving them money to view less ads. Isn&#x27;t this an inherently \"anti-ad\" consumer standpoint? I am telling YT&#x2F;Google that I as a consumer am willing to pay money to not see ads.Am I not telling them with my wallet to develop other ad-free solutions that I will pay them and the content creators money for?> They pay the creators per impression even if you block the ads. Blocking ads harms Google, not the content producers.Blocking ads and refusing to pay any money into the YT ecosystem decreases the revenue per viewer which will eventually reduce the amount of money YT pays to creators and&#x2F;or increase the price they charge to YT premium subscribers. reply guerrilla 3 minutes agorootparentNo, they&#x27;re not going to leave money on the table. Eventually you&#x27;ll be seeing ads too. This is just a hook period. I don&#x27;t understand how we as a culture haven&#x27;t learned this already. This is at least the fourth or fifth generation of this with media. How things actually work should be common sense by now. reply moonchrome 50 minutes agorootparentprevNo that&#x27;s what you get when you&#x27;re the product by being a free user. Paid service relationship works just fine for me - Google isn&#x27;t ideal but YouTube is one of my main content sources + YouTube music for my family for slightly more than the price of Spotify family subscription - yeah it&#x27;s an easy choice.Spotify suggestions and playlists weren&#x27;t a seller feature for me for years. Maybe I&#x27;m missing out on a few podcasts. reply ohgodplsno 45 minutes agorootparentNo, Google will keep fucking you over and destroying the Internet, whether you pay or not. Not to mention the fact that what they pay out to creators is absolutely pathetic. Go find their Patreon, their Ko-fi, hell their paypal, anything but giving Google 13 bucks.Adblocking Google is morally right. reply Shekelphile 30 minutes agorootparent> Adblocking Google is morally right.All ads should be blocked. I do not consume ads, and am not interested in paying a ransom to hide them. reply ddalex 10 minutes agorootparentIf you don&#x27;t consume ads, please do not use any ad-supported service, that&#x27;s the easiest thing to do. reply Shekelphile 9 minutes agorootparentNo. reply ddalex 11 minutes agorootparentprevWouldn&#x27;t be not using Google at all the morally right choice ? reply soraminazuki 21 minutes agorootparentprevI just have no sympathy for the ad industry. I wouldn&#x27;t have gotten into ad blocking if ads were non-intrusive, non-deceptive, and purely contextual. I used to even click on them more than a decade ago. But no, the ad industry wasn&#x27;t satisfied with the money they were already making. They wanted to stalk you across the web and shove endless amounts of junk ads to uninterested people.The ad industry brought the current situation on to themselves. reply ben_w 1 hour agoparentprevIf the ads were silent banners changing the aspect ratio of the videos, I wouldn&#x27;t mind them.30 second un-skippable advert to see a 7 year old 45 second clip? I press \"back\" and watch neither.Thinking of supporting creators: I looked at Nebula a while back as an alternative; I think there was some UX issue back then, but they&#x27;ve likely improved it and I should look again. reply Shekelphile 40 minutes agoparentprevI don&#x27;t see a point in giving google any money when the price of premium seems to go up every time I open the page for it (it&#x27;s literally gone up 50% in the last 2 months, with the cheaper tier also no longer being offered) on top of actively being worse than using normal adblockers since you won&#x27;t get any equivalent to sponsorblock by paying for premium. It&#x27;s literally worthless, at least until google begins clamping down on ad blocking. reply ffhhttt 1 hour agoparentprevYou could probably support them more directly over Patreon&#x2F;etc. so they’d get to keep a much bigger proportion of what you pay reply jjallen 43 minutes agorootparentI do that too when I really want to support someone. YouTube premium is a way to support each producers videos, not only the few that I might patronize on Patreon.There are dozens and dozens of different creators of videos that I watch each month, so if I only used Patreon most wouldn&#x27;t get anything from me. reply kaliqt 41 minutes agoparentprevThis reads like an ad.I wouldn&#x27;t support them that way. They shaft creators in every way possible.You should be subscribing to Patreons and their video subscriptions. YouTube Premium is NOT the way. reply jjallen 13 minutes agorootparent> YouTube Premium is NOT the way.So have 100 different Patreon subscriptions each month? The minimum pledge is $1. What if I watch 200 different YT creators? What about the short videos? Should I create a new Patreon subscription for each individual creator I watch? What if my interests frequently change (they do). Should I spend hours per month managing individual Patreon subscriptions?The original post is about blocking ads. Blocking ads reduces the amount of money going to creators. Now you are saying that paying actual real money to not see ads is also not the way.> They shaft creators in every way possible.I guess this could be true that YT \"shaft[s] creators in every way possible\". If this were true, I&#x27;m somehow guessing that not basically everyone would show their videos there, don&#x27;t you think?There&#x27;s a balance here; being universally against ads (which quite a few people here are) while also refusing to pay anything for content is not a congruent view.At a very minimum there is considerable costs associated with delivering the video content, as most of us know.And for the record, I do patronize the creators whom I watch lots of consistently. reply neurostimulant 12 minutes agoparentprevI understand the sentiment, but the creators actually only got peanuts (most don&#x27;t even see any money) out of your $13 while the rest go to Google. You are paying Google for youtube, and Google pay (some) content creators with a tiny fraction of your subscription money. reply mda 0 minutes agorootparentDo you have numbers to back your claim?Afaik From ad revenue channels get 55%. They also get money from premium subscribers depending on how much time they spent on channel. I wouldn&#x27;t call it peanuts. reply tcfhgj 10 minutes agoparentprevI recommend donating money yourself (E.G. Patreon).It&#x27;s not only more effective, but also doesn&#x27;t support Google (main player in the ad industry) reply k8sToGo 1 hour agoparentprevI would not mind paying for \"ad free Youtube\" if it was like 5 - 10 bucks. I don&#x27;t need or want Youtube Music. There was a YouTube Premium Lite at some point for some countries.Plus paying for youtube premium does not remove the sponsor ads inside videos.Also I feel like the algorithm has gotten worse and worse? I personally don&#x27;t like to support that. reply j_bum 1 hour agoparentprev*now a monthly $19. Still worth it for me as well, given how much I use it for entertainment and education. reply mrweasel 1 hour agorootparentI believe you can get it for $9.99 or something like that, if you don&#x27;t need YouTube Music. The product is called YouTube Premium Lite. reply ThePowerOfFuet 1 hour agoparentprevNebula sounds like a better fit. reply jasode 37 minutes agorootparent>Nebula sounds like a better fit.No, paying Nebula as an alternative to paying Youtube doesn&#x27;t work for many viewers because most creators who create good content are not on Nebula. E.g. Many popular channels with worthwhile info such as Applied Science, Technology Connections, 3Blue1Brown, etc are not on Nebula.Also, many people who use Youtube for learning DIY repair, hobbies, coding, etc and Nebula doesn&#x27;t really cater to those genres. E.g. I watched some videos about configuring Unifi networks and then some tutorials on installing some flooring. These types of videos are not on Nebula&#x27;s platform.There is a huge variety and scope of educational material on Youtube and platforms like Nebula&#x2F;CuriosityStream only have a fraction of that. reply cinntaile 1 hour agorootparentprevYoutube has the content the GP wants, why switch to a platform with different content? reply arnon 54 minutes agorootparentBecause people here like suggesting alternatives that _they_ like. reply isaacremuant 43 minutes agoparentprevNice ad, hackernews. Now I&#x27;ll surely reward YouTube for their terrible behaviour towards their creators and consumers... reply tinus_hn 32 minutes agoparentprevA problem with paying is that you have to be logged on so you can’t avoid being tracked and having every video you ever watch linked to you for all eternity. reply chronogram 24 minutes agorootparentYou have privacy controls in your Google account. I have web & app activity off, location history off, YouTube search off and YouTube watch history auto deleting after a few months. https:&#x2F;&#x2F;myaccount.google.com&#x2F;data-and-privacyIf you&#x27;re talking about them building a secret extra profile about you with those things turned off, then they wouldn&#x27;t need you to login for that. reply tinus_hn 22 minutes agorootparentAnd if you believe Google is not storing that information anyway I’ve got a beautiful bridge for sale.If you don’t use an account you can create a fresh container every once in a while and start the game anew and you can choose to not associate it all with your identity. reply msla 41 minutes agoparentprevSupport them through Patreon because it&#x27;s morally right.Keep your hand in the adblocking world because it&#x27;s morally right.People can do two things. reply rhaway84773 57 minutes agoparentprevI’m not against YT premium, but wouldn’t a better choice be to give the people you’re learning from money instead? reply jjallen 43 minutes agorootparentI do when I regularly watch a particular creator&#x27;s videos over and over. However, this isn&#x27;t the case for most of the videos I watch. Lots of one-off views. reply ajkblue 3 hours agoprevThis reminds me of a now-dockerized Privaxy, which is a UBlock-origin blocklist compatible MITM proxy. It’s crazy to see how many ads and tracking scripts are on smart products, especially my TV where so far in my testing it’s over 40% unnecessary traffic. Its been pretty fun to try and strip out ads on my smart-tv apps.https:&#x2F;&#x2F;github.com&#x2F;deetungsten&#x2F;webui-privaxy is the dockerized fork of https:&#x2F;&#x2F;github.com&#x2F;Barre&#x2F;privaxy reply glitchcrab 2 hours agoparentHow do you get your TV to trust the self signed cert? reply boesboes 2 hours agorootparentIt would not surprise me if most TVs don&#x27;t check. I remember LG or Samsung using unencrypted FTP to upload viewing data a few years back, so unverified TLS would be an improvement >_ I was kinda hoping to find a way to MITM devices that don&#x27;t allow the installation of custom CA&#x27;sThe point of TLS is to prevent that... You&#x27;d be relying on implementation flaws if it were ever achieved.Frankly I expect the days of being able to install our own trusted certificates are numbered on the few devices that do currently allow it. reply phito 3 hours agorootparentI know that&#x27;s the point, and I hate it. :) reply megraf 4 hours agoprevThis is an incredible write up. As soon as I saw the steps about patching mitm, I knew this would be special... wow! reply vachina 2 hours agoprevI find it easier to install AdGuard extension on Safari and then Apple play the video to the TV.You get native player and no ads. reply Noumenon72 4 hours agoprevWhy is toggling `has_premium_lite_entitlement` cheating compared to anything else? What would it do? reply yasoob 3 hours agoparentI am assuming it would completely prevent ads (so no need to figure out how to filter&#x2F;block them) as the name of this field suggests that it might be used by YouTube to figure out if someone has a premium subscription or not. Toggling this field would not have led the author to the later protobuf rabbit hole as there would have been no need for it.From personal experience, we programmers&#x2F;hackers sometimes like to make things more complicated than they need to be just for the fun of it (and learning experience too!). reply figmert 3 hours agoprevIncidentally, this is probably the best getting started guide for pfSense. When I set mine up last year, all tutorials were lacking. It was usually just installing pfSense, or some random settings that anyone would probably go through anyway. Took me awhile to collate the relevant information and set up my pfSense. I did eventually removed it and installed OPNSense, which has similar issues. reply sgammon 33 minutes agoprevRemember, app authors, pin your cert roots! :) reply quwert95 4 hours agoprevI applaud the author for the depth and detail - this is fantastic. Well done! reply speedgoose 3 hours agoprevOn a side note, I noticed a rare tracking consent banner. You may want to update it to track users and respect GDPR correctly. It should be possible to refuse as easily as accepting to be tracked, with the same button size and colour, for example. The tracking should start after consent is given. Also, GDPR isn’t so much about accepting cookies but giving consent to be tracked. So many websites get it wrong, and the likelihood that you will have issues is very close to zero, but since it looks like you implemented your banner yourself, you may be interested. reply jampekka 1 hour agoparentI interpret this as an opt-in as you can just scroll past the banner and not be tracked. If the site starts tracking without clicking the consent the banner is useless, or maybe even worse than useless, from the legal point of view.It&#x27;s maddening how people just refuse to understand the GDPR. This is likely partly due to intentional misinformation campaigns from the spyware (i.e. advertisement) industry. And then the cargo cult takes care of the rest.The general gist of GDPR is that if you&#x27;re not doing some shady shit that your visitors wouldn&#x27;t want you to do, you don&#x27;t need a consent. As you said, it has nothing to do with cookies.And yes, Google Analytics etc are shady shit that your visitors wouldn&#x27;t want you to do.Also most of the nags you see all the time are illegal for any sane intepretation of the law. But the regulators just don&#x27;t care to enforce the law at all. So if you want to do shady shit, just do it without adding to the insult with having to bother with your illegal nag. reply sgammon 4 hours agoprevthat&#x27;s not really a \"flaw\" in protobuf; the protobuf is Working As Intended by decoding the field in a different place when you modify it.i am not sure how one could possibly characterize that as a \"flaw,\" since protobuf is a field-numeric length-prefixed protocol in the first place. it makes a (reasonable) assumption that bytes won&#x27;t be messed with over the wire, leaving integrity to the reader, so even if this _was_ a flaw, it would be a flaw in the YouTube app for iOS, not in protobuf...since it isn&#x27;t a flaw, it isn&#x27;t an \"exploit,\" unless you are referring to the fact that youtube&#x27;s protobuf exchange on their iOS app isn&#x27;t checking hashes for returned payloads.i suspect after this post they will reply newaccount74 3 hours agoparentYeah, that&#x27;s some weird editorializing on behalf of the author. The \"flaw\" is mentioned only in the headline, the text just explains how the format works. It&#x27;s not a flaw, just working as designed.There&#x27;s also this bit:> Google makes it computationally expensive to decode, alter, and re-encode without the C++ source proto filesYeah, it&#x27;s computationally expensive if you use unoptimized Python code to do it. If you write your code in C (or another compiled language) then scanning 1.8MB of protobuf code should be trivial, with or without the proto source files.I&#x27;m pretty sure that making Protobuf files hard to decode without sources is not a design goal. If it was, they did a pretty lousy job. reply kccqzy 3 hours agorootparentExactly. It&#x27;s not exactly computationally expensive if you can do it at 2GB&#x2F;s!https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26931581 reply fsckboy 3 hours agorootparentit&#x27;s computationally expensive if it&#x27;s more computation than all the other things you&#x27;d like your hardware to do, i think is a better definition. reply newaccount74 1 hour agorootparentNo, that&#x27;s not the issue.The author seemed to have parsed the protobuf data by converting it all to a huge hierarchy of thousands (millions?) of Python objects. Of course that is slow and takes a few seconds. That&#x27;s so many allocations!But if you are just looking for a specific tag, there&#x27;s no need for that, I&#x27;m pretty sure you can parse protobuf in place without allocations, which would be a million times faster. You could maybe even do it in Python with reasonable speed. reply layer8 58 minutes agoparentprevI don’t know how mandatory fields work in Protobuf, but to mitigate the attack, Google’s YouTube client could treat the field as mandatory and refuse service when it finds the field to be missing or having a default value. reply sgammon 39 minutes agorootparentProtocol buffers don&#x27;t always support \"default\" values, because certain types will include a protocol-default value. For example, a `bool` which is not present will return `false` instead of say, a nil type.Required fields were a feature of Proto2. In proto3 syntax (latest), the required field concept was dropped because it caused issues with protocol evolution and was easy to misuse.In essence, because of the backward and forward compatibility guarantees supported by protobuf, a \"required\" field must be required for the entire lifecycle of the protocol.For these reasons and others, protobuf takes a stance where unrecognized fields are not necessarily errors. If it took a strict stance and failed in this condition, the presence of new fields in an \"evolved\" protocol would be an error which would break forward compatibility; old clients would not be able to communicate with new servers, and vice versa.Protobuf guarantees that new fields will not break forward or backward compatibility.This is why parsing unknown fields in protobuf is a feature, working as intended, not a flaw. In some language SDKs for protobuf I believe you can customize this behavior but it really isn&#x27;t a good idea.This is also why the app authors might want to consider a hash instead. Tampering with the payload would break the hash, and without the schema, the author would not necessarily know where the hash was situated in the payload to fix it, or even that one is present at all. The complexity of recalculating the hash (assuming they find it) vastly multiplies the attacker&#x27;s burden at little cost to the application; adding a few rounds and a salt, for instance, would make this kind of attack significantly harder to pull off.It&#x27;s not perfect security, but it would certainly be better. reply layer8 19 minutes agorootparentWell, for the field in question, I imagine that it should be easy to distinguish meaningful content from whatever it defaults to when the field is missing. reply sgammon 14 minutes agorootparentAnyway, none of this would be a problem if the TLS tunnel broke because the cert failed to validate against an issuer pin shipped with the app. reply layer8 7 minutes agorootparentMaybe the reason they don’t do this is that many enterprise networks break up TLS. reply sgammon 16 minutes agorootparentprevIn this case since he mentions it&#x27;s a \"tree\" of data (he means a \"message\"), it would be a sub-object that would become an initialized default. So there would be an \"object\" there, but it would have no \"ads\" array in it, or what not.Protobuf does this so you can do `deep.dotted.paths` and you won&#x27;t get null exceptions (probably a side effect of starting partly in Java). The leaf fields end up as empty strings, `0`, `false`, or an empty array for repeated fields.It&#x27;s a neat trick to get it to ignore a field, just not a \"flaw.\" It&#x27;s actually a compatibility feature in disguise.(So it might be pretty hard to detect, versus the potentially-legitimate case of just not having any ads to show.) reply layer8 9 minutes agorootparentThe article actually shows a screenshot of the structure they are cutting off.I would think that a dummy object would be trivial to detect. replyplayingalong 4 hours agoparentprevIt says January 2022. So likely if they wanted to harden the protocol after the blog post, they would already have. reply sgammon 10 minutes agorootparentThanks for pointing that out, I hadn&#x27;t noticed that. reply can16358p 2 hours agorootparentprevBut perhaps the article has just got popular now, due to HN? reply SergeAx 2 hours agoprevActually, YouTube as a service holds quite a bit value for me, so I am happily paying for premium subscription, which removes ads and also gives access to YouTube Music. reply omnicognate 3 hours agoprevThe only alternatives to a service like youtube showing people ads are for its users to pay for it, for it to be funded through donations, for it to be run by the government and paid for through taxation or for it not to exist. I prefer the first or second approaches and Youtube is unusual among social media sites in actually giving me the first option. So I happily pay for premium and while I&#x27;d rather that were the only option (I think ad supported content is an inherently socially corrosive model) I dislike the attitude of those who reject ads but also refuse to pay.(Some people are unable to afford it but that&#x27;s an entirely separate social problem, and it would be unusual for somebody with the skills demonstrated in the article to be struggling to earn a living wage.)What I would be interested in this protobuf inspection approach for would be implementing some decent parental controls. I would very much like to be able to enable&#x2F;disable individual youtube channels. Currently all I can do is switch the whole site on and off. I have all the necessary infrastructure already, so I might give it a try. reply cannedbeets 3 hours agoparentThere are so many reasons to block ads. Aesthetics alone. Protecting your valuable time. Consenting to watching an ad is not the same as consenting to your entire life being tracked and monitored.But the most important issue is that as long as malware can spread through ads (https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Malvertising), everyone should be blocking all ads. reply nevi-me 2 hours agorootparentAnd instead paying for services if there&#x27;s the option, right?Or should we just continue consuming people&#x27;s services and effort while blocking what&#x27;s sometimes their only revenue stream?I&#x27;d rather not use a service if it has ads and I can&#x27;t remove them, instead of block them and make everyone else&#x27;s experience worse. reply BLKNSLVR 2 hours agorootparentprevGiven that neither Facebook nor Google can appropriately police the content of their own ad networks (to the extent that they&#x27;re the two biggest purveyors of malware and scams on the internet - in this rando&#x27;s opinion), there is no moral argument against blocking ads.In fact, not blocking internet advertising is a security risk.If they get their house in order my opinion may change, but there&#x27;s currently no business reason for them to change their existing lax systems; no pressure or threat from regulation to hold them liable for what they allow on their advertising networks. reply Vortigaunt 2 hours agorootparentprevYeah it&#x27;s gotten so bad that the FBI recommends an ad-blocker as a means to protect yourself from malicious sites.https:&#x2F;&#x2F;www.ic3.gov&#x2F;Media&#x2F;Y2022&#x2F;PSA221221?=8324278624 reply taberiand 3 hours agorootparentprevEveryone should block ads and everyone who can pay for the use of the platform should. reply harshitaneja 3 hours agoparentprevVery well put. I have tried to argue the same point here and on reddit in past. The only real argument against I get is from the privacy perspective. That people tend to use alternative youtube clients or other such hacks to be able to consume ad free content anonymously and with the current state of google are not very keen on providing it with more information about them. Personally I am trying to degooglify my life including working my own open source alternatives for some services I don&#x27;t find much other good alternatives for- google keep and google books. But my youtube usage pattern being the data shared with google is quite low on the priority list for me but reasonable minds can differ. On the other hand, if enough do start to pay for youtube premium then we would be able to much more fruitfully present our demands including for privacy when we are actual customers and not the product as in the current dynamics. reply userbinator 3 hours agoparentprevI dislike the attitude of those who reject ads but also refuse to pay.How is this any different from changing the channel, leaving the room, or just hitting the mute button and closing your eyes in the scenario of \"regular\" TV when adverts or any other content you don&#x27;t want to see appears? Compelled consumption should be illegal. reply chii 3 hours agorootparentThe assumption is that not many people would leave the room, close their eyes or mute the ads.If you created a painless, super easy way to remove all ads, i&#x27;m sure that TV channels will also find it hard to sell to advertisers, and thus, their revenue would decrease. reply pmontra 1 hour agorootparentMy last CRT TV had a picture in picture mode. When ads started I pressed the PiP button on the remote, placed the channel I was looking at in the PiP window and started watching something else. When the ads were over I came back to that channel or stayed on the other one if I found something more interesting.I watch TV on my tablet now, streamed from a Raspberry PI with a TV Hat. Again, I activate the popup player, start browsing, maybe checking HN or whatever. I put the volume off. Maybe I start doing something else. The advantage of a tablet is that I can bring it with me wherever I go in my house. The TV, not so much. I rarely switched on my TV in the past two years. reply Ntrails 2 hours agorootparentprevIn my household growing up the ads were almost always muted as soon as the roll started.I always found it bizarre that other people did not do the same reply month13 2 hours agorootparentThey train you to do this when they volume boost the ads to blow your eardrums out. reply lloeki 1 hour agorootparentOver here volume boosting is illegal, so instead they DSP ad audio to maximise envelope across all frequency bands.Since ad sections are your typical break from a program to get to the fridge or toilet or whatever, the DSP transform makes sure you still hear the ads and pick up dialog even when far away from the TV.Downmixing audio so that you can both hear dialogue and not lose eardrums to music and &#x27;splosions seems to be an intractable decades old problem for the movie industry but it sure as hell been solved a dozen times over by the ad biz. reply userbinator 39 minutes agorootparentYes, https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dynamic_range_compression#Mark... reply bigfudge 1 hour agorootparentprevIf you don’t hugely care about the quality it’s easier. Movies also want to use the dynamic range for effect but they sometimes rely on people have better home audio systems than they actually do. reply joosters 2 hours agorootparentprevThat always felt counterproductive to me. I knew people who did this and they still stared at the adverts. In fact, without the sound, you are probably focusing more on the ads, trying to figure out what is going on. reply Ntrails 33 minutes agorootparentI would agree, the whole point was to enable conversation without the distraction of the ad sounds. If you&#x27;re gonna watch the damned things anyway I&#x27;m not sure it helped reply silverpepsi 2 hours agorootparentprevMy grandparents did that, it was one of the principle annoyances I had with visting them as a kidIt was very shocking to go from 75dB to an ambient 30dB or something like that out in the countryside. I&#x27;d have much preferred to talk over or zone out over the commercials without the suddenly shocking lack of auditory stimulus! reply userbinator 2 hours agorootparentprevIf you created a painless, super easy way to remove all adsWe had that almost 3 decades ago:https:&#x2F;&#x2F;www.orlandosentinel.com&#x2F;1995&#x2F;09&#x2F;20&#x2F;with-this-vcr-com... reply SkiFire13 2 hours agorootparentprevIf the ad is displayed but you don&#x27;t watch it you&#x27;re hurting the advertiser, but id the ad is not displayed at all you&#x27;re hurting the platform. reply Dfiesl 2 hours agorootparentSerious question here. What&#x27;s the difference between not responding to the ad in any meaningful way vs blocking the ad entirely? Does youtube know when you&#x27;ve blocked the ad and therefore the content creator earns less ad revenue? reply hurril 2 hours agorootparentprevWe need to differentiate a little more here. Instead of me having to watch another f*ing viagra ad, since I&#x27;m male and above 40, we should instead talk about substituting ads with getting actual fecal matter thrown at us. Your argument still applies. I should accept this because it is in my interest to support advertisers, since, really, I work for one. (In that I work for a private company that also pays for ads.)Now before you dismiss this as childish and&#x2F; or obnoxious: please consider the point. We cannot gloss over _what_ we \"have\" to watch and not just that it&#x27;s an ad.It is true that things have to be paid for and I am 100% for this. But if you want me to basically degrade myself in order for me to get to watch your content, then wtf? reply nolok 2 hours agorootparentprevIt&#x27;s different becaue regular broadcast TV pay a fee to get the channel out of a limited amount of available spot, and then use that limited available spot to have higher ad price.Of course on cabled channels, they get part of the fee of your package.There is no \"compelessed consumption\", there is available package \"this for free with ads\", or \"this for a fee\", you&#x27;re free to chose the one you want or neither.I&#x27;m certain your company whichever it is would have an issue if I wanted to use its services but then run away when it came time to pay the bill. reply beirut_bootleg 2 hours agoparentprev> I dislike the attitude of those who reject ads but also refuse to payAnd I dislike YouTube&#x27;s hostile ad escalation in recent years. One ad - fine, two ads - hmmm, three ads - what the hell. Unskippable ads. Inappropriate ads. Loud-ass eardrum ripping ads. Ads even on Premium. reply stingraycharles 2 hours agorootparentI have premium but don’t see any ads, except the sponsorships of the creators themselves. Which is a bit annoying but not a lot YouTube can do about. reply yard2010 42 minutes agorootparentI don&#x27;t know maybe auto skip on them for premium users? I have an extension that does just that, surely google can do it too reply pbhjpbhj 1 hour agorootparentprev>not a lot YouTube can do about. &#x2F;&#x2F;They&#x27;ve tried? It seems like it would be pretty easy to detect ad sequences in larger channels. reply anilakar 2 hours agorootparentprevAnd even if you get rid of the ads, the sponsored content is not going anywhere. reply a_imho 2 hours agoparentprevI find this a false proposition, there are plenty of other ways to to support a video streaming platform. There is nothing that suggest a platform like youtube has to exist in it&#x27;s current form either. If a monetizing strategy does not work it is not the users holding it wrong. People consumed videos online before youtube and will be consuming after youtube just fine. It is not like Google is the creative mind behind the content either, in fact, the streaming part is by far the most boring problem.I really dislike the attitude of defending megacorps and worrying about their bottom lines, especially anti customer ones like Google. reply alsodumb 2 hours agorootparentYou claim that there are plenty of other ways to support a video streaming platform yet fail to mention even one of them.Things cost money. Every monetizing strategy involves users paying for it or the company making money from the users indirectly. OP mentions both of these. So tell me, what&#x27;s a monetizing strategy other than these that works?People consumed videos online at a very limited scale before YouTube, and those videos were usually hosted by few, generous individuals. Even if every user in the world decides to contribute 50% of their device storage for a decentralized streaming platform, I doubt it would even fit a small part of all videos in YouTube&#x27;s catalog right now.I really dislike the attitude of hating megacorps without really proposing any viable alternatives. reply a_imho 1 hour agorootparentNitpicking alternatives is not the main point. There is nothing that suggest a platform like youtube has to exists in its current form.Consider a freemium model without the threat of adxtortion, obviously this would require youtube to offer a significant value add and&#x2F;or premium content besides trying to be a monopoly and gatekeeping eyes. Make it purely subscription based (e.g. Netflix before ads). Ask creators to pay for the blue checkmark. Make it a loss leader. Plenty of adult streaming sites manages to do just fine without youtube style invasive ads. I&#x27;m sure much smarter people can name countless other ways as well, it also does not need to be a 1-1 alternative either. reply fsflover 2 hours agorootparentprev> There is nothing that suggest a platform like youtube has to exist in it&#x27;s current form either.This. PeerTube can provide similar benefits without centralization. reply vintermann 2 hours agoparentprevBy the same logic, it&#x27;s irresponsible to watch ads and not buy the products. That&#x27;s after all what keeps the wheels turning.I remember I had this discussion after a school political debate in the 90s, with (adult) actual politicians. Textbooks at the time were not publicly funded, and naturally the textbook companies jacked up prices for their captive audience forced to buy their books.This one party had the \"brilliant\" idea of ad-funded textbooks. I asked, if the textbook companies currently take $50 for the book, if it was instead funded by say McDonalds ads, how many extra burgers would each student have to buy that year? They didn&#x27;t have any good answer to that. reply sneak 40 minutes agorootparentNone. The textbooks would then be subsidized by McDonalds&#x27; advertising budget, reducing their profit margin.It&#x27;s the same as blocking YouTube ads; Google still pays the creator as if you had watched the ads, so your video playback is being subsidized by Google&#x27;s ad business profits.When you choose not to block ads, you aren&#x27;t \"supporting creators\", you are supporting Google shareholders. reply riidom 40 minutes agorootparentprevThis happened for real, actually, at least some german science fiction publishing houses did that. They would \"insert\" a page into the book, which picks up the story in some really cheesy way and then bends in within two sentences towards the main character needing a quick soup now (the advertise was for soup always, they just had that one sponsor apparently).See here (picture gallery): https:&#x2F;&#x2F;johannes.freudendahl.net&#x2F;2019&#x2F;01&#x2F;werbung-in-romanen&#x2F;The introduction goes like: \"Only Kirk kept helping himself, because he was convinced he would need strength for the upcoming events.\" and then below the black bars the actual ad: \"The reader should do same bla e.g. soup bla takes just 5 minutes etc\"Just some anecdote. reply FireInsight 3 hours agoparentprevI use Youtube through Piped (https:&#x2F;&#x2F;github.com&#x2F;TeamPiped&#x2F;Piped) to preserve privacy, block ads, and prevent getting sucked in by the algorithm.The only part of Youtube that I find valuable is the content. Not the UI, not the comments, algorithm. Free content hosting is nice, but it&#x27;s not the only platform hosting videos for free.If I wanted to pay for a streaming service, it&#x27;d be Nebula (https:&#x2F;&#x2F;nebula.tv&#x2F;), because I know it benefits creators.But I&#x27;m never turning off the adblocker, thank you. reply izacus 2 hours agorootparent> If I wanted to pay for a streaming service, it&#x27;d be Nebula (https:&#x2F;&#x2F;nebula.tv&#x2F;), because I know it benefits creatorsHuh? Ad revenue and Premium subscription also ends up as direct payouts for YouTube creators, what are you talking about? Why the need for this BS? reply FireInsight 16 minutes agorootparentMaybe it&#x27;s just my bubble, but it is often I hear that \"Our Nebula subscribers fund this show, we couldn&#x27;t do this with youtube revenue alone\" or \"Signing up to Nebula with my link gives me a steady source of income that youtube just cannot provide\". reply sspiff 2 hours agorootparentprevWhile Nebula has some creators om it that I follow, no platform comes close to having the broad collection of channels YouYube does.I follow a wide variety of channels, but there are maybe a dozen to 20 that I would consider essential. Maybe 3-4 are on Nebula.I think for a lot of viewers and creators, YouTube is simply inevitable at this point. reply pixelesque 26 minutes agorootparentOn top of that, in my experience both CuriousityStream and Nebula&#x27;s search functionality is pretty bad: I got fed up of the number of times I searched for something mentioned in a spoken \"advertisment\" by users like Mustard on youtube who said they have extra content on those services and then I can&#x27;t find it or find out how to list all videos by those users, I stopped my subscription to them... reply chii 2 hours agorootparentprev> it&#x27;s not the only platform hosting videos for free.You&#x27;re only looking at this from your own point of view. The content producers are looking for monetization options, and youtube is the only game. Nebula might be sufficient for some small amount of content producers, but it&#x27;s unlikely to hit mainstream, and not enough people want to pay.It&#x27;s unfortunate, but ads are the only game in town on the internet atm. reply commoner 2 hours agorootparentprevPiped is a great web-based service, but since tvOS does not support web browsers on the Apple TV, to block YouTube ads, you either have to stream Piped videos to the Apple TV from another Apple device using AirPlay screen mirroring or use a workaround like the one described in TFA.I&#x27;m using NewPipe (https:&#x2F;&#x2F;newpipe.net) on Android TV which provides an ad-free YouTube experience just like the Android phone version of NewPipe. Piped would also work on an Android TV browser like TV Bro (https:&#x2F;&#x2F;github.com&#x2F;truefedex&#x2F;tv-bro).The legitimacy of ad blocking is well-established. People have been using DVRs, VHS players, and tape recorders to capture and consume ad-free broadcasts for decades. reply Scoundreller 3 hours agoparentprev> So I happily pay for premium and while I&#x27;d rather that were the only option (I think ad supported content is an inherently socially corrosive model)Still doesn&#x27;t protect you from in-video sponsorships (skullshare, OstVPN, etc.), product placements, etc. Some creators especially do these because it protects them from platform demonetization risk.Same shit with paying for cabletv & movie theatre tickets. If anything, people that pay are their most valuable targets for ads.Even a newspaper that I sub to runs ads and a zillion trackers against me. Ugh.I get where you&#x27;re coming from, but the platform could more to protect paying members from this. E.g. creators with over $x revenue must tag promos so the platform ships them for paying users reply jcronenberg 2 hours agorootparentTo me at least the sponsorblock extension is completely ethical when you are using youtube premium. The creators get paid extra for a premium view anyway, plus I don&#x27;t think advertisers for in video ads pay per view of that segment (if there are even tools to detect that metric) or anything like that so you&#x27;re not even hurting the creator. But I agree that something built in by youtube for premium users would be nicer. Would get youtube more premium users too I think because I was e.g. initially hesitent too of buying premium because I knew I would still be getting in video sponsors. reply scrollaway 2 hours agorootparentprevIt doesn’t, but Nebula does. Creators don’t put sponsorships in their Nebula videos. And they had a lifetime subscription recently so personally I jumped on it and don’t have to deal with Yet Another Subscription… reply dijit 3 hours agoparentprevI’m in the exact same mindset as you; youtube allows you to pay to rid yourself of ads (which is ironic because the more free you are with money the more attractive you must be to advertisers)- so I think they are better than most.but if I must take an alternative position: the last time I used youtube without premium (which happens sometimes because its not so smooth to log in if its a temporary session); the number and length of the ads was absurd, multiple levels of unskippable ads, minutes long, with volume that is much higher than the content itself. Awful experience and I can see why people who don’t have the free money want to lower it a little.Thats of course not including sponsored content which contains an ad inside the video itself- even YT premium users get those. reply nerbert 2 hours agorootparentThere are extensions that mark these \"premium\" ads and let you skip them. reply BLKNSLVR 2 hours agoparentprevI can be a petty individual at times, and the thing that convinced me to never pay a cent to youtube was their removing the ability for the app to continue to play the clip in the background when switching to another app or locking the phone.I listen to news and podcast-esque things in the car going to work or school drop-off &#x2F; pick-up, on the way to sport etc. I&#x27;d begrudgingly tolerate the ads if the app background-played but it doesn&#x27;t without paying for premium. I&#x27;m somewhere on an \"entitlement\" scale here, but background-play being a premium feature really feels like it&#x27;s stretching the friendship.So... alternative front-end it is. Great experience and no ads to boot. reply sfifs 2 hours agorootparent> removing the ability for the app to continue to play the clip in the background when switching to another app or locking the phone.Do you know that the paid version has this exact feature? This is a limitation of the ad-supported version, because advertisers are paying to actually have people watch their ad. reply BLKNSLVR 2 hours agorootparentYes reply izacus 2 hours agorootparentSo they didn&#x27;t remove it did they? You just refuse to pay for that service and spread bs to make you feel better? reply BLKNSLVR 2 hours agorootparentThey removed it from in front of the paywall to behind the paywall. The non-paid version used to do it. It was a memorably jarring experience working out WTF happened when background-play was rugged. reply izacus 1 hour agorootparentI don&#x27;t remember it ever playing in the background without a sub, when was that? replyconradfr 1 hour agorootparentprevUse the YouTube mobile site within Firefox. reply SergeAx 2 hours agorootparentprevThe said ability also exists in a premium subscription. So what you effectively saying is that YouTube offers you a valuable feature, but you refuse to pay for it. reply Tepix 2 hours agorootparentYouTube is not offering a valuable feature here. It&#x27;s an OS feature. YouTube is going out of its way for you not to have this feature, unless you pay them (even though it wasn&#x27;t them who brought you the feature to begin with). I understand why this upsets people.Imagine Youtube preventing you from adjusting the volume unless you paid. This is similar. reply rightbyte 2 hours agorootparentprevIt is fair to not want pay enshittification tax to rent seekers.The said ability exists on the YT website if you use desktop mode on the mobile browser. reply izacus 2 hours agorootparentAsking you to pay for service costs and content is not rent seeking. That&#x27;s not what that phrase means. reply yard2010 47 minutes agorootparentNo but you have to agree on the enshitification part. Youtube turned to one of the worst UX apps I have on my phone, I hate paying them for such a shitty product and I&#x27;m waiting for the time they&#x27;re off this planet reply laserlight 37 minutes agorootparentprevGiven that YouTube is a monopoly, I would call it rent seeking. reply BLKNSLVR 2 hours agorootparentprevCorrect. reply fsckboy 3 hours agoparentprevI too am happy pay for nice things, but I am never happy to pay a monopolist just on principle; so I don&#x27;t. reply chpatrick 2 hours agorootparentBut you&#x27;re happy to use the monopolist&#x27;s service. reply fsckboy 2 hours agorootparentyes, absolutely, but only inasmuch as it only decreases their producer surplus so it doesn&#x27;t actually cost them anything. If the monopolist allowed competition, then I&#x27;d evaluate and choose, but I don&#x27;t have that choice till then. reply chpatrick 1 hour agorootparentYou could choose to not use YouTube out of principle.Besides these days it&#x27;s barely a monopoly with TikTok. reply rplnt 3 hours agoparentprevThe issue with paying for youtube premium is that you are still left with tons of ads. Until YouTube themselves doesn&#x27;t tackle this issue as it should I refuse to pay to see sligtly less ads. reply trollied 2 hours agorootparentI pay for YouTube premium and have never seen an ad. Not sure what&#x27;s happening with you. reply master-lincoln 1 hour agorootparentHalf of the content on YouTube could be considered to be an ad by itself. Also sponsors are being advertised regularly within videos which I would consider to be ads too reply Aaron2222 7 minutes agorootparentThere&#x27;s always SponsorBlock: https:&#x2F;&#x2F;sponsor.ajay.app&#x2F; reply layer8 41 minutes agorootparentprevIt strongly depends on the kind of content you watch. I watch a lot of YouTube, but hardly any of it has sponsored content. reply joosters 2 hours agoparentprevNowhere in YouTube’s voluminous terms of service does it say that you have to watch the ads.Why are you defending a multi billion dollar company from something that the users aren’t obliged to do in the first place? reply SnorkelTan 2 hours agoparentprevPeople paid for cable and they still forced ads on people. reply izacus 2 hours agorootparentAnd YouTube doesn&#x27;t. And you can stop paying when they do. reply fsflover 2 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37280072 reply layer8 39 minutes agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37280895 reply megous 1 hour agoparentprevIt&#x27;s possible to download stuff you like, for free, without being funded by donations, ads, or being run by the government. P2P.People using their excess Internet connectivity, they already pay for for other reasons, to share content with others.It works for socially disadvantaged, too. reply squarefoot 2 hours agoparentprev> I dislike the attitude of those who reject ads but also refuse to pay.What about fair advertising? The main problem here nobody dares to talk about because dealing with it would undermine the very essence of capitalism: unlimited growth, is that there is no way to have fair advertising exactly as there&#x27;s no way to have a fair use of any resources. Once you allow anything to be used for profit, it will be abused from the strongest players at the expense of the others until the last drop. It would be extremely easy to put well defined limits on how much advertising can be shown, and make the Internet a better place, but no way, it&#x27;s anti capitalistic and therefore a no-no. Ad blockers weren&#x27;t born the same day advertising came to the Internet, and many years passed until someone realized we needed them; that was the day surfing became such a horrid experience thanks to unlimited, pervasive and ever growing advertising.edit: and, by the way, I still have to see some company going bankrupt because of ad blockers. reply samstave 3 hours agoparentprevDoes anyone recall when cable TV first came out - \"Pay for cable, see no ads!!!\"That didn&#x27;t last long... reply oneshtein 2 hours agorootparentYou can go to the cinema, buy a ticket, buy a popcorn, and then watch ads there. reply yard2010 44 minutes agorootparentThis is why you enter the theater 20 minutes after the hour that is written on the ticket reply happytiger 3 hours agoparentprevYou mean like PBS?But now they have ads. reply Teever 2 hours agoparentprevThat&#x27;s a way to look at it, and another way to look at it is this:I already pay Google much more than I care to and am willing to in the form of my privacy and personal data because of the ubiquitious surveillance that Google performs on as many people as they possibly can.If I could cut Google out of my life I would do it in an instant, but I can&#x27;t because they won&#x27;t allow it. In lieu of that I take whatever I can from them.“To steal from a brother or sister is evil. To not steal from the institutions that are the pillars of the Pig Empire is equally immoral.” -- Abbie Hoffman reply izacus 2 hours agorootparentIf you could cut Google out easily, you wouldn&#x27;t be using YouTube. Who are you lying to, yourself or us? reply mattigames 3 hours agoparentprevBy that logic we shouldn&#x27;t be even a allowed to look away or mute our sound when the ads are playing, after all if enough people did it it would be just as \"damaging\" as people with ad blockers.Also, YouTube is a video streaming monopoly, if it didn&#x27;t exist there would be a significant chance of new streaming platforms to succeed, but given that it captured the marked such chance is unlikely to exist, monopoly that they achieved hosting videos free of ads (or very light on these) and now that they have the control want to force people to pay or watch a ridiculous amount of ads. reply userbinator 2 hours agorootparentIf the advertisers had their way unimpeded, we&#x27;d be in \"drink verification can\" territory now. reply mattigames 2 hours agorootparentIn case some people here don&#x27;t know about that reference: https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;4chan&#x2F;comments&#x2F;1ggg4u&#x2F;please_drink_... reply redrove 3 hours agoprev>I propose heuristically scanning for query and path parameters of ad URLs with high entropy and using those as keys (fingerprints).>https:&#x2F;&#x2F;xn--rr6sn-uxa0n-t8gz-vg6i.googlevideo.com&#x2F;initplayba... &orc=1&oeis=1&c=IOS&oss=1&oda=1&oad=5500&ovd=5500&oaad=11000&oavd=11000 &ocs=700&oputc=1&oses=1&ofpcc=1&osbr=1&osnz=1&msp=1&odeak=1&odepv=1 &osfc=1&id=58cc678216d6aaca&ip=121.35.98.26&initcwndbps=2125000 &mt=1640373902This is one of the many things that make it _exactly_ like malware. Ads are delivered the same way malicious code or artifacts would be delivered to your device.Weird-ass random subdomains, obfuscated query params -- no legitimate service that works for the user&#x27;s benefit should behave like this. reply thrdbndndn 3 hours agoparent>_exactly_ like malwareBut it&#x27;s googlevideo.com. I know this is Google&#x2F;YouTube&#x27;s domain so the rest doesn&#x27;t matter. reply BLKNSLVR 1 hour agorootparentBut it&#x27;s googlevideo.com, how could it be a video of some shyster pimping get-rich-quick investment schemes that are convincing enough to appear totally legit to anyone below the half-way point of the bell curve?But it&#x27;s a google ad, how could it link to a scam that looks exactly like my bank&#x27;s website? reply redrove 3 hours agorootparentprevWhich is besides the point and a minor nitpick at best.The fact of the matter is these techniques are well established black hat ways of preventing the user from discovering what you&#x27;re doing on their device. reply thrdbndndn 2 hours agorootparentDiscovering what exactly? To bad they don&#x27;t use a subdomain called \"adplayback\" I guess, but the query parameters are obviously only useful for YouTube internal, not the users.And I won&#x27;t even call them \"obfuscated\" -- it&#x27;s just a batch of switches and plain IP and ID hash. reply userbinator 3 hours agoparentprevBack when YouTube wasn&#x27;t owned by Google, replacing &#x2F;watch?v=... with &#x2F;get_video?video_id=... in the URL would immediately give you the video file (in FLV format, of course.) reply redrove 3 hours agorootparentThere was also a relatively brief time when YT was owned by google but ads were delivered from a separate (sub)domain so DNS adblocking would work wonders.Those days are gone as the distinction between ads and malware becomes a technicality. reply veavo 2 hours agoparentprevIn HN I expect a better analysis than \"this looks complicated so it must be bad\". That&#x27;s the kind of logic that someone who knows nothing about computers has. reply redrove 2 hours agorootparentYes, I evidently compared the obfuscation techniques to malicious actors because I know nothing about computers! reply taspeotis 4 hours agoprevThe real tragedy:> In fact, the YouTube app is zippier because fewer connections are made to ad URLs in the first place.I swear on LG TV that webOS runs at a smooth 60 FPS when it&#x27;s not connected to Wi-Fi and slows down as soon as it phones home for whatever telemetry and ads LG intend to serve me... reply rrrrrrrrrrrryan 3 hours agoparentFor LG TVs, if you set the region to \"Other,\" it completely disables all the ads, recommended content, and telemetry [1], presumably because they can&#x27;t keep track of all the changing laws for every nation on earth.In my experience, there was a noticable performance improvement as well. Bootup times alone are probably 2x-3x faster.[1] https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LGOLED&#x2F;comments&#x2F;1571djx&#x2F;guide_how_t... reply todd3834 4 hours agoparentprevIn a previous role I was tasked with increasing the lighthouse&#x2F;pagespeed score across some web properties. After some iterations and very little improvements we would be asked what else we could do. Did we need to speed up the backend? Could we lower latency, etc…The solution: I set up a query param that would disable google tag manager. All of the crazy tracking and telemetry stuff we didn&#x27;t control was the biggest issue. reply j16sdiz 4 hours agorootparentThose analystic spend most of its time trying to tell bots apart from real browsers. This is basically an arm race.I am not sure who is to blame, but I guess there is no way we can get the simple web we loved back. reply internet101010 3 hours agoparentprevConnecting smart TVs to the internet is always a net negative. reply mafuyu 2 hours agoparentprevYou&#x27;re not imagining it! The ads slow down webOS a lot, and blocking them with pi-hole made my TV much more usable. I highly recommend setting up pi-hole or similar, and blocking all the LG domains it tries to hit.I commented about it a while back here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34374725 reply j16sdiz 4 hours agoparentprevThis shows how little they care, or poor engineering, or both.Failing all engineering effort, they could have use a beefer CPU... reply gabereiser 4 hours agorootparentSo they can run more ads, negating the performance boost. The answer isn’t simply throw more cpu at the problem. reply te_chris 3 hours agoparentprevI’ve never connected my c2 to the internet and it’s great. reply lacoolj 1 hour agoprev [3 more] [flagged] regedit728 1 hour agoparentYou bought the laptop&#x2F;PC&#x2F;television. You request for data from a remote host.The remote host serves you the content. The remote host is also entitled to serve you ads, since they own their end of the communication.You view the content. You are also entitled to not view the ad, since you own the device at which you&#x27;re viewing their content. reply nelblu 1 hour agoparentprev [–] Because for some of us it is distracting, they are loud and obnoxious. Also, the obvious one - limited time to watch TV. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author explores various methods and tools to block YouTube ads on Apple TV, including decrypting and manipulating Protocol Buffer data.",
      "They discuss the importance of privacy and the negative effects of ads and tracking.",
      "The author sets up a pfSense router and multiple access points, discusses network configurations, troubleshoots issues, and experiments with using a VPN to change their YouTube location and avoid ads."
    ],
    "commentSummary": [
      "The discussion addresses methods to block YouTube ads on AppleTV and the impact of ad-blockers on creators and Google's ad revenue.",
      "It explores alternatives to support creators on YouTube, such as platforms like Patreon.",
      "Privacy and security concerns, including issues with downmixing audio in movies, are discussed, along with frustrations with YouTube's features and excessive ads."
    ],
    "points": 475,
    "commentCount": 192,
    "retryCount": 0,
    "time": 1693105993
  },
  {
    "id": 37274871,
    "title": "Slack’s migration to a cellular architecture",
    "originLink": "https://slack.engineering/slacks-migration-to-a-cellular-architecture/",
    "originBody": "Skip to content Search for: Search Slack’s Migration to a Cellular Architecture Cooper Bethea Senior Staff Engineer, Cloud 9 minutes • Written 4 days ago Summary In recent years, cellular architectures have become increasingly popular for large online services as a way to increase redundancy and limit the blast radius of site failures. In pursuit of these goals, we have migrated the most critical user-facing services at Slack from a monolithic to a cell-based architecture over the last 1.5 years. In this series of blog posts, we’ll discuss our reasons for embarking on this massive migration, illustrate the design of our cellular topology along with the engineering trade-offs we made along the way, and talk about our strategies for successfully shipping deep changes across many connected services. Background: the incident TCP retransmits by AZ, 2021-06-30 outage At Slack, we conduct an incident review after each notable service outage. Below is an excerpt from our internal report summarizing one such incident and our findings: At 11:45am PDT on 2021-06-30, our cloud provider experienced a network disruption in one of several availability zones in our U.S. East Coast region, where the majority of Slack is hosted. A network link that connects one availability zone with several other availability zones containing Slack servers experienced intermittent faults, causing slowness and degraded connections between Slack servers and degrading service for Slack customers. At 12:33pm PDT on 2021-06-30, the network link was automatically removed from service by our cloud provider, restoring full service to Slack customers. After a series of automated checks by our cloud provider, the network link entered service again. At 5:22pm PDT on 2021-06-30, the same network link experienced the same intermittent faults. At 5:31pm PDT on 2021-06-30, the cloud provider permanently removed the network link from service, restoring full service to our customers. At first glance, this appears to be pretty unremarkable; a piece of physical hardware upon which we were reliant failed, so we served some errors until it was removed from service. However, as we went through the reflective process of incident review, we were led to wonder why, in fact, this outage was visible to our users at all. Slack operates a global, multi-regional edge network, but most of our core computational infrastructure resides in multiple Availability Zones within a single region, us-east-1. Availability Zones (AZs) are isolated datacenters within a single region; in addition to the physical isolation they offer, components of cloud services upon which we rely (virtualization, storage, networking, etc.) are blast-radius limited such that they should not fail simultaneously across multiple AZs. This enables builders of services hosted in the cloud (such as Slack) to architect services in such a way that the availability of the entire service in a region is greater than the availability of any one underlying AZ. So to restate the question above — why didn’t this strategy work out for us on June 30? Why did one failed AZ result in user-visible errors? As it turns out, detecting failure in distributed systems is a hard problem. A single Slack API request from a user (for example, loading messages in a channel) may fan out into hundreds of RPCs to service backends, each of which must complete to return a correct response to the user. Our service frontends are continuously attempting to detect and exclude failed backends, but we’ve got to record some failures before we can exclude a failed server! To make things even harder, some of our key datastores (including our main datastore Vitess) offer strongly consistent semantics. This is enormously useful to us as application developers but also requires that there be a single backend available for any given write. If a shard primary is unavailable to an application frontend, writes to that shard will fail until the primary returns or a secondary is promoted to take its place. We might class the outage above as a gray failure. In a gray failure, different components have different views of the availability of the system. In our incident, systems within the impacted AZ saw complete availability of backends within their AZ, but backends outside the AZ were unavailable, and vice versa systems in unimpacted AZs saw the impacted AZ as unavailable. Even clients within the same AZ would have different views of backends in the impacted AZ, depending on whether their network flows happened to traverse the failed equipment. Informally, it seems that this is quite a lot of complexity to ask a distributed system to deal with along the way to doing its real job of serving messages and cat GIFs to our customers. Rather than try to solve automatic remediation of gray failures, our solution to this conundrum was to make the computers’ job easier by tapping the power of human judgment. During the outage, it was quite clear to engineers responding that the impact was largely due to one AZ being unreachable — nearly every graph we had aggregated by target AZ looked similar to the retransmits graph above. If we had a button that told all our systems “This AZ is bad; avoid it.” we would absolutely have smashed it! So we set out to build a button that would drain traffic from an AZ. Our solution: AZs are cells, and cells may be drained Like a lot of satisfying infrastructure work, an AZ drain button is conceptually simple yet complicated in practice. The design goals we chose are: Remove as much traffic as possible from an AZ within 5 minutes. Slack’s 99.99% availability SLA allows us less than 1 hour per year of total unavailability, and so to support it effectively we need tools that work quickly. Drains must not result in user-visible errors. An important quality of draining is that it is a generic mitigation: as long as a failure is contained within a single AZ, a drain may be effectively used to mitigate even if the root cause is not yet understood. This lends itself to an experimental approach wherein, during in an incident, an operator may try draining an AZ to see if it enables recovery, then undrain if it does not. If draining results in additional errors this approach is not useful. Drains and undrains must be incremental. When undraining, an operator should be able to assign as little as 1% of traffic to an AZ to test whether it has truly recovered. The draining mechanism must not rely on resources in the AZ being drained. For example, it’s not OK to activate a drain by just SSHing to every server and forcing it to healthcheck down. This ensures that drains may be put in place even if an AZ is completely offline. A naive implementation that fits these requirements would have us plumb a signal into each of our RPC clients that, when received, causes them to fail a specified percentage of traffic away from a particular AZ. This turns out to have a lot of complexity lurking within. Slack does not share a common codebase or even runtime; services in the user-facing request path are written in Hack, Go, Java, and C++. This would necessitate a separate implementation in each language. Beyond that concern, we support a number of internal service discovery interfaces including the Envoy xDS API, the Consul API, and even DNS. Notably, DNS does not offer an abstraction for something like an AZ or partial draining; clients expect to resolve a DNS address and receive a list of IPs and no more. Finally, we rely heavily on open-source systems like Vitess, for which code-level changes present an unpleasant choice between maintaining an internal fork and doing the additional work to get changes merged into upstream. The main strategy we settled on is called siloing. Services may be said to be siloed if they only receive traffic from within their AZ and only send traffic upstream to servers in their AZ. The overall architectural effect of this is that each service appears to be N virtual services, one per AZ. Importantly, we may effectively remove traffic from all siloed services in an AZ simply by redirecting user requests away from that AZ. If no new requests from users are arriving in a siloed AZ, internal services in that AZ will naturally quiesce as they have no new work to do. Our original architecture. Backends are spread across AZs, so errors present in frontends in all AZs. And so we finally arrive at our cellular architecture. All services are present in all AZs, but each service only communicates with services within its AZ. Failure of a system within one AZ is contained within that AZ, and we may dynamically route traffic away to avoid those failures simply by redirecting at the frontend. Siloed architecture. Failure in one AZ is contained to that AZ; traffic may be routed away. Siloing allows us to concentrate our efforts on the traffic-shifting implementation in one place: the systems that route queries from users into the core services in us-east-1. Over the last several years we have invested heavily in migrating from HAProxy to the Envoy / xDS ecosystem, and so all our edge load balancers are now running Envoy and receive configuration from Rotor, our in-house xDS control plane. This enabled us to power AZ draining by simply using two out-of-the-box Envoy features: weighted clusters and dynamic weight assignment via RTDS. When we drain an AZ, we simply send a signal through Rotor to the edge Envoy load balancers instructing them to reweight their per-AZ target clusters at us-east-1. If an AZ at us-east-1 is reweighted to zero, Envoy will continue handling in-flight requests but assign all new requests to another AZ, and thus the AZ is drained. Let’s see how this satisfies our goals: Propagation through the control plane is on the order of seconds; Envoy load balancers will apply new weights immediately. Drains are graceful; no queries to a drained AZ will be abandoned by the load balancing layer. Weights provide gradual drains with a granularity of 1%. Edge load balancers are located in different regions entirely, and the control plane is replicated regionally and resilient against the failure of any single AZ. Here is a graph showing bandwidth per AZ as we gradually drain traffic from one AZ into two others. Note how pronounced the “knees” in the graph are; this reflects the low propagation time and high granularity afforded us by the Envoy/xDS implementation. Queries per second, by AZ. In our next post we’ll dive deeper into the details of our technical implementation. We’ll discuss how siloing is implemented for internal services, and which services can’t be siloed and what we do about them. We’ll also discuss how we’ve changed the way we operate and build services at Slack now that we have this powerful new tool at our disposal. Stay tuned! infrastructurenetworking Search for: Search Post Types Post (151) Categories Uncategorized (132) Tags javascript (20) infrastructure (18) performance (13) software-development (13) android (12) Year 2023 (8) 2022 (21) 2021 (24) 2020 (26) 2019 (21) Most Recent Service Delivery Index: A Driver for Reliability @Slack Engineering Real-time Messaging @Sameera Thangudu Photo by Daria Nepriakhina on Unsplash Tracing Notifications @Slack Engineering @SlackEng how can I stay up-to-date on what's happening over there? Follow us on Twitter Post navigation PREVIOUS POST Previous post: Service Delivery Index: A Driver for Reliability Recommended Reading How We Use Terraform At Slack @Archie Gunasekara What We Learned from Building GovSlack @Archie Gunasekara@Andrew Martin Photo by Vecteezy Recommend API @Katrina Ni@Aaron Maurer Slack uses cookies to allow us to better understand how the site is used. By continuing to use this site, you consent to this policy. Click to learn more.",
    "commentLink": "https://news.ycombinator.com/item?id=37274871",
    "commentBody": "Slack’s migration to a cellular architectureHacker NewspastloginSlack’s migration to a cellular architecture (slack.engineering) 340 points by serial_dev 16 hours ago| hidepastfavorite208 comments athoscouto 15 hours agoTheir siloing strategy, which I&#x27;ll roughly refer as resolving a request from a single AZ, is a good way to keep operations and monitoring simple.A past team of mine managed services in a similar fashion. We had a couple (usually 2-4) single AZ clusters with a thin (Envoy) layer to balance traffic between clusters.We could detect incidents in a single cluster by comparing metrics across clusters. Mitigation was easy, we could drain a cluster in under a minute, redirecting traffic to the other ones. Most traffic was intra AZ, so it was fast and there was no cross-AZ networking fees.The downside is that most services were running in several clusters, so there was redundancy in compute, caches, etc.When we talked to people outside the company, e.g. solution architects from our cloud provider, they would be surprised at our architecture and immediately suggest multi-region clusters. I would joke that our single AZ clusters were a feature, not a bug.Nice to see other folks having success with a similar architecture! reply jasonwatkinspdx 14 hours agoparentYeah, I talked with a business that used a similar architecture for the same reasons. It can be really effective in multi-tenant apps where each customers data is fully independent and private. They also used multiple Amazon organizational accounts as a security partition. It made a few things more difficult but they felt the peace of mind was worth it. reply AugustoCAS 11 hours agoparentprevI assume you were using AWS? I know some of the AZ of other cloud providers (Azure? Oracle? Google?) are not fully siloed. They might have independent power and networking, but be in the same physical location.I&#x27;m mentioning this for other people to be aware as one can easily make the assumption that an AZ is the same concept on all clouds, which is not true and painful to realise. reply jeremyjh 9 hours agorootparentActually I assumed AWS did it the same way as the others - I thought maybe they are in another building on a campus but I didn’t think that should be a factor in planning and that I should use regions for geographic redundancy anyway. reply pl4nty 6 hours agorootparentprevAzure&#x27;s zones are \"physically separate\", but it&#x27;s unclear whether zones could be in the same building. Especially since they don&#x27;t guarantee distance between zones - they just aim for 300mi (483km) reply ak007 10 hours agorootparentprevThanks for highlighting this. Indeed all CSPs are not the same reply ComputerGuru 15 hours agoparentprevIt sounds like you didn’t have persistent data, and were only offering compute? If there’s no need for a coherent master view accessible&#x2F;writeable from all the clusters, there would be no reason to use multi-region cluster whatsoever. reply athoscouto 15 hours agorootparentWe did. But the persisted data didn&#x27;t live inside those ephemeral compute clusters though. reply slashdev 12 hours agorootparentSo your data store was still multi AZ? I’m a little confused how you’d serve the same user’s data consistently from multiple silos. Do you pin users to one AZ? reply lordofnorn 13 hours agorootparentprevYeah, keep stateful stuff and stateless stuff separate; separate clusters, network spaces, cloud accounts, likely a mix of all that.Clearly define boundaries and acceptable behavior within boundaries.Setup up telemetry and observability to monitor for threshold violations.Simple. Right? reply catchnear4321 11 hours agorootparenti mean you could also just spin up a reeeeeally big compute node and just do it all there.fewer things to monitor. fewer things that can fail.just log in from time to time to update packages.see, cloud doesn’t have to be complex. reply ryukoposting 10 hours agorootparentI&#x27;m not a cloud guy, but if you&#x27;re going to put everything in one region, what&#x27;s stopping you from shoving everything into a bunch of containers on a t2.2xlarge instance (or equivalent), and adding like one CloudWatch alarm (or equivalent) that reboots the instance if it stops responding? reply q7xvh97o2pDhNrh 5 hours agorootparentAt least three obvious reasons might be:(1) Raw scale might mean you just plain can&#x27;t fit everything on a single t2.2xlarge.(2) Different services (containers) might have different performance profiles, so you may want a few different types of machines around.(3) You probably still want N+2 redundancy even within your single AZ, so this scheme should at least be upgraded to three t2.2xlarge boxes. ;) reply catchnear4321 7 hours agorootparentprevwill you settle for one big container? reply theamk 10 hours agorootparentprevuntil you get \"hardware failure\" note from cloud provider. Or the person updating packages makes a typo and messes up a system.sure, use \"pet\" computers for experiments and dev.. but having produluction be a \"cattle\" makes your life so much less stressful. reply singron 6 hours agorootparentI think everyone internalizes pets vs cattle a little differently, but I think people often don&#x27;t realize that if you have cattle, then you now have a cattle ranch. I.e. you often create a new concept to manage your cattle, and you often run that like it&#x27;s a pet.E.g. you want to think about your machines&#x2F;containers like cattle, so you put them into a kubernetes cluster, which has become your new pet. If all your infra fits on one machine, it&#x27;s way easier to have that as your pet the same way it&#x27;s easier to have a dog than run a livestock operation. reply pclmulqdq 9 hours agorootparentprevHaving a few computers doesn&#x27;t imply a \"pets\" approach to managing them. reply catchnear4321 7 hours agorootparentmore like a zoo, right? reply lordofnorn 10 hours agorootparentprevHey you know what; you do you.I’m an EE by education. It’s electron state, silly leaky abstraction Stan’ing to my head.Different babble for allocation of memory and algorithmic manipulation of the values stored within.Correctness is important when it comes to results being mapped to human consumption and even then the subset of parameters to be be rigorous with can be made subj. personally I lean on a subset that includes biological health and well being and deprioritize religiosity replyendymi0n 11 hours agoparentprevIt took me some time to realize that Cloud Solution Architects are also just slightly more technical sales people in disguise whose only mission is upselling you onto more dependency. Same thing about their PR, every CxO these days says they need \"multi-cloud\", whatever that means and the costs are usually enormous, while complexity rises — with questionable benefit.I did the math for our own stack and after a setback month in client revenue, and decided to put all our servers into a single AZ in a single region. The only multi-AZ, multi-region services are our backups. Surviving bad machines happens often enough that it&#x27;s priced in via using Kubernetes, but losing a whole AZ is a freak accident that&#x27;s just SO rare that calculating real business risk, it seemed apt to pretend it just doesn&#x27;t happen (sorry, Google Cloud Paris customers).Call me reckless, but I haven&#x27;t looked back ever since and it saves us thousands of dollars in intra-AZ fees per month alone. reply anon84873628 11 hours agorootparentYeah, for many businesses it probably isn&#x27;t necessary to have crazy short RTO and RPO. Just restore the most recent backup in a new region and point at the cloud provider outage report... reply bushbaba 15 hours agoparentprevThe downside of single AZ clusters is capacity. If you have a need to drastically scale up the compute might not be available in a single AZ. reply athoscouto 14 hours agorootparentEven though each cluster was single AZ the whole system wasn&#x27;t, so we weren&#x27;t bound by the capacity of a single AZ.Most of the situations where we needed to drastically scale up were known ahead of time as well (e.g. campaign from customer), and we would preallocate instances or even more clusters.I may be forcing my memory, but if I&#x27;m not mistaken, our auto scaling was setup in a way that the system could handle sudden load increases of ~50% without noticeable disruption. Spikes bigger than this could lead to increased latency and&#x2F;or error rate. reply kccqzy 14 hours agorootparentThat&#x27;s another way of saying your typical utilization ratio is 66%. Which is on the low side honestly.That said, it&#x27;s a trade off between efficiency and load spike tolerance. I trust that the trade off is made with informed decision. reply ec109685 12 hours agorootparent66% isn’t low utilization. You’re always going to have micro spikes, and you never want to clip, so keeping some headroom around feels smart.Unless you co-mingle online and offline (batch) traffic on same hosts, flat response times and high utilization aren’t compatible. reply sitkack 11 hours agorootparentHigh utilization means high variability and low resiliency and the last k-percentage of utilization causes highly non-linear effects. reply kccqzy 9 hours agorootparentprevWhile I agree there&#x27;s always going to be micro spikes and keeping some headroom is smart, 33% may be too much of a headroom for all but the most latency sensitive RPC services. Personally I aim for only 20% headroom. reply rewmie 13 hours agorootparentprev> That said, it&#x27;s a trade off between efficiency and load spike tolerance. I trust that the trade off is made with informed decision.I don&#x27;t think that relatively low utilization rates is the scenario that requires \"informed decision\". The only tradeoff in low utilization rate scenarios is cost, which might be outright cheaper and irrelevant once you do the math on the tradeoffs of using reserved instances vs the cost of scaling up with on-demand instances.You need to make a damn good case to chronically underprovision your system and expect it to autoscale your way into nickle-and-dime savings. reply jldugger 14 hours agorootparentprevIndeed, this is the main problem I run into. We have to scale up capacity before the traffic can be redirected or you basically double the scope of the outage briefly. Which involves multiple layers of capacity bringup -- ASG brings up new nodes, then HPA brings up the new pods. reply ec109685 12 hours agorootparentIf there’s uncorrelated load you can also run on your hosts, then you can share their spare capacity, with the hope they don’t spike at same time.AWS does that with their lambda arch to reduce waste. reply jldugger 10 hours agorootparentMaybe, but the cost accounting is already a nightmare. reply Terretta 14 hours agorootparentprevIf you have enough scale that could be a problem, cookie cutter more smaller AZs so any one outage is less of numerator of capacity over the denominator of scale.Worth noting that requiring teams to use 3 AZs is a good idea because you get \"n\" shaped patterns instead of mirror shaped patterns, which have very different characteristics for resilience and continuity. reply danielovichdk 15 hours agoprev\"A single Slack API request from a user (for example, loading messages in a channel) may fan out into hundreds of RPCs to service backends, each of which must complete to return a correct response to the user.\"Not being a dick here but is this not a fairly obvious flaw?I mean why not keep a structured \"message log\" of all channels of all time ?For every write the system updates the message log.I am guessing and making assumptions I know. reply namdnay 2 hours agoparentI imagine the base messages are in a single store. But then you have reactions, attachments, gifs, user profiles, and probably hundreds of custom integrations&#x2F;plugins.Having worked on other messaging apps, these are usually separated because their performance&#x2F;scalability requirements are different reply skullone 14 hours agoparentprevXMMP was extensible to support all this in the early 2000s. Slack reinvented simple services in the most obtuse way. I have to use Slack and I sideline quarterback all the ways things could have been better every day. reply zx8080 8 hours agorootparentXMPPAgree with this point of view. Except the Jabber&#x2F;XMPP Cisco legal thing, there&#x27;s just no tech answer on why on earth Slack did not use XMPP under the hood. reply alberth 8 hours agorootparentWhat’s even more interesting is … WhatsApp is XMPP&#x2F;ejabberd based.Slack would have known about WhatsApp architecture because it was widely talked about pre-FB acquisition (2014).And Slack was founded in 2013. reply purpleturtle22 14 hours agoprevCan someone ELI5 the difference between using AWS availability zone affinity and then simply dropping the downed AZ at the top most routing point?Wouldn&#x27;t that be the same thing, with the obvious caveat you are t using the routing technology Slack is using (We don&#x27;t - We use vanilla AWS offerings) reply t0mas88 14 hours agoparentThey decided to use every routing tool available at least once in their setup, so they can&#x27;t do this. But there is no explanation in the blog about why they use so many platforms and so many routing tools. Sounds to me like they got themselves into a mess and decided to continue on that path. reply jonathankoren 14 hours agorootparentSomewhere, an engineering “leader” is going to point to this blog post and then say, “Well, that’s how Slack did it!” and promptly copy this overwrought system reply vinnymac 13 hours agorootparentI’m not sure if you’re being serious, but in any case; This will happen, as it always does, inevitably. reply sitkack 11 hours agorootparentWarning statement becomes the howto guide. reply esprehn 8 hours agoparentprevCells are not about guarding against AZ failure, but about partitioning the production infra to protect against bad deploys and configuration changes. Every AZ is split into many different cells. reply hliyan 3 hours agorootparentSo, guarding against human errors &#x2F; process failures, and not hardware failures? reply ec109685 12 hours agoparentprevIsn’t that exactly what they are doing? Keeping requests within an AZ and instead of using DNS at the first hop into AZ, they use envoy to control traffic shaping and making that initial decision if traffic needs to be routed away. reply Terretta 14 hours agoparentprevYou&#x27;re doing it right. reply ec109685 12 hours agoparentprevIsn’t that exactly what they are doing? Keeping requests within an AZ and using global DNS at the first hop into AZ. reply random3 12 hours agoprevThis brings back memories - we speced an open distributed operating system called Metal Cell and built an implementation called Cell-OS. It was inspired by the \"Datacenter as a computer\" paper, but built with open-source tech.We had it running accross bare metal, AWS and Azure and it one of the key aspects was that it handled persistent workloads for big data, including distributed databases.Kubernetes was just getting built when we started and was supposed to be a Mesos scheduler initially.I assumed Kubernetes would get all the pieces in and make things easier, but I still miss the whole paradigm we had almost 10 years ago.This is retro now :)https:&#x2F;&#x2F;github.com&#x2F;cell-os&#x2F;metal-cellhttps:&#x2F;&#x2F;github.com&#x2F;cell-os&#x2F;cell-os reply aftbit 15 hours agoprevHow can such an architecture function with respect to user data? If the DB instance primary handling your shard is in AZ-1 and AZ-1 gets drained, how can your writes continue to be serviced? reply progbits 15 hours agoparentUsually in distributed strongly consistent and durable systems, data is not considered committed until it has been persisted in multiple replicas.So if one goes down nothing is lost, but capacity and durability is degraded. reply skybrian 15 hours agorootparentThat makes sense on its own, but doesn’t it mean that there are lots of network requests happening between silos all the time? It doesn’t seem very siloed.Or is this some lower-level service that “doesn’t count” somehow? reply progbits 14 hours agorootparentIt&#x27;s siloed that if one is down others are not affected as long as enough other replicas are healthy to keep the quorum.You always need cross-AZ traffic, otherwise your data is single homed (which we used to call \"your data doesn&#x27;t exist\"). reply dexwiz 15 hours agoparentprevMultiple tiers of redundancy. There is usually redundancy within the AZ and then a following copy in another AZ. Usually at least four copies exist for a tenant. reply ThePhysicist 15 hours agoprevSo they run everything in AWS USE1? That doesn&#x27;t seem very redundant, but then I guess if the whole of USE1 goes down Slack won&#x27;t be the only service that will be affected. reply messe 15 hours agoparentAWS also uses Slack internally, so add that to the list of shit that can hit the fan if us-east-1&#x2F;IAD goes down. reply mynameisvlad 14 hours agorootparentDon’t they also use Chime? It wouldn’t be a single point of failure. reply skullone 14 hours agorootparentLots of teams use Slack as well. Oddly enough, I didn&#x27;t mind Chime as an end-user, but 6 years ago their API features were somewhat lacking. reply nostrebored 13 hours agorootparentprevTo contribute to the tangled ball of messaging, slack also uses chime sdk to handle huddles reply notyourwork 5 hours agorootparentWonder why huddles sound better compared to chime? reply fotta 14 hours agorootparentprevHuh, I’m surprised they’re not all in on Chime. reply shepherdjerred 14 hours agorootparentIt was all on Chime until the Pandemic. Then they moved to Slack. reply johannes1234321 14 hours agoparentprevBut then everybody trying to recover from USE1 outage can&#x27;t use Slack to coordinate the recovery ... reply radicality 15 hours agoparentprevIsn’t the point of the article that they don’t? And it describes how they implemented region drains to traffic shift between the different regions.edit: Hmm or maybe not? I still sometimes confuse aws terminology. Perhaps it is all in us-east—1, just in different availability zones (buildings?) reply ThePhysicist 15 hours agorootparentIf I understand it correctly they have an edge network for ingress traffic but host all of their core services in a single AWS region (USE1) in multiple availability zones there. reply jldugger 12 hours agorootparentprev>edit: Hmm or maybe not? I still sometimes confuse aws terminology. Perhaps it is all in us-east—1, just in different availability zones (buildings?)Correct, us-east-1 has several AZs, names like us-east-1a, us-east-1b etc. IIRC us-east-1 has six of them now. reply deanCommie 15 hours agoparentprevthe \"whole\" of USE1 very rarely goes down [0], because unlike other cloud providers, Amazon&#x27;s availability zones are actually independent and decoupled, and if you&#x27;re running on EC2 in a zonal way it&#x27;s highly unlikely an outage will affect multiple zones.[0] There are of course exceptions that come once every few years, but most instances people can think of in terms of widespread outages is one specific service going down in a region, creating a cascade of other dependencies. e.g. Lambda or Kinesis going down and impacting some other higher-level service, say, Translate. reply oceanplexian 12 hours agorootparentAZs are buildings often times right next to each other on the same street. People who think this is a great failure domain for your entire business are deeply misguided. All it takes is a hurricane, a truck hitting a pole, a fire, or any number of extremely common situations and infra will be wiped off the map. Build stuff to be properly multi-region. reply easton 8 hours agorootparentIs this true of AWS? I haven’t read that Wikileaks location document in a while, but I seem to recall in official docs the AZs being placed far enough away from each other to make sure a natural disaster won’t kill a whole region (different flood planes, etc). Of course, you go to Asburn and all the buildings are really close to each other. reply inopinatus 4 hours agorootparentprevWhen AWS is in immediately adjacent buildings, it’s for the same AZ. reply deanCommie 10 hours agorootparentprev> AZs are buildings often times right next to each other on the same street.Not at AWS: https:&#x2F;&#x2F;aws.amazon.com&#x2F;about-aws&#x2F;global-infrastructure&#x2F;regio...> An Availability Zone (AZ) is one or more discrete data centers with redundant power, networking, and connectivity in an AWS Region. AZs give customers the ability to operate production applications and databases that are more highly available, fault tolerant, and scalable than would be possible from a single data center. All AZs in an AWS Region are interconnected with high-bandwidth, low-latency networking, over fully redundant, dedicated metro fiber providing high-throughput, low-latency networking between AZs. All traffic between AZs is encrypted. The network performance is sufficient to accomplish synchronous replication between AZs. AZs make partitioning applications for high availability easy. If an application is partitioned across AZs, companies are better isolated and protected from issues such as power outages, lightning strikes, tornadoes, earthquakes, and more. AZs are physically separated by a meaningful distance, many kilometers, from any other AZ, although all are within 100 km (60 miles) of each other.This is unique compared to Microsoft, and Google (a single flood taking out multiple AZ&#x27;s? Uh oh: https:&#x2F;&#x2F;www.theregister.com&#x2F;2023&#x2F;04&#x2F;26&#x2F;google_cloud_outage&#x2F;)Sure, a massive earthquake or a nuclear strike could probably take out several. reply pl4nty 6 hours agorootparent> This is unique compared to MicrosoftAzure doesn&#x27;t guarantee distance between zones, but they aim for 483km. So they can provide better isolation at the cost of higher inter-AZ latency. Depends on the region - you&#x27;d need an internal contact (and&#x2F;or NDA?) to get approx numbers reply esprehn 8 hours agorootparentprevGCPs concept of Regions and Zones is different from AWS. For the same level of physical isolation as an AWS AZ you have to use different GCP Regions.https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;docs&#x2F;regions-zones reply asah 14 hours agorootparentprevAm I missing something about us-east-1 reliability ?https:&#x2F;&#x2F;www.google.com&#x2F;search?q=us-east-1+reliability https:&#x2F;&#x2F;www.google.com&#x2F;search?q=us-east-1+outage reply temp_praneshp 14 hours agorootparentYes. to put it a bit bluntly, you are using a very generic google search and being blind to nuance.us-east-1 does have more problems than other zones due to a variety of reasons, but it rarely (ie, once a few years) goes down as a whole. As long as you&#x27;re in several AZs within us-east-1, the impact of most outages should not take you down completely. In the context of the comment you are replying to, your google search links are lazy and fail to see the big picture. reply asah 1 hour agorootparentthanks - jfyi this was from my personal experience spanning a decade with USE1, but again maybe my experience is out of date, so thanks for the update.(p.s. the use of a google search vs direct results wasn&#x27;t \"lazy\" - it&#x27;s to allow readers to do their own research vs pasting one result and then getting accused of bias) replyasankama 6 hours agoprevDelighted to be part of this conversation on cell-based architecture. As the author of the cell-based reference architecture https:&#x2F;&#x2F;github.com&#x2F;wso2&#x2F;reference-architecture&#x2F;blob&#x2F;master&#x2F;r..., I&#x27;m here to share insights on this exciting approach.Cell-based architecture introduces modular &#x27;cells&#x27; into software systems, each with distinct APIs. This design fosters loose coupling and scalability – key for today&#x27;s dynamic software landscape. Particularly, for those intrigued by microservices, cells align seamlessly with the independent, scalable components that power microservices architectures.Curious to dive deeper? If you&#x27;re keen to explore the nitty-gritty technicalities, I invite you to check out the architecture paper https:&#x2F;&#x2F;github.com&#x2F;wso2&#x2F;reference-architecture&#x2F;blob&#x2F;master&#x2F;r... for an in-depth understanding. Let&#x27;s kick-start this dialogue on the potential of cell-based architecture and its impact on modern software design. Feel free to join the conversation! reply DandyDev 1 hour agoparentThis seems written by AI? And as such it comes across as not genuine reply dikei 46 minutes agorootparentIt&#x27;s from WSO2, a company selling enterprise middleware. Of course, the paper would read like something you bring to a sales meeting, not a tech talk. reply memefrog 12 hours agoprev\"For example slack is an incredibly successful product. But it seems like every week I encounter a new bug that makes it completely unusable for me, from taking seconds per character when typing to being completely unable to render messages. (Discord on the other hand has always been reliable and snappy despite, judging by my highly scientific googling, having 1&#x2F;3rd as many employees. So it&#x27;s not like chat apps are just intrinsically hard.) And yet slack&#x27;s technical advice is popular and if I ran across it without having experienced the results myself it would probably seem compelling.\"https:&#x2F;&#x2F;www.scattered-thoughts.net&#x2F;writing&#x2F;on-bad-advice&#x2F; reply lordgrenville 1 hour agoparentI really wouldn&#x27;t judge the quality of some company&#x27;s technical advice based on one person&#x27;s experience with their UI. For almost any consumer software that gets mentioned here, you will find some people who love it and lots of others with gripes. And for e.g. Slack might have bad product&#x2F;UI people but very good infra people. Better to look at TFA and judge it on its merits. reply 708145_ 3 hours agoprevIf each AZ is siloed, then how can different AZs serve the same user&#x2F;workspace? reply alberth 15 hours agoprevIs Slack still written in Hack&#x2F;PHP? reply muglug 15 hours agoparentYes — see my recent article https:&#x2F;&#x2F;slack.engineering&#x2F;hakana-taking-hack-seriously&#x2F;We use a few languages to serve client requests, but by far the biggest codebase is written in Hack, which runs inside an interpreter called HHVM that’s also used at Facebook. reply dcgudeman 13 hours agorootparentI noticed that the hack blog (https:&#x2F;&#x2F;hhvm.com&#x2F;blog&#x2F;) basically stopped posting updates since the end of 2022. As downstream users of hacklang development have you folks noticed a change in development pace or ambition within the hack development team? reply alberth 11 hours agorootparentI too am super curious about this.Plus, it seems telling that Threads was developed in Python - not Hack.(I’m aware IG is Python & it’s the same team) reply rubyss 11 hours agorootparentYou answered yourself there, Hack is still very widely used inside meta, just less so in IG. reply throwaway1777 5 hours agorootparentprevIf anything from what I’ve heard hack is slowly taking over IG and WhatsApp. But it’s an incredibly large codebase to move reply xwowsersx 11 hours agorootparentprevKinda makes sense you would use PHP, even though I&#x27;m sure many people are shocked by it. PHP was pretty much born in a web context. The language was created with servers and request&#x2F;response in mind and it shows. reply koolba 15 hours agorootparentprevI really like the writing style in that article:> PHP makes it really easy to make a dynamically-rendered website. PHP also makes it really easy to create an utterly insecure dynamically-rendered website. reply WinLychee 14 hours agorootparentprevPHP has some excellent ideas that other languages can&#x27;t replicate, while at the same time having terrible ideas that other languages don&#x27;t have to think about. Overall a huge fan of modern PHP, thanks for this writeup. reply pm 9 hours agorootparentWhich excellent ideas does it have that other languages can&#x27;t replicate? reply WinLychee 9 hours agorootparentPerhaps more precisely: the defacto Apache-as-runtime + PHP model simplifies a ton of things. Namely your request state is created and destroyed all within the context of a single process, and you don&#x27;t have to reason about shared state with other in-flight requests (unless you explicitly choose to go this route). It makes some bad programming patterns workable, because your state doesn&#x27;t linger over a long-running period. Deploys are also super fast, you just have to swap the application code on disk and it&#x27;ll get picked up on the next request (in-flight requests will keep processing with the old version IIRC). It&#x27;s productive if not necessarily pretty. Also it has a type system now!As a related thought, a lot of the modern serverless stuff feels like it&#x27;s reinventing the ideas of Apache + PHP, or perhaps CGI? reply alberth 14 hours agorootparentprevHi MattThanks for Psalm!Curious, if Slack was built today from ground up - what tech stack do you think should&#x2F;would be used? reply muglug 14 hours agorootparentThat’s a simple question that’s hard to answer.A slightly different question that’s a bit easier to answer: “if I could wave a magic wand and X million lines of code were instantly rewritten and all developers were instantly trained on that language”.There the choice would be limited to languages that have similar or faster perf characteristics to Hack, without sacrificing developer productivity.Rust is out of the question (compile times for hundreds of devs would instantly sap productivity). PHP, Ruby, Node and Python are too slow — for the moment at least.So it would be either Hack or Go. I don’t know enough about JVM languages to know whether they would be a good fit. reply syspec 12 hours agorootparentThank you for being brave enough not to suggest Rust. reply alberth 14 hours agorootparentprevI like your question way better than mine :)Some follow-up …A. isn’t PHP on par perf wise to Hack these days? Re: “PHP is too slow” comment.B. have you ever looked into PHP-NGX? It’s perf looks impressive, though you lose the benefit of statelesshttps:&#x2F;&#x2F;github.com&#x2F;rryqszq4&#x2F;ngx-phphttps:&#x2F;&#x2F;www.techempower.com&#x2F;benchmarks&#x2F;#section=data-r21 reply tacker2000 58 minutes agorootparentPHP served by an nginx (never saw the abbreviation NGX to be honest) server is standard procedure in PHP land.Other alternatives are Apache, Caddy, and more… reply muglug 13 hours agorootparentprev> isn’t PHP on par perf wise to Hack these days?No. But I don&#x27;t have any numbers, because it&#x27;s been years since the two languages were directly comparable on anything but a teeny tiny example program.Facebook gets big cost savings from a 1% improvement in performance, so they make sure that performance is as good as it can possibly be. They have a team of engineers working on the problem.PHP doesn&#x27;t have any engineers working on performance full-time — it&#x27;s impossible for the language to compete there. Hack has also removed a bunch of PHP constructs (e.g. magic methods) that are a drain on performance, so there&#x27;s no way to close the gap.But that should in no way make you choose Hack over PHP. Apart from anything else, the delta won&#x27;t matter for 99.9% of websites. reply tacker2000 1 hour agorootparentYes, Hack is for Google or FB scale stuff. But to be honest, Slack is probably up there also, so it makes sense reply davedx 13 hours agorootparentprevNot erlang? reply conradfr 12 hours agorootparentBut Discord uses Rust to improve performance bottlenecks in OTP ;) replyaftbit 15 hours agoparentprevfrom the article:>Slack does not share a common codebase or even runtime; services in the user-facing request path are written in Hack, Go, Java, and C++. reply skullone 15 hours agorootparentMan what a mess. Meanwhile, everyone else can extend a library used by their common services in a common language trivially. reply hotnfresh 14 hours agorootparentMeh. As long as you’ve got a good, typed interface for passing messages between them and for having a common understanding of (and versioning system for) key data structures, that’s fine for this sort of thing where it’s largely processing steams of small messages and events.… but it’s probably JSON and some JSON-Schema-based “now you have two problems” junk instead of what I described. In which case, yeah, ew, gross. Unless they’ve made some unusually good choices. reply nostrebored 13 hours agorootparentThere are tons of approaches to align on service contracts for JSON based API calls. There’s also libraries like gRPC which help make contacts explicit. Neither are really uncommon reply xwowsersx 11 hours agorootparentWhat are some of those approaches? Are there formal methods and&#x2F;or tools for doing this? reply wmf 15 hours agorootparentprevAlmost everyone embraced polyglotism and microservices together. reply rs_rs_rs_rs_rs 15 hours agorootparentprevLet me guess, they should rewrite everything in Javascript? reply tomrod 15 hours agorootparentNah, Excel. &#x2F;s reply skullone 15 hours agorootparentprevWoe is us if they actually did. replydr_kiszonka 13 hours agoprevNice write-up! If no new requests from users are arriving in a siloed AZ, internal services in that AZ will naturally quiesce as they have no new work to do.Not necessarily because, due to some bug, there may be resource-hungry jobs running indefinitely. (Slack&#x27;s engineers must have considered this; I am just nitpicking this particular part of the text.) reply ninkendo 11 hours agoparentIf you replace \"because\" with \"if\", your comment makes more sense. \"If\" there are such bugs, you are right, but such bugs might not exist. reply awinter-py 12 hours agoprevtheir backend being on 2G explains a lot of other stuff about their software reply chrisweekly 15 hours agoprevI appreciate the clear explanation of the problem and the solution, which (as is so often the case) seems fairly simple or obvious in retrospect.Semi-related tangent: sometime around mid-2016, I came across a tool that helped visualize requests in near real-time, and showed what it \"looks\" like (ie, flow slows to trickle in service A during draining, while it ramps up in service B)... there was a really compelling demo, but I never bookmarked it and can&#x27;t seem to find it. IIRC its name was a single word. Maybe someone reading this will know what I&#x27;m talking about... ? reply mrkeen 14 hours agoparentVizceral reply xwowsersx 11 hours agorootparentNeat.> If a graph of nodes and edges with data about traffic volume is provided, it will render a traffic graph animating the connection volume between nodes.How would one go about providing such a graph? :) reply chrisweekly 8 hours agorootparentprevYES! Thank you!! :)This kind of shared communal knowledge is one of many reasons I&#x27;m very grateful for the HN community. reply fiddlerwoaroof 13 hours agoprevThe thing I don&#x27;t understand about Slack is how the core functionality seems to have continuously degraded since I started using it in ~2015. When I started using it, its core message sending features basically didn&#x27;t have the issues with delayed messages or failure to send that I had experienced with competitors. Now, I routinely have to reset the app&#x2F;clear the cache and go through various dances to get files to upload reliably (add the file to a message, wait five or ten seconds, then hit send). It&#x27;s nice to see these technical write-ups about improving the infrastructure behind Slack, but I&#x27;d like to see fewer feature launches and more stability improvements to make the web, desktop and mobile apps feel like reliable software again. (nice to haves would be re-launching the XMPP and IRC bridges) reply tmpX7dMeXU 13 hours agoparentNot to “works on my machine” you, but I…genuinely do not have these problems. I’ve never heard it from my team either. So we could at the very least say it’s not a widespread global issue.Even the percentage of nerds that would want IRC or XMPP bridges back would have to be vanishingly small. I’d be annoyed if Slack reimplemented such functionality because it no doubt slows down future development. Slack has a number of mechanics that do not carry across to IRC or XMPP, and they did when they killed the bridges. I’d be annoyed if new features were compromised to increase compatibility with this blatant nerd vanity project. reply fiddlerwoaroof 12 hours agorootparentSo, it&#x27;s workspace and user&#x2F;device specific: two of the workspaces I interact with regularly have these problems and the problems also show up intermittently for some users and not others. (Anecdotally, my experience is that Matrix&#x2F;Element used to be annoying compared to the Slack experience and now I mostly prefer it to Slack)I would be fine with the understanding that the IRC bridge was missing functionality (and it always was). Although threads might make it impossible to implement in a nice way now.As far as new features go, I don&#x27;t want any new features in Slack: it worked exactly like I wanted it to seven years ago and the new stuff is nice, but not worth the degradation in user experience. reply calrueb 9 hours agorootparentI’m gonna go to bat for Slack on this one and say the “Later” feature they added recently has completely changed my workflow for the better. It’s so simple, but removes all the cognitive overhead of feeling pressured to deal with specific messages real time, else I forget about them. Now I just throw the message in Later and get back to it when I’m free. reply fulladder 12 hours agoparentprevI haven&#x27;t used Slack in a long time, but isn&#x27;t this just the normal enshittification cycle that occurs with all Internet products? The founders got a nice exit several years back, I doubt they stuck around at Salesforce for long, so it&#x27;s natural that the product would deteriorate over time.Slack IRC bridging in the 2014&#x2F;2015 era was great. We had a lot of people who spent their whole workday in a terminal window and weren&#x27;t interested in running a web browser in the background continuously just for a chat room. reply fiddlerwoaroof 12 hours agorootparent> Isn&#x27;t this just the normal enshittification cycle that occurs with all Internet products?Yeah, although one can dream that some SaaS company would do htings differently reply memefrog 12 hours agorootparentprev>isn&#x27;t this just the normal enshittification cycle that occurs with all Internet products?No! Stop diluting this word. reply fulladder 11 hours agorootparent> No! Stop diluting this word.Yes, you&#x27;re right, I&#x27;m misusing it.However, I think that there is a phenomenon that happens to a lot of tech products that is more general than what Doctorow is talking about. There is a certain type of person who is attracted to building a new thing, and there is a different type of person who is attracted to a thing that is already successful. Pioneers and Settlers, as a former colleague of mine described it. In the context of Internet services, pioneers care a lot about attracting users initially so they tend to dwell on every minor detail. Settlers care a lot about stability, so gradual degradation over time (e.g., in performance, in other measures of quality) is tolerable as long as its rate is controllable and well-understood.I think that Doctorow&#x27;s thesis is a special case of this where greed is the driving factor behind the gradual erosion of quality. reply jmull 11 hours agorootparentprevThis is the Cory Doctorow sense of the word, is it not?(Or, now that I notice your username, maybe you’re making an ironic joke, since complaining about the misuse of the word enshitification is a meme now?) reply ec109685 12 hours agoparentprevThey support much much larger workspaces now, and support team to team shared channels, so the problem space is much more complex than 2015.Not saying they shouldn’t fix their reliability. Every other week it seems like they have an outage with this or that.The Flickr style commit to production multiple times per day seems to have its limits. Perhaps longer canary and slower rollouts would help. reply t0mas88 14 hours agoprevThey got themselves into a mess here:> This turns out to have a lot of complexity lurking within. Slack does not share a common codebase or even runtime; services in the user-facing request path are written in Hack, Go, Java, and C++. This would necessitate a separate implementation in each language.This sounds crazy. I&#x27;ve seen several products where there is a core stack (e.g. Java) and then surrounding tools, analytics etc in Python, R and others. But why would you create such a mess for your primary user request path?Sure, they&#x27;re not \"just a chat app\" they have video, file sharing etc included and a lot of integrations. But still this sounds like a company that had too much money and too little sense while growing rapidly. reply skullone 14 hours agoparentIt even pains me to see they&#x27;re suffering from so many own goals. And it&#x27;s unfortunately reflected in the poor experience using the Slack client. Not to mention the multiple deprecated bot&#x2F;integration APIs with such bad feature parity between all the different ways to integrate your own tooling into Slack. reply nostrebored 13 hours agorootparentWhat do you mean? Slack is one of the most responsive and reliable tools I touch every day. reply skullone 13 hours agorootparentHow slow are the rest of your tools? The Slack client probably performs worse today than it did a few years ago. It has the laggiest interface of any of my tools, you can watch your CPU spike to 60-80% just switching channels. Just do it right now, open up htop&#x2F;top&#x2F;atop&#x2F;Activity Monitor - whatever you want, and just switch channels. Laugh as the Slack client wastes a universe&#x27;s worth of time just... rendering a DOM with plain text. It is genuinely pathetic how bad the client is. reply lopkeny12ko 12 hours agorootparentprevI hope this is satire. Slack is one of the slowest work tools I&#x27;ve ever used. Every interaction and click visibly lags.It&#x27;s a sad state of the world that almost every application now is written in Javascript and deployed with Electron, and massive memory usage and slow UIs have become accepted as the norm.Try any IRC client and tell me, with a straight face, that Slack is just as responsive. reply ladzoppelin 11 hours agorootparentSo I only use Firefox and the Slack web client and don&#x27;t experience any lag. I am surprised so many people use the Slack app over a web tab. reply FridgeSeal 10 hours agorootparentprevOk genuine question: what other tools do you use?Slack won’t seem that bad, until you use something that’s actually good.The loss of performance on commonplace applications has been a real “boil the frog” situation; we’ve lost so much performance and responsiveness, but it’s happened so gradually that most people don’t notice. reply jldugger 10 hours agorootparentprevWell, status.slack.com says they&#x27;re currently having an outage, that has been ongoing for multiple days. reply snoman 13 hours agorootparentprevThere was a time when this was the case (and electron was the punching bag for critics at the time, iirc) but I don’t think this criticism is fair anymore. Slack is quite responsive and performant these days. reply tbrownaw 14 hours agoparentprev\"The right language for each job\" was one of the heavy advertising points for microservices. Might still be too some extent, even. reply BoorishBears 13 hours agorootparentThe problem is most engineers don&#x27;t understand the \"job\".They see the job as a strictly technical problem looking for the best technical solution. They don&#x27;t look up and see how that problem fits into the larger organization.They think things like \"I can make a microservice that encodes PDFs 10x faster by using Rust\" and give an estimate based on that, never thinking about how we&#x27;re going to need to hire 2 more Rust devs to keep that running, and we could have delivered twice as quickly if I had used our default Python stack and now our \"10x faster\" doesn&#x27;t matter because that feature is old news.Microservices are such an unfortunate concept because they attract the people least suited to use them: If your team can&#x27;t handle a monolith, you shouldn&#x27;t even be looking up what a microservice is. reply pavlov 14 hours agoparentprevThe only way you get Hack on that list of languages is that they had a policy of letting lead engineers starting a project to choose the language at will, and they hired enough lead engineers who previously worked at FB&#x2F;Meta. reply tlunter 14 hours agorootparentI think that Hack might’ve been on that list earlier than you think. Slack started as a PHP application. reply matwood 13 hours agorootparentYeah. If they already had a large php codebase, moving to Hack makes complete sense. reply eikenberry 14 hours agoparentprevWhat mess? That sounds like a healthy internal language ecosystem to me. You need at least 2 primary languages to avoid accidental lock-in and maintain good developer diversity. That very paragraph is a great example of how the diversity helped them avoid the trap of plumbing it through their RPCs. reply t0mas88 13 hours agorootparentSince when is an \"internal langue ecosystem\" a good idea? Technology in a company like Slack exists to deliver useful features and good performance&#x2F;stability to users faster than competitors can do it. For an app like theirs it doesn&#x27;t sound like something that needs several disparate internal platforms that are slowing them down. reply nostrebored 13 hours agorootparentHow is choosing the right language for a task&#x2F;team slowing them down?For large scale, cross cutting initiatives you’ll have some pain. For feature velocity, you’ll see great results. Everything is a trade off. reply lopkeny12ko 12 hours agorootparentprevYou&#x27;re suggesting that needing to reimplement the same thing 5 times for every single language in use is a hallmark of a \"healthy internal language ecosystem\"? reply eikenberry 5 hours agorootparentThat&#x27;s the red flag, the thing you are trying to avoid. You don&#x27;t want to implement things in each language and you always have more than one language even if you standardize (over time). You don&#x27;t want libraries, you want services. This is why things like Istio are way better than libraries for mesh networking. Using external services for common things keeps you from being locked into a single tech stack and the limitations that entails. reply gumballindie 14 hours agoprev\"cellular architecture\"What? Does amazon need to push for new sales points or are they simply making up architectures now? reply tedd4u 13 hours agoparentCell architecture goes way back, at least 10 years. Tumblr for example.http:&#x2F;&#x2F;highscalability.com&#x2F;blog&#x2F;2012&#x2F;5&#x2F;9&#x2F;cell-architectures.... reply diarrhea 13 hours agoparentprevA big term for a simple design principle indeed.But their implementation isn’t as grim as what I had initially envisioned when hearing that term. I immediately thought of Smalltalk and the idea of objects sitting next to each other, forming a graph (of no particular structure… just a graph), passing messages to neighbours. Like cells in an organism send hormones and whatnot. That makes for a huge mess that cannot be reasoned about, hence why we instead went with stricter structures like trees for (single) inheritance. That’s much closer to this silo approach, which seems nice and reasonable (although I get the impression considerable complexity was swept under the rug, like global DB consistence; the siloes cannot truly be siloed). reply ignoramous 14 hours agoparentprevex-AWS hereMay be marketing but it is an architecture born out of Amazon&#x27;s (and AWS&#x27;s) use of AWS:- Reliable scalability: How Amazon.com scales in the cloud, https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=QeW9wCB36ck&t=993 (2022)- How AWS minimizes the blast radius of failures, https:&#x2F;&#x2F;youtu.be&#x2F;swQbA4zub20 (2018)For massive enterprise products like Slack that need close to 100% uptime across all their services, cells make sense. reply gumballindie 11 hours agorootparentYeah that&#x27;s what microservices were meant to achieve. Suppose the market is staturated with \"microservices\", so a new term was needed. reply ignoramous 11 hours agorootparentMicroservices is one reason you need cells. If you haven&#x27;t, the second talk I linked to might interest you. reply mike_hock 14 hours agorootparentprevCells, interlinked. reply unethical_ban 3 hours agoparentprevYeah, the idea was present at my bank employer 15 years ago. Drain a DC to do maintenance and load testing. It was called high availability.This blog is writing about availability zones as if they&#x27;re a new concept too. reply mike_hock 14 hours agoparentprevWhy is than an either&#x2F;or? reply CyberDildonics 12 hours agoparentprevSounds like it&#x27;s two bird with one stone. reply skullone 15 hours agoprevSo they used a feature built into a load balancer to gracefully drain traffic from specific availability zones? Odd that a feature found in load balancers from the last 25 years is a blog post worthy thing. reply colmmacc 15 hours agoparentClose but I don&#x27;t think it&#x27;s quite 25 years! I added graceful draining to Apache httpd&#x27;s mod_proxy and mod_proxy_balancer either in 2003 or 2004, and at the time I&#x27;m nearly certain it was the first software load balancer to have the feature, and it wasn&#x27;t available on the hardware load balancers of the time that I had access to ... though I later learned that at least BigIP load balancers had the feature.At the time, we had healthy debates about whether the feature was useful enough to justify additional complexity, and whether there could be cases where it would backfire. To this day, it&#x27;s an underused feature. I still regularly run into customers and configurations that cause unnecessary blips to their end-users, so it&#x27;s nice to see when people dig in and make sure that the next level of networking is working as well as it can. reply djbusby 15 hours agorootparentMicrosoft bought Convoy in 1998[0]. Then incorporated it into NT4sp6a and Win2k as NLB&#x2F;WLBS. One of its features was to gracefully remove a server from the cluster after all connections were closed - draining. But, cluster not the same as an LB.[0] https:&#x2F;&#x2F;news.microsoft.com&#x2F;1998&#x2F;08&#x2F;24&#x2F;microsoft-corp-acquire... reply skullone 15 hours agorootparentprevI migrated some old BigIP load balancers over to Apache in 2004ish, and extended some of mod_proxy to do some \"unholy\" things at the time. We also did a lot of direct server return stuff when no load balancer you could buy could handle the amount of traffic statefully. Man, how times have changed, and lesson forgotten. reply robertlagrant 15 hours agorootparentprevWell played, HN. reply jameshart 15 hours agoparentprevThat seems like a shallow dismissal. In a distributed system, making sure that sub requests are handled across distributed nodes within the local AZ, and correctly draining traffic from AZs with partial component service outages, is not as trivial as &#x27;using a feature built in to a load balancer&#x27;. reply skullone 15 hours agorootparentIt may be shallow, but architecting for this is not really \"advanced, FAANG-only accessible methodology\". I&#x27;m surprised their services have been as \"reliable\" as they have been considering such trivial stuff is just now being employed in their architecture. reply jameshart 15 hours agorootparentHalf the complaints on here on architecture posts are &#x27;you don&#x27;t need this kind of stuff unless you&#x27;re at FAANG scale&#x27;. Now we have a write up of something that&#x27;s accessible to businesses at non-FAAANG scale, and we have the new complaint, that this kind of stuff isn&#x27;t worthy of FAANG-scale architecture. reply skullone 14 hours agorootparentGeo traffic distribution, multi regions&#x2F;AZs with functionality to weight and drain traffic should be used in most SaaS services where a simple failure somewhere could cost users time and lose company money&#x2F;goodwill. It&#x27;s not terribly hard nor expensive. reply jameshart 9 hours agorootparentHow do you think people are going to learn this stuff if not by reading about it from architects who have done it?This writeup seems like a useful contribution to spreading this knowledge that you think every engineer should, somehow, innately be born with, to those members of the development community who missed out on picking this stuff up in elementary school. reply nostrebored 13 hours agorootparentprevThose are all much looser restrictions than routing traffic consistently to a cell reply mlhpdx 13 hours agorootparentRoute 53 latency based routing -> APIGW or ALB -> Lambda or Step Functions -> DDB Global Table.No reserved capacity (pay for usage), so it works for boot strapping startups and provides superior resilience while being extremely simple to setup and involves almost zero maintenance or patching (even under the hug of death). I don’t understand settling for less (and taking longer and paying more for it). reply robertlagrant 15 hours agorootparentprev> architecting for this is not really \"advanced, FAANG-only accessible methodology\"Sorry - where are you quoting this claim from? reply wilg 15 hours agorootparentThe S in FAANG is for Slack. reply skullone 15 hours agorootparentprevMy own words, but this is fairly trivial in the context of these massive companies with presumably PHDs working on their architecture. replyprogbits 15 hours agoparentprevThe other bit is separating the service into isolated cells so issues in one don&#x27;t affect dependent services everywhere like they had experienced before.But yeah any good SRE could point this out years ago. reply skullone 15 hours agorootparentJust odd a company worth billions and billions of dollars is just now discovering HA models standard since the 90s. Can expand the Clos network architecture to these distributed service applications too. But judging by Slack&#x27;s client quality, mature concepts such as those must be new to them. reply antoniojtorres 13 hours agorootparentThe linked AWS article specifically explains that it’s not just the typical single load balancer for cross AZ routing. I frankly don’t know where you’re getting that this means that HA is new to them. reply skullone 13 hours agorootparentOf course this isn&#x27;t a typical single load balancer for cross AZ - but the general gist of their \"new\" architecture is first principles level of design. But sure, we can celebrate their minor achievement I guess replyUncleOxidant 12 hours agoprevInitially read this as: \"Slack&#x27;s Migration to Cellular Automata\" and now I&#x27;m a little disappointed. reply madduci 15 hours agoprevCellular architecture? They&#x27;ve just rediscovered the art of redundancy systems reply Terretta 14 hours agoparentIndeed, for 20+ years of distributed data centers (remember AZs are generally separate DCs near a city but on different grids, regions are geographically disparate cities) we called it \"shared nothing\" architecture pattern.Here&#x27;s AWS&#x27;s 2019 guide for financial services in AWS, where the isolated stack concept is referenced under parallel resiliency section and called \"shared nothing\":https:&#x2F;&#x2F;d1.awsstatic.com&#x2F;Financial%20Services&#x2F;Resilient%20Ap... reply hliyan 3 hours agorootparentI wish modern architecture writing could go back to being this straightforward:\"There are three dominent themes in building high transaction rate multiprocessor systems, namely shared memory (e.g. Synapse, IBM&#x2F;AP configurations), shared disk (e.g. VAX&#x2F;cluster, any multi-ported disk system), and shared nothing (e.g. Tandem, Tolerant). This paper argues that shared nothing is the pre- ferred approach.\"https:&#x2F;&#x2F;dsf.berkeley.edu&#x2F;papers&#x2F;hpts85-nothing.pdf reply skullone 15 hours agoparentprevBut if they call it cellular architecture, it sounds much more exotic than a shared-nothing active&#x2F;active service! reply politelemon 15 hours agoparentprevIt&#x27;s a common pattern in tech. Everything old will be new again. reply donutshop 14 hours agorootparentBut kubernetes reply benatkin 13 hours agoparentprevTo me it seems without the art. The costs will be passed on to the customers. I think there must be good ways to do redundancy without having all services running at full blast in each Availability Zone.It&#x27;s a blunt tool, much like PHP. PHP does seem to be a good choice for them, but I wouldn&#x27;t want to work there. It&#x27;s all right, there are different ways to do stuff. reply gumballindie 14 hours agoparentprevOh hey they now have a new buzzword to sell! reply heywhatupboys 15 hours agoprevIs Slack dead? unironically. Does it have a future? With Teams, etc. coming out, it seems most companies do not want to go the Slack route reply PoignardAzur 27 minutes agoparentOne day Zulip will take over everything. Probably the same year Ubuntu beats Windows as the majority desktop OS. reply zomglings 10 hours agoparentprevI started using Slack in 2015 and thought it was a great product.Since then, they have hit 2 home runs on top of their basic chat functionality:1. Slack Connect: Being able to share channels between workspaces is simply amazing. Most of our customers are on Slack, and having a Slack connection to them makes it much easier to communicate with them and get their feedback as we improve our product. I don&#x27;t know any other tool that even comes close to how important Slack Connect has been to product development in my startup.2. Canvas: They rolled this out last year as notes or something, and I was pretty underwhelmed with the experience at first. But very recently (within the past month I think) they reintroduced this as \"canvas\" with really tight integration with threads. We have moved all of our planning and synchronization activity to a canvas that we set up every week.Although these features are not difficult for Google or Microsoft to implement on a purely technical level, their product organizations don&#x27;t seem to understand the network effects of chat the way that Slack&#x27;s product organization does.Slack is certainly not dead today and they are showing the savvy to stay alive well into the future. reply robertlagrant 15 hours agoparentprevTeams is doing well because it&#x27;s often an IT department&#x27;s simplest choice, but I don&#x27;t find it&#x27;s great for users. reply packetlost 14 hours agorootparentThe company I work for has a \"Hours wasted because Teams sucks\" page that gets updated at least weekly.Eventually the list will grow so large that we could probably attach a 5-figure dollar amount to it, if it hasn&#x27;t already. reply Racing0461 14 hours agorootparentDepending on the size of the company, that value is absolutely insignificant. reply hotnfresh 14 hours agorootparentBigcos with robust sales truly can’t afford the organizational-attentional cost of walking across the street to pick up a $10,000 coin. reply Racing0461 13 hours agorootparent&#x2F;s ? reply hotnfresh 11 hours agorootparentNo, that’s really how it is. They leave opportunities to save or make five-figure (and larger) amounts all the time, because it’s not worth the distraction from other activities. And also from straight-up mis-management, but a lot of the time they know exactly what they’re doing, and it’s on purpose, and it’s probably not a mistake. replyzo1 14 hours agorootparentprevWhy would I choose Slack for my employees when Teams integrates so nicely with everything else in the \"stack\". Teams is leaps and bounds ahead already, and Slack really lost the boat many years ago.Speaking of which, I&#x27;m going now to buy more Microsoft shares. reply zdragnar 14 hours agorootparentI don&#x27;t think I have ever heard someone favorably compare teams chat with slack before. Even when I worked at a company that used teams for video calls and MS for email and calendar and documents and what not, everyone used slack for chat.I don&#x27;t think anyone was sad that slack didn&#x27;t integrate with the other MS services \"stack\". reply fooster 14 hours agorootparentprevYou are choosing teams. What are your employees choosing? In my experience teams is a terrible mess and a company using it would exclude me from working for the company because they very likely don’t give a crap about the day to day experience of the employee. reply Shared404 14 hours agorootparentprev> Why would I choose Slack for my employees when Teams integrates so nicely with everything else in the \"stack\".Does it really though? In my experience teams has a buggy integration with other things in the stack.And Teams itself ia massively buggy and a resource hog for the whole time I&#x27;ve used it. reply grokys 12 hours agorootparentprevMaybe because you value your employees being able to copy an image from your chat platform?(Teams still can&#x27;t copy images, instead you get a massive base64 block of text iirc) reply xwowsersx 10 hours agorootparentprevThe boat or the moat? reply wasmitnetzen 15 hours agoparentprevMy employer buys no Microsoft SaaS service, since we&#x27;re mostly on Google services, so a stand-alone like Slack works quite well. And nobody uses Google Chat.And besides that, the UX of Teams is miles behind Slack. reply walthamstow 15 hours agorootparentNot even GitHub? I believe that&#x27;s the only MSFT service we have at my <40 people fintech dayjob reply quickthrower2 12 hours agorootparentprevSlack is not good UX in my opinion. It is often hard to see what generated a message notification - so yeah someone called me out, but who? where?. It shows me latest thread as being from last month when I know there have been more recent ones. It doesn&#x27;t collapse those threads, so 100 reply incident threads dominate that view. Slack doesn&#x27;t scale well (UX-wise) above say 30 people. reply snoman 11 hours agorootparentOpinions are valid, for sure. I can tell you that I’m a happy slack user at a company of just over a hundred thousand.I haven’t regularly used teams in about a year, but I would legitimately consider passing on a job offer where they used it.In a thread where many folks are talking about using the best tools for a job, teams is never the best tool for any form of digital communication. reply aftbit 15 hours agoparentprevClearly no. Legacy inertia will carry it pretty far, even if literally nobody new tries to sign up for it. Our team is still using Slack and has no plans to migrate away at the moment. reply devmor 15 hours agoparentprevIf your goal is to monitor your staff and gather metrics on their communication - Teams outdoes Slack and is incomparable. If your goal is to have a platform that enables your employees to communicate with as little friction as possible, I have yet to see anything capable of replacing Slack.Teams especially, is something I loathe using every day. Everything about the UI and UX gets in the way of what I’m trying to do, rather than assisting in or even enabling it. It’s like it doesn’t want me to communicate - it wants me to react and offer as little useful information as possible. reply ecshafer 15 hours agorootparentI went from a company using teams to slack a few years ago. Truly night and day. I have such a visceral hatred for Teams, it actually surprises me how much I can dislike some software that is for messaging. From how it can&#x27;t copy and paste in and out of chat, to the way it sets laptops on fire, or its horrible ui. I really truly hate that software. Please just use slack or god forbid set up an irc node or something. reply imperialdrive 14 hours agorootparentprevAgreed. Teams is already the most painful experience, and it&#x27;s about to get even worse with the new 2.0 version being deployed. reply enduser 15 hours agoprev [–] So.. IRC? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Slack has transitioned from a monolithic architecture to a cell-based architecture to enhance redundancy and minimize the impact of site failures.",
      "The migration was prompted by an incident where network disruption in one availability zone resulted in errors for Slack users.",
      "Slack's new cellular architecture enables the isolation of failures within a single availability zone and redirects user requests to ensure continuous service availability."
    ],
    "commentSummary": [
      "Slack has implemented a cellular architecture with a siloing strategy, allowing for better performance and scalability.",
      "The company also utilizes multiple availability zones to ensure high availability of their service.",
      "A major challenge in Slack's microservices architecture is the use of different programming languages, which can lead to compatibility issues.",
      "Users have expressed dissatisfaction with Slack's performance, especially when compared to Microsoft Teams.",
      "Suggestions have been made to consider using alternatives like IRC, which may offer better performance and reliability."
    ],
    "points": 340,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1693070848
  },
  {
    "id": 37278345,
    "title": "If you're interested in eye-tracking, I'm interested in funding you",
    "originLink": "https://twitter.com/paulg/status/1695596853864321055",
    "originBody": "Want to start a startup doing eye-tracking? If so I&#39;d be interested in funding it. A friend of mine has ALS and can only move his eyes. He has an eye-controlled keyboard, but it&#39;s not very good. Can you make him a better one?— Paul Graham (@paulg) August 27, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37278345",
    "commentBody": "If you&#x27;re interested in eye-tracking, I&#x27;m interested in funding youHacker NewspastloginIf you&#x27;re interested in eye-tracking, I&#x27;m interested in funding you (twitter.com/paulg) 292 points by pg 9 hours ago| hidepastfavorite126 comments Componica 5 hours agoMy three partners and I have be developing and selling multi-camera arrays specifically for eye tracking as well as measuring other physiological features for several years now. Our main customers are a couple university research groups, a human factors group in Lockheed, and just recently the US Air Force. In fact we just returned from a trip to Wright-Patterson installing an array in a hypobaric chamber to perform gaze tracker and pupil response for pilots under hypoxic conditions. Phase two will be a custom gaze tracker for their centrifuge. Our main features are accurate eye and face tracking up to a meter from the array, minimal calibration per subject (about 10 seconds staring at a dot), pupil response for measuring fatigue and other things, plus we can adapt the array for the client ranging from a cockpit to a large flat screen TV. We&#x27;ve looked into medical usage such as ALS, but we&#x27;re bootstrapped based in Iowa and found the military niche as a more direct way to generate cash flow. It&#x27;s ashame we can&#x27;t apply this work towards people with medical needs, but we don&#x27;t have the funds nor the clients to make such a pivot. reply t0mas88 39 minutes agoparentHave you thought about settinng up a subsidiary that licenses your base tech for a reasonable royalty fee and raise capital for the subsidiary to develop a medical product from it?The risk and part of the returns there are for the investors. While it will generate additional revenue (and diversification) for your bootstrapped company allowing you to keep building and mitigate some of the risk of having a narrow (military) client base.And if it becomes a major success (sounds like pg thinks that&#x27;s possible) you&#x27;ll co-own it. reply AndrewKemendo 8 hours agoprevI responded to the thread but Senseye has been working on this for a while now. Originally they were working with the US Air Force to help with improving pilot training - fatigue etc.. inference with retinal readinghttps:&#x2F;&#x2F;senseye.co&#x2F;They have generally struggled to find funding for their eye tracking focused work, and have recently had to pivot away from the really exciting but hard to fund stuff into PTSD screening (which is important too).I can connect you with the founder if desired via the email in my bio reply justinlloyd 5 hours agoprevI do hardware. I do software. I do computer vision. I built some software that ran on a cellphone used by LEO (law enforcement officers) to determine if the person they are quizzing is inebriated or impaired through controlled substances by examining the person&#x27;s eyes and having them focus on images displayed on the phone screen. I&#x27;ve done eye tracking using fully custom solutions and also through a few of the off-the-shelf SDKs such as GazeSense from eyeware and a few other SDKs.The problem is not the eye-tracking, it is reasonably easy to build robust systems that can do that easily enough, even with custom hardware under all sorts of lighting conditions. The hard part is the UX if you are trying to build something that isn&#x27;t hampered by current UI paradigms.Rapid typing and menus of custom actions with just eye movement, though fatiguing, shouldn&#x27;t be hard to solve, and then render the output however you want; text, text to speech, commands issued to an machine, etc. Making a usable user interface to do anything else, that&#x27;s where the rubber hits the road.@pg, which software is your friend using? If it is anything like I&#x27;ve looked in to in the past, it&#x27;s over-priced accessibility crap with a UI straight out of the 1990s. reply modeless 5 hours agoparentYes, UX is the key. The iPhone succeeded because they didn&#x27;t just take macOS&#x27;s mouse&#x2F;keyboard UI and slap it under a touchscreen. They took the limitations and strengths of capacitive touch and designed a bespoke UX with new concepts everywhere.Input modalities define platforms. Eye tracking is a new input modality and will define a new platform. It needs a whole new UX designed around its limitations and strengths. It needs a keyboard, it needs a browser, it needs copy and paste, it needs an app switcher, it needs a whole vocabulary of standard interactions and best practices. Apple has a good start in Vision Pro but they&#x27;re not going to be the only ones doing UX for eye tracking. There&#x27;s definitely room for other players with fresh ideas. reply dewarrn1 8 hours agoprevEEG recording is an alternative that would outlast the potential disease-related degradation of eye movements. Manny Donchin gave a brown bag at UIUC about the possibilities of using this approach to support communication by ALS patients many years ago. It&#x27;s clever: they use the P300 marker to index attention&#x2F;intention. I do not recall whether he and his colleagues ever commercialized the tech. I believe that this publication is representative: https:&#x2F;&#x2F;doi.org&#x2F;10.1016&#x2F;j.clinph.2005.06.027 reply mikpanko 5 hours agoparentI did a PhD in brain-computer interfaces, including EEG and implanted electrodes. BCI research to a big extent focuses on helping paralyzed individuals regain communication.Unfortunately, EEG (including P300) doesn’t provide sufficient signal-to-noise ratio to support good communication speeds outside of the lab with Faraday cages and days&#x2F;weeks of de-noising including removing eye-movement artifacts in the recordings. This is a physical limit due to attenuation of brain’s electrical fields outside of the skull, which is hard to overcome. For example, all commercial “mind-reading” toys are actually working based off head and eye muscle signals.Implanted electrodes provide better signal but are many iterations away from becoming viable commercially. Signal degrades over months as the brain builds scar tissue around electrodes and the brain surgery is obviously pretty dangerous. Iteration cycles are very slow because of the need for government approval for testing in humans (for a good reason).If I wanted to help a paralyzed friend, who could only move his&#x2F;her eyes, I would definitely focus on the eye-tracking tech. It hands-down beat all BCIs I’ve heard of. reply minihat 3 hours agorootparent+1 from a fellow BCI PhD. EEG tech is not ready for this application yet. reply matthewbarras 58 minutes agorootparent+1 +1 from another fellow BCI PhD. EOG over EEG at the moment (likely forever, non-invasively). reply incongruity 8 hours agoparentprevThis! Eye tracking is slow and not good - but does that just mean we need to “faster horse” it or is there another option for bridging the communication gap for people with ALS and similar diseases? I have to believe there are better answers with other tech - likely EEG (+ AI).My family is one of the unlucky ones that has genes for ALS so I’ve watched enough family members struggle. (I’m lucky, selfishly, because I dodged the gene but I still care deeply about this). reply BoorishBears 6 hours agoparentprevI had this thought, but then I thought about if my friend was struggling with a problem had had practical but imperfect solutions, would I better serve them by funding highly feasible solutions that they&#x27;re already familiar with, or experimental moonshots that are more likely to fail, will take longer to implement, and my friend may not even care for at all... reply blackguardx 8 hours agoprevI worked on eye tracking hardware for Microsoft HoloLens. Several AR headsets offer decent eye tracking, including Hololens 2 and Magic Leap&#x27;s ML2. I think Tobii&#x27;s eye tracking glasses are probably better as a stand-alone solution though: https:&#x2F;&#x2F;www.tobii.com&#x2F;products&#x2F;eye-trackers&#x2F;wearables&#x2F;tobii-... reply zh3 3 hours agoparentAgreed, the eye tracking itself is really a mostly-solved problem (Tobii are indeed leaders in the area). It&#x27;s how it&#x27;s used that matters - and as mentioned above, it&#x27;s likely that it&#x27;s the usability&#x2F;interface that needs work. reply tootie 4 hours agoparentprevHave used Tobii as well and they are very accurate with a bit of calibration. reply bacon_waffle 1 hour agoprevEdit: Check out Dasher for much better interface to enter text with a cursor, compared to a virtual keyboard.https:&#x2F;&#x2F;dasher.acecentre.net&#x2F; , source at https:&#x2F;&#x2F;github.com&#x2F;dasher-project&#x2F;dasher---I remember seeing a program years ago, which used the mouse cursor in a really neat way to enter text. Seems like it would be far better than clicking on keys of a virtual keyboard, but I can&#x27;t remember the name of this program nor seem to find it...Will probably get some of this wrong, but just in case it rings a bell (or someone wants to reinvent it - wouldn&#x27;t be hard):The interface felt like a side-scrolling through through a map of characters. Moving left and right controlled speed through the characters; for instance moving to the left extent would backspace, and moving further to the right would enter more characters per time.Up and down would select the next character - in my memory these are presented as a stack of map-coloured boxes where each box held a letter (or, group of letters?), say &#x27;a&#x27; to &#x27;z&#x27; top-to-bottom, plus a few punctuation marks. The height of each box was proportional to the likelihood that letter would be the next you&#x27;d want, so the most likely targets would be easier+quicker to navigate to. Navigating in to a box for a character would \"type\" it. IIRC, at any instant, you could see a couple levels of letters, so if you had entered c-o, maybe &#x27;o&#x27; and &#x27;u&#x27; would be particularly large, and inside the &#x27;o&#x27; box you might see that &#x27;l&#x27; and &#x27;k&#x27; are bigger so it&#x27;s easy to write \"cool\" or \"cook\".(I do hardware+firmware in Rust and regularly reference Richard Hamming, Fred Brooks, Donald Norman, Tufte. Could be up for a change) reply jwm1 56 minutes agoparentThat sounds like Dasher (https:&#x2F;&#x2F;dasher.acecentre.net&#x2F;about&#x2F;), invented by the late David MacKay. reply bacon_waffle 55 minutes agorootparentYep, thanks! reply Avshalom 56 minutes agoparentprevDasherhttps:&#x2F;&#x2F;dasher.acecentre.net&#x2F; reply bacon_waffle 44 minutes agorootparentWow that was quick, thanks!Have imagined a music theory&#x2F;improvisation practice program that looks something like Dasher + Guitar Hero. reply archo 9 minutes agoprevhttps:&#x2F;&#x2F;archive.is&#x2F;TiCun reply readyplayernull 8 hours agoprev> A friend of mine has ALS and can only move his eyes. He has an eye-controlled keyboard, but it&#x27;s not very good. Can you make him a better one?When I worked for one of the big game engines I got contacted by the makers of the tech that Stephen Hawking used to communicate, which includes an eye tracker:https:&#x2F;&#x2F;www.businessinsider.com&#x2F;an-eye-tracking-interface-he... reply amelius 18 minutes agoprevI hear the Apple Vision Pro has a good implementation. If this were Microsoft, you&#x27;d be able to find the details in the Microsoft Research website. reply musesum 7 hours agoprevI&#x27;ve been working on the menuing side [1] based on crossing Fitt&#x27;s Law with Huffman trees. But, don&#x27;t know the constraints for ALS.Hopefully, whomever takes this on doesn&#x27;t take the standard Accessibility approach, which is adding an extra layer of complexity on an existing UI.A good friend, Gordon Fuller, found out he was going blind. So, he co-founded one of the first VR startups in the 90&#x27;s. Why? For wayfinding.What we came up with is a concept of Universal design. Start over from first principles. Seeing Gordon use an Accessible UI is painful to watch, it takes three times as many steps to navigate and confirm. So, what is the factor? 0.3 X?Imagine if we could refactor all apps with a LLM, and then couple it with an auto compete menu. Within that menu is personal history of all your past transversals.What would be the result? A 10X? Would my sister in a wheelchair be able to use it? Would love to find out![1] https:&#x2F;&#x2F;github.com&#x2F;musesum&#x2F;DeepMenu reply arketyp 4 hours agoprevTobii have been doing eye-tracking since 2001 and have a product for that. https:&#x2F;&#x2F;www.tobiidynavox.com&#x2F; reply tpmx 4 hours agoparentBut that&#x27;s not in California so it doesn&#x27;t matter.(&#x2F;s) reply arketyp 4 hours agorootparentYou were being facetious, but Swedes are used to being flexible with collaborations. I don&#x27;t why I&#x27;m playing the ambassador, I don&#x27;t work there. reply fastball 8 hours agoprevIs the lack of mentioning Apple deliberate? It seems like they&#x27;ve already poured a lot of R&D into this for the Vision Pro, which might be exactly the kind of thing the friend needs. reply pg 8 hours agoparentIt&#x27;s not available yet. And in any case if this is the future there should be multiple companies doing it, not just Apple. reply ladberg 7 hours agorootparentI used to work on it and have spent tons of time in the headset. The eye tracking is next-level and it&#x27;s really the only platform that exists with eye tracking as a primary input method. I&#x27;m pretty confident it will greatly improve your friend&#x27;s quality of life.Because of that, I&#x27;m also sure that eye tracking will go mainstream in other areas once the Vision Pro is released once everyone else catches on to it as a great input method. reply GnarlyWhale 1 hour agorootparentThis is pretty much exactly why I vehemently disagree with Apple&#x27;s decision to draw such a firm line in the sand preventing devs from accessing the eye&#x2F;gaze data directly. I&#x27;m part of an academic spin-off start-up that specializes in analyzing gaze and movement data. Locking the gaze information outside of the app sandbox severely hampers the ability to quickly iterate design and UI patterns that could be game changing for accessibility. Hopefully they make accommodations moving forward for these circumstances.The issue is doubly close to my heart because my father has ALS and is nearly at the point where eye-tracking will be his only means of communicating effectively with the world. While existing Tobii systems work well enough, typing with your eyes is still exhausting to do.Ultimately I don&#x27;t think a platform like the vision pro is suitable for ALS patients, especially later term. They cannot support the weight of the headset and&#x2F;or fatigue will set in rapidly. Many (including my father) also require use of a ventilator, accompanied with a mask that can seal effectively enough to support the positive pressure necessary to inflate their lungs. Unless the form factor for HMD&#x27;s minimalizes significantly, it will likely interfere with the respirator&#x27;s efficacy. reply blululu 5 hours agorootparentprevThe level of eye tracking performance for general population interactions is really only possible when you control the illumination like in a VR headset. A Vision Pro might work for the friend in question. More generally this requires the full vr display to make it work. See through AR or just plane glasses will not be nearly as good, and I think that will cap the general acceptance. reply dgrin91 6 hours agorootparentprevDoesn&#x27;t it rely on external cameras to see users hands and use that as the \"click\" inputs? Seems like that negates usage for ALS cases.Also, I&#x27;m not an ALS expert, but if the only muscular control is in the eyes, then lack of control in the head&#x2F;neck probably breaks some assumptions about how the vision headset works (just a guess though). reply extra88 5 hours agorootparentIt does not require using one&#x27;s hands to click, it supports various input hardware (keyboard, mouse, switch, etc.). If someone has control of basically any muscle, it can use a switch input. The Vision Pro also has Dwell Control, activating things by keeping your gaze on it long enough, but I don&#x27;t know whether it can currently be solely operated using nothing but one&#x27;s eyes. reply Anticlockwise 6 hours agorootparentprevNot just multiple companies, multiple approaches. Eye tracking is exhausting, and that&#x27;s pretty fundamental to the modality - dwell time requires significant control to be usable as a click, and even able bodied people find it exhausting. Some folks have tried doing eye tracking and using something else (EMG for example) as the click, but it doesn&#x27;t work consistently for the population. ALS is also progressive, and people lose their eye control. Blackrock Neurotech has been working on a brain implant, with spinal cord injury as a first target population (because they&#x27;re less fragile, among other reasons), and it works for current research patients, but medical devices take a lot of time, money and work to get cleared in the US. The implant itself is cleared, but the FDA wants the entire system to be cleared too. reply Difwif 8 hours agorootparentprevGlad to see you still lurk around here. How do you think about going up against a company like Apple when it comes to patents in this space?I think that would be my major hesitation but I don&#x27;t have a lot of experience evaluating patents.Apples Eye Tracking Patent: https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;US20180113508A1&#x2F;en reply dtihanyi 7 hours agorootparentprevAgreed. It would be great if the hardware was more affordable&#x2F;accessible as well. That&#x27;s potentially a barrier to entry worth addressing for devs who might otherwise be interested in tackling the problem, but don&#x27;t have the quality eye tracking hardware to start. A Tobii-like hardware devkit could be a starting point. reply KaiserPro 2 hours agoparentprevYes, because:1) its eye tracking isn&#x27;t good enough for this kind of application.2) direct access to the gaze vector is disabled3) its really intrusive4) its heavy.5) it doesn&#x27;t exist(in consumer world) yet.The goal is to enable someone who has motor control issues, be able to communicate directly with the outside world. Shoving a heavy skimask that totally obscures the outside world on their face directly stops that.Not only that, but you&#x27;ll need to create and keep up to date the software needed to make a communicator. Apple are many thing, but it&#x27;s new platforms are not stable, rapid os updates will break things. reply omeze 7 hours agoparentprevALS really doesn’t leave much strength for having a headset strapped to you… reply fartjetpack 8 hours agoprevAnother route might also be sub-vocalization[1], like TTS for your thoughts. I recently picked up some cheap toys to get started trying to emulate the results[2].1. https:&#x2F;&#x2F;www.nasa.gov&#x2F;centers&#x2F;ames&#x2F;news&#x2F;releases&#x2F;2004&#x2F;subvoca...2. https:&#x2F;&#x2F;github.com&#x2F;kitschpatrol&#x2F;Brain reply tbenst 5 hours agoparentI agree! My PhD thesis is on this topic [1]. We’ve also done a very limited pilot test on a patient with ALS, with above random chance. Actual results may vary heavily on individual disease progression—the more motor recruitment that’s intact, the better.[1] https:&#x2F;&#x2F;neuroscience.stanford.edu&#x2F;research&#x2F;funded-research&#x2F;s... reply qup 8 hours agoparentprevHow is it going? It&#x27;s not obvious to me at a glance. reply fartjetpack 8 hours agorootparentI should clarify that is not my repo. I just received the Mind Trainers and am in the process of finding suitable EEG pads. reply qup 7 hours agorootparentI guess I&#x27;m just interested in more information. Do people who aren&#x27;t NASA have this working? I am just learning this sci-fi feature from Ender&#x27;s universe is possibly a reality, and if I can check it out, I want to.Got any jumping off points? reply MasterYoda 1 hour agoprevPG mention that the solution his friend used wasn&#x27;t any good. How does the best system there is out today work? And what different solutions are there? reply modeless 5 hours agoprevI agree, eye tracking is going to have really broad applications. I&#x27;ve been interested in eye tracking for over a decade, and in fact built my own eye tracker, joined a startup, and got acquired by Google[1]. But there&#x27;s way more to do. We&#x27;ve barely scratched the surface of what&#x27;s possible with eye tracking and I&#x27;d love to take a second crack at it.[1] https:&#x2F;&#x2F;techcrunch.com&#x2F;2016&#x2F;10&#x2F;24&#x2F;google-buys-eyefluence-eye... reply krsrhe 5 hours agoparentWhat happened to the tech after acquisition? reply modeless 4 hours agorootparentThe \"Daydream View\" VR headset developed before we were acquired totally bombed. Then a bunch of VR tech, including both long running internal projects and recent acquisitions, got shelved. reply ZeroCool2u 6 hours agoprevI literally just bought this last night. Works with just a webcam and is shockingly accurate. https:&#x2F;&#x2F;beam.eyeware.tech&#x2F; reply acyou 4 hours agoprevYes, the ALS&#x2F;disability angle is noble. Viewed another way, the entire human race is afflicted by the disability of not having access to eye-tracking (and other) technologies. Paul Graham and co. are also invested in companies that are going to be highly enabled and boosted by the growth of eye-tracking and related technologies. I don&#x27;t view his statement of motivation related to ALS as insincere, I just also notice that it&#x27;s accessible, easily understandable, and also in line with other aspects of Paul&#x27;s motivation (and that&#x27;s a good thing).I would also recommend Jean-Dominique Bauby&#x27;s Le Scaphandre et le Papillon to anyone interested in this topic. Typing using eye movements was used in that book in a slow, inefficient manner. In the book&#x27;s case, the question one should ask is, was his UI paced at the exact correct speed? I was and still am deeply emotionally moved by what the author was able to accomplish and convey. I am unsure if a faster keyboard would have made a meaningful and positive difference in that particular case, to the author&#x27;s quality of life. I&#x27;ll need to give that book another read with that question in mind.Happily, I expect eye tracking to find fascinating, novel and unexpected applications. As others have stated, UI&#x2F;UX design is an interesting part of this puzzle. For example, if you ask an LLM to output short branches of text and have a writer look at the words that he wants to convey. It&#x27;s definitely blurring the line between reading and writing. Myself, finding writing to be a tactile exercise, I think that emotional state comes into play. That&#x27;s what I&#x27;m interested in. Yes, can you literally read someone&#x27;s eyes and tell what they are thinking? reply sailplease 7 hours agoprevAdhawk, adhawk.io, has the only all day ultralight eye tracking wearable I&#x27;m aware of, all MEMS based with ultra high scan rates, 500Hz+ and research grade accuracy. For ALS u likely need something light and frictionless, wearing a hot and heavy headset all day probably doesn&#x27;t work. reply mercurialsolo 4 hours agoprevEye tracking is essentially a model of visual attention. Visual attention is part of the overall attention space and big companies and use-cases are built around visual attention. Today we track attention by explicit interactions, if we can model around implicitly observable interactions - then we have a much larger observable data space around the user., reply mcbutterbunz 4 hours agoparentThis comment makes me think we’ve gone too far and I should shut off my phone. reply guerrilla 2 hours agorootparentIndeed, it&#x27;s time to re-learn how to live without the Internet and such advanced technology. reply sprocket 6 hours agoprevI used this software when my mom was battling ALS: https:&#x2F;&#x2F;www.optikey.org&#x2F;which ran on a$10-15k) which were sadly out of out budget. reply supremearkitect 2 hours agoprevLooking at the downvoted comments, it feels like YC&#x2F;PG has been hit by the \"curse of desirability\", like Google did back in the day when it was desirable: so many people have been rejected by them that they have accumulated a critical mass haters who will attack them at every opportunity. reply sillysaurusx 2 hours agoparentHmm. I was curious and started looking for the comments you mention, and was pleasantly surprised to find zero pg hate comments, downvoted or otherwise. People seem pretty on board with billionaires solving problems for disabled people in exchange for mutual upside.I used to be bothered by those kinds of sentiments too, by the way. The way I got over it was to realize how many people are just bitter, and not because of pg or YC. This is different than having an actual issue with pg or YC — it’s random noise rather than points worth listening to.Weirder than the haters are the people who reply to his tweets. Some of them post bizarre things. I find it fascinating when people project their own feelings on him, whether it’s hate, admiration, or (my favorite, having been a victim of it myself) misplaced ambition. reply gwurldz 8 hours agoprevThis seems like it would fithttps:&#x2F;&#x2F;thinksmartbox.com&#x2F;products&#x2F;eye-gaze&#x2F;I once interviewed at this company. Unfortunately didn&#x27;t get the job but very impressed nonetheless. reply Verath 3 hours agoparentI was part of developing the Lumin-i variant of this (working for Smart Eye)! Working with the Smartbox team was a pleasure :).The solution actually works pretty well, especially when calibrated to a single individual. reply ankaAr 6 hours agoparentprevI work for them.., they have their ins and outs. The stack is very impressive but there is a loooot to improve yet reply tmalsburg2 3 hours agoprevSolving eye-tracking keyboards is not so much a task for a company with eye-tracking expertise but for one with expertise in large language models. reply jfrbfbreudh 3 hours agoparentPlease elaborate. reply user3939382 7 hours agoprevHow about a library that starts loading a link when you look at it with intent. Or maybe with BCI integration that detects the moment you decide you want to access it.Or how about a UI that automatically adapts to your eye movement and access patterns to minimize the amount of eye movement required to complete your most common tasks by rearranging the UI elements. reply 6stringmerc 3 hours agoprevJason Becker is a great subject because if you can help him compose with his eyes the world can use his music he’s a genius. reply quietthrow 5 hours agoprev@paulg look in to this: https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;brain-implant-speech reply KaiserPro 2 hours agoparentno. Thats super intrusive, and given the the risks of major surgery with ALS, its not a good option. reply PBnFlash 8 hours agoprevI suspect a foveated system is going to be a big thing in machine vision as well. reply steve_adams_86 8 hours agoparentThat&#x27;s an interesting idea. How do you see it being beneficial to machine learning models, other than (I assume) it could work more efficiently within less foveal regions? Perhaps cases where you want the vision to emulate human vision? reply PBnFlash 7 hours agorootparentRunning a fast network on sparse data then calling one optimized for a task on a subset seems like a good optimization and dealing with video we are probably going to need them.After you parse what an object is, tracking it doesn&#x27;t take anywhere near the effort of original segmentation. No need to re-evaluate until something changes.Maybe even use activations to turn on and off networks. \"Oh text better load ocr into memory\"And it does inform a lot of our built world It&#x27;s strange to think that when watching a movie only 10% is in focus.Eye movement does provide a lot of information to other people and I think the physical movement produces feedback for velocities and things too. Mimicking biology is often a good bet. reply kken 7 hours agoprevIn case anyone is interested: There are plenty of companies around.Both apple and Facebook acquired eye tracking companies to kickstart their own development.Here are some Top-listshttps:&#x2F;&#x2F;imotions.com&#x2F;blog&#x2F;insights&#x2F;trend&#x2F;top-eye-tracking-ha... https:&#x2F;&#x2F;valentinazezelj.medium.com&#x2F;top-10-eye-tracking-compa...Its also an active research field, this is one of the bigger conferences: https:&#x2F;&#x2F;etra.acm.org&#x2F;2023&#x2F; reply TootsMagoon 7 hours agoparentRe: There are plenty of companies around.I believe Paul Graham can Google or use AI and already knows about the companies and links you posted. His post was a call to action to connect with people working on yet to be discovered innovations and inspire those and others quietly working to come forward and connect with him. reply kken 7 hours agorootparentWell I thought people may be interested in learning what is already out there. reply joshm93 3 hours agoprevI can make an eye tracking keyboard with tensor flow, if anyone is interested in this problem.It would be great to hear from paul about how his friend uses the keyboard and what kind of tasks he’d love to do but can’t with current solutions.It seems like a throughput problem to me. How can you type quickly using only your eyes?Have people explored using small phonetic alphabets or Morse code style encoding?Once I got tensorflow working, I’d start mapping different kinds of ux. Throughput is king. reply splatcollision 8 hours agoprevThis was designed for a graffiti artist with ALS:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EyeWriterhttps:&#x2F;&#x2F;github.com&#x2F;eyewriter&#x2F;eyewriterhttps:&#x2F;&#x2F;www.instructables.com&#x2F;The-EyeWriter-20&#x2F;https:&#x2F;&#x2F;www.moma.org&#x2F;collection&#x2F;works&#x2F;145518 reply peter_retief 1 hour agoprevI would like to look at the problem more deeply, the eyes can be tracked but what about facial movement, the more data the better training for machine learning reply frakkingcylons 8 hours agoprevI hope this effort bears fruit. My uncle passed from ALS eight years ago. reply jacquesm 5 hours agoprevWhatever happened to GazeHawk and their crew? reply quickthrower2 6 hours agoprevWhat about brain waves to control the keyboard? reply hardwaregeek 8 hours agoprevAw, that&#x27;s nice of pg to want something better for his friend. As cynical as we are about technology, new developments can be so fantastic for accessibility and better quality of life. reply forgetfreeman 8 hours agoparentAnd if that were where the story ended we&#x27;d have an honest feel-good going. New developments -could- be fantastic for accessibility and QoL, but without exception they just end up getting sucked into a marketing surveillance suite. reply frenchman99 7 hours agoparentprevnext [5 more] Unfortunately we use all that technology on devices that are built with metals mined by kids in Congo and similar states. Talk about quality of life. reply lotsofpulp 7 hours agorootparentThose are unrelated topics. Not developing the technology is not going to help those kids’ quality of life. reply frenchman99 6 hours agorootparentBut building it as we currently are is directly putting them at risk of poisoning, dying buried alive when their cobalt mining tunnels collapse, etc. reply CyberDildonics 6 hours agorootparentprevThis has nothing to do with anything and it isn&#x27;t even true.You are talking about cobalt and that is only used in lithium ion batteries. You can avoid cobalt by using lithium iron phosphate batteries.There are active efforts to develop new lithium ion chemistries to avoid cobalt and there are even commercial sodium ion batteries now.You bring this in to a completely irrelevant conversation, what have you done to help solve it? reply frenchman99 5 hours agorootparentLithium extraction is also very bad for the environment. Requires insane amounts of water, requires often times destroying forests or other natural areas that are on top of lithium, etc.Sure I use lithium ion batteries too, in the developed country I live in, I can&#x27;t go and live in a cave. But I won&#x27;t buy a SUV that weighs 2 tons to sit alone in it most of the time and have it parked 95% of the time in a garage.The \"what have you done\" attack is a bit too easy and, really, this is not about me.We should strive to be sober, to buy repairable goods whenever possible, to educate ourselves on environmental impact of things, and perhaps more importantly to teach this to our children. reply soligern 8 hours agoprevIt feels like Apple has solved this problem with the Vision Pro? So just wait for a couple more months? reply post_break 8 hours agoparentExcept Apple has stated they will encrypt that information and not supply it to apps to avoid targeting or fingerprinting. And second how would that help someone with ALS? reply gnicholas 6 hours agorootparent> And second how would that help someone with ALS?They won&#x27;t share information on where you look, but they will share info on where you &#x27;click&#x27;, which is used to navigate apps. IIRC you are supposed to use your fingers to do this, and other actions, but I imagine that Apple&#x27;s accessibility team will have an alternate mode for people with motor limitations. It could be a long-blink, or rapid blinking, for example. reply LegitShady 5 hours agorootparentEven the large headset is a no go for als sufferers. reply hparadiz 8 hours agorootparentprevPeople use stuff like this in VRChatVR Eye-Tracking Add-on Droolon F1 for Cosmos(Basic Version) https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;asAAZwTYou can use it with any headset cause the data it provides is independent of the headset. Not sure how accurate that one is in particular.Eye tracking data is not particularly complex nor super sensitive in nature. Once the sensor is calibrated it just sends over two vectors. reply woodruffw 8 hours agoparentprevThe context here is ALS; someone with only the ability to move their eyes may not have a couple of months free to wait. reply soligern 8 hours agorootparentI think that makes sense but a startup is going to have a hard time delivering something better between now and January if they start from scratch.But maybe I’m wrong, it might be a purely software based problem that can be solved quicker. reply woodruffw 8 hours agorootparent> I think that makes sense but a startup is going to have a hard time delivering something better between now and January if they start from scratch.I agree entirely! reply KaiserPro 2 hours agorootparentprevnot really.There are a bunch of hardware out there to get gaze vectors, the problem is that they rely on a generalised model of the eye. With fine tuning you can go from >5 degree of error, toNot really a huge PG fancan you elaborate? reply j45 8 hours agoparentprev [–] Not sure if PG fits a billionaire stereotype.YC was investing in ways the traditional VCs weren’t when it started, and coding HN was a part of it. I doubt I’m the only one who had having a few HN tech support emails from PG. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Paul Graham, a renowned investor and co-founder of Y Combinator, is actively seeking to fund a startup that focuses on enhancing eye-tracking technology for people with ALS.",
      "The startup's primary goal would be to develop an improved eye-controlled keyboard, which can greatly assist individuals affected by ALS in communication and everyday tasks.",
      "Graham's interest in this field showcases the potential for technological advancements to significantly improve the lives of those with ALS, offering a glimpse into the exciting possibilities of assistive technology innovation."
    ],
    "commentSummary": [
      "The post on Hacker News explores the potential applications of eye-tracking technology and its impact on usability and accessibility for individuals with limited physical mobility, like those with ALS.",
      "The limitations and challenges of eye-tracking are discussed, along with alternative technologies and solutions.",
      "The post mentions various companies, products, and advancements in the field, highlighting the positive potential for improving the quality of life for individuals with disabilities. Additionally, there is a brief discussion on the environmental impact of lithium extraction and ethical implications of technology development."
    ],
    "points": 293,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1693097473
  },
  {
    "id": 37275856,
    "title": "90% of “eco-friendly” paper straws contain traces of toxic forever chemicals",
    "originLink": "https://scienceswitch.com/2023/08/27/90-of-eco-friendly-paper-straws-contain-traces-of-toxic-forever-chemicals/",
    "originBody": "Skip to content Home About Contact the site’s owner Search SCIENCESWITCH Exploring the Depths of Curiosity with Razeez HEALTH 90% of “Eco-Friendly” Paper Straws Contain Traces of Toxic Forever Chemicals Date: August 27, 2023 Author: ScienceSwitch 1 Comment The growing movement against single-use plastics has led many bars and restaurants to swap plastic straws for paper ones. On the surface, this seems like an easy win – we get to sip our drinks through an eco-friendly alternative while keeping tons of plastic out of landfills and oceans. But the truth about paper straws is more complicated. A study conducted at the University of Antwerp found that a shocking 90% of so-called eco-friendly paper straws actually contain traces of “forever chemicals.” Forever chemicals, more formally known as per-and polyfluoroalkyl substances (PFAS), are compounds that don’t break down once released into the environment or our bodies. They stick around virtually forever, which is how they got their ominous nickname. PFAS have been linked to concerning health effects including high cholesterol, reduced immune response, thyroid disease, and increased risk of certain cancers. So why are they turning up in paper straws? The researchers tested 39 different brands of straws made from various materials like paper, bamboo, glass, stainless steel, and plastic. PFAS were detected in the majority – 69% overall. But paper straws were by far the worst offenders, with PFAS identified in a whopping 90% of brands tested. The concentrations varied quite a bit, but the frequent presence of the chemicals suggests they were likely intentionally added in some cases. PFAS are sometimes used as a water-resistant coating – not something you want leaching into your daily iced tea. Among the PFAS found in paper straws was perfluorooctanoic acid (PFOA), which has actually been globally banned since 2020 due to health risks including cancer and organ damage. Also frequently detected were other concerning PFAS chemicals trifluoroacetic acid (TFA) and trifluoromethanesulfonic acid (TFMS). While bamboo straws fared slightly better than paper ones, PFAS was still found in 80% of the bamboo brands tested. Plastic and glass straws also occasionally contained PFAS, though less commonly than plant-based options. The one material that seems safest is stainless steel – the researchers did not detect any PFAS compounds in the steel straws analyzed. While the PFAS levels measured in this study were fairly low, these chemicals have the ominous ability to accumulate in the human body and the environment over time. The findings raise the question – if paper straws leach PFAS into our drinks over months and years of use, could they be harming our health? Unfortunately the current research didn’t examine whether the chemicals transfer into liquids. But previous studies have shown PFAS can migrate from food packaging materials into actual food and drinks. More research is critically needed to determine if PFAS leach out of paper straws during typical use. In the meantime, it’s clear we need to rethink the assumption that paper and other plant-based products are inherently better for health and sustainability compared to plastic. The revelation about paper straws casts doubt on the idea that swapping plastic for paper is a foolproof eco-friendly solution. After all, PFAS spreading from straws into waterways and landfills still contribute to environmental contamination – regardless of that paper label. The study was published in the journal Food Additives and Contaminants. SPREAD THE KNOWLEDGE! FacebookTwitterRedditWhatsApp Related Your BPA-Free Water Bottles May Not Be Safe. Here’s Why. Microplastics Detected in the Marine Air from Norway to the High Arctic BPA-free Products Maybe Just As Hazardous, Scientists Warn ECO-FRIENDLY TRADEOFFSFOREVER CHEMICALSPAPER STRAWSPFAS RISKSPLASTIC POLLUTION Post navigation PREVIOUS Previous post: Naked Mole Rat’s Longevity Gene Gives Mice a Longer Life ONE THOUGHT ON “90% OF “ECO-FRIENDLY” PAPER STRAWS CONTAIN TRACES OF TOXIC FOREVER CHEMICALS” Add Comment SheketEchad August 27, 2023 at 4:50 am PFAs for the day. Walked Walden Pond path today – beautiful place . Lots of fishermen. But the warning sign on the boat ramp advised no more than two fish per month due to PFAs. Then there was the mercury warning in addition Like Reply LEAVE A REPLY This site uses Akismet to reduce spam. Learn how your comment data is processed. Izberite jezik slovenščina afrikanščina ajmarščina albanščina amharščina arabščina armenščina asamščina azerbajdžanščina bambarščina baskovščina beloruščina bengalščina bojpurščina bolgarščina bosanščina burmanščina češčina čevščina danščina diveščina dogri esperanto estonščina evejščina finščina francoščina frizijščina galicijščina grščina gruzinščina gudžaratščina gvaranščina haitijska kreolščina havajščina havščina hebrejščina hindijščina hmonščina hrvaščina igboščina ilokanščina indonezijščina irščina islandščina italijanščina japonščina javanščina jidiščina jorubščina kanareščina katalonščina kazaščina kečvanščina kinjarvandščina kirgiščina kitajščina (poenostavljena) kitajščina (tradicionalna) kmerščina konkanščina korejščina korziščina koščina krijščina kurdščina (kurmandži) kurdščina (soranščina) laoščina latinščina latvijščina lingala litovščina lugandščina luksemburščina madžarščina maitilščina makedonščina malagaščina malajalščina malajščina malteščina maorščina maratščina meiteilon (manipurščina) mizojščina mongolščina nemščina nepalščina nizozemščina norveščina odijščina (orijščina) oromščina pandžabščina paštunščina perzijščina poljščina portugalščina romunščina ruščina samoanščina sanskrt sebuanščina sepedščina sesotščina sindščina singalščina slovaščina somalščina srbščina sundanščina svahilščina škotska gelščina šonščina španščina švedščina tadžiščina tagaloščina tajščina tamilščina tatarščina teluščina tigrinjščina tsongščina turkmenščina turščina tviščina ujgurščina ukrajinščina urdujščina uzbeščina valižanščina vietnamščina zulujščina Uporablja tehnologijo Prevajalnik ScienceSwitch (formerly Sparkonit) offers insider perspectives on the latest advancements in science, technology, engineering, and math. Through frequently updated articles and news posts, we dive deep into trending topics and emerging innovations across the STEM fields. FOLLOW BLOG VIA EMAIL Enter your email address to follow this blog and receive notifications of new posts by email. Email Address: Follow Join 12.5K other subscribers POPULAR POSTS 90% of \"Eco-Friendly\" Paper Straws Contain Traces of Toxic Forever Chemicals Why Do Old Books Smell So Good? Naked Mole Rat's Longevity Gene Gives Mice a Longer Life Revolutionary Electrolyzer Efficiently Converts CO2 into Renewable Propane Fuel What Happens When You Lick A Battery? The Terrifying Possibility of Accidental Nuclear War If You Are A Grammar Nazi, Scientists Have Bad News For You Wearing The Same Shirt Everyday Is A Sign Of Genius, Psychologist Suggests How to Get Rid of Mosquitoes Excessive Screen Time Linked to Developmental Delays in Toddlers, New Study Finds © 2023 SCIENCESWITCH Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37275856",
    "commentBody": "90% of “eco-friendly” paper straws contain traces of toxic forever chemicalsHacker Newspastlogin [dupe] 90% of “eco-friendly” paper straws contain traces of toxic forever chemicals (scienceswitch.com) 257 points by conse_lad 14 hours ago| hidepastfavorite144 comments swores 14 hours agoSee also 86 comments a day ago: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37256484 reply hristov 12 hours agoprevThis smells like astroturfing in favor of plastic. The fact that something contains \"traces\" of PFAS is not that much of a revelation. Unfortunately, thanks to tragically insufficient environmental regulation, PFAS have gotten everywhere nowadays, so most naturally sourced ingredients will contain traces of PFAS.It is important to know how much PFAS they contain, whether those amounts are higher than the wood feedstock (i.e., are PFAS being added), whether the amounts are medically relevant, and whether the amounts are more than the alternative. (And lets not kid ourselves, stainless steel straws are not a viable alternative.) reply yyyk 3 hours agoparentI&#x27;m not so sure this is the case regarding paper straws&#x2F;cups. At least regarding paper cups, they do not involve paper alone but some addition of plastics (extra hardness and plasticity, avoiding water soaking). I suspect it&#x27;s the same for straws as the same reasons apply. So this measurement is likely a result of production and not outside pollution. reply nerdponx 12 hours agoparentprevMaybe they&#x27;re not a complete replacement in all cases, but for getting an iced latte from the local coffee shop, the metal straws are just fine. There are also reusable plastic ones. reply KETpXDDzR 8 hours agoprevPaper straws are the perfect example of human hypocrisy. It sounds so convincingly good for the nature and makes everyone forget that the oceans are polluted with fishernets.Effectively, paper straws are really really bad when it comes to recycling. Since paper doesn&#x27;t have the right qualities for a straw (it will soak up all the liquids pretty fast), they are usually coated inside. That makes it problematic for recycling since you somehow need to reverse that coating. Besides, recycling paper costs a lot of water. Plastic on the other hand doesn&#x27;t need coating and is pretty easy to recycle (a bit harder if it&#x27;s colored). The reason why this doesn&#x27;t happen is simply that new plastic is much cheaper than recycled one. I&#x27;m afraid with the de-icing of Greenland this trend will continue with all the new sources of oil. reply teekert 12 hours agoprevIs this just because these chemicals are just everywhere? Or are PFAS actually used in the production of straws? reply evolve2k 12 hours agoparentPFAS are used to add a water resistant coating to paper products, so I’d imagine straws to be worse than most paper cutlery as they literally needs to be designed to be submerged in water.The article linked out to this related article: https:&#x2F;&#x2F;www.theguardian.com&#x2F;environment&#x2F;2022&#x2F;jan&#x2F;26&#x2F;water-re... reply tenken 13 hours agoprevMy uncle has Parkinson&#x27;s disease attributed (in part) by Veterans Affairs due to Agent Orange exposure in Vietnam.He can only drink out of a cup using a straw due to the trembling and shakes.Also, straws are fun. reply therealdrag0 7 hours agoparentMaybe Buy him some metal straws with rubber mouth pieces. reply stop50 14 hours agoprevwhy should stainless steel require pfas? reply c4mpute 14 hours agoparentStainless steel is expensive, roughly a factor of 10 compared to plain steel. The reason is that Chromium is expensive. You can use low-chromium not-so-stainless steel if you then coat it with transparent paint containing among other things, PFAS, and save a ton of money on the material.Edit: the prototypical stainless steel is Cr&#x2F;Ni 18&#x2F;10 with 18% chromium and 10% nickel, aka V2A or 1.4301 reply PeterisP 13 hours agorootparentStraws require ridiculously small amounts of raw materials though, if you choose a material that increases the steel price by $1000&#x2F;ton, then that adds a single extra cent to the costs of a 10g metal straw which then retails for a dollar a piece. reply hirsin 13 hours agorootparentSo you&#x27;re saying you can cut it out and increase profit by a percentage point? That&#x27;s pretty huge.I recall finance going ballistic on my division at one point because our profit margin dropped by a tenth of a percentage point (and yet was still well above fifty) reply ryanwaggoner 12 hours agorootparent99.999% of corporations are way too wasteful to be complaining about a tenth of a percent on 50%+ margin.Think of the savings of slashing that finance department staff :) reply hirsin 12 hours agorootparentWith 8 billion in revenue it hit differently I guess, yeah. reply ThunderSizzle 14 hours agorootparentprevSounds about right. Most grills out here are $200-400, but will rust and fall apart within a couple years in my climate (humidity is insane here).For $2000-4000, you can buy real stainless steel grills that are warrantied to last 15+ years, not 1 year. reply BolexNOLA 12 hours agorootparentHard to sell people on spending 10x the cost when they can just buy, abuse, replace after 3-5 years what they already have. reply ThunderSizzle 9 hours agorootparentCertainly. Especially when they load the cheap stuff with all the useless Bluetooth&#x2F;wireless smart phone app crap. I guess people think a crappy grill with flashy widgets and an app is the next best thing. Or maybe it&#x27;s what companies think people want. reply kyleyeats 14 hours agorootparentprevI don&#x27;t think this really happens. reply xenonite 14 hours agoparentprevWell there wasn’t any PFAS with the stainless steel straws. reply conse_lad 14 hours agoparentprevTo provide additional resistance to corrosion&#x2F;staining. reply yetanotherloser 14 hours agorootparentThat sounds unlikely. It&#x27;s not how stainless steel works; to bond a coating to the surface of the stainless you have to fight the stainlessness pretty hard. reply galangalalgol 14 hours agorootparentOne of the best indicators for not so stainless stainless steel is a coarse texture to aid in that bonding. Even some fairly expensive brands of vacuum flask exhibit this. Only way to be sure that I know of is a knife. reply jdietrich 12 hours agorootparentGenerally, the easiest way is with a magnet. The most corrosion-resistant of the common stainless steels are austenitic. These steels are not ferromagnetic, or very weakly ferromagnetic if they have been cold worked. Cheaper and less corrosion-resistant ferritic stainless steels are strongly ferromagnetic.Martensitic stainless steels are less corrosion resistant than austenitic steels and are ferromagnetic, but they&#x27;re used for good reason. Unlike other types, martensitic steels are hardenable through heat treatment, making them the only suitable choice for many sharp-edged tools or parts subject to severe abrasion. Stainless steel cutlery is most commonly an 18&#x2F;0 ferritic grade, but premium cutlery may be an 18&#x2F;10 austenitic. Kitchen knives are invariably martensitic, because ferritic or austenitic grades wouldn&#x27;t hold a sharp edge. reply bornfreddy 12 hours agorootparentprevYou mean by scraping it and seeing if it rusts, or something else? reply tomxor 12 hours agoparentprevSome pretty nasty accidents have already happened with stainless steel straws... doesn&#x27;t take much imagination. reply yetanotherloser 14 hours agoparentprevWhere did someone suggest it did? reply wahnfrieden 14 hours agorootparentThe article suggested it is a concern, and then resolved the concern. reply xdennis 12 hours agoprevThis is one of the few issues where I feel I&#x27;m the only sane person on the planet: you can just drink from the cup.We survived the first 600 million years of multicellular life without straws, and we can last a few more.People are at each other&#x27;s throats over nothing. We could&#x27;ve been a type 2 civilization by now if we spent as much time researching energy extraction as we do talking about straws.reply johnnyanmac 8 hours agoparentfar from the first time people argued to death over what is ultimately a slight convenience.But for the sake of devil&#x27;s advocate: putting your lips directly against a piece of plastic or glass is one of the easiest ways to expose oneself to a myriad of germs and bacteria. a wrapped straws solves many problems about cups in public outings that you cant fully control. and it leaves non-disposable cups just a bit cleaner.It&#x27;s also a big factor for the elderly or disabled to prevent spills or worse. reply Gigachad 10 hours agoparentprevI always chuck the paper straw out at restaurants. I find they often have a weird effect of rapidly decarbonating the drink. Agreed that straws are just not useful for 99% of drinks. Only required for thick drinks. reply brnt 12 hours agoprevWhich brands? Cant get at the supplementary materials.I bought a set of those IKEA bamboo straws, said to be 100% natural, and indeed I don&#x27;t see why pfas would be needed on those; solid bamboo. reply teekert 12 hours agoparentBamboo also has its issues [0]. I think mainly because it is kept in shape by bad stuff. Could be that your straws are really 100% bamboo, but some products are something like ground bamboo in some polymer.[0] https:&#x2F;&#x2F;www.europarl.europa.eu&#x2F;doceo&#x2F;document&#x2F;E-9-2020-00064... reply brnt 12 hours agorootparentThe ones I have are just drilled out bamboo sticks (they vary in size and have visible bamboo structure), not reconstituted. I&#x27;ve never seen other types of bamboo straws (everything appears to be paper around here, once I had a pasta-straw), so I&#x27;m really curious. reply kragen 13 hours agoprevi think the bigger issue is probably that the paper straws are about an order of magnitude higher in mass, virtually 100% organic chemicals, and so represent about an order of magnitude higher resource consumptionthe bigger issue than that is that disposable straws, even after that order-of-magnitude increase in impact, are an absolutely insignificant issue in ecological terms and yet have somehow become a political issue and spawned new laws and ridiculous greenwashing marketing reply audunw 13 hours agoparentTo me it doesn’t seem that paper straws is about the resource consumption or oil used or anything like that. I think you have completely misunderstood the purpose.Even with the order of magnitude increase in resources used it’s still insignificant, as you touch on.What’s not insignificant is that in the contexts where straws are used.. fast food and coffee shops and such, they’re all too likely to be just thrown out into nature rather than being properly disposed of.Any material in that category needs to be biodegradable. That’s just a hard requirement in my opinion. So plastics is just not a suitable material.Yes, there are other sources of plastic pollution that are much worse in volume. Though they tend to end up in other places. We need to work on all the sources of plastic pollution in parallel.(Unless we go the other route and do massive bioengineering of microorganisms to let them break down plastics) reply kragen 13 hours agorootparentfrom my point of view, it depends on how much of it there is and what effect it has on the environmentsand, glass, metal, and rust aren&#x27;t biodegradable either, but i don&#x27;t think we should ban mountains because they throw sand out into nature when they erodeplastic straws are generally polypropylene, which is photodegradable to relatively nontoxic materials reply dddssddd 13 hours agorootparentDidn&#x27;t realize Mountains were pollution until you pointed it out. Thanks for your meaningful and on discussion contribution! reply kragen 12 hours agorootparentyou seem to have interpreted my comment as saying the opposite of what it did in fact say, presumably for humorous effect reply marcus0x62 12 hours agorootparentDude drank through too many PFAS-enhanced paper straws and now has reading comprehension problems :( reply yyyk 3 hours agorootparentprevGlass is biodegradable. Metal is so easily recycled.I&#x27;ll note though that biodegradability is not the only consideration, and there are other important advantages to plastic straws. reply chmod600 12 hours agorootparentprevPlastic straws strewn in a natural setting feels a lot worse than sand. I can&#x27;t tell you exactly why, but I still think that \"don&#x27;t throw plastic around\" is a good starting place for a discussion and I don&#x27;t think it&#x27;s productive to argue that point. reply kragen 11 hours agorootparentmaybe what feels good or bad to people in a natural setting is not actually a useful measurement of what affects the well-being of naturemaybe the actual health of the motherfucking ecosystem matters more than what looks nice on a postcardcommon sense is what tells you the world is flat, chemotherapy is bad for you, and lead paint and sassafras are good to eat reply ricardobeat 13 hours agoparentprevSources needed. This study says paper straws uses slightly less energy and emits about the same CO2 as a plastic one: https:&#x2F;&#x2F;www.appropedia.org&#x2F;HSU_straw_analysis#:~:text=A%20si....Even if that’s not the case, “resource usage” is not the right metric to optimize for, this cost-focused mentality is exactly how we ended up with plastic [literally] everywhere.Hundreds of billions of plastic straws are thrown away every year, this is a massive problem even if its only a few % of the total. reply kragen 13 hours agorootparentprobably it&#x27;s good to have plastic everywhere if it decreases environmental damagethe hsu analysis is wrong because it&#x27;s omitting the energy consumed by growing the trees; it rates \"craft paper\" as 12.6 kJ&#x2F;g, but according to https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Energy_density#In_chemical_rea... burning wood produces 18 MJ&#x2F;kg = 18 kJ&#x2F;g, which is to say, more energy than that is still available in the end product, without even taking into account the \"embodied\" energy dissipated in processingthe energy consumed by the tree in growing is about 20× larger than this, 300–400 kJ per gram of wood, which is close to 700 kJ per gram of paper, because about half the tree is lignin, which is digested in the papermaking process and then discharged into waterwaysit does give a reasonably plausible (if misleadingly precise) figure of 95.4 kJ&#x2F;g for the polypropylene strawsalso, it incorrectly compares 200-mg polypropylene straws against 200-mg paper straws. but paper straws are, as everyone knows, enormously thicker than polypropylene straws of the same level of durability; even with the accounting error of omitting the embodied energy of the paper, its conclusion presupposes the opposite of my premise above, which you should have mentioned in your comment (but presumably could not because you had not actually read the study you were citing)in fact, a typical 6-mm-diameter paper straw made from 330 gsm paper at a length of 200 mm weighs some 1250 mg, roughly 6× as much as the hsu study&#x27;s 200-mg estimate. a 200-mg paper straw would be 53 gsm; that&#x27;s like tracing paper. it would collapse immediately if you tried to suck on itfinally, it is not correct that hundreds of billions of plastic straws are thrown away per year, and those that end up in landfills (which is the vast majority) are not a problem at all. nor are they a few % of the total, as you say, but 100× less than that; https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Drinking_straw#Environmental_i... says, &#x27;In total, they are less than 0.022% of plastic waste emitted to oceans.&#x27; reply ricardobeat 13 hours agorootparentI’m not surprised you replied in less time than it takes to read the first paragraph. The study is about embedded energy, so yes one assumes it does account for energy used growing trees (remember the solar energy they use is free), unless you have evidence to the contrary?I can’t even start understanding that logic. The whole reason we’re having this discussion is that we know the environment, especially marine life, is being ravaged by plastic waste. reply kragen 13 hours agorootparenti have added my calculations to the contrary to the comment above, perhaps after you wrote your comment, so you can see that i had somehow come to the correct conclusions before reading the first paragraphconsider the possibility that this is because i have previous knowledge of the area instead of just pasting the first link google throws at me, so my opinions are based on domain knowledge instead of the kind of common sense that tells you the world is flatif solar energy is free then why do we care about embodied energywe do not know that the environment, especially marine life, is being &#x27;ravaged&#x27; by plastic waste. it is being ravaged by clear-cutting (including for papermaking), by industrial waste effluents (including from papermaking), by agricultural waste effluents, by global warming, by ocean acidification, by habitat destruction from farming (including tree farming), by overfishing, by desertification, and by dumping of toxic wastethere is clearly a problem with plastic waste due to poor waste disposal practices in a few countries (mostly indonesia and the philippines) but in the overall scheme of environmental devastation, it is comparatively small, and plastic straws are an utterly insignificant part of that comparatively small problem replymoron4hire 14 hours agoprevWhy does every drink need a straw, anyway? reply reaperducer 13 hours agoparentWhy does every drink need a straw, anyway?For my wife, because it ruins her lipstick less than a lid with a hole in it.I&#x27;ve heard some people say they do it because they think it reduces the effect of the soda&#x2F;coffee&#x2F;whatever staining their teeth.I think it just increases consumption because you don&#x27;t feel it filling your mouth as much as when you drink from the rim of a cup. reply bemusedthrow75 13 hours agorootparentDrinking the kind of \"coffee\" that needs a straw already makes one a soulless monster, though ;-)The ethics of straws just won&#x27;t move the needle.I mean this only mostly in jest. Iced coffee drinks really are to me a particular indicator of overconsumption. reply asciimov 13 hours agoparentprevSanitation, plenty of people handle the outsides of cups after they are washed before you drink from it.If you have a compromised immune system, straws are important part of staying healthy. reply primordialsoup 13 hours agorootparentI have heard this argument from perfectly healthy people, and I couldn&#x27;t really believe it, since there are just so many other touch points when you go to a restaurant.If someone is immuno compromised I think this makes sense to extent. reply VancouverMan 13 hours agoparentprevMany of the drinks that would come with such straws are consumed in moving vehicles.In such an environment, sipping from a straw tends to work significantly better than drinking from the rim of a tilted, open-topped cup.While smaller drinks might use a lid with a small gap in it, that just isn&#x27;t a practical option for larger drinks. reply ryandrake 13 hours agorootparentFor passengers, maybe, but people really should not be eating and drinking while driving vehicles. Distracted driving kills. Stuffing your face can wait until you pull over or get home. reply throwaway290 13 hours agorootparentprevLocal shop near me sells very large drinks with very secure thick lids with two holes (bigger pluggable hole to drink from and super tiny to let the air in). Sadly it&#x27;s all plastic too of course.(edited to remove claim that straw is no better than secure lid with a small hole, it could be a little better) reply derekp7 13 hours agoparentprevBiggest reason for me is ice. It is very difficult to drink a soda with crushed ice keeping the ice out of your mouth without a straw. reply throwaway290 13 hours agoparentprevSome drinks are designed for straw (iced, layered, smoothies) and some people want to have more control during intake (maybe they think packaging is dirty or fear for makeup). Then it becomes a mindless habit reply wahnfrieden 14 hours agoparentprevConsumers demand it, and we chose a society that mostly freely provides goods for consumer demands. So is your issue with the free market, or is it toothless consumer elitism(I don&#x27;t mean this reply to be a defense of the market either. I&#x27;m asking you to evaluate what is core to your criticism) reply timeon 13 hours agorootparent> Consumers demand it, and we chose a society that mostly freely provides goods for consumer demands.Except for Ad industry and marketing. reply akira2501 13 hours agorootparentThe presumption that all advertising is merely crass mass manipulation in order to force consumers to do things they otherwise wouldn&#x27;t want to do is, I fear, continued elitism.And in the context of this discussion, you might be asked to prove that straws are used purely because of the manipulations of marketers. reply kwhitefoot 13 hours agorootparentSo why do advertisers do it? reply akira2501 12 hours agorootparentThere are tons of reasons. New location just opened. New product is available. Improvement to old product was released. Inventory clearance sale is about to happen. Seasonal businesses that are just entering the season. New consumers who might not be familiar with the products available to them.I work in a business that serves a lot of local advertisers. We do take national and agency client business, but the majority of our work is with local businesses. They do it because it works. People hear the ad and foot and digital traffic to their locations increases.Advertising is just a market. \"Advertisers\" are just people with a business who want to reach consumers. I&#x27;d be far more comfortable with the case that, as a market, it should be policed by some administrative agency, and like most administrative agencies over the past few decades they&#x27;re likely asleep at the switch and so the market shows obvious signs of abuse.This is why I, and the other poster, take some umbrage to what seems to be a very simplistic elitist take from you. This is a market. It has benefits, and it has the potential for abuse. Rather than looking at this as a social problem that simply needs basic agency actions to be solved to defend those benefits, the rather radical idealism of destroying the market entirely gets bandied about a little too comfortably. reply wahnfrieden 13 hours agorootparentprevOnly because they are outbid. Individual consumers won&#x27;t pay as much as advertisers will to keep ad space empty. reply sixstringtheory 12 hours agorootparentprevI concur with your first statement to the extent that people ab initio demand straws and aren’t mostly just failing to examine why everything already comes with one, but your question presents a false dichotomy.My problem is with poor education and critical thinking skills, and the anti-intellectualism on display whenever you see full-grown humans stamping with their fingers in their ears because “I just want what I want!” reply bsuvc 13 hours agoprevI&#x27;m sure someone probably feels strongly about this, but I will ask anyway:Do we as a society even need straws?I never use a straw at home.The only time I would consider wanting one would be for a milkshake maybe, due to its thickness making it hard to sip otherwise.I am not anti-straw, just think it is sort of a weird thing for our society to use when I stop to think about it. reply paulproteus 13 hours agoparentWhen people wear lipstick and are drinking something, a straw helps keep it on. If society&#x27;s going to have lipstick and people go out, I think society sorta has to have straws! See e.g. https:&#x2F;&#x2F;stylecaster.com&#x2F;beauty&#x2F;makeup&#x2F;468366&#x2F;how-to-make-lip... reply aziaziazi 13 hours agorootparentI can’t help asking weather do we as a society need lipstick ? reply marvin 13 hours agorootparentWell, you could mandate that women aren&#x27;t allowed to use particular types of beauty products to compete for more desirable partners, and hope that the follow-on effects of that lead to lower straw usage. But then you&#x27;re totalitarian and convoluted. reply woodruffw 13 hours agorootparentprevWe have a lot of things that we don’t need. Abundance and option (rather than bare sustenance) are defining features and goals of a healthy society.That’s a long way of saying that there are a lot of things we don’t need, but that eliminating them makes relatively little sense. We should instead develop compensating systems based on those needs (such as disincentivizing single-use straws, and normalizing reusable ones in the ways that reusable bottles and bags have been normalized.) reply dvdhnt 13 hours agorootparent> Abundance and option (rather than bare sustenance) are defining features and goals of a healthy society…Do you have a source for this claim? It’s not something I’ve read or heard in 36 years. reply woodruffw 12 hours agorootparentI think that falls under conventional wisdom. reply tuhriel 13 hours agorootparentprevI see that there might be some cases where a straw can be helpful or necessary. But there are handed out so many straws wh ich aren&#x27;t needed. I never understood why they put a straw into my whiskey cola or cuba libre. We should get there where we just hand out straws if people ask for them as it is with other extras. reply bsuvc 13 hours agorootparentprevAh makes sense. I didn&#x27;t think about that scenario. reply LeoPanthera 13 hours agoparentprevWhen drinking particularly acid drinks, juice, soda, etc., a straw significantly reduces the amount of erosion of your teeth. reply sixstringtheory 13 hours agorootparentI question if it actually does make a difference, and in any case, we should kill two birds with one stone and just not drink unhealthy drinks.“It’s so simple!” -Jim Gaffigan“Stop it!” -Bob Newhart reply irrational 13 hours agorootparentLet’s just outlaw everything but tap water. reply sixstringtheory 13 hours agorootparentYou don’t have to outlaw anything. Disincentivize it.“But then only the rich will get to rot their teeth out!” Good, I guess? So what?“Poor people will still spend money on sugar water! You’ll drive them deeper into poverty!” Then the price isn’t high enough yet. It needs to exceed the cost of the dental and medical work it will precipitate. Which by definition will price many poor people out of sugar water. Which it should. reply Havoc 13 hours agorootparentprevAny link&#x2F;source? Not that I don’t believe you just curious as it seems plausible but never chances across support for it reply LeoPanthera 12 hours agorootparenthttps:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;9785633&#x2F; reply SoKamil 13 hours agorootparentprevDo we as a society even need acid drinks? reply LeoPanthera 13 hours agorootparentDo we as a society even need [alcohol|nicotine|cannabis|refined sugar|fat|salt]?Maybe not. But I refuse to believe that you asked that question in good faith, because we&#x27;re obviously going to have all of them. People should be free to live as healthily or as unhealthily as they choose. reply sixstringtheory 13 hours agorootparentPeople should be free to live as unhealthily as they choose as long as the problems they inevitably create don’t negatively affect other people.Activities high in negative externalities should be prohibitively expensive to help pay for remediation, and the opposite should be positively reinforced, even subsidized. A stitch, in time, saves nine. reply Turing_Machine 12 hours agorootparentI&#x27;m pretty sure more people have been killed by governments with too much power than have ever been killed by drinking straws. reply rayiner 12 hours agorootparentprev> But I refuse to believe that you asked that question in good faith, because we&#x27;re obviously going to have all of them. People should be free to live as healthily or as unhealthily as they choose.Why? Especially in a country with government-subsidized healthcare? reply Jweb_Guru 13 hours agorootparentprevWe don&#x27;t need a lot of things. A better example than plastic straws is beef: we definitely don&#x27;t need beef, it&#x27;s already expensive, and it has an extremely large and disproportionately heavy impact on CO2 consumption due to the combination of required grain, methane release, and needing land for cows incentivizing cutting down rainforest. Most people here would be pretty up in arms about any proposal to ban beef, so why focus on comparatively harmless stuff like lipstick and soda? reply ricardobeat 13 hours agorootparentprevIf you’re going down that path, all we need is water. Human needs go beyond the physical. reply newaccount74 13 hours agoparentprevDo we need disposable straws?Some people need straws (kids, disabled people), but in most cases it&#x27;s better to bring your own reusable straw to fill that need rather than relying on whatever straws they have at the place you are going to.My toddler for example will just chew up most types of straws (especially those disgusting paper straws). Bringing a stainless steel, a glass straw, or one of those cups with integrated straw is a much better alternative.People with movement disorders will probably want something more flexible, so I guess a reusable silicone straw is probably best.I don&#x27;t think we need disposable straws. reply kwhitefoot 13 hours agorootparentKids do not need straws. reply newaccount74 12 hours agorootparentProbably not. But they like them. reply hinkley 13 hours agoparentprevIn theory it can reduce tooth decay. In practice it only does so when drinking high sugar, high acid beverages, and if memory serves drinking a glass of water afterward is about as effective. reply kragen 13 hours agoparentprevmostly they&#x27;re important for people who are disabled with neurological issues or immune deficiency reply irrational 13 hours agoparentprevThe only time I find it useful is when I’m driving while drinking a side I got at the fast food place I stopped at. It’s pretty easy to drive while drinking out of a straw. reply tuhriel 13 hours agorootparentThose cups in themselves are a pain. Why cant they just hand out PET bottles like you get everywhere else? (at least in europe) hand out a reusable sport cap aswell and you have a perfect bottle without the need of a) a straw b) a cup c) a lid reply xp84 12 hours agorootparentA bottle uses way more plastic than our flimsy plastic lids do. Paper cups are mostly paper which comes from trees which are grown just because there’s a need for paper (big carbon win).It would be a massive step backward to use bottles instead of fountain drinks. Not to mention how much more expensive they are than a fountain drink. And there’s no way you could fill them efficiently from a fountain at the restaurant. reply konschubert 13 hours agoparentprevI think they&#x27;re fun, and kind of useful if drinking while the move. reply newsclues 13 hours agoparentprevControl flow liquid and avoid spills with moving the glass.Very useful for children, old people and those with special needs.But also useful for things like sensitive teeth, avoiding consuming heavy solids in a drink, or to spit balls of tissue at teachers.Good for on the go consumption as they can move, and you can avoid hitting your mouth with a cup. reply Shikadi 9 hours agoparentprevThe Starbucks lids are awesome, we should use them everywhere reply Swizec 13 hours agoparentprevI need straws to deal with American ice servings. Almost impossible to drink without a straw.Of course you don’t need straws at home unless you have special needs, because your glass is full of drink not ice with a splash of drink. reply guerrilla 13 hours agoparentprevYes, many disabled people need straws. Specifically soft ones, if they have movement disorders. reply bsuvc 13 hours agorootparentGreat point.Now that you mention it, I did work with a person who had a condition that extremely affected his ability to move and yes, straw usage was essential for him. reply bilsbie 13 hours agoparentprevThey’re important when drinks have lids. reply jayd16 13 hours agorootparentAre they? Lids can have spouts. reply irrational 13 hours agorootparentWhile driving, trying to drink from a spout puts more of the cup into your field of vision. It’s not as safe as a straw.The retort, of course, will be to not drink while driving. Sigh. reply spike021 13 hours agorootparentprevMost of the current lids on fast food togo cups these days don&#x27;t work with my lip shape. It sounds funny but drinking from them especially while driving does not work, the drink just leaks out the corners of my mouth. reply fortran77 13 hours agoparentprevYou&#x27;d feel differently if you had no arms. reply bsuvc 13 hours agorootparentYes. Yes I would.It is clear there are some use cases where straw usage is a necessity.I do wonder if that should just be something people use when they need it.The analogy would be, some people use mobility scooters at the grocery store, but not everyone uses one, only the people who choose to them (presumably because they need it, but the point stands either way, need or want) reply wouldbecouldbe 13 hours agoparentprevGet some kids. reply bsuvc 13 hours agorootparentGot one and sippy cup was the thing to use, but yeah straws were also helpful for a while after graduating from the sippy cup. reply wouldbecouldbe 13 hours agorootparentanywhere you go, friends, bars, they will get their drinks with straws. You can take it away, but it&#x27;s not set up for it. reply psychphysic 13 hours agoprevAll this stuff sold to us as eco alternatives are horrendous.They are harmful imo as they detract from the ideal and usually attainable solution of reducing consumption. reply ben_w 13 hours agoparentSome of it is, but not all.> usually attainable solution of reducing consumption.Hell no.I&#x27;m a real life example of this \"unicorn\" — someone so utterly uninterested in acquiring material things that I spent an average of €1131 per month on everything combined in the last six months. Rent, travel, food, new laptop… and I&#x27;m not even trying to be frugal, this is with a lot of eating out and organic groceries.If everyone did what I did, not only would we still have wasteful straws (why were they in my mango lassis?), but also the economy would collapse immediately.If everyone cuts back as far as I can when I last tried seriously, the economy breaks much harder. reply Closi 13 hours agorootparentEdit: Misread and assumed 1100 euros &#x2F; 6 months. Have removed comment reply ben_w 13 hours agorootparentI think you may have misread something; €1131 per month, of which €468 is rent and utilities (in Berlin, so still a good rate).€7.6 euros per week for food is doable, I think, but last time I really tried to optimise that I was at university, in the UK, and it was 2003. (£0.50&#x2F;day: Lidl instant noodles that they don&#x27;t even sell any more, Quaker oats packs that aren&#x27;t sold here, skimmed milk, dried fruit in the oats; I don&#x27;t recommend reproducing this, it was a game to see how little I could spend without going hungry). reply Closi 13 hours agorootparentApologies I did misread - removed original comment. reply ben_w 13 hours agorootparentIt happens to all of us, no worries :) replyjbb67 13 hours agoprevwhen I see the words \"forever chemicals\" in some writing I assume the use of emotive language is simply there to try to manipulate me and so whatever the opposite of what the article says is likely the truth reply Aachen 12 hours agoprevBut so does our drinking water afaik. The real news is that> PFAS are sometimes used as a water-resistant coating [on \"paper\" straws]Surprised Pikachu that paper isn&#x27;t water resistent (though then why do they melt in your mouth? Are those straws the pure paper variant?). What we need is for people to be able to reuse the things. Return the reusable straw to any McDonald&#x27;s worldwide for dishwashing and reuse, for example, if we can&#x27;t get people to bring it from home (the latter is my solution atm). Single use paper straws isn&#x27;t more greenhouse gas efficient than single use thin plastic straws anyway, that was never going to be the answer even if it alleviates a decimal of a fraction of plastic trash issues reply shyn3 12 hours agoparentThe corporate world has decided paper straws are better. reply iancmceachern 14 hours agoprevI think those pasta straws are the answer, assuming we cook and eat them after. reply WildGreenLeave 14 hours agoparentEven if we don&#x27;t I assume they would be healthier and better biodegradable right? reply newaccount74 13 hours agorootparentThere&#x27;s a small risk that raw pasta might be contaminated with E. Coli or Salmonella, but I assume that this risk is miniscule compared to the health risks of frequently consuming sugary drinks (with or without straws). reply someguy7250 13 hours agoprevAll I can say is.. Garbage collection, and memory management (\"recycling\"), are hard, lol. reply 01100011 14 hours agoprevFrom the paper(https:&#x2F;&#x2F;www.tandfonline.com&#x2F;doi&#x2F;full&#x2F;10.1080&#x2F;19440049.2023.2...):> PFAS were detected in almost all paper-based straws, with highly variable concentrations between brands, ranging fromsold drinks-> return bottle -> sanitize bottle -> repeat\". Low waste, no plastic crap, and REUSE (of the 4 R&#x27;s). But nope, it&#x27;s cheaper to consume new material and throw it \"away\" AKA: our children or their children to deal with. Its not like they can vote to stop us. reply c22 12 hours agoparentprevAn aluminum straw with the wall thickness of an aluminum can would be pretty flimsy (try cutting the top and bottom off a can). reply hinkley 13 hours agoprevThe only ones of these I actually want to entertain are the straws made of actual straw.And those are not fit for blended drinks. reply znite 13 hours agoprevJust stop using straws, simple reply Tokkemon 12 hours agoprevPaper straws are terrible. reply yieldcrv 14 hours agoprevAs long as it comes with a single use plastic cup reply gcau 13 hours agoprevWhat utensils&#x2F;containers should I be using to avoid all forever chemicals and microplastics? reply xwdv 13 hours agoparentGlass. Metal. reply ianai 13 hours agorootparentCeramic, as a glass, is valid too. Pottery I’m thinking as well but maybe with some caveats such as non-leaded paint.Edit-I wish store items could be bought in reusable containers made from such materials. It would make groceries heavy and the cost of the containers might need to be “leased” some way (like old milk jugs were perhaps). But I’d do it. reply shmde 13 hours agorootparentprevAdd ceramic&#x2F;clay. reply scotty79 14 hours agoprevDid anybody check paper cups? reply wahnfrieden 14 hours agoparentHot liquid paper cups are lined with PFAS and also can&#x27;t be recycled reply sirmike_ 13 hours agoprevAny place which serves paper straws (in my area) gets an automatic no-go. Not interested in a business virtue signaling to superficial ecology preservation. It is akin to anti-gunners betting all in on stopping made up categories of firearms (assault weapons) which make up a tiny portion of murders. Whereas if they were serious they would focus on restrictions of hand-guns. The two stats of crime committed with both are NOT the same levels. reply wahnfrieden 14 hours agoprev [–] Consumer solutions for saving the planet result in greenwashing (distraction from actual meaningful change), new poisons, and growing waste through growing demand. Ecology isn&#x27;t simply making correct purchasing decisions even if they feel good. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study from the University of Antwerp reveals that 90% of eco-friendly paper straws contain harmful \"forever chemicals\" called PFAS.",
      "PFAS have been linked to various health issues such as high cholesterol, reduced immune response, thyroid disease, and increased cancer risk.",
      "The study found PFAS in 69% of the 39 tested straw brands, with paper straws having the highest presence of these chemicals. The water-resistant coating on paper straws likely contributes to the use of PFAS.",
      "This challenges the assumption that paper straws are automatically healthier and more sustainable than plastic alternatives, calling for further research to determine if PFAS leach out of paper straws during typical use."
    ],
    "commentSummary": [
      "The debate focuses on the environmental impact of straws and alternatives like stainless steel or reusable plastic straws.",
      "Concerns are raised about the presence of harmful chemicals in eco-friendly paper straws and the challenges of recycling them due to their water-resistant coating.",
      "The discussion also highlights the broader issues of plastic pollution, the energy consumption of different straw types, and the need for comprehensive solutions to address this problem."
    ],
    "points": 257,
    "commentCount": 144,
    "retryCount": 0,
    "time": 1693076613
  },
  {
    "id": 37272611,
    "title": "Fish – A friendly interactive shell",
    "originLink": "https://github.com/fish-shell/fish-shell",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up fish-shell / fish-shell Public Notifications Fork 1.7k Star 22.1k Code Issues 447 Pull requests 12 Discussions Actions Projects 1 Wiki Security 1 Insights fish-shell/fish-shell master 31 branches 75 tags Go to file Code Latest commit yuntaz0 Improve completion for rpm-ostree (#9910) … 9d0d166 Git stats 17,558 commits Files Type Name Latest commit message Commit time .builds fish.spec/.builds: drop SHOW_INTERACTIVE_LOG .github Make CI use the workspace, so we format/check all benchmarks Add more benchmarks build_tools style.fish: Add rustfmt support cmake Use the workspace from CMake debian fish.spec/Debian packaging: update licensing details doc_internal Add note to rust devel about the wchar builtin doc_src fish_key_reader: Humanize key descriptions docker Add Dockerfiles for ARM64 and ARMv7 etc Update /etc/config.fish to use current syntax fish-rust Also allow command and in a pipeline osx Add the get-task-allow entitlement po fixed a few smaller things in my translations share Improve completion for rpm-ostree (#9910) src parse_execution: Remove dead tcgetattr code tests fish_key_reader: Humanize key descriptions .cirrus.yml Update Cirrus CI FreeBSD runner to 13.2-RELEASE .clang-format Ensure that clang-format places config.h first in header list .clang-tidy .clang_tidy: turn off cert-dcl21-cpp, add some others. .editorconfig In .editorconfig replace max_line_length: none with off. .gitattributes .gitattributes: rig the count .gitignore gitignore: add clangd .cache directory .oclint Tell oclint to ignore another idiom that is safe BSDmakefile Preserve CMake options when make is invoked CHANGELOG.rst CHANGELOG: Document incompatible changes CMakeLists.txt Complete the transition of the kill ring and remove kill.cpp CODE_OF_CONDUCT.md Add code of conduct CONTRIBUTING.rst CONTRIBUTING: Improve translation section COPYING Licensing: note MIT licensing status of Dracula theme Cargo.lock Use a cargo workspace Cargo.toml Move edition and MSRV to workspace Dockerfile Update Dockerfile for cmake3 GNUmakefile GNUMakefile: remove redundant CMake arguments README.rst README: remove Xcode, minor linting config_cmake.h.in drop unused functions and configure checks fish.desktop Update fish.desktop (#8584) fish.pc.in Use pkg-config variables fish.png fish.png: use the same thing we ship with the docs fish.spec.in fish.spec/Debian packaging: update licensing details README.rst fish - the friendly interactive shell fish is a smart and user-friendly command line shell for macOS, Linux, and the rest of the family. fish includes features like syntax highlighting, autosuggest-as-you-type, and fancy tab completions that just work, with no configuration required. For downloads, screenshots and more, go to https://fishshell.com/. Quick Start fish generally works like other shells, like bash or zsh. A few important differences can be found at https://fishshell.com/docs/current/tutorial.html by searching for the magic phrase “unlike other shells”. Detailed user documentation is available by running help within fish, and also at https://fishshell.com/docs/current/index.html Getting fish macOS fish can be installed: using Homebrew: brew install fish using MacPorts: sudo port install fish using the installer from fishshell.com as a standalone app from fishshell.com Note: The minimum supported macOS version is 10.10 \"Yosemite\". Packages for Linux Packages for Debian, Fedora, openSUSE, and Red Hat Enterprise Linux/CentOS are available from the openSUSE Build Service. Packages for Ubuntu are available from the fish PPA, and can be installed using the following commands: sudo apt-add-repository ppa:fish-shell/release-3 sudo apt update sudo apt install fish Instructions for other distributions may be found at fishshell.com. Windows On Windows 10, fish can be installed under the WSL Windows Subsystem for Linux with the instructions for the appropriate distribution listed above under “Packages for Linux”, or from source with the instructions below. Fish can also be installed on all versions of Windows using Cygwin (from the Shells category). Building from source If packages are not available for your platform, GPG-signed tarballs are available from fishshell.com and fish-shell on GitHub. See the Building section for instructions. Running fish Once installed, run fish from your current shell to try fish out! Dependencies Running fish requires: curses or ncurses (preinstalled on most *nix systems) some common *nix system utilities (currently mktemp), in addition to the basic POSIX utilities (cat, cut, dirname, ls, mkdir, mkfifo, rm, sort, tee, tr, uname and sed at least, but the full coreutils plus find and awk is preferred) The gettext library, if compiled with translation support The following optional features also have specific requirements: builtin commands that have the --help option or print usage messages require nroff or mandoc for display automated completion generation from manual pages requires Python 3.5+ the fish_config web configuration tool requires Python 3.5+ and a web browser system clipboard integration (with the default Ctrl-V and Ctrl-X bindings) require either the xsel, xclip, wl-copy/wl-paste or pbcopy/pbpaste utilities full completions for yarn and npm require the all-the-package-names NPM module colorls is used, if installed, to add color when running ls on platforms that do not have color support (such as OpenBSD) Switching to fish If you wish to use fish as your default shell, use the following command: chsh -s /usr/local/bin/fish chsh will prompt you for your password and change your default shell. (Substitute /usr/local/bin/fish with whatever path fish was installed to, if it differs.) Log out, then log in again for the changes to take effect. Use the following command if fish isn’t already added to /etc/shells to permit fish to be your login shell: echo /usr/local/bin/fishsudo tee -a /etc/shells To switch your default shell back, you can run chsh -s /bin/bash (substituting /bin/bash with /bin/tcsh or /bin/zsh as appropriate). Building Dependencies Compiling fish from a tarball requires: a C++11 compiler (g++ 4.8 or later, or clang 3.3 or later) CMake (version 3.5 or later) a curses implementation such as ncurses (headers and libraries) PCRE2 (headers and libraries) - optional, this will be downloaded if missing gettext (headers and libraries) - optional, for translation support Sphinx is also optionally required to build the documentation from a cloned git repository. Additionally, running the test suite requires Python 3.5+ and the pexpect package. Dependencies, git master Building from git master currently requires, in addition to the dependencies for a tarball: Rust (version 1.67 or later) libclang, even if you are compiling with GCC an Internet connection fish is in the process of being ported to Rust, replacing all C++ code, and as such these dependencies are a bit awkward and in flux. In general, we would currently not recommend running from git master if you just want to use fish. Given the nature of the port, what is currently there is mostly a slower and buggier version of the last C++-based release. Building from source (all platforms) - Makefile generator To install into /usr/local, run: mkdir build; cd build cmake .. make sudo make install The install directory can be changed using the -DCMAKE_INSTALL_PREFIX parameter for cmake. Build options In addition to the normal CMake build options (like CMAKE_INSTALL_PREFIX), fish has some other options available to customize it. BUILD_DOCS=ON|OFF - whether to build the documentation. This is automatically set to OFF when Sphinx isn't installed. INSTALL_DOCS=ON|OFF - whether to install the docs. This is automatically set to on when BUILD_DOCS is or prebuilt documentation is available (like when building in-tree from a tarball). FISH_USE_SYSTEM_PCRE2=ON|OFF - whether to use an installed pcre2. This is normally autodetected. MAC_CODESIGN_ID=String|OFF - the codesign ID to use on Mac, or \"OFF\" to disable codesigning. WITH_GETTEXT=ON|OFF - whether to build with gettext support for translations. Note that fish does not support static linking and will attempt to error out if it detects it. Help, it didn’t build! If fish reports that it could not find curses, try installing a curses development package and build again. On Debian or Ubuntu you want: sudo apt install build-essential cmake ncurses-dev libncurses5-dev libpcre2-dev gettext On RedHat, CentOS, or Amazon EC2: sudo yum install ncurses-devel Contributing Changes to the Code See the Guide for Developers. Contact Us Questions, comments, rants and raves can be posted to the official fish mailing list at https://lists.sourceforge.net/lists/listinfo/fish-users or join us on our gitter.im channel. Or use the fish tag on Unix & Linux Stackexchange. There is also a fish tag on Stackoverflow, but it is typically a poor fit. Found a bug? Have an awesome idea? Please open an issue. About The user-friendly command line shell. fishshell.com Topics shell fish terminal Resources Readme License View license Code of conduct Code of conduct Activity Stars 22.1k stars Watchers 283 watching Forks 1.7k forks Report repository Releases 39 fish 3.6.1 (released March 25, 2023) Latest + 38 releases Used by 5 Contributors 805 + 794 contributors Languages C++ 42.8% Rust 31.8% Shell 17.4% Python 5.1% CMake 1.2% JavaScript 0.6% Other 1.1% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37272611",
    "commentBody": "Fish – A friendly interactive shellHacker NewspastloginFish – A friendly interactive shell (github.com/fish-shell) 233 points by keepamovin 20 hours ago| hidepastfavorite154 comments mattgreenrocks 17 hours agoBest part of fish is how little config is needed. I’m 41, married with kids. Old AF by some standards. I have zero patience with wasting my time configuring tooling.zsh felt like it fought me every step of trying to configure it to be halfway decent. And a lot of zsh scripts out there aren’t exactly bulletproof. It shouldn’t matter, except for the fact that if you use the shell with any regularity you will inevitably bump into edge cases that weren’t handled well by a mishmash of user scripts whose provenance is mostly copy&#x2F;paste with little understanding of why it is all needed.Here’s my fish dotfiles:https:&#x2F;&#x2F;github.com&#x2F;mattgreen&#x2F;dotfiles&#x2F;tree&#x2F;master&#x2F;fishIt has a submodule based plugin system (loader in conf.d), an async git prompt, my aliases, and a few env vars set. It needs no maintenance because fish provides almost everything already.The only thing I want from fish at this point is to make async prompts first-class. They are best handled by the shell, not user code, due to the state tracking. reply joseph 16 hours agoparentI use bash and also have no patience for configuring tooling. Your fish dotfiles are more complicated than my bash ones. I used to work on a team where many of the other engineers used fish. I never saw it doing anything I couldn&#x27;t do in bash, although it looked a little fancier. But the annoying thing was when they asked me for help, and none of the commands I gave them worked in fish. It made for very slow troubleshooting sessions. reply mcjiggerlog 16 hours agorootparentFish has so many more features out of the box than bash. Once you use fish for a while it&#x27;s really quite painful to go back to basic bash. reply em-bee 10 hours agorootparentprevi am using fish for more than a decade and i don&#x27;t have any dotfiles for it. (do i win? :-p )your commands to help not working in fish? that is rather surprising. i would think that fish users should be aware that shell specific things in fish are different, so they should have been able to cope and translate as needed.and it&#x27;s not what you can do in fish that makes it special. it&#x27;s how you do it. the syntax coloring, the completions, the syntax itself...the key thing for me is how it handles searching history and autosuggestions. i just learned how to somehow recreate this setup in zsh, and i am very curious if bash can do that too: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37274207btw i believe bash got a lot better at command completion after fish popularized the idea. reply lost_tourist 7 hours agorootparentAtuin or fzf is well worth adding to fish. I only add one of those (atuin these days) and a few custom scripts to make my life a bit easier. reply mid-kid 16 hours agoparentprevI went through the initial config wizard of zsh exactly once, almost a decade ago[1]. It took me maybe 5-10 minutes, and even though I don&#x27;t fully understand what each command means, I haven&#x27;t modified it in all this time, and it works well. I really don&#x27;t think this was any significant waste of time or tedious task - I was just as free to simply ignore it.Most of the remainder of my zsh config are prompt utilities and other things I&#x27;ve added over the years. I don&#x27;t use or really need any plugins, though if I needed, last time I tried zplug it was really easy to set up and use.[1]: https:&#x2F;&#x2F;github.com&#x2F;mid-kid&#x2F;config&#x2F;blob&#x2F;master&#x2F;shell&#x2F;.zshrc#L... reply ansdomizzz662 17 hours agoparentprevAgree with everything you said. If I didn&#x27;t have to write &#x2F;bin&#x2F;sh compatible scripts for work, I would switch to Fish for similar reasons. From a UX point of view it&#x27;s indisputably ahead of every other shell and it isn&#x27;t even close, to the point I&#x27;m surprised it hasn&#x27;t been adopted as the default by an OS like Mac yet. I can walk my family members through terminal things with Fish and nobody gets frustrated or quits. I can&#x27;t say that about other shells. reply paradox460 16 hours agorootparentYou can just put a bash shebang at the top of the script and use it just fine under fish reply lolinder 16 hours agoparentprev> zsh felt like it fought me every step of trying to configure it to be halfway decent.oh-my-zsh is a lifesaver here. I have a very small dotfile that delegates most of the config to omz, which I have in a bare repo that I clone onto each new machine. It took maybe an hour a few years ago to settle on the plugins I wanted and put the repo together, and each new machine now takes 5-10 minutes to get up and running. reply mattgreenrocks 16 hours agorootparentOMZ is what drove me away from zsh. Fired up a prompt while working one day and it was asking if it could check for plugin updates.Really feels like OMZ doesn’t know its place when it is configured by default to do that. Tools should be quiet and keep to themselves. reply lost_tourist 7 hours agorootparentthat&#x27;s really easy to turn off if you&#x27;re happy with your setup. reply xwowsersx 16 hours agoparentprevIf I already have zsh set up to my liking, what improvements&#x2F;changes, if any, would I experience if I switched to fish? reply hiepph 1 hour agorootparentI would say it has a \"better\" scripting languages syntax.For example, compare this in zsh:``` case $input in \"foo\") echo \"Input is foo\" ;; \"bar\") echo \"Input is bar\" ;; ) echo \"Input does not match any case\" ;; esac ```with this in Fish shell:``` switch $input case \"foo\" echo \"Input is foo\" case \"bar\" echo \"Input is bar\" case \"\" echo \"Input does not match any case\" end ```And it was a really small example. Fish can do much more with \"simpler\" and not arcane syntax.Fish also has `string` to work with string much much easier [0].You miss `oh-my-zsh`? Fish has `oh-my-zsh` [1].You miss integration with `fzf`? Fish also has it.One caveat is Fish is not POSIX-compatible. But I don&#x27;t find it a compelling reason to not using it.Personally, I use Fish as my main shell. I do use zsh&#x2F;Bash in my company though since they&#x27;re more ubiquitous.[0] https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;cmds&#x2F;string.html[1] https:&#x2F;&#x2F;github.com&#x2F;oh-my-fish&#x2F;oh-my-fish reply nonethewiser 16 hours agoparentprevYour fish dotfioes are a lot more extensive than my extremely small .zshrc file. What have you configured it to do? reply keepamovin 22 minutes agoprevI like fish. It&#x27;s good to have on my machine. I can see myself using sometimes. I&#x27;m used to bash. Bash for scripting definitely. I&#x27;m not sure what makes me look more like a \"hacker\" using bash, or using fish?I don&#x27;t really care, but...ha! Just wondering.I guess fish is like, you feel like you&#x27;re living in the future, but also like \"this is a past that should have already been available\" then you find out it has been available, for 18 years, and you wonder, \"Was it me that was living in the past?\"It&#x27;s the kind of thing I&#x27;m scared to get burnt on, when it fails, because I already like it. I don&#x27;t want it to disappoint me, because I just feel like: \"new fangled, it&#x27;s always gonna break.\" But then, it has been around for 18 years...so...hmm.So, I don&#x27;t know. It looks pretty! I like to use it. But bash is, feels, more stable.Worth exploring! I&#x27;m not gonna config-it, as much as possible, but for interactive shell? I think it&#x27;s good! :) reply pxc 19 hours agoprevI&#x27;ve been using Fish as my login shell for more than a decade now. Unlike many other commenters here, I also use it for scripting. For simple stuff, it&#x27;s way nicer for writing scripts because the language just has has fewer gotchas than bash.If you&#x27;re just reading instructions online, translating between examples given in bash and fish is trivial. I see people talk about that being an issue for them and I don&#x27;t understand it; it&#x27;s literally never given me trouble. reply karl42 17 hours agoparentThe one thing that keeps me from using it more often for scripting is the lack of a fail-on-error mode (similar to `set -e` on bash). I know it is hard to get this to behave well in all cases (e.g. pipefail) but I don&#x27;t want to do much scripting without it. reply pxc 17 hours agorootparentThe other ones that annoy me are shell redirection from fish functions and some job control issues, which I&#x27;m hoping will both be fixed when job control is rearchitected as part of the ongoing Rust port.I still use bash in CI, and for Linux scripts that I distribute to others. For macOS automation, I use zsh since it&#x27;s the default nowadays.My fish scripting is mostly for personal use and occasionally little wrappers on servers that I own. Sometimes I&#x27;ll share a bit of fish code with other fish users at work, too.Fail-on-error would be nice and help make the case for using fish in more places. At organizations where no one really knows bash that well anyway, fish would actually be nicer for scripting than bash if it had just a few more goodies like that imo. reply dinckelman 20 hours agoprevI&#x27;ve used fish for about 5 years now, and I don&#x27;t really wanna go back. Out of the box, without any addons at all, it does everything my old zsh setups did, with a package manager and plugins. The only change I&#x27;ve made to it was spacefish (now starship.rs) reply LibertyBeta 17 hours agoparentSame story here. But I recently moved to Tide prompt. It&#x27;s pure fish and really amazingly fast. reply BeFlatXIII 19 hours agoparentprevWhat are your use cases for starship? It looks interesting but I think I&#x27;m missing the imagination necessary to use it to its full potential. reply lolinder 18 hours agorootparentI use starship with zsh. The biggest value is showing the current environment for any project without any config. Shows the active node version, Python venv, k8s context, all without having to think about it.The other day an AWS command was rejected with a generic 403 error and at a glance I realized I&#x27;d forgotten to switch the default profile—without starship I suspect I would have spent a while troubleshooting my SSO login instead of just switching profiles. reply Cu3PO42 19 hours agorootparentprevI also use starship with barely any custom config (like fish). It shows me the environment I&#x27;m in for a project, including which versions of tools are active and which server I&#x27;m currently connected to (if any). And it looks pretty enough. reply natebc 19 hours agorootparentprevBig one for me was out of the box support for showing current kubernetes context. Very helpful if you work in multiple kubernetes clusters and in particular if you move around namespaces helping others.Doable with configuration and either lots of work or plugins in other shells but the combo of fish + starship.rs offers a lot for little setup. reply mdwalters 18 hours agorootparentprevNot OP, but I use Starship with fish and bash, it shows me my git repo&#x27;s status without having to run `git status`, which is very useful for me. reply theshrike79 19 hours agorootparentprevThe use case for me is a prompt that Just Works. No need to hack $PS1 or anything else, I just install it and everything works.There are some optional bits for more niche things (like laptop battery) you can enable with a config file, but it’s not necessary. reply beebmam 20 hours agoparentprevDoes it have support for reverse search yet? Not interested in auto complete. reply memco 18 hours agorootparentMaybe the recent ctrl-r behavior changes: https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;relnotes.html#fish-3-6-0-... do what you want? reply tipsytoad 19 hours agorootparentprevI like https:&#x2F;&#x2F;github.com&#x2F;PatrickF1&#x2F;fzf.fishCan also do cool stuff like search for a file to open in $EDITOR and searching git log reply srjilarious 19 hours agorootparentprevI end up installing mcfly (https:&#x2F;&#x2F;github.com&#x2F;cantino&#x2F;mcfly) in all my shells, and it works great in fish as well. reply petepete 19 hours agorootparentThere&#x27;s also fzf.fish, the only plugin I use.https:&#x2F;&#x2F;github.com&#x2F;PatrickF1&#x2F;fzf.fish reply pbowyer 17 hours agorootparentSame. A shell without fzf now feels weird. reply bin_bash 19 hours agorootparentprevyou just push ctrl-r just like in zsh reply boxed 19 hours agorootparentprevtype something, press arrow up reply WesolyKubeczek 18 hours agorootparentGood luck with that if what you’re looking for is in the middle of the command, though reply Rebelgecko 17 hours agorootparentI can search for just an argument and it finds the whole command fine reply cpach 17 hours agorootparentprevFish will match the string even so. reply bobbylarrybobby 14 hours agorootparentprevFish explicitly handles that case reply raverbashing 19 hours agoparentprevDid you have to convert your scripts to fish? Or is there an automated way? reply bin_bash 19 hours agorootparentNobody (I know) that uses fish actually writes scripts in fish. Everyone writes scripts in bash for portability. reply prokopton 18 hours agorootparentI’ve been writing all my shell scripts as .fish files for years. They’re just for me and I enjoy the syntax. reply ModernCannabist 17 hours agorootparentSame! I love the syntax, and I only share my .fish scripts with a friend or two I program with that also uses fish. reply theshrike79 19 hours agorootparentprevI’ve used fish for a half decade too, I still write my scripts in bash like everyone else. I want them to be standard and portable.Longer scripts get the Python treatment or a Go application. reply rgoulter 19 hours agorootparentprevWhile there is a tool called `babelfish` that will automatically convert bash to fish, in practice it&#x27;s rarely needed.You can run bash scripts from fish.For sourcing, often it makes sense to use direnv to automatically load variables. -- For \"just source this one time\", in the worst case you can run a bash shell, source that, then run a fish shell. reply junon 19 hours agorootparentprevYou can always run .sh scripts reply stavros 20 hours agoparentprevYou may also want to try z, and, err... I don&#x27;t have my config with me, but I have a plugin that notifies me if a long-running background command finishes, which is really handy. reply dang 14 hours agoprevAs it has been a while—related threads. Others?What&#x27;s Happening with Fish Releases? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36875727 - July 2023 (1 comment)My shell setup with Fish and Tmux (2021) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35672358 - April 2023 (80 comments)Are alternative (oil, nu, etc.) shells usable as daily drivers? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34722208 - Feb 2023 (141 comments)Rewrite it in Rust - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34588340 - Jan 2023 (464 comments)Fish 3.6.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34298157 - Jan 2023 (23 comments)Fish Shell 3.5.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31768405 - June 2022 (71 comments)Fish 3.4.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30734072 - March 2022 (90 comments)Fish 3.4.0 Released - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30660587 - March 2022 (21 comments)Oil or Fish Shell? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30154652 - Jan 2022 (2 comments)The fish shell is amazing - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29341390 - Nov 2021 (290 comments)Nsh: A fish&#x2F;bash-like Posix shell in Rust - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28967257 - Oct 2021 (50 comments)Fish Shell 3.3 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27663637 - June 2021 (1 comment)Fish shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27180420 - May 2021 (118 comments)Fish Shell 3.2 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26302678 - March 2021 (128 comments)Fish is not operational on a VT220 terminal (2015) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25526237 - Dec 2020 (113 comments)New Features in the Fish Shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24631138 - Sept 2020 (138 comments)Dolphins learn from their peers to use empty shells to catch fish - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23660910 - June 2020 (8 comments)Fish Shell 3.1.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22314671 - Feb 2020 (1 comment)Fish: A command line shell for the 90s - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21361696 - Oct 2019 (83 comments)Fisher 3.0 – the package manager for the fish-shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18920972 - Jan 2019 (1 comment)Fish shell 3.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18776765 - Dec 2018 (220 comments)Fish: A user-friendly command line shell for macOS, Linux, etc - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=15910897 - Dec 2017 (204 comments)Fish (Shell) for a Week - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=14422672 - May 2017 (2 comments)Why I&#x27;m Hooked on Fish Shell (and How to Set It Up Right) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=14417046 - May 2017 (1 comment)The fish shell is awesome - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=14179081 - April 2017 (7 comments)Fish Shell Design Principles - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11102941 - Feb 2016 (71 comments)Fish shell 2.2 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9873090 - July 2015 (70 comments)Fish shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9566441 - May 2015 (182 comments)FISH Shell: A dynamic shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8783150 - Dec 2014 (3 comments)Fish shell 2.1 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=6626635 - Oct 2013 (151 comments)fish shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=6224524 - Aug 2013 (75 comments)Fish shell 2.0 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5723235 - May 2013 (175 comments)Fish 2.0 shell beta - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5567639 - April 2013 (56 comments)Fish: Finally, a command line shell for the 90s - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4073162 - June 2012 (146 comments)Fish sucks (but your shell sucks more) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=2031110 - Dec 2010 (60 comments)Fish - The friendly interactive shell - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=820677 - Sept 2009 (16 comments)Fish Shell: A User-Friendly Shell or Like a Heavily Customized zsh - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=811113 - Sept 2009 (8 comments) reply JNRowe 12 hours agoparentI think https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23660910 may be a trap street^wlink to see who is watching :) reply dang 11 hours agorootparentRight! I upped the ante from https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29343065 by taking out the j&#x2F;k reply keepamovin 11 minutes agorootparentHaha, Good one! :) reply _thisdot 18 hours agoprevI was using fish on Ubuntu in college. First job gave me a macbook and I set it up using fish. We only had one devops guy and he shared the app set up docs and all the scripts were available only in zsh or bash. I was okay with switching to zsh tbh. But the dude stopped me and then spent half a day learning and then updating all the docs with fish scripts as well! Bless him! reply 21eleven 20 hours agoprevWhat I like about fish is that it provides a lot of nice-to-have ergonomic features from the get go without having to install plugins.I add starship.rs to it and fzf integration but that&#x27;s it. reply wodenokoto 17 hours agoparentWouldn’t that also be the two things one would do in bash? reply 21eleven 16 hours agorootparentThis is true. However I was calling out, wrt fish, the only two additional \"plugin\" type things I add in order to have a comfortable shell environment.Fish conveniently provides history based autocomplete so I don&#x27;t need to setup some plugin for that. reply Kiro 20 hours agoparentprevWhy do you need starship.rs? reply dinckelman 20 hours agorootparentYou don&#x27;t need it. But it&#x27;s just a really good, no-bullshit, customizable prompt, and you can use it with basically any shell you like, drop-in reply hiAndrewQuinn 20 hours agorootparentYeah. I love the default starship and install it on every shell I use, currently PowerShell + fish + bash. It shows me all kinds of useful info like which k8s cluster I&#x27;m logged into, which AWS&#x2F;Azure&#x2F;GCP account, whether the current directory has uncommitted git changes... reply Kiro 20 hours agorootparentprevI think I misunderstand what \"prompt\" is referring to here. What is it? reply dinckelman 20 hours agorootparentWhen you open a new shell, by default it&#x27;ll say something like `user@hostname: cursor`. Starship lets you change that to whatever you want, but out of the box it hides unnecessary information, and shows you stuff like the your language and package versions, if you&#x27;re navigated into a git repo, for example. Take a look at it yourself, there&#x27;s a lot you can do reply Zizizizz 20 hours agorootparentprevhttps:&#x2F;&#x2F;starship.rs&#x2F;A shell theme reply mattgreenrocks 18 hours agorootparentprevDoes it have async git checks yet? reply 21eleven 16 hours agorootparentBased on my experience opening a clone of the nixpkgs repo the other day... I don&#x27;t think so :) replydizhn 20 hours agoprevI love their tagline. Very funny. I used it for a while and liked it enough but their development strategy is explicitly against having configurable options. A few things nagged me and there was no way to change the behavior so I switched to zsh and made it work like fish, but the way I like it instead. For me this was a good decision and I recommend it. (I am not a fan of oh-my-zsh or plugin managers etc either) reply em-bee 19 hours agoparentcan you elaborate on what nagged you? i am just curious, not critical.i use fish, zsh and now also elvish. the main thing for me is autosuggestion and getting history with uparrow. zsh has a module for autosuggestion. elvish has uparrow history (but only matches at the start). so fish still wins over the others. elvish comes second because typing a command and hitting uparrow once is almost like autosuggestion. but i could not find a way to get that in zsh. i also prefer the way fish and elvish handle blocks over the traditional sh-shell style. reply JNRowe 18 hours agorootparentI&#x27;m unsure what specific behaviour you want from zsh and the up key, but it provides more than one up-line-*¹² function out of the box. Also, you can add any behaviour you wish with a custom zle function. That said, I understand some people prefer to just use something with the default settings.¹ https:&#x2F;&#x2F;zsh.sourceforge.io&#x2F;Doc&#x2F;Release&#x2F;Zsh-Line-Editor.html#...² https:&#x2F;&#x2F;zsh.sourceforge.io&#x2F;Doc&#x2F;Release&#x2F;Zsh-Line-Editor.html#... reply em-bee 17 hours agorootparentto explain the up key: prompt> some-word[up key]will search for some-word in the history.this feature helps because in 90% of cases i can type some-word and have autosuggestion show me the right command, so i just need to hit right arrow and enter to run it. but, if the suggestion is wrong, i can instead hit up arrow and search for a another history entry.in zsh currently, i can get autosuggestions, but if the suggestions is wrong, i have to type ctrl-A and retype some-word in order to search the history. i want to be able to do that without retyping, the way it is done in fish.elvish only has the uparrop feature which gets me there halfway, i can type something, and then hit uparrow to find a matching command. in most cases the first hit is the one i want, but if not i keep searching.i prefer to also have the autosuggestion because often i don&#x27;t remember that i have a similar command already, and the autosuggestion provides that hint.together these are the two most useful features that i want from a shell. reply JNRowe 15 hours agorootparentThat is the difference between the up-line-or-history and up-line-or-search functions that I linked above. The default Up binding is the -history function, whereas the -search function in unbound by default. There are pattern variants too, if you don&#x27;t like the prefix only checks.If you also need to mimic the fish behaviour of C-r mid-command because your suggestion wasn&#x27;t correct, then that does need a custom function to bind to C-r as you have to provide ${L,}BUFFER to populate the search pattern like fish does. reply em-bee 10 hours agorootparentah, thank you. that actually helps a lot. i don&#x27;t use zsh as much, but it&#x27;s good to know that this feature is available. i don&#x27;t use ctrl-R in fish yet, so i won&#x27;t miss that. reply em-bee 11 hours agorootparentprevooops, typo: ctrl-A above is supposed to be ctrl-R, in case anyone is confused replyrany_ 19 hours agoprevThe biggest screw up is that fish is not bash compatible. I&#x27;m just too used to bash and am not willing to change that because there are corporate systems where I only have access to bash and nothing else; and cannot install fish.It will just be hurtful to need to keep switching between different scripting languages; I will never be able to do so comfortably and with muscle memory. reply erikpukinskis 19 hours agoparentI don’t follow… could you put #!&#x2F;bin&#x2F;bash at the top of your scripts, and still use it for scripting, but then use fish as your interactive shell? reply rany_ 18 hours agorootparentNo, I mean creating some kind of quick program from the prompt itself.Like for instance bulk renaming of files from the prompt, there is no way I could do that quickly in fish&#x27;s language and having to switch to bash to do that would be unnecessarily slow. Might as well stick to bash.What I mean to say is that fish would hurt my productivity rather than boost it. reply em-bee 10 hours agorootparentlearning any new tool takes a bit of time. but i believe you are overestimating the effort it takes to learn fish syntax. it is not that hard. you also need to consider the features in fish that boost your productivity that don&#x27;t need to be learned at all. just give it a try. reply mcpackieh 18 hours agorootparentprevI think this is what most fish users do. I suspect that failing to understand this is possible, due to not understanding how shebang scripts are executed by the kernel, is a major reason why bash remains popular for interactive use. reply joseph 16 hours agorootparentIt&#x27;s not that. We don&#x27;t want to switch shell syntax between workstation and server, for example. The fish users I&#x27;ve known moved very slowly when they had to hop on a server, or build a new container image where it involved a &#x27;docker run&#x27; into the shell to test it out. If you know bash or sh well enough to do those things quickly then there is no incentive to use fish. reply nimih 6 hours agorootparent> If you know bash or sh well enough to do those things quickly then there is no incentive to use fish.I honestly think you might misunderstand why a lot of people use fish. I know bash “pretty well”—I’ve written and maintained my fair share of complex bash scripts, and remain pretty comfortable opening a shell in a running docker container or EC2 instance to debug various nonsense. What makes fish attractive to me for use as my login shell is the creature comforts which are very nice to have on my regular workstation, but aren’t really necessary when mucking around in some random environment: syntax highlighting, tab completion&#x2F;autosuggestion&#x2F;history search which “just works”, somewhat nicer syntax for writing simple scripts for personal use, saner word splitting, and so on. I guess I can’t really speak for other fish users and am perhaps biased by learned bash first a couple decades ago, but I don’t personally find it especially burdensome to have to remember multiple shell syntaxes&#x2F;semantics (I already use half a dozen in my day to day work; what’s one more?), and I view it as a reasonable price to pay for a UI I find much more pleasant on whole. reply mcpackieh 12 hours agorootparentprevBut `docker run` is the same in every shell. The only things that really change is the syntax for looping over files, advanced globing, things like that. Control-R, tab completion etc all works more or less the same with some minor quirky differences, but nothing that would slow somebody down.Context: I used bash for about 5 years, zsh for the next 10 before switching to fish. reply akho 3 hours agoparentprevThat&#x27;s not a screwup, that&#x27;s the point of fish.You can&#x27;t make a sane shell scripting language without dropping POSIX compatibility. reply rany_ 2 hours agorootparentI don&#x27;t believe that&#x27;s the goal they set out for themselves; and besides I feel like it should at least be as POSIX compatible as they could make it. They could drop POSIX oddities where they see fit, but POSIX is not all insane.I mean, I really doubt that the `export` command is terrible somehow. In fish, you have to use `set -Ux` which is just ridiculous and petty of them, the world doesn&#x27;t revolve around the fish developers and this just breaks many files that you try to source from fish; for example, Python venv activation scripts.As for why I don&#x27;t think that&#x27;s their goal, just look at https:&#x2F;&#x2F;fishshell.com&#x2F; not one of the listed features requires them to drop POSIX compatibility entirely. I just want something like fish shell that isn&#x27;t too radical and tries to be as POSIX compatible as possible while adding their improvements, out of the box (so ZSH doesn&#x27;t count). reply em-bee 19 hours agoparentprevi use fish for interactive work and bash for scripting. if there is a script that i don&#x27;t want to write in bash, then i use a real programming language like python or ruby. reply bin_bash 19 hours agoparentprevas long as you&#x27;re not doing conditionals and loops you probably won&#x27;t be able to tell you&#x27;re not using bashpersonally I almost never put anything that complicated into my shell, once it gets to that point it goes into a script. reply stealthypoo 19 hours agoparentprevI haven’t found much need to swap due to using basshttps:&#x2F;&#x2F;github.com&#x2F;edc&#x2F;bass reply thibran 18 hours agoprevNushell > Fish > ZSH > BashI tried a lot of shells and that&#x27;s what I ended up with. reply kattagarian 18 hours agoprevI don&#x27;t know much about shells. Fish was the first one that made everything so easy and the only downside was not being posix compliant, but i can easily call bash and run the command. I tried leaving fish and the others requires so many configurations, but fish does by default. It suits me. reply Hrun0 18 hours agoprevI was hesitant to switch to fish shell, but after seeing so many recommendations on HN, I gave it a shot. Been using it for a while now, and it&#x27;s mostly good.The one hiccup is the syntax; it&#x27;s different from ZSH, so you have to update your existing config. ChatGPT has been pretty useful for that, though. reply iLoveOncall 18 hours agoparentAt least now && works. It used to not be the case and required you to type \";and\" which was incredibly annoying as you had to modify basically every single command that you found online or that people sent you.Now that && works, I don&#x27;t have any big conplaints about it anymore. reply ilyash 3 hours agoprevHi. I&#x27;m Ilya Sher, author of Next Generation Shell. That&#x27;s the only shell that I&#x27;m aware of that plans to do something \"radical\" about the UI&#x2F;UX. By radical I mean something out of the telegraph style communication paradigm.https:&#x2F;&#x2F;ilya-sher.org&#x2F;2022&#x2F;12&#x2F;31&#x2F;telegraph-and-the-unix-shel...https:&#x2F;&#x2F;blog.ngs-lang.org&#x2F;2023&#x2F;06&#x2F;08&#x2F;the-shell-vs-the-web&#x2F; reply woleium 20 hours agoprevI used fish for a while (and really enjoyed it, it&#x27;s a great shell), but it&#x27;s formatting is too inconsistent with bash for me. I found myself dropping back to zsh so often to write documentation or run a playbook that I switched back.If you often share shell code with others it may be to big of a leap for you. reply cedilla 19 hours agoparentI use fish since they relented and allowed to use && and || instead of ;or and ;and. Still, I always script with bash (or POSIX sh for certain things). I can&#x27;t recommend that split enough. Also, I can&#x27;t speak highly enough of shellcheck[1], it&#x27;s a lifesaver especially when you target POSIX.1: https:&#x2F;&#x2F;www.shellcheck.net&#x2F; reply keepamovin 19 hours agorootparentI&#x27;m there with you on that. reply csmattryder 19 hours agoparentprevIf you&#x27;re running a script, you can use edc&#x2F;bass to run it from a fish shell. Fisher is one of the first things I install after fish, then bass, z and a few other helper plugins.https:&#x2F;&#x2F;github.com&#x2F;edc&#x2F;basshttps:&#x2F;&#x2F;github.com&#x2F;jorgebucaran&#x2F;fisher reply zvmaz 18 hours agoprevI may be mistaken, but since I have to work with different machines that all have bash as a shell, I try not to mess with my muscle memory and stick to bash even on my own machine. But maybe I should try Fish. reply error9348 18 hours agoprevBeen using it for years. Accidentally found out a few months ago, shift+tab allows you to search for completions. reply assbuttbuttass 19 hours agoprevI tried zsh at some point, but I got the impression that it&#x27;s basically the same as bash out of the box, and you need to spend time customizing it to see the benefits. I don&#x27;t want to spend time customizing my shell, I want it to work out of the box.Fish is noticeably better than bash out of the box, with absolutely no customization. Magic autocomplete is life-changing. reply lacrimacida 19 hours agoprevFish is a pleasure to use, been using it for about half a decade. reply BeetleB 16 hours agoprevNot to hijack, but also consider xonsh[1]. It&#x27;s Python based, and all your scripts can be Python (or hybrid-Python). I&#x27;ve been using it for both Windows and Linux for over 5 years.[1] https:&#x2F;&#x2F;xon.sh&#x2F; reply ansdomizzz662 16 hours agoparentI&#x27;m interested especially for Windows, does it have any of the footguns relating to awful corporate network drive setups, $HOME, expensive prompts, and the like?I need a good shell for when I&#x27;m forced to work on Windows machines (and when WSL isn&#x27;t available). Git Bash (and even plain MSYS2 bash) performance is so unbelievably awful every single time, and the fixes can be hard to determine and a giant pain in the ass, and sometimes impossible if they are due to windows defender or whatever antivirus junk the corporate environment has installed.However, Python runs fine, so maybe Xonsh would run fine?I realize I should probably just use PowerShell but I strongly dislike the syntax and would have to write function wrappers for basically every command I setup. I&#x27;m sure most here can relate to that. reply BeetleB 15 hours agorootparent> does it have any of the footguns relating to awful corporate network drive setups, $HOME, expensive prompts, and the like?Not sure what you mean - can you give an example?There will be a $HOME environment variable.I never use WSL, Git Bash or Cygwin stuff. Just the normal command prompt with xonsh running on top of it. So I can&#x27;t speak to performance issues. If you could give examples, I may be able to address them.Definitely should not have issues due to antivirus. It will be a program running continuously.> I realize I should probably just use PowerShellPowershell is probably the best, but I didn&#x27;t want to expend energy learning it. With xonsh I can have the same config in Linux and Windows, and Python is always a plus. reply istjohn 19 hours agoprevI quit fish because I missed being able to `sudo !!` to rerun the previous command with sudo. There&#x27;s an alternative way to do it (something like up arrow, ctrl-i, \"sudo\", enter), but I can never remember it when I need it, which is not often enough to stay in my head, but often enough to be come quite annoying. reply 7839284023 19 hours agoparentI hope that you are joking since you just have to press `Alt` + `S` to rerun the previous command with sudo in fish-shell:> `Alt` + `S` Prepends sudo to the current commandline. If the commandline is empty, prepend sudo to the last commandline.https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;interactive.html#shared-b... reply JNRowe 18 hours agorootparentThat is a recent(-ish) addition¹, arriving in 3.1. Your interpretation of recent may be a different length to mine, but one Debian release in this instance ;)¹ https:&#x2F;&#x2F;github.com&#x2F;fish-shell&#x2F;fish-shell&#x2F;pull&#x2F;6140 reply winter_blue 17 hours agorootparentprevI guess he wasn&#x27;t aware. I use fish, and I&#x27;m learning this now too. I probably really should give the fish docs a read-through, as I imagine it could significantly improve my shell efficiency. reply rileymichael 18 hours agoparentprevYou can set this up to work the same way with the recent abbr changes, and I believe they may add it as a default in the future. function last_history_item; echo $history[1]; end abbr -a !! --position anywhere --function last_history_itemsource: https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;relnotes.html#id1 reply alsuren 17 hours agoparentprevI also bounced off of fish for the same reason.This post has prompted me to give fish another go, so I looked into it again.It looks like the abbreviation system can now (since March this year) help you with !! (https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;cmds&#x2F;abbr.html even gives it as an example)I also use `!$` (`vim script.py` and then `python !$` or `git commit !$`) but the parser rejects `!$` before it can be rewritten by the abbreviation system. [edit: https:&#x2F;&#x2F;superuser.com&#x2F;a&#x2F;1762626 points out that if you add a space before hitting enter then it works fine, so I&#x27;m guessing it&#x27;s just a bug, and I should go with d below]Options seem to include:a) make a !$ replacement that is not illegal and change your muscle memory `\\$` or `!\\$` or `!@` or `!%`b) use a keybinding for !$ as suggested in https:&#x2F;&#x2F;github.com&#x2F;fish-shell&#x2F;fish-shell&#x2F;issues&#x2F;288c) some combination of a and b (e.g. make a `!\\$` abbreviation and then make a binding so that if you type !$ it replaces it with `!\\$` so that it gets past the parser without expliding)d) patch the parser to allow !$ as a special case if there is an abbr for it.I just tried b but it&#x27;s pretty jarring. I think I might go with c instead.I&#x27;m actually feeling quite positive about this now.There is something I&#x27;ve been wanting to add to bash since forever, which is something to help me cd into a repo that I just cloned (e.g. `git clone https:&#x2F;&#x2F;github.com&#x2F;fish-shell&#x2F;fish-shell` then `cd !&#x2F;` could expand to `cd fish-shell`).Exciting times. reply JNRowe 15 hours agorootparentBash has a range of modifiers for history expansion. You can \"cd !$:t\" to execute \"cd \" for your git example. zsh, somewhat predictably, has a superset of bash&#x27;s modifiers so it works there too. reply aquova 18 hours agoparentprevThat behavior was added earlier this year - https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;relnotes.html#fish-3-6-0-... reply justinmayer 16 hours agoprevIf you use Fish shell and Python, my project VirtualFish can make managing virtual environments a lot easier and more fun:https:&#x2F;&#x2F;github.com&#x2F;justinmayer&#x2F;virtualfish reply xwowsersx 16 hours agoparentThanks for mentioning. I think it would help a bit if you copy-paste a short terminal session to show what VF looks like in operation. I know there are extensive docs, but a quick tldr&#x2F;screenshot helps quite a bit in a README I find reply girishso 20 hours agoprevTried fish a couple of times, it&#x27;s really good, many zsh plugins are created to replicate features of fish. But it&#x27;s not my default shell, because I need to run bash shell scripts and I didn&#x27;t find any way to do it in fish. So I am stuck with my slow zsh. reply bin_bash 20 hours agoparentI often see people complain about this but I seriously don&#x27;t understand. The shebang at the top of a bash script will point to bash no matter what your shell is. reply BeetleB 16 hours agorootparentAt various jobs I&#x27;ve often seen bash scripts to set up your environment (mostly environment variables). Running a bash script with shebang will not preserve the changes to the environment variables, will it? At least that was my experience.I use xonsh and fortunately it has source-bash for stuff like that. reply bin_bash 5 hours agorootparentI&#x27;ve never needed it, but there is bass for this use-case: https:&#x2F;&#x2F;github.com&#x2F;edc&#x2F;bass reply laputan_machine 20 hours agorootparentprevYeah I would have thought so too, but I have personally ran into this issue running fish-shell on my mac. There are some scripts I need to run that do not work even when I shebang the script to run in bash. reply zkldi 19 hours agorootparentthe shebang is literally handled by the kernel, so fish has nothing to do with this here.are you sure you&#x27;re running `.&#x2F;scriptname` or bash scriptname` reply stavros 20 hours agorootparentprevThat&#x27;s really odd. I have never had a single issue with this, I don&#x27;t understand how shebanged scripts can fail? What&#x27;s the error? reply laputan_machine 19 hours agorootparentYes, it really is odd, I couldn&#x27;t figure it out so switched back to zsh.The specific issue was to do with a script we had to run to gain ssh access to an internal network. I can&#x27;t post the script, but it was related to openssh.Even logging into bash and running the script didn&#x27;t work, I had to remove all fish binaries, symlinks, etc and set my shell to bash&#x2F;zsh. Maybe it was an issue with how I installed fish, but yeah like I said, very strange, but I can vouch that I&#x27;ve encountered a similar issue beforeIt&#x27;s a real shame because I think the fish syntax alone is worth the switch, for my personal machine(s) I use it.Edit: this was years ago now, about 4 years, maybe the issue doesn&#x27;t exist anymore but it caused me a bit of grief at the time (beacuse I didn&#x27;t know it was related to using fish!), I&#x27;ve not since tried it again. I might try again and get back to this thread reply _TwoFinger 19 hours agorootparent> I had to [...] and set my shell to bash&#x2F;zshMost likely a command in your script (or one source-d into it) makes an assumption about your $SHELL or login shell that is true for bash&#x2F;zsh but not for fish.Merely adding a shebang won&#x27;t fix such a script. reply pxc 18 hours agorootparentprevSee my other comment and let me know if that script contains ssh-agent $SHELL ...or exec $SHELL ...or eval \"$SHELL ...\"or similar. :)If it ends up passing a script file or arguments to $SHELL and you wanna fix it without rewriting it, just add some conditionals where $SHELL is used and use the equivalent flags or syntax when $SHELL indicates fish.Alternatively, if you just wanna work around it, just launch that script like env SHELL=(which zsh) whatever-script.sh reply em-bee 19 hours agorootparentprevfish doesn&#x27;t have builtins but all fish commands are external binaries or fish functions. i think at one point early in the history of fish those binaries may have been installed on the global path so they were accessible outside of fish and possibly there was a name conflict with one of them that this script triggered.although such a name conflict should not have happened (and i can&#x27;t think of which command such a script might have used that would also be a fish command), and the global path thing was also fixed soonish. but this is all a faint memory, so i am not sure i remember any of that right. reply pxc 18 hours agorootparentFish definitely has builtins, for example - cd - source, . - eval - string - and - or - builtin - commandand many others.Not sure what the point of distinguishing between fish builtins and fish functions is; whether a builtin is shipped as a function distributed with fish or a reserved word in the fish evaluator seems like an implementation detail. reply em-bee 17 hours agorootparentfish has grown and evolved. i was referring to this:Builtin commands should only be created when it cannot be avoided. echo, kill, printf and time are among the commands that fish does not implement internally since they can be provided as external commands. Several other commands that are commonly implemented as builtins and can not be implemented as external commands, including type, vared, pushd and popd are implemented as shellscript functions in fish.if i remember correctly, this led to some useful commands that are builtin elsewhere to be external binaries shipped with fish. but since those where not actually tied to the fish shell they could run without it, and if they ended up on the global path be accessible from other shells.the relevant text on the website has been changed, but it is referenced here:https:&#x2F;&#x2F;github.com&#x2F;fish-shell&#x2F;fish-shell&#x2F;issues&#x2F;612the discussion also points out that this has changed over time reply pxc 17 hours agorootparentIdk if fish has ever shipped builtins that way, but doing so is pretty conventional and doesn&#x27;t normally put those executables on the PATH. It&#x27;s what libexec is for: https:&#x2F;&#x2F;refspecs.linuxfoundation.org&#x2F;FHS_3.0&#x2F;fhs&#x2F;ch04s07.htm...If you wanna add a builtin like that to your own distribution of fish, you could do it cleanly by keeping those binaries in &#x2F;usr&#x2F;lib or &#x2F;usr&#x2F;libexec and then wrapping them in a fish function that ships in fish&#x27;s install prefix. (This is basically how fish&#x27;s Python scripts for generating completions from manpages are shipped today.) reply em-bee 17 hours agorootparentdoesn&#x27;t normally put those executables on the PATHright, i don&#x27;t remember the details, but when it happened it was probably fixed quickly. could even have been a packaging error in a distribution. replypxc 18 hours agorootparentprevThis is plausible if you have scripts that do dumb shit like eval \"$SHELL ...\"because (at least sometimes?) $SHELL is set by your login program and not your shell, and dropping to an alternative shell by just typing zshand hitting enter or whatever won&#x27;t reset $SHELL.You mention elsewhere that this had to do with a special OpenSSH setup, which also fits.One of the things you can do with ssh-agent is use it to launch a child process with a dedicated SSH agent that (only) has certain keys on it, and which exits once its child exits. This is sometimes handy for deployment scripts or doing git checkouts or whatever because you can ensure you don&#x27;t get locked out for too many auth attempts because the user just has too many extraneous keys on the agent associated with their normal user session.If you were leveraging this feature for interactive shells, you might be tempted to use $SHELL to decide what executable to have ssh-agent launch, so that you could (for example) accommodate both bash and zsh users and let them launch a shell with a special SSH agent but which honors their usual preferences by loading their usual shell and reading their usual zshenv or bashrc or whatever it is.You mention as well that you had to actually uninstall fish to get things to work again, and also that you were on macOS. I can&#x27;t be certain about the cause here, but one obvious thing occurs to me:macOS doesn&#x27;t handle environment setup like any &#x27;normal&#x27; (Linux or *BSD) Unix. On normal Unices, your login shell actually also launches your graphical user session, so to configure a session-wide environment variable, you just set it in your shell startup somewhere. On macOS, login shells are actually only used in SSH sessions and terminal emulators. If you want to set environment variables for apps that are not launched from terminal emulators, you have to use hacks (like Doom Emacs&#x27; env file, for example) or configure them for the whole user session via a LaunchAgent.In the case of $SHELL, that environment variable is used by editors to determine what shell to use when you run external commands. Without it, if you are a fish user and you launch MacVim or Emacs (or, presumably, VSCode or anything else) from your dock, when you go to launch external commands, they will run not in fish but some other shell (probably zsh or bash). If your install method for fish tried to handle this for you (pkgsrc and Nix don&#x27;t, but the .pkg from the developers or Homebrew might, idk), or if you dropped to bash only from terminal emulator windows that were already running fish instead of opening a new session for bash, you may have wound up in a bash session where $SHELL was still set to fish. That&#x27;s the only reason I can think of for why you might have had to actually uninstall fish to get this ill-behaved script to work right.Anyway:1. As a user, pay attention to what $SHELL is.2. As a script author, never use `eval \"$SHELL ...\" or equivalent`. reply akho 2 hours agorootparent> macOS doesn&#x27;t handle environment setup like any &#x27;normal&#x27; (Linux or *BSD) Unix. On normal Unices, your login shell actually also launches your graphical user session, so to configure a session-wide environment variable, you just set it in your shell startup somewhere.That&#x27;s no longer true for Linux, at least. GDM launches stuff via systemd user sessions, which do not source your profile. reply notnmeyer 19 hours agorootparentprevthis sounds really strange. i don’t suppose you have an example? reply innocentoldguy 19 hours agorootparentprevIs the path you’re shebanging to correct? One of my coworkers was having this problem and it turned out his path had a typo in it. reply st3fan 20 hours agoparentprevYou don&#x27;t have to translate them. Just stick `#!&#x2F;usr&#x2F;bin&#x2F;env bash` on top. It is totally fine to use fish as your \"terminal shell\" and default to Bash for scripting for things like automation, etc. I&#x27;ve been doing this for a decade. I will also add that Fish is so good by default that I barely have any config. reply mroche 20 hours agoparentprevIs the issue running bash shell scripts or copy-pasting one liners? If the latter, you can always use the command flag for bash to execute one liners within its own context. bash -c \"grep word file.txtsort -utail\"Scripts shouldn&#x27;t be an issue as long as you either launch it with the proper shell or configure the shebang correctly after making the script executable. reply PufPufPuf 19 hours agoparentprevWhat do you mean? If the script is using hashbang, you can just run it. If not, run \"bash script.sh\". If you need to source it, use the plugin \"bass\". If you want to run a one-time bash command copypasted from somewhere, just type \"bash\", run your command, and then ctrl-c. reply 28304283409234 20 hours agoparentprevI just run `bash script.sh`, or `.&#x2F;script.sh`? What does not work for you exactly? reply keepamovin 20 hours agoparentprevMaybe ask ChatGPT4 to translate them? reply pxc 17 hours agorootparentI asked an LLM to translate a bash script to fish once and it just changed the shebang line... cracked me up.Edited to add:There&#x27;s a program out there for translating bash to fish called babelfish. It&#x27;s pretty good but not complete, so it won&#x27;t work for all scripts. Worth checking out, though:https:&#x2F;&#x2F;github.com&#x2F;bouk&#x2F;babelfish reply keepamovin 4 hours agorootparentYeah, I&#x27;ve seen those stuck in loops where they don&#x27;t see an obvious mistake. reply notnmeyer 19 hours agorootparentprevthis shouldn’t be necessary and is probably fairly error prone. using one shell doesn’t mean you can run stuff in another.if someone is saying they can’t run a bash script when they’re invoking bash from fish the most likely thing is they’re doing something wrong. reply gfiorav 19 hours agoprevI loved fish for about 5 years. My only gripe is that going back to Mac it wouldn’t play nice with the terminal color scheme, or the dark mode switch. Anyone found a way around that? reply memco 18 hours agoparentFish has some options for that via `fish_config`: https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;cmds&#x2F;fish_config.html. You can use the browser tool or `fish_config theme ...` to find colors that work better. reply innocentoldguy 19 hours agoparentprevI use iTerm2 instead of the default Terminal app. In iTerm2, you can change the impossible-to-see blue and red to more reasonable values (or do what I do and use the Dracula Pro Themes). reply pacifika 19 hours agoprevI had to abandon the last time I tried fish because it’s not compatible with my export PATH declarations from tooling in bash&#x2F;zsh, any tips? reply bin_bash 19 hours agoparentOK so if you&#x27;re new to fish you should understand universal variables since it&#x27;s a concept that bash&#x2F;zsh does not have and it&#x27;s actually pretty great.When people first try out fish they want to add their global env vars and PATH configuration to ~&#x2F;.config&#x2F;fish&#x2F;config.fish. You can absolutely do this similar to how you do it in ~&#x2F;.bashrc. However, it&#x27;s not idiomatic and once you get used to universal variables, you&#x27;ll see that it&#x27;s a lot of yak shaving you really just don&#x27;t need editing config.fish.Instead, if you want to permanently set an env var across the current session and all new sessions, run: `set -Ux MY_ENV_VAR 1` (set a universal variable, and export it to subprocesses)That will put it into a machine-readable file ~&#x2F;.config&#x2F;fish&#x2F;fish_variables. You can open it if you want but this way you don&#x27;t need to source your rc files, open a new shell, or even open your editor.For PATH, just run: `fish_add_path ~&#x2F;my-new-bin`. It uses universal variables by default.For some reason I avoided universal variables as much as possible for years using fish and now I think that was really silly. reply artemisart 19 hours agoparentprevJust rewrite them once with fish_add_path? https:&#x2F;&#x2F;fishshell.com&#x2F;docs&#x2F;current&#x2F;tutorial.html#path Or maybe use https:&#x2F;&#x2F;github.com&#x2F;edc&#x2F;bass reply Flimm 18 hours agoparentprevI think later versions of Fish do support export statements. This line of code works with Fish, as well as Bash and Zsh: export PATH=\"$PATH:$HOME&#x2F;foobar&#x2F;\" reply PufPufPuf 19 hours agoparentprevYou can source bash files (like .bashrc) using the plugin \"bass\". You can also launch fish using a bash file, just export the variables and run fish as the last command.I personally just put what path modifications I need in .profile and have fish as my login shell. reply foobarqux 19 hours agoprevI don&#x27;t use fish but it does have one great feature that I&#x27;m surprised hasn&#x27;t been replicated in zsh: automatic completions derived from man pages. So you get at least basic flag completions for basically every program automatically. reply madspindel 19 hours agoprevWhy use this over nushell? reply bin_bash 19 hours agoparentThey&#x27;re really completely different. Fish is mostly about having features that help you enter a command (history, error checking, completions, etc). Once you execute something, it really behaves the same as bash&#x2F;zsh.Nushell is really more about command output (my understanding, I haven&#x27;t used it heavily). With Nushell you can do things like parse TOML files right in your shell: open Cargo.tomlget package.versionNushell understands the structure of data but fish is like bash&#x2F;zsh in that it just deals with streams of text. Nushell can even interact directly with sqlite databases which is very cool.I think if you&#x27;re just looking for a simple shell that behaves a lot like bash&#x2F;zsh, use fish. I think Nushell is more targeted to people that want to use its powerful data pipeline features—or are generally interested in a bigger departure from bash&#x2F;zsh.Personally I prefer fish, but I should start using Nushell more since it could definitely help with some tasks. I probably would just run Nushell when I need it though, I don&#x27;t see myself running chsh to switch over. reply em-bee 19 hours agoparentprevi can&#x27;t find anything about history handling in nushell. it&#x27;s one of the key features of fish reply microflash 18 hours agorootparentThey recently added sqlite backed history. You can also use atuin[1] for more advanced usecases.[1]: https:&#x2F;&#x2F;github.com&#x2F;atuinsh&#x2F;atuin reply mcpackieh 18 hours agoprevFish is pretty good, but I wish it would come with fzf-like capabilities built into it by default, for automatically searching history&#x2F;files&#x2F;etc.Yes I know I can just install fzf and the fzf&#x2F;fish integrations, I&#x27;ve done so. But my understanding is that the whole point of fish is that it comes well configured by default. fzf is a quantum leap forward for shell UX, this sort of functionality should be built in by default. reply buildbot 20 hours agoprevI’ve used fish for nearly a decade now, it’s awesome. The autocomplete works for so many things you don’t expect!Command line arguments! Remote path completion! Git!It’s something I install basically on everything machine I can. The history based autocomplete is so useful for keeping track of and refinding those less used complex commands that you have not saved in a function yet. reply mezobeli 16 hours agoprevI think it&#x27;s not Bash compatible, had issues in the past to run some programs and scripts reply ireallywantthat 16 hours agoprev [–] Am i the only one who feels fish is not worth it despite of hype? Don&#x27;t get me wrong. I think that fish is really good shell.BUT...After adding the following plugins to zsh(before you chime in, it&#x27;s just adding these lines,not anything configuring much. also it auto bootstraps on new install), I found out that fish is no where as good as configured zsh.1) https:&#x2F;&#x2F;github.com&#x2F;zdharma-continuum&#x2F;zinit (plugin manager)2) https:&#x2F;&#x2F;github.com&#x2F;zdharma-continuum&#x2F;fast-syntax-highlightin...3) https:&#x2F;&#x2F;github.com&#x2F;zdharma-continuum&#x2F;history-search-multi-wo...4) https:&#x2F;&#x2F;github.com&#x2F;zsh-users&#x2F;zsh-autosuggestions5) https:&#x2F;&#x2F;github.com&#x2F;zsh-users&#x2F;zsh-completions6) https:&#x2F;&#x2F;github.com&#x2F;Aloxaf&#x2F;fzf-tab7) any good shell prompt generator like https:&#x2F;&#x2F;github.com&#x2F;romkatv&#x2F;powerlevel10kFor example, I use fzf integration for tab completion. Fish&#x27;s fzf integration is nowhere as good as that of zsh&#x27;s. Also, posix compat and almost bash compat of zsh is plus.I acknowledge that zsh isn&#x27;t perfect shell either and I have tried and failed few times in past to switch to fish. If you provide me compelling reason&#x2F;s to switch to fish, I am all ears. reply AnthonBerg 16 hours agoparentSincerely: What hype? heheh –I see fish as a mostly obscure shell with some design principles.It works for me. It’s a great tool.I tried zsh; zsh was a lot slower as I set it up. Maybe I did it wrong.I think the case is that with either of fish or zsh you can’t lose. Both are great. reply em-bee 10 hours agoparentprev [–] well, one of the big benefits is that i don&#x27;t have to set up all this in order to get the functionality, because fish provides it out of the box. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fish shell is a command line shell available on GitHub for macOS, Linux, and various platforms.",
      "Features of fish shell include syntax highlighting, autosuggest-as-you-type, and tab completions.",
      "Installation instructions are provided for macOS, Linux, and Windows, including building from source and dependencies.",
      "The summary also mentions how to contribute to the project and where to find support and resources."
    ],
    "commentSummary": [
      "The Fish shell is praised for its user-friendly interface, simplicity for scripting, and built-in features.",
      "Users express frustration with other shells like zsh and discuss compatibility and configuration issues.",
      "While there are some limitations, overall, users have a positive view of the capabilities of the Fish shell."
    ],
    "points": 233,
    "commentCount": 154,
    "retryCount": 0,
    "time": 1693055854
  },
  {
    "id": 37276502,
    "title": "Thoughts about what worked in math circles",
    "originLink": "https://buttondown.email/j2kun/archive/thoughts-about-what-worked-in-math-circles/",
    "originBody": "JULY 17, 2023, 11:10 A.M. Thoughts about what worked in math circles Halfspace Thoughts about what worked in math circles After about 7 months of math circles with a group of 7- turning 8-year-old boys and girls, I decided to take a break to breathe and reflect on what worked and what didn't. It's interesting how big a gulf there is between what math topic you think will be interesting to a 7-year-old and what actually captures their attention. Let me start by giving some examples of things I thought would catch their interest but flopped. The game SET. Fold-and-cut puzzles. Geometry snacks. Cutting a Mobius strip. Tessellations (Tooti Tooti, pdf link). Prime Climb. Making flexagons. Ruler and compass constructions. Things I didn't think they'd like but they loved: Knights and Knaves puzzles, and more generally any topic about propositional logic (blue-eyed islanders. Manually scheduling a round-robin tournament's worth of sports games, trying to minimize the latency of the entire tournament. (I originally phrased it as a soccer tournament, but that week the kid who loves soccer the most didn't show up, and so it turned into a DANCE competition, which was much more fun) Seven bridges problems, and trying to find the smallest \"impossible\" bridge problem. Trying to figure out who is better at penalty kicks based on counts of scores/misses. Coming up with your own Pascal's triangle-type pattern. And then there were the problems I thought they would love, and they did. The Function Machine game (guess a function given the ability to query it as a black-box) Variations of Nim. The Turing Tumble. Fair cake cutting (with real cookies and oddly-distributed toppings). Game theory games like Prisoner's dilemma and Chicken. Making mocktails for 3 people, given a recipe for 1 drink, and again with a recipe that serves 5. (fractions practice). Measurements were in quarters of ounces. Back in 2019 I wrote an article, Attention spans for math and stories in which I described how I have used storytelling with kids of various ages (not in a math context) to get them participating in activities and feeling welcome in a group. I tied it back to math, To have good mathematical content revolving around stories, mathematicians should learn to tell stories well. Somehow, though, my story-telling game was off during some of my math circles. I think through all my reading and learning about math circles, I had internalized a different viewpoint. That viewpoint, roughly speaking, is that the math should speak for itself. Much math circle literature seems to suggest that a facilitator should start with an open-ended mystery (like, \"can you draw a perfect shape?\") and then sit quiet until the participants start asking questions and exploring on their own (in this example, maybe discovering ruler and compass constructions). I suspect this might work with an older group of students, or a group of students who have already bought into math in some sense. I know, for example, that many parents who find math circles are desperately searching for resources because their kid's math ability is beyond their comprehension. Some of these kids are believed to be on the autism spectrum as well. The group I worked with were as typical upper middle class kids as you could find. They came to math circle after soccer practice. When they got bored during the circle they goofed off and roughhoused. Though they had never played \"Among Us,\" they constantly called things \"sus.\" More importantly, they just didn't care about number patterns unless it was couched in a more engaging format. Geometry was a complete dud, because it's even harder to come up with stories about arbitrary figures with shaded regions you want to find the area of. They didn't think tessellations were pretty. And they didn't have the dexterity required to make enough cuts and folds to construct objects out of paper, so they ended the fold-and-cut and flexagon activities feeling frustrated. But the idea that there are two people, one of whom is a ROTTEN LIAR, and you have to figure out who is the liar based on the clues in what they say? That's gold. For that knights and knaves puzzle, I wrote down the phrases Alice and Bob said on pieces of paper, taped them to plastic straws, and held them up like signs. The first puzzle was: Alice: Bob is a liar! Bob: Neither of us are liars. The kids all jumped to say who they thought was the most \"sus\", and they predicted that Alice was suspicious for blaming Bob. With a bit of discussion, they realized that they can't both be telling the truth because their claims are mutually contradictory (though they didn't have the word for this and often called it \"opposites\"). Then we talked about how many possibilities there are. First they thought 2, then 4. It's 4: two liars, liar truth-teller, truth-teller liar, and two truth-tellers. Then we proceeded to inspect each option, and after a while they agreed that the only possibility was that Alice was telling the truth and Bob was lying (correct!). Then an interesting thing happened. As I moved on to the next knights-and-knaves puzzle they asked if they got the first one right. And I said, \"well, do you think you got it right?\" One boy admitted he wasn't entirely certain, and then we all agreed to keep thinking about it until we were convinced by the proof. So it was planting the seed: how do you know if you've truly proved something? Later in that session he remarked to one of the girl's comments, \"No, we already proved that case!\" After the months of weekly sessions, however, I think the kids are warming up to the idea of the math speaking for its own sake. While I led the Seven Bridge of Konigsberg problem with a story, they quickly discarded the story and focused on the challenge. And in a later session they asked to revisit it because they wanted to try to find the \"smallest impossible bridges problem.\" Indeed, they did! While we didn't solve the original problem, the idea of simplifying a problem, making it smaller and smaller until you can solve it, and then gradually adding back complexity, was clearly on display those weeks. And though they hated flexagons, for an \"end of the session\" gift I made them each a hexaflexagon from a printed template which critically had bright, distinct pictures on each face. Weeks later, one girl's dad told me that she is obsessed with it, only recently discovering the sixth face. I let him know that you can draw a map of the flexagon's movements, much like the Seven Bridges maps we drew, to get a clear picture of the whole configuration space. I have yet to hear back whether they were able to figure it out. So I have hope that this group can graduate to appreciating the math for its own sake. But if I were to start with a new group of kids who had no a priori love of math, I'd have to be a bit more deliberate in framing the problems in engaging stories. You just read issue #26 of Halfspace. You can also browse the full archives of this newsletter. Subscribe Brought to you by Buttondown, the easiest way to start and grow your newsletter.",
    "commentLink": "https://news.ycombinator.com/item?id=37276502",
    "commentBody": "Thoughts about what worked in math circlesHacker NewspastloginThoughts about what worked in math circles (buttondown.email/j2kun) 225 points by sberens 12 hours ago| hidepastfavorite30 comments opportune 8 hours agoWow, all I can think is how exceptionally lucky these kids are to be taught these concepts&#x2F;exposed to these problems at such a young age by a willing and enthusiastic teacher. Most people professionally employed as K-12 math teachers wouldn’t even be able to teach this kind of curriculum well. I looked at the author’s blog history to find out if they were doing this for some huge amount of money and found a blog that suggests not only were they doing it for free (skimmed it, but didn’t see any reference to pay) but they had to try to convince other parents to let their kids participate! https:&#x2F;&#x2F;buttondown.email&#x2F;j2kun&#x2F;archive&#x2F;a-foray-into-math-cir...In my opinion, there is a relatively unknown (to those outside mathematics) huge “privilege” gap in mathematics education that makes it so those that only follow a cookie standard or accelerated curriculum are relatively unprepared for careers in mathematics compared to those tutored (or taught in special magnet programs, or by their mathematician parents) in these kinds of non-standard-curriculum concepts from a young age. Mostly, the problem is that the standard curriculum is almost purely rote-computational until you become a college ~Sophomore and it abruptly changes to being open ended and proof-based (which is the world most pro mathematicians live in) requiring skills in creatively applying logic. So students with this kind of exposure from a young age have a much easier transition to that while also scooping up all the math-career-builders like early papers and contest wins on the way.Those other parents probably don’t know this but OP is providing an immensely valuable service that is hard to find in some areas and which some parents would pay a huge amount of money for. reply pro-kythera 7 hours agoparent> those that only follow a cookie standard or accelerated curriculum are relatively unprepared for careers in mathematicsCulture-dependent? I recall the story from France of the second-grader who, asked what 2x3 equals, replied \"3x2\", knowing only that multiplication was commutative. reply dfdz 5 hours agorootparent> the story from France of the second-grader who, asked what 2x3 equals, replied \"3x2\", knowing only that multiplication was commutative.This is a classic joke making fun of the issues with French education based on the Bourbaki [1] school of mathematics, see [2] for more discussion. Different issues than the USA, but also bad in my opinion.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Nicolas_Bourbaki[2] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230315185224&#x2F;https:&#x2F;&#x2F;www.uni-m... reply zarzavat 5 hours agorootparent[2] is excellent satire because I honestly can’t tell if it is a parody of physicists with a contempt for mathematics (e.g. Feynman), or if the author truly believes it. reply Tainnor 3 hours agorootparentIt&#x27;s not satirical. It&#x27;s a very well known opinion piece by one of the most famous former Soviet mathematicians.FWIW, I understand where he&#x27;s coming from but I fundamentally disagree (not in the least because for me, computer science applications of mathematics are much more interesting than physics ones, and these can be incredibly abstract). reply svilen_dobrev 1 hour agorootparentprev[2] is interesting read. Detaching any science (or other knowledge-gathering-activity) from reality may well turn it into teology :&#x2F;And This observation:> \"genuine mathematicians do not gang up, but the weak need gangs in order to survive.\"applies to programmers as well, and may be just about any profession&#x2F;activity.. replyavital 4 hours agoprevFor those who are interested in getting involved with online math circles (as parents or potential instructors), check out https:&#x2F;&#x2F;theglobalmathcircle.org (Jeremy, the author of this post graduated from our training program) reply gnicholas 6 hours agoprev> The Function Machine game (guess a function given the ability to query it as a black-box)My kid has loved this one since I read about it on HN when she was 6. As she learned more advanced mathematical operations, we added them to the toolkit. It&#x27;s great! I can tell she&#x27;s mastered a concept when we can swap roles and she can accurately answer my queries. reply dan-robertson 11 hours agoprevIf you’re interested in more about ‘math circles’: https:&#x2F;&#x2F;www.msri.org&#x2F;people&#x2F;staff&#x2F;levy&#x2F;files&#x2F;MCL&#x2F;Zvonkin.pdf reply rahimnathwani 10 hours agoparentYes, in a previous blog post the author says he read Zwonkin&#x27;s book in preparation for running his circles. reply msla 9 hours agoparentprevhttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20141231040717&#x2F;https:&#x2F;&#x2F;www.msri.... reply dools 11 hours agoparentprevThat link gave me a 404 reply dan-robertson 10 hours agorootparentAh it was working when I posted it I think. Here it is in book form: https:&#x2F;&#x2F;www.amazon.com&#x2F;Math-Three-Seven-Mathematical-Prescho...I suspect you can find an online pdf if you search for the title. reply rahimnathwani 10 hours agorootparentprevThat URL used to contain a PDF of this book:https:&#x2F;&#x2F;bookstore.ams.org&#x2F;mcl-5 reply BoppreH 8 hours agoprevDifferent age group, but I had success in engaging with high-school students with \"Bitcoin mining\". This was a ~15 minute exercise after a lecture on blockchains, during a cryptography seminar.The original Bitcoin proof-of-work algorithm is to tweak the middle input of a hash so that the result starts with many binary zeroes (find x such that `sha256(sha256(a || x || b))Trying to figure out who is better at penalty kicks based on counts of scores&#x2F;misses.If you have kids who care about a particular sport, this is a great way to teach linear algebra. There&#x27;s a book &#x27;Who&#x27;s #1? - The Science of Rating and Ranking&#x27; that goes through different methods of ratings&#x2F;rankings in great detail (it was one of the required readings for my MSc in Data Science). reply gilleain 8 hours agoparentWell from the way the linked article describes it, there is no &#x27;story&#x27; to maths like Euclidian geometry.After all, what were the original motivations for compass and straightedge constructions? Ideas about perfection, symmetry, and constructability are all very abstract.I found https:&#x2F;&#x2F;www.euclidea.xyz&#x2F; to be fun, but then I find drawing Girih patterns fun, and I&#x27;m also not 8 years old :) reply mbivert 8 hours agoparentprevIn case this is of interest, and unknown, there&#x27;s an aesthetically pleasant digitization of Euclid&#x27;s elements[0]. But I&#x27;m not sure whether it&#x27;s best for studying: usually, actively engaging with the material is key (e.g. performing the constructions, without a model), thought the effective rules for kids might be different.I&#x27;m actually happy to see them interested in propositional logic, given how foundational it can be to coherent thinking. I would have guessed, as the author, that manual activities would have been preferred.[0]: https:&#x2F;&#x2F;www.c82.net&#x2F;euclid&#x2F;#books reply Mathnerd314 6 hours agoparentprevI remember learning about hyperbolic and spherical geometry in middle school, and that was cool. Not really because of the axiomatic aspect, but more of the \"how many lines can you draw through two points? Up to you!\" sort of questioning of mathematical assumptions and the funny diagrams. The Fano projective plane model was interesting, the Poincaré disk model was interesting. I remember some animations and some interactive software you could play with. But yeah, after about a week I got bored of it. I would say one 2-hour session devoted to different geometries and constructions would probably be about right.The Euclid&#x27;s Elements approach of axiomatic geometry is interesting, and suitable for maybe a high school course. Before students learn algebra they don&#x27;t really have an appreciation of deriving equations or proofs from a small starting point. And coordinate geometry is much more practical (some things are simply unconstructible with ruler and compass). reply elesiuta 8 hours agoparentprevI don&#x27;t know the setup used for the ruler and compass constructions, but there&#x27;s a game called Euclidea [1] which may be of interest. I found the level progression, scoring system, and solving proofs to unlock new \"tools\" was done very well.[1] https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.hil_hk.euc... reply noncovalence 8 hours agoparentprevI only gained an appreciation for ruler and compass constructions early in secondary school, at age 7 I&#x27;m not sure I could fully understand the beauty of deriving a huge system from axioms.For making Euclid interesting to children, I remember really enjoying a game called Euclidea: https:&#x2F;&#x2F;www.euclidea.xyz&#x2F; reply godelski 7 hours agoprevI want to add to this list for something that I teach to kids of similar ages: counting to a thousand on your hands. This is natural for any computer programmer, but there&#x27;s some key aspects to it that help with math education.This is quite fun for them as your question of \"Do you know how to count to a thousand on your hands?\" appears like magic or a superpower to them. So I demonstrate the beginning counting to 20 or so (quickly moving through 4 and 6). Then I start to ask them to predict certain unseen configurations (i.e. zero shot generalization). Re-demonstrate when failure to predict. Once the pattern is successfully learned, then I present a quiz&#x2F;puzzle, and ask how many fingers \"this many\" is (all fingers unfurled). Always stumped, I provide the hint \"if I had an additional finger and that finger were open and all others were closed, how many would that be? Can you figure out the other number from here?\" It takes time, but they almost always get it.The beauty of this is that we have a low barrier to entry, as the kid just needs to know how to multiply by 2 and know the names for numbers up to 1024. It surprisingly has many avenues of thinking that can help a kid better generalize concepts of math while still being entertaining (similar to concepts in this article). First, we teach the kids that there are multiple representations of things, and that we need to formulate things to match our goals. That we can break away from the common and expected thinking that most people have to gain \"super powers\" (i.e. not count like most people). Another important aspect is the above puzzle, where we specifically teach them that there are often better ways to go about solving a problem if we can find patterns. Rather than brute-forcing your way through this (summing each finger) you can exploit the iteration pattern to know that hinted at position is only one away from the desired. Frame of reference is such a crucial concept to mathematics and is at the root of solutions to many famous problems. Obvious post hoc, but inconceivable a priori.We can even go quite deep and talk about proofs and how to design algorithms! I&#x27;ll explain the algorithm identical to how we would perform a proof by induction (this is not how I teach kids, at the beginning):k0th step: starting palms facing user, and an initialized position where all fingers are closed (thumb is a finger and at left most and right most positions). Starting from the right, increment the right most finger (thumb)knth step: start from the right most position. If finger is closed, then unfurl. If finger is unfurled, close it and attempt to increment the next right most finger recursively following this condition.There&#x27;s more that you can build off of this one concept and similarly that with the topics in the article. What I&#x27;ve found is that which ever \"game\" the kid likes best is the one you should focus on and formulate your basis around. When they have difficulties with one game you use a different game that they are successful at to teach the difficult one. After all, math is a language and so many things can simply be rephrased.I find that one of the difficulties many have with math is that the internalize it as quite strict. That it is often taught \"this is the way,\" with no other methods accepted and thus people gain quite low generalizability of the concepts. Something that \"word problems\" are intended to resolve, but this approach is quite brute forced and more akin to how one might teach a machine rather than a human. This is coupled with the fact that so many are at a young age taught by people void of passion for the subject. This dispassion only passes from teacher to student (I&#x27;m sure many people can remember the breath of fresh air if they were lucky enough to find a teacher who loved math and encouraged the creative side of it. Honestly, that&#x27;s how I came the love the subject and prior to that Junior in High School class, I hated the subject despite being good at it and in advanced classes). reply akermany 6 hours agoprevI am wondering if this has been tried with children on the Autism Spectrum. I suspect a very different pattern of interests. reply thenobsta 11 hours agoprevHuh, my daughter and I taught her first grade class SET last year (I did most of the pedagogy…). They seemed both able to learn it and engaged. It wasn’t in a math circle setting, but a lesson to the whole class. Would be cool to investigate the differences! reply RheingoldRiver 3 hours agoparentYeah Set has been dear to me since I was about 5 years old, and I remember bringing it into class for \"favorite board game day\" in 1st grade (so when I was 6). Really surprised the kids didn&#x27;t like it!There&#x27;s a LOT of math you can do with it too, starting with some modular arithmetic. and I guess just the idea of abstracting the attributes to 0, 1, and 2. Then you can do a little bit of group theory and how the game is Z3^4 (iirc this is the right notation? been a while), 4 copies of Z3. And there are similar card games that represent other games that you can print out cards for if they&#x27;re getting excited about group theory, so you can talk about axioms of groups, and how the games represent the groups, and why it makes sense.Also you can introduce a bit of programming too and explain like how would you teach a computer how to play this game using the invariant property that a definition of a set is that sum c_i = 0 for all i 0 -> 3. and you can also easily generalize the game to other lengths by adding additional traits (background color of the card to add one) or fewer (remove bg color of the symbol).Anyway yeah this game is the best. reply rahimnathwani 10 hours agoparentprevWe played Set with my son when he was ~6.5yo, and he immediately loved it. After a couple of games, he was spotting sets almost as quickly as we were. But his performance and interest varied based on distraction, tiredness etc.If you want a one-player Set game, there&#x27;s a nice open source one here:https:&#x2F;&#x2F;playset.netlify.app&#x2F;The &#x27;AI&#x27; looks for solutions randomly. Every 2 seconds (in easy mode) it picks two of the visible cards at random, and sees if the card needed to make a set is visible.If your kid is totally new to Set, you probably want to adjust the delay to 5 seconds or something.Set is more fun against human players of course. reply thenobsta 10 hours agorootparent~6 seems to be the right age. I tried with with my kiddo at 5 and with another kid when they were 5 with no success. A bunch of first graders, on the other hand, were quick studies. reply jacknobody 11 hours agoprevThis is great! Home school teachers - take notice! reply benlivengood 11 hours agoprev [–] This is probably the most important recent scientific article about the (possible) future of STEM in the U.S. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Leading a math circle for 7-8 year olds involved experimenting with different topics to capture their attention.",
      "Propositional logic puzzles and game theory games were successful, while geometry and fold-and-cut activities were not engaging for the children.",
      "Storytelling played a crucial role in engaging young learners, leading them to appreciate math for its own sake, but the author acknowledges the need for more engaging stories with a new group of children."
    ],
    "commentSummary": [
      "Math circles are valuable and rare opportunities for young students, providing benefits in preparing them for math careers.",
      "Euclid's Elements approach and math games are mentioned as resources and activities to engage students.",
      "The article highlights the potential benefits and challenges of introducing math concepts, including for children on the Autism Spectrum, and emphasizes the importance of innovative and interactive teaching methods for math education."
    ],
    "points": 225,
    "commentCount": 30,
    "retryCount": 0,
    "time": 1693081207
  },
  {
    "id": 37272298,
    "title": "A venture-backed startup has quietly bought more than 80 mom-and-pop shops",
    "originLink": "https://techcrunch.com/2023/08/24/this-venture-backed-startup-has-quietly-bought-more-than-80-mom-and-pop-shops/",
    "originBody": "Login Join TechCrunch+ Search TechCrunch+ Startups Venture Security AI Crypto Apps Events More (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Link Copied Venture This venture-backed startup has quietly bought more than 80 mom-and-pop shops Connie Loizos@cookie / 12:50 AM CDT•August 25, 2023 Comment Image Credits: Teamshares Teamshares is a low-flying, New York-based startup with big ambitions to capitalize on an opportunity in plain sight: that of small businesses without a succession plan. It’s not a small market. According to the U.S. Small Business Administration, small businesses represent 99.7% of U.S. employer firms and 64% of private-sector jobs. Meanwhile, just 15% or so of small business owners pass along their company to a family member, with many others simply closing up shop at some point. With an aging population in the U.S., Teamshares is betting this market will grow even bigger, which is why since 2018, it has snapped up 84 small businesses from retiring owners. These owners like its pitch. Though Teamshares says that it sometimes pays below market price for a company, it installs a new president that it trains and grants 10% of the business’s stock to its employees. Moreover, it promises to increase those employees’ ownership to 80% within 20 years. It sounds almost valiant, like when KKR bought out a door company in 2015 and promised every employee a payout of at least $15,000 if the company met its targets when sold. When in 2022, KKR sold the company for 10 times what it paid, its 800 employees saw a payout of $360 million. But Teamshares isn’t in the private equity business. It’s a fintech company that has raised $245 million in venture capital to date, including from QED Investors, Spark Capital, Union Square Ventures, Inspired Capital, Khosla Ventures and Slow Ventures. It has also secured another $150 million in debt. Those backers aren’t funding Teamshares so that it can grow and resell the businesses it acquires. In fact, according to co-founder and CEO Michael Brown, Teamshares doesn’t want to sell the companies it is buying — ever. The plan instead is to generate revenue from a growing array of fintech products that it sells to the businesses it buys. Think insurance, think credit cards. If everything goes as planned, Teamshares will eventually replace the majority of vendors these companies use — and become a brand known to many others outside of its immediate sphere. Certainly, it’s among the more unique fintech models this reporter can recall. More below, edited for length. TC: Other than some exceptions like KKR, which is focused in part on employee ownership because owners tend to be better employees, I don’t know of another venture-backed company doing what you’re doing. How did you settle on this broader idea? MB: I spent the first seven years of my career in investment banking. And that’s where I met Alex Eu and Kevin Shiiba, the other two founders. Kevin decided he wanted to join the tech industry very early [and joined the] coding bootcamp General Assembly; Alex and I went and bought one, and then eventually eight, small businesses. We transitioned from being financial spreadsheet people to being operators and later entrepreneurs; learning how to operate a businesses informs [our work] today. How did you exit those businesses? We still own the ones in Canada; they’re running themselves today. There’s a president, a vice president. They’re just sort of like a dormant legacy business, but they’ve started the employee ownership journey, too, and that’s continuing on. You make money off those businesses through dividends? Is this how you’ll make money at Teamshares? How Teamshares makes money is we buy businesses, we dilute ourselves voluntarily to get employee ownership jump-started. We [carve out] 10% for all the employees and an additional 5% for [a president who we hire to run each business], and that stock is a gift — it’s earned over time through service. From a financial standpoint, we’re [structured] just like Berkshire Hathaway, so if we buy a business with $5 million in revenue, then that becomes our revenue the next day. We profit from the profits of the business that was acquired, proportionate to our ownership, and we sell our stock back over time to the companies until it becomes 80% employee owned. We also have new revenue streams that we’ve just started launching. We built a neobank, we’re soon to launch credit cards, and we’re building an insurance business as well, so there’s a secondary layer of financial products that will basically replace the vendors that the companies used to use. These products are going to be available exclusively to Teamshares companies or you start there and expand out? The hope is the latter. We only build something if a product doesn’t exist for our exact use case, which is some combination of really traditional small business or employee ownership. And there’s not a lot of stuff [out there]. When we set out, we didn’t think we’d build a neobank, but there just wasn’t something that existed to our satisfaction, in part because small businesses still unfortunately receive a lot of checks. But the hope would be that in the future — let’s call it in the next five years — we could scale up and open these products up and have small businesses generally get to know Teamshares. What do the companies you’ve acquired so far have in common? Where we have commonality in the companies is around employee ownership, financial education, the president program and financial infrastructure. So, we’re audited by KPMG, for example, and we help these companies go from mom-and-pop accounting to having real financial infrastructure and being able to produce statement financials every month that are in accordance with GAAP. But we really believe in the companies [operating as] independently as possible. We provide support, and we work closely with the presidents. But we don’t think that it’s a good idea to try and integrate all the companies. So you aren’t trying to roll up similar companies, or swaths of similar companies? There are some exceptions where, for example, we’ve been buying pizza shops in a state back East, and those are being integrated to create one larger company that’s going to create more employee ownership wealth than could a stand-alone set of pizza shops. We’re doing this again in pool maintenance, where a lot of the businesses are really [small] and actually [buying] a first one that’s small but big enough to support the cost of a president, and then you can add smaller ones. So there’s a roll-up-esque element of certain companies we work with, but in general, we think these are really high-quality businesses that can operate fairly independently and we actually make a very devout customer promise that the companies are going to become 80% employee owned, or never for sale again. What’s your investing criteria? There are over 40 specific industries [represented in Teamshares’ current portfolio], but they really fall into about six categories, which are business services, consumer services, distribution, manufacturing, restaurants, and retail. So they’re all traditional businesses that are, on average, 30 years old, with annual revenue of between $2 million and $10 million generally. We have a belief that employee ownership works in every industry, and our actual final decision — amongst the 70,000 leads we get every year — is all done on a case-by-case basis. But we start off by filtering the companies on what we call our structural criteria. So is it a true retirement sale? Are the owners of that age? Are there two or more managers? Is there low customer concentration? Do the earnings show up on the tax returns? You’re planning to sell these companies your products. Are there other ways the companies in the Teamshares ecosystem can work together? Absolutely. We’re now getting to the size where we’re starting to organize the companies, around industry groups. So there’s talk of the restaurant companies all kind of banding together [toward the goal of] common purchasing. The presidents [sometimes] share knowledge about what’s the best sort of ERP system and other software to use? Then there’s other things that don’t make sense for us to build but we can arrange large, corporate vendor partnerships. So, for example, you know, lots of these companies need vehicles, so having a national account with one of the major vehicle lessors is going to make sense. You mentioned Berkshire Hathaway early on. Is that what you aspire to build? Do you want Teamshares to go public? The most probable outcome is we go public, but there are ways to stay private, too. We do not plan to ever sell Teamshares; we would want it to be independent. In terms of the Berkshire Hathaway piece, we subscribe to a lot of their philosophy about being very long-term minded and being pretty efficient in our underwriting and keeping things simple. But we’re not a one-for-one translation of the model. Their model is to have the permanent ownership forever, whereas our model has employee ownership as a twist, so we’re actually forgoing some amount of future growth by making employee ownership happen. And we believe that’s the right thing to do. And we believe the companies will be bigger and better for it. Also Berkshire Hathaway can only buy companies that already have a CEO in place, whereas that’s not a luxury you can have in small business. We realized we had to build up a new generation of people, generally in their 30s and 40s, who were ready for something more entrepreneurial and ready for something really mission aligned. And so we recruit people from some really great companies — McKinsey, USAA, Tesla and Amazon — and train them to run these small businesses. How many employees do you have, and how big is your tech team? We have about 140 people altogether, and a 70-person tech team, so we’ve closed seven companies a month with two people. We’ve created a lot of leverage through building a lot of software for ourselves and for the companies. More TechCrunch A Brazilian phone spyware was hacked and victims’ devices 'deleted' from server As AI porn generators get better, the stakes get higher All hail the new EU law that lets social media users quiet quit the algorithm Five takeaways from Instacart’s S-1 filing Please login to comment Login / Create Account TechCrunch Disrupt Sept 19-21 San Francisco, CA Register Now Sign up for Newsletters See all newsletters (opens in a new window) Daily Week in Review Startups Weekly Event Updates Advertising Updates TechCrunch+ Announcements TechCrunch+ Events TechCrunch+ Roundup Email Subscribe (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Copy Tags Inspired Capital Khosla Ventures Spark Capital Union Square Ventures venture capital Venture This venture-backed startup has quietly bought more than 80 mom-and-pop shops Connie Loizos 12:50 AM CDT•August 25, 2023 Teamshares is a low-flying, New York-based startup with big ambitions to capitalize on an opportunity in plain sight: that of small businesses without a succession plan. It’s not a small mark... Social Microsoft brings Python to Excel, Cruise reduces fleet following crash, and MrBeast creates controversy Kyle Wiggers 3:15 PM CDT•August 26, 2023 Hello, folks, and welcome to Week in Review (WiR), TechCrunch’s regular newsletter that covers the biggest happenings in tech over the past few days. Haven’t been able to follow the new... Featured Article A Brazilian phone spyware was hacked and victims’ devices ‘deleted’ from server A Portuguese-language spyware called WebDetetive has been used to compromise more than 76,000 And... Zack Whittaker 3:00 PM CDT•August 26, 2023 Market Analysis Yes, in my backyard Anna Heim 12:00 PM CDT•August 26, 2023 Can startups help solve the U.S. housing crisis? BuildCasa thinks so. It raised a $3.5 million round of pre-seed funding to let California homeowners build new homes in their backyards. Venture The scoop on Gen-Z and how they are rewriting the rules of the Internet Alex Wilhelm 9:05 AM CDT•August 26, 2023 Listen here or wherever you get your podcasts. Hello and welcome back to Equity, a podcast about the business of startups, where we unpack the numbers and nuance behind the headlines. Welcome to an... Social The mugshot that launched a thousand memes Amanda Silberling 4:15 PM CDT•August 25, 2023 Memes can happen in the blink of an eye, like a Jeopardy! contestant who accidentally makes a sexual innuendo under the pressure of stage lights, or a kid who randomly gets interviewed on a playgro... TechCrunch Market Analysis Five takeaways from Instacart’s S-1 filing After so long an IPO drought, what does Instacart have in store for its existing investors and th... Alex Wilhelm, Mary Ann Azevedo 2:34 PM CDT•August 25, 2023 Fundraising Bitcoin startups remain undercapitalized as funding drought drags on Jacquelyn Melinek 2:25 PM CDT•August 25, 2023 Bitcoin-focused companies are falling behind as fewer checks are being written, according to Erik Svenson, co-founder and CFO of Blockstream. Startups How founders raised money so far in 2023 Haje Jan Kamps 2:05 PM CDT•August 25, 2023 Welcome to Startups Weekly. Sign up here to get it in your inbox every Friday. This week, DocSend dropped a big load of statistics about the VC activity over the past half year or so. For TC+, I di... Featured Article VFX artists show that Hollywood can use AI to create, not exploit Hollywood may be embroiled in ongoing labor disputes that involve AI, but the technology infiltra... Devin Coldewey 1:32 PM CDT•August 25, 2023 Apps WhatsApp rolls out support for HD video Sarah Perez 12:33 PM CDT•August 25, 2023 Last week, WhatsApp announced it was adding support for HD photos, allowing the messaging app users the option to preserve the high-def resolution of the phones they wanted to share with friends an... Work The 6 most important things to know about SaaS+ product architecture Justin Kaufenberg, Greg Blasko 12:30 PM CDT•August 25, 2023 Being aligned on these concepts will drive product roadmap, core technical architecture, pricing strategy and product marketing. Transportation Tesla investors might get payout from SEC settlement Rebecca Bellan 12:20 PM CDT•August 25, 2023 Tesla shareholders who claimed to face financial losses after CEO Elon Musk tweeted about taking the company private might be on the verge of receiving compensation from a $42.3 million fund establ... TechCrunch Market Analysis OnlyFans’ profitability proves the creator economy boom was real enough Quibbles aside, OnlyFans has proved that the creator economy is just as real (and profitable) as ... Alex Wilhelm, Anna Heim 12:00 PM CDT•August 25, 2023 Transportation Uber, squeezed by insurance, increases minimum age for new drivers in California Kirsten Korosec 11:32 AM CDT•August 25, 2023 Uber has raised the minimum age requirement for new rides-hailing drivers in California to 25 years old due to what it described as “baselessly higher” commercial insurance costs in the... Apps YouTube demystifies the Shorts algorithm, views and answers other creator questions Sarah Perez 11:13 AM CDT•August 25, 2023 YouTube this week put out a new video meant to address creators’ questions over its short-form video platform, YouTube Shorts. The questions it answered ranged from how the algorithm for Shor... Apps Dropbox drops unlimited storage, blames crypto miners and resellers for the change Aisha Malik 11:10 AM CDT•August 25, 2023 Dropbox is ending its unlimited option because some customers were using it for purposes like crypto mining, pooling storage for personal use cases and even reselling storage. The company’s highest... Transportation Joby Aviation narrows down to Ohio or North Carolina for new air taxi factory Aria Alamalhodaei 11:06 AM CDT•August 25, 2023 Joby Aviation is on the verge of choosing the location for its electric aircraft factory, with the choice now between Ohio and North Carolina, according to multiple sources who spoke to TechCrunch ... Fundraising Pitch Deck Teardown: BusRight’s $7M Series A deck Haje Jan Kamps 11:00 AM CDT•August 25, 2023 BusRight’s pitch deck is well-designed and full of careful touches. Featured Article MOVEit, the biggest hack of the year, by the numbers The mass-exploitation of MOVEit Transfer software has rapidly cemented itself as the largest hack... Carly Page 10:45 AM CDT•August 25, 2023 Transportation Polestar 4 to feature Mobileye’s hands-off, eyes-off driving tech Rebecca Bellan 10:44 AM CDT•August 25, 2023 Swedish electric vehicle maker Polestar wants to bring Mobileye’s Chauffeur, a hands-off, eyes-off autonomous driving technology, to its Polestar 4 electric SUV coupe. The Polestar 4, which l... About TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Legal Terms of Service Privacy Policy TechCrunch+ Terms Privacy Dashboard Code of Conduct About Our Ads Trending Tech Topics MOVEit Hack Instacart IPO Trump Back on Twitter Tech Layoffs ChatGPT Facebook (opens in a new window) Twitter (opens in a new window) YouTube (opens in a new window) Instagram (opens in a new window) LinkedIn (opens in a new window) Mastodon (opens in a new window) © 2023 Yahoo.All rights reserved.Powered by WordPress VIP (opens in a new window) .",
    "commentLink": "https://news.ycombinator.com/item?id=37272298",
    "commentBody": "A venture-backed startup has quietly bought more than 80 mom-and-pop shopsHacker NewspastloginA venture-backed startup has quietly bought more than 80 mom-and-pop shops (techcrunch.com) 215 points by rntn 21 hours ago| hidepastfavorite151 comments sema4hacker 15 hours agoFinding mom+pop businesses with growth potential can be difficult. If there is no growth you might not be able to squeeze any money out of the business at all. I recently did due diligence on the highest rated bakery in our area owned by a couple that did just about all the work but wanted to retire. Unfortunately all the profits became their salary. Replacing them meant their replacements&#x27; salaries would eat all the profits too. Their weekly sales were the same regardless of how many days they were open because new customers were rare and existing customers either squeezed into or spread out to whatever hours they were open. 40 other local bakeries meant competition was stiff. Everything was cash so an accurate audit was essentially impossible.Perhaps Teamshares is good at identifying acquisitions with sufficient margins to permanently afford Teamshares services, but if I was an employee at a company being bought I&#x27;d be concerned that after the owners retired with their cut and after Teamshares kept extracting their fees, I&#x27;d be left holding the bag, ie, a non-growing company slowly dying. reply adrianmonk 15 hours agoparentMakes sense. At https:&#x2F;&#x2F;www.teamshares.com&#x2F;brokers , if you click on \"Download buyer&#x27;s profile\", it says a few things that suggest they&#x27;ve taken that into account:> Due to our specific needs, we are often forced to pass on good businesses.And they want companies with:> at least two managers or supervisors supporting the owner in bookkeeping, dispatch, sales, or project managementAnd:> Our structure requires the inclusion of certain expense items (like presidents, finance leads, and&#x2F;or general managers) that other buyers may not have to factor in. This means sometimes our price comes in lower than an individual buyer who benefits from that salary. reply SoftTalker 11 hours agorootparent> And they want companies with:>> at least two managers or supervisors supporting the owner in bookkeeping, dispatch, sales, or project managementThat sounds like a bigger business than “mom and pop” to be honest. reply JKCalhoun 10 hours agorootparentMaybe family-run business is a better term?Somewhat related, I feel like probably every city in the U.S. has a family or two that have seemingly sewn up the new-car dealership businesses in their respective communities. reply Humboldtsnee 13 hours agoparentprev> Unfortunately all the profits became their salary.Genuinely, why is this unfortunate? It sounds like the workers in the business are getting to keep the value they create, and were more likely to be committed to the business as a result. reply idopmstuff 13 hours agorootparentIt means the business can&#x27;t practically be sold - if you buy it and have to spend all the profits on someone to manage it, you make nothing for what you&#x27;ve spent. You could buy it and manage it yourself, but then you&#x27;re effectively paying a significant amount of money for a very difficult job - might as well just go get a job for someone else.That ultimately means that the business itself isn&#x27;t worth anything, so when the owners decide they don&#x27;t want to manage it anymore, it&#x27;ll likely just have to fold. reply Humboldtsnee 12 hours agorootparentWhy is that unfortunate?Genuinely.It seems like the people doing the labor keeping the profits is a good outcome? reply adrianmonk 5 hours agorootparentFor some people, building up the business is both a job and an investment. When they get old, they want the business to have enough value that they can sell it and pay for their living expenses during retirement. Or they want to be able to pass the business on to their kids so their kids are set up to make a good living.If the business&#x27;s only value is that it can provide full-time employment to someone, then it has worked out as a job but not as an investment.There&#x27;s no one right way to do it. You could instead pay yourself a salary, invest the money in other stuff (maybe through IRAs or individual 401k), and just shut down the business when you retire. And for your kids, send them to college and let them find their own careers.It really depends on why you got into business in the first place. Maybe you just like working that way better. Or maybe you&#x27;re good enough at it that you think you can get better returns by investing in your own business than you can by buying a stock market index fund. reply idopmstuff 11 hours agorootparentprevIf the business can&#x27;t be sold, all of those people lose their jobs.Also, the owners presumably took a significant financial risk in starting the business, which hasn&#x27;t paid off. It really baffles me when people think that employees, who aren&#x27;t taking out personally-guaranteed SBA loans and risking losing it all in order to start a business, deserve all of the profit from the business. They deserve to be paid a fair wage, but people who actually take the risk to create something deserve to capture the upside. reply trifurcate 11 hours agorootparentprevIt&#x27;s unfortunate for the potential purchaser of the business.\"Unfortunately, my friend ate his entire birthday cake.\" It&#x27;s not unfortunate that my friend ate the cake (though it probably actually is, that&#x27;s not why it&#x27;s used there). It&#x27;s unfortunate that I don&#x27;t get to have any of his cake. reply bitcurious 11 hours agorootparentprevIf mom & pop doing the labor wanted to retire by selling the business, they can&#x27;t. What might have been an asset isn&#x27;t. So they either keep working even though they are of retirement age, or they close up shop with a smaller nest-egg. reply bjablonski 12 hours agorootparentprevWhat OP probably means that business was able to pay a living wage for owners and nothing more. So there was no additional cash for hiring manager, not even thinking about something for \"new owner\". reply Narkov 9 hours agorootparentprevThey don&#x27;t own a business...they own a job. reply Humboldtsnee 8 hours agorootparentNo, they own a business they work at. Just like workers co-ops. In many ways that&#x27;s the ideal. reply imperfectcats 5 hours agorootparentUntil they ant to retire. Then what do you do?If you are happy to walk away and hand the \"business they work at\" for free to someone, flame on. Thing is, unless that is family, who would you give it to and why? reply ahahahahah 12 hours agorootparentprevI feel like that&#x27;s simple reading comprehension. The \"unfortunately\" isn&#x27;t like in the context of whether that fact is good or bad in general, but specifically in the context of whether or not it was a good business to buy. reply goodbyesf 9 hours agorootparentprev> It means the business can&#x27;t practically be soldWhat? Of course it can be sold. To someone else who wants to run a mom-and-pop operation.> might as well just go get a job for someone else.Or be your own boss?> That ultimately means that the business itself isn&#x27;t worth anythingAre you serious?> so when the owners decide they don&#x27;t want to manage it anymore, it&#x27;ll likely just have to fold.Or they sell it to another person who wants to run the business?You act like the only option is as passive investment. reply Vt71fcAqt7 8 hours agorootparent>Of course it can be sold. To someone else who wants to run a mom-and-pop operation.It&#x27;s a small market of people who are just rich enough to buy that business, don&#x27;t have another job already and don&#x27;t mind working that business. And that market is already filled pretty well by franchises. It&#x27;s not impossible to sell the business obviously but if they were only making eg. 100k a year there is really no market for buyers for that because if you need to take out a big loan to buy it you might make nothing and if you can afford it you have better options. It&#x27;s more common in these cases from my anecdotal experience, especially for something like a restaurant, that whoever buys it will restart the business completely with a new sign, menu, ect. after the last one shuts down. This is especially true in big cities where the owners usually lease the shop. What do they really have? Why would I buy a sign and menu from them for x hundred thousand dollars if I have another option? reply mgh95 13 hours agorootparentprevThe individuals founding the bakery took a risk in firm formation (incorporation, initial lease collateral, equipment loans which may have been cosigned by the owners as individuals, etc.). The rewards received were purely salary based -- exactly what a worker receives. The net result is that while the owners of the business received a return (a good salary), this return is not a capital return based upon the risk absorbed as founding which may have been greater. reply innagadadavida 12 hours agorootparentDo you think the margins were low because they just used higher quality ingredients and did not doing any food management? If so the next owner can optimize these inefficiencies and extract value from the brand value. reply Humboldtsnee 12 hours agorootparentIs using a higher quality ingredient an inefficiency? It seems like it produces a different product. reply transcriptase 10 hours agorootparentI mean…gestures broadly at every company large enough to hire MBAs reply mediaman 10 hours agorootparentprevUsually it’s more structural than that. Too much competition, too few customers, too little scale to afford the type of talent that can optimize inefficiencies. There is a reason these small localized businesses tend not to produce outsized profits. reply SaintGhurka 13 hours agorootparentprevSerious question - If all the profits go to the workers&#x27; salaries and nothing is left to pass through to the owner, who would have an incentive to guarantee the workers&#x27; salaries if revenue falls short? Who would be willing to risk capital to get the company through unexpected hard times? Should the workers chip in to keep it going? reply Humboldtsnee 12 hours agorootparentI mean, the owner is a worker. These are not mutually exclusive roles.If times are tough, then the owners probably take a smaller salary for their labor, or the workers can decide how to cut costs together through salaries, benefits, reducing costs of manufacturing, or whatever. reply idopmstuff 11 hours agorootparentThe owner is a worker AND an investor. If they&#x27;re actively working in the business, they deserve to be paid for that labor. Regardless of whether they&#x27;re actively working in the business, they deserve to be rewarded for taking the extremely risky step of creating a small business, which in turn created all the jobs for those workers. reply Guvante 12 hours agorootparentprevYou imply a hypothetical investor would do that.Typically they are only interested in injecting money for growth.If there is insufficient profit to satisfy their cost of capital expectations they sell off or fire until it does.Our growth model doesn&#x27;t support resilient businesses only gambling at phenomenal amounts. reply soared 19 hours agoprevThis is not a fintech company, it’s a holding company. Selling their financial products they said is a secondary new revenue stream - their primary revenue stream is from the companies they acquire, which for some reason decreases over time as they sell back stock to employees.Maybe they’ve identified that employees in small business will overpay for stock in the company they work at. Then this is just a financial move to own that stock and sell it overvalued to employees? reply wombat-man 19 hours agoparentWell, it sounds like the long term strategy is to develop business software solutions that work perfectly for their various arms, that they can then take external and pitch to other small businesses. reply esjeon 17 hours agoparentprevIt&#x27;s like real estate development. You buy a land, develop it, and sell it at a higher price.Same here. You buy a small business, improve it by adapting your solution, and sell it back at higher price.Of course, the \"improve\"-ment part better be real, but it sounds like a win-win business model if properly conducted. reply gremlinsinc 8 hours agorootparentit sounds like it square bought food truck businesses that weren&#x27;t using square pos and basically installed square pos and resold the business with contract stating they couldn&#x27;t switch pos providers....I mean it&#x27;s a way to guarantee vendor lockin but it&#x27;s also risky. I do hope they follow through with the 80 percent ESO plan later on, as I&#x27;d love to see that the norm not the exception in the next generation. reply SoftTalker 10 hours agoparentprevIt’s generally a bad idea to buy stock in the business where where you work. It’s the opposite of diversification. If it’s equity compensation OK, but you should diversify that into other investments as soon as you can. reply htrp 18 hours agoprev> Certainly, it’s among the more unique fintech models this reporter can recall.Its not a fintech business model.This is more like a McDonalds franchise model where they are extracting value by forcing stores to buy amounts all mannner of services from Food to Ordering Automation along with paying a percentage of gross sales back to Corporate.Except in this case TeamShares won&#x27;t even provide for good marketing support or branding to drive traffic. reply skeeter2020 18 hours agoparentMcDonalds always had the implicit promise that you&#x27;ll work hard, make us very rich but you&#x27;ll also be \"small town rich\" too. TeamShares doesn&#x27;t even pretend to deliver on the last part. reply ochoseis 20 hours agoprevThere’s a whole world of folks who do this, with acquisitions and sophistication ranging from really small businesses[0] to ones in the range the article discusses[1]. It does seem like a numbers game where it makes sense to pool the risk.[0]: https:&#x2F;&#x2F;www.amazon.com&#x2F;Buy-Then-Build-Acquisition-Entreprene...[0]: https:&#x2F;&#x2F;www.amazon.com&#x2F;gp&#x2F;aw&#x2F;d&#x2F;B01KP33K4Y reply jeremyjh 19 hours agoparentThey aren&#x27;t buying them for the business upside, but to force the business to buy its own ecosystem of Fintech products. reply notahacker 19 hours agorootparentDoesn&#x27;t make any sense to do that without a financial upside as well, as the businesses are unlikely to spend more their entire valuation on fintech products (and 84 mom and pop shops owned by the VC signing up isn&#x27;t much of an illusion of growth to boost the fintech companies&#x27; valuation either) reply ralferoo 19 hours agorootparentThe financial upside is that they also own 85% of the company shares, so get 85% of the profits, reducing to 20% over 20 years by selling shares back to the employees. Selling here implies they&#x27;ll also make profit from that too. reply sangnoir 17 hours agorootparentEmployees who&#x27;ll likely withstand lower than market rate wages and&#x2F;or poor conditions because of sunk-cost fallacy. Sucking up profits from both the captive businesses using software licensing, revenue, and employees (as they buy shares from the startup) is well-thought-out evil genius, OR a path towards fully automated luxury worker-led communism, but I&#x27;m guessing it&#x27;s the former in the guise of the latter. reply smeej 14 hours agorootparentprevThe article said diluting, not selling, so I don&#x27;t think it does apply here that they&#x27;ll profit from that process. reply robotresearcher 14 hours agorootparentThe fine article says:\"we sell our stock back over time to the companies until it becomes 80% employee owned\" reply jeremyjh 9 hours agorootparentThat’s how it looks on the books but it has to be part of compensation - it’s booked that way in the GL with the company paying for the shares as incentive out of earnings. Employees in these kinds of business just aren’t going to be buying stock in the company they work for. reply robotresearcher 4 hours agorootparentRight, but as the small company is on the hook to buy the shares from the parent company, before passing them to the employees as comp, the parent company gets cash for their stake. replypdonis 13 hours agorootparentprev> the businesses are unlikely to spend more their entire valuation on fintech productsIf the fintech company has a controlling interest in the business (more than 50% of the share ownership), what&#x27;s to stop them? reply foobiekr 16 hours agorootparentprevJuicing growth for a pump and dump scheme probably. reply monkeydust 17 hours agorootparentprevAre they forced? You would imagine contractual in someway they might be but should the owners be able to tender out and shop around ? reply wombat-man 18 hours agorootparentprev\"force\" sounds so dark. Small businesses use all kinds of solutions to run themselves. They want to end up with a product that they can pitch to external businesses, it&#x27;s more like they are using these acquired businesses as market research and testing. reply version_five 18 hours agoparentprevI don&#x27;t have a link handy but I know this is big for the veterinary and dentistry industries. Companies are buying up all the clinics. reply pxue 17 hours agorootparentcalled consolidators I believe. It&#x27;s pretty genius.Entire model is about buying dental practices with cash, profit share with the dentists and then do all back-office work with economy of scale.Pocket any efficiency gains and reinvest in more dentists, rinse and repeat.I think this model might be a huge opportunity in Mexico. reply klipt 16 hours agorootparentBad for the patients though because \"efficiency gains\" usually translates to \"give patients expensive treatment they don&#x27;t actually need\" reply edmundsauto 15 hours agorootparentLess bad if you add some nuance. Some dental procedures are “you might not need this right now” or cosmetic. There are bad incentives that can be at play for sure - but procedures aren’t a clear line of “necessary”&#x2F;“not necessary”. reply mdorazio 14 hours agorootparentMany of them are, though. I suggest you read this article: https:&#x2F;&#x2F;www.rd.com&#x2F;article&#x2F;how-honest-are-dentists&#x2F; reply mh- 9 hours agorootparentThanks for sharing that. Good read. Everyone who reads it should know upfront though, that the article was published in 1997. I didn&#x27;t notice until the end.So multiply all of those prices by >2.5x to account for the inflation of costs. replyhtrp 18 hours agorootparentprevthats usually PE backed reply aaronax 17 hours agoparentprevSafe Harbor I think buys marinas as owners age out of them. A marina tends to start out small and grow over time under a single owner, until they are successful yet unattractive for any one other individual to plunk down $x million. So they get bought up by the big org and it gets harder to find reasonably priced mom and pop marinas. reply siliconc0w 18 hours agoprevSeems like sorta a middle ground between a bs PE buyout, a roll-up, and a holding company. I think they&#x27;re hoping the fintech fairy dust is going to give them tech multiples. reply _spduchamp 17 hours agoprevAging business owners should look at Employee Owned Trusts. They exist in the US and UK with slightly different structures. Canada will have some legislation around EOTs sometime soon. reply dsr_ 18 hours agoprevThe one really negative bit:\"And so we recruit people from some really great companies — McKinsey, USAA, Tesla and Amazon — and train them to run these small businesses.\" reply sangnoir 17 hours agoparent> The one really negative bitIt being a negative depends on which end of the table you sit. I agree it&#x27;s telling on the kind of leadership they expect, given the reputation of the environments and people who work at those organizations. reply gunapologist99 18 hours agoparentprevThat might not be a bad thing.. but it could be. reply screwturner68 13 hours agorootparentIt just assumes that only people that work for companies like Amazon and Tesla have the pedigree to manage a company.I look at it like how every politician either elected or appointed seems to have gone to one of 10 well known universities -you know Harvard, Yale, Stanford..etc. It&#x27;s not about what they know or what they want to do as much as the fact that they are all in the same club. I&#x27;ve always said that being a CEO is just a game of playing follow the leader -one CEO cuts their 401K, they all cut their 401K, one CEO switches to \"unlimited vacation\" they all switch to \"unlimited vacation\". It&#x27;s not a surprise that these companies all act the same, all the leaders all went to the same schools with professions that went to the same schools. They&#x27;ve all bee taught to think alike, they aren&#x27;t disruptive-it&#x27;s just group think.When was the last time you heard of a CEO that went to community college and some shitty state school -even if they founded the company they are quickly replaced by a person more suited to be the CEO- someone for a Ivy school&#x2F;FAANG once they IPO. reply iancmceachern 16 hours agoprevIt&#x27;s like amway or other MLMs but instead of locking them in with proprietary products to sell, they&#x27;re locked into proprietary ways of doing business.In a way, it&#x27;s a lot like a franchise model. reply tempusalaria 20 hours agoprevSounds like an easy and cheap way to bump up revenue and metrics for next raise.Prob buying at 1x revenue and selling stock to investors at 100x revenue reply mariodiana 20 hours agoprevIt&#x27;s difficult to develop products without understanding customer needs, and it&#x27;s difficult to understand customer needs without a variety of customers. That&#x27;s the problem their business model is it solving. reply zdw 20 hours agoparentThis sounds like they&#x27;re going to be collecting a large amount of data from a huge variety of small businesses that all operate in different ways and have very different clientele.I wonder how practically useful all of this data collection is going to be, and whether doing it will be accurate and result in insight.Learning about small niches where modest profit can be made (which is where many small businesses tend to fit, IMO) is not the typical&#x2F;theoretical \"scale to the heavens\" startup plan, but if just getting ideas is the goal... good luck? reply gopher_space 13 hours agorootparentThe people doing real estate forecasts want actual numbers to crunch and would enumerate the fleas on your dog and rank sort its name on the date of sale if you let them. They think confounding variables are for quitters. reply birdyrooster 18 hours agorootparentprevIt&#x27;s a boondoggle. reply wand3r 18 hours agoprevThis sounds a lot like the Search Fund model except at scale. Typically in a search fund an entrepreneur raises a small pool of capital for operations and search for a traditional low tech company to acquire where they can optimize operations typically leaning on their MBA education. When a target is found, they make a capital call to the investors and buy out the company.This basically seems like a search fund run at scale. Its actually a cool concept that I suspect is quite profitable. From the article though I don&#x27;t really know if there is a tech component. It&#x27;s more like a pure-play private equity company, e.g. finance. That said, there are a lot of interesting opportunities here and probably limited competition. reply JakeAl 8 hours agoprevSounds like these are businesses with aging owners with no succession plans that can also be modernized. They are sustainable and healthy but will run out of steam at some point so they buy them, modernize them, and ultimately sell them back t the employees who will own 80% of the stock after 20 years. Not that uncommon of a business model except the stock ownership part. Typically you see business flippers do this and sell them after 3-5 years, but much like an incubator they leverage the businesses they buy so they also use each others services and lift them all up while keeping the employees employed. reply silisili 13 hours agoprev> small businesses represent 99.7% of U.S. employer firms and 64% of private-sector jobsIs this accurate? Those percentages just -feel- way too high at first glance. Is it counting every gig worker and etsy seller as an independent small business or some other trickery, or were my assumptions just that far off? reply pdonis 13 hours agoparent> Those percentages just -feel- way too high at first glanceNot really, no. Large corporations have lots of employees per corporation, but there just aren&#x27;t that many of them, so the total number of jobs they represent is still a minority of all jobs, and the fraction of firms they represent will indeed be tiny. reply silisili 13 hours agorootparentSeems my issue was with the definition of small business. Found this link helpful in explaining what all qualifies in this number, and it&#x27;s quite more than I expected...https:&#x2F;&#x2F;www.shopify.com&#x2F;blog&#x2F;what-is-considered-a-small-busi... reply MattGaiser 13 hours agoparentprevI would bet every individual corp is counted as an employer, so under this very few Wendy’s staff count as working for Wendy’s and rather for the franchise business. reply TimPC 19 hours agoprevSo is the idea that they acquire the company for debt they place in the company and then they offer a complete suite of fintech products (including servicing that debt) to each of the companies they acquire? They aren’t too worried about giving away much of the company because with the debt inside the company the valuation is near zero? But if the employees can successfully grow the company it represents a decent return since they’ll be able to share 80% equity. reply 52-6F-62 19 hours agoprevWhy do they call this fintech?Isn’t this essentially a reworked trust? reply op00to 19 hours agoparentBecause the idea is to sell fintech products to the acquired businesses. reply bornfreddy 19 hours agorootparentThat sounds like a cherry on top to me. I mean, considering the cost of the business that they paid for, fintech expenses shiuld be negligible. Otherwise it sounds like a great business - buy successful businesses without successors, shape them up, motivate employees and reap the benefits, long term. Win-win-win for everyone involved and society too. reply foobarian 17 hours agorootparentIt&#x27;s like any acquisition, you don&#x27;t let the acquired shop keep running workday if the main company is running base camp. It makes sense to consolidate. reply asu_thomas 17 hours agorootparentOnce they lose control by selling 80% to the employees, they no longer have that power though, right? reply sangnoir 17 hours agorootparentprev> fintech expenses shiuld be negligibleAnd that&#x27;s the rub - it&#x27;d be more profitable to thr mothership if the fintech expenses were not negligible over 20 years. reply bornfreddy 16 hours agorootparentDo you think so? Their profits are their mothership&#x27;s profits, so any expenses are, too. It&#x27;s like putting from one wallet to another and harming the businesses (assuming their fintech solution is not optimal) along the way. I don&#x27;t get it, but from the article I don&#x27;t think this is what is happening anyway. It wouldn&#x27;t make sense either. reply sangnoir 13 hours agorootparent> It&#x27;s like putting from one wallet to another and harming the businessesSort of, but they&#x27;ll be pulling money from a joint wallet that&#x27;s 80% owned by other people. I expect even if the workers gain majority ownership, they will have no control - so the fintech service contracts will likely outlive the businesses. replyKiro 19 hours agoparentprevThe irony that \"reworked trust\" is even more of a nonsense word. reply 52-6F-62 10 hours agorootparentIndeed… reply skeeter2020 18 hours agoparentprevbecause the latter has a single digit multiplier and the former double or triple digit. reply maxerickson 19 hours agoprevSo is their plan that the businesses will be employee owned but not employee controlled, thus locking nice rates for their services? reply kdamica 20 hours agoprevOpenStore is doing something similar for small e-commerce businesses: https:&#x2F;&#x2F;open.store&#x2F; reply hiatus 17 hours agoprevThis reads very much like a franchising arrangement, except instead of goods you pay for back office services. Even if the acquirer&#x27;s products would succeed on the open market, a captive audience of guaranteed business seems like it might align the incentives of the parent company to _not_ bleed their acquisition dry. reply kristopolous 19 hours agoprevSocialists like Richard Wolff have been advocating for a similar thing for a while ... Some kind of ESOP continuity plan.Is that a business strategy now? Take some socialist idea and repackage it as a for profit one?It&#x27;s probably been a business play for a long time and I just never realized it reply brnaftr361 17 hours agoparentI think with proper terms this would be a good launchpad for tested and tried businesses to transition into worker owned cooperatives, which I think would be a noble endeavor.As it&#x27;s set up currently it reads more or less like a tribute system, which is pretty trashy - it draws a line in the sand where they&#x27;re effectively minimizing risk to themselves and slowly foisting responsibility onto others in exchange for a quasipermanent deal. I&#x27;m curious as to how the \"ownership\" works, as well, I&#x27;m sure there are caveats written in that secure the stake of Teamshares. reply billjings 18 hours agoprevWow:> The plan instead is to generate revenue from a growing array of fintech products that it sells to the businesses it buys.If these products were any good, couldn&#x27;t they make money with them on the open market? The only thing that owning gives you is the ability to force them to buy from the company store, so to speak.This isn&#x27;t tech. This is pure capitalist financial engineering: extracting money from people who actually do real work for real paying customers. reply 55555 18 hours agoprevThis is pretty strange. The real business model could probably be described in just a few blunt sentences, but without that happening we&#x27;re left to speculate. reply ajkjk 15 hours agoprevOne thing&#x27;s for sure: there&#x27;s no possible way this makes the world a better place to live in. reply burcs 15 hours agoparentWhy would you think that? There was no succession plan for these businesses, there was a high potential for them to shutter and the jobs would dry up with them.Honestly, this feels like one of the better&#x2F;more practical uses of venture capital that I&#x27;ve seen in a while. reply ajkjk 15 hours agorootparentBecause the businesses are now owned by a profit-maximizing anonymous fintech company. If you can&#x27;t imagine any of the thousand ways that ends up sucking for everybody and draining life out of the world it&#x27;s not likely that anything I say could convince you. reply smeej 14 hours agorootparent85% owned out of the gate, decreasing to 20% over 20 years.Just because you can&#x27;t imagine a way it could be good doesn&#x27;t mean they&#x27;re evil. reply screwturner68 13 hours agorootparentprevShow me a merger that has been good for the customer and good for the employee. I&#x27;ll wait. reply numair 19 hours agoprevProtip: If someone says they are trying to be like Berkshire Hathaway, and their business plan doesn’t include a strategy for cornering some segment of the insurance market, they do not understand and will not become like Berkshire Hathaway. reply jononomo 17 hours agoparentI would even go so far as to say that if someone says they are trying to be like Boeing, but their business does not involve manufacturing jumbo jets, they do not understand and will not become like Boeing. reply Dalewyn 20 hours agoprevhttps:&#x2F;&#x2F;archive.is&#x2F;P1cUyArchive link because clickbait can die in a fire. reply theunixbeard 17 hours agoprevLooks like PE and venture-backed tech have a bad rep these days given how cynical the comment section is...It seems the core problem at hand attempting to be solved is baby boomer small business owners retiring and having no one to buy their business (or pass down to who actually wants to run it)...That seems like a worthy problem to tackle. Definitely will keep an eye on this company over the years to see if the model pans out or not. reply monero-xmr 19 hours agoprevPrivate equity rolling up small businesses is extremely common for decades. There is even a major plot in the 2000s HBO show “Six Feet Under” of the evil PE guys buying up all the mom and pop funeral homes to corporatize it. Nothing new or innovative about this. reply smcameron 18 hours agoparentService Corporation International. I used to know a guy that worked for them back in the early &#x27;90s doing AS&#x2F;400 stuff, I think. reply rmoriz 17 hours agoprevSomehow reminds me of Constellation Software. reply yieldcrv 14 hours agoprev> just 15% or so of small business owners pass along their company to a family member, with many others simply closing up shop at some point.Businesses shouldn’t be immortal so it’s fine. People should celebrate closing as most owners are indifferent. reply birdyrooster 18 hours agoprevThis idea is potentially so terrible I almost feel bad for the founders -- if it also wasn&#x27;t scummy. The crux of their problem is that these businesses have a very finite lifetime regardless of the succession plan. The succession plan is completely secondary, the bigger question is the viability of the business plan, which for many small businesses, is not robust. TeamShares is merely acquiring customers until they abandon after the business plan is replaced and changes the quality or price of service.Of course business owners who are selling to them are happy because they can buy their business back for less when TeamShares goes tits up. TeamShares is probably going to find this scheme will only work if the businesses being acquired are very homogeneous. Trying to scale something which inherently cannot or should not scale is kinda silly. reply jancsika 19 hours agoprevThis is brilliant.Instead of saving on labor costs by pretending your employees are contractors like Uber and friends, they go in the opposite direction. You&#x27;re not a contractor, or even an employee, but an owner.Just imagine how big your milkshake will be once you all own 80% of the business! Admittedly, a business where this company has slurped out most of the value and saddled you with various software license fees or whatever in perpetuity. But a business nonetheless.And now when the business goes belly up and these owners are destitute, the HN logic applies-- hey man, most businesses fail. So why not just learn some python and code up some nice fintech that extracts value from other rubes? reply jancsika 18 hours agoparentReplying to my own comment because I just can&#x27;t get over how ingenious this is.On HN we&#x27;re used to FOSS devs acting quickly when, say, a proposed or implemented license change turns project X into project X&#x27;. Upon reading the diff, they&#x27;ll fork from X and continue on with a new org, and X&#x27; dies on the vine. We&#x27;ve seen it recently on HN.Employees of a mom and pops have specialized skills either in the frontend or backend of the business but typically only a basic idea of the fundamental business model. If they were to become owners in X it would take them at least a year and probably longer to learn the ins and out. E.g., how a change to even a few vendors can have a large effect on the bottom line. If they think they are getting X but instead get X&#x27;, they won&#x27;t know for awhile. In fact, if were talking about succession then the owner may be gone and they&#x27;ll never know.Perhaps I&#x27;m being cynical and fintech really is here to help the little guy. But something tells me that&#x27;s unlikely. reply lr4444lr 16 hours agorootparentI still can&#x27;t tell whether you&#x27;re being cynical or not. These businesses are mostly going to just shutter if PE doesn&#x27;t take over. The ones left to a family member aren&#x27;t necessarily going to do well for that succession either: that bequest can be an act of love more than business smarts. Furthermore, just because there may be important subtleties about which vendors to use, branding, and service processes that are vital to how things work, it does not mean that the prior owners were at all savvy about the nuts and bolts of modern financial products, and could have really been held back by traditional banks preying on that ignorance and ensnaring them in less than ideal solutions.The important cog in this wheel is the one you haven&#x27;t touched on, namely, that president Teamshares installs - wish they&#x27;d explain more about that. Teamshares&#x27; investors aren&#x27;t stupid. They know very well the risk on their money if the company comes in like a bull in a china shop, quickly destroying the businesses it buys. There aren&#x27;t going to be consolidation options and economies of scale like you see with medical practices - each of these mom &#x27;n pop shops are somewhat special snowflakes. reply busterarm 16 hours agorootparentprevBeing an owner in a business is a typical way to route around labor laws completely.If you&#x27;re a restaurant or retailer that needs your staff to work 14 hour days 7 days a week, giving ownership is a fairly common scheme to CYA against future lawsuits. The ownership shares are usually miserly and forced-transferrable upon leaving.Not saying that&#x27;s what&#x27;s happening here, but it could be. reply lotsofpulp 14 hours agorootparentLabor laws are for employer-employee relationships. You cannot simply “give” some of your employees shares and then disregard labor laws.If someone wants to work 14 hour days 7 days a week so that their shares are worth more, that is their choice. reply busterarm 2 hours agorootparentThey never get classified as employees. They start as owners to begin with. This is what cults like Twelve Tribes do with the Yellow Deli in Boulder, CO. The whole place operates on unpaid labor because they&#x27;re all \"owners\". reply Spooky23 14 hours agorootparentprevThe brilliance depends on whether it’s a scaled version of a Berkshire Hathaway like business, or some sort of reverse franchise. It sounds to me like the latter - a scheme to create captive customers for preferred source vendors who are close to the beneficial owners. This also sounds like medical consolidators like Schweiger dermatology who soak up independent dermatology practices. Similar models exist for dentists and attorneys as well.I’m cynical because Buffet’s goal was very clear - he needs to generate cash flow forever to make more money. A venture capital entity has a different vision of success, which I can’t see being aligned with the “owners” of these companies. reply 3np 17 hours agorootparentprevThem setting terms for insurance and likely de-facto cotrolling all the firms&#x27; financial capabilities through their mandated fintech services surely helps hedging the risk, too. reply grensley 18 hours agoparentprevIt feels like marketing sleight-of-hand. Like \"you own the house, but you have to rent the walls from us\". reply dylan604 17 hours agorootparentOr the real world situation that happens to people, you own the domicile, but we own the land it is on reply jimt1234 14 hours agorootparentprevThat&#x27;s my feeling, too. It reminds me of a scene in \"The Founder\", the movie about McDonalds: \"You&#x27;re not in the burger business. You&#x27;re in the real estate business.\" reply robertlagrant 18 hours agoparentprev> the HN logic applies-- hey man, most businesses fail. So why not just learn some python and code up some nice fintech that extracts value from other rubes?I haven&#x27;t really seen this here. Is there any need to perpetuate such silly stereotypes? reply googlryas 18 hours agorootparentRight, I would more ascribe that viewpoint to some journos on Twitter. I think if that viewpoint is referenced on HN, it is done so derisively. reply robertlagrant 18 hours agorootparentIt was a big thing ten years ago - why not learn to code if your job has gone overseas? At the point Mayor Bloomberg tweeted something about learning to code, it seems Jeff Atwood felt it was time to weigh in[0].[0] https:&#x2F;&#x2F;blog.codinghorror.com&#x2F;please-dont-learn-to-code reply borski 17 hours agorootparentI think the point is that it wasn’t big on HN. reply robertlagrant 17 hours agorootparentI was saying it wasn&#x27;t just some \"journos on Twitter\". reply borski 16 hours agorootparentFair. replyMatthiasPortzel 17 hours agoparentprevIt’s a whole 6th viral growth method. Buy companies and force them to use your product before spinning them off.(Emmet Shear’s 5 viral growth methods: https:&#x2F;&#x2F;twitter.com&#x2F;eshear&#x2F;status&#x2F;1402449655208632321) reply MatthiasPortzel 11 hours agorootparentPast the window where I can edit the comment, but Emmett (like Matthias) has two T’s. reply adrianmonk 15 hours agoparentprev> saddled you with various software license fees or whatever in perpetuityAre they necessarily forced into it for perpetuity? Once they transition to 80% employee ownership (or 51%), don&#x27;t the employee-owners decide whether to continue? Unless there&#x27;s some kind of non-voting ownership stake or contract that never expires or something.Plus, 20 years is the timeline to transition to employee ownership. So for the first 10 years, if the acquired business pays software license fees, the parent company is mostly paying itself, which isn&#x27;t revenue. More importantly, that means whatever tech stuff they supply to the acquired companies needs to actually pull its weight.It seems more likely they just want to keep proven businesses going so they can tap into that established revenue year after year. Giving ownership to the employees probably helps with retention and continuity so that the company doesn&#x27;t fail after being sold. The corner pizza shop&#x27;s customers still see familiar faces, the plumbing company&#x27;s customers still recommend them to neighbors, etc. People don&#x27;t say, \"It used to be good, but it&#x27;s not the same since it was bought.\" The point of handing over 80% is keeping the goose healthy to keep laying golden eggs.Yes, being a supplier to these companies you own 20% of is some nice gravy. But you also want the revenue (and expansion), so you really can&#x27;t bleed them dry. reply AlbertCory 17 hours agoparentprevUnfortunately, most mom-and-pop businesses are around because they&#x27;ve built a clientele, hired good employees, and mastered the basic economics in their local economy, which is all they need. Sophisticated fintech for them is just a frippery, as is big-time professional management. reply edmundsauto 15 hours agorootparentI would bet the weaknesses of most mom and pops, and where professional management excels, is in the efficiency and vendor relationships. Lots of small mom and pop places pay exorbitant amounts for things like credit card processing, cash management and banking, tech, inventory management, etc.If team shares can be a good partner to complement the strengths of the small business owners, they can increase the profitability significantly. By leaving the community element in place, theoretically it could be the best of both worlds. reply AlbertCory 13 hours agorootparent\"theoretically\" doing a lot of work there.Also: \"Lots of small mom and pop places pay exorbitant amounts for things like credit card processing, cash management and banking, tech, inventory management, etc.\" is totally unsubstantiated. Like they&#x27;re too stupid to know what they&#x27;re doing?We&#x27;ll have no trouble at all finding stories of old businesses that changed ownership to a soulless group of MBA&#x27;s, the customers heard about it, complained that it wasn&#x27;t the same anymore, and quit coming. I doubt you can find many stories going the other direction. reply edmundsauto 11 hours agorootparentEdit, never mind, prefer not to engage here. reply bryanrasmussen 15 hours agoparentprev>Admittedly, a business where this company has slurped out most of the value and saddled you with various software license fees or whatever in perpetuity. But a business nonetheless.didn&#x27;t I see an episode of The Sopranos where this was the plot, albeit in mafia dress. reply 99_00 15 hours agoparentprevWhat&#x27;s the difference between this and a franchise? reply brookst 19 hours agoprevAny headline that uses “quietly”, “finally”, or “openly” is a signal of a bad faith article.And headlines using “This company” rather than naming the company are clickbait.Funny that TechCrunch wants to cast aspersions using cheap devices like that. reply tgv 18 hours agoparentYou need a bit more substance than association by guilt (and not even a strong association) to criticize an article or a headline. My reading of e.g. \"quietly\" is that either they&#x27;re claiming a scoop, or they&#x27;re critical of the acquisition, not of bad faith. reply brookst 18 hours agorootparent“Quietly” is a way to imply wrongdoing in something purporting to be a news article. Which is funny because you can use “openly” the same way, and it seems to me that every action can be characterized as either quiet or open.That’s why it’s bad faith. It’s a cheap shot that purely injects a negative feeling without actually expressing an opinion.“Teamshares buys mom and pops to lock them in as customers” or “Teamshares screws small businesses to make a buck” would be honest, good faith headlines. Innuendo is never good faith. reply robertlagrant 18 hours agorootparentprevWhat is \"association by guilt\"? reply actionfromafar 15 hours agorootparentI love this \"Association by Guilt\", great lo-fi post-punk band. reply _0ffh 16 hours agorootparentprevMaybe they mixed up \"guilt by association\". reply robertlagrant 15 hours agorootparentPossibly, but then I would ask how that&#x27;s relevant as well! reply tgv 13 hours agorootparentI did mean guilt by association. The comment&#x27;s author assumes the articles uses cheap devices based on an association the word \"quietly\" with bad faith arguments. replyjamilton 17 hours agoparentprev\"This venture-backed started\" is reasonable, saying \"Teamshares\" instead isn&#x27;t actually informative because (presumably) no one has heard of them. reply lolinder 17 hours agorootparentThe headline would feel less like clickbait if it omitted \"this\": \"Venture-backed startup has...\". The word \"this\" in a headline has become strongly associated with low-effort articles that try to draw you in by being simultaneously provocative and non-informative. reply dcow 14 hours agorootparentClick-bait works, sad as it may be… reply ford 16 hours agoparentprevThere&#x27;s very little incentive to write headlines that aren&#x27;t clickbait reply htrp 18 hours agoparentprevNot sure its in bad faith. It literally reads like a PR placed puff piece reply Nicholas_C 18 hours agoparentprevA browser add in that replaces article titles with a factual summary based on the content of the articles would be pretty neat. reply sroussey 16 hours agorootparentI thought there was one already reply brookst 17 hours agorootparentprevLove it. reply bwanab 17 hours agoparentprevI agree. I&#x27;ve started avoiding almost any headline with the phrase \"this X ...\" where you&#x27;ve got to click to see what X is. Almost invariably, the headline could have easily specified what X was but then you might know you don&#x27;t have any interest. reply 99_00 15 hours agoparentprevThanks for sharing. I find signals like this very useful. reply dbingham 14 hours agoprev [–] I understand the cynical takes and it&#x27;s totally fair to be wary. We&#x27;re all used to seeing startups where the only goal is to make money, and when they&#x27;re venture backed, the goal is to make a _ton_ of money - externalities be damned. If that&#x27;s the case here, then the cynical takes are logical.But it is possible (just possible) that there&#x27;s something else going on here.It&#x27;s possible that the founders genuinely are dedicated to increasing the prevalence of employee owned and governed businesses. And that they&#x27;ve found social impact investors aligned with that mission. In that world, they aren&#x27;t looking for astronomical returns, just modest returns and enough revenue to keep going.If you assume that&#x27;s what is happening here then a lot of these decisions make sense and don&#x27;t look so ominous.Employee owned businesses often struggle to get financing and insurance from traditional banks and insurers. Because those companies don&#x27;t know what to make of them. So creating financing and insurance products allows Teamshares to provide those services to businesses that would otherwise struggle to get them. (And if they&#x27;re doing that - why not offer them to others as well?) The gradual increase in ownership is how employee buyouts often go. And retaining the 20% ownership stake also makes sense - it&#x27;s a pay it forward thing, allowing Teamshares to continue to help businesses make the transition to employee owned.If you assume it&#x27;s on the level - that the founders and investors are genuinely interested in helping owners sell their small businesses to their employees when they retire - and that they&#x27;re genuinely dedicated to increasing the prevalence of employee ownership - then this is _brilliant_ and _incredible_ and to be lauded.It is also possible the whole thing is a scheme to screw the employees and extract a ton of wealth from them for venture capital. Only time will tell.Personally, I&#x27;m going to choose to be optimistic and hopeful for the moment. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Teamshares, a New York-based startup, specializes in acquiring small businesses that lack succession plans and offering employee ownership.",
      "The company has successfully acquired 84 businesses and generates revenue by selling fintech products.",
      "Teamshares has raised an impressive $245 million in venture capital and intends to replace existing vendors while expanding its product offerings."
    ],
    "commentSummary": [
      "Start-up TeamShares has acquired more than 80 small businesses and transformed them into worker-owned cooperatives.",
      "The aim of this unique business model is to provide financial security for employees and a path to ownership.",
      "However, there are concerns about the long-term viability of these businesses and doubts about TeamShares' focus on selling fintech products rather than improving business profitability."
    ],
    "points": 215,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1693053438
  },
  {
    "id": 37274052,
    "title": "n8n.io - A powerful workflow automation tool",
    "originLink": "https://n8n.io",
    "originBody": "Features Use cases Docs Community Embed Pricing Sign in Get started Workflow automation for technical people Build complex automations 10x faster, without fighting APIs Your days spent slogging through a spaghetti of scripts are over. Use JavaScript when you need flexibility and UI for everything else. Get started for free GitHub ★ 32,833 Full source code available Self host-able 55,385 community members What is n8n? Power to the technical people n8n allows you to build flexible workflows focused on deep data integration. And with sharable templates and a user-friendly UI, the less technical people on your team can collaborate on them too. Unlike other tools, complexity is not a limitation. So you can build whatever you want — without stressing over budget. Code when you need, no code when you don’t Connect APIs with no code to automate basic tasks. Or write vanilla Javascript when you need to manipulate complex data. Build custom scenarios at speed Integrate with any app Independent instances for each environment Bulk operations Painless debugging Host on your own infrastructure Common use cases This isn’t just a helpful tool – it’s the heart of your business Pump data around your entire tech stack with 350+ native integrations. (Or use custom code to create your own.) From Support, to DevOps, all the way to Sales. Customer integrations SaaS backend prototyping Lead automation CRM customization Optimize engineering resources Save time building customer integrations. Engineer faster POCs. And keep your customer-specific functionality separate from product. All without writing a single line of code. See workflow Boost efficiency Focus on your KPIs, not your APIs Forget error-prone tasks like setting up servers and monitoring APIs for your less tech savvy teams. n8n automates the frustrating work for you. So you can focus your energy on tasks that move the needle. And even your entry-level engineers and interns can become more productive. Get started for free Scalable performance 220 workflow executions per sec on a single instance, and add more instances if required. More info Customizable error handling Share workflows with a click Use 600+ templates to move faster 350+ native integrations Automated API auth How it works Connect. Customize. Conquer. You can choose how to use n8n. Either sign up for the hosted n8n Cloud or self-host with a one-line npm command or Docker installation. Pull in data Set up triggers for app events or specific times to fetch data across your app stack Set up steps Use 220+ app nodes to create, read, and update the valuable data across your apps Save time - every day From monthly syncs to millions of executions, sit back as your workflow does the heavy lifting Why n8n? Because the best tech bends to your will Your apps should adapt to how you work. Not the other way around. Your workflows Your way Full source code available: Audit, tweak, and fork our codebase to suit your needs. Self-hostable: Easily keep your data secure. And ensure compliance with data privacy laws. Embeddable: White label our UI to give your customers access to 220+ native integrations. Build without blowing your budget Other platforms’ per-execution pricing can eat up your budget insanely fast. With n8n, you can self-host for free. Or pay for a package of workflows in the cloud. So you can make your flows as complex as you like — at no extra cost. Resolve 99% of issues in hours, not months You don’t have to wait weeks for someone on your vendor’s team to fix your issue. (If they can fix it at all.) Get access to a 6K-strong forum of n8n engineers and community experts available 24/7 to answer your questions. You can expect same-day responses (almost) every time. n8n for enterprise Scale your company's operations with our advanced on-prem or cloud automation Contact Sales over 387 integrations See all integrations 29,504 Github users ❤ n8n – here’s why JodieM @jodiem Anything is possible with n8n I think @n8n_io Cloud version is great, they are doing amazing stuff and I love that everything is available to look at on Github. Igor Fediczko @igordisco Build complex workflows that other tools can’t do I was a regular integromat user. I got to know the N8N and I say it properly: how it is better to do everything on the N8N! Congratulations on your work, you are a star! Maxim P @maximpoulsen I’ve said it many times. But I’ll say it again. n8n is the GOAT. Anything is possible with n8n. You just need some technical knowledge + imagination. I’m actually looking to start a side project. Just to have an excuse to use n8n more 😅 Robin Tindall @robm Thank you to the n8n community I did the beginners course and promptly took an automation WAY beyond my skill level. Case studies Your apps should adapt to how you work. Not the other way around. Enhancing digital experiences Dropsolid needed to integrate data from different sources and manage integrations for the various apps and services they use. Read more Scraping a multi-page website Learn how uProc replaced time-consuming Python scripts with a n8n workflow. Read more Building a $100K online business Discover how Bordr uses workflow automation to help people relocate to Portugal. Read more See more case studies Stop struggling with your scripts Start creating workflows 10X faster — with n8n Start building for free Automate without limits Features Pricing Press Integrations Affiliate program Careers Workflow library Become an expert Contact Case Studies n8n Enterprise Merch Make vs n8n Zapier vs n8n Blog Impressum & Legal © 2022 n8nAll rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=37274052",
    "commentBody": "n8n.io - A powerful workflow automation toolHacker Newspastloginn8n.io - A powerful workflow automation tool (n8n.io) 209 points by sacrosanct 18 hours ago| hidepastfavorite78 comments vbezhenar 15 hours agoWe&#x27;re using this tool for some of our project. Basically our manager with zero programming skills was able to build a quite complex backend, which uses postgres, some REST APIs. It runs scheduled tasks and webhook-initiated tasks. It was impressive for me.One of the downsides is that we have sporadic errors which we just live with, with retries. Probably will be fixed in the foreseeable future.I, personally, don&#x27;t have interest with this tool, I prefer proper programming stack. However I can suggest this kind of tool for someone with lacking programming skills (however it&#x27;s expected that you understand some SQL, some databases fundamentals, some HTTP fundamentals).We self host it within our kubernetes cluster, it&#x27;s not a worst thing I had to deal with. Of course free version is quite restricted when it comes to user management, etc, can&#x27;t even think about oidc integration. But we&#x27;re cheapos, don&#x27;t have money for software, so better than nothing. reply zmmmmm 9 hours agoparent> I, personally, don&#x27;t have interest with this tool, I prefer proper programming stack. However I can suggest this kind of tool for someone with lacking programming skills (however it&#x27;s expected that you understand some SQL, some databases fundamentals, some HTTP fundamentals).It&#x27;s an interesting dilemma. End users who are directly generating the requirements can do amazing things when empowered by these tools. But they have zero understanding of some of the unreducible complexities that bedevil almost any system that gets beyond a toy level size. Transactions ... error handling... race conditions ... throttling &#x2F; load balancing ... computing costs etc etc.We use Apache Camel for something similar to this and it&#x27;s a full programming stack (mostly JVM based so you have to be in that scene really). You can get diagrams out the other end. It&#x27;s not too bad if you want to do all this programmatically. But the end users have zero mechanism to do anything. I wouldn&#x27;t mind having something that was hybrid and we had a graceful &#x2F; gradual mechanism to let users build simple things and then onramp them to fully engineered solutions. reply rglullis 14 hours agoparentprevThe lack of user management was what killed it for me. I was ready to sell it for management when our Zapier bill was growing to equivalent salary of a FTE support person, but it wouldn&#x27;t work if there was at least no basic separation for accounts. reply sisve 12 hours agorootparentCheck out windmill.dev they have auth including sso in their open source version. Used it to replace zapier for a lot of stuff and quite happy reply debarshri 11 hours agoparentprevWould you pay of an enterprise version of this platform? reply 01acheru 12 hours agoprevThe problem I see in n8n is that a lot of the integrations seem a little half baked. We tried to use it instead of Zapier something less than an year ago:- you have an FTP node, but it doesn&#x27;t work with FTP over TLS- you have an AWS SES node, but cannot attach files to the email- you have a Salesforce node, but it only has very few options availableJust to name a few that I remember now, we were quite disappointed. It is a great software crafted with care, but the integration nodes seem to be built on a hurry to say \"over N integrations available\".Maybe it changed now that it reached 1.0, I don&#x27;t know but they need to invest a bit into it. reply gcanyon 6 hours agoprev\"Interesting\" I think -- \"I wonder if it can parse a PDF?\" I check, and there is an action to parse a PDF. I just want to see how well it does that...Okay, not really, but it has been something like 20-30 minutes, and I&#x27;m still nowhere near being able to test this one action.Can I upload a file manually from my computer? Seems not.Can I read it from Google Drive? There&#x27;s an action for that, but authentication hell took five minutes of my life and did not succeed.Just getting set up took several minutes.So, yeah, it&#x27;s not looking good for me at this point. reply iFire 15 hours agoprevSustainable Use Licensehttps:&#x2F;&#x2F;github.com&#x2F;n8n-io&#x2F;n8n&#x2F;blob&#x2F;master&#x2F;LICENSE.md reply Towaway69 15 hours agoprevHow does this compare to Node-RED? My impression is that Node-RED is more flexible and extendable than n8n but I&#x27;ve hardly used n8n.By the sound of it Node-RED has simpler licensing, its completely open source. reply ChymeraXYZ 10 hours agoparentI am maintaining a fairly complex set of nodered flows, dealing with some long running tasks performed by other tools.When checking n8n the impression was that it&#x27;s like a v2 of NodeRed that learned from what NR did wrong. Lots of tools an capabilities you end up wishing for in NR are built into n8n.For example:* data flow is simplified, no one global \"msg\" var that gets clobbered by every 2nd custom script * you can fairly easily test flows * you can see execution history, including in&#x2F;out data * you can see exacting flows reply cowthulhu 2 hours agoparentprevAre you associated with Node-Red? reply Towaway69 1 hour agorootparentMe? No, I just do a lot work with node-red because I enjoy the visual programming experience.I wonder why programs have to be textual when we have tools that can make them visual and thereby more inclusive. reply BaseballPhysics 16 hours agoprevAnyone know how this compares to Huginn? I&#x27;ve built out some self hosted automation on Huginn and it works great once it&#x27;s set up, but it&#x27;s just a bit janky and difficult to use. And getting initial flows set up can be frustrating as the diagnostics aren&#x27;t always great. reply input_sh 15 hours agoparentI haven&#x27;t tried Huginn in a while, but from my experience n8n can get a bit janky at times as well.I feel like the sweet spot it hits is neither developer- nor newbie-friedly, but somewhere in between where it&#x27;s equally bad for both target groups. Workflows get out of hand very quickly, making me need more blocks than lines of Python I&#x27;d have to write to achieve the same thing. You need to really understand their logic gates to do stuff, and the docs you&#x27;ll be relying on range from not great to very bad, incomplete, or just plain incorrect. You&#x27;ll have to rely on their (Discourse) community forum quite a bit.If you&#x27;re one of those people that are strict about open source definitions (I&#x27;m personally not one of them), then it&#x27;s not open source, as you&#x27;d need the enterprise license to run it in production for commercial purposes. But, to make it worse, you&#x27;ll reach some of those enterprise features in your personal projects as well: global variables, Git version control, bash scripts, custom nodes, workflow history (so that you can revert if you mess something up)... all behind an unobtainable license for personal use.With that out of the way, it is the closest thing to what I want out of such a tool, so I keep on using it despite its flaws. Managing credentials is very easy, you can make custom HTTP requests, sharing and importing workflows is very straightforward, debugging them is easy (most of the time), it&#x27;s easy to self-host using Docker, it supports many of the APIs I want to use that other similar tools don&#x27;t (okay some of the cloud ones do, but they&#x27;re pretty unobtainable .Overall, I&#x27;d say 6&#x2F;10? It&#x27;s good, but it could be so much better. reply cutemonster 5 hours agorootparentYou were describing n8n not Huginn, right?(Just to avoid misunderstandings. \"It\" in \"sweet spot it hits...\" is not crystal clear) reply input_sh 3 hours agorootparentYes, I&#x27;m talking about n8n, sorry for the confusion! reply rubenfiszel 16 hours agoparentprevwindmill.dev is a modern take on Huginn: optimal performance, great DX, scale to any cluster, work with python, typescript, go, bash, and flows that are more powerful.n8n is great because their UX is simple and they have many well-made integrations, including an automatic way of setting up the webhooks in your github account for instance to trigger automation on changes to your repo.Windmill is less about having many integrations, and more about being able to write real code-based workflows, running on your infra and with potentially long-running jobs that you can assign easily to bigger nodes. It&#x27;s a compromise between n8n and temporal for the workflow part.Anyway, n8n was a precursor in many aspects and a great inspiration for all of us building workflow engines. reply c0brac0bra 15 hours agorootparentI&#x27;m loving windmill currently. I&#x27;ve been able to automated all sorts software painful manual stuff with it.For a developer, it seems like a great low code tool with the right flexibility to write whatever script you need. reply robertlagrant 12 hours agorootparentprevNote: previous commenter is a windmill dev, I think. reply tonyhb 16 hours agoparentprevRE. initial flows and diagnostics, I totally feel your pain. Part of the trouble with these systems is that they&#x27;re too different from our average SDLC we have every day:- Write regular code- Test locally- Then deployThis is one of the key aspects we&#x27;re fixing at https:&#x2F;&#x2F;www.inngest.com — you can write regular TS (or Go, or Elixir) code as a function, create simple workflows, test locally, and have your functions automatically triggered by events.I still think there&#x27;s room to go with improving automations here, and it&#x27;s going to be an interesting few years as things develop. reply cpursley 16 hours agorootparentElixir, really? That sounds amazing. So many of these tools are TS or Python only. reply tonyhb 15 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;darwin67&#x2F;ex_inngest. We&#x27;ll officially support this soon — it&#x27;s written by one of our engineering team.The SDKs are lightweight, work in any language (we only support a few right now), and you can live-migrate long running functions across languages at any time. Long running state is automatically transferred across those SDKs.One of our foundational aspects is to make long running state, queues, events really easy, and that means we need to make multi-cloud and multi-lang migrations easy, too. reply thelastbender12 6 hours agorootparentTransferring state across sdks sound very cool, how do you achieve that?With all the workflows as code frameworks (like say, Temporal), this is what I imagine to be a shortcoming. With regular services + state in database implementations, you can query the database separately. While with a temporal workflow, you can&#x27;t cleanly figure out where a particular workflow run is atm since the state is an append only stream of events? reply giovannibonetti 15 hours agorootparentprevFor Elixir, you might be interested in Broadway [1], described in their website as \"Build concurrent and multi-stage data ingestion and data processing pipelines with Elixir.\" It is maintained by Jose Valim&#x27;s consultancy company, so it should be pretty good. I&#x27;m looking forward to using it in a project at work soon.[1] https:&#x2F;&#x2F;elixir-broadway.org&#x2F; reply fnikacevic 15 hours agorootparentprevSorry for the loaded question, but can you share examples of companies using inngest in production and roughly what scale? Your product appears to fill the exact gaps in Supabase&#x27;s current offering. reply tonyhb 15 hours agorootparentYeah, for sure. Individual companies run tens of millions of functions a month across anything as basic as braze-like customer lifecycle emails (https:&#x2F;&#x2F;www.inngest.com&#x2F;blog&#x2F;lifecycle-emails-with-resend) to running complex AI workflows at scale.The basic premise is that you can send Inngest events (for free) then start writing functions hosted in your own API at any time, with local testing, branch deploys, etc. reply iamwil 16 hours agoparentprevWhat do you usually automate? I had some before when I was working with a friend, but now I struggle to find stuff for myself. reply BaseballPhysics 4 hours agorootparentA few things.My favourite is a flow to pull HTML-formatted newsletters out of my email and push them to Wallabag. I then use Wallabag&#x27;s RSS feature with Calibre to turn them into an ebook I can read on my Kindle.My other major use case is centralized notifications. For a lot of things (e.g. backups), I have a webhooks in Huginn that then push out a notification via Gotify to my phone.I&#x27;ve also used Huginn to scrub&#x2F;clean up RSS feeds, since it can pull the feed, apply transforms to it, and then republish it. reply gettodachoppa 3 hours agorootparentThis sounds fine but what is this doing that a bash script + cronjob doesn&#x27;t? Isn&#x27;t all of this functionality available in CLI tools (and in fact you&#x27;re likely already using them, e.g. making calibre convert the HTML newsletter to .mobi).I ask because I&#x27;m also curious what I can use these sort of tools for. I installed Node Red before and other than visual smart home automation, was at a loss of ideas. As someone who can write bash scripts (and nowadays ChatGPT does all the scripting for me), how can they make my life easier? reply BaseballPhysics 3 hours agorootparentI think you&#x27;re underestimating the effort involved in writing something to poll an IMAP folder, checking for new emails, pull the right mime attachments, etc, etc, and then turning around and post them to the right place.Yeah I could write some Ruby or Python or Perl to do the job but I can also spend way less time and use something like Huginn to do it for me.Honestly, your argument could apply to virtually anything you might do with something like Zapier or equivalent. Nothing they do can&#x27;t be done via scripting. The point is these tools simplify the grunt work so you can go from idea to implementation much faster, with proven code that you don&#x27;t have to write and maintain yourself. reply nylonstrung 16 hours agoparentprevThis is an straightforward alternative to Make.com or Zapier vs Hugginn has AI agent stuff reply mercurialsolo 4 hours agoprevSomeone should look at a very different take on this space based on cause and effect based modeling.DX based on cause and effect is a.lot more intuitive for users and reasoning agents reply reion 16 hours agoprevI have been using n8n for over a year. I prefer it over popular Zapier as it gives me more flexibility and I am able to self host. It have its quirks that you learn about only when you work enough with it to look up solutions on community forums. The only thing I wouldn&#x27;t recommend is their Cloud, it seams more buggy&#x2F;unstable than my self hosted instance (more timeouts, probably to conserve shared resources). Still I would recommended to anyone looking for a cheap and open source alternative for Zapier. reply JimDabell 16 hours agoparent> Still I would recommended to anyone looking for a cheap and open source alternative for Zapier.It’s not open source, it’s source available with commercial restrictions. reply toomuchtodo 16 hours agorootparentRight, you can run it yourself or pay n8n to run it. For purists the language matters, realistically for users it does not. You’re not locked into the SaaS platform is the point. reply JimDabell 16 hours agorootparentIt’s not about being a purist, the difference was a $50k&#x2F;yr hole in our budget for a license. reply toomuchtodo 16 hours agorootparentI assume because you were not running it for internal business only but were attempting to distribute or white label&#x2F;SaaS it? Isn’t $50k about 3-4 months of one dev’s time (assuming fully loaded costs)?https:&#x2F;&#x2F;docs.n8n.io&#x2F;choose-n8n&#x2F;faircode-license&#x2F; reply JimDabell 16 hours agorootparent> I assume because you were not running it for internal business only but were attempting to distribute or white label&#x2F;SaaS it?Yes, we wanted our customers to be able to set up integrations themselves. We didn’t care about white labelling it, we just needed to a) modify it, b) self-host it, and c) use it commercially. Something that open source is ideal for.> Isn’t $50k about 3-4 months of one dev’s time (assuming fully loaded costs)?Yes but that means absolutely nothing if you don’t have the budget for it, or even if you do have the budget for it but there are more valuable things for your developers to work on, or if you do have the budget for it but it isn’t worth that much. In our case the value provided by n8n wasn’t anywhere near $50k&#x2F;yr. And, more to the point, $50k&#x2F;yr is $50k&#x2F;yr more expensive than open source. It would have been worth using if it had been open source, but it wasn’t worth using at that price. reply toomuchtodo 16 hours agorootparentRight, so it prevented freeloading. It’s working as intended. Still usable for those who want to eject from the hosted platform, but if you make money from it, n8n should get paid for that value. You’ve proved the point of why open source would’ve been a suboptimal license for them to use.Open source was intended as free as in speech, not free as in beer. “Open source because I don’t want to pay something” is…not great.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gratis_versus_libre reply shrubble 6 hours agorootparentWhere does this \"freeloading\" meme phrase come from? Seems astroturfed.Is a person that uses Linux or FreeBSD without paying for it also a &#x27;freeloader&#x27;?If someone wants to release their own code under any sort of license they have the freedom to do so. reply gettodachoppa 3 hours agorootparent>Is a person that uses Linux or FreeBSD without paying for it also a &#x27;freeloader&#x27;?A few times? No. All the time, without ever giving back? Yes. It&#x27;s the truth.It&#x27;s not about money specifically, it&#x27;s about contributing to the open-source movement in general. This movement is why desktop and server computing is as open as it is and we&#x27;re not all renting our dev tools and OSes for a monthly fee to one of the dystopian tech giants.It&#x27;s like if you joined a commune where they provide you with a room and meals at no cost. They tell you you can stay as long as you want. If you&#x27;re still there after 2 years, you don&#x27;t think you oughta give something back? reply commoner 3 hours agorootparentUsers of free and open source software also give back by contributing feedback, bug reports, and patches. They promote the software through word of mouth and offer support to other users, building a community that extends the longevity of the software. The FOSS movement encompasses more than monetary payment in exchange for software, and it is not \"freeloading\" to use software exactly as prescribed by the license the developers selected.While n8n is not open source, n8n is at least upfront about its business model and does not falsely brand itself as open source, which is more than can be said about some other companies. reply JimDabell 15 hours agorootparentprev> if you make money from it, n8n should get paid for that value.We weren’t really expecting to make any money out of it. We already have a Zapier integration that our customers were using. We just wanted things to be a little bit easier for our customers. Does this have an indirect impact on our profits? Sure, I guess marginally. Enough to justify a $50k&#x2F;yr license fee? Nope, not even remotely close. Our customers can carry on using Zapier.> You’ve proved the point of why open source would’ve been a suboptimal license for them to use.They didn’t get paid either way, the only difference was we send all our customers to their competitor now. Which also isn’t open source, of course, but Zapier has the brand recognition and reach n8n doesn’t. Everybody knows Zapier, a lot of customers ask for it specifically. Nobody asks for n8n. I don’t want to make the “you’ll get paid in exposure” argument, but in practical terms, the only difference to n8n in our particular case was they had a chance to stop us sending customers to Zapier. They never had the opportunity to earn money from us directly, only to get us to stop sending customers to their competitor.If n8n want to license their product in that way, that’s up to them. It’s totally their right to do so. But it’s not open source and this is a big issue for some potential users here. Discussion about that belongs here, especially when people are saying that it’s open source.> Open source was intended as free as in speech, not free as in beer.You’ve misunderstood that. Open source and Free Software includes both. Open source was originally promoted as the commercially-attractive alternative to Free Software. reply toomuchtodo 15 hours agorootparentGreat to hear you’re sending customers to Zapier, thanks for the context. reply JimDabell 14 hours agorootparentI don’t have specific numbers to hand, so assume any percentages below are inflated placeholders.Let’s say 10% of our customers explicitly ask for Zapier integration because they are already Zapier customers. A further 20% have the expressed need for some third-party automation that we don’t directly support, but is supported through Zapier. And a further 30% could benefit from it but have no idea this kind of thing even exists. 0% ask for n8n. 0% have even heard of n8n.Well we need to build the Zapier integration to keep that 10% happy. Now that we have that integration, we can turn to the 20% that need something like this and tell them to sign up for Zapier, and then they will be happy too. Then we can publish how-to articles and give a nice surprise to the other 30%, who will also go and sign up to Zapier.There’s friction here. Some customers will fit in Zapier’s free tier and others will have to pay extra. The process for hooking Zapier up to our product is clunky. And every time the customer wants to change some aspect of their automation, they have to leave their product dashboard and go to an external service.The goal was to self-host n8n so that customers could keep doing everything within our product. Most of the 10% existing Zapier customers would carry on using Zapier; some would switch. We wouldn’t need to send customers over to Zapier to keep the 20% of users asking for something like this happy, and the how-to articles would help the other 30% without sending them to Zapier as well. Some of our customers would save money by not having to pay Zapier, for others it would make no difference. Our customers would be able to manage their integrations without going off to some third-party site.You can see how this is a desirable thing for us to do. You can also see that the value to us is way, way, way below $50k&#x2F;yr. We aren’t going to gain or lose any customers over this. The main difference for us is marginal UX improvements.n8n received $0 from us. If n8n were open source, they would still receive $0 from us. The difference is that we wouldn’t be sending 50% of our customers to become new Zapier customers. n8n would have gained one small integration – us. There’s no point in us building an n8n integration when we have Zapier though, because nobody is asking for it and Zapier does everything we need and has more integrations. It’s also possible that we &#x2F; our customers would add to the other n8n integrations if we needed them or contribute functionality or bugfixes, but again, that’s veering a little to close to the “payment in exposure” argument I dislike.As I said before, if n8n want to play things this way that’s their prerogative. But somebody here was telling people that it’s open source when it’s not. It being open-source or not is a big deal for cases like ours; it’s not “purism”. reply toomuchtodo 14 hours agorootparentI suppose I don’t understand why you couldn’t build an integration with n8n solely with generic webhooks vs having to bring a copy of their software into your stack. You didn’t need a copy of Zapier to integrate with Zapier (although you mentioned it was a clunky integration, I’m sure the Zapier folks would be interested in feedback on how to improve there).It sounds like n8n needs to offer a library under a different license to smooth this integration issue? Correct me if I’m wrong there.Email in profile if you’d rather have the convo there. I’m very interested in smoothing the integration story for all workflow providers, and I misunderstood your use case that you were trying to bring the entire software app in to support your integration. reply JimDabell 13 hours agorootparent> I suppose I don’t understand why you couldn’t build an integration with n8n solely with generic webhooks vs having to bring a copy of their software into your stack.It’s a better user experience for customers. They don’t have to sign up for some third-party service, they don’t have to pay for some third-party service, they don’t have to mess around with API keys or onboarding flows, they don’t have to go to a third-party service to configure how things work, they don’t have to manage their admins separately, etc.Sure, we could integrate with n8n the same way we integrate with Zapier. But why would we? We already have Zapier for that. And our customers ask for Zapier. And they’ve heard of Zapier. And Zapier has more than 10x number of integrations. There’s no benefit for us to replicate what we already have with Zapier using n8n. The benefit of n8n was closer integration, but in order to get that we would have to spend $50k&#x2F;yr which simply wasn’t worth it for us.I don’t think the problem can be solved with a differently licensed library. n8n explicitly considered this use case and this is how they want things to work:https:&#x2F;&#x2F;n8n.io&#x2F;embed&#x2F; reply aliasxneo 16 hours agoparentprevI read the home page twice and struggled to figure out the use case. Is Zapier what it&#x27;s typically compared to? reply reion 16 hours agorootparentIn footer they have n8n vs Zapier and n8n vs Make pages, I guess other similar software would be IFTTT reply grotorea 15 hours agorootparentIFTTT is target more at personal usage while the others are more professional or more complex uses. n8n is, as the starting page, open source and self-hosted unlike those two. reply commoner 3 hours agorootparentn8n is source-available, not open source, because they restrict commercial use. They acknowledge this themselves: https:&#x2F;&#x2F;docs.n8n.io&#x2F;choose-n8n&#x2F;faircode-license&#x2F;#is-n8n-open... replysmusamashah 15 hours agoprevLooking at self hosting, one of the requirements is docker. Is there another tool with similar UI to automate workflows on your computer locally (windows, Linux etc)? I just realized there are a few very good android automation tools which monitor various states and can act on apps and settings but I haven&#x27;t seen anything that intuitive for windows. reply tough 15 hours agoparentdocker is a -requirement- only if you plan to use their pre-fab stuffyou can just take their dockerfile and run the infra however you wish too, probably.Haven&#x27;t checked n8n on a whileActually. says npm OR docker right there in their docs https:&#x2F;&#x2F;docs.n8n.io&#x2F;hosting&#x2F;installation&#x2F; reply gettodachoppa 3 hours agoparentprevDocker is the ultimate application format for Linux. It IS Linux. If you read a Dockerfile, you can replicate it on a fresh install command by command, it serves as doc too. For example if it says \"FROM debian:bookworm RUN apt install nginx blah blah\" you can just repeat those steps on Bookworm. It&#x27;s just the developer already that work for you so all you need to do is run \"docker run -dt sometool:sometag\" and presto it&#x27;s all running on your PC.Dockerized apps run with almost no overhead, it&#x27;s not like using a VM.Take 2 hours to learn it, trust me it&#x27;s worth it. This isn&#x27;t some \"Cloud Scale!\" hype. It&#x27;s useful even for someone with just a Pi at home. Just stick to the basic Docker commands (exec, run, compose if you want to be fancy). Don&#x27;t bother with that Google-scale stuff like Kubernetes unless this becomes your career. reply skripp 15 hours agoparentprevMaybe Node-RED? reply alberth 15 hours agoprevWhat do people use these tools for?I’ve yet to find a need for Zapier, etc but know it’s hugely popular & generates a ton of revenue. reply JimDabell 15 hours agoparentLet’s say you’re building a software product. When something happens in your product (maybe somebody buys something, or shares a link, or creates an image, etc.), some of your customers want something to happen in response. Maybe they want the user to receive an email, maybe they want something to be posted to social media, etc.Normally you would have to integrate with each of those third-party services directly. With n8n, Zapier, etc., you can write one integration and let your customers decide what to plug it into. So you get thousands of integrations “for free” by integrating one service.The same goes in reverse – maybe something happens in a third-party service and your customers want something to happen in your product as a result. Instead of requiring all those third-party services to integrate with you, they can just integrate with n8n, Zapier, etc.Because services like n8n and Zapier provide a common interface between very different services, it sidesteps a combinatorial explosion of integrations needed to wire everything up to everything else explicitly.For instance “when somebody buys something from our Shopify store, I want to add them to a private Slack channel”. Shopify aren’t going to spend time building an integration like that, Slack aren’t going to spend time building an integration like that, and a customer isn’t going to want to commission bespoke software to wire it all up. But if they both integrate with n8n or Zapier, then customers can do it themselves. reply afro88 12 hours agorootparentI&#x27;m pretty sure OP was asking about the end user use cases. But I appreciate your reply because I&#x27;m developing a product and this made something click for me about letting users integrate with other things with minimal effort. reply extragood 15 hours agoparentprevMy company has \"apps\" on n8n, Zapier, and Make. I&#x27;ve used them all and they&#x27;re fairly similar: they make integration of supported platforms easy and support simple automation workflows.E.g. if x happens on y platform, get relevant data, process it, send me a text message if it&#x27;s during the day or email me if it&#x27;s at night&#x2F;weekend.It&#x27;s frequently faster than building out the integrations yourself, and is more accessible to inexperienced programmers&#x2F; less technical folks.In terms of ease of use, I&#x27;d rank it: Zapier (top), Make, n8n. Same ranking for available apps. Complexity of workflows I&#x27;d rank those in reverse though. You can do more with n8n. reply pacbard 11 hours agoparentprevI use it for some webhook stuff to put together an RSS feed for a website that doesn&#x27;t provide one. I didn&#x27;t want to have to code up a web app just for it.N8N comes with a webhook listener, and it was easy enough to cobble something together with the built-in nodes and coding custom ones with javascript (they just released a python node that I haven&#x27;t tried yet). reply dang 11 hours agoprevRelated:N8n.io – Workflow automation alternative to Zapier - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21191676 - Oct 2019 (196 comments) reply iAkashPaul 15 hours agoprevAlways adored tools like this, Isoflow for isometric flowcharts is another one that was closed sources but is being opened up one feature at a time. reply rabbitofdeath 9 hours agoprevOk slightly off topic, but how do you pronounce&#x2F;say n8n? Like nation? reply b0afc375b5 8 hours agoparentFrom the readme[0], it&#x27;s pronounced nodemation.[0] https:&#x2F;&#x2F;github.com&#x2F;n8n-io&#x2F;n8n&#x2F;blob&#x2F;master&#x2F;packages&#x2F;cli&#x2F;READM... reply RankingMember 7 hours agorootparentwow, bit of a clunker, that. I read \"n8n\" as \"nation\" too. reply rabbitofdeath 8 hours agorootparentprevah Thanks! reply ericcholis 14 hours agoprevAnybody have experience with this in comparison to parabola? reply ugur2nd 16 hours agoprevLocale is easy to install and difficult to add to the server. reply ulrischa 15 hours agoprevI found n8n some years ago and dexcided to use NodeRed instead. It has a large Community and more built in features reply bevenky 16 hours agoprevAs per its description on github: N8n is a Free and source-available fair-code licensed workflow automation tool.Not really OSS.Check out: https:&#x2F;&#x2F;www.activepieces.com&#x2F;MIT open source. reply commoner 3 hours agoparentThank you for this recommendation. I was looking for a FOSS replacement for n8n with a similar user interface and feature set, and Activepieces seems to be a great fit. reply JimDabell 16 hours agoparentprevThanks for this. We had previously evaluated n8n a year ago and couldn’t use it because it wasn’t open source and they wanted to charge us $50k&#x2F;yr. I wasn’t aware of ActivePieces, will check it out. reply Hnrobert42 15 hours agoprev [–] I really want to like these tools. Yet every time I consider Zapier or IFTTT, their integrations are a mile wide and an inch deep. I’ll see that they integrate with XYZ corp, but then it’s only with a handful of endpoints.Like say I wanted to gather attendees from my Google Meet, Zoom, Webex, etc and send them to salesforce. I’d look at Zapier and see they work with Google. Then I’d look for Google Meet and see there’s nothing there.I get that these connectors can only integrate with existing endpoints. I’m not criticizing. I’m just confused. How do people actually use these services? reply quasiuna 15 hours agoparentWe’ve used N8N for about 2 years, at scale, in production, self-hosted on a VM with docker compose. It’s phenomenal.We run every piece of client-specific custom integration work through it.Plumbing a few systems together is a piece of cake - either triggered by webhook or scheduled cron-like.There are tonnes of out the box nodes for common services, but for everything else the JavaScript code block and HTTP request nodes fill in any missing gaps.We’ve tried Zapier, Integromat and loads of others - N8N has nailed the UX for us. reply klysm 15 hours agoparentprevI find that these services are typically used to implement shitty half broken database replication. It’s obvious to anybody that’s worked on that sort of problem that it’s a fools errand and is going to result in terrible, brittle, untrustable data. However, their marketing and product success depends on you not knowing that. reply toomuchtodo 15 hours agoparentprev [–] Simple integrations that would otherwise require dev time to build and maintain. As long as the workflows last just long enough for the value they’re providing, it’s a superior solution to a bespoke build. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "n8n is a workflow automation tool that is designed to make it easier for technical people to create complex automations efficiently.",
      "It offers a user-friendly interface and the option to customize the automation using JavaScript.",
      "With over 350 native integrations and the ability to create custom scenarios, n8n can be used in various use cases such as customer integrations, CRM customization, and SaaS backend prototyping.",
      "It prioritizes scalability and customizable error handling and can be self-hosted for free or used in the cloud with affordable pricing options.",
      "The n8n community provides support and resources for its users, and the platform is highly praised for its capabilities and flexibility."
    ],
    "commentSummary": [
      "n8n.io is a popular workflow automation tool that is praised for its ability to build complex backends without extensive programming knowledge.",
      "Users mention sporadic errors and limited user management and integrations as drawbacks of n8n.io.",
      "Other tools like Huginn, Windmill, and Inngest are discussed, with their benefits and drawbacks highlighted.",
      "n8n.io is highlighted as a cheaper open-source alternative to Zapier, and there is a debate about whether open-source software should be freely available or require payment.",
      "It is emphasized that understanding licensing and business models of software tools is important.",
      "Integration capabilities of n8n.io are discussed, with users suggesting improvements for better integration with other platforms.",
      "The thread includes discussions on the pronunciation of \"n8n,\" comparisons to other tools, and the functionality and reliability of these tools for workflow automation."
    ],
    "points": 209,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1693066002
  },
  {
    "id": 37277907,
    "title": "Linux on a Commodore 64",
    "originLink": "https://github.com/onnokort/semu-c64",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up onnokort / semu-c64 Public forked from sysprog21/semu Notifications Fork 22 Star 68 Code Pull requests Actions Projects Security Insights onnokort/semu-c64 master 3 branches 1 tag Go to file Code This branch is 25 commits ahead, 2 commits behind sysprog21:master. Latest commit onnokort New README for C64 a49f0cf Git stats 84 commits Files Type Name Latest commit message Commit time .ci Enable GitHub Actions .github/workflows Enable GitHub Actions configs Update linux.conf for a smaller kernel image mk Avoid duplicated URL assignment scripts Copy built rootfs.cpio to project's root directory .clang-format Import from internal tree .gitignore C64: Script to create REU initialization file (for e.g. VICE EMU) CONTRIBUTING.md Fix typo LICENSE Initialize the repository Makefile Enable C64=1 in Makefile README.md New README for C64 README.original.md Move original README around boot_anim.gif Proof pics :) booted.jpeg Proof pics :) common.h C64: Fix ilog2(..) implementation device.h C64: UART emulation that uses kernal functions feature.h Introduce feature test macro and build options main.c C64: #ifdefs for a corresponding main(..) minimal.dts Downsize VM RAM in device-tree to just 16MiB mk_linux_reu.py C64: Script to create REU initialization file (for e.g. VICE EMU) plic.c Use deterministic ilog2 when possible ram.c C64: Use REU for RAM access reu.c C64: Add REU driver for RAM access reu.h C64: Add REU driver for RAM access riscv.c C64: fprintf(..) -> printf(..) riscv.h Rework MMU riscv_private.h Import from internal tree uart.c C64: UART emulation that uses kernal functions virtio-blk.c Avoid unexpected symbol exposure virtio-net.c Rewrite vnet_preprocess as an inline function virtio.h Refactor VirtIO MMIO register map handling (sysprog21#23) README.md Running Linux on a Commodore C-64 \"But does it run Linux?\" can now be finally and affirmatively answered for the Commodore C64! There is a catch (rather: a couple) of course: It runs extremely slowly and it needs a RAM Expansion Unit (REU), as there is no chance to fit it all into just 64KiB. It even emulates virtual memory with an MMU. I have not tested it on real hardware yet, that's the next challenge .. for you. So please send me a link to a timelapse video of an original unit with REU booting Linux :D Building it Just use make. You need mos-c64-clang. Change the single C64 variable at the top of the Makefile and you should be able to switch between a x86_64 and an llvm-mos-6502 build of the code. The notes from the original README apply for the most part. The kernel configuration is different, though, as the kernel from the original semu is too bloated with huge section alignments. A more fitting kernel configuration can be found in the config subfolder. Finally, to assemble it all into the REU image needed for the VICE emulator, use the mk_linux_reu.py script. It still uses the original initrd image, as that works just well. Running it To run it, simply create a .d64 file containing the compiled semu executable (or simply select the correct path for a virtual disk drive in the emulator). Then (in VICE EMU), go to PreferencesSettingsCartridgesRAM Expansion Module, enable it and select the file reufile.linux, and make sure to select the correct size (16MiB) as well. If you started x64 from the console, a message that it loaded successfully should appear. Then, do LOAD \"SEMU\",8,1 and run and ... wait ... (hours!). With \"warp mode\" enabled in the emulator, the first boot messages should appear within a few minutes, though. You can also use the PC semu binary with the -k option to load the reufile.linux into the PC emulator and you should get a 100% identical boot sequence, as everything should be deterministic until the first keypress. I plan to add an archive with all the neccessary premade binaries as soon as I figured out how to do that on github. Look for something on the \"Releases\" tab. Further notes The screenshots took VICE a couple hours in \"warp mode\" (activate it with Alt-W) to generate. So, as is, a real C64 should be able to boot Linux within a week or so. The compiled 6502 code is not really optimized yet, and it might be realistic to squeeze a factor 10x of performance out of this. Maybe even a simple form of JIT compilation? It should also be possible to implement starting a checkpointed VM (quickly precomputed on x86-64) to avoid the lengthy boot process. Maybe X on an emulated framebuffer device in 320x200 graphics mode? VIC-II DRI? :D I also tested a minimal micropython port (I can clean it up and post it on github if there is interest), that one does not use the MMU and is almost barely remotely usable with lots of optimism at 100% speed... The generated semu executable is a generic RISCV32 emulator and it simply assumes that the REU maps to the address range 0x00000000 .. 0x01000000. You should be able to compile any (embedded, bare-bones) RISCV32 executable that uses just the emulated UART, fill it up to a size of 16MiB, load it as a REU-image into VICE and run it using the same semu 6510 binary. Likewise, I made a simple kernalemu fork with \"REU support\" which seems to run a lot faster than Vice. The emulated UART does upper-/lowercase PETSCIIASCII translation. That could use a lot of improvement, though ... Thanks This is in essence a fork of the very nicely minimalist RISC-V32 emulator named semu, compiled and ported using the new llvm-mos and would not have been so possible without all that previous work. (Boot animation) Time not to scale. About Linux on a Commodore C64 Resources Readme License MIT license Activity Stars 68 stars Watchers 0 watching Forks 22 forks Report repository Releases 1 Binaries v0.0.1 Latest Packages No packages published Languages C 94.1% Makefile 3.9% Shell 1.5% Python 0.5% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37277907",
    "commentBody": "Linux on a Commodore 64Hacker NewspastloginLinux on a Commodore 64 (github.com/onnokort) 188 points by johnwbyrd 10 hours ago| hidepastfavorite69 comments johnwbyrd 10 hours agoOnno Kortman has taken semu, a minimal RISC-V emulator, and cross-compiled it with llvm-mos, an LLVM port to the MOS 6502 processor, in order to run Linux on the Commodore 64. Kortman writes: \"The screenshots took VICE a couple hours in &#x27;warp mode&#x27; to generate. So, as is, a real C64 should be able to boot Linux within a week or so.\" reply wk_end 9 hours agoparentThe 6502 is a notoriously poor target for C compilation, especially C that hasn&#x27;t been written with the 6502&#x27;s limitations in mind. I&#x27;ll bet if you wrote a RISC-V emulator in native 6502 you could get Linux booting on a real machine in a day instead of a week. Think about how many lives that&#x27;d save!https:&#x2F;&#x2F;www.folklore.org&#x2F;StoryView.py?story=Saving_Lives.txt reply johnwbyrd 9 hours agorootparentSays you. llvm-mos generates surprisingly efficient 6502 code given its age and maturity. Don&#x27;t take my word for it, try some experiments with it on godbolt. reply wk_end 7 hours agorootparentSure. Here&#x27;s a couple of functions to iterate over an array of \"Ball\" objects, as you might do in a Breakout-style game that has a multi-ball powerup. I didn&#x27;t do anything to make it particularly 6502-amenable; it&#x27;s how I&#x27;d write it for a modern machine, probably. Even compiled with -O2: as expected, the code is slow and enormous - a single addition compiles to something like 30 instructions.[0] https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;f6Ysv7nve reply johnwbyrd 3 hours agorootparentSeems like your problem is more with the venerable 6502 itself rather than the compiler. Most of that assembly code is spent calculating the offsets inside the Ball struct, which must be done at 16 bits of resolution in every case. The compiler&#x27;s using the indirect indexed (zero page address with Y offset) 6502 addressing mode to get at all the fields in your struct. It has placed all the variables in zero page, so no instruction is more than two bytes long; additionally, the code in question is entirely linear, with no JSRs or other subroutines. Note in particular how it efficiently uses DEY&#x2F;INY pairs of one byte instructions to get at low and high bytes of 16-bit memory. Hand-written assembly might be speedier, but not by much and still deal with all the corner cases that your generated code does. \"While writing Apple BASIC for a 6502 microprocessor I repeatedly encountered a variant of Murphy&#x27;s Law. Briefly stated, any routine operating on 16 bit data will require at least twice the code that it should.\" -Steve Wozniak reply classichasclass 7 hours agorootparentprevI&#x27;ve yet to see the 6502 C compiler that can beat good assembly code. I appreciate the convenience and llvm-mos has certainly improved greatly, but if you want speed on a 6502, there&#x27;s no substitute. reply dwheeler 6 hours agorootparentI&#x27;ve yet to see a 6502 C compiler get within sight of good assembly code. C makes many assumptions that are slow to implement on a 6502, and are notoriously hard to optimize. reply johnwbyrd 1 hour agorootparenthttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2lW3WHPtmKo replynxobject 9 hours agoparentprevOh wow! This bootstrapping method reminds me of yet another Linux-on-an-8-bit-micro project (https:&#x2F;&#x2F;dmitry.gr&#x2F;?r=05.Projects&proj=07.%20Linux%20on%208bi...), which used an 8-bit AVR with an ARMv5 emulator. But, this takes the cake in terms of geek coolness. reply userbinator 3 hours agorootparentThat&#x27;s exactly what it reminded me of too; there&#x27;s been plenty of HN discussion about it: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19762928 reply mattl 10 hours agoparentprevI&#x27;d be curious to see this running on real hardware. I hope someone&#x27;s able to make it work. reply pengaru 10 hours agorootparentIt might be more interesting than watching paint dry, just via risk that an old C64 will let the smoke out. reply usr1106 6 hours agorootparentWhy would it let smoke out? I doubt a C64 has any power management. So whether it idles or boots Linux via a couple of emulation layers, the thermal load will be exactly the same. reply hakfoo 5 hours agorootparentI know there can be issues with thermal saturation on a heatsink design-- it was expected not just to generate N watts of heat, but to only do so for M hours. Can you expect to leave a real 64 on for days or weeks and it will stay up? I wonder if stores that had them as demo units when it was a relevant product, for example, power-cycled them regularly.I know from experience if you block the bottom intake vents on a VIC 20, so it can&#x27;t convect properly, it will eventually start acting funky.On a related note, I understand the 64&#x27;s original power bricks are considered timebombs, they might also not appreciate being left on for weeks at a time. reply userbinator 2 hours agorootparentCan you expect to leave a real 64 on for days or weeks and it will stay up?Yes. These early computers found their way into various embedded control applications too, and I suspect there&#x27;s quite a few C64s still in operation that way; they would&#x27;ve been replaced long ago if they weren&#x27;t stable. An article occasionally appears when someone discovers this:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=12604414 reply exitb 2 hours agorootparentprevI just saw a museum exhibition that featured a C64C, running all day, with a dust cover on, on what appeared to be the original PSU. I think it makes sense to be cautious about your own unit, but they’re probably not as vulnerable as people assume. reply NoZebra120vClip 2 hours agorootparentDefinitely the Achilles heel in any C64 setup. Perhaps new PSUs are visually distinct from the old ones, but practically everyone had to replace theirs as they aged.Now the 64C was released in 1986, four years after the 64 and its faulty power supplies came out. I don&#x27;t know whether Commodore had decisively fixed the flawed PSUs by that time, but I know for sure that my second PSU lasted for the lifetime of that device too. reply pengaru 6 hours agorootparentprevJust because it&#x27;s likely an old and long dormant piece of electronics, nothing to do with linux beyond it having to run the machine for multiple days 24x7. My understanding is they don&#x27;t come out of deep dusty storage in ready for service condition. Leaky caps. reply einr 1 hour agorootparentC64 caps are generally fine and do not need replacing. The most common things to spontaneously go bad of ”old age” on a 64 are probably RAM chips and the PLA, and of course the power supply is a time bomb. replylayer8 32 minutes agoprevI wonder, if instead if requiring REU, it could work by using a few dozen floppy discs as RAM, prompting the user to swap discs as needed.I’d be interested in watching a time-lapse video of that on real hardware, if someone has a couple of months&#x2F;years to spare. ;) reply Roark66 2 hours agoprevVery nice, but my first thought was \"surely this will not fit in 64k of ram!\". And it doesn&#x27;t. It requires a 16MB REU!To explain for the uninitiated how rare this bit of hardware is. The REU available for the c64 back in the day were 256kB and 512kB. These are most commonly built replicas as there are schematics available for them. Sometime in the late 90s there was also an \"expansion\" for c64 that contained a completely new CPU (superCPU - 65816) that was code compatible with the original and I believe this device could accommodate up to 16mb.Later reimplementations based purely on fpga popped up including a REU with 16mb. The original SuperCPU schematic was lost to time. Allegedly fpga based expansions are available to buy for few hundred EUR now, but I don&#x27;t know anyone that attempted to buy one or has one.So, although it is a neat trick(still a cool tech achievement) , saying it runs on c64 is akin to saying I got doom3 running on a 386, but my 386 is actually a pci card in a modern pc...If I can&#x27;t pull my c64 with hardware available back in the day (or hardware one could realistically built back in the day) I&#x27;m not sure saying \"runs on c64\" is correct.Coming back to the subject of a REU, why has no one published a schematic for one yet? There are cheap SRAM chips floating on ebay. It should be trivial to put one together. Unfortunately it isn&#x27;t, because the original (Super Cpu) had two components we need a beefy fpga to emulate. The supercpu itself and it&#x27;s dma controller which was a custom asic I believe.Perhaps as cheap(ER) fpgas or uC with fpga-like functionality become available someone will create an open source \"super cpu\". As of yet, everyone I ever heard using these, uses emulation. Nothing wrong with that, but I get the most out of my \"retro hobby\" by running original hardware. Emulation is very useful for dev, but for general use it&#x27;s a bit \"meh\" for me. reply einr 1 hour agoparentIf I can&#x27;t pull my c64 with hardware available back in the day (or hardware one could realistically built back in the day) I&#x27;m not sure saying \"runs on c64\" is correct.A 16MB REU could absolutely have been built in the 80s. It would have been absolutely astronomically expensive, but there’s no technical reason it could not be done. You seem to be confusing the SuperCPU with a plain REU expansion — the REU is just a bunch of RAM and an ASIC that talks to the 64 and allows it to store or retrieve banks of RAM (because obviously a 6502 cannot address more than 64K so instead you have to tell it to swap out system RAM) — there is no CPU on it.The SuperCPU (65816) can indeed address up to 16MB directly and that is a different thing. The project in the OP runs on a stock C64 on the stock C64 CPU, it just needs a mountain of RAM that would have cost the equivalent of a house back then ;) reply noobermin 42 minutes agoparentprevThis is marginally \"on a commodore 64\" if it requires a 16MB memory addition reply jhallenworld 7 hours agoprevNot Linux related, but I&#x27;ve been trying trying recent (at least to me..) C-64 accessories:I&#x27;ve tried the \"Kung Fu Flash\"- it&#x27;s a software defined cartridge that is cheap- just a single STM32 and can do pretty much everything. I bought this because I&#x27;m trying to duplicate the developer experience I see on \"8-bit show and tell\"- it can emulate the \"super snapshot\", but not the REU. It&#x27;s a really nice way to quickly try a lot of C-64 software and games.https:&#x2F;&#x2F;8bithardware.wixsite.com&#x2F;website&#x2F;post&#x2F;kung-fu-flashhttps:&#x2F;&#x2F;github.com&#x2F;KimJorgensen&#x2F;KungFuFlashI also have an SD2IEC: what I&#x27;ve learned is that it would have been useful to get a variant with an extra DIN socket. It&#x27;s nice but I was never a fan of C-64&#x27;s DOS and this reinforces it. To mount a D64 disk image you have to: OPEN1,8,15,\"CD:MYIMAGE.D64\":CLOSE1... yuck..JiffyDOS (replacement ROM for the C-64) improves this (it&#x27;s faster and includes a permanent DOS wedge), I bought one- it&#x27;s on the way. I&#x27;m curious to try it with the real 1541 drive.What got me started on this recently is the \"Penultimate +2\" cartridge for the VIC-20:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eNGyneXHKJQIn this case, I basically bought a VIC-20 just to try out the cartridge. reply Decabytes 9 hours agoprevThis begs the question. What is the oldest hardware that can boot modern Linux but still be used as a daily driver? reply speed_spread 7 hours agoparentThe main \"daily driver\" constraint is probably the crypto required to access most modern websites. You can make the leanest and meanest system you can to run great on the slowest machine but the internet is nowadays an unforgiving place. reply charcircuit 1 hour agorootparentSurely video encoding &#x2F; decoding is more compute intensive than the crypto. Taking video calls is a reasonable part of being daily driver capable. reply MrRadar 6 hours agoparentprevAssuming \"daily driver\" requires a modern web browser running modern web productivity apps I&#x27;d put the minimum at a Core 2 Duo with 4 GB memory. It wouldn&#x27;t exactly be snappy but with a bit of patience you shouldn&#x27;t be limited by the hardware. Throw in a GPU with hardware video decoding and you might even be able to watch YouTube in above-potato quality. reply lelanthran 3 hours agorootparentI&#x27;ve got a core 2 duo with 2GB RAM that I used for around 6 hours yesterday to write an application.Only slightly noticeable waiting times when I accessed some sites, but it worked and the application works too. reply TillE 6 hours agoparentprevFor the sake of argument, let&#x27;s say a computer where you can install Debian 12 and run a WM and a browser, and it&#x27;s not excruciatingly slow.I think you&#x27;d want to aim somewhere around the Pentium 4 &#x2F; Athlon XP era. The docs say it doesn&#x27;t support the original Pentium, so I suppose you could go back as far as the Pentium II if you really want to suffer. reply karczex 4 hours agorootparent3 years ago I tried to run any modern distro on Pentium 3 (without compiling anything by myself). It appeared I wasn&#x27;t able due to \"invalid opcode\" error inside systemd. I switched to Devuan (Debian fork without systemd) and it boot and was as usable as first raspberry pie. reply mcmoor 6 hours agorootparentprevDamn and I still remember when Pentium 4 is the epitome of speed and I have to make do with Pentium 3 and even 2. reply p1mrx 6 hours agorootparentPentium 4 was the epitome of heat. The Athlon XP was generally faster and cheaper during that era. reply pjmlp 4 hours agoparentprevDefinitely not modern Linux, when I got Slackware 2.0 in 1995&#x27;s Summer, I owned a Pentium 75Mhz, with 8MB RAM, Trident card capable of 1024x768 (X could only handle 800x600 on it), IDE CD-ROM and HDD. reply sixothree 4 hours agoparentprevProbably something with a core 2 duo. Though I’m sure a 230mhz cpu will “run” Linux with desktop just fine. reply teawrecks 7 hours agoparentprevThe bar for \"daily driver\" is different for different people&#x27;s requirements. Would streaming Netflix be included? Running simple games? reply wang_li 9 hours agoprevA demonstration of Turing equivalency. Any Turing complete computer can do what any other Turing complete computer can do if you don’t care about time. reply rhplus 8 hours agoparentTime and memory. reply jhallenworld 7 hours agorootparentYeah, so technically a Turing machine has infinite memory.. so no real-world computer is fully Turing complete. reply jwilk 2 hours agoparentprevHow do you run Linux in lambda calculus? reply krylon 1 hour agorootparentSlowly. Very slowly. reply mgkimsal 9 hours agoprevIs this different from Lunix?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LUnix reply sedatk 6 hours agoparentLUnix is an actual C64-native operating system that you can write apps for and run on C64 hardware directly. This is a RISC-V emulator running on C64 emulating a Linux boot up. reply skavi 9 hours agoparentprevthis is linux reply sedatk 6 hours agoprevThis isn&#x27;t Linux running on C64 per se. This is C64 emulating a RISC-V environment on which Linux runs.Still impressive of course, but semantics matter :) reply gbraad 6 hours agoparentSemu-ntics to be precise ;-) reply userbinator 3 hours agoprevNow someone needs to do the same with a ZX spectrum ;-)As others have mentioned, a 6502 is very poorly suited to C-style code, but a Z80 should be somewhat better with that. reply ryukoposting 8 hours agoprevI recently came into possession of a fully-functioning TRS-80 Model 4, and I fantasize regularly about putting some vaguely Unix-esque thing on it. The fantasy continues. reply whartung 7 hours agoparentYou should be able to boost that up to 128k. Once there you have a solid chance of being able to run Fuzix on it.Start there and you’ll find a rabbit hole of reasonable depth. reply chungy 9 hours agoprevOnce you add more RAM to a Commodore 64, is it still a Commodore 64? reply mdp2021 3 hours agoparentExpanding from Johnwbyrd&#x27;s nearby:-- Commodore sold a Ram Expansion Unit named \"1764\" to bring the C64 to 256kb of RAM;-- it was possible to use the REU for the C128 named \"1750\" to bring the C64 to 512kb of RAM;-- and it is possible to expand on that to have a 2MB REU for the C64 - see https:&#x2F;&#x2F;www.neperos.com&#x2F;article&#x2F;rlut8ce90fbb7701You can have two megabytes on the C64, pretty \"legally\". reply Roark66 2 hours agorootparentI can imagine \"someone\" back in the day could take PC SIMM modules and cobble together some monstrosity that would allow one to fill 16MB of RAM on a c64 using simple bank switching. However, the main \"innovation\" of these original and later REUs wasn&#x27;t the memory amount, but the chip that implemented DMA. That DMA chip could be used to copy ram contents very quickly with minimal CPU involvement. This is why c64 equipped with the REU has much better graphics capabilities (used for background animation etc).As far as I know, we still don&#x27;t have an open source equivalent of that dma chip. reply johnwbyrd 9 hours agoparentprevYes, if you use an REU, which is a correctly contemporary memory upgrade for the C64. reply tpmx 9 hours agoparentprevNo, it&#x27;s a Commodore 16384.(The max addressable memory with a C64 REU is 16 Megabytes.) reply vlasky 5 hours agoprevHow long does a kernel recompile take? reply snvzz 5 hours agoprevRISC-V is inevitable. reply doctor_radium 5 hours agoprevBut will it impact the sales of GEOS? reply brazzy 2 hours agoprevThat 16MiB memory requirement makes this rather disappointing, given that you can run Linux on machines with only 4 MiB of RAM: https:&#x2F;&#x2F;tldp.org&#x2F;HOWTO&#x2F;4mb-Laptops.html#toc3 reply peter_d_sherman 3 hours agoprevMinimal FORTHs (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Forth_(programming_language)) can run on an unexpanded VIC-20 (5K) or even early TRS-80 Model 1 (4K) -- with room and functionality to spare...On the VIC-20, you even get a few colors! reply erwincoumans 8 hours agoprevWhat&#x27;s the BogoMips? reply johnwbyrd 7 hours agoparentThe loading screen reports 130 BogoMIPS, but remember that it&#x27;s emulating the timer as well, so the number is meaningless. reply jandrese 4 hours agorootparentI assume that&#x27;s the \"warp speed\" BogoMIPS, on real hardware the number would be around 1. reply sys_64738 8 hours agoprevRun Neofetch! reply dusted 10 hours agoprev [–] So, I like Linux and I love my C64, but.. Linux are for computers too primitive to come with their own kernel and.... the C64 comes with a kernel and shell right from the factory :P reply msla 9 hours agoparentThe Commodore 64 doesn&#x27;t come with a mere kernel, it comes with a mighty KERNALhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;KERNAL> The KERNAL was known as kernel[6] inside of Commodore since the PET days, but in 1980 Robert Russell misspelled the word as kernal in his notebooks. When Commodore technical writers Neil Harris and Andy Finkel collected Russell&#x27;s notes and used them as the basis for the VIC-20 programmer&#x27;s manual, the misspelling followed them along and stuck.[7]> According to early Commodore myth, and reported by writer&#x2F;programmer Jim Butterfield among others, the \"word\" KERNAL is an acronym (or, more likely, a backronym) standing for Keyboard Entry Read, Network, And Link, which in fact makes good sense considering its role. Berkeley Softworks later used it when naming the core routines of its GUI OS for 8-bit home computers: the GEOS KERNAL. reply bch 3 hours agorootparent> Jim ButterfieldI had a 6502 machine language book of his as a kid. I figured out in my head what I thought I wanted to do with the various instructions, then wrote out on graph paper the (decimal) number for the op or it’s args, then transcribed the whole affair into memory manually via POKEs. Good times. reply westmeal 8 hours agorootparentprevThe mighty KERNAL is how us mere mortals can JSR FFD2. (I think that&#x27;s right) reply mdp2021 3 hours agorootparent> JSR [$]FFD2. (I think that&#x27;s right)Yes, that is the \"print char in A and inc screen pos\" in the lookup table for the actual subroutine. reply Agingcoder 10 hours agoparentprev [–] Yes, but it’s fun :-) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Semu-c64 is a project that allows running Linux on a Commodore C64 using a fork of the semu emulator.",
      "It requires a RAM Expansion Unit and runs very slowly, with booting Linux on a real C64 estimated to take a week.",
      "The code can be built using make and mos-c64-clang, and the emulator can be run on VICE EMU by creating a .d64 file and loading the semu executable."
    ],
    "commentSummary": [
      "A developer has successfully run Linux on a Commodore 64 using a RISC-V emulator and an LLVM port.",
      "There are debates regarding the efficiency of the compiler and the limitations of the Commodore 64's processor.",
      "Some are interested in running the project on real hardware, but it requires a rare and hard-to-find RAM Expansion Unit."
    ],
    "points": 188,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1693092992
  }
]
