[
  {
    "id": 38088538,
    "title": "Phind Model beats GPT-4 at coding, with GPT-3.5 speed and 16k context",
    "originLink": "https://www.phind.com/phindmodelhn",
    "originBody": "Hi HN,We’re excited to announce that Phind now defaults to our own model that matches and exceeds GPT-4’s coding abilities while running 5x faster. You can now get high quality answers for technical questions in 10 seconds instead of 50.The current 7th-generation Phind Model is built on top of our open-source CodeLlama-34B fine-tunes that were the first models to beat GPT-4’s score on HumanEval and are still the best open source coding models overall by a wide margin: https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;bigcode&#x2F;bigcode-models-leaderb....This new model has been fine-tuned on an additional 70B+ tokens of high quality code and reasoning problems and exhibits a HumanEval score of 74.7%. However, we’ve found that HumanEval is a poor indicator of real-world helpfulness. After deploying previous iterations of the Phind Model on our service, we’ve collected detailed feedback and noticed that our model matches or exceeds GPT-4’s helpfulness most of the time on real-world questions. Many in our Discord community have begun using Phind exclusively with the Phind Model despite also having unlimited access to GPT-4.One of the Phind Model’s key advantages is that it&#x27;s very fast. We’ve been able to achieve a 5x speedup over GPT-4 by running our model on H100s using the new TensorRT-LLM library from NVIDIA. We can achieve up to 100 tokens per second single-stream while GPT-4 runs around 20 tokens per second at best.Another key advantage of the Phind Model is context – it supports up to 16k tokens. We currently allow inputs of up to 12k tokens on the website and reserve the remaining 4k for web results.There are still some rough edges with the Phind Model and we’ll continue improving it constantly. One area where it still suffers is consistency — on certain challenging questions where it is capable of getting the right answer, the Phind Model might take more generations to get to the right answer than GPT-4.We’d love to hear your feedback.Cheers,The Phind Team",
    "commentLink": "https://news.ycombinator.com/item?id=38088538",
    "commentBody": "Phind Model beats GPT-4 at coding, with GPT-3.5 speed and 16k contextHacker NewspastloginPhind Model beats GPT-4 at coding, with GPT-3.5 speed and 16k context (phind.com) 806 points by rushingcreek 21 hours ago| hidepastfavorite320 comments Hi HN,We’re excited to announce that Phind now defaults to our own model that matches and exceeds GPT-4’s coding abilities while running 5x faster. You can now get high quality answers for technical questions in 10 seconds instead of 50.The current 7th-generation Phind Model is built on top of our open-source CodeLlama-34B fine-tunes that were the first models to beat GPT-4’s score on HumanEval and are still the best open source coding models overall by a wide margin: https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;bigcode&#x2F;bigcode-models-leaderb....This new model has been fine-tuned on an additional 70B+ tokens of high quality code and reasoning problems and exhibits a HumanEval score of 74.7%. However, we’ve found that HumanEval is a poor indicator of real-world helpfulness. After deploying previous iterations of the Phind Model on our service, we’ve collected detailed feedback and noticed that our model matches or exceeds GPT-4’s helpfulness most of the time on real-world questions. Many in our Discord community have begun using Phind exclusively with the Phind Model despite also having unlimited access to GPT-4.One of the Phind Model’s key advantages is that it&#x27;s very fast. We’ve been able to achieve a 5x speedup over GPT-4 by running our model on H100s using the new TensorRT-LLM library from NVIDIA. We can achieve up to 100 tokens per second single-stream while GPT-4 runs around 20 tokens per second at best.Another key advantage of the Phind Model is context – it supports up to 16k tokens. We currently allow inputs of up to 12k tokens on the website and reserve the remaining 4k for web results.There are still some rough edges with the Phind Model and we’ll continue improving it constantly. One area where it still suffers is consistency — on certain challenging questions where it is capable of getting the right answer, the Phind Model might take more generations to get to the right answer than GPT-4.We’d love to hear your feedback.Cheers,The Phind Team alex-moon 7 hours agoI tried my standard \"trick\" question I use for LLMs:\"Give me five papers with code demonstrating the state of the art of machine learning which uses geospatial data (e.g. GeoJSON) as both input and output.\"There is no such state of the art. My hand-wavey understanding is that GIS data is non-continuous, which makes it useless for transformers, and also contextual, which makes it useless for anything else. Will defer to actual ML people for better explanations.Point is, LLMs invariably give five papers with code that don&#x27;t actually exist - it&#x27;s a guaranteed hallucination.Phind was able to give me five links that do in fact exist, as well as contextual information as to why these five links were not papers with code doing ML with GIS data. This is by far the best answer to this question from an LLM I&#x27;ve received yet. reply geedzmo 5 hours agoparentI don&#x27;t see how this would be relevant for a code model?The code model isn&#x27;t trained to retrieve papers&#x2F;articles, it&#x27;s meant to complete code. Whether or not you find hallucination in a unrelated task isn&#x27;t particularly interesting. reply jstummbillig 7 hours agoparentprevChatGPT 4 with web browsing: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;19a425b5-ed37-469e-860d-65ee70...ChatGPT 4 without web browsing: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7e11b4a6-52f2-441a-8614-7266c3... reply alex-moon 7 hours agorootparentChatGPT 4 seems to be better than it was when I was using it (mere months ago)! reply lucubratory 3 hours agorootparentYeah, all of OpenAI&#x27;s stuff gets better much quicker than I&#x27;m used to. So does the general performance ceiling of all open source models, even if individual models don&#x27;t improve as much. reply jamessb 4 hours agoparentprev> the state of the art of machine learning which uses geospatial data (e.g. GeoJSON) as both input and output> There is no such state of the artSome GIS work uses vector data: points&#x2F;lines&#x2F;polygons representing features (e.g., the location of roads or the outlines of buildings), which can be stored in formats like GeoJSON or WKT. But other work uses remote sensing data&#x2F;satellite imagery that can be stored in raster formats like GeoTIFF - essentially TIFF image files with additional information stored to georeference them.You can totally do machine learning on satellite imagery where both the input and output are geospatial data (e.g. to categorise land use - the inputs are multispectral images and the outputs can be images where the value of each pixel represents the identified land use).You can also use machine learning for tasks like building footprint detection&#x2F;delineation (e.g., [1]) based on satellite imagery. The output from such a pipeline can be a set of polygons, which could be saved as GeoJSON.I&#x27;d consider either of theses to be examples of \"machine learning which uses geospatial data (e.g. GeoJSON) as both input and output\".[1]: https:&#x2F;&#x2F;azure.microsoft.com&#x2F;en-us&#x2F;blog&#x2F;how-to-extract-buildi... reply Smith42 5 hours agoparentprevCheck out EarthPT! https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.07207 reply zoogeny 19 hours agoprevI just spent a few minutes doing a comparison between Phind and GPT-4 for a very high-level question on a distributed job queue. I gave them both the same fairly vague sketch of a kind of system I would like to build. Here are my impressions:In the positives of Phind:* Phind was able, even eager, to recommend specific libraries relevant to the implementation. The recommendations matched my own research. GPT-4 takes some coaxing to get it to recommend libraries. Phind also provided sample code using the libraries it recommended.* Phind provides copious relevant sources including github, stackoverflow and others. This is a major advantage, especially if you use these AI assistants as a jumping off ground for further research.* Phind provides recommendations for follow on questions that were very good. One suggestion to the Phind team: don&#x27;t remove the alternate follow on questions once I select one. A couple of times it recommended a few really good follow up questions but as soon as I selected one the others disappear.In the positives of GPT-4:* GPT-4 gave better answers. This is my subjective opinion (obviously) but if I was interviewing two candidates for a job position and using my question as the basis for a systems-design interview then GPT-4 was just overall better. In many cases it added context beyond my question, recommending things like logging and metrics for example. It seemed to intuit the \"question behind the question\" in a much better way than the literal interpretation of Phind. This is probably highly case-dependent, sometimes I just want an answer to my explicit question. But GPT-4 seemed to understand the broader context of the question and replied with that in mind leading to an overall more relevant response.* GPT-4 handled follow-up questions better. This is similar to the previous point - but GPT-4 gave me the impression of narrowing down the scope of the discussion based on the context of my follow-up question. It seemed to \"understand\" the direction of the conversation in a way that felt like it was following context.NOTE: this was not a test on coding capability (e.g. implementing algorithms) but on using these AI coding assistants as sounding boards for high-level design and architecture decisions. reply idonotknowwhy 14 hours agoparentThis is a good point about GPT-4, it can intuit the \"question behind the question\" really well compared with other models. And it&#x27;s been profoundly useful for me with the most random tasks I knew nothing about prior (like fixing a wall in my house), etc. reply Ghexor 3 hours agorootparentThat&#x27;s probably because OpenAi can train on the (succesfull) conversations we have with ChatGPT! reply X6S1x6Okd1st 19 hours agoparentprev> * Phind provides copious relevant sources including github, stackoverflow and others. This is a major advantage, especially if you use these AI assistants as a jumping off ground for further research.Did you find them to be correct? reply pbhjpbhj 18 hours agorootparentI don&#x27;t use Phind for coding, except occasionally, but I like it best for generalised tech search because each para has a reference and there&#x27;s a list of references down the side -- often the references would really be sufficient for me on their own.I&#x27;ve had one glaring error, I can&#x27;t quite remember the details, but it switched the names&#x2F;characteristics of two different processes (ie was exactly opposite in what it said); it was something to do with instruction caching and TLB, IIRC. I assumed you&#x27;d was a problem with the input corpus not allowing antonyms to be disambiguated.Anyway, for me it&#x27;s the best of the LLM tools I have access to and had mostly replaced search engine (Google, Dukgo) for my tech-related work.I&#x27;ve only used chat.openai.com (free), bing chat, HuggingChat. reply zoogeny 18 hours agorootparentprevI don&#x27;t think \"correct\" is the right word since these were open ended systems design type questions. There are many ways to accomplish the same task.I also spent about 20 minutes on this which is why I mentioned this is a first impression. I&#x27;ll leave it to researchers to develop a \"relevancy\" metric and objectively apply it.In my experience, the sources were sufficiently relevant based on its responses. They were about as relevant as equivalent Google queries. Some tiny, tiny niggles, like I was explicit I wanted it to recommend approaches in Go and for one reference I recall related to distributed locking mechanisms it provided a reference to an implementation in Java. However, that is completely fine for me since the context was more about the locking on the database side and not really the implementation in a specific language. reply foobarbecue 16 hours agorootparentAnd the sources actually existed? i.e. there weren&#x27;t any made-up ones? reply zoogeny 16 hours agorootparentThe sources are urls to the cited page (e.g. stackoverflow.com, pkg.go.dev). In the side-bar next to the answer is a more standard search-result style link list with pulled quotes from the pages (like a Google search).I didn&#x27;t click every single link (as I mentioned, the citations are copious) but the few I did follow went to relevant articles. I just went back and randomly clicked several more and they all went to pages that exist and mostly relate to the content of the answer. The inline citations seem a bit more on-topic compared to the side bar which does seem more like the links were lifted directly from a search engine.To be fair there are some lower-quality blog-spammy kinda stuff - more or less the same kind of thing you would get out of Google. But compared to GPT-4, which provides no sources whatsoever, it is an advantage IMO. reply webappguy 18 hours agoparentprevDo you have custom instructions? Everyone needs to mention and post prompts else entirely antidotal reply rushingcreek 18 hours agorootparentWe support custom instructions at https:&#x2F;&#x2F;phind.com&#x2F;profile. reply bredren 18 hours agorootparentI’m trying to get it to answer only in executable Python. I used the template with instructions I use for my system prompt on gpt4. And I tried using the additional context field for the same.It gets to writing the expected code but it still wants to include formatted headings instead of commenting those out so the entire response is executable Python.As a follow up I provided an example heading with the hash out front. It didn’t work.Any ideas on how to get it to this? Fwiw, gpt4 often if ignores this request, but only about half the time. When it does it is typically a single block of explanatory text.For that, I include prose detection and commenting as part of my post processing.Also, I don’t see it easily, but do you have an API for this or is it intended to be run by the user? reply rushingcreek 17 hours agorootparentGetting it to not output additional text is not something that it can do super well at the moment, unfortunately. We&#x27;ll work on that. reply soulofmischief 17 hours agorootparentprevMy trick for this has been one-shot training + regex. I tell the model to produce executable code within triple backticks suffixed by a keyword, like:```keyword &#x2F;&#x2F; code ```and then I just ignore anything outside of those blocks. reply zoogeny 16 hours agorootparentprevI did not have custom instructions for either assistant. You can see the full conversation logs which I posted as a reply to another comment. reply m3kw9 16 hours agoparentprevThe “give context” part has a lot to do with prompting well based on the model. To have a fair comparison there should be just code and see what that come up with reply fthd 19 hours agoparentprevmind providing some of the prompts you use to question them? reply zoogeny 18 hours agorootparentHere are the conversation logs:https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;867ff0c4-d4cf-4af9-a785-31a599...https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=ej8pn1dfjjwfr1tgc6ybwhlgNOTE: there are a few more question&#x2F;answer blocks in the phind conversation since I was testing out the follow up question feature. reply fartasanelk 15 hours agoparentprevwould you be able to share your prompt(s)?Edit: they are already posted as comment in this thread. reply cccybernetic 20 hours agoprevI&#x27;m glad there&#x27;s growing competition, but GPT4 still outperforms. Here&#x27;s a recent question I asked:Could you please provide me with a query for my PostgreSQL table? It consists of three columns: &#x27;id,&#x27; &#x27;teaser,&#x27; and &#x27;full_text,&#x27; all of which are of type &#x27;text.&#x27; Most &#x27;full_text&#x27; entries are articles around 1000 words in length. I&#x27;d like to update the &#x27;teaser&#x27; column for each row with the first approximately 200 words from the &#x27;full_text&#x27; column. How can I achieve this?Phind: CREATE OR REPLACE FUNCTION get_first_n_words(text, integer) RETURNS text AS $$ DECLARE word_count integer := 0; word_start integer := 1; word_end integer; BEGIN WHILE word_count&#x27;&#x27; ) WHERE full_text IS NOT NULL; reply rushingcreek 20 hours agoparentRunning \"Ignore Web Context\" enabled can improve performance for design tasks like this. I just got a more plausible answer: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=f0fkv5mxscwvagxgkuwnwgtl. Consistency is something we&#x27;re working on. reply cccybernetic 20 hours agorootparentThanks for sharing, you&#x27;re right - that does improve performance! reply ta8645 18 hours agorootparentprevHow do you enable \"Ignore Web Context\"? I don&#x27;t see that option anywhere on the page you linked, am I just being blind? reply rushingcreek 18 hours agorootparentIt&#x27;s in the model dropdown under the search bar. reply raducu 6 hours agorootparentYou mean \"Ignore Search Results\" ? reply riku_iki 20 hours agoparentprevOne example is not enough for performance conclusions reply cccybernetic 20 hours agorootparentObviously not. Perfectly reasonable to share anecdotes though.Also, I ran a few different tests, and every GPT-4 response was superior, but I didn&#x27;t want to clutter my comment with queries and code. reply Wytwwww 20 hours agorootparentprevThere is a performance conclusion in the title though. reply riku_iki 20 hours agorootparentThat conclusion is based on benchmark with many examples in different tasks. reply emptysongglass 8 hours agorootparentThat conclusion is based on their benchmarks. I&#x27;m not interested in those. I&#x27;m interested in community benchmarks, like those we&#x27;re seeing in the comments. Lo and behold, GPT-4 is still king. The claims of any company should be taken with exactly a pinch of salt. reply riku_iki 8 hours agorootparentthat benchmark(HumanEval) is some public benchmark built by others. reply PoignardAzur 3 hours agorootparentThat kind of benchmark is a lot more reliable for models published before the benchmarks; models published afterwards have more opportunity to \"study to the test\". That&#x27;s especially a concern when a company explicitly uses its score on that benchmark as a marketing point. reply spmurrayzzz 18 hours agorootparentprevAFAIK they haven&#x27;t released the dataset they fine-tuned on, so we can&#x27;t be 100% there wasn&#x27;t benchmark contamination. Agree that we definitely need more than N=1 to challenge the performance claims, but I still think its valid to call it out given how much benchmarking-gaming we&#x27;ve seen in this space. reply riku_iki 18 hours agorootparentI think you can bring contamination claim to every public benchmark results nowdays: models are trained on TBs of data crawled from internet, and there is no guarantee benchmark is not leaked in some way. reply spmurrayzzz 15 hours agorootparentWith respect to the pretraining data, its true that we&#x27;re probably SOL there in terms of verification. But for fine-tuning, they could still publish the dataset and see if others can reproduce their results as well as audit for contamination.If we&#x27;re comparing benchmark deltas between different fine-tuned variants that share the same base models, that seems like the bare minimum we should expect to come along with performance claims. reply riku_iki 15 hours agorootparentI think both pretraining and finetuning datas are essential secret information for commercial models&#x2F;services. reply spmurrayzzz 15 hours agorootparentIn the case of Phind though, they also publish their models on HF with similar bold performance claims without publishing the datasets: https:&#x2F;&#x2F;huggingface.co&#x2F;Phind&#x2F;Phind-CodeLlama-34B-v2Even I am to grant that their subscription product has some secret sauce they want to keep close to the chest (ignoring for a moment their paid product is GPT-4 based), not doing the same for all the models they release to the open source community free of charge with a commercially-permissible license seems suspect.I realize this sort of open source contribution is mostly for marketing purposes, but being critical of the performance claims I think is still valid nonetheless. replyWytwwww 19 hours agorootparentprevFrom what I understand it&#x27;s a single test suite? Of course I don&#x27;t really mind the clickbait title that much, it&#x27;s hard to attract attention otherwise. reply riku_iki 15 hours agorootparentI think it is valid criticism that that HumanEval benchmark is not completely representative, they also say it in the post. reply amelius 18 hours agorootparentprevDepends on the claims made. reply gardenhedge 5 hours agoparentprevWith some simple clarification I got thisUPDATE your_table SET teaser = substring(full_text from &#x27;(\\S+\\s*){1,200}&#x27;) reply nofunsir 16 hours agoparentprevI really dislike article teasers and \"read more\" buttons. Now I know it&#x27;s intentional clipping of the corresponding articles. reply brucethemoose2 20 hours agoprev> We can achieve up to 100 tokens per second single-stream while GPT-4 runs around 20 tokens per second at best.Is that with batching? If so, thats quite impressive.> certain challenging questions where it is capable of getting the right answer, the Phind Model might take more generations to get to the right answer than GPT-4.Some of this is sampler tuning. Y&#x27;all should look at grammar based sampling (https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773) if you aren&#x27;t using it already, as well as some of the \"dynamic\" sampling like mirostat and dynatemp: https:&#x2F;&#x2F;github.com&#x2F;LostRuins&#x2F;koboldcpp&#x2F;pull&#x2F;464I think these should work with nvidia&#x27;s implementation if you just swap the sampling out with the HF version.BTW, all this is a great advantage of pulling away from OpenAI. You can dig in and implement experimental features that you just can&#x27;t necessarily do through their API. reply rushingcreek 20 hours agoparentWe leverage Flash Decoding (https:&#x2F;&#x2F;crfm.stanford.edu&#x2F;2023&#x2F;10&#x2F;12&#x2F;flashdecoding.html) in TensorRT-LLM to achieve 100 tokens per second on H100s. reply claytonjy 19 hours agoparentprevis that impressive? I was thinking 100 tok&#x2F;s on an H100 is really slow considering LMDeploy claims 2000+ on an A100 and a large batch size. reply rushingcreek 19 hours agorootparentWe get 100 tokens a second with batch size 1. Those 2000+ figures are for large batches. reply claytonjy 19 hours agorootparentAh, that&#x27;s fair, and faster than any of the LMDeploy stats for batch size 1; nice work!Using an H100 for inference, especially without batching, sounds awfully expensive. Is cost much of a concern for you right now? reply lyjackal 18 hours agorootparentI don&#x27;t think they&#x27;re saying they&#x27;re doing batch size of 1, just giving performance expectations of user facing performance reply brucethemoose2 18 hours agorootparentYeah, and this is basically what I was asking.100 tokens&#x2F;s on the user&#x27;s end, on a host that is batching requests, is very impressive. reply claytonjy 18 hours agorootparentprevI think they _are_ saying batch size 1, given that rushingcreek is OP. reply ErikBjare 2 hours agorootparentYes they are saying batch size 1 for the benchmarks, but they aren&#x27;t doing batch size 1 in prod (obviously). reply claytonjy 1 hour agorootparentI don&#x27;t think that is obvious. If your use case demands lowest latency at any cost, you might run batch size 1. I believe replit&#x27;s new code model (announced about a month ago) runs at batch 1 in prod, for example, because code completions have to feel really fast to be useful.With TensorRT-LLM + in-flight batching you can oversubscribe that one batch slot, by beginning to process request N+1 while finishing request N, which can help a lot at scale. reply brucethemoose2 14 minutes agorootparentI&#x27;m not sure about TensorRT, but in llama.cpp there are seperate kernals optimized for batching and single use inference. It makes a substantial difference.I suppose one could get decent utilization by prompt processing one user while generating tokens for another.brucethemoose2 18 hours agorootparentprevWithout batching, I was actually thinking that&#x27;s kind of modest.ExllamaV2 will get 48 tokens&#x2F;s on a 4090, which is much slower&#x2F;cheaper than an H100:https:&#x2F;&#x2F;github.com&#x2F;turboderp&#x2F;exllamav2#performanceI didn&#x27;t test codellama, but the 3090 TI figures for other sizes are in the ballpark of my generation speed on a 3090.100 tokens&#x2F;s batched throughput (for each individual user) is much harder. reply drcode 18 hours agoprevI am a heavy user of GPT4, and Phind was surprisingly able to match GPT4 on several initial programming tasks I gave it. Given the large context window of Phind, it will likely be able to outperform GPT4 for some tasks.That is quite an accomplishment, I am impressed reply iandanforth 17 hours agoparentFWIW The default context window of GPT-4 via ChatGPT is about to change to 32k. reply jeswin 11 hours agorootparentGiven the number of times it just fails with large prompts on 32k contexts, I&#x27;m not sure if they&#x27;ready for this. In my experience, if you&#x27;re consuming 20k+ tokens failure rate is more than 50%. reply ComplexSystems 16 hours agorootparentprevThis would be great if true. Any source for this? reply jstummbillig 3 hours agorootparentprevSource? reply drcode 16 hours agorootparentprevthat would put them significantly ahead again, for my use cases reply rushingcreek 16 hours agorootparentWe will eventually increase the Phind Model to 100K tokens -- the RoPE embeddings in Code Llama were designed for this. reply arugulum 16 hours agorootparent> the RoPE embeddings in Code Llama were designed for this.The RoPE embeddings were not \"designed\" for that. The original RoPE was not designed with length extrapolation in mind. Subsequent tweaks to extrapolate RoPE (e.g. position interpolation) are post-hoc tweaks (with optional tuning) to an entirely vanilla RoPE implementation. reply antupis 11 hours agorootparentprev100k tokens and good ide support would be great. Copy pasting back and forth with browser and IDE is kinda annoying and you always miss some context. I think model is now good enough but what is kinda missing is good developer experience eg what to load in that context window and how model integrates to IDE. But this is kinda missing with copilot and chatgpt4 as well. reply m3kw9 16 hours agorootparentprevIs it “100k” or really 100k there are so many ways to do context, I remember seeing 100k before but it was doing some cheap trick to get it replyslowhadoken 21 hours agoprevI love that Phind cites what it scrapes. This should be the obligation of all LLM. I always suggest people use it over ChatGPT. reply make3 20 hours agoparentWhat they&#x27;re citing isn&#x27;t what the LLM \"scraped\", it&#x27;s what the retrieval model fed to the LLM. You&#x27;re not guaranteed that it&#x27;s what it actually used to give you the output, and it&#x27;s also definitely not all the text that it used to get appropriate knowledge to generate the answer, as this is split over whatever millions of examples for the language and for human language in a non human-understandable way reply slowhadoken 14 hours agorootparentI&#x27;ve heard this coldtake before but OpenAI&#x27;s source code isn&#x27;t open to academic scrutiny. So I don&#x27;t understand why some people are so confident about how it works. It&#x27;s certainly not magic and Phind seems to be capable of it citation. reply pbhjpbhj 18 hours agorootparentprevA couple of times I&#x27;ve had the reference not include the detail being mentioned in the foregoing paragraph; the citations are still highly relevant, but it wasn&#x27;t quite what I expected. reply Racing0461 20 hours agoparentprevAs a user, i perfer getting the right response compared to the thing spitting out a link. (not saying phind is bad). Lets focus on getting llm right before nerfing it in its baby stages. reply ryanklee 20 hours agorootparentWho said anything about nerfing? Citation is just additive, no? reply joshspankit 20 hours agorootparentIn fact, I’d argue that citation makes LLM better. Kind of a “think carefully” indicator. When LLMs are able to verify those citations independently it’s going to level up again by skyrocketing the objective truthiness. reply lsaferite 20 hours agorootparentInterestingly, I&#x27;d say that _not_ being able to give citations helps protect the LLM from copyright issues. That being said, I&#x27;m much prefer if the LLM could provide citations for every piece of information it was trained on and uses to provide an answer. reply pbhjpbhj 18 hours agorootparentCitations are essential for me as I&#x27;m using Phind for work and can&#x27;t rely on \"trust me bro\". It needs to confirm to my expectations or be confirmed in a couple of the citations that have trustworthy sources (eg are from known domains, well-cited journals, etc.). reply slowhadoken 14 hours agorootparentI&#x27;ve found great sites and devs using Phind. reply slowhadoken 15 hours agorootparentprevYeah, I prefer the context provided by the original creator. If I&#x27;m writing code and I need to reference someone else&#x27;s work I put their name in my comments. I was digging through Box2D for polygon vs ray intersections and in the comments of the source code Erin Catto cites Collision Detection in Interactive 3D Environments by Gino van den Bergen. It makes me respect him even more. reply __jonas 18 hours agorootparentprevI find it often makes the responses worse when it&#x27;s being pre-fed these search results, it was the case when I tried gpt-4 with web browsing enabled, and seems to be the case with this, since even the person from the Phind team in this thread pointed out that turning this feature off improves performance for some tasks:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38089888https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38090442 reply Racing0461 20 hours agorootparentprevNerf is the wrong word, more like regulatory capture. If all llm had to quote their sources at this point, along with all the other for the human changes we want to do, only the big players would be able to do them effectively making it hard to enter and compete. The current big players want launching a new llm product to be more like opening a new bank than opening a lemonade stand based on the ai executive order released yesterday. reply donmcronald 15 hours agorootparentprevGive me the citations every day of the week. The source of information matters. For example, I don&#x27;t rely on any ZFS info or opinions I find online if I can&#x27;t verify it came from a contributor or highly reputable person that has a lot of experience with ZFS.If you want to show the warts of all these LLMs, ask it about ZFS if you know enough to spot the commonly parroted misinformation that plagues the internet.IMHO, these systems look super useful if they&#x27;re citing sources and they&#x27;re worthless without. reply ErikBjare 4 hours agorootparentFunny you bring up ZFS specifically. I embarrassed myself a couple weeks ago by parroting something GPT-4 told me about ZFS to someone on reddit, which turned out to be completely wrong. reply slowhadoken 14 hours agorootparentprevTransparency is paramount. If OpenAI doesn&#x27;t want to make it&#x27;s proprietary software open to academic scrutiny I completely understand. However, if their app is going to play an educational role then sources and citation are mandatory in academic content. reply slowhadoken 15 hours agorootparentprevwhy not both? reply joaodias 20 hours agoprevAsked it to write a program that I&#x27;ve written before, to compare with gpt4. Didn&#x27;t really get what I was asking for, gpt4 understood it perfectly, and is ready to continue prompting toward completion.https:&#x2F;&#x2F;www.phind.com&#x2F;agent?cache=cloeowfla000dl1084ermly3c vs https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;4147da33-3669-4657-88fa-3a9dfc...Might not be representative of the whole thing, but it went on about random things I didn&#x27;t ask about, and just basic information I already knew reply rushingcreek 20 hours agoparentThe Pair Programmer mode currently either uses GPT-4 or GPT-3.5 (if you&#x27;ve run out). Please try again in the default search mode to use the Phind Model.Using the Phind Model in the default search seems to work well: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=ln6dpdtv5auwn4cq1ofg3gs9 reply joaodias 12 hours agorootparenthttps:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=z5odlx0o9lspzpfm4sfpp131Way way better, I&#x27;m stunned. Congratulations on this reply Capricorn2481 18 hours agorootparentprevEven though the phind model is selected? Is there a technical reason Phind doesn&#x27;t do pair programming yet? reply rushingcreek 18 hours agorootparentIt&#x27;s because we haven&#x27;t updated the Phind Model to support function calling yet but we&#x27;re working on it. reply Capricorn2481 18 hours agorootparentCan you share what your long term monetization model is? I&#x27;m noticing Phind is free to use right now. reply rushingcreek 17 hours agorootparentWe have a Pro plan where you can get (virtually) unlimited GPT-4 and soon, an even faster Phind model. https:&#x2F;&#x2F;phind.com&#x2F;plans reply Capricorn2481 9 hours agorootparentIs there something you&#x27;re doing with GPT-4 that would make me want to use it through you vs just using it myself? replyTheGeminon 20 hours agoparentprevThe problem is that it’s doing a search of your relatively niche problem, and probably getting pretty poor results. The text from the search is then more highly weighted than the base model, but with relative junk, so it performs better without the additional (unhelpful) context.You see this with Bing search on ChatGPT as well, and I’ve seen it in my own projects. reply ojosilva 17 hours agoprevAwesome model from a quick run-through comparison, it&#x27;s comparable in results to GPT-4 with web search and references as a plus, but runs faster. Two small nitpicks:- Dark mode is hard to read, the answer text font has too much weight and brightness which makes it hard to read long paragraphs of non-code text. Light mode is obviously too bright overall, but it&#x27;s already nighttime where I&#x27;m at so maybe tomorrow at noon I&#x27;ll have another opinion. I&#x27;d preferred gray (dark, ie OpenAI) and sepia (light, ie HN) as backgrounds when long lines of text are involved.- Pricing page and ties to GPT-4: what does \"500+ best model uses per day (GPT-4)\" mean? What&#x27;s the \"GPT-4\" part for? I saw I can pick GPT4 as a model on the landing page, but I just don&#x27;t get the best model&#x2F;GPT-4 thing. Is Phind announcing it&#x27;s a competitor but also proxies GPT-4? Sorry, I&#x27;m not up-to-date on GPT-4 \"resellers\" and the story behind Phind, it&#x27;s just weird when it announces it \"beats GPT-4\" then the pricing is about GPT-4 usage. reply rushingcreek 17 hours agoparentThanks for the feedback. We also support GPT-4 as an answering model so users can pick and choose what&#x27;s best for their use case, but we recommend the Phind Model for the majority of users. reply donmcronald 15 hours agorootparentWhy is there an 8x difference in price-per-search between Plus and Pro?I always shy away from stuff like this because I view it as one of two things. Either I&#x27;m getting ripped off if I pay for Plus, because 8x the cost to me means your margin is huge, or I&#x27;m getting subsidized by you with the Pro version which means I can&#x27;t rely on it lasting long term.I also dislike daily limits for search. My search usage isn&#x27;t uniform day-to-day. I might go most of the month without searching for anything and then do a ton of searching over 2-3 days when I&#x27;m trying to learn something. So I&#x27;ll be idle most of the month and then not have enough searches on the days I actually want to use it.I prefer the model used by a lot of pre-paid services. Let me deposit a chunk of money (ex: $20-50 minimum) and charge me per search until my money is gone. That way I&#x27;m not \"losing out\" if I don&#x27;t use it every day and I can \"burst\" as high as I want when I&#x27;m trying to learn something.If the pricing is based on a certain amount of loss (on my side) from the use-it-or-lose it model, I don&#x27;t like that. I want simple, fair pricing, not a complex pricing scheme where the primary purpose is to get me to overpay for my usage. reply ezekiel68 12 hours agorootparentPlenty of people know their upper limit. The ability to pay 50% less if that limit applies is a feature, not a bug. (This applies to any service -- I am not affiliated with phind except as an occasional user). reply rushingcreek 15 hours agorootparentprevPhind Plus is $15&#x2F;month and Phind Pro is $30&#x2F;month. There is a 2x price difference, not an 8x difference. And Phind Pro comes with (virtually) unlimited GPT-4 uses.We understand that the incentives of setting daily limits for search aren&#x27;t great, which is why the Phind model is unlimited for free. GPT-4, however, is unfortunately too expensive for us not to charge past a certain usage threshold. reply donmcronald 15 hours agorootparentPlus costs $0.016 per search and Pro costs $0.002 per search.https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=wgyz13tg4jkbl9pklptmpds5 reply ojosilva 14 hours agorootparentTo me the $15&#x2F;mo plan is just bait so users pick the target $30&#x2F;mo month. Why would you pay $0.016&#x2F;search when you can pay 8x less and feel smart about making that choice?edit: looking at it again, I think the $15&#x2F;mo is actually just for people who wants Phind \"private\", so that their data is not used for training. reply nick-sta 14 hours agorootparentprevCost per search isn&#x27;t really a great metric. For me, I hit the cap of 30 searches&#x2F;day pretty easily, but 500 is pretty hard to hit. For me, its just a question of what tier matches my volume. replyaccrual 20 hours agoprev> it supports up to 16k tokens> Llama 1 supports up to 2048 (2K) tokens, Llama 2 up to 4096 (4K), CodeLlama up to 16384 (16K). [0]This is wild to me.The token window is one of the limiting factors for having an AI that can actually remember you and past conversations. Having a large window is key for future AI applications that involve long running conversations (weeks, months, years). The tech is already very impressive, but imagine it as it becomes more like an actual pair programmer and remembers all the various things it&#x27;s learned and worked on with you in the past.[0] https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;main&#x2F;model_doc&#x2F;llam... reply seydor 19 hours agoparent640k is enough for anyone reply happycube 14 hours agorootparentExtending that analogy, imagine what one could do with 128B tokens.On cast off&#x2F;cheap workstation&#x2F;server hardware. reply mycall 20 hours agoparentprevToken window size is being virtualized with the like of MemGPT, so its effect will diminish. reply Der_Einzige 20 hours agoparentprevStill waiting for the day that medium term memory (token average pooling like in sentence transformers) becomes used for this. It&#x27;s staring all of these companies in the face and apparently no one thinks to implement it. reply heavyarms 20 hours agorootparentI&#x27;ve been thinking along the same lines. The token window IMO should be a conceptual inverted pyramid, where there most recent tokens are retained verbatim but previous iterations are compressed&#x2F;pooled more and more as the context grows. I&#x27;m sure there&#x27;s some effort&#x2F;research in this direction. It seems pretty obvious. reply matsemann 19 hours agorootparentBut some of the earlier tokens are also the most important ones, right? Like the instructions and rules you want it to follow. reply visarga 9 hours agorootparentPhrase embeddings could bring a 32x reduction in sequence length because:> Text Embeddings Reveal (Almost) As Much As Text. ... We find that although a naïve model conditioned on the embedding performs poorly, a multi step method that iteratively corrects and re embeds text is able to recover 92% of 32-token text inputs exactly. We train our model to decode text embeddings from two state of the art embedding models, and also show that our model can recover important personal information (full names) from a dataset of clinical notes.https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.06816 reply a_wild_dandan 18 hours agorootparentprevThey are. Moreover, the idea that AI companies are missing and&#x2F;or not implementing this “obvious” tactic is hilarious. Folks, these approaches have profound consequences for training and inference performance. Y’all aren’t pointing out some low hanging fruit here, lol reply Der_Einzige 16 hours agorootparentActually, yes I am pointing out low hanging fruit here. These approaches do not have \"profound consequences\" for inference or training performance. In fact, sentence transformer models run orders of magnitude more quickly. Performance penalties will be small.Also, I actually have several top NLP conference publications, so I&#x27;m not some charlatan when I say these things. I&#x27;ve actually physically used and seen these techniques improve LLM recall. It really actually works.Here&#x27;s more examples of low hanging fruit. The proof in that they work is in the implementations which I provide. You can run them, they work!: https:&#x2F;&#x2F;gist.github.com&#x2F;Hellisotherpeople&#x2F;45c619ee22aac6865c...Check yourself before you try to check others. reply pbronez 2 hours agorootparentConcur. LLM are still very young. We’re barely a year out from the ChatGPT launch. Everyone is iterating like mad. Several stealth companies working on new approaches with the potential to deliver performance leaps.You ain’t seen nuthin’ yet… replybrrrrrm 20 hours agorootparentprevOut of curiosity, why do you think the answer would be so simple and also completely untested? reply Der_Einzige 16 hours agorootparentToo much money being thrown around on BS in the LLM space, hardly any of it is going to places where it matters. Ignorance on the part of investors.For example, the researchers working hard on better text sampling techniques (i.e. https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.00666), or on better constraint techniques (i.e. like this https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.03081), or on actual negative prompting&#x2F;CFG in LLMs (i.e. like this https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;transformers&#x2F;issues&#x2F;24536) are doing far FAR more to advance the state of AI than dozens of VC backed LLM companies operating today. They are all laboring in relative obscurity.HN, and the NLP community have some serious blindspots with knowing how to exploit their own technology. At least someone at Andreessen Horowitz got a clue and gave some funding to Oogabooga - still waiting for Automatic1111 to get any funding. reply fullstackchris 20 hours agorootparentprevAnother curiosity, what do we estimate (if it&#x27;s even possible) the context window of a human? Obviously an extremely broad question, and of course it must have some sort of decay factor... but... would be interesting to get a rule of thumb number in terms of token count. I can imagine its massive! reply travisjungroth 19 hours agorootparentHuman memory, in my limited understanding, doesn’t have the bifurcation of weights and context that LLMs do. It’s all a bit blurrier than that.Something interesting that I heard from people trying to memorize things better is that memory “storage space” limits for people are essentially irrelevant. We’re limited by our learning and forgetting speeds. There’s no evidence of brains getting “full”.Think of it like a giant warehouse of plants, with one employee. He can accept shipments (learning). He can take care of plants (remembering). Too long without care and they die (forgetting). The warehouse is big enough that it is not a limiting factor in how many plants he can keep alive. If it was 10x bigger it wouldn’t make a bit of difference. reply Filligree 19 hours agorootparentprevI don&#x27;t think it&#x27;s massive. In fact, since it&#x27;s roughly equivalent to working memory, I suspect it&#x27;s on the order of 100 tokens at most.It&#x27;s just that, unlike these AIs, we&#x27;re capable of online learning. replyxrd 20 hours agoprevI know it isn&#x27;t popular, but I wish there was a way to use this inside Emacs. Or, vim. I just don&#x27;t want to use VS Code anymore. reply freedomben 20 hours agoparentThe standardizing on VS code is one of the saddest developments over the last several years IMHO. I think it&#x27;s great that VS Code exists, but we&#x27;re headed for a world where you have to use VS Code if you want the best tooling because it won&#x27;t support other options. The same thing happened with Java dev and IntelliJ, and IMHO it has been extremely unhealthy for the ecosystem. I&#x27;m immensely glad that Copilot supports vim, but I&#x27;m fearful that it soon won&#x27;t. reply papichulo2023 18 hours agorootparentDidnt vscode standardise language servers making much easier for all the rest text-editor-close-almost-ides to integrate? Is it really that sad? reply freedomben 17 hours agorootparentVery fair point. Vim has benefited tremendously from that effort. reply selfhoster11 5 hours agorootparentprev> The same thing happened with Java dev and IntelliJ, and IMHO it has been extremely unhealthy for the ecosystem.While I agree, at the very least IntelliJ stood up on its own as a good IDE. I cut my baby teeth on Eclipse, and as soon as I realised how good IntelliJ is, I jumped ship without looking back. The same can barely be said about VS Code. reply FreezerburnV 20 hours agorootparentprevSame could have&#x2F;could be said about Jetbrains products. People are likely always going to use vim&#x2F;emacs and create tooling around whatever new hotness exists for them. And honestly? VS Code is just a new iteration on how vim&#x2F;emacs work in a lot of ways: Providing a place to edit text and then a bunch of plugins that do things with that text.And if you want vim&#x2F;emacs to keep living, then you should spend time helping! Create your own extensions, maintain&#x2F;contribute to existing ones, etc. They will only die out when the last person actively contributing to them stops, so keep the chain of people going :) reply Jeff_Brown 20 hours agoparentprevIf only the depth of our feelings for Emacs counted for more in the market.There&#x27;s an argument that music and the arts are dumbed down by the fact that, for instance, making an album worth $10 to millions of people pays way better than making an album worth a million dollars to tens of people, since the album is going to get priced at $10 one way or the other. It only just now occurred to me that the same phenomenon applies to tools. reply regularfry 6 hours agoparentprevI&#x27;ve hacked together a basic Emacs ollama api integration that does simplistic code completion against a local LLM from someone else&#x27;s copilot example. It&#x27;s slower than I want (about 7 seconds per inference on my M1 mac, typically) and very stupid about what context it sends, but nevertheless: it&#x27;s just, and only just, enough to be useful. Hadn&#x27;t considered publishing it because it relies on a python façade to convert copilot-style requests and responses back and forth to ollama, but if there&#x27;s interest I&#x27;ll spruce it up and get it out. reply regularfry 6 hours agorootparentFrom downthread, just use ellama. They&#x27;re further ahead than me by the looks of things. reply mg 20 hours agoparentprevIn Vim, I tried to assign a shortcut to send the selected text to Phind (or any other LLM) and came up with this::&#x27;y|call system(&#x27;firefox ?q=&#x27;.shellescape(@*).&#x27; &&#x27;)The only problem left is that the text is not urlencoded.There probably is some elegant way to urlencode it. But I did not come up with one yet. reply wizzwizz4 18 hours agorootparenthttps:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;76488059 claims to have one, though it&#x27;s not explained. reply bigdict 20 hours agoparentprevPretty sure GitHub Copilot has emacs&#x2F;vim integration. reply freedomben 20 hours agorootparentIt does, although not the most recent features. I use the compatible features in Vim and I really like it. Not enough to switch editors though. reply accoil 17 hours agoparentprevMaybe ellama[1] would work? It doesn&#x27;t support Phind yet, but a provider could be created for the underlying connection package llm[2].[1]: https:&#x2F;&#x2F;github.com&#x2F;s-kostyaev&#x2F;ellama[2]: https:&#x2F;&#x2F;github.com&#x2F;ahyatt&#x2F;llm reply notpublic 20 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;github&#x2F;copilot.vimhttps:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;llm.nvim reply haarts 20 hours agoparentprevYou and me both brother. LSP integration seems the way forward. reply fictorial 20 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;CoderCookE&#x2F;vim-chatgpt reply BugsJustFindMe 20 hours agoprev> You can now get high quality answers for technical questions in 10 seconds instead of 50.ChatGPT 4 does not take 50 seconds to answer, so I don&#x27;t understand this comparison. reply bethekind 20 hours agoparentRecently I&#x27;ve used gpt 4 and yes it does take up to a minute even for easy questions.I&#x27;ve asked it how to scp a file on Windows 11 and it&#x27;ll take a minute to tell me all the options possible.If this takes 1&#x2F;5th the time for equivalent questions, I&#x27;d consider switching reply joshspankit 20 hours agorootparentNot my experience at all. Are you counting the entire answer in your time?If so, consider adding one of the “just get to the point” prompts. GPT4’s defaults have been geared towards public acceptance through long-windedness which is imo entirely unnecessary when using it to do functional things like scp a file. reply theWreckluse 20 hours agorootparentLOL, it’s not just for “public acceptance”. Look up Chain of Thought. Asking it to get to the point typically reduces the accuracy. reply freedomben 20 hours agorootparent> LOL, it’s not just for “public acceptance”. Look up Chain of Thought. Asking it to get to the point typically reduces the accuracy.Just trying to provide helpful feedback for you, this would have been a great comment, except for the \"LOL\" at the beginning that was unnecesary and demeaning. reply bigfudge 18 hours agorootparentprevYou are being snarky but are right. I have scripts set up to auto summarise expansive answers. I wish I could build this into the ChatGPT ui though. reply maccard 4 hours agorootparentI know this is silly, but I&#x27;ve had great success asking chatgpt to summarise chatgpt&#x27;s answers. reply idonotknowwhy 15 hours agorootparentprevTry the custom instructions feature reply londons_explore 20 hours agorootparentprevThe words \"briefly\" or \"without explanation\" work well.By keeping the prompt short, it starts generating output quicker too. reply phillipcarter 20 hours agorootparentprevYeah, I would say this is a prompting problem and not a model problem. In a product area we&#x27;re building out right now with GPT-4, our prompt (more or less) tells it to provide exactly 3 values and it does that and only that. It&#x27;s quite fast.Also, use case thing. It is very likely the case that for certain coding use cases, Phind will always be faster because it&#x27;s not designed to be general purpose. reply furyofantares 20 hours agorootparentprevThis isn&#x27;t a fair comparison because I have custom instructions that mention being brief but complete, but I did \"how to scp a file on Windows 11\"ChatGPT4: 14 secondsphind with \"pair programmer\" checked: 65 secondsphind default: 16 seconds reply BugsJustFindMe 20 hours agorootparentprev> I&#x27;ve asked it how to scp a file on Windows 11 and it&#x27;ll take a minutehttps:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;iqxOJUV was 6.5 seconds.https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;pQFfWli was 15.You can tell they&#x27;re GPT-4 because the logo is purple (the logo is green when using 3.5). reply JoshGlazebrook 20 hours agoparentprevChatGPT4 is more often than not noticeably slow enough that I question why I pay for it. reply shmoogy 18 hours agorootparentSometimes it&#x27;s insanely quick - like gpt3,5 turbo or a cached answer or something. reply rushingcreek 20 hours agoparentprevWe find that it takes around a minute for a 1024-token answer. Answers to less complex questions will take less time, but Phind will still be 5x faster. reply selfhoster11 5 hours agoparentprevThat really depends on the complexity of your request and any prompt engineering techniques in use for that request. Especially with \"think step by step\" in certain contexts, it can improve answer quality at the expense of generation time (because more tokens are emitted). reply eoinboylan 20 hours agoprevRan a quick test with a Rust async code snippet that contains an error. Compared with GPT-4 its gives a far clearer solution, with linked sources to learn more! Super impressive! reply rushingcreek 20 hours agoparentAmazing, that&#x27;s great to hear. reply passion__desire 20 hours agorootparentIs it possible to output all steps of solutions in a single copyable block? I don&#x27;t want to copy 4 separate blocks. reply ezekiel68 12 hours agorootparentWhen I use it I often give a final prompt like \"Now combine the above answers together into a function that accept the following arguments...\". This has worked well for my use cases. reply rushingcreek 20 hours agorootparentprevYou can tell it that in a followup. Or, configure an answer profile and tell it to use that style: https:&#x2F;&#x2F;phind.com&#x2F;profile. reply buildbot 20 hours agoprevWell, neither GPT4 or this Phind model where able to answer my torture test: \"Write amaranth code that can be used to control the readout of a frame from a kodak CCD with 4096 columns and 2048 rows.\"Which yes, is missing a lot of detail (you could&#x2F;I have feed&#x2F;fed in a datasheet).But Phind goes off on using pyserial (?!), and GPT4 assumes amaranth is a hypothetical CCD control library and makes a useless class control CCD using the hypothetical library.Edit - Phind at least acknowledged that amaranth exists, unlike GPT4 with this prompt: \"Write amaranth code that can be used to control the readout of a frame from a kodak CCD using an lattice FPGA with 4096 columns and 2048 rows. Assume the design will be hooked up to a larger litex SoC \" reply mensetmanusman 20 hours agoparentThat’s torture for humans as well. The key to LLMs is communicating clearly to the information cloud. reply buildbot 18 hours agorootparentSure, but a good example of how far certain domains have to go still. These datasheets should be in the models training data, at least one CCD datasheet, and verilog & (migennmigenamaranth) certainly are.Controlling a CCD is actually pretty easy, I built (very simple, but working) controllers for several CCD chips in undergrad doing research for the ATLAS detector. You just clock a rows out basically, N columns times. Reset first. I&#x27;d expect an senior undergrad EE student to be able to design a simple core in a few class projects. reply idonotknowwhy 15 hours agoparentprevI have no idea what that means (even after googling it) lol. This is how my local WizardLM-70B responded to your prompt.https:&#x2F;&#x2F;pastebin.com&#x2F;BCAthV8y reply tinco 20 hours agoprevWill you be offering the model as an API service? The product my team is working on would benefit from a significantly faster and possibly better performing model than GPT-4. If you&#x27;re planning on keeping pace with competitive models we&#x27;d love to integrate the use of your model into our service. reply rushingcreek 20 hours agoparentIf we get enough demand that&#x27;s definitely something we&#x27;ll consider. We&#x27;re still a small team, however, and we do everything in our power to not get distracted from our main mission. reply ilaksh 18 hours agorootparentPlease consider releasing an API. Having a faster alternative to GPT-4 would be amazing for so many use cases.Especially for agents that do function calling. reply mike_hearn 19 hours agorootparentprevIf you offer an API then you can be used with tools like https:&#x2F;&#x2F;aider.chat&#x2F;, which is the best way to use LLMs for coding. But if only available via the web it&#x27;s not possible. BTW this is the main reason I pay for the OpenAI API. reply tinco 20 hours agorootparentprevMakes sense, we&#x27;re also very small (pre-seed) so definitely no cash cow for you guys yet. We probably shouldn&#x27;t be prematurely optimizing our prompting performance as it&#x27;s not really a bottleneck, but a 4x improvement just by swapping an API would be too good not to act on. reply halfjoking 7 hours agorootparentprevIf you offer an API you don&#x27;t have to maintain a Visual Studio plugin. Trying to compete with tools like Cursor would be the real distraction.And Cursor is just the start - there will be innovative workflows built on top of APIs you can&#x27;t predict. You&#x27;re missing out not having developers build an ecosystem for you. reply hasoleju 6 hours agoprevI don&#x27;t use LLMs in my workflow frequently. When I do I have a hard time making sense out of the very specific and long answers to my questions. Especially if I don&#x27;t know the answer it is hard to figure out if the long answer of the model indicates the right direction or misses my point completely.Maybe I&#x27;m not knowledgeable enough. But asking questions I already know the answer of has no real life use case other than testing the model. Which of course might be a valid use case for some.Having a way to let the user specify his own level of knowledge might help to receive answers that are better tailored to the user asking the question. reply lysecret 6 hours agoparentHave you tried custom instructions ? I use this:My dad always used to say: Everything that can be said, can be said simply. I prefer top-down structured, short and thoughtful responses. reply dontreact 20 hours agoprevI tried this question and GPT4 did way way better to getting closer to a final answer. Phind was horribly wrong. I can&#x27;t help but think something seems off with your eval given just how badly Phind did on this.I want to make an interactive plot in Colab where I can showX axis is interest rate of a 15 year mortgage. Y axis is the relative advantage of buying a house vs. renting in terms of total net worth at 15 years.Assume a monthly budget for renting + investing or buying a house of 10kPlot different lines for a few different market returns.Make a slider that controls the total size of the loan. reply rushingcreek 20 hours agoparentSeemed to give plausible results for me: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=lswmiuewv2l33jt337dgrsho reply dontreact 18 hours agorootparentdef calculate_relative_advantage(interest_rate, loan_size, market_return): # Your calculation logic here passChat gpt actually implements it reply letitgo12345 9 hours agorootparentJust prompt it to implement the function reply elif 14 hours agoprevHmm I wonder what kind of code quality can be accomplished by looping from phind->gpt->copilot for multiple iterations, asking for criticisms of the code qualities then seeking code which addresses the ai-generated criticisms etc until it knocks out better than I would in a second. reply sagarpatil 10 hours agoparentYou could cook something like this using Microsoft Autogen. It does allow you to daisy chain the models. reply rushingcreek 13 hours agoprevPhind co-founder here! Here&#x27;s a link to our blog post: https:&#x2F;&#x2F;www.phind.com&#x2F;blog&#x2F;phind-model-beats-gpt4-fast reply archibaldJ 13 hours agoparenthi; great work. so is this more fine-tuning on Phind-CodeLlama-34B-v2?will there be api access soon?also: will it be open-source at some point? thanks reply rushingcreek 13 hours agorootparentThank you. Yes, it is the 7th iteration that started with our open-source models. We do plan to open source this model as well down the road, once we&#x27;ve released a few more generations.API access is on the roadmap but we have no time estimates for when we will build it. We&#x27;re trying to not get distracted from our main mission :) reply archibaldJ 12 hours agorootparentI see. Thanks!So Phind&#x27;s main mission is to overtake Google right? ;) reply lgkk 18 hours agoprevFirst off, congrats on building such a cool product. I love that I can just \"jump into it\" which is great.Note that I&#x27;m not really a power user of these GPT style tools- here are my questions:Is it possible to get right to the code without the ELI5 and general information?Do you guys offer an API? I was browsing on my small iphone so maybe I missed this info.Could you give an overview for someone like me how something like phind works technically? You mentioned those H100s, but at a very high level without revealing any \"secret sauce\" how does this GPT work from my input to getting a response?Good luck! reply quickthrower2 18 hours agoprevCould you open source these great models? OK yes you need a competitive advantage. So maybe open source them when you are say 2 models ahead in production?In any case I am happy there is some competition and that it has come from a more pragmatic scrappy space than one of the multiple billion dollar funded places. reply sounds 18 hours agoparentCan we have a larger discussion about the tradeoffs that come with open sourcing a model?When fb released Llama they obviously gained a huge amount of developer goodwill but it also required them to invest a serious amount of their own developer time to engage with the community.I&#x27;m asking the community what it can offer the company? Or is this just self-abnegation by the company that releases the model? reply selfhoster11 5 hours agorootparentI question the word \"required\". They, or anyone else releasing an open source product into the world, doesn&#x27;t owe anyone anything, least of all support. As long as there are enough instructions to run the thing, you are perfectly within your rights to let the community sort out the rest between themselves. reply poser-boy 16 hours agoparentprevI don&#x27;t know what model runs on Phind&#x27;s site right now, but in August Phind published a fine tune of CodeLlama 34Bhttps:&#x2F;&#x2F;huggingface.co&#x2F;Phind&#x2F;Phind-CodeLlama-34B-v2 reply mtkd 20 hours agoprevBeen using Phind for a bit now and started paying for proThey&#x27;re smashing it and can&#x27;t do enough if you report an issue, also they have started a weekly voice call to discuss algos and such with senior devs, like a surgery, only 10 people join at momentDon&#x27;t think I&#x27;ve ever recommended anything as much as I have these guys in last couple of months reply shazar 19 hours agoprevI gave it two tries, GPT-4 was much better in both cases. Tried with two Leetcode questions. It came back with an empty response for one, and provided a worse code (O(n2) solutions when it can be done with linear time) for the other one.GPT-4 on the other hand provided a good answer for both questions. Also I guess the UI is buggy w.r.t code formatting, it things the following line is a code and switches to a code block.``` You are given an array prices where prices[i] is the price of a given stock on the ith day. ```The only downside for GPT-4 for me right now, is its slowness. reply popularonion 18 hours agoparentGPT-4 has ingested all of Leetcode, you can literally just type \"leetcode 100 python\" and it will regurgitate a response for you.Only exception I found is with some of the Leetcode Premium questions, you might have to actually type in the problem statement, but it&#x27;s still very likely that multiple solutions have been ingested from GitHub and elsewhere. reply rushingcreek 19 hours agoparentprevI suggest you try enabling \"Ignore search results\" from the model dropdown for these types of questions. The web results can be distracting for the model for Leetcode-type questions. reply doctoboggan 18 hours agorootparentI see you&#x27;ve had to suggest this a few times in this thread, and in my experience I would agree with the suggestion. I wonder if you can have a simple gpt model decide automatically when ignoring search results would improve the result and do it automatically. reply rushingcreek 18 hours agorootparentInteresting idea. reply shazar 18 hours agorootparentprevI tried with that option enabled and now it can&#x27;t generate code at all. Here&#x27;s my prompt:``` You are given an array prices where prices[i] is the price of a given stock on the ith day.Find the maximum profit you can achieve. You may complete at most two transactions.Note: You may not engage in multiple transactions simultaneously (i.e., you must sell the stock before you buy again).Write Python code to solve this: def maxProfit(self, prices: List[int]) -> int: ```Output:``` It seems like you want to find the maximum profit that can be achieved by buying and selling stocks, with the constraint that you can only make at most two transactions. Is that correct?Could you please provide some example input and output to help me better understand your requirements? ```I also tried a more basic prompt, but the output is not what I&#x27;d consider good code.Can you maybe share some examples where we can see how it exceeds GPT-4&#x27;s capabilities? Thanks! reply rushingcreek 18 hours agorootparentSeemed to work well just now: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=w1jyatqyia1a8r3pfxlxqby6 reply mediaman 17 hours agorootparentprevIn my own RAG implementations in the industrial sector, I&#x27;ve found it effective to first have the AI decide whether it needs to search at all. If it doesn&#x27;t, the answers are much better. reply notadev 18 hours agoprevI use Phind daily, including the VSCode extension, and I love it. Much better than anything ChatGPT is able to come up and the code it generates requires little-to-no modification to work properly. Very big fan! reply rekubot 1 hour agoparentFar as I can tell it isn&#x27;t possible to hook up the VSCode extension to the Phind model, only GPT-4. Do you know any different? reply schmorptron 17 hours agoprevI&#x27;ve been a pretty heavy user of phind and have been very satisfied! Haven&#x27;t been using it to write code for me but to ask about features and docs and it&#x27;s been pretty incredible. reply scarface_74 18 hours agoprevI was just discussing using ChatGPT to make working with deploying serverless code easier.I gave this as an example“create a CDK typescript app that deploys a lambda + API Gateway where the lambda works with Get request and a dynamodb table. The lambda should have permission to read and write to the Table”It wrote the code perfectly. I wanted to see if it was trained on the AWS APIs. reply sagarpatil 10 hours agoprevI&#x27;ve been using GPT-4 for coding since it&#x27;s launched. I did try Phind when you launched it with GPT4 and found it useful but I use VS Code and hate having to switch. I see you do have a VS Code extension now (great job!). I tried the phind model and at first glance it definitely looks better than GPT-4 wrt coding. Do you have any plans to provide this model as an API? reply smusamashah 6 hours agoprevHi, is there any plant to improve the UI? About 1&#x2F;3rd of vertical space is used by phind logo and the search box below it. I sincerely believe it needs some professional&#x2F;business touch on its UI. reply deegles 17 hours agoprevWhat&#x27;s the best way to use an LLM with a large codebase that isn&#x27;t RAG? Ideally we could have the full source in the context or already trained into the model... I was thinking I could set something to fine tune a model overnight and every morning I&#x27;d have a fresh one ready. Any ideas? reply mistercow 20 hours agoprevSo I gave it this prompt:> I need a typescript function which takes in an object with an id string property and a string message property, and also takes an array of search strings, and returns a mapping of search strings to matching message idsThe response I got was close, but it assumed that each search string would match only one message, so it returned Record. I fed this to GPT-3.5 and it answered 10x faster with the correct return type.This is a slightly tricky example, because it requires the model to infer that multiple message matches are possible. But I think that it’s interesting that ChatGPT nailed it despite not using any chain of thought. reply starbugs 19 hours agoparent> I need a typescript function which takes in an object with an id string property and a string message property, and also takes an array of search strings, and returns a mapping of search strings to matching message idsYour prompt is wrong. You want a function that takes an array of id&#x2F;message objects, not an object.It&#x27;s quite impressive that GPT is just able to correct for that. As a human, I would first ask what you actually mean, because your prompt appears to be unclear. reply smusamashah 8 hours agoprevPhind can be very good for general tech searches too. I spent long time looking for a way to disable my Pixel 4a from auto updating to android 14 (which it has already downloaded). With Google I only found one solution which disables update on restart. I asked the same in Phind and in one query I have got around 4 solutions [1].[1]: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=vtzigjx3rnruc9ltocv9gqi1 reply seidleroni 21 hours agoprevThe results I get are so-so. The rubric I use to evaluate coding LLM&#x27;s is to ask it to create a Python script that determines if the contents of a given directory have been changed since the last time the script was run. This should be done recursively and handle files being added, removed, or modified and be based off the contents of the files and not the timestamps.When I ask it as one statement it performed ok, but if I made more specifications with follow-up statements, it kept trying to go down one path even though I told it to do it a different way. A solid start but it definitely needs some improvements, IMO. reply jiggawatts 20 hours agoparentThis is a problem that human programmers screw up… regularly.E.g.: the efficient and robust file change monitoring on Windows is to read the NTFS change journal. For a single process lifetime there are other change notification APIs as well. Most software does neither and is either very slow or misses changes… reply rushingcreek 21 hours agoparentprevThanks for the feedback. We&#x27;re working on improving consistency and precise instruction following in followups. reply webappguy 7 hours agorootparentIf you can make this best in class for code outside just human eval, wow, that&#x27;s the differentiator. Add cursor, replit and vscode support after. But best in class for code, it would be my daily driver reply benxh 20 hours agoprevI can&#x27;t wait to see this open sourced, there&#x27;s a lot of sampling strategies that help coding.And I also can&#x27;t wait to see how much Phind will improve further if the Glaive dataset is added onto it.Edit: Contrastive search, dynamic temperatures. reply throwaway4good 8 hours agoprevPlaying on the other AI prompt thread (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38089247) here on HN I tried:\"write me an angry birds clone using JavaScript and the matter physics library\"And I really enjoyed the answer; in particular that it would show the sources for it - making it obvious how close its answer is openly available tutorials.This is much better than a black box pretending to do black magic. reply andai 18 hours agoprevTo the folks in this thread comparing the model with GPT-4, are you comparing it with GPT-4 in ChatGPT, or with GPT-4 on Phind? Because it should be the latter for a fair comparison. The Phind response seems to be heavily based on the top search results, which may affect the quality of the response.(An even more interesting question would be to compare ChatGPT GPT-4 with Phind GPT-4, i.e. GPT-4 with relevant web results in context.) reply blago 19 hours agoprevIt failed for me at a much more basic level.I asked 5 different, and increasing explicit, variations of the following question: \"Can you generate HTML and CSS for a JPG mockup I&#x27;m going to give you?\"Each time it answered along the following lines: \"Sure, here is how you can create HTML and CSS from a JPG mockup. Follow this process...\"In my experience this never happens with GPT-4. reply pbhjpbhj 18 hours agoparentI&#x27;ve not seen that anywhere, ChatGPT does image input now? Do you have examples of the output from feeding it a JPEG? reply atleastoptimal 12 hours agoprevJust a reminder GPT-4 is almost 1.5 years old at this point (from before they started internal safety testing), and even the one we have is diminished from the first, uncensored version. reply theage 20 hours agoprevPretty big jump for java eval, what is the reason for java being so notoriously difficult for LLMs? never mind I asked phind[1] and it said all the complexity... but do you have any tips or tricks for working with that language in your model?[1] https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=u3mnj3iwmjvgqlyf60bnbqo1 reply johnfn 19 hours agoprev> Phind Model beats GPT-4 at codingDoes it? I don&#x27;t see any evidence of this strong claim in your post, and I think it&#x27;s quite deceptive how the only link is to a benchmark of open source models (which doesn&#x27;t include GPT-4). I&#x27;ve tried Phind a few times in the past when it made equally strong claims and been somewhat unimpressed. (To be fair, comparing anything to GPT-4 is tough!) I think it would strengthen your position significantly to simply say that you&#x27;re the best of all open-source models.To be honest though I&#x27;ve been completely ruined by https:&#x2F;&#x2F;cursor.sh&#x2F;; copying and pasting results back and forth from a web UI to my IDE is so painfully slow when you do it tens or hundreds of times that I don&#x27;t think I would be able to go back. I&#x27;d be happy to try out a Phind extension that has similar UI&#x2F;UX if you ever make one. reply varunvummadi 6 hours agoparentThat is true cursor extension is awesome reply wanderingmind 4 hours agoprevIs the Phind model available outside of phind.com as an api or are weights available for fine tuning? reply aquarin 4 hours agoprev> \"Am I talking to real person?\" >> \"Yes, you are talking to a real person...\" reply ShakataGaNai 18 hours agoprev\"Python script to extract a list of all Elastic IP&#x27;s from all regions, from multiple AWS accounts.\"ChatGPT4 gave me a solid answer hitting all the points I wanted. Phind din&#x27;t get the account handling correct, didn&#x27;t address regions, and didn&#x27;t handle pagination.\"Write a python based script that uses boto3 to query AWS Route53. It should print a list of every record for a given hosted zone ID.\"ChatGPT4 did exactly as requested with pagination, and even smartly decided to use \"input\" so I could give it a zone ID at run time. Phind didn&#x27;t handle pagination, or do ANY error handling. It was also slower than ChatGPT4 to generate currently, and it wasn&#x27;t in a single block of copy&#x2F;pasteable code.ChatGPT&#x27;s solution worked without modification. Copy-Paste. Run. reply rushingcreek 18 hours agoparentJust worked well for me: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=g9y2uizgjwcn378aovb65v92.We do have issues with consistency sometimes -- please try regenerating if that is the case. reply scarface_74 17 hours agorootparentYour example didn’t include pagination. reply facu17y 18 hours agorootparentprev\"We do have issues with consistency sometimes\" That&#x27;s a strange statement. Having issues with consistency means that sometimes the output is wrong. What does it mean to have issues with consistency sometimes ? You&#x27;re either consistent or you&#x27;re not. reply rushingcreek 18 hours agorootparentThere&#x27;s a difference between models that are incompetent and aren&#x27;t capable of getting the right answers ever and models that are capable of getting the right answer but may not do so every time. The Phind Model is in the latter camp.Consistency issues can be caused by a wide range of factors from inference hyperparameters to prompting. reply facu17y 18 hours agorootparentI meant that saying \"something is inconsistent sometimes\" is weird because inconsistency implies \"sometimes\" replyposer-boy 16 hours agoprevA few of Phind&#x27;s models are open&#x2F;availablehttps:&#x2F;&#x2F;huggingface.co&#x2F;Phind&#x2F;Phind-CodeLlama-34B-v2 reply SirMaster 20 hours agoprevI tried this, but I still have yet to get any LLM to answer me a programming question (that actually works) that I actually want to solve.Basically:\"How can I send network control commands to an AppleTV in C#\"They always make up some nonexistent library or gives an example using some nonexistent API. reply richardw 20 hours agoparentI’d guess the intersection of both tech has low training content so it starts dreaming. If you break up the question into “AppleTV API” (or whatever the primary terms are), then use that context for C# it might work better? Isolate the Apple bit so it uses more specific parts of the training. reply jiggawatts 20 hours agoparentprevThat’s because you’re asking it something too obscure that I would have at first assumed wasn’t even possible.“Make me a billionaire… I’m still poor! Bad AI!”You need to collaborate with the AI, use it to help with each small step of the problem, with input references provided.To a degree Phind can do the reference chasing for you, but it’s not magic. reply SirMaster 20 hours agorootparentIt&#x27;s definitely not impossible at least.Someone is doing it in python here:https:&#x2F;&#x2F;pyatv.dev&#x2F;GPT-4 actually sent me here:\"Here is an example of a C# library that implements the HAP: CSharp.HomeKit (https:&#x2F;&#x2F;github.com&#x2F;brutella&#x2F;hkhomekit). You can use this library as a reference or directly use it in your project.\"Which, to no surprise based on my experiences with LLMs for programming does not exist and doesn&#x27;t seem to have ever existed.I get that they aren&#x27;t magic, but I guess I am just bad at trying to use LLMs to help in my programming. Apparently all I do are obscure things or something. Or I am just not good enough at prompting. But I feel like that&#x27;s also a reflection of the weakness of an LLM in that it needs such perfect and specific prompting to get good answers. reply jiggawatts 15 hours agorootparentIn a sense you’re asking it the wrong questions. It’s a bit like asking Google “my PC crashed, how do I fix!?” and then expecting something specific to a rare issue in the first hit.Assuming a C# library even exists for what you’re doing (maybe not!) then still the best use of AI is to troubleshoot specific issues given an almost working piece of code as input.Ask it to explain why something doesn’t work instead of asking it to do your job for you wholesale.PS: GPT 4 (you are using the best coding AI, right? Right?) can get you going quickly:“There are several libraries available for controlling Apple HomeKit from C#. One such library is *HapSharp* ². It is a .NET implementation of the HomeKit Accessory Server that allows you to create your own custom HomeKit accessory on a Raspberry Pi, Mac computer, or any other platform that can run Mono ².Another option is *HomeKit* ¹. It is a native C# library for Apple&#x27;s HomeKit Accessory Protocol. However, it is not a complete implementation and does not work ¹.I hope this helps!Source: Conversation with Bing, 31&#x2F;10&#x2F;2023 (1) netonjm&#x2F;HapSharp: HomeKit Accessory Server .Net bridge! - GitHub. https:&#x2F;&#x2F;github.com&#x2F;netonjm&#x2F;HapSharp. (2) GitHub - ppumkin&#x2F;HomeKit: Native C# Libary for Apple&#x27;s HomeKit .... https:&#x2F;&#x2F;github.com&#x2F;ppumkin&#x2F;HomeKit. (3) homekit-accessory-protocol · GitHub Topics · GitHub. https:&#x2F;&#x2F;github.com&#x2F;topics&#x2F;homekit-accessory-protocol?o=asc&s... reply SirMaster 12 hours agorootparentEven all of that is on the wrong track. There is nothing that I can see anywhere about controlling an ATV with the homekit accessory protocol. reply jiggawatts 9 hours agorootparentThen you asked the wrong question.AFAIK Apple generally does not allow arbitrary remote control (headless mode) for security reasons — it could be used for spam automation! reply SirMaster 1 hour agorootparentThey do though. Pyatv can do it (and home assistant is using pyatv since HA is python based) and commercial home automation systems like Crestron and Control4 can do it too.Really I just need to get an LLM to port pyatv to C# for me I guess. reply wizzwizz4 18 hours agorootparentprev> Or I am just not good enough at prompting.Or you&#x27;re good enough at using your tools that you can do all the low-hanging fruit. LLMs excel at working around inadequate tooling, but (at least at the moment) they can&#x27;t help you if you&#x27;re trying to do something actually tricky and get stuck enough that no rubber duck can save you. reply danenania 20 hours agoparentprevI’m working on an open source, terminal-based AI coding tool that is designed specifically for more complex, multi-iteration tasks and features. I think it could likely do a good job on this task.I’m using it personally every day and while it still needs more work and polish, I’m finding it much better than ChatGPT or any other tools I’ve tried for bigger and more difficult tasks.Please let me know if you (or anyone else reading this) would be interested to try a late alpha&#x2F;early beta version: dane@envkey.com reply rushingcreek 15 hours agoparentprevInteresting, I seem to have gotten a decent answer: https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=avbridtm69ejk8pdqpx8hcnf reply SirMaster 15 hours agorootparentUnfortunately there’s nothing correct about that answer. There’s no tcp service listening for requests like that on port 7000 on an AppleTV. reply rushingcreek 15 hours agorootparentIt&#x27;s quoting that from a StackOverflow post: https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;11857130&#x2F;tcpclient-or-ht.... reply SirMaster 11 hours agorootparentYeah, that port 7000 service is AirPlay protocol and they are sending photos and videos to an ATV with it.But I want to control a unit like send navigation controls like 4 directions, back and select.The only app I know that can do it is pyatv, (a python app) but I want to do it in my C# app.It would be nice if an LLM could port pyatv to C# for me as I don&#x27;t really know python at all. replyunshavedyak 20 hours agoprevRe: \"We&#x27;re excited to announce\" - when did this get deployed? I was on Phind Pro ... a month ago or something, and curious if i already experienced this or not.Phind was really good, but still had a difficult time with library versions. Notably a lot of the search results it saw felt like they polluted it with incorrect assumptions about available methods on specific library versions. The web results felt like it made the LLM worse at some things. In the end i switched back to ChatGPT. Though i expect i&#x27;ll retry Phind at some point, i do tend to ping pong on each respective release.Does this version tackle that any better in your eyes? reply rushingcreek 20 hours agoparentThanks for the feedback and I&#x27;m sorry to see you go. The new version should be better at library versions. If you&#x27;re in our Discord, I&#x27;d be happy to help you one-on-one -- please send me a DM. reply unshavedyak 20 hours agorootparentI&#x27;m sure i&#x27;ll be back soon, the overall experience was good. So many competing products it&#x27;s difficult to pay for them all at once. reply iillexial 20 hours agoprevDidn&#x27;t work fine when I asked it a design question: the code and API it used is not correct. GPT-4 did a better job.https:&#x2F;&#x2F;www.phind.com&#x2F;search?cache=ay8rx37gq8oy3z7uixftlqkthttps:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;a3a91dcc-a91a-4b04-8afd-40bd1a... reply xmprt 20 hours agoparentThe GPT-4 answer is only better in so far as it uses RunTransaction. I don&#x27;t know why it&#x27;s trying to loop through the stores and then running the i&#x27;th operation on that store when it could have just had the store referenced in the operation instead of passing it as a parameter. And then it&#x27;s also creating a new client for each transaction which seems wrong (to be fair I&#x27;m not familiar with Firestore so maybe this is idiomatic). reply iillexial 20 hours agorootparentIt&#x27;s not idiomatic. I agree that ChatGPT implementation is not very good, but at least it&#x27;s probably working (not tested) and used correct APIs. I tried several iterations after that, and it came up with a better design. reply naet 20 hours agoparentprevNot looking deeply at the technical side of the answers, but the time of GPT4&#x27;s answer is very casual&#x2F;conversational (it starts with \"Alright, listen up.\" and keeps that tone throughout).I think you might get a better answer if you rewrote your prompt using full sentences and more formal language. reply rushingcreek 20 hours agoparentprevThanks for sharing the links, we&#x27;ll investigate this example. reply passion__desire 19 hours agorootparentI straight away asked it a stackoverflow question in which input and expected output samples were given. Phind didn&#x27;t do well. ChatGPT though, [kissing hearts emoji] reply tydunn 20 hours agoprevThis is awesome. Are you planning to open-source the V7 model? reply rushingcreek 20 hours agoparentThanks! We generally plan to open-source our previous models once they&#x27;re no longer cutting-edge, so yep :) reply 69 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Phind has enhanced its 7th-generation model to outperform GPT-4's coding abilities and deliver answers to technical questions five times faster.",
      "The updated model, which is based on the open-sourced CodeLlama-34B, has achieved a HumanEval score of 74.7%.",
      "Despite some issues with handling complex queries, the model has been warmly accepted by the user community, and it can process up to 100 tokens per second and support up to 16k tokens."
    ],
    "commentSummary": [
      "Online users show diverse experiences while using AI models GPT-4 and Phind, particularly for coding tasks; both models have their own strengths and shortcomings.",
      "Phind stands out for its speed and understanding of context, while GPT-4 excels in high-level design handling and follow-up queries; however, users have proposed enhancements for GPT-4, such as enabling one-shot training with regex and the inclusion of prose detection.",
      "A robust debate revolves around the performance, cost, and user-friendliness of these models, with future improvements possibly focusing on ease of IDE integration, proprietary software transparency, citation effectiveness, and token expansion."
    ],
    "points": 806,
    "commentCount": 320,
    "retryCount": 0,
    "time": 1698774047
  },
  {
    "id": 38089342,
    "title": "macOS Sonoma Boot Failures",
    "originLink": "https://github.com/AsahiLinux/docs/wiki/macOS-Sonoma-Boot-Failures",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up AsahiLinux / docs Public Notifications Fork 45 Star 1.6k Code Issues 25 Pull requests Actions Projects Wiki Security Insights macOS Sonoma Boot Failures Edit New page Hector Martin edited this page · 11 revisions Pages 70 Project related: Glossary FAQ \"When will Asahi Linux be done?\" Feature Support Project:References Recent Changes Platform documentation: Apple Silicon Subsystems Apple Platform Security Crash Course Devices Codenames For users: Broken Software SW:Alternative Distros For developers: Yaks in need of shaving (HELP WANTED!) Tethered Boot Setup (For Developers) m1n1:User Guide Boot loader SW:Hypervisor U-Boot SW:DT-bindings Open OS ecosystem on Apple Silicon Macs Clone this wiki locally What happened? macOS Sonoma and macOS Ventura 13.6 were released with multiple serious bugs in their upgrade and boot process. Combined, these bugs can create conditions where a machine always boots to a black screen, no matter what power button press combination is used. This leaves users stuck, and the only solution is to use DFU recovery. This bug can affect users both with and without Asahi Linux installed. This situation can happen with certain settings on certain models, when multiple macOS versions are installed side by side (one Sonoma, one earlier). Since Asahi Linux behaves as if it were macOS 12.3/12.4/13.5 (depending on model and installation time), dual-boot installs of macOS Sonoma and Asahi Linux have the same effect. For macOS 13.6, this situation doesn't even require a dual-boot system, and can be triggered stand-alone as the only installed OS. We have updated the Asahi Linux installer to automatically perform an integrity check and diagnose your system on startup. To run it, paste this command into Terminal in macOS: curl https://alx.shsh You can quit the installer once you reach the main menu, without making any changes to your system. Apple bug reports: FB13319681 and FB13319708 What are the bugs exactly There are two bugs: macOS Sonoma upgrades use the previously installed version as System Recovery. This makes some sense, but does not consider backwards compatibility problems between older RecoveryOS and newer firmware. If this mismatch causes recoveryOS to fail to boot, this will leave System Recovery unusable. For 14\" and 16\" models: Once System Firmware is updated to the macOS Sonoma version, if the display is configured to a refresh rate other than ProMotion, that system will no longer be able to boot into older macOS installs nor Asahi Linux correctly. This includes recovery mode when those systems are set as the default boot OS, and also System Recovery at least until the next subsequent OS upgrade. What happens if I get hit by the bug? Will I lose data? You will need another Mac to recover from the fault using DFU mode. However, you will not lose data. What machines are affected? MacBook Pro models with ProMotion displays (14\" and 16\") are affected by the black screen boot bug. What versions are affected? macOS Sonoma 14.0+ (not fixed as of 2023-10-31) macOS Ventura 13.6+ (uses 14.0 firmware) Possibly: macOS Monterey 12.7 (unconfirmed) (confirmed unaffected, 12.7 uses 13.6 firmware apparently? weird.) What should I do? I have not upgraded to macOS Sonoma (or macOS Ventura 13.6) yet and I want to We recommend waiting until these issues are fixed by Apple before upgrading. If you want to risk it and you have a 14\" or 16\" machine, make sure the display refresh rate is set to ProMotion before attempting the upgrade. You might still end up with a corrupted System Recovery, which can only be fixed with DFU mode or a subsequent successful upgrade. Regardless of whether you plan to install Asahi Linux or not, we recommend running the Asahi Linux installer after a Sonoma upgrade to check the status of your System Recovery partition. It will inform you about any issues prior to the main menu, before any changes are made to your system. I have not upgraded to macOS Sonoma (or macOS Ventura 13.6) yet and I'm in no rush Feel free to stay on macOS version 13.5 or earlier for the time being. You can safely install Asahi Linux if you wish. I have already upgraded to macOS Sonoma and I want to install Asahi Linux The Asahi Linux installer has been updated to check the version of your System Recovery, and will inform you of the risks if there is a mismatch. It will also check the ProMotion refresh rate, and refuse to install if it is set to anything other than ProMotion mode. Therefore, it is safe to install at this time. Start the installation process normally. Follow the prompts carefully and read all the information printed. If your System Recovery version is mismatched, make sure you understand the risks. If your display refresh rate is incorrect, the installer will ask you to change it. I have already upgraded to macOS Sonoma and I have Asahi Linux If you are currently booted into macOS, ensure the display refresh rate is set to ProMotion (for 14\" and 16\" machines). We recommend running the Asahi Linux installer again to verify the integrity of your System RecoveryOS partition and ProMotion status. If there is a problem, you should refrain from making any major changes to your system until the issue is fixed by Apple. I am affected to the issue, what do I do? If your machine boots to a black screen (brief Apple logo, then nothing), first attempt a regular recoveryOS boot by fully powering down the machine, then holding down the power button. If that does not work, try booting into System RecoveryOS. To do this, fully power down the machine, and then perform a fast \"tap-and-hold\" power button gesture (press and release once, then press and hold). If that also leads to the same problem, unfortunately you will have to resort to DFU mode. See the following section for details. If you can successfully reach a boot menu, select your macOS Sonoma install and hold down Option while confirming your selection to make it the default boot OS. If you have macOS 13.6 ventura instead, follow the special section below. How do I fix my machine with DFU mode? First, you will need another Mac running a recent version of macOS (an Intel Mac is OK). Install Apple Configurator from the App Store on the other Mac and open it. Follow Apple's instructions to connect your two machines together, and put your target machine in DFU mode. The target machine's display should remain off at this point. You should see a large \"DFU\" icon in Apple Configurator. If you see anything else, the machine is not in the correct mode. Repeat the procedure and try again. Once you see the DFU icon, right click it and select Advanced → Revive. This will begin the revive process. If you get a message saying \"A system update is required for this device\", you can ignore it and press \"Restore Anyway\". This process has been tested with another Mac running macOS 13.5. Follow the prompts and accept any accessory connection requests. Do not leave the machine unattended, as you might miss one of those prompts (and there is a timeout). The process will take a few minutes to complete. Once the Revive process completes, the machine should boot into macOS Recovery. Follow the prompts and authenticate yourself. After this, the machine will reboot into the Boot Picker. If you have macOS 13.6 ventura instead, follow the special section below. Select your macOS Sonoma install, then go into the Display settings page and set the display refresh rate to ProMotion. This will prevent the problem from reoccurring. Should you wind up with a \"black screen boot\" again after this point, follow the steps in the previous section to perform the \"tap-and-hold\" power gesture. This should now work properly, as your System RecoveryOS has been updated. You may then select macOS again and fix the display refresh rate. I don't have another Mac to use DFU mode! What do I do? You can take your Mac to the Apple Store and ask them to do a DFU Revive. Make sure they do not do a Restore, which would wipe all your data. They should perform this service for free. Do not let them charge you any money for it. This is a problem Apple caused, and purely a software issue. If the technicians claim there is hardware damage, they are wrong. What if I have macOS 13.6 Ventura and not Sonoma? macOS 13.6 Ventura uses the macOS Sonoma System Firmware, but suffers from the problem. Even users with just 13.6 installed single-boot are affected by this issue (no Asahi Linux needed). We do not understand how Apple managed to release an OS update that, when upgraded to normally, leaves machines unbootable if their display refresh rate is not the default. This seems to have been a major QA oversight by Apple. If your system has 13.6 Ventura and ended up in the black boot situation, unfortunately the only known solution is to upgrade to Sonoma. From the Boot Picker, select Settings. This will boot into recoveryOS. From there, select \"Install macOS Sonoma\". Follow the prompts and select your existing macOS volume. This will upgrade macOS without losing your data. Wiki for the Asahi Linux project: https://asahilinux.org/ Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=38089342",
    "commentBody": "macOS Sonoma Boot FailuresHacker NewspastloginmacOS Sonoma Boot Failures (github.com/asahilinux) 596 points by ColoursofOSINT 20 hours ago| hidepastfavorite246 comments krackers 20 hours agoSee also his twitter for some speculation as to how on earth simply changing refresh rate would cause boot corruption: https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111329614147717090>Why? I can tell you why: because Apple hates display modeset flicker, and switching modes between ProMotion on&#x2F;off causes a modeset flicker, so of course they made it so that is stored in nvram somewhere and applied when the screen is turned on during early boot, so when macOS boots it doesn&#x27;t have to flicker again.>And they didn&#x27;t test it with older OS bootloaders, so display handoff&#x2F;init just fails catastrophically with those when this mode is enabled. reply whywhywhywhy 1 hour agoparent>Why? I can tell you why: because Apple hates display modeset flicker,Thank god someone does. Hate how jank plugging monitors in just because some engineers thought “meh, good enough”.Don’t think I should be seeing things flicker anywhere in my life with the computing power we have today and yet many consider visual nails on a chalkboard as acceptable. reply jwells89 18 hours agoparentprevThe messiness of resolutions during boot always annoyed me on PCs. It was understandable back in the days of BIOS, but ith the advent of UEFI it seems like it should be possible to run EFI config screens and the like at monitor native rez (or at minimum, native aspect ratio) but I’ve never seen this… it’s always 1024x768 or somesuch stretched to fit a 16:9 monitor which looks awful. reply wannacboatmovie 18 hours agorootparentEFI config screens should be text mode only, full-stop. So they can easily be used over serial console redirection.Ran into one recently that was high-rez graphical. It needed a USB mouse to change critical settings because the tab order for the onscreen widgets didn&#x27;t work.Anyone responsible for creating graphical EFI config screens should stop writing software for the good of humanity. reply userbinator 16 hours agorootparentText-only BIOS setup was the norm for a long time before the stupidly bloated EFI graphical stuff became common. Even then, there were the better full-featured TUIs:https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;0&#x2F;05&#x2F;Award_BI...https:&#x2F;&#x2F;liveusb.files.wordpress.com&#x2F;2010&#x2F;05&#x2F;awardbios-firstb...And the simplified crap with tabs that often came with prebuilt PCs but later seems to have spread to others too:https:&#x2F;&#x2F;cdn.staticneo.com&#x2F;a&#x2F;Intel_Sandy_Bridge_Z68_P67&#x2F;S%20B... reply jasonjayr 13 hours agorootparentTo my horror, I recently had to visit the UEFI firmware setup of a Lenovo tablet.... That was touch enabled. reply alexvoda 8 hours agorootparentAnd it is to be expected to be able to configure a touchscreen device using the touchscreen. reply Ayesh 10 hours agorootparentprevMost gaming laptops&#x27; UEFI screens are so \"gamer\" it&#x27;s cringe. Dell XPS series have UEFI GUIs that are quite neat and absolutely an improvement over the text screens. reply minedwiz 10 hours agorootparentI&#x27;m also partial to the Surface devices&#x27;. MS put a surprising amount of effort into making them look Windows-y. reply lights0123 10 hours agorootparentprevI did enjoy my Dell touchscreen-supported firmware setup when there was a menu 15 items long and an incredibly slow mouse speed. reply AshamedCaptain 16 hours agorootparentprev> Text-only BIOS setup was the norm for a long timeLong-time Thinkpad users scoff at that ... while the figure of a duck suddenly enters their minds..(Yes: I clearly remember my pre-USB thinkpad having a graphical BIOS with windows, icons, and a duck-shaped mouse cursor). reply userbinator 14 hours agorootparentFor those who haven&#x27;t seen it: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=XTaNi6uL41sBIOSes of the time were all written in highly-optimised Asm, and I suspect those little \"easter eggs\" they added were because the programmers knew they had enough space left over to put some more fun stuff in.There was also AMI WinBIOS that provided a GUI, but I remember it being much less featureful than other BIOSes of the time with a TUI and didn&#x27;t like mobos that used it, so in that case they may have sacrificed functionality for appearance. reply ojbyrne 11 hours agorootparentSomebody missed the memo: https:&#x2F;&#x2F;bwiggs.com&#x2F;notebook&#x2F;queens-duck&#x2F; reply doublerabbit 14 hours agorootparentprevA 90&#x27;s TUI that will forever be more productive than Windows 11. reply pjmlp 6 hours agorootparentAs someone with experience in Turbo Vision and Clipper, I don&#x27;t miss them, beyond some nostalgia from simpler times. reply larvaetron 14 hours agorootparentprev> Text-only BIOS setup was the norm for a long timeI&#x27;ve had a GUI BIOS setup on almost every PC I&#x27;ve owned since the first 486 I built back in 1993. reply xcv123 13 hours agorootparentThe GUI was rendered in text mode. It&#x27;s called a TUI (Text-based User Interface) reply einr 4 hours agorootparentPlenty of 486 era machines had the AMI ”WinBIOS” whose setup utility kinda-sorta emulated a Win 3.x look and ran in (EGA 640x350 4bpp?) graphics mode, with mouse support:https:&#x2F;&#x2F;media.moddb.com&#x2F;images&#x2F;groups&#x2F;1&#x2F;4&#x2F;3107&#x2F;winbios.gif reply mratsim 10 hours agorootparentprevTIL, I thought TUI meant Terminal UI reply p_l 4 hours agorootparentprevYou know what&#x27;s funny?UEFI actually lets you provide both touchscreen-capable bells&whistles gui, and a text UI for the frankenstein VT-UTF8 standard (essentially, VT-220 compatible with UTF-8, kinda like linux console) - all in mostly one codebase.There&#x27;s a standard UI description language which is used to specify menus, options and values (and how they are written into nvram), which is then interpreted by text mode interface driver (enabled when you connect over serial port) and graphic mode interface driver (where you can drop all sorts of graphical bells & whistles).It&#x27;s also how you can integrate menus from add-on cards into firmware setup. reply Reason077 8 hours agorootparentprevText UIs don’t actually require different resolution and refresh rates. Even Macs can boot into a text mode, but there’s no jarring mode-change flicker when it switches in and out of it!Besides, there’s nothing to prevent you having a nice graphical boot configuration while still having a text version as a fallback (which is exactly what Intel Macs do) reply jwells89 18 hours agorootparentprevEven for text-only I’d prefer native rez if possible to reduce scrolling, label truncation, etc.That said yes, there’s no reason why there shouldn’t be a low rez textual fallback. reply secondcoming 17 hours agorootparentThen you&#x27;d need scaling and all that. Seems a bit overkill for something people rarely use. reply xp84 16 hours agorootparentscaling? nah, I&#x27;d say to just choose at runtime a sane text size (only to avoid using the same pixel size on a 1024x768 as a 5k screen) and set the number of rows and columns to fit the screen. Even if there isn&#x27;t enough to fill the screen that&#x27;s fine.> Seems a bit overkill for something people rarely use.Okay, but a lot less so than a full GUI with mouse and thousands of colors, like many motherboards have gone to. reply userbinator 12 hours agorootparentThe \"sane text size\" is naturally going to be the 80x25 text mode (720x400) which is what those config screens were originally defined for. Monitors will usually upscale lower resolutions anyway. reply jyrkesh 10 hours agorootparentprevUpside though? I was helping a more software-oriented buddy get a PC build up and running that&#x27;d been half-finished by some kid he paid to put it together. The GUI on the EFI config was so intense, it was slowing down and completely locking up.Got into the temps, realized that the CPU fan had been plugged into an AUX fan header instead of the CPU header.Fan was spinning, wouldn&#x27;t have thought to check if the EFI wasn&#x27;t crashing.I&#x27;m completely joking of course. I completely agree with you, I miss text-only mode. The modern Dell one stinks, the Asus one stinks...I have no data, but I&#x27;d be shocked if Gigabyte or ASRock were any good... :( reply postmodest 15 hours agorootparentprevReal boot loaders have embedded Forth interpreters! reply pmarreck 14 hours agorootparentDo Macs still have this? reply MBCook 11 hours agorootparentNo, it stopped for the Intel switch, I believe. reply sneak 1 hour agorootparentYeah, the Open Firmware preboot Forth console was a PowerPC only thing.Now Apple’s bootloader is actually a tiny macOS. As much as I don’t like the complexity this brings, I do strongly approve of a boot environment that supports proper input devices and video. My iMac Pro’s (intel, non-macOS-based bootloader) bootloader drops keyboard inputs when typing my long passphrase because I type too fast for it. The Mx macs no longer have this problem. reply sneak 1 hour agorootparentprevText mode on my 8K monitor at any time, even in boot, is dumb and annoying and anachronistic. It’s 2023. reply AshamedCaptain 17 hours agorootparentprevBy the time my Dell monitor finally wakes from sleep, finishes negotiating whatever crap DisplayPort has to negotiate these days, and starts actually displaying frames, the computer has long since finished booting and is already idling at the desktop. reply m463 14 hours agorootparentprevThere&#x27;s a lot going on there. To prevent flicker, you not only have to preserve the screen resolution, but also all the graphics card memory and state and hand it off through stages of boot from efi to the os.As an analogy this would be sort of like rebooting the OS in place while preserving all the running apps, network state and USB connections without resetting anything.These kinds of things are possible, but have lots of corner cases. reply wmf 18 hours agorootparentprevGood UEFI like Surface devices is native resolution so you can have flicker-free boot. My Gigabyte motherboard recently got native resolution with a UEFI update. reply ddalex 18 hours agorootparentI don&#x27;t understand why modeset causes flicker - fade to black, turn off screen, change resolution, turn on screen, fade to image. reply mjg59 17 hours agorootparent\"Fade to black, turn off screen, turn on screen, fade to image\" is just slower flicker. reply kelnos 12 hours agorootparentTrue, but that does look nicer than normal-speed flicker? reply mjg59 11 hours agorootparentAnd slows boot down by a couple of seconds. As long as the firmware sets a native mode, modern OSes can just inherit that rather than performing a modeset and we just ignore the entire problem anyway. reply astrange 13 hours agorootparentprevBecause most modeset protocols&#x2F;implementations aren&#x27;t atomic, so some frames are drawn halfway through setting the mode.Turning off the screen can take a long time, but it is possible that putting up a \"hot black\" screen would be better than flicker if you had to do it. reply WesolyKubeczek 17 hours agorootparentprevThis summer I went into an apple store, and there was this 2019 Intel Mac Pro tower hooked up to the shiny 6k XDR display. I brought up the System Settings, and set the resolution one notch towards \"More Space\". It faded to black and never came back. reply beebeepka 18 hours agorootparentprevFancy fade in&#x2F;out effects this early? reply jwells89 18 hours agorootparentprevNice to hear that good implementations exist somewhere out in the wild. I hope my AM4 and LGA1700 boards by Asus get similar updates at some point. reply tripdout 18 hours agorootparentprevMy old AM3+ motherboard has an option for full screen boot logo, and it starts in full HD, continuing with systemd boot, all in 1080p.I thought this wasn&#x27;t really a problem anymore. reply JasonSage 17 hours agorootparentThis is fine if you have a 1080p monitor. I was impressed when this first happened to me, now on an ultrawide monitor it’s back to being not great.I do recall my last motherboard had an option for a splash which was centered in a black screen, so you could basically display it at native resolution with no stretching and it would look great and seamless. I wish every motherboard had that splash option now. reply vondur 16 hours agorootparentprevHa, back in the day when I was a student assistant in a campus computer lab, we flashed the BIOS boot screen with a full screen image of Darth Maul. The staff person who oversaw us was not amused. (This was in the Pentium 3 era IIRC) reply tomxor 16 hours agorootparentprevAt least it works. I find low-res bios screens reassuring... something I can depend on. reply shawnz 14 hours agorootparentMaybe instead of spending effort providing low res fallback options, we should be spending more effort making high res GUI-based options more dependable? reply doubloon 13 hours agorootparentprevi heard these new fangled jibjabs don&#x27;t even have audible POST beeps. reply dm319 17 hours agorootparentprevMy Amiga in the 1990s seemed to do a pretty good job at boot. reply tpmx 16 hours agorootparentAs did pretty much any PC motherboard&#x2F;CPU&#x2F;GPU combination from the past 25 years. reply lvncelot 6 hours agoparentprevIt&#x27;s somewhat endearing that a trillion dollar company goes through something similar as I did - fiddling around with rEFInd, my BIOS splash image, plymouth-git & plymout-sddm, \"quiet splash\" and god knows what else to get a \"smooth\" boot experience - not only adding several seconds to the boot process but also having to rescue the system multiple times with a boot stick.I&#x27;ve come to embrace the flicker and the systemd messages. It&#x27;s just a boot, it&#x27;s in the order of seconds in this day and age, I can&#x27;t even tell you what the initial reason for my obsession was. reply NavinF 18 hours agoparentprevInteresting. I wonder why anyone would turn ProMotion off considering that 120Hz massively improves responsiveness. I&#x27;ve only encountered one app that doesn&#x27;t work with variable refresh rate and that&#x27;s Genshin on Windows. Even that&#x27;s probably not an issue with newer monitors that can handle VRR down to 60Hz without my monitor&#x27;s frame-doubling flicker as it keeps switching been 60Hz and 120Hz reply Wowfunhappy 18 hours agorootparent> I wonder why anyone would turn ProMotion off considering that 120Hz massively improves responsiveness.The first reason that comes to mind is battery life. That&#x27;s probably the most broadly applicable use case.But also, if I was still doing e.g. frontend web development, I would want to confirm that my css animations looked nice at 60 hz.Edit: My first use case is likely wrong, thank you to replies for reminding me Apple uses adaptive refresh down to 1 hz. reply jwells89 18 hours agorootparentmacOS is very good at adaptively reducing refresh rate when nothing is happening on screen, with the panel reportedly supporting the full range of 1-120hz so barring badly engineered apps that are permanently pinned at max refresh, the battery impact of keeping ProMotion on is minimal for most use cases. reply londons_explore 16 hours agorootparentWhich raises the question even more why the refresh rate matters during early bootup - surely you could just start with an apple logo and a 1 Hz refresh rate, and then up the rate later during boot when it&#x27;s time to do some animation... reply lxgr 16 hours agorootparentChanging the refresh rate makes the screen go blank for a second or so.GP of this thread links to a post arguing that Apple is going out of their way to avoid just that during the boot sequence. reply londons_explore 15 hours agorootparentExcept it doesn&#x27;t... because during use the dynamic refresh rate changes between 1Hz and 120Hz... reply lxgr 15 hours agorootparentWell, I can only tell you what happens when you manually change the resolution from 60 Hz to \"ProMotion\" in macOS.Presumably ProMotion is a specific mode that the display&#x2F;display controller&#x2F;... first needs to be set to. If you start out in anything other than that and then switch to it later in the boot process, you&#x27;d get that blank screen for a second, and Apple avoids that by writing the startup mode to non-volatile memory.Otherwise they could also just always start out in ProMotion mode – but then you&#x27;d get flicker every time you (re)boot into any other mode, like 60 Hz for people who prefer that. reply Wowfunhappy 15 hours agorootparent...so this is where I&#x27;m confused, and where I think GP is confused. Why is there a separate 60 Hz mode that requires blanking the display? Why not just keep dynamic refresh enabled on the panel, and then lock it to updating 60 times per second (which it can do, since it&#x27;s dynamic) for people who prefer that for whatever reason? What is the difference? reply lxgr 15 hours agorootparentNo idea, but if I&#x27;d had to speculate: Probably ProMotion activates a quite different internal rendering mode, and fixed 60 Hz mode offers a way to opt out of that?Many applications have a way of synchronizing their drawing loop to the monitor refresh rate, for example; ProMotion must be doing something clever to support them, or they&#x27;d just force the refresh rate to 120 Hz.macOS also supports variable refresh rate external monitors these days (via both DisplayPort and HDMI); I&#x27;m not sure if that would be labeled \"ProMotion\" in the display settings, but in any case there are things that can go wrong there, and having a way to opt out of that at the HDMI&#x2F;DisplayPort signal level (and not just fixing the frame rate at the GPU level while driving the external link under VRR) seems like a good idea. reply pmarreck 3 hours agorootparentprev> Why is there a separate 60 Hz mode that requires blanking the display?I&#x27;m guessing it probably has to do with compliance with the original VESA standard, or whatever the completely basic support of multiple resolutions and refresh rates in all monitors is called.The bootstrap of booting a system always ends up relying on the most basic supported things to start with (such as 640x480@60Hz using the VESA standard) and then upping it from there. reply bscphil 15 hours agorootparentprevIf I understand correctly, ProMotion is the feature that allows dynamically changing the refresh rate without screen blanking. So the reason refresh rate matters in early bootup is that if ProMotion is not enabled, you get brief screen blanking. Setting the screen to 1 Hz in early bootup and then changing it to the user setting later would require screen blanking. reply TylerE 15 hours agorootparentprevThat&#x27;s not a modeset though, that&#x27;s just the display working as intended. Basically a VSYNC that runs at a variable clock rather than a fixed refresh. reply lxgr 14 hours agorootparentPretty sure VRR is a mode as far as the display (controller) is concerned.There’s very likely still a scan out rate determined by the maximum refresh rate, just that the source can delay the next frame if it’s not ready yet.In other words, e.g. 120 Hz and 144 Hz of VRR aren’t the same even when displaying a 60 Hz signal at the moment – the faster signal would have more pauses and a higher signal rate. reply TylerE 14 hours agorootparentVRR is a property, node a mode. A VRR display showing 60hz will be running at 60hz. They can typically clock down in 1hz intervals. reply lxgr 12 hours agorootparentAs far as I understand it, nothing \"clocks down\"; rather, frames are delayed as required to achieve the frame rate desired (or reachable, in the case of gaming) by the source, down to 1 Hz.So, yes, fixed 120 Hz and 120 Hz with VRR and without any skipped frames might well be the same mode to a GPU, but it also might be a different one, requiring a mode switch. I don&#x27;t know how Apple has implemented it.But in any case, for the bug at hand it&#x27;s irrelevant: Apple&#x27;s ProMotion uses a refresh rate of 120 Hz, so switching between that and 60 Hz is definitely a mode switch. replyWowfunhappy 18 hours agorootparentprevOops, thank you, I completely forgot they were doing the adaptive refresh thing! reply vvillena 18 hours agorootparentprevIsn&#x27;t battery life a reason to keep it on? The refresh rate will be down to 24hz most of the time. reply beebeepka 17 hours agorootparentprevWhy would 60 FPS CSS animations look bad on high refresh displays? reply Wowfunhappy 17 hours agorootparentWell the CSS transition wouldn&#x27;t run at 60 fps, it would run at 120 fps, no?An animation that looks slick at 120 fps might look too fast&#x2F;slow&#x2F;complex&#x2F;whatever on a common 60 hz screen. So if I was still doing this sort of development, I&#x27;d prefer to be working on a 60 hz monitor. reply c-hendricks 17 hours agorootparentI&#x27;m not even sure CSS animations can go above 60fps, and am unsure why you&#x27;d think it would be faster &#x2F; slower on a different refresh rate screen: CSS transitions are defined by time, not frames. reply Wowfunhappy 17 hours agorootparentSorry, I meant the animation might look too fast, psychologically. The frame rate changes how we perceive movement. reply beebeepka 17 hours agorootparentprevAren&#x27;t CSS animations capped at 60, same as requestAnimationFrame?I&#x27;ve been advocating (and using) high refresh displays for over two decades and I find your reasoning preposterous. Downgrading to crappy 60 Hz monitor for nothing. reply fulafel 10 hours agorootparentCSS transitions and animations seem to be declared using expressions that are continuous over time so it would make sense that they are just quantized down to whatever refresh rate the system supports. reply mmis1000 10 hours agorootparentprevI am pretty sure they are synchronized to refresh rate (at least on windows).I made a small experiment about raf https:&#x2F;&#x2F;codepen.io&#x2F;mmis1000&#x2F;pen&#x2F;qBxqgLr and it always looks uniform regardless I am on a 60, 120, 160 fps screen. (It would blink crazily if you put it in the middle of two screen with different refresh rate, because it can&#x27;t be in two refresh rate at same time)Erit: okay, it looks non uniform only in safari. Clap, clap, clap, Apple… reply Wowfunhappy 17 hours agorootparentprev> Aren&#x27;t CSS animations capped at 60, same as requestAnimationFrame?Did some quick Googling to make sure I wasn&#x27;t just out of the loop on this, as far as I can tell they are not the same: https:&#x2F;&#x2F;github.com&#x2F;whatwg&#x2F;html&#x2F;issues&#x2F;5025 reply beebeepka 17 hours agorootparentCan you point me to the part confirming your claim? If anything, it&#x27;s confirming mine that they both are stuck at 60 Hz. reply Wowfunhappy 17 hours agorootparentThe link says:> As such, on their 120hz devices, requestAnimationFrame is throttled to 60hz, whereas CSS animations run at 120hz.Please let me know if I am misunderstanding, it has been a few years since I&#x27;ve done this type of work. replyapwoefjwepoo 10 hours agorootparentprevI turned it off. The primary reason is that I use ctrl+arrow keys to move between workspaces frequently.These might seem unrelated, but:* There&#x27;s a `defaults set` setting that allows you to speed up the transition animation length from 1 second to 0.5 second, which is huge because that transition is extremely poorly implemented (it leaves the windows on the workspace that you&#x27;re leaving activated until the transition is complete, so you start typing and it&#x27;s on the other screen you can&#x27;t even see any more) and VERY SLOW* That setting only works if the refresh rate is 60Hz, and it completely fails to do anything if ProMotion is on, because for some reason the animation length isn&#x27;t programmed to handle the different refresh rates.So having ProMotion off relieves frustration. reply gassi 46 minutes agorootparentThis is exactly the reason why I disabled it when I upgraded to my current M1, and I&#x27;m relieved to hear I&#x27;m not the only one experiencing this. reply bluescrn 5 hours agorootparentprevEmulation is one case where specific refresh rates are desirable.Would be nice if I could force my MBP to run at 100Hz for PAL Amiga&#x2F;C64 emulation - or even better if emulators could&#x2F;would change the refresh rate at least when running full-screen.(Actually, since Sonoma, I can manually set it to 50Hz, but there&#x27;s no fixed refresh rate options above 60Hz, just &#x27;Pro Motion&#x27;. Previously, the refresh rate setting seemed missing entirely on my M1 MBP) reply Audiophilip 3 hours agorootparentInteresting, that could be a limitation to the internal screen of the MBP.On Sonoma I can select 24, 25, 30, 50, 60, 100, 120 Hz, in addition to \"Variable (40-120 Hz) refresh rates for my LG C2 display. When selecting 50 or 100 Hz, scrolling in (PAL) C64 emulation in VICE becomes much smoother, but not perfect. However, when I enable variable refresh rate and switch to fullscreen mode, VICE can perfectly synchronize the refresh rate and scrolling&#x2F;animations become butter smooth. reply zippergz 17 hours agorootparentprevI turn it off because I can’t tell the difference and if it doesn’t improve anything for me, I might as well not have the system wasting battery and other resources on it. reply NavinF 12 hours agorootparentVRR displays run at 1Hz to save battery when the display is static. Reasoning like yours is why every OS&#x27;s settings page gets neutered with every update. reply pb7 17 hours agorootparentprevIt does the opposite: it goes well below 60Hz when there is no motion on screen. reply kccqzy 9 hours agorootparentprevSurely I&#x27;m not the only one that simply cannot perceive any difference between 60Hz and 120Hz? reply MagerValp 18 hours agorootparentprevTo run x64sc at a buttery smooth 50 fps.Admittedly rather niche use case. reply userbinator 17 hours agorootparentprevI wonder why anyone would turn ProMotion off considering that 120Hz massively improves responsiveness....and I bet that&#x27;s exactly the attitude Apple had when implementing things, which lead to this mess. reply stcg 14 hours agorootparentWell then don&#x27;t allow turning it off in the first place. reply neilalexander 20 hours agoprevInterestingly I ran into this exact problem with my work MacBook Pro M1 upgrading to Ventura 13.6 and assumed it was a totally isolated incident. I don&#x27;t have a dual-boot setup either, just a single macOS install.The computer was connected to a Thunderbolt Display during the update which I assume had the same effect of changing the refresh rate to something other-than-ProMotion that the linked article mentions. I had to do a DFU restore from another Mac and then run the macOS Sonoma installer from USB, which thankfully detected the existing install and did an in-place upgrade, preserving all of my data. Nothing else worked.I also wasted far too much time trying to get the DFU restore to work before discovering that you cannot use a Thunderbolt cable — it has to be done using a plain USB-C cable, otherwise the Apple Configurator simply won&#x27;t detect the other Mac. reply alsetmusic 20 hours agoparent> I also wasted far too much time trying to get the DFU restore to work before discovering that you cannot use a Thunderbolt cable — it has to be done using a plain USB-C cable, otherwise the Apple Configurator simply won&#x27;t detect the other Mac.I would have expected a Thunderbolt cable to be required, if either was. This is quite surprising to me. Usually, the more capable (higher bandwidth) cable works if one isn’t supported. I’ll hope to remember this is I ever find myself reviving a bricked Mac in the future. reply phillco 18 hours agorootparentI&#x27;ve used a Thunderbolt cable as well successfully, but one note is that they&#x27;re very picky about which port you use. On my Mac mini, I had to use the exact port outlined here or it did not show up: https:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;apple-configurator-mac&#x2F;reviv... reply microtherion 12 hours agorootparentYes, this is absolutely key. Only one of the USB ports per machine supports this functionality. reply nnf 3 hours agorootparentprevFrom Apple’s support page on how to revive or restore after a failed upgrade [1]:> A supported USB-C to USB-C charge cable, such as the one sold by Apple (may not be available in all countries or regions) or a supported USB-A to USB-C cable> The USB-C cable must support both power and data. Thunderbolt 3 cables aren’t supported.[1] https:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;apple-configurator-mac&#x2F;reviv... reply brigade 19 hours agorootparentprevIt&#x27;s done over USB 2.0 largely because that&#x27;s simpler than involving newer and faster specs, and partly because that&#x27;s how the original iPhone did it.My understanding is that all complaint USB USB-C cables should work for USB 2.0, even USB4&#x2F;TB4 cables, but active TB3 cables might not hook up the USB 2.0 pins. reply spacedcowboy 19 hours agorootparentprevI am currently restoring an MBP using Configurator and a thunderbolt cable. You definitely can use one, perhaps your TB cable is buggered ? reply vbezhenar 19 hours agorootparentprevI restored my Macbook just one hour ago with crappy USB-C USB-A cable, god bless the libimobiledevice creator. reply tpmx 18 hours agoparentprevThis is depressing. They clearly have they ability ($$$) to do the required amount of manual QA, but don&#x27;t. Or there was QA and someone decided that your case still wasn&#x27;t enough to hold up the release.In my mind, when we pay that ridiculous Apple premium on RAM and storage, we pay for excellent quality in SW&#x2F;HW. They also need to deliver that quality. reply mort96 18 hours agorootparentOr they did QA but just happened to miss this issue. Most companies would consider \"the upgrade sometimes bricks the device\" to be a release-stopping bug, I&#x27;m betting Apple is among them. reply krackers 18 hours agorootparentApple still hasn&#x27;t put up any official page about the issue though, nor does it appear they&#x27;ve pulled the update. Even if it missed QA, why haven&#x27;t they made any official comment? reply FirmwareBurner 17 hours agorootparentYou clearly don&#x27;t know Apple as a company. Last most big companies, they never EVER publicly admit any faults or mistakes with their products (unless forced to by large scale fiascos) because that would damage their perfect brand image. It&#x27;s why they have comments disabled on all their social media accounts. reply gcr 13 hours agorootparentGoogle this week seems to be going through a similar bug on their flagship Android 14 release, affecting users who have multiple accounts set up. They also seem to be favoring a \"minimal\" strategy when it comes to PR communication surrounding this issue. reply tpmx 12 hours agorootparentOkay? reply JumpCrisscross 17 hours agorootparentprev> they never EVER publicly admit any faults or mistakes with their productsOf course they do. They’re just secretive in general, and keep communications edited. Compared to the word salad of modern companies on social media, I find it refreshing. Just fix the problem, issue replacements for those affected and move on quietly. reply FirmwareBurner 17 hours agorootparent>Of course they do. Where? Do you have any examples? reply JumpCrisscross 16 hours agorootparent> Where? Do you have any examples?The whole battery gate saga. Touch Bar. The 2013 Mac Pro [1].[1] https:&#x2F;&#x2F;www.theverge.com&#x2F;2017&#x2F;4&#x2F;4&#x2F;15175994&#x2F;apple-mac-pro-fai... reply FirmwareBurner 16 hours agorootparentYeah but that only proves my original point that Apple only admits mistakes when the public scandals are so violent it can&#x27;t possibly deny them anymore as the shit pile broomed under the carped has grown so large it makes even them trip on it, so then they just enter damage control mode and PR recovery but not out of the kindness of their heart but because of media backlash.But they never have the common sense to release statements like \"hey, the latest MacOS update might brick some systems so we&#x27;re pulling the updated until we can do further testing and patching, if you&#x27;ve been affected by the bug already go to a Apple store and have it fixed for free\". reply JumpCrisscross 15 hours agorootparentThey have pulled updates [1]. The one person I know who was affected was given a replacement.I suppose I&#x27;m failing to see the need for a public statement if you&#x27;ve fixed the problem and provide service to those affected. Nobody can pull the faulty update anymore. And it&#x27;s not like someone with a bricked device is more likely to see a PR statement than seek out support.[1] https:&#x2F;&#x2F;osxdaily.com&#x2F;2023&#x2F;07&#x2F;11&#x2F;apple-pulls-rapid-response-u... reply pmarreck 3 hours agorootparentprevmethinks you&#x27;re the self-victim of some confirmation bias here, sir. reply tpmx 16 hours agorootparentprevIt&#x27;s not \"refreshing\" to hide problems. reply TylerE 15 hours agorootparentIt IS refreshing not to be insulted by the usual \"You are important to us and we&#x27;re taking this very seriously\" PR fluff. reply JumpCrisscross 15 hours agorootparentprev> It&#x27;s not \"refreshing\" to hide problemsHiding entails ignoring the problem. They&#x27;re not doing that. Their track record is to fix it. Not every action needs an accompanying tweet and blog post. reply tpmx 15 hours agorootparentOf course they are not ignoring the problem, internally. The issue issue at hand is that they are not being open about the problem. reply cirrus3 13 hours agorootparentprevMaybe because it isn&#x27;t that big of an issue? Have you heard about this anywhere besides HN? If it were a big deal you know all the websites would be all over it as if the Mac were doomed. reply rainbowzootsuit 14 hours agorootparentprev\"You&#x27;re updating it wrong.\" —Steve reply tpmx 18 hours agorootparentprevThat would be: not delivering while still charging a premium. reply codr7 17 hours agorootparentprevUsed to be, while Jobs was still around.These days it&#x27;s just a bunch of wannabes trying too hard to be him. reply Joeri 7 hours agorootparentprevBut how would they then keep up their profit margins to keep shareholders happy? Their first obligation is to the shareholder, not to the customer.(I think it is ridiculous that the system works in that way, especially for a company that hasn’t needed investors in over a decade, but it is what it is.) reply pb7 17 hours agorootparentprevIt&#x27;s a bug... reply tpmx 17 hours agorootparentIt&#x27;s a device bricking bug. For a $2.5-10k device. reply astrange 13 hours agorootparentBrick usually means unfixable without an EEPROM replacement or data loss.It&#x27;s not possible (well, it&#x27;s very difficult) to do this on an Apple Silicon Mac; once there&#x27;s an update you can always apply it from another Mac, like the steps on this page do, and your data is still there. With Intel Macs it&#x27;s possible. reply cesarb 13 hours agorootparent> Brick usually means unfixable without an EEPROM replacement or data loss.The definition of \"bricked\" is not set in stone; a lot of what a normal person would consider \"bricked\" (doesn&#x27;t turn on, or turns on to an unresponsive black screen, and no magic sequence of button presses can reset it to working order) could be fixed by a power user with the right equipment, software, and knowledge.In this case, it requires fairly expensive equipment (another $2.5-10k device), somewhat easy to acquire software, and the appropriate set of instructions, to overwrite the device&#x27;s broken firmware with a working copy; you don&#x27;t have to open up the device and plug a JTAG adapter, but using the DFU protocol is very similar to that, since in both cases you&#x27;re writing directly to the firmware under control of an external device. This is not like \"BIOS FlashBack\" and similar on non-Apple PCs, in which the device can rewrite its firmware by itself from a common USB stick.(Also, about data loss: a device with removable storage could get bricked without any data loss, and fixed also without any data loss, simply because the data storage is separated from the firmware and from most of the hardware. It&#x27;s Apple&#x27;s insistence on non-removable storage which risks losing data when something else makes the device fail to boot.) reply astrange 12 hours agorootparent> In this case, it requires fairly expensive equipment (another $2.5-10k device)A few minutes of access to one, not ownership of it, and hardly any system requirements on it.> It&#x27;s Apple&#x27;s insistence on non-removable storage which risks losing data when something else makes the device fail to boot.That&#x27;s actually not the reason. All storage is removable if you just desolder it. It&#x27;s because the storage is encrypted and you can&#x27;t extract the keys. replyatregir 17 hours agoparentprevAlso what&#x27;s with the magic trick of entering DFU mode by pressing the buttons at a very specific time for a very specific number of seconds? Felt like singing a song to some fictional Mac OS gods and hoping for the stars to align for the laptop to show up in the second Mac. Ah, also the port you use for the USB-C cable matters!! Has to be the first from the left? But why?Anw, I followed a video by Mr. Macintosh and managed to get mine up and running, whew. reply adamomada 14 hours agorootparentWell it’s a mode you really don’t want users going into if they didn’t intend to, so it kind of makes sense to only activate if the user has deliberately done an action that would not happen randomly.See Also: entering bootloader mode in android devices reply magicpointer 4 hours agoparentprevAlso with the M1 Pro MacBook, my LG USB-C monitor broke during the upgrade. Black screen, same on another connected USB-C laptop. Tried different cables, unplugging power from the monitor and factory reset on the monitor, no luck. Other inputs like HDMI and DisplayPort still work. I don&#x27;t think the breakage during the upgrade is a coincidence.I would really advise against having anything connected to the Macbook during upgrades, except the charger... reply user9163 17 hours agoparentprevya - I cant update my m1 macbook air without going into DFU mode and using configurator to “revive” my macbook. Otherwise it just tells me “Failed to personalize the software update”. Made the mistake of going to the Apple Store where they promptly restored my machine deleting all my data - only to encounter the exact same issue when the next update is shipped. This way you cant even show them that their fix did not actually fixed it permanently. reply samcat116 13 hours agoparentprevI&#x27;ve done this several times with a TB3 cable. Has to be the right port for DFU. reply JohnMakin 19 hours agoparentprevExact same thing happened to me. reply tpmx 16 hours agorootparentWhat kind of HW? reply JohnMakin 16 hours agorootparentsame specs as OP reply tpmx 16 hours agorootparent:( replyvbezhenar 19 hours agoprevToday I had to DFU restore my macbook because I wanted to reinstall it, but built-in restore over the web did not work. My base system was 13.2, it downloads all the files for 13.6, it filled bar to 100% and then spewed error.It&#x27;s obvious that it&#x27;s some incompatibility between 13.2 base system and 13.6 install. Apple quality is atrocious these days. One would have thought they would test the most basic scenarios before releasing their x.6 software.And worse of all, there&#x27;s no official (or even unofficial, at least I wasn&#x27;t able to find one) way to create USB boot installer without another Mac or to DFU restore Mac without another Mac. Do they think I live in Apple Store? I don&#x27;t have other Mac. I was able to DFU restore with libimobiledevice, god bless its creator, but it really should not happen. Windows or Linux are so much more transparent compared to macOS. reply baz00 18 hours agoparentYeah the Apple bootloader and restore stuff scares the shit out of me. The network access requirement, firmware on SSD and hardware lock are always lurking waiting for the most inconvenient time to go wonky when I hose something.Conversely windows, just got a USB stick in the drawer I can boot off. reply jonhohle 27 minutes agorootparentIn the FireWire days, you could firmware boot a Mac into target disk mode and plug it into another mac where it would show up as a disk.How far we’ve fallen. reply cesarb 12 hours agorootparentprev> Conversely windows, just got a USB stick in the drawer I can boot off.It goes further than that, on many motherboards even a failed firmware update can be fixed through a random USB stick from the drawer, you just need the right BIOS file to put in it. reply acheong08 6 hours agorootparentprev> Conversely windows, just got a USB stick in the drawer I can boot off.Linux as well. Will probably work better than windows on older hardware reply EstesPark 16 hours agorootparentprevAs a lifelong Mac user, it just now hit me how inconvenient locked down the restore process is. reply jamesfmilne 18 hours agoparentprevYes same here. I did install then uninstall Avahi Linux a year or so ago, but now I can&#x27;t upgrade past 12.6.I&#x27;ll need to get an external drive, back everything up, then do a DFU restore on my M1 Max MBP to get it upgraded to Sonoma. reply acheong08 6 hours agorootparentI deleted the MacOS installation on my (older) Mac. Linux works well enough reply jiripospisil 19 hours agoprev> Do not let them charge you any money for it. This is a problem Apple caused, and purely a software issue. If the technicians claim there is hardware damage, they are wrong.Good luck with that. reply crazygringo 19 hours agoparentThe Apple Store is usually great with this stuff.If there&#x27;s a documented problem that affects your hardware model and the given software versions, they&#x27;re extremely unlikely to try to charge you for anything. reply baz00 18 hours agorootparentIf it&#x27;s not documented and you have a problem then you are usually shit out of luck. The early days of butterfly keyboards was hell for a lot of people. I managed to get mine back to them for a full refund 3 days after I got it thank fuck. reply somehnguy 1 hour agorootparentI got a full MacBook Pro replacement when my MBP had something wrong causing it to charge extremely slowly - completely on Apple&#x27;s dime. They first sent me an overnight shipping box to send in my MBP, where they then replaced the top case assembly. After that didn&#x27;t work they overnighted me a brand new in box MBP.I had to spend 6+ hours on the phone over multiple days with a senior tech support staff to make it happen, but at least it was eventually resolved and I didn&#x27;t pay anything for it. Obviously it wasn&#x27;t a documented problem because we troubleshooted everything possible before replacement. reply rollcat 1 hour agorootparentprevYep, my experience has usually been the opposite. \"We normally charge for fixing this, but we&#x27;re a little embarrassed that this happened so it&#x27;s free\". reply saagarjha 16 hours agorootparentprevDocumented by whom? Are you going to show a marcan post to them and claim it’s an Apple issue? reply gpm 11 hours agorootparentMarcan&#x27;s post contains apple ticket numbers... presumably you show them those. reply krackers 10 hours agorootparentApple store employees probably may not have access to bug reports that their engineers would be able to access? reply p_l 4 hours agorootparentIn many countries Apple stores aren&#x27;t run by Apple and won&#x27;t have access to bug reports. reply throwaway290 1 hour agorootparentUh, what? You mean the actual Apple Stores (which are only available in select countries) are not run by Apple? That would be new.If you mean various third party resellers then of course, it&#x27;s just a run of the mill shop that happens to sell Apple products, a completely different experience. replySpaceManNabs 18 hours agoparentprevI didn&#x27;t have much trouble. When MacbooksAir 2011 version had those SSD hardware failures, I told multiple classmates of mine about the hardware failure page and they got the repairs for free instead of spending $800. reply cleansingfire 19 hours agoprevOnly affects Apple silicon chips (intel unaffected) with ProMotion display. Just a quick Exit clause for people with older machines. reply meithecatte 14 hours agoparentOnly one of the two bugs listed requires a ProMotion display. The other one can occur on all Apple silicon machines. reply ehutch79 2 hours agoprevReading many of the comments here… I wonder if a lot of hacker news commenters have actually met real, everyday users of technology. Not other nerds and grognards, but like, the lady sitting over in a cubical, who only knows enough about computers to do their job.Do you really think users want graphic mode selection on boot? What percent of Mac users have alternate bootloaders or even know what that means.A lot of commenters need to do some time in the proverbial trenches and support a fleet of devices at a large company. See if users really care about the things you think they do. reply OJFord 1 hour agoparentFrom the submission:> Once System Firmware is updated to the macOS Sonoma version, if the display is configured to a refresh rate other than ProMotion, that system will no longer be able to boot into older macOS installs nor Asahi Linux correctly. This includes recovery mode when those systems are set as the default boot OS, and also System Recovery at least until the next subsequent OS upgrade.That can and will absolutely affect regular users, even if they don&#x27;t &#x27;care&#x27; about it or &#x27;know what it means&#x27;. reply eddieroger 4 minutes agorootparent> that system will no longer be able to boot into older macOS installsNo, that seems pretty super-user to me. The average user goes forward in versions, not back, and rarely has two at the same time. reply throwaway290 54 minutes agoparentprevIf you met an everyday user of technology you&#x27;d see that he&#x2F;she is completely fine simply remembering what to click on a cryptic screen which no one understands or has time to spend looking up. Just think of all the notifications and alerts about various security stuff while you need to get things done. Muscle memory. Except unlike security warnings, dismissing which can pwn you, in this case it could one day save your system&#x2F;work so I don&#x27;t see how it&#x27;s not worthwhile.This issue can occur to any user who wants to have two macOS versions for whatever reason. Not that extraordinary especially between creative professionals reply jcul 56 minutes agoprevI&#x27;m not a Mac or Asahi user (though I think it is an amazing project).However, this is such a great write up, very thorough with root cause, mitigations etc.Keep up the good work! reply mattchamb 20 hours agoprevNot sure if related, but my 2020 M1 macbook air bricked a week or so after upgrading to Sonoma. I was suspicious if this was related to the update. Luckily the logic board was replaced for free under warranty laws here, though it put me off switching to iphone which I was a day away from doing. reply bscphil 19 hours agoparentUpgrades bricking hardware seems to be a common failure mode for macOS. For example Big Sur bricked a bunch of 2013 and 2014 MBPs: https:&#x2F;&#x2F;www.macrumors.com&#x2F;2020&#x2F;11&#x2F;15&#x2F;macos-big-sur-update-br...I was affected by this and like many users the problem was fixed after replacing the I&#x2F;O board. In my case, I did it myself using a $10 part from Ebay since the machine was well out of warranty at that point. reply miles 19 hours agorootparentFrom comments #736 and #747 attached to the forum post you kindly shared, it sounds like simply disconnecting and reconnecting the I&#x2F;O board may be sufficient (found those comments linked in #831):https:&#x2F;&#x2F;forums.macrumors.com&#x2F;threads&#x2F;macos-big-sur-update-br...https:&#x2F;&#x2F;forums.macrumors.com&#x2F;threads&#x2F;macos-big-sur-update-br...https:&#x2F;&#x2F;forums.macrumors.com&#x2F;threads&#x2F;macos-big-sur-update-br... reply fifteen1506 18 hours agorootparentAnd this is why there will never be a Year of the Linux Desktop -- no-one wants to have to depend on forum posts to fix these kind of issues.&#x2F;troll reply coldtea 18 hours agorootparentWhy the \"&#x2F;troll\"? You&#x27;re 100% right non-ironically: the problem being that on Linux the need to consult forum posts to fix these kind of issues is way more frequent than in macOS. reply jonhohle 8 minutes agorootparentThis is anecdotal, but my last “corporate job” was the closest to thing to shrink-wrapped software, even though it was a SaaS. Every release was meticulously documented. Any public facing UI or API change was approved the appropriate teams.This is similar to macOS, Windows, or even FreeBSD releases. I haven’t seen any Linux distribution that has such comprehensively coordinated releases. Between systemd and the Linux kernel, I’m not sure it would be possible.Many distros have good documentation, but, in my experience, far too often the bulk of it is in out of date wikis or forums. Perhaps this is out of date thinking and I’ve missed the train in the past 10 years.As a counterpoint, OpenWRT has been good, but their main “product”, imho, is LuCI. Lower level issues often require vendor specific forums. reply bscphil 15 hours agorootparentprevBy the standard of \"do you ever need to consult forum posts to solve a problem\", sure, Linux is worse than macOS. By the standard of \"do you ever need to consult forum posts to fix hardware that has apparently been bricked by a software update\", macOS seems to be considerably worse. At least, that&#x27;s my experience. I&#x27;ve never had hardware damaged by Linux, which I&#x27;ve run almost exclusively. On the other hand the one Apple device I&#x27;ve ever owned got bricked by their software update.I can&#x27;t say I&#x27;ve heard of that happening to people on Linux at all other than maybe early days of Xorg. Damage (reversible or otherwise) to hardware is extraordinarily rare on Linux, I can only think of it happening during the very early days of EFI and only under very specific conditions. reply cesarb 14 hours agorootparent> I&#x27;ve never had hardware damaged by Linux, which I&#x27;ve run almost exclusively. [...] I can&#x27;t say I&#x27;ve heard of that happening to people on Linux at all other than maybe early days of Xorg.There was that LG CD-ROM drive which treated a CD-RW command (which it should ignore or reject since it&#x27;s not a CD-RW drive) as a firmware upload command. When a newer Linux kernel started using that command, these drives got bricked (source: https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;55537&#x2F; and https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20041204072839&#x2F;http:&#x2F;&#x2F;www.mandra...). reply gpm 13 hours agorootparentMore recently there was \"rm -rf &#x2F;\" wiping efivars and bricking some motherboards with shitty uefi implementations thanks to systemd mounting efivars rw by default (and shitty motherboard firmware). The kernel \"fixed\" this by mounting unknown efivars as (mostly) immutable.https:&#x2F;&#x2F;www.phoronix.com&#x2F;news&#x2F;UEFI-rm-root-directoryhttps:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;filesystems&#x2F;efivarfs.... reply cesarb 12 hours agorootparentThere were also some motherboards with shitty UEFI implementations which got bricked when the efivars storage did not have enough free space to do the garbage collection. The kernel \"fixed\" this by not allowing more than half of the efivars storage to be used (https:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;linux&#x2F;kernel&#x2F;git&#x2F;torvalds&#x2F;lin...). reply bscphil 11 hours agorootparentprevRight, this is what I meant by the EFI brick in my comment. And in my comment \"I can&#x27;t say I&#x27;ve heard of that happening\", I meant bricking a device on a system update. That&#x27;s the specific thing which seems to happen on occasion with macOS, but that I&#x27;ve not seen with Linux. I do grant that there have been some (very rare) instances like this where hardware can be bricked by a command run on a Linux system. reply umanwizard 6 hours agorootparentprev> macOS seems to be considerably worseMost users will just take their machine in to the Apple Store when this kind of thing happens, rather than try to fix it themselves. reply m45t3r 4 hours agorootparentSure, doesn&#x27;t make this any less inconvenient though. I would much prefer to finish whatever I want to finish today (even if I spend a few hours trying to fix an issue) than wait whatever amount of days waiting until my hardware is fixed. reply umanwizard 1 hour agorootparent> doesn&#x27;t make this any less inconvenient thoughYou&#x27;re right that it&#x27;s not ideal, but it certainly makes it a lot _less_ inconvenient than being completely stuck forever (as most non-highly-technical people would be if they had to follow instructions on forums to fix Linux). reply fsflover 17 hours agorootparentprevOn Linux it&#x27;s as rare as on MacOS, if you buy preinstalled. reply coldtea 15 hours agorootparentAs long as you don&#x27;t do anything with it on your own. reply kelnos 12 hours agorootparentSo essentially, the situation you&#x27;d have if you&#x27;d bought a Mac?If we want to compare apples to apples, then we compare:Mac with macOS updates installed regularly, and only those provided by Apple. Non-Apple apps get dropped in &#x2F;Applications like they should be. If there&#x27;s an installer that asks for root access, you might get boned.Linux preinstalled with OS updates installed regularly, and only those provided by the vendor. Apps that don&#x27;t come with the OS&#x27;s package manager should be installed somewhere under $HOME, and never installed systemwide as root.Sure, if you have a Mac and disable SIP (or whatever it&#x27;s called nowadays) and start mucking around with files in &#x2F;System or whatever, because you want to install some mod that does something cool, you might have a bad time. Same as if you decide that screwing around in &#x2F;lib on a Linux machine is a good idea.But if we actually compare these two apples, I suspect the Linux one would have fewer problems. reply coldtea 7 hours agorootparent>So essentially, the situation you&#x27;d have if you&#x27;d bought a Mac?No, worse, with more device incompatibilities, manual fiddling, arcane settings, and so on to make things work.>Sure, if you have a Mac and disable SIP (or whatever it&#x27;s called nowadays) and start mucking around with files in &#x2F;System or whatever, because you want to install some mod that does something cool, you might have a bad time.Sure, but I&#x27;m not talking about that. With Linux you often have a bad time trying to make basic, but not distro configured, functionality to work. reply fsflover 6 hours agorootparent> with more device incompatibilities, manual fiddlingDid you read what I wrote above? \"if you buy preinstalled\"If you install Linux on an ordinary \"Windows-certified\" computer, you will have problems. If you install an alternative OS on a Macbook, you will have exactly the same problems. reply coldtea 4 hours agorootparent>Did you read what I wrote above? \"if you buy preinstalled\"And did you understand my point? Buying preinstalled isn&#x27;t a cure-all, only ensures that the bundled hardware drivers are compatible and configured. That&#x27;s a pretty low bar.It doesn&#x27;t cover doing stuff with third party devices (which on the Mac 99% of the time it works every time).Not to mention even the bundled-hardware doesn&#x27;t always work even if you buy pre-installed (like the laptop not sleeping properly for example). reply fsflover 2 hours agorootparent> Not to mention even the bundled-hardware doesn&#x27;t always work even if you buy pre-installed (like the laptop not sleeping properly for example).I agree that this is not tolerable. However my devices from Purism have a reliable sleep and other functionality out of the box.> third party devicesCheck Linux compatibility before buying and they will work reliably. Works for me. replyWowfunhappy 17 hours agorootparentprevThis issue in GP is unrelated to Linux, it happens on single-boot macOS. reply yjftsjthsd-h 14 hours agorootparentThat&#x27;s the point, I think - Linux gets derided because people say it just breaks at random and you have to wade through forums to find arcane incantations to fix it, either implying or outright stating that their favorite proprietary OS would never just blow up in your face and force you to resort to exotic troubleshooting steps. So when macos, the poster child for \"user friendly\", proceeds to brick the machine and require elaborate rituals to fix, it invites a certain level of snark from users pointing out that the high and mighty proprietary OSs might be just as bad as Linux after all.Of course, whether that&#x27;s valid is at minimum a question of actual frequency of problems and relative impact and effort to fix, but from a perspective of optics and emotions I understand the reaction. reply m45t3r 3 hours agorootparentI concur, the amount of times I had to Google dozens of minutes for issues happening in my work-issued Macbook Pro, and never finding answers because things are supposed to \"just work\" is maddening.For one example on top of my head, sometimes I can&#x27;t adjust the brightness of the monitor in the Macbook using the Notification Center (it is grayed out), but if I open the \"Settings -> Displays\" I can do it. Never found a solution for it after searching for a while, so I just gave up.Or the fact that I can&#x27;t enable retina or font smoothing in my 1440p monitor, so the fonts looks ugly (I got used eventually, but they still looks worse than Windows or Linux in the same monitor). I used a workaround in the past using \"Better Display\" to create a 4k framebuffer that was downscaled to 1440p, but this was so slow and also prone of other issues so eventually I just got used to the ugly fonts.Another one: I have a TouchBar Macbook (again, this is a work-issued laptop), but I just want it to work as a normal keyboard: show the Function keys, if I press Fn show the shortcuts. Yep, doesn&#x27;t work: while you can do this, pressing Fn while pressing some of the shortcuts in the TouchBar doesn&#x27;t work. This is especially infuriating because one of the shortcuts that doesn&#x27;t work is the brightness one. Go back to the first issue and you can see why this drive me mad sometimes. replyaetherspawn 16 hours agoparentprevFWIW I have been using iPhones for 10+ years and not once has an update ever failed or had any issues.But my Google Pixel phone used to brick itself all the time, I think twice in the two years I had it. reply kelnos 12 hours agorootparentI&#x27;ve never had an Android phone brick itself in 13 years of owning them. I have friends whose iPhones have gotten bad updates. Not sure if they were bricked, though, or if they \"only\" needed a factory reset to get things going again. reply Kuinox 12 hours agorootparentprevIn the same period, 10-12 years ago, both androids and iPhones bricked themselves if there was no storage left on the device. Both needed somes bytes on boot and if they couldn&#x27;t write on disk, they failed to boot. reply dehrmann 11 hours agorootparentprevPhones are Apple&#x27;s main business. At this point, Macs are second-tier. With Google, I suspect it&#x27;s their engineering practice. Google doesn&#x27;t like to make engineering mistakes. reply windowsrookie 19 hours agoparentprevThe logic Board failed in my 2020 M1 Air as well. Opened the lid one day, and it wouldn&#x27;t power on. I have AppleCare on it, otherwise it would have been a $500 repair.About two weeks ago I&#x27;m sitting in a hotel room with the air on bed with the lid open. I grab it by the screen to slide it closer to me and the screen shatters from the light pressure of my finger.There are instances of both these things happening to the Air all over the internet. At first I really liked the M1 Air, but it has now proven too unreliable for me. reply VagabundoP 7 hours agorootparentMy wife is still rocking a 2012 Mac air and uses it regularly. Apart from never rebooting it - WHAT ABUT MY TABS - its a sturdy little fellow.Shame to hear the build quality in the latest is so poor. reply theodric 18 hours agorootparentprevMy 2020 M1 Air generally requires a hard reboot if left closed and on a charger overnight, but that&#x27;s been the worst of it until now (besides the rapidly degrading battery that seems calibrated to hit 79% a month after my AppleCare+ expires, while my 2015 Air&#x27;s is still going strong).Premium™ reply teaearlgraycold 19 hours agoparentprevSeems like a weird rationale. Any manufacturer is going to have its share of software and hardware issues. reply benreesman 3 hours agoprevI don’t know what’s going on with Apple lately. They’ve built one of the world’s best brands after a near-death experience via a ruthless focus on and fanatical commitment to providing a holistically premium experience (for the people who want their version of that) to justify their premium pricing and huge margins. If you like what they do, it Just Works from purchase on. Or did until recently.Just today I had an experience that was so Kafkaesque it felt like a mean spirited prank, and because they never fuck up this badly, I had no contingency plan for one of the times it matters a lot.Any advice on how to get the “we fix things for loyal customers by doing what’s required” people on the phone would be appreciated, but based on the runaround, infinite hold Ferris wheel the primary support line apparently is now, I’m not getting my hopes up. reply SamuelAdams 3 hours agoparentThe Apple today is very different from the Apple of 20 years ago. The brand is the same, yes, but the people are all largely different. You see this all the time in the video game industry, ie Blizzard, Bungie, 343 industries.Maybe the newest group of programmers and engineers are dealing with a very complicated code base? Maybe no one fully understands everything involved until something breaks? reply benreesman 3 hours agorootparentJust my N=1 anectdote, but I’ve been having almost universally great experiences until maybe 2 or 3 months ago.On the software side, I tend to tolerate more security risk (within reason) to delay updates until a consensus emerges that they’re robust, because I’m not a high value target to anyone north of “script kiddy” and run a tight ship on the easy stuff, so the EV of an abruptly unusable work machine vs. getting pwned weighs heavily relative to winding up in the crosshairs of anyone sophisticated enough to exploit a recent CVE. My online banking is properly 2-fac’d, if anyone wants to read my browser history or email and cares enough to go ti that trouble, I’ll want them that I’m not important enough for it to be worth the trouble.This would clearly change if my work went back to having demanding security requirements, but it doesn’t just now.It’s really the customer service, fulfillment, Apple Store experience (it used to feel like stepping into the least stressful room in the mall and now it’s a zoo). reply MichaelZuo 1 hour agorootparentprevIt&#x27;s likely not a single person understands the entire MacOS stack anymore, at least since Mavericks, all the pre-1985 old guard engineers having retired by then. reply gcr 20 hours agoprevTL;DR: Recent macOS Sonoma and 13.6 Ventura have upgrade bugs that brick some macs and make recoveryOS unusable, causing a black screen that requires a DFU revive.Issues on Sonoma appear most often on dual-booting macs: https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT208891Ventura upgrades can also bite you if your display refresh rate is set to anything other than ProMotion, for unclear reasons.The doc is on the Asahi Linux wiki because their developers discovered this issue, but it&#x27;s not unique to Asahi. In fact, running the Asahi Linux installer can detect whether your mac will be affected by this issue, even if you ultimately choose not to install Asahi Linux. See the article for details. reply markmark 13 hours agoparentErg, I ran into this on my mac twice when I upgraded. I have two bootable OSX partitions and it hit on both upgrades. I&#x27;m not really a mac guy and it took a _lot_ of messing around (and learning that DFU exists and what it does) to sort out. Just lucky that my daughter has a mac so that I could even use DFU without having to take the thing into an apple store. reply bitigchi 20 hours agoprevI am somewhat glad that there is a 3rd party that actively helps finding macOS issues. reply keepamovin 11 hours agoprevWhen I saw the upgrade to Sonoma appear in my Settings I had a feeling the first version of this new OS would be buggy so I held off on it. Now extra glad I did! Gonna stick with Ventura for a while! Haha ! :) reply ch13_ 9 hours agoparentAgreed reply jug 17 hours agoprevI wonder if this is behind a failed Sonoma upgrade I saw on eBay today; Mac Mini M2 Pro sold as-is for a very decent price, about $300-$400 off despite from this year. :) Seller didn&#x27;t know what was wrong with the Mac, only that it happened during Sonoma upgrade and this sounds mighty suspicious for such a new machine if it&#x27;s widespread. reply racl101 20 hours agoprevI am so terrified of this upgrade that I think I&#x27;ll wait a whole year. That&#x27;s not a good thing. reply hbn 19 hours agoparentI pretty much always wait 6 months or so for Mac upgrades on whatever machine is important to me. There seems to pretty consistently be regular bugfix updates for the few months following a release. reply shever73 17 hours agoparentprevThat’s probably wise. I wish I had waited. Since upgrading to Sonoma, I have recurring issues with the system file dialog. Sometimes the dialog will open, but not allow me to save, other times it will just fail to open altogether.Any time I start a new video project now, I save it instantly because Command+S still works, but if it opens the Save As dialog then it frequently won’t. reply cramjabsyn 19 hours agoparentprevIts realistically what you should be doing unless your machine is a test host itself. reply rangestransform 18 hours agoparentprevthis happened to my work macbook while I was trying to upgrade to ventura, a 1 year old macos version reply teaearlgraycold 19 hours agoparentprevUnless you aren’t doing anything important on your Mac that’s always good advice. reply doubloon 16 hours agoprevin 30 years we have gone from the idea that your computer could accidentally brick your monitor, to the idea that your monitor could accidentally brick your computer.https:&#x2F;&#x2F;trixter.oldskool.org&#x2F;2006&#x2F;02&#x2F;02&#x2F;computing-myth-1-sof... reply wizzard0 6 hours agoprevFYI the Asahi Linux installer says “please upgrade that should help” but bumping 13.6 -> Sonoma 14.1 did not help, the SystemRecovery still shows up as 13.5Or does that mean wait for 14.2? reply SpaceManNabs 18 hours agoprevThis seems like a very unusual bug by Apple standards. Makes me consider upgrading to new macbooks... reply dgellow 17 hours agoparentAt this point it’s kind of common knowledge to wait a while before upgrading macOS to latest major version. I don’t remember a major update that didn’t come with its own set of problems. reply cromka 3 hours agoparentprevI don’t know, it’s pretty high there on the list of their complete fuckups, like allowing anyone to log in as root from the login dialog… reply dharma1 17 hours agoprevHad another weird refresh rate bug with 14.1 - external display doesn’t have a HDR option in settings at 120hz anymore - only works with HDR if I change the refresh rate 100hz or lower. Was fine in earlier MacOS reply da768 17 hours agoprevCan something be done using VoiceOver boot mode? I&#x27;ve already recovered macs stuck on 0 brightness after an upgrade with that... Can&#x27;t find the documentation now, but it definitely exists. reply user3939382 3 hours agoprevTangentially related, ever since upgrading to Sonoma my computer reboots when I put it to sleep. I’ve heard the same from other users. reply Alifatisk 5 hours agoprevThis is why I am not so quick with upgrading to next major version anymore. reply cramjabsyn 19 hours agoprevThis is exactly why I lag one major version behind the latest. reply als0 19 hours agoparentWell, this also affects the previous major version, macOS Ventura 13.6 reply silverwind 17 hours agorootparentJust don&#x27;t upgrade to any version ending in 0. reply lynguist 4 hours agorootparent13.6.1 is also affected. reply cromka 3 hours agorootparentNeed to wait for 13.6.1.1 reply supportengineer 18 hours agorootparentprevThis is exactly why I lag two or three versions behind the latest. reply formerly_proven 17 hours agorootparentThis is why I&#x27;m still using RHEL 7. reply cirrus3 14 hours agorootparentprevIf that is the case, why does the OP label it as a Sonoma issue? reply theodric 18 hours agoparentprevThis is why I&#x27;m still on Big Sur-- it mostly works! reply Apocryphon 16 hours agorootparentOne of my machines is still on Mojave- my 32-bit games still work! reply pseingatl 11 hours agorootparentPicasa will only run on 32 bit as well. reply sameg14 16 hours agoprevI had this exact thing happen to me when I tried to reset a Mac and wipe it clean. Would not start up and went into this doom loop when booting with the apple logo and a black screen. No amount of key combinations worked. I had to drop into DFU, which is a huge pain to get into to begin with and then use another Mac to recover. reply nusaru 19 hours agoprev> macOS Ventura 13.6Well dang, I just upgraded yesterday, too. Fingers crossed that nothing breaks... reply RadixDLT 8 hours agoprevthere&#x27;s something fundamentally wrong at apple theses days, macos just doesn&#x27;t work like it used to reply mstep 19 hours agoprevdoes anyone have info if this is fixed in ventura 13.6.1? https:&#x2F;&#x2F;support.apple.com&#x2F;de-at&#x2F;HT213985 reply kppullin 15 hours agoparentI just installed 13.6.1 on an M1 MacBook Pro and am now facing the boot issue, so I&#x27;m guessing it&#x27;s not fixed :). To make matters worse, the specific USB port required for the DFU revive fix is broken as well, which was never an issue as the other two worked... oof. reply iudqnolq 16 hours agoprevOn a much more minor note the .0 version of the upgrade also has a big that pops up a contacts window every few minutes and steals keyboard focus. reply dclowd9901 8 hours agoprevMan, I had a rough week last week. Shipped two regressions. Seeing this story, as awful as it must be for the responsible eng, has really made me feel much better. Not schadenfreude. Just commiseration. reply asylteltine 19 hours agoprevI’m an apple fanboy and let me be the first to say their SDLC since the pandemic has been AWFUL. I have never had so many bugs with apple devices. And I’m not talking about giant catastrophic bugs you would expect with windows or Linux. I mean little things, like random phone reboots, overheating, my mac restarting when I wake up from sleep, internet issues, etc. They need a shake up and to stop focusing on all these features NO ONE uses. Can one person tell me they use the features they just announced? Nobody even knows you can edit an iMessage still. reply aetherspawn 16 hours agoparentI agree, I started buying some Macbooks for work and was horrified when the Launchpad just wouldn&#x27;t open on a brand new Mac.Like, you press Launchpad, and it just ... doesn&#x27;t open. sometimes. This kind of rancid stuff you would expect on Windows (i.e. after upgrade to Windows 11, half our laptops can&#x27;t right click on the desktop sometimes) but it never used to happen on OS X. reply doubloon 13 hours agoparentprev\" . . . The new version - it&#x27;s not there to fix bugs. That&#x27;s not the reason we come up with a new version. \" - Bill Gateshttp:&#x2F;&#x2F;www.cantrip.org&#x2F;nobugs.html reply ShadowBanThis01 11 hours agoprevThe Sonoma update bricked my M1 MBP and Apple had to wipe the whole thing.Something stinks in this thing. reply tempodox 18 hours agoprevHoly fuck, thanks for the warning! I&#x27;m just glad I didn&#x27;t upgrade to 13.6 yet. And installing Sonoma on a second volume to try it out is also out of the picture for the foreseeable future. Apple&#x27;s OSs seem to get worse with every turn. Maybe I shouldn&#x27;t touch Sonoma at all. What&#x27;s the point on an Intel Mac anyway? reply alberth 19 hours agoprevAbstraction Layers.We&#x27;ve gotten to point with the huge number of abstraction layers (and now AI as well) that troubleshooting what causes system to do what it did, has become so unwieldily difficult to diagnosis. reply jahewson 19 hours agoparentThis doesn’t seem to be the problem here? It’s an issue of having a combinatorial number of versions to test when upgrading software and firmware. reply JohnMakin 19 hours agoprevLost a workstation to this last week. infuriating. reply cirrus3 14 hours agoprevFirst I&#x27;ve heard of any issues.. I have done a couple upgrades already with no issue. I&#x27;m sure there are some scenarios where it fails, but Sonoma has been out a while with millions of users being prompted constantly to upgrade. Feels like less than a \"you&#x27;re holding it wrong\" problem. HN is obv going to bring out the edge cases, but it doesn&#x27;t seem like the world is on fire with \"Sonoma Bricks\" by any means. reply bigDinosaur 4 hours agoparentI use a lot of Apple products but this attitude you&#x27;re expressing has always annoyed me (because I see it most frequently when it comes to Apple&#x27;s software and hardware quality). These bugs affect people all the time and are indicative of poor QA. 5 users at a company we provide some software support for (note: we don&#x27;t control their machines) decided to upgrade their machines and somehow became unbootable just yesterday. Please don&#x27;t be in denial about Apple&#x27;s increasingly worse QA. An intern with a checklist could have uncovered these issues. reply codingpanic 4 hours agoparentprevWe have a fleet of several hundred Macs, most are M1&#x2F;2 at this point. I heard reports of several Macs coming in for support that booted to a black screen after Sonoma&#x27;s .0 landed. So many that the JAMF team blocked Sonoma until the .1 landed.Definitely shoddy QA on Apple&#x27;s part. Also, your sample size is too small. Everyone works differently and it takes a certain set of settings&#x2F;workflows to trigger this compatibility issue. reply markmark 13 hours agoparentprevDo you dual boot? I&#x27;ve got two bootable OSX partitions on my mac and this hit me when I updated. reply KingLancelot 19 hours agoprev [–] I think my 2014 MacBook on MacOS 12.5 was affected by this too.I had Ubuntu installed in a second partition and it refuses to boot ever since I installed 12.5.1 on it. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MacBook Pro users have been experiencing severe boot failures due to significant bugs in macOS Sonoma and macOS Ventura 13.6, leading to persistent black screens.",
      "The bugs affect all users, including those who have and haven't installed Asahi Linux, with the installer now checking for these issues automatically.",
      "Users are advised to refrain from system upgrades until Apple rectifies the bugs. Those already impacted can use the Asahi Linux installer for diagnoses and solutions, while those unable to boot may require DFU (Device Firmware Update) mode for recovery."
    ],
    "commentSummary": [
      "Apple's decision to store a display refresh rate in a device's Non-Volatile Random-Access Memory (NVRAM) could potentially cause boot corruption in macOS, based on user discussions on Hacker News.",
      "This issue seems to be associated with altering display modes, outdated bootloader software, and potential problems with certain macOS updates. Some users have faced hardware failure and have concerns about Apple's response.",
      "Users have debated between graphical Extensible Firmware Interfaces (EFI) and text-only alternatives, with wider conversations addressing different user interfaces, boot loaders, and how screen resolutions impact computer performance."
    ],
    "points": 596,
    "commentCount": 246,
    "retryCount": 0,
    "time": 1698777232
  },
  {
    "id": 38087573,
    "title": "Firefox got faster for real users in 2023",
    "originLink": "https://hacks.mozilla.org/2023/10/down-and-to-the-right-firefox-got-faster-for-real-users-in-2023/",
    "originBody": "HACKS Hacks on YouTube @mozhacks on Twitter Hacks RSS Feed Download Firefox Down and to the Right: Firefox Got Faster for Real Users in 2023 By Bas Schouten Posted on October 31, 2023 in Developer Tools, Featured Article, Firefox, and JavaScript One of the biggest challenges for any software is to determine how changes impact user experience in the real world. Whether it’s the processing speed of video editing software or the smoothness of a browsing experience, there’s only so much you can tell from testing in a controlled lab environment. While local experiments can provide plenty of metrics, improvements to those metrics may not translate to a better user experience. This can be especially challenging with complex client software running third-party code like Firefox, and it’s a big reason why we’ve undertaken the Speedometer 3 effort alongside other web browsers. Our goal is to build performance tests that simulate real-world user experiences so that browsers have better tools to drive improvements for real users on real webpages. While it’s easy to see that benchmarks have improved in Firefox throughout the year as a result of this work, what we really care about is how much those wins are being felt by our users. In order to measure the user experience, Firefox collects a wide range of anonymized timing metrics related to page load, responsiveness, startup and other aspects of browser performance. Collecting data while holding ourselves to the highest standards of privacy can be challenging. For example, because we rely on aggregated metrics, we lack the ability to pinpoint data from any particular website. But perhaps even more challenging is analyzing the data once collected and drawing actionable conclusions. In the future we’ll talk more about these challenges and how we’re addressing them, but in this post we’d like to share how some of the metrics that are fundamental to how our users experience the browser have improved throughout the year. Let’s start with page load. First Contentful Paint (FCP) is a better metric for felt performance than the `onload` event. We’re tracking the time it takes between receiving the first byte from the network to FCP. This tells us how much faster we are giving feedback to the user that the page is successfully loading, so it’s a critical metric for understanding the user experience. While much of this is up to web pages themselves, if the browser improves performance across the board, we expect this number to go down. Image 1 – Median time from Response Start to First Contentful Paint in milliseconds We can see that this time improved from roughly 250ms at the start of the year to 215ms in October. This means that a user receives feedback on page loads almost 15% faster than they did at the start of the year. And it’s important to note that this is all the result of optimization work that didn’t even explicitly target pageload. In order to understand where this improvement is coming from, let’s look at another piece of timing data: the amount of time that was spent executing JavaScript code during a pageload. Here we are going to look at the 95th percentile, representing the most JS heavy pages and highlighting a big opportunity for us to remove friction for users. Image 2 – 95th Percentile of JS execution time during pageload in milliseconds This shows the 95th percentile improving from ~1560ms at the beginning of the year, to ~1260ms in October. This represents a considerable improvement of 300ms, or almost 20%, and is likely responsible for a significant portion of the reduced FCP times. This makes sense, since Speedometer 3 work has led to significant optimizations to the SpiderMonkey JavaScript engine (a story for another post). We’d also like to know how responsive pages are after they are loaded. For example, how smooth is the response when typing on the keyboard as I write this blogpost! The primary metric we collect here is the “keypress present latency”; the time between a key being pressed on the keyboard and its result being presented onto the screen. Rendering some text to the screen may sound simple, but there’s a lot going on to make that happen – especially when web pages run main thread JavaScript to respond to the keypress event. Most typing is snappy and primarily limited by hardware (e.g. the refresh rate of the monitor), but it’s extremely disruptive when it’s not. This means it’s important to mitigate the worst cases, so we’ll again look at the 95th percentile. Image 3 – 95th Percentile of the keypress present latency Once again we see a measurable improvement. The 95th percentile hovered around 65ms for most of the year and dropped to under 59ms after the Firefox 116 and 117 releases in August. A 10% improvement to the slowest keypresses means users are experiencing more instantaneous feedback and fewer disruptions while typing. We’ve been motivated by the improvements we’re seeing in our telemetry data, and we’re convinced that our efforts this year are having a positive effect on Firefox users. We have many more optimizations in the pipeline and will share more details about those and our overall progress in future posts. About Bas Schouten More articles by Bas Schouten… Discover great resources for web development Sign up for the Mozilla Developer Newsletter: E-mail I'm okay with Mozilla handling my info as explained in this Privacy Policy. Sign up now No comments yet Post Your Comment Your name * Your e-mail * Spam robots, please fill in this field. Humans should leave it blank. Your comment Submit Comment Except where otherwise noted, content on this site is licensed under the Creative Commons Attribution Share-Alike License v3.0 or any later version.",
    "commentLink": "https://news.ycombinator.com/item?id=38087573",
    "commentBody": "Firefox got faster for real users in 2023Hacker NewspastloginFirefox got faster for real users in 2023 (hacks.mozilla.org) 594 points by kevincox 22 hours ago| hidepastfavorite262 comments myfonj 21 hours agoI can subjectively confirm that Firefox feels snappier recently and deeply appreciate and enjoy all improvements.But I have some itching concerns about that methodology with heavy anonymisation and stuff there:Couldn&#x27;t it be that the web itself got faster, and folks have better hardware?I mean, yes, generally these sloppy script kiddies with bloated frameworks produce less and less effective code … but I can imagine, that when some heavily visited page deploys a new better optimized and leaner version (I assume such things happen in reality, don&#x27;t they?), there is no way to tell it apart from telemetry data telling that everything got slightly faster on average. Or with people getting better hardware, or with OS and driver updates, etc. reply toldyouso2022 17 hours agoparentI&#x27;ve used an older firefox version from 2020(the why I did is a long story) and only updated after the webp security issue. New version felt immediately faster. reply ro-ka 19 hours agoparentprevAs older Firefox versions are still in use, too, it’s possible to check whether the improvements come from updates in Firefox itself or the web in general. reply MiddleEndian 16 hours agorootparent>the web in generalThat would certainly be overly optimistic. reply KeplerBoy 8 hours agorootparentprevThe data will be biased though. Few people will buy new hardware and install old firefox versions. reply 1vuio0pswjnm7 15 hours agoparentprevSeems like the easiest path to increased speed is to hold software constant whilst processing and networking continue to improve.Historically, software has continued to behave like a gas, expanding to fill space and consume resources. The resources generally do not belong to the software authors.Software isn&#x27;t eating the world, it&#x27;s eating your computer&#x27;s resources and the bandwidth you pay for every month. reply aetherspawn 17 hours agoparentprevIt was starting to really “feel like a hog” to me over the last 6 months, including random crashes and stutters, and I considered switching to Chrome.I hadn’t noticed until I read this, but I think that feeling has gone away recently and I had already stopped thinking about switching. reply littlestymaar 16 hours agorootparentI mostly use Firefox but I have to use Chrome on a regular basis[1] and Chrome feel slower than Firefox despite having only one open tab. On a pretty old Linux computer.[1] Because Slack still doesn&#x27;t support WebRTC on Firefox after 8 years… reply wldlyinaccurate 20 hours agoparentprevThe web is getting faster, yes. This manifests as a constant (albeit slow) downward trend in global aggregate metrics. We think this trend is mostly due to Google pushing performance metrics being linked to search rankings.However the data presented in this post shows obvious step changes in performance that correlate with browser version rollout. It would be disingenuous not to attribute this to a concerted effort on performance improvements from the Firefox team. reply MBCook 19 hours agoparentprevIt would’ve been nice to see this normalized by CPU cycles or javascript tokens executed or something like that.Something so that more megahertz&#x2F;cores doesn’t throw off the number.Whatever the reason, it is nice to see it improving. I think it would be interesting to also see a median figure in addition to a 95% figure. reply jraph 18 hours agorootparentI bet it&#x27;s difficult to normalize because performance depends on so many things. CPU cycles, but also other factors like RAM speed, swap usage, CPU cache sizes and speeds, background tasks, GPU and GPU drivers, OS, display servers (X11 vs Wayland on Linux), window managers, available fonts, and probably a ton of other things are other factors that will play a role. reply xedrac 22 hours agoprevI like seeing Mozilla actually improving Firefox instead of just shuffling UI components around. I&#x27;ve been a longtime user, and am happy to support the underdog here to try and keep some balance of power on the web. Having Mozilla focus more on their tech, and less on politics is a good thing. Regardless, Firefox is a good piece of software and I have no major qualms with it. reply Qwertious 13 hours agoparentI&#x27;m happy for Mozilla to keep shuffling UI components around - if it gets them more users then that&#x27;s good, and it&#x27;s vital that Mozilla be willing and permitted to take risks, instead of always being a step behind in every aspect.For instance, FirefoxOS seems to have been a failure, but most longshots are a failure, and if you scrimp on long shots then you end up like Microsoft, realizing that some kids these days don&#x27;t even have a laptop and their phone sure as hell isn&#x27;t running Windows. So I&#x27;m fine with more FirefoxOS-like projects. reply Alifatisk 4 hours agoparentprev> I&#x27;ve been a longtime user, and am happy to support the underdog here to try and keep some balance of power on the web.I am with you on this one, not only that but I am actually satisfied with the switch I did years ago. reply ksec 20 hours agoparentprev>Having Mozilla focus more on their tech, and less on politics is a good thing.And not just a focus on Tech but also focus on product. i.e Firefox.You could have them focus on Tech and they spend all their resources on Firefox OS. reply jacoblambda 16 hours agorootparentSpending time on Firefox OS honestly would have been a productive use case and it&#x27;d probably also be a decent revenue source for Mozilla rather than abandoning it and letting KaiOS pick it up.Especially given that it&#x27;s now become the third largest mobile OS with over 100 million active users worldwide. reply ta1243 22 hours agoprevSince upgrading to 118 I&#x27;ve had random hangs of firefox every few days. Not clear why, no CPU or swap. All windows just freeze and need a \"killall firefox\", which works - shutting firefox down cleanly.Of course it&#x27;s impossible to find anything anywhere about this due to search engine spamWas fine for years until 118 and is rare enough to not be able to reliably reproduce it (and thus do things like disabling extensions, running the pain of a new profile, etc), so I guess I have to live with it, as life&#x27;s too short. reply padenot 21 hours agoparentFirefox developer here. There are a few ways to diagnose this, depending on your setup. If everything is frozen on Linux, it&#x27;s probably the parent process that is having an issue. The \"parent process\" is the process that oversees all the tabs, it&#x27;s the top process in a Firefox process tree, the one that has lots of children.If our crash reporter is enabled, you can also just kill the parent process with `SIGABRT`, this will produce an entry in `about:crashes` that you can look up on restart, and submit. This will then give a link to our crash reporting front-end.If you have `gdb` and `debuginfod` on your distro, and you&#x27;re using your distro&#x27;s Firefox, attach `gdb` to the parent process of Firefox, let it download symbols, and do `thread all apply bt`, this will dump the stacks of all the threads of your parent process.If you&#x27;re using one of our Firefox builds, you can use https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;toolkit&#x2F;crashreporte..., that will integrate with our own symbol servers. Depending on your distro this might or might not work on your distro&#x27;s Firefox (some distros submit their symbols to our infra to help diagnosing crashes).Once you have some info about the crash, you can open a ticket on your distro bug tracker, or https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;enter_bug.cgi?product=Core to reach us directly, attaching the stacks, Firefox version, crash report, about:support, or anything else that you think is relevant.Oftentimes, those freezes (on Linux) are caused by a bug between Firefox and the desktop environment, or by graphics drivers, that kind of thing, and stacks allow narrowing down the issue greatly, sometimes it&#x27;s just a package update or a configuration flip away! reply LoganDark 19 hours agorootparentHoly crap, this is the most helpful answer I&#x27;ve ever seen from a Firefox developer on HN. When I was having a memory exhaustion issue, I was just told \"enable the page file, running without overcommit is a recipe for disaster\" (looks at my 40GB of memory). I should figure out if that issue still occurs. reply mort96 15 hours agorootparentRunning without overcommit is a recipe for disaster! Modern JITs make good use of virtual memory for both security and performance reasons.Firefox on my laptop currently consumes almost 400GiB of virtual address space, while consuming \"only\" 458GiB of RSS. And that&#x27;s not a bug, that&#x27;s simply the browser making good use of the virtual memory system to provide significant advantages to all users on systems without overcommit disabled (which I&#x27;m guessing is 99.99% of people).The difference in response you&#x27;re seeing is simply because ta1243 is reporting a Firefox bug and you&#x27;re reporting user error.EDIT: Here&#x27;s some further reading on some of the ways which Chrome&#x27;s JavaScript engine (V8) uses virtual memory for security: https:&#x2F;&#x2F;docs.google.com&#x2F;document&#x2F;d&#x2F;1HSap8-J3HcrZvT7-5NsbYWcj... reply LoganDark 14 hours agorootparent> simply because ta1243 is reporting a Firefox bug and you&#x27;re reporting user errorDon&#x27;t tell me Firefox needs 40GB of virtual memory to keep a tab open for longer than a couple weeks. Or that it&#x27;s the JavaScript engine when closing all tabs or windows didn&#x27;t free the memory, only restarting the entire browser did. It wasn&#x27;t the extensions, either.If Chromium works properly without leaking memory, and Firefox leaks memory and calls it \"user error\" to not have overcommit enabled, I&#x27;m going to use Chromium, simply because it actually respects my computer&#x27;s resources.Also, you&#x27;re citing ways in which Chromium&#x27;s V8 uses virtual memory, when V8 does not suffer from this problem. Clearly you can use virtual memory in that way without having a memory leak.Also remember that Windows does not have unlimited overcommit like Linux does, because it has no OOM killer. So if Firefox were to use 400GiB of virtual memory, that would require the page file to take up the remainder of that.I did have issues with my page file \"automatically\" growing to 64GiB with Firefox running, so maybe it literally does do this and it actually uses up hundreds of gigabytes of space on Windows machines. But that is not acceptable behavior from Firefox and it is definitely not user error to not want to give up that much space. reply jraph 17 hours agorootparentprev> running without overcommit is a recipe for disaster(but yes, it probably is, even with 40GB of memory. I bet many things are designed on Linux with overcommit as an assumption) reply LoganDark 17 hours agorootparentWell, that was just the wrong answer, since their software is supposed to be releasing memory back to the OS properly. Overcommit is just a coping mechanism, you should be addressing the root cause.I have since enabled the page file for other reasons - LLMs demand up to 50GB of memory sometimes, and my new desktop only has 16.The change of machine is why I should probably try Firefox again to see if it behaves. reply ColonelPhantom 16 hours agorootparentOvercommit != Swap.Overcommit is allocating virtual memory without any backing. Swap is allocating physical memory backed by disk.Overcommit is useful in some cases, for example to preallocate a large heap without immediately making it all resident. Or to allocate &#x27;guard&#x27; pages to fight buffer overflows. On Linux, overcommit is commonly assumed and as such disabling it tends to break some programs, as it&#x27;s not out of the ordinary for something to allocate 100s of GBs of virtual memory. reply LoganDark 14 hours agorootparentRead up on Windows. Windows does not do overcommit whatsoever, unless swap is enabled, in which case it only allows overcommit up to the size of the swap file.Overcommit cannot be enabled without a swap file, whatsoever. This differs from Linux that can tend to have overcommit enabled without swap. reply ColonelPhantom 6 hours agorootparentYes, Windows doesn&#x27;t have overcommit. (Also not with swap, since overcommit is unbacked virtual memory, which Windows still doesn&#x27;t allow. The only thing it allows is disk-backed virtual memory).But as a user, I don&#x27;t care (except that I don&#x27;t have to worry about an OOM killer because an allocation will just fail). The only real difference is that application developers need to be careful with allocating memory without using it, unlike on Unix-likes.Because software on Linux runs on the assumption of overcommit, you shouldn&#x27;t disable it, even though the lack of overcommit on Windows is not problematic. reply fomine3 8 hours agorootparentprevYou&#x27;re correct, that&#x27;s why having pagefile is important for Windows even if there&#x27;s enough RAM. Why don&#x27;t you enable it? reply LoganDark 8 hours agorootparentIt takes up disk space that I thought I could save. I have it enabled now, as a side effect of working with LLMs on my new computer that only has 16GB of memory (working on fixing that).I still wouldn&#x27;t be comfy letting Firefox fill it up, because no matter how large the page file is, your system will always crash when Firefox fills the entire thing. I do not know if my new computer will have this problem, though. reply mort96 15 hours agorootparentprevThe reasons browsers rely on overcommit has nothing to do with them failing to release memory back to the OS properly. reply LoganDark 14 hours agorootparentIf the memory is never released back to the OS after it is done being used (or when it is not going to be used), then the browser has failed to release it back to the OS. reply mort96 7 hours agorootparentThe memory is released back to the OS after it is done being used. replyce4 20 hours agorootparentprevWow, thanks for the information!Side question: what can be done on Windows in such a case? reply flanfly 22 hours agoparentprevI got these on Brave on two different computers. Disabling hardware acceleration fixed it. Both had Intel graphics. reply OfSanguineFire 22 hours agoparentprevAre you using anything other than a Linux distro’s stable, extended-support release? Most of the complaints on HN about Firefox instability seem to be either Windows users, or Linux users upgrading to the latest and greatest, often outside of their distro’s packaging. Meanwhile, I have been running Debian stable’s Firefox for many years and simply have never encountered the bugginess that gets described on these HN threads. reply PaulDavisThe1st 21 hours agorootparentAnd I on the other hand use Mozilla&#x27;s latest & greatest all the time on Debian, and \"simply have never encountered the bugginess that gets described on these HN threads\" either.So there&#x27;s that ... reply dinosaurdynasty 22 hours agorootparentprevDebian uses Firefox ESR. It&#x27;s rare for Linux distros to use ESR (Ubuntu and derivatives notably don&#x27;t, I don&#x27;t think flatpak does either). reply wizzwizz4 20 hours agorootparentprevI use Debian&#x27;s Firefox ESR, and for at least five major (ESR) versions there&#x27;s been a bug where sometimes if multiple tabs try to do a web push notification at once, the entire browser process hangs maxing out a core and nothing I do will recover from that. (I use X11 with PulseAudio.) One of these days, I&#x27;ll get around to reliably reproducing it. (I haven&#x27;t tried `pulseaudio -k`, which might fix it if it&#x27;s an issue playing the sound: videos hang kinda like that, though more recoverably, if the sound isn&#x27;t working right.) reply kiwijamo 15 hours agorootparentSame here, I also use Firefox ESR from Debian packages and I&#x27;ve observed Firefox to lock up hard a few times. Often to the point it affects the entire desktop so not quite sure if it&#x27;s a bug in Firefox itself or possibly elsewhere e.g., Wayland. reply heavyset_go 13 hours agorootparentSounds like it could be a DE or graphics driver problem. Have you checked the kernel and system logs when that happens? reply heavyset_go 13 hours agorootparentprevHave you tried stress testing triggering notifications over D-Bus or something? Might be a DE problem. reply yorwba 22 hours agoparentprevDoes it happen while typing? Might be https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1844505 I&#x27;m affected by that bug, but I hadn&#x27;t considered to search for a ticket until now. Guess I&#x27;ll have to start using plain Mozilla binaries to reproduce... reply lazulicurio 13 hours agoparentprevAre you on linux? For a while I&#x27;ve been running into issues with FF where it will randomly halt repainting after switching tabs. The process is clearly still responding to keystrokes and mouse events, but the ui is mostly frozen.I&#x27;ve also been running into an annoying issue where hover menus will randomly stop working---it seems like the mouseout event is firing before the click event is handled.But all in all not annoying enough to switch. reply krona 22 hours agoparentprevSame for me. It happened twice yesterday. reply qup 22 hours agoparentprevI&#x27;ve been getting these but I hadn&#x27;t figured out what to blame yet. I imagined it was one tab doing something bad.I&#x27;ll have to pay attention now to if it&#x27;s happening on all my machines. it for sure happened on a Windows 10 machine reply pivo 21 hours agoparentprevSame for me on a mac. I only saw this on 118 and haven&#x27;t seen them again since upgrading to 119.0Edit: Spoke too soon. Just happened again while joining a GoogleMeet meeting, if that&#x27;s relevant. reply emgeee 20 hours agoparentprevthrowing in a \"same here\" -- macosx v118 and 119 reply EMM_386 22 hours agoprevThis is good news, and makes me want to start using it again.Was a user from the Phoenix&#x2F;Firebird days with the \"unzip it somewhere\" fancy installation process, used it for almost 20 years, and then switched to a Chromium-based browser due to perceivable speed differences.I wasn&#x27;t running benchmarks to confirm my suspicions or that performing some action was x milliseconds slower in Firefox or anything. But when you&#x27;re using something all day, every day including as part of your job, it is easy to get a feel for.With these multiple reports recently of performance work, along with real-world metrics ... I&#x27;m thinking of sticking with it for a few days again. If I don&#x27;t notice the difference, or it actually seems faster, I&#x27;ll switch back.I want to switch back, because we need to ensure there are alternate browser engines, and I don&#x27;t want standards committees to turn into \"this year, Google deems we shall be doing the following\" sort of events. reply diroussel 21 hours agoparentCombine the good performance with great add-ons like Multi Account Containers, and Tree Style Tabs, and you have a great browser. reply jacoblambda 16 hours agorootparentOr instead of Tree Style Tabs, using Simple Tab Groups which I find has far better UX:https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;simple-tab-gr... reply Ayesh 13 hours agorootparentIt&#x27;s good to see STG praised here.I context switch often, and am so much more productive because of this plugin. reply purerandomness 15 hours agorootparentprevNowadays it seems that everybody switched to Sidebery, the tree-style tabs add-on that Tree Style Tabs always wanted to be. reply mackrevinack 17 hours agorootparentprevthe user.js file is a very underrated feature as well. i have a few computers and some of them are dual boot which means i have a lot of firefox installs so its great just being able to drop in the user.js file and have everything set up the way i like it reply diroussel 17 hours agorootparentI have a userChrome.css to hide the default tabs. What do you have in your user.js and have you automated the install of it?Here is a reference for the userChrome.css to hide the default tabs. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23268077 reply mackrevinack 7 hours agorootparentheres a few general ones. on my linux computers i have a bash script to install firefox, then it sets up symlink of the user.js file from my own config folder to the default .config folder. on windows i just manually add it user_pref(\"browser.aboutConfig.showWarning\", \"false\"); &#x2F;&#x2F; disable about:config warning user_pref(\"browser.startup.page\", 3); &#x2F;&#x2F; restore previous session user_pref(\"browser.ctrlTab.sortByRecentlyUsed\", \"true\"); &#x2F;&#x2F; cycles tabs in recently used order user_pref(\"signon.rememberSignons\", \"false\"); &#x2F;&#x2F; dont ask to save passwords user_pref(\"browser.search.suggest.enabled\", \"false\"); &#x2F;&#x2F; disable address bar suggestions user_pref(\"toolkit.legacyUserProfileCustomizations.stylesheets\", \"true\"); &#x2F;&#x2F; enable custom cssthis is the only css i could find that i like since it keeps the window controls as well, although since a recent update, theyre just showing as a white box now but they still works https:&#x2F;&#x2F;github.com&#x2F;mbnuqw&#x2F;sidebery&#x2F;issues&#x2F;458#issuecomment-9... replybombledmonk 21 hours agoprevThe killer app for Firefox is it still allows some flexibility in tab management. Sidebery and TreeStyleTab have been my anchors in the FF ecosystem. The experience is so vastly superior for tab hoarders and tab-todo methodology that I really can&#x27;t imagine using something else. I also use FF on android because it has ublock origin and dark reader addons. This make browsing the web on mobile far better. I actually hold little allegiance to FF as whole, I just haven&#x27;t found any Chromium based browser that works as well for me. reply wongarsu 18 hours agoparent> I just haven&#x27;t found any Chromium based browser that works as well for me.The native vertical tabs in Edge are also pretty good. Not nearly as feature-rich, basically just vertical tabs with automatic unloading and tab groups; but in return it&#x27;s incredibly stable and bug-free. reply dmix 17 hours agorootparentIs there a reason Chrome hasn&#x27;t adopted this? Tabtree is the only reason I&#x27;m using FF (not that I&#x27;m unhappy with FF I just use Chrome for work cuz the devtools is better). reply andreashaerter 21 hours agoparentprevAs a tab hoarder, I alsoa) need \"Auto Tab Discard\" which sends unused tabs in the background to sleep, not consuming resources.b) enjoy I can still use CSS to hack the tab bar for e.g. three scrollable rows reply clumsysmurf 21 hours agoparentprevI tried both but ultimately preferred Safari tab groups which is seamlessly integrated into the browser experience. reply worthless-trash 21 hours agoparentprevIn regards to treestyletab did you get rid of the top tabs or do you have both on your screen. I feel like i lost quite a lot of real estate on smaller screens with both. reply abdullahkhalids 21 hours agorootparentYou can remove the top tab bar with some CSS.https:&#x2F;&#x2F;superuser.com&#x2F;questions&#x2F;1424478&#x2F;can-i-hide-native-ta... reply bombledmonk 13 hours agorootparentprevI got rid of the top row. reply dinkleberg 21 hours agoprevGotta say I’ve been using Firefox for years as my daily driver and it has been great. Maybe it is because I’m running on higher end machines for the most part, but I’ve had no complaints with it across Linux, windows, and Mac. reply SoftTalker 20 hours agoparentSame. And I&#x27;m not using high-end machines, all of my daily drivers are 5 years old or more. I&#x27;ve been completely happy with Firefox + uBlock Origin. reply NTARelix 18 hours agoparentprevI&#x27;ve also been using it for several years and almost completely agree with your sentiment. The only areas that have given me trouble are in the dev tools. On my machines the debugger is significantly slowed down when opening very large JS files, source maps compound the debugger slow down, and I can&#x27;t always inspect variables&#x27; values when using source maps (possibly a build tool config problem). reply zmmmmm 15 hours agoprevPlease anybody still clinging on to Chromium based browsers on perception of speed being an issue, at least give FireFox a try. I haven&#x27;t looked back and really enjoy it these days, and it&#x27;s really important to the future of the web that browser diversity remains strong. reply th3_nsa 11 hours agoparentI&#x27;m using Brave with rewards, vpn, wallet disabled and around 20 flags modified. It works faster, better extension support for me with fewer bugs, less memory usage when fewer tabs are opened. I chose brave because it can sync.I&#x27;m impressed with Firefox and tried a fork called floorp. It has some useful additions and find it better than regular Firefox while still supporting sync and was using ungoogled chromium before.https:&#x2F;&#x2F;github.com&#x2F;Floorp-Projects&#x2F;Floorp&#x2F;releasesUnfortunately some websites still work better with chromium browsers in my experience. This is anecdotal but I also feel some negative fingerprinting from Google owned websites on Firefox, more memory leaks as well. It&#x27;s only a matter of time before I change to Firefox (forced manifest V3) but I will stick with brave for now. reply lionkor 9 hours agorootparentWhat&#x27;s wrong with firefox&#x27;s sync? reply sfortis 21 hours agoprevIn the Speedometer 2, Firefox is much slower than Chrome, which is a bit slower than Edge. But who cares! In real life, this makes no real difference. I respect and trust the privacy of Mozilla. Features like containers and the ability to run Ublock and Tampermonkey on mobile are priceless! reply windowsrookie 21 hours agoparentIt does still matter for people using low-end computers. My MacBook&#x27;s screen cracked while on vacation recently and I had to buy an emergency laptop. I picked up a device with a Celeron 6305 and 4GB of RAM. I loaded up Firefox like I normally do, and it was so slow and laggy to the point it was unusable.I then switched over to Edge and it performed significantly faster, and was using less of the 4GB of RAM. I was surprised at how significant the difference was, but there was no denying it. Edge performs much better than other browsers on low-end PC&#x27;s. reply sfortis 8 hours agorootparentChromium (new) EDGE or OG? reply windowsrookie 4 hours agorootparentChromium based new Edge. I hate all of the Junk Microsoft has added to it. But if you are willing to take the time to turn it all off, it is a much more efficient browser than Chrome or Firefox. I&#x27;m not sure what Microsoft has done to optimize it, but on a low-end system it is very noticeable. reply criddell 21 hours agoparentprevAll of the major browsers are probably fast enough for now. It would be nice to see the emphasis shift to decreasing power consumption. reply astrange 19 hours agorootparentThose are mostly the same thing. You save power by being faster so that you can go idle faster.Of course, there&#x27;s a difference between going faster by using more resources and by just taking less time. reply sfortis 8 hours agoparentprevalso: https:&#x2F;&#x2F;github.com&#x2F;gorhill&#x2F;uBlock&#x2F;wiki&#x2F;uBlock-Origin-works-b... reply rg111 21 hours agoparentprevWith a 75 MBPS connection, FF loads everything I need instantaneously.Who cares about benchmarks? reply MBCook 19 hours agorootparentSee the sibling comment about the person using a very low spec PC. reply jszymborski 22 hours agoprevI trust the Firefox team knows what they&#x27;re doing and came to the right conclusion re: performance.That said, I have a small nit. I would have liked to see how performance changed relative to the same time last year, to control for seasonal effects. Image 1 is showing changes on the scale of 1&#x2F;100 of a second. I&#x27;m not an expert in the field, but when you&#x27;r looking at signal of that magnitude controlling for noise is more relevant.EDIT: I should add, I am a satisfied user of FF. reply temp0826 21 hours agoparentI think that&#x27;s what arewefastyet is?https:&#x2F;&#x2F;arewefastyet.com&#x2F;Edit- also see https:&#x2F;&#x2F;wiki.mozilla.org&#x2F;Areweyet reply Alifatisk 4 hours agorootparentIf I read the graphs correctly, FF performs worse than both Chrome and Safari on all measurements!? reply alwa 21 hours agoparentprevI’m curious what seasonal effects you hypothesize might be in play here. I don’t know enough about the browser performance space to understand what might change: do people really consume a different mix of web technologies through their browsers seasonally?It looks to my naive eyes like the trajectories here are consistent and that the “signal” looks bigger than the variance. The measurements seen consistent with a bunch of smart engineers working to optimize for them during the time period they were measured.At the same time you’re right: that big August improvement might well have something to do with Northern-hemisphere people switching to lighter vacation reading rather than just the Firefox 116 release happening to drop August 1. I’d share your interest in the longer timescale. reply Osmose 20 hours agorootparentTo the first question: Yes. An example would be travel sites and shopping sites getting way more use during holidays. A big one is always December: end of the year holidays mess with usage metrics a ton given how many people take off work or spend time away from their computers, to the point that most companies I&#x27;ve worked at tend to ignore data from that month or try to be very careful about only comparing it to data from December in other years. reply rickstanley 17 hours agoprevI really could not tell if it is better or not. But I&#x27;ve had 2 problems that seems to never be resolved:- using hardware accelerated video decoding is bizarre if the video uses VP9 (even disabling it or forcing AV1) it stutters from time to time;- watching a video in the background and playing game at the same time, with hybrid graphics, freezes&#x2F;hangs kWin, then, the video that was playing in the browser becomes green and everything that used either iGPU or dGPU starts to struggle and stutters a lot, forcing me to log in and out, i. e. restart my session manually;The last one may be because of Nvidia (yes, my fault for having this card) prime offload in Wayland, but even so, I did not find any topic related to this, that has not otherwise been solved in bugzilla, and honestly I am kind of afraid to report this and be met with judging questions; I&#x27;d like to debug some more, but I don&#x27;t have the patience.These are the two ever lasting headaches that I have with Firefox. None of this bothers me enough to leave Firefox though.Anyway, my congratulations to the team. Today, I have successfully converted 5 people to use Firefox. reply mort96 15 hours agoparentHardware decoding is sadly somewhat of a mess in Linux... I&#x27;m guessing that with most of those issues, Firefox is interfacing with the various video coding APIs correctly, and some driver or something is just buggy. If you&#x27;re on a desktop, turning off hardware video decoding altogether might be worth it. reply kiwijamo 15 hours agoparentprevPro Tip: There is a Firefox extension that forces YouTube to use H.264. Even though my machine does hardware accelerated VP9 I&#x27;ve found it to be unreliable. Switching to H.264 makes YouTube videos play smoothly. All other videos sites use H.264 by default so this only really needs to be done for YouTube. reply cmplxconjugate 17 hours agoparentprevThat second point is something that drives me CRAZY. For years I would keep YouTube or Twitch streams open on the second monitor. Now I deal with constant fps loss, video stutters or freezing. Absolutely bizarre regression in performance. reply mazugrin2 11 hours agoprevI just found out today that Firefox does not yet support the css has() selector, while Chrome has supported it for over a year now. I get that there are a lot of reasons for this, but it surprised me, I guess.I use Firefox because its fullscreen mode is far better than all the other browsers I&#x27;ve tried on Linux, but it does seem like it&#x27;s clearly slower to perform and slower to be able to adopt new web &#x27;quasi&#x27;-standards. reply kevincox 4 hours agoparent:has() is Chromium-only right now. Firefox and Safari both have it in preview builds and it is scheduled to be released soon on both.This is why having more browser diversity is important. We can&#x27;t have people thinking that \"the web\" has a feature once Chrome releases it. reply abound 21 hours agoprevWhile I&#x27;m glad the data is trending in the right direction, isn&#x27;t this what you&#x27;d expect to see from these metrics as people adopt faster hardware and better internet connectivity?I know it&#x27;s hard to control for those things while maintaining anonymity and doing aggregate analysis, but this would be a much stronger argument controlling for at least some level of available compute.(I exclusively use Firefox on all the platforms) reply LightBug1 17 hours agoprevYup, I&#x27;ll co-sign this. I&#x27;m using FF right now on inferior hardware and have done for quite a few years. Feels pretty new and snappy. reply xxpor 22 hours agoprevOnly looking at the 95th percentile is pretty disappointing. Enough page loads happen that higher percentile experiences aren&#x27;t exactly rare. reply sfink 21 hours agoparentYou mean only displaying and discussing the 95th percentile in a blog post?There&#x27;s no reason to assume that what is brought up in a blog post is going to match what engineers are looking at. In this case, I&#x27;m a developer at Mozilla, and I would say that I agree that it&#x27;s worthwhile to look at the 99th percentile as well. And the median (50th percentile). And other platforms. And segregate it by website, but we don&#x27;t collect that, or by country, but although I think we might be collecting that we avoid correlating too many things before discarding the non-aggregate data. There are too many German users to worry about identifying one by knowing they&#x27;re German, but there&#x27;s aren&#x27;t that many German users with >100 tabs running on Windows 7 on slower hardware, etc.I wouldn&#x27;t want to pile up any more data than necessary in a blog post, though. The point would get buried. Man Bites Dog Whose Litter Mate Once Skipped A Veterinary Visit Because Owner Was Out Of Town At A Wedding Between Two People Whose Names Start With D(Yes, we do consider many different percentiles when making decisions. We kind of have to come up with arguments for what matters, given a change we made or are contemplating. Some things improve the 50th and regress the 95th, for example, and that&#x27;s a useful clue. Telemetry tracks half a dozen different percentiles.) reply teo_zero 5 hours agorootparentBut what is the reason behind the choice to only show the 95th percentile and not the mean or median, that undoubtedly are more understandable by a vast audience? reply xxpor 19 hours agorootparentprevI&#x27;m sure internally folks are looking at more stuff, but blog post wise, it makes it look like you&#x27;re intentionally omitting it (see https:&#x2F;&#x2F;youtu.be&#x2F;lJ8ydIuPFeU?t=1239) reply charcircuit 22 hours agoparentprevIt&#x27;s not like real users aren&#x27;t hitting loading times in those higher percentiles. They really should be showing p100. reply persnickety 22 hours agorootparentp100 would include those where the uplink is so slow that the page takes minutes to render completely. Those users are useful to see, but the browser is much less of a bottleneck for them, and the data should be broken out into a separate bin. reply sfink 21 hours agorootparentIt would also include users who happened to close their laptop lids and suspend for an hour, right during pageload. reply astrange 19 hours agorootparentThat&#x27;s if it&#x27;s measured by wallclock time, but they should be using a monotonic timer that ignores sleep and clock changes. replymilliams 21 hours agoprevGraphs like https:&#x2F;&#x2F;hacks.mozilla.org&#x2F;files&#x2F;2023&#x2F;10&#x2F;FCPRUM.png which don&#x27;t start at zero on the y-axis are very misleading. reply dabedee 20 hours agoprevIn the last five years, my experience with Firefox has always been far superior in terms of performance than when using Chrome. I just can&#x27;t bring myself to justify using a Google product for something as important as browsing. I guess it&#x27;s ideological, but I just want Firefox to succeed. reply sillyalbatross 19 hours agoprevUnfortunately Firefox still has a lot of issues when it comes to font rendering on macOS. For example, it&#x27;s been two years and it still renders San Francisco incorrectly: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1721612Not to mention all fonts appearing bolder than they should compared to Chrome and Safari. It might seem like a small thing but I&#x27;m a stickler for typography and it really stands out on a Mac.I hope they get around to fixing these issues but two years is a long time for such an obvious bug. What confuses me is how few people have noticed given that it seems to affect all Apple silicon devices. reply karmakaze 18 hours agoparentI confirmed the letter spacing is still an issue by comparing the \"How I digitize books\" paragraph on Chrome and FF. I had to override the CSS as the site has switched to \"Newsreader, serif\".I don&#x27;t see the fonts appearing bolder difference (on my 4k screen). Actually that&#x27;s not true, I have seen differences on lower DPI displays. I get around that using BetterDisplay to enable HiDPI on the external. I&#x27;ve also never noticed San Francisco font rendering improperly which I only would if it didn&#x27;t fit in a clipped box.Now that performance is largely improved, maybe they&#x27;ll get around to fixing this one. reply wodenokoto 19 hours agoparentprev> Not to mention all fonts appearing bolder than they should compared to Chrome and Safari.No they don&#x27;t. https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;p9V4GdN reply sillyalbatross 17 hours agorootparentInteresting, must be only happening on some native MBP displays. I&#x27;m on an M1 MBP and haven&#x27;t tested it on an external display but it&#x27;s definitely noticeable on mine, although not as big of a deal as the letter spacing thing reply insanitybit 21 hours agoprevReally cool to see the real world performance as well as a new Speedometer. I think anyone who&#x27;s against the telemetry collected is really nuts, as long as it&#x27;s done responsibly - the idea that Firefox could compete without that data is just a fantasy. reply Centigonal 22 hours agoprevI switched to Firefox from Chrome for personal browsing several months ago, after the Manifest v3 debacle. So far, it&#x27;s been good!Very few sites only work on chrome. Firefox is fast, and the auto tab discard works better for me than Chrome&#x27;s equivalent (or the Marvelous Suspender), I really like container tabs, and the whole experience feels pretty snappy. There are some product affordances I don&#x27;t get with Firefox (ex. being able to run math expressions in the address bar), but it&#x27;s small potatoes. reply tempusr 22 hours agoparentI started using Firefox as a main driver a year ago due to me interfacing with Linux distros a lot more often. It&#x27;s the browser that is usually always installed from the get and offers the best experience after logging into my Firefox account.They also have some other really good tools they support such as firefox relay which is basically a proxy email address for your main email so you can post your an address on the airwaves w&#x2F;o compromising your main email.Pocket for saving articles you read on the internet.Mozilla Thunderbird? reply zanellato19 21 hours agoparentprev> ex. being able to run math expressions in the address barThis works here for me just fine, at least for simple ones reply Centigonal 20 hours agorootparentdivision breaks it, because FF doesn&#x27;t want to send a potential URL to google (which evaluates math expressions). details here: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1318813Thanks to your comment, I did some more research and discovered an about:config flag (browser.urlbar.suggest.calculator) that fixes this for me! reply Night_Thastus 18 hours agoprevBeen using Firefox back since version 2 way back when.After all these years, it still does what I need, how I need it done. That&#x27;s the best recommendation of a product I think I can give.Just about my only complaint is I wish there was a way to more quickly cancel saving a duplicate file. When the prompt appears with \"this file already exists, do you want to overwrite?\" it&#x27;s much faster to just click \"yes\" than to click \"no\" and then drag the mouse down to \"cancel\" to close the window. Do this once it&#x27;s no biggy. Do it hundreds or thousands of times and it gets obnoxious. Waste of bandwidth and disk writes, or waste of time.I know that sounds dumb, but it&#x27;s one of the only pain points I have. reply southernplaces7 21 hours agoprevSounds wonderful, but they&#x27;ve been claiming speed increases for years, causing me to go and check if they&#x27;re true, and being deeply disappointed. I don&#x27;t use powerful laptops with fancy hardware for my browsing, but how stupid can a browser be if it only works well even with heavy use if your hardware is great? Not everyone has that luxury even if they&#x27;d like a bit of privacy features.As much as I detest and avoid all things Google in so many ways, Chrome remains preferable because at least it can deliver 50+ open tabs on a completely ordinary laptop without completely freezing everything to shit.You&#x27;ve had so many years to get this basic thing right Mozilla, yet you keep failing, and for a company that claims to track less than the others, then what the fuck is your browser doing to keep being so goddam slow? reply orev 21 hours agoparentFirefox is definitely on par with Chrome these days, so if you’re seeing issues like this, I would first suspect that it’s the web sites you have loaded in those 50+ open tabs instead of the browser itself. So many sites use bad JavaScript and that’s often what causes the problems. reply aembleton 20 hours agorootparent> So many sites use bad JavaScript and that’s often what causes the problemsThen Firefox needs to handle that better. As an end user, I don&#x27;t care about the quality of the JS of the sites I want to browse - I just want it to work, and if it works in Chrome but not Firefox then I guess I&#x27;ll switch to Chrome. reply southernplaces7 20 hours agorootparentExactly this. Often with complaints about FF performance someone comes along and says something like the above, about JS or my laptop&#x27;s hardware, or etc, but if Chrome, with all its shitty tracking, can make those same sites load just fine on nearly any machine, then FF should be able to do the same if it wants more users. I don&#x27;t care about your browser&#x27;s problems and exceptions to decent performance. I shouldn&#x27;t be expected to filter the sorts of sites I visit for the sake of making sure they don&#x27;t harm my delicate little FF instance. I just want the damn thing to work as other browsers apparently can. reply jacobyoder 20 hours agorootparentprev> Firefox is definitely on par with Chrome these days,The GP is likely going to be triggered by those words, because... I&#x27;ve seen this repeated every X months&#x2F;years... \"Oh... yeah, you had problems in the past, but it&#x27;s so much better now\"... and... it rarely is. GP will just need to try out again at their own schedule and make their own determination.I had this standard issue with desktop&#x2F;laptop linux for years... \"xyx doesn&#x27;t work well\"... \"Oh yeah, it&#x27;s so much better now - no problems now\". Try the new recommendation - still broken.I had a f2f with someone at a local meetup, and we got in to \"xyz is subpar&#x2F;broken on linux\" (some gnome thing possibly). This happened to be a linux user group, and someone challenged me with \"no, you&#x27;re wrong, it&#x27;s fine now\". So... I pulled out the laptop and fired it up and showed the irritation&#x2F;bug. The response - after showing that what I was saying was a bug - was a shrug and \"Oh, I don&#x27;t care about that - doesn&#x27;t affect me\". The verbal equivalent of \"WONTFIX\". In person.tldr: telling people who&#x27;ve been burned - often for years - that things are \"better now\" is generally not all the productive. Most of the time, people who have specific&#x2F;legit issues will figure out if&#x2F;when they&#x27;re fixed or tolerable enough. reply Osmose 20 hours agorootparentThis is valid but in both directions: people will say \"Firefox is slow\" because they don&#x27;t have the time&#x2F;interest to say \"Firefox is slow on this specific webapp that is very important to me on my specific laptop\". Of course the responses to the first statement are going to interpret it generally rather than specifically. reply post_break 20 hours agoprevHas anyone at firefox used the iOS app? I want you to track what the workflow is to access a password in the app. Tap tap tap left side, right side, can&#x27;t get out of the settings to check the website while doing so. It&#x27;s maddening. Besides that... it&#x27;s lovely. reply kevincox 4 hours agoparentYeah, it is hidden away on Android too. They tried to mitigate this by adding an awkwardly named \"Passwords shortcut\" app action (long press the app or add it to your home screen) but this just opens the password settings, still another click to actually get to the passwords list. reply snailmailman 9 hours agoparentprevIn iOS you can add Firefox as a password manager auto fill option. Then when you tap in a password field, the relevant passwords should prompt to auto fill.I haven’t tested this with Firefox’s password manager, but I did test in firefox and Bitwarden is auto filling correctly, and in iOS settings I see Firefox is listed as a password manager.It’s settings->passwords->password options. I don’t think apps can automatically enable auto fill, you might have to manually enable this. reply post_break 2 hours agorootparentThat&#x27;s not when this is an issue, it&#x27;s when Firefox doesn&#x27;t auto fill because it&#x27;s confused. reply JohnTHaller 17 hours agoparentprevIs it complex in all iOS browsers due to the whole &#x27;you&#x27;re actually running Safari underneath&#x27; thing? Or is it Firefox specific on iOS? reply saagarjha 16 hours agorootparentThis sounds like a UI issue? reply post_break 15 hours agorootparentprevIt’s terrible UI reply inparen 21 hours agoprevYay! Happily using Firefox since 3.5 release. Keep going guys. reply chungy 20 hours agoparentBeen using it since it was called Mozilla Firebird. :) reply brnt 8 hours agorootparent0.5 or 0.6 iirc. I even remember the ad for the 1.0 release ;) reply mike_hock 21 hours agoprev> Collecting data while holding ourselves to the highest standards of privacy can be challenging.Yes, explaining away a blatant self-contradiction can be challenging.You&#x27;re not holding yourselves to the highest standards of privacy, you&#x27;ve explicitly prioritized data collection over privacy. reply autoexec 12 hours agoparentThere not much harm as long they&#x27;re making sure users are aware of the telemetry and can disable it if they choose to. Opt-in is best, but collecting data with consent isn&#x27;t a problem reply eviks 8 hours agorootparentSo how many users in your estimate are aware?(Opt-in is a method of verifying consent) reply fooker 22 hours agoprevI must be a virtual user or something.I have Firefox installed for testing WASM targets, and everything seems slower than usual.If you open 20+ tabs, the UI seems to be laggy. At some point, I had to kill a tab, the whole browser froze for a while. reply diggan 21 hours agoparentI regularly have 100+ tabs open depending on what I&#x27;m doing, and killing tabs in groups of 10+ sometimes without any lag. But then I&#x27;m on a 5950x CPU + Linux so maybe that plays some role. What hardware are you using? reply fooker 15 hours agorootparentTwo generations old 8 core i7, 64 gigs of ram, various GPUs interchangeably.Doesn&#x27;t seem to be a resource issue unless Linux is doing something odd. reply throitallaway 21 hours agoparentprev> the whole browser froze for a while.Are you swapping out? I think a lot of people don&#x27;t realize how heavy web pages are, often taking up hundreds of MB of RAM (at least) for each tab. I highly recommend the Auto Tab Discard plugin. I&#x27;m terrible with leaving tabs around, and tab suspension plugins let me continue that bad habit. reply fooker 15 hours agorootparentPossible, but unlikely.I just tweaked vm.swappiness, and there&#x27;s no obvious change. reply brianbreslin 21 hours agoprevSo firefox was ahead of the pack on the add-ons&#x2F;extensions game, but then didn&#x27;t push it or support it after a while. Now after years of chrome having a few integrations or add-ons that make my life easier, i have a hard time switching back to firefox even though chrome is such a giant memory hog. These aggregator moats are real that stratechery talks about.Maybe I&#x27;ll give firefox another shot. reply Ikatza 15 hours agoprevIt&#x27;s a real pity that speed keeps being the golden metric by which browsers measure themselves. I&#x27;d much rather have Mozilla focus on making Firefox usable on many popular webs (including HN) than on shaving another millisecond. reply alberth 16 hours agoprevWhy use Chrome?I&#x27;m curious, for those of you who use Chrome ... why do you (vs. another browser)? reply sexy_seedbox 14 hours agoparentUsing Vivaldi on desktop so I can zoom to exactly 85% on some websites. Their history features and search is much better than Chrome.Using Kiwi Browser on mobile so I can install any extensions. reply sharno 20 hours agoprevMy battery with FF on a Macbook Pro with M2 still lasts less than the same device with Chrome. Hope this improves soon.Ofc, Safari beats them both but I hate Safari&#x27;s plugins system so I need a browser that doesn&#x27;t need an AppleID to install plugins. reply someNameIG 19 hours agoprevFor normal use it does feel the same speed as Safari. But the font rendering seems a little of on macOS compared to Safari&#x2F;Chrome, anyone else notice this? reply Timber-6539 22 hours agoprevOnly because fake users didn&#x27;t receive the update. reply nfriedly 22 hours agoparentfake users? reply halfmatthalfcat 22 hours agorootparent“Firefox got faster for real users…” why include “real”? Are there fake users? Just strange phrasing. reply sojsurf 22 hours agorootparentPerhaps as opposed to \"Firefox got faster in the benchmarks\", which do not always correlate to how normal users use the web. reply mcpherrinm 22 hours agorootparentprevI think they&#x27;re distinguishing from synthetic benchmarks reply JohnTHaller 17 hours agorootparentprevFirefox&#x27;s analytics allows Mozilla to analyze changes in the real world for Firefox users. Testing things like startup time and load times for actual users as opposed to synthetic benchmarks. reply unethical_ban 21 hours agorootparentprevI assume it implies \"we base our claims on data from real users, not artificial metrics\" reply ksec 19 hours agoprevSo after e10s, Quantum, Azure. Are there any upcoming major changes to Firefox or Gecko? reply agumonkey 22 hours agoprevI applaud firefox devs, and wish they can keep on improving everything they want or can. reply bingemaker 22 hours agoprevWhen more and more parts of FF are written in rust, I thought FF will get a lot faster. But for the past 1 year, I can only see marginal improvements w.r.t speed. And occasionally FF hangs when I have 20 tabs opened. reply bpbp-mango 17 hours agoparentAfter the CSS parser and Webrender has there been any more new rust components? reply rs_rs_rs_rs_rs 22 hours agoparentprevWhy would you think that? Rust is certainly a little bit slower than C&#x2F;C++ reply pcwalton 22 hours agorootparentThey use the same compiler backend and you can generate pretty much any LLVM IR you want with Rust. You can argue about the performance characteristics of the kind of code the language encourages you to write, but a blanket statement like that isn&#x27;t true. reply qup 22 hours agorootparentprevEverything I&#x27;ve read says that you&#x27;re right in theory, but in practice, rust rewrites tend to outperform.At Mozilla&#x27;s level, though, I wouldn&#x27;t necessarily expect that to hold water. They should be able to write great code in either language. reply lxgr 22 hours agorootparentI wouldn’t be surprised if rewrites in any language (including the original one!) would have a tendency to outperform.A rewrite (by people familiar with the original and its pain points) is an excellent opportunity to optimize. reply lrem 19 hours agorootparentprevEh, no. A rewrite is pretty much always better. You now know the problem you’re actually facing. Drop all the little wrong assumptions. And in general are better equipped than the last time.I vaguely remember reading here about a company that slapped a backend together in Python. When they took off, the compute costs stung, so they rewrote in Go. Saved most of the bill. Some time later that started creaking, so they rewrote again. In Python, but managed to save most of the bill again. reply bingemaker 22 hours agoparentprevNot sure why am I getting down voted for posting an observation :shrug: reply hoppyhoppy2 21 hours agorootparent>Please don&#x27;t comment about the voting on comments. It never does any good, and it makes boring reading.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply xbmcuser 21 hours agoprevI have been trying firefox for last 1-2 months it was running great but last week or so it suddenly freezes my whole computer. This happens both on windows and a different linux pc. reply ramesh31 22 hours agoprevI&#x27;ve made the switch. The difference is so minimal at this point it&#x27;s unnoticeable. And regardless of telemetry and who sees what, I simply cannot stomach touching anything even remotely related to Google anymore. reply joduplessis 21 hours agoprevLove headlines like these. As opposed to what, fake users? reply rhdunn 20 hours agoparentSynthetic benchmarks or tests. For example, improving performance of an empty loop is useful for starting somewhere [1], but does not show how fast the browser is on a real page with complex JavaScript such as a vue&#x2F;react component used to render a tree-based select control with searchable items.[1] E.g. creating the new jitter for Ladybird. reply sputr 17 hours agoprevGreat for them. The mobile app, at least for me, is getting unusuble. I have a crappy phone and reopening a page takes 3x the time opening a new tab and writing the url does.Even then it&#x27;s still significantly slower than chrome, even with ads.I think it&#x27;s time I find a different mobile browser with adblocking. reply knodi 21 hours agoprevBeen a user of Firefox from when he launch the renderer, loving it and never looked back at chrome or safari. reply secondcoming 21 hours agoprevI don&#x27;t know if it&#x27;s the fault of Firefox or Cloudflare WARP but I&#x27;ve been getting a lot of \"PR_END_OF_FILE\" errors (something like that) when browsing. reply tbihl 22 hours agoprevI was a consistent Firefox user, probably for the past 15 years, but I recently switched to Brave and Edge after too much frustration with power consumption. Firefox makes my laptop shriek, while the other 2 normally don&#x27;t cause the fan to start at all.Does anyone actually care about loading speeds (apart from the necessary ad blocking)? reply RheingoldRiver 22 hours agoparent> Does anyone actually care about loading speeds (apart from the necessary ad blocking)?It&#x27;s kinda like money imo: You think you don&#x27;t care about it until you don&#x27;t have it. The only time I&#x27;ve ever cared about loading speeds was when I stayed on LTS Firefox for 2 years to avoid switching to WebExtensions, because I wanted to keep using several addons that were discontinued in Quantum. And near the end...yeah I cared about loading time. Felt amazing when I finally did upgrade (although I&#x27;m still pissed af that they never re-added the ability for extensions to access tab-specific history & will never get over this unless they do one day add it).So I do think it&#x27;s important to pay attention to even when no one cares, just to make sure that no one starts caring. reply WillPostForFood 22 hours agorootparentthey never re-added the ability for extensions to access tab-specific historyCurious, what was the use case for this? reply RheingoldRiver 18 hours agorootparentIn MouseGestures extension, you can bind right-click scroll-up & right-click scroll-down to whatever you want. I bound this to back & forward (within this tab), respectively. So you&#x27;d get a little context menu at your cursor to be able to navigate however many ticks you wanted. Insanely useful, especially when websites bullshit autoredirected you once, so navigating away from them requires either super quick reflexes to go back twice with hotkey or mouse gesture, or actually moving your cursor all the way to the back button @@I still actively get mad that I can&#x27;t use this shortcut every single time I have to go to the physical buttons. reply jwells89 22 hours agoparentprevWith laptops having taken over computing aside from a small sliver of professionals and enthusiasts and browsers being one of the most consistently used categories of software, one would think that energy efficiency would be a bigger priority for browser devs… I mean who likes their laptop’s fans screaming and finite battery cycles being torn through?It’s rarely ever mentioned though and not something that significant gains are regularly made in, which is a bit strange to me. Browsers across the board have crossed the threshold of diminishing returns when it comes to speed, I’d personally rather they shift focus towards battery friendliness. reply OfSanguineFire 22 hours agorootparentA lot of laptops don’t even have fans, and as a Firefox user who has owned ultrabooks for the last several years, I can’t say that this choice of browser has had any noticeable detrimental impact; I still get the many hours of battery life that ultrabooks are known for. I suspect that the devs, faced with limited resources and the need to prioritize, would consider this a matter for the hardware and OS to deal with. reply magicalhippo 21 hours agoparentprevI&#x27;m mostly working on a desktop computer so I don&#x27;t care that much about energy consumption, however I do notice that a lot of websites have some timer going off at very high frequency, as part of some framework or whatnot.Personally I don&#x27;t see why Firefox can&#x27;t just stop JavaScript execution on tabs that aren&#x27;t visible after say 5 seconds, unless the user has enabled background execution. reply jakub_g 20 hours agorootparentAll browsers already heavily throttle js timers execution in background tabs. You also have specific apis like requestAnimationFrame to decouple UI timers from non-UI timers like setInterval.Stopping it entirely and then suddenly restarting on foreground would be probably too much of a breaking change for the websites&#x27; developers. I mean, I guess it could be possible but would require properly thinking it through. Some browsers aggressively freeze background tabs but AFAIR they do full reload on unfreeze.The breakage area of shipping that kind of change into the web ecosystem of a major browser is huge. reply oldshatterhand 22 hours agoparentprevI had to switch from Firefox to Safari on my M1 Max 16\" MacBook Pro because the battery drains in a few hours. I experimented a lot with turning different plugins on and off, but the power draw remained almost constant. reply chrisjc 21 hours agorootparentInteresting. Up until recently I was on a intel Mac and Firefox was always in the list of \"Apps Using Significant Energy\". I don&#x27;t know if it coincided with some Firefox improvement, but after switching to an M2 it has never show up since.Fortunately it never affected any need to switch to another browser since I&#x27;m plugged in 95% of the time. reply frandroid 22 hours agoparentprevAre you serious? reply tbihl 20 hours agorootparentI&#x27;m absolutely serious. Apart from using my work laptop to visit an ad-ridden page, doing stupid timed sign-up activities like going to Disney World, or using my older work desktop that was so old and slow that it spent 10 minutes every morning at 100% disk utilization before calming down, I can&#x27;t think of a time when I&#x27;ve experienced noticeably slow webpage loading in years, maybe a decade. reply IshKebab 19 hours agoprevWhat about memory usage? For some reason Chrome gets a lot of flak for this but Firefox is significantly worse in my experience. I&#x27;m considering switching just because of that. :&#x2F; reply pipeline_peak 20 hours agoprevI don&#x27;t know what their definition of a \"real user\" is. But everyone I&#x27;ve met who uses Fiercefox does so for philanthropic or political reasons. I have a hard time believing some non techie in Minnesota has noticed performance improvements. Idk, the data looks very pseudo sciencey, just feels like another marketing ploy from the blue haired people. reply IainIreland 19 hours agoparentGenerally we say \"real users\" internally as a comparison to benchmarks, as in \"this improves JetStream by 5%, but I don&#x27;t think it will make any difference to real users\". reply Doches 22 hours agoprev> We’ve been motivated by the improvements we’re seeing in our telemetry data, and we’re convinced that our efforts this year are having a positive effect on Firefox users.Mozilla gets a lot of flak (especially around here!) for their sometimes heavy-handed usage analytics, but it&#x27;s nice to see that used for its stated purpose! Great use of data here. reply StableAlkyne 22 hours agoparentI&#x27;m not a fan of telemetry in any browser (I love Lynx because of this), but Mozilla is definitely more trustworthy than Google or Microsoft.Edit: I&#x27;m not saying that Lynx should be a daily driver or that it&#x27;s more secure, but it&#x27;s a neat little project that avoids some of the bad patterns in modern browsers. reply kwanbix 18 hours agorootparentHow do you expect companies to understand how their products are used for improvement purposes without telemetry? Honest question. reply StableAlkyne 28 minutes agorootparentYou don&#x27;t need spyware just to improve a product. Dev teams were able to produce great software before we were constantly online.If a team is so unfamiliar with their product and customer base that it cannot take action without telemetry, maybe they&#x27;re not the right team to make that product. Statistics are not a substitute for domain knowledge. reply rurp 17 hours agorootparentprevTaking stock of the connected devices and software that I am familiar with, I&#x27;d say there is a strong correlation between detailed user tracking and worse UX. It seems weird at first glance but I think there are some solid explanations for why that might be.Data analysis is difficult to perform and understand well. It is easy to draw mistaken conclusions or to twist results to show the conclusion a person wants, and using detailed numbers can lead to a false sense of confidence in the results.Companies are first and foremost optimizing for their benefit, not the user. Detailed tracking can uncover interesting ways for a company to make more money at the expense of the user. reply JohnFen 18 hours agorootparentprevOthers have answered this, but I just wanted to point out the software devs have been managing to understand how their products are used for improvement purposes from long before telemetry was a realistic possibility.Telemetry doesn&#x27;t make it possible, it makes it less expensive. reply kwanbix 18 hours agorootparentDo you think it is the same asking a small subset of users than having info on all the users? I work as a Product Manager, and trust me, it is not the same. reply JohnFen 18 hours agorootparentOf course it&#x27;s not the same. But having detailed information from all users is also not required in order to produce a quality product. reply hotnfresh 18 hours agorootparentprev1) Ask2) Conduct user studiesHow are companies that aren&#x27;t software vendors and aren&#x27;t able to spy on their customers able to do it? Did software companies not have good ways to do this before spying on their users? reply kevingadd 18 hours agorootparent1 and 2 are problematic because it&#x27;s very hard to get representative data from either one. The people who have time for user studies or post on your forums are not representative users.Only listening to data from 1 & 2 results in the sort of angry posts you frequently see on HN complaining that devs aren&#x27;t listening to \"real users\" or have the wrong priorities.You end up needing data from additional sources, telemetry being one of them. reply hotnfresh 18 hours agorootparentYou do not need it. This is a really weird attitude. Until like the late &#x27;00s \"telemetry\" was, full stop, spyware (still is, for those of us who didn&#x27;t shift our attitudes with the prevailing winds). I wouldn&#x27;t say that responsiveness to user needs and desires has improved since then, in software design. reply kwanbix 17 hours agorootparentBut what is the problem? That I can know that you press the print button? That you chose the Edit menu? I really don&#x27;t see the problem. Please, explain, I really want to understand. reply autoexec 12 hours agorootparent> But what is the problem? That I can know that you press the print button?When the internet was young, and most people were using dial up connections, just collecting the dates and times that a person was online and using a program was (and still is) a massive violation of privacy. Software \"phoning home\", even just to check for updates (collecting IP addresses, timestamps, and version numbers) was enough to get your software branded as spyware.No software company needs to know which hours I&#x27;m awake, when I&#x27;m using my computer, which hours I work, which hours I use their program, how long I use their program, how long it&#x27;s been since I last used their program, etc. It&#x27;s intrusive, entirely none of their business, and it&#x27;s insane that they all feel entitled to that kind of information.If I print something, don&#x27;t print something, or what the things I print are is also none of their business. Neither is what I&#x27;m printing it for, where I put the printout after I take it from the printer tray, or if I use tape or a thumb tack to secure it in place, but you can bet that if software could easily collect that data it would and somehow it would be considered impossible to write good software without that information.From a privacy standpoint telemetry is always invasive, which is why I disable it any way that I can. Even without the privacy aspect telemetry is a bad idea. I don&#x27;t want program updates that remove features just because I (and others) don&#x27;t use them very often. I don&#x27;t want updates that constantly shuffle the UI around according to how they think \"most\" people have been using it this week. I don&#x27;t want my workflow disrupted every few months because it&#x27;s uncommon. I don&#x27;t want the way I choose to use the software on my device to influence how other people are expected to use it either.Telemetry is much better when it&#x27;s limited to reporting errors and bugs, but even that should be opt-in only. reply hotnfresh 17 hours agorootparentprevYou don&#x27;t see the problem of someone recording the actions you take using your own computer in your own home or office? It&#x27;s like having a stranger sitting over your shoulder watching you. It&#x27;s creepy and weird, and it&#x27;s gross that people try to do it at all. reply kevingadd 17 hours agorootparentIt&#x27;s one thing to argue over whether basic user facing software like an image compressor or a text editor should have telemetry, but a web browser is one of the least controversial scenarios for telemetry I can imagine. It is constantly sending and receiving data on your behalf with hundreds or thousands of servers spread across the internet as a user agent. Your usage patterns - i.e. is it crashing, is the feature you&#x27;re trying to use failing to work for some reason, is it rendering at a good framerate, is it running out of memory, are you having trouble finding the information you&#x27;re looking for - are going to be incredibly complex and specific to you.Significant bugs can affect only 1% or 0.1% of a browser&#x27;s userbase but at Chrome scale or even Firefox scale that&#x27;s like a million people. If you don&#x27;t have telemetry it is REALLY hard to hear from those people about their problems and understand them. There simply are not alternative solutions that work half as well as opt-in (or opt-out) telemetry. People who say web browsers don&#x27;t need telemetry are simply ignorant of what it&#x27;s like to ship one and try to keep it working in the face of a constantly shifting environment - broken drivers, broken VPNs, malicious websites, malicious extensions, broken hardware, and users who are confused or tired or simply just bad at using software. No one is speaking on their behalf, you have to dig their suffering out of the data by looking at crash reports and performance metrics.Shipping a web browser used by a million (or a billion) users means that you have a responsibility to do a good job. If your browser is not well engineered and reliable and responsive to users&#x27; needs that can result in data breaches or third-party server outages when your browser misbehaves or incorrectly channels user intent.I&#x27;m personally a fan of making usage telemetry opt-in instead of opt-out, but browsers are a case where I don&#x27;t opt out because I know how important the data is for browser vendors to make informed decisions.This is of course different from sending your browsing history to Google, Microsoft, or any other company. I encourage people not to opt in to that stuff and not to sync their history&#x2F;bookmarks&#x2F;etc to those companies. reply hotnfresh 17 hours agorootparent> It&#x27;s one thing to argue over whether basic user facing software like an image compressor or a text editor should have telemetry, but a web browser is one of the least controversial scenarios for telemetry I can imagine. It is constantly sending and receiving data on your behalf with hundreds or thousands of servers spread across the internet as a user agent.It&#x27;s probably no accident that spying on users got popular just as this became the case. Constant network traffic while web browsing didn&#x27;t start to become the norm until late in the &#x27;00s, either. If you weren&#x27;t clicking links, you could often open Wireshark or sniff with Netcat and see nothing. Not from your browser, not from anything. Certainly ~nobody was collecting heatmaps of where you move your mouse, or firing a network request if you selected text. Or recording entire user sessions for playback, or so you can watch them live (god, those tools are creepy as hell) reply kevingadd 17 hours agorootparentThe prevalence of \"every app you use is a web browser now\" is absolutely a catastrophe for user privacy and software reliability for this reason, IMO. Every tiny component now has a thousand moving parts that can spy on you. replyJohnFen 18 hours agorootparentprev> Only listening to data from 1 & 2 results in the sort of angry posts you frequently see on HNIf that&#x27;s the sort of responses your studies produce, then your studies are seriously flawed. reply eviks 8 hours agorootparentprevBy reading up on those decades-old bugs in the issue tracker, by making said issue tracker easier to vote on and pleasant to look at, by making other easy feedback submission mechanisms that don&#x27;t become black holes themselves, by many other options mentioned elsewhere reply tester756 17 hours agorootparentprevThat&#x27;s good questionI feel like people who are fully against telemetry never had to deal with such issues in big apps reply mftrhu 18 hours agorootparentprevThey could ask their users. reply mo_42 18 hours agorootparentOr observe people how they interact with the browser. If they would observe my parents, they could learn a lot that cannot be captured by telemetry. reply kwanbix 18 hours agorootparentprevSo how many users do you have to ask for it to be statistically relevant for a user base of 360 million users? reply eviks 8 hours agorootparentHundreds? Increasing user base doesn&#x27;t matter much for sample size reply smegsicle 22 hours agorootparentprev> Mozilla definitely hold a public perception of being more trustworthy than Google or Microsoft100% true, definitely reply noman-land 21 hours agorootparentMozilla, the legally registered non-profit foundation with a mission statement[0], for sure is more trustworthy than a for-profit data behemoth whose sole revenue comes from collecting as much data a possible, or a for-profit tech company with a history of corporate abuse and user hostile behavior.[0] https:&#x2F;&#x2F;www.mozilla.org&#x2F;en-US&#x2F;about&#x2F;manifesto&#x2F; reply tapoxi 21 hours agorootparentThat&#x27;s the Mozilla Foundation, the Mozilla Corporation is the for-profit developer of Firefox that&#x27;s owned by the Foundation. If Mozilla never established the Corporation I&#x27;d give them more slack, but from a \"it&#x27;s nonprofit\" perspective it&#x27;s on the same level as IKEA, which is also owned by a nonprofit foundation. reply kbelder 15 hours agorootparentFunny that I trust the Mozilla Corporation more than I trust the Mozilla Foundation. reply astrange 19 hours agorootparentprev\"Non-profits\" are still just as motivated to increase revenue as \"for-profits\".Most US hospitals are non-profits but you still see people complaining about them. reply barbariangrunge 20 hours agorootparentprevTechnically, google doesn&#x27;t sell people&#x27;s data. It uses data to train AIs to predict people&#x27;s behaviour, modify that behaviour, modify attitudes&#x2F;beliefs (it&#x27;s an ad company), and eventually replace people reply noman-land 20 hours agorootparentThanks, I updated my original post because how they profit from the data is immaterial to the fact that they want it and they coax people into letting them collect it. reply shawnz 20 hours agorootparentDoesn&#x27;t that more general statement now apply to anyone that collects telemetry, even for \"noble\" purposes, like Mozilla? reply kortilla 20 hours agorootparentprevIt sells a direct derivative of the data though, which is targeted ads. reply crawsome 21 hours agorootparentprevI&#x27;m not trying to be a contrarian, but Google paid Firefox lots of money to force Google as the default search. Likely an offer they would refuse at their own peril, but I really liked how my search engine settings persisted when I reinstalled. Now it defaults to google.There&#x27;s also a ton of promoted garbage on your homepage and privacy switches that need to be toggled off by default. Those settings don&#x27;t carry-over when you sync your account settings.I still prefer Firefox, but they are not immune to the encroaching enshittification. reply noman-land 20 hours agorootparentI agree they&#x27;re not immune whatsoever. In fact I hold them to a higher standard than the others because it&#x27;s their mission to do it, so their failures sting much harder.But I hold the others to zero standard. There is less than zero trust there. I expect to be abused by them because their mandate requires them to ignore my wishes. It&#x27;s not a failure but a success to them. reply PaulHoule 21 hours agorootparentprevThere was the “thoroughly pizzled” pockethttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Autofacon the other hand Microsoft and Facebook are doing this all the time. reply pseudalopex 21 hours agorootparentprevDid they remove public perception or did you quote something they didn&#x27;t say? reply jeffbee 22 hours agorootparentprev> I love Lynx because of thisPseudonymous user so concerned about privacy that they use the browser with by far the greatest density of exploitable flaws. reply StableAlkyne 21 hours agorootparentFriend, it is okay to enjoy things. Lynx is just a cool project :) reply tombert 21 hours agorootparentWell wait, I don&#x27;t think jeffbee was saying it&#x27;s bad to enjoy things, but rather that the person they were responding to was implying something, namely \"Lynx is (in some way) better than Firefox because it doesn&#x27;t take telemetry data.\"Lynx definitely takes less telemetry data than Firefox, but it also gets substantially fewer updates, including security updates. I think text-based browsing is pretty fun but I don&#x27;t really use it in no small part because of the infrequency of updates. reply s3p 20 hours agorootparentThe person you are replying to is the same person that they are replying to. you can just say \"you\". reply tombert 20 hours agorootparentI didn&#x27;t see that! Silly me! reply StableAlkyne 21 hours agorootparentprevI can see how the post could be interpreted that way. I&#x27;ve added an edit at the bottom to clarify that I&#x27;m not suggesting people actually use it as they main one. reply yjftsjthsd-h 21 hours agorootparentprevIf it doesn&#x27;t run JavaScript it immediately loses most attack surface relative to other browsers. reply TylerE 21 hours agorootparentIt also doesn’t (nor can it) load images, which is #2 reply yjftsjthsd-h 21 hours agorootparentYeah, right after I hit post it occurred to me that assorted media codecs (pictures, video, audio) were probably the next largest attack surface that lynx would also necessarily be immune to :) reply jraph 18 hours agorootparentI don&#x27;t know about Lynx, but terminal browsers can display images. w3m is able to do it on virtual terminals and terminal emulators that support it if you install the right packages (w3m-img on Debian for instance). reply astrange 19 hours agorootparentprevAttack surface matters for unknown attacks. If the browser just never gets security updates, it&#x27;s got more than enough known attacks. reply yjftsjthsd-h 17 hours agorootparenthttps:&#x2F;&#x2F;lynx.invisible-island.net&#x2F;current&#x2F;CHANGES.html seems to show it still getting updates; can you point to these known attacks that aren&#x27;t getting fixed? reply astrange 13 hours agorootparentI don&#x27;t know nothing about Lynx, except that I always wanted to write a CLI web browser that did support all web features like JavaScript, just to see if it&#x27;d work.This advice mainly applies to people using old OSes or who don&#x27;t update their browsers. reply SkyMarshal 20 hours agorootparentprevAnd also probably one of the most distinct footprints. reply downWidOutaFite 19 hours agorootparentprevI just went through Lynx&#x27;s thePseudonymous user so concerned about privacy that they use the browser with by far the greatest density of exploitable flaws.\"I love Lynx\" is different from \"I use Lynx for security-sensitive browsing,\" and \"greatest density of publicly documented exploitable flaws\" is, even if true (I don&#x27;t know), not the same as \"greatest density of exploitable flaws.\" reply Zekio 22 hours agoparentprevEspecially considering that google and microsoft probably collects 10x the data reply chrisjc 21 hours agorootparentWhile you&#x27;re probably right and we should be concerned, I&#x27;d say what is more concerning that than the quantity is the content.Whenever I hear that an app is collecting telemetry I feel conflicted between leaving it on for maintainers to gain a better understanding of performance and potential issues, or off so that it&#x27;s not used to profile me.It would be nice if telemetry was somehow simply differentiated through some app options. reply kccqzy 21 hours agorootparentprevChromium is open source. And unsurprisingly all the data collection bits are open source too. (They call it UMA metrics in the codebase.) Search in the codebase for things like UMA_HISTOGRAM_ENUMERATION or SCOPED_UMA_HISTOGRAM_TIMER and with a free afternoon you&#x27;ll have a pretty good idea what kind of telemetry Google really collects.Example: https:&#x2F;&#x2F;source.chromium.org&#x2F;chromium&#x2F;chromium&#x2F;src&#x2F;+&#x2F;main:bas... reply pornel 20 hours agorootparentChrome is closed-source though. There’s no way to make a reproducible build of Chrome (the Google binary adds DRM and could be adding more).I’m mentioning this, because this open-closed ambiguity is a typical Google strategy. Similarly, Android in the AOSP flavor is open, but the OS that actually ships on phones is different. reply eviks 8 hours agoparentprevWhat&#x27;s great about it? They can&#x27;t tie to a specific website, the data is dirty with other factors (as they acknowledge themselves), so what&#x27;s the benefit vs just testing in on an sample of actual websites to see what is slow? reply ad404b8a372f2b9 19 hours agoparentprevI don&#x27;t think that data gave them anything more than what testing on a few consumer computers in different price ranges would have.(Edited, original comment read: \"What more information does that give them than just buying a few computers at different price points?\") reply lolinder 19 hours agorootparentA vastly larger variety of different computers and computer setups than they could have come up with on their own. reply ad404b8a372f2b9 19 hours agorootparent(Sorry I edited my comment before I saw your reply.)That doesn&#x27;t seem very useful for the metrics shown in that article. For hard to find bugs sure, for 95th percentile calculations and so on you can just buy a few computers at a retail store and get the same information. reply astrange 19 hours agorootparentNew computers don&#x27;t behave like old computers, and it&#x27;s not worth trying to guess why that might be. Could be anything running in the background, old NAND, old battery, low disk space, satellite internet…Once you do have a model of badness I agree it&#x27;s better to try to set that up yourself. reply lolinder 19 hours agorootparentprevThat can get you 95th percentile calculations for brand new computers that you bought from the store in 2023 that are running Firefox alone, but that doesn&#x27;t help you understand what your performance will look like when you&#x27;re running on a 10-year-old machine running Windows 7 while the user is also running Microsoft Word, Excel, and Outlook at the same time. Your P95 numbers aren&#x27;t especially meaningful if you&#x27;ve only tested ~10 different PC configurations. reply sefeng 18 hours agorootparentprevMaybe you get the same result, but with the real user data, you can confidently say the performance has been improved without an disclaimer saying the data was collected in-house. reply lxgr 22 hours agoparentprevHappy to see the top comment on a Mozilla&#x2F;Firefox article not being somebody grinding their axe with Mozilla (and I say that as somebody definitely having a few) :) reply g-b-r 22 hours agoparentprevSure it really led to great things on Firefox Android :facepalm: reply g-b-r 14 hours agorootparentI invite people who downvoted to try it, I can&#x27;t believe you have reply user3939382 21 hours agoparentprevI just don&#x27;t like being bullshitted. Constant marketing about privacy while they&#x27;re phoning home a bunch of data when you start and stop the browser. I did at some point find a doc page with a zillion steps to disable all of it but that doesn&#x27;t remediate the hypocrisy IMHO. reply StressedDev 20 hours agorootparentWhat telemetry are you objecting to? Telemetry has good and bad uses. For example, sending in automatic crash reports helps companies find bugs. It can also expose sensitive information which was in ram at the time of the crash.Another example is usage telemetry tells developers what part of the app is being used and can help them focus popular features or on working to let people know about useful but under used portions of the app.My main complaint about people who dislike telemetry is they never acknowledge its good uses and they never state what telemetry is objectionable. reply Fnoord 18 hours agorootparent> My main complaint about people who dislike telemetry is they never acknowledge its good uses and they never state what telemetry is objectionable.There&#x27;s a good reason for that: it is an asymmetric relationship.The person who enabled telemetry isn&#x27;t necessarily the user of the software. Ie. it can be mandated or put on by a sysadmin (even by mistake), without user&#x27;s say. On top of that, the user of the software and&#x2F;or sysadmin are unable to assess whether they want to share the data because they cannot analyze the data beforehand. They lack the expertise in doing so.Meanwhile I have to disable telemetry every friggin&#x27; time I use Mozilla Firefox. It gets old, having to say &#x27;no&#x27; all the time, ya know? I now realize how it feels being a young woman on the market. Geez, I feel sorry for my daughter. The shit she&#x27;ll have to endure, sayin&#x27; &#x27;no&#x27; all the time. reply kortilla 19 hours agorootparentprevIf “being useful” is your argument for it, I don’t think you’re ever going to see eye to eye with people who don’t want it.It’s like you’re arguing about the good things the church does when it’s a discussion on separation of church and state. reply bee_rider 19 hours agorootparentReligion seems like a needlessly incendiary example that is going to bring up some strong rhetoric.But I mean I’m an atheist and I think religion is, on net, bad. But we’ve allowed a sort of less dangerous version of it to persist in most advanced countries, in the form of separation of church and state. If it was really just all bad, I suppose we’d ban it altogether.I think people can generally see that there are some pros to things they don’t like. Not engaging with the aspects of something that are inconvenient to your case puts you in the realm of propaganda and rhetoric, not good faith discussion. reply JohnFen 18 hours agorootparentprev> they never acknowledge its good usesProbably because there&#x27;s little disagreement about the existence of the benefits of it or what they are. That&#x27;s not the issue.For me, the issue (as with all things like this) is about consent. Opt-in telemetry? I have no issue with it. Opt-out telemetry? Very sketchy, but at least you can opt out. Undisclosed or mandatory telemetry? Completely unacceptable. reply ceejayoz 21 hours agorootparentprevA zillion?Preferences > Privacy > Firefox Data Collection and Use. Uncheck a couple boxes. reply user3939382 21 hours agorootparentThat&#x27;s some of it but not all of it. If you uncheck those and proxy FF when it&#x27;s starting you&#x27;ll see the chatter. I have the doc page I&#x27;m talking about somewhere but I have no idea where it is. Fully disabling it is a long complex process involving about:config.* Found this: https:&#x2F;&#x2F;github.com&#x2F;K3V1991&#x2F;Disable-Firefox-Telemetry-and-Dat... I haven&#x27;t compared their list to the one I&#x27;ve used before but it&#x27;s along the same lines and explains the discrepancy between the config settings and Firefox&#x27;s actual behavior. reply ceejayoz 20 hours agorootparentThose largely appear to affect local collection of telemetry.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;firefox&#x2F;comments&#x2F;7k3r9u&#x2F;mozilla_is_...> Telemetry data is stored locally by default. As long as the relevant options in the settings&#x27; UI are unchecked, or datareporting.healthreport.uploadEnabled is set to false in about:config, this data won&#x27;t be sent. There&#x27;s likely to still be some non-telemetry chatter, like checking for available Firefox&#x2F;plugin updates etc. reply A4ET8a8uTh0 19 hours agorootparent What makes you think they won&#x27;t one day push an update to just upload that local data?I&#x27;d imagine it&#x27;s a buffer; presumably someone using Firefox for a decade with telemetry off won&#x27;t accumulate ten years worth of telemetry pings. replymichaelmrose 19 hours agorootparentprevClick the menu button Fx89menuButton and select Settings. Select the Privacy & Security panel. Scroll to the Firefox Data Collection and Use section. Deselect the Allow Firefox to send technical and interaction data to Mozilla checkbox.You can get directly there by copying into the url barabout:preferences#privacy reply 3 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mozilla's Firefox browser in 2023 has undergone performance improvements as part of the Speedometer 3 effort, aimed to simulate real-world user experiences and drive enhancements.",
      "Improvements include a 15% reduction in time for loading the first visual from receiving the first byte of data from a network and a 20% cut in JavaScript execution time.",
      "There's also a recorded 10% improvement in \"keypress present latency\", offering users quicker feedback when typing, demonstrating Firefox's progress in prioritizing user experience."
    ],
    "commentSummary": [
      "Firefox users and developers have been assessing the browser's speed, advancements, and performance issues since 2023; recent versions and add-ons received high ratings despite some software incompatibility issues and slow adoption of new standards.",
      "The handling of JavaScript and data collection practices were key points of discussion, with some users highlighting both as essential to Firefox's improvement despite privacy concerns.",
      "The use of browser telemetry data, a potential privacy violation, was debated, with users emphasizing its role in software improvement and advocating for an opt-in system."
    ],
    "points": 594,
    "commentCount": 262,
    "retryCount": 0,
    "time": 1698770353
  },
  {
    "id": 38089247,
    "title": "Copying Angry Birds with nothing but AI",
    "originLink": "https://twitter.com/javilopen/status/1719363262179938401",
    "originBody": "Midjourney, DALL•E 3 and GPT-4 have opened a world of endless possibilities.I just coded \"Angry Pumpkins 🎃\" (any resemblance is purely coincidental 😂) using GPT-4 for all the coding and Midjourney / DALLE for the graphics.Here are the prompts and the process I followed: pic.twitter.com/st3OEhVVtK— Javi Lopez ⛩ (@javilopen) October 31, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38089247",
    "commentBody": "Copying Angry Birds with nothing but AIHacker NewspastloginCopying Angry Birds with nothing but AI (twitter.com/javilopen) 549 points by hackerbeat 20 hours ago| hidepastfavorite264 comments leshokunin 16 hours agoDisclaimer: I was a PM on Angry Birds.This is such a great demo. The original used Box2D,LUA scripting, and of course you had to make enemies and levels.There&#x27;s obviously no expectation that you&#x27;d make a hit game from the tech in its current state. You&#x27;re bound to be limited by the tech, rather than your own skills.But for rapid ideas, for prototypes, for game jams, this is a game changer. I can also see it as a great alternative to Scratch for kids to play around with ideas. Hope to see more platforms try to turn this into an offering! reply vvoyer 15 hours agoparentNice, what&#x27;s the craziest story about your time here reply leshokunin 9 hours agorootparentWould derail the thread pretty hard and I&#x27;m not sure even which one to pick. But my favorite memory was walking the streets of Seoul and getting in a little street market. There was this kid who was the son of the shop owner, playing on a cheap Android device. Super into the last update we shipped. You could tell he was gonna sit there on the floor in the corner and this would be his day. I was suddenly so self conscious about how we made levels and updates. Until then it was just the next update at the office, we had to make it good and polished and respectful of the player. But now it was this kid&#x27;s world, much like Super Mario Bros had been to me. It was important. It was a really humbling moment. reply savolai 8 hours agorootparentIt would be wonderful if such stories were more prevalent and lauded in the overall industry: at the ens of the day, it&#x27;s not about specific tech but about how we end up affecting concrete lives. Human-computer interaction as a research field is all about this; seeing the others&#x27; perspective. Sadly it&#x27;s seems to be largely seen as niche activity by the wider community. reply leshokunin 6 hours agorootparentI&#x27;d argue it&#x27;s the most important goal of all consumer software. It needs to be respectful of the player. To do that you need to really, actually care about where they are in their lives and what you can do to meet them. We had an expression internally: \"surprise and delight\". On a more personal level I&#x27;ve always loved Gunpei Yokoi&#x27;s \"lateral thinking, with withered technology\". reply generic92034 3 hours agorootparentThat might be a good approach for games and other apps with a certain level of redundancy and competition. But the other approach is having a vital product with high vendor lock-in factor, then eliminating the competition and consequentially forcing down the throats of customers whatever is promising more profit (browsers, \"big\" ERP, ...). reply simonebrunozzi 7 hours agorootparentprevI think many of us would love to hear more. Not looking for gossip or anything, just good stories about some technical hurdle you&#x27;ve overcome, or a special moment like this one you&#x27;ve just described. reply leshokunin 7 hours agorootparentWhats a good way to do this, an AMA? reply makapuf 7 hours agorootparentThat, or a tellHN text story with questions following ? replymattkevan 6 minutes agoprevI&#x27;ve literally just finished writing a Wordpress plugin with ChatGPT.It took me a few hours to build functionality that would normally need a paid plugin, and most of that time was spent working out the features. Woocommerce are charging a $50 subscription for basically the same thing.It&#x27;s fantastic to be able to have an idea for something and prototype and iterate it rapidly, without having to struggle with the implementation details. reply invalidusernam3 19 hours agoprevI did a similar exercise recently when I needed to make a fairly basic rest API and CRUD frontend using 2 frameworks I wasn&#x27;t particularly familiar with. I used GPT4 to generate ALL the code for it. I&#x27;ll write a blog post about it soon, but a quick overview was:I suspect it was slower than just writing the code&#x2F;referencing the docs, and would be much slower than someone could do if they were experienced with the two frameworks. I had to be very specific and write a few long and detailed prompts for the more complex parts of a the application. It took around 5 hours to make the application, with a lot of that time spent sitting waiting for the (sometimes painfully slow) ChatGPT output. In a framework I&#x27;m more familiar with I think I could have easily got it done in under 2 hoursIt was definitely useful for making sure I was doing it the correct way, kind of like have an expert on call for any questions. It was also very useful for generating perfectly formatted boilerplate code (some frameworks have CRUD generation built in, but this one did not).It was a fun experiment, and I found it useful as a learning&#x2F;guiding&#x2F;generation tool, but I won&#x27;t be using it for general day to day development any more than I currently do. For most instances it&#x27;s quicker to just learn the framework well and write the code yourself. reply jsight 19 hours agoparent> It was definitely useful for making sure I was doing it the correct way, kind of like have an expert on call for any questions.I&#x27;ve found it to be shockingly good at this. I end up asking a lot of questions like, \"what is the best directory structure for a project on {foo} platform?\" or \"What is the idiomatic way to do {x} in {language y}?\" It has the advantage of having seen lots of projects in every language, and for some questions that automatically leads to a good answer. reply two_in_one 16 hours agorootparentBe careful and don&#x27;t trust all it says. Sometimes it invents API functions which are not there, or doesn&#x27;t see existing. And always very confident till you point it. reply simonw 16 hours agorootparentI&#x27;m finding that code is the area where hallucinations matter the least... because if it hallucinates an API function that doesn&#x27;t exist, the mistake becomes apparent the moment you actually try to run it.It&#x27;s like having an automated fact checker! I wish I had the same thing for the other kinds of output it produces. reply zamfi 2 hours agorootparent> because if it hallucinates an API function that doesn&#x27;t existYes, absolutely agree.And also I’m no fanboy but when it does this and I only notice because the code doesn’t run, half the time I’m thinking to myself that the API function really should exist because it’s so logical! reply two_in_one 12 hours agorootparentprevIf it imagines a function it&#x27;s fine. You can fix it in one prompt. But when it doesn&#x27;t see it may move in the wrong way and produce limited solution. And you wouldn&#x27;t know. reply vasco 7 hours agorootparentYou would know in a similar way to a colleague of yours having done this code the previous day, or you joining a company with legacy code. It either has tests or you can&#x27;t really trust it anyway regardless. You can ask the AI to also write tests for you, inspecting tests is usually much faster than understanding all the nuances of the code. reply bugglebeetle 15 hours agorootparentprevIt will, however from time to time insert lines and variables that do nothing, but could result in bugs or confusion if not removed. I’ve encountered these hallucinations a few times. Overall, I agree with your sentiment, but I think it’s important to note that running isn’t always the indicator or correctness we think it to be. reply BbzzbB 13 hours agorootparentYou&#x27;re still supposed to read it, like you hopefully wouldn&#x27;t blindly paste a big code block from SO. A useless&#x2F;unused line or variable doesn&#x27;t seem that hard to spot? reply bugglebeetle 12 hours agorootparentOf course, but ease of detection can vary relative to the complexity of the code being returned. GPT-4, correctly prompted, can produce some pretty complicated stuff. But it also hallucinates in ways that are more subtle than one might think. The example I’m thinking of, it created an unused variable in a set of fairly complex ML training set up scripts that I mostly caught because I was familiar with all the proper inputs. But the unused variable was quite plausible if you were not familiar, new to the domain etc. reply gowld 0 minutes agorootparentCompilers automatically detect unused variables. Unused variables are the last of your problems. You should be far, far more worried about all the misused variables. JCharante 8 hours agorootparentprevDon&#x27;t IDEs highlight variables that aren&#x27;t read&#x2F;written to? reply lobsterthief 2 hours agorootparentIn this case “unused” might mean declaring or initializing a variable and then assigning or reassigning a value to it later. In this case, it is technically used, so most linters won’t pick that up. But it actually does nothing so it’s wasted cycles. reply ChatGTP 5 hours agorootparentprevI&#x27;ve noticed some other funny things, maybe harmless but undesirable.One example was really really hard to spot. Once I queried GPT 3.5 for a function to do X, and it did pretty well, when I looked closer though, it had wrapped 90% of the code in an unnecessary if statement. I looked at the code an thought something was off until I realized.My point here is, if that was easy to spot, who knows what else people are missing because even in a simple case, unless you&#x27;re actually trying to spot issues, you likely won&#x27;t see them. reply 1f60c 16 hours agorootparentprevAnd then it’s like, “thank you for telling me about this, I’ll remember that for next time,” which is how a human ought to respond but not how ChatGPT actually learns. reply simonw 16 hours agorootparentHah, yeah that&#x27;s so frustrating. It&#x27;s memory is reset every time you start a new conversation, but it doesn&#x27;t make that at all clear to people. reply gverrilla 12 hours agorootparentIt also resets inside a single conversation if you go beyond a certain number of tokens, and as far as I know there is no warning whatsoever to the user when it happens. reply taneq 2 hours agorootparentprevThe obvious next thing to try would be to continuously fine tune the model on these conversations, so it actually fulfills the promises most of these models make about \"learning continuously\". I haven&#x27;t yet seen any actual implementations of this, though. I&#x27;m sure someone&#x27;s tried it, I wonder how it went. reply PeterStuer 8 hours agorootparentprevOften I find that the hallucinations is how the API or lib should have been if it was more sane. Maybe someone could turn this into a virtual API critique. reply smsm42 9 hours agorootparentprevI see it all the time. Even more annoying is when the API exists, but in a different class or with different parameters and outputs than you need, and the model would claim it does exactly what you need right until the time you try to use it and discover it can&#x27;t work in your case. reply dartos 18 hours agorootparentprevI always get the classic “It really depends on your use case and neither pattern is exactly better than the other” when asking gpt about programming patterns reply sprobertson 18 hours agorootparentPut something in your system prompt along the lines of \"don&#x27;t waffle\" reply bfuller 14 hours agorootparentit has such a completionist fetish, I have found it works much better when you basically tell it to pick a side and not go out of its way to be balanced. reply Kiro 7 hours agorootparentprevEven when it says that it always continues with \"but\" and gives me an answer. reply acedTrex 18 hours agorootparentprevthis is how exactly how i use gpt4, i find it very useful reply Spivak 18 hours agorootparentprevI use Sourcegraph a lot for this when GPT can&#x27;t get a satisfying answer. reply marknutter 2 minutes agoparentprevYou should actually time how long it takes you to write it yourself rather than guess. The results may surprise you. reply COAGULOPATH 15 hours agoparentprev>I had to be very specific and write a few long and detailed prompts for the more complex parts of a the application.This is my experience. You still have to understand programming: you&#x27;re just typing it out in Natural English. reply invalidusernam3 3 hours agorootparentYes exactly. I had to be very specific and tackle the project in the same way I would if I was fully writing the code. First data schema, then models, then controllers with CRUD and views, then routes, then authentication, then test cases, then TS transpiling, etc...It&#x27;s definitely not something someone with zero coding experience could easily do, and I feel even a junior developer would struggle with anything even as complex as this. You have to have the concept and structure in your head, it&#x27;s just writing the code for it. reply SamBam 24 minutes agorootparent> You have to have the concept and structure in your head, it&#x27;s just writing the code for it.I wonder how far you&#x27;d get with the technique of asking ChatGPT to lay out its plans first, kind of like the improvements in math questions you see when you ask it to write down its reasoning before committing to any answer.\"This is what I&#x27;m looking for: XXX. What are the different pieces of this that I&#x27;m going to need to create?\"\"Ok, the first thing on your list you gave me was a database to store the data. What would the structure of that database look like?\"\"Can you give me the code to create that database?\"Etc etc. i.e putting the actual code as the last step each time. reply bugglebeetle 1 minute agorootparentThis is the best form of prompting for generating code. You tell it to first generate a technical spec for solving the stated problem problem, consider multiple options, return for your review. You then use a trigger command like “build” to then implement, once you’ve specified any changes. PeterisP 4 hours agorootparentprevThat&#x27;s a great fit for scenarios where you do know programming but don&#x27;t know the particular language and framework on which you suddenly have to do some maintenance or improvement.For many things the available documentation is poor, and asking a bot is much more helpful. reply bugglebeetle 15 hours agorootparentprevConversely, doing so has helped me flesh out my thoughts on many occasions. As I ran into obstacles with errors or imprecise prompting, I realized my design had issues or edge cases I hadn’t take into account. Perhaps it would be better if I wrote out several paragraphs describing my intentions before taking up most coding tasks, but I hardly think my boss would be in support of this! reply jdironman 14 hours agorootparentLike a rubber duck which provides feedback. but since it&#x27;s coming from a rubber duck it&#x27;s good to verify that duck knows what it&#x27;s talking about. reply jprete 12 hours agorootparentprev> Perhaps it would be better if I wrote out several paragraphs describing my intentions before taking up most coding tasksI often do things like this, and if the scale of the document was somewhat larger than you describe, it would be a design document. reply bugglebeetle 12 hours agorootparentMy role unfortunately doesn’t allow for this. I do more “in the trenches” data science stuff. The value is quite obvious to me for a role where there is more space for this or in product planning. reply drcode 11 hours agoparentprevWhat I think you&#x27;re overlooking is that most people can only do a few hours of hardcore coding at peak productivity a day (3hours for me, maybe)So you could spend 3hours babysitting GPT4 to write some code for you, but then you&#x27;d still have 3 hours of peak code productivity that day that you haven&#x27;t \"used up\" yet reply _delirium 11 hours agorootparentI’m the opposite, personally. I can code for 5 or 6 hours just fine if I’m “in the zone”, but I can’t deal with LLMs for more than an hour or two max, usually less. I find their sweet spot is when I need to ask one or two questions with one or two follow-ups, 5-10 minutes ideally. They can sometimes be a big win in small doses if you can keep it to that kind of interaction. But they are just draining to interact with for longer periods. For me they’re a lot like being a TA stuck in multi-hour office hours with undergrads once you get past a few questions. Just a really shitty slog. reply selcuka 11 hours agorootparentprevIf it were me, babysitting GPT4 would still spend my peak code productivity credits, as it&#x27;s basically coding (in natural language). reply kaba0 8 hours agorootparentprevIt’s thinking either way. I would even wager that the trivial code that GPT writes may be easier to read for me, than some convoluted, human language description of the same thing, done with numerous corrections at every point.The relative uniformity of code is a positive for human understanding as well, e.g. a^2+b^2=c^2 is easier to parse&#x2F;transmit the idea over any “spoken” version of the same thing. reply sundarurfriend 5 hours agoparentprev> I used GPT4Do you use the ChatGPT Plus version or the API? If the API, what do you usually use to access it? reply danielvaughn 20 hours agoprevThis is more interesting than the deluge of posts that say \"I created an iOS app in 30 minutes using ChatGPT!\" Which doesn&#x27;t mean much because it could&#x27;ve done nothing more than create a simple hello world.This one at least shows the finished product, which is indeed pretty impressive.Some details I&#x27;d need to know are (a) how long did it take, (b) how many prompts, (c) how many course-corrections were required, and (d) how competent this individual was with the technologies in question.I&#x27;ve personally found ChatGPT extremely empowering in lots of scenarios, but code generation was not among them. reply strombofulous 19 hours agoparenthttps:&#x2F;&#x2F;twitter.com&#x2F;javilopen&#x2F;status&#x2F;1719363669685916095 is relevant> Although the game is just 600 lines of which I haven&#x27;t written ANY, [coding the game] was the most challenging partNot quite hello world, but not too much more difficult than a shopping list. The really impressive thing to me is you can make angry birds with just 600 loc (and a couple libraries) reply samspenc 17 hours agorootparentMy guess is that the main parts of the game are physics (collisions etc) and the scoring system, so that part wasn&#x27;t too surprising to me.I was pleasantly surprised at the visual quality, I knew Midjourney could produce quality graphics assets, but I guess I didn&#x27;t realize how easy it was to pull into a game. reply croes 18 hours agoparentprevThere are lots of open source Angry bird clones, so it&#x27;s not quite as impressive as it seems.Programming a new game without dozens of existing templates would be a better litmus test. reply realharo 8 hours agorootparentNot only are there tons of Angry Birds clones (Angry Birds itself is kind of a clone of earlier games), there are also tons of step-by-step tutorials for making them, which were no doubt included in the training data. reply fauria 17 hours agorootparentprevSumplete would be a good example: https:&#x2F;&#x2F;sumplete.com&#x2F; reply realharo 8 hours agorootparentThat&#x27;s not an entirely new game (though the other versions of it are pretty obscure), but super interesting https:&#x2F;&#x2F;www.digitaltrends.com&#x2F;gaming&#x2F;sumplete-chatgpt-ai-gam... reply low_tech_love 7 hours agoparentprevOne other interesting question is “how does it work in all the other cases not shown in the video?” reply cryptoz 19 hours agoparentprevI’ve been playing with ChatGPT code generation to make entire sites with flask, python, html+js+css, backed with SQLite db and it’s amazing. I’ve had it write like 5k lines that are all live in prod and working (not much traffic lol but still).A huge huge factor is knowing the limitations and getting better at prompting. And identifying likely hallucinations and asking for risks etc.I’ve found it best with tech I don’t know well (I’m an android dev using it to make websites, something I haven’t done myself in like 15 years).Most of the coolest stuff for me is help with sysadmin and running the server. The ability to debug gunicorn errors is great.I do have to modify the code it outputs as the project grows and it loses context, but honestly the context limits are the biggest hurdle for bigger projects and those will be lifted soon.Edit: Most recent site I made with like 95% code from ChatGPT is https:&#x2F;&#x2F;cosmictrip.space&#x2F; which generates prompts with GPT-4 that are then used to generate space images with DALL-E.It&#x27;s a simple site but there is a secret adventure game I&#x27;m working on (GPT+Dall-E) that is open-ended image+text AI-driven game. I&#x27;m hoping to launch before Nov 6 with DALL-E 3 API (hopefully...!). The adventure game is also written like 95%+ by ChatGPT.I&#x27;ve had such great success with it coding that I&#x27;m using the GPT-4 API with an agent I&#x27;m making (everyone is huh). I have function calling hooked up to generate structured subtasks that the agent can then write the code for, and support for files to include context, chat with your code, etc. It&#x27;s not ready to show but the GPT-4 code generation abilities are really incredible - but you have to be experienced at prompting. Your first prompts aren&#x27;t likely to be great, which is why I&#x27;m hoping my agent can have success. The idea of the agent I&#x27;m writing is a Jira&#x2F;kanban style board where you have AI coders assigned to tasks that you can approve and modify etc. The tickets should automatically move across the columns as the AI checks the work etc. reply maxwelljoslyn 19 hours agorootparent+1 for its suitability in helping with systems administration.One responsibility at my current job is administering a Windows server and trying to get it to do things that are easy on a Unix -- that should be easy anywhere -- but, on Windows, seem to inevitably degrade into nightmares. ChadGPT has given me huge amounts of blessed ammo to shoot at the nightmares, and there&#x27;s no way I could do that portion of the job in a feasible time frame without it. reply ChatGTP 8 hours agorootparentChadGPT ? reply vunderba 15 hours agorootparentprevadventure game I&#x27;m working on (GPT+Dall-E) that is open-ended image+text AI-driven game. I&#x27;m hoping to launch before Nov 6 with DALL-E 3 API.Some people have hooked AI dungeon &#x2F; koboldAI up to stable diffusion to generate these kinds of procedural Ender&#x27;s game style interactive graphical text adventures with varying degrees of success.If your game is going to be similar, you&#x27;d better get in the habit of aggressively caching the generated imagery for it on S3 because no way the DALL-E 3 API is going to be cheap. reply sagarpatil 11 hours agorootparentprevYou are right about the context window limitation. I exclusively use Azure OpenAI GPT-4 32k version and it&#x27;s been a game changer when coding on complex projects. reply abdullahkhalids 18 hours agorootparentprevIs it at all possible for you (or someone reading who has done something similar) to share their chat?Reading good prompting is probably one of the better ways of learning how to do it. reply cryptoz 17 hours agorootparentThat is a great point and I will definitely share my prompting experience and some real prompts in a blog post this week. I&#x27;ll come back here and link to it when ready. reply vunderba 15 hours agorootparentprevThere was a Show HN a few months ago with something similar where a GPT agent would open up PRs with corresponding code against your GitHub repo. reply isoprophlex 19 hours agorootparentprevI feel that trapping your AI agents in a kanban board isn&#x27;t going to do your survival chances a lot of good when the robot apocalypse inevitably comes for us meatbags. reply meiraleal 17 hours agorootparentParents know what&#x27;s better for they kids, they will understand reply croes 18 hours agorootparentprevHow much of these 95% is boilerplate code? reply cryptoz 17 hours agorootparentSome for sure but all the algorithms (simple ones) and such is also done successfully by ChatGPT. reply wokwokwok 12 hours agoparentprevHonestly, it’s kind of difficult to believe.GPT4 is great at this stuff, but iterative refinement doesn’t work in my experience.As the conversation increases, the previous context is lost and the generated code deviates from its previous behaviour.For example, “fix this bug…” can easily result in a solution that breaks some other thing. You can also see code generated in thread (1) that does exist in the final result (2), suggesting that (since this is the very top of the code), they were getting chatGPT to iteratively generate 600+ line segments.I severely doubt this.Creating a new Slingshot on line 20 after it is defined on line 500? That is extraordinarily unlikely unless you specifically prompted it to do that.“loadImage(&#x27;stone2.png&#x27;);”, it just happened to pick the right file names? The right sprite sizes? You provided all that in a prompt and it wrote the code? Come onnnn… show us the actual prompt you used.It seems much more likely they generated a set of class objects relatively independently, then manually assembled them into a larger file, copied the entire thing as input and then crafted a “code prompt” like “write a function that does such and such”.It’s not impossible they used prompts like they claim (3), but I feel they are (for likes and cred) vastly overstating the “it did all the coding” part of this project.I feel they probably hand wrote some of the code (or assembled it) and used it as input + a “now do this also” style prompt, so the output was “100% generated”, but not in the way people are assuming.This approach tends to make GPT4 rewrite the existing code, but unless you specifically ask for (or add) comments describing the intent through out the code (missing in most of the generated code), it will drift from the previous functionality. With no test suite to verify, you won’t notice this subtle drift and things just break. There’s no mention of either of these things being done by the author.Further more, this user has a vested interest (4) in selling training materials for AI, so it’s in their interest to appear to be an expert at this, and has provided (even when asked on X) no additional details, no “step by step” git repo with history, no actual prompts they’ve used.Given the lack of details and the frankly unbelievable results, I think there’s fair call to be sceptical in this case.You could generate this kind of thing from models such as codellama 34B, or GPT 3.5; but not using the method as described.I’m… not convinced you could do it with gpt4. The prompts seem too stupid to be real (5)… but I happy to be proved wrong with more details. GPT4 is good.[1] - https:&#x2F;&#x2F;nitter.net&#x2F;pic&#x2F;orig&#x2F;media%2FF9xoI8mXgAAn7v9.jpg [2] - https:&#x2F;&#x2F;bestaiprompts.art&#x2F;angry-pumpkins&#x2F;sketch.js [3] - https:&#x2F;&#x2F;nitter.net&#x2F;javilopen&#x2F;status&#x2F;1719363669685916095#m [4] - https:&#x2F;&#x2F;javilopen.substack.com&#x2F; [5] - “Now, make the monsters circular, and be very careful: apply the same technique that already exists for the rectangular ones regarding scaling and collision area, and don&#x27;t mess it up like before. ” reply inciampati 11 hours agorootparentContext is 8k and it&#x27;s quadratic. It \"sees\" everything in that window. If you want to have a long conversation try Claude or some of the 32k models. Claude uses a strange kind of attention that isn&#x27;t always as precise but it&#x27;s very good at finding key information in huge documents. reply wokwokwok 11 hours agorootparentKey information is not relevant for generating code.You have to generate specific api calls with specific semantics not “high level summary” and “key information” .You have to generate token sequences that are functionally equivalent to an exact segment of the input prompt.A lower precision is less useful for code generation.How do you maintain existing code functionality when you give code + “refactor for x” as an input?I’m skeptical you’ve tried this and know what you’re talking about. reply inciampati 10 hours agorootparentYou are welcome to be skeptical and I will happily continue to use these tools for drafting code and writing every day. I usually provide documentation for the systems I want to use on input. Then I include source code of anything I&#x27;m hacking on. If none exists I build it up using \"let&#x27;s do this step by step\" where the first step is outlining or architecture and subsequent steps fill out components. The same pattern works for long form prose. Having 100k tokens is almost enough. It means the model can attend to a ton of relevant information.Also, this works well when the system gives you patches. I wouldn&#x27;t say \"rewrite this entire thing to make this one change\" because if it&#x27;s anything non trivial it will shift. Again I see the same patterns for code and text. Ask for small changes, contained updates. Guide the model to work in small increments, using abstraction to deal with high level broad topics. reply wokwokwok 10 hours agorootparentSeriously?You wouldn’t use it refactor because the implementation will drift, but you’d use it to generate a patch to apply to the code?Hm.Well, I don’t think that style is relevant or practical for large scale code generation as shown even in this ~600 line example.…but, I’d love to see the details of how it could done, end to end, by someone who has done something like that successfully and is willing to prove it by sharing the prompts and outputs. reply inciampati 2 hours agorootparentIt&#x27;s very hard to ask one of these systems to copy an entire piece of text and then change one or two things in it. They will often make small errors. So it&#x27;s easier to ask for patches and apply them manually to edit the code or text that&#x27;s being worked on. Happy to talk more how do I find you? replyfranze 20 hours agoprevAfter seeing my son rage-tapping a loading spinner I &#x2F; GPT coded this game on a lazy Sunday afternoon.https:&#x2F;&#x2F;spinner.franzai.com&#x2F;Think it could be an interesting UX pattern. Having interactive loading (spinner) games that at least give is feedback that our actions (even in between things) have impact. reply mhitza 20 hours agoparentIt is an interesting approach to loading screens, and personally I would have expected way more games to use such a feature. Not AAAs, of course, but indie games.I clearly recalled having read the news about the patent of this having expired a while ago, and from a quick search, a while ago, has been 8 years ago https:&#x2F;&#x2F;www.eff.org&#x2F;deeplinks&#x2F;2015&#x2F;12&#x2F;loading-screen-game-pa... reply dave84 18 hours agorootparentI remember playing Galaga while Tekken loaded on the PS1. reply feirlane 19 hours agoparentprevFor what is worth, my partner and I just had a good laugh playing this with four hands and pushing it over 25. Really fun fidget, thanks for sharing! reply leshokunin 5 hours agoparentprevFun fact: there&#x27;s a patent on loading mini games that has prevented such developments. I think it&#x27;s owned by Namco, you can see it in Ridge Racer reply jihadjihad 2 hours agoparentprevReminds me of watching the Saibamen grow while spamming the analog sticks on the loading screen in Budokai 3 (PS2). reply m_kos 11 hours agoparentprevFinger tapping test: https:&#x2F;&#x2F;psycnet.apa.org&#x2F;record&#x2F;2014-37068-023 reply GalaxyNova 17 hours agoparentprevI got it to level 7 reply 4ninesfine 12 hours agorootparentCould only get to level 6 on PC. On mobile with 8 fingers tapping got to level 37 pretty easily. reply jeswin 11 hours agoprevThat AI is transformative for development is not in doubt any more. Just this past week, I&#x27;ve been able to build two medium sized services (a couple of thousand lines of code in python, a language I hadn&#x27;t used for more than a decade!). What&#x27;s truly impressive is that for the large part, it&#x27;s better than the code I&#x27;d have written anyway. Want a nice README.md? Just provide the source code that contains routes&#x2F;cli args&#x2F;whatever, and it&#x27;ll generate it for you. Want tests? Sure. Developers have never had it so easy.One thing to note is that for code generation, GPT4 runs circles around GPT3.5. GPT35 is alright at copying if you provide very tight examples, but GPT4 kinda \"thinks\".Another piece of information from experience - GPT4 32k contexts fail quite often. So if you&#x27;re generating let&#x27;s say 10k tokens or more (around 30k characters), you&#x27;d have to give it a few tries. Another, ChatGPT is not the ideal interface for non-trivial work. You should use the API directly, or use something like Azure OpenAI Chat Playground which lets you use 32k contexts.Shameless plug: I have this open source app which automates grunt work in prompt generation - https:&#x2F;&#x2F;github.com&#x2F;codespin-ai&#x2F;codespin-cli reply junon 3 hours agoprev> any resemblance is purely coincidentalErr.. no it&#x27;s not. It&#x27;s trained on this stuff. It definitely knows how those games work after being trained on countless articles describing those games in detail.Cool project nonetheless though! reply atleastoptimal 15 hours agoprevThere have got to be some freelancers&#x2F;remote workers who have 100x&#x27;ed their productivity using GPT-4 and AI tools correctly. I can&#x27;t imagine all these cool hacks exist in a vacuum. Imagine what we&#x27;ll have in 2 years. The genie is out of the bottle. reply TheRoque 3 hours agoparent100x? Well they probably weren&#x27;t very productive in the first place then. If you know tips to use chatgpt and \"100x\" your productivity, please share. reply bluescrn 5 hours agoprevI&#x27;d be more interested in seeing AI create a game that doesn&#x27;t already exist.AI auto-plagiarism is a neat party trick, but can it create something new? reply dgb23 5 hours agoparentAngry Birds itself was sufficiently fresh and well made so people liked it.But it wasn’t really original in a true sense.One of the most appreciated games in nerd culture currently is the new Baldur’s Gate. It’s extremely well made, but not really original.Factorio or The Witness would be games that are both original and have been made with great technical and artistic care. But how many of these are made in comparison to genre games and mashups?I don’t think these tools are necessarily a hindrance to create good games. Tools are just tools. reply bluescrn 4 hours agorootparent> Angry Birds itself was sufficiently fresh and well made so people liked it.&#x27;Crush The Castle&#x27; was an earlier Flash game with the same mechanics as Angry Birds. Angry Birds just gave it appealing characters and visuals. reply gumballindie 4 hours agorootparentprevThe question is not about a game’s freshness. The question is wether procedural generators such as chatgpt can generate something truly new or is limited to its plagiarised parameters - which seems to be the case. reply haidev 5 hours agoparentprev+1 for this especially for anything other than CRUD or an already exciting game like Angry Birds where the first GitHub searches will return several results reply gwoolhurme 13 hours agoprevEvery time I see these articles I get more and more worried about my employability to be frank... with no backup plan and way too much time poured into learning software engineering. It&#x27;s not looking good gang. reply simonw 12 hours agoparentI&#x27;m genuinely not worried about that. As others have observed, us programmers will be in trouble when regular people learn to produce a product spec that&#x27;s detailed enough that an LLM can create the working software that they need.That sounds a lot like programming to me!I expect our work will change: we&#x27;ll be able to spend more time thinking about what we are building and less time typing code on our keyboards. But if anything, we&#x27;re going to become more valuable - because we&#x27;ll be able to get a whole lot more done. reply TheCleric 7 minutes agorootparent> I expect our work will change: we&#x27;ll be able to spend more time thinking about what we are building and less time typing code on our keyboards. But if anything, we&#x27;re going to become more valuable - because we&#x27;ll be able to get a whole lot more done.That would be lovely, but not how efficiency works in a capitalistic society. We can produce cars much faster in a factory then we could in the past due to various factors including automation. This doesn&#x27;t mean the workers get to take their time and a do a better job. Instead it means they are expected to have a higher volume.This is what I worry about with the rise of LLM programming (especially as someone who is less than impressed with the actual output I&#x27;ve seen). It&#x27;s not that I as a software engineer will be replaced by someone using GPT, but rather it&#x27;s I&#x27;ll be replaced by another software engineer who doesn&#x27;t care, using GPT to produce 3x as much \"software\" at half the quality because the only metric that some will look at is volume. reply chefandy 12 hours agorootparentprevNot having a detailed product spec is a much, much bigger problem when you can&#x27;t change the product to fit your needs on a whim. Beyond that, there&#x27;s a few layers between \"software developer\" and \"regular people\" that complicate your prediction.While most developers don&#x27;t hold interface designers in particularly high regard, honestly ask average people what they think of most developer-made interfaces and you&#x27;ll find out the skill is a lot trickier than it seems. Most developers only think they know what developers do, but they&#x27;re like many corporate workers see everyone from the head network architect to the community college desktop support intern as \"computer people who can fix your email.\" Most think interface designers primarily work on aesthetics, but most probably aren&#x27;t even invited to meetings about branding&#x2F;visual aesthetic&#x2F;etc...) Going further, many of those designers are savvy enough to write some basic code and likely bodge something into place, especially if they&#x27;re using some kind of purpose-built interface that can handle things like data model consistency between builds.It&#x27;s a very unpopular opinion around here, but I think designers using the next generation of no-code tools will eat front-end and simple app developers&#x27; lunches and I think it will happen really soon. I&#x27;ll bet teams at Wix, Webflow and other no-code authoring tools are working like mad to develop these tools right now, and I&#x27;ll bet that&#x27;s a hair&#x27;s breadth from automatically generating electron apps from whatever users make there. If your specialty is code, and there are people with whole other useful skillsets that could passably approximate that capability with a few occasional hours from a contractor, the developer isn&#x27;t going to be the one that still has a job.While the demand for developers is still large, it&#x27;s not infinite, and I look askance at assumptions that there won&#x27;t be a really painful &#x27;adjustment&#x27; for a lot of working professionals. reply kaveh_h 10 hours agorootparentThat’s assuming frontends need to be ”developed” at all in the future. There’s a possibility intelligent chat bots able to generate microfrontends on the fly is going to eat our lunch, but what is really going to eat the lunches is a failing capitalistic system due too lack of demand for labour. I guess overall society is going to balance things out somehow, curious if it’s going to be a in a civil manner or brutal disruption. reply chefandy 9 hours agorootparentWell, no the point to my comment was that they won&#x27;t need to be developed, and that the real skill will be in knowing how people interact with things so you can tell the machine what to make, and that is absolutely not a technical job. Even in the interim, incidentally gained technical skills will suffice rendering the technical people in the chain redundant. Surely the human understanding component will be whittled down at some point, too, but it&#x27;s a much much further goal than automating essentially mechanical processes.And, of course-- all of the \"unpleasant\" side effects of massive innovation would be totally avoidable if we didn&#x27;t treat people as disposable labor units worth nothing more than their market value. reply realharo 8 hours agorootparent>Surely the human understanding component will be whittled down at some point, too, but it&#x27;s a much much further goal than automating essentially mechanical processes.Why do you think that?People used to think that making paintings and poems would be one of the most difficult things for AI, and look how that turned out. reply chefandy 1 hour agorootparentBecause interfaces require situation-specific reasoning that purely expressive art can be imitated without. And frankly, I think the slick looking images that AI spews out from actual artists&#x27; munged up work is a far cry from being equivalent. Like interfaces, the people who wouldn&#x27;t pay an artist or designer to begin with probably don&#x27;t care enough about the quality of the art or interface for it to matter. Cookie cutter applications and stock images are going to suffer, but developers making basic crud functionality or simple API interactions will suffer soon after. reply gwoolhurme 7 hours agorootparentprevI don&#x27;t think the above comment disagrees that much with you. As far as paintings and poems go those are also pulling off of patterns that humans naturally have given off too right? An LLM is a bit more than a stochastic parrot sure, but it&#x27;s also a large part of how it functions. The real surprise, or maybe not a surprise, is how formulaic everything is. reply gwoolhurme 9 hours agorootparentprevI can only see brutality personally. I’m not prepared. Once I lose my way of making a living I think it’s done basically. Time will tell, but it’s never been kind before, why now? reply chefandy 8 hours agorootparentMany here seem to think anyone \"smart enough\" or \"hardworking enough\" could simply pivot into something else after their entire category of employment was decimated. I assume that:a: These people are very young and don&#x27;t understand what it takes to invest 3, 4, or 5 decades in a career and&#x2F;or despite their assumptions about their life experiences, have never actually experienced significant hardship.b: They&#x27;re neurologically or emotionally incapable of empathy or lack a usable theory of mind.orc: They&#x27;ve read too much inspirational linkedin hustle porn about people pulling themselves up by their own bootstraps (which is actually supposed to be a joke-- it&#x27;s obviously impossible to pull youself up by your own bootstraps, but for some reason people repeat it without considering its true meaning) and think if they are tough and ruthless enough that they&#x27;ll be one of the ones on top. Which is kind of sad. reply TeMPOraL 3 hours agorootparentOr a variant of a: they&#x27;re forgetting how little their first jobs paid.Even in most lucky case, pivoting your career into an entirely different category means reverting to entry-level pay, while your age, health and obligations remain the same. Imagine just the paycut alone happening to you, out of a sudden. And that&#x27;s the best case for what people displaced by AI will experience. reply ChatGTP 8 hours agorootparentprevI’d pivot into crime and drugs if I had too survive. I’ll be eating no matter what. Not too worried. reply chefandy 1 hour agorootparentAs someone who spent quite some time as a young person with the fringe end of society, I can assure you that saying you&#x27;ll pivot into crime and drugs is like saying you&#x27;ll pivot into being a plumber. It takes time to build a career that pays more then entry level money consistently, and good luck developing a network of connections to make it happen. It&#x27;s not like walking down the street to pick up an application at Chipotle. And AI is probably going to take individual computer criminals&#x27; jobs even before most other people&#x27;s. reply whatshisface 8 hours agorootparentprevYou know, they send people to jail over that stuff. reply chefandy 1 hour agorootparentFor most people who don&#x27;t already have an established network associated with crime, it would probably be the only way you&#x27;d get anybody to trust you. reply mrkstu 4 hours agorootparentprevHey they’d still have food&#x2F;shelter in that scenario… reply TeMPOraL 3 minutes agorootparentYeah, but a lot depends on where they live. From what I heard about the US penal system, someone living there would be better off being homeless than jailed. HPsquared 4 hours agorootparentprevHe still gets his food in that case. replygwoolhurme 12 hours agorootparentprevThat&#x27;s fair and I hope that is the case. That might even be fun, and I mean I actually have a lot of fun with gpt-4 now. My bigger complaint there then is that you need more money to be competitive in this industry now? Until LLMs become smaller more efficient? Like back in university the best student was a Russian immigrant who learned back in Moscow on pen and paper, no compiler to mostly handhold. reply agileAlligator 12 hours agorootparentprevThe workflow has shifted a step up:1. Define problem2. Generate specifications No prompts, no nothing, just the finished productDid you read beyond the first tweet? reply tw061023 7 hours agorootparentThere are 6 tweets in the thread: announcement, link to the game, introduction, graphics, programming, conclusion.These tweets do not describe the exact and specific steps to reproduce the complete result. They only provide rough and obvious (for anyone ever interacted with GPT) advice, as is par for the course for AI hyping.This:> And from there, keep asking for more and more things. And every time something goes wrong, clearly explain the mistake and let it fix it. Patience!Is pathetic, and proves exactly nothing.Yep, I did not do that all the times I tried to actually see why GPT4 is so popular, thanks a lot for advice! reply LastTrain 19 hours agoprevThis is interesting, but, the \"nothing but AI\" part is clearly not true and so I&#x27;m not exactly sure what was done here. reply carnitine 19 hours agoparentYou’re saying that based on what? All the code and assets are AI. reply LastTrain 19 hours agorootparentThe music? reply somsak2 15 hours agorootparentWhat music? There is none. reply omarfarooq 18 hours agorootparentprevThere&#x27;s AI for that too, now. reply LastTrain 18 hours agorootparentBut it wasn&#x27;t used to generate the music in this \"game\" that isn&#x27;t a game. This was my point - that it is unclear exactly what AI did and did not do in this case. Like, I&#x27;m 100% sure my mom could not have done this, so, not \"all\" AI like the title says. reply simonw 17 hours agorootparentThe Angry Pumpkins game doesn&#x27;t have sound effects or music - you can play it here: https:&#x2F;&#x2F;bestaiprompts.art&#x2F;angry-pumpkins&#x2F;index.htmlThe Twitter thread shows exactly what the AI made. It was used for the JavaScript code and the image assets.If you don&#x27;t have a Twitter account you can see the full content on Nitter https:&#x2F;&#x2F;nitter.net&#x2F;javilopen&#x2F;status&#x2F;1719363262179938401 or in my Gist copy: https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;f7ed52daaa66f849858d17e0d6c1c... reply ziddoap 17 hours agorootparentprev>\"game\" that isn&#x27;t a game.Why is it not a game? I even played it a bit -- was I hallucinating? replyKiro 19 hours agoparentprevWhat do you mean? reply fareesh 12 hours agoprevAside from the images I suspect the code is inspired by something in the training data since it&#x27;s quite a common project reply simonw 12 hours agoparentOne of the prompts they used was:\"Now, I ask you: do you know how the birds are launched in Angry Birds? What the finger does on the screen? Exactly. Add this to the game, using the mouse.\" reply la64710 17 hours agoprevThe real challenge is generating a large code base (think more than a JavaScript loaded page) - the front end backend and everything in between and then automating the testing and deployment … reply m3kw9 20 hours agoprevProb needed to a ton of glue code to have it at quality reply nobodyiam 14 hours agoprevPretty impressive! Using AI as a copilot is definitely the right way forward. reply demondemidi 17 hours agoprevDoes it generate the same result for everyone who enters the prompts? (Not an AI guy here) reply simonw 17 hours agoparentNo, it won&#x27;t. There&#x27;s a big random element to this, especially when you are prompting GPT-4 directly through the ChatGPT interface.Image generation models can sometimes produce the exact same image if you fix the seed they are using - there are different procedures for doing that for different image models.LLMs like GPT-4 can have their \"temperature\" dialled down, but even at 0 they aren&#x27;t guaranteed to return exactly the same response to a given prompt. I believe this is because they run floating point operations in parallel across multiple GPUs and floating point arithmetic isn&#x27;t actually commutative - you can get back a slightly different result if the multiplications run in a different order. reply dgs_sgd 17 hours agoprevThis is exciting, like we’re about to enter a new golden age for indie apps and games. reply tayo42 16 hours agoprevidk why it wasnt obvious to me before, i never bothered trying to make games because i wasnt good at digital art and didn&#x27;t really have the interest to try to be. i should now... lol reply kevinsync 18 hours agoprevDespite the expected contrarianism in the comments, and I promise I&#x27;m being positive here, I&#x27;m pretty sure GPT-4 did really well on this task because a quick Google search shows a bunch of existing projects spanning blogs, GitHub and YouTube that it almost certainly trained on:https:&#x2F;&#x2F;www.google.com&#x2F;search?q=matter.js+angry+birds+cloneThis is not a Bad Thing (tm) -- it&#x27;s actually really sick because you can quickly get out of the weeds and get productive, especially if your skillset is not as deep as you&#x27;d have needed to accomplish even half of this a decade ago.Nobody ever said paint by numbers was capital-P \"Painting\", but sometimes it&#x27;s a blast to do one. I remember being 12 and making custom WADs for Doom &#x2F; Hexen; my 6th grade son builds endlessly-creative and complicated modded Minecraft worlds with detailed machinery and electrical circuits and all this crazy seemingly-adherent-to-real-world-physics shit. Angry Pumpkins is arguably an order of magnitude better than simply re-skinning a Cyberdemon, because lowering the \"time-to-screen\" with any project (and in this case, providing a blueprint) is fun, creative, and most importantly ENCOURAGING for the next generation.Anyways, I like it! reply epiccoleman 18 hours agoparentThanks for writing this. This really mirrors my own perspective. Yeah, these tools aren&#x27;t exactly \"learning to fish,\" but if this gets someone excited about \"fishing&#x27;, then that&#x27;s a good thing. A lot of my early coding experiences were in a similar vein to what you described, altering gamemaker projects and things like that. And even now I have a lot of fun playing with this AI stuff. It can help me go from 0 to 20% on something I previously knew nothing about, and sometimes that initial boost is all I need to get over the friction and actually do something cool. Or sometimes I realize that it&#x27;s not worth the amount of effort it would take to go to the next 80%. That&#x27;s OK too.I totally understand the cynicism around this stuff, but for me it&#x27;s like... 99% exciting and cool. reply godelski 17 hours agoparentprev> This is not a Bad Thing (tm)I wholeheartedly agree. I am often one to critique ML systems, especially LLMs and GPT. But this is my training as a researcher. I think it is important that we recognize critiques and discussions of limitations are not equivalent to calling a tool useless or worthless. It does not even devalue the tool. Rather the discussions are beneficial for two contexts: we learn the limitations to build better tools (since no tool is perfect there will always be critiques available) and we learn how to use the tool effectively (you&#x27;re still not going to use LLMs to do you differential equations homework despite this certainly being within the training set). There&#x27;s also the important context that we are on a tech form in a community that is well known to be inhabited by the exact type of people that build, test, and deploy these types of systems (myself included). These are not the same discussions we&#x27;d be having in the context of sitting around with my parents who are absolutely tech illiterate.My thoughts as a highly critical person (check my history, or even a very recent highly relevant comment in another thread) are \"this is pretty fucking cool\" (same to that very same thread btw). I hope to see more stuff like this. It is what makes me passionate about ML and it is what keeps me coming to HN.Your work doesn&#x27;t need to be novel to be useful. Nor does it need to be useful to be good. I&#x27;m just happy to be seeing people do shit and having fun. reply toddmorey 15 hours agoparentprevVery good perspective from the creator&#x27;s vantage point.From the consumer vantage point, I do worry. Even Apple&#x27;s \"curated\" App Store is already flooded with quickly made knockoffs... as close as they can get in the hopes that they&#x27;ll confuse just a few folks into a purchase. It works well enough and it&#x27;s profitable enough that an entire industry does factory-style it for every popular title. (Like a digital Shein.)The internet is already full of the quick-launch low-value-add content that AI excels at creating. We&#x27;re about to see a whole lot more! The good news is AI can also be very effective at prescreening and filtering out all this content vying for our eyeballs. Right now it feels like me vs the AI content cannon, but soon it will be AI filters battling AI content while the machines sort out what makes it to my digital devices. reply simonw 15 hours agorootparentHonestly there&#x27;s enough junk content out there that I don&#x27;t see generative AI making much of a difference.What we need is better habits around peer-to-peer recommendation. I need people I know with good taste to spend more time talking about the games that they like! reply TedDoesntTalk 15 hours agorootparentAre there Reddit subs for that? reply simonw 15 hours agorootparentIf anyone can join a subreddit you can&#x27;t guarantee that spammers won&#x27;t join up to promote junk.I&#x27;m having great recommendations from invite-only Discords these days. reply fnimick 4 hours agorootparentNot all of us have access to elite invite-only communities, nor the name recognition or clout to solicit invites to them. reply simonw 3 hours agorootparentCreate your own and invite people who&#x27;s opinions and taste you respect to join it. replycroes 18 hours agoparentprevOk, but many of these AI tools are promoted as Programming bots with a capital-P reply kevinsync 18 hours agorootparentThat&#x27;s just marketing. McDonalds will sell you what it calls a Hamburger with a capital-H, but we could argue endlessly about the veracity of that.In the end it doesn&#x27;t matter -- some people like it, some people hate it, it&#x27;s good, it&#x27;s terrible, it&#x27;s whatever you at this moment in your life decide it is for you, but regardless of opinions, it&#x27;s still edible.I just love what this guy made mostly because he followed through and made something, anything, and put it out there (presumably for the pure joy of creation).. and it got us all talking about it lol reply godelski 16 hours agorootparent> That&#x27;s just marketing. McDonalds will sell you what it calls a Hamburger with a capital-H, but we could argue endlessly about the veracity of that.Well they can&#x27;t sell you a quarter pound of horse meat as third of a pound of beef. There are laws about this and I believe they do deserve criticism. But that criticism is completely orthogonal to how good the \"hamburger\" tastes and the nutritional value of it.But personally I could never do marketing. I feel like their skills lay in getting as close to a lie as possible without technically being one. But I also think this is why people are not happy with a lot of products, because they aren&#x27;t getting what they were expected. But at the same time I think companies are in an arms race that has simply been a race to the bottom where we&#x27;re at or near and no one can get an economic edge simply by telling the whole truth and nothing but the unquestionable truth. The (near) liars have the distinct advantage in a world where it is impossible to have objective validators. It&#x27;s why we have reviewers but why reviewers also got metric hacked. Idk what the solution here is but I definitely understand why people are upset and I wouldn&#x27;t call this a fruitful endeavour where we&#x27;ll argue endlessly. That&#x27;s more about people having difficulties in expressing why they feel frustrated. reply nativeit 17 hours agorootparentprevAt best, I expect it will maybe reach parity with (more likely fall short of) the kind of accessibility that other low-code application development tools and WYSIWYG website builders have reached. Specifically, I can see where this kind of utility will be too limited for professionals and skilled amateurs to bother with, beyond maybe doing some kind of “boilerplate+”, and yet it will remain out of reach for the vast majority of laypeople who will quickly realize that programming requires more than just a grasp of syntax and an IDE. Square Space and Wix haven’t meaningfully impacted the professional web design market as near as I can tell, and Airtable hasn’t cost any SQL engineers their jobs.Just my gut instinct, though, and I’ve certainly been wrong before. reply godelski 17 hours agorootparentprevSure, and that deserves more critique than this. But the critique there is that you&#x27;re being marketed a product under false pretenses. I&#x27;ll give you an example to help clarify. In another thread[0] the OP is showing off their ML programming assistant. The project is unquestionably cool and has every right to be on the front page of HN. But there are still major questions I have. The implicit critique here comes form the fact that the author says \"beats GPT 4 at coding\" but then their basis for this claim is simply via HumanEval performance. In reality the evidence does not support the claim (it doesn&#x27;t say the contrary either, it simply is indeterminate -- not to be confused with orthogonal&#x2F;irrelevant). This is marketing. I&#x27;m not sure if it is dishonest marketing, but I would not call it honest marketing either. It&#x27;s in the gray. The thread originally had an intro from OP who was specifically requesting comments too and so the context is appropriate, other than the nature of simply being on HN.[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38091869 reply Aeolun 16 hours agorootparentprevWell, most programming is just doing what was done before again?Anecdotally a lot of my coworkers seem to say they did something ‘with chatgpt’. reply Waterluvian 18 hours agorootparentprevAnd some people think Synthesia is actually teaching them piano.It might get them into the door. It might give them all they are seeking and that’s all awesome. They might find that they hit a wall and need to go learn how to read sheet music. Or they don’t.The thing about “it’s not real programming” is that I don’t think it matters. They might just end up a bit surprised that they hit a wall and have to go back and learn more of the fundamentals. reply yieldcrv 17 hours agorootparentAI is good at that tooI learned just enough about “chord progressions” in order to ask ChatGPT to make both the lyrics and chord progressions for meI just input them and humans like itI wouldn’t have initially known the terms to use. Nowadays I can prompt for that too though “what concepts do I need to understand in this field” “tell me more about number 3” and I hope it didn’t just make something up but it’s good enough to converse with humans about - who also make things up reply LastTrain 18 hours agoparentprevI like it too. I also wrote a negative comment, but it was about how the title was not completely honest, which is a different issue than whether or not this was an impressive feat of AI. reply yieldcrv 17 hours agoparentprevI just like that I don’t need to hire designers anymoreI didn’t mind designers or their cost, I minded the time and the gamble involved with output close to what you imagined, and revisionsI also found negotiating rights to be full of hubris and pride that caused alot of more friction. Ironclad contracts being too heavy handed with that communityI’ll take the potential forfeit of copyright in exchange for instant output, i can put up a payment portal for royalty free works, i can still sell data reply hnlmorg 18 hours agoparentprevThat’s a really interesting perspective. Thank you for sharing. reply simonw 17 hours agoprevTwitter is a bad place to share original content these days, because anyone without a Twitter account not only won&#x27;t be able to see anything more than the first tweet but (crucially) won&#x27;t even see a visual indicator that there IS more content to see.Here&#x27;s a screenshot to illustrate: https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;f7ed52daaa66f849858d17e0d6c1c...For people without a Twitter account, I&#x27;ve pasted the content of the thread into a Gist here: https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;f7ed52daaa66f849858d17e0d6c1c...The most important missing link is the live demo, https:&#x2F;&#x2F;bestaiprompts.art&#x2F;angry-pumpkins&#x2F;index.html reply lazycouchpotato 17 hours agoparentThere&#x27;s Nitter.net for now, thankfully.Nitter link: https:&#x2F;&#x2F;nitter.net&#x2F;javilopen&#x2F;status&#x2F;1719363262179938401 reply 1f60c 16 hours agorootparentThere’s a list of Nitter instances here, if the flagship instance isn’t working (this happens from time to time): https:&#x2F;&#x2F;github.com&#x2F;zedeus&#x2F;nitter&#x2F;wiki&#x2F;Instances reply lazycouchpotato 15 hours agorootparentOh I wasn&#x27;t aware there were other instances. Thanks! reply mackwell 16 hours agoparentprevI have an account and half the time when I follow a link from HN to Twitter &#x2F; X it just throws an error that something went wrong &#x2F; can&#x27;t load the tweet. And video content works even less often than that. The site seems like it barely works at this point and is rapidly becoming a ghost town. What a waste. reply worldsayshi 16 hours agoparentprevAnd also, who knows where Twitter will be in a year. This could all disappear in a black whole judging by the somewhat chaotic developments. reply pvg 15 hours agoparentprevTwitter is a bad place to share original content these daysIt might be but it&#x27;s an interminable debate that&#x27;s mostly HN-offtopic since its been long rendered uninteresting through sheer repetition. reply simonw 14 hours agorootparentI don&#x27;t think that&#x27;s the case.I have seen plenty of complaints on here about Twitter in general, but I don&#x27;t think the specific point that the new registration wall makes it a bad place to post original content has been discussed much here at all.Happy to be proved wrong.Edit: proving myself wrong here: it looks like links to nitter show up in comments here every few days, so the fact that the Twitter registration wall needs to be bypassed is actually pretty well understood. https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=false&qu... reply pvg 13 hours agorootparentIt is so much the case there&#x27;s a site guideline about it plus countless mod comments.The registration thing is just like the paywall thing - if there are workarounds, it&#x27;s fine. reply xwdv 19 hours agoprevEveryone will think this impressive, but they’re not game developers.You could literally make all this in probably 24 hours and not spend any time mucking around with prompts.Like what are we even seeing here? Basically a tech demo of a physics engine, a little UI interaction for throwing a collidable entity into other entities, and some code for setting up a level?Show me the maintenance, adding new features, bug fixing, cross platform compatibility, shaders, networking code, sound, etc. reply furyofantares 18 hours agoparent> Everyone will think this impressive, but they’re not game developers.I&#x27;m a game developer. It&#x27;s impressive.I&#x27;m extremely aware of how short a game jam demo is compared to an actual product. There&#x27;s an ocean between the two.That doesn&#x27;t diminish how much easier and more approachable it suddenly is for someone with little experience to make a game jam demo, and with kinda-passing art. reply l33t7332273 19 hours agoparentprev>ou could literally make all this in probably 24 hours and not spend any time mucking around with prompts.I couldn’t make that art in 24 days.The big thing about the state of current AI isn’t that it does a bunch of things, it’s that it drastically increases the number of people who can do things.That is, I could not make this game in a day before AI. With it, maybe I could. I am far from unique. reply rchaud 16 hours agorootparent> it’s that it drastically increases the number of people who can do things.Giving the whole world blogspot.com 20 years ago didn&#x27;t measurably improve the internet, it just added a few more winners and a gigantic increase in low-quality spam pollution. reply l33t7332273 7 hours agorootparentIf you’re saying blogspot is in the same ball park as generative AI I just don’t know how we can continue. reply rchaud 3 hours agorootparentBloggers have broken news well in advance of large news outlets, partially because of the ability to publish online rapidly, without knowing HTML or administering a web server.But it&#x27;s mostly been used to pollute the internet with useless spam. With generative AI, the same thing will happen. The very example shown here is an Angry Birds clone, patient zero of the pay-to-win hellscape of mobile games. I don&#x27;t think it&#x27;s an accident that they had AI in their hands and decided to build that. reply gowld 18 hours agorootparentprevAnd it drastically increases the number of things a person can do. reply torginus 19 hours agoparentprevWhich imo summarizes what GPT4 is great at - bootstrapping devs who have a general idea of what they want, but are not familiar with the exact specifics of the technology, or need to freshen up their knowledge.I&#x27;ve learned Kubernetes and Powershell this exact way. reply dan-g 19 hours agoparentprevYou could argue then that this reduces the barrier to entry for people to become game developers.Isn’t everything you just listed (physics engine, UI, collide entities) how you make a simple game? It doesn’t matter that it doesn’t have networking code, shaders, or sound. Those things can be added later.I don’t think it’s productive to gatekeep who is and isn’t a game developer. They developed a game, that makes them a game developer—it doesn’t matter how they got there. reply raytopia 19 hours agorootparentI&#x27;m not sure how this reduces the barrier to game developement. There are already lots of free assets and game engines designed for making arcade games that are a lot easier then say Unity or Unreal. Like https:&#x2F;&#x2F;arcade.makecode.com&#x2F; or https:&#x2F;&#x2F;microstudio.dev&#x2F; or https:&#x2F;&#x2F;scratch.mit.edu&#x2F;. And if you don&#x27;t want to make arcade games there are other tools like RPG Maker, RenPy, GDevelop, and many more each of which are much easier to use then this AI pipeline (not to say it isn&#x27;t impressive you can do this with AI though) and will lead to better outcomes of actually understanding game development. reply dan-g 16 hours agorootparentMy point is there isn’t a “correct” way to become a game developer— by your own response you showed that there are frameworks you can use, WYSIWYG editors, you can code a framework from scratch in a high- or low-level language, or you can work with an AI to make something that works.This person successfully developed a game. Just because it isn’t how others would have done it doesn’t minimize the result. reply gowld 19 hours agorootparentprevAll of those things require me to write code, in an annoying, slow, hard to debug click-drag format. I&#x27;d rather the AI write the code for me based on my natural language description of what I want. reply xwdv 19 hours agorootparentprevI think some gatekeeping is warranted. If I stitch a wound it doesn’t suddenly mean I’m a doctor.Similarly, using AI to develop a game makes you as much of a game developer as someone who hires someone to make a game for them. And some development studios are basically that, people hiring developers to make games. But AI can’t compete well with that.It’s like coming up with a new fusion power plant, but it takes more energy to run than what it produces. Inspiring, but useless. reply dan-g 16 hours agorootparentYeah, being a doctor is a certifiable profession— there are tests, governing bodies, standardized curriculum— are you saying the same exists for “game developer”, a role which could mean a hobbyist, indie developer, or someone working at a huge studio?This really sounds like “real programmers write in assembly” to me. An AI is a tool, not dissimilar from a higher level language. This person used a tool to create something that didn’t exist before. The result is right there. reply gowld 18 hours agorootparentprevAngry Pumpkins did not exist. Now it does. In time for Halloween. You can&#x27;t refute that.Using a computer to write a letter makes you as much of a writer as someone how hites someone to write a letter for you. And some writers are basically that, hiring scribes to write for them. Computer can&#x27;t compete well with that.Except it does. reply gardenhedge 18 hours agorootparentDid I miss the link to download the app or something? Where does it exist? reply GaggiX 18 hours agorootparenthttps:&#x2F;&#x2F;bestaiprompts.art&#x2F;angry-pumpkins&#x2F;index.html (it&#x27;s in the second tweet) reply gardenhedge 18 hours agorootparentOh, I don&#x27;t have a twitter account so only see the linked tweet reply GaggiX 16 hours agorootparentI used the nitter link someone linked in the HN comment section. replyphkahler 19 hours agoparentprevBut have you seen most programmer art? This has really nice graphics too. reply xwdv 19 hours agorootparentSome people are really good at art, some aren’t.Regardless, I can pull down some off the shelf assets from an asset store and make a game with them. reply GaggiX 18 hours agorootparentI doubt the asset store has a pumpkin in the style of Angry Birds that looks like Red, it doesn&#x27;t seem a good alternative if he wanted to create this game. reply gowld 18 hours agorootparentprevWhere are the off-the-shelf Halloween-theme Angry Birds-style sprites?Where are the ones that look different from the ones 50 other game makers used?I don&#x27;t know, and now I don&#x27;t need to care. reply pphysch 19 hours agoparentprevYeah the killer feature here is being able to generate premium-looking game assets without any art team or funding. That&#x27;s always been the tough part of creating even simple games for solo programmers. The rest is whatever. reply Veuxdo 19 hours agoparentprevAnd, most importantly, marketing. reply gardenhedge 18 hours agoparentprevAgree. No menus or anything reply gowld 19 hours agoparentprevDoes 24 hours include learning how to use a game engine that you&#x27;ve never used before? When you&#x27;ve never used ANY game enginer before?Maintenance and new features are more of the same already done. Networking code is a library. Sound is a library. Cross-platform is a library. Shaders are a library. AI fixed bugs. reply product-render 17 hours agoprevAlways instructional how eager a lot of people are to not pay artists.I&#x27;m guessing the mood will be less celebratory when we can stop paying most programmers. reply alright2565 16 hours agoparentThis article is about replacing programmers with AI.I, personally, will celebrate, since it&#x27;ll allow me to explore opportunities I would not have time for on my own. And I&#x27;m not worried for my career, since 99% of people will still be unable to think and write coherently enough to use the AI tools.And I think the reality here is not so much being unwilling to pay artists as the budget being extremely low. If I&#x27;ve got an art budget of $10 for a quick experiment like this, I&#x27;m not going to hire an artist, I&#x27;m just going to use the circle tool in GIMP. reply tw061023 7 hours agorootparentThis article is about precisely nothing, as almost all AI articles are.By the way, I have a nice bridge for sale. reply vunderba 15 hours agoparentprevDid you read the actual post? They use generative AI to replace both programmers AND artists. And if anything programmers have been at risk of replacement FAR longer than traditional artists. Low code solutions in the form of Squarespace for web programming, AirTable for CRUD, Unity for making games, the list goes ON AND ON. reply somsak2 15 hours agoparentprevIt&#x27;s interesting how most don&#x27;t consider programmers artists, even though coding requires quite a bit of creativity. reply bigfishrunning 20 hours agoprev [–] So AI made a cheap copy of something people made...Can it do anything else? reply solardev 20 hours agoparentIt&#x27;s apparently pretty good at annoying people on HN who like to downplay its every achievement reply WoodenChair 18 hours agorootparent> It&#x27;s apparently pretty good at annoying people on HN who like to downplay its every achievementIt&#x27;s not really \"its\" achievement. There are many open source repositories of Flappy Bird that it was trained on and there are many brilliant engineers at Google and OpenAI who have worked on LLM technology. It is their achievement if anything. It is a product. A product of others&#x27; achievement. You don&#x27;t say Excel had an achievement when it calculates a good formula for you? Do you say a neural network that produces great speech to text had an achievement? Or do say the people who developed it did. reply ben_w 1 hour agorootparentWe have exactly the same argument on a regular basis about whether or not we should say Musk is responsible for the success of Tesla; likewise with attributing the achievements of the USA[0] (or even just the government of the USA[0]) to the specific president of the time rather than to the nation as a whole.And before Musk was born, similar debates about describing Armstrong as the first man on the moon, given how even saying that inherently brushes aside the contributions of all those who worked on the mission without going to space.[0] In the UK it seems to be half on the Prime Minister and half the party of the age; I don&#x27;t pay enough attention to the local opinion of politics elsewhere, though I will say the British press seems to blame everything Germany does on the German Chancellor personally… reply og_kalu 18 hours agorootparentprev>Do you say a neural network that produces great speech to text had an achievement? Or do say the people who developed it did.Sure Why not? The engineers at google and open ai or wherever else trained the models but they didn&#x27;t teach it how to do anything it does because they don&#x27;t know how to teach it to do anything it does. So yeah the achievement is on the neural network.Many people gave the likes of alpha go achievement on super human Go play. reply throw555chip 17 hours agorootparent> So yeah the achievement is on the neural network.It is? OK, tell them to completely clear the model of any angry bird original and clone code, data and assets that it scarfed from the Internet.It can retain scarfed definitions of angry and bird as well as scarfed information on making a 2D video game.Then tell the model to create the game and see what if anything it comes up with. reply simonw 17 hours agorootparentIn terms of the code, I don&#x27;t think it would be hard to create an Angry Bird clone of this quality using a GPT-4 scale model that had somehow had all knowledge of Angry Birds excluded from it.Most of the Angry Birds mechanics in this demo come from the underlying Matter 2D library. Relevant demo here: https:&#x2F;&#x2F;brm.io&#x2F;matter-js&#x2F;demo&#x2F;#slingshotHonestly, that&#x27;s most of the code part accounted for.The bigger question is the graphical assets. The developer shared their prompts for those here: https:&#x2F;&#x2F;twitter.com&#x2F;javilopen&#x2F;status&#x2F;1719363587351740711Some of them make no mention of Angry Birds - \"Wooden box. Large skeleton bone. Item assets sprites. White background. In-game sprites\" - but others do: \"Item assets sprites. Wooden planks. White background. In-game sprites. Similar to Angry Birds style\"My hunch is that a skilled image prompter could still get to results that were right for this particular demo even with a model that had not seen Angry Birds assets before. reply tw061023 7 hours agorootparentprevWhich, precisely, achievement?Show all prompts step-by-step and let people reproduce.Someone claims they did X using a couple of AI instruments, without sharing anything to prove the claim, and everyone is excited. I understand that the industry needs a new hype to keep going, but this is just pathetic. reply GaggiX 7 hours agorootparent>Show all prompts step-by-step and let people reproduce.Read beyond the first tweet. reply tw061023 7 hours agorootparentI see six tweets in the thread, how many do you see?If you also see six tweets, please reproduce the result following instructions in the tweets and share the recording of you doing so.Graphics don&#x27;t matter, let sprites be colored rectangles. reply GaggiX 6 hours agorootparent>Graphics don&#x27;t matter, let sprites be colored rectangles.Why? Are the sprites and backgrounds too easy to recreate with MJ and Dall-e after you realized that the author actually provided the prompts for them? replytw061023 7 hours agoparentprevExcept it didn&#x27;t. reply breakfastduck 19 hours agoparentprev [–] Come on... I&#x27;m fairly cynical when it comes to AI but someone building a pretty complete game from scratch entirely using AI to generate the code and assets is a little beyond it &#x27;making a cheap copy of something else&#x27;. reply bluescrn 5 hours agorootparentIf you fed a competent human massive quantities of human-created code and artwork, they could fairly quickly mash it up and produce a clone of a simple game, too.Have we created real AI, or merely &#x27;AP&#x27; - Auto-Plagiarism? reply raytopia 19 hours agorootparentprev [–] I mean while impressive all the art assets were very clearly knockoffs of Angry Bird&#x27;s art. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "User Javi Lopez has developed a project named \"Angry Pumpkins 🎃\" through AI technologies.",
      "GPT-4, an advanced AI model for coding, was utilized in the project's development.",
      "The graphics for the project were created using Midjourney/DALL-E, an AI model for generating images."
    ],
    "commentSummary": [
      "The discussion revolves around the use of AI, particularly OpenAI's ChatGPT, in tasks like game development, web design, and code generation, highlighting contrasting opinions about its efficiency and reliability.",
      "While some developers applaud AI for enabling rapid prototyping and fostering creativity, others voice concerns about potential inaccuracies and the need for substantial programming skills.",
      "Issues raised include AI's possible implications on job displacement, the production of unoriginal content, and exacerbation of low-quality content, suggesting that this promising technology still requires ongoing refinement and judicious management."
    ],
    "points": 549,
    "commentCount": 263,
    "retryCount": 0,
    "time": 1698776835
  },
  {
    "id": 38094620,
    "title": "uBlock Origin 1.53",
    "originLink": "https://github.com/gorhill/uBlock/releases/tag/1.53.0",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up gorhill / uBlock Public Notifications Fork 2.9k Star 39k Code Issues 13 Pull requests 1 Actions Projects Wiki Security Insights Releases 1.53.0 1.53.0 Latest Compare github-actions released this 1.53.0 6fb8639 Commits to master since this release Commits since last release To install the stable build: Firefox: Review pending uBO works best on Firefox. Chromium: Submission pending Edge: Install from Microsoft Store: https://microsoftedge.microsoft.com/addons/detail/odfafepnkmbhccpbejgmiehpchacaeak The Microsoft Store version of uBO is published by Nicole Rolls Opera: Submission pending Fixes / changes Add additional set-cookie names (by @ryanbr) Improve google-ima shim script (by @kzar) Match type exactly in prevent-addEventListener scriptlet Add filtering expressions for logger output Add warning against adding custom filters from untrusted sources Consider My filters an untrusted source by default Add trusted-prune-inbound-object scriptlet Add dontOverwrite vararg to (trusted-)set-cookie scriptlets Add \"on\" and \"off\" values to set-cookie (by @peace2000) Fine tune set-local-storage-item as per feedback Support AdGuard's [trusted-]set-cookie-reload scriptlets Ignore assets older than cached version when fetching from CDNs Support quoting scriptlet parameters with backticks Add new static network filter option: urltransform Support pane: mark lists as obsolete only when update button is clicked Bring header= filter option out of experimental status Add trusted-click-element scriptlet Add ability to update lists through links with specifically crafted URLs Fix overzealous matching in (remove|replace)-node-text scriptlets Fix no-xhr-if scriptlet for Firefox Support restoring from application/json file Use safe versions of Math.floor/Math.random in scriptlets Improve google-ima.js surrogate Add stackToMatch vararg to json-prune-related scriptlets Reduce race conditions in scriptlet injection on Firefox Add scriptlet aliases for compatibility with AdGuard lists Remove unmaintained urlhaus PUP filter list Use AG version of urlhaus list Minor code review of scriptlets Contributors kzar, ryanbr, and peace2000 Assets 6 👍 14 🎉 3 ❤ 7 🚀 10 20 people reacted Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=38094620",
    "commentBody": "uBlock Origin 1.53Hacker NewspastloginuBlock Origin 1.53 (github.com/gorhill) 429 points by archo 10 hours ago| hidepastfavorite222 comments codeflo 8 hours agoFrom the “uBO works best in Firefox” page, I found this gem:> Firefox will wait for uBO to be ready before sending network requests from already opened tab(s) at browser launch.> In Chromium-based browsers, this is not the case. Tracker&#x2F;advertisement payloads may find their way into already opened tabs before uBO is ready, while Firefox will properly filter these.That’s a hell of a “bug” in Chromium, that blocker initialization has a race condition with restoring the last opened tabs. What a weird little “accident” that Chromium just moves forward and loads all the trackers, “oopsie”. I wonder which kind of promotion the engineer who made that “mistake” has been awarded. reply Justsignedup 4 hours agoparentAd nauseum solves this. Sure you get tracked but you also send all the wrong signals. reply gustavus 1 minute agorootparentI&#x27;ll give a warning with that, the traffic generated by adnausem starts to get cloudflare suspicious and then you end up having 1&#x2F;2 of the internet made inaccessible because Cloudflare decided at some point you are a bad actor and you&#x27;re pretty much hosed from that point on. reply malka 4 hours agorootparentprevAd nauseam is \"weirdly\" banned from the chrome store. Guess it hurts them :) reply kitkat_new 1 hour agorootparentEspecially, because it clicks ads without you seeing them reply Condition1952 3 hours agorootparentprevCan’t you sideload applications like a hacker? reply throitallaway 42 minutes agorootparentOur computing landscape has deteriorated if installing an application&#x2F;extension outside of a walled garden makes you a \"hacker.\" reply qwertox 3 hours agoparentprevThanks. Good to know. Solidifies my belief that additionally using Pi-Hole can only improve things. reply freedomben 6 minutes agorootparentFor now, hopefully DoH&#x2F;DoT isn&#x27;t forced upon us reply vietvu 8 hours agoparentprevAnti ad block feature, not a bug I guess. reply zx8080 8 hours agoparentprevI would expect nothing less than an immediate promotion to the next title. So cool. reply leloctai 7 hours agoparentprevWhich is a horrible design on Android. Firefox on my (admittedly relatively old) phone take 20s to load the first page when browser start with uBlock enabled. On desktop this is fine as it only happen once a day. But on the phone it happen a lot since apps getting killed is a normal thing. reply Sayrus 6 hours agorootparentI have the same issue with UBlock Origin since my phone is quite aggressive when killing apps. While it is indeed annoying, I don&#x27;t think it&#x27;s a bad design.Maybe it&#x27;s lacking a setting to toggle this (Suspend all network until lists are loaded doesn&#x27;t control this behavior), but I wouldn&#x27;t want to load pages full of ads on mobile simply because the app got killed.The real issue for me is my phone killing applications when it has both battery and memory available. reply cbarrick 2 hours agorootparentprevChrome desktop since v110 has started killing background tabs and reloading them upon use. [1]Lately, I&#x27;ve noticed Chrome being really aggressive about this.[1]: https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;02&#x2F;chrome-110-will-auto... reply Goz3rr 1 hour agorootparentI&#x27;m on the regular stable Chrome build and was explicitly asked on several devices over the last few months if I wanted to enable memory saver or not, it wasn&#x27;t automatic for me at least. reply danielbln 7 hours agorootparentprevMy 4 year old S10E does not exhibit this behavior at all (Firefox with uBlock). reply erremerre 6 hours agorootparentS10e was the peak of mobile design. reply nullandvoid 1 hour agorootparentI feel the same about my s7 edge I keep as a spare, although currently using the s21 ultra and no complaints reply danielbln 6 hours agorootparentprevPreach! I&#x27;m holding onto it for dear life, perfect form factor, no BS. reply plussed_reader 1 hour agorootparentI could&#x27;ve done without the useless Samsung button that doesn&#x27;t do anything but whine for a Samsung account before you can change the behavior of the button. So I used adb to disable the button entirely, to prevent the whiny Samsung page from accidentally being pressed on the button raised off the left side of the s10e. reply fuzztester 3 hours agorootparentprevWhy was it that? reply leloctai 4 hours agorootparentprevDo you mind sharing your ubo settings? reply danielbln 4 hours agorootparentWhatever the defaults are after installation, I didn&#x27;t adjust the settings at all. reply boudin 5 hours agorootparentprevAnd my 7 years old oneplus 3T neither reply leloctai 4 hours agorootparentDo you mind sharing your ubo settings? reply boudin 4 hours agorootparentJust the default one plus french list in regional settings. To be fair though, I had a tablet from the same time but it was way cheaper than this phone, specifically having way less ram and firefox was not really usable. reply Sander_Marechal 5 hours agorootparentprevIIRC there&#x27;s a setting for that in UBo (look for pre-fetching) reply leloctai 4 hours agorootparentI&#x27;m already allowing prefetching reply LegitShady 6 hours agorootparentprevI don&#x27;t get this behaviour on Firefox in Android at all. reply leloctai 4 hours agorootparentDo you mind sharing your ubo settings? reply Moldoteck 6 hours agorootparentprevi&#x27;m pretty sure there&#x27;s an setting&#x2F;option to disable battery optimization for firefox reply leloctai 4 hours agorootparentIn fact there are multiple switches you have to turn, however I&#x27;ve made sure to check all of them. reply seethedeaduu 5 hours agoparentprevI have experienced this on firefox as well but it is rare and don&#x27;t know of a way to reproduce it. reply Sander_Marechal 5 hours agorootparentAre you sure you don&#x27;t have the option to wait turned off in the UBo settings? reply RileyJames 4 hours agoparentprevI thought chromium was open source? reply neurostimulant 4 hours agorootparentIf this \"feature\" is intentional, then even though it&#x27;s open source, your patch to fix the behavior may not be accepted. reply harry_ord 4 hours agorootparentprevShooting from the hip, here but part of it is. Other parts are closed source from Google or some other group that doesn&#x27;t share. reply rs_rs_rs_rs_rs 6 hours agoparentprev> What a weird little “accident” that Chromium just moves forward and loads all the trackers, “oopsie”. I wonder which kind of promotion the engineer who made that “mistake” has been awarded.This \"bug\" is in Safari&#x2F;Webkit too, stop it with the conspiracy theory. reply kibwen 3 hours agorootparentYou realize that Apple is ad company too, right? Just like every other shitty tech company these days. Apple generated $5 billion in ad revenue in 2022. reply bluish29 2 hours agorootparentFrom the app store ads mainly. Omitting this fact is dishonest at best. reply freedomben 4 minutes agorootparentHow much was from outside the app store? reply SmarsJerry 12 minutes agorootparentprevI think they are requiring apps on their store use ads provided by their store as well though. reply Already__Taken 8 hours agoparentprevThat&#x27;s not a bug IMO I want Chrome to be as fast as possible and especially not to wait for 3rd party calls. This is a design compromise not malicious. FF themselves have complained many of their bug reports and complaints are generated by plugins and directed at Firefox. reply throwaway141455 8 hours agorootparent\"I want my browser to load ads as fast as possible\" is an interesting take reply haunter 7 hours agorootparentWhy did you make a new account just for this comment? reply skrebbel 7 hours agorootparentSome people have a weird habit of creating a throwaway account for every comment they make, no matter how mundane. I’m not sure what the rationale is, something privacy-ish i guess? reply Condition1952 3 hours agorootparentI like destroying accounts from time to time. Prevents becoming attached, identifying you with your comments, flushes your permanent record, etc.Besides, it’s a pain in the ass and you might get banned so you end up working fewer hours for the website.People with careers are getting cancelled because of their opinions published online. Nudging people to identify themselves online is inviting them to dig a grave reply ploum 4 hours agorootparentprevcould it be automated? reply andyjohnson0 4 hours agorootparentprevIt&#x27;s possible that they work for an ad company, or aspire to do so, or work in a business where saying anything even mildly disparaging about adtech could be problematic. reply chii 8 hours agorootparentprevwhich is why uBO has the option to delay, but also to disable this delay (which relies on firefox enabling the capability to make a choice). Why can&#x27;t chrome also let the plugin (and by proxy, the end user) decide? reply cookiengineer 7 hours agorootparentprevNot wait for third party calls, but wait for third party calls from _remote_ third party websites?Your logic is utterly flawed. reply formerly_proven 7 hours agorootparentOn the cosmological scale, it&#x27;s all nearby. reply arpanetus 7 hours agorootparentprevIf you want your Chrome to be as fast as possible, you would get rid of all extensions you have. It doesn&#x27;t matter even if it&#x27;s an adblock atp.Hence calling it a feature, not a bug is rather misleading. Since you went and installed plugins understanding that it might and it will affect your workflow. reply tyingq 5 hours agorootparent> It doesn&#x27;t matter even if it&#x27;s an adblock atpPre-manifest V3, when OnBeforeRequest actually blocked requests before they were downloaded, browsing typical sites with it enabled was objectively faster than with it off. Any overhead was pretty quickly recovered in not downloading the ads.Many benchmarks proved that. Here&#x27;s one: https:&#x2F;&#x2F;whatsoftware.com&#x2F;10-ad-blocking-extensions-tested-fo...So, unless you&#x27;re browsing exclusively all ad-free sites, it very much DOES matter, or used to. reply hackideiomat 5 hours agorootparentprevUsually, ad blockers will dramatically improve a websites performance reply LightHugger 4 hours agorootparentprevwaiting for ublock improves website performance. there is no design compromise. reply flakes 10 hours agoprevI&#x27;ve been using uBlock since shortly after it launched, and I&#x27;d rather lose access to all Google services than not have an ad blocker. I seriously question how people use a browser without one. Completely changes how the web feels. reply soultrees 9 hours agoparentIt’s crazy. Even with an adblocker you are subjected to a crazy amount of ads or hostile design. With ads, it’s just a free for all on your attention. reply reactordev 8 hours agorootparentand for your cpu. Ads are the number one killer of performance. reply squarefoot 8 hours agorootparentAnd money. Metered connections do exist, and ads consume a lot of bandwidth which is not free. reply chakintosh 4 hours agorootparentThe cognitive load is the worst part of ads for me. The amounts of ads that display an X to close the banner only for that X to be an actual link to another fkn ad or straight up opens a new tab. Not to mention the invisible divs spanning the entire page so wherever you click, it&#x27;s gonna open a link which is most of time either porn, betting sites or aliexpress. This sh* should be illegal. reply specialist 3 hours agorootparentYup. They&#x27;re pollution. (There&#x27;s gotta be a phrase for \"cognitive load\" + \"pollution\".)I used to love tech ads. I&#x27;d inspect every ad in BYTE, Creative Computing, etc. I&#x27;d even buy Computer Shopper, a massive catalog interrupted by some articles, just for the ads.Ads can be useful, informative, and engaging. I wouldn&#x27;t mind that. reply epgui 48 minutes agorootparentI like the term “information pollution”. reply RachelF 8 hours agorootparentprevI wonder what the CO2 emissions of all these ads are? reply e2le 2 hours agorootparenthttps:&#x2F;&#x2F;www.mdpi.com&#x2F;2227-7080&#x2F;8&#x2F;2&#x2F;18Although this study doesn&#x27;t discuss C02 emissions, it does discuss energy use and the potential impact of internet advertising.Unfortunately, it only discusses the impact on client-side devices, the energy consumption of hardware used to serve advertisements (networking, servers) is left to a future study.>Strikingly, uBlock Origin has the potential to save the average global Internet user more than 100 h annually.>So, for example, the 1.35 × 1010 kWh saved globally for using uBlock Origin is equivalent to more than 1.0% of the electricity generated per year from coal in the United States, which is responsible for the premature deaths of about 52,000 American every year from air pollution [43,44].>Globally, the results with the most efficient open source ad blocker tested, uBlock Origin, would be even more substantial: ad blocking would save consumers more than $1.8 billion&#x2F;year. reply titaniumtown 1 hour agorootparentWow, that is a mind-blowing figure. $1.8 billion&#x2F;year and 100 h annually. Would&#x27;ve never expected the figure to be that large. reply TheRealDunkirk 2 hours agorootparentprevSo many people so concerned about CO2 emissions from computing devices... all the way down to Microsoft setting the default timeout for Bluetooth on Windows 11 to ONE MINUTE. It took me 2 weeks of hair pulling and updating everything before I realized why my mouse and keyboard would stop working, because it NEVER occurred to me in my WILDEST dreams that an OS developer would be given the insane task of creating a timeout like this, and writing a UI to control it. Then I realized that some middle manager in the guts of Microsoft probably got a bonus by being able to tell his management that \"Microsoft\" was now saving a collective million pennies a year of energy costs by crippling this basic feature. Well done, guys.Where&#x27;s the outrage from the colossal carbon footprint of the overarching, advertising-based economy? Does anyone have any idea what the electrical costs or carbon footprint per dollar of ad revenue is? It surely must be one of the lowest returns per environmental impact in the entire spectrum of capitalism. Sure, complain about cryptocurrency \"setting the earth on fire,\" but Google gets a free pass for much the same thing to make their trillions? reply unreal6 1 hour agorootparentOr, for that matter, any incremental call Microsoft is making to any GPT-based model. The power consumption from these inferences are immense, and appearing everywhere in their interfaces. reply unreal6 1 hour agorootparentprevOr, for that matter, any incremental call Microsoft is making to any GPT-based model. The power consumption from these inferences are immense, and appearing with increased frequency. reply iamacyborg 8 hours agorootparentprevA lot, given the sheer number of network requests a single ad can spawn reply gruez 7 hours agorootparent\"A lot\", compared to what? A single household? Probably. As a percentage of overall global electricity consumption? Probably negligible.Some math with conservative estimates:* power consumption of mobile processor: 5W* daily ad use: 1 hour (assume it&#x27;s 100% cpu for the entire time)* smartphone users: 7.8 billion (world population)Total yearly electricity consumption given the above: 2.8 TWhWorld electricity consumption: 23,921 TWh in 2019 reply wasmitnetzen 6 hours agorootparentYou&#x27;d have to include the servers doing the auctions, sentiment analysis, profiling,... into it as well. And then the whole ad industry, every email, every meeting, ...I don&#x27;t think you can actually put a number on this waste. reply gruez 5 hours agorootparent>You&#x27;d have to include the servers doing the auctions, sentiment analysis, profiling,... into it as well.Feel free to put up an estimate then.>I don&#x27;t think you can actually put a number on this waste.Well that just makes it clear you&#x27;re only interested in your feelings&#x2F;vibes as opposed to anything objective. reply ploum 4 hours agorootparentYou have to include the fact that the very clear objective of advertising is to make you consume more. Thus producing more pollution than if there were no ads.So, even if advertising was technically neutral (which is clearly not the case), it would still be an ecological cataclysm.One would even argue that the whole climate emergency is created by our advertise&#x2F;consume culture. reply reactordev 4 hours agorootparentcareful now, you can&#x27;t make cents without advertising dollars. (pun) reply _Algernon_ 4 hours agorootparentprev>Well that just makes it clear you&#x27;re only interested in your feelings&#x2F;vibes as opposed to anything objective.Pulling an \"estimate\" out of your ass isn&#x27;t exactly any more objective than admitting that attempting to estimate it is futile.\"I know that I know nothing\" and all that. reply eru 4 hours agorootparentprev> I don&#x27;t think you can actually put a number on this waste.To give a really simple upper limit: 36.8 billion tonnes per year. Because that&#x27;s the current total global CO2 emissions per year. And we can be pretty sure that ads are less than that, or at least not more.I agree with your assessment of the grandparent comment. replyall2 10 hours agoparentprevThis. I&#x27;ve pretty much stopped using YouTube since the adblocker blocker shut me out.I figure it&#x27;s a good time to kick a bad habit. :D reply beej71 10 hours agorootparentI&#x27;m trying Grayjay, which works great, and I&#x27;ve noticed one big thing: it doesn&#x27;t keep showing me an endless stream of stuff to keep me on the site. It just shows my subs and a handful of suggestions.As a consequence, my time spent on the site is way down, and the time I do spend is higher quality material.But I&#x27;m with you. There&#x27;s no way I&#x27;m watching an ad on YT. If they figure out how to only stream with unblockable ads, I will never visit the site again.Patreon to pay the creators. reply WithinReason 7 hours agorootparentI think Grayjay is a great idea. Many creators have alternate accounts on platfroms like Odyssey (e.g. Hardware Unboxed and Veritasium), in those cases you can subscribe to the non-youtube platform. If enough people do this, it might help us move away from youtube. Of course the last step is also important for this to work (Pay the creators.) reply p1nkpineapple 3 hours agorootparentprev> As a consequence, my time spent on the site is way down, and the time I do spend is higher quality material.For me, I&#x27;ve found DeArrow (clickbait \"blocker\") has had exactly the same effect. I find myself no longer mindlessly scrolling through the suggested feed and am more particular about what I choose to watch. reply mopenstein 4 hours agorootparentprev>If they figure out how to only stream with unblockable ads, I will never visit the site againThat&#x27;s their goal. If you&#x27;re not earning them money, they don&#x27;t want you. You don&#x27;t exist to them and you not watching their ads&#x2F;videos is no threat at all. reply Tao3300 3 hours agorootparentIt&#x27;s a win-win! reply fuzztester 2 hours agorootparentprevWhat does Grayjay do? Is it some kind of aggregator? reply TerrifiedMouse 10 hours agorootparentprevSame. I only visit when someone links to a video or I absolutely have to to get information.Used to visit YouTube’s front page as part of my daily routine, effectively using it as a social media site - which it definitely is; it’s just that the posts are all videos, the comment section is like every other but moderated by the video poster, and the front page is completely algorithm driven. reply flakes 9 hours agorootparentOne thing which seriously improves my experience is using the \"Block element\" feature on non-ads as well. Suggested videos, youtube shorts, banners, etc, all get blocked. Leaves the site much more lean and leaves less distracting visual clutter.I use this strategy on a lot of sites (which sadly includes stackoverflow lately). reply fuzztester 2 hours agorootparentHow do you use the Block element feature? I looked in the uBO menu but cannot find how to do it. Can you give an overview, please? reply flakes 1 hour agorootparentWhen you right-click an element on the page (and you have uBlock installed at default settings) there should be a dialog for it at the bottom. reply bonton89 1 hour agorootparentprevIf I right click on an item I get a block element option in the context menu. But that doesn&#x27;t seem to make them persist. I usually use it to make irritating popups go away that I&#x27;m to lazy to read or that seem intentionally confusing since it is less mental load to just zap it blindly. reply lkuty 9 hours agorootparentprevYou might wanna use Unhook. reply flakes 9 hours agorootparentPotentially, for now I can get away with my custom filter list :)I generally try to limit the total amount of extensions I have on my browser, to a list of tools I feel that I can trust. I apply the same mentality for dependencies in my software. Limits the surface area for supply chain attacks. reply Daviey 7 hours agorootparentprevOddly, I had the soft warning first.. then 3 views until blocked warning... and now, nothing. Working like it did before. Strange. I don&#x27;t feel relaxed yet, but it seems they back-off if you hold-out, for now. reply flohofwoe 5 hours agorootparentIt&#x27;s randomly on and off for me since a couple of weeks. reply jenadine 9 hours agorootparentprevI&#x27;m not seeing any YouTube adds. I&#x27;m using ublock origin with firefox and didn&#x27;t do anything special. What YouTube adds are everyone talking about? reply swanee 9 hours agorootparentThey have been rolling out ad-blocker detection with warning popups telling you to disable it. Mine were skippable the first few times but that lead to a final 3 warnings with the player refusing to load after. They seem to be doing a lot of A&#x2F;B testing with the system currently. reply gonzo41 8 hours agorootparentTurn off Ublock, reload the page, then turn it back on. Usually solves the problem for me. reply lodovic 7 hours agorootparentprevyou can block the detection popup itself with uBlock. Seems to have done the trick for me. reply eikaramba 3 hours agorootparentNo don&#x27;t do that. And stop spreading misinformation. There is a thread on Reddit explaining why this is absolutely stupid and will only result in you losing access to YouTube. Or do you really think YouTubes for works like this.The biggest problem currently are people spreading those types of misinformation see https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;uBlockOrigin&#x2F;comments&#x2F;17j6ygs&#x2F;youtu... reply jksflkjl3jk3 29 minutes agorootparentHow would one lose access? Is Youtube blocking IP addresses? Fingerprinting browsers in a way that Firefox&#x27;s ResistFingerprinting setting doesn&#x27;t handle? reply master-lincoln 3 hours agorootparentprevHow is that misinformation? The site you linked even says it works, just not for long an maybe with negative side effects:> I was able to hide the popup simply by blocking it with uBO&#x27;s Picker. Why aren&#x27;t you doing that?> This only works temporarily. For stages 1-3. You&#x27;re still reach stage 4 by doing this. And this might cause scrolling issues and not let videos autoplay.Maybe you should stop using words as \"absolutely stupid\" because it makes you look like a snob, and when it turns out you were wrong, it makes you look like a fool. reply flakes 9 hours agorootparentprevSeems to be not hitting every user the same way. I also did not have any direct message about ad blockers, but I did notice videos not loading correctly and requiring a page refresh to work. Updating uBlock seemed to fix that issue. It was only afterwards that I heard of others having problems. reply erremerre 6 hours agorootparentprevIn my experience, it ahs not been hitting super users. But somehow they have been targeting people with adblock installed by someone else.My parents both have been targeted and had to instruct them on how to refresh the quick updates, which has not been easy. reply d3vmax 7 hours agorootparentprevI still use adblocker on everything else and I know YT without adblock &#x2F; premium is terrible.However, YT premium is only 2-3 USD&#x2F;mo in India. So, I use that to get ad-free experience on YT and also YT music is great. reply wintermutestwin 1 hour agorootparentYou are now \"paying\" google twice - once with money and twice by giving them your data. reply benhurmarcel 26 minutes agorootparentYour data is worthless if they can’t use it to show you targeted ads. reply alkonaut 5 hours agorootparentprevI still don&#x27;t understand how ad blocking in videos can work. I mean all it would take to force users to watch the ads is to ensure that after the ad starts streaming, you can&#x27;t request any frame of the actual content until N seconds (The full ad length) later? reply trumpeta 5 hours agorootparentI&#x27;d still rather stare at a blank screen for 20s than view the ads. reply alkonaut 5 hours agorootparentSure, but that doesn&#x27;t sound like something people would install an ad blocker to achieve... reply eru 4 hours agorootparentI often open videos in the background, and watch them later. So this would work perfectly well here. reply jillesvangurp 6 hours agorootparentprevublock works perfectly for me on Youtube. I never see ads there. Plenty of sponsored videos but no ads. I use Firefox; that might be the difference. reply ekianjo 5 hours agorootparentdoes not work if you are logged in reply Phelinofist 5 hours agorootparentIt does, you just have to purge and then update the filter rules reply zdhgbdthdtv 4 hours agorootparentYou are just being lucky. Youtube have been rolling out new adblock filtering globally for the last few weeks.See https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;10&#x2F;31&#x2F;23940583&#x2F;youtube-ad-bloc... reply pcdoodle 4 hours agorootparentprevThis works for me too having my youtube account logged in.Steps: click the U icon, click the gear, click filter list, click Purge, click Update.Ads are gone again while logged in. You might have to do it again every now and then. reply jillesvangurp 5 hours agorootparentprevI am logged in. reply PeterStuer 8 hours agorootparentprevTo be fair Youtube has to make a profit somehow. Ad revenue, direct and&#x2F;or through profile data collection is easy and effective but the worst businessmodel for human sanity.I like that they at least offer an alternative for the ad viewing part through Youtube premium. I don&#x27;t know about the US as streaming services seem to have catalogues orders of magnitude more extensive than over here in Europe, but compared to the likes of Prime Video, Netflix, Apple TV+, Disney+ and several local offerings, YT Premium is a steal in terms of value proposition.And like most here I fail to understand how anyone can stand YT with ads.You wiil seriously start to dislike the podcasts for speaking in video ads though. reply hellotheretoday 8 hours agorootparentYouTube premium pricing is ridiculous. $14 a month for android and $19 a month for iOS? Get out of hereHow much could they possibly make from ads in a given month off a single user. Best case scenario with a user that watches YouTube like 4 hours a day 6 days a week and clicks through once every week. $4? Probably not even that. And yet somehow YouTube premium needs to be almost $230 a year for apple users?I bet they’d make way more with a lower premium tier that just removed ads and had no other premium features for like $20&#x2F;year. Wouldn’t make as much obviously but I bet they’d do way more volume. I wonder if they have some dipshit mba arguing against something like this because it “makes them seem cheap” or “delegitimizes the platform against more traditional streaming networks” or some nonsense to justify charging Hulu prices for YouTube content reply chx 6 hours agorootparentEspecially when you consider you could VPN to Turkey and get it for 1.15 USD a month, if you do it for five people then it&#x27;s 0.46 USD per Youtube Premium account. https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;VPN&#x2F;comments&#x2F;14mwf6h&#x2F;how_to_enjoy_y... reply Tao3300 3 hours agorootparentprevFWIW we would hate them less too. reply avereveard 7 hours agorootparentprevWell I use to have them on whitelist for all these reason, but a) lately the amount of ads has gotten crazy and b) a large amount of videos are fraudulently copyright striken and revenue stolen from creators https:&#x2F;&#x2F;www.streemtunes.com&#x2F;post&#x2F;how-did-pewdiepie-get-a-cop...I think it&#x27;s egregious how YouTube treats content creators in general and how expect us to foot the content distribution bills in particular, especially since many of the video themselves are ads (they include product placement, or are straight up teasers for products)I think there&#x27;s a case to be made at least for non indies to pay proportionally to the minute viewed of their content, to decrease the pressure on monetizing indies. reply Tao3300 3 hours agorootparent(b) is totally ridiculous. Anyone who isn&#x27;t helping bleed YouTube to death is ultimately hurting creators and keeping them locked into an abusive platform. reply malka 4 hours agorootparentprev> To be fair Youtube has to make a profit somehowIf they were not Google, I&#x27;d be ready to pay about 10 euro&#x2F;m.Since it&#x27;s Google, they can rot in hell for all I care. I&#x27;ll happily freeload them as most as I can. reply ekianjo 5 hours agorootparentprev> To be fair Youtube has to make a profit somehow.I don&#x27;t care, I still won&#x27;t watch ads, and if I pay for something, I want to pay for something for that does actively track my watching habits and sell my data, so they are out of luck. reply epgui 31 minutes agorootparentI think you’re missing a “not” somewhere in there… reply wintermutestwin 1 hour agorootparentprev>To be fair Youtube has to make a profit somehow.I&#x27;d gladly pay for Youtube sans ads, but not if google also gets to steal my data. reply 0xedb 8 hours agorootparentprevYouTube Premium isn&#x27;t available worldwide. reply leosanchez 9 hours agorootparentprevCan&#x27;t you copy the url and open in incognito?If you are using Firefox you can open it in a container that is not logged into YouTube no ? reply all2 8 hours agorootparentI did that a little. The friction is irritating and enough for me to walk away from the computer after only a few videos. It was just enough to break me from my normal veg and consooooom cycle. reply leosanchez 1 hour agorootparentFair enough. reply hackideiomat 5 hours agorootparentprevI have been using invidious for a while and apart from having to switch instances every few months, it&#x27;s been a pleasure reply pests 8 hours agorootparentprevI&#x27;ve gotten so much value out of YouTube over the last 15 years, I added an exception for them.Maybe YouTube isn&#x27;t the bad habit, but how (metaphorical) you use it? reply globular-toast 7 hours agorootparentprevSame. I have accidentally clicked links a few times and, interestingly, I haven&#x27;t seen the anti adblock message again despite not updating the uBlock filters.For the information that only seems to be available on YouTube I use Invidious. reply Kate0CoolLibby 9 hours agoparentprevA few years now since I have given up on (most) of Google&#x27;s services. YouTube via Newpipe is the only exception I can think of.But if it came between choosing between uBlock and anything? I choose uBlock! reply Liquix 9 hours agorootparentSame. But IMHO Google would be fine with this. They aren&#x27;t in the business of giving out CPU time and bandwidth for free – your data must be catalogued and correlated and sold to keep YouTube viable.What do they gain from the 5-10% of users consuming videos but offering no salable data in return? It&#x27;s a direct hit to the bottom line from a minority who would rather stop using the service than be converted to impressions. Good riddance reply TerrifiedMouse 9 hours agorootparentYouTube isn’t just a video sharing site though. It’s a social media site. There is value in people participating by replying and Liking&#x2F;Disliking.Frankly, banning ad-blockers feels like treating the symptoms rather than the cause. There is something wrong with your platform if people hate your ads so much that if they can’t block them they would rather not visit your site at all. reply master-lincoln 3 hours agorootparentYoutube is an ad showing platform. All the other features are just there to get people to view ads. If you stop viewing ads you are of no value to Youtube. reply wintermutestwin 1 hour agorootparentprevYour point and attitude would be applicable if YouTube wasn&#x27;t a de facto monopoly due to the network effect and the Goog throwing their warchest around, effectively eliminating any semblance of a \"free market.\" Meanwhile this monopolistic site is the only repository of massive amounts of content with cultural and practical use to society. reply xctr94 1 hour agorootparentprevIn the US, we’re talking about a quarter of users. That’s a lot of traffic to lose.If they stop bundling Music, and possibly lower the cost of YT Premium, it might convert better. reply smartusers 9 hours agorootparentprevIt&#x27;s just going to push the smart people with self respect to other platforms. YouTube will then cater to the captive ad tolerant audience that&#x27;s left and the quality of the whole platform will degrade. More people will leave, the quality will drop, the number of ads will go up, etc. This will reduce the quality of video on YouTube until what you basically have now on reddit: a hot trash fire. Sure you can milk these people for a while, but eventually they&#x27;ll follow the crowd elsewhere. Cable TV -> Netflix. reply hellotheretoday 8 hours agorootparentCan that progression even happen anymore? Call me cynical but I think we are long past the days of “the digg migration to Reddit”, “MySpace exodus to Facebook”, leaving vbulletin forums en masse for social media, leaving irc and Usenet for vbulletin forums, etcHow could a viable competitor to YouTube even begin to pull away YouTube’s inertia without massive vc funding? That VC would want the platform to eventually end up with the same shitty ux issues, intrusive ads, and data collection as YouTube. Guaranteed. Unless someone finds a way to store and serve tons of hi def video for free.Not to mention even if you get past that step you’re going up against a Goliath. If you’re actually viable and potentially going to make a serious dent do you think google is just going to do nothing? They’ll leverage their gigantic market share and huge amount of resources to take you down. Whether it’s by suing you for some nonsense, replicating your service model in their own platform to recapture customers, straight up buying your platform, etc reply autoexec 7 hours agorootparent> How could a viable competitor to YouTube even begin to pull away YouTube’s inertia without massive vc funding?I think it depends on what people are trying to do with youtube. I doubt any one new service could replace all of it. Plenty of people want to share videos but aren&#x27;t looking to get rich from it though. For them, I think a competitor that does video delivery well, but doesn&#x27;t pay for views could exist.People who want to make videos for money would have a harder time replacing google, but lots of creators get direct support already so it isn&#x27;t hopeless. A lot of people are already on multiple platforms now too so it doesn&#x27;t have to be a hard cut off. reply master-lincoln 2 hours agorootparentprevYoutube will degrade and smaller competitors will not replace it because of what you said. But isn&#x27;t that a progression on it&#x27;s own?It will be a shittier experience for users, but I think that&#x27;s the general direction of the web anyway. Just look at other streaming companies. All of their UXs suck (as far as I have tried them on TV) and there is more and more segregation. reply wasmitnetzen 6 hours agorootparentprevIt&#x27;ll go to niche services. Dropout, Nebula, Curiositystream, possibly even Patreon. reply fallingknife 8 hours agorootparentprevWhich is fine. It&#x27;s just that the options they offer aren&#x27;t good. You either take annoying ads or pay $14 per month. How much do they make showing me ads per month? Probably not $1. If they wanted to offer me premium for $20 per year I would gladly pay and it would be win-win. As it stands I will play cat and mouse with ad blockers and they will get $0 from me. reply NelsonMinar 51 minutes agoparentprevMost people who work at Google use ad blockers. They agree with you that the web isn&#x27;t usable without them. The hypocrisy is becoming unbearable. reply thih9 3 hours agoparentprevLiving without YouTube can be hard though. Almost every online tutorial, product demo, music video, or other medium and long video material gets uploaded there. reply master-lincoln 2 hours agorootparentthat will change once users leave. I remember times where those videos were split between Vimeo and Youtube reply paganel 7 hours agoparentprevI&#x27;m just visiting fewer websites&#x2F;pages, i.e. those with no ads at all (like this forum) or those with less intrusive ones (such as old.reddit.com). As for websites like YT, I ended up just watching fewer videos (because of the ads).All in all I see it as a net positive. reply Twirrim 9 hours agoprevA nice little Quality Of Life improvement for me with uBlock Origin recently has been using it top block Confluence&#x27;s pop ups when someone has commented on a page I&#x27;m reading.We use Confluence to do document reviews at work, and sitting there attempting to read a document while Confluence is popping up that annoying dialogue box over and over again as people comment on the doc is insanely annoying. With uBlock Origin I was able to (after a few false attempts) sniff the specific element and filter it out. reply janpio 7 hours agoparentGitHub notifications blue dot for me. Not seeing it makes me click that button much less, only when I _want_ to handle notifications. reply nathansherburn 4 hours agorootparentThank you! I can&#x27;t believe I never thought to do this! reply 0xedb 8 hours agoparentprevI used it to block Twitter&#x27;s ad bugging me to pay. Funny thing is I can&#x27;t use the paid version since it&#x27;s not available in my country. However, the popup kept bugging me reply climb_stealth 6 hours agoparentprevAgreed, I love it for things like this. Someone puts a big bright yellow and red banner on the top of confluence or Jira weeks in advance to notify about upcoming outages. I really couldn&#x27;t care less about those and it&#x27;s perfect to get rid of them. reply loughnane 2 hours agoprevYesterday I figured out how to block cards in my LI feed that contained certain words. Here&#x27;s the one for things containing \"excited to\"``` www.linkedin.com##.relative:has-text(&#x2F;excited to&#x2F;i)```between that, blocking images, and user taglines my feed is much more concise and readable. reply lolinder 36 minutes agoparentThis is cool, but sincere question: what is even left after you block all the fluff? I rarely bother to go to my LinkedIn feed, but when I do it&#x27;s all fluff that I don&#x27;t need to see. Is there actually value buried somewhere under there? reply Flammy 27 minutes agorootparentIMO I care much more about contacts changing jobs, getting laid off, and talking about their side projects than anything else.I probably should see if someone has a linkedin script to remove non-1st connection content. reply altairprime 10 hours agoprevNote that this release is not, as of this comment, finished being published and approved in any of the four browser app stores, so you may not see the new version when using check for updates (if you installed the normal way) until they’ve finished the release process.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;uBlockOrigin&#x2F;comments&#x2F;17kw0vc&#x2F;ubloc... has the usual “it hasn’t completed review yet” guidances as well how to rush ahead of the app stores for those that are impatient. reply bloopernova 1 hour agoprevuBlock Origin can also be used to modify the DOM or CSS in specific URLs via its \"My Filters\" screen.For instance, I use it to switch HackerNews to dark mode, and restrict the width of comments to about 10-12 words: https:&#x2F;&#x2F;gist.github.com&#x2F;aclarknexient&#x2F;c39c83f2f97c3c6b1c307c...It&#x27;s a great alternative to GreaseMonkey or other user style extensions. reply flutas 42 minutes agoparentThanks for the gist.I tweaked it a tiny bit since overscroll on FF on osx was showing as white, figured I&#x27;d share it back. It&#x27;s not perfect, but the BG color differences are close enough to not bother me. ! Invert the colours of the site, making a dark mode that I like ! `invert(95%)` does most of the work, ! but you can tweak the hue-rotate value to fine tune the colours news.ycombinator.com##body:style(filter:invert(95%) hue-rotate(200deg); background: white) news.ycombinator.com##html:style(background: black)` reply bloopernova 12 minutes agorootparentHey that&#x27;s good stuff, thank you! reply creatonez 10 hours agoprevFor anyone looking for up-to-date information on getting YouTube ad blocking to work: https:&#x2F;&#x2F;github.com&#x2F;uBlockOrigin&#x2F;uAssets&#x2F;issues&#x2F;19976 reply spartanatreyu 10 hours agoparentIn the last year, youtube anti-ad-block only ever occurred to me once and I fixed it in 2 minutes by reading the instructions on that github issue.All I had to do was manually trigger an update for uBlock Origin&#x27;s filter lists then restart firefox.The filter lists update automatically, but a new youtube change got around them and the filter had a fix inside an hour (too short a time for my extension to auto-update it&#x27;s filter lists). reply chii 8 hours agorootparentThis has been continuing for the past couple months. I don&#x27;t see youtube giving up tbh, and i don&#x27;t see how uBO can continue to maintain a manually constructed filter every time a new mechanism is added&#x2F;altered in youtube.This is different to other ads, which is a crowdsourced list of filters, and isn&#x27;t on a small or single individual to keep up. There must be a better way to utilize the crowd to make it work. reply autoexec 7 hours agorootparent> This has been continuing for the past couple months. I don&#x27;t see youtube giving up tbh, and i don&#x27;t see how uBO can continue to maintain a manually constructed filter every time a new mechanism is added&#x2F;altered in youtube.If UBO stops working, I&#x27;ll use newpipe, if that stops working I&#x27;ll use yt-dlp and if that stops working I&#x27;ll use whatever else people have come up with, and if nobody has anything that gets rid of the ads I&#x27;ll just stop watching youtube.I don&#x27;t see that happening though. As long as we have computers that still work for us, I doubt google will come up with a way to stop ad blocking entirely. Maybe we&#x27;ll have youtube re-release groups that manually edit out the ads and re-upload videos from popular channels to P2P sites. Maybe we&#x27;ll get AI that can download videos and edit out the ads for us. We&#x27;ll figure something out. reply paulryanrogers 3 hours agorootparentThere is YT Premium reply CuriouslyC 1 hour agorootparentWe do not negotiate with terrorists reply jeron 7 hours agorootparentprev> i don&#x27;t see how uBO can continue to maintain a manually constructed filter every time a new mechanism is added&#x2F;altered in youtubeDon’t underestimate what open source can and will do just to spite things they despise reply thomastsch 5 hours agoparentprevFor those who can&#x27;t or don&#x27;t want to install an ad blocker on their device, a youtube viewer bookmarklet: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37973944 reply smartbit 2 hours agorootparentLow resolution, but works great. Thanks. reply uoaei 10 hours agoparentprevAd-blocking never stopped working for me. I use a combo of uBlock Origin, uMatrix, and Unhook. reply mantra2 10 hours agorootparentI don’t think they’ve rolled it out to everyone yet. reply bluescrn 5 hours agorootparentCurrently doesn&#x27;t seem to affect logged out users. So I just logged out. reply bonton89 49 minutes agorootparentOne of my PCs never had an account and the ad blocker no longer works. My other PC appears to be logged into my throwaway account and the most I ever saw one message about blocking. reply sphars 3 hours agorootparentprevThis explains why I haven&#x27;t seen the popup yet. I&#x27;m logged out on FF, logged in on Chrome (I have premium), but do all casual YT viewing in FF. reply pests 8 hours agorootparentprevThey haven&#x27;t. I was hit just last week. reply uoaei 10 hours agorootparentprevuMatrix breaks so much across the entire internet that I feel like it has an effect here. But I haven&#x27;t done any tests to confirm that. reply venatiodecorus 9 hours agorootparentprevI used to use uMatrix before it ceased development, but eventually switched over to only uBlock advanced mode. Do you find it still works fine? What cases do you keep uMatrix around for? reply brigandish 9 hours agorootparentThe UI is superior, in my opinion. Better colours; much clearer about which connections are made or attempted; less interaction with typing out rules or looking at such rules.If I could get the uMatrix \"skin\" on top of uBlock Origin that would be great. reply Semaphor 10 hours agorootparentprevuBO + uMatrix, got the nag and the 3-video warning. Adding \"uBlock filters – Annoyances\" fixed it for me. reply therein 10 hours agorootparentprevAs far as I can tell, they are leaving Silicon Valley IPs to the end of the rollout. reply applecrazy 10 hours agorootparentthis is untrue. located in the bay area and getting dinged hard on most of my devices reply therein 9 hours agorootparentInteresting. Maybe it is Google Fiber in Bay Area, or something more specific like that.I get it on my devices when I travel outside Bay Area and my friends everywhere else are getting the treatment that people are complaining about.But with just uBlock Origin, haven&#x27;t seen anything pertaining ads on YouTube on Google Fiber in Bay Area. reply hypertele-Xii 10 hours agoparentprevAdBlocker Ultimate still works. I just blocked the nagging popup element. reply beej71 10 hours agoprev\"uBO works best on Firefox\". I can&#x27;t say I&#x27;m totally shocked that getting it working better under Chrome is somehow more difficult. reply jchook 8 hours agoparentChrome now aggressively blocks ad blockers on YouTube.com reply xd1936 3 hours agorootparentYouTube&#x27;s new anti-adblocking has nothing to do with which browser you&#x27;re using reply skrebbel 7 hours agorootparentprevHmmm source?I know youtube does but I didnt know Chrome does. reply theshrike79 4 hours agorootparentSite and browser owned by the largest ad company in the world don&#x27;t want you to block ads.News at 11. reply theshrike79 24 minutes agorootparent(If you disagree, don&#x27;t just click the down arrow, argue your point.) reply demondemidi 4 hours agorootparentprevWhat triggers this? I use adnauseum on Firefox and I haven’t seen a YouTube blocker warning in weeks. Not sure why it is so intermittent. reply tekla 1 hour agorootparentprevProve it. reply iza 8 hours agoprevIs there something significant about this release? I read the changelog but nothing really stands out to me. reply a2dam 8 hours agoparentI was going to ask the same thing. Why is this on the top of the front page? reply saos 6 hours agoparentprevWondering the same. Will it bypass YouTube latest efforts reply Jedd 10 hours agoprevUnsure of provenance for this link, but it shows your browser&#x27;s current success &#x2F; failure state for blocking youtube anti-adware efforts.https:&#x2F;&#x2F;drhyperion451.github.io&#x2F;does-uBO-bypass-yt&#x2F; reply chii 8 hours agoparentIt&#x27;s not actually showing success in blocking - it&#x27;s showing whether uBO&#x27;s filters are up-to-date with the latest youtube scripts. It is possible that youtube has updated, and none of the new ids are put into the pastebin yet, and thus, adblock fails. reply Jedd 5 hours agorootparentAh, yeah, that&#x27;s more accurate. I&#x27;ve equated the two so far, but I expect the rate of change by both sides is still ramping up. reply tedunangst 8 hours agoprev\"Do not add filters from untrusted sources.\" Interesting addition. reply kriro 8 hours agoprevI have been hit a lot by the adblock-block and my default browser for youtube was Chrome with uBlock. There was some back and forth and it still worked around 50% of the time. I took the oportunity to try the youtube experience on a brand new clean browser, not logged in. My seed recommendations were 80% right wing and conspiracy material. I humored the algorithm a bit and after three days I was basically in a right wing&#x2F;anti science&#x2F;flat and hollow earth bubble. An interesting experience to say the least. It is basically the opposite of my real world interests. I&#x27;d describe myself as libertarian and love to learn about different cultures and I do work in academia.I have since cut my youtube viewing by about 50-80% and am not using Chrome anymore (except for testing&#x2F;security). Great success Google and thanks for all the idiotic brainwashing content.I do get that youtube needs to make money somehow and adds are the way. Unfortunately the experienc is so bad, perormance is suffering etc. that I&#x27;d rather have no youtube than youtube with adds. reply nullandvoid 1 hour agoparentI find YT is only useable via the following combination of extensions these days- Ublock (still works for me, maybe it&#x27;s a Firefox thing) - News feed eradictor (hides reccomended vids) - Pocket tube (how subscription management should have been) - Sponsorblock (auto skip sponsors which are typically gambling or predatory games) reply shiroiuma 10 hours agoprevgorhill should be given a Nobel Prize and a knighthood for contributions to humanity. reply radicalriddler 9 hours agoparentHow many Kilowatts has this man saved by computers not having to load trackers and render ad banners!? reply ranting-moth 2 hours agoparentprevI can&#x27;t imagine browsing the internet without uBlock installed. I honestly don&#x27;t think I could. reply UberFly 9 hours agoparentprevNo kidding. How do we thank this person? Compensate the effort? reply chii 7 hours agorootparenthe has explicitly denied the option for donations, which is excellent moral standing from my POV. However, it does beg the question - how can the community reward people who want to do this sort of work? reply shiroiuma 7 hours agorootparentPerhaps a gigantic status of him standing over a harbor? Or a national holiday?We should also not forget to give accolades to the heroic people who tirelessly maintain the filter lists. reply MandieD 5 hours agorootparentAccolades and money - Mr. Gorhill asks us to consider donating to the filter list maintainers instead if we want to give money to uBO. reply uxcolumbo 4 hours agorootparentDo you have a link or is this donating to each individual? reply MandieD 3 hours agorootparentI guess each individual filter list; you can check your uBO settings to see which ones you use. replyspecialist 3 hours agoparentprevYes and: apparently the moderators on reddit&#x27;s r&#x2F;ublock have been having rough time. At least one has quit and deleted their account because of abusive users.No good deed goes unpunished. reply randomdev3 9 hours agoprevnever had an issue with YouTube. At least until now they only try to block blockers if you are signed in. And there really is no reason to login to watch videos. reply iamalchemist 9 hours agoprevHow is UBO on Google Chrome different than Brave browser?Context - I&#x27;ve used UBO on Google Chrome in the past and now using Brave browser for the last few years. I don&#x27;t see much difference how web feels with UBO and Brave. reply andirk 6 hours agoparentBrave browser isn&#x27;t necessarily blocking advertisements as much as it is blocking scripts that are naughty, and those naughty scripts are very popular in ads and ad networks.And the Basic Attention Token concept is something I hope takes off since the current state of online advertising is pretty abysmal. reply nextlevelwizard 9 hours agoparentprevuBlock blocks ads while Brave deliberately shows you ads and gives you monopoly tokens. reply 8organicbits 9 hours agorootparentI think that&#x27;s opt in now:> But if you choose to see Brave Ads, you can earn.https:&#x2F;&#x2F;brave.com&#x2F;brave-rewards&#x2F; reply arbol 8 hours agoparentprevBrave ad blocker is not as good as UBO. You need to install UBO if you use brave. reply arpanetus 7 hours agorootparentI switched to Brave from Chromium + UBO. Despite seeing some ads, it&#x27;s still comfier to use vanilla Brave than Chromium + UBO. reply archo 10 hours agoprevuBlock Origin is a recommended extension[1]Recommended extensions undergo full code review by staff security experts to provide a strong additional security check.[1] - https:&#x2F;&#x2F;blog.mozilla.org&#x2F;en&#x2F;products&#x2F;firefox&#x2F;extensions-addo...uBlock Origin – Wiki : https:&#x2F;&#x2F;github.com&#x2F;gorhill&#x2F;uBlock&#x2F;wiki reply demondemidi 4 hours agoparentI’m really surprised 1Password isn’t recommended. reply jchook 8 hours agoprev [–] Google&#x27;s Chrome browser now aggressively thwarts uBlock on YouTube.com.Since Firefox is not owned by Google, uBlock still works. reply cornedor 6 hours agoparent [–] Isn&#x27;t this just asking for an antitrust case? There is no way I implement this for my own site. reply paulryanrogers 2 hours agorootparent [–] Implement what? Anti-ad-blocking? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The gorhill / uBlock project on GitHub has released an update, version 1.53.0 which includes improvements, bug fixes and new filtering expressions for logger output.",
      "The update contains a cautionary note against adding custom filters from unknown sources, thus emphasizing online security.",
      "Contributors kzar, ryanbr, and peace2000 have been essential in the implementation of these updates, which also include enhancements to existing scriptlets and changes based on user feedback."
    ],
    "commentSummary": [
      "The recent update of the ad-blocking extension, uBlock Origin, is sparking online discussions, with its effectiveness on platforms like YouTube at the core.",
      "Users report improved performance in Firefox as opposed to Chromium-based browsers, raising debates about the extension's varying results across different browsers.",
      "Users are expressing their concerns on the environmental impact of digital advertising and the economics of ad-blocking, citing saved time and costs with ad-blockers like uBlock Origin, while discussing potential actions by platforms such as YouTube to hinder ad-blocker performance."
    ],
    "points": 429,
    "commentCount": 222,
    "retryCount": 0,
    "time": 1698813182
  },
  {
    "id": 38092612,
    "title": "Norwegian ban on Meta behavioral advertising extended to entire EU",
    "originLink": "https://www.datatilsynet.no/aktuelt/aktuelle-nyheter-2023/datatilsynets-vedtak-mot-meta-utvides-til-eueos-og-gjores-permanent/",
    "originBody": "Til hovedinnhold Logo og hjelpeverktøy Hva leter du etter? Søk MENY VIS/SKJUL MENY Hovedmeny Aktuelle nyheter 2023 Vi bruker informasjonskapsler (cookies) Våre nettsider benytter noen få informasjonskapsler (cookies) til sikkerhet og analyse. I tillegg bruker vi cookies til en valgfri skjemafunksjon der vi ber om samtykke først. Les om hvilke vi bruker og hvordan vi administrerer dem i cookie-erklæringen vår. Nødvendige cookies Disse støtter opp under kjernefunksjonalitet knyttet til sikkerhet. Vi har vurdert disse som nødvendige, og de lagres derfor uten samtykke. Skjemafunksjoner Dette er nødvendig å samtykke til dersom du ønsker å ta i bruk skjema på nettsidene. Den øvrige funksjonaliteten på nettsidene påvirkes ikke dersom du lar være å samtykke. Valget du tar her gjelder i inntil 90 dager. Skjemafunksjoner av/på Webanalyse Vi bruker session-cookie til statistikk. Det er en ikke-identifiserbar, tilfeldig verdi som forsvinner idet du lukker nettleseren eller etter 30 minutt. Du kan trekke tilbake samtykket når som helst ved å velge «administrer cookies» nederst på våre sider. Lagre mitt valg LUKK Datatilsynets vedtak mot Meta utvides til EU/EØS og gjøres permanent Det europeiske personvernrådet har nå bestemt at det norske forbudet mot adferdsbasert markedsføring på Facebook og Instagram skal bli permanent og utvides til å gjelde hele EU/EØS. - Vi er veldig glade for at Personvernrådet er enige i Datatilsynets vurderinger og utvider forbudet vårt. Målet er at innbyggere over hele Europa vil få bedre personvern, sier direktør i Datatilsynet Line Coll. Datatilsynet er svært bekymret for den ulovlige sporingen, overvåkingen og profileringen som skjer på Facebook og Instagram. Selv om det lenge har vært klart at Meta bryter loven, og på tross av Datatilsynets forbud i Norge, fortsetter Meta med sin ulovlig behandling av personopplysninger. Dette er grunnen til at vi har valgt å løfte saken til Personvernrådet (EDPB), som nå har sagt seg enige i at det haster med et permanent forbud mot de ulovlige aktivitetene på europeisk nivå. Facebook og Instagram har over 250 millioner aktive brukere i EU/EØS. Personvernrådets vedtak er en instruks til det irske datatilsynet om å nedlegge et permanent forbud ovenfor Metas europeiske hovedkontor i Irland. Når dette har skjedd vil forbudet begynne å gjelde. - Nok er nok. Etter over fem år med krenkelse av brukernes grunnleggende personvern, setter Personvernrådet nå ned foten mot Metas manglende respekt for loven, sier leder for internasjonal seksjon, Tobias Judin. Meta har fått klar beskjed om at forretningsmodellen deres og bruken av personopplysninger strider med det europeiske personvernregelverket. De har sagt at de vil be brukerne om samtykke til å bruke dataene deres til adferdsbasert markedsføring i fremtiden. Selskapet har imidlertid ikke innført noen konkrete endringer ennå, og dermed fortsetter de ulovlige aktivitetene fortløpende. Datatilsynet er dessuten i sterk tvil om Metas foreslåtte samtykkeløsning, som innebærer at de som ikke samtykker til adferdsbasert markedsføring må betale en avgift, vil være lovlig. Personvernrådets avgjørelse er derfor viktig for å unngå at Metas lovbrudd fortsetter mens selskapet leter etter en lovlig måte å innrette seg på. Kontaktperson Tobias Judin Tobias Judin seksjonssjef, internasjonal seksjon Kontor: +47 22 39 69 47E-post: tobias@datatilsynet.no Janne Stang Dahl Janne Stang Dahl kommunikasjonsdirektør Kontor: +47 22 39 69 03Mobil: +47 97 08 11 20E-post: janne@datatilsynet.no Publisert: 31.10.2023 Relatert innhold Meta-saken løftes til europeisk nivå Meta går til ny sak mot Datatilsynet Datatilsynet vant mot Meta i Oslo tingrett Meta-saken opp i Oslo tingrett Midlertidig forbud mot adferdsbasert markedsføring på Facebook og Instagram Datatilsynet Postboks 458 Sentrum 0105 Oslo Org.nr 974 761 467 Kontakt oss Tilgjengelighetserklæring Motta vårt nyhetsbrev Datatilsynet på twitter Aktuelt Ordliste Ofte stilte spørsmål Datatilsynets personvernerklæring Datatilsynets cookie-erklæring Administrer cookies Andre nettsteder",
    "commentLink": "https://news.ycombinator.com/item?id=38092612",
    "commentBody": "Norwegian ban on Meta behavioral advertising extended to entire EUHacker NewspastloginNorwegian ban on Meta behavioral advertising extended to entire EU (datatilsynet.no) 413 points by aleksanb 16 hours ago| hidepastfavorite226 comments neontomo 12 hours agoContext from the Norwegian article:Meta promised to ask users whether they want to opt-in, but they never did, so now they are banning these behaviours until they have come up with a better way of handling this.Furthermore, Meta wanted those who opt-out of data sharing to have to pay money, which is most likely not legal. reply xp84 10 hours agoparent> Meta wanted those who opt-out of data sharing to have to pay money, which is most likely not legal.I really don&#x27;t get this attitude. I 100% endorse everyone&#x27;s right to uninstall every Meta app and never use them, and to block their on-page trackers on third-party websites with an adblocker, all that. But the notion that there should be some sort of EU-protected \"Right To Use Facebook For Free\"... nah. Using the apps inherently shares data with the company whose servers you&#x27;re using. Don&#x27;t like it, that&#x27;s fine, there&#x27;s only one correct recourse: Don&#x27;t use it.Also, if Facebook&#x27;s users were all paying for it (and all its competitors), there would be no advertising on it, and incentives in social media would be aligned much better. The government which requires companies to provide their service \"for free\" would be actively working against that better world by pushing the ad-supported model, which they clearly hate, as the only one. reply stubish 10 hours agorootparentWhat you are asking for is the ability to sell your right to privacy. Laws generally don&#x27;t allow you to sell or otherwise relinquish your rights, eg. selling your vote or selling yourself into slavery or accepting licenses in conflict with rights granted by local consumer laws. Some things we don&#x27;t want assigned a value that can be traded. The EU has decided that the right to privacy includes not being tracked on the Internet, and any &#x27;you can only use this if you give up your right or pay money&#x27; is not going to be allowed, because it ends up destroying that right for many. reply bluelu 7 hours agorootparentIt&#x27;s a double standart again.Newspapers lobbied the EU that it s allowed for them (not sure if it was changed at the end). But if you go to a large european newspaper site (eg spiegel.de) then it explicitely asks you tha you pay to access it or you must agree to behavioral advertising. But facebook should not be allowed to do this. reply klabb3 7 hours agorootparentYes and this should be pointed out. However, it’s imo far from a simple selfish lobbying move. If behavioral advertising and tracking is not allowed by anyone, it will even the playing field as ads return to being context-centric, as it should. It’s too early to say if news papers will try to weasel out an exception for themselves in such a world, imo.More generally, you can want a change for everyone even if you are not currently doing what you’re preaching. You can play a game according to the rules and want to change the rules at the same time. While I agree this is a lower level of belief you can still want it, and argue for it, in good faith. Deviating from laws and even industry norms can be disproportionately costly, relative to your competitors, especially if you’re already struggling, which is true for most of legacy media.Also, journalists are typically not the owners of media companies, and they sometimes cover issues with conflicts of interest with their owners. That’s a healthy thing. reply bluelu 2 hours agorootparentNewspapers weaseled already an exeption out 2 years ago, see https:&#x2F;&#x2F;www.heise.de&#x2F;news&#x2F;E-Privacy-Verordnung-EU-Rat-fuer-V... reply einarfd 6 hours agorootparentprevI&#x27;ve never seen anything like that in any Norwegian newspaper, and I would expect some of them to try if they thought they could get away with it. But I don&#x27;t think they would at least not if the retoric coming out of Datatilsynet is anything to go by.How German newspaper get away with that I have no idea. But you can&#x27;t expect the Norwegian government to handle German language newspapers. If spiegel.de had a Norwegian presence though. Then it would be reasonable for Norway to have a look at it. reply seabass-labrax 6 hours agorootparentprevI loath Spiegel just as much as any other online privacy advocate, but I&#x27;d always assumed they were simply in violation of the GDPR. Can you provide any references indicating that this is the result of a special exemption due to successful lobbying? reply bluelu 2 hours agorootparentThere is a german artcile about this here:https:&#x2F;&#x2F;www.heise.de&#x2F;news&#x2F;E-Privacy-Verordnung-EU-Rat-fuer-V...Read the part about cookie walls for newspapers:Cookie-Wall soll bleibenWer auf seiner Webseite unentgeltlich Nachrichteninhalte verfügbar macht und das durch Werbung finanziert, soll dabei Cookies ohne Zustimmung der Nutzer setzen können. Eine \"Cookie-Wall\" als Alternative zu einer Bezahlschranke soll also zulässig bleiben. User, die nicht für Werbezwecke analysiert werden möchten, müssen gegebenenfalls ein kostenpflichtiges Abo abschließen. Diese Klausel wird an die Voraussetzung geknüpft, dass der User prinzipiell zwischen verschiedenen Varianten wählen können. Dazu kommen weite Spielräume für Direktmarketing auch via Bots. reply soco 5 hours agorootparentprevMany German sites do that too - nothing that I use daily to remember names, but I see that choice between ads and pay rather often. And I usually choose to leave, but not always... reply pests 9 hours agorootparentprevBut as you say, they aren&#x27;t asking you to give up your rights (because of the &#x27;or pay money&#x27; clause). You can just stop using it. If you want to use it and not give up rights, pay money. What is wrong with that? reply piaste 8 hours agorootparentThe \"or you can give up your rights in exchange for a discount\" part is the problem. You can&#x27;t buy a car by agreeing to be a slave for 90 days either.Commercial subscription services that don&#x27;t violate your privacy are 100% fine, and incidentally, as xp84 noted, are way healthier because the user is at least a customer. (I dream of a day where companies spend $0 on advertising and instead all commercial websites and social media are run on small subscriptions or frictionless micropayments and the only person they need to keep happy is the customer.)Of course \"free\" services have a massive advantage over paid ones. If Meta can profitably run Facebook just on generic ads without tracking, like a newspaper, that&#x27;s allowed too. But if they can&#x27;t, well, tough shit. reply tagyro 8 hours agorootparentprevI don&#x27;t agree - you can&#x27;t just stop using it. Given the size of facebook (or google, amazon, microsoft, apple etc), they are ingrained in our (tech) life in such a way that one has to invest a - not negligible - amount of work to stop using them. To sum it up: companies want to have \"power\", but without having \"responsibility\". reply dadadatamen 7 hours agorootparentYou can. It&#x27;s almost quite literally an effort of 30 - 60 min per day or week or month, depending on how skilled you are at keeping things convenient, meaning self-hosting services and maintaining them. reply tempaccount1234 6 hours agorootparentYou can, but if you decide to stay away from messengers like WhatsApp, you miss out. Which is OK unless you have kids in school age.Once a service gets so big, that you are practically forced to join, regulation seems like a very good idea reply dadadatamen 3 hours agorootparentRegulation is imperative.Missing out is an illusion.Enough ways to get around the benefits of using WhatsApp for business. Enough customers hate using WhatsApp to communicate with businesses. reply hackideiomat 6 hours agorootparentprevteach your kids signal? reply logifail 4 hours agorootparent> teach your kids signal?Getting your own kids to switch messenging client is fairly trivial. Then they can talk to you (and to each other).The network effect means you then have to persuade other kids, and parents, and sports coaches, and music teachers and ... to switch.(Source: have three kids and we have exactly this issue) reply dadadatamen 3 hours agorootparentDid you organize meetings with parents? In coop with teachers?Signal is spy stuff. WhatsApp means obedience and submission. reply logifail 3 hours agorootparent> Did you organize meetings with parents? In coop with teachers?At least where we are, schools have been told not to touch WhatsApp at all, and use another (more GDPR-compliant) messaging product; despite this there is typically an unofficial WhatsApp group for each class, but no teachers are members.> WhatsApp means obedience and submissionI don&#x27;t disagree, but I don&#x27;t think you&#x27;ll convince many parents to stop using WhatsApp if you approach it like that.My impression is that most parents are very busy people and are just trying to keep up with the chaos caused by their kids; they will opt for the easiest solution that solves their problem. replytheonlybutlet 7 hours agorootparentprevAnd say getting a job, when everything is through LinkedIn? reply dadadatamen 7 hours agorootparentYou can get the contact details of the hiring manager on the companies website or call their front desk or ask in an E-Mail to info@xyz or support@xyz or even by asking around.and there are various ways to prove your value that are not based on networks reply theonlybutlet 7 hours agorootparentYou won&#x27;t know unless you saw the listing, which these days is put on LinkedIn. reply dadadatamen 7 hours agorootparentwell, change your way of picking an employer, I guess?!the thing is, almost everyone is or will be looking in the near future. reply theonlybutlet 7 hours agorootparentWhat I do is of no consequence if that&#x27;s all hiring managers do. These apps can become systemic. reply dadadatamen 3 hours agorootparentattentional bias. That&#x27;s not all all hiring managers do. replygraphe 8 hours agorootparentprevYou CAN stop using them. Do you WANT to? Are you unable to?Social media addiction isn&#x27;t a right, and just because you have a share to Facebook or Twitter integration doesn&#x27;t mean you have to use either. reply interactivecode 8 hours agorootparentprevThats like saying, if you don’t like lead in your paint. You can just use different paint. Like yeah sure, but still some regulations that stop them from putting lead in paint is a good thing reply disiplus 8 hours agorootparentprevIt does not work like that, the country made some laws. For example what safety rules does the car have to follow to be legal in us. You cannot just say, if you don&#x27;t like that the car does not have a backup camera doesn&#x27;t use it. reply stubish 7 hours agorootparentprevIn the case of the right of privacy, what is wrong with your suggestion is that it is what we have today, and we end up where we are today. You must sacrifice your right of privacy to use Facebook, Twitter and others. And using Facebook, Twitter and others is not a choice for many people. It is forced on many (most?) by rules of employment (some schools require teachers to be on Facebook for example), economic reasons (must be on social media to be economically competitive), or just social (all my friends are there, so I need to be there too). Choosing to retain your right of privacy is a sacrifice, which is to say that maintaining your right of privacy has a cost. The EU has said that there should not be a cost to preserving what it sees as a right. Not everyone can afford to pay that cost. reply anilakar 8 hours agorootparentprev>> Laws generally don&#x27;t allow you to sell or otherwise relinquish your rights,> If you want to use it and not give up rights, pay money.Ahh, we are not asking you to sell. We are asking you to give them in exchange for services. reply A_non_e-moose 6 hours agorootparent> >> Laws generally don&#x27;t allow you to sell or otherwise relinquish your rights,> Ahh, we are not asking you to sell. We are asking you to give them in exchange for services.That&#x27;s covered in the \"or otherwise relinquish your rights\" part. Privacy is a right, you can&#x27;t sell or relinquish it, in exchange or donated, doesn&#x27;t matter. reply ralusek 8 hours agorootparentprevThat’s like saying that using a site with moderation rules is asking you to sell your right to free speech, or that going to a nude spa is asking you to sell your right to privacy.I have no problem with EU regulating what Facebook can do, in the same way I accept that some places might regulate against nude spas, I just take issue with the way you framed it. reply anilakar 8 hours agorootparentPlease dont bring free speech into this. As everyone very well knows, it trumps everything else including basic human rights in a certain country. reply DangitBobby 1 hour agorootparentIt is a basic human right. reply lopis 9 hours agorootparentprevI often see this argument that if we&#x27;d all pay for services like Facebook, they wouldn&#x27;t have to charge.Let me offer a counterpoint: if there is money on the table, corporations will get it. Example, you pay for cable, and still get ads. You pay for Netflix and still get Netflix ads in the app. All paid aps harvest and sell your behaviour data. Greed does not permit that money be left on the table. reply hackideiomat 6 hours agorootparentThere are companies that try to align their incentives with the customers incentives by using a certain business model. I pay $25 for a search engine, that costs way less than operating netflix. I would be very shocked if they actually abuse the data they shouldn&#x27;t collect on me. My point being, this only applies to very big coorps. There are companies that (at least claim to) care about privacy and do not sell off their users. reply lopis 3 hours agorootparentWell of course. If they sell you a specific product and then don&#x27;t deliver, then there wasn&#x27;t money on the table, that&#x27;s just lying. reply Youden 8 hours agorootparentprevFacebook is only banned from behavioural advertising; regular advertising is still perfectly fine. They&#x27;re not being banned from making money at all, they&#x27;re only being banned from using personal data to make more money. reply dadadatamen 7 hours agorootparentNobody will blow the whistle on whether that&#x27;s true or not. It&#x27;s a fact that we can&#x27;t trust companies like Meta. Not because it&#x27;s engineers who implement dark patterns or because all the people in a business earn more money if they disregard human or environmental wellbeing but because leadership literally lies to congress, judges, the public, their users and their customers all the freaking time. reply A_non_e-moose 6 hours agorootparent> leadership literally lies to congress, judges, the public, their users and their customers all the freaking time.The judiciary system takes lies into account. Doing that while testifying under oath might end poorly. See SBF&#x27;s trial for reference. reply dadadatamen 3 hours agorootparentAnd that&#x27;s great! Similar schemes are still rollin&#x27;, though, and there are people right here on HN, who could blow the whistle on a great many things that are unethical and corrupt. reply neontomo 10 hours agorootparentprevWell, they are already pushing ads on people and make money through that business model. Forcing the ads to be targeted creates another revenue stream for Meta but does not add anything to your argument that we should be willing to give this away in exchange for free use. We are already paying for it, with time and attention and them manipulating our emotions.I don&#x27;t mind this business model as much as some, but I think you&#x27;re arguing the wrong thing here. reply alkonaut 7 hours agorootparentprev> Using the apps inherently shares data with the company whose servers you&#x27;re using.That&#x27;s not a problem. The problem is that these companies share it with others. That&#x27;s what requires consent and Meta isn&#x27;t asking for it and does it anyway.Facebook can show as many ads it wants. It can even show as many ads as it wants without asking for user consent. reply butlerm 10 hours agorootparentprevI would love to believe that advertising would go away if only we all paid subscription fees. Cable television tells a different story. reply fragmede 10 hours agorootparentThen again, Netflix and YouTube Premium contradict that (for now). reply manuelmoreale 8 hours agorootparentBoth are either introducing or toying with the idea of introducing ads. Because paid + ads still makes them more money than just a regular subscription.And since the goal is to make always more money the future is gonna be paid subs + ads. reply skydhash 7 hours agorootparentI don’t really think this is gonna fly. It’s quite jarring having ads before or during a movie (even at cinemas, but at least it’s once in a while). With cable you could switch channels, but streaming is a more personal experience. Especially when you’re supposed to have control over the programming. reply WaxProlix 7 hours agorootparentprevCable also contradicted that for a time. reply zelphirkalt 7 hours agorootparentprevWhere can I opt-out of being tracked by them without ever having a facebook&#x2F;meta account? reply jdietrich 7 hours agorootparentprevThe GDPR says that consent must be freely given and freely revocable, otherwise it isn&#x27;t real consent. It would be obviously unfair if, for example, your employer could say \"agree to install our spyware on your personal devices or you&#x27;re fired\", or for your landlord to say \"agree to let me put surveillance cameras in your apartment or you&#x27;re evicted\". That isn&#x27;t consent, it&#x27;s coercion. A right that you can be coerced to relinquish isn&#x27;t a right.Facebook have a right to charge a subscription fee. They have a right to ask you to provide your personal data. They don&#x27;t have the right to charge their users a privacy tax. reply littlestymaar 9 hours agorootparentprev> Also, if Facebook&#x27;s users were all paying for it (and all its competitors), there would be no advertising on it,Ah yes, much like how cable TV has no ads on it, right? Or newspapers. Or how Microsoft Windows has no ads on it because you paid for the OS? Or like how smart TVs aren&#x27;t spying on you because you bought them…If there&#x27;s money to be made by spying and putting ads, it will be done, no matter if you pay for it or not.And that&#x27;s the reason why it is probably illegal: if you accept the cookies, they track you, if you refuse cookies and pay, you have to agree to their terms and conditions which allow them to track you as well. Head they win, tail you lose. reply ako 8 hours agorootparentWith cable you’re paying the cable company, not the content provides. For that you’d have to pay the stations as well. Similar to Netflix, pay for your network, and pay the content provider. reply Terretta 7 hours agorootparent> With cable you’re paying the cable company, not the content providers.Cable and satellite such as Comcast, Time Warner Cable or DirecTV pay networks like ESPN and TNT a certain amount PER CUSTOMER for programming content each month. The median price paid for each channel a subscriber gets is 14 cents. Sports content costs the cable company the most, ESPN was estimated to cost $8.37 per month in 2018, but arguably actually should cost much more if you consider time each channel is watched versus its cost:https:&#x2F;&#x2F;www.thewrap.com&#x2F;cable-network-carriage-fees&#x2F;https:&#x2F;&#x2F;variety.com&#x2F;vip&#x2F;pay-tv-true-cost-free-1234810682&#x2F; reply littlestymaar 7 hours agorootparentprevThat&#x27;s exactly the kind of BS Facebook would say to defend their ads for paying customers as well: “you&#x27;re paying for the portal, not for the feed, the ads pay for the feed” or something like that.In fact, I&#x27;m pretty sure Google will eventually do this for premium after some time: “you&#x27;re paying the platform, ads are paying the content creators ”. replyradium3d 13 hours agoprevI don&#x27;t think it&#x27;s the ads people need to be worried about. It&#x27;s pages, groups and their \"users\" posts manipulating people. News flash: a majority aren&#x27;t even real human users. reply polygamous_bat 12 hours agoparentWhy not both? reply o_1 6 hours agoparentprevI the term bot is interesting, I think it cbelievean be expanded to any automata predictably responding in a certain fashion. Twitter \"reply\" accounts even if operated by humans but acting like bots should be considered bots. Posts that don&#x27;t move the discussion along but just reaffirm in one direction or the other are just pure noise and useless. Discourse is broken or the human brain is, unsure which it is. reply az09mugen 8 hours agoparentprevI wonder if one day there will be a majority of bots liking AI-generated content, so it will be a closed loop. reply Drakim 7 hours agorootparentLong after the last human logs off we still have to run it because it will be the primary economical engine of tech. reply omarfarooq 12 hours agoparentprevSource that dissects this? reply AuryGlenz 11 hours agorootparentI always doubt anyone who sees &#x27;bots&#x27; everywhere they go, but I agree with them on the groups part. https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;ShitMomGroupsSay&#x2F; regularly has some good examples.Ironically, I&#x27;ve posted there a couple of times in a way that (barely) went against their own groupthink and got downvoted like crazy. reply omarfarooq 11 hours agorootparentI wonder how much of these are powered by GPT. reply paganel 9 hours agoparentprev> \"users\" posts manipulating people.Are we talking about MSM here? Because those doing it are real human users, some of them quite famous. reply runesoerensen 14 hours agoprevFor people who don&#x27;t read Norwegian, here&#x27;s the Norwegian Data Protection Authority&#x27;s previous post on this matter (which the EDPB has now sided with Norway on) in English: https:&#x2F;&#x2F;www.datatilsynet.no&#x2F;en&#x2F;news&#x2F;aktuelle-nyheter-2023&#x2F;me...More details on the temporary ban: https:&#x2F;&#x2F;www.datatilsynet.no&#x2F;en&#x2F;news&#x2F;aktuelle-nyheter-2023&#x2F;te... reply bfrog 13 hours agoprevI wish the US would get its act together on stuff like this but it’s too busy getting campaign funds from such schemes reply alkonaut 7 hours agoparentYeah I don&#x27;t think there is much hope there so long as corporations are donors to political campaigns (Something that still looks weird when I type it, but presumably doesn&#x27;t sound strange to a US person). reply shiroiuma 10 hours agoparentprevIt&#x27;s not just that; the US just doesn&#x27;t believe much in regulating businesses, even if they&#x27;re demonstrably harming society. They really believe \"The Invisible Hand\" will make everything better in the end. reply Jensson 10 hours agorootparent> the US just doesn&#x27;t believe much in regulating businessesThe US has tons of strange regulations like banning car manufacturers from selling cars themselves without a middleman or dictating what kind of showerheads are allowed to be sold. reply mozman 10 hours agorootparentFun fact: most showerheads can easily be modified to allow maximum water flow rates. 30 seconds and a pair of pliers is often all it takes. reply shiroiuma 8 hours agorootparentprevThe US is nothing if not inconsistent. The car-selling thing is due to state laws, not federal, and really the result of corruption: the dealerships are politically connected. The showerhead thing is due to environmentalism, so the US does sometimes make regulations with that impetus. There&#x27;s no environmental aspect to banning targeted advertisements; it&#x27;s purely social. reply layer8 7 hours agorootparent> There&#x27;s no environmental aspect to banning targeted advertisements; it&#x27;s purely social.Arguably, the process of targeted advertisements consumes more power. reply hackideiomat 6 hours agorootparentLook at your adblock stats. Now imagine most of these scripts probably would have loaded even more stuff if you didn&#x27;t block them. Depending on the sites I visit, I have like 30% of my web traffic removed.AdBlock is an environmental thing! And true, I don&#x27;t wanna know how much these \"real time bidding on ad space\" things cost to operate, energy wise. reply 127 9 hours agorootparentprevIt&#x27;s worse than that: the US makes laws based on who pays them the most. reply LMYahooTFY 9 hours agorootparentprevThat&#x27;s what a politician might say, but there is an absurd amount of regulation in most industries. What it results in is debatable. reply fallingknife 8 hours agoparentprevHas nothing to do with campaign contributions. The government likes it that the data exists, because if it does, that means they can access it. reply exabrial 15 hours agoprevIf i travel to the eu as an American does that mean it’s illegal to track me while present in their territory? Would I be able to sue them and which country would be most favorable for the largest payout if so?I’m happy to write their support team an email letting them know my intentions to travel (lol). reply throwaway447 14 hours agoparentI am not a lawyer.\"If i travel to the eu as an American does that mean it’s illegal to track me while present in their territory?\"Yes.\"Would I be able to sue them\"You can sue any time but only makes sense if meta does something illegal.\"and which country would be most favorable for the largest payout if so?\"If Meta breaks the EU law you would likely have to sue in the country were you were present. Could also be that you have to sue Meta in an EU country were they have an office. (Ireland? Luxembourg? Dunno).\"I’m happy to write their support team an email letting them know my intentions to travel (lol).\"This is a great idea, unfortunately there are no punitive damages in most EU countries. Your payment would be tiny. reply makeitdouble 13 hours agorootparent> Could also be that you have to sue Meta in an EU country were they have an office. (Ireland? Luxembourg? Dunno).One could probably sue them in the country the behavior was documented.The equivalent case would be if A assaulted B in Norway and flee to Chicago. B could report the crime and sue in the UK, get a legal ruling, and the Norway legal branch would then deal with the US branch to bring something out of the situation (compensation, equivalent punishment in the US, extradition etc.) reply exabrial 14 hours agorootparentprevThat is disappointing. What is the motivation for them to actually obey the law? reply a_humean 9 hours agorootparentThe enforcement is that the state regulators can fine them quite substantially. In the EU and UK a lot of things around regulating business behaviour with consumers happens with consumers complaining to regulators rather than consumers suing companies through class action suits.In the UK at least more often than not if I have a problem with a company, esp for some kind of utility, there is an ombudsman that is the first port of call over the courts.The fines that the EU states can issue are very substantial % of revenue amounts.In the case of the UK, which I&#x27;m most familiar with, it&#x27;s probably a combination of the ico and ofcom which have the relevant powers to fine someone like Meta. reply throwaway447 14 hours agorootparentprevWell, they EU can sue too and if the government sues you it is a different game and can get expensive.Fines for breaking EU Competition Law Overall limit: The fine is limited to 10% of the overall annual turnover of the company.Annual turnover of Meta? reply SargeDebian 14 hours agorootparentprevNot sure if that&#x27;s a serious question and you actually consider lawsuits by private individuals the only functioning method of law enforcement, but: enforcement by governments or regulators is a thing, and on top of that anyone can still sue Meta, they&#x27;re just not going to get rich doing so. reply monosphere 14 hours agorootparentprevThe GDPR fines can actually be quite large, although they won&#x27;t be paid out to you personally.«The more serious infringements go against the very principles of the right to privacy and the right to be forgotten that are at the heart of the GDPR. These types of infringements could result in a fine of up to €20 million, or 4% of the firm’s worldwide annual revenue from the preceding financial year, whichever amount is higher.»Source: https:&#x2F;&#x2F;gdpr.eu&#x2F;fines&#x2F; reply xwolfi 12 hours agorootparentprevAnd when you sue you must justify a damage. You dont sue on principle when no damage was inflicted upon you. For instance if someone runs a camera in the street and always delete the footage, sure it s not legal per se, he tracked you, but since he actually always deleted the footage, you cant well ask for any compensation for any damage: how will the judge repair your tort ? reply kaugesaar 14 hours agoparentprevI guess you probably could, but any fines or such would not be paid out to you personally. Enforcement is primarily the responsibility of national data protection authorities (DPAs) in each EU member state. reply beberlei 9 hours agoparentprevIndividuals cannot sue for GDPR violations. They van only raise their concerns to data protection agencies and these can sue, bur they can also decide to ignore. reply graphe 8 hours agoparentprevIn practice it&#x27;s easier to register a new account in Europe and just use that account. reply nusq 12 hours agoparentprevNo, RGPD only applies to EU citizens even if they are abroad or if they are using services not based in the EU. reply Y-bar 2 hours agorootparentNot entirely correct, it applies to EU and EEA _residents_. reply 8fingerlouie 6 hours agoparentprev> If i travel to the eu as an American does that mean it’s illegal to track me while present in their territory?In short, no.The GDPR is about protecting EU citizens, and only if you reside in the EU (even as a US citizen), the GDPR will be relevant for you. reply petre 9 hours agoparentprevIt&#x27;s easier to report them to your state&#x27;s data protection authority. If more people do so and the authority does its job, they will sue on your behalf, like the Norwegian Data Protection Authority did. reply randomdev3 8 hours agoprevThey could just show dumb ads and it might even work better. It&#x27;s not so hard, you look at the page &#x2F;content and get the ad category. I&#x27;ve had Google and Meta account for more than 10 years and all ads are completely irrelevant. I go to r&#x2F;programming on new browser and they show me ads that actually might have something interesting. reply alkonaut 7 hours agoparentThe whole adtech vs. hand-crafted ad systems is a big question for small site owners who can&#x27;t be asked to sell their own ad space etc.But Meta is in a very special position. They have enough user data to pinpoint ads without having to trade data with anyone. They are large enough that they can easily manage all their ad sales in-house.They if anyone should be interested in really strict regulation. Because if everyone just has to use the data they have in house for good reason (Facebook does have my age, city, interests etc and I accept that!) then facebook has an extreme advantage in advertising. reply mrweasel 6 hours agorootparent> The whole adtech vs. hand-crafted ad systems is a big question for small site owners who can&#x27;t be asked to sell their own ad space etc.Could the ad networks scan the site instead and use the content on the pages to determine likely target audiences? You could still do ad networks, and target audience, based on the site that they are currently on.The current version of adtech is pretty damaging to society as a whole and it&#x27;s getting increasingly worse. Apparently nothing online or content related is able to generate enough revenue to keep itself afloat without ads. Manufactures of TVs and cars are collecting and selling data to increase profit, but are themselves buying ads, making it akin to a pyramid scheme. Maybe we need to start taking a look at the industries that are heavily depending on selling ad space to survive and question if they need to exist, or should be transformed into actual products. reply alkonaut 5 hours agorootparent> Could the ad networks scan the site instead and use the content on the pages to determine likely target audiences? You could still do ad networks, and target audience, based on the site that they are currently on.Yes. But it simply doesn&#x27;t work as well for most cases as targeting based on what you watched on netflix yesterday, googled last tuesday, and what products you had in your shopping basked last year but removed before you checked out. reply mrweasel 5 hours agorootparentI&#x27;d still love to see the statistics that shows that hyper targeted ads are more effective to any reasonable degree.What I&#x27;m currently browsing seems more relevant in many cases, as compared to which sites I visited last week. replymerdaverse 6 hours agoprev> The Norwegian Privacy Council&#x27;s decision is an instruction to the Irish Data Protection Authority to place a permanent ban on Meta&#x27;s European head office in IrelandIsn&#x27;t this going to be a problem? The Irish DPA has been known to be in bed with big tech in the past, considering Ireland&#x27;s entire economy is based around being a tax haven for Big Tech, and importing tech workers with the highest EU salaries taxed at 52% for the highest brackethttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230609051152&#x2F;https:&#x2F;&#x2F;www.irish... reply rambambram 7 hours agoprevI translated this text to English and what I don&#x27;t understand is they talk about the Norwegian Data Protection Authority, quickly say something about European Privacy Council, and then go on telling:> \"The Norwegian Privacy Council&#x27;s decision is an instruction to the Irish Data Protection Authority to place a permanent ban on Meta&#x27;s European head office in Ireland. Once this has happened, the ban will come into effect.\"Either Norway is banning something on their own, or they follow EU regulations, but I don&#x27;t think a &#x27;Norwegian ban gets extended to here and there&#x27;. I have the feeling stuff gets mixed up a little here. reply Joeri 7 hours agoparentThe holding company for Meta in the EU is located in Ireland because the double Irish system of accounting allowed them to avoid paying corporate taxes in the EU. (Not sure if this is still the case, I think they now always have to pay the minimum 13% rate.)I think any kind of enforcement against Meta has to go through Ireland because of that. The EU is a treaty, not a country. It is always local authorities that have to enforce legal action. reply rambambram 7 hours agorootparent> The EU is a treaty, not a country. It is always local authorities that have to enforce legal action.I know, that&#x27;s why the order of things mentioned in the article feels out of line. reply rusk 7 hours agoparentprevMy guess is they implemented EU policy (all states implement their owns laws to satisfy the various EU treaties) and they have notified the Irish DPC of their findings; and naturally expect Ireland to follow suit … reply dadadatamen 7 hours agoprevbehavioral marketing is about more than making money. you are nudging millions and billions of people in certain directions. It has completely changed majorities of brackets of the current and last generation.laws will not be enough to stop this reply Nextgrid 6 hours agoparentLaws may not be enough but it would be a good start at least. If that doesn’t work we’ll try something else. reply dadadatamen 3 hours agorootparentmy bad for not elaborating.we have always been dependant on whistleblowers and ethical hackers and now, for just a few years, we are at the tipping point where they are the last line of defence. Corruption has almost irreversibly disabled the playing field on which the civil society can act as a red team to corporate visions and strategies.Something else is always in attempt and laws are an absolute must but whether either of the many measures work, lies in the hands of whistleblowers and hackers. reply janandonly 7 hours agoprevMaybe this makes my ultimate dream come one step closer: paying for what I use (I still like to log into Instagram about once a month), without being tracked at all, and without having to watch any advertising at all. reply fsckboy 13 hours agoprevscandinavians are no different from other people, and changing the rules of advertising will not diminish Norwegian companies from wanting to advertise their goods.back in the 80&#x27;s Norway had a ban on cigarette advertising, so Marlboro launched a clothing&#x2F;lifestyle brand, blue jeans and other cowboy style clothes. With their competitors hobbled by the advertising ban, perhaps that was even more effective. reply __rito__ 8 hours agoparentIn India, you cannot directly advertise alcohol on TV.So, famous alcohol brands launched soda water, mineral water, and even glassware. One company has music CDs. They advertise those instead. reply Barrin92 12 hours agoparentprev>scandinavians are no different from other peopleHousehold consumption as a % of GDP in Norway is 30% compared to 68% in the US. The Norwegian public sector produces 70% of Norway&#x27;s GDP. You&#x27;re underestimating to what extent these policies reflect real differences in how countries are run. In the good old USA Facebook et al are allowed to do what they do because people keeping those credit cards busy is what keeps the economy up. Doesn&#x27;t work that way in Norway and a decent chunk of Europe. reply fsckboy 7 hours agorootparentNorway has a ton of publicly owned oil, on an industrial scale. You aren&#x27;t establishing that that isn&#x27;t the explanation for all of it.When Europeans come to the US, they largely behave like Americans, they fit right in. What Europeans need to stop doing is telling themselves that they&#x27;re different. reply martin8412 6 hours agorootparentA ton of oil they sell, but don&#x27;t spend the money from. The oil money is simply invested. They&#x27;re one of the largest funds in the world. The government of Norway can spend 3% per budget year under certain rules, but rarely do. The first time it ever happened was in 2016.When the oil runs out or demand for oil disappears, Norway won&#x27;t plummet into poverty unlike a lot of other oil rich countries. The oil certainly made them rich initially, but their reluctance to spend money derived from oil will keep them rich. reply avgcorrection 4 hours agorootparentTrue but frankly doesn’t matter to the online commentariat. Norway is a tiny country that most people don’t know anything about, but if they do know that it is an oil state then that becomes the explanation for literally everything. Even traits that are exactly like Sweden and Denmark are because of Oil.Disclaimer: guess my passport. reply avgcorrection 5 hours agorootparentprev> When Europeans come to the US, they largely behave like Americans, they fit right in. What Europeans need to stop doing is telling themselves that they&#x27;re different.America has military bases all over Europe. I’m going to arbitrarily decide that you need to establish that that doesn’t explain what you have been experiencing. reply tschwimmer 9 hours agorootparentprev70% seemed insanely high to me and so I checked this. It seems like the IMF has a similar (but not exact stat) that you quoted as 48%: https:&#x2F;&#x2F;www.imf.org&#x2F;external&#x2F;datamapper&#x2F;exp@FPP&#x2F;NOR?zoom=NOR...USA is 42% on the same measure. reply Barrin92 9 hours agorootparentGovernment expenditure is a very different metric as that&#x27;s just what the state spends, not how it generates its income. Which in theory could be almost entirely by the private sector. Here&#x27;s the US state department quoting the relevant reports (https:&#x2F;&#x2F;www.state.gov&#x2F;reports&#x2F;2022-investment-climate-statem...)\"The public sector accounts for nearly 66 percent of GDP. The Norwegian government is the largest owner in Norway, with ownership stakes in a range of key sectors (e.g., energy, transportation, finance, and communications)\"[...] reply Someone 15 hours agoprevNitpick: the title if this article currently is “Norwegian ban on Meta behavioral advertising extended to entire EU”Either “Entire” shouldn’t be there, as Norway isn’t in the EU, or “EU” should be “European Economic Area” (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;European_Economic_Area).My Norwegian is almost nonexistent, but I think it’s the latter. It makes more sense to my understanding of law (why else would a Norwegian claim extend to EU countries?) and the Norwegian title mentions “EU&#x2F;EØS”, and that matches the Norwegian name of that Wikipedia page (https:&#x2F;&#x2F;nn.wikipedia.org&#x2F;wiki&#x2F;EØS)If so, it also would apply to Iceland and Liechtenstein. reply bosse 14 hours agoparentYeah, the article refers to EU&#x2F;EØS which includes the non-EU members of the EEA, of which some union regulations may apply and be ratified into national law, like on food safety, energy markets or data privacy, while others can be vetoed and do not apply, like on fishing where Norway wants to control quotas in its own waters.Nevertheless, in cases where EEA countries are part of union law, decisions can be appealed to EU courts, and decisions there will apply to the whole area.At least I think that’s how it works, it’s a bit messy at times. reply finnjohnsen2 6 hours agoparentprevI agree it&#x27;s a bit sloppy but understandable (for me) since legislation&#x2F;directives is where we (Norway) is most aligned with the EU. As adapting EU directives is a part of the EEA&#x2F;EØS deal (with some exceptions).As for other central EU features like open market, currency, sovereignty (particularly naval), freedom of movement, we are on the outside of the union and I wouldn&#x27;t sloppily consider or phrase us an EU country. reply monosphere 14 hours agoparentprevYou&#x27;re quite right. \"extended to entire EU&#x2F;EEA\" would be more correct. reply mstade 14 hours agoparentprevI&#x27;m not norwegian but I can read norwegian fairly well and the article says the European Data Protection Board has decided that the norwegian ban should be made permanent, and expanded to apply to all of the EU and EEA. It&#x27;s a little light on detail, but that&#x27;s the gist of it anyway. reply Daz1 14 hours agoprevnext [99 more] [flagged] fsckboy 13 hours agoparent> Why are people so vehemently oppose to being shown ads that are actually relevant to them on ad-supported platforms?speaking only for myself, two reasons:1. they don&#x27;t show me relevant ads. I would honestly fill out surveys for them to show me relevant ads, but they still won&#x27;t, just like Netflix and Amazon won&#x27;t restrain themselves from showing me the same screens full of movies and TV that I will never watch. If they find out that I don&#x27;t want to drink sugarwater, I swear they will only show me ads for Pepsi, Sprite, etc.2. They&#x27;re addicted to hot javascript and flashing lights. If they&#x27;d just give me a short text blurb that says \"this podcast that you love is brought to you by X ice cream brand\", I&#x27;d buy that ice cream as thanks. But when they take over my screen and kill my right click menu, no.In a related way, some vlogger&#x2F;podcasters that I listen to who touch on controversial subjects have this elaborate \"we only advertise products that we ourselves use\" speech they give, and I&#x27;m thinking, hey, what about an advertiser that would say, \"we support free speech on both sides of this issue\". I&#x27;d buy their product in a second. reply xp84 10 hours agorootparent> hot javascript and flashing lights.I really don&#x27;t think we&#x27;re using the same Facebook. Facebook&#x27;s ads are tiles in the feeds, they&#x27;re very occasional ads that play after a video when you&#x27;re in their video section, they&#x27;re an occasional sponsored Reel that you can just swipe past, and they&#x27;re a 0.75cm tall strip of products (I get Nordstrom) across the bottom of a playing Reel. Of all the advertising platforms, this seems one of the most respectful of me. Compare this to YouTube&#x27;s unskippable preroll and mid-roll ads (though the cheap availability of Premium means you&#x27;re choosing to pay with your time instead of money so :shrug: whatever). And compare with any local or national TV news website and most blog-style sites, laden with fake malware ads, \"one weird trick for fat loss\" with disgusting body horror pictures. I really genuinely do not find Meta that bothersome compared to almost anyone else. reply fsckboy 7 hours agorootparentyou are on to something: I have never used Facebook even for a second, except to click inbound links and discover they won&#x27;t let me use Facebook without signing up. reply BirAdam 11 hours agorootparentprevThe one about pop is funny. I am quite fond of Pepsi Zero Sugar, and it’s the only one I don’t personally see ads for. Weird. Never thought of it until you mentioned it. I seriously see ads for Starry and Coke constantly. reply esafak 10 hours agorootparentIsn&#x27;t that the right choice for the advertisers? Pepsi knows you&#x27;re in the bag and Coke wants to change your mind.Try drinking Coke for a year to see if the advertisers flip :) reply fsckboy 7 hours agorootparentyeah, I&#x27;m not saying advertisers don&#x27;t know what they&#x27;re doing, just why I don&#x27;t want to watch their ads, which somebody up above called \"relevant\". reply PostOnce 14 hours agoparentprevNobody is opposed to relevant ads on TV (I mean, not any more than they&#x27;re opposed to ads in general).it&#x27;s the means by which they make them relevant.No one would be cool if Facebook sent agents to your home each night to rifle through your drawers to learn about you and \"tailor ads to you and make them more relevant\".That&#x27;s the problem, the data-collecting and spying. reply ninjin 14 hours agorootparentIndeed, \"opposed to relevant ads\" is just a rhetorical trick or misunderstanding of the \"opposing\" position, akin to: \"murdering babies\" for abortion, \"allowing criminals to go free\" for maintaining privacy standards, \"artists not getting paid\" for opposing \"modern\" copyright, etc. The truth of the matter is that many positions are far more nuanced and complex; all in shades of grey. reply mynameisash 13 hours agorootparentPoisoning the well: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Poisoning_the_well reply throw101010 14 hours agorootparentprevAnd the potential use of this data by governments around the world for less innocuous purposes than \"showing relevant ads\".It is not too surprising that companies who can profit from it push the data collection as far as they can. It is more surprising&#x2F;troubling how the people in general seem to either have completely capitulated due to the generalization of the data collection... or fail to understand the implications it can have.Thankfully some people in EU courts still think that privacy is a right. reply corbezzoli 13 hours agorootparentGot it, so why not outlaw that? For all we know, they can continue doing what but not show us relevant ads.I suppose twitter knows nothing about me and shows me stupid gaming ads all the time. I click on them exactly 0 times. Show me something relevant to what I see on HN and probably will even find it useful.If I can’t block all ads, at least show me something useful. reply chefandy 12 hours agorootparentWell, a good start would be a ban specifically on the behavioral advertising on Facebook and Instagram which in recent US elections exposed dangerous consequences when bad actors were thrown into the mix. Many people wrote millions of words about it over the better part of the past decade if you are inexplicably unfamiliar with the problem. The idea that anyone could effectively outlaw political influence by covert operatives directed by nation states is patently ridiculous, so you have to look at the mechanism they used to do it. And, voila! That&#x27;s the topic of this post. reply Daz1 7 hours agorootparentprev\"No one would be cool if Facebook sent agents to your home each night to rifle through your drawers to learn about you and \"tailor ads to you and make them more relevant\"Not sure why we need a bizarre analogy here? The actual premise is straightforward and doesn&#x27;t need abstraction. reply 2muchcoffeeman 10 hours agorootparentprevIt doesn’t even work. They steal all my data and ads and suggestions are still garbage. reply cheriot 13 hours agorootparentprevI don&#x27;t get the analogy. Facebook is using data you give them when using the app. How is that similar to invading your home? reply jpalawaga 13 hours agorootparentfacebook is using a lot more data about you than &#x27;when you use the app&#x27;.every share button on the internet is basically a tracking pixel. who asked for that? nevermind network effects. nevermind intrusive, subversive attempts at tracking like the SDK shenangians. nevermind contact book uploads.no, they&#x27;re not invading your home. Gathering information about you from friends who DID let them in? Rifling through your garbage? A chase car to surveil your movements? Perhaps those are more apt comparisons. reply password4321 12 hours agorootparentprevAlso offline:Facebook is combining the information they have with information from data collection companies like Datalogix, Acxiom, Epsilon, and BlueKai...way more than you&#x27;d think, including race, gender, economic status, buying habits, and morehttps:&#x2F;&#x2F;lifehacker.com&#x2F;how-facebook-uses-your-data-to-target... (2013) reply stubish 9 hours agorootparentprevFacebook is violating your right to privacy in both cases. You could voluntarily hand over your data or voluntarily allow them into your home. But the EU isn&#x27;t going to allow Facebook or anyone to force people to give up their rights. It is illegal unless Facebook also allows use without giving up their right to privacy. reply piva00 13 hours agorootparentprevNo, they&#x27;re using the data that FB trackers installed on pages to track conversion, display ads, etc. collects from you. Even if you do not use nor ever used anything produced by Facebook&#x2F;Meta. reply vivekd 13 hours agorootparentprevI donno, I know I&#x27;m in the minority but I agree with the parent. Facebook isn&#x27;t going to people&#x27;s homes and rifling through drawers. They&#x27;re using information people willigly share in their profiles.They&#x27;re not selling personally identifiable information. They&#x27;re selling generalized group info on categories people fall into for targeted ads.I don&#x27;t understand how this is a privacy violation or unethical. Especially given Facebook isn&#x27;t hiding what it&#x27;s doing, they&#x27;re open about what they&#x27;re doing. I assume the customers are informed and are consenting to this in exchange for free use of Facebook&#x27;s services.I think it was wrong for Ubuntu to sell user data to Amazon because their users weren&#x27;t informed. Some people choose Linux for privacy reasons and that trust was violated.No one who values privacy would willingly use Facebook. Facebook doesn&#x27;t hide what it does, it&#x27;s a consensual sharing of information. They even have a big button on their site inviting their users to try targeted ads. Everything they do is in the open. reply photonbeam 13 hours agorootparent> Facebook isn&#x27;t going to people&#x27;s homes and rifling through drawersWhen they start correlating with external payments sources they are reply fallingknife 8 hours agorootparentSeems like this is not a FB issue, but a payments industry issue. Payment data should absolutely be illegal for processors to sell. reply Nextgrid 6 hours agorootparentWhy not both? If someone is buying a firearm off the black market, the buyer is in the wrong but so is whoever is selling it to them without doing a proper background check. reply jurynulifcation 12 hours agorootparentprevlmao no, you&#x27;re either misinformed or a bad actor. when they start tracking me through services they don&#x27;t own, when they retain data on me indefinitely and purchase other data sources to do entity resolution, when they refuse to let me see what they have on me and refuse to let me set policies on what I&#x27;m comfortable with them having, when they partner with Walmart and CCTV providers to spy on me as I go throughout my business when they literally try to predict my behavior with the data they have on me, when they sell my data without my permission to God knows who... they&#x27;re filthy degenerate stalkers and anyone who works in the industry ought to be shunned by polite society. we should not suffer stalkers. reply BirAdam 11 hours agorootparentThey also build profiles on people who do not have Facebook accounts, and in that case they were absolutely never given consent. reply mjan22640 8 hours agorootparentprevStalking and cyberstalking is a criminal offense in many countries. reply vivekd 12 hours agorootparentprevI have a hard time believing Facebook is tracking it&#x27;s customers through CCTV.In any case even if they are I still don&#x27;t care because they&#x27;re not tracking me. Know why - it&#x27;s easy, I just don&#x27;t use Facebook. People who complain about Facebook collecting their information all the while continuing to use Facebook are not victims - they&#x27;re just complainers.If stopping it is as simple as logging off forever and people can&#x27;t even do that, I can only assume that they consent.People who want the government to step in to prevent something they could prevent by hitting a log off button...I don&#x27;t even know what to say about that.Besides even the criticisms don&#x27;t make sense - eg complaining that they won&#x27;t say what info they have while at the same time complaining about video tracking. How do you know they have that if you don&#x27;t know what they have? reply batch12 12 hours agorootparentThat&#x27;s not exactly true. Using tracking pixels and third-party scripts and cookies, it&#x27;s simple to track you as a unique entity. No logon necessary.A step further- associating this entity with your identity is trivial with access to additional information. For example, a tagged photo or contact info uploaded by the friend or family member who uses the same networks or devices you do.Maybe you have yourself sufficiently shielded and have excellent OPSEC. Can you reasonably expect the same from everyone else? Does not having the expertise to be as savvy as you justify being exploited? reply vivekd 11 hours agorootparentWell first if tracking and selling data on non-registered users really is that trivial then the issue isn&#x27;t Facebook it&#x27;s every website that could be doing this.Second more importantly privacy seems to be a watchword for tech people. Maybe people claim to care about the sort of privacy you are talking about when asked but their actions speak different. People use Facebook, google maps, leave location data on on their phones. Obviously people don&#x27;t value privacy as much as they do having access to certain tech. Sad but that&#x27;s the world, privacy seems to be a thing of the past.We can all opt out by not using these services. To the extent that we don&#x27;t there must be some extent to which we accept and consent to this tracking.I care because I&#x27;m afraid of my government and want to keep myself secure from them. I also realize that&#x27;s not the average person. My preference for privacy means not using Facebook it doesn&#x27;t mean I get to control how Facebook does business or how people choose to use it.My view is that ultimately people have to be responsible for the tech that they use and how they use it. We can&#x27;t just pass along that responsibility to government or business. reply mongol 11 hours agorootparentPeople do lots of things in lack of better options. Some things are too big or complex for an individual to change themselves, and people choose the less bad option, and live with the unwanted consequences.But through democracy, they can elect politicians that can create laws to give authorities tools to assert leverage. This is what we see in action here. reply jurynulifcation 11 hours agorootparentprevYeah I really don&#x27;t care about other people&#x27;s preferences and actions. I care about the fact that Facebook is stalking me through avenues I don&#x27;t consent to. I care about privacy. My actions match my preferences. They&#x27;re creepy stalkers for trying to follow everyone as hard as they try to. I&#x27;m not saying government should be involved. I&#x27;m saying we should fucking stop inviting adtech workers to Thanksgiving and birthday parties. We should make them outcasts for being creepy fucking stalkers. reply mjan22640 7 hours agorootparentprevMine phone number is mine. A friend who has my number in the contact list is not in the position to give consent to the number. They would need consent from the friend to read their contact list, and then consent from each person on the list, before they can legally use their number. reply jurynulifcation 12 hours agorootparentprevDo you visit websites that have a \"share on facebook\" button? They&#x27;re tracking you.Talk to people who have downloaded Facebook or Instagram to their phones? They&#x27;re tracking you.Have someone take a picture of you, even incidentally in the background in public, and post it to Facebook? They&#x27;re tracking you.They&#x27;re literally shameless stalkers who suck up as much data as possible through every possible avenue to do entity resolution to track individuals to the degree they possibly can.This is mass, corporatized surveillance, and we shouldn&#x27;t suffer it. reply vivekd 12 hours agorootparent>Have someone take a picture of you, even incidentally in the background in public, and post it to Facebook? They&#x27;re tracking youI would agree this is a big deal if it&#x27;s true but I haven&#x27;t seen evidence of it being true.The rest of your arguments ignore the human choice aspect. Facebook didn&#x27;t come pre-installed on my phone, I don&#x27;t think it came pre-installed on anyone&#x27;s.At the end of the day using Facebook is a choice. Nobody has to have Facebook. I get by fine without it, without instagram, WhatsApp any of it. These are things people willigly choose to use and give their info to.I think your arguments have weight only if their users are unaware of Facebook selling data to advertisers. You&#x27;d have to be living under a rock not to know that in 2023. I mean it&#x27;s not just a choice it&#x27;s an informed choice. reply jprete 11 hours agorootparentI think you’re ignoring things like tracking through share buttons and tracking pixels on third-party sites, which make it impossible for people to block FB’s spying except through extraordinary technical means, and also that Meta has had automatic face and identity detection for photos for a long time. replyreaperman 13 hours agoparentprevContent-based ads generally seem relevant to me. If I&#x27;m browsing small tech blogs, independent sex toy review sites, or mad scientist forums, I tend to get good static advertisements which aren&#x27;t targeted to me, but rather are just the ads that everyone who visits that site see. Those always seem to be relevant.The modern personally targeted ads are fucking terrible, excuse my language. They have a relevancy rate ofthey should show fewer ads that don&#x27;t fuck with our headsIf I&#x27;m shown an ad that caters to my taste in software and horror movies, I don&#x27;t consider that to be fucking with my head. reply qwertox 12 hours agoparentprevMy apologies to you, but last time I logged into Facebook through a VPN (my network has all the IP ranges of Meta blocked), which was about 1.5 months ago, I got served ads that were exactly the kind of thing I hate about when scum gets to publish advertising on a global platform without the platform checking it. These where among the first 5 ads shown.I made screenshots just to be able to show them to people like you.For context:Image 1 and 2 are successful and popular persons in Germany.\"He didn&#x27;t know his mic was on. Is his career over now?\"\"The scandal which is shocking the entire world, Stefan Raab didn&#x27;t know that the camera was filming\"Image 3: Attractive women with 6 fingers because they were made with Stable Diffusionhttps:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;tm3wQs2 (excludes 3rd image)https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;9Q9YI4b (requires accepting 18+, but it is sfw) reply allan_s 14 hours agoparentprevThe problem is that Meta collect so many data about you for that purpose. Data which then can be used for purpose we didnt accept in the first place. If you remove this kind of advertising you remove a big reason to collect and keep these data.\"Why people are so vehemently against leaving their door open for the amazon delivery guy to put the package they ordered indoor instead of outside in the rain, they pay for a safe delivery ?\"Because things that can be abused are abused reply tentacleuno 14 hours agorootparent> Data which then can be used for purpose we didnt accept in the first place.The obvious counter-argument is that, somewhere in the 100(+?)-page ToS, User Agreement, EULA, Terms and Conditions and Privacy Policy documentation, you did.We really need to make new laws to force companies to explain, in plain (terse) English, what they&#x27;re doing with our data -- everyone knows nobody reads those documents. reply andyferris 13 hours agorootparentWell, beyond that I might argue we really need regulations about what terms are legally and socially acceptable, and what terms are unconscionable.(EU privacy&#x2F;data protection regulations already have some of these, and they were violated by Facebook, which is what the article is about). reply analog31 13 hours agorootparentprevThey gather data on me, even if I didn&#x27;t sign up for their service. reply lazycouchpotato 10 hours agorootparentFor people looking for more information on this: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Shadow_profile reply troupo 8 hours agorootparentprev> the 100(+?)-page ToS, User Agreement, EULA, Terms and Conditions and Privacy Policy documentation, you didFacebook&#x27;s EULA is over four thousand pages long [1]. Burying info in a bunch of legal text does not constitute informed consent in the EU.[1] https:&#x2F;&#x2F;www.visualcapitalist.com&#x2F;terms-of-service-visualizin... reply f0e4c2f7 14 hours agoparentprevTargeted advertising creates an incentive to closely track and monitor users across the entire internet. This tracking data is then collated, packaged, and sold to various parties (advertisers, private intellegece companies, etc)Without targeted advertising this cottage industry and the associated data on people would not have as much of a reason (or any) to exist, improving privacy for the average person. reply TerrifiedMouse 13 hours agorootparentGoogle and Facebook probably don’t selling user information to others. Why would they? It’s their moat.From what I have heard, Google instead sells ad space in real-time with information about the viewer attached to the ad space - but not the identity of the viewer; real life, online alias, or otherwise. Advertisers then in real time bid for that ad space depending on whether they are interested in the viewer characteristics attached to it - it’s all automated &#x2F; done by preprogrammed bots. reply dyno12345 14 hours agorootparentprevFacebook 100% does not sell \"tracking data\" to advertisers or \"private intelligence companies\".I&#x27;d like to see an example of an ad platform that actually does this. reply andyferris 13 hours agorootparentI mean it doesn&#x27;t matter if its transferred or not, it&#x27;s the purpose the data is used for.One concept I&#x27;ve seen floated is separating the advertising markets from the user-facing services. As in DOJ&#x2F;antitrust legal seperation of Google, Facebook, etc into smaller entities.In that world Facebook-the-social-network-I-use company would need to send data Facebook-the-advertising-market company for each page load to request some ads to display. What data would be in that request? My reading of EU law is that such data couldn&#x27;t be personally identifying or of a private nature (so, like, 99.9% of what I do on facebook...). Features like time of day and language of user would be fine and appropriate - the sort of data used by TV networks to choose which ad to display on their broadcast.It doesn&#x27;t matter if you seperate the Facebook company this way, my understanding of EU privacy law is that they still can&#x27;t use your private data to augment the advertising part of the business when you were there to use the social network part of the business. (Note: the social network still provides user aggregation and has value to FB without any ad personalization). reply Hnrobert42 13 hours agorootparentprevThis article has a pretty good description of data brokers.https:&#x2F;&#x2F;clearcode.cc&#x2F;blog&#x2F;what-is-data-broker&#x2F; reply javier2 14 hours agorootparentprevIsnt that what they did for Cambridge Analytics? reply ensignavenger 13 hours agorootparentNo, Facebook didn&#x27;t sell them the data... they gave it to them... sort of. CA made a personality test, got users to take the test and grant them permission to use their Facebook data. So users gave CA the data. But, the data users gave CA also included data about their friend graph. CA apparently did not reveal what they were going to do with the data. It was also against Facevook ToS to use the social graph data this way. But CA did it anyway. So Facebook did not sell it to them, they just had an API that have the data away. In the wake of the CA scandel, Facebook shut down parts of their API that allowed this data to be obtained. reply asmor 13 hours agorootparentprevCA used a large variety of timewaster Facebook apps (Quizzes and the sort) to gain access to more user data than was likely ever intended, not just about the party that authorized the app, but also about their friends. They essentially extracted the entire social graph including likes and did all their extrapolation from there.It is more Facebooks inaction despite being aware of this rather than their actions. reply phyrex 13 hours agorootparentprevIt is not. It was a data breach: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Facebook–Cambridge_Analytica... reply sheepscreek 14 hours agoparentprevIt’s the difference between periodically requesting my inputs&#x2F;preferences compared to constantly surveilling my every move.The latter gives them constant unchecked access. It’s like handing someone a blank check instead of a check for a fixed amount. reply cheriot 13 hours agorootparentHow are they surveilling your every move? Every company has records of what we do in their app. How is using that data for advertising, \"constant unchecked access\"? reply mehlmao 13 hours agorootparentBecause it&#x27;s not just in their app. I do not have an account for any Facebook &#x2F; Meta product. I am still tracked by them across the internet, they still build a shadow profile on me based on photos and contacts uploaded by friends. There is no way for me to stop them. How is that anything but constant unchecked access? reply edgyquant 14 hours agoparentprevI love how these bad faith questions aren’t even tolerated here anymore. You know exactly why people aren’t comfortable with this, and if you weren’t a quick Google would enlighten you. But you 100% are. reply nonrandomstring 9 hours agorootparentIt&#x27;s most interesting which HN comment threads garner high quality analytical comments and which descend into chaotic bickering and hair-splitting.This is a particularly poor one.Someone mentioned \"poisoning the well\" earlier. I sense a lot of that and like you I am struck by the prevalence of whataboutism and bad faith questions in this thread, particularly low quality leading questions relentlessly sealioning in the credulous tone of a five year old child ;\"But mummy, why is it bad to stab someone in the face with a garden fork?\" reply eur0pa 8 hours agorootparentThey are poisoning the well. It&#x27;s worked for two decades on 4ch, it works everywhere else too. reply denlekke 14 hours agoparentprevi&#x27;m not sure i&#x27;ve ever seen an ad that i considered helpful, useful, or was grateful to seei get the dream and i buy things all the time but for me ads don&#x27;t make that buying experience easier because i dont trust any of the content in them so it doesn&#x27;t save me any time on researching what i want to buy. i&#x27;d rather have irrelevant ads because maybe they are easier to ignore and they won&#x27;t serve as a constant reminder of how much data companies have on me. seeing an ad for something i recently searched on a different company&#x27;s site generally makes me unhappy. reply xxs 8 hours agoparentprev>that are actually relevant\"actually\" stands as a weasel word here. Trying to use the internet w&#x2F;o an adblock is a daunting experience. When I have tried: I am, yet, to see a single relevant ad shown to me, it&#x27;s especially funny if you live in a country where you don&#x27;t speak the local language - the browser preferences&#x2F;headers(accept-language) are ignored altogether, so pretty much everything \"targeted\" is entirely useless.However, receiving an online invitations to learn that programming language is still funny enough. Car ads are funny too, especially if you don&#x27;t drive at all. Local pizza deliveries, when the same chain won&#x27;t deliver to the place you live (the IP location is pretty spot on). That kind of stuff: \"actually\" irrelevant. reply CapsAdmin 11 hours agoparentprevPerhaps a long shot analogy, but let&#x27;s say there is a trend to plan ahead and write everything you need to buy in the grocery store on a piece of paper. It works very well, shopping become more efficient and you don&#x27;t end up with items you didn&#x27;t plan for.The grocery store doesn&#x27;t like this and want to start making it illegal to enter the store with any notes.Their argument is that they have laid out the store in such a way that it expects people to get distracted and buy things they don&#x27;t need, so planning your trip to the grocery store harms their current way of doing things.To me at least, this sounds insane and extremely arbitrary. Arbitrary because it __feels like__ I can just keep the list of notes in my head instead. It also __feels like__ I&#x27;m being denied behaving in a certain way.Perhaps it&#x27;s a personality trait, but when something is this contrived it&#x27;s easy to feel vehemently opposed to this. reply frob 11 hours agoparentprevI love when ads mistarget me because I am then not tempted by them. I would much rather get my current untargeted swath of ads ranging from military contractors to industrial manufacturing supply chain equipment to bras for all sorts of body shapes to [checks random site] bulk supplies of the little adjustable knobs you put on the end of stool legs. I&#x27;m not tempted by any of those nor do I think about them after seeing them beyond a good chuckle like this. Now, if I were to be bombarded with ads for the new indy rougelike or rts or modular solar setup or self-mapping LED systems, those things would invade my thoughts and eventual actions. So, I block ads wherever I can and depersonalize them everywhere else. reply javier2 14 hours agoparentprevIts not the ads thaaat much. Its the absolutely obscene lenghts these companies have gone to to track every single detail you do over the entire web and connected it all, then they even sell this to third parties. I would be more open if the tracking was sandboxed to the current website and not used to create other businesses as well. reply 2c2c2c 13 hours agorootparent> then they even sell this to third partiesdo they? isn&#x27;t this the secret sauce? reply javier2 5 hours agorootparentThe AD targeting they sell is based on this tracking connecting you across sites reply dataflow 13 hours agoparentprevWhy didn&#x27;t you ask \"why are people so vehemently opposed to behavioral tracking\"? reply HDThoreaun 13 hours agoparentprevI don&#x27;t like being manipulated and targeting allows Facebook to better manipulate me. reply tomschwiha 8 hours agoparentprevFor me most of the time relevant ads are not relevant. If I visited a website about dogfood because I talked about it with friends I get constant ads about birdfood. But I don&#x27;t even have a bird. But I also don&#x27;t want to so transparent to share that information with someone random. reply farhanhubble 14 hours agoparentprevPersonally I&#x27;d either pay for a service or let it be ad supported and I prefer seeing high relevance ads only, which would require data like my IP, age, browsing habits etc to be factored in. So I prefer Google ads that are based on my searches to Twitter ads that always seem to sell some contraption with dubious utility.But ads can get ultra intrusive if you carry around tracking thingies like cookies and people have varying thresholds for what they consider \"personal\" information. reply honeybadger1 12 hours agoparentprevOh, you actually think it&#x27;s just about the ads, cute. reply bedobi 13 hours agoparentprevspeaking for myself, the ads i get are clearly very targeted but very rarely relevant, and sometimes distressingjust as an example, two random subjects i recently browsed online are taylor swift and over vs under breast implantsi can&#x27;t stand taylor swift, i just wanted to see what the fuss about her concert movie was about, kinda hoping it was panned (it&#x27;s not being panned)the over vs under breast implants was to settle a bet i had with my gf - she said her friend has under muscle breast implants, i didn&#x27;t believe her when she said that was a thing so googled and was proven wrongnow i&#x27;m being presented news articles and ads about both those topics, despite me having zero interest in either of them (and no, i&#x27;m not going to engage in some semantics about akshully i&#x27;m implicitly interested in them, otherwise i wouldn&#x27;t have googled them - i&#x27;m not, periodt) reply freetanga 8 hours agoparentprevThat is a biased question, similar to “why does Zuck insists on making money pushing teenagers to depression and suicide? Isn’t he rich enough?” reply m463 9 hours agoparentprevthat is not what ads are.Ads are surveillance of you to find out your age, income, sex, address, phone, behavioral characteristics, etc.Those characteristics are then sold to advertisers who bid to present ads to you.In other words, if you like lego, you will not see lego ads.Instead you will see water filter ads because they won the bid to serve someone with your characteristics, income, etc the advertisement. reply mbgerring 14 hours agoparentprevBecause the data used for behavioral advertising are sold widely and abused for purposes other than advertising, and because “advertising” also includes micro-targeted, personalized propaganda and misinformation that has, and will continue, to be used as a tool of authoritarian control and violence. reply mbgerring 14 hours agorootparentI would gladly fill out a form indicating what kinds of ads I would like to see. I do not want to be passively and pervasively surveilled for this. reply firecall 14 hours agorootparentIn a way, we used to actually do this by purchasing media!Positional Advertising in magazines worked perfectly well for decades, as an example.The canonical example being that if you buy a Car magazine, as an Advertiser I can assume you are a potential car buyer and therefore warmed up to see Ads about cars.The Digital Ad market is nonsense for many businesses: At one point Facebook Ads for Australia promoted a potential audience reach than was greater than the population of Australia.In smaller markets, Ad Targeting is often useless :-&#x2F; reply makestuff 14 hours agorootparentprevThis is what Google is trying to do with topics (https:&#x2F;&#x2F;developer.chrome.com&#x2F;docs&#x2F;privacy-sandbox&#x2F;topics&#x2F;ove...). Topics are supposedly the replacement after cookie deprecation, although the deprecation timeline continues to be extended. reply IG_Semmelweiss 12 hours agoparentprevbecause it takes control from our devices.in the past, we could tune out that channel with the remote.Tune another channel. Catch another show. And the original show would continue when you came back, even if you missed a few secsThe current setup does not allow this. We are losing ownership of our devices. reply ImJamal 14 hours agoparentprevI don&#x27;t think many people are opposed to relevant ads. What people are opposed to is tracking of behavior, interests, etc. If there was a way to get tailored ads without the privacy issues people wouldn&#x27;t be so opposed to it. reply polyomino 14 hours agorootparentSeems like people didn&#x27;t like Google FloC, it&#x27;s possible the implementation was bad, but I suspect people don&#x27;t like ads because the vast majority of ads are low quality. reply horrible-hilde 14 hours agoparentprevits the ads relevant to me I dont want and neither should you. Ads relevant to the content or site makes sense. reply matheusmoreira 13 hours agoparentprevBecause advertising and surveillance capitalism are inherently unethical and should be illegal. reply dottjt 13 hours agoparentprevAre there even people who like ads, period? reply changoplatanero 13 hours agorootparentof course there are. Instagram made a special feature so that people who wanted to just browse ads could do that. It was very very popular with a certain group of people. reply dottjt 13 hours agorootparenthmmmm when you think about, everything is an ad. Put more simply, everything is \"content\" and all content has an agenda.I guess an ad is just a particular type of content with a particular type of agenda. reply twelve40 13 hours agorootparentno it&#x27;s not. FB ads are force-fed content that nobody asked for. I&#x27;ll take a ad-free subscription service over that any day so I can keep my freedom to spend my attention on things I actually want, not someone else&#x27;s random garbage. Unfortunately, this arm-twisting ad-supported model is the only one available in the US on all socials, so I had to suffer through it because there is no choice, but now I&#x27;m pretty much out, I have no patience for this \"ads\" garbage anymore in my life. reply dottjt 13 hours agorootparentYou kind of went on a rant there. You didn&#x27;t really explain how ads aren&#x27;t a form of content. You just expressed how you don&#x27;t like ads. replyspeed_spread 12 hours agoparentprevYou use words like \"relevant\" but the real terminology that&#x27;s used in the ad industry is \"targeted\". If somebody pays for you to view it, you&#x27;ll view it, whatever you actual interests are. reply jmyeet 13 hours agoparentprevI don&#x27;t really get it either. I honestly think there&#x27;s a number of motivations.First, some people just don&#x27;t want to see ads at all. I&#x27;m sympathetic to this. I use ad blockers. I don&#x27;t feel bad about that. But it&#x27;s not really a reason to oppose contextual advertising.Second, a lot of people don&#x27;t really understand what targeted advertising is. I think some people think Meta or Google are selling a zip file saying \"Bob Smith of 1234 Main Street like Lego, trains and polyamory\" when an advertiser doesn&#x27;t actually care about you, personally. They care about an audience. This is a group of people with some defined set of characteristics like \"Men aged 18-35 that live in the Pacific Northwest and like fishing and hiking\". And they&#x27;re not selling that data. They&#x27;re selling access to people who match a profile.It&#x27;s a little trickier with third-party data services and cookie matching but all that really comes down to is the platform creates an ID for you and passes that to the advertiser so when they see you, they can build their own contextual data. That may sound nefarious but the ID is just a random string. It&#x27;s different for every advertiser so you can&#x27;t match across advertisers. Users can pretty much reset that ID at any time and all that matching data is effectively orphaned and lost.Now we can, should and have had conversations about what targeting is allowed. Generally, location can&#x27;t be too specific (eg typically only down to a city or town). There have been issues too with illegal discrimination (eg [1][2]).I also think we should generally ban all advertising to anyone under 18, targeted or not.So personally I see advertiser targeting capabilities not behavioural contextualization of preferences to be the issue to tackel.[1]: https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2022&#x2F;06&#x2F;21&#x2F;faceboo...[2]: https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2011&#x2F;aug&#x2F;24&#x2F;google-se... reply coding123 13 hours agoparentprevMake it relevant to the content presented, not the person that was tracked and followed around with cookies. reply johnwheeler 13 hours agoparentprevI’ve asked the same before. It’s the stupidest thing. It’s just another thing people collectively bitch about like “the government”. I don’t get it either. reply throwaway237289 12 hours agoprevnext [5 more] [flagged] seydor 9 hours agoparentBanning facebook would be a great thing for local replacements because it&#x27;s relatively easy to replicate and will re-create some online advertising business. Once the local startups take off there will be pressure to dismantle business-hostile aspects of gdpr to sustain it. EU completely submitted to american online superiority, but as china shows, protectionism can fix that. reply yowzadave 12 hours agoparentprev> You teach those filthy capitalists while you sit on a sovereign fund of oil wealth.Not sure how this is supposed to be a gotcha—a sovereign wealth fund is by definition socialistic? reply pb7 7 hours agorootparentThe point is they never learned how to create any value because they’re sitting on a goldmine. reply okr 7 hours agorootparentprevDirty oil money made you filthy rich, while destroying the environment. And from that pedastal you judge about other filthy capitalists. It is all a joke.(But, maybe you are right, hackernews is full of people saturated on a pedestal and judging from there with a socialistic mindset. Well, it is a virus, that takes on young people with yet underdeveloped brains. ;) reply make_it_sure 13 hours agoprevnext [4 more] [flagged] gherkinnn 8 hours agoparentIf those startups built anything that goes against GDPR then good riddance. reply janosdebugs 12 hours agoparentprevUS companies need to pay VAT when they sell to EU customers and EU companies don&#x27;t pay VAT when they sell to US customers, so that can&#x27;t be the reason. reply NorwegianDude 11 hours agorootparentThere is sales tax for US too, so where you are located does not really mater. Companies outside US pays sales tax in the US. reply personomas 8 hours agoprev [–] Totally insanity. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The European Data Protection Board has expanded a Norwegian ban on behavior-based marketing on Facebook and Instagram across the entire EU/EEA. This decision addresses illegal tracking, surveillance, and profiling on these platforms.",
      "Despite past prohibitions, Meta (formerly Facebook) has continued to handle user data illegitimately. Therefore, the board has forwarded this decision to the Irish data protection authority to enforce the ban on Meta’s European headquarters in Ireland.",
      "While Meta plans to secure user consent for data usage for behavior-based marketing in the future, it hasn't implemented any specific changes yet. The board also expressed skepticism towards Meta's suggested solution of charging users who refuse to consent."
    ],
    "commentSummary": [
      "The European Union has extended a ban on Meta's behavioral advertising due to its failure to ask for user consent and plans to charge users who opt out of data sharing.",
      "The ban remains in effect until Meta resolves these issues, prompting discussions on data privacy, ad-blocking impact and advertising effectiveness among users.",
      "The European Data Protection Board has temporarily banned Disqus from processing personal data in Norway, citing violations of the EU's General Data Protection Regulation (GDPR)."
    ],
    "points": 413,
    "commentCount": 226,
    "retryCount": 0,
    "time": 1698793811
  },
  {
    "id": 38089356,
    "title": "Jury Finds Realtors Conspired, Awards Nearly $1.8B in Damages",
    "originLink": "https://www.wsj.com/real-estate/jury-finds-realtors-conspired-to-keep-commissions-high-awards-nearly-1-8-billion-in-damages-b26f9c2f",
    "originBody": "SKIP TO MAIN CONTENT SKIP TO SEARCH Skip to... Select DJIA33207.33 points with a 0.47%▲ S&P 5004216.10 points with a 0.53%▲ Nasdaq12935.15 points with a 0.65%▲ U.S. 10 Yr32/32 with a 4.803%▲ Crude Oil82.63 points with a 1.99%▲ Euro1.0547 points with a 0.29%▼ Limited Offer: $1/Week Sign In SPECIAL OFFER English Edition Print Edition Video Audio Latest Headlines More World Business U.S. Politics Economy Tech Finance Opinion Arts & Culture Lifestyle Real Estate Personal Finance Health Science Style Sports REAL ESTATE Jury Finds Realtors Conspired to Keep Commissions High The National Association of Realtors and big residential brokerages were found liable for about $1.8 billion in damages By Laura Kusisto , Nicole Friedman and Shannon Najmabadi Updated Oct. 31, 2023 5:56 pm ET Share Resize 852 Listen (2 min) From New York to Austin, America’s biggest cities are littered with vacant plots of land. WSJ explains the unseen role property taxes play in the country’s housing shortage. Photo Illustration: Amber Bragdon KANSAS CITY, Mo.—A federal jury on Tuesday found the National Association of Realtors and large residential brokerages liable for about $1.8 billion in damages after determining they conspired to keep commissions for home sales artificially high. The verdict could lead to industrywide upheaval by changing decades-old rules that have helped lock in commission rates even as home prices have skyrocketed—which has allowed real-estate agents to collect ever-larger sums. It comes in the first of two antitrust lawsuits arguing that unlawful industry practices have left consumers unable to lower their costs even though internet-era innovations have allowed many buyers to find homes themselves online. Copyright ©2023 Dow Jones & Company, Inc. All Rights Reserved. 87990cbe856818d5eddac44c7b1cdeb8 Already a WSJ subscriber? Sign in To continue reading, choose an option below Create Your Free Account Register now to read this article for free. Register Now or Unlimited Access Subscribe to WSJ Today Just $1/Week for 1 year Unlimited access to world-class journalism Daily puzzles and crosswords Exclusive podcasts and newsletters You can cancel any time. Subscribe Now Already a subscriber? Sign In What to Read Next SPONSORED OFFERS TURBOTAX: Save up to $15 with TurboTax coupon 2023 THE MOTLEY FOOL: Epic Bundle - 3x Expert Stock Recommendations H&R BLOCK TAX: Get 20% off H&R Block tax software products TOP RESUME: Top Resume Coupon: 10% off professional resume writing EBAY: eBay coupon: Save 20% on purchases GROUPON: Up to $50 off any order with Groupon promo code MOST POPULAR NEWS Jury Finds Realtors Conspired to Keep Commissions High The Left Is Tearing Itself Apart Over Israel Israeli Airstrike Hits Crowded Refugee Camp in Northern Gaza This Year’s Hottest Investment Could End Up Costing You The Money Has Stopped Flowing in Commercial Real Estate MOST POPULAR OPINION Opinion: The Global War on the Jews Opinion: Black Lives Matter and the World’s Oldest Hatred Opinion: Benjamin Netanyahu: The Battle of Civilization Opinion: Biden Has a Spending Choice: Guns or Butter Opinion: A Big Legal Defeat for the Realtors RECOMMENDED VIDEOS The Wall Street Journal English Edition Subscribe NowSign In BACK TO TOP« WSJ Membership Buy Side Exclusives Subscription Options Why Subscribe? Corporate Subscriptions WSJ Higher Education Program WSJ High School Program Public Library Program WSJ Live Commercial Partnerships Customer Service Customer Center Contact Us Cancel My Subscription Tools & Features Newsletters & Alerts Guides Topics My News RSS Feeds Video Center Watchlist Podcasts Visual Stories Ads Advertise Commercial Real Estate Ads Place a Classified Ad Sell Your Business Sell Your Home Recruitment & Career Ads Coupons Digital Self Service More About Us Content Partnerships Corrections Jobs at WSJ News Archive Register for Free Reprints & Licensing Buy Issues WSJ Shop Facebook Twitter Instagram YouTube Podcasts Snapchat Google Play App Store Dow Jones Products Barron'sBigChartsDow Jones NewswiresFactivaFinancial NewsMansion GlobalMarketWatchRisk & ComplianceBuy Side from WSJWSJ ProWSJ VideoWSJ Wine Privacy NoticeCookie NoticeCopyright PolicyData PolicySubscriber Agreement & Terms of UseYour Ad ChoicesAccessibility Copyright ©2023 Dow Jones & Company, Inc. All Rights Reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=38089356",
    "commentBody": "Jury Finds Realtors Conspired, Awards Nearly $1.8B in DamagesHacker NewspastloginJury Finds Realtors Conspired, Awards Nearly $1.8B in Damages (wsj.com) 298 points by nerdo 20 hours ago| hidepastfavorite255 comments jsight 18 hours agoThe problem isn&#x27;t just realtors, it is that the whole system is designed to maximize transaction costs. Who cares how much the attorney and loan paperwork cost when they are only 1-2%, you are already paying 5-6% to realtors, ~.5-1% in repair costs, and often a part of the buyer&#x27;s closing costs too?But if you think about that wholistically, that means sellers are paying 8-10% of the cost of a house every time they sell!Surely that means someone could cut the cost in half and make a much more attractive platform, right? Opendoor comes kind of close, but they end up shouldering a lot of the risk of the transaction and therefore tend to lowball. reply conductr 18 hours agoparentMy problem has always been with the percentages used on certain things; like commissions. Just make it a flat fee. Things that require agent&#x27;s time like open houses; bill for that. It&#x27;s the essentially the same effort on a $100K house and a $500K house and a $1M house. Maybe once you get to $5M+ houses the fees need to increase since this is a different class of RE with much smaller pool of buyers. But still should be fixed amount and not percentages.In my area, since I bought my first house 10 years ago house prices have 4X&#x27;d. I don&#x27;t think the wages of most professions have, the demand for housing makes it easier to sell, so why should agents be making 4X more? reply sizzle 6 hours agorootparentThis was the business model for PurpleBricks that exited the US market after failing to disrupt the Realtor mafia in control. reply semiquaver 16 hours agorootparentprevIs there anything else in real estate that’s normally priced in terms of percentages other than the realtor cut? I’m not aware of any. reply lttlrck 15 hours agorootparentProperty tax. reply deelowe 10 hours agorootparentprevEverything is negotiable, but sellers often get asked to pay some portion of closing costs. reply salamanderss 17 hours agorootparentprevYeah it also causes the problem of making it a real pain in the ass to buy cheaper plots of land. Realtor often don&#x27;t give a flying fuck about the sale of stuff under 50k, not worth it for them. Can be hard to get representation. reply firstplacelast 2 hours agorootparentprevMaybe we should all learn from real estate agents and price our labor at a % of the median home price within 1 hour commute to our offices?While I do think RE agents are overpaid in expensive markets, I also kind of think...good for them. Pegging your wages to your most expensive living cost is a supremely intelligent move. reply notaustinpowers 18 hours agoparentprevA huge hurdle with trying to cut costs is because of NAR themselves, and local Realtor Associations. Any Realtor is with NAR and a local Association, which heavily restricts what they can do. Not being in a local Association can remove your access to the MLS, reducing your visibility to other agents, and remove your access to the state-specific legal forms.Add in closing attorneys and home inspectors being brought in-house to reduce costs, it can be a very expensive start-up cost that would require lots of capital to achieve. Zillow&#x2F;Opendoor got REALLY close, but they stopped (Zillow) or, like you said, lowball offers because they&#x27;re fronting all of the backend costs that used to be spread across 4 or 5 different services. reply jsight 18 hours agorootparentGood points. I totally forgot about the whole home inspection process and how ridiculous it tends to be. Even when they aren&#x27;t in house, you know it will be someone that the realtor has worked with before. It will certainly catch things because it has to demonstrate its value, and those things will be worth at least hundreds of $$s. Unfortunately, it will also offer no real guarantee that those things were worth catching or that other things weren&#x27;t missed.You are right, a party trying to fix this will need great funding, large scale, and they can&#x27;t be someone that will just sell out (ala zillow). With the NAR&#x27;s ability to block out parties that they don&#x27;t like, it might not even be practically possible. reply tylergetsay 18 hours agorootparentprevNot only everything you mentioned above -- the associations control access to the homes themselves reply notaustinpowers 18 hours agorootparentYup! Forgot to mention that. In my area, you have to be a member of the local Association & NAR to access the lockboxes. reply Willish42 17 hours agoparentprevDumb, uninformed question here, but are there not some sort of For Sale By Owner systems that cut into the huge percents in closing costs? Or is the issue that you have to pay the buyers&#x27; realtor fees too and that&#x27;s unavoidable?I&#x27;m trying to figure out why nobody&#x27;s figured out \"DIY MLS listing as a service without having to pay for a realtor\". Maybe everyone who does this just gets a realtor&#x27;s license or something. reply 404mm 17 hours agorootparentI’m not a realtor but I considered selling my home myself once. Two issues I hit immediately:1. I could not list the home in MLS as That system requires annual fees to use and you need to have a realtor license.2. You still need to pay the purchasing side’s realtor otherwise they will simply not consider your home for their clients. That’s 3% that’s hard to get any lower.I ended up negotiating my realtor’s selling fee down to 1.5% with the promise of using them for my purchase as well. reply macNchz 17 hours agorootparent> 1. I could not list the home in MLS as That system requires annual fees to use and you need to have a realtor license.Additionally, if you were to decide to list \"For Sale by Owner\" and market it yourself, you can submit it to the major aggregators (Zillow et al), but their contracts with the MLS systems often disallow them from mixing MLS and FSBO listings in the same search result set, so the FSBO listings are hidden behind a toggle or something and go unseen by the great majority of people browsing. reply photonbeam 13 hours agorootparentThat seems like something the government should stop reply Willish42 14 hours agorootparentprevaha, so THIS must be the real reason people like Redfin can make money off of giving you a \"digital realtor\" rather than FSBO uploads alongside the MLS listings. Makes sense, monopoly &#x2F; oligopoly working as intended. I knew there had to be a reason :&#x2F;Thanks for your reply reply pb7 16 hours agorootparentprevFurther blatant abuse of their monopoly. reply justinclift 5 hours agorootparentHmmm, sounds like a cartel that could be ripe for a bit of legal action. ;) reply bentt 53 minutes agorootparentprevIt&#x27;s almost entirely because entrenched interests (realtors, NAR) sabotage those efforts. The market has never had a chance to support any other approaches. reply cgh 17 hours agorootparentprevIt&#x27;s true that there&#x27;s scope for an alternate MLS that&#x27;s just for sale by owner listings. But as someone else mentioned, the buyer often uses an agent (I refuse to use the made-up word \"realtor\") and you&#x27;ll have to pay that fee anyway. Unless, that is, your listings site provided handholding to do away with the buying agent. To handle the paperwork, a notary and&#x2F;or a lawyer is necessary but the site could either provide those services for cheap or detailed instructions on how to proceed if you want to use your own notary&#x2F;lawyer. It&#x27;s simple enough. It turns out that the main function of a real estate agent is to simply ferry paperwork back and forth between the clients and the lawyers. You can just as easily do this yourself (we did and saved a lot). reply lelanthran 7 hours agorootparent> It&#x27;s true that there&#x27;s scope for an alternate MLS that&#x27;s just for sale by owner listings. But as someone else mentioned, the buyer often uses an agent (I refuse to use the made-up word \"realtor\") and you&#x27;ll have to pay that fee anyway.Maybe I&#x27;m misunderstanding how this works.With (often) the seller holding a lot of the cards, they could simply insist that any buyer pay their own agent, or buy elsewhere.If the demand is even minimally high it wouldn&#x27;t take a lot of sellers to cause people looking to buy to avoid signing on with an agent just to find a house. reply leephillips 12 hours agorootparentprevI sold a townhouse in DC using a company that listed in the MLS for a flat fee (I think it was about $200). I held my own open house and got my target price from a buyer I met there. He did have an agent but I told them I wasn’t paying any commission. The agent thought I didn’t know what I was doing and tried to sneak a commission onto the sales contract. Typical real estate agent behavior. (I had sold and bought a few houses before, using agents, so I was familiar with the process, and aware that the agents added no value.) reply nwellinghoff 11 hours agorootparentBy what method did he try to sneak a commission in? What it something obscure that you have to know to look for or? reply leephillips 9 hours agorootparentShe just put it right there in the contract, despite our verbal agreement that it would not be there. When I objected she made a show of having made a “mistake”. Quite crude, in fact. reply fshbbdssbbgdd 8 hours agorootparentIt’s surprising to me that the buyer’s agent would even consent to produce a contract that doesn’t pay them any fee. reply jsight 12 hours agorootparentprevA lot of buyer&#x27;s agents fastidiously avoid FSBO properties. reply wanderingstan 12 hours agorootparentThe first home I bought was FSBO—but I only found it because it was across the street from an agent-listed house! reply OJFord 17 hours agoparentprevThe problem is &#x27;buying agents&#x27;. Looks totally bonkers from over here (UK, I think it&#x27;s foreign to at least most of Europe too). reply aeternum 17 hours agorootparentYes, this is where the collusion comes in. Many seller agents will simply ignore buyers without a buying agent. reply lloyddobbler 17 hours agorootparentIn the U.S., at least, I&#x27;ve never known a seller&#x27;s agent to do that (having done a good number of real estate transactions). In fact, in my experience I find it to be the exact opposite. Seller&#x27;s agents are incentivized to not work with buyer&#x27;s agents, if the situation arises where they&#x27;re approached directly by a buyer.If the seller&#x27;s agent is comfortable acting as the intermediary, and recognizing the limits of conflict of interest, then it&#x27;s in their best interest to keep all of the 6% commission instead of giving half of it to the buyer&#x27;s agent. reply fatnoah 16 hours agorootparentCorrect, and this is something I&#x27;ve used to my advantage before. It&#x27;s not a huge one, but when all othet things are equal... reply tootie 16 hours agoparentprevPaying a percentage to realtors is just theft. They add so little value in my experience. The fact that a fee can be split between two brokers or kept by one just shows they are extracting rents for ambiguous value. reply kelnos 17 hours agoparentprevYep. And a lot of it is of dubious value; I think for many (most?) properties, title insurance is a scam. Most houses, especially those built (or at least having changed hands) in the last, oh, 50 years (or more?) should be fine.It also just seems kinda dumb that realtors get paid a percentage rather than a flat fee. On the buyer side, it&#x27;s essentially the same amount of work to help someone find and buy a $200k house as it is for a $1M house. For the two properties I&#x27;ve purchased, things moved so quickly that I don&#x27;t think the realtors had to do all that much. Conservatively, the first one made at least $2k&#x2F;hr, and the second at least $1k&#x2F;hr (and I&#x27;m probably underestimating there). I&#x27;m not saying their services weren&#x27;t valuable -- they certainly were -- but I can&#x27;t see most people agreeing to pay that rate if it were presented to them that way.And I&#x27;m not convinced there&#x27;s all that much of a difference on the seller side, either. The staging is going to cost more for a larger&#x2F;nicer house, but the sellers are paying separately for the staging anyway. I was also reading somewhere recently that orgs that control access to the MLS will not even allow you to list if there&#x27;s no buyer&#x27;s realtor&#x27;s commission, and there&#x27;s a floor, like it has to be at least 2% or something.From the buyer&#x27;s perspective, I really liked Redfin&#x27;s pre-pandemic model, where they&#x27;d give you part of the buyer&#x27;s commission as a \"refund\", because their realtors are salaried. I assume they figure out from the traditional commission how much they need in order to pay their own operating costs (plus whatever profit margin they&#x27;ve decided to take), and then give you the rest. Of course, they stopped doing that during the pandemic, and now pocket the entire buyer&#x27;s commission.Granted, the realtors we&#x27;ve worked with through Redfin were hit-or-miss. One we worked with was fantastic and knowledgeable, and helped a ton, but another (in a different region) let us put an offer on a home that we wouldn&#x27;t have been able to rent out legally in the way we wanted to, which is something she absolutely should have known (a non-realtor friend alerted us to the issue; fortunately we were able to rescind the offer before it was acted upon). I haven&#x27;t listed anything on Redfin as a seller, but they charge 1% of the sale price, which is a lot better than the 2.5%-3% traditional realtors take. Still, the percentage model seems unnecessary there too; the amount of work needed to sell houses of different values shouldn&#x27;t necessarily be directly linked to the eventual sale price.> But if you think about that wholistically, that means sellers are paying 8-10% of the cost of a house every time they sell!I can only assume this also is part of our housing affordability issues. Sellers need to see some minimum amount of appreciation (and a fairly large amount at that) in order to break even (without even taking inflation into account), so homes sell for higher than they would otherwise, especially in markets where sellers have the upper hand. reply frumper 16 hours agorootparentTitle insurance is often required by the lender. If I loan you a boatload of money, I want to make sure there isn&#x27;t any funny business about who owns what when you buy that the borrowed money. If there is funny business, that why I want you to have bought the insurance. Seems as reasonable as home owners insurance on a mortgaged property. reply pxx 16 hours agorootparentLenders could internalize this risk, which is miniscule. But mortgages in the United States are a subsidized product. The real problem is that the lender wants to sell the note to Fannie&#x2F;Freddie, who require title insurance.Title insurance is a total scam. Title insurers pay 3-6% of their premiums in claims [0]. Compare to auto insurance, which is ~80% [1], or home insurance (~50-70%) [2].[0] https:&#x2F;&#x2F;www.ceicdata.com&#x2F;en&#x2F;united-states&#x2F;title-insurance-in... [1] https:&#x2F;&#x2F;www.insurancejournal.com&#x2F;news&#x2F;national&#x2F;2023&#x2F;05&#x2F;12&#x2F;72... [2] https:&#x2F;&#x2F;www.spglobal.com&#x2F;marketintelligence&#x2F;en&#x2F;news-insights... reply frumper 11 hours agorootparentYou really haven’t added anything. You’ve just restated that people that own the mortgage want title insurance to protect them. It isn’t for the home owners protection. It’s the same with PMI. That’s another insurance the lender requires a buyer to purchase to protect them.Title insurance is relatively cheap compared to home or auto insurance. It’s a one time purchase cheaper than the 6 month premium of either of the others. reply nrb 7 hours agorootparent> You really haven’t added anything.Are you intentionally glossing over that it could&#x2F;should cost less than 1 month of premiums of either of the other types of insurance? reply frumper 1 hour agorootparentThey aren&#x27;t saying it&#x27;s priced a little too high, they&#x27;re saying it&#x27;s a scam. Compared to those other insurances, it&#x27;s very cheap. Over a 30 year mortgage you&#x27;ll pay tens of thousands of dollars in home owners insurance. For title insurance you&#x27;ll pay a few hundred dollars for the average house. For my house, which is close enough to the national average, it was about 2 months worth of home owners premiums. replystuff4ben 20 hours agoprevCommission based on home value is a joke. Realtors should earn a flat-rate. reply ejb999 20 hours agoparentI agree - especially for the last few years, when in order to sell a house all you had to do was put in on the market - and then get 10-15-20 offers at or above listing price - no agent deserves a 6% commission for simply getting something listed on zillow or MLS where in recent years, the houses just sold themselves. reply judge2020 19 hours agorootparent> no agent deserves a 6% commission for simply getting something listed on zillow or MLSTypically 3% is seller agent commission and 3% is buyer agent commission - although in the paperwork it&#x27;s most likely 6% to the seller&#x27;s agent and the seller&#x27;s agent offers 3% to the buyer&#x27;s agent.Although 5% total &#x2F; 2.5% to each realtor is becoming a bit more popular as of recent, based on the listing I browse. reply Spooky23 19 hours agorootparentRemember there’s no professional responsibility for realtors, so they do shady shit like shop the house internally to keep the full 6%. reply poulsbohemian 18 hours agorootparentI encourage you to report any behavior you believe to be illegal or unethical to both your local realtor association as well as your state agency. That’s why those organizations exist and we are all better if people are held to professional standards. reply the_optimist 17 hours agorootparentIs there a practical way to diligence theoretically unethical behavior? reply refulgentis 17 hours agorootparentParsing the question as:- a broker with a client who is selling- to pitch buying to another broker who has a client who is buying- and for the brokers to work for the same companyI don&#x27;t think so? It sounds obviously ethical reply Spooky23 1 hour agorootparentMore like the selling realtor “forgetting” to take a call from a competing buyers agent and keeping it in-house. It happens all of the time and cost the sellers money.There’s also many scenarios where real estate folks steer certain ethnicities or religious practitioners away from some areas. reply judge2020 1 hour agorootparentAs said earlier, any and all discrimination is illegal&#x2F;unethical and there are checks in place to prevent it from proliferating. Anyone who is a victim can report a HUD fair housing complaint form, contact their local state&#x27;s office of fair housing, or contact their local Association of REALTORS® to report an ethics violation.And people do report:> The most important finding of this report is that the number of housing discrimination complaints increased significantly in 2021, despite the fact there were fewer agencies reporting complaint data. There were 31,216 housing complaints in 2021, an 8.7 percent increase over the number of complaints filed in 2020. At the same time, there were seven fewer agencies that reported data in 2021 than in 2020. Had all fair housing agencies been able to submit their data, undoubtedly the number of reported fair housing complaints would have been even higher.https:&#x2F;&#x2F;nationalfairhousing.org&#x2F;wp-content&#x2F;uploads&#x2F;2022&#x2F;11&#x2F;2... replyscarface_74 19 hours agorootparentprevYou choose the buyers agent. reply tssva 16 hours agorootparentprevI don&#x27;t understand why people don&#x27;t negotiate more on this. I paid 3.5% total commission (1.5% listing and 2% buyer agent) on the last 2 homes I sold. One in 2012 and one earlier this year. In both cases the homes sold quickly and above asking. reply scarface_74 19 hours agorootparentprevThat’s only true if you are in a competitive market. There is a whole swath of land in flyover country and rural America where it can take awhile to sell a house. reply hotnfresh 18 hours agorootparentOutside cities, yes, but there also aren&#x27;t many houses there.In flyover country, in the cities, it&#x27;s been \"OMG, this house just came on the market four hours ago... quick, send a full offer! Damnit, they already sold it for $20k over asking, again?!?!\" for years, only letting up recently.[EDIT] And I don&#x27;t just mean like Chicago and Minneapolis, either—any metro area a million or larger, it&#x27;s probably been like that, and even in some of the smaller ones. reply jsight 18 hours agorootparentprevIs that still the case? I feel like rural markets have really boomed in the last few years. At least I&#x27;m seeing that in the southeast. Maybe \"flyover country\" is different. reply scarface_74 12 hours agorootparentRural America I mean rural GA, FL, AL, MS. reply pc86 19 hours agorootparentprevI mean yes, it&#x27;s sort of tautological that if you are trying to sell a home in a place very few people want to live, it might be (but isn&#x27;t by definition!) harder to sell than someplace where a lot of people want to live. reply zone411 18 hours agoparentprevCommissions for the seller&#x27;s relator are fine, but they shouldn&#x27;t be based on the full price of the house. This setup encourages quick sales rather than getting the best price. Instead of the realtor earning 3% on a $1,000,000 house, set a base amount at, say, $700,000 and calculate the commission only on the remainder - 10% on $300,000. The same principle should apply to the buyer&#x27;s agent but in reverse or there should be a flat fee. Their current incentive structure is totally screwed up. reply Kirby64 20 hours agoparentprevYou can. It&#x27;s just a bit of a racket (hence, conspiracy judgment) and nobody will work with you if you only offer a flat rate. Since MLS is mostly limited to Realtors in most markets, you&#x27;re basically locked out from posting there.There&#x27;s ways around it, and flat fee brokers that exist, but you hamper your sales ability. Not an issue when its a sellers market, but can be rough in a buyers market. reply bluGill 19 hours agorootparentThere are flat rate realtors where I live. However they are only 50%, the still give the same 3.5% to the buyers agent, but they take for themselves a fixed rate to get you on MLS. I&#x27;m not sure if it is a good deal - they still charge high prices relative for what they do for you. (it is cheaper than a full agent, but they also do much less) reply Kirby64 18 hours agorootparentYou just don&#x27;t sign a contract where you give a buyers agent commission, although again this limits the pool. Frankly, buyers agents are largely a scam in my view. With MLS, Zillow, Redfin, etc, their &#x27;experience&#x27; seems mostly worthless. It certainly is not worth 3% of the cost of a house.If anything, sellers agents are more useful since they actually offer something valuable to the real estate experience (e.g., listing housing, photos, providing buyers access, etc). reply bluGill 18 hours agorootparentBuyers agents know better how to search the MLS system (though only a few do this). They also line up times to see houses, and take time to drive you to each. So a good buyers agent has spent about 8 hours of time to each buyer, plus expenses. I agree they are getting far too much, but they still are valuable. reply Wytwwww 17 hours agorootparent> but they still are valuable.All of those things seem to be pretty simple and worth barely of fraction of $2000 per hour (if they actually only spend 8 hours in total? I mean at that point it might make sense to spend 40-80 hours to do the same things yourself instead depending on your income). replymynameisash 19 hours agoparentprevI expect that when it comes time to sell my house, I&#x27;ll hire a real estate attorney to make sure all the paperwork is in order, and I&#x27;ll deal with the rest myself. I engaged an attorney when I bought my house, and she was super thorough. reply sct202 19 hours agorootparentAttorneys are so ridiculously cheap compared to the realtors. In my area there are discount real estate attorneys that will do sales&#x2F;purchases for $200, and the normal price is like $500 which is nothing compared to the real estate agents getting like $10k on an average home in the area. reply PaulDavisThe1st 19 hours agorootparentprevI&#x27;ve sold 4 houses \"by owner\". I didn&#x27;t even use an attorney for 3 of them - just a title&#x2F;escrow service who take care of handling the deposit, filing the deeds after the funds transfer is complete etc. reply ejb999 19 hours agorootparentbuying a house, I would want an attorney - selling the house, I agree, no need for a realtor or attorney if you are willing to do a bit of work yourself. reply staticman2 18 hours agorootparentWhere I live, the real estate agents association has model home sale contracts and it&#x27;s not common or necessary for a buyer to have an attorney. reply SoftTalker 19 hours agorootparentprevSame. It&#x27;s all very standardized and the title&#x2F;escrow company does it 10 times a day and will handle all the paperwork and filings. reply alok-g 2 hours agoparentprevShould it be the same for income tax too? Let&#x27;s think through why exactly it be based on income? (Genuinely saying.) reply fma 19 hours agoparentprevAgreed. Add to the fact if you&#x27;re a seller agent the money is easy. A buyer&#x27;s agent struggle. AFAIK usually you start out as a buyer&#x27;s agent and build up a network&#x2F;reputation before people trust you to sell.In a seller&#x27;s market, seems like a buyer&#x27;s agent should be compensated more because it&#x27;s more difficult to win bids now. reply scarface_74 19 hours agorootparentNot every inch of America is in such a competitive market. reply sahila 17 hours agorootparentSure, but then the logical step is to compensate for the realtors time as opposed to some national average. reply exmicrosoldier 10 hours agoparentprev\"Stock options are a joke. Developers should just get a flat fee.\"There are people worth their commission and there are people who are not worth it.The bigger reason house prices are so high isnt the real estate agent cartel, it is the banking cartel and the capital chasing homes to rent them out. reply m463 9 hours agorootparentI think a better analogy would be \"stock sales are a joke, you should be able to sell them for a flat fee\" reply balderdash 19 hours agoparentprevI’d be willing to pay a percentage above some predetermined price (e.g. if the realtor produces some sort of above market outcome) - but agree, that the value provided does not equal 3-6% of home value reply wbsun 18 hours agoparentprevI have always been wondering what kind of work a realtor needs to do for selling&#x2F;buying a $100M mansion and ended up with $5M commission… reply plagiarist 17 hours agorootparentNepotism, same as every other million-dollar job. reply bozhark 19 hours agoparentprevBrokers do, 1.5% from seller and buyer.Don’t use realtors. reply poulsbohemian 20 hours agoparentprevSo negotiate that with your agent if that&#x27;s what you prefer. reply poulsbohemian 19 hours agorootparentSo why downvote me? We&#x27;ve got this already in our buyer&#x27;s agency agreements - if you as a buyer want to negotiate compensation with your agent, you have the ability to do that. Similarly, in both states where I work, you as a seller have had the ability to choose what, if any, compensation you want to offer to a buyer&#x27;s broker. None of this is actually that different from how you negotiate (or not) with any other professional - your lawyer, your accountant, your financial advisor, etc. reply conjecTech 19 hours agorootparentNegotiation is not an effective strategy when there is active collusion to fix prices. You are commenting on a story where a jury just found that had been systematically done. reply staplers 19 hours agorootparentprevDid you forget the context of the article? reply onlyrealcuzzo 19 hours agoparentprevIf you&#x27;re selling a $2M house, you&#x27;re willing to pay more for someone to get you a good price.On the flip side, no one is going to pay $5k to sell a $30k house.Flat rates don&#x27;t make sense. Maybe you think the percentage is too high. reply losteric 17 hours agorootparent> If you&#x27;re selling a $2M house, you&#x27;re willing to pay more for someone to get you a good price.That sounds very last-century... kinda like selling antiques to a pawn shop or consignment store that would take of finding a buyer.Why does discovery and bidding justify $200k in overhead for the $2MM property? Why does a person need to go out and \"find a buyer\"?Without this Realtor conspiracy, surely something like Redfin meets eBay would be more efficient? Posting online is what the cast majority of realtors do anyway, they don&#x27;t actually \"find\" buyers... At least until you get to 1%er prices where golf club chats matterHeck, this racket gates even access to standardized legal forms that states themselves should freely offer. reply ska 18 hours agorootparentprevMaybe the percentage should be laddered, or there should be a floor. reply plagiarist 17 hours agorootparentprevThe incentive for the agent selling the $2M house is to price it to sell so they can move on to get their cut of the next $2M sale. reply seattle_spring 17 hours agorootparentprevnext [–]min(5000, House.price * 0.03) reply Xeoncross 18 hours agoprevReal Estate in the US is like a bunch of little MLS fiefdoms still angry you have access to the internet.Eventually the Real Estate market will adopt like the music industry and others had to. Welcome to the 21st century.Brokers and agents are mostly sales people that drive around showing places. Its the lawyers, inspectors, insurance underwriters, loan originators, and title companies that do the real and&#x2F;or legal work.It&#x27;s time for broker&#x2F;agents to take a more fitting role instead of charging 6% for posting cell phone pictures of your house on their regional MLS. reply Root_Denied 18 hours agoparent> Its the lawyers, inspectors, insurance underwriters, loan originators, and title companies that do the real&#x2F;legal work.And they get paid a flat rate to do that work (hourly or per contract). There should be no reason for commission based compensation for brokers and RE agents in the residential market. I could see an argument in the commercial market for it though. reply brentm 18 hours agoparentprevThe music industry didn&#x27;t have a patch work of local laws protecting it&#x27;s thiefdom, unwinding Real Estate is a much more difficult challenge. If it was not I think we would have seen some real inroads by now, it&#x27;s obviously a massive market. reply harrisonjackson 18 hours agoparentprevInspectors maybe since they go on site and climb around etc... but every other profession you listed uses the same documents&#x2F;software for every single deal so I don&#x27;t know what you mean by \"real\" work. reply scottwick 19 hours agoprevNot really related to the article but something I&#x27;ve been wondering...In recent years the housing market has been so competitive that escalation clauses are often written into offers. They typically include a base offer of $X and then an agreement to escalate that value by increments (maybe $1-5k at a time) up to some cap. All the offers are collected by a certain date and then an auction is run behind the scenes by the realtors involved.What&#x27;s to stop a seller from having one of their friends enter into one of these escalations? Submit a non-serious offer with a high escalation and include a minimal deposit which would be forfeited if that fake offer happens to win but otherwise hope it comes in 2nd to push everyone else&#x27;s escalation up. reply SLSMan 2 hours agoparentI had an escalation clause in my offer, but I adjusted it so it said something to the effect that the clause would only be in effect for comparable offers. Then I defined comparable offers to be offers that were for the same type of loan with a minimum down payment and deposit amount. I wanted to protect against the buyers getting a higher offer that they were likely to reject on some other basis, but using that higher offer to make me pay more for the house. The downside was that I could be beat out by other legitimate buyers whose escalation clause didn&#x27;t consider the quality of the offer they were beating. I cared more about not feeling like I was being swindled though. I got the house after about a $10k escalation, and the seller&#x27;s agent presented the competing offer so I could verify it met the conditions of my escalation clause. reply FireBeyond 19 hours agoparentprevVery little. When I was younger growing up in Australia, auctions were very common, and it was very much the \"traditional\" model, everyone stands around in front of the property and puts up their hand to bid.Regularly auctioneers would get caught taking bids from trees or vehicles to push prices up. They&#x27;d get caught when their fake bid was the highest. It became so common it was almost expected, and reforms to the process had to be introduced. reply bitbckt 18 hours agorootparentThis is called \"chandelier bidding\" in industry parlance. reply tehlike 19 hours agoparentprevsadly the answer is honor code.There are also a lot of shenanigans realtors could be pulling.Example: Few years ago, we wanted to buy a house, we made a bid for 2.6, the realtor said they would not accept anything less than 2.8 as this was their competing offer. We said no, the house sold for 2.4. I suspected the realtor might have been double dipping, or bluffing, i don&#x27;t know. But what I do know is they did not present the offer to the seller.(numbers are not exactly precise, but directionally and somewhat magnitude wise, it should be similar). reply bravoetch 19 hours agorootparentI had a similar issue. A put a full price cash offer on a place for 1.9. The seller said they had a competing offer that was higher and asked me to submit a new offer at 2.1. I declined, and said they are welcome to provide a written counter offer at 2.1. The reason they won&#x27;t counter is that a new higher offer from any buyer (me) will trigger escalation clauses for other buyers offers. Dirty trick that screws over buyers, because sellers can see all offer details. reply FireBeyond 19 hours agorootparentprev> But what I do know is they did not present the offer to the buyer.I believe in most states a real estate agent (I despise &#x27;Realtor(TM)&#x27;) is obliged to present an offer (at least by the Realtor&#x27;s Code of Conduct&#x2F;Membership Agreement).Edited to add: I&#x27;m not sure if this refers to seller agents (who cannot hold back an offer from their client), or to buyer agents, presenting that to the seller side, or both. I think at least the first. reply nordsieck 19 hours agorootparent> I believe in most states a real estate agent (I despise &#x27;Realtor(TM)&#x27;) is obliged to present an offerSure. But enforcement is the soul of the law.And it&#x27;s pretty tough to catch stuff like that. Most people who put in offers and don&#x27;t \"win\" aren&#x27;t sitting around monitoring how much the winning bid ended up being. reply tehlike 19 hours agorootparentExactly. In my case, I thought of finding the seller after sale was final, and ask if their agent presented my offer. He&#x27;d then maybe sue their agent.I didn&#x27;t care enough to pursue that route. reply weeblewobble 18 hours agorootparentprevMaybe there was something else unattractive about your offer and the 2.8 fell through? Happens all the time.When I sold a house recently I took the second highest offer, because the highest offer came from someone out of state who had never set foot in the house reply crazygringo 1 hour agorootparentI don&#x27;t understand, why was that a motivation for not taking the highest offer?Is that associated with some kind of risk of the sale not closing, or other risk?(Sorry if it&#x27;s a dumb question with an obvious answer -- this is not my area of expertise.) reply tehlike 17 hours agorootparentprevRealtor definitely didn&#x27;t mention anything, but mentioned a higher offer, which definitely didn&#x27;t end up happening.It was a standard bay area offer - 20% down preapproval, no contingency, 4 weeks close, and could have been shorter. reply MikeTheGreat 19 hours agoparentprevThis is just my understanding, but here goes:1) If your bid wins then you&#x27;re on the hook to buy the house. Part of the offer your make includes \"earnest money\" which is that deposit you&#x27;re talking about (which you forfeit if you don&#x27;t actually buy the house). The seller sees all the offers so presumably you putting down $500 earnest money on a $300K house would look suspicious enough to get you ignored by the buyer.2) However, you&#x27;ve got a bigger issue: it&#x27;s a secret auction. You put in your bid&#x2F;offer, and so does everyone else, but _nobody_knows_about_anyone_else&#x27;s_bid_. Heck, you don&#x27;t even know how many other people are bidding. You _may_ be able to ask your realtor to nicely ask the seller&#x27;s realtor for a general description of how hot the listing is (which works in the realtors&#x27; favor - the hotter the listing, the more you&#x27;ll anticipate needing to bid), but beyond that you don&#x27;t know about the other bids. And you for sure don&#x27;t know about the specific, bogus bid that the realtor&#x27;s friend put in to influence all the people that don&#x27;t know about the bogus bid :)I might be wrong (realtor&#x27;s friend puts in a bogus bid so the seller&#x27;s realtor can lie and say the listing is hot, after your realtor asks them about it), but I don&#x27;t think this is a strategy that will work in general.Legal context: United States reply scottwick 19 hours agorootparent> putting down $500 earnest money on a $300K house would look suspicious enough to get you ignored by the buyerAssuming you mean the seller here? If I were the seller I too would ignore that kind of offer but first I&#x27;d let it push all the other escalation clauses up ;) reply hammock 19 hours agoparentprevYou can ask to see the other offer if the escalation clause is triggered. It technically has to be \"bona fide\" reply teen 18 hours agorootparentThis happened to me in 2019. I went into escrow and they didn&#x27;t give me the offer for about 5 days. When I finally got it, it was lower than it should have been. It rubbed me the wrong way and I bailed out of the deal. reply scottwick 18 hours agorootparentHow did you bail without losing your deposit? I would have thought if you were the highest bidder you&#x27;d either be on the hook for the full purchase or lose your deposit. reply userinanother 18 hours agorootparentIf the escalation was fraudulent then you can bail. reply scottwick 19 hours agorootparentprevDo you see the deposit amount and all the details of the escalation from the triggering offer in that case?Say I saw that the triggering offer had a measly deposit and I suspected it of being fake. Would I be on the hook to prove it? Technically if I rescind my offer at this point I lose my own deposit, right? reply teen 18 hours agorootparentYes but they can drag their feet in giving it to you, since they can just sign your offer immediately. However, you can just cancel your offer after with a follow up document. reply taude 19 hours agoparentprevI think a lot of the escalations involve more than just one other person bidding, so you&#x27;d really need to be running a good game to get three or four people involved to run up a price in something like this.Additionally, in a competitive market, with multiple offers, people aren&#x27;t doing a bare minimum deposit. More like 30 - 50K is involved based on my experience, but it varies dependending on state.... I&#x27;m currently looking in a new market, and we were told our offers should have about 10 to 30K on them between Due Dilligence and Ernest money....Besides, it&#x27;s just easier for the seller&#x2F;buyer agent to have a conversation on which buyer wants it the most. reply roshin 10 hours agoparentprevIt doesn&#x27;t seem unethical, just weird. The seller can just require a higher starting bid, the result would be equivalent. Of course the risk would be that no one would buy the property if the price is too high. reply koolba 19 hours agoprevGood for them. On the list pointless middlemen, they’re definitely at the top.One of the dumbest parts of the real estate commission scam is purporting the lie that “the seller pays the commission”. Anyone with half a brain knows that if money is coming out of a transaction, it’s a transaction cost being eventually passed onto the buyer. reply senorrib 19 hours agoparentAnyone with microeconomics knowledge would tell you that it depends on the elasticity on each side of the transaction. reply pxmpxm 15 hours agorootparentSomeone took econ! reply Spivak 12 hours agorootparentprevSee: Doordash, Amazon, Apple, Visa, ... for seller side elasticity.See: Ticketmaster for buyer side elasticity. reply loosescrews 18 hours agoparentprevI think this assumes that the price of real estate is set by the post-fees price that sellers receive. I don&#x27;t think that is true.I think the strongest factor in real estate pricing is what buyers are willing to pay. In some cases that is influenced by how much the buyer was able to keep after selling a previous property, but I don&#x27;t think that is the most significant factor.Another factor that influences the sale price is the psychology surrounding the pre-fee sale price. Many sellers become fixated on a particular sale price. A common strategy for getting a lower effective sale price is getting sellers to include more in the sale price. One particularly notable example is seller financing. reply fsckboy 18 hours agoprevmy beef with the commissioned agents is that paying them a commission does not actually influence them to work on your behalf; they still work on their own behalf. For example, keeping your house for sale on the market longer (by rejecting offers) tends to eventually bring a higher price. A study or two has shown that real estate agents keep their own houses on the market for longer than average.But longer on the market is more work for the agent, while the small percentage increase in a higher price doesn&#x27;t enhance their commission by nearly as much as it does the homeowner&#x27;s, especially considering there is frequently a substantial mortgage on the house (meaning, the homeowner gets to collect the \"bank&#x27;s share\" of any additional sale price)but what will your realtor recommend? \"list it at a low price to generate interest and start a bidding war\", pretty much the opposite of what you should do.In the grand scheme of things, a commission for making a large, complex selling process go smoothly is not a ridiculous notion, but when your agent is participating in plucking your feathers it&#x27;s pretty annoying. reply ajhurliman 18 hours agoparentYou’re not forced into taking any deal you don’t want to; your real estate agent can’t accept deals without your consent. I agree, agents are usually more focused on deal flow than particular outcomes, but it’s sort of a fundamental issue with agency in general.A software consultant is more focused on you signing off on the work than your bottom line, it’s hard to get people to not act in their best interest, and for the average person the home buying&#x2F; selling process is probably too complicated for them to navigate without going through some training.I think the biggest reform that could be passed is to disentangle NAR and MLS. reply fsckboy 17 hours agorootparentwhen I am paying somebody handsomely for their domain expertise, I don&#x27;t want to become as educated as they are in order to evaluate what they throw in front of me. I want advice that I can trust from a fiduciary. reply userinanother 18 hours agoparentprevThe incentive is to close the deal asap the extra 100k for the seller isn’t much for the realtor reply semiquaver 19 hours agoprevAlso known as Sitzer&#x2F;Burnett. Docket at https:&#x2F;&#x2F;www.courtlistener.com&#x2F;docket&#x2F;15018641&#x2F;sitzer-v-natio... reply karaterobot 17 hours agoprev> For several years NAR has been fending off accusations by U.S. antitrust officials and private litigants that it has conspired to keep home-sale costs high in the face of major technological upheavals. This verdict is by far the group’s biggest setback yet.Buying or selling a home involves paying numerous middlemen thousands of dollars without having a clear idea what value they are providing in the process, except that if you don&#x27;t pay them, you can&#x27;t pay the next person in the line. Burn that whole industry to the ground as far as I&#x27;m concerned. reply poulsbohemian 19 hours agoprevHere&#x27;s the brief response I offered earlier today when asked what this actual does:I don’t really expect significant changes. We are in a more balanced market today than when these lawsuits were first filed. Many sellers will find it advantageous to offer buyer agent compensation. If&#x2F;when we return to a seller-advantaged market, some buyers may need to pay their agents directly, which could involve rolling those costs into their financing. Lenders are more of an expert than myself on any issues in doing that, but it appears to happen in other states already. One of the problems of these lawsuits is the conflation of agency with payment. States - both WA and OR, for example - are working to fix the agency problem that wasn’t made explicit to buyers post-subagency. But, I don’t think there’s any question that buyer’s having to directly pay buyer’s agent compensation will be a higher cost to buyers. reply briffle 19 hours agoparentA bit part of the lawsuit, was that the buyers agent compensation was ONLY visible on MLS to other registered agents.So, when you were looking online, you had no idea if the houses you found where offering 3% or 1.5% buyers agent commission, but your agent was, and could steer you to the higher paying homes. reply riku_iki 19 hours agoparentprev> Many sellers will find it advantageous to offer buyer agent compensationso, now conspired realtors charge seller and not buyer. Still looks broken. reply poulsbohemian 19 hours agorootparentI guess you aren&#x27;t familiar with this having been the system in most markets for decades? reply manuelabeledo 18 hours agorootparent> I guess you aren&#x27;t familiar with this having been the system in most markets for decades?Definitely not in most markets. This is very unique to the US.Also, what&#x27;s the advantage of paying someone whose goals don&#x27;t quite align with yours? And isn&#x27;t it a massive conflict of interest? reply jjoonathan 18 hours agorootparentprevBroken systems linger despite themselves all the damn time, are you really suggesting otherwise? reply closewith 18 hours agorootparentprevThe system as described is nearly unique to North America. It takes a particularly distorted and unregulated market to allow this kind of anti-competitive structures to arise. reply riku_iki 19 hours agorootparentprevyour guess is incorrect reply alwa 19 hours agoparentprevI’ve never been involved with residential real estate in the US, so forgive me if I’m missing something obvious.Why will it be a higher cost to buyers? At the macro level, aren’t the transaction costs effectively priced in? Is the idea that the home has some absolute value that exists independently of the cost structure of the market it trades in (so the buyer paying commission directly is doing so “on top of” this amount as it’s valued under the status quo)?Is it mainly a question of categorizing the commission as “a cost” rather than “hidden in the seller’s asking price therefore part of the value of the home”?Otherwise, why wouldn’t the buyer who now says “I have $100,000, so I’ll buy a $100,000 house” instead say “I have $100,000, and I know my agent is going to charge me around $3,000, so I’ve got to buy a $97,000 house instead”? If that becomes the new norm, wouldn’t all sellers find that people who could buy at $100,000 before can only buy at $97,000 now, and have to price their homes accordingly, making it a wash?If it were me, I feel like I’d want to hire my agent at a flat rate if I could, to reward them for finding me a better deal rather than incentivize them to make more by selling me more. But then again maybe that’s part of the higher cost to buyers that you mention: maybe there’s no question that buyers’ agents will be able to squeeze the buyers for more commission directly than they presently get out of the sellers? reply ajhurliman 18 hours agorootparentIn the US the seller pays for both the listing agent as well as the buyer’s agent. When you list your house, you agree to a commission for your listing agent and you advertise a commission to co-broke on the MLS listing, which entices buyers agents to show your house (or steer buyers away from it if the commission is low).I think the biggest impediment to driving down costs to the consumer is the momentum of social convention.Even for agents at fixed-cost brokerages, they know they can charge 2-3% so they do, and most people don’t know that it’s negotiable. reply bogota 19 hours agoparentprevHonestly just going to do a FSBO if i ever sell. The fact that I pay out 5% of my house price for what is essentially a few hours of data entry work is beyond stupid. reply loosescrews 19 hours agorootparentYou will likely still need to offer a buying agent commission if you want buying agents to show the house. Still, that cuts the fee roughly in half.At least some selling agents do a lot more than data entry. They generally pay for photos, staging, and landscaping while the house is on the market. They also research similar houses to position the property in the market and talk to buying agents. A lot of the negotiation can happen before the offer.You can do most if not all of that yourself and you may do a better job than the real estate agent you would have hired. Doing a good job is a fair amount of work. Most real estate agents cost the same amount, so there generally isn&#x27;t a price different between a good and a bad agent (unless you count the commission on a higher sale price). If you can find a good one, it is likely worth the cost. A bad one might even decrease your sale price though.Do you think you can do a better job selling your own house than you can do at hiring a real estate agent? reply sp332 19 hours agorootparentprevWhen we bought, the seller&#x27;s agent apparently spent a good chunk of her fee on little scent dispensers. We were finding those things tucked behind cabinets for months. reply poulsbohemian 19 hours agorootparentprevSo go for it! If you believe you have the ability to market your house successfully, then by all means do so. As a realtor, if I had a house in a market where I don&#x27;t do business, there is absolutely no bloody way I would try to sell my own home. reply flkiwi 18 hours agorootparentThe concern is perhaps less one’s ability to “market” a house better than a realtor than it is whether the realtor’s services, both individually and as a combined effort between buyer and seller agents, is worth anything remotely like the fees charged. The answer is clearly no to the latter.With prices where they are today and the combination of effort and skill demonstrated by the realtors I have worked with—each of whom was highly regarded—I would give them perhaps a 1% commission split between them. In all but the most unusual cases, even that would be an overpayment at a reasonable hourly rate for their education and skill level. reply georgeecollins 19 hours agoparentprevThis seems like a very disingenuous interpretation of the verdict by avoiding \"what it said\" and then telling us what will actually happen (as though you can predict) or what&#x27;s wrong with it. If I were a realtor what is wrong with it is it could threaten my fat commissions.What the jury said was that the national association of realtors colludes to keep agent fees high in a way that violates anti-trust rules.(edited for grammar) reply poulsbohemian 19 hours agorootparentDude - any realtor paying attention has been watching this (and other) cases now for years. You think we haven&#x27;t been monitoring this along with state legislation, Congressional action, MLS rule changes, and all the other things that have potential legal impact to our business and our clients? NWMLS (for those of you in WA) made rule changes over a year ago that were good changes regardless of the outcome of this case, plus the legislature made clarifying agency changes that go into effect in January. We&#x27;re not the trolls you all think we are. reply closewith 19 hours agoparentprevI think this is unimaginative. More than likely, eventually the US will join most of the world in having no buyer&#x27;s agents and low seller&#x27;s agent commissions. reply briffle 19 hours agorootparentat 6% of the median 500k for a house, they have about 30k reasons to fight that tooth and nail.. reply bozhark 19 hours agoprevRealtors are a scam.Use brokers, fixed 1.5% from both sides to the same person. reply r00fus 18 hours agoprevI&#x27;m just as worried about the conspiracy among landlords to ratchet up rents and home sale prices.https:&#x2F;&#x2F;www.propublica.org&#x2F;article&#x2F;yieldstar-rent-increase-r... reply albroland 20 hours agoprevhttps:&#x2F;&#x2F;archive.ph&#x2F;Ahzio reply 1vuio0pswjnm7 16 hours agoprevThe opinion:https:&#x2F;&#x2F;ecf.ca8.uscourts.gov&#x2F;opndir&#x2F;23&#x2F;08&#x2F;222664P.pdf reply toomuchtodo 20 hours agoprevRelated: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38088740 reply osigurdson 17 hours agoprevIf you think about the problems to solve in a real estate transaction are roughly as follows:Seller problems: 1) Maximize selling price 2) Minimize damage to property &#x2F; theft 3) Minimize cleaning &#x2F; preparation for showingsBuyer problems: 1) Minimize purchase price 2) Minimize number of hidden problems with houseOne would think that realtors might help to maximize selling price but their incentives are much more aligned with selling a property quickly as it is less work that way. For the most part, they solve seller problem #2 by acting as a kind of well dressed (and likely not very tough) security guard.The pricing problem could arguably be solved by having something along the lines of a Dutch auction. Many of the uncertainties (largely not addressed with the current system) could be solved via insurance. reply a-posteriori 20 hours agoprevDoes anyone know what this actually means for real estate brokerage fees?There are few markets which have supported 3-5% brokerage fees (even i-banking ismaximizing the value of their client&#x27;s home by reducing the commission the seller pays.Selling a house quickly (convincing the seller to take a qualified and likely-to-close offer) still dominates as a strategy over eeking out a few extra points of contract price. As an agent, taking 1.25% or 1.5% of a $950K sale quickly is way better than holding out for a $1M offer.The difference in commission at 1.5% on a $50K delta in sales price is $750. Freeing up your time to work on the next listing is more valuable. reply efitz 19 hours agorootparentI always thought the right strategy would be to have a sellers agent contract that was tiered, eg agent gets 1-2% of selling price up to average comps, and then 20% of excess selling price over that. Maybe a bonus or penalty for timing, to prevent waiting forever for a good offer. reply notaustinpowers 19 hours agorootparentprevThe main issue with that possibility is many brokerages (at least ones in my area) do not allow a Seller&#x27;s Agent to reduce their commission without prior Broker authorization. Regardless of what the Seller themselves wants. So while that deal may be advantageous for the Seller (sell quickly) and the Agent (get the deal over with and move on to the next), the Broker is the one getting paid a lower sum and will not allow that contract to be ratified. reply sokoloff 19 hours agorootparentNothing in my comment is about changing the percentage of the commission. (The 1.25% or 1.5% is simply the listing agent&#x27;s personal split of a 5% or 6% total commission [whichever is customary in the local area]). reply notaustinpowers 19 hours agorootparentSorry, I didn&#x27;t explain enough. The total commission remains 6%, but if the Seller&#x27;s Agent split is only 1.25%, the Seller Agent&#x27;s Broker (most likely) will deny that as the Broker would receive a reduced cut of the commission.The Seller and the Seller&#x27;s Agent may be cool with the reduction, but the Broker would ultimately have the final say since it&#x27;s, legally, their contract. reply sokoloff 19 hours agorootparentAh. I’ve never seen a percentage-based commission divided unequally into the four parts: agent and brokerage crossed with listing and buying.I have seen 6% (1.5% x 4) and 5% (1.25% x 4). reply notaustinpowers 18 hours agorootparentYeah, it&#x27;s usually unequal in the area I used to work in. The Agent&#x27;s have their own agreements with their Brokers that are independent of any sale&#x2F;purchase they work on. I&#x27;ve seen everything from 50&#x2F;50 all the way to 90&#x2F;10 (10% to Broker). replyjfk13 19 hours agorootparentprevThese US fees always seem astonishingly high to me. Here, something more like 1.5% would be typical. reply notaustinpowers 19 hours agorootparentYeah, it is very high. Although, the real estate industry in the US is vastly different.- Agents do not receive salary, benefits, etc. Their only payment is when they close a deal. - Real Estate Agents are a dime a dozen since the licensing and training is pretty minimal. So lots of competition fighting over small supply, so it can be difficult to consistently get clients. - Agents can pay around $100&#x2F;month to their Brokerage for E&O insurance, maybe access to legal forms, and a Broker for questions&#x2F;insight. So they start spending money from the get-go. - Agents, typically, pay all expenses related to the job (advertising, signage, listing fees, etc). reply jandrese 19 hours agorootparentYeah, it&#x27;s tough on both sides. Competition is fierce for leads, but the rates have to be sky high to support the enormous mass of realtors. If the fees drop a lot of people are going to need to find new jobs. reply flkiwi 18 hours agorootparentIf competition is fierce for leads because there is a glut of workers due to nearly zero requirements to become one, one would expect rates to plummet. Which, I suppose, is why we have a collusion situation here. reply manuelabeledo 18 hours agorootparentprevThis reads like the reason why one shouldn&#x27;t become an agent in the US. It&#x27;s honestly hard to feel sympathy for people who are basically gambling their professional careers on the real estate market. reply jjtheblunt 19 hours agorootparentprevFor what definition of \"Here\"? reply jfk13 18 hours agorootparentUK reply rubymancer 20 hours agoparentprevNothing yet. I&#x27;d imagine it will go through appeals for a few years before anything actually happens, and U.S. antitrust enforcement has not exactly been a powerful force for the last few decades. reply bozhark 19 hours agoparentprevNothing over 1.5%.Ever. reply thedougd 12 hours agoprevI’ve had success a few times with flat fee agents. $1000 to sell plus the buying agents 2.5-3%. Their argument was compelling, it’s not as much work to sell a house in the Internet age. reply denton-scratch 19 hours agoprevhttps:&#x2F;&#x2F;archive.ph&#x2F;Ahzio reply IronWolve 16 hours agoprevThey are also doing the same thing with apartment rents by all using the same rent pricing company that keeps raising rents across the city. It&#x27;s all collusion to raise prices. reply WalterBright 18 hours agoprev> by making it difficult for buyers and sellers to negotiate for lower rates.I&#x27;ve negotiated lower commissions with real estate agents. They always say it&#x27;s non-negotiable, and always cave. reply elyobo 19 hours agoprevUS fees seem very high; Australia & New Zealand have a selling agent fee in the 2-3% range (+ variable vendor paid advertising on top) and buyers agents are uncommon so not a fee most pay at all. reply underseacables 14 hours agoprevI&#x27;ve had very good experiences with realtors. reply rubymancer 20 hours agoprevThere&#x27;s not much to the article.> KANSAS CITY, Mo.—A federal jury on Tuesday found the National Association of Realtors and large residential brokerages liable for about $1.8 billion in damages after determining they conspired to keep commissions for home sales artificially high.> The verdict comes in the first of two major antitrust lawsuits that target decades-old industry practices and seek to drive down commissions and change the way agents are compensated. The two-week trial involved claims by home sellers in several Midwestern states. The jury issued its verdict after just hours of deliberations.> Under antitrust rules, the presiding judge could triple the damages verdict, which would total more than $5 billion. The plaintiffs also have asked the judge to order changes to how the industry operates.> For several years NAR has been fending off accusations by U.S. antitrust officials and private litigants that it has conspired to keep home-sale costs high in the face of major technological upheavals. This verdict is by far the group’s biggest setback yet.> An NAR spokesman said, “This matter is not close to being final as we will appeal the jury’s verdict.”I would love for there to be some sort of competition injected into real estate commissions. I&#x27;ve bought and sold twice now and you get the same rate from everyone (within 1%) regardless of what they end up doing. reply RHSeeger 19 hours agoparentI bought a few years back and we didn&#x27;t really use an agent to find the house at all. Looking into it, I found that a certain percentage of the sale amount goes to pay the agent(s); 6% I think. If there are two agents, they each get half. If one person doesn&#x27;t use an agent... the other person&#x27;s agent gets it all. The person without an agent doesn&#x27;t get to keep their half... it just all goes to the other agent. Wtf...So anyways, we wound up bringing in an agent to help us out with the last bits, because we had to pay the money anyways, it might as well go to someone that helped us in some way.The real estate process is fairly broken, as far as I&#x27;m concerned. reply conductr 18 hours agorootparentTechnically, the 6% goes to the Seller agent. They promote on the listing how much they&#x27;re willing to share with the Buyer&#x27;s agent; half is customary but not set in stone.There are agents for your situation. They&#x27;ll collect the 3% (or whatever it is) and rebate it back to you at or after closing; less some fixed fee ($600 in my experience). They are not going to do much for you, but if you already found the house yourself and are familiar with the buying contracts&#x2F;process. It&#x27;s an option that can save you a lot.This may differ by state of course. My experience is limited to Texas. But I&#x27;ve bought and sold property using these type of agents. When selling, you just do all the work (hire a photographer $200-500, write the description $0+, and they load it to the MLS for you as the listing agent). I&#x27;m of the opinion that for most properties, the only value added marketing is the MLS. When they talk about their websites and portals and ads they run in print media I roll my eyes. reply philips 17 hours agorootparentIn Oregon it is illegal, by statute, to give a refund to a real estate client. reply nicholasjarnold 18 hours agorootparentprevI used an attorney specializing in real-estate to represent our side of the house during my first home purchase. We subsequently reduced the bid by 3% with an explicit note about why (no buyer&#x27;s agent commission to pay). The seller&#x27;s agent was a broker and was apparently motivated because they accepted our deal along with fixing a list of little items uncovered during inspection. We paid our lawyer a $2-3k iirc.I&#x27;ll never know if that broker got 6% from the seller or took 3% to close the deal, but our strategy worked: I paid 5 figures less for the home than what was being asked for at a time when houses were selling for over asking price in this area.It&#x27;s worth a shot I guess. 2 warnings: Some seller&#x27;s agents will get very pissed at you (b&#x2F;c this and other things like Redfin&#x27;s 1% is disrupting their cash cow and they&#x27;re not stoked about it). It might be difficult to find an attorney since most RE attorneys focus on commercial deals. reply cgh 17 hours agorootparentSame, we used a notary public for most of the paperwork and a lawyer for a bit of it. I think I calculated that we saved around $20,000. reply trey-jones 19 hours agorootparentprevIt&#x27;s like this throughout the real estate and real estate development industries to be honest. Building my own house I expected plenty of savings over buying (and to be fair, I still did of course), but even beyond permitting (which is also more about who you know than what you know) I encountered things like this (roughly from most mind-boggling to least):- You can&#x27;t build a septic system, you have to use sewer because you&#x27;re in city limits (later rescinded when they realized they would have to pump my sewage up to the city sewer.- You need to hire an engineer to make sure your lumber is ok (we milled our own lumber)- You need to hire an architect to make sure your plans are ok- You didn&#x27;t finish in 6 months? Buy a new permit please.I know there were a million more things like this, but it&#x27;s been over ten years and some things you don&#x27;t want to remember... Contractors act like I&#x27;m taking food out of their kids&#x27; mouths by wanting to do the work myself, and the municipality is on their side. reply LeafItAlone 18 hours agorootparentYour list of “mind-boggling” items all seem extremely reasonable to me.Your city and neighbors don’t want to be responsible for or have to deal with your house falling down because it was improperly constructed. And having lived in neighborhoods with septic systems most of my life, a little neglect can go a long way.Unless you’re building in the middle of nowhere (far from anything labeled a “city”), there are obligations to those around you.Signed, someone whose neighbors properties have dilapidated buildings in various states of disrepair. reply Turing_Machine 17 hours agorootparent> Your city and neighbors don’t want to be responsible for or have to deal with your house falling down because it was improperly constructed.Why on earth would the city or the neighbors be \"responsible\" for that? reply autoexec 17 hours agorootparentIf my neighbor doesn&#x27;t wire their home to code and it burns down and the fire spreads to my house it doesn&#x27;t matter who is \"responsible\", I&#x27;d still lose my stuff (or my life).Hell, if my neighbor&#x27;s tree falls into my property and causes damages I can&#x27;t be sure I&#x27;d be fully compensated for my losses. You can take someone to court, but they can&#x27;t give you what they don&#x27;t have.People also just don&#x27;t want to live in slums filled with run down barely standing shacks since it hurts their property value too. Part of living in a community means giving consideration to other people around you. The closer you are to others the more responsibility you have to be considerate of your impacts on those others. reply salamanderss 17 hours agorootparentHow many lives of man hours are lost from overhead for these costs and compliance? The issue is people enforcing these regulations see the dead bodies from the burned out home but not the dead bodies of the homeless or the kids with less food or the dude with untreated cancer because regulatory costs and materials safety margins sucked away money that could&#x27;ve been spent on other life critical things.At this point it seems completely plausible more lives would be saved through complete deregulation including setting loose uncle joe the methhead electrician.RE:>cities to turn into dangerous shanty towns where anyone who can lean a piece of corrugated sheet metal against a mud pile can call themselves a home builder.My whole county did this. No inspections or building plans. It turned out fine. I became a legal &#x27;home builder&#x27; with nothing more than filing my signature with the county. It&#x27;s the only way I can even afford a house.re county: believe the options are unincorporated burrows of Alaska, greenlee or cochise Arizona, Jackson Wayne and several other county in Tennessee, bunch of others. reply autoexec 16 hours agorootparentIf kids can&#x27;t get food that&#x27;s a problem entirely separate from the costs of an electrical inspector. No one builds a house and then becomes homeless because of how much it cost to make sure it was up to code.I&#x27;d agree that those costs shouldn&#x27;t be excessive, and they may even be higher than they should be right now, but we&#x27;ve got plenty of examples of what deregulated construction leads to and it&#x27;s never the utopia you&#x27;d imagine. It&#x27;s much better to have sane standards than to deregulate and allow our cities to turn into dangerous shanty towns where anyone who can lean a piece of corrugated sheet metal against a mud pile can call themselves a home builder.I&#x27;m certain that I can find more evidence that a lack of regulation leads to deaths than you could of code compliance causing untreated cancer. In fact, some regulations prevent building homes using materials that we know have caused cancer. Feel free to try to find a study or evidence that suggests otherwise though. reply LeafItAlone 16 hours agorootparentprev> My whole county did this. No inspections. It turned out fine.Would you be willing to provide us with the name of the county so that we can determine for ourselves how it turned out? reply Turing_Machine 10 hours agorootparentprev> The issue is people enforcing these regulations see the dead bodies from the burned out home but not the dead bodies of the homeless or the kids with less foodRight. It&#x27;s exact same problem as the FDA. If the FDA approves a drug and it kills people, they look bad. If they don&#x27;t approve a drug and that kills people, no one blames the FDA because the FDA&#x27;s victims in that case are invisible. reply Turing_Machine 10 hours agorootparentprev> People also just don&#x27;t want to live in slums filled with run down barely standing shacks since it hurts their property value too.Someone else&#x27;s property value is their problem, not mine. You&#x27;re not guaranteed that the value of an investment is going to go up. It&#x27;s called \"risk\", dude. Your opinion of what I should do with my property does not trump my opinion of what I should do with my property.At one time, people claimed that their property values went down when a black family moved into the neighborhood. Guess what? They eventually had to suck it up and live with it. reply fragmede 10 hours agorootparent> Someone else&#x27;s property value is their problem, not mine.On an individual level, sure, but if we have a repeat of 1929 or 2001 or 2008 or 2020 (we&#x27;ll see about 2024), even if you&#x27;re not personally directly affected, there are going to be ramifications that affect society beyond a couple of unlucky individuals. We don&#x27;t really need another once-in-a-lifetime economic event. reply brewdad 17 hours agorootparentprevWhen my neighbor&#x27;s house fails and causes damage to my property, I&#x27;m not legally \"responsible\" but I still have to deal with a whole lot of negatives. Hence the \"or deal with it\" part of OP&#x27;s statement. Far better to reduce the risks by making sure the project isn&#x27;t being half-assed up front. reply kemayo 17 hours agorootparentprevDepends on the specific thing, but generally it&#x27;s because there might be consequences to doing things poorly that would spill onto your neighbors, or which might cost the local government money to fix after it hurts or kills you. It&#x27;s the same kind of reason that laws requiring motorcycle helmets or seatbelts exist.The sewer one is obvious, since it could be a public health issue -- if you screw it up you could wind up contaminating local water sources (or just stinking up the area). Issues with the lumber you use, or with your building plans, could potentially result in your house collapsing in such a way that it might damage your neighbor&#x27;s property. And getting a new permit if you take too long is probably just a way to force you to check in and make sure that you&#x27;re not deviating from the earlier plans you filed. reply chongli 17 hours agorootparentprevBecause it damages their property values. Would you want to buy a house next to a dilapidated pile of abandoned rubble? reply Turing_Machine 10 hours agorootparentWhat makes you think you&#x27;re entitled to an increase in your \"property value\" at the expense of someone else?Maybe you should look at your house as a place to live rather than an investment vehicle.Or maybe you should just accept that investments come with risks. reply chongli 1 hour agorootparentNo one&#x27;s entitled to returns on any investment, of course. But would you expect investors to stand idly by while their investments lose ground? Or would you expect them to take whatever opportunities are available to them to protect their investments? reply salamanderss 17 hours agorootparentprevThey usually aren&#x27;t it&#x27;s an argument used to scare people into making housing stock replenishment more expensive and lock in property values.I&#x27;m building a house now. I sent the county... A picture of a square on a map. No plans no inspections nothing. Fuck all that. I build based on what seems reasonable after a cool Busch Light and then I just do it without asking permission from anybody.Half my county did the same. It&#x27;s not rocket science, and the world here hasn&#x27;t fallen apart or burned down. But you will be told the opposite to get locked into expensive contractors and corrupt inspectors and the cash extracting nightmare licensing and permitting systems that surround that.And before anybody gets too excited... this is all 100% legal if you pick the right spot. reply mholm 18 hours agorootparentprevThe municipality is on their side because many people who try to get variances on these things are legitimately cutting terrible corners that compromise both the safety of the inhabitants (present and future) and the neighbors. It&#x27;s inconvenient, but these regulations save a lot of lives&#x2F;QoL from bad&#x2F;naive actors. reply ethbr1 18 hours agorootparentThe municipality is on their side because they&#x27;re overworked.In even the smallest town, if any appreciable percentage of new builds required custom handling... the system would instantly be person-starved and start backing up.Business-as-usual is the fast&#x2F;efficient path from a paperwork standpoint. Anything odd is (a) discouraged and (b) looked at with annoyance because it takes more time.One reason it&#x27;s almost always cheaper to tear-down fire damaged houses with still viable framing. No one wants to take the time to quantify exactly how much the framing was damaged. reply salamanderss 17 hours agorootparentMy town solved the guilty until proven innocent issue regarding permits by just giving people carte blanche. Imo this is far more rational: if the county can&#x27;t&#x2F;won&#x27;t verify paperwork they should default towards freedom and let the property owner have at it rather than presuming guilt and saying you haven&#x27;t the money&#x2F;people to check it.Granted people aren&#x27;t rich where I live so we&#x27;d rather them live in potentially a subpar house and maybe have it fall in on them than be homeless and die from the elements.Re below: USA &#x2F; Arizona. Pick the right county and no code inspections. reply ethbr1 16 hours agorootparentWhich country&#x2F;state? Inquiring minds want to know! reply pixl97 17 hours agorootparentprevWhy is number one the most boggling? Not dealing with sewage correctly is a public health hazard. In most places if there is a sanitary sewer hookup you must, by law, connect to it. Now in your particular case they don&#x27;t have a sewage lift, but if one is ever installed it is likely you will have to connect to it if you ever need to do septic maintenance again. I certainly hope your municipality requires regular inspections of your septic so you&#x27;re not flowing shit water into the local environment. reply mywittyname 18 hours agorootparentprev> - You can&#x27;t build a septic system, you have to use sewer because you&#x27;re in city limits (later rescinded when they realized they would have to pump my sewage up to the city sewer.You got lucky. Houses with lift stations are a thing. Usually a bunch of houses will go to a common lift station, but that&#x27;s not always the case.My dad runs a company installing and servicing various sewage treatment solutions and I spent a lot of weekends as a child going to nice houses on service calls because their lift station threw an alarm and it wasn&#x27;t pumping their sewage. reply aidenn0 17 hours agorootparentprevYour list seems fairly reasonable.I looked into building where I was (because land was surprisingly cheap compared to houses) and was told to allocate 2 years and $250k for permits. A significant chunk of that was paying an architect to respond to the city and resubmit the plans. This was back when most houses were under $1M, and the lots we were looking at were around $200k, so the permits were literally more valuable than the land, and a pretty large fraction of the value of the improvement. reply duped 18 hours agorootparentprevThose examples sound pretty reasonable, what&#x27;s the issue? reply pixl97 17 hours agorootparentThey want to be the reason why the laws are created, they don&#x27;t want to have to follow them. reply trey-jones 13 hours agorootparentI will own this I guess. You are correct to some extent: I don&#x27;t want to have to follow laws that cause unreasonable expense, when they are created to prevent disaster that I am going to prevent without your oversight. You&#x27;ll just have to take my word for it: my house is better built than any for-profit house you&#x27;ll find on the market today. It&#x27;s for me and my family, of course I would make sure that it is! The wood that I milled is thicker, heavier, stronger than any Yellawood you&#x27;ll find. Yet I can&#x27;t be trusted to recognize a board that shouldn&#x27;t be used as a joist. I have to higher a professional to look at it&#x27;s fit for use. Which could legitimately be someone that&#x27;s never worked with lumber before. You have to admit it&#x27;s insane. By the way they definitely stamp and sell lumber that I would never use in a joist. reply majormajor 19 hours agorootparentprev> I bought a few years back and we didn&#x27;t really use an agent to find the house at all. Looking into it, I found that a certain percentage of the sale amount goes to pay the agent(s); 6% I think. If there are two agents, they each get half. If one person doesn&#x27;t use an agent... the other person&#x27;s agent gets it all. The person without an agent doesn&#x27;t get to keep their half... it just all goes to the other agent. Wtf...In hot markets this is a way people often get an advantage as a buyer: tell the selling agent you want to use them as your agent too, so they get the whole 6% if the seller picks your offer. So if the bids end up being close, the agent ends up lobbying for you (or lobbying you to make your offer closer).Some selling agents refuse to do this because it&#x27;s pretty shady, but definitely not all.I&#x27;ve also heard of similar things including negotiating down the selling agent&#x27;s cut as part of it but haven&#x27;t seen as much of that firsthand. reply _aavaa_ 19 hours agorootparent> Some selling agents refuse to do this because it&#x27;s pretty shady, but definitely not all.This is a blatant conflict of interest. My god. reply ethbr1 18 hours agorootparentIt&#x27;s only a conflict of interest if either the seller or the buyer expect their agents to negotiate price for them.Generally agents steer well clean of that, for legal and time reasons.A realtor is there to put properties in front of you &#x2F; put your properties in front of others, and then close the deal when you tell them which property you&#x27;re interested in.Volume pays realtors, not price-over&#x2F;under-replacement. reply DavidPeiffer 17 hours agorootparent>It&#x27;s only a conflict of interest if either the seller or the buyer expect their agents to negotiate price for them.There are other details that come up through a transaction that many people wouldn&#x27;t even think about. Are appliances included? Window treatments? Leftover paint? What year the transaction closes could impact taxes or incentives for either party. Inspections (what types of inspections are permitted, their timeline, what will be repaired prior to sale).If there are disagreements about any of those, or if the property was materially misrepresented by the selling agent, it&#x27;s way more messy than if another agent is involved and it&#x27;s clear who represents who. reply _aavaa_ 18 hours agorootparentprevIt’s a conflict regardless of negotiating price.Your realtor (as the seller) is now going to give preferential treatment to one buyer for their own personal gain. reply ethbr1 16 hours agorootparentThe realtor doesn&#x27;t care which side of the party \"wins\", as long as the deal goes through.So they&#x27;re only preferring whoever is bitching the loudest? reply ska 18 hours agorootparentprevThe entire thing is a bit of a racket. reply conductr 18 hours agorootparentprevIt will be presented to both parties. It&#x27;s not a hidden conflict. reply _aavaa_ 17 hours agorootparentHidden or not it still is one. reply conductr 13 hours agorootparentI guess my point was, if it’s transparent the seller can easy take that into consideration when evaluating the offers. I’ve never given much thought to an agents opinion once I’m at that stage. I can evaluate the offers, their job is to bring them to me.If people are out there just doing what their agents say with no questions asked, well, then yeah probably insist your agent doesn’t represent the other party too. That even gets murky given a large number of agents represent a few brands and they’re completely incentivized to have one of their partner agents on the other side of the transaction. replydminor 18 hours agorootparentprevWe used a real estate lawyer instead of an agent and the seller worked it out with their agent to keep the 3%. The seller&#x27;s agent told us that&#x27;s what ended up making our bid the most attractive. reply francisofascii 18 hours agorootparentprevYep, I learned that the hard way when we bought our first house a long time ago. I naively thought I would be a more attractive buyer because they don&#x27;t have to pay my agent. There ended up being two other offers. Anyway, I remember seeing in the closing documents the amount allotted to their agent, the full 6%. Wtf, indeed. reply stronglikedan 19 hours agorootparentprevIt was 6% when I bought, but I can tell you that my ex put our realtor through hell during the process - same questions over and over, daily phone calls for status updates once under contract, etc. I would have felt bad, but I knew how much she stood to make, so I didn&#x27;t say anything and just let it all happen. I feel she earned it, lol. reply xyzelement 18 hours agorootparentprevIt doesn&#x27;t sound like you negotiated well and is a sign you could use an agent :)But seriously, imagine you and I are both bidding $1,000,000 on a house. You have an agent, so if your bid is accepted, your agent and the sellers agent each get $30,000.I don&#x27;t have an agent. In my offer, I write \"the sellers agent gets the usual 3%, and I am allocating the 3% that the buyer&#x27;s agent would get towards the seller instead.\" That means for the seller&#x27;s agent there&#x27;s no difference whether I use an agent or not, but to the seller themselves, my offer looks $30,000 better than yours because I am sweetening the deal using that $ I&#x27;d otherwise give my realtor.All that said, I used a realtor on my house purchase despite being financially savvy and a good negotiator because they actually helped us find the right house, and they were well worth the fee. reply ralph84 18 hours agorootparentThe commission is spelled out in the listing contract between the seller and their agent. The buyer is not a party to that contract and can’t dictate changes to it. reply ethbr1 18 hours agorootparentFYI, here&#x27;s what an example seller&#x27;s contract from northeast FL MLS looks like:>> Broker will cooperate with and compensate, as stated below, NEFMLS brokers and any broker who reciprocates with NEFMLS. For finding a buyer ready, willing and able to purchase the Property, SELLER will pay BROKER, no later than the date of closing, a broker transaction fee of 5% of the Purchase Price, whether a buyer is secured by BROKER, SELLER, or any other person. BROKER agrees to offer cooperating broker compensation of: 2.5% of the Purchase Price to a single agent for a buyer; or 2.5% of the Purchase Price to a transaction broker for a buyer; or 1% of the Purchase Price to a non-representative broker.>> If no cooperating broker compensation is offered, the Property cannot be placed in NEFMLS. SELLER hereby directs closing attorney&#x2F;settlement agent to disburse at closing all compensation to brokers payable hereunderSo in this case, the seller&#x27;s broker is entitled to 5%, of which 2.5% is required to be shared with a buyer&#x27;s broker, if existent.In the event that no buyer&#x27;s broker exists... it would be a conversation with the seller&#x27;s broker as to how to dispose of the 2.5% (refund to the deal, etc.). reply xyzelement 18 hours agorootparentYeah agree! Great reference to the contract language. Point being is that there&#x27;s now a 30K that&#x27;s freed up for creative use. reply ethbr1 16 hours agorootparentHappened to have a recent contract handy. ;) reply sib 18 hours agorootparentprevWell, sorta.The contract between the seller and their broker&#x2F;agent definitely reserves (typically) 3% for the buyer side broker&#x2F;agent. What happens to that 3% is definitely under the influence of the buyer. We negotiated a 50&#x2F;50 split of the 3% back to us as the buyer in the most recent house that we bought. I guess we could have instead offered it as an incremental incentive to the selling party to sweeten the deal. reply xyzelement 16 hours agorootparentYeah totally it&#x27;s the same thing. The bottom line is you now have an extra 3% to \"play with\" between you, the seller&#x27;s agent, and the seller that would have previously gone to the buyer&#x27;s agent. How you split up that 3% depends on who&#x27;s got most of the leverage in the scenario. reply xyzelement 18 hours agorootparentprevCorrect, but I can make the offer with that language and the seller can review that w their agent. If the agent is \"just as well off\" or even ahead of the game they can direct the ~3% I whatever way makes sense to get the deal done. reply jliptzin 19 hours agorootparentprevYea, it’s fucked. As a buyer, I had an agent for a while, thinking that since the same commission is coming out from the seller’s side anyway, it can’t hurt. Wrong. I kept having my offers turned down without any good reasons, getting slow walked on offers that were for the seller’s full asking price, etc, until I dropped the buyer’s agent and just went directly to the seller’s agent and it was amazing how fast the offer was accepted. reply ransom1538 19 hours agoparentprevJust sell it &#x2F; or buy it yourself. It isn&#x27;t hard by any stretch. You can use a $200 listing broker on a MLS site. That is the big secret. Then it gets on zillow,redfin, etc automatically. reply SoftTalker 19 hours agorootparentYou might not even need to do that much. I sold a home in a desirable neighborhood (I don&#x27;t mean high-end, just a nice solid middle-class area with good schools, etc) by just putting a \"for sale\" sign in the front yard.Having commission be a percent of sales has some theoretical advantages. For example you might think the agent is motivated to get you the highest selling price. But in reality they are much more interested in making a sale at any price, because that lets them get paid and lets them move on from marketing your property.Residential real-estate transactions with a mortgage are about as regulated and standardized as it gets. The listing agent actually does very little beyond getting the property listed in the MLS. The difference in the amount of work they do in selling a $100K house vs. a $900K house is small (in fact the $100K house might take a lot more work because at that price it&#x27;s probably got some serious drawbacks), so why should the higher sale price pay them much more? reply conductr 18 hours agorootparentMLS puts a lot of eyeballs on it and likely can and will increase the sales price. A sign in the yard is not likely to ignite a bidding war. Although I&#x27;m glad this worked out for you, it seems like bad advice in general.> For example you might think the agent is motivated to get you the highest selling price. But in reality they are much more interested in making a sale at any price, because that lets them get paid and lets them move on from marketing your propertyThis is true. Although, it&#x27;s just important to remember your contract with the realtor is to sell it at a Listing Price. You have no obligation or liability to except a lower offer or reduce your list price, ever. They are salespeople and lean into the friendship thing, but remember they work for you and treat it as a big important financial transaction like it probably is (to you) reply SoftTalker 18 hours agorootparent> You have no obligation or liability to except a lower offer or reduce your list price, everThat’s true but in my experience they will pressure you to do so. reply hn_throwaway_99 18 hours agorootparentprevI agree with this sentiment, and I&#x27;m especially in favor of selling where you purchase services \"a la carte\" (e.g. pay a fee for a real estate attorney, a separate one to the escrow company, photographers if needed, etc.).However, if you say \"it isn&#x27;t hard by any stretch\", I invite you to take a look at listings in your area and compare for-sale-by-owner listings with those listed by an agent. Half the time it looks like the photos on FSBO listings were taken by a flip phone from the early 00s, often times the pictures look like the person didn&#x27;t even clean or there are garbage cans in curbside pics, the descriptions have glaring typos, etc. My point being that I believe it shouldn&#x27;t be hard, but I am often dumbfounded about how the average quality of FSBO listings (at least where I live) is abysmal. These people are easily losing out on a lot of money by not putting a minimal amount of effort into selling the biggest asset they own. reply DavidPeiffer 17 hours agorootparentWe sold our first home with some help of a FSBO service. I think it was $1,500. They wrote the property description (and passed it by me), created the 3d virtual tour which in my experience gives an amazing preview on whether the house would work for a buyer and would be worth visiting, listed it on their site and zillow, and for another $300 would provide an attorney to facilitate the closing.I agree most FSBO pictures are awful. We were happy to pay for a service to help the listing look polished, and we firmly believe we got more money&#x2F;closed faster because of it. With 7% interest rates on a 30 year mortgage, it would take about 5 years of payments to accumulate 6% equity to pay the commission to sell the house, before accounting for other fees (and appreciation).We ended up paying effectively ~0.8% for the FSBO service and 2.5% to the agent representing the buyer. The agent was apprehensive, but the buyer really wanted our house. Everyone acted in good faith after the hail storm a few weeks prior to closing and everyone was happy as far as I could tell. reply pc86 19 hours agorootparentprevIn many states that just means the other agent gets all the commission instead of splitting it with your agent. You don&#x27;t get any of it, and it isn&#x27;t discounted anywhere. reply hn_throwaway_99 18 hours agorootparentThat is really not how it works, and goes to show there is at least some value in agents, as they do know how the process works.The \"standard\" in the US is that the sellers pay 6% commission, with 3% going to their listing agent, and 3% going to the buyers agent. If, as a buyer, you show up without a listing agent and don&#x27;t demand 3%, it is totally reasonable, and quite common, to ask for a 3% price discount since you have no agent. Any sensible seller would take your offer as it means they are getting the same amount of money.I&#x27;m not saying this always \"works\", but sometimes people act like these are rules that are set in stone, as opposed to things you can negotiate for.Back in the early 00s I went with a discount listing agent who only charged 1%. They recommended I still give 3% to the buyers agent, but I said fuck that, and only offered 2% (market wasn&#x27;t crazy strong but also wasn&#x27;t weak), and the buyer&#x27;s agent accepted that. So all in I sold my house for 3% instead of 6%, which I thought was totally fair given the amount of work the agents did. reply defen 18 hours agorootparentprevThe agent&#x27;s commission is irrelevant. That just means the buyer needs to make a higher offer to be competitive with someone who is not using an agent. reply pc86 18 hours agorootparentThis whole thing is about agent commissions. The comment I&#x27;m replying to says \"just list it yourself\" in direct response to \"I would love for there to be some sort of competition injected into real estate commissions.\"How in the world in that context is \"the agent&#x27;s commission...irrelevant?\" reply bilsbie 18 hours agorootparentprevGreat idea but I got like 20 spam calls a day from realtors pretending to have an interested buyer and then trying to sell me on their services instead.Any way around that issue? reply TedDoesntTalk 19 hours agorootparentprevThat doesn&#x27;t help. The seller does not save money unless BOTH buyer and seller have no real estate agent.If the buyers have a real estate agent and the seller does not, the seller pays the buyer&#x27;s real estate agent double their usual payment - at least in the 3 states where I&#x27;ve sold properties. reply plorkyeran 18 hours agorootparentThat is not a state law thing. All that matters is the specific contracts you have with your agent and with the buyer. If you&#x27;re working with an agent they&#x27;ll nearly always require the standard 6% split between agents, but if you are not then the buyer&#x27;s agent commission is something that can be negotiated just like any other clause of the contract.It also just doesn&#x27;t really matter. What you care about as a seller is that you get the most net money for your house. If one of the buyers wants to have 6% of the money they&#x27;re paying you go to their agent, that just means their offer needs to be that much higher than a buyer who doesn&#x27;t have you paying their agent as much. reply SoftTalker 19 hours agorootparentprevA buyer&#x27;s agent should be paid by the buyer, since the agent is working for the buyer. You could agree to do it, or you could reject their offer if they ask you to pay the agent commission. reply hotnfresh 18 hours agorootparentprevBuyer&#x27;s agent can ask for that, sure. It&#x27;s not like it&#x27;s automatically that way and the seller has to agree to it. reply bozhark 19 hours agorootparentprevWhat if you own the title? reply johnea 18 hours agoprevA side note: archive.ph didn&#x27;t overcome the wsj paywall on this article... reply hackerfooze 19 hours agoprevWhy not just link your house to an NFT and transfer that? Easy, no intermediary needed reply havefunbesafe 18 hours agoparentSounds great! Let us know when you do that! reply nextworddev 13 hours agoparentprevwhy not use Postgres in append only mode? reply seattle_spring 17 hours agoparentprevI can&#x27;t tell if this is a legitimate suggestion, or a satirical comment poking fun at crypto-folk. reply hackerfooze 1 minute agorootparentCrypto is decentralized so it eliminates the middleman reply underseacables 19 hours agoprev [–] I know people will knock on realtors, but I&#x27;ve had nothing but good experiences with them. There&#x27;s so much s",
    "originSummary": [
      "A federal jury has convicted the National Association of Realtors and several major residential brokerages of conspiring to keep commission rates artificially high, leading to an estimated $1.8 billion in damages.",
      "The case stands to potentially instigate changes in long-standing industry rules, which have preserved high commission rates even amidst rising home prices, bolstering profits for real estate agents.",
      "This lawsuit is the first of two antitrust cases alleging that illegal industry practices have hindered consumers from lowering their costs, despite advancements in online property search technology."
    ],
    "commentSummary": [
      "A jury has awarded $1.8 billion damages in a high-profile real estate case, citing a conspiracy to inflate housing transaction costs.",
      "Critics question the value provided by realtors and are advocating for greater transparency about their practices and commission rates.",
      "Alternative strategies are being suggested to disrupt the control over the housing market held by National Association of Realtors, including fixed-fee models, an alternate Multiple Listing Service (MLS) for For Sale By Owner (FSBO) listings, and a buyer-pays model."
    ],
    "points": 298,
    "commentCount": 255,
    "retryCount": 0,
    "time": 1698777311
  },
  {
    "id": 38090521,
    "title": "A Grand Theft Auto III Re-Implementation",
    "originLink": "https://openrw.org/",
    "originBody": "OpenRW News GitHub Issues 114 Wiki Artifacts A Grand Theft Auto III re-implementation For users A faithful rendition of the classic action PC game Runs on modern Linux, BSD, macOS and Windows systems For developers Open source under GNU GPLv3 license, in active development Developer information Frequently asked questions What is OpenRW OpenRW is an open-source game engine that attempts to re-implement the engine used in the classic video game Grand Theft Auto III (GTA III), first released in 2001. With the purpose of enabling better compatibility with modern systems and ensuring that it remains possible to play the game in the future. The primary goal of the project is to reach “Version 1.0”, this would mean: Fully implementing the original gameplay Compatible with all data formats used in the game Compatible with modern gamepads where possible Able to load save game files from the game Run with community made mods that only change game data Run natively on Windows, Linux and macOS OpenRW would not aim for Version 1.0 to re-create any obvious bugs such as crashes or situations where the game becomes impossible to progress. Other features, which would not be needed for Version 1.0 include: Enhanced support for user modification Changes to the gameplay Multiplayer Features like these will not be accepted into OpenRW at present, as these don’t contribute to the primary goal. Once Version 1.0 has been reached a “new” version of OpenRW may be forked that contains these kinds of features. Do I need GTA III to play OpenRW? In short: Yes. OpenRW is simply a game engine that is compatible with the original game, it has no assets of its own. In order to play GTA III using OpenRW you must own the game and have the data installed on your system. If you need a copy of the game it’s available on Steam. It is theoretically possible to develop a completely new game, without any of the assets or content from GTA III, however no such project is currently under way. Can I play OpenRW now? In its current state it is not possible to complete the game using OpenRW, or make any significant progress through the game. There are many bugs that need to be fixed and features that need to be developed before it becomes possible to play anything with OpenRW. The latest version of OpenRW will always be available from the source code repository. Can I play OpenRW on my macOS / Linux computer? Yes. OpenRW runs on macOS and Linux, as well as some BSDs. Why make OpenRW? Beyond technical curiosity, OpenRW exists to conserve the game and ensure it is playable into the future by improving compatibility with modern systems and allowing future developers to make the engine compatible with whatever systems may exist in the future. In addition to conservation it may also offer a platform for others to build 3D action games in the future. Can I contribute to OpenRW? Yes, development of OpenRW is open, you can follow along and contribute via the GitHub project page. Also drop into the IRC channel, #openrw @ irc.libera.chat. What licence is OpenRW released under The OpenRW engine is released under the GNU General Public License Version 3. Who is working on OpenRW? The project is developed in an open and collaborative manner, anyone who wishes to contribute code or documentation is able to send changes via a pull request to the github repository. Will it be possible to play Vice City with OpenRW? The current priority of the project is to implement support for playing GTA III. Once this is completed it will be clear how much extra work will be required to fully support Vice City in addition to III. The work may need to be done in a fork of OpenRW dedicated to Vice CIty, or it may be unfeasible for one reason or another. What is the story? Development on OpenRW was started by tsjost and danhedron in 2013, where it began as a simple model viewer that became a map viewer. Over time OpenRW has gained new features such as physics, vehicles and pedestrians, and a script machine that make more of the game accessible via the OpenRW engine. Now it is possible to start a new game or load a save game within OpenRW and interact with the world. At present, development is performed in the open where anyone is free to contribute to the project via the github repository. © 2017 OpenRW OpenRW is an unofficial project and is not endorsed by Rockstar Games. Website Design & Code by Hugo Locurcio. Website Source.",
    "commentLink": "https://news.ycombinator.com/item?id=38090521",
    "commentBody": "A Grand Theft Auto III Re-ImplementationHacker NewspastloginA Grand Theft Auto III Re-Implementation (openrw.org) 286 points by ibobev 19 hours ago| hidepastfavorite120 comments wicket 18 hours agoIt&#x27;s worth pointing out that this project has not seen active development for a couple of years, since Take-Two sued the developers:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26199879https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28402640 reply Hamuko 18 hours agoparentAren&#x27;t those links about a completely different project with a completely different name? reply Philpax 17 hours agorootparentThat&#x27;s correct - OpenRW is a from-scratch reimplementation of GTA3, while re3 is a manual decompilation that&#x27;s capable of reproducing the original executable (or something very close to it). Both projects are very impressive in their own right.When re3 went public, OpenRW archived their repository; when re3 was DMCA&#x27;d, OpenRW unarchived their repository; and when re3 was sued, OpenRW ceased development.(This is based on my recollection from observing this two years ago - there may be other factors involved) reply LAC-Tech 16 hours agorootparentVery sad to see.OpenMW is a very similar project for a game of the same vintage - Morrowind. Still in active development (last commit 1 hour ago as of writing).To think Bethesda would be fine with openMW, but rockstar had to shut down openRW. reply netruk44 15 hours agorootparentBethesda has, in fact, taken issue with OpenMW in the past [0].Bethesda at least had a specific reason for going after OpenMW, though. They’re okay with it now under “certain conditions” that I’m sure the OpenMW devs aren’t going to argue with.Their main ask was that the OpenMW devs don’t advertise OpenMW as a way to play Morrowind on Android (or other platforms besides PC).And there’s an understanding that OpenMW’s “intention” isn’t solely to be a way to play Morrowind, but also to implement a generic RPG engine and editor that uses Morrowind’s gameplay and file structure. For someone to make their own game with, not using any of Morrowind’s assets. (I’m not sure if any such game exists, though)[0]: https:&#x2F;&#x2F;wiki.openmw.org&#x2F;index.php?title=Bethesda_Emails reply skocznymroczny 1 hour agorootparent\"And there’s an understanding that OpenMW’s “intention” isn’t solely to be a way to play Morrowind, but also to implement a generic RPG engine and editor that uses Morrowind’s gameplay and file structure. For someone to make their own game with, not using any of Morrowind’s assets. (I’m not sure if any such game exists, though)\"To be honest, every project of this kind claims that. And in reality, everyone knows 99% of usecases for such engine is to play the original game. Sometimes there are new IPs being created on such engine. For example recently there&#x27;s been some \"boomer shooters\" coming out using engines which were made originally to play classic DOOM or Duke Nukem 3D. But such cases are rare. reply kevinmchugh 12 hours agorootparentprevOpenmw is a clean room implementation. Bethesda could throw a legal fit regardless but it would be indefensible for them to do so. reply magic_hamster 7 hours agorootparentThey can still take you to court for a cost which is negligible to them, but not to OpenMW developers. reply iforgotpassword 6 hours agorootparent... In countries with broken legal systems. reply immibis 50 minutes agorootparent... i.e. all of them. reply sandworm101 4 hours agorootparentprevClean rooms protect from patent issues, but do little to protect against copyright or trademark actions. The fact that one creates totally new code from scratch means nothing if the end product is too similar to the existing copyrighted work. reply marcinzm 1 hour agorootparentThat&#x27;s literally the exact opposite of reality:> Clean-room design is useful as a defense against copyright infringement because it relies on independent creation. However, because independent invention is not a defense against patents, clean-room designs typically cannot be used to circumvent patent restrictions.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clean_room_design reply kevinmchugh 2 hours agorootparentprevNo, clean rooms are a mechanism that allows a team to avoid copyright infringement by ensuring that the developers have never seen the copyrighted code. reply sandworm101 1 hour agorootparentThe code avoids copyright, if it is actually different. The end product doesn&#x27;t if it is still similar to the copyrighted work. Use a computer to rewrite Harry Potter all you want, but if it comes up with the same book it doesn&#x27;t matter how you got there. reply marcinzm 1 hour agorootparentThat&#x27;s not a clean room implementation. A clean room would be having a description for the game of quidditch (game rules are not copyrightable just like specifications for software) and then writing a background story to explain it without ever having read a single word of Harry Potter. If that comes out anywhere similar to the Harry Potter books I&#x27;d be utterly amazed. reply kevinmchugh 1 hour agorootparentprevIn Sony v Connectix a judge found that software designed for compatibility deserved less protection than literary works. reply tiahura 29 minutes agorootparentprevYou’re 180 degrees backwards.Copyright infringement requires copying.Patent infringement does not require copying.There&#x27;s a famous case on this exact issue.Atari Games Corp. v. Nintendo of America Inc. 975 F.2d 832 (Fed. Cir. 1992)\"Nintendo can show copying by proving that Atari made literal copies of the NES program. Alternatively, Nintendo can show copying by proving that Atari had access to the NES program and that Atari&#x27;s work — the Rabbit program — is substantially similar to Nintendo&#x27;s work in ideas and the expression of those ideas.\" reply DrOctagon 6 hours agorootparentprevWhat does clean room mean in this context? Never decompiling the target? reply bc_programming 5 hours agorootparent\"Clean room\" reverse engineering basically has you with two completely separate groups of developers. One group will decompile and analyze the target software, and build a detailed specification of how it works. The second group, with legal, sworn documents that they have never seen even the machine code of the target software - uses those specifications to build the \"clone\". reply SXX 5 hours agorootparentprevUsually clean room mean those writing the code and people who decompiling are different people. So code is written against specification.So no it&#x27;s unlikely to actually be fully clean room project, but written from scratch. reply Dalewyn 15 hours agorootparentprevTo be fair to Bethesda, they provide all the tooling you would need to make your own Elder Scrolls game with Morrowind, Oblivion, Skyrim, et al..Modding a Bethesda game is literally getting into the innards of the game itself and changing or replacing bits in it as you please, at least until we get into hooking in DLLs which is a whole different story. reply LAC-Tech 15 hours agorootparentOpenMW is a brand new engine though, built from scratch. reply Dalewyn 15 hours agorootparentI might be confusing it with the project that seeks to remaster Morrowind in Skyrim, then. reply LAC-Tech 14 hours agorootparentYeah the modding community is pretty insane.There&#x27;s also \"Skyrim, Home of the Nords\" which is an effort to re-create pre-Skyrim (the game) lore about Skyrim... in Morrowind. replyopyate 6 hours agorootparentprevOf course publishers are going to keep these old IPs under lock and key, because they&#x27;ve now figured out they can slap new graphics on it every few years and re-sell it to us at full price. reply chmod775 3 hours agorootparentprevWorth noting that in case of the lawsuit they settled, with terms likely being \"don&#x27;t do it again\".https:&#x2F;&#x2F;www.pcgamer.com&#x2F;take-two-dismisses-lawsuit-against-g... reply hd4 17 hours agorootparentprev>when re3 was suedThe day reverse-engineering legal protections failed. reply bigstrat2003 16 hours agorootparentNot really. No legal protection is able to stop an overzealous litigant from suing you. The real test is whether they win the case, not whether they can file one. Unfortunately, most people don&#x27;t have the means to defend such a lawsuit, so they get bullied out of their legal rights. reply flykespice 2 hours agorootparentThisThese companies know very well these independent groups, even if it&#x27;s on their legal bounds, can&#x27;t afford a legal defense team and actively exploit that to abuse them away. reply kevinmchugh 12 hours agorootparentprevre3 is a very dubious legal case. They decompiled the game with debug symbols and then did a (aiui) non-clean room reimplementation of the code, based on the decompilation.It is protected legal activity to decompile a binary and study the source.It is protected legal activity to study some source code, describe it, and have someone who never saw the source reimplement the code described.It is straightforwardly illegal to decompile source code, recompile it, and the distribute the recompiled binary.re3 is somewhere between the latter two, and (again aiui from looking into it 2 years ago) they didn&#x27;t have a clean room step.It&#x27;s probably a good thing no one will litigate it. It seems highly likely to be illegal and reasonably do. It would be a bad thing to spend money on. reply hd4 5 hours agorootparent\"It is straightforwardly illegal to decompile source code, recompile it, and the distribute the recompiled binary.\"According to what? If the rules are so poorly defined that way then maybe it&#x27;s not a bad thing to disregard them. Because simply decompiling source code and then recompiling it isn&#x27;t a simple one-step thing in the way you suggest, not even close. reply kevinmchugh 2 hours agorootparentIt&#x27;s the distribution step that&#x27;s illegal, since you don&#x27;t own the original binary. If you can&#x27;t distribute the original binary, why can you distribute a modified version of it?If you wrote a bash script which decompiled and recompiled the original binary, that would be your property to distribute as you like reply immibis 48 minutes agorootparentDecompilation is also illegal in broken countries (which is most of them) reply throwaway290 5 hours agorootparentprevNext you will suggest that stealing original artwork and laundering copyright through generative art ML systems is not illegal... reply hd4 24 minutes agorootparentfalse equivalence reply yard2010 4 hours agorootparentprevWell, you wouldn&#x27;t steal a car &#x2F;s reply yard2010 4 hours agorootparentprevWell, you wouldn&#x27;t steal a car &#x2F;s reply formerly_proven 3 hours agorootparentprev> It is straightforwardly illegal to decompile source code, recompile it, and the distribute the recompiled binary.But it is not straightforwardly illegal (according to Microsoft et al) to decompile source code, train an LLM on it, generate the source code, recompile it, and then distribute the recompiled binary.One easy 947 quadrillion tensor-operations lifehack reply wicket 17 hours agorootparentprevYou are right, however it&#x27;s likely that OpenRW was also impacted by Take-Two&#x27;s actions towards Re3 given that its development also ceased around the same time. reply MiddleEndian 16 hours agoprevI&#x27;m surprised there are no open source GTA 2 clones (either straight-up or just similar games of that style). The total topdown PoV with rotating sprites seems like it would be ideal for low&#x2F;zero budget enthusiast projects. reply eternauta3k 7 hours agoparentThere was \"Greedy Car Thieves\" but I can&#x27;t seem to find a working official website, probably dead.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pxAMVhLNVX0 reply qwerty456127 6 hours agorootparentThe trailer looks super cool. Kind of like a cross between the actual GTA2 and Crimsonland which sounds an awesome mixture. But their website appears dead indeed while all the download links Google can find lead right there :-( reply proxysna 5 hours agorootparentIt is still available as Street Arena on steam. reply tetris11 4 hours agorootparentprevA lot of needless explosions, but very cool nonetheless reply moonshinefe 13 hours agoparentprevThey gave GTA2 away for free officially at some point, which might have reduced a desire for it. That&#x27;s my only guess. reply robbiep 7 hours agorootparentI have been looking to play GTA2 for a long time - I have such good memories of it.For any on mac who are looking - it is available for free from Porting Kit (which is a Wine-like platform). I am assuming they can install it for free since they&#x27;re some sort of side project of GOG and I presume they have the original binary from when it was released for freeSo presumably anyone else with a Win system could get it from GOG (actually looks like you can get it here - https:&#x2F;&#x2F;gta.com.ua&#x2F;rockstargames-classics-free-download.phtm... ) reply qwerty456127 6 hours agoparentprevYeah GTA2 was one of the most fun games I&#x27;ve ever played. Sadly it isn&#x27;t even available on GOG, let alone open source... reply vkaku 5 hours agorootparentGTA1 and GTA2 were released for free as Rockstar Classics and you should be able to find a copy on the Internet Archive, if not on Rockstar. Cheers! reply qwerty456127 5 hours agorootparentWow. Thank you. I didn&#x27;t know. reply dividuum 5 hours agoparentprevThere&#x27;s Retro City Rampage (which also has a DOS version) and Shakedown Hawaii. reply dento 15 hours agoparentprevThis is an open source game from my childhood which is somewhat similar: https:&#x2F;&#x2F;github.com&#x2F;suomipelit&#x2F;ultimatetapankaikki&#x2F; reply mikrotikker 1 hour agoparentprevThere is newer one battle Royale and multiplayer I can&#x27;t remember the name. It&#x27;s on steam came out in the last couple of years.GTA2 was a LAN party favourite. reply harrisonpage 16 hours agoparentprevYou are so so so right. I&#x27;ve only ever seen a few out there. reply GartzenDeHaes 6 hours agoprevSan Andreas in Unity, if anyone is interested. You can&#x27;t do anything more than walk around, drive, and shoot though.https:&#x2F;&#x2F;github.com&#x2F;GTA-ASM&#x2F;SanAndreasUnity reply looping8 5 hours agoparentIt&#x27;s strange, even though the graphics of San Andreas definitely don&#x27;t look good, this somehow looks worse to me. It&#x27;s like smoothing out the outdated models and making them higher resolution makes them seem worse. Not blaming the developers of this, just surprised that a much stronger engine ends up looking worse somehow, maybe it&#x27;s just the initial shock? reply Karliss 4 hours agorootparentI can think of a couple reasons.* Fidelity level (in terms of resolution, color amount and similar) needs to match with the amount of information within drawing. One example of this are some of the games during transition from EGA to VGA which allowed to use more colors. Just slapping a color gradient on everything doesn&#x27;t necessarily look better than more stylized look carefully using a limited color pallet.* Inconsistent quality level. While some of the assets are much higher resolution, not all of them are. This makes the older assets look worse compared to everything being equally low resolution. The mismatch can be caused not only by asset quality level but also lighting techniques.On hand you have sharp high resolution shadows on the other there are still some low quality textures and geometry.* Higher resolution textures makes it easier to notice bad texture tiling and low resolution geometry. With a high resolution textures perfectly projected on low polygon it&#x27;s much easier to tell how blocky they are and where the edges are, compared to using more blurry textures. reply tentacleuno 4 hours agorootparentprevIt&#x27;s most likely because the game seems to use the textures from an existing installation. You can&#x27;t just enlarge textures and have them look the same.I&#x27;m sure they could do some AI upscaling, but that probably wouldn&#x27;t improve the situation much. GSG tried that for the Definitive Edition, and look how that went.It would be interesting to see a new texture pack made for it, which focuses less on nostalgia and more on fidelity. reply Inviz 10 hours agoprevhttps:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=N3KhMOk_6HE&t=538s&pp=ygUMR3Rh...There is a video of a guy reviewing some of the code. It’s quite readable. The game was much simpler back then, some special casing was made (eg Catalina copter). But it’s a cool look behind the scenes reply gabegm 9 hours agoparentHe&#x27;s actually reviewing re3 which was the project DMCA&#x27;d by R* and involved manual decompilation rather than a complete reimplementation.It&#x27;s an interesting video to watch to get his perspective though. reply tentacleuno 4 hours agoparentprevhttps:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=SebVNodMV4Q&pp=ygUjR1RBIGRldmV...This one was very enjoyable, too. It was an ex-Vice City developer reviewing the re3 source code. reply jamesnorden 16 hours agoprev>In its current state it is not possible to complete the game using OpenRW, or make any significant progress through the game.Plus last commit was 2 years ago.why even post this? reply xcdzvyn 4 hours agoparentit gratifies one&#x27;s intellectual curiosity. reply MBCook 16 hours agoprevDespite being called OpenRW they never tell you where the name comes from, only that it’s an attempt to write the engine from scratch with clean code.But why RW? Did the GTA games run on RenderWare? reply OatmealDome 16 hours agoparentYes, the early 3D Grand Theft Auto games (III, Vice City, and San Andreas) ran on RenderWare. [0][0] https:&#x2F;&#x2F;gtamods.com&#x2F;wiki&#x2F;RenderWare reply mattbee 14 hours agoparentprevThis is one gem from the project, a partial reimplementation of RenderWare: https:&#x2F;&#x2F;github.com&#x2F;aap&#x2F;librw reply Lammy 13 hours agorootparentI would love to see the first few Burnout games given the modern re-implementation treatment, but EA would probably behave the same way as Take2. reply tenkabuto 3 hours agorootparentI&#x27;d love to see the Burnout games somehow remade and&#x2F;or open sourced.Looking into it, I found one instance of a reimplementation attempt[0], but it isn&#x27;t clear to me how far along it is. There&#x27;s some discussion of it here [1].[0]: https:&#x2F;&#x2F;github.com&#x2F;reburndev&#x2F;reburn3[1]: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;REGames&#x2F;comments&#x2F;15ymbtq&#x2F;an_open_so... reply oynqr 8 hours agorootparentprevThis is from re3, not OpenRW. reply alternatetwo 8 hours agorootparentlibrw started long before re3. reply moosedev 16 hours agoparentprevI think the GTA 3 family of GTA games did, yes. They were PlayStation 2 games first, and RenderWare was relatively common for PS2 games.Source: worked in game dev using RenderWare on PS2 back then reply MBCook 13 hours agorootparentSince you were in the industry, was RW the first big 3rd party engine?I know it’s common now, and seems to have really taken off in the Wii&#x2F;PS3&#x2F;360 era. My understanding is it wasn’t in the PSX generation (at least early?). reply qingcharles 11 minutes agorootparentIt was everywhere in the 90s that I remember when I was a game dev. I don&#x27;t know if you would call it a game engine? We just called it a 3D engine back then. Back then at least I only remember it doing the graphics, no physics, animation, sound, etc?It must have started off as a purely software renderer as I can remember trying to compete with their published stats on tris&#x2F;sec. reply justsomehnguy 6 hours agorootparentprev> RW the first big 3rd party engineRW is RenderWare, it&#x27;s not a game engine.> really taken off in the Wii&#x2F;PS3&#x2F;360 eraNo? RW have&#x2F;had the immense success as an engine used in more than a dozen commercial games (compared to idTech1&#x2F;2&#x2F;3), but it&#x27;s usage explodes in 2001, with 18 titles, compared with 4 in 2000.> PSX generationToo early.https:&#x2F;&#x2F;en.everybodywiki.com&#x2F;List_of_RenderWare_games reply Crosseye_Jack 16 hours agoparentprevGTA3&#x2F;VC&#x2F;SA, Manhunt and Bully ran on RenderWare. They made their own engine for GTA4 (and also for their pingpong game and RDR1 iirc) and I \"presume\" the games since.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rockstar_Advanced_Game_Engine reply alternatetwo 7 hours agorootparentThey also made their own engine for the other games you mentioned. RW is more of a rendering layer than anything else, it has no gameplay logic, scripting, audio logic associated with it. reply tetris11 4 hours agorootparentprev> BullyJust a heads up that a Bully sequel (trilogy?) is in the works:https:&#x2F;&#x2F;www.xfire.com&#x2F;ex-rockstar-games-employee-leaks-bully... reply MrGilbert 16 hours agoparentprevIt&#x27;s \"Open ReWrite\". That&#x27;s what the description of the Github repository says. reply MBCook 16 hours agorootparentYeah but that’s clearly a backronym. reply alternatetwo 3 hours agorootparentBack when the name OpenRW was coined, there was a much more widespread belief that RenderWare was the engine GTA3 runs on. At some point people realised that&#x27;s nonsense, GTA3 doesn&#x27;t have an engine (all code was written specifically for GTA3), and so they had to come up with something that&#x27;s not RenderWare related. reply hanniabu 16 hours agoparentprevrewrite reply rabbits_2002 2 hours agoprevThere is a similar project for Morrowind called OpenMW. It runs great on Linux. reply globular-toast 7 hours agoprevDid it really look that bad? There wasn&#x27;t even a shadow underneath the character?I always find it a bit sad when I see pictures of old games I used to play. My memory of them seems to automatically \"upgrade\" how they look to modern standards. Then when I see them it&#x27;s shocking and disappointing to see how wrong my memory is. I&#x27;d rather leave it as a memory. reply CapsAdmin 4 hours agoparentSomewhat sadly it seems memory works that way. It&#x27;s as if over time it gets compressed and generalized in some way.Maybe it depends on the person, but for me personally I have difficulties imagining what my parents looked like when they were 20 years younger, apart from reciting some specific photos.When someone I see daily gains or loses weight slowly over time it&#x27;s hard to remember what they looked like in the past.I had a good mental picture of my now deceased cat in my head, but when I got a new cat of with a similar color and fur, the mental image of my previous cat slowly got replaced with how my new cat looks. reply hulitu 6 hours agoparentprevLCD&#x27;s are crap when it comes to colors. The new HDR monitors seem to be better, but playing old DOS and Windows games on an (non HDR) monitor is a pain.I am very courious how many colors from those 16 milion of 24 bits are LCDs able to reproduce. My LCD seems to be able sometimg less than 16 bits (65535). reply Lwerewolf 5 hours agorootparentGood LCDs (i.e. native 8-bit IPS) have been available for a very long time. No-compromise gaming IPS&#x27;s (120hz+, backlight strobing) - for more than 7 years. Decent 60hz ones (and even 76hz - 2209WA with overdrive) - for far, far longer. Yes, there&#x27;s still the IPS glow, A-TW polarizer-equipped panels are almost impossible to look up in the first place. Yes, the black level is still pretty bad, unless you have a stacked matrix reference Sony or something. Yes, cheap 16-bit-with-bad-dithering TN less-than-sRGB-gamut LCDs are not great, but so were the el cheapo shadow mask CRTs. reply tentacleuno 4 hours agorootparentGreat OLED screens are on the market now, too. They look absolutely incredible; once you go OLED, you don&#x27;t go back :) reply globular-toast 4 hours agorootparentYes, but my cheap LCD monitors I use for work have endured I reckon at least 3 years of continuous operation over the space of 7 years. What will an OLED that costs probably 5x as much look like after that much time? replygardenhedge 18 hours agoprev\"GTA 3 is no longer available on the steam store\" reply colechristensen 17 hours agoparentIt wasn’t for a while, they released a “definitive edition” which is available. They took the old versions down somewhat prematurely before releasing the remasters. A small number of people got some attention being disproportionally upset about this. reply powersurge360 17 hours agorootparentThis minimizes things a bit. The definitive editions got torn apart for being ugly and poorly developed. It was a better experience to use the originals and mod them in many cases. This original version is still not available and people are still upset about it. Looks like the DE version of GTAIII currently has a 6 out of 10 on steam so it probably hasn’t been improved since release. reply qingcharles 9 minutes agorootparentI know they took out this reference, probably because they didn&#x27;t know what it was for:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;gaming&#x2F;comments&#x2F;3ylmm4&#x2F;comment&#x2F;cyet... reply vasdae 17 hours agorootparentprevI have played the DE version of GTA 3 (in fact I just finished) and it wasn&#x27;t nearly as bad as they make it out to be. In fact I would say it&#x27;s a better experience than the originals for those who haven&#x27;t played them. Of all the bugs I&#x27;ve experienced, almost all of them were in the original release, which I played extensively.It&#x27;s best to ignore youtubers and generally disagreeable nerds from reddit and all those places. They feed on hate. reply user_7832 16 hours agorootparent> I have played the DE version of GTA 3 (in fact I just finished) and it wasn&#x27;t nearly as bad as they make it out to be. In fact I would say it&#x27;s a better experience than the originals for those who haven&#x27;t played them. Of all the bugs I&#x27;ve experienced, almost all of them were in the original release, which I played extensively. It&#x27;s best to ignore youtubers and generally disagreeable nerds from reddit and all those places. They feed on hate.While I don&#x27;t disagree with your experience at all of it being better than the originals, that is unfortunately just part of the issue here. The background is that Take Two has been very litigious, and a number of high-quality mods are no longer relevant due to their actions.I may be misremembering the details but iirc there was a very high quality GTA4 graphics mod that essentially gave the game \"modern\" graphics that too was forced to stop due to legal issues(to say nothing of the GTA3&#x2F;VC etc mods). GTA 5 loading times were very high until a single guy fixed their shitty code with a mod.Take Two isn&#x27;t just poorly managed or have poor code quality (which they do), they are also hostile to users wanting to modify their game. A good bit of the criticism here isn&#x27;t specific to the game itself (which for eg may be fine once it loads) but rather their behaviour. reply dingnuts 16 hours agorootparentconsidering all of the moral hand-wringing over the content of the GTA games there&#x27;s some sort of deep irony over the fact that the developer is apparently not super ethical.or maybe it&#x27;s not irony, but the opposite of irony. maybe it&#x27;s totally predictable and shouldn&#x27;t take anyone by surprise at all. reply giancarlostoro 17 hours agorootparentprevTo be fair, even though I disagree with Rockstar on removing them from the store, you can still play the originals if you already owned them on Steam. Unlike the recent scandal with Assassins Creed where they removed it from your Steam library. reply hiatus 15 hours agorootparent> Unlike the recent scandal with Assassins Creed where they removed it from your Steam library.Do you have a link with more information? Steam removed games that people legitimately purchased from their personal libraries? reply giancarlostoro 14 hours agorootparentHeres a HN thread on it:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32049508 reply Belopolye 13 hours agorootparentprev> Steam removed games that people legitimately purchased from their personal libraries?The sad reality is that you purchased a license under terms that allow them to do whatever they want- it’s not really your personal library. Unless a government were to pass a law and fine them about it nothing will happen- it’s what you agreed to when you use services like Steam. reply BlueTemplar 4 hours agorootparentAnother reason to keep backups. reply matheusmoreira 9 hours agorootparentprev> Unlike the recent scandal with Assassins Creed where they removed it from your Steam library.The desire the \"purchase\" games decreases with each passing day. reply thebigspacefuck 15 hours agorootparentprevI still have them in my library. I haven’t tried playing it recently but Vice City and San Andreas both play fine on my steam deck as the PC version and as emulated PS2 games. If the PC versions work with proton today then should they be able to run as long as proton is still supported? reply omginternets 17 hours agoprevAll you had to do was follow the damn train, CJ. reply ThrowawayTestr 17 hours agoparentWrong game reply crazysim 17 hours agorootparentThough there is a train following mission in GTA3 too! reply omginternets 17 hours agorootparentprevOh shoot, you&#x27;re right! reply sdwvit 14 hours agoprevDoes anyone have a mirror of ReVC project? reply Zambyte 13 hours agoparenthttps:&#x2F;&#x2F;git.robbyzambito.me&#x2F;mirror&#x2F;re3.git&#x2F;log&#x2F;?h=miami reply dawidpotocki 10 hours agorootparentSeems to be down.Here is my mirror, it should have all the commits: https:&#x2F;&#x2F;git.dawidpotocki.com&#x2F;mirror&#x2F;re3&#x2F; reply xcdzvyn 3 hours agorootparentIs this a fork of cgit? Do you have the source? It&#x27;s lovely :)Edit: I see, it&#x27;s just some CSS. New question: Is it FOSS? reply dawidpotocki 3 hours agorootparentYep, just some CSS.I have not cleaned it up for release or anything, so it&#x27;s a bit messy, but feel free to use it under the licence terms of cgit (GPLv2.0-only) and if you don&#x27;t mind, put an attribution somewhere, like at least at the top of the CSS file.EDIT: You will also need this in your , otherwise you won&#x27;t have a mobile-friendly layout: And also a custom pygments config so it uses the correct variables for colours, like this: class BiualStyle(Style): background_color = \"#000000\" highlight_color = \"#222222\" default_style = \"#cccccc\" styles = { Token: \"var(--code-cyan)\", Whitespace: \"\", Comment: \"var(--code-blue)\", Comment.Preproc: \"\", Comment.Special: \"var(--code-red)\", Comment.Hashbang: \"var(--code-magenta)\", Keyword: \"var(--code-yellow)\", Keyword.Declaration: \"var(--code-green)\", Keyword.Namespace: \"var(--code-magenta)\", Keyword.Pseudo: \"\", Keyword.Type: \"var(--code-magenta)\", Operator: \"var(--code-yellow)\", Operator.Word: \"var(--code-yellow)\", Name: \"\", Name.Class: \"var(--code-cyan)\", Name.Builtin: \"var(--magenta)\", Name.Exception: \"var(--code-green)\", Name.Variable: \"var(--code-cyan)\", String: \"var(--code-red)\", Number: \"var(--code-magenta)\", Generic.Heading: \"var(--code-green)\", Generic.Subheading: \"var(--code-magenta)\", Generic.Deleted: \"var(--code-red)\", Generic.Inserted: \"var(--code-green)\", Generic.Error: \"var(--code-red)\", Generic.Emph: \"italic\", Generic.Strong: \"bold\", Generic.Prompt: \"bold var(--code-blue)\", Generic.Output: \"var(--code-gray)\", Generic.Traceback: \"var(--code-blue)\", Error: \"border:var(--code-red)\" } reply Zambyte 10 hours agorootparentprevHm... it&#x27;s up for me? If you just tried cloning, I linked directly to the web view of the VC branch, since that&#x27;s what they asked for. This is the clone link https:&#x2F;&#x2F;git.robbyzambito.me&#x2F;mirror&#x2F;re3.gitThanks for your mirror though reply dawidpotocki 10 hours agorootparentHmm, just checked and it seems that it doesn&#x27;t work when I&#x27;m connecting through some Mullvad VPN exits, but works when I disconnect. Oh well. I assume you have something like fail2ban. reply gattilorenz 7 hours agorootparentprevDoes it have any significant changes&#x2F;improvements compared to the original version? Does it compile “easily”?Ah, nvm, it&#x27;s all mentioned in the README: https:&#x2F;&#x2F;git.robbyzambito.me&#x2F;mirror&#x2F;re3.git&#x2F;tree&#x2F;README.md?h=... reply jmyeet 12 hours agoprevI&#x27;m honestly shocked how game companies can refuse free money by remastering old popular titles. And when they do actually do it, they do it so cheaply that the resulting product is just godawful.Case in point: Warcraft 3 [1]. This remaster was not only awful technically but Blizzrad changed the ToS on third-party maps so they owned all the IP because they didn&#x27;t want a repeat of the Dota fiasco where Dota 2 sprange from a WC3 map and Blizzard basically lost the MOBA war.Rock Star not so long ago released an awful remaster of the GTA3 trilogy [2]. These games are beloved. It&#x27;s hard to believe they could screw up such an easy lay up but they did.There seems to be an all too common thread of outsourcing to third-party contractors on the cheap, little oversight, no internal accountability, limited oversight and honestly not really caring.But as we see people write emulators to play dead games on dead platforms. People remaster existing games largely for free. It&#x27;s crazy to drop the ball so hard on something with such a huge inbuilt market.[1]: https:&#x2F;&#x2F;www.resetera.com&#x2F;threads&#x2F;i-still-feel-absolutely-awf...[2]: https:&#x2F;&#x2F;screenrant.com&#x2F;gta-trilogy-definitive-edition-remast... reply skocznymroczny 1 hour agoparentHave they really changed the ToS that much? My understanding was that by EULA the content you create through Warcraft 3 World Editor always belonged to Blizzard and Reforged hasn&#x27;t really changed much in that aspect.On the other hand, a lot of custom maps for Warcraft 3 were based on external IPs (Dragonball Z maps etc) so it&#x27;s not something Blizzard can claim anyway.Even when transitioning to Dota 2 they had to purge some of the more obvious IP things that existed in Dota 1, such as the sorceress character named \"Lina Inverse\" became \"Lina\". reply danbolt 11 hours agoparentprevI don’t think Blizzard&#x2F;Rockstar’s scenario necessarily applies here, Frank Cifladi has a GDC talk[1] about how the financial argument for remastering older IP can prove tricky. The enthusiast might not be happy with a bare bones, economically-sound port, so it can be challenging to market to them.Digital Eclipse gets around it by making nicer ports on the cheap, but I think a long-term solution would be a low-cost way for rights holders to keep older games in circulation without effort.[1] https:&#x2F;&#x2F;youtu.be&#x2F;HLWY7fCXUwE reply pelasaco 8 hours agoprevSo many better games, people go for the game that can be used as example of a failed society. reply the_player 18 hours agoprev [–] To save everyone the trouble – the last commit is 2 years old. reply oynqr 17 hours agoparent [–] Around the time re3 got public interest. reply alternatetwo 3 hours agorootparent [–] Specifically, shortly after re3 was done and got public attention - i.e. compiled to exe and no longer required the original gta3.exe. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenRW, an open-source project, intends to re-implement the engine of the classic video game GTA III to make it compatible with contemporary systems. The ultimate goal is to reach \"Version 1.0,\" implementing original gameplay and compatibility with all game data formats, and modern gamepad support.",
      "Once developed, OpenRW might allow for player modifications, gameplay changes, and enable multiplayer features but a copy of GTA III with game data installed will be needed to play.",
      "OpenRW is currently under development, with contributions being open to anyone via GitHub. Initiated by tsjost and danhedron in 2013, it is not endorsed by Rockstar Games."
    ],
    "commentSummary": [
      "The conversation in a Hacker News post surrounds the halted Grand Theft Auto III Re-Implementation project owing to a lawsuit by Take-Two, while the OpenMW, a Morrowind game project, is still actively developed.",
      "Users discussed the 'clean room' reverse engineering process, a practice argued to be legal when understanding and redeveloping source codes.",
      "Quality of the Definitive Edition of GTA 3 was scrutinised, with participants also citing an old code and its relevance to game remastering practices."
    ],
    "points": 286,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1698781980
  },
  {
    "id": 38095542,
    "title": "What the Goddamn Hell Is Going on in the Tech Industry?",
    "originLink": "https://ludic.mataroa.blog/blog/what-the-goddamn-hell-is-going-on-in-the-tech-industry/",
    "originBody": "Ludicity What The Goddamn Hell Is Going On In The Tech Industry? Published on November 1, 2023 Sweet merciful Jesus, I woke up this morning and my inbox was flooded with horrific stories about how employers treat people. I knew things were fucked, but this was so much worse than I imagined, and that's not even getting into the comments on Hackernews. I am going to dig into some of those emails, but first... I usually don't waste time on the negative comments because usually the person making it has obviously gulped down so much corporate Kool-aid that I am afraid they will projectile vomit Agile terminology all over me, but there was one that was so funny that I had to share it. With regards to my post on saving half a million dollars: There is a high likelihood that many other people in the org were lightyears ahead of the author. It's even more likely that an engineer or manager in their group was \"Banking\" the inefficiencies to use during a cost-cutting period - and the author ruined that chance... which will inevitably cause massive suffering and possibly poor performance reviews when there is nothing to trim.\" My brother in Christ, I have a blog that is largely about corporate dysfunction and the soul-cost it imposes on well-meaning engineers, and you think that I'm the problem because someone else was deliberately wasting money so that they could pretend to save it later? In the words of the late Hitchens, \"Do you see what brain rot descends on people?\" Incidentally that wasn't what was happening here, they really just never checked the database defaults. I'm sure someone is out there by 5-dimensional hyper-chess by deliberately going over the budget by a billion percent, but rest assured that this is not the simplest explanation. The whole idea that management must have a reason to do something this stupid is something I toyed with for a while, but it really only applies to the minority of cases. I. We're Just Wasting Like 30-90% Of All Technical Productivity I am near absolutely convinced that the vast majority of our species' ability to produce things of value for the human race is just utterly squandered at large companies. I suspected we were wasting about 50%, but the volume of stories I got, frequently from serious companies, including some of the FAANG places that mere normal engineers like me look up at in awe while we worship at the altar of StackOverflow, just blew my mind. A lot of them involved doing variations of almost exactly what I did in different stacks, and every single time management just buried what happened. If you recognize yourself in these emails but didn't give me permission to write an email, then it isn't actually you, it turns out these stories are so similar that they really do sound the same. I received: A few stories about idling EC2 instances, totaling a total of about $4,000,000 saved per month, which management buried to avoid looking bad. Another guy that discovered the same optimisations I made, with the same result from management. Some security guys that just... I don't even know what to say about these stories, but quite a few stories were about finding out that a large proportion of a company's servers were infected with malware or mining cryptocurrency, which management, guess what, buried. A guy, whose story deserves a whole post on its own, involving being told he's \"not a team player\" because he didn't stop someone else from flooding a server with crypto-bots. Some people discovering other multi-million dollar optimisations that were ignored because they didn't have admin credentials, so they had to write suggestions which were ignored. There were some others, with a handful genuinely seeming to possibly add up to billions of dollars saved industry-wide, but the largest payout anyone ever received in the emails was $5K. Sampling bias, yadda yadda, listen, I'm pretty sure things are just fucked up. The best story, which I have verified is true beyond all reasonable doubt, involved literally saving a colleague's life with immense personal effort and in traumatic circumstances, which was rewarded by not getting the rest of the day off and $50. Like what the fuck is going on out there? I mean, I guess we already know what's going on out there - keeping a large company efficient is actually an unsolvable problem. I suspect that if you want to build a modern GPU, you just have to be able to sustain all that inefficiency or... you don't get to have anything that takes more than 50 people (or something in that range) to make. It's just all so much worse than I thought. In fact, while a lot of those stories were bad, most of them probably weren't the worst places because most of the readers here are actually super talented engineers, which was evident from their excellent writing skills, open source contributions, and rugged good looks. The worst places wouldn't have any talented engineers. Like, Christ, let that sink in. It's like thinking you're in Hell with a few other people, desperately hanging on, then realizing that just in the next room is Super Hell which consists entirely of demons torturing each other. Ack, it makes my skin crawl just thinking about it. There's a team out there where the main drama isn't one right faction and one wrong faction, there are two factions fighting to the death over how best to use a spreadsheet as a database for a production application. I feel like this has to be stopped but I don't have the strength. It is fucking awful out there. Maybe we should set up a support group. II. The Other Side The other thing I wanted to highlight is that there were three kinds of respondents, both via email and on Hackernews. The first type, my favourite commenters, whose grim-faced no-nonsense corporate visages grace standups across the world. Thanks to their fearless leadership and keen business sense, I have it on good authority that all projects are scheduled to move from red status to green status despite all those risks unfortunately materializing, which is no one's fault in particular. Despite the various challenges we have faced over the years and lack of forward progress, I think this retro is the one where things are going to change. The second type, the vast majority, who read this stuff and immediately suffer flashbacks. My heart goes out to you, my kin. As a few people wrote in, don't let the bastards grind you down. And the mythical third type, who aren't sure whether my stories are real. Like, they just assume that I must be making stuff up, because how could anyone do their work so ineffectively? God, I wish I was them. I read stories similar to mine and can just tell that they're true. I really, really wish I couldn't - if only I could toggle my brain back to that sweet pre-employment state, where I knew there would be some minor inefficiencies and I'd have a great time tackling them. Before I realized that wasting ten years of someone's career on a task that doesn't need to be done is actually a rounding error for many companies, and that some absolute clowns would spend all their time trying to gaslight their peers into believing the work was accomplishing anything. Some of the third type are obviously actually also working at really stupid companies, but just accept the social fiction. It's probably good for them. However many of the others actually work somewhere functional, and their experience is so far divorced from the average engineer's that I only have one friend that has worked at both a good and a bad place - and I keep a lot of friends in the tech space between being pretty extroverted and this blog. There's just some massive unwashed mass of utterly stupid companies where nothing makes any sense, and the only efficiencies exist in the department that generates the money to fund the other stupid stuff, and then a few places doing things halfway right. The places doing things right tend to be characterized by being small, not being obsessed with growth, and having calm, compassionate founders who still keep a hand on the wheel. And the people that work there tend not to know the people that work elsewhere. They're just in some blessed bubble where the dysfunction still exists in serious quantities, but that quantity is like 1/10th the intensity of what it is elsewhere. However, it's really hard to tell these people apart. Anyway, what I'm saying is, hold out hope. I'm aiming to keep a few conversations going with people via email that have made the jump, and I'm hoping to write up a guide on how to most effectively follow suit. If I can help even a handful of readers connect with like-minded peers and escape their hellish office settings, that would be enough good to last me a lifetime. Plus then I can probably do some corporate backstabbing and stay karma-positive. Take me to management, baby, I want to buy an expensive hammock. Subscribe via RSS / via Email. Powered by mataroa.blog.",
    "commentLink": "https://news.ycombinator.com/item?id=38095542",
    "commentBody": "What the Goddamn Hell Is Going on in the Tech Industry?Hacker NewspastloginWhat the Goddamn Hell Is Going on in the Tech Industry? (mataroa.blog) 219 points by l0b0 7 hours ago| hidepastfavorite191 comments sho 6 hours agoI didn&#x27;t write any reply to the original, but enjoyed reading it, and this one too - but as someone who&#x27;s been on both sides of the IC&#x2F;Senior Management divide, mixed with and worked with plenty of C-level types and has a pretty good understanding of how companies \"really\" work - none of this is shocking. It&#x27;s not even surprising. It&#x27;s just really, really hard to organise a large group of people towards any common purpose, let alone profitably, let alone efficiently, especially in something so relatively new and little-understood as tech.You think it&#x27;s hard trying to find good programmers? Try finding good managers. reply lapcat 3 hours agoparent> You think it&#x27;s hard trying to find good programmers? Try finding good managers.There&#x27;s an ambiguity in the word \"good\": it can mean skilled, but it can also mean ethical. Personal ambition and greed can turn any organization dysfunctional, even if everyone is highly skilled. And you can&#x27;t really blame individuals within a company for wanting to make as much money as they can, because that&#x27;s more or less the point of the company itself.As far as management is concerned, smart ethical people who are inexperienced will eventually become better at their jobs through experience, though this may involve a lot of trial and error. But in a certain important sense, smart unethical people will never become \"better\" at their jobs.By the way, I personally don&#x27;t think it&#x27;s hard to find good (skilled) programmers. Companies make hiring a lot harder than it needs to be. Despite my years of documented excellence and my success as a self-employed indie developer, I&#x27;m essentially unhireable by most companies, because I&#x27;m not good at, or indeed willing to devote myself to, jumping through the arbitrary flaming hoops they set up to keep people out.Perhaps this is an ethics problem too. Everyone seems very concerned about candidates who lie about their résumés. But for some strange reason, companies are exclusively focused on trying to evaluate the skills of candidates rather than evaluating their ethics. Here&#x27;s a thought on this subject: companies practically demand that job candidates lie to them about the reasons they left their previous job. The truth is that a lot of people quit because their previous manager was an idiot or an asshole, but nobody is allowed to say that in a job interview, otherwise you&#x27;d be immediately rejected as someone who has a \"bad attitude\" and is not a \"team player\". In other words, playing along, having a \"good\" attitude, means lying. reply fnimick 2 hours agorootparentI question your assertion that companies are looking to select ethical employees. In fact, I would argue they are looking to select unethical employees who know the game well enough to play along for the appearance of ethics (see: expectation of lying in a job interview)Given the choice between someone who will have ethics and someone who will make money unethically, companies will choose the latter every time. And the people who are willing to be unethical to get ahead are the ones who get rewarded internally once hired. reply lapcat 1 hour agorootparent> I question your assertion that companies are looking to select ethical employees.I didn&#x27;t assert that. To the contrary, I said, \"But for some strange reason, companies are exclusively focused on trying to evaluate the skills of candidates rather than evaluating their ethics.\" reply gosub100 2 hours agorootparentprevsee also: painfully byzantine and demeaning hiring processes. I&#x27;m thinking \"behavioral assessments\", clumsy applicant tracking software from 2006, long waits between communication. Its not inefficient, its very efficient, in fact, at selecting for subervent mules who respond well to the stick and don&#x27;t need many carrots to stay in place. reply ChrisMarshallNY 2 hours agorootparentprev> I&#x27;m essentially unhireable by most companies, because I&#x27;m not good at, or indeed willing to devote myself to, jumping through the arbitrary flaming hoops they set up to keep people out.Can relate. I was also a very good manager, but hated the job, and no one was interested in hiring me as one, anyway, (lost at Buzzword Bingo, yanno).These days, I do my own thing, writing free software for folks that can&#x27;t afford people like me, and I&#x27;m really happy. reply kcplate 2 hours agorootparentprev> jumping through the arbitrary flaming hoops they set up to keep people out.Amen. Having HR set up some bullshit criteria and resume robot to presort your candidates, then subject the ones who fall through that sieve to stupid gotcha programming questions is an amazing way to develop the attitude that it’s “hard to find good programmers” reply sfn42 1 hour agorootparentThe only part of this process that I don&#x27;t have a problem with is the technical interview&#x2F;test.I hear people complain about this type of stuff all the time but based on the tests and challenges I&#x27;ve received they&#x27;re reasonable. I&#x27;ve never been asked by a potential employer to do anything I didn&#x27;t consider trivial or close to trivial. I&#x27;ve done some quizzes with easy questions (though the recruiters were very impressed that I aced them, apparently most don&#x27;t come close), I&#x27;ve done a technical interview where I implemented a simple vehicle registry based on stubs and tests, just basic C# programming (I didn&#x27;t even know C# when I did it, I knew Java) with basic data structures. A friend of mine had one where they were asked to implement a very simple frontend that gets some data from SpaceXs graphql api and display it in a table.All of these are completely reasonable expectations for a competent developer. I could easily complete all of them as a fresh graduate with no work experience.I understand not everyone is this reasonable, what I&#x27;m saying is that I think these kinds of simple exercises are a reasonable way to eliminate candidates who actually don&#x27;t know basic shit you would expect them to know. There are a lot of them, even with degrees.It&#x27;s pretty much just bias. I&#x27;m biased towards these tests because to me they&#x27;re trivial so it benefits me that I get an easy way to stand out. I also wouldn&#x27;t want to hire anyone who can&#x27;t do simple basic programming tasks, so I sympathize with the employers in that regard. On the other hand you have people who are mad because the tests reveal their incompetence. reply fnimick 1 minute agorootparentThe problem is when the tests let in \"too many people\" for big companies, they end up ramping them up to be unnecessarily hard to compensate. Then small companies feel that they need to copy what successful big cos do, so they end up with insane leetcode problems and then complain that they can&#x27;t get any good candidates because they&#x27;re all failing at the arbitrary barrier specifically designed to cut out 99% of the applicant pool.When I hear \"technical test\", I don&#x27;t think \"reasonable implementation\", I think of the interview I was in where I was asked a moderately difficult graph question, I reasoned my way to the solution from scratch, then got cut from the process with the explicit feedback that I should have recognized Djikstra&#x27;s algorithm and had it memorized rather than needing to derive the correct solution myself (!!!)(that still blows my mind, apparently being able to understand the problem and derive the correct solution is worse than memorizing it) nobodyandproud 3 hours agorootparentprevIt&#x27;s not just intelligence and ethics but a strong-enough personality and verbal skills--yes, I&#x27;m projecting here.I can&#x27;t overstate how difficult it is to say \"no\" in the moment, and do so in a way that doesn&#x27;t make you a problem and target in senior management&#x27;s eyes. reply RandomLensman 1 hour agorootparentprevYou are allowed to say your previous manager was bad, but you are expected to be able to say it in certain ways (\"development opportunities\", \"technical direction\", \"team vs individual responsibilities\", ...). reply ludicity 5 hours agoparentprevVery fair. The funny thing is that I&#x27;m pretty jaded, and people tell me that I&#x27;ve got the wrong read. Then I see comments like this where people say \"This is so obviously true that it&#x27;s crazy it bears mentioning\".I suspect that it actually is surprising for some people, but based on the emails I get, it&#x27;s mostly cathartic because so many engineers spend time being told by management that they&#x27;re imagining all of this. Because, as you&#x27;ve said, it&#x27;s super hard to find good managers. reply ljm 3 hours agoparentprevGood management and leadership is also hard to quantify because it&#x27;s a bidirectional relationship. The best manager in the world is going to struggle with a direct report who doesn&#x27;t want to play ball, but will do a fantastic job with those who nurture the relationship or are trying to find their feet in their career. A poor manager isn&#x27;t going to succeed with either of those people.I find the author&#x27;s dry sense of humour quite amusing, and I feel for them because I&#x27;ve been there. Most of us have been there I expect. I would say that feeding this mindset is likely to lead to burnout in the long term.A lot of these issues are as inevitable as they are utterly confounding and at some point in your career I think you need to find that sweet spot where you can do your best work without having to push back too hard against the organisation. If you can manage to find that peace of mind then you&#x27;re golden, and if you&#x27;re lucky you can stay in a positive mindset or at least delay the onset of Jaded Greybeard Syndrome. reply kmac_ 2 hours agorootparentEvery talented junior and mid hits this wall at some point. This is where a new mindset and new skills have to be acquired: moving with the whole company in the same direction and improving it from the inside. Pointing out inefficiencies is important, but more important is how you do it and to who. It&#x27;s easy to complain, it&#x27;s hard to act accordingly. reply vsareto 1 hour agorootparentBut why should any of us bother picking up new skills and adjusting mindsets if the author has to fight for a raise after saving the company $500k?Secondarily, why should the author continue to fix things like this when they don&#x27;t benefit, but others responsible are also not facing any consequences? reply ljm 9 minutes agorootparentYour skills and mindset are going to help boost your career when it comes time to find a new position. It&#x27;s not really for your employer&#x27;s benefit, but your own, and the job is just a convenient way for you to learn some new things for yourself rather than doing it at home.Loyalty to a company isn&#x27;t rewarded today the way it used to be, so you just have to take that experience to a company with a better proposition at some point. reply kmac_ 1 hour agorootparentprevWell, this is an internal driver. A person has it or not. (Just like technicall skills but in a different area.) reply vsareto 1 hour agorootparentIf you do it for yourself, that&#x27;s great, but you should withhold the benefits of that from the company if they aren&#x27;t going to reward you for being better. reply kmac_ 47 minutes agorootparentI don&#x27;t expect any reward, praising or eternal glory. I&#x27;m paid for doing the job. At some level, and to get to that level, doing a contract minimum is not enough. replynpteljes 5 hours agoparentprevI wholeheartedly agree with this sentiment.I think that people are looking at waste in a wrong way. It&#x27;s relatively easy to point out inefficiencies in a working system. What&#x27;s harder is organizing a working system. Energy and attention are finite on many levels, and this is true on the organizational level too. Let&#x27;s pick an example of a computer game. Games are usually riddled with performance problems, in fact, I think that it&#x27;s hard to find a well-optimized game. Yet many of these inefficient games provide good fun for a lot of people. As it turns out, engine efficiency is not a top priority for a game, there&#x27;s much more to it, like the game design, level design, and the context of the game, which is marketing, timing the release, setting the price, and so on. reply boredumb 1 hour agoparentprevManaging people is easy if you are personable and have the ability to adapt to culture and the people that comprise it. (managing 5 people is different than managing 20 people, which is different than managing 20 people in a different target industry)Being a good manager also means shielding groups from other groups and making yourself the filter so you aren&#x27;t wasting productive peoples times in endless meetings that are generally for other groups to show they are working to the wider company. You also have to provide a non-technical analysis of the internal state of the product&#x2F;teams&#x2F;tech to people outside your team. Those are the two hard things, everything else should be figuring out how you can make your team operate at it&#x27;s highest levels without burning people out and hating their job. reply randomdata 2 hours agoparentprev> Try finding good managers.Is that necessary? I know &#x27;Agile&#x27; isn&#x27;t cool anymore, but at the heart of the Agile Manifesto is a suggestion that every contributor on the team should share in the management role rather than having a dedicated manager. Granted, it also suggests you need motivated people. reply ljm 5 minutes agorootparentEvery contributor can share the product or delivery management role, sure, but it doesn&#x27;t really follow that 1:1s, career discussions and compensation reviews are also handled by the team, and those are important functions served by a manager. reply timmg 2 hours agorootparentprev> Is that necessary?Yes, it is.First, you can&#x27;t expect everyone on the team to have all context on everything. That would be an incredible waste of everyone&#x27;s time. Second, even if everyone did, in most cases the individuals would disagree on priority -- someone needs to be the final arbiter.In practice, few people will make the \"best decisions\". They will often rationalize what they want. A leader needs to be there to \"check\" those decisions. reply ryanklee 2 hours agorootparentprevThe amount and kind of work that managers do cannot be distributed across a scrum team. It&#x27;s literally impossible and attempts to do so would be abusive and would tank productivity. reply kunley 2 hours agoparentprev\"It is really, really hard to organize a large group of people towards any common purpose\"Well, one very healthy rule to organize people is that people are responsible for their mistakes, which has a long-term effect of having less mistakes instead of having them covered under the carpet and still biting. reply darkerside 2 hours agorootparentIt all comes down to defining what is and isn&#x27;t a mistake. A mistake at the team level may be an organization win and vice versa. And the instant you change the incentives to fix this, you are upsetting someone else&#x27;s apple cart. reply gibsonf1 2 hours agoparentprevIt seems like Tesla and Spacex prove it’s quite possible to do at scale. reply randallsquared 1 hour agorootparentAssuming by \"it\" here you mean> to organise a large group of people towards any common purpose, let alone profitably, let alone efficiently, especially in something so relatively new and little-understood as tech...I don&#x27;t think those are good examples. The very sympathetic recent bio of Musk details a lot of dysfunction in those organizations, and they largely achieve anyway by leaning on The Mission, working people harder, driving burnout, and then discarding them. reply api 43 minutes agorootparentThat story of mission driven burnout happens a whole lot in human history. During the race to the moon in the 60s I recall reading about the epidemic of broken marriages and families around the space program due to overwork and burnout.A troubling question I often ask is: is it possible to do big things in a healthy balanced way? Or is greatness intrinsically a “Moloch” that demands human sacrifice? (That imagery was inspired by the 20s film Metropolis that touches on this question a little.)If the latter is true then I don’t think this bodes well for the future of our species. It means we either die in the fire of our own striving or we die quietly in mediocrity, but either way we die. There’s never a lasting positive outcome.BTW Elon Musk himself looks an awful lot like a victim of his own burnout culture. I suppose you can give him credit for taking his own medicine. reply gumballindie 5 hours agoparentprevTech companies need tech leads not managers, or managers with a solid technical background. Otherwise it ends up in a mediocre show of power and power games such as those described by the author. Sitting on your bottom and holding meetings all day long and discussing processes for the sake of processes has no place in tech. Tech companies need to understand that. reply swiftcoder 5 hours agorootparentYou can&#x27;t be an effective tech lead in most (large) companies without at least passable ability to manage all of your dev team, your counterparts in product, and your management chain in general.As a result, a lot of tech leads are engineer->management conversions who just haven&#x27;t made the leap yet. reply gumballindie 3 hours agorootparent> As a result, a lot of tech leads are engineer->management conversions who just haven&#x27;t made the leap yet.And thats how it should be - folks with a technical background doing the management of technical people and work. How can you even manage that which you dont understand? Ticking boxes and measuring output is not management, that can be delegated to a script and graph charts. To manage the delivery of a technical project you need to understand the technology behind it - in an equal amount to how well you understand communicating with business stakeholders and balancing business and tech needs. And no, taking a udemy course in programming python doesnt mean you have tech experience, equally taking a udemy course in agile doesnt make you a manager. reply jt2190 2 hours agorootparent> How can you even manage that which you dont understand?Unless you’re an expert at literally everything, there is something in your life that you have to manage that you have no expertise in.The typical way these things are managed is through measuring outcomes rather than focusing on how the work is performed. Tools include setting goals and milestones, auditing, cost bidding, reputation, etc. replyyterdy 5 hours agoprevMy \"Crack Theory That Everyone Is Going To Hate\": the tech industry as we know it arose out of the Great Financial Crisis and was a way to ensure that people with the \"right\" educational and professional pedigree were getting the spoils of the money-printing that was preventing the utter collapse of our economy. (Dotcom-era salaries vis a vis productivity were high, but not anything like today.) No one has to do anything because \"job creators\" don&#x27;t care; tech workers are just a convenient receptacle to prevent a wage-price spiral in the broader economy. Here&#x27;s some money, kid, go to town, don&#x27;t start any fires. The accountability that does exist is largely for social, rather than business, reasons; \"Don&#x27;t make me look bad,\" instead of, \"Make me money.\"Bonus, re: layoffs: Now, we are on the verge of another massive deflationary crisis for which we don&#x27;t have any solution once the ball gets rolling, so such workers are no longer useful. The coddling ends, cuts to the bone begin (and justifications like TFA start appearing). Pigs get slaughtered. reply sandworm101 5 hours agoparentTo add to the concept, how a tech company today makes money is very different than in the past. Profit doesnt matter anymore. It is all speculation against the dream of future profits once a tech company dominates a market. Money people will pay the kids because in faint hope of being on the ground floor of the next facebook or microsoft. But with entrenched companies now dominating tech, nobody will be the next microsoft. Investors are starting to realize those days are gone. Tech companies will be started and many will succeed, but now must actually compete with each other, often in courtrooms, to justify why they should be allowed into existing markets.Look at nokia. A few decades ago anyone with a billion dollars could start making cellphones. Good luck with that today. You would need a hundred billion, and a few decades of IP lawyering, before being allowed to compete with the likes of apple&#x2F;samsung. If your device has a touch screen and connects to the internet, you will suffer innumerable patent issues. reply javcasas 3 hours agorootparent> Profit doesnt matter anymore. It is all speculation against the dream of future profits once a tech company .Oh, this time is soooo different to the dotcom crash, where it was speculation on companies, where profits didn&#x27;t matter because it was the dream of future profits once a tech company . reply EVa5I7bHFq9mnYK 1 hour agorootparentI remember large celebrations of a first ever profit eked out by an internet company, namely Yahoo. reply infecto 3 hours agorootparentprevProfit has always mattered. The only change in attitude was because of historically low rates, it was easier to get more funding. Cheap rates = cheap money, investors are more willing to part ways. reply jt2190 2 hours agorootparentYes, cheap money literally means “profitable next year” becomes “profitable _someday_”. To people who have only been in the tech industry for the last decade this feels like “profits don’t matter” because it’s never been “someday” in their entire careers, but now with interest rates back up “someday” is coming very fast at many companies (and has maybe already arrived at some). reply kakwa_ 1 hour agorootparentprev> A few decades ago anyone with a billion dollars could start making cellphonesDid you mixed-up million and billion?A billion dollar is a gigantic pill of money. This feel a bit like saying \"anyone with a British crown on his head can reign over the UK\".Also, looking at Fairphone, they operate with a fairly reasonable budget: all revenue, including phone sells in 2022 are around $60M, and if we exclude production, ~$17M are needed to pay for product development, marketing, support and all other expenses for a year. At 2 years to create a phone, that&#x27;s ~$30M. reply packetlost 1 hour agorootparentprev> But with entrenched companies now dominating tech, nobody will be the next microsoft.Idk, wasn&#x27;t this the sentiment 30-40 years ago towards IBM? reply brigadier132 3 hours agorootparentprev> Profit doesnt matter anymoreUh, you might have not been paying attention to it but profit does matter now. If you look out the window you can see all the startups doing mass layoffs or going out of business. reply cmrdporcupine 2 hours agorootparentprev> Profit doesnt matter anymore.Until it does.Also, Google etc clearly are profitable. Insanely profitable. The question is... how? I think people are right to question whether the majority of the employees are engaged in work which ensures this profitability. But that&#x27;s not the same as saying there&#x27;s no profit.It&#x27;s all built on an edifice of advertising, which feels like a bit of a sandcastle to me. But I am also of the .com generation that saw the whole beach wash out into the ocean once already, and never understood how the advertising thing actually ended up yielding profits, and was initially quite pessimistic about the Google IPO (though was happy to take money from them by working there for a decade).I&#x27;ve seen the CPMs and the CPCs from the inside. I don&#x27;t get it. I worked on ad servers and in realtime ad bidding. But I still don&#x27;t understand why ads make money. reply gosub100 41 minutes agorootparent> But I still don&#x27;t understand why ads make money.total guess here, but instead of thinking of an ad as something that actually converts someone into a paying customer, maybe it&#x27;s more about buying \"mental real estate\"? If nobody knows your brand, you have almost no sales. If you&#x27;re at least in the neighborhood, then by pigeonhole principle, at least some customers will stop at your property. So maybe ads are a sort of dilemma that (with very few exceptions), your business must burn money on advertising just to stay in business? reply cmrdporcupine 17 minutes agorootparentAbsolutely, I get this impressions-as-marketing thing. But this also seems remarkably vulnerable to recession economics.Back when I worked in ads, the line was always that digital ads budget were still a fraction of what was being spent in traditional media, and so there was huge room to grow. I&#x27;m kinda guessing this is no longer the case. reply BlueTemplar 2 hours agorootparentprevThat&#x27;s what IBM thought.And this doesn&#x27;t even take into account the possibility of these companies getting forcibly shut down &#x2F; competitors coming in from outside.The only question is how long will this take ? reply infecto 3 hours agoparentprevThe only reason people might hate it is because it has no proof or defense of the argument. Its a narrative that would require so many steps that its hard to imagine being true.How about a simpler reason. During the mortgage crisis&#x2F;recession the fed rate dropped to historical lows. Cheap money is good for startups. The economy was doing well for a decade and towards the end of that decade rates started to creep up and we got hit by a black swan, a pandemic. Rates crashed again + stimulus money and incredibly strong consumer spending and we now have high inflation. The rates go back up and its less attractive for startups&#x2F;tech companies. reply randomdata 1 hour agorootparent> stimulus money and incredibly strong consumer spendingSeems like you are ultimately operating on the same theory: That tech was used to keep the \"Great Financial Crisis\" money away from the broader economy in order to prevent an inflationary spiral. It is unlikely that it was fully pre-meditated in exacting detail, but it is clear that the money &#x27;printed&#x27; was directed to interests that would not spend it on bread, so to speak.The pandemic stimulus changed that. It saw &#x27;printed&#x27; money flow to regular average Joes who would spend it on bread, and thus consumer inflation took hold. That is what earlier stimulus packages were trying to avoid. reply yterdy 3 hours agorootparentprevYou&#x27;re right, it&#x27;s a holistic rather than analytical argument. I would at least say that part of the \"proof\" is in the fact that it&#x27;s trying to explain what&#x27;s in the article it&#x27;s responding to, which we&#x27;ve taken to be true on its face. That&#x27;s the mechanical action, but I agree that it&#x27;s difficult to show the intent I accuse tech boards ad C-suites of. All a bit circumstantial, innit?>Cheap money is good for startups.We&#x27;re talking about MEGAMAN (E stands for \"Everyone else that fits the definition in my head\"). Big, relatively established corporations. I would also counter that real income didn&#x27;t budge after the GFC, so saying that \"the economy was doing well\" is stretching things. reply niodnyod 4 hours agoparentprev>\"Crack Theory That Everyone Is Going To Hate\"Because you&#x27;re going to have to explain how it works.>way to ensure that people with the \"right\" educational and professional pedigree were getting the spoils of the money-printing that was preventing the utter collapse of our economy.How is giving money to the \"right\" people supposed to do that?>tech workers are just a convenient receptacle to prevent a wage-price spiral in the broader economy.How is giving money to these people in particular different than giving money to, say, nurses? reply tl 1 hour agorootparent> How is giving money to the \"right\" people supposed to do that?According to various studies there is a limit to how much money per year changes your base happiness. The ones I have read say $80,000 but inflation probably makes that a dated number. Everybody meaningfully burning more than that is either a member of the upper class buying superyachts or stuck in a red queen race like a speculative real estate market or collectibles. The ones who make more than the happiness threshold who don&#x27;t have some other sink for it (the majority) prudently lock it into index funds where it&#x27;s made available to the people who didn&#x27;t want to lose control in the first place. That is the \"how\".> How is giving money to these people in particular different than giving money to, say, nurses?Canonically, there are three competing types of people getting paid out with some overlap:1. Small business professionals. The standard here is your family doctor or dentist. Restaraunt owners also qualify. These groups deal with fairly intense regulation &#x2F; \"insurance\" policies to limit how successful they are.2. High-end white collar workers. Prior to the tech bubble conscripting software engineers, the usual suspect was lawyers. Lawyers have a wide gulf in compensation between \"Ivy League Grads at BigLaw\" and everyone else. That trend mirrors the current trend of BigTech vs. everyone else as described in the \"Crack Theory\". Look up \"bi-modal salary\" for more details.3. Strikers. The halls of power are more than willing to max out the happiness threshold of anyone from auto workers in the 50s to airline points in the 90s who can make a credible threat that the spice will not flow. Power is willing to do this because they have spare money to print and the ability to strip the compensation long term by shifting jobs around. Based on current events in NJ, you may or may not get to watch this pay out in real time with your nurses. reply badcppdev 3 hours agorootparentprevIt&#x27;s because the tech economy is a new pathway for money to flow. The wage inflation spiral that terrifies economists is where current jobs start paying more which leads to inflation in prices for goods and services which leads to the requirement for higher wages... I think that&#x27;s the theory of the wage spiral.So OPs theory is that the government can print money, boost GDP, and pay out profits to the owners&#x2F;shareholders but not trigger the inflation... until now reply yterdy 3 hours agorootparentCorrect. The people we&#x27;re talking about - Ivy League alums, the children of professionals, immigrants, and people who want to be like them - are much likelier than the average American to drive their wealth into assets and savings. Housing prices, stock prices, retirement portfolios would balloon, not (for the most part) the prices of everyday goods.Which is what happened; the wage-price spiral that we did see was largely localized to Silicon Valley&#x2F;San Francisco (and, to a lesser extent, a few big cities). Until the Sept. &#x27;19 repo crisis and then the pandemic, of course. reply MicolashKyoka 3 hours agoparentprevThis is nonsense. How are multibillion dollar companies accountable to shareholders and other owners willingly giving away money for some nebulous principle such as having the \"right\" people make money. Conspiracies should at least be based on some tangible elements. Fringe roles are too few to be seriously considered.The reality is that it&#x27;s all a matter of supply and demand. Ofc, there is waste, but any industry having margins like google are bound to excesses eventually if leadership doesn&#x27;t intervene. reply yterdy 51 minutes agorootparent>How are multibillion dollar companies accountable to shareholders and other owners willingly giving away money for some nebulous principle such as having the \"right\" people make money.Because of the specter of the alternative, once QE et al. started. Proven by the fact that it straight-up started happening anyway when the (completely justified) COVID helicopter money started flying.Of course, there were other options:>Vacuuming up the excess money supply through taxation before it became a pillar of an entire sector&#x27;s business model>Accept lower profits, executive compensation, and asset returns by letting worker pay rise without raising pricesBut those are anathema, I suppose. Which is why it didn&#x27;t take a conspiracy for everyone to act in such a way that what&#x27;s described came about. reply brianolson 3 hours agoparentprevI have heard many times: Google hires good engineers not to _do_ things, but to _not do things elsewhere_. (even if 80% of Google engineers are &#x27;productively&#x27; working on products Google cares about, thats thousands of grade-A engineers spinning their wheels, and given the rate Google discontinues and replaces its own software, 80% is certainly high) reply cmrdporcupine 1 hour agorootparentI have propagated this meme. It&#x27;s only partially true.SREs at Google are generally an insanely good use of Google&#x27;s resources in keeping actually profitable services (like ads, search, cloud, etc.) running and running at a standard that I think few non-Googlers on this forum really have a concept of.But the bulk of SWEs are working on developing things which are not part of those Product Areas. I actually don&#x27;t think the discontinuation thing is the main problem. The problem is that outside of Search, Ads & Cloud, pretty much nothing else at Google is really a profitable revenue generator. But you don&#x27;t need >100k engineers to make the profitable stuff run. There&#x27;s only so many ways to sling ads and report on them and build the infra for them.But Google&#x27;s conundrum is that if they just focused on those areas, someone would eventually come along with something that would eat their lunch. So in the past Google would prefer to a) hire those people and shower money on them to stop them from doing that and b) farm out a bazillion \"bets\" and projects to try their hand at that stuff in the hopes of striking a vein of gold again, like they did with AdWords 20+ years ago.Cancelling projects is the byproduct of this continual search for new gold veins.Also a lot is changing now. SV execs seem to have made a gentleman&#x27;s agreement among each other to tighten the labour market.Anyways, I think Meta is in more trouble than Google, long run. They&#x27;re in a much riskier, shakier position. reply AnimalMuppet 2 hours agoparentprevIn addition to what others have said:> Now, we are on the verge of another massive deflationary crisis for which we don&#x27;t have any solution once the ball gets rolling...Um, what? Deflation? No, that is not the crisis that we&#x27;re on the verge of. reply yterdy 59 minutes agorootparentWell, the jury&#x27;s still out, but the important thing to consider is what credible threat is keeping Powell from going full-Volcker and slamming on the brakes.I wouldn&#x27;t say that we&#x27;re on the verge of an inflationary crisis because we&#x27;ve been in one, which we do actually have tools necessary to try to thread the needle. However, China, Japan, and the US commercial real estate market loom ominously over proceedings (and also that one thing no one is thinking of). reply AnimalMuppet 53 minutes agorootparentGoing full Volcker is not called for. Inflation hasn&#x27;t been building for nearly two decades; it&#x27;s been nearly nonexistent for nearly two decades. Inflation hasn&#x27;t reached 14%, nor anything close. They are, as you say, trying to thread the needle. That&#x27;s still an option, and a less damaging one than going full Volcker.> and also that one thing no one is thinking ofDon&#x27;t vaguepost. If you&#x27;ve got something to say, say it. reply yterdy 36 minutes agorootparent>Going full Volcker is not called for. Inflation hasn&#x27;t been building for nearly two decades; it&#x27;s been nearly nonexistent for nearly two decades. Inflation hasn&#x27;t reached 14%, nor anything close.It&#x27;s actually about 20-30% since 2020, if you measure the way they used to. People at the bottom are hurting, but the goal is to prevent full institutional collapse, so they get sacrificed in a slow walk to stabilization that risks hyperinflation, versus just getting it over with and starting on a recovery.>a less damaging one than going full Volcker.Well, a lost generation or two begs to differ.>Don&#x27;t vaguepost. If you&#x27;ve got something to say, say it.Unknown unknowns. I have no idea where a hypothetical sucker punch is coming from because it&#x27;s a sucker punch. replyJackMorgan 4 hours agoprevI have one opinion why this happens.Imagine you&#x27;re in charge of Google Search in like 2005. You&#x27;ve got a killer product that could probably be run realistically by 50 extremely good engineers working efficiently. Take out server costs, what&#x27;s your profit margin, like 99%? Well if you&#x27;re the board, and you&#x27;ve got a 99% profit company, what do you do? On the one hand you can get rich and call it a day, but then how long before a competitor builds the same exact product and you lose half? Or lose everything if everyone switches?So you take a huge chunk that money and reinvest it with the hope of cementing your position or finding another product.At this stage there&#x27;s tons of money flying around. Internal projects are started and stopped constantly. Extreme inefficiencies are tolerated, after all, as the business grows, plenty of people just want to get paid and do as little work as possible. reply prepend 3 hours agoparentI think it’s probably basic accounting math.Let’s say you can make $100B with 50 engineers at 99% profit margin. You pay your employees $1B and they are the highest paid in the world and all ecstatically happy and the stockholders make $99B and they are pretty happy too.The board decides they’d rather make $300B at 50% margins because that’s $150B to investors. So it’s lower margin, but they’ve already invested and they just want more money.Of course, I know many programmers that have insanely high profit margins with 1-4 employees and will never go public and no one except for an IRS computer will know they exist.I think corporations are usually pretty efficient. It’s just not always clear what they are efficient toward. reply tcgv 42 minutes agorootparent> I think corporations are usually pretty efficient. It’s just not always clear what they are efficient toward.This. People often examine things on a small scale and lack the context to understand why certain aspects appear counterintuitive. Once we gain a broader perspective, things begin to make more sense. reply Cthulhu_ 2 hours agoparentprevYup; any department with money in their budget left over at the end of the budget period will see their budget reduced, even if they need it.And (I&#x27;m theorizing here, I know little of management layers) I&#x27;m confident that a manager&#x27;s wage is a percentage of a department&#x27;s budget. Therefore, it&#x27;s in their interest to use up and ask for more budget constantly. reply robotcapital 1 hour agorootparent> Yup; any department with money in their budget left over at the end of the budget period will see their budget reduced, even if they need it.Anecdote here. I&#x27;ve been a senior manager at small, medium, and large (ie FAANG) tech companies over the past 20 years and I&#x27;ve never run into this. Teams make a case for the budgets they need and those are approved (or not) based on the finance team&#x27;s overall guidance and the return on investment. I&#x27;d be curious if others have have actually seen this \"use it or lose it\" mentality for budgets in practice.> And (I&#x27;m theorizing here, I know little of management layers) I&#x27;m confident that a manager&#x27;s wage is a percentage of a department&#x27;s budget. Therefore, it&#x27;s in their interest to use up and ask for more budget constantly.Again, not my experience. Like you say, this would create perverse incentives which would quickly become apparent to a company&#x27;s overall finances.I don&#x27;t doubt these sorts of policy mistakes have happened at other companies in the past, but I&#x27;m doubtful that they&#x27;re pervasive, or even common, in the tech industry. reply KineticLensman 2 hours agorootparentprev> And (I&#x27;m theorizing here, I know little of management layers) I&#x27;m confident that a manager&#x27;s wage is a percentage of a department&#x27;s budgetUnlikely in a conventional organisation with salaried staff split into multiple depts &#x2F; divisions. Bonuses may depend on the performance of a specific dept but base salaries typically have company-wide bands. reply onlyrealcuzzo 2 hours agoparentprev50 engineers couldn&#x27;t even keep Borg running, let alone keep all the machines maintained, let alone procure new ones to keep up with growth, let alone do any product development to get any growth, let alone keep up with the regulatory changes constantly coming in necessary to even operate. reply EVa5I7bHFq9mnYK 1 hour agoparentprev>> Take out server costsServer costs were actually bulk of the costs, not engineers salaries. reply mplewis 2 hours agoparentprevWhy do people keep spouting stuff like “I bet 50 people could run golden era Google search?” There’s no reason to believe this. reply arh5451 5 hours agoprevThe tech industry and business in general has an enormous challenge in how management is hired and selected. Currently it is either. 1. Selected by MBA or some management certification 2. Engineers who perform well&#x2F;are more visible. Both are really poor choices for technology related management roles and inevitably lead to unethical&#x2F;poor management practices regardless of the firm in many cases.The best manager traits are usually soft skills which are nearly impossible to measure and more impossible for HR to find (HR departments are largely lost in tech hiring). I think if you want to see examples of excellent run large companies you need to look in the places where there is an internal culture of up-skilling employees whether its rotational leadership programs or learning credits. Often my experience is they are much better run and invested in the people and it is reflected in the managers&#x2F;management. reply travisgriggs 3 hours agoparentOne of the interesting things about the tech industry (to me) is the presence and massive success of open source movements. OS does some things well, and others not as well, but it does it with 1&#x2F;100th of the familiar management institutions we’re used to in the workplace. I don’t know what the answer is, but it makes me wonder if we haven’t somehow mis-arranged the whole thing. I’m old enough that I recall a time when organizations had secretaries, sometimes many. Now days it feels that management is really just the above, getting paid “higher than the rest of you” salaries to do what more equal secretary&#x2F;clerk functions used to do. reply diarrhea 3 hours agorootparentI suppose the difference is money. Open source needn’t be free of its involvement, but it often is. Add money to open source and you get either a functional org, but with the usual overhead, or dysfunction and corruption. reply shrimp_emoji 1 hour agorootparentMoney is the root of all evil.Often, nobody would be doing the closed source stuff they&#x27;re doing without the cold incentive of money, unlike free software which is inherently decoupled from a profit motive. Maybe there&#x27;s an externality to pay in herding and keeping the cats committed to the profit motive. reply kibwen 3 hours agorootparentprevSpot on. The only difference between a manager and a secretary is that one is above you on the totem pole and the other is below. reply koliber 4 hours agoparentprevIt’s possible to develop those soft skills. Management concepts can be taught. It’s possible to teach a good engineer how to use existing management frameworks.Trouble is, often the learning materials are written in a way that does not “land” for people with an analytical technical background.Translating management tools and concepts into tech speak for engineers on the management has been my job for a good part of the past decade. It can be done. reply Yeul 4 hours agorootparentI don&#x27;t think so. Lots of people went into IT because they don&#x27;t have those soft skills. If you&#x27;re in management you need to be a people person.I think HN underestimates the amount of petty bullshit that managers have to fix in order for a company to function reasonably well. reply bsenftner 3 hours agorootparentHN also underestimates the level of pettiness in the non-people-persons who became managers in tech. I was recently down voted for commenting that the typical tech manager does not want their engineers to have communication skills such that they can push back on unreasonable demands. My experience has been that is absolutely true; sure, they will say they want quality communications, but only as long as those communications are in agreement with whatever that manager and management want. Try telling them the truth that the overall architecture is bad, or there are these fundamental negative issues that were never addressed and are now consuming larger and larger resources to continue to \"ignore\"...Actually being a material operator in a company that makes a difference is exactly what many, the majority, of middle managers simply can&#x27;t handle. It scares them. It is too large, too aggressive, and demands too much upper level communications they can&#x27;t handle. Not rocking the boat is the only game most managers know how to play, as the management above them appears simply untouchable to them. reply P_I_Staker 3 hours agorootparentprevYes, I think part of the problem is we view social skills, charisma, etc. as givens, or even as virtues.We forget that these things actually take a lot of brain function, it&#x27;s an ability. It&#x27;s something we do effortlessly, but there&#x27;s actually a lot going on.For example, struggles of people with ADHD and ASD can be hard to understand because many things that we take for granted are harder and more nuanced than people realize. reply sauwan 4 hours agorootparentprevCan you speak more to this? Any suggested resources for companies struggling with teaching management skills? reply bsenftner 5 minutes agorootparentLook into Cognitive Distortions, the fancy words for \"how people play themselves\". I&#x27;ve found that poor management and impostor syndrome are both manifestations of self deception. For managers, self deception takes the form of not listening or not taking seriously to developer concerns, trusting their management&#x27;s every word rather than using critical analysis in all interactions with their management, and generally \"playing the Cover-Your-Ass game\" rather than actually being their upper management&#x27;s objective communication channel to developers and the objective voice for developers back such that both are functionally optimally in respect to the other. reply kunley 3 hours agoprevHere is a story not about wasting cloud resources, but about wasting careers:A decade-long project at the ThreeLetterYouknowwho was turning into a separate business, so people were being convinced to abandon their dozen-years old employments at the mentioned ThreeLetterGiant (evil or not, but at least with perspectives and an established routine how to live in this corp), so they did the move, only to be fired 5 months later, as the newly born company was reduced to a half, to fit into parameters required by some stock market related operation.The crux is that the management knew about all the planned moves when negotiating people&#x27;s leave from HAL (oops, I mean, ThreeLetterGiant). Yet they needed the massive flux of initial employees to fullfill some other business parameters. Everything was done with a cold blood.I wasn&#x27;t reduced this way (I wasn&#x27;t even at HAL originally, was part of the completely fresh hires) but I left these assholes a month after the layoffs. Even the mob is treating their own people better. reply ChrisMarshallNY 1 hour agoparent> Even the mob is treating their own people better.They actually treat them quite well. I know a number of ex-wiseguys.When you manage folks that, by definition, don&#x27;t like rules and structure, and can probably clip you in a moment, you learn to manage well.Bad managers don&#x27;t last (literally). reply f5e4 6 hours agoprevWow, I made it to the compliments page! I feel like it&#x27;s cheating a bit that I knew about the page before writing a comment.I don&#x27;t really have anything important to say, but I did find this interesting. I&#x27;m unused to this sort of indirect response. It feels slightly like a personal response, since he links to a page where my comment is one of a few added, and refers to \"commenters\". However, my criticism was close to the opposite of what he is replying to.I criticized the author for writing a story where I felt they mostly acted like a cog in a dysfunctional system, but was sneering at everyone else doing the same. I suppose, though, that perhaps they believe that the best&#x2F;only solution for being in a poorly-functioning company is to jump ship.edit: To clarify, I do agree that most corporate systems are dysfunctional and I&#x27;m not an agile fan. I&#x27;m not defending these systems. reply ludicity 5 hours agoparentHello! Sorry, that whole page is a bit tongue-in-cheek, but there are two types of comment on there. One batch is from people that... well, you can see that they&#x27;re like.The other half I put up there because I think they actually have me dead to rights. It&#x27;s one of those weird things where, being fairly young, I already know that I&#x27;m going to look back on many of the things I write and realize they were hot-headed, and I wasn&#x27;t nearly as good as I thought I was. I didn&#x27;t think the writing came off as smug - I&#x27;m pretty aware that I clicked five buttons and skipped a computer science education - but I still appreciate the reality check that maybe I -am- being obnoxious. It&#x27;s just fun to be a hothead sometimes, and I&#x27;m actually starting to get nervous with all the HN traffic. Yelling into the void is less threatening to my career.The only quibble I have with the original comment is the assumption I didn&#x27;t try very hard to let people know it was an issue - I promise I did, sometimes management just... doesn&#x27;t care.Anyway, what I&#x27;m trying to say is, sorry for any unintended offense I might have caused, because you were totally fair. It feels wrong to take it off the page anyway though! reply Spooky23 3 hours agoprevThe callous regard for human life jumped at me. My uncle worked for a big Wall St firm in the 80s and 90s. A CE from a big company was doing some early morning maintenance and long story short, had a heart attack and died in the data center.The ops people called 911, fire&#x2F;ambulance came — and were turned away at the door by security because they took too long and they needed to avoid impact to trading.Basically they put some sort of tarp on the guy and wheeled him in and out of the way throughout the day. My uncle was some sort of big shot, heard about it, came in and reamed out the security director guy. Pretty sure the family never knew. reply teeray 54 minutes agoparent> The ops people called 911, fire&#x2F;ambulance came — and were turned away at the door by securityIt’s astounding that impeding an emergency response wasn’t an immediately arrestable offense. If there’s a mortal threat and “security” is in the way, police should have every right to subdue the rent-a-cops. reply tester756 6 hours agoprev>There is a high likelihood that many other people in the org were lightyears ahead of the author. It&#x27;s even more likely that an engineer or manager in their group was \"Banking\" the inefficiencies to use during a cost-cutting period - and the author ruined that chance... which will inevitably cause massive suffering and possibly poor performance reviews when there is nothing to trim.\"That&#x27;s crazy, how it isn&#x27;t pure sabotage? career oriented people, jezz christ.That&#x27;s instant fire by me if somebody considered such a thing reply klabb3 6 hours agoparentSeems like a normal day in a corporation? Bean counters who decide your salary use beyond-stupid metrics. For instance, fighting fires is often rewarded disproportionately, so it’s good to be “visible” during many, recurring fires. Of course people game that, intentionally or unintentionally. You don’t get the behavior you say you want, you get what you incentivize.Even at pure tech companies with somewhat technically competent leadership the incentives are whack, and often the people at the very top are still replicating some MBA doctrine that will be debunked as horse manure within a decade.Just because our computers get exponentially better doesn’t mean people do, particularly groups of people. reply aardvark179 6 hours agorootparentI think there’s a spectrum here, I doubt many people are deliberately hoarding huge, easy, and &#x2F;certain&#x2F; cost or resource savings just to use later, but it is easy to end up with a long list of possible things that you haven’t had time to try, and won’t get prioritised until somebody else cares.Also, be careful what you wish for regarding cost savings. You may think you’re doing well saving 500k, but in a medium sized company there are likely a lot of easy ways to save a chunk more than that which you really aren’t going to like. reply arethuza 3 hours agorootparentI have a book about the management consulting industry that suggest there is at least one large successful firm of management consultants where the answer is always \"fire 23% - 33% of your staff\" regardless of what the question was.Apparently this is the level that most organisations can stagger on long enough for senior management to bank the bonuses and move on and upwards and before long term effects kick in. reply aardvark179 1 hour agorootparentYeah that’s always a bit depressing, but most companies only really seem to get the consultants in so they can be told the thing they were going to do anyway.I’ve seen good products and companies brought low by making the wrong bets and doing what was safe and sensible and cost reducing but not really thinking long term enough. They can stagger on for a long time still turning a reasonable profit until they suddenly don’t. reply arethuza 1 hour agorootparentI suspect senior management who hire that consultancy know exactly what will happen but they need the cover to be able to say that they had \"independent\" management consultants come in and look at the business and give their \"honest\" recommendations. reply BlueTemplar 2 hours agorootparentprevGP did mention that the whole project was actually a waste of money. reply aardvark179 1 hour agorootparentYeah, but I’ve seen plenty of very smart engineers over the years who can’t see why a business values X which they think is worthless but not Y which they think is important.I was thinking of all the other ways businesses can “save money”, like travel bans, or getting rid of nice things, or closing offices, or getting rid of staff… They may not really save money, but they’ll look just as good on somebody’s spreadsheet. reply OrderlyTiamat 48 minutes agorootparentprev\"Practical men who believe themselves to be quite exempt from any intellectual influence, are usually the slaves of some defunct economist.\" ― John Maynard Keynes reply blitzar 5 hours agorootparentprev> “visible” during many, recurring firesAlways turn up second or third to the fire otherwise they might suspect you of being the arsonist - Firefighter Arson is a real thing https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Firefighter_arson reply pjc50 5 hours agoparentprevOn that level? The original comment, which it is extremely funny to see getting roasted like this, was being hyper-cynical. It probably has happened somewhere but that level of dysfunction is not widespread.On smaller levels .. it is well-known in organisations that employ \"stack ranking\" that there is no incentive to get rid of poor performers immediately, and indeed an incentive to acquire one or two, so they can be sacrificed at stack ranking time. reply RandomLensman 6 hours agoparentprevSometimes companies are incentivised to grow, sometimes to cut costs - investors reward different things at different times. Knowing areas that could be trimmed and not trimming can be entirely rational then. reply Brian_K_White 4 hours agorootparentThat would be rational within an irrational context.That is still irrational, and I see no reason to forgive or excuse it instead of calling it out as irrational.It&#x27;s understandable, but that doesn&#x27;t mean tolerable or excusable, just that the mechanism by which the irrational process plays out is understood. reply RandomLensman 4 hours agorootparentIt&#x27;s is not irrational to follow the desires of the owners. And those desires need not be irrational either, as capacity for change and execution is limited in any corporation - focus matters. reply nullc 6 hours agoparentprevDo you fire engineers who consistently finish projects ahead of their estimates?Is any degree of sandbagging is a firing offense? If not, wheres the threshold?Is your organization completely and unconditionally free of mandates like each department must \"Cut budget x%\" or \"improve output by y%\" -- irrespective of the incremental cuts and improvements that a group may have had in recent memory? If not, isn&#x27;t a group that diligently finds and implements efficiencies at a disadvantage compared to ones that just don&#x27;t look until a mandate comes in?Kudos if you really do have an organization where there is no structural incentive to sandbag or otherwise bank results. reply aardvark179 5 hours agorootparentPeople who are consistently conservative in their estimates do get noticed, and the estimates adjusted appropriately in the same way that people who always under estimate get their estimates adjusted. That’s fine, the worst that’s going to happen is a conversation about learning from previous estimates.People who sandbag to give themselves an easy life, or to try and empire build by getting more resources, definitely get noticed, and not in a good way. reply rightbyte 4 hours agorootparent\"Adjusting estimates\" is just another way to force engineers to lie in their Jira tickets about how much time they spend on each ticket.At one point my agile master was complaining to me about estimations, so I just focused on reporting the correct amount of hours to make the burn down chart be straight. Decoupling reported time from actual time spent.Good lord I switched jobs. reply swiftcoder 5 hours agorootparentprev> try and empire build by getting more resources, definitely get noticed, and not in a good wayThis is actively incentivised in a lot of tech companies - maybe more so for managers than ICs, but the bigger-your-fiefdom the easier it is to promote phenomenon tends to be pretty widespread. reply aardvark179 5 hours agorootparentEmpire building is often incentivised, sandbagging to try and get those resources generally isn’t. reply couchand 3 hours agorootparentprevHumans are bad at estimation and there&#x27;s no evidence that \"having a conversation\" will make them any better at it.Your organization should acknowledge and handle the fallibility of humans, not try vainly to excise it. reply aardvark179 3 hours agorootparentIf your colleague always estimates that a particular type of task will take a couple of days, and it always takes a couple of weeks, you wouldn&#x27;t discuss it next time they estimate it is only going to take a couple of days?Yes, humans are bad at estimation, which is why it&#x27;s good to reflect on how well you do and to correct if you consistently over or underestimate. reply hardware2win 6 hours agorootparentprev>Do you fire engineers who consistently finish projects ahead of their estimates?>Is any degree of sandbagging is a firing offense? If not, wheres the threshold?Intentionally just to slack off or just because they arent sure or want use that time to improve other small thing? reply WJW 30 minutes agorootparentAs if the average manager can reliably tell the difference. reply blitzar 5 hours agoprev> two factions fighting to the death over how best to use a spreadsheet as a database for a production applicationRemind me again are we using production_database_v6_new_final22_final.xlsm or production_database_v4_final_finaldraft23_final_v2.xls ? reply _tk_ 6 hours agoprevIt is kinda interesting, that these rants about corporate life that are filled with little substance but with lots of swearing are so popular here. Is there one interesting takeaway here? Big organizations tend to grow in weird ways, opaque to the folks on the ground. They sometimes make big mistakes and spend money where they shouldn’t. But because of their size, that doesn’t mean the end for them. reply braza 5 hours agoparent> Big organizations tend to grow in weird ways, opaque to the folks on the ground. They sometimes make big mistakes and spend money where they shouldn’t.The article is good and at the end of the day, it&#x27;s a... rant.The core issue that substance the main point of the author is that we do not have a scientific and empirically validated method for management in technology (IT). This is expected since tech is a quite new industry that surged after the late 90&#x27;s.On top of it, we do not have established literature related to the economics of IT to calculate the opportunity costs, average acceptable waste, association between cloud costs x productivity and delivery value, and so on.Most leaders and managers are using methods that can or cannot work, but it&#x27;s a discovery phase now in how to establish a management method that covers inefficiencies, opportunity costs, and value. reply RandomLensman 3 hours agorootparentNot sure tech is fundamentally so different. There is typically a lot commonality between management practices of high performance companies across industries. There is also no reason to assume certain microeconomics don&#x27;t apply. Some benchmarks might be different or perhaps still patchy, but I don&#x27;t think that is really holding things back. reply RamblingCTO 5 hours agoparentprevFull of swearing? Have we read different articles? reply ludicity 5 hours agorootparentTo be fair, my other stuff is full of swearing. He&#x27;s got me there.Although I started writing at 6PM on a random day after a stupid meeting, and actually tend to agree that there&#x27;s worthier stuff to be popular - but people click on what they want.I have a whole bunch of more boring stuff around, with much less swearing, and I think I&#x27;m more comfortable with the low level of attention that gets. reply RamblingCTO 4 hours agorootparentWell, I don&#x27;t mind the more flippant writing style anyway ;) I liked your writing and it reminded me of the phoenix project, not in writing but in content. I&#x27;ll be sure to check out your more boring stuff! reply gniv 2 hours agorootparentprevThere are four instances of the f-word and a few religious references, including in the title. reply fallingknife 5 hours agoparentprevThis is why it&#x27;s a major red flag when your org starts doing things \"because big company X does it.\" And they never stop to think whether they do it because it works or that it&#x27;s a failure and they are getting away with it because they are big. reply nologic01 1 hour agoprevLarge corporate conglomerates are essentially how power is shared and delegated in any modern oligarchic society with large economic footprint. Details around public sector role vs market structure and function vary, but overall its the same story: A bunch of ruthless actors, with various degrees of starting point privilege, climb the greasy poles, typically in colluding cohorts of &#x27;old boy networks&#x27;. Revolving doors between private and public roles are the norm.In this organizational design producing anything of value is a secondary concern and incidental to the job description. Control and maintenance of power structure is the prime objective. Large firms are lawyer and lobbyist undertakings with a tiny production engine attached.Rather gloomy but not really new.There is nevertheless something very intriguing about the tech industry. It may be at the forefront of disrupting this rather wasteful house of political cards.This very discussion on HN is point in case. Go and check Linkedin to see what corporate vacuity typically sound like :-)The success of the open source movement with its incredible efficiency and leverage is another interesting hint that something interesting is brewing.Why would tech be any different? Well its not \"tech\", its information tech. And power structures require and are shaped by the control of information. So for as long as tech is not completely locked down the next phase of human political-economic organization is in-principle up for grabs. reply iandanforth 3 hours agoprevSo you know the latency numbers that every programmer should know? (I hope you do: https:&#x2F;&#x2F;colin-scott.github.io&#x2F;personal_website&#x2F;research&#x2F;inte...)Is there an equivalent for software org spend? Obviously it couldn&#x27;t be as principled as the above but if you look at engineering at StackOverflow and their compute &#x2F; requests ratio it&#x27;s orders of magnitude better than companies I&#x27;ve worked at. I just want numbers in spend on compute and headcount related to operational requirements.Has someone compiled a set of simple heuristics that says \"If you are serving thousands of requests per hour to hundreds of enterprise clients your AWS bills shouldn&#x27;t be more than thousands per month?\" Something which can be used to say very clearly \"we are incompetent\" to upper management? reply benjaminwootton 6 hours agoprevThe cost saving comes from the fact that Snowflake virtual warehouses by default time out after 10 minutes and this can be lowered, realistically to 60 seconds.They must have been using very overprovisioned servers to run up $1 million per year in Snowflake spend for occasional 10 minute bursts of activity prior to the change.I think this points more to poor and ungoverned use of Snowflake and Cloud than it does organisational dysfunction. reply pjc50 5 hours agoparent> I think this points more to poor and ungoverned use of Snowflake and Cloud than it does organisational dysfunction.Those are the same thing.(one of the massive, massive advantages and disadvantages of cloud in general is that it circumvents \"purchasing\" departments. One the one hand: you don&#x27;t have to spend $10,000 of time trying to buy $1000 of computer. On the other: you can waste millions on the cloud and maybe nobody will even notice.) reply arethuza 3 hours agorootparentIt can also circumvent in-house infrastructure teams - who I used to find were a far bigger challenge than purchasing. I used to work somewhere where the main mission of the infrastructure team seemed to be to prevent anyone actually running anything on all of the lovely hardware they managed - which reached peak madness when I was quoted £75,000 for hosting a single static HTML page for internal only access. reply hodgesrm 2 hours agoparentprev> I think this points more to poor and ungoverned use of Snowflake and Cloud than it does organisational dysfunction.This is a \"blame the user\" argument that I hear a lot. It&#x27;s true that in many or most cases users being super attentive can mitigate cost issues. But it&#x27;s also true that this turns out to be very difficult in practice for a variety of reasons like scattered responsibility, complexity of cloud costs, and vendor cost models that encourage spending.For my own money this problem looks like a business opportunity for vendors that offer customers ways to avoid it. The high margin era of cloud services with 10x markup on compute (e.g., Snowflake) won&#x27;t last forever. reply dustingetz 4 hours agoparentprevnumber is also reported out of context and not as a % - i detect moral hazard by author here reply kubanczyk 6 hours agoprevA better analysis: https:&#x2F;&#x2F;thezvi.substack.com&#x2F;p&#x2F;what-is-life-in-an-immoral-maz... reply brazzy 2 hours agoparentReads more like fictional worldbuilding than an analysis. reply layer8 3 hours agoprev> The places doing things right tend to be characterized by being small, not being obsessed with growth, and having calm, compassionate founders who still keep a hand on the wheel.This right here. Go look for those places. reply johhns4 2 hours agoparentI don&#x27;t know. Just because a company doesn&#x27;t move fast doesn&#x27;t mean that they are a good company to work for. Calm and compassionate can just mean out of touch and dispassionate in investing in the future. Having energy and passion to move forward as well as the ability to place your bets somewhere is important too. When nothing ever happens because everything is too much of a risk, work can get a bit tedious. But I suppose in todays climate people will look towards these companies as the holy grail just to get some stability. reply layer8 2 hours agorootparentYou’re manufacturing a false dichotomy here. There’s no contradiction between founders being compassionate and calm (in the sense of level-headed) and also being passionate and innovative. In those small companies where I worked, the work was anything but tedious, and there was no lack of risk. But exponential growth wasn’t the goal, making good products in a sustainable fashion was the goal. reply johhns4 29 minutes agorootparentI will back up here a bit as my first claim came off as a bit confrontational. However, I find it a bit unrealistic to expect an environment where you have founders that are very compassionate and calm. The very nature of building a business is a maddening task. Which is something we seem to forget.Most level-headed people would never do it. The very idea of starting something that has a very minimal chance of success isn’t rational. Therefore I do find the traits you describe at somewhat of a contradiction.Many of the most known innovators and leaders are often described as intense, driven, and even obsessive. Their willingness to defy convention, take significant risks and challenge the status-quo can be seen as crazy.I suppose I’ve seen the other side of this coin, in small companies where everything is ”too much of a risk” if it cannot generate a good cash flow within a few months. This is a very level-headed approach. I’ve also seen them miss some great opportunities because of it. Nevertheless, they are still operating and probably will be for a long time. However, I&#x27;m uncertain that they have enough energy and will power to \"change\" the world.Now, I&#x27;m not saying that a small company with calm level-headed leaders are a bad thing. But I don’t believe that there aren’t trade-offs. Both have their pros and cons. reply l0b0 7 hours agoprevHow do big companies stay alive for so long? I guess it&#x27;s still possible to coast on a single success for so long that the company has time to completely rot from the inside before any of it reaches their customers. Or maybe the early money gets invested in a bajillion projects, on the very slim chance that the company isn&#x27;t a one-trick pony. reply TulliusCicero 6 hours agoparentBecause they&#x27;re not actually much more dysfunctional than smaller companies, you just hear more stories because they&#x27;re bigger. Bigger means more employees for things to go wrong around, bigger means that people are more likely to be interested in hearing stories and thus other people are more likely to tell, remember, and repeat said stories.A story about some idiot doing an idiotic thing at Google is vastly more likely to be passed around forever than a story at a random mom and pop company*. People love hearing about morons at big tech giants, and the storytellers oblige.That, plus sufficient economies of scale or complementary tech products.* unless that story is REALLY incredible, like that guy who went to an interview and accidentally killed the CEO&#x27;s dog reply habitue 6 hours agorootparentThe bigness itself causes dysfunction, apart from just having more employees and more chances to have a disaster. It&#x27;s the whole Dunbar&#x27;s number thing, we really haven&#x27;t figured out a great way to work effectively in huge groups yet.But... some things can only be done with huge groups, so even working ineffectively can be worth it. And in a competitive setting, your competition also has these problems, so you can win in the market despite them. reply blablabla123 6 hours agorootparentThe problem with tiny startups is often that people are really inexperienced with people problems. Large corps somewhat fix that by having HR departments and all. But ultimately I&#x27;m starting to think today&#x27;s business often relies on some sort of hype train. reply WJW 5 hours agorootparentThere are plenty of businesses that don&#x27;t rely on hype, you just won&#x27;t find them on HN. The average supermarket chain, steel mill or insurance company just produce valuable goods or services that people and&#x2F;or businesses want to buy, and they can be stable businesses for decades or even centuries. Hacker news is a forum hosted by a VC that predominantly invests in software startups however, and so you won&#x27;t find a lot of stories here about companies that don&#x27;t fit that mold. reply fallingknife 5 hours agorootparentprevI tend to think of HR departments as a people problem, not the solution to one. reply P_I_Staker 3 hours agorootparentprevSeems to attract broken people searching for greatness. reply kypro 5 hours agorootparentprevIn my experience bigger companies are more dysfunctional, but they appear less so the higher up in the company you are.When you&#x27;re just some low-level worker for a mega corp high-level decisions tend to get passed down with little to no context through several layers of management half of whom are disconnected from the issues you face on the ground, and the other half are disconnected from the decision making at the top.This does cause some dysfunction, but I agree with you that it&#x27;s not often not as bad as it seems when you have context of the why decisions are being made.Not all companies do such a bad job at communication either and flatter organisation structures can help empower the people on the ground to make decisions which might otherwise need the approval of several layers of management. But still, in a large company there&#x27;s inevitably always going to be some disconnect which will cause some level of dysfunction that you wouldn&#x27;t get in a small company. reply ludicity 5 hours agoparentprevAuthor here. My organization continues to exist in its current massive form due to regulatory capture - I can&#x27;t provide details and remain anonymous, unfortunately. We would probably survive at 1&#x2F;10th the size or something akin to that without that protection, and we would be considerably more efficient.EDIT: Oh, and the part that earns money through regulatory capture earns so much money that we can have all these departments doing nothing in the meantime. We might do something one day with amazing leadership, but the incentives and odds are stacked against us. reply ian0 6 hours agoparentprevAt its core a company is a machine that makes money.Once the machine is up and running, you just have to avoid not breaking it. An org at this stage can be completely dysfunctional as long as the machine keeps running. Also figuring out the \"wins\" while scaling are much more obvious than while trying to start. reply freefaler 6 hours agorootparentThat&#x27;s true if the environment where the machine work doesn&#x27;t change. However with business environment changing the machine need to change as well.Big corporations have \"moats\" (as per Buffet&#x27;s definition) and a big bank vendor locked into your solution will drag a badly working machine for years. reply lmm 6 hours agoparentprevSometimes being big is a structural advantage. Also there&#x27;s a variant of the Peter Principle at work: any effective company grows until it is ineffective, therefore productive work is done only by companies that haven&#x27;t finished growing yet. reply swiftcoder 5 hours agoparentprevBig companies tend to have a handful of divisions that generate almost all of the revenue, and then everyone else is a cost centre. As long as the revenue generators outweigh the cost centres, no one really cares broadly about efficiency.For Facebook the revenue generator is Ads. For Amazon it was initially physical shipping, and later cloud hosting. Outside of those divisions you could burn billions on long shot projects that went nowhere, and nobody really cared... reply _tk_ 6 hours agoparentprevA lot of big companies don’t. Additionally, a single success often implies multiple times smaller successes that are just not visible outside a corporation. reply throwaway5959 7 hours agoparentprevRegulatory capture. reply gruez 6 hours agorootparentWhat sort of regulations are preventing a google competitor from starting up? \"GDPR&#x2F;CCPA\" isn&#x27;t very convincing because it was only a recent thing, but google has been around for decades. reply throwaway5959 6 hours agorootparentRegulatory capture covers more than just regulations. It also covers the lack of regulation; including anti-trust.Do you want to do a search or mobile OS startup with Google’s market position? Do you think they’ll release a YouTube or Google Maps application for your phone OS? reply pjc50 5 hours agorootparentI think that&#x27;s stretching the definition of \"regulatory capture\" beyond useful meaning. Just say \"monopoly\" or the softer \"market power\". reply imhoguy 5 hours agorootparentprev- Patents, grow a bit more and the sharks will come.- Unfair taxation advantages, and fines are laughable. reply yesbut 6 hours agorootparentprevand Zombie Companieshttps:&#x2F;&#x2F;www.cnbc.com&#x2F;2023&#x2F;10&#x2F;31&#x2F;zombie-firm-bankruptcies-ami... reply nullc 6 hours agoparentprevThere are many companies that are so wealthy that they could just stop all revenue completely and coast no for decades while management continues to skim out their fat paychecks. Some theorize that this has already occurred.Besides, -- if you think how some companies work is fugly, go take a look at biology or politics. Companies are evolved systems. Once they&#x27;re old enough they&#x27;re almost always messy even when they aren&#x27;t especially dysfunctional.The human body is full of almost vestigial parts and dead end metabolic pathways... huge chunks of our DNA are just self replicating repeating sequences.In reality the cruft in companies is often not even non-functional, but sometimes it serves some more complex purpose. Lots of large companies, for example, have some useless figurehead security position that exists for the actual purpose of having someone to fire when there the inevitable serious security issue occurs, without putting anyone actually productive at risk.Companies are built out of and owned by people. Like anything else they have to respect the the limitations of the building material and the needs of their owners. The resulting requirements are no less real even though they might not exist in a world populated by homoeconomicus instead of man kind. If man kind wants a blood sacrifice for security incidents then it&#x27;s reasonable and good for a company to have one. reply ludicity 5 hours agorootparentThis is an incredible comment. The part that drives people to absolute frustration is that you might be in some weird vestigial organ, either with no purpose or with a purpose not at all aligned with what the organization is saying, and then waste years trying to \"fix it\". It&#x27;s a bursting appendix, don&#x27;t worry about it - or well, maybe this is a bit stretched now, remove it. reply lesuorac 2 hours agorootparentYou might enjoy reading the external version [1] of View from Above [2] on apenwarr&#x27;s blog. The internal version is much better if you can get a copy of that as it goes into his actual experience with trying to improve Google.Although IIUC you both read High Output Management so it might just be nice to know that even within fang people think things are wrong.[1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34385570 [2]: https:&#x2F;&#x2F;apenwarr.ca&#x2F;log&#x2F;20190926 reply willismichael 2 hours agorootparentprevWell, if you find yourself as an individual contributor in some weird vestigial organ, I feel like you have a few choices: * Stay put to collect the money, with the morale cost of feeling like you don&#x27;t have a purpose and the risk of getting axed if&#x2F;when the bursting appendix gets removed * Proactively seek a lateral transfer to a position doing something more meaningful * Get out. Find a different employer.The latter two are likely better, but have their own risks. reply RandomLensman 6 hours agorootparentprevFor investors winding down and returning money fast might be preferable to a company without profits. reply nullc 6 hours agorootparentSure, and for a period corporate raiders took advantage of companies like that-- but standard defenses against raiding have become well known and widely deployed. Like life learning how to make cellulose suddenly the landscapes were littered with the husks of things that nothing knew how to digest.But the value to society at large isn&#x27;t just a profit (much less an ever growing profit). It&#x27;s good that we have businesses which simply satisfy the involved parties (their customers, their employees, and their owners)-- even if they don&#x27;t perform well on any external metric of efficiency. reply RandomLensman 6 hours agorootparentInvestors certainly look at winddown scenarios for companies not performing. Sometimes broader considerations win out, sometimes a change in management is all that is needed, sometimes more aggressive things happen. reply fallingknife 5 hours agorootparentprevHow is there value to society in zombie corps that no longer make a profit? reply pjc50 5 hours agorootparentThe employees are still getting paid! Quite often the product is genuinely useful. It may be a beloved brand. Companies don&#x27;t vanish the microsecond they cease to be profitable and nor should they. It&#x27;s only when they run out of cash.I don&#x27;t think it&#x27;s anyone&#x27;s job to be \"euthanizing\" low-profit businesses that might recover if there is a turn in the economy. The \"zombie\" concept is economically illiterate. Occasionally you will get a private equity firm doing this and the result is widely unpopular (Toys R Us, Maplin, etc) reply rightbyte 3 hours agorootparentprevThe employees and customers are surely a part of society.More offent than not, not making enough profit is overreaching the profit goals to justify unfair stock prices. And the executives and board make bad gambles since they lose the owners money if they lose and win the owners money of they win. reply waveBidder 6 hours agorootparentprevWish I could double upvote this over all the political commentary. reply csomar 6 hours agoparentprevOne overlooked reason is the government intervening to save these companies. Either by bailout, lowering rate, special loans, etc… This prevents these companies from going into bankruptcy and restructuring and keeps the status quo as is.It’s kind of a disguised communism and the longer the government keeps proping the economy (and making it difficult to start new companies), the worse this will get. reply pjc50 5 hours agorootparent> is the government intervening to save these companiesName some.Many very dysfunctional companies are also very profitable and have no need of outside bailouts. How long has IBM been at it? reply Dracophoenix 3 hours agorootparentGeneral Electric. reply ace32229 5 hours agorootparentprevCorporate socialism it&#x27;s often called. reply nuc1e0n 5 hours agoprevYou need to view matters from the perspective the parasites do to understand the situation. Inefficiencies and waste are good for them because the wasted money is funneled into their own pockets. Controlling large budgets and teams gives them a sense of greater power.But the fact is, they don&#x27;t need to horde all this. With a laptop anyone can achieve anything they need with the touch of a button. Minimalism is just more effective in the long run.They need to realise, the things you &#x27;own&#x27;, own you.It&#x27;s especially important to be efficient when you&#x27;re acting as a custodian for other people&#x27;s money and wellbeing. reply ZeroGravitas 6 hours agoprevSo, serious question: how do you maintain your health and sanity when you find yourself in such a situation?If the main reason to stay is a steady paycheck then you&#x27;re only doing harm to yourself by being aware of and caring about the bigger picture. reply probably_wrong 5 hours agoparentAssuming you can&#x27;t leave the place (no other prospects around, family to feed, etc) you simply check out mentally. You do an okay job (no point in overachieving), stop being personally invested in the success of projects, roll your eyes a lot, and find meaning somewhere other than work. And if things get too overwhelming you can always vent to your co-workers who are also stuck in your same situation. reply ludicity 5 hours agoparentprevDon&#x27;t stress too much about improving things there, spend time with the colleagues you like, and make incremental (and sometimes major) changes to your life, I think. Not super insightful, but you&#x27;ll note it&#x27;s a good idea in every domain of life. reply fnimick 5 hours agoparentprevThat&#x27;s exactly how you do it. Don&#x27;t care about things the company doesn&#x27;t measure and reward. reply dbrueck 3 hours agoparentprevBeing aware of and adjusting your sphere of concern vs sphere of influence (see e.g. Covey & 7 Habits) can help you survive in a way that at least feels more ethical than, say, quiet quitting.Ultimately though I got fed up and stopped working for large organizations. Small companies have their own problems, but they tend to be less maddening to me personally, so I&#x27;m happier overall. YMMV! reply EVa5I7bHFq9mnYK 1 hour agoprevYou might find pure $1M saving opportunities. But quite often the saviour of $1m is not aware that this can cause a $10m loss somewhere else, for example, a legal liability. Or maybe in order to find one $1m saving opportunity, established processes should be disrupted at a cost of $10m. reply Spiwux 2 hours agoprevSometimes I have this urge to try getting into a manager role. I really want to see and experience for myself if most managers I work with are just bad at their job, or if being a \"good\" manager is simply impossible and you&#x27;re doomed to fail regardless of skill. reply mikewarot 3 hours agoprevI know the answer.... Free Money[1], when the Fed lowered the prime interest rate to zero, the free money distorted the market and allowed all this insanity to happen.Now that the free money is drying up, all this shit has to evaporate. Just like the great simplification[2] that has to take place on the downside of the great carbon pulse that&#x27;s feeding civilization right now.What a depressing thought in the short&#x2F;medium term, in the long run, it&#x27;ll be good for Humanity, my grandkids, should they every be born[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Zero_interest-rate_policy[2] https:&#x2F;&#x2F;www.thegreatsimplification.com&#x2F;about reply lootsauce 3 hours agoprevYou think the waste is high in tech saving a few mill here and there with db settings an ec2 optimizations? Imagine all the low sophistication marketing managers and CDOs, CMOS literally with 10 to 100+ million budgets much of which is completely wasted. Ten years in this space I have 2nd hand knowledge of specific cases that make your face melt. reply Roark66 5 hours agoprevI&#x27;ve mixed feelings after reading this. On one hand I&#x27;ve had the \"opportunity\" to briefly work for some dysfunctional companies on short term projects and I know exactly what the author is talking about. But after over 2 decades in this line of work I disagree that this is the majority of Fortune 300~500.Every huge company I worked for had some level of apparent dysfunction that later, once I got to know the history why they did it this way turned out to be the best of the worst options available.At the same time I had people tell me, \"of what a horrible mess and a dumpster fire of crap, are we allowed to throw it all out and do it properly? \" when showing them around corporate systems and codebases. Then after eventually we obtain permission to \"throw out and do it properly\" for some small part of the system it is discovered that \"no, the people that did it before us were not idiots, we were just not aware of certain constraints that forced their choices and now are forcing ours\". You would have to replace everything... Which never was and never will be possible in a large company that has the same system and apps working since they started developing it on punch cards in 1960s... reply ludicity 5 hours agoparentWell, there&#x27;s levels to it, right? I got an invite for a senior role at a company that some people here would recognize, and they had problems that sucked but were reasonable. Most of the problems I see don&#x27;t really have a good reason, and I think people&#x27;s experience is heavily influenced by career path-dependence.I started at a trash place that didn&#x27;t even use version control, so the pathway of jobs through my contacts has been a very slow road to improvement. Similarly, people that start at better places just tend to stay at better places.Or as a much more experienced friend said to me: \"All places are dysfunctional, but the difference between the best and worst I&#x27;ve worked at is indescribable.\" reply api 3 hours agoprevThree words: zero interest rates.Since around 2008-2009, our customers have not been customers. Our customers have been investors. Money has been so cheap that the primary goal of most organizations has been to court investment, not to actually create value. It was easier to raise money than to build product or sell anything.To do this the goal is to make the company look like a potential \"unicorn.\" That means burying whatever is wrong, over-hiring and over-engineering to make the company look serious and big, complexifying everything to give all those over-hired engineers something to do, and trying to gain as many users as possible as fast as possible even if it&#x27;s completely unsustainable.In that world efficiency literally does not matter. In fact, it can be a liability since it means you&#x27;re not spending investor cash fast enough and you don&#x27;t have enough complexity to make your over-hired engineering teams feel like they are being productive. If you&#x27;re not spending that cash you don&#x27;t need to raise more. It&#x27;s the startup fund raising version of the well known \"you have to spend your entire budget by the end of the fiscal year or you will get less next year.\" reply gumballindie 6 hours agoprev> What The Goddamn Hell Is Going On In The Tech Industry?Management and agile happened. Instead of engineering, people chase tickets to achieve mediocre goals set by clueless non technical people. They thought something as creative as software development can easily be converted into assembly line manufacturing. Well, these are the results. reply WJW 5 hours agoparentCompanies being inefficient has been around for WAY longer than agile and&#x2F;or modern management practices. Franz Kafka wrote his novels in the 1910s, after all. In software specifically, Fred Brooks already wrote about the problems with organizing groups of people in the 1970s. reply ludicity 5 hours agoparentprevI was actually writing something on this, so I&#x27;m super interested that you brought this up. I have some strong theories, but I must admit I don&#x27;t have the work experience to be that confident in them. reply borg16 3 hours agorootparent> I have some strong theories, but I must admit I don&#x27;t have the work experience to be that confident in them.This has not stopped you from posting the dozen or so blog posts you have already written so far. Go ahead and post what you are thinking. Do not let lack of experience stop you :) reply randomdata 1 hour agorootparentTo be fair, if he had the experience to know for sure, there would be no motivation to write about it anymore. People only talk about what they are unsure of. reply gumballindie 5 hours agorootparentprevPretty much all companies i’ve been with an did “agile” ended up debating agile more than doing it. The outcome expected by managers was unequivocally to be able to allocate work and measure output similar to factories. Obviously it has always been a struggle to add anything of technical importance because there was no user story for it (in their limited thinking everything needs to benefit users directly, clearing tech debt is only a nice to have). As systems degrade over time they’d hire more people to maintain or increase velocity (factory output basically). Goes without saying that that doesnt work and you end up with the horror stories described here.Agile engineering practices on the other hand are beneficial. But those arent really invented by agile. All existed well before agile.Also every single large corporation i served suffered from endless meetings. It was almost always managers demanding such meetings. Somehow their belief is that engineers shouldnt spend time thinking about a problem - they should instead discuss it right away. A dubious mindset and telling of how said managers have no clue how thinking is to be made generally speaking. There needs to be communication between team members, but a good technical person is one that understands that and does it when needed. However since management and a factory mindset leads to hiring assembly line workers that lack communication skills that can sometimes be an issue - then the vicious cycle dictates that there need to be more meetings to cover communication gaps made by managers that hired assembly line workers that dont communicate well with peers, and so on.Companies run by founders usually fare better because founders are either technical, domain experts and or care about inefficiencies - thus they rarely hire non technical managers.Such companies often get acquired by larger companies that then turn them into factories and so the cycle begins. They still generate revenue and profits because generating profits doesnt always require a stellar product or sometimes they abuse their dominant position (google’s regressing, amazon’s a swamp of counterfeits, and both still make money).After a long time in tech i’ve reached the conclusion that tech has been turned into factory work (including threats of automation replacing “workers”). Growth will indeed come from ai companies because … such companies are not yet managed and factorised to death (still run by tech founders, and so on). Thats why google’s struggling to get ai working while openai is smashing it. But those too will become bastardised. reply dalbasal 4 hours agoprevSoftware is too valuable, too high potential. It&#x27;s production methods too creative, too subjective, and insufficiently legible.So... We can&#x27;t afford not to do it. Sometimes we can&#x27;t do it, and we can&#x27;t afford not to just pretend we&#x27;re doing it.Do we really need to quantify the number of firms who&#x27;s main declared priorities involve producing technology (eg \"AI\") that they have no idea how to make and no chance producing? I mean those who communicate this clearly to the board, the employees and such. Many&#x2F;most aren&#x27;t even tech companies. Their little teams that coordinate salesforce integration & automate google sheets are tasked with tasks somewhere between \"winning ycombinator\" and developing AGI in 5 months.The reason might be a penchant for \"growth stories.\" It might be something else, but we know it is. Maybe someone said \"why aren&#x27;t we just using AI to cut our CS costs in half?\" Maybe no one had a convincing retort.\"I am near absolutely convinced that the vast majority of our species&#x27; ability to produce things of value for the human race is just utterly squandered at large companies.\"So... I studied economics circa 2004. A conservative school, during the peak of certainty in particular economic ideas. A very rational view of microeconomics... firms, prices, etc.Anything outside that paradigm was weird \"alternative theory\" and we learned the famous polemics to address the obvious rhetorical questions.I&#x27;ve gone back to most of those polemics over the years. I think they have some answers for us... Especially thought from the 1920sAnyway... I no longer think the model predicting that our species (or industry&#x2F;company&#x2F;etc) ability to produce things should be a limiting factor is totally wrong.Sometimes our actual ability is the limiting factor. Those problems get solved though. The rest of the time, other factors are limiting us and utilizing our productive potential is irrelevant.Eg smartphones. They were a hit. In about a decade they went from yuppie toy to prevalence among subsistence farmers. They got good, and cheap, fast. That&#x27;s technology being efficient.Once everyone has a decent smartphone, that market has peaked. The \"classical model\" predicts that prices should now freefall. The market can&#x27;t get bigger, but that shouldn&#x27;t make price performance halt. Prices should take over as the driver of price performance now.^FYI The classical model&#x27;s definition of \"technology\" is pretty much \"price performance\" and it is treated as a black box.Irl, hat&#x27;s not how this works. A commodity business model is not the next step. There&#x27;s no incentive to go this route at all.The model T had a similar life journey. Rapidly reducing prices until market peak, then a different business model... one that wasn&#x27;t really about efficiency anymore. Henry Ford hated it, but he did succumb eventually.That means we are no longer pursuing efficiency. Wasting productive potential is default, when in this mode.At least from the perspective of the individual firm... Efficiency is only the paradigm sometimes... Times when supply (the companies&#x27; output) is factor limiting profit, share price, reward...The rest of the time, it&#x27;s demand.Take retail banking. I am sure, if the population of earth was growing 20% YoY... retail banking would keep pace. Accounts & credit cards for everyone would be no issue.They wouldn&#x27;t need to scale their workforce by 20% pa. Banks&#x2F;banking would get more efficient instead... especially if competition is weak.That doesn&#x27;t mean that in a \"normal\" state, where banks have limited growth potential... Those efficiency gains are not going to happen. It doesn&#x27;t matter what technology exists. Retail banks are not going to slowly shrink, as efficiency gains",
    "originSummary": [
      "The author expresses concerns over wasted technical productivity in large tech companies, referencing reports of inefficiencies and management ignoring issues at FAANG and other reputable firms.",
      "The narrator identifies three categories of readers: those resistant to change, those enduring challenging conditions, and those in denial about existing problems.",
      "He proposes creating a support group and is currently working on a guide to assist employees who wish to exit unproductive work environments."
    ],
    "commentSummary": [
      "The author criticizes the tech industry's hiring practices, which often reward those who can navigate outdated systems and unethical individuals, highlighting a significant deficiency in focus on crucial soft skills alongside tech competences.",
      "The article emphasizes the tech industry's urgent need for better management, discussing struggles in finding skilled and ethical leaders, and suggesting shared managerial roles over the traditional \"one manager for all\" approach.",
      "It was also discussed how the tech industry responds to economic crises, the changing ways companies generate revenue, and the impact of compensating tech workers on the economy."
    ],
    "points": 218,
    "commentCount": 190,
    "retryCount": 0,
    "time": 1698824407
  },
  {
    "id": 38086894,
    "title": "Reverse-engineering Ethernet backoff on the Intel 82586 network chip's die",
    "originLink": "http://www.righto.com/2023/10/reverse-engineering-ethernet-backoff-on.html",
    "originBody": "Ken Shirriff's blog Computer history, restoring vintage computers, IC reverse engineering, and whatever Reverse-engineering Ethernet backoff on the Intel 82586 network chip's die Introduced in 1973, Ethernet is the predominant way of wiring computers together. Chips were soon introduced to handle the low-level aspects of Ethernet: converting data packets into bits, implementing checksums, and handling network collisions. In 1982, Intel announced the i82586 Ethernet LAN coprocessor chip, which went much further by offloading most of the data movement from the main processor to an on-chip coprocessor. Modern Ethernet networks handle a gigabit of data per second or more, but at the time, the Intel chip's support for 10 Mb/s Ethernet put it on the cutting edge. (Ethernet was surprisingly expensive, about $2000 at the time, but expected to drop under $1000 with the Intel chip.) In this blog post, I focus on a specific part of the coprocessor chip: how it handles network collisions and implements exponential backoff. The die photo below shows the i82586 chip. This photo shows the metal layer on top of the chip, which hides the underlying polysilicon wiring and silicon transistors. Around the edge of the chip, square bond pads provide the link to the chip's 48 external pins. I have labeled the function blocks based on my reverse engineering and published descriptions. The left side of the chip is called the \"receive unit\" and handles the low-level networking, with circuitry for the network transmitter and receiver. The left side also contains low-level control and status registers. The right side is called the \"command unit\" and interfaces to memory and the main processor. The right side contains a simple processor controlled by a microinstruction ROM.1 Data is transmitted between the two halves of the chip by 16-byte FIFOs (first in, first out queues). The die of the Intel 82586 with the main functional blocks labeled. Click this image (or any other) for a larger version. The 82586 chip is more complex than the typical Ethernet chip at the time. It was designed to improve system performance by moving most of the Ethernet processing from the main processor to the coprocessor, allowing the main processor and the coprocessor to operate in parallel. The coprocessor provides four DMA channels to move data between memory and the network without the main processor's involvement. The main processor and the coprocessor communicate through complex data structures2 in shared memory: the main processor puts control blocks in memory to tell the I/O coprocessor what to do, specifying the locations of transmit and receive buffers in memory. In response, the I/O coprocessor puts status blocks in memory. The processor onboard the 82586 chip allows the chip to handle these complex data structures in software. Meanwhile, the transmission/receive circuitry on the left side of the chip uses dedicated circuitry to handle the low-level, high-speed aspects of Ethernet. Ethernet and collisions A key problem with a shared network is how to prevent multiple computers from trying to send data on the network at the same time. Instead of a centralized control mechanism, Ethernet allows computers to transmit whenever they want.3 If two computers transmit at the same time, the \"collision\" is detected and the computers try again, hoping to avoid a collision the next time. Although this may sound inefficient, it turns out to work out remarkably well.4 To avoid a second collision, each computer waits a random amount of time before retransmitting the packet. If a collision happens again (which is likely on a busy network), an exponential backoff algorithm is used, with each computer waiting longer and longer after each collision. This automatically balances the retransmission delay to minimize collisions and maximize throughput. I traced out a bunch of circuitry to determine how the exponential backoff logic is implemented. To summarize, exponential backoff is implemented with a 10-bit counter to provide a pseudorandom number, a 10-bit mask register to get an exponentially sized delay, and a delay counter to count down the delay. I'll discuss how these are implemented, starting with the 10-bit counter. The 10-bit counter A 10-bit counter may seem trivial, but it still takes up a substantial area of the chip. The straightforward way of implementing a counter is to hook up 10 latches as a \"ripple counter\". The counter is controlled by a clock signal that indicates that the counter should increment. The clock toggles the lowest bit of the counter. If this bit flips from 1 to 0, the next higher bit is toggled. The process is repeated from bit to bit, toggling a bit if there is a carry. The problem with this approach is that the carry \"ripples\" through the counter. Each bit is delayed by the lower bit, so the bits don't all flip at the same time. This limits the speed of the counter as the top bit isn't settled until the carry has propagated through the nine lower bits. The counter in the chip uses a different approach with additional circuitry to improve performance. Each bit has logic to check if all the lower bits are ones. If so, the clock signal toggles the bit. All the bits toggle at the same time, rapidly incrementing the counter in response to the clock signals. The drawback of this approach is that it requires much more logic. The diagram below shows how the carry logic is implemented. The circuitry is optimized to balance speed and complexity. In particular, bits are examined in groups of three, allowing some of the logic to be shared across multiple bits. For instance, instead of using a 9-input gate to examine the nine lower bits, separate gates test bits 0-2 and 3-5. The circuitry to generate the toggle signals for each bit of the counter. The implementation of the latches is also interesting. Each latch is implemented with dynamic logic, using the circuit's capacitance to store each bit. The input is connected to the output with two inverters. When the clock is high, the transistor turns on, connecting the inverters in a loop that holds the value. When the clock is low, the transistor turns off. However, the 0 or 1 value will still remain on the input to the first inverter, held by the charge on the transistor's gate. At this time, an input can be fed into the latch, overriding the old value. The basic dynamic latch circuit. The latch has some additional circuitry to make it useful. To toggle the latch, the output is inverted before feeding it back to the input. The toggle control signal selects the inverted output through another pass transistor. The toggle signal is only activated when the clock is low, ensuring that the circuit doesn't repeatedly toggle, oscillating out of control. One bit of the counter. The image below shows how the counter circuit is implemented on the die. I have removed the metal layer to show the underlying transistors; the circles are contacts where the metal was connected to the underlying silicon. The pinkish regions are doped silicon. The pink-gray lines are polysilicon wiring. When polysilicon crosses doped silicon, it creates a transistor. The blue color swirls are not significant; they are bits of oxide remaining on the die. The counter circuitry on the die. The 10-bit mask register The mask register has a particular number of low bits set, providing a mask of length 0 to 10. For instance, with 4 bits set, the mask register is 0000001111. The mask register can be updated in two ways. First, it can be set to length 1-8 with a three-bit length input.5 Second, the mask can be lengthened by one bit, for example going from 0000001111 to 0000011111 (length 4 to 5). The mask register is implemented with dynamic latches similar to the counter, but the inputs to the latches are different. To load the mask to a particular length, each bit has logic to determine if the bit should be set based on the three-bit input. For example, bit 3 is cleared if the specified length is 0 to 3, and set otherwise. The lengthening feature is implemented by shifting the mask value to the left by one bit and inserting a 1 into the lowest bit. The schematic below shows one bit of the mask register. At the center is a two-inverter latch as seen before. When the clock is high, it holds its value. When the clock is low, the latch can be loaded with a new value. The \"shift\" line causes the bit from the previous stage to be shifted in. The \"load\" line loads the mask bit generated from the input length. The \"reset\" line clears the mask. At the right is the NAND gate that applies the mask to the count and inverts the result. As will be seen below, these NAND gates are unusually large. One stage of the mask register. The logic to set a mask bit based on the length input is shown below.6 The three-bit \"sel\" input selects the mask length from 1 to 8 bits; note that the mask0 bit is always set while bits 8 and 9 are cleared.7 Each set of gates energizes the corresponding mask line for the appropriate inputs. The control logic to enable mask bits based on length. The diagram below shows the mask register on the die. I removed the metal layer to show the underlying silicon and polysilicon, so the transistors are visible. On the left are the NAND gates that combine each bit of the counter with the mask. Note that large snake-like transistors; these larger transistors provide enough current to drive the signal over the long bus to the delay counter register at the bottom of the chip. Bit 0 of the mask is always set, so it doesn't have a latch. Bits 8 and 9 of the mask are only set by shifting, not by selecting a mask length, so they don't have mask logic.8 The mask register on the die. The delay counter register To generate the pseudorandom exponential backoff, the counter register and the mask register are NANDed together. This generates a number of the desired binary length, which is stored in the delay counter. Note that the NAND operation inverts the result, making it negative. Thus, as the delay counter counts up, it counts toward zero, reaching zero after the desired number of clock ticks. The implementation of the delay counter is similar to the first counter, so I won't include a schematic. However, the delay counter is attached to the register bus, allowing its value to be read by the chip's CPU. Control lines allow the delay counter's value to pass onto the register bus. The diagram below shows the locations of the counter, mask, and delay register on the die. In this era, something as simple as a 10-bit register occupied a significant part of the die. Also note the distance between the counter and mask and the delay register at the bottom of the chip. The NAND gates for the counter and mask required large transistors to drive the signal across this large distance. The die, with counter, mask, and delay register. Conclusions The Intel Ethernet chip provides an interesting example of how a real-world circuit is implemented on a chip. Exponential backoff is a key part of the Ethernet standard. This chip implements backoff with a simple but optimized circuit.9 A high-resolution image of the die with the metal removed. (Click for a larger version.) Some of the oxide layer remains, causing colored regions due to thin-film interference. For more chip reverse engineering, follow me on Twitter @kenshirriff or RSS for updates. I'm also on Mastodon occasionally as @kenshirriff@oldbytes.space. Acknowledgments: Thanks to Robert Garner for providing the chip and questions. Notes and references I think the on-chip processor is a very simple processor that doesn't match other Intel architectures. It is described as executing microcode. I don't think this is microcode in the usual sense of machine instructions being broken down into microcode. Instead, I think the processor's instructions are primitive, single-clock instructions that are more like micro-instructions than machine instructions. ↩ The diagram below shows the data structures in shared memory for communication between the main processor and the coprocessor. The Command List specifies the commands that the coprocessor should perform. The Receive Frame area provides memory blocks for incoming network packets. A diagram of the 82586 shared memory structures, from the 82586 datasheet. I think Intel was inspired by mainframe-style I/O channels, which moved I/O processing to separate processors communicating through memory. Another sign of Intel's attempts to move mainframe technology to microprocessors was the ill-fated iAPX 432 processor, which Intel called a \"micro-mainframe.\" (I discuss the iAPX 432 as part of this blog post.) ↩ An alternative approach to networking is token-ring, where the computers in the network pass a token from machine to machine. Only the machine with the token can send a packet on the network, ensuring collision-free transmission. I looked inside an IBM token-ring chip in this post. ↩ Ethernet's technique is called CSMA/CD (Carrier Sense Multiple Access with Collision Detection). The idea of Carrier Sense is that the \"carrier\" signal on the network indicates that the network is in use. Each computer on the network listens for the lack of carrier before transmitting, which avoids most collisions. However, there is still a small chance of collision. (In particular, the speed of light means that there is a delay on a long network between when one computer starts transmitting and when a second computer can detect this transmission. Thus, both computers can think the network is free while the other computer is transmitting. This factor also imposes a maximum length on an Ethernet network segment: if the network is too long, a computer can finish transmitting a packet before the collision occurs, and it won't detect the collision.) Modern Ethernet has moved from the shared network to a star topology that avoids collisions. ↩ The length of the mask is one more than the three-bit length input. E.g. An input of 7 sets eight mask bits. ↩ The mask generation logic is a bit tricky to understand. You can try various bit combinations to see how it works. The logic is easier to understand if you apply De Morgan's law to change the NOR gates to AND gates, which also removes the negation on the inputs. ↩ The control line appears to enable or disable mask selection but its behavior is inexplicably negated on bit 1. ↩ The circuitry below the counter appears to be a state machine that is unrelated to the exponential backoff. From reverse engineering, my hypothesis is that the counter is reused by the state machine: it both generates pseudorandom numbers for exponential backoff and times events when a packet is being received. In particular, it has circuitry to detect when the counter reaches 9, 20, and 48, and takes actions at these values. The state itself is held in numerous latches. The new state is computed by a PLA (Programmable Logic Array) below and to the right of the counter along with numerous individual gates. ↩ One drawback of this exponential backoff circuit is that the pseudorandom numbers are completely synchronous. If two network nodes happen to be in the exact same counter state when they collide, they will go through the same exponential backoff delays, causing a collision every time. While this may seem unlikely, it apparently happened occasionally during use. The LANCE Ethernet chip from AMD used a different approach. Instead of running the pseudorandom counter from the highly accurate quartz clock signal, the counter used an on-chip ring oscillator that was deliberately designed to be inaccurate. This prevented two nodes from locking into inadvertent synchronization. ↩ Email This BlogThis! Share to Twitter Share to Facebook Share to Pinterest Labels: chips, intel, reverse-engineering 4 comments: Anonymous said... I wrote and maintained the Intel 82586 \"ie\" and AMD Lance 7990 \"le\" ethernet drivers at Sun Microsystems back in the day. Interesting semi-related story, Sun contracted NCR Fort Collins to reverse-engineer several vendor i/o chips including the AMD Lance to produce a pair of (bug-compatible) integrated ASICs. The project reduced costs and uncovered several interesting long lurking chip bugs. neal October 31, 2023 at 4:19 PM Anonymous said... Out of (morbid) curiosity, did you know anyone who worked on HME? I've hacked a bit on the Linux driver. The comments are littered with David Miller's frustrations with the hardware (as I can attest to). October 31, 2023 at 6:45 PM Ken Shirriff said... Neal, can you get in touch with me? I'd like to ask you some questions. My email is firstname.lastname@gmail.com October 31, 2023 at 7:32 PM Anonymous said... Hello, very nice article. how may transistor does this chip contain ? October 31, 2023 at 11:41 PM Post a Comment Older Post Home Get new posts by email: Subscribe About the site Contact info and site index Popular Posts Examining the silicon dies of the Intel 386 processor Reverse-engineering Ethernet backoff on the Intel 82586 network chip's die Reverse-engineering the mechanical Bendix Central Air Data Computer Apple iPhone charger teardown: quality in a tiny expensive package How flip-flops are implemented in the Intel 8086 processor A Multi-Protocol Infrared Remote Library for the Arduino A dozen USB chargers in the lab: Apple is very good, but not quite the best Teardown and exploration of Apple's Magsafe connector Search This Blog Labels 386 6502 8008 8085 8086 8087 aerospace alto analog Apollo apple arc arduino arm beaglebone bitcoin c# cadc calculator chips css datapoint dx7 electronics f# fpga fractals genome globus haskell html5 ibm ibm1401 ibm360 intel ipv6 ir java javascript math microcode oscilloscope photo power supply random reverse-engineering sheevaplug snark space spanish synth teardown theory unicode Z-80 Blog Archive ▼ 2023 (29) ▼ October (3) Reverse-engineering Ethernet backoff on the Intel ... Examining the silicon dies of the Intel 386 processor Reverse-engineering the mechanical Bendix Central ... ► September (1) ► August (2) ► July (3) ► May (1) ► April (2) ► March (4) ► February (5) ► January (8) ► 2022 (18) ► 2021 (26) ► 2020 (33) ► 2019 (18) ► 2018 (17) ► 2017 (21) ► 2016 (34) ► 2015 (12) ► 2014 (13) ► 2013 (24) ► 2012 (10) ► 2011 (11) ► 2010 (22) ► 2009 (22) ► 2008 (27)",
    "commentLink": "https://news.ycombinator.com/item?id=38086894",
    "commentBody": "Reverse-engineering Ethernet backoff on the Intel 82586 network chip&#x27;s dieHacker NewspastloginReverse-engineering Ethernet backoff on the Intel 82586 network chip&#x27;s die (righto.com) 187 points by zdw 23 hours ago| hidepastfavorite33 comments kens 23 hours agoAuthor here. This chip is pretty obscure, but I was looking at it for another project and figured I might as well write it up. Any questions? reply dekhn 22 hours agoparentMinor detail whilst I read through this (I&#x27;m on a quest to understand my childhood Apple IIe, and at just the level to start understanding ripple counters): I think it&#x27;s 10Mbit or 10Mb&#x2F;sec ethernet, not 10MB&#x2F;sec. reply kens 21 hours agorootparentThanks, I&#x27;ve fixed that. reply aftbit 22 hours agoparentprevI just wanted to say thank you for all of these write-ups, and for the restoration and reverse engineering work that you do for the retrocomputing community.Here&#x27;s a question: how has this implementation changed in modern nano-scale ethernet implementations? Modern ethernet cards are asked to do much more offloading and processing, potentially including application protocols like TLS and DMA not just from memory but directly from NVMe devices as well. Given that we can now spam out transistors by the billions, are things like 10-bit counters still implemented via clever dynamic logic in hardware, or is there a more brute-force approach in use today? reply kens 21 hours agorootparentI looked at the datasheet of a random modern Ethernet chip (ENC28J60) and it&#x27;s simpler than I expected, doing much less than the old Intel chip, although it includes the low level \"PHY\" circuitry, which was a separate Intel chip in the olden days. I expect that the newer chip has things like 10-bit counters, but they would be implemented with standard cell logic (i.e. computer-generated layout of gates) rather than the hand-optimized circuitry of the Intel chip.On the other hand, you can get a chip like the W5300 which includes the whole TCP&#x2F;IP stack along with ARP and ICMP, presumably running on an internal microcontroller.https:&#x2F;&#x2F;ww1.microchip.com&#x2F;downloads&#x2F;aemDocuments&#x2F;documents&#x2F;O...https:&#x2F;&#x2F;www.wiznet.io&#x2F;wp-content&#x2F;uploads&#x2F;wiznethome&#x2F;Chip&#x2F;W53... reply FastFT 19 hours agorootparentHigh end NICs like Mellanox ConnectX are probably more similar to the 82586 in terms of breadth of functionality. They have (R)DMA, hardware timestamping, encryption, etc. Although, I wouldn’t expect to see much hand crafted logic design outside of the very high speed signal paths like in the serdes. reply accrual 22 hours agoparentprevHi Ken, thanks for another excellent article! I just wanted to add that I recently bought an Intel EtherExpress 8&#x2F;16 for my 486 PC and it uses this chip. So although the chip may be obscure, it still finds its way into the hands of new users even today. :)The fact that I just got this card and had to search around the net for drivers and documentation, and now your die photos are available - I&#x27;m just amazed. What a cool chip and card. reply jecel 14 hours agoparentprev> The idea of Carrier Sense is that the \"carrier\" signal on the network indicates that the network is idle.Wouldn&#x27;t a carrier indicate that the network is busy? Actually, Ethernet is a baseband system and so doesn&#x27;t actually have a carrier, but for Alohanet you would only have the carrier when a transmitter was on even if it wasn&#x27;t actually sending 1s or 0s at that instant. reply tails4e 17 hours agoparentprevOne part I didn&#x27;t follow 2qs where then pseudorandom element is introduced. This seems like it can implement variable delays in powers of 2 based on the mask. reply kens 15 hours agorootparentThe first counter simply counts, so when you sample it you get a pseudorandom number. (Assuming the sampling time is random.) Then applying the mask gives you the power of 2 scaling. reply tails4e 6 hours agorootparentThanks, makes total sense. If the first counter is free running then it should look pretty random if sampled when there are collisions as those would be random themselves. Love how simple the solutions are when transistors were expensive. reply PaulHoule 23 hours agoparentprevThat&#x27;s nice simple logic that is laid out in a way that makes your reverse engineering straightforward. I really appreciate these articles because sometimes I build discrete logic circuits for fun so I see a lot of beauty in these things. reply kloch 19 hours agoprevI love Ken&#x27;s blog posts and this one is right up my alley.> introduced in 1973, Ethernet is the predominant way of wiring computers together.That sentence does not really convey how hard it was for Ethernet to win the network L1&#x2F;L2 protocol wars. It was fairly popular right from the start because it worked well enough (better than it should) and was very simple to understand, configure, and operate. It also kept evolving with new media.But there were other systems it had to compete with, in some use cases (ISP&#x27;s) well into the late 1990&#x27;s&#x2F;early 2000&#x27;s.Engineering workstations (Sun&#x2F;SGI&#x2F;IBM&#x2F;HP) were early adopters but often had to integrate with mainframe&#x2F;minicomputers running things like: - Token Ring: IBM was the 800lb gorilla at the time - FDDI: supported 100mbps over MMF! - DEC LATIn the PC sector - Novell&#x2F;IPX: was very popular in the 80&#x27;s and persisted well into the 1990&#x27;s. Most DOS games like Doom *only* supported Novell&#x2F;IPX - Macintosh: AppleTalk - There were many other proprietary PC&#x2F;DOS protocols but they were not memorableIn the ISP sector - Ethernet was very popular but consistently lagged in supporting the fastest link speeds that ISP&#x27;s needed. The industry rapidly shifted to 1G (1999) and 10G (2003) Ethernet once they became widely available. - FDDI: 100mbps over MMF. The MAE-EAST peering exchange in the mid 1990&#x27;s used DEC Gigaswitches with unique switched FDDI 100mbps Full-Duplex mode where each port was it&#x27;s own separate FDDI domain. - ATM: Telco types last gasp at optimizing for circuit switched networks (phone calls) at the expense of packet switched networks like TCP&#x2F;IP. ATM over Sonet&#x2F;SDH however supported much faster link speeds initially. - Packet over Sonet&#x2F;SDH: Allows the use full-size TCP&#x2F;IP packets over high speed fiber (Sonet&#x2F;SDH) links without ATM segmentation. This is what many OC3-OC48 ISP circuits were running before 1GE&#x2F;10GE took over.There were probably many dozens of other competitors that even I&#x27;m too young to remember. Some of these were later modified to run over Ethernet as you can see here:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ethertype reply pdw 18 hours agoparentDidn&#x27;t IPX always run on top of Ethernet? I thought it was pretty much a direct derivative of Xerox PARC&#x27;s research network protocol. reply peteri 16 hours agorootparentIt ran on top of several things. I remember the company I worked for (Alfa Systems) uploading IPX drivers to Novell for testing over a modem using IPX as a protocol.Alfa designed Sage Mainlan originally a z8530 + RS485(?) PC card followed by a 10Mbps Ethernet with our own chip design (Enzo) fabbed as an ASIC by Toshiba. We wrote IPX drivers for both versions.Interestingly we could hang systems with the 3COM cards in our test systems if we ran at full speed and at somepoint we had the full 500 metres of thick ethernet in the office.The IPX version that came with Netware 3 was rather nice, I seem to recall it had a buffer of segments and these got filled by the different layers of the network stack as needed along with some fancy protocol filtering so your code only saw just the data packets it was interested in. reply Terr_ 15 hours agorootparentprevIt could, but not the further step of running on top of TCP&#x2F;IP, which is why software like Kali [0] was needed if you wanted to play over the internet.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kali_(software) reply wmf 17 hours agorootparentprevDid IPX run on ARCnet? I remember ARCnet being popular in the DOS world. reply jdofaz 15 hours agorootparentSeems so https:&#x2F;&#x2F;www.cisco.com&#x2F;en&#x2F;US&#x2F;docs&#x2F;internetworking&#x2F;troubleshoo...NetWare runs on Ethernet&#x2F;IEEE 802.3, Token Ring&#x2F;IEEE 802.5, Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), and ARCnet. NetWare also works over synchronous wide-area network (WAN) links using the Point-to-Point Protocol (PPP) reply jtaft 3 hours agoprevI’m always blown away by people who can reverse engineer dies.I’m curious can heat be used to detect interesting parts of a die? Ie decap then re-run target functionality and see what’s heating up? reply wrs 18 hours agoprevThere is still a Linux driver for the 825xx chips, if you want to see how the software side works.https:&#x2F;&#x2F;github.com&#x2F;torvalds&#x2F;linux&#x2F;blob&#x2F;master&#x2F;drivers&#x2F;net&#x2F;et... reply userbinator 18 hours agoparentAs far as I know, all of Intel&#x27;s Ethernet controllers with the exception of the most recent ones like the horribly-named i2xx (is that a lowercase i, uppercase I, or lowercase L? Even Intel seems to be confused about that on its site) have a 825xx part number. The 82574 is commonly emulated for VMs. reply rasz 12 hours agoparentprevFrom the initial article I expected some Bus mastering DMA, or at least ISA DMA, but its a big shared memory window. For ISA Network card choices were:Bus Mastering - fancy and fast, but troublesome with lots of ram and&#x2F;or in protected mode http:&#x2F;&#x2F;www.os2museum.com&#x2F;wp&#x2F;vds-borne-out-of-necessity&#x2F;ISA DMA - slow, example AMD Lance Am7990 like Novell NE2100. Maximum original 8237 DMA controller throughput was ~1MB&#x2F;s while stealing 100% of ISA bus thus stalling CPU completely.Memory sharing - also problematic because you lose precious DOS memory.Port IO - like good old NE2000. Small software interface footprint, fast with 286&#x2F;V20 &#x27;REP INSW&#x2F;OUTSW&#x27;. reply asylteltine 22 hours agoprevI can’t fathom how there are humans who can understand this stuff. I “just” do software and microcontrollers reply tails4e 17 hours agoparentI work in ASIC design, and while it seems like gobbledygook, it&#x27;s not too hard to grok with some experience. Ken&#x27;s blogs help a lot in that regard. For context, compared to modern chips these are extremely simple, bit at the time the tools for chip design were limited so it was a bit of art and science in one. Now there is a lot of automation to help &#x27;draw&#x27; the layout using standard cells for digital, but analog design is still an art (and incredibly complex one). So at least for digital weve first order abstracted designers from the individual gates and wires, and design is more akin to programming, though in languages designed for hardware. I feel fortunate enough to have seen both sides, so have done both the full custom design as well as the highly EDA driven design. reply wmf 19 hours agoparentprevTo give some perspective, a chip like this from 1982 would have been designed by a very small team; maybe just 2-3 people and they were using primitive 1970s technology with no Internet access. Today you could learn how to design a chip like this in a few years, maybe faster if you just stick to logic design. reply voxadam 5 hours agorootparent> using primitive 1970s technologyIncluding, but not limited to, miles of Rubylith.[0][0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rubylith reply kens 6 minutes agorootparentWell, square feet of Rubylith maybe. I haven&#x27;t been able to find the exact date that Intel switched from Rubylith to digitally-generated masks, but I&#x27;m pretty sure they had switched by 1982. reply PaulHoule 21 hours agoparentprevChips at that level are often pretty simple. For fun I something build out circuits with 74xx or 54xx that are about this complex on a breadboard and drive them with an Arduino. reply dboreham 19 hours agoprevKen, not mentioned in the article but I wondered about the history of this design. Some distant memory that it may have been a dec design or dec-involved? Obviously there were TTL-based Ethernet implementations in the 70s (Metcalf famous self-wire-wrapped prototype[1] being the first). Perhaps this chip was a VLSI re-do of one of those designs?[1] https:&#x2F;&#x2F;americanhistory.si.edu&#x2F;collections&#x2F;search&#x2F;object&#x2F;nma... reply kens 17 hours agoparentRobert Garner is writing a book on the history of Ethernet; I&#x27;m leaving those historical details to him :-) reply kritr 13 hours agoprevGreat article! The led me into a rabbit hole, exploring collisions in Wi-Fi and the corresponding CSMA&#x2F;CA Protocol. I hadn’t put that much thought into how this worked in practice. reply noNothing 17 hours agoprevBrings back memories. I worked at DEC when Ethernet first came out and I remember a few ocmpanies producing great benchmarks by not backing off. reply formerly_proven 17 hours agoprev [–] There is a second generation of this chip, the 82596SX&#x2F;DX. Much faster 32-bit bus, still 10 MBit&#x2F;s on the Ethernet side of things. \"Software compatible\". Way bigger buffers.http:&#x2F;&#x2F;bitsavers.informatik.uni-stuttgart.de&#x2F;components&#x2F;inte... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post by Ken Shirriff delves into the technical workings of Intel's 82586 Ethernet LAN coprocessor chip that was released in 1982.",
      "The post highlights how the chip manages network collisions, uses exponential backoff, and employs shared memory structures for communication. Also mentioned are the mechanisms within the counter circuit, dynamic latch circuit, and mask register.",
      "The Ethernet backoff mechanism and potential drawbacks of the system are also discussed, adding an additional perspective on the topic."
    ],
    "commentSummary": [
      "The Intel 82586 network chip was reverse-engineered to study its role in Ethernet backoff, finding that newer chips, despite having more transistors, perform fewer tasks.",
      "Modern chips carry certain features from old models like the 10-bit counters and high-end Network Interface Cards (NICs) show considerable similarity to the 82586, highlighting the enduring influence of older technologies.",
      "A book about the history of Ethernet, documenting both past and current chip designs and technologies, is reportedly being compiled by Robert Garner, offering an in-depth look at Ethernet's development."
    ],
    "points": 187,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1698767997
  },
  {
    "id": 38086598,
    "title": "MicroTCP, a minimal TCP/IP stack",
    "originLink": "https://github.com/cozis/microtcp",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up cozis / microtcp Public Notifications Fork 6 Star 288 Code Issues 2 Pull requests Actions Projects Security Insights cozis/microtcp main 1 branch 0 tags Go to file Code Latest commit cozis fixed a couple typos in the readme e6dbeaf Git stats 28 commits Files Type Name Latest commit message Commit time 3p new makefile examples new makefile src new makefile .gitignore gitignore update .gitmodules general cleanups README.md fixed a couple typos in the readme makefile new makefile README.md MicroTCP MicroTCP is a TCP/IP network stack I started building as a learning exercise while attending the Computer Networking course at the Università degli Studi di Napoli Federico II. It's just a hobby project and is intended to just be a minimal, yet complete, implementation. At this moment MicroTCP implements ARP (RFC 826, complete), IPv4 (no fragmentation), ICMP (minimum necessary to reply to pings) and TCP (complete but not stress-tested). Note that \"complete\" should not be intended as \"fully compliant\" but just as a measure of progress on all of the major features. For instance, it's complete enough to handle HTTP traffic on a local network (Look into examples/microhttp to know more). Where does it run? MicroTCP can run on Windows and Linux alongside the OS's network stack. To route the network traffic to MicroTCP, the process running it behaves as a virtual host with its own IP address. This is done using a TAP device, which comes built-in on Linux and needs to be installed on Windows. It should be very easy to adapt MicroTCP to run on microcontrollers but haven't tried yet. The dream is to serve my blog from an STM32 board! Build and Install If you are on Windows, you need to install the TAP driver provided by OpenVPN and instanciate a virtual NIC so that MicroTCP can connect to it when started. To build the project from source, make sure you cloned the repository with submodules git clone https://github.com/cozis/microtcp.git --recursive and then run make You'll need both make and cmake for it to work. If all goes well, you'll find the library files libtuntap.a, libmicrotcp.a and header files tuntap.h, tuntap-export.h, microtcp.h in out/. Usage MicroTCP's uses the usual socket interface any network programmer is familiar with, the main difference being you need to explicitly instanciate the network stack and pass its handle around. Here's a simple echo server that shows the basic usage: #includeint main(void) { microtcp_t *mtcp = microtcp_create(); uint16_t port = 80; microtcp_socket_t *server = microtcp_open(mtcp, port, NULL); while (1) { microtcp_socket_t *client = microtcp_accept(server, false, NULL); char buffer[1024]; size_t num = microtcp_recv(client, buffer, sizeof(buffer), NULL); microtcp_send(client, \"echo: \", 6, NULL); microtcp_send(client, buffer, num, NULL); microtcp_close(client); } microtcp_close(server); microtcp_destroy(mtcp); return 0; } // NOTE: Errors checks were omitted for readability's sake. // If you want to use this code, you probably want to // add some checks! This should be pretty straight forward to understand. One thing may be worth noting is that microtcp_open behaves as the BSD's socket+bind+listen all at once to setup a listening TCP server. There is more than one way to set up the stack, the main way being microtcp_create which creates a virtual network inferface on the host OS with IP 10.0.0.5/24 and a virtual host for the MicroTCP process at 10.0.0.4/24. You can open Wireshark on the virtual NIC to inspect the traffic between the host and the process. It's also possible to configure the stack using the microtcp_create_using_callbacks, which lets you explicitly provide the input L2 frames to it and receive the frames in a buffer. This is how one would configure the stack to run on a microcontroller. Each instance of MicroTCP (without considering the callbacks) is completely isolated from the others, therefore, if your specific callback implementation allows it, you can have as many instances as you like! Testing There is still no testing infractructure. The way I'm testing it is by setting up an HTTP or echo server and stressing it until something breaks while capturing what happened using Wireshark. About A minimal TCP/IP stack Topics c socket tcp minimal ip socket-programming Resources Readme Activity Stars 288 stars Watchers 4 watching Forks 6 forks Report repository Releases No releases published Packages No packages published Languages C 98.9% Makefile 1.1% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=38086598",
    "commentBody": "MicroTCP, a minimal TCP&#x2F;IP stackHacker NewspastloginMicroTCP, a minimal TCP&#x2F;IP stack (github.com/cozis) 185 points by cozis 23 hours ago| hidepastfavorite42 comments tpmx 20 hours agoSomething similar from... a while ago. How does it compare?https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20060615041317&#x2F;http:&#x2F;&#x2F;www.sics.s...uIP is an implementation of the TCP&#x2F;IP protocol stack intended for small 8-bit and 16-bit microcontrollers. It provides the necessary protocols for Internet communication, with a very small code footprint and RAM requirements - the uIP code size is on the order of a few kilobytes and RAM usage is on the order of a few hundred bytes.https:&#x2F;&#x2F;github.com&#x2F;adamdunkels&#x2F;uiphttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;UIP_(software)(I believe uIP was extracted and improved upon from Contiki, a C64 OS with TCP&#x2F;IP support written in C in 2002: https:&#x2F;&#x2F;www.c64-wiki.com&#x2F;wiki&#x2F;Contiki) reply jug 17 hours agoparentHaha, oof, it&#x27;s evil to compare to that! Adam is a \"10x programmer\" genius. reply tpmx 16 hours agorootparentYeah, it felt a bit evil, but I also really wanted to share this because it predates HN and deserves sharing. And then the MicroTCP poster went AWOL... reply riedel 17 hours agoparentprevWas about to post the same. Contiki actually came to fame though as it was commonly used for sensor networks an IoT application. Particularly integrating 6lowpan (ZigBee IPv6) made it interesting for us at the time. reply cozis 23 hours agoprevHello HN! This is a project I&#x27;ve started this year to learn about sockets and network programming. Nothing serious, just a hobby project! I&#x27;d love to hear your opinions about it and feel free to ask questions reply willprice89 10 hours agoparentCool project! I also created a userspace network stack for Wallpunch, a censorship circumvention tool I built. It wasn&#x27;t clear from the article if you were planning on working on this further or leaving it as is, but if you want to keep perfecting it I have a suggestion for testing:An HTTP&#x2F;echo server you control is great for the bare essentials, but there are so many mind-boggling ways things can go wrong in the real world. I think the only way to catch those edge cases (and even so you&#x27;ll never catch them all!) is to use it on as many different devices for as many real world applications as possible. reply cozis 5 hours agorootparentHey, happy you liked it!!> It wasn&#x27;t clear from the article if you were planning on working on this further or leaving it as isAt the moment I&#x27;m working on it on and off in my spare time. I think I will continue that way until all major features are done and stable> An HTTP&#x2F;echo server you control is great for the bare essentials, but there are so many mind-boggling ways things can go wrong in the real world. I think the only way to catch those edge cases (and even so you&#x27;ll never catch them all!) is to use it on as many different devices for as many real world applications as possible.Yes, I&#x27;m realizing that. From the beginning I&#x27;ve been thinking about going the unit test route but couldn&#x27;t find a way to make it work. Thanks for the feedback! reply surteen 21 hours agoparentprevWhat is the licensing for this code? reply wolf550e 18 hours agorootparent(I&#x27;m not OP)1. There is no license, so it&#x27;s proprietary code.2. It&#x27;s a student project, you shouldn&#x27;t use it for anything. reply OJFord 17 hours agorootparent> 2. It&#x27;s a student project, you shouldn&#x27;t use it for anything.I&#x27;m a graduate, should you use it if I write it? reply tptacek 17 hours agorootparentNot if you call it a student project! Probably your TCP&#x2F;IP stack should not be someone&#x27;s hobby project. A good threshold test: do you need to care about the license? If so... reply OJFord 15 hours agorootparentI think we&#x27;re making the same point really - I meant that it&#x27;s not that OP&#x27;s a student that means you might not want to actually use it for something, that just seems a bit mean&#x2F;gatekeepy, but also naïve, to me.I don&#x27;t think there&#x27;s any reason not to experiment with this any more than similar ShowHN hobby work from anyone else. i.e. follow its progress, maybe toy with it in your own hobby thing.And honestly, I knew more about how to write a TCP&#x2F;IP stack when I was a student than now. If I could do a better job now it would only be from some experience writing other code to RFC spec. reply tptacek 15 hours agorootparentIt&#x27;s surprisingly good code for a student hobby project. I dipped in earlier hoping to find some silly gotcha to preen about, but it&#x27;s well structured, follows a close read of the RFCs, and for its problem domain it probably needs to be in C anyways. I agree, the author shouldn&#x27;t sell themselves short if they don&#x27;t want to. But I also kind of took the \"what&#x27;s the license\" question as a bit snippy, which I assume that preceding commenter did too. replysquarefoot 20 hours agoprev\"The dream is to serve my blog from an STM32 board!\"That (uControllers and small systems in general) should be among the best use cases as there is obviously a much higher demand for a low footprint network stack in that field, also with an eye to Single Pair Ethernet, should it become cheaper and widely supported in common uCs in the future. reply mannyv 12 hours agoprevI love these tiny stacks because it shows people that not everything needs to be a super complicated implementation that takes years.Of course it needs tap but it might not be too hard to get it to work with an phy driver directly. reply Uptrenda 19 hours agoprevAs a networking nerd I respect the project OP. Very good learning exercise. There are still many unsolved problems in networking, too. It&#x27;s a bit of an esoteric field. reply fuzztester 15 hours agoprevHow about TCP for DOS?mTCP:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=13264041 reply swimwiththebeat 21 hours agoprevHow did you even get started with this? There are many systems I&#x27;d love to learn to implement from scratch like databases, network stacks, and caches, but the task seems so vast and daunting that it&#x27;s hard to get started. Learning from existing codebases is also difficult b&#x2F;c there&#x27;s so much code to go over and understand. Can you elaborate on what your process was to build this without any help? reply vlovich123 19 hours agoparentThe strategy that works best for me is to just start at the simplest step & iterate from there. Do research online to find blog posts &#x2F; articles describing how to solve specific problems. When doing reading, make sure to note terms of art that repeat so that you know what to look for.So the first step I would do to start on a TCP&#x2F;IP stack would be \"how to open a raw socket\" (granted you have to know the magic phrase here). There&#x27;s also tons of \"how to implement TCP stack\" articles (same for ethernet etc) that probably are good starting points if I didn&#x27;t know that magic phrase. The other thing is to find people to talk to who know more than you to answer those questions.Once you have that, you can setup a real TCP socket on one end and a raw socket client on the other & then the same thing in reverse. Then look up the TCP&#x2F;IP framing on Wikipedia (+ read up on the broad overview of how TCP works and the various parts). Once you have the framing implemented, try implementing the basic sequence to establish a connection. Then keep noting what features a full TCP stack has, which are required, & which are missing from my implementation (that&#x27;s when I&#x27;d start reaching for the standards that everyone references).Of course, if you want to do something novel beyond just \"hey I have confidence that I can implement such a stack myself\" (e.g implementing something with certain performance characteristics) that requires a deeper understanding of how things work and a good filter on possible ideas & which ones are going to likely work out the best (that is gained through expertise, creativity & intelligence) reply pipes 18 hours agorootparentIf you made this into a book, I&#x27;d buy it! Especially if it was structured so that each chapter had a coding exercise that built on the previous one so that by the end I had a working stack.My favourite programming book is structured like this \"elements of computer systems\" also referred to as \"from nand to Tetris\" reply cozis 5 hours agoparentprevI think it boils down to the ability of being able to divide a big problem into smaller parts and understanding in what order you need to takle them. The more you try building big things the better you get at doing it.After getting into university I decided to build an interpreter[0]. For someone who didn&#x27;t even have the notion of a parser, it just felt like an unaproachable task. Even though, I sticked to it and the architecture became clear in time. That&#x27;s another thing, even if you try to build something and miserably fail at it at each iteration, you still get better at it. The feeling of the task being too vast and daunting is just a feeling and knowing there&#x27;s something on the other side makes it easier to power through it.Hope to see your database on HN someday! :^)[0] https:&#x2F;&#x2F;github.com&#x2F;cozis&#x2F;Noja reply technothrasher 20 hours agoparentprevI wrote a little embedded TCP stack a while back as a learning project. I just read the RFCs and coded away. I&#x27;m sure it&#x27;s the world&#x27;s least efficient stack, but it wasn&#x27;t too hard to get basic functionality. reply Lukeisun 17 hours agoparentprevI am not very familiar with this kind of stuff either but I have read through \"Beej&#x27;s Guide to Network Programming\" https:&#x2F;&#x2F;beej.us&#x2F;guide&#x2F;bgnet&#x2F;html&#x2F;split&#x2F;. Which seems like enough to implement something like OP posted.As for db&#x27;s&#x2F;other interesting things, I haven&#x27;t read them myself but this site seems solid https:&#x2F;&#x2F;build-your-own.org&#x2F;. If anyone has any real experience with this site, I would love to hear it! reply coddle-hark 20 hours agoparentprevNo OP but I think there’s three parts to really getting TCP&#x2F;IP:- Read the spec(s)- Learn the OS APIs deeply- Look at a bunch of real network data in e.g. Wireguard reply OJFord 17 hours agorootparent> Look at a bunch of real network data in e.g. WireguardI think you probably meant data in e.g. Wireshark?But another good suggestion (or maybe what you meant) might be to look at &#x27;real&#x27; (production) networking code in e.g. Wireguard, I imagine. reply nradov 15 hours agoprevCool project. It reminds me of another minimal TCP implementation from Viewpoints Research Institute back in 2007. They managed to do it in under 200 lines of code by writing a parser that directly interprets the ASCII art diagrams in the IETF RFC. Which is kind of a bizarre approach, but very clever and somewhat self documenting.http:&#x2F;&#x2F;www.vpri.org&#x2F;pdf&#x2F;tr2007008_steps.pdfIt&#x27;s not really intended for production use, more as a demo of a new experimental programming language. reply cozis 5 hours agoparentAmazing! I would have NEVER thought of that! That&#x27;s just another level of \"following the standards\" reply specialist 3 hours agoparentprevThank you so much for sharing this.What would you call this paradigm?Ian Piumarta (this researcher) calls it \"self implementing\". https:&#x2F;&#x2F;www.piumarta.com&#x2F;cv&#x2F;bio.htmlMy best effort so far is \"example driven programming\", which is turrible.I did something similar for HL7 specifications, at about the same time. Our consultants (what the kids today would probably call business analysts) would hammer out an \"HL7 interface\" document. (Think human readable OpenAPI for the time.) It&#x27;d serve as an actual contract, between us and the hospital, of sorts.Being lazy, I wrote a parser (not BNF based, like Piumarta&#x27;s work) which scrapped the \"interface\" and generated code. Implemented in minutes, instead of days or weeks.I&#x27;ve since applied that strategy to other domains, with similar results.But I have the hardest time describing this paradigm. Even when people see demos, they don&#x27;t quite get it. This stuff is supposed to be hard, right? Surely I&#x27;m cheating somehow.Naively, I&#x27;ve been thinking that if I coined an insipid new phrase, maybe it could become an inscrutable meme. Like \"Agile Methodology\" and \"Extreme Programming\" did. Catnip for PHBs. reply dariosalvi78 21 hours agoprevBene! reply waynesonfire 19 hours agoprev [–] I really want to understand how this fits into my mental model. Wtf is a TCP&#x2F;IP stack? It&#x27;s blurry because I _GUESS_ some of it maybe lives on the network card, some in the kernel, and some in usermode. So, when one decides to write their own network stack, what abstractions are they building on top of?Maybe it would be helpful to understand this from the perspective of that STM32 board. So it has an ethernet jack, maybe? Is that the abstraction that a TCP&#x2F;IP stack would have to build on top of?Now, if that&#x27;s the case, why is it that in this case the user is using a TAP device? Is it because they didn&#x27;t want to write a kernel driver? E.g. is interacting with the TAP device the equivalent of the \"fuse\" abstraction for filesystems? reply dboreham 19 hours agoparent [–] > Wtf is a TCP&#x2F;IP stack?You may want to consider toning it down. Readers here would be expected to know all this.And yes TAP is a user mode raw interface to the NIC. reply ninkendo 14 hours agorootparent> You may want to consider toning it down.FWIW I didn’t take OP’s comment to be of a criticizing tone, I just assumed they were legitimately curious and looking to improve their understanding. I don’t think there’s anything for them to “tone down” in that regard. reply pipes 18 hours agorootparentprevThat&#x27;s a big assumption. Who says they are expected to know this? reply fragmede 16 hours agorootparentPersonally I say yes but who cares what I say. Let&#x27;s see what this poll says in a few hours.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38092364 reply pipes 6 hours agorootparentYour poll is asking a different question. You said people expected to know this. Implying that there is a minimum level of knowledge required to participate in hacker news.Your poll is asking do they know what a TCP IP stack is. Even if 100 percent of respondents know, it doesn&#x27;t validate your claim that hacker news requires this knowledge.Btw I got really good responses to my questions about networking recently. Should I not be asking these types of questions?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37842863 reply hujun 17 hours agorootparentprevthe purpose of using TAP is to be able to write IP stack in user mode code; however TAP is not the only way on linux, you could also use raw(AF_PACKET)or XDP socket, they also allow you bypass kernel IP stack reply waynesonfire 18 hours agorootparentprev [–] > Readers here would be expected to know all this.I&#x27;m not asking about the OSI model. I&#x27;ve long moved beyond that. Sorry that wasn&#x27;t clear from my message I was typing in haste. I suspect very few readers here have implemented a TCP&#x2F;IP stack or would even know where to begin. So, I&#x27;m acknowledging this.There is a comment in this thread asking, \"How did you even get started with this?\" and it was able to successfully solicit the response that I was looking for. reply ksherlock 16 hours agorootparentTCP was designed in 1974. Ethernet was designed in 1980. UDP was designed in 1980. ICMP was designed in 1981. ARP was designed in 1982. Think about the computing power available in 1974 or 1980-1982. If you break it down into chunks and follow the RFCs it&#x27;s manageable. tap gives you easy access to read&#x2F;write ethernet packets. From there you can start sending ARP queries and responding to ARP requests. ICMP is simple, adds support for that and now you can ping. UDP? just as simple. TCP is more work but most of that is error handling and timeouts so skip them for now. reply spc476 17 hours agorootparentprevStart at the hardware&#x2F;IP layer. Easiest would be serial port for the hardware, and there are at least two methods of sending IP over serial, SLIP and PPP---there are documents out there that describe how those work. Then work on IP. IP itself is fairly easy---it&#x27;s just best effort and IP options are just that---options. Then ICMP. Once you have that, then you can at least ping the device. UDP is the next easiest to implement, it&#x27;s just portnumbers to an otherwise IP packet. reply sitzkrieg 18 hours agorootparentprev [–] the osi model layers describe exactly what is going on in embedded systems (well all), though. look at a mcu board with ethernet. find the magjack. then the PHY, then the MAC, then... reply bvrmn 16 hours agorootparent> the osi model layers describe exactly what is going on in embedded systemsUnless it doesn&#x27;t. OSI describes non-existing stack from the long gone past. reply Hikikomori 15 hours agorootparentprev [–] The OSI model describes the OSI protocols, does not really describe what goes on exactly. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MicroTCP is a minimal but comprehensive TCP/IP network stack created by \"cozis\" as part of a personal learning project during a Computer Networking course at Università degli Studi di Napoli Federico II.",
      "The stack, compatible with both Windows and Linux, provides full functionalities for handling ARP, IPv4, ICMP, and TCP communications, and could potentially be adapted for use with microcontrollers.",
      "Despite ongoing testing, MicroTCP already possesses the capacity to manage local network HTTP traffic."
    ],
    "commentSummary": [
      "MicroTCP, a minimal TCP/IP stack project, is gaining interest for its low code and RAM requirements, along with wider discussions about real-world applications and unit testing.",
      "The project's creator plans to continue development until it achieves stability, despite licensing concerns.",
      "Forum discourse dwells on building a TCP/IP stack from the ground up for DOS, lean on iterative learning, online research, and expert advice. It also delves into the abstraction layers in systems and the application of OSI (Open Systems Interconnection) model in deciphering network operations."
    ],
    "points": 185,
    "commentCount": 42,
    "retryCount": 0,
    "time": 1698766992
  },
  {
    "id": 38095699,
    "title": "How Bear does analytics with CSS",
    "originLink": "https://herman.bearblog.dev/how-bear-does-analytics-with-css/",
    "originBody": "ᕕ( ᐛ )ᕗ Herman's blog Home Projects Podcast Blog How Bear does analytics with CSS 01 Nov, 2023 Bear Blog has a few design constraints for speed, efficiency, and stability. There are many great open-source, privacy-focussed analytics platforms out there, but I wanted to build one native to Bear. tldr; One of my constraints for Bear is to not use client-side javascript. This applies to the analytics system as well. Client-side javascript can be tweaked to determine the authenticity of traffic to a page and determine (partially) whether it is bot traffic or not, which is very useful for analytics. The main downside, however, is that most adblockers block analytics scripts. And not just the bad ones, like Google Analytics. Even Fathom and Plausible analytics struggle with logging activity on adblocked browsers. There's always the option of just parsing server logs, which gives a rough indication of the kinds of traffic accessing the server. Unfortunately all server traffic is generally seen as equal. Technically bots \"should\" have a user-agent that identifies them as a bot, but few identify that since they're trying to scrape information as a \"person\" using a browser. In essence, just using server logs for analytics gives a skewed perspective to traffic since a lot of it are search-engine crawlers and scrapers (and now GPT-based parsers). So instead of using server logs, I trigger a read with CSS. Here's my slightly boutique analytics system. When a person accesses the website the page is loaded. On each page I have the following CSS: body:hover { border-image: url(\"/hit/{{ post.id }}/?ref={{ request.META.HTTP_REFERER }}\"); } The only info I need to actively re-add to this request is the referrer (yes, HTTP_REFERER is spelt incorrectly). Now, when a person hovers their cursor over the page (or scrolls on mobile) it triggers body:hover which calls the URL for the post hit. I don't think any bots hover and instead just use JS to interact with the page, so I can, with reasonable certainty, assume that this is a human reader. I then confirm the user-agent isn't a bot (which isn't perfect, but still something). I also extract the browser and platform from the user-agent string. My second constraint is to not store any identifying information about the reader either in browser cookies, or on the server. In order to do this I use the IP address of the request to determine the country, then hash the IP address along with the date. All subsequent requests to the page are checked for matching IP address + date hashes and duplicates are discarded. In this way each IP address per day constitutes one \"read\" of the page. No IP addresses are stored un-hashed and the IP-with-date-hash creates a convenient built-in expiry time. Here's the code if you're interested: user_agent = httpagentparser.detect(self.request.META.get('HTTP_USER_AGENT', None)) if user_agent.get('bot', False): print('Bot traffic') return ip_hash = hashlib.md5(f\"{client_ip(self.request)}-{timezone.now().date()}\".encode('utf-8')).hexdigest() country = get_user_location(client_ip(self.request)).get('country_name', '') device = user_agent.get('platform', {}).get('name', '') browser = user_agent.get('browser', {}).get('name', '') referrer = self.request.GET.get('ref', '') if referrer: referrer = urlparse(referrer) referrer = '{uri.scheme}://{uri.netloc}/'.format(uri=referrer) Hit.objects.get_or_create( post_id=self.pk, ip_address=ip_hash, referrer=referrer, country=country, device=device, browser=browser) edit: The IP address hash's only use is to prevent duplicate hits for a given day. This way all page views are unique by default. I then have a background task which runs at the end of each day to scrub the hashes from the hit logs, so as to not step on any over-zealous GDPR advocate's toes. The only downside to this method is if there are multiple reads from the same IP address but on separate devices, it will still only be seen as one read. And I'm okay with that since it constitutes such a minor fragment of traffic. This provides an accurate count of reads and I feel is more concise and simpler than many other forms of analytics capture. tldr; I use CSS to trigger a url analytics endpoint on body:hover, determine useful information from the IP address and user-agent, then hash the IP address with the date to create a unique \"read\" of a page. Enjoyed the article? I write about 1-2 a month. Subscribe via email or RSS feed. 141 Made with Bear ʕ•ᴥ•ʔ",
    "commentLink": "https://news.ycombinator.com/item?id=38095699",
    "commentBody": "How Bear does analytics with CSSHacker NewspastloginHow Bear does analytics with CSS (herman.bearblog.dev) 184 points by todsacerdoti 7 hours ago| hidepastfavorite147 comments jackjeff 6 hours agoThe whole anonymization of IP addresses by just hashing the date and IP is just security theater.Cryptographic hashes are designed to be fast. You can do 6 billion md5 hashes in a second on an MacBook (m1 pro) via hashcat and there’s only 4 billion ipv4 addresses. So you can brute force the entire range and find the IP address. Basically reverse the hash.And that’s true even if they used something secure like SHA-256 instead of broken MD5 reply WhyNotHugo 3 hours agoparentAside from it being technically trivial to get an IP back from its hash, the EU data protection agency made it very clear that \"hashing PII does not count as anonymising PII\".Even if you hash somebody&#x27;s full name, you can later answer the question \"does this hash match the this specific full name\". Being able to answer this question implies that the anonymisation process is reversible. reply kevincox 2 hours agorootparentI think the word \"reversible\" here is being stretched a bit. There is a significant difference between being able to list every name that has used your service and being able to check if a particular name has used your service. (Of course these can be effectively the same in cases where you can list all possible inputs such as hashed IPv4 addresses.)That doesn&#x27;t mean that hashing is enough for pure anonymity, but used properly hashes are definitely a step above something fully reversible (like encryption with a common key). reply bayindirh 2 hours agorootparentprevWe&#x27;re members of some EU projects, and they share a common help desk. To serve as a knowledge base, the tickets are kept, but all PII is anonymized after 2 years AFAIK.What they do is pretty simple. They overwrite the data fields with the text \"\". No hashes, no identifiers, nothing. Everything is gone. Plain and simple. reply alkonaut 3 hours agoparentprevHashes should be salted. If you salt, you are fine, if you don&#x27;t you aren&#x27;t.Whether the salt can be kept indefinitely, or is rotated regularly etc is just an implementation detail, but the key with salting hashes for analytics is that the salt never leaves the client.As explained in the article there seems to be no salt (or rather, the current date seems to be used as a salt, but that&#x27;s not a random salt and can easily be guessed for anyone who wants to say \"did IP x.y.z.w visit on date yy-mm-dd?\".It&#x27;s pretty easy to reason about these things if you look from the perspective of an attacker. How would you do to figure out anything about a specific person given the data? If you can&#x27;t, then the data is probably OK to store. reply piaste 2 hours agorootparent> Hashes should be salted. If you salt, you are fine, if you don&#x27;t you aren&#x27;t.> Whether the salt can be kept indefinitely, or is rotated regularly etc is just an implementation detail, but the key with salting hashes for analytics is that the salt never leaves the client.I think I&#x27;m missing something.If the salt is known to the server, then it&#x27;s useless for this scenario. Because given a known salt, you can generate the hashes for every IP address + that salt very quickly. (Salting passwords works because the space for passwords is big, so rainbow tables are expensive to generate.)If the salt is unknown to the server, i.e. generated by the client and &#x27;never leaves the client&#x27;... then why bother with hashes? Just have the client generate a UUID directly instead of a salt. reply rkangel 2 hours agorootparentWithout a salt, you can generate the hash for every IP address once, and then permanantly have a hash->IP lookup (effectively a Rainbow table). If you have a salt, then you need to do it for each database entry, which does make it computationally more expensive. reply tptacek 1 hour agorootparentPeople are obsessed with this attack from the 1970s, but in practice password cracking rigs just brute force the hashes, and that has been the practice since my career started in the 1990s and people used `crack`, into the 2000s and `jtr`, and today with `hashcat` or whatever it is the cool kids use now. \"Rainbow tables\" don&#x27;t matter. If you&#x27;re discussing the expense of attacking your scheme with or without rainbow tables, you&#x27;ve already lost. reply alkonaut 56 minutes agorootparentprev> > the salt never leaves the client> I think I&#x27;m missing something....> If the salt is known to the server,That&#x27;s what you were missing yes reply SamBam 20 minutes agorootparentDid you miss the second half where GP asked why the client doesn&#x27;t just send up a UUID, instead of generating their own salt and hash? reply darken 2 hours agorootparentprevSalts are generally stored with the hash, and are only really intended to prevent \"rainbow table\" attacks. (I.e. use of precomputed hash tables.) Though a predictable and matching salt per entry does mean you can attack all the hashes for a timestamp per hash attempt.That being said, the previous responder&#x27;s point still stands that you can brute force the salted IPs at about a second per IP with the colocated salt. Using multiple hash iterations (e.g. 1000x; i.e. \"stretching\") is how you&#x27;d meaningfully increase computational complexity, but still not in a way that makes use of the general \"can&#x27;t be practically reversed\" hash guarantees. reply alkonaut 45 minutes agorootparentAs I said the key for hashing PII for telemetry is that the client does the hashing on the client side and the client never transmits the salt. This isn&#x27;t a login system or similar. There is no \"validation\" of the hash. All the hash is is a unique marker for a user that doesn&#x27;t contain any PII. reply sysop073 17 minutes agorootparentWhat&#x27;s the point in hashing the IP + salt then, just let each client generate a random nonce and use that as the key reply SamBam 19 minutes agorootparentprevHow does the client generate the same salt every time they visit the page, without using cookies? reply tptacek 1 hour agorootparentprevSalting a standard cryptographic hash (like SHA2) doesn&#x27;t do anything meaningful to slow a brute force attack. This problem is the reason we have password KDFs like scrypt.(I don&#x27;t care about this Bear analytics thing at all, and just clicked the comment thread to see if it was the Bear I thought it was; I do care about people&#x27;s misconceptions about hashing.) reply michaelmior 23 minutes agorootparent> Salting a standard cryptographic hash (like SHA2) doesn&#x27;t do anything meaningful to slow a brute force attack.Sure, but it does at least prevent the use of rainbow tables. Arguably not relevant in this scenario, but it doesn&#x27;t mean that salting does nothing. Rainbow tables can speed up attacks by many orders of magnitude. Salting may not prevent each individual password from being brute forced, but for most attackers, it probably will prevent your entire database from being compromised due to the amount of computation required. reply alkonaut 48 minutes agorootparentprevWhat do you mean by \"brute force\" in the context of reversing PII that has been obscured by a one way hash? My IP number passed through SHA1 with a salt (a salt I generated and stored safely on my end) is 6FF6BA399B75F5698CEEDB2B1716C46D12C28DF5 Since this is all that would be sent over the wire for analytics, this is the only information an attacker will have available.The only thing you can brute force from that is some IP and some salt such that SHA1(IP+Salt) = 6FF6BA399B75F5698CEEDB2B1716C46D12C28DF5 But you&#x27;ll find millions of such IPs. Perhaps all possible IP&#x27;s will work with some salt, and give that hash. It&#x27;s not revealing my IP even if you manage to find a match? reply infinityio 26 minutes agorootparentIf you also explicitly mentioned the salt used (as bear appear to have done?), this just becomes a matter of testing 4 billion options and seeing which matches reply alkonaut 21 minutes agorootparentI think it&#x27;s just unsalted in the example code. Or you could argue that the date is kind of used as a salt. But the point was that salting + hashing is fine for PII in telemetry if and only if the salt stays on the client. It might be difficult to do without JS though. replyEtheryte 3 hours agoparentprevFor context, this problem also came up in a discussion about Storybook doing something similar in their telemetry [0] and with zero optimization it takes around two hours to calculate the salted hashes for every IPv4 on my home laptop.[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37596757 reply berkes 6 hours agoparentprevMaybe they use a secret salt or rotating salt? The example code doesn&#x27;t, so I&#x27;m afraid you are right. But one addition and it can be made reasonable secure.I am afraid, however, that this security theater is enough to pass many laws, regulations and such on PII. reply dspillett 1 hour agoparentprev> Cryptographic hashes are designed to be fast.Not really. They are designed to be fast enough and even then only as a secondary priority.> You can do 6 billion … hashes&#x2F;second on [commodity hardware] … there’s only 4 billion ipv4 addresses. So you can brute force the entire rangeThis is harder if you use a salt not known to the attacker. Per-entry salts can help even more, though that isn&#x27;t relevant to IPv4 addresses in a web&#x2F;app analytics context because after the attempt at anonymisation you want to still be able to tell that two addresses were the same.> And that’s true even if they used something secure like SHA-256 instead of broken MD5Relying purely on the computation complexity of one hash operation, even one not yet broken, is not safe given how easy temporary access to mass CPU&#x2F;GPU power is these days. This can be mitigated somewhat by running many rounds of the hash with a non-global salt – which is what good key derivation processes do for instance. Of course you need to increase the number of rounds over time to keep up with the rate of growth in processing availability, to keep undoing your hash more hassle than it is worth.But yeah, a single unsalted hash (or a hash with a salt the attacker knows) on IP address is not going to stop anyone who wants to work out what that address is. reply SAI_Peregrinus 55 minutes agorootparentA \"salt not known to the attacker\" is a \"key\" to a keyed hash function or message authentication code. A salt isn&#x27;t a secret, though it&#x27;s not usually published openly. reply marcosdumay 49 minutes agorootparentprev> only as a secondary priorityThat&#x27;s not a reasonable way to say it. It&#x27;s literally the second priority, and heavily evaluated when deciding what algorithms to take.> This is harder if you use a salt not known to the attacker.The \"attacker\" here is the sever owner. So if you use a random salt and throw it away, you are good, anything resembling the way people use salt on practice is not fine. reply krsdcbl 1 hour agorootparentprevDon&#x27;t forget that md5 is comparatively slow & there are way options for hashing nowadays:https:&#x2F;&#x2F;jolynch.github.io&#x2F;posts&#x2F;use_fast_data_algorithms&#x2F; reply TekMol 5 hours agoparentprevThat is easy to fix though. Just use a temporary salt.Pseudo code: if salt.dayEven Fathom and Plausible analytics struggle with logging activity on adblocked browsers.The simple solution is to respect the basic wishes of those who do not want to be tracked. This is a \"struggle\" only because website operators don&#x27;t want to hear no. reply anonymouse008 1 hour agoparentI don&#x27;t know how I feel about this overall. I think we took some rules from the physical world that we liked and discarded others that we&#x27;ve ended up with a cognitively dissonant space.For example, if you walked into my coffee shop, I would be able to lay eyes on you and count your visits for the week. I could also observe were you sit and how long you stay. If I were to better serve you with these data points, by reserving your table before you arrive with your order ready, you&#x27;d probably welcome my attention to detail. However, if I were to see you pulled about x number of watts a month from my outlets, then locked up the outlets for a fee suddenly - then you&#x27;d rightfully wish to never be observed again.So what I&#x27;m getting at is, the issues with tracking appear to be with the perverse assholes vs. the benevolent shopkeeps of the tracking.To wrap up this thought: what&#x27;s happening now though is a stalker is following us into every store, watching our every move. In physical space, we&#x27;d have this person arrested and assigned a restraining order with severe consequences. However, instead of holding those creeps accountable, we&#x27;ve punished the small businesses that just want to serve us.--I don&#x27;t know how I feel about this or really what to do. reply croniev 51 minutes agorootparentThe coffe shop reserving my place and having my order ready before I arrive sounds nice - but is it not an innecessary luxury, that I would not miss had I never even thought of its possibility? I never asked for it, I was ready to stand in line for my order, and the tracking of my behavior resulted in a pleasant surprise, not a feature I was hoping for. If I really wanted my order to be ready when I arrive, then I would provide the information to you, not expect that you observe me to figute it out.My point is that I don&#x27;t get why the small businesses should have the right to track me to offer me better services that I never even asked for. Sure, its nice, but its not worth deregulating tracking and allowing all the evil corps to track me too. reply OhMeadhbh 24 minutes agoparentprevI have, unfortunately, become cynical in my old age. Don&#x27;t take this the wrong way, but... The purpose of the web is to distribute ads. The \"struggle\" is with people who think we made this infrastructure so you could share recipes with your grand-mother.reply reustle 1 hour agoparentprevAs much I agree with respecting folks wishes to not be tracked, most of these cases are not about \"tracking\".It&#x27;s usually website hosts just wanting to know how many folks are passing through. If a visitor doesn&#x27;t even want to contribute to incrementing a private visit counter by +1, then maybe don&#x27;t bother visiting. reply gizmo 1 hour agorootparentIf it was just about a simple count the host could just `wc -l access.log`. Clearly website hosts are not satisfied with that, and so they ignore DO_NOT_TRACK and disrespectfully try to circumvent privacy extensions. reply jakelazaroff 54 minutes agorootparentIs there a meaningful difference between recording \"this IP address made a request on this date\" and \"this IP address made a request on this date after hovering their cursor over the page body\"? How is your suggestion more acceptable than what the blog describes? reply gizmo 40 minutes agorootparentGoing out of your way to specifically track people who indicate they don&#x27;t want to be tracked is worse. replymyfonj 2 hours agoprevSeems clever and all, but `body:hover` will most probably completely miss all \"keyboard-only\" users and users with user agents (assistive technologies) that do not use pointer devices.Yes, these are marginal groups perhaps, but it is always super bad sign seeing them excluded in any way.I am not sure (I doubt) there is a 100 % reliable way to detect that \"real user is reading this article (and issue HTTP request)\" from baseline CSS in every single user agent out there (some of them might not support CSS at all, after all, or have loading of any kind of decorative images from CSS disabled).There are modern selectors that could help, like :root:focus-within (requiring that user would actually focus something interactive there, what again is not guaranteed for al agents to trigger such selector), and&#x2F;or bleeding edge scroll-linked animations (`@scroll-timeline`). But again, braille readers will probably remain left out. reply demondemidi 1 hour agoparentKeyboard only users? All 10 of them? ;) reply bayindirh 1 hour agorootparentWell with me, it&#x27;s probably 11.Joking aside, I love to read websites with keybaords, esp. if I&#x27;m reading blogs. So, it&#x27;s possible that sometimes my pointer is out there somewhere to prevent distraction. reply myfonj 1 hour agorootparentprevI think there might be more than ten [1] blind folks using computers out there, most of them not using pointing devices at all or not in a way that would produce \"hover\".[1] was it base ten, right? reply zichy 1 hour agorootparentprevThink about screen readers. reply nannal 6 hours agoprev> And not just the bad ones, like Google Analytics. Even Fathom and Plausible analytics struggle with logging activity on adblocked browsers.I believe that&#x27;s as they&#x27;re trying to live in what amounts to a toxic wasteland. Users like us are done with the whole concept and as such I assume if CSS analytics becomes popular, then attempts will be made to bypass that too. reply berkes 6 hours agoparentWhy?I manually unblocked Piwik&#x2F;Matomo, Plausible and and Fathom from ublock. I don&#x27;t see any harm in what and how these track. And they do give the people behind the site valuable information \"to improve the service\".e.g. Plausible collects less information on me than the common nginx or Apache logs do. For me, as blogger, it&#x27;s important to see when a post gets on HN, is linked from somewhere and what kinds of content are valued and which are ignored. So that I can blog about stuff you actually want to read and spread it through channels so that you are actually aware of it. reply morelisp 4 hours agorootparentYou&#x27;re just saying a smaller-scale version of \"as a publisher it&#x27;s important for me to collect data on my audience to optimize my advertising revenue.\" The adtech companies take the shit for being the visible 10% but publishers are consistently the ones pressuring for more collection. reply ordersofmag 3 hours agorootparentI&#x27;m a website &#x27;publisher&#x27; for a non-profit that has zero advertising on our site. Our entire purpose for collecting analytics is to make the site work better for our users. Really. Folks like us may not be in the majority but it&#x27;s worth keeping in mind that \"analytics = ad revenue optimization\" is over-generalizing. reply HuwFulcher 2 hours agorootparentprevHow horrifying that someone who does writing potentially as their income would seek to protect that revenue stream.Services like Plausible give you the bare minimum to understand what is viewed most. If you have a website that you want people to visit then it’s a pretty basic requirement that you’ll want to see what people are interested in.When you start “personalising” the experience based on some tracking that’s when it becomes a problem. reply peoplefromibiza 1 hour agorootparent> a pretty basic requirement that you’ll want to see what people are interested in.not reallyit should be what you are competent and proficient atpeople will come because they like what you do, not because you do the things they like (sounds like the same thing, but it isn&#x27;t)there are many proxies to know what they like if you want to plan what to publish and when and for how long, website visits are one of the less interesting.a lot of websites such as this one get a lot of visits that drive no revenue at all.OTOH there are websites who receive a small amount of visits, but make revenues based on the amount of people subscribing to the content (the textbook example is OF, people there can get from a handful of subscriber what others earn from hundreds of thousands of views on YT or the like)so basically monitoring your revenues works better than constantly optimizing for views, in the latter case you are optimizing for the wrong thingI know a lot of people who sell online that do not use analytics at all, except for coarse grained ones like number of subscriptions&#x2F;number of items sold&#x2F;how many email they receive about something they published or messages from social platforms etc.that&#x27;s been true in my experience through almost 30 years of interacting and helping publishing creative content online and offline (books, records, etc) reply HuwFulcher 43 minutes agorootparent> people will come because they like what you do, not because you do the things they like (sounds like the same thing, but it isn&#x27;t)This isn’t true for all channels. The current state of search requires you to adapt your content to what people are looking for. Social channels are as you’ve said.It doesn’t matter how you want to slice it. Understanding how many people are coming to your website, from where and what they’re looking at is valuable.I agree the “end metric” is whatever actually drives the revenue. But number of people coming to a website can help tune that. replyaccount-5 6 hours agoparentprevMakes me reminiscent of uMatrix which could block the loading of CSS too. reply its-summertime 4 hours agorootparentnext [–]||somesite.example^$csswould work in ublock reply momentary 5 hours agorootparentprevIs uMatrix not in vogue any more? It&#x27;s still my go to tool! reply account-5 4 hours agorootparentIt&#x27;s not actively developed anymore so I&#x27;ve been using ublocks advanced options which are good but not as good as uMatrix was. reply ben_w 5 hours agoparentprevThe bit of the web that feels to me like a toxic wasteland is all the adverts; the tracking is a much more subtle issue, where the damage is the long-term potential of having a digital twin that can be experimented on to find how best to manipulate me.I&#x27;m not sure how many people actually fear that. Might get responses from \"yes, and it&#x27;s creepy\" to \"don&#x27;t be daft that&#x27;s just SciFi\". reply input_sh 4 hours agoparentprevNothing&#x27;s gonna block your webserver&#x27;s access.log fed into an analytics service.If anything, you&#x27;re gonna get numbers that are inflated because it&#x27;s a bit impossible to dismiss all of the bot traffic just by looking at user agents. reply chrismorgan 5 hours agoparentprevThis approach is no harder to block than the JavaScript approaches: you’re just blocking requests to certain URL patterns. reply nannal 4 hours agorootparentThat approach would work until analytics gets mixed in with actual styles and then you&#x27;re trying to use a website without CSS. reply chrismorgan 3 hours agorootparentYou’re blocking the image, not the CSS. Here’s a rule to catch it at present: ||bearblog.dev&#x2F;hit&#x2F;This is the shortest it can be written with certainty of no false positives, but you can do things like making the URL pattern more specific (e.g. &#x2F;hit&#x2F;*&#x2F;) or adding the image option (append $image) or just removing the ||bearblog.dev domain filter if it spread to other domains as well (there probably aren’t enough false positives to worry about).I find it also worth noting that all of these techniques are pretty easily circumventable by technical means, by blending content and tracking&#x2F;ads&#x2F;whatever. In case of all-out war, content blockers will lose. It’s just that no one has seen fit to escalate that far (and in some cases there are legal limitations, potentially on both sides of the fight). reply macNchz 1 hour agorootparent> In case of all-out war, content blockers will lose. It’s just that no one has seen fit to escalate that far (and in some cases there are legal limitations, potentially on both sides of the fight).The Chrome Manifest v3 and Web Environment Integrity proposals are arguably some of the clearest steps in that direction, a long term strategy being slow-played to limit pushback. reply marban 5 hours agoparentprevPlausible still works if you reverse-proxy the script and the event url through your own &#x2F;randompath. reply fatih-erikli 4 hours agoprevThis is known as \"pixel tracker\" for decades. reply cantSpellSober 2 hours agoparentUsed in emails as well. Loading a 1x1 transparentis a more sure thing than triggering a hover event, but ad-blockers often block those reply p4bl0 3 hours agoprevI have a genuine question that I fear might be interpreted as a dismissive opinion but I&#x27;m actually interested in the answer: what&#x27;s the goal of collecting analytics data in the case of personal blogs in a non-commercial context such as what Bearblog seems to be? reply taurusnoises 3 hours agoparentI can speak to this from the writer&#x27;s perspective as someone who has been actively blogging since c. 2000 and has been consistently (very) interested in my \"stats\" the entire time.The primary reason I care about analytics is to see if posts are getting read, which on the surface (and in some ways) is for reasons of vanity, but is actually about writer-reader engagement. I&#x27;m genuinely interested in what my readers resonate with, because I want to give them more of that. The \"that\" could be topical, tonal, length, who knows. It helps me hone my material specifically for my readers. Ultimately, I could write about a dozen different things in two dozen different ways. Obviously, I do what I like, but I refine it to resonate with my audience.In this sense, analytics are kind of a way for me to get to know my audience. With blogs that had high engagement, analytics gave me a sort of fuzzy character description of who my readers were. As with above, I got to see what they liked, but also when they liked it. Were they reading first thing in the morning? Were they lunch time readers? Were they late at night readers. This helped me choose (or feel better about) posting at certain times. Of course, all of this was fuzzy intel, but I found it really helped me engage with my readership more actively. reply hennell 1 hour agoparentprevFeedback loops. Contrary to what a lot of people seem to think, analytics is not just about advertising or selling data, it&#x27;s about analysing site and content performance. Sure that can be used (and abused) for advertising, but it&#x27;s also essential if you want any feedback about what you&#x27;re doing.You might get no monetary value from having 12 people read the site or 12,000 but from a personal perspective it&#x27;s nice to know what people want to read about from you, and so you can feel like the time you spent writing it was well spent, and adjust if you wish to things that are more popular. reply Veen 3 hours agoparentprevCuriosity? I like to know if anyone is reading what I write. It&#x27;s also useful to know what people are interested in. Even personal bloggers may want to tailor content to their audience. It&#x27;s good to know that 500 people have read an article about one topic, but only 3 people read one about a different topic. reply mrweasel 3 hours agorootparentFor the curiosity, one solution I&#x27;ve been pondering, but never gotten around to implementing is just logging the country of origin for a request, rather than the entire IP.IPs are useful in case of attack, but you could limit yourself to simply logging subnets. It&#x27;s a little more aggressive block a subnet, or an entire ISP, but it seems like a good tradeoff. reply freitzzz 5 hours agoprevI attempted to do this back at the start of this year, but lost motivation building the web ui. My trick is not CSS but simply loading fake images withtags:https:&#x2F;&#x2F;github.com&#x2F;nolytics reply openplatypus 4 hours agoprevThe CSS tracker is as useful as server log-based analytics. If that is the information you need, cool.But JS trackers are so much more. Time spent on the website, scroll depth, screen sizes, some limited and compliant and yet useful unique sessions, those things cannot be achieved without some (simple) JS.Server side, JS, CSS... No one size fits all.Wide Angle Analytics has strong privacy, DNT support, an opt-out mechanism, EU cloud, compliance documentation, and full process adherence. Employs non-reversible short-lived sessions that still give you good tracking. Combine it with custom domain or first-party API calls and you get near 100% data accuracy. reply TekMol 2 hours agoparentnext [–]The CSS tracker is as useful as server log-based analytics.It is not. Have you read the article?The whole point of the CSS approach is to weed out user agents which are not doing mouse hover on the body events. You can&#x27;t see that from server logs. reply EspressoGPT 3 hours agoparentprevYou probably even could analyze screen sizes by doing the same thing but with CSS media queries. reply croes 4 hours agoparentprevIf it&#x27;s an US company then EU cloud doesn&#x27;t matter regarding data protection for EU citizens.The Cloud Act rendered that worthless. reply openplatypus 10 minutes agorootparentWide Angle Analytics is German company operating everything on EU cloud (EU owners, EU location). reply mcny 6 hours agoprevOn the topic of analytics, how do you store them?Let&#x27;s say I have an e-commerce website, with products I want to sell. In addition to analytics, I decide to log a select few actions myself such as visits to product detail page while logged in. So I want to store things like user id, product id, timestamp, etc.How do I actually store this? My naive approach is to stick it in a table. The DBA yelled at me and asked how long I need data. I said at least a month. They said ok and I think they moved all older data to a different table (set up a job for it?)How do real people store these logs? How long do you keep them? reply jon-wood 6 hours agoparentUnless you’re at huge volume you can totally do this in a Postgres table. Even if you are you can partition that table by date (or whatever other attributes make sense) so that you don’t have to deal with massive indexes.I once did this, and we didn’t need to even think about partitioning until we hit a billion rows or so. (But partition sooner than that, it wasn’t a pleasant experience) reply victorbjorklund 3 hours agoparentprevI use Postgres with timescale db. Works unless your e-commerce is amazon.com. Great thing with timescale db is that they take care of creating materialized views with the aggregates you care about (like product views per hour etc) and you can even choose to \"throw away\" the events themselves and just keep the aggregations (to avoid getting a huge db if you have a lot of events). reply n_e 5 hours agoparentprevAn analytics database is better (clickhouse, bigquery...).They can do aggregations much faster and can deal with sparse&#x2F;many columns (the \"paid\" event has an \"amount\" attribute, the \"page_view\" event has an \"url\" attribute...) reply ordersofmag 3 hours agoparentprevWe&#x27;ve got 13 years worth of data stored in mysql (5 million visitor&#x2F;year). It&#x27;s a pain to query there so we keep a copy in clickhouse as well (which is a joy to query). reply ludwigvan 6 hours agoparentprevClickHouse reply fdaslkjlkjklj 2 hours agoprevLooks like a clever way to do analytics. Would be neat to see how it compares with just munging the server logs since you&#x27;re only looking at page views basically.re the hashing issue, it looks interesting but adding more entropy with other client headers and using a stronger hash algo should be fine. reply dontlaugh 6 hours agoprevWhy not just get this info from the HTTP server? reply hk__2 5 hours agoparent> Why not just get this info from the HTTP server?This is explained in the blog post:> There&#x27;s always the option of just parsing server logs, which gives a rough indication of the kinds of traffic accessing the server. Unfortunately all server traffic is generally seen as equal. Technically bots \"should\" have a user-agent that identifies them as a bot, but few identify that since they&#x27;re trying to scrape information as a \"person\" using a browser. In essence, just using server logs for analytics gives a skewed perspective to traffic since a lot of it are search-engine crawlers and scrapers (and now GPT-based parsers). reply dontlaugh 5 hours agorootparentDon&#x27;t bots now load an entire browser including simulated user interaction, to the point where there&#x27;s no difference? reply janosdebugs 5 hours agorootparentNot for the most part, it&#x27;s still very expensive. Even if, they don&#x27;t simulate mouse movement. reply victorbjorklund 6 hours agoparentprevHard if you run serverless reply dontlaugh 6 hours agorootparentThere&#x27;s still a server somewhere and it can log URLs and IPs. reply victorbjorklund 5 hours agorootparentOf course. But you can&#x27;t access it. You can&#x27;t get logs for static sites on Cloudflare Pages. reply berkes 6 hours agorootparentprevAnd even if there are many servers (a CDN or distributed caching) you can collect and merge these. reply victorbjorklund 5 hours agorootparentTell me how to collect the logs for static sites on Cloudflare Pages (not functions. The Pages sites) reply berkes 4 hours agorootparentCloudflare Pages are running on servers. These servers (can, quite certainly will) have logs.That you cannot access the logs because you don&#x27;t own the servers doesn&#x27;t mean there aren&#x27;t any servers that have logs. reply victorbjorklund 3 hours agorootparentYes, no one has argued that Cloudflare Pages arent using servers. But it is \"hard\" to track using logs if you are a cloudflare customers. Guess only way would be to hack into cloudflare itself and access my logs that way. But that is \"hard\" (because yes theoretically it is possible i know). And not a realistic alternative. reply tmikaeld 6 hours agorootparentprevNot if it&#x27;s static generated html&#x2F;css.And the real benefit of this trick is separating users from bots. reply Spivak 2 hours agorootparentprevHuh? You can get logs just fine from your ALB&#x27;s and API Gateways. reply spiderfarmer 5 hours agoparentprevAll bots reply Wouter33 6 hours agoprevNice implementation! Just a heads-up, hashing the ip like that is still considered tracking under GDPR and requires a privacy banner in the EU. reply openplatypus 6 hours agoparentCorrect. This is a flawed hashing implementation as it allows for re-identification.Having that IP and user timezone you can generate the same hash and trace back the user. This is hardly anonymous hashing.Wide Angle Analytics adds daily, transient salt to each IP hash which is never logged thus generating a truly anonymous hash that prevents reidentification. reply thih9 6 hours agorootparentWhat if my hashing function is really destructive and has high likelihood of collisions? reply hk__2 5 hours agorootparent> What if my hashing function is really destructive and has high likelihood of collisions?If it’s so destructive that it’s impossible to track users, it’s useless for you. If not, you need a privacy banner. reply thih9 5 hours agorootparentA high collision hash would be useful for me on my low traffic page and I’d enjoy not having to display a cookie banner.Also: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38096235 reply victorbjorklund 6 hours agoparentprevProbably should be \"salted hashes might be considered PII\". It has not be tried by the EU court and the law is not 100% clear. It might be. It might not be. reply thih9 6 hours agoparentprevCan you explain why or link a source? I’d like to learn the details. reply fizzbuzz-rs 6 hours agorootparentLikely because the hash of an IP can easily be reversed as there are only ~2^32 IPv4 addresses. reply openplatypus 6 hours agorootparentIt is not just that. Having user IP and such a hashing approach you can re-identify past sessions. reply thih9 6 hours agorootparentprevWhat if my hashing function has high likelihood of collisions? reply firtoz 6 hours agorootparentThen you cannot trust the analytics reply rjmunro 5 hours agorootparentYou can estimate the actual numbers based on the collision rate.Analytics is not about absolute accuracy, it&#x27;s about measuring differences; things like which pages are most popular, did traffic grow when you ran a PR campaign etc. reply thih9 5 hours agorootparentprevDo you trust analytics that doesn’t use JS? Or relies on mobile users to scroll the page before counting a hit?It’s all a heuristic and even with high collision hashing, analytics would provide some additional insight. reply dsies 6 hours agorootparentprevhttps:&#x2F;&#x2F;gdpr-info.eu&#x2F;art-4-gdpr&#x2F; paragraph 1:> ‘personal data’ means any information relating to an identified or identifiable natural person (‘data subject’); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person; reply thih9 6 hours agorootparentThis does not reference hashing, which can be an irreversible and destructive operation. As such, it can remove the “relating” part - i.e. you’ll no longer be able to use the information to relate it to an identifiable natural person.In this context, if I define a hashing function that e.g. sums all ip address octets, what then? reply jvdvegt 6 hours agorootparentA hash (whether MD5 or some SHA) on IP4-address is easily reversed.Summing octets is non-reversable, so it seems like a good &#x27;hash&#x27; to me (but note: you&#x27;ll get a lot of collisions). And of course, IANAL. reply dsies 5 hours agorootparentprevI was answering your request for a source.The linked article talks about identification numbers that can be used to link a person. I am not a lawyer but the article specifically refers to one person.By that logic, if the hash you generate cannot be linked to exactly one, specific person&#x2F;request - you’re in the clear. I think ;) reply e38383 6 hours agoparentprevIf the data gets stored in this way (hash of IP[0]) for a long time I&#x27;m with you. But if you only store the data for 24 hours it might still count as temporary storage and should be \"anonymized\" enough.IMO (and I&#x27;m not a lawyer): if you store ip+site for 24 hours and after that only store \"region\" (maybe country or state) and site this should be GDPR compliant.[0] it should use sha256 or similar and not md5 reply donohoe 4 hours agoparentprevActually no. It’s very likely this is fine. Context is important.Not a layer but discussed this previously with lawyers when building a GDPR framework awhile back. reply sleepyhead 3 hours agorootparentContext is irrelevant. What is relevant is whether a value, for example a hash, can be identified to a specific person in some way. reply p4bl0 6 hours agoprevThe :hover pseudo-class could be applied and unapplied multiple times for a single page load. This can certainly be mitigated using cache related http headers but then if the same page is visited by the same person a second time coming from the same referrer, the analytics endpoint won&#x27;t be loaded.But maybe I&#x27;m not aware that browsers guarantee that \"images\" loaded using url() in CSS will be (re)loaded exactly once per page? reply kevincox 2 hours agoparentI&#x27;m not sure about `url()` in CSS but `` tags are guaranteed to only be loaded once per URL per page. I would assume that `url()` works the same.This bit me when I tried to make a page that reload an image as a form of monitoring. However URL interestingly includes the fragment (after the #) even though it isn&#x27;t set to the server. So I managed to work around this by appending #1, #2, #3... to the image URL.https:&#x2F;&#x2F;gitlab.com&#x2F;kevincox&#x2F;image-monitor&#x2F;-&#x2F;blob&#x2F;e916fcf2f9a... reply freitasm 5 hours agoprev\"The only downside to this method is if there are multiple reads from the same IP address but on separate devices, it will still only be seen as one read. And I&#x27;m okay with that since it constitutes such a minor fragment of traffic.\"Many ISPs are now using CG-NAT so this approach would miscount thousands of visitors seemingly coming from a single IP address. reply tmikaeld 5 hours agoparentOnly if all of them use the exact same user agent platform&#x2F;browser.(It would be better if he used a hash of the raw user agent string) reply rzmmm 5 hours agoprev> Now, when a person hovers their cursor over the page (or scrolls on mobile)...I can imagine many cases where real human user doesn&#x27;t scroll the page on mobile platform. I like the CSS approach but I&#x27;m not sure it&#x27;s better than doing some bot filtering with the server logs. reply victorbjorklund 6 hours agoprevThis does make sense! Might try it for my own analytics solution. Anyone can think of a downside of this vs js? reply berkes 5 hours agoparentI can think of many \"downsides\" but whether those matter or are actually upsides really depends on your use-case and perspective.* You cannot (easily) track interaction events (esp. relevant for SPAs, but also things like \"user highlighted x\" or \"user typed Y, then backspaced then typed Z)\"* You cannot track timings between events (e.g. how long a user is on the page)* You cannot track data such as screen-sizes, agents, etc.* You cannot track errors and exceptions. reply alabhyajindal 6 hours agoprevWow, I didn&#x27;t know you could trigger a URL endpoint with CSS! reply chrismorgan 4 hours agoprevI’d like to see a comparison of the server log information with the hit endpoint information: my feeling is that the reasons for separating it don’t really hold water, and that the initial request server logs could fairly easily be filtered to acceptable quality levels, obviating the subsequent request.The basic server logs include declared bots, undeclared bots pretending to use browsers, undeclared bots actually using browsers, and humans.The hit endpoint logs will exclude almost all declared bots, almost all undeclared bots pretending to use browsers, and some humans, but will retain a few undeclared bots that search for and load subresources, and almost all humans. About undeclared bots that actually use browsers, I’m uncertain as I haven’t inspected how they are typically driven and what their initial mouse cursor state is: if it’s placed within the document it’ll trigger, but if it’s not controlled it’ll probably be outside the document. (Edit: actually, I hadn’t considered that bearblog caps the body element’s width and uses margin, so if the mouse cursor is not in the main column it won’t trigger. My feeling is that this will get rid of almost all undeclared bots using browsers, but significantly undercount users with large screens.)But my experience is that reasonably simple heuristics do a pretty good job of filtering out the bots the hit endpoint also excludes.• Declared bots: the filtration technique can be ported as-is.• Undeclared bots pretending to use browsers: that’s a behavioural matter, but when I did a little probing of this some years ago, I found that a great many of them were using unrealistic user-agent strings, either visibly wonky or impossible or just corresponding to browsers more than a year old (which almost no real users are using). I suspect you could get rid of the vast majority of them reasonably easily, though it might require occasional maintenance (you could do things like estimate the browser’s age based on their current version number and release cadence, with the caveat that it may slowly drift and should be checked every few years) and will certainly exclude a very few humans.• Undeclared bots actually using browsers: this depends on the unknown I declared, whether they position their mice in the document area. But my suspicion is that these simply aren’t worth worrying about because they’re not enough to notably skew things. Actually using browsers is expensive, people avoid it where possible.And on the matter of humans, it’s worth clarifying that the hit endpoint is worse in some ways, and honestly quite risky:• Some humans will use environments that can’t trigger the extra hit request (e.g. text-mode browsers, or using some service that fetches and presents content in a different way);• Some humans will behave in ways that don’t trigger the extra hit request (e.g. keyboard-only with no mouse movement, or loading then going offline);• Some humans will block the extra hit request; and if you upset the wrong people or potentially even become too popular, it’ll make its way into a popular content blocker list and significant fractions of your human base will block it. This, in my opinion, is the biggest risk.• There’s also the risk that at some point browsers might prefetch such resources to minimise the privacy leak. (Some email clients have done this at times, and browsers have wrestled from time to time with related privacy leaks, which have led to the hobbling of what properties :visited can affect, and other mitigations of clickjacking. I think it conceivable that such a thing could be changed, though I doubt it will happen and there would be plenty of notice if it ever did.)But there’s a deeper question to it: if you don’t exclude some bots; or if the URL pattern gets on a popular content filter list: does it matter? Does it skew the ratios of your results significantly? (Absolute numbers have never been particularly meaningful or comparable between services or sources: you can only meaningfully compare numbers from within a source.) My feeling is that after filtering out most of the bots in fairly straightforward ways, the data that remains is likely to be of similar enough quality to the hit endpoint technique: both will be overcounting in some areas and undercounting in others, but I expect both to be Good Enough, at which point I prefer the simplicity of not having a separate endpoint.(I think I’ve presented a fairly balanced view of the facts and the risks of both approaches, and invite correction in any point. Understand also that I’ve never tried doing this kind of analysis in any detail, and what examination and such I have done was almost all 5–8 years ago, so there’s a distinct possibility that my feelings are just way off base.) reply meiraleal 5 hours agoprevInteresting approach but what about mobile users? reply welpo 2 hours agoparentFrom the article:> Now, when a person hovers their cursor over the page (or scrolls on mobile) it triggers body:hover which calls the URL for the post hit reply cantSpellSober 2 hours agorootparentIt doesn&#x27;t do that though.> The :hover pseudo-class is problematic on touchscreens. Depending on the browser, the :hover pseudo-class might never matchhttps:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;CSS&#x2F;:hoverDon&#x27;t take my word for it. Trying it in mobile emulators will have the same result. reply colesantiago 5 hours agoprevHow would one block this from tracking you?I think we would either need to send fake data to these analytics tools deliberately like https:&#x2F;&#x2F;adnauseam.io&#x2F;Or now include CSS as a spy tracker that needs to be blocked. reply its-summertime 3 hours agoparentnext [–]||&#x2F;hit&#x2F;*$imageIn your favorite ad blocker reply Kiro 5 hours agoparentprevI don&#x27;t see how this is more intrusive for privacy than what you can already get from access logs. reply matrss 50 minutes agorootparentIf it is not then it must be unnecessary, since you could get the same information from the access logs already. reply colesantiago 5 hours agorootparentprevIt is still tracking you so it needs to be blocked. reply Kiro 4 hours agorootparentSo are access logs. How are you going to block those? reply colesantiago 4 hours agorootparentI never said anything about access logs, I specifically mentioned this CSS trick that will become popular for ad companies to track people.For this, this would need to block the endpoint or send obfuscated data deliberately in protest of this.Should you want to cover access logs also, then forms of tracking then sending excessive, random obfuscation data with adnauseam would also help here.https:&#x2F;&#x2F;adnauseam.io&#x2F; reply jokethrowaway 2 hours agorootparentprevI sure hope you&#x27;re being sarcastic here and illustrating the ridiculousness of privacy extremists (who, btw, ruined the web, thanks to a few idiot politicians in the EU).If not, what&#x27;s wrong with a service knowing you&#x27;re accessing it? How can they serve a page without knowing you&#x27;re getting a page? reply colesantiago 3 hours agoprevIf you want to send obfuscated data on purpose to prevent this dark pattern behaviour from spreading I recommend Adnauseam.(not the creator, just a regular user of this great tool)We need more tools that send random, fake data to analytics providers which renders the analytics useless to them in protest of tracking.If there are any more like Adnauseam, I would love to know.https:&#x2F;&#x2F;adnauseam.io&#x2F; reply jokethrowaway 4 hours agoprevLovely technique and probably more than adequate for most uses.My scraping bots use an instance of chrome and therefore trigger hover as well, but you&#x27;ll cut out the less sophisticated bots.This is because of protection systems, if I try to scrape my target website with just code I just get insta banned &#x2F; \"captched\". reply user20231101 6 hours agoprev [–] Smart approach! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Herman's Bear Blog has created a unique analytics system that tracks user engagement while maintaining strict privacy standards and without the use of client-side Javascript.",
      "This new method uses CSS instead of server logs or conventional analytics tools, which can often be blocked by ad-blockers. It tracks user engagement when the cursor hovers over the page, triggering a URL for the post viewed.",
      "The system ensures user privacy by hashing the IP address with the date for a unique 'read' count of a page, without storing any identifying information. They only temporarily store IP addresses."
    ],
    "commentSummary": [
      "Hashed IP addresses are under scrutiny in online discussions due to their reversible nature, despite using secure algorithms, compelling attention to the European Union’s data protection agency's view that hashing doesn't truly anonymize data.",
      "Suggested practices for enhanced security include salting hashes, generating a universally unique identifier independently, and employing a temporary or secret salt.",
      "Debates on the necessity of data collection for boosting revenue and user experience have gained traction, while concerns include GDPR compliance, user privacy, refining content, and the storage and partitioning of data."
    ],
    "points": 184,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1698826089
  },
  {
    "id": 38093353,
    "title": "Distil-Whisper: distilled version of Whisper that is 6 times faster, 49% smaller",
    "originLink": "https://github.com/huggingface/distil-whisper",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up huggingface / distil-whisper Public Notifications Fork 10 Star 565 Code Issues 3 Pull requests Actions Projects Security Insights huggingface/distil-whisper main 1 branch 0 tags Go to file Code Latest commit sanchit-gandhi Update README.md 8ff6923 Git stats 18 commits Files Type Name Latest commit message Commit time Distil_Whisper.pdf Update paper README.md Update README.md README.md Distil-Whisper [Paper] [Models] [wandb] Distil-Whisper is a distilled version of Whisper that is 6 times faster, 49% smaller, and performs within 1% WER on out-of-distribution evaluation sets. Model Link distil-medium.en To be published on November 2nd distil-large-v2 To be published on November 2nd 1. Usage 👨💻 The Distil-Whisper checkpoints will be released on November 2nd with a direct 🤗 Transformers integration. Instructions for running inference will be provided here: from transformers import WhisperForConditionalGeneration ... 2. Why use Distil-Whisper? ⁉ Distil-Whisper is designed to be a drop-in replacement for Whisper on English speech recognition. Here are 4 reasons for making the switch to Distil-Whisper: Faster inference: 6 times faster inference speed, while performing to within 1% WER of Whisper on out-of-distribution audio: Robustness to noise: demonstrated by strong WER performance at low signal-to-noise ratios: Robustness to hallucinations: quantified by 1.3 times fewer repeated 5-gram word duplicates (5-Dup.) and 2.1% lower insertion error rate (IER) than Whisper: Designed for speculative decoding: Distil-Whisper can be used as an assistant model to Whisper, giving 2 times faster inference speed while mathematically ensuring the same outputs as the Whisper model. 3. Approach ✍ To distill Whisper, we copy the entire encoder module and freeze it during training. We copy only two decoder layers, which are initialised from the first and last decoder layers from Whisper. All other decoder layers from Whisper are discarded. Distil-Whisper is trained on a knowledge distillation objective. Specifically, it is trained to minimise the KL divergence between the distilled model and the Whisper model, as well as the cross-entropy loss on pseudo-labelled audio data. We train Distil-Whisper on a total of 22k hours of pseudo-labelled audio data, spanning 10 domains with over 18k speakers: This diverse audio dataset is paramount to ensuring robustness of Distil-Whisper to different datasets and domains. In addition, we use a WER filter to discard pseudo-labels where Whisper mis-transcribes or hallucinates. This greatly improves WER performance of the downstream distilled model. For full details on the distillation set-up and evaluation results, refer to the Distil-Whisper paper. 4. Acknowledgements OpenAI for the original Whisper model and codebase Google's TPU Research Cloud (TRC) programme for Cloud TPU v4s About No description or website provided. Topics audio speech-recognition whisper Resources Readme Activity Stars 565 stars Watchers 40 watching Forks 10 forks Report repository Releases No releases published Packages No packages published Contributors 4 sanchit-gandhi Sanchit Gandhi patrickvonplaten Patrick von Platen IbrahimAmin1 Ibrahim Amin amrrs amrrs Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=38093353",
    "commentBody": "Distil-Whisper: distilled version of Whisper that is 6 times faster, 49% smallerHacker NewspastloginDistil-Whisper: distilled version of Whisper that is 6 times faster, 49% smaller (github.com/huggingface) 178 points by omarfarooq 14 hours ago| hidepastfavorite52 comments FL33TW00D 4 hours agoSuper exciting! I&#x27;ll be shipping Distil-Whisper to whisper-turbo tomorrow! https:&#x2F;&#x2F;github.com&#x2F;FL33TW00D&#x2F;whisper-turboShould make running in the browser feasible even for underpowered devices: https:&#x2F;&#x2F;whisper-turbo.com&#x2F; reply kkielhofner 4 hours agoparentI have the same plans for ctranslate2[0] and Willow Inference Server[1]![0] - https:&#x2F;&#x2F;github.com&#x2F;OpenNMT&#x2F;CTranslate2[1] - https:&#x2F;&#x2F;heywillow.io&#x2F;components&#x2F;willow-inference-server&#x2F; reply asplake 7 hours agoprevIt’s a shame that the README doesn’t link to the original Whisper, or at least not prominently. There’s the etiquette, but also I still don’t really know what this does. reply refulgentis 4 hours agoparentThe AI ethos is more academic and open in general, that&#x27;s why stuff like this, and not linking directly to what they forked aren&#x27;t faux pas in the that community but raise eyebrows here.It does speech recognition reply szszrk 3 hours agorootparentWow, you managed to squesse what&#x27;s missing in the whole readme in just 4 words. Thanks. reply naveen99 1 hour agorootparentYeah, the readme just says “ASR”. Apparently that means automatic speech recognition.I guess it could be worse. In the future our ai overlords will just talk in embeddings (not even abbreviations), and we will have no clue what they are talking to each other about. reply nwoli 4 hours agoparentprevThe paper mentions it, I don’t think this is an etiquette error reply yjftsjthsd-h 37 minutes agoprevOn a partially-related note, has anyone packaged any version of whisper as an Android keyboard? It seems like a reasonably good fit, and I would be interested to see if it worked better than the deteriorating quality of Google&#x27;s offering. I think it would work even with the existing versions, but a faster+smaller version would obviously be a better fit for running on phone hardware. reply jankovicsandras 5 hours agoprevI&#x27;m using this: https:&#x2F;&#x2F;github.com&#x2F;guillaumekln&#x2F;faster-whisper Smaller, faster, works well with CPU, multiple languages, etc. reply regularfry 5 hours agoparentThat&#x27;s just using the original model with a faster runtime. It&#x27;s limited by the model itself, as is ggerganov&#x2F;whisper.cpp. This changes the model. reply asylteltine 2 hours agorootparentSo it is possible to combine that with distil for extra speed? reply kkielhofner 2 hours agorootparentI&#x27;m the founder of Willow[0] (we use ctranslate2 as well) and I will be looking at this as soon tomorrow as these models are released. HF claims they&#x27;re drop-in compatible but we won&#x27;t know for sure until someone looks at it.[0] - https:&#x2F;&#x2F;heywillow.io&#x2F; reply rjwilmsi 1 hour agorootparentprevThat&#x27;s the implication. If the distil models are same format as original openai models then the Distil models can be converted for faster-whisper use as per the conversion instructions on https:&#x2F;&#x2F;github.com&#x2F;guillaumekln&#x2F;faster-whisper&#x2F;So then we&#x27;ll see whether we get the 6x model speedup on top of the stated 4x faster-whisper code speedup, at same&#x2F;nearly same accuracy.I would generally start with the assumption that if something is significantly faster the accuracy has to suffer a bit, but increasing model size and&#x2F;or settings such as beam size to compensate should allow same accuracy and higher performance (just not all of the stated performance gain). reply srush 1 hour agorootparentprevYup, should work nicely together. reply worldsavior 5 hours agoparentprevIf it&#x27;s faster, why openai doesn&#x27;t implement it? reply MacsHeadroom 1 hour agorootparentBecause OpenAI focuses on putting out quality models. Efficient execution of ML models is another skill set entirely. Projects like CTranslate2 (which is what faster-whisper uses) are focused on fast model execution and work across all kinds of models from speech recognition to image and speech generation and everything in between. reply spandextwins 3 hours agoprevNice! But next time do the press release when the product is released. Really tired of sites like HN pushing these stories out without any code or files Feels like vaporware. reply cjdell 4 hours agoprevI wonder if fast enough for wakeword detection in WASM. Picovoice worked extremely well for this but it&#x27;s proprietary. reply kkielhofner 2 hours agoparentThere&#x27;s also OpenWakeWord[0]. The models are readily available in tflite and ONNX formats and are impressively \"light\" in terms of compute requirements and performance.It should be possible.[0] - https:&#x2F;&#x2F;github.com&#x2F;dscripka&#x2F;openWakeWord reply srush 1 hour agoparentprevThe model targets the decoder part of the system which is the speed bottleneck. So for tasks like classification it is not likely to be helpful. However a similar method could be used for that use case. (Coauthor) reply regularfry 2 hours agoparentprevIt&#x27;s probably still too big to be helpful with these model sizes, but if someone helpful runs the same training on `small.en` (and smaller) we might have something.Yes, this is me praying to the benevolent HN gods that someone will pick this up and run with it. I don&#x27;t have a GPU anywhere close to capable... reply FL33TW00D 1 hour agorootparentYou&#x27;d be surprised how capable old GPUs are! I&#x27;ve had great success with people running Whisper-Turbo in the browser on really old hardware: https:&#x2F;&#x2F;whisper-turbo.com&#x2F; reply kkielhofner 1 hour agorootparentWe have benchmarks[0] for Willow Inference Server using Whisper + ctranslate2 + some of our own optimizations.TLD a six year old ~$100 used GTX 1070 is roughly 5x faster than a Threadripper PRO 5955WX at a fraction of the cost and power.[0] - https:&#x2F;&#x2F;heywillow.io&#x2F;components&#x2F;willow-inference-server&#x2F;#ben... reply regularfry 1 hour agorootparentprevIt&#x27;s not the inference, it&#x27;s the training. They say in the paper: \"We train with a batch size of 256 for a total of 80,000 optimisation steps, which amounts to eight epochs of training.\" That&#x27;s a fair chunk of time. Mind you, `small.en` has smaller decoder layers than `medium.en`... reply pkoird 1 hour agoprevHave not read the paper yet but why do they only cut the decoder and not the encoder? reply srush 1 hour agoparentWhen distilling models for speed, you get a better win from removing decoder parameters, since they are run in serial, than encoder parameters. For example see this work https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2006.10369- paper co-author reply regularfry 1 hour agoparentprevThey don&#x27;t justify it explicitly, but they do talk about using the distilled model as an assistant for the original. With the encoder precisely the same for both you only need to additionally load the distilled decoder layers for a 2x speedup with the same accuracy as the original. reply regularfry 4 hours agoprevFunnily enough, `-small`, `-base` and `-tiny` versions of this would be more exciting to me. `small.en` is the largest of the original whisper models that will run anywhere near usable speed on a raspberry pi zero 2 with whisper.cpp, and it&#x27;s still too slow to really bother with for streaming. Anything smaller is too inaccurate for day to day use. If there was a distilled version which had a similar 6x speedup, that would be transformative. reply abecedarius 3 hours agoparentAnother important use is low-latency transcription on a phone, for hard-of-hearing people like me. I&#x27;ve been tempted lately to buy a beefier phone. reply rjwilmsi 4 hours agoparentprevI understand that, though I think significant speedups can be useful at multiple levels. So for me for example I am using either the base or small model on beam size of 1 with faster-whisper for real-time dictation on a laptop CPU (Rzyen 4500U). The recognition time is just that bit too high when using a larger beam size or is much too high when using the medium model. So if these models offer a decent speed up it means I can either increase beam size or go up a model size which will lead to good improvement in accuracy I think - With real-time dictation I find that small errors are quite annoying to deal with so any improvement in accuracy is really useful.At a larger level, say an exercise to transcribe a back catalogue of audio might need a $1000 GPU with the current model speeds to get the job done in a reasonable time. With models that run 6x faster it might be that a $200 GPU is sufficient. That could be quite a significant saving for a small company or charity etc. reply regularfry 2 hours agorootparentOh yes, that&#x27;s absolutely true - faster is better for everyone. It&#x27;s just that this particular breakpoint would put realtime transcription on a $17 device with an amazing support ecosystem. It&#x27;s wild.That being said, even with this distillation there&#x27;s still the aspect that Whisper isn&#x27;t really designed for streaming. It&#x27;s fairly simplistic and always deals with 30 second windows. I was expecting there to have been some sort of useful transform you could do to the model to avoid quite so much reprocessing per frame, but other than https:&#x2F;&#x2F;github.com&#x2F;mit-han-lab&#x2F;streaming-llm (which I&#x27;m not even sure directly helps) I haven&#x27;t noticed anything out there. reply mkl 6 hours agoprev> performs within 1% WERFrom the paper, for short-form audio:> the distil-large-v2 model achieves the lowest overall average WER of 10.1%. It is one percentage point higher than the large-v2 baseline, with 5.8 times faster inference speed and fewer than half the parameters.Long-form is similar, except Distil-Whisper does slightly better than Whisper (fewer hallucinations, apparently).10% WER seems awfully high, and doesn&#x27;t match my experience with Whisper. Maybe my audio is nice and clean relative to their test set? reply smallerfish 31 minutes agoparentWER is a pretty strict metric. IIRC it can penalize missing repeats, disfluencies, and the like that an ASR model may reasonably decide to drop. Additionally it will penalize for incorrect pluralization, unique proper nouns that aren&#x27;t in the model, etc. 10% is still very readable.I built a tool in the mid-201Xs on an ASR engine with 20%+ WER, and even that was good enough for what we were trying to do. reply rjwilmsi 4 hours agoparentprevI agree. When using the small or medium en models either for real-time speech recognition of a native English speaker or for transcribing podcasts of native English speakers the error rate is nowhere near 10%. I might say it&#x27;s something like 1% of which the majority of errors are possibly subjective decisions about punctuation. But I have found the error rates are much higher on the tiny model and higher on the base model.I assume therefore that the 10% word error rate is on very difficult audio such as pilots speaking to Air Traffic Control (distorted or clipped microphones with significant background noise), which I personally find can be difficult to 100% understand even though I&#x27;m a native English speaker and when both pilots and air traffic control are native English speakers. reply GaggiX 6 hours agoparentprevReading the paper the table is showing performance on out-of-ditribution test sets. reply refulgentis 4 hours agorootparentI see: what does that mean, exactly? :) if it means \"data they dont usually test on\", 10% does still sound pretty high reply rjwilmsi 1 hour agorootparentYes, it&#x27;s not that clear to me either what test sets get a 10% error rate. Because in my use (native English dictation or native English podcast transcription) the small or medium original whisper models have what I&#x27;ll call a \"discrepancy\" rate of say 1-2% which is mostly punctuation and \"umms&#x2F;errs\" inclusion or not. The actual \"error\" rate is below 1% in my experience, and excluding surnames, brands and place names that I don&#x27;t know how to spell either the remaining errors tend to be minor (missed plural etc.).So I infer that these data sets are some deliberately difficult audio: call centre recordings with lots of background noise, phoneline quality audio etc. Maybe non-native speakers. If I only heard that sort of audio once I also might have an error rate of 10%. reply zaptrem 8 hours agoprevHow much faster in real wall-clock time is this in batched data than https:&#x2F;&#x2F;github.com&#x2F;m-bain&#x2F;whisperX ? reply Zetobal 6 hours agoparentmaybe 2-3x? faster-whisper says it&#x27;s 2x faster than whisper. reply VadimPR 3 hours agoprevDoes anyone know if it is possible to fine-tune the whisper models to add new words? Say, brand names it doesn&#x27;t yet know about? reply azeirah 3 hours agoparentYou shouldn&#x27;t need to fine-tune it at all. Whisper supports adding prompts -- not to be confused with GPT-style prompts -- these prompts let you specify the \"style\" of output the model should give. So if you&#x27;re giving input that is somewhat ambiguous or has strange spellings of common pronunciations, you can do that via the prompt.You say \"I really like Jason\". But, your audience is developers:prompt=json\"I really like Jason\" => \"I really like JSON\"The docs give some more detail about how to structure the prompts and has examples about what does and doesn&#x27;t work, it&#x27;s meant for this exact purpose. reply coder543 1 hour agorootparentMy experience is that what you&#x27;re describing is only initial_prompt, and it only affects the first 30-second transcription window of the audio in question.It&#x27;s effectively useless for helping the model transcribe new words in longer content. That also wouldn&#x27;t be a long-term solution anyways... no one wants to compile a huge list of \"words Whisper probably doesn&#x27;t know\" and have to pass those in every time the model is being used. Even if that worked, it would also distort the transcription, since you&#x27;re not saying you know which words are in the actual speech, you&#x27;re just passing in a list of words. So, you could end up influencing Whisper to choose the wrong words, giving priority to this list of random words being passed in.I am similarly curious about how we can train Whisper models to learn new words over time, unless OpenAI plans to release updated models themselves. reply regularfry 1 hour agorootparentWould attention sinks work here? https:&#x2F;&#x2F;github.com&#x2F;mit-han-lab&#x2F;streaming-llm - it sounds like they might. In theory it doesn&#x27;t involve retraining, it&#x27;s just a change to how the data is managed between invocations. reply GaggiX 5 hours agoprevIt seems they have only distilled on English data, so the distil-large-v2 model will probably perform badly with any other language, we&#x27;ll see tomorrow when they are going to release their models. reply api 3 hours agoprevIs there a good project out there that pairs whisper with something like llama.cpp to create a private local voice assistant?Llama2 isn&#x27;t as good as GPT-4 but it&#x27;s a hell of a lot smarter at Q&A than Siri or Alexa or any of those things.PSA: I will pay for such a thing if it&#x27;s really good, privacy respecting, local-first, and preferably at least source available. reply gpderetta 2 hours agoparentI literally played with cat&#x27;ing the output of one into the input of the other and it worked better than I had any reason to expect.edit: in my 30minutes of playing with it, I didn&#x27;t find a good sounding open-source text-to-speech model for the final stage of the pipeline. reply cooper_ganglia 1 hour agorootparentIt’s not open-source, but Play.HT has a new “Turbo model” that can begin generating text-to-speech within 150ms. I’ve tried it out, and it’s pretty impressive in terms of both quality and speed. There’s an API, so perhaps that would be worth looking into! reply regularfry 1 hour agorootparentprevThis lack of a decent open text to speech is really frustrating, because some of the closed ones are just scary good. reply regularfry 2 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;whisper.cpp&#x2F;tree&#x2F;master&#x2F;example... is worth a poke. llama.cpp supports llama2 on CPU. reply Ono-Sendai 2 hours agoparentprevI have something pretty rudimentary here: https:&#x2F;&#x2F;github.com&#x2F;Ono-Sendai&#x2F;project-2501 Whisper.cpp + chatGPT + windows text-to-speech. reply siva7 7 hours agoprev [–] Hm isn&#x27;t this problematic from a trademark pov? reply refulgentis 4 hours agoparent [–] Nah, Whisper isnt trademarked. The AI ethos is more academic and open in general, that&#x27;s why stuff like this, and not linking directly to what they forked aren&#x27;t faux pas in the that community but raise eyebrows here. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hugging Face has introduced Distil-Whisper, an optimized version of OpenAI's English speech recognition system called Whisper.",
      "The improved model is six times quicker, 49% smaller but performs with almost identical accuracy within 1% WER (Word Error Rate) on unfamiliar evaluation datasets. It also enhances tolerance to noise and hallucinations, effectively reducing error rates.",
      "Distil-Whisper will be released on November 2nd and is accompanied by guidelines for activating its inference feature and incorporating it with the Hugging Face's Transformers library. The system was fine-tuned using 22,000 hours of pseudo-labelled audio data from over 18,000 speakers across 10 domains."
    ],
    "commentSummary": [
      "OpenAI has released a more efficient version of their AI speech recognition tool, Whisper, called Distil-Whisper. It is six times faster and 49% smaller, making it suitable for power-limited devices and web browsers.",
      "Distil-Whisper has an error rate of 1-2% for English transcription, mainly due to issues with punctuation and filler words.",
      "Some users are seeking to fine-tune this model and potentially integrate it with other tools for creating private voice assistants."
    ],
    "points": 177,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1698800141
  },
  {
    "id": 38088856,
    "title": "Upstream Linux support available for Qualcomm Snapdragon 8 Gen 3 Mobile Platform",
    "originLink": "https://www.linaro.org/blog/upstream-linux-support-now-available-for-the-the-qualcomm-snapdragon-8-gen-3-mobile-platform/",
    "originBody": "Linaro Forge (current) Connect (current) CodeLinaro (current) (current) (current) (current) (current) Working Groups Services Resources Support About Upstream Linux support now available for the the Qualcomm Snapdragon 8 Gen 3 Mobile Platform Neil ArmstrongThursday, October 26, 20234 mins read Linux Kernel Qualcomm Snapdragon At Linaro, we’re thrilled to share the latest development in our ongoing collaboration with Qualcomm. Linaro Engineer Neil Armstrong has successfully enabled upstream Linux support for the Qualcomm Snapdragon 8 Gen 3 Mobile Platform, the latest addition to the Snapdragon processor family. This achievement signifies a significant milestone in the realm of Linux support, as it demonstrates our commitment to providing cutting-edge solutions to our partners. Here an inside look at this groundbreaking development, showcasing the unparalleled collaboration between Qualcomm and Linaro, impacting positively on: Effortless upstream Linux integration Powerful performance optimization Running AOSP with Mainline Continued collaboration The Qualcomm Announcement The initial support was posted on October 25th 2023 on the Linux kernel mailing lists for review by the Linux developers community. With the set of patches released by Linaro engineers, it is also possible to boot an AOSP image with Graphics Software Rendering using Google’s SwiftShader. Since 2014, Linaro Engineers have been working closely with Qualcomm Engineers to enable Snapdragon platforms to work with Mainline Linux. Running a recent upstream Linux kernel immediately after the announcement of a new SoC is a significant achievement, and is a testimony to the close working partnership between Qualcomm and Linaro. What has been upstreamed for the Snapdragon 8 Gen 3 Mobile Platform? With the recent series of patches released by Linaro, the following features are enabled for the Snapdragon 8 Gen 3 Mobile Platform: Qualcomm® Kryo™ CPUs, including DVFS (Dynamic voltage and frequency scaling) and Power Management System foundation: Clocks, Power controllers, PMICs Low-Speed I/O: I2C, SPI, RTC, Buttons, LEDs High-Density Storage: UFS 4.0, SDXC High-Speed Peripherals: PCIe Gen3 and Gen4, USB Version 3.1 Gen 2, USB-C PD Qualcomm® Hexagon™ Processor SubSystems: Audio, Sensors, Compute and Modem Mobile Display Subsystem + DSI Engine, Touch Controller Communication: WCN7850 Bluetooth All patches sent for review are also integrated and available in the following development branch on CodeLinaro.org. Qualcomm Snapdragon 8 Gen 3 Running Android 14 How do I run AOSP using Mainline? One might think it is quite hard to run AOSP with mainline on such a new platform, but in reality, not at all! Thanks to the long term effort of Linaro and Google engineers making it possible to run AOSP with vanilla Linux releases. Thanks to Amit Pundir for providing a helping hand to get AOSP on this platform. To generate an AOSP image for the Snapdragon 8 Gen 3 Qualcomm Reference Device using the current set of patches available on the mailing list, use the following instructions, which are derived from here https://source.android.com/docs/setup/build/devices with some small changes. Download the Android source tree: $ mkdir AOSP $ cd AOSP $ AOSP=$PWD $ repo init -u https://android.googlesource.com/platform/manifest -b master $ repo sync -j`nproc` Prepare SM8650 device config by pulling this pathset: $ cd device/linaro/dragonboard $ git fetch https://git.codelinaro.org/linaro/qcomlt/demos/device_linaro_dragonboard.git \\topic/sm8650/demo/android-14-20231016 && git checkout FETCH_HEAD Build the Linaro SM8550 tree containing the patches sent for review: $ cd $AOSP $ git clone https://git.codelinaro.org/linaro/qcomlt/demos/linux.git \\ -b topic/sm8650/demo/aosp-next-20231016 sm8650-kernel $ cd sm8650-kernel $ make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- \\ rbX_aosp_defconfig $ make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- -j`nproc` $ mkdir $AOSP/device/linaro/dragonboard-kernel/android-6.6/ $ cp arch/arm64/boot/Image.gz arch/arm64/boot/dts/qcom/sm8650-qrd.dtb \\ $AOSP/device/linaro/dragonboard-kernel/android-6.6/ $ find ./ -name \"*.ko\" -exec cp {} $AOSP/device/linaro/dragonboard-kernel/android-6.6/ \\; Build AOSP $ cd $AOSP $ . build/envsetup.sh $ lunch qrd8650-userdebug $ make -j`nproc` Flash AOSP Images $ cd out/target/product/qrd8650/ $ fastboot erase super erase boot erase vendor_boot \\ erase userdata erase metadata erase dtbo erase recovery $ fastboot flash -S 256M super ./super.img flash boot ./boot.img \\ flash vendor_boot ./vendor_boot.img format:ext4 metadata \\ flash userdata ./userdata.img reboot Next steps In the coming weeks, Linaro engineers will continue to work with the Linux kernel community to ensure all the patch series are merged in a timely manner. Additional patches are expected soon to enable display, audio and modem use cases. Want to learn more ? To find out more information on the ongoing work, check https://lore.kernel.org/all/?q=SM8650 or contact us. The Snapdragon 8 Gen 3 Specification & features can be found Here For more information about what Qualcomm platform services Linaro offers and how we can help develop, maintain and optimize products using Qualcomm technologies, go to https://www.linaro.org/services/qualcomm-platforms-services/. Recent Posts Upstream Linux support now available for the the Qualcomm Snapdragon 8 Gen 3 Mobile Platform Thu Oct 26 2023 Effortless upstream Linux integration, powerful performance optimization, running AOSP with Mainline and last but not least continued collaboration WindowsPerf Release 3.0.0 Mon Oct 23 2023 We are happy to announce the latest WindowsPerf release version 3.0.0. This major release is a continuation of WindowsPerf development. It combines updates from release 2.5.1 and adds new features that were missed previously. Tracking code size variations between LLVM releases Wed Oct 18 2023 In this blog post, we talk about tracking the size of LLVM generated code and look at the results on the latest releases. UEFI HTTP and HTTPs Boot in U-Boot Mon Oct 16 2023 UEFI HTTP boot simplifies the network boot process by allowing the firmware to retrieve operating system images and EFI executables directly from an HTTP server. This eliminates the need for unsecure protocols like TFTP (Trivial File Transfer Protocol) and enables mass deployment using public networks. Let’s go through the current U-Boot status and roadmap. Improvements to GCC’s code-gen for vector initialization on AArch64 Mon Oct 09 2023 The blog post is about Linaro TCWG's improvements to code-gen in GCC for NEON vector initialization on AArch64 target. The post details a few examples of the improvements, and the rationale behind them. Other Posts The Challenges of Abstracting Virtio Tue Nov 15 2022 In this blog we talk about the challenges of abstracting Virtio. Read the blog to find out more. Arm Transfers CMSIS-Pack Technology to Linaro Wed Jun 02 2021 In this article, Francois Ozog looks at the CMSIS-Pack Technology which has been trasnfered from Arm to Linaro. Read here about the goals of the project. Linaro contributions to the Linux Kernel 5.16 Release Tue Jan 18 2022 In this blog, we asked the Linaro developers to talk about the contributions and impact they made to the Linux kernel 5.16 release. Read about the release here. Python and Go in the Arm World Tue Dec 17 2019 In this article, Siddhesh Poyarekar takes a detailed look at Python and Go in the Arm World. Read about his findings here! Linaro reference devboards boot Android 14 on the day of its release Thu Oct 05 2023 Android14 boots on Linaro reference devboards on the day of its release Sign up for the Linaro Insights Newsletter Automotive, IoT & Edge Devices Cloud Computing & Servers Client Devices Core Technologies Artificial Intelligence Linux Kernel Security Testing & CI Toolchain Virtualization Projects Membership Services Support Downloads about Blogs Events News Careers Go to Twitter profile Go to Facebook Page Go to LinkedIn profile Go to instagram social media page Go to YouTube channel Go to GitHub Page Edit on GitHubReport an IssueLegalCookiesContactSitemap Copyright © 2023 Linaro Limited en • ch Cookies & Privacy Policy Enabling cookies allows you to use our website to its full extent and to personalize your experience on our sites. They tell us which parts of our websites people have visited, help us measure the effectiveness of ads and web searches and give us insights into user behavior so we can improve our communications with you. Cookies Policy - Privacy Policy Accept All CookiesCustomise Cookies",
    "commentLink": "https://news.ycombinator.com/item?id=38088856",
    "commentBody": "Upstream Linux support available for Qualcomm Snapdragon 8 Gen 3 Mobile PlatformHacker NewspastloginUpstream Linux support available for Qualcomm Snapdragon 8 Gen 3 Mobile Platform (linaro.org) 171 points by fsflover 21 hours ago| hidepastfavorite87 comments bfrog 20 hours agoWith or without binary blobs and undocumented registers&#x2F;IPs? reply aseipp 18 hours agoparentThe kernel will work fine, but at minimum EL2 runs the Qualcomm Hypervisor (Gunyah) which prevents native KVM virtualization from taking place. This is true of all Snapdragon platforms.Windows supports virtualization on the 8 Gen 3 only because they use a custom setup to load a signed binary blob (\"applet\") into the EL2 hypervisor, whose signature it is is hardcoded to accept, and that blob&#x2F;applet then can be used by Windows as a kind of shim into EL2-land to spawn VMs, etc. But Qualcomm&#x27;s hypervisor is always present and enforcing its security policy.In practice every single modern system is running tons of binary firmware blobs, it&#x27;s mostly where you draw the line on functionality and isolation of components (security, integrity, availability.) Here, Qualcomm does intentionally reduce some functionality, which is pretty bad when you consider that the UEFI spec for ARM mandates EL2 handover, I think, and they just ignore it. reply kramerger 8 hours agorootparentMy experience from working a few years with qualcomm CPUs at a major home electronics brand:1. Half of the EL3 and EL2 code is so old, it has to jump between aarch32 and aarch64 multiple times during the boot process.2. The silicon is full of errors. There are also major security vulnerabilities due to Qualcomm doing their own slightly modified version of everything.3. Not even their biggest customers (e.g. Samsung) is given the source code for the magical blobs used during boot.4. Given these issues, the EL2 code is basically there to hold things together. It will never go away and they will never show you what it contains reply thomastjeffery 17 hours agorootparentprev> In practice every single modern system is running tons of binary firmware blobsThis is a problem we should be loud critics of. Proprietary firmware hurts us all, and practically benefits no one. reply matheusmoreira 13 hours agorootparentYeah. These days our operating systems don&#x27;t actually operate the system anymore. Hardware manufacturers usurped our control of the machine. They think of Linux as the \"user OS\", to be virtualized and sandboxed away from the real computer.https:&#x2F;&#x2F;youtu.be&#x2F;36myc8wQhLo reply gary_0 11 hours agorootparentOnly a secret and privileged few actually get to boot and talk to a modern physical CPU. The rest of us only get to run on top of an abstraction.Wake up, Neo. The Matrix has you... reply StillBored 9 hours agorootparentprevAnd frankly that is as it should be. The OS has enough responsibility trying to arbitrate the collection of hardware resources while providing its own set of abstractions (filesystems, processes, etc) to the application layers.These computers are no longer simple cores with simple devices. If you want that go buy a DOS machine from the 1980&#x27;s, or a arm7TDMI.The problem though is that companies invest in all this firmware, and become convinced that DIMM training, signal integrity&#x2F;phy training, and algorithms which estimate the cooling capacity and thermal mass of the attached heatsink, or any of a hundred other things are somehow competitive advantages and deserve to be locked up behind closed doors rather than opensource. In some cases they are right, but that shouldn&#x27;t keep them from publishing reference firmware sources and register documentation.So, really people complaining about proprietary firmware are sorta missing the point. Complain about the lack of documentation to create your own firmware, not that the company thinks they have a competitive advantage in that firmware.And also admit that what one needs is hardware&#x2F;firmware abstractions that allow big kernels like linux to communicate with all the little cores in the machine working on specific tasks, be that NVMe for disks, AT command sets for modems, or ACPI for power management. reply 127361 4 hours agorootparentNot on Rockchip platforms as far as I am aware. The RK3588 is one of their highest performing SoCs, it has 4 Cortex-A76 cores running 2.4GHz thus making it somewhat close to desktop performance, without any of these blobs or locked down bootloaders. And mostly complete documentation[1] is available.1. https:&#x2F;&#x2F;github.com&#x2F;FanX-Tek&#x2F;rk3588-TRM-and-Datasheet&#x2F;tree&#x2F;ma... reply matheusmoreira 9 hours agorootparentprevWhat good is open source firmware when the hardware only accepts cryptographically signed proprietary blobs? reply fsflover 17 hours agorootparentprevIt&#x27;s a bit better in Pinephone: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36659544 reply asddubs 17 hours agorootparentprevWhat&#x27;s EL2 exactly? reply Avery3R 17 hours agorootparentException Level 2 [1] They&#x27;re analogous to \"protection rings\" on x86. Generally, EL0 is usermode, EL1 is kernel mode, EL2 is hypervisor, and EL3 is the \"secure monitor\"&#x2F;firmware code, closest analogy I think would be SMM on x86. On top of all of that there&#x27;s also trustzone with its own EL0 and EL1.1: https:&#x2F;&#x2F;developer.arm.com&#x2F;documentation&#x2F;102412&#x2F;0103&#x2F;Privileg... reply baby_souffle 17 hours agorootparentprev> What&#x27;s EL2 exactly?Probably execution level 2. reply dmitrygr 17 hours agorootparentprevnext [–]> In practice every single modern system is running tons of binary firmware blobsThis one does not: https:&#x2F;&#x2F;www.amazon.com&#x2F;ASUS-C100PA-DB02-10-1-inch-Chromebook...The SoC&#x27;s boot ROM is 32K, fully inspectable, does not linger once the OS is booted. Every other software component is built from source and you can replicate it reply fragmede 16 hours agorootparentEven the broadcom-based wifi card? my read of https:&#x2F;&#x2F;wireless.wiki.kernel.org&#x2F;en&#x2F;users&#x2F;drivers&#x2F;brcm80211 says for the 4354 in the c100, you need firmware, for brcmfmac. reply dmitrygr 16 hours agorootparentYou are right.(I use a usb-to-ethernet dongle and the wifi card is disabled, but you are right in theory) reply StillBored 8 hours agorootparentAnd you probably still have firmware on the main machine. Just about every modern usb controller offloads the USB packet arbitration&#x2F;sequencing behind a microcontroller and a pile of fw. Ex XHCI is usually a 8051 and some firmware sitting on the other side of the XHCI register description. Its probably the same on the actual USB->ethernet device, where there is conceptually something like the cypress FX3 integrated with a ethernet mac&#x2F;phy in the chip an a couple arm&#x27;s running firmware to respond to the USB packets and act as a control plane for the data being DMA&#x27;ed to&#x2F;from the ethernet buffers. Same with the disk, does it have NVMe, SD, emmc? Then likely there is another handful of arm device doing the load leveling and flash management on the \"disk\". Or for that matter the battery and charge controller might look dumb but has a little microcontroller integrating instantaneous charge&#x2F;discharge information and adjusting charge current&#x2F;etc.https:&#x2F;&#x2F;blog.einval.com&#x2F;2022&#x2F;04&#x2F;19#firmware-what-do-we-do reply mips_r4300i 5 hours agorootparentAgreed, people seem to only see blobs when they run on x86. A typical PC system probably has at least two dozen ancillary CPU cores spread out among the IO and peripherals alone.If I had a dollar for every 8051 that turned out to be inside a chip I designed around... reply fsflover 16 hours agorootparentprevTry this one: https:&#x2F;&#x2F;www.crowdsupply.com&#x2F;sutajio-kosagi&#x2F;precursorAlthough \"modern\" is debatable. reply dmitrygr 16 hours agorootparentMerely 6x the cost :) replywyldfire 20 hours agoparentprevAs a practical matter, I think the article happens to describe the steps to test it out yourself. I suppose the absence of a mention of binary blobs doesn&#x27;t necessarily mean that they&#x27;re not being used, I think it&#x27;s plausible that there aren&#x27;t (m)any.> How do I run AOSP using Mainline?> One might think it is quite hard to run AOSP with mainline on such a new platform, but in reality, not at all! Thanks to the long term effort of Linaro and Google engineers making it possible to run AOSP with vanilla Linux releases. Thanks to Amit Pundir for providing a helping hand to get AOSP on this platform.> To generate an AOSP image for the Snapdragon 8 Gen 3 Qualcomm Reference Device using the current set of patches available on the mailing list, use the following instructions, which are derived from here https:&#x2F;&#x2F;source.android.com&#x2F;docs&#x2F;setup&#x2F;build&#x2F;devices with some small changes. reply spookie 18 hours agorootparentThis is quite refreshing! Thanks for the details reply nomel 20 hours agoparentprevNaive question. What&#x27;s the practical impact for not having these? It seems that AMD and Intel are also guilty. reply lrvick 20 hours agorootparentThose blobs, if backdoored, could have massive security implications.Also those blobs are often targeted at specific kernel versions, so in 2 years when the upstream vendors stop releasing updated blobs, then it no longer becomes possible to upgrade the kernel, making it very very hard to keep last gen devices secure.This exact problem is why I was forced to admit there is no secure path to use Android today, and a big reason why I gave up on smartphones entirely. reply nomel 18 hours agorootparentAMD and Intel both have their share of proprietary blobs, in their \"open source\" packages, including microcode. Where do you see a secure path, for any computing, especially high performance? reply tremon 16 minutes agorootparentThe Raptor Blackbird and Talos systems might qualify: https:&#x2F;&#x2F;www.raptorcs.com&#x2F;content&#x2F;base&#x2F;products.htmlNot sure if the Broadcom GbE NICs they use require firmware. It would seem odd to me that they&#x27;d go so far as to include an open FPGA[0] for board management and system bringup to avoid closed firmware blobs, only to then rely on a network interface with firmware requirement.[0] https:&#x2F;&#x2F;www.crowdsupply.com&#x2F;raptor-computing-systems&#x2F;talos-s... reply yjftsjthsd-h 18 hours agorootparentprev> Where do you see a secure path, for any computing, especially high performance?I believe POWER9 is the only modern option that doesn&#x27;t use blobs? Of course that doesn&#x27;t remove the possibility of hardware backdoors (nothing does, except maybe an electron microscope and a lot of free time), but that&#x27;s a higher bar. reply AnthonyMouse 18 hours agorootparentprevPeople rightly disapprove of the AMD and Intel blobs and do what they can to disable or remove them, but at least those have stable interfaces that don&#x27;t decay when there is a new kernel version. Basically every x86_64 processor ever made can run the latest version of the Linux kernel. Would that it were for Qualcomm. reply nomel 17 hours agorootparent> do what they can to disable or remove themIs there open source microcode, at this point? I can&#x27;t find anything that suggests there is. reply pabs3 5 hours agorootparentIntel microcode is signed so you can&#x27;t run open source microcode even if you were able to create it, and the microcode is encrypted so you can&#x27;t reverse engineer it anyway.On long obsolete AMD K8 CPUs, there was some work on reverse engineering the microcode back in 2017:https:&#x2F;&#x2F;github.com&#x2F;RUB-SysSec&#x2F;Microcode reply fsflover 17 hours agorootparentprevThe parent probably speaks of Intel ME neutralizing&#x2F;disablement. reply surajrmal 9 hours agorootparentprevIsn&#x27;t it true that even if the firmware was open, as long as the hardware is closed it could still be backdoored and doing things you don&#x27;t want it to? Where do you draw the line? reply fsflover 2 hours agorootparentYou don&#x27;t draw the line: you support practical, existing systems that are as open as possible. Also, there is Precursor, which is open hardware. reply jancsika 15 hours agorootparentprev> Also those blobs are often targeted at specific kernel versions, so in 2 years when the upstream vendors stop releasing updated blobs, then it no longer becomes possible to upgrade the kernel, making it very very hard to keep last gen devices secure.Is this true for the blobs in the Snapdragon 8 Gen 3 Mobile Platform? reply fsflover 20 hours agorootparentprev> and a big reason why I gave up on smartphones entirelyThis is not necessary: my Librem 5 doesn&#x27;t rely on blobs in kernel and runs FSF-endorsed GNU&#x2F;Linux, PureOS. reply dawidpotocki 16 hours agorootparentBecause Purism cheated and just moved the blobs into a chip that you can&#x27;t update and made it go through a separate processor[1]. FSF-endorsement is meaningless. This is worse than having a loadable blob from a kernel.[1]: https:&#x2F;&#x2F;puri.sm&#x2F;posts&#x2F;librem5-solving-the-first-fsf-ryf-hurd... reply fsflover 16 hours agorootparentI don&#x27;t see how it&#x27;s worse. As a consequence, it&#x27;s the only phone that can run fully free OS and have lifetime updates. reply dawidpotocki 15 hours agorootparentYou can&#x27;t update the firmware at all and you are still running it.Librem 5 has very dated hardware that barely runs. It has only Cortex A53 cores @ 1.5 GHz that were released in 2012. You will see it even lag in Purism&#x27;s videos.Modern Android phones have better OS, hardware security, battery life and will be useful for longer and cheaper.Librem 5 now costs 1000 USD, the same price that Google Pixel 8 Pro costs which also has guaranteed 7 years of OS support. Will you want to use Librem 5 in 7 years?Also let&#x27;s not forget how Purism took forever to ship the devices and was declining refunds from people that didn&#x27;t even get sent the device and waited way over a year.Oh and there are Android phones that can run on mainline kernels. reply fsflover 6 hours agorootparent> Will you want to use Librem 5 in 7 years?Yes: Librem 5 is a full desktop, with my full control, \"Thinkpad T400 in mobile\". It will always run latest Linux and all desktop apps. I can use it as a full desktop connected to keyboard&#x2F;screen. On the other hand, Android is not a general purpose computer, which only runs what Google allows you to run.You should try SXMo if you want to see how smoothly Librem 5 and even Pinephone can work if the software is optimized.> You can&#x27;t update the firmware at all and you are still running it.Is there even theoretically an attack vector here?Yes, Purism has been having problems with refunds. It doesn&#x27;t affect security or freedom of they devices. Don&#x27;t buy from them if you will want a refund. reply forty 5 hours agorootparentHow will you fix it in 4 years? I don&#x27;t see were they sell spare parts. reply fsflover 2 hours agorootparentThey don&#x27;t have spare parts in the online shop, but people on the forum were able to buy them or repair the devices by contacting Purism directly. AFAIK in case of a larger demand, Purism promised to provide spare parts more explicitly. replyHappyDaoDude 15 hours agorootparentprevIt is the closest we have to a freedom respecting device. The baseband processor is still a closed blob but it is a lot better than pretty much everything else out there. Maybe Pinephone eventually will get there as well. reply fifteen1506 19 hours agorootparentprevPixels may also be an option -- though Librem 5 is, in this context, better.Pixels Pro have now... 7 or 8 years support. reply fsflover 19 hours agorootparentprevhttps:&#x2F;&#x2F;www.gnu.org&#x2F;philosophy&#x2F;free-software-even-more-impor... reply robert_foss 17 hours agoparentprevThe GPU probably runs a firmware blob. Other than that Linaro is serious about upstream support. reply almatabata 19 hours agoparentprevAt minimum i expect QSEE and all their TAs to remain binary blobs, like the keymaster for example. reply foobiekr 20 hours agoparentprevSomeone knows Qualcomm. reply apatheticonion 17 hours agoprevWill this help bring Linux to the upcoming Qualcomm Elite X laptop SoC?A viable Linux ARM laptop would be cool, especially if it promised high performance and long battery life! reply seabrookmx 15 hours agoparentAsahi is very close to daily driver material so it&#x27;s likely that Macs will be the first viable ARM Linux laptops, funny enough.But it would certainly be great to see more variety, and with a standard (ie: UEFI based) install process.I would already be rocking an X13s if the Linux support was there. reply camel-cdr 4 hours agorootparent> Asahi is very close to daily driver material so it&#x27;s likely that Macs will be the first viable ARM Linux laptops, funny enoughI&#x27;ve been daily driving my pinebook pro since 2020. reply apatheticonion 8 hours agorootparentprevIt&#x27;s honestly incredible how much progress the Asahi team have made with Linux on Apple Silicon. In a few years I imagine we will have Vulkan support, external displays, bluetooth and good performing drivers for most of the hardware.I swear, the MBP running Linux would be an unstoppable development environment - at least as far as ultrabooks go.With the developments in Proton, FEX (x86 translation), and usability improvements in desktop linux (Gnome 4x and KDE); I&#x27;d go as far to say a MBP running Linux with full hardware support would be the best gaming and general purpose ultrabook on the market.For now I am testing Asahi but daily driving MacOS. reply StillBored 10 hours agoprevThe title is upstream support available, yet when I look at the tree in the article it is a 6.6 rc, and a bunch of public patches under review. I don&#x27;t see a -next branch its on, and I don&#x27;t see it in the 6.7 merge list.Its not actually upstream, is it?SOS then? reply wyldfire 10 hours agoparent> Its not actually upstream, is it?I agree: it&#x27;s not at all clear from the title, it sounds as if it&#x27;s truly \"upstream.\"But patches based on an upstream tree (as opposed to any forks intended for Android) are pretty useful IMO. They&#x27;re not accepted&#x2F;landed but you can use them now and I&#x27;d wager good money that they&#x27;ll continue rebasing them until they land, so you should expect to be able to use them for the foreseeable future. reply robert_foss 5 hours agoparentprevI haven&#x27;t checked but you may be correct, but Linaro has a stellar track record. These patches will land upstream if they haven&#x27;t already. reply bjackman 7 hours agoprevWow this is fantastic (assuming the matches get merged).Anyone have a picture of how likely&#x2F;soon we can reach a future where mobile devices get kernel upgrades in the mainstream market?I hear graphics drivers are getting pretty isolated now so is it even possible without open graphics? reply tetris11 7 hours agoparentPostmarketOS is pretty mainline, and comes with a nice Phosh interface, but smart battery support remains an issue on a lot devices reply flakiness 18 hours agoprevIt doesn&#x27;t cover either GPU or ISP (image processing unit). Not sure about NPU. Does Hexagon support cover that?It&#x27;s still a nice progress though. reply robert_foss 17 hours agoparentISP won&#x27;t happen. GPU is just a matter of time, and has been enabled for previous platforms. reply neilalexander 20 hours agoprevPerhaps with this, the Microsoft Dev Kit 2023 will turn out to be a decent option for Linux on ARM. reply entropicdrifter 20 hours agoparentMeh, still worse than a 2020 M1 Mac Mini reply neilalexander 20 hours agorootparentUnless you like RAM. The Dev Kit comes with 32GB as standard. reply entropicdrifter 19 hours agorootparentFair point. For my workloads compute matters a lot more than RAM, but it&#x27;s not as straightforward a trade-off as I was initially thinking reply klardotsh 14 hours agorootparentHeh, and then I&#x27;m on the opposite end of the spectrum: I can happily get by with the CPU power offered by Skylake (or maybe even older) devices, but need 32GB RAM to be \"mostly comfortable, usually\" in my developer workflows. I could easily make use of 64GB. I&#x27;m considering putting 96-128GB in my next desktop build for some future-proofing.And yet laptop manufacturers seem hellbent on insisting 4GB is still acceptable to ship at all, and even still market 8GB machines to professionals. Folks, \"professional software\" like Slack takes hundreds of MB of RAM to even render the splash screen these days, it should be nearly criminal to ship a consumer device with less than 16GB now (alternatively, we should be taxing software companies for the negative externalities their waste produces, but that&#x27;s a messy political fight) reply tjoff 19 hours agorootparentprevIf you want to support an ecosystem that goes against your own interest. Sure, but what would cause you to be that shortsighted? reply entropicdrifter 19 hours agorootparentI run my M1 Mac Mini with Asahi Linux?I&#x27;m not a big fan of any SoCs which have soldered-on RAM or storage, but I find it an odd point to argue that I&#x27;m supporting Apple&#x27;s ecosystem overall when all I did was buy their hardware on sale. Their App Store is by far their biggest money-maker. reply tjoff 18 hours agorootparentYou are supporting the biggest threat to the open platforms we have. And you are actively not supporting the ones that keep it alive.How is that an odd argument? Voting with your wallet suddenly doesn&#x27;t count because shiny? reply wmf 18 hours agorootparentI would say it doesn&#x27;t count because they&#x27;re all \"evil\". Apple, Intel, AMD, Qualcomm, Microsoft... The only stuff that&#x27;s close to being truly open like Freescale and Talos is completely obsolete and overpriced. reply tjoff 18 hours agorootparentYeah, no, that is delusional.Sure, you can go the purist route if you want. But it is not either or, few things in life are. reply fomine3 14 hours agorootparentprevIntel and AMD aren&#x27;t so bad for openness reply fsflover 18 hours agorootparentprevPurism, System76, Framework etc. are not evil. reply pjmlp 18 hours agorootparentIf only the hardware on their laptops would be 100% functional. reply fsflover 16 hours agorootparentWorks quite well for me. reply pjmlp 14 hours agorootparentAs in, \"the hardware features that don&#x27;t work are irrelevant to me\", or \"I enjoy tinkering\"?https:&#x2F;&#x2F;frame.work&#x2F;de&#x2F;en&#x2F;linux reply tjoff 10 hours agorootparentAre you making such a big deal out of the fingerprint reader? reply pjmlp 8 hours agorootparentWhen I pay for something it better either everything works, or money refund.To get GNU&#x2F;Linux going without proper hardware support I can do it myself, no need to pay extra. reply tjoff 4 hours agorootparentI don&#x27;t think you understand the value proposition.But you can at least try to be honest and not spread fud. reply pjmlp 2 hours agorootparentHaving used GNU&#x2F;Linux since kernel 1.0.9 and subscribed all Linux User Journal issues since the 5th issue until their insolvency, I am quite aware of I am talking about.What FUD, when the Framework themselves admit none of the provided Linux distributions support 100% of the hardware features they are selling?We already had white brands doing the same 20 years ago during the dot-com wave.Eventually tinkering becomes tiresome. reply fsflover 2 hours agorootparent> when the Framework themselves admit none of the provided Linux distributions support 100% of the hardware features they are selling?Which means you get exactly what was advertised. Try the other two companies in my list. reply pjmlp 42 minutes agorootparentThe standard reply, herehttps:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;System76&#x2F;s&#x2F;dohrbjShW6Great experience for Apple like prices. &#x2F;smartin8412 5 hours agorootparentprevPurism are unethical scumbags. reply fsflover 2 hours agorootparentThis is FUD. I flagged your post.Also: Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html replychx 15 hours agorootparentprev> I&#x27;m not a big fan of any SoCs which have soldered-on RAM or storage,Funny way of putting \"I am stupefied people pay actual, real world money for a laptop with soldered on storage\". reply blackoil 12 hours agorootparentLaptops may still make some sense, but a desktop!! You can easily get 2x value going with an assembled. reply mschuster91 7 hours agorootparentprevSoldered CPU&#x2F;memory makes sense for performance. Part of why Apple&#x27;s M SoCs blow Intel&#x2F;AMD away so hard is that the physical signal paths are incredibly short and don&#x27;t have physical sockets in their way, so way better signal integrity and less worrying about EMI. reply chx 6 hours agorootparent> Soldered CPU&#x2F;memory makes sense for performance.And I have talked about storage. reply mschuster91 3 hours agorootparentYou wrote \"soldered RAM\", and besides, the argument is just as valid for storage given today&#x27;s transfer bus speeds. replyfsflover 21 hours agoprev [–] I wonder if one can run GNU&#x2F;Linux like PureOS on the respective devices. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Linaro Engineer Neil Armstrong has enabled upstream Linux support for the Qualcomm Snapdragon 8 Gen 3 Mobile Platform, underscoring Linaro's commitment to offering trailblazing solutions.",
      "Posted on October 25, 2023, this support permits Linux integration, performance optimization, and running of AOSP (Android Open Source Project) with Mainline, with Qualcomm® Kryo™ CPUs, Low-Speed I/O, High-Density Storage, High-Speed Peripherals among the enabled features.",
      "Future plans include collaborating with the Linux kernel community to merge all the patch series swiftly and activate more features."
    ],
    "commentSummary": [
      "Linux now offers support for Qualcomm's Snapdragon 8 Gen 3 Mobile Platform with a Qualcomm Hypervisor dependency, prompting some concerns over its impact on system operations.",
      "Users engaged in debates regarding the use of proprietary firmware, potential security risks from binary blobs in Android open-source projects, and the susceptibility of open-source firmware when used with closed-source hardware.",
      "Discussions among users also reflected contrasting views on non-upgradable laptops with soldered memory, and the price, quality, and ethical aspects of System76 and Purism products."
    ],
    "points": 171,
    "commentCount": 87,
    "retryCount": 0,
    "time": 1698775287
  },
  {
    "id": 38087448,
    "title": "Apple’s keynote event shot on iPhone and edited on Mac",
    "originLink": "https://www.apple.com/newsroom/2023/10/behind-the-scenes-at-scary-fast-apples-keynote-event-shot-on-iphone/",
    "originBody": "Apple Store Mac iPad iPhone Watch Vision AirPods TV & Home Entertainment Accessories Support 0 + Newsroom Search Newsroom Apple Stories Popular Topics PHOTOS October 31, 2023 Behind the scenes at Scary Fast: Apple’s keynote event shot on iPhone and edited on Mac Scary Fast, shot by award-winning documentary filmmaker Brian Oakes, unveiled the all-new MacBook Pro with the M3 family of chips and iMac with M3. On Monday, October 30, at Apple’s Scary Fast special event unveiling the all-new MacBook Pro with the M3 family of chips and 24-inch iMac with M3, there was an unseen star of the show working behind the scenes. All of the presenters, locations, and drone footage in the event were filmed using iPhone 15 Pro Max, the preferred smartphone for creative pros and filmmakers. Led by documentary film director Brian Oakes, known for the award-winning Jim: The James Foley Story and Living with Lincoln, Scary Fast put iPhone 15 Pro Max right in the middle of the action. The iPhone 15 Pro Max camera system offers the best video in a smartphone, with its quality rivaling those of professional video cameras. iPhone 15 Pro Max enables creatives to capture in ProRes up to 4K60 fps to an external drive with Apple Log encoding, which allows even more detail to be preserved for post-production color grading. iPhone 15 Pro and iPhone 15 Pro Max are also the first smartphones in the world to support the Academy Color Encoding System (ACES), a global standard for color workflows. “We were able to get the same complex shots with iPhone 15 Pro Max,” says Oakes. “Everything is there to be an extension of someone’s vision or personality. The image quality of iPhone definitely democratizes the access.” The production was advised by Apple’s Jon Carr, a Pro Workflow video specialist whose credits include Top Gun: Maverick and Terminator: Dark Fate, and Jeff Wozniak, who has worked on productions including Transformers: Dark of the Moon, Avatar, and Iron Man 2. “This year, iPhone 15 Pro Max was supercharged with the ability to record ProRes to an external drive, and Apple Log, our flavor of a format that all of the very high-end digital cameras shoot,” says Wozniak. “It’s pretty amazing how you can put this in the hands of someone who’s a professional director and they don’t have to change their equipment — they don’t have to change any of the things that they always do,” adds Carr. Capturing footage with multiple iPhone 15 Pro Max devices, the team utilized the integration between iPhone 15 Pro, the Blackmagic Camera app, and Tentacle Sync, showcasing the true power of the Apple ecosystem. Connected via Bluetooth, Tentacle Sync drives timecode and enables all devices on set — including Macs and preview screens — to be synced throughout the production. Beastgrip accessories, including cages and rigs, were also used during the production. Here’s how Scary Fast came to life behind the scenes. Last night’s reveal of the new MacBook Pro and the 24-inch iMac with the M3 family of chips involved a crew of filmmakers, editors, and colorists working on iPhone 15 Pro Max and Mac computers throughout the production. iPhone 15 Pro Max with the new USB-C connector brings a huge leap in data transfer with speeds of up to 10Gbps with a compatible USB 3 cable. This supports new workflows like ProRes video recording directly to an external SSD drive, allowing the crew to review footage in near real time and make adjustments on the fly. In post, editors can also take advantage of the higher dynamic range enabled with Apple Log, bringing even more control and flexibility into color grading. With a custom SpaceCam rig that’s regularly used on major productions, the team could work seamlessly with iPhone as their main camera and get the same complex shots they were used to. Shot under the cover of night at Apple Park, Scary Fast showcased the improvements in low-light video performance on iPhone 15 Pro Max. With ProRes Log encoding, iPhone 15 Pro Max has even more high and low light range than previous models, resulting overall in better dynamic range and better flexibility for color grading in post-production. “When I first got the footage from iPhone 15 Pro Max, I was immediately pleasantly surprised,” says Stefan Sonnenfeld, Company 3’s CEO, who colored the presentation and has worked on projects including Stranger Things, The Equalizer 3, and Fast X. “The quality of the image on iPhone 15 Pro Max is incredible, and it’s there. And I know because I’ve done it and I’ve seen it, and we’re doing this project with it.” Tim Cook on set for Scary Fast at Apple Park. Using the Blackmagic Camera app designed exclusively for iOS users, the crew was able to leverage the same interface as Blackmagic Design’s award-winning digital film cameras, which provided the same tools used in feature films, television shows, and documentaries. Available now for free on the App Store, the app adds digital film camera controls to iPhone and supports Apple Log encoding on iPhone 15 Pro Max. “We’ve done a tremendous amount of work behind the scenes working with a great third-party developer, Blackmagic Design, that has created an incredible app that allows us to have huge amounts of monitors and crew, and everybody working how they traditionally would,” says Carr. Blackmagic Camera, an iOS-exclusive app, adds digital film camera controls to iPhone and supports Apple Log encoding on iPhone 15 Pro Max. On the set, the crew employed traditional filming techniques — even the use of drones — seamlessly with iPhone 15 Pro Max to capture the scenes and showcase the new MacBook Pro. “There’s cranes, there’s dollies, there’s all the toys that you want as a filmmaker, and everybody’s moving and has their job to do, and it’s just a very exciting and lively environment,” says Oakes. On the set, iPhone 15 Pro Max in a dolly captures MacBook Pro in a mock medical setting to showcase new capabilities for health professionals. Reflecting on the incredible versatility and ease of use of iPhone, Sonnenfeld says, “I think what I love about the iPhone is it enables everybody who uses it to have access to incredible amounts of information, and with a really intuitive operating system, so that whether it’s myself or my 7-year-old, anybody can pick it up and pretty much use it right away.” Share article Text of this article October 31, 2023 PHOTOS Behind the scenes at Scary Fast: Apple’s keynote event shot on iPhone and edited on Mac On Monday, October 30, at Apple’s Scary Fast special event unveiling the all-new MacBook Pro with the M3 family of chips and 24-inch iMac with M3, there was an unseen star of the show working behind the scenes. All of the presenters, locations, and drone footage in the event were filmed using iPhone 15 Pro Max, the preferred smartphone for creative pros and filmmakers. Led by documentary film director Brian Oakes, known for the award-winning Jim: The James Foley Story and Living with Lincoln, Scary Fast put iPhone 15 Pro Max right in the middle of the action. The iPhone 15 Pro Max camera system offers the best video in a smartphone, with its quality rivaling those of professional video cameras. iPhone 15 Pro Max enables creatives to capture in ProRes up to 4K60 fps to an external drive with Apple Log encoding, which allows even more detail to be preserved for post-production color grading. iPhone 15 Pro and iPhone 15 Pro Max are also the first smartphones in the world to support the Academy Color Encoding System (ACES), a global standard for color workflows. “We were able to get the same complex shots with iPhone 15 Pro Max,” says Oakes. “Everything is there to be an extension of someone’s vision or personality. The image quality of iPhone definitely democratizes the access.” The production was advised by Apple’s Jon Carr, a Pro Workflow video specialist whose credits include Top Gun: Maverick and Terminator: Dark Fate, and Jeff Wozniak, who has worked on productions including Transformers: Dark of the Moon, Avatar, and Iron Man 2. “This year, iPhone 15 Pro Max was supercharged with the ability to record ProRes to an external drive, and Apple Log, our flavor of a format that all of the very high-end digital cameras shoot,” says Wozniak. “It’s pretty amazing how you can put this in the hands of someone who’s a professional director and they don’t have to change their equipment — they don’t have to change any of the things that they always do,” adds Carr. Capturing footage with multiple iPhone 15 Pro Max devices, the team utilized the integration between iPhone 15 Pro, the Blackmagic Camera app, and Tentacle Sync, showcasing the true power of the Apple ecosystem. Connected via Bluetooth, Tentacle Sync drives timecode and enables all devices on set — including Macs and preview screens — to be synced throughout the production. Beastgrip accessories, including cages and rigs, were also used during the production. Here’s how Scary Fast came to life behind the scenes. iPhone 15 Pro Max with the new USB-C connector brings a huge leap in data transfer with speeds of up to 10Gbps with a compatible USB 3 cable. This supports new workflows like ProRes video recording directly to an external SSD drive, allowing the crew to review footage in near real time and make adjustments on the fly. In post, editors can also take advantage of the higher dynamic range enabled with Apple Log, bringing even more control and flexibility into color grading. Shot under the cover of night at Apple Park, Scary Fast showcased the improvements in low-light video performance on iPhone 15 Pro Max. With ProRes Log encoding, iPhone 15 Pro Max has even more high and low light range than previous models, resulting overall in better dynamic range and better flexibility for color grading in post-production. “When I first got the footage from iPhone 15 Pro Max, I was immediately pleasantly surprised,” says Stefan Sonnenfeld, Company 3’s CEO, who colored the presentation and has worked on projects including Stranger Things, The Equalizer 3, and Fast X. “The quality of the image on iPhone 15 Pro Max is incredible, and it’s there. And I know because I’ve done it and I’ve seen it, and we’re doing this project with it.” Using the Blackmagic Camera app designed exclusively for iOS users, the crew was able to leverage the same interface as Blackmagic Design’s award-winning digital film cameras, which provided the same tools used in feature films, television shows, and documentaries. Available now for free on the App Store, the app adds digital film camera controls to iPhone and supports Apple Log encoding on iPhone 15 Pro Max. “We’ve done a tremendous amount of work behind the scenes working with a great third-party developer, Blackmagic Design, that has created an incredible app that allows us to have huge amounts of monitors and crew, and everybody working how they traditionally would,” says Carr. On the set, the crew employed traditional filming techniques — even the use of drones — seamlessly with iPhone 15 Pro Max to capture the scenes and showcase the new MacBook Pro. “There’s cranes, there’s dollies, there’s all the toys that you want as a filmmaker, and everybody’s moving and has their job to do, and it’s just a very exciting and lively environment,” says Oakes. Reflecting on the incredible versatility and ease of use of iPhone, Sonnenfeld says, “I think what I love about the iPhone is it enables everybody who uses it to have access to incredible amounts of information, and with a really intuitive operating system, so that whether it’s myself or my 7-year-old, anybody can pick it up and pretty much use it right away.” Press Contacts Renee Felton Apple rfelton@apple.com Apple Media Helpline media.help@apple.com Copy text Images in this article Download all images Press Contacts Renee Felton Apple rfelton@apple.com Apple Media Helpline media.help@apple.com Latest News UPDATE 8 new games and more than 50 updates coming to Apple Arcade this holiday season November 1, 2023 PRESS RELEASE Apple unveils new MacBook Pro featuring M3 chips October 30, 2023 PRESS RELEASE Apple unveils M3, M3 Pro, and M3 Max, the most advanced chips for a personal computer October 30, 2023 Apple Newsroom The latest news and updates, direct from Apple. Read more Apple Footer  Apple Newsroom Behind the scenes at Scary Fast: Apple’s keynote event shot on iPhone Shop and Learn Store Mac iPad iPhone Watch Vision AirPods TV & Home AirTag Accessories Gift Cards Apple Wallet Wallet Apple Card Apple Pay Apple Cash Account Manage Your Apple ID Apple Store Account iCloud.com Entertainment Apple One Apple TV+ Apple Music Apple Arcade Apple Fitness+ Apple News+ Apple Podcasts Apple Books App Store Apple Store Find a Store Genius Bar Today at Apple Apple Camp Apple Store App Certified Refurbished Apple Trade In Financing Carrier Deals at Apple Order Status Shopping Help For Business Apple and Business Shop for Business For Education Apple and Education Shop for K-12 Shop for College For Healthcare Apple in Healthcare Health on Apple Watch Health Records on iPhone For Government Shop for Government Shop for Veterans and Military Apple Values Accessibility Education Environment Inclusion and Diversity Privacy Racial Equity and Justice Supplier Responsibility About Apple Newsroom Apple Leadership Career Opportunities Investors Ethics & Compliance Events Contact Apple More ways to shop: Find an Apple Store or other retailer near you. Or call 1-800-MY-APPLE. United States Copyright © 2023 Apple Inc. All rights reserved. Privacy Policy Terms of Use Sales and Refunds Legal Site Map",
    "commentLink": "https://news.ycombinator.com/item?id=38087448",
    "commentBody": "Apple’s keynote event shot on iPhone and edited on MacHacker NewspastloginApple’s keynote event shot on iPhone and edited on Mac (apple.com) 171 points by ayoreis 22 hours ago| hidepastfavorite140 comments zavertnik 20 hours agoA lot of people here are bringing up all of the expensive gear surrounding the iPhone that helped give it the professional look. This isn&#x27;t unique to iPhone as a sensor.I work in TV and have spent a great deal of time on set shooting. The only time I&#x27;ve ever relied entirely on the camera&#x27;s sensor and lens for a high quality image is shooting outside, and even then that requires adjustments, such as facing away from the sun, moving away from contrasty shadows, ect.Outside of documentaries, every other shoot will have a great deal of time, effort, and money spent on lighting and set design to elevate what is being shot. For scripted projects&#x2F;films, an even smaller % of shots will be shot with the raw, available light&#x2F;environment.What Apple did with the iPhone 15 proved that the iPhone can be used in a professional setting without being the on set bottle neck. For example, a short film shoot which had it&#x27;s budget blown entirely on renting an Alexa will be bottle necked by the lack of lighting for the scene. Similarly, a short film which had its budget blown entirely on renting lights will be bottle necked if its shot on an iPhone 4.The goal is balance and for smaller productions, that balance is found in budgeting. If anyone on set has an iPhone 15 Pro in their pocket, the shoot suddenly has a viable second camera-- maybe its not good enough for the entire shoot, but its surely going to be good enough as a B-Cam or even as an A-Cam in certain scenarios where a smaller form factor is required to get the shot.I don&#x27;t think Apple is sugar coating their demonstration here with all the expensive toys being used in parallel with the iPhone. The use of these tools in parallel with the iPhone IS the demonstration.Like any good video, if its shot correctly and edited correctly, you won&#x27;t have an easy time visually identifying what sensor is being used. reply vr46 19 hours agoparentWithout the expensive gear, the iPhone looks considerably downgraded compared to better source equipment. I had a Canon 5DII the day it was released and within a week some friends and I had a music video entered into a festival, and within a year, two short films, all done without any extra lighting or equipment - including gimbals. The source camera and lenses were good enough - and the look was amazing compared to camcorders - to achieve this.Forgetting \"shoots\" and professional lighting, the iPhone isn&#x27;t going to have the massive range of other equipment, and when you&#x27;re spending literally thousands of pounds on studio time, lighting hire, operator costs, etc etc, are you really going to pick up and shoot on an iPhone when you&#x27;ve got a Black Magic or Sony or Canon at hand? Unless you&#x27;re being paid by Apple?I get that it&#x27;s viable but there really is a lot of road between viable and superlative. reply joshspankit 59 minutes agorootparentOk, but the 5D Mark II was a gamechanger and in my opinion creates a result that still beat the III, IV, and many cameras that came after. reply zavertnik 18 hours agorootparentprevTo be fair, the iPhone is not a camera, its a smart phone with a camera. There is no question that a DSLR with an interchangeable lens will beat out iPhone.> The source camera and lenses were good enough - and the look was amazing compared to camcorders - to achieve this.I would bet that the camera and lenses used didn&#x27;t do the heavy lifting there, the selection of the location, the time of day, and the direction from the DP did. An expensive lighting setup isn&#x27;t a requirement for a good image but good lighting is. Whether its natural or artificial is up to the DP.The minimum viable quality you need for a project depends on the needs of the shoot.> Forgetting \"shoots\" and professional lighting, the iPhone isn&#x27;t going to have the massive range of other equipment, and when you&#x27;re spending literally thousands of pounds on studio time, lighting hire, operator costs, etc etc, are you really going to pick up and shoot on an iPhone when you&#x27;ve got a Black Magic or Sony or Canon at hand? Unless you&#x27;re being paid by Apple?Of course not! I don&#x27;t think anyone thinks the iPhone 15 is replacing the main camera on a shoot with a proper budget. But could the iPhone 15 be an additional camera for specialty shots or experimentation? Absolutely. For instance, if I&#x27;m shooting an unscripted scene with two people talking alone and I can mount my phone for a passable wide shot that can roll the whole time, giving me flexibility to shoot both individuals without losing coverage, then that&#x27;s a huge value add.I think in cases like that and in cases where people want to experiment without buying into a camera system, the iPhone becomes elevated beyond being just a mobile camera.> I get that it&#x27;s viable but there really is a lot of road between viable and superlative.Totally agree, however I don&#x27;t think I argued that. From my perspective, a viable camera is a viable camera for a job. The iPhone 15 seems viable from my viewing and it lives in my pocket while every other viable camera does not. That to me is the impressive feat. iPhone not living up to a proper DSLR is expected. reply Shawnj2 18 hours agoparentprevAll of Jet Lag The Game and DankPods are shot on iPhone and they look fine. It doesn’t look like some ultra high quality movie production but they also don’t stand out particularly looking bad, it’s completely fine for the content m reply gamblor956 18 hours agoparentprevThe new Olivia Rodrigo music video&#x2F;ad was shot on an iPhone. And it shows. Even on 4k, there&#x27;s blurriness, color balance issues, and noticeable artifacts that just aren&#x27;t present on videos shot with a proper video camera (i.e., the commercials airing right before and after).Yes, the iPhone can be used as a video camera. The same way that a camcorder can be used as a video camera. And neither of them are anywhere close to professional-level quality without a lot of extra work and equipment: you actually need more expensive equipment than you would with an expensive camera (and this other equipment usually costs a multiple of what a good camera would cost). reply SirMaster 21 hours agoprevI don&#x27;t think many people were really wondering if this sort of thing \"could\" be done.IMO that&#x27;s not the important question.The question is, did the people who filmed and created the video with the iPhone hardware actually enjoy this process &#x2F; workflow? Or did this process cause a bunch more pain and hassle to deal with the iPhone as the source camera?Compared to some alternative they could have used.Is there actually a compelling reason to use an iPhone for this type of work over the various alternatives? reply conductr 21 hours agoparent> Or did this process cause a bunch more pain and hassle to deal with the iPhone as the source camera?Did you read&#x2F;skim the article because that&#x27;s the focal point of the whole piece and discussions taking place in the videos. The whole thing is touting how easy the pros were able to slot this in and do their normal workflows on top.> Is there actually a compelling reason to use an iPhone for this type of work over the various alternatives?I&#x27;d guess cost is the big one, and the fact this will be in your pocket already for a lot of people. reply FireBeyond 21 hours agorootparentWell, the misleading thing is that Apple&#x27;s implication is \"you too can make videos that look like this with just the phone in your pocket\" (emphasis mine).> the pros were able to slot this in and do their normal workflowsBecause you can&#x27;t do it with \"just the phone in your pocket\". You can do it with the $50-100K of equipment you see on that page, just using the phone as the camera, one small part of the process. (Not to denigrate the camera&#x27;s role - I am a photographer, though not a videographer, so I appreciate the importance). reply spease 21 hours agorootparentI’m not sure what your objection is here. As you point out, they have photos that very prominently feature professional lighting and tripod equipment. They even explain in a caption that they customized it for the iPhone.How is that misleading that all they used was “the phone in your pocket”? reply FireBeyond 21 hours agorootparentFor clarity, this page is not misleading. I loved reading it, to be honest, and I love seeing the advances.But he rest of Apple&#x27;s marketing around things like this is much more \"look at the videos you can create with just an iPhone and a Mac\".I get it, marketing. reply dmz73 17 hours agorootparentprevWell, for one, they had to take that phone out of my pocket and they didn&#x27;t because it is still in my pocket :) They also had to take the phone out of their pocket otherwise all we would see if dark and pocket sand. Then of course to make the actual video you see in the presentation they had to use a whole bunch of other equipment without which the phone in my pocket would not produce the result we are seeing. So, misleading, but not more than any other Apple marketing claim. We are used to it now. The reality distortion field has not been breached so maybe Steve Jobs will return with a whole fleet of dark star destroyers to conquer the galaxy once more. reply conductr 21 hours agorootparentprevOh yeah, totally agree on that point. Apple always does these \"shot on iPhone\" things that just don&#x27;t look anything like my videos. But I also have never once been bothered enough by it to put my videos through editing software&#x2F;color correction&#x2F;etc. So I can&#x27;t really complain.I think it does still highlight that you can take this device far, almost as far as you&#x27;d ever need to. I think most people making videos are doing it for youtube and social, they would invest in a few smaller accessories that would cover 80% of the needs and would never need to use all of what Apple had at their disposal (the SpaceCam rig is excessive, a lot can be done with amateur&#x2F;affordable gimbles and rigs). So, it&#x27;s selling the fact that it&#x27;s a good starter device for budding videographers (plenty of room for you can grow into it). But also not likely to convert pros away from whatever they&#x27;re already using. reply elzbardico 21 hours agorootparentprevWell, a professional cinema camera and a set of lens can easily pass 100K and you&#x27;ll still need the 50-100k of equipment. reply FireBeyond 21 hours agorootparentYou can rent a RED camera and lenses for $3,000&#x2F;week. If you&#x27;re a major production, then this is a non-issue.If you&#x27;re doing an indie&#x2F;film school short or similar, I can&#x27;t see people breaking down their tech budget as \"$100K for lighting, gimbals, etc., and $1100 for an iPhone\". reply SirMaster 21 hours agorootparentprevI admit I committed the cardinal sin of not really reading the article.I&#x27;ll do better next time. reply gamblor956 18 hours agorootparentprevI read the part where the people who were paid to use the iPhone 15 to film their videos told the company paying them lots of money to do that they enjoyed using it to film those specific videos.And then I noticed that those same professionals went right back to using regular video cameras for their next shoots. (See e.g., Olivia Rodrigo...who shot 1 music video with an iPhone 15 because Apple paid $$$ for to do it and went right back to using regular video equipment for everything else. Also Sodenberg, for an earlier version of the iPhone, who uses regular video equipment after that brief, well-funded experiment.) reply crazygringo 21 hours agoparentprev> Is there actually a compelling reason to use an iPhone for this type of work over the various alternatives?For major studios? Of course not.For tiny-budget indie films, student films, YouTube comedy webseries, and the like? Hugely. reply zavertnik 20 hours agorootparentI think the best comparison for the iPhone is looking at DSLRs that do not shoot RAW but do shoot in Log. The workflow out of iPhone compared to say, an a7s, should be relatively similar, aside from the differences in sensor capabilities such as color depth, dynamic range, ect.I can see a lot of potential use of the iPhone 15 as on hand as a \"deploy anytime, anywhere\" B-Cam. For the editor, having that B-Cam to cut away to is invaluable and for small shoots or tight schedules, slapping the iPhone 15 on a cheap tripod is at the right level of convenience to give that a shot. reply FireBeyond 21 hours agorootparentprev> For tiny-budget indie filmsThere&#x27;s easily $100K of equipment on that page.You can rent an EOS C700 and 6 CN-E lenses for $2000&#x2F;week. RED for not much more.If you&#x27;re making a tiny budget indie, you already have similar caliber equipment. You&#x27;re not renting high end ARRI and Panavision optics.I love that you can make good video with such small equipment. I just think if you&#x27;re doing something like this, optimizing for \"well, let&#x27;s buy an iPhone\" over the benefits of traditional cameras is odd, even for a smaller scale production.Frankly, I think, \"show us what you can do with an iPhone and a small gimbal, a couple of basic continuous lights, even if it doesn&#x27;t look as good as this production\" would have given a better view of the capabilities and potential. reply robenkleene 20 hours agorootparentI don&#x27;t think saying that you can get the same results with a $2,000+&#x2F;week rental is making the argument that you think it is... reply crazygringo 19 hours agorootparentYeah, I&#x27;m not talking a $5 million indie film, I&#x27;m talking about your $50K indie film. $2K&#x2F;wk for camera rental is just totally out of the question. reply FireBeyond 19 hours agorootparentYour $50K budget indie film isn&#x27;t going to be able to afford any&#x2F;much of the equipment in that article, either. And then, in fact, it&#x27;s generally more difficult to rent that stuff than it is to rent cameras. replyandrewcl 20 hours agoparentprevIf you don&#x27;t have any of those alternatives in the first place.The Best Food Review Show Ever went to Egypt for a series and the authorities impounded their video equipment and wouldn&#x27;t let the team access the equipment until they left Egypt. Sunny, the host, was super frustrated but stated that the default was buying a few iPhones and filming the whole show through those devices.I believe this is the series: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=u-PgumHXWVo reply m463 9 hours agoparentprevThis seems to be more like people doing software development on their laptop vs at a desk with large monitor, a proper keyboard and ergonomics.(on a tangent, there are no osha-approved laptops, they are not ergonomic. To work for hours, you should have a proper body posture. You should be looking forward at the screen with your head balanced on your neck, not up or down. there is also posture for arms, wrists, shoulders, etc.) reply kranke155 21 hours agoparentprevThe fact that Apple has done this can be helpful to filmmakers to prove a point.Ie go to your producer and say hey Apple did this. We can do it reply dzikimarian 21 hours agorootparentI can program in notepad. I just don&#x27;t want to. Neither I&#x27;m going to my CEO to make us do that.Being serious - there&#x27;s no point in doing that, because it requires ton of additional, janky equipment and ton of extra job in the post production.See: https:&#x2F;&#x2F;youtu.be&#x2F;OkPter7MC1I?si=Enx7IAFzNHfOPrBWThis is just marketing stunt. No idea why anybody cares. reply izzydata 21 hours agorootparentprevThe phone itself looks like a pretty insignificant portion of the total equipment cost. Why would you use an iPhone instead of an full camera at that point? reply olliej 21 hours agorootparentYes, a phone is a small part of the cost in this set up.An actual film camera instead can be much, much more per day.In reality no one other than apple is going to have high end professional light rigs and a phone camera. But plenty of people could use the money they aren&#x27;t spending on a \"proper\" camera on better lighting instead and perhaps get a better final product than the historical configuration of \"we&#x27;ve spent a tonne renting the camera, let&#x27;s see if we can afford any lighting\". reply steve1977 9 hours agorootparent> An actual film camera instead can be much, much more per day.You can rent a Sony Venice for around 250 bucks per day. ARRI Alexa is maybe twice as much? reply steve1977 21 hours agorootparentprevBut why would you?This is not some low-budget video, it’s a high-end production.If you have that kind of budget, your producer probably won’t care if you’re using an iPhone or a Sony FX-3(0) or even a rented “real” cinema camera like a Sony Venice or an Arri reply Shawnj2 17 hours agorootparentI think this is targeted towards low budget productions reply steve1977 9 hours agorootparentBut those would probably not be able to afford the other equipment and crew, that was my point. reply Shawnj2 9 hours agorootparentObviously not but any other professional production would have those, all Apple did is remove the real camera and put an iPhone in. So any professional video setup able to afford say a camera rental and shit lighting or Bob the producer’s iPhone for free and actually good lighting can feasibly pick the latter. reply kranke155 16 hours agorootparentprevThe fact that HN overall doesn’t understand is a bit revealing. The overall negativity is also surprising. reply dimmke 21 hours agoparentprevFWIW the 2017 film Tangerine was shot on an iPhone 5S and I rewatched it recently and it at least looked okay to my non professional eyes.And that movie had a lot of night scenes too. I can only imagine how much the situation has improved. reply owenpalmer 21 hours agoparentprevThe compelling reason for Apple is to show off their phone. Other than that, I can&#x27;t imagine the workflow on set is more effective. However, maybe the team enjoyed the process simply from the novelty and challenge of it. reply joshmanders 22 hours agoprevI love their commitment to walking the walk with the camera on the iPhone, but as this footage shows, while YES it is \"shot on an iPhone 15 Pro Max\" it also uses thousands of dollars worth of equipment that makes it hard for the average user to replicate similar quality. reply guptaneil 22 hours agoparentApple is showing that an iPhone Pro can be used by _professionals_ to replace their existing camera. It’s not trying to replace an entire studio (yet). That would be like expecting a new centrifuge machine to replace an entire lab of equipment. Nobody expects an average user to compete with professionals, even if they were given a $20k RED camera. reply skhr0680 22 hours agorootparent> Apple is showing that an iPhone Pro can be used by _professionals_ to replace their existing cameraIt still looks strictly worse than an equivalently priced $1000 camera+lens when directed, lit, operated, and edited by professionals. reply threeseed 21 hours agorootparentBe curious what the new $1000 camera is that has a 13-120mm lens, 48MP and is capable of shooting ProRes Log. reply diggan 21 hours agorootparentA Blackmagic Pocket Cinema starter bundle comes close, would be under 1500 but over 1000 USD. Gives you BRAW or ProRes, both log. Infinite more control over the captures, huge ecosystem of (professional) tooling and equipment that is compatible with it. reply chmod775 21 hours agorootparentThat&#x27;s already way more than you need to beat the iPhone. The iPhone can&#x27;t even capture 4k 60fps ProRes on device - you need to connect an external recording device to use that.Also note that, according to its datasheet, the iPhone cannot capture video on its tiny 48MP sensor at that resolution at all - just 4k. reply threeseed 19 hours agorootparentprevIt doesn&#x27;t come with a lens though. iPhone is f&#x2F;1.8 -> f&#x2F;2.8.Equivalent is maybe Sigma 24-70 which is constant f&#x2F;2.8 at an extra 1200 USD.So all up ~3x more expensive than iPhone. replynerdjon 22 hours agoparentprevSo I think the important question is though, if you had spent thousands on dollars on a camera would those lights still be required?If the answer is yes, then the feat is still an important one.I know that some lights would still be required, but I honesty don&#x27;t know the answer if they needed additional lights to compensate or if they could have gotten away with less. reply _aavaa_ 22 hours agorootparentYes the lights are very important. Lighting is more than just about “how much light there is”.Important considerations include where the light is coming from, how diffuse it is, and its color.Lights (or flashes for photography) get used even outdoors. Amateur outdoor headshots usually give the subject racoon eyes since the eyes are sunken in versus the eyebrows. Pros will get light on the face to get rid of that. reply jimkoen 22 hours agorootparentprev> If the answer is yes, then the feat is still an important one.I can recommend watching the Better Call Saul DVD documentary, they regularly have the lead lighting guy answering questions in there. The tl;dr was to me that yes, you definetely need additional lighting, even if your camera has a massive, light sensitive sensor.I don&#x27;t think anyone expects an iPhone to compete with a top of the line Arri 65 or other IMAX enabled cameras when it comes to low light performance (the sensor on these is huge after all), but the intro shot with Apple Park shows that it&#x27;s possible.Maybe don&#x27;t try to reenact a shooting of Barry Lyndon on an iPhone, but for nearly everything else it seems to work just fine. reply nateroling 22 hours agorootparentExplaining that semi-obscure reference: Barry Lyndon is a Kubrick film that famously has shots lit by only candlelight. This was accomplished by using extremely ”fast” lenses created by NASA for (I believe) the Apollo missions. reply threeseed 22 hours agorootparentLenses were custom Carl Zeiss 50mm f&#x2F;0.7.So yes extremely fast even with today&#x27;s technologies. reply itishappy 21 hours agorootparentThat&#x27;s insane!> After \"tinker[ing] with different combinations of lenses and film stock,\" the production obtained three super-fast 50mm lenses (Carl Zeiss Planar 50mm f&#x2F;0.7) developed by Zeiss for use by NASA in the Apollo Moon landings, which Kubrick had discovered. These super-fast lenses \"with their huge aperture (the film actually features the lowest f-stop in film history) and fixed focal length\" were problematic to mount, and were extensively modified into three versions by Cinema Products Corp. for Kubrick to gain a wider angle of view, with input from optics expert Richard Vetter of Todd-AO. The rear element of the lens had to be 2.5 mm away from the film plane, requiring special modification to the rotating camera shutter.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Barry_Lyndon> The lens was designed and made specifically for the NASA Apollo lunar program to capture the far side of the Moon in 1966.> In total there were only 10 lenses made. One was kept by Carl Zeiss, six were sold to NASA, and three were sold to Kubrick.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Carl_Zeiss_Planar_50mm_f&#x2F;0.7 reply twoodfin 21 hours agorootparentI often wonder wistfully what Kubrick might have done in the digital age of IMAX&#x2F;8K&#x2F;HFR. reply nerdjon 22 hours agorootparentprevMaybe I should have written the question better, since I know you would still need lights.But to me the important question is if it has any impact on the number of lights. If you still need all the same lights to use the iPhone that you would for a camera that is several thousand dollars. it is still really cool. reply tambourine_man 21 hours agorootparentprevI think you could shoot Barry Lyndon’s candle light scenes on iPhone just fine. The lens was custom made ƒ&#x2F;0.7 because the film was shot at ISO 100, IIRC.People forget how much more sensitive silicon is to light than film.Edit: got currious, it was ISO 100 pushed 1 stop during development[1]. So, since an iPhone&#x27;s ƒ&#x2F;1.78 main lens is ≈2.5 stops slower than ƒ0.7, using ISO ≈1200 should give you the same exposure (if shot at 24fps). Certainly doable.[1] https:&#x2F;&#x2F;neiloseman.com&#x2F;barry-lyndon-the-full-story-of-the-fa... reply crazygringo 21 hours agorootparentprevYes, lights are still required.But it&#x27;s not so much to compensate, just to ensure that your shot is lit the way you want, without the weird hard shadows and background-brighter-than-foreground problems that occur in your average space that hasn&#x27;t been specifically lit for film&#x2F;TV. reply stuff4ben 22 hours agoparentprevI mean just get a gimbal on your iphone 15 pro max and you&#x27;re pretty much there. A DJI Osmos 3-axis gimbal is only $150. reply kstrauser 22 hours agoparentprevI think what this shows is that it&#x27;s capable of being used at all for pro-level work. No, I don&#x27;t have all the nice gear that Apple has, but I can have the same camera.It&#x27;s similar to how they show MacBook Pro users making movies, doing AI work, processing huge datasets, etc. The message is that I don&#x27;t need to do all those things. But if I did, the computer would be good enough to do them.In the context of the iPhone&#x27;s camera, I&#x27;m not going to shoot an ad on one, but it&#x27;s clearly going to be good enough to take pictures of my vacation. reply randomdata 22 hours agorootparent> but it&#x27;s clearly going to be good enough to take pictures of my vacation.Is that clear? Even ignoring the form factor, I expect you would be quite disappointed casually shooting your vacation on a camera typically used on these types of shoots. reply kstrauser 21 hours agorootparentIt&#x27;s clear to me, perhaps because I don&#x27;t know enough about it to appreciate why I might be wrong. When it comes to cameras, I&#x27;m just a regular Joe who points my phone at stuff and then it shows up in Photos. More camera == more better, right? reply Moto7451 22 hours agoparentprevLike siblings comments have mentioned, the gear has always been part of the game. Before I was in software I did low budget videography. Lighting, audio, set equipment, editing, and the little bits that add extra quality have always been part of a good production. There are hacks to make equipment or repurpose things for the same effect as the expensive and nice hardware you’re seeing.One of the most common hacked together items is a steady cam rig. The simplest version is made from a couple iron pipes and an appropriate screw for your camera mount. reply jimkoen 22 hours agoparentprev> worth of equipment that makes it hard for the average user to replicate similar quality.Define quality. What I take away from the documentation is that you can replace iPhone&#x27;s in workflows that would have traditionally used a heavy and expensive film grade camera. The gimbals, rigs and software used the video are actually quite normal for professional video shoots and you&#x27;d see them in use with more expensive cameras as well. reply plussed_reader 22 hours agoparentprevThat&#x27;s always been part of the prosumer equation; kit to go around the digital lynchpin. It&#x27;s the void Digidesign&#x2F;Avid filled with the mbox series back when.Consumer --> Prosumer --> ProAka tacit endorsement of the incumbent &#x27;way things be.&#x27; reply steve1977 21 hours agoparentprevAlso interestingly, shot with the Blackmagic app. Not sure if they also used Davinci or FCP. But if they would have used FCP, I guess they would have mentioned it? reply geodel 22 hours agoparentprevSo if some rando is given millions dollar worth equipment they can shoot movie like James Cameron? reply altairprime 21 hours agorootparentBlue light gels are cheap, no need for millions of dollars. reply kube-system 22 hours agoparentprevThe equipment is nice, but it&#x27;s really the expert staff that make the difference. reply threeseed 22 hours agorootparentSure and now you can learn with nothing more than an iPhone and cheap LED lighting.Apple has massively reduced the barrier to entry. reply kube-system 18 hours agorootparentMost renowned filmmakers refined their skills before digital photography even existed. reply asimpletune 21 hours agoparentprevAll that equipment would be necessary for an ARRI as well. reply m3kw9 22 hours agoparentprevyou can likely jerry rig a cart and attach a tripod to it, not expensive, bottom line is that it is possible with the iPhone to film something like that. reply NelsonMinar 22 hours agoprevSee also a more skeptical take, emphasizing all the expensive studio equipment involved: https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;10&#x2F;31&#x2F;23940060&#x2F;apple-event-sho... reply hipshaker 22 hours agoparent“a great deal of fancy equipment — from drones, gimbals, dollies, industrial set lighting, and other recording accessories — is still required to make iPhone footage look this good.”But that’s just a standard requirement to make stuff look that good.Slap a cheap lens on an Alexa and light like an amateur and you will get a subpar video-result with the only redeeming factor being the sensor.And sure, the sensor (or medium) does matter, but production design and good lighting can be used to make almost any camera look great. I don’t think thhere’s anything wrong with that.Steven Soderberg shot a movie some years ago on an earlier iphone. Some of the shots were truly terrific because of attention to the above.You can copy or emulate a lot of high-end&#x2F;cinematic&#x2F;filmic looks quite affordably. For light you need output + size of light source, easily attainable on a budget. Good audio solutions also exist for reasonable $$. What you pay the most for when using expensive equpiment is more features related to interconmectedness and lifting some of the work in post-production, and durability. But it does not nescessarily translate to better images than what can be achieved by even bedroom-indie filmmakers reply elicash 22 hours agoparentprevYou can be skeptical of it like the Verge or impressed by it like some in these comments, but either way it&#x27;s good that Apple is showing you exactly what that means in practice.The transparency here is welcome and both Google and Apple should do something similar when it comes to the photographs they show off when rolling out new phones. They shouldn&#x27;t show a photo in those keynotes without also showing exactly what it took to get those photos out of those phones. reply threeseed 22 hours agoparentprevI think you and others have completely missed the point.Apple was always going to use that equipment. It&#x27;s needed for all decent video production work.What they&#x27;ve shown is that you can skip the Red Camera and use an iPhone instead. reply kemayo 22 hours agorootparentExpanding slightly on this, the cheapest Red Camera costs $6k (and I think might not include a lens?), so that&#x27;s a pretty big savings. reply FireBeyond 21 hours agorootparentOn this shoot? $100K+ of equipment, and that team?I can rent a RED camera and lenses for maybe $1000&#x2F;day ($3,000&#x2F;week).It&#x27;s not that big a savings at all, for one of the most pivotal parts to the process, is that where you want to be skimping? reply CodeBrad 21 hours agorootparentprevIs it though? How much does all the associated gear, operators, actors, sets, producers cost? In the context of professional video production, a one time savings of $6k seems pretty small. reply MBCook 21 hours agorootparentThe point is what the footage looks like. It’s about the camera output.An iPhone + good lighting + microphone will give you fantastic footage.You don’t need the drone or lift. If you’re not trying to do those effects they don’t matter. The iPhone can give you great results if you own one, you don’t need to buy a fancy camera, you can spend your budget elsewhere if you’re getting started. reply kemayo 20 hours agorootparentYeah, I think the real target of this kind of marketing is indie&#x2F;student filmmakers. People whose entire budget for a short film is a few thousand dollars they&#x27;ve pooled together. reply RockRobotRock 22 hours agorootparentprevHow are they missing a point? They only provided a link to a different take. reply ayoreis 22 hours agoprevInteresting that they used the Blackmagic Camera app instead of their own, maybe it&#x27;s finally time for an upgrade to the default one. reply sandofsky 22 hours agoparentThe first party camera is designed to be operated by every human being on the planet. Redesigning it to accommodate highend workflows makes as much sense as redesigning a $50,000 cinema camera to accommodate parents who want to record their kid&#x27;s soccer game. reply ayoreis 22 hours agorootparentI believe it could be designed in a way to accommodate both user groups. I don&#x27;t mind another app but they&#x27;ve always been paid (while writing this I checked and turns out Blackmagic camera is free, awesome!) reply sandofsky 22 hours agorootparentI think you should try designing such an app and report back your results. reply diggan 21 hours agorootparentprevMost software&#x2F;hardware goes for one group, as otherwise you&#x27;ll need to make sacrifices to equalize the experience. It&#x27;s just not feasible to build something that works as well for average joe as for a professional user, they use their tools differently. reply aalimov_ 22 hours agorootparentprevWith all of the emphasis they put on the iPhone cameras i think they have considered this and decided against it, at least for now. reply alberth 22 hours agoparentprevApple wants to demonstrate that an ecosystem exists of companies making Pro-Level software & solutions, just for Apple hardware.Historically, this has meant for the Mac.But it also includes iPhone. reply randomdata 20 hours agoparentprevPerhaps even more interesting, the behind the scenes video also suggests that most of the editing was done in DaVinci Resolve, not Final Cut Pro. reply nerdjon 22 hours agoparentprevI was honestly curious about that myself, I have generally just used the stock one but I am now curious if that one works better or has some better features. reply turnsout 20 hours agorootparentOne of the big advantages to the Blackmagic Camera app is that you can shoot Apple Log into an H.265 container rather than ProRes, saving huge amounts of storage space.It also has far better features for exposure, focus peaking, etc. It&#x27;s the same UI which is in Blackmagic&#x27;s actual cameras. reply cglong 22 hours agoprevA lot of people were asking why yesterday&#x27;s keynote wasn&#x27;t just a press release instead. I wonder if this was the actual point of the presentation. reply alberth 21 hours agoparentAnd having the event early evening (which is super odd for a press event), to demonstrate the low-light capabilities. reply MarkusWandel 22 hours agoprevGenuine question, since I&#x27;m not part of the Apple ecosystem and my smartphones tend to be from the low end of the range.Even my humble one takes great pictures and video, but the touch-screen UI is really limiting. Whereas professional movie camera work has smooth pan&#x2F;zoom work that, at least until now, was done with appropriate controls. Do professionals using a slab phone have external pan&#x2F;tilt&#x2F;zoom&#x2F;focus rigs that they can plug in as an accessory, or do they have to do all that via the touchscreen UI? reply lbourdages 21 hours agoparentIf you watch the video, you can see that they have a big rig with like a gimbal and external controllers and screens. So it&#x27;s not \"just an iPhone\" but it&#x27;s also not a $50k+ pro camera body. reply hnburnsy 21 hours agorootparentHow do the external controllers interface with the third party camera app? How.much do these controllers cost? reply FemmeAndroid 21 hours agorootparentI think a lot use separate apps. I had a gimbal that I used to use with an old iPhone with buttons to move the gimbal and direct the phone, but also with buttons to start&#x2F;stop recording, and do other things without touching the phone itself. This gimbal was in the $300-$500 range. reply brianpan 21 hours agoparentprevLook at pretty much any one of the pictures in the article for your answer.No professional camera, iPhone or not, isn&#x27;t in a rig&#x2F;harness&#x2F;on a trolley etc. That&#x27;s for pan&#x2F;tilt&#x2F;push in&#x2F;pull out. For controlling camera settings&#x2F;zoom&#x2F;focus, the article says they are using Blackmagic Camera. reply spacedcowboy 22 hours agoprevVincent is an awesome guy - I met him when I was a manager on Aperture, and sweet-talked him into being my wedding photographer. reply y04nn 21 hours agoprevA major problem with telephone cameras, including the iPhone (not sure for the last model), is that they suffer from very notable reflections of light [1] which are very distracting. Dealing with this on a set must not be easy.[1]: https:&#x2F;&#x2F;discussions.apple.com&#x2F;thread&#x2F;251977011 reply masto 21 hours agoprevI think that explains why they did this one at night and it had that same annoyingly dark look as modern streaming shows. \"Look, our phone makes it possible for the best DPs and colorists in the world to produce the same unwatchable dimness as they could with cameras costing orders of magnitude more!\" reply residentraspber 21 hours agoparentYes! I recently watched Hello Tomorrow during the day and had to turn up the brightness on my TV to make out some of the scenes. Day or night shots in the show didn&#x27;t matter, it was all too dark and pale looking.Watching the same episode at night for me was a much nicer experience.~4 yr old 4k Samsung Smart TV with all the motion blur and vivid stuff turned off. reply kuschku 21 hours agoprevI&#x27;d love to see what they did to work around the framerate issues. iPhones record in variable framerate (they just encode one frame, once that&#x27;s fully encoded read the next frame and repeat). This leads to fps varying by up to ±10%, which causes a lot of issues with most editing software. reply mnemoni_c 21 hours agoparentThat&#x27;s why they used third party app to control ISO and shutter speed I presume reply kuschku 21 hours agorootparentEven the BMD camera app — at least the version that&#x27;s publicly available — can&#x27;t work around those limitations. It still records footage in VFR. reply oittaa 21 hours agorootparentprevhttps:&#x2F;&#x2F;twitter.com&#x2F;MKBHD&#x2F;status&#x2F;1719384434041090452MKBHD says it was a camera app from BlackMagic. Their software Resolve is used in professional movies, but for some reason it&#x27;s also available for free with some minor limitations. I&#x27;ve used it when I needed quickly combine some simple video clips and it was really intuitive use. Though the color grading and other advanced tabs looked scary to a noob :) reply Tepix 21 hours agoprevThe iPhone 15 Pro Max costs more than 1400€. You can get a nice \"real\" video camera for that money! Now, the iPhone has the advantage of being always available (without all the pro gear that Apple used). But in the case of a production like this, that&#x27;s not relevant.My guess is that most upcoming filmmakers on a budget will continue to other options such as Blackmagic cameras. reply TimTheTinker 22 hours agoprevSince editing tools weren&#x27;t mentioned, I suspect they must have used DaVinci Resolve or similar, instead of Final Cut Pro and Motion. reply randomdata 20 hours agoparentSeems like a reasonable suspicion. The behind the scenes video shows use of DaVinci Resolve throughout. reply someNameIG 20 hours agoparentprevWhy do you think so? reply TimTheTinker 1 hour agorootparentIt was a guess, based on what so many editors in Hollywood use. The \"behind the scenes\" video confirms it though - yes, they were using DaVinci Resolve.I hope Apple takes that as a shot across the bow -- they need to up their game with FCP and its ecosystem, if the contractor they hired to produce an Apple event shot on iPhone and edited on Mac doesn&#x27;t even use FCP. reply ggoo 22 hours agoprevWhat did they shoot the behind the scenes with though? reply aresant 22 hours agoparenthttps:&#x2F;&#x2F;np.reddit.com&#x2F;r&#x2F;motorcycles&#x2F;comments&#x2F;5v1j2i&#x2F;my_water... reply LesZedCB 22 hours agorootparenti believe this is &#x27;the original&#x27;https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;AskReddit&#x2F;comments&#x2F;cmwov&#x2F;comment&#x2F;c0... reply whalesalad 22 hours agoparentprevone of those kids tablets in the blue rubberized shell with built-in handle that is covered in sticky apple juice and smells like earrings reply eigenvalue 22 hours agoprev“The production was advised by Apple’s Jon Carr, a Pro Workflow video specialist whose credits include Top Gun: Maverick and Terminator: Dark Fate, and Jeff Wozniak, who has worked on productions including Transformers: Dark of the Moon, Avatar, and Iron Man 2.”I can’t even imagine how annoying it must be for that guy to be working with Apple on stuff with the last name Wozniak and to have everyone whispering around him “is he related to Steve??”. It’s an uncommon enough name that it’s not an unreasonable supposition.I bet people are really nice to him just in case! reply kaugesaar 21 hours agoprevGood on them for walking the walk. But I genuinely believe you could, with that equipment, get the same footage with a 10-year-old dslr-camera and its stock lens for just a few hundred bucks. reply alberth 22 hours agoprev0m 39secThis is definitely a nitpick…Presuming they also shoot this behind the scenes video with an iPhone as well, the video quality is out-of-focus for the individual on the right at 0m39s.Look how the right side of their face is fuzzy, not well defined.https:&#x2F;&#x2F;ibb.co&#x2F;xLKZkQ8As an aside, I do appreciate Apple bringing Pro-Level functionality to the masses. reply neilv 22 hours agoprev\"Yeah, uh, we&#x27;re just gonna crop out the SpaceCam logo. The doomscroller surveillance handheld is the star here.\" reply RomanPushkin 22 hours agoprevI wish somebody can tell me what was wrong with the video being shot on iPhone, is it visible for a professional eye that it is iPhone? I was always told that the lens and matrix size is everything. Have things changed dramatically since the time you could only make a good shot on a full-frame DSLR? reply mholm 22 hours agoparentIt&#x27;s noticeable if you&#x27;re specifically looking for it, but much harder to tell. Log color makes a huge difference, and the equipment they&#x27;re using around the iPhone, along with the editing (and now better color grading) really close a lot of the gap. reply brokencode 22 hours agoparentprevWho said there’s something wrong with it? I’ve mainly been seeing people be impressed that they didn’t notice. reply astrange 22 hours agoparentprev\"Full frame DSLRs\" were not ever the cameras that took the best pictures, they were just the top end prosumer for a while. Mirrorless are somewhat better than DSLR now, rangefinders always were if you were into Leica, and medium format or large format have always been better than full frame. reply chazeon 21 hours agoparentprevLens and matrix size is everything when you cannot control the environment, when you can change the lighting and design the scene, then you can make up for the smaller sensor. reply baz00 22 hours agoparentprevThe camera is ok.The difficult bit is the expensive rig + post processing software + extensive skills required to get this result. reply asimpletune 21 hours agoparentprevReally it’s the lighting that’s everything. reply t0bia_s 20 hours agoprevSo you have professional set with high tech tools like cranes, gimbals, LED panels... And shoot on iPhone.Why this doesn&#x27;t make any sense? reply tambourine_man 20 hours agoprevWhile watching the presentation, I found the faces a bit too sharp, but I was watching on a different, newer screen, which I imagined had a higher pixel density than the one I&#x27;m used to everyday.But I just checked and the difference is neglectable (224 vs 218 ppi), so my guess is the over-sharpening of the iPhone.Not that it was bad, just different enough to be noticeable. reply flakiness 22 hours agoprevThis is a super impressive tech-demo. Not practical for us consumers (who don&#x27;t have expensive pro-level equipment surrounding the phone-camera), and not meaningful for professionals (who would just use a normal camera), but it is still a pure technical achievement that deserves a look and a cheer. reply GoToRO 19 hours agoprevThe iphones have horrible lens flares. The editing is a necessity. reply inparen 22 hours agoprevIs this really that big deal ? Soderberg already shot two movies on iPhone. reply altairprime 22 hours agoparent(Soderbergh.) reply kart23 21 hours agoprevokay apple, take your wallpaper photos on iphone also. reply hnburnsy 21 hours agoprev-1 for Apple for using a third party app to capture the footage. I dont have an iphone so how do they control the camera app without touching the screen? reply chr-s 9 hours agoparentOne of the stills [0] shows a Tilta Nucleus-M focus&#x2F;zoom wheel [1], see it in use on https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Yx5s0M-_ib4[0] https:&#x2F;&#x2F;www.apple.com&#x2F;newsroom&#x2F;images&#x2F;2023&#x2F;10&#x2F;behind-the-sce...[1] https:&#x2F;&#x2F;tilta.com&#x2F;shop&#x2F;nucleus-m-fiz-unit&#x2F; reply rconti 22 hours agoprev> the preferred smartphone for creative pros and filmmakers.Upon reading that, I immediately looked at the domain of the source. I know, I should be in this habit BEFORE reading anything, but still. reply _factor 22 hours agoprev [–] This could have been accomplished with an iPhone 8 years ago. For a keynote that 99.9% of the population will watch on YouTube, what is this trying to prove? It&#x27;s an interesting demonstration, that&#x27;s about it. reply empath-nirvana 22 hours agoparentIt&#x27;s amazing how quickly people get acclimated to what are basically miraculous technological advancements.So much of what people have been doing matter of factly on iphones daily for years was just pure science fiction when I was a kid. reply artimaeis 22 hours agoparentprevAn iPhone 8 years ago (iPhone 6S released Sep 2015):- Is limited to a 12MP sensor (15 Pro has 48MP on the main sensor)- Can only shoot 4K SDR at 30fps- Cannot shoot ProRes LOG modeYou could absolutely get a great video with an iPhone 6S. Soderbergh shot all of Unsane with an iPhone 7 and FiLMiC Pro. But comparing the video quality from Unsane to this clearly shows how far the iPhone has come.It&#x27;s an interesting demonstration. That&#x27;s all it ever needed to be. reply threeseed 22 hours agoparentprevNo it couldn&#x27;t be accomplished with anything other than iPhone 15 Pro.It is the only one to support ProRes with the Log profile.Without it it&#x27;s not possible to do decent video color grading. reply m3kw9 22 hours agoparentprevwouldn&#x27;t get the low light and dynamic range, if you&#x27;ve ever used an iphone to take pics 8 years ago reply blairbeckwith 22 hours agoparentprev [–] Consider that all it was trying to prove was that it was an interesting demonstration. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The \"Scary Fast\" event by Apple was filmed using the iPhone 15 Pro Max and edited on Macs to display the capability of their technology. The event introduced the new MacBook Pro and 24-inch iMac, both equipped with the M3 chip family.",
      "iPhone 15 Pro Max, for the first time in a smartphone, supports the Academy Color Encoding System (ACES), enabling users to capture ProRes video up to 4K60 with Apple Log encoding.",
      "The event also emphasized the ability of the new iPhone's USB-C connector in fast data transfer, direct recording to an external SSD drive, and improved camera capabilities for low-light performance and color grading flexibility in post-production."
    ],
    "commentSummary": [
      "Apple's recent event sparked a debate over the iPhone's capabilities as a professional camera, following a demonstration of its video function.",
      "Critics argue that professional-level videography necessitates expensive additional equipment and post-production work, making potential savings on using an iPhone minimal.",
      "Supporters highlight the device's portability and ease of use, potentially making it a viable option for low-budget films or independent projects."
    ],
    "points": 171,
    "commentCount": 140,
    "retryCount": 0,
    "time": 1698769957
  }
]
