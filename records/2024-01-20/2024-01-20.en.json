[
  {
    "id": 39063242,
    "title": "Discovering a Mysterious Touchscreen: Unveiling an Energy Monitoring System and Its Hidden Functionality",
    "originLink": "https://laplab.me/posts/whats-that-touchscreen-in-my-room/",
    "originBody": "Discussion on HackerNews and Lobsters. Roughly a year ago I moved into my new apartment. One of the reasons I picked this apartment was age of the building. The construction was finished in 2015, which ensured pretty good thermal isolation for winters as well as small nice things like Ethernet ports in each room. However, there was one part of my apartment that was too new and too smart for me. This thing: It is obviously a touchscreen of some sort, but there was zero indication as to what it controls. The landlord had no idea what this is. There are no buttons or labels on the thing, just a tiny yellow light to let you know it has the power. I had a million questions, but I was too busy with the move and kinda of forgot about it until about a week ago. I was looking through a huge binder of various appliance manuals for my apartment when this thing slided out: Wait a second, that’s my touchscreen! Turns out it is a part of an energy monitoring system, which tells you current energy usage and has the ability to display historical data. That actually sounds pretty neat - I would be interested to see energy usage patterns of my house. Brochure also mentioned a second part of the so-called “energy manager”, which was directly plugged into an electricity meter to get usage information. I went to inspect communal cupboard housing electricity meters - and sure enough, there it was, just standing in the corner. I never even noticed these boxes before, but they at least have the same branding as the brochure - some company creatively named “NETTHINGS”. Pretty straightforward so far. We have two devices, one “server” gathering the data and another one “client” reading the data. Now the distance between them is actually very short - just a few meters and maybe 2-3 walls, totally reasonable setup for a cable connection. It was at that moment when I noticed a weird sticker in the corner of the brochure. There were two strings printed with labels “SSID” and “Pwd”. I froze in horror. They wouldn’t dare. It is literally 3 meter distance. These are embedded devices, they do not need this complexity… And of course the two devices communicate using WiFi. Now that was unusual for me, since I am not an embedded developer. But a friend of mine, who worked on smart home features for one voice assistant told me that this is actually a pretty common thing to do in IoT space. C in IoT stands for “cost-effective” I guess. Moving on, I needed to somehow turn on the weird touchscreen. Upon closer inspection, I noticed a small hole on the side, which looked a lot like something you insert a pin into to reset the device: I held a hidden button with a wire for a few seconds and was greeted by…an Android bootup logo! Yes, this turned out to be in fact an Android tablet, and a pretty old one at that. It has Google Talk, Flash and all kinds of other interesting stuff pre-installed: From what I can tell, this is an Android 5, but I am not exactly sure. One of the apps stands out with a familiar name: “NetThings”. Launching it leads us to the screen where we select a WiFi network. Unfortunately, the one that is mentioned on the brochure, was not on the list. I double-checked the list, tried to refresh it, looked for WiFi networks using my other devices, tried to directly connect to the WiFi using the credentials, but no luck. When I came back to the meter room I noticed the obvious: boxes for all other apartments had the light on, but mine was off for some reason: I live in the UK and if anything, this is a country of electrical fuses. The more fuses the better, everything is fused, even some plugs. Fuses for certain appliances come in separate boxes with a small drawer that can slide out, allowing to replace the fuse. It looks like this: As you can see, my fuse box did not have a fuse inside for some reason. No fuse - no electrical connection, no power for the energy manager and no WiFi hotspot. Thanks to the fuse box design, it is easy to replace one, but I did not know what kind of amperage should be allowed in the circuit. Luckily, I had a few working energy managers in the same cupboard, so I opened their boxes (cutting the power to them for a few seconds) to see what kind of fuses they use. Turns out, I need a 3A fuse, so I ordered one from Amazon and installed it the next day. To be honest, the whole thing was a bit scary, since I was very close to the mains. After installation, I checked the temperature of the fuse multiple times during the day to get at least some indication that things are not going to get worse. It worked fine for a more than a week now, but I still do not recommend experiments like this to anyone. After installing the replacement fuse, energy manager started blinking with green LEDs and the promised WiFi network appeared on all devices. Once I selected the network on the Android tablet, it changed to the following screen: When tapped, it changes to this menu, inviting the user to select what kind of resource they want to monitor. Nothing here actually works except for “Mains Electricity” because that’s the only meter the energy manager is hooked up to. “Mains Electricity” leads us to the most dissapointing screen in the history of UX design: Ugh, where to start. What’s up with this color indicator on the right? What does the vertical position mean? If it is green, does it mean that I am using a small amount of electricity or just a normal one? What exactly is small? If it gets all the way to the top, is it compared to my historical maximum usage? Over what period of time? Out of 5 numbers displayed to the left of the indicator, only one is actually true - number of kW consumed. All other numbers depend on the energy provider and definitely changed since the time this monitor was installed. I saved best for last. The amount of money you pay as well as estimate of CO2 per kW is not configurable. According to the brochure, it was configurable during the initial installation, but it has no information on how to reset the system back into configurable state. Finally, brochure says the following: I have no idea why they decided to include this. Of course the clock on Android tablet shifted by almost 15 minutes since 2015, when it was supposedly installed. The whole thing was quite dissapointing. However, I do have a few Raspberry Pico microcontrollers lying around at home. If I could connect to the WiFi network of the energy manager directly and get the data from the server, I could just extract kW consumption from the API, multiply it by a correct rate and then display it on some Grafana instance. The main problem was that I do not know the IP of the server. I was just about ready to launch a full IP scan from laptop when I noticed that one of the use cases brochure advertised is checking the energy usage from the PC. The IP and port were conveniently provided together with the instructions. Opening it in the browser displays a familiar screen: Turns out, interface on the Android tablet is just a webview. This makes our job that easier, since we can just go to the web inspector and see all the API calls. Looking at the URLs we see… …Socket.IO! Wow, I honestly did not expect that. Client literally needs to receive 5 numbers from the server, Socket.IO seems to be a complete overkill for this usecase. The client code also looks very complicated for what it does. There are at least 6 RequireJS modules, all loading dynamically through different requests of course. There is Handlebars, Backbone.js, Underscore.js… I feel like I am in high school again. These are all technologies I was very interested when I just started web development. But wait a second, Socket.IO would mean that an embedded device in my meters cupboard is running JavaScript? This must be weirdest Edge Computing Platform I have seen in my life. I want to deploy something there! Totally forgetting the idea with Raspberry Pico fetching the data from the server, I put on my hacker hat and started poking around. IoT devices have a terrible reputation from the security perspective, so I expected it to be an easy run for a couple of hours tops. Boy was I wrong. Direct SSH using ssh root@172.16.0.254 immediately fails with “Connection refused” error. That could mean a number of things, let’s see which ports are available: $ sudo nmap -p- -sV -O 172.16.0.254 ... truncated output ... Nmap scan report for 172.16.0.254 Host is up (0.011s latency). Not shown: 65530 closed tcp ports (reset) PORT STATE SERVICE VERSION 53/tcp open domain dnsmasq 2.63rc6 80/tcp open http Node.js (Express middleware) 1534/tcp open micromuse-lm? 3000/tcp open http Node.js (Express middleware) 41142/tcp open ssh OpenSSH 6.2 (protocol 2.0) Now this is interesting. As expected, we see a Node.js server running. We also have dnsmasq, which is a DHCP server (makes sense, since the device is a WiFi access point) and a hidden SSH server on port 41142. SSH connection is no longer refused, but the root turned out to be password-protected. None of the simple username/password combinations like admin/admin or root/root worked, so we are essentially back to square one. However, nmap detected an unrecognized service on port 1534 called micromuse-lm. The first Google result is the following forum post: I do not know who you are @ljohnson, but may your life be happy and prosperous. This post does not give a lot of information, but it provides one with the correct keywords to continue the search. The main phrase here is tcf-agent. The concrete description of what is going on here is spread atom-thin across several websites, all of which expect you to know the terminology. Each of these websites provides you with a tiny piece of the puzzle and you are expected to combine it together on your own. So after a few hours and lots of cursing, here is what I know about tcf-agent: TCF stands for “Target Communications Framework”. It is a text protocol, which allows to read the filesystem, start new processes, send signals to processes and a lot more with the target system. tcf-agent is the server implementing this protocol or, in another words, probably the second biggest security vulnerability after passwordless root SSH. I do not understand why they went into all this trouble with SSH passwords, but kept tcf-agent running. TCF seems to be closedly tied to Eclipse ecosystem. The Getting Started guide suggests several plugins for Eclipse as the main way to interact with tcf-agent. I tried installing these plugins on a new version of Eclipse and it is absolutely impossible. There are dependency issues everywhere and when you actually try to install the missing dependencies, Eclipse does not let you because they conflict with some other dependencies. It’s a mess, which is exactly how I imagined this interaction to go. Conveniently, TCF project has a Python SDK. As with everything during this research, I needed to go through 3 links on different websites to actually find one. First, we are met with this lovely page: Which has a link that leads to here, which has a very small text pointing out that the repo moved to this Gitlab repository. Phew. The repo even has a few fresh commits, which seems a bit suprprising to me, as TCF in general gives off vibes of an abandoned project. Nevertheless, the repository contains a pretty modern Python 3 (!) SDK, even with some inline documentation. It is not perfect, some docs are outdated, some methods are very weird, but you can pretty easily figure out what’s going on from the code. Protocol specification here and here are a huge help in this process. In a nutshell, a tcf-agent provides a bunch of services that expose various parts of the system. For example, there is a FileSystem service for all interactions with the filesystem, Processes service for starting/stopping/debugging processes, etc. Here is an example of getting current user information: import tcf from tcf.util.sync import CommandControl tcf.protocol.startEventQueue() cmd = CommandControl(tcf.connect('TCP:172.16.0.254:1534')) error, user = cmd.FileSystem.user() print(user) And that’s how we learned that tcf-agent, in fact, runs under the root user. Again, why bother with SSH passwords if you leave a debug server with root access - this I will never understand. FileSystem and Processes services have other functions, roughly corresponding to syscalls. You can pretty easily replicate alternatives to common commands like ls, cat, ps and the like using this API. Now I say “pretty easily”, but in reality that was 4 hours of guessing the protocol format, trying to the find the documentation, fixing bugs in the SDK, all on an extremely unstable WiFi connection from an embedded device. Fun times. You can find the results in this Github repo. Now that we have basic instruments, let’s get to hacking! My first attempt was to crack the root password, as I still believed it was something trivial. I used John the Ripper password cracker in the following way # `cat.py` fetches file contents from the energy manager # using `FileSystem` TCF service. $ ./cat.py /etc/passwd > passwd.txt $ ./cat.py /etc/shadow > shadow.txt $ unshadow passwd.txt shadow.txt > passwords.txt $ john passwords.txt I left it running for roughly 7 hours, but it did not find a match. John reported that it will finish its brute-force in the year 2035, so I decided to try out a different approach. After a bit of Googling, I found out that one can simply make root’s password empty by modifying /etc/shadow. Having done just that, I powercycled the device by removing the fuse I installed previously and putting it back after some time. Unfortunately, SSH still rejected my login attempts. More out of desperation than anything else, I decided to look at sshd config of the host and finally found the offending line. sshd_config had PermitRootLogin no line included, which is a very sensible security measure as long as you are not providing a full disk access to anyone on the network. I replaced the line with PermitRootLogin yes and finally, I saw the output I was struggling for: We are in! God, that was quite a journey, wasn’t it? Let’s look around! root@nt-core:~# uname -srm Linux 3.10.28 armv5tejl We can see that we are running Linux 3.10, which is actually quite a recent release (middle of 2013), considering this device was developed and installed roughly in 2014-2015. Unsurprisingly for an embedded device, it is powered by an ARM chip: root@nt-core:~# cat /proc/cpuinfo processor : 0 model name : ARM926EJ-S rev 5 (v5l) BogoMIPS : 226.09 Features : swp half fastmult edsp java CPU implementer : 0x41 CPU architecture: 5TEJ CPU variant : 0x0 CPU part : 0x926 CPU revision : 5 Hardware : Freescale MXS (Device Tree) Revision : 0000 Serial: 0000000000000000 We have an ARM9 family CPU. Wikipedia says that it was released in 2001, with a list of notable mentions including being a coprocessor for Nintendo Wii. The fact I find even more surprising is that this processor supports executing Java bytecode directly. Yep, you read that right, the java in the list of CPU features actually means that Java. The ARM extension for this feature was called Jazelle. This seemed to be some kind of a trend around 2000s, since this is not the first time I encounter such feature. root@nt-core:~# cat /proc/meminfo MemTotal: 118172 kB ...truncated... Lastly, we have 118MB of RAM. I am not an embedded Linux expert, but this does seem like a lot after tinkering with Raspberry Pi Pico and such. At the same time, it makes sense, since we do have a Node.js app running on the host and JavaScript isn’t exactly a memory-efficient language. The app itself is quite a sizeable codebase. Despite the fact that the company that made the device and software for it is already dissolved, I don’t want to risk being sued over releasing the source code. I am pretty sure nobody would actually care, but I still want nothing to do with it. So instead we will just look at some file lists. Top-level directory structure looks like this: root@nt-core:/srv/server# ls -la drwxr-xr-x 13 nodejs nogroup 4096 Oct 23 10:47 . drwxr-xr-x 3 root root 4096 Oct 14 12:13 .. -rw-r--r-- 1 nodejs nogroup 8125 Oct 14 12:13 Gruntfile.js -rw-r--r-- 1 nodejs nogroup 1916 Oct 14 12:13 app.js drwxr-xr-x 2 nodejs nogroup 4096 Oct 14 12:13 app_data drwxr-xr-x 10 nodejs nogroup 4096 Oct 14 12:13 bin -rw-r--r-- 1 nodejs nogroup 1278 Oct 14 12:13 bower.json drwxr-xr-x 2 nodejs nogroup 4096 Oct 23 10:40 info -rw-r--r-- 1 nodejs nogroup 16 Oct 14 12:13 jira_version -rw-r--r-- 1 nodejs nogroup 2673 Oct 14 12:13 karma.conf.js drwxr-xr-x 2 nodejs dialout 4096 Oct 23 10:49 logs drwxr-xr-x 4 nodejs nogroup 4096 Oct 14 12:13 modules drwxr-xr-x 17 nodejs nogroup 4096 Oct 14 12:13 node_modules -rw-r--r-- 1 root root 0 Oct 23 10:40 nodejs.log -rw-r--r-- 1 nodejs nogroup 76023 Oct 14 12:13 npm-shrinkwrap.json -rw-r--r-- 1 nodejs nogroup 2216 Oct 14 12:13 package.json drwxr-xr-x 6 nodejs nogroup 4096 Oct 14 12:13 production drwxr-xr-x 6 nodejs nogroup 4096 Oct 14 12:13 public drwxr-xr-x 4 nodejs nogroup 4096 Oct 14 12:13 routes drwxr-xr-x 3 nodejs nogroup 4096 Oct 14 12:13 scripts drwxr-xr-x 4 nodejs nogroup 4096 Oct 14 12:13 views From what I could figure out, the app consists of two parts. The first part is responsible for actually reading usage data from the electricity meter connected to the device. This part is called a “Pulse app” and its binary is located in the bin folder: root@nt-core:/srv/server# ls -la bin drwxr-xr-x 10 nodejs nogroup 4096 Oct 14 12:13 . drwxr-xr-x 13 nodejs nogroup 4096 Oct 23 10:47 .. drwxrw---- 2 nodejs dialout 4096 Nov 16 00:12 aggregate drwxrw---- 2 nodejs dialout 4096 Oct 23 11:03 cfg -rwxr-xr-x 1 nodejs dialout 52418 Oct 14 12:13 ct-read-daemon drwxrw---- 2 nodejs dialout 4096 Nov 16 01:00 daily -rwxr-xr-x 1 nodejs nogroup 1155 Oct 14 12:13 get_sys_versions.sh drwxrw---- 2 nodejs dialout 118784 Nov 16 03:00 hourly drwxrw---- 2 nodejs dialout 4096 Nov 1 01:00 monthly drwxr-xr-x 2 nodejs nogroup 4096 Oct 14 12:13 output -rwxr-xr-x 1 nodejs dialout 34543 Oct 14 12:13 pulse-app -rwxr-xr-x 1 nodejs dialout 117029 Oct 14 12:13 pulse.ko -rwxr-xr-x 1 nodejs nogroup 758 Oct 14 12:13 reset_nrg_mgr.sh drwxrw---- 2 nodejs dialout 4096 Nov 16 01:00 weekly drwxrw---- 2 nodejs dialout 4096 Oct 23 11:00 yearly Judging from the debug symbols, my initial guess was that this is a regular C appication, which seems appropriate for the task of interacting with low-level GPIO pins. However, pulse.ko file got me interested. .ko extension usually means “Kernel Object”, which would suggest that this is actually a kernel module. I do not know a first thing about kernel modules, so I might be wrong here. Pulse app reads the data from the GPIO pins and stores the results in CSV files. These CSV files are split by month, day and hour in the directories with the respective names, still in the bin folder. Such separation is no coincedence. Historical data view in the web UI of the energy manager supports displaying the data only by month, by day and by hour. Along with the Pulse app, there is the second part of the application. A Node.js app reads CSV files populated with energy usage data and displays them to the user in the web UI. It uses Node.js 0.10.26, Express.js 4.13.3 and Socket.io 1.3.6. Scrolling through the dependencies, I noticed an mqtt package. This was intriguing, because I did not see any message broker interaction until now. After reading the sources for a little while, this seemed to be an unfinished cloud integration that Netthings promised in their brochure. There are even some hardcoded IPs mentioned in the source, which are used to connect to a message broker. Unsurprisingly, none of them are up any more. I am not even sure how that would work, since the device does not have an internet access. All in all, this was a very fun investigation! I grew accustomed to calling it “my urban archeology project”. I now have access to one of the weirdest Edge Computing platforms imaginable. If you have any fun ideas on what to do with it, feel free to drop me a line at hi@laplab.me! P.S. As a final touch, I decided to leave a small note in the home directory. It’s kind of weird to realise that I am probably the only person who would actually read it. But maybe in some distant future another software engineer will live in this apartment and discover it. Time will tell :)",
    "commentLink": "https://news.ycombinator.com/item?id=39063242",
    "commentBody": "What's that touchscreen in my room? (laplab.me)706 points by todsacerdoti 9 hours agohidepastfavorite205 comments jonathanlydall 2 hours agoA few years ago I came to the realisation that if you want people to be more environmentally conscious or economical in terms of utility consumption, (electricity, water, gas, etc), they need far better data than a single figure per month. You want to be able to see usage to a resolution of at most 5 minutes. That way people can spot things like “having my electric heater on for those couple of hours used more electricity than all my lights use for a month”. I have an inverter and solar panels in my place (very common now in South Africa middle class homes due to unreliable electricity producer) and I can see a full history of electricity usage. It’s easy for me to see where I can improve my efficiency or why my consumption was so high. It’s still only an overall figure though, so you have to do an informed assumption as to what caused the consumption. For example it’s obvious that the 3kw draw for about an hour or so after I shower is the geyser heating itself back up. I can see from the usage stats that my battery was depleted from the night, that the solar production is still low due to my showering in the early morning and that the energy was thus coming from the grid (the inverter records all these figures). It is then obvious that I can very simply save money on electricity by putting a timer on my geyser so that it only heats after 10am or so, once the sun is high enough for solar production to cover the energy usage. Now I just wish I had something as convenient for monitoring water consumption. reply lloeki 38 minutes agoparentPer device energy tallies also give you interesting data. Home Assistant can do that in the Energy dashboard, and you can answer questions/learn surprising things, like how much energy my \"rack\" (UPS+mac mini+5 disk bay+a few other things) actually uses vs e.g my fridge or my washing machine, or my desk compute actually is quite low but boy does the screen costs a lot when active, or what does charging the electric bike costs, or what's the effect of setting thermostat to 19 instead of 20 in winter, or oh wow in summer this fan that we use a lot to make things bearable actually ends up using as much energy as our water heater! (power measurements are done using Shelly Plug Plus S + 3EM + 4PM devices, thermal measurements using Shelly H&T Plus) reply bradley13 1 hour agoparentprevBeing able to see your usage is helpful - at least, for those of us interested. For example, I was surprised to see how much our electronics (stereo, amplifier, TV, etc.) in the living room use, even when off (some devices are older, with high standby currents). It motivated me to put everything on a timer that only turns power own in the evenings, since that's the only time they get used. It's a small thing, but small things add up. reply wolpoli 8 minutes agorootparent> It motivated me to put everything on a timer that only turns power own in the evenings, since that's the only time they get used. I was surprised to learn that a timer itself also uses power. I borrowed a Kill-a-watt from the library and found that an 2 decades old timer uses 2.3W while a newer one uses 0.6W. That tells me that I should just keep the old timer for the rare occasions. reply gambiting 43 minutes agorootparentprevYeah we were away from home recently and it was interesting to see that with everything \"off\" we were still using a constant 200W or so, so even with no one home we used just over 4kWh each day. 120kWh each month just for \"idle\" usage definitely is not trivial amount of money, at current prices that's £20! reply calvinmorrison 1 hour agorootparentprevNot when you're on solar. Its more akin to being poor and shopping at dollar tree - cash/solar flow is more important than total cost. reply isoprophlex 2 hours agoparentprevAbout water consumption: depending on your make of water meter, there's often a small reflective wheel that turns eg. once for every liter. Sometimes these are made out of metal or even slightly magnetic. An arduino with an optical or Hall effect sensor might get you real far in real time, high resolution data collection! Alternatively I've had success in wiring up a temperature probe directly to the incoming water line, and comparing that temperature to the ambient temperature. Where I live that works because the water arrives from underground & is always much cooler than ambient air. The time-integrated difference between the two is a proxy for how much water you use... this is much more involved to get meaningful data from, tho. --- Edit: a proximity sensor that detects metal might be the most straightforward thing, if you have a water meter with a rotating metal gauge https://www.alldatasheet.com/view.jsp?Searchword=LJ12A3-4-Z/... reply cricalix 2 minutes agorootparentOn mobile so hard to link, but memory says OpenEnergyMonitor's docs site on pulse counters has a computer vision approach too. Think it reads the numbers from the display. reply failingslowly 1 hour agoparentprev> if you want people to be more environmentally conscious [...] they need far better data This is one of the reasons all UK homes are being fitted for free with smart meters. (There are others, such as enabling better grid control.) > You want to be able to see usage to a resolution of at most 5 minutes. My one updates every few seconds and has a set of traffic light LEDs at the bottom giving a visible guide to energy use. https://www.edfenergy.com/smart-meters/using-a-smart-meter/c... reply gambiting 48 minutes agorootparentWe have one as well, but since we're on a variable rate tariff(Octopus Tracker) it's completely useless - it doesn't know the current electricity/gas price, it seems to receive rate updates from the network about once every few weeks - so the numbers it displays are just wrong. I've made my own little Raspberry Pico display that queries today's energy prices and shows those, but I have not been able to show today's energy consumption alongside(and therefore show the day's cost so far). Octopus provides an API to query the kWh used....but only for the last day. I even got their little Octopus Mini that broadcasts live usage to their app but I have not been able to query the live data from it from my raspberry, I don't have the necessary skills in web technologies to do that unfortunately :-( reply jonathanlydall 34 minutes agorootparentprevAs evidenced by the article, the problem is that some of these devices within less than 10 years can become essentially bricks. I think these devices must be required to send the data to the utility company and the utility company must be forced to make the data easily accessible in a standard format so that independent analysis is trivially possible. This way you don't have a situation where a device manufacturer goes out of business and the capability to monitor is lost. reply verisimi 46 minutes agorootparentprevThe consumer element is the sugar to help the masses swallow the pill. If it was just about the consumer, the unit would never report its findings back to base. But blurting back your information is integral to, well, all smart devices. That is the point. Once the government has that info, it will be able to come up with bespoke taxes for you according to what it ordains as fair use. 'Your showers are too long', 'your toolshed is too big a draw on the electric' therefore 'you need to buy carbon credits to offset the environmental damage you are causing'. It's the slow descent to greater tyranny, and loss of personal control. It's amazing that people put up with it, but a slight discount in the short term, or visibility of your own data, is probably enough to get most people to accept spying infrastructure in their lives forever. reply gambiting 35 minutes agorootparentI don't understand your point - these meters only report your overal usage, not what is using the energy/water. It's letting you skip the step where you manually upload the reads every couple months or whatever, or worse, where the energy company employee has to visit your house to read them in person. Why does it matter if I upload my meter reads to my provider every month or if the device reports it automatically? The end result is the same. (At least that's how it works in the UK - the \"smart\" meters don't report live usage back to providers, they just submit kWh reads, the live readout is local device only) reply userbinator 27 minutes agorootparentthe \"smart\" meters don't report live usage back to providers Either they can be easily upgraded to do that, or they already are and the energy company merely gives you the total every month to maintain the impression that they aren't. If the meter-reader needs to visit periodically, you know with much greater certainty that they aren't gathering live data. reply cjfd 1 hour agoparentprevSounds pretty good as such. The worry to have these days, though, is if we can also get this without energy usage data being traded between all sorts of shady companies and/or criminal organizations. reply mtsr 46 minutes agorootparentHome Assistant with a connector for whatever smart meter you have will happily do this for you without the data ever leaving your home. reply verisimi 55 minutes agorootparentprev> shady companies and/or criminal organizations. You mean energy companies and governments? reply oarsinsync 24 minutes agorootparentThere was a report recently that Facebook users have their data sold to 1000-5000 companies, and Facebook takes input from up to 100k companies when compiling data on people. Supermarkets are also into the data game, exploiting the gold mine of data that is shopper loyalty cards. Smart TVs are in the data game, selling details of what you’re watching on to other people. Cars are recording visuals, audio, telemetry, and selling that on. I think it’s reasonable to assume that energy companies are selling the data they’re collecting about you onto data brokers (aka shady companies and/or criminal organisations) reply ako 1 hour agoparentprevDepending on your water meter this device may be useful: https://www.homewizard.com/watermeter/ reply systemz 2 hours agoparentprevAbout monitoring water consumption, maybe using some webcam + OCR would help to recognize reading of a water meter? Then Home Assistant would be helpful to see charts with energy consumption etc reply tomqueue 27 minutes agorootparentThis is what I am using for this exact purpose: https://github.com/jomjol/AI-on-the-edge-device reply 8n4vidtmkvmk 1 hour agoparentprevSomething in my apartment is consuming a ton of power and I don't know what. I would love a graph with a resolution better than a day. reply jonathanlydall 22 minutes agorootparentIf you're looking for something simple to try work it out, I bought a smart plug a few years back which could record usage for around 20USD, you can then move it between your devices getting a sense of each's usage. Long term tracking usage of individual device energy usage is nice, but just knowing from past measurements how much a device tends to use is already very useful. reply Jedd 1 hour agorootparentprevDo you have a conventional HWS? These are notoriously power-hungry, often poorly maintained and calibrated, and hard to monitor. You can buy a power meter plug - that sits between appliance and socket - and work your way around almost all your appliances apart from, typically, oven, air conditioner(s), and hot water systems. For those you're going to need to experiment by turning as many things off as you can, to establish a baseline, and review your switch meter periodically for short (several minute) intervals, with and without the larger appliances turned on. (You can get induction coil systems to report usage of these larger appliances, but they're typically onerously priced.) reply yread 1 hour agorootparentprevCheck the coffee machine. Full auto espresso machines can be huge hogs reply miellaby 2 hours agoprevI like how the author is surprised by the technological aberration that form Linux powered home appliances. A node server to power and publish over wifi a web site, an API, a web socket, while the site is being displayed by a outdated webview engine within an heavily constrained terminal which cant be reused for anything else. That's... the norm. All this is very common. And yet displaying a couple of digits and a bar graph could be done with a pair of microcontrollers communicating onto some wired bus. With the power supplies of this era, this pair of devices probably pumps 16w idle. Running 24/24 7/7, they probably consume as much as a small fridge as a whole. The LCA of the solution must be consterning as well, especially compared with few one dollard microcontrollers. The worst of all is that this whole mess turned into bricks probably 3 years after it was installed, maybe less. reply squarefoot 23 minutes agoparent> within an heavily constrained terminal which cant be reused for anything else. Except for botnets and/or spying. Some of those boards already contain MEMS microphones and cameras (the box in the picture even shows the camera objective). I'd have took apart the device to take a look inside, or at least run some diagnostics to explore which hardware was installed/detected. reply thrwwycbr 2 hours agoparentprevThe reason why the Mirai botnet is still at large is: Android. From a business perspective nobody wants to pay the costly people that can do microcontroller programming. Frontend devs are dirt cheap, especially for something as simple as that interface displaying the bar charts. reply PeterisP 31 minutes agorootparentFrom employee perspective it was my impression that EE developers tend to get lower salaries than web developers. But it could be the case that building an android or web app for a simple UI would take less dev-months than an embedded app with similar functionality. reply justinclift 1 hour agorootparentprev> nobody wants to pay the costly people that can do microcontroller programming The embedded world isn't known for paying well. reply throw310822 34 minutes agorootparentprevThere is also an enormous amount of flexibility gained when, instead if designing and building your own single-purpose device, you just use a cheap, mass produced, off the shelf, general purpose device. reply freetanga 2 hours agoparentprevHe probably would get more savings by removing the fuse again than keeping that useless thing on… reply XorNot 2 hours agoparentprevPulling wires through anywhere after it's finished is an immense installation hassle though. It might be possible...or it might be completely impractical even if you can (i.e. low voltage buses and unshielded power wires don't play nice together if they're parallel). reply IshKebab 39 minutes agorootparentYeah I don't understand why he is shocked that this communicates wirelessly. He even bought a modern flat with Ethernet because he clearly knows how much pain it is to add wiring to a house. Very weird. reply kelnos 7 hours agoprev> There were two strings printed with labels “SSID” and “Pwd”. I froze in horror. They wouldn’t dare. It is literally 3 meter distance. These are embedded devices, they do not need this complexity… Not surprising at all. I would expect that a lot of these are bought as retrofits, and not as a part of new construction. Running wires through existing walls can be annoying, and they don't want to put that barrier to sale in front of them. And you can get a good-enough WiFi chipset for a few bucks these days. > I need a 3A fuse [...] After installation, I checked the temperature of the fuse multiple times during the day to get at least some indication that things are not going to get worse. It worked fine for a more than a week now, but I still do not recommend experiments like this to anyone. Probably don't need to be so worried here. If it's a 3A fuse, the entirety of your apartment's mains power is not running through it. A 3A fuse would burn out in a fraction of a second if you tried to do that. Also, oh, man, Jazelle. I'd forgotten about that. Hardware support for Java bytecode... that did not pan out well. reply xerox13ster 5 hours agoparent> A 3A fuse would burn out in a fraction of a second if you tried to do that. he bought it on Amazon. He has every reason to be worried that it won't burn out. Louis Rossman did a video[0] where he put 8 amps through a 2 amp fuse and left the room for quite a long time, I think it was several minutes with 8a going through a 2a fuse. [0]: https://www.youtube.com/watch?v=B90_SNNbcoU reply userbinator 5 hours agorootparentFuses are notoriously imprecise, even \"fast blow\" ones: https://www.youtube.com/watch?v=WG11rVcMOnY reply fulladder 4 hours agorootparentprevThat is very disturbing. Does Amazon reimburse you when your house burns down? reply eastbound 1 hour agorootparentSeriously, I think they would refund the fuse since you are not satisfied. I think the only way for Amazon to stop organizing countraband would be if dozens of people die in each country and it makes a big media mess and public prosecutors finally rule that Amazon is responsible for mingling and smuggling the products in-country. Which will impact all marketplaces, requiring Craigslist/Leboncoin/Gumtree to asses the liability of the sellers on the marketplace. Which could be a good thing. reply ssl-3 5 hours agoparentprevAlso, too: Wifi has inherent galvanic isolation with a wide gap. It isn't strictly necessary, as anyone here obviously knows, but it can be a cost-effective way to isolate the [electrical] pokey-bits from the [meat-based] pokey-bits, and to avoid loops when things go wrong. Wireless has uses beyond just eliminating wires. reply alexambarch 4 hours agoparentprev> Also, oh, man, Jazelle. I'd forgotten about that. Hardware support for Java bytecode... that did not pan out well. As someone who was too young to be paying any attention during this time, what were some of the reasons this didn’t pan out? Java seems so dominant looking back that I’m surprised something like this wouldn’t have been a success. reply vanderZwan 3 hours agorootparentI have also wondered this for years, and always was told \"because JITs work better\", but that felt a bit handwavy. Luckily for both of us David Chisnall just published an article on ACM about designing ISAs that properly explains the reasoning behind Jazelle and why it did not work in the long run: > Small code is also important [for a simple single-issue in-order core]. A small microcontroller core may be as small as 10KB of SRAM (static random access memory). A small decrease in encoding efficiency can dwarf everything when considering the total area cost: If you need 20 percent more SRAM for your code, then that can be equivalent to doubling the core area. Unfortunately, this constraint almost directly contradicts the previous one [about decoder complexity]. This is why Thumb-2 and RISC-V focused on a variable length encoding that is simple to decode: They save code size without significantly increasing decoder complexity. > This is a complex tradeoff that is made even more complicated when considering multiple languages. For example, Arm briefly supported Jazelle DBX (direct bytecode execution) on some of its mobile cores. This involved decoding Java bytecode directly, with Java VM (virtual machine) state mapped into specific registers. A Java add instruction, implemented in a software interpreter, requires at least one load to read the instruction, a conditional branch to find the right handler, and then another to perform the add. With Jazelle, the load happens via instruction fetch, and the add would add the two registers that represented the top of the Java stack. This was far more efficient than an interpreter but did not perform as well as a JIT (just-in-time) compiler, which could do a bit more analysis between Java bytecodes. > Jazelle DBX is an interesting case study because it made sense only in the context of a specific set of source languages and microarchitectures. It provided no benefits for languages that didn't run in a Java VM. By the time devices had more than about 4MB of RAM, Jazelle was outperformed by a JIT. Within that envelope, however, it was a good design choice. > Jazelle DBX should serve as a reminder that optimizations for one size of core can be incredibly bad choices for other cores So: a decent JIT works better if you can afford the overhead of the JIT. Jazelle was only a good idea in a very brief period of time when this wasn't true, and even then only if you insist on running a Java VM. [0] https://queue.acm.org/detail.cfm?id=3639445 reply bitwize 2 hours agorootparentprevThe Lisp machine failed because Lisp compiler technology got better and better at targeting generic 32-bit CPU hardware, which was becoming increasingly cheap and plentiful. So the benefits of having all this custom hardware to specially execute Lisp code were nullified -- leaving only the costs. The same thing happened to Java in hardware. It seemed like a good idea at the time because it allowed developers to target a language they were already familiar with, and present an alternative to Wintel -- especially when you realize that Java was all the rage as a sort of universal programming environment, and in particular J2ME was a big deal for proto-\"smart\" phones before the iPhone came along. But embedded Java didn't really pan out, memory and CPU time got cheaper, and compiler and JIT tech improved to the point where there was just no benefit to adding the hardware it took to decode Java instructions. So Jazelle was deprecated and replaced with something called ThumbEE, which was a more generic framework based on ARM's Thumb instruction set for running code for an abstract machine, providing features like automatic null-pointer checking and that. Like you could set up a ThumbEE environment for running Python or .NET code in addition to Java. Nowadays even ThumbEE is deprecated. Neither feature appears in ARMv8 processors, for instance. reply AnthonyMouse 4 hours agoparentprev> Running wires through existing walls can be annoying, and they don't want to put that barrier to sale in front of them. It also makes it more convenient to compromise the device from across the street (or across town with a directional antenna). Though of course that's not a problem if your security is up to par and the device continues to receive regular security updates, and we can only surmise that the author has discovered a rare outlier in this space where that is not the case. reply a2800276 1 hour agorootparent> we can only surmise that the author has discovered a rare outlier in this space where that is not the case. Exactly what I was thinking! What luck that the author found the single IoT device out there that's a cobbled together piece of bodged electronics designed by a graduate from a webdev bootcamp with a Corel Draw focus. A device that, while only ~15 years old is not only hopelessly useless, but also obsolete and insecure. It's a good thing all other consumer IoT device manufacturers think about and prioritize security, longevity! Also, that customers nowadays are more focused on installing something fit-for-purpose and sustainable once than buying the cheapest shit possible with the blinkiest LEDs. I shudder to think about how long they tried to get the string-and-cups based telephone to work in my building until the 1930's when they installed the copper still used today for DSL. Or how terrible the paper-straw based water system must have been up to the 1890's when they realized investing in metal pipes has advantages. So glad the days of short-term thinking are behind us. reply eastbound 1 hour agorootparentI’m passionate about the problem of software maintenance: - Can we solve this with some companies dedicated to maintaining simple code (1 probe, 2 charts for each IoT, or more if the IoT subscribed for more) multiplied by 10k different IoT objects over 30 years? - How would upgrading all of them look like? Can we batch the upgrade of NPM’s package.json? Can we define a minimum toolset, say NPM+Next+React, for long-term support? - How can we keep software engineers passionate for that software over dozens of years? Can the challenge of upgrading and migrating to newer frameworks and applying security upgrade be ever a trove of genius and a competiton of the best hacks? For the moment, when it’s done, it’s all GitHub Actions. Released in 2018. Well, not a good start. Plus everyone has a different pile of … in their actions, it’s all custom code, nothing is standardized, and each new IoT requires a new guy writing new ones. - Is this already done in some part of OSS (openWrt?) and how do they deal with the boredom of engineers? reply inetknght 4 hours agorootparentprev> Though of course that's not a problem if your security is up to par and the device continues to receive regular security updates Just remember that the S in IoT stands for security :) reply injidup 3 hours agorootparentSecure Home reply bbarnett 3 hours agorootparentprevdevice continues to receive regular security updates Have to reply to this, and my response was covered a bit by your statement of \"security up to par\". Nothing should be considered secure. All those bug bounties are to entice black hats, into giving up juicy pre-0day vulnerabilities. So just because a device is up to date with security updates, we all must understand, there are countless bugs unknown, needing to be patched, and often, being discovered by those that will never tell, never disclose, never report, and only use them for nefarious purposes. This is why security is nothing without monitoring. And why nothing is ever \"safe\", only likely \"more safe\" due to a security update. Consider everything that is network connected as compromised. Everything. reply AnthonyMouse 3 hours agorootparent> Consider everything that is network connected as compromised. Everything. This doesn't seem like useful advice. If you know something is compromised, you're going to want to stop using it and build a clean system etc. You can't just do that continuously the instant you've built the new system. Likewise, how does monitoring even work? Every device and app wants to phone home to some random server. The connection will be encrypted and even if it wasn't it could be some arbitrary custom protocol you'd have to spend several hours to reverse engineer. You could just block them all but that will cause massive breakage and possibly impair security when the thing you're blocking is whatever thing's security update mechanism. What's a solution someone can actually use? reply Semaphor 1 hour agorootparentI agree with your first part, but not with your second. It really depends what you use, you can easily build up a while home automation system that doesn't phone home or require internet at all reply bbarnett 2 hours agorootparentprevThis doesn't seem like useful advice. Understanding reality is always useful advice. Wishing reality isn't as it is, won't help. The mindset I have described, is how one must view all electronics. Unsecure. reply AnthonyMouse 2 hours agorootparentBut what does that mean in practice? Throw them all into the fire and go back to pen and paper? reply pmontra 1 hour agorootparentSame thing as the security of the lock on our doors. We know that if somebody really want to get into our homes they will. In the case of IoT and computers add to it the automation of the attack. What do we do with our homes? Tradeoffs. We put some valuables in banks, we keep some at home. We insure precious items, if we do have them. We curse when burglars steal from us. We also install curtains so people outside cannot look at us and at what we are doing at home. There are several level of protections to do the same thing for networks and devices. Of course vulnerabilities mean that they are not perfect. Curtains are not perfect too. Add to that imaging through walls with WiFi or mobile network signals, but that's still fringe at best even if you should read https://news.ycombinator.com/item?id=37469920 So, tradeoffs and be conscious of them. reply bbarnett 1 hour agorootparentprevIf that is your choice. You may also understand that your devices are not secure, take steps to reduce risk, and so on. Why do you think yubikeys are a useful thing? Or hardware crypto wallets? Devices that reduce risk, that are designed with the thought that connected computers aren't secure, can never be secure. Know where risk sits. reply mrmanner 16 minutes agorootparentI think this discussion mostly comes down to how we interpret the word “secure”. Do we mean “zero risk”, “nothing can go bad”, “no potential attack, ever”? Or do we mean “low enough risk for this thing , here, now”? I prefer the latter, even if that implies that statements like “this thing is secure” are somewhat useless due to the subjectivity. reply inetknght 6 hours agoparentprev> Probably don't need to be so worried here. If it's a 3A fuse, the entirety of your apartment's mains power is not running through it. If it's a \"3A fuse\" that doesn't blow at 6A or worse, then it will get very hot (fire hazard) if/when there's a short regardless of the distance to the mains power. If it truly is a 3A fuse, then great. If it's bought from Amazon then I doubt it's truly a 3A fuse. reply naitgacem 5 hours agorootparentLouis Rossman over at YouTube has been going over this fuses thing from Amazon. All the fuses he tried from top-results didn't blow until he put 4x or 5x the current rating through them. reply AceJohnny2 4 hours agoparentprev> Also, oh, man, Jazelle. I'd forgotten about that. Hardware support for Java bytecode... that did not pan out well. I'd love someday to learn more about why Jazelle failed. The first SoC I worked on almost 20 years ago was built around an ARM926EJ-S, just like in the story. It was built for Nokia, who used Symbian OS [1], and supported user-installable apps written against Java Micro Edition [2]. The utter mess of Symbian's app discovery and installation, I suspect, was a prime reason Apple created their App Store for the iPhone. Nevertheless, the fundamental concept of HW-accelerated Java apps doesn't sound crazy. What happened? Were they just stuck with a sinking ship, Symbian? [1] https://en.wikipedia.org/wiki/Symbian [2] https://en.wikipedia.org/wiki/Java_Platform,_Micro_Edition reply pmontra 1 hour agoparentprevYeah, the author makes this pun > C in IoT stands for “cost-effective” I guess but it's actually C for cableless. reply madaxe_again 1 hour agoparentprev>> To be honest, the whole thing was a bit scary, since I was very close to the mains I laughed at this. Changing a fuse is… a bit scary? They literally teach this in elementary school in the U.K. - or they did. As you say, no need to fretfully check the fuse - either it blows or it doesn’t, and you’ll know when it does. At least he didn’t find the receptacle holding a dead fuse, carefully wrapped in the ceremonial aluminium shroud of eternal life and certain death, which is a crime I may have committed in my younger, more fire-prone years. I find it interesting how uncomfortable some people are outside of their comfort zones - but then I am a person who spends his life sticking his nose in stuff he has no business with. reply M6WIQ 1 hour agoprevThe name of the company (Netthings) seemed familiar with me, turns out I had read an blog article regarding the hardcoded NTP servers that they used in their devices being firewalled off and therefore losing time sync. Article: https://strugglers.net/~andy/blog/2018/12/24/the-internet-of... It also appears that they went into liquidation in 2018, so good luck getting any support with that device from them! reply cybrox 17 minutes agoprevAs someone who works in IoT, I very much enjoyed your disbelief. I'd place this right about in the middle in terms of useless complexity. There's a lot worse and a lot better. A lot better usually only comes from bigger vendors that can afford dev teams with possible rotations. As a small company or startup, good luck finding a successor to your embedded developer if they leave, so they just slap everyday tech on way overpowered hardware which makes it easier to find devs. reply josu 8 hours agoprev>DATE & TIME ARE ALWAYS CORRECT AND NEVER NEED TO BE ADJUSTED Reads like a quote from a Philip K. Dick book. reply skrebbel 39 minutes agoparentMaybe it’s the technical writer’s way of saying “we ping an NTP server so don't worry” https://news.ycombinator.com/item?id=39065780 (Clearly that didn't pan out so well) reply Ayesh 8 hours agoparentprevMy guess was that it probably had a time correction feature from those British radio tower integration, but this device is from 2015 (says in the article), so probably not. reply Aaron2222 7 hours agorootparentMaybe they originally intended for them to be internet connected? That would also explain the MQTT. reply Ayesh 7 hours agorootparentYeah I think it makes more sense like you said. It has the Wifi stuff there already too. reply adolph 5 hours agorootparentCould prolly take it out of access point and attach it to your network (or one you segregated from your actual network). Set up nat, dyndns, wireshark and see what happens. reply girvo 5 hours agoprev> C in IoT stands for “cost-effective” I guess I know this sounds pithy (and it is!) but you'd be surprised exactly how cheap and cost effective Wi-fi enabled SoCs are. A lot of the time we're getting Wi-Fi for free, and most of those SoC's don't have the Ethernet controller by default, so it's more cost-effective to use Wi-fi if it can fit your use-case. Other physical protocols/connection types can be supported of course (I wonder what the longest I2C run ever is), but when you're talking about a retro-fitted client like this is, Wifi or wireless protocols in general are best. reply PeterisP 1 hour agoparentPurely from a materials perspective, 2x cheap WiFi-capable microcontrollers (e.g. esp8266) will cost the manufacturer something like $4-$5 total for both devices - which is comparable to 3m cable+connectors+cheap chips to handle the cable connection (even ignoring the cost of some person to install the cable which is far more expensive than that) so indeed I don't get why the author considers that doing the connection over WiFi is somehow wasteful. reply paradox460 1 hour agoparentprevESP32s are basically universal at this point. You can have them for under a dollar if you order in any sort of bulk, and you get Wifi and Bluetooth right out of the box. At this point is more expensive to not use Wifi reply INTPenis 9 minutes agoprevThat was so interesting because around 2015 they built some new apartment buildings in Malmö Sweden and they also included touch screens in every apartment. Not the same system, but I wonder if that system is as abandoned today as this one was 8 years later. reply wkat4242 6 hours agoprev> Turns out, I need a 3A fuse, so I ordered one from Amazon and installed it the next day. Ummm. 3A is 720W. If that tiny box dissipated that much, the entire closet full of them would be a literal oven. Besides there's not much point in an energy meter using that much power. It defeats the purpose. It's like testing matches :P it'll be 10W at most. Even peak inrush current would be nowhere near that high. 1A fuse would be more than enough. > To be honest, the whole thing was a bit scary, since I was very close to the mains. Nah this is all installed very cleanly. reply hales 3 hours agoparentDepends on the fuse time rating and the inrush current for the power supply (which can sometimes be more than 10A). Some 1A fuses might occasionally blow when you turn the unit on. reply matthewaveryusa 8 hours agoprevYou should host your write-up on the device itself in case your domain succumbs to the sands of time reply chefandy 8 hours agoprevWeird to see some micromuse thing listed as the service listed for 1534. I worked for them back in like 2006 and we got eaten by IBM/Tivoli and I don't believe they kept the name for anything? I always knew nobody really updated those but man, really nobody updates those. reply alexfoo 53 minutes agoparent1534 was the port used by the license manager (elmd - Elan license manager). The bane of many a Netcool installation until we joyfully ripped it out post IBM acquisition. -Alex (Micromuse 1997 to 2021). reply Nursie 5 hours agoparentprevHah, weird to see micromuse come up. I started working for them two weeks before the acquisition was announced! reply chefandy 4 hours agorootparentHa! I did support there for Proviso— the product of a startup that Micromuse had acquired not too long before the IBM acquisition. I started in between the acquisitions. reply userbinator 5 hours agoprevInteresting article but one thing stood out: The landlord had no idea what this is. There are no buttons or labels on the thing, just a tiny yellow light to let you know it has the power. You move in and find a mysterious device on the wall that, at least to me, appears somewhat ominous and it's not obvious whether it may have a camera and possibly a microphone (the picture of it on the manual appears to show that it does have at least a camera)... Roughly a year ago I moved into my new apartment. ...and you were perfectly fine with living in its presence for a year? When I saw the picture, my first thought was closer to \"that's a telescreen\", and I'd certainly try to find out more about it ASAP. From what I can tell, this is an Android 5, but I am not exactly sure. I believe those icons are from 4.1-4.3 - Lines up with the Linux kernel version being mid-2013. Android 5 was released in 2014. reply UberFly 4 hours agoparentThat was my first though as I read it. It would be disabled or removed the first day. reply anigbrowl 2 hours agoparentprevThe landlord had no idea what this is. Golgafrincham B Ark candidate detected. reply madaxe_again 1 hour agorootparentHey, he might be an exceedingly skilled telephone sanitiser. reply NautilusWave 4 hours agoparentprevHe hadn't read 1984 reply MenhirMike 8 hours agoprevOkay, but: Did the author find the configuration for the energy cost (money and CO2) and update it, so that the touchscreen shows the proper info now? reply laplab 8 hours agoparentHe did! :) It was located in the `/srv/server/bin/cfg` file. reply MenhirMike 8 hours agorootparentAwesome! I had some instances of \"digging so deep into a fascinating problem that I forgot the initial reason I started digging\" :) It actually looks like a reasonable system overall. Maybe a bit bloated on the node.js side (what isn't?), but I wonder if they just had that toolchain already in place/experience with it, even though it's overkill for the system as-is. Or maybe they just googled how to do networking and copy/pasted the top Stack Overflow answer that included Socket.IO. reply qingcharles 7 hours agorootparentprevDid you figure out what the green graph on the right of the display represents? :) reply ncann 7 hours agoprev> TCF seems to be closedly tied to Eclipse ecosystem. The Getting Started guide suggests several plugins for Eclipse as the main way to interact with tcf-agent. I tried installing these plugins on a new version of Eclipse and it is absolutely impossible. There are dependency issues everywhere and when you actually try to install the missing dependencies, Eclipse does not let you because they conflict with some other dependencies. I laughed out loud at this part. Some things never changed I guess. reply metadat 7 hours agoprev> There were two strings printed with labels “SSID” and “Pwd”. I froze in horror. They wouldn’t dare. It is literally 3 meter distance. These are embedded devices, they do not need this complexity... Responding with disbelief seems a little over the top. It isn't typically easy to run wires in pre-built spaces. Sounds like a resilient design to me. reply 65a 2 hours agoparentNot resiliant, because in the 10-20 year lifespan of a home electrical panel, at least one critical vulnerability is going to allow complete remote pwnage of that device. It's stupid IOT garbage that belongs in ewaste, especially with a trivial remote code execution mechanism. reply leoedin 1 hour agorootparentThere's not really much those devices can do - they're just metering, and don't have an active internet connection. WiFi isn't a bad choice of communications protocol. reply rini17 2 hours agorootparentprevLayperson will always prefer wireless. \"But what if I need to move the tablet?\" Never bet against convenience. reply methou 41 minutes agoprevI remember when I rented a palace in Singapore, my landlord asked me to download an app called MyKNX to control the lights and blinds in the room. I dumped some packets, and found system is using tcp/ip and the KNX is standardized protocol. The box is more like a PLC than “smart things”, so it doesn’t need internet to function. It’s also supported by home-assistant. I want to get one when I’m building my own home. Edit: added something details reply 55555 35 minutes agoparentPlease, please write a blog to document the build of your next palace. reply user_7832 8 hours agoprev> C in IoT stands for “cost-effective” I guess. Thanks, that got a laugh out of me. reply dotancohen 8 hours agoparentThe old joke asks what is the S in HTTPS, what is the S in SFTP, what is the S in IoT. reply anotherevan 6 hours agorootparentI've heard it phrased more directly as, \"The S in IoT stands for security.\" reply Ayesh 7 hours agorootparentprevI'm gonna steal this to use in my casual conversations! reply flyinghamster 7 hours agorootparentprevAlso works for the P (privacy). reply mkl 7 hours agorootparentProtocol. reply smingo 1 hour agoprevPutting the WiFi SSID and password on the side of the energy monitor sensor box allowed for this: > The whole thing was quite dissapointing. However, I do have a few Raspberry Pico microcontrollers lying around at home. If I could connect to the WiFi network of the energy manager directly and get the data from the server, I could just extract kW consumption from the API, multiply it by a correct rate and then display it on some Grafana instance. Love it! reply petepete 1 hour agoprevOn a related note, I had a new boiler installed last year with Vaillant's smart controls. There's a little puck shaped 'control unit' with WiFi/radio which allows the app to talk to it, and it to talk to the thermostat. Like most people in the UK, the boiler's in the garage. A brick rectangle separate from the house. Did Vaillant include an ethernet port? You bet they didn't. The support team suggested I installed WiFi in my garage, which definitely wasn't going to happen. I had to get the installer back and he ran the cable through the wall so it's now inside and working fine - but how did this ever make it to market? No wonder the reviews are all terrible. reply knolan 1 hour agoparentMost people in the UK don’t have a garage. Almost every home I’ve lived in has had a gas boiler somewhere inside. reply petepete 1 hour agorootparentFair. But I strongly suspect nearly every house with a garage has the boiler in it. Edit. So having done a little research this probably isn't the case. Maybe it's a regional thing, all the (mostly suburban) houses I've lived in and visited, in the north west of England, are set up that way. reply aworks 8 hours agoprev\"urban archeology\": The device was using an ARM processor extension that could directly execute Java bytecode. https://en.wikipedia.org/wiki/Jazelle reply Everdred2dx 7 hours agoparentThe Nintendo Wii’s “Starlet” processor also supported this though never used it! reply Something1234 7 hours agoparentprevI want to know more. History of java is just insanely weird. reply astrange 6 hours agorootparentSIM cards and secure elements (contactless credit cards) both use this, or did at one point. reply a2800276 1 hour agorootparentSIM cards and secure elements still use this, but it's arguably less Java than Javascript. Except that the trademark and tech (JavaCard) was owned by Sun, now Oracle. It's the basis of the claim, that gazillion devices run Java. JavaCard is a massively trimmed down version which is more a dumbed down C (with no standardization, little documentation and no third-party tool support) which is essentially Java reduced to basic arithmetic operator, an arguably saner, much trimmed down standard library focusing on cryptography and most importantly no GC. reply geerlingguy 6 hours agorootparentprevFor a time, Java was set to be the 'everything everywhere' language, IIRC in some quarters the hype behind Java on everything was even bigger than Cloud, then Crypto, then AI. reply AVincentInSpace 1 hour agorootparentJust you watch, WASI is gonna be next reply fortran77 5 hours agorootparentprevI remember those days well. I had the misfortune of working for one of Java's biggest advocates at Sun, Patrick Naughton https://en.wikipedia.org/wiki/Patrick_Naughton To this day, I refuse to use Java or anything on the Java ecosystem, like Clojure, or Groovy, etc. reply lpapez 2 hours agorootparentI've always thought of Java programming as being kind of perverse with the patterns and verbosity, now I see where the perversion is coming from. reply neither_color 5 hours agoprev>More out of desperation than anything else, I decided to look at sshd config of the host and finally found the offending line. sshd_config had PermitRootLogin no line included, which is a very sensible security measure as long as you are not providing a full disk access to anyone on the network. Enjoyed this article because I've wasted countless hours of my own getting into devices I bought or poking around networks I've airBnB'd at. I'm not as smart as the author but I found his whole approach relatable. reply P5210 53 minutes agoprevlaplab, awesome job and great writeup! I had a similar experience when moving into my \"smart apartment\" 9 years ago and finding a wall-mounted Galaxy Tab 3. I went on to develop a one-click root to allow my neighbors to \"free\" their systems, too: https://hackaday.io/project/181646-hacking-tabs/logs?sort=ol... reply BubbleRings 8 hours agoprevI like the part where you flip the neighbor’s power off for a couple seconds. That’ll teach ‘em to get a UPS! reply laplab 8 hours agoparentI felt pretty bad about it, but my curiosity took over :) It was only the power for their Energy Manager though, not the power to the entire apartment! In any case, I doubt they were actually using this Energy Manager thing anyway. The number one feature listed on websites selling these things is \"Earn two code credits under the code for sustainable homes\". I assume you do not need to teach people how to use the thing to earn these credits... https://uk-metering.net/products/netthings-energy-manager reply virexene 8 hours agoparentprevthat was only the power to the energy measuring device i believe. reply wkat4242 6 hours agorootparentCorrect, since its only on a 3A fuse it would have blown as soon as the owner tried to make a coffee, if the house power literally ran through it. Most likely this is just a current clamp style meter. Most of these kinds of meters are. reply borissk 8 hours agoparentprevNext step - format all their SSDs to teach them to make backups :) reply DougBTX 1 hour agoprevInteresting point about not having internet access: these smart meters typically report usage to the energy supplier for billing. I’d go look for a mobile network connection, maybe still up? reply harry8 6 hours agoprevStill for sale? https://uk-metering.net/products/netthings-energy-manager reply r4indeer 4 hours agoparentOnly 2 left, probably for a while already. I'd guess that's old stock. reply azalemeth 8 hours agoprevA fun read! I feel compelled to say that all British (type G plugs) _have_ to be fused as the ring main has a maximum current of (typically) 30A yet the plug and socket maximum is 13A. So every appliance plug is fused, and the consumer unit has an RCD on most accessible circuits in addition to a circuit breaker. Some plugs don't make the fuse obvious, but the traditional values are 1A, 3A, 5A, 7A, 10A and 13A (iirc -- for some reason!) There are actually many features of the British and European wiring system that I think are really quite good. The device is closely related to a \"smart meter\", which are being slowly rolled out -- the UI is similar to those rolled out nationally, but it's a bit different. Keep exploring (and don't play with the mains!) reply leoedin 1 hour agoparentRing circuits may have made sense in the past, but they really don't any more. It's basically impossible to test a ring circuit in place - you have to break the connection somewhere to ensure the ring is complete. That's a huge downside. They were conceived at a time when circuit breakers were expensive and wire was in short supply - neither is true now, yet people are still installing them. reply Symbiote 7 hours agoparentprevFuses in plugs in Britain are either 3A or 13A, by regulation. 5A used to be another value, but is no longer used (though replacement 5A fuses are easily available.) I've never seen 7A or 10A fuses, and I was the kind of boy to rummage through my grandparent's workshops. .. reply leoedin 1 hour agorootparentI've had 10A fused cables before - IEC leads are pretty common. https://www.cablewarehouse.co.uk/10a-uk-plug-to-iec-c13-main... for example. reply alanfranz 5 hours agoparentprevWhy don’t you use a 13A circuit breaker in UK? That’s what we do in the rest of the EU, I think. There’s a main input to the house which usually is around 15A-30A , then we’ve got multiple sublines with individual circuit breakers, typically 10A or 16A. reply leoedin 1 hour agorootparentThat seems really low. Most houses in the UK have a 60 - 100A supply. Just my stove alone can draw about 7.3kW - about 32A. reply alanfranz 5 hours agorootparentprevI just read up about radial vs ring circuits; I had seen ring circuits only in industrial contexts here in Italy, so the fused approach makes sense I suppose. reply oynqr 1 hour agoprevIf you actually want to crack a password, use hashcat. Although even md5crypt is comparatively hard to crack. reply crummy 9 hours agoprevDid you take notes along the way? Usually when I am \"exploring\" a problem like that it's hard to reproduce my steps later. reply laplab 8 hours agoparentYes! I started taking some notes when I was halfway through, that helped a lot with the thought reconstruction. There is no chance I would find these TCF links organically again reply qingcharles 7 hours agoparentprevAh, it's not just me that does this. I also start taking notes from the beginning now, otherwise when I go back to write it up for others I sometimes can't even replicate the starting conditions. reply incanus77 6 hours agoparentprevFor me, a particular browser window's (many) open tabs are usually a pretty good record. reply neilv 6 hours agoprevEven if this device (presumably with known vulnerabilities) isn't directly reachable via the Internet, could the device be bumped off the WiFi and onto an impersonating AP, where the device can be taken over? The photo on the retail box has a tablet camera hole. Does this particular unit have a camera and mic, placed in a living area? reply rPlayer6554 6 hours agoprevThis was an extremely well written article. It had me gripped in the story. Thanks for posting! reply daviddever23box 8 hours agoprevSecurity through obscurity, I suppose? Seems to be a common thing with UK-based home or energy automation edge devices.... reply layman51 8 hours agoprevI recognize the forum post as being Salesforce Chatter. So it is one of those Experience Cloud sites. reply IlliOnato 8 hours agoprevI am curious, what \"jira_version\" in that listing means. Surely not Jira?.. :-) reply SonOfLilit 5 hours agoparentWhy not? It most likely means \"version in the sense of a release version we configured in Jira to attach tickets to\" reply famicom0 5 hours agoprevProbably a long shot, but would anyone happen to know the color scheme used by the author in the snippet of Python code showing an example of tcf-agent? I really like the mix of bold, italics, underline and shading to achieve a distinct syntax highlighting with such a limited color palette. reply cm2187 2 hours agoprevA bit of a dick move to remove the root password on an IOT device of a flat you only rent. reply denysvitali 1 hour agoparentConsidering that: - the Wi-Fi is password protected - root privileges can already be granted via the \"backdoor\" - exactly as the author did I don't think it's a dick move, the device security wasn't decreased (or increased) since RCE was already possible via the tcf port reply caslon 2 hours agoparentprevIt was completely non-functional before, so there's really no loss. reply cm2187 1 hour agorootparentI see half of the article about how he struggled to get the password, so not that dysfunctional. reply ilikehurdles 6 hours agoprev“DATE & TIME ARE ALWAYS CORRECT AND NEVER NEED TO BE ADJUSTED” sounds like it’s straight out of a fever dream reply mlk 2 hours agoparentIt would if it had an NTP client running reply justinator 2 hours agoparentprevTHEY'RE MADE OUT OF MEAT. reply xydac 7 hours agoprevthis is first time i have read something completely in a long span of time !! reply PNWChris 2 hours agoparentI agree, I really enjoyed the author’s curiosity and writing style! reply Affric 2 hours agoprevGreat article. Not so sure about the usefulness of these devices without having a battery though. reply yashg 2 hours agoprevI thought it would a Telescreen. (1984 reference) reply j1elo 7 hours agoprev> tcf-agent is [...] probably the second biggest security vulnerability after passwordless root SSH. I thought that passwordless SSH is actually a good idea in general for servers? Assuming, that is, that the public/private key login mechanism is used as the alternative to passwords. reply bombcar 7 hours agoparentPasswordless meaning a blank root password allowing login with no credentials- not public/private key. reply asylteltine 9 hours agoprevSmall bit about that Wi-Fi remark. Yes in your case it’s close to the server but Wi-Fi lets you mount the touchscreen anywhere. Wi-Fi completely makes sense here. reply archi42 8 hours agoparentAbsolutely. Try retrofitting this into a multi unit home and \"just run a digital data cable up there\". With some bad luck, this can easily cost as much as the whole unit. I don't like getting everything on WiFi, too. OTOH I have ~30 devices on an VLAN isolated IoT WiFi network. This easily saved us a 4 digit expense and a lot of time(!) as opposed to installing new additional wire (redoing all the old ones was bad enough). Plus, I can do dumb stuff like control my office's window blinds individually, which is nice when only one of them has the sun blinding me while using the PC (temporary desk location due to ongoing renovations). reply Retr0id 8 hours agoparentprevThe equivalent energy monitoring device in my flat uses an RF link (no idea what kind, I haven't investigated further) to talk to its base station. Wireless seems fine, but WiFi itself seems like overkill. reply lawgimenez 8 hours agoprevVery nostalgic, I have developed several apps before with Lollipop and was surprised with their choice of using WebView. I believe they set the NetThings app as a “launcher” app? reply laplab 8 hours agoparentI also assumed that they would, but weirdly no. When the tablet booted up, I was greeted with stock launcher. Also, WebView is only part of the app, they used something else (which did not look like Android native UI) for the WiFi network picker. reply mananaysiempre 8 hours agorootparentThe launcher with its Holo tabs and the icon style look more like Android 4.something (I to K) to me, by the way. Android 5 (L) was the first Material Design release (the one[1] that had actual coherent principles behind it). [1] https://m1.material.io/ reply krackers 7 hours agorootparentYeah given the holoyolo look it's almost certainly ICS or jelly bean. I think kitkat's launcher looked a bit different, it didn't have the tabs: by then they had moved from tron blue to white. reply lawgimenez 7 hours agorootparentprevYeah you are right, I believe it is on Jelly Bean. This was Holo running on ICS. https://law.gmnz.xyz/uploads/2023/169e32e731.png reply exikyut 8 hours agorootparentprevYeah, I'd be curious to see what the About activity shows. reply exikyut 8 hours agorootparentprevOoh, what did it look like? reply efitz 7 hours agoprevDid you ever fix the cost per kWh? reply hacker_newz 8 hours agoprevNice write-up, I wish my apartment had this. reply Symbiote 7 hours agoparentIf the live and neutral cables of your electricity supply are seperate and accessible, you can buy a meter that measures power use with a clamp (loop) that fits around the live cable. Perfectly safe, they were often given away by electric companies in Britain in the 2010s to encourage thriftiness. Here's a zigbee one: https://smarthomescene.com/reviews/tuya-zigbee-single-clamp-... Here's one with an app: https://aeotec.com/products/aeotec-home-energy-meter/ You'll find many more if you search \"clamp energy meter\". reply belinder 8 hours agoprevCool article! You have a small typo towards the end, coincedence -> coincidence reply nurettin 4 hours agoprevI loved the final touch where they leave a note in a text file. Feels much like the talos principle. reply borissk 8 hours agoprevCurios what was the price the developer paid for these devices. reply k1t 8 hours agoparentWhile I doubt they paid the retail price, and the price has probably increased in the 9 years since installation, the current price is £385.00. https://uk-metering.net/products/netthings-energy-manager reply fortran77 5 hours agoprevFrom the article: > I am not an embedded Linux expert, but this does seem like a lot after tinkering with Raspberry Pi Pico and such. ...but of course the Pi Pico doesn't run Linux and doesn't need a lot of memory reply xyst 6 hours agoprevYet another reminder: I really need to get off my ass and isolate all of the IoT junk connected to my network away from home/work/lab devices. reply anotherevan 5 hours agoparentHonestly, this is the main reason¹ I just haven't got into IoT much as I love the idea in theory. I don't want an adversarial relationship with the electronics I'm putting in the house, so I just don't. I want my IoT to work off-line with no talking to the Internet unless I explicitly let it for some reason. I want it to interoperate with other things and not just some shitty app on my phone - I don't carry my phone with me around the house all the time and it's a PITA anyway. I could go the DIY route and bust out the soldering iron and some ESPHome compatible chips, but that's not my passion and life is too bloody short. And even if I did I'd still have strong reservations doing DIY around the 240V AC mains power. ¹ That, and the first thing I'd automate is light switches², but the regulations around mains power wiring in Australia are pretty stringent and the only AES certified IoT light switches I've seen look like I would have and adversarial relationship with and can only be controlled by a shitty app. ² Automating light bulbs themselves is a sub-optimal solution in most circumstances, in my opinion. Perhaps if I wanted to control the colour, but not for on, off and brightness. If I did that it would just make me feel sad. reply BHSPitMonkey 5 hours agorootparentYou can go far using only Zigbee or Z-Wave devices with a Home Assistant server, and then nothing (but the server) has to be networked. As for switches vs. bulbs, at this point I can't go back to the life I led before picking up a bunch of Hue White Ambiance bulbs and having HA automatically adjust the color temperature throughout the day. reply anotherevan 4 hours agorootparentYeah colour temperature would be my rationale for smarter bulbs as well. reply LAC-Tech 8 hours agoprevI really hope we'll look back at this fad of android powered wifi domestic IoT devices one day and laugh about how silly it all was. Not an IoT hater. I've worked for IoT companies, and there's a lot of very smart embedded engineers doing very cool things in the space. But an old android tablet installed in the wall with a WiFI point? oh dear. reply Ancapistani 8 hours agoparentTo be fair, that particular Android device is still installed and at least marginally useful. How many other Android devices from that era can say that? reply lawgimenez 7 hours agorootparentAlso back then, you can fit an Android OS (pre-lollipop) inside a USB and plug it in a TV. It was really cool. reply ilaksh 7 hours agoparentprevWhat do you recommend as an alternative? reply LAC-Tech 6 hours agorootparentbasic electronics, mostly reply Brajeshwar 8 hours agoprevHey Nikita, that was an excellent read. It felt like a pivotal scene in a movie that would change the course of the succeeding narrative. I envy the ability to write so nicely and clearly, making it enjoyable for most generally technical people and keeping us engaged. I will watch out for more articles. reply rideontime 8 hours agoparentHi Brajeshwar, that was a nice comment. It convinced me to read the article, and I'm glad I did. reply tome 2 hours agoparentprevSame! This is my favourite of all recent HN posts. reply geocrasher 6 hours agoprevWiFi is not only reasonable but preferable. Because if a cat5 cable is going to be ran, it'll be done by an electrician. And when they get to the end of a spool, they will break out the wire nuts and splice away. I've seen it first hand. Not even electricians can screw up WiFi :D reply neither_color 5 hours agoparentIt's a little more expensive but it's always worth it to get a low voltage specialist to run your ethernet. To an electrician a conductor is just a conductor no matter how you splice it. reply inetknght 8 hours agoprev [–] > Turns out, I need a 3A fuse, so I ordered one from Amazon OP might want to watch Louis Rossmann's video about buying things from Amazon. https://www.youtube.com/watch?v=B90_SNNbcoU reply Symbiote 7 hours agoparentI was surprised someone would order this from Amazon, rather than get one from the nearest convenience shop or supermarket. Those places only sell the normal thing for local use. I was further surprised that someone would be worried about installing the fuse. Is he also worried about plugging things in generally? reply xattt 7 hours agorootparentI see the recommendation every so often to buy a fuse locally, but I don’t live in Akihabara. I HAVE to buy online electronic components, and usually it ends up being Amazon, because other national suppliers insist on charging $15 for courier shipping on a $2 part. reply Symbiote 7 hours agorootparentThe person lives in an apartment in Britain. Apartments are only built in towns and cities, and are generally within walking distance of convenience shops and supermarkets. Every plug in Britain has a fuse, so they are about as easy to buy as replacement light bulbs. Probably on the same shelf. reply MeImCounting 6 hours agorootparentThis is fascinating! I did not know this about british plugs. Why is that? Is it a safety measure? reply zarzavat 6 hours agorootparentLet’s say you desperately need a cup of tea. So you buy a cheap 4-way extension cable and 4 electric kettles. You fill all the kettles and turn them on at the same time for maximum tea-making throughput. The combined load of all the kettles exceeds the rating of the extension cable. With a fuse: the fuse in the extension cable plug blows, you buy another fuse, and learn some patience. Without a fuse: the extension cable overheats and causes a fire, your house burns down, and worst of all you still don’t have any tea. reply TheCoelacanth 4 hours agorootparentWithout a fuse, the circuit breaker trips and then you go reset it and hopefully learn not to plug in so many kettles next time. You would have to be a maniac to wire up a house without fuses or breakers. reply oasisaimlessly 2 hours agorootparentFrom sibling comment: > British household electrical systems are normally built as one large ring circuit, originally in order to save copper after WW2. > This means you don't have breakers for each branch circuit (there are no branch circuits), just the single mains breaker for the house. reply manarth 7 minutes agorootparentIn the UK, there's typically one ring circuit and one lighting circuit per storey, a separate ring circuit for the kitchen, and dedicated circuits for large current draws such as an electric oven or hob, shower, or immersion heater. Each circuit would have a dedicated MCB (Miniature Circuit Breaker) which will trip if too much current is drawn. The standard MCB rating for a ring circuit in the UK is 32A. tjohns 6 hours agorootparentprevBritish household electrical systems are normally built as one large ring circuit, originally in order to save copper after WW2. This means you don't have breakers for each branch circuit (there are no branch circuits), just the single mains breaker for the house. This single breaker is too large to trip from a short from occuring in the smaller wires inside an appliance. So each plug (or hardwired device) needs it's own dedicated smaller fuse instead. reply outofmyshed 1 hour agorootparentHouses built post-1960s (with more than one floor) will have more than one socket ring each protected by a circuit breaker at the distribution board, usually one per floor for general sockets, with a separate one for the kitchen, and usually individual 32A breakers for things like electric ovens and hobs. Lighting rings are also separate, usually on 6A breakers. We cheap out on cable by not running neutrals to the switches, which causes nerds headaches when they want to install generic smart light switches. My house is reasonably large (worked hard, all my own money) and has a 20-way distribution board with separate socket and light rings for groups of rooms. It’s handy for isolation purposes. More recent builds’ rings will be protected by a combination of MCBs and RCDs, or individual RCBOs (now the cost has come down) which combine the two functions and is ultimately the safest option for most situations. Individually fusing plugs (and in the case of high-draw appliances like washing machines and dryers, protecting with a fused socket) is still a very good idea. And don’t get me started on earthing practices in other countries… reply zarzavat 5 hours agorootparentprevTo add: Many pre-90s buildings don’t even have circuit breakers, they have fuse boxes with fuse wire (different fuse to the one being talked about). Literally just a piece of wire that burns out at a certain current and breaks the connection. You “reset” it by putting a new piece of wire in. The second fuse at the plug allows using a narrower gauge of wire in the device’s cord. Let’s say you have a lamp with a 3A fuse, the cord only needs to be able to handle 3A, so then it can be lighter and cheaper. If it had to handle the same amperage as the circuit it’s plugged into then it would be seriously impractical and expensive. Of course there are modern ways of solving this but fuses are dirt cheap and already implemented. reply outofmyshed 1 hour agorootparentMy last place had a 1970s Wylex board, which at least had plug-in MCB modules that replaced the fuse wire holders and can be reset. However given you can still buy fuse wire in DIY stores there still must be installations out there that need it. Shudder. reply ikt 2 hours agoparentprevThat's what immediately stood out to me, why the hell would you order it from Amazon instead of literally driving 5 minutes down the road to pick one up from any electronics or hardware store? what a horribly inefficient way to do things reply neither_color 5 hours agoparentprev [–] For US readers: The big orange or blue store are probably better for you for anything electric that would go in your walls. I went down a rabbit hole of amazon clones of popular brand things like switches/dimmers/outlets and what I found is dubious UL certificates shared by multiple \"brands\". reply inetknght 4 hours agorootparent [–] > what I found is dubious UL certificates shared by multiple \"brands\" Have you reported it to UL? https://www.ul.com/resources/market-surveillance-departments reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author stumbled upon a touchscreen device in their apartment that turned out to be an energy monitoring system.",
      "They discovered an old Android tablet with pre-installed apps, one of which allowed them to monitor their power usage.",
      "Through network scanning, they found a Node.js server, a DNS server, and a hidden SSH server on the device, gaining access to explore its files."
    ],
    "commentSummary": [
      "The conversation covers various topics related to energy consumption, monitoring devices, IoT security, and electrical systems.",
      "Users share their experiences with monitoring utility consumption, concerns about privacy and data control, and frustrations with IoT devices.",
      "Specific technologies mentioned include the Jazelle DBX and Raspberry Pico microcontrollers."
    ],
    "points": 706,
    "commentCount": 205,
    "retryCount": 0,
    "time": 1705709876
  },
  {
    "id": 39059307,
    "title": "Fujitsu Admits Prior Knowledge of Bugs that Caused Wrongful Convictions in UK Post Office Scandal",
    "originLink": "https://arstechnica.com/tech-policy/2024/01/fujitsu-bugs-that-sent-innocent-people-to-prison-were-known-from-the-start/",
    "originBody": "British Post Office Scandal — Fujitsu bugs that sent innocent people to prison were known “from the start” Software bugs were hidden from lawyers of wrongly convicted UK postal workers. Jon Brodkin - 1/19/2024, 6:00 PM Enlarge / Paul Patterson, co-CEO of Fujitsu's European division, testifies for a public inquiry in London on January 19, 2024. Getty ImagesAFP reader comments 165 Fujitsu software bugs that helped send innocent postal employees to prison in the UK were known \"right from the very start of deployment,\" a Fujitsu executive told a public inquiry today. \"All the bugs and errors have been known at one level or not, for many, many years. Right from the very start of deployment of the system, there were bugs and errors and defects, which were well-known to all parties,\" said Paul Patterson, co-CEO of Fujitsu's European division. That goes back to 1999, when the Horizon software system was installed in post offices by Fujitsu subsidiary International Computers Limited. From 1999 to 2015, Fujitsu's faulty accounting software aided in the prosecution and conviction of more than 900 sub-postmasters and postmistresses who were accused of theft or fraud when the software wrongly made it appear that money was missing from their branches. Some innocent people went to prison, while others were forced to make payments to the UK Post Office to cover the supposed shortfalls. So far, \"only 93 convictions have been overturned and thousands of people are still waiting for compensation settlements,\" a BBC report said. Post Office lawyers rewrote Fujitsu witness statements During the prosecutions, courts hearing cases against postal employees \"were not told of 29 bugs identified as early as 1999 in the system it built,\" The Guardian wrote in a summary of Patterson's testimony today. The article said: When bugs were acknowledged, witness statements from Fujitsu staff due to be heard in court were then edited by the Post Office as it sought to maintain the line that the system was working well as it pursued innocent people through the courts. Paul Patterson agreed that both organizations had failed the accused. \"I am surprised that that detail was not included in the witness statements given by Fujitsu staff to the Post Office and I have seen some evidence of editing witness statements by others,\" he said. Asked by the lead counsel of the public inquiry, Jason Beer KC, whether he agreed that this was shameful, Patterson, who has worked at the company for 14 years, said: \"That would be one word I would use. Shameful and appalling. My understanding of how our laws work in this country, is that all of the evidence should have been put in front of the subpostmasters that the Post Office was relying on to prosecute them.\" A Financial Times article said that the public inquiry \"heard in December last year that the Post Office's lawyers had rewritten Fujitsu witness statements.\" Advertisement The FT article also said the Post Office, which used prosecution powers available to private corporations in the UK, obtained 700 of the 900 convictions. The other convictions came in cases brought by Scottish prosecutors. The scandal may lead to reforms of the private prosecution system that lets organizations take people to court. Bugs were understood “way back to 1999” Earlier this week, Patterson told UK Parliament members that \"Fujitsu would like to apologize for our part in this appalling miscarriage of justice. We were involved from the very start. We did have bugs and errors in the system and we did help the Post Office in their prosecutions of the sub-postmasters. For that we are truly sorry.\" Patterson also told Parliament members that Fujitsu has \"a moral obligation\" to contribute to the compensation for victims. Patterson testified today in a different setting, answering questions from lawyers representing victims. One of those lawyers, Flora Page, asked Patterson, \"Did nobody historically make that pretty obvious connection between very poor code going out into operation and then very poor data coming out and through the litigation support service?\" Patterson answered, \"Whether people made that connection or not, what is very evident... is that that connection and understanding about what was going on and where was it, was understood by certainly Fujitsu and certainly understood by Post Office way back to 1999. It's all about what you do with that information... that is a question for this inquiry.\" Post Office Minister Kevin Hollinrake, the MP for Thirsk and Malton, told the BBC that his \"number one priority\" is to \"try and get compensation and get answers for people.\" \"You've had marriages fail, people commit suicide, an horrendous impact on people's lives,\" he said. \"It's perfectly reasonable that the public should demand people are held to account and that should mean criminal prosecutions wherever possible.\" The UK government also has plans for a new law to \"swiftly exonerate and compensate\" people who were falsely convicted. reader comments 165 Jon Brodkin Jon has been a reporter for Ars Technica since 2011 and covers a wide array of telecom and tech policy topics. Jon graduated from Boston University with a degree in journalism and has been a full-time journalist for over 20 years. Advertisement Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39059307",
    "commentBody": "Fujitsu bugs that sent innocent people to prison were known \"from the start\" (arstechnica.com)454 points by MBCook 15 hours agohidepastfavorite222 comments orbisvicis 13 hours ago\"I [Paul Patterson, co-CEO of Fujitsu's European division] am surprised that that detail was not included in the witness statements given by Fujitsu staff to the Post Office and I have seen some evidence of editing witness statements by others\" How does this scandal keep getting worse and worse when the only thing to cover up is a contract for some poorly written software? At this point I'm starting to suspect some underlying malfeasance yet to be discovered. reply ldoughty 13 hours agoparentI found that interesting as well. It shifts the blame away from software and a cover up by Fujitsu to more of a perception/reputation/political cover up by the Post Office. Fujitsu still has some blame, but if their statements were being modified by the post office, who's responsibility is it to review that? If I gave a written statement to a police officer, is it my responsibility to follow up and make sure they didn't edit my statement? Of course... if I found out, it is my responsibility to raise a flag, but I should be able to trust agents of the courts to not alter evidence. reply jahewson 12 hours agorootparentTo be clear it’s the Post Office that’s accused of editing Fujitsu’s statements. reply stefan_ 10 hours agorootparentBut it was Fujitsu staff acting as witnesses in trials. reply PakG1 3 hours agorootparentIf it was the Post Office editing Fujitsu's statements, who better than Fujitsu staff to confirm as a trial witness what was in the original pre-edited statements? reply fauigerzigerk 1 hour agorootparentI'm not sure whether the same Fujitsu people who wrote the witness statements were then questioned in a court room. reply neilv 11 hours agoparentprev\"The coverup is worse than the crime\" is a terrible effect. But it can happen from: * smaller-fry butt-covering (e.g., lower-level function trying to cover their own butt, putting larger org at risk of much higher cost to the org); * arrogance (e.g., individual/org thinks they are in the right and justified in escalating countermeasures); * bully-like confidence (e.g., individual/org thinks they are powerful enough to get away with escalating the offense, to escape cost from the original offense). It's not unusual, especially on smaller scales (e.g., in companies without genuine cultures of trust and integrity, many people will try to internally suppress info about failures, committing worse and/or more harmful acts in the process). reply chris_wot 7 hours agorootparentThere seemed to be a culture in Fujitsu where incompetent and judgemental people were allowed to rule the roost. The best example of this is the testimony of one Peter Sewell, who never met one of the victims but who, in an email, called him a “nasty chap” and that he was out to “rubbish the FJ name”. You can see how he realises the enormity of his stupidity in testimony and tries to half heartedly defend himself (unsuccessfully): https://youtu.be/fGCsvjYNWr0?si=q-ss0T35RFOecv7n reply FerretFred 3 minutes agorootparent> There seemed to be a culture in Fujitsu where incompetent and judgemental people were allowed to rule the roost. This also applies to Parliament. They're renowned for it! reply neilv 6 hours agorootparentprev> its [sic] up to you to maintain absolute strength and integrity Sounds like he was using a different sense of the term \"integrity\" than I was. Figuratively, like integrity of a physical barrier, to the (claimed) attack of this other person. reply abraae 4 hours agorootparentprevHis testimony is infuriating. Every question answered quickfire and monosyllabicly, trying to shut it down. Exactly the mindset that led to this giant fubar in the first place. reply droopyEyelids 11 hours agorootparentprevThis is actually how the Manson family murders started! They first injured Gary Hinman trying to get money from him- before the Tate murders. While he was injured they spent days first injuring him, and then debating how to keep him from going to the police for two days before he died. reply neilv 11 hours agorootparentIs there a chart of the rationality over time? reply snickerbockers 26 minutes agoparentprev>when the only thing to cover up is a contract for some poorly written software? There are a lot of programmers who seem to think it would be a horrific miscarriage of justice for somebody to be held responsible for the behavior of their own computer programs. reply marcosdumay 12 hours agoparentprevIt's not the first time I see news about people committing hideous crimes just to cover up some mild offense. It's always surprising, and always feels absurd and impossible, but it just keeps happening. I guess just like comedy and bad suspense movies, crimes always escalate. reply amatecha 9 hours agorootparentRight, like the ppl who murder their partner rather than admit to cheating on them or being way in debt or whatever... So messed up :( reply hutzlibu 1 hour agorootparentThere are also less extreme examples: during a school trip with overnight stays, 2 of the teenage girls went out in the evening, even though it was forbidden. It was noticed after a while, so the teacher went looking for them. Just as he went out, they were about to come back(not too late). But they saw the teacher coming out - and hid themself, to not get in trouble in this moment. And this is of course when the real trouble started, because now the search started for real, with informing police about missing female students, big search etc. Coming out right at the beginning would have meant been giving a warning ... but the hiding because of fear for the trouble made the trouble very big and got them close to being expelled. And anger from the others, because from then, everything was less fun with the teachers .. reply EasyMark 8 hours agoparentprevIt's terrible that it's starting to look more and more like they would rather let people go to prison rather than just fix the software and make everyone whole before it got out of hand. reply ikidd 8 hours agorootparentPrison? Heck, 4 people committed suicide over the course of this malfeasance and there's be a pile of bankruptcies and divorces. If they can prove what seems to have obviously happened here, there should be a pile of jail time involved. reply KennyBlanken 10 hours agoparentprev> How does this scandal keep getting worse and worse when the only thing to cover up is a contract for some poorly written software? A massive contract for the entire postal service of which a number of government managers? On top of which Fujitsu provides software for a huge swath of other UK government agencies like NHS? So not only are they protecting a huge contract, but they were also covering up the fact that they lied and people ended up going to jail, committing suicide, etc. Aside from the criminal and civil liabilities - that would generate substantial political outrage and is the sort of thing that would shed a lot of unwanted light on the contracts, how they were selected, etc. Light nobody wanted. This literally caused deaths - people committed suicide because of the shame and debt and utter destruction of their careers. reply puzzledobserver 12 hours agoprevThe Wikipedia article on Paula Vennells tells me that the Post Office prosecuted 700 subpostmasters between 1999 and 2015 [0]. That works out to about one prosecution every 8 days. I do not know the baseline rate at which postmasters commit fraud or are prosecuted, but isn't one prosecution every 8 days an awfully high number? Shouldn't the Post Office have conducted some sort of internal investigation as soon as the frequency of prosecutions hit a number this high? [0] https://en.wikipedia.org/wiki/Paula_Vennells reply puzzledobserver 12 hours agoparent> \"In 2013, Vennells hired forensic accounting firm Second Sight, headed up by Ron Warmington, to investigate the Horizon software losses. Warmington discovered the system was flawed and faulty, but Vennells was unhappy with Warmington's report and terminated their contract.\" Inexcusable. reply ikidd 7 hours agorootparent> terminated their contract Two days before the report was due to be released. reply tjpnz 2 hours agorootparentprevVennells deserves to spend the rest or her life in prison. An evil piece of work that one. reply conductr 10 hours agorootparentprevYes totally but shouldn’t it have been the prosecution that hired forensic accountants in order to, well, prosecute reply ajcp 10 hours agorootparentThe Post Office was the prosecution! That's what makes this even worse... reply cge 9 hours agorootparentprevI get the impression that, no, forensic accountants were not used in the prosecutions, and they instead just relied on the software's accounting. From the bugs described, it seems like forensic accountants legitimately looking at specific cases would have been unable to confidently state that funds were missing. reply Eisenstein 9 hours agorootparentprevIn the UK, private parties can prosecute people. The Post office was doing this. As a citizen of the USA, this is a completely alien concept to me. How can a corporation put a person in prison? reply Ichthypresbyter 5 hours agorootparentA lawyer paid by the private party fills the role of the government prosecutor, but the case is heard by the same judge and jury who would hear it in a state prosecution. Until the 1980s this was how almost all criminal prosecutions worked in England, though by the end the \"private prosecutor\" was usually a police officer. reply wonderwonder 4 hours agorootparentSo a company with money and a good lawyer could really just essentially have you thrown in jail? Seems really not good. reply qingcharles 3 hours agorootparentYes, because often they are in control of all the evidence and/or can create evidence. In the 90s, I caught the technical head of a certain very large telecoms firm logging private IRC chats and then blackmailing the users, some of whom were gay and not out. When I made it clear I knew what was going on and that it needed to stop this person went on to fake logs of me hacking into said firm and sent them to the dean of the university where I was studying and there was a serious attempt to have me expelled and talk of criminal charges. I was only saved by the heads of the computing department who vouched for my good character and independently proved that the logs were fake. reply conductr 2 hours agorootparentWere you then able to prosecute him for this fraudulent conspiracy he manufactured? Is there any check and balance, like something seriously discouraging people from doing this nefariously? Is there any responsibility on the judge or jury to demand burden of evidence? As in the postmaster situation, if I were the judge or jury I first and foremost need to be convinced a crime occurred and money is missing. The fact a forensic accountant wasn’t required is still odd to me. I suppose they were glad to call guilty on circumstantial evidence or just took the financial statements at face value reply Eisenstein 1 hour agorootparentYou are missing a crucial factor which is that the Post office leveraged prosecution for a much larger 'theft' crime in order to pressure the defendants to plead guilty to a lesser 'bookkeeping' crime along with 'repayment' of missing funds. It was a shakedown. reply fractallyte 2 hours agorootparentprevCan you say more about this, in particular, what happened next? Because it's not really over until there's justice, and the guilty person is punished. I'm hoping that's what happened next! reply mananaysiempre 8 hours agorootparentprev> In the UK, private parties can prosecute people. [...] How can a corporation put a person in prison? On criminal trial, not in prison. (Prosecute, not convict.) In theory, this sounds like it could somewhat mitigate the phenomenon where a law is on the books but the DoJ or whoever employs public prosecutors decides to just ignore it. (Whether that’d be a good thing or a bad one from a separation of powers perspective I’m not sure.) reply Eisenstein 8 hours agorootparent> On criminal trial, not in prison. In this case they ended up getting guilty pleas in exchange for 'promises' of leniency. That sounds like 'putting people in prison using leverage' to me. With an imbalance between resources of the entity going after you and what you have available, I would say the giant corp will win the overwhelming majority of the time. The problem is that they have every incentive to push people to pay them/take a deal with what is essentially extortion and there is no oversight. If the city prosecutor were threatening otherwise upstanding citizens with jail time if they didn't pay them many thousands of pounds for mystery expenses viewable by only the prosecutor, that person would be impeached or at least lose the next election, then be prosecuted for corruption. No such luck when the entity pursuing is 'faceless corporation that needs to maximize profits and has no person held to account for injustice'. I fail to see how this is in the public interest. reply mananaysiempre 7 hours agorootparentI mean, many others have used the same tactics with civil suits—being stripped of all of one’s money might be marginally better than being put in prison, but I’d argue it’s still on the same spectrum, so it makes for a hell of a lot of leverage. So I don’t think this works as an argument against private prosecutors—it’s rather an argument against a legal system that necessitates ruinously expensive lawyers, which is a major problem, but one I see no solution for, not even a blank-slate one. (To be clear, I still reserve my judgment on whether private prosecutors are actually a good idea. What do you do if a private party takes up a murder investigation and screws it up?.. I’m not ready to give up non bis in idem for this. On the other hand, the idea sounds sufficiently reasonable that I probably wouldn’t have thought to question it had I been brought up to think it were normal.) reply Eisenstein 4 hours agorootparent> I mean, many others have used the same tactics with civil suits—being stripped of all of one’s money might be marginally better than being put in prison, but I’d argue it’s still on the same spectrum, so it makes for a hell of a lot of leverage. So if one thing is terrible let's use that to justify something worse? reply anigbrowl 8 hours agorootparentprevLook up how much power postal inspectors have in the US. They can arrest you if you commit crimes that fall within their jurisdiction. reply Eisenstein 8 hours agorootparentThe Postal Inspector in the USA is not a private entity, and they cannot prosecute you. There is not 'Postal Prosecutor' there is District Attorney and a Federal Prosecutor and they are either directly elected or appointed by elected officials. reply anigbrowl 3 hours agorootparentThat's why I said 'they can arrest you', a fact which surprises a lot of people when they first discover it. reply Eisenstein 1 hour agorootparentTechnically anyone can arrest you. reply scott_w 3 hours agorootparentprevIt still goes to the regular courts. The problem comes when the prosecution lies and fabricates evidence. reply spondyl 1 hour agoparentprevWhile Paula is getting all the attention, mostly due to appearing in the dramatisation, I'd point out that we haven't heard from Adam Crozier who was CEO of the Royal Mail from 2003 - 2010 which was a fairly key period when this was all going down. I pick on him particularly because after he handed the role over to Vennells, he went over to ITV for a number of years. The same ITV who provides the very dramatisation that brought all this stuff into the public eye once again. That said, he had left ITV well before the series would have started production so it may have just been a creative decision rather than due to any outside influence. https://en.wikipedia.org/wiki/Adam_Crozier reply hermitcrab 11 hours agoparentprevOne possibility is that the PO bosses thought that there had always been a high level of theft and that Horizons system was finally uncovering it. The ultimate case of projecting your own failings onto others by grasping and immoral execs? I mean seriously, if you were a criminal, would you go to all the trouble to run a post office for years? reply lazide 10 hours agorootparentIf you went to all the trouble of running a post office for years - would you mind ‘losing’ a package or two every once in awhile to pad your retirement? reply chris_wot 7 hours agorootparentNo. reply lazide 7 hours agorootparentThen you’re doing better than they expected 10% of their sub postmasters to be doing. reply dataangel 11 hours agoparentprevI think the more important variable is how many subpostmasters there are. If there are millions then 700 is impressive. reply vlovich123 11 hours agorootparentCouldn’t find the exact number, but anywhere from 9k-12k according to https://en.m.wikipedia.org/wiki/Post_Office_Limited#Services That’s ~8.5% of their subpostmasters that were arrested (the actual number according to Wikipedia is 900 not 700). That seems really high to me. Also I think you meant to say that 700 out of millions would be unimpressive instead of impressive right? reply conductr 10 hours agorootparentThose are positions. The roster is constantly churning and this spanned several years. Either way, it’s apparent the truth didn’t want to be known. I’m actually curious why these people were pursued if in theory everyone could have been. It’s like the head guy could just victimize people at will. Was he just having some sick fun or coming down on specific people for some reason. reply londons_explore 11 hours agorootparentprevAs of 2023, there were 6727 subpostmasters. So about 10% committed fraud. Seems a little high - but I could believe it if the subpostmasters are the local \"boss\", handling cash, and are supposed to pay 'the blokes in London' who they never meet. Also, most subpostmasters had many employees - and I believe if any one of their employees was commiting fraud/stealing money, then it was the sub postmaster responsible - so that 10% number might actually only be 1% if every branch had 10 people involved in the running of it. reply vlovich123 10 hours agorootparentI think this is too generous a take given the facts we know that happened. First, the time period we’re talking about here is 16 years. You’re telling me that the post office in 16 years couldn’t figure out how 10% of their branches were having persistent problems with their counts for 16 years! What business operates this way when dealing with such large amounts of money. At a minimum even if it was legit fraud by the subpostmasters this would be an indictment of the competence of the Post Office in managing the offices. Then there’s gems like this: > Some subpostmasters noticed the new system reporting false shortfalls, sometimes for thousands of pounds, but the Post Office insisted that the system was robust and, when shortfalls occurred, prosecuted the subpostmasters or forced them to make good the amounts, as required by their contract. Then an audit that was disputed and ignored: > In 2012, as a result of pressure from campaigners and Members of Parliament, the Post Office appointed forensic accountants Second Sight to conduct an investigation into Horizon. Second Sight concluded that Horizon contained faults that could result in accounting discrepancies, but the Post Office insisted that there were no systemic problems with the software. Finally, the most egregious thing is that even if you go back in time and are an honest player, as the convictions start happening more and more often, maybe at some point you go and ask the question “what changed in 1999 when we started prosecuting and why weren’t we catching this fraud before? Did we become better at it somehow?” Actually it corresponds to the rollout of the system. It’s possible of course that this system added new auditing capabilities that didn’t exist before but honestly 10% is still ridiculously high. Ultimately, the facts of the case are pretty clear this is bad faith from the Post Office (and maybe Fujitsu) top to bottom. There’s no point playing hypotheticals with good faith actors when the Post Office even had audits showing the software was buggy and the response was to dispute the audits they themselves contracted. It’s beyond the pale. reply was_a_dev 11 hours agorootparentprevIt was the arrogance that they thought that these subpostmasters had been doing this for years, and just been caught out by their new computer system. The contempt for their staff is insane reply thinkingemote 12 hours agoprevThings still going on right now: Prosecutions are still going on but are being led by the Crown Prosecution Service (vs. the post office). Fujitsu are continuing to proving the CPS / post office with data that they have been doing for years (and possibly still providing witness statements, I dunno). Subpostmasters still complain about bugs in the horizon software causing balance errors. Subpostmasters still get fined and have to pay the Post Office ( automatically deducted from their salary) for any shortfalls that occur. reply jiggawatts 10 hours agoparentThis issue has been public knowledge for years. How is this possible!? reply amiga386 9 hours agorootparentThe contract to be an SPM makes you liable for all losses, no matter how they are caused, which includes blatant faults of the accounting/ePOS software. It's the ultimate case of moral hazard. Why fix the broken software if it's only some other sucker who's on the hook for it? reply heads 3 hours agorootparentI taught in a private school for a while. In England and Wales the law says that your employment “contract” is simply the verbal, written, or implied agreement to work there and the document enumerating the details — the written statement of employment particulars which is basically the thing you or I would call “the contract” — doesn’t have to be supplied until up to two months after you’ve started work. My employment particulars came the day of the two month deadline. They included a clause that said that the school had the final say on any claim brought by a pupil or their family against me for loss or damage and that any compensation would automatically be deducted from my salary. Unsurprisingly, I did not agree to this clause and did not sign the document! The school also refused to negotiate and I worked there for two years in a kind of contract limbo. I’ve gone back to being a SWE now. I was lucky to not be beholden to one industry like my fellow teachers were. I can completely see how a sub-postmaster, without a fallback career, can get cornered into accepting some ludicrously unfair terms. reply dang 11 hours agoprevI've attempted to compile the HN threads on this. Can anybody find other significant ones? (It's interesting that there was one submission, with one comment, in 2012, and seemingly nothing for the next 7 years...) Fujitsu CEO Deposition – Post Office Horizon IT Inquiry - https://news.ycombinator.com/item?id=39059302 - Jan 2024 (1 comment) Fixing Horizon bugs would have been too costly, Post Office inquiry told - https://news.ycombinator.com/item?id=39039712 - Jan 2024 (59 comments) Fujitsu says it will pay compensation in UK Post Office scandal - https://news.ycombinator.com/item?id=39023695 - Jan 2024 (26 comments) How a software glitch at the UK Post Office ruined lives - https://news.ycombinator.com/item?id=39010070 - Jan 2024 (326 comments) Post Office Horizon scandal explained: Everything you need to know - https://news.ycombinator.com/item?id=38983144 - Jan 2024 (8 comments) A TV Show Forced Britain's Devastating Post Office Scandal into the Light - https://news.ycombinator.com/item?id=38951802 - Jan 2024 (168 comments) British Post Office Scandal - https://news.ycombinator.com/item?id=38937705 - Jan 2024 (149 comments) How the Post Office's Horizon system failed: a technical breakdown - https://news.ycombinator.com/item?id=38931792 - Jan 2024 (4 comments) Ex Post Office CEO hands back award after IT failures lead to false convictions - https://news.ycombinator.com/item?id=38930011 - Jan 2024 (127 comments) Post Office Horizon Enquiry – Fujitsu Report on Eposs PinICL Task Force (1998) - https://news.ycombinator.com/item?id=38926582 - Jan 2024 (1 comment) Fujitsu bosses knew about Post Office Horizon IT flaws, says insider (2021) - https://news.ycombinator.com/item?id=38890468 - Jan 2024 (8 comments) Mr Bates vs. the Post Office - https://news.ycombinator.com/item?id=38869011 - Jan 2024 (3 comments) What went wrong with Horizon: learning from the Post Office Trial - https://news.ycombinator.com/item?id=38867712 - Jan 2024 (19 comments) UK Post Office: 700 Horizon software scandal victims to receive £600k each - https://news.ycombinator.com/item?id=37561428 - Sept 2023 (40 comments) After 20 years, the Post Office scandal cover-up is happening in plain sight - https://news.ycombinator.com/item?id=36778486 - July 2023 (1 comment) The UK post office database scandal – “can't see the bug = user is a thief” - https://news.ycombinator.com/item?id=35837576 - May 2023 (2 comments) Hundreds of lives ruined by faulty UK Post Office computer system - https://news.ycombinator.com/item?id=35792896 - May 2023 (4 comments) Ex UK Post Office staff tell inquiry of stress of IT scandal - https://news.ycombinator.com/item?id=30394685 - Feb 2022 (2 comments) Post Office scandal: Public inquiry to examine wrongful convictions - https://news.ycombinator.com/item?id=30329668 - Feb 2022 (149 comments) Post Office scandal: 'I want someone else to be charged and jailed like I was' - https://news.ycombinator.com/item?id=30329510 - Feb 2022 (2 comments) Bad software sent postal workers to jail - https://news.ycombinator.com/item?id=26973583 - April 2021 (1 comment) Convicted Post Office workers have names cleared - https://news.ycombinator.com/item?id=26924882 - April 2021 (187 comments) UK court clears post office staff convicted due to ‘corrupt data’ - https://news.ycombinator.com/item?id=26913037 - April 2021 (284 comments) UK legal system assumes that computers don't have bugs - https://news.ycombinator.com/item?id=25518936 - Dec 2020 (24 comments) Post Office scandal: Postmasters celebrate victory against convictions - https://news.ycombinator.com/item?id=24661321 - Oct 2020 (2 comments) Bankruptcy, jail, ruined lives: inside the Post Office scandal - https://news.ycombinator.com/item?id=24440476 - Sept 2020 (1 comment) Postmasters were prosecuted using unreliable evidence - https://news.ycombinator.com/item?id=23454606 - June 2020 (2 comments) Faults in Post Office accounting system led to workers being convicted of theft - https://news.ycombinator.com/item?id=21795219 - Dec 2019 (104 comments) Post Office hires accountants to review sub-postmasters' computer claims - https://news.ycombinator.com/item?id=4143107 - June 2012 (1 comment) reply switch007 1 hour agoparent> It's interesting that there was one submission, with one comment, in 2012, and seemingly nothing for the next 7 years... It was the recent TV mini series that got this mass attention, which triggered the mass media covering it I believe. reply prof-dr-ir 1 hour agoparentprevFor the record, here is a submission (and comment) by me: Computer Says 'Guilty' - https://news.ycombinator.com/item?id=27392724 - June 2021 (1 comment) reply EasyMark 8 hours agoparentprevThanks dang, someone more industrious than me could turn this into a CompSci or Tech term paper or great Medium/Substack article (or series). Also computer ethics case study as well for those professors out there, but maybe it needs to cook a while longer for more details to come out reply hermitcrab 11 hours agoparentprevPrivate Eye have been covering it continuously since Computer Weekly broke the original story. reply ninjin 1 hour agorootparentThe Eye, still the most trustworthy source in the UK. It honestly feels like you are doing society a great service every time you grab a copy. reply dang 11 hours agorootparentprevYes, that's mentioned in a number of the HN threads listed above. If anyone finds an interesting thread I missed, please reply so I can add it! reply jacquesm 7 hours agoparentprevIt's interesting to read through these chronologically. Thank you very much for compiling this list! reply qingcharles 3 hours agoparentprevTake a vacation one of these days, Dan. I think you might have earned it. reply bjornsing 12 hours agoprevIn England and Wales perverting the course of justice carries a maximum sentence of life imprisonment. IMHO this would be appropriate for the lawyers who rewrote those witness statements. reply londons_explore 11 hours agoparentwitness statements are frequently collaboratively written/edited and then signed by the witness... I don't think collaboration or editing is in itself a crime - the crime is to sign a statement which you know to be untrue or deceiving. reply EasyMark 8 hours agorootparentBut it seems pretty obvious these lawyers were covering up for their customers. That would fall under being fraudulent, no? reply throw7 13 hours agoprev\"...witness statements from Fujitsu staff due to be heard in court were then edited by the Post Office...\" I hope there is serious jail time and fines for the persons that did this. Bonkers. reply IronWolve 6 hours agoparentI would think re-writing witness statements is a crime. reply infamouscow 6 hours agoparentprevOr off a tall building. reply justinclift 7 hours agoprevSeems like the senior Post Office staff purposely \"perverted the course of justice\" here. Doesn't that mean they should be facing criminal charges? reply switch007 1 hour agoparentYes but it gets very awkward very quickly when you realise it’s the government who own and have responsibility for the Post Office. Why stop at the Post Office directors? And who runs the Crown Prosecution Service? Ah yes, the government. reply CM30 13 hours agoprevTo an extent, this is basically the norm for most software projects. Often you know there are bugs and issues in a piece of software, but don't consider them enough of a blocker to delay the release date for. That works okay for something like game development where the stakes are very low. That does not work for a piece of software where people's lives and finances are on the line, especially not when you still accuse people of committing criminal actions knowing full well that it could be the fault of your system's bugs rather than their actions. Some might question if this 'move fast, break things and ignore bugs that aren't thought to be complete showstoppers' is the right move, but the way they handled it on a business and legal level was definitely the wrong one, and the majority of the problems came from the dodgy actions of the execs and business folks trying to cover things up. reply jacquesm 7 hours agoprevSo, when your new software system identifies fraud where none was seen before the onus is really on you to check, recheck and triple-check your results before you start ruining people's lives. Those working on the present crop of AI classifiers should take note because those too can, will and probably already are being used to figure out who to target for surveillance, perform facial matching and will likely be embedded in AI based legal software. We're not that far from 'computer says guilty' and even if it isn't the computer that says so directly all it needs to do is give the wrong kind of person enough cover that they believe they are doing the right thing. Something very similar happened in the Netherlands with the tax office and I suspect that if and when the IND here gets turned inside out we'll find a lot more of this sort of stuff. reply ChrisArchitect 13 hours agoprevMore/related: Fixing Horizon bugs would have been too costly, Post Office inquiry told https://news.ycombinator.com/item?id=39039712 Fujitsu is sorry that its software helped send innocent people to prison https://news.ycombinator.com/item?id=39038263 reply WalterBright 13 hours agoprevPeople who frame others for a crime should be subject to the same sanctions as the crime itself. reply worik 12 hours agoprev\"Patterson also told Parliament members that Fujitsu has \"a moral obligation\" to contribute to the compensation for victims.\" How often do you hear a suit talk of their \"moral obligation\"? That really struck me. So true So often we (computer programmers) get to walk away free and clear from the cluster fucks that arrive from our mistakes reply notatoad 4 hours agoparenttalking about a \"moral obligation\" usually means there's no legal obligation, so people don't start down that route until they've exhausted all other obligations. unfortunately, a moral obligation is about the least powerful type of obligation there is. reply metabagel 11 hours agoparentprevClearly, there must have been systemic issues at Fujitsu which allowed the accounting software to fail so spectacularly. reply hermitcrab 11 hours agorootparentHorizons was based on a failed benefits system and it was widely known that the quality of the software team was not good. IIRC it didn't even use ACID transactions, so glitches and power outages could cause big problems. What sort of company would put their Z team on a multi-billion pound contract? reply wbl 10 hours agorootparentEvery company that wants to succeed in the bodyshop world. Government contracting is broken in the Anglosphere. Parties contracting out software tend to do it because they cannot manage the project themselves, but they can pay a lot of attention to the financials. So you need to cut costs and just meet the delivery bar that the customer tests for, not actually exceed expectations. You're not going to get credit for the next one. reply Twirrim 9 hours agorootparentGovernment procurement trends towards broken in most countries. You start out with a nice and clean set of rules, easy to validate. Stuff like \"make sure the c-suite aren't relatives of the government officials making the decision\". Time goes by, something goes wrong. Press has a field day. Politicians get embarrassed and add a rule to ensure they can't be embarrassed that way again. For example, maybe the company chosen was in a dire financial situation, and goes bankrupt, leaving the government up the creek without a paddle. The politicians get embarrassed and add a rule to the procurement process that requires the company getting the contract must demonstrate that they are a going concern. Over time, what started as a neat and clean system, ends up with the most convoluted and complicated sets of checks and balances known to man. Purchasing decisions that used to take a week, now take 6 months+, and require a significant outlay from the companies that are in the running. What you end up with is that very few companies can actually compete in the space, few of them have the financial resources to be able to make the kinds of outlay involved, nor take that kind of bet. The companies that remain in the field are those with the most skill at navigating through the ever changing government procurement processes, and deliver just enough of a solution to satisfy the government, without causing drama. You can practically guarantee this Fujitsu drama is going to cause yet more rules to be added to the procurement process, because politicians won't want to be embarrassed this way again. This is almost identical to the way a lot of software development works. So much organic growth. Something that started out completely sane, becomes a near impenetrable mess that practically guarantees bugs. We find edge cases and we fix them. We need to add extra functionality, so we just find a place that looks reasonably logical for it to go. Over and over, until \"Wait, what....?\" becomes the background sound of the office. At least in software, we can more easily reach a consensus that it's time to refactor, or completely gut and replace what has gone before. It often hurts us to a sufficient degree that we're motivated to do so. With governments, all the incentives are missing on the very people that need to be incentivised for it to be fixed. They don't want to have their name against a big re-do of the procurement process, and have it drop something that would have stopped the next disaster. Those are the kinds of things that opponents in an election will jump all over and tout as an example of why you're unfit to serve. reply Twirrim 9 hours agorootparentprev> What sort of company would put their Z team on a multi-billion pound contract? A company that stands to make significantly larger profits by doing so. Why pay $$$ on engineers when you can pay $ engineers, and still get a product you can ship to the customer that works to a sufficient degree to satisfy the purchaser? reply csan 11 hours agoprevThere are dangerous flaws within the case management software used by the UK justice system itself - https://csan149.substack.com/p/justice-at-risk reply hermitcrab 11 hours agoprevI think it was more than 'bugs'. The whole architectural design was inadequate. See Computerphile video: https://www.youtube.com/watch?v=hBJm9ZYqL10 (C++ programmer, but not an expert of distributed systems - would be interested to hear from someone that is) reply pizzafeelsright 9 hours agoparentReconciling and accounting isn't difficult. Is the intent accuracy? Was money a motive? I don't know the full story but cooking the books is how you skim. And once you're dirty, in order to come clean you need to expose everything. reply amiga386 9 hours agorootparentThe intent was to keep their chummy contract with government going and keep riding the gravy train, no matter how shit the software was. So far, I haven't seen evidence of anyone at Fujitsu inserting fake records in order to enrich the company - FYI the contract was such that the government took basically no risk, Fujitsu fronted the money to pay for Horizon's development, and in return Fujitsu gets a cut of all transactions. All they need to do is keep the sweet deal going. What I have seen evidence of is them clearly detecting bugs, and inserting fake records to make the numbers reconcile, but still being so thick that their support staff didn't notice the fake numbers didn't add up either. https://www.postofficetrial.com/2019/03/the-smoking-gun.html Their motive appears to keep the corporate gravy train going, so yes it's personal enrichment, and to fudge the numbers on the sly so nobody questions Fujitsu's competence to run their system... but not cook the books directly. Then of course the Post Office would prosecute the SPMs for discrepencies hallucinated by Fujitsu's broken accounting software, and not be curious or ask questions of Fujitsu, because then the Post Office bosses wouldn't get their performance-based bonuses. There's also straight up incompetence: https://www.postofficescandal.uk/post/ecce-chambers/ > Chambers admitted to the Inquiry that despite being told the discrepancies had occurred on various occasions at the branch throughout the year, she only looked at the system information behind the most recent discrepancy. She also didn’t check to see if something similar had been reported by any other branch. Her “investigation”, from assignation to conclusion, took one hour sixteen minutes. > Chambers conceded that she didn’t know if it was an unknown system error was affecting the branch, and seemed to accept that her stark conclusion in 2013: “No fault in product” and “user” error, was misleading. She added: > “I don’t think I handled it terribly well. I was frustrated by it and I think that shows… because, you know, it really looked like there was a genuine problem… [but]… There was no sign of it.” > In summary, ten years ago, Anne Chambers appears not to have considered the possibility of unknown system problems, or prompted an investigation more advanced than what she could achieve within the limits of her knowledge and ability. Instead, after a quick squizz at a limited dataset she concluded there was no obvious problem, which meant there was no problem and the cause of the discrepancy was the Subpostmaster. reply danjc 3 hours agoprevAlso, products named Horizon are problematic. reply whythre 3 hours agoparent? I don’t follow. Problematic is a pretty vague descriptor. What’s wrong with the name? reply calzone5116 9 hours agoprev> \"We did have bugs and errors in the system and we did help the Post Office in their prosecutions of the sub-postmasters. For that we are truly sorry.\" Every time some CEO issues an apology i can't help but not take it seriously because it reminds of following scene: https://youtube.com/watch?v=15HTd4Um1m4 reply tomcar288 12 hours agoprevtravesty of justice doesn't begin to describe it. there must be something else wrong besides just the software? how could the justice department just blindly trust the software accounting without any other evidence. reply magospietato 11 hours agoparentYou are misunderstanding how much of a travesty this is. No government organisation (typically the Crown Prosecution Service in England and Wales) was involved in bringing these prosecutions. The Post Office itself was legislatively empowered to bring private prosecutions of their employees to the state courts of England. The whole thing is insane. reply mardifoufs 10 hours agorootparentReminds me of private prosecutions here in Canada. Is it similar or does the postal office have specific powers that go even beyond that? reply komadori 10 hours agorootparentAnyone can bring a private prosecution in the UK and I don't believe the Post Office has any specific additional powers in this regard. reply magospietato 1 hour agorootparentInstitutionally empowered would have been a better phrase. While the PO doesn't have specific legislative powers to bring private prosecutions, they did have a significant amount of institutional holdover from when is was a public body. Specifically, a close working relationship with the police and other bodies with statutory powers that went far beyond any relationship a privately owned body should have. E.g. they were given direct access to the Police National Computer System. reply dessimus 9 hours agoparentprevThere are lots of wrongful convictions here in the US. Some even have DNA edivence clearing them and proving another committing the crime, and the Prosecution will fight that it does not matter, as long as 12 people thought they were guilty, then they are. reply nabla9 11 hours agoparentprevDid you read the article? It was not justice department (aka Crown Prosecutor) prosecuting those people. In UK private prosecution for crimes is possible. Probably a major reason for this kind of bullshit goes on. reply kelnos 10 hours agorootparentWait, \"private\" meaning a non-government entity such as a corporation can prosecute someone, without any involvement of the public justice system, and send people to jail? I assume not just any private entity is empowered to do this, but still... Wow, it's bad enough here in the US that we have a private prison system, but that really takes the cake. reply optimalsolver 7 hours agorootparent>I assume not just any private entity is empowered to do this Anyone can bring a private prosecution. reply nabla9 10 hours agorootparentprevYes. Really weird. https://en.wikipedia.org/wiki/Private_prosecution https://www.cps.gov.uk/legal-guidance/private-prosecutions reply 123pie123 10 hours agorootparentto me, there nothing really wrong with the concept of private prosecutions whats happened here is a total fuck up of justice, with many many people lying and the fact people/ judges have believed computer printouts as fact - ffs reply cesther 10 hours agoprevThe documentary that accompanied the recent ITV Drama \"Mr Bates vs The Post Office\" provides a good overview. Listening to the actual people impacted by this is heart breaking. Someone has put it on YT, also available in the torrent bundle on PB. https://www.youtube.com/watch?v=OHIr5fqfqKs reply cannonpr 10 hours agoprevHow material were the post offices “overbooking” of profits by false sales registered via this bug ? How plausible is it that in-fact the internal narrative was that the post office was wildly more profitable than it was, but that they just need to crack down on this minor theft problem that they have via prosecutions while at the same time padding their figures a bit via postmasters money ? reply amiga386 9 hours agoparentIt's worse than that. Post Office investigators got performance-related bonuses for every successful prosecution. They were chomping at the bit to prosecute anyone who showed the slightest discrepancy, and all their Christmases came at once after Horizon was installed. Moral hazard, cobra effect, if all you have is a hammer, etc. https://www.telegraph.co.uk/news/2024/01/10/post-office-exec... reply buggeryorkshire 8 hours agorootparentJesus Christ I didn't know that. Wow. reply jocoda 12 hours agoprevThere is no way to make good the harm inflicted, and I'm skeptical that anyone except, maybe the innocent, are going to be punished. The central villain of this shit show is the Post Office. The history of the project shows that - from initial procurement onwards. Poorly implemented by ICL, a UK company, taken over by Fujitsu as some sort of favour to the UK government. The developers are guilty but this is just another government project, a disaster, but that's apparently nothing really unusual. The minor villains are the members of the lynch mob. Most were probably ignorant of the facts and so, filled with righteous indignation they did whatever was necessary to make sure that the evil thieves got theirs. How do you make something like this right? I don't think you can. Shit happens. The villains will keep their heads down for a while, and then like much of politics, will carry on because it seems that there are no consequences anymore. reply kelnos 10 hours agoparent> How do you make something like this right? You can't make it fully right, since you can't give people back the time they spent wrongfully imprisoned. But you can at least throw a truckload of cash at them to make things a little less awful. But yeah... these people will never get their lives back, and it will never be right. This is mainly why I am against capital punishment. Even if we do believe we should have the right to say who lives and who dies (I'm not convinced of that, but many people are), we do not have the ability to say with any certainty that anyone is actually guilty. While the state can later recognize a mistake and let someone out of prison, they can't bring someone back who they executed. reply alt227 11 hours agoparentprev>How do you make something like this right? The UK government reckon it takes about £600,000 each https://www.bbc.co.uk/news/business-66843548 reply akira2501 11 hours agoparentprev> How do you make something like this right? If only there was a single person ensconced with supreme authority and a duty to protect the realm around. reply SuperNinKenDo 9 hours agorootparentIt seems they shirked any responsibility to the actual governance of the realm decades ago. reply zoklet-enjoyer 14 hours agoprevI've been listening to this podcast about it. Very messed up how these sub-postmasters were treated. https://open.spotify.com/show/6BL7LWzXRdmwa0JVXOChQL?si=51p1... reply iovrthoughtthis 11 hours agoprevthis is crazy cant help but consider that fujitsu is an SI that competes with infosys and this really undermines fujitsu in the minds of british tac payers... reply amiga386 9 hours agoparentThe UK government took Fujitsu off their \"preferred vendors\" list. But they're not allowed, by law, to exclude a company completely from new contracts. They tried to cancel another Fujitsu contract, but Fujitsu took them to court and won, so the government have to keep accepting their shit service. reply Zuiii 6 hours agoprevWhat infuriates me is that the courts decided to convict people when there was no evidence of malpractice other than that damn software. What happened to innocent until proven beyond reasonable doubt? Where the fucking proof? Why are judges ignoring the very foundations upon which our justice systems were built? reply wonderwonder 4 hours agoprevIs this a case where the software just had bugs in it like most production software that are patched with new releases that introduce new bugs and as such is a useful scape goat for the defense and the media has no idea what they are talking about and decided to run with it? Or is it the bugs are egregious and clearly responsible for the convictions? Please note I have no dog in this fight, just generally curious if anyone knows more? reply DarkmSparks 9 hours agoprevTLDR: UK legal system has no legitimacy. The whole thing is just yet another example of the consequences of letting lawyers lie as much as they want without consequences in order to win. reply vladgur 14 hours agoprevgiven how much a prior conviction makes employment difficult here in the US, how would you quantify financial impact not just of the time served, but also the reputational impact it has on your income. reply dylan604 14 hours agoparentyou pick a really big number, and 10x it. it's all part of the negotiating. let a jury decide the final number. some people will tell you some formula about salary at the time, calculating anticipated increases in salary of that time, blah blah. screw a bunch of that. make it hurt. however, isn't this a UK issue? reply kelnos 10 hours agoparentprevPresumably their record would also get expunged? Not sure how that works in the UK though. reply yieldcrv 13 hours agoprevThe real question is who is this happening to now? Its like you go to a prison and everyone says \"I'm innocent\" and the officer sarcastically dismisses them saying \"you and everyone else\", the irony being..... that's plausible? reply csan 11 hours agoparentMore than plausible; it's happening again right now within the UK justice system itself - https://csan149.substack.com/p/justice-at-risk reply tsol 11 hours agoparentprevThis is kind of the idea behind the innocence project. I'm not sure if they have a certain focus but they work on cases of people falsely accused. reply helsinkiandrew 14 hours agoprevBugs are inevitable. The real issue is with the post office management that prosecuted people they knew there was a good chance were innocent, withheld evidence, falsified evidence, and harassed journalists investigating. What really bothers me is that the CEO of the Organisation at the time was also a Christian priest/deacon https://en.wikipedia.org/wiki/Paula_Vennells > witness statements from Fujitsu staff due to be heard in court were then edited by the Post Office as it sought to maintain the line that the system was working well as it pursued innocent people through the courts. reply arp242 13 hours agoparentI have generally found that there's not that much relation between people's stated beliefs and their actual every-day behaviour. By and large, I do think their beliefs are genuine and heart-felt, and that they're not faking them. It's just that it doesn't really influence their daily behaviour all that much. Generally people are motivated by the incentives of the moment, emotion of the moment, and that kind of thing. I am no exception to this by the way. People often assume that if someone has the \"right set of beliefs\" (whatever that \"right set\" is, which may or may not be religious) that they're also a good person. I'm not saying there is zero correlation for all people, but typically it's very small at best, if it even exists at all. reply CoastalCoder 13 hours agorootparent> People often assume that if someone has the \"right set of beliefs\" (whatever that \"right set\" is) that they're also a good person. IIUC, there are a few aspects of Christian theology that muddy this issue a bit. I'm probably a bit wrong, so I'd be grateful for any corrections: 1) Christians believe in progressive sanctification. I.e., the Holy Spirit works, over time, to make Christians more like Jesus. So you really should expect true Christians, on average, to gradually become better people. 2) Not everyone professing to be a Christian truly is [0]. As an agnostic, those issues have frustrated my efforts to decide if Christianity generally true. [0] https://www.openbible.info/topics/fake_christians reply mylastattempt 12 hours agorootparentAll logic following from illogical things such as religion, are flawed and utterly useless. Determining anything based on it, is a waste of thought and energy. You'd be better off debating laws within the Star Trek universe. reply all2 12 hours agorootparent> All logic following from illogical things such as religion, are flawed and utterly useless. Interesting take considering the scientific method arose originally as a method for understanding God's consistent and ordered creation. Just because you don't agree with something, or are not otherwise familiar with it, does not mean it is illogical. reply throw7 1 hour agorootparentprevPaul has letters admonishing christians for not being christians. We see everyday that professing christians often are not christians. All I can say is that christ called all of us to love God and love our neighbors. reply TheOtherHobbes 12 hours agorootparentprevI've yet to meet any Christians who don't contradict other Christians, while being 100% convinced their personal beliefs are correct and all those other interpretations are wrong. So I don't think No True Christian is relevant here. Whatever religion the CEO was cosplaying, the bottom line is that she was involved in organising an aggressive criminal cover-up which caused multiple suicides, unlawful jail terms, and bankruptcies. She must have done this knowingly, because it's unimaginable that information about these problems didn't filter through to the board. Ultimately everyone on the board is personally responsible, and should be treated accordingly. reply PH95VuimJjqBqy 11 hours agorootparent> I've yet to meet any Christians who don't contradict other Christians, while being 100% convinced their personal beliefs are correct and all those other interpretations are wrong. Christian means \"Christ-like\", it's not surprising that different people have different interpretations of what that means. But my experience has been the stronger someone proclaims their christianity, the less trustworthy they are in general. That may seem paradoxical, but consider that I'm not christian which means they feel more justified in treating me as an out-group. The most die-hard christian I've ever met once got into a fist fight with one of his tenants for being late on the rent. He also, at one point, climbed onto his roof with a compound bow every night for several weeks because some thieves stole a generator and he wanted to catch them coming back. He also one time told me this story about he was doing a job (he had a lawn care business) and this group of mexicans just randomly attacked and beat the crap out of him. No, I didn't believe the ass-whooping was undeserved. reply kelnos 9 hours agorootparent> it's not surprising that different people have different interpretations of what that means. Perhaps that's not surprising, but it's certainly \"un-Christ-like\" to be so arrogant to think your interpretations are right and everyone else is doing it wrong. Of course, most organized religion has at least some focus on telling people outside their religion that they're doing it wrong, so this attitude among religious people shouldn't be surprising, either. reply JohnFen 10 hours agorootparentprevJesus himself said that worship of God is a thing that is private. That those who loudly proclaim or make public displays of their faith are straying from the path. reply ryao 4 hours agorootparentI usually avoid religious discussions, but I really would appreciate a citation on this considering it is the exact opposite of what is actually attested to him: https://biblehub.com/matthew/10-27.htm reply whythre 3 hours agorootparentprevMatthew 28:18-20 quotes Jesus as saying ‘All authority in heaven and on earth has been given to me. Go therefore and make disciples of all nations, baptizing them in the name of the Father and of the Son and of the Holy Spirit, and teaching them to obey everything that I have commanded you.’ Jesus was really annoying to many, many people when he was going around preaching to large crowds. The fact that he was viewed as a rabble rouser and demagogue played a significant role in his death. (Along with proclaiming that he was the Son of God). reply burkaman 11 hours agorootparentprev> you really should expect true Christians, on average, to gradually become better people. I think you can only expect them to gradually become more Christian, and every Christian defines what that means for themselves. There is no definition of goodness that is shared by all Christians. reply BobaFloutist 12 hours agorootparentprev>So you really should expect true Christians, on average, to gradually become better people. Only if I accept their beliefs as accurate. reply labster 11 hours agorootparentYou shouldn’t have to accept the beliefs, just the virtues, if it’s a religion with a stated goal of making people virtuous (excluding some polytheistic faiths, for instance). reply kelnos 9 hours agorootparentThe poster upthread said that the mechanism for becoming better people was that the Holy Spirit makes it so. If the Holy Spirit doesn't exist, then the only mechanism for self-improvement is one's own ability to make those improvements, consciously. Virtues alone don't make people better. Doing the hard work to introspect and actually make yourself better... that's what makes you better. reply ACow_Adonis 12 hours agorootparentprevOr even their professions of belief to actually be something approaching truthful. But there are many incentives, both on a self-deceptive psychology level, and on a societal-wide level, for wanting to be seen as a virtuous and forthright person irrespective of one's actual behaviours or beliefs. reply kelnos 9 hours agorootparentprevI feel like that falls under the \"no true scotsman\"[0] fallacy. Rather than just branding every self-professed Christian a \"fake Christian\" if they don't actually gradually become a better person throughout their lives, it's probably more reasonable and useful to recognize that people are flawed, and, despite their sincerely-held beliefs and convictions, often still do bad things. (Of course, magical, invisible spirits that change your personality and values are unlikely to actually exist, so the point is somewhat moot.) [0] https://en.wikipedia.org/wiki/No_true_Scotsman reply arp242 12 hours agorootparentprevI wasn't even talking about Christians specifically, or even religion. Just \"beliefs\" in the broadest possible sense. I don't know if it's better or worse among Christians (or a subsection of Christians) as opposed to anything else (e.g. political affiliation or beliefs). I am hesitant to start listing examples, as I don't want to side-track this discussion too much. I think there's probably a bit of a general assumption to consider people on \"your team\" to be \"one of the good guys\". Perhaps this ties in with how people tend to justify their own actions. I'm not entirely sure where it comes from. reply jacquesm 7 hours agorootparentSometimes it is also used as protective coloration, to blend in and be passed over for scrutiny because of the outwardly visible religious affiliation signalling 'good person here, no need to look any closer'. That's one reason why Catholic priests got away with all their crap for so long. reply pavel_lishin 7 hours agorootparentprev> Not everyone professing to be a Christian truly is.* Ah, so they're Scotsmen. reply RangerScience 13 hours agorootparentprevRelated, started realizing that \"being a principled person\" doesn't really mean \"having (stated) principles\", it means belief that you can (and should) have principles that you're trying to apply consistently and continuously. Lots of people have principles. Not so many people are principled. reply smcin 12 hours agorootparentPerhaps, but if they're unstated, what prevents you revising your principles after the fact, to fit your actions? Anyway the UK Fujitsu/Postmaster scandal is about a huge chain of dishonest human behavior, not bugs in software. reply kelnos 9 hours agorootparentBeing principled would preclude you from changing those principles to excuse your own bad behavior. Put another way, if you were to do this, then you weren't really principled in the first place, were you? And it's not like people don't say out loud that they are a certain way, and then act against that. There's no magic in principles being explicitly stated. reply smcin 8 hours agorootparentBut that wouldn't be proveable, if they never stated their principles. Almost anyone could then claim to be principled if they didn't state what principles, unless we knew the innermost contents of their mind; or unless their behavior was grossly self-contradictory (rather than nuanced, or deniable). > There's no magic in principles being explicitly stated. Sure there is: we can see the audit trail of precisely what principle they claimed to adhere to and, when. For example in this case the defence for Paula Vennells (and other key figures) is going to be very interesting. What if Vennells blames expert advice, or the prosecutors, or Fujitsu? reply PH95VuimJjqBqy 11 hours agorootparentprev> Perhaps, but if they're unstated, what prevents you revising your principles after the fact, to fit your actions? then you're not a principled person, that's why actions speak louder than words. reply JohnFen 12 hours agorootparentprevYour actual principles are demonstrated by how you act when nobody is looking. reply taeric 11 hours agorootparentprevI've found it is easier than that. If a system is setup so that professing a belief will get someone a benefit, then you will find a ton of people claiming said belief. Now, there are also people that will act counter to their beliefs for other reasons. Sometimes for reasons you don't know. But that is, largely, a different thing. reply deepsun 12 hours agorootparentprevYep, except for the cases when some group of believers becomes so obsessed and intolerable, that they pack belongings and go do great things like founding Providence or Salt Lake City in the middle of a desert. Those deeds are very respectable IMO. reply rayiner 12 hours agorootparentIt’s pretty impressive, right? I don’t think if you took random New Yorkers and dumped them into that same situation they would have achieved the same outcomes. reply PH95VuimJjqBqy 11 hours agorootparentyou don't think other groups would have fought for survival? reply rayiner 8 hours agorootparentI think everyone would have fought for survival. But there is a difference between survival, and creating an orderly and prosperous civilization in harsh surroundings. reply deepsun 11 hours agorootparentprevOther groups would adapt to their local community, blend in, so there would be no need to move out and found countries. reply at_a_remove 13 hours agorootparentprevWasn't there a study of ethicists which pointed out that even ethicists were not particularly more ethical in their day to day behavior? More and more, I have come to regard what people state as their beliefs or guiding principles as some kind of mission statement buried on a corporate website. It's more congruent with reality. reply ijhuygft776 24 minutes agoparentprev> What really bothers me is that the CEO of the Organization at the time was also a Christian priest/deacon Why does that bother you? It's just a bunch of lies too. reply ExoticPearTree 13 hours agoparentprevSeriously now, with all this information now available, shouldn't all the people that lied and rewrote statements be prosecuted for perjury? reply thinkingemote 12 hours agorootparent2 of them are being investigated by the Met Police for perjury right now. Not much info right now and its being paused whilst the inquiry is going on. reply qwertox 12 hours agorootparentprev\"I'm sorry, I don't remember\". But yes, they should and probably will be. But just for show. reply linkjuice4all 13 hours agoparentprevIt's generous of you to assume that someone's religious affiliation would have any impact on how they conduct their professional lives. Perhaps she should consider working within her preferred religious organization and leave the job open to people whose ethics are more closely aligned with their customers (in this case the presumably secular government of the UK) otherwise people might mistake her as a greedy self-centered plutocrat. reply liveoneggs 13 hours agoparentprevThe CEO Priest is a head scratcher all by itself > I tell you the truth, it is hard for a rich man to enter the kingdom of heaven. Again I tell you, it is easier for a camel to go through the eye of a needle than for a rich man to enter the kingdom of God. reply CoastalCoder 13 hours agoparentprev> What really bothers me is that the CEO of the Organisation at the time was also a Christian priest/deacon At the risk of making a No True Scotsman argument, it's anyone's guess as to whether or not she truly is a Christian. The only conclusion I can really draw from this is that she apparently acted in a way that's not consistent with Christian ideals. reply kelnos 9 hours agorootparentThe main conclusion I draw from this is that people will generally do whatever they want or feel they need to do, and their religious beliefs or affiliations continue to not really matter all that much. > she apparently acted in a way that's not consistent with Christian ideals Considering that \"Christian ideals\", depending on whom you ask, can include some pretty bad things, I don't think this matters all that much. reply InCityDreams 11 hours agorootparentprevShe acted just like a person with Christian ideals. reply CoastalCoder 10 hours agorootparent> She acted just like a person with Christian ideals. How so? reply bedobi 13 hours agoparentprev> What really bothers me is that the CEO of the Organisation at the time was also a Christian priest/deacon lol, in my experience... well, let me not finish that sentence reply nihonthrowaway 13 hours agorootparentAs a Christian, I have learned to be in my guard when business partners tell me about their Christianity. Or any other way of signaling their self-proported ethics. reply akoboldfrying 12 hours agorootparentMy gut feeling: Being Christian is a very weak signal. Telling people that you're Christian (in a context where it's not important to do so) strongly signals a desire for social prominence, which is itself usually a bad sign. I expect this holds for other religions too, I just don't have much experience there. reply jacquesm 7 hours agorootparent> Telling people that you're Christian (in a context where it's not important to do so) strongly signals a desire for social prominence, which is itself usually a bad sign. This happens just about everywhere, including right here on HN. reply bombcar 12 hours agorootparentprevI'll go so far as to say anyone who mentions it in a business context (or especially leads with it) is almost certainly going to be some form of scam. If it's anything beyond a little add in the church bulletin or a small fish on a truck, it's probably indicative. reply SAI_Peregrinus 11 hours agorootparentprevIn Matthew 6 Jesus forbids praying in public, like the hypocrites did, and instead commands Christains to pray where only the \"father\" can see them. Overt displays of piety by Christians are the original meaning of the word \"hypocrisy\", they claim to be Christian but display their supposed piety for public reward in direct contradiction to Jesus's command. reply ryao 4 hours agorootparenthttps://www.biblegateway.com/passage/?search=Matthew+6%3A5-8... He did not forbid anything there. He simply said not to pray publicly to try to earn points since God would not fall for it. In Matthew 10:27, he advises people to tell everyone everything he has told them: https://biblehub.com/matthew/10-27.htm To be fair, I imagine trying to earn points is not the same thing in his eyes as telling others what he taught them. To speak more generally and not about you in specific, it would be nice if people interpreting religious texts on the internet would at least take a college class on them like I did. It enables you to avoid some of the more common pitfalls, although it is still possible to make mistakes. I took the time to consult an actual theologian on a number of things when I was younger, which was even more useful than the college class. That said, even trained theologians will make mistakes on these things. My favorite example is the “vinegar” offered to Jesus on the cross. It was actually a drink called posca, which is basically water sanitized by vinegar with herbs optionally added for additional flavor. When the story was written in Greek, the convention at the time was to call that drink vinegar and everyone understood that drinking vinegar meant drinking water that had a few % vinegar and possible herbs added, yet now many years later when almost nobody does that anymore, most people misunderstand what it means. Even trained theologians will misunderstand that because they are not familiar with ancient Mediterranean dietary habits. They imagine the solider that offered the vinegar as being cruel, when in fact, he was the sole nice guy among the Romans there. It would not be surprising if during Roman persecution of Christians, the act had been used as an example of not all Romans being bad, yet today if you hear about it, it is incorrectly used to demonstrate the cruelty of the Romans. Interestingly, despite Latin having the word posca, the Latin translation did not properly translate this. The translator had been a huge fan of Greek so much that he used Latin incorrectly in a number of places to mimic Greek grammar and word definitions. He used the word for “and” as a word for also instead of the proper Latin word “quoque”, because the Greek word καὶ could mean either “and” or “also”, and no Latin word meant both at once. Given that he did that, it is no surprise that he also wrote vinegar and expected everyone to apply the Greek interpretation. Then translations of the Latin translation into other languages followed where the translators had no clue that vinegar had been written in place of posca due to an ancient convention. By the time translations were done from the original Greek, Greek had adopted posca as a loanword from Latin and almost nobody remembered the original convention, so the English translations continue to say vinegar despite English never using the word vinegar to refer to vinegar-sanitized water (with optional herbs). There is a video by a youtube historian that talks about posca in detail and mentions the biblical account: https://youtu.be/2nBVsW0LtQI There are other YouTube videos on this, but that is the one where I first learned about this. Also, to make this tangent useful to anyone who has read it to the end, I find that posca actually enhances the flavors in modern Italian food. Note that I used apple vinegar when making my own, which is not the same vinegar people in the ancient Mediterranean likely used, but it was close enough for my purposes. Also, for a laugh, imagine this. In 2000 years, it is possible that people will think making children drink soda was a form of punishment. That is about as close to what children consider soda to be today as most discussion of religious texts on the internet is to what those texts actually say. reply worik 12 hours agoparentprev> Bugs are inevitable. Yes But accounting software that gets totals wrong is not inevitable Entirely avoidable reply dumbfounder 11 hours agorootparentAnd can't the numbers be, I dunno, audited?!!?!!? WTF. Like, did all these numbers just get spit out to a jury and then these people were prosecuted? How in the hell????? reply golem14 5 hours agorootparentI mean, the DOD/Pentagon has not been able to finish an audit and account for their finances to the GAO (General Accounting Office) for many years now. There's a proposal that they will be able to pass a clean audit in 2027. Just sayin' ... reply surfingdino 12 hours agoparentprevIf you want to turn one's life into living hell, it helps to ask a priest for help. reply hermitcrab 11 hours agoparentprev>What really bothers me is that the CEO of the Organisation at the time was also a Christian priest/deacon Because Priests have never done anything bad before? reply alfalfasprout 11 hours agoparentprevIn general, as much as we trash on the US judicial system the UK judicial system makes it even harder to have any sort of recourse in a situation like this. reply matheusmoreira 13 hours agoparentprevAbsolutely. Another example: people are routinely sent to jail based on highly sensitive field drug tests which have significant rates of false positives. reply DiggyJohnson 13 hours agoparentprevHow is that relevant, other than making him a bit of more a hypocrite? reply kitd 13 hours agorootparentHer reply msie 15 hours agoprevnext [36 more] All the PO lawyers rewriting witness statements must go to jail. All the prosecutors must go to jail for negligence and malpractice. reply dougSF70 14 hours agoparent100% Agree...prison time, public excoriation and significant financial penalties. reply droopyEyelids 14 hours agoparentprevIn china they have a saying \"A punishment milder than death would not sufficiently assuage public indignation\" https://www.tiktok.com/@chinesedemystified/video/71123116513... I only post this as a fascinating example of how different Western and Chinese perspectives can be. Not that these people would be killed in China, or that it would be justice if they were- but we don't even have this in our vocabulary! reply jpgvm 13 hours agorootparentI doubt they would have been executed in this case but for heinous corporate crime China doesn't hesitate to apply the death penalty to executives: http://news.bbc.co.uk/2/hi/asia-pacific/8375638.stm reply plagiarist 13 hours agorootparentprevWe have \"death is too good for him\" and the West, at least the US, has no shortage of bloodthirsty Calvinist Predestination believers who love to imagine people receiving punishment. reply SoftTalker 14 hours agoparentprevOdd that so often here on HN we talk about how prisons don't work, don't deter crime, don't rehabilitate... yet whenever some CEO or high level official is caught in malfeasance, we insist that \"sending them to jail\" is the only proper response. reply arp242 13 hours agorootparentThere are different people on HN with differing views. I, for one, would never claim that \"prisons don't work, don't deter crime, don't rehabilitate\" without any qualifiers. Maybe some specific systems have some problems, but that's a very different thing than \"prisons\" as a concept. reply acdha 12 hours agorootparentprevIt’s more nuanced than that, in part because there are two separate issues: Not all crimes are the same: harsh punishment won’t deter crimes where people think they won’t get caught (e.g. speeding) or where they are not thinking rationally (e.g. drunken fights). In this case, these are lengthily premeditated decisions so deterrence is likely to be effective _if_ they aren’t confident about being able to evade consequences. That’s why it’s so important to have them now because every other white collar criminal is watching and learning. The other factor is what form the consequences come in. Fines are problematic if they can be treated as a cost of doing business, but even the richest people only have 24 hours in a day. I personally think community service would be better than jail: if nothing else, it’s cheaper and I think these guys would be incredibly motivated to avoid spending their time scraping gum off of park benches. reply sfifs 12 hours agorootparentprevIt appears many western sociologists and have gotten confused over the last half a century or so and have started building theories like castles in the air from dogma instead of rooting them in empiricism, not much different from religious theoreticians of a bygone era who insisted earth is the center of the universe. The only reason for prisons and criminal justice of various to exist throughout history has been to (1) deter crime by threatening punishment and (2) give the rest of the society confidence that \"crime doesn't pay\" - because a system that has higher intrinsic trust and follows rules invariably outperforms ones that don't economically and often militarily. Yes part of such a successful system is graded treatment for people who have a better chance of rehabilitation as such folks are much more useful in society and tempering of justice contextually. However trying to add additional tasks to the system, like rehabilitation or empowerment or economic development of a disadvantaged class serves only to compromise the core function and result in societal breakdown. These are all important tasks and they should be delivered through other parts of the government that are focused on these missions. It is perfectly fine for different arms of a government to have seemingly contradictory missions and these need not be aligned like how audit/controls and commercial functions are not necessarily aligned. reply metabagel 11 hours agorootparent> However trying to add additional tasks to the system, like rehabilitation or empowerment or economic development of a disadvantaged class serves only to compromise the core function and result in societal breakdown. Citation needed reply xbar 13 hours agorootparentprevSocieties expect that people who violate laws to endure some amount of reciprocal suckage to balance the suckage they inflicted in their violations. That is called justice. Prisons, generally, suck. Are prisons good schools or preventers of recidivism? Some say yes, some say no. But most agree that they suck. I cannot speak for the remainder of HN but my read is that prisons are effective at delivering suckage--sometimes more or less than intended, which you can call a miscarriage of justice. reply jstarfish 13 hours agorootparentprevLike an attorney getting a speeding ticket, sometimes you have to rub a high-level official's face in some dirt to humble them and change institutional policy. America has weird leadership fetishes. Captains are supposed to go down with the ship but in times of crisis the President abandons us all to run away on his. reply whythre 13 hours agorootparent>America has weird leadership fetishes. Captains are supposed to go down with the ship but in times of crisis the President abandons us all to run away on his. That’s… not that weird when you think about it. The ‘Going down with the ship’ cliche exists because the ship and crew are main responsibility of the Captain. His responsibility and power do not extend Nation-wide. In a time of crises the last thing you need is your head of state throwing their life away, because then you also have to worry about matters of succession on top of the pre-existing crisis. reply dylan604 14 hours agorootparentprevi'd posit that you're jumping to a conclusion. we've never actually tried prosecuting/convicting/incarcerating CEOs or other high level officials, so we don't know what the deterrent on that would actually be. we need to run the experiments through to the end to see. reply WalterBright 13 hours agorootparentKen Lay of Enron. reply jzb 13 hours agorootparentThe exception that proves the rule. It would have been more accurate for OP to have said we haven't tried prosecuting and imprisoning CEOs, etc, with the same vigor we apply to street crime. Every great once in a while, yes, we actually prosecute the hell out of a few executives. But it's hardly commonplace. reply teddyh 10 hours agorootparentI suspect that it’s not really the crimes, per se, which makes a CEO be prosecuted. Like Joseph Nacchio. reply WalterBright 13 hours agorootparentprevOver time, my thoughts on prison have evolved. I no longer consider their purpose to be punishment, but instead simply segregating people from society who refuse to follow the rules of society. The segregation is enough punishment itself, more punishment doesn't need to be heaped on. reply WalterBright 8 hours agorootparentA corollary to this would be non-violent offenders would be sent to Camp Cupcake, the violent ones to a prison with cells to keep them from preying on their fellow inmates. reply bombcar 12 hours agorootparentprevAnd in this case, where the crime is not one of violence, the punishment doesn't need to involve prison. But the people who knowingly did wrong should receive some sort of punishment, even if it is just financial or being barred from their career path. reply kelnos 9 hours agorootparentI dunno, I think forcibly imprisoning someone under false pretenses counts as violence. Not the clear-cut obvious violence of throwing a punch or firing a gun, but still violence nonetheless. I prefer to look at it in terms of the harm caused to other people, and how direct that harm is. * Use illegal drugs? No direct harm to anyone else. * Deal drugs? Indirect harm to others. * Put someone in prison for crimes you know they didn't commit? Direct harm to others. (And on top of that, abuse of the trust that the public has put in you, in allowing you to have that power over others.) The magnitude of harm should also factor in, but I think that's a discussion for another day. reply whyenot 13 hours agorootparentprev> here on HN we talk about how prisons don't work I don't know who has argued that, HN is a community of people all with different views. That's a big part of why I am here! I think the current crime rate in El Salvador, which is now supposedly lower than in the US, is a pretty clear illustration that prisons do work. Of course, there are also a lot of negatives and injustices with mass imprisonment, but it sure looks like it works to reduce crime. reply bloqs 13 hours agorootparentprevI think because both things can be correct. Prison is a deterrent to people who participate in society to a high level, but not to those who fundamentally reject society as they are at the bottom of the pyramid. reply kelnos 9 hours agorootparentprevWho is this \"we\"? HN is not a monoculture; beliefs differ. But I think it's more nuanced than that. I don't think it's hypocritical to believe that some crimes are better handled with mental health care or drug treatment programs than prison, while also believing that people who knowingly send people to jail under false pretenses should themselves spend some time there. Also consider that sometimes people think that others should be punished. If my neighbor goes to jail because they like cocaine, and just had some around the house (and weren't dealing), I don't think I'm going to sit back and be all like, \"wow, that person had it coming, glad they're getting punished for ::gasp:: having some powdery substance at home, the horror\". But if my neighbor goes to jail for murdering my other neighbor, I'm probably fine thinking that a murderer deserves some sort of punishment for what they did. reply pasabagi 12 hours agorootparentprevI guess there are two aspects to prison: the first is as you said, a deterent, an agent of rehabilitation, a place of punishment, etc - the ideal form. Questionable, but ultimately something a lot of people could agree to. Then, there is really-existing-prison, which is a place of misery for the people who, almost entirely due to structural reasons, get railroaded repeatedly into its embrace. So even prison abolitionists are often rather sanguine about imprisoning people like CEOs and high level officials who, despite being absolutely manifestly not railroaded, who have the structure covering from them at every turn, and end up both committing and being convicted as criminals. I don't think this is necessarily contradictory: you can be fine with the idea of some kind of prison while also recognizing that the current system is a rather pointless and dysfunctional form of sadism that has no relation to any practical or ethical goal. reply jzb 13 hours agorootparentprevSome users say those things, but they may be different users than the ones saying CEOs (etc.) should go to jail when they commit crimes. And/or it could be that, despite the idea that prisons don't work, if you're going to punish one set of \"criminals\" then we ought to apply the penalties evenly... especially since the crimes committed by CEOs/HLOs are often more harmful overall. Ironically, the threat of prison might be much more effective if white collar types expected to be punished more regularly than they are. Economically, people who wind up incarcerated are often[1] on the low end of the income scale. That is, people who may feel they have little to lose by committing crimes because their standard of living isn't great to begin with. [2] If these CEOs/HLOs felt there was a good chance they'd end up not only ruining their career but actually going to jail ... they might feel they have too much to lose to commit the crimes in the first place. [1] https://www.prisonpolicy.org/reports/income.html [2] I'm not suggesting that the standard of living in prison is comparable to being free, even if you are actually dirt poor. But if you've been broke or poor, and you have no expectation of that changing, you might understand why someone might take risks. reply surfingdino 12 hours agorootparentprevThe kind of response you see in this case is a call for a payback for the miscarriage of justice that destroyed people's lives. Quite justified given what was done to hundreds of people. reply didntcheck 12 hours agorootparentYep. I'm not normally one for harsh punishments, but IMO acts which knowingly undermine the integrity of the justice system, and especially using the state as an unwitting tool to punish innocent people, should be offences treated extremely harshly as they're pretty much attacks on the foundations of \"society\" itself. And this was a very premeditated conspiracy to pervert the course of justice on a gross scale, and they did so numerous times reply cowboysauce 10 hours agorootparentprevI'm curious, where are you seeing this? At least four people are dead and hundreds had their lives ruined in the aftermath. I'm struggling to think of a crime with a similar number of victims that has been posted here and people have been sympathetic towards the perpetrators. There was that Hans Reiser message that was posted recently and I saw a good number of comments saying that he was an unrepentant psychopath who deserves to be in jail. And he \"only\" killed one person. I see people calling for reform and rehabilitation for things like drug possession, but never for crimes of this magnitude. reply nothercastle 14 hours agorootparentprevYes prison does deter white collar crime. Petty crime probably not but this kind of shit absolutely. reply FpUser 13 hours agorootparentprevSo change prisons with the emphasis on rehabilitating people where possible instead of punishing for the fuck of it. What does that have to do with sending criminals to \"rehabilitation\" prisons. And when people of power commit crime they must be first in line for compromising integrity. reply plagiarist 13 hours agorootparentprevThey don't deter crimes like theft and gang as much as actual thriving wages and possibly for advancement do. But I reckon they might deter crimes such as falsifying evidence or burying hundreds of people in a mass grave behind your work building, if the people doing those crimes actually did go to jail. Wage theft is another crime we should try jails for, those are not people struggling to make ends meet. reply sophacles 11 hours agorootparentprevThere's a lot to unpack in this little comment! First of all - HN is a website where many different people, with different views post comments and have discussions/debates. Declaring that there's one singular view while ignoring the dozens of debates in comment sections all over the front page is kind of absurd. Some people don't think prisons work, some do. The voices calling for prison reform or abolishment may not be the same voices calling for CEO imprisonment. Second - The idea that the law should be applied to everyone with the same vigor is not at odds with wanting to change bad laws. If the law can send a peon to prison for years, it should just as well send a CEO to prison for years too. Hell, if I think a law is bad and needs to change, having a CEO face consequences for it might cause a rare circumstance where a CEO uses their position and influence to effect the change. Third - wanting prisons that actually rehabilitate or deter or whatever is often advocating for prison reform, not consequence-free law-breaking. I can want a murderer sent to prison at the same time I want make prisons actually effective, in fact it's pretty consistent no? Fourth a lot of voices are louder when a CEO or official is suspect of a crime since (as in this case) often they get away with crimes far worse than those committed by people who are severely punished. Even when the ceo/official is blatantly guilty. Even more so when the ceo and officials commit additional crimes and frame innocents for them. Fifth, in the spirit of \"turnabout is fair play\" - (again as in this case) the CEOs and officials that wanted to stomp out the bad actors and be tough on the crime should not be hypocritical and accept that the crimes they committed need to be stomped out and have tough consequences. reply ClumsyPilot 13 hours agorootparentprevWhy is it that the same people who call for capital punishment, suddenly loose all their steam if you agree with them and say Boeing executives should be first in line for killing 300 people? reply senderista 13 hours agorootparentKinda like the people who think the Capitol police should have just shot all the rioters. reply mulmen 12 hours agorootparentprevBecause those people are made of straw. They can only speak when you speak for them. reply JohnFen 12 hours agoprev [–] If bugs of that severity were known from the start, then (taking the most generous interpretation), it was incompetence of the highest degree that the software was released. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fujitsu has acknowledged that software bugs in its Horizon system, used by the UK Post Office, were present from the start, resulting in the wrongful prosecution of over 900 postal workers.",
      "The bugs were deliberately concealed from the wrongly accused individuals' lawyers, and witness statements were altered by the Post Office to give the appearance that the system was functioning correctly.",
      "Approximately 93 convictions have been overturned, and there are still pending compensation settlements. The scandal may prompt changes in the system that permits private corporations to prosecute individuals. Fujitsu has apologized and committed to assisting in compensating the victims, while the UK government plans to introduce a new law to swiftly exonerate and provide compensation for those falsely convicted."
    ],
    "commentSummary": [
      "The UK Post Office scandal involving Fujitsu has sparked discussions on various topics including tampering with witness statements, company culture, and software issues.",
      "The scandal has raised concerns about wrongful convictions, the impact on individuals, and the need for a fair legal system.",
      "The discussions have also highlighted flaws in software development processes, government procurement, and the role of private prosecutions."
    ],
    "points": 454,
    "commentCount": 222,
    "retryCount": 0,
    "time": 1705689644
  },
  {
    "id": 39057502,
    "title": "Thailand Unearths 15M Tonnes of Lithium, Bolstering EV Ambitions",
    "originLink": "https://www.malaymail.com/news/money/2024/01/19/thailand-discovers-nearly-15-million-tonnes-of-lithium/113414",
    "originBody": "ADVERTISEMENT MONEY Thailand discovers nearly 15 million tonnes of lithium Aerial view of brine ponds and processing areas of the lithium mine of the Chilean company SQM (Sociedad Quimica Minera) in the Atacama Desert, Calama, Chile, on September 12, 2022. Thailand has discovered nearly 15 million tonnes of lithium deposits, a government spokesman said today, a boost for the kingdom's goal of becoming a regional hub for electric vehicle production. — AFP pic Join us on our WhatsApp Channel, follow us on Instagram, and receive browser alerts for the latest news you need to know. Friday, 19 Jan 2024 7:00 PM MYT ADVERTISEMENT BANGKOK, Jan 19 — Thailand has discovered nearly 15 million tonnes of lithium deposits, a government spokesman said today, a boost for the kingdom’s goal of becoming a regional hub for electric vehicle production. The find means Thailand has the third largest lithium resources, behind Bolivia and Argentina, but it is not yet clear how much can be exploited commercially. The 14.8 million tonnes of lithium are distributed between two separate sites in the southern province of Phang Nga, government deputy spokeswoman Rudklao Intawong Suwankiri told The Nation television station. ADVERTISEMENT “We are trying to find out how much can we use from the resources we found. It takes time,” Rudklao told The Nation. Lithium is a key component in the manufacture of batteries used in electric cars, as well as smartphones and other electronics. The government of Prime Minister Srettha Thavisin, which took over in August, has made it a priority to try to boost Thailand as a regional production hub for electric vehicles, building on the kingdom’s history of assembling conventional cars. ADVERTISEMENT During the World Economic Forum meeting in Davos, Srettha met industry leaders including the deputy chairman of Bosch to urge him to invest in EV production in Thailand. “It’s good news. It’s an opportunity for Thailand to become self-reliant in the production of EV batteries,” Rudklao said of the lithium discovery. In December 2023, two Chinese EV giants said they would invest 2.3 billion baht (RM301 million) to develop Thailand as a production hub. — AFP ADVERTISEMENT You May Also Like Related Articles Money / 13 Jan 2024 Tesla, Volvo Car pause output as Red Sea shipping crisis deepens Money / 24 Dec 2023 Musk, US interested in Argentina’s lithium reserves, says president Money / 1 h ago UK lawmakers ask public bodies for details on contracts with Fujitsu ADVERTISEMENT JUST IN 1 m ago Tawau’s RM20m International Cultural Centre construction to commence this year, says Sabah asst minister 15 m ago Major drug syndicate bust: Ringleader, 10 members to face prosecution in Kota Kinabalu 19 m ago State minister: No discussion on new governor during Sarawak Cabinet meeting on Thursday ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=39057502",
    "commentBody": "Thailand discovers nearly 15M tonnes of lithium (malaymail.com)429 points by amarant 17 hours agohidepastfavorite252 comments rmm 10 hours agoThis is my wheelhouse (mining engineer) and sorry to say this is bunk from what i can see. Its not 15M Tonnes of Lithium. Its 15M Tonnes of lithium containing ore, with an average grade of 0.4% (which i also question without seening core results). Also terms such as \"resource\" and \"reserve\" have very specific meaning in mining (to do with economic viability of deposity/ level of confidence) and this is by no way a \"reserve\". Most likely overzealous government minister/media hyper. (sorry to rain on parade!) reply bboygravity 7 hours agoparentThe real info is always in the comments. reply omginternets 6 hours agoparentprevCan you elaborate on the specific meanings of “resource” and “reserve”? This has piqued my interest. reply defrost 5 hours agorootparentThe largest resource market on the globe is the Toronto TSX which uses the Australasian Code for Reporting of Exploration Results ( JORC ) and other damn near equivilent definitions. https://www.jorc.org/ Pages 8 & 9: https://www.jorc.org/docs/JORC_code_2012.pdf Essentially: (InferredIndicated) Resources is weak guesswork whereas: (MeasuredProved) Reserves is (almost) bankable. If you're in a certtain type of geology that looks a lot like other geology that's been mined, and you have some surface geochemstry results you can claim to have (say) a 10 square mile area of indicated copper resources which correlates with (say) 500 million tonnes of extractable resources. This will then appear in a resource map .. and it's fantasy footbal stuff. The real money gravitates towards increasing proven resources - this is a volume of the earths crust that has been * surface tested, * geophysically tested, * sparsely drill tested, * densely drill tested, * modelled as a 3D volumetric dispersal of elements and compounds, * modelled for economic feasibility of extraction (will it cost less to extract than the value of the material extracted). This is the evolution of potential mining ground from a prospect through to something that gets listed on a minerals exchange as a capital investment to build processing equipment and dig holesshaftsleach miningetc. reply defrost 3 hours agorootparentApologies for so many typos ... s/fantasy footbal /fantasy football / > The real money gravitates towards increasing proven reserves etc. Like a Reserve Bank - a mineral Reserve is a known entity - at least as known as anything can be to the limits of modern technology prior to actually digging it up. There's been enough drilling to know the volumetric extents and grades of the materials of interest (most deposits have multiple minerals of interest), and quite often there's been an independant third party engineering and economic Technical Report commissioned on the feasibility of extraction, costs, methods, lifetime, and expected profit margins. reply manvillej 6 hours agoparentprevso like 6 million KG of lithium. or enough lithium for 750,000 EV cars reply mkl 6 hours agorootparent15,000,000t×0.004 = 60,000,000kg. 60,000,000kg/63kg per car [1] ≈ 952,000 cars, about 55% of Tesla's production last year. [1] https://electrek.co/2016/11/01/breakdown-raw-materials-tesla... reply uoaei 5 hours agorootparentYikes, looks like EVs are gonna be resource-constrained real soon unless new battery tech emerges. reply prawn 2 hours agorootparentSwear I read an article recently about cuts to a lithium project in Australia due to dwindling demand. Here's an article about it: https://www.abc.net.au/news/2024-01-18/kemerton-lithium-proj... Including: \"Demand for lithium has dropped by more than 80 per cent in the past year and nearly 11 per cent in the past month alone.\" reply fooker 1 hour agorootparentprevLithium is one of the most abundant solids in the universe. The earth has plenty, it's just going to become more and more economically feasible to extract it. You can even get reasonably large amounts from seawater if you have cheap energy. reply MattRix 4 hours agorootparentprevMore lithium deposits will be found now that it is more desirable. The earth has plenty. reply Throwawayh89 5 hours agorootparentprevOr new lithium sources reply borissk 2 hours agoparentprevHow would you interpret this news about phosphate in Norway: https://www.euractiv.com/section/energy-environment/news/gre... ? reply maliker 16 hours agoprevLooks like existing worldwide reserves are 26M tons [0], so this is a big find. [0] https://pubs.usgs.gov/periodicals/mcs2023/mcs2023-lithium.pd... reply Night_Thastus 15 hours agoparentI think that true global reserves are much higher than what we know now. Before, Lithium was important, but not nearly in the quantities needed for EV's. Now that EV's have picked up, more people will be looking for Lithium, and that will make all the difference. reply ajuc 15 hours agorootparentWhen you look at elements' abundance in Earth's crust lithium is about 50% more common than lead, but we mine 268 times more lead every year. We just weren't looking very hard to find lithium compared to lead till very recently. https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth... reply legulere 13 hours agorootparentMinerals can be common but infeasible for extraction. Aluminum is one of the most common elements but we extract it just from bauxite reply Tuna-Fish 8 hours agorootparentWe extract aluminum only from bauxite because it's slightly (think 5%) less expensive to refine it from bauxite than the next class of materials. If all of world's bauxite reserves ran dry, we would move to the next best sources, and this would impact aluminum prices less than typical yearly variations in electricity costs near smelters. Nearly all aluminum minerals are potential ores for aluminum, the only question is how much other, undesirable material (mostly silica) you need to remove. Bauxite is nice because nature did a lot of the early separation process steps (slightly acidic rains washed away silica over millennia). reply Ringz 11 hours agorootparentprevJust like uranium. reply brianwawok 14 hours agorootparentprevLithium is a pretty volatile chemical though. Does the 50% more common take into account the fact that some lithium blows up? reply kadoban 13 hours agorootparentLithium isn't found as a pure element, if that's what you mean. It's part of minerals bound up into stable molecules. So it won't blow up. It's very hard to find anything volatile in nature, pretty much by definition. Exceptions are things that are continually generated, eg you can find reactive oxygen in nature because plants keep making more. That or things that are only volatile once you purify or transform them in some way. reply adonovan 13 hours agorootparentprevThat “blowing up” already happen billions of years ago. Lithium salts (ore) is what is left when lithium violently oxidizes. reply frabert 14 hours agorootparentprevIs lithium normally mined in its elemental form? If not, its volatility as an ore might be wildly less than in its metallic form reply Legend2440 10 hours agorootparentEssentially no metals are mined in their pure elemental form - only the noble metals like gold or platinum. reply HeatrayEnjoyer 14 hours agorootparentprevDoes the ore blow up often? reply Arrath 7 hours agorootparentI suppose it depends on if blasting is utilized at a given lithium ore production site. reply crote 13 hours agorootparentprevA big part of that is simply in the meaning of \"reserve\". For something to be counted in the reserve it has to be a) measured, and b) known to be economically viable to extract. There are plenty of known deposits of unknown size and quality. They are just by definition not included in the reserve. As demand grows those will be explored and included in the total count. reply nordsieck 15 hours agorootparentprev> I think that true global reserves are much higher than what we know now. That was certainly true of oil. As reserves got depleted, progressively more advanced techniques allowed people to extract from more difficult locations. reply stouset 15 hours agorootparentAt ever-increasing costs. reply baq 15 hours agorootparentAnd decreasing EROI. Maybe you meant that, but it’s worth stating outright, as no amount of money can fix that. reply newyankee 4 hours agorootparentThe EROI of Solar PV is quite decent. I hope a lot of demand can move to Solar peak at different locations, especially industrial demands. reply stouset 9 hours agorootparentprevYep, that’s frankly a much bigger deal and something I should have specifically noted. reply kortilla 9 hours agorootparentIt’s not really a big deal because we have renewables that can fund the extraction. Oil isn’t useful for its contribution to global energy, it’s useful because it’s portable. reply stouset 5 hours agorootparentRenewables used for extracting oil are renewables that can’t be used for other uses, and this shortfall will need to be made up for by… burning fossil fuels. reply BurningFrog 10 hours agorootparentprevThat's what I learned from the \"Peak Oil\" scare/fiasco. Let's not be fooled again! reply linhns 15 hours agorootparentprevIt’s very likely to go the way of oil. EV demand has slowed down recently (honestly I don’t believe the world is ready for mass adoption and EVs themselves are not ready also), so we’ll keep finding more and more and always beyond the consumption. reply kccqzy 14 hours agorootparentI hate the weasel words of \"demands slowing down\". It's always not clear what exactly is happening from this phrase. Is the production or sales going down year-over-year or quarter-over-quarter? Because that's what people think \"demand slowing down\" means. However what's actually happening is that demand is going up, but at a rate slower than before. Imagine that in 2022 demand increased by 60% YoY but in 2023 demand only increased by 40% YoY (these are approximate figures). You are measuring the second derivative which is decreasing from a big positive value to a smaller positive value, which is not usually described by the word \"slow\". Intuitively \"slow\" means the second derivative has become negative. reply Rexxar 10 hours agorootparentIt's worst than that : the 40% are bigger that the 60% of the previous year in absolute value (100 => 160 => 224). It's not even slowing down. reply digging 11 hours agorootparentprevSo the rate of change of demand is decreasing. Decreasing rate of change is the definition slowing down. Although I agree that most people probably misinterpret the phrase as you say. (It seems other replies have had that interpretation.) reply throwaway167 6 hours agorootparentIncreasing less fast is not the definition of slowing down, it's the definition of increase increasing less fast. reply thebruce87m 1 hour agorootparentprevIf you reduce acceleration, your speed is still increasing if you still have positive acceleration. This is still speeding up, not slowing down. reply thebruce87m 14 hours agorootparentprevGlobally demand is up. https://www.reuters.com/business/autos-transportation/global... > LONDON, Dec 12 (Reuters) - Global sales of battery electric vehicles (BEV) and plug-in hybrids (PHEV) rose 20% versus a year ago as strong growth in North America and China offset lower sales in Europe, according to market research firm Rho Motion. reply feedsmgmt 14 hours agorootparentprevI think that is an odd opinion to have. The data shows otherwise: https://www.canarymedia.com/articles/electric-vehicles/chart... reply epistasis 13 hours agorootparentThere are large propaganda channels masquerading as news outlets that push this idea continually as part of culture war. I would agree it's an odd opinion, but it is fairly common due to the ever present misinformation. reply enslavedrobot 6 hours agorootparentOr maybe it's the fact that incumbent manufacturers of internal combustion cars spend billions on advertising and publications are protecting their source of income. reply SeanAnderson 16 hours agoparentprevThe second sentence of the article states, \"The find means Thailand has the third largest lithium resources, behind Bolivia and Argentina, but it is not yet clear how much can be exploited commercially.\" If Thailand has 14M and there are two others with >14M then total known resources must be at least 42M tons, no? reply marcosdumay 15 hours agorootparentReserves are only defined when you also state a price. It's not a free number. Those people are probably using different prices, and not communicating them. reply whimsicalism 15 hours agorootparentWhat? These are denominated in tons, not dollars. reply adgjlsfhk1 15 hours agorootparentThe point is that reserves are only economically viable at a given price. At $0 there are 0 reserves because no one is willing to give you lithium. At $1 mil per kg, there is basically infinite reverses because you can do things like dig up the entire earth's crust and filter all the lithium out of it. reply solardev 13 hours agorootparent> At $1 mil per kg, there is basically infinite reverses because you can do things like dig up the entire earth's crust and filter all the lithium out of it. YC Summer 24? reply whamlastxmas 10 hours agorootparentprevIt's even more relevant because it doesn't have to get that crazy, there's 230 BILLION tons in sea water, and it's not a crazy impossible processes to extract lithium from it given some more advances in the process reply Jensson 6 hours agorootparent230 billion tons in sea water isn't even a single PPM, doesn't seem feasible to me. reply whamlastxmas 6 hours agorootparentThey're already building a pilot facility to do so: https://www.theengineer.co.uk/content/news/kaust-spinout-wil... Lithium can be a lot more prevalent in some waters, they are already competitive commercial mining operations from briny lake beds. Utah's Salt Lake for example is 21ppm and is mined at $2/kg reply Jensson 4 hours agorootparentBut that is lakes, not seas. Lakes are extremely small compared to the seas so doesn't hold that much lithium so you can't really scale that up. To get the amount you talked about we would need to start pumping water from the depths of the seas, since most of it is there. reply whimsicalism 13 hours agorootparentprevgotcha - thanks! reply Vecr 15 hours agorootparentprevTons economically extractable at that price. reply DougBTX 16 hours agorootparentprevReserves and resources are different measures, same doc says 98M resources. reply mrinterweb 14 hours agoparentprevThere was a very large (20-40M tons) deposit recently discovered on the border of Oregon and Nevada. https://www.nevadacurrent.com/2023/09/22/report-of-giant-lit... reply Tagbert 13 hours agorootparentthat one is near the surface and consists of clay deposits so extraction and refining should be much easier than many other deposits, such as in Australia. reply tim333 12 hours agoparentprevReserves are very different from resources though. In mining jargon the resource is how much you think is out there, a reserve is ore that you drilled, analysed, mapped out and shown to be profitable extractable, so a lot less. Because turning resources into reserves is expensive only a limited amount is done before it is mined. reply Tuna-Fish 8 hours agorootparentNot quite. Resource is how much you can show is there, reserve is how much can be extracted at a given cost. \"What you think is out there\" differs from resource in that a honest answer to the former would need to involve doing a lot of statistics on the 99+% of \"empty space\" of earth's crust that could potentially be exploited but that has not been explored, based on the data points you have of the areas that you have explored. While resource refers to specific deposits that someone has done work on to show they exist, not the best estimate of how much material is there to be mined. Sorry for being nitpicky, but people on the internet constantly get this wrong. No-one maintains a number for \"how much lithium (or oil, or any other material) we believe there remains to be mined\", and every number that occasionally gets misused to represent that is off by multiple orders of magnitude. reply alexwasserman 16 hours agoparentprevThat link says 98M tonnes towards the end, unless I’m misreading reply scythe 15 hours agorootparentRight, Thailand hasn't just opened 14Mt reserves, rather resources. A reserve is a resource that you're prepared to exploit. But see also: https://news.ycombinator.com/item?id=39059076 reply nilsherzig 15 hours agorootparentprevI think it's 89M t resources (under the ground?) and the other number is what they already mined reply onthecanposting 14 hours agoparentprevLet's hope this isn't another BRE-X. The press release seems to imply these are inferred or probable reserves. Great news if it's true. reply cmcaleer 11 hours agoparentprevImportant line from the article: \"...but it is not yet clear how much can be exploited commercially\". This likely doesn't mean a straightforward +15M tons to the world's supply. reply genman 12 hours agoparentprevThe confusion comes from wrong vocabulary. There are two different words in use: resources and reserves. Resources is what ever there is in (or in some cases on) the ground. Reserves is what can be viably extracted. World lithium resources are close to 100M tons, but usable part, reserves, is about 1/4 of it. Notice how it is also stated in the article: “We are trying to find out how much can we use from the resources we found. It takes time,” Rudklao told The Nation. So they don't know how big are the reserves. reply nextaccountic 5 hours agorootparentWhy only 100M? Shouldn't Lithium be absurdly abundant, given it's a lightweight element? reply topspin 15 hours agoparentprev> so this is a big find Plus it's far away from the environment, so recovery will be uncomplicated. reply mindcrime 9 hours agorootparent> Plus it's far away from the environment So it's in another environment? reply Hackbraten 14 hours agorootparentprevI see what you did there. [0] [0]: https://youtu.be/3m5qxZm_JqM reply smcin 1 hour agorootparent@ 1m30s Classic Clarke & Dawe reply laweijfmvo 15 hours agoprevI'm assuming it's not a giant 15M ton chunk of (highly reactive) metal in the ground, but rather they took a bucket of dirt, analyzed it, and extrapolated how much lithium is available in the ground. My question is, how much \"earth\" do they need to dig up and refine to extract this amount of lithium? reply rmm 9 hours agoparentfrom what i can see the media/government minister have blown this out of proportion. First off it looks like they identified 15M tonnes of lithium hosting rock (pegmatite) which has a grade of 0.4% of lithium in the form of spodumene (which then needs ot be processed to extract the lithium out of). But in general, how it works is they drill a bunch of holes in the ground and analyse the cores. From that that interpolate the size/shape of the ore body and calculate an estimate of size. The more holes they drill the greater the confidence. There is a lot of 'art' to this science reply hackernewds 3 hours agorootparentcurious how you know all this info, if you can share to the level you feel comfortable reply chefandy 9 hours agorootparentprevRoughly what how much volume would 15m tons of pegmatite take up? I have no intuitive sense of scale with these things. reply Jensson 2 hours agorootparentRocks tend to be 5-10x denser than water, so assume 2 million cube meters. That is just 2 square kilometers 1 meter high, so not mountains or so. As a comparison, for a large iron mine they dig up many billions of tons of rock, and that is for very cheap iron, so you wouldn't need a very large operation to dig this up. reply s0rce 13 hours agoparentprevthis site says 0.4% so they would need to extract 3.5B tons of rock https://thethaiger.com/news/national/thai-lithium-deposits-o... reply rmm 10 hours agorootparentIts not. Its 0.4% of the 15M Tonnes. (so much smaller) This is most likely government minister/media hype. reply hackernewds 3 hours agorootparentprevdouble check your math reply herdrick 12 hours agoparentprevNormally an announcement like this would be based on a program of drilling. But yes there would be a lot of interpolation and I think some extrapolation. reply latchkey 16 hours agoprevIf Thailand has it, Myanmar, Laos and Cambodia probably do too. Edit: After checking on a map, probably Myanmar/Malaysia. reply drak0n1c 16 hours agoparentMyanmar has the most bountiful gem mines in the world. I visited in 2019 and there were many shops with piles of ruby, jade, sapphire, even amber. They're already pretty specialized in mining and have little qualms about razing mining areas so would be able to take quick advantage - if their civil conflict allows. reply kingkongjaffa 15 hours agorootparent> Myanmar has the most bountiful gem mines in the world. I assume that's hyperbole because I couldn't find a list of top producing countries that included Myanmar, do you have a link? reply seaal 15 hours agorootparenthttps://en.wikipedia.org/wiki/Myanmar#Extractive_industries > Myanmar produces precious stones such as rubies, sapphires, pearls, and jade. Rubies are the biggest earner; 90% of the world's rubies come from the country, whose red stones are prized for their purity and hue. The article that is cited is from 2010, seems like overall gem production has decreased significantly since then. https://www.statista.com/statistics/1061659/myanmar-producti... reply crossroadsguy 15 hours agorootparentprevWell, it’s definitely not ideal. But if history is anything to go by, then either they themselves take it and maybe by killing each other; or someone from outside will come and do the killing for them and then take it all and also sell some freedoms while they’d be at it. reply whimsicalism 15 hours agorootparentprevNo, I think Botswana or DRC does reply huytersd 15 hours agorootparentprevAnecdotal evidence can be misleading. I went to India and saw a literal pile, 7 ft high and maybe 10 ft in diameter of emeralds casually “stored” in a corner of a room but I don’t think India produces all that many emeralds (it’s primarily a cutting hub). reply imnotreallynew 7 hours agorootparentWhere was this? reply huytersd 5 hours agorootparentSomewhere in Rajasthan. reply downrightmike 13 hours agoparentprevMyanmar is in active civil war and under sanctions https://www.state.gov/burma-sanctions/ Even if they did find it, no one would be able to use it. reply panzi 15 hours agoparentprevGiven where the province is I would only speculate for Myanmar and Malaysia. reply latchkey 15 hours agorootparentI admit that I didn't check closely enough on a map and now that I have, you're probably right about that. reply kyawzazaw 16 hours agoparentprevAs someone from Myanmar, this piques my interest reply Rodmine 16 hours agorootparentIt's the new oil, so I would be careful. Democracy and camaraderie and all those greater good things tend to come where the cheap resources are. reply toomuchtodo 16 hours agorootparentDeposits appear sufficiently distributed to not cause geopolitical conflicts [1]. This is not oil. Lithium is relatively abundant, and a mineral to be reused, not energy to be consumed once through. To keep it conflict free, we must continue to discover reserves and drive down the value of the commodity. No one goes to war over say, salt, in the 21st century (at least not yet!). [1] https://lithiumfuture.org/map.html reply NERD_ALERT 16 hours agorootparentThe 2019 Bolivian political crisis [1] came right off the heels of Evo Morales negotiating lithium trade with Russia and China. Bolivia happens to have the largest lithium reserves of any nation. [1] https://en.m.wikipedia.org/wiki/2019_Bolivian_political_cris... reply m00x 14 hours agorootparentGood context, but not a geopolitical crisis, it was an internal civil conflict. reply NERD_ALERT 13 hours agorootparentThe US/CIA has a long history of inciting coups, rigging elections, and funding far right terror organizations across Latin America for matters similar or lesser than this [1]. I wouldn’t be so quick to dismiss this as unprovoked internal conflict. Especially given that only a year after this event, another election was held in which Luis Arce won in a landslide [2]. Luis Arce was importantly the finance minister for the Evo Morales administration [3]. There’s no evidence that popular support had ever waned for the Movement for Socialism in Bolivia. Yet Jeanine Añez was able to win in 2019 and exile Evo Morales in an election that involved, “irregularities and serious human rights abuses by security forces,” according to independent human rights organizations [4]. [1] https://en.m.wikipedia.org/wiki/United_States_involvement_in... [2] https://en.m.wikipedia.org/wiki/2020_Bolivian_general_electi... [3] https://en.m.wikipedia.org/wiki/Luis_Arce [4] https://www.theguardian.com/world/2021/aug/17/bolivia-govern... reply astrange 10 hours agorootparent> The US/CIA has a long history of inciting coups, rigging elections, and funding far right terror organizations across Latin America for matters similar or lesser than this [1]. More recently we've been supporting leftist elected candidates against right-wing coups. We don't care Bolivia has lithium. We get lithium from Australia. Third worldist leftists have many dumb ideas, but among them is the idea that wars are for resources or that we're exploiting third world countries by taking their resources. It's almost the opposite - they are poor because we aren't trading with them. reply NERD_ALERT 19 minutes agorootparentWhich left wing governments have we defended against right wing coups? reply avgcorrection 11 hours agorootparentprev> Good context, but not a geopolitical crisis, it was an internal civil conflict. Do you think clandestine services pursue their goals by declaring war on countries? reply Izikiel43 13 hours agorootparentprevThis was because Evo was running again even when their constitution forbid it, basically every latin american president dream of eternal reelection. reply latchkey 16 hours agorootparentprevIt won't cause conflict because China will just come in and take it. Look at what they've done with the silkroads through Laos/Cambodia. \"Here, take a 'free' hydrodam on your river and we will just take some land and electricity.\" reply TaylorAlexander 15 hours agorootparentSounds like a trade to me. Predatory tho if the country is very poor and easily exploited. But as someone from a country that loves to invade others for resources I’d take predatory trading over military force any day. reply latchkey 15 hours agorootparentYou didn't dive deep enough into the literal eco/social catastrophe that the silkroad is. It isn't military because neither of those two countries have any sort of way to defend themselves against China, but it might as well be military, because China. https://en.wikipedia.org/wiki/Belt_and_Road_Initiative reply iinnPP 15 hours agorootparentprevThat's a whole lot better than the deal from the US, frankly. reply dragonelite 13 hours agorootparentprevBut processing the lithium and making productive tools or products out if it isn't really distributed. reply vlovich123 16 hours agorootparentprevCan you clarify about reuse? At least as far as batteries go, right now once it's in a battery it gets used up & then ends up in the trash [2]. There's no efficient / cost-effective way to extract lithium from spent batteries for reuse in new batteries. We might in the future but it would require some scientific advances + expensive commercialization to scale up. Even if in the future we do develop a mechanism, it could remain very expensive & not be practical until mining costs have gone up enough. Similarly, all batteries that have been consumed until that point are likely irrecoverable as they're in the waste stream & finding & collecting those batteries is unlikely to ever be economical. [1] https://americanbatterytechnology.com/lithium-costs-a-lot-of... [2] https://www.popularmechanics.com/science/energy/a42417327/li... reply toomuchtodo 16 hours agorootparenthttps://www.forbes.com/sites/alanohnsman/2023/11/02/redwood-... > In 2024, a quarter million aging electric vehicles will be ready for dismantling and recycling. That could be more than a 30% jump from 2023 — and Redwood Materials, which aims to be the country's leading EV battery recycler, is ramping up its operations to prepare for the coming onslaught. > The company created by Tesla cofounder JB Straubel, which also makes components for new batteries from materials it recovers from old ones, expects some 250,000 aging Tesla Model S sedans, Nissan Leaf hatchbacks, Toyota Priuses, Prius plug-ins and other hybrids, to turn up at dismantler lots in 2024 — with more coming every year after. That’s up from between 150,000 to 200,000 this year. To ensure it gets as many of those old batteries as possible, it’s launched a web portal to quickly give auto dismantlers purchase offers and schedule trucks to haul them away for recycling. https://www.reuters.com/markets/deals/redwood-inks-long-term... (\"Redwood inks long-term EV battery materials supply deal with Toyota\") Redwood Materials is currently operational, processing the waste stream. Ford and Volvo are also partners. They'll also accept EV packs that are damaged, defective or recalled (DDR) on an ad hoc basis if you open a ticket with their team. https://www.redwoodmaterials.com/auto-recyclers-battery-port... (have shipped them old Leaf and Tesla packs) reply dark_star 16 hours agorootparentprevCheck out Jeffrey \"JB\" Straubel's new company, Redwood Materials[1][2]. They recycle lithium-ion batteries. He was Tesla's former chief technology officer. They are essentially a lithium mine that's using a very high quality ore, ground-up batteries. There are other companies doing this as well. [3] 1. https://www.redwoodmaterials.com/ 2. https://www.cbsnews.com/news/battery-recycling-redwood-mater... 3. https://li-cycle.com/technology/ reply danans 16 hours agorootparentprev> There's no efficient / cost-effective way to extract lithium from spent batteries for reuse in new batteries. We might in the future but it would require some scientific advances + expensive commercialization to scale up. It's already 95% efficient. No fundamental scientific advances are needed. It's already being scaled commercially. One example: https://li-cycle.com/ reply kube-system 14 hours agorootparentprevBasically zero EV or HV batteries make it into the trash. They're recycled and already have a pretty good scrap value. reply vlovich123 12 hours agorootparentI was thinking mostly about phones, laptops, power banks etc. I couldn’t find any source online that expressed what percentage of lithium goes to different kinds of applications. reply lainga 16 hours agorootparentprevCountries can suffer Dutch disease just fine without ever seeing a single Marine. reply jldugger 15 hours agorootparentprevWell, it's not like Mynamar's democracy is particularly functional: https://en.wikipedia.org/wiki/2021_Myanmar_coup_d%27état reply deepsun 15 hours agorootparentprevSo... Autocracy / tyranny are better? reply cbsmith 15 hours agorootparentprevIn the sense of \"we'll bring Democracy to your country\", yes. ;-) reply deepsun 15 hours agorootparentPlease do bring democracy to my country of birth, yes. And I mean it. Right now it pretty much is held occupied by brute force. 90% of population would welcome ANY change. reply avgcorrection 11 hours agorootparentThe democracy is of the sarcastic kind by the way. reply 1equalsequals1 14 hours agoparentprevCan't wait for the next genocide in the region, all in the name of freedom reply m00x 14 hours agorootparentBecause there's not currently a genocide happening in the region? https://en.wikipedia.org/wiki/Rohingya_genocide reply setgree 16 hours agoprevwhen valuable resources are scarce, people have an incentive to find and produce more of those resources. As Henry George put it: \"Both the jayhawk and the man eat chickens, but the more jayhawks, the fewer chickens, while the more men, the more chickens\" [0]. [0] https://www.econlib.org/archives/2009/12/the_gist_of_jul.htm... reply jlhawn 15 hours agoparentthat's an argument which works for capital goods (like livestock) but not for what Henry George considered to be natural opportunities of fixed supply like lithium ore (and land in general). Henry George, if he were still alive today, would probably say that valuable raw mineral deposits like this would be more likely to be discovered and brought into productive use earlier if they were taxed. The argument being that people would have no reason to speculate on a large untapped reserve of it. There would still be an incentive to bring it into production because the earned profit would be made through extraction, processing, and distribution of the material even if the higher holding cost of the land is factored in as a cost. reply Waterluvian 16 hours agoparentprevLike with chickens, the Jayhawk should just learn to fuse hydrogen down to lithium. I think the analogy doesn’t quite work. Humans produce chickens because we can do that. We find more lithium because we need it. Jayhawks can also evolve to get better at finding more chickens. And by their very nature, have been doing exactly that. reply wolverine876 16 hours agorootparentEvolution is a bit slow. How many millenia will it take the Jayhawks to figure it out? Humans can increase chicken production this year or maybe next. reply Waterluvian 16 hours agorootparentFor sure. That’s what makes us exceptional. What I’m mainly pointing to is that we can’t currently just mass produce lithium. We just go around looking for it more. reply setgree 15 hours agorootparenthttps://www.cato.org/economic-development-bulletin/julian-si... > when a particular resource becomes scarcer, its price increases, and that change incentivizes people to discover more of the resource, ration it, recycle it, or develop a substitute for it. As such, population growth and resource use do not automatically lead to higher commodity prices in the long run. So no, we can't mass produce lithium, but a high enough price might drive someone to discover a substitute. reply Gravityloss 15 hours agorootparentSodium batteries are being researched as alternative to lithium. Same with other materials like cobalt, nickel, and graphite - there are battery versions that avoid those. reply jacobr1 14 hours agorootparentprevIt is more than that. We also invent new technologies. Searching for resources, refining them, do the same stuff more cost-effectively, extraction from different kinds of compositions and ores with processing methodologies, recycling, changing other elements of a system to require different amounts or mixtures in a final product are all different ways to \"increase yield.\" On the scale of decades, collectively, this is very responsive to demand and why arguments about \"only so much of resource X exists\" are usually highly misleading. reply brianbreslin 16 hours agoprevDoes this mean other elements like cobalt are becoming the bigger bottleneck in battery production? The US found a large lithium reserve in Nevada not long ago; or to be clear a large reserve that they can now more affordably extract. As another commenter said its not that rare, just wasn't cheap to extract before. reply cbg0 16 hours agoparentLFP batteries don't use cobalt. reply mbgerring 14 hours agorootparentOr nickel! reply pkaye 16 hours agoparentprevThere is also the lithium in the California Salton Sea which is further along in getting into production. https://www.energy.gov/eere/articles/us-department-energy-an... reply xeromal 16 hours agoparentprevPretty sure the Salton Sea in california is gonna be a big lithium mine once it dries up reply Geee 6 hours agoprevEarth is huge. It's diameter is almost 13,000 kilometers. The deepest mine is 4 km. There's plenty of stuff. reply mullingitover 16 hours agoprevTechnically every non-landlocked county has a near-infinite supply of lithium. It's the extraction costs that are the problem. reply WrongAssumption 14 hours agoparentReserves take extraction cost into account. reply _heimdall 15 hours agoprevOne thing I didn't see mentioned here, lithium brine extraction has some pretty serious environmental downsides. Finding all that lithium will be a win if/when its extracted and usable, actually extracting it is a different story. reply epistasis 13 hours agoparentI hear people complain about this, but they never place it in context with the damage from, say, iron or copper mining. I've done lots of web searches, read lots of articles, and there's never definitive measures of harm or comparisons to what current mining does. In a standard f150, how much damage is done from mining? How much damage comes from oil extraction compared to the one-time cost to extract lithium? reply jillesvangurp 1 hour agorootparentOr fossil fuels. We do a lot of damage to our planet to extract coal, gas, and oil. And that's before you consider the damage we then do by burning it. Most of that becomes redundant if we scale renewable energy production enough. The impact of Lithium mining is absolutely tiny in comparison to all that. And it kind of is really important as a resource to complete that transition. The good news is that lithium is really common. The bad news is it's mostly not found in high concentrations. For example, ocean water contains about 180 billion tonnes of lithium. But in a concentration of 0.2 parts per million, you'd need to process about five million tonnes of ocean water to get 1 tonne of lithium. Extracting lithium and other minerals from sea water is something we can do nevertheless. It's just not very economical to do it. But the good news is that we are aware of quite a few natural deposits with much higher concentrations of lithium in either brines or different kinds of mineral deposits. That's nature taking its course over billions of years concentrating the lithium for us. And we've barely scratched the surface (quite literally) looking for that stuff as the interest in large scale lithium mining did not exist until about 10-20 years ago. In short, we're not going to run out of lithium. There's plenty of it. Extracting it is indeed costly and depending on how it's done can be a bit nasty. But the good news is that the damage is typically highly localized. And we have ways to mitigate that. And once extracted we can use the lithium over and over again. It's not destroyed by using it. Unlike fossil fuels. reply _heimdall 13 hours agorootparentprevI got a but ranty there. To get back on topic, lithium isn't a one-time cost. Batteries wear out and have to be replaced. If we assume the batteries would outlive the average vehicle, we're committing to vehicles having an expected life of say 10 years. Meaning every 10 years it has to be destroyed, recycled, and replaced. I have a 1988 pickup that still runs great. I don't drive it regularly as my hybrid is much better on fuel, but the damage done from producing that truck was paid for decades ago and I'd be shocked if the cost of a tank or two of gas per month comes anywhere near the ecological impact of a producing a new, electric F-150 that is marginally useful for towing or hauling (my only reason for needing a pickup). reply hinkley 8 hours agorootparentDepends on if we can separate the lithium like we do for lead acid batteries. I wonder if there are any processes left to discover or if this is it. reply _heimdall 13 hours agorootparentprevOh for sure, I have no idea how similar comparisons would shake out. I can say, though, that such comparisons pretty easily lead to tragedy of the commons problems. If we want to decrease our impact on the environment we need to stop using so much energy and so many resources, period. Chasing the next miracle cure, in this case lithium batteries for energy storage, we can easily run down that path picking up all the ecological damage of lithium mining and new manufacturing only to find that there are new problems and we're not much better off, we simply have different problems and a similar level if environmental damage as if had we stayed on the original path. Now that doesn't mean I don't have hope for alternative energies or think we should decrease dependence on nonrenewable sources. I do like the promise of wind, solar, nuclear. etc and also think we should be killing off non-renewables as quickly as possible. I just hope we don't attempt to treat environmental impact as a zero sum game, signing off on more damage based on not exceeding the damage caused by current systems. I also hope we don't stick to a consistent growth of 2-3% in annual energy consumption, its no coincidence that number matches GDP targets and its unsustainable. reply dudeinjapan 2 hours agoprevRIP Kurt https://www.youtube.com/watch?v=pkcJEvMcnEg reply Throw84949 16 hours agoprevLithium is quite common. Problem is minign it without totally destroying local environment! reply bregma 15 hours agoparentLithium is quite common in the ground. Mines are a dime a dozen all over the world. Mining it is the easy part. All processing is done by a handful of plants in China. It needs to be shipped to China, and the products need to be shipped from China to wherever they're used. Mining it is hard on the environment, yes, but it's just a drop in the bucket compared with the part no one talks about. reply unglaublich 16 hours agoparentprevIronically, undestroyed local environment is getting quite rare. reply ashconnor 8 hours agoparentprevDon't worry the Thai government won't care about the environment. reply darth_avocado 14 hours agoprevThis was discovered in Phang Nga. It is full of natural beauty and has some of the most recognizable tourist spots. I wonder how those would be affected. reply print_r 4 hours agoprevWhenever I read articles like this about a small country that finds a rare resource I can't help but think about playing civ 5 in late game and finding out that I have a ton of uranium on my land. reply ggm 10 hours agoprevLithium mines in australia (spodumene) are either delaying opening, or shutting down because market prices have fallen below cost of production. There is no shortage of lithium. reply brianmcc 14 hours agoprevHighly recommend this if you've not heard of it yet, goes into detail about lithium and some other vital raw materials : https://www.amazon.co.uk/Material-World-Substantial-Story-Fu... \"Sand, salt, iron, copper, oil and lithium. They built our world, and they will transform our future.\" reply scythe 15 hours agoprevApparently this has been disputed: https://www.bangkokpost.com/business/general/2727119/thai-li... >But Jessada Denduangboripant, another lecturer with the same faculty, used his Facebook page to offer a reality check. The 14.8 million tonnes, he wrote, represents the pegmatite igneous rocks that contains around 0.45% of lithium. This is a cumulative find in an ongoing exploration project that has identified multiple sites with various grades of lithium-bearing rock: https://www.chemanalyst.com/NewsAndDeals/NewsDetails/thailan... The true quantity of lithium resources in Thailand will probably continue to be adjusted over the coming year, but it probably hasn't crossed the 10M mark. reply Gravityloss 15 hours agoprevHmm so 300 million cars with 50 kg lithium in each. That's about four years worth of global car production. Would make a dent in oil usage certainly! reply kwhitefoot 15 hours agoparentAn EV doesn't have 50 kg of lithium. The 70 kWh battery in my Tesla S has about 12 kg of lithium. reply Gravityloss 13 hours agorootparentHmm the the first source I found said 60 kg but now found others saying a lot less like only 6 kg. https://electrek.co/2016/11/01/breakdown-raw-materials-tesla... https://elements.visualcapitalist.com/the-key-minerals-in-an... reply Aloisius 11 hours agorootparentThe 63 kg number is lithium carbonate equivalent, not elemental lithium. It originated from a Goldman report and they used it because lithium carbonate is what's traded. reply stetrain 13 hours agoparentprevAnd long term the supply a new lithium needed per year will be less than that needed to meet that year's global car production. Most of the metals used in EV batteries are recyclable, they aren't consumed permanently by putting them in a battery. reply tiffanyh 14 hours agoprevDumb question: how do they measure/know it's \"15M tonnes\". Meaning, it's not like they just found one big 15M tonne solid bar of lithium. reply rmm 10 hours agoparentnot a dumb question, as seen by the fact that the media/government minister etc. have blown this story out of proportion. In reality its most likely 15M tonnes inferrred resource of 0.4% lithium content So much smaller amount of actual lithium. They work this out by doing core drilling, and then inferring/extrapolating the size/shape of the orebody boundaries. (Im a mining engineer) reply great_psy 14 hours agoparentprevI think there’s different ways: - take random samples from the area and statistically come up with that value - put a radar/sonar/ xray etc in a hole and get an outline of how big the deposit is. I did not work in this field explicitly, but worked on Gaussian processes which were first used as a way to aggregate data like this from multiple sources to minimize the number of drillings required to find oil. reply saos 15 hours agoprevTheir govt should be all over that before they get leeched reply rkunde 15 hours agoprevWhat are the chances of battery tech advancing beyond lithium before extraction of these deposit can even begin at scale? reply mrinterweb 14 hours agoparentI've been wondering the same. Battery tech seems like there are new breakthroughs weekly. Investing billions in extraction/production seems like a pretty big gamble if by the time you're operational your tech is outdated. Still, even if there is a game changing battery tech breakthrough, it would take years before it could make it to mass production and adoption. reply genman 16 hours agoprevThere is important lesson to learn from here. Everybody who claims that there is not enough some mineral for something must consider the following. First in every moment in time there are certain number of mineral resources - these are known deposits that are not all necessarily accessible economically, but some of them are - these are reserves. If the demand for something increases then also the price will increase, making more of the resources available as usable reserves at the new price point. At the same time it increases the incentives to find even more new resources. More over, if there is certain amount of mineral already in circulation then it may suddenly become economically viable to recycle it, limiting the demand for new resources. What is important to observe instead is if the increase in production can follow the increase in demand and if the resources grow at such speed that the growth can continue. https://www.sustainabilitybynumbers.com/p/lithium-electric-v... reply gregwebs 15 hours agoparentThat's a good article. The issue is not finding another tonne of lithium, the issue is cranking up production. The article says 4-5 years minimum to build a mine, but sometimes it takes 10 years. So there is a supply issue- it is the supply produced by mines. We still could be in for more lithium prices shocks in the future as happened during the pandemic because the mining production can't elastically expand or contract (financing can make shutting down a non-option) as fast as demand. Building out a recycling program is something should be able to be done more quickly than building out a mine but there may still be issues if we don't design for recycling from the beginning. > The world doesn’t currently have the production capacity in mining operations to scale to this level. And, the problem is that the minimum time to build lithium mines is four to five years. They can be even longer – especially the lithium extracted from brine because it takes a long time to pump the saltwater out, before waiting for it to evaporate. > Countries have already invested in some increases in capacity, but we will need much more if we’re to keep up with demand. > This is a short-term challenge, and one that is typical of a fast-moving market. We’re playing catch-up. But, it’s a problem that we can’t afford: it could slow the decline in battery prices, and limit the number of EVs that companies can produce. > If we want to move the EV transition forward, we need to mine more lithium. And we need to do it quickly. reply api 16 hours agoprevLithium is not actually that rare. We are just now spending a lot of effort to find more of it. reply surfingdino 12 hours agoparentApparently the UK has some too and the economics of it make production viable https://www.wired.co.uk/article/cornwall-lithium reply mista2nith 16 hours agoparentprevYup - as always, \"price will save us\" You couldn't make money on lithium mining before, so no one bothered. Now, you can, so people are finding it everywhere. The main bottleneck in the USA (as always) is our insane permitting system, which punishes green projects and yet essentially doesn't exist for the fossil fuel industry. As a result, we're doing fun (bizzare) stuff like fracking for lithium in Arkansas, instead of just digging up Thacker Pass. reply andrewstuart 5 hours agoprevAny such discovery in Australia is assumed to be owned by our minerals billionaires. reply jongjong 5 hours agoprev15 million tonnes of Lithium... That reminds me. Isn't Thailand a monarchy? How long until US government decides to restore democracy there? reply specialist 14 hours agoprevAside: The global trade community should insist countries set up sovereign wealth funds wrt exports tied to resource extraction. Like Norway did (FTW) and Australia didn't (ruefully). reply buggythebug 16 hours agoprevhttps://www.youtube.com/watch?v=pkcJEvMcnEg reply wnevets 16 hours agoprevHow more stories do we need about finding lithium and \"rare\" earth metals being found before people realize they're not all that rare and we can stop reporting on it as if it's special? reply adtac 16 hours agoparentRare earth metals aren't actually rare. It's a misnomer. Some of them are pretty common. It's just that they're hard to extract and refine. reply whynotmaybe 16 hours agoparentprevLithium is so 'not' rare that you can find it in the geothermal water in... Belgium. https://www.thinkgeoenergy.com/geothermal-developer-hita-see... reply Accujack 12 hours agorootparentOr under the Salton Sea. reply EasyMark 15 hours agoparentprevRare is not what you think it is in that context. Wikipedia article would be instructive as to why reply oblio 15 hours agoprevOil is the standard example. I forgot what the exact peak oil production years were supposed to be, but they went something like this: In 1880 peak oil was expected to be 1910. In 1910 it was 1940. In 1940 it became 1970. Etc. Basically we kept finding more and more as technology and practical prospecting experience advanced. reply AdamH12113 15 hours agoparentUS oil production did, in fact, peak in 1970 and declined for decades afterward. Production only started to increase again about 15 years ago with the widespread use of hydraulic fracturing. https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=M... EDIT: To be clear, I am responding to a specific, narrow idea implied by the parent comment: that there was a prediction of peak oil in 1970, and that that prediction failed. I wanted to clarify the history. I know that global oil production continued to increase. reply rsanek 15 hours agorootparentcheck out worldwide production. except for the 80s, it's been consistently increasing for at least 120 years. https://ourworldindata.org/grapher/oil-production-by-country... reply moffkalast 14 hours agorootparentGreat news for climate change. reply aiauthoritydev 13 hours agorootparentnext [3 more] [flagged] tasty_freeze 13 hours agorootparentI'm sure you have read that from multiple sources. But I'd LOVE to know you in person and bet real dollars. Let's bet $10,000 on any of the IPCC estimates from the past 25 years and see if those old predictions overstated the problem. I'm sure you've been TOLD that, but it isn't true. The writers of the IPCC reports are aware of the political danger of overshooting, and they intentionally understate the severity of the problems. It chaps endlessly that thousands of climate researchers spend decades of their live researching the problem, often going to inhospitable places for months at a time to collect data. Papers are written, conferences are held, and conservative summaries produced. Yet some dingleberry paid for by the Koch brothers (having done no research and having written no papers) will say, \"Nuh uh, their predictions are wrong again, they are being paid by Soros\" or some other BS, and a large portion of the pubic believes them over the tens of thousands of man-years of research. EDIT: to make this more substantive, potholer54 is a youtuber who mostly debunks climate change denier claims. Why should you listen to him? In his own words, \"Don't, you can do it yourself by reading primary sources.\" Unlike people like Anthony Watt (popular and influential climate denier) who spout claims and provide no sources, potholer provides links to all of his sources. He is a sober person, not a bomb-thrower. Not that it matters, but he has a degree in geology and has spent his life as a science reporter. He makes no money off his channel and spends the time researching because climate change denial is a severe problem. Here is a good starter video: https://www.youtube.com/watch?v=ugwqXKHLrGk reply moffkalast 11 hours agorootparentWhoever can invest the most into constant blatant propaganda is the one whose message sticks. And the fossil fuel lobby's been doing it since the 60s while being funded by a large share of all of our paychecks. reply dwighttk 15 hours agorootparentprevProduction is not the same as existence reply stouset 15 hours agorootparentEvery year global we discover fewer additional oil reserves than what we are currently burning. Not that it matters. If we burn what we’ve already discovered, we’ll already be completely fucked from a greenhouse gas perspective. reply m00x 14 hours agorootparentWe were heading into an ice age, which would be just as bad for humans. The issue is that we built a bunch of things that depend on the current climate, but the climate has been changing for a long time and will keep changing. We need to adapt to it or find a way to adapt it. The holocene is an incredibly small period compared to the age of the Earth. Nature doesn't gaf, it'll cycle in and out and we'll have to adapt. reply flir 14 hours agorootparentIt's not the direction, it's the velocity. reply sheepdestroyer 14 hours agorootparentprevNot taking the extreme and unprecedented rate of temperature change into account is either ignorance or disingenuity. https://xkcd.com/1732/ It's probable that very few species will be able to adapt to such an abrupt change. reply SoftTalker 14 hours agorootparentAdaptation happens when it's forced to happen. reply hughesjj 12 hours agorootparentThey also happen when they're not forced to (competition), and sometimes they don't happen when they're forced to (extinction). reply 3000000001 13 hours agorootparentprevYes, but there is always the second half of “adapt or die” to consider reply SoftTalker 11 hours agorootparentYes, that's how evolution works. Those with a survival advantage succeed. Mother Nature doesn't hand out consolation prizes. reply ClumsyPilot 13 hours agorootparentprevThis literally doesn’t mean anything reply avar 13 hours agorootparentprevThe rate at which the temperature is changing is probably at historic highs, but both the current temperature and atmospheric CO2 concentrations are close to historic lows. See [1], that xkcd is picking a really biased starting point by using the last ice age as a baseline. Ice ages themselves being extreme abnormalities from the general historic trend. 1. https://www.researchgate.net/figure/Global-Temperature-and-C... reply hatthew 11 hours agorootparentThat xkcd is not demonstrating the amount of warming, it is demonstrating the velocity of warming. Historic temperatures on a time scale of millions of years are completely irrelevant to the current discussion of climate change, unless you think we have a chance to evolve into dinosaurs in the next few centuries (/s). reply avar 11 hours agorootparentThe temperature and CO2 concentrations are also unusually low for the Cenozoic Era. That's the post-Dinosaur era (if we're not including avians): https://www.researchgate.net/figure/Dynamics-of-global-surfa... The rise of mammals happened almost immediately after the extinction of dinosaurs, when the average surface temperature was around 10°C hotter than today. reply hatthew 10 hours agorootparentI had hoped that my point was clear without too much elaboration, and that you were joining this discussion in good faith. My understanding: At the moment, climate projections are that within the next few centuries we will reach temperatures not seen since the eocene. The mammals of the eocene were quite small, because larger mammals had trouble surviving the hot climate. While the broad categories of animals that still exist today also existed back then, in aggregate they looked very different from today. Given current trends, the majority of animals of today will be unable to adapt to the new climate, and will die off. Please correct me if I'm wrong, and then also follow that up with correcting the scientific consensus of experts who are forecasting drastic and damaging changes to the earth caused by humans. reply avar 10 hours agorootparentYou no longer believe that we're conversing in good faith? > At the moment, climate projections are that within the next few centuries we will reach temperatures not seen since the eocene. That seems about right, see e.g.: https://www.marum.de/en/Dr.-thomas-westerhold/CENOGRID.html > The mammals of the eocene were quite small, because larger mammals had trouble surviving the hot climate. What makes you think mammal size was limited by the temperature differences we're discussing? I think the predominant theory is that the asteroid impact killed off the larger ones, and it took a while for larger mammals to evolve. See e.g.: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7645244/ In any case, even if the Earth as a whole was much warmer on average that just means that you'd get the average temperatures that now occur closer to the equator (where some of the largest land mammals presently live) closer to the poles. So higher average surface temperatures shouldn't preclude the existence of larger mammals. > Given current trends, the majority of animals of today will be unable to adapt to the new climate, and will die off. I think this has less to do with climate change per-se, and more to do with the widespread ecological destruction that's followed industrialization, and the reduction in wild habitats. Although there's surely some species that'll go extinct mainly due to temperature changes, e.g. ones confined to a small atoll that'll get overrun by sea levels rising. reply hatthew 8 hours agorootparentBased on the context of your first comment I thought you were trying to argue that the environment isn't really in trouble. If you agree that humans are negatively impacting the environment, that's good enough for me :) reply aiauthoritydev 13 hours agorootparentprevThis is a very common misconception. Production is all that matters and existence is completely irrelevant independently. Production factors in existence and future expected existence. For example if any oil rich nation thinks oil going to run out they will hoard it for future so they can make money. But some get pedantic and ask \"But isnt number of Oil molecules in earth finite?\" Such pedantism can be easily blowm away by responding with pedantism. Oil molecules on \"earth\" might be finite but in universe they are infinite. Even if the molecules are finite atoms of Carbon and Hydrogen are vastly infinite in universe. We already know how to merge these atoms to form hydrocarbons. These arguments then get into the saner territory of \"but isnt it too expensive to bring water from Jupiter and turn it into Oil on moon and then ship it to earth?\", yes it is compared to fracking but fracking was considered too expensive compared to drilling which was considered too expensive compared to using mined coal etc. Ignore existence and focus on \"production\". As far as production is concerned we are not going to run out of oil ever. Unless we stop \"needing\" it. reply earthling8118 11 hours agorootparentWhile the resources are out there it's very feasible that we could become locked into a scenario where it is out of reach. I don't particularly care for letting the cost stop us from taking it from outside Earth, but the prerequisite for doing so is having enough energy available to accomplish the goal. Which is a path we could easily close off for ourselves. reply aiauthoritydev 1 hour agorootparentNothing you have said contradicts what I have said. I said the same thing. reply FrustratedMonky 15 hours agorootparentprevYes. Think people have impression we are energy independent and Scot-free because of fracking. Really, fracking was a second chance. A reprieve. We'll just be behind 8-ball again if we don't take this reprieve and grow some other energy source. reply cinntaile 15 hours agorootparentWind and solar are pretty nice and rapidly growing. reply whimsicalism 15 hours agorootparentprevI do not really understand why we are obsessed with energy independence. It only matters if we were to ban exports which is an absurd thing to do. reply markerz 15 hours agorootparentIsn’t energy independence more about other countries exports? From the perspective of Germany, their reliance on Russian oil caused a high spike in cost of energy during the current Ukraine invasion. For the US, we don’t really want to be at the whim of OPEC. The 1973 Oil Crisis is a historical example of OPEC taking a religious and political stance and using their oil exports to coerce the US against Israel. Another way of looking at it is that oil production has largely been an effective monopoly for a long time by authoritarian states (many OPEC, China, Russia), many that are politically unstable (Venezuela). There are only a few oil rich countries and many of them are allied with each other so there isn’t strong competition or incentive to keep prices competitive. Many of them view the US negatively. reply ethbr1 14 hours agorootparentExactly. Large parts of the economy require oil as feedstock or energy. Parts that cannot be down for more than a week, or bad things happen, and which by virtual of volume have limited storage capacity (at normal consumption rates). Consequently, US energy independence is about creating a credible detachment of the US from global market oil prices, such that countries thinking of using an oil embargo to pressure the US... don't. In reality, oil embargos obviously impose immediate and intermediate term costs on the exporters as well, so doing a painful thing that the US might be able to blunt anyway becomes less attractive. reply whimsicalism 13 hours agorootparentprevNo, it's about what the US exports - because the US produces more oil than it needs domestically. We will always be at the 'whim of OPEC' as long as we are in a market-based system because OPECs actions impact global oil supplies. reply FrustratedMonky 13 hours agorootparent'market-based' is the key here. Without competition there is no market. In the 70's when the US was NOT producing enough. Then OPEC had a 'monopoly' or at least an outsized influence. A large enough % of the market that they could dominate the price. Right now we are NOT at the 'whim' because we can produce more if we need it. IF we stopped, then we would return to being at their 'whim'. Solar, Wind, anything, is all very important for National Security. See Germany. reply ZoomerCretin 14 hours agorootparentprevGermany's plight is entirely owed to their own political malfeasance in shutting down their nuclear power plants. With them, they would have managed just fine without Russian oil and natural gas. reply edgyquant 13 hours agorootparentThere is still a bulk of our modern economy which relies on combustion engines and oil. You are out of touch with this reality if you think Nuclear is a quick replacement for anything but basic power generation. We are generations away from electrifying everything. reply megaman821 13 hours agorootparentprevCan you explain that thought more? The bulk of oil and natural gas don't go to electricity generation. How would more electricity generation help? reply FrustratedMonky 13 hours agorootparentprevBut that was kind of bad luck in timing. They started shutting down nuclear, to make switch to wind/solar, before Russia invaded. (or at least being very trusting of Russian supply, so that is error in hindsight). You could make argument that the switch to wind/solar should have been more gradual, or with more ability to roll back. But don't think it is a good argument to not switch to wind/solar. Just about how to do it. reply ClumsyPilot 13 hours agorootparentNah, it was actual stupidity. The same wind turbine in the scotland produces 3 to five times more power than in Germany The same solar panel produces 3 times more power in Spanish winter than in German winter. This is basic information available to anyone https://globalwindatlas.info/ https://globalsolaratlas.info/ But fine, you decided to do energy transition inefficiently. At least don’t switch of nuclear while you are still relying on fossil fuels! reply FrustratedMonky 12 hours agorootparentYes. I agree. That is better way to put it. Sure, switch to wind/solar. But at least mothball nuclear so they could be ramped back up (i'm not sure if that is possible with nuclear like with other power plants). But yes, have a better fall back position. reply spacebanana7 14 hours agorootparentprevExport bans of politically sensitive commodities are not that uncommon. For example, India banned onion exports this year [1] & the US has restricted oil exports before. [2] Moreover, without officially banning exports a similar result can be achieved by mixing exports taxes with consumption subsidies. If international oil prices got too high, like over $200, the political pressure for an oil export ban / restriction than made domestic prices $50-$100 would be hard for congress to tolerate. [1] https://www.reuters.com/world/asia-pacific/asia-feels-sting-... [2] https://ballotpedia.org/Crude_oil_export_ban#:~:text=The%20c.... reply rectang 15 hours agorootparentprevStrong US domestic energy production disempowers petro-state dictatorships such as Russia, Venezuela, Saudi Arabia etc. whose interests and values are not aligned with ours. reply Aerbil313 14 hours agorootparentBurning and bombing their countries down to the ground works pretty well too. reply rectang 14 hours agorootparentThe sharp ramp up of US oil production happened under the \"all of the above\" energy policy of Obama, who famously opposed that burning and bombing. Energy independence is vastly preferable to waging war, and may be worth making some environmental tradeoffs for — even if we would like to see cleaner alternatives to fracking in the long run. reply ClumsyPilot 12 hours agorootparent> Energy independence is vastly preferable to waging war, and may be worth making some environmental tradeoffs Environmental collapse will lead to wars, so this statement is self-contradicting. In fact the sooner we run out of oil, the better - high oil prices mean that any alternative will get huge investment. France built out nuclear due to an oil price shock. reply whimsicalism 13 hours agorootparentprevWe really are in a jingoistic moment right now. reply Aerbil313 6 hours agorootparentIt is satire. reply jon_richards 14 hours agorootparentprevSoft power. “European countries are estimated to have spent additional 792 billion euros in the last year just on the status quo system to protect consumers from the effects of the energy crisis introduced by the Russian invasion into Ukraine” Honestly I think building solar and wind farms in Europe would do more for America’s military power than more tanks. reply pi-e-sigma 13 hours agorootparentYou have a flaw in your reasoning. More solar and wind farms in Europe make it more independent from both Russia and the US. reply politician 12 hours agorootparentThe EU is dependent on the US for nuclear deterrence, so the dependency relationship will continue even after they choose to use less imported US LNG. That’s probably a long time from now though, as they are expanding LNG regasification terminals (6 projects that I’m aware of) since the pipelines from Russia became unavailable. reply edgyquant 13 hours agorootparentprevThis is because you’ve been living a very comfortable life with no real foreign threats thanks to US hegemony and the globalization it allowed. Due to other countries growing and wanting to have a say, this can’t be expected to continue going forward and so we have to think about things from a strategic perspective and not from a purely economic one. reply whimsicalism 13 hours agorootparentWe have more than enough significant allied countries in the Americas that we never have to worry about energy security ever again - in the sense of literally getting enough electricity to meet domestic demand. If it is about getting low price energy, then integration with the global system is unavoidable, no matter how many domestic export bans you enact, etc. - you will be impacted by global energy prices. reply rayiner 14 hours agorootparentprevWhy would you want to be dependent on other countries if you didn’t have to be? reply whimsicalism 13 hours agorootparentBecause comparative advantage means that we all get richer collectively? Like - the basic principle driving better living standards over the last 80 years? reply rayiner 12 hours agorootparentDefine “better living standards.” Obviously has been great for third world countries. But folks in the west don’t seem to happy about the situation. I don’t think the widespread availability of cheap Chinese crap offsets the downside of hollowing out the industrial base and non-college jobs. reply astrange 10 hours agorootparentThat was caused by bad US monetary policy. You've confused cause and effect. (Americans hate inflation so much they preferred the Volcker recession in the 70s, which is what caused the deindustrialization, which is what caused things to move to Asia.) reply FrustratedMonky 12 hours agorootparentprevAh. I see. You are going back to old Adam Smith. Let places/people that can make things more efficiently, do them. Example: Don't give subsidies to car companies in countries that aren't good at making cars, it is inefficient. Better to focus on what you are good at. There are exceptions: National Security. See Energy, Semi-conductors. or To protect an industry while it grows, gets up to speed. Japan didn't become industrial power house out of nothing, they were very protectionist. Now they are dominant, but they aren't dominant because they let anybody at all come in and compete. They subsidized and protected their industry until they could stand on their own. reply FrustratedMonky 12 hours agorootparentprev\"independence\" means we don't have to buy energy from the outside. Send money to someone, so they give us Energy. It is super important. Think of it like this. How many oil producers do we have a problem with? That are dictators, at war, or generally bad. Every time we buy gas, we give them money. We send trillions of dollars to our enemies. It is such an overwhelming National Security issue, that I'm frankly surprised Republicans fought renewable energy for so long. Oil isn't going to last forever. We should have been throwing resources at our own internal energy R&D. . reply kfrzcode 15 hours agorootparentprevProductions; what about reserves? reply hinkley 14 hours agoparentprevWorld peak oil production was expected to happen in the late 1980's, but what happened then was new subterranean imaging techniques to find oil, horizontal drilling to get at tricky oil, and new electrolytes (zeolytes) to refine crude, basically doubled the amount of petroleum we could possibly produce, and increasing the amount of crude we could get to if we wanted. That said, even with process efficiency improvements like electrolytic cracking, the number of useful Calories we extract per Calorie of input has declined over time. More and more of the fossil fuels we produce are going into producing the next unit of fuel, which is a little harder to retrieve than the ones from last month. reply yieldcrv 14 hours agorootparentyes but this happens in every commodity and serves to the earlier point what happens is that because the price goes up and the margins potentially increase, more investment is tolerable for more expensive extraction methods reply dang 11 hours agoparentprev(We detached this subthread from https://news.ycombinator.com/item?id=39058847. Nothing wrong with it but it's a bit of a tangent.) reply outlore 11 hours agoprevThe cultural significance of the resource wars in the middle east has been immense. I wonder if the modern imperial powers will wage new wars for resources in east Asia in the future. reply riffic 16 hours agoprevnext [12 more] [flagged] greggsy 16 hours agoparentLese Majeste has nothing to do with this news. Every country has problems. reply genman 16 hours agorootparentnext [10 more] [flagged] bobthepanda 16 hours agorootparentat the same time Thailand is no Congo. the reason stuff like this gets downvoted is that it's pretty counterproductive to list a country's sins every single time an article remotely relevant is posted, to have it devolve in to a flame war reply linhns 15 hours agorootparentAnd make everyone take extra scrolls. reply genman 12 hours agorootparentprevYes, indeed, it is not, but coincidentally today a person was imprisoned for 50 years for being a little critical about the king of Thailand. 50 years! A young man! It clearly foreshadows this otherwise very good news. Many people I know live considerable time of the year in Thailand and they are very supportive of the country but in my opinion this particular legislation clearly reminds that not everything is good there and there exists a considerable risk to personal freedom. I think that we should be vocal about this and not accept it as a \"local peculiarity\" - voicing disagreement actually can change the world to a better place as silently accepting a wrongdoing clearly does not. Similarly we should not close our eyes in case of US when it is gravitation toward less freedom. But this news is not about US. reply avgcorrection 11 hours agorootparent> Similarly we should not close our eyes in case of US when it is gravitation toward less freedom. But this news is not about US. - New rare earth metal reserves found in Utah - How will this affect the notorious police-on-black brutality issue? reply d7udsf 16 hours agorootparentprevImagine that this article was about a lithium deposit found in the USA. Would you find it productive / relevant for me to say - Ah! That same country that is going back to the 50s in women's rights? - Ah! That some country that had the most gold medals in the last olympic? I'm guessing not. Why should it be acceptable to say something completely unrelated about Thailand? It's even worse if it's something negative. It would be fine if it were something relevant about Thailand (their mining legislation, for example) reply genman 14 hours agorootparentFirst, it has been not found in US and even if it had, it would have been not a sizable share of US economy, but for Thailand it would be. Second it was told most likely because it is the newest news about Thailand https://www.nytimes.com/2024/01/19/world/asia/thailand-sente... Perhaps it has even become a defining feature of Thailand. reply avgcorrection 11 hours agorootparentprevThe whataboutism would be to bring up the Thai Royal Family apropos of nothing on the topic of lithium, no? (I honestly can’t tell who are you are agreeing with.) reply orthecreedence 15 hours agorootparentprevnext [3 more] [flagged] greggsy 15 hours agorootparentWe know. Please don’t put more fuel on a flame war. reply astrange 10 hours agorootparentThe Iraq War was not for oil, so I hope you don't know that part. (That gives it too much credit. It wasn't for /anything/. We didn't get any oil out of it though.) reply mannyv 15 hours agoparentprevnext [2 more] [flagged] EasyMark 15 hours agorootparentCCP? Sure they were violent when you tried to do something out of the norm, but there weren't even in the same order of magnitude compared to taliban or isis. I think you can't really lump them together. You would get banished from the community for the most part back in the day, taliban will just shoot you and your family in the face. reply More GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Thailand has discovered approximately 15 million tonnes of lithium deposits, positioning itself as the third largest lithium resource globally after Bolivia and Argentina.",
      "This discovery is a significant development for Thailand's goal of becoming a regional hub for electric vehicle manufacturing.",
      "However, the commercial utilization of these lithium deposits remains uncertain, and the government is currently assessing their viability. Thailand sees this as an opportunity to achieve self-sufficiency in electric vehicle battery production."
    ],
    "commentSummary": [
      "The discovery of lithium deposits in Thailand has sparked a discussion about global supply and its potential implications.",
      "There is skepticism about the reported quantity of lithium and its economic viability, raising doubts about its significance in meeting the demand.",
      "The conversation also delves into related topics such as the environmental impact of lithium extraction, the recycling of lithium batteries, and the importance of energy independence. Geopolitical considerations and resource conflicts are also mentioned."
    ],
    "points": 429,
    "commentCount": 252,
    "retryCount": 0,
    "time": 1705682660
  },
  {
    "id": 39057862,
    "title": "Step back in time: Experience web nostalgia with a 1999-inspired website",
    "originLink": "https://billsworld.neocities.org/",
    "originBody": "SURF THE WEB LIKE IT'S 1999! I'm trapped in 1999 on GeoCities! I've made this time portal so you future people can visit my site. Bill's WorldContact to join!HOTLINE WEBRINGGet an official Bill's World web button for your site and show me some link love on your site.",
    "commentLink": "https://news.ycombinator.com/item?id=39057862",
    "commentBody": "Surf the web like it's 1999 (billsworld.neocities.org)389 points by throwup238 16 hours agohidepastfavorite152 comments LeoPanthera 15 hours agoIf you set your HTTP proxy to \"theoldnet.com\" with port 1999, and add an exclusion for \"web.archive.org\", then all your web pages will come from 1999, via the Wayback Machine. You can pick a different year by changing the port. Edit: It may have been hugged to death... reply brassattax 15 hours agoparentI like https://oldweb.today ... actually emulates old OS/browser combinations and proxies stuff from archive.org reply epcoa 11 hours agorootparentI never get over the weird feeling seeing something like Windows 95 which was released with such spectacle, Jay Leno and millions of dollars in launch events, requiring the latest available PC equipment to boot the same day, and of course the looming threat of the SPA sending you to PMITA prison if you didn’t pay your $209.95 being reduced to a small square on my mobile phone still running faster through a million layers of framework. Seemed like serious shit at the time. reply SllX 6 hours agorootparentUnfortunately it’s still Windows 95. Not trying to be a hater, but I did recently install a Windows 95 VM on my Mac to relive that old experience… and then the very first error alert sound, that incredibly tinny really loud annoying sound that would always make me jump out of my chair with crappy PC speakers came blasting out of my much much better speakers backed by a subwoofer and I realized there is no nostalgia value to be had here. I liked what I had at the time when it was all that I had but I would never want to completely relive that experience. If I got sent back in time to the day Windows 95 launched and had to live the rest of my life from that point on, I honestly don’t know if I would want to touch another computer until like early 1999, maybe late 1998 at the earliest, and only for work. reply PaulRobinson 1 hour agorootparentSame. It was around that time I discovered Linux, and then the *BSDs. Before that, getting online required Trumpet Winsock. I did some tech support for an ISP up until 1998, so I had to know the stack, but rarely touched it myself. From the mid-2000s I moved to Apple, but only because I wanted a laptop with a unix command line and working bluetooth and that was _hard_ back then. Just realised that means I've not owned a Windows machine - and barely touched one professionally or even much in my personal life - in almost 25 years now. reply 83457 6 hours agorootparentprevhttps://youtu.be/13bs7oz4wp8?si=lx58N7UsdTXOD8D1 reply dirtyhippiefree 10 hours agorootparentprevSPA (Software Publishers Association…and RIAA lawsuits… reply xerox13ster 1 hour agorootparentIt's so funny to see the SPA and RIAA being mentioned in the same context as PMITA prison because I just told my friend yesterday that if I ever released the software I actually want to build, that the RIAA and WMG would PMITA in court without so much as spitting on me in disgust before starting. reply al_borland 13 hours agorootparentprevThis really captures how slow the web, and everything else, was back then. reply Gud 11 hours agorootparentNot necessarily. I was living in Stockholm and had a 10/10Mbit connection. Not too bad for a 15 year old kid. reply AlienRobot 8 hours agorootparentprevNothing quite says Moore's law like putting the web in a website. reply jart 11 hours agoparentprevSee also https://olduse.net/ for a 42 year delay on USENET. All I had to do was put this in my ~/.emacs file: (setq gnus-select-method '(nntp \"olduse.net\" (nntp-port-number 11942))) Then I typed `M-x gnus` and used the `^` key to see a listing of newsgroups. reply dylan604 15 hours agoparentprevi love the creativity people come up with for such novel things reply quaffapint 15 hours agorootparentSimilarly check out https://protoweb.org/about/. They dont have every site, but they also include a fun 'antique' youtube where you get to stream with Real player or windows media player to bring back the 'greatness' of those products. reply dylan604 13 hours agorootparenti'm excited to see if they properly recreated the \"Buffering...\" reply kwelstr 9 hours agoparentprevYay! My old web page is there :O https://theoldnet.com/get?url=www.shadow.net%2F%7Egiorgio%2F... reply Brajeshwar 6 hours agorootparentAwesome. Mine too. I was starting out https://theoldnet.com/get?url=brajeshwar.com reply dehrmann 5 hours agoparentprevhttps://web.archive.org/web/20000407061146/http://www.x.com/ reply willcipriano 14 hours agoparentprevIn a few decades or so I could see setting that up for a nursing home so the residents could relive their youth. Might also be good for a young kids pc. reply drewcoo 11 hours agorootparentUseful for dementia patients. reply 1vuio0pswjnm7 12 hours agoparentprevDoes his proxy send x-forwarded-for header reply happytiger 10 hours agoprevYou know these kinds of nostalgia capture an aesthetic, but what made the web special in 1999 was the voices of individuals publishing websites of their own… their movable type sites were usually high brow affairs, but ‘99 added LiveJournal and Blogger to the mix. I really miss independent voices. I feel like social media is a hollow version of what was, kind of like a bowling alley with bumpers on the lane. The web felt vital to expression in 1999, and today it usually doesn’t. It feels corporate. Wish we could find a way to recapture that feeling of connection with one another. reply dehrmann 5 hours agoparentI have a different take. The opportunities were so wide-open that no one really knew what to do. There's a thing where if you restrict an artist, they're actually more creative. Where was Wordle in 1999? reply xerox13ster 1 hour agorootparentWell for one, we were still using CGI scripts and for two, we didn't have local storage in the browser.... reply happytiger 3 hours agorootparentprevIt was called Acrophobia and it was awesome. reply dirtyhippiefree 10 hours agoparentprevAgree entirely. Let me share what revolutionized my tech experience. #getoutside Edit: Not being snarky, I’m totally serious. Online only goes so deep…then…nothing… reply donatj 23 minutes agoprevOh man, posting screenshots of your desktop brings me back. It was waasy more interesting back when actually methods for OS customization existed beyond “favorite color” we’ve really lost so much. I never had that complicated of a setup but still found it fun https://www.deviantart.com/donatj/art/Screenshot-9-of-Mine-i... reply AdamH12113 16 hours agoprevFor you younger members of the audience, this page is a great demonstration of how animated GIFs were originally used on the web and why a lot of us were so surprised when they made a big comeback in a totally different style in the 21st century. reply egeozcan 14 hours agoparentI'm also amused by the fact that the file format GIF became a name for a snippet of animation, and you usually get a webp when you search for a GIF (for good reasons too, but funny nevertheless). reply fritzo 13 hours agorootparentI've heard the specific old format pronounced 'GIF', whereas the newer general use case for any image format is pronounced 'GIF' reply rchaud 13 hours agoparentprevthis is exactly how GIFs should have remained. The new generation calls these \"stickers\" which are all over Tiktok and Snapchat, and they're all Canva-made identikit garbage. It's sad to think that GIFs that still remain are movie/TV scenes that are clipped to use as reactions to online comments. reply rkagerer 12 hours agorootparentThanks for finally explaining stickers to me. reply dirtyhippiefree 10 hours agorootparentprev> It's sad to think that GIFs that still remain Those under thirty should be aware that this occurred because the owner of the GIF spec (H&R Block) began a legal strategy that caused most of us to move to JPEG. reply Brajeshwar 6 hours agoprevHaving read about the Internet in magazines since its launch in India (Aug 15, 1999), the first thing I did on the first day I landed in a city with the Internet was going to a cybercafé[1] to create my Yahoo! and Hotmail ID in 1999. I still own the Hotmail ID but lost the Yahoo! Re-taking back the Hotmail ID was also a nice story from the past. ;-) My recollections of the actual events could be clearer, but here it goes. I started with Blogspot[2] before Google bought it. It had no commenting options. A Russian developer contacted me to try his commenting script, which works with Blogspot. I'm either the only person or part of a few people using it. He helped me set up, and we emailed regularly, and that's how comments started on my website. I let go of my comments recently (they are in the 5-figures after removing spam.) I searched my blog but I either deleted it or have forgotten the name of the program that powered it but it was a good thing. Thanks to another nice person on the Internet. Then, Blogger to Movable Type to WordPress (before it even had options to create pages). Now, I'm in \"plain-text\". 1. https://en.wikipedia.org/wiki/Internet_café 2. https://en.wikipedia.org/wiki/Blogger_(service) reply ilrwbwrkhv 12 hours agoprevWebsites were so easy to read and navigate back then. It just worked. Some of the websites might be a bit rock and roll but there is a strange clarity to the whole thing. I actually found https://www.seat61.com/ recently and it is this one dude who runs the greatest train website on the planet and he has been doing it since 2001. Site looks ancient but it is so useful. reply Levitz 11 hours agoparentNothing but desktop computers were intended to display these, and so they could take advantage of the screen width. No desire to have them be an app either. reply kaycebasques 15 hours agoprevI love the idea and look forward to diving in. There's an anachronism in the first paragraph though... \"check out my MySpace page\"? MySpace didn't launch until 2003... Honest question, was this created by someone who was not actually on the web in 1999? Or maybe they're just taking artistic license with the \"1999\" idea? reply LinuxBender 15 hours agoparentFor what it's worth, MySpace prior to officially being a social media site was created in '96 and officially launched as a internet network drive around 1999 cant remember the exact date, then was later sold to Murdoch and evolved more into a social media site later on but was already unofficially used as one. People shared music, short movies, porn. It didn't scale well as there was no de-duplication, files were stored in an EBCDIC database on a couple HP Surestore's which I and others upgraded a few times from 9TB to 18TB comprised of 4 and 9 GB drives, then eventually 18 GB drives. reply broast 13 hours agorootparentThat was XDrive. I don't think the name MySpace came around till the social network in 2003. The sale to Murdoch was 2005. reply LinuxBender 12 hours agorootparentIt was definitely Myspace in 1996+. Perhaps they didn't start marketing the brand until 1999? I had to register about 50 variants of that domain name in 99' for them using the all so much fun email template with Internic. As to what relationships they had with other companies I have no clue. The HP SureStore's left the dataceter in 2002 or 2003. I met their CEO in 1999 when they were going to launch the drive space feature. As a fun side note they were the only customer I was ever allowed to let into the datacenter. Some of the domain variants were MyLinuxSpace, MyBSDSpace, MyWindowsSpace and so on... reply broast 10 hours agorootparentThe founder of MySpace came from XDrive so I assumed XDrive is what is being referred to here. Wikipedia suggests this too, with MySpace starting later as a new company, but it states that the early team were inspired by social features in some other existing software. Maybe that was called MySpace and is what you are talking about. Would love to read more about it reply LinuxBender 9 hours agorootparentStartups were a little odd back then. Some would be in the process of changes but the employees wouldn't know until they pulled the trigger. I am just guessing but maybe you saw the exit stage of XDrive and I saw the entry of Myspace but there was some hush-hush secret overlap. It certainly wouldn't be the strangest thing I saw back then. reply swozey 15 hours agorootparentprevWas this just like s/ftp accounts? Or something more complex like a 1996 dropbox? It was a mounted filesystem in your machine? reply LinuxBender 15 hours agorootparentIt was a drive letter mounted on your Windows machine or a mount point on Linux. I forgot what protocol was used and I never personally used it as I had my own SFTP servers. On Windows people would run an app but I think it was just mounting a SMB drive. I only handled the backend storage, HP-UX servers and DNS for them. Other people managed the Windows servers and their company managed the applications. reply swozey 14 hours agorootparentNeat. I was 10 back then but I remember having to deal with IPX networking to play Warcraft 1-2 with my dad, and over Mplayer, or some sort of online game service IIRC. Never really thought about how you'd do a mounted network share back then. IPX was a pain but we had no idea what we were doing back then. edit: Oh duh, battlenet.. sigh, my how blizzard has changed. reply devin 14 hours agorootparentprevI'm going to take a guess this was FUSE. reply NikkiA 13 hours agorootparentMore likely to be WebDAV, which was the 'great hope' for cloud storage before it was called cloud. reply fragmede 14 hours agorootparentprevFUSE was 2004, so it's anyone's guess. reply JKCalhoun 15 hours agoparentprevYeah, also everything loads too fast. And maybe too many colors (too high a bit-depth). reply Clamchop 14 hours agorootparentBy 1999, most would have been on 24-bit color, or \"millions of colors\" as Apple called it. Most images are still 24-bit today. reply extr0pian 15 hours agoparentprevLooking at his neocities (self made) profile, he's 45-50. https://billsworld.neocities.org/profile/ reply dexwiz 15 hours agoparentprevThe favorites also has a Dr Who page that features David Tennent and Freema Agyeman, who didn't appear on the show until 2006. reply cableshaft 15 hours agorootparentYeah except it's known that they can travel through time and space, so that one makes sense. reply frognumber 15 hours agoparentprev99% odds artistic license. 1% odds anything else. It's better that way. The feel of 1999 was there in 1998 and yes, the distant future, the year 2000. reply Apocryphon 15 hours agoparentprevWas going to say that Friendster is not as cool, but only just realized it came out the same year as MySpace did... whoa reply xxr 15 hours agoparentprevAnd Tomoyasu Hotei didn't release \"Battle Without Honor or Humanity\" (the autoplaying MIDI) until 2000 ;) reply ksec 15 hours agoprevFor probably nostalgic reason, this put a big smile on my face. But for those who are under 30s, or may be under 25s. What do you think of it? Ugly? Interesting? Boring? or what? Interested to know. reply culopatin 3 hours agoparentYou mean under 25. Otherwise the would probably remember win 95 onwards. I somehow like it more, but could be nostalgia of a time when anything a display showed was magical. I wanted more but didn’t know what. I think these UIs leave some work for the imagination, cartoonish in a way. Now they are too business reply ThinkingGuy 14 hours agoprevPretty accurate, except for one major thing: all the pages load instantly. In 1999 you pretty much expected each web page to take at least 10 seconds to load, mostly for the images to gradually...fade...into.....view. reply xxr 14 hours agoparentI remember a very specific rastering effect with loading images, probably around 1994-1996? The image would load every nth line and then iteratively nth line + i until i==n. Compared to what I would see later (just loading in every line from top to bottom), you could get a sense of the whole image sooner, just in an increasing fraction of the vertical resolution. I can't recall which image type this was or whether it was Mosaic or Navigator, but the effect was very distinct; at the time I assumed it was the way the image data was streamed in, but now I'm wondering whether it was just the way the image codec built the viewable bitmap. reply fiddlerwoaroof 14 hours agorootparentI think this was progressive JPEGs https://www.hostinger.com/tutorials/website/improving-websit... reply raphman 14 hours agorootparentNice demo: https://pooyak.com/p/progjpeg/ reply neckro23 3 hours agorootparentprevInterlaced GIFs. Early browsers only rendered the single lines as they came in (leaving the unloaded parts blank), but eventually browsers started doubling the lines so the image seemed to increase in resolution as it loaded. I think MSIE started the latter behavior, and that's what modern browsers do. Progressive JPEGs are somewhat similar, but IIRC didn't gain traction until 2000 or so. reply zczc 13 hours agorootparentprevThat was interlaced GIF, see https://en.wikipedia.org/wiki/GIF#Interlacing (the demo image in the article is from Chrome which tries to approximate the image with rectangular regions, the 1990s browsers showed not yet received lines as blank which made interlacing effect) reply shiomiru 13 hours agorootparentprevGIF supports this too: https://en.m.wikipedia.org/wiki/GIF#Interlacing reply hinkley 13 hours agorootparentprevProgressive PNGs added a 2d variant of this, but almost nobody ever used it, because it made the image take longer to load. reply samch 14 hours agoparentprevFor me, the “https” in the Netscape URL is sort of an anachronism. I mean, yes, technically it was available in Netscape in 1999, but very few sites used it (even among e-commerce sites). I remember the first ProLiant server we flipped to support SSL had to have an add-in card to accelerate the encryption based on the traffic we handled. It was something like this: https://www.hpe.com/psnow/doc/c04283920.PDF?jumpid=in_pb-psn... reply wolpoli 14 hours agoparentprevIn terms of load speed, the period between introduction of broadband and the rise of SPA was heaven. reply xxr 14 hours agorootparentAbsolutely--I'd click a link, and it would feel like the page had already been in memory. reply wscott 14 hours agorootparentprevSPA? reply kristopolous 13 hours agorootparentIt's what people who didn't understand the separation of concerns with HTTP, HTML, CSS, JavaScript and server side were did by deciding to jam it all into JavaScript and entangle it in code complete and gang of four constructs and then call it superior, easy, efficient, well designed, robust ... It's ... It's simply wild. HTML content? In the javascript. Style information? In the javascript. A way to negotiate network loading and resources, document structure? You guessed it. Want the back button to work again? More JavaScript. URLs to be universal? Even more! Eventually you'll get the page to be almost as functional as it would have been by default had you not used any of it. Read the mdn and w3c documentation guys, I promise you 99.9% of what you want is in there without reinventing it from base principles. It's not 2010 anymore It's like a bad cook who is trying to fix a poorly made meal by making more mistakes, covering it in salt and oil, smearing honey over it, and calling it delicious. reply highwaylights 13 hours agorootparentprevSingle Page Applications. The spaghetti mess of JavaScript-heavy monstrosities that replaced the web. reply hathawsh 13 hours agorootparentprevSingle-page application. SPAs became popular once JS had matured enough to generate all the HTML for the page. reply dkga 13 hours agorootparentprevHear hear reply atomicfiredoll 14 hours agoparentprevI'm thought the Netscape logo only animated when the page was loading? I found myself instinctively hitting the stop button to try and make the logo stop looping. Overall, it's really great though. I love the stuff popping up on Neocities. reply bityard 14 hours agoparentprevQuite a while ago, someone (jwz?) brought back the original Netscape home page circa 1994, complete with dialup-level speed throttling. It \"feels\" like 56K to me, but I believe 9600-14.4K would have been more common at the time. http://home.mcom.com/home/welcome.html reply mixmastamyk 14 hours agoparentprevI first used the net at work in the mid 90s, where we had a T1 and pages were light by modern standards. It was peppy with a Mac IIci. reply optimalsolver 14 hours agoprevRelated: https://www.my90stv.com/ Watch TV from the 90s. reply rchaud 13 hours agoparentI love this site. It is using YouTube embeds, but it doesn't show any ads, which would ruin the retro experience. I wonder if that's just my adblocker though. reply dkga 13 hours agoprevVeteran of the browser wars here. So many (good) feelings checking this website… I loved that era’s internet. Incidentally my spotify started playing songs I used to download via Napster so I’m now 100% nostalgic. reply dexwiz 15 hours agoprevMight as well listen to music like its 1999 likes you are at it. https://webamp.org/ It really whips the llama's @$$! reply i8comments 15 hours agoprevThe website is wellmade and cool and stuff, but I am a bit tired of these all-quirky-in-the-same-way retro 1990s geocities homages... reply hinkley 13 hours agoparentNostalgia comes from forgetting that we got tired of these all-quirky-in-the-same-way retro 1990s geocities homages in the 1990's. reply drewcoo 11 hours agorootparent> Nostalgia comes from . . . Or from remembering the Angelfire/MySpace DIY aesthetic from before the world became consumption-only and flatly Material. reply ape4 14 hours agoprevSadly nobody says \"surf the web\" any more reply al_borland 13 hours agoparentIt's also been quite some time since I've heard anyone talking about the \"information superhighway\". reply rchaud 13 hours agorootparentThat was a Microsoft term, Bill Gates wrote a book about it in 1994, and then wrote a second edition a year later replacing the phrase with \"internet\". reply doublerabbit 13 hours agoparentprevNor the \"world wide web\", ask the younger ones what www stands for and they get really confused. If you notice nowadays all websites use just https:// rather than https://www. reply dakna 14 hours agoprevFriends don't let friends use anything but web safe colors. Everyone else can enjoy dithering on their 8-bit CRT reply mostlysimilar 16 hours agoprevSo realistic. BSOD when I try to open the start menu. reply cheschire 16 hours agoparentI appreciate the effort to make images load at what feels like 56k speeds. reply dylan604 15 hours agoparentprevi wonder how many people will actually try to use ctrl-alt-delete to recover. i did just to see if it would do anything, but i don't use windows so I wasn't going be rick rolled by it. like it would be funny if it launched a full screen window of the start up screen for win98 or something. reply nickthegreek 16 hours agoparentprevI wish there was a bit more latency. Everything is way to smooth! reply exitb 15 hours agoprevUsing the correct, non-antialiased fonts would go a long way. reply marginalia_nu 15 hours agoparentCRTs did a lot of heavy lifting in anti-aliasing those fonts. reply PaulDavisThe1st 15 hours agoprev1999? I was ready to get off the web in 1999. How about surfing the web like it's 1994! reply kloch 14 hours agoparentI agree, Mosaic was groundbreaking but when Netscape 0.9 launched in the fall of 1994 was like waking up in another century. Or we could go back to 1991 with IRC, Archie+FTP, and Telnet BBS's on Wyse terminals or SparcStations. I'm very nostalgic for that era. IMO Netscape 3.04g was the peak browser experience - and by far peak performance. I remember when a friend who ran a business out of his basement got a T1 installed in 1997. Myself and several other friends were there the day Verizon hooked up the local loop. I did the first test on a desktop windows95 machine with Netscape 3. I typed \"cnn.com\", hit enter and BAM! the entire page loaded and rendered instantly before you could blink an eye. I fell out of my chair. On dialup it would take about almost a minute to download all the images. Once Netscape 4 hit it was a slow downhill path of bloat. I have not been able to replicate that instant rendering experience since then. reply Al-Khwarizmi 12 hours agorootparentWyse terminals! I had my first programming courses at university in those. I remember dumping core and somehow sending the core file to a classmate's screen, and they had to stare at the screen beeping for a while. Now I teach those courses at the same university. Those terminals are long gone. This week we had a coding exam and students were coding with their laptops. They are forbidden from checking the Internet, sharing folders, and using AI assistance, but I'm sure some of them did because it's impossible to watch their every move. The exam would be fairer if we still had the Wyse terminals! reply PaulDavisThe1st 14 hours agorootparentprevMy nostalgia is mostly for the Bitnet chatrooms from the mid-80s. Especially the \"hot tub channel\". I didn't know it was possible to be that lascivious in plain text! reply imiric 11 hours agoparentprevMust've been fun browsing all 2,278 web sites[1] on Mosaic 2.x. [1]: https://en.wikipedia.org/wiki/List_of_websites_founded_befor... reply mysterydip 16 hours agoprevI miss those \"under construction\" gifs. reply TheCondor 16 hours agoparentEnjoy: http://textfiles.com/underconstruction/ reply throwup238 16 hours agorootparentSadly it's missing the Dunder Mifflin animation: http://ohiogunlawyer.com/ reply dataangel 14 hours agoprevThe word \"blog\" seems like a giveaway this isn't from a real archive. I don't remembering hearing it until years later. reply busfahrer 10 hours agoparentThe first thing I remember reading that could be described as a blog would be John Carmack's .plan file that he frequently updated with his progress on Quake development. This could be retrieved using a dedicated \"finger\" program, but I seem to remember that mIRC also had the ability. https://en.wikipedia.org/wiki/Finger_(protocol) Excerpt: \"The program would supply information such as whether a user is currently logged-on, e-mail address, full name etc. As well as standard user information, finger displays the contents of the .project and .plan files in the user's home directory. Often this file (maintained by the user) contains either useful information about the user's current activities, similar to micro-blogging, or alternatively all manner of humor.\" reply al_borland 13 hours agoparentprevApparently the term 'blog' was coined in 1999, and Blogger was launched later that same year, so it actually is possible. https://en.wikipedia.org/wiki/Blog#History reply pattle 15 hours agoprevSee also https://simulator.money/play for a Windows XP nostalgia trip reply vdaea 15 hours agoparentThat game seems cool, but it's a bit buggy and unfinished. Are there any similar games (as in personal finances simulation) that are more complete and stable? Obviously the game does not need to simulate a Windows XP computer ;) reply zX41ZdbW 15 hours agoprevThe power off button on the monitor does not work. If I type \"http://yahoo.com/\" in the address bar, it does not work as expected. Clicking on the Netscape Navigator logo works, but if I type the same address, \"www3.netscape.com\" manually into the address bar, it does not work. The URL in the address bar isn't updated. reply nonameiguess 16 hours agoprevLaughing hard at the Olean ad. As many won't get that, it's the brand name for Olestra, a fat substitute with similar nutritional qualities but zero calories because humans can't digest it, that was briefly popular in low-calorie foods in the late 90s. But since you can't digest it, it leads to horrible shits and was mostly taken off the market. reply bregma 15 hours agoparentThe official phrase was \"causes anal leakage\". reply Lammy 10 hours agorootparent¡Olé Olestra! https://web.archive.org/web/19981201183830/http://www.zug.co... reply dylan604 15 hours agorootparentprevthat phrase is much much much worse than the black box labeling the FDA can require you to use. once that phrase hit the late night stand up bits, it was pretty much over. it's just sad it had to make to that far. reply itronitron 12 hours agoprevI haven't been able to find the \" π \" symbol. Has anyone else spotted it? reply lcof 13 hours agoprevThis feels like a madeleine de Proust: simpler times, so much left to discover. We ruined it reply pimlottc 16 hours agoprevThis is pretty fun but it doesn't seem like the URL bar ever updates? Even though this are all real pages. reply jesterswilde 15 hours agoprevOh snap, I forgot about Tom. Good to see he's still 30 and hanging out in Santa Monica. reply swozey 15 hours agoprevI've never been able to find my old geocities account. I'm pretty sure I remember the neighborhood/number correctly. It was an ultima online and final fantasy 7 cheats webpage haha reply miohtama 12 hours agoprevMy mobile screen has way higher resolution than 15\" monitor from 1999. I can fit multiple Netscape's on my screen. reply wiremine 16 hours agoprevIt's funny because it's true. Instantly took me back to the late 90s. I remember trying to optimize images for 16k colors, and dealing with all the weird, disparate javascript versions. reply Cockbrand 15 hours agoparent16k colors, man! You must have been rich to be able to afford a machine being able to display all of these ;) I optimized for the official 216 color Web Safe Palette (“How many shades of neon green do we really need?”) well into the early 2000s. reply wiremine 13 hours agorootparent216! Yes! I has totally blocked memories about that. I think I built my first website in 1997, and it was wild what we had to do back then. reply pepelotas 9 hours agoparentprevOr, god forbid, the intrusions that VBScript made on the web. reply d1m 14 hours agoprevFirst of all, A BIG THANKS TO YOU MAN! this thing blew mind and I discovered a new site. This is like unlocking a new map for me. reply ess3 14 hours agoprevVery nice! The first brief I give my students when teaching web development is similar - Web design like it’s 1999 reply MarkusWandel 14 hours agoprevMissed a detail! It should be an IE4 (or so) window half obscured by a stack of junk \"toolbars\". reply spiritplumber 12 hours agoprevI miss the optimism of that era. I don't miss the weekly family beatings though. reply pknerd 14 hours agoprevNo JS framework, no NPM, no AJAX, and so on. The web was so simple, and so was life. reply rchaud 13 hours agoparentThe earliest DRM I can remember are those sites that blocked you from selecting text or right-clicking. reply hinkley 13 hours agoparentprevNo boats, no lights, no motorcars. Not a single luxury. reply HeckFeck 12 hours agorootparentWe aint so quaint, we're just technologically impaired! reply doublerabbit 13 hours agorootparentprevNo humans, just trees and dinosaurs. That's the life I want now. reply fsflover 16 hours agoprevSee also: https://wiby.me, search engine for such websites. reply O1111OOO 13 hours agoparent> See also: https://wiby.me, search engine for such websites. Thanks for reminding me about this! So much of the older information is lost using modern search engines. Even when I use the date range feature, I don't turn up the pages Wiby does. I had been using Yandex for searching older content but now I've added Wiby (right click inside its search form) to: https://addons.mozilla.org/en-US/firefox/addon/contextsearch... reply dakial1 11 hours agoprevThat Cyber-bear looks familiar... reply quartz 15 hours agoprevOh how that Soundblaster midi vibe takes me back. reply luizsantana 14 hours agoprevThis brings so much nostalgia and joy reply edpichler 14 hours agoprevIt was so much better. reply AlienRobot 8 hours agoprevFrom the little experience in web design I have, my opinion is that what killed the joy of web design were smartphones. Before screen size fragmentation you could just have a sidebar because everyone had the screen width to see it. You could just put two drilling workmen gifs and a huge under construction gif in the middle and everyone would be able to see it the way you designed it. Now you can't count on that anymore, which would be a bit of a problem if we were talking about JUST having a desktop design and a mobile design, but that's not how it works these days. Fluid, responsive design is sheer insanity to me. In principle, it makes perfect sense, but HTML is EXTREMELY inadequate at supporting this paradigm. You literally can not have a design that is minimal for mobile devices and then unfolds into glorious fixed width sidebars, because you MUST include the HTML for the sidebar in the mobile version and hide it with CSS black magic if you want it to unfold on wide screens, which means now the mobile version which should be as slim as possible is bloated with HTML it won't use, or you'll have to dynamically load the sidebar with javascript for desktop, which means the desktop version can't work without javascript enabled even though you're only using it make the sidebar it should have by default appear. I feel like many problems could be solved if we just replaced HTML with something else. reply ulrischa 13 hours agoprevPretty authentic. I love the blue links in black background - today a accessibility nightmare. reply pepelotas 9 hours agoparentThat's what sealed the deal for me. That and the animated GIFs of ladies. reply system2 14 hours agoprevIn 1999 websites were a little more modern compared to the early 90s. By 2000 there were many online gaming communities already. The BSOD is so realistic though :D reply rchaud 13 hours agoparentGeoCities/Angelfire sites looked like this at least until 2004 when blogs took off. As CMS architecture was a lot more complicated than static HTML/CSS, people stopped customizing their sites and just went with default themes. That was the magic of early Internet. No themes, no frameworks, just whatever you could do with HTML. reply mixmastamyk 14 hours agoprevDoesn't have a modem/ethernet icon in the tray to connect/disconnect and see traffic? I always looked for the blinking... and only now realized that I haven't had that for years. When did that go out of style? reply sylware 15 hours agoprevOnce you get that html table as layout are not harmful, that you use properly the border enabling attribute, augment the noscript/basic (x)html withand . Well... reply busymom0 15 hours agoprevIs it just me or is the address bar never updating even though the site changes? reply irrational 15 hours agoprev [–] I already surfed the web (and built websites) in all of 1999. Not even misplaced nostalgia would make me want to go back and surf the web like 1999 again. I’ll keep my modern browser, CSS Grid, and 1 Gigabit Fiber Optic line thank you very much. reply switchbak 15 hours agoparentSurf the web like it's 1999. And all the images load instantly. Yeah, that wasn't what it was like! And altavista.com doesn't even load! reply nrb 13 hours agoparentprev [–] What makes the nostalgia misplaced? reply shermantanktop 9 hours agorootparentNostalgia is the opiate of the elderly. Taking small sips before you get truly wizened is sometimes harmless, which I think is the case here. Too big a sip leads to yelling at clouds. reply irrational 12 hours agorootparentprev [–] Nostalgia is for good things. I surfed the web for the entirety of 1999. It wasn't good. reply HeckFeck 12 hours agorootparent [–] I'm not convinced that it is much better in this decade: - paywalls & 'login to see more' - autoplaying videos that follow you whn you're just trying to read an article - cookie banners - artificial loading throbbers - horrible intrusive tracking - an advertising corporation also has the near-monopoly on browsing - we have more bandwidth but apparently need 5Mb of javascript just to render text - mobile first design, meaning much lower information density - walled gardens like discord, facesbook, twitter, reddit storing content in inaccessible, unarchivable form There were problems then but there were fewer headaches and fewer exhausting battles just to stay sane. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has developed a website that mimics the design and aesthetics of websites from the 1999 era.",
      "They encourage others to visit their website and become part of their web ring by displaying a web button on their own sites.",
      "The website aims to evoke nostalgia and celebrate the design trends of the 1990s internet."
    ],
    "commentSummary": [
      "The discussion is centered around nostalgia for the early days of the internet, specifically the late 1990s web design and functionality.",
      "Participants reminisce about the simplicity of HTML-based layouts and technologies like interlaced GIFs and progressive JPEGs.",
      "Some express fatigue with the trend of retro-style websites, while others argue that the modern internet offers more advanced technologies and features."
    ],
    "points": 389,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1705684094
  },
  {
    "id": 39056169,
    "title": "Groundbreaking Discovery: Graphene-based Chip Outperforms Silicon in Electron Mobility",
    "originLink": "https://spectrum.ieee.org/graphene-semiconductor",
    "originBody": "SEMICONDUCTORS NEWS Researchers Claim First Functioning Graphene-Based Chip The semiconductor bests silicon alternatives for electron mobility DEXTER JOHNSON18 JAN 20244 MIN READ Walt de Heer of Georgia Tech peers through a chip based around the world’s first working graphene-based semiconductor. CHRIS MCKENNEY/GEORGIA INSTITUTE OF TECHNOLOGY",
    "commentLink": "https://news.ycombinator.com/item?id=39056169",
    "commentBody": "Researchers claim first functioning graphene-based chip (ieee.org)307 points by Brajeshwar 19 hours agohidepastfavorite99 comments ajb 16 hours agoBuries the lede a bit? Near the end is \"Conventional GFETs [graphene transistors] do not use semiconducting graphene, making them unsuitable for digital electronics requiring a complete transistor shutdown. [...] the SEC [material] developed by his team allows for a complete shutdown, meeting the stringent requirements of digital electronics.\" As far as I heard before, this was the problem with graphene transistors, they had a nonlinear response but did not shut down the current flow, making them not useful for digital logic, only analog circuits. But, it's a while since I read about this so maybe someone else already achieved this before. reply happytiger 10 hours agoparentI believe what you are referring to is called the Bandgap problem. Good explanation on the issue is here: https://www.allaboutcircuits.com/technical-articles/graphene... Convenience quote of relevant section: > Lack of Bandgap Despite being a fast and efficient transistor, the GFET does not have a bandgap. The gapless structure means that the valence and conduction bands meet at zero volts, hence making graphene to behave like a metal. In semiconductor materials such as silicon, the two bands are separated by a gap which behaves like an insulator under normal conditions. Usually, the electrons require some additional energy to jump from the valence band to the conduction band. In FETs, a bias voltage enables a current to flow through the band which acts as an insulator in the absence of the bias. Unfortunately, the absence of a band gap in GFET makes it hard to turn off the transistor since it cannot behave as an insulator. The inability to completely switch it off results in an on/off current ratio of about 5, which is quite low for logic operations. Consequently, using GFETs in digital circuits is a challenge. However, this is not a problem with analog circuits hence making the GFET suitable for amplifiers, mixed-signal circuits, and other analog applications. Multiple parties are researching ways to address these bandgap challenges, including techniques such as the negative resistance approach and the bottom-up synthesis technique of fabrication. reply singularity2001 12 hours agoparentprevSemi analog transistor would be perfectly fine for AI operations though? ( matrix multiplication, sigmoid, tanh etc ) reply marcosdumay 10 hours agorootparentAnalog or digital are properties of the signals you put on the circuits, not of the transistors. You can do digital manipulation with non-gapped transistors too. You just can't use the extremely intense when active but self-limiting designs we use today. Besides, unless we get some very creative new insights, analog computers are a dead-end. reply lbourdages 10 hours agorootparentI've been trying to find the source for a while, but I recall reading about a fundamental property of analog computers that makes them inherently unstable (as in, noise will always win on the long run), unlike digital computers. No matter how good the design is, little bits of noise add up in complex analog computers and the output is inexact. I guess my Google-fu is good enough, because I've been unable to find where I read about it. reply magicalhippo 3 hours agorootparentMultiplying two numbers in an analog circuit requires taking the logarithms and add those, then converting back, or some similar trick. In practice this is done using non-linear effects of transistors[1], however the exact details of those effects are individual to each transistor and is also temperature dependent. Since the multiplication circuit relies on different transistors behaving identically, compensation circuitry and trimming is required, which will never be perfect. [1]: https://www.analog.com/media/en/training-seminars/tutorials/... reply jari_mustonen 4 hours agorootparentprevCould this be the reason why human (and things with brains) need to sleep from time to time? Sleep would reset the accumulating noice from the brain. reply smolder 2 hours agorootparentIt's not really clear what you mean by the brain accumulating noise. An analog computer can suffer from compounding imprecision, because error bars carry forward. We are analog computers in a vague sense, but as humans we aren't imprecisely crunching numbers all day such that our results are out of whack by nightfall... You could say sleep is like a reset for the brain, but that doesn't say much. Sleep is complex and relates to most everything else about an organism in complex ways. reply Qwertious 1 hour agorootparentprevNah, humans just blank-out for a couple of seconds mid-task instead. reply marcosdumay 10 hours agorootparentprevAre you thinking about the property of analog data that it can't be stored, reprocessed, or copied without the noise increasing? That doesn't make the computers unstable. It just makes the data less fit for long-term storage. And even then, people manage. reply lbourdages 6 hours agorootparentNo, it wasn't about storage. It was really during calculations, you can't prevent the noise from affecting the results, from a fundamental level. reply fooker 29 minutes agorootparentFor any complicated calculation, you need to store and propagate multiple intermediate results. This is what goes wrong. error(x + y) > error(x) + error(y) reply j16sdiz 12 hours agoparentprevThat's the \"bandgap\" thing mentioned in the article. They exists, but very unreliable. reply throwbadubadu 16 hours agoprev> The outcome is transistors capable of operating at terahertz frequencies, offering speeds 10 times as fast as that of the silicon-based transistors used in current chips. Why? We are single digit gigahertz, so terahertzes should be ~ 100 times faster? reply AdamH12113 16 hours agoparentThe clock frequency is single-digit gigahertz. But digital signals have to propagate through multiple layers of logic gates, so the transistors have to switch much faster. At a glance, the article doesn't make it clear whether the \"terahertz\" speed refers to switching frequency or gain bandwidth (fT). You can definitely get transistors with fT in the hundreds of gigahertz range right now. reply itcrowd 11 hours agorootparent> digital signals have to propagate through multiple layers of logic gates, so the transistors have to switch much faster I don't think this is accurate. Are you saying that in digital computers each individual transistor switches faster than the clock rate of, say, 3 GHz? I think there is one clock signal that is distributed to all transistors and they turn on/off synchronously at this rate. The GHz number on the processor advertisement is the switching rate of all transistors, not some hypothetical 'system rate' which would somehow be much lower?? Please clarify or correct me if I am mistaken. reply xyzzy123 10 hours agorootparentI think it's easier to see if you jump up 1 level of abstraction from transistors to logic gates. Imagine an adder made up of logic gates. The gates aren't inherently synchronous - they don't have a clock input - signals appear at their inputs and some time later propagate to their outputs. To make the adder synchronous you need flip flops at the inputs/outputs and a clock. If you squint a bit you can view most designs as blobs of async logic sandwiched between sync elements (gated by the clock). We can see that a signal might have to go through a lot of gates/transistors between flip-flops and so the gates (and their underlying transistors) will necessarily need to be able to switch faster than the clock. reply AdamH12113 9 hours agorootparentprevYou’re mixing up time and frequency. For a signal to propagate through multiple logic gates in one clock cycle, each gate must switch in a fraction of a cycle. That means a single gate could switch more often (higher frequency) if it were by itself. But it’s not. (Technically, many gates do switch more than once per cycle since their inputs change at different times. But their outputs are only latched at the end of the cycle, so any extra switching is ignored.) reply itcrowd 14 hours agoparentprevFor digital computers, clock speeds are single digit GHz. For analog circuits, ~100 GHz is achievable in silicon. E.g., automotive radar chips, communication systems etc. This THz comment relates to analog circuits, which is supposedly around a factor 10 higher with this new tech. If you want to learn more, read about Fmax and Ft of transistors. reply daveFNbuck 16 hours agoparentprevWe're at single digit gigahertz for an entire chip, not a single transistor. reply mtlmtlmtlmtl 16 hours agoparentprevNot an EE, but my guess is that current transistors can likely operate at a much higher clock rate than current chips. The problem is that when you pack them together, they get far too hot to permit dennard scaling to reach the limits of the individual transistor. reply tux3 15 hours agorootparentThis one's not because of heat, but because signal had to go from the beginning of a stage, through several transistors, to the end of the stage So the transistors switch fast individually, but the speed of the chip is limited by the slowest path in any stage, where you wait for every transistor on the path in series reply magicalhippo 3 hours agorootparentI recall reading some decades ago about dividing chips into separate domains that would commuicate asynchronously, precisely to shorten the longest path and increase the max frequency. It's my understanding modern processors do indeed do this to varying degrees. reply foota 14 hours agorootparentprevOut of curiosity, how long are these paths generally? reply tux3 12 hours agorootparentSo, when I talked about the length of the path in number of transistors, I oversimplified a bit. The length of the path would be measured in nanoseconds (or even picoseconds). That number depends not just on the number of transistors, but also on the routing delay (are the interconnect wires between transistors long or short? How high is the resistance/capacitance?), and a lot of low-level details of the fabrication process that are extremely not public But say you buy a brand new CPU and it's clocked at 5 GHz, you can easily get a rough estimate of how long the critical path is, since 1/5GHz = 0.2ns What you can't easily get is the speed of the transistors or the number of transistors in the critical path, that info is not public, and you could only make a very rough guesstimate. reply jiggawatts 12 hours agorootparentprevLow single digit millimeters for current chip designs. One reason that clock speeds are going above 5 GHz these days is that chips are getting smaller. That means shorter signal propagation distances. reply mtlmtlmtlmtl 14 hours agorootparentprevAh, right, thanks for correcting me. reply deepnotderp 16 hours agoparentprevSingle transistor level frequency is different than chip level frequency. Each clock stage has many layers of transistors reply sheepscreek 10 hours agoparentprev> Why? We are single digit gigahertz, so terahertzes should be ~ 100 times faster? *1000 times reply bee_rider 17 hours agoprevThe manufacturing process seems quite friendly compared to the (albeit, local) ecological nightmare that is Si. It sure is hard to compete with half a century of Si advancement, though. Especially given how many STEM-brains get attracted to software instead, nowadays… reply varispeed 17 hours agoparent> Especially given how many STEM-brains get attracted to software instead, nowadays… It's just common sense. You won't earn decent money at semiconductor company and given the niche, you will be sentenced to whims of one or two (if you are lucky) companies operating in your region. If you find that your employer doesn't treat you well, you cannot exactly leave and bootstrap your own chip making business. Software is more democratised and you have much better chances to grow wealth of your family in that area. Although corrupt regulators are doing their best to pull as many ladders as they can to limit ways workers can go their own way (like changed IR35 legislation in the UK that massively limits how small service based business can operate). reply ngneer 16 hours agorootparentThis is right. The flip side is that having many talented software engineers renders each one slightly more dispensable. You want to find the right Goldilocks niche. Not too rare that mobility is limited, but not too prevalent that compensation suffers. reply tyre 16 hours agorootparentAs a hiring manager, I can confidently say that we are nowhere close to saturated with talented software engineers. reply bboygravity 7 hours agorootparent* talented very experienced software engineers under 35, who are willing to work on-site full-time (which often means move to the company) and are allowed to work in the US? Or am I being too synical? reply Firmwarrior 2 hours agorootparentSoftware is the easiest thing in the world to outsource. There's no reason we can't play Chinese-made games or use Indian-made chat apps Market forces (more demand than supply) are what push coding salaries into the stratosphere reply agumonkey 16 hours agorootparentprevso the niche is in training ? :D reply throwaway22048 13 hours agorootparentYes, I earn 3x more doing training than myself or any of my senior SWE colleagues/friends. Think 1500 EUR daily rate instead of 500 (in Central Europe). reply mindentropy 17 hours agorootparentprevIt is simple. If the Govt wants to support the semiconductor industry provide proper worker protections. It should know that the a few companies would have cartel like power and exploit their employees. reply idiotsecant 14 hours agorootparentIts rare that nuanced problems have simple solutions. The problem is not that evil employers are oppressing helpless employees, at least not entirely. The problem is that making physical things requires physical infrastructure and investment at a massive scale. Things move slowly and barrier to entry is high. Conditions like that are going to cause a slower, less transferrable skill set just because few entities are willing to take the capital risk to develop that infrustructure so fewer entities exist. Contrast that with software where you and I could go start a business now and potentially unseat a major player somewhere with enough talent and dedication. Its obvious which one is going to have more mobile employees. reply robertlagrant 12 hours agorootparentprevIt's not worker protections that will help. They will just end up incentivising industry to move elsewhere. The problem is it's too hard to set up competitors. Competitors are what raise employees' standards of living, far higher than vote-winning legislation. reply soitgoes511 11 hours agorootparentprevWon't earn decent money? Have you ever worked for a big semi company? I have and that is simply not true. Niche, maybe... But, they did not skimp high performers regarding wage. Believe it or not, there are plenty of good software positions in semiconductors too.. reply bee_rider 17 hours agorootparentprevI agree that the market has shifted in a way that we’re all individually making the rational decision by going into software, but it still seems like a shame. reply burnished 14 hours agorootparentprevYep! When I was in school and learning about semiconductors I was so interested that I went to the library for further reading and dropped by the physics department to ask questions, purely for my own edification. But I chose to pivot towards software due to the career prospects. reply crotchfire 15 hours agoparentprevJust wait until they scale it up and commercialize it; the nightmare will return. The sad fact is that nasty and exotic chemicals provide ways to make many manufacturing processes cheaper and run large batches. When you're pushing the limits of everything and the stakes are high, you can't really take them off the table. reply causal 18 hours agoprevIf I'm reading this correctly, this would more accurately be a graphene wafer, right? There are no circuits on this thing, it's just a sheet of graphene, right? Still remarkable if so, just not what I would call a \"functioning chip\". reply gwill 18 hours agoparentyea, looks like the author doesn't understand the difference between a semiconductor and a chip. the researchers said \"functioning semiconductor\". reply deepsquirrelnet 17 hours agoparentprevLikely single devices patterned from a epitaxially grown graphene layer. It would be a functioning transistor —- or set of transistors, albeit not terribly useful as single devices. Typically they would pattern the devices with large metal landing pads to drop probes onto, and perform characterization from there. reply OnACoffeeBreak 18 hours agoparentprevI only scanned the article and the paper, but the paper linked in the article talks about the researchers characterizing performance of a MosFET. reply idiotsecant 14 hours agoparentprevThe difference is just engineering once the material science is there. reply johntb86 16 hours agoprevPrevious discussions: https://news.ycombinator.com/item?id=38912240 and https://news.ycombinator.com/item?id=38878780 reply foota 13 hours agoprevAre there any niches for super high speed chips that it isn't possible to fill with silicon based chips? Would there ever be a niche for a small company making handfuls of them, or would it only be feasible at scale? reply Jweb_Guru 11 hours agoparentSure. Network switches for example have a pretty insatiable supply for processing speed. reply margorczynski 16 hours agoprevThe question is can this be as effectively processed and miniaturized as silicon. Still as someone pointed out they've already produced a transistor based on it and the claim is the same processes used for silicon can be used here so I sure hope it works out. reply EasyMark 15 hours agoparentYep, we have much faster switching semiconductors than silicon based ones, but that is like 10% of the deal; there is also miniaturization techniques, fab equipment, engineer/scientist expertise in the subject, conductor/semiconductor/insulator layers & interfaces, and oh so much more. It's nice to hear about advancements outside the regular silicon ecosystem but it's a tough row to hoe to push silicon aside for a \"better material\". It's probably going to have to be a revolutionary advantage (100x?) improvement over current tech to move to a new tech stack. reply dotnet00 14 hours agorootparentSince density with Si is approaching a wall soon and thus a switch in materials likely to end up being necessary at some point in the next 2-3 decades anyway, I feel like rather than being immediately revolutionary, all that'll end up mattering is where the theoretical limits are. After all, at that point, you need to retool and retrain anyway. reply mcshicks 16 hours agoparentprevSilicon based chips rely on oxide and metal layers to connect the transistors. Not clear to me from the article how that would work for graphene based devices. This was also an issue for GaAs based chips. From the Wikipedia article on GaAs \"The second major advantage of Si is the existence of a native oxide (silicon dioxide, SiO2), which is used as an insulator\" reply moffkalast 14 hours agoparentprevEven if it can't, ridiculously high current mosfets without heatsinks FTW. reply foota 13 hours agoprevIt's amusing to think about something like a several thousand (probably more like billions?) transistor graphene based chip outdoing a trillions transistor behemoth. I don't know if that's possible in reality though, since things like cache space are important regardless of your clock speed and there's no point in being able to do fast logic if you can't pipe in enough data. reply photochemsyn 17 hours agoprevFull research article: https://arxiv.org/pdf/2308.12446 They did make a proof-of-concept device: \"The electrical properties of the SEG were measured by characterizing a fabricated top-gated SEG FET.\" reply ngneer 17 hours agoprevTrouble is always with scaling and equipment. Unless one uses the existing infrastructure, low chance of success. reply px43 16 hours agoparentI also think that a fundamental issue with using carbon for compute is that we don't actually have a lot of it, and what we do have we largely need for all that organic chemistry that keeps us alive. For reference, carbon makes up about 0.18% of the earth's mass, whereas silicon makes up 27.7%. The moon basically has zero carbon, and the regolith is 20% silicon. reply AdamH12113 15 hours agorootparentFar more of the silicon (from sand) goes into concrete and glass, though. And it's not like we're short on hydrocarbons. From what I can gather, the total yearly worldwide production of concrete is tens of billions of metric tons, fossil fuels are billions of tons, and silicon is millions of tons -- barely a blip on the radar. reply klysm 4 hours agorootparentIt's not like we're anywhere close to short on Si though... not sure it's a relevant comparison reply h0l0cube 9 hours agorootparentprevAnd imagine running out of coal! reply programjames 17 hours agoprevWhere did they claim to make a chip? It seems to be just a single epigraphene layer. reply jacquesm 15 hours agoparent'just'? reply robertlagrant 12 hours agorootparentA chip is a lot harder than a wafer, and a chip is what's claimed. reply jacquesm 11 hours agorootparentFrom nothing at all to a wafer of a new material is a giant step compared to the step from a wafer to a chip. reply topspin 10 hours agorootparentIs it? What is the plan for depositing these materials with precision to implement logic? Doesn't seem like conventional lithography is applicable. reply h0l0cube 9 hours agorootparentAccording to a sibling comment they already made a FET https://news.ycombinator.com/item?id=39057303 reply topspin 8 hours agorootparentThat paper describes using e-beam deposition: they're using an electron beam to fabricate individual components in the lab. That's fine for experiments. It has zero value for making devices with billions of components. Unless there is something akin to lithograph techniques you can't make products economically. reply jacquesm 7 hours agorootparentIt would seem a bit much to require that they jump from 'have a wafer' to 'volume production' overnight. But the fact that they can use electron beam deposition to fabricate indicates one very important thing (to me, at least): the same kind of technologies that can work on Silicon wafers appear to be viable for these Graphene based ones. And that would allow recycling a whole pile of tech, possibly speedrunning through the last bunch of feature sizes because of all of the experience gained with Silicon. To me it says Graphene will now work in the next five to ten years or it will likely never happen. It would need to outperform Silicon on at least one metric (density, power consumption, speed) to make it worth it for niche applications and then bit by bit economies of scale would take over. reply GalaxyNova 8 hours agoprevmoore's law is not dead. reply klysm 4 hours agoparentI don't think this has any relevance (at least in its current state) for digital compute. reply RecycledEle 11 hours agoprev> This heating step is done with an argon quartz tube in which a stack of two SiC chips are placed in a graphite crucible, according to de Heer. Then a high-frequency current is run through a copper coil around the quartz tube, which heats the graphite crucible through induction. So they use a tube furnace? > “The chips we use cost about [US] $10, the crucible about $1, and the quartz tube about $10,” said de Heer. Tube furnaces do not cost $10 except when you build it yourself and do not count the thousands of dollars of equipment you have sitting around. reply uSoldering 11 hours agoparentThey are talking about the price of consumables in the process. You also need a building and electricity and employees and a whole bunch of other stuff you can infer via deduction. reply LAC-Tech 15 hours agoprevoh very cool. I remember hearing about graphene in inorganic chemistry 101 and thinking it that was the neatest thing in the world. That and carbon nanotubes. De Heer says that it will take time to develop this technology. “I compare this work to the Wright brothers’ first 100-meter flight. It will mainly depend on how much work is done to develop it.” Something to look forward to! reply kaptainscarlet 18 hours agoprevThis could be the breakthrough that could miniaturized AI more powerful. reply programjames 17 hours agoparentThis is still years away from mass production. The process takes hours at very high temperatures to make a single layer. reply givinguflac 17 hours agorootparentNope, it takes about an hour for one layer. FTA: “Then a high-frequency current is run through a copper coil around the quartz tube, which heats the graphite crucible through induction. The process takes about an hour.” reply mthcalixto 16 hours agoprevGraphene is the future and Brazil is the largest country that has this resource, it could be the best country in the world. reply binarymax 16 hours agoparentGraphene (https://en.m.wikipedia.org/wiki/Graphene) is manufactured from carbon. You don’t pull graphene out of the ground, you manufacture it in a lab. reply neuronexmachina 16 hours agorootparentI've been playing too much Dyson Sphere Program lately, my first thought was \"you just need to combine graphite and sulfuric acid in your chemical plant\": https://dyson-sphere-program.fandom.com/wiki/Graphene Looks like that's sort-of a real thing? https://www.americanscientist.org/article/mass-producing-gra... > Researchers at Rutgers University are making sheets of graphene out of ordinary graphite flakes and some sulfuric or nitric acid. reply klyrs 12 hours agorootparentEven if you could just magically make a reel of graphene with this graphite+sulphuric acid recipe, it wouldn't help one bit in chip fabrication. You need to build things layer by layer; there's only one place where a bulk material is used, and that's the substrate. reply seaal 13 hours agorootparentprevAlways nice when games introduce you to real life concepts. Shout out to Greg Tech: New Horizons, often leading me down a wikipedia rabbit hole. reply neuronexmachina 16 hours agoparentprevAssuming you mean graphite (which can be used in graphene production), it looks like Turkey might have even more reserves. China, Madagascar, and Mozambique also have pretty significant graphite reserves: https://www.statista.com/statistics/267367/reserves-of-graph... reply dudeinjapan 16 hours agoparentprevBrazil is the world’s third largest producer of graphite, behind China and Mozambique. Our current most reliable graphene production methods start with graphite and exfoliate it into single layers of graphene. reply wigster 16 hours agoparentprevits made out of sellotape/scotch tape and pencils! ;-) reply cassiogo 16 hours agoparentprevI belive you are thinking about Niobium and not Graphene reply ur-whale 16 hours agoparentprevI thought Graphene was just a form of Carbon, and mostly produced from regular carbon through some sort of process. Are you saying Graphene can be found in nature? reply dtx1 16 hours agoparentprevIsn't graphene just carbon? reply moffkalast 14 hours agoparentprevEven if that were true, countries where most of the wealth is dug or pumped from the ground are the worst places to live because it can all be be easily extracted by foreign companies who pay a cut to the dictator directly and the people have nothing to threaten the laughably rich autocrat with. reply r3d0c 16 hours agoparentprevlol.. unless brazil is the only country in the world with carbon, this is absolutely not true reply dylan604 18 hours agoprev [–] Having a title for anything with \"Researchers claim...\" is such a red flag that I don't even want to click the link. I've been burned too many times. I know that fire is hot, I don't need to touch it again to find out. I'm a quick study, and after the 10th time, it took hold reply bogtog 17 hours agoparentIsn't it notable that the article is at least acknowledging this uncertainty? reply colordrops 17 hours agoparentprev [–] Speaking of graphene, I've been hearing about its miraculous powers for years. Are there any practical applications yet? reply theragra 17 hours agorootparentIt is used in industrial uses widely, for composites with greater durability, strength etc reply dotnet00 15 hours agorootparentprevI'm not sure if they're available on market already, but I recall that graphene Li-ion batteries are being seen as a decent near term upgrade, with the production issues of graphene reduced because they don't need large sheets of it. reply theragra 17 hours agorootparentprev [–] Also, for fun, search for nano tape. I think it is using carbon nano structures, close relatives of graphene reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers at Georgia Tech have created the world's first operating chip made from graphene, a material with superior electron mobility compared to silicon.",
      "Graphene-based chips have the potential to outperform silicon alternatives in terms of speed and power consumption.",
      "This breakthrough could lead to more efficient and advanced electronic devices in the future."
    ],
    "commentSummary": [
      "A new graphene-based chip called SEC has been developed, addressing the bandgap issue faced by graphene transistors and making it viable for digital electronics.",
      "Terahertz frequency-operating transistors using SEC offer speeds ten times faster than current silicon-based transistors.",
      "There is a debate on the potential of graphene-based chips, with some emphasizing the need for more research and development to determine their effectiveness. The manufacturing process of graphene, its potential applications, and limitations are also discussed."
    ],
    "points": 307,
    "commentCount": 99,
    "retryCount": 0,
    "time": 1705675961
  },
  {
    "id": 39060339,
    "title": "Building a Record-Breaking Single-Cluster Ceph: Achieving 1 TiB/s Performance",
    "originLink": "https://ceph.io/en/news/blog/2024/ceph-a-journey-to-1tibps/",
    "originBody": "News Ceph Blog Publications Contribute Content Crimson Project Ceph: A Journey to 1 TiB/s Jan 19, 2024 Mark Nelson (nhm) I can't believe they figured it out first. That was the thought going through my head back in mid-December after several weeks of 12-hour days debugging why this cluster was slow. This was probably the most intense performance analysis I'd done since Inktank. Half-forgotten superstitions from the 90s about appeasing SCSI gods flitted through my consciousness. The 90s? Man, I'm getting old. We were about two-thirds of the way through the work that would let us start over at the beginning. Speaking of which, I'll start over at the beginning. Back in 2023 (I almost said earlier this year until I remembered we're in 2024), Clyso was approached by a fairly hip and cutting edge company that wanted to transition their HDD backed Ceph cluster to a 10 petabyte NVMe deployment. They were immediately interesting. They had no specific need for RBD, RGW, or CephFS. They had put together their own hardware design, but to my delight approached us for feedback before actually purchasing anything. They had slightly unusual requirements. The cluster had to be spread across 17 racks with 4U of space available in each. Power, cooling, density, and vendor preference were all factors. The new nodes needed to be migrated into the existing cluster with no service interruption. The network however was already built, and it's a beast. It's one of the fastest Ethernet setups I've ever seen. I knew from the beginning that I wanted to help them build this cluster. I also knew we'd need to do a pre-production burn-in and that it would be the perfect opportunity to showcase what Ceph can do on a system like this. What follows is the story of how we built and tested that cluster and how far we were able to push it. Acknowledgments I would first like to thank our amazing customer who made all of this possible. You were a pleasure to work with! Thank you as well for allowing us here at Clyso to share this experience with the Ceph community. It is through this sharing of knowledge that we make the world a better place. Thank you to IBM/Red Hat and Samsung for providing the Ceph community with the hardware used for comparison testing. It was invaluable to be able to evaluate the numbers we were getting against previous tests from the lab. Thank you to all of the Ceph contributors who have worked tirelessly to make Ceph great! Finally, thank you especially to Anthony D'Atri and Lee-Ann Pullar for their amazing copyediting skills! Cluster Setup When the customer first approached Clyso, they proposed a configuration utilizing 34 dual-socket 2U nodes spread across 17 racks. We provided a couple of alternative configurations from multiple vendors with a focus on smaller nodes. Ultimately they decided to go with a Dell architecture we designed, which quoted at roughly 13% cheaper than the original configuration despite having several key advantages. The new configuration has less memory per OSD (still comfortably 12GiB each), but faster memory throughput. It also provides more aggregate CPU resources, significantly more aggregate network throughput, a simpler single-socket configuration, and utilizes the newest generation of AMD processors and DDR5 RAM. By employing smaller nodes, we halved the impact of a node failure on cluster recovery. The customer indicated they would like to limit the added per-rack power consumption to around 1000-1500 watts. With 4 of these nodes per rack, the aggregate TDP is estimated to be at least 1120 Watts plus base power usage, CPU overage peaks, and power supply inefficiency. IE it's likely we're pushing it a bit under load, but we don't expect significant deviation beyond the acceptable range. If worse came to worst, we estimated we could shave off roughly 100 watts per rack by lowering the processor cTDP. Specs for the system are shown below: Nodes 68 x Dell PowerEdge R6615 CPU 1 x AMD EPYC 9454P 48C/96T Memory 192GiB DDR5 Network 2 x 100GbE Mellanox ConnectX-6 NVMe 10 x Dell 15.36TB Enterprise NVMe Read Intensive AG OS Version Ubuntu 20.04.6 (Focal) Ceph Version Quincy v17.2.7 (Upstream Deb Packages) An additional benefit of utilizing 1U Dell servers is that they are essentially a newer refresh of the systems David Galloway and I designed for the upstream Ceph performance lab. These systems have been tested in a variety of articles over the past couple of years. It turns out that there was a major performance-impacting issue that came out during testing that did not affect the previous generation of hardware in the upstream lab but did affect this new hardware. We'll talk about that more later. Without getting into too many details, I will reiterate that the customer's network configuration is very well-designed and quite fast. It easily has enough aggregate throughput across all 17 racks to let a cluster of this scale really stretch its legs. Testing Setup To do the burn-in testing, ephemeral Ceph clusters were deployed and FIO tests were launched using CBT. CBT was configured to deploy Ceph with several modified settings. OSDs were assigned an 8GB osd_memory_target. In production, a higher osd_memory_target should be acceptable. The customer had no need to test block or S3 workloads, so one might assume that RADOS bench would be the natural benchmark choice. In my experience, testing at a large scale with RADOS bench is tricky. It's tough to determine how many instances are needed to saturate the cluster at given thread counts. I've run into issues in the past where multiple concurrent pools were needed to scale performance. I also didn't have any preexisting RADOS bench tests handy to compare against. Instead, we opted to do burn-in testing using the same librbd backed FIO testing we've used in the upstream lab. This allowed us to partition the cluster into smaller chunks and compare results with previously published results. FIO is also very well known and well-trusted. A major benefit of the librbd engine in FIO (versus utilizing FIO with kernel RBD) is that there are no issues with stale mount points potentially requiring system reboots. We did not have IPMI access to this cluster and we were under a tight deadline to complete tests. For that reason, we ultimately skipped kernel RBD tests. Based on previous testing, however, we expect the aggregate performance to be roughly similar given sufficient clients. We were able, however, to test both 3X replication and 6+2 erasure coding. We also tested msgr V2 in both unencrypted and secure mode using the following Ceph options: ms_client_mode = secure ms_cluster_mode = secure ms_service_mode = secure ms_mon_client_mode = secure ms_mon_cluster_mode = secure ms_mon_service_mode = secure OSDs were allowed to use all cores on the nodes. FIO was configured to first pre-fill RBD volume(s) with large writes, followed by 4MB and 4KB IO tests for 300 seconds each (60 seconds during debugging runs). Certain background processes, such as scrub, deep scrub, PG autoscaling, and PG balancing were disabled. A Note PG counts ¶ Later in this article, you'll see some eye-popping PG counts being tested. This is intentional. We know from previous upstream lab testing that the PG count can have a dramatic effect on performance. Some of this is due to clumpiness in random distributions at low sample (PG) counts. This potentially can be mitigated in part through additional balancing. Less commonly discussed is PG lock contention inside the OSD. We've observed that on very fast clusters, PG lock contention can play a significant role in overall performance. This unfortunately is less easily mitigated without increasing PG counts. How much does PG count actually matter? With just 60 OSDs, Random read performance scales all the way up to 16384 PGs on an RBD pool using 3X replication. Writes top out much earlier, but still benefits from up to 2048 PGs. Let me be clear: You shouldn't go out and blindly configure a production Ceph cluster to use PG counts as high as we are testing here. That's especially true given some of the other defaults in Ceph for things like PG log lengths and PG stat updates. I do, however, want to encourage the community to start thinking about whether the conventional wisdom of 100 PGs per OSD continues to make sense. I would like us to rethink what we need to do to achieve higher PG counts per OSD while keeping overhead and memory usage in check. I dream about a future where 1000 PGs per OSD isn't out of the ordinary, PG logs are auto-scaled on a per-pool basis, and PG autoscaling is a far more seldom-used operation. A Rough Start We were first able to log into the new hardware the week after Thanksgiving in the US. The plan was to spend a week or two doing burn-in validation tests and then integrate the new hardware into the existing cluster. We hoped to finish the migration in time for the new year if everything went to plan. Sadly, we ran into trouble right at the start. The initial low-level performance tests looked good. Iperf network testing showed us hitting just under 200Gb/s per node. Random sampling of a couple of the nodes showed reasonable baseline performance from the NVMe drives. One issue we immediately observed was that the operating system on all 68 nodes was accidentally deployed on 2 of the OSD drives instead of the internal Dell BOSS m.2 boot drives. We had planned to compare results for a 30 OSD configuration (3 nodes, 10 OSDs per node) against the results from the upstream lab (5 nodes, 6 OSDs per node). Instead, we ended up testing 8 NVMe drives per node. The first Ceph results were far lower than what we had hoped to see, even given the reduced OSD count. The only result that was even close to being tolerable was for random reads, and that still wasn't great. Clearly, something was going on. We stopped running 3-node tests and started looking at single-node, and even single OSD configurations. That's when things started to get weird. Spooky Behavior As we ran different combinations of 8-OSD and 1-OSD tests on individual nodes in the cluster, we saw wildly different behavior, but it took several days of testing to really understand the pattern of what we were seeing. Systems that initially performed well in single-OSD tests stopped performing well after multi-OSD tests, only to start working well again hours later. 8-OSD tests would occasionally show signs of performing well, but then perform terribly for all subsequent tests until the system was rebooted. We were eventually able to discern a pattern on fresh boot that we could roughly repeat across different nodes in the cluster: Step OSDS 4MB Randread (MB/s) 4MB Randwrite (MB/s) Boot1 1 OSD 5716 3998 2 8 OSDs 3190 2494 3 1 OSD 523 3794 4 8 OSDs 2319 2931 5 1 OSD 551 3796 20-30 minute pause6 1 OSD 637 3724 20-30 minute pause7 1 OSD 609 3860 20-30 minute pause8 1 OSD 362 3972 20-30 minute pause9 1 OSD 6581 3998 20-30 minute pause10 1 OSD 6350 3999 20-30 minute pause11 1 OSD 6536 4001 The initial single-OSD test looked fantastic for large reads and writes and showed nearly the same throughput we saw when running FIO tests directly against the drives. As soon as we ran the 8-OSD test, however, we observed a performance drop. Subsequent single-OSD tests continued to perform poorly until several hours later when they recovered. So long as a multi-OSD test was not introduced, performance remained high. Confusingly, we were unable to invoke the same behavior when running FIO tests directly against the drives. Just as confusing, we saw that during the 8 OSD test, a single OSD would use significantly more CPU than the others: 4MB Random Read ¶ PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 511067 root 20 0 9360000 7.2g 33792 S 1180 3.8 15:24.32 ceph-osd515664 root 20 0 9357488 7.2g 34560 S 523.6 3.8 13:43.86 ceph-osd513323 root 20 0 9145820 6.4g 34560 S 460.0 3.4 13:01.12 ceph-osd514147 root 20 0 9026592 6.6g 33792 S 378.7 3.5 9:56.59 ceph-osd516488 root 20 0 9188244 6.8g 34560 S 378.4 3.6 10:29.23 ceph-osd518236 root 20 0 9390772 6.9g 33792 S 361.0 3.7 9:45.85 ceph-osd511779 root 20 0 8329696 6.1g 33024 S 331.1 3.3 10:07.18 ceph-osd516974 root 20 0 8984584 6.7g 34560 S 301.6 3.6 9:26.60 ceph-osd A wallclock profile of the OSD under load showed significant time spent in io_submit, which is what we typically see when the kernel starts blocking because a drive's queue becomes full. Example tp_osd_tp Thread io_submit Wallclock Profile ¶ + 31.00% BlueStore::readv(boost::intrusive_ptr&, g... + 31.00% BlueStore::_do_readv(BlueStore::Collection*, boost::intrusive_ptr, std::_List_it...+ 24.00% io_submit+ 24.00% syscall Why would running an 8 OSD test cause the kernel to start blocking in io_submit during future single OSD tests? It didn't make very much sense. Initially, we suspected throttling. We saw that with the default cooling profile in the bios, several of the core complexes on the CPU were reaching up to 96 degrees Celsius. We theorized that perhaps we were hitting thermal limits on either the CPU or the NVMe drives during the 8-OSD tests. Perhaps that left the system in a degraded state for a period of time before recovering. Unfortunately, that theory didn't pan out. AMD/Dell confirmed that we shouldn't be hitting throttling even at those temperatures, and we were able to disprove the theory by running the systems with the fans running at 100% and a lower cTDP for the processor. Those changes kept them consistently around 70 degrees Celsius under load without fixing the problem. For over a week, we looked at everything from bios settings, NVMe multipath, low-level NVMe debugging, changing kernel/Ubuntu versions, and checking every single kernel, OS, and Ceph setting we could think of. None these things fully resolved the issue. We even performed blktrace and iowatcher analysis during \"good\" and \"bad\" single OSD tests, and could directly observe the slow IO completion behavior: Blkparse Output - Good vs Bad ¶ Timestamp (good) Offset+Length (good) Timestamp (bad) Offset+Length (bad) 10.00002043 1067699792 + 256 [0] 10.0013855 1206277696 + 512 [0] 10.00002109 1153233168 + 136 [0] 10.00138801 1033429056 + 1896 [0] 10.00016955 984818880 + 8 [0] 10.00209283 1031056448 + 1536 [0] 10.00018827 1164427968 + 1936 [0] 10.00327372 1220466752 + 2048 [0] 10.0003024 1084064456 + 1928 [0] 10.00328869 1060912704 + 2048 [0] 10.00044238 1067699280 + 512 [0] 10.01285746 1003849920 + 2048 [0] 10.00046659 1040160848 + 128 [0] 10.0128617 1096765888 + 768 [0] 10.00053302 1153233312 + 1712 [0] 10.01286317 1060914752 + 720 [0] 10.00056482 1153229312 + 2000 [0] 10.01287147 1188736704 + 512 [0] 10.00058707 1067694160 + 64 [0] 10.01287216 1220468800 + 1152 [0] 10.00080624 1067698000 + 336 [0] 10.01287812 1188735936 + 128 [0] 10.00111046 1145660112 + 2048 [0] 10.01287894 1188735168 + 256 [0] 10.00118455 1067698344 + 424 [0] 10.0128807 1188737984 + 256 [0] 10.00121413 984815728 + 208 [0] 10.01288286 1217374144 + 1152 [0] The Three Fixes At this point, we started getting the hardware vendors involved. Ultimately it turned out to be unnecessary. There was one minor, and two major fixes that got things back on track. Fix One ¶ The first fix was an easy one, but only got us a modest 10-20% performance gain. Many years ago it was discovered (Either by Nick Fisk or Stephen Blinick if I recall) that Ceph is incredibly sensitive to latency introduced by CPU c-state transitions. A quick check of the bios on these nodes showed that they weren't running in maximum performance mode which disables c-states. This was a nice win but not enough to get the results where we wanted them. Fix Two ¶ By the time I was digging into the blktrace results shown above, I was about 95% sure that we were either seeing an issue with the NVMe drives or something related to the PCIe root complex since these systems don't have PCIe switches in them. I was busy digging into technical manuals and trying to find ways to debug/profile the hardware. A very clever engineer working for the customer offered to help out. I set up a test environment for him so he could repeat some of the same testing on an alternate set of nodes and he hit a home run. While I had focused primarily on wallclock profiles and was now digging into trying to debug the hardware, he wanted to understand if there was anything interesting happening kernel side (which in retrospect was the obvious next move!). He ran a perf profile during a bad run and made a very astute discovery: 77.37% tp_osd_tp [kernel.kallsyms] [k] native_queued_spin_lock_slowpath---native_queued_spin_lock_slowpath--77.36%--_raw_spin_lock_irqsave ||--61.10%--alloc_iovaalloc_iova_fastiommu_dma_alloc_iova.isra.0iommu_dma_map_sg__dma_map_sg_attrsdma_map_sg_attrsnvme_map_datanvme_queue_rq__blk_mq_try_issue_directlyblk_mq_request_issue_directlyblk_mq_try_issue_list_directlyblk_mq_sched_insert_requestsblk_mq_flush_plug_listblk_flush_plug_list|| |--56.54%--blk_mq_submit_bio A huge amount of time is spent in the kernel contending on a spin lock while updating the IOMMU mappings. He disabled IOMMU in the kernel and immediately saw a huge increase in performance during the 8-node tests. We repeated those tests multiple times and repeatedly saw much better 4MB read/write performance. Score one for the customer. There was however still an issue with 4KB random writes. Fix Three ¶ After being beaten to the punch by the customer on the IOMMU issue, I was almost grateful that we had an additional problem to solve. 4K random write performance had improved with the first two fixes but was still significantly worse than the upstream lab (even given the reduced node/drive counts). I also noticed that compaction was far slower than expected in RocksDB. There previously have been two significant cases that presented similarly and appeared to be relevant: Ceph can be very slow when not properly compiled with TCMalloc support. Ceph can be very slow when not compiled with the right cmake flags and compiler optimizations. Historically this customer used the upstream Ceph Ubuntu packages and we were still using them here (rather than self-compiling or using cephadm with containers). I verified that TCMalloc was compiled in. That ruled out the first issue. Next, I dug out the upstream build logs for the 17.2.7 Ubuntu packages. That's when I noticed that we were not, in fact, building RocksDB with the correct compile flags. It's not clear how long that's been going on, but we've had general build performance issues going back as far as 2018. It turns out that Canonical fixed this for their own builds as did Gentoo after seeing the note I wrote in do_cmake.sh over 6 years ago. It's quite unfortunate that our upstream Deb builds have suffered with this for as long as they have, however, it at least doesn't appear to affect anyone using cephadm on Debian/Ubuntu with the upstream containers. With the issue understood, we built custom 17.2.7 packages with a fix in place. Compaction time dropped by around 3X and 4K random write performance doubled (Though it's a bit tough to make out in the graph): 4KB random write performance was still lower than I wanted it to be, but at least now we were in roughly the right ballpark given that we had fewer OSDs, only 3/5 the number of nodes, and fewer (though faster) cores per OSD. At this point, we were nearing winter break. The customer wanted to redeploy the OS to the correct boot drives and update the deployment with all of the fixes and tunings we had discovered. The plan was to take the holiday break off and then spend the first week of the new year finishing the burn-in tests. Hopefully, we could start migrating the cluster the following week. The First week of 2024 On the morning of January 2nd, I logged into Slack and was greeted by a scene I'll describe as moderately controlled chaos. A completely different cluster we are involved in was having a major outage. Without getting too into the details, it took 3 days to pull that cluster back from the brink and get it into a stable and relatively healthy state. It wasn't until Friday that I was able to get back to performance testing. I was able to secure an extra day for testing on Monday, but this meant I was under a huge time crunch to showcase that the cluster could perform well under load before we started the data migration process. Fate Smiles ¶ I worked all day on Friday to re-deploy CBT and recreate the tests we ran previously. This time I was able to use all 10 of the drives in each node. I also bumped up the number of clients to maintain an average of roughly 1 FIO client with an io_depth of 128 per OSD. The first 3 node test looked good. With 10 OSDs per node, We were achieving roughly proportional (IE higher) performance relative to the previous tests. I knew I wasn't going to have much time to do proper scaling tests, so I immediately bumped up from 3 nodes to 10 nodes. I also scaled the PG count at the same time and used CBT to deploy a new cluster. At 3 nodes I saw 63GiB/s for 4MB random reads. At 10 Nodes, I saw 213.5GiB/s. That's almost linear scaling at 98.4%. It was at this point that I knew that things were finally taking a turn for the better. Of the 68 nodes for this cluster, only 63 were up at that time. The rest were down for maintenance to fix various issues. I split the cluster roughly in half, with 32 nodes (320 OSDs) in one half, and 31 client nodes running 10 FIO processes each in the other half. I watched as CBT built the cluster over roughly a 7-8 minute period. The initial write prefill looked really good. My heart soared. We were reading data at 635 GiB/s. We broke 15 million 4k random read IOPS. While this may not seem impressive compared to the individual NVMe drives, these were the highest numbers I had ever seen for a ~300 OSD Ceph cluster. I also plotted both average and tail latency for the scaling tests. Both looked consistent. This was likely due to scaling the PG count and the FIO client count at the same time as OSDs. These tests are very IO-heavy however. We have so much client traffic that we are likely well into the inflection point where performance doesn't increase while latency continues to grow as more IO is added. I showed these results to my colleague Dan van der Ster who previously had built the Ceph infrastructure at CERN. He bet me a beer (Better be a good one Dan!) if I could hit 1 TiB/s. I told him that had been my plan since the beginning. A Partially Operational Death Star I had no additional client nodes to test the cluster with at full capacity, so the only real option was to co-locate FIO processes on the same nodes as the OSDs. On one hand, this provides a very slight network advantage. Clients will be able to communicate with local OSDs 1/63rd of the time. On the other hand, we know from previous testing that co-locating FIO clients on OSD nodes isn't free. There's often a performance hit, and it wasn't remotely clear to me how much of a hit a cluster of this scale would take. I built a new CBT configuration targeting the 63 nodes I had available. Deploying the cluster with CBT took about 15 minutes to stand up all 630 OSDs and build the pool. I waited with bated breath and watched the results as they came in. Around 950GiB/s. So very very close. It was late on Friday night at this point, so I wrapped up and turned in for the night. On Saturday morning I logged in and threw a couple of tuning options at the cluster: Lowering OSD shards and async messenger threads while also applying the Reef RocksDB tunings. As you can see, we actually hurt read performance a little while helping write performance. In fact, random write performance improved by nearly 20%. After further testing, it looked like the reef tunings were benign though only helping a little bit in the write tests. The bigger effect seemed to be coming from shard/thread changes. At this point, I had to take a break and wasn't able to get back to working on the cluster again until Sunday night. I tried to go to bed, but I knew that I was down to the last 24 hours before we needed to wrap this up. At around midnight I gave up on sleep and got back to work. I mentioned earlier that we know that the PG count can affect performance. I decided to keep the \"tuned\" configuration from earlier but doubled the number of PGs. In the first set of tests, I had dropped the ratio of clients to OSDs down given that we were co-locating them on the OSD nodes. Now I tried scaling them up again. 4MB random read performance improved slightly as the number of clients grew, while small random read IOPS degraded. Once we hit 8 FIO processes per node (504 total), sequential write performance dropped through the floor. To understand what happened, I reran the write test and watched “ceph -s” output: services: mon: 3 daemons, quorum a,b,c (age 42m) mgr: a(active, since 42m) osd: 630 osds: 630 up (since 24m), 630 in (since 25m) flags noscrub,nodeep-scrub data: pools: 2 pools, 131073 pgs objects: 4.13M objects, 16 TiB usage: 48 TiB used, 8.2 PiB / 8.2 PiB avail pgs: 129422 active+clean 1651 active+clean+laggy io: client: 0 B/s rd, 1.7 GiB/s wr, 1 op/s rd, 446 op/s wr As soon as I threw 504 FIO processes doing 4MB writes at the cluster, some of the PGs started going active+clean+laggy. Performance tanked and the cluster didn't recover from that state until the workload was completed. What's worse, more PGs went laggy over time even though the throughput was only a small fraction of what the cluster was capable of. Since then, we've found a couple of reports of laggy PGs on the mailing list along with a couple of suggestions that might fix them. It's not clear if those ideas would have helped here. We do know that IO will temporarily be paused when PGs go into a laggy state and that this happens because a replica hasn't acknowledged new leases from the primary in time. After discussing the issue with other Ceph developers, we think this could possibly be an issue with locking in the OSD or having lease messages competing with work in the same async msgr threads. Despite being distracted by the laggy PG issue, I wanted to refocus on hitting 1.0TiB/s. Lack of sleep was finally catching up with me. At some point I had doubled the PG count again to 256K, just to see if it had any effect at all on the laggy PG issue. That put us solidly toward the upper end of the curve we showed earlier, though frankly, I don't think it actually mattered much. I decided to switch back to the default OSD shard counts and continue testing with 504 FIO client processes. I did however scale the number of async messenger threads. There were two big takeaways. The first is that dropping down to 1 async messenger allowed us to avoid PGs going laggy and achieve “OK” write throughput with 504 clients. It also dramatically hurt the performance of 4MB reads. The second: Ceph's defaults were actually ideal for 4MB reads. With 8 shards, 2 threads per shard, and 3 msgr threads, we finally broke 1TiB/s. Here's the view I had at around 4 AM Monday morning as the final set of tests for the night ran: services: mon: 3 daemons, quorum a,b,c (age 30m) mgr: a(active, since 30m) osd: 630 osds: 630 up (since 12m), 630 in (since 12m) flags noscrub,nodeep-scrub data: pools: 2 pools, 262145 pgs objects: 4.13M objects, 16 TiB usage: 48 TiB used, 8.2 PiB / 8.2 PiB avail pgs: 262145 active+clean io: client: 1.0 TiB/s rd, 6.1 KiB/s wr, 266.15k op/s rd, 6 op/s wr and the graphs from the FIO results: Sleep; Erasure Coding After finally seeing the magical \"1.0 TiB/s\" screen I had been waiting weeks to see, I finally went to sleep. Nevertheless, I got up several hours later. There was still work to be done. All of the testing we had done so far was with 3X replication, but the customer would be migrating this hardware into an existing cluster deployed with 6+2 erasure coding. We needed to get some idea of what this cluster was capable of in the configuration they would be using. I reconfigured the cluster again and ran through new tests. I picked PG/shard/client values from the earlier tests that appeared to work well. Performance was good, but I saw that the async messenger threads were working very hard. I decided to try increasing them beyond the defaults to see if they might help given the added network traffic. We could achieve well over 500GiB/s for reads and nearly 400GiB/s for writes with 4-5 async msgr threads. But why are the read results so much slower with EC than with replication? With replication, the primary OSD for a PG only has to read local data and send it to the client. The network overhead is essentially 1X. With 6+2 erasure coding, the primary must read 5 of the 6 chunks from replicas before it can then send the constructed object to the client. The overall network overhead for the request is roughly (1 + 5/6)X*. That's why we see slightly better than half the performance of 3X replication for reads. We have the opposite situation for writes. With 3X replication, the client sends the object to the primary, which then further sends copies over the network to two secondaries. This results in an aggregate network overhead of 3X. In the EC case, we only need to send 7/8 chunks to the secondaries (almost, but not quite, the same as the read case). For large writes, performance is actually faster. * Originally this article stated that 7/8 chunks had to be fetched for reads. The correct value is 5/6 chunks, unless fast reads are enabled. In that case it would be 7/6 chunks. Thanks to Joshua Baergen for catching this! IOPS however, are another story. For very small reads and writes, Ceph will contact all participating OSDs in a PG for that object even when the data they store isn't relevant for the operation. For instance, if you are doing 4K reads and the data you are interested in is entirely stored in a single chunk on one of the OSDs, Ceph will still fetch data from all OSDs participating in the stripe. In the summer of 2023, Clyso resurrected a PR from Xiaofei Cui that implements partial stripe reads for erasure coding to avoid this extra work. The effect is dramatic: It's not clear yet if we will be able to get this merged for Squid, though Radoslaw Zarzynski, core lead for the Ceph project, has offered to help try to get this over the finish line. Squeezing in Msgr Encryption Testing Finally, we wanted to provide the customer with a rough idea of how much msgr-level encryption would impact their cluster if they decided to use it. The adrenaline of the previous night had long faded and I was dead tired at this point. I managed to run through both 3X replication and 6+2 erasure coding tests with msgr v2 encryption enabled and compared it against our previous test results. The biggest hit is to large reads. They drop from ~1 TiB/s to around 750 GiB/s. Everything else sees a more modest, though consistent hit. At this point, I had to stop. I really wanted to do PG scaling tests and even kernel RBD tests. It was time, though, to hand the systems back to the customer for re-imaging and then to one of my excellent colleagues at Clyso for integration. Finale So what's happened with this cluster since the end of the testing? All hardware was re-imaged and the new OSDs were deployed into the customer's existing HDD cluster. Dan's upmap-remapped script is being used to control the migration process and we've migrated around 80% of the existing data to the NVMe backed OSDs. By next week, the cluster should be fully migrated to the new NVMe based nodes. We've opted not to employ all of the tuning we've done here, at least not at first. Initially, we'll make sure the cluster behaves well under the existing, mostly default, configuration. We now have a mountain of data we can use to tune the system further if the customer hits any performance issues. Since there was a ton of data and charts here, I want to recap some of the highlights. Here's an outline of the best numbers we were able to achieve on this cluster:30 OSDs (3x) 100 OSDs (3x) 320 OSDs (3x) 630 OSDs (3x) 630 OSDs (EC62) Co-Located Fio No No No Yes Yes 4MB Read 63 GiB/s 214 GiB/s 635 GiB/s 1025 GiB/s 547 GiB/s 4MB Write 15 GiB/s 46 GiB/s 133 GiB/s 270 GiB/s 387 GiB/s 4KB Rand Read 1.9M IOPS 5.8M IOPS 16.6M IOPS 25.5M IOPS 3.4M IOPS 4KB Rand Write 248K IOPS 745K IOPS 2.4M IOPS 4.9M IOPS 936K IOPS What's next? We need to figure out how to fix the laggy PG issue during writes. We can't have Ceph falling apart when the write workload scales up. Beyond that, we learned through this exercise that Ceph is perfectly capable of saturating 2x 100GbE NICs. To push the throughput envelope further we will need 200GbE+ when using 10 NVMe drives per node or more. IOPS is more nuanced. We know that PG count can have a big effect. We also know that the general OSD threading model is playing a big role. We consistently hit a wall at around 400-600K random read IOPS per node and we've seen it in multiple deployments. Part of this may be how the async msgr interfaces with the kernel and part of this may be how OSD threads wake up when new work is put into the shard queues. I've modified the OSD code in the past to achieve better results under heavy load, but at the expense of low-load latency. Ultimately, I suspect improving IOPS will take a multi-pronged approach and a rewrite of some of the OSD threading code. To my knowledge, these are the fastest single-cluster Ceph results ever published and the first time a Ceph cluster has achieved 1 TiB/s. I think Ceph is capable of quite a bit more. If you have a faster cluster out there, I encourage you to publish your results! Thank you for reading, and if you have any questions or would like to talk more about Ceph performance, please feel free to reach out. Share this article Twitter Facebook Read more articles like this ceph osd encryption throughput iops rbd benchmarks performance nvme",
    "commentLink": "https://news.ycombinator.com/item?id=39060339",
    "commentBody": "Ceph: A Journey to 1 TiB/s (ceph.io)306 points by davidmr 13 hours agohidepastfavorite134 comments amadio 4 hours agoNice article! We've also recently reached the mark of 1TB/s at CERN, but with EOS (https://cern.ch/eos), not ceph: https://www.home.cern/news/news/computing/exabyte-disk-stora... Our EOS clusters have a lot more nodes, however, and use mostly HDDs. CERN also uses ceph extensively. reply theyinwhy 2 hours agoparentGreat! What's your take on ceph? Is the idea to migrate to EOS long term? reply alberth 11 hours agoprevCeph has an interesting history. It was created at Dreamhost (DH), for their internal needs by the founders. DH was doing effectively IaaS & PaaS before those were industry coined words (VPS, managed OS/database/app-servers). They spun Ceph off and Redhat bought it. https://en.wikipedia.org/wiki/DreamHost reply artyom 9 hours agoparentYeah, as a customer (still one) I remember their \"Hey, we're going to build this Ceph thing, maybe it ends up being cool\" blog entry (or newsletter?) kinda just sharing what they were toying with. It was a time of no marketing copy and not crafting every sentence to sell you things. I think it was the university project of one of the founders, and the others jumped in supporting it. Docker has a similar origins story as far as I know. reply pas 6 hours agorootparenthttps://en.wikipedia.org/wiki/Sage_Weil right? https://ceph.com/assets/pdfs/weil-crush-sc06.pdf reply epistasis 10 hours agoparentprevA bit more to the story is that it was created also at UC Santa Cruz, by Sage Weil, a Dreamhost founder, while he was doing graduate work there. UCSC has had a lot of good storage research. reply AdamJacobMuller 9 hours agorootparentI remember the first time I deployed ceph, would have been around 2010 or 2011, had some really major issues which would nearly resulted in data loss and due to someone else not realizing what \"this cluster is experimental, do not store any important data here\" meant, the data on ceph was the only copy of the irreplaceable data in the world, loosing the data would have been fairly catastrophic for us. I ended up on the ceph IRC channel and eventually had Sage helping me fix the issues directly, helping me find bugs and writing patches to fix them in realtime. Super amazingly nice guy that he was willing to help, never once chastised me for being so stupid (even though I was), also wicked smart. reply antongribok 3 hours agorootparentprevSage is one of the nicest, down to earth, super smart individuals I've met. I've talked to him at a few OpenStack and Ceph conferences, and he's always very patient answering questions. reply dekhn 10 hours agorootparentprevthe fighting banana slugs reply stuff4ben 12 hours agoprevI used to love doing experiments like this. I was afforded that luxury as a tech lead back when I was at Cisco setting up Kubernetes on bare metal and getting to play with setting up GlusterFS and Ceph just to learn and see which was better. This was back in 2017/2018 if I recall. Good ole days. Loved this writeup! reply knicholes 11 hours agoparentI had to run a bunch of benchmarks to compare speeds of not just AWS instance types, but actual individual instances in each type, as some NVME SSDs have been more used than others in order to lube up some Aerospike response times. Crazy. reply j33zusjuice 9 hours agorootparentAd-tech, or? reply knicholes 4 hours agorootparentYeah. Serving profiles for customized ad selection. reply redrove 2 hours agoparentprevA Heketi man! I had the same experience around the same years, what a blast. Everything was so new..and broken! reply kylegalbraith 2 hours agoprevThis is a fascinating read. We run a Ceph storage cluster for persisting Docker layer cache [0]. We went from using EBS to Ceph and saw a massive difference in throughput. Went from a write throughput of 146 MB/s and 3,000 IOPS to 900 MB/s and 30,000 IOPS. The best part is that it pretty much just works. Very little babysitting with the exception of the occasional fs trim or something. It’s been a massive improvement for our caching system. [0] https://depot.dev/blog/cache-v2-faster-builds reply guywhocodes 50 minutes agoparentDid something very similar almost 10 years ago, EBS costs were 10x+ the cost for same perfomance CEPH cluster on the node disks. Eventually we switched to our own racks and cut it almost in ten again. We developed the inhouse expertise for how to do it and we were free. reply amluto 12 hours agoprevI wish someone would try to scale the nodes down. The system described here is ~300W/node for 10 disks/node, so 30W or so per disk. That’s a fair amount of overhead, and it also requires quite a lot of storage to get any redundancy at all. I bet some engineering effort could divide the whole thing by 10. Build a tiny SBC with 4 PCIe lanes for NVMe, 2x10GbE (as two SFP+ sockets), and a just-fast-enough ARM or RISC-V CPU. Perhaps an eMMC chip or SD slot for boot. This could scale down to just a few nodes, and it reduces the exposure to a single failure taking out 10 disks at a time. I bet a lot of copies of this system could fit in a 4U enclosure. Optionally the same enclosure could contain two entirely independent switches to aggregate the internal nodes. reply evanreichard 8 hours agoparentI used to run a 5 node Ceph cluster on a bunch of ODROID-HC2's [0]. Was a royal pain to get installed (armhf processor). But once it was running it worked great. Just slow with the single 1Gb NIC. Was just a learning experience at the time. [0] https://www.hardkernel.com/shop/odroid-hc2-home-cloud-two/ reply eurekin 2 hours agorootparentSame here, but on PI 4b's. 6 node cluster with a 2tb hdd and 512 Tb ssd per node. CEPH made a huge impression on me, as in I didn't recognize how extensive the package was. I went up to 122mb/s and thought it's too little for my hack-NAS replacement :) The functionality: mixing various pool types on the same set of SSD's, different redundancy types (erasure coded, replicated) was very impressive. Now I can't help but look down at a RAID NAS in comparision. Still, some extra packages like the NFS exporter were not ready for the arm architecture reply Palomides 10 hours agoparentprevhere's a weird calculation: this cluster does something vaguely like 0.8 gigabits per second per watt (1 terabyte/s * 8 bits per byte * 1024 gb per tb / 34 nodes / 300 watts a new mac mini (super efficient arm system) runs around 10 watts in interactive usage and can do 10 gigabits per second network, so maybe 1 gigabit per second per watt of data so OP's cluster, back of the envelope, is basically the same bits per second per watt that a very efficient arm system can do I don't think running tiny nodes would actually get you any more efficiency, and would probably cost more! performance per watt is quite good on powerful servers now anyway, this is all open source software running on off-the-shelf hardware, you can do it yourself for a few hundred bucks reply amluto 10 hours agorootparentI think the Mac Mini has massively more compute than needed for this kind of work. It also has a power supply, and computer power supplies are generally not amazing at low output. I’m imagining something quite specialized. Use a low frequency CPU with either vector units or even DMA engines optimized for the specific workloads needed, or go all out and arrange for data to be DMAed directly between the disk and the NIC. reply Palomides 10 hours agorootparentsounds like a DPU (mellanox bluefield for example), they're entire ARM systems with a high speed NIC all on a PCIe card, I think the bluefield ones can even directly interface over the bus to nvme drives without the host system involved reply 3abiton 10 hours agorootparentprevTrusting your maths, damn Apple did a great job on their M design. reply somat 5 hours agoparentprevI have always wanted to set up a ceph system with one drive per node. The ideal form factor would be a drive with a couple network interfaces built in. western digital had a press release about an experiment they did that was exactly this, but it never ended up with drive you could buy. The hardkernel HC2 SOC was a nearly ideal form factor for this, and I still have a stack of them laying around that I bought to make a ceph cluster, but I ran out of steam when I figured out they were 32bit. not to say it would be impossible I just never did it. reply progval 1 hour agorootparentI used to use Ceph Luminous (v12) on these, they worked fine. Unfortunately, a bug in Nautilus (v14) prevented 32-bits and 64-bits archs from talking to each other. Pacific (v16) allegedly solves this, but I didn't try it: https://ceph.com/en/news/blog/2021/v16-2-5-pacific-released/ If you want to try it with a more modern (and 64-bits) device, the hardkernel HC4 might do it for you. It's conceptually similar to the HC2 but has two drives. Unfortunately it only has double the RAM (4GB), which is probably not enough anymore. reply eurekin 28 minutes agorootparentLooks so good, wish for a > 1gbit version, since HDDs alone can saturate that reply progval 20 minutes agorootparentDid you look at their H3? It's pricier but it has two 2.5Gbits ports (along with a NVMe slot and an Intel CPU) reply kbenson 11 hours agoparentprevThere probably is a sweet spot for power to speed, but I think it's possibly a bit larger than you suggest. There's overhead from the other components as well. For example, the Mellanox NIC seems to utilize about 20W itself, and while the reduced numbers of drives might allow for a single port NIC which seems to use about half the power, if we're going to increase the number of cables (3 per 12 disks instead of 2 per 5), we're not just increasing the power usage of the nodes themselves put also possible increasing the power usage or changing the type of switch required to combine the nodes. If looked at as a whole, it appears to be more about whether you're combining resources at a low level (on the PCI bus on nodes) or a high level (in the switching infrastructure), and we should be careful not to push power (or complexity, as is often a similar goal) to a separate part of the system that is out of our immediate thoughts but still very much part of the system. Then again, sometimes parts of the system are much better at handling the complexity for certain cases, so in those cases that can be a definite win. reply booi 11 hours agoparentprevIs that a lot of overhead? The disk itself uses about 10W and high speed controllers use about 75W leaves pretty much 100W for the rest of the system including overhead of about 10%. Scale up the system to 16 disks and there’s not a lot of room for improvement reply walrus01 3 hours agoparentprev10 Gbps is increasingly obsolete with very low cost 100 Gbps switches and 100Gbps interfaces. Something would have to be really tiny and low cost to justify doing a ceph setup with 10Gbps interfaces now... If you're at that scale of very small stuff you are probably better off doing local NVME storage on each server instead. reply jeffbee 11 hours agoparentprevI think the chief source of inefficiency in this architecture would be the NVMe controller. When the operating system and the NVMe device are at arm's length, there is natural inefficiency, as the controller needs to infer the intent of the request and do its best in terms of placement and wear leveling. The new FDP (flexible data placement) features try to address this by giving the operating system more control. The best thing would be to just hoist it all up into the host operating system and present the flash, as nearly as possible, as a giant field of dumb transistors that happens to be a PCIe device. With layers of abstraction removed, the hardware unit could be something like an Atom with integrated 100gbps NICs and a proportional amount of flash to achieve the desired system parallelism. reply chx 8 hours agoprevThere was a point in history when the total amount of digital data stored worldwide reached 1TiB for the first time. It is extremely likely this day was within the last sixty years. And here we are moving that amount of data every second on the servers of a fairly random entity. We not talking of a nation state or a supranatural research effort. reply qingcharles 6 hours agoparentThat reminds me of a calculation I did which showed that my desktop PC would be more powerful than all of the computers on the planet combined in like 1978 :D reply fiddlerwoaroof 6 hours agoparentprevIt’s at least 20ish years ago: I remember an old sysadmin talking about managing petabytes before 2003 reply aspenmayer 6 hours agorootparentThose numbers seem reasonable in that context. I first started using BitTorrent around that time as well, and it wasn't uncommon to see many users long-term seeding multiple hundreds of gigabytes of Linux ISOs alone. Here’s another usage scenario with data usage numbers I found a while back. > A 2004 paper published in ACM Transactions on Programming Languages and Systems shows how Hancock code can sift calling card records, long distance calls, IP addresses and internet traffic dumps, and even track the physical movements of mobile phone customers as their signal moves from cell site to cell site. > With Hancock, \"analysts could store sufficiently precise information to enable new applications previously thought to be infeasible,\" the program authors wrote. AT&T uses Hancock code to sift 9 GB of telephone traffic data a night, according to the paper. https://web.archive.org/web/20200309221602/https://www.wired... reply fiddlerwoaroof 4 hours agorootparentYeah, at the other end of the scale, it sounds like Apple is now managing exabytes: https://read.engineerscodex.com/p/how-apple-built-icloud-to-... This is pretty mind-boggling to me. reply ComputerGuru 5 hours agorootparentprevI archived Hancock here over a decade ago, stumbled upon it via HN at the time if I’m not mistaken: https://github.com/mqudsi/hancock reply aspenmayer 4 hours agorootparentThat’s pretty cool. I remember someone on that repo from while back and was surprised to see their name pop up again. Thanks for archiving this! Corinna Cortes et al wrote the paper(s) on Hancock and also the Communities of Interest paper referenced in the Wired article I linked to. She’s apparently a pretty big deal and went on to work at Google after her prestigious work at AT&T. Hancock: A Language for Extracting Signatures from Data https://scholar.google.com/citations?view_op=view_citation&h... Hancock: A Language for Analyzing Transactional Data Streams https://scholar.google.com/citations?view_op=view_citation&h... Communities of Interest https://scholar.google.com/citations?view_op=view_citation&h... reply MPSimmons 11 hours agoprevThe worst problems I've had with in-cluster dynamic storage were never strictly IO related, and were more the storage controller software in kubernetes having problems with real-world problems like pods dying and the PVCs not attaching until after very long timeouts expired, with the pod sitting in ContainerCreating until the PVC lock was freed. This has happened in multiple clusters, using rook/ceph as well as Longhorn. reply mrb 11 hours agoprevI wanted to see how 1 TiB/s compares to the actual theoretical limits of the hardware. So here is what I found: The cluster has 68 nodes, each a Dell PowerEdge R6615 (https://www.delltechnologies.com/asset/en-us/products/server...). The R6615 configuration they run is the one with 10 U.2 drive bays. The U.2 link carries data over 4 PCIe gen4 lanes. Each PCIe lane is capable of 16 Gbit/s. The lanes have negligible ~3% overhead thanks to 128b-132b encoding. This means each U.2 link has a maximum link bandwith of 16 * 4 = 64 Gbit/s or 8 Gbyte/s. However the U.2 NVMe drives they use are Dell 15.36TB Enterprise NVMe Read Intensive AG, which appear to be capable of 7 Gbyte/s read throughput (https://www.serversupply.com/SSD%20W-TRAY/NVMe/15.36TB/DELL/...). So they are not bottlenecked by the U.2 link (8 Gbyte/s). Each node has 10 U.2 drive, so each node can do local read I/O at a maximum of 10 * 7 = 70 Gbyte/s. However each node has a network bandwith of only 200 Gbit/s (2 x 100GbE Mellanox ConnectX-6) which is only 25 Gbyte/s. This implies that remote reads are under-utilizing the drives (capable of 70 Gbyte/s). The network is the bottleneck. Assuming no additional network bottlenecks (they don't describe the network architecture), this implies the 68 nodes can provide 68 * 25 = 1700 Gbyte/s of network reads. The author benchmarked 1 TiB/s actually exactly 1025 GiB/s = 1101 Gbyte/s which is 65% of the maximum theoretical 1700 Gbyte/s. That's pretty decent, but in theory it's still possible to be doing a bit better assuming all nodes can concurrently truly saturate their 200 Gbit/s network link. Reading this whole blog post, I got the impression ceph's complexity hits the CPU pretty hard. Not compiling a module with -O2 (\"Fix Three\": linked by the author: https://bugs.launchpad.net/ubuntu/+source/ceph/+bug/1894453) can reduce performance \"up to 5x slower with some workloads\" (https://bugs.gentoo.org/733316) is pretty unexpected, for a pure I/O workload. Also what's up with OSD's threads causing excessive CPU waste grabbing the IOMMU spinlock? I agree with the conclusion that the OSD threading model is suboptimal. A relatively simple synthetic 100% read benchmark should not expose a threading contention if that part of ceph's software architecture was well designed (which is fixable, so I hope the ceph devs prioritize this.) reply magicalhippo 3 hours agoparentThey're benchmarking random IO though, and the disks can \"only\" do a bit over 1000k random 4k read IOPS, which translates to about 5 GiB/s. With 320 OSDs thats around 1.6 TiB/s. At least thats the number I could find. Not exactly tons of reviews on these enterprise NVMe disks... Still, that seems like a good match to the NICs. At this scale most workloads will likely appear as random IO at the storage layer anyway. reply mrb 1 hour agorootparentThe benchmark were they accomplish 1025 GiB/s is for sequential reads. For random reads they do 25.5M iops or ~100 GiB/s. See last table, column \"630 OSDs (3x)\". reply wmf 8 hours agoparentprevI think PCIe TLP overhead and NVMe commands account for the difference between 7 and 8 GB/s. reply mrb 8 hours agorootparentYou are probably right. Reading some old notes of mine when I was fine-tuning PCIe bandwith on my ZFS server, I had discovered back then that a PCIe Max_Payload_Size of 256 bytes limited usable bandwidth to about 74% of the link's theoretical max. I had calculated that 512 and 1024 bytes (the maximum) would raise it to respectively about 86% and 93% (but my SATA controllers didn't support a value greater than 256.) reply _zoltan_ 50 minutes agorootparentMellanox recommends setting this from the default 512 to 4096 on their NICs. reply one_buggy_boi 8 hours agoprevIs modern Ceph appropriate for transactional database storage, how is the IO latency? I'd like to move to a cheaper cfs that can compete with systems like Oracle's clustered file system or DBs backed by something like Veritas. Veritas supports multi-petabyte DBs and I haven't seen much outside of it or ocfs that similarly scales with acceptable latency reply antongribok 3 hours agoparentNot sure about putting DBs on CephFS directly, but Ceph RBD can definitely run RDBMS workloads. You need to pay attention to the kind of hardware you use, but you can definitely get Ceph down to 0.5-0.6 ms latency on block workloads doing single thread, single queue, sync 4K writes. Source, I run Ceph at work doing pretty much this. reply patrakov 2 hours agorootparentIt is important to specify which kind of latency percentile this is. Checking on a customer's cluster (made from 336 SATA SSDs in 15 servers, so not the best one in the world): 50th percentile = 1.75 ms 90th percentile = 3.15 ms 99th percentile = 9.54 ms That's with 700 MB/s of reads and 200 MB/s of writes, or approximately 7000 reads IOPS and 9000 writes IOPS. reply samcat116 8 hours agoparentprevLatency is quite poor, I wouldn't recommend running high performance database loads there. reply rafaelturk 7 hours agoprevI'm playing a lot with MicroCeph. Its aopinionated low TOS, friendly setup of Ceph. Looking forward additional comments. Planning to use it in production and replace lots of NAS servers. reply matheusmoreira 13 hours agoprevDoes anyone have experience running ceph in a home lab? Last time I looked into it, there were quite significant hardware requirements. reply nullwarp 13 hours agoparentThere still are. As someone who has done both production and homelab deployments: unless you are specifically just looking for experience with it and just setting up a demo - don't bother. When it works, it works great - when it goes wrong it's a huge headache. Edit: As just an edit, if distributed storage is just something you are interested in there are much better options for a homelab setup: - seaweedfs has been rock solid for me for years in both small and huge scales. we actually moved our production ceph setup to this. - longhorn was solid for me when i was in the k8s world - glusterfs is still fine as long as you know what you are going into. reply dataangel 12 hours agorootparentI really wish there was a benchmark comparing all of these + MinIO and S3. I'm in the market for a key value store, using S3 for now but eyeing moving to my own hardware in the future and having to do all the work to compare these is one of the major things making me procrastinate. reply rglullis 12 hours agorootparentMinio gives you \"only\" S3 object storage. I've setup a 3-node Minio cluster for object storage on Hetzner, each server having 4x10TB, for ~50€/month each. This means 80TB usable data for ~150€/month. It can be worth it if you are trying to avoid egress fees, but if I were building a data lake or anything where the data was used mostly for internal services, I'd just stick with S3. reply woopwoop24 12 hours agorootparentprevminio is good but you really need fast disks. They also really don't like, when you want to change the size of your cluster setup. No plan to add cache disks, they just say use faster disks. I have it running, goes smoothly but not really user friendly to optimize reply rglullis 12 hours agorootparentprev> glusterfs is still fine as long as you know what you are going into. Does that include storage volumes for databases? I was using glusterFS as a way to scale my swarm cluster horizontally and I am reasonably sure that it corrupted one database to the point I lost more than a few hours of data. I was quite satisfied with the setup until I hit that. I know that I am considered crazy for sticking with Docker Swarm until now, but aside from this lingering issue with how to manage stateful services, I've honestly don't feel the need to move yet to k8s. My clusters is ~10 nodes runningSingle root file system > Storage device failure tolerance > Gradual expansion capability The problem with every storage solution I've ever seen is the lack of gradual expandability. I'm not a corporation, I'm just a guy. I don't have the money to buy 200 hard disks all at once. I need to gradually expand capacity as needed. I was attracted to this ceph because it apparently allows you to throw a bunch of drives of any make and model at it and it just pools them all up without complaining. The complexity is nightmarish though. ZFS is nearly perfect but when it comes to expanding capacity it's just as bad as RAID. Expansion features seem to be just about to land for quite a few years now. I remember getting excited about it after seeing news here only for people to deflate my expectations. Btrfs has a flexible block allocator which is just what I need but... It's btrfs. reply chromatin 9 hours agorootparent> ZFS is nearly perfect but when it comes to expanding capacity it's just as bad as RAID. if you don't mind the overhead of a \"pool of mirrors\" approach [1], then it is easy to expand storage by adding pairs of disks! This is how my home NAS is configured. [1] https://jrs-s.net/2015/02/06/zfs-you-should-use-mirror-vdevs... reply roygbiv2 8 hours agorootparentThis is also exactly how mine is done. Started off with a bunch of 2TB disks. I've now got a mixture of 16TB down to 4TB, all in the original pool. reply deadbunny 7 hours agorootparentprevZFS using mirrors is extremely easy to expand. Need more space and you have small drives? Replace the drives in a mirror one by one with bigger ones. Need more space and already have huge drives? Just add another vdev mirror. And the added benefit of not living in fear of drive failure while resilvering as it is much faster with mirrors than raidX. Sure the density isn't great as you're essentially running at 50% or raw storage but - touches wood - my home zpool has been running strong for about a decade doing the above from 6x 6tb drives (3x 6tb mirrors) to 16x 10-20tb drives (8x mirrors, differing sized drives but matched per mirror like a 10tb x2 mirror, a 16tb x2 mirror etc). Edit: Just realised someone else as already mentioned a pool or mirrors. Consider this another +1. reply amadio 4 hours agorootparentprevEOS (https://cern.ch/eos, https://github.com/cern-eos/eos) is probably a bit more complicated than other solutions to setup and manage, but does allow to add/remove new disks and nodes serving data on the fly. This is essential to let us upgrade harware of the clusters serving experimental data with minimal to no downtime. reply bityard 9 hours agorootparentprevOn a single host, you could do this with LVM. Add a pair of disks, make them a RAID 1, create a physical volume on them, then a volume group, then a logical volume with XFS on top. To expand, you add a pair of disks, RAID 1 them, and add them to the LVM. It's a little stupid, but it would work. If multiple nodes are not off the table, also look into seaweedfs. Also consider how (or if) you are going to back up your hoard of data. reply matheusmoreira 8 hours agorootparent> Also consider how (or if) you are going to back up your hoard of data. I actually emailed backblaze years ago about their supposedly unlimited consumer backup plan. Asked them if they would really allow me to dump into their systems dozens of terabytes of encrypted undeduplicable data. They responded that yes, they would. Still didn't believe them, these corporations never really mean it when they say unlimited. Plus they had no Linux software. reply ianlevesque 12 hours agoparentprevI played around with it and it has a very cool web UI, object storage & file storage, but it was very hard to get decent performance and it was possible to get the metadata daemons stuck pretty easily with a small cluster. Ultimately when the fun wore off I just put zfs on a single box instead. reply victorhooi 12 hours agoparentprevI have some experience with Ceph, both for work, and with homelab-y stuff. First, bear in mind that Ceph is a distributed storage system - so the idea is that you will have multiple nodes. For learning, you can definitely virtualise it all on a single box - but you'll have a better time with discrete physical machines. Also, Ceph does prefer physical access to disks (similar to ZFS). And you do need decent networking connectivity - I think that's the main thing people think of, when they think of high hardware requirements for Ceph. Ideally 10Gbe at the minimum - although more if you want higher performance - there can be a lot of network traffic, particularly with things like backfill. (25Gbps if you can find that gear cheap for homelab - 50Gbps is a technological dead-end. 100Gbps works well). But honestly, for a homelab, a cheap mini PC or NUC with 10Gbe will work fine, and you should get acceptable performance, and it'll be good for learning. You can install Ceph directly on bare-metal, or if you want to do the homelab k8s route, you can use Rook (https://rook.io/). Hope this helps, and good luck! Let me know if you have any other questions. reply reactordev 12 hours agoparentprevThere's a blog post they did where they setup Ceph on some rPI 4's. I'd say that's not significant hardware at all. [1] [1] https://ceph.io/en/news/blog/2022/install-ceph-in-a-raspberr... reply m463 12 hours agorootparentI think \"significant\" turns out to mean the number of nodes required. reply aaronax 11 hours agoparentprevI just set up a three-node Proxmox+Ceph cluster a few weeks ago. Three Optiplex desktops 7040, 3060, and 7060 and 4x SSDs of 1TB and 2TB mix (was 5 until I noticed one of my scavenged SSDs was failed). Single 1gbps network on each so I am seeing 30-120MB/s disk performance depending on things. I think in a few months I will upgrade to 10gbps for about $400. I'm about 1/2 through the process of moving my 15 virtual machines over. It is a little slow but tolerable. Not having to decide on RAIDs or a NAS ahead of time is amazing. I can throw disks and nodes at it whenever. reply antongribok 4 hours agoparentprevI run Ceph on some Raspberry Pi 4s. It's super reliable, and with cephadm it's very easy[1] to install and maintain. My household is already 100% on Linux, so having a native network filesystem that I can just mount from any laptop is very handy. Works great over Tailscale too, so I don't even have to be at home. [1] I run a large install of Ceph at work, so \"easy\" might be a bit relative. reply dcplaya 4 hours agorootparentWhat are your speeds? Do you rub ceph FS too? I'm trying to do similar. reply antongribok 4 hours agorootparentIt's been a while since I've done some benchmarks, but it can definitely do 40MB/s sustained writes, which is very good given the single 1GbE links on each node, and 5TB SMR drives. Latency is hilariously terrible though. It's funny to open a text file over the network in vi, paste a long blob of text and watch it sync that line by line over the network. If by \"rub\" you mean scrub, then yes, although I increased the scrub intervals. There's no need to scrub everything every week. reply mcronce 11 hours agoparentprevI run Ceph in my lab. It's pretty heavy on CPU, but it works well as long as you're willing to spring for fast networking (at least 10Gb, ideally 40+) and at least a few nodes with 6+ disks each if you're using spinners. You can probably get away with far fewer disks per node if you're going all-SSD. reply chomp 12 hours agoparentprevI’ve ran Ceph in my home lab since Jewel (~8 years ago). Currently up to 70TB storage on a single node. Have been pretty successful vertically scaling, but will have to add a 2nd node here in a bit. Ceph isn’t the fastest, but it’s incredibly resilient and scalable. Haven’t needed any crazy hardware requirements, just ram and an i7. reply sgarland 10 hours agoparentprevYes. I first tried it with Rook, and that was a disaster, so I shifted to Longhorn. That has had its own share of problems, and is quite slow. Finally, I let Proxmox manage Ceph for me, and it’s been a dream. So far I haven’t migrated my K8s workloads to it, but I’ve used it for RDBMS storage (DBs in VMs), and it works flawlessly. I don’t have an incredibly great setup, either: 3x Dell R620s (Ivy Bridge-era Xeons), and 1GBe. Proxmox’s corosync has a dedicated switch, but that’s about it. The disks are nice to be fair - Samsung PM863 3.84 TB NVMe. They are absolutely bottlenecked by the LAN at the moment. I plan on upgrading to 10GBe as soon as I can convince myself to pay for an L3 10G switch. reply sixdonuts 5 hours agorootparentJust get a 25G switch and MM fiber. 25G switches are cheaper, use less power and can work with 10 and 25G SFPs. reply mikecoles 7 hours agoparentprevWorks great, depending on what you want to do. Running on SBCs or computers with cheap sata cards will greatly reduce the performance. It's been running well for years after I found out the issues regarding SMR drives and the SATA card bottlenecks. 45Drives has a homelab setup if you're looking for a canned solution. reply willglynn 12 hours agoparentprevThe hardware minimums are real, and the complexity floor is significant. Do not deploy Ceph unless you mean it. I started considering alternatives when my NAS crossed 100 TB of HDDs, and when a scary scrub prompted me to replace all the HDDs, I finally pulled the trigger. (ZFS resilvered everything fine, but replacing every disk sequentially gave me a lot of time to think.) Today I have far more HDD capacity and a few hundred terabytes of NVMe, and despite its challenges, I wouldn't dare run anything like it without Ceph. reply samcat116 8 hours agorootparentCan I ask what you use all that storage for on your NAS? reply mmerlin 10 hours agoparentprevProxmox makes Ceph easy, even with just one single server if you are homelabbing... I had 4 NUCs running Proxmox+Ceph for a few years, and apart from slightly annoying slowness syncing after spinning the machines up from cold start, it all ran very smoothly. reply bluedino 12 hours agoparentprevRelated question, how does someone get into working with Ceph? Other than working somewhere that already uses it. reply hathawsh 9 hours agorootparentThe recommended way to set up Ceph is cephadm, a single-file Python script that is a multi-tool for both creating and administering clusters. https://docs.ceph.com/en/latest/cephadm/ To learn about Ceph, I recommend you create at least 3 KVM virtual machines (using virt-manager) on a development box, network them together, and use cephadm to set up a cluster between the VMs. The RAM and storage requirements aren't huge (Ceph can run on Raspberry Pis, after all) and I find it a lot easier to figure things out when I have a desktop window for every node. I recently set up Ceph twice. Now that Ceph (specifically RBD) is providing the storage for virtual machines, I can live-migrate VMs between hosts and reboot hosts (with zero guest downtime) anytime I need. I'm impressed with how well it works. reply SteveNuts 12 hours agorootparentprevYou could start by installing Proxmox on old machines you have, it uses Ceph for its distributed storage, if you choose to use it. reply candiddevmike 12 hours agorootparentprevLook into the Rook project reply loeg 12 hours agoparentprevWhy would you bother with a distributed filesystem when you don't have to? reply imiric 12 hours agorootparentFor the same reason you would use one in enterprise deployments: if setup properly, it's easier to scale. You don't need to invest in a huge storage server upfront, but could build it out as needed with cheap nodes. Assuming it works painlessly as a single node filesystem, of which I'm not yet convinced if the existing solutions do. reply loeg 10 hours agorootparent> if setup properly, it's easier to scale For home use/needs, I think vertical scaling is much easier. reply imiric 18 minutes agorootparentNot really. Most consumer motherboards have a limited number of SATA ports, and server hardware is more expensive, noisy and requires a lot of space. Consumers usually go with branded NAS appliances, which are also expensive and limited at scaling. Setting up a cluster of small heterogeneous nodes is cheaper, more flexible, and can easily be scaled as needed, _assuming_ that the distributed storage software is easy to work with and trouble-free. This last part is what makes it difficult to setup and maintain, but if the software is stable, I would prefer this approach for home use. reply m463 11 hours agorootparentprevlol, wrong place to ask questions of such practicality. that said, I played with virtualization and I didn't need to. but then I retired a machine or two and it has been very helpful. And I used to just use physical disks and partitions. But with the VMs I started using volume manager. It became easier to grow and shrink storage. and... well, now a lot of this is second nature. I can spin up a new \"machine\" for a project and it doesn't affect anything else. I have better backups. I can move a virtual machine. yeah, there are extra layers of abstraction but hey. reply iwontberude 12 hours agorootparentprevIt's cool to cluster everything for some people (myself included). I see it more like a design constraint than a pure benefit. reply erulabs 11 hours agorootparentprevSo that when you do have to, you know how to do it. reply loeg 9 hours agorootparentI think most of us will go our whole lives never having to deploy Ceph, especially at home. reply erulabs 6 hours agorootparentYou’re absolutely not wrong - but asking a devops engineer why they over engineered their home cluster is sort of like asking a mechanic “why is your car so fast? Couldn’t you just take the bus?” reply matheusmoreira 9 hours agorootparentprevI'm indifferent towards the distributed nature thing. What I want is ceph's ability to pool any combination of drives of any make, model and capacity into organized redundant fault tolerant storage, and its ability to add arbitrary drives to that pool at any point in the system's lifetime. RAID-like solutions require identical drives and can't be easily expanded. reply m463 12 hours agoparentprevI think you need 3 or was it 5 machines? proxmox will use it - just click to install reply louwrentius 10 hours agoparentprevIf you want decent performance, you need a lot of OSDs especially if you use HDD. But a lot of consumer SDDs will suffer terrible performance degradation with writes depending on the circumstances and workloads. reply nghnam 6 hours agoprevMy old company ran public and private cloud with Openstack and Ceph. We had 20 Supermicro (24 disks per server) storage nodes and total capacity was 3PB. We learnt some experiences, especially a flapping disk made whole system performance degraded. Solution was removing bad sector disk as soon as possible. reply brobinson 4 hours agoprevI'm curious what the performance difference would be on a modern kernel. reply hinkley 6 hours agoprevSure would be nice if you defined some acronyms. reply louwrentius 10 hours agoprevRemember, random IOPs without latency is a meaningless figure. reply einpoklum 11 hours agoprevWhere can I read about the rationale for ceph as a project? I'm not familiar with it. reply jacobwg 10 hours agoparentNot sure how common the use-case is, but we're using Ceph to effectively roll our own EBS inside AWS on top of i3en EC2 instances. For us it's about 30% cheaper than the base EBS cost, but provides access to 10x the IOPS of base gp3 volumes. The downside is durability and operations - we have to keep Ceph alive and are responsible for making sure the data is persistent. That said, we're storing cache from container builds, so in the worst-case where we lose the storage cluster, we can run builds without cache while we restore. reply jseutter 10 hours agoparentprevhttp://www.45drives.com/blog/ceph/what-is-ceph-why-our-custo... is a pretty good introduction. Basically you can take off-the-shelf hardware and keep expanding your storage cluster and ceph will scale fairly linearly up through hundreds of nodes. It is seeing quite a bit of use in things like Kubernetes and OpenShift as a cheap and cheerful alternative to SANs. It is not without complexity, so if you don't know you need it, it's probably not worth the hassle. reply peter_d_sherman 9 hours agoprevCeph is interesting... open source software whose only purpose is to implement a distributed file system... Functionally, Linux implements a file system (well, several!) as well (in addition to many other OS features) -- but (usually!) only on top of local hardware. There seems to be some missing software here -- if we examine these two paradigms side-by-side. For example, what if I want a Linux (or more broadly, a general OS) -- but one that doesn't manage a local file system or local storage at all? One that operates solely using the network, solely using a distributed file system that Ceph, or software like Ceph, would provide? Conversely, what if I don't want to run a full OS on a network machine, a network node that manages its own local storage? The only thing I can think of to solve those types of problems -- is: What if the Linux filesystem was written such that it was a completely separate piece of software, and a distributed file system like Ceph, and not dependent on the other kernel source code (although, still complilable into the kernel as most linux components normally are)... A lot of work? Probably! But there seems to be some software need for something between a solely distributed file system as Ceph is, and a completely monolithic \"everything baked in\" (but not distributed!) OS/kernel as Linux is... Note that I am just thinking aloud here -- I probably am wrong and/or misinformed on one or more fronts! So, kindly take this random \"thinking aloud\" post -- with the proverbial \"grain of salt!\" :-) reply wmf 8 hours agoparentwhat if I want a Linux ... that doesn't manage a local file system or local storage at all [but] operates solely using the network, solely using a distributed file system Linux can boot from NFS although that's kind of lost knowledge. Booting from CephFS might even be possible if you put the right parts in the initrd. reply lmz 7 hours agorootparentNFS root docs here https://www.kernel.org/doc/Documentation/filesystems/nfs/nfs... reply peter_d_sherman 3 hours agorootparentNFS is an excellent point! NFS (now that I think about it!) -- brings up two additional software engineering considerations: 1) Distributed file system protocol. 2) Software that implements that distributed (or at least remote/network) file system -- via that file system protocol. NFS is both. That's not a bad thing(!) -- but ideally from a software engineering \"separation of concerns\" perspective, this future software layer/level would ideally be decoupled from the underlying protocol -- that is, it might have a \"plug-in\" protocol architecture, where various 3rd party file system protocols (somewhat analogous to drivers) could be \"plugged-in\"... But NFS could definitely be used to boot/run Linux over the network, and is definitely a step in the right direction, and something worth evaluating for these purposes... its source code is definitely worth looking at... So, an excellent point! reply riku_iki 13 hours agoprev [–] What router/switch one would use for such speed? reply NavinF 12 hours agoparentLinked article says they used 68 machines with 2 x 100GbE Mellanox ConnectX-6 cards. So any 100G pizza box switches should work. Note that 36 port 56G switches are dirt cheap on eBay and 4tbps is good enough for most homelab use cases reply riku_iki 12 hours agorootparent> So any 100G pizza box switches should work. but will it be able to handle combined TB/s traffic? reply aaronax 12 hours agorootparentYes. Most network switches can handle all ports at 100% utilization in both directions simultaneously. Take for example the Mellanox SX6790 available for less than $100 on eBay. It has 36 56gbps ports. 36 * 2 * 56 = 4032gbps and it is stated to have a switching capacity of 4.032Tbps. Edit: I guess you are asking how one would possibly sip 1TiB/s of data into a given client. You would need multiple clients spread across several switches to generate such load. Or maybe some freaky link aggregation. 10x 800gbps links for your client, plus at least 10x 800gbps links out to the servers. reply baq 12 hours agorootparentprevany switch which can't handle full load on all ports isn't worthy of the name 'switch', it's more like 'toy network appliance' reply birdman3131 12 hours agorootparentI will forever be scarred by the \"Gigabit\" switches of old that were 2 gigabit ports and 22 100mb ports. Coworker bought it missing the nuance. reply bombcar 12 hours agorootparentStill happens, gotta see if the top speed mentioned is an uplink or normal ports. reply bombcar 12 hours agorootparentprevEven the bargain Mikrotik can do 1.2Tbps https://mikrotik.com/product/crs518_16xs_2xq reply margalabargala 12 hours agorootparentFor those curious, a \"bargain\" on a 100gbps switch means about $1350 reply epistasis 11 hours agorootparentOn a cluster with more than $1M of NVMe disks, that does actually seem like a bargain. (Note that the linked MikroTik switch only has 100gbe on a few ports, and wouldn't really classify as a full 100gbe switch to most people) reply margalabargala 11 hours agorootparentSure- I don't mean to imply that it isn't. I can absolutely see how that's inexpensive for 100gbe equipment. That was more for the benefit of others like myself, who were wondering if \"bargain\" was comparative, or inexpensive enough that it might be worth buying one next time they upgraded switches. For me personally it's still an order of magnitude away from that. reply bombcar 10 hours agorootparenthttps://mikrotik.com/product/crs305_1g_4s_in is the sweet spot right now for home users. Four 10g ports and a 1g, you can use the 1g for “uplink” to the internet and one of the 10g for your “big old Nortel gigabit switch with 10g uplink” and one for your Mac and two for your NAS and VM server. ;) Direct cables are moderately cheap, and modules for 10g Ethernet aren’t insanely expensive. reply Palomides 10 hours agorootparentprevthere's usually some used dx010 (32x100gbe) on ebay for less than $500 the cheapest new 100gbe switch I know of is the mikrotik CRS504-4XQ-IN (4x100gbe, around $650) reply riku_iki 12 hours agorootparentprevTB != Tb.. reply epistasis 12 hours agoparentprevGiven their configuration of just 4U spread across 17 racks, there's likely a bunch of compute in the rest of the rack, and 1-2 top of rack switches like this: https://www.qct.io/product/index/Switch/Ethernet-Switch/T700... And then you connect the TOR switches to higher level switches in something like a Clos distribution to get the desired bandwidth between any two nodes: https://www.techtarget.com/searchnetworking/definition/Clos-... reply KeplerBoy 13 hours agoparentprev [–] 800Gbps via OSFP and QSFP-DD are already a thing. Multiple vendors have NICs and switches for that. reply _zoltan_ 12 hours agorootparentcan you show me a 800G NIC? the switch is fine, I'm buying 64x800G switches, but NIC wise I'm limited to 400Gbit. reply KeplerBoy 11 hours agorootparentfair enough, it seems I was mistaken about the NIC. I guess that has to wait for PCIe 6 and should arrive soon-ish. reply CyberDildonics 11 hours agorootparentprev [–] 16x PCIe 4.0 is 32GB/s 16x PCIe 5.0 should be 64 GB/s, how is any computer using 100 GB/s ? reply KeplerBoy 11 hours agorootparent [–] I was talking about Gigabit/s, not Gigabyte/s. The article however actually talks about Terabyte/s scale, albeit not over a single node. reply CyberDildonics 10 hours agorootparent [–] 800 gigabits is 100 gigabytes which is still more than PCIe 5.0 16x 64 gigabyte per second bandwidth. You said there were 800 gigabit network cards, I'm wondering how that much bandwidth makes it to the card in the first place. The article however actually talks about Terabyte/s scale, albeit not over a single node. This does not have anything to do with what you originally said, you were talking about 800gb single ports. reply NavinF 9 hours agorootparentI'm not aware of any 800G cards, but FYI a single Mellanox card can use two PCIe x16 slots to avoid NUMA issues on dual-socket servers: https://www.nvidia.com/en-us/networking/ethernet/socket-dire... So the software infra for using multiple slots already exists and doesn't require any special config. Oh and some cards can use PCIe slots across multiple hosts. No idea why you'd want to do that, but you can. reply KeplerBoy 10 hours agorootparentprev [–] Yes, apparently I was mistaken about the NICs. They don't seem to be available yet. But it's not a PCIe limitation. There are PCIe devices out there which use 32 lanes, so you could achieve the bandwidth even on PCIe5. https://www.servethehome.com/ocp-nic-3-0-form-factors-quick-... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their experience building and testing a 10 petabyte NVMe deployment for a company transitioning from an HDD backed Ceph cluster.",
      "The new configuration includes smaller nodes with faster memory throughput, more CPU resources, and greater network throughput.",
      "Performance testing revealed issues with inconsistent results and performance drops, potentially due to kernel-side issues and incorrect compile flags, but impressive results were achieved after resolving an outage and conducting additional testing."
    ],
    "commentSummary": [
      "Users are discussing their experiences and opinions on using Ceph, a software-defined storage solution, on different hardware setups.",
      "The conversation includes discussions on the performance, complexity, and suitability of Ceph in various environments, including home and professional settings.",
      "Other storage solutions like EOS, glusterfs, and ZFS, as well as networking equipment and capabilities, are also mentioned in the discussion."
    ],
    "points": 306,
    "commentCount": 135,
    "retryCount": 0,
    "time": 1705694575
  },
  {
    "id": 39054671,
    "title": "Turning an Old SNES Controller into a USB Gamepad with Arduino",
    "originLink": "https://blog.chybby.com/posts/building-a-usb-snes-controller",
    "originBody": "Building a USB SNES Controller Tue Jan 16 2024 · Dome A few years ago on a trip to Tokyo, we took a day to explore Akihabara. We found a shop that was selling retro gaming stuff and when I saw an old SNES controller for sale I had to buy it. Playing the SNES was one of my favourite things as a kid and Secret of Mana remains one of my favourite games to this day. Of course, I didn’t have a SNES console anymore so when we returned back home I decided it would be a fun project to modernize the SNES controller so I could plug it straight into my PC via USB. SNES Controller Hardware The first step was to figure out how the SNES controller hardware reported which buttons were being pressed. After a bit of Googling I found this document describing the hardware. Luckily I now have another unmodified SNES controller so I can take some pictures of the original hardware. The plug of the unmodified SNES controller. The pins of the plug from left to right are: Pin Purpose Internal Wire Colour 1 +5v power line White 2 Data clock Yellow 3 Data latch Orange 4 Serial data Red 5, 6 Nothing No wire 7 Ground Brown Inside the unmodified SNES controller. Pins 2 and 3 are driven by the console and begin high and low respectively. Pin 4 is driven by the controller. The document above also described the process the SNES console used to read which buttons of the controller were pressed. The gist is: Send a 12us high pulse on pin 3. Wait 6us. If pin 4 is low, the B button is pressed. Send a 6us low pulse followed by a 6us high pulse on pin 2. Repeat the previous 2 steps for all of the remaining buttons in order (Y, Select, Start, Up, Down, Left, Right, A, X, L, R) and then 4 extra times with no corresponding button. Repeat the whole process every 16.667ms (60Hz) Programming the Arduino Next I needed something that could perform the above steps and relay the result to the connected computer. I decided on a tiny board based on the ATmega32u4 chip as it was small enough to fit inside the controller and could power the controller at the right voltage. I connected the wires inside the SNES controller to the pins of the board: SNES Controller Wire Arduino Pin White VCC Brown GND Yellow 14 Orange 15 Red 16 The board installed in the modified SNES controller. Coding up the button scanning process on the Arduino looks like this: #define CLOCK_PIN 14 #define LATCH_PIN 15 #define DATA_PIN 16 const uint8_t num_buttons = 16; void setup() { pinMode(CLOCK_PIN, OUTPUT); pinMode(LATCH_PIN, OUTPUT); pinMode(DATA_PIN, INPUT); digitalWrite(CLOCK_PIN, HIGH); } void loop() { // Collect button state info from controller. // Send data latch. digitalWrite(LATCH_PIN, HIGH); delayMicroseconds(12); digitalWrite(LATCH_PIN, LOW); delayMicroseconds(6); bool button_states[num_buttons]; for (uint8_t id = 0; id#define SNES_BUTTON_B 0 #define SNES_BUTTON_Y 1 #define SNES_BUTTON_SELECT 2 #define SNES_BUTTON_START 3 #define SNES_BUTTON_UP 4 #define SNES_BUTTON_DOWN 5 #define SNES_BUTTON_LEFT 6 #define SNES_BUTTON_RIGHT 7 #define SNES_BUTTON_A 8 #define SNES_BUTTON_X 9 #define SNES_BUTTON_L 10 #define SNES_BUTTON_R 11 #define SNES_BUTTON_UNDEF_1 12 #define SNES_BUTTON_UNDEF_2 13 #define SNES_BUTTON_UNDEF_3 14 #define SNES_BUTTON_UNDEF_4 15 // Map SNES buttons to HID joypad buttons. const uint8_t snes_id_to_hid_id[] = { 2, 4, 7, 8, 0, 0, 0, 0, 1, 3, 5, 6, 10, 11, 12, 13 }; I’m not sure why I chose this mapping or if it matters how the buttons map beween the SNES and the HID gamepad buttons, but I’m sure I had a good reason for this mapping at the time. In the setup function I needed to initialize the library: Gamepad.begin(); After every button scan cycle I updated the library’s state based on the values in the button_states array (with some special logic for the D-pad) then reported those values to the computer with Gamepad.write(): // Report button states over HID. void reportButtons(bool button_states[num_buttons]) { // D-Pad. int8_t dpad_status = GAMEPAD_DPAD_CENTERED; if (button_states[SNES_BUTTON_UP]) { dpad_status = GAMEPAD_DPAD_UP; if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_UP_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_UP_RIGHT; } } else if (button_states[SNES_BUTTON_DOWN]) { dpad_status = GAMEPAD_DPAD_DOWN; if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_DOWN_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_DOWN_RIGHT; } } else if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_RIGHT; } Gamepad.dPad1(dpad_status); Gamepad.dPad2(dpad_status); for (uint8_t snes_id = 0; snes_id = 4 && snes_id#define CLOCK_PIN 14 #define LATCH_PIN 15 #define DATA_PIN 16 #define SNES_BUTTON_B 0 #define SNES_BUTTON_Y 1 #define SNES_BUTTON_SELECT 2 #define SNES_BUTTON_START 3 #define SNES_BUTTON_UP 4 #define SNES_BUTTON_DOWN 5 #define SNES_BUTTON_LEFT 6 #define SNES_BUTTON_RIGHT 7 #define SNES_BUTTON_A 8 #define SNES_BUTTON_X 9 #define SNES_BUTTON_L 10 #define SNES_BUTTON_R 11 #define SNES_BUTTON_UNDEF_1 12 #define SNES_BUTTON_UNDEF_2 13 #define SNES_BUTTON_UNDEF_3 14 #define SNES_BUTTON_UNDEF_4 15 const uint8_t num_buttons = 16; // Map SNES buttons to HID joypad buttons. const uint8_t snes_id_to_hid_id[] = { 2, 4, 7, 8, 0, 0, 0, 0, 1, 3, 5, 6, 10, 11, 12, 13 }; void setup() { Gamepad.begin(); pinMode(CLOCK_PIN, OUTPUT); pinMode(LATCH_PIN, OUTPUT); pinMode(DATA_PIN, INPUT); digitalWrite(CLOCK_PIN, HIGH); } // Report button states over HID. void reportButtons(bool button_states[num_buttons]) { // D-Pad. int8_t dpad_status = GAMEPAD_DPAD_CENTERED; if (button_states[SNES_BUTTON_UP]) { dpad_status = GAMEPAD_DPAD_UP; if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_UP_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_UP_RIGHT; } } else if (button_states[SNES_BUTTON_DOWN]) { dpad_status = GAMEPAD_DPAD_DOWN; if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_DOWN_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_DOWN_RIGHT; } } else if (button_states[SNES_BUTTON_LEFT]) { dpad_status = GAMEPAD_DPAD_LEFT; } else if (button_states[SNES_BUTTON_RIGHT]) { dpad_status = GAMEPAD_DPAD_RIGHT; } Gamepad.dPad1(dpad_status); Gamepad.dPad2(dpad_status); for (uint8_t snes_id = 0; snes_id = 4 && snes_id <= 7) { // D-Pad. continue; } if (button_states[snes_id]) { Gamepad.press(snes_id_to_hid_id[snes_id]); } else { Gamepad.release(snes_id_to_hid_id[snes_id]); } } } void loop() { // Collect button state info from controller. // Send data latch. digitalWrite(LATCH_PIN, HIGH); delayMicroseconds(12); digitalWrite(LATCH_PIN, LOW); delayMicroseconds(6); bool button_states[num_buttons]; for (uint8_t id = 0; id < num_buttons; id++) { // Sample the button state. int button_pressed = digitalRead(DATA_PIN) == LOW; button_states[id] = button_pressed; digitalWrite(CLOCK_PIN, LOW); delayMicroseconds(6); digitalWrite(CLOCK_PIN, HIGH); delayMicroseconds(6); } // Update HID button states. reportButtons(button_states); Gamepad.write(); delay(16); } #arduino#hardware#games",
    "commentLink": "https://news.ycombinator.com/item?id=39054671",
    "commentBody": "Building a USB SNES Controller (chybby.com)279 points by chybby 21 hours agohidepastfavorite91 comments allenu 13 hours agoControllers are surprisingly super easy to work with and a good gateway to some basic electronics hacking. I've actually gone the opposite direction from this post. I have a Neo Geo arcade board (JAMMA) and it has plugs for Neo Geo controllers (as in the controllers for the console version of the Neo Geo). I wanted to use the Neo Geo without plugging it into an arcade cabinet, so I got a \"Supergun\" board to play it on an RGB monitor. However, I didn't have a controller for it. I noticed that there was an emulator-based \"Neo Geo X\" system out in the wild and you could purchase a controller accessory on its own, so I got one, not realizing it was purely a USB controller in the shape of the original Neo Geo ones, but no problem. I bought a Neo Geo controller cable and just desoldered the button to USB connections inside the controller and connected them directly to the Neo Geo controller cable. Worked like a charm! reply vikingerik 13 hours agoparentAnd I'll add my controller hacking as well: https://imgur.com/a/Mu43dqg As a poor college student, I home-built a dance pad for Dance Dance Revolution, out of wood and foil and by soldering the connections into a controller. Worked perfectly! reply rahimnathwani 12 hours agorootparentI love this. It probably worked better than a cheap 'soft' pad. reply RockRobotRock 9 hours agorootparentYes! Soft pads are the worst. reply allenu 13 hours agorootparentprevWell done and good job using what looks like a cheap controller and aluminum foil to keep costs down. :) reply qiqitori 7 hours agoparentprevA while ago I was a little into controller hardware hacking and did almost the same thing but for an MSX! Even wrote a blog entry, but unfortunately in Japanese (with pictures though): https://blog.qiqitori.com/2022/09/%E6%9D%90%E6%96%99%E8%B2%B... And one year later I also used a Raspberry Pi Pico to convert a USB controller's signals to MSX: https://blog.qiqitori.com/2023/09/using-a-usb-hid-game-contr... (And later, USB controller to Nintendo Switch, https://blog.qiqitori.com/2023/09/playing-on-the-nintendo-sw...) reply ansible 12 hours agoparentprevYes. I got my start, back in the day, following along a magazine article on modifying an Atari 2600 joystick for use with the Tandy Color computer. Worked fairly well too, though I ended up modifying my Galaxian arcade game clone to work with it. reply crote 18 hours agoprevLooking at the described protocol it seems the SNES controller uses a simple 16-bit parallel-in-serial-out shift register - and a quick Google confirmed that. This means the timing is almost certainly quite loose, and there's a pretty decent chance you might even be able to poll it as the 1kHz \"needed\" for \"serious\" gaming. And it'd be pretty trivial to offload the readout to the MCU's SPI peripheral. reply toasteros 18 hours agoparentIt's extremely loose! Using a custom PCB to connect the controller over RJ45 to a custom Pi hat I wrote some code to simply display the button presses on screen, to test the functionality of the controller (we are modifying hundreds). I had to play around a lot with the timings to match up the response of the program with the speed of my finger pushing a button, else the program would return \"you pushed B\" a dozen times on a single push. I do wonder how much original SNES devs had to consider similar scenarios. reply 65a 17 hours agorootparentThe physical switches may actually bounce, so you might need some debounce logic, if it wasn't the shift register glitching out. It's pretty common for buttons to need this, often seen in keyboard firmware as well for similar reasons, the physical mechanism actually will oscillate a bit between states. reply snitty 14 hours agorootparentThe way the NES and SNES work is that once per frame you read from the memory address mapped to the shift register to get all the bits out, one at a time. For certain inputs you only care if it's pressed now. Others you compare to previous state to see if it changed. Bounce could, theoretically, cause an input to be read as a non-input if it just bounced at exactly the wrong time, but it won't cause multiple inputs, as it's only polled every 1/60th of a second. reply 65a 8 hours agorootparentYes, it sounds like SNES implements debounce by just scanning slowly, but if you want to feed USB reports at maximum (or above maximum) specification, you will want to check the state more frequently, and you'll need an alternate mitigation for switch bounce. reply snitty 14 hours agorootparentprevWere you checking to see if the button state changed between reads? Or were you reading a 1 as \"down\" regardless of whether the previous read was \"up\"? reply chybby 5 hours agoparentprevThanks for teaching me about SPI, I might have a play around and see if I can get that working. reply 65a 17 hours agoparentprevI converted a DOS-era joystick like this, and the shift registers inside were stable at higher speeds, I don't remember needing to care about the timing much. I may have just run the clock in a for-loop during the polling loop. reply pipes 1 hour agoprevNot sure if this has been mentioned already: https://github.com/MickGyver/DaemonBite-Retro-Controllers-US... It's how to build your own demon bite adapters using Arduino, for various console. These are super low lag. If you Google demon bite you can find various sites selling premade adapters. These are really popular with mister fpga users: https://en.m.wikipedia.org/wiki/MiSTer This is a bit of a rabbit hole, the mister is the best retro related thing I've bought / built. Here's a useful listing of various usb adapters and their latency: https://rpubs.com/misteraddons/inputlatency reply xg15 17 hours agoprevThis is really cool! One thing I'm wondering is how the SNES implemented its Multitap support[1] with such a simple \"wire protocol\". Could it be that the two missing wires and/or 4 unused slots in the polling cycle are used for some kind of adressing scheme when a multitap is plugged in? https://nintendo.fandom.com/wiki/Super_Multitap reply ooterness 17 hours agoparentRGMX has a video series on a lot of the low-level SNES functions. If you've ever wanted to know how Mode-7 works, it's great. The video below goes over the controllers, Super Scope, mouse, etc. A brief discussion of the multi-tap starts around 16:00. You are correct that it leverages the spare pins. https://www.youtube.com/watch?v=2Dw7NFm1ZfY reply dougg3 3 hours agoparentprevThe schematics for the multitap are out there in the SNES developer manual [1]. I actually made one on a breadboard for fun [2] and eventually turned it into a PCB. It's a pretty simple circuit with an analog mux and some tri-state buffers. [1] https://archive.org/details/SNESDevManual/book2/page/n385/mo... [2] https://www.downtowndougbrown.com/2013/04/homebrew-snes-4-pl... reply wharvle 17 hours agoparentprevThe NES also had “multitaps”. One model was wired (the “Four Score”), the other was wireless (battery powered; the “Satellite”) with an IR receiver unit that plugged into both controller ports. The IR wireless one was, in my experience (it was the only one I had) far less janky and failure-prone than one might suppose. Actually worked quite well. reply patrickpkt 17 hours agoprevThe Daemonbite project (https://github.com/MickGyver/DaemonBite-Retro-Controllers-US...) does essentially the same thing, but works like a normal USB controller from the perspective of the host. I've used one with a MiSTer FPGA setup and it's almost indistinguishable from a native SNES controller in terms of response. For my build, I cut a cheap controller extension cord in half, avoiding the need to actually modify the controller itself. reply makapuf 11 hours agoprevI think the project is cool, but since a usb snes controller is, what 5$ on ebay (or more to have quality one), I find it too bad that you damage a working, vintage real snes controller that there will be less and less of. reply chybby 6 hours agoparentThe way I saw it, I'd rather have a memento of the past that I can actually use than one that will sit around in a drawer. reply MarioMan 3 hours agoprevI prefer a nondestructive approach. I set up an ATTINY85 clone to serve as a DIY USB adapter. Just solder a controller extension cable to the microcontroller to donate the right port, and you have everything you need. You have enough GPIO pins and the requisite 5v logic to make it a great fit. Mine was made for NES controllers, but it uses the same shift logic as the SNES controller, just with fewer buttons. reply kilpikaarna 19 hours agoprevI've tried building an arcade stick in the past by having the Arduino emulate a keyboard and doing standard Arduino lib digitalRead of the buttons and sending keypresses (for MAME) over USB. It worked, but the lag was terrible. I wonder if this fares any better. In any case, if you can handle the wait, you can get a knockoff SNES USB pad from China for a few bucks. The plastic will feel way off, but you can probably swap over the shell from your original pad with little effort. And you'll get fresh rubber button pads, rather than 30 year old spongy ones, as a bonus. :) reply frameset 18 hours agoparentIf you're making a home made arcade stick, check out the GP2040-CE project - https://github.com/OpenStickCommunity/GP2040-CE It's got low latency and good compatibility for a bunch of platforms. Even some compatibility for PS4. reply Grazester 19 hours agoprevBefore the existence of Blue Retro or any commerically available adapter, I wanted to use Playstation 4 Dual Shock wireless controllers with my Sega Saturn as an analog controller. I used the Arduino USB Shield Adapter since that supported wireless Dual Shock controller and all I needed to handle was the Saturn side of things with emulating a controller protocol so the Saturn things it had a 3D controller plugged into it. This was my introduction to Arduino programming, bitmasks and direct port manipulation. I have changed the recently to not use direct port manipulation since it really isn't need for the Saturn and I wanted to make the code more portable. I have since made a wireless for the official 3D controllers for the Saturn with no noticeable latency. Something it seems is still taking others a while to figure out it. I am not doing anything fancy so I don't know how they can't figure that out yet. They are using Blue Retro though where as I am just using an nRF24L01. So maybe the Blue Retro is adding some unnecessary over head. This i have not released the source for though. reply jareklupinski 18 hours agoprevmy very first electronics projects were classic controller to USB conversions. I remember struggling with PIC after just wrapping my head around BASIC Stamps, and trying to follow raphnet tutorials https://www.raphnet.net/electronique/multiuse_tiny1/index_en... going to show this article when people ask 'how do i get started with a fun electronics project' :) reply chybby 5 hours agoparentThank you! Glad you liked it :) reply candiddevmike 20 hours agoprevTitle should say converting a SNES controller to USB. I was thinking there would be 3D printing involved. reply spintin 19 hours agoprevWhen Toys'r Us folded in EU I bough a ton of NES Mini/Classic I2C controllers, paired with https://www.raphnet-tech.com/products/wusbmote_1player_adapt... you have the same thing but brand new. Too bad all controllers are sold out. reply bonzini 19 hours agoparentI did the same but went for an ESP-8266 to connect over WiFi (using UDP). https://github.com/bonzini/wcc contains both the Arduino sketch and the client that runs under Linux to present a virtual input device. reply kalium-xyz 11 hours agoprevIve done this with the attiny85 based digisparks for various controllers. Can recommend. It has very little IO though which can be an issue reply mfonda 18 hours agoprevThis brings back memories. The first (and only) hardware project I've ever done is building a 4-controller multitap that connected via parallel port. It ended up working really well--lots of fun playing games on snes9x with friends. reply snerbles 19 hours agoprevThis reminds me, years back I picked up an NTT Data Super Famicom Controller [0] with the idea of adapting it to USB. An off-the shelf USB converter only handled the standard SNES/SFC buttons and completely ignored the number pad. At the time few resources even mentioned the existence of this thing, so I put it on the shelf and promptly forgot about it for other projects. [0] https://www.raphnet.net/divers/ntt_data_sfc_controller/index... reply amenghra 19 hours agoprevYou could put all the logic in the USB connector and then not have to modify the shell. See eg the OMG cable: https://mg.lol/blog/ reply MarkusWandel 19 hours agoprevI did something similar by cutting down the PCB of a standard Microsoft game controller and wiring it into an old Wico Command Control joystick (the only thing I kept when I gave away all my C64 stuff - before it became collectible). https://wandel.ca/pic.cgi?49ceb103 Totally authentic for playing old C64 games in an emulator. But these days, I'd leave the joystick alone and just use an Arduino to do a DB9 to USB translator. reply nkozyra 19 hours agoprevI'm fairly novice with Arduino and interfacing with buttons/pots but I thought delays / loop interrupts were discouraged versus a reset-able counter variable? reply Goz3rr 19 hours agoparentThey are if you have anything else that needs to be done at the same time. I would say they're fine if you have nothing else to do while waiting, or you need microsecond delays to generate a signal like in this case. reply hellweaver666 17 hours agoprevI once modified a SNES controller and put a whole Raspberry Pi Zero, battery and boost/charger board inside for a portable retropie setup. reply wayvey 17 hours agoparentWow, that would be incredible! Did you document the project at all? I'd love to know more and maybe attempt something similar. reply hellweaver666 15 hours agorootparentI just followed this guide. It’s pretty straightforward! https://hackaday.io/project/16288/instructions reply r0bbbo 18 hours agoprevAre there any implications of the polling rate not quite aligning as the original controller would've? reply armada651 13 hours agoparentYeah I too wondered why the author would target 60Hz at all. The fact that the SNES controller is polled at 60Hz is simply a consequence of the game reading the input at that rate. As mentioned in the other comment in this setup the polling of the controller is not in sync with the game reading the input at all. Thus even if you target a polling rate of 60Hz perfectly you'd actually have worse input latency than the original hardware. It would be much better to target 120Hz or higher to reduce input latency and bring it as close to the original hardware as possible by ensuring there is always an up-to-date input state ready for the game to read. reply chybby 6 hours agorootparentI had a feeling the polling rate was probably to do with the frame rate of the SNES rather than some requirement of the controller. I'll try out a higher polling rate and see what happens. reply jerf 14 hours agoparentprevIf for the sake of argument we are plugging this into an SNES emulator running at 60Hz, then the stack between the USB gamepad and the emulator already has to handle that the gamepad is not rigidly synced to the emulated SNES and will presumably take every input from the gamepad and use it as the emulated input to the SNES next time it asks, unless a new one comes in first. At slightly faster than 60Hz, the net effect will be that the delay between input and having an effect on the SNES will wander about 1/60th of a second over time, as the sync varies, and every once in a while a particular input will be overwritten before it makes it into the emulator. It may be very difficult to perceive this, though, due to other delays already built into such a set up. On a real SNES, it would be right on the edge of perception anyhow. Being very close to the poll rate but not quite there is probably near the theoretically worst case. It would probably be much better to poll at 240+Hz, cutting the latency between input to a consistent 1/4ish of a frame. However, I doubt this improvement could be \"felt\" by very many people at all. reply drzaiusx11 19 hours agoprevGreat write-up. Next logical step is adding Bluetooth support so you can use it on the Switch: https://www.instructables.com/DIY-ESP32-Bluetooth-GamePad-fo... reply snerbles 19 hours agoparentDon't forget that these controllers operate at 5V logic and the ESP32 at 3.3V. Supposedly the ESP32 can tolerate 5V inputs [0], but it's probably best to put a level shifter between the two. reply daneel_w 17 hours agoprevThese, as well as NES dittos, were all over eBay and AliExpress for $3 a piece some 10 years ago. Probably still are. I've got one of each, just to get the right feeling when playing Zelda 1 and Pocky & Rocky on emulators. reply itslennysfault 18 hours agoprevThis is AWESOME. I set out to do exactly this like a decade ago and couldn't figure out how. I still have the two SNES controllers in my electronics box and dozens of Arduinos. Looks like I'll be making some USB SNES controllers this weekend. reply chybby 5 hours agoparentHave fun! reply hellweaver666 17 hours agoprevI bet you could build something like this with a Seeeduino Xiao (or Adafruit QTPY) to get a smaller footprint inside the case and not need to modify the plastic. reply jdelman 13 hours agoprevIs Arduino real-time? I.e. is a 6 millisecond delay guaranteed to actually be 6 milliseconds? reply mcpherrinm 13 hours agoparentThe Arduino is a single-threaded microcontroller running a single code loop, plus interrupts. delayMicroseconds is a busy-wait loop, so is relatively precise (to within a few instruction's execution time. However, interrupts can happen during that sleep, and the time spent handling interrupts won't be accounted for properly. It isn't a real real-time system, but for a project like this, it'll be good enough. reply vvoid 10 hours agoparentprevYes, it is real time, but due to interrupts you have to manage critical sections with cli() and sei() and your time base is a 16.000 MHz crystal. Most instructions for ATmega and ATtiny execute in 1 clock cycle so writing deterministic, time-critical code is straightforward. reply chybby 6 hours agorootparentThanks for the tip to turn off interrupts when working with precise timing! reply AYoung010 13 hours agoparentprevLargely, yes. Arduino code runs on bare metal, and delays simply block execution so they should be accurate with some constant overhead. reply hackan 17 hours agoprevI built a gamepad port snes adapter a decade ago, 10/10 would do this :ok_hand: reply rrr_oh_man 17 hours agoparent:thumbs_up: reply onli 20 hours agoprevOf course completely awesome to make a modification like this. However, if you yourself want a USB SNES controller, consider buying one instead. 8BitDo offers them with the SN 30 Pro - the quality is good, they work with the Nintendo Switch or PC (including Linux), they have the additional buttons needed for modern games, there is a wired and a wireless version and the newer variant has afaik a replaceable battery (unlike the first). Edit: I was probably wrong about the replaceable battery, that was the 8BitDo Pro 2. Which might indeed be the better choice. Looks less like a SNES controller, but at least still has the correct button labels and core layout, see https://www.8bitdo.com/pro2/ reply edwcross 19 hours agoparentI did try different 8BitDo controllers, and one issue with them is the \"multi-mode\": in order to make them work with Android/iOS/Windows/whatever, you need to press some key before connecting them, to change the way the OS recognizes the input. Which is a deal-breaker for small children, and prevents keeping things simple (e.g. \"remember to disconnect and reconnect the USB before turning the power on\", e.g. when using a Raspberry Pi-based console emulator). For wireless controllers, it's even worse (extra Bluetooth mode). If only they had mechanical switches to select this behavior... You may need to keep the instructions booklet with it, just to remember which keys must be pressed before turning it on, to see which mode will be activated. The controller in TFA is more useful in this scenario, since it will always behave in the same way. reply stickmangallows 19 hours agorootparentThe ones I have (SF30/SN30) remember which mode they're in so I just press the start button and it connects to my Switch. Then if I change it to bluetooth, it's the same for my Steam link until I switch it back. Plus there's a sticker on the back that gives the combos to change modes (Y+Start=Switch, X+Start=Bluetooth, etc). Some models, like the Lite 2, do have that physical mode switch. reply wingmanjd 19 hours agorootparentprevI have four of the bluetooth SN30's for couch co-op games on my SteamDeck. I agree that if I switched between devices often (like my son's switch) I'd need a lookup table for the power-on chording. Mine have the key combinations printed onto the label on the back. Fwiw, the ones I have remember their last pairing setup, so I only need to power them back on via the \"Start\" button. reply onli 19 hours agorootparentprevCompletely agree. I even had that situation myself - I misremembered how the mode switch/bluetooth pairing mode worked and was not able to connect my controller to a switch, thinking it was broken, until I realized what had happened. A small toggle switch really would be much easier. Still think it's worth it, also to not destroy an original one. On the other hand, better to modify it like this than to throw it away of course... reply JamesSwift 18 hours agorootparentThe new version does actually use a switch instead of the magic button combination. Agreed on the previous version being annoying. Had many kid debugging sessions when they accidentally switched the mode and “broke” it. reply 65a 17 hours agorootparentWireless ones have a switch, the wired ones all have the \"maybe you have to hold a letter depending on the game, kernel version and OS\" problem. reply patrickpkt 17 hours agoparentprevI speed run Zelda 2, though using an SNES controller. My experience with 8BitDo controllers is that they're stiffer than OEM, especially with the d-pad arrow keys. If you can use the analog inputs, they're great -- I use a Pro 2 with my Switch all the time. The d-pad, though, is a deal-breaker for classic gaming. iBuffalo used to make a controller that really did feel like OEM, but they've been out of the business for a few years. reply bondant 15 hours agorootparentCan only recommend the iBuffalo SNES controller too, I have two of them and they are quite good. Didn't know the brand stopped making them, it's a pity. reply Lutzb 18 hours agoparentprevThere is also the 8BitDo Mod Kit for SNES/SFC Classic Edition Controller which allows to convert original SNES controllers to bluetooth. https://shop.8bitdo.com/products/8bitdo-mod-kit-for-snes-sfc... reply erremerre 18 hours agoparentprevMaybe if you want to play super mario, the 8bitdo sn30pro works. But it has a huge problem of false diagonals, making is absolutely worthless to play tetris, or any fighting game that requires precise control. If you need precise controls, avoid this model. reply onli 18 hours agorootparentI have the SF30 Pro since a few years now and there might have been different revisions, but I definitely did not observe that. And I played through Hollow Knight with it, so I doubt that the controls are imprecise - I would not have had succeeded. Granted though, neither tried Tetris nor a classical fighting game. reply ludocode 19 hours agoparentprev8BitDo makes great controllers. I have an SN30 Pro, a Zero 2 and a pair of Ultimate Cs. All of them have been used extensively and they are all excellent quality. On the other hand I've had back luck with generic NES and SNES knockoff USB controllers. The quality is much worse than the originals especially in the D-Pad. It seems nobody but 8BitDo can get this right. If you stick with 8BitDo you'll have great quality but they don't necessarily match the form factor of the originals. I can see why OP would want to convert a real one. reply onli 19 hours agorootparentThe form factor is really close though. Ignoring the added buttons, which is completely possible while gaming, it does not feel much different. https://www.onli-blogging.de/uploads/sf30pro.jpg for an example picture :) reply jbverschoor 17 hours agoparentprevIt's not the same... It's like buying a non-nintendo controller in the past. They simply don't feel and respond the same reply 65a 17 hours agoparentprevI wish they would have proper Linux and fwupd support, which they seem to have dropped. reply mikepurvis 17 hours agoparentprevI'm using the 8BitDo wireless pads on my Switch and am very happy with them— vastly more comfortable than joycons, but a fraction of the price of the official pro controller. reply lopis 19 hours agoprevReminds me of that meme that says > Look What They Need to Mimic a Fraction of Our Power! That tiny arduino has a 16Mhz chip, while the NES main CPU ran at 1.66 MHz. Just a funny fact :) reply raldi 18 hours agoparentIn that case, you’ll love tom7’s Reverse Emulation video: https://youtube.com/watch?v=ar9WRwCiSr0 reply lopis 17 hours agorootparentYou're totally right. I loved it, thanks! reply cybrox 18 hours agoparentprevI once designed a custom PCB that fits inside the original NES four score case. You can connect 4 NES controllers to it and the inputs were sent to a Raspberry Pi via UDP (so no wire between couch table and TV was needed). I think my PCB had more parts for its simple power supply than all 4 NES controllers combined. These things are an absolute masterpiece of simplicity! reply toasteros 18 hours agorootparentMy coworker has done a similar thing, designing a PCB that allows us to connect the SNES controller over RJ45 to a custom Pi hat. We have students writing bare metal code for it! reply derefr 17 hours agoparentprevThat 16MHz of processing power is doing a pretty magical thing, though. It's encapsulating what is basically a serial bus, into a universal serial bus — i.e. it's making it so that: • you can plug this controller into any USB host, and the host can probe the device and discover that it's got a USB HID gamepad device • the SNES buttons get mapped onto standard USB HID event codes (HID Usage IDs), such that you could have a SNES controller plugged into one USB port and a Sega Saturn controller plugged into another USB port on the same computer, and they'd both be using a common language for events like \"D-Pad Up button pressed\", such that a framework like DirectInput or SDL can understand that out of the box. The SNES just uses the same 16 bits of input register no matter what's plugged in (gamepad, mouse, super scope, etc) — with games either assuming a specific static input device type and thus parsing those 16 bits in terms of that; or telling you to have a gamepad on P1 and whatever on P2, and then asking you on startup what type of thing you've got plugged into P2. • And — not so applicable to the SNES — but with USB, you can also have more than one of any given HID Usage ID reported by the same device. A gamepad with two analogue sticks can† just report analogue data for X/Y/Z-axis Usage IDs twice. • You can also have as many USB HID gamepads plugged into the same host machine at the same time as you like†. Even USB 1.1 is a very fast bus compared to the SNES's input polling rate; tons of HID reports will \"fit\" down the pipe as packets. The SNES, meanwhile, fundamentally only supported four input devices at once, because the hardware had exactly 64 bits mapped starting at $4218, representing the 16-bit readouts from polling of up to four input devices. And even then, if you wanted all four inputs to be polled, then you'd only be getting input for devices 1+3 refreshed on even frames, and 2+4 polled on odd frames. • You can have tons of other things — more data-intensive things! — plugged into the USB bus at the same time as the gamepad, and it'll still work just fine, because USB HID reports are given high QoS by USB host controllers and hubs. The SNES needs a separate bus for the cartridge, but on a PC the equivalent of a \"cartridge\" (an eGPU + eFPGA + NVMe, let's say?) could be connected to a USB4 dock, that your gamepad is also plugged into — and a single USB cable will take all that into your computer. • You can hotplug USB devices, without confusing either the client input device or the running program on the host. Both sides of a USB link (well, assuming the client retains power when unplugged) have knowledge of the connection lifecycle state. \"Device unplugged\" or \"device plugged in\" or even \"a new, second device plugged in\" are just like any other gamepad events, that your game can have a handler for. Meanwhile on the SNES, both input ports are just assumed to be populated at all times — and are therefore electrically live‡ and receiving a polling clock at all times. The distinction between there being 1/2/3/4 input devices connected, has to be made manually, by the game asking. There's no way for the game to know that a device was plugged/unplugged. --- † Consumer OSes mostly don't like this — but that's because consumer OSes are dumb, and have to this day never surfaced a high-level \"gamepad API\" that actually exposes the full extensibility of USB HID reporting. A high-level API that was actually designed to reflect the HID spec, would have an input-event report be a dictionary where the keys are usage IDs and the values are arrays of sensor readouts. Or a stream of polymorphic Usage-ID-keyed sensor-readout records. And either way, each report would at the very least identify which USB device it's coming from, so that you can tell apart reports from two identical controllers. But instead, what most gamedevs get from using industry \"best practices\" when writing an app-game using e.g. DirectInput or SDL for input, is an API that's even more naive than the SNES joypad input registers — it assumes that there's exactly one gamepad, and that it's reporting exactly one of each HID Usage ID. (And even worse with XInput, which assumes a fixed set of Usage IDs corresponding to \"what an XBox controller has!\") As such, most USB HID gamepads sold to consumers for use with PCs, in practice, don't take real advantage of what USB HID gamepads can in theory report. USB HID gamepads made to be used in proprietary ecosystems, on the other hand — think \"the Nintendo Switch Pro controller\" or \"the input board on an arcade machine\" — are free to be designed to actually use USB HID correctly. Which is why such devices usually need special drivers on PCs. They're not speaking a brain-damaged wire protocol; rather, they're living in the present and taking full advantage of USB HID features... while consumer OSes are still stuck in the past, unable to cope. :) This is also why so many systems like emulators that support these proprietary input devices — or games complex enough, that they expect USB HID devices that are themselves complex enough to only be possible if using the spec the modern way (think, uh, this thing: https://www.amazon.ca/Logitech-Saitek-Vehicle-Panel-945-0000...) — just skip the high-level gamepad-input-handling frameworks, and just register to listen to USB HID events directly. Because that's the only level at which they'll receive the information they actually care about, without the OS first mangling it into incomprehensibility. ‡ I believe polling for the input ports get zeroes rather than garbage if the ports aren't connected — but this is likely more for hardware protection than anything else, with pulldown resistors on the read path to prevent you from shorting out the input pins by unplugging while the console is on. Nintendo at least learned the lesson of the PS/2 bus.) reply tenebrisalietum 17 hours agoparentprevSNES can go up to a whopping 3.58Mhz (NTSC clock, not sure if exactly the same for PAL) but I believe due to some bus/architecture weirdness slows down to 1.79Mhz (which is what the NTSC NES runs at) when reading the controllers. Now the SuperFX chip, in Star Fox, ran at 10Mhz. Later versions like the one in Doom on SNES went up to 21Mhz. reply al_borland 19 hours agoprev [–] RetroUSB has adapters for those not looking for a project. I bought one of their NES adapters years ago. https://www.retrousb.com/product_info.php?cPath=21&products_... reply TillE 17 hours agoparentRaphnet adapters (designed by one guy in Canada) are the most popular option among serious speedrunners, if you want minimum latency. Their equivalent product is currently out of stock: https://www.raphnet-tech.com/products/snes2usb_1player_adapt... reply micheljansen 19 hours agoparentprevKind of amazing that you can get a whole controller (including buttons etc.) for a fraction of the cost of an adapter. Probably a less authentic experience though: https://www.aliexpress.com/item/1005005998083106.html reply creesch 18 hours agorootparentControllers that cheap generally are made of terrible creeky plastic, mushy buttons and generally poor assembly. You can get decent retro styled USB controllers, but they will be a bit more expensive than this one. reply TheCleric 18 hours agorootparentYeah I love the 8bitdo ones. But they're not inexpensive. reply JamesSwift 18 hours agorootparentPeople are always surprised that the controllers are the largest line item when building a retropie. You really want quality though, they make a big difference in that the dpads and the thumb sticks are both good. reply al_borland 15 hours agorootparentprevI picked up my NES controllers at Goodwill. Super cheap and the real thing. reply kevinsync 16 hours agoparentprev [–] I just got a RetroUSB Genesis adapter to use a 22-year-old Asciiware Power Clutch SG I had rotting in the basement for some JavaScript Gamepad API experiments. The adapter works great, feels good to breathe new life into an ancient peripheral! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts their experience of purchasing a vintage SNES controller in Tokyo and transforming it into a USB controller for their PC.",
      "They delve into the hardware components of the SNES controller and how it transmits button presses.",
      "The author describes their process of using an Arduino board to program the controller and remap the SNES buttons to HID gamepad buttons, including providing code snippets and setup instructions."
    ],
    "commentSummary": [
      "Discussion focuses on creating DIY USB SNES controllers and converting retro gaming controllers to USB, with users sharing their experiences and techniques for building controllers and adapters.",
      "Pros and cons of various gaming controllers are discussed, along with the limitations and advancements in technology.",
      "The advantages and disadvantages of using USB HID gamepads on PCs are explored, including the availability of adapters and controllers for retro gaming setups."
    ],
    "points": 279,
    "commentCount": 91,
    "retryCount": 0,
    "time": 1705667435
  },
  {
    "id": 39056733,
    "title": "Canadian Man Falsely Accused in E-commerce Scam, Stuck in Legal Limbo",
    "originLink": "https://krebsonsecurity.com/2024/01/canadian-man-stuck-in-triangle-of-e-commerce-fraud/",
    "originBody": "January 19, 2024 11 Comments A Canadian man who says he’s been falsely charged with orchestrating a complex e-commerce scam is seeking to clear his name. His case appears to involve “triangulation fraud,” which occurs when a consumer purchases something online — from a seller on Amazon or eBay, for example — but the seller doesn’t actually own the item for sale. Instead, the seller purchases the item from an online retailer using stolen payment card data. In this scam, the unwitting buyer pays the scammer and receives what they ordered, and very often the only party left to dispute the transaction is the owner of the stolen payment card. Triangulation fraud. Image: eBay Enterprise. Timothy Barker, 56, was until recently a Band Manager at Duncan’s First Nation, a First Nation in northwestern Alberta, Canada. A Band Manager is responsible for overseeing the delivery of all Band programs, including community health services, education, housing, social assistance, and administration. Barker told KrebsOnSecurity that during the week of March 31, 2023 he and the director of the Band’s daycare program discussed the need to purchase items for the community before the program’s budget expired for the year. “There was a rush to purchase items on the Fiscal Year 2023 timeline as the year ended on March 31,” Barker recalled. Barker said he bought seven “Step2 All Around Playtime Patio with Canopy” sets from a seller on Amazon.ca, using his payment card on file to pay nearly $2,000 for the items. On the morning of April 7, Barker awoke to a series of nasty messages and voice calls on Facebook from an Ontario woman he’d never met. She demanded to know why he’d hacked her Walmart account and used it to buy things that were being shipped to his residence. Barker shared a follow-up message from the woman, who later apologized for losing her temper. One of several messages from the Ontario woman whose Walmart account was used to purchase the goods that Barker ordered from Amazon. “If this is not the person who did this to me, I’m sorry, I’m pissed,” the lady from Ontario said. “This order is being delivered April 14th to the address above. If not you, then someone who has the same name. Now I feel foolish.” On April 12, 2023, before the Amazon purchases had even arrived at his home, Barker received a call from an investigator with the Royal Canadian Mounted Police (RCMP), who said Barker urgently needed to come down to the local RCMP office for an interview related to “an investigation.” Barker said the officer wouldn’t elaborate at the time on the nature of the investigation, and that he told the officer he was in Halifax for several days but could meet after his return home. According to Barker, the investigator visited his home anyway the following day and began questioning his wife, asking about his whereabouts, his work, and when he might return home. On April 14, six boxes arrived to partially fulfill his Amazon order; another box was delayed, and the Amazon.ca seller he’d purchased from said the remaining box was expected to ship the following week. Barker said he was confused because all six boxes came from Walmart instead of Amazon, and the shipping labels had his name and address on them but carried a contact phone number in Mexico. Three days later, the investigator called again, demanding he submit to an interview. “He then asked where my wife was and what her name is,” Barker said. “He wanted to know her itinerary for the day. I am now alarmed and frightened — this doesn’t feel right.” Barker said he inquired with a local attorney about a consultation, but that the RCMP investigator showed up at his house before he could speak to the lawyer. The investigator began taking pictures of the boxes from his Amazon order. “The [investigator] derisively asked why would anyone order so many play sets?” Barker said. “I started to give the very logical answer that we are helping families improve their children’s home life and learning for toddlers when he cut me off and gave the little speech about giving a statement after my arrest. He finally told me that he believes that I used someone’s credit card in Ontario to purchase the Walmart products.” Eager to clear his name, Barker said he shared with the police copies of his credit card bills and purchase history at Amazon. But on April 21, the investigator called again to say he was coming to arrest Barker for theft. “He said that if I was home at five o’clock then he would serve the papers at the house and it would go easy and I wouldn’t have to go to the station,” Barker recalled. “If I wasn’t home, then he would send a search team to locate me and drag me to the station. He said he would kick the door down if I didn’t answer my phone. He said he had every right to break our door down.” Barker said he briefly conferred with an attorney about how to handle the arrest. Later that evening, the RCMP arrived with five squad cars and six officers. “I asked if handcuffs were necessary – there is no danger of violence,” Barker said. “I was going to cooperate. His response was to turn me around and cuff me. He walked me outside and stood me beside the car for a full 4 or 5 minutes in full view of all the neighbors.” Barker believes he and the Ontario woman are both victims of triangulation fraud, and that someone likely hacked the Ontario woman’s Walmart account and added his name and address as a recipient. But he says he has since lost his job as a result of the arrest, and now he can’t find new employment because he has a criminal record. Barker’s former employer — Duncan’s First Nation — did not respond to requests for comment. “In Canada, a criminal record is not a record of conviction, it’s a record of charges and that’s why I can’t work now,” Barker said. “Potential employers never find out what the nature of it is, they just find out that I have a criminal arrest record.” Barker said that right after his arrest, the RCMP called the Ontario woman and told her they’d solved the crime and arrested the perpetrator. “They even told her my employer had put me on administrative leave,” he said. “Surely, they’re not allowed to do that.” Contacted by KrebsOnSecurity, the woman whose Walmart account was used to fraudulently purchase the child play sets said she’s not convinced this was a case of triangulation fraud. She declined to elaborate on why she believed this, other than to say the police told her Barker was a bad guy. “I don’t think triangulation fraud was used in this case,” she said. “My actual Walmart.ca account was hacked and an order was placed on my account, using my credit card. The only thing Mr. Barker did was to order the item to be delivered to his address in Alberta.” Barker shared with this author all of the documentation he gave to the RCMP, including screenshots of his Amazon.ca account showing that the items in dispute were sold by a seller named “Adavio,” and that the merchant behind this name was based in Turkey. That Adavio account belongs to a young computer engineering student and “SEO expert” based in Adana, Turkey who did not respond to requests for comment. Amazon.ca said it conducted an investigation and found that Mr. Barker never filed a complaint about the seller or transaction in question. The company noted that Adavio currently has a feedback rating of 4.5 stars out of 5. “Amazon works hard to provide customers with a great experience and it’s our commitment to go above and beyond to make things right for customers,” Amazon.ca said in a written statement. “If a customer has an issue with an order, they may flag to Amazon through our Customer Service page.” Barker said when he went to file a complaint with Amazon last year he could no longer find the Adavio account on the website, and that the site didn’t have a category for the type of complaint he wanted to file. When he first approached KrebsOnSecurity about his plight last summer, Barker said he didn’t want any media attention to derail the chances of having his day in court, and confronting the RCMP investigator with evidence proving that he was being wrongfully prosecuted and maligned. But a week before his court date arrived at the end of November 2023, prosecutors announced the charges against him would be stayed, meaning they had no immediate plans to prosecute the case further but that the investigation could still be reopened at some point in the future. The RCMP declined to comment for this story, other than to confirm they had issued a stay of proceedings in the case. Barker says the stay has left him in legal limbo — denying him the ability to clear his name, while giving the RCMP a free pass for a botched investigation. He says he has considered suing the investigating officer for defamation, but has been told by his attorney that the bar for success in such cases against the government is extremely high. “I’m a 56-year-old law-abiding citizen, and I haven’t broken any laws,” Barker said, wondering aloud who would be stupid enough to use someone else’s credit card and have the stolen items shipped directly to their home. “Their putting a stay on the proceedings without giving any evidence or explanation allows them to cover up bad police work,” he said. “It’s all so stupid.” Triangulation fraud is hardly a new thing. KrebsOnSecurity first wrote about it from an e-commerce vendor’s perspective in 2015, but the scam predates that story by many years and is now a well-understood problem. The Canadian authorities should either let Mr. Barker have his day in court, or drop the charges altogether. This entry was posted on Friday 19th of January 2024 10:34 AM A Little Sunshine The Coming Storm Web Fraud 2.0 Adavio Amazon.ca Duncan's First Nation RCMP Royal Canadian Mounted Police Timothy Barker triangulation fraud Walmart",
    "commentLink": "https://news.ycombinator.com/item?id=39056733",
    "commentBody": "Canadian man stuck in triangle of e-commerce fraud (krebsonsecurity.com)267 points by todsacerdoti 18 hours agohidepastfavorite249 comments mcv 17 hours agoThis sounds extraordinarily poorly handled by the RCMP. He could show that he purchased it from his own credit card and on Amazon, so that's pretty good evidence that he's the victim of fraud, not the perpetrator of it. Weird how extremely aggressive the RCMP is. That this is allowed to exist in legal limbo is ridiculous. He should be able to demand rectification and damages. And the real problem here is of course Amazon for enabling such scams. They should be on the hook for this, not some unsuspecting customer. And the real fraudster should be easy to track down through Amazon if they've done their due diligence. reply pixelcloud 13 hours agoparentIn terms of the RCMP and their aggressive behaviour. It makes perfect sense. First Nations people have not been treated well by the RCMP or LE for a very long time in Canada... This still persists to this day, systematic discrimination and all that stuff. reply asvitkine 11 hours agorootparentWell, it doesn't make sense that this still happens. You'd think there would be policies and training to prevent this sort of thing nowadays... reply zoky 11 hours agorootparentThat would require the Canadian government to admit they have a racism problem, which they steadfastly refuse to do. reply andy99 17 hours agoparentprevYeah what I got from the story is how unprofessional the police were. Unless there's more too it, the whole thing sounds like it should be an administrative investigations where everyone involved is assumed to be a victim unless more evidence comes to light. But somehow they rushed to treat this guy like a criminal. reply BunsanSpace 14 hours agorootparentHe's first nation/aboriginal.... It's racism. reply account-5 13 hours agorootparentI can see incompetence on the police's part sure. What makes it racist? reply jpollock 7 hours agorootparentThe police in Canada have a long history of poor interactions with aboriginal peoples. https://en.wikipedia.org/wiki/Saskatoon_freezing_deaths#:~:t.... Now called \"Starlight Tours\" https://www.theguardian.com/world/2023/apr/25/darrell-night-... https://www.cbc.ca/news/canada/rcmp-investigate-two-freezing... 2017 death in custody https://www.theguardian.com/world/2023/feb/02/canada-rcmp-of... reply account-5 3 hours agorootparentI'm not denying any of that. But those examples don't make this particular interaction racist. reply cbsmith 13 hours agorootparentprevPolice incompetence has a way of being disproportionately common depending on your race. Knowing definitively that is what is happening here without a lot more context is difficult, but it's entirely possible this is textbook racism. reply account-5 12 hours agorootparentBut as you say, based in the information provided that conclusion is speculative at best. The sensible conclusion based on the information provided is incompetence. I think hanlons razor is applicable here reply andreareina 6 hours agorootparentHalon's razor applies to the totality of the evidence, not just instance by instance. If you have a pattern of \"incompetence\" when dealing with First Nations issues that doesn't arise when not, that's really no longer adequately explained by incompetence. reply account-5 2 hours agorootparentHave we established a pattern of behaviour for this particular officer in this regard? reply cbsmith 11 hours agorootparentprevYes, I do not think one can draw conclusions. However, much as one might wish to apply Hanlon's razor, Occam's razor also applies, and from a lot of people's perspective it cuts towards racism. reply account-5 11 hours agorootparentBut surely the fewest assumptions here points to incompetence? Or more kindly a lack of knowledge about the way the fraud was commited? Based on the information provided I'd side with belligerent incompetence. Based on the information would you conclude it was racist if the accused person was white? Would you conclude it was racist if the cop was also a first nation/aboriginal? I doubt it. What would your conclusion be then? reply michael1999 8 hours agorootparentA little bit of column A, and a little bit of column B. Remote postings don't get star officers. And the RCMP has a famously ugly history with the natives of Western Canada. And some officers at a remote detachment might feel freer to act against some than others. What do you think the RCMP was even for? reply account-5 2 hours agorootparentWhat parts in those columns (I'm on mobile and only have one column, do you mean paragraphs?) show this was racist? I fully accept historical injustices occurred, and the possibility that remote places might not attract \"star\" officers and maybe that some remote officers could feel that a remote posting is an opportunity to enact their racist desires. But even if these are true it doesn't make this interaction racist. > What do you think the RCMP was even for? To police their communities? Or, based on your preceeding sentences are you suggesting that the RCMP's purpose is racism? reply orwin 59 minutes agorootparentTo protect the 'common man' from indigenous tribes at the borders. I think originally it's a military Corp designed to protect settlers. reply account-5 0 minutes agorootparentTIL. Not being Canadian I didn't know this. mlinhares 6 hours agorootparentprevWhy not both, right? reply verbify 7 hours agorootparentprevHanlon's razor is \"never attribute to malice that which could be attributed to stupidity\". However racism itself might be stupidity and not malice - much of everyday racism isn't the malicious KKK kind, it's much more similar to stupidity. reply account-5 2 hours agorootparentSo if this interaction was either down to malice or stupidity it's racist? Seems like a neat tautology... reply mikeravkine 11 hours agorootparentprevThe razor doesn't apply to the police. reply account-5 10 hours agorootparentInteresting. Why not? reply mnot 13 hours agorootparentprevYou think that incompetence is evenly deployed no matter what the race of the accused? reply account-5 12 hours agorootparentI don't think incompetence is something that can be deployed evenly or not. The article provides no information that I can see that makes it a racist cop targeting a minority. Or is it racist for any first nation/aboriginal person to be subject to a police investigation? reply asvitkine 11 hours agorootparentTheoretically, incompetence can be unevenly deployed if you assign incompetent people more predominantly to specific regions or cases. reply account-5 11 hours agorootparentSo theoretically the police chief is racistly deploying non-racist but known incompetent officers in the hopes their incompetence is going to adversely affect those specific regions or cases. That's leaving an awful lot to chance. I can think of more efficient and surefire ways to ensure those areas/cases are racially targeted, you could take Baltimore city as an example. But we're surely getting beyond any reasonable speculation of the information provided in the article? reply Eisenstein 8 hours agorootparentI think they are saying not that it is some grand plan by racism at the highest level, but that it is people at the higher levels not caring about certain people and the justice they get. People hear 'racism' and they think of that speech in the 60s 'segregation now, segregation forever' and firehoses, but it can be much more insidious than someone hating a subsection of people. It can be systemic in the sense that some people are not afforded the things most of us take for granted, like the protection of law, or due process of law, or innocence until guilt is proven, because there j isn't a will do it at the levels that matter. Fictional example: a cop is a problem, he tends to be heavily aggressive in his actions but he is also stupid and unlikeable. People he works with complain and he pissed off some people in the district. District administrator decide it is easier to transfer him to bumfuck, where if there are any complaints they can ignore them because they have no political power or pull, rather than let him mess with people who have the ability to get the media or politicians involved. This isn't even a conscious decision -- people in bumfuck don't complain because they are used to shitty treatment and no recourse, so they don't bother, whereas people like you or I would treat it as a travesty and get worked up and make a huge stink. The fact that it works like this makes it easy and the admin doesn't have to worry about it any more. Wash hands, done deal. reply account-5 2 hours agorootparentI can fully appreciate what you are saying. I'm not denying racism, (structural, systemic, or otherwise, conscious, unconscious) exists. Or that you fictional example might play out in reality. What I'm saying is that we can speculate until we are blue in the face, but based on the information in that article you can't simply conclude racism. reply defrost 1 hour agorootparentA good number of people here can read that article and incorporate a decade or more of past knowledge of reported interactions between the RCMP and indigenous communities in Canada. Call it one part racism, three parts utter indifference, with an occasional dash of one or two exceptions actually giving a damn and attempting to do the right thing. You're correct that no simple definite conclusion can be reached here on logic alone, however from context many can distinguish a hawk from a heronsaw given a favourable wind. reply account-5 1 hour agorootparentI think you have a good point. There are definitely historical wrongs that may influence someone's reading of a situation. Unconscious bias is a thing that we should all try and avoid, hard as is may be. reply Eisenstein 2 hours agorootparentprevI get it, but your response regarding incompetence being weaponized to me demonstrated a reductive and unsophisticated understanding of the causes and effects in 'racism'[1]. I get that you were most likely being hyperbolic to make a point, but unfortunately many people who are not personally familiar with such things tend to think in that way. I know that this is frustrating and sometimes can look very much like opportunistic virtue signaling, and many times it can be, but I would caution against immediately dismissing such claims when they are made and defended by parties that otherwise would not have reason to do so. [1] I wish we had a different word that didn't have all the loaded connotations inherent in 'racism' especially with its use in the past as a excuse for slavery, but we don't... reply account-5 1 hour agorootparentI don't think I advocated anywhere about \"weaponizied\" incompetence. I believe I was arguing that weaponizied incompetence is far fetched. My whole point engaging here with the many people I have has been to bring it back to what we know from the information we have. I'm more than willing to accept racism is the primary factor if racism was at all obvious from the article or even further information provided. The initial post I was replying to was a blanket statement that the accused person was first nation/aboriginal so the incident was racist. What has followed is ever more far fetched reasons for why it might be racist but no information to say it is so. I was enjoying reading what you'd previously written but changed, about domain knowledge and how domain experts can guess based on the outcome what was likely going on inside the system (EDIT: paraphrasing from memory, so I hope I got it right). I'd never thought about it like that before, very interesting perspective. But even then you'd have to be careful to make bloody sure your assumption, experience based though it is, was actually factually correct before tarring someone with racism. I hope my interactions here don't coming off as me dismissing people concerns/claims. I'm simply trying to take an objective view of the situation as presented. I'm aware that some people consider objectivity a problem in and of itself. reply walrus01 4 hours agorootparentprevThe RCMP in Canada has a long and well documented history of racism against indigenous people. reply RobRivera 6 hours agorootparentprevPlausible deniability? Baffling reply vdaea 9 hours agorootparentprevThis argument sounds ridiculous/unhinged to the average person. reply michael1999 9 hours agorootparentStated that bluntly, yeah. But not outlandish one you add some Canadian context. The RCMP is a national service, and the kinds of officers posted to a remote reserve like Duncan's First Nation might not be the best of the best. They are paying their dues in a para-military organization, with no union (unlike most cops). They are over-scheduled, and likely far from their homes. An adversarial relationship between the members of an RCMP detachment and local band is sadly common. reply krapp 9 hours agorootparentprevThe average person isn't aware of how endemic racism and abuse of indigenous people by the police and government is in the US and Canada. It's obviously not certain that racism was a factor in this case, but the assumption is anything but ridiculous or unhinged. If you aren't white, malice always has to be a factor to consider in any interaction with the American or Canadian government. reply cbsmith 13 hours agorootparentprev> Unless there's more too it, There is definitely more to it. We're hearing the story from one side, and there are many good reasons why the parties on the other side wouldn't share all of their context. Honestly, as I was reading it, I was thinking that it was both conceivable this was a gross miscarriage of justice and an outright failing of the police forces, it's also entirely possible that the guy is as guilty as sin and they're just having trouble putting a case together (which is common when dealing with online fraud). Keep in mind the police forces might arrest someone, but it's the prosecutors that make the decision about whether to bring charges. The prosecutors could have vacated the charge entirely, but chose not to. There's a lot of possible explanations for why they didn't, but that part of it isn't the RCMP's responsibility. reply droopyEyelids 6 hours agorootparentIt's possible in the same way it's possible to win the lottery. If he is guilty, why did the order fulfillment from Amazon register the delivery from Walmart? reply homero 14 hours agorootparentprevThey want an arrest, rarely do police care who it is reply actionfromafar 17 hours agoparentprevAs a foreigner, the only I have ever heard or seen of the RCMP is how courteous they are, with their red jackets, on fictional TV shows and movies, and how agressive they seem on the news. reply chromatin 14 hours agorootparent> As a foreigner, the only I have ever heard or seen of the RCMP is how courteous they are, with their red jackets, on fictional TV shows and movies, and how agressive they seem on the news. Canada has cultivated this image [of niceness] when in reality, their jack-booted state enforcers are just like every other country's. reply yieldcrv 14 hours agorootparentprevStarlight tours represent Canadian police, this article isn’t about RCMP but the lack of accountability doesn’t make a difference https://en.m.wikipedia.org/wiki/Saskatoon_freezing_deaths reply bparsons 17 hours agoparentprevThe RCMP, particularly in small towns are very bad at these types of investigations. The truly shocking thing is that they followed up on it at all. reply BobaFloutist 14 hours agorootparentI never really thought about it, but, looking them up it looks like they're basically the equivalent of the FBI(+ATF), but also sometimes are contracted for local policing by towns too small to maintain their own department? Is that accurate? reply morkalork 14 hours agorootparentYes, and more. They are federal police like FBI. They used to do intelligence work (like the CIA?) until the 80s where after some scandals, a new security agency was created to take over for that responsibility. Then there's some provinces that use them like the equivalent of state troopers and local small town police. It's a mess and a ball of conflicts of interest. reply cbsmith 12 hours agorootparentThe FBI also does intelligence work. What's different is that in Canada the RCMP take in local policing responsibilities where there's no local resources to do so themselves. reply morkalork 11 hours agorootparentHow would you classify CSIS which is the successor to what the RCMP was doing? reply wlonkly 6 hours agorootparentCSIS is more analogous to the CIA. It's an intelligence service, not a police service. But the US have a lot of specialized police agencies -- the RCMP is also the DEA, the Secret Service, the US Marshals... probably many more I'm forgetting or don't even know about. reply Scoundreller 14 hours agorootparentprevThey technically have jurisdiction across the country (for federal offences) and might take on big cases (e.g. terrorism) anywhere. Think of them as the “default” service. In many provinces, they’re the primary police service for all towns/cities except the largest ones. Other provinces have a provincial police service to be the default in towns/cities that don’t have their own municipal police service. reply michael1999 9 hours agorootparentprevNot just towns -- entire provinces (BC, Alberta, and others). Consider that the officers posted to a remote reserve like Duncan's First Nation might not be the best and brightest of the service. More Keystone Kops than Dudley Do-right. reply houseofzeus 14 hours agorootparentprevLargely, and in this case they'd likely be involved because of the latter type of jurisdiction. reply mthoms 11 hours agorootparentprevStraight out of training, RCMP officers almost always get posted to remote locations. Locations that nobody with any seniority will touch. These postings often require the new recruit to move - not just towns - but whole provinces away from their extended families. Throw in the cold, boring nature of these postings and what you get is a very bitter officer. One who is looking to pad their resume and move up the ranks and get out. It's also common for officers to be internally disciplined in this way; The best cops get the most prestigious postings, and the worst get the opposite (just like Catholic priests). (To be clear, I have no idea if this is true in this case - it's more of a generalization) reply wubrr 12 hours agoparentprevRCMP's main purpose is to serve as the enforcement arm of big corporate interests and politicians. Their secondary purpose is to serve themselves. Serving Canadians and upholding the law is like 30th on the list. reply jackconsidine 17 hours agoprevI will have to write a case study on this at some point, but triangle fraudsters have attempted to use our company's delivery service [0] to fulfill curbside pickups from Best Buy etc presumably to unsuspecting e-commerce buyers. I noticed certain a subset of users frequently changing their card, and the name on their delivery, and figured out what they were doing. We stopped a few dozen attempts, filing police reports and contacting the people with names matching the cards. We now use Stripe Verify to ensure identity matches, which I really would have preferred not to do as a privacy-oriented person. Interestingly, the police usually didn't want to deal with these things, even if the merchandise was in their jurisdiction reply ctrlaltdylan 14 hours agoparentWe provide ID verification specifically for eCommerce to help prevent chargeback fraud: https://getverdict.com This is the first where I've heard of using IDv for preventing triangle fraud on the fulfillment side. Just curious - how does this fraud harm you the delivery service? The chargeback hits the merchant only no? Or are you the merchant in this transaction as well? reply jackconsidine 13 hours agorootparentSimilar to you, chargeback is a concern (triangle fraudsters using stolen credit cards and all). We're not the merchant, normally that's a brick and mortar retailer. In addition to chargeback Generally, I really hate the idea of seedy users exploiting the service and feel obligated to root that out. reply UseStrict 17 hours agoprevSounds about right, the RCMP has a long history of First Nations neglect. This seems like it would be a straightforward case to prove his innocence. Also a good reminder of why it's important to never speak with police without a lawyer. reply naasking 17 hours agoparentExcept we don't have the same rights to a lawyer as in the US. We have a right to speak to a lawyer, but that could be over the phone and they are not present during questioning: https://blogs.ubc.ca/ijhr/2021/11/29/the-right-to-counsel-it... reply Scoundreller 14 hours agorootparent> We have a right to speak to a lawyer, but that could be over the phone and they are not present during questioning You can refuse to answer most questions during questioning, but even if you yell “lawyer!!!” A million times and spill the beans after the millionth repeat question, you’re screwed. Then there’s the constitution “protections” about illegally gained evidence where the judge can say “yeah, it was unconstitutional but I’ll allow it anyway” reply Spoom 17 hours agorootparentprevIt also sounds like the RCMP will never take the case to trial (based on the article, they may know that this is actually triangulation fraud) and as such, he'll never have a chance to either defend himself or expunge his record. reply papercrane 16 hours agorootparentIf charges are withdrawn or dismissed, as long as you don't have any convictions on record and there isn't a public safety concern you can request the destruction of non-conviction information from your record. It's silly that you need to request it, but there is a process to expunge your record. reply whimsicalism 15 hours agorootparentI think part of the issue here is the subtle distinction between stayed and withdrawn. reply deno 14 hours agorootparentIt seems the charges expire after a year. As per https://laws-lois.justice.gc.ca/eng/acts/c-46/page-98.html#d...: (4) However, if the Attorney General or counsel does not give notice under subsection (3) on or before the first anniversary of the day on which the stay of proceedings was entered, the proceedings are deemed never to have been commenced. reply wredue 14 hours agorootparentprevI don’t know why Canada gets so many weird AF legal claims on HN and Reddit (in particular that we supposedly don’t have the right to self defence), but we do, in fact, have the right to remain silent and to not be compelled to testify against oneself. There are circumstances where you can be interviewed without a lawyer present, but you cannot be compelled to answer those questions, and you can still consult a lawyer for all interview questions. reply naasking 12 hours agorootparentI'm not sure if you're claiming that what I wrote is \"weird\", but nothing I said was incorrect and the link I provided provides extensive information on case law here. Suffice it to say, most people have a very hard time refusing to answer while being grilled for hours, and the article cites numerous such examples. > and you can still consult a lawyer for all interview questions. This is simply not as straightforward as you're implying. Per the article, R v Sinclair established that in most cases, a detainee may be permitted to consult a lawyer only once. reply smcin 12 hours agorootparentR v Sinclair (2010 SCC 35) is a leading case from the Supreme Court of Canada on a detainee's right to counsel under section 10(b) of the Canadian Charter of Rights and Freedoms. Specifically, the case addresses two issues regarding the police's implementation duty under the right to counsel: 1) does a detainee have the right to have a lawyer present during police questioning, and 2) does a detainee have the right to make multiple phone calls to their lawyer. A majority of the Court answered the first question in the negative, and answered the second question in the negative, subject to a change of circumstances. https://en.wikipedia.org/wiki/R_v_Sinclair reply mthoms 11 hours agorootparentYou seem to be in agreement. Perhaps you responded to the wrong person? That's the same case law the parent cited (albeit indirectly - see their link up thread). reply smcin 8 hours agorootparentI responded to naasking with supplementary details supporting their answer. Like itsnotafight says, we don't always have to disagree with a poster. reply mthoms 4 hours agorootparentGot it. Maybe your post should be more substantial then? Then people don’t have to guess what you’re trying to say. You literally just echoed back something to someone that they already said. That’s more than a little confusing to a reader. reply itsnotafight 10 hours agorootparentprevYou can reply to someone and agree with them, even provide additional bolstering evidence — like a direct quote. It turns out not everything on the internet is a fight you have to win. reply mthoms 3 hours agorootparentIt wasn’t “additional boistering evidence”. It was the exact same case law that very same person had already cited. Hence… I politely asked if they meant to reply to someone else. I don’t know why you’re talking about fighting. reply wredue 9 hours agorootparentprevIt’s weird because you chose wording that isn’t entirely correct, and also chose to ignore that whether a lawyer is present or not, you cannot be compelled to testify against yourself, which is what a lawyer is going to tell you during your phone call. reply naasking 7 hours agorootparent> It’s weird because you chose wording that isn’t entirely correct My wording was entirely correct. > and also chose to ignore that whether a lawyer is present or not, you cannot be compelled to testify against yourself Irrelevant to the point I was making, which was specifically about how our right to counsel differs from the US. reply mardifoufs 10 hours agorootparentprevNo, we don't. This is a misconception. There's no equivalent to the pleading the fifth. The supreme Court has been pretty clear about that. >In the United States, the Fifth Amendment permits a witness to refuse to answer any question that may incriminate them (a.k.a. “taking the fifth” or “pleading the fifth”). This is not how the law works in Canada. In Canada, a witness can be forced to answer incriminating questions. https://www.aclrc.com/section-13#:~:text=In%20the%20United%2.... reply pyth0 10 hours agorootparentNot sure why you didn't include the remainder of that section: > As part of the bargain, however, the Crown cannot use that evidence to incriminate the witness in another proceeding. It seems important since it still prevents one from self-incrimination in the context of the courts. Maybe there are other legal ramifications caused by this distinction but it sounds functionally equivalent. reply mardifoufs 7 hours agorootparentWell, it leads to situations like these: >The Supreme Court discussed the relationship between the section 7 pre-trial right to silence and the confessions rule in Singh.90 That case involved a detained murder suspect who was interrogated by individuals he knew were police. In the course of the interrogation, Singh asserted his right to remain silent 18 times before ultimately responding to police questions with some self-incriminating statements. The defence objected to the admissibility of Singh’s statements on the basis that they were obtained in violation of his section 7 right to silence, but a slim majority of the Supreme Court rejected this argument. The majority held that, where a detainee is interrogated by known police, the section 7 right to silence is subsumed into the voluntariness inquiry.91 Since the trial judge had considered all the circumstances and determined that the statements were made voluntarily, the question whether the accused’s free will was overborne had already been answered and the section 7 right to silence could provide no further protection.92 Source(pdf): The Patchwork Principle against Self-Incrimination under the Charter https://digitalcommons.osgoode.yorku.ca/cgi/viewcontent.cgi?... reply twisteriffic 13 hours agorootparentprevThere's a huge cottage industry of YouTube rage farmers who spread that kind of misinformation for clicks. It's particularly popular in the prairies right now. reply mardifoufs 10 hours agorootparentThat's funny because no, they are wrong. We can be compelled to answer questions that incriminate ourselves and our right to speak to a lawyer isn't as strong as it is in the US. You can be interrogated even after asking for a lawyer. reply twisteriffic 8 hours agorootparentNo, you are wrong, though you provide a humorous example of how effective that form of brainwashing is. https://www.justice.gc.ca/eng/csj-sjc/rfc-dlc/ccrf-ccdl/chec... reply mardifoufs 8 hours agorootparentThey can keep interrogating you after you ask for a lawyer even if your lawyer isn't present. It amounts to the exact same considering how vulnerable a person is during interrogation. Your link agrees with me. How is this not \"not as strong as the US\", which is what I said in my comment? >There is no constitutional right to have a lawyer present throughout a police interview (Sinclair, supra at paragraphs 34-38). Rather, in most cases an initial warning, coupled with a reasonable opportunity to consult counsel when the detainee invokes the right to counsel, satisfies section 10(b) (Sinclair, supra at paragraph 2). Edit: This is what I mean >Unlike the U.S. Constitution’s right to counsel under the fifth amendment, neither section 10(b) of the Charter nor the right to counsel allowed by Supreme Court cases allows for your lawyer to be present with you during an interrogation. That means that after you’ve spoken to your lawyer it could be hours or days before you speak to them again and the police will take every opportunity they can to get a statement from you that seals your conviction. >https://www.jeffreismanlaw.ca/understanding-your-right-to-co... reply wredue 9 hours agorootparentprevNo, you are wrong: https://www.justice.gc.ca/eng/csj-sjc/rfc-dlc/ccrf-ccdl/chec... I don’t even know how you could force someone to testify against themselves. Seems like an unreliable witness… reply mardifoufs 7 hours agorootparentWhat? How does that prove me wrong? You can still be forced to be a witness and answer questions even if they do incriminate yourself. >In Canada a person has the right not to have any incriminating evidence that the person was compelled to give in one proceeding used against him or her in another proceeding except in a prosecution for perjury or for the giving of contradictory evidence. Thus, in Canada, a witness cannot refuse to answer a question on the grounds of self-incrimination, but receives full evidentiary immunity in return. https://www.mpllp.com/no-right-to-remain-silent reply orwin 52 minutes agoparentprevBy the way, quick aside, if you go to the police yourself (someone wronged you), you should also go with a lawyer. It'll be taken more seriously, be harder to dismiss, and be both council and support while you go through the steps. reply chromatin 14 hours agoparentprevUnfortunately, Canada does not have the same legal protections (both in written law [i.e., the Bill of Rights] and in jurisprudence) as in the United States. reply beached_whale 14 hours agorootparentWhat rights in the US would have helped here the Canadian Charter of Rights and Freedoms doesn't already do. Section 9 and 10 seem to cover this well reply chromatin 10 hours agorootparent> What rights in the US would have helped here the Canadian Charter of Rights and Freedoms doesn't already do. Section 9 and 10 seem to cover this well A fair question. First, as I was not making a top level comment, but responding to another comment, I was not specifically addressing this case, but instead making a broader statement about the Canadian Charter of Rights and Freedoms (and the attendant judicial interpretations of same) versus the US Bill of Rights (and likewise legal interpretations). (Side note, a sibling comment thread makes the same argument). In particular, Canadian courts have pretty consistently allowed more exceptions to the charters compared to US courts and Bill of Rights. Additionally, the charter makes much weaker protections in several specific circumstances, for example in section 24(2), whereby evidence collected illegally may still be used in criminal proceedings (see R v Grant 1990). But section 1 is the real kicker. As a specific example, you referenced Section 9 of CRF. In R v Ladouceur [1], the Canadian Supreme Court found that although random traffic stops (fishing expeditions) violated Section 9 of the Canadian Charter of Rights and Freedoms, they were permitted under Section 1 of the Charter. Section 1 contains the prefatory text: \"The Canadian Charter of Rights and Freedoms guarantees the rights and freedoms set out in it subject *only to such reasonable limits prescribed by law as can be demonstrably justified in a free and democratic society*\" (emphasis mine) The fact that such weasel words / escape hatch would be enshrined into something that is purported to be as fundamental as the Bill of Rights essentially nullifies the entire thing, in my opinion. Indeed, section 1 is often quoted in Canadian jurisprudence as justification for all sorts of -- again, in my opinion -- government overreach. [1] https://en.wikipedia.org/wiki/R_v_Ladouceur reply adamwk 13 hours agorootparentprevWell going off the article he’d at least not have a criminal record reply mthoms 11 hours agorootparentHe doesn't have a criminal record though. He has an arrest record. Granted the way the article explained it is pretty poor. I'm not totally clear what it was trying to say in that regard. As an aside, Canada has a robust pardon system[0] that the US doesn't have. At least aside from the truly bizarre (at least to me) system of presidential pardons. A pardon wipes your record of the specific crime completely FWIW. [0] https://www.pardons.org/pardons/faqs/ reply tamimio 15 hours agoprevGreat, all it takes in Canada to ruin someone’s life is to know their name and address, and a stolen card! I’m still missing one part, if that woman has her account hacked (plus the credit card, isn’t it supposed to be encrypted in walmart site?), and that scammer sent the goods to the guy, how did the scammer know that the guy ordered the stuff in the first place?! The coordinated attack is a little too sophisticated for a stolen credit card, because that would assume the scammer is also hacking that guy amazon account? Unless the seller is the scammer or part of a scammer ring and whenever he placed that order, they used the woman card to make the purchases, but why bother, they could’ve just used that card somewhere else, harder to track and a higher outcome? something isn’t adding up. That being said, I always use virtual cards for anything online, and those are a “prepaid credit cards”. reply papercrane 15 hours agoparent> how did the scammer know that the guy ordered the stuff in the first place?! The idea is the scammer is the seller on Amazon. So the guy orders from Amazon Marketplace, the Marketplace seller uses a hacked Wal-Mart account to fulfill the order and pockets the cash from Amazon. reply tamimio 15 hours agorootparentWhat’s the point or the advantage of doing so? The card will be cancelled right after and instead of using the max amount of that card, now you are only limited with what left after purchasing that goods, from the scammer perspective, I don’t see how’s this any better than maxing the card somewhere online instead, unless I’m missing something. reply andrewla 15 hours agorootparentI think the idea is that the scammer gets a legitimate payment from the receiver, and charges a bad payment to the sender. The sender cancels their card, and reverses the charge, so now Walmart is out the money and out the item. But the receiver card is not cancelled because they actually intended to use it, and received the goods that they ordered, so Amazon pays out to them for fulfilling the order. The problem with maxing out the stolen card is that you can't get cash -- you can get stuff, but even then, you have to give away your address. reply beaeglebeached 14 hours agorootparentAnother interesting twist of this happened to me. Someone created two eBay accounts. One in my name, one as a seller. They used my card to pay the seller with my forged eBay account. Then they found the tracking number of a package sent to my city around the same time. Ultimately the charge back failed when I reported fraud. They had a tracking number and invoice in my name, which my bank and eBay said had to be me. When I asked eBay to refund, they said the opposite as what they said to my bank. They said only the creator of the account could refund, not the person named on the account, so I could only refund if I found the fraudster and got their consent. reply tamimio 14 hours agorootparentprevVery interesting! I think the next step for that guy is to go after amazon for enabling the scam and being the front-end. reply mapreduce 17 hours agoprevSlightly tangential question but why is credit card security so weak in the first place? I mean all we need is 16 digits of card number, 4 digits of expiry date and 3 digits of CVV. The 23 digits can leak from so many places. In this day why don't the credit card payment systems require multi-factor authentication for online payments? Why don't payment machines challenge you for PIN for payments? reply mcv 16 hours agoparentEvery time this comes up, people claim that this lack of security doesn't matter because it's easy to reverse these payments. But if that's true, then why is the woman so upset and why is Barker handled so aggressively? It should be easy to revert both payments. reply everybodyknows 16 hours agorootparentThat's a question for Amazon, which makes the whole thing possible by: 1. Lulling naive or hurried customers who like to think they're buying \"from Amazon\" into buying from fraudsters, and 2. Paying the fraudsters so quickly that the seller's account is closed before action is taken the fraud, and 3. Vetting sellers so promiscuously that the individual fraudster's cycle can continue. In this light, Krebs diagram is deficient, because it omits Amazon from the loop. It's not \"triangulation\", the more accurate word would be quadrilateralization -- but spell-check says that's not a word. reply rootusrootus 16 hours agorootparentprevThis case is probably not a great example to use, because the woman's card wasn't stolen. Her account at Walmart was hacked, and the purchase was made there with the shipment sent to a different address. reply JaggedJax 14 hours agorootparentThis looks like an easy thing for Walmart to prevent if they bothered. On Amazon if you add a new shipping address, you can't ship to it until you re-verify your credit card CVV. With just that simple check this attack would be blocked (unless they steal the entire CC info of course). reply mcv 16 hours agorootparentprevWhy would that not make it a good example? It's still a case of fraud, enabled by the lack of security on credit card payments. The payment hadn't been authorised by the woman. reply zerbinxx 4 hours agorootparentprevThe woman was presumably upset because she thought she was scammed and had caught the scammer red-handed, and probably didn’t fully understand how credit disputes happen, or had some extenuating circumstances (poor credit, no credit) that she was actively trying to fix by having a CC only to get defrauded (although I don’t think credit fixes actually affect your credit score). It’s safe to assume the average person doesn’t really understand credit. reply Gare 17 hours agoparentprevSimple: because it adds friction, and the optional amount of fraud is not zero. https://www.bitsaboutmoney.com/archive/optimal-amount-of-fra... reply markus92 14 hours agoparentprevIn the EU it’s not uncommon to have some 2FA. My bank asks me to confirm online CC purchases all the time on their app with 3D secure. reply bpye 3 hours agorootparentThis is also true for me in Canada. I often get an SMS based 2FA prompt… reply BobaFloutist 14 hours agoparentprevThat's the idea with the expiry date, and the CVV, and the zip code. The problem is, it doesn't seem possible to convince businesses not to hold on to whatever security info is required to charge the card in plain text, so whatever the relevant details are inevitably get leaked from some hotel or eCommerce giant that really shouldn't have them in the first place, but hasn't set up a way to securely verify credentials with the bank without literally recording them. You can keep adding on additional pieces of bullshit information customers need to remember all you want, none of it will matter as long as banks and credit card companies don't force businesses to treat them as actually sensitive information. reply mainde 14 hours agorootparentI think that enforcing what you're suggesting is incredibly hard and I don't think can scale, it's what PCI-DSS and similar are meant to tackle, it really doesn't work in my experience. This is a protocol/product problem, it's wild that to make a payment all the crown jewels need to be put on the wire. It's about time that payment devices and the whole ecosystem adopts some sensible cryptography that, at minimum allows signing payment requests, and ideally keeps its keys private. Although this whole problem is kind of already solved by 3DS2, albeit not in a great way. reply rootusrootus 16 hours agoparentprevNit: you also need the five digit zip code reply toast0 4 hours agorootparentAddress verification is optional. Depending on your merchant account, you can request address verification for a customer, and you may get a lower discount rate with correct address information. But you can also run charges without it. reply ekanes 14 hours agoprev> He says he has considered suing the investigating officer for defamation, but has been told by his attorney that the bar for success in such cases against the government is extremely high. Canada is a relatively less litigious country, but it seems he was harmed quite materially by losing his job. I'm not sure why they'd arrest him if he could show he placed the order the way anyone else would through his Amazon account. reply living_room_pc 1 hour agoprevThe RCMP held a gun to my wife's head when she was pulled over and threatened to shoot. I think it was because she was driving a beat up car in a wealthy part of the city. After they realized she was a student, they just let her go and did a complete 180 pretending they were all buddy-buddy with her. During the interaction they said some really threatening, creepy, and disparaging things. We launched a complaint, but since we left the country (for work), they said they couldn't do anything as we were non-residents. The whole thing was completely unacceptable. I'm not anti-police, but the RCMP need serious reform. I feel uncomfortable every time we return to Canada visit family. reply whimsicalism 17 hours agoprevIt is too bad that the woman who was victimized appears too dumb to understand what triangulation fraud is and seems convinced that Barker is the perpetrator. reply mcv 16 hours agoparentYou can't blame this on the other victim. The problem is that the RCMP has no clue what they're doing, and that Amazon is enabling this fraud. reply whimsicalism 15 hours agorootparentWas not saying this was the issue at hand, I just am surprised the woman quoted is so dense. reply krunck 17 hours agoparentprevCan't rule out racism here. On the part of the woman and the RCMP. reply whimsicalism 17 hours agorootparentCertainly on the part of RCMP, you can tell when you are reading a case where the cops are dealing with a community they do not expect to advocate for themselves. reply unsupp0rted 17 hours agorootparentprevNeedn't rule in racism, so I don't. reply Fripplebubby 17 hours agoparentprevDoes it have any bearing on the case, though? I agree but it may make no difference reply unsupp0rted 17 hours agoprev> Barker says the stay has left him in legal limbo — denying him the ability to clear his name, while giving the RCMP a free pass for a botched investigation. He says he has considered suing the investigating officer for defamation, but has been told by his attorney that the bar for success in such cases against the government is extremely high. reply beeburrt 14 hours agoprevHere's a Defcon talk about this: https://www.youtube.com/watch?v=2IT2oAzTcvU reply Wowfunhappy 12 hours agoprev...I did not realize merely being arrested gave you a criminal record. That would seem to go against \"innocent until proven guilty.\" Is this Canada-specific or does it also apply in the US? reply qingcharles 17 hours agoprevI don't know Canadian law. Once a prosecution is started, must it be completed within the statute of limitations for that crime? I think that's how it generally works in the USA. Because the prosecution is stayed you lose the right to a speedy trial, but the statute of limitations still ticks. reply papercrane 7 hours agoparentIn Canada we have the right to be tried in a reasonable amount of time. The Supreme Court of Canada put strict time limits in place in R. V. Jordan. For cases without a preliminary inquiry (which this would be) the Crown has 18 months from the arrest to bring the case to trial. For cases with a preliminary inquiry it's 30 months. Since he was arrested April 2022 that means he must be tried before the end of 2024, or the charges withdrawn. reply OsrsNeedsf2P 16 hours agoparentprevThere is no statue of limitations in Canadian law. reply andrewla 14 hours agorootparentThere is no statute of limitations, generally, but Canada does recognize the right to a speedy trial. The Charter of Rights And Freedoms [1] 11b says \"Any person charged with an offence has the right ... to be tried within a reasonable time\". Common law interpretation through R. v. Jordan [2] establishes a presumptive ceiling on the time between charges and trial, \"18 months for cases tried in the provincial court, and 30 months for cases in the superior court\". In the US statutes of limitations vary between jurisdictions and offenses; some start the clock ticking at the commission of the criminal act, others at when it comes to light, and others when it is reported to law enforcement. This is in addition to the right to a speedy trial, but the US does not have any uniform guidance on what \"speedy\" means and generally courts do not entertain speedy trial motions. [1] https://laws-lois.justice.gc.ca/eng/const/page-12.html [2] https://scc-csc.lexum.com/scc-csc/scc-csc/en/item/16057/inde... reply qingcharles 4 hours agorootparentThere are generally three types of speedy trial rights in the USA, depending on where you live. Federal constitutional right, State constitutional right, and State/federal statutory right. The federal one is vague and hand-wavy and only defined in case law. Usually the same with State constitutional right. The statutory rights are usually more explicit and often define an exact number of days and how those days are calculated, e.g. Illinois it is 120 days. Courts definitely do entertain them. I've seen dozens over the years and there are thousands of examples of successful challenges in case law. I can think of several weird examples off the top of my head: 1) Guy from Hawaii transferred to mainland prison, murder case reversed for new trial on appeal, State doesn't do the paperwork to fly him back from prison to Hawaii within 180 days, then tries to blame it on the prisoner for not getting himself to his own trial :D 2) Guy burgles building which is built on a county line. State charges him in the wrong county (he burgled the other side of the building); tries to change venue, judge says they blew out their speedy trial days holding him in the wrong county. 3) I personally lost a year. I was in jail before COVID broke out. I filed for my 120 day speedy. There's no exception in the Illinois statute for emergencies (unlike the federal statute). Illinois Supreme Court unilaterally modifies the statute without involving the legislature. I didn't go to court for over a year, just stuck in a flooded cell. Filed a motion to dismiss for speedy trial violation and violation of the Illinois constitution for having the court create a new law. Illinois Supreme Court rules that it can do whatever the fuck it wants because they are the ones who have the final say on a motion and they are not going to find against themselves lol \"Where, as here, a statute and a supreme court rule governing court procedure cannot be reconciled, the statute must give way to the rule.\" (a rule created without consultation over-rides a law created by lawmakers!) https://law.justia.com/cases/illinois/supreme-court/2023/128... reply retrac 13 hours agorootparentprevSpecifically, there is no statute of limitations for indictable criminal offences, the equivalent of a felony. Minor offences have a limit of one year. Civil matters have a limit in many provinces, too. reply Affric 3 hours agoprevKrebs is great but there is one thing that's killing me: > \"hacked\" Where is any of the evidence of hacking? I see inadequate protections against fraud from the sellers. I see an account that has been compromised. I don't see any evidence of hacking. reply doodlebugging 8 hours agoprev>>Barker shared with this author all of the documentation he gave to the RCMP, including screenshots of his Amazon.ca account showing that the items in dispute were sold by a seller named “Adavio,” and that the merchant behind this name was based in Turkey. That Adavio account belongs to a young computer engineering student and “SEO expert” based in Adana, Turkey who did not respond to requests for comment. Seems like this would be a great time to track this guy down, Adavio, and get his side of the story whether he wants to tell it or not. The fact that he disappeared makes him sound more like he has connections to scammers and thieves who use stolen card info. Something's rotten here and it has nothing to do with Denmark. reply randerson 17 hours agoprevSounds like the Ontario woman was likely reusing a password and had her account taken over. Walmart should help this guy out by running password dumps against her account to see if that's the case. reply actionfromafar 17 hours agoparentWalmart... helping? reply cantrevealname 15 hours agoprev> Barker said he bought seven “Step2 All Around Playtime Patio with Canopy” sets from a seller on Amazon.ca, using his payment card on file to pay nearly $2,000 for the items. Presumably Baker would have immediately shown the RCMP the Amazon transaction record for his (legitimate) payment to the (fraudulent) seller. And that Baker's payment to the seller would have been timestamped before the seller perpetrated the fraud on the Walmart account and shipped the goods to Baker. If you saw the timeline above, and you believed the transaction records were accurate (and I assume the RCMP has the means to verify those transaction records with Amazon and Walmart), then what would you conclude was going on? Would you assume that Baker was a master criminal who was acting as both the buyer and crooked seller, and was covering his tracks with a prepayment from himself (as the buyer) to himself (as the seller), thereby creating a transaction record to give plausible deniability? Even the most cynical jaded hard-edged RCMP officer should see that doesn't make sense. Either the investigation was very incompetent or there's some more detail to the story that we haven't heard. reply race_condition 15 hours agoparentNo need to presume. > Eager to clear his name, Barker said he shared with the police copies of his credit card bills and purchase history at Amazon. But on April 21, the investigator called again to say he was coming to arrest Barker for theft. reply naitgacem 17 hours agoprevwhere I'm from, it's insanely common to buy a smartphone, only to find out when you put your sim card in, that it was stolen. The authorities will just take it back (with no refund ofc) if you can prove that you bought it. However, most purchases are from online sellers, or stores that say (this phone came from abroad by an immigrant). Now this is indeed how most electronics enter the country, so the risk is unavoidable sadly. reply 8organicbits 17 hours agoparentCouldn't the seller put in a sim card to determine if the phone was stolen? reply ivalm 17 hours agorootparentWhy would they? The seller wants to move product and illegal product comes with discount. reply naitgacem 14 hours agorootparentunfortunately it's much more insidious, they are both priced exactly the same. no one's the wiser until the police hit you up, or you try to fly abroad. reply 8organicbits 7 hours agorootparentprevStolen product is less valuable to the buyer (see complaints in thread) and seller reputation at the very least. reply toast0 4 hours agorootparentIf the seller has mostly stolen goods, seller reputation isn't a big concern. Startup a new shop when the old one dries up. reply mcv 16 hours agorootparentprevDoesn't that make them guilty of fencing? Do they at least refund the illegal purchase? reply whimsicalism 15 hours agorootparentYou are reasoning from high rule of law when OP is clearly describing a low rule of law country, prolly middle-income. reply lewdev 8 hours agoprevTwo bad things: * There is clear fraud going on and the authorities are doing nothing about it. * The authorities mistakenly attacked the victim and not owning up to it. reply jschrf 5 hours agoprevRCMP in general is pretty broken - sorry - needs reform. Systemic issues. reply deadbabe 14 hours agoprevAs someone whose been accused before of something I didn’t do, by people who were damn sure I had done it, it can be a very stressful traumatic experience, it doesn’t sound like a big deal until it happens to you. Don’t just hurl nasty messages at someone you don’t know and don’t even have 100% proof they have wronged you. reply ngneer 8 hours agoprevSounds like a man in the middle attack, made possible since buyer and seller do not mutually authenticate one another? reply ttul 17 hours agoprevFrankly, this is yet another article justifying why you must never speak to the police. reply dmoy 17 hours agoparent(the canonical talk on that topic: https://youtu.be/d-7o9xYp7eE?feature=shared) reply bigbabybuckman 17 hours agorootparentHappy STFU Friday! https://www.youtube.com/shorts/kEeId0EG-XE reply tamimio 15 hours agorootparentDoes that even work in Canada? The article is about a Canadian issue. reply cldellow 14 hours agorootparentIf you invoked the fifth, you'd be made fun of, since that's a US thing. But section 7 of the Charter of Rights and Freedoms: > Everyone has the right to life, liberty and security of the person and the right not to be deprived thereof except in accordance with the principles of fundamental justice. has been found to provide similar protections. You can be required to identify yourself, and, in drunk driving cases, you can be required to do roadside sobriety tests, but in general, you aren't obliged to answer questions from the police. reply oh_sigh 17 hours agoparentprevWhat part of him talking to the police worsened his situation? reply TinyRick 17 hours agorootparentMy interpretation is that he provided enough evidence to the RCMP that convinced them to stay the case, since they likely thought the evidence they had to convict Barker was weak. This lead to him not having a chance in court to clear his name. Had he not spoken to the police at all, and instead waited to present his evidence in court, he likely would have been found not guilty and therefore would have cleared his name. Him talking to police worsened the situation because they are not the ones who evaluate the evidence and make a conviction decision (judges/juries do that). The job of the police is to collect evidence, and Barker did that for them (to his detriment). reply mindslight 16 hours agorootparentprevSo much just-world-fallacy-inspired victim blaming in this thread. The problem here is actually better described as a breakdown in communication with the police, on the part of the RCMP. (I wonder if they have their own videos like \"Don't listen to your victims\" and \"Shut your eyes Mondays\" ?) Modulo the third party scammer that created the situation, the bad actor here is the RCMP itself for bringing the weight of the government down on this guy without doing the real work of actually investigating. The true reform would be to destroy this regressive idea whereby government agents/systems can attack people and then just walk away from the matter after realizing they are wrong. If there were statutory reimbursements for hiring legal representation, time spent/detained, emotional distress etc, then the victim here would have the resources to continue the matter in the eventually consistent justice system. Instead the official policy would seem to be something like \"Thank you for your involuntary contribution to this rookie agent's training. Better luck next time\" reply unsupp0rted 17 hours agorootparentprevBeing out of town in Halifax for the following 3 days probably made the officer a lot less convinced of innocence right off the bat. That's why he showed up at the house the next day. reply trevyn 17 hours agoparentprevnext [5 more] [flagged] mkoryak 17 hours agorootparentEven better, live somewhere where you're the police reply dorfsmay 17 hours agorootparentprevCan you elaborate? Which countries would that be? And have you tried to live in one of them? How did it go? reply dmoy 16 hours agorootparentThe only people who I've talked to at length who lived somewhere without police were Somali living in Minneapolis They do not have good things to say about no police (also tends to go hand in hand with no firefighters, and everything controlled by warlords). reply selimthegrim 13 hours agorootparentSimilar to people I talked to who lived in (former) Pakistan FATA and PATA reply cushpush 7 hours agoprevFeel for this man reply FpUser 13 hours agoprevUntil we make our fucking \"servants\" including police accountable for abuse of power and what they do to people it'll keep happening. reply aurizon 10 hours agoprevThis resembles the man-in-the-middle attack, which is also a triangulation attack in structure. I wonder if it could be defeated with a dual path defence, where traffic went one way out and another way back? reply reso 13 hours agoprevThe RCMP is an extremely troubled police force (like many). There was a mass shooting event in 2020 in rural Nova Scotia, and it is not an exaggeration to say that the RCMP response made Uvalde look good in comparison. RCMP officers attacked civilians at a designated safe shelter, failed to warn the public of the danger for 12 hours leading to more deaths, and there is circumstantial evidence that the shooter himself may have been a RCMP confidential informant. There has been no credible investigation or accountability. The podcast Canadaland Commons has an episode on the Portapique incident I highly recommend. Accountability for police forces and other elements of the criminal justice system seems to be a critical unsolved problem in western societies. reply wubrr 12 hours agoparent100%, RCMP is extremely corrupt and incompetent. reply walrus01 4 hours agoparentprevThe RCMP knew for years in advance that the shooter was building a near perfect replica of a police vehicle and did nothing about it. reply whimsicalism 17 hours agoprev> In Canada, a criminal record is not a record of conviction, it’s a record of charges and that’s why I can’t work now,” Barker said. “Potential employers never find out what the nature of it is, they just find out that I have a criminal arrest record.” Funny, I usually associate Canada with good policymaking but this is substantially worse than the US. reply sandworm101 17 hours agoparent>> Funny, I usually associate Canada with good policymaking but this is substantially worse than the US. Generally yes, but this is a specific law enforcement problem tied to Canada's unique police culture. Specifically, the way the RCMP hire and promote police officers has direct negative implications on \"white collar\" investigations in Canada. Without explaining all the details, the RCMP is effectively Canada's national police force but is also the local police force for most communities. Imagine it as if the FBI also did speeding tickets. All new cops start out doing something like traffic enforcement, often in small/northern communities well away from their homes. Only after years of \"general duty\" (aka traffic) can they move up to things like \"electronic crime\". Many good people are lost through this process. The average compsci or finance grad isn't going to want to spend years handing out speeding tickets before doing what they are actually trained to do. And the people who rise to the top of general street policing are often not the best people for long-term white collar investigations. https://www.rcmp-grc.gc.ca/en/police-officer-careers \"The RCMP is a national organization with diverse career opportunities like no other police service. Applicants may be asked to relocate anywhere within Canada where there is need of your services.\" \"You may choose to continue in general duty policing, or you may have the desire and opportunity to train for and transfer to more specialized areas of policing.\" Want to investigate online fraud? Have a forensics or criminology degree? Ready to chase down people doing horrible things online? Well, here is your radar gun and ticket to the Yukon territory. Remember to bring a coat. Call us back in a few years and we may have something for you. reply BobaFloutist 14 hours agorootparentWow that sounds almost as bad as how we select our cops in the US. Almost. reply ttul 17 hours agoparentprevWhat they’re referring to is the court records that show whether someone was ever put through any kind of criminal justice process. If someone is arrested and charged, that record is publicly accessible to anyone for a few dollars. If the charges go nowhere, the record of the arrest and charge remains on the public record forever. It is indeed an unfair system. reply papercrane 16 hours agorootparent> If the charges go nowhere, the record of the arrest and charge remains on the public record forever. This isn't necessarily true. It's dumb that it's not automatic, but you can request in the destruction of non-conviction information. reply pi-e-sigma 15 hours agorootparentAnd they can deny the destruction of that non-conviction information without having to explain why. https://www.rcmp-grc.gc.ca/en/managing-criminal-record reply mapreduce 17 hours agorootparentprevIt really is so unfair! Is it like this in other countries too? Like US, UK, Germany, etc.? I'd really like to know how this system works in other developed countries of the world. reply fnimick 17 hours agorootparentIt is very much the same in the US. Some states and cities have implemented a so called \"ban the box\" law, but most of the country has not. I've filled out many background check, employment applications, rental application etc that will ask \"have you ever been arrested or charged with a crime\", and regardless of circumstance will deny you if you say yes. If you are found innocent, or charges dropped because they messed up the evidence etc, doesn't matter. reply leros 16 hours agorootparentIn the US, as I understand it, you can go through a process (not free) to get your arrest record expunged and then you can legally answer no to that question. Still messed up but there is a path at least. reply marcosdumay 14 hours agorootparentprevWell, not a developed country, but in Brazil the government can only disclose convictions (outside of the government, internally there are a few exceptions), only to the person or a security-related organization, and it's illegal to even ask for a record in a work related process unless it's about one of those security-related organizations (the Federal Police maintains a list of them). Also, the data stays there starting at the conviction and only up to the point the person is found innocent in another ruling or the penalty ends. But the one things that keeps surprising me about the other countries isn't any of that discrimination against minor misbehaving. It is that justice promoters so often see their roles on society as harassing suspects until they break down. This seems to be the norm, and it's completely ridiculous. reply jyunwai 17 hours agorootparentprevI researched this, and I believe that both Barker's quote and this summary are not entirely correct. The reality in Canada is more nuanced. --- 1. Non-conviction records are not publicly available, and require the consent of the individual to be released. > If someone is arrested and charged, that record is publicly accessible to anyone for a few dollars. If the charges go nowhere, the record of the arrest and charge remains on the public record forever. Not exactly. The person under consideration must give their consent before the records are released. From the Alberta Civil Liberties Research Centre (ACLRC) [1]: \"In Alberta, an individual’s consent is required before police will perform a search of their police records for background check purposes. [...] Although it is common practice to provide the results only to the individual who requested the check, there is some variation depending on the police services. It may be released to an employer or volunteer agency when the individual requesting the check signs a consent form, or it is agreed to by both parties. No other outside party will receive any negative information about the individual.\" This is also backed up by a report from a Canadian Civil Liberties Association (CCLA) publication, distributed by Public Safety Canada (a department of the federal government) [1] (Page 23) [2]: \"How does the Police Information Check process work? Most police services indicated that the Police Information Check process requires that the individual requesting the information attend a police station in person with identification and payment.\" --- 2. Barker's quote has inaccuracies, though there is a core of truth. Several different levels of criminal record checks exist, and not all levels include non-conviction records. > \"In Canada, a criminal record is not a record of conviction, it’s a record of charges and that’s why I can’t work now,” Barker said. “Potential employers never find out what the nature of it is, they just find out that I have a criminal arrest record.” While it's true that Barker said this, it looks like the reporter took his word without adding important nuance (though I appreciate Krebs on Security's work to bring attention to the issue, and the thoroughness of the description of the fraud). In reality, according to the ACLRC, employers who choose to request a background check must first request the candidate to submit a consent form to a police department, before the employer can access that person's records. So, the record is not publicly available to any person. (Anecdotally, this matches with my personal experiences applying for the most in-depth check—called the Vulnerable Sector Check, or VSC—in the past.) --- 3. The least in-depth record check would not include non-conviction records; the middle-depth record check may or may not include these records, depending on the judgement of the police department; and the most in-depth record check would always include these records. But this is where there is ambiguity about whether non-conviction records are included. While it might be expected that the Vulnerable Sector Check would include these charges as this check is the most in-depth, the ACLRC also identifies two lower levels of checks: the Criminal Record Check (CIC) and Police Information Check (PIC). According to the ACLRC, it looks like the CIC does not require a list of non-conviction records (aka charges without conviction), but a police department may reveal non-conviction records in certain cases for a PIC. From the ACLRC article: \"The police will often disclose your non-conviction records in a PIC if they believe the information will help the potential employer or other agency in their decision-making process. This assumes that these agencies are qualified to make a determination that the information disclosed will determine the candidate’s suitability or pose a safety risk. \"It may lead to unfair stigmatization and result in the candidate being excluded from consideration for the position. As a result, the candidate may never know why they have been excluded from consideration, and thus are unable to respond. Although never convicted for a crime, the candidate will suffer an invisible form of punishment. The repercussions may reach beyond the denial of a position to a lingering loss of self-esteem, trust, and respect from the community.\" --- To summarize: while I completely sympathize with Barker and hope his situation can be quickly and justly resolved, Barker's quote is not completely incorrect, but it can be misleading. It's possible that more nuanced information from Barker was omitted from the final article, but in any case, a person's record of charges that did not lead to a conviction is not publicly available. Instead, access to these records requires an individual to submit a consent form to a police department. Furthermore, not all potential workplaces require a the type of background check that would reveal these non-conviction records. Some workplaces would require a Criminal Record Check (CIC), which would not include these records. Others, however, would require a Police Information Check (PIC), which may or may not include these records, depending on the police department's response. I want to re-emphasize that Barker's situation is unjust, and clearly puts him in a difficult situation in life. But it is in the reader's interest to know the Canada's legal situation in reality includes important nuances that differ from the account provided in the article. --- Sources: [1] https://www.aclrc.com/disclosure-of-non-conviction-records [2] https://www.publicsafety.gc.ca/lbrr/archives/cnmcs-plcng/cn3... --- If any person with legal expertise is reading this, as my commentary is based on personal research without relevant legal training, please feel free to add your perspective. reply mcv 16 hours agorootparentRequiring consent doesn't make a difference when it's about employment. If you don't give consent, you don't get the job. reply jyunwai 16 hours agorootparentIt's true that Barker is now disadvantaged for certain types of jobs for an accusation he was never convicted of, which is completely unjust. He deserves far better treatment. However, requiring consent means that the records are not publicly available, so he is not immediately disqualified when he applies. In addition, a company has to specifically request for a deeper background check for this to appear—the base level of a background check only includes convictions. No person in Canada who is charged yet not convicted is therefore barred from work, which is an impression made from Barker's quote and a previous comment. A more precise understanding of the system is important for advocacy to change it. It's more effective to argue for reforms related to Police Information Checks (such as for more transparency) to be specific, and this requires a specific awareness of how Canada's process for background checks works. reply belval 16 hours agorootparentprev> a person's record of charges that did not lead to a conviction is not publicly available, but rather requires an individual's consent. Unless I misunderstood isn't that almost the exact same thing though? When getting hired they will ask you to fill out some forms prior to your background check that explicitly give the permission to run a background check. I never tried to refuse but I doubt it would be welcomed. reply jyunwai 16 hours agorootparentIt's still a problem for Barker, and I don't want at all to discount that his situation is unjust. However, the non-conviction records will not necessarily show up on his report. If the employer requests the base level of a background check, the records will not show up. If the employer instead requests a more in-depth check (a PIC), the records may or may not show up. Not all employers would request the more in-depth check. Barker is therefore not at a disadvantage for all jobs for a non-convicted charge, but it is completely unjust that he can potentially be at a disadvantage for a fair number of jobs. Barker deserves recourse and more awareness of his case. But at the same time, the potential impression that any Canadian resident that is charged-but-not-convicted will have a publicly-available record that bars them from work, is not a correct one. reply j45 15 hours agorootparentprevThis is pretty defensive and confusing. Maybe police information checks are a revenue stream. Consent to get someone’s record is being conflated with what is on someone’s record being wrong, or only a charge. It’s a bit of a moot point where consent is involved when the content of a charge has the same impact on not getting employment. reply jyunwai 15 hours agorootparentTo make this clearer, the comment I was replying to says, \"If someone is arrested and charged, that record is publicly accessible to anyone for a few dollars. If the charges go nowhere, the record of the arrest and charge remains on the public record forever.\" But neither statement is true upon a search. Separately, Barker's quote in the article asserts that in Canada, there is a single criminal record check available for a person, and that \"is not a record of conviction, it’s a record of charges.\" The reality is that there are several types of background checks, and the base level lists a record of convictions while omitting charges—though in any case, Barker is clearly an innocent person who should have the incident dropped from a check at any level. reply j45 6 hours agorootparentAh, I see, thanks for clarifying what you meant Does that mean a police information check is the only way to search for charges against a person? Charges are usually registered with courts too, and those courts are usually searchable as public record I’m assuming. reply dghlsakjg 17 hours agoparentprevThis information seems to be incorrect based on this https://stepstojustice.ca/questions/employment-and-work/can-... and this https://certn.co/blog/criminal-record-check-alberta-your-faq... It seems like employers can only factor convictions, and they must justify why that conviction would be a factor in doing the job. What I can believe is that the RCMP would botch a case involving a native person. Just yesterday a bunch of video transcriptions were released of RCMP officers busting up a peaceful protest by native tribes. https://www.cbc.ca/news/indigenous/rcmp-audio-wetsuweten-coa... The officers referred to tribal members with face-paint honoring missing and murdered women as \"orcs\". In regards to arresting a mentally disabled man: \"That big f--king ogre looking dude that is in those videos he is actually like autistic, then the f--king guys just beat the shit out of him and then he started crying. I felt bad for him, apparently the sergeant grabbed his balls and twisted, I guess. He was on the ground and everyone was just grabbing limbs. He didn't have a limb to grab so he just like grabs his balls like 'You done now? You done resisting?\" Canada has decent policy, but we have, for some reason, imported policing culture from the states. reply _rm 17 hours agorootparentJust based on reading the first link you posted, what you've said is incorrect, as it says they can ask for a \"Criminal record and judicial matters check\" which includes charges. If that's the case, \"they can't\" reject you just based on charges really means \"they can as long as they don't say they did\". reply dghlsakjg 17 hours agorootparentIn my experience in working in Canada the records check is done after an offer is extended since it is not free, requires the consent of the person being checked, and takes several days at best, so it would be very obvious why the offer was retracted. I haven't said anything incorrect. I said that employers can only factor convictions, not that they can't get access to other records. reply bparsons 17 hours agorootparentprevHe is likely referring to a \"vulnerable sector check\". This is a special type of background check for people that interact with children, the disabled or seniors etc. This type of background check includes stuff like expunged convictions, or charges where prosecutions were not pursued. It can be a useful tool, but it obviously needs to account for instances such as this. reply jyunwai 16 hours agorootparentI found that Canada has three types of background checks: the Vulnerable Sector Check (VSC) as you mentioned, the Police Information Check (PIC), and the Criminal Record Check (CIC). The VSC always includes non-conviction records. The CIC omits these types of records, as this only reports convictions. However, the middle-level PIC can include these records on a case-by-case basis. The Alberta Civil Liberties Research Centre reports [1]: \"The police will often disclose your non-conviction records in a PIC if they believe the information will help the potential employer or other agency in their decision-making process. This assumes that these agencies are qualified to make a determination that the information disclosed will determine the candidate’s suitability or pose a safety risk.\" The circumstances are especially unfair to Barker as he has been working for Duncan First Nation in a role that requires involvement in finance. So, Barker may be especially affected by the non-conviction record even for jobs related to managing finances that don't require a VSC, but also a PIC, as a police department would likely find the record relevant for any position related to finances. [1] https://www.aclrc.com/disclosure-of-non-conviction-records reply fnimick 16 hours agorootparentprevI'm not sure (EDIT: replaced 'it is' with 'it should be') a useful tool when taking non-convictions into account. If person A was arrested and then charges were dropped, does that make them less innocent than person B who was never arrested in the first place? You could argue that from a probabilistic view, any person who is arrested for a crime is more likely to be a criminal than one who is never arrested ever - and it's up to us as a society whether we want to expose that information so that people can avoid hiring those who have ever been arrested. reply dghlsakjg 13 hours agorootparentYou could also argue that someone who was arrested, but never convicted, is even less likely to be a criminal. After all, the not inconsiderable resources of the state were focused specifically on that person and their behavior, and the state determined that there wasn't enough evidence to even proceed with charges. A person who has never been arrested has likely never had someone who is deeply incentivized to find wrongdoing look into their actions. It would seem that, logically, we should look most suspiciously at those who have never been arrested! This is of course a naive view of the justice system. We should perhaps treat an arrest as nothing at all since we know that plenty of innocent people get arrested, and the noble thing to do is presume innocence absence a conviction instead of presuming guilt on a weak signal. reply jstarfish 16 hours agorootparentprev> You could argue that from a probabilistic view, any person who is arrested for a crime is more likely to be a criminal than one who is never arrested ever - and it's up to us as a society whether we want to expose that information so that people can avoid hiring those who have ever been arrested. Radical feminism really fucked society with this logic since it resonates with hysterics and fools. Previously, it was how everyone blames all crime in town on the Bad Kid because he was caught stealing that one time. \"He clearly has it in him to do it!\" they say. We all do, I say. Criminals aren't Morlocks from the fucking moon, they're people just like you who were unlucky/incompetent enough to get caught. Arrests/accusations are cheap. Convictions require vetting and evidence. Weighing both the same is a social travesty that defeats the purpose of the justice system and opens everybody up to being framed for anything. If you dare to know how dangerously you live, read up on domestic violence laws and see how many you break when arguing with your spouse. It takes very little to get yourself arrested. reply noah_buddy 17 hours agoparentprevI think that Canada is absolutely undeserving of this record and there have been a few recent stories that illustrate governmental ineptitude or even malice. This is the one that springs to mind: https://www.bbc.com/news/world-us-canada-65107912.amp reply whimsicalism 17 hours agorootparentEh, I dont find these in-hindsight \"reports\" that compelling. The implication that if someone beats their wife we should be abke to stop them from committing a mass shooting seems incorrect. reply noah_buddy 17 hours agorootparentI think clearly a major failing to not immediately announce to the public that a mass shooter is driving a replica police car. That’s beyond even the other details that didn’t clue the government off that he was up to no good (like withdrawing half a million in cash from a bank account). reply fnimick 17 hours agoparentprevIt absolutely works that way in the US. Lots of jobs, financial applications, housing rental applications etc ask if you have ever been charged with a crime - not convicted, only charged - and even if you are found innocent, or the charges dropped because it turns out their initial investigation was wrong etc - it closes most doors for you. reply whimsicalism 17 hours agorootparentProbably state dependent, do not think they can do that where I live. reply fnimick 17 hours agorootparentIt is state and municipality dependent. https://www.paycor.com/resource-center/articles/ban-the-box-... reply whimsicalism 17 hours agorootparentfwiw that map covers a significant majority of Americans in states with some box restriction reply fnimick 17 hours agorootparentThe map itself is wildly misleading. New York is colored in the map, for example, because four cities in the state have some sort of restriction on it (some only for government employees, too, so private companies can ask whatever they want) reply belval 17 hours agoparentprev> Canada > good policymaking As a Canadian, seems like we just have good PR. reply rootusrootus 16 hours agorootparentYou look almost European in design and you're in close proximity to a country everyone loves to hate. You absolutely glow by comparison. I gotta say, though, that every time I go up to Canada I'm struck by how much everything seems just like the US. If the US ever gets universal healthcare it'll be especially hard to tell the difference. Hell, we're even well on our way to having our own king! reply unsupp0rted 17 hours agorootparentprevCanada has INCREDIBLE international PR. Perhaps better than any other OECD country, compared to its reality. reply lbhdc 17 hours agoparentprevI used to work in heavy industry and did a lot of work in Canada (I am an American). Canada always had the worst security to go through because the same thing this guy is experiencing everyone crossing the boarder for work got the same thing from boarder security. Anyone who had been arrested would get held at customs for a few hours, and occasionally over night. Basically you would get interrogated by a boarder guard, and the boarder guards would complain that they don't convict people of crimes in the US while asking about 20 year old arrest records. I kind of assumed they were just terrible to foreigners coming in, but to do it to their own citizens is pretty awful. reply dghlsakjg 17 hours agorootparentIf you think Canadian border guards are bad, its because you've never seen how American border guards treat non-citizens. If you tried to enter the US with a criminal record, there is a VERY good chance that you would not be allowed in, and would be handed a 5-10 year ban. Most countries do not allow visa-less entry to convicted criminals. The fact that Canada let your co-workers in at all is at the discretion of the border guard. Canada is very clear about the steps that those with a criminal record need to go through prior to applying for entry at the border. It sounds like your coworkers showed up to the border without the necessary preparation and were allowed to enter at the officer's kindness/discretion in spite of their criminal pasts and lack of documentation. https://www.canada.ca/en/immigration-refugees-citizenship/se... reply lbhdc 16 hours agorootparentI had to shepard many South Americans and Europeans through American boarder security for this same job. I found Canadas process to be much more restrictive. They similarly handed out decade+ bans. We had a legal team prepping the paperwork for these trips, they had the correct paperwork. reply dghlsakjg 13 hours agorootparentDid the people entering the US from Europe/South America have criminal records? Part of the reason that it is harder for an American with a criminal record entering Canada is the fact that it is visa free. A convicted American at the Canadian border has likely not gone back and forth with immigration authorities, or had an interview at the embassy like a South American at the US border would. By the time a European or South American arrives at the border they have already submitted the paperwork to an embassy (or received an ESTA/visa waiver), and have been given permission. Without convincing proof that they are eligible to enter the USA, the airline won't even let them on the plane. The reality is that it is perfectly reasonable for a country to deny entry or investigate a convicted criminal before granting the privilege of entering the country. Doubly so when the purpose of entry is for work. As a non convict, I had to prove to Canada that I could support myself and would not be a burden on the medical or other social systems in addition to an FBI background check, and a variety of other paperwork before I was granted residency. It took upwards of a year for all that. By what reasoning should Canada prioritize or not investigate people that have, in the past, been a burden or danger to their society. Entry by non permanent residents or citizens is a privilege, and I think it is perfectly reasonable for a country to ensure that a convicted criminal won't pose a danger or burden. reply lbhdc 12 hours agorootparentEveryone had to pass a security clearance that prevented them from accepting people with criminal convictions, but prior arrests with no-convictions were fine. Our work required Canadian work visas for us to operate in Canada, and everyone had the correct passport stamps before ever leaving (this again was handled by the legal team). We were getting hassled over the arrests without convictions (this was only air travel, we never drove). I am fine with countries doing whatever the need to. I think citizens getting subjected to similar treatment (tfa) pretty unreasonable. reply dghlsakjg 12 hours agorootparentGotcha. I imagined you were driving a busload of roughnecks with convictions to the oil fields. It is absolutely BS that an arrest with no conviction would lead to delays at the border. reply beaeglebeached 14 hours agorootparentprevOutside of five eyes most countries don't know dick about your record, and usually don't even ask. Our neighbor Mexico often doesn't even look at your ID. US and Canada share immigration info, so they have unusual overlap. reply whimsicalism 16 hours agorootparentprevThe reality is that if you expect immigration trouble, you should always enter through an airport and never a border crossing. reply beaeglebeached 13 hours agorootparentI was on some kind of watchlist for awhile ( fought in foreign militia ) and you get the extremes at the land border. Most times things are much better. But when they're worse, it's WAY worse. (Although to be fair at airport was only place CBP told me they'd deny entry to the country to me US passport holder) reply rolph 15 hours agoparentprevin the US as long as its not too bad [misdemenor] and you behave yourself, it goes away [depending on state]. in canada you are the sum total of every mistake you have made in your life, for your entire life. reply newsclues 17 hours agoparentprevCanada has terrible policy making. reply mattw2121 17 hours agoprevThis is not me blaming the victim. He totally shouldn't have to worry about what I am about to say. If he was ordering for himself, my advice wouldn't apply. If you are ordering something for your work, use a work credit card and have it delivered to your work address. I never put myself (or my finances) out there for my work. I've had people ask me to pick up snacks for meetings and say I can just expense it later. Sorry...not happening. Someone decides they don't want to approve the expense and I'm holding the bill. Either give me a work credit card or figure out another way to order your stuff. reply Zenst 17 hours agoparentI can vouch for that advice and equally double check. My story - I worked for a Canadian company Blackberry in the UK and they wanted me to go to the Seattle office for few weeks. I said I couldn't afford to be covering expenses and my manager said would sort that out, came along with a bit of paper saying was expense advance - sign that. Well, turns out he lied, was pay advance as I found out when I got paid say 12 hours TZ difference from my bank etc when my rent, council tax and everything bounced. So I'm on the other side of the World and chaos is starting to rain on my home back home. Now was a Canadian also there for a few weeks and not only had he got a proper expense advance, was 3x what I got (yes I was underpaid and that's another story) and was shocked how my boss messed up. Long story short, they never fixed the mess and caused me to have a breakdown, never did get my expenses back, lost my home and ended up with a massive council tax bill that took me years paying off and life went very downhill from there afterwards from one surreal predicament to another. So do remind your companies that you are not a bank, you are already working in areas for the company and never ever pay for expense stuff from your own money unless you can charge interest and penalty clauses for late paying. reply ipaddr 16 hours agorootparentNever agree to travel without them sending a plane ticket prepaid first. reply Zenst 11 hours agorootparentOh I had that, just stitched up with salary advance instead of expense advance. reply jpambrun 15 hours agoparentprevEven with a corporate credit card you are usually personally responsible until the expense is approved. reply happyopossum 14 hours agorootparentThat depends on the card and how you acquired it. A corporate Amex is typically backed by the employee, but they are falling out of favor in part because of that. If you have a corporate card through a bank other than Amex, there’s a very good chance you do not carry the liability for paying it. Your employer could come after you if they feel it was used improperly, but that’s a very different can of worms than carrying credit liability. reply NoZebra120vClip 7 hours agoparentprevI don't know how it works for First Nations bands, but from my perspective as a long-time church volunteer, we're often expected to make use of our personal resources for our volunteer roles. We pay out of pocket for supplies and stuff, we're driving personal cars, there's not a lot of guidance about how to structure our email or other online accounts. The church is certainly never going to give us a church-owned computer to do stuff on, or a church credit card to rack up expenses. We may get reimbursed, or we may be out of pocket as a \"donation\" to support these ministries. It's one of the most difficult things about being a church volunteer, for me. I finally got wise on the account front, and I've created accounts which are totally separate and dedicated to doing only church volunteer activities, so that it's not mixed in with my personal activity or data. And in terms of USB thumb drives or something, I can purchase separate ones. But when it comes down to capital expenses and such, we seldom have a choice but to mingle our personal lives with those volunteer roles. reply lopkeny12ko 17 hours agoprev [–] This is an important lesson in data and operational security. Don't use your credit card on websites you don't trust, and use virtual cards whenever possible. And 2FA all your online accounts. A few easy steps could have avoided a massive headache. reply belval 17 hours agoparent> Don't use your credit card on websites you don't trust The person in this article bought stuff from Amazon with their credit card and did not have their account compromised. Unless you are arguing against buying stuff on the Internet in general I don't see how you comment has anything to do with the case at hand. This is mostly typical RCMP overreach and the person should seek legal advice on counter-suing for damages. reply leereeves 17 hours agorootparent>> Don't use your credit card on websites you don't trust > The person in this article bought stuff from Amazon Yeah, you shouldn't trust Amazon. They don't do nearly enough to ensure their 3rd party marketplace is safe. reply mcv 16 hours agorootparentAmazon is one of the largest companies in world. They have a responsibility to be more trustworthy than this, and should be held accountable. reply leereeves 16 hours agorootparentI agree, and I didn't mean to blame the victim here (in case it sounded like that to anyone). But it is a lesson to the rest of us, about the risk of shopping on Amazon. reply mcv 16 hours agorootparentI totally agree, and I don't buy from Amazon as a matter of principle, but considering their size, clearly most people don't. And I suspect that's not because they're fine with the risk, but because they're not aware of it. And that's a problem. Amazon is profiting from trust that they're not worthy of. reply rohansingh 17 hours agoparentprevIf the man is taken at his word, his only error was buying from a seller on Amazon.ca. What credit card he used there didn't matter at all. reply stanmancan 17 hours agoparentprevThe two websites in question were Amazon and Walmart. If you can’t trust either of those then who can you trust? reply nytesky 17 hours agorootparentTechnically it was a 3rd party seller right? Like eBay or a flea market or the back of a truck? reply toast0 17 hours agorootparentYes, but you still pay Amazon, and Amazon pays the seller. Using a virtual card wouldn't have helped him here. The other victim wouldn't have been helped by using a virtual card at Walmart.ca either. reply nytesky 17 hours agorootparentA virtual card that expires or is limited would have protected somewhat. reply interestica 16 hours agorootparentThere are no virtual card options reply oh_sigh 17 hours agorootparentprevNo, because the order would still have gone on Walmart.com with his real name and address reply organsnyder 17 hours agorootparentprevTechnically, yes. But Amazon's site doesn't make this clear. reply keithweaver 17 hours agoparentprevI completely agree about using Virtual Credit Cards generally. However, the majority of Canadian Banks (Especially the Big 6) don't offer virtual credit cards. Even US banks that offer credit cards in Canada don't offer it in here, but they do it the US (Ex. Capital One). reply function_seven 17 hours agoparentprevHow would this prevent what happened to Timothy Barker? reply leros 17 hours agoparentprevUnfortunately in this case, the guy getting punished didn't do anything wrong. It's the woman who's Walmart account was hacked who messed up. reply rootusrootus 17 hours agorootparentEven then, I'd put at least some blame on Walmart. Adding a new shipping address to an existing e-commerce account is an obvious situation where a little extra scrutiny is warranted. At least a 2FA check. reply bayuah 17 hours agorootparentI agree. In my country, many e-commerce platforms require to add of a phone number. Therefore, if you add an address, you must input the code sent to your phone. Another point to note is that, for additional security, some e-commerce platforms even put your account on hold for a few days if you change the aforementioned phone number. reply TheCleric 16 hours agorootparentprevEven Amazon in the past has at least asked me to reenter the card’s CVV when attempting to add a new address. reply croes 16 hours agoparentprevThey claim he used the woman's card, so no that wouldn't have helped reply organsnyder 17 hours agoparentprevAnd don't buy anything from Amazon (at the very least only from sellers that use Amazon's fulfillment services, which is easy to gloss over). reply bsder 17 hours agoparentprev [–] How about we simply make credit card companies liable for all of these kinds of frauds? Not the merchant, not the consumer, not the marketplace--the credit card company. If we did that, suddenly all the banks, marketplaces, etc. would have all the nice security things we've been bitching about for years. reply mcv 16 hours agorootparentEvery time credit cards come up, everybody always tells me that this is their big advantage: that it's trivial to revert these two payments. So this fraud shouldn't work, and yet it does. How is that possible? reply toast0 3 hours agorootparentReversing the payment to Walmart doesn't reverse the shipment, and assuming they don't get arrested or harassed, and the triangle purchaser is none the wiser, so the fraudster gets apparently clean money from the triangle purchase. reply razakel 17 hours agorootparentprev [–] They are, that's part of the point of having a credit card - you're spending the bank's money, not yours, and they have better lawyers. reply TheCleric 16 hours agorootparentNot in my experience. It appears that way to the CC user, but usually comes back to the merchant as a chargeback. reply bayuah 17 hours agorootparentprev [–] Well, that is why I totally prefer debit card. Credit card basically you just borrowing money from bank for your (usually daily and small) purchases. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Timothy Barker is seeking to clear his name after being falsely charged with orchestrating a complex e-commerce scam known as \"triangulation fraud.\"",
      "Triangulation fraud involves a consumer purchasing an item online, the seller using stolen payment card data to purchase the same item from an online retailer, and the only party left to dispute the transaction is the owner of the stolen card.",
      "Barker claims to have purchased items for his community using his own payment card from a seller on Amazon, but later received accusations from an Ontario woman of hacking her Walmart account.",
      "Barker was arrested by the Royal Canadian Mounted Police, lost his job, and now has a criminal record that is affecting his employment prospects.",
      "Barker believes both he and the Ontario woman are victims of triangulation fraud, with someone hacking her account and adding Barker's name and address as a recipient.",
      "Despite providing evidence, Barker's charges were stayed, leaving him unable to clear his name."
    ],
    "commentSummary": [
      "The summary explores various topics in Canada, such as fraud, law enforcement, racism, and legal rights.",
      "It highlights specific cases involving mistreatment and wrongful accusations by the RCMP.",
      "The summary also addresses the need for reform and the challenges related to background checks, criminal records, immigration policies, e-commerce fraud, credit card security, and the responsibility of companies like Amazon in preventing scams."
    ],
    "points": 267,
    "commentCount": 249,
    "retryCount": 0,
    "time": 1705678648
  },
  {
    "id": 39056902,
    "title": "SourceHut's 170-hour outage: Lessons learned and future plans",
    "originLink": "https://sourcehut.org/blog/2024-01-19-outage-post-mortem/",
    "originBody": "It’s been a busy couple of weeks here at SourceHut. At the time of writing, we have restored SourceHut to full service following an unprecedented 170 hour outage, and while we still have numerous kinks to sort out following an unscheduled emergency migration of all services across an ocean, all services are now fully operational. Allow me to open this post-mortem by extending my deepest apologies to the SourceHut community for this interruption in service. This outcome was unacceptable: we failed you, and I am sorry. We know that you depend on SourceHut to be reliable, and you trust us to make sure that you can always depend on our services to be there for your projects. We value this trust profoundly, and we will strive to prevent a situation like the one we faced last week from recurring. The Internet can be a fragile place, and we will do what we can to re-enforce it. Here’s what happened, what we did about it, how we’re making things right, and what we’re doing to ensure it does not happen again. Background SourceHut runs on servers owned and provisioned by SourceHut, installed in colocation facilities at three datacenters, respectively codenamed PHL, AMS, and FRE. PHL was our primary datacenter, FRE was used for off-site backups, and AMS was a research installation intended for a future migration of our production infrastructure in PHL and next-generation deployment of SourceHut intended to scale into the indefinite future. We have been setting up an installation in AMS for researching a future infrastructure migration to the EU and means of increasing our resilience and redundancy, which we had planned to gradually roll out with minimal disruption to user service over the course of at least a year. In the end, we rolled it out with maximum disruption to user service in 7 days. The AMS datacenter installation was provisioned according to a projected research workload with an eye towards expanding it to support a full SourceHut installation in the future; at the time of the incident it was provisioned at a scale appropriate for running most of a SourceHut installation. Our FRE datacenter is used for off-site backups. We maintain a Postgres standby which is replicated in real-time and is usually up-to-date within seconds of production, as well as daily backups of large data silos such as git.sr.ht. We have a comprehensive monitoring system in place which, among monitoring other systems, keeps track of these backups and notifies us when their metrics fall outside of our window; for instance we receive an alarm if the database replica is more than 5 minutes behind production of if large storage backups exceed 48 hours. We maintain a comprehensive set of operational plans for responding to various incidents which may arise, ranging from hard drive failure up to and including the complete failure of a datacenter, which proved to be important when addressing this scenario. We also have standard response times for responding to various tolerances being exceeded which are designed to minimize user impact; for instance we configure the storage utilization alarms with sufficient lead time to provision additional storage. The complete failure of a datacenter is the most challenging situation we have prepared for, and it is the situation with which we were ultimately faced. The incident At around 06:00 UTC on January 10th, a layer 3 distributed denial-of-service (DDoS) attack began to target SourceHut’s PHL infrastructure. We routinely deal with and mitigate application layer (layer 7) DDoS attacks, however, a layer 3 attack takes place at a lower level and is not within our ability to mitigate without the assistance of our network provider. Starting from about 06:00, our monitoring systems noticed that something was wrong and raised the alarm, and we started investigating the issue shortly thereafter. However, before we could get a handle on the situation, our access to the PHL network completely disappeared at around 09:00 UTC. We never received any kind of ransom note or other communication from the attacker. We do not know who was behind the attack, nor their motivations, and likely never will. We know that they targeted SourceHut specifically, and that they followed us as we worked on mitigations, directing their attack at new infrastructure as it was being set up. In this post-mortem we are going to focus on the impact on our network and the steps we took to restore service, rather than going into what we know of the attack and the details of our mitigations, both for information security reasons and to avoid lending legitimacy to a bad actor. In the end, the response to the attack from our upstream network in PHL did more damage to our infrastructure than anything else. We rent network service in PHL from our colocation provider, who provisions a subnet out of their AS and routes it through Cogent and Level 3. In response to the attack, Cogent announced null routes for our downstream AS, causing our PHL network to become unreachable both for SourceHut staff and the general public. We attempted to contact our colocation provider at this point, but we were unsuccessful. Our provider in PHL has been acquired twice over the past couple of years, and it seems that the ticketing portal we were used to paging them with had been deprecated and our account had not been migrated to the new system. We were unable to reach them until their normal office hours opened at 14:00 UTC. Our provider restored our access to the priority ticketing system and began to investigate the issue. Eventually they were able to convince Cogent to reduce the null route from our entire /24 to a narrower /32 focusing on the specific IP address being targeted by the DDoS. As a result, service was mostly restored by 18:00 UTC. At about 06:30 UTC the following morning, the DDoS escalated and broadened its targets to include other parts of our PHL subnet. In response, our colocation provider null routed our subnet once again. This subnet has been unreachable ever since. At 09:00 UTC, I made the call to perform an emergency migration to AMS and restore from backups. We began urgently planning the scope of this work, making an assessment of our backups and the Amsterdam installation’s capacity to host a fully functional SourceHut installation, and planning the work that needed to be done. We verified the health of FRE and AMS and our backup systems, finding that our standby database was less than 30 seconds out of date with production and that our large storage backups were no more than 12 hours old. We found that AMS was in good health and we touched up a few research systems (e.g. Ceph) to bring them to production readiness. What essentially followed was creating a new installation of SourceHut from scratch, importing production data, testing and verifying the installation, and bringing it online for user service on a new DDoS-resistant network. This involved hundreds of small tasks that we planned out and distributed among ourselves and executed as urgently as possible, the full details are too involved to repeat here. However, the general plan had the following broad strokes: Migrate to external DNS Bring up a new primary database Restore backups from FRE to AMS Migrate object storage from PHL to AMS Bring up database-only services, such as meta, todo, project hub Bring up large storage services as backup restores finish Manually apply the diff between production data and the last backups Provisioning a new mail system and configuring mail services for it Identify a suitable DDoS-resistant network to bring us into general service Provision servers to backfill AMS capacity to production readiness Test the new systems and bring them into general service All of this work happened in parallel and had cross-dependencies, so from here on out we will omit some timestamps. Network solutions The selection of a suitable network to bring into service that would not immediately collapse as the DDoS attack followed us presented some challenges. First, this was a layer 3 attack, which can essentially only be mitigated by having more bandwidth than the attacker and/or by filtering traffic at a location suitably far upstream. Furthermore, many DDoS protection systems only operate at the application layer, namely for the web as the application in question, whereas SourceHut has user-facing services through not only HTTPS but also SSH, SMTP, and IRC; moreover we strongly prefer to utilize end-to-end encryption on all traffic and terminate it on SourceHut-operated infrastructure. We initially researched a number of solutions, and spoke to Cloudflare in particular due to their ability to provide a rapid response to ongoing incidents. However, given our complex requirements, Cloudflare quoted us a figure which was not attainable within our financial means as a small company. Other options we researched (though we did not seek additional quotes) had similar economical constraints. However, we found that OVH’s anti-DDoS protections were likely suitable: they are effective, and their cost is amortized across all OVH users, and therefore of marginal cost to us. To this end the network solution we deployed involved setting up an OVH box to NAT traffic through OVH’s DDoS-resistant network and direct it to our (secret) production subnet in AMS; this met our needs for end-to-end encryption as well as service over arbitrary TCP protocols. We also got in contact with our network operator in AMS and explained the situation to them. We found some solutions to mitigate attacks directed at AMS but we will not disclose details regarding the AMS network for reasons of information security. We made some mistakes throughout the operation, rsyncs done incorrectly, networks misconfigured, and so on. One particularly amusing mis-step occurred when we configured the NAT through OVH: we naively NAT’d all traffic through to AMS, and when the attack resumed targeting our OVH infrastructure, the inbound DDoS was briefly forwarded to AMS before OVH’s mitigations kicked in, which made our brand new OVH account look like the source of an outgoing DDoS, with predicable consequences that took some work to resolve with OVH. Following our initial quote from Cloudflare, we understand that some Cloudflare employees undertook a grassroots effort internally to convince the leadership to sponsor our needs, and eventually Cloudflare came back to us with an offer to sponsor our services for us free of charge. This was a very generous offer for which we are very appreciative; in the end we did not take them up on it as we had made substantial inroads towards an alternative solution by that time. I have had my reservations about Cloudflare in the past, but they were there for us in a time of need and I am grateful for that. On January 12th, our network provider in PHL agreed to provision a temporary subnet through which we could receive out-of-band access to our PHL servers. We were able to speed up the provisioning of replacement infrastructure thanks to this being made available. Provisioning services Efforts to restore individual SourceHut services came with a variety of challenges. Some of them were fairly straightforward; services like paste and the project hub depend only on a working SQL server and once we had that in place we were able to restore them to service at about 19:00 UTC on January 11th. git.sr.ht and hg.sr.ht had special considerations due to the large amount of data they were responsible for. We restored them from backups to read-only service based on somewhat stale data by 20:00 UTC, and restored to full read/write service by 11:00 UTC on January 13th. We also did our best with hg.sr.ht, but it is community maintained and restoring service was delayed until we could get the community maintainer, Ludovic Chabant, online to help; it was fully restored at 08:20 UTC on January 15th. pages.sr.ht also presented unique challenges due to its use of an S3-compatible object storage solution, which we discovered was not considered in our off-site backups. However, it was a priority to restore service to bring online the numerous personal and project websites which depend on pages.sr.ht. Migrating object storage from PHL to AMS is a slow procedure which is still underway now, we are running pages through an out-of-band link to PHL which comes with some performance limitations but provides service while the slower migration process is underway in the background. Pages also had to be moved to a new subnet and IP address, which posed a problem for users who configured their apex records to point directly to the PHL subnet; we have now emailed affected users with instructions for manual intervention. chat.sr.ht also poses some unique constraints due to its approach to networking; for a number of reasons we implement outbound IRC connections on a unique IPv6 address per-user. Preparing the requisite network infrastructure and bringing it online required special considerations and as a consequence chat.sr.ht was the last service to be restored to full operation at 10:30 UTC on January 17th. builds.sr.ht also required some extra considerations due to the fact that our research installation in AMS was under-provisioned for its compute requirements. Currently we are running build workers on dedicated baremetal OVH servers and we are planning to bring build service back onto SourceHut-operated infrastructure once we are able to ship our builds-oriented compute servers from PHL to AMS in the coming weeks. We began accepting build jobs again at 18:00 UTC on January 16th. All told, we began restoring partial service availability on the afternoon of January 12th, and gradually brought up services over the following days until full service was restored on the morning of January 17th. Following the complete restoration of service we credited all paying SourceHut users with 7 days of free service. What’s next We have completed all user-facing steps required to restore SourceHut to full service. However, we have numerous tasks to perform internally to put the finishing touches on the new installation and to clean up workarounds and hacks put in place to restore service as quickly as possible. We have an internal bugtracker with about 60 post-incident tasks to be completed, some of which are finished and others which are still underway: for instance, we have provisioned a new standby database, configured backups from AMS => FRE, and we are working on installing a new monitoring system. We are also deprecating our PHL datacenter installation entirely. We still cannot reach the network there, and the operator has egregiously exceeded their SLA with us. We will pack up the servers in PHL and ship them to AMS to supplement capacity there. Ironically, this emergency migration allowed us to quickly achieve many of the long-term goals we had in mind for migrating to the EU. We are now running almost entirely on European infrastructure and we quickly finished bringing many of our plans to ensure future scalability and reliability of SourceHut infrastructure to production readiness. We had planned to do these upgrades without user impact, but, well, alas. Part of the work involved in setting up the AMS datacenter installation was geared towards increasing resilience, reliability, and redundancy, and reducing the impact of attacks and outages of this nature. SourceHut is still in an “alpha” state, and though we have built a platform that is sophisticated and depended on by numerous free software projects, that comes with some caveats. This incident exposed one such caveat, a shortcoming that we were aware of and actively working on improving, but which was exploited before we could complete our goals for redundancy and resilience. Our definition of production readiness, our “definition of done” for the alpha, includes building infrastructure that prevents this kind of outcome. We have made unexpectedly urgent inroads on these milestones, and we will continue to build out these solutions as part of our work to bring SourceHut from alpha to beta to production. In the service of this work, we have been researching a solution for running SourceHut in an on-premise Kubernetes cluster (cue gasp from the audience). The migration to AMS did not involve a migration to Kubernetes, but it did put us in a better position to expedite that work. We intend to utilize this work to reduce user-impacting downtime during internal maintenance, such as when scaling up our infrastructure or upgrading software, but also to improve our resistance to events such as the one that transpired this week. Once we have completed an implementation of this solution, we will be planning out a secondary production-ready datacenter which we can load balance against and which can step up to take on full service in the event of a datacenter outage, as well as making it easier to conduct the procedures that we employed this week to stand up SourceHut from scratch in a new datacenter should the need ever arise again. As unfortunate as these events were, we welcome opportunities to stress-test our emergency procedures; we found them to be compatible with our objectives for the alpha and we learned a lot of ways to improve our reliability further for the future. We are going to continue working on our post-incident tasks, building up our infrastructure’s resilience, reliability, and scalability as planned. Once we address the high-priority tasks, though, our first order of business in the immediate future will be to get some rest. Acknowledgements I’d to acknowledge those who helped us in this difficult time. Of course, I extend my thanks to the rest of the staff, Simon and Conrad, whose long hours of work ensured we could restore service for our customers as quickly as possible. I would also like to thank the staff and network operators at our various datacenter locations, for their role in facilitating our needs in the rapid bring-up of new infrastructure. Thanks especially to the community members who sent us their words of support and kindness, and offers of aid, via email, Mastodon, on IRC, and so on. Thanks are also due to our peer in the free-software-forge space, Codeberg. They hosted our status page prior to the incident, and likely faced their own DDoS attack in retaliation for the services they provided to us. We shared information across our teams extensively and their communication and relationship with SourceHut has always been superb. I’d also like to thank the team at Cloudflare; though we did not accept your generous offer we were appreciative that you were there for us in a time of need. On a personal note, I would like to thank my fiancé for their patience and unwavering emotional support during a challenging time. Thank you all for your patience and support. – Drew DeVault",
    "commentLink": "https://news.ycombinator.com/item?id=39056902",
    "commentBody": "Sourcehut network outage post-mortem (sourcehut.org)262 points by ggpsv 18 hours agohidepastfavorite84 comments tetha 14 hours agoI find it somewhat chilling how their original colo left them to hang and dry. Maybe I'm weird, but I'd consider colo to be a closer cooperation than just renting some virtual servers from wherever. And just getting told \"Yupp, your null-routed. No, we can't give you access for specific sources over a different path. Get fucked\" - or, in fact, not getting told that - is ... one of our ex-hosters was like that. And as a service provider, I have strong feelings about the customer service there. Maybe I don't know big infrastructures, but this just leaves me with a weird feeling in my guts. But hell. Make sure to give your engineers - and their family - something. After some hell-weeks, we've given people some budget to do something fun with their family, because the company had to take so much private time during those weeks. reply dsr_ 10 hours agoparentCorporations gonna corporate. And when they merge and buy each other, information disappears. People get fired or leave, dropping relationships. I had a ten year colo relationship with AT&T, mostly but not entirely datacenters, where the salescritter would be changed every single time I tried to talk to them. 3-4x a year, they either left or were re-org'd elsewhere or our account was moved to a different group. (Datacenter techs: competent. Datacenter manager: competent. Sales staff: chaotic.) Eventually I learned to open a ticket to find out who the salescritter would be. On the other hand, there was a competent server salesperson at company X who I used to buy lots of stuff from; company X started raising prices and flubbing tech support returns, so on my next order I tried company Y. I was rather surprised to get the same server salesperson -- who had just taken a job at Y. reply jabart 12 hours agoparentprevDepends on the contract and the attack size. Sometimes the DC has to pick all it's other customers over trying to handle a DDoS for one. Our DC had an issue where packets over 1492bytes were being dropped in Chicago by one transit provider and that took 3 hours to make the call to drop them. reply downrightmike 13 hours agoparentprevbeing null routed is really the only thing they can do. Then then undid it and they had to do it again. This wasn't a standard DDOS attack, which they normally handle just fine. Good coverage of the event: Security Now! Podcast https://www.youtube.com/watch?v=ehfV7cRLkFE reply iso8859-1 3 hours agorootparentSubscribed and the unsubscribed shortly after when they mistook Greenland for Iceland (42m55s), Italy for ??? (43m42s) and then Equatorial Guinea for Chad (44m55s). reply aidenn0 13 hours agorootparentprevAbout 29minutes in is where it picks up after reading verbatim the status report from Drew. reply MaxBarraclough 10 hours agorootparentprevDrew's second mention on Security Now, for what it's worth. Gibson quoted one of his blog posts back in September. https://www.grc.com/sn/sn-941.htm reply svieira 14 hours agoprevLooks like Cloudflare did change their minds later and offered to mitigate the attack pro bono: > Following our initial quote from CloudFlare, we understand that some CloudFlare employees undertook a grassroots effort internally to convince the leadership to sponsor our needs, and eventually CloudFlare came back to us with an offer to sponsor our services for us free of charge. This was a very generous offer for which we are very appreciative; in the end we did not take them up on it as we had made substantial inroads towards an alternative solution by that time. I have had my reservations about CloudFlare in the past, but they were there for us in a time of need and I am grateful for that. reply zeroclicks 14 hours agoparentTypical \"corporate pricing\"--they offer a really high price they'll expect you'll negotiate downwards to something reasonable. The Sourcehut negotiators probably never dealt with this kind of \"sales model\" before. That said, what will happen when more companies publish their experiences with \"enterprise sales\"? There's an article from HEY[1] about how broken the sales process is. To get a quote, you normally have to endure 2 or 3 zoom calls before the price is unveiled. There's probably room for an innovator to fix all of this. 1: https://world.hey.com/dhh/the-only-thing-worse-than-cloud-pr... reply drewdevault 14 hours agorootparentWe did negotiate them down a bit but we didn't feel that we could come to an agreement within our budget and decided to move on. Apparently this was an excellent negotiation tactic because they came back with an offer of $0! reply ralph84 9 hours agorootparentprevIt’s not broken per se. Charging different customers different prices based on their willingness to pay maximizes profits. Heck even Sourcehut does it, but they don’t require interacting with sales because at their pricing they don’t have enough margin for a sales team. reply hypeatei 17 hours agoprev> As unfortunate as these events were, we welcome opportunities to stress-test our emergency procedures; This right here is invaluable and something you only get from experience. Planning and theory only get you so far. I extend this thinking to deploying large infrastructure changes you've never done before - you can only plan so much before pulling the trigger and just doing it and seeing what happens. reply 20after4 6 hours agoparentWikimedia's operations team go through a full-datacenter failover regularly. That is, once every 6 months or so. It takes several hours of intense all-hands-on-deck operations. They do this repeatedly in order to be sure that all of the procedures are practiced and documentation is well maintained. reply kyrra 17 hours agoprevI've been using Sourcehut for a couple years now. One thing this outage taught me about the service that I didn't know is that Mercurial (hg) is community maintained: > We also did our best with hg.sr.ht, but it is community maintained It looks like git.sr.ht is hosted on OVH in France, while hg.sr.ht is hosted on High5! in the Netherlands. It's not entirely clear to me how this affects their product roadmap or support, but definitely good to know. reply twic 14 hours agoparentThis also came as a surprise to me! Not only that but: > restoring service was delayed until we could get the community maintainer, Ludovic Chabant, online to help Maintainer, singular! The only reason i use Sourcehut, and the main reason i pay for it, is because i stubbornly still use Mercurial, and want first-class support for it. With the utmost of respect to M. Chabant, that is not exactly first-class. reply nequo 14 hours agorootparent> With the utmost of respect to M. Chabant, that is not exactly first-class. It would appear that Ludovic Chabant is working full-time at Epic Games. He is unlikely to have the capacity to be on call for Sourcehut. reply vanderZwan 13 hours agorootparentI think the complaint was aimed at Sourcehut leaning on a sole volunteer for this service, not at Ludovic Chabant reply drewdevault 1 hour agorootparenthg.sr.ht would not exist if not for being community maintained; the cost/benefit ratio does not work out in its favor were we to maintain it internally. The deal is that we provide infrastructure and operations but that the software itself is maintained by the community that needs it. I think this is an advantage of SourceHut's free software model and ethic that allows people to build what they need and to get its infrastructure needs met in a way that wouldn't be possible, for example, on GitHub. reply drewdevault 14 hours agoparentprevhg.sr.ht is operated by SourceHut, but the software is maintained by the community. Ludovic is the primary maintainer and various other Mercurial users participate in its development. reply skywal_l 17 hours agoparentprev> It looks like git.sr.ht is hosted on OVH in France They explain it here: > However, we found that OVH’s anti-DDoS protections were likely suitable: they are effective, and their cost is amortized across all OVH users, and therefore of marginal cost to us. To this end the network solution we deployed involved setting up an OVH box to NAT traffic through OVH’s DDoS-resistant network and direct it to our (secret) production subnet in AMS reply pelagicAustral 17 hours agorootparentThat's such an odd choice for this type of infra. I've had horrendous experiences with OVH in the past and what even worse, terrible customer service. Yes, this was about 8 years ago, and not with France based metal, but still... Being that this is Drew, I wouldn't be shocked to know that this provider choice has more to do with an anti-establishment manifesto than any practicality. Then again, I might be wrong. reply DistractionRect 16 hours agorootparentWell, it's certainly better than their last provider who they couldn't reach during a critical time, and still cannot reasonably communicate with. They can at least reach and reason with OVH, as mentioned when they got flagged as an out bound DDoS. > Being that this is Drew, I wouldn't be shocked to know that this provider choice has more to do with a anti-establishment manifesto than any practicality I feel this is a pretty unfair barb considering one of their first moves was reaching out to Cloudflare. Unfortunately, non-http traffic + the need for tls termination on their own servers (pretty sure cloudflare calls this Keyless SSL) squarely lands them as an enterprise customer w/ enterprise pricing. Drew probably had already entered into agreements with OVH when cloudflare came back around, and we don't have insight on the terms or period for which Cloudflare's second offer was good for. reply elpy1 8 hours agorootparentprev> Being that this is Drew, I wouldn't be shocked to know that this provider choice has more to do with a anti-establishment manifesto than any practicality Not wanting your traffic MITM'd is anti-establishment. That's where we're at LOL. reply moberley 13 hours agoparentprevFor me there a bit of a language barrier with the terminology. After reading the sentences about hg.sr.ht and community maintenance it seems that some notable meaning is being conveyed about what that means for the operation of the service but its one I'm not smart enough to understand. I appreciate the service though so I hope the differences between maintained and operated doesn't mean anything in the long term. reply vander_elst 13 hours agoprevMostly curious about the k8s plans. From some past posts it seems that the team was strongly against employing containerization [0]. However, it seems something changed. If anyone has more info about this if love to hear more. [0] https://news.ycombinator.com/item?id=23030489 reply scandox 17 hours agoprevI'm still left not quite certain what would happen if they were hit with another L3 DDOS tomorrow. That said I'm very happy to use Sourcehut and I think they'll overcome these challenges over time. They seem to have the staying power. reply mrled 16 hours agoparentI am really curious if the DDOS tried to follow them to the new infra and failed to cause an outage or not. Apparently the perpetrator noticed when they got Cogent to narrow the null route, but the blog post notes they still can't access the original subnet in that datacenter. Are they still trying to knock Sourcehut offline? Is the DDOS still pointing at now deprecated infra for some reason? reply wpm 12 hours agorootparentWhen they switched DNS over to point to the AMS datacenter, the DDOS attack followed it until it got smacked down by the OVH NAT. reply caboteria 15 hours agorootparentprev> At about 06:30 UTC the following morning, the DDoS escalated and broadened its targets to include other parts of our PHL subnet. In response, our colocation provider null routed our subnet once again. This subnet has been unreachable ever since. reply mrled 14 hours agorootparentRight, that's expanding to the rest of the subnet in their old DC. They've since migrated to the new DC with new countermeasures. Did the DDOS follow and the countermeasures are working? Or if it didn't follow, why not? There's also the question of whether the DDOS is still even trying the old infrastructure. The post says it's unreachable, but that would be true if the null route hadn't been removed yet. reply drewdevault 14 hours agorootparentYes, the DDoS followed us to networks with countermeasures, and yes, the countermeasures worked. We don't want to disclose too much about that, though. reply frakkingcylons 16 hours agoparentprevThey’re on OVH now and should have protection from it by virtue of being on their network now. > However, we found that OVH’s anti-DDoS protections were likely suitable: they are effective, and their cost is amortized across all OVH users, and therefore of marginal cost to us. To this end the network solution we deployed involved setting up an OVH box to NAT traffic through OVH’s DDoS-resistant network and direct it to our (secret) production subnet in AMS; this met our needs for end-to-end encryption as well as service over arbitrary TCP protocols. reply treesknees 12 hours agorootparentI'd consider it mostly protected, because no their servers are not on OVH, just a single box performing front-facing NAT/proxy essentially. The attacker now just needs to find the \"secret\" production subnet and attack it directly instead of through the front-facing NAT addresses. reply bombcar 10 hours agorootparentThat is very easy to mitigate, because you null route the production subnet except for a VPN that only can be reached by the proxy. You can even VPN over a completely different IPv6 route. They could still try to knock your entire datacenter offline but that is much harder. reply frakkingcylons 10 hours agorootparentprevThat's true. I guess it'd be more accurate to say they're on OVH's network, not necessarily their compute and other infrastructure. reply makeworld 16 hours agoparentprevMy reading is that OVH would handle it. reply shrubble 17 hours agoprevWould have liked to know what the difference was in response between Cogent and Level3. Did only Cogent respond at all, or was Cogent the one handling all their IPv4 space? reply zeroclicks 15 hours agoparentSeems only Cogent was advertising their routes. Once Cogent blackholed their prefixes, there'd be no way to reach their services via the internet. reply rezmason 14 hours agoprevWild speculation: maybe the attacker's motive was to usher specific Sourcehut hosted repositories to the jurisdiction of the EU. reply ploum 11 hours agoparentOn a more serious note, I’m really wondering about the motivations. I see the following hypothesis: 1) Test/demonstration of a DDOS against a random target. 2) Attack against a project hosted on sourcehut to make it unavailable (there was even the speculation of disabling a master repository so an end-user could not check that his own local version was the correct one, thus using it with a security hole or a trojan) 3) Attack against a page hosted on sourcehut (I joke that someone wrote \"Putin = Fag\" on his sourcehut hosted blog). 4) What else ? reply miki123211 7 hours agorootparent5) Somebody very vehemently disagreeing with Drew's (often radical) views. This could also be a simple transphobe, though I expect those people to have far juicier targets to attack. reply SSLy 9 hours agorootparentprev1A) Test/demonstration of a DDOS against a service well know among some circles reply doublerabbit 12 hours agoprev> This outcome was unacceptable No it wasn't. The outcome is due to major networks being shite. Not accommodating newer technologies and gate keeping services to resolve DDoS attacks. All major network upstreams could do so much more to make the net more reliable and resilient to small ISP. Myself included. peer neutral networking, not having tons upon tons of e-waste prone to botnet behaviour, it wouldn't be like this. reply OsrsNeedsf2P 16 hours agoprevUnrelated, but TIL Drew DeVault is one of the SourceHut maintainers. His blog[0] is strongly opinionated and always an informative read. [0] https://drewdevault.com/ reply matthews2 16 hours agoparentYou don't need to agree with all of his opinions to use SourceHut :) I'm not a big fan of some of his hot takes, but I still respect him and trust him with my data. reply gray_-_wolf 16 hours agorootparentI stopped paying for sourcehut because his opinions are relevant here since he bans types of projects based on them. You never know when another restriction will be added. reply cornstalks 16 hours agorootparentIf you're talking about banning cryptocurrency and blockchain projects, personally that earned some favor in my eyes. I'm happy to use and pay for a service that doesn't contribute to that blight. For the curious, the terms are here: https://man.sr.ht/terms.md#permissible-use reply gray_-_wolf 16 hours agorootparentI also do not like \"crypto\", but I do not think this type of restriction is great on a paid service. Maybe, maybe it could be argued for public repositories. Or if it was free. But like, why does Drew DeVault care that I would have a private repository with \"explicit sexual content\"? On an account I pay for? And even if you agree with the current set of restrictions, are you sure it will not be further expanded? I am not. reply mrmanner 11 hours agorootparentI like when people bring their values when they do business. Especially when those values are more than “make money”, and expressed in more ways than product design. reply farhaven 12 hours agorootparentprev> On an account I pay for? On an account that you pay _Drew_ for. Do you also complain because someone renting you a garage doesn't want you running a strip club out of there? reply stonogo 10 hours agorootparentprevHaving dealt with this in the past, once you let cryptocurrency people onto a service they will stop at nothing to abuse shared resources for whatever mining fad is currently underway. As an operator, you can either hire staff for a full-time whack-a-mole game, get into arguments with customers about whether what they're doing is shitty even though it meets some pedantic interpretation of policy, or just ban the whole crowd and focus on customers who don't suck. As for banning sex content on a paid service, you'll find it's more common than you think, since payment processors tend to drop customers who permit that sort of thing. Porn-enabled services have chargeback and failed-charge rates orders of magnitude higher than services which forbid them. There are a ton of reason to fire a client. The two mentioned here are completely uncontroversial from a business standpoint. reply eesmith 15 hours agorootparentprev> why does Drew DeVault care that I would have a private repository with \"explicit sexual content\"? For the same reason GitHub does? GitHub's AUP at https://docs.github.com/en/site-policy/acceptable-use-polici... says: \"We do not allow content or activity on GitHub that: ... is sexually obscene or relates to sexual exploitation or abuse, including of minors\". Atlassian's AUP at https://www.atlassian.com/legal/acceptable-use-policy says \"Inappropriate content\" includes \"Posting, uploading, sharing, submitting, or otherwise providing content that ... Is deceptive, fraudulent, illegal, obscene, defamatory, libelous, threatening, harmful to minors, pornographic (including child pornography, which we will remove and report to law enforcement, including the National Center for Missing and Exploited Children), indecent, harassing, hateful\"? GitLab's AUP at https://handbook.gitlab.com/handbook/legal/acceptable-use-po... says \"unacceptable use of our services [which] applies to all users of all GitLab services including those on the Free, Premium, and Ultimate GitLab tiers\" mean \"you must not: Create, upload, submit, execute, transmit, or host anything that ... is vulgar, obscene, or pornographic, or gratuitously depicts or glorifies violence.\" Now, there are differences between \"explicit sexual content\", \"sexually obscene\" and \"pornographic\", but if you are worried about possible further expansion, you shouldn't use any of these code hosting services. reply gray_-_wolf 15 hours agorootparentThe reason does not seem to be stated at the provided link. If you know the reason (which your message seems to imply), could you please share it? reply cornstalks 15 hours agorootparentIt's hard to find a payment processor for pornographic providers. Existing payment processors are likely to stop supporting you if you become a porn provider. Additionally, there are branding risks in being associated with adult content. There's also more legal scrutiny involved, and it's outright illegal in some jurisdictions. A simple Google search on the topic should be educational. reply eesmith 15 hours agorootparentprevI was conjecturing it was the same reason as the other hosting providers, not saying that was the same or that I had special insight. Instead, I was pointing out that since all the providers I looked at have essentially the same restriction, you likely shouldn't use any of them. Certainly there are a lot of people who use GitHub despite having no guarantee the ToS won't be more restrictive in the future. Sourcehut's ToS is certainly not exceptional in that regard, so really you are objecting to essentially every 3rd party code hosting provider, yes? Or is there one you had in mind where you aren't concerned about further expansion? reply dijit 14 hours agorootparentprevYou know, it's fair not to support the service on that principle, However, Sourcehut is actually FOSS software. IE: if you wanted to run one of their banned things, you could, just on your own hardware. It's fine, in my opinion, to moderate your services if people have an escape hatch to get out of your service if you require them to move along. This is a far cry from services such as GitHub, or even Gitlab (with their open core) as transferring to your own system is actually possible, though not without some relative pain. I don't like crypto projects, so of course I am biased here. But if you like free speech then there's not many options and I think sr.ht is the best one (especially if you plan to self-host). GitHub is well known to be controlling of speech and even championed some measures that affected the entire industry, and as others have mentioned they have restricted projects on a relatively arbitrary basis. Sometimes even due to geographic region. reply cinntaile 14 hours agorootparentprevThis also keeps me away from sourcehut. I like everything else about it but this is a deal breaker. reply beanjuiceII 12 hours agorootparentsame for me reply Gentil 4 hours agorootparentprevAll services have permissible use clause in their terms & conditions. And if this is about cryptocurrencies and blockchain. It's absolutely a valid choice for a small service provider to block them. They are resource hungry and resource abusive. A small provider like SourceHut can't afford to take that unnecessary stress. VC funded or big players can. And they do that for easy, quick & short boost in money or marketing PR. Also, I always have observed this. This reminds me. Not targeted at gray_-_wolf but a general observation which I just remembered... There is a trend where people attack small actors/entities for smaller mistakes or opinions. But give free card to big players you cannot touch for atrocious BS. Because they are monopolies or filty rich. Especially in tech, you don't talk shit about google or ms a lot publicly. Cos that makes you less hirable. reply jraph 12 hours agorootparentprevI find this refreshing that someone does business according to their values, not allowing money to buy everything. I believe generally letting things happen as long as money comes without any regards to values behind the things might have been detrimental. reply sneak 16 hours agorootparentprevThe reason I don’t use srht is because of his opinions about product development (of srht itself), not his personal opinions. Social/collaboration features are explicitly deprioritized by design; I think this is a natural consequence of srht being built by and for lone wolf developers. GitHub and Gitea (which is basically a github clone) seem much more geared toward collaboration by groups, something most small-time f/oss developers don’t need. Also, the emphasis on email and irc is bad, imo. The web won because it is better. A lot of the anti-web stuff is just tradition. reply xigoi 14 hours agorootparentEveryone has an e-mail account. That means if you want to contribute to a project on SourceHut, you don’t need to create an account there. Also, I hate when I’m looking for useful forks of something on GitHub and have to sift through tens of useless forks that were created just to be able to submit a pull request. reply bombcar 10 hours agorootparentThose “onetime” forms are blight on GitHub. Sometimes useful when the main project gets nuked or deleted, if you can find them. reply tslocum 16 hours agorootparentprevAs someone who was there in the early days, who joined the chorus of people warning Drew about the effects of such a policy, I just want to say that Forgejo is a treat to self-host and use. Gitea is now open-core, and its future is unclear. https://forgejo.org reply mroche 14 hours agorootparentThis really comes down to the intended workflow. By design, SourceHut aims to provide the Linux kernel development model to a wider audience (with extra features beyond mail and Git). It is a very different collaboration model than the likes of GitHub and its peers. I summarize the comparison of the two as \"to each their own\"; I'm okay with both models and see the merits of both, but my preferences and willingness or ability to work with a given model won't always line up with contributors. I also self-host Forgejo in my homelab and really enjoy it. reply zufallsheld 14 hours agorootparentprevThe only mention I can find that gitea is open core comes from forgejo. Do you have some kind of proof that there are parts of gitea that are not MIT licensed? reply johnmaguire 14 hours agorootparentGitea Ltd's stance seems to be that it does \"custom development\" support contracts.[0] It may be a matter of perspective whether you consider this \"open-core\" or \"contract work.\" See also their clarifications on Gitea the company[1]: > Gitea Ltd. will be open to building special versions for special clients and will contribute any features back to the main repository when possible This was in a followup to the original announcement.[2] Forgejo (i.e. Codeberg, a FOSS non-profit) maintains that the project should be led by the community, not a company[3]: > Sadly, Gitea Ltd broke that trust by a lack of transparency: its existence was kept a secret during months. After the initial announcement, Gitea Ltd published another blog post but it was still vague and there has been no other communication since. Who are the Gitea Ltd shareholders? Who, among the Gitea maintainers, are employees of Gitea Ltd? [0] https://about.gitea.com/pricing/ [1] https://blog.gitea.com/a-message-from-lunny-on-gitea-ltd.-an... [2] https://blog.gitea.com/open-source-sustainment/ [3] https://blog.codeberg.org/codeberg-launches-forgejo.html reply tarxvf 16 hours agorootparentprevThat the social and communication tools they prefer are not the tools you prefer does not mean they are asocial. reply kstrauser 15 hours agorootparentThat's so true, but I agree with sneak here (did I just write that?). If my code is on GitHub or GitLab or Gitea or whatever, and I want to work on it with a friend, I can invite them to join me on a website using a workflow similar to 1,000 other not-source-code-related collaboration tools. It's damn near impossible to talk someone into joining an email-based process unless that's something they've already been doing elsewhere. Look at the git-send-email docs[0] which talk about configuring SMTP auth. Followup question from the new person I'd be trying to rope in: \"I dunno, my work uses Outlook. What's SMTP?\" If someone contended that SourceHut optimizes for devs who've been writing Linux kernel code for 25 years, so you weed out all the newbs and can get the hardened veterans involved in your project, I could buy that. I'd disagree that it's what I'd want for my project, but to each their own. I couldn't recommend it as an alternative to other services that require participants to know how to use a web browser. [0]https://git-scm.com/docs/git-send-email reply myaccountonhn 12 hours agorootparentOnce you learn the git-send-email flow, it is a lot better, especially for distributed development. With the PR flow, people need to sign up to the website, create a fork, clone the repo, make their changes, go into a slow web ui etc. It mostly works because everyone is on Github. However, even that solution sucks if you are having a polyrepo setup and need to make changes in many places. For bazaar style development where you accept contributions from anyone and don't use Github, the email flow is so much faster and simpler. Yes, you need to set it up once. But the other day I contributed to a open source project that was self-hosted, and it's amazing that I just can clone the repo, make my changes, commit and then git-send-email, bam done. Had I needed to sign up and create an account, set up a fork, I probably wouldn't have bothered because it was a small contribution. However no need to register to a website, no need to click through a slow ui, no need to create a fork, it reduces the ritual to make contributions by quite a lot, given that you've set it up. There is also https://git-send-email.io/ which provides a nice tutorial for people. I am glad that there is a good alternative that supports this flow, because I think it is superior. There are a ton of alternatives if you want the PR flow (Gitlab, Gitea, Github, Codeberg). reply avgcorrection 11 hours agorootparentprevI’ve done the email workflow for a bit. I’ll say this much: it might be comparable to configuring a power editor vs. using some powerful and ready-to-go IDE. You can set up things how you like and the preferences of everyone else doesn’t really matter. You can also just edit anything because it’s fast and there is probably a good enough configuration for all kinds of languages and modes. But in some ways it isn’t. Like any fool (like me) can just get some Emacs configuration for free from others. There doesn’t seem to be that kind of sharing for all the fiddly little things you need to do with git-send-email and the rest. All I’ve heard so far is that, oh yeah I usually deal with this specific issue by running some Perl scripts that I wrote eight years ago and that I’ve been nurturing ever since. But it wouldn’t be very useful for you because it’s very, very idiosyncratic. Might not even work outside Debian and my Apt state... reply avgcorrection 28 minutes agorootparent> But in some ways it isn’t. Like any fool (like me) can just get some Emacs configuration for free from others. To be clear though: there are programs and tools beyond the git(1) tools themselves that help you with email workflows. Like b4 which is for the Linux workflow. https://github.com/mricon/b4 reply bombcar 10 hours agorootparentprevA few plugins to allow git-send-email to work without much configuration by using your existing Outlook or Gmail or Thunderbird setup (basically, a git plugin for outlook) would be very desirable. reply avgcorrection 45 minutes agorootparentThat might be intractable. Some clients will rewrite/corrupt (whatever you want to call it) messages before sending. Like maybe it reflows paragraphs and ruins your inlined diff. Or it helpfully replaces tabs with spaces (the project requires tabs). So what can you do with that? Doesn’t seem like you can do anything. Outlook seems especially bad. [Here] is some HN hearsay about how even Microsoft had to run Linux machines in order to contribute to the Linux project. [Here]: https://news.ycombinator.com/item?id=12621135 reply kstrauser 16 hours agorootparentprevI adore Gitea. 99% of the stuff I keep there is private code, where Gitea is basically an SSH-able Git remote. However, I occasionally want to share a project with a friend, and then it's trivially easy to invite them to collaborate with me using the same infrastructure I was already using. Minus that last part, I'd just stick with plain Git. It's everything I need for my own personal, only-for-me projects. reply avgcorrection 12 hours agorootparentprevAre they deprioritized (spelling dunno)? Or are they just different in a way which you judge as being not-conducive to collaboration? (I mean you mention mailing lists.) There’s not really much need for a “forge” without collaboration. I wouldn’t pay the price of SourceHut just so that I can fetch and whatever between my machines. That’s like a pricey sneaker net. reply zilti 2 hours agorootparentprevLOL! That something wins because it's better almost never happens. Your example included. reply mortallywounded 16 hours agoparentprevMaintainer? More like creator. reply j4yav 15 hours agorootparentArent open source project maintainers typically the creators? reply otachack 16 hours agorootparentprev¿Por qué no los dos? reply trevyn 16 hours agorootparentprevOpinionated? More like firebrand. reply imiric 10 hours agoprev [–] I admire Drew's work and SourceHut, but I wonder if choosing colocation instead of a cloud provider, and not adopting modern cloud tooling hurt the recovery time. The article mentions how setting up SourceHut from scratch is a complex undertaking with hundreds of small tasks. Some of those are understandable, especially given the amount of data they surely handle, but setting up a complete environment and restoring from a backup should be a simple and mostly automated procedure, not a gargantuan undertaking that needs to involve the entire team several days. There are always difficulties when production is down, and you're trying to restore a full system while undergoing a DDoS attack, I get that, but the reason we have modern cloud providers and tooling is to make creating new environments as painless as possible. It seems foolish not to take advantage of that. I'm not a fan of Kubernetes either, but it's good that they're experimenting with it. Hopefully it leads to quicker deployments if this happens again. reply nullwarp 10 hours agoparent [–] Cloud isn't a dependency to accomplish this. I can stand up new instances of our primary infrastructure within minutes on any VM or server running linux and our agent. This sounds like a case of treating your infra as pets and getting stuck when it suddenly needs to be replaced. reply Aeolun 2 hours agorootparent [–] That’s not really a surprise considering how they started? To some extend I think it’s unavoidable if you use colocation. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SourceHut, a datacenter, suffered a prolonged 170-hour outage as a result of a DDoS attack and emergency migration.",
      "Although some services have been restored, there have been difficulties and delays in fully recovering.",
      "SourceHut is taking steps to prevent future incidents, such as strengthening infrastructure and enhancing redundancy, and is actively exploring solutions to minimize downtime and enhance resilience to similar events."
    ],
    "commentSummary": [
      "The discussion revolves around various topics related to Sourcehut, a software development platform, including network outages, experiences with service providers, and issues with maintaining the Mercurial service.",
      "There is speculation on the motivations behind a DDoS attack on Sourcehut, as well as discussions about content restrictions and collaboration models.",
      "The article also touches on topics such as SMTP authentication, advantages of using the git-send-email flow, challenges in maintaining open-source projects, and the impact of cloud tooling on recovery time and infrastructure setup."
    ],
    "points": 262,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1705679740
  },
  {
    "id": 39061587,
    "title": "Firefox Faces Technical Challenges on Major Platforms",
    "originLink": "https://mozilla.github.io/platform-tilt/",
    "originBody": "Platform Tilt This dashboard tracks technical issues in major software platforms which disadvantage Firefox relative to the first-party browser. We consider aspects like security, stability, performance, and functionality, and propose changes to create a more level playing field. Further discussion on the live issues can be found in our platform-tilt issue tracker. Vendor: AppleExpand all Issue Status App Store forbids third-party browser engines#open Support for third-party multi-process applications on iOS#open JIT Support on iOS#open Accessibility APIs on iOS#open Messages integration on iOS#open Importing browser data on iOS#open Setting and checking default browser on iOS#open Origin-Based Associated Domains dependent features for third-party browser engines on iOS#open Browser extension support on iOS#open Beta testing on iOS#open Vendor: GoogleExpand all Issue Status Importing browser data on Android#open Some Android features launch Chrome instead of the user’s default browser#open Lower quality search result pages in third-party browser engines on Android#open Vendor: MicrosoftExpand all Issue Status Setting default browser on Windows#open Default browser is set to Edge by several Windows flows#open Some Windows features launch Edge instead of the user’s default browser#open",
    "commentLink": "https://news.ycombinator.com/item?id=39061587",
    "commentBody": "Platform Tilt (mozilla.github.io)250 points by SethMLarson 12 hours agohidepastfavorite48 comments nox101 6 hours agoThey mention both Android and Microsoft have some apps that don't launch the user's browser choice. I have a related problem which is apps that launch their own web view as a builtin web browser when you click a link in the app. This lets them spy on any web activity that you do while in that embedded web view. I think I wish that both the Android Play Store and the iOS App Store required apps to launch the user's browser for all 3rd party websites. To do this, they'd have apps categorize themselves as \"web browser\" or \"not web browser\". For a \"not web browser\", the app would have to make a short list of domains (5? 10?) that it's allowed to talk to. Any others would be blocked by the OS. For a \"web browser\" the app could contact any domain. I don't know what legalize like language they'd use to define \"Web browser\" but apps like Facebook, FB Messenger, Google Maps, and others who's primary use is not \"Browsing the web\" could be clearly in the \"not web browser\" category. There's multiple reasons I want this. 1. Apps with embedded web views can spy on all network activity and web view activity. By preventing apps from having embedded browsers that problem is solved. 2. Passwords, addresses, other things are synced in my browser profile. Every time some app launches an embedded browser I get none of that 3. Bookmarks are synced in my browser profile. Any sites I view in an embedded browser I can't bookmark 4. History is synced in my browser profile. Any sites I view in an embedded browser don't show up in my history One other feature I might require if I was ruler of the world is that these apps that launch links be required to support a context menu for \"open in private browser window\" reply tempestn 4 hours agoparentI feel the same way personally, but recently discovered that most others don't. When we launched the autotempest app we had it use the user's default browser for all third party links, which are common for us, as we link directly to vehicle detail pages on various other sites. Turns out people hated that, and really wanted to load those pages inside the app instead. (So we made that the default, but left the option to use the default browser.) reply baq 2 hours agorootparentI would prefer in-app view of links if apps wouldn’t have a broken back button. In-app web view back buttons go back to the app instead of one page back in the history. It’s driving me nuts. reply tempestn 32 minutes agorootparentWe did get that right at least! reply neongreen 3 hours agorootparentprevDid they provide any feedback on why they hated it, btw? reply tempestn 3 hours agorootparentNot really. My impression was that people just felt it was a cleaner experience having everything in the app. Objectively it didn't have a significant effect on load times either way, but I could see a couple of potential reasons that could make sense, like leaving around open browser tabs that would have to be manually closed. Also some may not know how to quickly switch back to the previous app. As well as giving the option to just open by default in browser, we do also now provide a button along with the webview to open a given page in the browser, which seems like a good balance to me. That way if you want it in browser for bookmarking or what have you, it's easy to get that, but if you just want to take a quick glance, there's no need to leave the app. reply vages 2 hours agorootparentI have observed non-technical people struggle with phone multitasking. They usually fail to notice the apps switching, and if they do, they often use a slow path back to the original app (for example opening an app via the Home Screen) rather than through the app switcher. reply wahnfrieden 2 hours agorootparentprevPeople don’t like littering tabs and changing the focused tab in mobile safari. And they don’t like switching back to another app instead of just closing a modal. The safari view component solves the privacy issue when adopted. reply naitgacem 5 hours agoparentprevthis is already the case, you can click open in browser. but I'm not sure it's in Google's best interest here. remember that it's been 9 generations of android major versions since they added runtime permissions for camera and such. internet access is still not requiring a permission... reply warkdarrior 2 hours agorootparentWhat are you talking about? Android apps must request the INTERNET permission to use the network. reply naitgacem 1 hour agorootparentI'm talking about a runtime permission, something like \"App_name wants to use internet\" with options \"allow once\" , \"while using the app\", and reject. Same with camera microphone storage etc. Internet is the reason camera and mic access are sensitive in the first place after all. reply TrianguloY 29 minutes agorootparentEdit: apparently they added it back! Now the play store shows the full permission list (and not that horrible simplified version). I missed the change. (Original incorrect post below) Not only that, but on the play store that permission isn't mention at all. Is like \"all apps will use it so why bother\" but some of us create apps without it, and we cannot probe it. reply filleduchaos 3 hours agoparentprev...don't points 2-4 (the sandboxing of the webview's context, so that it does not overlap with your actual web browsing activity or with other apps' webviews) contradict point 1 (the level of danger from apps' ability to control their own webviews)? > For a \"not web browser\", the app would have to make a short list of domains (5? 10?) that it's allowed to talk to. Any others would be blocked by the OS. What does \"allowed to talk to\" mean in practice? Off the top of my head, either you only check the domains of URLs that are explicitly navigated to (too lax, easily circumvented) or you check the URLs of literally every request (too strict, many developers would not be able to load their own sites). reply jstanley 40 minutes agorootparent> check the URLs of literally every request (too strict, many developers would not be able to load their own sites). This is why it's 5 or 10 domains instead of just 1. You just need to list every domain you actually use. reply akoboldfrying 6 hours agoparentprevI was sceptical at first, but the \"small whitelist\" concept really does provide a clear, fair and easily enforced delineation. reply zilti 2 hours agoparentprevNumber 2 is easily solved with a password manager, at least reply runlevel1 7 hours agoprev> App Store forbids third-party browser engines Mozilla is justified in challenging it, but I don't know if they want to go pulling that thread. Safari's monopoly on iOS devices is the only reason a sizable number of developers care about non-Chrome support. Currently, they have to. If the message to users becomes \"broken feature is not broken on Chrome\" we're on the road to monopolyville. And then Google really doesn't need consensus when it creates new web standards. The status quo is all sorts of messed up, but it could be worse. Hopefully I'm wrong about this. reply commoner 1 hour agoparentOf course it's in Mozilla's interest to challenge Safari's Apple-imposed monopoly on iOS. Firefox does not benefit from being suppressed on iOS just because Chrome is also suppressed on iOS. Removing Apple's restrictions that prevent Firefox from implementing Gecko and Gecko-based WebExtensions (especially ad blockers) can only increase Firefox's market share on iOS. Those new iOS Firefox users would then be encouraged to adopt Firefox on their desktop computers, because they would finally be able to sync desktop Firefox with an adblock-enabled Firefox on iOS. reply pjmlp 2 hours agoparentprevThe day it is free reign on iOS, I am betting plenty of people will install Chrome, basically all PC owners whose only Apple device is an iPhone. reply petesergeant 3 hours agoparentprevCame to say the same thing. Safari and the inability to replace it with Chrome on iOS is the only thing stopping the complete dominance of Chrome, for better or for worse reply bitpush 6 hours agoparentprev> Safari's monopoly on iOS devices is the only reason a sizable number of developers care about non-Chrome support. Sounds like you like monopoly. reply gleenn 6 hours agorootparentI don't think that's charitable. They are stating that iOS enforcing the second browser to exist makes at least some space for the third to exist and preventing Chrome from completely taking over. reply yjftsjthsd-h 5 hours agorootparentprevIf a small monopoly prevents a large monopoly, it might be the lesser evil. reply girvo 5 hours agorootparentprevTwo is greater than one. reply KTibow 4 hours agoprevAs an Android user the main reason I don't use Firefox is that it feels slower, not because of any anticompetitive behavior. In Firefox, there's often layout shifts when I load the home page, keyboard animations sometimes jump around, I can't use the \"release to select\" menu option, etc. reply recursive 4 hours agoparentI've been using it for years and never been able to notice this. reply yorwba 4 hours agoparentprevWhat is \"release to select\"? reply dang 8 hours agoprevRelated: https://blog.mozilla.org/netpolicy/2024/01/19/platform-tilt/ (via https://news.ycombinator.com/item?id=39059255, but no comments there) reply pmontra 2 hours agoprev> \"Google Search within the Google app\" Correct but I don't notice that because I search by opening Firefox and typing the search query there. It's an icon tap anyway. I don't use the search widget on the home screen, I removed it. reply Havoc 30 minutes agoprevGreat website...now we just need tech new reporters to be aware of it. reply lamontcg 6 hours agoprevCopy and paste in google colab works correctly with chrome and not firefox. reply sneak 8 hours agoprevRight-clicking a selection in macOS and selecting web search (perhaps only in Mail.app, I don’t recall) always opens Safari even if you have a different browser selected as default. They missed that one. reply shadowgovt 7 hours agoprev> Browsing information like history, bookmarked sites, and cookies isn’t accessible to third-party browsers on Android. As a user, why the hell do I want third party applications to be able to access my browser's history, bookmarked sites, and cookies? That's an obvious privacy leak! Firefox can have that data when it's generated by Firefox while I'm using Firefox and not in other contexts. reply crummy 7 hours agoparentAs a user who wants to easily migrate to a new browser, I would like the new browser to have access to the old browsers bookmarks etc to make the process easier. reply no-dr-onboard 7 hours agoparentprevThis is mostly for importing to/from other browsers. It’s a very common operation for onboarding. reply jwells89 7 hours agorootparentOne way to accomplish this that doesn’t make it easy for unscrupulous apps to suck up browser data is for the OS or stock browser to be able to export an archive of user data that Firefox (or other browsers) could then import. Adds a bit of friction but much more difficult to abuse. reply Qwertious 4 hours agoparentprev>As a user, why the hell do I want third party applications to be able to access my browser's history, bookmarked sites, and cookies? >That's an obvious privacy leak! No it's not. It's only a leak if they access that data without your permission. There's nothing wrong with them being able to request that data, with you-the-user being able to respond to that request \"fuck no\". reply pmontra 2 hours agorootparentBetter than that, add an export feature to Safari that must be activated by a user action. That would probably be in the spirit of GDPR's right to access one's own data. reply g-b-r 6 hours agoparentprevFor history and cookies it's definitely objectable, but it's essential that the bookmarks be exportable and reimportable. Something that Firefox on Android doesn't support, by the way :facepalm: https://github.com/mozilla-mobile/fenix/issues/417 reply naitgacem 5 hours agoparentprevI think this is disingenuous. we can already import contacts and other sensitive data with no \"privacy leak\". they're not requiring unvetted import functionality, from the issue: Android is able to mediate access to other sensitive data with user consent. reply johanbcn 55 minutes agorootparentYeah, but that means all major browsers agreeing on a standard, and we all know how that goes. reply charcircuit 7 hours agoparentprevI agree. The justification \"but desktop operating systems let us do it\" means nothing to me because desktop operating systems are known for having bad security. It only works on those systems because there is no security for programs reading each other's data. reply lxe 8 hours agoprevnext [5 more] [flagged] Borealid 8 hours agoparentWebUSB has... some issues. For example, there's a huge song and dance around a web site only being able to create and use a FIDO2 credential for its own domain (in other words, badactor.example can't get an assertion for goodactor.example). But with WebUSB, you can just have your web site directly communicate with a USB authenticator and send it whatever domain you want, not even using the browser's webauthn APIs! So... google blocked USB devices that respond with FIDO2 HID Report Descriptors from being usable over WebUSB. There are just so many of those types of issue, and the standard response seems to be playing whack-a-mole instead of requiring that a USB device be \"opt in\" or user-selected, which would make more sense to me. It's a huge attack surface. I don't like that this means you can Do More (TM) with Chrome(ium), but I'm also pretty happy not to have my web browser be allowed to reprogram my motherboard's fan controller hub. reply modeless 7 hours agorootparent> It's a huge attack surface. People say this about so many useful Web APIs. Bluetooth, WebGL, WebGPU. The truth is these APIs have largely been exposed to the web for many years now and the promised deluge of vulnerabilities never materialized. Sure, there have been a couple here and there but overall the security mitigations built in have proven very good and the security impact has been very minor compared to the dire warnings people gave. Other areas of the browser continue to be worse. reply lol768 8 hours agoparentprevMozilla's position on these specs is nicely outlined publicly and transparently as part of their standards-positions project: https://github.com/mozilla/standards-positions/issues/100 I'm kinda glad it's not implemented in my browser, to be honest, because the whole thing seems like a security nightmare. It's a shame it impacts some hobby usecases, but I don't think this outweighs the reasoning set out on the GitHub issue. reply o11c 7 hours agorootparent> I'm kinda glad it's not implemented in my browser, to be honest, because the whole thing seems like a security nightmare. You shouldn't look at the spec and think it's a security nightmare. Look at the history, so you can know it's a security nightmare. reply jwells89 8 hours agoprev [–] Most of these are understandable, but the one talking about Messages integration on iOS gives me bad vibes. Specifically a “recently sent links” API for Messages that the user must opt into wouldn’t be a problem but full access to message data is not something that I (and I suspect many others) would ever consent to a third party app having (even if Mozilla is the dev). As for extensions on iOS, Orion has the capability to install extensions from both the Chrome and Firefox extension galleries which would suggest this either isn’t actually a problem or slipped past App Review and has somehow remained available for years. reply captn3m0 1 hour agoparent [–] Yeah, Orion's support for Firefox extensions is a big red flag. These 2 issues on the Firefox-iOS tracker[0,1] around extensions and content blockers have long mentioned Orion, but there's no response from Mozilla. [0]: https://github.com/mozilla-mobile/firefox-ios/issues/7374 [1]: https://github.com/mozilla-mobile/firefox-ios/issues/9155 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary highlights technical issues that Firefox faces on major software platforms, such as security limitations, stability and performance issues, and functionality disadvantages compared to first-party browsers.",
      "Proposed changes are mentioned to address these issues, with a reference to a platform-tilt issue tracker for further discussion and details.",
      "The summary categorizes specific issues based on the vendors Apple, Google, and Microsoft."
    ],
    "commentSummary": [
      "The discussion revolves around the issue of apps launching their own web browsers instead of the user's preferred browser, sparking concerns about spying on web activity and maintaining browsing history.",
      "Suggestions are made to categorize apps as \"web browsers\" or \"not web browsers\" to address these concerns and provide user control over their browsing experience.",
      "Developers face challenges in determining which domains can be communicated with, leading to the use of a small whitelist, while restrictions on third-party browser engines on iOS devices, particularly Safari's monopoly, raise concerns. The discussion also touches on browser monopolies, performance comparisons, privacy issues, and security vulnerabilities in web browsers."
    ],
    "points": 250,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1705700488
  },
  {
    "id": 39061800,
    "title": "Microsoft Responds to Nation-State Attack by Midnight Blizzard",
    "originLink": "https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/",
    "originBody": "Microsoft Actions Following Attack by Nation State Actor Midnight Blizzard / By MSRC / January 19, 2024 / 2 min read The Microsoft security team detected a nation-state attack on our corporate systems on January 12, 2024, and immediately activated our response process to investigate, disrupt malicious activity, mitigate the attack, and deny the threat actor further access. Microsoft has identified the threat actor as Midnight Blizzard, the Russian state-sponsored actor also known as Nobelium. As part of our ongoing commitment to responsible transparency as recently affirmed in our Secure Future Initiative (SFI), we are sharing this update. Beginning in late November 2023, the threat actor used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions, and exfiltrated some emails and attached documents. The investigation indicates they were initially targeting email accounts for information related to Midnight Blizzard itself. We are in the process of notifying employees whose email was accessed. The attack was not the result of a vulnerability in Microsoft products or services. To date, there is no evidence that the threat actor had any access to customer environments, production systems, source code, or AI systems. We will notify customers if any action is required. This attack does highlight the continued risk posed to all organizations from well-resourced nation-state threat actors like Midnight Blizzard. As we said late last year when we announced Secure Future Initiative (SFI), given the reality of threat actors that are resourced and funded by nation states, we are shifting the balance we need to strike between security and business risk – the traditional sort of calculus is simply no longer sufficient. For Microsoft, this incident has highlighted the urgent need to move even faster. We will act immediately to apply our current security standards to Microsoft-owned legacy systems and internal business processes, even when these changes might cause disruption to existing business processes. This will likely cause some level of disruption while we adapt to this new reality, but this is a necessary step, and only the first of several we will be taking to embrace this philosophy. We are continuing our investigation and will take additional actions based on the outcomes of this investigation and will continue working with law enforcement and appropriate regulators. We are deeply committed to sharing more information and our learnings, so that the community can benefit from both our experience and observations about the threat actor. We will provide additional details as appropriate. Previous Post",
    "commentLink": "https://news.ycombinator.com/item?id=39061800",
    "commentBody": "Microsoft actions following attack by nation state actor Midnight Blizzard (microsoft.com)220 points by nycdatasci 12 hours agohidepastfavorite128 comments yborg 9 hours ago\"We were pwned by the Russians (again) and they were reading all of Satya's emails, but it's okay, they were just looking for shout-outs to post in their interoffice Telegram channel for the lulz.\" I understand that the company has to minimize every breach but this frankly looks a lot more serious than Microsoft suggests here. reply shultays 1 hour agoparentI like this bit ... a very small percentage of Microsoft corporate email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions, and exfiltrated some emails and attached documents. Yeah, at least they make a very small percentage of all Microsoft employees I guess reply fauigerzigerk 1 hour agorootparentAlso this: \"To date, there is no evidence that the threat actor had any access to customer environments, production systems, source code, or AI systems.\" So email accounts of senior leadership and employees in cybersecurity are apparently not production systems. reply fremenite 16 minutes agorootparentThey mean root access on the production email servers, not access to individual email accounts. reply jug 6 hours agoparentprevI love how they emphasize only few were exposed. Like just a few, only our senior staff and cybersecurity team... I mean -- they aren't lying, but... Wow reply voidwtf 5 hours agorootparent\"very small percentage\" 1% of 238,000 employees is a \"very small percentage\" and still 2,380 employees. Insight into certain operational information and potentially undisclosed/unpatched zero days could be monumentally valuable to a nation state actor. reply Fire-Dragon-DoL 4 hours agorootparentprevIsn't the rule \"if you are being targeted directly, lose all hope\"? reply SlavikCA 3 hours agorootparentI wonder, is it any different, if it's not just average \"you\", but CEO? Don't they have additional security measures? May be not, I think Jeff Bezo's WhatsApp was hacked few years ago... reply wly_cdgr 2 hours agorootparentprevNever lose hope. If you can't protect the data, poison it! reply bamboozled 2 hours agoparentprevNot to downplay the severity but honestly, every breach I read about seems “serious” but very rarely does anything of consequence happen with these events. Azure was owned pretty hard a while back, very little was ever heard of it again. Is the drama of them appealing ? What might we expect to happen from this ? They’ve read Satya’s email ? reply bobmaxup 1 hour agorootparentHow do you know if nothing happens? It isn't like the people siphoning, selling, or purchasing this data are broadcasting their wins on news aggregators. reply tempodox 1 hour agorootparentprevIt makes the news when an entity like Microsoft gets cracked, but when their users get robbed or otherwise hurt as a consequence it will hardly make the news. You not knowing of the consequences doesn't mean they don't exist. reply bamboozled 37 minutes agorootparentThe company will be making record profits next year. There maybe consequences but nothing consequential in the grand scheme of things. reply PoignardAzur 17 minutes agorootparentI find this reply incredibly cynical. GP is clearly saying \"this is important because small people will get hurt invisibly\" and your hot take is that them being exploited isn't going to impact Microsoft's bottom line, so this isn't newsworthy? This is vice-signaling. reply bamboozled 12 minutes agorootparentBeginning in late November 2023, the threat actor used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions, and exfiltrated some emails and attached documents. The investigation indicates they were initially targeting email accounts for information related to Midnight Blizzard itself. We are in the process of notifying employees whose email was accessed. It says nothing about users being compromised. This is why they won’t do anything about it though ? Do you understand how it works ? They’re not going to do anything about the consequences for the users until it impacts their profits. Name one person who is done with Microsoft after this? reply wholinator2 6 minutes agorootparentI think the confusion lies between the terms \"consequences\" and \"consequences for Microsoft\". There won't be consequences _for Microsoft_ but there will be consequences for regular people. Saying there won't be consequences full stop implies you don't consider the damage to regular people as worthy of discussion or consideration malermeister 17 minutes agorootparentprevTurns out there's more possible consequences than company profits being impacted. Users are more than just things you milk for cash, they're people that trusted you and your product. reply nycdatasci 4 hours agoparentprevThe Friday evening blog post also seems designed to brush this under the rug. \"We will act immediately to apply our current security standards to Microsoft-owned legacy systems and internal business processes\" In other words: Microsoft will adopt their own security standards. Curious whether their SOC reports mention these are optional? reply thrwwycbr 2 hours agoparentprevAnd somehow it's always cross tenant issues for easy lateral movement, because Azure ASNs are always allowlisted specifically to bypass all kinds of filters. Microsoft is pretty learning resistant lately. Always prioritize the spamming customers, I guess? reply yukIttEft 5 minutes agoprevFrom the same company that charges you to access your logfiles. https://www.theregister.com/2023/07/20/under_cisa_spressures... reply hbcondo714 10 hours agoprevMicrosoft filed this late today with the SEC[1] just before they stopped accepting new filings for the day under their new Cybersecurity Incident disclosure rule[2]. FWIW, two other publicly traded companies disclosed[3] their breaches since the rule went into affect last month. [1] https://www.sec.gov/Archives/edgar/data/789019/0001193125240... [2] https://www.sec.gov/news/press-release/2023-139 [3] https://last10k.com/stock-screeners/cybersecurity reply paxys 9 hours agoprev> Beginning in late November 2023, the threat actor used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts [...] > The attack was not the result of a vulnerability in Microsoft products or services. Hmm... reply juggertao 8 hours agoparentThey mention it was a password spray guess. reply deelowe 7 hours agorootparentI'm guessing they don't know what a password spray is? reply tommica 3 hours agorootparentWhat is it? Just spam a form with passwords? reply tgv 2 hours agorootparentWell, your \"legacy non production test tenant\" can be opened by just guessing passwords, and it allows access to \"very much in use production non-test\" tenants, then you could say MS has a vulnerability. It may not be a buffer overflow, but it is a vulnerability nonetheless. reply booi 1 hour agorootparentYes, and I think most people would consider it a vulnerability if an authentication system doesn't rate-limit or otherwise slow/stop \"password spray\" attacks. reply oezi 1 hour agorootparentYou can rate limit individual users but password spray attacks use a large number of accounts to remain undetected in a authentication system used by an even more users. reply mattigames 56 minutes agorootparentWe are getting 10000x times the number of wrong passwords than average, I'm sure it's nothing to worry about. reply Towaway69 34 minutes agorootparentIt was a legacy test system connected to a production system so it doesn't count. Obviously. /s reply slackr 9 minutes agoprevWhy do they say \"nation state actor\", isn't \"state actor\" the correct term? I thought Russia, like the UK and many other states, is a multinational state, including numerous languages and cultures. reply voidwtf 7 hours agoprevHow did they pivot from a test tenant to corporate email access? That's the most concerning fact that they just glossed over. reply shermantanktop 6 hours agoparentYou know, they pivoted. Non-production tenant PIVOT Satya’s email inbox. Like that. reply isoprophlex 38 minutes agorootparentPivot! PIVOT!!! https://youtu.be/njgfomF51fg reply utdoctor 5 hours agorootparentprev1. Password spray 2. Access non-prod environment 3. ??? 4. \"Look at me, look at me, I am the CEO now.\" reply voidwtf 5 hours agorootparentI reflexively read #4 to the tune of Flobots - Handlebars reply foota 27 minutes agorootparentReflexively? That song is almost 20 years old! (oh god now I feel old too) reply palmfacehn 4 hours agorootparentprevIt was a \"Captain Phillips\" reference for me. reply chrnola 4 hours agorootparentprevunderrated comment reply kjellsbells 4 hours agoparentprevI suspect more corpos have exposure like this than any of them would like to admit. E.g.: BigCo picks up a company SmallCo, and inherits their systems for some time. There's some cruddy ancient CRM, IT or travel system, and some random test tenant, that has hooks to email, and from there it's a short step to enumerate targets, send auto-generated emails from a trusted system and the hackers are off to the races. reply euoia 6 hours agoparentprevJust guessing but perhaps with a phishing attack on a Microsoft domain. reply voidwtf 5 hours agorootparentThis is genuinely something I hadn't considered. A test tenant may have been in a more than ideal position to stage phishing attacks from. Hopefully this is the case, and not a more concerning lack of disclosure or shudder NSL situation. reply BandButcher 11 hours agoprevHaha \"...access a very small percentage of Microsoft corporate email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions, and exfiltrated some emails and attached documents.\" Seems like a big deal. Also, this may be why I've been getting massive amounts of \"unusual account sign-in activity\" emails for Microsoft about an old outlook account i no longer use... Hopefully these state actors can get access to my vsts server i no longer can find and deploy an old app for me ;) reply kgeist 2 hours agoprev>Microsoft has identified the threat actor as Midnight Blizzard, the Russian state-sponsored actor also known as Nobelium How do they identify those groups? reply rightbyte 22 minutes agoparentThey are just making it up. Security people seems to be of the militaristic type ofent, so I guess they add a slive of war mongering to it to to play ball. Iran, North Korea and what not. Very convenient since it is not falsifiable in practice. reply fremenite 12 minutes agoparentprevFrom the artifacts they leave behind after the attack, broadly speaking. reply akira2501 11 hours agoprevInteresting that they seem to suggest that applying security is now more important than avoiding service disruptions. This may be the hopeful dawn of a new era. reply booi 1 hour agoparentWell well well.. how the turn tables. It's karma after years of my windows machine forcing a restart for a security update while I'm working on something in the middle of the day.. reply bamboozled 1 hour agoparentprevIt won’t be. Everyone will forget about this in a week and it will be BAU. Like every other breach. reply robblbobbl 10 hours agoparentprevIt is indeed the beginning of a new AI related era. But why cloud services, Microsoft? There is already a new infrastructure on the way better suited for AI, called edge computing. I'm not talking about completely eliminating cloud services. But solely depending on these kind of services could lead to further problems later due to this topic (national security) is very serious for all of us. reply gustavus 7 hours agoparentprevI work in the security space. It is the dawn of an era where all the makers are stamped down under the boot ridiculous security theater via regulation for \"security\" and \"protection\" and the current interests become entrenched to ensure a couple of guys in their garage can no longer upset the behemoths of the tech space. reply clwg 9 hours agoprevThey should look at upgrading their Entra ID plan to P2 in order to protect against these attacks. reply this_steve_j 9 hours agoparentAnd all things considered, an AI security assistant like Copilot might be a good investment too, if they lack highly skilled front line security staff. Not to mention, AI generated automated playbooks in Sentinel to automatically apply Zero Trust principles! I also wonder if they had upgraded all of their Subscriptions to Defender for Cloud CSPM Tier 2 in order to use the premium Cloud Security Attack Graph explorer, and then enabled Workload protections, this tragedy could have been averted. It’s going to take an army of motivated sales engineers to protect against these new cybernetic attacks by augmented warfighters. reply Voultapher 1 hour agorootparentLost my sanity there for a moment before realizing what you did. Good job! reply voidwtf 5 hours agoparentprevI wonder if they switched from user-based MFA to Conditional Access MFA yet, maybe they forgot to enable alerting for non-interactive logins. Maybe they forgot to update the Log Analytics Agent to the Azure Monitoring Agent. /s reply 1vuio0pswjnm7 1 hour agoprev\"Microsoft took advantage of news of this hack to talk about how they are going to move forward to make itself more secure.\" https://techcrunch.com/2024/01/19/hackers-breached-microsoft... reply IronWolve 11 hours agoprevDid they release this late on a friday to downplay the scope of the attack? If they had top leadership accounts and service accounts hacked just by password protection sounds like a major security fubar. reply skybrian 9 hours agoparentReleasing news after the stock market is closed gives traders a chance to digest the news before trading begins the next day. (Which doesn't explain why it's on a Friday.) reply bee_rider 9 hours agorootparentIt could be sort of neat if there was a convention for all news agencies and press rooms to queue up all their stories and release them after the end of the business day. Why advantage parties that can process in less than 12 hours? Rushing analysis just makes it worse. reply dylan604 7 hours agorootparentprevtraditionally, the weekend gave even more time to sleep on it. modern near 24/7 trading makes that less of thing. back when the traders went home, there was a cooling off period. just like the circuit breakers to stop trading on big loss days to get the humans to stop and think for a second/minute/overnight. the high frequency trading doesn't have these emotions to cool down from, so it's still something that seems to be done on tradition now. reply blibble 9 hours agorootparentprevtrading MSFT doesn't cease when the NASDAQ closing bell rings reply skybrian 9 hours agorootparentStill, it seems to be the custom. reply fsckboy 6 hours agorootparentit's the custom because it's not just stock trading that they care about, it's brand/image, and weekends give the story time to disappear from the headlines, being replaced by new stories. Fewer people are paying attention to the news over the weekend. reply blibble 9 hours agorootparentprevif you're a retail investor maybe there's thousands of ways to get exposure to MSFT one way or the other beyond the primary market reply modeless 5 hours agoprevUm. Why does \"a legacy non-production test tenant account\" have \"permissions\" for \"email accounts, including members of our senior leadership team and employees in our cybersecurity, legal, and other functions\"? reply SoftTalker 4 hours agoparentThe usual reason include: oversight; mistake; incompetence. reply cedws 6 hours agoprev>Beginning in late November 2023, the threat actor used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts I have so many questions from this sentence alone. What did they password spray? Microsoft's internal identity provider? Was the non-prod system internet facing? Why isn't MFA enforced? reply thrwwycbr 2 hours agoparentThey got Kerberoasted and don't want to admit it publicly. reply Too 3 hours agoparentprevIndeed. How can they not be mandating MFA? reply sagman 2 hours agorootparentMaybe this is why it only affected leadership team. Maybe they can circumvent requirements meant for lowly employees. reply voytec 9 hours agoprevI wonder which mail client the execs were using. If Outlook, their messages would be already harvested by 700+ companies[0] and another leak wouldn't be an issue. [0] https://news.ycombinator.com/item?id=38441710 [0] https://news.ycombinator.com/item?id=38953618 reply midtake 5 hours agoparentEver since Delve was introduced, Microsoft Outlook has felt weird to me reply Roark66 1 hour agoprevSeriously? This reads like a joke. They brute forced some tenant test systems. Fine, I bet the password was Password123!, but then \"they used account's permissions\" to access various corporate emails. How is that even possible? What does it mean \"they used the account's permissions\"? Are you telling me there was no privilege separation between a tenant test environment and the internal domain? That the tenant system was not in its own isolated network? This is absolutely insane. Whenever I read stuff like that I wonder if some junior IT employee didn't just buy a new home for cash few months ago. I'm all for \"don't look for malice where incompetence is a sufficient explanation\", but that's just a little too much incompetence to be believable. reply starik36 11 hours agoprev> access a very small percentage of Microsoft corporate email accounts Ok, so far so good. > including members of our senior leadership team Ahhh, so maybe the attackers were after the senior leadership team and therefore stopped at the \"very small percentage\". reply nighthawk454 11 hours agoparentSeems weird to word it as “a very small percentage” instead of “a very small number” unless the number was a little bigger than they want to admit. reply blibble 10 hours agorootparentyes, at least 1% of their users which is a very large number > To date, there is no evidence that the threat actor had any access to customer environments, *production systems*, source code, or AI systems. senior executive's email accounts aren't production? having every western company use the garbage that are Microsoft's hosted products (notably Teams and Outlook) is a national security issue that's a massive disaster that's just waiting to happen reply skybrian 9 hours agorootparentThe denominator is \"Microsoft corporate email accounts.\" I interpret that as email accounts of the Microsoft organization (management, employees, and so on), but not customers. It's pretty embarrassing and not very reassuring that they themselves got owned, but they wanted to tell their customers that they didn't. reply calgoo 10 hours agorootparentprevI agree around teams and outlook, but what is the alternative? Google? AWS? Self host? Honest question, because the way enterprise tends to work, they want to offload the responsibility to a third party so When information does leak or get hacked, they can blame someone else. reply ivlad 7 hours agorootparentGoogle or self-host. With self-hosting you get to use thing now considered legacy (e.g., IMAP servers), but I definitely have seen them working for organisations with thousands of employees. You’ll need staff to support it, too, but at some scale it will none be more expensive than cloud services. Yet, you’ll have more control over it. OTOH, some things will definitely be less feature-rich, for example, on-prem Sharepoint (not that I recommend using it) may not live up to the expectations of users familiar with the online version. reply blibble 10 hours agorootparentprev> but what is the alternative? Google? AWS? Self host? I mean, given this was possible: > used a password spray attack to compromise a legacy non-production test tenant account and gain a foothold, and then used the account’s permissions to access a very small percentage of Microsoft corporate email accounts pretty much anything is going to be better than letting Microsoft host your email/corporate data reply redavni 9 hours agorootparentYou realize the Chinese government has compromised Gmail accounts through an dedicated interface for law enforcement right? I really don't see how you think Gmail is better. This is just bad passwords/lack of 2FA probably. reply roca 8 hours agorootparentGot a reference for that? To be clear: I've never heard of any such thing. I happen to work for Google, but I'm open the possibility that this happened and I didn't hear about it. reply ivlad 7 hours agorootparentThey probably confuse it with Russians hacking Yahoo and having access to user account admin interface: https://www.csoonline.com/article/560623/inside-the-russian-... reply c0pium 5 hours agorootparentprevThis kind of attack can happen on any tech stack where bad passwords have ever been allowed. The dunking is obviously fun, but the fact that the underlying technology happened to be Microsoft’s is largely irrelevant. reply Aeolun 3 hours agorootparentYeah, it’s just that less legacy conpanies have less chance of having a system that can be compromised in this way. Conversely, Microsoft is almost guaranteed to have it. reply switch007 1 hour agorootparentprevI’ve noticed in PR it’s very common (I’d say even standard practice) to use percentages to hide absolute numbers, and vice versa reply postepowanieadm 1 hour agoprevJust block all traffic from russia :) reply ikekkdcjkfke 31 minutes agoparenttakes step over the border and opens laptop reply sneak 11 hours agoprevWhy does the data security industry seem to be so into obfuscated jargon? It’s like a new industry microcosm corporatespeak. It’s ok to call them countries, hackers, and intrusions. Microsoft got hacked by Russian government hackers. reply parl_match 11 hours agoparent> It’s ok to call them countries, hackers, and intrusions. It's not if you want to do business in that country. Or if you annoy allies of that country (accusing certain countries might get senators breathing down your neck!). You are accusing a government of committing a crime, or at least a wildly unethical behavior. Those are huge charges. To your point, I wish they could be more direct, but... > Microsoft got hacked by Russian government hackers. It is not known whether this hacking group is private, government sponsored, or government run. They could be a private group that takes both private and government contracts. If they were funded via government channels, who was it? A higher up person using their personal wealth? A specific agency? Multiple agencies? The reason they are being so vague is because they don't know the answers, and it is very discrediting to throw around incorrect accusations. reply carom 9 hours agorootparentIt is government sponsored. It says in the article. >Microsoft has identified the threat actor as Midnight Blizzard, the Russian state-sponsored actor also known as Nobelium. reply kgeist 2 hours agorootparentBut how do they know that it's sponsored by Russia? They saw the paychecks? reply toss1 11 hours agorootparentprev>> It is not known whether this hacking group is private, government sponsored, or government run. Coming from Russia, that's a distinction without a difference. Sure, private groups can 'freelance', but not without at least tacit permission from the FSB, GRU, and/or SVR (more accurately, cant freelance for long). Especially so for sch a high visibility target such as Microsoft. And when the RU govt isdues a denial, it's confirmed. But still no reason for MS to escalate the wording. They put enough in there that anyone with a clue knows it's serious. reply parl_match 10 hours agorootparentThe distinction probably matters to a lot of people at the scale that Microsoft is operating at. They likely worked with some sort of MS US government liaison on the wording. Operating with tacit approval is not the same as being a government entity. Even you admit there is a small chance that this group is not tacitly approved (\"for long\"). I mean yeah, we all know the score, but a it's really bad idea to levy heavy charges without knowing the answer 100%. This statement does pretty heavily implicate the Russian Govt though, yeah :) reply SoftTalker 11 hours agoparentprevMy summary understanding of this write-up is that a weak password was guessed and allowed entry into an old system that had access to stuff it shouldn't have had access to. reply wrsh07 11 hours agoparentprevYour summary is also ambiguous. Were they hacked by the Russian CIA equivalent? Were they hacked by people funded by the Russian government? Were they hacked by people funded by senior government officials? I think it's possible that the truth is a little murky, and capturing that ambiguity is actually clearer than trying to wave it away reply 2OEH8eoCRo0 10 hours agorootparent> The U.S. Federal Bureau of Investigation (FBI), U.S. Cybersecurity & Infrastructure Security Agency (CISA), U.S. National Security Agency (NSA), Polish Military Counterintelligence Service (SKW), CERT Polska (CERT.PL), and the UK’s National Cyber Security Centre (NCSC) assess Russian Foreign Intelligence Service (SVR) cyber actors—also known as Advanced Persistent Threat 29 (APT 29), the Dukes, CozyBear, and NOBELIUM/Midnight Blizzard https://www.cisa.gov/topics/cyber-threats-and-advisories/adv... So, they're \"Russian Foreign Intelligence Service (SVR) cyber actors\" reply Morte42 9 hours agorootparentIm guessing that's like saying they are hired by the Russian equivalent of the CIA and following direct orders from top Russian officials? reply 2OEH8eoCRo0 9 hours agorootparentWhile the CIA is a US foreign intelligence agency, I'd hesitate to call them equivalent. Hired by as in, employees of, Russian intelligence? Unless my link is inaccurate, yes. reply nozzlegear 11 hours agoparentprevIt largely boils down to the same reason scientists classify animals into taxonomies. It helps to have a framework for classifying the groups so you can refer back to them in the future. Going back to my example with taxonomies: Yeah, you got bit by a spider, but exactly which kind of spider bit you? What do we know about those kinds of spiders, e.g. are they known for being venomous or not, does their bite have a well-known reaction in humans, etc. reply chatmasta 11 hours agoparentprevAt least for the \"Midnight Blizzard\" part of the title, it's the result of a naming framework [0] for threat actors that Microsoft has been using since April 2023. I agree it sounds weird. [0] https://learn.microsoft.com/en-us/microsoft-365/security/int... reply jstarfish 11 hours agorootparentThe naming framework for these groups isn't even consistent, with every vendor having their own scheme. Midnight Animal to one vendor is Dancing Bear to another and known by Wet Cat to yet another. They all sound like bad translations to bargain-bin porno movies. reply true_religion 10 hours agorootparentI’m not aware of another company that uses a naming framework. reply ivlad 7 hours agorootparentCrowdstrike. FireEye. reply true_religion 6 hours agorootparentDefinitely agree that Crowdstrikes naming veers past what is necessary. They even draw up supervillain graphics for them. https://www.crowdstrike.com/adversaries/arcane-kitten/ reply PoignardAzur 11 minutes agorootparentThis is really cool and incredibly stupid. Like, who is this made to appeal to? Is this meant to make corporate executive browsing for cybersecurity solutions feel like they're in a spy movie? reply jrowen 1 hour agorootparentprevThis is wild. Ethereal Panda? Labyrinth Chollima?! Why are we modelling threat actors/\"adversaries\" as a video game bestiary? Or meteorological phenomena in the case of MS? reply tempestn 47 minutes agorootparentWhy not? reply riversflow 2 hours agorootparentprevper that link: Midnight Blizzard == Cozy Bear[1] who were in the US news. [1] https://en.wikipedia.org/wiki/Cozy_Bear reply mc32 11 hours agoparentprevRussia hacks, but so do China, North Korea, Iran and Ukraine. They all have bagged large targets. It could be any of them but could be someone else as well. reply doublerabbit 9 hours agorootparentAs does UK and the USA. Maybe it's Microsoft hacking it self; GPT style. If so, hello Skynet. reply newsclues 11 hours agoparentprevBecause the reality is murky. reply 2OEH8eoCRo0 10 hours agoparentprevWoah. Easy there. It sounds like you're trying to start a flamewar by singling out Russia. Don't you know that every country does this?! Please preface any accusations against Russia with paragraphs of anti-Western invective. /s reply JeffSnazz 4 hours agoprevOh god they're russian. That means they're evil! reply m3kw9 3 hours agoprevSwiss cheese security as usual reply carabiner 11 hours agoprevWhat does the title mean? reply wg0 4 hours agoparentI had to read the title multiple times but couldn't make sense of what is exactly happening. Why is this happening to English? The other day, there was a story about an airplane window that got melt and many native speakers couldn't make sense of what the title of the story meant? In that case too, as a non native speaker of English, I blamed myself first for not understanding the language well enough. reply nozzlegear 11 hours agoparentprevI believe “Actions taken by Microsoft following an attack by a group named Midnight Blizzard, who are backed by a nation-state”. reply nycdatasci 11 hours agoparentprevThe title here matches the title of their blog post, which I agree is poorly worded. reply voytec 9 hours agorootparent> poorly worded Or intentionally obfuscated \"we were hacked\". reply wly_cdgr 2 hours agoprevNow I understand why Microsoft bought Activision Blizzard. So they could fight Midnight Blizzard. reply m3kw9 3 hours agoprevMS is a joke at security and they prob have 2000 person in a building doing this stuff too reply yieldcrv 7 hours agoprev“it was Russia, they went thata way!” this presents no proof, but I’ve read lots of krebs security proof on other exploits and I think it is all very weak nothing is stopping anybody here from putting breadcrumbs in a payload to point the finger at North Korea or a former Soviet state This is kind of a silly standard that allows hackers to operate with impunity and companies to avoid accountability and the fbi from not bothering reply mr_mitm 7 hours agoparentDepends. If the breadcrumbs are key material which correlates to other known incidents from the same group, or exclusive tooling, or C2 infrastructure, then there is definitely something stopping them from putting breadcrumbs there. They'd have to hack the other group first in order to do so. I agree with you that seeing evidence would be nice, but I understand that there is the possibility that evidence supporting the claim exists and at the same time cannot be released to the public. reply sudosysgen 4 hours agorootparentAs we've seen, many of the cybersecurity teams have been pwned, so a large part of the breadcrumbs they'd pattern match are already out there. Additionally, if security is poor enough, there can be more than one hacker into a system, which is another way they could accumulate breadcrumbs. This has precedent - there has been malware that uninstalls other malware. reply mr_mitm 3 hours agorootparentMany? I'm only aware of the Equation group, believed to be the NSA, whose extremely powerful tools were made public. What other threat actor's internals (and I mean more then chat logs) have been made public? reply ClickedUp 3 hours agorootparentCIA & GCHQ (Wikileaks). reply mistrial9 11 hours agoprev [–] this reminds me of guys trying to out-shout each other about who wants to fight the most, in front of a lot of (Ynews) onlookers reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Microsoft detected a nation-state attack by a group called Midnight Blizzard on January 12, 2024.",
      "The attack involved compromising a test account to access a limited number of corporate email accounts, including senior leadership.",
      "Microsoft's immediate response process mitigated the attack and prevented the threat actor from accessing customer environments, production systems, source code, or AI systems. Microsoft is taking further security measures and will provide updates as the investigation continues."
    ],
    "commentSummary": [
      "Microsoft confirms security breach by nation-state actor Midnight Blizzard compromising a small number of corporate email accounts.",
      "Customer data and production systems were not accessed, but concerns about severity and data security implications remain.",
      "Criticism towards Microsoft for allowing the breach and response, discussion on security measures, potential consequences for users, and suggestions for improving cybersecurity. Attribution of the attack to the Russian government is debated, speculation on vague language used to describe the breach. Conversation includes alternative hosting options, vulnerability of different systems, and the use of video game-like names for threat actors."
    ],
    "points": 221,
    "commentCount": 128,
    "retryCount": 0,
    "time": 1705701411
  },
  {
    "id": 39056403,
    "title": "Japan's SLIM spacecraft successfully lands on moon, highlights precision landing technology [video]",
    "originLink": "https://www.youtube.com/watch?v=2-yBlZplnKQ",
    "originBody": "[Music] [Music] it's for [Music] [Music] for for [Music] k for [Music] for [Music] for e for for [Music] e for for for [Music] he [Music] for hi smart rer for investigating MO for for [Music] for e for r for for for for for for for for because while it's a very long distance when you reach these very far distances from the Earth and Moon you can actually use the gravity of the Sun Moon and Earth to bring you back towards the moon without exerting a lot of thrust of fuel so it's long but it's efficient now once we entered into orbit on Christmas Day we started to change the orbit to become more circular it entered rigidly slim entered into elliptical orbit um and then passing between 4,000 km and 6ou 600 kmers in the lunar surface and then it became more circular and has gradually be lowering since then so let's look at the demonstration of Technology needed for high Precision land Landing this Pinpoint Landing on the moon so how does slim actually do this this very accurate Landing oh we've gone back to look at the spacecraft design again in particular these solar panels which are flexible and fold around the fuel tank as opposed to being the flat wings that you normally see with conventional spacecraft this is very efficient for space among other things this is because uh slim will be landing in the morning and then it needs more sunlight so it has to be tilted okay now we're going to we are going to go and look at the technology for the high Precision landing and in particular this Pinpoint Landing technique this is the uh Mission movie for slim we're going to do a run run through from um the launch through to uh arriving at the moon so this is a spacecraft separation and then the first step is both an earth swing where we use the gravity of the earth to give us a kick in the right direction and this is followed by the lunar swing by that we mentioned early where we actually pass the moon and go out to a much further distance uh in order to use the gravity of the Earth Moon Sun System to pull us back and now we uh observations from lunar orbit this is part of the vision based navigation using the onboard cameras so Slim's cameras uh scan the ground beneath it on the lunar surface and identify craters which help slim know where it is now we rotate to a vertical position as we prepare for landing and slim starts scanning the ground again this time looking for obstacles that would actually be dangerous to the spacecraft should it land directly on them for example large Boulders and if it spots a large Boulder it moves horizontally in order to avoid that Boulder and to an open space and then just before landing it's going to release the spacecraft two rad left one and left two and then here is the two-step Landing where we land on that Back le first and then tip forward onto the front landing gear these are the two Rovers left one and left two and this is the movement of left one which is a hop and this is left two the little ball Rover we'll talk a little more about that later it Springs open to actually have a wheeled format so it will be moving along the lunar surface with wheels and uh slim is also equipped with a um infrared a near infrared multiband camera and it will take observations from there so now we look again at the this Landing sequence so the spacecraft starts with a power descent from an altitude of 15 kilometers and approaches the target point on the Luna surface using this image matching navigation where it's spotting craters with its navigation camera and autonomously uh then guiding to its correct location at an altitude of 7 kilm space the uh spacecraft will transition to a vertical descent and precise measurements of the altitude will be taken with the landing radar and then finally the two-step uh Landing with the autonomous obstacle detection that we saw in the movie will uh be performed before we're safely on the ground and the uh the maximum during the power descent phase the maximum velocity is 1700 m/ second and that is about seven times the speed of a passenger aircraft and this whole thing will take about 20 minutes which is sometimes known by the team as a 20 minutes Terror so how do you actually know where you are on the lunar surface to do these pinpoint Landings unfortunately unlike the Earth there is no GPS on the moon GPS devices do not work so therefore we need to use other ways to find our location over the lunar surface now conventional Landers PL their trajectory from the earth and then they use their inertial navigation equipment such as the accelerometers and the gyro sensors to work out where they are and then this allows them to find roughly their Target location and land however those techniques are not particularly accurate and little measurement errors add up all the way through to end up as a result with quite a large landing area with these conventional techniques so in order to improve this what we do is we add in this image matching scheme which allows slim to have a much better assessment of where it is on that lunar Surface by using its navigation cameras to photograph the pattern of craters below it on that lunar surface so here's the process of that we capture images with a navigation camera on Slim and then an extraction software program is performed to actually identify those craters which are now circled in blue and then with that pattern of craters slim Compares it with its onboard Maps which has got from previous orbit missions such as kaguya and from NASA's lro Orbiter and that Creator pattern can actually identify very accurately where it is on the surface and so in addition to its inertial navigation equipment it has a much better idea of its location and then it can autonomously correct to find out where it is now in hyabusa and hyabusa 2 which were the asteroid explorers led by jaxa um actual people perform the Min uh image matching operation as opposed to inbuilt software but slim has the issue that it's not landing on an asteroid rather it's landing on a moon and while the Moon is much smaller than the earth it's gravity is much greater than that of an asteroid and you can't have a slow descent so as a result you actually need to do this image matching scheme incredibly fast otherwise the lunar gravity has just pulled you past the point where it's useful now the other factor you've got to consider is that space computers only have about a hundredth of the capacity of their terrestrial counterparts due to the very harsh conditions of space so as a result the team had to develop this image matching algorithm that required only a few seconds of processor time otherwise you missed your chance on equipment that was not cutting edge and there's no redo on a moon landing once you start that descent that is it you can't just pull up and start again unlike on an asteroid so now we have a look at a couple of the other navigation equipments on board slim the top is the navigation camera these are two units they're actually placed at different orientations so that slim can examine the surface both during The parad Descent phase and during the vertical descent phase when the spacecraft is tilted at a different angle the middle part here is the landing radar this is an altitude rage sensor to measure the altitude and velocity in the direction of the lunar surface during vertical descent phase and finally we have the laser rage finder which is much more accurate and it's used during that final descent to pinpoint the altitude immediately before landing so once we get to the point of the landing uh we're actually landing on something that should be a 15 degree so slope and that's that's dangerous it's very difficult to do so in order to land safely on a fairly steep incline we actually have this twostep Landing system was adopted and this was developed after copious amounts of simulations both computer and and practical to find out what's the safest combination for a spacecraft like slim so it doesn't tip over and the the ultimate result was you land on the back legs and then you rock forward as we saw in the movie to a stable position now the legs of slim themselves are actually these 3D printed semicircular aluminium spheres and they're designed to compress to absor absorb the impact of slim landing on the surface this is a very compact design because much larger missions would use legs with joints but slim doesn't have the space for that so they have these uh very compact crunchable uh 3D aluminium spheres now when just before slim lands it's going to release two lunar Excursion Vehicles Lev one and Lev two and these will be a demonstration of small probe movement technology on the lunar surface environment so L one is the bigger of the two is 2.1 kg 26x 40 by 30 cm and left two is a smaller round ball at25 kgrs and these two will communicate as follows the left one will actually talk directly to the Earth and it will move through this hopping motion um where there is an arm that presses forward onto the lunar surface and it causes the Rover to jump and it has an antenna so it can communicate its pictures and other information back to the Earth left two is smaller it's going to have wheels because it Springs apart from its spherical configuration into these two wheeled parts and it will send its data via Lev one back to the Earth this is a closeup of the movement of Lev one it has this punching arm that pushes down to the Luna surface because the moon gravity is very weak this is actually very effective and the Rover should jump forward um a fair distance before coming back down to the moon and this is left two also known as soru and it starts off a ball configuration but once it lands it actually pops forward and it has these two modes of motion this kind of crawl and also a more butterfly like motion and so here we are uh Designing Technology from an era of Landing where we can to Landing where we want and if you're feeling worried that you didn't manage to absorb everything that we said morisan will be back to take us through the key points just before we uh begin Des sent so our next guests are are members of the private company manufacturing behind the slim Mission first we have Ida U who's from the Mitsubishi Electric Company sometimes referred to as Melco and these are the spacecraft system contractors kaidan is based at Kamakura Works where slim was constructed so mitubishi had actually a very tough job since as we've seen slim needed be made as lightweight as possible so if the spacecraft can be made lightweight like slim then you do have the option of increasing the mass available for possible observation equipment and also costs such as transportation to the rocket can be kept very low such development therefore can lead to more frequent lunar and Planetary Exploration in the future so this is why a light mate mission was very important for slim uh and the challenge in construction was passed at least in part to MCO so one example of that is Slim's tank was a new design because it acted as the body of the spacecraft as well as storing the fuel this actually meant the tank was more exposed and various devices had to be attached to the tank exterior this was a new problem that had to be considered very carefully during the construction MCO are also the spacecraft systems contractor for one of Jackson's upcoming missions the Martian moons exploration Mission MMX MMX will launch in fiscal year 2026 and visit the moons moons of Mars Phobos and deos spacecraft will land on fobos and collect a sample from the Moon returning to the Earth in 2031 so our next guest is akagi Kens from takura Tommy now takura Tommy is very well known but not for spacecraft it's most well known for being a Japanese toym maker company company is perhaps most famous for originally creating the Transformers the alien robots that can disguise themselves as machines however in this case takura Tommy have built Lev two as seen here it's tiny little robot also known as Sor Cube and it's one of the Rovers on the slim Mission and Lev two does indeed transform into the second uh image that you can see that Shin is holding the Rover is about the size of a baseball it has a honeycomb aluminium alloy shell and starts off as a sphere as you can see from akaki San's uh model that he's holding and it then splits in half to reveal a pair of cameras that point front and back and the two hemispheres actually become the Rover wheels so this little transforming robot will um photograph the slim spacecraft and also the surrounding terrain before sending those images back via left to the Earth cameras and at the back it's even got little tail for balance so the first part was uh from the toy of the Transformers so it's called a transformation technique that it has been developing and the second one is this so imagine that the sea turtles move on the shore and they inspired by the movements and then they try to capture and then try to have that mechanism embedded so so what I'm hearing is this is a transform of sea turtle yes that's right that's wonderful it looks like um this has been really creative process to invent this sort of toy and is that right and then he thinks that um this is because of the company strengths that the toy has been made into the space excellent and toys like Transformers are incredibly imaginative so maybe this is a more logical step than we might have previously considered and it [Applause] is so our next guest is uh Morata tomatsu from The Graduate School of Science in the University of Tokyo soan is particularly interested um in the science rather than engineering behind slim and the science slim plans to do on the lunar surface Lan is previously worked with a lot of lunar observation data including that from the jaxa lunar orbiter kaguya so kaguya which was launched in 2007 orbited the moon and mapped the moon's geology over its surface the result with these very high resolution maps that kaguya and similar missions such as NASA's lunar reconnaissance Orbiter L revealed um revealed and you see these key bodies of rock that aren't particularly large areas but are really interesting and they could shed some light onto important questions in planetary science such as those related to the moon's formation so you have this situation now where you have fairly small but numerous regions of interest that you really want to get a look at and this brings us to the need for Slim's Pinpoint Landing technology and the ability to land on slopes which enables us to choose a much wider region of possible Landing sites and also land on some rough terrain which is what we're seeing here and we can actually get close enough with this technology to actually start studying these areas so the important this important use case means that while slim is a technology Mission and is designed to be testing the Pinpoint Landing technology on slip terrain the spacecraft is also equipped with a scientific instrument the near infrared multi multiband camera and it's designed to investigate the composition of the surrounding rocks after landing and this takes us on to considering the landing destination for slim which is near the sholi crater which I hope I'm pronouncing correctly so sholi is an impact crater meaning that it was formed when a meteorite struck the moon's surface when a crater forms through an impact event the debris from the deep interior can be ejected and a central Hill forms from those exposed deep materials so in and around impact craters we expect to possibly find rocks from the moon's deep interior that have been ejected and these are often found in Mounds in the center of craters or the surrounding Boulders in that region so one of the minerals that is particularly interesting for this is Olivine which is quite a heavy mineral and we expect it to have sunk into the moon's mantle during its formation therefore if we spot Olen On's surface it's probably a mantle Rock that's been ejected from the moon's interior and if we could land near one of those Olivine containing rocks and compare the composition with those on the earth it can tell us more about how the Earth formed moon formed and it might be taking like an hour to explain but he'll try to say it in one minute so here's a moon and this is the so this is the shape of the rabbit and you can see and this is a pattern that you can recognize on the moon so in Japan well uh the rabbit is what's seen on the moon's surface that's right and here he's pointing out the finger in that area this is man terce yeah so the Shi crater it's just right there at the spot of the right ear of the rabbit and then trying to um BL on this exact spot as you explained so here it is this is the rabbit's ear and there are two rabbit ears and the bottom one is the western side and then this is where the crater is so this is the landing site for slim it's going to be on this this Crater where we think we're going to have exposed Olivine material from the um moon man and it's on this slope terrain so we have to land very accurately the CR itself is very small like 1 kilm but um slim is trying to get that so by going there by slim what will we be able to find out so this is beyond the Slim's um scope but could you please tell us about the importance of This research so one of the main theories for the moon's formation is that it formed during a giant impact with the Earth if that's true the composition of the moon's mantle which is about 90% of the Moon would be expected to be similar to the Earth so if we can identify a mantle Rock I.E that Olivine and look at its composition in more detail we'll learn more about the moon's formation so kaga examined the moon's gey all over its surface it's spotted that near the Shi crater was a place where the mantle Rock seems to become Expos Ed and that's why slim is planning to touch down in this very small area and examine it with his multi-band camera could you please tell us more about this uh great Shi so the the bottom of the slide here we're actually seeing a model for how the moon might have formed if we look at these Cuts they're actually cuts through a wouldbe moon um these the sort of pizza slices where the core is at the bottom and then the surface is at the top so going from left to right the First Slice the green circles are this Olivine which is floating in initially a Molten maget ocean these thought have existed on the moon when it first formed if we go towards the right we're going to see the moon start to evolve this is the evolution a little later the relatively heavy Olivine has now sunk down to become sediment and begins to form the mantle in slice three the lighter buoyant calcium rich uh plagio class crystals which were actually shown by little rectangles at the top were rising to the surface and these form the moon's crust so then we only see Olivine again if you can dig up some of that mantle for example during a meteorite impact which might have created the sholi crater so in the larger picture that the scientist will be comparing the formation of the moon and the formation of the Earth by looking at that composition of the Olivine which should have come from the Moon B the question is if that was a giant impact that created the Earth or not but they might be more Ser to come so the research will be developed from this point on so Shi has a double meaning that by doing this you know landing on this Creator will leave the mark in on history and Shi in Japanese mean marking so this is a double meaning okay our last guest is ja's Vice President Sak so BP Sasaki is a director general for human spaceflight technology directorate and the leader for Japan's participation in altimus so could you please tell us about what you are doing right now for the [Music] altimus so Japan has already said that um it will be participating altimus and then there are three things that we will be planning on doing okay so the main goal of the altimus program is to establish a human presence on the moon but while doing so that Japan will be contributing more on the robotics as well and the first one is the uh crude mission that will be sitting on the foot on the lunar surface and also another one will be sending the uh pressurized Rover for crew driving on the lunar surface so in Washington DC as well that he has just been to that they are paying much attention to this project slim and because this is leading more uh techniques to be developed for altimus in the future so it has like a lot of anticipation and also excitement and for alist project to be going on that the both sides so crude and then unud so man and UNM um projects are important so they have to be developed in tandem so the slim will just go on and the first um focusing on the technology and um what will be what more can you do with this technique so this technique will leading us to go to the narrow space or the hidden space so it will give us much freedom to move around on the mar surface on the moon surface and there will be more applications in the future so we will be having more presence and also we'll be building more trust with the partners and it has been that Japan has um great trust building by presenting a trustful um Rockets um and also like you know we are adding more to this trust in international uh Partners so that um this technique will be highlighted and then it will be developed more in the near future what's next and then what can we say about the projects coming after Slim So we already have a few more things planned in the future so this will be the critical time for us to look at the success of the slim so Does it include the pressurized Rover and yes the Rover as well that it will go to the place where they want to go so the Pinpoint Landing is necessary but the Rovers can only go to the safer places so building this technique and then going to the place where is sort of hidden or it's very difficult to go and it's still um that technology will be useful in the future so that's exactly why BB Sasaki has been emphasizing the importance of both B and unand exploration and thank you very much hi so now we're going to return to morisan who's going to remind us of the key points as we head towards descent and Landing so here's our summary slide of slim attempting a Pinpoint Landing on the moon the power detent the power descent is from an altitude of 15 kilometers with uh three Thruster boots uh boosts and um coasting in between we approach the target sit on the lunar surface using this image matching navigation technology where we're going to match the craters to no and patterns on our onboard map using a navigation camera and autonomous guiding control then we begin the vertical descent from a 7 km altitude this includes three short hovering times and we also do obstacle detection to avoid any dangerous Boulders uh from about a 50 meter altitude and then the two little left rovers are released at a 2 meter altitude before we do the two-step landing on the sloped terrain and we're aiming for Luna Landing accuracy of order 100 Metter during this 20 minutes of teror Landing can be confirmed relatively quickly but more than that to do with the Pinpoint Landing accuracy might be determined um as much as a month from Landing this curve is very important because we start from the altitude 15 kilm and by pushing it forward from that point point it will be going a little bit upwards and then that will be very useful for the landing technique going vertical and also the engine will be shooting down so that uh energy will put the probe up there so this curve itself is very much uh suitable for pinpoint Ling so this looks like a very difficult design but um how what kind of things did you do to make it possible because slim looks like you know very much challenging you know including many new techniques so could you please tell us about um the highlights so that's right that there are many techniques that they are pushing um and also they're really um new and Innovative so uh what the team tried to do the most is try to um have more and more exper uh experiments and by getting successes um they are very confident to place those techniques put together in this prob slim the rocket launched on the 7th of September and around four months later that we are here today and other missions such as Russians and they took less time so why did Slim take four months could you please explain to us about it so this is something that we um so on the slide so the swing by we could probably just do one swing by to get into the AR U moon's orbit but by doing so we need to put so much fuel on the probe but um we want to have less in a tankk so we decided to do the longer swing by and then have this uh slim orbit so we chose this to have um more efficient and and this has become the one of the main goal of the Swing project so it's somewhat counterintuitive that this very long swing by orbit turns out to be much more efficient on fuel but even though it takes longer and it goes further it is able to use the gravity of this sun earth Moon system to actually alter the uh position and attitude of theace spacecraft to put it back onto a trajectory towards the moon and this is actually much cheaper on fuel as opposed to breaking when you got when you reach the moon the first time to enter lunar orbit straight away that's right so what do you think that we will be successful and it has been like many challenges and also failures as we all know but we like to uh believe that this will work today and um we have many experiments and many discussions so um today we believe that things will work I'm sorry for asking the difficult questions but as um morisan explained that many experiments proved that this technique should work so okay next question or maybe comments from the audience as the side if you look at the Moon that's in front of oh it's just gone off camera but to the left of that is one of the actual Landing legs from slim so you can examine its mesh Crush structure when it comes back on [Music] camera so um Can anyone observe it through the observatories or the telescope and morison's answer is that it's probably very difficult ah we can't see slim to so could you also tell us about this plan of landing on the slope so could you please uh explain to me a little bit more so from this angle you can see the five legs on the slim spacecraft the rear leg that sticks out the furthest and then um a more Square structure for the uh forward landing gear and middle landing gear so slim initially descends vertically and it's going to land on that rear most leg first that's the first one that's going to touch surface so it lands on the back leg and then it tips forward onto those front two legs two steps let us see this model what is it I'm glad they came back to this yeah it's one of these little legs so while a big Luna Lander such as you know Apollo actually has legs with a joint that are able to absorb the impact slim has these very compact Lattis likee legs that will compress on impact and absorb that Force as it comes down on the lunar surface so this is the end of the Q&A and comment so there are only five minutes to go so um morisan will review what will be happening in the next um yeah in the next uh few so this is our um Pinpoint Landing again the um Power descent from 15 kilomet the vertical descent from 7 kilm the search for possible hazards such as Boulders so overall when is start it will take about 20 minutes 20 minutes teror so first it approaches to the targeted position and then the vertical descent and it will have three hings and it will try to detect any Boulders and then when approaches it approaches to the slope and have two step um descent and Landing so it will be determined relatively soon about the landing itself but the pinpoint or not so how precise it was it will take about a month to process so now let us explain about the Telemetry so we will be moving forward to the screen like this and the Telemetry is the data that has been sent from the pro so this is the ql quick look screen and we'll see this during The Descent of the lunar surface and it will display the Telemetry the data coming from the spacecraft and we're going to go through just each of what you're seeing here to explain what it means so this is the date and the time in top yellow it's a spacecraft time but that corresponds almost exactly with Earth time as it only takes about a second for radio waves to travel between the Moon and the Earth it's showing the time in UTC universal time which is Japan time minus 9 hours now this part is the GNC guidance navigation control mode mode and you can see the different options for the modes with SPM being some pointing mode ocm being orbital control mode Etc and it tells you what phase we're in at the moment this is going to show us the spacecraft acceleration is the actual measured value of the accelerometer is on the left the estimated value based on the model is on the right and descending order for the acceleration goes from Green through to Red uh this shows the status of the auxiliary thrusters the scale here goes from Z to 100% And this is the status of the main engine injection with a scale again going from zero through to 100% this shows the angular velocity of the spacecraft along the three axes X Y and Z the colors here indicate descending orders of control error with green having minimal control error gosh we're going FAS this is the remaining propellent fuel is on the left the oxidizer is in the middle the total is on the right the fuel to oxidizer ratio is 1 to 0.8 the bat sock is the remaining battery capacity and now we are looking at uh if this graph looks like this this is the mode before power descent so um altitude from the Sun is seen on the left uh the attitude from the earth is on the right um this is now what it looks like when we go into the power descent mode uh showing positional information such as the trajectory white line and the actual trajectory is that right in the Red Line This is the vertical descent mode my apologies last one was the power descent mode this is vertical descent mode and so that takes us into an era of Landing where we can to Landing where we want so on the screen you will see the same Telemetry as the mission control room will be seeing so we are now switching the screen to the telemetry so during this phase as we head towards the lunar surface we are not going to say a great deal uh please watch the Telemetry and um so you can see for yourself how the spacecraft is progressing and there will be minimal uh commentary during this time main engine is 100% that means that it put the brakes and now the altitude is 15 kilom and it's slightly up so on the right you see the graph and the white is expected orbit and the red one is how slim is going so now Slim is going more or less on the planned trajectory and you started descent so now the engines are on but soon it will be turned off just for a while and then it will fly a little bit without slashing and on the right hand corner you see the second control room and in the second control room as well that they are seeing the same exact Telemetry as we see here on the screen for the altitude is now 20 kilm and this is the phase of the first boost and it we will keep going for a while Fuel and uh you can see it on the right top corners and it will have to decrease as it goes the velocity is just about right so you can see it on the left bottom and now you can see both A and B are green and it has been uh as it has been planned so things are going okay on that side as well the altitude is now reaching 25 kilm and it will now go into coasting mode so now it started to scan on the Boon's surface so it's looking for the exact place to land the altitude is just about 25 kilomet so slim is going into the second phase of boost so now you can see the engine ofing now you can see the planned trajectory and the red trajectory is going on the model so this is going very close to the planned trajectory so it start to descent a little bit as you can see on the right side it's still doing the second boost then fuels also decreasing as you can see on the right top corner and uh now you can see 96.6 kilog kilograms of fuel and it will be about 10 kilograms or even a little bit slightly more so that's where we are aiming at so it will not be completely empty velocity is increasing that's on the left hand side and because the mass is decreasing that means velocity is um getting a little bit more um in number it will continue a little bit we are still on the second boost stage now is still the second boo stage and it's now above 15 kilm and it will continue a little bit longer y still the second boost so when it goes below altitude 15 kilm it will start the coting again and then try to do the image scanning now you can see the engine has stopped like Z percent so now it starts cruising and trying to see um the surface so image scanning right now as it and soon we'll probably see the third phase of boost now you see the engines is on now 100% and now the thir stage of boost has just started and the third one will not be 100% all the time it's called the P SL so it's been expected that it's not going to be always 100% on [Music] now please pay attention to the left top PDM it will soon change vdm into vdm so PDM will change into vdm now approaching altitude 5 kilm now it's been changed BDM now starting the vertical descent so x axis is the west and the Y is now it started vertical descent for it will descend around 500 meter and it will start the first hovering around 500 meter it will start doing the first hovering it will be a short time but this is the first hovering it starts to descend again and next aim is 50 m so at the next point it will scan again to see if there are any obstacles or boulders second hovering now it's looking for the safe place to land around the two M it will release the left and it will land twep Landing as expected now you see on the left hand side MLM that means it has landed from the Telemetry it shows the sign m from the Telemetry what we see is the slim has landed on the slope for it looks like on the Telemetry that slim is on the surface of the Moon this we are now checking the status from the screen the slim is on the moon we are checking the status right now we are now checking the status of this limb it looks like it has reached on the moon from the screen that we see but we are checking the status [Music] we are still checking the stages [Music] e we are still checking the status for hi EG can we are still checking the status so please wait we are still checking the status so please wait you so we are still checking the stages so we close um this session at 12:30 and later on the same link and the same website that um press conference will start so please come back to the press conference we are still checking the status we are ending this program at 12:30 but we are still checking the status later on this channel that you later on this channel we will have the press conference so please wait we are still checking the status and the press conference will start shortly thank you you so we will end this program at 12:30 the press conference will be held will be held on the same link so please wait until the press conference begins we will be ending this program at 12:30 thank you for watching thank you very much for staying with us [Music] [Music] [Music] [Music] [Music] hi for [Music] [Music] foree [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] for [Music] [Music] [Music] [Music] [Music] [Music] [Music] e for [Music] [Music] [Music] [Music] [Music] [Music] for [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] to confirm the situation I could ask everyone we are still trying to confirm the situation right now so if we just wait for a little more while [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] e [Music] what and um thank you everyone at the sagamihara campus and also people participating through WebEx and those people um looking at this through uh YouTube uh we are still trying to confirm the situation um at the moment and so I apologize um to keep your waiting but please be with us for a little more while and uh we did actually say that it could take um as long as to hours um at the most uh in the the presskit in advance and for those people participating through YouTube please understand that it is taking a little bit of time um and uh we are trying to confirm the situation thank [Music] you [Music] [Music] [Music] yeah [Music] [Music] e [Music] [Music] e [Music] [Music] [Music] e [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] for [Music] [Music] for [Music] [Music] [Music] for [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] e [Music] [Music] [Music] [Music] [Music] [Music] e [Music] to say from Jacka The PR department and um everyone at the sagamihara at the campus present Center and also everyone listening through uh WebEx and also uh those people um looking at uh the Youtube and thank you very much uh for um uh waiting uh we now have some information uh we will uh start the the press conference uh from about 21 and so uh if you could U start make your preparation uh we intend to start the press conference at uh 10 minutes uh after 2 a.m. jst Japan Standard Time and uh we will uh also issue a release at the pointing as well but um uh we are also trying to upload information on our website at the same time and so there could be a bit of a a time lag to when we makes the exual press release [Music] e [Music] fore [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] for [Music] [Music] [Music] hi uh thank you for waiting my name is Kishi from um the the media of uh jaon we will be starting press conference soon so if I could ask you to be prepared and uh we have another uh person uh appearing on the stage so the person is heading uh towards the uh the podium so if you could just be with us for a few more seconds please uh thank you everyone for waiting and I apologize for uh making you wait uh we are already at a starting um time but um if you could just give us a little more while um while we prepare the the press conference thank you [Music] um thank you thank you very much for [Music] waiting uh we will uh start the uh the Press um briefing session regarding Luna in of slim a smart Lander for investigating Moon thank you very much for many of you for participating despite being aate into the night and we apologize for the fact that we have kept you waiting for quite a long time for those participating through uh web um WebEx and for those people also uh watching through the Jax official uh site um on the YouTube Jack Channel um apologize to have kept you uh waiting for quite a a long time my name is K Sasaki the the general manager of PR from Jackson I will be the MC today um the uh the Press briefing today um is held in a hybrid format live from communication Halls of of Space Science and exploration at sagam miara campus Jaa and uh we're also streaming this live on the Jaa official YouTube channel Jaa channel so I'd like to introduce the attendees uh from the right Dr Hiroshi yakwa president of Jackson and in the middle uh Dr hosi director general of Isis Jackson and next to him drakim deputy director of Ja and I think I think uh we are handing out the uh the press release um as of 10 minutes past two and so we would like to ask um the the president to uh start with a statement my name is director of um sorry the president of Jackson thank you very much for any of you for participating today I would like to start by saying uh a few things then the details will be explained by Mr kak and on the 20th of January 2024 uh at 1020 jst a smart Lander for investigating Moon landed on the moon we have been able to confirm that it has arrived on the moon as surface my name is k the the director general of Isis as I was explained a smart Lander for investigating Moon slim um we made a a challenge to landing on the moon now uh the slim has um been communicating uh to the Earth uh station and it is um receiving command from um the Earth accurately and uh is spacecraft is responding to these um um in a normal way however it seems that um the the solar cell is not generating electricity at this point in time and since we are not able to generate electricity and so the operation is being done using batteries onload and um based on the data um and Landing has been stored on the safe spacecraft and so uh we are trying to um the data source that to the Earth um and we are making effort to uh maximize the scientific um um the achievement um and during the descend To The Moon And while hovering above the uh the the moon uh surface we have been able to uh separate L one and L one uh once um are separated I will automat uh sent um the uh uh signal and that um has been successful so uh we do consider L one and Lev two have been successfully separated and uh we are making an effort to acquire data at this point in time and in order for us to analyze the data uh we will require some time uh that has been the case um uh schedule from the the start and so in regards to um sharing of the data um we will require a little more time and so what we know at this point in time is um as I have explained and so we are still Gathering data to understand the situation of this spacecraft also uh slim uh has um targeted uh the high Precision Landing um uh with an accuracy of 100 Metter well we require to do a uh detailed analysis of data as we have um um indicated in advance and so as to whether we have been able to achieve 100 meter accuracy or not um we would require a little more time for us to be able to confirm on this point and also um so we will gather um the data um we have been able to gather and we are hoping of holding a press conference uh next week uh as for the precise uh date uh we will inform you um uh uh next week and so that is what we know at this point in time so thank you very much any followup comment from droto thank you thank you very much the materials have been distributed to everybody in the venue and also those who are participating through WebEx online we are also web streaming this program so if you haven't received the materials yet please wait for them and also there will be a press release on the website of jaxa and we are updating information every now and then on the website so please be patient to receive the materials thank you very much indeed from an one without F you I would like to start taking questions from the members of the press so we have um members joining in the venue as well as online participants so first participants in the venue followed by questions by online participants if you are participating through weip line please state your name and affiliation by typing that into the chat and then we will appoint you so from the venue please wait for the microphone once you get the microphone please s your name and affiliation before you ask a question and since there are many members of the media joining the session so please limit your question to just one question and be brief now I can see some hands okay please wait for the microphone of s newspaper and first and foremost this time around a slim descended from the orbit and the landing itself stof Landing itself was it successful or was it a failure so solar cell panel is not a functional is not working at the moment the does that mean is that part of the criteria of um Successful Failure of the landing itself thank you for your question we believe that the soft learning itself was successful the major reason is because the space aircraft was um able to send T Teter to us which means that most of the equipment on the spacecraft is a functional working properly so as you could see online 10 kilm was the altitude from which descent was made so if The Descent power to descent wasn't successful then there would have been collision at a very high speed then the spacecraft function would have lost would have been lost completely but now it is still sending a data properly to us which means a original purpose objective of soft Landing was successful I believe this is the evidence for that thank you very I'm very happy to hear that if that's the case the trouble is just around solar cell it's a separate trouble or problem from the soft Landing thank you the the person towards my right I will take a microphone to you K from NHK no the uh the solar cell is not generating uh electricity right now and is that a trouble of the the solar panel itself or is it the the uh the attitude or direction or what are the possible reasons for this yes um as you have indicated the hardware of the solar cell and also the section receiving the electricity could be the cause of the trouble but other portion of the spacecraft is functioning uh correctly whether it be temperature data or the de pressure data we have been able to receive all the uh the the healthy uh values and so I don't think it's just the singular era of a solo self uh in itself um but another Point um it could be of um the uh attitude not um aiming at the intended um Direction so we are trying to analyze the data that we're gathering at this point in time and analyze the status at this point but what we can say at this point in time is what I've actually explained well thank you very much the gentleman in green n freelance writer so what is your observation could I ask um each of those three speakers to share your observations thank you very much first and foremost Landing was made and communication was established so minimum success was made in my view as for the details and detailed data assessment this will take place in the future so what about the Precision within 100 met and so on that assessment is still open so going forward by assessing a data and so on we will make many more findings so first and foremost learing was successful so going forward Japan's technology should develop even further and we should be able to access the lunar surface I believe that there is a path for opening to that now so with the various countries going forward there will be international corporation which is already underway so we'd like to provide all sorts of knowledge and insights that's my observation thank you very much so my question was that I wanted to ask observation from each speaker so as you saw on the web a quick look the original orbit intended orbit was a traced by the spacecraft the orbit was in line with that and the expected um acceleration was also traced the actual acceleration was also realized so on a real time basis we were able to share such information result with you so such an Outreach activity was possible this was uh done very well looking at the trace 100 meter Pinpoint Landing Precision Precision Landing was um pretty much successful of course regarding the accurate result we still need one month or so to do the analysis as we had already communicated with you in advance but in that sense we cannot say anything definitively it is premature to try to do that but the internet course was um followed so I personally observe that the Pinpoint Landing was also successful this technology going forward we will send more spacecrafts to the moon and also MMX some program is underway towards Mars as well so altim is some program is also saying moon to Ms should be realized so in this context as well Japan has established a major Milestone or stepping stone to that so I believe this was a greater step forward thank you very much so I was um in charge of the online a program I could see so many people rooting for it on the English Channel as well from across the globe tens of thousands of people have been watching and I'm very happy about it thank you very much so you are supporting us with we are in space science so at the end of the day we are doing things we are supposed to be doing we should be doing but it's not just really about your ego it is about um people supporting you then we will be even more motivated slam is such a difficult Mission but we've reached this point and that is because of the support that you've been providing and the team has been motivated even more I believe this is the reason why we have been able to do this thank you thank you yes uh the person at the front and the third person from here yes please go ahead my name is Ino a freelancer now the solar cell is not generating electricity as you have explained but um based on the plan for how long uh could um the the spacecraft continue to operate and the acquisition of data from the Luna surface is what you're going to prioritize but in terms of data do you have priority of what you would like to obtain well right now uh we are operating using battery mode and uh in order to conserve the the battery uh the electricity uh we have um um shut off the heat electricity in order to prolong uh its life and also the trajectory navigation that when the spacecraft was moving to the the the landing side we actually took photos of um the the crater um but we are downloading that with priority um and so navigation uh technology navigation data um in other words um as to whether Slim have been able to obtain this data accurately or not once we obtain this data then we know what type of trajectory uh the the uh the spacecraft took in uh making its descent and also be able to uh re uh produce or regenerate um the trajectory it took to the Aluna surface so that would be the data we want to download uh with priority we also have multiband uh camera um so the mental um substance composition can be analyzed using this um um the mul um then um um the Cera so we want to make sure that uh we are going we will try to you know function this with a priority but there is a limit to the battery and so at this point in time the battery power is likely to last for several hours and so it's already been 1 hour since Landing but within the the time available uh we'll try to do what we can do uh with our priority thank you very much okay so the lady over there well thank you very much I am writing for a news week a freelance writer AK is my name congratulations on the successful Landing so solar power cell is not working currently so slim can it take a pictures itself and 100 meter Pinpoint Landing success or failure I understand that slim can take pictures to make such an judgment and going forward if solar power may not be restored then Pinpoint Landing judgment would it become difficult maybe it's restored but if not would it be difficult to make the Judgment or what about the timing impact well thank you very much the store data is now being down link and by doing so on the flight pass what sort of data did it take we will be able to understand that largely and then currently it is receiving receptional signals so from the Earth orbit or trajectory decision technology can be used to identify where signals are coming from and already this decision making a technology for trajectory this cannot be done on a real time basis data has to be analyzed to identify the position in so 100 meter pinpoint leing success of failure data which can be evidence oford we will be able to obtain all the relevant data necessary for that as for the photos of pictures it can take the spacer craft was up in the air and then you took some pictures I believe you're talking about those are photos separately there is a r one L one and l two which had been separated already so L one and l two if they are functioning properly then slams photos and images have been taken by Lev one and left two and and I believe such a data is now being sent to us as for the analysis of this data it will take some time because of the nature of the work unfortunately it's not something we can show you immediately but Lev one and l two results are also something we looking forward to seeing thank you thank you yes um the person over there please yes um what is Saka from jst science portal now the solar cell is not generating electricity as you have explained and based on what you said battery would last for several hours in other words the several hours would be the the the remaining life of a slim U for it to operate that's probably how we should look at it but in order to enable solar cell to start generating electricity are you going to make any attempt is there anything you can do to try to enable the solar cell to start generating electricity well I think there are various ways of looking at it but um it is a invaluable um the the spacecraft and uh we don't know the accurate situation right now so we don't want to do anything that is um um too excessive so of the remaining hours and to try to do something about it we want to try to remain keep status quo and and the the solar angle will change and so every month um where the sunlight um uh Shines on the moon uh changes um um and this change occurs every month and so uh one day in Earth is um it moon goes around so so it takes 30 days for the solar angle to change of the Moon and so if that's the case so when the the the solar Direction change and and when the light shines from a different direction um the the light could end up um um hitting the the solar cell and so we have been discussion what is the best course of action for us to take into consideration of this and by data that's s angle uh return uh we uh hoping for it to regain uh Power so first of all while the battery is um alive you try to obtain data that you can obtain rather than trying to uh revive the solar cell but um if um um there could be the the the possibility that um the line the the the sun's direction will change and so uh even the battery may be not um generating electricity but there is still hope for uh this solar cell to start generating electricity again and um so if if so even if the battery runs out and the the the slim um they loses um um all power uh if um the panel catches sunlight then um it will um uh restart and so as as far as the function is concerned we will be able to you know uh re the operation of um the slim um in that instance thank you very much the gentleman sitting at the back hatanaka is my name on the live streaming screen there was a control room but there were almost no image from the control room what was it like during the landing so Landing was a finalized and solar power cell problem was discovered so any changes in the control room so we ourselves couldn't see the situation in the control room so we apologize that we we don't know what it was like in the control room thank you is that nak is from new if the solar cell um is not restarted then how would that impact the success criteria uh what can be achieved and what may not be achieved well in terms of success criteria um so you have the minimum success uh the full success and extra success and in regards to minimum success and is to achieve achieve Luna Landing uh using uh Optical navigation and to achieve um Precision uh landing and to demonstrate that and also develop a lightwe spacecraft system and check its operation in Orit so these are the minimum success criteria so in that regard we do feel that we have been successful in achieving the the minimum uh criteria for full success achieve High Precision Landing within 100 meter accuracy and in this regard as I've been explaining uh from the outset it will take about a month to do a accurate analysis so but um as you saw on the real time um the the live stream um the slim did Trace um the expected cause so my my personal uh impression is that we probably have been able to more or less achieve a high Precision uh Landing within 100 meter accuracy and so um the the solar cell state is unlikely to impact the the full um the success criteria extra uh continue activities on a luner surface for a certain period of time until Sunset well in this regard uh it requires the function of the solar cell so in regards to extra success uh there is a possibility of of not been able to um achieve this yeah thank you very much uh yes over there please first of all Japan has become the fifth country which made a success on this Landing Mission congratulations so the current posture of the space craft now the solar cell is not generating electricity so after the vertical Ling it touched the lunar surface in its right position or is the posture the same or is it upside down for example the solar cell is at the botom do you have any information about the posture of the spacecraft well thank you we are now gathering information and Performing analysis at this point in time we cannot give you um a response if that's thank you so once you receive some data through down link you can get some information to make a judgment yes we have obtained data so perform analysis would be possible and so next um we would like to um now receive questions from those people participating through WebEx and we'll come back to question questions from the venue um once again but if you like to ask a question from WebEx please um send in your question uh on the chat um but please mention your name so please write in your questions if you have one and I have now received a question please unmute yourself and ask your question my name from y congratulations for today now in relation to success criteria I would like to ask a question now in regards to the discussion of um the the attitude of this spacecraft you need to look at that but um one of the landing for uh slim was I think A two stage um uh Landing if after a soft Landing uh if you did not achieve um the uh the desired position so if uh the two-step Landing method was not successful then not being able to achieve the two-step Landing would that be considered um negatively from the success criteria perspective well well as long as you read the success criteria um we have not given a definition in regards to two stage Landing or two step landing and so if we apply the uh the success criteria as it's written then we have likely have met the criteria for for success and uh we did not give a a definition including in the twostep landing understood thank you it thank you very much the next question from web X newspaper please go ahead of my shimo newspaper thank you very much for this opportunity and congratulations on your success today once again my question would be that this time around slam made a successful landing on the lunar surface going forward well is now competing very fiercely about the lunar exploration what is the significance the success could you please share your thoughts on this once again Dr kuna thank as is we are in technology development what we do is technology development so Luna exploration for example Crips are promoted by NASA that is a commercial Luna Transport service and Jaa and iasa we are not really focusing on that sort of a area but technology obtains through this Mission can be leveraged for a private sector if some private sector companies want to use this technology then we try to proactively provide such a technology to them that's the position or thinking of ours so are we going to start a Luna transportation service that is not something we have been considering at all but from the Viewpoint of Industry development we do have some motivation what about pres yaka from the Viewpoint of international corporation what is your assessment about this success thank you very much for your question well earlier 100 met Precision was it realized or not we still need a one month more to make that assessment but at any this time around we were able to gain some insight and knowledge as well as experience based upon them used to be that we were Landing where we could now we are trying to land where we want that is the slogan of the project if you like so if 100 met Precision has been successful then as a result of this project this technology has been established and in relation to this this is the very first time in the world that this has achieved and the significance of this is that on a global basis across the globe there is some Fierce competition taking place about the access to the lunar surface that's because sustainable Luna exploration activity is expected and sort after now the position of the crater used to be that it was a landing where it good as opposed to where it wants to going forward it is more about exactly where in the crater he want to land such a high your level of precision will be needed so in that sense sustainable Luna and Luna service coration this will become a very important technology so by obtaining such technology of course um Japan International competitiveness can be enhanced and Acquired and without technology background it's not possible to provide International cooperation so we'd like to promote International cooperation to this end thank you thank you very much thank you next from weex from K news Su um apparently difficult ask questions um verly and so um please allow me uh to uh read this in regards to the Multi Band camera uh you have said that you'll try to operate this as quickly as possible but can this be operated and acquire data even without the the solar cell operating and if it is only with battery would it be that uh the amount of exploration that can be done will be limited in comparison to when the solar cell is generating electricity well it can only operate while the electricity is available so in terms of um um exploration time um the uh the scope to which the acceleration can be done could be narrowed um um based on this but given the environment uh we want to achieve the maximum uh scientific um um the achievement and so we'll continue to make effort enabled that thank you very much did I respond to the question thank you there was a comment written in the chat I saying thank you very much so freelance toim over to you to freelance writer congratulations on the successful Ling so I am aware that this is a detailed point in the release statement a solar cell is not generating electricity that's the current situation so the meaning of this is that it is it absolutely zero electricity being generated or electricity is generated but it's not enough for operation could you please um share with us the Nuance of this sentence we haven't looked at um numbers so we cannot quantify this having said that we understand that there is no electricity being generated not enough electricity for continuing activities that's what we hear from the team thank you very much I have a followup question you mentioned at this point in time so Sol cell Hardware problem may be solved or if the angle of the some changes the situation may be improved the solar cell itself is intact but it is generating no electricity is it the issue around the postor attitude do you have any evidence to make such a call or judgment so you mention that this may not be a hardware problem you have any evidence for that what is the rationale thank you on the orbital trajectory including the solar cell it is working appropriately and also after landing was made there was it is very unlikely that damage was made to the solar cell only the feature of the slim is that it is a small lightweight one 700 kilog which is only about a small car weight that's how the design and Manufacturing and production was done so it is a very a compact one in terms of the equipment inside so destroying or damaging the spacecraft when the solar cell only would be a damage that is very unlikely so we don't believe that it was under Hardware damage because we cannot detect any damage to other parts of the spacecraft and that's our thinking thank you thank you very much going forward I'm looking forward to hearing some good news thank you does anyone um participating through WebEx have um additional questions if you have a question uh please um indicate this it seems none so we'll go back to the venue and the person um with the hands up right at the end yes my name is um faki from Power Network um producing TV programs congratulations for your uh success now it is quite late in the night right now but um there could be children uh or young people who are interested in space or um better the moon but uh with this success um do you have any message particularly for young people and children and young people well the for the details we still have to analyze the data going forward but as I have said we have made a landing we have been able to establish communication so in that regard we are relieved um uh for now the slim project or um what um the Jackson Isis has always been saying is landing on the moon itself is of a very difficult technology and so doing something that is challenging like this um making efforts making challenges to you know something that is not all that easy is very important so the first point and and children um who will be our future I really do hope that children uh is going to try to make challenges to areas of Interest areas that one wants to engaging now in the the outer space um area there is um intensive competition but is also an area where collaboration is um essential so this is an area that require both competition and collaboration and in that regard the the Bas Technology based knowledge based KN how unless you have that unless you have these it's difficult to engage in neither competition nor collaboration so in that regard uh going forward you know we do want to you know link with various countries in the future and children who want to you know be engaged with um uh the countries outside Japan then the noan experience that will become the basis of that kind of interaction I think is very important um now at this point in time where we don't have accurate data and so it may be too much for me to say at this but this is my thoughts at this point in time well making in making preparation uh for uh the slim Mission I've um spoke with many people and someone said that no one on this Earth has never seen a moon so when children look up to the Moon from tomorrow and so slim landed uh in that location of the Moon um that we said that we're going to land and we made that Landing but why did Slim actually get there and of course there are a lot of reasons as to why slim traveled there and so we went there and we investigated the Rocks there and if we investigate those rocks what we what will we come to learn um in terms of um this type of um Mission U it's not just taking a photo where we obtain um information but uh we need to do a lot of things but the slim made a large steps the slim went to the moon in that location and what is it doing you're able to you know expand your thinking from there and if you actually think it in that way then I think the success on this occasion ends up being very meaningful we to welcome some more questions okay the person in Orange yes please NHK Miss as I had you making comments Landing was successful and 100 meter Landing is likely to have succeeded too if the possibility is high then I thought that you could look happier but all of your faces look very serious why is that answer because you really wanted to achieve extra success well it's um somewhat concerning that the solar cell is not working it is not activated so I am working most closely to the team and first and for almost we just want to know what's happened so including the president we just thinking about what a spacecraft is looking like what sort of condition it finds itself in so once that we know we will know the next step because we are always thinking about the next step so this kind of a situation is a very tough for us so rather than being happy about um what already happened we are always thinking about the next step and we don't have a full visibility about what the next step will be that's tough for us you saying that there has been a success but there are many steps going forward so you're concerned about them yes so if we can't work on the plan we' already made then we'd be happier but we don't know so we just want to think about the next step right okay thank you thank you very much yeah I know yes um the the person second row from the front nay is my name from um the kod news I on this occasion um the the focus has been the vision based navigation um and um the the Precision Landing but in regards to the vision um based um navigation has that gone well or will you not no this until you have identified that situation in regards to the Pinpoint Landing And in regards to the twostep landing you're still confirming as to whether we have achieved a success or not that's correct um we have accurately traced and we have actually um travel to the C crator and the we have been able to show the data in the real time downrange cross range we have been able to maintain very small number and we have been able to um Trace um the the trajectory and so in that regard um we do feel that Vision based navigation performed very well in regards to the two stage um um or two step Landing we are still trying to analyze the situation as you have indicated that's it thank you very much yes a person over there the person in the very front row newspaper so the landing itself was confirmed 20 past midnight were you able to immediately confirm that the landing was made and also when did you find out that the solar cell was not working could you share with us the specific timings you made these findings thank you as you could see in the real time monitor at the left of top there is a mode being indicated so power descent mode and vertical descent mode and finally Moon learning Mo mode such indications were made in that sequence so the spacecraft was switching across these different modes autonomously making um judgment and then a first 20 pass midnight ml MLM indication was AIT so by looking at that we were able to identif and recognize that the landing was made by the spacecraft and then after that happened if there was um a stronger Collision then the spacecraft would have lost its function losing signals and everything but even after that signals were continued to be sent so we were certain that the soft Landing was successful and then immediately after the landing then all sorts of checks took place the temperature and pressure of the equipment were they in normal range all teams analyzed that and then electricity was not being generated from the Sola cell that report came that way so the loss of electricity from the Sola cell that was immediately after the landing because the teams um made the confirmational checking work immediately after that yes sir person at the front here please my name is mat zawa from G press so it Leed that the the attitude was incorrect was not able to generate um electricity I think that was with the European the horizontal Landing feel I think similar thing had occurred and I assume they had presume something like this could occur so in that regard once the battery runs out and the procedure of thing so when the battery runs out and electricity is lost completely are you going to just wait for that naturally or are you going to implement some measures in the meantime and to maybe going into sleep C mode well and when the electricity or the but power is lost um we do allow for um the spacecraft um to um become in operation know but um after two weeks of nights and U the if the spacecraft um survives then in two weeks time uh we will have two weeks of night then after the two weeks of night there will be two weeks of day and um at that point in time uh the the sun will uh arrive uh at the solar panel and so if the uh the the spacecraft survives Theus 300° nights then in two weeks time uh it could um uh revive again so we did actually assume in the program of having to go through these cold nights so um the craft does have such a functionality so so we did we making we do have that kind of expectation so it does have that kind of function before the battery runs out are you going to do anything uh any procedure no we're not assuming to do so at this point in time well after the battery runs out and until it um um comes back what type of mode would you call it is there any name given to a mode so it's like a sleep mode well I suppose it would be kind of as sleep mode then I have a request I know you're involved in uh you know at tough times and so several hours so uh probably the all the operations will be completed um um by the day uh today so uh if you could make a press release or what had happened so maybe you know just a press release to say that the battery has run out if you could make kind of press release that will be appreciated we consider any other questions okay now I see one two three four five six hands and so we will take those questions and then we will give the floor to the WebEx participants okay the person over there rean osar currently the condition of the lunar surface so as Slim made the Ling and then I believe that spot is more towards the morning so where is the Su if you say what time it is that would be appreciated okay we cannot say an accurate number we don't have such data available able to make a response to that question if I remember correctly I believe that that spot is more of a morning so if the spacecraft is in a vertical posture and then if the cell the solar power cell is looking towards the west then it's going to be a little bit after a noon that the sunlight will shine on it is my understanding correct well yes we assume that there is such a possibility Anda to overcome the night to spend the night there may be a possibility that this will be successful to be more specific I believe you have some concerns about the aaty and so on what sort of functions that do you have available to prepare for this kind of situation well thank you what Slim So orinal purpose or main purpose is not to overcome the night so we just have this wishful thinking that slam will be able to survive the night if the light is on the solar cell then the reception equipment will start working once again automatically and then we can send a command from us to reawake the system but it's not slim is a main objective so it's not a fun main function but there is a possibility that this may be realized and to leave such a possibility available we have that function though it's not the main function thank you very much yes um the person I Look to yes as a second person yes thank you my name is takaka from minich shimun my newspaper sleep um landed on the moon um have you received any messages from overseas well we have not um received a kind of an official message um as yet we've been busy so we have not been able to confirm but just prior to um their Landing um we I did actually receive a message from NASA um and and um someone the shair person of um the the the the scientific group in the uslim was I think um um something that attracted lot of um interest in us because sizewise um and there is a cryp service where it's a private sector service trying to go into the move so this is similar service in that sense and so at that size would um good Mission can be carried out um and we are adopting a different approach to the states and so that's the reason why we have um received lot of interest um but after landing um I'm sure a lot of messages have been sent because my smartphone was very busy but I haven't had a look time to look at it but um I think they were looking at the the screen on the uh the live stream and they were send a message and I would assume that um the message is uh congratulate Le message but I'm little scared to look at it but I just didn't have time to look at them my smartphone oh yes the third person so the spacecraft signals are being received what about the ground station situation is in NASA that is being used at the timing of the landing the Japan base was used and 34 a met and US 64 meter were also operated so the main station was Ura station and that's the station that was used when the landing took place if that's the case it's not Ura it's a gold stone that is being used yes not true so the Japan base is no longer used it is um using um overseas station I don't remember of my head which station is being used right now yes sir the lady Wass the back my name is sasaya from TV Kanagawa I apologize for my question being very basic but data analysis for a Pinpoint Landing would require a certain time and in regards to the analysis of data concerning the current attitude of un slim I would require some time but without the that electricity from solar cell the time required for data analysis would that be affected one way or another or um that part is um going along the original schedule um it is actually U activity based on the original schedule and this is separate from the functionality of the solar cell so just um analysis of our acquired data and so in that regard uh we're not impacted by the the solell situation thank you very much the next question please newspaper Kar today to the media materials were distributed and then the images of the Luna surface were planned one hour later after the landing and 4 hours later the first lighter image from the camera was expected and in relation to this because of the solar cell the images themselves were not taken but IM or is it that the images had been indeed taken but you checking other situations you are not doing that yet and going forward what sort of images will be made available by slim thank you for your question about the images because of the solar cell situation we wen't able to we will not be able to proceed with the original plan my apologies having said that in um few days time there is a possibility that a slim has taken some data so it'll be analyzed under some Moon images maybe sh with you so it's not possible for us to provide such images within a couple of hours from now on but in due course I believe that we will be able to make some data available for you then is that the surface image of the Moon and a slim image Moon image is taken by slim and there is a possibility that uh Lev one and Lev two have taken some data and a multi band data camera data Maybe shared with you this is a possibility thank you very much and here right at the front is my name from n shim and uh congratulations on successful landing on the moon in regard to the development of slim on dis occasion I understand that many Japanese companies were involved and so I'm sure the Japanese companies have been very supportive and I would like to ask for you to make a comment to those the companies who have provided support yes many companies have U contributed and all those people involved um uh for Gathering today and um through the realtime Outreach um I think we also had an opportunity to enjoy um what was happening um uh inside onsite and uh space business or Space Project cannot be done by Jackson alone so procuring and um assembling and developing and uh this also requires efforts the know how the knowledge and all that from Japanese companies and so in that regard and also not just the companies but a lot of um uh the uh the teachers um from University are helped uh by providing their knowledge so in that regard we have received support from everyone uh throughout Japan which has enabled this I talked about the USA I talked about the antennas at those stations and um the the local community has um um made effort to contribute towards the space um the initiatives and so I would like to take this opportunity to express my sincere gratitude to everyone who have provided their support well thank you very much from web ex if anyone has a question we will be able to entertain to two three more questions anyone from weex any questions please write your questions into the chat two reporters have written questions as there second questions but I'd like to take questions from someone who's asking a question for the first time if not I'd like to give the floor to these two reporters we're asking questions for the second time if any please write your question into the chat so your M my apologies news so it's not a a voice the question it is a written question so let me read the question so eara solar cell is not a functional and you said that this is your concern based upon this situation and the learing itself was successful but going forward about the lunar exploration and learning technology to develop this even further what sort of challenges have you identified and what sort of issues would you like to overcome please we likey to increase the Precision or accuracy in making Landing soft landing on the moon itself was the very first attempt by jaxa as well as Isis so hard Landing had been made or realized a few times in the past but this time around this was um challenge because it was soft landing and then there are many difficult um issues and challenges we need to overcome we recognize them once again more frequently and more sustainably so that we can transport things to the Moon then we have to achieve a higher Precision learning a technology and we are feeling this once again fir hand so we try to obtain even more Technologies we want to increase the accuracy in our technology such our learning technology should become more accurate and precise and by doing so not just to the moon but also to Mars Landing will be possible this is within our scope of work so we try to make certain of such achievements what I wish to say earlier is that the battery end doesn't mean the end of the mission so I want to think about what sort of next steps can be taken of course beyond the slim there will be the next mission but at the same time the B doesn't mean a slim ending so that we can identify specific steps that we first of all want to know what sort of situation slim finds itself in so we want to spend the time available for us to grasp the situation to get the data we have to Aid so we cannot put a Smiles on our faces as yet because we are just wanting to see the next information the end of the battery doesn't mean the end of of SL Mission we just want um a Time an opportunity to think about the next steps and then about what's beyond slam my colleague had already discussed that for you thank you so suan has also um written in thank you um is from your shim from y shim here and in the Q&A before confirmation of landing and confirmation that the solar cell was not generating you have been able to confirm that relatively early but um the start of the press conference um took quite a long time so was that something that made judgment difficult and also uh from the Japanese perspective uh from the L exploration um um so following Gaga and we have been able to realize Luna landing and we have been able to return to the moon and so could I have your comment um in reflection of that as well please um well I do apologize for the fact that that we were late in starting the press conference well uh we are trying to analyze and interpret the data acquired so that did actually take more time than uh we had wanted and that was the reason why we needed uh more time uh to have been able to start the press conference and I very much apologize for that now we have returned to the moon but um going forward we do have a lupex plan and the lead uh plan and um we have deed um the pressurized l and the exploration U towards the moon we do have various um plans in mind and also towards the emis program uh we have um selected um candidates for astronauts so as indicated by these um U towards the moon and expansion of activities on the lunar surface we are uh in the midst of um um the uh going through the the steps and so we want to uh build up on the momentum towards these Endeavors thank you thank you very much there is one more question from web X Tokyo television T Tokyo please TV Tokyo your question please we cannot hear you it seems that theying to State the question verb so the question has been typed into the chat let me read it this is a basic question I'm afraid if a solar power generation has been possible then how long would the operation be and what is your satisfaction level if you quantify it please in theory during the day from the solar cell a power can be used and activities would be possible but another issue is that during the day the temperature is more than 100° C and the equipment temperature goes up along with the surface temperature of the Moon then chips or semiconductors will lose their functionalities at about 100° cus so if the temperature situation duras then the equipment would be broken especially electronics and so one would be dysfunctional so we don't know unless we actually do it that is a level of certainty we enjoy if the equipment lasts or survives for um a few days that is a good enough for us that was our Outlook so thank you very much thank you there was one more question from WebEx from modan modan from DK business please go ahead this is Mori from n business thank you for this opportunity now how to utilize the the successful outcome on this occasion you have mentioned um competition and collaboration number of times already but in terms of collaboration how to uh [Music] collaborate and are you going to wait as Jacka uh to be invited to projects by other countries or other companies or are you going to be proactive uh in trying to um they sell um What U we have um ourselves or is there already a kind of a technology collaboration agreement if you have something like that please let us know well at this point in time it's not the case that um we have a specific um project of um um providing this technology there is nothing that we can talk of at this point in time however from the perspective of international collaboration and towards um the oversees and the space agencies and the space agencies from around the world are creating missions together by bring um offering uh respective Technologies and so we want to you know deal um in those initiatives proactively as well but at this point in time uh we don't have any project we are able to mention um at this point in time thank you and U I would like to add a little bit um Optimus program uh is a program to explore the moon and the Mars um uh with a collaboration of various um countries astronauts are at the same time attracting a lot of attention but what timus program is saying is to have a lot of people engage and participate to explore the moon and the Mars and so the missions could be small but uh we need to create a system to enable meaning for um the outcome and that was what we have aimed for and I don't know whether we will take the initiative or not but um when you look at the outcome on this occasion um the people would consider this to be positive leading to International collaboration for those new countries uh wanting to get um involved in the space um exploration we want to collaborate and that is my thought um you know thinking about various things at the Isis that's my thought thank you by the way if that should happen would there be income um um for uh Jaa well well not a a monetary income um you know it could be International reputation in one sense but if we do something together and if a great um know the uh the observation um the equipment was provided uh for Japanese um the scientist to be able to make access uh so there are various um aspect in the deal but it's not a cash income per se but um I think slim on this occasion um and people uh praising this are considering it to be worth well as price R really oh thank you very much I'd like to conclude taking questions from web X and now turning to the Avenue once again or I could see or so many hands in the air first comes first okay so we will take five more questions and then that's the end of the press conference yes please Hai a freelancer writer thank you very much for this opportunity today kunaka said that the planned orbit was a traced trajectory was traced and acceleration was Trace so everything was very smooth and a Pinpoint Landing was more or less successful what about the final hovering when the vertical descent was made I saw that the final 2 to 3 m was somewhat fast about the vertical descent until the landing did you were you somewhat uncomfortable about the posture of the space aircraft which may have led to the issue this time around did you see any signs about this well thank you I wasn't able to identify that myself because I didn't have a data available so I couldn't Rec I had no recognition I didn't see what you had seen halfway through acceleration and a planed trajectory Trace so you you were seeing that yes but you just talked about some impression about the final couple meters I didn't have that what about Dr Fujimoto so my heart is pounding so I I'm impressed that you were looking at that so we will obtain data going forward so want to make a verification what was your impression when you saw the F final couple meters so during that operation from overseas I was being interviewed by overseas so I was in a way confused I I didn't no notic that if I respond simply so why did you say that you were impressed that you noticed that why it was um just old at your observation so now the reason why we are getting so much data trying to obtain so much data is because of what we want to do thank you another question is that my pinpoint learing was pretty much successful and then Dr yamawa said that this would become a world first achievement and then 100 m Precision Pinpoint Landing is it really the first feed and achievement in the world because I did some research in Apollo 12 in the cabinet of his materials 163 M Landing was successful I was able to find some materials but was that not intentional it just happened to be 163 M so are you saying that this intended Pinpoint Landing is the very first achievement in the world is that what you meant well that's my knowledge um to try to respond to your question accurately so could anyone follow up so yes intended 100 met Precision in London was the first achievement by a slim so this is amazing if it's the first achievement in the world yes that's our understanding thank you thank you thank you very much thank you yes the person there my name is Kanda from GJ press um the until the the the slim um the the the spacecraft structure was decided um lot of simulation and experiment must have been conducted but um as a consequence um so the time bench uh maybe the attitude um uh was not um um the right in the end but what were the potential risks that you had identified and you have recognized B on the surface and based on a k data you w't able to identify but in terms of the spacecraft stability um something that may have had the impact like a great Zone the large rocks or something like that um was something like that identified as a risk um initially well uh Kya data or the US um satellite or the US spacecraft data all these were utilized and put together um and to Target near the Cod Creator and that is what we had done and so um the utmost effort that we could have made have been uh injected to uh choose the location uh of landing and develop the the spacecraft enable that we feel that we have done everything we can and all the methods all the efforts we could and if there was anything that was um uh insufficient from our perspective uh we are trying to you know uh assertain that by gathering data and uh by analyzing the data so please give us a little more time in that regard yes thank you very much the person at the back and please wait for the microphone thank you now the data down link is proceeding and is slam data will include so much information but separately from that when making an attempt to the lunar Surface by various countries and NASA and so one are also providing precious images in terms of um slim are you going to provide um information to other countries and because of the ER or data is there going to be additional insight hi uh well thank you very much for your question so data taken by a slim will be a very local data well I cannot really respond to this question directly but what we can share the most is that when attempting a Pinpoint Landing we get experiences that can be shared so rather than data itself it is about the operational knowhow that we will be able to share so a slim will get KN how andely greater detailed data not really data itself but it's more about how to capture the data to make a Pinpoint Landing the experience or knowhow itself is what we can share I'm afraid I didn't fly understand your question so LR R going forward slim Landing sport images will be shared and so on to understand the situation of the space aircraft and so on for example we will you will know the attitude and positioning posture of the space aircraft uh yes so we will only have um a chance every one month because of the orbit condition now once data is made available the posture or attitude I can be recovered and recreated and we will be able to see that so now we are in the learning process yes you're right and so once the data has to be recreated and then L has to be checked but it doesn't happen immediately it's not going to be in the immediate future yes that's right so it to the back study with a back it sound a this is it all from sank news paper I apologize for asking questions while you quite tired but simple uh confirmation so right now uh solar cell is not generating electricity that's a situation but but prior to making the landing and so solar cell was um uh operating uh normally without any problem is that right yes um prior to making the landing uh SPM was um the the indication some pointing mode and that's the mode for the solar Asel pointing to the sun there was no warning and so I do believe that the solar cell was functioning well and so uh the solar cell issue had occurred after landing that's with question yes that is what we think and so uh I think it was proceeding uh in line with the plan but you didn't mention this in the release so um the start of The Descent start um as scheduled at um the midnight on the the do 000000 Z is that right yes yes please sh is science this is my second question about the solar cell so looking at the overview once again of configuration there is just one phase of one surface like a shell of a turtle just one side of the aircraft so perhaps you could have put a solar cells on other sides of the spacecraft um I believe that there are some design restraints and so on could you share with us the reason why solar panels are only one side or face of the space a craft the reason why I'm asking this is because of the past many years a slim has been underway and then looking at the CG provided by a Jaa of course this is only a 2d diagram so I somewhat remember that the was an verion which had um solar cells on all sides of the aircraft so perhaps that would have been helpful so could you please explain us to why you ended up with this configuration yes you're right through the history of the development configuration has changed many times as you rightly pointed out at the beginning it was a cylinder type space a craft and around the there was a spin axis there was a spin mode type spacecraft and then we made a some further considerations then for the twostep landing we opted for this particular approach and as a result this type of flood space aircraft was what we opted for twep Ling approach was what we we chose which changed the configuration to a great deal and solar panel body mount type a cylinder type model was abandoned and now we have this kind of a total shell solar cell type of model we made that change so body mount a cylinder body getting solar cells around it whatever Direction light comes from partial power generation would be possible which is a benefit but then there is a side which doesn't receive any sunlight then there will be a loss of power generation efficiency about one3 will be lost so it'll only be one third of the benefit compared with with the situation when all the power or solar cells are functioning but if there is only one side which carries solar cells receiving a sunlight and being fully operational which is very efficient this is very effective so with a small amount of solar cells necessary electricity can be generated a such benefit was expected so this was really a tradeoff we wanted to make the spacecraft lightweight because was one of the objectives of a Slim So as a result of such tradeoff cylinder a body was change to the turtle shell shape of body and then because of the combination with the two step Landing we opted for this particular method so not necessarily it's sometimes a good to put solar power cells across the space aircraft or putting that on only one area is sometimes a good so there is no right answer we just decided to opt for this option for slim there are also design parameters and as a result of making each decision we ended up with this model so design concept or thinking because of the slim concept rather than trying to be on the safe side by having solar cells all over the place just choosing one area was more ideal that was part of your design thinking thank you yes that's the case thank you very much so we do have um time constraints I'd like to uh limit the last question to someone asking questions someone who has not asked question yet are there two people okay so the person the front first please my name is shikura from shim now this um press conference um uh sakan was um uh to attend this initially the fact that he's not attend this because he was to prioritize the data down linking right yes yes myself too I was um a little bit um I'm concerned the fact that you don't look all that facty now now could um of this slim operation if you were to score um this uh how would you score and what SC out of what schore well I am um the director general of um Isis um jackon and so um the staff um tend to uh uh dislike um me for the fact that I tend to um make U rather harush uh comment uh so if you could have that in mind uh when I give my score and my score is 60 out of 100 so it's a pass Mark just yes the person at the back newspaper thank you just to confirm regarding L one and left two l two is working through Lev one so they working normally were able to confirm that they were taking images as well or any that's already being confirmed or any timing in the future you know that confirmation can be made and the only thing we are able to confirm is that the signals are being received for left one and left two and within those signals what s of data are included we are still performing analysis so with whether or not we have the images we cannot make a judgment as yet we will need a several more days to make s",
    "commentLink": "https://news.ycombinator.com/item?id=39056403",
    "commentBody": "Japan's first-ever soft lunar landing with SLIM spacecraft [video] (youtube.com)217 points by NedF 18 hours agohidepastfavorite83 comments dang 14 hours agoRelated articles: https://www.newscientist.com/article/2413336-japans-slim-spa... https://spacenews.com/japan-makes-history-with-tense-success... https://www.bbc.com/news/live/science-environment-68019846 (these were all submitted later but there weren't any comments yet to merge) qingcharles 16 hours agoprevLanding was successful. It is communicating with Earth, but the solar cell is not providing power so they are burning up the battery. They are trying to get as much data from the unit as possible before the battery dies. They took photos and are downloading them as priority now. They have been forced to switch off the heater. There is only a few hours of battery available to do what they need. They have separated LEV1 and LEV2 (rovers). Stay posted, they say. Need more time to figure out what is going on. reply fffernan 12 hours agoparentHappens to me all the time in Kerbal reply deepsun 10 hours agorootparentUsually because I forgot about the solar panels. reply raisin_churn 7 hours agorootparentFortunately with EVA construction you can now just send Bill to glue one on. I hope JAXA is running >1.11. reply efitz 4 hours agorootparentprevAnd the ladder reply nickmcc 12 hours agoparentprevHas anyone confirmed if LEV1 and LEV2 can continue to operate and communicate to earth independently from SLIM, if the SLIM batteries fail? reply londons_explore 9 hours agorootparentone can, the other cannot reply sjwhevvvvvsj 15 hours agoparentprevIsn’t there just an “IT guy” they can send over? reply T-A 15 hours agorootparentYou just reminded me of this little cinematic gem: https://www.imdb.com/title/tt1182345/?ref_=nv_sr_srsg_8_tt_6... reply aikinai 59 minutes agorootparentI had never heard of Moon and randomly picked it to watch on an airplane with no Internet. I was not prepared for that good of a movie! reply seraphsf 14 hours agorootparentprevLove that movie! What an amazing piece of small-scale sci-fi. reply ddol 7 hours agorootparentAnother great small budget movie is Primer (2004). It has one of the biggest Budget to Box office multiples I know of: ~120x ($7k -> $841k) reply grecy 5 hours agorootparentI think Mad Max holds the record. (the original) Mad Max. $200k budget, almost $100m worldwide, for a 495x ROI reply kevinmchugh 4 hours agorootparentDeep Throat had at least a 600x multiple (a budget of $47,000 and a box office somewhere between 30 million and 50 million). Blair witch had over a 1000x multiple, with the same 200k budget as mad Max and a box office around 200 million. Paranormal Activity also seems to be close to the 1000x mark. reply dtgriscom 7 hours agorootparentprevWhat a quiet, calm, moving soundtrack. reply HPMOR 15 hours agorootparentprevWow seems like a great movie! reply qingcharles 14 hours agorootparentIt's an awesome under-rated gem. reply belter 14 hours agorootparentprevIt is. Great finale also. reply riffraff 12 hours agorootparentprevit's an absolute masterpiece. reply noncoml 11 hours agorootparentprevIt is! Highly recommended! reply deepsun 10 hours agorootparentprevThe best acting by Kevin Spacey! reply ASalazarMX 12 hours agorootparentprevI hope to see the time when it's normal to send a pair/party of multifunctional robots instead of a single rover. Imagine them repairing each other's back. reply dotancohen 6 hours agorootparentprevJeb? reply layer8 13 hours agorootparentprevHave they tried turning it off and on again? reply letmevoteplease 18 hours agoprevThe official JAXA streams are here: Japanese: https://www.youtube.com/watch?v=Udh6kvjZYC8 English: https://www.youtube.com/watch?v=nvXLt3ET9mE Edit: It was supposed to touch down at this point, but they are pausing for 30 minutes to check the status of the craft. Doesn't look hopeful to me. Edit 2: They now say it may take up to 2 hours to confirm the situation. Edit 3: The craft landed successfully and is communicating properly, but the solar cell is not generating electricity, so it is being operated on low battery power. Lunar Excursion Vehicle 1 and 2 have been successfully separated. reply rtkwe 17 hours agoparentLooks like it might have rolled on landing if their telemetry representation is accurate. There were some pretty significant rotation rate readings right after the throttles shut down. reply bradyd 15 hours agorootparentFrom @roelschroeven's post [1], rolling during landing was part of the design. It's possible it didn't roll as expected, though, blocking the solar panels. However the fact they were able to separate the rovers makes it seem like it could be a technical issue with the panels instead. [1] https://news.ycombinator.com/item?id=39057224 reply rtkwe 13 hours agorootparentSaw that after I posted. It's an interesting design I hadn't seen before. Hopefully it worked out. reply greggsy 16 hours agorootparentprevIt is designed to approach vertically, the drop forward on four feet reply londons_explore 9 hours agorootparentand it actually dropped sideways instead of forward reply burrish 18 hours agoparentprev250k viewers in the Japanese stream wow reply JKCalhoun 16 hours agoparentprevPress conference has begun. reply greggsy 15 hours agoparentprevIt really is refreshing to see the restrained satisfaction after a successful operation, compared to the jeering and cheers we’ve come to expect from the team during every SpaceX mission. reply huytersd 5 hours agorootparentI think it’s more a dissatisfaction over a not totally successful mission than a restrained satisfaction. reply jcims 9 hours agorootparentprevEh, I love the cheering. reply codeulike 18 hours agoprevAmbiguous landing The tiny LEV2 spherical rover looks cool, hope it made it https://global.jaxa.jp/activity/pr/jaxas/no088/03.html reply cuSetanta 15 hours agoparentThe forst model of that rover was on the ispace lander and I had the pleasure of working with the Jaxa team integrating it. Was super fun to see it rolling back and forth and taking images in the test facility. It was the payload I was most sad to have lost on our crash. reply rwmj 18 hours agoparentprevI hope Tomy company is the very same that did all the toys and robots in the 1980s: https://en.wikipedia.org/wiki/Tomy reply ginko 18 hours agorootparentIt is. They mentioned in the live stream. reply samstave 17 hours agoparentprevI wish we could \"cluster bomb\" celestial bodies with such spheres where they have a sensor core and just roam about. Imagine deploying a body of bots via a star-link-type-launcher that just spits out a bunch of these guys as it orbits the moon - then they land and roll araound and comm back to the deployment sat and talk to eachother as the Roomba the F out of the moon and give all sensor data back to the sat launcher as it orbits... reply FranOntanaya 17 minutes agorootparentSeismic sensors would definitely benefit from this. Scientists have to get clever to estimate the direction of events when using a single sensor like on the InSight lander. reply Teever 17 hours agorootparentprevI had similar thoughts when I saw the flea robot from Boston Dynamics.[0] Imagine exploring mars with a combination of a dozen or so flea type robots that have solar panels on them and a robot arm for sample retrieval that can fold up into the body. They can trundle around the surface taking video and picking up samples as desired and then return to the stationary lander that they came from when needed. The stationary lander can have all of the sample analysis machinery, seismograph, weather station, as well as a high bandwidth uplink to satellites in orbit / Earth. Keep landing more and more of these within the the same area so that the fleas can travel between the stationary landers as they travel further and further, heck you can even form a mesh network between all of the machines on the ground, and offload a lot of heavy computational processing to the stationary landers that could be powered by an RTG. You can risk individual fleas doing dangerous things that you otherwise wouldn't want to risk one large all in one lander on, as losing a flea only degrades a small fraction of your research and if fleas get stuck somewhere another flea can attempt to rescue it. You could even have the fleas return home to overwinter if they're not designed to withstand the winter. There's so much versatility that you gain in a model like this with small disposable rover robots paired with massive stationary landers. [0] https://www.youtube.com/watch?v=6b4ZZQkcNEo reply anigbrowl 3 hours agorootparentCan't believe that video is >10 years old. The 'big wheels on a pancake' form factor is easily available now inIt also looked like it went below 0 altitude? \"Lithobraking\"[1] [1]: https://en.wikipedia.org/wiki/Lithobraking reply T-A 17 hours agorootparentprevThat would be consistent with it rolling down the slope. reply burkaman 17 hours agorootparentThat makes sense. I was thinking that its altitude sensor might have been miscalibrated or confused, so it hadn't yet reached the ground when it thought it had. reply rebolek 17 hours agoparentprevIIRC, it should have flipped, that's how it lands. Unusual, but why not. reply tjpnz 17 hours agoparentprevAssuming it did flip over would Japan still be on the list of countries to have successfully landed? There's a big difference between what we presumably witnessed and an out of control craft smashing into the surface. reply eichin 15 hours agorootparentIn the vein of \"any landing you can walk away from\", between it (a) successfully deploying the sub-rovers (though maybe that happens slightly before contact?) (b) it communicating enough post-landing telemetry that they can diagnose things, I think that should count as \"successfully landing\". (One of the actual mission goals was ending up on the ground within meters of where they intended, and it sounds like they nailed that too?) reply talldatethrow 10 hours agorootparentIf your main goal was to land and go forward with tests, but your landing started the soon to be demise of the cargo, I cant really say it's successful. It deployed the rovers similar to how injured pilots might still exist an aircraft after a crash. If they soon die due to solar panel issues from the crash, they didn't really walk away to live another day. reply tjpnz 15 hours agorootparentprevNote that my comment was written when they were still trying to regain contact with the lander. reply skeaker 16 hours agoprevListening to the press conference, it sounds like the landing was a success but that the solar generators aren't creating any power, so they're currently on low power from the battery as they try to figure that out. reply layer8 13 hours agoprevAnyone know why the crater is romanized “shioli” rather than “shiori”? reply z2 12 hours agoparenthttps://planetarynames.wr.usgs.gov/Feature/15851 Reference: [536] - “‘Deadpool 2’ Sets Actress Shioli Kutsuna In A Key Role”: https://deadline.com/2017/06/deadpool-2-shioli-kutsuna-ryan-... So perhaps the question is, did Shioli's parents choose this spelling because they felt Australians may more correctly pronounce her name with an L instead of an R? reply layer8 12 hours agorootparentI’m not sure I understand the reference, since it doesn’t mention the crater. It looks like it is just meant to be a evidence that “Shioli” can be a “Japanese female first name”. In either case, that romanization is uncommon, so the question stands. I wondered about pronunciation by foreigners being a motivation, but I would still expect an incorrect pronunciation like “shy-oh-ly”. reply numpad0 10 hours agorootparentConsidering this is an ISAS project I wouldn't be surprised there were an eroge character named and spelled conspicuously similar to that. That naming was briefly mentioned in the press conference, and the official reasoning told was it was so named \"in the hope this landing will be a bookmark(shiori) in the long history of human aspirations towards the Moon\", :shrug:. reply kadoban 10 hours agorootparentprevIt's a quote from the first link, about the crater. I believe the meaning is that the crater was named after the actress, and presumably copied the spelling of her name. reply seatac76 14 hours agoprevThe rovers are so interesting, glad they got those out. reply aaron695 18 hours agoprevThere is livestream of the signal being picked up at Bochum. They say it landed safely (See comments on the right) \"Live spectrum view and waterfall from the X-Band or S-Band receiver at the 20m radio telescope at Bochum Observatory / Germany\" -https://www.youtube.com/watch?v=2pPBCIpVGsM Space really has a PR issue, waiting around for a press conference and they really need live video from the moon, it's hard but important. reply GartzenDeHaes 16 hours agoparentLive TV from Apollo 11 had a huge cultural impact. People who were born before the Wright Brothers flier watched the moon landing on live TV. They had an incredible sense of Progress that we seem to have mostly lost. reply xeromal 15 hours agorootparentTo this day, it's the most watched program in terms of raw numbers, not even percentage! reply londons_explore 9 hours agorootparentprevSomeone born in 1900 went from horse and cart to landing on the moon in their lifespan. Someone born in 1960 will go from telephones and libraries to apps and VR headsets... I know which transformation I think is more impressive. reply edgyquant 17 hours agoparentprevThe moon is far enough away that there will be a 1 second time delay regardless reply wolverine876 17 hours agoprev [–] It is a private company, not the country of Japan, if I understand correctly. EDIT: Other sources say it's JAXA. I'll withdraw the comment, sorry, but I wonder if there's a bit more to it. reply SECProto 17 hours agoparent [–] > It is a private company, not the country of Japan, if I understand correctly. What makes you say that? It looks like a JAXA programme to me: https://en.wikipedia.org/wiki/Smart_Lander_for_Investigating... reply wolverine876 17 hours agorootparent [–] Hmmm ... the CBS Evening News channel on YouTube said it was a private company, another subthread here refers to one. I wonder what he arrangement is. JAXA subcontracted it? reply burkaman 16 hours agorootparentCBS was probably talking about LEV-2, one of the rovers on board, which did have some contributions from private companies: https://en.wikipedia.org/wiki/Smart_Lander_for_Investigating.... reply seaal 16 hours agorootparentprev>JAXA is the Japanese national air and space agency. Through the merger of three previously independent organizations, JAXA was formed on 1 October 2003. reply RationPhantoms 17 hours agorootparentprev [–] Maybe they're confusing that with the last Japanese-originated lunar landing (That was a private company, ispace, that attempted and was unsuccessful) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "China's lunar mission is utilizing the spacecraft SLIM, which employs gravitational forces and is equipped with solar panels and rovers.",
      "The mission aims to study rock formations and analyze the mineral Olivine on the moon's surface.",
      "Despite some solar cell issues, the spacecraft has successfully landed and established communication, showcasing the significance of precise landing technology and global cooperation in lunar exploration."
    ],
    "commentSummary": [
      "Japan has achieved its first soft lunar landing with the SLIM spacecraft, but is experiencing issues with the solar cell and battery power.",
      "The team is collecting data before the battery fails, raising concerns about the mission's success without proper solar panel functionality.",
      "There is discussion surrounding the spherical rover LEV2, the involvement of Tomy in creating toys and robots, and debates over crater names and the impact of moon landings on culture. Speculation suggests that JAXA may have subcontracted some aspects of the space program to private companies."
    ],
    "points": 217,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1705676819
  },
  {
    "id": 39055506,
    "title": "French Cheese Industry Faces Threat from Lack of Microbial Diversity",
    "originLink": "https://news.cnrs.fr/articles/french-cheese-under-threat",
    "originBody": "You are here Home / Articles / French cheese under threat Lire en français 0 comment Life Biology -A +A Print article French cheese under threat 01.16.2024, by Mehdi Harmi Romain GAILLARD/REA Share Share (link is external) (link is external) Cheeses host a multitude of microorganisms that turn milk into curds. Selected by humans, these ferments are not exempt from food industry regulations – to the point that blue cheeses and Camembert could disappear. Ever heard of Termignon blue? This little-known cheese, produced by just a few farms in the French Alps, could well save the entire blue cheese industry, which is threatened with extinction due to the standardisation of production processes. This is because its characteristic blue-green mould comes from a previously unknown population of Penicillium roqueforti, the fungus used in the fermentation of all blue and veined cheeses. The discovery is a bombshell in the world of cheese. Termignon blue, made in the Savoie region in the French Alps, naturally develops a blue-green mould, unlike other blue cheeses that are inoculated with “Penicillium”. Termignon blue, made in the Savoie region in the French Alps, naturally develops a blue-green mould, unlike other blue cheeses that are inoculated with “Penicillium”. Science Photo Library / DK Science Photo Library / DK Share Share (link is external) (link is external) “Until now, only four populations of the P. roqueforti species were known in the world,” reports Jeanne Ropars, who, with Tatiana Giraud and their team at the ESE1 in Gif-sur-Yvette (near Paris), has successfully sequenced the genome of the microorganism responsible for the fermentation of Termignon blue. This consists in “two ‘wild’ populations, involved in the rotting of fruit, the decomposition of certain foods and silage (the fermentation of fodder for livestock - Editor's note), plus another two used in cheese production”, the researcher specifies. Of the two domesticated populations, one is specifically dedicated to PDO (Protected Designation of Origin) Roquefort, whereas all the other blue cheeses are inoculated with a single strain of P. roqueforti. To produce cheese in large quantities, manufacturers have selected fungus strains that meet their self-imposed specifications. The cheeses must be appealing, with a good flavour, no unappetising colours and no mycotoxins (toxins secreted by fungi), and the chosen fungus must grow quickly in the cheese that it is intended to colonise. In pursuit of this goal, the food industry has exerted so much pressure on the selection of fungi that the microbial diversity among non-farm-produced, non-PDO cheeses has become extremely impoverished. Blues entering the red zone “We’ve been able to domesticate these invisible organisms just as we did with dogs or cabbage,” Ropars explains. “But what happened, as it does every time an organism large or small is subjected to overly drastic selection, is that their genetic diversity has been greatly reduced. Working with microorganisms, the cheese makers didn’t realise that they had selected a single individual, which is not sustainable over the long term.” Microorganisms are capable of both sexual and asexual reproduction, but the industry relied primarily on the asexual method, producing clonal lineages to perpetuate the moulds. As a result, they can no longer reproduce with other strains that could provide them with new genetic material, a situation that, over time, induces the degeneration of the strain in question. A 3D illustration of the “Penicillium roqueforti” fungus used in the production of blue cheeses. A 3D illustration of the “Penicillium roqueforti” fungus used in the production of blue cheeses. Dr_Microbe /Stock.adobe.com Dr_Microbe /Stock.adobe.com Share Share (link is external) (link is external) “The population used in PDO Roquefort has not suffered so much from the selection process, and still has a bit more diversity,” adds Giraud, who reports having identified several different strains. This is not the case for the clonal line used by the rest of the producers, which has been weakened to the point of becoming nearly infertile. “Even the smallest cheese makers are affected,” the researcher recounts. “For a long time they ‘grew’ their own strains of P. roqueforti, but now they mostly buy their ferments directly from large spore producers that supply the entire food industry.” Consequently, the fungi that have accumulated multiple deleterious mutations in their genomes over years of vegetative propagation become virtually infertile, adversely affecting cheese production. “This is what happens when we completely stop using sexual reproduction,” Giraud explains. “It’s the only way to compensate for detrimental mutations through the introduction of new genes – the famous genetic mixing.” This is where Termignon blue, with its newly-discovered population of P. roqueforti, comes into play: it could in fact offer cheese producers the genetic diversity that is woefully lacking in their ferments. However, this means assuming the risk of sexual reproduction, which does indeed create diversity but also causes greater variability in the finished product. Camembert on the endangered list Blue cheeses may be under threat, but the situation is much worse for Camembert, which is already on the verge of extinction. The world over, this other symbol of French gastronomy is inoculated exclusively with one single strain of Penicillium camemberti, a white mutant that was selected for Brie cheeses in 1898 and Camemberts in 1902. The problem is that ever since then the strain has been replicated by vegetative propagation only. Until the 1950s, Camemberts still had grey, green or in some cases orange-tinged moulds on their surface. But the industry was not fond of these colours, considering them unappealing, and staked everything on the albino strain of P. camemberti, which is completely white and moreover has a silky texture. This is how Camembert acquired its now-characteristic pure white rind. Year after year, generation after generation, the albino strain of P. camemberti, which was already incapable of sexual reproduction, lost its ability to produce asexual spores. As a result it is now very difficult for the entire industry to obtain enough P. camemberti spores to inoculate their production of the famous Norman cheese. The albino strain of “P. camemberti” gives Camembert its characteristic white, silky rind. The albino strain of “P. camemberti” gives Camembert its characteristic white, silky rind. CHARLY TRIBALLEAU / AFP CHARLY TRIBALLEAU / AFP Share Share (link is external) (link is external) Worse still, while the Roquefort PDO standard retains a degree of microbial biodiversity, the PDO specifications for Camembert require farmers and other producers to use P. camemberti exclusively. To compensate for the shortcomings caused by its degeneration, some cheese makers resort to supplementing P. camemberti with a second species of fungi: Geotrichum candidum, also selected for its white, cottony texture. So what can be done to save Camembert? Should producers return to a “wild” population, similar to P. camemberti, and restart the long process of domestication? Could they resort to genome editing technologies in order to counter the accumulation of mutations or the loss of specific genes with a given desirable function? “People in the industry sometimes ask us whether it’s possible to modify a gene and allow a strain to sporulate in greater quantities,” Giraud reveals, quickly adding that this would not solve the problem: “Genome editing is another form of selection. What we need today is the diversity provided by sexual reproduction between individuals with different genomes.” Cultures of “Penicillium camemberti” (white and cottony) and “Penicillium biforme” (greyish green) in a petri dish. Cultures of “Penicillium camemberti” (white and cottony) and “Penicillium biforme” (greyish green) in a petri dish. Tatiana Giraud Tatiana Giraud Share Share (link is external) (link is external) A species that is genetically similar to P. camemberti, called Penicillium biforme, also found in cheese because it is naturally present in raw milk, possesses an incredible genetic and phenotypic diversity. This opens up the possibility of inoculating Camemberts and Bries with P. biforme. If cheese lovers want to keep enjoying these products, they will have to learn to appreciate greater diversity in flavour, colour and texture, perhaps even among cheeses from a single source. And, who knows, thereby contribute to enriching our gastronomic heritage. ♦ Footnotes 1. Laboratoire Écologie, Systématique et Évolution (CNRS / AgroParisTech / Université Paris-Saclay). Go further 0 comment Keywords Camembert Roquefort Bleu de Termignon P. roqueforti Microorganism Protected Designation of Origin mycotoxin fungus mould genetic mixing P. camemberti Brie Geotrichum candidum genome editing P. biforme Share this article (link is external) (link is external) Author Mehdi Harmi Writer for CNRS Le Journal See author's bio Is a war for water looming?Previous Science behind the scenesNext See also Life Slideshow 01/18/2024 Science behind the scenes Article 12/15/2023 Addiction is not hardwired in the brain Article 12/05/2023 A new antibody for fighting cancer Article 11/29/2023 AI detects the early signs of multiple sclerosis Article 11/20/2023 Understanding vertigo Biology Article 07/14/2023 The endless cycle of pandemics Article 06/22/2023 Modelling the lungs for personalised medicine Slideshow 03/24/2023 Do women enjoy better muscle recovery? Video 01/25/2023 Organoids : laboratory brains for research Article 10/10/2022 Mini-organs with maximum potential Comments 0 comment RSS feed To comment on this article, Log in, join the CNRS News community Log in Register",
    "commentLink": "https://news.ycombinator.com/item?id=39055506",
    "commentBody": "French cheese under threat from lack of microbial diversity (cnrs.fr)213 points by perihelions 20 hours agohidepastfavorite168 comments forty 14 hours agoI like how cheese stubbornly doesn't want to be an industrial tasteless odorless crap. Camembert is well known to be mostly controlled by industrial, meaning most Camembert even here in France are industrial crap (there is a AOP/DPO \"Camembert de Normandie\" which is better and at least forbids pasteurized milk). reply conradfr 1 hour agoparentActually the AOP has been weakened by the industrial lobby since 2021, the real one is now «véritable camembert de Normandie». Personally I've never been a fan, except when barbecued. reply JodieBenitez 12 hours agoparentprevWatch out for: - Jort - Marie Harel - Gillot - Moulin de Carel reply hammock 11 hours agorootparentThose are good ones? Or bad ones? I believe Marie Harel invented camembert reply JodieBenitez 3 hours agorootparentYes, those are good ones. BTW, Marie Harel is made by Gillot. As a general rule, avoid any pasteurized camembert, they have no taste. reply wazoox 11 hours agorootparentprevThose are good. reply xwolfi 9 hours agoparentprevTo be honest, I was born and spent my first 23 years in Normandy, never quite could enjoy the real Camembert. I prefer the supermaket ones with less aggressive taste. Ofc I moved to China and now all I can eat is Brie. reply ekianjo 4 hours agorootparentThey dont import Camembert in China? In Japan we hardly ever find Brie reply WirelessGigabit 13 hours agoprevCleanliness is also the cause that there were less and smaller holes in Swiss Cheese. HN-celebrated Tom Scott did a video on it last year: https://www.youtube.com/watch?v=evV05QeSjAw reply hammock 11 hours agoparentTLDR: milk is produced in closed system now, meaning dust from the barn doesn't get in it. They added 1 part per thousand of hay dust to the milk, and all the holes came back reply troad 7 hours agorootparentThank you for the summary. YouTube links are a terrible way to transmit information. reply fsckboy 6 hours agorootparentprev1cc of hay dust per liter of milk is actually a lot of hay dust. does the hay need to be from the barn, are we talking barn dust here? reply thfuran 5 hours agorootparentThat is a lot. What they actually said was 1 mg of hay dust per 1000 L. They didn't elaborate on how they sourced their hay. reply jahewson 5 hours agorootparentThat’s 1 ppm. Much more reasonable! reply leobg 14 hours agoprevReminds me of a book I read more than a decade ago. The Culture Code. By Clotaire Rapaille. He argued that 'the French Code for cheese is ALIVE. The American Code for cheese, on the other hand, is DEAD.' I don’t have the book handy, but here is a quote from the web: > I started working with a French company in America, and they were trying to sell French cheese to the Americans. And they didn't understand, because in France the cheese is alive, which means that you can buy it young, mature or old, and that's why you have to read the age of the cheese when you go to buy the cheese. So you smell, you touch, you poke. If you need cheese for today, you want to buy a mature cheese. If you want cheese for next week, you buy a young cheese. And when you buy young cheese for next week, you go home, [but] you never put the cheese in the refrigerator, because you don't put your cat in the refrigerator. It's the same; it's alive. We are very afraid of getting sick with cheese. reply GuB-42 9 hours agoparentAs a french, and also cheese lover. Yes, cheese is absolutely alive. And one thing I love about \"real\" cheese is variation. Depending on the season, conditions,... and chance, you get cheese that is different. Not always great, sometimes I am disappointed, but there are other occasions where the result is so good that it is well worth the occasional disappointment. Industrial cheese is boring, it is never bad, but it is never good either. As for being sick. I never got sick with cheese, despite eating cheese on a daily basis. And I have eaten cheese that is way after its \"use by\" date, cheese with the \"wrong\" mold, cheese strong enough to numb the tongue after eating a tip of a knife worth, cheese I forgot until smell alerted me of its presence,... and all that raw milk. I didn't try the kind with maggots yet though. I know that cheese borne diseases exist, but overall, for how alive it is, cheese is surprisingly safe. In fact, that's the big idea with cheese. It is full of bacteria and molds that we know are safe, and these tend to outcompete the pathogenic ones. reply d-lisp 11 hours agoparentprevI only buy old cheese because it is more intense. It is rather hard to perform the \"affinage\" of the cheese without a controlled environment (Roquefort is \"affiné\" in natural caves in which you have several exits that you can open or close depending on the temperature and hygrometry of the caves, that's part of the AOP). I never got sick eating cheese, but that's actually possible Salmonella, Listeria, E.Coli, Tick-borne encephalitis virus (and you could die from it, in rare occasions). reply rvba 10 hours agorootparentWhoa tick-borne encephalitis virus can be found in goat cheese? reply itcrowd 10 hours agorootparentRoquefort is from sheep, but Roquefort is also the GOAT, so you may be technically correct reply kazinator 4 hours agoparentprevWell over 10 years ago, I went through a phase when I was into ripening cheese. I'd get a round of brie and put it into the bookshelf in my cubicle at work, for weeks. Very tasty. One time I had a mild fever that I'm sure was from eating the stuff, but recovered overnight. reply carabiner 13 hours agoparentprevYes, the US FDA has tight restrictions on unpasteurized milk and cheeses, and France does not. Some French cheeses are straight up illegal in the US because they're raw and not aged long enough i.e. reblochon. reply jandrese 13 hours agorootparentIf you are wondering, yes, every year a handful of French people get hospitalized from eating bad cheese. Usually E. Coli contamination. reply ta988 8 hours agorootparentA lot more in the US from Romaine lettuce of meats. reply ajmurmann 4 hours agorootparentI'm so glad the US government is keeping us safe from our own culinary decisions. reply psunavy03 11 hours agorootparentprev. . . which is horrible. I wouldn't wish E. coli on my worst enemy. reply kazinator 4 hours agorootparentThat only says you don't have such a bad worst enemy. reply umvi 11 hours agorootparentprevI can't tell if this is satire or not since every healthy person has probably trillions of e coli in their gut. reply pazimzadeh 10 hours agorootparentE. coli is usually less than 1% of a healthy gut flora, but yeah. It one of the first bacterias to move from the mother's vagina to the newborn baby, until it uses up the oxygen which then lets the anaerobes move in. reply pvaldes 10 hours agorootparentprev> I wouldn't wish E. coli on my worst enemy Is curiously a double true. Either way you take it, there is always a possible interpretation that leads to a logical, non-satirical meaning. reply ceejayoz 11 hours agorootparentprevIs this satire? They’re clearly not talking about the benign strains. reply mtlmtlmtlmtl 10 hours agorootparentThe strains in your gut aren't really benign, they're just isolated to your gut. If you exposed someone to those strains by say not washing your hands before cooking, it would not be fine. I agree GP is being silly though. reply YeGoblynQueenne 7 hours agorootparentThe E. coli strains of concern are the so-called enterotoxic (or enterotoxigenic) E. coli and the Shiga-toxin producing strains. Those are not commonly found in peoples' guts and when they are, they cause... trouble. Enterotoxigenic Escherichia coli (ETEC) is a type of Escherichia coli and one of the leading bacterial causes of diarrhea in the developing world,[1] as well as the most common cause of travelers' diarrhea.[2] Insufficient data exists, but conservative estimates suggest that each year, about 157,000 deaths occur, mostly in children, from ETEC.[3][4][5] https://en.wikipedia.org/wiki/Enterotoxigenic_Escherichia_co... The most common sources for Shiga toxin are the bacteria S. dysenteriae and some serotypes of Escherichia coli (STEC), which includes serotypes O157:H7, and O104:H4.[4][5] Symptoms of Shiga toxin ingestion include abdominal pain as well as watery diarrhea. Severe life-threatening cases are characterized by hemorrhagic colitis (HC).[15] The toxin is associated with hemolytic-uremic syndrome. In contrast, Shigella species may also produce shigella enterotoxins, which are the cause of dysentery. https://en.wikipedia.org/wiki/Shiga_toxin reply pazimzadeh 10 hours agorootparentprevNot really. Anyway the genome of E. coli is extremely diverse, there is not really such a thing as \"E. coli.\" And strain that colonizes your gut may not colonize someone else's, or cause problems. But most living things can be opportunistic e.g. if your immune system is compromised. reply mtlmtlmtlmtl 9 hours agorootparentI stand corrected. reply pazimzadeh 6 hours agorootparentWell, you're not totally wrong since the body does have several layers of defense to keep the bacteria in the intestine, and bad things happen when they break down: https://www.pnas.org/doi/10.1073/pnas.0803124105 On the other hand the immune system selects for beneficial bacteria, which take up space and nutrients so that really harmful ones can't colonize: https://sci-hub.se/10.1038/nri3535; https://www.nature.com/articles/s41586-022-05141-x reply littlestymaar 11 hours agorootparentprevMostly children and elderly people though, and raw cheese isn't the lead cause for such contamination, despite regulation processed food is quite high as well (with the record in recent years going to … Nestlé, who else. /r/fucknestle) reply tnecniv 10 hours agorootparentprevKind of funny given the guy who invented pasteurization reply foobarian 12 hours agorootparentprevAh, I had reblochon in a tartiflette once. Made the whole house smell like feet :-) reply carabiner 11 hours agorootparentYeah I didn't really get the appeal of reblochon for that reason. Really liked Brie de meaux though. Other cheeses that have \"barnyard\" aroma (manure) have an appeal that inscrutable to me. reply xwolfi 9 hours agorootparentprevIm French, and when I was 16, I went to New York and was traumatized by the border checks on both ends opening all my luggages in front of everyone (and every other French person had to do it) to make sure I wasnt carrying frigging supermarket cheese nobody cares about. They specifically check French people for these crimes, I was told, because we seem not to realize we're threatening the US with our crappy Camemberts. reply kazinator 4 hours agorootparentYou should take back that statue. reply albert180 8 hours agorootparentprevIf you tried the abomination sold in German Supermarkets as \"Camembert\" you would suddenly highly appreciate your \"crappy\" Camembert reply gavin_gee 10 hours agorootparentprevnext [3 more] [flagged] edgyquant 7 hours agorootparentHow ridiculous it is that you think “big cheese” is behind unpasteurized milk regulations. reply carabiner 10 hours agorootparentprevThere's a thriving US artisanal cheese scene, but yeah, it's not France. In the PNW there are quite a few creameries. Rogue River Blue is the best blue I've had anywhere though. reply numpad0 5 hours agoparentprevI think it's worthy of a note that Europe is extremely dry and cold as inside of a refrigerator. Someone in Europe might not keep cheese artificially refrigerated, but nor would one keep it in a shower room. reply whatshisface 5 hours agorootparentEurope spans 37 degrees latitude and has a lot of climactic diversity. It's not \"extremely dry and cold, like the inside of a refrigerator.\" Countries in the north temperate zone have four seasons. reply refurb 5 hours agoparentprevI think we need a “no true cheese” fallacy. I love the underlying tone to this. The French are a civilized people who care about the age of their cheese. While the country bumpkin Americans lack the sophistication and knowledge of cheese age. I mean, really? reply pazimzadeh 10 hours agoprev> the fungi that have accumulated multiple deleterious mutations in their genomes over years of vegetative propagation become virtually infertile If they've identified the genes that led to the bacteria becoming infertile, then they should be able to reverse the genetic changes. > “Genome editing is another form of selection. What we need today is the diversity provided by sexual reproduction between individuals with different genomes.” That kind of reads like nonsense, or phobia of genetic engineering. The only reason sexual reproduction would be required is if the original strains are not fit any more due to new selective pressures in the modern environment. But then you run the risk of changing the properties (flavor) of cheese since it's constantly mutating. So your 2010 Brie might taste different than 2030 Brie from the same brand. In research this was solved by making stocks of your strain once you're happy with it and freezing it at -80C so you can keep going back to it. reply flir 8 hours agoparent> But then you run the risk of changing the properties (flavor) of cheese since it's constantly mutating. So your 2010 Brie might taste different than 2030 Brie from the same brand. Hopefully, yes. reply h0l0cube 3 hours agorootparentGod forbid something new and interesting might happen! Hopefully it isn't food poisoning though. History has shown that as soon as we learn the market optimizing mechanisms behind something, we find a way to make it boring (movie sequels, reboots, MCU anyone?) > Until the 1950s, Camemberts still had grey, green or in some cases orange-tinged moulds on their surface. But the industry was not fond of these colours, considering them unappealing, and staked everything on the albino strain of P. camemberti, which is completely white and moreover has a silky texture. Give me the orange camembert please. reply BiteCode_dev 11 hours agoprevNo it's not. There are plenty of small cheese makers with diverse biomes and we buy from them every day. They all have their own batch, many are unique passed from generations or affected by the animals they raise. Nobody expect supermarket cheese to be sustainable anymore than their standardized vegetable. reply mylons 4 hours agoparentdo you have any idea on how the biodiversity of cheese is catalogued? i'd love to read more about that! reply telesilla 19 hours agoprevThose consumers who also don't buy heritage tomatoes or apples because of the irregularities in appearance, will be the ones who lose out. Sounds like there are still plenty of opportunities for cheeses, just not in a uniform delivery. reply mcv 19 hours agoparentUniformity and standardisation are a plague. Years ago there was an article here describing how Switzerland destroyed much of its rich cheese heritage because a powerful cheese lobby wanted everybody to standardise on Emmentaler and Gruyere. reply soco 19 hours agorootparentI can only say I cannot notice this destruction. I can count about 20 types of cheese in my Swiss fridge right now (ok not all Swiss) and none is Emmentaler or Gruyere. In my village we have a cheese shop with about 200 sorts, and every chain offers a few dozens at the minimum. Again, not all Swiss, but plenty enough types some of them even regional. So if there was any push on standardizing, I would say it largely failed. But I'll definitely search for that article/initiative, I'm very curious now. reply mcv 17 hours agorootparentI've also encountered plenty of other cheeses in Switzerland, so it certainly wasn't absolute, but it did happen. I can't find the original article anymore, but https://en.wikipedia.org/wiki/Swiss_Cheese_Union also mentions it. In short, the Cheese Union insisted on focusing on these two cheeses. This ended in 1999, so seeing more cheese now is to be expected, but even in the 1980s, there were absolutely other cheeses available. However, that doesn't mean that variety wasn't way down. Too bad I can't find that original article, which went into a lot more detail than Wikipedia. reply com2kid 13 hours agorootparentprev> I can count about 20 types of cheese in my Swiss fridge right now Maybe a stupid question, but how can you remember all those different types of cheeses and what they taste like? I'd have to have an extensive notebook every time I went to the store if I wanted to manage 20 types of cheese. (My typical fancy cheese buying system is to go to the store and buy something at random and hope I like it, which since I like cheese, often works out, but it means buying it again can be almost impossible) reply Loic 13 hours agorootparentYou know at least 20 songs, from the Beatles to ABBA or Eminem. This is part of your culture because you heard them over and over. We do the same but with cheeses. reply throwup238 12 hours agorootparentThat’s what we’re missing in America - branded cheeses! ABBA’s Goudas Just Wanna Have Fun and Eminem’s The Real Slim Cheddy from 3Mile. Beatle’s Let it Brie! reply Tainnor 57 minutes agorootparentYour joke is in good taste (!) but slightly tainted by the fact that Girls Just Wanna Have Fun is by Cindy Lauper, not ABBA. reply defrost 51 minutes agorootparentClearly they were thinking of Gouda! Gouda! Gouda! (Edam After Midnight) reply serial_dev 11 hours agorootparentprevYou can develop and improve your appreciation for cheese, you don't need to be born in France or Switzerland for that. I'm not from one of the big cheese nations of Europe, when I grew up we had one kind of cheese for everything, but a couple of years ago I tried to broaden my palette, buy everything I could in local shops and supermarkets, and remembering twenty different kinds of cheese is not difficult. What also helps is that these cheeses are significantly different, so Emmentaler, Camembert, Parmigiano Reggiano, Mozzarella, Bavarian Blu, Manchego, Pecorino, Gouda, Feta, etc, they all are very different, and most supermarkets in Europe have them all, so you can try out things easily. reply Fezzik 7 hours agorootparentprevTastes are pretty easy to remember - think of all the candy bars at a grocery store. Some you may have had only once or twice in your life but I bet most people know what most of the dozens and dozens of candy bars taste like and can recognize them by their branding alone. Don’t sell yourself short! reply code_duck 6 hours agorootparentprevI’m an American who likes trying new things and I could list at least 2 dozen types of cheese I’m familiar with. That’s about it though unless varieties with flavorings or smoking makes them count separately. reply kjs3 12 hours agorootparentprevI'm an idiot American and I can definitely remember and describe 20 different kinds of cheese. It's pretty easy to remember if you think in groups based on use: there's a couple of soft cheeses I like with fruit, a couple more that are good on top of pasta, a couple that are good on sammiches, a couple more to make creamy sauces, and a bunch that I just like to eat. You can get to 20 real fast, tho admittedly being someone who cooks makes it a lot easier to keep straight. If everything you eat comes from the freezer or Doordash, maybe not so much. reply trealira 9 hours agorootparent. reply kjs3 8 hours agorootparenttl;dr: \"This is how I am, therefore this is how normal people are, and you must be the outlier\". Whatever. Knowing 20 of pretty much anything isn't some One Weird Thing. Get out more. Maybe try something new. You have my sympathy. reply xwolfi 9 hours agorootparentprevYou know these people who can recite dozens of gun specs, know which bullet pierce which material at which velocity etc, in your country ? It's part of your culture because you discuss guns all the time, well in France, we do the same but for cheese. reply tejohnso 14 hours agorootparentprev> I can count about 20 types of cheese in my Swiss fridge right now Are you some kind of cheese nerd, or is this not all that unusual for a Swiss fridge? reply prmoustache 13 hours agorootparentI will say 20 is a lot but it is not uncommom to have a lot of different cheese. First swiss often do fondue with 2 different cheeses, the usual moitié-moitié mix of Vacherin fribourgeois and Gruyère. Then sometimes you have 2 to 3 different raclette cheeses because you like different tastes. Then there are the cheese you might grate on your pastas (in my case I would usually use italian cheeses) and the different cheese you want to offer at the table in regular diners + the ones dedicated for the aperitives like Tête de Moine...It can add up quickly without being a nerd. reply namtab00 7 hours agorootparentI have so much envy for you right now. I'm an Italian living in the northeast of Italy. I love Tête de Moine, but I cannot find a place selling it at decent prices.. It always has a ridiculous \"luxury\" tax, ending up above 50€/kg, which is absurd for Italy... reply mcv 11 hours agorootparentprevVacherin fribourgeois? I thought the standard was to use Emmentaler with Gruyere. Of course you can fondue with any kind of cheese. I love using Dutch farmer's cheese in my fondue. In fact, my brother-in-law has recently started making cheese which is very suitable for it. I'm Dutch, and I don't have 20 cheeses, but 5 different cheeses is very common, and more than 10 is not rare for us. reply ericd 13 hours agorootparentprevIt's pretty common in France, at least, to have a pretty solid collection of cheeses like that. Really glad the US has been getting better in terms of options. reply fgdelcueto 13 hours agoparentprevI'd love to buy more heirloom tomatoes. The flavor is great. The problem is that often they're like 3 USD for a single large tomato in my supermarket :( reply kjs3 12 hours agorootparentSee if there's a farmers market local to you. Even there they aren't (relatively) cheap, but IME way cheaper than the supermarket. reply jahewson 5 hours agoparentprevIt’s actually transportability and shelf life that were the original drivers - looks were a follow-on trend. The former of course translate to price - which I can’t argue with people for being motivated by. reply timcobb 19 hours agoparentprevI was in Paris this past summer for the first time in a long time. In fact, it was my first time out of the US in a long time. I was stunned/disappointed by the fact that even in high-end produce stores, all the apple varieties were pretty much exactly the same ones we have in the US. Gala, Fuji, Red Delicious, Golden, Granny Smith, etc., the familiar line-up. The whole time I was in Paris, I did not encounter an unconventional apple type, and I went to many produce and grocery stores during my time there. I assumed that produce monoculture wouldn't have hit France as hard as it's hit the US... but no, it seemed just as bad there. reply nicolas_t 14 hours agorootparentWrong season, the best time is really september, october. Even in Paris, it should be relatively easy to find Belles de boskoop and reine de reinettes which are delicious. Otherwise, any farmer’s market in Britany and Normandie will have plenty of interesting apple varieties. The problem though is that those more unconventional cultivars tend to only be available seasonally. reply jfengel 19 hours agorootparentprevI can't speak to the grocery stores, but I did briefly work on an apple farm in Calvados. They had two dozen different kinds of apples, not one of which I'd ever heard of. (I did once get a very lame baguette at a Monoprix once. Blew my mind that the French tolerated it.) One possibility is that you were there out of season. We've gotten very good at preserving apples for all year, but they are harvested only for a month or so. It takes industrial climate control to make them taste good after about December. reply BobaFloutist 15 hours agorootparentI understand that this probably refers to a French grocery store of some sort, but I can't get the image out of my head of you ordering a baguette off of the localized French version of https://www.monoprice.com/. reply albert180 8 hours agorootparentMonoprix is a strange store that sells Food, Clothes, Household Items etc... reply conradfr 47 minutes agorootparentIsn't that most supermarkets? reply estebank 7 hours agorootparentprevKind of like Target. reply kansface 13 hours agorootparentprev> Calvados As in, where the brandy comes from? I never knew it was eponymous. Booze is of course the original technology for preserving apples and fruit in general. My understanding is that was the original intended purpose for our older orchards included those planted by Johnny Appleseed. reply dminor 13 hours agorootparentSince he didn't graft, the fruit from the trees he planted would have mostly been unpleasant to eat. But still fit to ferment alcohol from, or feed to livestock. reply prmoustache 13 hours agorootparentprevThe calvados beverage is not only made in the Calvados departement. There are 3 different appelations: - regular calvados made from cider from different parts of Normandy - calvados Pays d'Auge which must be made from cider of that eponymous Pays d'Auge area (which is within the Calvados departement) - calvados du Domfrontais which is made from cider of the Domfront area in the Orne departement. reply zer00eyz 19 hours agorootparentprevApples are a poor choice to look at, because much like avocados they are all grown from cuttings and grafts. Apples are also an odd fruit because they can be kept for such a long time: https://www.foodrenegade.com/your-apples-year-old/ this makes shipping them anywhere much easier than a tomato... reply timcobb 18 hours agorootparentWhy does being grown from cuttings and grafts make them a poor choice to look at? Wouldn't there be local varieties with different flavors that people would want to consume. You can cut and graft those just the same? It seems they optimized for the varieties that are easier to ship and preserve. reply zer00eyz 17 hours agorootparentFor the same reason we have 1 banana and mostly only see hass avocados. IF you take the seeds of a tomato you will get a mostly decent tomato out of it. IF you take the seeds of an apple or a haas avocado you will likely get something that looks nothing like its parent. Unlike tomatoes it takes a LONG time to grow a tree, so if you want an avocado or apple orchard your going to use grafts to make sure you get the best chance of having a good product in 5 or 10 years... The economics of commonality should be readily apparent... pick something that you know works for your multi year bet to pay off sounds like a good plan. Avocados are also interesting because we DO get other varieties due to how it reproduces (you need plants of both sexes). IM fairly sure that apples do not have this issue so farms are monocultures. Add on to that the fact that the varieties we see are designed to be kept long enough to have a birthday and this is what you get. reply fsckboy 6 hours agorootparentapples themselves, all on their own, don't \"breed true\". If you take seeds from an apple from a tree that you love and plant them, you will not get a tree that produces fruit that tastes the same. The majority of apples \"born\" are sour. When a tasty apple tree is grown, it's a small miracle, and cuttings are propagated from it because it's the only way to produce more apples that are good. Johnny Appleseed walking through colonial American planting apple trees? he was a hippy promoting more fermentation of alcoholic apple cider, for which sour apples work just fine. virtually all French wine grapes, btw, are grown from cuttings grafted onto American root stocks because the native roots were not resistant to the invasive Phylloxera fly https://en.wikipedia.org/wiki/Phylloxera it is because of grafting that we have variety in these cases. reply bsder 18 hours agorootparentprevWhy would you assume that France has a diversity of apples? (they may--but I wouldn't automatically expect it) Johnny Appleseed is American. The US has a huge diversity of apple trees based on locality. However, like so many things, said diversity is seasonal. There is a good reason for pressing apple cider--you need to do something with the enormous number of apples you couldn't eat directly. If you want apples out of season, you're only going to see the mass-manufactured ones. reply nasmorn 17 hours agorootparentVery true. In Austria you can still get a lot of heritage apples but mostly in the fall. Some varieties don’t keep well at all. reply noSyncCloud 17 hours agorootparentprevWhat does Jonny Appleseed have to do with anything? Apples are native to central Asia, not the Americas. https://en.wikipedia.org/wiki/Apple?wprov=sfla1 reply WrongAssumption 14 hours agorootparentHow is where they are native to relevant prevalence and diversity? reply bsder 16 hours agorootparentprevThe point is that Johnny Appleseed actively spread apple cultivars over a very wide geographic area (Pennsylvania, Ohio, Illinois, Indiana, and parts of West Virgina and Ontario). Since these cultivars were no longer connected by breeding, they changed characteristics over several centuries giving rise to an absolutely enormous diversity of local apple types in the US--especially since apple trees from seed are kinda unstable genetically. reply subpixel 14 hours agorootparentprevHow they are grown has nothing to do with what varieties are grown and sold. Apples are in fact a great example of fruit that has hundreds of centuries-old varieties that are no longer traded commercially bc of homogenization of consumer taste. reply Quarrel 11 hours agorootparentIt is a little more complicated for apples because apple seeds do not breed true. You get random crabapples on average, if you plant apple seeds, so all commercial apples are grafted. At least apples aren't in the same deadend that bananas are in.. ie, most of the time they won't be sweet eating apples- in the US in particular this used to be less of a problem, because apples were for cider / alcohol. During prohibition entrepreneurs got active in trying to save their industry (while others were just ploughing orchards over) and we get modern ideas like \"an apple a day\" and the whole modern sweet eating apple became very mainstream. Not that eating apples weren't a thing before that, but it helped explode their popularity in modern western eating habits. reply nebula8804 7 hours agorootparentprevI was just in Paris. One of my favorite French cafes got replaced with a Popeyes. :/ My fat american butt eventually relented a few days later and I bought a single breast from them. It wasn't even good Popeyes. Tasted like either they dont know how to make a good crispy piece of chicken or Europe gets sent the scraps. reply currymj 19 hours agorootparentprevin the US, especially at \"organic\" grocery stores such as Whole Foods, you can typically get various weird apple cultivars -- although usually newly-developed rather than traditional. worth checking out if you like apples. reply timcobb 18 hours agorootparentI've never noticed interesting apple cultivars in places like Whole Foods. I've noticed apples that had different names, but looked and tasted like Gala apples :). reply InSteady 14 hours agorootparentprevDepending on your region, worth checking your local farmer's markets, food coops, and/or produce markets during fall-winter. There are multiple stalls in my town that have 15-20 apple varieties, only a few of which are \"greatest hits\" from grocery stores (pink something or other, jonagold). I have no doubt there is at least a sprinkling of heritage varieties in there. reply Kon-Peki 12 hours agorootparent> There are multiple stalls in my town that have 15-20 apple varieties I just checked the websites of about half a dozen orchards within a reasonable driving distance from me, and they all had a range of 30-40 varieties. Not all will be ripe at the same time; 15-20 all at once is going to be a huge orchard! reply tschwimmer 17 hours agorootparentprevI can't speak to french apple grocery store selection, but I wonder if you should maybe go to a different grocery store in the US. In my area (SF Bay Area) at the most common grocery chain (Safeway) there are probably 8 or so varieties of apples on sale and they often rotate. I would say that they always have the common ones that you describe (Red Delicious, Gala, Fuji, Granny Smith), some less common ones that are there 80% of the time (Honeycrisp, Pink Lady) and then some more exotic ones that rotate (this time they had two I had never tried before - Pazaz [I had to check twice to make sure they didn't say Pazuzu] and Sugar Bee). The Sugar Bee's were incredible - firm, crispy, juicy and sweet with just a small hint of tartness. Beyond just the bulk loose apples, they had a bunch of weird apple \"products\" that were either packaged up or sold in a bag. The weirdest ones were apple \"bites\" which were just tiny little apples - no variety specified. In my experience, the average US grocery store has a vast selection of produce and I see the pattern with apples (standard base varieties, with some rotating specials) across most categories of produce - citrus, cucumbers, peppers, root veggies, etc. So in short, I dunno, I actually feel like there's a massive variety of agricultural products in the US. Certainly way more than in Switzerland, the country in which I've been to the grocery store the most outside of the US. Coop has like 3 kinds of apples, Migros was a bit better and had some interesting Kanzi apples which I had not seen in the states. YMMV ¯\\_(ツ)_/¯ reply giraffe_lady 19 hours agorootparentprevIn most of france produce markets are where you'd go for this, but you're rigidly tied to the seasonal production. So you can get all kinds of apples! In september and october. And no apples at any other time. I'm not sure this applies in paris though, I suspect it does not. It's such a big city it's likely the markets are similar to american ones, being targeted & priced at affluent upper middle class professionals. IDK though I have spent very little time in paris. reply timcobb 18 hours agorootparentWhere could I find this in France? reply giraffe_lady 18 hours agorootparentTowns and small cities will just have a permanent structure for it, usually in or near the city center. It'll say \"marché\" or \"les halles\" on it, once you know what to look for they're easy to spot. The market is normally a couple times a week, early morning hours, in some places it will be over by 9, but in the summer vendors will be leaving even before that. Very small towns will just do it in the central square in front of the city hall or prominent church. Big cities will have one huge covered market somewhere that runs daily, and then smaller ones spread around different squares on other days. Again idk about paris. Lived in france for many years and still back regularly for family. But spent maybe a week total in paris, and even that was over a decade ago. reply rtsil 8 hours agorootparentThere are many markets in Paris, they're open one day a week and most of them are over by 1 pm. reply Solvency 19 hours agoparentprevIn not convinced its consumers refusing to eat varied heritage tomatoes. I frequent five different farmers markets and they sell like crazy. Most people can be easily conditioned and persuaded to but anything. Hence consumerism. I blame big food corporations for trying to homogenize, sterilize, pasteurize, and genericize the taste/appearance/chacteristics of food to the equivalent of white bread. Society just trudges along with it with extremely low awareness as to how much better it can be. reply wannabelife 12 hours agoparentprevThis is one of those cons of adapting to modern life so much, we forgotten how to pick fruits and vegetables basically. Our understanding of whats good is surface level things like what looks good or having no clue if food's actually gone bad vs not pleasing to the eyes Its also why ugly food industry took off and companies like misfit markets or imperfect foods have billions of dollars in business, who've created a market for ugly looking perfectly edible food reply VoodooJuJu 15 hours agoparentprevApples, tomatoes or pork, most people don't buy heritage anything because they're fucking poor. reply ToucanLoucan 19 hours agoparentprevIt's a crime against humanity how much food is thrown away because it's \"not appealing\" enough to the eye when we have so many in this world who go to bed hungry. I hope someday there's a society we've managed to build that's good enough to look back on the 20th and 21st centuries with the judgemental glare we rightly deserve. reply gambiting 19 hours agorootparent>>It's a crime against humanity how much food is thrown away How much of it is actually thrown away though? It's my understanding that the \"ugly\" looking vegetables are just used to make sauces, canned produce, ready meals etc etc. No one is throwing out perfectly good tomatoes just because they are ugly - they just get turned into something else. reply soco 19 hours agorootparentIf they are redirected at the producer, for sure. But if they are labeled as ugly, or expired, only when they are on the shelves, I'm not that sure anymore. So I don't know how much is each share - recycled vs thrown away... and again, what does \"thrown away\" mean? Vegetables landing in compost are thrown away? reply gambiting 19 hours agorootparentProduce almost never gets sent to shops \"as is\" straight from the field - everything gets sorted into classes, 1st class, 2nd class, 3rd class etc......1st class should already be perfect and nice and even - that's usually what supermarkets buy. There might be an occassional \"ugly\" bunch of stuff that falls through, and I guess yes in that case it will probably be thrown out. And yes it's also a tragedy that a lot of food at supermarkets gets thrown out when unsold. But I'd bet that 99% of \"ugly\" produce never makes it to the shelves in the first place, it just gets turned into processed food. reply Kluggy 19 hours agorootparentprevOr made into chips https://www.ugliessnacks.com reply pxx 19 hours agorootparentprevThis is a myth invented by some food delivery startups. As mentioned in sibling comments, this produce is often used in alternative streams. https://www.vox.com/the-goods/2019/2/26/18240399/food-waste-... reply ToucanLoucan 19 hours agorootparentI'm open to being corrected but this article doesn't offer much for proof of what this person is claiming. It starts by reaffirming ~161 billion in waste (in 2008) (termed: not eaten) and citing some of the cause of that as cosmetic defects. Then the interviewed person goes on to say it's used in alternative production as mentioned in the other comments, but offers no proof or statistics of this. And the fact that enough ugly food existed to fill the purchase orders of a number of startups going out of their way to sell it kind of implies if they weren't, it would be going in the trash. reply avgcorrection 16 hours agorootparent> And the fact that enough ugly food existed to fill the purchase orders of a number of startups going out of their way to sell it kind of implies if they weren't, it would be going in the trash. In the same way that a sudden interest in therapy for dogs would prove that dogs were suffering from a mental health crisis. Yeah, you want to sell produce at a premium so that somewhat well-off people can feel like they are making a difference? Sounds good to me, yup yup. I mean the vagaries and arbitrariness of upper/upper-middle class social signaling is a trope in itself. reply WrongAssumption 14 hours agorootparentprevNo, it implies they were willing to pay more than the alternative user. Makes sense, a retail customer will always pay more for a tomato than a canning factory. reply daveoc64 15 hours agorootparentprevIn the UK, most of the supermarkets now sell \"wonky\" fruit and veg - it may look less appealing, but it's safe to eat and cheaper. reply avgcorrection 19 hours agorootparentprev> It's a crime against humanity how much food is thrown away because it's \"not appealing\" enough to the eye when we have so many in this world who go to bed hungry. Evidence for this? Any at all? Because I can’t imagine someone getting caught in the act of frowning in disgust which then immediately causes a shop owner to toss out that and similar-looking produce in the hopes that no one else will be disgusted. And how you would cook up such a causal connection is beyond me. What actually happens—and which just trivially follows from good old “economics”—is that perfectly good food is thrown out because you make more money by eliminating supply that can’t be sold. (Maybe also food regulations, I don’t know.) reply ip26 13 hours agorootparentIn different terms, think about when you go shopping. Do you take only the prettiest apples? Personally, I will take about any apple that doesn't have soft spots, damage, or mold. (Before you argue damage is cosmetic, a significant break in the skin molds quickly) reply avgcorrection 13 hours agorootparentExactly. In fact around these parts, the more natural-looking, y’know local region grown apples are more popular. That’s what people are looking for. Not the bright red, big, more perfect apple-shaped ones with a kind of polished glean to them which were probably imported from abroad. People want those smaller red-and-green(-and-yellow) ones. (But they’re too sour for my taste.) reply ToucanLoucan 19 hours agorootparentprev> Evidence for this? Any at all? Because I can’t imagine someone getting caught in the act of frowning in disgust which then immediately causes a shop owner to toss out that and similar-looking produce in the hopes that no one else will be disgusted. And how you would cook up such a causal connection is beyond me. Yeah that'd be pretty crazy, probably why that's not what happens. It's far likelier that the produce is filtered on the farm before it even gets to a supplier. https://econreview.berkeley.edu/the-good-the-bad-and-the-ugl... > What actually happens—and which just trivially follows from good old “economics”—is that perfectly good food is thrown out because you make more money by eliminating supply that can’t be sold. (Maybe also food regulations, I don’t know.) I think that's more why they lock the dumpsters behind grocery stores and/or dump bleach on the food, but that's also disgusting, so, lateral move I think. reply avgcorrection 16 hours agorootparentI got worried when I saw the UC Berkeley link. But turns out it is not about research—it’s an opinion piece on the “Ugly Food MOVEMENT” (God...). Which is fronted by, yeah, you guessed it, some scrappy startups who are asserting that there is a market failure[1] and that they can amend it. Then there is a link to some concrete numbers which links to a Hill article. Which is a puff piece for one of these startups—the cause of the food waste is just asserted in the first paragraph.[2] Then there’s the crucial farmer link. Which is just some loose “farmers we’ve talked to, like X” (one step above “people are saying”) and a link to a human interest or whatever you call those uninteresting subject-driven The New Yorker articles. I don’t know how people are in the USA (spoiler alert), but where I am from food is the everyday grocery product that people are most stingy about.[3] Lower prices are always good. So it seems bewildering that the consumer would send such signals to the Market—surely this would cause higher prices for the consumer? Not only that but here (like in America) there are farmer subsidies. Payed for by tax payers which are also consumers. (And Americans care about food æstehetics that much? Well let’s look to the article again: “Psychologists argued that the lack of public interest in ugly food was connected to self-esteem.” What the fuck? Seriously?) Not to mention inflation which makes such everyday products more expensive. Which everyone who cares about Economics on this site seems to be tearing their hair out over on a weekly basis. The article talks about how these noble startups are enabling ugly produce to be sold to smoothie retailers or whatever. Or juice factories... like the Market is so catastrophically mismanaged that you need a hipster startup for that? To connect that an orange shaped like Steve Buscemi doesn’t taste bad as juice? I am not being negative about the article by the way. Just the Movement. The article raises the question several times about whether this is really A Thing or if it is an astroturf, someone trying to make a buck on real climate change and environmental issues. Just look at penultimate paragraph. > The ugly produce movement exemplifies the twenty-first century consumer’s reliance on social media to navigate lifestyle changes. Food waste isn’t a simple problem; it’s an example of the broken agricultural system’s inability to distribute resources in a way that benefits all consumers. If individuals really want to be part of the solution, they have to look beyond the glitzy marketing of ‘socially responsible’ firms and become more vigilant of companies that claim to have an answer for everything. Would you look at that. A somewhat funny part is where they describe how the customers of these things are higher-income because it is more expensive. So the Market is so screwed up that “ugly food” isn’t something that the poor buy out of practical necessity? It’s been relegated to social indulgences-buying upper-middle class uh, people? All in all this damning evidence that you have presented here demonstrates to me that The Ugly Food Movement is a silly, boutique food practice that some I Want To Make a New Consumer Need marketing firm cooked up, some startups made A Thing, and that upper-middle class water cooler NPCs are probably now doing the good work of spreading the word about. [1] Because if this was about consumer choice, according to these startups, what difference would a new kind of company make? [2] “One innovative company called [Redacted], based in [Hipsterville, USA]” [3] Just imagine if people were given the chance to buy almost-expired or some other such ugly food... and of course they are and people love it. Why the heck do you need a startup for that? reply ToucanLoucan 15 hours agorootparentYou have gone on like... three different wild tangents here, none of which contradict anything I've said. My point was never that startups are helping yuppies save the world by getting yuppies to buy ugly food. My point was, that food being deemed as below standard and thrown out, in any amount, is disgusting in a world that still has food-insecure people in it. That's it. I don't give a shit about these startups. If it is true what they say that they are indeed bridging a gap between food that would otherwise be discarded and well-meaning people who want to change how they consume in such a way that's slightly more beneficial to the world, then more power to them. That's a good thing, IMO. But it is also a band-aid solution to the larger problems of the logistics of food production and distribution, and if anything, it's an extension of one of the bigger problems in itself: that food is not grown, shipped, and sold to feed people, it is done to make money and therefore, if a given group of people exists that it is not profitable to sell food to, they will not be fed. That, to me, is disgusting. The rest of this is a lot of waffle about how stupid Americans are and I'm just not interested in that as a topic. Edit: Yeah I just saw your other comment and it's clear you're just here with an axe to grind about people you perceive to be richer than yourself, and, I dunno man, maybe that's important, but to me it's boring. Go find someone else to grind it with. reply avgcorrection 15 hours agorootparent> You have gone on like... three different wild tangents here, none of which contradict anything I've said. You posted an article, I responded to it. Standard fare. reply RcouF1uZ4gsC 19 hours agorootparentprev> because it's \"not appealing\" enough to the eye when we have so many in this world who go to bed hungry. Throwing or not throwing away the food would make no difference in the lives of the people going hungry. The people going hungry are going hungry not because of a dearth of food, but due to issues such as war or political or family instability. reply mnw21cam 19 hours agorootparentThere's a pretty major problem with economics. If the food that is grown and is currently thrown away wasn't thrown away, then it would be effectively be available for a lower price than mainstream food. If this were taken to its logical conclusion, then allowing this food to be given to hungry people lowers the demand for the full-price food, leading to a reduction in price of that food, causing the people growing it to be unable to make ends meet. It is necessary for the production of food to continue to throw away the food that isn't bought, otherwise the people producing the food will go bankrupt and stop producing food. The above sounds very harsh. Obviously there are some schemes that allow excess food to be used by poorer people, like food banks, quality tiers, common agricultural policy type schemes, or just ensuring everyone has sufficient income through tax breaks or benefit schemes. Food banks give food away for free, and they are very limited in scope, and therefore have a limited affect on food price. Quality tiers are things like a supermarket selling \"wonky veg\" next to full-price veg, but you'll tend to notice that the wonky veg isn't actually much lower in price than the full-price veg. The EU's old common agricultural policy scheme effectively solved the problem by getting the government to guarantee that a food grower could sell their food for a viable price, but it led to huge complaints about \"butter mountains\" and waste - I think the point was missed that this waste was a reasonable trade-off for ensuring that food continued to be produced in sufficient quantities even in a bad year, and the fact that the government bought the excess meant that they owned it and could if they wanted to feed the hungry with it. Tax breaks and benefit schemes solve the problem without lowering the price of the food because the food seller still gets paid full price for the food. My point is that good intentions have generated schemes to get excess food to hungry people, but they necessarily have to be small in scale to avoid negatively affecting economics. reply badpun 15 hours agorootparentPeople who are hungry obviously can't afford the food, so giving them free food does not withdraw them from the food market, as they weren't on it already. Consequently, the overall demand for food does not fall. reply colordrops 2 hours agoprevI'm sure most of you don't want to hear it, but the dairy industry is brutal for cows, in many ways far worse than the meat industry. Cows are forceably impregnated repeatedly to keep milk flowing, and their calves are taken from them and slaughtered for veal. Some breeds are so large they can barely move, often being milked in their last moments while laying prone. Then they are slaughtered like meat cows in the end. reply paulkon 2 hours agoparentWhat are the vegan cheese alternatives I can conceivably substitute in a dinner party of discerning charcuterie board lovers? reply colordrops 2 hours agorootparentI wasn't looking to promote cheese alternatives, but rather point out the cruelty of the industry. In any case, cheese is difficult to replicate due to the nature of the proteins in milk. There are companies that have made casein in bioreactors that will hopefully soon put products on the market. Until then, there are other alternatives, but don't expect them to have the same flavor and texture. Some of the best ones are not trying to be a facsimile. There's the Vegan Cheese Co that maintains a worldwide database of vegan cheeses, and here's the list from their yearly awards: https://www.vegancheese.co/awards reply 11235813213455 12 hours agoprevMost people would call vegetable rotten when they start to ferment, but that's just like for cheese, it makes them better raw (for peppers, onions, garlic, grapes, etc..) reply mtlmtlmtlmtl 10 hours agoparentBananas too. They're the best when the skin starts going black, which is when a lot of people throw em out. It's once they start turning white you might wanna move em to the compost. reply trealira 9 hours agorootparentThey're still good for baking banana bread when they're black. I don't like directly eating bananas with black skin, though; they're mushy and overly sweet. reply bilsbie 9 hours agoprevI wish we could take better care of our planet. reply 6LLvveMx2koXfwn 19 hours agoprevWho would have thought compromising genetic diversity might lead to problems downstream . . . reply ajsnigrutin 19 hours agoparentThis surely never happened before, that's why artificial banana flavourings taste exactly the same as banans we get in stores today! reply pxx 19 hours agorootparentThis is a myth. The causal effect does not go that way. There is little evidence that artificial banana flavors were developed in a way to mimic older cultivars of banana. https://www.bbc.com/future/article/20140829-the-secrets-of-f... reply Toutouxc 19 hours agorootparentThe article doesn't really dispel the myth, just shuffles the causality around. To me it sounds like it's still true that artificial banana tastes different that what we can get now. reply nonethewiser 19 hours agorootparent> To me it sounds like it's still true that artificial banana tastes different that what we can get now. But that's not whats being claimed. He's rebutting the claim (which the original commenter may or may not have implied) that artificial banana flavor is like the old banana's that dont exist anymore. He, nor anyone here, is saying artificial banana tastes like real banana. And if someone like that shows up lets get them. reply InSteady 14 hours agorootparentI have tasted unusual varietals of banana, mostly from SE Asian supermarkets, that taste very close to artificial banana when they are super-ripe. I have a sense for it too, because artificial banana used to be my favorite candy/popsicle flavor as a child. Full disclosure though, I probably haven't tasted artificial banana in at least a decade. reply Toutouxc 19 hours agorootparentprevThat's an interesting detail about the bananas, I've always found artificial \"banana\" flavourings too strong, too \"artificial\" and I vastly prefer the taste of a slightly green banana (as you can buy it in Europe). Apparently the artificial flavourings are actually closer to what the OG bananas tasted like. reply Kluggy 19 hours agorootparentI only eat slightly green bananas. They're readily available everywhere in the US, so it's not a strictly Europe thing. reply Toutouxc 17 hours agorootparentOh, I’m sure it isn’t. I just wanted to emphasize that I’m in Europe (central) and what they sell as bananas here may not be the exact same thing as somewhere where you can eat them fresh. reply InSteady 14 hours agorootparentprevGreen bananas have a nice balance of resistant starch and prebiotic fiber. They're great for your colon! reply lloeki 12 hours agorootparentprevAt some point I grew deeply disgusted of the flavour because of a chemistry bench experiment in school where we made the isoamyl acetate ester, which is basically what most would describe as the archetypal banana flavour... except that when you have a whole classroom of people doing that it gets extremely strong! Took me close to a decade to enjoy bananas again. I still don't like bananas or pears that are too ripe, mostly because they become too sugary for my taste, but also because of the stronger flavour. https://en.wikipedia.org/wiki/Isoamyl_acetate reply ToucanLoucan 19 hours agorootparentprevKnowing history doesn't let you not repeat it, it just shows you the flat circle the vast majority of society runs on, making the exact same fucking mistakes over and over again. reply mnw21cam 19 hours agorootparentExperience is what allows you to recognise a mistake the second time you make it. reply wkat4242 19 hours agoprevIn this case it looks like a completely self-imposed problem by the industry. Pretty similar to the fishing industry actually. Focus on short-term profits and none on long term sustainability :'( reply nonethewiser 19 hours agoparentYeah, pretty much this from the article: > Consequently, the fungi that have accumulated multiple deleterious mutations in their genomes over years of vegetative propagation become virtually infertile, adversely affecting cheese production. “This is what happens when we completely stop using sexual reproduction,” Giraud explains. “It’s the only way to compensate for detrimental mutations through the introduction of new genes – the famous genetic mixing.” Live and learn. Seems like a common story in agriculture. Perhaps we can relearn this lesson in the context of human propagation someday. reply SV_BubbleTime 19 hours agoparentprevYou make it seem like they knew and just ignored the risks of lowering the biodiversity. The exceptionally more likely scenario is they had no idea what those risks were. It’s also complete clickbait nonsense to suggest blue cheeses will go away. When the reality is they may add some more colors, or have to come up with some more options. But these cheeses aren’t going anywhere. reply nonethewiser 19 hours agorootparentIf blue cheese is no longer blue then you could argue it did go away. reply GuB-42 8 hours agorootparentIt doesn't seem there is a much of a problem with blue cheese in general. Some strains of blue molds are endangered, but there are plenty of other blue molds that are fine. According to the article Camembert and Brie are more at risk as their white mold is more rare. They won't disappear either, but if we don't do something, they may stop being white and start being blue, and maybe taste a little different. It doesn't mean they can't make good cheeses, but it will be different from the cheeses we know. reply incomingpain 19 hours agoprevTip: People with allergies to penicillin often love blue cheeses but are unknowingly harming themselves mildly. https://en.wikipedia.org/wiki/Penicillium_roqueforti Yes, most of the penicillin breaks down... but.. reply hollerith 19 hours agoparentMost of the penicillin breaks down before it has a chance to enter the bloodstream, but not before the components of the immune system resident in the gut and the gut's lining detect it, initiating a reaction that can involve the entire body. reply incomingpain 18 hours agorootparentTotally correct! reply InitialLastName 19 hours agoparentprevI was hoping your link would have interesting information about allergic reactions to blue cheese (and possibly a trend where those allergic to penicillin are drawn to blue cheese), but for anyone who follows: no such luck. reply nonethewiser 19 hours agoparentprev> People with allergies to penicillin often love blue cheeses Are you saying penicillin allergies cause or influence this? Or simply coincidental, since many people in general like blue cheese. Also, supposedly penicillin allergies are often inaccurate. Either false diagnosis as a child or simply growing out of it. Guess maybe blue cheese could be a good test. reply incomingpain 18 hours agorootparent\\0/ I don't know is the correct most answer I can provide. In terms of am I allergic, oh ya, no question. Recently been minorly exposed and reaffirmed that one again. Though typically I must take it internally to really screw me up. Blue cheeses taste like it's an elixer of the gods to me. totally unlike all other things. I enjoy practically all other cheeses, but they are not quite the same thing. reply sokoloff 19 hours agoparentprevIf I had such an allergy, I'm pretty sure I would continue to harm myself mildly, knowingly or not. reply manmal 14 hours agorootparentDo you mean blue cheese in particular, or just anything stimulating opioid receptors? reply incomingpain 18 hours agorootparentprevLol, guilty as charged. Blue cheese dressing with my wings is still a thing I do. I do the others as well like ranch, so it's not that common and I get away with it I think. reply Toutouxc 19 hours agoprev [–] > Until the 1950s, Camemberts still had grey, green or in some cases orange-tinged moulds on their surface. But the industry was not fond of these colours, considering them unappealing I couldn't help but chuckle. The mouldy cheese industry says something is unappealing. reply nonethewiser 19 hours agoparentI don't see anything ironic or not self-aware about this. There are molds ranging from benign and non-descript to deadly and grotesque looking. I wouldn't expect someone OK with eating the former to be OK with any mold on that basis. In fact I would expect them to be highly scrutinizing because its fucking mold. reply mnw21cam 19 hours agorootparentIn other words, having your cheese a predictable colour allows you to recognise when something else is growing on it. reply toxik 19 hours agoparentprev [–] What’s next, the Scots food-dyeing haggis to look more appealing? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The French blue cheese industry is at risk due to the uniformity of production methods, leading to a lack of genetic diversity in the fungus used for fermentation.",
      "Termignon blue cheese, produced in the French Alps, has a unique population of Penicillium roqueforti that could help diversify the genetic pool and save the industry.",
      "The Camembert cheese industry is already facing extinction because it relies solely on a single strain of Penicillium camemberti that has lost its ability to reproduce, highlighting the urgent need for genetic diversity through sexual reproduction with different strains."
    ],
    "commentSummary": [
      "Topics covered in this collection include French cheese, apple diversity, the ugly produce movement, and allergies to blue cheese.",
      "Discussions highlight concerns such as the lack of microbial diversity in French cheese, regulations around unpasteurized milk and cheese in the US, genetic changes in bacteria used in cheese production, availability and pricing of certain food items, the problem of food waste and the perception of \"ugly\" produce, and the potential decline of blue cheeses due to a lack of genetic diversity.",
      "This collection provides valuable insights into various aspects of the food industry, including quality, regulations, sustainability, and consumer preferences."
    ],
    "points": 213,
    "commentCount": 168,
    "retryCount": 0,
    "time": 1705672865
  },
  {
    "id": 39057219,
    "title": "Books and Projects Inspiring a Philosophy of Engineering",
    "originLink": "https://news.ycombinator.com/item?id=39057219",
    "originBody": "I am a software engineer by passion. I love computers, I am curious. I love to learn new things &#x2F; concepts. I love to see the beauty in existing concepts being applied in completely unexpected ways, which makes you wonder that every boring thing has myriad of variations which are not obvious.Through my college education & industry experience & curiosity, I have learned a lot. But, even after trying to search about books on the philosophy of engineering or the art &#x2F; craft of engineering - I have fallen short.I would love to hear what books &#x2F; and projects that you have seen that have inspired you as an engineer & have provided you with your own philosophy of engineering.I am talking about general \"engineering\" here, not just specifically \"software engineering\".Requesting the universe to enlighten me :)",
    "commentLink": "https://news.ycombinator.com/item?id=39057219",
    "commentBody": "Good books on philosophy of engineering?212 points by s3micolon0 17 hours agohidepastfavorite120 comments I am a software engineer by passion. I love computers, I am curious. I love to learn new things / concepts. I love to see the beauty in existing concepts being applied in completely unexpected ways, which makes you wonder that every boring thing has myriad of variations which are not obvious. Through my college education & industry experience & curiosity, I have learned a lot. But, even after trying to search about books on the philosophy of engineering or the art / craft of engineering - I have fallen short. I would love to hear what books / and projects that you have seen that have inspired you as an engineer & have provided you with your own philosophy of engineering. I am talking about general \"engineering\" here, not just specifically \"software engineering\". Requesting the universe to enlighten me :) jonjacky 16 hours agoDon't overlook books that are critical of engineering as it is often practiced and how it fits into our society: Computer Power and Human Reason by Joseph Weizenbaum (1976). Weizenbaum wrote Eliza, the first AI chatbot, almost sixty years ago and was appalled at the reception. This book is still very pertinent, especially the Introduction, Chapter 1 On Tools, chapter 9, Incomprehensible Programs, and chapter 10, Against the Imperialism of Instrumental Reason. Chapter 4, Science and the Compulsive Programmer, is one of the first written accounts of the hacker culture. Weizenbaum's original paper on Eliza (1966) [0] is still very pertinent to the present generation of chatbots, especially the introduction and discussion. Tools for Conviviality, Ivan Illich (1973) [1]. Influenced recent work by the computer scientists Steven Kell [2],[3] and Kartik Agaram [4]. Computation and Human Experience, Phil Agre (1997) (excerpt at [5]). Agre got a PhD in AI at MIT in the 80s and 90s and became very critical of the field. I think his shorter writings [6][7] are a better introduction, especially the personal memoir at [6]: \"about how I became (relatively speaking, and in a small way) a better person through philosophy.\" 0. https://dl.acm.org/doi/10.1145/365153.365168 1. http://akkartik.name/illich.pdf 2. https://www.humprog.org/~stephen//research/talks/kell19de-es... 3. https://www.humprog.org/~stephen//research/talks/kell19softw... 4. http://akkartik.name/akkartik-convivial-20200607.pdf 5. https://pages.gseis.ucla.edu/faculty/agre/che-intro.html 6. https://pages.gseis.ucla.edu/faculty/agre/notes/00-7-12.html 7. https://pages.gseis.ucla.edu/faculty/agre/critical.html reply jsenn 11 hours agoparentA critical book I enjoyed when I read it (before starting my career) was The Real World of Technology: https://www.goodreads.com/en/book/show/1291973. Worth it just for the first chapter where she defines technology as practice, which helps clarify why the classic “technology X is a neutral tool that can be used for good or ill” argument isn’t very satisfying. That said, I haven’t read it in a long time so not sure how well it holds up. reply crabmusket 9 hours agoparentprevI need to read Illich. I've been following The Convivial Society, a newsletter whose author is very influenced by Illich. My introduction to tech criticism was To Save Everything, Click Here by Evgeny Morozov. He describes a lot of tech culture as \"solutionism\" which I think is a great lens to have in your pocket. reply undershirt 13 hours agoparentprevI’ll second this. A philosophy for engineering is nestled I think in the larger “philosophy of technology”, but this field of philosophy has traditionally been a lot more critical of technology than most of us can stomach today. This is a really good map of the field that not many know about, written in 1995: https://shaunlebron.github.io/chandler-1995.pdf reply RyanHamilton 14 hours agoprevI can recommend a Philosophy of Software Design Paperback by John Ousterhout. I've been programming for 15 years and it closely parallels my own current beliefs about programming. He stands above the lower aspects of programming/code/modules, raising the discussion to a conceptual level, that you seem to be wanting. I think there were only 2 areas out of approximately 10 that I thought I had a few better ideas but a)He may have simplifying it to more easily allow explanation. b) His explanations are much better than mine and if I tried to explain it, maybe I'd fail. reply computerdork 12 hours agoparentHaven't read this, but based on looking through the table of contents (so take what I'm saying with a grain of salt), I agree with your choice. You mentioned that you've been programming for awhile, you might have heard of Grady Booch and \"Object-Oriented Analysis and Design with Applications.\" Object oriented techniques has fallen a little out of fashion now, which may be part of the reason why this book isn't as popular, but it was big around 20 years ago. It also discusses on the many topics of your choice: - Complexity, what it is and how to manage it - Encapsulation (Information Hiding). - Interfaces - contracts for your encapsulated code - Abstraction And am certain that Grady Booch's book was itself mostly based on older material. I also really like any really good book on doing requirements (they all have 80% of the same info). Getting the true needs of all your stakeholders (your users, the business people, the devs themselves, and the technical needs of the system) is probably the step that is done the poorest in most organizations, and the one that could save project the most time and money if done well. reply ATMLOTTOBEER 10 hours agoparentprevHis idea to keep interfaces small and powerful bothered me - I don’t think it expresses any truth about programming despite being a good rule of thumb. I kept feeling frustrated while reading. The lambda calculus has the best interface to functionality ratio possible but you don’t see humans using it to program. This objection led me to the conclusion that a better heuristic would be: programs should try to communicate intent primarily to another reader, and then to the computer. He does touch on this a little by saying aim for ease of reading over ease of writing, but I don’t think it was a main point. I agreed with almost everything else he had to say including the “taking it too far” chapter (I don’t actually think we should be using lambda calculus to program lol). Curious to know which parts you disagreed with. I am only 2yoe reply __loam 9 hours agorootparentMost so the book is meant to be taken as a rule of thumb. I personally think simple interface hiding deep functionality is a really good one. I was looking at the langchain codebase last year after having read the book and the point was struck home. Many of the functions in Langchain are one line wrappers of other functions. I try to think of functions as atomic units of knowledge. Very short functions are a good indicator that you're not organizing that knowledge effectively. When you have a simple interface with deep logic, you're encapsulating logic in a single place. This is very good for reducing the cognitive load of a developer. Shallow functions fragment that knowledge across multiple classes/functions/files. The developer needs to hold more of the world in their head to make sense of things. This increases complexity. Additionally, you can sort of intuit this by looking at very successful commercial products like Google Search, the iPhone, and ChatGPT. Search is a single text input. The iPhone is a screen with a very small number of buttons. Chatgpt has a simple chat interface. All of these systems are incredibly complex, but they're able to present a simple interface to the public to allow most people to leverage that complexity without having to think about it. Just my 2 cents. reply Darmani 8 hours agorootparentTo people who are experienced in writing out the full interface of modules, ie their assumptions and guarantees, it's quite clear that being a \"deep module\" in Ousterhout's sense is quite rare and often undesirable, and that Ousterhout's examples of deep modules are actually shallow. See https://www.pathsensitive.com/2018/10/book-review-philosophy... He gets a lot of other stuff right though. Love his writing on comments reply ducharmdev 11 hours agoparentprevI was about to recommend the same book - lots of good nuggets of wisdom in here, without the dogma you sometimes find in this kind of literature. reply koliber 20 minutes agoprevThe Timeless Way of Building, by Christopher Alexander. It’s about designing houses, and in a more general sense spaces for people. There is a powerful philosophy that he conveys in this book which applies to software engineering as well. Some notes of caution though. The book is not an easy read. It’s also not very direct and quite philosophical. Also, don’t try to reduce it to just software patterns. There is a lot more in there about a sense of beauty, quality, and essence which people miss when they mechanically reduce the message to the patterns. reply jsf01 15 hours agoprevRichard Hamming’s The Art of Doing Science and Engineering is one that’s really shaped my philosophy on CS. It pushes for the importance of reasoning from first principles, experimentation, and taking on extraordinary work. There’s also a fascinating and prescient section on AI and the limits of computers and how we think about them. Stripe Press makes a nicely bound hardcover edition of the book, too: https://press.stripe.com/the-art-of-doing-science-and-engine... Heartily recommend! reply pcvarmint 8 hours agoparentThat was the one I was going to recommend. https://www.youtube.com/watch?v=AD4b-52jtos reply bgnn 9 hours agoparentprevOh Hamming is amazing to read! His \"the art of probability\" too is an amazing read. As the title says, he explains why probability isn't math but an art and philosophy! reply demondemidi 6 hours agoparentprevI read this and I was really surprised by how dismissive he was of his peers! Like it was almost catty. Great book tho. reply NegatioN 14 hours agoprevI'm not sure if these books really are what you're looking for, because each of them is a mix of engineering history, and the description of how a group of people end up doing amazing things. In each of the books, there were nuggets of wisdom that I've tried to bring along with me in my job (as best I can). Like: - Doing things as simply as possible to start off - Keeping iteration time to a minimum, for maximum exploration of ideas - Being willing to think outside the box My takeaways above, hardly do these books justice, but they are as follows: - Skunk Works: A Personal Memoir of My Years at Lockheed [0] - Hackers: Heroes of the Computer Revolution. [1] - The Dream Machine: J.C.R. Licklider and the Revolution That Made Computing Personal [2] [0]: https://www.goodreads.com/book/show/101438.Skunk_Works [1]: https://www.goodreads.com/book/show/56829.Hackers [2]: https://www.goodreads.com/book/show/722412.The_Dream_Machine reply dstroot 13 hours agoparent+1 for Skunk Works. Great story, well written and the engineering challenges they overcame were astounding. reply jpiburn 17 hours agoprevThe Design Of Everyday Things by Don Norman might be something of interest https://www.goodreads.com/en/book/show/840 reply Minor49er 14 hours agoparentSeconding this. It's an important book for all kinds of design I would also recommend \"Clean Code: A Handbook of Agile Software Craftsmanship\" by Robert C. Martin. It focuses on crafting higher quality code, which is the property of it not only running well, but being easy to understand and to work on reply NukedOne 11 hours agorootparentI'm curious as to how you feel about this[1]? [1]: https://qntm.org/clean reply Minor49er 8 minutes agorootparentWhile the criticism is valid, I think it misses the points of the book. It's worth reading both but the book definitely has helpful perspectives that eclipse what's mentioned on that webpage reply pixelmonkey 13 hours agoprevI love your passion! When I was CTO of a software startup, I wrote a blog post reviewing various books about engineering and software teams, neatly organized into six sections. The three sections that you might find interesting, each featuring a few relevant books: - Debugging dysfunctional product cultures: https://amontalenti.com/2020/11/28/definitive-reading-list#d... - The psychology of deep work: https://amontalenti.com/2020/11/28/definitive-reading-list#p... - Programmer mindset and philosophy: https://amontalenti.com/2020/11/28/definitive-reading-list#p... reply s3micolon0 14 hours agoprevI am so happy to get all these responses! All of the resources look interesting!! I am going to start with Richard Hamming's The Art of Doing Science & Engineering. It looks to be something to get started. I have been wondering this question ever since, I wish I had reached out to request help earlier. I am glad I did, nonetheless. I am 26, hope there is a lot more to learn, apply & build. I am grateful to the universe (and the internet/hackernews). Thank you :) reply pjmorris 13 hours agoprevA couple favorites that haven't been mentioned: 'An Introduction to General Systems Thinking', Weinberg, and he's got a dozen more worthwhile books behind it. 'The Logic of Failure: Recognizing and Avoiding Error in Complex Situations', Dietrich Dorner reply philip1209 15 hours agoprevI recommend Shop Class as Soulcraft, which contrasts blue-collar work (motorcycle repair) with knowledge work. It's not specifically \"tech\"-related, but it does a good job of exploring how corporatization has diminished the ability to be a craftsperson in modern careers. reply trentnix 14 hours agoparent+1 I thought Shop Class as Soulcraft was excellent and found the author's theories on the lack of job and life satisfaction among those doing \"knowledge work\" compelling. It reminded me of the movie Margin Call when Kevin Spacey's character, who manages a trading floor for a wall street investment firm, laments that if he'd been a ditch digger, at least he'd have a bunch of holes left behind as evidence he accomplished something. reply Pamar 13 hours agoparentprevYou can get an overview of \"Shop Class as Soulcraft\" here: https://news.ycombinator.com/item?id=8280379 reply mcbishop 16 hours agoprevA Philosophy of Software Design by John Ousterhout. The principles / approaches (e.g. problem disaggregation) apply to other engineering disciplines. reply a_c 14 hours agoprevThe Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter Engineers (and scientists) often boast ourselves as master of causality. We solve problem by understanding the domain. We laugh people as cargo-culting - not knowing why one does things. The Secret of Our Success shows it is a feature rather than a bug. The effect of \"culture\" takes much longer to manifest, often beyond our comprehension. One example given by the book is how we process cassava, lots of superfluous ritual. Without those processing culture, people get poisoned slowly. Only with modern chemistry do we comprehend the full extend of those ritual. But people have been eating cassava way before modern science were available. Similar can be said about medicine, lots of folk remedies don't work. But when they do, they do. Is not understanding a feature or a bug? With the advent of LLM, things seem to come in full cycle. We now prompt the engine and get a result/an opinion of sort. No longer is understanding required. I see the use of LLM in software engineering very anti-engineering, hindrance to learning and understanding. But it might not be a bug after all. reply shagie 16 hours agoprevPhilosophy of Computer Science: An Introduction to the Issues and the Literature by William J. Rapaport - ( https://www.apaonline.org/news/254862/William-Rapaport-is-th... ) > The APA is pleased to announce that William Rapaport (University at Buffalo) has been selected by the APA committee on philosophy and computers as the winner of the 2015 Barwise Prize! This corresponds to the class https://cse.buffalo.edu/~rapaport/510.html https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... The table of contents can be read at https://www.wiley.com/en-us/Philosophy+of+Computer+Science%3... You are likely interested in sections 3.12 through 3.18 3.12 CS as Engineering 64 3.13 Science xor Engineering? 66 3.14 CS as “Both” 66 3.15 CS as “More” 68 3.15.1 CS as a New Kind of Science 68 3.15.2 CS as a New Kind of Engineering 70 3.16 CS as “Neither” 71 3.16.1 CS as Art 71 3.16.2 CS as the Study of Complexity 71 3.16.3 CS as the Philosophy(!) of Procedures 72 3.16.4 CS as Computational Thinking 72 3.16.5 CS as AI 73 3.16.6 Is CS Magic? 74 3.17 Summary 76 3.18 Questions for the Reader 77 And section 5 which starts out with: 5 Engineering 95 5.1 Defining ‘Engineering’ 95 5.2 Engineering as Science 97 5.3 A Brief History of Engineering 98 5.4 Conceptions of Engineering 99 5.5 What Engineers Do 100 reply rjrodger 11 hours agoprevYou did say philosophy of engineering, right? Look no further than “The Specialist” by Charles Sale “YOU'VE heard a lot of pratin' and prattlin' about this bein' the age of specialization. I'm a carpenter by trade. At one time I could of built a house, barn, church, or chicken coop. But I seen the need of a specialist in my line, so I studied her. I got her, she's mine. Gentlemen, you are face to face with the champion privybuilder of Sangamon County.” Sometimes the best books are also the shortest. https://www.toiletrevolution.com/wp-content/uploads/The-Spec... reply I_complete_me 10 hours agoparentThank you so much for that. It is wonderful. So therefore you must be. I am from Ireland and the whole sense of it resonates with me; the soft humour, the self-confidence, the sheer loveliness of his outlook, the different times. And the beautiful \"nartural\" language used is a joy. Cheers. reply bitzun 10 hours agoparentprevI found an small old copy of The Specialist without any attribution in a junk shop a few years ago and went down a short research rabbit hole about Chic Sale. Thanks for the reminder! reply atrettel 7 hours agoprevI recommend reading What Engineers Know and How They Know It by Walter Vincenti [1]. The book is directed towards mechanical and aerospace engineers, but discusses the philosophy and epistemology of engineering as a discipline via several case studies. A major topic of the book is the idea that engineering is not just \"applied science\" and does not necessarily need to use the scientific method (kinda summarized in the saying \"it's not stupid if it works\" in my opinion). The book analyzes several case studies to break apart the engineering process from the drawing board and through the production phase, and sometimes in multiple iterations back and forth even. [1] https://en.wikipedia.org/wiki/What_Engineers_Know_and_How_Th... reply kesavvaranasi 15 hours agoprevFor software engineering, I recommend A Philosophy of Software Design. It has principles that I think translate well to other engineering fields. For engineering in general: To Engineer is Human - Henry Petroski The Art of Doing Science and Engineering - Richard Hamming Structures: Or Why Things Don't Fall Down - J.E. Gordon reply robto 13 hours agoprevThey say naming is one of the hard problems of computer science, but there's not much concrete work addressing it. I'd recommend Elements of Clojure[0]. Don't be fooled by the title, it's not really about Clojure, it just uses Clojure as an illustration as it discusses a very subtle general problem. From the website: > The first chapter, Names, explains why names define the structure of our software, and how to judge whether a name is any good. > The second chapter, Idioms, provides specific, syntactic advice for writing Clojure which is clean and readable. > The third chapter, Indirection, looks at how code can be made simpler and more robust through separation. > The final chapter, Composition, explores how the constituent pieces of our code can be combined into an effective whole. I find it a thoughtful and considerate overview of an area that everybody has some implicit knowledge of, and something that leads to a more abstract concept of quality. [0]https://elementsofclojure.com/ reply ChicagoBoy11 15 hours agoprevNot totally what you are looking for, but I'd highlghly recommend \"Apollo\" by Murray and Cox. It focuses on the engineering history of the Apollo program, and it is a superbly well written and researched worked and so many of the stories are about engineering philosophy that I think it'll really be worth your while. reply pjmorris 13 hours agoparentSeconded, phenomenal book and suggestion. IMO in a similar vein is 'The Making of the Atomic Bomb', Richard Rhodes, another industry- and world-reshaping project. reply roarcher 14 hours agoparentprevIn a similar vein, there's \"Skunk Works\" by Ben Rich and Leo Janos, which covers the development of the U-2, F-117, and SR-17 aircraft. Not about the philosophy of engineering per se, but it's a great perspective into how problems were solved in a very unique program with extreme goals, before modern computer-aided tools. reply DyslexicAtheist 16 hours agoprevA city is not a tree. It is more about the limits of systems thinking. Must read for Smart-City IoT but applies to anything where you might think Tech is an easy fix to some social problem: http://worrydream.com/refs/Alexander%20-%20A%20City%20Is%20N... reply hyggetrold 16 hours agoparentYes! Christopher Alexander is a must-read for engineers. Notes on the Synthesis of Form is also very excellent. reply kaycebasques 16 hours agoprevCoincidentally I just started reading Engineering: A Very Short Introduction by David Blockley. I was very excited after the first chapter: it has a lot of profound ideas about engineering at large. Did you know that \"engineer\" does not derive from \"someone who cares for Industrial Revolution era engines\" but rather stems from a Latin / old French word for \"ingenious\"?? The second chapter feels a bit thrown together; i.e. the author seems to struggle a bit to unite all the events coherently. I think it's safe to say however that this book will give a broad overview of the long-term historical trends in the discipline, which is foundational for any type of philosophical understanding. P.S. I love the VSI series. Fits in my back pocket and usually gives a satisfying overview of a discipline. I always get a few fascinating ideas from every book. I've read probably 20 from the series at this point. reply stared 17 hours agoprevTao Te Ching, seriously There is a lot of emphasis on simplicity and that things are the best when they work seamlessly. Chapter 17, from the translation by Derek Lin, which I wholeheartedly recommend: The highest rulers, people do not know they have them The next level, people love them and praise them The next level, people fear them The next level, people despise them reply hosh 16 hours agoparentThere are several ways to approach the Tao Te Ching, including the mystical, but I think that there's a great book that explains the underlying approach the Chinese have, called, Treatise on Efficacy. Essentially, in Chinese philosophy, any given situation has a propensity (water tends to run downhill). It is therefore more effective to work with that propensity, than it is to work heroically against that propensity. This is very much a layer in what the Tao Te Ching talks about. reply svat 14 hours agorootparent> Essentially, in Chinese philosophy, any given situation has a propensity (water tends to run downhill). It is therefore more effective to work with that propensity, than it is to work heroically against that propensity. Interesting, this is similar to the Hindu/Indic idea of dharma (e.g. the dharma of water is to flow) and the idea of working with/towards dharma (both of oneself and the world generally). (Dharma refers to both the proper order of things and to the actions one takes to uphold it.) Edit: The \"See also\" section on the Wikipedia page for Ṛta is interesting: • Asha (Zoroastrianism) https://en.wikipedia.org/wiki/Asha • Maat (Egyptian religion) https://en.wikipedia.org/wiki/Maat • Me (Sumerian religion) https://en.wikipedia.org/wiki/Me_(mythology) • Tao (Chinese Taoism) https://en.wikipedia.org/wiki/Tao and a few others. In Hinduism there are Ṛta, Dharma, etc. (https://en.wikipedia.org/wiki/%E1%B9%9Ata https://en.wikipedia.org/wiki/Dharma) (also in Buddhism Jainism etc) reply hosh 14 hours agorootparentWhat's also interesting to me is that there are enough similarities between Vedic and ancient Greek thought, and yet here we are with Aristolean ideas in the West, and in India, things went the way of the Puranas. (Treatise of Efficacy went into the flaw baked into Aristolean thoughts separating Theory and Practice, and how going with the propensity bypasses that). The Chinese word for this propensity of the situation is shi (勢), rather than dao (道). There are other texts that talk about exploiting and profiting from propensity (shi), rather than what the Dao De Jing talks about with wei wuwei (為無為). reply agumonkey 10 hours agorootparentprevThe notion of propensity/flow made me question if one's life is not best when being able to see and surf trends as you need. Tiny soft and round exchanges between all parties.. a kind of dance. reply drannex 17 hours agoparentprevAnd if you want something a bit more relaxed and updated, The Dude De Ching[1], is quite good. It's a rewrite based around the core concepts of Dudeism, a fan-made spiritual practice based on the character \"The Dude\" from The Big Lebowski. > The rug is a fabrication which ties our ruminations together. 1. https://dudeism.com/thedudedeching/ Edit: There is an online version available as well, https://aui.me/text/the-dude-de-ching/ reply hyggetrold 16 hours agoparentprevAnother great translation is by Witter Bynner - the book is titled The Way of Life rather than Tao Te Ching. reply morelisp 16 hours agoparentprevDiscussed most recently/productively here at https://news.ycombinator.com/item?id=37686713 I think. reply stared 15 hours agorootparentThis very thread inspired me to read not only this book, but also this particular translation. reply therealmocker 14 hours agorootparentRead through the thread and didn't see references to the translation by Derek Lin, could you point to why you selected that version? reply stared 13 hours agorootparentIt is in the linked post, not - comments. reply FrustratedMonky 16 hours agoparentprevFor Eastern Influence. I think AI Engineers would be interested in a more Zen take, examining 'conceptual mind', 'subjective experience'. \"\"The Zen Teaching of Huang Po: On the Transmission of Mind\"\" https://www.goodreads.com/book/show/276779.The_Zen_Teaching_... reply archi42 9 hours agoprevIn the ethics department I enjoyed \"The Cambridge Handbook of Information and Computer Ethics\" (978-0521888981). We read part of it for a ethics lecture during my M.Sc., and like most ethics/philosophy piece I found a lot of things to think about. IIRC chapters are contributed by different authors, so it's not a single point of view (even though of course there is some filtering by the editor). Since it's from 2010 it is light on more recent developments like AI, however (unlike software) it's rare for ethic ideas to become outdated. So I would not dismiss it due to age. Also it's 5$ used on Amazon, so depending on your situation it's not a huge deal to get it and skim it - IMHO this kind of work doesn't have to be read front to back, instead it's great to get back to it when you feel like and think about a few pages and explore new ideas, re-evaluate your own concepts, etc. Description from the publisher: \"The Cambridge Handbook of Information and Computer Ethics, first published in 2010, provides an ambitious and authoritative introduction to the field, with discussions of a range of topics including privacy, ownership, freedom of speech, responsibility, technological determinism, the digital divide, and online pornography.\" Editorial reviews stolen from Amazon: \"...This five-part work examines difficulties in the field of information ethics and offers practical applications and criticisms... Recommended...\" --B. G. Turner, Faulkner University, CHOICE \"...This is a rich and fascinating book, bringing to interpretative debates much that has been hitherto unknown. The chapters are long and complex, and the argument is multidimensional and far-reaching.\" --George Lăzăroiu, PhD, Institute of Interdisciplinary Studies in Humanities and Social Sciences, New York, Contemporary Readings in Law and Social Justice reply hide1713 17 hours agoprevZen and the Art of Motorcycle Maintenance reply aristofun 17 hours agoparentI've never understood what engineers find in this book. It looks like a shallow kitchen philosophy of a guy next door to me. What you think is so good about this book for engineers, in a nutshell? reply borlanco 9 hours agorootparentPirsig's book is not really about engineering, but about how we engineers relate to the world. In engineering school I was taught to see the world in a special and unique way, to be able to solve engineering problems as a professional. In the book, this worldwiew is very well laid out. An example: > Precision instruments are designed to achieve an idea, dimensional precision, whose perfection is impossible. There is no perfectly shaped part of the motorcycle and never will be, but when you come as close as these instruments take you, remarkable things happen, and you go flying across the countryside under a power that would be called magic if it were not so completely rational in every way. It's the understanding of this rational intellectual idea that's fundamental. John looks at the motorcycle and he sees steel in various shapes and has negative feelings about these steel shapes and turns off the whole thing. I look at the shapes of the steel now and I see ideas. He thinks I'm working on parts. I'm working on concepts. reply hosh 16 hours agorootparentprevThe core thing is exploring just exactly what is subjective and what is objective, and whether quality is subjective or objective. Pirsig came up with an answer, and then goes on to talk about excellence (arete). Thinking back, this discourse seems like it was deliberately embedded in a kind of every day, guy-next-door narrative in order to touch on lived experience of \"quality\". Although Pirsig didn't explore it, quality is very much at the heart of any engineering, particularly when you try to quantify it. How effective is ISO-9000? GE was big on that. Boeing measured quality of their builds, until they compromised the process. What about Deming's approach (Total Quality Management)? What is quality in software engineering? (We often sidestep that question and call it Software Craftsmanship instead). And there's a whole can of worms when we try to apply this to AIs. reply aristofun 10 hours agorootparenti donknow... wasting so much time just to get a basic idea that quality is important looks like a terrible book to me. Of course in the context of \"books useful for engineers\". If you just enjoy someone's couch philosophy - i can totally understand that and agree that the book may be great. reply hosh 7 hours agorootparentThe idea isn’t about that quality is important though. It is that, even though people feel it is important, no one has been able to rationalize it or measure it. And that sometimes we act and talk as if we can. I’m not sure why you keep denigrating it as a couch philosophy. Just curious, are you doing that because you have worked through philosophies from academia or the classics? reply __loam 9 hours agorootparentprevMaybe you should try reading it before dismissing it like this. reply __loam 9 hours agorootparentprevIt's about how quality is fundamentally unmeasurable. reply hyggetrold 16 hours agorootparentprevDid you read the whole book yourself or just skim it? (asking sincerely) reply detourdog 15 hours agorootparentI read the book completely. The book was on a second year reading list for my industrial design department. I absorbed as an introduction to the philosophical aspects of quality. Quality is truly a tough concept if approached as a universal truth. reply hyggetrold 14 hours agorootparentThat makes sense to me. I'm not sure how to articulate what I got out of that book exactly but I did enjoy it. Some of the more 'spiritual' books I find, the value of them doesn't really hit you until you're older or have had some tragic life experiences happen. Until then some of it can just make you feel \"this is some vapid feel-good hippie crap.\" Not saying that was your reaction of course but it makes sense to me why you might not vibe with it if you read it in a university setting. reply aristofun 11 hours agorootparentprevi've tried few times to fight through first several pages - it gets dead boring and meaningless right from beginning reply hosh 7 hours agorootparentIf none of the comments here ignite your interest, it might not be time then. I had books like that. I also had books I can feel I need to read, and yet they are slogs. And then something happens, or I encounter an idea elsewhere, and it is as if something unlocks. And I am diving through the book… until I reach the next roadblock. I definitely would not force it. reply timeagain 15 hours agoparentprev+1. It can become a ramble at times and full-time philosophers seem to hate it. On the other hand, there is a lot of practical wisdom in the first half of the book, and what I consider to be a good payoff if you stick through to the end. reply max_ 17 hours agoprevLewis Mumford's Books; - Technics & Civilization - The Culture of Cities - The Story of Utopias Lewis Mumford talks about technology, but from an anthropological pint of view. Another book I would recommend is The Nature of Technology by Brian Arthur The other I would recommend is James Burk's Connections he's has some books but I but the documentary is highly recommended. reply Loic 13 hours agoprevIn How to Build Impossible Things, Ellison tells the story of his unconventional education in the world of architecture and design, and how he learned the satisfaction and joy that comes from doing something well for a long time. https://www.penguin.co.uk/books/447751/how-to-build-impossib... Enjoyable, not a philosophy of engineering but philosophy with engineering. reply ics 17 hours agoprevI enjoyed Engineering and the Mind's Eye by Eugene Ferguson https://mitpress.mit.edu/9780262560788/engineering-and-the-m... reply nshunter 16 hours agoparentCame here looking for this one to be mentioned reply weyj4 17 hours agoprevI've just purchased Richard Hamming's \"The Art of Doing Science and Engineering\" but haven't read it all yet, it looks pretty great. reply Tangurena2 16 hours agoparentIt is a great book, and it includes an amazing essay by him titled You and Your Research [0][1] - which explains why it is important to \"always be learning\". 0 - https://www.cs.virginia.edu/~robins/YouAndYourResearch.html 1 - https://www.youtube.com/watch?v=e3msMuwqp-o (lecture version) reply ignoramous 10 hours agorootparent> [Richard Hamming's] You and Your Research Add Edsger Dijkstra's The Humble Programmer (1972 Turing Lecture) as a companion read for software engs: https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340... / https://archive.is/U8GwX reply hyggetrold 16 hours agoparentprevI read it last year and it is fantastic - super absolutely ultra highly recommend that everybody read it. Run, don't walk, towards this book! reply buildsjets 16 hours agoprevSystemantics, AKA \"The Systems Bible: The Beginner's Guide to Systems Large and Small\" by John Gall. It is offered from the perspective of how not to design systems, based on system engineering failures. The primary precept of the treatise is that large complex systems are extremely difficult to design correctly despite best intentions, so care must be taken to design smaller, less-complex systems and to do so with incremental functionality based on close and continual touch with user needs and measures of effectiveness. https://en.wikipedia.org/wiki/Systemantics reply mezod 17 hours agoprevProbably not what you are asking for but thought they might be worth a look - https://www.goodreads.com/book/show/61899637-philosophy-of-c... - https://www.goodreads.com/book/show/60965426-the-creative-ac... - https://www.goodreads.com/book/show/530415.The_Art_of_Doing_... reply jpiburn 17 hours agoparentI second Rick Rubins book reply c6400sc 17 hours agoprevNormal Accidents and To Engineer is Human are two popular and great books. reply gooseyard 17 hours agoprevSimon Winchester's \"The Perfectionists\" is worth reading reply tracerbulletx 12 hours agoprevI enjoyed The Art of Doing Science and Engineering: Learning to Learn by Richard Hamming a lot. https://www.amazon.com/Art-Doing-Science-Engineering-Learnin... reply Ezku 11 hours agoprevThis book is probably about a very different kind of ”engineering” than what you had in mind, but it’s been highly influential to my thinking: “The Social Construction of Reality: A Treatise in the Sociology of Knowledge.” Berger & Luckmann 1966. Perhaps the core insight to me is that not only does every practice of engineering exist as embedded in the context of a socially constructed reality, but the practice of engineering itself also fundamentally involves the continual construction of such realities. In other words, for a software engineer to be able to do their job, they must among other things be a kind of applied social epistemologist. I expect this framing doesn’t make much sense to many readers — I’m hoping the following articles might serve to illustrate: “Programming as Theory Building.” Peter Naur, Microprocessing and Microprogramming 1985 (https://doi.org/10.1016/0165-6074(85)90032-8) > … suggests that programming properly should be regarded as an activity by which the programmers form or achieve a certain kind of insight, a theory, of the matters at hand. This suggestion is in contrast to what appears to be a more common notion, that programming should be regarded as a production of a program and certain other texts. “Interpretation, Interaction and Reality Construction in Software Engineering: An Explanatory Model.” Kari Rönkkö, Information and Software Technology 2007 (https://doi.org/10.1016/j.infsof.2007.02.014) > Floyd’s paper Outline of a Paradigm Change in Software Engineering requested that we move from a product oriented paradigm to a process oriented paradigm. > Naur’s paper Programming as Theory Building made it painfully clear to us that exemplary resources in the form of material and available support are not enough when modifying others’ programs. In fact, if Floyd’s claims had been taken seriously by the software developers in Naur’s study, and if the same developers had access to an explanatory model … their difficulties could have been both anticipated and prevented. > This article … explains from a natural language point of view, how interpretation takes place, and discusses the consequences of this in relation to interaction and reality construction in software engineering practice. reply efortis 8 hours agoprevFrom Code Complete 2nd edition: \"Engineers in every discipline learn the limits of the tools and materials they work with. If you’re an electrical engineer, you know the conductivity of various metals and a hundred ways to use a voltmeter. If you’re a structural engineer, you know the load-bearing properties of wood, concrete, and steel. \"If you’re a software engineer, your basic building material is human intellect and your primary tool is you.\" Page 819 reply wenc 16 hours agoprev“The effective engineer” by Edmond Lau is a good book for the IC software engineer working in an engineering organization. The most influential content on engineering in my life is not in a book but a YouTube talk entitled How Complex Systems Fail by Richard Cook, which is about designing resilient systems. I’ve applied these ideas to many aspects of life, not just engineering. reply throwaway888abc 17 hours agoprevTrying to stick to bellow as much as possible all the time: \"Keep it simple, stupid!\" https://en.wikipedia.org/wiki/KISS_principle The Basecamp's books are enjoyable, recommending https://basecamp.com/books/rework reply jdelacueva 16 hours agoprevAnything written by Langdon Winner https://en.wikipedia.org/wiki/Langdon_Winner I would begin with \"Do Artifacts Have Politics?\" and continue with \"Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought\", M.I.T. Press, 1977. reply yourcelf 13 hours agoprevIt may be a bit more zoomed out than what you're looking for if you're specifically looking at philosophical treatments of the practice of engineering, but Andrew Feenberg's \"Questioning Technology\" is excellent introduction to the philosophy of technology, particularly exploring the interplay between technological constraint and political/economic/social drivers of its development. \"Philosophy of Technology\" in general is a pretty rich field with a long history, and you might find more references in it than in engineering specifically. reply drannex 17 hours agoprevI can't understate just how great \"Waking Up: Overcoming the Obstacles to Human Potential\" by Charles Tart (2001) is. It's a cross between engineering and the spirituality (although I argue, it's more on the philosophy and psychoanalysis of engineering than spiritual). I wrote a (short) review on the book directly after reading it here[1]. I've since reread the book, and while some of my opinions on it are the same, some I understand the nuance much more in context of the rest of the book, I need to update it. 1. https://macleodsawyer.com/books/waking-up/ reply softwaredoug 11 hours agoprevNobody has mentioned the “Do Committees invent” paper by Melvin Conway. It’s the origin of Conway law, but the actual paper is way deeper than that https://www.melconway.com/Home/Committees_Paper.html reply ctrlp 8 hours agoprevSamuel Florman wrote some interesting books reflecting on engineering and the humanities The Civilized Engineer The Introspective Engineer The Existential Pleasures of Engineering A few others I haven't read reply DanielBMarkham 17 hours agoprevI wrote one which I do not promote, but I dropped by the forum and you asked. https://leanpub.com/info-ops/c/LeanpubWeeklySale2024Jan19 Note: Book 2 is more code-centric, with active strategies to minimize solution complexity. This book is all about how to minimize to-do list complexity and tracking (which arguably is more important) reply MPSimmons 13 hours agoprevRisk Society by Ulrich Beck is one that I enjoyed. Make sure to get it used; the new prices are crazy https://www.amazon.com/Risk-Society-Modernity-Published-asso... reply Cloudly 17 hours agoprevI would recommend \"The Things We Make\" for an outlook into engineering mindsets through history. A good reminder that a lot of useful engineering comes before the theory can fully explain it :) https://www.goodreads.com/en/book/show/75598048 reply crabmusket 9 hours agoprevThe Beginning of Infinity by David Deutsch is more broadly about science and epistemology, but I think it has a lot to say about how we do engineering. reply javiramos 17 hours agoprevThe Art of Doing Science and Engineering reply saintblasphemer 14 hours agoprevThe Sciences of the Artificial by Herbert A. Simon. Absolutely foundational. reply yair99dd 8 hours agoprevTo engineer is human by Henry Petroski [1982]. The short film of this is also great reply Fromusonia 10 hours agoprev“The unwritten laws of engineering” https://www.asme.org/publications-submissions/books/find-boo... reply nikhilsimha 12 hours agoprevcannot recommend sicp enough: https://mitp-content-server.mit.edu/books/content/sectbyfn/b... uses scheme to illustrate how to think about computation abstractly. reply kjqgqkejbfefn 16 hours agoprevHeidegger's https://en.wikipedia.org/wiki/The_Question_Concerning_Techno... reply R41 14 hours agoprevI recommend Marvin Minisckys society of minds book. He was one of founding fathers of AI tech, the book tells lot about human mind an Interesting read. reply walterbell 17 hours agoprevThe Ancient Engineers by L. Sprague de Camp (1963), https://news.ycombinator.com/item?id=8158385 reply matesitox 14 hours agoprevThe Things We Make by Bill Hammack Changed my way of understanding what engineering is. Read the chaoter on designing cathedrals without math, science or modelling. reply waingake 13 hours agoprevZen and the art of motorcycle maintenance reply 3abiton 10 hours agoprevThanks for this thrrad OP! Lots of great recommendations for the rest of us reply iancmceachern 7 hours agoprevThe Introspective Engineer The Intentional Engineer reply JojoFatsani 12 hours agoprevThe Phoenix Project. reply HeyLaughingBoy 11 hours agoprevSafeware by Nancy Leveson. reply random3 17 hours agoprevIf you seek elightment, you seek truth. Look down towards foundations like physics, mathematics, logic and look back towards the past. It' smaybe check out the Computer History Museum. Read Feynman's (or about) books. \"Surely you're joking, Mr Feynman\" is light but profound. Max Tegmark's \"Our Mathematical Universe\" is great. \"I am a strange loop\" by Douglas Hofstadter will connect many dots. If you want to peek deeper - \"Through two doors at once\" describes experiments at the edge of our reality. \"The singularity is near\" is a good perspective that connects dots through time back many years to many in the future. These are just some incomplete starter points. It's deep, beautiful rabbit hole. Enjoy it. reply dankco 17 hours agoprevI like to recommend \"Kill It With Fire\" by Marianne Bellotti. It is full of insights far beyond managing legacy systems (as the subtitle would have you believe) and does a great job of analyzing the technology and the people/organizations who build it. reply mtillman 17 hours agoprev* The Art of Unix Programming * The Art of Computer Programming reply matesitox 14 hours agoprevThe Things We Make by Bill Hammack reply demondemidi 6 hours agoprevAgainst Method by Paul Feyeraband Critical Path by buckminster fuller reply __loam 9 hours agoprevTo Engineer is Human by Petroski. It's about engineering failures and responsibility. reply lambdaphagy 10 hours agoprevFlorman's _The Existential Pleasures of Engineering_. reply troupe 12 hours agoprevTwo books that did for me what I think you are looking for: - From Mathematics to Generic Programming by Stepanov & Rose - Gödel, Escher, Bach: an Eternal Golden Braid by Hofstadter - The Little Schemer / The Seasoned Schemer reply alfiedotwtf 10 hours agoprevIf you want the philosophical approach to the way to do things on Unix systems, you can’t beat “The Art of Unix Programming” by ESR. That book flipped my whole understanding of the way to write code more than any other book. reply morelisp 16 hours agoprev [–] Aramis, or the Love of Technology. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author is a software engineer with a passion for computers and a desire to learn new concepts.",
      "They are interested in finding books and projects that have inspired others and have developed a personal engineering philosophy.",
      "They are specifically looking for recommendations in the broader field of engineering, not just software engineering."
    ],
    "commentSummary": [
      "This is a compilation of discussions and recommendations for books on a variety of topics, including philosophy of engineering, software design, computer science, coding, and motorcycle maintenance.",
      "Users suggest books that explore the societal implications of engineering, critique tech culture, and discuss the philosophy of technology.",
      "The recommendations also cover topics like systems thinking, information ethics, quality in engineering, and creativity in engineering and science."
    ],
    "points": 212,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1705681384
  }
]
