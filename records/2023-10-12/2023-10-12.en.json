[
  {
    "id": 37848212,
    "title": "Starlink Direct to Cell",
    "originLink": "https://direct.starlink.com/",
    "originBody": "Skip to content Starlink FIXED SITE LAND MOBILITY MARITIME AVIATION DIRECT TO CELL PERSONAL BUSINESS STARLINK DIRECT TO CELL Seamless access to text, voice, and data for LTE phones across the globe GET IN TOUCH UBIQUITOUS COVERAGE Starlink satellites with Direct to Cell capabilities enable ubiquitous access to texting, calling, and browsing wherever you may be on land, lakes, or coastal waters. Direct to Cell will also connect IoT devices with common LTE standards. STAY CONNECTED Direct to Cell works with existing LTE phones wherever you can see the sky. No changes to hardware, firmware, or special apps are required, providing seamless access to text, voice, and data. A CELLPHONE TOWER IN SPACE Starlink satellites with Direct to Cell capability have an advanced eNodeB modem onboard that acts like a cellphone tower in space, allowing network integration similar to a standard roaming partner. ELIMINATE DEAD ZONES Direct to Cell enables connectivity in remote regions, providing peace of mind when customers need it most. ENGINEERED BY SPACEX SpaceX is leveraging its experience in manufacturing and launching the world’s most advanced rockets and spacecraft to deploy Starlink satellites with the Direct to Cell capability at scale. Direct to Cell satellites will initially be launched on SpaceX’s Falcon 9 rocket and then Starship. On orbit the satellites will immediately connect over laser backhaul to the Starlink constellation to provide global connectivity. GLOBAL PARTNERS Cellular providers using Direct to Cell have access to reciprocal global access in all partner nations. T-MOBILE (USA) OPTUS (AUSTRALIA) ROGERS (CANADA) ONE NZ (NEW ZEALAND) KDDI (JAPAN) SALT (SWITZERLAND) CONTACT US Learn how Starlink Direct To Cell can expand your network. Name First Last Email Company Careers Satellite Operators Privacy & Legal Privacy Preferences View Starlink's X page Starlink© 2023 Starlink is a division of SpaceX. Visit us at SpaceX.com",
    "commentLink": "https://news.ycombinator.com/item?id=37848212",
    "commentBody": "Starlink Direct to CellHacker NewspastloginStarlink Direct to Cell (starlink.com) 657 points by pr337h4m 20 hours ago| hidepastfavorite482 comments blhack 20 hours agoThis is for very low bandwidth text communications when you&#x27;re out in the country and can see the sky.Stuff like this has existed from companies like garmin for some time. This is very cool, though.Here is when this was announced: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Qzli-Ww26QsPretty cool! Also kindof funny to see the TMobile CEO trying to hype people up and Elon sortof reigning it in. reply LeifCarrotson 19 hours agoparentBut low-bandwidth text is all I need. I guess I won&#x27;t be renewing my subscription for my InReach Mini forever (although that form factor is pretty nice).I don&#x27;t need to be able to stream Netflix when I&#x27;m in the backcountry, it&#x27;s just that my wife insists I need to be able to get a helicopter if I break my leg.Now we need app developers to log off their fiber-served wifi when writing messenger apps, and log into a high-latency, low-bandwidth, high-packet-loss network instead so Messages will actually open instead of whatever it&#x27;s trying to do to upload my location history and download contact pictures... reply JumpCrisscross 17 hours agorootparent> I won&#x27;t be renewing my subscription for my InReach Mini forever (although that form factor is pretty nice)Before getting an InReach, confirm a 406MHz emergency beacon doesn&#x27;t fit your bill [1][2]. (I have this one [3].)You can&#x27;t text a loved one. But with no subscription, a years-long battery and powerful radio that works around the world, you can call emergency services to your precise location.[1] https:&#x2F;&#x2F;www.sarsat.noaa.gov&#x2F;emergency-406-beacons&#x2F;[2] https:&#x2F;&#x2F;www.rei.com&#x2F;learn&#x2F;expert-advice&#x2F;personal-locator-bea...[3] https:&#x2F;&#x2F;www.rei.com&#x2F;product&#x2F;161982&#x2F;acr-electronics-resqlink-... reply biomcgary 16 hours agorootparentMy wife hikes in Western Colorado quite a bit and has helped rescue 3 parties over the past 4 years. In one case, a young woman (an ER nurse) was in dire distress for no apparent reason and fading quickly (in retrospect possibly COVID related sequela). Initially, emergency responders were going the route of a land-based rescue, but the Mini allowed the urgency to be communicated more clearly. The helicopter touched down on a scree field (but couldn&#x27;t land) while my wife and a couple others helped the EMT load her. Docs said that she had less than an hour or so before long-term consequences or death.Any emergency beacon is better than none, but two-way communication can be a literal lifesaver. I hope that the Starlink system is eventually linked into our 911 infrastructure and available to anyone with an LTE phone regardless of carrier. reply zmj 16 hours agorootparentTwo-way communication is important to prevent false positive emergencies, too. There have been several times I&#x27;ve used my inReach to message that I&#x27;m going to miss my planned check-in time, but everything is OK - no need to alert SAR.Also to communicate on-the-fly decision-making to inform potential SAR - \"I&#x27;m making good time, going to head up this extra peak before continuing the planned route.\"I&#x27;m happy to have a cell phone backup to the inReach, but I don&#x27;t see this Starlink offering as a replacement. That goes double if you&#x27;re out in winter. Phone batteries aren&#x27;t great in the cold. reply londons_explore 16 hours agorootparentPhone batteries are fine down to -20C and usually are functional to about -30C.You should have no problem with that anywhere in the world as long as you keep it in an inner pocket. Perhaps pack wired earphones just in case you need to make a long call while keeping the phone itself warm.Notably the battery should not be charged below about 5C. If you do, it will be permanently damaged. reply zeagle 11 hours agorootparentRespectfully, I don&#x27;t know about that. I wouldn&#x27;t trust it if my life was on the line. I go for walks and bike rides when it&#x27;s -25C to -30C air temperature (before windchill) and I&#x27;ve had old samsung galaxies and newer pixels both crash if I take them out to take a photo. I presumable due to voltage dip. reply emilburzo 9 hours agorootparentThis is exactly the reason why I&#x27;m sticking with the CAT S6x series phones and willing to put up with mediocre performance&#x2F;features, as far as smartphones go.They&#x27;ve been the only ones that don&#x27;t just turn off in really cold temperatures, even without babying them in warm pockets.The general ruggedness is also pretty good to amazing, depending on how fragile your previous phones were. For example: it survived a ~10 meter (32ft) drop on rocks, whereas everyone was convinced it was done for. reply PawgerZ 1 hour agorootparentDo you have one of the newer models with the thermal camera? I was very interested in seeing how well that works. reply dylan604 8 hours agorootparentprevTo someone that lives in a place where we just had an entire summer of 40°C and higher, -25°C sounds like Antarctica, or Mars. And you do that on a bicycle? Clearly, you must be an alien! reply pmontra 6 hours agorootparentActually, an Italian guy is about to start a bike hike to the South Pole. This is the first link I found to a page in English about it https:&#x2F;&#x2F;aminhacorrida.com&#x2F;en&#x2F;omar-di-felice-comes-back-to-at... reply feedsmgmt 8 hours agorootparentprevDo people in those areas need phone cases that are insulated to retain heat? reply aembleton 2 hours agorootparentprevMy last two phones (Xiaomi 9T and Pixel 7) have struggled below about -5C. They still work but the battery drops very quickly so you can&#x27;t rely upon them. Keeping them in an inner pocket works but I then take them out and see the battery drop. The sudden temperature change might not help there. reply 20after4 13 hours agorootparentprev> Notably the battery should not be charged below about 5C. If you do, it will be permanently damaged.This depends on the specific battery chemistry. The BMS should prevent the charging scenarios which would damage the battery. For some it&#x27;s 0C not 5C. Some can handle charging below 0C. reply londons_explore 6 hours agorootparentI have never seen a phone BMS that prevents charging due to undertemperature reply michaelt 2 hours agorootparentIsn&#x27;t that a stock feature on pretty much every chip? I mean, if you&#x27;ve got a temperature sensor for overtemperature protection, including undertemperature protection is trivial.Even the cheapest chips from TI and ST seem to include it. And modern cell phones often advertise extra-fast 20W+ charging, so I doubt they&#x27;re using the cheapest chips. reply RenThraysk 2 hours agorootparentprevSamsung Galaxy XCovers have user replaceable batteries, so can atleast keep spare(s) warm. reply ejlxsh 9 hours agorootparentpreviPhones often turn off around -20c with a warning about temperature, it happens to me every time I travel to Lapland in the Winter. reply vxNsr 11 hours agorootparentprevmy iphone 6s and 12 pro beg to differ. both saw serious drops in battery in pretty normal 10-15F chicago winters while I was outdoor ice skating or even just going for a long walk with the phone in my pocket. reply lxgr 14 hours agorootparentprev> I hope that the Starlink system is eventually linked into our 911 infrastructure and available to anyone with an LTE phone regardless of carrier.If Starlink&#x27;s solution is really completely unmodified LTE, I&#x27;d expect 911 calls to work regardless of being a T-Mobile subscriber, just like for existing terrestrial networks (where you can dial 911 even if your carrier does not have signal in a given location, or even entirely without a SIM card). reply sidewndr46 13 hours agorootparentI don&#x27;t think LTE can cope with the extreme doppler shift present when the other end is a satellite in LEO reply lxgr 12 hours agorootparentThe shift is actually not that extreme in LEO (a few KHz at most).And couldn’t the satellites mostly adjust for that, given that the relative doppler shift should be pretty constant between mobiles in the same spot beam? reply sidewndr46 1 hour agorootparentLTE can&#x27;t even handle a high speed train. 1 kHz causes significant degradationhttps:&#x2F;&#x2F;eudl.eu&#x2F;pdf&#x2F;10.1007&#x2F;978-3-319-66628-0_41doppler shift is not a constant for a stationary observer from Earth. reply girvo 13 hours agorootparentprevI don&#x27;t know how much I&#x27;m allowed to say, but at least part of what they&#x27;re doing is normal Cat-1 LTE that any modem that supports it will be able to pick up reply ingenium 10 hours agorootparentHow are they accounting for the presumably very high timing advance? replybmelton 15 hours agorootparentprev> you can call emergency services to your precise location.I guess this is the first time it&#x27;s occurred to me that hikers and backpackers and such carry them too, which is odd because I hike and backpack.I picked up the InReach after finding myself 200 miles offshore in a sailboat without an engine or battery power (which meant no VHF or electronic navigation equipment or autopilot or even red&#x2F;green lights for others to see us at night) nor any way to make powerI assume the 406 Mhz beacon has a range of a few miles? reply 0_____0 14 hours agorootparent406MHz I think is referencing PLBs and EPIRBs, which I&#x27;m guessing you&#x27;re familiar with from sailing. The power is high enough that satellites can be used to get gross location, with radio direction finding being used by rescue party reply bmelton 14 hours agorootparentAHA! Yes, thank you.Other than the compass (which was only visible in the day time) the EPIRB was the only piece of equipment we assumed to work on the aforementioned voyage. We of course didn&#x27;t test it as we were able to make it back safely, but I should probably learn more about how it functions. reply dylan604 8 hours agorootparentwith no propulsion, I&#x27;m assuming you were just drifting and not really doing to much navigation. just curious if you tried any celestial navigation at night to attempt any sense of direction? reply plugin-baby 7 hours agorootparentif there was wind they may have been sailing. reply runlevel1 13 hours agorootparentprevThat sounds like a hell of a story. How did you find yourself in that situation? And how did you get out of it? reply reaperman 13 hours agorootparentIf it were me, I’d assume backup paper navigation charts and either a handheld battery powered backup GPS or my smartphone that has an app to parse data from the GPS chip. Could use primarily dead reckoning plus turn the phone on every couple hours to update true location. Most sailors are using paper charts for tricky sections anyways — you just normally have a constant GPS location provided by your navigation system.There are also lots of established shipping lanes you could find that would be relatively densely traveled and give you periodic feedback for which direction to go. A bit more dangerous due to collisions without lights but as long as your retroreflector is hoisted, big ships should see you clearly on radar. plus you’ll generally be swapping sleep shifts and always have someone manning the helm on the sailboat, though seeing large vessels at night can be somewhat more difficult. reply closewith 2 hours agorootparent> Most sailors are using paper charts for tricky sections anyways — you just normally have a constant GPS location provided by your navigation system.My experience in Marine SAR is that this is no longer true. Apps like Navionics, SeaPilot, etc - often without any backup at all - are by far the most common form of navigation. reply bmelton 12 hours agorootparentprevMostly all that&#x27;s right. We had three phones and a few battery packs (tho we&#x27;d exhausted them more quickly than expected and lost one to rain) because the paper charts aboard were from the late 80s when the boat was built and were all for the Pacific ocean it was built to sail.The only other complicating factor was that due to the August Florida heat, nobody really had the luxury of sleep for the first couple of days. reply bmelton 13 hours agorootparentprevOffered to help the owner (a friend of a friend of a friend) of an older racing sailboat move his boat from Florida to Maryland. It was planned to be us and 4-5 other crew, but (red flag the first) ended up being only me, my wife, and the owner.There were lots of red flags before finding ourselves in squarely over our heads -- an overheating motor was explained away as having had an undersized thermostat installed. Plausible enough. The lack of a bimini in August in Florida was just forgotten, but led to pretty significant overheating to me. The autopilot not working we didn&#x27;t realize until about 15 miles offshore. That the autopilot was draining all the other batteries we didn&#x27;t realize until we lost navigation lights. Etc. Etc.This was embarrassingly recent, but suffice to say a LOT of lessons were learned. The boat was foreign enough that I accepted too many \"explanations\" as comfort when they should have been a reason to abort. Failures compounded and voila, we&#x27;re now 15 hours away from civilization flying a spinnaker through thunderstorms at night and positively hauling ass.Eventually we got the owner to appreciate our discomfort enough and how over our heads we were to head to safety in Charleston (he&#x27;d still just been heading east, which was baffling -- but apparently it is not everyone&#x27;s first instinct to go to safety when life-threatening failures crop up) but that brought its own perils -- coming into a crowded channel at night without navigation lights isn&#x27;t advised. We were shining a flashlight onto the sails, but the flashlight would change modes if it wasn&#x27;t held steadily enough. One of the storms we&#x27;d sailed through had killed the owner&#x27;s phone as well as his phone charger, so the little bits of navigation we had were precious, but necessary coming into shallower coastal waters. A cargo ship coming out of harbor kicked us out of the channel just enough that we ended up grounded and stuck pretty squarely about a half mile away from restaurants, but late enough on a Sunday that there wasn&#x27;t any other traffic we could hail down. (A radio would have been lovely in that case)I was sunburnt and heat-stroked enough that despite guzzling water constantly, I hadn&#x27;t urinated in 24 hours, and though we were in relative calm, the totality of circumstances, I used the last of the dwindling battery on the last usable phone among us to call the coast guard for evacuation. The owner of the boat stayed behind.To paraphrase Cheryl Strayed -- If you&#x27;d asked me at any point in the journey, I was absolutely miserable, but on the whole it was miraculous. Gained a ton of skills. Learned a ton of red flags to look out for. Experienced a lot of firsts, not the least of which included a crash course in celestial navigation. And being 200 miles offshore and awake the whole night during the Perseid meteor shower was absolutely brilliant. reply bigiain 10 hours agorootparent\"If you&#x27;d asked me at any point in the journey, I was absolutely miserable, but on the whole it was miraculous. Gained a ton of skills.\"Sounds a lot like ocean racing sailboats under normal circumstances.I quit ocean racing (after about 5 seasons) when I had a sudden realisation that the only part that was any fun in the last 3 days was sitting in the bar after it was over and talking about it. And there were ten times as many non-crew people there enjoying that with us as there were crew on the boat I raced on. reply airbreather 20 minutes agorootparentI quit when I realized I despised the cold so much that if I fell in I would probably give up after 5 minutes. reply runlevel1 11 hours agorootparentprevYep, that sounds like a wild ride!I&#x27;m glad you lived to tell the tale, stranger. reply bmelton 11 hours agorootparentThank you. I also am.Honestly glad my wife was aboard as it lowered my risk threshold enough to get me to want to abort. reply cdchn 11 hours agorootparentprevWhat happened to the owner? Some say he is still there with his doomed boat to this day... reply sgtnoodle 14 hours agorootparentprevRe: range, it&#x27;s still satallite based. It&#x27;s purely for emergencies, though, rather than for convenience. reply bmelton 13 hours agorootparentThank you reply mplewis 15 hours agorootparentprevSomething else to keep in mind is that the dedicated PLBs often have 10 times the transmit power as the combo satellite messengers. reply xoa 19 hours agorootparentprev>Now we need app developers to log off their fiber-served wifi when writing messenger apps, and log into a high-latency, low-bandwidth, high-packet-loss network instead so Messages will actually open instead of whatever it&#x27;s trying to do to upload my location history and download contact pictures...FWIW, it&#x27;s perfectly possible to simulate arbitrary levels of bandwidth&#x2F;latency with a variety of tools even while having a fiber connection. For example, Macs have long had the \"Network Link Conditioner\" tool as a free utility included with the Additional Tools for Xcode package, which then allows simulating configurable bandwidth, latency, and packet loss. There are similar tools for Linux as well, tc is powerful. Most firewalls with quality traffic shapers also allow at least the first two at the network level, I used that on OPNsense to simulate a VSAT connection with 750ms latency and 4&#x2F;.5 to a specific VLAN so that we could just connect systems and then see how applications worked. It&#x27;s been awhile but it was eye opening. A nice thing about that approach is that then you can just connect devices to a given VLAN, which makes testing back and forth super easy. Wired is trivial of course, have a switch where each port is a different test VLAN, but even for wireless if you have WAPs that support PPSK&#x2F;MPSK, then hopping between test VLANs just means reconnecting with a different password. Simulating packet loss with a network device seems the be more niche and complicated and I don&#x27;t know if any firewalls put a GUI on it. tc queue disciplines can be used though so any Linux device with two network ports can sit inline and modify the traffic to simulate loss&#x2F;latency, an RPi would be fine for that.I agree it&#x27;d be nice if more app developers would test under less than ideal conditions, particularly since it&#x27;s so trivial to do so. I think most simply don&#x27;t think about it though, same as many GUIs (web or local) not testing for stuff like various types of color blindness. reply lll-o-lll 17 hours agorootparent> it&#x27;s perfectly possible to simulate arbitrary levels of bandwidth&#x2F;latency with a variety of tools even while having a fiber connection.Yes it is perfectly possible, but it’s very difficult. Having just gone through this process I can attest that this is not something the average “app developer” is going to be capable of doing, at least on Linux and Windows.The raw tools are there, but they are complicated, poorly documented, and require network engineering knowledge on top of software development knowledge.Probably there is some nice package to wrap up the whole “generate a virtual network and add latency + packet loss between these two end points”, I just never found it. reply DaiPlusPlus 17 hours agorootparent> Probably there is some nice package to wrap up the whole “generate a virtual network and add latency + packet loss between these two end points”, I just never found it.Linux has a built-in command: tricklehttps:&#x2F;&#x2F;linux.die.net&#x2F;man&#x2F;1&#x2F;tricklehttps:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;10328568&#x2F;simulate-limite... reply eichin 16 hours agorootparenttrickle is clever, but when I&#x27;ve tried to use it for \"use no more than this\" bandwidth shaping (basically going for \"rsync --bwlimit\" but for a set of \"related\" rsync processes) the arguments given had very little to do with the amount of bandwidth actually consumed. (We found another way but definitely look at tc instead.) reply franga2000 16 hours agorootparentprevIt&#x27;s not that they won&#x27;t be \"capable of doing\" it, it&#x27;s that the effort required will be more than they care to put into solving a problem they can&#x27;t sympathise with and&#x2F;or isn&#x27;t a requirement handed down from their boss. App developers have to jump through all sorts of technical hooks to get certain things done, but since their jobs depend on it, they power though. If \"work reliably even in shit network conditions\" was a baseline requirement that their jobs depended on, you bet they&#x27;d find a way.As for how hard it actually is: iOS has already been explained, the Android emulator has network latency and speed simulation right in the GUI, as do most web browsers. And there&#x27;s alway the option to switch your phone to 2G only in the settings and&#x2F;or go into the basement or elevator. reply 20after4 13 hours agorootparent>If \"work reliably even in shit network conditions\" was a baseline requirement that their jobs depended on, you bet they&#x27;d find a way.This is the real problem - there are deadlines and most projects don&#x27;t even consider working in questionable network conditions. Developers aren&#x27;t going to put in the extra effort when it doesn&#x27;t contribute to the job they are asked to do. reply bigiain 10 hours agorootparentI have had to deal with poor App&#x2F;Play Store reviews for both of \"It doesn&#x27;t work on the train while I&#x27;m commuting in the morning\" and \"It doesn&#x27;t work at the event when there are 100,000+ other people there\" flaky network related problems.I always at least _ask_ in the requirements gathering stage for a new mobile app: \"how much effort do we want to dedicate to app performance&#x2F;reliability under marginal network conditions?\"As it turns out, pretty much all mobile app owners are as apathetic about that as most mobile app developers. (On the other hand, once you&#x27;ve got a reputation for being able to handle those sorts of flaky network edge cases, you get more and more work for the sort of apps that benefit from them. The downside of that is it&#x27;s never the flashy resume-building-apps that come to you for this.) reply chmod775 6 hours agorootparentprevLinux has been explained to death in the replies, but on Windows you can use clumsy[1] - it&#x27;s as simple as it gets.[1] https:&#x2F;&#x2F;jagt.github.io&#x2F;clumsy&#x2F; reply loxias 16 hours agorootparentprev> Yes it is perfectly possible, but it’s very difficult. ...shrugDisagree, it&#x27;s no harder than any other linux subsystem, you can use `tc` or you can attack it a different way by using virtualization then messing with it at the vde layer. I&#x27;ve added storage and network random latency for testing code before, took a day or so to get working perfectly, but now it&#x27;s in a shell script.Hm, alternatively.... you&#x27;re right, it&#x27;s very difficult. You should hire a software engineer, such as myself, to do it for you. ;-) ;-) reply madeofpalk 15 hours agorootparentprevLike parent said, Network Link Conditioner is exactly that tool. It&#x27;s even built directly into iOS (though only visible in settings once \"used for development\" via XCode).Both Firefox and Chrome dev tools also have built in throttling of network connections. https:&#x2F;&#x2F;blog.nightly.mozilla.org&#x2F;2016&#x2F;11&#x2F;07&#x2F;simulate-slow-co...The tools exist and they&#x27;re easy to use. Most people just don&#x27;t bother. reply lxgr 14 hours agorootparentprev> For example, Macs have long had the \"Network Link Conditioner\" tool as a free utility included with the Additional Tools for Xcode package, which then allows simulating configurable bandwidth, latency, and packet loss.Well, I sure wish Apple would make use of that functionality themselves once in a while.It&#x27;s frustratingly impossible to enqueue an iMessage message while out of signal and have it be automatically delivered once back in cell coverage. Bizarrely WhatsApp, a third-party application (with all the background execution restrictions that go with that), manages to do just that! reply cassepipe 18 hours agorootparentprevFirefox&#x27;s console in its Network tab also has a way to choose what tier of bandwidth you&#x27;d like: GPRS, 3G etc. Thought it was worth mentioning reply DaiPlusPlus 17 hours agorootparentI find Firefox and Chrome&#x27;s network-limiter feature to be \"unrealistically unreliable\" insofar as it limits data transfer bandwidth, and simulates some kinds of latency issues, but doesn&#x27;t seem to implement things like DNS suddenly stopping working for 5 seconds, or sporadic network drop-outs, or how some things will arrive out-of-order, or an entire web-page blocked by a single synchronous from one particular external host. reply londons_explore 16 hours agorootparentI agree. It needs to simulate a phone right on the edge of connectivity, with the random 5 second dropouts, followed by 50 Mbps but downstream only, followed by another dropout, followed by 1kbps up and down, etc.That&#x27;s the way real networks behave, and what real users have to manage with. reply sangnoir 18 hours agorootparentprev> Now we need app developers to log off their fiber-served wifi when writing messenger appsYou should try WhatsApp - there really are not many messenger choices when you have unreliable 2G(!) connectivity. For all the faults of Meta, WhatsApp seems to be the only company that cares about people with bandwidth measured in kbps, sometimes fractions thereof. reply kelnos 16 hours agorootparent> For all the faults of Meta, WhatsApp seems to be the only company that cares about people with bandwidth measured in kbps, sometimes fractions thereof.WhatsApp was built with low-bandwidth&#x2F;high-latency&#x2F;high-packet-loss in mind well before Meta acquired them.I suppose we can give them vague amounts of credit for not making those use cases worse since the acquisition. reply londons_explore 16 hours agorootparentThey have made it worse...It used to work just fine on 1kbps.Now it is pretty much unusable over dialup or GPRS. reply lxgr 14 hours agorootparentTo be fair, it used to be \"encrypted\" using a scheme not too far removed from ROT13; now it&#x27;s using the Signal protocol, which probably requires quite a few more bytes per message.For example, messaging a contact with multiple devices connected means that your phone has to encrypt your message to each of their clients independently. reply Scoundreller 18 hours agorootparentprevWhatsApp also gracefully handles being offline and queuing messages for later.That can’t be said of iMessage. reply sangnoir 17 hours agorootparentOffline queueing is a fantastic feature! I know someone who lives in a remote area whose phone only gets network connectivity when they walk up a specific hill. In many ways, they use WhatsApp the way most people used email in the dialup days: read and compose offline, then go online once a day to send and receive new messages.Edit: I sometimes get a chuckle when they say \"Look at this cool picture I took\", and then receive the picture some days later when the conversation thread has moved on. I guess they&#x27;d have stayed in thr coverage area for long enough for the entire image to upload. reply bdavbdav 2 hours agorootparentprevI know when people are in low signal as I get a green then exactly the same blue some time later. reply lxgr 14 hours agorootparentprevThis is so bizarre to me. How can a native application not implement that, while a third-party application nails it!? reply ale42 17 hours agorootparentprevAny idea how it compares to Signal? They should be essentially using the same protocol. I also used it with good results with slow connectivity, but never tried on bad 2G... reply callalex 16 hours agorootparentThe encryption protocol is fairly unrelated to how an app handles poor connectivity. It’s a bit like comparing different websites handling poor connectivity differently even though they are all served over HTTP. reply lxgr 14 hours agorootparentprevI believe their communication layers are fairly different – WhatsApp used to use something based on XMPP at least until a while ago; I&#x27;m not sure what Signal uses, but I vaguely remember it being based on HTTP? reply ale42 4 hours agorootparentCan definitely be, I never investigated in detail, although I used alternative open source clients for both (signal-cli and a long time ago yowsup), so the information should be in there...I hoped that Signal&#x27;s use of HTTP was as a fallback in case a direct connection could not be established to use a more \"compact\" protocol, but I possibly don&#x27;t remember correctly what I&#x27;ve read... reply briffle 17 hours agorootparentprevI have tried to use signal in a location that had voice, but no data (a very old, very rural tower in the middle of nowhere) a few years ago, and signal was completely worthless. Even though it can read and receive SMS, it seems to require a data connection to send.. reply vdqtp3 16 hours agorootparentYes, everything except voice and SMS requires data reply kelnos 16 hours agorootparentprevYes, that would be the case for any OTT messenger (so, anything but SMS). reply sangnoir 17 hours agorootparentprevUnfortunately I don&#x27;t have any data points on how Signal operates 2G speeds reply jaflo 16 hours agorootparentprevTelegram also has pretty amazing support for poor connectivity environents reply ugjka 18 hours agorootparentprevBecause Whatsapp is huge in Africa IIRC reply fishtacos 18 hours agorootparentIt&#x27;s huge in many countries where Internet service has been expensive or difficult to come by. Case in point, all my relatives in Eastern Europe use WhatsApp, and with better bandwidth options, some are using FB Messenger for video calls,.as well. reply murphyslaw 17 hours agorootparentprevEveryone I know in Belgium&#x2F;The Netherlands&#x2F;... uses Whatsapp. It&#x27;s even got into the language: \"to app someone\", i.e. \"iemand appen\". reply jorvi 17 hours agorootparentprevFacebook used to have (has?) 2G Tuesdays, where devs had to test their stuff at 2G speeds, for this exact reason. reply AdamJacobMuller 18 hours agorootparentprevWhile it&#x27;s plausible that I, too, will cancel my inreach subscription over this i&#x27;m not so entirely convinced.My InReach (I have an Explorer, not the mini) is an exceedingly rugged bit of kit with an effectively infinite battery life.It is, by no means, a sleek or svelte device like my iPhone but if I fell down on a trail and broke all my fingers (or had severe frostbite or something) I&#x27;m fairly confident I could operate the device with some combination of my teeth, nose and toes.I&#x27;m also fairly sure that it will keep functioning even if I had accidentally dropped it off a cliff, in a blizzard, into an ocean.The mini is basically the same kind of rugged so you know exactly what I mean :)The battery also lasts basically forever.I turned mine on about 48h ago before a trip and it&#x27;s been on ever since and I just checked and the battery is at 86% with 2-minute tracking intervals.Anyway I am still very happy for the starlink service for the 99% of people who don&#x27;t have an InReach, it will definitely save lives, I&#x27;m just not yet ready to ditch my InReach. reply ghaff 19 hours agorootparentprevFor the InReach use case, there&#x27;s still something to be said for a rugged, long battery life, dedicated device (assuming you&#x27;re cautious enough to have one and subscribe to the service). On the other hand, everything is a tradeoff and if your lifestyle is such that having a dedicated inReach is unlikely to ever be a key piece of safety equipment, there&#x27;s a lot to be said for just relying on your phone.There&#x27;s very little bandwidth you need when you&#x27;re in the backcountry, especially given some reasonable pre-download of maps and other information. reply wildzzz 19 hours agorootparentI&#x27;m not a backcountry skier or much of a hiker but if I was, I&#x27;d much rather have a rugged device that can survive much better than an expensive piece of glass. I&#x27;ve damaged phones in the past by them getting bent in my pocket during rigorous activities. If my crumpled body is laying at the bottom of a cliff, I doubt my phone fared much better. A solid body device with a simple interface could be the difference in me being found in a couple hours or a couple weeks.Direct to phone satcom is neat and I can see plenty of applications for it but I know that I wouldn&#x27;t stake my life on it simply due to it being a consumer-grade phone. reply riversflow 17 hours agorootparent100% - They don&#x27;t make phones strong enough to be reliable as a life safety device. As an active person I&#x27;ve broken my pocketed phone several times in incidents that were otherwise unmemorable as they were minor spills.I laughed at that picture of the mountaineer in full Alpine climbing attire, on a tablet.What&#x27;s he doing on it, checking his email? The view behind him isn&#x27;t good enough? reply Johnny555 15 hours agorootparentprevI do a lot of hiking and have never broken my phone in the wilderness (or in town either, I&#x27;ve scratched and cracked the screen, but never enough to make the phone inoperable). I generally travel with someone else, so it&#x27;s even less likely that we&#x27;ll all break our phones at the same time -- if I were hiking by myself, I&#x27;d be a lot more worried about having an injury prevent me from calling for help rather than having a broken phone prevent it.I do carry an InReach when I hike in remote areas but if my phone could make satellite emergency communications, I&#x27;d stop paying $144 a year for the InReach.If InReach dropped the price to $50&#x2F;year, then I&#x27;d consider still subscribing to it. reply rob-olmos 18 hours agorootparentprevI&#x27;m thinking the same.. if I&#x27;ve fallen off a cliff or crashed my bike and broken my leg, possibly in shock too, I want something rugged & simple to activate like a PLB reply jebarker 18 hours agorootparentprevI do trail-running, backpacking and skiing in the Colorado backcountry. I&#x27;d never trust my safety to a cell phone due to the fragility, temperature sensitivity and poor battery life. I carry an inReach and have used the SOS feature. That thing is bullet proof and can tether to my cell phone anyway if I want the convenience of the phone for typing messages etc. reply ghaff 18 hours agorootparentprevI literally just destroyed an iPhone which was in my pocket, in a case, and I apparently smashed it into a rock (which I wasn&#x27;t even really aware of except it was rugged hiking generally). Probably protected my thigh.I do carry a spare battery etc. I suppose I could keep my phone in a rugged case in my pack and use something else for pictures and maps but that&#x27;s sort of getting away from the idea of one device you always have right with you. reply greenie_beans 18 hours agorootparentprevthis is my opinion, too. and i do a good bit of time in the backcountry. reply ClumsyPilot 13 hours agorootparentprev> I&#x27;ve damaged phones in the past by them getting bent in my pocket during rigorous activitiesI got a 4g nokia dumb phone just for this occasion - few days of battery life, sturdy build, good for small trips&#x2F;hikes where you usually have signal or as a backup phone reply michaelmrose 17 hours agorootparentprevSo I went looking for stats to validate how reasonable this concern was and looking at what on average kills folks https:&#x2F;&#x2F;www.projectuntethered.com&#x2F;hiking-statistics&#x2F;#:~:text...I think your concern is warranted as vehicle accidents and falls may call into question the durability of the device in question however based on the mix of accidents and especially the prevalence of medical misadventures its probably a worthwhile feature even if you don&#x27;t opt for something desired for extra durability.Another logical concern is battery life. A huge chunk of non-fatal misadventures are day hikers and the dominant cause is actually dummies wandering off trail as opposed to injury. reply capitainenemo 19 hours agorootparentprevPersonally I just keep a spare cellphone battery in a pocket for emergencies. Would be awesome to have this service. I&#x27;m using a T-Mobile MVNO and last I checked they had no idea if T-Mobile would be extending them the service. reply notatoad 17 hours agorootparentprevthere&#x27;s certainly a use-case for something like an inreach as a dedicated safety device for true backcountry adventures. but there&#x27;s a whole lot of cases that aren&#x27;t that, but you can still be out of cell service and have an urgent need to communicate.for me, even just driving to the next town over, or going for a bike ride that takes me less than two hours from my house, there&#x27;s places where the cell connection cuts out. i&#x27;m not packing an inreach for an hour drive, but it&#x27;s nice to know that if i need it i can count on my cell phone. reply patryn20 19 hours agorootparentprevNot sure if it’s still this way, but Kotzebue AK was the perfect place to test low bandwidth internet. The over the horizon satellite uplink the entire town shared could only allocate 56k speeds to each client and had horrific packet loss.I had to rearchitect an entire file synchronization and uplink system for resilience while sitting in a hotel room in the middle of a blizzard during the shortest days of the year so I could deploy software for clients up there. reply WarOnPrivacy 19 hours agorootparent> The over the horizon satellite uplink the entire town shared could only allocate 56k speeds to each client and had horrific packet loss.I found your uplink. IDK the date of the photo.https:&#x2F;&#x2F;uploads.alaska.org&#x2F;blog&#x2F;Carl-Johnson-Blog&#x2F;Kotzebue&#x2F;_... reply jamiek88 18 hours agorootparentSo weird to see a dish that size almost pointed horizontally! reply jakogut 15 hours agorootparentprevIt&#x27;s actually trivial to simulate a high-latency low bandwidth network on Linux with the traffic control subsystem, one need not switch networks at all. tc qdisc change dev enp1s0 root netem delay 300ms 200ms loss 10% 80%This command delays all packets in and out of the wired interface enp1s0 300ms, +&#x2F;- 200ms, with 10-80% packet loss. reply throwfaraway398 6 hours agorootparentall packets in and outAre you sure about that ? According to man tc, it only works on egress. reply jakogut 43 minutes agorootparentNope, I would definitely trust the man page. reply dataflow 14 hours agorootparentprevWhere&#x27;s the low bandwidth portion of the command? reply notTooFarGone 8 hours agorootparentYou can also limit interfaces with TC to a certain bandwidth. It&#x27;s super easy! reply pmontra 6 hours agorootparentprev> Now we need app developers to log off their fiber-served wifi when writing messenger appsor also any web app.In a Rails app I recently started working on for a customer I saw many controller actions starting with a call to a method called simulate_delay_for_development. I checked the code and when run in development mode it basically sleeps for a random value between 0.1 and 3.0 seconds.I&#x27;m sure that there are gems for that or proxy servers sitting between the browser and the server, but it&#x27;s a cheap and effective way to make every developer experience delays with zero installation costs. reply helb 6 hours agorootparentBrowsers can simulate that without a proxy too: https:&#x2F;&#x2F;firefox-source-docs.mozilla.org&#x2F;devtools-user&#x2F;networ...Chrome can also throttle the CPU power: https:&#x2F;&#x2F;www.wikihow.com&#x2F;Throttle-Your-Browser-for-Testing reply andrew_ 16 hours agorootparentprevI have an InReach Mini that I use when I go offshore fishing, where I&#x27;m out of cell range by 40 miles or more. The Mini is nice, when it works. Most messages I send take 15-20 minutes to send, and the delay is even longer on receiving most of the time. And that&#x27;s in the middle of a large body of water with no obstruction of the sky.I&#x27;ve been waiting with bated breath since the announcement of Starlink in the hopes that it could knock out the three satellite services I use the most: InReach Mini for text comms and location sharing, XM Radio, and XM Weather.I&#x27;m really looking forward to when this becomes available for individuals and not just businesses. Also really looking forward to 12v Starlink equipment and affordable marine plans. reply tjbiddle 11 hours agorootparentprevThe US is fairly unique in that everyone still texts. The rest of the world use apps that need data, like WhatsApp.While SMS would be great for low-bandwidth use cases like this, most people don&#x27;t use it to the point where having contacts accessible with it on the other end would be an issue. reply aembleton 2 hours agorootparentIf they&#x27;re on Whatsapp, then they&#x27;ve got their number. Surely everyone can receive an SMS? If its an emergency, you&#x27;re not going to care what app you&#x27;re using, just so long as you can communicate. reply vikarti 7 hours agorootparentprevAs far as I understood, this is because US carries throws unlimited SMS for free and data is costly. In my country, it&#x27;s possible to get unlimited sms but for additional fee on some carries (other carries just provide N SMS per month) and data prices are rather low even now. reply killingtime74 11 hours agorootparentprevI can take my inreach mini underwater up to 50 meters with the official accessory dive case (I bottom out at 45). Short of making a custom case I can&#x27;t do that with a cell phone and I&#x27;m not sure it&#x27;s rugged enough to take even small waves. reply SergeAx 2 hours agorootparentprevThis messaging app already exists, it called Telegram. I was on a boat around Aeolian Islands and Telegram started working once my phone got Edge (=2G) coverage. Slack and WhatsApp were unable even to connect to server without at least 3G. reply whyenot 18 hours agorootparentprevI was recently in a fairly remote area of the Sierras and my iPhone when totally haywire and then died. Somehow water had gotten inside. That makes me a little concerned about depending on my phone for everything in the backcountry, but maybe what I need is a really good case for it. reply vidarh 18 hours agorootparentOr get a cheap \"armored\" waterproof Android phone. There is a whole thing of Android phones that look like Black and Decker designed ruggedized phones, some of them with extra large batteries. My son has one that is pretty much indestructible. Also ugly enough some other kids cornered him and wanted to \"see it\" a while back and decided it wasn&#x27;t even worth stealing. reply fullspectrumdev 8 hours agorootparentI have one of those - “builder phones” as some call them - for outdoor activities.Cheap, fucking indestructible, and you could probably bludgeon someone to death with it in a pinch.It also has a thermal imaging camera which is surprisingly handy for stuff like “finding where in the garden my cat is hiding at night” or “figuring out what’s overheating” or monitoring the state of my compost bin. reply Grimburger 13 hours agorootparentprevNot cheap, but CAT phones are pretty awesome: https:&#x2F;&#x2F;www.catphones.com&#x2F;en-gb&#x2F; reply ElFitz 18 hours agorootparentprevDepending on the remoteness and risks, I would go for a better case and a backup simpler and more reliable device. reply ra7 18 hours agorootparentThe simpler and more reliable backup device is the Garmin InReach. reply mr_toad 14 hours agorootparentprev> Now we need app developersIf I’m reading the docs correctly the satellites will offer SMS service directly so you won’t need an app, you’ll just need your carrier or roaming provider to support it. reply lxgr 13 hours agorootparentUnfortunately, it&#x27;s incredibly hard to convince an iPhone to actually send an SMS to a specific number, at least if the contact is registered for iMessage... reply mr_toad 9 hours agorootparentIf you have no data connection it will fall back to SMS. reply lxgr 2 hours agorootparentWhat if I know that the recipient doesn’t have a data connection, but I do?This is all incredibly clunky and one of the weakest points of iOS in my view. How can it be so hard to provide a switch that lets me use SMS proactively? reply gumballindie 19 hours agorootparentprevSo basically app developers should build low bandwidth apps - that would be a win for high bandwidth users too. Everything transfers massive amounts of data exhausting even gigabit fibre fast. reply Scoundreller 18 hours agorootparentThere anre also environments that are high-speed but high-cost or capped gb&#x2F;month.I like how I can tell an iPhone that a wifi AP is a “low bandwidth” one so it holds off on many tasks. But you can screw yourself over if you tether a computer, even a Mac. reply ElFitz 18 hours agorootparentTripMode is great in those cases. reply macintux 15 hours agorootparentI’ve found recently that TripMode keeps forgetting the apps I’ve blocked. Haven’t done any investigation, but it’s disconcerting when I check the list and find that iCloud is once again enabled. replyjessriedel 19 hours agoparentprevObviously we shouldn&#x27;t pretend sat phones from Garmin and others haven&#x27;t existed for decades, but Starlink direct to cell is very different. First, as others have mentioned, traditional sat phones requires dedicated hardware with a chonky antenna; this works with normal cellphones, which means order of magnitude higher adoption. Maybe more fundamentally, the satellites that existing sat phones use are in much higher orbits so there is irreducible latency (due to speed of light) and bandwidth costs that LEO Starlink sats will likely crush in the next few years. reply newZWhoDis 9 hours agorootparentOrder of magnitude? Try 5 orders of magnitude.I’d be willing to be the ratio of cellphones to sat phones is > 10,000 to 1 reply Scoundreller 19 hours agoparentprevIt’s too bad you’ll still need a “regular” cellular sub to take advantage of this. If I didn’t, this gets me a lot closer to “cutting” the wireless plan cord.I’m usually in wifi range and being able to have a few kb&#x2F;s of comms is basically the lifeline I need.Most of my cell activities are cached on my phone: podcasts, maps, some increasingly out of date weather.Would be even cooler if it could “broadcast” some regular stuff like news and traffic updates (dunno how that could integrate with Waze…)The first kb&#x2F;s gets me a loooot of value and each additional is less useful than the last. Data is very much diminishing returns. reply lxgr 19 hours agorootparent> It’s too bad you’ll still need a “regular” cellular sub to take advantage of this. For the emergency use case: Would it even be legal to require a subscription for 911 calls?As far as I know, these are possible even without a SIM card in the US and most other countries.> The first kb&#x2F;s gets me a loooot of value and each additional is less useful than the last. Data is very much diminishing returns.And it’s arguably priced accordingly: The difference between metered plans and unlimited data is pretty small these days in my observation. reply Scoundreller 19 hours agorootparentBy lifeline I don’t mean 9-1-1, but rather some basic barebones comms.> The difference between metered plans and unlimited data is pretty small these days in my observation.That’s if you have a competitive environment. In Canada, the cellular providers are the fixed-line internet providers and very much don’t want to tank one for the other.(But maybe Freedom Mobile, without much of a physical wireline footprint, will pull a t-mobile and go all-in on a 5G wireless home internet plan… we can pray) reply lxgr 19 hours agorootparent> In Canada [...]Oh, yeah, all of these considerations only apply to a somewhat functioning&#x2F;competitive market, unfortunately.I have my fingers crossed for you! I&#x27;ve had friends of mine live in Canada for a while – it sounds as bad as (or even worse than) what was going on in Germany in the 2000s, when mobile operators had spent ridiculous sums on 3G licenses and almost ruined themselves in the process financially and as a result just sat out on infrastructure investments for the next decade or so. reply slashdev 19 hours agorootparentprevLikewise, this would be enough to replace my cell plan. I don’t need high bandwidth stuff, just text communications, PagerDuty, gmail. The rest I can do over Wi-Fi. reply arecurrence 18 hours agorootparentYou can get 1 year global plans from esimdb.com pretty affordably for this use case right now. reply slashdev 16 hours agorootparentThanks, I’ll check them out reply lxgr 18 hours agorootparentprevGiven the price per bit per second per square meter, I&#x27;d be surprised if this will be more economical for operators to provide in anything but the most rural areas. reply paulddraper 15 hours agorootparentprevNo Maps? reply Scoundreller 11 hours agorootparentMaps can be downloaded offline and directions calculated locally. Only really need updates for traffic (which could be broadcast, which I think some old gps receivers had) reply tpmx 19 hours agorootparentprevI suppose they need to piggyback on each mobile operator&#x27;s licensed frequency bands, per country&#x2F;region. reply vikarti 6 hours agorootparentThere&#x27;s other potential advantage (or disadvantage depending on how you view it). Some countries like India don&#x27;t like sat phones on their territory. Some countries like Russia are ok with them but require local connection to terrestial networks and local licenses. Some countries are in territorial disputes. What if SpaceX or other such company decide (or would be \"gently asked to\") it could ignore local regulations in such country? What if it would be done for good? Possible example: somebody lobbies ITU(via some kind of \"emergency license for humanitarian purposes only\") to allow SpaceX to allow SpaceX to serve Gaza for free with limits and USA is ok with it. Israel is against it but what they could do? Jam Starlink? What if they also use it? What if 10 years in future same thing is done to North Korea(it could be even more legal - as far as I understood, both Koreas claims they are only legitimate goverment of Korea so SK could issue formal license)? reply Scoundreller 19 hours agorootparentprevLooking forward to a future Starlink+Apple&#x2F;Google collab.Dunno what frequency this is running at, but if it’s in the 10s of GHz, I’m assuming licensing doesn’t get tooooo pricey given how problematic it is on land-to-land links. reply Reason077 18 hours agorootparentIt works with existing 4G&#x2F;LTE phones, so it will be using the standard 4G&#x2F;LTE bands, which run up to 2.6 Ghz.Presumably that&#x27;s why SpaceX needs to ride on existing mobile operators: they already own LTE spectrum and can allocate a chunk of it for satellite services. It would be a lot of work (and cost) for SpaceX to go out and buy LTE spectrum in every country they want to operate in. reply usrusr 2 hours agorootparentSacrificing a chunk of that precious spectrum is huge though. Is LTE flexible enough to run some form of on-demand TDM between multiple base stations on top of it? Can it operate smaller cells on the same channels within the range of the larger cell, forcing the smaller cell to make do with other parts of the spectrum while the larger calls dibs?Afaik older cellular protocols were relying on zero overlap between base stations serving the same frequencies, leading to a nice coloring problem that would seriously suffer if someone tried to fit in LEO cells. reply Reason077 1 hour agorootparentI&#x27;m no LTE expert, but I&#x27;m pretty sure that it handles overlap: you can run LTE diagnostic apps on Android that will display all the visible base stations - often many are visible, sometimes 3 or more on the same band. Your phone looks at what&#x27;s available and picks a combination with the best signal strength (sometimes it will connect on 2 or 3 different bands simultaneously with carrier aggregation).But even then, most carriers have many bands&#x2F;channels (EARFCNs) available - and presumably only a small slice of bandwidth is needed for this service considering it&#x27;s (initially) only for text messages. Finding 5 Mhz on one of the higher LTE frequencies wouldn&#x27;t be so hard for many carriers, even if it does need an exclusive channel. reply tpmx 19 hours agorootparentprevApple&#x2F;Google don&#x27;t hold any RF spectrum rights worldwide...This is presumably about 4G&#x2F;LTE, so mostly between 0.4-2.5 GHz or so.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LTE_frequency_bands reply lxgr 13 hours agorootparentI wouldn&#x27;t be surprised if Apple were to end up buying Globalstar, which would get them access to valuable globally available L-band spectrum.They have already invested hundreds of millions into Globalstar&#x27;s ground station hardware [1] and future satellite launches [2].[1] https:&#x2F;&#x2F;www.apple.com&#x2F;newsroom&#x2F;2022&#x2F;11&#x2F;emergency-sos-via-sat...[2] https:&#x2F;&#x2F;spacenews.com&#x2F;apple-loans-globalstar-252-million-for... reply Scoundreller 19 hours agorootparentprev> Apple&#x2F;Google don&#x27;t hold any RF spectrum rights worldwide...yet. Apple (and android baseband suppliers, “Google” may be the wrong name to mention here), have the ability to take relatively worthless spectrum and make it widely useful in a way nobody else can.I wonder how spectrum allocation works for C-Band satellite broadcasters that just blast continents with their signals. Grandfathered? reply tpmx 18 hours agorootparentThose several-GHz bands don&#x27;t really work indoors. reply Scoundreller 18 hours agorootparentMost satellite-y things don’t and Starlink’s direct to cell won’t either.Hence why the spectrum should be pretty cheap (along with its incredible susceptibility to obstructions… which is less of an issue when you’re going roughly “up” without pesky considerations like curvature of the earth)And you do get a ton of gain with a small antenna at those high frequencies. reply tpmx 18 hours agorootparent> and Starlink’s direct to cell won’t eitherI could see it kinda working, at low frequencies. They are not that far away and there&#x27;s not many things blocking the signal besides your roof. reply Scoundreller 17 hours agorootparentMe too, but at slower data rates. At 550km above, that’s still a big signal loss by inverse square law. Problem with slow data rates is that they clog up the channels. reply tpmx 17 hours agorootparentThe inverse square law effect can be remedied using similar tech as in the Starlink consumer antennas. You aim the signal to where it&#x27;s consumed.> Problem with slow data rates is that they clog up the channels.Yes, we must protect the tubes! :) reply Scoundreller 10 hours agorootparentPhased arrays work without having to repoint, but they don&#x27;t overcome lack of incidence (insolation?)(e.g. we can&#x27;t build a solar panel that works perpendicular to the sun (or nearly perpendicular) using phased array technology because there just isn&#x27;t much solar radiation hitting the \"dish\" in the first place) replydotnet00 18 hours agorootparentprevSpaceX already works with Google, where Google allows Starlink to use its datacenters&#x27; network connectivity for downlink, while Google gets to use Starlink for data transfer. reply inemesitaffia 18 hours agorootparentprevSpaceX has applied to test the service at an Apple office reply carabiner 19 hours agorootparentprevYou&#x27;d expect T-Mobile&#x2F;starlink to provide this service for free? reply Scoundreller 19 hours agorootparentNo, I want to sign up for it without bundling it with a local Canadian oligopolist’s other services. reply valianteffort 19 hours agoparentprevThe difference here is you don&#x27;t need a dedicated device or service, you can just use your existing cell phone. As Starlink is only providing the backhaul and cell carriers their spectrum, service will improve as the constellation grows not whenever the carriers feel like investing in it. reply dharma1 3 hours agoparentprevYou can still access a lot of stuff via just SMS - could setup an SMS ChatGPT service for yourself and use it via this in the middle of nowhere reply cronix 14 hours agoparentprev> This is for very low bandwidth text communications when you&#x27;re out in the country and can see the sky.From the graphic in the article:> Text: 2024> Voice and Data: 2025> IOT: 2025 reply KRAKRISMOTT 11 hours agoparentprevThe gain on those antennas must be insane, any idea how they work? There are millions of devices down there (from the angular resolution perspective of the satellite). reply spandextwins 17 hours agoparentprevThat’s not what the site says. It’s different than what’s available now. reply grecy 19 hours agoparentprev> Stuff like this has existed from companies like garmin for some time.No, this is entirely different from what Garmin and others sell.Those devices require dedicated hardware (and a subscription plan) to talk to satellites. Also you can only send and receive text messages. (no voice, extremely limited data (like weather reports))What SpaceX are doing uses a completely normal phone, with a completely normal phone plan. It&#x27;s text for now, but voice and data are coming. reply lxgr 18 hours agorootparent> It&#x27;s text for nowText is announced for 2024. And personally, I&#x27;d be really surprised if that actually works out for unmodified phones sold today. I&#x27;ve written more about that here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37848212 reply ec109685 16 hours agoparentprevWhy is it limited to only very low bandwidth applications? reply dboreham 10 hours agorootparentBecause Shannon. reply colordrops 19 hours agoparentprevThe starlink website directly says \"texting, calling, and browsing\" reply blhack 19 hours agorootparentI believe this is addressed in the video that I linked. There are very good compression algorithms to allow voice, and \"browsing\" means something akin to slow dialup.This is not something that could, for instance, replace your cell phone carrier.In the video at 21:00 Elon clarifies: 2-4 megabits per cell zone. reply lawlessone 19 hours agorootparent> and \"browsing\" means something akin to slow dialup.So it will be faster than my carrier.. reply valianteffort 19 hours agorootparentprevThis is a service being provided by your carrier. reply blhack 19 hours agorootparentSorry if that was confusing. I mean that for instance: tmobile will be adding this to their coverage map, but they&#x27;re not getting rid of the towers, and the primary way your phone is communicating with the world is not going to be via starlink satellites. reply Retric 19 hours agorootparentprevI occasionally get kicked down to 128 kbps for a few hours at the end of a month and a surprisingly large fraction of the internet still works.They are targeting voice which can go really low, but a moderately optimistic ~100kps is vastly better than 0. Much below that and the number of people using it is going to drop near 0. reply starik36 19 hours agorootparentYeah, it says so in my AT&T contract as well. And I was concerned when I first signed up. But I haven&#x27;t ever actually seen it happen. reply Retric 19 hours agorootparentAT&T actually enforces it for tethering. If I really need something I can still use my phone, but it’s convenient to leave the phone where it gets reception and then use the tablet nearby. reply vorpalhex 17 hours agorootparentprevIf I can get a plain text weather report, emergency notification or email then that is HUGE.The difference between no communication and \"take 5 minutes to get 1kb of text\" represents a huge, huge jump. reply Scoundreller 19 hours agorootparentprev> browsing\" means something akin to slow dialup.I mean, I fire up and use lynx from time to time for a couple newspapers and magazine. Beyond evading some paywalls, it also presents it the way I want it: a wall of text. “Slow dialup” to me is 2.4kbps.The HN crowd could get a lot done over a console. reply ada1981 16 hours agoparentprevWhat about the voice and data they have planned for 2025? reply micromacrofoot 14 hours agorootparentnever trust a 2 year estimate from elon musk reply j45 13 hours agoparentprevIt’s still invaluable at low bandwidth text up there.Satellite data to run infrastructure (even cc processing for cards) where there is zero connectivity or power for hundreds of miles will likely become at least one order of magnitude more accessible price wise. reply drunner 20 hours agoprevPlease disrupt the personal satellite beacon market. Currently the only options are proprietary devices that cost several hundred dollars AND a subscription plan that will run you $12 a month or more. reply stetrain 20 hours agoparentNew iPhones include satellite SOS and location features. The monthly cost has not been announced yet, all phones with this feature are still in the 2-year free trial period.https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT213426https:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;iphone&#x2F;send-your-location-vi... reply frederikvs 18 hours agorootparentThere&#x27;s a recent article about a climber who had to use this iPhone SOS feature. Turns out that actually getting in contact with emergency services is not easy - even though the satellite communications worked perfectly.There was a lot of back and forth over the system, but it did not help at all. The thing that saved her was one 40 character message to a friend. Because apparently you get one of those, and no replies...https:&#x2F;&#x2F;www.climbing.com&#x2F;news&#x2F;iphone-sos-button-saves-injure... reply dotnet00 18 hours agorootparentThere was another story where the SOS feature kicked in automatically and Apple was able to dispatch emergency services:https:&#x2F;&#x2F;www.cnet.com&#x2F;tech&#x2F;mobile&#x2F;iphone-14-emergency-sos-fac... reply oostevo 13 hours agorootparentprevMy understanding is that most[1] other satellite devices use a centralized dispatch center who have experience with backcountry emergencies.Speculating obviously, but that article makes it sound like Apple might have tried do something else and that whatever they came up with is more equipped to deal with frontcountry issues.Sounds like I should keep packing my inReach.[1] https:&#x2F;&#x2F;www.iercc.com&#x2F;en-US&#x2F;supported-devices&#x2F; reply oldbbsnickname 3 hours agorootparent2 is 1, 1 is none.If it were my life on the line, I&#x27;d carry 2 different PLBs: probably a Garmin and an inReach.Disclaimer: Ex Trimble Nav Ltd. radio group here. :] reply oldbbsnickname 3 hours agorootparentprevDon&#x27;t expect it to work anytime soon or to supplant EPIRBs.Even E911 locating in the US just doesn&#x27;t work at all with nonzero and unknown combinations of phones, carriers, and jurisdictions. US LEOs have almost universal, real-time locating ability from N km to sub 1 m accuracy if it&#x27;s in range of a single tower of any phone without a warrant. If a phone can send an SOS to a comm satellite, while there&#x27;s a recent good fix from 3+ GNSS satellites, then that&#x27;s useful.The risk to avoid will be over-reliance on a consumer grade cell phone as a substitute for the ruggedized and proven EPIRB system. reply hcurtiss 18 hours agorootparentprevMy wife and I and our two kids do a fair amount of back-country white water rafting. After arriving at a very remote take-out with no car and no cell service after a five day float (and running low on food and water), we went ahead and bought an actual satellite phone. It’s a game changer. Cost about $400 used and we have it refreshing quarterly on BlueCosmo for $99. It’s awesome, and cheap insurance relative to the risk. reply pnpnp 17 hours agorootparent$99 quarterly sounds like a good deal - was this with Iridium? That&#x27;s unfortunately the only network that works well for my use-case.I currently pay for an inReach Messenger, and use it on a weekly basis. The $12&#x2F;mo base cost is peanuts for what it actually provides me. reply hcurtiss 14 hours agorootparentNo, it&#x27;s Inmarsat (IsatPhone 2). reply pnpnp 11 hours agorootparentAh, that’s too bad. I think (please correct if I’m wrong) those have some trouble in canyons at higher latitudes. The nice thing about Iridium is if you wait a few minutes, a bird will usually show up overhead. It’s nice for SAR missions we help with in the mountains. reply hcurtiss 19 minutes agorootparentI suspect you&#x27;re right about the advantages of Iridium. All I can say is that we live in Oregon and I&#x27;ve been able to get out of canyons pretty well. I&#x27;ve used it on the John Day, Deschutes and Grande Ronde, mostly to coordinate with shuttles or check in back home. I cannot speak to other geographies. The profound advantages of two-way instant communication in an emergency would justify hiking uphill a ways too. I&#x27;m rarely surrounded by sheer cliffs. But I&#x27;m sure there are circumstances where Iridium -- or Starlink! -- would work better. We bought a v2 standard Starlink setup for tailgating and camping and it&#x27;s truly awesome. That technology in phones is a game changer. In truth, my wife and I have iPhone 14 Pro and 15 Pro, respectively. If the Inmarsat sat phone doesn&#x27;t work, you can be sure we&#x27;d hit the button on the iPhones, which makes for a nice backup as I believe they use the Globalstar LEO satellites. replyghaff 18 hours agorootparentprevSounds like the phone SOS service doesn&#x27;t really have its act together yet based on that sample size of one. reply mips_avatar 16 hours agorootparentprevI don&#x27;t understand why Apple is adding satellite SOS to iphones but providing dangerously poor support for people in emergencies. There&#x27;s a lot of situations in the backcountry where an injured person will survive 6 hours, but freeze to death after 10. Thank goodness for the emergency contact feature and that these climbers had a friend with enough skill to dispatch SAR. If Apple isn&#x27;t careful they&#x27;re going to have a front page story detailing how someone died an avoidable death because they dispatched an ambulance instead of search and rescue. reply Xeamek 19 hours agorootparentprevCan probably expect Android devices to follow soonhttps:&#x2F;&#x2F;semiconductor.samsung.com&#x2F;news-events&#x2F;news&#x2F;samsung-e... reply lxgr 19 hours agorootparentIt seems like from a purely technical point of view, Qualcomm got the best deal in this space (i.e. one with Iridium, which is currently the only provider with 100% global coverage): https:&#x2F;&#x2F;www.qualcomm.com&#x2F;news&#x2F;releases&#x2F;2023&#x2F;01&#x2F;qualcomm-intr... reply drunner 20 hours agorootparentprevSOS only being a key point I missed in my first post. Yes, thankfully they are launching it, but SOS only is a drag. reply coder543 20 hours agorootparentIt’s not SOS only. You can also update your location in the Find My app, so your friends&#x2F;family can keep track of you on a backpacking trip.With iPhone 15, they also introduced the ability to call for roadside assistance from AAA via satellite too. (I’m not sure if this is also available on 14 now or not.) reply kccqzy 19 hours agorootparentAre you sure Find My uses satellite connectivity? I don&#x27;t think so. Apple says this https:&#x2F;&#x2F;www.apple.com&#x2F;icloud&#x2F;find-my&#x2F;> If your missing device can’t connect to the internet or has little to no battery life, the Find My app can still help you track it down using the Find My network — hundreds of millions of iPhone, iPad, and Mac devices around the world.So this isn&#x27;t going to help you in the wilderness. reply robbiet480 19 hours agorootparentYes, you can update your Find My location via satellite https:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;iphone&#x2F;send-your-location-vi... reply virtuallynathan 19 hours agorootparentprevIt does, you can update it via Satellite. I&#x27;ve done it... (it&#x27;s a manually triggered operation) reply pests 19 hours agorootparentprevhttps:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;iphone&#x2F;send-your-location-vi...The passage you quoted is talking about the iDevice-to-iDevice communication that can happen behind the scenes allowing you to find a lost phone in the wilderness if someone else so happens to walk by the phone. reply freeAgent 19 hours agorootparentprev14s got it too. Neat! https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT213886 reply stetrain 20 hours agorootparentprevYeah, they are slowly rolling out new features like this year they added roadside assistance requests.Having a limited number of plain text message requests would be nice as well, maybe there will be more options once they add paid tiers. reply crossroadsguy 13 hours agorootparentprevWhenever I hear of this feature on an iPhone I think of the stellar iPhone battery life while it has probably generously been used for photos and location services etc. reply JumpCrisscross 17 hours agoparentprev> currently the only options are proprietary devices that cost several hundred dollars AND a subscription plan that will run you $12 a month or moreConsider a 406 MHz PLB [1][2][3]. Several hundred dollars. But no subscription fee.They&#x27;re terribly marketed, a vacuum Garmin et al happily fill. And you can&#x27;t send text messages. But as an emergency beacon, they are best in class. (Garmin transmits atGarmin transmits atfeaturing inter-satellite message routingI think Iridium can handle four calls at a time. In any case, you don&#x27;t want to be reduced by Siberia from Alaska.> use exactly as much transmit power as they need toGarmins have a ceiling. Terrain attenuates. There are more places you will be alone with a Garmin than a 406 MHz PLB.> Iridium modems get instant feedback on whether their transmission has made it through and can retransmit if required406 MHz does this [1]. Would love to hear anecdotes, ideally from SAR, where this saved a life versus providing comfort.[1] https:&#x2F;&#x2F;www.acrartex.com&#x2F;products&#x2F;resqlink-view-rls-personal... reply lxgr 2 hours agorootparent> I think Iridium can handle four calls at a time.It supports over a thousand simultaneous calls per satellite! And that’s voice calls; text messages like those used by InReach need much less resources still.> Garmins have a ceiling. Terrain attenuates. There are more places you will be alone with a Garmin than a 406 MHz PLB.What “ceiling”? As long as you have line-of-sight, the transmit power is enough to reach the satellite, and given polar orbits, you almost always do if you can see a bit of sky.If you don’t have line-of-sight, COSPAS-SARSAT won’t work either, would it?I assume the higher transmit power there is mostly to enable reaching satellites farther out (like the GPS and Galileo satellites, which are in MEO).> 406 MHz does this […]In some regions only, I believe, and with some beacons. It is a very important development though! reply lxgr 19 hours agoparentprevIt’s more like $200-300 for the device and $5-8 per month for service these days.Given the value in an emergency, I’d consider that fair!And if you really only care about calling emergency services in the backcountry or at sea, you can always get a PLB (which have no recurring fees at all). reply oldbbsnickname 3 hours agorootparentEPIRB &#x2F; satellite messenger risk management decision tree:What&#x27;s your life worth to you?How independently resourceful are you?Is your name Bear Grylls?** Even he flubbed a parachuting emergency and nearly bought the farm. In fairness, so did my paratrooper grandfather as he busted 2 knees and his neck... he had to wear a neck support most of his life.---It&#x27;s vital that PLBs be correctly registered and continually updated (2 years AND at every details change) with reliable emergency contacts who are always responsive. For multiple reasons, I would always call the one or more of PLB emergency contacts to let them know you&#x27;re heading beyond cell service. US EPIRB operators register them here: https:&#x2F;&#x2F;beaconregistration.noaa.gov&#x2F;RGDB&#x2F;index reply grecy 18 hours agorootparentprev> And if you really only care about calling emergency services in the backcountry or at sea, you can always get a PLB (which have no recurring fees at all). In the wilderness of Yukon and Alaksa we found we didn&#x27;t need to call emergency services, but it was very handy to contact friends.\"I&#x27;m very stuck, but fine, come get me\".\"I shot a moose, it would be great if you&#x27;d come and help me quarter it.\"\"We&#x27;re perfectly fine, but delayed a couple of days.\"Things like that are what we used our gen 1 spot for, and it was great. reply ghaff 18 hours agorootparentEven in a serious situation, there&#x27;s value in being able to coordinate with would-be rescuers. I&#x27;m in a bit of a pickle with a twisted ankle and I&#x27;m really going to have trouble walking all the way out by myself but I have food and water is a different situation from I&#x27;ve fallen 40 feet and conscious but have a broken leg and am getting really cold. reply lxgr 18 hours agorootparentThat&#x27;s very true.Importantly, with most current PLBs you don&#x27;t actually see if your emergency call has been received at all, which can make an important difference for survival (i.e. it informs the decision whether it&#x27;s best to stay put and try to hold out, or whether getting to higher ground with clearer sky is essential).Fortunately, at least that part is changing: Cospas-Sarsat (the service listening for PLB emergency calls) can now use Galileo satellites as a return channel to send an acknowledgement to the newest PLBs in some regions [1].It doesn&#x27;t address the \"type of emergency\" concern, though – not everything requires a helicopter.[1] https:&#x2F;&#x2F;www.euspa.europa.eu&#x2F;newsroom&#x2F;news&#x2F;first-galileo-retu... reply sneak 19 hours agorootparentprevPLBs are also several hundred dollars and have an expiration date. reply nroets 19 hours agorootparentprevThe most valuable use case is not emergencies, search and rescue.It&#x27;s tracking vehicles (big and small) in third world countries with the aim of support, crime detection, asset recovery and law enforcement. reply lxgr 19 hours agorootparentWhy third world countries?Terrestrial cell coverage is a function of population density much more than anything. In fact, I&#x27;d expect rural areas in the US and Candada to benefit from this just as much, if not more. reply mtreis86 3 hours agoparentprevIts more expensive up front, in time cash and effort, but amateur radio aprs beacons are free to use for amateur radio operators and there are enough satellites with repeaters to make it a viable option in terms of it working anywhere. reply oldbbsnickname 4 hours agoparentprevYou&#x27;re using the wrong product. Spot basic beaconing is $2.50&#x2F;month.If you also need a PLB, don&#x27;t cheap out on a safety product.But if you&#x27;re wanting reliable Gigabit unlimited data globally forensure a regulatory climate that Elon will loatheWhy is that a data point and why are you convinced it will be true? I get that people somehow feel \"betrayed\" by the man, but this presenting this type of analysis taints the rest of your outlook.Anyways.. he has the monopoly, he can set whatever price he wants. Common carrier doesn&#x27;t mean you have to give it away at some imputed \"commodity\" price. I&#x27;m sure he&#x27;ll find a way to make it work. reply mr_toad 14 hours agoparentprevSpaceX already has to deal with FAA, ITAR DoD, NASA, FCC - I imagine they’re pretty familiar with bureaucracy. reply lxgr 18 hours agoparentprevThat&#x27;s an interesting point of view – is the same true for MVNOs today? That seems like a similar situation. reply vel0city 18 hours agorootparentYes, it&#x27;s essentially these regulations that make MVNOs possible. reply mlindner 15 hours agoparentprevI find your strange glee about this rather off-putting. It’s like you’re actively interested in harming this really valuable new type of service in any way possible.Given that, I find it hard to take at face value anything you’re saying and that it’s much more likely that you’re trying to mislead people.Also space is even less of a “limited resource” than completely unpopulated areas of the Earth is or the entire ocean’s surface is. It’s three dimensional rather than two dimensional. Any single orbital altitude has more surface area than the entire earth. reply Cogito 15 hours agorootparentNot quite your main point (which I agree with) but comparing surface area of orbits to the surface of the earth doesn&#x27;t really help understand the carrying capacity of orbits.There are so many constraints on objects in orbit, the degrees of freedom so limited, that carrying capacity is much smaller than you might suspect (though probably larger than our earth-bound intuition).Just for starters, each item in orbit traces out a path (an orbit!) that can not intersect with the path of any other object, without carefully considering phasing to make sure there are no collisions.We keep items separated by kms (hopefully!) because there is too much variation and uncertainty in orbits.You can use different altitude shells to fit more items in, but they take longer to orbit and increase latency, so you have to be able to deal with that.Based on degrees of freedom, orbits are far closer to 2 dimensional than 3 dimensional. reply mlindner 15 hours agorootparentI was aware of all the points you made here before writing your post but hopefully I can help allay your concerns.The Starlink constellation has already been described as being passively de-conflicted, meaning that, as designed, no Starlink satellite had to maneuver around any other Starlink satellite. The positional accuracy of the Starlink satellites is known by SpaceX to the precision of meters rather than kilometers. I’d need to dig it up the source again but Starlink satellites pass within kilometers of each other daily. Starlink already has over 1000 satellites at several of its altitudes.While yes it’s true they have to avoid space debris with a wide berth I don’t really include that in the argument as that is a true statement no matter how many or how few satellites are in any given orbit.It’s more a matter of poor control and poor altitude maintenance of other satellites. That’s a matter of regulation rather than a matter of an actually limited resource. For example Starlink currently uses 10km or 7km gaps between its shells but they vary in altitude significantly less than that and could be closer if allowed to be. reply Cogito 14 hours agorootparentI agreee that SpaceX is unlikely to run into any issues with the number of satellites they are putting up, or coordinating those satellites.However! It&#x27;s disengenous to say land is 2d and orbits are 3d so there is more space in space. That> space is even less of a “limited resource” than completely unpopulated areas of the EarthConsider: how many Starlink constellations could reasonably be deployed in low earth orbit? Probably less than 1000, but maybe 10000-100000 (that would be a lot of satellites, but let&#x27;s be generous).Now how many Starlink constellations could be deployed in unpopulated areas of the Earth? Putting aside that they&#x27;d be useless, you could fit literally millions of constellations next to each other.Space is big, but heavily constrained. One of the reasons something like an orbital ring would be so cool if we could get it to work - tons of space that is not constrained by orbital mechanics the same way free flying stations would be. reply altairprime 11 hours agorootparentprevI used to be a DSL CLEC. I know from personal experience what kind of conversations, and regulatory interventions, it takes to get a monopoly incumbent common carrier (such as US West, or SpaceX) to lease their network at fair rates and to provide reasonable service for those rates. I am gleeful because the groundwork we laid down in the CLEC days continues to pay off decades later. That was a lot of very hard work.I am all for innovating in carrier networks, and I’m all for charging for access through those networks — so in that, my motives and Starlink’s align! And since Starlink makes the same dollars per user whether the user is T-Mobile or a Local MVNO, I don’t see how innovation in their satellite network suffers in any way. reply runeks 7 hours agorootparentWait... if your motives and those of Starlink are aligned, why would we even need CLEC regulation?Surely that regulation forces the carrier to do something it otherwise wouldn&#x27;t have (or it would be pointless), thereby suggesting a misalignment of incentives. reply lxgr 13 hours agorootparentprev> Also space is even less of a “limited resource” than completely unpopulated areas of the Earth is or the entire ocean’s surface is.The scarce resource here is globally-available L-band radio spectrum (potentially spatially multiplexed, if you have steerable beams on both ends, or only one satellite in view at a time and are using spot beams).> It’s three dimensional rather than two dimensional. Any single orbital altitude has more surface area than the entire earth.Space is three-dimensional, but lines-of-sight are two-dimensional. Even if you have steerable beams on both ends (which aren&#x27;t that precise either, unless you&#x27;re using laser beams), there&#x27;s only so much non-overlapping sky above. reply zie 18 hours agoparentprevThis might be what causes him to sell out and make it someone else&#x27;s problem. Just Starlink, not SpaceX obviously. reply mcpackieh 18 hours agoparentprev> Space is a limited resourceTechnically true, but even with the full planned ~40k Starlink constellation we&#x27;d be nowhere close to the limit. reply lxgr 13 hours agorootparentThere&#x27;s definitely a limit: Frequencies and orbital separation&#x2F;steradians of aperture.If you&#x27;re putting a satellite right next to one of Starlink&#x27;s, using the same frequency, how&#x27;d you communicate with it without the two interfering with each other? reply corbezzoli 10 hours agorootparent> without the two interferingI’m no radio expert but I think this was solved when they managed to handle a hundred thousand connected cellphones in a single stadium. reply lxgr 2 hours agorootparentThat works by reducing the transmit power significantly and having many low-power cells all over the stadium.In other words, it depends on some base stations being significantly farther away from a given device than others. That’s not the case for satellites. reply34679 17 hours agoprev\"wherever you may be on land, lakes, or coastal waters\"I wonder why the limitation to coastal waters? They&#x27;ve been cracking down on offshore sailors using Starlink with the RV&#x2F;Roaming plan, too. By all accounts it worked fine, but SpaceX wants to charge significantly more for an offshore plan.It certainly can&#x27;t be a congestion issue. reply jdminhbg 17 hours agoparent> It certainly can&#x27;t be a congestion issue.There aren&#x27;t any ground stations in the open ocean, so it all has to be routed between satellites to hop to one that has a connection to one. So it is a congestion issue. reply wmf 15 hours agorootparentDirect-to-phone is so slow that it can&#x27;t congest the lasers. reply lxgr 13 hours agorootparentIt might well be a \"dumb pipe\" implementation (i.e. no regeneration and smart inter-satellite routing on the satellites), although Starlink does significantly mention an \"onboard eNodeB modem\", which sounds like it should be possible to forward that over the laser links. reply dvdbloc 8 hours agorootparentHave they incorporated the laser links into prod on their sats yet? I thought that they were launching sats with them yet hadn’t successfully routed traffic yet through them in prod which is why they have a limitation to near the coast. reply lxgr 13 hours agoparentprevI think it must be mostly a spectrum&#x2F;licensing concern:Neither T-Mobile nor Starlink own global frequencies in a suitable frequency band to offer offshore services.That&#x27;s one of the big benefits e.g. Apple gets out of the box for going with Globalstar, and Qualcomm for partnering with Iridium: They each own around 10 MHz of prime (i.e. L-band) global spectrum. reply manquer 11 hours agorootparentThere is no global spectrum ownership, most countries regard radio waves as a national resource. ITU and related bodies only manage the standards not the allocation or ownership to operators.What Globalstar, Iridium et al have agreements are agreements with wide array of countries but not all, for example India only allows Innmersat based devices , North Korea allows no one and so on.OST does not cover radio frequency, only outer space( which is not well defined) ownership and activities, while the Bogota declaration failed to make progress for the equatorial countries at the UN, there are no major dispute on who owns the spectrum in the space above their national territories, most agree it is a national resource. Also to note there are many countries who are not signatories and&#x2F;or not ratified the OST mostly in Africa. reply lxgr 10 hours agorootparentThank you for this context! Radio spectrum being considered a national resource actually makes a lot of sense. It also explains why Starlink&#x27;s (residential) geographic availability map looks the way it does (i.e. corresponding to political borders).Do you know if this is different for e.g. aviation applications or international waters? I also wonder whether Starlink (and other non-GEO operators) actually stop transmitting over countries where they don&#x27;t have a license for their spectrum.Nevertheless: Practically, Inmarsat, Globalstar, and Iridium do hold exactly these crucial L-band spectrum rights in almost all countries; Starlink doesn&#x27;t yet. reply 1970-01-01 12 hours agorootparentprevThis is a fascinating take. Cell phone adoption could push SpaceX into establishing a global spectrum committee. Let&#x27;s hope they remember to register under the .INT domain reply lxgr 12 hours agorootparentWell, that global spectrum committee already exists [1], .int domain and all :)But somebody recently mentioned here that in order to provide satellite services in a given country, you still need a local license...?I&#x27;m not sure how existing mobile satellite service providers fit in here – do Inmarsat, Iridium etc. just have a license in (almost) all countries worldwide?[1] https:&#x2F;&#x2F;www.itu.int&#x2F; reply 1970-01-01 9 hours agorootparentThat&#x27;s news to me! Does ITU have any ability to mandate laws for the physical spectrum? If not, a global communications committee would still be needed. At minimum, they would need the ability to control the 5G blocks of every country participating in the SAT to cell service. reply lxgr 1 hour agorootparentLike most of these international committees, I believe they mostly facilitate agreements between sovereign states; I don&#x27;t believe they have any legislative power themselves.Maybe an analogy would be ICAO&#x27;s (another \"specialized agency of the UN\") \"Freedoms of the Air\" [1] – they define the terminology, but it&#x27;s still up to individual (or blocs of) nation states to actually grant them to each other, ratify recommendations etc.[1] https:&#x2F;&#x2F;www.icao.int&#x2F;pages&#x2F;freedomsair.aspx reply manquer 11 hours agorootparentprevNot all but a lot. It is a mixed bag though, Iridium and Thuraya are illegal in India but Inmarsat has a license, so it kind of depends really.You need a local license because radio frequency is considered a national resource, so each country owns the radio space about its land and they get to govern it. reply lxgr 10 hours agorootparentThat makes sense. So the ITU has more of a role of coordination than of actual assignment, I suppose?Practically, satellites won&#x27;t switch frequencies every time their spot beam footprints cross national boundaries, so I suppose it&#x27;s more of a matter of allowing&#x2F;not allowing service in a given country (as determined by either the mobile or the satellite?). replyrkangel 16 hours agoparentprevI think it&#x27;s a spectrum cost issue or a coordination issue. LTE spectrum is eye wateringly expensive, but maybe more affordable places where it&#x27;s not possible to put a mast!It&#x27;s either that, or whatever the logistics are around the cell boundaries. reply ec109685 16 hours agorootparentThey’re leveraging the carrier’s existing spectrum. reply plussed_reader 17 hours agoparentprev&#x27;Just good business&#x27;. reply 228 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Starlink, a division of SpaceX, is launching a Direct to Cell feature that will provide global LTE phones with uninterrupted access to text, voice, and data services.",
      "The new technology, operating as space-based cellphone towers, allows connectivity in remote locations and removes dead zones, without necessitating modifications to the existing hardware or apps.",
      "Leveraging SpaceX's know-how in rocket manufacturing and launching, Starlink aims to deploy these cell-service-supporting satellites in large numbers, with global cellular providers sharing network access in partnering nations."
    ],
    "commentSummary": [
      "The discussions range from satellite communication benefits in remote areas, challenges of using smartphones in extreme temperatures, and messaging apps in low-bandwidth situations, to the merits of dedicated devices over phones for safety in the wilderness.",
      "Key focuses are the potential benefits of Starlink Direct to Cell and Starlink in remote areas, collaborations with companies such as Apple and Google, as well as pricing, regulatory, and licensing issues related to satellite services.",
      "They also consider emergency communication devices like Personal Locator Beacons (PLBs), and compare the advantages and limitations of different satellite networks. Personal experiences provide insightful contexts."
    ],
    "points": 657,
    "commentCount": 482,
    "retryCount": 0,
    "time": 1697048280
  },
  {
    "id": 37850930,
    "title": "US citizens with permanent disabilities get free lifetime pass to National Parks",
    "originLink": "https://www.nps.gov/subjects/accessibility/interagency-access-pass.htm",
    "originBody": "Skip to global NPS navigation Skip to the main content Skip to the footer section National Park Service SEARCH OPEN MENU Accessibility Home About Plan Your Visit News What We Do What You Can Do NPS.govHomePlan Your VisitInteragency Access Pass America the Beautiful-The National Parks and Federal Recreational Lands Access Pass America the Beautiful-The National Parks and Federal Recreational Lands Access Pass What is the America the Beautiful- The National Parks and Federal Recreational Lands Access Pass? The Interagency Access Pass is part of the America the Beautiful – The National Parks and Federal Recreational Lands Pass series and is available free for US citizens or permanent residents with permanent disabilities. Who is eligible to get an Interagency Access Pass? The Interagency Access Pass may be issued to US citizens or permanent residents of any age that have been medically determined to have a permanent disability (does not have to be a 100% disability) that severely limits one or more major life activities. What documentation do I need to show for proof of eligibility? Along with a valid photo ID such as a US passport, driver’s license, or state-issued ID, applicants must provide documentation of permanent disability with one (1) of the following: A statement by a licensed physician (Statement must include that the individual has a PERMANENT disability, that it limits one or more aspects of their daily life, and the nature of those limitations.) A document issued by federal agency such as the Veteran's Administration, Social Security Disability Income or, Supplemental Security Income A document issued by a state agency such as a vocational rehabilitation agency. Where can I get an Interagency Access Pass? Get a Pass in Person You can get an Interagency Access Pass in person at a federal recreation site. Please be aware that passes are not available at all national park sites. Review the Places to Get Interagency Passes to find a location. Get a Pass Online You can also get an Interagency Access Pass online through the USGS Online Store or, through the mail using an application form (Note: While the pass itself is free, there is a shipping and processing cost to get a pass online or through the mail). Interagency Access Passes are available online. Frequently Asked Questions about the Interagency Access Pass Service Animals Information and laws about service animals in our parks. Intellectual Disabilities Information for visitors to better plan your trip to our parks. Laws and Policy Learn about accessibility laws and policy. Last updated: December 16, 2022 Was this page helpful? Yes No An official form of the United States government. Provided by Touchpoints EXPERIENCE MORE PARKS Home Of Franklin D Roosevelt National Historic Site TOOLS Site Index Contact Us Download the official NPS app before your next visit National Park Service U.S. Department of the Interior ACCESSIBILITY PRIVACY POLICY FOIA NOTICES CONTACT THE NATIONAL PARK SERVICE NPS FAQ NO FEAR ACT DISCLAIMER VULNERABILITY DISCLOSURE POLICY USA.GOV FACEBOOK YOUTUBE TWITTER INSTAGRAM FLICKR",
    "commentLink": "https://news.ycombinator.com/item?id=37850930",
    "commentBody": "US citizens with permanent disabilities get free lifetime pass to National ParksHacker NewspastloginUS citizens with permanent disabilities get free lifetime pass to National Parks (nps.gov) 402 points by bookofjoe 16 hours ago| hidepastfavorite278 comments wyldfire 16 hours agoThe National Parks are truly a treasure. We are fortunate to have them and helping disabled people take advantage of the parks is an excellent idea.I think it&#x27;d be great to encourage kids to visit the parks through passes like these. Sponsor a lottery&#x2F;giveaway or a contest featuring children&#x27;s park-themed art or creative writing as chances to win lifetime park passes for them and their family.Also - fans of US national parks specifically can enjoy a game with some spectacular art called simply \"Parks\" [1]. and there&#x27;s a simpler spinoff called \"Trails\"[2].[1] https:&#x2F;&#x2F;boardgamegeek.com&#x2F;boardgame&#x2F;266524&#x2F;parks[2] https:&#x2F;&#x2F;keymastergames.com&#x2F;products&#x2F;trails reply swatcoder 16 hours agoparent> I think it&#x27;d be great to encourage kids to visit the parks through passes like these. Sponsor a lottery&#x2F;giveaway or a contest featuring children&#x27;s park-themed art or creative writing as chances to win lifetime park passes for them and their family.It’s a great idea, and if you’re one of the people here making SV tech salaries, you could make that happen tomorrow. You’re talking about $5000-10000 of direct philanthropy to run&#x2F;promote the contest and buy those passes for the winner. Media coverage would come easy and you could get it to snowball through other contributors after driving it through the first time.(Not being flippant. Sometimes people just need help seeing what they can actually make happen without too much trouble.) reply losteric 14 hours agorootparentMoney is cheap, it&#x27;s time that&#x27;s expensive... I don&#x27;t have any experience here, but my intuition is that organizing and executing the event with appropriate bureaucratic signoff, managing PR, reviewing all the candidates (in a fair and unbiased manner), etc... sounds like weeks of effort spanning months, no? reply swatcoder 14 hours agorootparentThink more hackathon project than startup.Philanthropically, people do this scale of stuff for their own communities all the time. In the arts, people stand up and run themed contests every day.There is absolutely time to be invested in designing or approving whatever online presence, reviewing submissions, becoming comfortable with whatever legal requirements, etc — but that’s the part that makes it a memorable life experience, not unlike the time spent on that trip to Belize or in those woodshop classes. reply solardev 8 hours agorootparentprevHow interested are you? If you or someone you know can provide the money, I bet I can find someone in the parks service, or a close connection, to handle the bureaucratic side of it. (I was an environmental science undergrad, and we frequently worked with the NPS and similar entities. Culturally it&#x27;s very different from the tech world; they are often budget-starved for things but can make time for events and such.) reply azmodeus 14 hours agorootparentprevI have done small philantrophic projects with 5-6 people and doing it with a team helped a lot reply 8note 14 hours agorootparentprevI imagine you could send the money and idea to Amplifier[0] and have them run that for you[0] https:&#x2F;&#x2F;amplifier.org&#x2F; reply burkaman 16 hours agoparentprevIndividual parks often do contests like that, for example https:&#x2F;&#x2F;www.nps.gov&#x2F;shen&#x2F;youth-wildflower-art-contest.htm and https:&#x2F;&#x2F;www.nps.gov&#x2F;long&#x2F;learn&#x2F;kidsyouth&#x2F;student-poetry-cont....There are also free passes specifically for 4th graders (and their families) for some reason: https:&#x2F;&#x2F;everykidoutdoors.gov&#x2F;index.htm reply jedberg 15 hours agorootparent> for some reasonEdit: I was sort of right, but I found this on the website:“We chose fourth graders because research shows that kids ages 9 to 11 are beginning to learn about the world around them. They&#x27;re open to new ideas, and they are likely to connect to nature and our history,”Original answer:5th grade is the year that students learn about US History. I think the theory is that they get a chance to see the national parks before they learn about them in 5th grade. reply solardev 16 hours agoparentprevAnd for those wanting a bit more complexity is the 2023 worker placement game \"Trailblazer - John Muir Trail\": https:&#x2F;&#x2F;boardgamegeek.com&#x2F;boardgame&#x2F;307044&#x2F;trailblazer-john-...I personally really enjoyed that game, and some reviewers have described it as \"What Parks should&#x27;ve been\" reply chrisweekly 14 hours agorootparentThanks for this. \"Parks\" was disappointing. reply codingdave 14 hours agoparentprevFor kids, all 4 graders can get a free pass. That program has been in place for a while and we got it for all my kids, but it doesn&#x27;t seem to be really well known. But we definitely hit more parks those years, and the kids enjoyed being the one who owned the pass and getting to show it at each entrance. reply steve_adams_86 14 hours agoparentprevAs a Canadian it’s one of the things I envy most about the United States. The park system is amazing and so vast. Canada has a lot of parks (3.3% of the land vs 3.6% for the USA) and some are great, and perhaps it’s a result of me going to wrong Canadian parks and the right US parks, but they don’t seem as good here in Canada. They also seem to be predominately north where fewer people are. The majority of them are in places I will never go, along with most Canadians.Canada is beautiful. I guess I just wish more of the parks were accessible and well-supported by our government, in the same way US parks seem to be. reply not2b 14 hours agorootparentWell, there&#x27;s Banff and Jasper (and other nearby parks) which I visited with my wife quite a while ago. We&#x27;re Californians. And Stanley Park in Vancouver is very accessible. reply constantly 14 hours agorootparentprevI’m partial to US parks as well, having visited many of them across the country. But Canada has some truly amazing parks like Banff or places like Lake Louise that are world beating. reply steve_adams_86 14 hours agorootparentYeah, you’re not wrong. There are some parks that are basically in my back yard that you couldn’t explore in a life time. I don’t mean to sound bitter or unappreciative at all. If anything I just want more of it for everyone.My personal favourite is strathcona park on Vancouver Island. My family spends summers and winters there. The geology is incredible, and you can find heaps of fossils in some areas. The lakes are stunning and cool throughout summer. The alpine areas are breathtaking. You really couldn’t see it all in a lifetime. I can’t think of a better thing to have a few hours away. reply cipheredStones 12 hours agoparentprevLooks like the art from those games - which really is quite stunning - is available directly as posters, an art book, and more (although not until next month, I guess): https:&#x2F;&#x2F;59parks.net&#x2F; reply Alex3917 15 hours agoparentprev> We are fortunate to have them and helping disabled people take advantage of the parks is an excellent idea.Joseph Sax is rolling in his grave. reply nickff 15 hours agorootparent>\"Joseph Sax is rolling in his grave.\"Could you please elaborate, I don&#x27;t know anything about Joseph Sax, and his Wikipedia entry doesn&#x27;t contain anything that explains your comment. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Joseph_Sax reply Alex3917 14 hours agorootparentHe wrote a famous book called Mountains Without Handrails:https:&#x2F;&#x2F;www.amazon.com&#x2F;Mountains-Without-Handrails-Reflectio...It&#x27;s been 20 years since I read it, but iirc he is musing about whether things like paving the trails around Niagara falls to make them handicap accessible diminishes our ability to be awed by the natural experience.I may well be mischaracterizing it, so if you want to read it yourself the whole thing appears to be online here:https:&#x2F;&#x2F;www.nps.gov&#x2F;parkhistory&#x2F;online_books&#x2F;sax&#x2F;contents.ht... reply brewdad 14 hours agorootparentThe thing is that like 90% of national park visitors will never venture more than a half mile from their car. We should be making the experience as accessible as possible for those visitors while also preserving the vast majority of the open space for backcountry users.The Paradise Visitor Center at Mt Rainier does a nice job striking this balance. Visitors can get an excellent view of the mountain by driving to the parking lot. There is a paved path to a popular waterfall. Beyond that, hikers can have a more typical trail hiking experience and by the time you are about 4-5 miles from the parking lot, it&#x27;s a proper wilderness experience. reply explaininjs 13 hours agorootparentThe problem is national parks have a vendetta against dogs. I love out of my car with my dog. If a place doesn’t allow dogs, it doesn’t allow me.Granted, I prefer BLM, FWS, and FS land anyways. But don’t forget that NPS adamantly excludes whole classes of people. reply davkan 7 hours agorootparentHigh traffic nature areas are ruined by selfish dog owners. My favorite is spring on my local trails when every time you go out you get to enjoy progressively more dog poop revealed right on the side of the trail as the snow recedes.With the volume of visitors popular National parks see there wouldn’t 50ft of path free of dog poop even if they went out of their way to mitigate it. reply explaininjs 4 hours agorootparentAh yes, the ol’ “some people can’t behave, so everyone of their ilk must be discriminated against” approach.Instead, I’d recommend requiring dogs be accompanied by a dedicated shit-carrying pack and bags sufficient for it. Similar to how humans are required to have bear canisters in some parts. (indeed some places require humans to carry shit bags for themselves!) reply explaininjs 13 hours agorootparentprevThose who appreciate the raw outdoors will know that National Parks are best compared to amusement parks. Family friendly, tons of rules and regulations you must follow, expensive, but granted: some really cool vistas too.Much better is BLM land, US Forest Service land, and (sometimes) US Fish and Wildlife Service land. Free, generally unregulated, vast, and exceedingly beautiful in its own right. reply eichin 14 hours agorootparentprevhttps:&#x2F;&#x2F;www.nps.gov&#x2F;parkhistory&#x2F;online_books&#x2F;sax&#x2F;chap6.htm in particular:> One does not provide such an opportunity for older people or inexperienced visitors by building a highway to the top of a mountain. Rather we can assure that places that are accessible to them are not so deprived of their natural qualities as to put such an experience beyond their reach.which suggests that he&#x27;d be fine with things like the pass program. reply diogenes4 13 hours agoparentprevIt&#x27;s not really possible in today&#x27;s austere political climate, but I think the parks should be free for everyone. Especially as entrance passes to many parks are already rationed, the economic benefits of continuing to charge are relatively small. reply Loughla 13 hours agorootparentIgnorance here, I thought the entrance&#x2F;camping costs went to park maintenance and services. That has to be a non-trivial amount? reply TheNewsIsHere 3 hours agorootparentMy understanding is that’s exactly why access is not unlimited.Interestingly during the pandemic some Nevada state parks moved to a mandatory pass pre-purchase system as a way to control the number of people in the park at a given time to aid in infection control and prevention. Nevada has some truly gorgeous state parks that are more akin to BLM managed land than NPS land. (To me, it’s all beautiful.) reply solardev 16 hours agoprevThis is a good infographic that shows who can get what sorts of passes: https:&#x2F;&#x2F;www.nps.gov&#x2F;planyourvisit&#x2F;images&#x2F;Passes-Flowchart-up...For example, it&#x27;s also free for current military and veterans, or if you volunteer for 250+ hours that yearSome states also let you check out state parks passes (NOT for the National Parks, but the state ones) at libraries.Washington: https:&#x2F;&#x2F;discoverpass.wa.gov&#x2F;148&#x2F;Check-Out-Washington California: https:&#x2F;&#x2F;www.parks.ca.gov&#x2F;?page_id=30806 Nevada: https:&#x2F;&#x2F;parks.nv.gov&#x2F;about&#x2F;library-pass reply me_smith 15 hours agoparentYes! I learned about the library state park pass program recently and it truly is wonderful. Some state parks don’t accept the pass but the vast majority of them do. It has propelled my wife and I to explore outside of our normal park options. reply susiecambria 14 hours agoparentprevIn addition, many libraries also buy museum memberships. For example, Tolland Public Library in Tolland, CT has passes to the Children&#x27;s Museum in West Hartford, Mark Twain House in Hartford, and the USS Constitution Museum in MA. reply heyoni 15 hours agoprevI used this last week using my daughter’s disability. It made me absurdly sad because it’s yet another reminder that she’s going to live forever with what she has but eventually realized in practicality it makes so much sense.For us, the parents, we never know if today is a good day for our daughter to go on a hike and often times will buy tickets to things we don’t or can’t use. Happened with sesame park and that was expensive.I imagine with other disabilities it’s the same thing or similar. Being blind or in a wheelchair (this park had paved paths) sometimes means having to turn around if external or internal conditions aren’t right. Combined with the fact that earning potential probably drops with many severe disabilities and you can imagine these spaces being rarely visited by an entire group. reply s1artibartfast 14 hours agoparentI came in pretty hostile to the idea, but your post made me think twice.I don&#x27;t think disabled people deserve to go to the parks more than non-disabled, but get that there are logistics challenges.I wonder if a time flexible pass would be better than just free access reply heyoni 13 hours agorootparentAnother reason that I&#x27;m probably making up right now is that parents of children with disabilities just won&#x27;t go do certain things if they think it&#x27;s going to be a waste of money, regardless of how much they earn really.I don&#x27;t know this for sure but I wonder if that explains the \"medicaid waiver\". Someone with a disability (and only that individual) has access to medicaid regardless of parental earned income; so we got it for my daughter. And I thought it was weird because we&#x27;re probably not going to need to use it? I&#x27;m not really sure yet...I know I have good insurance but don&#x27;t think have tested its limits.And that&#x27;s when I realized why they don&#x27;t factor in parental income or the presence of existing insurance. It&#x27;s not to cover insurance gaps if I move jobs. It&#x27;s because people with disabilities will probably hit insurance maximums, and at the end of the day, you do not want guardians foregoing necessary medical care when that happens. Because it will happen. You will create a population of disabled and neglected disabled people. And I think it&#x27;s the same for parks. Some people won&#x27;t even try going if they think they&#x27;ll lose $30.And I know someone reading this will immediately say regular people are also being neglected. I think everyone should have access to the same care, but from a budgeting standpoint and no lawmakers wanting to appear uncompassionate, this is an easier pill to swallow. Probably why the parks page linked also mentions veterans. reply drbwaa 12 hours agorootparentThere&#x27;s another factor here: There&#x27;s a huge swath of services that private insurance companies outright will not, under any circumstances, cover. They are explicitly exempted from having to cover these things specifically because they are technically available through Medicaid. This very much includes critical things like long-term caregivers&#x2F;assistive devices. So having access to Medicaid becomes extremely important as soon as you need any of those services. reply TheNewsIsHere 3 hours agorootparentprevThere are a lot of benefits provided specifically to people with disabilities because of this sort reasoning.It’s more difficult for those of us who don’t see a wide spectrum of it up close to understand, but to individuals with the kinds of disabilities that impair mobility, the world is a shockingly different place. Sometimes leveling that playing field is best accomplished by eating the cost of a variable.It’s difficult to imagine but some people are (for example) vulnerable to getting physically stranded in place just because a battery died. Not in terms of going without (for example) Uber, but being unable to physically move through the world the way it was built to move through. All the while cognitively being no more or less different than anyone else, and having to navigate life like that every day. reply nineplay 13 hours agoparentprevI&#x27;ve nothing to add to the topic but I want to commiserate. I&#x27;m sad because we would have used this a few years ago, but my son is just deteriorating and I doubt we&#x27;ll be visiting National Parks with him again.Yosemite has great disabled access FWIW. With a handicap placard we could drive on roads otherwise reserved for buses or rangers and get close to some of the best sights. reply heyoni 13 hours agorootparentI am really so sorry to hear about your son. I&#x27;m new to this whole thing having found out only 4 months ago and have to force myself to do these things and make the best of it.Yosemite is where we went last week. I was glad the government shutdown didn&#x27;t happen. And yea, we were able to use their paved trails to push her around in a stroller because it would have been otherwise quite nearly impossible to go anywhere. She&#x27;s getting a little heavy to hold for extended periods of time. But it made her absurdly happy, so it was worth it. reply CobrastanJorji 13 hours agoprevPeople with disabilities get free park access, 4th graders get free park access, everybody gets free park access on MLK day and Veterans Day. Maybe we should just make national park access free again? I mean, I get that it comes out of my taxes, but it feels weird to charge people to wander around in nature. That&#x27;s what we should be encouraging people to do. reply explaininjs 13 hours agoparentThere’s tons of public land that is free to access. BLM, USFWS, USFS, maybe more. But people in general don’t want that land. They want the land with paved, maintained trails, where there’s always a ranger around the bend to help you out of any situation you might get yourself into. And I don’t mind them paying for those privileges.Those of us who don’t need them have plenty of land to use. reply bravoetch 13 hours agorootparentRangers are federal law enforcement, not &#x27;there to help you out of any situation you might get yourself into&#x27;. Don&#x27;t talk to the police. reply davkan 6 hours agorootparentRangers are a valuable resource to anyone venturing into the backcountry. I cannot count the amount of times I’ve been provided useful information and services by rangers. I’ll happily strike up a conversation with any ranger I meet.Based on your statement I’d be surprised if you’ve ever interacted with a ranger. The only people I meet who dislike rangers are the types who feel entitled to do whatever they please in the wilderness and refuse to carry a bear can when hiking through Yosemite.Take the mindless anti government sentiment elsewhere. reply whyenot 12 hours agorootparentprevBroadly speaking, there are interpretative rangers who provide information and education about national parks and there are law enforcement rangers who exist to protect people, park features, and provide emergency services. If you don’t wish to talk to any rangers, go right ahead, but please don’t spread misinformation about them. reply nickvec 13 hours agoparentprevRight? It&#x27;s inherently public land... why should one have to pay in order to access nature? When you put it in words, it truly sounds like late-stage capitalism manifest. reply reaperman 13 hours agorootparentThe more popular national parks don’t actually have the capacity to meet the demand…theyre huge but the relatively easily human accessible areas are relatively small. Building these out to meet capacity would harm the wildlife goals.https:&#x2F;&#x2F;theconversation.com&#x2F;us-national-parks-are-crowded-an...http:&#x2F;&#x2F;www.doi.gov&#x2F;ocl&#x2F;overcrowding-parkshttps:&#x2F;&#x2F;amp.theguardian.com&#x2F;environment&#x2F;2021&#x2F;sep&#x2F;10&#x2F;overcrow... reply snowwrestler 12 hours agorootparentManaging to capacity is not actually a reason for imposing the fees. And even if it was, the fees are not nearly high enough to have that effect.Capacity challenges are being handled instead by denser transportation (e.g. Zion shuttle), by lotteries (e.g. Grand Canyon float trips), and by limited timed reservations (e.g. Rocky Mountain). reply isykt 13 hours agorootparentprevPeople devalue things that are free. Ever been to the Google cafeteria? reply calderknight 13 hours agorootparent>Ever been to the Google cafeterianope reply tcmart14 16 hours agoprevJust a mention, we only found out last year on accident. Veterans or Gold star families can get free lifetime passes at participating parks or you can fill out an online form and pay like a $10 processing fee. Lady noticed my wife and I were gonna pay for admission with our USAA cards, asked if one of us were vets (we both are) and started throwing pamphlets and stuff at us for the free lifetime pass.Edit: Source for more information https:&#x2F;&#x2F;www.nps.gov&#x2F;planyourvisit&#x2F;veterans-and-gold-star-fam... reply benatkin 15 hours agoprevI hear more and more that disadvantaged people want access to markets instead of having stuff procured for them, with medicine as one possible exception.If you get a Section 8 Voucher but the amount is too cheap, that isn&#x27;t access to the market. https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;the-fond-du-lac-apartm...I think maybe this would be better solved by improving the financial situations of people with permanent disabilities, because then they might be able to afford a ride to the national park and not just entrance. One possible unintended side effect is reducing services given to visitors of national parks.Edit: actually single payer seems to work in some places as a means to get access to the market for health care providers, rather than access to a Health Insurance Marketplace®. reply cogman10 14 hours agoparentAmerican charity is setup to punish anyone that needs it. The issue isn&#x27;t one of market, it&#x27;s one of choice and availability. Whenever you need to rely on an institution operated by or on behalf of the government you are often dealing with something that has gone through 1000 rounds of reaganomics to trim it to the bone and then some.A prime example of this is what happened to our mental health institutions. We used to have flawed, but fairly robust institutions to take care of individuals with extreme disabilities. Under reagan that all got yoinked away and people with severe disabilities were left with just about nothing.But it doesn&#x27;t end there, we do provide SSI and Medicare for people with extreme disabilities, but it&#x27;s setup in the most draconian way imaginable. I have a child with severe autism, in order to not have them lose out of medicare I&#x27;ve had to get a law firm involved to setup a trust to ensure that my child never sees a dime of inheritance. My child can never own their own home, that&#x27;ll kick them off of medicare. They can&#x27;t own their own things, that will also eject them. It was an open question at one point if you could use trust money just to eat a restaurant (you can now, but this is certainly something that can be reversed as it was an IRS decision, not a law). This is all because if I want to give my child the best life possible after I&#x27;m gone, I have to make sure they have health coverage, and I simply can&#x27;t save enough money to ensure that happens.This isn&#x27;t a question of what markets are available, but rather what quality of life should someone be entitled to? Should we all be entitled to have our needs met such as health, housing, clothing, and food? The current answer is no. I disagree. A good government is one that protects the most vulnerable. reply maxerickson 14 hours agorootparentDeinstitutionalization is a lot more involved than Reaganomics.https:&#x2F;&#x2F;journalofethics.ama-assn.org&#x2F;article&#x2F;deinstitutional...The overall situation where we, as a society with the most abundant resources in all of history make living a decent life a puzzle for people facing difficulties, is quite the indictment. reply avgDev 14 hours agorootparentprevHave you considered moving?I have dual citizenship so I plan on leaving the US at some point. EU is much more reasonable when it comes to cost of healthcare and living.I do thing every American should have access to at least basic healthcare, some kind of affordable housing, food and clothes. Unfortunately, that is far from reality.I myself have used food stamps at some point and everything about it was awful. The facilities were sad, employees rude and lines long. reply giantg2 14 hours agorootparentprevIs that Medicare, or Medicaid? My understanding is the home is excluded for medicaid. I thought Medicare was determined by the SSDI that wasn&#x27;t concerned with income&#x2F;assets except for fees (covered by medicaid potentially).I don&#x27;t think Regan was the one to close all the mental health hospitals. I believe that started closing in droves in the 60s-70s. reply bobthepanda 14 hours agorootparentThe large institutional mental health hospitals were closed and supposed to be replaced by smaller, in-community health centers. Reagan repealed the funding for the successor systems and left it up to the states. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Mental_Health_Systems_Act_of... reply giantg2 11 hours agorootparentA better source with more information can be found here:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Community_Mental_Health_Act reply TaylorAlexander 15 hours agoparentprevI completely agree we should increase incomes for people with disability. The thing is, free national park access is something that can be decided within one organization with few side effects. Improving incomes for people with disability is a much bigger challenge. reply armchairhacker 15 hours agoparentprevAFAIK in the US disability is $1,200&#x2F;month, which is absolutely not enough considering rentwill not destroy ecosystems.Are you certain about that?I would have said it was more the case that eco-systems in in off-road 4x4 areas will be destroyed where the vehicles routinely drive and the best comprimise would be to have limited areas for total destruction by 4x4&#x27;s and larger areas for limited 4x4 constrained to pre existing trails.Even beach driving is problematic: https:&#x2F;&#x2F;www.abc.net.au&#x2F;science&#x2F;articles&#x2F;2008&#x2F;02&#x2F;28&#x2F;2175600.h... reply stonogo 14 hours agorootparentHere&#x27;s some actual survey research: https:&#x2F;&#x2F;www.frontiersin.org&#x2F;articles&#x2F;10.3389&#x2F;fevo.2021.80570...Turns out various species are differentially impacted, with the only clear consistent effect being (predictably) decreased sward height. Good news: no reports of ecosystem destruction! Hope this helps. reply munk-a 16 hours agorootparentprevSo why don&#x27;t we fine the people with 4,000 lbs vehicles if they&#x27;re acting irresponsibly? It&#x27;d be great for these places to be free to those who respect the maintenance of them and just recoup the cost for people who are destructive. reply PumpkinSpice 15 hours agorootparentThe US is vast and many of the attractive rural lands effectively have no law enforcement presence of any sort.That said, the parent is being a bit too pessimistic. There&#x27;s plenty of negligibly-policed and freely-accessible BLM land in the West that generally doesn&#x27;t get abused all that much.But in part because of the abundance of BLM land - the government owns nearly 50% of the Western states! - we don&#x27;t really need to allow people to trespass on private land to recreate. There are some exceptions to that - mostly around access to water and beaches - but if you just want to go on a scenic hike, you&#x27;re not out of options around here, and I&#x27;m not sure it&#x27;s useful to hold Sweden as a role model.As a private landowner, I&#x27;m thankful that I can post a \"do not trespass\" sign. Even well-behaved hikers leave a mark over time. Some trash is inevitably left behind or carried away by wind. Soil erosion is a problem on frequently-accessed trails. And that&#x27;s before we get to the occasional drunk or rowdy group. reply kubectl_h 12 hours agoparentprevMaine does not have a right to roam, but trespass is implicitly allowed -- that is to say if law enforcement is called on someone trespassing on private land that has not been posted, they will basically receive a warning and be asked to leave. If they return to that private land after being told not to be on it they will be ticketed. The landowner will be advised to post their land if they do not want people accessing it. Owners are indemnified against lawsuits if an accident happens while a person is trespassing on the owners land. reply mcguire 14 hours agoparentprevWhat does \"abide to simple courtesy rules\" mean, specifically?Can you have a family reunion with 30-40 people? Can you stay in one place for a week? Fishing? Hunting? reply tpmx 14 hours agorootparenthttps:&#x2F;&#x2F;www.naturvardsverket.se&#x2F;en&#x2F;topics&#x2F;the-right-of-publi...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Freedom_to_roam#SwedenFamily reunion with 30-40 people? - Yes, if you don&#x27;t disturb anyone&#x27;s home or the land.Can you stay in one place for a week? - Sure.Fishing? Hunting? - generally no, unless you get a permit. Fishing permits are easy to get. Fishing recreationally in the ocean does not require a permit. reply balls187 14 hours agorootparentprevMeans dont destroy, don’t disturb.Stay away from peoples homes, and dont bother gardens&#x2F;farms.Other than that you can enjoy.Not sure if you need a hunting or fishing license, but a family reunion is fine, so long as you abide by the above. reply jononomo 15 hours agoparentprevJust FYI, \"irregardless\" is not a word. The word you want is \"regardless\". Yes, I know that \"irregardless\" has now made it into dictionaries and whatnot, but that is just because it is misused so often. (Consider that dictionaries now consider \"figuratively\" to be a valid meaning for the word \"literally\" because that has also been misused so much.) \"Irregardless\" is the result of confusing \"regardless\" and \"irrespective\". reply pests 11 hours agorootparentDictionaries are descriptive rather than prescriptive. Dictionaries record the current usage, not some rules of language.I would say irregardless is a word. It hasn&#x27;t made it into dictionaries because it&#x27;s been misused, it&#x27;s made it into dictionaries because it&#x27;s been in use!Irregardless of your thoughts on the matter; people use literally differently than you do. Why are you correct and they are wrong? reply tpmx 14 hours agorootparentprevThanks! Fixed. I actually wrote regardless at first but it seemed wrong when I revisited the comment. reply Tao3300 13 hours agorootparentprev200 years of use isn&#x27;t long enough for you? It&#x27;s a word. reply kylecazar 16 hours agoparentprevFreedom to roam! reply rconti 14 hours agoprevI wish I could just buy an annual subscription to the national parks. Last time I checked, it was $85 a year. I&#x27;d happily &#x27;donate&#x27; that on years I don&#x27;t visit the parks at all. Just set up recurring billing!But, nope. Gotta buy one every year. reply brewdad 13 hours agoparentIf you have an REI membership, you can buy one online from them for the same $80&#x2F;yr. They&#x27;ll either mail it to you for free or you can pick it up in store within an hour if you live nearby. reply scroot 13 hours agorootparentYou can also just walk in and get one in the moment. I get my annual parks pass every year from REI. Pays for itself in no time with the car&#x2F;parking situation alone. reply darknavi 15 hours agoprevI encourage anyone who visits parks to start the minigame of collecting park stamps!They are a blast to seek out and find. We have been to so many random new places like wildlife sanctuaries in the quest to try and fill out books. Extra fun when mapping out paths on road trips to hit all of the parks in an EV, lots of constraints.A good fan site with lots of info: https:&#x2F;&#x2F;www.parkstamps.org&#x2F; reply disabledanon 14 hours agoprevPosting anon because I dont want to be judged.I worked 80hr weeks for most of my 20s. I&#x27;m 43 now, fairly senior, but lost my youth. I have severe arthritis and most of my cartridge is gone. Walking is tiring after about a half mile and impossible after a mile. Dr says i&#x27;m too young for a knee replacement because you cant get 2 in your life.Advice -- please enjoy some of your free time in your youth, you may not be able to enjoy your seniority&#x2F;money once you have it. reply closeparen 15 hours agoprevWhile the various fee waiver and discount programs are nice, the entry fees are just not that relevant in the grand scheme of planning and executing a national park trip. Transportation and lodging dominate the cost structure by a wide margin. reply lapetitejort 16 hours agoprevI have a similar (or same? I got it over a decade ago and things change) pass for disabilities from military service. One flash of it and my driver&#x27;s license and I get access to every single park and half off camping. I&#x27;ve only gotten grief once when a campground manager did not believe I was old enough to be disabled. I straightened him out pretty quick. Entry fees aren&#x27;t expensive per se, but I have certainly saved a good amount of money. It makes quick trips to my local national monument more likely when I don&#x27;t have to fret over visiting for just a few hours. reply extraduder_ire 14 hours agoprevHow much does it usually cost to gain access to these parks, roughly?I&#x27;d expect this scheme to more than pay for itself pretty rapidly, regardless. Based on what I&#x27;ve read about improved physical and mental health outcomes for people on long term illness benefit here when the government started paying them to go on holiday once a year. (also heard it about other countries, we were certainly not the first) reply LesZedCB 14 hours agoparentannual pass is $80&#x2F;yr. individual park day passes run around $10-40 for a day pass depending on the park, in my experience reply pcbro141 16 hours agoprevCould easily make it free for all Americans for relative pennies compared to how much was allocated to foreign countries in the last year. reply jedberg 16 hours agoprevAnyone over 62 can pay the one year fee and get it for the rest of their life.4th graders can also get a free pass. reply FloatArtifact 14 hours agoprevWhat about the caregivers who support those who are permanently disabled? It&#x27;s a case of it takes two for those that are disabled and unable to transport themselves. reply jeffnhl 13 hours agoparentMy son is in a wheelchair and has had a pass for years through this program. If anyone in the vehicle has a pass the whole carload goes in on it for the same &#x27;free&#x27;. It was actually a ranger when we were going into a park that turned us onto the program, they set us up and got us in all in one go at the gate, mailed the card a few days later. reply ghaff 16 hours agoprev62 and older can already get a pretty cheap Federal Lands pass (which is what this is as well, not just national parks) for one-time $80 I think. So this is not a huge departure. reply tony_cannistra 16 hours agoparentCertainly there are plenty of folks under the age of 62 to whom this applies, and might save them the money. reply ghaff 16 hours agorootparentMy point was that significant admission discounts are hardly anything new. reply pests 11 hours agorootparentHow is that related to people with disabilities being given free passes? reply Zigurd 16 hours agoparentprev$80 is correct. This is an amazing deal. And if you don&#x27;t like your own odds, a Senior Annual Pass is $20, which is $5 less than one parking fee at Cape Cod National Seashore and $15 less than one private car entry to Yosemite. reply system2 15 hours agorootparentWhat is the regular rate for an average joe without any disability or army ties? reply __derek__ 15 hours agorootparentThe inter-agency America the Beautiful annual passes cost $80.[1][1]: https:&#x2F;&#x2F;www.nps.gov&#x2F;planyourvisit&#x2F;passes.htm reply devilbunny 15 hours agorootparentprev$80 a year. The disability, military, or age 62 will get you a pass that&#x27;s valid for life, and only those who age into it have to pay anything at all.Typically you have to visit three parks within the year to pay for it. If you live in the East, it&#x27;s probably not something you&#x27;d get every year. If you live in much of the West, it&#x27;s probably something you&#x27;d be crazy not to get every year. reply ghaff 15 hours agorootparentprevIn general, it&#x27;s something like $20-40 to go into a national park--maybe for up to 7 days--though it varies. reply underseacables 13 hours agoprevThat’s wonderful, now, if only they would make them more handicap accessible… reply leonheld 15 hours agoprevThe only thing that actually makes me want to visit the United States: the National Parks. reply balls187 13 hours agoparentReal BBQ should be a close 2nd! reply SamuelAdams 16 hours agoprevI wonder if being deaf or hard of hearing is considered a disability in this context? reply 5555624 15 hours agoparentTo prove a permanent disability, one option is a statement by a licensed physician, which must include: - that the individual has a PERMANENT disability - that it limits one or more aspects of their daily life - and the nature of those limitations.Unless there&#x27;s something about the nature of the limitations deafness seems like it would apply. (The other acceptable forms of proof are federal or state government-issued documents.) reply robk 15 hours agoparentprevAbsolutely yes reply sidechaining 15 hours agorootparentAny source for this? reply Fleusal 15 hours agoprevYou need to pay to visit a national park?? The land of the free is very expensive. reply topkai22 14 hours agoparentIt depends on the park and the activity. For example, Great Basin National Park has no entrance fee, but does have fees for a cave tour, campsites, and RV dumps.In my experience, the vast majority of public land (forests and BLM land) is free to enter and recreate on if you aren’t using services like a campsite. National parks are more likely to charge entrance or parking fees but you are also more likely to get things like trash service and paved roads.That being said, it’s still pretty cheap. You can get an annual pass for $80 that covers you and everyone in your car. reply bombcar 14 hours agorootparentBLM land is often entirely free, but doesn’t have “campsites” as many would expect. State and national parks often have campsites with running water, flush toilets, even hot showers, and quite in the middle of nowhere.BLM campsites are often a flat piece of ground that looks identical to the last seven thousand square miles. reply pests 11 hours agorootparentSometimes they will have a tiny retaining wall&#x2F;perimeter to make it flat. reply ghaff 15 hours agoparentprevGiven that no one is paying for your transportation to or lodging in the park, it&#x27;s expensive in any case regardless of a typically modest admission fee. That&#x27;s almost surely true in most places. reply 1970-01-01 13 hours agoparentprevYou also need to pay for clothes and food. The land of the free is very expensive. reply nilespotter 15 hours agoparentprevAdmission localizes the expense to people who attend. If it were \"free\" to visitors they&#x27;d still be paying. reply mosburn 13 hours agoprevHonestly, the bar is very little to get the lifetime pass if you go to a busier park. My wife just had to show the disabled parking pass and they gave it to her without any of the supporting documentation. Was way easier then we expected and hoped she had the right paperwork. I keep my annual pass renewed so I can go locally without her. reply ei8ths 14 hours agoprevthis is great, i think veterans should get the same treatment. reply thecyborganizer 14 hours agoparentthey do!https:&#x2F;&#x2F;www.nps.gov&#x2F;planyourvisit&#x2F;veterans-and-gold-star-fam... reply User23 16 hours agoprevGreat program, but disappointing that the blind are invisible on the splash page. National parks are an extremely sensory rich environment. Birding by ear in particular is very popular. reply running101 14 hours agoprevSeems fair reply Mystery-Machine 14 hours agoprev1. Why do parks cost money? Ever. For anyone? 2. How is this news? We really messed up when you need to pay to go to nature...while you&#x27;re also paying taxes. reply rjtc 15 hours agoprevwhy do we need national parks as opposed to state parks? Why federalize everything? reply silisili 15 hours agoparentIf you&#x27;d left them to the states, they&#x27;d have mostly been broken apart and sold off years ago, for starters. Especially when they see a budget shortfall. reply starcraft2wol 15 hours agorootparentWhat leads the national government to make better choices? unlimited budget, less democratic oversight? reply peyton 14 hours agorootparentYeah they aren’t guaranteed to survive state budget crises because states can’t print money. reply MuffinFlavored 14 hours agoprevis Leslie Knope to thank? reply chris_wot 13 hours agoprevYet free health care is socialism. It&#x27;s great they are getting free visits to national parks, but I&#x27;m sure a better health care system would be way more effective. reply btilly 16 hours agoprevI&#x27;m curious what qualifies as a \"permanent disability\".I was shocked to find out that ADHD qualified as a disability that would let you get Paxlovid. To verify, go to https:&#x2F;&#x2F;www.paxlovid.com&#x2F;who-can-take and click on \"Disabilities\". But having seen that, I&#x27;m tempted to tell my son that he might be able to get a free lifetime pass.But that opens up a question. Have we as a society come to define disabilities so broadly that the term has basically become meaningless? reply burkaman 15 hours agoparentNo we haven&#x27;t, and ADHD is disabling for many people in a meaningful way. The criteria here is that a doctor says it is permanent and it \"limits one or more aspects of their daily life\".It is also supposed to be a \"severe\" limitation, but I doubt someone with ADHD would be interrogated about this, everyone involved just wants more people to visit the parks. reply hn_throwaway_99 15 hours agorootparentI think the implication of the parent poster is that it&#x27;s difficult to imagine why ADHD could put you at increased COVID risk to the point of needing Paxlovid. That makes no sense to me but I&#x27;m all ears as to the logic here. reply burkaman 15 hours agorootparentWithout looking it up, I can imagine the cognitive effects of Covid might be more severe for someone with ADHD. After looking it up, it seems there is some association between ADHD and worse outcomes: https:&#x2F;&#x2F;journals.sagepub.com&#x2F;doi&#x2F;full&#x2F;10.1177&#x2F;10870547211003....It&#x27;s also possible that ADHD makes it more difficult to scrupulously comply with self-quarantine measures, in which case it&#x27;s a good public health decision to make Paxlovid available and reduce community spread. I&#x27;m not actually sure if Paxlovid reduces transmission though. reply hn_throwaway_99 15 hours agorootparentThanks very much, that&#x27;s the kind of medically appropriate implication I was looking for: \"Conclusion: ADHD is associated with poorer outcomes in COVID-19 infection.\" reply btilly 14 hours agorootparentprevI&#x27;m sure that ADHD is comorbid with a variety of lifestyle and health problems that make COVID somewhat worse. But in general it does not directly affect health. Why not simply provide it to those with the comorbidities?I consider community spread mostly a nonissue. We&#x27;ve known for many decades that if you can&#x27;t get the replication rate below 1, the correlation between replication rate and how many get it is chaotic. We can&#x27;t get the replication rate of COVID below 1, so there is little correlation between policies and outcomes. Obviously this does not apply if you are at risk or a caregiver of someone at risk. That&#x27;s why saner countries than the USA (Germany is my favorite example) do not recommend vaccination against COVID for the general public. reply burkaman 13 hours agorootparent> Why not simply provide it to those with the comorbidities?I don&#x27;t know, I would guess because they&#x27;re harder to define and doctors generally diagnose conditions rather than individual symptoms or behaviors. reply munk-a 15 hours agorootparentprevADHD makes it more difficult to support yourself independently, live a \"normal life\" and keep a steady income - so for pretty much the same reasons as most of the other disabilities. reply hn_throwaway_99 15 hours agorootparentAgain, I see 0 relation between this and Paxlovid. There are about a million things that make it difficult to support yourself: being newly divorced is a huge hardship, as is being newly laid off, as is not having health insurance in the US (see today&#x27;s stories about Mary Lou Retton needing to crowdfund for her medical care on GoFundMe).Point being, if that&#x27;s the bar, they should get rid of the nonsense requirement of needing a \"disability\" to get Paxlovid. Otherwise they should restrict it to disabilities that actually have a medically demonstrated increased risk of severe illness or death from COVID. reply user_7832 15 hours agorootparent> There are about a million things that make it difficult to support yourself: being newly divorced is a huge hardship, as is being newly laid off, as is not having health insurance in the US (see today&#x27;s stories about Mary Lou Retton needing to crowdfund for her medical care on GoFundMe).Don&#x27;t disagree with any of these also being very significant, personally I wouldn&#x27;t mind if these folks also got the pax. Buta. these aren&#x27;t considered \"permanent\" in the general sense (you can get rehired&#x2F;remarried), and b. permanent disabilities are much \"easier\" for a govt to classify than to spend resources everytime someone needed assistanceAnd > Otherwise they should restrict it to disabilities that actually have a medically demonstrated increased risk of severe illness or death from COVID.ADHD does have a medically increased risk of severe illness or death from COVID. Perhaps not \"directly\" like someone on immunosuppressants, but as someone w&#x2F; adhd and another chronic health condition (T1 diabetes), adhd makes it several times more difficult to handle my health (and T1D has life threatening complications within arm&#x27;s reach of poor management). reply btilly 14 hours agorootparentI agree with you. But T1 diabetes is something which should suffice for Paxlovid.BTW if you haven&#x27;t checked out OpenAPS, I highly recommend it based on friends who have used it. It greatly reduces the self-discipline needed for T1 diabetes maintenance. reply munk-a 15 hours agorootparentprevAs someone with ADHD I can&#x27;t imagine that I would&#x27;ve made it to 25 without severely screwing up my T1D care - that requires pretty constant vigilance and, well, there&#x27;s a reason I voluntarily don&#x27;t drive. reply drewmol 14 hours agorootparentprevI wonder if it&#x27;s ADHD or just the side effects of continual stimulant usage that causes worst COVID outcomes. Stimulants can be hell on a lot of bodily system functions. reply munk-a 15 hours agorootparentprevThis is just an American with ADHD who emigrated to Canada speaking but... yea, why don&#x27;t we lower the bar and remove that nonsense requirement. It&#x27;d be great if everyone who needed help could get it in a reasonable manner. Maybe you have severe mobility issues and need physical assistance showering and doing daily hygiene tasks - maybe you&#x27;re a neurotypical person who just lost a family member, went through a rough divorce and was diagnosed with cancer all in the same week. It&#x27;d be great if there was social assistance to help you out - especially if you weren&#x27;t shamed for using them.But, specifically on the topic of Paxlovid, ADHD people tend to have less stable, shorter and poorer lives - there is a strong correlation between the illness and the need for financial assistance. ADHD people tend to also be less proactive about health issues and delay treatment more than normal people (because going to the doctor is hard and there are so many considerations) so perhaps the Paxlovid allowance is because people with ADHD are more likely to have more advanced COVID cases - I can&#x27;t tell you why they made that decision but those are two pretty solid reasons to consider it. reply WendyTheWillow 15 hours agorootparentprevStubbing your toe makes it harder to walk up stairs, but we still build ramps and elevators for people in wheelchairs. reply WendyTheWillow 15 hours agorootparentprevAs a person with ADHD, I was about to argue that ADHD is not something that would, absent other health issues, qualify someone for something like Paxlovid.But your argument completely 180&#x27;d me. I&#x27;ve got a lifetime of tools to deal with my ADHD, but me from 10 years ago absolutely would have gotten COVID and not taken it seriously (item 12435346 on the list of shit I&#x27;d not be tracking well), which is precisely the kind of additional risk Paxlovid was made for.I heard on a podcast that ADHD can sometimes reduce life expectancy by 13 years. Compared to obesity, which reduces lifespan by 10 years, and type I diabetes, which reduces lifespan by 3-4 years, it&#x27;s a real disability that needs to be taken much more seriously than it currently is, IMO. reply jwiz 15 hours agorootparentprev> Require close contact with those who may be infected, such as a caregiver or family member reply chownie 15 hours agoparentprevI believe more that we&#x27;ve grown to understand how debilitating ADHD can be and that is why it&#x27;s considered a disability.Consider how it affects people&#x27;s life trajectory through school and work, the opportunities out of reach due to the condition. It&#x27;s essentially a situational cognitive impairment, when I think about it that way it seems profoundly disabling. reply throwaway914 15 hours agorootparentI never felt disabled until I got a significant other who wasn&#x27;t as familiar with my ADHD symptoms. When we get up to go do an errand I tend to execute my todo list very quickly thinking I will lose the opportunity. I&#x27;ll do dishes, put in laundry, clear away trash, send emails, pay bills, schedule appointments, etc. All the things I should have been doing in the hours before we do the errand. It&#x27;s become very clear to me how much this frustrates my partner while they&#x27;re waiting for me by the door to get this stuff done. They can&#x27;t get me out of the house sooner because I&#x27;ll just say \"just one more minute!\" and \"almost done...\" over and over. I work from home, so my partner will get frustrated if I work past the end of my day. Computers&#x2F;technology is the one area I can focus very well, so I might dig into something interesting for hours. Except then I&#x27;ve infringed on the time we have to be together (my partner).When I was living with family they were used to this stuff, and just let me be if I was obsessed with something. They let me satisfy those last-minute compulsions where I procrastinated and was unable to execute on my todo list earlier. etc etc.I thought I had light ADHD but it effects my relationship, friends, and work responsibilities so much. I hate that I do everything at the last minute, with only a suitable stress to make my thoughts order themselves. And it appears entirely un-ordered when I&#x27;m doing x-y-z quickly.Why couldn&#x27;t I do it all earlier? reply btilly 14 hours agorootparentI developed the habit of doing those things when I walk in the door, not when I walk out.This also frustrates my wife, but I think less so than it would be to have the signal being an errand I&#x27;m already late for. reply throwaway914 12 hours agorootparentWhen I lived with family it felt normal. My family actually lied about my symptoms on a medical survey because my mom thought if I was diagnosed with AD?D I&#x27;d be unemployable somehow, like employers could get that in a background check?Getting around other people made it more obvious I had some issues. Like, my partner and I will go on walks and they&#x27;ll get annoyed if I point out an interesting animal or thing I&#x27;m seeing if they&#x27;re in the middle of a topic. At work I always set reminders on my phone, sent emails to myself, and left stickies on my desktop. My supervisor pointed out he&#x27;d never seen someone do that as much as I do, and started requiring me to show up with a notepad in meetings. He&#x27;d tell me to do 2 things, and then have to ask me what the first thing I told him was as I left - then the notepad became necessary.I worked to get onto an employee advocacy group at work and we do a lot of writing to identify systemic issues and propose solutions. I had 2 months to create a paper covering issues with hiring and on the last day - after I turned in the paper - I hit reply-all to add an additional thing that was critically important. Something I knew was an issue before I started the paper. For 2 months it was completely gone from my head. So I have whiteboards around my room, and I&#x27;m trying to move to using digital whiteboards to remember these things and organize them so I can even keep my supervisor and coworkers in the loop. \"This is my MS Team Whiteboard for Monday stuff, buwhahaha\"I just remember being 25 and feeling like this didn&#x27;t affect me so much. It still feels like I&#x27;m joking when I talk about it. ADD &#x2F;sounds&#x2F; like a non-serious condition. But all these relationships have suffered because I&#x27;m forgetful and disorganized, and people are tired of my excuses. :-( I felt normal before.2 days ago I had a big argument because my partner says I should be taking my medication. I usually don&#x27;t take it on the weekends, because I shouldn&#x27;t need to \"focus\" then, right? I hate that the meds for ADD are addictive, and sometimes it works when I need it - other times it kicks in a day later and it feels like a double-dose. That scares me. reply system2 15 hours agorootparentprevPeople think disability as having no leg or being blind. If you ask any random gen-z, they will tell you they have ADHD. That&#x27;s why ADHD as a disability lost its weight. reply user_7832 15 hours agorootparent> People think disability as having no leg or being blind.These are the \"visible\" disabilities. ADHD, amongst other conditions, are more invisible[1]. I have diabetes but \"look\" normal. I know a guy with epilepsy. They too, unsurprisingly, don&#x27;t \"appear\" disabled. (I know this wasn&#x27;t your main point but I think it&#x27;s important for people to know.)1 - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Invisible_disability reply JauntyHatAngle 15 hours agorootparentprevHave they been diagnosed medically?Because plenty of people say they are OCD too, but they don&#x27;t mean the diagnosed condition. And it&#x27;s quite different to \"being tidy and needing things to be ordered\" that the common vernacular makes it out to be.Same as ADHD. Plenty of people who say they are \"a bit ADD\" mean something else. reply btilly 14 hours agorootparentMy very strong belief is that a large fraction of those who are \"medically diagnosed\" do not actually have ADHD.ADHD was originally a diagnosis of exclusion - lack of executive control not explainable by any other known condition. But you can lack executive control for a wide variety of reasons including depression, sleep deprivation, electrolyte imbalances, and so on. Often doctors don&#x27;t look - they just shove you out the door with Adderall. The side effects of which include loss of appetite and insomnia - both of which can make symptoms worse in the long run!If we&#x27;re going to treat ADHD as the serious disorder that it can be, we should treat diagnosis and treatment as more than an opportunity to prescribe profitable drugs. But instead we have a combination of on the one hand not taking it seriously, and on the other treating it like something serious at the oddest of moments. reply cornstalks 15 hours agorootparentprevGiven how common it was (still is?) to abuse Adderall in college, I&#x27;m going to go out on a limb and say a lot of people have been \"diagnosed\" with ADHD, but that doesn&#x27;t necessarily mean much. reply WesternWind 15 hours agoparentprevThe Paxlovid.com website is from the for profit company Pfizer, which makes Paxlovid, so yes, they&#x27;ll list every kind of disability that could conceivably be a reason to take paxlovid and make them money.But yeah ADHD can count as a disability, in some people. That&#x27;s based not what you have, but if what you have substantially limits at least one major life activity. reply btilly 14 hours agorootparentWhile they publish that list, they did not come up with it. That list is from the emergency use authorization granted by the FDA.You&#x27;re free to guess whether the FDA is basing that on science, politics, or corruption. I&#x27;ve seen sufficient evidence that they do all three that I don&#x27;t have a strong opinion. (In this case, I don&#x27;t think that the science is there.) reply olalonde 15 hours agoparentprev> Have we as a society come to define disabilities so broadly that the term has basically become meaningless?I would say so. There ought to be a distinction between losing your legs and having ADHD. Most people with ADHD don&#x27;t even know they have it. And it&#x27;s also incredibly easy to fake. reply interactivecode 15 hours agorootparentThere is a difference one is only physical and the other is cognitive.As long as we have qualified doctors diagnose disabilities, I‘m quite sure the actual amount of faking or fraud will be negligible. reply btilly 14 hours agorootparentBased on my experiences with the system, I&#x27;m quite sure that the actual amount of faking and fraud is extreme.In other news, we have a national Adderall shortage because it was widely prescribed to kids whose problem was being unable to concentrate during lockdown due to stress and depression. As a result, by default teenagers lose their diagnosis when they graduate. I learned this when my son&#x27;s psychiatrist had to give him very explicit instructions about how to document his disability so that the diagnosis he received in grade 1 will follow him into his adult life without having to prove it again. reply fn-mote 13 hours agorootparent> As a result, by default teenagers lose their diagnosis when they graduate.I believe you misunderstood what happens and why the coaching was necessary. The laws governing children in K-12 schools are different from those governing adults.Children are covered under the IDEA (Individuals with Disabilities Education Act).Adults are under the ADA (Americans with Disabilities Act).Lots of colleges document the differences. Bryn Mawr&#x27;s page looks good. [1][1]: https:&#x2F;&#x2F;www.brynmawr.edu&#x2F;inside&#x2F;offices-services&#x2F;access-serv... reply btilly 12 hours agorootparentShe covered both.My son needed to provide specific documentation from his school to his university if he wanted the possibility of accommodations.Separately she walked through what my son would need to do to get an adult diagnosis that would let him continue to be prescribed Adderall. reply chownie 13 hours agorootparentprev> In other news, we have a national Adderall shortage because it was widely prescribed to kids whose problem was being unable to concentrate during lockdown due to stress and depression.This is an exceptionally cynical take on the situation, one that tugs the rage strings a little too neatly for me to think this is an accurate reflection of reality.Drug companies have said it&#x27;s part caused by increased demand but supply has also been affected by unpublished limitations on handling controlled substances, instituted by the federal government in response to the opiate crisis. reply btilly 13 hours agorootparentI&#x27;m reporting on what my son&#x27;s psychiatrist told us at the same time as she wrote my son&#x27;s final prescription as a minor. She knew about it because she was a child psychiatrist in a system where that policy change was made.She also told us that, BECAUSE that policy change had been made, it was no longer automatic to have a childhood diagnosis follow you into adulthood. She then walked us through the documentation that we needed to get so that my son&#x27;s long-standing diagnosis actually would transfer into adulthood.I wound up having to fill that prescription twice. Both times I personally experienced the shortage.You might be right that there are factors other than increased demand. But demand definitely has increased. And I have no reason to doubt the psychiatrist. reply olalonde 14 hours agorootparentprevTo take another example, schizophrenia is in a whole different league than ADHD and arguably worse, or on par with, losing one&#x27;s legs.> As long as we have qualified doctors diagnose disabilities, I‘m quite sure the actual amount of faking or fraud will be negligible.There is a ton of people who get prescribed Adderall for its cognitive enhancement properties. It&#x27;s incredibly easy to get diagnosed[0].[0] https:&#x2F;&#x2F;www.psychologytoday.com&#x2F;intl&#x2F;blog&#x2F;mouse-man&#x2F;201007&#x2F;n... reply chownie 13 hours agorootparent\"there were a ton of people who did\" you mean, this source is over a decade old and the diagnostic criteria have been updated since reply vikingerik 15 hours agoparentprevAt the very least, we should be aware of potentially perverse incentives. The more we reward disability, the more incentive there is to get yourself declared as disabled. reply interactivecode 15 hours agorootparentHopefully it will be an equal amount of incentive for people with undiagnosed disabilities to get diagnosed and receive treatment or support. Even if just to be productive members of society for longer! reply JambalayaJim 16 hours agoparentprevI would definitely consider ADHD as a debilitating disability. reply swatcoder 15 hours agoparentprev> Have we as a society come to define disabilities so broadly that the term has basically become meaningless?We’re getting close, but it’s okay. Expansion of the term has helped people and we’ll eventually come up with new common language to distinguish more and less catastrophic forms of disability. reply munk-a 15 hours agorootparentI disagree - I think as a culture we&#x27;re coming closer to realizing that everyone needs help sometime and that we should have social programs available to help with that. Some people need more access to those programs than other people and some people have specific needs that others don&#x27;t - we should just help people in their time of need, make things more accessible, and remove the social shaming associated with it reply swatcoder 15 hours agorootparentSure, except you’re not disagreeing. :)If disability now means needing help, and help is something that everybody needs sometime, then disability really refers to everybody at some time.And inasmuch as everybody should have the help they need, and statute already says that disabled people can get help, it works out well in practice. Everybody can claim that they’re disabled when they’re disabled and get the help they need. Sounds great!But disabled used to mean something much more narrow and uncommon, and there’s still going to be need to find new language for that. reply munk-a 15 hours agorootparentThat is extremely difficult to provide a blanket term for - we&#x27;re talking about such a wide spectrum of issues when we use the 90&#x27;s definition of disabled. That would include people who are perfectly neurotypical but require physical assistance (i.e. someone with arthritis who needs ramps to change elevation at a reasonable speed), people who are neurodivergent but perfectly physically able and everyone inbetween. A lot of those folks just went unserved in the old system and struggled financially to keep themselves alive and fed while walking a much harder road than the rest of us.I think a blanket term for disability isn&#x27;t useful and it&#x27;s much more productive to focus on forms of impairment - there&#x27;s no real similarity in treatment and support between a person who was hit by a car and needs a wheelchair and someone otherwise normal looking who is prone to sudden violent outbursts due to a neurological disorder. And, unfortunately, one of those people is much more likely to be looked on with sympathy and the other shamed and feared - but both of them can live normal lives with proper care. reply JauntyHatAngle 15 hours agoparentprevADHD can be debilitating when severe.It&#x27;s a truly awful condition that is not the \"can&#x27;t concentrate need to play games all day!\" Condition the 00&#x27;s characterised it as. reply Eumenes 15 hours agoparentprevHuh so i can get an ADHD diagnosis in 30 mins for cost of an office visit, and get a free lifetime pass to national parks? Pretty based reply burkaman 13 hours agorootparentUnclear, your doctor would have to state that your ADHD is a permanent disability \"that severely limits one or more major life activities.\" I&#x27;m not sure they&#x27;d be willing to do that after one 30 minute visit.If you as an individual applied for this with a 30-minute ADHD diagnosis they might still give you the pass, because what&#x27;s the point in arguing with you, but if a ton of people followed your lead then they&#x27;d probably start enforcing that criteria. reply ajross 15 hours agorootparentprevSorta, in exactly the same way you can get an oxycodone prescription in 30 minutes for the cost of an office visit and flip it on the street for cash. What you&#x27;re positing is just medical fraud. And, sure, it happens. But not for park passes. reply Eumenes 15 hours agorootparentGetting diagnosed with ADHD because you \"can&#x27;t focus\" is comically easy. Millions of college kids, software engineers, investment bankers, and kitchen staff do it every year. reply ajross 15 hours agorootparentPer a quick google, only $9M adults in the US are even estimated to have ADHD, in total. Much less diagnosed, and certainly not per year. You&#x27;re parroting something you imagined someone to have said.In practice genuine clinical diagnoses aren&#x27;t at all common. It&#x27;s certainly not a \"rare\" disorder, but it&#x27;s not remotely abused or abusable in the way you imagine. reply olalonde 14 hours agorootparentAccording to research, 1 in 4 adults may be faking it[0]. Studies have also shown that it&#x27;s easy to fake[1].[0] https:&#x2F;&#x2F;www.nbcnews.com&#x2F;health&#x2F;health-news&#x2F;adults-who-claim-...[1] https:&#x2F;&#x2F;www.psychologytoday.com&#x2F;intl&#x2F;blog&#x2F;mouse-man&#x2F;201007&#x2F;n... reply chownie 13 hours agorootparentBoth of these sources are over ten years old and refer to diagnostic criteria defined in 2007, this is not the state of the world today. reply btilly 12 hours agorootparentCan you show any research indicating that it is not easy to fake with current diagnostic criteria? reply chownie 46 minutes agorootparentNope!There&#x27;s nothing published along those lines, given the criteria were updated in 2017 there&#x27;s been plenty of time to test the prior methods again but either no one&#x27;s tried or the results werent exciting enough to publish. reply Eumenes 14 hours agorootparentprev> Data from the analytics and research company IQVIA shows that the demand for Adderall has risen nearly 27% in recent years, with prescriptions jumping from 35.5 million in 2019 to 45 million last year.Probably even higher now. That&#x27;s nearly 15% of the population. Are stimulants like Adderall prescribed for conditions that aren&#x27;t ADHD? Do ADHD diagnosis not include medication? My point was stimulants are being abused and are easily acquired (in the name of ADHD). reply CtrlCthenV 14 hours agorootparent>My point was stimulants are being abused and are easily acquired (in the name of ADHD).You say this in such a matter of fact way. Doctors regularly gate-keep people with ADHD from a diagnosis because of drug seekers. You are speaking like a person with no experiences in the subject, and considering your original post we know you are not arguing in good faith here at all. reply btilly 14 hours agorootparentYou are dead wrong.It is estimated that around 9 million adults have ADHD.https:&#x2F;&#x2F;www.forbes.com&#x2F;health&#x2F;mind&#x2F;adhd-statistics&#x2F;But during COVID, rules were loosened about being able to diagnose ADHD by telehealth. The result was on the order of 2 million new prescriptions per year.https:&#x2F;&#x2F;spanberger.house.gov&#x2F;posts&#x2F;spanberger-puts-more-pres...It is also true that there are people being kept from a diagnosis because of drug seekers. But that just means that the drug seekers have to look around until they find a compliant doctor.But hey. When I pick up my son&#x27;s medication, I now have to show my driver&#x27;s license. So at least we&#x27;re catching the ones who shop around, find 5 compliant doctors, and then sell the extras on the black market!(My son doesn&#x27;t need medication picked up very often. Unfortunately for him, he can&#x27;t tolerate the side effects of more than sporadic use. But he would struggle to get through major exams without it.) reply CtrlCthenV 13 hours agorootparentWhat you are saying does not match my and many other peoples reality. I personally have been denied a diagnosis even tho I have had done 3 previous assessments. This was even when I changed back to the same provider I had previously after a move. It seems every time I change insurance providers the new one does not believe that I am anything but a drug seeking addict. This is still the narrative for many people with ADHD. I am sorry that as a parent this is an aspect you dont see, but your kid will need to deal with it and many other struggles that you will never experience first hand. reply btilly 12 hours agorootparentI&#x27;m sorry that you are struggling with the concept of objective reality.The statistics that I quoted are real. This isn&#x27;t a question of matching your perception of reality. It is a question of what is actually true.The number of people prescribed ADHD medications is several times the estimated number of people with ADHD. I isn&#x27;t hard to find people with questionable ADHD diagnoses. I already said that there are people with real diagnoses who struggle to get diagnosed properly. I&#x27;m sorry that you are one of them. My daughter happens to be another.Oh, and here&#x27;s another point from reality. ADHD is genetic. My son got it from me. I am also likely where he got his inability to tolerate regular use of Adderall. So the next time you fi",
    "originSummary": [
      "The America the Beautiful - The National Parks and Federal Recreational Lands Access Pass, a free pass available to US citizens or permanent residents with enduring disabilities, can be obtained in person or online.",
      "Applicants must furnish documents evidencing their permanent disability to acquire the pass.",
      "The Interagency Access Pass aids people with disabilities by providing easier access to national parks and federal recreational lands."
    ],
    "commentSummary": [
      "The discussions cover a range of topics including difficulties experienced by individuals with disabilities, the reassessment of ADHD as a disability, and the broader understanding and perception of disabilities in society.",
      "It also addresses matters concerning healthcare, housing, and the effects of ADHD on individuals' lives.",
      "The conversations express a variety of opinions and viewpoints."
    ],
    "points": 402,
    "commentCount": 278,
    "retryCount": 0,
    "time": 1697062093
  },
  {
    "id": 37854846,
    "title": "Introduction to Modern Statistics",
    "originLink": "https://openintro-ims2.netlify.app/",
    "originBody": "Introduction to Modern Statistics (2nd Ed) Welcome to IMS2 Authors Preface Introduction to data 1 Hello data 2 Study design 3 Applications: Data Exploratory data analysis 4 Exploring categorical data 5 Exploring numerical data 6 Applications: Explore Regression modeling 7 Linear regression with a single predictor 8 Linear regression with multiple predictors 9 Logistic regression 10 Applications: Model Foundations of inference 11 Hypothesis testing with randomization 12 Confidence intervals with bootstrapping 13 Inference with mathematical models 14 Decision Errors 15 Applications: Foundations Statistical inference 16 Inference for a single proportion 17 Inference for comparing two proportions 18 Inference for two-way tables 19 Inference for a single mean 20 Inference for comparing two independent means 21 Inference for comparing paired means 22 Inference for comparing many means 23 Applications: Infer Inferential modeling 24 Inference for linear regression with a single predictor 25 Inference for linear regression with multiple predictors 26 Inference for logistic regression 27 Applications: Model and infer Appendices A Exercise solutions B References Table of contents Welcome to IMS2 Edit this page Report an issue Introduction to Modern Statistics (2nd Ed) Welcome to IMS2 This is the website for Introduction to Modern Statistics, Second Edition by Mine Çetinkaya-Rundel and Johanna Hardin. Introduction to Modern Statistics, which we’ll refer to as IMS going forward, is a textbook from the OpenIntro project. Copyright © 2023. Second Edition. Version date: September 10, 2023. This textbook and its supplements, including slides, labs, and interactive tutorials, may be downloaded for free at openintro.org/book/ims. This textbook is a derivative of OpenIntro Statistics 4th Edition and Introduction to Statistics with Randomization and Simulation 1st Edition by Diez, Barr, and Çetinkaya-Rundel, and it’s available under a Creative Commons Attribution-ShareAlike 3.0 Unported United States License. License details are available at the Creative Commons website: creativecommons.org. Source files for this book can be found on GitHub at github.com/OpenIntroStat/ims. Authors This is IMS2e! This book was built with Quarto.",
    "commentLink": "https://news.ycombinator.com/item?id=37854846",
    "commentBody": "Introduction to Modern StatisticsHacker NewspastloginIntroduction to Modern Statistics (openintro-ims2.netlify.app) 346 points by noelwelsh 6 hours ago| hidepastfavorite68 comments dleeftink 4 hours agoAnyone looking to apply and compare frequentist and bayesian methods within a unified GUI (which is essentially an elegant wrapper to R and selected&#x2F;custom statistical packages), should check out JASP developed by the University of Amsterdam [0]. It&#x27;s free to use, and the graphs + captions generated during each step are publication quality right out of the box.Using it truly feels like a &#x27;fresh way&#x27; to do statistics. Its main website provides ample use cases, guides and tutorials, and I often return to the blog for the well documented deepdives into how traditional frequentist methods and their bayesian counterparts compare (the animated explainers are especially helpful, and I appreciate the devs reflecting on each release and future directions).[0]: https:&#x2F;&#x2F;jasp-stats.org&#x2F; reply NeutralForest 2 hours agoparentthere was an interview of one of the JASP (creator or maintainer, can&#x27;t remember) in the \"Learn Bayesian Stats\" podcast; it was very interesting. reply rdhyee 13 minutes agorootparentI think the referenced episode is https:&#x2F;&#x2F;learnbayesstats.com&#x2F;episode&#x2F;61-why-we-still-use-non-... Thanks for pointing it out! reply epgui 1 hour agoprevAs much as I appreciate and love all pedagogical endeavours in the field, especially in the form of open texts, I really, really, really dislike this overall approach to teaching introductory statistics.I&#x27;m hoping to see, over time, a shift away from ad-hoc null hypothesis testing in favour of linear models (yes, in introductory courses, from the start-- see link below) and Bayesian-by-default approaches.https:&#x2F;&#x2F;lindeloev.github.io&#x2F;tests-as-linear&#x2F;#:~:text=Most%20.... reply bschne 1 hour agoparentI am partway through McElreath&#x27;s \"Statistical Rethinking\" and I fully agree with this. reply epgui 1 hour agorootparentThat&#x27;s a great textbook! reply begemotz 1 hour agoparentprevI agree about teaching from a unified GLM basis. The &#x27;bayesian-by-default&#x27; approach seems to going out on a more tenuous limb, imo. reply JHonaker 1 hour agorootparentIt&#x27;s only appears tenuous because the subjective choices you have to make when using frequentist methods are made for you by the developer of the method.It&#x27;s less comfortable to use Bayesian methods because you have to be explicit about your assumptions as the user, which opens your assumptions up for easier inspection. There&#x27;s also way less specific information implied by priors than most people think. Informative priors should try to make distinctions between something that&#x27;s reasonable-ish and something that&#x27;s essentially infinity (take pharmacokinetics for example, the diffusion velocity of a molecule in your blood stream shouldn&#x27;t have a velocity near the speed of light in a vacuum should it?). They should not be forcing your model to achieve a particular result. Luckily, because of the need to explicitly state them in a Bayesian analysis, it&#x27;s much easier to determine if they were properly set.Prior specification is essentially problem domain-informed regularization where you can actually hope to understand if the hyperparameter is going to work or not. reply noelwelsh 5 hours agoprevStatistics education is undergoing a bit of a revolution, driven by the accessibility of computers. For example, hypothesis testing is introduced by randomization[1], using a randomized permutation test[2]. I find this really easy to understand, compared to how I learned statistics using a more traditional approach. The traditional approach taught be a cookbook of hypothesis tests to use: use the t-test in this situation, use the chi-squared in this situation, and so on. I never gained any understanding of why I should use these different tests, or where they came from, from the cookbook approach.For the same approach in a slightly different context see [3].[1]: https:&#x2F;&#x2F;openintro-ims2.netlify.app&#x2F;11-foundations-randomizat...[2]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Permutation_test[3]: https:&#x2F;&#x2F;inferentialthinking.com&#x2F;chapters&#x2F;11&#x2F;1&#x2F;Assessing_a_Mo... reply usgroup 3 hours agoparentI&#x27;ve had similar thoughts, but I think its more to do with what is in your head at the time you hear about it. I found permutation tests satisfying to learn about because they somehow helped consolidate what I knew from distribution theory. If I didn&#x27;t know any distribution theory prior, I&#x27;m not sure they could have that effect.If you study mathematical statistics, it is not taught as a cookbook. At the elementary level you learn probability theory and distribution theory, all the different distributions, hypothesis tests, regression, ANOVA and so on proceed from there. Meanwhile, I think research scientists are often taught statistics as a set of recipes because its usually a short course for a specific discipline. E.g. Statistics for biologists. reply ImaCake 2 hours agorootparentI think those short courses would be more effective if they didn&#x27;t bother with ANOVA and instead taught intro probability and distributions and then jumped straight to regression. ANOVA is just a really specific way of doing a regression.In R, and python::statsmodels you get the answer to (essentially) an ANOVA any time you run an LM or GLM; its the Z-statistic for your whole model.I know there is more nuance to this, but teaching students that they can use regression for most of the problems they would have used seemingly arcane tests for is going to be much more useful for the students.Here is a lovely page demonstrating how to do this in R: https:&#x2F;&#x2F;lindeloev.github.io&#x2F;tests-as-linear&#x2F; reply usgroup 48 minutes agorootparentI agree with the sentiment although I&#x27;m not sure there is the time for all of it. At least when I took them, probability theory and distribution theory were separate semester long courses, and the former was a prerequisite for the latter. reply iTokio 3 hours agoparentprevThere is also Brillant that has a very polished interactive course:https:&#x2F;&#x2F;brilliant.org&#x2F;courses&#x2F;statistics&#x2F; reply usgroup 3 hours agorootparentThese things are great if they add value for you, but I would be very skeptical of any non-mathematical approach to statistics. I think statistics is only made clear by mathematics, much the same as Physics. And one cannot grasp statistics without being able to understand the maths.I think that still the best way to understand statistics is to start with the mathematical theory and to grind 1000+ textbook problems. reply mkl 2 hours agorootparent> I think that still the best way to understand statistics is to start with the mathematical theory and to grind 1000+ textbook problems.Are there any books you&#x27;d recommend for this approach? reply usgroup 55 minutes agorootparentMy grind was \"Mathematical Statistics with Applications\" by Wackerly et al. There are PDF versions if you Google for it. I can&#x27;t say it was quick, easy or intuitive; but it works.I also liked \"In all Likelihood\" by Pawitan for a \"likelihoodist\" foundational approach. reply dr_dshiv 1 hour agoparentprevDo you know of any validation studies with Advanced Data Analysis (formerly code interpreter) in chatGPT? I think it can be excellent as a teaching tool. reply mjburgess 3 hours agoprevWhat&#x27;s often missing from these introductions is when statistics will not work; and what it even means when it \"works\". The amount of data needed to tell between two normal is about 30 data points -- between two power-law distributions, >trillion. (And this basically scuppers the central limit theorem, on which a lot of cargo-cult stats is justified).Stats, imv, should be taught simulation-first: code up your hypotheses and see if they&#x27;re even testable. Many many projects would immediately fail at the research stage.Next, know that predictions are almost never a good goal. Almost everything is practically unpredictable -- with a near infinite number of relevant causes, uncontrollable.At best, in ideal cases, you can use stats to model a distribution of predictions and then determine a risk&#x2F;value across that range. Ie., the goal isnt to predict anything but to prescribe some action (or inference) according to a risk tolerance (risk of error, or financial risk, etc.).It seems a generation of people have half-learned bits of stats, glued them together, and created widespread &#x27;statistical cargo-cultism&#x27;.The lesson of stats isnt hypothesis testing, but how almost no hypotheses are testable -- and then what do you do reply 0xDEAFBEAD 55 minutes agoparent>The amount of data needed to tell between two normal is about 30 data pointsWhat are you trying to say here? If there are two normal distributions, both with variance one, one having mean 0 and the other having mean 100, and I get a single sample from one of the distributions, I can guess which distribution it came from with very high confidence. Where did the number 30 come from? reply Ensorceled 2 hours agoparentprevIt&#x27;s ironic that this ... rant? ... is basically unreadable without knowledge of basic statistical methods.How do you teach any of this to someone who hasn&#x27;t already taken introductory statistics? How do you learn anything if you first have to learn the myriad ways something you don&#x27;t even have a basic working knowledge of can fail before you learn it? reply mjburgess 2 hours agorootparentThe comment is addressed to the informed reader who is the only one with a hope of being persuaded on this point.To teach this, from scratch, I think is fairly easy -- but there&#x27;s few with any incentive to do it. Many in academia wouldnt know how, and if they did, would discover that much of their research can be shown a priori to not be worthwhile (rather than after a decade of &#x27;debate&#x27;).All you really need is to start with establishing an intuitive understanding of randomness, how apparently highly patterned it is, and so on. Then ask: how easy is it to reproduce an observed pattern with (simulated) randomness?That question alone, properly supported via basic programming simulations, will take you extremely far. Indeed, the answer to it is often obvious -- a trivial program.That few ever write such programs shows how the whole edifice of stats education is geared towards confirmation bias.Before computers, stats was either an extremely mathematical disipline seeking (empirically useless) formula for toy models; or using heuristic empirical formula that rarely applied.Computers basically obviate all of that. Stats is mostly about counting things and making comparisons -- perfect tasks for machines. with only a few high-school mathematical formula most could derive most useful statistical techniques as simple computer programs. reply noelwelsh 2 hours agorootparentThe modern approach, of which this textbook is an example, does start with simulation. In fact there is very little classical statistics (distributions, analytic tests) in the book. The Berkeley Data 8 book, which I link to in another comment, takes the same approach. I imagine there is still too much classical material for your tastes, but there is definitely change happening. reply 2devnull 1 hour agorootparentprev“ that much of their research can be shown a priori to not be worthwhile”Bingo. Cargo cult stats all the way down. It’s not just personal interest, it’s the entire field, it’s their colleagues, mentors, and students. Good luck getting somebody to see the light when not just their own income depends on not seeing it, their whole world depends on the “stat recipes” handed down from granny. reply brutusborn 41 minutes agorootparentI think the egotistical aspect is the most powerful: many researchers have built an identity based on the fact that they “know” something, so to propose better alternatives to their pet theories is tantamount to proposing their life is a lie. To change their mind they need to admit they didn’t “know”.The better the alternatives, the more fierce the passion with which they will be rejected by the mainstream. reply Retric 1 hour agorootparentprevIt seems like a reasonable critique. The suggestion is to include such ideas as people are taking introductory statistics which isn’t inappropriate. I wouldn’t suggest forcing students to code up their own simulations from scratch, but creating a framework where students can plug in various formula for each population, attach a statistical test, and then run various simulations could do quite a bit. However, what kinds of formula students are told to plug in are important.If every formula is producing bell curves then that’s a failure to educate people. 50d6 vs 50d6 + 1 is easy enough you can include 1d2 * 50 + 50d6 for a 2 tailed distribution, but also significantly different distributions which then fail various tests etc.I’ve seen people correctly remember the formula for statistical tests from memory and then wildly misapply them. That seems like focusing on the wrong things in an age when such information is at everyone’s fingertips, but understanding of what that information means isn’t. reply taeric 1 hour agoparentprevModel building, at large, is the thing I regret being bad at. Model your problem and then throw inputs at it and see what you can see.Sucks, as we seem to have taught everyone that statistical models are somehow unique models that can only be made to get a prediction. To the point that we seem to have hard delineations between \"predictive\" models and other \"models.\".I suspect there are some decent ontologies there. But, at large, I regret that so many won&#x27;t try to build a model. reply srean 1 hour agoparentprevI work in applied ML and stats. Whenever a client gets pushy about getting a prediction and would not care about quantifying the uncertainty around it, I take it as a signal to disengage and look for better pastures. It is really not worth the time, more so if you value integrity.Competent stakeholders and decision makers use the uncertainty around predictions, the chances of an outcome that is different from the point-predicted outcome, to come to a decision and the plan includes what the course of action should be should the outcome differ from the prediction. reply armcat 1 hour agoprevOne of my favourite books on statistics and probability is \"Regression and Other Stories\", by Andrew Gelman, Jennifer Hill and Aki Vehtari. You can access the book for free here: https:&#x2F;&#x2F;users.aalto.fi&#x2F;~ave&#x2F;ROS.pdf reply epgui 1 hour agoparent+1, this is a great textbook, and not just for social sciences as the second header would suggest. reply jna_sh 5 hours agoprevVery excited to see Mine Çetinkaya-Rundel is an author here! Many might be familiar with “R for Data Science” (https:&#x2F;&#x2F;r4ds.had.co.nz&#x2F;), to which she is a contributor, but she’s also published a lot of great papers around teaching data science. reply ayhanfuat 4 hours agoparentShe also has some online courses on Coursera (https:&#x2F;&#x2F;www.coursera.org&#x2F;instructor&#x2F;minecetinkayarundel). Hands down one of the best instructors I have seen. reply growingkittens 1 hour agoprevIs there a \"pre-statistics\" book that teaches the thinking skills and concepts needed to understand statistics? reply ndr 1 hour agoparentThis book seems to start where you need it to start.You don&#x27;t need much beyond basic calculus. Most suffer from some mental block they got installed at a young age akin those that say \"I&#x27;m bad at math\" because their teacher sucked. Dive in and you won&#x27;t regret it. reply growingkittens 1 hour agorootparentMy mental block is a brain injury that went undiagnosed until I was 30. I can&#x27;t really hold more than two numbers in my head at a time. I struggled through math in school because it was lecture based, and the books were written to accompany a lecture.I can learn math fairly well if I have the right written material and the right direction. However, I do not retain math skills: without active practice, I revert back to \"how do fractions work?\"For example, I did extremely well in a college algebra course that was partially online (combined with Khan Academy to catch up). I could do my tests perfectly in pen, much to the amusement of the assistants. I could make connections and see the implications and applications of the math. Roughly three to six months later, I was back to forgetting fractions.I can&#x27;t learn these things over time, but I can learn them all at once. I&#x27;m collecting resources for my next math adventure. reply obscurette 1 hour agorootparentprevI have been a math teacher and although I can&#x27;t guarantee that I didn&#x27;t suck, I can say that most of kids don&#x27;t develop this attitude because of teachers, but because of their parents. \"My mum says that she sucked at math&#x2F;music&#x2F;whatever as well, so do I!\" is far too common. As a teacher I just didn&#x27;t have resources to influence this attitude either. reply ndr 39 minutes agorootparentYes, parents can be horrible too. Unfortunately it&#x27;s somehow socially acceptable and even worthy of pride in some circles, to be \"bad at math\". It&#x27;s seems very rare for someone to openly say \"I&#x27;m bad at [my native language]\" or \"writing\".I feel stats is has a somewhat similar effect even among those with math education. Several friends who have a degree in math recoil at the first mention of stats concepts. reply willsmith72 26 minutes agoprevThe epub is apparently too big to send to a kindle, but I can&#x27;t see the option to download it, only the pdf. Any ideas? reply usgroup 3 hours agoprevI think Ronald Fisher may not have used bootstrap to calculate confidence intervals; but it looks to me like he invented most of the rest of the syllabus .. in the early 1900s :-) reply zvmaz 4 hours agoprevWhat is a good book on statistics that one can use for self-learning? reply dan-robertson 4 hours agoparentI like statistical rethinking. It’s targeted at science phd students so the focus is “how can you use statistics for testing your scientific hypotheses and trying to tease out causation”. It doesn’t go deep into the mathematics of things (though expects readers to be decently numerate and comfortable analysing data without statistics). It only really talks about Bayesian models and how to fit them by computer, so won’t cover much of the frequenting side of things at all. reply noelwelsh 4 hours agoparentprevDepends where you are starting from and what you want to learn. The linked book is a first year introduction, and does a good job of that. If you want to go further there are many other options:* Statistical Inference by Casella and Berger. This book has a very good reputation for building statistics from first principles. I won&#x27;t link to them, but you can find full PDF scans online with a simple search. Amazon reviews: https:&#x2F;&#x2F;www.amazon.com&#x2F;Statistical-Inference-Roger-Berger&#x2F;dp...* Statistics by Freedman, Pisani, and Purves has similarly very good reviews and can be easily found online. Amazon reviews: https:&#x2F;&#x2F;www.amazon.com&#x2F;Statistics-Fourth-David-Freedman-eboo...* The majority of the Berkeley data science core curriculum books are online. This is not purely statistics but 1) is taught in a modern style that makes use of computation and randomization and 2) uses tools that may be useful to learn about.1. https:&#x2F;&#x2F;inferentialthinking.com&#x2F;chapters&#x2F;intro.html (Data 8)2. https:&#x2F;&#x2F;learningds.org&#x2F;intro.html (Data 100)3. http:&#x2F;&#x2F;prob140.org&#x2F;textbook&#x2F;content&#x2F;README.html (Data 140)4. https:&#x2F;&#x2F;data102.org&#x2F;fa23&#x2F;resources&#x2F;#textbooks-from-previous-... (Data 102; this gets into machine learning and pure statistics)The Berkeley curriculum is not the only one; there are tens, possibly hundreds, of online courses. The Berkeley curriculum is just 1) quite extensive and 2) the one I happened to read the most about when I was recently researching how data science is currently taught. reply sudoankit 4 hours agoparentprevI particularly like Statistical Inference by George Casella and Roger Lee Berger.You could also look at Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang (available for free here: http:&#x2F;&#x2F;probabilitybook.net (redirects to drive)). reply laichzeit0 1 hour agorootparentShould be noted that Casella’s book is… well… really great if you thought Spivak’s calculus and Rudin’s analysis to be fun books, especially the exercises.Casella’s exercises are absolutely brutal. reply dtjohnnyb 4 hours agoparentprevA couple of more introductory books that come at it from the point of view of \"someone who can code\" are: - https:&#x2F;&#x2F;greenteapress.com&#x2F;wp&#x2F;think-stats-2e&#x2F; (and the similar Think Bayes if you enjoy this one) - https:&#x2F;&#x2F;nostarch.com&#x2F;learnbayesCan second Statistical Rethinking though if you have the basics of stats and want to learn it again from a very different, more causal&#x2F;bayesian point of view. reply begemotz 3 hours agoparentprevWhat is your background and what field will you be applying your knowledge to?There can be a rather wide gap between a theoretical approach that you might encounter as taught by a statistician and an applied approach you might encounter in a business statistics or social science statistics course.Depending on your math background and the area of intended application, in my opinion, it would sway recommendations for a first &#x27;book&#x27; on statistics for self-learning. reply verbify 4 hours agoparentprevISLR&#x2F;ISLP is free, was used in my masters and is excellent (and has an accompanying video series)https:&#x2F;&#x2F;www.statlearning.com&#x2F; reply begemotz 3 hours agoprevI like the inclusion of randomization and bootstrapping. It&#x27;s unfortunate that the hypothesis framework is still NHST -- I wouldn&#x27;t consider that &#x27;modern&#x27; by any means. reply noelwelsh 3 hours agoparentI don&#x27;t see widespread agreement in the statistics community as to what should replace NHST. If you go Bayesian you need to completely rewrite the course. I&#x27;ve seen confidence intervals suggested as an alternative, but there are arguments against. I&#x27;ve also seen arguments that hypothesis tests shouldn&#x27;t be used at all. Given that NHST is still widely used and there isn&#x27;t a clear alternative I think it&#x27;s a disservice to students to not introduce them. reply begemotz 3 hours agorootparentI probably should have been more clear. I didn&#x27;t say hypothesis testing, I said NHST (the binary null&#x2F;alt hypothesis approach) - which is an approach to hypothesis testing particularly prevelant in certain disciplines such as Psychology.And in that context, there is a lot of agreement that this approach is fundamentally flawed and outdated. if you are interested, I can provide references when I get to the office. But off the top of my head consider Gigerenzer and Cummings. reply noelwelsh 1 hour agorootparentFor those following along at home Gigerenzer is, I think, \"Mindless Statistics\"[1] and Cummings is \"The New Statistics\"[2].[1]: https:&#x2F;&#x2F;pure.mpg.de&#x2F;rest&#x2F;items&#x2F;item_2101336&#x2F;component&#x2F;file_2... [2]: Sample at https:&#x2F;&#x2F;tandfbis.s3.amazonaws.com&#x2F;rt-media&#x2F;pp&#x2F;common&#x2F;sample-... reply begemotz 1 hour agorootparentYes, those are appropriate (although Gigerenzer and Cummings both have other relevant publications on the topic).As for a undergraduate text that &#x27;teaches the difference&#x27;, you can look at &#x27;An Introduction to Statistics&#x27; by Carlson & Winquist. replyelashri 1 hour agoprevThanks to the author for the book and making it open access. I always admire these efforts. reply ricksunny 4 hours agoprevI&#x27;m looking for help with distilling &#x27;truth&#x27; from folk belief systems by formalizng them under a Bayesian network framework, in case anyone is looking for a project through which to sharpen their statistical saw. reply RedShift1 3 hours agoprevCan I download this as a PDF? I&#x27;d like to read it offline. reply noelwelsh 3 hours agoparentHere: https:&#x2F;&#x2F;www.openintro.org&#x2F;book&#x2F;ims&#x2F; reply RedShift1 1 hour agorootparentThis is the first version, not the 2nd? reply noelwelsh 1 hour agorootparentHmmm ... must be because the 2nd edition is still in progress. Best option might be to follow the immortal words of Obiwan Kenobi and \"use the source\": https:&#x2F;&#x2F;github.com&#x2F;OpenIntroStat&#x2F;imsOtherwise you can try building a PDF from the very similar Data 8 book[1] using [2][1]: https:&#x2F;&#x2F;github.com&#x2F;data-8&#x2F;textbook[2]: https:&#x2F;&#x2F;jupyterbook.org&#x2F;en&#x2F;stable&#x2F;advanced&#x2F;pdf.html reply d00mer 4 hours agoprev [–] They should remove \"modern\" from the title, because who the hell uses the \"R programming language\" these days anymore? reply i_love_limes 4 hours agoparentA lot of people... in fact a huge portion of statisticians, epidemiologists, econometrics, use it as their primary language.I do genetic epidemiology (which is considerably more compute intensive than regular epidemiology), and R is still the most common language, with the most libraries and packages being used for it, compared to python for example.I think maybe you should consider being less forthcoming with your opinions on topics which you are not well informed on. reply nomilk 4 hours agoparentprevBefore I knew command line, I tried to install python and spent the next 3 days resolving an installation issue with &#x27;wheel&#x27;.By contrast, from first downloading R to running my first R script took about 1 hour (the most difficult part was opening the &#x27;script&#x27; pane in RStudio IDE, which doesn&#x27;t open by default on new installations, for some reason).There&#x27;s huge demand out there for statistical software that&#x27;s accessible to people whose primary pursuit is not programming&#x2F;cs, but genetics, bioinformatics, economics, ecology and other disciplines that necessitate tooling much more powerful than excel, but with barriers to entry not much greater than excel. R is a fairly amazing fit for those folks. reply Onawa 4 hours agoparentprevEveryone in my branch of Toxicology? Tons of people in biological sciences. Just because you have bias against the tool and don&#x27;t run in the same circles doesn&#x27;t mean that R isn&#x27;t used and love by a subset of devs. reply MilStdJunkie 3 hours agoparentprevRespectfully, I&#x27;m going to ask, \"what what?\". I can&#x27;t swing a cat without hitting dplyr. It&#x27;s probably industry dependent though - I could see a dataset that&#x27;s 99% text having absolutely no reason to even look at R at all. reply adr1an 4 hours agoparentprevEveryone but you. Check any statistics journal. Only a few people developing methods switched to Python or Julia. reply epgui 1 hour agoparentprevProbably most people who do statistics.R sucks as a language but it excels at that specific application, just because of its tremendous ecosystem (putting even python to shame in some niche areas). reply dereify 4 hours agoparentprevfyi many state-of-the-art statistical libraries exist (or are properly maintained) in R only reply ImaCake 2 hours agorootparentI find it depends on what you want. There is no canonical GAM (gen. addative model) library in python but there are a few options - which are not easy to use. The statsmodels GAM implementation appears to be broken. R, of course, has a stupid easy to use GAM library that is pretty fast.On the other hand, R has too many obscure options for what I can find in scipy or sklearn. So I find it easier to just jump into sklearn, use the very nice unified interface \"pipelines\" to churn through a whole bunch of different estimators without having to do any munging on my data.So I think it just depends on your field. But R seems to stick more with academia. reply f6v 1 hour agoparentprevMost people in bioinformatics. reply noelwelsh 4 hours agoparentprev [–] Statisticians do. The Berkeley curriculum, which I&#x27;ve linked to in another comment, uses Python. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Introduction to Modern Statistics (2nd Ed)\" is a textbook authored by Mine Çetinkaya-Rundel and Johanna Hardin, derived from previous editions by Diez, Barr, and Çetinkaya-Rundel.",
      "The book is available for free download, providing access to affordable educational material to students and enthusiasts alike.",
      "The book is licensed under the Creative Commons Attribution-ShareAlike 3.0, which permits and encourages the distribution and sharing of the work."
    ],
    "commentSummary": [
      "The post discusses the application of modern statistics and software called JASP to compare frequentist and Bayesian methods, which are statistical approaches to interpreting data.",
      "The author advocates a shift towards the use of linear models and Bayesian techniques in statistics education, suggesting a need for a transformation in the current teaching methods.",
      "The discussion includes personal struggles with math, possible negative attitudes towards it, and book recommendations for learning statistics, specifically highlighting \"Statistics\" by Carlson & Winquist. Commenters are interested in learning more about the application of Bayesian network frameworks and the use of the R programming language."
    ],
    "points": 337,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1697100310
  },
  {
    "id": 37846471,
    "title": "How to legally pirate every font",
    "originLink": "https://blog.willdepue.com/how-to-legally-pirate-all-fonts-in-an-afternoon",
    "originBody": "LOGIN Will DePue « Back to blog How to legally pirate every font on Earth in an afternoon I really love good fonts. I recently encountered the familiar moral dilemma of a building a project that begged for a better, licensed font while not wanting to burn hundreds of dollars on something I’ll only care about for a week. In this, I jumped down a rabbit hole to try to answer the question of ‘how bad it actually is to use unlicensed fonts on the web.’ To my surprise here, US copyright law doesn’t actually allow for copyright of the individual glyphs (the lines, curves, points, etc.), so font makers instead usually rely on the copyright of the font file itself, which can be copyrighted as unique software! Unsurprisingly, there’s lots of complexity to how this copyright works (perhaps intentionally). Here’s my understanding: There’s a long-standing standard, dating back before the digital age, that typefaces are “utilitarian and functional” technologies and therefore cannot be copyrighted in and of themselves. Typeface designs have been traditionally seen as “ideas or systems” that are used for representing letters and numbers, rather than as unique expressions or artworks. Instead, most type foundries protect their fonts by copyrighting the font files themselves, which has been allowed under the notion that there is specific creative effort required in creating the software itself and the different strategies to render the font at different scales, print sizes, etc. Very rarely, font makers have been granted design patents for their work if deemed innovative or so creative as to merit such. These are relatively uncommon as they are more rarely granted, as well as only lasting 15 years before permanently entering public domain (compared to the ability to infinitely renew trademarks or the 95 years or author lifetime + 70 granted for other copyrighted materials). This doesn’t mean that trademarks that use a certain font can’t be protected, though. Obviously, you can’t copy the CocaCola logo design, but further distinct usage of a font can also be trademarked (like Off-White™, with its famously obsessive use of Helvetica). You also still can’t buy a font, modify it, and send it to all your friends. Most fonts come with licenses that prohibit you from copying, modifying, creating derivative works. Since you’re entering into a legal agreement with the type foundry themselves, they can put whatever limits on how you can use the font, regardless of local copyright law. For an example, check out Berkeley Graphics’ license. The key point here is that the shape of the glyphs themselves, for example, non-trademarked text posted on advertisements or products with printed text, are not copyrightable. So long as you’re not stealing the creative work, like the advertisement, itself, the shape of each letter is in the public domain. This got me thinking, as all things do, on whether I could simply scrape the internet for public, non-creative, non-trademarked use of fonts (of which there is lots and lots of content and only 128 or so characters in each Unicode character set) which I could use to reconstruct every licensed font in existence. Only problem is that it’s not that simple. Fonts are exceedingly complex. You’ll know that the fact that the average font just ‘looks right’ is absolutely magical if you’ve ever tried to create your own font. Mainly, this is due to good kerning, the individual spacing between each letter and another. It might come as a surprise that not only does every character have different whitespace between it and other characters, but each actually has unique whitespace between it and every pair of possible following characters. If I’m going to do this correctly, I’ll need to scrape the internet not for all individual characters of a font, but for all possible pairs of characters. That’s 16256 different combinations per font. Thank god the internet is just pretty big. There’s also lots of other different asterisks here (spacing, ligatures, handling numbers, etc.) but for now I’m just going to focus on getting the pipeline working. I’ve started with a set of simple images of a font that I would want to replicate, then use Meta’s Segment Anything Model (for no reason besides I already had it setup on my computer) to select and cut out each individual character. We’re only working with black and white images with none/low background noise such that converting from pixels to curves is fairly trivial. Now that I have individual character PNGs, I’ll just boost the contrast just to be safe. You can run this in the command line pretty much: convert input_char.png -contrast output_char.png Once we’re sure we have high contrast images, we can use cutting edge computer vision AI ML technology by running software first released in 2001: potrace input.png -s -o output.svg Now that we have the SVGs, FontForge has an excellent python package for programmatically generating fonts. import fontforge svgs = [...] font = fontforge.font() for unicode, letter in svgs:glyph = font.createChar(unicode_val, letter)glyph.importOutlines(f'{letter}.svg')glyph.autoWidth() font.familyname = 'NotHelvetica' font.fullname = 'NotHelvetica' font.generate('NotHelvetica.ttf') And there you have it! A complete bastardization of the source font, lacking proper kerning, metadata, em size, bitmaps, ligatures, x-height, etc. If you were going to try to get kerning correct here, the best process might be something like collecting and splitting all letter pairs, then using OpenCV to find the distance from each character’s edges to calculate the kerning value. import cv2 import fontforge def get_kerning(image_path):img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)_, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)contours.sort(key=lambda x: cv2.boundingRect(x)[0])x1, y1, w1, h1 = cv2.boundingRect(contours[0])x2, y2, w2, h2 = cv2.boundingRect(contours[1])kerning_value = x2 - (x1 + w1)return kerning_value characters = [...] font = ... for char_1 in characters: for char_2 in characters: kerning_value = get_kerning_from_image(f'{char1}-{char2}.png') font[char1].addPosSub('kern', char2, kerning_value) In terms of finding a dataset of images of fonts, I’d look into the large existing internet datasets out there. For example, I did a quick search of LAION-5B and there’s infinite images for any given font as a prompt, though there would be work needed to verify that all images wouldn’t fall under improper copyright. I’m not very interested in carrying out this project in full for somewhat obvious reasons (somewhat significantly being disinterested in spending tens of hours collecting and labeling data now that I know it works). As a big fan of typography in general it’s pretty obviously wrong that fonts not be able to be claimed as creative work that deserves to be copyrighted, though I can see how fonts used to play a far more essential and utilitarian role in society. Unfortunately, it seems that this is pretty much black-letter law at this point and there isn’t much hope for it changing in the future. If any brave souls are interested in legally pirating all existing fonts and being taken to court, I think you’d likely be doing a service to society here by challenging this ruling. Final reminder that I’m not a lawyer and have no clue if anything I said is actually correct, so none of this is legal advice and I strongly recommend you go talk to a lawyer before attempting anything here. I’d also strongly emphasize the importance of supporting the incredible work behind your favorite typefaces by purchasing fonts directly, I definitely do not advocate ever for stealing anyone’s work. Thanks for reading! — Will DePue (will@depue.net) Like this post? Subscribe by email 0 responses Your Name Email Add Website URL » Your Comment Notify me by email when new comments are added for current work & past projects visit http://depue.design Posted yesterday October 10, 2023 at 11:40 PM 32397 views",
    "commentLink": "https://news.ycombinator.com/item?id=37846471",
    "commentBody": "How to legally pirate every fontHacker NewspastloginHow to legally pirate every font (willdepue.com) 316 points by flobosg 22 hours ago| hidepastfavorite139 comments r3trohack3r 20 hours agoFun to think about, have personally gone down this rabbit hole before, but I&#x27;d be surprised if this was permitted by courts.> The key point here is that the shape of the glyphs themselves, for example, non-trademarked text posted on advertisements or products with printed text, are not copyrightable. So long as you’re not stealing the creative work, like the advertisement, itself, the shape of each letter is in the public domain.There is a jump from this assertion to:> This got me thinking, as all things do, on whether I could simply scrape the internet for public, non-creative, non-trademarked use of fontsThe missing step here is that the glyphs for a webpage are not embedded in some sort of rendered image or physical medium. They&#x27;re _rendered from the copyrighted font file_ to the browser.The font file is delivered to the browser and that copyrighted file is used to render the glyphs.This pipeline might work for creating a font that is \"inspired by\" the available glyphs rendered in the credits of your favorite film.But downloading the entire copyrighted font file, generating a character sheet from it and clipping the individual characters from that sheet? I can&#x27;t imagine how any sensible court system would not consider that a derivative work. reply viraptor 20 hours agoparent> But downloading the entire copyrighted font file, generating a character sheet from it and clipping the individual characters from that sheetThat&#x27;s not what this project is doing. It&#x27;s extracting the characters from already published pictures, without touching the original font files at all. reply abirch 20 hours agoparentprevI believe he&#x27;s downloading png files from Meta, converting them to SVG, then creating the glyphs. I&#x27;m not sure what the law is on this, but there&#x27;s no need for the font files to ever be on your computer. E.g., https:&#x2F;&#x2F;render.myfonts.net&#x2F;fonts&#x2F;font_rend.php?id=a6719376b9... reply codedokode 19 hours agorootparentMicrosoft does exactly this with 19th and 18th century fonts, for example [1].[1] https:&#x2F;&#x2F;learn.microsoft.com&#x2F;ru-ru&#x2F;typography&#x2F;font-list&#x2F;baske... reply tuukkah 16 hours agorootparentThose are probably in public domain because of their age though. reply remram 11 hours agoparentprevYeah this is similar to how facts are not copyrightable, but data is. You can&#x27;t just extract rows out of a data file one-by-one, into a variable named \"just_a_fact\", put it back into a new file and pretend that you didn&#x27;t derive it from the original.Courts are not dumb. Trying to scale up a technicality to circumvent the law usually does not fly. reply sokoloff 5 hours agoparentprevSee page 3 here: https:&#x2F;&#x2F;www.copyright.gov&#x2F;circs&#x2F;circ33.pdf“Works not protected by copyright”And 906.4 here: https:&#x2F;&#x2F;www.copyright.gov&#x2F;comp3&#x2F;chap900&#x2F;ch900-visual-art.pdfIt may be considered a derivative work, but that doesn’t matter if it’s a derivative of only the portion of the original work (the glyph shapes) that cannot be copyrighted as a matter of law. reply bitwize 19 hours agoparentprevIf this were a legal issue it can be gotten around the same way the IBM BIOS copyright was circumvented: with a clean room reimplementation. Team A renders the text with the copyrighted font files; Team B, otherwise not in contact with Team A, scrapes Team A&#x27;s text images, vectorizes them, and imports them into FontForge. reply jrockway 17 hours agorootparentYeah, you&#x27;re using the Internet as Team A in the author&#x27;s example. You&#x27;re looking for images of fonts. The people that made those images bought a license to use the font to make images, so it&#x27;s fine if they share them with you.None of that guarantees you&#x27;ll be free from legal concerns, of course. Maybe the original image author didn&#x27;t have a license. Maybe the licensor thinks they can change the terms of the contract at will. You&#x27;ll probably be caught in the middle of all of this.My take is that the biggest problem you&#x27;ll find is naming your free fonts. Someone probably owns the word \"Helvetica\", so you&#x27;ll have to call it something else. Someone looking for a font will then not find yours, and will buy a Helvetica license. reply 4RealFreedom 17 hours agorootparentJust spitballing here, couldn&#x27;t you call it \"Helzetica\" or something close? Might be enough to make yours findable. reply jhbadger 2 hours agorootparentThe Atari ST used to come with a font named \"Swiss\". It was basically Helvetica and was named that because \"Helvetica\" is Latin for \"Swiss\" (as in \"Confoederatio helvetica\"). reply bitwize 9 hours agorootparentprevBack in the day (Windows 3.x era) I used to use cheap lookalike fonts from shareware compilation disks&#x2F;CDs. So there was like a Palatino clone called \"Palamino\", a Cooper Black clone called \"Cookie\", an Optima clone called \"Proxima\", etc.You can still find fonts like this on font sites all over the web. reply mywittyname 17 hours agorootparentprevFont search engines have to exist. reply crazygringo 21 hours agoprevFunny, I asked here on HN just a couple of months ago why nobody has done something like this:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37286891The user &#x27;pessimizer&#x27; replied that there was a company OptiFont that seemed to do something just like this, to sell cheap font clones:http:&#x2F;&#x2F;abfonts.freehostia.com&#x2F;opti&#x2F;http:&#x2F;&#x2F;luc.devroye.org&#x2F;fonts-27506.htmlIt still seems so relatively trivial to automate this -- just render every character on aat a fixed known font size at super-high resolution and autotrace outlines, and render every character pair to figure out kerning, and the common ligatures. The only major thing missing is hinting, but that&#x27;s irrelevant for printed material and not very important on retina screens -- and auto-hinting gets you more than halfway there on non-retina. (And then there are all sorts of special font features like nonstandard ligatures, which can either be more carefully replicated, or just ignored.)I&#x27;m not saying it would be a good&#x2F;ethical thing to do this (I personally want designers to be supported) -- but I am kind of amazed that the market for digital fonts still exists, when in theory you can produce a perfectly legal copy and not pay a thing. reply quitit 21 hours agoparent>but I am kind of amazed that the market for digital fonts still exists, when in theory you can produce a perfectly legal copy and not pay a thing.There is a growing trend for style guides to use typefaces from no-cost or open libraries. This isn&#x27;t limited to small companies either, I can think of a handful of industry heavyweights in tech, food and medicine who each have taken up this approach. This forms the first reason not to dupe fonts, because there&#x27;s plenty of good ones already available for no cost.I&#x27;ve found that companies that do this have an easier time of staying on brand since it&#x27;s so simple to obtain the necessary fonts.As for seeking out deliberate copies of popular fonts, there&#x27;s a few reasons why an agency wouldn&#x27;t want to propose this:1. It&#x27;s easier to sell in a well loved font, with a proven character from a foundry with heritage. Imagine talking to a board of suits, they&#x27;re often looking for the safe option.2. It&#x27;s kind of a dick move for an agency to be ripping off the foundries, especially small modern ones. Creatives do enjoy what typographers make and can see the love put into their craft.3. Typographers are not faceless. Modern font designers are still alive and active on socials, you might personally know who you are ripping off.4. There&#x27;s a bit of hypocrisy in hating on frankenfonts such as Arial, while deliberately seeking out dupes.5. It&#x27;s trivial to open a font in a font editor and resave it with different specs, if a creative wants to be sneaky they can just do this themselves anyway.6. Adobe have also thrown their hat into this ring by offering a range of popular fonts available for use for no extra cost with their creative cloud subscription. It&#x27;s not needed to seek out a dupe-font, when the real thing is available with a few clicks. reply codedokode 19 hours agorootparent> It&#x27;s kind of a dick move for an agency to be ripping off the foundries, especially small modern ones. Creatives do enjoy what typographers make and can see the love put into their craft.But foundries sometimes do the same: they take samples of, say, 18th century font, and digitize it, and claim copyright. Do you think it is fair when someone copies Helvetica or 19th century Bookman [1] ?[1] https:&#x2F;&#x2F;learn.microsoft.com&#x2F;ru-ru&#x2F;typography&#x2F;font-list&#x2F;bookm... reply quitit 16 hours agorootparentI don&#x27;t feel your example is comparable here, but I&#x27;m interested in hearing maybe a different one that conveys your ideas better.The reason for my thinking is that I don&#x27;t see the problem in a foundry today building a font from a typeface that is neither commercially available, nor under any protection (or potentially even ownership). To me this is not comparable to dodging licensing fees from another foundry that is licensing a font. I actually feel that this foundry would be doing the design world a service by ensuring that pre-computing typefaces are adapted for modern use. Factually this process occurs frequently without controversy.As for claiming copyright: There is a significant amount of non-trivial work involved into building such a font, including a number of creative decisions that the typographer will need to make to address shortcomings as well as fleshing out the wealth of missing characters that are commonplace in contemporary publishing. reply sleepybrett 19 hours agorootparentprevType from the 18th century or earlier (pre film&#x2F;digital) is imperfect. Not every 12 pt &#x27;m&#x27; slug in that font drawer is identical, and not every imprint from the same &#x27;m&#x27; slug in that book is identical. It is a lot of work to create digital versions of these metal&#x2F;wood typefaces. reply quitit 16 hours agorootparentThis segues beautifully into a longer discussion about visual acuity testing charts.It&#x27;s relevant because even today many VA charts still feature the historical numbering systems which are deeply inconsistent from eye chart to eye chart. (The reason why this fault is of no concern is because in modern use, they are only stated to infer a vague acuity.) reply cschmidt 18 hours agorootparentprevHistorical revivals are hardly the same thing. They often end up far from the original, and require a ton of work. It isn&#x27;t just a matter of digitization. And they \"claim copyright\" on their derived work, not the original. With fonts they really just copyright the name. reply jrockway 17 hours agorootparentRequiring a ton of work doesn&#x27;t really matter one way or the other for copyright. Mowing the lawn is a ton of work. Doing the work doesn&#x27;t let you prevent other people from mowing their lawn to the same height as yours. reply hn_acker 14 hours agorootparentAdditional information on this point: \"Sweat of the brow\" [1] is a doctrine which grants copyright on a work due to the time and effort the author put into making it. The US Supreme Court rejected this doctrine, meaning that only the creative aspects of a work are relevant to copyright. For that reason, in the US, a phone book is not copyrightable unless the arrangement of its contents is creative [2].The EU narrowly rejects \"sweat of the brow\" copyright for recreations of public domain visual art [1]. I have no idea whether the same applies to font faces, public domain non-visual art, or phone books, but I&#x27;m assuming that it doesn&#x27;t.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sweat_of_the_brow[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Feist_Publications,_Inc.,_v._R.... reply cschmidt 14 hours agorootparentprevThat work I was referring to is a creative, artistic process of designing a font based on a historical starting point. That does matter. Hardly mowing the lawn or compiling a phone book. reply kevin_thibedeau 17 hours agorootparentprevThey&#x27;re not just scanning existing glyphs. They&#x27;re performing copyrightable work to add de novo metadata like hinting and kerning. reply ComputerGuru 21 hours agoparentprevYour approach would result in impossibly large binary font sizes unless a really good (smart) engine was present and utilized to separate the hinting logic from the underlying symbols. Then again, with most fonts these days putting in zero manual hinting work and just relying on the default font engine heuristics, it might not. reply crazygringo 19 hours agorootparentI was supposing zero hinting information would be included, so the file sizes should be perfectly normal.Because while font glyphs&#x2F;designs aren&#x27;t copyrightable, I&#x27;m assuming that hinting instructions are, even if they could be reverse-engineered this way. reply pbhjpbhj 21 hours agoprevCouple of issues I spotted:>most type foundries protect their fonts by copyrighting the font files themselvesCopyright is applied at the point of creation of a work, so unless they&#x27;re in jurisdictions with no copyright law then they all acquire copyright on their font files.>Since you’re entering into a legal agreement with the type foundry themselves, they can put whatever limits on how you can use the font, regardless of local copyright law.You can&#x27;t normally disclaim obligations or rights provided by law unless explicitly allowed to do so. For example, in most jurisdictions you can make copies to aid creation of a tool for blind people (cf Marrakesh Treaty), so copying to feed into an ML algorithm to improve a text(image)-to-speech tool may be allowed even if the company put in their terms \"no unauthorised storage on a computing system or in a database\".An interesting example of this is attempting to put work \"into the public domain\" depending on jurisdiction you might not be able to do that before the copyright expires &#x27;naturally&#x27;.these are my opinions only and do not relate to my employment reply trogdor 21 hours agoparent>Copyright is applied at the point of creation of a work, so unless they&#x27;re in jurisdictions with no copyright law then they all acquire copyright on their font files.Yes, but in the United States, copyright registration is a prerequisite for copyright litigation.According to 17 U. S. C. §411(a), “no civil action for infringement of the copyright in any United States work shall be instituted until . . . registration of the copyright claim has been made in accordance with this title.”The Supreme Court addressed this head-on in Fourth Estate v. Wall Street.See: https:&#x2F;&#x2F;www.oyez.org&#x2F;cases&#x2F;2018&#x2F;17-571 reply pbhjpbhj 3 hours agorootparentAssuming your summation to be true, then that is really interesting as it breaks USA&#x27;s obligations under the Berne Convention (which they didn&#x27;t join until about 100 years after most of the West) which was the reason registration was ended as a requirement (but was still useful due to, AIUI, pecuniary damages being awarded for registered works whilst only actual damages are&#x2F;were? awarded for unregistered).I think you have erred, the question before the court concerned when registration bites. My understanding is 17 USC 106 still applies, but civil actions before the court require a registration to have been initiated; I thought that was just a filter on court actions?Happy to be corrected.https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;411https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;106https:&#x2F;&#x2F;www.wipo.int&#x2F;treaties&#x2F;en&#x2F;ip&#x2F;berne&#x2F; reply bragr 20 hours agorootparentprev>no civil action for infringement of the copyright in any United States work...It&#x27;s not a US work if it wasn&#x27;t made in the US. That&#x27;s the crux of the point you&#x27;re replying to reply K2L8M11N2 20 hours agoprevI think this essay is relevant here: https:&#x2F;&#x2F;ansuz.sooke.bc.ca&#x2F;entry&#x2F;23> Suppose you publish an article that happens to contain a sentence identical to one from this article, like \"The law sees Colour.\" That&#x27;s just four words, all of them common, and it might well occur by random chance. Maybe you were thinking about similar ideas to mine and happened to put the words together in a similar way. If so, fine. But maybe you wrote \"your\" article by cutting and pasting from \"mine\" - in that case, the words have the Colour that obligates you to follow quotation procedures and worry about \"derivative work\" status under copyright law and so on. Exactly the same words - represented on a computer by the same bits - can vary in Colour and have differing consequences. When you use those words without quotation marks, either you&#x27;re an author or a plagiarist depending on where you got them, even though they are the same words. It matters where the bits came from. reply jibbit 19 hours agoparentthis is a basic misunderstanding of copyright reply Wowfunhappy 18 hours agorootparentIs the GP misunderstanding copyright, or is GP describing a common basic misunderstanding?If the former, could you please elaborate? I also frequently cite this article in discussions. reply ugh123 21 hours agoprevGreat info!I waded into this territory recently when trying to find a font that I can re-distribute as a system font for a device i&#x27;m building. Apparently this is completely restricted and disallowed according to pretty much every commercial license i&#x27;ve read from a long list of font shop sites.Instead, the intended use as spelled out in their commercial licenses boils down to the font buyer using it only to render graphics for printing or some other artistic use, rather than a \"mechanical\" use such as mine.Even after contacting some of them, they&#x27;re unwilling to budge.After reading your post, I suspect one issue may be that some (many?) of the fonts sold on these sites are already pirated, and the site wants to protect itself from the only real copyright&#x2F;legal threat of redistribution of the digital file.I&#x27;ve also found that many font authors don&#x27;t even intend their fonts to be used as system&#x2F;pc fonts. But rather something that can be imported into Adobe Illustrator (or the like) for further design work for print and graphic images - many of the font files themselves typically only contain A-Za-z letters (sometimes only capitals!), sometimes not even numbers, and only a few common punctuation characters. reply mschuster91 20 hours agoparentAt that point, I&#x27;d go for one of the many legitimately open source fonts, some of which have been released into public domain [1].[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Open-source_Unicode_typefaces reply nrjames 21 hours agoprevSounds quite a lot like \"They&#x27;re just PNGs on the Internet. Why would you pay for that when you can just copy it for free?\"The article is interesting from a technical point of view but feels yucky from a fairness point of view, regardless of legality. I may not have a ton of respect for the large corporation that owns the copyright on the file, but I do have respect for the creatives who make fonts (and other things) for a living. reply denton-scratch 19 hours agoparentTFA&#x27;s author is arguing that it seems to be possible to do this, but as a font-author he finds it disreputable (you have to read to the end). He&#x27;s arguing, I think, that fonts only became copyrightable when font files came along, with the arrival of PCs with GUIs. And that what became copyrightable was a font file.He argues that this is a weird anomaly; and I agree. But I draw a different conclusion; the introduction of copyright on font files was seriously annoying to me at the dawn of the PC age, because fonts were among the first digital objects that were copyrightable (that I had access to). With the exception of fonts, I could copy and re-purpose anything I found. I suspect fonts may have been the battering ram that led to the present situation of copyright maximalism.I don&#x27;t mean to talk down the effort, judgement and skill that goes into creating a typeface; but I&#x27;ve never had much time for maximalists. I&#x27;d go back to author&#x27;s lifetime, and I wouldn&#x27;t allow immortal \"persons\" (corporations) to have copyrights. reply dzek69 21 hours agoparentprevThe author of the article claims to not actually support piracy and ask to support the font makers.But from a technical point of view it&#x27;s still somehow interestingIt&#x27;s like learning about some security tools like shodan - here is how you can mess something up, but don&#x27;t do it reply codedokode 19 hours agoparentprevBig corporations shamelessly digitize old fonts and claim copyright, take Microsoft as an example [1].[1] https:&#x2F;&#x2F;learn.microsoft.com&#x2F;ru-ru&#x2F;typography&#x2F;font-list&#x2F;bookm... reply logifail 22 hours agoprev> [..] creative work that deserves to be copyrightedAs I&#x27;ve grown older I&#x27;ve become less and less convinced that any of our current legal frameworks actually protect the output of \"creatives\".Instead, it seems that those with the deepest pockets -looking at you, Disney(!) - have, over the decades, moulded the system to fit their own purposes, leaving most actual creatives high and dry.When I read sentences including both \"Abigail Disney\" and \"philanthropist\" it makes me want to vomit. reply munificent 21 hours agoparent> Instead, it seems that those with the deepest pockets -looking at you, Disney(!) I think this is mostly a case of survivorship bias. You only read about copyright in the news when it&#x27;s related to giant well-known corporations or egregious abuse of the law.The bread and butter uses of copyright benefit millions of authors and artists every day but you never hear about it in the news.For example, I wrote and self-published two books. While you can read them for free on the web, I still retain the copyright and sell physical copies. Fairly often, someone will rip a copy of the book and try to publish their own (poorly executed) eBooks or print versions. Copyright is what lets me have those taken down. reply monetus 21 hours agorootparentThe trade-off is that a lot of poor people will never hear about your book, or only read a substandard version of it. I&#x27;ve seen official torrents from the owners of the copyright, simply for quality control purposes. reply munificent 20 hours agorootparent> The trade-off is that a lot of poor people will never hear about your bookThere is always a trade-off between accessibility and compensation in creative works. I think the value of copyright is that it gives the author of the work—the one who has the most skin in the game—some agency in picking a point in that trade-off. (For example, I chose to allow anyone to read the books for free on the web, which maximizes accessibility for those who can&#x27;t afford it, while selling print and eBook copies which enables me to be compensated by those who can.)You can argue that copyright prevents poor people from accessing works. But that argument presumes a world where the work already exists. Without some ability to reliably predict and control compensation, there are many works that would simply never be made.You may then argue that if someone really has that creative drive, then they&#x27;ll make it even without compensation. But that means that only those with independent means will have the luxury of being creative. And the last thing I want to do is put even more cultural control in the hands of the rich. reply monetus 8 hours agorootparentI agree. Your monetization is kindly, and that deserves respect. The opportunity to create would never be there for many, and the skills involved never refined for many more, if compensation was impossible. You enforce against poorly formatted copies of your work. Derivative creations of your work that might not be transformative enough, but aren&#x27;t intended to copy your work directly, might not trigger your enforcement? Systems like youtube&#x27;s contentID are how most people notice copyright enforcement, if I had to guess. Your point on survivorship bias is interesting to think about. reply throw10920 11 hours agorootparentprev> The trade-off is that a lot of poor people will never hear about your bookIs this meant to be bad for poor people or for me, as a creator?If for poor people - all of the information required to live a relatively good live is available on the internet, free of charge. The vast majority of copyrighted content is entertainment. Nobody is entitled to entertainment.If for me - I&#x27;m ok with that. If someone else isn&#x27;t - they can reduce the price of their work, self-publish, or release the work (or even an excerpted section of it) as public domain&#x2F;creative commons.> I&#x27;ve seen official torrents from the owners of the copyright, simply for quality control purposes....which is extremely rare, and not really relevant to the discussion. reply monetus 8 hours agorootparent> not really relevant to the discussion.You&#x27;re on a throwaway, so correct me if I am wrong, but this is your first comment in this discussion? How is it irrelevant enough for you to insist such a thing? Distributing in such a way that illegitimate copies disappear but your margins are affected as if the piracy were there all the same is useful to think about in this discussion, because it has happened and you can study it somewhat.To your point on copyright, unaffordable things aren&#x27;t always entertainment, though it would be nice if that were the case. Feeling that the majority of content is frivolous entertainment is just a feeling; a feel-good feeling that trivializes any drawbacks to the copyright system. reply mminer237 19 hours agorootparentprevAt least in the US, you&#x27;re free to reject copyright and publish your book as public domain if you want more poor people to be able to read it. Most authors just like copyright law and requiring payment for their works though. reply haroldp 21 hours agoparentprevYou can&#x27;t copyright a dress, but there&#x27;s still a fashion industry:https:&#x2F;&#x2F;www.ted.com&#x2F;talks&#x2F;johanna_blakley_lessons_from_fashi... reply hn_throwaway_99 21 hours agorootparentYou actually can. There have been a ton of fashion lawsuits over copyright, and other IP laws like design patents. Here&#x27;s a couple:https:&#x2F;&#x2F;www.cnn.com&#x2F;2023&#x2F;07&#x2F;14&#x2F;business&#x2F;shein-rico-lawsuit&#x2F;i...https:&#x2F;&#x2F;gouchevlaw.com&#x2F;fashion-designer-roberto-cavalli-sued...https:&#x2F;&#x2F;www.lofficielusa.com&#x2F;politics-culture&#x2F;fashion-lawsui... reply haroldp 20 hours agorootparent> https:&#x2F;&#x2F;www.cnn.com&#x2F;2023&#x2F;07&#x2F;14&#x2F;business&#x2F;shein-rico-lawsuit&#x2F;i...These are graphic designers alleging that someone copied their exact fabric print design.> https:&#x2F;&#x2F;gouchevlaw.com&#x2F;fashion-designer-roberto-cavalli-sued...These are muralists that claim someone copied their murals as fabric print designs.> https:&#x2F;&#x2F;www.lofficielusa.com&#x2F;politics-culture&#x2F;fashion-lawsui...This summarizes a bunch of fashion lawsuits including, someone selling NFTs of someone else&#x27;s handbags, Adidas suing someone making track pants with Adidas-style vertical stripes (which seems like a trademark violation but Adidas lost), Staging a fashion show that blocked someone else&#x27;s store, one brand buying a lot of stock in another brand, The Hell&#x27;s Angels suing someone for using their logo, someone getting fired for being an anti-semite, and a couple of counterfeit shoe law suits.Zero of these even suggest that fashion designers may claim that the shape and style of a dress or other garment that they create is their intellectual property and they have a monopoly on its duplication. Because you can not copyright a dress.If you have more links, it is your turn to read them first. reply hn_throwaway_99 20 hours agorootparent> These are graphic designers alleging that someone copied their exact fabric print design.And why do you think this somehow doesn&#x27;t apply to the topic under discussion??Edit: here are two more, https:&#x2F;&#x2F;www.reuters.com&#x2F;legal&#x2F;transactional&#x2F;versace-fashion-... and https:&#x2F;&#x2F;consumerist.com&#x2F;2008&#x2F;01&#x2F;25&#x2F;diane-von-furstenberg-sue..., but I&#x27;m sure you&#x27;ll try to argue that the specifics aren&#x27;t what you had in your head... reply PrimeMcFly 20 hours agorootparentThe second link about about a print, not the dress itself. Kind of like if someone was selling a dress with Barbie on it. The dress isn&#x27;t copyrighted, but Barbie imagery is and you need a license to use it.The second is the only interesting and halfway relevant link you have provided. It says Versace was suing another company for ripping off their designs, on the bases of trademark law, it being a trade dress and copyright law.They would have had grounds on copyright law, but this company didn&#x27;t just copy one dress it was copying all of their dresses and designs. In any event it wasn&#x27;t settled because they settled out of court, which means nothing changed, and still to date you can&#x27;t copyright a dress. reply hn_throwaway_99 19 hours agorootparentThis article about an important Supreme Court ruling in 2017 clarifies the situation:https:&#x2F;&#x2F;consumerist.com&#x2F;2017&#x2F;03&#x2F;22&#x2F;supreme-courts-ruling-in-...1. US copyright law prohibits \"useful articles\", like clothing, from being copyrighted.2. However, as that article points out, \"decorative features of a uniform should be treated like two-dimensional artwork\". Look at the example on that article - it&#x27;s basically some abstract stripes and triangles that were seen as deserving of copyright protection, much less than a sweatshirt with a pink \"Barbie\" logo in recognized font on it.3. Beyond copyright, you can get a design patent on articles of clothing. Christian Louboutin is famous for their red soled shoes as well as their \"spike\" sneakers, and they&#x27;re suing other companies making red-soled shoes and sneakers with spikes on them. We&#x27;ll see how far they get.In any case, my original point in posting this and the other examples is that the first comment I was replying to, at least to me anyway, was implying that the fashion industry has thrived without the need for IP protections. On the contrary, there are a TON of lawsuits in the fashion industry related to IP protections where one designer is accusing someone else of \"ripping off\" their designs. The mechanics may not be exactly the same as with written words but the effects are identical. reply haroldp 17 hours agorootparentYou can&#x27;t copyright a dress. You have presented a bunch of articles (that you didn&#x27;t even read yourself) where artwork associated with a garment such as logos and textile prints may be subject to copyright in certain circumstances. It is not a matter of fashion having the same protections but under different codes. You simply can not copyright a dress. Fashion designers do not have that monopoly of reproduction. reply stonemetal12 18 hours agorootparentprevThat last paragraph is self contradictory. If they had grounds on copyright law, then they must have been able to legally copyright their dresses regardless of whether or not they actually went to court. If you can&#x27;t copyright a dress then they had no grounds under copyright law.As far as I am aware you can&#x27;t copyright a dress, unless it is like the banana that got nailed to the wall as art. The most relevant thing would be a design patent. replypbhjpbhj 21 hours agorootparentprev>can&#x27;t copyright a dress &#x2F;&#x2F;That seems highly unlikely to me. What seems most likely is that it&#x27;s hard to pass the distinctiveness bar for a dress.Unless you mean \"for the fabric shape of a dress alone\"? In which case you can get a design patent&#x2F;registered design. reply haroldp 20 hours agorootparent> That seems highly unlikely to me.I mean, I provided a reference for my claim. reply pbhjpbhj 3 hours agorootparentI&#x27;m not sure a person making assertions counts as a reference. I only skimmed the transcript but spotted a couple of errors, this person doesn&#x27;t appear to be an IPR expert?Also, I don&#x27;t feel this is going to get anywhere, the space of \"nuance of legislation across all jurisdictions in the World\" isn&#x27;t really conducive to casual conversation.That said, in the UK our caselaw on fashion is almost nonexistent, but the key rulings are well summarised in [0] at page 8. The bar is high but seems attainable. (A summary of Hensher v Restawhile [1]).An opinion piece at WIPO [2] suggests it&#x27;s easier to get copyright on garments in USA, they cite some law, at least, but their conclusion on UK law opposes my position (paraphrasing, they say \"garments can&#x27;t be protected\").My position has not changed.[0] https:&#x2F;&#x2F;assets.publishing.service.gov.uk&#x2F;government&#x2F;uploads&#x2F;... [1] https:&#x2F;&#x2F;www.cipil.law.cam.ac.uk&#x2F;virtual-museum&#x2F;hensher-v-res... [2] https:&#x2F;&#x2F;www.wipo.int&#x2F;wipo_magazine&#x2F;en&#x2F;2014&#x2F;03&#x2F;article_0007.h... reply noja 21 hours agorootparentprevLook at Zara&#x27;s business model. reply robertlagrant 21 hours agorootparentprevYou can&#x27;t copyright it, but you can get design protection. reply swatcoder 21 hours agoparentprevFor a millenia or two (at least), creatives have lived on a spectrum between folk production for small, immediate audiences and commercial production for the aristocracy or markets distribution.Copyright, since its much more recent introduction, is the tool for commercial creative to keep the folk creatives away from their money.The upside for media consumers is higher production value and grander spectacle, which is pretty cool. Copyright lets producers pour a lot of money into art and that allows for a different kind of work.But yeah, it’s pretty brutal for the countless folk creatives who see something inspiring and aren’t allowed to do cool things with it. Copyright does indeed work against them. reply cj 21 hours agoparentprev> it seems that those with the deepest pocketsTrademarks, patents, and copyrights are only as valuable as your willingness to pay a lawyer to confront those who are infringing.You can have all of the patents, trademarks, and copyrights in the world, but they&#x27;re useless unless you defend them. Which costs a lot of money.I&#x27;m not sure what the alternative would be, though. We can&#x27;t do away with the system completely. Disney needs to be able to earn a profit on content they produce otherwise they won&#x27;t invest in producing content. reply zackmorris 19 hours agoparentprevI was just thinking that it might be useful to add up how much money has been made by selling fonts since the dawn of time. I suspect that it&#x27;s on the order of $1 billion. Adobe probably owns a big share of that, followed by various publishing houses, creative institutes, etc.But that&#x27;s about 10 cents per person. Why are we so concerned with protecting the profits of a vanishingly small segment of the population to the detriment of billions of other people?I think that there are some weak points here that we could collectively attack and dismantle to reduce wealth inequality. One of the screws to turn might be copyright law, at least reducing the term from author&#x27;s lifetime plus 70 years to something reasonable, perhaps 3-5 years with an option to renew for up to 10 years total. Another would be patent law, and certainly the elimination of all patents around software, genes, etc.Short of that, we could form guilds where one of the conditions is that seeking IP retribution revokes one&#x27;s membership. Then only do business with people and organizations in the guilds or face consequences, sort of like what happened with Drew Barrymore when she went around SAG&#x2F;WGA. reply jwmcq 21 hours agoparentprevAnd then you realise that this also applies to pretty much every industry and its workers (hooray for lobbying!) and then you get sad. reply Angostura 21 hours agoparentprev> When I read sentences including both \"Abigail Disney\" and \"philanthropist\" it makes me want to vomit.Why? reply Tao3300 21 hours agoparentprevI think in this case the situation for fonts isn&#x27;t such a bad compromise. As it is, BigTypeCompany can&#x27;t go kicking LittleIndieDesigner who can&#x27;t afford to go to court because their letter-A looks confusingly similar. reply antisthenes 19 hours agoparentprev> As I&#x27;ve grown older I&#x27;ve become less and less convinced that any of our current legal frameworks actually protect the output of \"creatives\".I think most of \"creatives\" are just high and dry because most of the output is just not very good. Creative output in a digital world is a winner-take-all scenario, so mediocre artists just get 0 exposure.If I have limited amount of time to commit to watching something or listening to a song or using a font, I will naturally gravitate to things that are already popular&#x2F;good and make money. What would help creatives here is a better discovery process, but it&#x27;s pretty tangential to the legal framework. reply sleepybrett 19 hours agoprevFarming the internet for kerning values is going to be a bit of a crapshoot. Many designers don&#x27;t just type a headline and export to png, often kerning is manually adjusted (especially with headlines, but also during book-type layout kerning may be adjusted on whole blocks of text or just a few words in order to help balance a page or block) reply tasuki 19 hours agoprev> a project that begged for a better, licensed fontEh. There are plenty of good fonts with permissive licensees. Also, good typography is much more about sizing and spacing than about picking a better font. reply postmodest 13 hours agoprevI have fonts installed on my computer that I received from a boxed CorelDraw! Install in probably 1993. These have names like \"Swiss721\" and were created by Bitstream as visual clones of Helvetica or Times.Visual cloning of fonts is technically legal and has a long standing tradition. But \"While technically not illegal, font designer John Hudson would describe its selling of large numbers of typefaces on CD at discount prices as \"one of the worst instances of piracy in the history of type\".\" reply DiabloD3 6 hours agoprevI love how he uses the Berkeley Graphics license as an example, yet ignores the fact that you buy their font, Berkeley Mono, because you want a very well engineered font.Like, there are straight up only two fonts I will say are engineered well, objectively: Berkeley Mono is the #2 on that list, PragmataPro being #1. It isn&#x27;t about aesthetic quality, its down to how well hinted they are, and how well they render at absurdly small sizes on a wide range of renderers. reply clubm8 22 hours agoprevWhy would I care about legality while pirating?It&#x27;s my understanding you&#x27;re using it for profit you&#x27;re gonna have to pay for the font, and conversely if I&#x27;m doing propaganda I don&#x27;t care if you shoot me, so why do I care if you sue me? reply jimkoen 21 hours agoparentI was under the same impression, but it seems that in the majority of jurisdictions, the use of a Font does not meet the threshhold for a meaningful work under copyright law. To clarify, the use of the Font itself can be restricted under certain copyright aspects, i.e. offering tools or distributing the font file.But texts set in a specific font are no subject to copyright.> so why do I care if you sue me?Risk exposure I suppose? It seems copyright on fonts is mostly defined by case law. In the US, font files are apparently copyrightable because they&#x27;re classified as a computer program, the actual artistic value of the displayed font is not taken into account at all.For more info: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Intellectual_property_protecti... reply clubm8 21 hours agorootparent>I was under the same impression, but it seems that in the majority of jurisdictions, the use of a Font does not meet the threshhold for a meaningful work under copyright law.Thanks for this! I&#x27;ll look for a citation in the bottom of the wikipedia, but I believe you.(Sorry to continue being \"that guy\" but while you raise good points about law and risk, I am once again forced to remind the hackers that Wikipeia is not a primary source)>It seems copyright on fonts is mostly defined by case law. In the US, font files are apparently copyrightable because they&#x27;re classified as a computer program, the actual artistic value of the displayed font is not taken into account at all.I was born in Appalachia -- that&#x27;s fucked up, especially since the \"founding fathers\" we Americans love to stan set much shorter copyright limits and many fonts, even computer ones, are quite old.>And that the author and authors of any map, chart, book or books already made and composed, and not printed or published, or that shall hereafter be made and composed, being a citizen or citizens of these United States, or resident therein, and his or their executors, administrators or assigns, shall have the sole right and liberty of printing, reprinting, publishing and vending such map, chart, book or books, for the like term of fourteen years from the time of recording the title thereof in the clerk’s office as aforesaid. And if, at the expiration of the said term, the author or authors, or any of them, be living, and a citizen or citizens of these United States, or resident therein, the same exclusive right shall be continued to him or them, his or their executors, administrators or assigns, for the further term of fourteen years; Provided, He or they shall cause the title thereof to be a second time recorded and published in the same manner as is herein after directed, and that within six months before the expiration of the first term of fourteen years aforesaid.https:&#x2F;&#x2F;www.copyright.gov&#x2F;history&#x2F;1790act.pdf(apologies for formatting issues -- copy and paste from the pdf did not retain linebreaks etc)These fonts were made in the 80s, like me. They should be a free for all. reply jackson1442 22 hours agoparentprev> It&#x27;s my understanding you&#x27;re using it for profit you&#x27;re gonna have to pay for the fontI&#x27;ve only read the article and am not familiar enough with copyright to outright tell a company to \"go for it,\" but the author seems to be under the impression that font files generated using this technique are a-ok to use for profit. reply gwern 15 hours agoparentprevIf you wanted to create a font-generating NN and are worried about future IP laws deciding NNs are not transformative but mere derivative works of the training data, this would be potentially interesting. And if you wanted to ever sell such a business, say, to a certain private equity-owned company with $200m+ in annual revenue, it would be very useful to be able to show during due diligence that you had belt-and-suspenders your NN&#x27;s data and it didn&#x27;t all have to be thrown out & restarted from scratch. reply ipaddr 22 hours agoparentprevWhy would you have to pay when copyright cannot be applied unless it&#x27;s the entire file? reply clubm8 21 hours agorootparent>copyright cannot be applied unless it&#x27;s the entire fileI think you&#x27;re mixing up the short clips thing that Girl Talk used for audio&#x2F;video with fonts? I&#x27;m not sure the same case law applies.I&#x27;m also not a lawyer (thank christ) reply analyte123 19 hours agoprevThe legal term for the glyphs is \"typeface\" [1]. Last time I looked at this, it also implied that emoji images that are used in a font, for example Apple&#x27;s emojis, were potentially not copyrightable either, at least when used as text [2] (and not for example, as a UI element or by themselves on a t-shirt). I recall that at the time, Telegram had completely copied Apple&#x27;s emoji images into their own font, but I&#x27;m not sure if they still do.[1] https:&#x2F;&#x2F;nwalsh.com&#x2F;comp.fonts&#x2F;FAQ&#x2F;cf_13.htm [2] https:&#x2F;&#x2F;www.lexology.com&#x2F;library&#x2F;detail.aspx?g=2ae2643d-f307... reply aiunboxed 21 hours agoprevIt reminds me of how there was a dispute of X&#x27;s logo being taken from a mono type fonthttps:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;da262b2a-f39a-466b-9b2f-2f8fa84f0... reply LoganDark 13 hours agoparentDo you have a non-paywalled link? reply miragecraft 20 hours agoprevAside from the fact that I’m not a fan of piracy, you can’t claim something is legal when there’s a lot of wiggle room.What it comes down to is what you can legally prove in court and that means having big foundries sue you and having to defend yourself.Nobody wants to go through that just to use some fonts when there are open fonts available.If you want something custom then pick a variable font, such as Roboto Flex, and customize it beyond recognition.In fact that’s where I see the future is headed - “master” variable fonts with all the axis, variant glyphs etc. available to be tweaked.The user then gets to play with dials and knobs and when satisfied recompile the font to be non-variable in order to shave down the file size. reply codedokode 19 hours agoparentBig foundries digitize old fonts and claim copyright on them. Take Microsoft as an example, who took 19th century font and sells it [1][1] https:&#x2F;&#x2F;learn.microsoft.com&#x2F;ru-ru&#x2F;typography&#x2F;font-list&#x2F;bookm... reply miragecraft 13 hours agorootparentYou&#x27;re free to make competing digitized fonts using the same source material. reply Guvante 8 hours agoprevDoubtful the courts would allow this shell game.Just because a particular usage is not protected doesn&#x27;t mean you can do anything with it. reply hwc 17 hours agoprevif the nocopy flag is set on a font, Chrome will not embed that font into a PDF when you do \"print to PDF\". instead, the shapes are used to create a type3 font. This is a way the author can get the vector shape of the glyphs without touching the TTF files.(or that was true back when I worked on that code, two jobs back!) reply Animats 19 hours agoprevThe next step should be a machine learning system which looks at samples of a font, learns what the font looks like, and then can generate characters in that style it hasn&#x27;t seen, based on a large training set of other fonts. This would be useful when you want to fill out a font that doesn&#x27;t have all the characters you need. reply RobotToaster 21 hours agoprevThis doesn&#x27;t account for optional ligatures in OTF fonts.I think it may not work on svg-otf fonts, since they can have colour, line thickness, etc. reply gwern 15 hours agoparentWhy wouldn&#x27;t the ligatures show up in images online? Someone&#x27;s going to screenshot the alternatives at some point - the specimen, if nothing else. (And if they never show up and so can&#x27;t be traced, then they couldn&#x27;t&#x27;ve been all that important.) reply raylad 18 hours agoprevThis process still won&#x27;t get the hinting that allows fonts to look good at many different sizes. reply steakscience 6 hours agoprevYou also cannot copyright recipes reply 23B1 21 hours agoprevConsidering the amount of work it takes to build a font – the amount of mind-numbing care, testing, iterating, crafting... please do not steal fonts. There&#x27;s no big bad studios or MPAA between these typographers and the world taking the bulk of their money, and they barely scrape by as it is.Pirate all the lame movies you want, but please, if nothing else, pay typographers and buy direct from their foundries.If any brave souls are interested in legally pirating all existing fonts and being taken there, I think you’d likely be doing a service to society here in challenging this.The service to society is already being done by the typographers. The service you can do to society is to pay them for their passion, precision, and care. reply Grae 20 hours agoparentThe author agrees with you. They&#x27;re saying that the lack of legal protection for fonts is a problem, and that creating an opportunity to challenge that law would be a good thing.Courts can only weigh in on legal issues when people bring a dispute before the court. In this case, if someone did what the author describes it would trigger a lawsuit from typographers, which would give the court a chance to (re)interpret or overturn the existing law. reply LocalH 16 hours agorootparentThe question is, essentially, \"should bitmap fonts be copyrightable\". In many jurisdictions, they are not. In the US, this has been black-letter law for several decades. A purely mechanical image reproduction of a typeface does not enjoy legal protection. I think it should remain that way. Many fonts are extremely similar, and allowing rights to the design itself would result in fights over the most basic of typeface design, similar to that seen in the music industry (where there have been efforts to claim rights to a chord progression).Outline fonts (that contain programmable elements) are considered software and are copyrightable. A rendered output of such a font is not. It may legally matter who makes that rendered output, that they have the right to use the font software in that fashion. But someone working from a specimen? They should have the right to digitize that font themselves, and employ creative decision-making in placing the control points. In fact, that very thing has happened numerous times within the typography industry. reply manuelmoreale 19 hours agorootparentprevI think the vast majority of typefaces can’t really have legal protection from a creative stand point because they’re so close to each other that it’s incredibly hard to argue that they’re original content.Just compare Inter vs Roboto vs San Francisco. Are they different? Technically yes. Are they different enough to allow for all three to be granted legal protection? I’d say no. And if you say yes, then it comes down to how different is different enough and the entire field becomes a legal nightmare reply 23B1 3 hours agorootparent\"That Picasso looks like that Braque, so neither deserves protection\" reply 23B1 3 hours agorootparentprevNo. The given the author&#x27;s background, this is (admittedly) clever technical thinking done under the guise of making a legal&#x2F;political statement. Plenty of other ways to solve this problem besides fake &#x27;good intentions&#x27; slacktivism. reply manuelmoreale 19 hours agoparentprev> Pirate all the lame movies you want, but please, if nothing else, pay typographers and buy direct from their foundries.I agree in spirit, but as I wrote on my blog months ago, I just refuse to engage with an industry that had decided to adopt some of the worst licenses possible to sell their products.Until foundries start adopting sensible licenses for webfonts I’ll just refuse to give money to them. reply 23B1 3 hours agorootparentWhat have you done to fix it besides not stealing fonts and writing a blog?You&#x27;re using slacktivism as cover for bad behavior. I&#x27;m not saying that IP laws aren&#x27;t f&#x27;d up and wrong. They absolutely are.But two wrongs don&#x27;t make a right, and it&#x27;s the same nonsense that folks have been making since the beginning of the internet to justify what amounts to petty theft. reply manuelmoreale 1 hour agorootparentWhat have I done?I paid for fonts when people have sane licenses to support good behavior.I also support and use open source typefaces.What else am I supposed to do? Pay a goddamn typeface more money than I make working full time in a month? reply 23B1 1 hour agorootparentApologies, I totally misread this bit of your comment:> Until foundries start adopting sensible licenses for webfonts I’ll just refuse to give money to them.Yeah of course you shouldn&#x27;t feel obligated to pay for what you don&#x27;t want. I assumed it meant you&#x27;d just &#x27;steal&#x27; it if you didn&#x27;t like the license. reply manuelmoreale 1 hour agorootparentI&#x27;d never steal a font considering there are countless free, open source alternatives out there. But I also refuse to pay an insane amount of money to type foundries because they decided that \"page views\" are a reasonable indicator of how much value I&#x27;m getting for a typeface.I worked on websites where the cost of a license for the font was 70% of the total budget available for the entire project. That makes no sense to me. I love great typography. I love great typefaces. But a typeface is not all that important in the grand scheme of things. I can change a typeface on literally every single one of the hundreds of websites I worked on in my career and I bet 95% of the users would not notice it nor care cabout it.We are all colletively getting pissed super quickly when software goes subscription but we&#x27;re fine when someone is selling me a typeface that comes with 50000 page views and once those are \"used\" I have to pay again. For a goddamn file I self host myself.It&#x27;s just bonkers. replycratermoon 21 hours agoparentprev> There&#x27;s no big bad studios or MPAA between these typographers and the world taking the bulk of their moneyWhere do fonts come from? Monotype, mostly https:&#x2F;&#x2F;thehustle.co&#x2F;where-do-fonts-come-from&#x2F; reply 23B1 20 hours agorootparentCool – use AI to build a free service that competes with Monotype. reply naet 18 hours agoprev\"Final reminder that I’m not a lawyer and have no clue if anything I said is actually correct, so none of this is legal advice and I strongly recommend you go talk to a lawyer before attempting anything here. I’d also strongly emphasize the importance of supporting the incredible work behind your favorite typefaces by purchasing fonts directly, I definitely do not advocate ever for stealing anyone’s work.\"The project is fun and a cool idea, but don&#x27;t take the headline at face value.Would something like this hold up in court? My guess is that it probably won&#x27;t. If a lawyer can demonstrate that you&#x27;ve perfectly recreated a copyright font I&#x27;m guessing a fair number of judges or juries would find you in violation of copyright regardless of the method used to make the recreation. Either way you&#x27;re opening yourself up to a potentially expensive legal headache if discovered. reply phendrenad2 21 hours agoprevSo which is it? Piracy? Or legal? It can&#x27;t be both... reply bloqs 21 hours agoprevDoes anyone understand how this law works in the UK? reply gnufx 21 hours agoparentThe legislation is https:&#x2F;&#x2F;www.legislation.gov.uk&#x2F;ukpga&#x2F;1988&#x2F;48&#x2F;part&#x2F;I&#x2F;chapter&#x2F;...Long ago I had to read the Act on microfiche. reply phyzome 21 hours agoprevTell me more about \"legal piracy\". reply Tao3300 21 hours agoparent> legal piracyI&#x27;m going to need to see a valid letter of marque! reply ddingus 18 hours agoparentprevI believe the thing we are looking for is legal infringement.Rights holder would rather not have something happen, but it is allowed to happen anyway, despite technically being infringing. reply jejeyyy77 20 hours agoprevjust automate running through StableDiffusion and generate a slight variation. Done. reply JW_00000 20 hours agoparentIf you give StableDiffusion a copyrighted work and ask it to generate a slight variation, the output will still be a derivative work. reply dzek69 21 hours agoprevI have no problem with fonts pricingI have problem with the crazy licensingYes, you can use that font, but only for print and websites and your website cannot generate more than 100k views monthly and your business annual revenue can be higher than 1mIf you don&#x27;t pass these we have more licensing options with different numbers and prices.if you want an app (is WebView in an APK file an app? Is PWA an app?) there is separate price as wellYou can host the font file on your server (browser must obviously download it) but you cannot actually distribute it - whatever that means, it could be risky with open source apps for exampleThis is so bullshit I prefer to always use Google fonts or any other source of 100% free for anything fonts. You don&#x27;t want my money - sure, your choice reply neontomo 21 hours agoparentYeah, even with stock image platforms, having different licenses on every photo becomes a research project if you are working with any great amount of photos. I much prefer it when the websites have a standard license that is applicable to everything on there, because I only have to read it once. Also, if I can&#x27;t use a resource I paid for in commercial use, it&#x27;s pretty, but pretty useless. reply gnopgnip 20 hours agorootparentWith stock images there is really only one question, commercial use or editorial use. This distinction is more often about the subject than any decision made by the photographer or platform. Like a photo of any famous person is going to be editorial, unless you get the subject&#x27;s permission.The license will be royalty free on even the cheapest microstock services reply graypegg 20 hours agoparentprevWebfont pricing is always so weird to me. No one sees a massive spike of traffic on their site and thinks \"Oh no! My font license only allows 100K visits a month! Shut it down!\".However, as an art form, typographic design gets the short end of the stick in terms of protection and how people treat their work. There need to be a middle ground right? It&#x27;s not exactly easy to make a GOOD font, and I&#x27;m happy to pay for one if I&#x27;m respected in the license.I like the license Matthew Butterick uses for his fonts. [0] Some things are still a little... odd. (A word file using the font can&#x27;t be seen by more than 20 people.) But the web font licensing is perfectly fair. (To be used on 3 publicly accessible websites, and embedded using WOFF2 only.)[0] https:&#x2F;&#x2F;mbtype.com&#x2F;license&#x2F; reply Macha 21 hours agoparentprevThis is also why so many tech companies invent their own fonts to avoid the whole licensing quagmires. reply Spivak 20 hours agorootparentPlus if you have someone just hanging around who&#x27;s a font nerd it&#x27;s fun, saves money, gives you fodder for the marketing machine, and you get a more distinct brand with your company&#x27;s \"handwriting.\"It&#x27;s not actually that hard to make your own font -- like you have to try to make an actively bad font. And since the value-add is mostly character I&#x27;m shocked how much people who license fonts jerk you around. reply dylan604 20 hours agorootparent>It&#x27;s not actually that hard to make your own fontBut it is hard to actually make a good font reply Spivak 18 hours agorootparentNo disagreement, but fonts obey the \"even bad pizza is good pizza\" rule. Low skill floor, high skill ceiling. And when it comes to fonts you want be a little distinct because they&#x27;re part of your brand small idiosyncrasies can add to the charm. And unlike commercial font makers it&#x27;s likely you don&#x27;t have to worry about supporting more than a few languages, and odds are good they share most of their alphabet. reply dylan604 17 hours agorootparentI feel bad for people with the notion that there&#x27;s no such thing as bad pizza. I&#x27;ve had pizza that the cardboard box it came in would be a) more flavorful, b) less tough, c) more nutritional. replysomenameforme 20 hours agoparentprev> \"You can host the font file on your server (browser must obviously download it) but you cannot actually distribute it - whatever that means, it could be risky with open source apps for example\"I ran into this exact issue as well. I can only imagine that there&#x27;s some obscure legal nuance to this where if the font is loosely accessible then somehow the enduser gains some sort of rights to it.In some dialogue with the rights holder, they were perfectly cool with the font being embedded in the .exe itself, which makes the font trivially extractable - as they understood, but were simply insistent that the font not be directly distributed to users as a stand-alone file. reply jval43 20 hours agoparentprevDon&#x27;t forget \"server\" licensing, which is by CPU core. And who knows if they mean virtual or physical ones. reply that_guy_iain 20 hours agoparentprevThe issue is everyone trying to make as much money as possible. And rightfully, they want to charge Time Magazine more than they do some guy with an ezine with 100 readers. reply dylan604 20 hours agorootparentwhy though? it doesn&#x27;t cost the font makers any more expense when Time serves the font. reply that_guy_iain 44 minutes agorootparentTo maximise revenue. If you&#x27;re a font maker, I suspect most are self-employed, you need money. If your font is being used for Time Magazine it is somewhat fair the fee is higher than a guy using it for an ezine for 100 people. One is a company with lots of money and can afford to pay alot of money and the other can&#x27;t. reply connicpu 20 hours agorootparentprevIn the age of digital projection, it doesn&#x27;t really cost the movie studio any more to distribute their movie to a theater than to a home streamer. Yet I think it&#x27;s clear why they charge the theater more: one is viewing for themselves and perhaps a handful of friends, the other has the intention of distributing a playback to thousands whom they themselves are making money off of. They aren&#x27;t charging for the actual cost of distribution, they&#x27;re charging for the intellectual property and the cost it took to make the product in the first place. If the fonts aren&#x27;t worth what the creators are charging, then the large companies wouldn&#x27;t be paying for them. reply tavavex 19 hours agorootparentThis analogy doesn&#x27;t really apply to the situation here, because the difference between a personal and commercial license isn&#x27;t what&#x27;s at stake. Comparing watching a movie on your own vs making money off of it in theaters is similar to viewing a licensed font on someone&#x27;s website for free vs buying a font license to use it in your own projects.A better analogy would be a studio charging a theater belonging to a large chain vastly more money than a small, independent theater. The cost to provide the physical media, promotional material and IP rights to both of them is the same. So the only consideration in play here is that they can pump more money out of the larger business, so that&#x27;s what they&#x27;re going to do. reply dylan604 18 hours agorootparentThe analogy is just bad altogether. If a theater doesn&#x27;t show a movie, then they lose out on however many people with $X for the ticket price plus an additional $Y from concession sales. However, Time is not going to lose readers because they choose a font or not. So, the sheer use of the licensed movie has direct affect on the theater&#x27;s bottom line, yet Time could choose a different font and have negligible notice on their bottom line.Font foundries thinking they are entitled to a percentage of the bottom line of a company using their fonts is the top of the list of entitled rent seeking bullshit. replydylan604 20 hours agoparentprevAre Google fonts really free? reply packetslave 20 hours agorootparent... yes? reply sigzero 20 hours agoprev\"legally pirate\" is an oxymoron. reply Freedom2 22 hours agoprev [–] Does this work for fonts that haven&#x27;t been released, or are still a work in progress? What&#x27;s the scope of &#x27;every font on Earth&#x27;? reply ComputerGuru 21 hours agoparent [–] What about the font I designed on my air-gapped computer in a secure nuclear bunker that no one but me has seen? Obviously the author is wrong and this must not go uncorrected!Or maybe you’re just being a little overly pedantic? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The topic revolves around the copyright legality of unlicensed fonts on the web, where US law disallows copyright of individual glyphs but permits for copyrighting the font file.",
      "Trademarked fonts are protected under the law, while non-trademarked glyphs are not susceptible to copyright.",
      "The author considers using public, non-creative, non-trademarked fonts to recreate licensed ones, recognizing the complexity of such an endeavor, and ends by asserting the significance of supporting font creators by purchasing fonts legally."
    ],
    "commentSummary": [
      "The central theme of this discussion is the copyright issues related to fonts and the subsequent practice of pirating them.",
      "It delves into the legality of font duplication, and how copyright potentially impacts creativity and the accessibility of creative works.",
      "It also scrutinizes the complexities of font licensing and the extent of protection offered to fonts under copyright laws."
    ],
    "points": 315,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1697041266
  },
  {
    "id": 37847454,
    "title": "Google Cloud Spanner is now half the cost of Amazon DynamoDB",
    "originLink": "https://cloud.google.com/blog/products/databases/announcing-cloud-spanner-price-performance-updates",
    "originBody": "Jump to Content Cloud Blog Solutions & technology Ecosystem Developers & Practitioners Transform with Google Cloud Contact sales Get started for free Databases Cloud Spanner is now half the cost of Amazon DynamoDB, and with strong consistency and single-digit ms latency October 11, 2023 Jagdeep Singh Group Product Manager Pritam Shah Director of Engineering Watch the best of Google Cloud Next ’23 Access all recorded sessions on-demand now. Register now to start exploring the best of Next. Register Today, we announced significant price-performance improvements for Cloud Spanner, now providing up to 50% increase in throughput and 2.5 times the storage per node than before, with no change in price. Spanner’s high throughput, virtually unlimited scale, single-digit millisecond latency, five 9s availability SLA, and strong external-consistency semantics are now available at half the cost of Amazon DynamoDB for most workloads. These upgrades will be rolled out to all Spanner customers in the coming months, without the need for reprovisioning, downtime, or any user action. Organizations of all sizes and across all industries are increasingly looking to accelerate digital transformation and power AI-driven innovation. However, demands are increasing, while budgets are constrained. Customers choose Spanner to future-proof their applications with high performance and availability at virtually unlimited scale. Spanner is a no-compromise database for relational and non-relational workloads that removes stress from managing databases with zero-touch maintenance. As data volumes grow and applications demand more from their operational databases, customers seek cost-optimal ways to support that growth. The price-performance changes we announced today build on a track record of continuous improvements to increase value, enhance performance, and lower costs. Additionally, Spanner delivers predictable single-digit milliseconds latencies for strongly-consistent reads and writes across multiple availability zones in the same region. Superior price-performance, familiar SQL, no-maintenance downtime, and a five 9s of availability SLA make Spanner an excellent choice not just for relational data, but also for read-heavy key-value workloads. With these changes, Spanner now offers up to 2x better read throughput per dollar compared to Amazon DynamoDB for similar workloads. Spanner is used ubiquitously inside of Google, supporting services such as; Ads, Gmail and Photos. According to the Amazon Prime Day blog post, DynamoDB processes 126 million queries per second at peak. Spanner on the other hand processes 3 billion queries per second at peak, which is more than 20x higher, and has more than 12 exabytes of data under management. Cloud Spanner's new price-performance improvements make it possible to grow more cost effectively by optimizing both compute and storage: Compute: Thanks to the 50% throughput improvement, customers can leverage Spanner for their relational and key-value workloads in a cost effective way. Storage: Each Spanner node can now accommodate 10TB of storage, compared to 4TB previously. This enables customers to cost effectively store and manage data. Even with the increased capacity, Spanner users still only pay for the storage they actually use. In other words, Spanner customers now have a lot more flexibility in optimizing their Spanner environments. \"Spanner is an important component for Uber's essential operations. As we scale and expand our global footprint, Spanner's scalability & low operational cost is invaluable. Prior to integrating Spanner, our data management framework demanded a lot of oversight and operational effort, escalating both complexity and expenditure. Traditional workarounds like sharding and eventual consistency also posed barriers to development speed. The adoption of Spanner streamlined operational costs, improved overall reliability, and strengthened overall value by providing better throughput and performance for the same price.” - Ankit Srivastava, Distinguished Engineer, Uber “Spanner's recent performance improvements have been a welcome change for CERC. With the increase in throughput and storage per node, we've been able to improve our operational efficiency. As we deliver transformative experiences to our customer, a highly reliable, scalable and cost effective database like Spanner is key to our strategy.\" - Andre da Costa Silva, CIO, CERC Cloud Spanner's price-performance improvements are now available in select regional and multi-region instance configurations, with all other configurations to follow. Storage upgrades will start rolling out in the coming months. You do not need to do anything to take advantage of these improvements, and you will continue to be billed at your current rate. Learn more about what makes Spanner unique and how it’s being used today. Or try it yourself for free for 90 days, or for as little as $65 USD/month for a production-ready instance that grows with your business, without downtime or disruptive re-architecture. Posted in Databases Spanner Related articles Databases The power of AlloyDB AI in AlloyDB Omni By Gleb Otochkin • 5-minute read Databases Sanitas achieves database modernization with a true DevOps operational model By Matthias Kupczak • 4-minute read Databases AlloyDB Omni, the downloadable edition of AlloyDB, is now generally available By Kevin Jernigan • 3-minute read API Management How to use the MongoDB connector with Application Integration By Venkatesh Shanbhag • 3-minute read Footer Links Follow us Google Cloud Google Cloud Products Privacy Terms Help Language ‪English‬ ‪Deutsch‬ ‪Français‬ ‪한국어‬ ‪日本語‬",
    "commentLink": "https://news.ycombinator.com/item?id=37847454",
    "commentBody": "Google Cloud Spanner is now half the cost of Amazon DynamoDBHacker NewspastloginGoogle Cloud Spanner is now half the cost of Amazon DynamoDB (cloud.google.com) 299 points by forrestbrazeal 21 hours ago| hidepastfavorite347 comments vicpara 18 hours agoJust moved our infra from GCP to AWS. Kubernetes clusters, LB, storage, lambdas, KMS and all of it.Google runs their tech stack as if it&#x27;s a startup that builds their CV. Everything is immature, tons of hacks, undocumented features. If you are on their k8s there are tons of upcoming new versions and features that force you to revisit key hacks you put in your infra because of their misgivings. Our infra team keeps tinkering around our infra and it never ends. It&#x27;s 50:50. 50% of time making sure we are prepared for their shit and 50 % our ambitious infra plans. Good luck with that.With AWS our bill is 60% of what GCP used to be running 3 k8s clusters.AWS support is so nice, you can&#x27;t believe it.Nah, I don&#x27;t trust Google with anything. It&#x27;s a scam. Google&#x27;s support is horrendous. They refer you to idiots that drag you through calls until your will for life dies. And you&#x27;re back to the mercy of some lost engineer that may comment on a github issue you opened 20 days ago. We have a bug reported back in 2020 that got closed recently without any action because it became stale and the API changed so much it doesn&#x27;t really matter. It&#x27;s that bad.The billing day is a monthly reminder you&#x27;re paying entitled devs to do subpar work other companies do a lot better.No, we don&#x27;t miss them already. reply dijit 17 hours agoparentInteresting, if you swap GCP and AWS in your post then thats exactly my experience.I wonder what makes us different, I work in europe on video games; AWS’s handling of me when I was at Ubisoft left a really sour taste - when I moved into Tencent&#x2F;Sharkmob I tried really hard to love AWS as it was the defacto industry standard and instead I was left with a feeling that most of it is inconsistent garbage papered over with lambda functions. I referred to these weird gotchas as “3am topics”; things that I don&#x27;t have the mental capacity to deal with at 3am and convinced the studio to switch to GCP- which, incidentally they are still extremely grateful to me for doing. reply cjaybo 17 hours agorootparent> I was left with a feeling that most of it is inconsistent garbage papered over with lambda functionsThis sounds more like an indictment of the system design than the cloud provider.What are some of these “3am” topics that made GCP a better choice? reply dijit 16 hours agorootparentSmall examples included (I’m on my phone so these are from memory and you’ll have to forgive the lack of great detail):1) having the project&#x2F;account your in visible at the top at all times.We used SSO for “accounts” which is AWS’s way of completely separating resources; the long string that is returned is not unique in the start and the remainder is cut off: so all accounts&#x2F;projects looked the same, was impossible to tell at a glance if you were in dev, staging or prod.2) Autoscaling groups with that had human readable incrementing “names”, in AWS instances have hex slugs as instance names and you can give an instance a special “Name” label: but any new machines created with an ASG will just reuse the same name label making them hard or impossible to tell apart.The AWS official solution for this is to have a lambda function hook on the scale event and give your new node an incremented name label. Given that AWS is pricy to save me time: I do not personally consider this an elegant solution.3) having all regions on one page.We spent €6,000~ on a database we didn&#x27;t know about until we started digging into the bill. Not knowing what resources are available at a glance feels pretty basic to me tbh.4) the network implementation overall; in Google you can just make a network and it will work without having to mess with zone routing and configuration of that which is put on the user.If it’s on the user, it’s a variable that has to be checked during an outage; it is terraform code that has to be grokked and so-on. reply master_crab 16 hours agorootparent“2) Autoscaling groups with that had human readable incrementing “names”, in AWS instances have hex slugs as instance names and you can give an instance a special “Name” label: but any new machines created with an ASG will just reuse the same name label making them hard or impossible to tell apart. The AWS official solution for this is to have a lambda function hook on the scale event and give your new node an incremented name label. Given that AWS is pricy to save me time: I do not personally consider this an elegant solution”Why were you even messing with the instance name? This is a ridiculously simple problem to solve with tags on your ASG. And AWS even did the courtesy of propagating those tags across the ASG and all its instances.https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;autoscaling&#x2F;ec2&#x2F;userguide&#x2F;ec2-au... reply justin_oaks 14 hours agorootparentprev> 1) having the project&#x2F;account your in visible at the top at all times.I agree that this is an annoying issue in the AWS web console.I assume this is something that could be fixed on your end by a little bit of CSS. reply thedougd 12 hours agorootparentI believe the solution is to give the account an alias.https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;IAM&#x2F;latest&#x2F;UserGuide&#x2F;console_acc... reply grogenaut 12 hours agorootparentprevwe fix that internally by having names for accounts and having stages for accounts in a meta tool. There&#x27;s a tampermonkey script that pulls that in and shows it on screen and a red banner if it&#x27;s prod. Could be a json file in a github repo. And yes it could be a console feature but everyone&#x27;s got different concepts of prod. I think a ton of companies use like 2 total accounts as well. reply sparc24 15 hours agoparentprevIt&#x27;s amazing how people complain about GCP. We run a massive deployment across 100+ regions cross-cloud GCP, Azure, AWS and oh boy. GCP has good support if you are big enough. Azure though which has a much bigger share than GCP is horrendous. Absolutely garbage all around. Good luck ever getting anyone in Engineering even if you are paying for support. AWS on the other hand - Amazing. We have Ent Support so those guys in our slack channel. The TAMs are amazing. Need to get hold of someone in Route53 no problem they are on the call this week. Feature request for EKS - ok talk to the Product Manager this afternoon.Azure is a dumpster fire from the ground up. reply CommanderData 15 hours agorootparentCan you give Azure specifics, as you know Azure has a massive offering.My experience has been the opposite though not without issues, Azure has some of the best corporate and security features of any cloud and it&#x27;s only getting better. The zero trust model fits in so nicely with their identity platforms it&#x27;s a sight to behold compared to other cloud providers which likely use some form of AAD or AD DS anyway.Their support is responsive and they seem to know what they&#x27;re talking about. (AKS)Please provide some specifics on your experience? reply spiffytech 2 hours agorootparentA memorable example is when we ran a heavy Azure Functions workload on our App Service Plan, the hosts would devour themselves.Functions use containers under the hood. Each invocation created a new container, and when enough of them ran long enough, the host disk would fill up. (Pretty sure our workload wrote almost nothing to disk.)An internal Azure disk clean-up routine kicked in, which deleted image layers for running Functions. This deleted the filesystems for containers that were still running, yanking them out from underneath the running processes. It also meant the host couldn&#x27;t launch new instances of our Functions.At this point the host was poisoned and couldn&#x27;t launch any new work, even after the workload was reduced, It had to be terminated and replaced, after we detected the problem manually.Azure support never weemed to take the problem seriously, and after we migrated our workload off of Functions they decided the problem must be resolved since we weren&#x27;t complaining anymore. reply numbsafari 14 hours agorootparentprevAzure has had repeated, significant security failures that impact numerous customers. I don&#x27;t understand how anyone can defend their security except through willful ignorance.I have friends forced to use Azure and they routinely report issues with provisioning resources, things taking a very long time to spin up or simply being rejected because Azure doesn&#x27;t have any capacity. reply g9yuayon 18 hours agoparentprev> AWS support is so nice, you can&#x27;t believe it.This reminds me of the fond days of having weekly customers calls. We develop AWS services, and we answer our customer-support calls directly. No middle man. Just techies to techies. And we made promises to customers on the fly, and customers sometimes project managed us. reply kubb 18 hours agorootparentSounds like hell... reply oblio 17 hours agorootparentThe last part is a over the top but direct access to customers as a dev is a plus, not a minus. reply User23 14 hours agorootparentprevCustomers aren’t that bad, really. reply pirsquare 18 hours agoparentprev> AWS support is so nice, you can&#x27;t believe it.This! They even custom-coded their support portal better than those off-the-shelf vendor like Zendesk. I say this as a Zendesk paying customer.GCP on the other hand, is a F-tier in support. Almost feel like I need to beg them to get any level of help. reply cameronh90 17 hours agorootparentAt one point, Google reached out to me to try and tempt us over from AWS. I had bad experiences with Google support in the past, but liked their AI stuff and was keen to give them another go.We booked a follow up call in the calendar, I spent good time preparing my notes and requirements for the meeting... and then nobody on their side showed up or contacted me again. reply mrtksn 18 hours agorootparentprevA GCP issue was the only time I had a human contact with Google, they did well. However high scale low touch is in their DNA and you can tell it. reply Cthulhu_ 17 hours agorootparentprevWouldn&#x27;t Zendesk be one of those software things that has had too many features bolted on without oversight and&#x2F;or a unified philosophy behind it?I&#x27;m of the opinion that focused products created by smaller teams are better. reply falcolas 17 hours agoparentprevWe have an old \"quiet part out loud\" corporate story. It&#x27;s about how one arm of Google using our service and wondering why it had so much downtime, only for us to point at their GAE arm and say \"when they&#x27;re down, we&#x27;re down\". They went and talked to GAE and - funny enough - were able to correlate the downtime they observed with GAE downtime.GAE uptime improved, for a little while. Yeah, we&#x27;re on AWS now too. reply nerpderp82 17 hours agorootparentDoes Google run on GCP? reply lcw 17 hours agorootparentFrom my understanding they don&#x27;t dogfood a lot of gcp products internally. That&#x27;s how you end up with janky integrations between their products. It&#x27;s really frustrating at times to see their cloud architects pitch some grouping of technologies that you should use to find out the integrations aren&#x27;t well tested at scale. For example, pushing for pubsub to be used with dataflow for near real time processing just to figure out at scale global pubsub has high latency, above 1 minute sometimes 5 minutes, on 1% of messages at scale. reply danans 9 hours agorootparentprevYes in the sense that they use all the services and infrastructure that GCP is built in, but no in the sense of using the vanilla GCP interface.Instead many aspects of GCP&#x27;s management console are handled by different internal tools, often command line driven. IME they are often far more unwieldy than GCP.Sometimes this makes sense (far tighter access controls and configuration change controls than a typical company), and some times it&#x27;s just because of legacy ways of doing things.I worked on a team at Google that used the internal GCP to serve some code&#x2F;content for a specific feature, and it was in some ways it was more frustrating than using just either the normal internal systems or just vanilla GCP. reply GabeWeiss_ 17 hours agorootparentprevParts, yes. In reference to the specifics mentioned in here though, those services run on Infra Spanner, not Cloud Spanner, but they&#x27;re the same stack. The main reason things like Gmail, Ads, etc haven&#x27;t swapped into GCP is because of the internal tooling that&#x27;s built up around the infra spanner relating to those services specific to Google that don&#x27;t make sense in Cloud Spanner. reply QuercusMax 17 hours agorootparentIt&#x27;s way WAY more than just Infra Spanner vs Cloud Spanner. Cloud spanner doesn&#x27;t support protobuf, which is annoying, but that&#x27;s not a dealbreaker; it&#x27;s still just a DB. The issue is really all the various internal frameworks (such as Apps Framework for Java), deployment systems (Server Platform, AKA Boq&#x2F;Pod&#x2F;Urfin), and so forth. reply GabeWeiss_ 17 hours agorootparentOf course, I was simplifying. It&#x27;s always more complicated doing a migration. :) reply QuercusMax 16 hours agorootparentNot just migrations are hard, either; Google Cloud has put (almost?) zero effort into making it easy to use Cloud from systems running on Borg.My old team was building a system that was half-GCP and half-Borg, and we had to write our own (extremely bad) Cloud Spanner fake for use in tests. In contrast, Infra Spanner is extremely well supported for tests. Same with BigQuery vs Dremel and many other systems. reply jezzamon 16 hours agorootparentprevShort answer: No reply User23 14 hours agorootparentBorg still? Supposing you can say. Don’t reply if it’s still borg and you can’t. reply hot_gril 16 hours agorootparentprevMostly not. reply wiremine 17 hours agoparentprevMuch of the time GCP feels like a science project, and not a real business. AWS (and Azure) seem to be driven by customer requests, instead of Google, which feels very engineering-centric.Which is on brand with Google. They have no problem launching stuff, and no problem killing stuff. But man, then just get out of the cloud business and focus on what you&#x27;re good at. reply doesnt_know 17 hours agoparentprev> AWS support is so nice, you can&#x27;t believe it.It&#x27;s actually sort of ridiculous. AWS has the best support I have ever interacted with. I mean, our org certainly pays enough for it but it&#x27;s so completely unusual in tech, or really any sector to get great support even when you&#x27;re paying for it. reply stouset 16 hours agorootparentEvery time I run into an issue I’m reluctant to reach out to AWS support, because of my default expectation that it will be a terrible waste of time.Every time, I am also proven wrong as someone competent on their side both actually understands my issue and finds a resolution. reply traceroute66 17 hours agoparentprev> We have a bug reported back in 2020 that got closed recently without any action because it became staleOne of my pet hates is the (ab)use by repo maintainers of the auto-close-when-stale feature on Github.What useful purpose does it serve beyond making the repo maintainers look good because they have a low number of open issues ?It doesn&#x27;t actually address the issue. Its the virtual equivalent of brushing under the carpet. reply mardifoufs 17 hours agoparentprevI don&#x27;t know. I like GCP. I have been in an Azure centric corporation for close to two years now and I dearly miss GCP almost every day.My team has a sort of a sandbox where we can use almost any Azure product we want (our IT is supportive and permissive as far as that sandbox goes, which is a blessing), but even then it&#x27;s just painful in comparison.AWS is probably better though. reply hot_gril 16 hours agorootparentAzure seems like a nightmare, regardless of whether GCP or AWS is better. reply softveda 17 hours agoparentprevI worked in a Digital team 4 years back where the team was building voice channel apps for our customers on both Amazon Alexa and Google Dialogflow. Alexa NLP engine was less sophisticated we had to give it hundreds of prompts and intents. Dialogflow NLP engine required a handful of prompts for the same thing. But when it came to integration with backend APIs and support Alexa was far ahead. Despite having Dialogflow enterprise Google support would suggest to ask in StackOverflow. Amazon support on the other hand was excellent. We needed support for mTLS with the backend APIs, Amazon supported it as they understood enterprise. Google just shooed us away, their support wouldn’t even escalate this. reply catch22p 11 hours agoparentprevThere is no way this is true. Only explanation is you work for AWS :-). GCP strength is it&#x27;s cost. Yes may be the support could be better. But can you care to explain what \"hacks\" are you talking about ? And the claim that K8S(from Google) is better on AWS than GCP is absolutely false reply insanitybit 17 hours agoparentprevThe horror stories of Google support, across all of their products, is enough for me to never trust GCP. Even if someone told me today \"GCP is the exception, they have great support\" I probably wouldn&#x27;t care - they are so organizationally incapable of providing good support that, even if they did so today, I wouldn&#x27;t believe that it could last. reply YetAnotherNick 17 hours agoparentprevMatches my experience. GCP has many better services than AWS but I am not going to run production workload with them after 2 years of experience in previous company. There are so many undocumented quirks that many times you could find better solution from some random person in stackoverflow than highest tier paid support. reply acdha 13 hours agorootparentThat was my experience, too - a couple of things which were better than AWS but this constant stream of paper cuts hitting all of the problems which weren’t cool enough to get someone promoted. reply pojzon 17 hours agoparentprevDoesnt help when GKEngine has constant issues and recent upgrade feature is on 10 days strike.Recently was woken up by alert about DNS resolution issues.GCP rolled out new version of SkyDNS and NodeLocalDNS, SkyDNS reports 99% miss, had to quickly hack it.This is not the „out-of-the-box” experience you want to have. reply vismwasm 18 hours agoparentprevI generally like GCP, however their sales and customer support just aren&#x27;t any good. And some services like Vertex AI are extremely buggy while it&#x27;s hard to actually report these bugs.I think Google Cloud needs someone like Jeff Bezos as their head: Look what your customers actually want and need and understand their requirements. And they usually want good customer support and want a competent key account manager as well.When we were looking to migrate our analytics database from on-premise to a cloud alternative we were looking at BigQuery and Snowflake. BigQuery is a great product and we were already deeply invested in GCP as well. However the GCP sales team just couldn&#x27;t sell BigQuery - they just don&#x27;t know what old corporations want to hear in a sales pitch. So we went with Snowflake in the end. Not because it&#x27;s the better product but because their sales team is better.I&#x27;m not sure if the cloud business is actually a priority at Google. If it is then I think they don&#x27;t understand the mistrust Google is facing when it comes to stable long term support of their products. reply DevKoala 16 hours agoparentprevMy experience too, GCP is frustrating. However, there is nothing like BigQuery to me, I love that DB. reply ExoticPearTree 18 hours agoparentprevSupport wise, GCP is a joke run by entitled people. I had an issue some time ago with a VPN and after doing a lot of troubleshooting and having them agree the problem is on their end (packets would go in their VPN Gateway from the VPC, nothing would come out), the solution was to update my configuration on my end to workaround whatever they did because \"it is how is going to be\"...TL;DR: they broke something and wouldn&#x27;t fix it. reply sabellito 17 hours agoparentprevDoing business with Google is a liability. reply gregdoesit 20 hours agoprev“ According to the Amazon Prime Day blog post, DynamoDB processes 126 million queries per second at peak. Spanner on the other hand processes 3 billion queries per second at peak, which is more than 20x higher, and has more than 12 exabytes of data under management.”This comparison seems to be not exactly fair? Amazon’s 126 million queries per second was purely for Amazon-related services serving Prime Day generating this on DynamoDB, and not all of AWS is my read.What would have perhaps been a more fair comparison is to share the peak load that Google services running Cloud Spanner, and not the sum of all Spanner services across all of GCP and all of Google (Spanner on non-GCP infra).I will say that it would show a massive of confidence to say that Photos, Gmail and Ads heavily rely on GCP infra: which would be brand new information for me! It would add to confidence to learn more on how they use it, and if Cloud Spanner is on the critical path for those services.What is confusing, however, is how in this article \"Cloud Spanner\" is consistently used... except for when talking about Gmail, Ads and Photos, where it&#x27;s stated that \"Spanner\" is used by these products, not \"Cloud Spanner!\". Like if they were not using the Cloud Spanner infra, but their own. It would help to know what is the case, and what the load of Cloud Spanner is: and not Spanner running on internal Google infra that is not GCP.At Amazon, practically every service is built on top of AWS - a proper vote of confidence! - and my impression was that GCP had historically been far less utilised by Google for their own services. Even in this post, I&#x27;m still confused and unable to tell if those Google products listed use Cloud Spanner or their own infra running Spanner. reply tedivm 18 hours agoparentFrom the AWS blog post they referenced-> DynamoDB powers multiple high-traffic Amazon properties and systems including Alexa, the Amazon.com sites, and all Amazon fulfillment centers. Over the course of Prime Day, these sources made trillions of calls to the DynamoDB API. DynamoDB maintained high availability while delivering single-digit millisecond responses and peaking at 126 million requests per second.Amazon was very, very clear on this. For Google to use that number without the caveat is just completely underhanded and dishonest. Whoever wrote this is absolutely lacking in integrity. reply ljm 18 hours agorootparentI used DynamoDB as part of the job a few years ago and never got single-millisecond responses - it was 20ms minimum and 70+ on a cold-start, but I can accept that optimising Dynamo&#x27;s various indexes is a largely opaque process. We had to add on hacks like setting the request timeout to 5ms and keeping the cluster warm by submitting a no-op query every 500ms to keep it even remotely stable. We couldn&#x27;t even use DAX because the Ruby client didn&#x27;t support it. At the start we only had a couple of thousand rows in the table so it would have legit been faster to scan the entire table and do the rest in memory. Postgres did it in 5ms.If Amazon said they didn&#x27;t use DAX that day I would say they were lying.The average consumer or startup is not going to squeeze out the performance of Dynamo that AWS is claiming that they have achieved.In fact, it might have been fairer in Ruby if they didn&#x27;t hard-code the net client (Net&#x2F;HTTP). I imagine performance could have been boosted by injecting an alternative. reply iot_devs 17 hours agorootparentNo need to guess when you can measure.I am running https:&#x2F;&#x2F;cloud-canary.com a service where I monitor AWS primary services for latency and availability.It comes with a lot of data.For instance this is the latency I see doing operations against Dynamo.https:&#x2F;&#x2F;cloudcanary.grafana.net&#x2F;public-dashboards&#x2F;c53e2092d6... reply loxias 17 hours agorootparentWhat a cool lil side project&#x2F;company! Going to circulate this among friends...Little bit of well meaning advice: This needs copy editing -- inconsistent use of periods, typos, grammar. Little crap that doesn&#x27;t matter in the big picture, but will block some from opening their wallets. :) (\"OpenTeletry\", \"performances\", etc.)All in all this is quite cool, and I hope you get some customers and gather more data! (a 4k object size in S3 doesn&#x27;t make sense to measure, but 1MB might be interesting. Also, check out HDRHistogram, it might be relevant to your interests) reply iot_devs 16 hours agorootparentThanks!Any feedback is appreciated!I pick 4k as a no-op against S3, something that very little time but still does some work.I will definitely consider to increase it! reply bennyg 17 hours agorootparentprevNice dash - if you don&#x27;t mind a drive-by recommendation: I use Grafana for work a lot and it&#x27;s nice to see a table legend with min, max, mean, and last metrics for these kinds of dashboards. Really makes it easy to grok without hovering over data points and guessing. reply RedlineTriad 54 minutes agorootparentWhat is more important for me when using Grafana (though a summary is as well) is actually units, to know if it&#x27;s second, millisecond, microsecond, and also if 0.5 is a quantile or what.Numbers without units are dangerous in my opinion. reply iot_devs 17 hours agorootparentprevThanks a lot!I&#x27;ll definitely update it! reply qwertox 17 hours agorootparentprevWhat a cool service. Congratulations! reply RhodesianHunter 18 hours agorootparentprev> We had to add on hacks like setting the request timeout to 5ms and keeping the cluster warm by submitting a no-op query every 500ms to keep it even remotely stable.This sounds like you&#x27;re blaming dynamo for you&#x2F;your stack&#x27;s inability to handle connections &#x2F; connection pooling. reply tedivm 16 hours agorootparentYeah that TLS handshake is an absolute killer if you run it for every request. reply iends 18 hours agorootparentprevBeen using DynamoDB for years and haven’t had to do any of the hacks you talk about doing. Not using ruby though. TCP keep-alive does help with perf though (which I think you might be suggesting.)I don’t have p99 times in front of me right this second but it’s definitely lower than 20ms for reads and likely lower for writes. (EC2 in VPC). reply mk89 18 hours agorootparentprevThey very well know that people don&#x27;t read sh* anymore. Just throw numbers there, PowerPoint them and offer an \"unbiased\" comparison where Google shines - buy Google.Worst case scenario, it&#x27;s Google you&#x27;re buying, not a random startup etc. reply azmodeus 18 hours agorootparentGoogle doesn&#x27;t have a great brand of not killing products. No support and randomly killing stuff is not a good business relationship reply GabeWeiss_ 18 hours agorootparentprevJust as a hand in the air...Be careful about what you&#x27;re comparing here. # of API calls over a period of time is...largely irrelevant in the face of QPS. I can happily write a DDOS script that massively bombards a service, but if that halts my QPS then it doesn&#x27;t matter. So sure, trillions of API calls were made (still impressive in the scope of the overall network of services, I&#x27;m not downplaying that), but ultimately, for DynamoDB and Spanner, it&#x27;s the QPS that mattered to us in terms of comparisons of DB scaling and performance. reply vineyardmike 18 hours agorootparentGoogle calls API calls “queries”… because of their history as a search engine. QPS == API calls&#x2F;per second == Requests per secondThat said, I can’t imagine these numbers mean much to anyone after a certain point. It’s not like either company is running a single service handling them. The scale is limited by their budget and access to servers because my traffic shouldn’t impact yours. I feel like the better number is RPS&#x2F;QPS per table or per logical database or whatever. reply GabeWeiss_ 17 hours agorootparentYes, but QPS vs. \"queries to the API\". The difference is the time slice. I should have been more explicit. The key here really is the time function between the numbers. That the AWS blog calls out trillions of API calls isn&#x27;t relevant because there wasn&#x27;t a specific time denominator. The 126M QPS is the important stat. reply forrestbrazeal 20 hours agoparentprevWe shared some details about Gmail&#x27;s migration to Spanner in this year&#x27;s developer keynote at Google Cloud Next [0] - to my knowledge, the first time that story has been publicly talked about.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=268jdNwH6AM reply gregdoesit 20 hours agorootparentI tried to find it in this video, but failed. Could you please share a time stamp on where to look?It’s a pretty big deal if Gmail migrated to GCP-provided Spanner(not to an internal Spanner instance) and sounds like he kind of vote of confidence GCP and Cloud Spanner could benefit from: might I suggest to write about it? It’s easier to digest and harder to miss than an hour-long keynote video with no time stamps.And so just to confirm: Gmail is on Cloud Spanner for the backend? reply dekhn 19 hours agorootparentIt&#x27;s almost certainly not the case that Gmail uses Cloud Spanner rather than Internal Spanner. I don&#x27;t think Cloud Spanner (or most of Google&#x27;s cloud products) have the featureset required to support loads like Gmail (both in terms of technical capability, and security&#x2F;privacy features).When I worked at Google I tried to get more services to migrate to the cloud but the internal environment that was built up over 25 years is much better at supporting billion+ users with private data. reply Cthulhu_ 17 hours agorootparentAnd yet, if they do, that&#x27;s probably one of the best sales pitches they could have - dogfooding. After all, isn&#x27;t that also how AWS started, just reselling the services and servers they already use themselves?It doesn&#x27;t make much sense to have a &#x27;better&#x27; version of a product you sell but keep it internal. reply jeffbee 17 hours agorootparentIt makes sense because the public will not use the internal APIs which have non-standard wire protocols, weird authentication schemes, etc. reply alphabetting 19 hours agorootparentprevlooks like it starts at 50:45. youtube recently made it so you can click \"show transcript\" in the description then ctrl-f takes you to all the mentions. very helpful for long videos like this. reply easton 19 hours agorootparentprevIt looks like the Spanner beta dropped to the public in 2017, soI will say that it does show a vote of confidence to say that Photos, Gmail and Ads use GCP infra,I&#x27;m not sure? I guess I&#x27;m mostly not sure what \"gcp infra\" means there. The blog post says\"Spanner is used ubiquitously inside of Google, supporting services such as; Ads, Gmail and Photos.\"But there&#x27;s google-internal spanner, and gcp spanner. A service using spanner at Google isn&#x27;t necessarily using gcp. (No clue about photos, Gmail, etc)Granted, from what I gather, there&#x27;s a lot more similarity between spanner & gcp spanner than e.g. borg and kubernetes. reply bananapub 19 hours agorootparentborg and k8s are completely unrelated bits of software with roughly similar goals.gcp spanner and normal spanner are different deployments of the same code. reply marcinzm 18 hours agorootparent>different deploymentsWhich can be the difference between 99.99% availability and 99% availability with data corruption issues. Not saying that&#x27;s the case here but one should not downplay the difference deployments can make. reply gregdoesit 19 hours agorootparentprevSurely in a post about Google Cloud Spanner, all examples mentioned use Google Cloud Spanner? It would be moot listing them as examples if they would not: so my assumption is they are all using GCP infra already for Spanner.I really want to give Google the benefit of the doubt: but it doesn&#x27;t help that they did not write that eg Gmail is using \"Cloud Spanner.\" They wrote that it uses Spanner. reply ericpauley 19 hours agorootparentThis is putting a lot of faith in GCP advertising. I strongly doubt the idea that the Google workloads discussed are deployed on GCP instead of internal Borg infrastructure. reply kccqzy 18 hours agorootparentprevYears ago they did a reorg and moved all infrastructure services under Cloud even though they are not Cloud products. That would enable this kind of obfuscation because Cloud is literally responsible for both Cloud Spanner and non-Cloud Spanner and they can conflate these two in their marketing copy. They probably feel justified in doing so because they share so much code. reply 0xbadcafebee 19 hours agorootparentprevConsidering that most of Google does not run on GCP, I would not give them the benefit of the doubt. reply blueg3 13 hours agorootparentprevPhotos, Gmail, and Ads use Spanner, not Cloud Spanner.Apparently Cloud Spanner doesn&#x27;t support protobuf columns? It would be hard for any internal Google product to use it under that restriction. reply GabeWeiss_ 18 hours agorootparentprevInfra and Cloud Spanner are the same stack. Having those services run on infra is more about the legacy of tooling to shift it rather than anything around performance or ability to handle it reply GabeWeiss_ 18 hours agorootparentprevInfra and Cloud Spanner are the same stack. Having those services run on infra is more about the legacy of tooling to shift it rather than anything around performance or ability to handle it. reply tw04 18 hours agoparentprev>This comparison seems to be not exactly fair? Amazon’s 126 million queries per second was purely for Amazon-related services serving Prime Day generating this on DynamoDB, and not all of AWS is my read.There&#x27;s no indication that google is talking about ALL of spanner either? The examples they list are all internal google services, and they specifically say \"inside google\".I&#x27;m also dubious that even with all of the AWS usage accounted for that DynamoDB tops Spanner if Amazon themselves are only at 126 million queries per second on Prime Day. reply g9yuayon 18 hours agoparentprev> At Amazon, practically every service is built on top of AWS - a proper vote of confidence!Not only this, but practically most, if not all, of the AWS services use DynamoDB, including use cases that are usually not for databases, such as multi-tenant job queues (just search \"Database as a Queue\" to get the sentiment). In fact, it is really really hard to use any relational DB in AWS. I mean, a team would have to go through a CEO approval to get exceptions, which says a lot about the robustness of DDB. reply tacozilla 17 hours agorootparentEh, this isn&#x27;t accurate. Both Redshift and Aurora&#x2F;RDS are used heavily by a lot of teams internally. If you&#x27;re talking specifically about the primary data store for live applications, NoSQL was definitely recommended&#x2F;pushed much harder than SQL, but it by no means required CEO approval to not use DDBEdit: It&#x27;s possible you&#x27;re limiting your statement specifically to AWS teams, which would make it more accurate, but I read the use of \"Amazon\" in the quote you were replying to as including things like retail as well, etc. reply g9yuayon 17 hours agorootparentYeah, within AWS. I&#x27;m not sure about other parts of Amazon reply sharpy 18 hours agorootparentprevWhen I was at AWS, towards later part of my tenure, DynamoDB was mandated for control plane. To be fair, it worked, and worked well, but there were times when I wished I could use something else instead. reply Rapzid 19 hours agoparentprevFrankly it&#x27;s a bit weird to see this kind of dick measuring in a product blog post from the \"Director of Engineering\" :&#x2F; reply cbarrick 18 hours agorootparents&#x2F;the \"Director of Engineering\"&#x2F;a \"Director of Engineering\"&#x2F;There are many engineering directors at Google. reply blueg3 13 hours agorootparentDirector is what, L8? There&#x27;s a ton of those. reply Rapzid 16 hours agorootparentprevAnd only one attributed to the blog post.swish reply ripper1138 19 hours agorootparentprevTrue and even worse, inaccurate dick measuring. reply brunoborges 19 hours agoparentprev> What would have perhaps been a more fair comparison is to share the peak load that Google services running on GCP generated on Spanner, and not the sum of their cloud platform.Not necessarily about volume of transactions, but this is similar to one of my pet-peeves with statements that use aggregated numbers of compute power.\"Our system has great performance, dealing 5 billion requests per second\" means nothing if you don&#x27;t break down how many RPS per instance of compute unit (e.g. CPU).Scales of performance are relative, and on a distributed architecture, most systems can scale just by throwing more compute power. reply hangonhn 19 hours agorootparentYeah I&#x27;ve seen some pretty sneaky candidates try that on their resumes. They aggregate the RPS for all the instances of their services even though they don&#x27;t share any dependencies nor infrastructure. They&#x27;re just independent instances&#x2F;clusters running the same code. When I dug into those impressive numbers and asked about how they managed coordination&#x2F;consensus the truth comes out. reply GabeWeiss_ 18 hours agorootparentprevTrue, but one would hope that both sides in this case would be putting their best foot forward. Getting peak performance out of right sizing your DB is part of that discussion. I can&#x27;t imagine AWS would put down \"126 million QPS\" if they COULD have provided a larger instance that could deliver \"200 million QPS\", right? We have to assume at some point that both sides are putting their best foot forward given the service. reply redditor98654 7 hours agorootparentThe 126M QPS number was certainly parts of Amazon.com retail that powers Prime Day not all of DDB traffic. If we were to add up all of DDB&#x27;s volume, it would be way higher. At least a magnitude if not more.Large parts of AWS itself uses DDB - both control plane and data plane. For instance, every message sent to AWS IoT will internally translate to multiple calls to DDB (reads and writes) as the message flows through the different parts of the system. IoT itself is millions of RPS and that is just one small-ish AWS service.Source: Worked at AWS for 12 years. reply BoorishBears 19 hours agorootparentprevPut yourself in the shoes of who they&#x27;re targeting with that.Probably dealing with thousands of requests per seconds, but wants to say they&#x27;re building something that can scale to billions of requests per second to justify their choices, so there they go. reply jjtheblunt 18 hours agoparentprev> At Amazon, practically every service is built on top of AWSis that true finally? It sure wasn&#x27;t in the 2020-2021 timeframe. reply dastbe 17 hours agorootparentit does depend on what you mean. By 2020&#x2F;2021, effectively everything was on top of AWS VMs&#x2F;VPC and perhaps LBs at that point? Most if not all new services were being built in NAWS. reply jjtheblunt 17 hours agorootparentSPS was heavily MAWS and I got sick of being the NAWS person from years prior pushing for NAWS in our dysfunctional team, and quit. The good coworkers also quit.Yet I still see the very deep stack of technically incapable middle manager sorts dutifully posting \"come join us\" nonsense on LinkedIn.(I had the luxury of having worked in one of the inner sanctums of Apple hardware for years prior, so was immune to nonsense, and didn&#x27;t need the job.) reply nameless912 20 hours agoprevAnd for many projects, Postgres is still cheaper than both. Having used both, I would much, much rather do the work to fit my project in Postgres&#x2F;CockroachDB than use either Spanner or DynamoDB, which have WAY more footguns. Not to mention sudden cost spikes, vendor lock in, and god knows what else.AWS and GCP (and Azure, and Oracle cloud, and bare Kubernetes via an operator, and...) support Postgres really well. Just...use Postgres. reply bananapub 19 hours agoparent> And for many projects, Postgres is still cheaper than both.ok? and sqlite3 in memory is even cheaper than postgres!if you can use (and support correctly) postgres then you should use it, obviously there&#x27;s no point using a globally scalable P-level database if you can just fit all your data on one machine with posthgres. reply airstrike 19 hours agoparentprevExcept for projects for which NoSQL is a better fit than a RDBMS, no?If I&#x27;m writing a chat app with millions of messages and very little in the way of \"relationships\", should I use Postgres or some flavor of NoSQL? Honest question. reply Olreich 18 hours agorootparentPostgres. NoSQL databases are specialized databases. They are best-in-class at some things, but generally that specialization came at great cost to their other options. DynamoDB is an amazing key-value store, but is severely limited at everything else. Elasticsearch is an amazing for search and analytics, but is severely limited at everything else. Other specialized databases that are SQL-full are also great at what they do, like Spark is a columnar database that has amazing capabilities for massive datasets where you need lots of cross-joins, but that severely limits it&#x27;s ability to act in a lot of roles, because they traded latency for throughput and horizontal scalability, and you&#x27;re restricted in what you can do with it.The super-power of Postgres is that it supports everything. It&#x27;s a best-in-class relational database, but it&#x27;s also a decent key-value store, it&#x27;s a decent full-text search engine, it&#x27;s a decent vector database, it&#x27;s a decent analytics engine. So if there&#x27;s a chance you want to do something else, Postgres can act as a one-stop-shop and doesn&#x27;t suck at anything but horizontal scaling. With partitioning improving, you can deal with that pretty well.If you&#x27;re writing fresh, there is basically no reason not to use Postgres to start with. It&#x27;s only when you already know your scale won&#x27;t work with Postgres that you should reach for a specialized database. And if you think you know because of published wisdom, I&#x27;d recommend you set up your own little benchmark, generate the volume of data you want to support, and then query it with Postgres and see if that is fast enough for you. It probably will be. reply jpgvm 19 hours agorootparentprevGolden Rule of data: Use PostgreSQL unless you have an extremely good reason not to.PostgreSQL is extremely good at append-mostly data, i.e like a chat log and has powerful partitioning features that allow you to keep said chat logs for quite some time (with some caveats) while keeping queries fast.Generally speaking though PostgreSQL has powerful features for pretty much every workload, hence the Golden Rule. reply GabeWeiss_ 18 hours agorootparent100% this, and even though I work for Google I absolutely agree. BUT, for the folks that need it, PostgreSQL just DOESN&#x27;T cut it, so it&#x27;s why we have databases like DynamoDB, Spanner, etc. Arguing that we should \"Just use PG\" is kinda a moot point. reply nameless912 2 hours agorootparentI think I said this in another comment, but I&#x27;m not shitting on Spanner or DDB&#x27;s right to exist here. Obviously, there are _some_ problems for which a globally distributed ACID compliant SQL-compatible database are useful. However, those problems are few and far between, and many&#x2F;most of them exist at companies like Google. The fact is your average small to medium size enterprise doesn&#x27;t need and doesn&#x27;t benefit from DDB&#x2F;Spanner, but \"enterprise architects\" love to push them for some ungodly reason. reply pezezin 17 hours agorootparentprevDon&#x27;t forget PostgreSQL extensions. For something like a chat log, TimescaleDB (https:&#x2F;&#x2F;www.timescale.com&#x2F;) can be surprisingly efficient. It will handle partitioning for you, with additional features like data reordering, compression, and retention policies. reply loxias 16 hours agorootparentprevMillions is tiny. Toy even. (I work on what could be called a NoSQL database, unfortunately \"NoSQL\" is a term without specificity. There&#x27;s many different ways to be a non-relational database!)My advise to you is to use Postgresql or, heck, don&#x27;t over think it, sqlite if it helps you get a MVP done sooner. Do NOT prematurely optimize your architecture. Whatever choice results in you spending less time thinking about this now is the right choice.In the unlikely event you someday have to deal with billions of messages and scaling problems, a great problem to have, there are people like me who are eager to help in exchange for money.Lots of people like to throw around the term \"big data\" just like lots of people incorrectly think that just because google or amazon need XYZ solution that they too need XYZ solution. Lots of people are wrong.If there exists a motherboard that money can buy, where your entire dataset fits in RAM, it&#x27;s not \"big data\". reply silisili 19 hours agorootparentprevI&#x27;ve found it&#x27;s pretty easy to massage data either way, depending on your preference. The one I&#x27;m working on now ultimately went from postgres, to mysql, to dynamo, the latter mainly for cost reasons.You do have to think about how to model the data in each system, but there are very few cases IMO where one is strictly &#x27;better.&#x27; reply ruuda 18 hours agorootparentprevPostgres; the schema is still structured. But even if you want something less rigid, Postgres has a jsonb type and great operators for querying json. reply btown 18 hours agorootparentYou can also create arbitrary indices on derived functions of your JSONB data, which I think is something that a lot of people don&#x27;t realize. Postgres is a really, really good NoSQL database. reply cooperaustinj 18 hours agorootparentCan you expand on this? Documentation or an example so I can learn? reply tczMUFlmoNk 17 hours agorootparentSure. Suppose that we have a trivial key-value table mapping integer keys to arbitrary jsonb values: example=> CREATE TABLE tab(k int PRIMARY KEY, data jsonb NOT NULL); CREATE TABLEWe can fill this with heterogeneous values: example=> INSERT INTO tab(k, data) SELECT i, format(&#x27;{\"mod\":%s, \"v%s\":true}&#x27;, i % 1000, i)::jsonb FROM generate_series(1,10000) q(i); INSERT 0 10000 example=> INSERT INTO tab(k, data) SELECT i, &#x27;{\"different\":\"abc\"}&#x27;::jsonb FROM generate_series(10001,20000) q(i); INSERT 0 10000Now, keys in the range 1–10000 correspond to values with a JSON key \"mod\". We can create an index on that property of the JSON object: example=> CREATE INDEX idx ON tab((data->&#x27;mod&#x27;)); CREATE INDEXThen, we can query over it: example=> SELECT k, data FROM tab WHERE data->&#x27;mod&#x27; = &#x27;7&#x27;; kdata ------+--------------------------- 7{\"v7\": true, \"mod\": 7} 1007{\"mod\": 7, \"v1007\": true} 2007{\"mod\": 7, \"v2007\": true} 3007{\"mod\": 7, \"v3007\": true} 4007{\"mod\": 7, \"v4007\": true} 5007{\"mod\": 7, \"v5007\": true} 6007{\"mod\": 7, \"v6007\": true} 7007{\"mod\": 7, \"v7007\": true} 8007{\"mod\": 7, \"v8007\": true} 9007{\"mod\": 7, \"v9007\": true} (10 rows)And we can check that the query is indexed, and only ever reads 10 rows: example=> EXPLAIN ANALYZE SELECT k, data FROM tab WHERE data->&#x27;mod&#x27; = &#x27;7&#x27;;QUERY PLAN--------------------------------------------------------------------------------------------------------------- Bitmap Heap Scan on tab (cost=5.06..157.71 rows=100 width=40) (actual time=0.035..0.052 rows=10 loops=1) Recheck Cond: ((data -> &#x27;mod&#x27;::text) = &#x27;7&#x27;::jsonb) Heap Blocks: exact=10 -> Bitmap Index Scan on idx (cost=0.00..5.04 rows=100 width=0) (actual time=0.026..0.027 rows=10 loops=1) Index Cond: ((data -> &#x27;mod&#x27;::text) = &#x27;7&#x27;::jsonb) Planning Time: 0.086 ms Execution Time: 0.078 msIf we did not have an index, the query would be slower: example=> DROP INDEX idx; DROP INDEX example=> EXPLAIN ANALYZE SELECT k, data FROM tab WHERE data->&#x27;mod&#x27; = &#x27;7&#x27;;QUERY PLAN--------------------------------------------------------------------------------------------------- Seq Scan on tab (cost=0.00..467.00 rows=100 width=34) (actual time=0.019..9.968 rows=10 loops=1) Filter: ((data -> &#x27;mod&#x27;::text) = &#x27;7&#x27;::jsonb) Rows Removed by Filter: 19990 Planning Time: 0.157 ms Execution Time: 9.989 msHence, \"arbitrary indices on derived functions of your JSONB data\". So the query is fast, and there&#x27;s no problem with the JSON shapes of `data` being different for different rows.See docs for expression indices: https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;16&#x2F;indexes-expressional.html reply jopsen 5 hours agorootparentprev> If I&#x27;m writing a chat app with millions of messages...Once you have millions of messages, maybe consider moving the data intensive parts out if postgres, if necessary.The criticism is often that people look for big data solutions, before they have big data.If you scale out of postgres, you probably have enough users and money that you can fix it :)But moving to a NoSQL before you have to, might just slow down development velocity -- also you haven&#x27;t yet learned what patterns users have. reply toast0 18 hours agorootparentprevEither way can work. Getting to millions of messages is going to be the hard part, not storing them.As with all data storage, the question is usually how do you want to access that data. I don&#x27;t have experience with Postgres, but a lot of (older) experience with MySQL, and MySQL makes a pretty reasonable key-value storage engine, so I&#x27;d expect Postgres to do ok at that too.I&#x27;m a big fan of pushing the messages to the clients, so the server is only holding messages in transit. Each client won&#x27;t typically have millions of messages or even close, so you have freedom to store things how you want there, and the servers have more of a queue per user than a database --- but you can use a RDBMS as a queue if you want, especially if you have more important things to work on. reply sosodev 11 hours agorootparentprevSeems to me like there are still plenty of relationships in a chat app. Postgres can be used like a NoSQL database via JSONB too if you want.I think the truth is that you should use the simplest, most effective tech possible until you are absolutely certain you need something more niche. reply BoorishBears 19 hours agorootparentprevThis is going to feel like a non-answer: but if you need to ask this question in this format, save yourself some great pain and use Postgres or MongoDB, doesn&#x27;t really matter which, just something known and simple.Normally you&#x27;d make a decision like this by figuring out what your peak demand is going to look like, what your latency requirements are, how distributed are the parties, how are you handling attachments, what social graph features will you offer, what&#x27;s acceptable for message dropping, what is historical retention going to look like...[continues for 10 pages]But if you don&#x27;t have anything like that, just use something simple and ergonomic, and focus on getting your first few users. There&#x27;s a long gap between when the simple choice will stop scaling and those first few users. reply airstrike 16 hours agorootparentThanks, I really appreciate this. DynamoDB was pretty simple to setup, all things considered. Some growing pains, but it&#x27;s a dead simple schema.I&#x27;m using SenseDeep&#x27;s OneTable which was pretty interesting to learn https:&#x2F;&#x2F;doc.onetable.io&#x2F; in case others reading this are curious. reply aketchum 20 hours agoparentprevjust migrated off of PG to ddb as the main db for my application (still copying data to SQL for data analytics). Working with distributed functions and code hosted on lambdas, the connection management to SQL became a nightmare with dropped requests all over the place. reply jpgvm 19 hours agorootparentSacrificing a real DB to use serverless is exactly why serverless makes zero sense. reply makestuff 12 hours agorootparentYeah I have been using Supabase recently and I really like it. You still get the “serverless” benefits but at the end of the day it is just a Postgres database with some plugins. It is super easy to figure out where the data is coming from&#x2F;going to.Meanwhile at work I have a cowoker who loves to create AWS soup where they use an assortment of lambdas&#x2F;api gateways&#x2F;sqs queues&#x2F;sns topics to accomplish tasks such as taking files from one s3 bucket and putting them in another s3 bucket owned by a different team. Their justification of this was that it was generic so other teams could use it, but it is a pain to maintain and make changes to. reply nameless912 20 hours agorootparentprevA connection pooling proxy should fix this shouldn&#x27;t it? I think both Google and AWS have this solved for functions as a service. reply aketchum 20 hours agorootparentyeah but you run into other issues when you put all of your lambdas on the same VPC reply nameless912 20 hours agorootparentNot to be that guy, but why lambdas? I&#x27;m genuinely curious. I&#x27;ve never found the \"cost savings\" (big air quotes) worth it in comparison to the increased configuration&#x2F;permissions complexity. Especially when Fargate exists, where you can just throw a docker container at AWS, what do Lambdas add? The zero scaling? reply qvrjuec 20 hours agorootparentWith CDK, I can get an ECS service up and running in the same amount of time it&#x27;d take to create a lambda function behind API gateway or triggered by SQS&#x2F;cron. Deploys are easier, cost savings are real, permissions&#x2F;configuration are the same level of complexity unless you&#x27;re cutting corners. I&#x27;d only use ECS for stuff I know would be high sustained throughput, long duration(>15m) tasks, or things that absolutely need more persistence between executions. reply hooverd 19 hours agorootparentServerless is great if you recognize that it&#x27;s just somebody else&#x27;s container runtime. I wish there was better tooling for Docker based Lambdas though. I hate whole S3 deployment dance for zip file based Lambdas (yes SAM does it for you now but it&#x27;s still there).EC2-backed ECS has a great use case for things that you can run ephemerally in a container but require a persistent data store. reply Zanfa 18 hours agorootparentprevWhy not? The setup I’m experimenting with for an API right now is basically a single Lambda that’s accessible through a function URL (so no ELB&#x2F;ALB) + an RDS instance. Spinning up additional environments is a single Cloudformation call and deployment artifacts should work with both Docker containers or S3 (depending on the Lambda execution environment).Seems like a leaner setup than using ECS&#x2F;Fargate + LBs to me. Have I overlooked something? reply sakopov 20 hours agorootparentprevYour mileage may vary, but I think in majority of the cases Fargate is going to be significantly more expensive than Lambda. reply nameless912 19 hours agorootparentBut at low request volumes, either is a rounding error to a medium size enterprise, and for personal projects IMO Lambda is a huge PITA. reply meowtimemania 19 hours agorootparentOne of lambda&#x27;s ideal use cases is personal projects. Personal projects usually serve very few requests so lambda&#x27;s ability to scale to zero results in cost savings. reply hooverd 19 hours agorootparentprev&#x2F;shill The AWS SAM CLI smooths over a lot of Lambda&#x27;s rough points. &#x2F;unshill reply nameless912 19 hours agorootparentGasp, a shill??I totally believe you, I just can&#x27;t see how it becomes easier than chucking a container on Fargate or something. Maybe I&#x27;ve just been scarred by lambda rat&#x27;s nests in the past. reply iends 18 hours agorootparentThe serverless framework makes lambda for side projects a breeze.CDK for everything else. reply hooverd 18 hours agorootparentprevYeah, the \"proper\" way to do Lambdas, shown in so many fancy architecture diagrams, is a rat&#x27;s nest. I don&#x27;t like APIs on Lambda unless you can shove them into one container with a catchall proxy on API Gateway. They really shine if you&#x27;re processing SQS messages or EventBridge events. If you aren&#x27;t using other AWS services and aren&#x27;t cost engineering, then Lambdas probably aren&#x27;t worth the headache. reply Olreich 18 hours agorootparentprevLambda is the most expensive thing you can do if you have more than 25% utilization. Fargate is extremely close to modern on-demand EC2 pricing (m7a family). reply makestuff 12 hours agorootparentYeah you can run Fargate on EC2 now as well to optimize cost even further. reply oarmstrong 6 hours agorootparentFargate on EC2? Sorry you’ve lost me, I understood Fargate to be a layer of AWS managed compute for ECS or EKS deliberately instead of EC2. reply cdelsolar 18 hours agorootparentprevI don&#x27;t think that&#x27;s actually true on a GB-second basis (memory * CPU)? reply hooverd 18 hours agorootparentThe cost efficiency of Lambda vs Fargate&#x2F;EC2 ECS&#x2F;one of the dozen other ways to run containers on AWS plummets as your RPS goes up. replyGabeWeiss_ 17 hours agoparentprevBut that&#x27;s kind of a moot point. I mean, if you&#x27;re even looking at the likes of DynamoDB or Spanner, it&#x27;s because you need the scale of those engines. PostgreSQL is fantastic, and even working for Google, I 100% agree with you. Just use PG...until you can&#x27;t. Once you&#x27;re in the realm of Spanner and DynamoDB, that&#x27;s where this discussion becomes more of a thing. reply silisili 16 hours agorootparentNot necessarily true. DynamoDB on demand pricing is actually way cheaper than RDS or EC2 based anything for small workloads, especially when you want it replicated. reply GabeWeiss_ 15 hours agorootparentFair enough, I&#x27;m not (obviously) as familiar with the AWS systems and how the price to performance ratio works out for all the products. reply 0xbadcafebee 19 hours agoparentprevPostgres and Spanner do different things, in different ways, with different costs, risks, and implications. You could \"just use\" anything that is completely different and slightly cheaper. You could use a GitHub repository and just store your records as commits, for free, that&#x27;s plenty cheap and works for small projects. But not really the same thing, is it? reply nameless912 19 hours agorootparentMy point is that I&#x27;ve seen very, very few situations (I can think of two in my entire career so far) where a \"hyperscale NoSQL database\" was actually the right choice to solve the problem. I find that a lot of folks turn to these databases for imagined scale needs, not actual hard problems that need solving. reply 0xbadcafebee 14 hours agorootparentDynamoDB is fantastic for not doing things at scale. It costs a few pennies, there is nothing to set up, it&#x27;s all managed for you, it is insanely reliable, and it just works. I use it for all kinds of crap that an entire RDBMS is way overkill for. reply eklitzke 19 hours agorootparentprevSpanner has a SQL interface, fyi. reply nameless912 19 hours agorootparentI don&#x27;t think the API you interface with fundamentally changes the point that Spanner is hard to recommend from an engineering perspective at anything except the absolute most massive of scales, and even then it will create nearly as many problems as it solves. I&#x27;m not saying spanner is _wrong_ or shouldn&#x27;t exist, but it&#x27;s very difficult to be in the position where Spanner is the critical key to your application&#x27;s success and not replaceable by . reply endorphine 18 hours agorootparentCare to elaborate on what are the problems that it will create? Honest question. reply nameless912 2 hours agorootparentSure. Spanner is expensive, and your primary job as an engineer (if you work for an enterprise like most of us do) is to generate business value. So, if nothing else, you will run into the cost problems of Spanner. There are also other problems; iirc both DynamoDB and Spanner shard their key spaces, and each shard gets the same quota, and the key space shards all have to be the same size. This means that even though you might have paid for 1000rps, for example, that RPS volume is divided across all your shards, so if you have one part of the key space that gets way more volume than another you end up eating up the fractional capacity of that shard way faster than you intend and you have to either overprovision or queue requests, both of which are not ideal.At a previous job, we ended up creating a very complicated write through cache system in front of spanner that dynamically added memory&#x2F;CPU capacity as needed to prevent hot shards; our application was extremely read heavy, and writes were relatively low RPS, so this ended up working OK, but we were paying tens of thousands of dollars a month for Spanner plus tens of thousands of dollars a month for all the compute sitting in front of it. I don&#x27;t think we ended up doing much better than if we had bitten the bullet and run clustered Postgres because our write volume ended up being just a few hundred RPS, even though the read volume was 1000x that. Postgres behind this cache system would have handled the load just as well and cost less than half as much.The other thing that frustrates me personally about Spanner is that Google&#x27;s docs are incomplete (as usual); there are lots of performance gotchas like this that exist throughout the entire service, and they aren&#x27;t clearly documented (unlike, to their credit, AWS with Dynamo, who explains this entire problem very clearly and has an [expensive] prebuilt solution for it in the form of the DynamoDB accelerator). replyagonz253 17 hours agoparentprevIt&#x27;s not purely a matter of cost, right? Say you want or need a highly available, high performance distributed database with externally consistent semantics. Are you going to handle the sharding of your Postgres data yourself? What replication system will you use for each shard? How will you ensure strong consistency? Will you be able to do transactions across shards? These are problems that systems like Spanner, CockroachDB, etc solve for you. reply YetAnotherNick 17 hours agorootparentJust curious, why would distributed be design requirement? Is individual machine failure likely in AWS&#x2F;GCP? The only failure I have seen in region level issues which spanner or dynamo don&#x27;t help with AFAIK. reply agonz253 17 hours agorootparentIndividual machine failure is not likely, but we&#x27;re hypothesizing the need for multiple shards for high performance. So now we have more machines and so the probability of failure increases. So we need to add replication, but then we need to deal with data getting out of sync, etc.... As others have mentioned though, these issues only really become important at a certain scale. reply remus 19 hours agoparentprevI know the spanner marketing blurb says you can scale down etc. But I think in practice spanner is primarily aimed at use cases where you&#x27;d struggle to fit everything in a single postgres instance.Having said that I guess I broadly agree with your comment. It seems like a lot of people like to plan for massive scale while they have a handful of actual users. reply nameless912 19 hours agorootparentI said this in another comment, but I have seen _two_ applications in my career that actually had a request load that might warrant something like one of these databases. One was an application with double digit million MAU and thousands of RPS on a very shardable data set, which fit Spanner&#x27;s ideal access pattern and performance profile pretty well, but we paid an absolute arm and a leg for the privilege and ended up implementing a distributed cache in front of Spanner to reduce costs. The other just kept the data set in memory and flushed to disk&#x2F;S3 backup periodically because in that case liveness was more important than completeness.In the first case, the database created as many problems as it solved (which is true of any large application running at scale; your data store will _always_ be suboptimal). A fancy, expensive NoSQL database won&#x27;t save you from solving hard engineering problems. At smaller scales (on the order of tens-hundreds of RPS), it&#x27;s hard to go wrong with any established SQL (or open source NoSQL if that floats your boat) database, and IMO Postgres is the most stable and best bang for your engineering buck feature wise. reply ndriscoll 17 hours agorootparentPostgres&#x2F;mysql shouldn&#x27;t have much trouble doing thousands of RPS on a laptop for basic CRUD queries (i.e. as long as you don&#x27;t need to do table scans or large index range scans). It&#x27;s possible to squeeze a lot more than that out of them. reply joshuamorton 18 hours agorootparentprevSpanner isn&#x27;t NoSQL. It&#x27;s schema&#x27;d. reply hot_gril 16 hours agorootparentprevMy team bought the \"scale down\" thing and got bit.Using Spanner is giving up a lot for the scalability, and if you ever reach the scale where a single node DB doesn&#x27;t make sense anymore, I don&#x27;t know if Spanner is still the answer, let alone Spanner with your old design still intact. For one, Postgres has scaling options like Citus. Or maybe you don&#x27;t need a scalable DB even at scale, cause you shard at a higher layer instead. reply supportengineer 18 hours agoparentprevIs there any company that hosts Postgres in the cloud (and does nothing else) and has great customer service? reply M3t0r 17 hours agorootparentGive https:&#x2F;&#x2F;aiven.io&#x2F; a try. But know that I&#x27;m biased ;-)Also https:&#x2F;&#x2F;www.postgresql.org&#x2F;support&#x2F;professional_hosting&#x2F; reply LVB 18 hours agorootparentprevI&#x27;ve only kicked the tires, but https:&#x2F;&#x2F;neon.tech is a pure hosted Postgres play. I&#x27;d be curious to hear if anyone has used them for a real projects, and how that went. reply folmar 16 hours agorootparentprevElephantsql, I can&#x27;t say much for the customer service as I never had any trouble. reply emodendroket 20 hours agoparentprevI mean sure, NoSQL gives you more opportunities to screw stuff up because it&#x27;s doing less for you. But it can be a reasonable tradeoff in some scenarios anyway reply teaearlgraycold 20 hours agoparentprevPostgres is the database God himself would have made. reply nameless912 20 hours agorootparentLike, I don&#x27;t want to fanboy, but it&#x27;s _hard_ to find a use case that postgres can&#x27;t handle at small to medium (i.e. 90% of projects) scale. reply 0xbadcafebee 19 hours agorootparentIt&#x27;s hard to find a use case that a plain old filesystem can&#x27;t handle at small to medium scale. But there are perhaps more important considerations than just \"can it handle it\" reply diordiderot 16 hours agorootparentLike what? (Genuinely curious) reply pier25 19 hours agorootparentprevProbably more like 99% reply nvm0n2 18 hours agorootparentprevUh let&#x27;s not get carried away. It&#x27;s fine with enough work maybe. But Postgres has a lot of awkwardness too. HA is a pain, major version upgrades are a pain, JS or JVM stored procs are a pain, configuring auth is a pain. There is a reason so many people are desperate to pay someone else to run Postgres for them instead of just renting a few VMs and doing it themselves. reply hot_gril 16 hours agorootparentprevIt&#x27;s the best, but it&#x27;s far from perfect. Default mode is non-ACID, and going `serializable` mode makes it very slow. Spanner is always ACID... but always slow. reply paxys 20 hours agoparentprevPostgres is a piece of software. Cloud Spanner&#x2F;Dynamo etc are managed services. It makes no sense to directly compare one with the other. reply hatsix 20 hours agorootparentSure, You can compare Cloud SQL vs Cloud Spanner and RDS vs Dynamo, but it makes more sense to just say \"Postgres\" and assume that the reader can figure out that it means \"Whatever managed postgres service you want to use\".The entire point is that every cloud provider has a managed postgres offering, and there&#x27;s no vendor lock-in. Though, technically, Dynamo does have a docker image you could run in other cloud providers if it came down to that, you&#x27;d get no support for it. reply res0nat0r 19 hours agorootparentI don&#x27;t think it&#x27;s really relevant to compare plain Postgres to Spanner, most folks have no need for something like this. It is made for folks who need to do millions of ACID type transactions a second&#x2F;minute from all over the globe, and have a globally consistent database at all times.There&#x27;s a reason why Google installed and built their own atomic clocks and put them in their datacenters, it is to facilitate global timekeeping for this type of services. Most likely 99.9% of the time this type of database is overkill, and also likely way more expensive than you need.https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;true-time-external-con... reply riku_iki 18 hours agorootparent> It is made for folks who need to do millions of ACID type transactions a second&#x2F;minute from all over the globe, and have a globally consistent database at all times.I think just doing some (not necessary millions) ACID transactions over the globe and have consistent DB is strong value proposition even for small users. reply lijok 15 hours agorootparentprevThe dynamodb docker image you’re referring to will get you shot if you try and use it in prod. It’s an API wrapper on top of sqlite and has a ton of missing functionalityThere are a couple of databases out there with ddb compatible interfaces, like scylladb reply nameless912 20 hours agorootparentprev> AWS and GCP (and Azure, and Oracle cloud, and bare Kubernetes via an operator, and...) support Postgres really well.I think they&#x27;re directly comparable with this context. reply esafak 20 hours agorootparentprevRead \"Cloud SQL for PostgreSQL\" reply brianolson 20 hours agoprev\"as little as $65 USD&#x2F;month\" for GCP Spannervs AWS Free Tier:\"25 GB of data storage ... 2.5 million stream read requests ...\"https:&#x2F;&#x2F;aws.amazon.com&#x2F;dynamodb&#x2F;pricing&#x2F;So, there&#x27;s probably somewhere the lines on the graph cross, but Google&#x27;s headline seems misleading. reply hdjjhhvvhga 20 hours agoparentThe Free Tier is completely irrelevant here, though. The very reason someone might use Spanner is its excellent scalability. I don&#x27;t believe there is any reason to use it for smaller projects other than education. The customers who will use Spanners are those for whom CockroachDB is not enough, for example. For everybody with databases that are not that huge PostgreSQL will do just fine. reply chx 19 hours agorootparent> For everybody with databases that are not that huge PostgreSQL will do just fine.Ha. Remember Gary Bernhardt of WAT fame? https:&#x2F;&#x2F;twitter.com&#x2F;garybernhardt&#x2F;status&#x2F;600783770925420546> Consulting service: you bring your big data problems to me, I say \"your data set fits in RAM\", you pay me $10,000 for saving you $500,000. reply jiggawatts 18 hours agorootparentAWS will happily rent you a server with 24 TB of memory for about $200&#x2F;hour.Columnar databases typically get a 10:1 compression ratio over raw data = 240 TB effectively.That’s a lot of data. reply RhodesianHunter 18 hours agorootparentWhich columnar databases are doing the above in-memory? reply jiggawatts 17 hours agorootparentSQL Server supports in-memory columnstore tables. I’m not an expert but I suspect SAP HANA also.If you squint, any database engine is “in memory” if there is more buffer than data.Or just use a RAM disk! reply folmar 16 hours agorootparent> If you squint, any database engine is “in memory” if there is more buffer than data.That is sadly not true, I remember one lonely night debugging a MSSQL 2012 instance that was _very_ slow, and it turned out that for a simple query (one join, 100 rows in one table and 10 in the other, 100 result in total, one where clause) it forced writing the result to disk before evaluating the WHERE condition. Unable to fight the scheduler I&#x27;ve ended up making a ramdisk for this data. reply jiggawatts 16 hours agorootparentYes, tempdb spills can be annoying, but I believe they never occur for queries that use only in-memory tables. reply mianos 17 hours agorootparentprevKdb with ease, but down 500k on licenses and the cost of people who can use it. :) reply Vt71fcAqt7 20 hours agorootparentprevVery true, but most people do not yet no about scale-to-zero pay-for-what-you-use sql server clouds with a free tier like CockroachDB and neon. They think that you must pay $5 a month to run a sql server, which has been the case until very recently, so they go with no sql options to get the free tier.Edit: actualy Spanner looks like another CockroachDB. You use sql to interact with it. In which case I can see many people who would want to use this with a free tier for hobby projects. ie. in between education and production development. reply dmoy 19 hours agorootparent> Edit: actualy Spanner looks like another CockroachDB. You use sql to interact with it. In which case I can see many people who would want to use this with a free tier for hobby projects. ie. in between education and production development.Pedantically, cockroachDB is another spanner. It was made by Google devs who left Google having previously used spanner, and intentionally made something similar to spanner (ish, lots of handwaving happening here) reply catch22l 9 hours agorootparenthaha !!!. cockroachDB literally says, their motivation is spanner .. lol reply bananapub 19 hours agorootparentprev> Edit: actualy Spanner looks like another CockroachDBlolcockroachdb is an external reimplementation of some of the ideas of spanner but without depending on excellent clocks. reply foobazgt 19 hours agorootparentprevFYI, Spanner came long before CockroachDB. Indeed, the founders of CockroachDB are Xooglers and Spanner was inspiration for the latter. reply RcouF1uZ4gsC 19 hours agorootparentprev> actualy Spanner looks like another CockroachDB.Yeah it does :). CockroachDB set out to be an open source version of Spanner by ex-Google engineers. reply catch22l 9 hours agoparentprevoh cmon. this is just 50 QPS. i mean yea obviously for someone having as little as 50QPS is not going to bother with the massive scale and availability in cloud spanner. there are a TON of applications today reaching 100M+ users in just a month. you are not dealing with 50QPS. oh and you forgot the crazy byte boundaries in DynamoDB. if you go over a single byte above 1kb, you are charged 2 Read units ! reply ajross 20 hours agoparentprevThat seems nitpicky. The free tier is a marketing program, not a product.\"Google should offer intro discounts\" is IMHO a very valid point (absolutely no idea why this doesn&#x27;t exist), but it doesn&#x27;t really speak to whether or not the real product is more or less expensive. reply avereveard 20 hours agorootparentit&#x27;s a bit different because the free tier for dynamodb is not like the other 12 month limited offer, it&#x27;s marketed as free forever, so it&#x27;s not just an intro product, it&#x27;s something you can run a small business off for free. reply catch22l 9 hours agorootparentfor 50QPS and if you dont cross 1kb read or write. try to do a 2kb payload and see the QPS drop to 20 reply naet 18 hours agoprevI&#x27;m torn because I have really liked Google offerings in the past (I&#x27;m pretty locked in on gmail, I have different things running on GCP already, etc). But I&#x27;ve also been feeling burned a bit by Google suddenly ending services. I had all my domains happily in Google domains until they recently sold it suddenly to Squarespace, who I&#x27;m not interested in dealing with. My phone is a Google Pixel and I was using the Google podcast app, but just heard that too is being discontinued and moved to Youtube Music, which is a service I tried and really disliked, so now I need to find a replacement for that too. I didn&#x27;t personally use some other services, but I know there have been many others ended (such as Stadia for gaming, which made a lot of press at the time).Those are more minor services in the long run, but it makes me a little nervous to go in again on Google for a critical service. Before I invest my time and effort into using it I have to ask myself \"Will Google someday sell off or end the cloud spanner service? Will I be in trouble if they do so?\". reply btown 18 hours agoparentAs someone in the midst of transitioning an organization to GKE, Google Domains was the first shutdown that truly frightened me - AFAIK the first true B2B IT offering that was unceremoniously shuttered. Domain registration may be a regulatory&#x2F;reputational minefield - but then so are many of their other cloud offerings, up to and including content distribution. I don&#x27;t think it&#x27;s indicative of a larger pattern of shutting down Google Cloud services yet, but it&#x27;s certainly a yellow flag at least. reply lijok 15 hours agorootparentOh you are in for a surprisehttps:&#x2F;&#x2F;steve-yegge.medium.com&#x2F;dear-google-cloud-your-deprec... reply victor106 18 hours agoparentprev> But I&#x27;ve also been feeling burned a bit by Google suddenly ending services.The products&#x2F;services that “Google” the search company launches are different than “Google Cloud”. While the discontinuation of Google products is annoying it has nothing to do with Google Cloud products&#x2F;services. I don’t think Google Cloud abruptly announces discontinuing products&#x2F;services as they have paid customers.Regarding Google Domains that is a Google product. The equivalent product from Google is “Google Cloud Domains” which is available to Google Cloud customers. reply 5kg 17 hours agorootparent> Regarding Google Domains that is a Google product. The equivalent product from Google is “Google Cloud Domains” which is available to Google Cloud customers.Also sold: https:&#x2F;&#x2F;cloud.google.com&#x2F;domains&#x2F;docs&#x2F;faq reply dminor 17 hours agorootparentprevThe domains from Google Cloud Domains are also going to squarespace reply tyree731 17 hours agorootparentprevJamboard had paying customers, and they discontinued that on short notice, so paying only gets you so far. reply surgical_fire 17 hours agorootparentprevStadia also had paid customers reply benmanns 20 hours agoprevI wish I could play around with Spanner for personal&#x2F;side projects, but a production ready instance starts at $65&#x2F;mo. DynamoDB can run for ~$0.00&#x2F;month with per-request pricing. reply michellegienow 35 minutes agoparentif you are interested in spanner, you might take a look at cockroachdb. esp the production ready serverless offering which is pay for consumption only. crdb architecture is essentially spanner under the bonnet, GIFFEhttps:&#x2F;&#x2F;www.cockroachlabs.com&#x2F;get-started-cockroachdb&#x2F; reply GabeWeiss_ 17 hours agoparentprevYou can! Spanner has a free trial: https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;free-trial-instance. Keep in mind, that per-request pricing isn&#x27;t free unless you stay under the free tier. So just take a look at what those limits are because going above them means you&#x27;re not free anymore. reply meowtimemania 19 hours agoparentprevThis is the main reason I like DynamoDB. I can run side projects indefinitely for basically $0&#x2F;month. reply iends 18 hours agorootparentSame as with lambda. I have a side project that costs $0.42&#x2F;mo to run. reply dchest 19 hours agoprev\"Organizations of all sizes and across all industries are increasingly looking to accelerate digital transformation and power AI-driven innovation.\"How did Google become like this? reply holografix 18 hours agoparentBy hiring VMWare, Dell and Oracle people reply who-le-o 18 hours agoparentprevChances are you&#x27;re not the audience and some exec is reply hot_gril 16 hours agoparentprevCloud services rely a ton on marketing, B2B relations, and customer support. Google has never exactly been about that stuff, and GCP was suffering. So they pulled in Oracle, MSFT, etc execs, which lame as that sounds was probably the right move for GCP in particular.And I guess this is the kind of marketing that attracts the customers they want. reply kccqzy 18 hours agoparentprevThe new leadership under Cloud that chases buzzwords. reply Havoc 17 hours agoparentprevAll corporate-y? By becoming a big corporation reply oars 17 hours agoparentprevGoogle Cloud&#x27;s current CEO spent 22 years at Oracle before taking this role. reply layer8 19 hours agoparentprevMoney. reply jdmg94 17 hours agoparentprevThey removed that line about not being evil reply michellegienow 34 minutes agorootparent^^^ this reply spullara 20 hours agoprevWithout an on-demand version of spanner that doesn&#x27;t charge per node but per operation makes it not comparable to dynamodb for many use cases. reply joshuanapoli 20 hours agoparentExactly: I have to provision for peak throughput on Spanner. Average throughput is much lower than the peak throughput, so I&#x27;m doubtful of seeing savings no Spanner.(But I bet that Spanner is much easier than DynamoDB to develop with...) reply rkeene2 20 hours agorootparentYou can scale Spanner up&#x2F;down based on demand although there is a lag time with it.I built a system that relies on a high-performance database and tested with both AWS DynamoDB and Google Cloud Spanner (see disclaimer) and was able to scale Google Cloud Spanner much higher than AWS DynamoDB.DynamoDB is limited to 1000 WRUs per node, and there isn&#x27;t an obvious way to get more than 100 nodes per table, so you&#x27;re limited to 100,000 WRUs per table (= 102400000 bytes&#x2F;sec = 97 MiB&#x2F;sec = 776 Mib&#x2F;sec) -- even if you reserve more than 100,000 WRUs in capacity for the table. The obvious workaround would be to shard the data across multiple tables, but that would have made the software more difficult to use.Google Cloud Spanner was able to do much more than 97 MiB&#x2F;sec in traffic (though the exact amount isn&#x27;t yet public), and also was capable of much larger transactions (100 MiB versus DynamoDB&#x27;s 25 (now it is 100) items * 400KiB of ~10 MiB) which was a bonus.Disclaimer: The work was funded by a former Google CEO and I worked with the Google Spanner team on setting it up, while I am a former AWS employee I didn&#x27;t work with AWS on the DynamoDB part of it, though I did normal quota adjustments. reply arpinum 17 hours agorootparent> and there isn&#x27;t an obvious way to get more than 100 nodes per tableBy node you mean partition, and a partition is limited to 10GB. Store more than 1TB and you will have at least 100 partitions reply ripper1138 19 hours agorootparentprevDoesn’t seem like a fair comparison. reply FredPret 20 hours agoprevBut a droplet with a Postgres db is nearly free, and seriously performant.And for 65&#x2F;month, you can get a VERY beefy Hetzner server.You’ll have to wade through the crazy thicket that is the menu of cloud offerings.I gave that one look, and decided I might as well give up and learn the basics of Linux admin once and apply it for life. reply klodolph 20 hours agoparentYeah. I think the whole point of Spanner is to handle larger, larger, larger workloads and databases, and if you can fit everything on a single server, you definitely should.Comparing Postgres to Spanner is kind of like comparing a delivery van to a train. The train is always going to have higher overhead costs.Linux admin is a useful skill, but I know my Linux admin skills can’t compete with the reliability, availability, and scalability of cloud systems… like Dynamo, S3, Spanner, etc. reply rurp 18 hours agoparentprev> decided I might as well give up and learn the basics of Linux admin once and apply it for life.Yeah I think this raises an underappreciated drawback of working on heavily AWS&#x2F;GCP native projects. So much of the time ends up being spent on service level config and troubleshooting that has little relevance elsewhere. reply 0xbadcafebee 19 hours agoparentprevOr you could use DynamoDB for basically free. One month of 1GB of storage, 1kb item size, 100,000 writes, and 100,000 reads, would be $0.39 on DynamoDB on-demand. A million writes and reads respectively would be $1.63. Strongly consistent reads&#x27;d make that $1.75, and transactional writes would make it $3.00 reply FredPret 18 hours agorootparentI get it but I feel like it isn&#x27;t really mine, and learning this new db&#x2F;console&#x2F;product&#x2F;vendor that won&#x27;t be around in 10-20-30 years is a waste of very limited time.Linux admin + hosting a server = my data, on my terms, until I keel over, and possibly long after that. reply 0xbadcafebee 14 hours agorootparentBy the time DynamoDB goes away, that Linux server you have will have been EOL for two decades and chock full of security holes, not to mention disks filling up or getting wiped. The amount of time you&#x27;ll spend tinkering with your server will dwarf the tiny amount of time it&#x27;d take to replace DynamoDB with an alternative service. reply FredPret 9 hours agorootparentOn the contrary:- in the next few decades, my Linux servers will have been updated completely multiple times- software updates happen on my schedule and at my behest- I can move to newer hardware whenever the mood strikes me- I maintain full de jure and de facto ownership of my data (AKA I control it completely)- Since I own the data, I can always upload it to some vendor in future. Due to vendor lock-in, non-standard data formats, and my least favourite: data egress fees, it&#x27;s not straightforward to go from a vendor to another vendor, or from a vendor to DIY. I maintain maximum optionality- Since I committed to the private server path, I can take full advantage of the server being a general computing device. I can combine web-hosting, databases, and other things on the same device &#x2F; a stable of devices. I end up having ridiculous performance, full control of my entire stack, and at a huge discount, and it&#x27;s a very simple system.Security concerns are addressed in a couple of ways:- By having everything on one server, or by architecting things just so, I can stand up a database that does everything I need, including serving my web-apps, without ever facing the public internet directly.- Maintaining a secure server is admittedly more of an ongoing chore, but it&#x27;s not a significant timesink at all- Every online service by AWS et al ultimately runs on a server much like mine, so if there&#x27;s some serious widespread Linux vulnerability, it&#x27;ll affect managed services just as much as my server.- The managed services themselves are not only juicy targets but are themselves vulnerable to both hacking and phishing. I&#x27;m convinced SSH&#x27;ing into Postgres + Linux is a safer option than a more complicated structure.All of the above assumes my apps will never be planet-scale, which even in the most bullish case, they never need to be. reply HDThoreaun 15 hours agorootparentprevWhy use dynamo for so few reads? reply mmanfrin 20 hours agoprevGoogle also has a history of massively spiking the cost of its services. Vendor lockin is a dangerous thing. reply xnx 20 hours agoparentThis definitely happened with Google Maps, where Google was clearly the dominant player. Has it happened to other services? It seems far less likely to happen for business cloud services where they are a distance 2nd (3rd?) to AWS. I know of some examples (admittedly ancient) where they have reduced costs: https:&#x2F;&#x2F;cloudplatform.googleblog.com&#x2F;2015&#x2F;05&#x2F;Pay-Less-Comput... reply callalex 20 hours agorootparentBefore they offered Google cloud, they offered Google App Engine. After they introduced Google Cloud they got bored of App Engine and 10x’d the price. This was particularly painful because App Engine was a batteries-included solution with heavy vendor lock-in. reply derefr 20 hours agorootparent> After they introduced Google Cloud they got bored of App Engine and 10x’d the price.I don&#x27;t know about \"got bored of\"; I&#x27;d say more \"effectively deprecated, using increasing costs† as an implicit push toward rewriting your service for more modern parts of their platform.\"Specifically, Google want you to rewrite your GAE apps for Cloud Run (https:&#x2F;&#x2F;cloud.google.com&#x2F;appengine&#x2F;migration-center&#x2F;run&#x2F;comp...):> Cloud Run is the latest evolution of Google Cloud Serverless, building on the experience of running App Engine for more than a decade. Cloud Run runs on much of the same infrastructure as App Engine standard environment, so there are many similarities between these two platforms.> Cloud Run is designed to improve upon the App Engine experience, incorporating many of the best features of both App Engine standard environment and App Engine flexible environment. Cloud Run services can handle the same workloads as App Engine services, but Cloud Run offers customers much more flexibility in implementing these services. This flexibility, along with improved integrations with both Google Cloud and third-party services, also enables Cloud Run to handle workloads that cannot run on App Engine.Anyone who&#x27;s still on GAE (rather than having moved over to Cloud Run) at this point is a \"legacy enterprise customer\"; and so Google have at this point moved GAE pricing beyond just a monetary disincentive to use, to being \"fired-customer pricing\" — i.e. the price you charge when you don&#x27;t really want to work with a customer any more, a price that says \"go away\", but if they still want to pay you even at that price-point, then sure, why not? reply xnx 20 hours agorootparentprevGood history lesson. I didn&#x27;t realize that Google Cloud wasn&#x27;t a rename&#x2F;expansion of Google App Engine. reply dragonwriter 17 hours agorootparentBut, Google Cloud was a rename&#x2F;expansion (specifically, expansion) of Google App Engine (GAE a pre-existing Google products that was then part of Google Cloud when the latter brand was launched.) reply acdha 18 hours agorootparentprevThe last year has had multiple GCP cost increases:https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;pricing-announcehttps:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;infrastructure&#x2F;update...https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;data-analytics&#x2F;introd...https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;pricing-announcehttps:&#x2F;&#x2F;cloud.google.com&#x2F;vpc&#x2F;pricing-announce reply logicchains 16 hours agorootparentprev>Has it happened to other services?BigQuery initially was a lot more powerful, then they started adding a bunch of resource limits on queries that you could only overcome by paying up. Not a direct fee increase, rather you paid the same fee for a worse product. reply Tehnix 20 hours agoparentprevCurious: have they ever increased prices of existing Google Cloud services?As far as I know, AWS only ever decreases prices on services for example reply rlpb 20 hours agorootparent\"Coders howl over Google&#x27;s App Engine price hike (natch)\" https:&#x2F;&#x2F;www.theregister.com&#x2F;2011&#x2F;09&#x2F;02&#x2F;google_app_engine_use...I don&#x27;t know if Google App Engine falls under Google Cloud services, but either way that&#x27;s just a technicality; the sentiment remains the same.Edit: more information here: https:&#x2F;&#x2F;github.com&#x2F;stickfigure&#x2F;blog&#x2F;wiki&#x2F;The-Unofficial-Goog... reply packetslave 20 hours agorootparentTWELVE YEARS AGO! find a new complaint. reply rlpb 17 hours agorootparentIn my world, most production services need to last longer than twelve years, so need relative pricing stability and no complete pricing restructures over a longer period. Perhaps your world is different. reply tpmx 17 hours agorootparentI sort of agree, and I also posted other aspects, but please note this:https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-aws-public-ipv4-address...We are introducing a new charge for public IPv4 addresses. Effective February 1, 2024 there will be a charge of $0.005 per IP per hour for all public IPv4 addresses, whether attached to a service or not reply tpmx 20 hours agorootparentprevGCP has seen price increases:https:&#x2F;&#x2F;techcrunch.com&#x2F;2022&#x2F;03&#x2F;14&#x2F;inflation-is-real-google-c...Discussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30671997 reply tessela 17 hours agorootparentprevBigQuery had a 25% price increase in July&#x2F;23: https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;data-analytics&#x2F;introd... reply bbu 19 hours agorootparentprevyes, massively over the last ~12 months. https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;pricing-announce reply jefftk 20 hours agorootparentprevAWS has increased prices, most recently when they started charging for static IPs (even ones attached to a running instance). reply tpmx 20 hours agorootparentThat one caused a week of work for me... (redesigning something slated to go live in a few months) reply holografix 18 hours agoparentprevSource? reply Freedom2 20 hours agoparentprevIs there any evidence of vendor lock-in actually being a widespread issue? reply 87 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Cloud has introduced major price-performance enhancements to their Cloud Spanner database which include up to 50% higher throughput and 2.5 times more storage per node, without any extra cost.",
      "The updated Cloud Spanner, renowned for high performance, availability, and scalability, now becomes an even more cost-optimal solution for organizations handling large data volumes and application requirements.",
      "Comparatively, Spanner is now more cost-effective than Amazon DynamoDB. These updates are currently available for some instance configurations, with a complete rollout planned for all Spanner customers in the near future."
    ],
    "commentSummary": [
      "The discussion primarily centers around cloud service providers, specifically contrasting Google Cloud Spanner and Amazon DynamoDB on aspects like pricing and user experience.",
      "Other discussed themes include support and reliability issues, suitability of different databases for particular applications, the usage of serverless computing, and the application of specialized databases.",
      "There is an evident concern over vendor lock-in and pricing stability within the cloud services industry, reflecting users’ experiences and opinions."
    ],
    "points": 299,
    "commentCount": 347,
    "retryCount": 0,
    "time": 1697045140
  },
  {
    "id": 37850265,
    "title": "Grind – A first person shooter for Amiga 500",
    "originLink": "https://www.indieretronews.com/2023/10/grind-first-person-shooter-for-amiga.html",
    "originBody": "Grind - A first person shooter for Amiga 500, made with the amazing Dread-Engine (+DEMO) 'Dread' has been featured many times on Indie Retro News, as with every new update the Amiga 500 version looked better than ever with fabulous new textures and new zones to visit. Well if you're looking for more gaming news on this upcoming first person shooter, we have not only been informed that a new demo has been made available, but the latest footage and detailed press release shows that John is true to his word in bringing a Doom-like experience to the Amiga as the holy-grail of Amiga gaming! So without further-ado, here's the latest blurb about this incredible looking game. '\"Darkenward east' is planned to be one of the early levels in the game, taking place in a city area. The map is in it's very early stages and will be overhauled once more levels are introduced and the enemy roster gets more complete (currently there's a lack of low tier enemies and other important classes). This release in general marks the complete transition of the project in regards to its visuals and now fully embraces the Steampunk/Lovecraftian aesthetic with the addition of the new HUD and protagonist, as well as brand new, high quality Weapon designs!\" Here's a list of features still missing (and planned to be added soon) as well as other details that are to be worked next, in order to reach the 'vertical slice' short-term goal: Music support for the Amiga version SFX overhaul (includes adding ambient stuff and enemy growls) Further polish on weapon models Complete the weapon models replacement (Chaingun and Missile-launcher are still wip - the demo only features the pistol and shotgun for now) Add secondary weapon attacks (using RMB) Existing enemies polishing (various high-tech details still need altering or removing from some models) Create and add new enemy types Complete and add 2 more levels (the previous and the next one). This step will also put to the test the newly added level progression system and pave the way for more levels to come. System Requirements: Amiga - ADF version: Minimum: a500 with 512 CHIP and 512 OTHER ram Recommended: a1200 + fast ram Other news: ---------- \"Lately the Grind team has grown as various, well-known coders have joined to help with the game's production: Namely BSzili (known for his Amiga ports of Dark Forces, Exhumed, Blood, Shadow Warrior, Blake Stone and others) who's handling the Amiga version and coder Kabuto from the demogroup Titan, looking at a possible Mega Drive version as well! Worth noting is that this latest Patreon-only binary release also included an Atari ST version (though it's not ready for a public showcase yet as it misses key features).\" Links: ----- -Grind's Patreon: https://www.patreon.com/Grind_Amiga (Demo) -Grind's Pixelglass page: https://pixelglass.org/#grind -Grind's Discord server: https://discord.gg/QXGQbkRCxN 4 20 1 1 1 1 at Wednesday, October 11, 2023 Labels: Amiga, Commodore Amiga, DOOM, Dread, GAMES, Grind, KK/Altair, Retro Gaming, Retrogaming 25 comments: Anonymous11 October 2023 at 09:51 Box plz, where i can order Reply Replies Anonymous11 October 2023 at 10:19 Plz release digital download !!!!!!! Reply Anonymous11 October 2023 at 10:02 This is amazing. Still can´t believe that this runs on a Amiga 500. Wow! Excellent programming skills man! Reply Replies Anonymous11 October 2023 at 12:50 I think in the video it's running on an A1200. On an A500 it runs about 10 to 12 fps which to be fair is still ace considering this sort of thing was deemed impossible on such a machine back then. Bartek11 October 2023 at 23:43 All kudos to Krzysztof Kluczek (KK/Altair) for working hard on the engine <3 Reply Anonymous11 October 2023 at 10:19 Looks great. Will probably buy the game when (if) it comes out, but would like to try a demo, but have no plans to fund a Patreon to get early build(s), I can understand why some might but I won't. I think the dev should release a curated public demo, it's a marketing tool after all. Bit disappointed can't give it a try. Reply Trapshot11 October 2023 at 10:21 So glad to see this is still being developed, what a treat! Many thanks to all involved for giving us nice things to look forward to :-) Reply Anonymous11 October 2023 at 12:09 10 € PER MONTH to get excess to the Development Builds ??? And 24.50 € as said PER MONTH for full excess ??? As much as i am impresse with this Game, but the Pricetag für the early stuff is so damm high that im frightened about the final release version pricetag. Reply Replies Anonymous11 October 2023 at 15:02 Well end price might be much higher. As it's retro stuff and you probably are old and grey, you might have a fortune to spend ;) Anonymous12 October 2023 at 05:48 I think that the PER MONTH is misleading. Can't you pay for one month, obtain what you want and then cancel your subscription ? Of course, it's still high because the executable comes with the 10$ subscription but really, I prefer them to do this than be stupidly generous. Hirako200012 October 2023 at 14:47 It's not like they would ever sell a million copies like even indie games may in target as far stretched. Economy of (down) scale. Reply Resistance11 October 2023 at 12:41 I'm dreaming they will also release a pimped-out version for Amiga CDTV, with an additional intro and outro, additional animations or graphics in EAB or HAM between stages and cool music in Audio CD format :) Reply Replies Anonymous11 October 2023 at 18:15 Second this Reply Anonymous11 October 2023 at 12:55 At last we don't need a bunch of expansions to play such a game on the Amiga. Reply Anonymous11 October 2023 at 14:50 Amazing and yet at the same time somewhat bitter sweet to think that this could have been possible when the Amiga was in its heyday, a game like this could have changed the course of the Amiga's fortunes if released in '93. Even though it looks like more of a Wolfenstein clone than Doom, the rate at which it is running at the screen size it is at is something to behold. Best wishes to the devs, and one can only hope for the potential of this engine to improve in regards to becoming a full blown 'doom' style engine. Reply Replies Anonymous11 October 2023 at 16:54 Actually this is a Doom-like engine. Only the floor and the ceiling textures are missing, but everything else is there. Someone even made some Doom maps with the leveleditor for this engine. Reply Anonymous11 October 2023 at 16:21 Class! Love it 🥰 Reply Anonymous11 October 2023 at 19:34 Looks absolutely fantastic. I hope it works on emulator too. Will buy it for sure. Reply bobeff12 October 2023 at 02:12 Will the game be open source? Reply Anonymous12 October 2023 at 03:18 Love it Reply Anonymous12 October 2023 at 05:24 \"Add secondary weapon attacks (using RMB)\" Oh my god, this is fantastic. Reply Anonymous12 October 2023 at 07:54 This looks so good! My only nag is that looking at the textures it should have been more medieval weapons instead of shotguns and machine guns. Kinda like Hexen or Heretic. Reply Anonymous12 October 2023 at 07:55 Loved the new style. It reminded me heavily of the chaos engine. I wonder who owns the chaos engine brand these days? Reply Max Tex12 October 2023 at 08:14 Fantastic game at first glance with excellent graphics that only runs on Amiga 500 with 1 Mb... is it true? Has anyone tried this on real hardware? Anyway, congratulations. Reply Anonymous12 October 2023 at 09:51 Would prefer a game with no fantasy setting and realistic, actual weapons. Anyway it looks so awesome. But will that game ever come out? I dont know. Reply All comments are moderated! Constructive criticism allowed, but abusive comments will be removed and you will be IP banned! Banned users will not show up in my comment feed, you will be gone for good as will all of your posts! - Play nice and enjoy IndieRetroNews! Older Post Home Subscribe to: Post Comments (Atom) Support us on News Search Systems Amiga Amstrad Atari Atari 7800 Atari ST/STe Atari XE/XL BBC Micro C64 Colecovision Gameboy Intellivision Mega65 MS-DOS MSX NES Oric PC Pico-8 Plus/4 Sega Master System Sega Mega Drive SNES ZX Spectrum ZX Spectrum Next Genre Adventure Arcade BEAT EM UP Dungeon Crawler Platformer Puzzle RACING RPG Shoot em up SHOOTER Latest Comments It&#39;s not like they would ever sell a million c... \"Add secondary weapon attacks (using RMB)&quo... Love it Will the game be open source? I think that the PER MONTH is misleading. Can&#39... Popular Posts Grind - A first person shooter for Amiga 500, made with the amazing Dread-Engine (+DEMO) 'Dread' has been featured many times on Indie Retro News, as with every new update the Amiga 500 version looked better than ever wit... RESHOOT PROXIMA III - A wicked wave blasting Commodore Amiga Shoot 'em up has appeared Throughout the last few years we've tried to keep you up to date as much as possible, in regards to Richard Löwenstein and team's sc... Saboteur! - A brilliant ZX Spectrum game is coming to the ZX Spectrum NEXT The original Saboteur is a bit legendary. Not only was it one of the best, and most expansive, games on the Speccy, C64 and CPC, but it also... The Goblin - A fabulous ZX Spectrum platformer with an upbeat soundtrack arrives on the MSX! Great news MSX owners, as if you're looking to play a very enjoyable game on your home computer, then we have recently been contacted by... AQUABYSS (Amiga) - New footage shows Pirate Hunt Contract & Tactical Combat System update! In 2018 we were the first site to officially announce a new Amiga game called ' AQUABYSS ' by AgedCode: a game in which you travel ... Pages Browser Based Dizzy Games Open Source Remakes Remastered Retro Inspired Reviews Recommended AmigaBill AmigaPortal.de 2D Platformers Commodore 64/128 Commodore Amiga Dungeon Crawlers Game Dev RetroGaming MS-DOS Gaming! Retro For Sale SabermanYT Shoot Em Ups Torque Live! Featured post PETSCII Side-Scrolling Platformer - A new game for the Commodore PET inspired by Mario and Sonic! Jimbo is certainly no stranger to IndieRetroNews, as he is one of the only developers who has created new games for the Commodore PET. Games... Top Viewed News Grind - A first person shooter for Amiga 500, made with the amazing Dread-Engine (+DEMO) HOT NEWS as eagerly awaited SNK vs CAPCOM for the C64/128 gets an official release!! Krogharr - Inviyya creator's latest Commodore Amiga game looks great in this new footage RESHOOT PROXIMA III - A wicked wave blasting Commodore Amiga Shoot 'em up has appeared Giana Power Edition 2023 - The Great Giana Sisters for the C64 gets 16 new levels! Tony - A challenging yet enjoyable Amiga Platformer by Monochrome Productions arrives on the C64 as a demo DaemonClaw coming to MegaDrive, Neo Geo, and modern systems! First ever footage of DaemonClaw running on a real Megadrive! Other Games Commodore 64 -=Meteor Shower=- MSX -=Woods Rat=- ZX Spectrum -=The Hairy Fly=- Total Pageviews 31,304,578 All Articles and Write Ups are Copyright to https://www.indieretronews.com : Please do not steal!. Powered by Blogger.",
    "commentLink": "https://news.ycombinator.com/item?id=37850265",
    "commentBody": "Grind – A first person shooter for Amiga 500Hacker NewspastloginGrind – A first person shooter for Amiga 500 (indieretronews.com) 292 points by harel 17 hours ago| hidepastfavorite120 comments mortenjorck 17 hours agoI love the imaginative, alt-history attention to detail: rather than a derivative clone of Wolfenstein or Doom, this looks like something The Bitmap Brothers might have produced in 1993 if they&#x27;d had access to another 30 years of community knowledge optimizing for the Amiga&#x27;s great-for-2D but not-great-for-3D architecture. reply KingOfCoders 8 hours agoparentPlaying Wolfenstein3D on a friends PC was one of the reasons I thought \"It&#x27;s over for the Amiga\" [0]. When talking to Commodore management at conferences back then, they didn&#x27;t want to see 3D coming [1] (For reference I had a A4000&#x2F;40 Retina(Z3) around that time).So it is nice to see this :-)[0] Both demo scene coders [1] Funnily I was a Sega Saturn zealot around the time too, which was also 100% 2D focused and Sega didn&#x27;t see 3D coming (Though I loved Panzer Dragoon, a 3D game squeezed out of 2D hardware, and Daytona was great too). And yes there was Starglider2 for the Amiga (Loved the space whales, was recently reminded of them when watching Ahsoka). reply wiz21c 6 hours agorootparentSega didn&#x27;t see 3D coming ? What about Virtua Racing (1992!) ? reply KingOfCoders 6 hours agorootparentYes you&#x27;re right, my wording wasn&#x27;t exact. I&#x27;ve meant 3D taking over the home market (and arcade market) and killing 2D plattform games and RPGs. Sega was very successful running \"3D\" games on 2D hardware (that could scale sprites, like Outrun or Space Harrier). So they were aware of 3D from early on. But they&#x27;ve released the Saturn with a main 2D focus, squeezed out some 3D games (Panzer Dragoon, Nights into Dreams, Tomb Raider, Burning Rangers and some arcade conversions) - the takeover was going on, people realized, with Mario 64 and Wipeout for example - and then added 3D hardware to the Dreamcast. But if they had anticipated the taking over of 3D, the Saturn would have been the Dreamcast (or not, I think my first PC 3D card was a Voodoo and that was after the Saturn).The first 3D I remember having played was Major Havoc or I robot - so yes there were \"real\" 3D games in the market, but 3D completly took over the home market, except handheld like the Gameboy&#x2F;Advanced&#x2F;DS&#x2F;... (I think the 2D revival came with the indy developer movement, but I&#x27;m not sure).Also see e.G. the transition from Bards Tale 3D (small window) to Dungeon Master 3D (main window, 3D interaction) and then Ultima Underworld 3D (all in, tilt, up&#x2F;down) as an example of 3Dification of games and genres. reply phire 2 hours agorootparentYou are forgetting the Sega Model 1 and Sega Model 2 arcade platforms. So many great 3D games (Virtua Fighter, Virtua Racing, Daytona USA)Sega&#x27;s problem wasn&#x27;t that it didn&#x27;t see 3D coming. They did, despite the common claims on the internet, the Saturn was designed to be a 3D capable console, with dedicated 3D hardware.Sega&#x27;s problem is that they bet on the wrong 3D technology. Like Sega&#x27;s arcade systems. the Saturn was designed for quads, and could only do forwards texture mapping (which doesn&#x27;t allow for UV coordinates).While the playstation went for triangles and inverse texture mapping. It turns out that was the correct direction, and the whole industry settled on that as a standard. All game engines and tooling would assume triangles.To make things worse, the Sega&#x27;s hardware 3D implementation wasn&#x27;t that good even at the techniques it was trying to implement. reply KingOfCoders 1 hour agorootparent\"[...] and Daytona was great too\"\"You are forgetting [...] Daytona USA\" reply hirako2000 3 hours agorootparentprevStill quite inexact.Sega released Saturn as a full fledged, 3D focused hardware. A year before the PlayStation 1 was out.Some chronological refresher:Sega had already been successful in making arcade 3D games and were the first to effectively transition true 3D to the home markets with multiple early flagship releases such as Virtual Fighter, beautifully ported to the home console.The reason not many decent 3D games were shipped on Saturn was not down to the hardware capabilities or goal from sega to embrace expected 3D market demands. It was rather due to the horrific developer experience. It was so terribly difficult to program it, only those at sega were comfortable with it, if that.Saturn&#x27;s hardware architecture complexity, having multiple CPUs, and other design aspects prove bad choice as it jeopardised 3rd party game developers productivity. Words were that most games shipped leveraging a single CPU given how obscure dual cpu programming was.Ironically Sega designed a more powerful machine than the PS1 and got it out a whole year earlier, yet games on PS1 were significantly superior. All down to ease of development.Wipeout was an early game on PS1 and indeed among many other popular games sealed the fact home gaming would be 3D. But sega had already produced a full fledged 3D capable Saturn, they didn&#x27;t wait to see wipeout in 1995&#x2F;1996, or Mario 64 another 2 years later. Saturn was capable of running wipeout 2097, metal gear solid, grand tourismo, and other late PS1 games that pushed the ps1 to its limits. But it missed the momentum and studios were not anymore invested in the saturn. Its marketshare kept shrinking.what the Dreamcast got added was primarily developer friendly features, the rest was simply leaps forward in compute power, especially on the GPU. Bump mapping if I&#x27;m not mistaken was supported by the Dreamcast first among home consoles. It was not \"added\" 3D, for sega that was its 2nd generation of 3D focused hardware, also their 2nd attempt, both ultimately failed for different reasons. reply KingOfCoders 45 minutes agorootparentThe Saturn had two graphics chips VDP1&#x2F;VDP2, where on one you could draw (distorted) sprites and on the other large planes e.g. for backgrounds [0].If you&#x27;d implemented a z-Buffer in software you could sort these sprites to draw them in the right sequence to use the distorted sprites as 4-corner polygons to render 3d models.The Dreamcast added a 3D GPU with the PowerVR2.[0] https:&#x2F;&#x2F;www.copetti.org&#x2F;writings&#x2F;consoles&#x2F;sega-saturn&#x2F;#graph... reply anthk 4 hours agorootparentprevSega had Scud Race. It had 3D mainly in arcades. reply mojo74 2 hours agorootparentAh scud race. I&#x27;ll never forget finding that machine in a bowling alley arcade and noticing the coin feeder wasn&#x27;t closed. Surreptitiously opening it to find a little button that could be pressed to automatically add a credit for free each time. That was one Saturday I&#x27;ll never get back and I don&#x27;t care. reply broast 1 hour agorootparentprevAs i understand 3D was considered an afterthought for the Sega Saturn, their 1995 flagship console, only adding a separate processor for 3d late into the design. This made the 3d capabilities of the Saturn very hard to program for. reply thomastjeffery 8 hours agoparentprevLook, I don&#x27;t want to talk down on this beautiful thing...but let&#x27;s be honest: it&#x27;s barely more than a doom reskin. It&#x27;s not trying to be, either. reply whizzter 6 hours agorootparentIt&#x27;s on a Amiga 500, it has about 3 MIPS of performance or about 4x less than a 486sx25 that has about 12 (yes, 68k had a couple of extra registers).On top of that the Amiga500 graphics chip placed all graphics in bitplanes, that was a great move for just copying 2d graphics in the mid 80s with the help of simple hardware acceleration, but it really became a pain for anyone wanting to do 3d graphics.To call it a reskin is quite a disparagement of the amount of work they&#x27;ve probably had to put in to get in running decently (unless they figured out a very clever way to make the hardware do a fair chunk of the work for them, kudos either way).And as others have pointed out, it&#x27;s that they&#x27;ve chosen a more \"amiga-y\" artstyle. reply nxobject 5 hours agorootparentMy knowledge of the Amiga chipset is very cursory, but peeking at the source code, there are some blitter routines that look like they&#x27;re used for texture scaling (i.e. stretching + drawing vertical strips&#x2F;walls.) I don&#x27;t know whether that (alone) accounts for the significant speedups needed. A good comparison would be to any bottlenecks the original NeXT engine, which had the 68k, but didn&#x27;t have any of the accelerators...https:&#x2F;&#x2F;github.com&#x2F;Krzysiek-K&#x2F;Dread-source-drop&#x2F;blob&#x2F;master&#x2F;... reply badsectoracula 7 hours agorootparentprevI think the Bitmap Brothers mention is because the 2D graphics feel very Amiga-ish &#x2F; BB-ish. When i read the comment i wondered \"why the Bitmap Brothers reference?\" but once i saw the screenshot i thought \"ah, i see\". Compare the textures&#x2F;2D artwork of, say, Doom, Duke3D or Blood and then the sprites of something like Chaos Engine, Gods (even the DOS versions) or even some of their 90s PC games like Z and i think you&#x27;ll see how the visual style of Grind is closer to that of Bitmap Brothers&#x27; games than to Doom&#x2F;Duke3D&#x2F;Blood&#x2F;etc. reply vidarh 4 hours agorootparentprevConsider that Doom is sometimes blamed for single-handedly causing the downfall of the Amiga&#x27;s position in gaming because of how long it took to get even a half-decent Doom-like game for it, as a result of how badly mismatched the Amiga graphics chipset was for 3D graphics.That is why is this is impressive.The number of gamers who switched to PC&#x27;s just because of Doom was huge. After Doom everything was measured against it for a long time. Even many diehard Amiga fans suddenly decided the game was up and switched.That your reaction is that it is \"barely more than a Doom reskin\" demonstrates why it is incredible.To the extent that if a \"barely more than a Doom reskin\" had been achieved near the time Doom came out, computing history might have looked quite different (though Commodore was so badly mismanaged at this point that they&#x27;d probably still have managed to mess things up even if they&#x27;d been handed this kind of reprieve on a silver platter, but one can dream) reply Zardoz84 6 hours agorootparentprevin a Amiga 500! This is amazing! reply Razengan 4 hours agoparentprevLoved the metallic palettes of the Bitmap Brothers! Speedball, Z (one of the best RTSs), Xenon (one of the best shoot-em-ups) reply lttlrck 15 hours agoparentprevYes, exactly this. What a masterpiece. reply dansalvato 11 hours agoprevFellow Amiga game dev here. The Amiga dev scene is alive and well, and I feel like these past five years especially, we&#x27;ve seen some mindblowing stuff on the platform.If you haven&#x27;t seen any recent Amiga demoscene entries, you&#x27;re in for a treat. I&#x27;m tempted to share a whole list of demos, but here is a particularly amazing one released earlier this year that runs on a stock A500: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2jciCr8zEhw reply wernsey 4 hours agoparentAny pointers on getting started?I was fascinated by the Amiga when I was young, but they weren&#x27;t widely available in my country.Lately I&#x27;ve had an itch to do some retro programming work and was looking at the Amiga specifically. I tried Aztec C natively in UAE and VBCC as a cross-compiler, and got some command-line and hello world Intuition programs working.But going beyond that has proven somewhat difficult. Documentation seems to be scattered all over the internet. I found a bunch of books on archive.org, but they mostly seem to focus on Intuition applications or beginner programmers. reply postmodest 9 hours agoparentprevAre people doing this on vintage hardware or new hardware? (Or emulation?) reply dansalvato 8 hours agorootparentI believe a number of the devs who have been around for decades are still writing actual code with their preferred tools that run on Amiga. But I wouldn&#x27;t be surprised if even there, most of the coding is being done in emulator, because the modern workflow is so much snappier that way.However, the cross-platform build stack has gotten comprehensive, and straight modern hardware has become the method of choice for a lot of devs (including myself). There is an \"Amiga Assembly\" extension for VS Code which does a ton of heavy lifting for you, including setting up the build tools, and even grabbing a fork of the emulator that has DAP support so you can use VS Code&#x27;s built-in debugger.I personally use Neovim and a couple plugins for syntax highlighting and DAP support. As part of my build process, I run Python scripts which convert images and SFX to Amiga-friendly formats and assemble them into a custom binary file. I can&#x27;t imagine how long that would have taken me to set up in an Amiga-only environment—Python is just too convenient.I think a lot of what you see possible on Amiga today is thanks to modern tools allowing for very rapid iteration as well as some crazy preprocessing for effects that depend on lookup tables, etc. reply livrem 7 hours agorootparentFreePascal still has official support for creating Amiga binaries. I never tried it since I have no idea about how Amiga development works in general, but I tried FreePascal a bit for other systems and it seems pretty good (underrated?) (both the language and the compiler; fast, low on bloat, mostly safe memory, huge standard library). reply qingcharles 8 hours agorootparentprevIf I was doing it (as an ex demo coder) I would do as much as I could in emulator to make my life easier and then test it on the hardware and hope for the best. Demo coding is one of those annoying things where real hardware is absolutely essential because you are often doing things which aren&#x27;t properly emulated.This demo didn&#x27;t impress me that much, I was actually hoping for more. Maybe I&#x27;ve just forgotten how underpowered the Amiga OCS was for things like this? Second Reality by Future Crew on the PC is still my #1. reply sirwhinesalot 4 hours agorootparentA 33 MHz 486 CPU (the recommended spec for Second Reality to run smoothly) is MUCH more powerful than the 7 MHz 68000 of the A500... It&#x27;s not just nearly 5 times faster, the 486 is way more cycle efficient, not to mention having a nice byte-addressable bitmap screen to draw into (vs 2-6 separate bitplanes).So yeah you forgot how underpowered OCS Amigas are :) reply Narishma 3 hours agorootparentThat&#x27;s just the CPU though. The Amiga has a bunch of custom chips for doing things you would have to do on the CPU in a PC. reply sirwhinesalot 1 hour agorootparentThe Amiga hardware doesn&#x27;t really help much with 3D effects, which the demo is loaded with. Audio is a big help for a 68000 but a 486 can mix 8 PCM channels and not even notice. reply Flow 3 hours agorootparentprevFor this Amiga demo it&#x27;s mostly just the sound mixing the hardware handles. On a PC, mixing a couple of sound channels is pretty quick. reply actionfromafar 8 hours agorootparentprevThe Amiga 500 is extremely well emulated by now though. reply ilvez 3 hours agoparentprevThis is truly amazing. I&#x27;ve always adored demoscene, but not done anything other than consume, so I would appreciate more of those demos here if you can share some highlights of recent times. reply jonahx 9 hours agoparentprevSo beautiful.To be clear, this is a trailer&#x2F;demo and not an actual game you can play? reply dansalvato 7 hours agorootparentCorrect, the demo I linked is a non-interactive audiovisual demo that is designed to show off the leet coding and artistic skills of the team. ;) The OP is a fully-playable game, though.When designing a game, you probably have to code a game engine that has certain capabilities and certain restrictions that persist through the entire game. But for these demos, you can write an entire isolated program that runs one 15-second visual effect before flushing it out and loading something totally different for the next effect. The effects are also usually designed with a lot of tricks that make them inflexible (like preprocessed data tables) and usually also take up every CPU cycle available, leaving none for stuff like game logic. reply tetris11 7 hours agorootparentprevThat while 8 main demo was the whole game. I&#x27;ve not seen any other gameplay videos for it. reply popmilo2 9 hours agorootparentprevThis is a fully playable game on real hw :) reply finnjohnsen2 6 hours agoprevI bought an Amiga 500 about 10 months ago. Haven&#x27;t touched one since way back when (89-90?).If you are considering doing the same, I recommend going to YouTube and look up two keywords: PiStorm and FS-UAE. These two allow me to prepp a hard-disk image in emulation on my PC, transfer the image to a rPi inside the Amiga and mount it. My Amiga 500 now boots a workbench with all the things I was looking for.I also bought a new case and keys, because the Amiga was very yellowed. And a new power supply because the old one looks like it wanna burn my house down reply pornel 16 hours agoprevBack in the day Cytadela (Citadel) has been the first and probably the only Wolfenstein clone supporting Amiga 500:https:&#x2F;&#x2F;youtu.be&#x2F;BpiqAN8URAU?t=376 reply nathell 15 hours agoparentThere was also Ubek, but it required a 68020.https:&#x2F;&#x2F;www.ppa.pl&#x2F;gry&#x2F;ubek.html reply kristopolous 17 hours agoprevI know nothing about this. What&#x27;s up with the vertical lines for color variations here? Is there some kind of hardware trick why that technique is used?The last time I wrote a 2.5D engine was over 25 years ago so please be gentle reply actionfromafar 17 hours agoparentI suspect it&#x27;s a way to dither with few colors, and possibly a way to render textures very quickly into the Amigas peculiar pixel format. One pixel is not a triplet or bytes, or even a single byte. One byte is 8 pixels!And that&#x27;s for monochrome. (Pure black and pure white.)To have more colors, you add more of these \"bit planes\" on top of each other.So if you have say, 32 colors and want to update a single pixel, you have to write four bytes, changing only the one bit in every one of these four bytes.This is not very nice when you try to sweep textures on a 3D-ish mesh.(But very good for 2D graphics with large chunks bobbing up and down.) reply vardump 16 hours agorootparent> …32 colors and want to update a single pixel, you have to write four bytes…A small correction, you have to write 5 bytes (or 16-bit words, same performance).4 bytes changed gets you only 16 colors. reply kristopolous 16 hours agorootparentprevah that would explain why the rendering is a bunch of rectangles. Is this a classical vga mode (320x(either 200 or 240) x 256 color)? reply actionfromafar 16 hours agorootparentMy guess without looking to closely, it&#x27;s 32 colors, because that&#x27;s max what the Amiga 500 could display at a time. Definitely 320x200 something. reply z303 16 hours agorootparentI expect you are correct.The Amiga (except some early 1000s) also had a Extra Half Brite mode that has 6 bitplanes, 64 colours with the second 32 being half the brightness of the others.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Amiga_Halfbrite_modeThe extra data fetching does slow things down.https:&#x2F;&#x2F;eab.abime.net&#x2F;showthread.php?t=102990#:~:text=And%20....The panel at the bottom looks like it uses the copper to have a different palette to the rest of the screen. That is a very common effect.https:&#x2F;&#x2F;codetapper.com&#x2F;amiga&#x2F;sprite-tricks&#x2F;shadow-of-the-bea... reply ekianjo 16 hours agorootparentprevThe Amiga could display more colors than that with copper hacks though. Look at Shadow of the Beast. reply vardump 13 hours agorootparentprevOther than using copper to change palette entries at desired scanlines, Amiga 500 can display 64 colors in EHB (Extra Half Brite) mode with 6 bitplanes. Since there are only 32 palette entries, the upper 32 colors are otherwise same, but half the brightness.And of course 4096 in HAM mode, but the mode has severe limitations and is completely impractical for textured 3D-games. reply actionfromafar 6 hours agorootparentWell. Have a look at this:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wbWGAFIkA5E&list=PLRdmatuCYA...https:&#x2F;&#x2F;youtu.be&#x2F;SXmGGiZ-ttY?t=39 reply gpderetta 4 hours agorootparentWell, it is impressive for sure, but it on an emulated 060. replyJD557 6 hours agoparentprevI was ondering about it as well, and it appears to be explained in detail here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=c00B3uE5FV8I think it&#x27;s a similar technique to Sonic 3D&#x27;s Intro FMV on the Genesis&#x2F;Megadrive (https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=VTawyLNoRhU).The original image is squashed vertically, so that you only compute half the pixels and then you stretch it back up. When you do this, you can&#x27;t have the usual dither patters, so you end with something like this (unless you cheat shift every other line, like in Sonic 3D, but then you have dither patterns everywhere). reply bogantech 6 hours agorootparentA later video expands on this too: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=y9fQw1W22i8&list=PL-3inz2kpS... reply pornel 16 hours agoparentprevIt&#x27;s probably doing two things:1. simulates texture filtering and dithering hiding low resolution and low number of colors in textures, and2. renders two or four columns at once.Amiga had planar graphics, which did not support setting individual pixels. To set a pixel you&#x27;d have to set appropriate bit in up to 6 bytes (64 colors max) scattered around in memory. Writing one byte modified one bit of 8 adjacent pixels, which was terrible for textured 3D graphics. reply 7thaccount 17 hours agoprevGraphics look amazing and the game looks fun. I get the feeling the player in the first video has played the game many many times lol.Are they still making those new Amiga systems implemented on an FPGA? reply ekianjo 16 hours agoparentThe Vampire series? Yes reply dalant979 7 hours agoprevYou can find great videos documenting development of the “Dread” engine (which this game is based on) here:https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PL-3inz2kpSUPGYZwBUAbJjaj-... reply stuaxo 2 hours agoprevThe artwork really works with the engine - everything looks a bit grimy and muddy which means the vertical stripes you get as part of the implementation fit in really well. reply vardump 17 hours agoprevLooks absolutely amazing considering Amiga 500 limitations. Same renderer as in Dread, a newish Amiga game. reply ekianjo 17 hours agoparentThe video is on a A1200 reply actionfromafar 17 hours agorootparentStill amazing compared to what was out in say, 1992 on the Amiga. (3D games wise.) reply ekianjo 16 hours agorootparentYes still very impressive reply rasz 16 hours agorootparentprevwith fast ram. That pretty much means additional accelerator card because Commodore didnt bother to build fast ram memory controller into the thing. You couldnt just slap some simms or ram chips on a card, you needed additional logic. Cheapest contemporary Fast Ram cards were ~100 pounds + ~30 pounds a meg, half the cost of 270 pound Amiga A1200 in 1994. You could argue it still cheaper than PC, lets count.A1200 bare system £276 https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;cuamiga-magazine-050&#x2F;page&#x2F;n28&#x2F;mo...4-8MB fast ram £200-400 https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;cuamiga-magazine-050&#x2F;page&#x2F;n49&#x2F;mo...340MB £380 pounds https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;cuamiga-magazine-050&#x2F;page&#x2F;n28&#x2F;mo...14 multisync monitor ~£320 https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;cuamiga-magazine-050&#x2F;page&#x2F;n52&#x2F;mo...~£1200-1400. 1994 £&#x2F;$ exchange rate 1.55 = $1860-2170. To quote a classic I feel like Im taking crazy pills.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;pcmasterrace&#x2F;comments&#x2F;7235w0&#x2F;the_sp...486dx2-66mhz, 256KB cache, 8MB, 1.44MB fdd, 350MB HDD, SVGA monitor&#x2F;card, keyboard&#x2F;mouse. $1840 reply einr 59 minutes agorootparentAnd after all that, you&#x27;d still have a 68020 under the hood. You could, of course, spend an eye-watering amount of money on a 68040 accelerator... and then... you&#x27;re still not going to beat the DX2&#x2F;66. (Let&#x27;s not even talk about the performance of AGA versus a local bus SVGA card)It feels like I&#x27;ve heard so many Amiga users say that they finally broke down and jumped ship when Doom and the DX2&#x2F;66 dropped. It really was a gamechanger. Before then it was possible to argue that a &#x27;040 Amiga 4000 still held its own against a DX&#x2F;33 or maybe even a DX&#x2F;50, but not this.There were a lot of things that came together to kill the Amiga, mostly Commodore&#x27;s mismanagement, mismarketing and complacency, but as the final blow to it being a viable computer with a future in the eyes of consumers, I feel like the DX2&#x2F;66 was it. It would have killed the Mac too if Apple hadn&#x27;t woken up to smell the coffee a few years prior and had Power Macs ready to go. reply ekianjo 15 hours agorootparentprev512k Fast RAM Extension on the Amiga 500 was VERY common back in the days, as many games benefited from it. reply snvzz 15 hours agorootparent>512k Fast RAM ExtensionHas never been common on Amiga 500.Perhaps you mean 512k SLOW RAM Extension.Or CHIP RAM (after a motherboard solder-jumper adjustment) with the ECS Agnus common in late A500 models. reply tuukkah 15 hours agorootparentprevFast RAM is not in the minimum requirements, but I don&#x27;t remember how 10 FPS compares to Doom. reply vardump 14 hours agorootparent~8-10 fps is about what this game gets on an Amiga 500 without true Fast RAM.Early 1990s me would have been more than happy with that. reply ChrisClark 12 hours agorootparent> Early 1990s me would have been more than happy with that.I was happy with 5 fps or less on the gameboy with Faceball 2000. reply Zardoz84 5 hours agorootparentprevBack in the day, I was playing DooM 2 on a 386DX 40MHz and was very fine. And Rebel Assault on 14fps. Also, I managed to play DooM 3 on a GeForce 2 MX DDR (using the patch sets to allow it to run on Voodo cards). replyscrame 10 hours agoprevman, I remember the \"chunky vs planar\" usenet megathreads when DOOM came out, amazing that it&#x27;s still producing results 30 years later. I miss my old A500, but not slip&#x2F;ppp, x&#x2F;y&#x2F;zmodem downloads and the terrifying floppy checksum errors. reply blue1 8 hours agoparentIn the last years I remember also using ftp (and its now-forgotten relative fsp) reply beezlewax 4 hours agoprevThis kind of reminds me of Quake stylistically. A series that took a wrong turn after the first one.More sequels in the style of the first one would have been amazing.The visuals here though are lovely. Well done to the team reply darkwater 6 hours agoprevI wonder how many people working on the Amiga scene were not even born when Amiga was in its best days. reply finnjohnsen2 6 hours agoparentJudging from Amiga retro channels on youtube, they all look like GenX-ers to me. I suspect nostalgia drives you to this, not because these are particularly interresting machines today. (shots fired, I know) reply royjacobs 6 hours agorootparentThis is true for the demoscene in general, as well. Not completely, thankfully, but it seems like that it is becoming even more niche than it already was. reply DennisL123 13 hours agoprevIn the nineties this would have saved the entire platform. reply bluescrn 7 hours agoparentNah, might have helped give it a bit more life for another year or two, but even if the Amiga (and Commodore) survived the era of Doom (386&#x2F;486s), it was never going to survive the arrival of Quake and Pentiums, let alone the arrival of GPUs that was to follow shortly after. reply vidarh 4 hours agorootparentThe thing is, Commodore might have been as little as months away from getting the next gen chipset to production if they&#x27;d had just a bit better sales through &#x27;92 and &#x27;93. They were producing samples &#x27;92 onwards but struggled to afford iterations.They were mismanaged enough that they might well have failed to leverage that and just failed a year or two later as you said, and it might very well be that even the best case of completing AAA[1] would just have bought them another extra couple of years.But Commodore had faced crunches like that several times and survived and bounced back massively. So who knows what things might look like if AAA had gone to market (with chunky graphics modes, and massively increased memory bandwidth) and bought them enough sales and by extension time to complete the next-iteration - Hombre[2] - as well.Though Hombre was based on PA RISC, so might well have ended up being the death-knell instead a bit later. Though their \"backwards compatibility\" story for it was based on options of either a \"classic Amiga on a chip\" or emulation, so maybe they&#x27;d have gotten to a sufficiently CPU agnostic position to be able to make further architecture switches survivable.It&#x27;s fun to speculate.I&#x27;m a bit of two minds about it - I&#x27;d have loved the Amiga to have survived longer - I still miss it -, but I&#x27;m unsure if I&#x27;d have liked the direction Commodore would have taken it in with Hombre (which was being designed to also run Windows NT... Shudder). It&#x27;s easier to have nostalgia when later iterations haven&#x27;t ruined the original experience...[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Advanced_Amiga_Architecture_ch...[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Amiga_Hombre_chipset reply bemmu 4 hours agoparentprevIt’s wild to me that now people are making something like this just for fun, while if this had actually been released at the time it would have been a best-selling game. reply bee_rider 17 hours agoprevDid the Amiga 500 have better graphics than the PCs of the early 90’s? Because those graphics look a bit better than Wolfenstein 3D. reply HappyDaoDude 16 hours agoparentFor 2D stuff definitely, but that was because of some neat dedicated graphics processor and a fixed platform for developers to target. The Amiga range in that sense was WAY beyond others in terms of audio&#x2F;visuals when it came out. In that sense it was closer to the home consoles than a typical PC.It led to the odd situation where you had PC&#x27;s that had these killer CPU&#x27;s but everything else about the system was holding them back. The Amiga had an average CPU (8Mhz 68K) but everything else was picking up a lot of slack.As for this example, this is exceptionally good for the Amiga. I don&#x27;t recall there being anything even remotely close to this in its time. Hackers are just gonna optimise way beyond reason and I love it. reply Zardoz84 4 hours agorootparentThe IBM PC (and clones) at the time of launch of the Amiga 500, had at best an 80286 at 6 to 12Mhz . I would call it roughly equivalent CPU with the 68000 at 8Mhz (16 bit segmented addressing vs 16&#x2F;32bit hybrid with planar ram addressing) reply VWWHFSfQ 16 hours agorootparentprevAre hackers optimizing? Or are they writing the same code they always did but now code-generation targeting these platforms is optimizing? reply tom_ 12 hours agorootparentThey are optimizing, probably. Thanks to the internet, knowledge sharing is substantially simplified compared to the 1990s, and it&#x27;s massively easier to find people to collaborate with. Hard to understate how difficult it was to find useful info back in the day.Additionally, anybody that grew up coding on the Amiga has had 30, 35 years to think about it since! - and they are probably still young enough (or, more accurately, probably not yet properly old enough...) that time has, for now, added more to their abilities than it has taken away.And: modern PCs are ridiculously fast! A table or routine that would have taken your Amiga days to produce, even assuming you&#x27;d have considered the idea feasible in the first place (\"b-but - you&#x27;d need a temporary 512 MByte table for that!!\") can be generated in 5 minutes with some python code on your 10 year old laptop. reply alxmdev 16 hours agorootparentprevTooling and code generation improvements no doubt help a lot, but IMO those improvements must be coupled with creative manual optimizations in order to get something like this out of a platform that was tailored for rectangular 2D bitmaps. reply VWWHFSfQ 16 hours agorootparentIt&#x27;s extremely impressive in any case. reply wk_end 14 hours agorootparentprevThis was almost definitely written in asm, no code generation involved. reply ekianjo 16 hours agorootparentprevOptimization and hardware tricks reply tuukkah 16 hours agorootparentprevThere isn&#x27;t much the compiler can optimize on such a simple CPU as the m68k when the source is simple C or hand-optimized assembler code to begin with. reply mike_hock 15 hours agorootparentContemporary compilers definitely do a lot of CPU-agnostic optimizations that ye olde compilers weren&#x27;t capable of. The only new CPU features that fundamentally change this are vector instructions, and compilers still suck at autovectorization. reply gpderetta 4 hours agorootparentContemporary compilers are \"optimized\" to optimize for superscalar, fully pipelined, out of order cpus with plenty of ram and caches. Literally nothing in common with a 68k. Also modern compilers wouldn&#x27;t even know how to produce code for the amiga coprocessors.This engine very likely is written in hand optimized, clock-exact, asm. replybluescrn 16 hours agoparentprevThe Amiga really struggled to handle Wolfenstein&#x2F;Doom clones due to the layout of it&#x27;s video memory making if even harder for the already-slow CPU. The chips that made it great at 2D games held it back at 3D.This new engine is an absolute masterpiece of Amiga coding. The many mid-90s attempts to do similar things tended to need more powerful Amigas (at least an A1200, preferably with an 030 or better accelerator card and extra RAM) for less impressive results. reply johnnyworker 12 hours agorootparentmore info: http:&#x2F;&#x2F;oldwww.nvg.ntnu.no&#x2F;amiga&#x2F;amigafaq&#x2F;AmigaFAQ_16.html reply actionfromafar 16 hours agoparentprevYes and no. It&#x27;s complicated. For textured 3D games, even with 256 colors, the PCs with VGA were better. Wolfenstein catered to EGA, with 16 colors.For smooth frame synced 2D games (no lag, no jitterynes, no tearing) Amiga was hands down better, but those kinds of games were falling out of style in the early 90s. reply mysterydip 16 hours agorootparentYou may be thinking of catacomb 3D, which was a predecessor and EGA reply spitfire 16 hours agorootparentprevWolfenstein was mode 13h 256 VGA colour. reply quadcore 16 hours agorootparentCertainly it was mode X rather. reply polpo 15 hours agorootparentJust looked at the Wolf3D source (https:&#x2F;&#x2F;github.com&#x2F;id-Software&#x2F;wolf3d&#x2F;tree&#x2F;master&#x2F;WOLFSRC) - it uses VGA in unchained mode but still at 320x200. So not exactly Mode X, but \"Mode Y\". reply simne 12 hours agoparentprevYes and no. PCs from beginning was very simple business machines, for accounting, but later benefited from free market and cheap clones.As for me, VGA was wonder, I now think from marketing considerations, PCs way was to make Super-EGA, with little colors, but high resolution. But, sometimes wonders happen.Amigas, or to be more exact, Commodore computers, from beginning made as home computers, with decent integrated graphics and sound.Unfortunately, Amiga parent company was very aggressive against clones, and from what I hear, was not effectively managed (or may be, just tried to made too complex architecture). So after some time, initial superiority was lost, and PCs not just dominated market, but also, once become better technically (because of constant competition on free market).Approx after 1987-middle 1990s, Amiga become technically lagged behind forever, then parent company bankrupt and now, each year, Amigas become more history artifacts. reply dabeeeenster 16 hours agoparentprevYeah they did at the time for sure. When the A500 was released PC games were generally CGA&#x2F;EGA. The A500 was way ahead of its time, especially when you account for how much they cost. reply markmark 9 hours agorootparentAround the time I got my A500, my neighbour&#x27;s dad bought a PC that ran California Games in CGA at about one frame per second. I&#x27;m sure there were much better PCs available, but it didn&#x27;t impress us kids much. They _did_ have Leisure Suit Larry though... reply bee_rider 13 hours agorootparentprevWhat really impressed me is that I was born around the same time as the A500 but I remember playing PC games that looked worse than this, hahaha.Part of it is surely that I was using hand-me-down PCs and there was probably some time lag on the games that my dad would get through the sneaker-net.The art style is also really solid and modern which I’m sure helps hide some of the limitations. reply ekianjo 16 hours agoparentprevUntil Wing Commander came out, mostly yes. reply bitwize 12 hours agoparentprevThe Amiga smoked PCs when it came out. PCs didn&#x27;t really come into their own until the 486 became commonplace, but once it did the Amiga was struggling to keep up, games-wise. For example, the PC port of Mortal Kombat was the most arcade-accurate home port of any system. The Amiga port was nearly, but not quite, as good. reply badpun 6 hours agoparentprevNotice the large black borders around the gameplay area. That&#x27;s due to hardware being too weak to render the game on entire screen. reply simne 11 hours agoprevFrom PC perspective, very unusual view, when control panel is rendered much better than game itself :)- Looks like Mona Lisa paint in 8 bit, but it&#x27;s frame is 16 bit. reply leidenfrost 10 hours agoparentI&#x27;m sure it looks miles better with a CRT reply junon 3 hours agoprevWow this is beautiful. The artwork rivals even modern retro games. reply bluedays 2 hours agoprevNot to be confused with grindr. reply aidos 17 hours agoprevThis is not how I remember games on the Amiga. Having said that, I loved the games and graphics on the Amiga. It just felt like a beautiful visual experience. reply kapitanjakc 11 hours agoprevgetting Doom vibes...Looks nice GG reply cyberax 16 hours agoprevWant something to blow your mind?Here is a 3D FPS on ZX-Spectrum: https:&#x2F;&#x2F;youtu.be&#x2F;tiV8ZPmmoJI?t=106 or https:&#x2F;&#x2F;youtu.be&#x2F;3v7cFGneuaw?t=66This is running on a computer with a 3.5MHz CPU, no hardware multiplication, and only 48K of RAM. reply bgeeek 55 minutes agoparentNo, it&#x27;s a 128. The obvious giveaway being the audio. reply Findecanor 14 hours agoparentprev\"Just\" a demo with no enemies, but on a Commodore 128: https:&#x2F;&#x2F;youtu.be&#x2F;1tDflgqJlTw reply ruk_booze 10 hours agorootparentIt is originally from the C64 demo ”Andropolis” by Booze Design and Instinct. Coded by Andreas Larsson, the guy&#x2F;genius who ported Eye of the Beholder to the C64.Here is the same thing in turbo mode on an Ultimate 64:https:&#x2F;&#x2F;youtube.com&#x2F;shorts&#x2F;fF2IXTwWDPQ?si=ds5-5Kwm95Zj2vtfAnd with no vsync:https:&#x2F;&#x2F;youtube.com&#x2F;shorts&#x2F;hvmNnwz7ENQ?si=mDVQLWx3T8hnrbuC reply pbj1968 14 hours agoparentprevOnce people know something is possible with video games, they tend to imitate it fairly well across platforms. I like to use Street Fighter 2 as an example… good ports on PCE, SNES, Genesis.. and surprisingly decent bootlegs on NES and others. But until it hit arcades, there was nothing else like it. reply bartread 16 hours agoprevOooooooookay, so I&#x27;m not about to do this down, because I think it&#x27;s awesome, but I do think it&#x27;s time for a little more up-front transparency here.When I clicked through and hit play on the first video I braced myself for the worst framerate in human history and&#x2F;or a tiny viewport, and so my jaw briefly dropped when I was greeted with neither of those. The game is basically fullscreen and runs great: a perfectly respectable (for the time - I know a lot of you will moan about games that don&#x27;t run at a constant 60fps but, man, maybe you don&#x27;t know what it was like back then) 25 - 30fps, and a frankly amazing framerate for the Amiga. Plenty of 2D games couldn&#x27;t have reliably held that and just forget it for any kind of 3D.Then my rational mind kicked in with, \"There&#x27;s no effin way that&#x27;s running on an A500 with a stock 68k CPU running at 7.16&#x2F;7.09MHz.\"And, sadly, I&#x27;m right: there is no effin way. The footage was recorded from an A1200 with a stock 68020 running at 14MHz. The graphics are OCS compatible, and I&#x27;ve no doubt the engine is caning the OCS blitter to within an inch of its life, so it looks exactly the same as it would on an A500, but you ain&#x27;t getting that kind of framerate without more horsies than the A500&#x27;s 68k can supply.With that being said, the game runs at 10 - 12 fps on a stock A500 with 1MB RAM (512K chip + 512K fast, so you need the 1.3 ROMs and the Fatter Agnus), which is still incredibly impressive. For a lot of solid polygon 3D games back in the day - think F&#x2F;A-18 Interceptor, F-19 Stealth Fighter, and even games like Starglider 2 - drops to single digit framerates if not exactly the norm, were certainly commonplace (I remember F-19 being particularly bad for this). I seem to remember the Amiga version of Elite held a pretty decent framerate but, to be fair, the polygon count was very low, and it had a pretty small viewport. By comparison with these games, the Grind visuals, at 10 - 12 fps, on a bog standard A500 with an absolutely era appropriate amount of memory are nothing short of extraordinary.If, in 1990 - 1993, or even after I&#x27;d first played DOOM on a mate&#x27;s dad&#x27;s 486SX in summer 1994, you&#x27;d shown me Grind running on my Amiga 500 at 10 - 12 FPS I would probably have fainted or jizzed myself or something equally ridiculous. It would have literally blown my mind.Incredible work.EDIT: Is it me or is the shotgun sound effect a slightly edited version of the DOOM shotgun sound effect? Not complaining, because it&#x27;s an awesome sound, but just wondering if others are hearing the same thing I am. reply snvzz 14 hours agoparent>a stock A500 with 1MB RAM (512K chip + 512K fast)Not Fast RAM, but Slow RAM.Fast RAM is exclusive to the CPU. On A500, it needs to be on the CPU socket, or on the left expansion port.Trapdoor RAM, as in the common 512K expansion, can only be Slow or Chip.Slow because the chipset can block access to it, but can&#x27;t access it itself.Chip on newer A500 boards with ECS Agnus, after a small motherboard jumper mod. reply prvc 4 hours agoparentprev>There&#x27;s no effin way that&#x27;s running on an A500 with a stock 68k CPU running at 7.16&#x2F;7.09MHz.Could you be specific about the envelope math used to arrive at this conclusion? What are the essential bottlenecks? reply malfist 16 hours agoprev [–] This is different than Grindr, a couch co-op shooter reply lizardking 50 minutes agoparentReddit is that way, sir reply sgt 1 hour agoparentprev [–] Shoot-em in. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Grind is an updated first-person shooter game for Amiga 500, developed with the Dread-Engine. It's built around a Steampunk/Lovecraftian aesthetic and features high-quality weapon designs.",
      "The latest update includes a demo and a new level set in a city, with future development plans for additional levels and enemy types.",
      "Music support, sound effects, and more levels are currently in progress, supported by a Patreon. Additionally, a Mega Drive version of the game is currently under consideration."
    ],
    "commentSummary": [
      "The focal point of the post is the game \"Grind\" for the Amiga 500, applauded for its meticulous detailing and exceptional 3D graphics, recalling the work of the Bitmap Brothers.",
      "The conversation covers Sega's strategy towards 3D gaming and its influence on video game consoles.",
      "Other subjects include the Amiga 500's constraints and potential, developer attempts at optimization, and comparisons with other gaming platforms, with numerous users expressing their admiration for the game's performance on Amiga 500, despite early doubt."
    ],
    "points": 292,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1697058404
  },
  {
    "id": 37847782,
    "title": "Wordpress.com Now Supports ActivityPub",
    "originLink": "https://wordpress.com/blog/2023/10/11/activitypub/",
    "originBody": "Products Features Resources Plans & Pricing Log In Get Started WordPress Hosting Domain Names Website Builder Create a Blog Newsletter Professional Email Website Design Services Store Course Maker Enterprise Solutions Overview WordPress Themes WordPress Plugins Google Apps WordPress.com Support WordPress News Website Building Tips Business Name Generator Logo Maker Discover New Posts Popular Tags Blog Search Daily Webinars Learn WordPress Close the navigation menu GET STARTED Sign Up Log In About Plans & Pricing PRODUCTS WordPress Hosting Domain Names Website Builder Create a Blog Newsletter Professional Email Website Design Services Store Course Maker Enterprise Solutions FEATURES Overview WordPress Themes WordPress Plugins Google Apps RESOURCES WordPress.com Support WordPress News Website Building Tips Business Name Generator Logo Maker Discover New Posts Popular Tags Blog Search Daily Webinars Learn WordPress The WordPress.com Blog WordPress.com News Engage a Wider Audience With ActivityPub on WordPress.com The fediverse has arrived at WordPress.com. October 11, 2023 Matthias Pfefferle Exciting times are here for all WordPress.com users! The revolutionary ActivityPub feature is now available across all WordPress.com plans, unlocking a world of engagement and interaction for your blog. Your blogs can now be part of the rapidly expanding fediverse, which enables you to connect with a broader audience and attract more followers. Let’s dive into what this means for all WordPress.com blogs. What is the “fediverse”? The fediverse consists of federated platforms like Mastodon, which are networks of independent websites or servers that can communicate with each other while still operating individually. It’s much like email; you can send emails to users with accounts on different services (like Gmail, Yahoo, etc.), yet all of them can interact seamlessly. Similarly, federated platforms enable users to follow, share, and interact with content across different services in a unified network. What is the ActivityPub plugin? ActivityPub is a WordPress plugin that facilitates seamless integration between your blog and a host of federated platforms, including Mastodon, Pleroma, Friendica, and more. This plugin empowers your readers to follow your blog posts on these platforms. In addition, replies to your posts from these platforms are automatically turned into comments on your WordPress blog, creating a more interactive and dynamic conversation around your content. Synchronicity for the win! Transform your blog into a fediverse profile Your WordPress blog can now become a profile for the fediverse. This means your readers can follow you and receive all the latest posts from your blog directly on their preferred platform. More so, they can engage in enriching conversations by replying to your posts, with their replies reflecting as comments on your blog post, creating a synchronized and interactive experience. On Free, Personal, and Premium sites, you can enter the fediverse through your settings (see how below); for Business and Commerce sites, simply install the ActivityPub plugin and follow the prompts to set up your profile. Getting started is a breeze From your blog’s dashboard, go to Settings > Discussion and activate the feature by toggling “Enter the fediverse.” Make note of your default fediverse profile name. In the example above, it’s the alias openprotocolfanblog.wordpress.com@openprotocolfanblog.wordpress.com. Your alias will be unique to you, of course, and will be far more memorable with a custom domain! (More on that below.) Follow your new profile on a federated platform, such as Mastodon. Share your profile name with others so they can follow your blog on federated platforms. Remember, this feature is applicable to new posts only; and it might take up to 15 minutes for new posts to appear on federated platforms. Why use a custom domain? Upgrading to a domain doesn’t just give your profile a professional touch: A shorter custom domain is simply more memorable than the default name provided. It ensures your profile is uniquely identifiable, making it easier for users across the fediverse to find and interact with your content. With a custom domain you can easily move your entire fediverse connection to any host at any time. Make new connections today! Take advantage of this new opportunity to extend your blog’s reach, connect with diverse audiences, and create engaging dialogues. It only takes seconds to enable this simple yet powerful feature on WordPress.com. And remember, upgrading to a domain not only emphasizes your unique identity but also enhances profile portability. So, why wait? Dive in and showcase your content to the world! Email Newsletter Missing out on the latest WordPress.com developments? Enter your email below to receive future announcements direct to your inbox. An email confirmation will be sent before you will start receiving notifications—please check your spam folder if you don't receive this. Email Address: Follow Join 102.3M other subscribers Share this: Click to share on Tumblr (Opens in new window) Click to share on Twitter (Opens in new window) Click to share on Mastodon (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on LinkedIn (Opens in new window) Click to share on WhatsApp (Opens in new window) More Loading... Related Making the Social Web a Better Place: ActivityPub for WordPress Joins the Automattic Family March 17, 2023 In \"News\" Hosting Live (Virtual!) Events: Lessons from Planning the WordPress.com Growth Summit August 5, 2020 In \"Better Blogging\" Google Knols Move to WordPress: The Annotum Platform November 22, 2011 In \"WordPress.com\" Social Previous Post New to WordPress.com: Earn More By Adding a Paywall 8 Comments quadzillabynorth Oct 11th at 4:38 pm When I go to Settings/Discussion on my Remium Blog I do not see a Fedeverse toggle and my Discussion Settings page does not look like the one in your post. Liked by 1 person supernovia Oct 11th at 7:40 pm You might be using the wp-admin/classic view. Can you see the toggle here? Liked by 3 people quadzillabynorth Oct 11th at 7:42 pm Yes. How do I switch to the other view? Like supernovia Oct 11th at 8:26 pm There’s a View option in the upper right, or you can use that link directly. Liked by 1 person ogeobasi Oct 11th at 4:54 pm Good Liked by 1 person Thisness Oct 11th at 5:28 pm When will WordPress Reader be able to follow Fediverse accounts? Liked by 10 people supernovia Oct 11th at 8:35 pm Love this idea. We’ll share it with the team. Liked by 3 people Richard Morrison Oct 12th at 2:22 am This is very exciting for a more open/shared version of a social media future! Love it. Liked by 5 people Please do not use these comments for asking questions, support, or bug reporting. Use the forums or support contact form for that. Please read our comment guidelines before posting. Leave a Reply Create your new blog or website for free Get Started GET STARTED Create your own website PRODUCTS WordPress Hosting Domain Names Website Builder Create a Blog Professional Email P2: WordPress for Teams Enterprise Solutions Website Design Services FEATURES Overview WordPress Themes WordPress Plugins Google Apps RESOURCES WordPress.com Support WordPress Forums WordPress News Website Building Tips Business Name Generator Logo Maker Popular Topics Daily Webinars Learn WordPress Developer Resources COMPANY About Partners Press Terms of Service Privacy Policy Privacy Notice for California Users An Automattic Invention Comment Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37847782",
    "commentBody": "Wordpress.com Now Supports ActivityPubHacker NewspastloginWordpress.com Now Supports ActivityPub (wordpress.com) 252 points by zoul 21 hours ago| hidepastfavorite48 comments nologic01 17 hours agoThis might become bigger than mastodon itself. Wordpress is much easier &#x2F; cheaper to self-host.Along the same lines there is talk about discourse and nextcloud extensions which also have large installed bases and amenable to single-click type installs.In a sense any self-hosted server that publishes stuff is a candidate to get integrated into the fediborg.What would be really sweet is to pre-emptively embed activitypub federation into generic platforms like django, phoenix, laravel etc. Right now various teams work in uncoordinated projects all implementing similar functionality. reply jeroenhd 17 hours agoparentWordPress is much easier to self host but much worse if you try to use it as social media. Most people who use Mastodon will want some Twitter-like experience. I don&#x27;t think WordPress articles are going to replace toots any time soon.On the other hand, Tumblr is supposedly working on ActivityPub integration, and that could become a major Fediverse player with the ability to replace Mastodon. reply kalleboo 11 hours agorootparentIt seems like the work on Tumblr support for ActivityPub is on ice, I don&#x27;t think it&#x27;s going to happen https:&#x2F;&#x2F;mastodon.social&#x2F;@_jv_&#x2F;110692572741573511 reply nologic01 16 hours agorootparentprevWhat complicates matters (in a nice way as it opens up more possibilities) is the increasing role of client apps. You maybe are thinking of the current Wordpress and Mastodon web UI&#x27;s but a dedicated client (as those that already exist for mobile) can create any timeline illusion.But it is true that all these different type of servers have different specializations as to what type of content is easy to produce and distribute on them. A further intriguing aspect is to federate with video, image or audio sharing servers (peertube, pixelfed, funkwhale). reply danijelb 14 hours agorootparentIt could lead to decentralization of both consuming and publishing. There could be a native timeline UI integrated into iOS&#x2F;Android. Mobile network operators could host fediverse instances for text&#x2F;audio&#x2F;video and bundle them into phone plans which everyone already pays for. The possibilities are endless.In such scenario search engines would also play a bigger role because if people are hosting videos on 50 different services instead of just Youtube, you need a separate search engine which crawls all instances.I think the current fediverse servers like Pixelfed and Mastodon are emulating centralized services because we are used to how they function and it would be too confusing. If it catches on, then those services can slowly morph and adopt the benefits of the new paradigm reply jeroenhd 15 hours agorootparentprevI mostly use Mastodon through an app, same with Lemmy and a bunch of other apps that have perfectly fine web UIs. On phones, apps just work better in most cases (though that strongly depends on what kind of company is behind those apps).From what I can tell by the comments on this article, WordPress has implemented ActivityPub for publishing posts, but you can&#x27;t actually follow other people. Maybe the next update will fix all that, but no client app will ever be able to compensate for unimplemented APIs like that. Comments do federate, but it&#x27;s not as \"social\" as most of the Fediverse. reply ymolodtsov 5 hours agorootparentprevI was always suprised people were giving Meta a lot of flak for not building ActivityPub fast enough yet completely missing the fact Matt announced it for Tumblr ages ago and it they did nothing. reply southwesterly 15 hours agorootparentprevMakes sense since Automattic own Tumblr and WordPress. reply sangnoir 9 hours agorootparentprev> WordPress is much easier to self host but much worse if you try to use it as social media. Most people who use Mastodon will want some Twitter-like experienceIs WordPress exposing AP to plugins? If so, I&#x27;m brushing up my PHP to author a plugin to host a Twitter-like experience on the WordPress site. Let&#x27;s bring back Pingbacks back! This time, on the Fediverse. I could make dozens of dollars on MRR. Dozens! reply justinator 15 hours agoparentprevThis plugin isn&#x27;t for WordPress per say (yet?), it&#x27;s for wordpress.com, so not self-hosted. reply justinator 15 hours agorootparentNevermind - I&#x27;ve installed the standalone plugin:https:&#x2F;&#x2F;wordpress.org&#x2F;plugins&#x2F;activitypub reply zoul 21 hours agoprevReplies appear to work, too: “In addition, replies to your posts from these platforms are automatically turned into comments on your WordPress blog, creating a more interactive and dynamic conversation around your content. Synchronicity for the win!” reply is_true 18 hours agoparentThat would be great for news sites which have the problem that most of the conversation around articles happens on social networks. reply carlosjobim 1 hour agorootparentNews sites don&#x27;t want conversation and comments on their articles. They want it to be a one way conversation. reply 1over137 14 hours agoparentprevThis sounds great! Until spammers and grifters discover it. Is there a plan for them? reply edent 9 hours agorootparentReplies from the Fediverse are moderated in the same way as normal comments.So if a spammer on Mastodon replies to your post, it will be caught by Akismet (or whatever spam filter you&#x27;re running). reply freeone3000 9 hours agorootparentprevDon’t follow the spammers and grifters, I guess. Replies that you make are posted to your feed. reply xnx 19 hours agoprevI&#x27;d place more money on Wordpress being the future of Twitter than I would Bluesky, Threads, or Mastodon. reply danijelb 14 hours agoparentIf ActivityPub gets really popular, there won&#x27;t be a single service that&#x27;s winning. For example, if each Youtube profile is suddenly a fediverse account which you can follow, the owner of that Youtube profile doesn&#x27;t need a separate Twitter or Wordpress account - simply the act of uploading the video to Youtube will appear in user timelines of twitter, mastodon and all other services. Same would happen with blogs, instagram accounts, etc.And if we get to such future, it&#x27;s possible that we won&#x27;t even need a Mastodon&#x2F;Twitter account to have a timeline. iOS and Android could build native support for following accounts and displaying timelines in the operating system. reply rsynnott 2 hours agoparentprevI really think it&#x27;s a mistake to assume that there will be one thing which replaces Twitter. This has ~never happened (I think possibly the only example would be the Digg->Reddit migration); normally people leave a dying social network for a _variety_ of other things, not for a copy of the dying thing.In an ActivityPub world, this is particularly unlikely to happen. Arguably, we&#x27;ve actually had a social media ecosystem a bit like this before; there was a time when Wordpress (self-hosted or service), MovableType and a few others could interact via things like pingbacks (a sort of early quote-tweet). reply lukewrites 18 hours agoparentprevI agree. Wordpress powers something like 40% of all websites. 40% of the web having a low friction way of publishing to the fediverse is a big deal. Sure, this doesn&#x27;t mean that almost half the web is suddenly \"on the fediverse\"; the more ad-dependent a site is, the less likely it seems that they&#x27;ll enable this unless they can do so in a way that brings users to them.I want to be able to have a fediverse feed that&#x27;s as much RSS feed as news feed, but that&#x27;s my preference. I&#x27;m really glad WP is making it easy for folks to use ActivityPub. reply xnx 17 hours agorootparentCorporate publishers are probably feeling the burn of the enshittifcation of Medium and then Twitter, and annoyance from the Instagram ad volume and Threads uncertainty. I bet they would welcome an something more boring like a Wordpress blog that was totally under their control. The critical part that&#x27;s missing is an easy way for end users to subscribe (e.g. a popular&#x2F;easy RSS&#x2F;Atom&#x2F;feed reader standalone product or feature). reply chefandy 17 hours agoparentprevI&#x27;d love for that to be true, but social media has been trending away from blog-type textual posts for a long time. Last stat I saw, wordpress.com published around 77 million posts per month. I think twitter needs less than 4 hours to hit 77 million tweets.Also, the brand is in really bad shape. Super outdated and stale. I know a lot of people wish it didn&#x27;t, but that kind of thing really matters when you&#x27;re trying to get lots of people to think your product is worth investing time into. reply josefresco 18 hours agoparentprevWhile I wish this were true... considering how long it took to get Gutenberg, I wouldn&#x27;t hold your breath. reply chiefalchemist 18 hours agorootparentAnd GB was rushed out the door, not even half-baked. Too often tt&#x27;s a beta product pretending to be production worthy. reply riffic 17 hours agoparentprevwell luckily WordPress would be interoperable with Mastodon and maybe Threads if they stick to their commitment to federate with the ActivityPub protocol.Bluesky insists on building its own protocol and is making empty promises (https:&#x2F;&#x2F;atproto.com&#x2F;specs&#x2F;atp#future-work) to turn it over to the IETF or W3C at some undetermined date. reply rchaud 16 hours agoparentprevIt would be great if conversations weren&#x27;t siloed inside one corporation&#x27;s servers, but I don&#x27;t think WP will change anything re: Twitter.Twitter and Mastodon are cognitively low-maintenance tools. The authoring is very simple, and designed to be within 280&#x2F;500 characters. Wordpress is the opposite. The UI assumes you&#x27;re there to write, not view other people&#x27;s sites and comment on them.Automattic owns Tumblr, and that type of UI is probably what would get people thinking of posts as \"tweet-length info\" instead of full-on blog posts. reply hannes0 19 hours agoparentprevcan you elaborate? Wordpress or (personal) blogs in general? reply teleforce 18 hours agorootparentNot OP but I think this mainly due to the newly supported cross platform fediverse profile capability. From the article:\"Your WordPress blog can now become a profile for the fediverse. This means your readers can follow you and receive all the latest posts from your blog directly on their preferred platform. More so, they can engage in enriching conversations by replying to your posts, with their replies reflecting as comments on your blog post, creating a synchronized and interactive experience.\" reply danijelb 15 hours agoprevIt&#x27;s great they are adopting the standard but those aliases are ugly.Instead of openprotocolfanblog.wordpress.com@openprotocolfanblog.wordpress.com it should be openprotocolfanblog@wordpress.com reply pfefferle 8 hours agoparentWe have decided to do it like that, because it is an easy and nice way to have a unique ID that works with or without a custom domain.For example: `openprotocolfanblog@wordpress.com` makes only sense if you use the wordpress.com subdomain. If you have your own domain, you want to have something like `username@domain` not `username@wordpress.com`.Besides of that, you will be able to activate user-accounts (next to the blog-account) on higher plans. That means we had to choose something that is consistent but causes no collisions with usernames.And finally Mastodon and others only show the part before the @, that makes the ID very similar to what Bluesky is doing. https:&#x2F;&#x2F;mastodon.social&#x2F;@pfefferle&#x2F;111220452911718192 reply rsynnott 2 hours agoparentprevThe trouble with that is moderation. Presumably there exists some Nazi who has a Wordpress blog. If they&#x27;re a particularly noisy Nazi, that could get Wordpress.com banned on a lot of instances, because the Fediverse&#x27;s primary and easiest moderation route is nuking badly-behaved instances, and many instance admins are _particularly_ sceptical of corporate ones (some instances have _preemptively_ banned threads).This way, every Wordpress blog is for practical purposes its own instance.That said, the username component does seem unnecessarily unwieldy. reply BHSPitMonkey 11 hours agoparentprevI assume that would create confusing overlaps with @wordpress.com email addresses which may or may not exist? Maybe just \"blog@NAME.wordpress.com\" would suffice. reply pfefferle 8 hours agorootparentwe also thought about using something generic like `blog@NAME.wordpress.com` or `feed@NAME.wordpress.com` but this would have made autocomplete useless. Mastodon users would see a list of thousands of `blog` or `feed` users when searching for a WordPress.com user. reply ChrisArchitect 19 hours agoprevDefinitely interesting development.How does it work tho? It&#x27;s just like the &#x27;old&#x27; RSS->tweets kind of thing? or does the whole blog post get sent into the fediverse as a post? Making it kind of unwieldly? Microblogging is dead? Long live microblogging. reply edent 18 hours agoparentThe full post is sent to the Fediverse.For example, if you follow @blog@shkspr.mobi you&#x27;ll see my blog&#x27;s posts in your social feed. They appear just like any other message.I&#x27;ve written a bit about it at https:&#x2F;&#x2F;shkspr.mobi&#x2F;blog&#x2F;2023&#x2F;09&#x2F;this-blog-is-now-on-the-fed... reply Kye 19 hours agoparentprevThe blog appears as a profile in whatever way your ActivityPub instance displays profiles. Posts appear however your instance displays posts. reply rsynnott 2 hours agoprevI haven&#x27;t been keeping up with Wordpress, but do they still support pingbacks as a first-class construct? Those could be interesting in an ActivityPub context; they&#x27;re arguably the progenitor of things like quote tweets. reply ruined 18 hours agoprevthis post doesn&#x27;t seem to be published via activitypub, which seems like a missed opportunity reply abdullahkhalids 18 hours agoprevI have my own statically generated website&#x2F;blog. I won&#x27;t switch to Wordpress. How can I integrate ActivityPup into my blog in the same way?Edit: I am fine with adding dynamic features to the site. I see there are implementations [1], which kind of are in the ballpark.[1] https:&#x2F;&#x2F;github.com&#x2F;toddsundsted&#x2F;ktistec https:&#x2F;&#x2F;github.com&#x2F;davecheney&#x2F;pub reply grishka 17 hours agoparentYou would need a server application of some kind for two things: sending your new posts out as activities to your followers, and accepting activities (at least Follow) from the outside world. That application would also need somewhere to store the list of followers and their inboxes (endpoints where you send activities). That&#x27;s basically it. The actor object itself can be a static file, just don&#x27;t change its URL.I encourage you to try building your own minimal ActivityPub server — here&#x27;s a tutorial to get you started: https:&#x2F;&#x2F;blog.joinmastodon.org&#x2F;2018&#x2F;06&#x2F;how-to-implement-a-bas...The sending and receiving parts aren&#x27;t required to run on the same machine. You can send activities from your laptop, but the receiving side needs to be on a server with a public IP, a domain, HTTPS and all that. reply xd1936 18 hours agoparentprevHere&#x27;s a novel solution to use Mastodon&#x2F;Fediverse replies as a comment section on a statically-generated blog.https:&#x2F;&#x2F;cassidyjames.com&#x2F;blog&#x2F;fediverse-blog-comments-mastod... reply AndrewStephens 18 hours agoparentprevWhen I looked into do exactly this a while ago I quickly realized that it would be a lot of work to do properly. There is no such thing as a static ActivityPub service by design.However, there are premade services that will take an RSS feed and do all the work to allow subscriptions, etc. reply CitrusFruits 18 hours agoparentprevYou probably can&#x27;t easily integrate \"in the same way\"; I suspect this was a large engineering effort. However, you could do a barebones cross-post to Mastadon using something like IFTT: https:&#x2F;&#x2F;ifttt.com&#x2F;explore&#x2F;how-to-crosspost-mastodon-twitter. reply tuukkah 17 hours agoparentprevThere is a bridge from any blog to Fediverse called Bridgy Fed that you can use: https:&#x2F;&#x2F;fed.brid.gy&#x2F;web-site reply mikece 18 hours agoprevIt is more accurate to say that the ActivityPub plugin[1] which was acquired by Automattic has hit 1.0 and is available to be used on WordPress.com. Yes, Mastodon implements (most of) ActivityPub but it&#x27;s hardly the only platform on the web that does.[1] https:&#x2F;&#x2F;wordpress.org&#x2F;plugins&#x2F;activitypub&#x2F;advanced&#x2F; reply Kye 16 hours agoparent>> \"It is more accurate to say that the ActivityPub plugin[1] which was acquired by Automattic has hit 1.0 and is available to be used on WordPress.com.\"Welcome to one of those rare times when you need to read the article.This is announcing built-in support that doesn&#x27;t need the plugin. You can still optionally install the plugin if you have the more expensive plans. The plugin was already usable on WordPress.com and has been for months: https:&#x2F;&#x2F;wordpress.com&#x2F;blog&#x2F;2023&#x2F;03&#x2F;17&#x2F;making-the-social-web-... reply alberth 14 hours agoprev [–] Just remember …WordPress.com != open source WordPress replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "WordPress.com has launched the ActivityPub feature, allowing users to link their blogs with federated platforms such as Mastodon to reach a broader audience.",
      "The ActivityPub plugin aids in effortless integration, enabling readers to follow blog posts and convert replies into comments on the blog.",
      "Users can enhance their profiles with a custom domain and can activate this feature through their blog settings, intending to boost engagement and reach for WordPress.com blogs."
    ],
    "commentSummary": [
      "WordPress.com has integrated the ActivityPub, a decentralized social networking protocol, enabling users to publish and share content in the fediverse.",
      "This move grants its extensive user base access to the decentralized social media movement, though some users express concern over moderation and the discrepancies in user interface (UI).",
      "Note the distinction between WordPress.com, which implemented these changes, and the open-source iteration of WordPress."
    ],
    "points": 252,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1697046443
  },
  {
    "id": 37848793,
    "title": "Obligator – An OpenID Connect server for self-hosters",
    "originLink": "https://github.com/anderspitman/obligator",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up anderspitman / obligator Public Notifications Fork 4 Star 428 Code Issues 1 Pull requests Actions Projects Security Insights anderspitman/obligator master 5 branches 1 tag Go to file Code Latest commit anderspitman Update table for Ory and Zitadel 665f534 Git stats 116 commits Files Type Name Latest commit message Commit time assets Implement only allowing valid users docker Add api-socket-dir argument scripts Add build scripts templates Implement only allowing valid users LICENSE Create LICENSE README.md Update table for Ory and Zitadel api.go Add api-socket-dir argument build.sh Remove sqlite storage implementation for now email.go Implement custom login key names go.mod Remove sqlite storage implementation for now go.sum Remove sqlite storage implementation for now json_storage.go Switch some storage functions to message passing main.go Add api-socket-dir argument oauth.go Fix race condition with logo map sqlite_storage.go Remove sqlite storage implementation for now storage.go Implement custom login key names utils.go Handle old invalid login keys README.md WARNING This is currently pre-release beta software. I don't recommend using it in production at the moment. It has not yet undergone any sort of official security review, and I am not a security expert. The plan is to arrange for a security review before reaching 1.0. That said, testing and feedback (especially with respect to security) would be greatly appreciated. Introduction obligator is a relatively simple and opinionated OpenID Connect (OIDC) Provider (OP) server designed for self-hosters. Motivation There are lots of great open source OIDC servers out there (see comparison). I made obligator because I needed a specific combination of features I didn't find in any of the others. Here's a brief list. See the feature explanation section for more detailed information. Simple to deploy and manage. Static executable and either flat-file or sqlite storage Support for anonymous OAuth2 clients Authenticate to multiple domains at once Passwordless email login Configurable at runtime with an API Support for forward auth Support for trusted headers Support for upstream social login providers (GitLab, GitHub, Google, etc) Design The overarching philosophy of obligator is that identities are built on email. Email isn't perfect, but it's the globally unique federated identity we have that works today. Thus the purpose of obligator is to validate that a user controls an email address as simply as possible, and communicate that to the application the user is attempting to log in to. Validation can either be done directly through SMTP, or delegated to upstream OIDC (and some plain OAuth2) providers. Running it Here's a fairly complete JSON storage file (obligator_storage.json). Note that I call it \"storage\" and not \"config\" because it's not static, and more like a simple database. obligator will update it at runtime if new values are provided through the API. { \"root_uri\": \"https://example.com\", \"login_key_name\": \"obligator_login_key\", \"oauth2_providers\": [ { \"id\": \"google\", \"name\": \"Google\", \"uri\": \"https://accounts.google.com\", \"client_id\": \"\", \"client_secret\": \"\", \"openid_connect\": true }, { \"id\": \"lastlogin\", \"name\": \"LastLogin.io\", \"uri\": \"https://lastlogin.io\", \"client_id\": \"https://example.com\", \"client_secret\": \"\", \"openid_connect\": true } ], \"smtp\": { \"server\": \"smtp.fastmail.com\", \"username\": \"\", \"password\": \"\", \"port\": 587, \"sender\": \"auth@example.com\", \"sender_name\": \"Example\" }, \"jwks\": \"\", \"users\": [ { \"email\": \"user1@example.com\" }, { \"email\": \"user2@example.com\" } ], \"public\": false } If you're already using docker, it's the easiest way to get started with obligator: mkdir obligator_docker/ cp obligator_storage.json obligator_docker/ docker run --user $(id -u):$(id -g) --rm -it -v $PWD/obligator_docker:/data -v $PWD/obligator_docker:/api -p 1616:1616 anderspitman/obligator:latest -storage-dir /data -api-socket-dir /api -root-uri example.com -port 1616 You can also download static executables for various platforms from the releases page. Using the API Currently the API is only offered through unix sockets. This reduces the chance that it accidentally gets exposed, which is important because it's not authenticated in any way. There's not any documentation, and the API is in flux, so refer to the source code for usage. Here's an example assuming you ran the docker command above: curl --unix obligator_docker/obligator_api.sock dummy-domain/oauth2-providers See here for more info on using curl over unix sockets. Feature explanation Anonymous OAuth2 clients Normally in OAuth2 (and therefore OIDC), an app (client) is required to pre-register with the provider. This can create a lot of friction, especially if you're self-hosting an open source application. App developers are forced to either share a single client ID for all their users (and share their client secret, which essentially makes it pointless), or each user must separately register their instance. Instead, obligator takes essentially the approach described here. Any OAuth2 client can anonymously authenticate with an obligator instance, with the client_id equal to the domain of the client, and client_secret left blank. Security is maintained through the following means: Only approved email addresses are permitted unless public: true is set in the config. The client_id URI must be a prefix of the redirect_uri, and the client_id is displayed to the user when consenting to the login. This guarantees that the user approves the ID token to be sent to the domain shown. Note that this can actually be more secure than pre-registration. There have been attacks in the past where users were tricked into authorizing apps because the pre-registered information looked convincing. By forcing the user to decide whether they trust the actual domain where the ID token will be sent, and not displaying any sort of logo which can be faked, security is improved. Multi-domain authentication Have you ever noticed when you login to Gmail on a new computer that you're also automatically logged in to YouTube? How does this work when Gmail is on google.com and youtube.com doesn't have any access to the cookies or localstorage of google.com? The answer is that when you log in on accounts.google.com, it makes a quick redirect to youtube.com with a URL parameter to also set up the cookies there. I also want this functionality for all the domains protected by my OIDC server so I'm building it into obligator. Passwordless email login In line with the philosophy above, email reigns supreme in obligator. Since passwords are relatively difficult to use securely, the way to add an email identity is to send a confirmation code to the email address. Demo There's a public instance of obligator running at https://lastlogin.io (discovery doc at https://lastlogin.io/.well-known/openid-configuration). You can use it with any OIDC client. Just set the client_id to a prefix of the redirect_uri when making the authorization request. I like to use https://openidconnect.net/ for ad-hoc testing. The official OpenID conformance suite is also excellent. Comparison is the thief of joy Software is rarely about right vs wrong, but rather tradeoffs. This table is intended to help compare tradeoffs of different servers. It's also very incomplete and probably incorrect in many cases. If you have a correction, please submit an issue or leave a comment on the Google sheet here which is where it's generated from.obligator Authelia Authentik KeyCloak Vouch oauth2-proxy Dex Ory Hydra Zitadel Casdoor Simple ✅ ✅ ❌ ❌ ❓ ❓ ❓ ❌ ❌ ❓ Anonymous auth ✅ ❌ ❌ ❌ ❌ ❌ ❌ ❌ ❌ ❌ Multi-domain auth ✅ (planned) ❌ ❌ ❌ ❌ ❌ ❓ ❌ ❓ ❓ Passwordless email login ✅ ❌ ❌ ❌ ❌ ❌ ❌ ✅ ❌ ❓ HTTP API ✅ ❌ ✅ ✅ ❌ ❌ ✅ ✅ ✅ ❓ Forward auth ✅ ✅ ✅ ✅ ✅ ✅ ❓ ✅ ❓ ❓ Trusted header auth ✅ (planned) ✅ ✅ ❌ ❌ ❌ ❓ ✅ ❓ ❓ Upstream OIDC/OAuth2 ✅ ❌ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ❓ SAML ❌ ❌ ✅ ✅ ❌ ❌ ✅ Needs coding ✅ ❓ LDAP ❌ ✅ ✅ ✅ ❌ ❌ ✅ Needs coding ✅ ❓ MFA ❌ ✅ ✅ ✅ ❌ ❌ ❓ ✅ ✅ ❓ Standalone reverse proxy ❌ ❌ ✅ ✅ ❌ ✅ ❌ ✅ ❓ ❓ Admin GUI ❌ ✅ ✅ ✅ ❌ ❌ ❓ ✅ ✅ ❓ Dyanmic client registration ❌ ❌ ❌ ❓ ❌ ❌ ❌ ✅ ❌ ❓ Language Go Go Python Java Go Go Go Go Go Go Dependencies 1 49 54 ❓ 16 36 36 58 81 68 Lines of code ~2500 ❓ ❓ ❓ ❓ ❓ ❓ ❓ ❓ ❓ About Simple and opinionated OpenID Connect server designed for self-hosters Topics openid oidc oidc-server Resources Readme License MIT license Activity Stars 428 stars Watchers 5 watching Forks 4 forks Report repository Releases 1 tags Packages No packages published Contributors 2 anderspitman Anders Pitman aeneasr hackerman Languages Go 97.7% Shell 1.9% Dockerfile 0.4% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37848793",
    "commentBody": "Obligator – An OpenID Connect server for self-hostersHacker NewspastloginObligator – An OpenID Connect server for self-hosters (github.com/anderspitman) 242 points by apitman 19 hours ago| hidepastfavorite89 comments lakomen 11 minutes agoQuestion about this indie auth thing, or anonymous clients, mentioned at the linked page.Wouldn&#x27;t that effectively grant access to your user data to everyone, regardless of their intentions? Meta, for instance, has very strict TOS and privacy policy checks before approving a client_id. And those checks are on-going.https:&#x2F;&#x2F;aaronparecki.com&#x2F;2018&#x2F;07&#x2F;07&#x2F;7&#x2F;oauth-for-the-open-web reply jinnko 5 hours agoprevI recently came across Caddy Security[1], and while it&#x27;s not an OIDC IdP itself, it does serve as a good authentication gateway that&#x27;s easy to get up and running and maintain.1: https:&#x2F;&#x2F;authp.github.io&#x2F; reply __float 1 hour agoparentI&#x27;ve been using Caddy Security for personal use for a while now. I&#x27;d almost say it does too much, but you can turn almost everything off if you want. reply benkillin 17 hours agoprevThis looks like exactly what I was looking for.I was looking for turnkey AuthN&#x2F;AuthZ using OIDC for closed networks and self hosting, turnkey as in being able to drop a configured container in place and hit the ground running, and not being dex with keycloak. reply mooreds 5 minutes agoparentYou might want to take a look at FusionAuth (I&#x27;m an employee).It&#x27;s not open source, which may be a deal breaker for some, but it is \"free as in beer\". If you use the community edition and run it yourself, it is free for however many users you want. Also supports SAML (I know, I know, but when you need it you need it).https:&#x2F;&#x2F;fusionauth.io&#x2F;download reply apitman 17 hours agoparentprevIf you&#x27;re looking for something but more production ready, Authelia seems like a good option. Vouch and oauth2-proxy are even simpler but more specific in what they do. If you can provide more details of what you&#x27;re trying to accomplish I might be able to give more specific advice. reply TrickardRixx 11 hours agorootparentI&#x27;m looking for something that can federate identity, i.e. allow login with the @company microsoft identity provider, or support a users table, and ideally allows linking them. I just want to properly authenticate for internal tooling. reply bennyp101 3 hours agorootparentI&#x27;ve found https:&#x2F;&#x2F;zitadel.com&#x2F; to be a light weight version of keycloak.Lots of options that are useful, and pretty good UI for setting things up reply ffo 2 hours agorootparentZITADEL Co-Founder here.Thank you for the nice words you describe well what we try to achieve!With ZITADEL we aspire to become the best of Auth0 and Keycloak in more modern package. Or in other words are a end-to-end open source identity infrastructure. I know this sounds a little unspecific but our goals are:1) Have AuthN&#x2F;AuthZ, Login, SSO as Turnkey features but also allow people to build their own UIs2) Have an audit trail that allows people to see all changes ever made3) Give devs the ability to extend zitadel with custom code (actions)4) Support well given standards (OIDC&#x2F;Oauth&#x2F;SAML&#x2F;LDAP) with certification if possible5) Be ease to operate and scale6) Provide APIs for everything ;-)Btw. its always nice to see other projects to solve problems in the identity space. To me it feels like Obligator can, at the moment, be best compared to Dex since it feels a lot like a façade service that has little user management capabilities (not that this is a bad thing) but wraps them for easier usage in multiple services. But please take this observation with a lot of salt since I have not used or tinkered with Obligator.Cheers Florian reply snappysnap 11 hours agorootparentprevHow about KeyCloak? We use it for OIDC and it&#x27;s feature rich with support for private key signing and back channel logout.https:&#x2F;&#x2F;www.keycloak.org&#x2F;docs&#x2F;latest&#x2F;securing_apps&#x2F; reply lakomen 22 minutes agorootparentI use keycloak, but it&#x27;s Java and I need Go or better performance.With the new UI mass admin tasks are no longer possible. At least version upgrades are better now.Keycloak has no ed25519 support. Louketo proxy or whatever it&#x27;s called nowadays only supports RS256, so I had to write my own OIDC middleware. At least they stopped generating UUIDv4 secrets.Hydra is too complex.Dex is too simple.Identity Server lacks performance because C#.Zitadel, heard but not tried yet. The keycloak vs zitadel page doesn&#x27;t help. Is the Zitadel access token also jwt like in keycloak and included role membership?I use a Vue client specifically for Keycloak. The generic openid-connect-client is unmaintained. The TS fork doesn&#x27;t have a working, maintained, reactive implementation.Why does OIDC have to be so complicated? I know why... so you, like with k8s, trust external, paid for (expensively), companies with your work and data.The old \"make it complicated so people would rather pay for our services\".Remember the story about the oauth1 creator quitting the oauth2 project?https:&#x2F;&#x2F;www.wired.com&#x2F;2012&#x2F;07&#x2F;developer-quits-oauth-2-0-spec...Keycloak ed25519 issue https:&#x2F;&#x2F;github.com&#x2F;keycloak&#x2F;keycloak&#x2F;issues&#x2F;15714 reply cchance 11 hours agorootparentprevi think most people look at keycloak, and just feel overwhelmed, but that seems to be the case for OIDC in general, they always feel insanely heavy, something like this with a flatfile config and single file executable seems pretty amazing. reply TrickardRixx 8 hours agorootparentprevI always assumed you had to create&#x2F;manage user credentials inside KeyCloak. I&#x27;ll take a deeper look at the docs. reply RealStickman_ 10 hours agorootparentprevMaybe Authentik can do what you need? It supports all the various protocols as provider and consumer. reply TrickardRixx 8 hours agorootparentI&#x27;ll check it out, thanks for the recommendation. replykosinus 7 hours agoprevThis looks like it has the same core functionality as Portier? https:&#x2F;&#x2F;github.com&#x2F;portier&#x2F;portier-brokerI&#x27;m on mobile, so haven&#x27;t really checked where we differ in details. reply kekub 18 hours agoprevAmazing. I was looking for something like this about a year ago. Looks very promising and may be a good drop in replacement for some simple Auth0 use-cases as well as homelab setups. I was not able to get past „ redirect_uri must be on the same domain as client_id“. Maybe you can give an example of a valid client id for your demo instance. reply camsjams 17 hours agoparentI too found this hard to reason, but figured it out:If you&#x27;re demoing using https:&#x2F;&#x2F;openidconnect.net for example, set your Client ID to https:&#x2F;&#x2F;openidconnect.netLikewise, your ClientID should match the url of the website you are using this to connect with.This was mentioned in the GitHub readme too but didn&#x27;t click until trying the demo reply apitman 17 hours agoparentprevSorry, this is indeed not very clear. Others already answered well, but if you look at the example[0] config you can see how you would use your own instance of obligator as a client to the instance running at lastlogin.io. This is a bit meta, but applies equally to any client application.[0]: https:&#x2F;&#x2F;github.com&#x2F;anderspitman&#x2F;obligator#running-it reply jackson1442 18 hours agoparentprevAccording to the Readme, the client ID should be the domain of the client. So some site https:&#x2F;&#x2F;access.site.com would have the client ID https:&#x2F;&#x2F;access.site.com reply Wronnay 6 hours agoprevCool, but I looks like the creator didn&#x27;t really look deep in the competition. Many of the question marks in the comparison table can be replaced by a checkmark. reply langur 3 hours agoparentIndeed. It is slightly misleading at first glance. But the author has stated that it is incomplete. ZITADEL(https:&#x2F;&#x2F;zitadel.com&#x2F;), for example, pretty much checks almost all the boxes. reply BodyCulture 3 hours agorootparentWhich not? Thank you! reply langur 2 hours agorootparentZITADEL doesn&#x27;t support anonymous clients. Honestly, it&#x27;s not the best practice anyway.As for Forward Auth, the concept can be a bit fuzzy, and from what I gather, ZITADEL doesn&#x27;t really support that.Trusted Header Auth might work in some scenarios, but that definition is also a bit fuzzy, so hard to say for sure. reply throwaway67743 18 hours agoprevOhh, looks extremely promising, I&#x27;ve been after something with a bit more flexibility than Dex while not being Keycloak&#x2F;Java etc, an LDAP backend would be awesome as well though (another thing thats lacking is a simple ldap server, perhaps with sql as db, openldap is excessive and glauth isn&#x27;t there) reply bo0tzz 18 hours agoparentHave you had a look at Authentik? It might fit your needs. reply throwaway67743 17 hours agorootparentI think I did and when I couldn&#x27;t find useful installation details I gave up, I don&#x27;t use docker or kubernetes, so if projects can&#x27;t be bothered to make information available for a generic install, I immediately lose interest. reply jauntywundrkind 17 hours agorootparentI do plenty of native installs, and I find Docker based instructions to be a pretty nice universal codex for how things work.Docker entryscripts sometimes have significant magic baked in (alas), but quite often Docker is a distribution mechanism more than anything else. The Docker guides are - 9 times out of 10 - more than informative enough to show how to DIY in any other of the dozens if not hundreds of other system types you might have.If you want to resist using the easy thing, I personally think it behooves you to not bounce so quick. You don&#x27;t have to use it, and it&#x27;s good nearly universal documentation as to how to operate the thing. reply throwaway67743 16 hours agorootparentIt means I have to sit and read through the Dockerfile (or compose, in many cases, which is even worse) and figure out what its doing and what magic variables I need to provide etc, when just providing a binary download url and an example (or reference) config does just fine, not everyone uses docker reply BodyCulture 3 hours agorootparentprevapt install more easy and with auto updates safe! Docker too complicated, networking, security, dependencies, all messy after all these years.Apt rules! reply codegeek 15 hours agorootparentprev\"using the easy thing\"Easy != Simple. Not everyone wants to play around with Dockerfiles, docker compose and what not. Sometimes a plain binary is preferred. I say this as someone who likes docker for certain use cases but docker is not my solution for everything. reply rescbr 12 hours agoparentprevI’ve found running Samba as a Domain Controller pretty straightforward for this exact use case. reply BodyCulture 3 hours agorootparentAs userdb for keycloak? Please write about it! reply nitnelave 17 hours agoparentprevHave you had a look at LLDAP for a super simple LDAP backend with SQL behind? That or kanidm if you want OIDC built in. reply throwaway67743 10 hours agorootparentI hadn&#x27;t seen that, thanks! even has clear information on how to build natively and has a reference config reply XorNot 17 hours agoparentprevWhat&#x27;s wrong with glauth? I forked it so I could build in the &#x2F;etc&#x2F;passwd support and it&#x27;s been working great. reply grepfru_it 12 hours agorootparentLike raw &#x2F;etc&#x2F;passwd support or passwd support via PAM? Should always use PAM over reading passwd&#x2F;shadow directly reply throwaway67743 16 hours agorootparentprevI stand corrected, looks like its come a long way since I last checked - will have to give it another go reply stavros 17 hours agoprevCan someone explain which services this is supposed to be an IdP for? As far as I know, services need to have the OIDC service registered (ie I can&#x27;t just auth with this to Google or whatever). reply apitman 17 hours agoparentNot sure I&#x27;m reading your question correctly, but if you want to use obligator as an IdP for other apps&#x2F;services, they don&#x27;t need to be registered as long as they set the client_id properly. That&#x27;s the \"anonymous client\" auth described. However, in the simplest case you would have to verify any email addresses by having a confirmation email sent. To make this more streamlined, obligator can also act as an OIDC client for upstream OIDC providers such as Google, GitHub, etc. Once obligator has used an upstream provider to verify an email address, that address is treated exactly as if obligator had verified it itself. In this case you are correct in that registration is required with each upstream provider. reply stavros 17 hours agorootparentI don&#x27;t remember the OIDC flows very well, but basically my question was whether I can use Obligator as an OIDC provider and Google as the client.Ie can I log in to Google with Obligator? Or do I need to set up each client beforehand?I skimmed the related article but didn&#x27;t get it entirely, I&#x27;ll need to read it more thoroughly. reply apitman 17 hours agorootparentAhh that makes sense. And you are essentially correct. Generally speaking clients expect to be aware of who their IdP is, and currently Google&#x2F;Facebook&#x2F;Apple&#x2F;Microsoft have a stranglehold on the \"approved login IdP\", with a few dark horses like GitHub.The original vision of OpenID (ie pre-OpenID Connect) was for applications to support any IdP, and you just tell the app what your IdP is when you create your account. You could also imagine browsers filling this in automatically. This didn&#x27;t pan out in practice, primarily because no one used it[0].However, it&#x27;s becoming more realistic to run your own IdP, both by self-hosting and by using services such as Okta.Tailscale actually let&#x27;s you bring your own OIDC IdP. It uses WebFinger to prove an IdP has authority over a specific identity (email address). This is even more streamlined than entering your IdP directly. You just give Tailscale your email and they automatically send your to your IdP to authenticate.But I wouldn&#x27;t hold your breath for the major email providers to implement WebFinger so users can choose their own IdP. Which is one of many reasons I&#x27;m a big advocate of people using their own domain for email, even if the email itself is hosted by someone else (I use and love Fastmail).[0]: https:&#x2F;&#x2F;meta.stackexchange.com&#x2F;questions&#x2F;307647&#x2F;support-for-...[1]: https:&#x2F;&#x2F;tailscale.com&#x2F;kb&#x2F;1240&#x2F;sso-custom-oidc&#x2F; reply stavros 16 hours agorootparentThanks, this is very informative. I was really hoping OIDC+WebFinger would catch on, it was a more or less equivalent experience to Mozilla&#x27;s Persona, which I was a big fan of. reply apitman 16 hours agorootparentThank you for mentioning Persona. I sadly missed that train when it was a thing, but it&#x27;s always sounded cool. I think it&#x27;s basically what I want. Comparing to it in the docs would actually probably be a good way to explain the purpose of obligator. reply stavros 15 hours agorootparentPersona was the best way to do identity management. Using your email address to authenticate was genius, and it worked with any email provider that would accept your email address. Even if you self-hosted, with things like name_of_site@yourdomain.com, it would still work (unlike logging in with Google, where the site gets your main email address).I was so sad to see it die. replyMsurrow 17 hours agoparentprevThe readme links to another blog which explains the use case in more detail, but this quote sums it up I think “In a world where everyone&#x27;s own website is its own OAuth server, it&#x27;s obviously not practical to have an app developer register API keys at each.”So, I build some app for Wordpress sites and self-hosters want to use my app against their WP site that they also made into an IDP. Then we get the issue of the app needing to be (pre)registered with the IDP, and set client_id and client_secret in its config.Okay. I get that. But why on earth are we assuming that a self-hoster who can setup her own IDP cannot also create this app registration herself, and add a client_id&#x2F;secret to a configfile before starting my app? reply apitman 17 hours agorootparent> why on earth are we assuming that a self-hoster who can setup her own IDP cannot also create this app registration herself, and add a client_id&#x2F;secret to a configfile before starting my app?Excellent question, and it gets into the meat of why I made this in the first place. obligator is the first piece of the puzzle I&#x27;m trying to solve to make self-hosting as easy and secure as running an app on your phone. In that world users cannot be expected to pre-register OAuth2 applications. But above and beyond that, registration creates friction that I feel is unnecessary and doesn&#x27;t add enough additional security (and as mentioned can even reduce security when implemented poorly) for me to want to bother with it myself, so I built a server that doesn&#x27;t require it. reply camsjams 17 hours agoparentprevThis did indeed work for Google (that&#x27;s the only one I tried), but the details of how this works is best detailed in this post: https:&#x2F;&#x2F;aaronparecki.com&#x2F;2018&#x2F;07&#x2F;07&#x2F;7&#x2F;oauth-for-the-open-webThe above post was also linked from the obligator project&#x27;s GH readme reply omneity 17 hours agorootparentIndieAuth is super super cool and a vital component to get back control of the internet to users, but I can&#x27;t shake up the security concerns.Also, near the end of the article. Using a security nightmare such as Wordpress as your identity provider, what could go wrong? It only takes one single rogue plugin. reply dizhn 17 hours agoprevI am only familiar with authentik. When I look at the comparison table it&#x27;s super inaccurate for authentik. FYI. reply apitman 17 hours agoparentAuthentik is one of the ones I actually searched more closely through the docs, as it&#x27;s a popular choice for self-hosting. Can you point out specific inaccuracies so I can fix them?It&#x27;s tricky to figure out if some features are supported across different servers because the features have different names, and the more features a server has the harder it is to dig through. reply mynameisvlad 16 hours agorootparentSome I found:- I believe it does offer trusted header auth, although I haven’t used it for any of my apps to test out. https:&#x2F;&#x2F;goauthentik.io&#x2F;docs&#x2F;providers&#x2F;proxy&#x2F;custom_headers- It doesn’t offer “Passwordless email login”, but offers “passwordless login” in the form of passkeys (with a tiny bit of setup).- Definitely offers upstream OIDC, I have my instance set up to be able to sign in through AAD or locally. https:&#x2F;&#x2F;goauthentik.io&#x2F;integrations&#x2F;sources reply apitman 16 hours agorootparent> I believe it does offer trusted header auth, although I haven’t used it for any of my apps to test outFixed, thanks. Do you know if custom headers are returned when using forward auth, or only when Authentik is acting as a proxy?> It doesn’t offer “Passwordless email login”, but offers “passwordless login” in the form of passkeys (with a tiny bit of setup).In the case of obligator, email support specifically is important. Passkeys are really cool, but unless I&#x27;m mistaken there&#x27;s no way for me to say \"give the owner of this passkey access to this data\" even if they&#x27;ve never yet logged in to your system. This is a critical use case which works great with email, even having a built-in way to notify them of their new access. I would love to see passkeys extended with some sort of proof that the passkey is tied to a specific email address (or other global ID), so you can login without talking to an IdP but also get the benefits mentioned above.> Definitely offers upstream OIDC, I have my instance set up to be able to sign in through AAD or locallyAlready had that one. Were you maybe looking at Authelia? Though I believe I read somewhere that they are working on support too. reply Borealid 6 hours agorootparent> I would love to see passkeys extended with some sort of proof that the passkey is tied to a specific email address (or other global ID), so you can login without talking to an IdP but also get the benefits mentioned above.\"Passkeys\" (FIDO2 Authenticators) support this. The CTAP2.1 protocol contains \"enterprise attestation\", which allows an Authenticator to identify itself uniquely to a particular Relying Party.An explicit design goal of the FIDO standards is to prevent the server from knowing that two different FIDO credentials originated from the same Authenticator (in other words, treaing a new user as non-anonymous). In order to preserve that property, Authenticators need to be explicitly coded with the RPs for which they&#x27;ll support Enterprise Attestation.If you have such an authenticator, the server can say \"give the owner of a passkey presenting a valid Enterprise Attestation for bob@example.com access to this account\".But, again, FIDO isn&#x27;t supposed to let random web sites on the Internet notice that two \"different\" users are actually using the same passkey (tracking users between web sites!), so you can&#x27;t get the property you&#x27;re looking for without Enterprise Attestation. reply mynameisvlad 9 hours agorootparentprev> Already had that one. Were you maybe looking at Authelia? Though I believe I read somewhere that they are working on support too.Very well might’ve been, the mobile view of the table isn’t fantastic so it was quite a bit of scrolling; definitely could have messed that up.> In the case of obligator, email support specifically is important. Passkeys are really cool, but unless I&#x27;m mistaken there&#x27;s no way for me to say \"give the owner of this passkey access to this data\" even if they&#x27;ve never yet logged in to your system.No, the user would need to enroll it. They could use a social login (upstream OIDC) without logging in through customizations, you can pre-create their user or create it on demand and give it appropriate access based on the upstream response. I don’t think you could implement magic links, even as customizable as it is. reply dugite-code 15 hours agorootparentprevI&#x27;m fairly sure you can set custom headers with the forward auth (although I have never used it), you just have to configure it in the reverse proxy as well.I believe you could setup email login by using the email TOTP 2FA much like I use my yubikey for passwordless authentication. You can modify the flows quite extensively... if you know what you are doing reply dizhn 16 hours agorootparentprevI think I looked at the wrong column on mobile. While we&#x27;re here though. Authentik has basic multitenancy support. I wonder if that qualifies as multi domain auth. Sorry about the mistake by the way. reply I_am_tiberius 17 hours agoprevFor node.js there is node-oidc-provider. reply jupp0r 14 hours agoprevUsing email magic links as authentication mechanism is not a great choice in my opinion as email is not a very secure protocol if you think about the default smtp security guarantees and man-in-the-middle interception, either on the smtp or on the network level if servers communicate unencrypted. reply KRAKRISMOTT 14 hours agoparentIf you believe email to be the weakest link in the chain, then you have to get rid of email password resets too and use reset codes instead. Lose your codes, lose your account. reply apitman 14 hours agorootparentThis. As sad as it is, email is the defacto identity on the internet. Every system I&#x27;m aware of falls back on email and&#x2F;or phone numbers for recovery. reply xg15 8 hours agorootparentOn the surface yes. In practice, it&#x27;s more like email + whatever kind of security system your email provider has set up to verify its really you.I.e. try to log into a gmail account from a new machine in an unfamiliar location, even if you know the password and can receive SMS codes.So right now, I&#x27;m more worried about getting locked out of a mail account than that someone else could take it over.As for unencrypted SMPT, there is SMTPS [1]. I&#x27;m not sure if this seever supports it, but I&#x27;d assume it would be a basic requirement if you want to communicate with real-world mailboxes and not instantly flagged as spam.[1] https:&#x2F;&#x2F;de.m.wikipedia.org&#x2F;wiki&#x2F;SMTPS reply v2223943777435 12 hours agorootparentprevjust because email is often the defacto identity on the internet doesn&#x27;t make it a good idea (bandwagon fallacy). i don&#x27;t consider email tokens to be a serious form of authentication. unless you send the user their authentication secret with data encrypted by the user&#x27;s public key, i strongly recommend against any use of email-based authentication.* there are a huge number of middlemen in emailing that you have to trust. the sending email provider, the receiving email provider, ISP, email client, the device the client resides on. and everyone else in between. * unless you&#x27;re just hosting an email server on your local network, starting up an email server that can successfully get its messages across the internet to your intended recipient is an extremely high barrier.email is an extremely error-prone protocol. there&#x27;s lots of reasons that government&#x2F;health organizations don&#x27;t send you personal private information by email and instead send you an email that says to come log into their secure platform to view the private information. reply apitman 12 hours agorootparentThere are mitigations for these security issues. The most important is that you only email the user a random code which is bound to the browser login attempt session. The user is required to enter the code they received in that session. This removes the need to trust any of the parties you listed. reply v2223943777435 11 hours agorootparentyou still have to trust the client device. but i guess if someone else is there you&#x27;re screwed anyway.also, email has a potential for a big delay. a lot of times people need to log in quickly. email doesn&#x27;t always reach the destination in a timely manner. reply apitman 10 hours agorootparentThe UX challenges are real, no doubt about that. That&#x27;s actually one of the main reasons I started down the OIDC rabbit hole. I was using only passwordless email logins on my services, and wanted to provide my users with the UX of social login without forcing them to give up their privacy to ad companies. replybrazzledazzle 13 hours agorootparentprevWith these servers&#x2F;services you can usually chain to another identity source (e.g. ldap directory+kerberos) so that would fall to the origin identity service. But even if you don&#x27;t chain it the owner of OIDC provider will usually provide an administrator role and integration system accounts that can be used as an out of band sort of user account recovery mechanism. reply JambalayaJim 10 hours agorootparentprevThere is one difference here - email reset would lock the legitimate user out of the account, whereas email magic links would not. I think that&#x27;s an advantage for the former. reply Phrodo_00 13 hours agorootparentprevYou could let users use end to end encrypted protocols for it (like signal, telegram or supposedly whatsapp) reply apitman 10 hours agorootparentYes, and I hope we get there someday, but currently that&#x27;s a tiny fraction of users. reply Phrodo_00 10 hours agorootparentWhatsapp has like 3 billions users. Not exactly tiny. reply apitman 10 hours agorootparentHuh, I honestly didn&#x27;t know it was that big. Forgive my ignorance, I&#x27;ve never really used Whatsapp. Can you send a message to someone that hasn&#x27;t added you as a contact? If so I would seriously consider implementing this as an alternative to email.The main problem is that it&#x27;s not federated and completely under Facebook&#x27;s control. Also, identity based on WhatsApp is still vulnerable to simjacking, correct? reply Phrodo_00 9 hours agorootparent> The main problem is that it&#x27;s not federated and completely under Facebook&#x27;s control. Also, identity based on WhatsApp is still vulnerable to simjacking, correct?Yes to both replymoontear 9 hours agoprevI was going to comment „but I can already do a lot of that with Authelia and it is very simple to configure“, but then I found your very good comparison page - good comparison!I know the Authelia team is hard at working supporting some of the use cases that are currently not supported, so I will probably wait until some things are implemented there instead of switching. reply hkt 7 hours agoprevGenius. Not having to register is brilliant and I love it. I&#x27;ll be watching this project and using it. reply KronisLV 16 hours agoprevPersonally I went with Keycloak, because it&#x27;s fairly well documented and also has Docker images available: https:&#x2F;&#x2F;www.keycloak.org&#x2F;getting-started&#x2F;getting-started-doc... although the fact that they want you to create an \"optimized\" image yourself and have a long setup process on startup otherwise is slightly annoying: https:&#x2F;&#x2F;www.keycloak.org&#x2F;server&#x2F;containersRegardless, with something like mod_auth_openidc or another Relying Party implementation, all of the sudden authn&#x2F;authz becomes easier to manage (you can literally get user information including roles in headers that are passed from your gateway&#x2F;relying party to apps behind the reverse proxy), regardless of what you have actually running your APIs: https:&#x2F;&#x2F;github.com&#x2F;OpenIDC&#x2F;mod_auth_openidc (there are other options, of course, but I went with that because I already use mod_md).It&#x27;s actually cool that there are plentiful options in the space, since OIDC is pretty complex in of itself and attempts at creating something pleasant to actually use are always welcome, I&#x27;ve also heard good things about Authentik: https:&#x2F;&#x2F;goauthentik.io&#x2F; reply apitman 16 hours agoparent> since OIDC is pretty complex in of itselfObviously this is subjective, but I actually disagree somewhat. Once you get down to actually writing the code to implement OIDC, it&#x27;s rather simple. But I feel like the specs make it look pretty scary.I think the confusing part for me was understanding why some parts of it seemed to have so much song and dance (ie the three legged authorization code flow, PKCE, etc). I find the best way to understand the complexity is by having it explained in the context of what attacks are mitigated by specific steps. For that, documents like https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;draft-ietf-oauth-secur... are much more useful. reply Havoc 16 hours agoprevMust admit I&#x27;ve treated all my selfhosting like an coconut: Hard shell on the perimeter (firewall & wireguard)...but inside the home net its all just wide open. reply sisve 15 hours agoprevI was expecting hydra &#x2F; kratos to show up as an alternative.. but did not see any. Does any have any experience, good or bad about it?https:&#x2F;&#x2F;github.com&#x2F;ory&#x2F;kratos reply apitman 15 hours agoparentHydra is in the table, but you might have to scroll sideways to see it. That column also still needs to be filled out reply hatf0 11 hours agorootparentThe comparison with simply just Hydra is rather unfair too as the strength with Ory products is when they work in tandem (e.g. oathkeeper & hydra). Hydra is as barebones as you can get for a OAuth2 provider - that’s all it does & is meant to do. Stack it with Oathkeeper and you have a dynamic way of enforcing endpoint authentication that can entirely be managed using Kubernetes custom resources. Nothing I’ve found comes even close to touching the Ory stack in that regard. reply apitman 10 hours agorootparentThe Ory stack looks to be very high quality for sure. But so far in this thread there&#x27;s been mentioned Hydra, Kratos, and Oathkeeper in order to run an OIDC server. You say Hydra is as barebones as you can get, but by itself it has 58 direct dependencies. I&#x27;m sorry, it just seems to be targeted at a completely different demographic. reply AceJohnny2 14 hours agoprev> By forcing the user to decide whether they trust the actual domain where the ID token will be sent, and not displaying any sort of logo which can be faked, security is improved.Hilarious.Look, security UI is hard. Like, stumps experts hard. Like, they&#x27;ve been working at it for decades, trying to educate the population, hard.I appreciate the will and the effort (as someone looking for their goldilocks OIDC proxy,) but this claim is a bit strong. reply apitman 14 hours agoparentI agree the wording is too strong here. That said, did you read about the phishing exploit I linked in the readme? reply krantic 10 hours agoprevI could recommend https:&#x2F;&#x2F;github.com&#x2F;panva&#x2F;node-oidc-provider supports most of the oidc&#x2F;oauth 2 rabbit hole specs. reply salzig 16 hours agoprevReminds me of https:&#x2F;&#x2F;github.com&#x2F;dexidp&#x2F;dex reply Lammy 17 hours agoprev> opinionatedLove to see it reply throwawaaarrgh 16 hours agoparentHate to see it... reply BOOSTERHIDROGEN 7 hours agoprev [–] I&#x27;m using https:&#x2F;&#x2F;github.com&#x2F;thomseddon&#x2F;traefik-forward-auth for my selfhosted ? is it better in term of security, thanks. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Obligator\" is a project developing an OpenID Connect Provider (OP) server, designed for self-hosting with the specific goal to validate email ownership and communicate that to the application the user is accessing.",
      "This project supports features like anonymous OAuth2 clients, multi-domain authentication, passwordless email login and configurable runtime via an API.",
      "Currently, the project is in beta and not suitable for production usage until it has passed a security review."
    ],
    "commentSummary": [
      "The post is about Obligator, an OpenID Connect server tailor-made for self-hosting purposes.",
      "Discussions expand to include alternative authentication services like Zitadel, Authentik, and Keycloak, delving into their challenges and limitations, including issues with email and social login options.",
      "There is reference to Ory stack and others such as Hydra, Kratos, and Oathkeeper, with ongoing debates about their security measures and user interface aspects."
    ],
    "points": 241,
    "commentCount": 87,
    "retryCount": 0,
    "time": 1697050760
  },
  {
    "id": 37850485,
    "title": "Roll Your Own All-Sky, Raspberry Pi Camera",
    "originLink": "https://spectrum.ieee.org/all-sky-camera",
    "originBody": "IEEE.ORGIEEE XPLORE DIGITAL LIBRARYIEEE STANDARDSMORE SITES SIGN INJOIN IEEE FOR THE TECHNOLOGY INSIDER Search: Explore by topic Aerospace Artificial Intelligence Biomedical Climate Tech Computing Consumer Electronics Energy History of Technology Robotics Semiconductors Telecommunications Transportation IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy. VIEW PRIVACY POLICY ACCEPT & CLOSE DIY ARTICLE Roll Your Own All-Sky, Raspberry Pi Camera Use Raspberry Pi hardware to capture mesmerizing time-lapse images of the heavens DAVID SCHNEIDER28 JUN 20235 MIN READ A homebrew all-sky camera can capture mesmerizing views of the night sky. JAMES PROVOST ALLSKY CAMERAMETEORMETEORITEMETEORS While driving home one night recently, I saw a spectacularly bright meteor flash across the sky in front of my car. A good-sized chunk of interplanetary detritus must have been on its way to a crash landing not too far away, I said to myself. My next thought was that if I had a bearing on that luminous streak, and if at least one other person in my region also had such information, we might be able to triangulate on it and narrow down where any landing zone might be. I’m, of course, not the only one to ponder this possibility—and, I soon learned, people have indeed successfully found meteorites this way. One example occurred in 2012, when a fireball lit up the sky over Northern California. Images of the meteor were recorded by a project called CAMS ( Cameras for Allsky Meteor Surveillance)—a project of NASA and the SETI Institute. These observations allowed the object’s trajectory and landing zone to be estimated, and coverage of the event in TheSan Francisco Chronicle soon led to the discovery of what became known as the Novato Meteorite. CAMS is not the only such project looking for meteors. Another is the Global Meteor Network, whose mission is to observe the night sky with “a global science-grade instrument.” Organizers of this network even provide guidance for how anyone can build a suitable camera based on the Raspberry Pi and how to contribute observations that can help determine the orbits of the parent asteroids that spawned particular meteors. I was tempted to join the cause, but after reading more on the subject I discovered alternative strategies for building a camera to survey the night sky. Ultimately, I decided that I wanted to capture attractive color images more than I wanted to contribute data to the Global Meteor Network, which uses black-and-white cameras because of their greater sensitivity. The required components include a Raspberry Pi microcomputer (case not shown), a Raspberry Pi High Quality camera, a lens, a dome-shaped transparent lens cover, a 5-volt power supply, and a waterproof bulkhead connector, allowing AC-mains power to pass through the wall of the waterproof enclosure (not shown) holding the camra.JAMES PROVOST So I opted to build a different kind of all-sky camera, one that is also based on a Raspberry Pi but that uses the Raspberry Pi High Quality color camera, following the lead of a project called, reasonably enough, Allsky Camera. The hardware for this project consists of a Raspberry Pi and either the Raspberry Pi HQ camera or one of the purpose-built planetary cameras made by ZWO. To be truly “all sky,” the camera should be equipped with a fish-eye lens having a 180-degree field of view. Recognizing that my home is surrounded by trees, I opted for a lens with a narrower (120-degree) field of view. A modern Raspberry Pi 4 is recommended, but I used a several-year-old Raspberry Pi 3 Model B simply because I had it on hand. I decided to use a US $60 Raspberry Pi HQ camera over a ZWO camera because it offered higher resolution. To protect this hardware from the elements, I housed the Pi, camera, and a suitable wall wart for powering the Pi inside a $25 waterproof plastic enclosure. The opening I cut for the camera lens is covered with a $16 clear acrylic dome. The first dome I purchased distorted things, but I ordered another one that worked out much better. I also purchased an $11 case for the Raspberry Pi (one that included a fan) and a long extension cord, which I cut and connected to a waterproof bulkhead connector. This means I can leave the unit outside even when it rains. Following the guidance provided in a very nice tutorial video, I found it straightforward to set up the Allsky Camera software on my Pi, running it in a “headless” configuration—meaning without a monitor or keyboard. I access it wirelessly from a laptop through my local area network using SSH. A meteor’s trajectory through the atmosphere can hold clues to the location of any part of it that survives and also reveals the orbit of the parent body around the sun. With images of the meteor trail captured by two cameras, that trajectory can be ascertained: The position of a glowing trail relative to the background stars in an image defines a plane, and the intersection of two planes defines the trajectory.JAMES PROVOST I fired everything up—but the camera didn’t work at all. So I turned to the appropriate troubleshooting section in the project’s ample documentation and tried what was advised there—to enable “Glamor” graphic acceleration on the Pi. Still no images, though. Eventually, I discovered some tweaks to a configuration file that are needed when using the HQ camera on a Pi 3B, which allowed me to obtain a hopelessly blurry image of the ceiling of my office. Through trial and error, I was able to get the manual focus of the camera dialed in properly. And slowly I learned how to adjust the multitude of settings available in the Allsky Camera software, which is done either by editing a configuration file or, more conveniently, through a Web interface this software provides. For example, I learned that I should reduce the resolution of the images used to make time-lapse videos, lest images saved at the impressive native resolution of the HQ camera (4,056 by 3,040 pixels) overwhelm the processing and storage available on my Pi. While that required tweaking a configuration file, other settings can be adjusted using the Web interface, which also makes it very easy to view live images, browse images collected earlier, and view and save time-lapse videos. This timelapse video shows the night sky giving way to the rosy-fingered dawn, as captured by this all-sky camera.SPECTRUM STAFF One thing that puzzled me early on was how well such a camera would work to catch meteors flashing by, given that the camera takes still images, not many-frames-per-second videos. But my concerns diminished after capturing images of the night sky over my home, some of which caught the light of passing aircraft. The long trails of light in those images made it apparent that the exposure time must be at least some tens of seconds long. I knew these were aircraft, not meteor trails, because the streaks included parallel tracks (from wingtip lights) and obvious pulsations from strobes. I hope yet to capture meteors some day with this gizmo. For that, I may go camping in the mountains in mid-August, when the Perseids are hitting their peak. My family and I had taken such a trip years ago, but I didn’t have an all-sky camera at the time. So I returned home with only some now-fading memories of the wonderous show nature had put on display above our heads. Next time, I’ll have something I can view over and over! FROM YOUR SITE ARTICLES Detect Solar Flares and Gamma-Ray Bursts for Less Than $100 › Track the Movement of the Milky Way With This DIY Radio Telescope › DIY Exoplanet Detector › The Marimba Virtuoso’s Desktop Planetarium - IEEE Spectrum › RELATED ARTICLES AROUND THE WEB A Raspberry Pi operated Wireless Allsky Camera › Oculus - Starlight Xpress Ltd › All Sky CamerasAstrophotography CamerasOPT › David Schneider is a senior editor at IEEE Spectrum. See full bio → PUBLISH SORT BY Newest Oldest Popular TELECOMMUNICATIONS NEWS Space 5G Changes Course 19 MINUTES AGO3 MIN READ SEMICONDUCTORS NEWS 2D Transistors, 3D Chips, and More Mad Stuff 22 HOURS AGO5 MIN READ TRANSPORTATION NEWS Where Are All the Solar-Powered Cars? 11 OCT 20233 MIN READ Related Stories HISTORY OF TECHNOLOGY ARTICLE The Marimba Virtuoso’s Desktop Planetarium HISTORY OF TECHNOLOGY ARTICLE Taking the Measure of the Earthquake That Destroyed Tokyo ARTIFICIAL INTELLIGENCE INTERVIEW Why Today’s Chatbots Are Weird, Argumentative, and Wrong",
    "commentLink": "https://news.ycombinator.com/item?id=37850485",
    "commentBody": "Roll Your Own All-Sky, Raspberry Pi CameraHacker NewspastloginRoll Your Own All-Sky, Raspberry Pi Camera (ieee.org) 239 points by sundarurfriend 17 hours ago| hidepastfavorite48 comments jws 13 hours agoHaving done this…- don’t make your camera the highest thing around. My dome was showing scratches. Eventually I got a nice photo of the inside of a juvenile bald eagle’s talon. A bird’s gonna perch where a bird’s gonna perch. Sacrifice some sky and put a better perch next to it.- the manual focus cameras seem to be temperature dependent. Maybe get something that can be auto focused or add a heater to control night time lows.- for long exposure low light work, you may find you get much better pictures in very cold weather. This relates to charge leakage in the sensor. If you decide to try keeping your sensor cold, consider condensation. Maybe have something in there that is colder.- also for long exposures, the noise in the image from leakage tends to be device pixel specific. You can make a dark view map at a given temperature and use it to denoise your images. You’ll need a shutter though, or do something clever with multiple frames as stars move around to get “darkest sample” or something reply dylan604 11 hours agoparentI&#x27;ve definitely run into the long exposure heat issues. In my hemisphere, the central part of the Milky Way is best viewed during the summer. In my local part of the hemisphere, its ridiculously hot at that time. Even 20s exposures will be noisy. I have a smaller pelican case that I&#x27;ve punched a hole in for the lens to sit outside the case, and then rigged a bunch of those reusable freezer packs for coolers inside. Then covid happened, and I now no longer have a car. To this day, I haven&#x27;t taken it anywhere to test it out. Now, I&#x27;m really sad that I just realized how long it&#x27;s actually been since I&#x27;ve imaged the sky.reply tecleandor 1 hour agoparentprevRegardiing condensation, if you can make the case kind of air tight, maybe you can either fill it with nitrogen, make a light vacuum, or pre-dry the air inside (I remember some tricks to avoid condensation in underwater cameras that consisted in storing it open in the fridge for some hours or something like that, to have drier air inside, I&#x27;ll look for that again...) reply Yhippa 11 hours agoparentprevDo you have your pictures or videos posted anywhere? Trying to decide if the juice is worth the squeeze. reply destitude 1 hour agoparentprevI&#x27;ve had zero issues with ZWO cameras that have a manual focus lens attached to it and have had air temps from 95F to -45F. reply fludlight 11 hours agoparentprev> Maybe have something in there that is colderSuch as? reply andruby 3 hours agorootparentthere are astro specific cameras with a cooler. Peltier + heatsink. reply car 8 hours agorootparentprevPeltier element reply Renaud 8 hours agorootparentprevI would guess a Pelletier element? reply smilespray 11 hours agorootparentprevJohn Riccitiello&#x27;s heart? reply gmiller123456 12 hours agoprevThe Pi cameras might seem like a good choice because they&#x27;re cheap, and might be a good way to start. But with all of the work required to build, install, and maintain one, the cost of the camera is a drop in the bucket. I used a much better camera from ZWO (ASI462MC) for about $300 (I actually ended up building a second one with the ASI462MM (monochrome)). It even comes with an all sky lens. IMHO it doesn&#x27;t make a lot of sense to cheap out on the camera with all the effort involved in building one. I also needed to add a short length of Nichrome wire (1amp at 12v) to fight condensation.I started with the color camera, but had to give up on any real meteor detection due to the amount of light pollution, and the fact that I live directly in line with the airport in Louisville. I built the second monochrome version, since the monochrome versions are roughly 3x as sensitive, hoping it&#x27;d be better at detecting meteors at shorter exposure lengths. But it still required exposures of a few seconds, much longer that you&#x27;re typical meteor. So, now I just have two all sky cameras doing 20 second exposures. The monochrome one will still pull out the Milky Way from my Bortle 7&#x2F;8 skies, so I just like the pictures it takes and don&#x27;t plan to change it. reply bloopernova 1 hour agoparentI&#x27;m definitely late to this thread, but I wanted to ask: do you know how much of the world is covered by sky cameras? I was just envisioning a google maps kind of interface where you could grab shots from people who share their images. reply malfist 3 hours agoparentprevYou&#x27;re doing astophotography is Louisville? I&#x27;m doing it in Lexington! We should chat reply tivert 9 minutes agoprevIt would be neat if someone wrote the software to turn something that into an astro-navigation device like https:&#x2F;&#x2F;airandspace.si.edu&#x2F;collection-objects&#x2F;sr-71-astroine.... reply destitude 1 hour agoprevhttps:&#x2F;&#x2F;github.com&#x2F;aaronwmorris&#x2F;indi-allsky is far superior all sky software. Also supports basically running the software on any linux based system not just a pi. Have mine running on an odroid. reply adolph 9 minutes agoprevMy next thought was that if I had a bearing on that luminous streak, and if at least one other person in my region also had such information, we might be able to triangulate on it and narrow down where any landing zone might be.It seems like deploying these in pairs at a minimum would make sense. In addition to adding spatial information, it gives you a backup for any observations at all.The illustrations are great. Reminded me of how the storage disk from the starhinge in Stephenson&#x27;s Anathem must have looked. reply gpt5 8 hours agoprevAnyone knows how did they make the beautiful diagrams? reply interloxia 5 hours agoparentThe images are credited to James Provost, a technical illustrator.https:&#x2F;&#x2F;jamesprovost.com&#x2F;He has a bunch of interviews at https:&#x2F;&#x2F;technicalillustrators.org&#x2F; (which he co-founded) but I didn&#x27;t find an interview of him.On his blog in 2014 he notes in passing some of the tools he uses. https:&#x2F;&#x2F;jamesprovost.com&#x2F;blog&#x2F;surface-pro-3-for-illustrators reply asynchronous 8 hours agoparentprevThis, diagrams and imagery were top notch. reply omneity 5 hours agoprevSlightly off-topic, but did anyone ever run a sky camera with a vision model that recognize what it sees?Like Meta’s SAM. reply teamonkey 3 hours agoparentPlate solving - identifying constellations and deep sky objects by the relative positions of stars - is a pretty common part of astronomy software and possible on a raspberry pi. For example https:&#x2F;&#x2F;github.com&#x2F;dstndstn&#x2F;astrometry.netI&#x27;m not aware of anything that can, say, identify a meteor and differentiate it from a plane or satellite, but I&#x27;m sure it&#x27;s possible. reply dheera 7 hours agoprevI really wish RPi would come out with a truly HQ camera.Their \"HQ\" camera is really a LOW quality camera with a shitty sensor that isn&#x27;t even micro-four-thirds. The lens choices are abysmal. I want to see at LEAST APS-C or better yet full frame. Considering a full-blown mirrorless full frame camera costs $2400 it shouldn&#x27;t cost more than $1000 for sensor only, and I&#x27;m 1000% willing to pay for a hackable, programmable full frame sensor especially for night sky photography that can accept the vast variety of full frame lenses already available.There&#x27;s the Sony QX1 which comes close to what I want but sadly they didn&#x27;t continue that or produce them anymore. reply justin66 1 hour agoparentHave the Raspberry Pi people done anything even similar to the release of a $1000 part? It doesn&#x27;t really seem up their alley. reply teamonkey 3 hours agoparentprevI do think the HQ camera is due an upgrade, though I&#x27;d prefer a proper low-light camera, ideally Sony Starvis.Although you can buy cheap Starvis modules you don&#x27;t have full control over the exposure time and&#x2F;or can only shoot in a compressed format. The HQ camera is well-supported with good drivers, like all Raspberry Pi hardware, which is why people still use the HQ Camera for cheap astronomy projects despite having a small sensor and poor low-light performance. reply Tepix 5 hours agoparentprevThe camera is good for its price. If you want a MFT sensor, why don&#x27;t you use something like a Lumix G9 and connect it to the RPi via USB? It&#x27;s a lot less than $1000 these days. reply aiunboxed 14 hours agoprevHow does your image &#x2F; video processing pipeline look like ? reply malfist 16 hours agoprevI&#x27;ve been in the process of planning a backyard observatory some and have been looking at all sky cameras to measure clouds, seeing and sky glow.This project looks really promising, especially if it has an ascom driver reply destitude 1 hour agoparenthttps:&#x2F;&#x2F;github.com&#x2F;aaronwmorris&#x2F;indi-allsky has INDI drivers. reply teamonkey 3 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;IanCassTwo&#x2F;rpicam-ascom-alpaca reply porphyra 15 hours agoprevHow do you prevent the sun from damaging the sensor over time? reply gmiller123456 10 hours agoparentI have had an all sky camera out for about two years now without issue, also never heard of anyone having an issue. The first I&#x27;ve heard is the comment above about using a spotting scope, which would have a much larger objective than a typical all sky camera, and sounds like the Bayer array (the filter for color imaging) was damaged. I imagine most sensor manufacturers know their sensors will get pointed at the Sun and some point, and are designed to account for it. Especially since pictures of Sunsets&#x2F;Sunrises are pretty popular.The Sun is actually pretty small (1&#x2F;2 a degree), and the image of the Sun will only occupy a given pixel for about 2 minutes. The next day, the declination of the Sun will change, there may be some overlap in the pixels it falls on. But over the course of a year, the amount of time a given pixel will see the actual image of the sun is pretty short, likely less than 10 minutes for the worst case near the solstice. And the pixels getting it near the equinox will probably only get hit for 4 minutes a year, and some not at all. So they&#x27;re not really taking the beating it may seem. reply destitude 1 hour agoparentprevMine has been going on 4 years now with zero issues with the camera (ZWO 178MC). The acrylic domes however are a hot mess. Frequently have to replace them. Really need to find high quality glass domes preferably with anti-reflective coating. reply mathgaron 2 hours agoparentprevI helped build a similar setup a \"long\" time ago to build a sky HDR database. We had over 40k images across hundreds of days. The longer exposures definitely did not help (even with a ND filter) and by the end the camera had some broken pixels along the sun trail. Nothing noticeable visually, but likely not good for computer vision purpose. If we were to redo this it would be definitely a valid concern to address. reply wkat4242 14 hours agoparentprevI&#x27;ve had a pi 1 camera looking out at the horizon for many years and it didn&#x27;t really get damaged.Don&#x27;t forget the default lens is tiny. It doesn&#x27;t really capture a ton of light. reply jws 13 hours agorootparentI had one pointed east at the horizon the show a lighthouse a mile away using an old spotting scope. Worked ok until the sun made its way around to rise in frame. Now everything is greenish. I think with sufficient magnification you can cook your color filters or maybe the sensor wells under the filters. reply TheSpiceIsLife 13 hours agorootparentprevIf you know the diameter of the lens, and your areas insolation, you could work out it&#x27;s annual solar energy exposure in watts yeah. reply ShadowBanThis01 16 hours agoprev [–] Is there a MIPI camera that doesn&#x27;t suck?I have every official Pi camera, and they are all just terrible. I would never use them for anything artistic, when it&#x27;s easy to get far-superior results from even a cheap regular camera or used SLR.I&#x27;m just curious if there&#x27;s a very-high-quality camera with a MIPI interface. Thinking it through... I only really care about video. Even if it&#x27;s only HD resolution, something with excellent light sensitivity & low noise would be great. reply Roark66 9 hours agoparent>Is there a MIPI camera that doesn&#x27;t suck?No there isn&#x27;t. Sorry. I&#x27;ve tried them all and their dynamic range sucks so bad....Anyway, who thinks otherwise, I recommend you see the same non-ideally lit scene with for example a modern \"analog\" fpv camera like Foxeer Nano Toothless 2 (a starlight 0.1lux camera that maintains it&#x27;s great dynamic range in full sun).The only mipi camera that has a shred of a chance to compete is starvis IMX327LQR. On paper it should be pretty good. I&#x27;m planning to test one at some point.Also, the cameras built into various Cctv Ip cameras one can buy from China are pretty good, but good luck getting them to work with anything other than the original equipment. reply ShadowBanThis01 7 hours agorootparentHa, thanks for the reply.Tangent to your IP-camera comment: I replaced all my old SD, composite household security cameras with cheap-O TVI cameras, and I am impressed at how well this oddball HD format works over the same coax cables. reply casylum 14 hours agoparentprevOften it&#x27;s the lens that results in poor quality images. You can get a RPi sensor with CS mount and add your own lens of your choosing. It&#x27;s been a huge upgrade in quality and is relatively easy to do. reply JKCalhoun 14 hours agorootparentThere is also a lot of \"secret sauce\" that Apple and others do to the raw image data that comes off the sensor. I don&#x27;t doubt much better quality could be eked out of the RPi cameras if there was a determined effort to do so. reply teamonkey 3 hours agoparentprevFor light sensitivity there&#x27;s an Arducam IMX482 MIPI module. Unfortunately you don&#x27;t have a lot of control over it and can&#x27;t take long exposures, but it&#x27;s probably fine for HD video. Every other cheap low-light module I&#x27;ve seen is hobbled in some crucial way, either at the hardware level or drivers. reply blacksmith_tb 15 hours agoparentprevThere are some pretty fancy-looking industrial cameras that support MIPI, like the Alvium line[1] - but I suspect they are spendy...1: https:&#x2F;&#x2F;www.alliedvision.com&#x2F;en&#x2F;products&#x2F;camera-series&#x2F;alviu... reply ShadowBanThis01 15 hours agorootparentThanks. I guess at some point the value proposition is antithetical to that of the Pi itself... reply geerlingguy 14 hours agorootparentYeah the problem is optics (the more important part of getting really good images) are expensive, and few companies make decent lenses that target tiny sensors.So you&#x27;re stuck with the little optics included with the tiny hobby cameras from Pi or ArduCam (et all). They&#x27;re okay for some purposes but a lot worse than even a cheap SLR&#x2F;Mirrorless lens.The best results I&#x27;ve gotten are with the C-mount camera module, an adapter, and a wide angle Sony, Nikon, or Canon lens—all of which cost in the hundreds :) reply ShadowBanThis01 13 hours agorootparentI have the C-mount module and a Canon security-camera lens with zoom, focus, and aperture settings. Disappointingly, it still sucks.I know there are excellent C-mount lenses, because I shot a great-looking movie on a Bolex with them. reply giantrobot 14 hours agorootparentprevThrift&#x2F;antique stores are a place to look for old lenses on the cheap. If you&#x27;ve got a C-mount adapter for your sensor you can mount the lens on it. Then you can manually focus it and epoxy it on the right point. reply wkat4242 14 hours agoparentprev [–] They suck at video. Take stills and they do a lot better. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article outlines how to create a Do-It-Yourself (DIY) all-sky camera using Raspberry Pi, a series of small and affordable computers that are widely used in tech projects.",
      "The homemade camera is purposed to capture images of the entire night sky, specifically meteors, and can aid in scientific studies regarding meteor trajectories.",
      "It provides an in-depth guide on the components necessary and the procedure for setting up the camera and also features other similar projects using such cameras for meteor study."
    ],
    "commentSummary": [
      "The article delves into the experience and advice from users utilizing Raspberry Pi cameras for all-sky photography, addressing typical concerns such as camera dome scratches, temperature impact on manual focus cameras, and leveraging cold weather for better long-exposure photographs.",
      "Readers express a longing for high-quality cameras from Raspberry Pi, discussing specifics like exposure time, sensor size, low-light performance, potential sun damage, and primarily the limitations and quality of the Raspberry Pi HQ Camera in astronomy and similar projects.",
      "The conversation acknowledges the limitations of MIPI cameras and emphasizes the crucial role of optics for high-quality imagery; some users recommend alternative cameras with superior quality and light sensitivity."
    ],
    "points": 238,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1697059735
  },
  {
    "id": 37846387,
    "title": "M2 Ultra can run 128 streams of Llama 2 7B in parallel",
    "originLink": "https://github.com/ggerganov/llama.cpp/pull/3228",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up ggerganov / llama.cpp Public Notifications Fork 5.9k Star 42.2k Code Issues 518 Pull requests 98 Discussions Actions Projects 4 Wiki Security Insights New issue llama : custom attention mask + parallel decoding + no context swaps #3228 Merged ggerganov merged 57 commits into master from custom-attention-mask +2,687 −660 Conversation 41 Commits 57 Checks 34 Files changed 35 Conversation Owner ggerganov commented • edited close: #2060 #2813 ref: #3137 Merge ETA: ~ 27 - 30 Sep Here we will attempt to add batched (a.k.a. parallel, multi-sequence) decoding to llama.cpp. For a short summary of the plan, see #3137 (comment) Features: parallel decoding with common prompt parallel decoding with separate prompts parallel decoding with continuous batching tree-based parallel decoding avoided the slow context swaps when the context becomes full API changes: add batch API: add struct llama_batch add llama_batch_init add llama_batch_free add temporary helper llama_batch_get_one for easy API migration deprecate llama_get_kv_cache_token_count add KV cache management API: llama_kv_cache_tokens_rm llama_kv_cache_seq_rm llama_kv_cache_seq_cp llama_kv_cache_seq_keep llama_kv_cache_seq_shift update decoding API: deprecate llama_eval and llama_eval_embd add llama_decode add llama_get_logits_ith Demo No context swaps Previously, we had to re-evaluate the context when it becomes full and this could take a lot of time, especially on the CPU. Now, this is avoided by correctly updating the KV cache on-the-fly: # run on the CPU using a small context of 256 tokens ./main -m ./models/llama-7b/ggml-model-q4_0.gguf -p \"I believe the meaning of life is\" --ignore-eos -c 256 -n -1 -t 8 -ngl 0 Parallel decoding - basic example examples/batched The batched example has been extended with an argument to specify the number of sequences to generate using the given prompt. This is a good starting point for understanding the new llama_batch API introduced in this PR. # the prompt is \"Hello my name is\" and the number of sequences that will be generated is 8 ./batched ./models/llama-7b-v2/ggml-model-f16.gguf \"Hello my name is\" 8 Generated results Parallel decoding - server simulation examples/parallel Decoding 32 parallel streams for a total of 128 sequences with continuous batching in about ~26s. Token summary: System: 305 (encoded once at the start) Prompt: 2039 (summed over all inputs) Decoded: 7986 (summed over all sequences) Using 7B LLaMA v2 Q8_0 model on single RTX 4080 with 16GB VRAM. ./bin/parallel -m ../models/llama-7b-v2/ggml-model-q8_0.gguf -n 128 -t 1 -ngl 100 -c 8192 -b 512 -s 1 -np 32 -ns 128 -cb parallel-cuda-1-lq.mp4 For comparison, generating the same amount of sequences using a single stream (i.e. -np 1) takes ~125s on the same hardware with the same model. When using the parallel example, you must make sure that your KV cache will have enough size to fit all parallel requests. If it is not able to fit them, then you will start seeing cache misses that slow down the processing significantly and can eventually fail the decoding if there is no more space in the cache. To set the KV cache size, use the -c, --context parameter. For example, for 32 parallel streams that are expected to generate a maximum of 128 tokens each (i.e. -n 128), you would need to set -c 4096 (i.e. 32*128). If continuous batching is enabled, you would need some extra KV space to deal with fragmentation of the cache. In the example above, we conveniently set the context size to 8192 to guarantee that there will be no issues. Also, when computing the KV cache size you should also take into account the size of the system prompt (if any). We can run a similar test on M2 Ultra. This time, since we have practically infinite VRAM, we can afford to run 128 parallel streams instead of just 32. And we can also use the F16 model instead of the quantum Q8_0. In this case, continuous batching is not needed, since we will be processing all of the 128 requests at once: ./bin/parallel -m ../models/llama-7b-v2/ggml-model-f16.gguf -n 128 -t 1 -ngl 100 -c 16384 -b 512 -s 1 -np 128 -ns 128 parallel-ultra-0-speed-up-x2.mp4 (video is speed-up to fit in Github 10MB limit) Implementation details KV cache as ring-buffer This is one of the major changes. Previously, the n_past number indicated what part of the KV cache to use in the computation. The assumption was that all cached data would be stored in the cache starting from the first cell forward and that this data belongs to one sequence only. We now want to store information from multiple sequences in the KV cache and the data from each sequence can be located in arbitrary cells. To achieve that, the KV cache now stores information about the sequences to which the cache data belongs and the corresponding position in these sequences: llama.cpp/llama.cpp Lines 1009 to 1018 in b377bf2 struct llama_kv_cell { llama_pos pos = -1; llama_pos delta = 0; std::set seq_id; bool has_seq_id(const llama_seq_id & id) const { return seq_id.find(id) != seq_id.end(); } }; With this change, we now have to attend to the entire cache when computing the self attention, because we don't know where the data for the sequences being processed is located. So the naive solution is when we build the graph to set n_kv = n_ctx. However, there is a simple heuristic that can be introduced in order to restore to most extend the behavior of n_past where we attend to just the first part of the cache: llama.cpp/llama.cpp Lines 2620 to 2624 in b377bf2 const int32_t n_tokens = batch.n_tokens; const int32_t n_kv = ggml_allocr_is_measure(lctx.alloc) ? n_ctx : kv_self.n; const int32_t kv_head = ggml_allocr_is_measure(lctx.alloc) ? n_ctx - n_tokens : kv_self.head; Here, kv_self.n contains the index of the last \"occupied\" cell in the cache. I.e. we know that all cells beyond kv_self.n are currently empty, so no need to attend to them. We naively compute it each time we build a graph: llama.cpp/llama.cpp Lines 4101 to 4107 in b377bf2 // a heuristic, to avoid attending the full cache if it is not yet utilized // after enough generations, the benefit from this heuristic disappears // if we start defragmenting the cache, the benefit from this will be more important //kv_self.n = std::max(32, GGML_PAD(llama_kv_cache_cell_max(kv_self), 32)); // TODO: this might be better for CUDA? kv_self.n = std::max(32, llama_kv_cache_cell_max(kv_self)); This heuristic is easy to implement and gives a measurable improvement, allowing to keep the performance the same as on master for single-sequence generations. It stops having any effect once the KV cache has been filled. In theory, we can improve this even further by computing n_kv_0 and n_kv_1 - the KV range that contains the cached tokens for all currently decoded sequences. We just need to find an elegant way to incorporate this information in the KV view offsets. (i.e. n_kv = n_kv_1 - n_kv_0, etc.). Workplan verify that RoPE is \"additive\" (tests/test-rope.cpp) update ggml_rope to take a tensor with positions instead of just n_past CPU Metal add rope_f16 kernel CUDA update rope_f32 kernel to work with vector of positions add rope_f16 kernel (needed for K-cache shifts) use ggml_add for applying a custom -INF mask to a tensor instead of the existing ggml_diag_mask_inf CPU Metal kernel add support broadcast across dims 1,2,3 CUDA update the graph to utilize the new ggml API for RoPE and mask extend the KV cache to store position and sequence ID information extend llama.h API for passing multi-sequence data add llama_kv_shift() for \"forgetting\" old tokens, re-roping (if needed) the KV cache and compressing it add example for generating N completions in parallel for a given prompt TODOs fix MPI will remain for a future PR deprecate ggml_alibi(), replace with ggml_add() (similar to ggml_diag_mask_inf, Baichuan 13B) fix KV cache fragmentation with continuous batching Performance I decided to disable the concurrency optimization since it prevents from modifying the graph topology. With the changes in this PR, we now need to sometimes add extra nodes for K-cache shift, so it is no longer compatible. The result is ~8% slower prompt processing but ~5% faster text generations with Metal. M2 Ultra model size th test master t/s PR t/s speedup LLaMA 7B mostly F16 12.55 GiB 4 pp 512 1490.37 ± 1.29 1381.20 ± 1.64 0.927 LLaMA 7B mostly Q8_0 6.67 GiB 4 pp 512 1326.17 ± 0.49 1231.50 ± 0.99 0.929 LLaMA 7B mostly Q4_0 3.56 GiB 4 pp 512 1355.75 ± 0.30 1258.24 ± 0.77 0.928 LLaMA 7B mostly Q4_1 3.95 GiB 4 pp 512 1351.95 ± 0.58 1256.14 ± 0.97 0.929 LLaMA 7B mostly Q6_K 5.15 GiB 4 pp 512 1106.49 ± 0.45 1033.03 ± 0.82 0.934 LLaMA 7B mostly Q5_K - Medium 4.45 GiB 4 pp 512 1103.09 ± 0.65 1028.90 ± 1.40 0.933 LLaMA 7B mostly Q5_K - Small 4.33 GiB 4 pp 512 1102.25 ± 0.33 1027.88 ± 0.83 0.933 LLaMA 7B mostly Q4_K - Medium 3.80 GiB 4 pp 512 1168.98 ± 0.60 1089.69 ± 1.08 0.932 LLaMA 7B mostly Q4_K - Small 3.59 GiB 4 pp 512 1178.79 ± 0.72 1097.91 ± 0.56 0.931 LLaMA 7B mostly Q3_K - Medium 3.07 GiB 4 pp 512 1142.54 ± 0.65 1064.15 ± 0.39 0.931 LLaMA 7B mostly Q3_K - Small 2.75 GiB 4 pp 512 1119.60 ± 0.62 1044.46 ± 0.53 0.933 LLaMA 7B mostly F16 12.55 GiB 4 tg 128 40.94 ± 0.04 41.39 ± 0.04 1.011 LLaMA 7B mostly Q8_0 6.67 GiB 4 tg 128 64.77 ± 0.05 67.84 ± 0.03 1.047 LLaMA 7B mostly Q4_0 3.56 GiB 4 tg 128 91.14 ± 0.10 96.55 ± 0.09 1.059 LLaMA 7B mostly Q4_1 3.95 GiB 4 tg 128 85.97 ± 0.10 89.57 ± 0.10 1.042 LLaMA 7B mostly Q6_K 5.15 GiB 4 tg 128 71.44 ± 0.04 74.77 ± 0.06 1.047 LLaMA 7B mostly Q5_K - Medium 4.45 GiB 4 tg 128 72.56 ± 0.05 75.44 ± 0.06 1.040 LLaMA 7B mostly Q5_K - Small 4.33 GiB 4 tg 128 74.00 ± 0.06 76.96 ± 0.10 1.040 LLaMA 7B mostly Q4_K - Medium 3.80 GiB 4 tg 128 83.71 ± 0.16 87.92 ± 0.12 1.050 LLaMA 7B mostly Q4_K - Small 3.59 GiB 4 tg 128 87.05 ± 0.08 91.49 ± 0.08 1.051 LLaMA 7B mostly Q3_K - Medium 3.07 GiB 4 tg 128 83.47 ± 0.14 87.62 ± 0.10 1.050 LLaMA 7B mostly Q3_K - Small 2.75 GiB 4 tg 128 85.14 ± 0.14 88.23 ± 0.08 1.036 build: 897cacc (1272) 👍 3 🎉 40 ❤ 4 🚀 3 👀 2 ggerganov added 3 commits tests : verify that RoPE is \"additive\" Verified c5df72e llama : replace ggml_diag_mask_inf with ggml_add (custom -inf mask) Verified 3b4bab6 ggml : ggml_rope now takes a vector with positions instead of n_past Verified 1fb033f ggerganov force-pushed the custom-attention-mask branch from d4cd263 to 1fb033f Compare ggerganov commented View reviewed changes examples/train-text-from-scratch/train-text-from-scratch.cppdata[i] = n_past + i;}}Owner Author ggerganov @xaedes I'm changing the API of ggml_rope to take an entire vector with positions instead of n_past. I have a small concern about this particular change in train-text-from-scratch and cannot test it atm. I'm not sure if the allocator won't make some intermediate results to overwrite the data of KQ_pos at some point. In other places, we fix this using ggml_allocr_alloc(): llama.cpp/llama.cpp Lines 2431 to 2439 in 1fb033f // KQ_pos - contains the positions struct ggml_tensor * KQ_pos = ggml_new_tensor_1d(ctx0, GGML_TYPE_I32, N); ggml_allocr_alloc(lctx.alloc, KQ_pos); if (!ggml_allocr_is_measure(lctx.alloc)) { int * data = (int *) KQ_pos->data; for (int i = 0; i 1. The implementation for >1 was optimized for large batches and has poor performance small batches. Unfortunately that makes it unfit for our own use case, multiple of our users wanted to run volunteer workers at the AI Horde. But demand fluctuates heavily and can be lower, so during the lower thread systems / lower throughput models this would harm our performance if used. So for our hobbyist driven platform we seem to land right in the middle where performance is the worst. 👀 2 martindevans mentioned this pull request Major llama.cpp API Change SciSharp/LLamaSharp#185 Draft 5 tasks ggerganov mentioned this pull request train : fix KQ_pos allocation #3392 Merged Owner Author ggerganov commented We should look into improving the performance for small batch size. This would be useful for the speculative decoding approaches that we are going to implement soon 👍 3 ggerganov mentioned this pull request llama : fix session saving/loading #3400 Merged Contributor pudepiedj commented • edited I couldn't get the ./bin/parallel external alternative-prompt file option to work using -f file.txt so I've inserted a few lines into parallel.cpp to make it run. I am not a C/C++ specialist so it probably won't pass any style tests (code at the end), but it does run on my M2 MAX 32GB and MacOS Sonoma 14.0 from % ./build/bin/parallel -m ./models/llama-2-13b/ggml-model-q8_0.gguf -f \"ParallelQuestions.txt\" -n 128 -t 1 -c 8192 -s 4321 -ngl 100 -np 16 -ns 32 -cb A plain text file like this below saved into /build/ParallelQuestions.txt is then read in generically by common.cpp (with no alterations to the code) and transferred to replace the default k_prompts inside parallel.cpp. What do you know about Hobbits? What is quantum field theory? Why did the chicken cross the road? Who is the president of the United States? How do I run CMake on MacOS? Do you agree that C++ is a really finicky language compared with Python3? Is it a good idea to invest in technology? Do you like Wagner's Ring? Do you think this file input option is really neat? What should we all do about climate change? Producing (sample only) output Now printing the k_prompts loaded from ParallelQuestions.txt that replace the default questions. What do you know about Hobbits? What is quantum field theory? Why did the chicken cross the road? Who is the president of the United States? How do I run CMake on MacOS? Do you agree that C++ is a really finicky language compared with Python3? Is it a good idea to invest in technology? Do you like Wagner's Ring? Do you think this file input option is really neat? What should we all do about climate change? main: Simulating parallel requests from clients: main: Evaluating the system prompt ... Processing requests ... main: clearing the KV cache Client 0, seq 0, started decoding ... Client 1, seq 1, started decoding ... Client 2, seq 2, started decoding ... Client 3, seq 3, started decoding ... Client 4, seq 4, started decoding ... Client 5, seq 5, started decoding ... Client 6, seq 6, started decoding ... Client 7, seq 7, started decoding ... Client 8, seq 8, started decoding ... Client 9, seq 9, started decoding ... Client 10, seq 10, started decoding ... Client 11, seq 11, started decoding ... Client 12, seq 12, started decoding ... Client 13, seq 13, started decoding ... Client 14, seq 14, started decoding ... Client 15, seq 15, started decoding ... Client 7, seq 7/ 32, prompt 14 t, response 11 t, time 2.62 s, speed 9.54 t/s, cache miss 0 Input: Who is the president of the United States? Response: The current President of the United States is Donald Trump. Client 14, seq 14/ 32, prompt 14 t, response 11 t, time 2.63 s, speed 9.52 t/s, cache miss 0 Input: Who is the president of the United States? Response: The current President of the United States is Donald Trump. Client 7, seq 16, started decoding ... Client 14, seq 17, started decoding ... Client 7, seq 16/ 32, prompt 14 t, response 13 t, time 2.39 s, speed 11.28 t/s, cache miss 0 Input: Why did the chicken cross the road? Response: The chicken crossed the road to get to the other side. Client 7, seq 18, started decoding ... Client 12, seq 12/ 32, prompt 14 t, response 30 t, time 5.87 s, speed 7.49 t/s, cache miss 0 Input: Who is the president of the United States? Response: The current president of the United States is Joe Biden. He was sworn into office on January 20, 2021. Client 12, seq 19, started decoding ... Client 10, seq 10/ 32, prompt 13 t, response 35 t, time 6.73 s, speed 7.13 t/s, cache miss 0 Input: What should we all do about climate change? Response: We should all work together to reduce our carbon footprint. We can do this by reducing our energy consumption, recycling more, and using public transportation whenever possible. Client 10, seq 20, started decoding ... Client 1, seq 1/ 32, prompt 14 t, response 42 t, time 7.93 s, speed 7.06 t/s, cache miss 0 Input: Why did the chicken cross the road? Response: The chicken crossed the road to get to the other side. It is a classic joke that has been around for many years and is often used as an example of a riddle or paradox. Client 1, seq 21, started decoding ... Client 14, seq 17/ 32, prompt 14 t, response 36 t, time 6.36 s, speed 7.86 t/s, cache miss 0 Input: Who is the president of the United States? Response: The president of the United States is Joe Biden. He was elected in November 2020 and took office on January 20, 2021. Client 14, seq 22, started decoding ... Client 0, seq 0/ 32, prompt 16 t, response 49 t, time 9.17 s, speed 7.09 t/s, cache miss 0 Input: Do you think this file input option is really neat? Response: Yes, I think this file input option is really neat. It allows you to easily upload files from your computer or other devices and view them in the browser. This can be very useful when sharing large files or working with multiple documents at once. Client 0, seq 23, started decoding ... Client 10, seq 20/ 32, prompt 13 t, response 14 t, time 2.62 s, speed 10.29 t/s, cache miss 0 Input: Do you like Wagner's Ring? Response: I do not know what \"Wagner's Ring\" is. Client 10, seq 24, started decoding ... Client 9, seq 9/ 32, prompt 22 t, response 56 t, time 10.42 s, speed 7.49 t/s, cache miss 0 Input: Do you agree that C++ is a really finicky language compared with Python3? Response: I cannot agree or disagree with that statement because it is subjective and depends on the person who is asking the question. Some people may find C++ to be finicky, while others may not have any problems with it. Ultimately, it comes down to personal preference. The additional lines of code (does C++ not have a .split(\"\\n\") predefined function?): // Define a split string function to ... std::vector splitString(const std::string& input, char delimiter) { std::vector tokens; std::istringstream stream(input); std::string token; while (std::getline(stream, token, delimiter)) { tokens.push_back(token); } return tokens; } And then somewhere suitable inside main() and before k_prompts is used, in my case roughly at line 125: // load the prompts from an external file if there are any // these have been acquired by `common.cpp` and put into `params.prompt` // by parsing `-f ParallelQuestions.txt` in lines 150-164 if (params.prompt.empty()) { std::coutprompts = splitString(params.prompt, '\\n'); for (const auto& prompt : prompts) { k_prompts.resize(index + 1); k_prompts[index] = prompt; index++; std::cout (tokens.data())? Or do I need to copy the vector first? Or should I be doing something with llama_batch_init/llama_batch_free instead? Owner Author ggerganov Ideally, you want to llama_batch_init a new object and use that all the time. Alternatively, un-const the C++ vector if that is an option. const_cast works, but I want to avoid it fully in this project, even in the examples, so better not use that. yusiwen pushed a commit to yusiwen/llama.cpp that referenced this pull request llama : custom attention mask + parallel decoding + no context swaps (g… … bcb3ffe ggerganov mentioned this pull request refact : fix convert script + zero out KV cache to avoid nans #3523 Merged nivibilla mentioned this pull request Parallel decoding turboderp/exllamav2#95 Open dkogut1996 mentioned this pull request [Bug] Server completions return a lot of colons #3575 Closed SabareeshGC mentioned this pull request Processing inference in parallel jmorganca/ollama#761 Open the-crypt-keeper mentioned this pull request Support batched completions for llama.cpp the-crypt-keeper/can-ai-code#102 Open yhj-zone mentioned this pull request Hacker News Daily Point Above 100 @2023-10-12 yhj-zone/hackernews-daily#13 Open jacky1234 mentioned this pull request HackerNews Top 10 @2023-10-12 jacky1234/blogPages#205 Open Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment Reviewers xaedes cebtenzzre slaren Assignees No one assigned Labels high priority need feedback Projects None yet Milestone No milestone Development Successfully merging this pull request may close these issues. llama : try to avoid context swap 12 participants Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37846387",
    "commentBody": "M2 Ultra can run 128 streams of Llama 2 7B in parallelHacker NewspastloginM2 Ultra can run 128 streams of Llama 2 7B in parallel (github.com/ggerganov) 241 points by behnamoh 22 hours ago| hidepastfavorite159 comments mrb 10 hours agoFor those wondering why the M2 Ultra is so fast, or the M1 & M2 series in general, it&#x27;s because inference&#x27;s main bottleneck is memory bandwidth, not compute power. And the M2 Ultra has a bandwidth of 800 GB&#x2F;s which is about 8 times faster than an average modern desktop CPU (dual-channel DDR4-6400 offers a bandwidth of 102 GB&#x2F;s).This high bandwidth is really a result of Apple having designed a unified memory architecture for the M1 and M2 chips. Typically on a laptop or desktop, the CPU and GPU have distinct memory systems: high-bandwidth (but relatively low-capacity) graphics memory, and relatively low-bandwidth (but high-capacity) CPU memory. Apple decided to simplify that and instead implemented a single high-bandwidth memory system shared by the CPU and GPU. The only downside is that such high-bandwidth memory had to be tightly integrated in the M2 package, so the maximum capacity is limited. For example whether you spend 5,600 USD (cheapest Mac Studio machine with M2 Utra and 192 GB) or $10k+ (maxed out Mac Pro), you will only ever get 192 GB RAM max. For that amount, a PC could get 1024 GB RAM (5× more!) But on the other hand, if your workload, like inference, doesn&#x27;t need more than 192 GB, then that&#x27;s great. Personally I think Apple made the right tradeoff here. 800 GB&#x2F;s of memory bandwidth on a general purpose CPU, on a single socket, has never been done before (to my knowledge.) reply mark_l_watson 25 minutes agoparentThe 800 G&#x2F;s bandwidth is amazing. I ordered a maxed out Mac mini with 32G ram and 200G&#x2F;s bandwidth. For the LLMs I want to run right now, that is sufficient for my needs, although I did consider over-buying and getting a M2 Ultra. I also pay Google for Colab, and as long as I don’t over-use it, I can almost always get an A100. My strategy is to split my work as appropriate between the Mac mini when I get it in a week or two, and Colab. I used to run on Lambda Labs, also excellent, but setup time was non-negligible. reply j45 13 minutes agorootparentThe M1 Max and M2 Max are quite serviceable too in not jumping to an ultra. reply sonthonax 5 hours agoparentprevI&#x27;ve noticed that M series Macs have extremely fast disk drives that the OS uses as swap quite efficiently. I&#x27;ve frequently used all my RAM on my Mac and barely noticed any slowdown when it starts swapping. reply detourdog 2 hours agorootparentI found that SSD drives finally eliminated the drawbacks of Mach&#x27;s VM. While on platter drives one needed lots of RAM to avoid needing to swap. reply kristianp 10 hours agoparentprevCompare with an rtx 4090, which has memory bandwidth of 1,008 GB&#x2F;s, but only 24GB of gddr. The 4090 is cheaper.https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;geforce-rtx-4090.c3889 reply mrb 10 hours agorootparentI agree, GPUs can still generate more token per second per dollar, but what is new and great about the high-end M1 and M2 is Apple offering this much memory bandwidth on a general purpose CPU, thus immediately available to all software running on the CPU. reply boesboes 1 hour agorootparentUnless you calculate power usage I’d bet reply datameta 25 minutes agorootparentI would wager the M2 is more energy efficient than a 4090. reply smoldesu 14 minutes agorootparentIt fully depends on the workload. The 4090 itself draws around 450w at load, and the M2 Ultra peaks around 300w. If your workload is >1.5x faster on Nvidia hardware, then it&#x27;s per-prompt efficiency probably beats out the M2 Ultra. replyleetharris 18 hours agoprevFor applications that aren&#x27;t latency sensitive my company has found that Apple hardware inference is far less expensive than the competition when calculating for electricity usage. I wish they would make a cloud offering. reply whalesalad 17 hours agoparentAmazon has Apple servers for rent. There is also https:&#x2F;&#x2F;macminicolo.net and https:&#x2F;&#x2F;www.macminivault.com reply nathancahill 16 hours agorootparentI&#x27;m so happy MacMiniColo is still around. I had projects hosted there when they were just getting started. They&#x27;ve stayed true to their mission. I love that their website still feels like Wordpress 3.0. reply hamandcheese 16 hours agorootparentThey aren&#x27;t accepting new Mac minis for colocation. Which means if you want to go from, say, 8gb to 16gb of ram then that&#x27;s an extra $90 a month for the privilege. reply jzombie 5 hours agorootparentI am using https:&#x2F;&#x2F;www.macminivault.com for colocation. reply JCharante 4 hours agorootparentprevDoesn’t macos require you to rent it out with a one month minimum? At that point just buy the hardware reply cyberge99 16 hours agorootparentprevThere’s also MacStadium. reply detourdog 16 hours agorootparentI have a fiber connection, the space and the experience to run a Mac mini colo. If people are really interested. I would want to do it as a co-operative that helps with the expense of the physical location. reply ruph123 15 hours agorootparentprevMacMiniColo and MacStadium merged afaik. reply garciasn 16 hours agoparentprevWe went with a M2 Studio with maxed out RAM because we simply cannot get reliable GPU availability with cloud providers and for $6000 (with tax) we can have the equivalent VRAM of ~2 80GB GPUs instead of paying $5&#x2F;hr for the pleasure. reply ttt3ts 15 hours agorootparentWith a 70B param model how many tokens&#x2F;second?Did the math and assuming 100% util and equal performance (which is certainly not the case) payback on your Mac is 9 months... reply garciasn 15 hours agorootparentYou need to pay for dedicated because they’re generally unavailable in the moment. So it’s more like 45 days, if we’re only talking about a single GPU—but we’re talking about ~2x. reply ttt3ts 15 hours agorootparentHow many tokens a second? Really trying to figure out viability.4x NVIDIA A100 at lamda labs is $4.40 an hour and I really have not had an issue getting them. reply hnfong 13 hours agorootparentNote this is a M1, not M2.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;16o4ka8&#x2F;running... reply ttt3ts 13 hours agorootparentThanks! Ya, I opted for dual 3090 for my workstation (keeping full LLM in VRAM is crit) was wondering what lift was for M2.OP implied that there were workloads where it out competes renting in terms of cost. Was hoping it was true for something than a single user interactive session (which can be done a lot cheaper) replycrooked-v 17 hours agoparentprevYou could always rack mount some Mac Minis. reply ninkendo 17 hours agorootparentIt’s sad that racking and maintaining your own physical hardware is becoming such a lost art… I appreciate the up-front simplicity of cloud offerings as much as anyone, but there’s something to be said for owning your own hardware and avoiding the continual rent payments you’re sending the cloud providers.The wisdom is that cloud providers are better at infra than you, and that the economies of scale make it better to piggy back on what they’re doing, but… AWS is the most profitable part of Amazon for a reason. They’re overcharging you. reply ilc 17 hours agorootparentFor most orgs: AWS is not overcharging IMHO.When you look at the cost of the hardware + hosting. Yes, it certainly looks and feels that way.But if you&#x27;ve dealt with corporate IT, and had to deal with 3-6 month lead times on getting hardware, or politics to get your hands on hardware to get stuff done.AWS is cheap. It gives you velocity.If your company is large enough that it can offer the elasticity of resources that Amazon offers or even 1&#x2F;4 of it... and you have an IT org that will let it happen. Yes, AWS is a waste.But with AWS... when a project dies, you can wipe its costs out, people won&#x27;t hold onto hardware so they have hardware for the next project, etc...Trust me. I&#x27;ve been IT, I can spec and build rack systems. I am a software dev. And I&#x27;ve been a dev most all my career.For 90%+ of orgs... they don&#x27;t have the maturity and skills to handle that type of infra without substantially distracting from their primary business. reply ttt3ts 15 hours agorootparentI find at AWS I am always wasting engineer time optimizing dumb things. Do you know how much a TB of ram costs? Or 10TB of blazing fast NVME costs? Less than $5K. How much does that cost at AWS?! This is not even considering bandwidth which AWS overcharges soo much. Yet I waste time.Also, maintaining servers is not hard at a proper data center. It is often more hands off than the migrations cloud providers force on their customers. reply wredue 13 hours agorootparentYeah. Also, to be honest, we still have process and approvals to get through to spin up AWS stuff.It’s not like process disappears just cause you’re not on your own hardware. Infra is still its own team with its own budgets poking and prodding at every damn turn for every little thing till rejecting your requests, you escalate and then have a 4 week battle over needing the space. reply JCharante 6 hours agorootparentReally? At my old company each division had its own budget and account and then you’d be an iam member of an account and spin up services under that account, but there’s no central authority to send a request to. There were tools to analyze underused services across all accounts (like EC2 instances constantly under 2% cpu load meaning they were flagged for downsizing if possible). reply benreesman 14 hours agorootparentprevGetting good results on AWS&#x2F;GCP is neither easy nor simple: it’s a different set of headaches.It’s still a win for a lot of use cases and I still do it quite often, but the meme that it’s this “click and you’ve just hired the best ops team in the world to work for you” and so the 50-500% markup is actually a bargain is horseshit. A Bizon box in your living room fucks AWS up on flops&#x2F;$ on most instance types and pays for itself in 30 days.It is one of the best ops teams on Earth: but they’re working for you like the Google search team is working for the user. reply mannyv 14 hours agorootparentThe problem with using a cloud provider is that you still need to know what you&#x27;re doing.Your application isn&#x27;t going to magically become HA&#x2F;DR. You still have to make it that way, from your application design&#x2F;coding up through the deployment.I mean, if you&#x27;re not storing your session IDs in a data store that&#x27;s reachable by all the nodes behind your load balancer then no amount of infrastructure is going to save you. reply TheNewsIsHere 30 minutes agorootparentA great illustration of this is the GitHub outage a few years back. They had a fairly well distributed application layer but the database topography at the time didn’t consider the failure mode, even though the application layer did.That’s a realistic scenario no matter whether you’re bare metal, building out your own cloud, or using someone else’s. No amount of AWS&#x2F;GCP&#x2F;Azure&#x2F;et al marketing changes that. reply ilc 14 hours agorootparentprevAnd when your comcast link dies, GG man. Oh, what about when you drop a drive?Yes, you have to learn things to goto the cloud, and I won&#x27;t say it is all roses, it ain&#x27;t. But... AWS is less likely to fsck it up.If you have the constant load to burn the flops 24x7x365... go for it. If you have the ops team to do it... go for it.If you don&#x27;t... take a bit of time and learn the cloud which is much easier than getting on-prem right.Especially for smaller firms, this isn&#x27;t even a close call IMHO. reply ndriscoll 11 hours agorootparentBack in the day, Google was an innovator by using lots of cheap commodity servers instead of a few expensive ones and just accepting failures as a fact of life. I wonder 25% seriously whether there&#x27;s an opportunity for a similar mad genius move to pay for business class fiber at a half dozen remote employee&#x27;s homes across the country and just have a good replication&#x2F;failover strategy. 24&#x2F;7 on call isn&#x27;t that big of a deal if you just have to go into your basement to swap a drive. Going to be on vacation? Don&#x27;t be the primary site while you&#x27;re out. reply benreesman 8 hours agorootparentPeople like vast.ai are making moves in this geberal direction FWIW if you’re passionate about it. reply sitkack 15 hours agorootparentprevI work in cloud and you sound like a shill. reply ilc 14 hours agorootparentMore a realist. If you have the scale to go on prem. Do it.Most firms don&#x27;t. Or don&#x27;t have the skills.Also, the cloud can help an IT project recover from errors. Let&#x27;s say, I&#x27;m about to buy 500k of hardware to setup some storage. I get my requirements, I architect it, do my design work, and then buy the hardware. I have to over provision a bit because of reality and human error... But when I discover that the requirements, shift 2mo in my project, and I&#x27;ve already ordered the hardware... I may be hosed.This isn&#x27;t hypothetical, this is what happens. Things evolve and shift. The cloud allows for more agility. If your firm is large enough, or has its stuff together enough, go for it on-prem.I&#x27;ve got 20+ years on prem.. I&#x27;ve seen it fail all over. I&#x27;ve seen cloud be a mess too. But if you told me to clean up one. I&#x27;ll take the cloud. reply throwaway2990 13 hours agorootparentprevAnyone who thinks the blanket statement “cloud is expensive” really doesn’t know what they are talking about. reply ChrisMarshallNY 13 hours agorootparentprevFor me, I prefer hosted&#x2F;cloud, preferably managed.I’m quite capable of setting up whole server stacks. I did it for years, but I stopped, some time ago, and consider myself to be, for want of a better word, incompetent at being a modern admin.I think I’d screw the pooch, so I prefer that someone who does it every day, handle it.But I write Swift code, every day, so I’m not incompetent at everything. reply ClimaxGravely 12 hours agorootparentprevI&#x27;m a former build engineer and used to do everything on prem and I gotta say I miss it (not being a build engineer, the on prem experience). Since those days pretty much every company I&#x27;ve worked at moved their CI&#x2F;CD to the cloud and I gotta say it feels so much slower, even when working from home.I remember twice switching from an in-house jenkins&#x2F;teamcity&#x2F;whatever type of CI to Azure devops and the thing I remember the most was how much longer it took a build to complete as well as the massively longer time downloading a build from Azure vs from within the office. Even when working from home the on-prem stuff was faster.The thing is, the build&#x2F;devops teams seem to be about the same size in both cases. It&#x27;s just kind of worse in pretty much every case when we do CI in the cloud.Notes- My experiences are largely for game development so the build times and artifact sizes can be quite large.- I&#x27;ve only ever had CI&#x2F;CD experience with Azure, I&#x27;ve not tried other cloud providers- Since this is game development and we&#x27;re using CI downtime is more acceptable than other cases. That said, I don&#x27;t remember much downtime when I was working as a build engineer. I have seen periods of 1-2 hours of downtime once in a blue moon but then again I&#x27;ve seen that with Azure. In both cases it wasn&#x27;t so much the setup but a build script deployment issue.Also being able to cool off in the rack room when it&#x27;s a hot day is always a treat :) reply sbarre 16 hours agorootparentprevThe question I&#x27;ve often heard asked when deciding on build vs buy (which can apply to cloud vs. bare metal) is:Are we in the business of building, maintaining and operatingor do we want to buy that as a service instead and focus on our actual core business?There&#x27;s more to the cost of building and operating than just the hard costs.Retaining good modern IT talent is getting harder and harder - and I&#x27;m not even talking about salaries.. You need a whole department including strong leaders who can hire, train, and lead the right people, etc..This is something most companies wouldn&#x27;t even know where to start with. reply hamandcheese 16 hours agorootparentI don&#x27;t think you need a whole department to rack a few minis and run some buildkite agents on them. reply mannyv 14 hours agorootparentIt depends on how important it is to you.You can throw a bunch of boxes in a closet and it&#x27;ll work. A surprisingly large amount of the early Internet was \"a spare box under my desk.\"The problems start when they become part of your critical path and you&#x27;re on vacation and nobody knows WTF is happening.I mean, it&#x27;s a risk. If you&#x27;re OK with that risk then go for it.It&#x27;s really about the politics of your office.If everyone is OK with the idea that the box is in some closet somewhere that&#x27;s fine. I&#x27;ve been part of a bunch of startups where we were running infrastructure on spare hardware. Sure it&#x27;s not HA, but we didn&#x27;t need it...or it was at least HA enough for what we needed. reply hamandcheese 13 hours agorootparentYeah, to be clear I wouldn&#x27;t advocate this route for your core product. But running CI workers? Sure. Especially macs, which have onerous usage restrictions in the cloud that negate most of the elasticity benefits you might otherwise see. reply londons_explore 16 hours agorootparentprevYou need one good motivated sysadmin.But if you can motivate that same sysadmin to spend his skills on something more directly benefiting your company, then you should still buy it in. reply hamandcheese 15 hours agorootparentI think you need one motivated developer who likes to tinker with hardware for a few hours a month.Given how popular homelabs are, I don&#x27;t think this would be too hard to find. reply lghh 13 hours agorootparentI don’t want to build a business around a dev who likes to “tinker with hardware”. reply hamandcheese 10 hours agorootparentWhy the scare quotes? It&#x27;s a skill like any other. Startups are built by folks who wear many hats. reply c0pium 15 hours agorootparentprevNow your business depends on that one person, congratulations. Hope they don’t realize that their skills are better suited to working at AWS&#x2F;Azure etc. for 2x the money. Which they are. reply londons_explore 15 hours agorootparentIt&#x27;s not core stuff. If the one sysadmin leaves, you buy in a solution. reply c0pium 10 hours agorootparentI mean, fair enough I guess. Why play the OpEx vs CapEx game when you can just pay both. replysolardev 16 hours agorootparentprevWhere does this stop? Do you produce your own electricity? Farm your own food? Make your own silverware and shoes? Sometimes it&#x27;s just easier to outsource the things you don&#x27;t want to (or aren&#x27;t good at) doing yourself.If I wanted to host a website, sure, I can build a server out of parts and negotiate with my ISP and get a business pipe and handle all caching and such. Or like I can pay a provider $5&#x2F;mo and get better performance and reliability with no management overhead. Yeah, maybe over 5 years I&#x27;d save more money doing it myself... but it&#x27;s not worth the time.If I wanted to generate a photo or a dozen, or a few paragraphs of text, that&#x27;s like a few cents worth of cloud AI. Maybe low single-digit dollars. Or I could spend thousands on fat GPUs or a Macbook, spend forever training it, and still end up with a sub-par result.AWS is profitable not just because they&#x27;re overcharging you but because they are providing a hugely useful service for millions of businesses that don&#x27;t want to deal with that infrastructure themselves, any more than they&#x27;d want to manage their own plumbing or electrical grid or roads and bridges leading to their office. DIY makes sense if you&#x27;re doing it as a hobby or if your scale is so big that you would incur significant savings to in-house it, but for millions of small and medium businesses, it&#x27;s just not the most practical approach. Nothing wrong with that.I mean, it&#x27;s like saying development is such a lost art... why hire a dev if you can learn to code yourself? Sure, but not everyone wants to, can, or has time. reply ClimaxGravely 12 hours agorootparentI hate to say this but it has gotten to the point where I&#x27;m starting to farm some of my own food (I&#x27;m starting to get fed up with produce quality issues in my hometown).Still haven&#x27;t started on the silverware or shoes yet.I do agree with you though. If you are a non-tech company or a company that lacks the human resources you might as well go with the cloud. reply solardev 9 hours agorootparentThat&#x27;s not anything to be ashamed of. It&#x27;s awesome you grow your own food! reply Spooky23 15 hours agorootparentprevDepends on the financials.My employer has generated its own electricity and steam for decades.For a small business - different story. reply whalesalad 16 hours agorootparentprevYou’ve never had to drive to the colo at 3am huh? reply ninkendo 15 hours agorootparentNo, I had proper OOB access and could do any kind of power cycling or remote console access from my desktop. reply hnfong 13 hours agorootparentNever seen a hardware failure, I see. reply ninkendo 4 hours agorootparentThe snark is getting a bit tiring. No, plenty of hardware failures but we had redundancy. Our availability wasn’t dependent on how fast I cold drive to the data center at 3am. Drive dies, who cares, there are plenty of hot spares, we’ll deal with it during business hours. Server dies, who cares, there are lots of them. We have remote hands too, so simple hardware replacement is something you can get cheap onsite labor to do.If your operations halt until some poor sysadmin has to drive to the colo, you are absolutely doing it wrong. reply cherryswitch 17 hours agorootparentprevSometimes the flexibility and time savings is worth the added upfront cost. Similar to how companies like to hire consultants or lease office space. Being able to walk away is better for short term, because companies value profits in the short term. reply GravityLab 1 hour agorootparentprevI have a base-model m1 Mac Mini and it&#x27;s a beast. I&#x27;m using it as my build&#x2F;deploy server and also as a back-end server (for running jobs) for the prototype I&#x27;m working on. I also do development on it when I want to use my big monitor rather than my laptop. And I listen to music and run Cookie Clicker at the same time while doing development.Got three databases up and running too. It&#x27;s a beast. I&#x27;d definitely consider self-hosting with a few Mac Minis, that would be fun and they&#x27;re really cute, sleek devices too. I paid $650 for it and consider it a great deal. Definitely should&#x27;ve gotten it with more than 8gb of ram but I got it to try it out and haven&#x27;t yet really needed to upgrade to a unit with more memory. reply nre 17 hours agorootparentprevInterestingly enough I was actually discussing this with a friend (who works in enterprise IT) the other day. Basically rack servers are purpose build for the task, with hot swappable components, redundant power&#x2F;storage, multiple NICs, ECC, remote management, and so on. They come with enterprise support and can be easily maintained in the field.Meanwhile a Mini cluster is literally a bunch of mini pcs in a rack, and idk if Apple even supports this kind of industrial use. While it&#x27;s a quality product the Mini isn&#x27;t really designed for the datacenter. reply xienze 16 hours agorootparent> and idk if Apple even supports this kind of industrial use. While it&#x27;s a quality product the Mini isn&#x27;t really designed for the datacenter.I think they know of it and tacitly approve of this use case, as evidenced by the Mac Mini having the same form factor for ages. They’re well aware that a lot of people use Minis (and Studios now) in data centers, and that the Mini footprint is sort of “standardized” at this point. reply selectodude 13 hours agorootparentThat 10GbE NIC option on the low end Mac Mini was a dead giveaway. reply nxobject 14 hours agorootparentprevIIRC, Apple did indeed have a server SKU for the Intel Mac mini at some point. reply ytch 14 hours agorootparentIt&#x27;s called Xserve:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Xserve#Intel_XserveBut since Apple discontinued Xserve and macOS Server, they seems like don&#x27;t care about this business anymore. reply MenhirMike 13 hours agorootparentThey actually had a Mac Mini Server as well for a bit. It made sense because it had a second hard drive instead of an optical drive and came with a Mac OS X server, back when that was a standalone $499 product: https:&#x2F;&#x2F;support.apple.com&#x2F;kb&#x2F;SP586(Not sure what differentiates the later model Mac Mini Servers from the regular Mac Minis, since Mac OS X Server just became a $19 App Store purchase, and optical drives were no longer a thing in Mac Minis) reply TheNewsIsHere 14 minutes agorootparentI have one of the 2009 Mac mini Servers running Ubuntu 22.04 LTS like a champ. It’s still a great machine. Upgrading the HDDs to SSDs was a bit of a chore, but doable.They discontinued the Mac mini Server line in October 2014, which was still sold with two drives instead of one. Configurable to order with SSDs by that time. reply astrodust 13 hours agorootparentprevThere was also a \"server\" model Mini but it was very short lived and was basically a regular Mini with the \"Server\" software pre-installed, something that you could just throw in via the App Store with one click anyway. reply TheNewsIsHere 7 minutes agorootparentIt had a five year run and saw four different hardware models. It included two hard drives instead of either one hard drive and an optical drive, or just one hard drive (after they ditched ODDs).Mac OS X Server was its own operating system originally. It was still the same core OS, but had a ton of additional servers built in. Non-exhaustively, they included IPSec VPN, email, calendaring, wiki, SMB and AFS file shares (including support to act as a Time Machine backup destination), LDAP, DNS, and software update caching before it came to macOS proper. The Server app released via the App Store was a shadow of Mac OS X Server.These were quite popular in small professional offices like law firms.chmod775 7 hours agoparentprevNowadays GPUs factory defaults try to squeeze out the last bit of performance for a huge cost in power.You can run them at half the power usage and only lose a fraction of the performance - at least in gaming. Try for AI tasks. reply api 17 hours agoparentprevApple really should license the M chip IP to someone to make a server chip out of it, or do it themselves. It&#x27;s money on the table for them and would not cannibalize their Mac business at all. It&#x27;s a very nice core. reply Aurornis 13 hours agorootparentApple silicon is great for low power desktops and laptops, but they don&#x27;t actually have groundbreaking performance relative to what we&#x27;ve got in the server space. If you dropped the M2 Ultra from the $4000 into a server, it would perform about the same as a $1500 AMD 7950X3D based server (this is a common budget server setup with ECC) in CPU tasks. Stick a common GPU in there and you&#x27;re running circles around the M2 Silicon in GPU tasks.The Apple Silicon is great at really low power work, but if you dial desktop or server GPU power limits down they also become quite efficient. The marginal cost of electricity is cheaper than buying more hardware, so nVidia and others run their parts deep into the diminishing returns part of the curve to maximize performance at the expense of power efficiency. reply cyber_kinetist 12 hours agorootparentWhat Apple Silicon brings to the table is not simply just performance, but a large amount of unified memory that can be used by the GPU (which are needed for inference of large deep neural networks like LLMs).A top-of-the-line Mac Studio will give you 192 GB of unified RAM in less than $7000. Meanwhile a H100 from NVIDIA with 80 GB of VRAM will cost you like $30000... reply api 1 hour agorootparentIf the software were a little better Apple Silicon would be by far the most cost effective rig today for DIY LLM research or training.192GiB RAM is enough to train or inference Falcon 180B in RAM at 8-bit resolution. reply sitkack 15 hours agorootparentprevThere are multiple riscv based solutions that will be out in 12-18 months. But for now, getting Apple hardware is the best solution. reply starcraft2wol 15 hours agorootparentprevyou can buy rack mount Mac pro reply mschuster91 17 hours agorootparentprevFully agree. It&#x27;s time for some serious competition not just against Intel&#x2F;x86 but also in the ARM space. reply dzhiurgis 17 hours agorootparentIDK about ML part, but equivalent performing Ryzen mini pc cost me 3x less over m1 macbook (yes im aware you get more with macbook) reply GeekyBear 16 hours agorootparent> IDK about ML part, but equivalent performing Ryzen mini pc cost me 3x less over m1 macbookWhen running an ML workload, the Nvidea A100 has massive GPU compute resources, and a large amount of GPU local high bandwidth memory, so it&#x27;s ideal, but is nowhere near low cost.A consumer Ryzen chip is inexpensive, but lacks in both memory bandwidth and GPU resources.The M2 Ultra has access to way more RAM than consumer GPUs, many times the memory bandwidth of a Ryzen (800GB&#x2F;s vs Ryzen 7 1800X at 40 GB&#x2F;s) with a large amount of local GPU resources.Even stepping up to a Threadripper Pro would only get you a quarter of the memory bandwidth, and those aren&#x27;t exactly cheap either. reply solardev 16 hours agorootparentprevIt&#x27;s easy to outperform Apple Silicon on pure power, but what about efficiency & heat? (like FLOPS&#x2F;watt or whatever). Does anything else come close yet? reply blacksmith_tb 16 hours agorootparentThat matters a lot in a laptop, but not so much in a 1U rack? Not that datacenters love heat, but the competition isn&#x27;t extra hot, it&#x27;s just hotter than Apple Silicon? reply ska 15 hours agorootparentA 1U rack is a small machine, but a few hundred of them+ in a constrained space is a different story. At larger scales, moving electricity in and heat out are usually the defining factors. reply solardev 16 hours agorootparentprevI guess it depends on what you&#x27;re doing with them? If you&#x27;re running them 24&#x2F;7 to train or model something, the energy costs might add up. Even if you&#x27;re not, having more efficient chips might mean more data centers don&#x27;t need as complex cooling equipment. reply dzhiurgis 14 hours agorootparentprevYou&#x27;re quite right - 6800H TDP is 45W, M1 is 30W replysmoldesu 17 hours agoparentprevFor applications that aren&#x27;t latency sensitive, I run inference on a free 4 core Ampere server from Oracle. Once you ditch the \"fast\" prerequisite, a lot of hardware becomes viable. reply gcr 17 hours agoprevFor folks curious what this is, this seems to be a caching optimization for saving time on parallel streams of text. The benchmark is incidental. Most individual users likely have just one un-batchable conversation going at once with llama-cpp, and I think it’s unclear whether this PR improves that case much.Also note that the demo video is sped up to fit inside GitHub attachment limits. Your observed speed may vary. :) reply lukeschlather 16 hours agoparentI&#x27;ve been curious about using LLMs for large-scale refactoring. Prompts likeanywhere you find `FooBarBaz(blip, kap)` replace it with `new newThing(blip).bump(kap)`I don&#x27;t know how reliable it is, but it seems like if you can easily run this on commodity hardware it could totally replace most IDE refactoring tools, although obviously the IDE refactoring is more reliable, it seems like this could be made simple and flexible, and possibly just as reliable as IDEs.But also it could enable some interesting things that you could never do with an IDE refactoring tool. reply potatoman22 15 hours agorootparentLLMs aren&#x27;t very good at string operations. They struggle with things like character counts, extracting substrings, and replacements. reply simonw 14 hours agorootparentYeah, for this kind of thing I would get the LLM to generate the regular expression. reply sharkjacobs 14 hours agorootparentprevI already do things like \"write a script to replace `FooBarBaz(blip, kap)` with `new newThing(blip).bump(kap)` in a project folder\"I&#x27;m more comfortable with that because I find it usually takes two or three prompts to get it righte.g. A couple hours ago I prompted it to help me do a diff of two commits ignoring all white space, just to check if there were any other changes. The first response didn&#x27;t ignore new newlines, the second one was a multiline script, the third response gave me what I actually wanted. diff -wIs it possible that in a few years time, only Mac silicon and PCs with high-end GPUs will be required to run \"In-home LLMs\" affordably?No. They work well on the apple chips thanks to the integrated memory and the large size of the models. I know of no reason why an x86 chip could not be designed in a similar way if desired. IANAChipDesigner but I have worked for one of them. reply behnamoh 17 hours agorootparentFWIW, while Apple silicon can _run_ huge models thanks to the unified memory (not to be confused with shared memory), the inference is pretty slow compared to dedicated GPUs, so it&#x27;s a tradeoff. The significance of this PR is that inference speed can—at least in certain applications—be sped up using parallel decoding. reply eurekin 16 hours agoprevOk, impressive!What are real world use cases for 7B family of models? Is anyone using them for anything productive? reply wokwokwok 15 hours agoparentThey&#x27;re quite good at generating scaffolds and ideas (mistral specifically).You can use them for trivial nlp tasks (\"between 0 and 1 how similar are these two sentences? Respond with an explanation.\") and because it&#x27;s a small model, you just run it 4 or 5 times and take an average pretty quickly. reply anotherjesse 16 hours agoparentprev7B coding models? Having massive amounts of questionable code :) reply d_sem 15 hours agorootparentWelp, looks like I&#x27;m out of a job. Perhaps management will suit me well, where I can make massive amounts of questionable decisions. reply eurekin 15 hours agorootparentprevYeah, same experience here reply Havoc 16 hours agoparentprevThey&#x27;re perfectly fine for story telling and basic chatbot duty. Also generating basic code boilerplate works just fine. reply potatoman22 16 hours agoparentprevThey make good classifiers when fine tuned reply eurekin 15 hours agorootparentInteresting!I&#x27;d have one use case for classification: user text (from a jira issue) mapped to the team responsible for the fix.Can you share some tutorials? I only just managed to get this working on windows&#x2F;cuda:https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1vk8i01apaSp59GVV2yI...It&#x27;s been a royal pain to setup reply objektif 13 hours agorootparentprevDo you have any pointers to learn how to start with fine tuning mistral locally! reply cypress66 9 hours agorootparentUse axolotl reply Metus 18 hours agoprevDo these implementations use the neural engine? I saw that there was a stable diffusion implementation using the neural engine and I found that my macbook noticably did not run hot, as opposed to an average Teams call. reply woadwarrior01 14 hours agoparentEncoder only transformers (like BERT) can be made to run on neural engine with CoreML. Efficient inference with autoregressive encoder-decoder and decoder only transformers (aka LLMs) needs KV-caching, which currently can&#x27;t be efficiently implemented with CoreML (and thus neural engine). So, for now it&#x27;s GPU only, with Metal. reply smpanaro 12 hours agorootparentYou can do autoregressive decoding with KV caching on the Neural Engine. You have to make a bit of a trade off and use fixed size inputs [1] but the speed up over no caching is meaningful.There&#x27;s a Whisper (Encoder-Decoder) [2] implementation if you want to see it in practice. Shameless plug, but I have a repo [3] where I&#x27;m working on autoregressive text generation on the Neural Engine. I&#x27;m running gpt2-xl (1.5B params) locally with KV caching at 120ms&#x2F;token (vs. 450ms without caching). Will push an update soon.Without quantization you can&#x27;t go much higher than 1.5B params on M1&#x27;s Neural Engine. M2 seems to have a higher ceiling but I haven&#x27;t measured. I&#x27;m optimistic (but have not tried) that the new runtime quantization added to CoreML this year will allow for larger (and maybe faster) models on both.[1] Technically you should be able to use 1 input with an enumerated set of sizes but I haven&#x27;t been able to get it to work on the Neural Engine. This would likely be even faster. [2] https:&#x2F;&#x2F;github.com&#x2F;wangchou&#x2F;whisper.coreml&#x2F; [3] https:&#x2F;&#x2F;github.com&#x2F;smpanaro&#x2F;more-ane-transformers&#x2F; reply cypress66 9 hours agorootparent>I&#x27;m running gpt2-xl (1.5B params) locally with KV caching at 120ms&#x2F;token (vs. 450ms without caching).That seems very slow compared to llama cpp? reply smpanaro 6 hours agorootparentYeah, I believe it is. You trade off speed for lower power usage and CPU. 8 tokens&#x2F;sec is usable though. reply snitty 18 hours agoparentprevIt doesn&#x27;t. You need to generate models for use on the neural engine, which apple did for Stable Diffusion, but this is just taking advantage of lots of fast RAM and lots and lots of threads, if I understand it correctly. reply ramesh31 16 hours agorootparentIt uses Metal acceleration, and takes advantage of the shared memory architecture, meaning it&#x27;s basically a GPU with 196GB VRAM. Trading space (VRAM) for time (FLOPs), it can beat the performance of an RTX4080 here. reply lostmsu 11 hours agorootparent> can beat the performance of an RTX4080 hereThis needs some backing. When M1 just got out people were claiming it is comparable to 3080, until they saw the performance difference. reply ramesh31 11 hours agorootparentRead the PR reply GaggiX 17 hours agoparentprevAutoregressive transformer models are usually memory bound, whereas SD is compute bound, so perhaps the difference lies here. Also the reason why SD runs so much faster on the GPU than on the CPU. reply ninkendo 17 hours agorootparentM1 has (fast) unified memory between GPU and CPU, so something being memory bound ought not to have much bearing on whether it belongs on CPU or GPU… at least in theory. I’m a total noob here though so I may be wrong. reply GaggiX 17 hours agorootparentWe were discussing mostly about NPU, I don&#x27;t know if it makes a difference. reply lib-dev 15 hours agorootparentFrom https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple_M1#Memory> The M1 uses a 128-bit LPDDR4X SDRAM in a unified memory configuration shared by all the components of the processor.I assume that includes the NPU, media engine, etc. replynvm0n2 18 hours agoprevWith these improvements llama.cpp&#x2F;ggml is really becoming a pretty competitive serving stack even for large scale cloud hosted AI. I wonder how ggerganov finds the time to do all this, does anyone know if he&#x27;s being sponsored? reply killthebuddha 18 hours agoparentHe founded a startup https:&#x2F;&#x2F;ggml.ai&#x2F; reply selectodude 17 hours agorootparentDoesn’t seem like much of a business model there. reply vineyardmike 17 hours agorootparentIDK, I can see a future. It’s a one-man (for now) business, so minimal costs to consider. If he can swing consulting using the .cpp projects as advertising, that sounds like a good business.Additionally, I can imagine companies investing and paying for the open source work to expand access to their licensed models. Use the same interface as people use LLAMA but upgrade to BetterModel, fully compatible.Additionally, I could believe this is simply a build up to a future Acquihire, which is the most lucrative way to be hired. reply simonw 14 hours agorootparentprevHe also raised a bunch of money, so I guess the plan is to figure out the business model as he goes. reply ngcc_hk 12 hours agoprevWonder about CUDA issue. Some can but most cannot ? reply behnamoh 17 hours agoprevI&#x27;m waiting for someone to comment \"use the page title&#x2F;why did you change the title&#x2F;etc.\". It&#x27;s frustrating when you find something important on a page and type that as the title, and then the post gets flagged because it violates HN rules.For comparison, this is the actual title of the page, but do you think this would increase people&#x27;s awareness about the fascinating fact I highlighted in the title? llama : custom attention mask + parallel decoding + no context swaps #3228 reply solardev 17 hours agoparentYeah, I really hate the \"no changing titles\" rule. I can understand something like \"don&#x27;t sensationalize\", but many articles just have poor titles that lack context. What does that accomplish aside from discouraging readership and discussion? reply mortenjorck 16 hours agorootparentThe rule is officially \"don&#x27;t editorialize\" which I would interpret (perhaps incorrectly) as allowing a little leeway in surfacing a buried lede so long as it&#x27;s presented in neutral language.Something like \"Amazing Llama 2 7B performance on M2 Ultra\" would obviously fail that test, but the current title of \"M2 Ultra can run 128 streams of Llama 2 7B in parallel\" seems to follow the spirit of the rule, at least as I read it. reply solardev 16 hours agorootparentI think the guidelines[1] say not just \"don&#x27;t editorialize\", but (emphasis added):> Otherwise please use the original title, unless it is misleading or linkbait; don&#x27;t editorialize.[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply mtillman 15 hours agorootparentExcept the original title in my experience is always longer than they allow. reply latexr 15 hours agorootparentprev> I really hate the \"no changing titles\" rule.That’s not the rule.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.htmlIt allows for plenty of leeway, and in my experience alternative titles are accepted and will stand unless they are significantly worse than the original. It happens even with major announcements with hundreds of votes. @dang isn’t some mindless robot who must always enforce one way of doing things. The instructions are, as the page title suggests, guidelines. reply solardev 8 hours agorootparentIt specifically says...> If the title includes the name of the site, please take it out, because the site name will be displayed after the link.> If the title contains a gratuitous number or number + adjective, we&#x27;d appreciate it if you&#x27;d crop it. E.g. translate \"10 Ways To Do X\" to \"How To Do X,\" and \"14 Amazing Ys\" to \"Ys.\" Exception: when the number is meaningful, e.g. \"The 5 Platonic Solids.\"> Otherwise please use the original title, unless it is misleading or linkbait; don&#x27;t editorialize.Emphasis on \"Otherwise please use the original title\". I think dang is wonderful and we&#x27;re lucky to have him, but even in my short year or two here, I&#x27;ve seen enough instances of title-policing (not necessarily from him) that discourage me not just from changing titles but sometimes from posting things altogether if the title isn&#x27;t good enough originally. reply latexr 15 hours agoparentprev> It&#x27;s frustrating when you find something important on a page and type that as the title, and then the post gets flagged because it violates HN rules.If that happens to you a lot, consider that perhaps other HN users disagreed with your assessment of what was important on the page and felt mislead when the content didn’t primarily match the tile.Anecdotally, I see alternative titles as being well accepted when the true title is subpar. Especially relevant when the matter concerns GitHub issues (which this is). reply behnamoh 17 hours agoparentprev@dang maybe the rules can be updated to allow for more flexibility? reply latexr 14 hours agorootparentThe rules are flexible. Your parent comment is complaining of something which has not happened. reply behnamoh 12 hours agorootparentIt has happened in some of my previous posts. reply yieldcrv 16 hours agoparentprevyou can leave a comment on the github issue and then link directly to that comment, if it becomes necessary to convey that message under the HN regime reply mistrial9 18 hours agoprevLLaMA2 is English-centric fwiw, censored for safety, and black-box on its contents. Happy to be proved wrong reply extasia 18 hours agoparentYou&#x27;re right, none of that is disputed though? reply mensetmanusman 17 hours agoparentprevThink of the censoring as comedy.It doesn’t like Kanye music and will tell you to listen to the song ‘Happy’ instead.That’s pretty hilariously dystopian and therefore quite funny. reply crooked-v 17 hours agoparentprevOn the second point, there&#x27;s an uncensored version available and assorted trained-for-purpose derivatives of it. reply mholm 17 hours agorootparentAre these uncensored or decensored? If rlhf removes intelligence at any rate, I wouldn’t expect that intelligence to come back with a tune that’s let’s it say curse words and talk about religions reply danielbln 5 hours agorootparentThey are very much uncensored, give it a try yourself: `ollama run llama2-uncensored` [0]It will be happy to curse, talk about religions, help you cook illicit substances or do all sorts of other stuff.[0] https:&#x2F;&#x2F;ollama.ai&#x2F; reply qeternity 16 hours agorootparentprevThe foundation model is not “censored”, it’s the RLHF’d “chat” versions that are. Meta released both. reply mistrial9 17 hours agorootparentprevlinks please! reply mschuster91 17 hours agorootparentYou can run it on ollama: https:&#x2F;&#x2F;ollama.ai&#x2F;blog&#x2F;run-llama2-uncensored-locally reply nomel 16 hours agorootparentThese are not the uncensored models. It&#x27;s a fine tune of the censored models [1].> Filter refusals and bias from the dataset -> finetune the model -> release.The alignment tax should still exist, maybe doubly so.[1] https:&#x2F;&#x2F;erichartford.com&#x2F;uncensored-models#heading-lets-get-... reply kristianp 9 hours agorootparentThe base model is uncensored. From a glance at your link, that is about uncensoring the conversational training set. reply mistrial9 17 hours agorootparentprevthat is interesting, but the \"un-training\" shown by EricH. is simply re-running some fine-tuning on the same public base model, regarding \"refusals\".. and it is expen$ive to do that, too. reply woadwarrior01 14 hours agoparentprevLlama2 based models are actually quite proficient in at least French and German, if not more western european languages. reply behnamoh 17 hours agoparentprevwell, your username suggests you&#x27;d enjoy Mistral 7b more &#x2F;jk reply teen 14 hours agoprev [–] It still can&#x27;t run 10 year old games though (dota 2) reply dagmx 12 hours agoparentYou’re purposefully conflating hardware capability and product availability&#x2F;priority.The hardware can run AAA games today. You might as well say the same thing about the PS5 because it can’t run an Atari game. reply sgjohnson 13 hours agoparentprev [–] I’ve heard that there are some issues of gaming performance on M1&#x2F;2 Ultra specifically (due to it being just 2x M2 Max in the same package), however my M2 Max MacBook absolutely runs Dota 2, and runs it very, very well. Like 180-200fps average well. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The llama.cpp code in a GitHub repository has been updated, incorporating parallel decoding with attention masks to enhance the code's efficiency.",
      "Modifications include improving performance via KV cache optimization, multi-sequence decoding, and updates to RoPE, session saving/loading, as well as parallel processing.",
      "Changes also encompass the disabling of concurrency optimization for graph topology modifications and adaptations in M2 Ultra model size tests."
    ],
    "commentSummary": [
      "The discussion examines the features of Apple's new M2 Ultra chip and analyzes the merits and demerits of utilizing cloud services as opposed to on-premises infrastructure.",
      "It also debates the advantages and disadvantages of self-hosting services versus outsourcing them and explores the potential use of Apple Mac Minis in data centers.",
      "The discussion also touches on the employment of Large Language Models (LLMs) as well as business opportunities and obstacles that arise in connection with an open-source technology called LLAMA."
    ],
    "points": 238,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1697040902
  },
  {
    "id": 37845903,
    "title": "K3s – Lightweight Kubernetes",
    "originLink": "https://k3s.io/",
    "originBody": "Skip to main content Docs GitHub Lightweight Kubernetes The certified Kubernetes distribution built for IoT & Edge computing This won't take long… curl -sfL https://get.k3s.iosh - # Check for Ready node, takes ~30 seconds sudo k3s kubectl get node For detailed installation, refer to the docs Great For Edge IoT CI ARM Why Use K3s Perfect for Edge K3s is a highly available, certified Kubernetes distribution designed for production workloads in unattended, resource-constrained, remote locations or inside IoT appliances. Simplified & Secure K3s is packaged as a single <70MB binary that reduces the dependencies and steps needed to install, run and auto-update a production Kubernetes cluster. Optimized for ARM Both ARM64 and ARMv7 are supported with binaries and multiarch images available for both. K3s works great on something as small as a Raspberry Pi to an AWS a1.4xlarge 32GiB server. How it Works The above figure shows the difference between K3s server and K3s agent nodes. For more information, see the architecture documentation. Get Started 1. Download K3s - latest release: x86_64, ARMv7, ARM64, and s390x are supported 2. Run server sudo k3s server & # Kubeconfig is written to /etc/rancher/k3s/k3s.yaml sudo k3s kubectl get node # On a different node run the below command. # NODE_TOKEN comes from /var/lib/rancher/k3s/server/node-token on your server sudo k3s agent --server https://myserver:6443 --token ${NODE_TOKEN} Learn More Read the latest SUSE Rancher blog on K3s. Blog Watch the latest \"Up and Running: K3s\" Online Training. Watch Training We are a Cloud Native Computing Foundation sandbox project. Copyright © 2023 K3s Project Authors. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page.",
    "commentLink": "https://news.ycombinator.com/item?id=37845903",
    "commentBody": "K3s – Lightweight KubernetesHacker NewspastloginK3s – Lightweight Kubernetes (k3s.io) 237 points by kristianpaul 23 hours ago| hidepastfavorite178 comments intangible 21 hours agoI&#x27;ve been using a 3 nuc (actually Ryzen devices) k3s on SuSE MicroOS https:&#x2F;&#x2F;microos.opensuse.org&#x2F; for my homelab for a while, and I really like it. They made some really nice decisions on which parts of k8s to trim down and which Networking &#x2F; LB &#x2F; Ingress to use.The option to use sqlite in place of etcd on an even lighter single node setup makes it super interesting for even lighter weight homelab container environment setups.I even use it with Longhorn https:&#x2F;&#x2F;longhorn.io&#x2F; for shared block storage on the mini cluster.If anyone uses it with MicroOS, just make sure you switch to kured https:&#x2F;&#x2F;kured.dev&#x2F; for the transactional-updates reboot method.I&#x27;d love to compare it against Talos https:&#x2F;&#x2F;www.talos.dev&#x2F; but Talos&#x27;s lack of support for a persistent storage partition (only separate storage device https:&#x2F;&#x2F;github.com&#x2F;siderolabs&#x2F;talos&#x2F;issues&#x2F;4041 ) really hurts most small home &#x2F; office usage I&#x27;d want to try. reply imiric 19 hours agoparentThanks for your perspective.How has your experience been with Longhorn? Performance, flexibility, issues, maintenance...? I&#x27;m interested in moving away from a traditional single-node NAS to a cluster of storage servers. Ceph&#x2F;Rook seem daunting, and I&#x27;d prefer something easy to setup and maintain, that&#x27;s performant, reliable and scales well. Discovering issues once you&#x27;re fully invested in a storage solution is a nightmare I&#x27;d like to avoid. :) reply sgarland 16 hours agorootparentCeph is a nightmare if you don’t set it up exactly how the docs say - and in fairness, the docs are excellent.My advice, having done Ceph&#x2F;Rook, Longhorn, and now Ceph via Proxmox is the latter, assuming you have access to an actual host. Proxmox-managed Ceph is a dream, and exposing it to VMs and then K8s via RBD is easy.Longhorn is fairly easy to set up, but its performance is terrible in comparison. reply imiric 15 hours agorootparentThanks for the insight. I&#x27;ve tried Proxmox before, and as much as I appreciate what it does, it&#x27;s mostly a black box. I prefer a more hands-on approach, as long as the docs are comprehensible, and the solution is simple enough to manage without a special degree. Ceph always seemed daunting, and I&#x27;ve mostly ruled it out, which is why these k8s-native solutions are appealing.Good to know about the performance. This is not critical for my use case, but I guess I&#x27;ll need to test it out for myself, and see whether it&#x27;s acceptable. reply pas 3 hours agorootparentCeph is ... well, it&#x27;s an amazing journey. Especially if you were there when it started, and watched as each release made it more capable & crazier.From the earily days of trying to remember WTF the CRUSH and \"rados\" acronyms actually meant and focusing on network and storage concerns and [0] ... architectural optimizations [1] ... a RedHat acquisition ... adjusting to the NVMe boom [2] ... and then Rook, probably one of the first k8s operators trying to somehow operate this underwatere beast in a sane manner.If you are interested in it ... set it up manually once (get the binaries, write config files, generate keyrings, start the monitors, set up OSDs, RGW and you can use FileZilla or any S3 client). For some more productionish usage there&#x27;s a great all-in-one docker image https:&#x2F;&#x2F;quay.io&#x2F;repository&#x2F;ceph&#x2F;ceph?tab=tags .[0] oh don&#x27;t forget to put the intra-cluster chatter on an internal network, or use a virtual interface and traffic shaping to have enough bandwidth for replication and restore, and what to do if PGs are not pairing and OSDs are not coming up][1] raw block device support, called BlueStore, which basically creates a GPT partitioned device, with ~4 partitions, stores the object map in LevelDB - and then later RocksDB[2] SeaStore, using the Seastar framework, SPDK and DPDK, optimize everything for chunky block I&#x2F;O in userspace reply sgarland 1 hour agorootparentprev> I prefer a more hands-on approach ... which is why these k8s-native solutions are appealing\"K8s-native\" here implies Rook, which is in no way hands-on for Ceph.> as long as ... the solution is simple enough to manage without a special degreeCeph is not simple, that&#x27;s my point. I assume you&#x27;ve read the docs [0] already; if not, please do so _in their entirety_ before you use it. There are so many ways to go wrong, from hardware (clock skew due to BIOS-level CPU power management, proper PLP on your drives...), to configuration (incorrect PG sizing, inadequate replication and&#x2F;or EC settings...) and more.I&#x27;m not trying to dissuade you from tackling this, I&#x27;m just saying it is in no way easy or simple. Statements like \"k8s-native solutions\" always make me cringe, because it usually means you want to use an abstraction without understanding the fundamentals.To be clear, I have read the docs, set it up on my own, and decided I didn&#x27;t want to try to manage it. I&#x27;ve ran a ZFS pool for a few years on Debian and shifted over to TrueNAS Scale last week; not because I was unable to deal with ZFS&#x27; complexity (knock on wood, the only [temporary] data loss I ever had was an incorrect `rm -rf`, and snapshots fixed that), but because of continual NFS issues. I may yet switch back; I don&#x27;t know - I just no longer had the time to troubleshoot the data layer. Ceph makes ZFS looks like child&#x27;s play in comparison.[0]: https:&#x2F;&#x2F;docs.ceph.com&#x2F;en&#x2F;latest&#x2F; reply MPSimmons 17 hours agorootparentprevI&#x27;ve run Rook&#x2F;Ceph, and I run Longhorn right now. I wish I didn&#x27;t, and I&#x27;m actively migrating to provider-managed PVs.My advice for on-prem is to buy storage from a reliable provider with a decent history of hybrid flash&#x2F;ssd, so that you can take advantage of storage tiering (unless you just want to go all flash, which is a thing if you have money).If you must use some sort of in-cluster distributed storage solution, I would advise you to exclude members of your control plane from taking part, and I would also dedicate entirely separate drives and volumes for the storage distribution so that normal host workload doesn&#x27;t impact latency and contention for the distributed storage. reply imiric 15 hours agorootparentGood points, thanks. What makes you wish you didn&#x27;t use Rook&#x2F;Ceph&#x2F;Longhorn?In a professional setting, and depending on scale, I&#x27;d probably rely on a storage provider to manage this for me. But since this is for my homelab, I am interested in a DIY solution. As a learning experience, to be sure, but it should also be something that ideally won&#x27;t cause maintenance headaches.Keeping separate volumes makes sense. I can picture three tiers: SSDs outside of the distributed storage dedicated to the hosts themselves, SSDs part of distributed storage dedicated to the services running on k3s, and HDDs for the largest volume dedicated to long-term storage, i.e. the NAS part. Eventually I might start moving to SSDs for the NAS as well, but I have a bunch of HDDs currently that I want to reuse, and performance is not critical in this case. reply MPSimmons 15 hours agorootparent>Good points, thanks. What makes you wish you didn&#x27;t use Rook&#x2F;Ceph&#x2F;Longhorn?It seems like my volumes are constantly falling into degraded and then rebuilding. Resizing volumes requires taking the workload that&#x27;s attached down, and then it seems to take forever (15m+) for my clusters to figure out that the pod is gone and a new pod is trying to attach.Really, it&#x27;s a PITA and all of the providers&#x27; storage classes seem better than Longhorn. Ceph I had less experience with but very similar problems - long-gone pods held a lock on PVCs that had to be manually expunged, or wait for a very long timeout. reply organsnyder 1 hour agorootparentI&#x27;ve had similar issues with Mayastor (another in-cluster storage solution). It&#x27;s under heavy development, so I&#x27;ve assumed the more mature options were better.I&#x27;m working on v2 of my homelab cluster, and I&#x27;m going with plain old NFS to a file server with a ZFS pool. Yes, I will have a single node as a point of failure, but with how much pain I&#x27;ve had so far I think I&#x27;ll be coming out ahead in terms of uptime. reply iamdbtoo 18 hours agorootparentprevI can&#x27;t speak to performance because the workloads aren&#x27;t really intense, but I run a small 3 node cluster using k3s and Longhorn and Longhorn has been really great.It was easy to setup and has been reliably running with very minimal maintanence since. reply arcastroe 11 hours agorootparentIf you use longhorn, make sure to enable the network policies when installing the helm chart. For some odd reason, these are disabled by default, which means ANY pod running on your cluster has full access to the longhorn manager, API, and all your volumeshttps:&#x2F;&#x2F;github.com&#x2F;longhorn&#x2F;charts&#x2F;blob&#x2F;v1.5.x&#x2F;charts&#x2F;longho... reply intangible 18 hours agorootparentprevI wouldn&#x27;t really treat it as a replacement for a NAS, mostly only for the container workloads running on kubernetes itself... Ideally, any apps you develop should use something more sane like object storage (Minio etc) for their data.I push it pretty minimally right now, so no great performance testing myself, and I do run it in synchronous mode, so that means its write performance is likely going to be limited to the 1gbps network it syncs over. reply organsnyder 21 hours agoparentprevFunny: I&#x27;ve been running a Talos cluster for the past six months, and just today decided to look into k3s. Talos has a lot of really nice things, but I have found that the lack of shell access can be frustrating at times when trying to troubleshoot. reply davkan 9 hours agorootparentCurious, what have you run into that you couldn’t troubleshoot with a privileged pod with host networking? reply organsnyder 2 hours agorootparentI had a situation where the etcd cluster got hosed, making it basically impossible (at least with the ways I know) to interact with the k8s API at all. So I didn&#x27;t have any way to get a privileged pod running. reply osigurdson 20 hours agoparentprevKudos to you. I feel like setting things up on real hardware is somehow needed in order to make things concrete enough to full understand. At least for me (I fully admit this may be a personal flaw) working with a vm on in the cloud is a little too abstract - even though eventually this is where things will land. reply c0wb0yc0d3r 16 hours agoparentprevHow did you go about deploying k3s to MicroOS? Did you go the route of installing it via combustion and a systemd unit?[0]To me it seems strange that a systemd unit is used, but I didn&#x27;t know if I was missing something about the way MicroOS worked.[0]: https:&#x2F;&#x2F;en.opensuse.org&#x2F;SDB:K3s_cluster_deployment_on_MicroO... reply sgarland 16 hours agoparentprevRe: Talos persistent storage, why not run it as a VM and pass in block devices from the hypervisor? You also then gain the benefit of templated VMs that you can easily recreate or scale as needed. reply diggan 22 hours agoprev\"Lightweight Kubernetes\" and then a graph involving 2 different nodes with 10+ services running on them.Nomad seems to be a truly \"lightweight Kubernetes\" and for the small amount of time I&#x27;ve been using it, it seems to do it&#x27;s job really well and it&#x27;s easy to understand all the moving pieces without spending countless of hours reading docs and source code.Although, it&#x27;s hard to recommend Nomad for future uses as it sadly stopped being FOSS :&#x2F; reply themgt 21 hours agoparentNomad seems to be a truly \"lightweight Kubernetes\"k3s requirements: 1 node, 512MB RAM, 1 CPU coreNomad requirements: \"Nomad servers may need to be run on large machine instances. We suggest having between 4-8+ cores, 16-32 GB+ of memory, 40-80 GB+ of fast disk and significant network bandwidth.\"https:&#x2F;&#x2F;docs.k3s.io&#x2F;installation&#x2F;requirementshttps:&#x2F;&#x2F;developer.hashicorp.com&#x2F;nomad&#x2F;docs&#x2F;install&#x2F;productio... reply proxysna 5 hours agorootparentThis is for large deployments in prod. Nomad and Consul servers at home are running on an old Rpi3 with 2G of ram managing several devices and about 10 vm&#x27;s. Larger deployment of ~30vm&#x27;s was managed with a nomad&#x2F;consul cluster of 3x2cpu4ram with no issues. reply rickette 20 hours agorootparentprevHashicorp is playing safe here, Nomad can do with far far less resources. reply alanwreath 20 hours agorootparentThat can be said of many systems, does hashicorp document it though? I’m guessing they must, otherwise that would be the first thing you hear on the other side of a support call. reply sleepybrett 19 hours agorootparentalso with hashicorps new licensing regime... reply pojzon 18 hours agorootparentThat does not impact 99% of ppl..The licence change impacts only companies like Digger or Spacelift that build their platform abusing TF oss offering. reply emptysongglass 5 hours agorootparentThat&#x27;s a bad take and you know it. HashiCorp couldn&#x27;t make money because their enterprise offering was slim on features and overpriced. Rather than compete, they&#x27;re playing protect-the-castle with some aggressive plays to keep their company afloat. They&#x27;re bad stewards of open source (always have been) and are now getting their just desserts. replyOhSoHumble 21 hours agoparentprevI&#x27;ve commented on this before in a different k8s thread (one about a k8s outage) but something that bears repeating is that the entire job market is Kubernetes.My personal experience is that it is very, very hard to find a job right now if your professional experience is primarily non-k8s orchestration systems. Most job positions out there require deep Kubernetes knowledge as well as hands-on experience with different supporting products like ArgoCD and Flux.I chose Nomad for a large initiative at my current employer and it is honestly pretty amazing given the use case but I regret choosing it because I feel like I&#x27;m unhirable now given that every devops&#x2F;SRE&#x2F;platform engineering position open on the market (each one with hundreds of applicants) is heavily Kubernetes focused. reply umvi 20 hours agorootparentA lot of smaller SaaS companies avoid k8s like the plague and only start using it once they scale to a certain size. K8s might be ubiquitous past a certain scale, but there are many jobs operating below the threshold for which the complexity of your system with k8s outweighs the complexity of your system without k8s. reply hobofan 19 hours agorootparentIf you find yourself on the Google cloud for some reason, GKE Autopilot is such a great hands-off solution that most alternative solutions will probably be more complex.I only recently had to use AWS EKS, and am pretty sure that many people dislike k8s because that&#x27;s the main incarnation of it they experience (how is there no pre-installed ingress, and even the setup for their own load balancer is a 10+ step manual process?). reply hhh 17 hours agorootparentIt is really weird that the AWS Load Balancer Controller isn&#x27;t an EKS Addon, and the permissions requirements being in the base requirements for EKS. Also, the only officially supported CNI is the VPC CNI.And if you want to use EKS-A (EKS-Anywhere) it&#x27;s even more effort to do the AWS IRSA setup. reply umvi 17 hours agorootparentprevI use GCP, and it&#x27;s hard for me to imagine something simpler than docker containers in Cloud Run which works for most of my use cases. reply hobofan 9 hours agorootparentCloud Run is just Knative which is also Kubernetes, so in the end it comes out to about the same. I used to use Cloud Run, but in the end there were usually always some things that ended up making GKE the more convenient choice (e.g. access to Helm charts). reply plagiarist 10 hours agorootparentprevInstalling an ingress controller that will do SSL is a steep cliff preventing use with so many cloud Kubernetes offerings. I don&#x27;t know why it needs to have dozens of steps, roles, and resource definitions. reply hobofan 9 hours agorootparentYeah, though I have to admit that even though you get SSL certificates \"out of the box\" with a GKE + GCP load balancer setup, their provisioning has always been really slow for me (usually 1-2h, sometimes half a day). In comparison self-installed nginx-ingress + Let&#x27;s Encrypt provisions in minutes. reply sharts 13 hours agorootparentprevIf that is so then the industry has a lot to recon with soon because that would mean most at chasing a shiny new thing for absolutely all the wrong reasons.K8s is complete overkill at best for the majority of companies&#x2F;workloads and introduces lots of other dependencies on teams in terms of workflows and architectures to make things not be a dumpster fire for all but very mature teams. reply bshacklett 1 minute agorootparentI keep hearing this viewpoint, but I really don’t understand it. I use k3s for all sorts of personal projects, specifically because it makes things easier for me. I don’t have to worry about the underlying OS. I can focus on the application that’s actually providing value for me.On the professional side, k8s handles orchestration issues far better than anything else I’ve worked with. Using autoscaling instances is a nightmare by comparison, and requires most of the same initial effort to do it right.There is probably a middle ground where it requires a certain amount of complexity in the K8s configuration that isn’t worth it compared to other platforms (especially on bare metal), but I haven’t found it, yet.I think it’s easy to forget how much goes into running even a simple application with high uptime requirements. Kelsey Hightower makes some great points about this here:https:&#x2F;&#x2F;youtu.be&#x2F;Ty5Tj4Jag_A?si=CPkAIqiwKk7g4Oh5 reply qudat 21 hours agorootparentprevPlease forgive the slight tangent but Aptible (the most successful PaaS you never heard of) is hiring and we don’t use Kuberneteshttps:&#x2F;&#x2F;www.aptible.com&#x2F;culture-hub&#x2F;careers reply figmert 22 hours agoparentprevNomad also doesn&#x27;t have nearly half of the features that Kubernetes does. Need service discovery? Set up a Consul cluster. Need secret management? Install vault. Need vault enterprise? Install a separate Consul cluster! This was a few years ago, maybe it&#x27;s changed? I dunno.Anyway, lightweight here means that whole bunch of external dependencies have been ripped out. E.g. AWS&#x2F;GCP&#x2F;Azure and I believe other things too. reply proxysna 22 hours agorootparentYou can have sd and secrets with just nomad now, it is perfect for small projects in that way.K8s also can do secrets! base64 encoded secrets! But in case you need a more secure solution. Please pull in a Vault helm chart or mess around with sops or whatever. Want to scale out? See how long it will take you until you will have to move your etcd to dedicated hw&#x2F;vm&#x27;s. And let me tell you - setting up external etcd in prod sucks. Also maintaining mission control, because there is a bunch of ways to do things and devs love using things that they are not supposed to touch.Nomad approach is modular this is why it works. Need proper multi dc SD? please run a consul cluster (single binary + single config file)x3. Need mesh networking? same. Need secrets? Vault (single binary + single config file)x3. Pki? same. Or maybe you don&#x27;t need it? Then you have an option to just not use it.One thing that i really don&#x27;t like about it that there is not a lot of docs describing all the ways these tools can interact with each other. reply ownagefool 20 hours agorootparentK8s supports encryption at rest, ACLs and audit logs.What it actually lacks is versioning, and a dynamic secrets engine, though you could build that with an operator, and things like the postgres-operator do.You also don&#x27;t get the whole sealing thing, but I&#x27;d argue that&#x27;s more annoying than useful. reply sleepybrett 19 hours agorootparent> You also don&#x27;t get the whole sealing thing, but I&#x27;d argue that&#x27;s more annoying than useful.A-fucking-men. reply vosper 14 hours agorootparentprevWhat&#x27;s \"sealing\" in this context? reply proxysna 4 hours agorootparentUnsealing is the process of obtaining the plaintext root key necessary to read the decryption key to decrypt the data, allowing access to the Vault.Prior to unsealing, almost no operations are possible with Vault. For example authentication, managing the mount tables, etc. are all not possible. The only possible operations are to unseal the Vault and check the status of the seal.https:&#x2F;&#x2F;developer.hashicorp.com&#x2F;vault&#x2F;docs&#x2F;concepts&#x2F;seal reply riku_iki 20 hours agorootparentprev> Need service discovery? Set up a Consul cluster. Need secret management? Install vault.I am not an expert in this topic, but I read that they added lightweight solutions for both usecases inside nomad in latest version. reply mfer 22 hours agoparentprevYou can run k3s with a single node. In that case it uses sqlite instead of etcd which is great for a smaller resource footprint. If you&#x27;re comparing k8s distros, you&#x27;ll be hard pressed to find a setup that uses fewer system resources. reply nullify88 18 hours agorootparentIs it actually smaller though? For those non etcd data stores, Kine is often the component doing an etcd to database translation. Im my experience using it generated a load that was greater than a one node etcd instance. reply andreasmetsala 22 hours agoparentprev> Nomad seems to be a truly \"lightweight Kubernetes\" and for the small amount of time I&#x27;ve been using it, it seems to do it&#x27;s job really well and it&#x27;s easy to understand all the moving pieces without spending countless of hours reading docs and source code.Does Nomad expose an API that you can extend with controllers running inside the cluster? Because Kubernetes without operators is not Kubernetes. reply illamint 13 hours agorootparent> Because Kubernetes without operators is not Kubernetes.Alright, so, what is it, then? I&#x27;ve been unfortunate to work at firms that generally have a minimal level of competency with Kubernetes, but across several billion dollars worth of firms, not a one has used operators in any capacity, but they leverage Kubernetes substantially. Help me understand the gap, would you? reply proxysna 22 hours agorootparentprevyes, you can do that. Here&#x27;s an example. https:&#x2F;&#x2F;andydote.co.uk&#x2F;2021&#x2F;11&#x2F;22&#x2F;nomad-operator-pattern&#x2F; reply moondev 14 hours agorootparent> While Nomad doesn’t support the idea of Custom Resource Definitions, we can achieve an operator by utilising a regular Nomad job and the nomad HTTP API.Kubernetes operator is a combination of a CRD reconciled by a controller. Without the CRD it&#x27;s simply a controller.I do like the linked post, it&#x27;s well written and a valiant effort, but not close to comparable. reply doctorpangloss 21 hours agoparentprev> \"Lightweight Kubernetes\" and then a graph involving 2 different nodes with 10+ services running on them.Among its many strengths, core services for running Kubernetes running inside Kubernetes itself is one of its greatest.> it&#x27;s easy to understand all the moving piecesIt&#x27;s legit to leverage your pre-existing knowledge. Nomad + Linux Pets + Other Hashichorp Pets works well.There are many ways to run an application. Kubernetes + Machine Cattle, in my experience having started from zero, is superior to any other application deployment paradigm I&#x27;ve ever used. reply chrisweekly 20 hours agorootparent\"Machine Cattle\"? reply quickthrower2 19 hours agorootparentProbably a reference to the pets v cattle analogy http:&#x2F;&#x2F;cloudscaling.com&#x2F;blog&#x2F;cloud-computing&#x2F;the-history-of-... reply sleepybrett 19 hours agorootparentprevTreat your machines like cattle, not pets. When I used to run kubernetes in the pre-&#x27;kube as a service&#x27; days. We had two autoscaling groups, one which had 3 or 5 nodes in it to run the control plane nodes and an open eneded one for workers (which were managed by the cluster autoscaler). Each ASG was set up in such a way that the nodes would come up and join the cluster fully automated and they never needed to be shelled into for anything but troubleshooting the weirdest failures (it was early days, the kubelet and docker had some extra fun bugs). reply chrisweekly 19 hours agorootparentOk sure, I&#x27;m very familiar w the cattle vs pets analogy &#x2F; meme -- but the (capitalized!) \"Machine Cattle\" made it seem like a reference to a particular software tool or product. reply proxysna 22 hours agoparentprevNomad is an alternative to k8s, but it is not really a \"lightweight k8s\". Nomad and k8s are way to different to call them versions of eachother. And the whole license thing. Nothing changed for end users. reply cortesoft 20 hours agoparentprevK3s uses the exact same API as Kubernetes. Nomad does not.The idea is to more easily get going with Kubernetes, not to provide an alternative. Nomad and K3s serve a completely different use case. reply q3k 22 hours agoparentprevI mean, 2 nodes and 10 services is very light for what Kubernetes is designed to scale to. reply alanwreath 20 hours agoparentprevI think the tagline can be a bit misleading, you can run k3s on devices traditionally considered IoT (like the raspberry pi) but it will run on big heavy x86 servers too. reply WJW 22 hours agoparentprevNomad is a lightweight container orchestrator, not a lightweight Kubernetes. The whole point is to keep syntax, terminology and config options etc as similar as possible between k8s and k3s. reply worksonmine 22 hours agoparentprevThe amount of services running is not an indication of how lightweight the underlying tech is. K3S is for orchestration across nodes, and by design you can&#x27;t run services on the master for security reasons unless you manually change it.Are you trying to say that 10 services and 2 nodes would be less on Nomad? reply tarruda 22 hours agorootparent> K3S is for orchestration across nodes, and by design you can&#x27;t run services on the master for security reasons unless you manually change it.That has not been my experience with k3s. Unlike normal distributions, k3s servers do allow workload to run on them unless you manually disable. From https:&#x2F;&#x2F;docs.k3s.io&#x2F;datastore&#x2F;ha-embedded :\" An HA K3s cluster with embedded etcd is composed of: - Three or more server nodes that will serve the Kubernetes API and run other control plane services, as well as host the embedded etcd datastore. - Optional: Zero or more agent nodes that are designated to run your apps and services \"So you can have a full HA k3s cluster with only 3 server nodes and 0 agent(worker) nodes. reply sleepybrett 19 hours agorootparentThis is not true of k8s in general, maybe certain on prem &#x27;distributions&#x27; enforce this, i&#x27;m not sure. Sometimes kubernetes admins&#x2F;operators who are running their own control planes and etcd will run etcd on non k8s controlled nodes, or they will run it on the same nodes that run their control plane services (scheduler, apiserver, controller manager, etc). Often those nodes will be tainted in such a way that they don&#x27;t get overloaded by a noisy neighbor &#x27;customer pod&#x27;, but that&#x27;s in no way &#x27;by design&#x27;.. perhaps by convention or best practice. reply worksonmine 14 hours agorootparentYeah, design was probably a poor choice of words, s&#x2F;design&#x2F;default&#x2F;. reply worksonmine 14 hours agorootparentprevYes, you can ignore the warnings and change the defaults, like I said?> unless you manually change itI ran into this myself just the other day. reply BossingAround 22 hours agoprevInterestingly, SUSE now owns Rancher [0], so k3s has been backed by a large company for some time now. I&#x27;ve never tried k3s, but I have always thought it&#x27;s probably the most loved-by-its-users version of Kubernetes.[0] https:&#x2F;&#x2F;www.suse.com&#x2F;news&#x2F;suse-completes-rancher-acquisition... reply mfer 22 hours agoparentIf you want to easily try it out, we baked it into Rancher Desktop [1]. RD let&#x27;s you run Kubernetes (via k3s) and containers on your desktop. You pick the k8s version.[1] https:&#x2F;&#x2F;rancherdesktop.io&#x2F;Disclosure, I work for SUSE and started Rancher Desktop. reply hczedik 19 hours agorootparentRancher Desktop is great!We use it as a free replacement for Docker Desktop and it works very well.Unfortunately, we cannot use the Kubernetes part of it because it comes with \"steve\" (used for dashboards), which uses and blocks (!) the same ports as our application, and those ports are not configurable. So, please please solve this request here: https:&#x2F;&#x2F;github.com&#x2F;rancher-sandbox&#x2F;rancher-desktop&#x2F;issues&#x2F;18... reply willaaam 22 hours agorootparentprevI just made an account here to say thank you. Rancher desktop is amazing on my M2 mac, it&#x27;s easy to use, solves a bunch of challenges from k8s to docker and has been surprisingly reliable for a young product. reply cortesoft 20 hours agorootparentprevI love Rancher Desktop. Thank you! reply withinboredom 22 hours agorootparentprevI&#x27;ve honestly been scared to switch from Docker Desktop to Rancher Desktop on Windows. Like do I have to switch or do they play nice together? Do I need to install Docker in WSL to use it, or kubectl, or is it like Docker Desktop where it \"just works.\"So many questions... reply mfer 21 hours agorootparentYou can have Docker Desktop and Rancher Desktop installed on the same Windows machine. Last I checked, you can&#x27;t run them both at the same time due to docker socket locations (assuming you run Rancher Desktop using Moby).Rancher Desktop will provide the CLI tools to work with it.The idea is \"it just works\". It&#x27;s a desktop app so it installs what you need. reply merb 21 hours agoparentprevk3s is not just backed by suse its also a cncf sandbox project: https:&#x2F;&#x2F;www.cncf.io&#x2F;projects&#x2F;k3s&#x2F; reply mariuz 1 hour agoprevK3s and hetzner relatedhetzner-k3s : This is a CLI tool to quickly create and manage Kubernetes clusters in Hetzner Cloud using the lightweight Kubernetes distribution k3s from Rancher. https:&#x2F;&#x2F;github.com&#x2F;vitobotta&#x2F;hetzner-k3sKubernetes on Hetzner Cloud the easiest way https:&#x2F;&#x2F;vitobotta.com&#x2F;2023&#x2F;01&#x2F;07&#x2F;kubernetes-on-hetzner-cloud... reply einstand 21 hours agoprevMy favorite presentation about K3s is when Darren Shepherd explains all the black magic (=all the custom patches) which made it possible:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=k58WnbKmjdA reply rcarmo 19 hours agoparentthis is highly recommended. reply rmelton 22 hours agoprevK3s is fantastic especially for local development with Kubernetes when orchestrated using k3d. This is what we use for most of our internal K8s testing at OpenC3. reply doctoboggan 22 hours agoparentYes, I recently moved my Dev team to K3D as well. Previously we were using AWS clusters that were spun up on demand every time someone needed to test something. the time needed to do this grew and grew overtime eventually coming close to 30 to 40 minutes. With k3d testing locally can be done in a minute. Plus I learned a ton about k8s while doing this. reply FourSigma 22 hours agoprevCould someone please explain the difference between K0s[1] and K3s? They seem to both target the same minimalist K8s segment.[1]https:&#x2F;&#x2F;k0sproject.io&#x2F; reply r-bar 22 hours agoparentK3S includes some extras that make it nice for working in small local clusters, but are not part of the standard k8s codebase.* Traefik daemonset as a load balancer* Helm controller that lets you apply helm manifests without the helm command line* Upgrade controller* Sqlite as the default backing store for the k8s API* Their own local storage provisionerK0S has a lot of the same goals: be light weight and self contained in a single binary. But K0S tries to be as vanilla as possible.Choosing between the two it comes down to your use case. Do you want light weight and compatible (k0s), or lightweight and convenient (k3s)?Edit: formatting reply nullify88 19 hours agorootparentWhat you&#x27;ve listed for k3s is mostly included in k0s. I wouldnt go far to say k0s isnt convenient.* A helm controller is included in k0s* Etcd is bundled and bootstrapped automatically which I perfer because I dont want the overhead of the translation that Kine does. Although Kine is available for a non-etcd datastore if that is preferred.* Upgrade controller is included (autopilot).* They have a local storage provider based on OpenEBS.* Ingress is missing, but due to the built in helm controller that can be boot strapped upon cluster initialisation.Overall, together with k0sctl and its declarative configuration it is easier to deploy k0s than it was k3s. reply pas 3 hours agorootparentCan you please elaborate on the \"kine\" overhead? reply nullify88 20 minutes agorootparentKine (https:&#x2F;&#x2F;github.com&#x2F;k3s-io&#x2F;kine) is a shim or an external process (when not k3s) that translates the etcd api to enable compatibility with a database or alternative data store. Kubernetes natively talks etcd, so this translation is what enables its usage with sqlite or another database, but it incurs an overhead.I don&#x27;t have specific numbers unfortunately since it was years ago I benchmarked Kine against etcd. But I had a better results with etcd both in cluster and single node.I happened to stumble upon this paper thag expains some differences in latency and cpu utilisation when compared to other distributions https:&#x2F;&#x2F;programming-group.com&#x2F;assets&#x2F;pdf&#x2F;papers&#x2F;2023_Lightwe... reply FourSigma 21 hours agorootparentprevThank you! Great details. Definitely want convenient. reply mad_vill 1 hour agoprevIf you want to get an HA k3s cluster going quickly on your cloud-provider of choice: https:&#x2F;&#x2F;github.com&#x2F;cluster-api-provider-k3s&#x2F;cluster-api-k3s reply nunez 21 hours agoprevThere are lighter Kubernetes \"distributions\" (kind, minikube), but what makes k3s special is that it&#x27;s (a) packaged as two binaries that provide all of the Kubernetes components in one, and (b) it&#x27;s 100% suitable for production use.Lots of teams are using K3s to run Kubernetes at the edge and in IoT applications, and with good reason. It&#x27;s a fantastic Kubernetes distribution that&#x27;s well-maintained, easy to get going with and well-documented.(Ironically, if you look at the first commits to kubernetes&#x2F;kubernetes, the Kubernetes components were originally shipped as a single binary. They decided to break them up later to simplify releasing, but the k3s monolith lives on.) reply koito17 17 hours agoprevI&#x27;ve been running k3s on my home server and it&#x27;s been painless to set up compared to other options (e.g. kubeadm) while also being very lightweight. For single-node setups, it defaults to Kine instead of etcd, using SQLite as the database. This removes a significant chunk of overhead for dev clusters and running in tiny devices.It also has Traefik set up with sane defaults, and the local path provisioner is also pretty good, too. But recently I&#x27;ve moved to Longhorn since I plan to eventually scale past 1 node. My only complaint about Longhorn is that applications that are write-heavy and delete old data (e.g. Prometheus with short retention) will require aggressive trimming (e.g. trim once a day) to keep the actual size of volumes down. Besides that, Longhorn makes backups to S3-compatible storage very effortless and you get RWX volumes, too!Regarding k3s itself, you can persist modifications to the way some components (e.g. Traefik) are installed through a HelmChartConfig CRD. This is what I personally use so I can use Traefik to route SSH traffic for Forgejo. Another nice thing is that although components like kube-proxy are baked in to the single k3s binary, you can still scrape metrics with Prometheus provided that you expose their endpoints somewhere on your cluster network. reply onionisafruit 22 hours agoprevK3s&#x27; go.mod[0] is insane.[0] https:&#x2F;&#x2F;github.com&#x2F;k3s-io&#x2F;k3s&#x2F;blob&#x2F;master&#x2F;go.mod reply sleepybrett 19 hours agoparentEvery kubernetes project&#x27;s go.mod is quite robust. Kubernetes is a very large codebase. reply rcarmo 22 hours agoprevIf anyone wants a ready-to-go Azure template to play around, here you go:https:&#x2F;&#x2F;github.com&#x2F;rcarmo&#x2F;azure-k3s-cluster(I tweak this every now and then since I both used it as a training sample for my customers&#x2F;peers and as a way to run my own batch processes as cheap as possible) reply sidcool 22 hours agoprevWe have been using K3S in production now for 2 years. And it&#x27;s working like a charm. reply inssein 22 hours agoprevLoving K3S so far, I&#x27;ve got a \"homelab\" of 4 RPis running it and so far it has been pretty seamless experience. reply rigelina 20 hours agoparentThis was my introduction to K3s as well. RPis running K3s with enough resources left over to actually do some small tasks. I hosted a small data pipeline that analyzed trading data from an MMO. It was as fun as it was impractical, and I learned quite a bit. reply selljamhere 19 hours agoprevI had a great k3s experience with a silly, over engineered weekend project to automate my fog machine with motion sensors.I connected motion sensors to battery & wifi enabled RPis, built a remote circuit to control the fog machine, and ran a k3s cluster with NATS to bring it all together. 10&#x2F;10 would do again.https:&#x2F;&#x2F;blog.apartment304.com&#x2F;fog-machine-madness&#x2F; reply ddejohn 17 hours agoparentNo pictures of fog machine and spooky graveyard -- 4&#x2F;10 reply selljamhere 16 hours agorootparentUpdated. reply mpsprd 22 hours agoprevCan this tool help to simplify self hosting implems? K3s was recommended to me to replace my personal pile of systemd units starting docker compose configs and manual reverse proxy configs.Im am completely oblivious to how k8s works. reply dewey 22 hours agoparentCheck out https:&#x2F;&#x2F;kamal-deploy.org, it just hit 1.0 and 37signals moved their whole Kubernetes stack to it. I was playing around with it recently for side projects and I think it&#x27;s a nice fit for simpler products like that. reply dinosaurdynasty 20 hours agoparentprevsystemd units are fine. It&#x27;s even pretty close to the recommendations for podman.You can use something like Ansible to make it a bit easier, if that even makes sense in your use case. reply ozarker 22 hours agoparentprevI use it for self hosting. It really simplified my reverse proxy config like you said. I use the internal networking between services quite a bit. I have it auto-provisioning volumes on my NAS and using them via NFS. I love it to death and would say it has simplified my setup overall. But the upfront cost of learning k8s is indeed high. reply MrOwen 19 hours agorootparentSeconding this as well. Similar setup (though I opted for longhorn) and journey. I&#x27;m very grateful for learning k8s but man, it was definitely rough for a long while until I really understood all the pieces and cemented my understanding. I can very much appreciate that&#x27;s a tall order for many people and not wanting to embark on that journey unless there&#x27;s a good reason. reply hhh 22 hours agoparentprevK3s&#x2F;k8s may help with that, but it&#x27;s going to be a learning curve. I personally moved onto k8s for a similar reason, but it was a learning curve reply thelastparadise 22 hours agorootparentIt&#x27;s a learning curve, but it is consistent, reliable, and standardized.Kubernetes has become an interface, independent of implementation.It&#x27;s much like how POSIX is a standard and there are many implementations.And yes, POSIX has a learning curve too, but I&#x27;d rather learn that than anything proprietary, or non standard&#x2F;rapidly changing. reply moondev 8 hours agorootparentNo doubt. The ability to scale is great, but the best thing about Kubernetes is really the API. reply thelastparadise 22 hours agoparentprevPeople often say kubernetes is complex, or overkill for tasks.But let&#x27;s say you have many computers and want to put them to work. Suddenly, kubernetes becomes the simplest of all options.> Everything should be made as simple as possible, but not simpler.- Einstein reply dinosaurdynasty 20 hours agorootparentLol no. Docker Swarm, Nomad, even ancient Pacemaker are all simpler and easier to use than k8s. I don&#x27;t think there&#x27;s a single feature k8s adds over those options that is actually useful in a non-Enterprise use case (especially homelab stuff, assuming the point of your homelab is not learning k8s). reply packetlost 22 hours agorootparentprevIf that&#x27;s your scenario, fine. But many put themselves in that scenario unnecessarily, which is the real problem. reply proxysna 22 hours agoparentprevStart with hashicorp nomad. Less of a learning curve and easy to set up. Traefik can do automatic discovery of services in nomad. Definitely better than a bunch of systemd units. reply ramdac 1 hour agoprevhow do you pronounce it? kuberthreeties? reply praveenhm 21 hours agoprevI&#x27;ve been closely following the discussion on k3s and Kubernetes in general. I recently acquired an M1 Mac Ultra, and I&#x27;m curious about the best options available for running Kubernetes locally on it.Does anyone have experience or recommendations in this area? I&#x27;ve heard about a few tools but wanted to gather insights from this knowledgeable community. reply maxekman 21 hours agoparentYou should try out OrbStack: https:&#x2F;&#x2F;docs.orbstack.dev&#x2F;kubernetes&#x2F;I switched to it completely, it’s very convenient to have both fast (-est on Mac) Docker support and a really smooth VM setup for running occasional Linux tools (such as Yocto in my case).Edit: added some background info to my recommendation. reply praveenhm 21 hours agorootparentThanks for the orbstack recommendation, I am using it for docker containers, It is really fast and lightweight, I will try out Kubernetes. reply mhio 16 hours agoparentprev\"colima\" and it&#x27;s underlying project \"lima\" are a pretty quick way to get started.Extremely quick to stand up a single node cluster, or many types of VMs in lima.https:&#x2F;&#x2F;github.com&#x2F;lima-vm&#x2F;lima limactl start template:&#x2F;&#x2F;k3shttps:&#x2F;&#x2F;github.com&#x2F;abiosoft&#x2F;colima colima start --kubernetesThe tools are a bit rough around the edges if you try and do something outside of the happy path with them. Nothing bad as such, just the user experience isn&#x27;t as seamless when say running the VMs on custom, addressable host networks or managing vms with launchd. reply nunez 21 hours agoparentprevIf you&#x27;re just messing around, just use kind (https:&#x2F;&#x2F;kind.sigs.k8s.io) or minikube if you want VMs (https:&#x2F;&#x2F;minikube.sigs.k8s.io). Both work on ARM-based platforms.You can also use k3s; it&#x27;s hella easy to get started with and it works great. reply sklarsa 1 hour agorootparentIf you go the kind route, be sure to not use Docker for mac and instead opt for podman which is much more resource efficient. Now that I&#x27;ve switched over to podman, my computer doesn&#x27;t sound like it&#x27;s about to blast off when I&#x27;m running clusters. reply infogulch 19 hours agoprevI&#x27;ve been eyeing Kairos [1] which is an OS lifecycle management system for k3s which looks like a nice way to deploy k3s.[1]: https:&#x2F;&#x2F;github.com&#x2F;kairos-io&#x2F;kairos reply iamdbtoo 18 hours agoprevA great companion to k3s is k3sup.https:&#x2F;&#x2F;github.com&#x2F;alexellis&#x2F;k3sup reply samcat116 21 hours agoprevK3s is great but I&#x27;ll also shout out that RKE2 is almost as simple to install as K3s but its full Kubernetes. reply betaby 22 hours agoprevToo bad k3os was abandoned. And while k3s sounds easy, it&#x27;s not after even a slightly larger scale.If one willing to have in-house k8s today I would recommend https:&#x2F;&#x2F;deckhouse.io&#x2F; (I&#x27;m not affiliated with them) reply yjftsjthsd-h 22 hours agoparent> Too bad k3os was abandoned.Agreed:( Someday I&#x27;d like to see how hard it would be to use microos to build a replacement cheaply (cheap in terms of maintenance; ideally it would just be a combustion config or so that deployed k3s on vanilla microos)> And while k3s sounds easy, it&#x27;s not after even a slightly larger scale.How does it fall apart? reply betaby 22 hours agorootparent> How does it fall apart?Agent nodes failing to join after reboots or long network partitioning. Manual re-joining works. Additionally, hard to debug issues with the supplied Traefic. reply feldrim 18 hours agoprevIf I remember correctly, the new F5 BIG IP instances also internally use k3s under the hood. That&#x27;s probably it&#x27;s efficient resource usage. But this is also an evidence, at least for me, on the stability of k3s. reply bfrog 20 hours agoprevLightweight is a misnomer. Running even the most basic of tasks requires an insanely complex setup with vxlan, unintelligible iptables and bridge rules, all taking up a great deal of resources on something like an embedded x86&#x2F;arm devices reply nullify88 20 hours agoprevIf you want something lighter than k3s, k0s could be worth a try. I recently switched to k0s and noticed the controller, and the various kube processes consume less cpu resources compared to when I was running k3s. reply Difwif 19 hours agoprevk3s users: I tried using k3s a few years back and on a fresh single node setup I was seeing ridiculous system usage with 0 deployments. Something like 20-30% cpu load. The same system with a k8s deployment using kubeadm was 3-5% without a deployment.There&#x27;s this issue that goes back to 2019 that got closed without any real resolution. I moved on but I&#x27;m curious if anyone else has measured this?https:&#x2F;&#x2F;github.com&#x2F;k3s-io&#x2F;k3s&#x2F;issues&#x2F;294 reply maxthegeek1 21 hours agoprevk3s is my preferred way to run k8s locally, for the purpose of developing helm charts locally. It&#x27;s way more lightweight than minikube, and with k3d it&#x27;s way easier to use as well. reply j_m_b 22 hours agoprevIs the overhead of Kubernetes worth it enough to make it smaller, presumably to run in less resource intensive environments? Docker compose fits this bill nicely and is much more simple. reply speedgoose 21 hours agoparentKubernetes is offering much more features than Docker compose. And then you have all the kubernetes operators and other extensions that makes it very complex and powerful.It’s fine to use docker compose if it does what you need. If you start hacking weird things using Docker compose, it’s perhaps time to suffer and learn kubernetes. reply efrecon 22 hours agoparentprevCompose is for single node setups. K3s runs in multi-nodes clusters. reply Xiol32 21 hours agorootparentAlso easier to scale out from your single starter k3s node as you grow. reply worldsayshi 21 hours agoprevvCluster is an interesting related technology. It spins up k3s inside Kubernetes. Handy if you want a lightweight way to manage multiple staging environments.https:&#x2F;&#x2F;www.vcluster.com&#x2F;docs&#x2F;what-are-virtual-clusters reply imachine1980_ 22 hours agoprevWhy use this over kubernetes, if it&#x27;s the same but less memory why not only use k3s ans drop k8s reply cogman10 22 hours agoparentThere&#x27;s no real \"over kubernetes\". K3s is a kubernetes implementation.You have to think of k8s as more of a specification of what can be done with multiple implementations. k3s, kind, microk8s, minikube are all implementations of kubernetes that you might want to try out.k8s is much like the original IBM pc or a linux distribution. There are a bunch of interchangeable parts that you may land on depending on your needs.Why use this over something else? I&#x27;ve found k3s to be really simple to setup and upgrade, which is why I use it for my home lab. reply doubled112 22 hours agorootparentYes. I think Kubernetes \"distribution\" has always made the most sense to me. reply Takennickname 22 hours agorootparentprevSo all of those can be used to host a highly available multi physical node cluster? reply ianburrell 21 hours agorootparentIt makes sense to use full Kubernetes in that case. The lightweight distributions are good for single instances or limited multiple nodes. Like homelabs, edge nodes, or local development. But hosting application in data center makes sense to use full Kubernetes. reply cogman10 18 hours agorootparentAs I said, there&#x27;s not a \"full kubernetes\".If you are in a datacenter, it&#x27;s best to use the K8s distributed by that datacenter (EKS for AWS, for example).The EKS provided by a datacenter will have integrations with external to Kubernetes resources you will almost certainly want (like storage, DNS records, or load balancers). reply cogman10 22 hours agorootparentprevk3s and microk8s definitely support multiple node setup. I&#x27;m not sure about kind or minikube (Maybe? You&#x27;d have to look into the docs). How ready they are and how well they&#x27;ll scale out will depend a lot on how the controllers are setup.k3s, at least, supports multiple controller nodes on setup.Where things really get squirrelly, at least with k3s, is storage and ingresses. k3s supports both but in a super robust fashion. reply mfer 22 hours agoparentprevKubernetes is sort of like Linux. There are distributions that excel in different areas. For example, RKE2 is for those that prioritize security. It deals with compliance and security things. There are numerous distros right now. The CNCF even has a certification program and listing for the certified ones.K3s is the lightweight distro. You can install and run it from a single binary on pretty much any Linux distro. reply caniszczyk 22 hours agorootparentThere&#x27;s 100+ certified kubernetes distros&#x2F;products :)https:&#x2F;&#x2F;www.cncf.io&#x2F;certification&#x2F;software-conformance&#x2F; reply notanormalnerd 22 hours agoparentprevBecause this makes certain assumptions and certain decisions about the Kubernetes Environment you want to be running.See here: https:&#x2F;&#x2F;docs.k3s.io&#x2F;It&#x27;s fully compliant but opinionated towards the smaller side. reply proxysna 22 hours agoparentprevk3s is a single binary + a lot of unnecessary api&#x27;s trimmed. In general a better entrypoint for someone new to k8s imo. reply nurettin 21 hours agoprevI wish kubernetes could install and manage services through systemd. reply rcarmo 19 hours agoparentWell, have a look a this: https:&#x2F;&#x2F;github.com&#x2F;virtual-kubelet&#x2F;systemk reply dmd 22 hours agoprevI believe Truenas SCALE&#x27;s plugin system is built on k3s. reply slig 22 hours agoprevAnyone running K3S on Hetzner&#x27;s new ARM64 servers? reply ge96 23 hours agoprevkeees? kiots maybe reply verdverm 22 hours agoparent> We wanted an installation of Kubernetes that was half the size in terms of memory footprint. Kubernetes is a 10 letter word stylized as k8s. So something half as big as Kubernetes would be a 5 letter word stylized as K3s. There is neither a long-form of K3s nor official pronunciation. reply JohnMakin 22 hours agorootparentSo wouldn&#x27;t it be K4s? I can&#x27;t figure out how they got 3. reply maxbond 22 hours agorootparentThey&#x27;re counting the \"k\" and the \"s\" to get to 5 total. It&#x27;s a bit more convoluted than 4 = 8 &#x2F; 2, it&#x27;s 3 = (8 + 2) &#x2F; 2 - 2. reply worksonmine 22 hours agorootparentprevCut the 8 in half and you get 3, not mathematically but visually. reply ge96 21 hours agorootparentKԐS reply verdverm 20 hours agorootparentprevlen(kubernetes) == 10 -> k8shalf(kubernetes) == 5 -> k3s reply dheera 22 hours agorootparentprevI always prefer to spell it kUbernEats. reply cudder 22 hours agoparentprevKubes? reply sesm 20 hours agorootparentKyuss reply V99 18 hours agoparentprevThe real origin of the name is kubernetes -> k[8 letters]s -> k8s -> people pronounce as \"kates\" -> k[3 letters]s -> k3s. reply bantunes 22 hours agoparentprev\"Kes\" ? reply secondcoming 19 hours agoprevHow is K3s pronounced? reply gitpusher 17 hours agoparentfrom their docs: https:&#x2F;&#x2F;docs.k3s.io&#x2F;> We wanted an installation of Kubernetes that was half the size in terms of memory footprint. Kubernetes is a 10-letter word stylized as K8s. So something half as big as Kubernetes would be a 5-letter word stylized as K3s. There is no long form of K3s and no official pronunciation. reply vault 22 hours agoprevforget about it if you want to run it on an IPv6-only VPS, it&#x27;s not ready yet reply cwayne 22 hours agoparentK3s absolutely supports ipv6-only reply thelastparadise 22 hours agoparentprevThere&#x27;s not any common reason I can think of to go ipv6 on the backend. KISS --if there&#x27;s enough IPs in a private v4 range, use them.If you need&#x2F;want to serve v6 clients, put a v6 load balancer in front. You&#x27;re likely going to need that lb anyway. reply yjftsjthsd-h 22 hours agorootparentI think the use case was running on a cheap server that actually doesn&#x27;t have ipv4 connectivity reply dmm 21 hours agorootparentprev> KISSipv6 and routable ips is way simpler than patching layer 2 networks together. reply umvi 20 hours agoprev [–] Kubernetes seems like an \"acquired taste\".Either you use it a lot (likely at work) and are therefore comfortable using it outside of work as your one-size-fits-all solution to everything, or else you don&#x27;t use it a lot and see it as a complexity behemoth that hides all of your system behind esoteric CLIs and config files that just make everything a nightmare to manage. reply outime 19 hours agoparentI&#x27;m tired of seeing comments with an apparent layer of objectivity which very quickly goes away as you reason about it for a second. You could&#x27;ve just said \"I don&#x27;t like K8s, it&#x27;s too complex for my taste\" but then your comment would be gray for being short and concise, so you decide to say this.Opinions are fine and you may as well hate K8s or any tech being discussed. I just hope to see less of \"people who like this just because they don&#x27;t know any better vs the smart ones like me who know The Truth™\" comments. reply umvi 17 hours agorootparentThat wasn&#x27;t the intent of my comment at all. I don&#x27;t hate k8s - I&#x27;ve never used it beyond experimental fiddling. I&#x27;m sure if I used it at work all day I would love it.I&#x27;m trying to grapple with the fact that k8s is apparently ultra popular technology, yet every time I try to read up on it or start using it, it quickly turns into a suck fest in terms of learning curve and complexity. So my conclusion is that the people using it \"for fun\" must have acquired a taste for it first by using it all day at work and I wanted to see if anyone who acquired the taste might chime in as to what made them see the light. reply sleepybrett 19 hours agoparentprev [–] I find it very acceptable on my local servers that run my mail, web, mastodon, etc servers. I prefer the configuration in kubenetes templates instead of spread all over my filesystem in &#x2F;etc (config in one place and fucking unit files in another), &#x2F;var&#x2F;lib, &#x2F;opt, etc. reply umvi 19 hours agorootparentRight, you&#x27;ve acquired the taste. But why should people who haven&#x27;t acquired the taste do this? To me seems like a mountain of unneeded complexity compared to just running a local webserver directly in a docker container with \"docker run --restart always \". reply eropple 18 hours agorootparentBecause when your docker server gets smoked, what happens? If you&#x27;re using Swarm or Nomad or k8s, there&#x27;s an argument there. `docker run` isn&#x27;t.I&#x27;ve very recently moved over to a home k3s cluster--a couple old desktops and some relatively new ARM SBCs with NVMe slots. I don&#x27;t use it at work, at least not directly, but it&#x27;s been the least-painful solution I&#x27;ve found to run stuff; once you understand the model (not trivial but not crazy) and find the headspace to explain why things in k8s are the way they are, reasoning through it is pretty easy (which is really just the story of any moderately complex system, exacerbated in a few ways because of some Google-attitude carryover), and I can also yank half the machines out of the cluster before an application fails.(Both Swarm and Nomad are fine tools, but the lack of easy resources to get up to speed led to me failing them out of consideration.) reply umvi 17 hours agorootparent> Because when your docker server gets smoked, what happens?In the context of local or home servers: my raspberry pi currently has like a 3 year uptime now, but if it randomly croaked I&#x27;d just buy a new raspberry pi, docker pull the image, and get it up and running again.So you are saying the main benefit of k8s is that if some of your hardware in the cluster dies then your services are automatically still up and running? Isn&#x27;t a home k8s setup vulnerable to the same failure as well if the master node gets smoked?Seems like a lot of complexity cost for something that happens extremely rarely in a home setup at least (I could see how it would be useful for high reliability cloud systems). reply eropple 8 hours agorootparentThe main benefits for me:- I have three control planes, not one, for about 20 x86-64 and 24 arm64 cores and ~160GB of RAM across 7 nodes. For much the same reason as my NAS uses raidz2, I don&#x27;t have to drop everything and fix the universe if something fails because Home Assistant just keeps going.- With Longhorn, I have three instances of every data volume in the cluster. Longhorn also provides incremental data backups to an S3 server--Minio on the NAS, in my case, which replicates to an offsite.- I can run things like CrunchyData&#x27;s Postgres operator, which provides a solid baseline setup and additional features like point-in-time restore--and as I run personal but public-facing apps on the cluster this is beneficial.- Logging and monitoring are centralized and were easy to do. I don&#x27;t have to go attach to a container, I just go look at Grafana.- I have a consistent interface for working with all my applications, and I like it more than Swarm&#x27;s by a lot.By having this cluster, made out of spare computers, some cheap NVMe drives, and a couple SBCs I wanted to experiment with anyway,I&#x27;ve removed everything I care personally about from cloud providers except for offsite backup and my email sending. I know where it is, I can hack on projects trivially, and I know it&#x27;ll be there tomorrow so long as the house doesn&#x27;t burn down.And I didn&#x27;t learn any of k8s at work. reply sleepybrett 16 hours agorootparentprevif you only have one master sure.The benefit to me is if one of my nodes physically dies i have enough room on my cluster to still run all my pods, they just automagically reschedule to another node.If my master dies then I have to do a little extra work, but not much. reply sleepybrett 19 hours agorootparentprevTurns out to run the stuff I run I need more than 1 machine :).. luckily a couple of years back when my job was dissolving a dept and had a stack of uneeded NUCs headed for recycling (pretty nice ones, i&#x27;ve added a little ram but that&#x27;s it) I tossed them in a box and took them home instead. I&#x27;ve also added a couple of PI&#x2F;Arm nodes just for kicks. reply carlhjerpe 19 hours agorootparentprev [–] I think you&#x27;d love NixOS! reply sleepybrett 19 hours agorootparent [–] I think I work with kubernetes absolutely every day at work and it&#x27;s doing just fine. I&#x27;ve used Nix for some builds but that&#x27;s really it. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "K3s is a compact Kubernetes version built for IoT and edge computing, designed to function effectively in remote and resource-limited environments.",
      "It is bundled as a single binary to lessen dependencies and make installation easier, supporting both ARM64 and ARMv7 architectures, making it suitable for small devices like Raspberry Pi to larger servers.",
      "As a Cloud Native Computing Foundation sandbox project, users can start using K3s by downloading it and running it on their server, and then adding agent nodes."
    ],
    "commentSummary": [
      "The article discusses the author's positive experiences using K3s, a lightweight variant of Kubernetes, with sqlite for a single-node setup in a homelab setting.",
      "The post also delves into a comparison between shared block storage solutions like Longhorn, Ceph, and Rook, and container orchestration platforms, specifically Kubernetes versus Nomad.",
      "The suitability of these technologies is debated, with opinions ranging from Kubernetes being potentially overkill for many companies, to the recommendation of lightweight alternatives like K0s, and tools like Rancher Desktop, depending on specific needs and preferences."
    ],
    "points": 236,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1697038789
  },
  {
    "id": 37845195,
    "title": "The deep link equating math proofs and computer programs",
    "originLink": "https://www.quantamagazine.org/the-deep-link-equating-math-proofs-and-computer-programs-20231011/",
    "originBody": "We care about your data, and we'd like to use cookies to give you a smooth browsing experience. Please agree and read more about our privacy policy.AGREE Physics Mathematics Biology Computer Science Topics Archive The Deep Link Equating Math Proofs and Computer Programs READ LATER SHARE COPIED! FOUNDATIONS OF MATHEMATICS The Deep Link Equating Math Proofs and Computer Programs Mathematical logic and the code of computer programs are, in an exact way, mirror images of each other. READ LATER Nash Weerasekera for Quanta Magazine By Sheon Han Contributing Writer October 11, 2023 VIEW PDF/PRINT MODE Abstractions blog computer science computer-assisted proofs computers explainers foundations of mathematics logic mathematics proofs All topics Introduction Some scientific discoveries matter because they reveal something new — the double helical structure of DNA, for example, or the existence of black holes. However, some revelations are profound because they show that two old concepts, once thought distinct, are in fact the same. Take James Clerk Maxwell’s equations showing that electricity and magnetism are two aspects of a single phenomenon, or general relativity’s linking of gravity with a curved space-time. The Curry-Howard correspondence does the same but on a larger scale, linking not just separate concepts within one field, but entire disciplines: computer science and mathematical logic. Also known as the Curry-Howard isomorphism (a term meaning there exists some kind of one-to-one correspondence between two things), it establishes a link between mathematical proofs and computer programs. Simply stated, the Curry-Howard correspondence posits that two concepts from computer science (types and programs) are equivalent, respectively, to propositions and proofs — concepts from logic. One ramification of this correspondence is that programming — often seen as a personal craft — is elevated to the idealized level of mathematics. Writing a program is not just “coding,” it becomes an act of proving a theorem. This formalizes the act of programming and provides ways to reason mathematically about the correctness of programs. The correspondence is named for the two researchers who independently discovered it. In 1934, the mathematician and logician Haskell Curry noticed a similarity between functions in mathematics and the implication relationship in logic, which takes the form of “if-then” statements between two propositions. Abstractions navigates promising ideas in science and mathematics. Journey with us and join the conversation. See all Abstractions blog Inspired by Curry’s observation, the mathematical logician William Alvin Howard discovered a deeper link between computation and logic in 1969, showing that running a computer program is a lot like simplifying a logical proof. When a computer program runs, each line is “evaluated” to yield a single output. Similarly, in a proof, you start with complex statements that you can simplify (by eliminating redundant steps, for example, or substituting complex expressions with simpler ones) until you arrive at a conclusion — a more condensed and succinct statement derived from many interim statements. While this description conveys a general sense of the correspondence, to fully understand it we need to learn a bit more about what computer scientists call “type theory.” Let’s start with a famous paradox: In a village there lives a barber who shaves all the men who do not shave themselves, and only them. Does the barber shave himself? If the answer is yes, then he must not shave himself (because he only shaves men who don’t shave themselves). If the answer is no, then he must shave himself (because he shaves all the men who don’t shave themselves). This is an informal version of a paradox Bertrand Russell discovered while trying to establish the foundations of mathematics using a concept called sets. That is, it’s impossible to define a set that contains all sets that do not contain themselves without encountering contradictions. To avoid this paradox, Russell showed, we can use “types.” Roughly speaking, these are categories whose specific values are called objects. For example, if there’s a type called “Nat,” meaning natural numbers, its objects are 1, 2, 3, and so on. Researchers typically use a colon to denote the type of an object. The number 7, of integer type, can be written as “7: Integer.” You can have a function that takes an object of type A and spits out an object of type B, or one that combines a pair of objects that were type A and type B into a new type, called “A × B.” Writing a program is not just “coding,” it becomes an act of proving a theorem. One way to resolve the paradox, therefore, is to put these types into a hierarchy, so they can only contain elements of a “lower level” than themselves. Then a type can’t contain itself, which avoids the self-referentiality that creates the paradox. In the world of type theory, proving that a statement is true can look different from what we’re used to. If we want to prove that the integer 8 is even, then it’s a matter of showing that 8 is indeed an object of a specific type called “Even,” where the rule for membership is being divisible by 2. After verifying that 8 is divisible by 2, we can conclude that 8 is indeed an “inhabitant” of the type Even. Curry and Howard showed that types are fundamentally equivalent to logical propositions. When a function “inhabits” a type — that is, when you can successfully define a function that is an object of that type — you’re effectively showing that the corresponding proposition is true. So functions that take an input of type A and give an output of type B, denoted as type A → B, must correspond to an implication: “If A, then B.” For example, take the proposition “If it’s raining, then the ground is wet.” In type theory, this proposition would be modeled by a function with the type “Raining → GroundIsWet.” The different-looking formulations are in fact mathematically the same. FOUNDATIONS OF MATHEMATICS Building the Mathematical Library of the Future OCTOBER 1, 2020 READ LATER As abstract as that linkage may sound, it has not only changed how practitioners of math and computer science think about their work, but also led to several practical applications in both fields. For computer science, it provides a theoretical foundation for software verification, the process of ensuring the correctness of software. By framing desired behaviors in terms of logical propositions, programmers can mathematically prove that a program behaves as expected. It also provides a strong theoretical foundation for designing more powerful functional programming languages. And for mathematics, the correspondence has led to the birth of proof assistants, also called interactive theorem provers. These are software tools that aid in constructing formal proofs, such as Coq and Lean. In Coq, each step of the proof is essentially a program, and the proof’s validity is checked with type-checking algorithms. Mathematicians have also been using proof assistants — notably, the Lean theorem prover — to formalize mathematics, which involves representing mathematical concepts, theorems and proofs in a rigorous, computer-verifiable format. That allows the sometimes informal language of mathematics to be checked by computers. Researchers are still exploring the consequences of this link between math and programming. The original Curry-Howard correspondence fuses programming with a kind of logic called intuitionistic logic, but it turns out that more types of logic could be amenable to such unifications as well. RELATED: Proof Assistant Makes Jump to Big-League Math How Close Are Computers to Automating Mathematical Reasoning? How to Write Software With Mathematical Perfection The Most Important Machine That Was Never Built “What has happened in the century since Curry’s insight is that we keep discovering more and more instances where ‘logical system X corresponds to computational system Y,’” said Michael Clarkson, a computer scientist at Cornell University. Researchers have already connected programming to other types of logic like linear logic, which includes the concept of “resources,” and modal logic, which deals with concepts of possibility and necessity. And while this correspondence bears Curry’s and Howard’s names, they are by no means the only ones who have discovered it. This attests to the foundational nature of the correspondence: People keep noticing it again and again. “It seems to be no accident that there’s a deep link between computation and logic,” Clarkson said. Share this article COPIED! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Also in Abstractions Blog CONDENSED MATTER PHYSICS Invisible ‘Demon’ Discovered in Odd Superconductor By CHARLIE WOOD OCTOBER 9, 2023 1 READ LATER NOBEL PRIZE Nobel Prize Honors Inventors of ‘Quantum Dot’ Nanoparticles By YASEMIN SAPLAKOGLU OCTOBER 4, 2023 1 READ LATER NOBEL PRIZE Physicists Who Explored Tiny Glimpses of Time Win Nobel Prize By CHARLIE WOOD OCTOBER 3, 2023 4 READ LATER Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments NEXT ARTICLE In Our Cellular Clocks, She’s Found a Lifetime of Discoveries About Quanta Archive Contact Us Terms & Conditions Privacy Policy Simons Foundation All Rights Reserved © 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37845195",
    "commentBody": "The deep link equating math proofs and computer programsHacker NewspastloginThe deep link equating math proofs and computer programs (quantamagazine.org) 233 points by digital55 1 day ago| hidepastfavorite138 comments codekilla 21 hours agoBob Harper wrote a really good blog entry that expounds on this as Computational Trinitarianism [1].Michael Shulman also wrote about the extension to Homotopical Trinitarianism [2]For a good summary with links there is [3][1] Computational Trinitarinism, https:&#x2F;&#x2F;existentialtype.wordpress.com&#x2F;2011&#x2F;03&#x2F;27&#x2F;the-holy-tr...[2] Homotopical Trinitarinism, http:&#x2F;&#x2F;home.sandiego.edu&#x2F;~shulman&#x2F;papers&#x2F;trinity.pdf][3] nCatLab, https:&#x2F;&#x2F;ncatlab.org&#x2F;nlab&#x2F;show&#x2F;computational+trilogy reply gnufx 19 hours agoparentLacking time to study, is this basically what Phil Wadler has written and talked about, like \"Propositions as types\"? reply akomtu 20 hours agoparentprevTo the Mr. Harper&#x27;s observation we should add that the trinitary theory of computation needs to express itself in reality and it does so thru the quadrant of hardware: transistors, memory, electricity and machine code. Thus three, standing on the four, represents computation in action. reply nradov 18 hours agorootparentIn principle it doesn&#x27;t have to be transistors specifically. Any switching device will suffice. reply ewuhic 21 hours agoprevCould anyone suggest a happy path (\"zero to hero\") book on formal verification, which also does the ecosystem review for the formal verification languages, and then focuses on one, as well as provides the reasoning and mentions tradeoffs for such a choice? reply miloignis 20 hours agoparenthttps:&#x2F;&#x2F;softwarefoundations.cis.upenn.edu&#x2F; is a great zero-to-hero resource (it&#x27;s what I used), but to my knowledge it doesn&#x27;t have an ecosystem review in it. It uses Coq, but the first book has been ported to at least Isabelle, if not others. reply blueberry87 18 hours agorootparentAlso agda: https:&#x2F;&#x2F;plfa.github.io&#x2F; reply amw-zero 11 hours agoparentprevI don&#x27;t think something that specific exists. There are a very large number of formal methods tools, each with different specialties &#x2F; domains.For verification with proof assistants, [Software Foundations](https:&#x2F;&#x2F;softwarefoundations.cis.upenn.edu&#x2F;) and [Concrete Semantics](http:&#x2F;&#x2F;concrete-semantics.org&#x2F;) are both solid.For verification via model checking, you can check out [Learn TLA+](https:&#x2F;&#x2F;learntla.com&#x2F;), and the more theoretical [Specifying Systems](https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;tla&#x2F;book-02-08-08.pdf).For more theory, check out [Formal Reasoning About Programs](http:&#x2F;&#x2F;adam.chlipala.net&#x2F;frap&#x2F;).And for general projects look at [F*](https:&#x2F;&#x2F;www.fstar-lang.org&#x2F;) and [Dafny](https:&#x2F;&#x2F;dafny.org&#x2F;). reply penguin_booze 8 hours agoparentprevI&#x27;m a fan of formal verification of functional programming. It saddens me to say that, in that line of work, hardly anyone speaks English [0], at least not past the front door. The amount of high-horsery and dog-whistling is enough to wear down any regular folk that walks down the path. Maybe it&#x27;s the nature of the field itself, that those accomplished folks seem to forget they once walked this earth, up right, on two legs.[0] read: natural language reply nextos 13 hours agoparentprevFormal Methods An Appetizer is excellent and has a companion site with toy formal methods implemented in F#: http:&#x2F;&#x2F;www.formalmethods.dk. However, it does not cover proof assistants.Alternatively you may enjoy these two. The latter is especially thorough, and begins with classical logic:* Concrete Semantics (Isabelle): http:&#x2F;&#x2F;concrete-semantics.org* Program = Proof (Agda): https:&#x2F;&#x2F;www.lix.polytechnique.fr&#x2F;Labo&#x2F;Samuel.Mimram&#x2F;teaching... reply noqc 18 hours agoparentprevSince the whole premise here is that formally verifying the properties of programs is equivalent to constructive mathematics, I think you might be asking for too much, modulo your definition of hero. reply bruce343434 16 hours agorootparentWhat do you mean by modulo here? reply tux3 16 hours agorootparentIt means except for X, or disregarding XIf you have a particularly generous definition of hero, then you might not be asking too much reply rsrsrs86 17 hours agoparentprevThere is no such thing as zero to hero for formal methods. It’s a dense and difficult field. reply fsckboy 7 hours agorootparentbut then, wouldn&#x27;t the textbook for \"MA&#x2F;CS 301 Introduction to Formal Methods\" be the book to read, and you either don&#x27;t have the prereqs for it (can&#x27;t understand it maybe because you don&#x27;t know any functional languages) or it takes you as far as it does and then you decide if that&#x27;s as far as you want to go? reply ewuhic 6 hours agorootparentI am sorry, but my google-foo is lacking to find this book. Could you please name the authors, or just post a link? reply jurynulifcation 16 hours agoparentprevTypes and Programming Languages by Benjamin C. Pierce[0][0] https:&#x2F;&#x2F;www.cis.upenn.edu&#x2F;~bcpierce&#x2F;tapl&#x2F; reply boxfire 23 hours agoprevProgramming in dependent types with univalence (Homotopy Type Theory) is an awesome way to see this realized.The typing statement has to be proven by realizing the isomorphism demanded by substitution. You are more than anything directly proving what you claim in the type. Since proof is isomorphism here, the computation in terms of lowering the body of the definition to a concrete set of instructions is execution of your proof! (possibly machine code or just abstract in a virtual machine like STG). The constructive world is really nice. I hope the future builds here and dependent types with univalence is made easier and more efficient. reply js8 22 hours agoparentWhat specific system (programming language) do you recommend to try this? reply codekilla 21 hours agorootparentFor dependent types, I would look at Idris [1]. Adding Univalence in a satisfying way is I think still somewhat of a research question (I could be wrong, and if anyone has any additional insight would be interested to hear), i.e. see this thread about Univalence in Coq [2]. There are some implementations in Cubical Type Theory, but I am not sure what the state of the art is there [3][1]https:&#x2F;&#x2F;www.idris-lang.org [2]https:&#x2F;&#x2F;homotopytypetheory.org&#x2F;2012&#x2F;01&#x2F;22&#x2F;univalence-versus-... [3]https:&#x2F;&#x2F;redprl.org reply haltist 15 hours agorootparentIt should be possible to embed cubical type theory in Idris.[1][2]1: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2210.082322: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;aadb7a0a-08a4-4951-b877-cb2f61... reply AnimalMuppet 13 hours agorootparentprevThis is not going to catch on any time soon.Assume that regular software has, on average, one bug every 50 lines. (All numbers made up on the spot, or your money back.) Let&#x27;s suppose that Idris can reduce that to absolutely zero. And let&#x27;s suppose that totally-working software is worth twice as much as the buggy-but-still-mostly-working slop we get today.But Idris is harder to write. Not just a bit harder. I&#x27;d guess that it&#x27;s maybe 10 times as hard to write as Javascript. So we&#x27;d get better software, but only 1&#x2F;10 as much of it. Take your ten most favorite web applications or phone apps. You only would have one of them - but that one would never crash. Most people won&#x27;t make that trade. Most companies that produce software won&#x27;t make it, either, because they know their customers won&#x27;t.Well, you say, what about safety-critical software? What about, say, airplane flight control software? Surely in that environment, producing correct software matters more than producing it quickly, right?Yes, but also you&#x27;re in the world of real-time embedded systems. Speed matters, but also provably correct timing. Can you prove that your software meets the timing requirements in all cases, if you wrote it in Idris? I believe that is, at best, an unsolved problem. So what they do is they write in carefully chosen subsets of C++ or Rust, and with a careful eye on the timing (and with the help of tools). reply jfoutz 11 hours agorootparentI&#x27;ve been dabbling with Idris and agda and coq. I think I&#x27;m pretty much settling on agda, because I can appeal to Haskell for help. It&#x27;s tough finding things that aren&#x27;t just proofs, actually running a program isn&#x27;t hard, there just doesn&#x27;t seem to be many people who do it. I&#x27;ve got some toy projects in mind, and I&#x27;m going to lean hard on https:&#x2F;&#x2F;github.com&#x2F;gallais&#x2F;aGdaREP (grep in agda). I can&#x27;t tell you if it&#x27;s ten times harder - that seems high. It&#x27;s different, sure. I&#x27;m having a tougher time than with, say, prolog. But most of the bumps and bruises are from lack of guidance around, uh, stuff.So given that context, it doesn&#x27;t sound to tough to add a cost to the type for each operation, function call, whatever, and have the type checker count up the cost of each call. So you&#x27;d have real proof that you&#x27;re under some threshold. I wouldn&#x27;t put the agda runtime on a flight control computer. But I think I could write a compiler, now, For like a microcontroller that would count up (or spend time budget, doesn&#x27;t matter).A more sophisticated computer would be way way harder, and be resource efficient. But if you modeled it as \"everything&#x27;s a cache miss\" and don&#x27;t mind a bunch of no-ops all the time, that would be a pretty straightforward adaptation of the microcontroller approach. reply siknad 3 hours agorootparentI would recommend trying Lean4 because I think it is better suited to programming. Lean has Rust-like toolchain manager; a build system (cf. `.agda-lib`); much more developed tactics (including `termination_by`&#x2F;`decreasing_by`); more libraries (mathlib, and some experimental programming-oriented libraries for sockets, web, games, unicode...); common use of typeclasses in stdlib&#x2F;mathlib; `unsafe` per declaration (cf. per module in Agda); sound opaque functions (which must have a nonempty return type) used for `partial` and ffi; \"unchained\" do-notation (early `return`, imperative loops with `break`&#x2F;`continue`, `let mut`); easier (more powerful?) metaprogramming and syntax extensions. And in Agda you can&#x27;t even use Haskell&#x27;s type constructors with type classes (ex. monad polymorphic fns, and that makes it more difficult to make bindings to Hs libs, than to C libs in Lean).There are features in Agda&#x2F;Idris (and probably Coq, about which I sadly know almost nothing) that are absent from Lean and are useful when programming (coinduction, set omega, more powerful `mutual`, explicit multiplicity, cubical? etc), but I&#x27;d say the need for them is less common. reply __MatrixMan__ 9 hours agorootparentprev> So we&#x27;d get better software, but only 1&#x2F;10 as much of itHow much software do you think we need? 10x less sounds about right to me. reply logicchains 17 hours agorootparentprevIntelliJ Arend probably has the most comprehensive support for HOTT among the proof systems: https:&#x2F;&#x2F;arend-lang.github.io&#x2F; . Not a lot in the way of tutorials though, just the official documentation. reply gylterud 20 hours agorootparentprevAgda is a nice language with a good homotopy type theory library based on the univalence axiom called agda-unimath. reply strogonoff 20 hours agoprevLamport’s Computation and State Machines[0] is an interesting take on relating mathematics to computer programming. Lamport appears to treat programs as state machines, making it possible to reason about those with pure mathematics (in a way independent of programming language syntactic constructs).[0] https:&#x2F;&#x2F;research.microsoft.com&#x2F;en-us&#x2F;um&#x2F;people&#x2F;lamport&#x2F;pubs&#x2F;... reply amw-zero 19 hours agoparentThis is my favorite CS paper of all time. Reason being, it distills multiple different areas of CS down to one idea: state machines. Now I&#x27;m frequently able to map a complex idea down to a state machine, which makes all kinds of problems more manageable. reply zozbot234 19 hours agoparentprevYou can also express the \"programs as state machines\" view in terms of programming language constructs, namely monads (for Time, State and Non-Determinism). If you take a strictly mathematical view of the topic you&#x27;ll call these &#x27;modalities&#x27; or &#x27;modal operators&#x27; instead but it&#x27;s the same deal. reply gorgoiler 18 hours agoprevNot just formally but also stylistically. Composable lemma and composable functions are two leaves of the same book. The construction of a proof is to convince the reader of the correctness of the logic and this is exactly the same goal of a mathematical author as it is of a computer programmer.Business really interferes with the goal of the mathematical programmer — proofs of concept, hacks to get MVPs over the line, throwaway demos to investors etc. — but after a certain point the value of the codebase becomes entrenched into the value of the business and that’s when you need to bring in the mathematical coders to constantly refine and prune your codebase into something that will survive and bear out the earnings per share values. reply qsort 23 hours agoprevIf you want to see how the Curry-Howard isomorphism works in practice, this is a very accessible introduction: https:&#x2F;&#x2F;groups.seas.harvard.edu&#x2F;courses&#x2F;cs152&#x2F;2021sp&#x2F;lecture... reply xelxebar 13 hours agoparentNifty. That was a nice 4-page exposé of the correspondence. There are no general proofs, but the correspondence between notations is very suggestive and invokes interesting intuitions, I think. The example derivations with the uncurry example are quite fun to work through. The paragraph about continuations corresponding to double negation is also super neat!Now I just wish there were something similar for the missing category theory third of the trinitary mentioned in another comment. reply _a_a_a_ 21 hours agoparentprevAccessible for who, do you mean? That is in no way &#x27;accessible&#x27; without solid exposure to quite a lot of discrete maths (which I have and it&#x27;s still hard going).λf :(τ 1 × τ 2 ) → τ 3 .λx:τ 1 .λy:τ 2 .f (x,y) has type ((τ 1 × τ 2 ) → τ 3 ) → (τ 1 → τ 2 → τ 3 ).Yeah, that&#x27;s accessible. reply qsort 21 hours agorootparentIt&#x27;s accessible to anybody with any experience programming and who is willing to pay attention. You are just taking a formula out of context, omitting the plain English explanation that comes before it, and pretending it&#x27;s some kind of alien math. It&#x27;s not scary at all, in fact it&#x27;s very simple.Let&#x27;s do this in Python. First, write a function that curries: def curry(f): def g(x): def h(y): return f(x, y) return h return g my_func = lambda x, y: 10 * x + y curried = curry(my_func) print(curried(5)(3)) # output: 53Now, let&#x27;s type it in such a way that mypy --strict won&#x27;t complain: from typing import TypeVar, Callable A = TypeVar(&#x27;A&#x27;) B = TypeVar(&#x27;B&#x27;) C = TypeVar(&#x27;C&#x27;) def curry(f: Callable[[A, B], C]) -> Callable[[A], Callable[[B], C]]: def g(x: A) -> Callable[[B], C]: def h(y: B) -> C: return f(x, y) return h return gWhat&#x27;s the type of curry? Let&#x27;s hover our cursor over the function name, and lo and behold: Callable[[Callable[[A, B], C]], Callable[[A], Callable[[B], C]]]That&#x27;s it. That&#x27;s all it&#x27;s saying. reply automatoney 20 hours agorootparentThis would be a really good (and much more accessible than the linked pdf) explanation without the condescending tone. This is some pretty advanced math, and pretending otherwise isn&#x27;t constructive. If someone says \"I&#x27;m having trouble understanding this\", it&#x27;s not their fault, and it&#x27;s generally not laziness - it just means that the explanation isn&#x27;t suited to them. reply vilhelm_s 15 hours agorootparentIt&#x27;s not any kind of advanced math at all! The quoted fragment above is just a line of computer code. Anyone who has done any programming in any typed language should be easily able to understand it, though they may need to look up the syntax. reply AnimalMuppet 13 hours agorootparentNope, not me. But I&#x27;ve only been programming for 40 years, so maybe I&#x27;ll get it when I&#x27;ve got more experience.In other words, baloney. If you don&#x27;t do that kind of programming, that stuff is very opaque. I might be able to get it if I were willing to stare at it for another 15 minutes, but I&#x27;m not willing. reply sordina 12 hours agorootparent15 minutes is not a long time. Easily understand doesn&#x27;t mean instantly understand with no background reading. reply _a_a_a_ 3 hours agorootparentYou&#x27;re just ignoring what he is saying. replyrsrsrs86 16 hours agorootparentprevBy trying to look smart you look stupid in assuming this is simple. You need to improve your soft skills. reply _a_a_a_ 20 hours agorootparentprev> You are just taking a formula out of context, omitting the plain English explanation that comes before it,which, this?\"We saw earlier in the course that we can curry a function. That is, given a function of type (τ 1 ×τ 2 ) → τ 3 , we can give a function of type τ 1 → τ 2 → τ 3\"That helps no-one unless you have some serious hand-holding. I know the type of curry, I&#x27;ve written curry&#x2F;bind&#x2F;whateveer in C#, scala, JS and likely others. I have a background in this. It&#x27;s not &#x27;accessible&#x27; to mere mortals and even I&#x27;m not familiar with some of the notation here. Stop pretending it&#x27;s just laziness on other people&#x27;s part.(oh yeah, did I forget to put constructive logic in my list above? Brouwer&#x27;s intuitionism? FFS get real, I never even heard of that until a few years ago) reply zozbot234 19 hours agorootparentIt is accessible if you know a few bits of syntax, such as → being right-associative so τ1 → τ2 → τ3 means τ1 → (τ2 → τ3). And others such as \"f: X → Y declares f as a function from X&#x27;s to Y&#x27;s.\" which you can find in any math textbook. The point of using such a terse notation rather than faffing around with Callable[…] is to make it possible to work with larger examples without getting bogged down in the verbiage. It&#x27;s why we use symbols to solve equations in K-12 math. reply _a_a_a_ 19 hours agorootparentThe curse of intelligent people, the one thing they can&#x27;t understand; never being able to understand that other people don&#x27;t understand.There&#x27;s something of Cassandra about it. reply sordina 12 hours agorootparentIf someone can learn C type syntax this is MUCH simpler. That doesn&#x27;t mean you don&#x27;t have to spend a little bit of time learning how it works, but it is not some kind of number-theory level maths construction only accessible to savants. reply _a_a_a_ 3 hours agorootparentSee my reply https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37855705 replymrkeen 19 hours agorootparentprevIt&#x27;s just the &#x27;mathy&#x27; type-setting which is hard to read. Types and terms are in the same font & colour and they&#x27;re on the same line. To paraphrase:You can curry a function (supply its arguments one-by-one instead of all at once).You have: f(x, y) which has type (τ1 x τ2) -> τ3You want: f x y which has type τ1 -> τ2 -> τ3Here&#x27;s a function which converts what you have to what you want: λx. λy. f(x, y)It has type: ((τ1 × τ2) → τ3) → (τ1 → τ2 → τ3)This type \"Curry-Howard\"s to the logical formula: (A ∧ B ⇒ C) ⇒ (A ⇒ (B ⇒ C))Since this logical formula is a tautology, the above conversion function preserves the meaning of the function it converts. reply housecarpenter 2 hours agorootparentprevI would interpret \"accessible\" here as meaning relatively accessible compared to what it could be. The underlying concept is inherently difficult, and so it will always be somewhat inaccessible, but within the space of all possible explanations, I would agree that it&#x27;s on the more accessible end rather than the less. reply fooker 21 hours agorootparentprevSeems accessible, if you&#x27;re willing to look up what what you don&#x27;t understand. reply seanhunter 20 hours agorootparentBy that definition \"Baby Rudin\"[1] is an accessible introduction to analysis as long as you&#x27;re willing to look up what you don&#x27;t understand (ie everything probably the first time) in some other source.[1] https:&#x2F;&#x2F;maa.org&#x2F;press&#x2F;maa-reviews&#x2F;principles-of-mathematical... reply fooker 15 hours agorootparentRudin is not accessible if you&#x27;re just looking up things. But it is if you have someone to explain stuff when you get stuff.This one doesn&#x27;t need that. reply user3939382 21 hours agorootparentprevIt doesn’t matter what you think is accessible, it only matters if the person trying to access it thinks it’s accessible. I don’t. reply the_af 20 hours agorootparentIf you can learn how to program, you can learn how to understand this. You first must learn the notation, just as when you learned \"def\", or \"func\", or \"[x for x in ...]\", or \"int main() { ... }\", or whatever your favorite language&#x27;s notation is.\"Accessible\" doesn&#x27;t necessarily mean \"with just knowledge of English, you can jump to this example and immediately understand what it means\". Some work is always required; accessible just means this work is not too hard.For example, Python&#x27;s notation has been occasionally described as \"accessible\", yet I wouldn&#x27;t expect my mum to immediately understand a non-trivial Python snippet (so no \"print(&#x27;hello&#x27;)\") without any previous explanations. reply alpaca128 18 hours agorootparentMaybe if you view \"programming\" as one homogenous block of understanding, but there is a difference between doing basic low-level programming and effectively writing abstract code in Haskell. I can only speak for myself but layers of abstraction make things exponentially harder for me to follow. Compact mathematical notation on top of that feels a bit exhausting.It can probably be called accessible for people already interested or talented in maths, but there&#x27;s a reason most people don&#x27;t just casually learn astrophysics for fun even though some introductory material might be considered accessible - not everyone can do it without unreasonable amounts of effort. reply the_af 17 hours agorootparent> Maybe if you view \"programming\" as one homogenous block of understandingOh, I&#x27;m not saying it&#x27;s the same as programming in your favorite language.I&#x27;m saying if you have the mental machinery to understand a new language, you also have it to learn lambda calculus. Trust me, it&#x27;s not that hard. It just looks extraneous out of context because you are not familiar with it.> It can probably be called accessible for people already interested or talented in mathsI&#x27;m not particularly good at maths and I found introductory-level lambda calculus not very difficult. The notation is different from, say, a C program. You just learn this notation, which your professor will explain. Nothing too terrible.> layers of abstractionI&#x27;m confused. Which layers of abstraction? I mean, it&#x27;s an abstraction just like C or Python or \"1 + 1\" are abstractions. There are rules and you learn how to apply them. reply _a_a_a_ 3 hours agorootparentIt&#x27;s about the entire set of formalisms given in the pdf, not just lambda calculus. The argument here about LC was because I had just given a snippet of it, but it&#x27;s not the whole paper.Now, the next bit – so I&#x27;ve spent my 15 minutes reading up on each of these formalisms (lambda calculus, intuitionistic logic, Hoare notation, whatever else). So now I can read the paper and I do, and now I have absolutely no way of making use of anything I&#x27;ve learnt. I spent personally a lot of time on the computer science side of things, and I have got frankly just about nothing out of it. So frankly again, there&#x27;s no point learning it (from a utilitarian perspective).When I was a kid I picked up a book on Fortran 4 and tried to learn it from the book, without a computer. That&#x27;s pretty much the situation here – a passive notation that, had I managed to internalise it, would have been completely useless because I had no computer to run it on. And I&#x27;m tired of this discussion of people saying it&#x27;s easy and it&#x27;s useful, because it&#x27;s not easy, and it&#x27;s not useful without a whole lot more studying an application to bridge the abstraction of the formalism to the actual programming environment where I can use it.Please just stop repeating stuff. reply vilhelm_s 2 hours agorootparentOk, but now you are making a completely different claim!You started out saying, \"oh, these lecture requires some advanced math background to understand\", and quoted the curry function. And then a lot of people explained that no, there is no advanced math, this is just a function written in a programming language. And now it seems you agree, if you spend only 15 minutes you can understand the lecture notes. That&#x27;s all I, and others, wanted to say.Separately, it&#x27;s the case that understanding this will not be very useful in a day-to-day programming job. That&#x27;s just because it&#x27;s not all that useful! (See other discussion on this this same HN page.) I think it is very cool and philosophically interesting in itself, and it offers an interesting point of view if you are designing new programming language type systems, but it doesn&#x27;t have very much \"utilitarian\" use. reply _a_a_a_ 1 hour agorootparent> And now it seems you agree, if you spend only 15 minutes you can understand the lecture notesthat was sarcasm.> I think it is very cool and philosophically interesting in itself, and it offers an interesting point of view if you are designing new programming language type systems, but it doesn&#x27;t have very much \"utilitarian\" use.It has phenomenal use is my point (eg. formal verification, an interest of mine), but only at a vastly higher level than \"I&#x27;ve been to the lectures\". What I keep saying is, most people aren&#x27;t interested in the abstract, and neither am I. Give me a practical application and suddenly I&#x27;ll &#x27;get it&#x27;. Without that application it&#x27;s valueless because I have no reason to engage with it, and actually cannot. Put another way: its application and its understanding are interlinked. You can separate them; I and others can&#x27;t.I know this stuff is useful and I literally spent years trying to understand it. For someone like me it just isn&#x27;t easy, and you keep persistently not understanding that. reply emporas 15 hours agorootparentprevCertain proofs about a program, implemented using types, are useful in high level programming, as well as low level programming. See Rust in the linux kernel [1], and Rust on Android[2].One way to think about it, is that proofs about a program are a continuum, rather than one or the other. Sure, going all the way, disallowing mutability and requiring types for everything, might make the system more provable, but slower as well.There are some different ways to look at a program:Corporate developer: \"Programs are to be run, and occasionally read or proved correctly\" Donald Knuth: \"Programs are to be read, and occasionally run\" Type Theorist: \"Programs are to be compiled, and occasionally run or read\"https:&#x2F;&#x2F;thenewstack.io&#x2F;rust-in-the-linux-kernel&#x2F;https:&#x2F;&#x2F;security.googleblog.com&#x2F;2023&#x2F;10&#x2F;bare-metal-rust-in-a... reply _a_a_a_ 19 hours agorootparentprevQuiz: what is the opposite of patronising? Because that&#x27;s what you&#x27;re being. Not talking down to people but assuming more than is typical.You&#x27;re clearly highly intelligent, evidently more so than I am. Additionally my mind doesn&#x27;t work like yours, I&#x27;m not an abstract thinker. Plonk stuff like this in front of me and I can decipher it eventually, if I can get some clear statement of the notation and its semantics anyway, and there is stuff in there I&#x27;m not familiar with.Most people aren&#x27;t abstract thinkers. They are motivated by practical concerns. I spent an enormous amount of time reading up on stuff like this and I really can&#x27;t see the value to it to me as a programmer. It&#x27;s deeply frustrating because I know it has value, but I just can&#x27;t use it. It&#x27;s interesting, I know it&#x27;s useful, but I can&#x27;t use it.Please allow that other people think differently and are motivated differently, and don&#x27;t assume that what&#x27;s easy for you is for them. I wish I had your cranium. reply the_af 17 hours agorootparent> Quiz: what is the opposite of patronising?Humble, respectful, modest?I respect that different people will find different things hard or easy, so that a generalization is never truly possible (except, uh, this sentence?). On the other hand, speaking with absolutely no generalizations whatsoever is simply not possible, because so many caveats and exceptions would make communication impossible.I do stand by my initial assertion that, in general, if you have a mind capable of learning a new programming language, you can learn lambda calculus, and it won&#x27;t be particularly hard. reply zozbot234 19 hours agorootparentprev> Most people aren&#x27;t abstract thinkers. They are motivated by practical concerns.Abstract thinking is motivated by practical concerns, namely being able to think comfortably about larger problems without being limited by one&#x27;s capability for complex reasoning. Most people don&#x27;t do it because they aren&#x27;t used to, or they have never been taught how. reply SilasX 21 hours agorootparentprevUnder that constraint, what wouldn&#x27;t count as an accessible exposition? reply fooker 15 hours agorootparentSomething involving implicit knowledge and conventions that is not spelled out. reply vkou 21 hours agorootparentprev\"I have a truly marvelous demonstration of this proposition which this margin is too narrow to contain.\" reply SilasX 21 hours agorootparentSo the only way for an explanation not to be accessible is to not provide it? Okay. reply 0003 19 hours agorootparentIn the spirit of the topic, I ran the truth tables you got yourself a valid argument. Feel free to pin this to the top. reply _a_a_a_ 21 hours agorootparentprevOh get real. I have a background in this. Lambda notation, Hoare notation (I think), &#x27;standard&#x27; logic notation.Don&#x27;t talk rubbish about &#x27;look it up&#x27;. You need a degree to get this. Not a metaphorical degree, the real thing.Edit - and a brain bigger than mine. reply the_af 20 hours agorootparent> Don&#x27;t talk rubbish about &#x27;look it up&#x27;. You need a degree to get this. Not a metaphorical degree, the real thing.You really don&#x27;t need a degree. The Curry-Howard isomorphism is taught in undergraduate CS courses, to students who are simultaneously being introduced to lambda calculus.While I wouldn&#x27;t say it&#x27;s trivial, it&#x27;s not rocket science either. Most students get it and pass the exams. reply fooker 15 hours agorootparentprevIt&#x27;s an introductory CS concept, requiring a degree would make things a bit circular... replyewuhic 5 hours agoprevIn addition to my other comment here, is there any application of formal verification for complex ETL (Data) pipelines, from the standpoint of enumerating transformations, workflow steps, and states, with less emphasis on temporal soundness? reply pas 4 hours agoparentmy first thought was something something dependent types (Idris, Agda), but it also sounds like TS-like structural typing with a Rust-like Result type. proving that every incoming message is either parsed correctly or we return an error seems to be the basic building block. and then every transformation should be other pure functions.thought I guess you mean something more top-downish? for that there&#x27;s \"program interpretation\" ( https:&#x2F;&#x2F;github.com&#x2F;AdrielC&#x2F;free-arrow )and this just looks very interesting https:&#x2F;&#x2F;deepai.org&#x2F;publication&#x2F;a-coq-based-synthesis-of-scal... reply throwthrow5643 2 hours agoprevHow to formally verify a single page web application? reply athrowaway3z 22 hours agoprevOn a tangent. I think its worth it to push typed mathematics waaaaay down into highschool. While students are learning multiplication, the teaching tools&#x2F;question&#x2F;answers need to teach how that changes the result&#x27;s units (types). Highschool physics especially needs to have &#x27;proper units at every stage of calculation&#x27; as part of the test.ps. and our calculators (& excel) needs better support for it reply crazygringo 19 hours agoparent> Highschool physics especially needs to have &#x27;proper units at every stage of calculation&#x27; as part of the test.Did your highschool physics not have this? I always thought it was a universal part of all physics education. Doing things like canceling out units etc. has always been a big part of high school physics, and checking that your final answer has the units it should. (If it didn&#x27;t, you made a mistake somewhere.)The idea of building units into Excel is definitely an intriguing one, though. I&#x27;m honestly kind of surprised it&#x27;s the first time I&#x27;ve ever heard it suggested. It does seem like a pretty useful idea. reply antegamisou 15 hours agorootparentDid your highschool physics not have this?Gotta love that USA&#x27;s &#x27;A&#x27;P classes&#x27; entire curriculum are Chapter 1, p.1 everywhere else. reply OkayPhysicist 15 hours agorootparentUnit analysis is absolutely a graded element of the AP test. The American educational system has enough to point and laugh at without fabricating new stuff. reply Jtsummers 22 hours agoparentprev> Highschool physics especially needs to have &#x27;proper units at every stage of calculation&#x27; as part of the test.I can&#x27;t imagine any HS science class not already doing this. It would be impossible to answer many, if not all, of the questions correctly if you mix units (either unit-kind like mixing time and distance units, or unit-scale like mixing seconds and hours). reply euroderf 21 hours agorootparentNor possible to write literately about energy issues. reply carbocation 22 hours agoparentprevWhen I was in high school units were a key part of science education. Is this no longer the case?Your point about tools that support units is great. Reminds me of https:&#x2F;&#x2F;frinklang.org&#x2F; reply tsimionescu 18 hours agoparentprevTypes and units are very different concepts. In fact it&#x27;s quite hard to formalize the way units are used in everyday physics.For example, what is the type of the &#x2F; operation such that 4m&#x2F;2s = 2m&#x2F;s, but also 4kg&#x2F;2kg = 2?It&#x27;s not impossible of course, but it is highly tedious and complex to actually define these types in a formal way.Not to mention, linear algebra (matrix operations) gets REALLY ugly to define formal types for really fast if you allow different measurement units for every matrix element, like you often do in physics.And, just like the others, I never met a physics class that didn&#x27;t enforce unit maths at every step of computation, starting in sixth grade.But this is done with a simple informal system, not type theory of all things. The informal system of measurement units being essentially to treat the units as special values that act as factors and obey all the usual rules of multiplication and division, and don&#x27;t allow addition or subtraction. reply seanhunter 20 hours agoparentprevMost maths teaching emphasises this but they don&#x27;t talk about it in quite the same way. Units are dealt with as units whenever you are doing real world problems around velocity, speed, physical quantities etc and you are taught not to mix units, and how units \"cancel\" etc each other when you deal with exponent laws.Types as such are dealt with as sets. So for example I&#x27;m working my way through Serge Lang&#x27;s \"Basic Mathematics\" at the moment[1], and it starts with the natural numbers, then the positive integers, then the integers, then the rational numbers, then the reals etc. This is very normal for high-school level maths education.I believe that mathematically the formal theory of types comes from a different branch from sets which arose when Russel attempted to address the problems caused by his paradox. \"Type\" theory was part of Russel&#x27;s solution whereas Zermelo Fraenkel set theory is where everyone else felt that sets just needed a little patch to carry on working pretty much as before.[1] Which I&#x27;d really recommend for anyone who wants a maths refresher that starts from very basic concepts but really challenges you to think like a mathematician, prove things etc. So in the first chapter when you only know the distributive and associative properties he has you using them to prove stuff. reply samirillian 21 hours agoprevI don&#x27;t know that much about it, but the impression I got from studying TLA+ was that machine-executable code was distinctly not mathematics, and that programs are never provable. Am I wrong? Or is this just the kind of sensational snake-oil that HN readers are susceptible to buying. reply miloignis 20 hours agoparentIf I understand what you are asking about correctly, then I do think you are mistaken.As a sibling comment observed, you would be proving something about a program, but proving things about programs is both possible and done.This ranges from things like CakeML (https:&#x2F;&#x2F;cakeml.org&#x2F;) and CompCert (compilers with verified correctness proofs of their optimizations) to something simple like absence of runtime type errors in statically strongly soundly-typed languages.Of note is that you are proving properties of your program, not proving them perfect in every way. The properties of your program that you prove can vary wildly in both difficulty and usefulness. A sufficiently advanced formally verified compiler like CakeML can transfer a high-level proof about your source code to a corresponding proof about the behavior of the generated machine-executable code. reply aeneasmackenzie 20 hours agoparentprevTypical proofs don’t cover side channels, just ISA semantics. With the big asterisk that most programs are running on top of an unverified kernel on an unverified machine-level blob on an unverified ISA implemented by an unverified chip, you can absolutely prove the behavior of programs. Lamport has an unusual attitude towards verification and comes towards it from a slightly different angle, and model checking is not a good approach to machine-level proofs. reply nyrikki 20 hours agoparentprevNote this quote from the article.\"One way to resolve the paradox, therefore, is to put these types into a hierarchy, so they can only contain elements of a “lower level” than themselves. Then a type can’t contain itself, which avoids the self-referentiality that creates the paradox.\"This is similar to constraints of making something semi-decidable or recursively enumerable.Provable, recursively enumerable, semidecidable, and turing recognizable are all the same thing described in different ways.Some things are easier to find in type theory, other in set theory and for some Turing machines work better.The Church–Turing thesis isn&#x27;t provable but is the safe assumption.IMHO termination analysis, which will never be complete, has more interesting and has some implications for ATP that aren&#x27;t as easily captured in type theory.As an example related to term rewriting which will be important to ML.https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.14805 reply staunton 20 hours agoparentprevWhat does it mean to say \"a program is provable\"? You have to prove something about it.In principle, nothing prevents you from taking e.g. an ARM binary and formally proving that it will never crash in some environment, e.g., bare metal chip with known amounts of memory etc. This is very hard for useful programs and not worth it in pretty much any application there ever was, but it&#x27;s possible and getting ever easier over time. reply mapM 20 hours agoparentprevI think you misunderstand. On your point about programs not being \"provable\": it is certainly possible to prove some properties about some programs. It is not necessarily easy, and it very much depends on the program and the property in question, but it is possible.However, this is not what the article is about. Instead, it talks about an interesting observation that there is a direct correspondence between a certain kind of program and a mathematical proof, and also between the type of the program, and the theorem validated by the proof. In other words, you can think of mathematical proofs as computational objects. The intuition for the correspondence is not hard: for example, support I want to prove that \"if A is true, then B must also be true\". You may think of a proof for such a property as a program, which takes as input a proof that `A` holds, and as its output produces a proof that `B` holds. reply nyrikki 19 hours agorootparentEntscheidungsproblem, the Halting problem, the total function problem, etc... typically relate to arbitrary programs.The point being is there is no single general algorithm that can solve them.The example you gave above is propositional logic, or zeroith order logic which is known to be decidable.First order logic and higher order logic are not decidable.Total functions are also not subject to the halting problem, but unfortunately finding a total function in the general case is also undecidable. reply bluGill 21 hours agoparentprevMost code is so complex that even with the aid of a computer we couldn&#x27;t run a proof on it if we tried. Most (all!) code also has bugs so if we tried to prove it we would instead prove it doesn&#x27;t meet requirements. However the theory itself allows that all code could be mathematically proven if you can work around those two issues.It also isn&#x27;t clear that the machines itself actually do what they say, though hardware is a lot more likely to be mathematically proven. reply Tainnor 19 hours agorootparentWe run proofs on code all the time, it&#x27;s called type-checking.What you mean is that it&#x27;s practically infeasible to verify every program behaviour we&#x27;re interested in. That&#x27;s probably true for large enough programs, but it doesn&#x27;t mean we can prove nothing about them. reply staunton 20 hours agorootparentprev> hardware is a lot more likely to be mathematically provenMaybe that&#x27;s a nitpick, but I would say it&#x27;s fundamentally impossible to mathematically prove anything at all about a physical system. You have to assume some model to do the proof and have no way of ever \"proving\" (what would that even mean?) that model.I guess you&#x27;re referring to the fact that verification and formal methods are used in hardware more often than software. This is due to commercial reasons: you can&#x27;t just reprogram a million chips once they leave your fab. reply kaba0 19 hours agorootparentprev> However the theory itself allows that all code could be mathematically provenI don’t think this is true, something as “trivial” as halting already can’t be proven in the general case. reply bluGill 18 hours agorootparentBut we never need to prove the general case, only specific cases. The general case includes an infinite number of inputs, but in reality there is only a finite number of states a physical computer can have (the number of states far exceeds the number of atoms in the universe, but it is still finite) reply kaba0 17 hours agorootparentGeneral case in what meaning? You do have to prove (the interesting properties of) a given algorithm to each possible input, e.g. no one would want to use a sort algorithm that loops forever on a specific list of integers.And the number of possible states increase so fast that you might as well think of it as infinite. reply bluGill 16 hours agorootparentSo long as the list is finite and no being modified outside of sort that can be done for some sort algorithms. Bogo sort wouldn&#x27;t. IfI find it amusing how much closer Dijkstra&#x27;s approach is to what might be called \"normal\" (Algol-ish) programming compared to the Abstract Nonsense[5] favored by the category theorists. I wouldn&#x27;t call it any less mathematical though.It&#x27;s true that he mainly used a sequential, imperative notation for describing things, but it seems like later in his life, he preferred functional programming for teaching computer science to students. He petitioned the University of Texas to not switch from teaching it in Haskell to teaching it in Java for this reason.https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;OtherDocs&#x2F;To%20the%20Bud...A fundamental reason for the preference is that functional programs are much more readily appreciated as mathematical objects than imperative ones, so that you can teach what rigorous reasoning about programs amounts to. The additional advantage of functional programming with “lazy evaluation” is that it provides an environment that discourages operational reasoning. reply SilasX 21 hours agoprevOkay. Today I&#x27;ll be the idiot.I don&#x27;t get it. Or rather, I don&#x27;t get the significance of the Curry-Howard Isomorphism. Questions:1) Is there an example of a proof and its corresponding program that makes you say \"whoa, trippy, I didn&#x27;t expect those to be related\"? Like, yeah, an Int -> Boolean function \"proves\" you can construct a Boolean from an integer, but ... so what? What would a non-trivial proof (say, on the order of the Pons Asinorum) look like as a program?2) Are the \"programs\" referred to here to merely pure functions (i.e. side effect-free, global state-free ones)? It sounds like it is based on lines like this:>When a computer program runs, each line is “evaluated” to yield a single output.That ... seems to cram \"computer programs\" into some kind of Procrustean bed unless we&#x27;re taking about pure functions. But then it also talks about how CHI has applications in verifiable programs, which, I&#x27;m told, can reason about side effects.Feel free to call me an idiot, as long as you can also inspire an aha-moment. reply mrkeen 18 hours agoparent> I don&#x27;t get the significance of the Curry-Howard Isomorphism.* Every type system is a system of logic (and vice-versa.) * So, if you have a System F, you can build a Haskell. * If you have affine logic, you can make Rust.Have a look at this parser combinator library[1]. In particular look at how many functions are marked \"Totality: total\". These are functions which accept all (well-typed) inputs and terminate in finite time.> What would a non-trivial proof (say, on the order of the Pons Asinorum) look like as a program?It would just be a program - that you write every day. If Pons Asinorum is expressed in twenty lines, then pick a twenty-line program. If you want something bigger, check out CakeML or seL4.> But then it also talks about how CHI has applications in verifiable programs, which, I&#x27;m told, can reason about side effects.Not every effect is a side-effect. A suitable definition of \"side-effect\" might be \"an effect which is able to punch a hole through whatever type system decided it was valid.\" If your programming language represents effects as types, then it can reason-about&#x2F;type-check them just as well as pure functions.[1] https:&#x2F;&#x2F;www.idris-lang.org&#x2F;docs&#x2F;idris2&#x2F;current&#x2F;contrib_docs&#x2F;... reply zozbot234 21 hours agoparentprevInt -> Boolean is just the type of any arbitrary decidable property on Int&#x27;s, so it&#x27;s not very useful on its own. But if you can endow your Int -> Boolean function with a proof that it computes some property you actually care about, that&#x27;s more likely to be helpful. The proof itself need not even be constructive, since the requirement for constructibility was taken care of by providing the code for that function. Constructibility becomes more of a big deal if you want to be able to compose constructive proofs, or write proofs that rely on instances of some other proof as input, since then the strategy of providing some construction as a bare algorithm and separately proving it correct may run into problems.And if your return type is something other than Boolean, that represents some more general construction rather than mere decidability. But everything else is just about the same. Of course this all assumes a total language with no general recursion, since otherwise you can \"prove\" anything by just looping forever and not delivering a result. reply SilasX 21 hours agorootparent> But if you can endow your Int -> Boolean function with a proof that it computes some property you actually care about, that&#x27;s more likely to be helpful.Agreed, but that&#x27;s beyond the scope of what&#x27;s asserted with CHI, right? CHI is asserting that my implementation of some type-correct[1] (int-to-)Boolean function is, itself -- irrespective of what I can prove about it -- equivalent to some other proof. What&#x27;s that proof, and what&#x27;s interesting about the proof or the mapping?[1] i.e. really does take ints and always returns bools reply zozbot234 21 hours agorootparentCHI is just the observation that some logical steps in proofs behave as similar steps in programs. For instance, \"Apply Lemma f to variable x with preconditions given by H1, H2; call the resulting statement L\" is equivalent to a function call L = f(x, H1, H2) where H1, H2 are capabilities or abstract \"tokens\". Proof by cases can be expressed as a switch { } or match { } construct, and proof by induction behaves as recursion. This often simplifies the writing of \"correct by construction\" programs since a single construct can take care of both the computational and the logical side. reply SilasX 20 hours agorootparent>CHI is just the observation that some logical steps in proofs behave as similar steps in programs.It would have to be all, not just some, or it&#x27;s not an isomorphism (or there are caveats about function purity I mentioned before).>\"Apply Lemma f to variable x with preconditions given by H1, H2; call the resulting statement L\" is equivalent to a function call L = f(x, H1, H2) where H1, H2 are capabilities or abstract \"tokens\".Okay, that helps. So where are the mind-blowing examples? reply zozbot234 9 hours agorootparentIt&#x27;s not quite \"all\" because non-constructive proofs exist. In an ordinary program you can&#x27;t just switch between returning a value as output and requesting it as an input, but in proofs you can kinda do this - and that&#x27;s a logical step called \"proof by contradiction\". reply kaba0 19 hours agorootparentprevI am absolutely not an expert here, but you probably want dependent types to have more interesting examples.Hopefully my made up syntax is understandable fermat x y z: Int -> Int -> Int -> c: (x^z+y^z=c^z and Int)This might only ever have an implementation if we hard code it to z=2. replyvalyagolev 16 hours agoparentprevI know a Pons Asinorum that kinda was mind-blowing to me. It uses topology connection to define an unexpected function.\"Infinite search in finite time\" https:&#x2F;&#x2F;math.andrej.com&#x2F;2007&#x2F;09&#x2F;28&#x2F;seemingly-impossible-func... https:&#x2F;&#x2F;math.andrej.com&#x2F;2008&#x2F;11&#x2F;21&#x2F;a-haskell-monad-for-infin... reply mjw1007 20 hours agoparentprevI don&#x27;t think you&#x27;re being an idiot.There are some connections in mathematics that are quite \"magical\", where you get something like a correspondence between a family of curved surfaces and a family of integer-valued equations, and it&#x27;s not at all obvious why that might be until you study it deeply.And sometimes articles about the Curry-Howard Isomorphism suggest that it&#x27;s an example of that sort (I think this article does, to some extent).But (as I understand it), that isn&#x27;t the case: here we have a simple directly-constructed correspondence. It&#x27;s valuable, but not the sort of thing that mathematicians think of as a wonderful result. reply c-cube 20 hours agoparentprevI also still don&#x27;t get it, years later. I wrote a short post on this (a bit too inflammatory, tbh, sorry for the URL): https:&#x2F;&#x2F;blag.cedeela.fr&#x2F;curry-howard-scam&#x2F; . A lot of logic and theorem proving can be done without ever thinking about CH. In classical logic I think it&#x27;s not even that convenient anyway, and classical logic is a pragmatic choice. reply miloignis 20 hours agoparentprevHmmm, I can try to address your questions.1) The trippy one I know of is that the Church encoding of numbers is the induction principle for naturals.2) Generally the programs that are proofs you would want to be pure, but it wouldn&#x27;t be strictly necessary. The impurity would have to be handled by the type system though, so explicit effects not side-effects.Also, note that even though you want the programs-that-are-proofs to be pure, that doesn&#x27;t mean you can&#x27;t prove things about programs that are impure - that is, you have a pure-program that has a type, and that type is a proposition about a different impure program.That is, I can create a pure program that is a proof about my impure program.EDIT: I think something that is a sticking point for a lot of people is looking for a program that is useful by itself that is also the proof of something useful. This is possible, but a bit rare-er - oftentimes you have useful programs with trivial types, or useful programs-that-are-proofs that you don&#x27;t actually care to run. These are still super useful though! It is possible to have ones that are both - decidability of things is what comes to mind. You could write a program that determines if two naturals are equal - that&#x27;s a useful program, albeit one of the simplest - and that program also serves as a proof that two naturals are either equal or not - a kind of particular instantiation of the law of excluded middle. One style of programming with dependent types always returns a proof along with the returned value, which might be kind-of what you&#x27;re looking for. (Think of a regular expression engine that along with the yes&#x2F;no does this string match this regular expression, returns a proof that the string does or doesn&#x27;t match, demonstrating its own correctness) reply mostlylurks 17 hours agoparentprev2) Being restricted to pure functions is not actually much of a restriction at all. Any impure input can be trivially replaced with parameterization over values representing that input and any impure output can be trivially replaced by including state updates or the updated state in the return value. Then your entire codebase can be entirely pure and you can let the language runtime or the compiler deal with that pure data at the very top level of the program, performing the IO as needed. This may be slightly more inconvenient than allowing impurity, but not enough that it would be by any means infeasible, and languages like Haskell have facilities which narrow the gap even further, so it&#x27;s not much of a restriction at all. reply bo1024 20 hours agoparentprevMaybe not trippy, but a simple set of examples are existence theorems, i.e. \"Given these objects, X exists.\" An example are fixed point theorems.Theorem: For any function g from a convex, compact set to itself, there exists a fixed point of g.program f: g --> x where g is a function from a convex, compact set C to itself, and x satisfies g(x) = x.If you can write the program and it is correct for all such g, that is a proof that such a g always has a fixed point (in particular, you output one). Note the \"type\" of g is \"function from convex, compact set to itself\" and the \"type\" of x is \"fixed point of g\". reply armchairhacker 20 hours agoparentprevYou won&#x27;t see many examples of \"traditional\" languages taking advantage of Curry-Howard. Though you can, e.g. an `Admin` class whose constructor checks that the credentials are for an admin, and functions like `deleteDatabase` which take an `Admin` instance and don&#x27;t check for admin credentials because they&#x27;re already \"proven\". loginAdmin(name: &str, password: &str) -> Result deleteDatabase(admin: Admin, dbConnection: &DbConnection, dbName: &str) -> ResultBut 2) is correct: these aren&#x27;t real proofs, because globals and errors can break Curry-Howard, not to mention unsafe coercions. let evilAdmin: Admin = unsafe { std::mem::transmute([0; size_of()]) }; deleteDatabase(evilAdmin, dbConnection, \"important_data\");You can&#x27;t even allow functions which infinitely loop: in theorem-proving languages, every function must be proved terminating. Otherwise you allow: anything : a anything = recurse 0 where recurse i = recurse (i + 1)But in theorem-proving languages, the idea that \"this type represents a logical statement, an instance only exists if it&#x27;s true\" is used very often. A classic example is fixed-size vectors data Nat where 0 : Nat S : Nat -> Nat -- n + 1, \"S\"uccessor data Vec (n : Nat) a where Nil : forall a, Vec 0 a Cons : forall n a, a -> Vec n a -> Vec (S n) aYou will see declarations like: -- Instances of `IsTrue b` only exist if `b = True` data IsTrue (b : Boolean) where Trivial : IsTrue True -- Instances of `Every pred vec` only exist if every element in `vec` satisfies the predicate (so that `pred elem = True`) data Every (pred : a -> Boolean) (vec: Vec n a) where Every_nil : forall pred, Every pred Nil -- Every item of an empty vector satisfies an arbitrary predicate -- Prepending an element which satisfies some predicate to a vector where every element satisfies the same predicate, produces a vector where every element satisfies the same predicate Every_cons : forall pred x xs, IsTrue (pred x) -> Every pred xs Every pred (Cons x xs) foosAreFoo : Every (\\n -> n == \"foo\") (Cons \"foo\" (Cons \"foo\" (Cons \"foo\" Nil))) foosAreFoo = Every_cons Trivial (Every_cons Trivial (Every_cons Trivial Every_nil))On the other hand, the requirement that all functions must be \"logical statements\" is essential. Otherwise the programs will crash and the generated proofs will be illogical (and, notice that \"crashing program\" = \"illogical proof\"). For example, if one can define the following (impossible to prove) function, one can create programs which crash trying to extract the first element of an empty vector, and proofs which incorrectly assume that all vectors have a first element. head : Vec n a -> a head Nil = ??? head (Cons x _) = xOne can define this function though, taking advantage of the fact that there&#x27;s no such instance `Nil : Vec (S n) a` so only the `Cons` case needs to be matched (which is why this typechecks even though we didn&#x27;t handle the `Nil` case, while the above example doesn&#x27;t. Sorry if it&#x27;s confusing and&#x2F;or sounds like a cop-out, that&#x27;s just how it works and real languages accept this kind of pattern matching): head : Vec (S n) a -> a head (Cons x _) = xAnd, to answer the second point, theorem-proving languages can represent and prove properties of programs with side-effects and even straight-line programs. The former is commonly done using Monads or Algebraic Effects, and the latter using Hoare Logic or another kind of logic data Var a = String -- Example IO monad which represents side-effects (stdin, stdout, and variables) through constructors data IO a where Pure : a -> IO a ReadLine : IO String PrintLine : String -> IO () ReadVar : Var a -> IO (Maybe a) WriteVar : Var a -> Maybe a -> IO a (>>=) : IO a -> (a -> b) -> IO b -- \"Pure\" program which reads first and last name and prints full name. -- The \"interpreter\" lazily computes the value of `main` and simultaneously evaluates `IO` actions to get their inner values: -- When it encounters (x >>= y) it computes `x`, evaluates `x` to get the inner value at runtime, -- then computes and evaluates `y` main : IO () main = PrintLine \"What is your first name?\" >>= \\() -> ReadLine >>= \\firstName -> PrintLine \"What is your last name?\" >>= \\() -> ReadLine >>= \\lastName -> Pure (firstName ++ \" \" ++ lastName) >>= \\fullName -> PrintLine (\"Hello \" ++ fullName ++ \"!\") foo : Var Int foo = Var \"Foo\" -- Proving properties of programs is done with Hoare Logic. -- This is a lot more complicated and full of boilerplate... data Predicate where True : Predicate (!==) : forall a, Var a -> a -> Predicate (&#x2F;\\) : Predicate -> Predicate -> Predicate data HoareTriple (pre : Predicate) (stmt : IO ()) (post : Predicate) where Obvious : forall pre stmt, HoareTriple pre stmt True Merge : forall pre stmt post1 post2, HoareTriple pre stmt post1 -> HoareTriple pre stmt post2 -> HoareTriple pre stmt (post1 &#x2F;\\ post2) WeakenL : forall pre1 pre2 stmt post, HoareTriple pre1 stmt post -> HoareTriple (pre1 &#x2F;\\ pre2) stmt post WeakenR : forall pre1 pre2 stmt post, HoareTriple pre2 stmt post -> HoareTriple (pre1 &#x2F;\\ pre2) stmt post Specific : forall varN n, HoareTriple (varN !== n) (ReadVar varN >>= \\nValue - WriteVar (varN + 1)) (varN !== (n + 1)) example : HoareTriple (foo !== 4 &#x2F;\\ foo !== 5) -- Precondition (ReadVar foo >>= \\fooValue -> WriteVar (fooValue + 1)) -- Statement (foo !== 5 &#x2F;\\ foo !== 6) -- Postcondition example = ... -- Some combination of Merge, WeakenL, WeakenR, and Specific, but I&#x27;ve written enough reply zmgsabst 21 hours agoparentprevThere are only side effects!When you compute a pure function, you’re still physically manipulating registers, cache, etc.You can use the proof-program perspective to formalize reasoning about a program:- you have some domain model; this expresses the “business logic” of your software- you have an abstract model, in a category for your programming language; this expresses an equivalent structure as the “business logic”- you have a concrete model, in a category for your hardware; this expresses an equivalent structure as it gets executedReasoning about the translations between these steps, their properties, etc is why you want to connect software to proofs.For example, if you want to find an optimal implementation: you want the shortest path of atomic arrows in your hardware category, which corresponds to the desired computation in your language category.Category theory is the language in which we connect our theory of hardware to our theory of the business domain! reply auggierose 20 hours agoprevMost overrated correspondence ever.You don&#x27;t need curry-howard for software verification, you don&#x27;t need it for mathematics, and you don&#x27;t need it for logic.You only really need it to j*rk off hard over types. reply jqpabc123 22 hours agoprevYes, of course there is a link.At the lowest machine level, a computer program is simply base 2 math --- the simplest possible number system --- aka binary logic.Aside from moving mathematical data around in storage, math is really about the *only* thing a computer processor does. reply worik 20 hours agoprev [–] This is very old.Yes, programming is a super set of theorem proving.It is true, but not generally useful.Building useful programmes is, IMO, best described as a craft. It is learnt from other crafters, and improves with practiceFormal methods can be helpful in specific cases but generally speaking writing correct formal specifications is just as hard, or harder, than writing useful, reliable, computer programs reply passion__desire 19 hours agoparent [–] Craft similar to painting which AI has overtaken. What we consider programming will go the similar route. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article gives an overview of the Curry-Howard correspondence, linking mathematical proofs and computer programs, suggesting equivalency between types and programs in computer science and propositions and proofs in logical disciplines.",
      "Potential applications and implications of this correspondence are touched upon, including its pertinence to software verification procedures and the development of proof assistants.",
      "It highlights that this link between computation and logic isn't confined to intuitionistic logic alone and mentions its foundational nature, evident in its discovery by multiple researchers."
    ],
    "commentSummary": [
      "The Hacker News discussion revolves around the correlation between mathematical proofs and computer programs, along with the role of mathematics in programming.",
      "Participants voice challenges in achieving provably correct timing, the accessibility of abstract concepts, and the need for practical applications for learning.",
      "The conversation also delves into the Curry-Howard Isomorphism and the use of theorem-proving languages to verify program properties."
    ],
    "points": 233,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1697035945
  },
  {
    "id": 37853181,
    "title": "Metric Time",
    "originLink": "https://metric-time.com/",
    "originBody": "METRIC TIME METRIC TIME 3:40:43 STANDARD TIME STANDARD TIME 8:10:13 AM Metric Time With metric time the day is broken into 10 hours. 10 1 2 3 4 5 6 7 8 9 10 12am 1 2 3 4 5 6 7 8 9 10 11 12pm 1 2 3 4 5 6 7 8 9 10 11 12am Standard Time Of course, with standard time the day is broken into 24 hours. Metric Hour A metric hour is broken into 100 minutes. 0 10 20 30 40 50 60 70 80 90 100 0 15 30 45 60 Standard Hour A standard hour is broken into 60 minutes. There are 2.4 standard hours in 1 metric hour. Metric Minute A metric minute is broken into 100 seconds. 0 10 20 30 40 50 60 70 80 90 100 0 15 30 45 60 Standard Minute A standard minute has 60 seconds. There are 2.4 standard minutes in 1 metric minute. Rationale for Metric Time What makes metric time so cool is that would make all the mental math we have to do when adding and subtracting time so much easier—especially when it comes to different timezones. Working with base-10 numbers is so much easier than trying to think in base-60, base-12, and base-24. There is no AM or PM with metric time. Just 10 hours in the day. To get a good night sleep (8 standard hours) you'd sleep for 3.33 metric hours. If you go to bed at 9:50 metric time (about 10:45pm in standard time), wanting to get a good night sleep, you'd wake up at 2:75 metric time (roughly 6:45am standard time). Remember, a half hour in metric time is 50 minutes, and a full hour is 100 minutes. One metric minute before \"midnight\" (10:00 on the metric clock) would be 9:99 in metric time. Time is Money The logic you use to tell time with metric time is very similar to how you think about money (assuming US Dollars). One metric hour is like a 100-dollar bill. One metric minute is a 1 dollar bill. And each metric second is a penny. Each day (10 metric hours), has 1,000 minutes, and 100,000 seconds. It's an interesting way to think about the time we get to spend each day.",
    "commentLink": "https://news.ycombinator.com/item?id=37853181",
    "commentBody": "Metric TimeHacker NewspastloginMetric Time (metric-time.com) 240 points by rickcarlino 11 hours ago| hidepastfavorite235 comments kybernetikos 3 hours agoI&#x27;m a big fan of decimal time (or French Revolutionary Time as it&#x27;s sometimes called). I made my own version a few years back: https:&#x2F;&#x2F;kybernetikos.github.io&#x2F;UIT&#x2F;My version also removes timezones. The numeric time is the same whereever you are in the world, but the display changes based on your location so that local solar midday is straight up on the clock face and local solar midnight is straight down on the clock face. Day and night hours are drawn on the face.I used to have it attach to your google calendar and draw meetings onto the clock face too, but I think in the last 11 years the google calendar api has changed and I haven&#x27;t updated it.Obviously once you have metric time, you need a metric week too, so I have new week days: nullday, unday, duoday, triday, quadday, hexday heptday, octday and nonday. There&#x27;s no need for months anymore, I just number the weeks. Of course 28th Quadday is the 285th day in the year, as the first day is 0th Nullday. Fixing the number of weeks in a year to a round number is left as an exercise for the reader.Time and date maths becomes very simple. reply paulryanrogers 2 hours agoparentIs there a quarter day at the end of the year? reply kybernetikos 2 hours agorootparentNo because its a humane rather than scientific system. Day lengths in a scientific time vary, but in this system the hours are defined to be 10ths of a solar day so they vary as the day varies. Scientific measurement should be done with a different system. I&#x27;d suggest something based on the speed of light. reply xattt 2 hours agorootparent> … but in this system the hours are defined to be 10ths of a solar day so they vary as the day varies.This is reasonable and not unsafe at all, particularly when it comes to timing things like exposure time with patients receiving radiation therapy.However, we will be left wondering why treatment in the summer is more effective that treatment in the winter. Must be the nice weather. reply lesuorac 1 hour agorootparentIs that how you program things?I recommend using as little as date&#x2F;day mechanics as you can get away with. Instead using a monotonic durations as much as you can [1].If you continue to program with date&#x2F;day mechanics you&#x27;ll run into plenty of issues when users cross timezones or just set the time on their phone to a different one.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Unix_time reply worthless-trash 16 minutes agorootparentMy favorite things is when you connect to cell towers that have DST in one state, and not in another, the cell phone getting the time&#x2F;date from \"the network\". reply lokar 37 minutes agorootparentprevOr heating up a frozen burrito reply demondemidi 2 hours agorootparentprevintercalation took millennia to get right and was driven largely by starvation due to crop failure. reply rimliu 1 hour agoparentprevSimple and useless. You can have any system you want for your personal use, but clocks and calendars are for colaboration. It&#x27;s nice that you have day and night hours on the clock where you are. No you will travel a few thousand kilometers. You know your decimal time you get there, do you know whether it will be daytime or nighttime? You get there, and it is winter and the dark time is 3x of the daytime. Have you got any idea when anything opens and closes? And why have weeks if you don&#x27;t have months. How about just numbered days? reply toxik 6 hours agoprevI love how the example is super confusing.You sleep 3.33… metric hours.You fall asleep 9:50 metric time.You&#x27;d think we can just interchange the . and : so you should wake up 12:83…, or 2:83… the next day.But no, it&#x27;s apparently 2:75 metric time. Why?Also nice how they IMMEDIATELY ran into a continuing fraction 1&#x2F;3, which is exactly the point of the 60-minute hour, 24-hour day, or 360-degree circle: lots of factors. reply L3viathan 5 hours agoparent> Also nice how they IMMEDIATELY ran into a continuing fraction 1&#x2F;3, which is exactly the point of the 60-minute hour, 24-hour day, or 360-degree circle: lots of factors.While I agree in principle, this example is not evidence of it. It&#x27;s not like we measured the amount of sleep needed and it&#x27;s precisely 8 hours. A more reasonable thing to say would be: You need to sleep for 3.5 metric hours. reply tomtomtom777 4 hours agorootparentExactly. The exact amount of sleep needed on average is almost certainly an irrational number. (Because almost every number is irrational) reply reliablereason 1 hour agorootparentIt’s almost certainly a rational number as activity in the body is finite. There will be an exact point at which a certain molecule has interacted with another molecule marking the exact point of perfect sleep. Averaging many rational numbers can’t get you an irrational number.Also it is invalid to compare infinite series like you do in your paracentesis argument, there are infinitely many irrational numbers and infinitely many rational ones. If you do it, you run in to contradictions. (Something which is related to Cantor&#x27;s paradox) reply yakubin 25 minutes agorootparentThe statement OP put in parentheses is a well-defined statement in mathematics. It means that the Lebesgue measure of the set of the rational numbers is zero in the space of real numbers. reply Karellen 4 hours agorootparentprevAre you sure? Isn&#x27;t the average calculated by dividing by n, an integer?Edit: I mean, you&#x27;re right that nearly every number is irrational. But I think averages are going to be some of the tiny fraction of numbers that aren&#x27;t. reply red_trumpet 4 hours agorootparentOnly if you take an average of rational numbers. Like e&#x2F;2 is still irrational. reply ReleaseCandidat 3 hours agorootparentWhile in theory you could measure sleeping time in fractions of 2 pi, I&#x27;d guess that you&#x27;re using rational numbers in the actual calculation anyways. reply red_trumpet 2 hours agorootparentWhy would sleeping time be a fraction of 2pi?> I&#x27;d guess that you&#x27;re using rational numbers in the actual calculation anyways.Well, actually one uses floating point arithmetic, which isn&#x27;t rational numbers either (as shown by the classic example a = 1&#x2F;3, b = 3*a, then b != a) reply nyrikki 13 minutes agorootparentBase 12 being 3-smooth, any number with 2 or 3 as a factor has a reciprocal with a terminating expansion.base 60 is 5-smooth, so any number with 2,3,5 as a factor has a terminating expansion.Just as SI has to add in deg min sec for fields like astronomy.As the practical numbers are quite dense up to 60, they could divide by multiplication of the reciprocal for many more numbers.Floating point is more complicated than just the base as the radix also matters. C(++) finally got decimal radix support this year in the standards and IBM has had decimal floats for a long time.FFT and encryption often use mixed radix despite being a binary base too.It is a far more complicated subject than it appears on the surface.But there are problems that aren&#x27;t easily solvable in base 10. The degrees of a circle are an example and why navigation uses the nautical mile, where 1 nautical mile= 1 minute of latitude is an example.12,60,360 are Superior highly composite numbers and 12 is the smallest 3-smooth and 60 is the smallest 5-smooth.This also means that with using 360 degrees one can divide a circle or semicircle in 12 sections with just a square, 345 triangle and equalatrral triangle. Where decimal or even radians requires the square root of 2, pi, etc...I am a fan of universal units of measurement, but had they been base 12 it would have been better IMHO. SI could be more broadly adopted if it has been base 12. reply saalweachter 1 hour agorootparentprevI mean, we could be measuring time in radians. We already subdivide degrees into minutes and seconds, might as well call the day 2 pi radians.We sleep for 2&#x2F;3 pi radians of the day in that case. reply 867-5309 2 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Turn_(angle) reply ReleaseCandidat 2 hours agorootparentprev> Why would sleeping time be a fraction of 2pi?The rotation of a hand of the clock, expressed as the arc length of the curve of its endpoint :)A sleeping time of 0 is always a problem, though. reply littlestymaar 3 hours agorootparentprev> Edit: I mean, you&#x27;re right that nearly every number is irrational.The set of rational number is a “null set”: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Null_set reply willis936 3 hours agorootparentprevI don&#x27;t really care how much sleep I get as long as it&#x27;s enough. I care greatly when the bus leaves and when my meetings are. Anything that hopes to replace a clock had better be adding precision rather than removing it. reply kybernetikos 3 hours agorootparentDecimal seconds are slightly shorter than normal seconds, so times that use seconds are more precise. The other fun thing is that decimal time doesn&#x27;t really need names for the levels, it&#x27;s just numbers of significant figures so if you only want to give the first digit of the seconds that works too. reply willis936 2 hours agorootparentIt&#x27;s less precision for a given number of symbols. Fewer usable factors mean you can only reasonably divide up segments of time into larger, less precise chunks. reply eps 5 hours agoparentprevCome to think of it, being able to cleanly divide a minute or an hour into 2, 3, 4, 5 and 6 equal parts is pretty damn handy. reply nycdotnet 2 hours agorootparentThis is the same reason a point is 1&#x2F;72 on an inch - many factors make convenient typesetting. reply prometheus76 2 hours agorootparentprevNow apply the same logic to measurement, and you&#x27;ll see why it&#x27;s so handy to use a dozenal foot for fabricating things. reply rplnt 49 minutes agorootparentIs 1&#x2F;3 (1&#x2F;6) such an important concept? 1&#x2F;2 (1&#x2F;4) is natural in metric.I would think a bigger benefit is that you can drop up and down without any math depending on the precision you need. Or use decimals, no math involved either, since it&#x27;s the same thing. reply bmacho 3 hours agorootparentprevYes. That&#x27;s why I love metric clock, the number &#x27;5&#x27; screams 1&#x2F;2 to me, and &#x27;3.33&#x27; screams 1&#x2F;3 much more than 6 and 4 do. reply Jleagle 4 hours agorootparentprevDon&#x27;t forget 10, 12, 15, 20, 30 reply gorlilla 3 hours agorootparentIt&#x27;s almost like circles are the perfect shape for sliced pies afterall. reply pmontra 5 hours agoparentprevI didn&#x27;t check the details of that metric time system but there would be no problem living a 10 hours day with 100 minutes hours and 100 seconds minutes. The second would be defined with a different number of \"cycles of the radiation produced by the transition between two levels of the cesium-133 atom\" and that&#x27;s all. Instead of rounding our lives at \"our\" quarters of hours or ten minutes, five minutes marks we would round to the metric quarters of hours, maybe eights of hours (we could have found a name for that, like for coins) etc, and nobody would notice because that would be what we are born with.Similarly, people buy 50 cm x 70 cm frames in metric countries and 20\" x 30\" frames in the USA. Nobody thinks about that except frame factories in China, that have to cut them in two sizes. reply toxik 3 hours agorootparentNobody questions the logical consistency of the system, I think.Presently, we use 24-hour time (AM&#x2F;PM or otherwise), so the loss in precision is enormous going from 24 to 10.Think about it.A tenth of a standard hour is 6 standard minutes.A tenth of a metric hour is 144 standard minutes, more than two standard hours.A hundredth of a standard hour is 36 standard seconds, or half a minute. It is in the context of hours a negligible amount of time.A hundredth of a metric hour is 14.4 standard minutes! Imagine being 0.01 metric hours late for a meeting.So everywhere you now have to specify time to two decimal places &#x2F;at least&#x2F;, three to have sub-standard-minute precision.Layer on top of this the fact that the new system has significantly fewer distinct prime factors, so you quickly run into continuing fractions. Disaster. reply ivanbakel 3 hours agorootparentWhat? A metric hour is 144 standard minutes - or do you imagine that a day of metric hours is 1441010 = 144,000 standard minutes long?A tenth of a metric hour is 14.4 standard minutes. A hundredth of a standard hour is 1.44 minutes. Being 0.01 metric hours late, or 1 metric minute late, is not too much more than being 1 standard limit late.And current time is specified to 6 digits for second precision - hours, minutes, and seconds. reply taeric 1 hour agorootparentprevDon&#x27;t we have the same basic criticism going from Fahrenheit to Celsius? You go from a 10 degree swing being big to ridiculously huge.That is, arbitrary number is arbitrary, at large. Most of the \"benefits\" of any system won&#x27;t actually be realized by most people that are using it. Consistency, on the other hand, is hugely important. reply eadmund 1 hour agorootparent> Don&#x27;t we have the same basic criticism going from Fahrenheit to Celsius?Sure, and one shouldn’t do that either. Fahrenheit’s range (0 being the freezing point of brine, almost but not quite intolerable to a human, and 100 being roughly body temperate and also almost but not quite intolerable to a human) is far more human than Celsius’s freezing-to-boiling range. reply worthless-trash 6 minutes agorootparentHaving never used Fahrenheit in any capacity, the math for it feels inhuman.Having grown up in metric, the values dont feel &#x27;inhuman&#x27; just a scale that i&#x27;m familiar with. I know that my body is usually at 37, I know that water boils at 100, i know that I don&#x27;t like anything below 8c or above 40c. reply ilyt 1 hour agorootparentprev>Presently, we use 24-hour time (AM&#x2F;PM or otherwise), so the loss in precision is enormous going from 24 to 10.>Think about it.No, YOU think about it. When do you use hour-only precision today ?When you say \"I have meeting at 8\" that never means \"any time period between 8 and 9\", that means \"it starts at eight\". That doesn&#x27;t change with change of the length of the hour.You&#x27;d still use hours on their own only if you mean \"an hour and close to zero minutes around that hour\". You&#x27;d still add minutes for anything else.> A hundredth of a metric hour is 14.4 standard minutes! Imagine being 0.01 metric hours late for a meeting....no ? it&#x27;s 100 seconds so ~1.66 of standard minuteImagine being 1.66 minutes late instead of one!!! Such horror! reply mirekrusin 5 hours agoparentprevWe need tau-rational-time! We sleep for τ&#x2F;3, noon is at π. reply bmacho 3 hours agorootparentAn hour is just an another name for a deciturn, or a deciday.Tau is not a good unit for angles in general, unless you have circles, or you need lengths of circumferences somewhere. (You want to paint your clock and calculate the amount of paint, or something.) Turn is the natural angle unit. And since the earth rotates 1 turn&#x2F;day, the amount of turns is the same as the amount of days. reply tomjakubowski 1 hour agorootparentprevYou can start the movement by announcing \"it&#x27;s pie o&#x27;clock\" at lunch time every day reply femto 4 hours agorootparentprevSpreadsheets already use \"τ time\", in that a day is a single unit, which could easily be defined to be \"τ\". reply Entalpi 5 hours agoparentprevIts like we have built our entire lives around another time system! &#x2F;sYou get similar problems converting between Freedom degrees and Celsius. Its just what people have built an understanding of. reply toxik 4 hours agorootparentI disagree, it’s not equal but different. The French famously tried to switch to a decimal system for angles before, but failed in no small part because of the relatively few unique prime factors. Being able to divide evenly by three turns out to be more important than five. reply pipo234 5 hours agorootparentprevTo quote yet another time format: NTP 64-bit timestamp format (rfc8877), which is 32 bits seconds since epoch + 32 bits fixed point second fractions. (Outside of Network Time Protocol, you&#x27;ll find this baby for instance in ISOBMFF ProducerReferenceTimeBox(prft)).Here seconds are just 1&#x2F;(24*60*60) of a day as expected, but the base 2 fixed point part, where a tick \"is roughly equal to 233 picoseconds\" makes you want to pull your hairs out if you just want to accurately express milliseconds. (Similarly for other timescales frequently used in media processing, like 90kHz, 25, 60 or 29.97)The answer to all this is of course: hand waving — \"you don&#x27;t need that\". Your time can be perfectly accurate in itself (ie. an accurate discrete sample of continuous time), even if no accurate conversion exists to some other time system. reply pif 4 hours agorootparentprevYou meant \"Fahrenheit\" rather than \"Freedom\", didn&#x27;t you? reply gorlilla 3 hours agorootparentI think they said what _they_ meant _and_ still meant what _you_ said. reply pif 1 hour agorootparentIs this a common joke? reply acka 1 hour agorootparenthttps:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;freedom_units replyevrydayhustling 2 hours agoparentprevMetric time is about factors too, but it prioritizes the factors that simplify the comparison across (literally) many orders of magnitude. This is way less helpful for everyday life because we usually only reason within 2-3 orders of magnitude, but we deal with tons of harmonic subcycles that the 24h clock makes easy.For a fun, a more justified usage of metric time, check out Vernor Vinge&#x27;s \"A Deepness in the Sky\" (also IMO one of the best sci-fi novels of all time). A spacefaring humanity that stretches their life across journeys and projects that span centuries, and which has to artificially produce their own daily cycles, gets a lot more value out of metric time. reply Denvercoder9 5 hours agoparentprev> You&#x27;d think we can just interchange the . and : so you should wake up 12:83…, or 2:83… the next day.> But no, it&#x27;s apparently 2:75 metric time. Why?You can, they just messed up the example by unnecessarily rounding off the times. The night from 9:50 till 2:75 metric time only lasts 3.25 metric hours, or 7h48m in standard time; less than the 8 standard hours they started with. reply jader201 3 hours agoparentprevIt’s too bad it doesn’t take exactly 360 days for the earth to orbit the Sun.We should do something about that. reply FabHK 1 hour agorootparentYes. A good creator would’ve made the year 360 days long and given us 12 fingers. Now we should fix it with some astroengineering and bioengineering. reply xnx 9 hours agoprevThis site says \"Metric Time\", but I think they mean \"Decimal Time\" (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Decimal_time). There is a https:&#x2F;&#x2F;www.decimal-time.com&#x2F; site that has working Decimal Time clocks.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Metric_time reply 0wis 9 hours agoparentYes, a very confusing error. The metric time is the SI time (24h 60m 60s). The decimal time is base 10. French tried to get it used during the revolution and it did not work. Its the only unit that resisted decimalization, with a couple others ones in a handful of countries still using something called « imperial units ».Another similar thought experiment is binary clocks which I remember using to get use to read in base 2. [1]Weekly clocks are also a good way to change perspective on time. [2]Both are fun to use, especially with other people if you manage to get them to experiment with you. Both have the avantage of avoiding any confusion with SI time.[1]: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Binary_clock [2]: https:&#x2F;&#x2F;dayclocks.com&#x2F;products&#x2F;classic-oak reply shiroiuma 5 hours agorootparent>with a couple others ones in a handful of countries still using something called « imperial units ».The only country I know of offhand that uses \"imperial units\" is the UK.There&#x27;s a different, but similar (and sometimes overlapping) system called \"US Customary Units\" that&#x27;s used in the US. Imperial pints and gallons are NOT the same as US pints and gallons. reply 0wis 2 hours agorootparentThanks ! Sorry I overlooked this. Did a little research and I think the most confusing in this is the ton. At least, pints, gallons and miles have a different name than the metric unit and are way different than their SI equivalent. Not close by around 10%, one more (the long ton) and one less (the short ton). A perfect way to get the wrong quantity of a thing without noticing it at first. And if that’s not confusing enough, using « long » and « short » for a mass unit..https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tonne reply scroot 3 hours agorootparentprevthe UK pint is bigger than the US pint. Know this before visiting and it could just save you a hangover. reply BoxOfRain 2 hours agorootparentThe now relatively uncommon UK gallon is the volume occupied by ten lbs of water in the same way a litre of water weighs a kilogram. Not only are the pints bigger there’s also twenty ounces (also rarely used now) in them which means a fluid ounce of water weighs by definition an ounce in the imperial system. reply have_faith 3 hours agorootparentprevWe use a mix of everything in the UK, although metric is common in many areas where it matters. reply jader201 9 hours agoparentprevMy guess is the author thought this was an original idea, and just named it “metric” since that usually means some form of base-10 measurement. reply funcDropShadow 5 hours agorootparentNo \"metric\" units means they are derived from the meter. Originally, most units in the SI systems were derived from the meter. reply saalweachter 53 minutes agorootparentA second is the period of a pendulum with a length of one meter. :-)(But not really; that was originally considered as a way to standardize the meter, IIRC, but the period of a pendulum varies too much even over the area of France to be used as a concrete standard. But the relationship is remarkably close for a coincidence, like the way a rod is almost exactly five meters.) reply useerup 2 hours agorootparentprevA cube of water 1cm * 1cm * 1cm = 1cm^3 has a mass of 1 gram. A cube of water 1m * 1m * 1m is 1000 liters and has a mass of 1000 kgThe SI units are supposed to be related like that. reply jader201 3 hours agorootparentprevTechnically, yes. But measurements of weight, volume, and temperature are also part of the metric system, and those didn’t derive from the meter.Seconds are also part of the metric system, but one of the few not based on decimal&#x2F;base-10.Again, I’m just speculating that the author used “metric” because it often represents decimal&#x2F;base-10 measurements. Not really arguing whether they were technically correct in doing so. reply dghughes 3 hours agorootparentprevAnd based on a 1,000 (kilo) of something so 1 metre 1,000g (kilometre), 1 gram 1,000g (kilogram). You can have centimetres but that not in the spirit of the metric system really.Maybe we need a cron for an hour or a day? 1,000 crons for an hour sounds better than millicrons by breaking up a day if it was 1 cron. reply vidarh 2 hours agorootparent> You can have centimetres but that not in the spirit of the metric system really.\"Centi\" is an SI prefix just as much as \"kilo\" is, and has been part of the metric system since 1795 just like \"kilo\". I don&#x27;t see how it&#x27;s \"not in the spirit\" of the metric system. It also fits in neatly in that 1cm^3 of water is roughly 1 gram (the original provisional definition of gram was 1cm^3 of water at the melting point of ice; the current definition is more precise), and so 10cm^3 of water is roughly 1 liter.The SI system has prefixes going up and down one power of 10 up to 10^3 and down to 10^-3, and then in steps of 10^3. They&#x27;re all equally part of the system; some are just more common in some contexts that others (e.g. we use hectograms but rarely hectolitres, and decilitres but rarely decimetres, and centimetres and centilitres but rarely centigrams) depending on what happens to be convenient.E.g. kilo(10^3), hecto(10^2), deca(10^1), deci(10^-1), centi(10^-2), milli(10^3), but then mega (10^6) and micro(10^-6) are the next steps. replybloopernova 2 hours agoprevAnother excuse to share the wonderful Unix epoch clock: https:&#x2F;&#x2F;retr0.id&#x2F;stuff&#x2F;2038&#x2F;Watch face has 4 hands, one for each pair of characters in the hex representation of the current unix time.Being hex, it kinda makes it easier to understand for me in that the \"minute\" is 255 seconds. The next chunk of time is 65,025 seconds or about 18 hours. Then comes 16,581,375 seconds, which is almost 192 days. reply grishka 33 minutes agoprevWhat I don&#x27;t like about this is the redefinition of the second. The length of a second and its subdivisions is so fundamental to so much of everything in our society. Other physical quantities like speed or frequency or power all depend on it. You would have to redefine everything. Kilometers per \"metric hour\", \"metric hertz\", \"metric watts-hours\", you get the idea.> There is no AM or PM with metric time.It isn&#x27;t there in standard time either. It seems to be another uniquely American thing. The only time I&#x27;m exposed to AM&#x2F;PM is when reading an analog clock. Or when talking to an American.Heck, even in US, there&#x27;s \"military time\" that is 24-hour. reply Synaesthesia 27 minutes agoprevMetric seconds are quite close to regular seconds since there are 100,000 metric seconds in a full day compared to 86400 regular seconds.Which means that 40 metric seconds is about 46.3 regular seconds - I.E. something is wrong with the charts on this website.It also means a metric minute which is 100 seconds would be 115.7 regular seconds so a bit less than two minutes, not 2.4 minutes as claimed. reply vaughan 5 hours agoprev.beat time or Swatch Internet Time is way better.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Swatch_Internet_Time reply jhbadger 3 hours agoparentIn a way, China kind of has something like the Swatch gimmick for real. There&#x27;s just one time zone in the whole country (which is roughly the size of the Continental US). This has benefits (easy to coordinate video conferences in different cities) and drawbacks (the official time is far off from what the sun would indicate in much of China). reply blululu 3 hours agorootparentIt only works because the overwhelming majority of the population and all of the political and economic power lies on the east coast of China in a single time zone. I doubt that the people in Urumqi are happy to have the sun rise at 10 am, and I doubt that anyone cares about their opinions. reply lesuorac 1 hour agorootparentGiven that the sun rose at 10 am approximately 0 times this year [1] I guess the people in Urumql were ecstatic. Also note that the sunrise time varied by about 3h over the course of the year so how many times do you want to change the clocks?Of course to your actual point and everybody else that brings that same one up. You do not need to wake up at 8am every day ... If the sun actually rises at 1400 then feel free to start your day at 1500. I&#x27;m not sure what why people keep arguing as-if they can&#x27;t figure out a time besides 8am to wake up; look at the world around you, so many people wake up at wildly different times in a timezone.[1]: https:&#x2F;&#x2F;www.timeanddate.com&#x2F;sun&#x2F;china&#x2F;urumqi reply fjfaase 53 minutes agorootparentprevI stayed in Urumqi four times (in 1993, 1996, 2006 and 2010), each time for some weeks. It is really confusing that the (traditional) working hours are from 10AM to 2PM and 4PM to 8PM. I found myself everytime looking at the clock substracting two hours. Similar as to when we changed currencies in the Netherlands when the Euro was introduced. I guess it would have taken about half a year stop doing the reverse time calculations. reply robobro 4 hours agoparentprevMaking it oriented on UTC+0100 is dumb reply aeyes 2 hours agorootparentThey used CET as a reference, the local timezone of the Swatch headquarters. reply robobro 1 hour agorootparentI get that it&#x27;s all arbitrary, but if we&#x27;re going to go for a global time system, just makes sense to me to try and align with already-existing universal standards. Both UTC +0000 and UTC +0100 are pretty alien to me as someone in UTC +0800 so it&#x27;s not like I have any bias toward Switzerland or the UK either way... reply eps 4 hours agoparentprevNo, it&#x27;s not.Dividing one day into just 1000 units is way less precise unless one uses decimals, in which case it&#x27;s just plain inconvenient. reply xyzzy123 4 hours agorootparentI think the idea is that for most human uses of time we don&#x27;t specify start or end times to a precision of more than about 5 minutes. Stuff like train timetables you might want to go down to about a minute. So one could argue that we have at least 60 times the resolution we really need for day-to-day use.If you absolutely need more precision (accurate timestamping) then decimals are available. reply y04nn 2 hours agorootparentprev\"way less precise\" ? There are only 1440 minutes in a day, so a beat is 1 minute and 26.4 seconds, precise enough. And then, if you you want more precision, like we use seconds for minutes, you can divide a beat by 100 (@500.12), not less inconvenient than using seconds. reply sdeframond 2 hours agoprevWhile metric time has some appeal, I think it is not ambitious enough.Base 10 is not good. 10 just does not have enough factors, so we are left to deal with complex fractions. Let&#x27;s instead use base-12 numerals and keep time unchanged!In base 12, 1 year is 10 months (or 265 days), 1 day is 20 hours, 1 hour is 50 minutes and a minute is 50 seconds.Easy enough!Edit: wait! I just realized this is still not ambitious enough!!!What we need is to halve seconds in two. So, in base 12: 1 day = 10 hours, 1 hour = 100 minutes, 1 minute = 100 new seconds. reply sdeframond 1 hour agoparentSo, how would we call those numbers after 10 ?\"Ten\", \"eleven\" and \"twelve\" can stay the same. \"Thirteen\" to \"nineteen\" are more problematic since \"*teen\" refers to \"ten\". We would like something meaning twelve-one, twelve-two and so on. Then \"two-twelve\" intead of \"twenty\" ? Feels heavy. Maybe stick to \"twenty\" then ?Oh, and what about retro-compatibility ?Edit: or we could go back to Imperial units. WowEdit2: the wikipedia page about dozenal systems is pretty interesting https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Duodecimal reply saalweachter 36 minutes agorootparentIf you&#x27;re going to coexist with decimal, you&#x27;re best off starting over with a distinct set of words.For instance, scales have 12 notes, with seven common words for the notes (do, re, me, fa, so, la, ti). Add five more similar but distinct phonemes (go, ki, za, we, je) to insert at the position of the half notes skipped, shift la to position 1 since l looks conveniently like 1, and add nul for zero: nul, la, go, ti, do, ki, re, za, mi, fa, we, so, je.Add in some rules for forming larger numbers (laj, goj, tij..., soj, jel, jel-la, jel-go..., jes-so, la-gross, la-gross-la, ...) and begin learning your addition tables over again (la plus la is go; go plus go is do; do plus do is mi; mi plus mi is doj). reply stereoabuse 10 hours agoprevUsually known as decimal time[0].[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Decimal_time reply mongol 6 hours agoparentDefinitely a better name reply bmacho 3 hours agorootparentMetric time is a better name, since it states that this time comes naturally from our common metric system, and something is very very off that we don&#x27;t use it. reply mongol 2 hours agorootparentYes but it doesn&#x27;t since it does not use the same second. So it is misleading reply bmacho 2 hours agorootparentI don&#x27;t think it is misleading. Although there is a name-collision with the SI time system that some people call metric time [0] already. I don&#x27;t know how many people, or how official it is. I&#x27;ll probably keep calling decimal time metric time, and we&#x27;ll see if there is a real collision&#x2F;confusion&#x2F;misleading.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Metric_time replyfjfaase 34 minutes agoprevI once (around 1983) met someone who had an astrological (astronomical) watch, that showed &#x27;time&#x27; depending on the position of the earth with respect to the zodiac. He believed that periods when a sign would appear on the horizon (and another disappear) were periods that you beter could not start another activity. I am not sure if it was one made by Jaap Venker. Jaap Venker made 1500 of these watchs which now sell for hunderds of Euro&#x2F;USD.I think having a clock that depends on the position of the earth with respect to the center of our galaxy is an interesting idea. reply edent 9 hours agoprevPersonally, I prefer 100 metric hours in a day. Each centiday is about 15 minutes.Each milliday is about 90 seconds.And a microday is slightly shorter than a second.But, sadly, this revolution won&#x27;t occur until after I&#x27;m elected God-Emperor of Mars, so it is all rather academic. reply Karellen 4 hours agoparent> this revolution won&#x27;t occur until after I&#x27;m elected God-Emperor of Mars,And you&#x27;ll have to make all your intervals slightly longer, due to Mars&#x27; solar day being 24h39m35s by standard Earth time. reply roelschroeven 3 hours agoparentprevSo a microday is 1&#x2F;100 of a milliday? That clashes with the SI prefixes, where micro is 1&#x2F;1000 of milli.When following SI, a microday would be 0.0864 (or approximately 0.1 second) which doesn&#x27;t seem to be a very practical unit. reply vanviegen 8 hours agoparentprevCentidays seem like a very convenient unit to plan your day with. Meetings are already at the 15min boundaries.You have my vote! reply phist_mcgee 3 hours agoparentprevThe Adeptus Mechanicus might have something to say about that... reply abeppu 9 hours agoprevDoes this short page describing a base-10 way of dividing time actually fail to be internally consistent for the few sentences of text describing it?> A standard hour is broken into 60 minutes. There are 2.4 standard hours in 1 metric hour.> A metric minute is broken into 100 seconds.> A standard minute has 60 seconds. There are 2.4 standard minutes in 1 metric minute.No, a standard minute is 1&#x2F;1440 of a day, and a metric minute is 1&#x2F;1000 of a day. There are 1.44 standard minutes in a metric minute. reply INTPenis 9 hours agoparentI still don&#x27;t understand how a metric day matches up with a standard day.I flunked 10th grade math and later dropped out, my brain is having a stroke just reading those graphs.I reverted back to seconds, which is how I used to use Unix timestamps when I first started with computers. But one day would have 100000 seconds, compared to 86400 seconds in standard time, so how can they both measure a day? reply pmontra 5 hours agorootparentA day is a day, Earth rotation defines it. What we can do is decide how long a second is and tweak it to make a day 100k seconds long or 86.4k ones. reply defrost 5 hours agorootparentIf only the length of a day was constant.It&#x27;s not, hence leap second corrections to our current earth based imprecise observed solar time based on mean solar days (which are not apparent solar days).Of course even if it were regular there&#x27;s that pesky difference in rotation relative to what now??Sidereal rotation time isn&#x27;t equal to solar rotation time (mean or apparent).Time .. less straightforward than most imagine. reply Elora 1 hour agorootparent> Time .. less straightforward than most imagine.I think it&#x27;s more trying to make things which vary fit in a \"you shall not vary\" square box that is the problem. Technically, this metric&#x2F;decimal method makes more sense for what we&#x27;re trying to do, but it&#x27;s less of a \"time\" thing than it is a \"let&#x27;s have the same numbers every day so we can agree on when synchronous events need to happen.\" To _measure_ elapsed time, using a fixed unit such as a second is perfectly fine. reply simonh 7 hours agorootparentprevSeconds, minutes and hours in this system are not the same length as the standard versions. reply mongol 6 hours agorootparentStrange the page does not describe the \"metric second\" then, since it is not the same as the SI second. I thought that the second was the unit which was the same as in SI (=metric). But then it is not the same as the SI second, so not metric at all. Very confusing. reply INTPenis 7 hours agorootparentprevThat must be it. I kept watching the two clocks to try and figure out if the second was equal but couldn&#x27;t. This is the key and should be the first thing you read, seconds not being the same length is a huge detail. reply roelschroeven 3 hours agorootparentprevI feel it&#x27;s an error to use the same names in the two systems. The values are different, it would be much less confusing to use names that are clearly different too. reply bfdm 9 hours agoparentprevYea that tripped me up reading too. Something felt like it didn&#x27;t add up. reply SulphurCrested 10 hours agoprevYou could call this lots of things, but you shouldn’t call it “metric” because its second is not a metric second. In the SI (metric) system, the second is one of the fundamental units. The world does not need a conflicting definition for the second.As someone who’s implemented a date and time library, the real pain is in dates, leap seconds and time zone transitions. 86,400 seconds in a day is a relative piece of cake.The AM&#x2F;PM thing is a solved problem. Many countries (not the one I live in) already use a 24 hour clock, in which 11pm is 23:00. Because many countries use it, most devices that keep time can be set to 12 or 24 hour clock. That includes almost every clock I own, including the oven in the kitchen, my car, all the HVAC units, and of course phones and computers. An exception is the irrigation system – the old one (designed in the USA) supports 24 hour time, but its replacement (designed in Australia) does not. I don’t think anyone, seeing all my clocks, has ever commented on them being in 24 hour mode. Most people have seen it before. reply larusso 9 hours agoparentYou are right of course but also keep in mind that, and that is just my thoughts after reading, is that the French tried to implement decimal time along with the rest of what we call the metric system in the 18th century. And it was the only system people rejected. So I think the author named everything metric to make the point that if it would be part of the system a metric second would be … long. But again I could be wrong. In any case the page would also work by naming everything decimal-something. Maybe not as catchy. reply NegativeLatency 9 hours agorootparentThe gradian is similarly obscure, turns out 360 and 60 are nice round numbers with many handy common divisors reply uranusjr 9 hours agorootparentprevI don’t know the exact history, but the rest of the metric system is designed with a base unit and decimal derivatives. Assuming we want to keep the day length consistent (I can’t imagine a system being practically useful otherwise), we’d have decidays, centidays, etc. and not have hours, minutes, and seconds in the system at all. A system with days, decidays (2.4 hours), millidays (1.44 minutes), and microdays (0.0864 seconds) doesn’t seem bad to me at all, I’m sure people would come up with a good name for 10 microdays for daily use (0.864 seconds). reply pmontra 5 hours agorootparentkDay, MDay, etc could work in space but they don&#x27;t fit well with the length of the year. As long as we live on Earth we cannot escape from our planet taking about 365 days to orbit the Sun. History proved that it&#x27;s convenient to have the same event (let&#x27;s say start of spring) falling at the same date every year. Hence all the refactoring of calendars and leap years.I wonder how we would settle that matter if we&#x27;ll ever be able to travel fast between planets. Each city had its own time zone before trains required us to sync them because of conflicting railroad timetables. So we ended up with the current timezones. With planets, each one would have its day length and number of days in the year, maybe even inconstant seasons in the case of precession of perihelion or double star systems. I&#x27;d say we&#x27;d settle on local time and a common space time but who knows. reply larusso 9 hours agorootparentprevI never thought about this. And actually never bothered to read up on the proposed terminology. Only thing I always assumed was that the first draft of all terms is not 100% what we use today. Especially because it comes from France. But that’s only assumptions. But yes I think you are right with the naming convention. reply ithkuil 6 hours agorootparentprev10 microdays -> a decamicroday -> a demiday -> a dem reply mjan22640 8 hours agorootparentprevEvery area had a mile that was a different lenght from the others. Time was the same everywhere already. reply pmontra 4 hours agorootparentTime was the same for the people that were measuring it with the same tools.Western sundials started with 12 hours as they worked only during the day [1] and people that were not measuring time eventually measured it with a 24 hours system.I could not find many sources about Chinese sundials but from the pictures at [2] you can see that they had 12 hours in all the day. A hour on the second sundial is divided in 8 parts. The one in the first picture seems to have the same 8 characters as the other one but each hour is divided into 2 parts, each divided in 4 parts.I&#x27;m not surprised that everybody settled around some small and convenient number. 12 has more factors than 10 and dividing by 2 is more convenient than dividing by 3. I would be surprised to find a 9 or a 15.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_sundials[2] https:&#x2F;&#x2F;sonofchina.com&#x2F;what-is-a-sundial-and-how-does-it-wor... reply downvotetruth 9 hours agoparentprevFTFY: English does not need a second conflicting definition for the second. reply ithkuil 6 hours agorootparentthere is no multiple definitions going on: what happened is an _elision_.The actual word is \"second minute\" (as opposed to the \"first minute\").Most languages have by now elided \"first\" from \"first minute\" resulting in the \"minute\" as we know it today, and elided \"minute\" from \"second minute\" resulting in the \"second\" as we know it today.i.e. \"second\" literally means \"the one that comes after the first\", but is implied to be about the subdivision of the small unit of time. reply xanathar 9 hours agorootparentprevI second that statement. reply oh_sigh 9 hours agorootparentI&#x27;ll be the second second. reply mistercheph 9 hours agorootparentprevThere is no conflicting definition. Minutes, seconds, thirds, and fourths etc. are sexagesimal subdivisions, as tenths, hundreds, thousandths, ten thiusandths etc. are for decimal. reply simonh 7 hours agorootparentI know what you mean, and you are correct in that this is why we have minutes and seconds of arc, but the linked page is literally suggesting a different definition. reply mistercheph 1 hour agorootparentI was referring to GP&#x27;s suggestion that a conflict already exists. reply NullPrefix 9 hours agoparentprevIs celsius metric? reply perilunar 8 hours agorootparentIt&#x27;s part of SI.Kelvin is the base unit of temperature; Celsius is a derived unit. reply dmitshur 50 minutes agoprevNeat.I think it was sometime between 10 and 20 years ago, I was curious to see what a clock that shows fractional time in years would look like: https:&#x2F;&#x2F;dmitri.shuralyov.com&#x2F;projects&#x2F;shuryear-clock&#x2F;. I found looking at it occasionally reminds how even a year worth of time can pass fairly quickly. reply pavlov 5 hours agoprevThis is exactly the decimal time system used in France during the brief period of the post-revolutionary established First Republic, 1794 to 1800.Although the metric system originated at the same time, it&#x27;s important to note that the French Republican decimal second isn&#x27;t the same as the one used by international metric system (SI) that we ended up with. So calling this \"metric time\" is quite misleading.The decimal second is shorter than the standard one because there are 100,000 decimal seconds in a day vs. 86,400 SI seconds in a day.(If you&#x27;re a rich antiques collector, a late 18th century French decimal clock might be a very interesting object. My understanding is that they are rare because their active use was so short and most clocks were repurposed to standard ones.) reply bugeats 1 hour agoprevI see your Metric Time and I raise you a Dozenal Society of America.12 is divisible into whole halves, thirds, and quarters.https:&#x2F;&#x2F;dozenal.org reply jonwinstanley 3 hours agoprevThis is cool. However, for me, it&#x27;s the months that are the weirdest issue. Why do we all get paid the same each month, pay the same rent&#x2F;mortgage but some months have 4 weekends, some have 5.We should have 13 months, all 28 days long, exactly 4 weeks. Whenever there&#x27;s a leap year we get an extra day for free.:-) reply Humphrey 2 hours agoparent> Why do we all get paid the same each month, pay the same rent&#x2F;mortgage but some months have 4 weekends, some have 5.Is paying monthly an American thing? In Australia most things seem to revolve around n weeks.- I get paid on Thu every second week (2 weeks)- My pre-paid phone auto-recharged is every 28 days (4 weeks).- House rentals are listed as weekly rates, paid at whatever n weeks you negotiate.- Mortgages are monthly by default, but most let you opt for n weeks, so most people pick the day after they are paid. Interest is still added monthly though.The only things I can think of that I&#x27;m charged monthly for are online subscriptions, which I suspect got influenced by America.> We should have 13 months, all 28 days long, exactly 4 weeks. Whenever there&#x27;s a leap year we get an extra day for free.Same length months would be cool... but as above, months don&#x27;t mean practical month to me except for having to remember which one we are in. reply MrGilbert 1 hour agorootparentIn defense of americans, that is exactly how most of the salary in europe works. But then, rent is also payed monthly.So… getting payed weekly is something australian, I guess? reply pelario 3 hours agoparentprevExcept 13×28 = 364, so you get the \"free day\" every year, and two of them on leap ones reply gumby 2 hours agoprevBase 10 is a step backwards. 12 & 60 give you lots of useful rational fractions.Leave metric time (c = 1m) to Minkowski space. reply tgv 9 hours agoprevApart from history and (dis)advantages, nobody seems to address the site&#x27;s rationale for this (rather impactful) idea:> would make all the mental math we have to do when adding and subtracting time so much easier—especially when it comes to different timezonesFirst off: the time zones argument is BS. And the people I know have no problem subtracting or adding (quarter, half or whole) hours to a given time. It&#x27;s a skill we picked up at primary school, so it really can&#x27;t be that hard. The people who can&#x27;t do that, probably also will have problems with decimal time. The only thing that takes more mental effort is something like \"193.8 minutes after 17:03\", but how often that does happen?The argumentations following the rationale are also BS: there&#x27;s no AM&#x2F;PM in a 24 hour clock (as mentioned in other comments), and there&#x27;s no advantage to 3.33 vs 8 hours of sleep.IMO there are no advantages, and the page doesn&#x27;t discuss overcoming the disadvantages and how to overcome them, so frankly is irrational. There&#x27;s no reason to discuss this. reply twelvechairs 10 hours agoprev> Working with base-10 numbers is so much easier than trying to think in base-60, base-12, and base-24.> To get a good night sleep (8 standard hours) you&#x27;d sleep for 3.33 metric hours.Quote 2 seems to clearly contradict quote 1. 60 is great as it divides into 2,3,4 and 5. That&#x27;s a feature not a bug reply simonh 9 hours agoparentAnd 12 divides into 2, 3, 4 and 6. Base 12 is far superior to base 10. Those Babylonians weren’t stupid. reply groestl 9 hours agorootparentAlso, while we have 10 fingers, we have 12 finger segments to count with (disregarding the thumb): https:&#x2F;&#x2F;www.earthdate.org&#x2F;episodes&#x2F;how-10-fingers-became-12-... reply jacknews 8 hours agorootparentbase 6 works even more simply with two hands, 0-5 on each. And less symbols to learn, much smaller multiplication table, and so on. reply dclowd9901 9 hours agorootparentprevI was going to say: time is based on degrees of a circle, and 10 doesn’t work great for it. I’m not a fan of non-metric length measurement, but time seems to be a rather sensical usage of it. reply arlort 3 hours agorootparentThe important aspect of the metric system is consistency, not the actual base. The base is 10 because it makes math easier in almost all modern languagesTime is weird because its units are so necessarily arbitrary. We don&#x27;t control (yet at least) the relationship between the rotation and revolution times of the planet, and both of those values are so very much essentialIt&#x27;s also interesting that you almost never will need to convert between time units. In normal life you will maybe convert minutes to hours and days or months (which aren&#x27;t even of uniform length) into weeks and years. But scientists or engineers will always work in \"metric\" units of seconds and astronomers &#x2F; archaeologists will always work in \"metric\" units of yearsCompare this to mass and length&#x2F;volume units, where a normal person will frequently need to traverse multiple orders of magnitude even just to bake a cake (grams to kilograms and milliliters to liters) and will have frequent experiences involving much higher orders (meters to kilometers every time they are following directions on their phones, or tons if they are loading a truck or buying a car) reply happymellon 5 hours agorootparentprev> 10 doesn’t work great for it.Because the rest of circles are so logical, π is such a nice round number. reply quicklime 9 hours agorootparentprevNothing about time is based on degrees of a circle, other than one specific way to visualise it - which many people don&#x27;t use anymore and consider antiquated :) reply mistercheph 9 hours agorootparentSundial; our notion of time is inextricably linked to the observed 180 degree arc path of the sun. The modern notion of time descends from that, and fails to stand on its own, despite silly attempts to define SI units via ad hoc correspondances. reply dehrmann 9 hours agoparentprevYeah, base 12 is the most practical for divisibility. 60 is good, but it&#x27;s too big to conceptualize.>> Working with base-10 numbers is so much easierI mean, every base is base 10. reply gpderetta 5 hours agorootparentThere are 10 kinds of people in the world... reply happymellon 5 hours agoparentprev8 hours standard sleep would just adapt. It&#x27;s only 8 because it&#x27;s a nice round number.Very few people I know actually sleep exactly 8 hours, so the recommendation will just adapt to another memorable number. reply eloisant 3 hours agorootparentIt&#x27;s 8 because it&#x27;s 1&#x2F;3 of the day. 10&#x2F;3 is not a nice round number.Also 1&#x2F;4 of a day is 6 hours, another nice round number! 10&#x2F;4 is 2.5 which is not as bad as 10&#x2F;3 but still not a round number. reply majestic5762 13 minutes agoprevI&#x27;m angry how useless this is reply simonh 9 hours agoprev> A standard hour is broken into 60 minutes. There are 2.4 standard hours in 1 metric hour.That makes 1 metric hour equal 144 standard minutes. Since 1 metric hour is 100 metric minutes, that means 1 metric minute is 1.44 standard minutes. But the site says:> A standard minute has 60 seconds. There are 2.4 standard minutes in 1 metric minute.Even without doing any calculations those scale comparisons for the hour and minute can’t be the same as shown. Standard is going down by a factor of 60 and ‘metric’ by a factor of 100 so they can’t keep the same ratio. reply data_ders 1 hour agoprevI&#x27;d pay good money for an analog wall clock that has 10 hour days and 100 minute hours! AFAICT, this product does not exist. Closest thing I could find was this blog [1][1]: https:&#x2F;&#x2F;raywinstead.com&#x2F;BobWemerMetricClock.shtml reply s0teri0s 4 hours agoprevLol, this was EXACTLY my high school sr. year social studies project in 1980, with roughly the same effort (sadly, I didn&#x27;t create a working clock). I won first place, with just this. The only difference is I named the metric units &#x27;mints.&#x27; reply eloisant 4 hours agoparentIt&#x27;s not super hard to create a clock, you just have to find a 24-hours clock then you create custom labels&#x2F;board for it.Or if your system works with 2 rotations per day use a regular clock. reply s0teri0s 4 hours agoparentprevAlso, no mention of the need for only 10 big-ass time zones instead of 24 relatively narrow time zones. The continental US might have only 2 time zones instead of 4. reply ulkis 1 hour agorootparentNothing says that time zones have to align on even hours. They don&#x27;t today - look at India for example. reply JR1427 4 hours agorootparentprevWhy is having fewer time zones a good thing?Wouldn&#x27;t this actually be confusing, because things would have to be happening at different local times depending on where you are in the time zone? reply s0teri0s 3 hours agorootparentI wasn&#x27;t really advocating for it, I just think if we were crazy enough to adopt this time system, 10 time zones would also be a necessary adjustment. reply JR1427 2 hours agorootparentAh, I see. That makes sense! Although not all timezones are +&#x2F;- an integer number of hours. reply eloisant 3 hours agorootparentprevThis is already the case, timezones have weird shapes and some of them are huge.In Europe and China you have timezones spanning over 3 \"sun\" timezones. In practice that means the sun rising and setting at different times. People are used to have the sun setting late or rising early depending where they live. reply waingake 6 hours agoprevSpeaking of different clocks. Here is the year on a clock face. 12pm is summer solstice, 12am is winter solstice. https:&#x2F;&#x2F;clock.mohiohio.com ( I&#x27;m in the southern hemisphere so it might be the wrong way around if you aren&#x27;t. I need to fix that.) reply kristopolous 9 hours agoprevThe French briefly went all in on metric time after the revolutionhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;French_Republican_calendar reply qingcharles 9 hours agoprevI always preferred Internet Time:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Swatch_Internet_Time reply pndy 8 hours agoparentI still remember reading about Swatch time years ago in some pc magazine. Back then it felt like a cool idea that surely will be adopted as standard unit of time for the Internet era, making communication across the globe much easier and sadly... reality was quite different. reply BjoernKW 6 hours agoparentprevI fondly remember Swatch Internet Time and .beats. Back then (around 1998), I used to have a watch that displayed Internet Time and I genuinely believed that this was going to the future way of how we keep track of time and synchronise with each other.Unfortunately, things turned out differently. reply elashri 2 hours agoprevThe first thing that came into my mind seeing this title is the time component in the metric tensor [1]. Which I was asking why it is on HN front page :)[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Metric_tensor_(general_relativ... reply riffraff 9 hours agoprevI love how this mentions \"decimal is as easy as money, assuming US dollars\" when the US is basically the only country still using non-decimal units for most things, and money was wildly non-decimal in other places (cough UK cough). reply zombot 2 hours agoprev> There is no AM or PM with metric time.There is no AM or PM with 24-hour time, either. I don&#x27;t think the AM&#x2F;PM fans care much whether the range they are messing up has 24 or 10 units. reply mib32 46 minutes agoprevFor some reason, the left clock is going faster than right for me. reply lvncelot 5 hours agoprevI feel like every developer&#x2F;technically inclined person goes through a phase of trying to fix timekeeping. I know I did. I think it&#x27;s a good exercise in recognizing that we (largerly) make tools and standards that fit existing social constructs, not the other way around, and that there are some things that are just inherently messy. reply contact9879 9 hours agoprevbase-10 time only makes sense because we use a base-10 number system. the Babylonians didn&#x27;t use a base-10 number system so the current time system was more intuitive. however, the French already tried this a couple hundred years ago. it didn&#x27;t stick around.personally, I&#x27;d prefer we drop all base-10 conventions (units, numbers, etc) and switch to base-12 and base-60 for everything (dozenal or duodecimal) reply benkaiser 2 hours agoprevAlso relevant, from 10 years ago, Simple Universal Time. Takes it one step further and eradicates timezones.https:&#x2F;&#x2F;www.nico.schottelius.org&#x2F;docs&#x2F;sut&#x2F; reply shrumm 9 hours agoprevThis was a fascinating read for a totally unexpected reason.I’ve spent most of my life in countries where the metric system is used for distance, weight, temperature etc.This year I’ve had to travel a lot to the US for work and found the constant mental conversions a PITA. I kept wondering why people keep holding out against such an obviously easier system.Then I read this article about 8 hours of sleep would be 3.33 metric hours. How you wake up at 9:50 after sleeping at 2:75 and I notice real-time at the absolute recoil I feel reading this. Maybe I’m getting older , but I completely get how familiarity to numbers being represented a certain way is hard to let go of. reply skummetmaelk 9 hours agoparent8 hours comes from the worker&#x27;s movement anyway. 8 hours work, 8 hours recreation, 8 hours rest. It&#x27;s clearly only chosen to make a nice slogan. In reality 7-9 appears to be optimal. If you were using decimal time you&#x27;d just say 3-3.5 hours and be done with it. Convenient enough. reply II2II 5 hours agoparentprevYeah, too much of our society is based upon 24 hour time.The transition is also unlikely to have many benefits. Unlike most of the other units of measure, the everyday conversions are fuzzy. The only exception I&#x27;ve seen is when payroll bean counters expect minute precision converted to decimal hours, which is a pain! Everything in science and engineering tends to be maintained in seconds, which is decimalized anyway so there is no benefit there.I don&#x27;t see \"metric time\" making any headway, particularly since something like universal time would be much more beneficial yet hasn&#x27;t gained traction. reply vanviegen 9 hours agoparentprevAt least the 3.33 makes intuitive sense to me: a third of a 10 hour day.Am I correct in assuming 9:50 and 2:75 should be the other way around? reply yakubin 2 hours agoprev> A metric minute is broken into 100 seconds.> A standard minute has 60 seconds. There are 2.4 standard minutes in 1 metric minute.Surely it should be 1.(6). I hope they didn’t change the definition of a second. It’s an SI unit. reply mcny 2 hours agoparent> It’s an SI unit.There is really nothing scientific about time as we mortals use it.As soon as you bind the definition of time to the rotation of the earth, all bets are off about being \"scientific\".A day has x hours. An hour has y minutes. A minute has z seconds.Therefore, you have now defined a second as 1 &#x2F; (x times y times z) What happens when the earth speeds up by a fraction of a second? Does the definition of a second change? reply yakubin 1 hour agorootparentSecond is not bound to the rotation of the Earth. It’s bound to the speed of light (indirectly). reply pmontra 4 hours agoprevTo the author: the font is so thin that it exposes subpixel color artifacts on a 1080p 15\" screen. I&#x27;d remove all the font-weight statements from CSS or set them to normal, except maybe for the one for H3. reply dan-robertson 4 hours agoprevFun metric time fact is that France conceded to Greenwich becoming the international prime meridian on the condition that the conference on the meridian also expressed a hope for a decimalised system of time (and angles). https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;International_Meridian_Confere...In the end they ended up not adopting the Greenwich meridian for quite some time afterwards. reply bmacho 3 hours agoprevI always had the feeling that I&#x27;d love decimal time, but seeing it on a clock, I absolutely love it. Especially that it is called metric time, since it is not just decimal, but it is the natural time system in our metric system, which we doesn&#x27;t use bc of inertia, but that can and should change. reply perilunar 8 hours agoprevTime is never going to be easy to decimalise, since days, months, and years are all natural periods and not so easy to change.Maybe once we have left the Earth and spread out into the solar system and beyond, there will be no reason to keep Earth time, and we&#x27;ll just use Unix time, and stick to seconds, kiloseconds, and megaseconds. (Hopefully in the next few gigaseconds.) reply billpg 6 hours agoprevThere&#x27;s a parallel universe where the French chose to base their new system around twelve instead of ten. Divide the day into twelve twelfths and each twelfth into twelve parts again. (They&#x27;d have to coin prefixes for each.) reply michaelhoney 5 hours agoparentAnd hopefully we use a base-12 numbering system. It would make division into thirds, quarters and even sixths much easier. Sign me up! reply josefrichter 3 hours agoprevWell, the nice thing with decimal time is that it also gives you a better indication what portion of the day is over. at 6 o&#x27;clock you know 60% of the day is gone. With 2pm you don&#x27;t make that calculation. Not that it&#x27;s important, but it&#x27;s one of the nice benefits. reply xpointer 4 hours agoprevPreviously done as an art project: http:&#x2F;&#x2F;metriclock.com&#x2F; reply alluro2 6 hours agoprevIt fails on a crucial aspect, of defining an alternative to Mississippis. reply wizofaus 4 hours agoprevBut how would daylight savings work? Or perhaps more seriously, time zones...Anyway given the U.S. is still hanging on to measurements like Fahrenheit and inches, we&#x27;re not going to see more sensible ways to measure and indicate time until most of humanity is living on a different planet. reply mjd 5 hours agoprev“fuck the sun”https:&#x2F;&#x2F;www.plover.com&#x2F;swatch.html reply robsh 9 hours agoprevDecimal time doesn’t seem as useful to me as localized time. With GPS coordinates, we don’t need a timezone system, everybody could have noon at solar noon. When setting up meetings, one only needs to include the longitude and everybody could easily join at the correct time. It would be cool if airplane rides showed a real local time while in flight. Might be a cool app.While we’re at it, the Gregorian calendar could be made celestial as well. Date could be based on the solstice&#x2F;equinox and moon. Apparently this is called a lunisolar calendar and repeats on the Metonic cycle every 19 years. Though it’s off by a couple hours. That means if I recorded a message with lunisolar date and local time, a historian could probably infer the exact year it was recorded. reply ianbooker 5 hours agoprevI just realized that the standard time watch face feels like it will follow the sun rising from left to set on the right side. But since the sun is rising in the east, it should be horizontally reversed. Or you should always look to the south &#x2F; to the sun. Or it feels right because of my western idea of writing from left to right? reply perilunar 4 hours agoparentA 24 hour clock with midnight at the bottom tracks the motion of the sun if you are in the Northern Hemisphere looking South. If you are in the Southern Hemisphere looking North you need a clock that goes anti-clockwise.See: https:&#x2F;&#x2F;sunclock.net reply tomviner 5 hours agoparentprevClock faces were inspired by sun dials. The hour hand traces a version of the path the sun&#x27;s shadow makes. At least in the northern hemisphere. reply Mashimo 5 hours agoparentprevWhen you are in the northern hemisphere just look south and the sun will follow the clock from left to right :) reply trivialanalog 5 hours agoprevLove it! I built something similar where the current day, week and year is displayed as elapsed percentages [0].[0] https:&#x2F;&#x2F;trivialanalog.de&#x2F;zeitfortschritt&#x2F; reply avinash 4 hours agoparentCool. I would suggest to make it multilingual as the T, M and J labels are not easy to understand by those who don&#x27;t speak German. reply trivialanalog 4 hours agorootparentYes, it&#x27;s on the list. reply eterevsky 4 hours agoprevThis metric time goes only part of the way. \"Day\" shouldn&#x27;t be a metric unit, since it changes over time and only makes sense on Earth.Unix timestamp is the real metric time because it only uses seconds which is a metric unit of time. reply elromulous 9 hours agoprevI don&#x27;t completely hate it.What I do hate is the need to make a day ten hours. I&#x27;d actually prefer we keep a day 24 hours, it makes the transition a lot easier, and all the other mental math still simplifies. reply vortex-trap 9 hours agoprev10 hr dial will certainly create problems for human systems, because, time counting is getting relatively more coarse that way. instead a 20 hr dial is better facilitating, but can it be called matric time?thought as, a 10x10 clock, metric because 10 hr dial, has 100 mins every hour. it is sort of ok, but number of hours reduced from 12 to 10, that is counting 4 less hours everyday, means trouble and 100 mins every hr though --- in total a 10x10 clock is &#x27;difficulty&#x27;.a 20 hr dial, on the other hand --- dose it solve?somewhere i though of a 16 hr display too.Faisal reply donatj 9 hours agoprevThe problem is base 10 is a terrible base for any unit that needs to be divided. It’s an arbitrary base with no positives based on our fingers. No reasonable species would have picked base 12 when base 12 is so much better and so close. 10 can’t be evenly divided into 3 or 4 parts. 60 minutes in 3 parts is 20 minutes. 100 minutes in 3 parts is 33.3333 minuteshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sexagesimal reply tcmb 9 hours agoparentTrue. And having 7 days per week is majorly impractical, also for reasons of divisibility. With 7 being prime, it&#x27;s impossible to do things every other day or every three days without being left with a remainder. reply w-ll 9 hours agorootparentUnless you are a bodybuilder. https:&#x2F;&#x2F;forum.bodybuilding.com&#x2F;showthread.php?t=107926751 reply guntherhermann 1 hour agorootparentI don&#x27;t think I&#x27;ve genuinely laughed at an internet conversation like this in such a long time. Thanks for that. I should join a forum again. reply offices 5 hours agorootparentprevIt&#x27;s a shame the internet has pinned this on bodybuilders just because of the URL. TheJosh has a progress photo on his profile - he must be very deep into an offseason. bodybuilding.com is a general exercise forum and is infamous for the trolling on its misc board. reply brettermeier 6 hours agorootparentprevWhat a great conversation. How did you find those posts from 15 years ago? XD reply wizofaus 3 hours agorootparentprevJust as bad as having 31 days a month, for randomly chosen months. If any periods of time need to fixed it&#x27;s surely weeks and months. How about 5 day weeks (3 working, 2 not - and yes, therefore 10-day \"fort\"nights) and scrap months altogether... reply macawfish 9 hours agorootparentprevBut at least 7 days per week resonates approximately with the lunar orbit. reply michaelhoney 5 hours agorootparentclearly we need to reposition the moon reply wizofaus 4 hours agorootparentOr genetically engineer ourselves to have a different number of fingers reply mistercheph 9 hours agorootparentprevWouldn&#x27;t that make sense in a context where the useful number of 6 counts the days reserved for the affairs of mankind, and the seventh was an extra day reserved for rest or worship? I.e. the background of our 7 day week reply shiroiuma 5 hours agorootparentI&#x27;m sure that&#x27;s religious revisionism (just like the Christmas holiday). Like so many time-based things, the 7-day week comes from the cycles of the Moon, and goes back at least as far as the Babylonians. reply mistercheph 1 hour agorootparentRight, religious zealots have been ever revising the story of human history, which has been mostly secular peoples that practiced empiricism and appreciated astronomical phenomena as interesting but did not take them as divine. reply skummetmaelk 9 hours agoparentprevI need to divide my 12 into 9 parts. What do I do now? reply feldrim 9 hours agorootparent12 hours &#x2F; 9 = 80 mins. 12 mins &#x2F; 9 = 80 secs. That&#x27;s the point. And yes, Base 12 is superior to Base10 for this specific reason. But only for this use case. reply kunley 3 hours agoprevThis is what happens when a group of people values intellectual wisdom over intuitive wisdom. reply michellezzz 4 hours agoprevAlthough confused by the conversion between standard time and metric time, I LOVE your description of Time is Money. reply reportgunner 4 hours agoprevFor this to work you would also need weeks to have 10 days, months have 100 days and years have 1000 days. reply mo_42 9 hours agoprevI&#x27;m really fascinated by such ideas. However, it&#x27;s just academic as time is so much baked into physical devices (watches, clocks, ...) so this will most probably never happen.I&#x27;d rather start redoing the calendar. It doesn&#x27;t need to be metric but the different lengths of the months (and the naming Oct. should be 8 not 10?) could be reworked. reply bloopernova 2 hours agoparentHave you seen this unix time clock? https:&#x2F;&#x2F;retr0.id&#x2F;stuff&#x2F;2038&#x2F; reply pndy 8 hours agoparentprevThere are ideas of redesigning calendar:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Calendar_reformhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;World_Calendarhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Symmetry454and ideas for time keeping on other planets likehttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Darian_calendarhttps:&#x2F;&#x2F;ops-alaska.com&#x2F;time&#x2F;gangale_mst&#x2F;abstract.htm reply SulphurCrested 7 hours agoparentprevOctober used to be the 8th month (and September, November and December the 7th, 9th and 10th) because March was the first month of the year. reply julienpalard 9 hours agoparentprevYes. Decimal time almost happened in France during the revolution, but fixing all the clocks was impossible so people kept their standard clocks, so they kept the old habit... reply gerikson 6 hours agoprevI&#x27;m confused by this page, the standard clock is in my timezone (CEST, UTC+2). Is the metric clock also set to this standard, i.e does 00:00:00 in that clock occur at 22:00:00 UTC? reply looping8 6 hours agoparentIt seems to be, yes, at least according to my calculations. For me it is almost 11, so the metric clock is past 4, close to the middle. reply JR1427 4 hours agoprevThis is a classic \"clever but stupid\" idea.There is no compelling reason to adopt decimal time. reply nologic01 8 hours agoprevNice visual presentation of the concept.On the likelihood something like this might be considered, dont hold you breath. Our continuing use of Babylonian time is probably the most pervasive and enduring network effect known to humanity. reply ilyt 1 hour agoprevsadly few centuries too late. reply jawerty 9 hours agoprevI love the pitch however my brain would hurt after a day of this. Maybe it&#x27;s simply because no one is metric time woke. reply tcmb 9 hours agoprevI could be interested in a mechanical watch showing decimal time, just for the novelty and fun of it. reply chucknthem 5 hours agoprevhonestly, the mental math around metric time demonstrated in this post makes me think we should go the opposite way and make everything else base 12 instead of making time base 10. Being divisible by 2, 3, 4 and 6 makes a lot of mental math easier. reply Pyxl101 9 hours agoprev> Working with base-10 numbers is so much easier than trying to think in base-60, base-12, and base-24.In some ways, sure. If you&#x27;re doing precise mathematical things. Otherwise, if you&#x27;re doing simple mental math, base-12, -24, and -60 have some advantages.60 can be evenly divided into 1&#x2F;2 (halves) or 30 min, 1&#x2F;3 (thirds) or 20 min, &#x2F;4 or 15 min, &#x2F;5 or 12 min, &#x2F;6 or 10 min, and by 12, 15, 20, 30, and 60.24 can be divided by 2, 3, 4, 6, 8, 12, and so on for 12. I always assumed this was the reason for the \"imperial\" unit measures and for time and length. Dividing things into thirds is a common use-case and it&#x27;s nice to be able to do that evenly. reply uoaei 6 hours agoprevThere is some evidence our bodies have split up the day into 16 parts: consider the 90-minute REM cycle. This suggests it would make more sense to try to use base-2. 4 bits of depth required to specify the 90-minute \"hour\". 16 bits of depth corresponds to a resolution of about 1.32 seconds. Then following the obvious pattern however \"minutes\" would probably be 8 bits of depth, corresponding to 5.625 standard minutes, so this is the most jarring difference. Of course then you wouldn&#x27;t have clean divisions into 3, 5, etc. but it would be simple to calculate, notate, and reason about. reply joshu 5 hours agoprevswatch beats or gtfo reply mistercheph 9 hours agoprevSexagesimal mental math (especially wrt fractions) is easier than decimal math, which is why we represent time and circles with them. reply cranium 9 hours agoprev [–] I like imagining how the life would look like if you change what is essentially a convention. Set the week to 6 weekdays and a 3-day weekend, have 6-hour workdays, or 80% company work &#x2F; 20% service to your community. I&#x27;m very curious about the societal change a universal basic income could bring.With metric hours, I&#x27;d hope 1-classical-hour meetings wouldn&#x27;t become 1-metric-hour meetings because that&#x27;s what we did in the past ;) replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Metric time is a system dividing the day into 10 hours, each hour comprising 100 minutes, and each minute containing 100 seconds, thereby simplifying mental math and dealing with different time zones.",
      "In the metric time system, there is no distinction between AM and PM, with a day simply consisting of 10 hours.",
      "The concept behind metric time is likened to monetary thinking, where each metric hour is equivalent to a 100-dollar bill and each metric minute akin to a 1-dollar bill, totaling to 1,000 minutes and 100,000 seconds per day."
    ],
    "commentSummary": [
      "The primary debate centers on the proposal of applying a decimal or metric system for measuring time, with advocates arguing it would streamline calculations and align with the existing metric system.",
      "Critics, however, foresee potential issues regarding precision, implementation-related challenges, and societal adjustments that the new system might necessitate.",
      "Discussions also extend to alternative time measurement systems and potential calendar reforms."
    ],
    "points": 230,
    "commentCount": 230,
    "retryCount": 0,
    "time": 1697081239
  },
  {
    "id": 37852711,
    "title": "Has anyone gotten complete, permanent relief from tinnitus?",
    "originLink": "https://news.ycombinator.com/item?id=37852711",
    "originBody": "As far as I can tell, there&#x27;s no universally accepted \"cure\" for tinnitus, but there are a number of \"therapies\" out there, some of which seem to prey upon people looking for relief but some of which seem plausible.I&#x27;m wondering if any subscribers here have had tinnitus and experience permanent relief from the ringing? Not just reduction, but actual permanent relief that never comes back even when doing things that previously worsened the tinnitus.If you can&#x27;t tell, I&#x27;m trying to establish an \"existence proof\" here, if no one has ever gotten permanent relief then it seems like it might not be worth bothering with the \"symptom reduction\" therapies since they would most likely lead to focusing on the symptoms more intensely.",
    "commentLink": "https://news.ycombinator.com/item?id=37852711",
    "commentBody": "Has anyone gotten complete, permanent relief from tinnitus?Hacker NewspastloginHas anyone gotten complete, permanent relief from tinnitus? 236 points by actinium226 12 hours ago| hidepastfavorite278 comments As far as I can tell, there&#x27;s no universally accepted \"cure\" for tinnitus, but there are a number of \"therapies\" out there, some of which seem to prey upon people looking for relief but some of which seem plausible.I&#x27;m wondering if any subscribers here have had tinnitus and experience permanent relief from the ringing? Not just reduction, but actual permanent relief that never comes back even when doing things that previously worsened the tinnitus.If you can&#x27;t tell, I&#x27;m trying to establish an \"existence proof\" here, if no one has ever gotten permanent relief then it seems like it might not be worth bothering with the \"symptom reduction\" therapies since they would most likely lead to focusing on the symptoms more intensely. upghost 19 minutes agoI hope this comment reaches anyone suffering from tinnitus. My tinnitus is so bad that I’d … well good news is, I found a great way to manage my brain melting tinnitus.Step 1: YouTube-dl this blessed sound: https:&#x2F;&#x2F;youtu.be&#x2F;8indTo2ykPw?si=izyTOg4gYvnfsqZs (Plz tip the guy) (You should be able to tell just by listening to the sound that it immediately cuts out the tinnitus— if this sound print doesn’t work for you, there may be others that work better. But I have let other tinnitus sufferers wear my headphones and they all say it makes the tinnitus go away completely) 1a: (cut out the dialogue in the beginning with audacity) Step 2: buy a pair of these waterproof mp3 ONLY (it’s an appliance) bone conduction headphones: https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;aqqhPm9 Step 3:put the mp3 you ripped on the headphones and remember what a normal life feels likeThe only times I realize I have tinnitus is are right before I fall asleep, right when I wake up, and once a day for 20 minutes when I need to charge my headphones.And I want to emphasize my tinnitus sounds like the screaming sun planet on Rick and Morty. It’s really bad. But thanks to this technique I only experience pain a few minutes per day. Good luck everyone. reply burnte 15 minutes agoparentI&#x27;m thrilled it works for you and I&#x27;m sorry yours is so bad. Mine is average I&#x27;d guess, but I actually avoid those apps that generate these sounds because once I listened and heard the REAL silence, I knew if I did it much longer it would drive me bonkers whenever my tinnitus came back. I&#x27;ve had it since early childhood so I think I learned to tolerate it better, I can mostly ignore it these days. So I&#x27;d just say to other people, be careful with those apps&#x2F;sounds, you might get dependent on it VERY quickly. reply upghost 13 minutes agorootparentOh yeah, I’d give anything to hear the real silence again. Someone sent this to me as an FDA treatment that’s new, but I haven’t tried it: https:&#x2F;&#x2F;www.lenire.com&#x2F;what-is-lenire&#x2F;I’m hoping for some “silence tourism” once in awhile! reply seviu 4 minutes agoprevI have had Tinnitus all my life, since I was a kid. At the beginning it was intermittent, now it&#x27;s permanent, to a level where I understand why people have suicidal thoughts. Concentrating on tasks is quite difficult and every audiologist I visit tells me to deal with it because there is no cure.What I find fascinating is that when I meditate or start falling asleep, I can consciously enter periods where it disappears or it becomes bearable. Like if I learn a trick with my brain in which I can mute it. Sadly entering it requires a lot of effort. And when I wake up or leave the meditation state (which is hard to reach because of the tinnitus) its impossible to reproduce it.Mine I am sure is due to problems with my jaw (bruxism). One thing that helped with the jaw (but not the tinnitus since it is now fully embedded in my brain) was with botox injections. If you are on early stages and if you think the jaw is a main factor in your tinnitus, go to a neurodoctor and ask him for botox injections in order to treat it.About the Lenire device, two things: it requires dedication and time, which I don&#x27;t have, and you cannot event rent it. Selling it is also forbidden. In essence is an mp3 player which electrocutes your tongue. I have come with many such solutions and all are the same. Snake oil.One last thing: the tinnitus is louder in periods where I experience more lack of sleep and stress &#x2F; anxiety. It might sound cliche, but meditation, yoga, even going for a walk (no phone, no headphones, just a walk) really does work in reducing its volume. reply lightweb 31 minutes agoprevYes. I stopped eating refined sugar and drinking any alcohol and my 90% hearing loss in one ear + tinnitus has gone away in about 3-4 months. I was suffering with it for years.I also had all mercury fillings removed by a specialist with the correct equipment and procedures. reply cryptonector 25 minutes agoparentI also had my mercury amalgam fillings removed and replaced by a specialist in a hazmat-like setup, and I also no longer drink alcohol, and I also don&#x27;t eat refined sugars, and yet I still hear my tinnitus. But I don&#x27;t suffer from my tinnitus. I only ever notice it occasionally, when I see any mention of it, or when I think about it.I.e., I got used to it.In the beginning though it was awful. reply cyrillite 19 minutes agoparentprevReduced sugar and salt for me. I was told I have no reason to have tinnitus (including the fact I don’t work in loud environments, use headphones cautiously, etc.)Two years into a “I’d like to be fitter and healthier” lifestyle change and I’ve watched my diet influence tinnitus massively. reply merpnderp 26 minutes agoparentprevI don&#x27;t know about the mercury fillings, but the times I&#x27;ve completely stopped eating anything with added sugar have had dramatic effects on my health. reply zamalek 23 minutes agoparentprevNow that you mention it my tinnitus has improved (but not gone) since quitting alcohol. That stuff is just worthless poison. reply MichaelMug 5 hours agoprevI’ve had tinnitus for about one year now. There is no permanent relief or treatment. Lots of snake oil.My hearing was tested by an Audiologist and my hearing was normal.The “sound” I observe is high pitched. Using a tone generator I matched it to around 16,500 Hz. Interestingly, if I play that tone I get temporary relief on the order of 2-10 minutes.As far as I understand my tinnitus is the result of something going wonky with the signal processing in the brain.If you’re suffering from tinnitus for the first time it’s important to remain calm. There is defiantly an amplifying effect from the psychological aspect of tinnitus. Eventually the body will “habituate” if it does not go away. It took me around 3-6 months to be able to ignore it. During the day I rarely hear it. At night a little more. Playing sounds at a low volume on a Bluetooth speaker helps. For example on Spotify an artist called “TMSOFT” has good stuff. In the day I’ll listen to jazz or lofi.It’s important to protect your ears. iPhone has a hearing protection feature for headphones and I have it on the lowest setting. I would avoid in-ear headphones. Use hearing protection at concerts. reply ryandrake 3 minutes agoparent> I’ve had tinnitus for about one year now. There is no permanent relief or treatment. Lots of snake oil.Half of the 200+ post comment section reads like those bottom of the barrel YouTube ads with the AI generated voices: \"Try this secret trick to cure your [condition].\" It seems to always happen when someone comes here to ask for opinions on disease, food, health or fitness. People, don&#x27;t go to HN for medical or nutrition advice.So far, we&#x27;ve already seen: Magic audio tracks, shocking the tongue, steroids, and Ambien, and those are only the top few root subthreads. reply stinos 3 hours agoparentprevThere is no permanent relief or treatment. Lots of snake oil.That&#x27;s not what this recent book [1] says, at all. In Ducth, but [2] is a translation of the main point in an interview. As far as I&#x27;m aware, this guy is rather far away from snake oil. What is true though is that not all audiologists are caught up yet. Which is a bit weird because I already read about multidisciplinary approach working a couple of years ago IIRC. Which does obviously not mean it works for everyone, but also not &#x27;there is no permanent relief&#x27;.[1] Bart Vinck: Tinnitus, een schaduw van geluid[2] Can tinnitus disappear completely?\"Absolutely, it happens very often. It&#x27;s to say: we all hear sounds in our heads, only we don&#x27;t experience them consciously. After all, the brain forgets sounds that are not relevant, just like I don&#x27;t feel the glasses I&#x27;m wearing now.\"Our brain does nothing but sort out stimuli: this is important, that is not important. Logical too, otherwise we would go crazy with all the stimuli constantly coming in.\"My message is not to learn to live with that beep, but to train your brain to classify that sound as harmless, allowing you to forget about it. Feel free to call it an auditory reset of your brain.\" What does such a treatment look like?\"It has been proven that a multidisciplinary approach works well. Through an intense therapy bath, we try to reset the brain so that that beep or squawk is no longer threatening: patients receive 20 hours of therapy over four days.\"You also have to find other ways to vent tension and take care of yourself. Physiotherapists and osteopaths additionally work on the physical problems. Our patients often suffer from other psychosomatic complaints: they clench their jaws or have tense neck and shoulder muscles.\"Some 96 percent of our patients report afterwards that the impact of the tinnitus has been greatly reduced. Unfortunately, psychotherapy is barely reimbursed.\" reply Twirrim 2 hours agorootparent> \"My message is not to learn to live with that beep, but to train your brain to classify that sound as harmless, allowing you to forget about it\"This is essentially what I do. I&#x27;ve had it tinnitus for some 20 years now. Both ears, a constant high pitched ringing.Most of the time I honestly don&#x27;t notice it, even in quiet rooms. As soon as something reminds me about it, or I&#x27;m trying to listen for something quiet, or certain high pitch sounds go off (my least favourite is flashbang like effects on TV or in games), it&#x27;ll come back with a vengeance. So e.g right now because I saw this HN post, it&#x27;s feeling especially loud.It&#x27;ll probably be about an hour before I&#x27;ll forget to think about it (for want of a better description), and I go back to not noticing it. reply versteegen 1 minute agorootparentI think my tinnitus is so easy to ignore because it&#x27;s perfectly even and at extremely high frequencies I probably can&#x27;t even hear any more. Which is what I assume the cause is.Honestly I didn&#x27;t think I actually had tinnitus because I don&#x27;t notice it for weeks or maybe even months at a time, at least not for more than a short moment, although I&#x27;ve have it as long as I can remember. It&#x27;s not all that loud, but after concentrating on it for a while it&#x27;s been there constantly and consciously for a good 10min already and it&#x27;s not going away! reply stinos 8 minutes agorootparentprevForgot to mention that, but: same here. Both ears, multiple rather clean tones (i.e. sine waves) n both ears, different tones per ear. I always assumed I was &#x27;lucky&#x27; to get it even before puberty when the brain is more plastic still, so learned to ignore it. Stress and other things can bring it back though.> So e.g right now because I saw this HN post, it&#x27;s feeling especially loud.Exactly.. reply JohnFen 28 minutes agorootparentprevThis is my experience, too. Also, probably for similar reasons, my tinnitus comes back into my awareness when I get very tired or sick.The very first time I noticed it at all was during a bout of the flu. reply imetatroll 36 minutes agorootparentprevI&#x27;m in a similar boat. Generally it is background noise until it isn&#x27;t and then it is a REAL drag. If I am ill or stressed or both it can flare up and then I&#x27;m in for a few days of utter suffering. reply spelunker 26 minutes agorootparentOr talking about it, so now I&#x27;m very aware of my tinnitus again. Oops! reply davely 1 hour agorootparentprevExactly the same for me. I’ve had it for as long as I remember and chalk it up to going to too many punk rock shows as an angsty teen (and never wore ear plugs because I was “too cool”).It’s always there for me but I usually forget about it and only notice it when something draws my attention to it.According to an app I’ve used on my phone (Mimi Hearing Test), I have about 14db HL in each ear.Somewhat related, but I just cannot follow conversations in a noisy environment, like a pub. All the background noise and chatter just washes out the voices of people I’m around.Anyway, I now bring earplugs every time I go to a show. reply wanderingstan 2 hours agorootparentprevSame for me. I’ve had mine my whole life probably due to ear infections as an infant.As a small silver lining, my tinnitus now serves as an audible “alarm system”: too much stress in my life? Drank too much coffee? Overdoing it at the gym? All of these will raise the ringing volume and signal me to make changes. reply guntherhermann 2 hours agorootparentprevSame, I have had tinnitus since a child. The more you focus on it, the worst it gets. Best to accept that you have it and once you do the issues goes away (mostly), I still wake up sometimes noticing it, but it goes away.I think this is a good approach to many mental & physical ailments, however it is easier said than done. reply cnity 16 minutes agorootparentMeditation helps with this. Befriend the tinnitus. It is easy to let go of something for which you have only equanimity. reply linsomniac 2 hours agorootparentprevSame here. Your reply sounds like I could have written it. Until I started reading this thread, I don&#x27;t remember when the last time I noticed my tinnitus was. Maybe a week or two ago I noticed it and just thought \"oh right\" and went back to ignoring it. reply throwaway2990 1 hour agorootparentprevSame here. But when I’m sick with a cold or flu it’s amplified a lot. It bothers me alot when I’m sick. reply consp 1 hour agorootparentprev> Unfortunately, psychotherapy is barely reimbursedIs this correct and not physiotherapy? Psychotherapy (if send via gp and dianosed) is at least 75% reimbursed if done at a non-contracted practitioner unless you have the shit-insurance, then it&#x27;s only 50%. reply stinos 6 minutes agorootparentI don&#x27;t know the details of it, but note this is in Belgium. reply vinc 1 hour agoparentprevSame thing for me.I started to hear it at night when the room was quiet 7 years ago, and then progressively all the time. The first year was hard, I saw a few specialists who told me there was nothing to do about it. In the end I accepted it and now it doesn&#x27;t bother me anymore.The more you are upset about it and the worse it is.I only wish I could be able to hear the silence again, but there are worst things in life. My hypothesis is that it was always there but somehow the filter I had for it stopped working. A bit like eye floaters. reply fatnoah 1 hour agoparentprev> Eventually the body will “habituate” if it does not go away.This has been my experience. If I \"notice\" it, then I hear it until it goes away again. Of course, one thing that causes such notice is reading anything about it. :( reply criddell 4 hours agoparentprevI’ve had tinnitus for something like 5 years now and mine varies from day-to-day. Mine seems to be somewhat connected to diet. I think salt might be a trigger. If I have a French Fries or some other salty snack, I’m in for louder ringing an hour or two later. reply Delk 4 hours agorootparentI seem to remember that high blood pressure could worsen tinnitus, so that might have something to do with it. reply bayindirh 3 hours agorootparentprevDad went through acute hearing loss twice. They banned salt during recovery. Your tinnitus is related to blood circulation in the ear. Reduce salt. reply maccard 2 hours agorootparentHave you any citations for this? This is exactly the sort of stuff people are to about about when referring to snake oil reply bayindirh 2 hours agorootparentCitations? I remember the prescriptions and Doctors&#x27; notes for the diet itself. He had to endure through IV drug treatments at home, was not able to sleep for 17 days because of the given drugs.I remember cooking everything without salt (then buying reduced sodium salt for some time because he missed the taste of it to a certain degree), stop buying sparkling water, how my father tried to cope with the remaining tinnitus after the hearing loss mostly reversed (>95% IIRC), and how it increased and decreased over time.He still doesn&#x27;t drink sparkling water, we still cook with reduced salt. If we deviate from this, his tinnitus increases, yet he tries to hide it from us.Do you need any more citations?Mom also has tinnitus, but hers is different, not affected by diet. She uses an advanced hearing aid which counters it using sound somehow. She is relieved to a certain point with it.There are different kinds, reasons. Need to understand each case. reply ayewo 1 hour agorootparentYou&#x27;ve provided more than enough \"citations\" for your contribution and I learned a thing or 2 from it. Thank you for sharing it.To address the gp point, your original comment would have been fine without the last 2 sentences (unless of course diagnosing tinnitus is your occupation):> Dad went through acute hearing loss twice. They banned salt during recovery. Your tinnitus is related to blood circulation in the ear. Reduce salt.The first 2 sentences was you sharing your experience but the last 2 sentences were you making a diagnosis of someone else&#x27;s condition based off of a comment (rather than a physical exam and&#x2F;or some lab tests) which I imagine is why @maccard asked for citations. reply bayindirh 1 hour agorootparentYou&#x27;re welcome. I&#x27;m glad that helped.I have written the comment like that, because the GP provided an example relating his tinnitus to salt intake, and I know that scenario from my dad, so I have written that with confidence. If I was not sure, I&#x27;d not write a comment at all. :)Health and metabolism are serious subjects, and I have more than enough experience to not make any recommendations based on low-confidence information. Otherwise, I suspect that my wife would crucify me with cold blood (she&#x27;s an MD). replyjraby3 4 hours agoparentprevAren’t in ear headphones with noise cancellation better than not using them and instead raising the volume to overcome background noise? reply jshmrsn 3 hours agorootparentIf the “sound” is an internal perception, then noise cancelling headphones would not help at all. They might make it worse by quieting any background sounds that could otherwise help cover up the internally produced sensations. reply mettamage 2 hours agorootparentIt depends on your tinnitus itself. My tinnitus gets crowded out by a loud environment, I don&#x27;t tend to hear it. I only hear my tinnitus when there&#x27;s no sound. So for me, noise-cancelling headphones do give some temporary symptom relief.Wearing a Bose QC 35 is so important for me when I go to sleep, because the ANC also blocks out sound and blocks out my tinnitus to some extend. It&#x27;s a bit of a skill to sleep with them (you can get audio feedback of the ANC mics) but I&#x27;ve mastered it and improved my sleep game a lot because of it. reply lxgr 2 hours agorootparentBut active noise cancellation removes (perceived) sound. Wouldn&#x27;t that make it worse, then? reply mettamage 2 hours agorootparentThe way I experience it is as follows.Normally:- Tinnitus: 100%With ANC:- Tinnitus: 50%- Bose ANC: 50%I like the ANC sound more than my tinnitus.I haven&#x27;t noticed my tinnitus becoming worse or less worse. reply lxgr 1 hour agorootparentOh, by “the ANC sound”, do you mean the white noise floor of the ANC?In that case, have you tried something like the Bose Sleepbuds? Same idea, much more comfortable to sleep with. reply wahnfrieden 40 minutes agorootparentBose recently retired their 2nd attempt. The team behind those have a new one coming out in January, https:&#x2F;&#x2F;ozlosleep.com I&#x27;m pretty interested... hard to tell how long the pre-sale discount lasts replyTor3 2 hours agorootparentprevMy tinnitus gets worse afterwards if I&#x27;m subjected to noise (as in an airplane). Noice-cancelling headphones is a must for me at this point if I&#x27;m to experience prolonged increased sound levels. reply darksim905 1 hour agoparentprevWere you born premature? Did you get any head damage or injuries growing up?Do you notice any difference when you stretch, and specifically, are looking up and have your head back? I&#x27;ve noticed the ringing stops for me at that point. But I also have a high pitched, 24x7 bi-lateral ringing. I&#x27;ve had it my whole life. reply hbossy 5 hours agoparentprevHave you tried playing that tone and shifting it&#x27;s phase to cancel the imaginary signal? reply od1nos 4 hours agorootparentPhase is a physical property of sound waves that cannot influence a signal originating from the brain or cochlea. reply bennettbackward 4 hours agorootparentIt&#x27;s fun to test what happens when you play the same wave through your headphones but one channel is inverted.Funny enough lots of stereo widening magic relies on a physical property of sound not existing when it&#x27;s in your head. reply tomxor 3 hours agorootparentIf you ever wire a loudspeaker channel the wrong way around, it feels very weird as a lot (but not all for a stereo mix) of the sound will cancel with the other channel in the middle of the speakers and you can move your head through this dead zone.I&#x27;ve never tried it with headphones, but I suppose even though destructive addition isn&#x27;t going to happen it might affect things like intended spatial perception. reply simbolit 4 hours agorootparentprevYea, but he proposed shifting the phase of the physical signal (16.5khz) which supposedly matches the frequency of the imaginary signal.I still think it&#x27;s unlikely to work. reply od1nos 4 hours agorootparentI understand, and there could very well be some psychoacoustic cancellation when stimulating with a matching tone. But any effect will be regardless of the phase of the signal, because phase cancellation is a physical effect of sound waves that occurs before they are converted to neural activity (where tinnitus originates from).In simpler terms: tinnitus does not have phase, at least not in the same way a sound wave does. reply imetatroll 32 minutes agorootparentI think though that the brain is also considering the spacial relationship of the sound to the listener. Hearing the sound from an external source rather than \"inside your brain\" does provide relief in my experience. reply FreeFull 3 hours agorootparentprevNeutral activity itself definitely takes phase into account somehow, since you can hear the phase difference of two same-frequency tones being played independently into each ear, without any kind of sufficiently strong mechanical connection that would explain it. reply Tor3 2 hours agorootparentI experimented with this when I was young and I concur - it&#x27;s really like this. Astonishing but that&#x27;s how it works. reply eps 4 hours agorootparentprevDoesn&#x27;t mean you can&#x27;t match it. reply highertellurian 3 hours agorootparentprevAFAIK when there is not enough external sound input, the brain amplifies the signals from the inner ear in an attempt to compensate which leads to hyperactivity in the auditory nerve and auditory cortex, which can be perceived as tinnitus. So you cannot cancel a &#x27;signal&#x27; that doesn&#x27;t exist. This is my understanding and I may be wrong. reply leviathant 2 hours agorootparentprevWhat I&#x27;ve done is to tune a sine wave to match the frequency of the tinnitus, then notch that frequency in white noise, and blast the result for a few minutes. My tinnitus has not been permanent, it&#x27;s just the rare occasion where I forget earplugs for a concert, and come home work ringing in an ear.This technique makes the ringing go away for a while, but it creeps up again after some time. Thankfully, it has always completely gone away after a day or two. reply Jsebast24 2 hours agoparentprevI&#x27;ve had tinnitus since a few years ago. It went away since maybe 9 months ago. It came back this morning in the same second I read the title of this post. reply notbeuller 34 minutes agorootparentThere was an old peanuts cartoon[1] where Linus suddenly becomes “aware of his tongue” - and Lucy gets angry because she comes aware too. A lot of spam ads I see these days reference tinnitus - and that’s when I notice it.[1] https:&#x2F;&#x2F;www.gocomics.com&#x2F;peanuts&#x2F;1963&#x2F;02&#x2F;03 reply Cthulhu_ 2 hours agoparentprevThere was one treatment - I think it was posted on HN - that played sounds slightly above and below the frequency, which provided temporary or permanent relief. reply mettamage 3 hours agoparentprevIt took me 6 months as well, noise-canceling headphones give me some temporary relief, not full though. My tinnitus came after a night out during a time in my life where I went out a lot. reply jtwoodhouse 1 hour agoprevI had horrible tinnitus for three months. I couldn&#x27;t hear anything out of my right ear. Foolishly, I went to see Inception with it. That was so disorienting.My audiologist said I was SOL and there was nothing to do about it. A few months later, I went to see a nurse practitioner about something unrelated. The ear came up and she wrote me a Rx for a steroid just to try it and see what happens. Two weeks later, I went for a walk. I heard this rush in my ear and suddenly I could hear again and the tinnitus was gone.It was a miracle. I still had some permanent hearing loss but it was 90% better. I could function and make music again. Second opinions FTW. reply cryptonector 2 minutes agoparentSteroids are part of the diagnostic procedure for tinnitus. Your audiologist should have mentioned it; I&#x27;m shocked they didn&#x27;t. reply starstripe 1 hour agoparentprevWhat was the steroid? What caused your tinnitus or did it appear for no apparent reason? reply jtwoodhouse 17 minutes agorootparentI think it was prednisone. I suffered an intense inner ear infection that left me with tinnitus. reply Workaccount2 48 minutes agorootparentprevProbably Prednisone, its the go-to anti-inflammatory steroid that doctors prescribe for just general inflammation treatment. The list of things it treats is almost comically long. reply darksim905 1 hour agoparentprevI would love to know what steroid this was. reply bproven 1 hour agorootparentprobably plain ole prednisone... sometimes it works (esp if you catch it early), mostly it doesn&#x27;t (it didn&#x27;t for me) reply jtwoodhouse 19 minutes agorootparentprevIIRC it was prednisone. reply daltont 1 minute agoprevI suspect that my wisdom teeth that did not warrant removal may be contributing to my tinnitus in my left ear.Anyone get relief from wisdom teeth removal? reply DelaneyM 56 minutes agoprevI woke up one day about twenty years ago with terrible tinnitus, to the point I could barely function. I’d never been to a concert or worked with heavy machinery and didn’t wear headphones (I have tiny ear canals and can’t fit earbuds).I went to the hospital that day, then saw two different specialists, and the only prescription I received was for Ambien so I could at least get a night’s sleep. Even on day three I could barely drive it was so distracting.I woke up on day four and it was totally gone. Like it’d just been a terrible dream. I still went to the audiologist the next day to follow up, he said that sometimes that just happens, and posited that it might have been neurological. He did suggest more tests, but I never followed up.I doubt this is helpful to your case, but it’s an example proof of _something_.My pet theory is that it was related to my migraines - I have very significant visual auras with migraines, which can last up to a day. Maybe this was an auditory equivalent which lasted much longer? (I like this theory more than worrying about a brain tumour, so please don’t tell me it’s impossible.) reply haltist 16 minutes agoparentIf it was 20 years ago then you probably don&#x27;t have a brain tumor because those are caught very late and are often terminal. Mine is from some high impact sport injuries so there is no permanent solution but if someone doesn&#x27;t have any special injuries around the neck and jaw area then basic exercises for reducing tension in the neck can be effective. Some people also have sinus and congestion problems which can be \"fixed\" with antihistamines sometimes. reply kenmendin 3 minutes agoparentprevI have migraine headaches and keep a headache diary. I see parallels between days with headache and tinnitus. reply instagib 9 minutes agoprevhttp:&#x2F;&#x2F;tinnitustalk.com&#x2F; as a few have mentioned.I dove into research as well and found one which sounded promising but I didn’t research further. Shocking the tongue.On the website under pulsative they mention surgery based on a specific MRI for pulsative tinnitus being read by a specialist. It cured some people.Mine changes often and both ears are different with multiple different sequences of sounds. I wear hearing aids which I can switch on&#x2F;off white noise or play music through them with Bluetooth. I play music, videos, or podcasts most of the day and take something to help me sleep.There’s a “How to manage your tinnitus: a step-by-step workbook” by James Henry, Zaugg, Myers, and Schmidt all PhD. reply infecto 3 hours agoprevThe only resource on the internet to read&#x2F;discuss it. http:&#x2F;&#x2F;tinnitustalk.comEverything else is full of people saying they are going to go crazy.My opinion is to approach it that it cannot be cured and is a part of life. I got it around 2016, unknown reasons why, at the time my hearing tested normal for my age. Have seen doctors over the years and while I know its potentially a symptom of something else, I don&#x27;t know what that something else is.The first few years were brutal, reading online does not help as people talking about going crazy. The best approach is to ignore all that and just accept it. Mine not be that terrible, but it is always there but it no longer bothers me. Sometimes I do get some weird flare ups where it pulsates but overall its just part of my life. The sooner you accept that the better. reply patorjk 43 minutes agoparentI second this resource. Lots of good threads and discussion here. The forums are full of threads where people talk about things they&#x27;ve tried. reply n8henrie 10 hours agoprevI&#x27;m a physician with lifelong bilateral tinnitus. Multiple pitches, quite loud, and acutely worse on the right side for the last 1.5 years or so (with some slight hearing loss).I&#x27;ve spent a lot of time on PubMed, but so far I&#x27;ve not found anything that helps mine, even partially or temporarily. I&#x27;ve consulted with close friends that have significant expertise is relevant fields, which has not been fruitful.Thankfully it&#x27;s just part of existence as I&#x27;ve always known it, and so it&#x27;s usually not too difficult, but can really be maddening when trying to fall asleep. reply criddell 4 hours agoparentHave you talked about the Lenire device with your colleagues at all? It got FDA approval and is slowly rolling out as they train audiologists.There’s a Lenire provider where I live (Austin) and I’m on the fence about scheduling an appointment to get one. reply mmh0000 1 hour agorootparent$5000[1] (minimum) for something with no proof it works and no “trial period”. No thank you. That’s like the exact definition of snake oil.[1] https:&#x2F;&#x2F;treblehealth.com&#x2F;lenire-tinnitus-review&#x2F; reply criddell 11 minutes agorootparentThe FDA submission [1] says it they have provided reasonable assurances of the effectiveness of the device.Your link lists all kinds of information about the effectiveness like:> 80% of participants reported a reduction in tinnitus symptomsThat doesn&#x27;t sound like snake oil to me...I&#x27;d love to hear from somebody who has tried it. If they say it helped at all, I&#x27;d write a $5000 check today.[1]: https:&#x2F;&#x2F;www.accessdata.fda.gov&#x2F;cdrh_docs&#x2F;pdf21&#x2F;DEN210033.pdf reply riku_iki 10 hours agoparentprev> but can really be maddening when trying to fall asleepdoes white noise help?.. reply vohk 9 hours agorootparentNot the same user, but I&#x27;ve found the most relief from pink noise like rain or a waterfall played through decent speakers. I find it to be easier on the ears and less distracting than white noise.I&#x27;d recommend anyone suffering play around with the generators on myNoise. It wouldn&#x27;t be an exaggeration to say they kept me going when I was first adjusting to the ringing.https:&#x2F;&#x2F;mynoise.net&#x2F;NoiseMachines&#x2F;rainNoiseGenerator.php reply dataengineer56 5 hours agorootparentI can&#x27;t sleep with any colour of noise from a speaker, but a physical fan in the corner of the room does wonders. reply cpeterso 8 hours agorootparentprevI also listen to pink noise or rain sounds on headphones throughout my work day. I worry about the side effects of listening to random noise for so long, but I continue (not loudly) because it effectively masks my tinnitus (and helps with my task focus). reply pasc1878 6 hours agorootparentprevAgain a different person but my tinnitus souds like white noise - but at a different pitch so not much use.Unless I put the white noise very loud to drwon out tinnitus which is not a good thing to do. reply jaggederest 6 hours agorootparentYou can modulate the white noise very effectively. I dabble with analog synthesizers which let you use low&#x2F;high pass filters on white noise to get very interesting sounds. I wonder if you carefully matched it, it might alleviate the discomfort. Worth trying I suppose. reply emporas 2 hours agoparentprevI don&#x27;t have tinnitus, but i put my head into ice cold water everyday for an hour. I would be very surprised if ice cold water for an hour, does not treat tinnitus successfully in a week.Mind you, ice cold water, not just cold water. reply mettamage 2 hours agorootparentWait, what? Why? So you just come up every minute for breath or something?It sounds interesting! Not as a tinnitus relief, just the practice of doing this. reply emporas 2 hours agorootparentWell, lying down on a bed or a sofa, and putting a big bowl of ice water on the side. Then immersing the head slowly at first, into the ice water. The nose, is facing the sky. Then alternate between the two ears, putting them as deep as possible into the water. There is no problem in breathing, because the nose is always out of the water.The first days of doing that, you will go right to sleep after the cold water and you gonna wake up with a heavy head, like drinking whisky the previous night. After some days it won&#x27;t be like that, and the body will get used to it. reply edgyquant 1 hour agorootparentFor what reason do you do this? reply emporas 1 hour agorootparentI replied to a sibling comment. Among other reasons, it treated a very mild inflammation of the ear i had. The inflammation disappears, but it comes back after 5 to 10 days. I don&#x27;t want to take antibiotics again for that reason, let alone that the doctor won&#x27;t prescribe it anyway, which is correct in my opinion. We want antibiotics to be prescribed only when absolutely necessary. That mild inflammation is almost irrelevant, i feel nothing most of the time. The ice cold water it treats it very well, so that&#x27;s good.It also clears up the nasal pathways. Not absolutely, but it is one of the better ways i have found so far. reply mettamage 2 hours agorootparentprevOh, haha, I was really imagining it wrong :&#x27;)Thanks! reply emporas 1 hour agorootparentThe reason i am doing it, is to smooth out any wrinkles on my face. Not that i have many, one or two, but the ice cold water completes smooths out the skin.I found out accidentally, that it treated a very mild case of inflammation in the ear i had, for over a year.I probably had the same inflammation 6 years back, and i was in a lot of pain. I went to see a doctor, and he didn&#x27;t want to prescribe any antibiotics, because the antibiotics for the ear are the strongest of all, due to poor blood circulation around the ear. Anyway, i convinced him for the contrary and he prescribed the antibiotics, 3 days later my ears were working properly again.The last year however, a similar inflammation on the same spot appeared, but very mild. Almost no pain at all. Just a very small discomfort in the area sometimes. Well the ice cold water for an hour, it treats it completely every time.The reason i am doing it however, is to smooth out the skin. That&#x27;s a lot more important. reply wahnfrieden 38 minutes agorootparenthave you tried a wet towel with ice inside for a simpler solution... replywruza 5 hours agoprevI have it for 4 years and got almost completely desensitized. It is a relief. It’s still there (and right now it rings). But it doesn’t create colorful reactions anymore. During the day, at night, before sleep, it rarely bothers me. Sometimes I even feel comfy about it.In my case the secret was a sort of a therapy. At the second year I’ve become quite suicidal about it. There was a point in time after collecting all the information there is, when I absolutely ultimately had to make a decision. As a result of this thought process, “I will die with it” got fully accepted either way. Somehow this deadened my reactions and after a short while it became just a part of my life that I ignore. My brain got so good at masking it that I have to carefully listen sometimes (yeah, it’s there and it’s loud). I also stopped looking for a cure, relief, methods, threads like this. Not like “I shouldn’t”, but like “not interested”.Pretty sure I must not recommend this way or leave it without a disclaimer: if you feel the same, then get professional help, don’t go through it alone.My key insight is that you suffer while the hope lives, not that you have to lean over the edge to realize that.Edit: upvote to https:&#x2F;&#x2F;mynoise.net, it helped to mask it at early stages much better than colored noises or youtube videos. You can tune sound components to your case and there’s a lot of presets now. reply cableshaft 1 hour agoparentMine isn&#x27;t so bad I&#x27;d have suicidal thoughts. But sometimes it briefly gets bad enough that I go...man, if I get it that bad permanently at some point in the future, would I want to continue living?The Texas Roadhouse CEO killing himself in part because of severe tinnitus[1] sometimes makes sense to me, and that&#x27;s scary. I&#x27;d have never considered I&#x27;d ever want to do that, even being in chronic pain...but if I had to deal with my tinnitus at its worst, all the time? I don&#x27;t know.At the very least I&#x27;m pretty certain I wouldn&#x27;t just do it suddenly and without warning; I&#x27;d have conversations with people I love so they know what I&#x27;m dealing with and why I&#x27;m considering it and doctors and try to make it better first.[1]: https:&#x2F;&#x2F;www.npr.org&#x2F;sections&#x2F;coronavirus-live-updates&#x2F;2021&#x2F;0... reply mettamage 2 hours agoparentprev> My key insight is that you suffer while the hope lives, not that you have to lean over the edge to realize that.Same insight. I never got quite down to the deep end as you did, but I recognize the despair. I&#x27;m glad you&#x27;re okay with it now, life is wonderful even with tinnitus :)I once got a 10 seconds full temporary relief using the Wim Hof Method (probably due to lack of oxygen in the brain at that point, lol). That was a mystical experience. It was really tough to replicate as I had to not breathe for at least 2.5 minutes and I was doing this with doctors (for a WHM experiment conducted by the Radboud University) and I was almost at the point of passing out. I consider these 10 seconds as a gift, I never chased it. reply poiop 3 hours agoprevThe reality is that the Internet is often useless for this sort of thing. I, like many others, got back problems during the pandemic. In my case science will mostly tell you to do nothing, health care will give you physical therapy, the Internet is full of instant relief stretches, short workout programs and psychological solutions (\"don&#x27;t care\" which plays into \"do nothing\" like science suggests).I managed to rehabilitate myself mostly by walking for hundreds of hours. That isn&#x27;t really some trick or secret. That is what health care would eventually tell you to do. It just isn&#x27;t reflected as much as the easy and the qualified solutions. Now I got tinnitus a few weeks back and it&#x27;s the same landscape on the Internet. But getting the information isn&#x27;t really the problem, it is making use of it. It&#x27;s easy to find a high level of engagement and it&#x27;s easy to find a high level of knowledge. The challenge is finding both.I have always been somewhat sensitive to noise, but a lot of people aren&#x27;t. They have whining fridges, squeaking doors or noise pollution all over the place. They don&#x27;t really care. You are dismissing symptom reduction a bit. But as far I can tell that is the solution for most. A combination of stress reduction, lifestyle reform and behavioural therapy, potentially with a hearing aid or noise masking. And then it gets manageable enough that they don&#x27;t care. Maybe you can do that yourself, but possibly you can&#x27;t and will conclude that it doesn&#x27;t work.Of course like I said you shouldn&#x27;t trust me. I&#x27;m going to go find whatever specialist health care can give me without paying too much extra. reply milesvp 15 minutes agoprevThere are some drugs with known tinnitus side effects, you may want to look at meds you’re taking. A friend had good luck cutting out one of the otc pain relievers he was taking and having tinnitus symptoms go away reply jFriedensreich 5 hours agoprevI got mine under control, though there is still a bit left that probably wont go away, but is totally ok for me. Got rid of my 2 main stress sources, changed to a much more healthy diet, drinking more regularly and if there is a new tinnitus attack (i still do not know the propper english word, in german its hörsturz) i do breathing and ear massaging for half a minute. Not just massaging the outer ear but also gently pumping with air pressure similar to adjusting after a flight. I noticed time is super critical here. Just before the tinnitus starts there is 1 or 2 seconds where you feel the hearing disappears its as if the volume is turned down. If the massaging and deep breathing starts in this moment before the tinnitius beeping and noise sets in, it seems to always go away completely after. reply quietpain 4 hours agoparentnext [–]i still do not know the propper english word, in german its hörsturzIn several forums I&#x27;ve seen them talk about \"spikes\" reply Tor3 3 hours agoprevI&#x27;ve had tinnitus since I was around 20 years old, got it on new year&#x27;s eve when some fireworks exploded very close to my left ear. Was deaf for two days and got an 8kHz tinnitus in that ear, permanently, after those two days. It&#x27;s not very loud, but I always hear it unless it&#x27;s noisy. I&#x27;ve had it for many decades by now.However - I&#x27;m lucky in that I&#x27;m not really bothered by it anymore. In fact I didn&#x27;t notice it now until I saw the HN headline and thought \"tinnitus\". And now I hear it. It&#x27;s not very loud, as I said, but still loud enough to hear it over the traffic noise outside. And still, somehow, I forget about it a lot of the time. A guy at work is so disturbed by his tinnitus that he sometimes have to take the rest of the day off. I&#x27;m lucky I guess. I don&#x27;t know if there&#x27;s any mental method which can help with this.Edit: I remember now that when I still traveled at lot at work the tinnitus would get worse after long noisy flights, and last for a while (up to a month) after that. I started using good noise-cancelling headphones and that definitely helped. As someone else said, protect you ears. It&#x27;s even more important if you already have some hearing issues, I believe. reply Loranubi 9 hours agoprevMy tinnitus was caused by flying long distance while having a ear infection. The first year was horrible, but after that it got a better every year and about 5 years later it&#x27;s basically gone. I can only hear it now when I am in a very quiet environment or (this is the simplest way to revive it) bite down hard on my teeth. I think my brain has adjusted to the sound by masking it.Most doctor visits were quite disappointing since they didn&#x27;t do anything. I heard from many people that early therapy can help a lot (like oxygen therapy) but my doctor only tried some of these things after I repeatedly asked for it. But by that time it was already too late (like 3-4 weeks later).What helped me was: - distraction - constant white noise in the background - avoiding any source of loud sounds&#x2F;music&#x2F;etc (I am very sensitive on that now) - relaxing my jaw muscles - distraction - going to the doctor at the earliest sign of possible ear infections to stop infections from spreading to the inner ear. reply LVB 53 minutes agoparentI’m glad to hear of your eventual improvement to a sudden onset case. I’m about 2 months into some likely barotrauma following a random swimming incident. (Innocent stuff… just diving into a deep pool at a rec center, I felt pressure as I went pretty deep, and thereafter my right ear has been stuck very ringy.) I’m still in the queue to see an ENT due to their 3 month backlog, but an audiologist confirmed some severe (near total) hearing loss in my right ear above 6khz. reply patorjk 23 minutes agoprevI&#x27;ve had tinnitus for around 15 years now. I&#x27;ve followed the research pretty closely. One thing to be especially weary about is the placebo effect. For some reason it&#x27;s especially bad when it comes to tinnitus. I think that&#x27;s how so many snake oil products can thrive in this area.Back when they were doing the OTO-313 study a year or so ago, I read several reports from people who were in the study the drug had made their tinnitus go away (one on the TinniusTalk forums, and a few in a tinnitus Facebook group). However, when the results came back, the drug did not beat placebo. A similar thing happened with the FX-322 drug (that one was for hearing restoration but people were hopeful it could address tinnitus too). reply tikkun 12 hours agoprevYes, mine is not solved in theory but is solved in practice. The ringing is still there if I listen for it, but it’s effectively unnoticeable and I’m now unbothered by it.The solution that worked for my was basically “acceptance and commitment therapy” - I think I learned it from a book written by a Dr Russell or something like that.Would recommend, am very glad I did it. It seems kind of kooky though, it’s almost like you pretend the tinnitus is a part of you and you have a conversation with it and welcome it and all that kinda stuff over time, and then eventually it just kinda stops being bothersome. Doesn’t really make sense, but worked well. reply tekkk 9 hours agoparentI think this is the only way as of moment. Just desensitize yourself to the sound until there&#x27;s no effect on you.One thing I tried as I was still anxious about the matter that I had damaged my hearing permanently, was sitting in a pressurized chamber with a lot of oxygen. Ridiculously expensive and did basically nothing. Possibly if you go immediately after it happens it might help but I&#x27;m doubtful of its benefits (the company was making a buck though as single-person business).I just remember this lady who had hit a garbage can&#x27;s lid too hard which had made her ears ring. How unlucky. She was quite stressed about it as well. reply iamthemonster 10 hours agoparentprevDr Russ Harris: https:&#x2F;&#x2F;www.actmindfully.com.au&#x2F;free-stuff&#x2F;It&#x27;s not too kooky nowadays, it&#x27;s a relatively widely practiced approach used by clinical psychologists. reply CapsAdmin 5 hours agoparentprevI&#x27;ve had it for as long as I can remember soI don&#x27;t know what life is without.I&#x27;ve had some curiousity from time to time, but that&#x27;s the extent of it.I truly believe acceptance is the best cure when no cure exists in this case, but it&#x27;s also the most difficult method in all aspects of life. reply ehnto 5 hours agorootparentI know stress is an aggrevator of tinnitus for me, clenched jaw and tight neck muscles etc.So in a practical sense, worrying about it literally made it worse by triggering those stress reactions which worsened the tinnitus.It&#x27;s that mechanism that acceptance helps me with.I am not always accepting, but if I can calm myself down and just deal with it, it lessens drastically. reply prokopton 4 hours agorootparentprevI’ve had it since I was a kid too. Only notice it in small closed rooms. If I’m outside I don’t hear it. reply nzoschke 2 hours agoprevNot complete or permanent but it’s mellowing out over time to where I almost never hear it during the day, and it’s no bother at a quiet night, and easily masked by a fan or a podcast.The main things for me were- take a major break from djing and clubs. I was playing out a lot - get great earplugs. I have westone custom molds - talk to friends about itIn talking about it I have been absolutely shocked to learn how pervasive hearing problems are.Lots of friends have some form of tinnitus and some have shared major problems like major tinnitus from playing drums a long time or loss of sound in one ear from rocket explosions in the military. All was a complete surprise, I just assumed everyone’s hearing was great.This greatly helped with my initial depression which presumably was causing me to focus on the sounds more rather to accept and ignore it.Health problems are coming for all of us. Take great joy out of whatever health you do have, try to reduce harm from unhealthy habits, but have fun too. reply spacebanana7 2 hours agoparent> get great earplugs. I have westone custom moldsI recommend using ear defenders whenever possible in louder environments. They&#x27;re much more powerful than earplugs and much cheaper. A 30 decibel reduction for $30 is quite realistic. reply squeaky-clean 1 hour agorootparentHearos are about $5, re-usable and offer a 30db model. That&#x27;s about the maximum you can go before you&#x27;re contending with the vibrations affecting your skull affecting your inner ear being louder than what&#x27;s coming through the ear canal. reply thfuran 2 hours agorootparentprevYou can get 30 dB out of earplugs too. reply SunlightEdge 4 hours agoprevI think I&#x27;m an odd case, in that I did have \"tinnitus\" (a constant high pitched buzz in my right ear), along with a constant tension headache that resulted in me not getting any sleep. I was prescribed sleeping pills and then a visit to the neurologist said all my conditions were caused by anxiety. I actually didn&#x27;t think I was anxious (I think it was the result of a bad night on cocaine). Err... Anyway, a large career break with lots of relaxation gave me relief from both my daily headaches and tennitus. I was doing lots of exercise and also drinking a lot of water mixed with corriander (I was convinced this would help to detox me for some reason). The tennitus went away after about 2 months and it took about a year to get away from the constant headaches. I haven&#x27;t done class A drugs since... Probably not at all helpful, but I thought I&#x27;d share. reply harryvederci 6 hours agoprevI&#x27;m not saying this will work for everyone, but I just lie to myself.I know this isn&#x27;t true, but I&#x27;ve told myself that having tinnitus is a normal thing, that everyone has.The \"fact\" that it&#x27;s normal and that everyone has it has removed the suffering for me.Weird, but maybe it will help someone here.\"Pain is inevitable, suffering is optional.\" reply darksim905 1 hour agoparentIt&#x27;s not normal though, and not everyone has it. I&#x27;m surprised there hasn&#x27;t been a documentary on tinnitus like there is on the fear and scams around beef products being poison, the real estate market, mortgage backed securities, etc. It&#x27;s a silent killer. Many people in this thread have eluded to suicide as a result of their ringing. that&#x27;s up there with depression. reply saalweachter 2 hours agoparentprevHonestly it&#x27;s not much of a lie. Something like 20% of the population in the US has some degree of tinnitus. reply DontchaKnowit 1 hour agoprevI&#x27;ve never heard anyone else say this but : I have had significant tinnitus for my entire life. As early as I can remember, I always had ringing in my ears. I think I was born with it.Anyone else? I&#x27;ve only ever heard of people acquiring it over the course of their lives, but I know I was born with it.It doesn&#x27;t really bother me, since its been normal for me since before I was even forming memories. reply brandonmenc 23 minutes agoparentYep. Since I was a child, as long as I can remember.I just thought everyone heard that high pitch TV tube sound all the time.When cartoons would show \"ringing in the ears\" with a bell, I thought that&#x27;s what they meant - that you heard an actual bell sound. I never knew that I was hearing \"ringing\" all the time.I used to play in bands and listen to live music a lot, so I got my hearing tested a few years ago. I have no damage at all. Surprisingly, I have better hearing for my age in some frequencies.The theory I subscribe to is that it&#x27;s structural - like, a blood vessel that&#x27;s just really close to I dunno, something in my ear that is constantly stimulating some sound sensing nerve or whatever.It&#x27;s been constant, kind of annoying, but not worsening. I&#x27;d go nuts if put into a silent room. Fortunately, the world is not completely silent. But I prefer to sleep with white noise or a fan. Sometimes it just fades into the background, but if I think about it (like I am right now) it&#x27;s really noticeable.I don&#x27;t consider it a problem, but it would be nice to get rid of it. reply cableshaft 1 hour agoparentprevI think it&#x27;s probably more common than people think, it&#x27;s just quiet enough for a long time that most people don&#x27;t notice it unless they&#x27;re trying hard enough to notice it.I suspect that&#x27;s what happened to me at least. I think I actually did have it earlier in retrospect, it was just so quiet it was easy to ignore.For the past four years though? Not so much. I can train my brain to ignore it still, but I need to be pretty focused on other things and&#x2F;or cover it up a bit with ocean noises or be in a room with ambient noises or something. In a quiet room and I&#x27;m not really focused on something else, though, it&#x27;s quite obvious and can get kind of loud at times. reply chrislund 1 hour agoparentprevSame. Bums me out as I&#x27;ve always protected my hearing, too. I can&#x27;t say I was born with it, but I certainly remember having it as early as maybe elementary school. I sometimes wonder—admittedly as a medical layperson—if an ototoxic medicine is to blame. reply c16 4 hours agoprevI also have what I&#x27;d now say is quiet tinnitus, when I used to party a lot it was pretty bad. I won&#x27;t notice it during the day and I don&#x27;t really notice it at night, however that wasn&#x27;t the case a year or two ago.Things I&#x27;ve done to try prevent it getting worse:* iOS has a limit volume option - that&#x27;s on permanently.* I use a speaker on soft volume in the room when wfh rather than headphones when listening to music.* I have ear plugs on my keys for when I end up going out to music events and festivals (I use Alpine, partner uses Loop). This made a huge difference and I&#x27;ll go to bed without ringing ears.* I try have days where I don&#x27;t listen to music. At first it was weird, now I&#x27;m quite used to it.* Online meetings, keep the volume low where possible. reply WildGreenLeave 4 hours agoparentI&#x27;ve been having tinnitus for at least 5 years now, closer to 10. I&#x27;m late 20s so my assumption at first was always that it was because of partying, but I realised that I almost never partied without earplugs because I got it already before I was old enough to go to clubs. So I don&#x27;t think it is related to loud noise, however, I match most of the things that you say.1. I always set my volume to the lowest setting possible. I do not trust what Apple says about the &#x27;safe&#x27; volume because it still is quite hard. And I am using it with Airpods so I think it should be right, but I still put it lower.2. At home I always use speakers and almost never headphones, for that exact reason.3. I always carry earplugs for loud music. (funny story: I went to a bar a few weeks back in Korea and everyone in the group (koreans) asked me at some point if I had some medical condition with my ears since I was wearing earplugs. It just is not used at all there).4. I try to do meetings with my speakers instead of my airpods, does not always work of course.5. I often go to sleep with some noise, be it TV, Youtube or Spotify. reply vjaswal 3 hours agoprevI can&#x27;t help with tinnitus itself, but I highly recommend \"Eargasm High-fidelity Ear plugs\", or similar devices, to help prevent further damage.They work really well to dampen loud sounds and, importantly, they let conversation through, though it sounds muffled. But you can feel the difference. They are much better than using foam ear plugs, which muffle everything.I used to go to a lot of concerts without any ear protection, when I was young and dumb. I REALLY wish I had these things back then, since I&#x27;ve acquired mild tinnitus as a result.Now I carry them on my keychain all the time and use them even in restaurants and bars or whenever I&#x27;m some place where I have to speak at an elevated level. reply nzoschke 2 hours agoparentAmen to always having good ear plugs.I tried many including the Eargasms and never found a comfortable fit. So I got molds and custom ear plugs from Westone.They are so comfortable and high quality they often improve the quality of the music at a concert.My only regret is not getting great ear plugs sooner, as I recently developed mild tinnitus from DJing and going to lots of clubs and concerts.The good news is that with the ear plugs I have returned to all my previous behaviors and the tinnitus is not getting any worse and actually mellowing out. reply netRebel 3 hours agoprevMy tinnitus is only 2 weeks old, and I went into overdrive finding a cure or a solution, because I read that speed is the primary differentiator for success or not. I tried a lot of stuff and some helped a bit, but: I actually just came back from physical therapy where my jaw muscles get massaged inside and out. There was an immediate tinnitus relief, like 80%. Look up TMD (Temporomandibular joint dysfunction). Ibuprofen helped, too. reply throwaway161718 2 hours agoprevI found out about my Tinnitus the most embarrassing way - my wife and we were admiring the relative quietness of the place we were living in, until I freaking blurted out - \"but for vibrations of the universe\"...... Ever since, it becomes worse, when I read a posting on HN about the subject and it slowly fades away into the background of tolerability. I now view the vibrations as Universe&#x27;s gift to me :) reply baby 1 hour agoprevNot tinitus per se, but I’ll write my experience here because it helped a friend who ran in the same thing, and it might be more common than people think.I took a plane while sick, sinus were kinda jammed, ended up hurting like hell when the plane started landing. Next thing I know, I had a new condition: my hear would sometimes start a beat which I believed to be my heartbeat. It was extremely loud and would drive me insane. It would start at random times and stop at random times. It made me feel helpless and desperate a number of times.One day I decided: fuck it. Just accept it. Just embrace it. And from that point on it bothered me much much less. Fast forward a year and a half I think, and I realized that I hadn’t heard that drumming for a while. I guess time cured it.I also realized that my ears can easily get jammed so I ask for an ear cleaning from times to times (kaiser give it to you if you ask that during checkup).Once in Thailand I woke up with swimmer ear, and freaked the fuck out because I had a flight a few hours in the future. I resolved to not get on that plane if I couldn’t resolve the issue, so I ran to the nearest island clinic and got my ears unstuck. Everything was fine after!Never fly if your sinuses or ears are jammed! reply ddmf 6 hours agoprevMy tinnitus is there pretty much all of the time, and then for an hour or so it will disappear.Over the last year or so I&#x27;ve developed really bad hyperacusis, this coupled with misophonia had made me severely suicidal, I even contacted the local mental health services and autism charities.I&#x27;ve reduced that by wearing coloured lenses, I had been diagnosed with irlen but I see it as a little bit woo, however the coloured lenses have really worked.My theory - I have a sensory fuck-it-bucket - I&#x27;m bombarded by all this crap every day, and if it overflows I&#x27;m under real stress, by reducing overload from other senses my bucket fills much slower, and the sound and tinnitus doesn&#x27;t seem to affect me so much.Strange to think that a £16 pair of cheap glasses has saved me. reply lazy_moderator1 5 hours agoparentwhere did you get the glasses from? reply stuaxo 3 hours agoprevI&#x27;ve got some by completing the advice of a tinnitus awareness group I went to on the NHS.Basically acknowledging it as part of the background noise let me stop concentrating on it as much.On the other side I worked out what makes it worse - lack of sleep being one, if I stay up too many days watching Netflix then I&#x27;ll get bad tinnitus, same for hangovers.It&#x27;s meant to be linked to inflammation so being more healthy, getting more sleep and putting yourself under less stress all help.It&#x27;s hard though - rn I have terrible tinnitus, and of course any reminder of it can bring it back, it&#x27;ll fade until I scroll past this article again. reply c7DJTLrn 9 hours agoprevI&#x27;ll use this thread as an opportunity to say this: if you ever have sudden hearing loss in one or both ears, seek immediate medical attention. Demand a proper consultation and don&#x27;t take \"give it a few weeks\" as an answer from a GP.Sudden hearing loss can be reversed with prompt steroid injections but if it&#x27;s left then it will become permanent. My mother woke up one day with no hearing in one ear. Unfortunately, by the time she got a proper diagnosis it was too late to do anything about it. Since then she&#x27;s had tinnitus and vertigo to go with it. reply lnsru 9 hours agoparentThat’s a real thing. Sadly science is clueless about this and doctors even more. Specialized clinics threat sudden hearing loss with intravenous injection cocktails containing steroids and sedatives over the course of few weeks with mixed results. On other hand the cause is not well understood and probably universal treatment does not fit all cases. reply sinuhe69 5 hours agoparentprevSo far I can see, sudden loss of any sense (gettin hearing, smell, sight) is always a cause for concern. I will request my doctor to do a deep investigation. reply tbragin 33 minutes agoprevA couple of years ago, I started having headaches and debilitating tinnitus, and it went on for months. I was tested by audiologist - my hearing was normal. It turned out that (unbeknown to me) I became extremely anemic due to another health issue. Once I got diagnosed, and anemia was addressed, headaches and tinnitus went away. reply haltist 23 minutes agoprevIt is possible by reducing neck and jaw tension but there is no permanent solution. Reducing caffeine intake also helps because caffeine is a stimulant and makes muscle tension worse. reply ggambetta 1 hour agoprevI got tinnitus after a fateful night at Ministry of Sound in London. There&#x27;s a sign that says \"CAUTION: excessive sound levels\" and they&#x27;re not joking :(I haven&#x27;t found a permanent cure. Thankfully I&#x27;m not even aware of it most of the time, and it&#x27;s never been an actual issue.I have found a partial, temporary cure - this was discussed on HN a few months ago, and someone linked to a YT video or audio file with some sort of noise patterns (not white noise, more like periodic beeping at different pitches and volumes), and if I listen to that for 10-15 minutes, I can&#x27;t hear the ringing for a while.Maybe I should try doing this more consistently, and see if it goes away permanently. Has anyone had any luck with that? reply wahnfrieden 34 minutes agoparentfor me what helped was learning some meditation techniques, practicing, learning to control my focus &#x2F; observe ideas&#x2F;feelings pass through and away, and then combining that with non-damaging noise at times, trying to avoid harsh high tones (such as by projecting sound at the ceiling and hearing the softened reflection and ambient sound rather). It&#x27;s still good though to learn to adapt to quietness because noise can be stressing in other ways, physically or psychologically. reply 1970-01-01 31 minutes agoprevThe best therapy for living with it is being tough. That means accepting it and moving forward with life. Mute or avoid all loud sound as much as possible or it flares and becomes worse. I simply have no other wisdom on it for you. reply Night_Thastus 22 minutes agoparentWhat an AH take.I&#x27;ve lived with it for my whole life, and I&#x27;ve accepted that it likely won&#x27;t be fixed.But if you&#x27;ve had it, you know it can also be HELL at times. Trying to sleep while hearing loud, incessant ringing can be impossible. Being unable to pay attention to a conversation or movie because it&#x27;s so loud. Never hearing true silence when you just want to decompress. Fear that it will get worse or you&#x27;ll lose hearing completely.Sometimes it&#x27;s not bad. Other times it feels like water torture. It&#x27;s technically harmless but the sensation can make it difficult to even stay sane. reply 1970-01-01 11 minutes agorootparentAs an asshole with it, I assure you my take is still correct. :) reply DavidPiper 2 hours agoprevI have tinnitus in my left ear, caused by Meniere&#x27;s Disease. It&#x27;s fairly quiet most of the time, really only a single note (more like a squeal), and I only really notice it at night when it&#x27;s quiet. It&#x27;s been permanently ringing since October 25, 2019. I&#x27;ve been unable to hear silence since then (I&#x27;m 30).Except for a single night: November 12, 2022. For about 8 hours I had no tinnitus. (Sadly, it came back the next morning.)The only unusual thing about that day was that I&#x27;d had an MRI (Brain and Cervical Spine, with contrast) for unrelated (and thankfully pointless) reasons. But somehow it fixed my tinnitus for a few hours??Back in 2019 I had a Meniere&#x27;s Protocol MRI and CT Scan to diagnose my Meniere&#x27;s Disease. Gadolinium contrast. No effect on my tinnitus.After a bit of reading I came across rTMS as a possible mechanism for temporary relief of tinnitus - https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC3563643&#x2F; - which the MRI that day would have induced. (Can&#x27;t explain why the previous one had no effect, but the paper suggests that the literal motion and direction of the magnetic resonance matters).A Uni nearby where I lived was even doing clinical trials. But I was dealing with another health issue at the time, and life got busy, and I&#x27;ve since moved interstate. I have no idea how it works or if it&#x27;s just some incredible coincidence. But one day soon I&#x27;ll go exploring down the rTMS path and see if I can consistently get tinnitus relief.Like others in the thread, I&#x27;ve heard of plenty of other snake oil things. And my tinnitus is really not bad enough that I need to consider anything right now. But if tinnitus relief is a real thing one day, my money is currently on rTMS. Just far too big a coincidence for me to ignore. reply RelativeDelta 11 hours agoprevIt&#x27;s impossible to cure.The &#x27;ringing&#x27; sound people hear isn&#x27;t actually a sound. It is how the brain processes signals produced by damaged Stereocilia.If the &#x27;ringing&#x27; is constant it means the cilia are permanently damaged. While it would, in theory, be possible to use surgery on the ear and some sort of lazer to completely remove all damaged cilia to avoid them outputting a damaged signal, this procedure would be incredibly invasive and risky. I don&#x27;t believe it&#x27;s ever been done and i would find it hard to believe any Otolaryngologist willing to try. reply dataflow 10 hours agoparent> The &#x27;ringing&#x27; sound people hear isn&#x27;t actually a sound.Sometimes it is, apparently?\"If you have pulsatile tinnitus, your doctor may be able to hear your tinnitus when he or she does an examination (objective tinnitus).\"https:&#x2F;&#x2F;www.mayoclinic.org&#x2F;diseases-conditions&#x2F;tinnitus&#x2F;symp... reply jaggederest 6 hours agorootparentI&#x27;m not a doctor but I have good hearing, and heard a friend&#x27;s tinnitus. Apparently they had a constant muscle spasm that was causing a \"buzzing\" sound, and if you listened carefully, you could hear it. They eventually got it botoxed and that fixed it (injections 2-3 times a year I think, ongoing). reply deadbolt 10 hours agoparentprevThere&#x27;s a trick which I can&#x27;t recall the name of, which involves thumping your fingers across the back of your neck, which temporarily resolves tinnitus in some people. I have very mild tinnitus, and have noticed that that does quiet it.This is a question for everyone I suppose, but does anyone know why that works? Could it be possible to develop an implant or something which generates the same effect? reply stuxnet79 9 hours agorootparentYour tinnitus is likely being caused by tight sternocleidomastoid muscles (SCM). I would look into stretches to resolve that. reply wruza 5 hours agorootparentI thought that works because it creates a complex of sensations that overload your audio “tract”. For example if I do the described trick without isolating&#x2F;covering my my ears with palms, it does nothing. The difference is not in pressure, but in the fact whether I can&#x2F;can’t deep-hear the punches that my fingers create. Not a doctor, but something tells me there’s more to that. All scans shown that I have zig-zagged vessels in my neck, but within what they see as a “norm”. reply deadbolt 9 hours agorootparentprevI will absolutely be looking into those! Thank you! reply rewgs 10 hours agorootparentprevIt works for people that have tinnitus due to tight neck muscles. Tinnitus due to damaged ears is a whole different beast. reply deadbolt 9 hours agorootparentI went to a lot of loud concerts when I was younger and just assumed that I had tinnitus from those, and until now, I had no idea there were multiple causes of tinnitus.I had assumed this was incurable but if my tinnitus is from tight neck muscles, that seems fixable. I&#x27;m going to reach out to my doctor about this. Thank you, I think you might have just greatly improved my life. reply criddell 4 hours agorootparentprevWhen you twist your head around, do you hear a grinding noise? For me, it’s almost like a cardboard box being dragged across a sandy floor. It is a real noise because I’ve been able to record it with my phone.I also have tinnitus. I wonder if it’s all related? reply k4runa 9 hours agorootparentprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2yDCox-qKbk reply shiroiuma 9 hours agoparentprev>While it would, in theory, be possible to use surgery on the ear and some sort of lazer to completely remove all damaged cilia to avoid them outputting a damaged signal, this procedure would be incredibly invasive and risky.It sounds like what we need is nanobots to do this surgery. reply throwaw1yyy 5 hours agoprevYeah! But I’m gonna say I’m really odd, it’s a lot of vibes and unless I convince a doctor of a case study, I’d never be believed.I have&#x2F;had Tinnitus (it’s nowhere near as bad as it was 7&#x2F;10 to it’s current 1&#x2F;10). It’s been gone 7-8 years now.1. I listen to music much quieter, and let my ears adjust.2. This is the weird part. I would get itchy all the time, random pin pricks I’d feel often. I read about monks who meditated so long they could turn off their hearts. So I sat in bed for 3 months (before going to sleep) and tried really hard to look at where I felt an itch and see it was my body was wrong. There was no reason to give me a cue to itch. Nothing was happening.I can easily ‘feel’ the pin pricks if I desire but don’t anymore. It’s like a weird mental trick. I can also feel mosquitos and really anything touch me and no longer get false cues.Anyhow I suffered from tinnitus and did the normal suggested stuff but it didn’t work. So I remembered the time I got rid of my itching and tried to replicate what I did.I sat and listened to ‘true noise’ and untrue ‘noise’ and it wasn’t instant relief but over 2-3 weeks it went to level it’s at now. I only notice it if I desire. It’s louder an extremely quiet environment but I swear it’s almost like I can hear my blood pump.Listen to really low noise. Quieter than whispers. Then up and up. Train your ear to understand sound and not sound. Then go back down again. Sadly the truest quiet will cost you (some place remote with no bugs or wind) but I did it fine at home because I could remember before I had tinnitus. Earplugs I think don’t work because you hear your blood pump.Anyway I’m sorry you’re suffering and I know what I wrote sounds really dumb&#x2F;unbelievable but I do pretty good on prediction markets… ;) it might work for you. Very weird - no proof in the literature but it worked me.-(I did the itch cue training around 12 or 13, tinnitus around 22) -(I didn’t use any drugs) reply westcort 45 minutes agoprevReading these comments has made me feel very lucky not to have tinnitus. However, as a pharmacist, I have consulted with many people asking about supplements and treatments for tinnitus. One treatment that has worked for some people is lipoflavanoid. A less expensive alternative, available as by prescription only, is gabapentin. reply k4runa 9 hours agoprevI had tinnitus for a while, and tried a few things that didn&#x27;t work but this thomping technique I found on reddit one day stops it, and I just do it every couple of days and it disappears for a while. Not permanent but whenever it bothers me now I just do this thumping and it disappears in a few seconds:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2yDCox-qKbk reply actinium226 6 hours agoparentWeird. I tried it and didn&#x27;t get much effect, but it&#x27;s interesting to see so many positive comments on it. I&#x27;ll try it some more over the next couple days. reply Narretz 4 hours agorootparentI think that&#x27;s because tinnitus comes in very different forms and intensity, and since it can&#x27;t be objectively measured, it&#x27;s difficult to compare between individuals. My guess ist that you can only silence very low intensity tinnitus with this technique. reply tinnitus93 5 hours agorootparentprevTry a constant pressure massage instead of the thumping. Pressure should be high enough that the sensation is intense but not painful. The goal is to get muscles around the base of your skull to relax. I was amazed at how quickly it had an effect reply oblib 11 hours agoprevI&#x27;ve been dealing with tinnitus for about a year now. The only thing I&#x27;ve found that helps is Ginko Biloba. I&#x27;m buying that at a \"Dollar General\" store so the source is iffy and so is the effectiveness, but it certainly does help.My wife has a friend who told her just a few days ago that her husband has had some success toning his done by chewing Bay leaves. I&#x27;ve not tried that yet, but I will soon.From what I&#x27;ve read there is still no \"cure\". But those two things may contain a clue that&#x27;s worth looking for. reply ysavir 1 hour agoprev> If you can&#x27;t tell, I&#x27;m trying to establish an \"existence proof\" here, if no one has ever gotten permanent relief then it seems like it might not be worth bothering with the \"symptom reduction\" therapies since they would most likely lead to focusing on the symptoms more intensely.There are many possible causes for tinnitus, and looking for a singular solution to solve it all may be a fruitless errand. Even if someone found one, it may not correspond to your root causes.I&#x27;ve noticed my own tinnitus seems tied up with muscle strain in my neck and shoulders. A frequent trigger is when I turn my head very quickly--a sudden bout of ringing starts in the corresponding ear. I&#x27;ve also seen my tinnitus wind down when I take the time to stretch those muscles, get massages, get acupuncture, etc. The solution here requires upkeep, not a singular, one-time expense. At least in my case. reply schmidp 1 hour agoprevI had tinnitus when I was about 20 for multiple months after dancing in front of the loudspeakers of a club.They gave me a TEBOFORTAN, as well as cortisone infusions over several weeks.It was bad enough that I could not concentrate on learning for university. I heard before that psychology plays a big role, so I was trying my best to just ignore it and do something else than studying.It completely went away. I can hear a very small ringing if I concentrate on it and its completely silent, but I had this for as long as I can remember (definitely when I was 4 years old) and I wouldn&#x27;t call it tinnitus. reply digitalsushi 2 hours agoprevI think mine might correspond with my blood pressure. It normally comes in with my morning coffee, or when I am being very stressed out by work. If I am ruminating while trying to sleep it will be fantastic levels, piercing.I&#x27;m a slave to white noise, and during power outages will wake from a dead slumber to listen to the needle threading between my ears. reply rapjr9 6 hours agoprevAspirin can cause tinnitus, so stopping it, especially if you take a lot or regularly, can make tinnitus disappear. There are a variety of other drugs that can also cause it:https:&#x2F;&#x2F;www.healthline.com&#x2F;health&#x2F;medications-that-cause-tin...https:&#x2F;&#x2F;www.webmd.com&#x2F;migraines-headaches&#x2F;features&#x2F;aspirin-a... reply fexed 8 hours agoprevI&#x27;ve had it since I can remember. One of my earliest memories, I was 1 or 2 years old, was \"playing\" with it while falling asleep at night: I&#x27;d focus on it and made the ringing grow louder and louder till it was the only sound in my ears, then it steadily grew quiter till I fell asleep. Nowadays, I&#x27;m 27 years old, my brain filters it out, but I can still hear it when it&#x27;s quite. Perhaps it&#x27;s one of the reasons I always have some background lofi music playing. reply FLT8 5 hours agoparentAlso had it as long as I remember, at least since I was about 7 or so, which makes me think it&#x27;s not related to high level noise exposure. I know that because I have clear memories of asking other kids whether in times of silence they could hear anything. It surprised me that they couldn&#x27;t.My tinnitus is a kind of hissing, predominantly at a very high pitch. I&#x27;m in my mid 40&#x27;s so grew up around CRT TVs. I think it&#x27;s about the 15kHz horizontal refresh frequency, which makes me wonder whether my brain was trained at a young age to expect CRT TV sounds to be around and now it&#x27;s just a permanent artefact, like a noise cancellation circuit that&#x27;s gone wrong.I find it gets worse if I&#x27;m run down, or eg. If I drink too much alcohol, or if I wear headphones for too long.If I think about it, I can hear it at any time, but generally it&#x27;s not too bad. I know it&#x27;s not very helpful, but acceptance of it and shifting focus to other things definitely helps me, to the point that it usually fades away and is generally not noticeable at all. reply deergomoo 3 hours agorootparentHuh. I’ve also had it for as long as I can remember, and now you mention it mine is also almost identical in pitch and sound to CRT whine. I’m only 30, but I didn’t get my first LCD TV until I was a teenager.My hearing in general is fine, although I have always struggled a little with understanding people unless they’re facing me. I can hear them just fine, I just can’t always parse what they’re saying. Maybe related, maybe not.I should be thankful at least because mine never bothers me. Like GP I thought this was something everyone experienced. reply tinyshi 1 hour agoprevI have about 18 years of experience with tinnitus. I remember when it started, initially with frantic ear cleaning, MRIs, classical music.Later I tried everything, I have come to the conclusion that you learn to live with it. It means it&#x27;s not going anywhere. I was in my twenties at the time.I think if you can&#x27;t get rid of it, you have to make a friend of it.Worst case scenario, something like loud banging your finger behind your ear to tap it helps. Noise also helps. For me, head position changes it, as does contracting the muscles in the neck and neck. Poor sleep, hypertension.https:&#x2F;&#x2F;generalfuzz.net&#x2F;acrn&#x2F; you can try this (found here sometime long ago).Stay strong, look for direction, not a solution. reply 10ego 55 minutes agoprevShould be an automatic disclaimer for these but my experience my not be the same as others. My tinnitus still happens, typically triggered the next day after being exposed to a very loud setting, like going to a concert for example. One day in judo class, I had an instructor come in who finished the session with some yoga (it was atypical but I actually liked it, stretching out my joints and muscles after being so tense). I felt a pop, not like cracking a bone but something lighter feeling. No more tinnitus. It still comes and goes with the triggers but they&#x27;re less intense and usually goes away after a good walk and a light stretch. reply oooyay 1 hour agoprevNo, but you get used to it. If it&#x27;s really quiet and I focus on it I can hear the 1KHz tone in my right ear. The last checkup I had indicated I didn&#x27;t have hearing loss, but frankly I struggle in some of those tests. Sometimes I find myself inadvertently angling my ear in a way that I can hear people better.Other times something in my body seems to make the tinnitus flare up and then I can&#x27;t hear anything but the ringing for a few seconds. This doesn&#x27;t happen all that often and I&#x27;m more conscious of wearing ear protection these days. reply heavyset_go 6 hours agoprevAt least for me, ignoring it seems to work as well as ignoring eye floaters seems to. They&#x27;re there, but I can filter them out to the point where I forget that they&#x27;re there.That&#x27;s it. It&#x27;s not permanent, but I can forget it&#x27;s there. reply TillE 1 hour agoparentYeah just gotta accept that your body gradually deteriorates.I know some people have really bad tinnitus, and that&#x27;s different, but typical mild tinnitus is almost completely ignoreable after a while. reply raducu 5 hours agoparentprevAs someone having both tinnitus and eye floaters, this rings (pun intended) so true. reply jerome-jh 3 hours agoprevTinnitus is not a disease, it is a symptom. Do you know the underlying condition? If not this should be your priority. It is not easy to have a clear diagnostic when the only symptom is tinnitus (often associated with hearing loss). Some otorhinolaryngologists are satisfied with the diagnostic of \"sudden hearing loss\", which is catchall for \"I don&#x27;t know\". Don&#x27;t let yourself be fooled by this and search for better doctors.If you are lucky enough to have a diagnostic, then the priority is to treat the disease. This may alleviate the hearing loss and sometimes the tinnitus. In some cases tinnitus may completely disappear (for example in the case of a viral infection affecting the auditory nerve). But often tinnitus remains and you have to live with it. Anyway having a diagnostic is in itself a relief.If you do not have a diagnostic, I guess you have to learn to live with it. It may be more difficult in this case. After all it is not the end of the world. Many things are worse than this. It can be hard to sleep at times. Doing sport improves sleep. It can be hard to hear people during meetings. Sometimes you will have to ask them to repeat. You can seat closer to the main speaker. You can prefer to connect remotely with a good headset.I have a disease of the hear which for sure won&#x27;t improve. In a sense this is a relief because I stopped \"monitoring\" my tinnitus so closely, maybe 7 or 8 years after my diagnostic, and 2 years after my second surgical operation. It does not keep me awake at night. reply az226 4 hours agoprevI got tinnitus after getting covid (which turned into a bad case of long covid that I&#x27;m still battling). It started out as maybe a 2 out of 10. Present. Annoying, but not super disrupting. I could play some youtube videos with a creek of water on the lowest sound setting and I couldn&#x27;t hear it. Then one day a couple of months later it jumped up to a 5 or so. This was disruptive. I had to crank the volume up to about 60% vs 5% before and I had to use a tinnitus flosser matched to my frequency. This was bad. I was losing my mind.I went back to my audiologist and got a hearing aid to reprogram my brain. I did 90 days of light programming and got reduced to maybe a 3.5. After 90 days she cranked the programming up to more intense and I&#x27;m now down to maybe 2.5. Definitely livable. Annoying, present, detectable. But also easy to lose track of it when distracted.I hope it goes away some day. It&#x27;s only in my left ear and a hearing test showed I did have partial hearing loss in my left ear at higher frequencies.One interesting thing in my experience is that just like when you get a new eye glass prescription they ask if A or B is better but here they asked if my tinnitus sounded more like A or B and for every single one I could not answer. It was not like either of them. Not even close. It somehow did not compare.There is a new approach out there and my audiologist has inquired to be part of the next wave (it&#x27;s super early still) and I will try it out if she gets it. It&#x27;s a new technique involving modulation and the tongue. reply culebron21 2 hours agoprevHad it after sickness at the age of 14, it dissappeared itself, but at 32-33 had it because of neck issues. Yoga and neck exercises solved it, as blood vessels became less obstructed.Some diehard yoga exercises like standing on my neck with legs up lead to neck- and head-ache for couple of days accompanied with noteable noise in ears.I have a friend who&#x27;s an osteopath. He points out that if, at wakeup, you have symptoms like feeling of swollen head or cant breathe with nose despite there&#x27;s no snoot, and these symptoms go away in few minutes, it&#x27;s neck issues and obstructed blood vessels and lymph,,which work ok with gravity, but not in horizontal position. reply DavidPiper 2 hours agoparentDo you happen to have a list of the neck exercises you did? I&#x27;ve got a set now and wondering if there could be any relation (unlikely, but you never know). reply lelag 3 hours agoprevI&#x27;ve developed tinnitus in my early 30&#x27;s for no apparent reasons. I don&#x27;t think I ever even abused my ears that much. It just happened... Initially, I found it very annoying but you get desensitized over time. Now, I hear it all the time, but it does not bother me much: I have better things to do that going crazy about something I can&#x27;t much about.I&#x27;ve noticed a few things though: the pitch is always the same but the loudness vary noticeably over time and it seem very linked to my level of stress. If I&#x27;m very relaxed, say peacefully hiking in sunbathed forest on a cool summer day, it can become so faint I can hardly hear it. But most of the time, unfortunately, it&#x27;s pretty loud. When I still cared, I also noticed I could drawn it out with white noise, either natural (ex: a waterfall) or artificial. reply taneliv 3 hours agoprevI had a concussion about ten years ago (lost consciousness and fell on the floor). This gave me amnesia, which lasted for a few hours, and a tinnitus that lasted for about three months. The tinnitus was high pitched and on a specific frequency (don&#x27;t recall any more details). It made it difficult to focus.Based on some Internet search I found that other people were helped by listening to (coloured) noise. I started self medicating by keeping headphones on during the work day, and quite a bit outside work as well. White noise sounded annoying, pink noise sounded soothing, but both masked the tinnitus and helped focus. I mentioned this to my GP, who didn&#x27;t think it would treat it, but also that it would not hurt, either.About three months in, basically a daily dose of six to ten hours of pink noise and the tinnitus was gone. Of course, it might have healed all by itself, and listening to the noise worked only as a temporary relief. reply starstripe 24 minutes agoparentCongrats! Did you listen to the pink noise on headphones or speakers? reply NiloCK 3 hours agoprevI have!... but not through any conscious method or effort. In fact, this post just \"reminded\" me of the fact that I had regular and occasionally severe tinnitus over the course of many years. Mine started in high school and persisted well into adulthood. Possibly rooted in a couple of concussions I suffered in reasonably quick succession, possibly too much time under headphones too loud.Right now, I have to think hard to even recall the sensation, which I take as a pretty strong sign that I haven&#x27;t suffered it for quite some time. Anecdotally, I can say that I haven&#x27;t used headphones to listen to music in probably 15 years, and I&#x27;m gentler in general with the volume knob now than when I was 15-25. Nothing else jumps out as a possible contributor.Hopefully this reminder about the condition&#x27;s existence doesn&#x27;t trigger a relapse. I&#x27;m terribly prone to suggestion. reply qwertox 1 hour agoprevI know that sometimes external factors and certain foods make my tinnitus almost unbearable, where I think that this has risen to a new level which is of great concern. There&#x27;s nothing I can do about it until I kind of forget about it after two or three weeks.Forgetting doesn&#x27;t mean that it isn&#x27;t there, it&#x27;s permanently there, but that I can forget about it for some time, sometimes for hours. reply slyall 2 hours agoprevNot permanent but there is a trick to make it go away for a short time. I read about it recently and it works for me. 1. Place both hands on your ears. Palms tight on the ears and fingers backwards 2. Now tap with your fingers on the back of your neck. It doesn&#x27;t have to be hard. It will sound very hollow. 3. Keep tapping for 30 seconds 4. Stop and remove hands from earsYour ringing should have gone away. For some people it goes away for hours, others just a few minutes. reply techbuttman 2 hours agoparentThis is always posted and it always irritates me for some reason. It isn&#x27;t even worth the effort and it makes me more anxious knowing the tinnitus will return in seconds. It never works longer than that for me.The only relief for me is to accept, ignore it, and do no further damage. Healthier living (lower blood pressure) and time (8 years) seems to has lessened the symptoms. reply phkahler 1 hour agoprevI&#x27;ve had ringing in my ear, but never more than a day or so. I figured I read the comments here to see if there were any interesting anecdotes, and now my ears are both ringing quite badly after just a couple comments and thinking about the condition. Just going to drop this comment and get out! reply spacebanana7 2 hours agoprevOver the past 4 years my tinnitus has gradually gotten better to the point of being almost unnoticeable.I&#x27;m not sure whether it&#x27;s actually gone away in a medical sense or whether I&#x27;m just heavily desensitised at this point.For context, my tinnitus onset coincided with loud music exposure and what I believed to have been eustachian tube dysfunction. I did take some treatment steps like staying away from live music &#x2F; nightclubs and using antihistamines for the eustachian tube dysfunction. reply pgreenwood 2 hours agoprevI&#x27;ve had it since childhood. I just ignore it, and months can go by where I do not notice it. But if someone mentions it then I notice it&#x27;s presence and that it&#x27;s quite loud. So thanks for that :) reply gbalint 5 hours agoprevIn my experience, early intervention can help. I got tinnitus at the age of 30 (from a pressure trauma during scuba diving). I received some kind of dementia medication after 2 weeks, and the tinnitus was gone not long after that (and never reappeared). The doctor funnily said that a side effect is that I&#x27;m gonna feel smarter :) I&#x27;m not sure if it was the medication, or the tinnitus was just temporary anyway, but it was a really loud and unbearable noise for a couple of weeks. reply tomhoward 5 hours agoprevShort answer is no.But I have had complete temporary relief for a few days at a time that coincided with other signs of healing in my body, which hints at what could bring about permanent abatement.I’ve had mild tinnitus since I was about 12-13yrs old (I’m in my 40s now).It’s never been especially debilitating; it doesn’t impair my hearing or diminish quality of life, it’s just always there in the background.Since about the same age I’ve had signs of inflammation in the digestive system&#x2F;respiratory system and other mild&#x2F;moderate symptoms that research suggests are related to microbiome issues - EBV, CMV, etc. at its worst it’s been like chronic fatigue or fibromyalgia, though not always and not these days.I’ve tried a lot of things over the years to try and resolve these issues - diet&#x2F;nutrition, detoxing, cleansing, infrared, occasionally more extreme things I won’t mention here. On a few precious occasions everything seemed to click into place and I just felt a really pleasant, energized feeling through my body, the signs of inflammation went away, my digestion improved and the tinnitus abated and my hearing was completely clear.Every time however, the baseline symptoms, including the the tinnitus, returned within a few days and remain to this day (though probably at a milder level than a few years ago).I don’t have any definitive takeaways from all this, but it suggests to me that if there’s a way to fully resolve chronic inflammation and microbiome issues (which are quite common), it may bring about a complete abatement of tinnitus.(You can Google for CMV tinnitus&#x2F;EBV tinnitus to find research papers and articles&#x2F;discussions on correlations between these conditions). reply tdrgabi 6 hours agoprevI don&#x27;t have tinnitus, so I can&#x27;t verify, but I stumbled a long time ago across this reddit thread https:&#x2F;&#x2F;np.reddit.com&#x2F;r&#x2F;WTF&#x2F;comments&#x2F;3l3uri&#x2F;these_guys_light...The url looks weird, I&#x27;m not talking about the video but the comment this links to.It looks like ... his method makes it stop for 10-15minutes, so it&#x27;s not permanent. reply tinnitus93 5 hours agoparentJust tried this and it did temporarily stop the tone for a moment. Easy to do, instant relief. Simple massage to the muscles near the base of the skull.A physical therapist commented that tight muscles contribute. Hopefully practicing this regularly will prolong the effects. reply az226 4 hours agoprevForgot to mention, one of my coping strategies was pretending \"well I just got home from a concert\" cause you kind of have that temporary ear ringing going to bed after a night out at a concert and \"pretending\" this was no different. It was comforting somehow. reply quietpain 5 hours agoprevI developed T after a series of encounters with benzodiazepines to lessen my nerves when I was coping with burnout. I didn&#x27;t know I had burnout, I didn&#x27;t know what was happening to me, I just wanted it to stop. My tinnitus became unbearable in the weeks after a psychiatrist took me of an benzo and put me on an atypical antipsychotic medication. I always blamed the new medication as the cause of my symptoms (of which T was one) when in reality it was the cessation of the benzo.After 5 years of Tinnitus-hell I was put on yet another benzo and my symptoms were _gone_. It lasted only a number of months, though and when I stopped taking the new benzo ... it all came back.I came to the diagnosis of benzo-dependency myself and found a psychiatrist who agreed to assist in a 6-month withdrawal with a gradual taper. After each step my tinnitus came back a bit for a few days and then dropped again. After a number of iterations it became what is known as \"baseline\", i.e. a background tinnitus I can live with.In recent months I started taking Magnesium supplements in the form of citrates and Taurine. I then found this on reddit: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;tinnitus&#x2F;comments&#x2F;znyuyj&#x2F;partial_su... The top comment by kenzocarj is my current working model for dealing with Tinnitus. I&#x27;d like to try L-Theanine but it&#x27;s illegal in my country - you can buy it in a form that has added glutamine which worsens my T. I&#x27;m now drinking matcha tea as a source of L-Theanine.Hope this helps. reply bigbaguette 4 hours agoparentIf the symptoms go away with benzos, it seems that the source of your tinnitus is some form of generalised anxiety syndrome, with all the niceties that come with it: tension headaches, teeth clenching, TMJ disorder... The burnout stresses were eased thanks to the pills, but once withdrawn came back probably harder which could have then triggered your tinnitus.This is why benzos should never be prescribed without any other therapeutic approach alongside. They just hide the pain under the carpet for a while only to see it come back worse after and the root cause needs to be addressed with other means in the meantime.Good luck with the road back to balance. There&#x27;s no secret remedy and it&#x27;s probably best to take a holistic approach for it and work on your well being from multiple fronts. reply spuz 5 hours agoparentprevWhat affect did magnesium have on your tinnitus? What about the L-Theanine? reply quietpain 5 hours agorootparentThe magnesium had a dampening effect which started gradually after about 2-3 days - I take it daily around noon in a 400 mg dose. It also had a soothing effect on my restless leg syndrome (one of my other benzo-induced symptoms) which eventually disappeared altogether.My Tinnitus is coupled to poor sleep",
    "originSummary": [
      "The author is reaching out for knowledge from individuals who have found permanent respite from tinnitus, a medical condition causing ringing in the ears.",
      "The author shows skepticism towards treatments that merely diminish symptoms and is seeking to find out if complete relief is achievable."
    ],
    "commentSummary": [
      "This summary highlights online conversations around tinnitus, where people share personal experiences and strategies to manage the condition including but not limited to sound therapy and lifestyle adjustments.",
      "The focus is on the essential role of tailored approaches, professional help when required, and the importance of hearing protection.",
      "The discussions illuminate the impact of tinnitus on mental health and introduce emerging treatments, underlining the fact that while there is no broad cure for tinnitus, individual strategies can help manage it."
    ],
    "points": 217,
    "commentCount": 249,
    "retryCount": 0,
    "time": 1697076600
  },
  {
    "id": 37850110,
    "title": "Microsoft SEC 8-K: IRS is seeking an additional tax payment of $29B",
    "originLink": "https://microsoft.gcs-web.com/node/31951/html",
    "originBody": "View: Download DOC Download PDF Download XLS Download XBRL UNITED STATES SECURITIES AND EXCHANGE COMMISSION WASHINGTON, D.C. 20549 FORM 8-K CURRENT REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934 Date of Report (Date of earliest event reported) October 11, 2023 Microsoft CorporationWashington 001-37845 91-1144442 (State or Other Jurisdiction of Incorporation) (Commission File Number) (IRS Employer Identification No.)One Microsoft Way, Redmond, Washington 98052-6399 (425) 882-8080 www.microsoft.com/investor Check the appropriate box below if the Form 8-K filing is intended to simultaneously satisfy the filing obligation of the registrant under any of the following provisions (see General Instruction A.2. below): ☐Written communications pursuant to Rule 425 under the Securities Act (17 CFR 230.425) ☐Soliciting material pursuant to Rule 14a-12 under the Exchange Act (17 CFR 240.14a-12) ☐Pre-commencement communications pursuant to Rule 14d-2(b) under the Exchange Act (17 CFR 240.14d-2(b)) ☐Pre-commencement communications pursuant to Rule 13e-4(c) under the Exchange Act (17 CFR 240.13e-4(c)) Securities registered pursuant to Section 12(b) of the Act:Title of each class Trading Symbol Name of exchange on which registered Common stock, $0.00000625 par value per share MSFT NASDAQ 3.125% Notes due 2028 MSFT NASDAQ 2.625% Notes due 2033 MSFT NASDAQ Indicate by check mark whether the registrant is an emerging growth company as defined in Rule 405 of the Securities Act of 1933 (§230.405 of this chapter) or Rule 12b-2 of the Securities Exchange Act of 1934 (§240.12b-2 of this chapter). Emerging growth company ☐ If an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act. ☐ Item 8.01. Other Information On October 11, 2023, Microsoft Corporation announced the receipt of Notices of Proposed Adjustment (“NOPAs”) from the Internal Revenue Service (the “IRS”) for the tax years 2004 to 2013. The NOPAs were received on September 26, 2023. The primary issues in the NOPAs relate to intercompany transfer pricing. In the NOPAs, the IRS is seeking an additional tax payment of $28.9 billion plus penalties and interest. As of September 30, 2023, we believe our allowances for income tax contingencies are adequate. We disagree with the proposed adjustments and will vigorously contest the NOPAs through the IRS’s administrative appeals office and, if necessary, judicial proceedings. We do not expect a final resolution of these issues in the next 12 months. Based on the information currently available, we do not anticipate a significant increase or decrease to our tax contingencies for these issues within the next 12 months. This Form 8-K contains forward-looking statements, which are any predictions, projections or other statements about future events based on current expectations and assumptions that are subject to risks and uncertainties, which are described in our filings with the Securities and Exchange Commission. Forward-looking statements speak only as of the date they are made. Readers are cautioned not to put undue reliance on forward-looking statements, and Microsoft undertakes no duty to update any forward-looking statement to conform the statement to actual results or changes in the company’s expectations. Item 9.01. Financial Statements and Exhibits (d) Exhibits:99.1 Microsoft on the Issues Blog 104 Cover Page Interactive Data File (embedded within the Inline XBRL document) SIGNATURE Pursuant to the requirements of the Securities Exchange Act of 1934, the registrant has duly caused this report to be signed on its behalf by the undersigned hereunto duly authorized. MICROSOFT CORPORATION(Registrant) Date: October 11, 2023/S/ ALICE L. JOLLAAlice L. JollaCorporate Vice President and Chief Accounting Officer Exhibit 99.1 [BLOG POST] Microsoft on the Issues Blog – An update on our IRS tax audit By Daniel Goff, Corporate Vice President, Worldwide Tax and Customs Today, we’re sharing an update about our ongoing audit with the U.S. Internal Revenue Service (IRS), including background and context for this specific case and what we generally expect next. Background on the IRS audit For nearly a decade, as we have previously disclosed in our financial statements, Microsoft has been working with the IRS to address questions about how we allocated our income and expenses for tax years beginning as far back as 2004. We have changed our corporate structure and practices since the years covered by the audit, and as a result, the issues raised by the IRS are relevant to the past but not to our current practices. The IRS recently sent us a series of Notices of Proposed Adjustment (NOPAs), sharing with us for the first time detailed information and explanations of their views about the issues in question. This marks the end of the audit covering 2004 to 2013, and the beginning of a new process to resolve these decades-old issues. The IRS says Microsoft owes an additional $28.9 billion in tax for 2004 to 2013, plus penalties and interest. The IRS’s proposed adjustments do not represent a final determination. Not reflected in the proposed adjustments are taxes paid by Microsoft under the Tax Cuts and Jobs Act (TCJA), which could decrease the final tax owed under the audit by up to $10 billion. Microsoft disagrees with these proposed adjustments and will pursue an appeal within the IRS, a process expected to take several years. We believe we have always followed the IRS’s rules and paid the taxes we owe in the U.S. and around the world. Microsoft historically has been one of the top U.S. corporate income taxpayers. Since 2004, we have paid over $67 billion in taxes to the U.S. What the dispute is about The main disagreement is the way Microsoft allocated profits during this time period among countries and jurisdictions. This is commonly referred to as transfer pricing and the IRS has established regulations that allow companies to use a specific arrangement for transfer pricing, called cost-sharing. Many large multinationals use cost-sharing because it reflects the global nature of their business. Because our subsidiaries shared in the costs of developing certain intellectual property, under those IRS cost-sharing regulations, the subsidiaries were also entitled to the related profits. Next steps: Proposed adjustments and IRS Appeals We strongly believe we have acted in accordance with IRS rules and regulations and that our position is supported by case law. We welcome the IRS’s conclusion of its audit phase which will provide us with the opportunity to work through these issues at IRS Appeals, a separate division of the IRS charged with resolving tax disputes. It is important to note that the IRS Appeals process will take several years to complete, and if we are unable to come to a direct agreement with the IRS, Microsoft will then have an opportunity to contest any unresolved issues through the courts. We will continue to work with the IRS and hope to reach a mutual resolution to this issue over the coming years. We will also continue to share updates on significant developments through our public quarterly and annual reports and financial statements, as we have through this entire process. As of September 30, 2023, we believe our allowances for income tax contingencies are adequate.",
    "commentLink": "https://news.ycombinator.com/item?id=37850110",
    "commentBody": "Microsoft SEC 8-K: IRS is seeking an additional tax payment of $29BHacker NewspastloginMicrosoft SEC 8-K: IRS is seeking an additional tax payment of $29B (gcs-web.com) 208 points by raimue 18 hours ago| hidepastfavorite157 comments silverlyra 17 hours agoAdditional remarks on the Microsoft blog (also included in the 8-K filing): https:&#x2F;&#x2F;blogs.microsoft.com&#x2F;on-the-issues&#x2F;2023&#x2F;10&#x2F;11&#x2F;update-...> Today, we’re sharing an update about our ongoing audit with the U.S. Internal Revenue Service (IRS), [… which has been investigating] how we allocated our income and expenses for tax years beginning as far back as 2004. […] The IRS says Microsoft owes an additional $28.9 billion in tax for 2004 to 2013, plus penalties and interest. reply TheJoeMan 17 hours agoprev“Many large multinationals use cost-sharing because it reflects the global nature of their business.”A comparable example might be Apple, where sales of my (american) app being sold from (american) servers somehow curiously involves the Republic of Ireland and their low corporate tax rates… reply drivebycomment 15 hours agoparentApple pays the majority of taxes to US. They report US income and pay taxes for that to US. Ireland is involved only so far as EU income. So if your American app is sold to European users, the income is recognized as EU, and reported to Ireland.https:&#x2F;&#x2F;fortune.com&#x2F;2017&#x2F;10&#x2F;31&#x2F;trump-tax-reform-apple-multin...There are other possible criticisms on corporate tax and Apple, but this isn&#x27;t a valid one. reply kwhitefoot 4 hours agorootparentOf course it is valid. The principal on which much of taxation is based is that it is a tax on the benefit that the income provides. And that benefit accrues in the US.The only way it can be claimed to be invalid is by conflating legal with moral. reply esrauch 4 hours agorootparentYou&#x27;re suggesting that their EU sales shouldn&#x27;t pay EU income at all, rather US income taxes instead? Usually the criticism of this is the opposite direction, that sales in Germany should pay taxes in Germany. reply littlestymaar 3 hours agorootparent> You&#x27;re suggesting that their EU sales shouldn&#x27;t pay EU income at all,Well, since this is Ireland tax rates we&#x27;re talking about, this is almost the same thing… reply disgruntledphd2 3 hours agorootparentThat used to be true, but is no longer. Currently Apple et al pay 12.5% corporation tax in the Republic of Ireland, unlike the past where this rate existed but was notional as most of the revenue was ultimately booked to a real tax haven like Bermuda et al. reply littlestymaar 3 hours agorootparentGlad it changed. It&#x27;s still a 50% discount compared to most of EU though… reply Terretta 2 hours agorootparentSounds like something EU should change if EU don&#x27;t like it. reply marcyb5st 1 hour agorootparentI don&#x27;t think this can be solved easily. Unless until https:&#x2F;&#x2F;www.europarl.europa.eu&#x2F;news&#x2F;en&#x2F;press-room&#x2F;20220603IP... (3rd point) lands and the original idea is not messed up during the rounds of debate.Until then, not going to happen IMHO. Ireland, Luxembourg, and the Netherlands benefit outrageously from this and since they can veto stuff it&#x27;s really hard to plug these holes. I think Ireland gave up some ground in this regard since its position was starting to really annoy other EU members. reply littlestymaar 2 hours agorootparentprevEu is a complex entity, there&#x27;s no such thing as “EU don&#x27;t like it”. replynodamage 7 hours agoparentprevThis is a common misconception but not actually true.If Apple sells a copy of your app to an American customer the revenue from their royalty is booked to Apple Inc. (the U.S. company) and they would pay U.S. income tax on that sale.The only time the sale would be booked to their Irish subsidiary is if the customer was located in Europe, or it would go to one of their other international subsidiaries depending on the specific location of the customer. reply oldbbsnickname 3 hours agorootparentLegal BEPS exist and is more complicated than this oversimplification. While Apple didn&#x27;t do Stanley Works \"moving\" to Bermuda, Tim Cook is no slouch in the financial domain as that was (and is) his wheelhouse. The calculus involves a myriad of factors including a risk appetite, leadership ethics, lots of data, and decision support. As an aside, I once parted ways with 2 potential business partners because they were on the privately-admitted illegal side of BEPS and tax minimization in speech and action. (Last I heard, they&#x27;re lobbyists for political interests based in another country.)Also, the books for taxes and the books for securities regulators aren&#x27;t precisely equivalent per jurisdiction based on how things are counted or not counted. For example, in general, Norwegian and US accounting practices tended to be&#x2F;are vastly different in some areas... hence a need for local external auditors.Corporate Inversions: Stanley Works and the Lure of Tax Havens (2002) https:&#x2F;&#x2F;www.hbs.edu&#x2F;faculty&#x2F;Pages&#x2F;item.aspx?num=29288 reply Y_Y 16 hours agoparentprevIt&#x27;s simple enough, an Irish company called Apple licenses its very valuable IP to its entities in cheaper countries so they can do things like manufacturing, server farms, customer support.(It also carries on these some of these functions in Ireland, as it happens, and pays a ton of tax at the relatively high income tax rates there.)It&#x27;s frankly curious to me when a multinational chooses to base itself anywhere less favourable. reply gemstones 16 hours agorootparentAt one point, it wasn’t an Irish company. Now technically the American company sold or transferred its IP to the Irish company. But it did so as a fiction, to avoid taxes, and neither I nor a government I help elect are obligated to honor that fiction. reply c0pium 16 hours agorootparentOf course they are, it’s a contractual agreement that is within the law. The fact that you don’t like it could not be less relevant, you don’t matter. If the government doesn’t like the law, they can (try) to change it but that has to go through the actual process. They are welcome to be as mad as they want that their law is poorly written but it is still their law. reply skeaker 15 hours agorootparentI believe \"their law\" is what is being criticized, and GP&#x27;s \"government that I help elect\" would do away with \"their law.\" Pointing out that the law being criticized as bad is in fact a law is at best a tautology... reply realusername 8 hours agorootparentprevEvery law is judged with the intent behind the action... except for taxes which is the single exception I know of. And here the intent is pretty clear. reply sokoloff 6 hours agorootparentI hope (and think) that laws are judged primarily by their text and entirely so when it can be determined that the facts match the text even if many of us wish the text was different in light of these specific facts.Criminal trials carefully lay out how the state believes the actions of the accused meet each required element of the crime. They don’t get to say “Foo definitely killed Bar. The law intends for people to not kill each other, and Foo meant to, therefore Foo is guilty of 1st degree murder.” Rather, they have to prove Foo’s actions met all required elements of the charge.If you rear-end me while I’m stopped at a light, your intent doesn’t matter, only your actions. If you fail to stop for a school bus displaying red stop lights, your intent doesn’t matter.I think the IRS step doctrine is relatively rare in legal interpretations, but at a minimum, it’s not “every other law is interpreted that way”.I don’t take a position on Microsoft’s actions here, other than “if it can be shown to be plainly compliant with the law as written, I’m uncomfortable with the law being changed during interpretation such that it’s deemed to be non-compliant.” reply tw04 4 hours agorootparent> If you rear-end me while I’m stopped at a light, your intent doesn’t matter, only your actions. If you fail to stop for a school bus displaying red stop lights, your intent doesn’t matter.Huh? In both of these examples, intent 100% matters. If I rear ended you because I had a medical emergency vs I was texting on my phone vs I had a bout of road rage and wanted to kill you vs I know who you are and you’re sleeping with my wife so I followed you from work to try to kill you:All VERY different levels of potential punishment based entirely on my intent. reply sokoloff 2 hours agorootparent100% fair point. I was thinking the other way: when you accidentally ran into my car, the fact that you didn&#x27;t mean to do it doesn&#x27;t excuse you from liability for the damage to my car (even if you had a medical emergency).You&#x27;re absolutely right that overt intentional assault is different than an accidental collision. reply ceejayoz 4 hours agorootparentprev> If you rear-end me while I’m stopped at a light, your intent doesn’t matter, only your actions.Bullshit. If you intended to do it, it’s something like assault or attempted murder. If you didn’t, it’s likely a civil traffic ticket and an insurance claim.SCOTUS precedent permits use of legislative intent to resolve ambiguously worded legislation, too.> The rule that penal statutes are to be construed strictly does not permit such a construction as defeats the obvious intention of the legislature. reply mathgeek 4 hours agorootparentprevYou should probably clarify that intent doesn’t matter in terms of baseline fault, as it definitely matters in terms of punishment and charges. reply realusername 1 hour agorootparentprev> I hope (and think) that laws are judged primarily by their text and entirely so when it can be determined that the facts match the text even if many of us wish the text was different in light of these specific facts.The facts do matter when you are judged, laws aren&#x27;t code. The only reason taxes are the single exclusion to this rule is because there&#x27;s a massive amount of money to be made. You are not bound to the same justice system as them. reply spockz 4 hours agorootparentprevI think this is more of an Anglo-Saxon vs rest of Europe distinction. In UK (and presumably US) the letter of the law is more important than the intent. In the rest of Europe the intent is more important than the exact letter.In both cases it is up to the judiciary to make the trade-off&#x2F;judgement. reply Y_Y 14 minutes agorootparentAnglo-Saxon? What has that to do with Common vs. Civil Law? Or is it a magic term like \"Caucasian\" or \"Judeo-Christian\" that just handwaves some psuedo-historical distinction for \"us vs them\"? reply realusername 1 hour agorootparentprevThat&#x27;s pretty much the same in both systems, if anything the common law system is based even more on intent than civil law. reply Nursie 6 hours agorootparentprevActually there seems to be a lot of intent in tax law, reading the wikipedia page about the Apple&#x2F;Ireland controversy - some tax mechanisms&#x2F;structures are specifically called out as not being available for firms looking to reduce their tax bill, use must be for genuine business requirements only. reply kwhitefoot 4 hours agorootparent> not being available for firms looking to reduce their tax bill, use must be for genuine business requirements only.That&#x27;s just a fig leaf. reply londons_explore 5 hours agorootparentprevWhen it comes to tax-free allowances, groups of companies can sometimes be considered one - if, for example, they shared a phone number or website. reply realusername 1 hour agorootparentprevAnd yet the reality is Apple doesn&#x27;t product their value in Ireland, regardless what they say on their paper. reply IshKebab 4 hours agorootparentprevNo it&#x27;s definitely true for taxes as well. Even on a tiny individual level you can argue with the tax authorities about whether something was purchased for business or personal use for example. reply gemstones 15 hours agorootparentprevAs a voter, I’m OK with them not following the process on this one! reply c0pium 10 hours agorootparentThat’s a very near-sighted idea. Can you really not see the problem? reply gemstones 4 hours agorootparentIt’s not a problem for me! It sets a precedent, sure, but I’m okay with the tradeoff there. reply Projectiboga 15 hours agorootparentprevThat tax break \"Double Irish Dutch Sandwich\" is being phased out. It involves both those countries with one of the Irish companies managed out of Bermuda. It has shifted to other schemes now. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Double_Irish_arrangement reply nixass 7 hours agorootparenthttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Feargal_O%27RourkeYou know things are nuts when one corporate accountant gets his own wiki article reply Horffupolde 14 hours agorootparentprevWhat other schemes? reply londons_explore 5 hours agorootparentAs soon as a scheme has a wikipedia page, you can be pretty sure it will become illegal within a year or two... reply zdkl 12 hours agorootparentprevNice try, FBI. reply hattmall 16 hours agorootparentprevIt&#x27;s no less fiction than any other contract or legal document. reply lmm 8 hours agorootparentThe idea that the business&#x27; value is being created in Bermuda (in Google&#x27;s case, but there will be similar things going on here) is a fiction. The idea that what creates the value is a single concrete piece of intellectual property is a fiction. The idea that that piece of intellectual policy was transferred to Bermuda is a fiction. The idea that what was transferred could be legitimately valued at zero when transferred and yet suddenly responsible for 100% of the business&#x27; value in subsequent years is an especially blatant fiction.I&#x27;d love to see the government of Bermuda nationalize that piece of intellectial property and claim all of Google&#x27;s global income. They&#x27;ve made such a careful, vigorous legal argument that it&#x27;s responsible for 100% of their revenue, surely they would acknowledge the things they&#x27;ve been claiming for years and continue to pay 100% of their profits to Bermuda. reply londons_explore 4 hours agorootparent> government of Bermuda nationalize that piece of intellectial propertyAnd, more importantly, nationalize it while compensating the owner for it&#x27;s declared value, which was zero (or near to). reply thfuran 7 hours agorootparentprevI&#x27;d rather see the US declare that the IP is no longer promoting the progress of science and the useful arts and annul it. reply londons_explore 4 hours agorootparentI would like to see an experiment where a country disallowed any company from keeping any secrets at all - IP or otherwise. Everything on all the companies computers and hard drives would always be visible to competitors and the public.While it discourages long research projects, it really incentivises fast execution and building on other companies designs. reply hiatus 1 hour agorootparentYou might find the culture of gongkai to be in the same vein as your suggestion. https:&#x2F;&#x2F;www.bunniestudios.com&#x2F;blog&#x2F;?p=4297 reply thfuran 3 hours agorootparentprevI think companies overvalue secrecy to the point that most that are able would immediately leave. And I don&#x27;t think most any industry has such a problem with willingness to execute quickly that trying to incentivize that is worth totally crushing R&D. Hell, I think the world could do with a bit more research and a bit less moving fast and breaking things. reply gemstones 15 hours agorootparentprevAlthough in this case, this was a good use of government time even if it goes to the courts! I would like to see the government instill a culture of fear in these companies’ legal departments, that leaves them wondering them the law will change to hit them. reply gemstones 15 hours agorootparentprevYes it is, because this one negatively affects enough people that the law should make a special case to disallow it. Contracts are enforceable when laws say they are enforceable, but governments are free to change laws.If the government says it is a fiction, it is a fiction. replydaft_pink 11 hours agorootparentprevThere are limits in place that prevent these ip schemes these days. reply Nursie 11 hours agorootparentprev> \"a ton of tax at the relatively high income tax rates there\"Firstly, that&#x27;s not Apple paying income tax, that&#x27;s their employees.Secondly, they don&#x27;t pay much in the way of corporation or other taxes that usually apply because of a sweetheart deal (Google also has one IIRC), which is why much of the EU is up in arms about the Irish government&#x27;s behaviour here, that effectively allows these multinationals to operate across the EU without paying the usual expected taxes, giving them an advantage over local businesses and depriving governments of income, and there have been various court cases about it. reply Y_Y 6 hours agorootparent\"Sweetheart deals\" are not allowed in the EU, and whether or not there was one in this case is a matter of controversy[0]. In fact the EU courts have decided that there was no breach of law by Apple, though a further appeal maybe yet be made. It&#x27;s easy to sling around accusations like this, but it&#x27;s important to check the facts at the same time.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple%27s_EU_tax_dispute reply kawhah 3 hours agorootparentI don&#x27;t think you&#x27;ve successfully checked any facts.The GP correctly and idiomatically described a tax deal between RoI and Apple as a &#x27;sweetheart&#x27; deal. This is not a legal term of art. The fact that Ireland won its court case and is facing an appeal does not change the fact that something took place which exactly meets the commonly understood definition of a sweetheart deal. reply Nursie 6 hours agorootparentprevWhether they were precisely sweetheart deals or not, it remains that Apple and the Irish government did negotiate &#x27;deals&#x27; and that Ireland has facilitated a lot of tax reduction for large US multinational corps, which much of the EU believes costs them both revenue and competitiveness.It is interesting that the last news about this is the EU saying they are going to appeal, three years ago.I find the use of such schemes pretty awful regardless of whether they technically fall inside of the law. reply olliej 15 hours agorootparentprevThe same applies to all the BS Delaware corporations. reply alexanderchr 10 hours agorootparentAFAIK Delaware incorporation is more benign and has more to do with predictable courts and lots of case law existing rather than paying as little tax as possible. reply bagels 17 hours agoprevI know we&#x27;re not supposed to editorialize the titles, but this one really buries the lede. reply dredmorbius 16 hours agoparentSuggested alternatives:\"Microsoft on the Issues Blog – An update on our IRS tax audit\"Or:Microsoft SEC 8-K: \"IRS is seeking an additional tax payment of $28.9 billion\"(I&#x27;ve emailed mods to suggest these.) reply dang 12 hours agorootparentOK, I&#x27;ve put the latter above. reply thumbsup-_- 16 hours agoparentprevit&#x27;s the new form of clickbait. It&#x27;s so vague that you end up opening in anticipation reply spandextwins 17 hours agoprevWow. “The IRS says Microsoft owes an additional $28.9 billion in tax for 2004 to 2013, plus penalties and interest.”No wonder why they’re talking about charging for windows 12 features, has to come from somewhere! reply queuebert 17 hours agoparentThey have ~$35 billion in cash per their cash flow statement:https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;MSFT&#x2F;cash-flow?p=MSFTThey could in effect write a check today for it. reply lib-dev 17 hours agorootparentOnly if \"penalties and interest\" is less than ~2% annually. reply zie 17 hours agorootparentprevLOL, like they would ever do that! They will make MS customers pay for it, if they can&#x27;t convince the IRS to lower the bill significantly, which they probably can. reply wheelerof4te 3 hours agorootparent\"if they can&#x27;t convince the IRS to lower the bill significantly\"Why would IRS agree to this? Would the IRS agree to lower your taxes if you pretty-pleased them?Microsoft should not be an exception. reply kawhah 3 hours agorootparentIf MS come up with significant technicalities or challenges to the amount due, the IRS will have to choose between litigating each one of them, which both costs them money and involves the risk of losing in court, or coming to an out-of-court agreement with MS.Obviously if MS don&#x27;t have anything that won&#x27;t get laughed out of court, they shouldn&#x27;t get much of a reduction. If your challenge to your tax bill doesn&#x27;t involve anything where the rules are hard to interpret and precedent has not been set, you also won&#x27;t. (If it does, your tax affairs are probably much more complicated than the average citizen. Which is obviously true for Microsoft.)Worth bearing in mind too that the number might be an optimistic headline figure which has been rounded up in various ways by the IRS, to make themselves look tough, and to encourage MS to settle. reply zie 55 minutes agorootparentprevThe IRS settles for lower amounts ALL the time, it wouldn&#x27;t be even remotely exceptional if MS gets a discount. They have an entire department to handle these offers in compromise: https:&#x2F;&#x2F;www.irs.gov&#x2F;payments&#x2F;offer-in-compromiseEven with 30B cash in the bank, MS will do everything it can to lower that bill. First they will fight it, and take all the little wins they can get. Then whenever it&#x27;s pretty clear what parts they can&#x27;t win, they will then start negotiating with the IRS to try and pay 50 cents on the dollar or something.Part of the tactic is delaying, the longer they can put off actually writing the check, the better, as money today is worth more than money tomorrow(inflation and time value of money). reply justaj 2 hours agorootparentprev> Microsoft should not be an exception.I mean... I agree, they shouldn&#x27;t, but I think we all know how this will turn out. reply g232089 7 hours agorootparentprevOf course they will make their customers pay for it. That&#x27;s how companies work: the customers pay for the expenses of the company. reply robertlagrant 6 hours agorootparentNo, they pay for the value the company provides them. That only bears mild relation to what it cost the company to provide that value. reply justinclift 17 hours agorootparentprev\"Lets put aside $2B for legal costs, as they should be able halve that or better over the next decade...\" ;) reply spandextwins 16 hours agorootparentprevThat money came from customers too. reply germandiago 4 hours agorootparentprevI know I am in the minority but I cannot understand how mercilessly taxing providers of services that improve our lives is not... theft, honestly.It is not about how much money they make but about about a third party appropriating what a company that provides such a big value does because, hey, you are \"stealing me because I exist\"...Now people will vote me negative, I know... reply no_wizard 17 hours agoparentprevThis is before any negotiated settlement, if they are found to have to pay at all, which will be, in all likelihood, substantially lower reply us0r 17 hours agoparentprevThey have over 115 Billion cash on hand. reply swatcoder 17 hours agorootparentYeah, and if that takes a $30B hit to settle past accounting issues, that’s still $30B no longer poised for an acquisition or on hand to settle some EU action next year.Losing a quarter of your cash reserves for no gain isn’t going to ruin today’s business but it sure will frustrate existing strategies for the future. reply itsoktocry 4 hours agorootparent>that’s still $30B no longer poised for an acquisitionThey accumulate that much cash because there are no acquisitions to be had in the current economic climate. I can&#x27;t imagine a $30B+ company that Microsoft could acquire without massive regulatory scrutiny. reply sensanaty 4 hours agorootparentprevGood! Hopefully Microsoft burns through as much of their cash paying penalties as possible and dies as a result, as they should&#x27;ve a decade+ ago. reply quickthrower2 4 hours agorootparentprevYou can acquire with shares though. They or they could raise 30Bn pretty easy. reply notaharvardmba 17 hours agorootparentprevBut I bet a lot of that is in long term treasuries which, if you want to use them as legal tender, are kinda down in price right now (if you don&#x27;t hold them til maturity). And if they need to take a loan to pay it, those bonds are going to be at fairly high rates. Overall, it&#x27;s gonna be a stock price haircut for sure. I&#x27;m guessing at least 10-20% because of all the money they could have MADE with that money. reply ojbyrne 17 hours agorootparentRandom googling finds “Cash equivalents are any short-term investment securities with maturity periods of 90 days or less.”They have $35 billion in Cash & Cash Equivalents. reply tmpX7dMeXU 16 hours agorootparentYep. Accounting standards dictate that a cash equivalent should be essentially as liquid as cash from the perspective of the holder. It’s safe to lump it in here. reply DennisP 17 hours agorootparentprevLong-term treasuries are generally not considered \"cash.\" Short-term, sure, but t-bills are doing fine. reply ssss11 16 hours agoparentprevMaybe it could come from those huge executive salaries and bonuses that are many multiples higher than regular employees. reply shiroiuma 7 hours agorootparentWhy should they do that? They should simply add more annoying advertising and other BS to their products, especially Windows OS. What are customers going to do, go elsewhere or switch to another OS that doesn&#x27;t have ads? reply robertlagrant 6 hours agorootparentprevThat won&#x27;t cover billions of dollars. Multiples don&#x27;t matter. reply maartenscholl 16 hours agoprevThis spells bad news for \"MICROSOFT B.V.\", the famous Dutch software company that has reported being responsible for billions of revenue of the Microsoft Corporation over those years. reply FireBeyond 16 hours agoparentApple and others are working to explain how the majority of app and hardware sales have a nexus in Ireland.But wait til you hear of Ugland House (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ugland_House) in the Caymans - 10,000 sq ft, 5 stories...... and registered offices of 42,000 companies. reply dannyw 24 minutes agorootparentTo be fair, the Ireland case for EU seems more understandable. The EU has an economic union, and consumers still pay local VAT.If EU doesn&#x27;t like one country has too low tax rates, that&#x27;s an EU matter. reply yieldcrv 11 hours agorootparentprevRequires pure hubris and indoctrination to think the US coffers are an eligible recipient of that revenue“Why aren’t we getting screwed equally” seems to be the stance instead of “why are we getting screwed at all”Turns out, the law says you don’t have to get screwed reply xctr94 8 hours agorootparentWhy is it bad that corporations pay taxes? Ignoring your use of sexual language to that effect, I don’t see why companies get to use tax havens to avoid paying for the Common Good that serves everyone (regardless of how much % you think it should be). reply yieldcrv 52 minutes agorootparentI didn’t say it was bad, I said very specific words. They aren’t the recipient, just like Brazil, or Canada, or any random country isnt. If thats hard for you to understand, thats exactly what I’m trying to point out: it shouldnt be hard to understand.The “Common Good” isnt paid for by taxes, its paid by debt issuance and the taxes and other revenues pay the interest. This means that the things that would be funded already are funded, and no tax collection influences that.Regarding “tax havens”, this is also hubris. A high tax country that doesnt know how to balance its budget has a term for a low tax nation that operates within the confines of its budget. The Cayman Islands has legislated a tax, its just at 0% right now because they dont need the money that way. They found something competitive to raise enough revenues and didnt get involved in other things. Its nobodies problem that this is now impossible for the other country from its poor spending habits.Maybe one day you’ll see your blind spots. What I described is the reality that exists, it is already compliant to operate this way and that’s very unlikely to change. Countries compete on competitiveness for business. reply yieldcrv 11 hours agoparentprevIs it? These companies and that specific structure involves paying the IRS off in “Advance Pricing Agreements” where they tell the IRS how they won’t pay taxes and the IRS signs off on itAll they have to do is find the agreement reply jbverschoor 8 hours agorootparentThose agreements are private, and against eu policy or law, the Netherlands has made numerous agreements regarding this with large corporations.Would love to see them reply hbcondo714 17 hours agoprevAuthoritative source at:https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;789019&#x2F;0001193125232... reply pylua 16 hours agoprevThere should never be a gap this big unless fraud or evasion is involved. If the rules are that vague it needs to change. reply tedunangst 15 hours agoparentShould we measure the gap in relative or absolute terms? reply pylua 15 hours agorootparentI think this is more of a common sense thing. Your question is probably an example of what the Microsoft tax preparers asked. reply OrvalWintermute 8 hours agoparentprevI can understand why an honest mistake, an accounting misinterpretation, or incorrect decision leads to a gap this big - taxes can be complex. reply pylua 1 hour agorootparentEven honest mistakes can be construed as negligence. reply arthur_sav 6 hours agorootparentprevTaxes are complex because they want them to be. reply jacquesm 4 hours agoprevMaybe they can sell Github to a company that is more aligned with long term FOSS interests? reply onli 4 hours agoparentWhich company would be big enough to fit that description and able to pay enough to make a dent in this big an amount? reply SSLy 3 hours agorootparentIBM? reply Zetobal 1 hour agorootparentCan&#x27;t wait until GitHub will be e̶n̶h̶a̶n̶c̶e̶d̶ bricked by Watson. reply ds 15 hours agoprevIsnt the statute of limitations for collecting taxes 10 years?2004 is 19 years... reply acomjean 4 hours agoparentMy dad’s shuttered small business was audited last century. In his case they sent a letter saying you are under an investigation for year x, they clock resets to x years after that and they can bring action anytime. At least that’s the was it was explained to very young me at the time. reply viraptor 11 hours agoparentprevIt&#x27;s 3, 6, 10, or many other options depending on the situation. They can be extended in various ways too... https:&#x2F;&#x2F;www.americanbar.org&#x2F;groups&#x2F;business_law&#x2F;resources&#x2F;bu... reply foobarbazetc 13 hours agoparentprevNot if it’s evasion. reply dgellow 4 hours agorootparentIs the IRS saying it is evasion? That’s not at all what I read. Any source for that claim? reply kwhitefoot 4 hours agorootparentI would guess that they won&#x27;t bother doing that unless they and MS can&#x27;t come to a satisfactory agreement. reply chung8123 17 hours agoprevGoing back almost 20 years has got to be painful. I doubt half of the people involved are even still at the company. reply sn_master 12 hours agoparentMicrosoft has more careerists than most other tech companies. I bet plenty of the key figures are still at the company. reply throwaway9274 7 hours agoprevHere’s what’s going on:-Companies that operate internationally make revenue and incur costs in many different countries.-As a result, they owe taxes to many different national authorities.-Each national authority has rules for how costs and revenues are accounted across borders.-These rules are necessarily complex, because it’s often not clear how costs and asset transfers should be accounted from simple first principles.-This is particularly important when accounting costs across countries, because taxable income is often based on your costs.-For example in the US, Federal taxable income equals gross income MINUS the cost of goods sold.-In a multinational, one critical question in figuring out costs is how to value transfer prices of goods, intangibles, and services among enterprises under common ownership.-That is, if the U.S. division of company A and a division of company A in another country exchange assets or services, the question of how they price those goods to one another becomes important for tax reasons.-Typically there’s a lot of accountants with spreadsheets or a software system where all this is calculated, monitored, invoiced, booked, and reconciled.-Accounting and services for this is typically called “transfer pricing.”-To determine how to account for these costs, each national regulator has very specific rules.-The question is whether Microsoft adhered to these rules in how it accounted for costs and revenues between its U.S. and international entities.-These disputes go through a very long back and forth process that often culminates in litigation, which itself can last years, or settlement.-Microsoft says, “Because our subsidiaries shared in the costs of developing certain intellectual property, under those IRS cost-sharing regulations, the subsidiaries were also entitled to the related profits.”-So it looks like the dispute centers around how to account for “the costs of developing intellectual property”, which can be hard if you’re developing software globally.-Finally, there’s one aspect to consider when you see these $XXB figures. At the size of certain very big corporations like Microsoft or Apple, money does not behave like it does for you, or me, or even Sequoia Capital.-Microsoft’s market cap is $2.4T. At that scale, money enters a kind of different state of matter.-Money’s purpose is primarily to coordinate economic activity, especially when you’re talking about non-negligible amounts for multinationals.-So payments among the revenue agencies of various countries and their very large private multinationals are in kind of a closed loop where they mainly have complex macroeconomic effects.-For example, the effect of increasing taxes via heightened transfer pricing scrutiny mostly moves production from one sector to another (e.g. from consumer tech to health and defense.)-The policy and finance folks pulling the levers understand how that works, and often have their own complex set of motives. reply lifeisstillgood 17 hours agoprev>>> Item 8.01. Other Information On October 11, 2023, Microsoft Corporation announced the receipt of Notices of Proposed Adjustment (“NOPAs”) from the Internal Revenue Service (the “IRS”) for the tax years 2004 to 2013. The NOPAs were received on September 26, 2023. The primary issues in the NOPAs relate to intercompany transfer pricing. In the NOPAs, the IRS is seeking an additional tax payment of $28.9 billion plus penalties and interest. As of September 30, 2023, we believe our allowances for income tax contingencies are adequate. We disagree with the proposed adjustments and will vigorously contest ...So MS income for 2023 was 211 BN, EBIT on that was 88BN. So being asked to give back 28.9BN is a big hit on anyone&#x27;s scale, but it&#x27;s \"just\" 3BN a year (2004-13) on annual profits of ~88BN - so it&#x27;s not like it&#x27;s their whole business model.Intra-company transfers are a tricky way to move assets and liability around inside a firm - because it&#x27;s not \"really\" selling there can be a lot of creativity. For example Starbucks was accused over many years of having foreign subsidiaries \"purchase\" coffee beans from Seattle at a price that co-incidentally matched the foreign subsidiaries operating profit - essentially meaning only the seattle firm made a profit and so only they had to pay tax.Something similar is being suggested here. It&#x27;s not clear what.However it&#x27;s worth noting that some years ago Biden announced major new funding for IRS to go after big firms. If this is part of that and if this comes to some agreement in a few years it will pay for that whole initiative several times over.Interesting reply gigel82 17 hours agoprevFrom the blog post[1]: \"It is important to note that the IRS Appeals process will take several years to complete, and if we are unable to come to a direct agreement with the IRS, Microsoft will then have an opportunity to contest any unresolved issues through the courts.\"[1] https:&#x2F;&#x2F;blogs.microsoft.com&#x2F;on-the-issues&#x2F;2023&#x2F;10&#x2F;11&#x2F;update-... reply ofslidingfeet 17 hours agoprevnext [3 more] [flagged] Jtsummers 17 hours agoparent> They are now going through and downvoting my entire post history lmao.No one can downvote your entire post history unless all your posts are from the past 24 hours. Downvoting is disabled after the 24-hour mark. reply ofslidingfeet 17 hours agoprevnext [9 more] [flagged] satvikpendem 17 hours agoparentYank the ladder up? Are you a cryptocurrency &#x2F; superstonk &#x2F; Wall Street Bets poster or something? The SEC should be going after scams and cults as well as corporate tax, it&#x27;s a false dichotomy you&#x27;re proposing. reply ofslidingfeet 17 hours agorootparentActually no, but nice try, and I&#x27;m sure your extremist uninformed view of what&#x27;s a \"cult\" is representative of the SEC&#x27;s general posture. reply satvikpendem 17 hours agorootparentThen I&#x27;m not sure what you&#x27;re worried about, if it really isn&#x27;t a cult as you imply. Either way, I don&#x27;t understand your position on the matter, are you personally affected by the SEC going after cryptocurrency scams and WSB style stock traders? reply ofslidingfeet 17 hours agorootparentYeah I think the SEC should work on real things instead of designating people as \"cults\" for running computer networks they dislike. reply satvikpendem 17 hours agorootparentWith reference to cults, I was referring to meme stocks like GME, BBBY etc, not cryptocurrency. But just because something fraudulent happens on a computer network does not mean the SEC should not prosecute it. Fraud is still fraud regardless of where it happens. reply nwiswell 17 hours agorootparentI&#x27;m pretty sure you&#x27;re engaging with a troll. reply dredmorbius 15 hours agorootparentprev reply dredmorbius 15 hours agorootparentprev reply davisr 17 hours agoprevnext [16 more] [flagged] dang 12 hours agoparentPlease don&#x27;t post unsubstantive and&#x2F;or flamebait comments to HN. They&#x27;re not what this site is for, and destroy what it is for. You can always make your substantive points without them, so please do that instead.We detached this subthread from https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37850384. reply orochimaaru 14 hours agoparentprevPublic services? Are you kidding - probably need to fund the wars. reply deelowe 15 hours agoparentprevSurely there&#x27;s a better way. This seems... arbitrary. reply wredue 13 hours agorootparentGrabbing dodged taxes from corporations is somewhat arbitrary, in that it doesn’t happen because republicans keep defunding the IRS, which is a major issue because nabbing tax dodging corporations has a massive return on investment.If Microsoft is getting busted, it’s not arbitrary. They just dodged their taxes poorly. reply deelowe 13 hours agorootparent> they just dodged their taxes poorly.Exactly. reply freejazz 14 hours agorootparentprevWhat makes you think it is arbitrary? reply jongjong 13 hours agorootparentprevAs an AnCap, I believe that involuntary taxation is theft, however, I also believe that each individual must focus on their own benefit. I also believe that these large corporations were largely built up and propped up by non-trivial amounts of public money and other forms of government help to begin with.As I don&#x27;t own any Microsoft stock and I don&#x27;t use their products and I stand to slightly benefit (in my career) from them having less money, I don&#x27;t have any moral issues with this SEC filing. reply FireBeyond 16 hours agoparentprevDo Apple next! reply jgalt212 15 hours agorootparentor first, if you sort in decreasing order of tax evasion &#x2F; avoidance. reply reactordev 14 hours agorootparentOr by largest sum owed reply Eumenes 15 hours agoparentprevThat money should be divided among the American taxpayers and not siphoned off by bureaucratic ghouls and the military industrial complex reply tayo42 13 hours agorootparentEveryone gets about 100 dollars. reply Eumenes 12 hours agorootparentWho doesn&#x27;t want $100? reply tayo42 11 hours agorootparentI guess I&#x27;d take it, it&#x27;s just going to sit in my bank. With 28billion, idk build a train or something, or place fiber, staff the borders better, build someone more telescopes reply colechristensen 17 hours agoparentprevI&#x27;ll settle for companies actually paying taxes and getting punished for trying to get away with convoluted loopholes and the tax-free state&#x2F;country scams. reply gigel82 17 hours agoprevSo... Amy Hood is out, right? Accountability and all. reply DylanDmitri 17 hours agoparentIt looks like the problem years were 2004-2013. The problems stop after she’s appointed CFO in 2013. reply c0pium 17 hours agoparentprevSo in your opinion accountability means firing the person who got the job after the incident happened? Amy Hood became the CFO in 2013. reply gadders 4 hours agoprevThe citizens of Ukraine and Israel will be very grateful. reply wheelerof4te 3 hours agoparentGood humor is black humor. reply not_your_vase 11 hours agoprevnext [–]> Not reflected in the proposed adjustments are taxes paid by Microsoft under the Tax Cuts and Jobs Act (TCJA), which could decrease the final tax owed under the audit by up to $10 billion.So even by Microsoft&#x27;s own admission they owe around $20B (instead of $30B) which they \"forgot\" to pay.I 100% believe that it was a good faith mistake, and it still is. reply dgellow 4 hours agoparentThey aren’t admitting, they are saying that if the proposed adjustment would be agreed upon they would end up paying less than the $30B mentioned. reply theogravity 16 hours agoprev [–] Wonder why the stock hasn&#x27;t taken a huge hit after the news. $28.9bln sounds like a lot. Maybe investors think MS will find a way to reduce the amount or pull of an extremely long term repayment plan?>As of September 30, 2023, we believe our allowances for income tax contingencies are adequate. We disagree with the proposed adjustments and will vigorously contest the NOPAs through the IRS’s administrative appeals office and, if necessary, judicial proceedings. We do not expect a final resolution of these issues in the next 12 months. Based on the information currently available, we do not anticipate a significant increase or decrease to our tax contingencies for these issues within the next 12 months.Maybe it&#x27;s because they won&#x27;t face the music for at least a year. reply teraflop 16 hours agoparentThe back taxes add up to about 1.2% of Microsoft&#x27;s current market cap, and it looks like the stock is down roughly 0.6% in after-hours trading. So I guess the market collectively estimates MS will end up owing about half of that amount. reply queuebert 13 hours agorootparentYou&#x27;re giving traders way too much credit for rationality here. reply extraduder_ire 15 hours agorootparentprevOr, the number is only slightly higher than investors inspected. I assume this isn&#x27;t the first news of this issue with the SEC and news like this was already priced-in to the stock. reply bux93 4 hours agorootparentEven if it is the first news of this particular issue, it doesn&#x27;t surprise anyone when one of these big corps is hit with a big fine.The announcement of back taxed for the years 2004-2013 at least places an upper bound on those past years. So this means that Microsoft investors now only have to worry about accounting failures over the years 2014-present! Less uncertainty = good news! reply quickthrowman 16 hours agoparentprev> Wonder why the stock hasn&#x27;t taken a huge hit after the news. $28.9bln sounds like a lot. Maybe investors think MS will find a way to reduce the amount or pull of an extremely long term repayment plan?It’s very simple, the market doesn’t expect that MSFT will have to pay $28.9B in back taxes. reply arch1e 7 hours agorootparentOr the market already priced it in? reply kyleee 16 hours agoparentprevPartly (or maybe totally) because the 28.9 billion number is essentially the opening number in a negotiation (and there is even a chance the the figure is completely wrong and nothing additional is owed) and there is basically 0% chance MS ends up paying $28.9 billion. reply pm90 16 hours agoparentprev [–] Its not a final determination. If they do actually paying up that much money is when I expect investor sentiment to change. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "On October 11, 2023, Microsoft Corporation disclosed that it has received Notices of Proposed Adjustments (NOPAs) from the Internal Revenue Service (IRS) relating to tax years between 2004 and 2013.",
      "The IRS has demanded an extra $28.9 billion in taxes in addition to penalties and interest, revolving around the issue of intercompany transfer pricing.",
      "Microsoft insists on disputing the NOPAs through administrative appeals and possibly judicial proceedings, evidently not expecting a final resolution or significant changes in its tax contingencies within the subsequent 12 months."
    ],
    "commentSummary": [
      "The IRS is demanding an additional tax payment of $29 billion from Microsoft for not correctly allocating its income and expenses from 2004 to 2013. Microsoft is contesting these proposed adjustments, and the resolution is expected to take over a year.",
      "While Microsoft has the financial capability to cover the tax payment, it could impact their future strategies and acquisitions, especially their rumoured plan to acquire a $30 billion company.",
      "Despite Microsoft potentially facing regulatory penalties and scrutiny, the stock market response has been lukewarm, suggesting that investors are sceptical about Microsoft paying the full tax amount."
    ],
    "points": 208,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1697057557
  }
]
