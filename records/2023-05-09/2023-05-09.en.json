[
  {
    "id": 35863837,
    "timestamp": 1683564401,
    "title": "Ink: React for interactive command-line apps",
    "url": "https://github.com/vadimdemedes/ink",
    "hn_url": "http://news.ycombinator.com/item?id=35863837",
    "content": "Ink is a component-based UI building experience for command-line apps that uses Yoga to build Flexbox layouts in the terminal, providing most CSS-like properties. As a React renderer, Ink supports all features of React, and documentation can be found on the React website. Ink version 4 methods will be documented in this release. Examples of who is using Ink include GitHub Copilot, Cloudflare's Wrangler, and Blitz. The essential Ink <Box> component can be used to build layouts, and the available components include <Text>, which can display text and change its style, and <Newline>, which creates a new line. Other available components include <Spacer>, <Static>, and <Transform>. Useful hooks such as <useInput>, <useStdin>, and <useFocus> are also available.",
    "summary": "- Ink is a UI building tool for command-line apps that uses Yoga to create layouts with CSS-like properties.\n- Ink supports all React features and has been used by popular services such as GitHub Copilot and Cloudflare's Wrangler.\n- Essential components like <Box>, <Text>, <Newline>, <Spacer>, <Static>, and <Transform> are available, along with useful hooks like <useInput>, <useStdin>, and <useFocus>.",
    "hn_title": "Ink: React for interactive command-line apps",
    "original_title": "Ink: React for interactive command-line apps",
    "score": 490,
    "hn_content": "React-based command-line app Ink offers a quick and convenient option for multi-terminal clients to run in parallel. Developers can use it to monitor websockets and improve workflows and debugging of CLI text output through immediate rendering. Ink\u2019s major limitations are an inability to support nested rendering/overlays and to enable modals, which could be a major drawback. Ink is just one of many useful technologies for building text-based UIs, such as Bubbletea, Textual, TUI-rs, Dioxus, Mosaic and more. These programs can offer significant benefits to developers even when extensive testing is not required. While traditional GUI elements like HTML/CSS may be missed in some instances, the layout system offered by Ink ensures a smooth user experience.Developers discuss different tools and libraries that can help with graphics editing, drag-and-drop design tools, as well as building interactive command-line apps. React and Electron are mentioned as options, though some express concern about their drawbacks. Ink, a React-based library for building command-line apps, receives praise and criticism. It is noted that Ink uses Yoga for layout, but some find other alternatives, such as CSS Grid, to be more useful for certain types of apps. Overall, developers offer their experiences and opinions on the various tools and approaches for building interactive command-line apps.Ink is a JavaScript library that allows developers to build interactive command-line interfaces using React. The comments include both positive and negative opinions on the use of React, as well as the practicality of using CLI interfaces. Some programmers find the CLI tools more accessible and SSH-friendly, while others see it as alienating to a large portion of users. Moreover, developers have found Ink suitable for building custom CLI tools that allow them to access via remote shell, handle user input, and responsive re-render for visualizations. Some users recommend using other CLI tools such as Charm for Go and Notcurses, while other comments express a lack of understanding of the purpose of Ink.",
    "hn_summary": "- There are other useful technologies available for building text-based UIs, such as Bubbletea, Textual, TUI-rs, Dioxus, and Mosaic.\n- Developers give their experiences and opinions on various tools and approaches for building interactive command-line apps, including both positive and negative opinions on the use of React, as well as the practicality of using CLI interfaces."
  },
  {
    "id": 35862656,
    "timestamp": 1683559602,
    "title": "FBI agents accuse CIA of 9/11 coverup",
    "url": "https://www.spytalk.co/p/exclusive-fbi-agents-accuse-cia-of",
    "hn_url": "http://news.ycombinator.com/item?id=35862656",
    "content": "Previously unreported interviews from a court filing allege that the CIA is hiding information about a failed recruitment effort involving the Saudi intelligence asset, Omar al-Bayoumi, who met with two of the 9/11 hijackers in February 2000. Former FBI agents claimed that the CIA possessed \"operational\" files and a \"paper trail\" about the Saudi spy's recruitment efforts, and that the CIA hid critical evidence from the FBI. Defense lawyers for 9/11 defendants in Guantanamo Bay have asked a judge to order the CIA, FBI, Congress, and the 9/11 Commission to turn over all documents related to Bayoumi. A CIA spokesperson has strongly disputed the allegations, stating that the agency has complied with Executive Order 14040 of September 2021 and that the allegations of a cover-up are false.An anonymous FBI agent recently came forward to claim that there is evidence implicating Saudi Arabia and the CIA in the 9/11 attacks that remains hidden from the public. The article explores previously known links between Saudi Arabia and the hijackers, examining a recently declassified FBI memo, court filings, and interviews. The article raises questions about the actions of the CIA in the lead-up to the attacks, particularly surrounding the agency\u2019s efforts to prevent the FBI from gaining knowledge of some of the hijackers. The article also examines the role of a Saudi intelligence network that assisted the hijackers, which was created and funded by officials in the Saudi embassy under the leadership of Prince Bandar bin Sultan Al Saud. The article concludes that key 9/11 riddles remain unsolved.",
    "summary": "- Former FBI agents allege that the CIA has been hiding information about a failed recruitment effort involving a Saudi intelligence asset who met with two of the 9/11 hijackers in February 2000.\n- Defense lawyers for 9/11 defendants in Guantanamo Bay have requested all documents related to the Saudi spy\u2019s recruitment efforts from the CIA, FBI, Congress, and the 9/11 Commission.\n- The CIA strongly denies any cover-up, but the article raises questions about the actions of the agency and Saudi Arabia in the lead-up to the attacks and concludes that key 9/11 mysteries are still unsolved.",
    "hn_title": "FBI agents accuse CIA of 9/11 coverup",
    "original_title": "FBI agents accuse CIA of 9/11 coverup",
    "score": 420,
    "hn_content": "FBI agents have accused the CIA of hiding information on the lead up to the 9/11 terrorist attacks as part of a culture of secrecy between intelligence and law-enforcement agencies. The FBI claims that had the CIA shared information when requested, their target may have been prosecuted or deported, thus rendering the FBI\u2019s investigation worthless. At the time of the attacks, information sharing was not even permitted between the two agencies. The CIA is an intelligence agency that focuses on foreign action, and one that primarily relies on secrecy over public disclosure. Conversely, the FBI is focused on domestic law enforcement, aiming to protect constitutional rights while being publically accountable for its activities.The discussion revolves around the relationship and information-sharing between the CIA and FBI. In the pre-9/11 era, there was a hard firewall between the two agencies enforced to protect domestic citizens against spying. The CIA primarily deals with international intelligence gathering, while the FBI focuses on domestic crime investigation. The CIA operates outside the law, so they don't need a warrant to surveil a subject. However, this also means the agency isn't obligated to explain itself to Congress, making oversight of any such agency difficult. The Office of the President maintains the right to order the execution of anyone without trial. The Patriot Act has expired in 2020 but has resulted in the erosion of citizens' privacy rights. The FBI has a counterintelligence/domestic intelligence mission alongside its law enforcement mission.The post discusses the separation of powers in the US government, particularly the separation of the FBI and the CIA. The two agencies operate under separate mandates with different focuses, with the FBI being a domestic law enforcement agency and the CIA being an intelligence gathering agency focused on foreign countries and their citizens. Following the 9/11 attacks, there have been mechanisms put in place to allow for some information sharing between the agencies, but the walls between domestic and foreign spying remain. The post includes some discussion of past CIA scandals, including the MKUltra program, and suggests that while the CIA may act with good intentions, their job involves lying, manipulating, and committing criminal acts.The comments section of an article covers a range of topics related to the U.S.\u2019s pre-9/11 intelligence gathering. Some comments reference concerns about the CIA covering up its involvement in 9/11, but the article itself doesn\u2019t discuss that. Other comments discuss patterns of behavior in recruiting operatives and possible ally/enemy relationships between the US government and extremist groups. There are also comments on the use of \u201ccoverup\u201d as a sensationalized and misleading term.The article talks about the possibility of a cover-up regarding recruitment of 9/11 hijackers by the CIA, and lack of cooperation between the FBI and CIA in the aftermath. Some comments suggest that the title is intentionally vague, and point to the history of lies and secrecy in these agencies. One commenter offers a theory that terrorism is a tool of rulership over publics rather than a tactic of war. While some dismiss this as old news, others argue that it is still relevant due to the significant impact it had on American policy and public sentiment.",
    "hn_summary": "- CIA and FBI have different mandates, with the CIA focusing on foreign intelligence gathering and the FBI on domestic law enforcement.\n- The post discusses past scandals of the CIA, including the MKUltra program, and suggests that their work involves lying, manipulating, and committing criminal acts."
  },
  {
    "id": 35856820,
    "timestamp": 1683504875,
    "title": "Ancient Earth Globe",
    "url": "https://dinosaurpictures.org/ancient-earth/#470",
    "hn_url": "http://news.ycombinator.com/item?id=35856820",
    "content": "\u00ab Back to Dinosaur DatabaseWhat did Earth look like750 million600 million540 million500 million470 million450 million430 million400 million370 million340 million300 million280 million260 million240 million220 million200 million170 million150 million120 million105 million90 million66 million50 million35 million20 million0years ago?Jump to...first green algaefirst shellsfirst coral reefsfirst vertebratesfirst land plantsfirst land animalsfirst insectsfirst reptilesfirst dinosaursfirst flowersfirst primatesfirst grassfirst hominidsPannotia supercontinentPangea supercontinentTriassicJurassicCretaceousdinosaur extinctionDisplay OptionsCreditsOrdovician Period. The seas are diverse and the first coral reefs emerge. Algae is the only multicellular plant, and there is still no complex life on land.Use the \u2190 and \u2192 keys to step through timePaleogeographic maps by C.R. Scotese, visualization developed by Ian Webster \u00b7 Details \u00bb470 million years ago",
    "summary": "- The Ancient Earth Globe is an interactive website that allows users to see how Earth looked like millions of years ago, including the first coral reefs and the emergence of complex life on land during the Ordovician Period.\n- The globe features different time periods, displaying the first emergence of various forms of life that existed during those times, starting from 750 million years ago all the way to the dinosaur extinction 66 million years ago.\n- The website was created by geologist C.R. Scotese and web developer Ian Webster, and it is a great educational tool for anyone interested in learning about Earth's history.",
    "hn_title": "Ancient Earth Globe",
    "original_title": "Ancient Earth Globe",
    "score": 393,
    "hn_content": "The Tech Times reports on a new earth globe site that accurately depicts how the earth looked 20 million years ago. The site is based on the work of Chris Scotese, who has traditionally struggled to depict ancient continents. Some HN users voiced concerns over the accuracy of the site's information and mapping. There were calls for more emphasis on the southern hemisphere and the ability to track plate tectonics movement over time.The comments section of this post includes various discussions about the Earth's past, including the positioning of landmasses, the presence or absence of ice at the North Pole, and the evolution of humans and apes. There is also some speculation about the potential effects of climate change on the planet's geography. One commentator suggests adding a slider to the website in question, while another expresses interest in seeing a timeline of country borders over the last 10,000 years. Overall, this post is simply an exchange among individuals about various historical and hypothetical facts related to the Earth.",
    "hn_summary": "- Concerns over the accuracy of the site's information and mapping were voiced, with calls for more emphasis on the southern hemisphere and the ability to track plate tectonics movement over time.\n- Commentators discuss various historical and hypothetical facts related to the Earth, including the positioning of landmasses, the evolution of humans and apes, and potential effects of climate change on the planet's geography."
  },
  {
    "id": 35857463,
    "timestamp": 1683513037,
    "title": "You don't need Scrum, you just need to do Kanban right (2022)",
    "url": "https://lucasfcosta.com/2022/10/02/scrum-versus-kanban.html",
    "hn_url": "http://news.ycombinator.com/item?id=35857463",
    "content": "Why did you choose Scrum instead of Kanban? If you can\u2019t answer that question, you didn\u2019t choose Scrum. Someone else chose it for you.Even in the rare case people can answer this question, they reveal their deep misunderstanding of Kanban by mentioning one or more of these reasons:Scrum makes teams more responsiveScrum makes estimations easierScrum makes work visibleScrum reduces wasteScrum creates cadenced meetingsAll of the reasons above apply to Kanban as much as they apply to Scrum. The difference is that Scrum completely ignores your process\u2019 nuances and tells you exactly what to do and how to do it. In a way, Scrum is a manager\u2019s training wheels: it prevents them from bruising their knees, but also prevents their teams from being as fast and dynamic as they could be.Kanban, on the other hand, establishes principles. Once you understand these principles, you can tailor them to your particular situation and obtain much better results. Managers who master Kanban\u2019s principles don\u2019t need training wheels. Whether they\u2019re riding a bike or a motorcycle, they\u2019ll just need a few laps to understand the circuit, optimize their strategy, and overtake competitors.And, no, I\u2019m not saying Scrum doesn\u2019t work. I\u2019m saying the exact opposite. Scrum does work, but it works for the same reasons Kanban does. The difference between them is that Scrum is slower and more prescriptive, and thus less adaptable (or \u201cagile\u201d, whatever you wanna call it).Scrum becomes even more harmful when managers create their flavor of Scrum, trying to shoehorn prescriptive guidelines into a context in which they don\u2019t fit. When that happens, managers turn an inefficient yet sound framework into an inefficient and defective process. That\u2019s because they ignored the Kanban dynamics which made \u201cby-the-book Scrum\u201d work.In this post, I\u2019ll expound on the reasons I prefer Kanban over Scrum, and explain the ways in which Scrum hinders a team\u2019s performance.Additionally, I\u2019ll also explain why each of the aforementioned benefits of adopting Scrum also apply to Kanban, and how Kanban amplifies those benefits.How Kanban amplifies Scrum\u2019s benefitsScrum makes teams more responsiveScrum makes teams more responsive because when sprints are two-week long, you\u2019ll take no longer than two weeks to respond to feedback.Still, teams that perform Kanban can respond to feedback even more quickly because they don\u2019t have to wait until the next sprint planning meeting to decide what the next steps are and take action.Furthermore, because Kanban focuses on tasks rather than sprint-sized batches, it pushes responsibility to the edges of the team, meaning engineers are responsible for going after the pieces of information they need to move forward.When that happens, instead of designing features by committee, which demands a significant amount of back-and-forth discussions, decisions happen locally, and thus are easier to make.Additionally, fewer people making decisions lead to fewer assumptions. Fewer assumptions, in turn, lead to shipping smaller pieces of software more quickly, allowing teams to truncate bad paths earlier.Scrum makes estimation easierScrum shortens planning horizons by limiting batch-sizes to two week sprints. These two-week long batches are better than year-long batches because it\u2019s there\u2019s less room for error when estimation fewer tasks. Furthermore, errors become less critical because you can course-correct earlier.Still, because Scrum is a push-based system, it still requires you to do some form of estimation so that you know how large will be the batch you must push.This demand for estimations leads to unproductive and unnecessary estimation meetings. These meetings are unproductive because they cause developers to spend time debating whether something is worth two or three story points instead of actually writing code. They\u2019re also unnecessary because if you feed the system with more work as soon as software comes out, estimations don\u2019t matter.That\u2019s not to say you can\u2019t accurately estimate software tasks unless they know exactly what pieces of code must be written, in which case it would be probably better to write that code instead of thinking about it and doing useless planning.Kanban, on the other hand, is a pull-based system. In Kanban, processors pick new work items whenever they\u2019re ready for more work.Therefore, instead of having to estimate tasks, you simply focus on ensuring tasks come into the system at the same rate tasks come out. When that happens, all you need to do is prevent the system from starving, which is much easier to do than estimating tasks accurately.Scrum makes work visibleI find this reason to adopt Scrum extremely ironic. It\u2019s ironic because the way Scrum makes work visible is by adopting a Kanban board.I don\u2019t think this topic would need any further explanation because the simple fact that Kanban boards were made for practicing Kanban should be a strong enough argument. Still, it\u2019s worth highlighting that making work visible by itself doesn\u2019t make any difference if you don\u2019t actually use that visualisation to take action.In Kanban, practitioners use the board to visualise which tasks have been stuck in a particular column for too long, assess why that\u2019s happening, and either cut scope or take further action to remove the bottleneck.There\u2019s no particular structures in Scrum that incentivise that to happen because Scrum is an opaque framework. It hides from its practitioners the fact that the more items you have on the board, the longer average cycle times will be. It also offers no advice on how to handle those aging items.Scrum reduces wasteImagine you own a car factory. In that factory, there are three production stages. First, you make the vehicle\u2019s tires, then, you attach them to the car\u2019s chassis, and, finally, you assemble the body parts.If you produce tires faster than you can attach them to the chassis, you\u2019ll end up cluttering the factory floor with useless ruber. Conversely, if you can\u2019t produce tires fast enough, the chassis production will starve. The same problem would happen if you produce chassis faster than you can send them forward to assemble and attach body parts and vice-versa.In Scrum, you must ensure that each part of the process will perform uniformly throughout the whole sprint because you\u2019ll push a two-week large batch at once. Otherwise, you may create tires more quickly than you product the chassis to which you\u2019ll attach them, or produce too few tires for further stages of the process to consume.In Kanban, instead of carefully measuring each part of the process and ensuring it works uniformly, you simply focus on rate matching processes from right to left, meaning you will only start working on the next set of tires once the chassis-mounting stage has signaled its ready for more work.That way, you can dynamically adapt to problems that may happen temporarily at any part of the process. If your deployment process breaks, for example, you\u2019ll be able to focus on fixing it instead of starting new tasks and causing everything to take longer on average, both because of the sheer amount of pending tasks and because of the cost of context switching.Scrum creates cadenced meetingsIn Scrum, teams will usually have regular stand-ups, sprint planning meetings, and retrospective sessions. Except for the sprint planning meeting, those are all productive meetings to have. Still, you don\u2019t need to practice Scrum to be able to put regular meetings in everyone\u2019s calendar. Additioanlly, it may not be productive for these meetings to happen on a fixed cadence.As I mentioned before, sprint planning meetings are unproductive because they lead to \u201cdesigning by committee\u201d and focus on getting estimations right, which is not only a waste of time, but also impossible to do in a stochastic process such as software development.Daily stand-ups and retrospective sessions, however, are useful and productive.Regular daily stand-ups help teams cut scope earlier and coordinate to move aging tasks forward, keeping their cycle-times more uniform and predictable. In Kanban, these meetings become even more useful because practitioners have clearer intervention points due to setting work-in-progress limits and going through the Kanban board itself to ensure team members focus on outcomes, not implementation details.Retrospective sessions are also fundamental for a team to continuously improve the way it works. The problem with these sessions in Scrum is that they either happen too early or late. Although it\u2019s good for teams to discuss their practices and look for ways to improve them, it may not be necessary to hold a retrospective session if everything is going fantastically well. Conversely, it may be harmful to wait for two or more weeks to discuss systemic problems impacting the current pieces of work or the overall goal the team is working towards.In Kanban, there\u2019s nothing preventing teams from scheduling regular meetings. Yet, teams have the flexibility to schedule meetings whenever they\u2019re necessary.Putting it all togetherScrum is not necessarily a bad framework to adopt. It works. However, Scrum is a manager\u2019s training wheels. It helps managers get started quickly without having to spend too much time designing processes in detail. Still, Scrum prevents teams from moving as fast as they could because of its prescriptiveness.Teams could reap all of Scrum\u2019s benefits without having to adhere to its prescriptive practices which may not work for their particular scenario.Kanban is an excellent way to design those processes because it\u2019s a simpler and less-prescriptive pull-based system whose sound principles establish the dynamics for creating efficient system. In fact, those very principles are built into Scrum, and are what makes Scrum work.Teams that do Kanban can still be responsive, size work effectively, make it visible, reduce waste, and create cadenced continuous improvement and adaptative meetings.Kanban helps teams be more responsive because it allows them to respond to customer feedback and adapt to week in a time-frame shorter than two weeks.Furthermore, it enables teams to size work effectively because it relies on rate matching instead of accurate accurate estimations, which are almost impossible to do given the stochastic nature of the software development process.Such focus on rate-matching, when combined when principles such as limiting work in progress, reduces waste because it incentivises just-in-time scoping, allowing teams to create stories closer to the time at which they\u2019ll be implemented and shipped.Finally, Kanban makes work visible as much as Scrum does because the Kanban board was made, obviously, specifically for Kanban, which also determines good practices for reviewing the board and taking action.Most of Scrum\u2019s cadenced meetings, with the exception of the planning meeting are also useful. Still, teams don\u2019t need Scrum to be able to schedule regular events such as daily stand-ups. In some cases, teams may not even want to have such regular events. Retrospectives, for example, may be useless if everything is working fantastically well, and the team needs to focus on shipping a particular feature instead of meeting to say everything is going great.Wanna talk?If you\u2019d like to have a chat, you can book a slot with me here. I\u2019d love to talk about ephemeral environments, what we\u2019re building at Ergomake, or simply Agile in general.Alternatively, you can send me a tweet or DM @thewizardlucas or an email at lucas@lucasfcosta.com.",
    "summary": "- Scrum is a more prescriptive framework that can prevent teams from being as fast and dynamic as they could be, while Kanban is a pull-based system that provides sound principles, allowing managers to tailor them to their particular situation and obtain much better results.\n- Kanban amplifies Scrum\u2019s benefits, making teams more responsive, enabling them to size work effectively, reducing waste, and making work visible.\n- While Scrum\u2019s cadenced meetings are useful, such as daily stand-ups and retrospective sessions, teams don\u2019t need Scrum to be able to schedule regular events and improve their processes.",
    "hn_title": "You don't need Scrum, you just need to do Kanban right (2022)",
    "original_title": "You don't need Scrum, you just need to do Kanban right (2022)",
    "score": 341,
    "hn_content": "The author argues that switching to Kanban has improved the speed of every team he has worked on. On the other hand, Scrum has slowed them down without delivering the promised benefits. Most of the benefits of Scrum are for external reporting, which is not free since it takes time to prepare estimates, update Jira, and have retrospectives. Many people pad their estimates and report actual worked time as what they estimated to keep burn down charts straight. While estimates aren't accurate, they are necessary for planning, but they don't have to be detailed. Contractors charge based on the value they provide, not their costs and labor. Moreover, outside visibility is mostly a mirage, and the estimation stuff is only for your team, not for external consumption. Finally, the value of retrospectives depends on how senior the team is, and how seasoned managers are.Team members discuss the usefulness of retrospectives in the context of scrum and kanban methodologies. Some argue that retrospectives are a waste of time, while others argue that they are helpful for identifying areas of improvement. Kanban is suggested as a better alternative to scrum for some teams. Predictability and observability in software development are seen as important, but there are limits to what can be achieved with process. Metrics can be useful for internal use by the team, but may not always be useful for higher level decision-making. The main point of the discussion is the balance between process and flexibility in software development.The post discusses the use of Scrum and Kanban for software development teams, with some commenters noting the difficulty of estimating time frames for projects. The differences between successful and unsuccessful teams using Scrum and Kanban tends to be more centered around people, specifically team members with the right skills and motivation. Agile processes are meant to prioritize delivering value over lines of code written. However, some commenters feel that Scrum without Extreme Programming and rigorous iteration becomes a shallow process, and teams that don't constantly iterate and change direction may not find Scrum to be the best tool for the job. Some individuals believe that Scrum is better suited to service teams with requests not naturally tied to one another, while prioritizing tickets in a Kanban queue is a viable approach for other teams.A debate over whether sprints or a kanban approach is better for project management. Those in favor of sprints argue that they provide visibility into the future and allow for regular, well-defined touchpoints; whereas, kanban provides better granularity and visibility. Others argue that touchpoints can be implemented in kanban without sacrificing continuous flow. Scrum is also criticized for creating the illusion of accountability and often operates unproductively in many instances. Despite these criticisms, scrum defenders argue that it creates alignment, provides accountability, transparency, and conflict resolution, all of which are useful for stakeholders and aligning team efforts. Ultimately, the debate seems to come down to case-by-case situations and people's preferences and abilities.The article discusses the pros and cons of Scrum and its effect on team alignment, communication, and productivity. Some argue that Scrum provides a strong foundation for effective communication and team dynamics, while others argue that it can hinder it. Developers may not always follow the plan, which can be due to a lack of leadership or effective communication. The article suggests that Scrum may not be the best fit for every team and that it should be tailored to a team's needs. However, many have experienced slower productivity and lower quality when switching from Kanban to Scrum. Ultimately, the article highlights the importance of effective leadership, clear communication, and a strong foundation for successful software development.Waterfall-style development resulted in the successful deployment of a code with no bugs even after a decade of using it. The fixed requirements allowed for a fast development process and high-quality code. However, well-thought-out requirements are essential in this type of development. Customers with strong requirements are vital in creating specifications that thoroughly cover all aspects of system requirements. Agile was created for cases where requirements are uncertain, but it may not be necessary when dealing with fixed requirements. Scrum delivers more ownership to individual teams, which is beneficial for larger teams. However, it adds complexity and more emphasis on the outcomes rather than the tasks. Companies should use the appropriate approach for their projects, and even then, only the parts which are suitable for the product, team, and culture.The Tech Times article discusses the pros and cons of Scrum and Kanban methodologies. Scrum is seen as too rigid, requiring too many meetings, and being limiting in terms of flexibility. Kanban, on the other hand, allows for small teams and faster decision-making since requirements gathering and stakeholder methodology aren't prescribed. However, Kanban can lead to stalled, poorly prioritized, and overly-large tasks. Estimations are vital in prioritizing tasks, but unproductive meetings on estimations can be a waste of time. Retrospective sessions are fundamental but can either happen too early or too late. The process is less important than good project management, which can make any process work. Nonetheless, there are weaknesses with both Scrum and Kanban, and teams should find what's best for their organization.The post discusses the differences and benefits of using Kanban versus Scrum methodologies for managing work tasks. Some argue Kanban is simpler and more flexible, while Scrum is better for deadline-driven work. Both rely on visualization and regular review of work progress. Some commenters point out the importance of proper planning and documentation in both systems to avoid duplication and ensure quality. There is also some debate about the role of a scrum master and the strict adherence to certain Scrum rules. Overall, the post offers insight into the ongoing discussion among software engineers about which methodology works best for their particular situation.",
    "hn_summary": "- The usefulness of retrospectives in Scrum and Kanban is debated, with some arguing they are helpful while others find them to be a waste of time.\n- The debate between using sprints or a Kanban approach is discussed, with some arguing for the importance of regular touchpoints and others suggesting that touchpoints can be implemented in Kanban."
  },
  {
    "id": 35859338,
    "timestamp": 1683534658,
    "title": "Street Fighter II, paper trails (2021)",
    "url": "https://fabiensanglard.net/sf2_sheets/index.html",
    "hn_url": "http://news.ycombinator.com/item?id=35859338",
    "content": "FABIEN SANGLARD'S WEBSITEABOUT EMAIL RSS DONATEDec 22, 2021STREET FIGHTER II, PAPER TRAILSThe late 90s saw the emergence of Capcom in the world of arcades. The Osaka based company seemed to produce one hit after another with Ghouls'n Ghosts in 1988, Final Fight in 1989 and Street Fighter II in 1991 among a myriad of other excellent games.During this era, a video-game enthusiast could not go to an arcade without seeing multiple Capcom cabinets, proof of their popularity with both players and operators.Over the past six months, I have spent my spare time studying Capcom success stories and in particular the genesis of Street Fighter II. If discovering the engineering behind the CPS-1 was fascinating, I found the side story of how developers tracked ROM budget using paper and scissors equally interesting.CP-SYSTEM 101Introduced in 1988, the CPS-1 (a.k.a CP-System at the time) was Capcom unified arcade platform. Among its many innovations was a powerful graphic rendering pipeline.If it still embraced the concept of layers, the CPS-1 abandoned the constraint of rectangular sprites. The OBJ layer is built via 16x16 units called \"tile\". In Street Fighter II, tiles are combined to make character poses. This approach gave considerable freedom to the artists who proceeded with designing \"objects\" of arbitrary sizes and shapes.Ryu's victory pose (29 tiles) Sagat's Tiger Uppercut pose (30 tiles) Honda's Jump pose (45 tiles) Chun-li being awesome pose (25 tiles)Besides a few basic operations such as horizontal and vertical flipping, the CPS-1 cannot alter tiles. It has no rotating or scaling capabilities. What made the machine stand out was the sheer volume of tiles it could manipulate per frame, reported to be in the vicinity of 256.It was a real tour-de-force at the time to make so much of the screen move. The \"wow\" factor immensely contributed to the success of the games. In a game like \"The Punisher\", the kingpin final boss is made of poses reaching up to 80 tiles.\"The Punisher\" screen can be almost covered with sprites (Source: rq87.flyingomelette.com).ROM BUDGETIf the CPS-1 capabilities were a blessing for artists, it was a problem for project managers. In an era where ROM chips were very expensive, a game was allocated a ROM budget at its beginning which it could not exceed.Before the CPS-1, remaining within the budget was a simple matter of a division. The number of #sprites allowed to the art team was ROM size / rectangular sprite size. But the free form factor introduced a tracking problem.THE SHEET SYSTEMThe solution came under the form of paper sheets and scissors.In order to make the best use of the capacity we had, we wrote the ROM\u2019s capacity on a board, and cut and paste the pixel characters on the board.If there was space left on the board, then there was open capacity in the ROM. So, from there we started filling in the spaces, like a puzzle.One thing that happened that\u2019s kinda interesting, we saved making the ending for last, and by the time we got there we were all out of capacity. We were wondering what to do, when we found a board that had gone missing under a desk.We called it the \u201dMirac-ulous Memory.\u201d- Akira Nishitani, SF2 development interviewA blank sheetSince the CPS-1 uses 16 indexed colors (4-bit per pixel), a sheet of 16x16 tiles represents 16x16x16x16 / 2 = 32 KiB. For a game such as Street Fighter II: World Warrior, the team allocated 4.6 MiB out of its 6 MiB ROM budget to sprites and therefore printed 144 paper sheets.SHEETS ARCHEOLOGYThis system is a golden opportunity for a software archaeologist. Among other things one can see which features were added later (these would be implemented using left-over space and therefore less elegantly cut out).Unfortunately, I was only able to come across two of them. I found a Dhalsim in the article \"Final Fight Developer's Interview\"[1] and a Ryu in the book \"How To Make Capcom Fighting Characters\"[2].Sheet 0x3300 Sheet 0x4500Notice the tile addressing system in the upper left of each sheet (Dhalsim 0x3300 and Ryu 0x4500). The first two hex characters give a value [0-255] which is the sheet ID while the two remaining are the tile ID within that sheet.Also notice how the sheet tiles are rectangular instead of square. The CP-System uses a resolution of 384\u00d7224 which aspect ratio differs from the 4:3 aspect ratio of a CRT. Had designers drew in squares, the result would have been compressed on screen. By drawing in rectangles, they essentially reverse-stretched the visual assets so tiles would be displayed as they were drawn. This non-square pixel system was a nightmare for the art team.When I was working on Forgotten Worlds, I noticed the problem of aspect ratio. \"The pixels are not square!\" I told my boss.\"Impossible, I ordered them to be square!\" he replied and called hardware on the spot.\"The pixels are square!\" he replied.Later I protested again to which my boss replied it was a calculation error.- Akira Yasuda, SF2 producer[3])It was disappointing to see that only two sheets had come out but it was possible to reconstruct them using the imprint left in the ROM. Thanks to mame and sf2platinium providing the GFX-ROM format, a tool[4] was written to automate the process. With all the sheets reconstructed, it was analysis and hypothesis time.EXPLORING THE SHEETSThe CPS-1 works with four layers. The OBJ layer of Street Fighter II is made of 144 sheets totaling 4.6MiB. The remaining 1.4MiB is used for the background and frontground layers called SCROL1 (16 sheets), SCROL2 (8 sheets), and SCROL3 (23 sheets).The most byte-heavy characters are Zangief (19), followed by Honda (15), Dhalsim (14, he is slim but stretches a lot!), Blanka (15), Ryu (13.5), Guile (11), Chun-li (10), Dictator (9, his cape takes a whole sheet!), Sagat (6), Boxer (6), Claw (6), and Ken (3).The first sheet features, without surprise, the main protagonist Ryu.Notice how Ryu's top hair for 0x69/0x6A was placed at 0x6F/0x9F in order to not disturb the layout. Why the hair of the top left pose is offsetted is unknown. Could it be that GFX ROM address 0x0000 could not be used? Analyzing other games also showed that tile 0x0000 was never used.KEN IS A PATCH                Ryu palette                Ken paletteLooking at the pie chart, we can see that Ken character is consuming an impossibly small amount of three sheets.That is because Ken is a patch on top of Ryu tiles. Ryu palette is specially designed to be skin tone compatible with Ken. Only the clothes and face colors differ.The patching is obvious on sheet 0x0100 where Ryu's winning pose 0x76 is next to Ken 2x2 patch at 0x70.Ken's victory pose starts with Ryu's pose. The palette is changed and only differing tiles are used. Notice how Ryu's teeth white color comes from his clothes. For Ken, artists had to reuse some of the skin color because Ken's Gi is red.HUNTING CRUMBLESIn sheet 0x4700 (\"Ken is patch\" section), we can see a 2x2 portrait at 0xC0 that is not a fighter. This is in fact the picture of the development team. They are featured in the credit at the end of the game. Notice how it features neither accurate pictures nor give real names. Likely done so to avoid talent poaching.Fun fact: \"NIN\" is the alias of Akira Nishitani who was a producer at Capcom. It was used for all high scores in all games he worked on including Forgotten Worlds, Final Fight, and Street Fighter 2.NO SMALL SAVINGDevelopers seem to have been so short on ROM that they even used partial pose symmetry. In 0x4E00, Sagat's left leg is missing at 0xBA. To draw it, the CPS-1 is instructed to use the right leg tiles and flip them horizontally.DHALSIM (0X3300) SHEET DIFFERENCESDhalsim reconstructed sheet is a near perfect match. Although we can see that the pose outlined in red did not make the cut. It was sacrificed to Chun-li's \"Hundred Rending Legs\" which would indicate it was a later addition. At 0x4C we can see crumble space was allocated to Blanka.RYU (0X4500) SHEET DIFFERENCESSimilar differences can be seen in Ryu's sheet. Two poses (at 0xC2 and 0xCC) were deleted before shipping to accommodate Chun-li's \"Spinning Bird Kick\" (a move also added at the end of development?) and the team credit portraits.FOR HOW LONG WAS THE SHEET SYSTEM USED?With powerful workstations such as the X68000 around at the time, I always wondered for how long the sheet system was used before a tool was written to compile the GFX assets. With the ability to look at other game sheets, it was possible to make a rough estimate.The first destination was to visit all games made by the same team starting with titles released prior to SF2, Forgotten World and Final Fight. Although I did not take the time to locate the palettes and used a default greyscale, it was still possible to see shapes distinctively.Forgotten World sheet (1988)Final Fight sheet (1989)Without surprise, the same structure was found. Later games such as Street Fighter 2: Champion Edition and Street Fighter 2: Hyper Fighting were also checked. The GFX received minimal improvements[5] and the sheet structure remains unchanged.Street Fighter 2: Champion Edition (1992)Street Fighter 2: Hyper Fighting sheet (1992)OTHER CAPCOM TEAMSCapcom had several titles produced in parallel by different teams. Checking other teams' work responsible for Ghouls 'n Ghosts and Strider showed once again the same process albeit less crammed.Ghouls 'n Ghosts sheet (1988)Strider sheet (1989)NON-CAPCOM GAMESSome CPS-1 games were not produced by Capcom. This was the case for Pang-3 by Mitchell Corporation. Once again, no changes.CPS-2 AND SUPER STREET FIGHTER 2It seems like the sheet system was in effect for most if not all CPS-1 games. Looking at CPS-2 games was a bit more difficult since Capcom added many protection mecanisms. While the 68000 instructions and Z-80 instructions were encrypted, the GFX ROMs are merely shuffled and easily viewable.In the first CPS-2 title, Super Street Fighter 2 (1993), four new characters were added to the existing twelve roster. The existing character sheets are unchanged.Super Street Fighter 2 Ryu sheet (1993)Super Street Fighter 2 Cammy sheet (1993)But if we look at Cammy sheets (0x9000) the layout was clearly not made by hand. It seems an allocation system proceeding top to bottom and left to right was used instead. It seems like Capcom started using tools to build new GFX ROMs for SSF2 circa 1992. Whether x68000 workstations were used remains unknown.STREET FIGHTER ALPHAMoving forward with CPS-2 titles, Street Fighter Alpha (1995) and Street Fighter Alpha 3 (1998) both show the same type of structure indicative of a tool. All sheets look like mashed potatoes without any wasted tile space. It is likely that none of the CPS-2 titles used the sheet system.Street Fighter Alpha sheet (1995)Street Fighter Alpha 3 sheet (1998)CALL FOR INTERVIEWI have made several attempts to talk with developers who worked on CPS-1/CPS-2 systems. All of them have failed so far. I would like to document and preserve how these machines were programmed. I am especially interested in knowing how the X68000 was used. If you have first hand experience or if you can get someone in touch with me, please email me :) !REFERENCES^ [1] Final Fight Developer's Interview^ [2] How To Make Capcom Fighting Characters^ [3] Akiman's Twitter account^ [4] Tool CPSheet^ [5] Differences Between SF2 World Warrior and SF2 Champion Edition*",
    "summary": "- The article discusses the use of a paper and scissors system to track ROM budget in the creation of Street Fighter II using the CPS-1 arcade platform in the late 90s.\n- The CPS-1 platform had powerful graphic rendering capabilities but limited rotating and scaling functions, which presented a challenge for project managers in allocating a ROM budget.\n- Software archaeologists can reconstruct the paper sheets to analyze characters and features added later, with the sheet system being used for most CPS-1 games and gradually replaced by tools in later platforms like CPS-2.",
    "hn_title": "Street Fighter II, paper trails (2021)",
    "original_title": "Street Fighter II, paper trails (2021)",
    "score": 339,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginStreet Fighter II, paper trails (2021) (fabiensanglard.net)339 points by tangue 1 day ago | hide | past | favorite | 37 commentsyamazakiwi 17 hours ago | next [\u2013]> Notice how Ryu's teeth white color comes from his clothes. For Ken, artists had to reuse some of the skin color because Ken's kimono is red.That's interesting that I never noticed the slight differences in color on the teeth given their restrictions.Also... Ken is wearing a Gi, not a Kimono. Kimono does literally mean \"thing to wear\", but a Gi is the training clothes pictured in Ken's model.replyfabiensanglard 17 hours ago | parent | next [\u2013]Thank you for the clarification, I had no idea. Fixed it.replyyamazakiwi 15 hours ago | root | parent | next [\u2013]Overall this is an excellent write-up and I enjoyed reading it very much! Thanks for the reply!replythrdbndndn 23 hours ago | prev | next [\u2013]Previous discussion:https://news.ycombinator.com/item?id=29657343Street Fighter II paper trails \u2013 allocating sprite space by hand (December 23, 2021 \u2014 554 points, 76 comments)replyfabiensanglard 17 hours ago | prev | next [\u2013]If you enjoyed the topic of CP-System games, there is now a whole book about it.https://fabiensanglard.net/cpsb_paper/replymisterprime 16 hours ago | prev | next [\u2013]The end of the article speculates that the sheet system was dropped since the tiles appear scrambled. I'm wondering if the artists still used the sheet system, but a memory optimizer tool re-ordered the tiles to help free up a little more space on the ROM.replyduskwuff 13 hours ago | parent | next [\u2013]> I'm wondering if the artists still used the sheet system, but a memory optimizer tool re-ordered the tiles to help free up a little more space on the ROM.Seems unlikely. Managing the \"physical\" layout of sprites on a sheet is a lot of work; there's no reason to do that if it's going to be thrown out by an optimizer in the end.Besides, notice that, on the optimized SF2 sheet, all of the tiles for one sprite get written out in order; they aren't interleaved left-to-right like the tiles would have been on a sheet.replyfredoralive 14 hours ago | parent | prev | next [\u2013]The way Super Street Fighter II has a mix of methodologies seems to count against that. Why only run this optimiser on the new art?I could see artists might still use a grid when sketching and planning to keep a handle on sprite size / memory usage. But not in the hand packed sort of way, more just each sprite drawn unscrambled on a grid. You wouldn't go through all the rigmarole of hand optimising memory layouts if some stage in the build system is going to ignore it and do its own thing instead.replyDwedit 11 hours ago | root | parent | next [\u2013]Because if you change the tiles, you need to redo all the tile number tables throughout the program. Much easier to only change it for new graphics added to the game than to rework a bunch of old stuff that works.replyDwedit 14 hours ago | prev | next [\u2013]Also see: Street Fighter II, The World Warrierhttps://fabiensanglard.net/sf2_warrier/index.htmlreplyairstrike 12 hours ago | parent | next [\u2013]That is an awesome read as well, thanks for sharing!replyxdavidliu 12 hours ago | parent | prev | next [\u2013]to save people some clicking, the word \"Warrier\" here is in fact misspelled intentionally by the article, which discusses how it was misspelled unintentionally by one of the original graphic designers of the game.replyai_ja_nai 23 hours ago | prev | next [\u2013]Fabien Sanglard is an ace, his 3dfx posts are legendary. Very enjoyable readingreplywdr1 10 hours ago | parent | next [\u2013]+1I very much enjoyed his Game Engine Black Books on Wolfenstein 3D & Doom.replycollenjones 17 hours ago | parent | prev | next [\u2013]His books are all also fantastic value!replypsychphysic 23 hours ago | prev | next [\u2013]I played this game to death on my megadrive (genesis) and now occasionally plate third strike.So amazing to see a bit of street fighter history and funny I'd never noticed Ken's jaundiced eyes and teeth!replylostgame 20 hours ago | parent | next [\u2013]The only gaming console I still own is a SEGA Saturn - and a burned copy Street Fighter 2 Alpha practically lives in the disc tray. (I use an Action Replay cartridge solution for booting burned discs called \u2018Pseudo Saturn Kai Lite\u2019.)I am fortunate enough to have a live-in music studio, and it actually lives attached to the secondary monitor in the studio for us to take breaks on and do a few fights to decompress. Pretty much never fails to be a hit.replyRunSet 13 hours ago | root | parent | next [\u2013]Just in case your Saturn ever dies the arcade version is well emulated by Final Burn.https://github.com/finalburnneo/FBNeo/releaseshttps://archive.org/download/2020_01_06_fbn/roms/arcade.zip/...replypsychphysic 15 hours ago | root | parent | prev | next [\u2013]Amazing! Absolutely love the alpha series too.I only briefly had a Saturn and Virtua Cop series is still one of my most intense memories. A light gun game at home with graphics that looked like the arcade to my childhood eyes!I wonder if kids these days will look back on the ps5 similarly hard to imagine!replybluedino 15 hours ago | prev | next [\u2013]With today's 100GB game downloads, it's easy to say that developers gave up on these kinds of tricks.But they have to be doing something (other than data compression), right? Otherwise we'd be seeing 500GB downloads?replyturtledragonfly 15 hours ago | parent | next [\u2013]Tricks for packing data are still relevant today, though obviously hardware has changed so the tricks are different. One important concept on today's machines is that memory latency is huge relative to the cost of executing other instructions (eg: arithmetic, logic). In some senses, such packing has become even more important as time has gone on. There was a point in history when memory operations and ALU operations were about the same speed, so it made sense to keep even small computations in memory, and retrieve them later (eg: a lookup table, possibly pre-computed). Nowadays, it is often faster to re-compute values from scratch when needed, rather than going to memory, even for biggish computations.In today's world, the GPU largely deals with textures, but the same rule holds \u2014 it can make sense to compute values rather than doing texture fetches. Anyway, I'd say your instinct is right \u2014 developers are still using lots of tricks to get things where they are. There is still a lot of competitive pressure to provide more, more, more and squeeze the most out of the hardware.All that said, the 100GB download is often going to be audio/video. Then probably textures. There is certainly standard compression going on for a lot of that. But not the sort of manual \"these texels go here, those texels go there\" fiddling of data like described in this article. Though UV unwrapping is still and art and a science (:replyBearOso 8 hours ago | parent | prev | next [\u2013]Part of the size problem in the last generation was because of duplication of assets to load faster from spinning hard drives. They bundled assets for level loads sequentially because it's quicker to have all the assets inline instead of seeking all over the place.I imagine when the HDD-era engines are end-of-lined we'll get a slight shrink, but it'll probably be eclipsed by the growing number of high resolution assets pretty quickly.replydjur 15 hours ago | parent | prev | next [\u2013]Data compression is really good these days, and there are file formats and compression strategies that are optimized for gaming. The specific technique being used here is still used in 2D games, but there are spritesheet optimization tools available to do it automatically.My understanding is that for the biggest games there's an intentional tradeoff to use more storage in exchange for faster load times, although the need for that has apparently lessened over time. If you go back and look at some of the big multi-disc games of the late '90s/early '00s you might be shocked by how much duplication there was in order to reduce the need for disc swapping. (You might also be shocked by how much of that disc space was required solely to support pre-rendered cutscenes.)replyracl101 12 hours ago | parent | prev | next [\u2013]Games are also way bigger these days. It may not feel like they're trying but they probably are.replyCTDOCodebases 23 hours ago | prev | next [\u2013]I like how they recycled sprites from other games like Final Fight e.g the burning body sprite that Dhalsim triggers.replykaptain 21 hours ago | prev | next [\u2013]Can someone help with the math? Why do they divide by two to calculate the memory size of the sheet? Thanks!replybeached_whale 20 hours ago | parent | next [\u2013]Each pixel was 4bits(1/2 byte), and memory is in bytesreply0xcde4c3db 20 hours ago | parent | prev | next [\u2013]Each pixel is stored as a 4-bit index, so 2 pixels per byte.reply592528368 2 hours ago | prev | next [\u2013]Okreplyrikthevik 16 hours ago | prev | next [\u2013]I love it! Thanks for putting this together.replypm2222 22 hours ago | prev | next [\u2013]https://youtube.com/@QuanZhenyouxijieshuo Plenty channels like this one. Surprised to find that Zangief can be so strong.replytiffanyh 21 hours ago | prev [\u2013]Monospace fonts + Justified alignment, are the two biggest contributing factors to reduced readability.Just because it looks pretty, doesn\u2019t means it\u2019s good UX.replycubefox 21 hours ago | parent | next [\u2013]I find monospace fonts surprisingly readable, but the font size is too small on smartphones, and yeah, the alignment is off.replytangue 16 hours ago | parent | prev | next [\u2013]We\u2019re in 2023. Use reader mode.replyaflag 19 hours ago | parent | prev [\u2013]I feel like that is a myth. Most people I know use monospace fonts for programming.replytiffanyh 18 hours ago | root | parent [\u2013]For programming, correct.But long form essays - it's super difficult.Braille Institute is an authority research group in this space and they development their own font that achieves maximum readability.That font is NOT a monospace font, because the found it too difficult to read in long-form. It's a proportional font.https://brailleinstitute.org/freefontreplyaflag 17 hours ago | root | parent [\u2013]That font seems to be designed for low vision readers. I'm not sure if you can extrapolate that to people without any sort of vision issues. I mean, I can read the essay just fine, and I don't find it particularly hard to read or anything. If anything, given that I'm already used to reading monospaced fonts all day, I think I can probably read it faster than if it was a font that I'm less familiar with.replyApplications are open for YC Summer 2023Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Discussions on artists' subtle decisions when designing character sprites, including color choices and reused assets from other games.\n- Speculations on whether memory optimizer tools were used and how they affected sprite allocation and arrangement."
  },
  {
    "id": 35859877,
    "timestamp": 1683540051,
    "title": "KeePassXC pull request to add basic support for WebAuthn",
    "url": "https://github.com/keepassxreboot/keepassxc/pull/8825",
    "hn_url": "http://news.ycombinator.com/item?id=35859877",
    "content": "Skip to contentProductSolutionsOpen SourcePricingSign inSign upkeepassxreboot/keepassxcPublicSponsorNotificationsFork 1.2kStar 15.8kCodeIssues613Pull requests30DiscussionsActionsProjects1WikiSecurityInsightsNew issueAdd basic support for WebAuthn #8825Openvarjolintu wants to merge 3 commits into keepassxreboot:developfrom varjolintu:feature/support_webauthn+2,204 \u221246Conversation 4Commits 3Checks 0Files changed 28ConversationMembervarjolintu commented on Nov 21, 2022Nov 21, 2022 \u2022editedAdds basic WebAuthn support to KeePassXC. Currently it uses the default Elliptic Curve key (EC2, ES256 signature, P-256 curve), 2048-bit RSA key, and basic registration/authentication with User Verification enabled and the default none Attestation. Optional extensions credProps and uvm are supported in the registration phase. Timeouts are respected, and a new confirmation dialog is added for them.Qt's CBOR libraries requires at least Qt 5.12, and for that reason a new CMake configuration parameter WITH_XC_BROWSER_WEBAUTHN is added.At registration phase a new credential is stored to KeePassXC with the following information:Generated private key for the credential is stored as attachment with the name \"webauthn.pem\". Can be exported and imported normally.Generated User ID is stored as the entry password.Username and URL fields are set normally.Authentication phase:Supports all User Verification options. Single entry with discouraged is returned immediately.Stored credentials are retrieved only when the webauthn.pem key file is present. User ID and URL domain must also match.What is not working / is missing / won't be implemented:Some extensions are still missing (authentication doesn't support them at all, yet).Support for Resident Key.Support for triggering unlock from extension.Support for root certificates.Support for PIN/TouchID when authenticating.What is not tested:Support for Passkeys (in theory some sites should work, needs at least Chrome 108 for testing it).Exporting credentials and private key to other password manager and testing that it works (does any of them support this kind of feature yet?).What needs to be discussed:How to actually import and export full credentials? Now the process is semi-manual because only the private key attachment can be used. There is no standard way to proceed with this.Related extension PR for the feature: keepassxreboot/keepassxc-browser#1786Documentation: https://w3c.github.io/webauthn/Fixes #1870.ScreenshotsRegister new credentials:Authenticate existing:Testing strategyAutomated tests are written with a valid data captured from a real registration and authentication.The following sites can be also used for testing the feature:https://webauthn.iohttps://webauthn.me/debuggerhttps://webauthn.lubu.ch/_test/client.htmlhttps://demo.yubico.com/webauthn-technical/registrationType of changeNew feature (change that adds functionality)56goetzc, alensiljak, JLP, garymoon, waspoza, tve, pabs3, smurfix, HLeithner, TAG-Epic, and 46 more reacted with thumbs up emoji26sm1999, Ajedi32, goetzc, Rakambda, garymoon, pabs3, bossley9, lapo-luchini, connerturner, julled, and 16 more reacted with hooray emoji35sm1999, zroug, cnmicha, tgurr, Be-ing, JLP, garymoon, waspoza, nagromc, yasammez, and 25 more reacted with heart emoji15darkdragon-001, garymoon, HLeithner, foss-, szszszsz, Asmial, protortyp, teddybear, zehhu, aaossa, and 5 more reacted with rocket emoji3tve, ColCh, and wmehilos reacted with eyes emojivarjolintu added new feature feature: Browser labels on Nov 21, 2022Nov 21, 2022varjolintu added this to the v2.8.0 milestone on Nov 21, 2022Nov 21, 2022This was referenced on Nov 21, 2022Nov 21, 2022Add support for WebAuthn keepassxreboot/keepassxc-browser#1786OpenFeature Request: Integration with the Web Authentication API #1870Openvarjolintu mentioned this pull request on Dec 10, 2022Dec 10, 2022Support for passkey #8214OpenMemberAuthorvarjolintu commented on Dec 11, 2022Dec 11, 2022Support for 2048-bit RSA private key added.J-Jamet mentioned this pull request on Jan 29Jan 29, 2023Support for Passkeys Kunzisoft/KeePassDX#1421Opensmurfix commented 3 weeks agoApr 17, 2023Woo hoo. :-)Any progress on this?5txtsd, hlandau, skar395, garymoon, and matteing reacted with thumbs up emojithomasmerz commented yesterdayMay 8, 2023Support for 2048-bit RSA private key added.\"As of 2020, it is not known whether such keys can be cracked, but minimum recommendations have moved to at least 2048 bits. link\"20xpr03 and fionn reacted with thumbs down emojiAdd basic support for WebAuthnf6e8191varjolintu force-pushed the feature/support_webauthn branch from 003809d to eb11e04Compare14 hours agoMay 8, 2023 19:54Add support for 2048-bit RSA key7fae36dvarjolintu force-pushed the feature/support_webauthn branch from eb11e04 to 7fae36dCompare14 hours agoMay 8, 2023 20:02MemberAuthorvarjolintu commented 13 hours agoMay 8, 2023 \u2022editedWoo hoo. :-)Any progress on this?Just rebasing and trying to solve all new compilation problems on CI.. :) Special thanks to Homebrew for removing support for Botan 2. Luckily support for Botan 3 was fixed recently.5garymoon, 0xpr03, a-b, nagromc, and hex-m reacted with heart emojiheadllines bot mentioned this pull request 9 hours agoMay 9, 2023Hacker News Daily Top 10 @2023-05-09 headllines/hackernews-daily#1028Opengithub-actions bot mentioned this pull request 9 hours agoMay 9, 20232023-05-08 Hot Posts jiacai2050/hot-posts#277OpenFix building with Botan 3bda9f60varjolintu force-pushed the feature/support_webauthn branch from 9090394 to bda9f60Compare4 hours agoMay 9, 2023 05:20github-actions bot mentioned this pull request 3 hours agoMay 9, 2023Hacker News Daily Top 30 @2023-05-09 meixger/hackernews-daily#233OpenSign up for free to join this conversation on GitHub. Already have an account? Sign in to commentReviewersNo reviewsAssigneesNo one assignedLabelsfeature: Browsernew featureProjectsNone yetMilestonev2.8.0DevelopmentSuccessfully merging this pull request may close these issues.Feature Request: Integration with the Web Authentication API3 participantsFooter\u00a9 2023 GitHub, Inc.Footer navigationTermsPrivacySecurityStatusDocsContact GitHubPricingAPITrainingBlogAbout",
    "summary": "- KeePassXC has added basic support for WebAuthn through a pull request.\n- This support uses the default Elliptic Curve key (EC2, ES256 signature, P-256 curve), 2048-bit RSA key, and offers basic registration/authentication with User Verification enabled and the default none Attestation.\n- Some extensions are still missing, and support for Resident Key, triggering unlock from extension, root certificates, and PIN/TouchID when authenticating is not yet available.",
    "hn_title": "KeePassXC pull request to add basic support for WebAuthn",
    "original_title": "KeePassXC pull request to add basic support for WebAuthn",
    "score": 323,
    "hn_content": "KeePassXC has submitted a pull request to add basic support for WebAuthn, which could allow passkeys to become a viable alternative to passwords. Passkeys are not tied to a device, biometrics, or a proprietary ecosystem, and an open version is available that's portable across devices and browsers. However, support for platform authenticators and compatibility with other platform authenticators remains an issue, and more guarantees are needed that attestation won't be used to block KeePassXC as an authenticator. Apple has removed anonymous attestation services with the introduction of Passkeys in iOS 16, which could make it impossible for any service to block anonymous attestation. An industry standard for criteria that a passkey manager must meet could solve the issue, or attestation could just not be a part of the WebAuthn spec.No meaningful content.The post discusses the potential risks and benefits of attestation in the FIDO WebAuthn standard. Some argue that attestation could be used for malicious purposes and lead to more DRM, while others believe it adds a necessary layer of security. Apple's practice of zeroing out attestation for its devices may nullify its use in practice. The idea of portability, where users can export their keys to any authenticator, is discussed, but it may not be feasible under the current standard. The FIDO Alliance is urged to address this issue. Overall, the post offers a nuanced perspective on the implications of attestation in WebAuthn and the potential impact on user privacy and security.The author argues about the harm caused by the lack of portability in FIDO authentication, blocking login and limiting key usage to particular ecosystems, leading to vendor lock-in and user abuse. Although attestation is necessary for WebAuthn, it enables abusive uses of technology, like tracking user data, and its acceptance by web browsers could encourage DRM practices. The argument favors multi-platform use, greater transparency and privacy, and user interest over vendor interests. Despite this, multi-platform, open-source solutions already exist and show promise for adoption. The FIDO Alliance must coordinate a solution to allow seamless interoperability between different authenticators and platforms. Addressing portability issues will make FIDO authentication a successful and accessible standard for users, promoting stronger security measures, increased privacy protection, and user freedom.Google, Microsoft, and Apple are introducing \"passkeys\" or \"passwordless\" authentication that allows users to log in without a password. Instead, users will use device and biometric authentication, with biometrics performed on the device. The device for this method could be a smartphone or Windows PC with a TPM, or for a small number of users, a biometric yubikey. Passkeys sync with the user's cloud account, so if the user loses their device, they can retrieve their credentials to access their account from a new device. Passkeys encrypt a user's credentials, which reduces phishing risks and replaces traditional passwords with cryptographic keys. Critics argue that the passkeys system favours centralisation and vendor lock-in, with passkeys pushing users towards using a specific provider.1Password is implementing Passkey support and cross-platform Passkeys should exist soon.\nThe spec needs to support interop better with formal import/export support.\nMost users won\u2019t export or back up their keys.\nPeople want things to be simple, but simplistic solutions like buying another phone because you lost your Google account password shouldn't be necessary.\nPasskey is designed as a replacement for passwords, but even the downsides affect ordinary people as well.\nIf passkeys are going to be a replacement for passwords, they have to handle all of the use cases and build import & export into the spec. \nThe US Federal Government got rid of passwords in 2004 by using smart cards issued by approved issuers; they are certificate-based, so if you lose your card, another one can be issued to you with the same properties on the certificate.Users are reporting lockouts from their Google and Meta accounts, potentially triggered by bad actors. The lack of transparency and redressal processes from big providers is not tenable and leads to a lack of accountability. The failure rate may be small, but it still has human consequences. Centralization is not the scariest problem \u2013 it is the lack of recourse when things go wrong. WebAuthn and passkeys have potential for abuse, especially if attestation is required. Attaining more privacy-preserving qualities in attestation is necessary. Users express concern about vendor locking and centralization of authentication in the hands of a few megacorps. However, FIDO/WebAuthn is not solely implemented by Google or Microsoft, and some sites self-host it. Users desire to own their authentication keys themselves rather than trusting mega-corporations.Passkeys are similar to SSH keys and can be obtained from different vendors, but authenticating websites can choose to only allow a few vendors to log in. Implementations with the secret hidden behind an HSM and made by smaller companies that care about security are likely to be rejected. Apple doesn't support attestation in their implementation of passkeys. A parsing error can prevent users from decrypting passwords on Android's OpenKeychain, and newer versions of GPG may have changed the format of the ciphertext that bouncy castle version OpenKeychain uses. Attestation certificates contain detailed information about the device that signed them, and nothing stops services from limiting accepted devices to only those approved by the passkey gang. While some people have accepted the situation, others are still fighting.Discussion on using passkeys for authentication and its potential impacts on privacy and user choice among big corporations. Commentary on the benefits of KeePassXC as a password manager. Some concerns raised about mobile app compatibility and syncing. No major announcements or releases.- Users recommend Syncthing and KeePassDX/2Android for cloud-less data synchronization and efficient password management on Android, respectively.\n- The open-source community seems to have beaten commercial password managers in implementing WebAuthn, with KeePassXC usage as a WebAuthn device for logins.\n- Bitwarden only supports WebAuthn for vault logins for paid accounts.\n- 1Password already has a beta/demo of WebAuthn implementation. \n- Passkeys are random data and cryptography, but popular implementations use TouchID/FaceID/Passcode for protection.",
    "hn_summary": "- The post discusses the potential risks and benefits of attestation in the FIDO WebAuthn standard, with different opinions on its use for user privacy and security.\n- Passkeys are being introduced by major tech companies, but critics argue that the system promotes centralization and vendor lock-in, and a more interoperable approach is needed."
  },
  {
    "id": 35867935,
    "timestamp": 1683585913,
    "title": "Ancient Greek terms worth reviving",
    "url": "https://classicalwisdom.substack.com/p/12-ancient-greek-terms-that-should",
    "hn_url": "http://news.ycombinator.com/item?id=35867935",
    "content": "Discover more from Classical WisdomA Newsletter Dedicated to Bringing Ancient Wisdom for Modern Minds. Enjoy the Classics and the love of learning in your inbox. Subscribe to our FREE bi-weekly newsletter and receive our \"Guide to the Greek Gods\"!Over 52,000 subscribersSubscribeContinue readingSign in12 Ancient Greek Terms that Should Totally Make a ComebackEudaimonia, Arete, and much more...CLASSICAL WISDOMMAY 2, 2023876ShareDear Classical Wisdom Reader,Learning Ancient Greek can be\u2026 challenging.For one thing, there are competing dialects (as was discussed in our Podcasts with the Professor of Linguistics at the University of Cyprus.) As such, there are times when we aren\u2019t even sure how the word is pronounced.There are also like 5 different translations for every word, which gives translators a huge artistic license, truth be told. Just look at the huge variety of translations of the first line of The Odyssey! There are over 70\u2026 and man oh man do they change the tone of the epic, to say the least.Indeed, it can be difficult to decide which version of the word the author intended because we just don\u2019t think exactly like ancient Greeks. The huge differences in time and culture can make it tricky to figure out what they really meant.So while actually dedicating years to learning this beautiful and complicated ancient language might not be the most practical use of your time, I do think you should at least learn a few of the most important concepts.In fact, I reckon these 12 terms should definitely make a comeback in our current society\u2026 and that we might be a lot better for it\u2026 check them out below and let me know if you agree.Enjoy!All the best,Anya LeonardFounder and DirectorClassical Wisdom and Classical Wisdom KidsShare12 Ancient Greek Terms that Should Totally Make a Comeback1. Eudaimonia (Greek: \u03b5\u1f50\u03b4\u03b1\u03b9\u03bc\u03bf\u03bd\u03af\u03b1)Eudaimonia is regularly translated as happiness or welfare; however, \u201chuman flourishing or prosperity\u201d and \u201cblessedness\u201d have been proposed as more accurate translations. In Aristotle\u2019s works, eudaimonia was used as the term for the highest human good, and so it is the aim of practical philosophy, including ethics and political philosophy, to consider (and also experience) what it really is, and how it can be achieved.2. Arete (Greek: \u1f00\u03c1\u03b5\u03c4\u03ae)Arete in its basic sense, means \u201cexcellence of any kind\u201d. The term may also mean \u201cmoral virtue\u201d. In its earliest appearance in Greek, this notion of excellence was ultimately bound up with the notion of the fulfillment of purpose or function: the act of living up to one\u2019s full potential.In the Homeric poems, Arete is frequently associated with bravery, but more often with effectiveness. The person of Arete is of the highest effectiveness; they use all their faculties\u2014strength, bravery, and wit\u2014to achieve real results. In the Homeric world, then, Arete involves all of the abilities and potentialities available to humans.The Choice of Hercules by Carracci, 1596. Depicts Hercules deciding between Vice (right) and Virtue, or Arete (left)In some contexts, Arete is explicitly linked with human knowledge, where the expressions \u201cvirtue is knowledge\u201d and \u201cArete is knowledge\u201d are used interchangeably. The highest human potential is knowledge and all other human abilities are derived from this central capacity.3. Phronesis (Greek: \u03c6\u03c1\u03cc\u03bd\u03b7\u03c3\u1fd0\u03c2)Phronesis is a type of wisdom or intelligence. It is more specifically a type of wisdom relevant to practical action, implying both good judgement and excellence of character and habits, or practical virtue. As such, it is often translated as \u201cpractical wisdom\u201d, and sometimes as \u201cprudence.\u201d Thomas McEvilley has proposed that the best translation is \u201cmindfulness\u201dShare4. Kleos (Greek: \u03ba\u03bb\u03ad\u03bf\u03c2)Kleos is often translated to \u201crenown\u201d, or \u201cglory\u201d. It is related to the word \u201cto hear\u201d and carries the implied meaning of \u201cwhat others hear about you\u201d. A Greek hero earns kleos through accomplishing great deeds.Kleos is invariably transferred from father to son; the son is responsible for carrying on and building upon the \u201cglory\u201d of the father. This is a reason for Penelope putting off her suitors for so long, and one justification for Medea\u2019s murder of her own children was to cut short Jason\u2019s kleos. Kleos is sometimes related to aidos \u2014 the sense of shame.5. Xenia (Greek: \u03be\u03b5\u03bd\u03af\u03b1)Xenia means \u201cguest-friendship\u201d and is the concept of hospitality. It includes the generosity and courtesy shown to those who are far from home and/or associates of the person bestowing guest-friendship. The rituals of hospitality created and expressed a reciprocal relationship between guest and host expressed in both material benefits (such as the giving of gifts to each party) as well as non-material ones (such as protection, shelter, favors, or certain normative rights).6. Aidos (Greek: \u0391\u1f30\u03b4\u03ce\u03c2)Aidos was actually the Greek goddess of shame, modesty, respect, and humility. Aidos, as a quality, was that feeling of reverence or shame which restrains men and women from wrong. It also encompassed the emotion that a rich person might feel in the presence of the impoverished, that their disparity of wealth, whether a matter of luck or merit, was ultimately undeserved. Ancient and Christian humility have some common points, they are both the rejection of egotism and self-centeredness, arrogance and excessive pride, and is an recognition of human limitations. Aristotle defined it as a middle ground between vanity and cowardice.Subscribe7. Nostos (Greek: \u03bd\u03cc\u03c3\u03c4\u03bf\u03c2)Nostos is a theme used in Ancient Greek literature which includes an epic hero returning home by sea. In Ancient Greek society, it was deemed a high level of heroism or greatness for those who managed to return. This journey is usually very extensive and includes being shipwrecked in an unknown location and going through certain trials that test the hero.The return isn\u2019t just about returning home physically but also about retaining certain statuses and retaining your identity upon arrival. The theme of Nostos is brought to life in Homer\u2019s The Odyssey, where the main hero Odysseus tries to return home after battling in the Trojan War.Incidentally, the word nostalgia was first coined as a medical term in 1688 by Johannes Hofer (1669-1752), a Swiss medical student. It uses the word \u03bd\u03cc\u03c3\u03c4\u03bf\u03c2 along with another Greek root, \u03ac\u03bb\u03b3\u03bf\u03c2 or algos, meaning pain, to describe the psychological condition of longing for the past.8. Oikos (Greek: \u03bf\u1f36\u03ba\u03bf\u03c2)Oikos refers to three related but distinct concepts: the family, the family\u2019s property, and the house. Its meaning shifts even within texts, which can lead to confusion.The oikos was the basic unit of society in most Greek city-states. In normal Attic usage the oikos, in the context of families, referred to a line of descent from father to son from generation to generation. Alternatively, as Aristotle used it in his Politics, the term was sometimes used to refer to everybody living in a given house. Thus, the head of the oikos, along with his immediate family and his slaves, would all be encompassed. Large oikoi also had farms that were usually tended by the slaves, which were also the basic agricultural unit of the ancient economy.9. Apatheia (Greek: \u1f00\u03c0\u03ac\u03b8\u03b5\u03b9\u03b1)In Stoicism, Apatheia refers to a state of mind in which one is not disturbed by the passions. It is best translated by the word equanimity rather than indifference. The meaning of the word apatheia is quite different from that of the modern English apathy, which has a distinctly negative connotation. According to the Stoics, apatheia was the quality that characterized the sage.10. Ataraxia (Greek: \u1f00\u03c4\u03b1\u03c1\u03b1\u03be\u03af\u03b1)Ataraxia literally translates as \u201cunperturbedness\u201d, but is generally considered as \u201cimperturbability\u201d, \u201cequanimity\u201d, or \u201ctranquillity\u201d. It was first used by Pyrrho and subsequently Epicurus and the Stoics for a lucid state of robust equanimity characterized by ongoing freedom from distress and worry. In non-philosophical usage, the term was used to describe the ideal mental state for soldiers entering battle.Achieving ataraxia is a common goal for Pyrrhonism, Epicureanism, and Stoicism, but the role and value of ataraxia within each philosophy varies depending their philosophical theories. The mental disturbances that prevent one from achieving ataraxia vary among the philosophies, and each philosophy has a different understanding as to how to achieve ataraxia.11. Doxa (Greek: \u03b4\u03cc\u03be\u03b1)Doxa means common belief or popular opinion and comes from verb \u03b4\u03bf\u03ba\u03b5\u1fd6\u03bd dokein, \u201cto appear\u201d, \u201cto seem\u201d, \u201cto think\u201d and \u201cto accept\u201d. Used by the Greek rhetoricians as a tool for the formation of argument by using common opinions, the doxa was often manipulated by sophists to persuade the people, leading to Plato\u2019s condemnation of Athenian democracy. It is used in direct contrast to Episteme and Techne.12. Episteme (Greek: \u1f10\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b7) and Techne (Greek: \u03c4\u03ad\u03c7\u03bd\u03b7)Episteme can refer to knowledge, science or understanding, and which comes from the verb \u1f10\u03c0\u03af\u03c3\u03c4\u03b1\u03c3\u03b8\u03b1\u03b9, meaning \u201cto know, to understand, or to be acquainted with\u201d. The word \u201cepistemology\u201d is derived from episteme.Meanwhile Techne is often translated as \u201ccraftsmanship\u201d, \u201ccraft\u201d, or \u201cart\u201d. While it resembles epist\u0113m\u0113 in the implication of knowledge of principles, techne differs in that its intent is making or doing as opposed to disinterested understanding. However, Plato regularly used the two terms interchangeably, and to the ancients, techne and episteme simply mean knowing and \u201cboth words are names for knowledge in the widest sense.\u201dExcellence is not an act\u2026 but a habit. Bring ancient wisdom into your regular life by subscribing today:Subscribe87 Likes\u00b710 Restacks876SharePreviousNext",
    "summary": "- This post discusses 12 ancient Greek terms that are worth reviving in modern society.\n- The terms include Eudaimonia, Arete, Phronesis, Kleos, Xenia, Aidos, Nostos, Oikos, Apatheia, Ataraxia, Doxa, and Episteme/Techne.\n- These terms encompass concepts such as human flourishing, excellence, practical wisdom, glory, hospitality, shame, returning home heroically, family/home, equanimity, popular opinion, and knowledge.",
    "hn_title": "Ancient Greek terms worth reviving",
    "original_title": "Ancient Greek terms worth reviving",
    "score": 314,
    "hn_content": "The post discusses ancient Greek concepts worth reviving, such as eudaimonia and ataraxia, which emphasize the importance of fulfillment and robust equanimity. Some argue that the West values resolution and happiness over all emotions and experiences, unlike the Greeks, who embraced all aspects of life. The etymology of the word eudaimonia is also highlighted, as it means \"good demons\" and was used by Plato to refer to the source of Socrates' inspiration. Discussions on the intersection of esoteric philosophy and artificial intelligence are also presented, along with the importance of pushing the envelope with new ideas. Finally, the concept of akrasia, or weakness of will, is discussed in relation to the modern struggle with self-control and the changing of presumptive morals in society.Various comments on language and ancient Greek are made in a thread discussing a book on akrasia and how to commit oneself to doing the right thing, like Ulysses binding himself to the mast. The use of ancient languages and grammar constructions are praised for their usefulness in problem solving and bug finding skills. The meaning of various Greek words like metanoia, democracy, and xenia are discussed. The importance of ancient language study and its potential worth to modern education is emphasized by some commenters. The comments also touch on language evolution and the use of English grammar constructions to express concepts from other languages.No meaningful tech-related content present.",
    "hn_summary": "- It discusses the intersection of esoteric philosophy and artificial intelligence and the importance of pushing the envelope with new ideas.\n- Various comments highlight the usefulness of ancient language study, grammar constructions, and the meanings of various Greek words."
  },
  {
    "id": 35859142,
    "timestamp": 1683532544,
    "title": "Please don't upload my code on GitHub",
    "url": "https://nogithub.codeberg.page/",
    "hn_url": "http://news.ycombinator.com/item?id=35859142",
    "content": "Please don\u2019t upload my code on GitHubThis is a call to open source developers to not upload the work of others on GitHub.What\u2019s the problem with GitHub?Well, there are a lot of problems with GitHub. Here, we will mainly focus on a feature called Copilot, but if you\u2019re interested to learn more about the others, please visit this page.What is Copilot?According to GitHub,GitHub Copilot is an AI pair programmer that helps you write code faster and with less work. It draws context from comments and code to suggest individual lines and whole functions instantly.\u2014 https://github.com/features/copilotThe question is where does it know how to code? Well, it learns by scanning GitHub repositories:GitHub Copilot is trained on billions of lines of public code. The suggestions it makes to you are adapted to your code, but the processing behind it is ultimately informed by code written by others.\u2014 https://github.blog/2021-06-30-github-copilot-research-recitation/The problem is that this so-called public code is not always under public domain dedication. Sometimes, the code is licensed under a copyleft license (such as GPL), which requires any modification of the source code to be redistributed under the same license as the original.However, when Copilot suggests pieces of copylefted code, it doesn\u2019t include any notice of the original author, nor the license. This can lead to some copylefted code being included in proprietary or simply not copylefted projects. And this is a violation of both the license terms and the intellectual proprety of the authors of the original code.We are tired of this legal abuse and we want to stop right now! Microsoft has been attacking copyleft licensing over the years. In short, we would like to protect our work.So, just don\u2019t put your code on GitHub, what\u2019s the big deal?The issue is bigger than it seems. Even if a project is not hosted on GitHub, other people have the legal right (depending on the license) to redistribute the source code. It means that they have the right to share the code of others on GitHub, as long as they respect the terms of license. This is totally legal. But then, Copilot will be able to analyze the code and violates the license terms, which isn\u2019t.This is why we ask you, as other developers of the open source community, to not upload our code on GitHub.Is this a legal document?No, it isn\u2019t. If the project is under an open source license, it means that everyone can share a copy \u2013 even on GitHub \u2013 of the licensed material under certain conditions. A license restricting this right wouldn\u2019t be open source anymore. However, since GitHub may not respect the terms of licensed code that is hosted on their servers, not uploading the code of others there is, in fact, an ethical choice.How to ask others to not share my code on GitHub?If you want, you can add our badge to your website or to your repository\u2019s README:Markdown:[![Please don't upload to GitHub](https://nogithub.codeberg.page/badge.svg)](https://nogithub.codeberg.page)HTML:<a href=\"https://nogithub.codeberg.page\"><img src=\"https://nogithub.codeberg.page/badge.svg\" alt=\"Please don't upload to GitHub\"></a>Copyright \u00a9 2022 Twann \u00b7 Edit this pageMade with Hugo \u0295\u2022\u1d25\u2022\u0294 Bear",
    "summary": "- A call to open source developers to not upload the work of others on GitHub due to the Copilot feature's potential violation of licenses and intellectual property rights. \n- Copilot, an AI-powered pair programmer, is trained on billions of lines of public code from GitHub repositories, including copylefted code without proper attribution or licenses, leading to legal abuse and intellectual property violations. \n- Not uploading the code of others on GitHub, even though it may be legal under certain licenses, is an ethical choice, and developers can add a badge to their website or repository's README to ask others not to share their code on GitHub.",
    "hn_title": "Please don\u2019t upload my code on GitHub",
    "original_title": "Please don\u2019t upload my code on GitHub",
    "score": 312,
    "hn_content": "Codeberg user modinfo has written a plea for others not to upload their code to GitHub because Copilot, GitHub's AI assistant for code synthesis, is \"synthesizing code identical to existing code\", which could be a violation of copyleft licenses and intellectual property rights. While some users argue that Copilot is not stealing code, but instead synthesizing code from memory, the controversy remains. Similar claims about copying images, copyright, and legal liabilities, and the need for legal frameworks, have emerged in the discussion, demanding the attention of developers, companies, and policymakers. The lack of legal consensus and the need for ethical considerations have also been highlighted.An expert journalist discusses the potential legal implications of using Language Learning Models (LLMs) to replicate code without using training data for that specific code. The journalist's advice is to prove the accuracy of LLMs by counter-examples and creating new code from long-established patterns. The legal implications involve copyright law, and the discussion centers around whether LLM replicated code is considered a derivative work, copied work, or a newly created work. The court decision may be based on whether the replication process used the original material as training data or relied on previously established mathematical patterns. The discussion concludes by emphasizing that the legal implications of LLM-generated code are currently being closely watched. The article discusses the issue of copyright infringement in relation to AI-generated content, specifically looking at OpenAI's Copilot program. It highlights the legal implications of reproducing substantially similar work, and the potential infringement upon existing copyrighted material. Commentary from readers includes discussions on the definition of derivative work, the limitations of current AI models, the potential benefits of AI for open-source, and the responsibility of users in prompting the AI program. The article ultimately raises important considerations for the development and use of AI-generated content in relation to copyright law.Microsoft's Copilot, a new AI designed to help coders write code more efficiently, is being called out for potentially containing GPL code, which violates its license. The discussion centers around the legality of code generation and the responsibility of the user, rather than Microsoft, to ensure that they are not infringing on copyrights. While some argue that the use of GPL code can be unintentional, others believe that Microsoft should be held accountable for publishing black box software that may contain infringed code. Additionally, there are calls for Copilot to include a feature that detects and prevents the use of GPL code, similar to plagiarism detection software for academia. Overall, this controversy highlights the complex legal and ethical issues surrounding AI-generated code and how it is used in real-world situations.Some commenters on a Hacker News thread are discussing whether GitHub's new AI-driven code suggestion tool, Copilot, constitutes copyright infringement due to its use of publicly available GitHub code. Some argue that Copilot \"learns\" like a human coder would by generalizing patterns from example code, while others dispute this characterization. The issue is complicated by the fact that GitHub has the right to train Copilot on public code hosted on its platform, and many open-source software licenses permit copying and distribution with certain conditions attached. Some propose adding a \"No GitHub\" clause to open-source licenses in response. Others argue that Copilot's close relationship with proprietary software and Microsoft's ownership of GitHub make it a less-than-ideal tool for open-source projects.There is debate surrounding whether artificial intelligence (AI) and machine learning (ML) that learns from copyrighted or licensed data should be exempt from copyright laws. Some argue that it is not transformative enough to qualify for an exemption, while others argue that it is just data and no one owns data. The discussion also centers around whether LLMs actually learn like humans and if open-source ideas should be the only ideas in town. Lastly, there is concern around the impact of AI-generated code on copyright, particularly if it contains copyrighted material. However, it is noted that such copyrighted material is typically not just sitting around in a store to be queried, and AI does not always produce identical copies of the original work anyway.- LLMs and stable diffusion have been able to generate copyrighted material verbatim, which contradicts the idea that they only learn patterns from copyrighted code\n- The gray area in using open source code to train AI models lies in the patterns and ideas learned, rather than verbatim copying\n- The ethical issue arises when AI models are trained on open source code to create proprietary products without proper attribution or compensation for the original creators\n- Using open source code on GitHub to train AI models has legal issues if the license prohibits commercial use or redistribution, but GitHub's terms of service may grant them too-permissive licenses \n- LLMs learn patterns, not just copy and paste, and practical examples of verbatim copying that would be copyright infringement are unclear.Developers are posting requests to refrain from posting their code on GitHub due to ethical concerns. They are worried about open-source code potentially used by commercial vendors to train proprietary models. Copilot has raised concerns about using this system to train on open-source code, violating GPL and other licenses. There is a debate about how AI-generated code should be treated. Some argue that these are multiple discoveries and not plagiarism, while others think ethical the use of open-source code should be limited. This practice may lead to future adaptations to current open-source licenses. While some may argue that this violates free speech, others view it as an ethical choice. Ultimately, developers have the right to put any restrictions on the code they share with the world.The AI community is facing backlash for violating code license terms. Microsoft is being sued over Copilot and not respecting some terms of licenses. Github is not adhering to license terms, potentially exposing authors' rights to infringement. People should do what is permitted in their license to protect their code. License checking is a part of CI pipelines. It's difficult to protect code from being used in model training without permission. Copyright laws may need to change to adapt to ML technology.",
    "hn_summary": "- Legal implications of using Language Learning Models (LLMs) to replicate code are being closely watched, with potential infringement lawsuits possible.\n- Ethical considerations of AI-generated content in relation to copyright law are being emphasized, with calls for AI to include plagiarism detection software to prevent the use of copyrighted code."
  },
  {
    "id": 35867275,
    "timestamp": 1683581308,
    "title": "Cantonese Font with Pronunciation",
    "url": "https://visual-fonts.com/",
    "hn_url": "http://news.ycombinator.com/item?id=35867275",
    "content": "Cantonese Font \u7ca4\u8a9e\u5b57\u9ad4Pronunciation at your fingertips. Intuitive tones. Expand your vocabulary.Traditional Chinese characters accompanied by Jyutping romanization. Indispensible aid for learning Cantonese, a few taps away on your keyboard / track-pads. Use offline in your choice of compatible apps, including Microsoft Office, Apple iWork, LibreOffice, Sketch, and Chrome.Available for MacOS / Ubuntu (Kinetic Kudu+)DOWNLOAD NOWWhat & HowVisual Fonts are fonts with colors and image, easy to use as your everyday emojis \ud83e\udd73: no prior knowledge is required.We use this to help you learn & teach Cantonese. Type, write, speak, or copy-paste the Chinese. Change the font to \u201cVisual Fonts \u2013 Cantonese\u201d, and the text is now displayed with the pronunciation \u2014 in your choice of application, even when offline.Features & BenefitsComprehensive ScopeAbout 3,000 characters are used in daily life. The Cantonese Font includes pronunciation for over 8,000 characters, including special characters used only in vernacular Cantonese.In practical terms, this means you can read the entire \u5510\u8a69\u4e09\u767e\u9996 (300 Tang dynasty poems) and \u56db\u66f8 (the Four Classics) with full coverage. The font grows with you from your first step to an advanced reader.Keep Your Pronunciation TruePronunciation is difficult for learners when one character can be read several ways.Pronunciation in the Cantonese Font adapts to the context. Based on what comes before or after, the Jyutping romanization changes to the right one. The magic behind this is a careful curation from 100,000 contexts where the pronunciation differs from the standalone character.Testing against day-to-day prose and conversation transcripts showed an accuracy averaging > 99%. This exceeds what a native speaker can do.Thoughtful, Visual RomanizationWe start with Jyutping, the modern Cantonese romanization system. Then we make it even easier to learn with good design: space and colors, topped with a tone-hint system that frees you from desperately trying to recall whether \u201c4\u201d is high or low. Now you just intuit the sound.Meets You Where You AreThe Cantonese Font enhances the apps you already use. Write in Word, take notes in Good Notes, make presentations in Keynote, design in Sketch.app, browse the web with Chrome, write your music score in MuseScore, or do 3D art in Blender.Learn At Your Own PaceDon\u2019t know how to write, type, speak or copy \u201cfriend\u201d? Just type friend in English and watch it turn into \u670b\u53cb. The font becomes a mini-dictionary too, with a vocabulary size of over 1,500.For our friends in Hong Kong, the font understand every MTR station and other places in Hong Kong. Impress the locals by saying gam1 zung1 instead of Admiralty.Want to tell native speakers where you are from? With 250+ countries and 250+ world cities, we got you covered.Want to teach or learn related terms? Use a syntax like emotion(1), emotion(2)\u2026 to access vocabulary thematic way.* Learner\u2019s Edition in Spanish and other Latin-Greek-Cyrillic characters may be available in the future.What\u2019s includedThe FontAvailable in .ttf format. On Macs, it\u2019s a simple two-click install.Starter SamplesSample Keynote presentation, Pages document, Numbers spreadsheet, and LibreOffice documents showing its use.Font + Phrasebook (English)8,000+ characters with context-sensitive jyutping. Toggling a separate font variant enables mini-dictionary feature (in English) with 2000+ words, including all MTR stations, 200+ countries, and 250+ world cities.The Cantonese Font is freely available. You can name any price, and it can be used in any projects including commercial products. For details, consult the SIL Open Font License included in the download.DOWNLOADHow to support this workContinued development of the project relies on user support. You can:As an individual,pay for the font,buy some of our other Visual Fonts when they are available,write a review, andhelp spread the word;As an organization,fund particular extensions, orproviding recurring funding in the form of schemes and grantsFor designers & publishers, we can provide bespoke, custom design for your brand or projectMembers of our team are available for consulting. Our expertise from in the font projects include constructing automation pipelines (Elixir, Python, and Javascript), typesetting (LaTeX), and vector graphic design (Illustrator). We also know a thing or two about font engineering and Cantonese linguistics.The Cantonese Font is a piece of culture funded from our savings, and from revenue from our dance studio in Causeway Bay. If you are in Hong Kong, come join our fun, friendly, best Argentine Tango classes for all levels at www.eli.dance \ud83d\ude42What our users sayCantonese Visual Fonts is a game-changer for anyone learning Cantonese and exploring traditional characters. The added Jyutping pronunciations on top of the characters make it incredibly convenient to use on a daily basis to read. \u2b50\u2b50\u2b50\u2b50\u2b50PTK (beginner)FAQsCan you use this in Windows?Can you use this in [insert your Linux distro]?The appearance looks squished in [insert Adobe app].The jyutping is too small! Can you make it bigger?Can I use this in commercial work?The romanization is wrong for [\u2026]Deep DivesInstallation / System CompatibilityWhy a font?What characters / words are included?Versioning, Changelog, and RoadmapVersioningThe font software adopts semantic versioning. The version number has three parts: x.y.z, standing for:x: major version. This is reserved for a complete font re-build, where unknowable number of pronunciation changes may happen. If this happens, the last major version will still be available so users that prefer the previous version can always download the previous version.y: minor version. This increments when significant new features are added or changed. Examples include entire new class of categories in the Phrasebook, or new language availability for the Phrasebook.z: patches. This increments with bug-fixes, added chars, added words, or added categories and terms in the Phrasebook.I personally dislike getting subscription emails, so patches are definitely not announced anywhere except in the changelog.Changelog1.1.2First public release.RoadmapCantonese Font is feature-complete and stable. The following is my wishlist / todo-list (not in any order) around this project:PDF manual. This would be bi-lingual, including screenshot/instructions for using the font. Instructions would include (0) authoritative compatibilities, (1) install/uninstall on different platforms, (2) StyleBot/Chrome setup for web-browsing on different OS, (3) mixing with Latin / Zh fonts, (4) enabling ligatures in apps that does not turn on by default (Office, I think), and (5) listing of chars and Phrasebook terms/categories.Cantonese linguistic categories. Using a syntax of Canto.___(n), exhaustively tally linguistic aspects of Cantonese. An example is Canto.measure(n) which shows all the measure words (\u500b, \u96bb, \u652f, \u2026); another example is Canto.particles(n) for \u5566, \u558e, \u5569. These should be helpful for systematic study or teachers preparing teaching material.100% traditional characters coverage. CJK (Chinese-Japanese-Korean) characters are complicated in their encoding and usage in different variant. At the first steps of this project, I started with commonly used characters (to ensure they are pronunciable Zh-T entries) and expanded by patching upwards. A complementary approach is to run through the full list of Unicode CJK codepoints, filter out for what is Zh-T and have one or more Cantonese pronunciations. This requires fast access to UniHan and Rime, and will have to wait for the completion of the Elixir libraries UniHan (Kip Cole) and ExCantonese.Re-compute pronunciations. v1 of the font was constructed when I knew far less about the idiosyncracies of Cantonese NLP. Knowing what I know, I think there are better approaches once we can have user feedback.Website revamp. The WordPress landing page would be replaced by an Elixir-Phoenix-Ash setup. This opens up possibilities for much more interesting real-time interactive experiences, that are exposed by UniHan / ExCantonese. (A little teaser: with these libraries, we are able to answer questions like, \u201cwhich jyutping have the most characters mapping to it?\u201d, \u201chow many characters are there for each radical?\u201d, or \u201cwhat characters have an onset of f and a tone of 2?\u201d) The text-editor workflow would also means less barrier to writing about Canto / font blog posts. (Not to leave you hanging: the sound that maps to the most character is \u201cjyu4\u201d, with over 30 characters. There is a great deal of low-usage characters that contains \u4fde with different radicals.) It may also be possible to enable dynamic processing / SVG generation, using user-supplied styles.Chinese / Spanish / Italian website internationalization. Awaits new website architecture.Skip back to main navigation",
    "summary": "- Cantonese Font is a font that includes Jyutping romanization for traditional Chinese characters to aid in learning Cantonese.\n- It adapts to context for accurate pronunciation and includes a tone-hint system to make learning easier.\n- Available for MacOS and Ubuntu, it can be used offline in compatible apps and includes a mini-dictionary with over 1,500 vocabulary words.",
    "hn_title": "Cantonese Font with Pronunciation",
    "original_title": "Cantonese Font with Pronunciation",
    "score": 295,
    "hn_content": "An article discussing tonal languages has been posted on Hacker News, and readers are discussing how tonal detection systems could be helpful tools for language learners to ensure they are pronouncing words accurately, similar to language pronunciation apps like ELSA speak for English. The article also explores the differences between tonal languages, such as Mandarin, Thai, Cantonese, and Vietnamese, with Mandarin being noted as particularly challenging due to the large number of homophones. The article also speculates on the reasons why tone adherence is generally higher in Cantonese than in Mandarin, with one theory being that the complexity of Cantonese syllables requires less ambiguity in tones to avoid confusion. Overall, there is a discussion of the importance of tonal detection systems, accuracy in pronunciation, and the challenges of tonal languages.The comment thread discusses the use of spaces between words in different languages, particularly in ideographic languages such as Chinese and Japanese, as well as the challenges for lexical analysis without spaces. While spaces are a relatively recent invention, interpuncts and other symbols are used to separate words in some languages. Cantonese has both register and pitch tones, with different syllable groupings becoming ambiguous or having multiple meanings with different tonal combinations. The lack of spaces can pose challenges for text processing, though expert speakers can often rely on the context and natural cues to aid comprehension.- Cantonese has 6 tones, but some may refer to 9 \"categories,\" which are based on Middle Chinese's 4 tones and a \"checked\" tone\n- Words ending in stops in Cantonese do not have tones 2, 4, or 5 and are sometimes counted as a different tone, causing some to classify Cantonese as having 9 tones\n- Japanese has pitch accent rather than tones, with one culminative pitch contour over multi-syllable words\n- Automatic tonal detection systems for language learners are difficult to develop, as tone sandhi (tone changes due to surrounding morphemes) can be complex and dependent on each morpheme",
    "hn_summary": "- Differences between tonal languages are explored, with Mandarin being particularly challenging due to the large number of homophones\n- Challenges of tonal languages are discussed, and the importance of tonal detection systems and accuracy in pronunciation is highlighted"
  },
  {
    "id": 35866283,
    "timestamp": 1683575810,
    "title": "1-Bit Hokusai's \"The Great Wave\"",
    "url": "https://www.hypertalking.com/2023/05/08/1-bit-pixel-art-of-hokusais-the-great-wave-off-kanagawa/",
    "hn_url": "http://news.ycombinator.com/item?id=35866283",
    "content": "Back1-bit Hokusai\u2019s \u201dThe Great Wave\u201d8 May 2023JamesMount Fuji5 years ago I started a now completely stalled project (fingers crossed I can figure out how to restart soon) to draw all of Hokusai\u2019s 36 views of Mount Fuji as 1-bit pixel art.Why?I started this project for no other reason than I love to get into the \u2018flow state\u2019 from this kind of creative endeavour, and obviously I love to use old Macintosh computers.It feels very satisfying to get each pixel to fall into place, capturing both the original vision of Hokusai and the aesthetic that Susan Kare mastered early on with \u2018the Japanese lady\u2019.Kare\u2019s picture of course starred on the cover of every box of MacPaint and you can still buy beautiful prints of it today, directly from her.Another challenging aspect of this project is to make sure the images are the original Macintosh screen resolution of 512 x 342 pixels. Why do I do this to myself?! Well, it just felt \u2018right\u2019 and I guess I\u2019m a glutton for punishment when I want to make things feel authentic.How?The idea is to recreate every one of Hokusai\u2019s woodcut prints from the series on an early black and white Macintosh, using contemporary hardware and software.I usually use either my Quadra 700 or PowerBook 100, mostly because those are my reliable and easy to access computers (that run System 7, my favourite and most familiar OS of that era).Software-wise I use Aldus SuperPaint 3.0, which is what my family had when I was a kid. Yes, I\u2019d say that all of this is 99% nostalgia-driven\u2026Anyway, @polyducks urged me to share at least the first of these (although this was actually the 2nd or 3rd of the series I tackled, not sure why I did them \u2018out of order\u2019), \u201cThe Great Wave off Kanagawa\u201d. Took me a while to get around to it, but here it is:01 of 36 views of Mt. Fuji by hypertalkingPlease, if you reproduce this or post it anywhere be sure to credit me and link back to this website!Bonus!As a little extra, if you have a Macintosh with a 640 x 480 screen, you can download a version (PNG | PICT as compressed .zip) to use as a desktop pattern.I\u2019ll aim to post more from this project soon.",
    "summary": "- An artist has recreated all of Hokusai's 36 views of Mount Fuji as 1-bit pixel art using contemporary hardware and software on early black and white Macintosh computers, in a nostalgic attempt to capture the original vision and aesthetic of Hokusai and Susan Kare's 'the Japanese lady.'\n- The images are the original Macintosh screen resolution of 512 x 342 pixels, and the artist used Aldus SuperPaint 3.0 software on Quadra 700 or PowerBook 100 computers running System 7.\n- The first of these pixel art images recreated by the artist is \"The Great Wave off Kanagawa,\" which can be downloaded as a desktop pattern for Macintosh computers with a 640 x 480 screen.",
    "hn_title": "1-Bit Hokusai\u2019s \u201dThe Great Wave\u201d",
    "original_title": "1-Bit Hokusai\u2019s \u201dThe Great Wave\u201d",
    "score": 288,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit login1-Bit Hokusai\u2019s \u201dThe Great Wave\u201d (hypertalking.com)289 points by scraplab 14 hours ago | hide | past | favorite | 57 commentsstatico 12 hours ago | next [\u2013]This site design is one of the best retro Mac site designs I've seen. The author really nailed the pixel perfect fonts \u2014 it looks perfect on my low-DPI and high-DPI displays.If anyone's interested, there's an active HyperCard community with some fun projects. There's a Discord server, too. https://hypercard.org/I found that community through the Avara community, a port of the classic Mac multiplayer networked mech shooter from Ambrosia: https://github.com/avaraline/AvaraAlso, if you're into retro Mac stuff or just want nostalgia, the Infinite Mac project is amazing. You can run all the major Mac OS Classic releases right in the browser, you can drag and drop files from Macintosh Archive or Macintosh Garden onto the window, and you can even create an AppleTalk network between browsers: https://infinitemac.org/replybirracerveza 1 hour ago | parent | next [\u2013]The website is really good but the font is blurry on my windows machine, only in this blog post.If I adblock the (beautiful) \u201cGreat Wave\u201d image, the font reads perfectly.replylmm 10 hours ago | parent | prev | next [\u2013]> The author really nailed the pixel perfect fonts \u2014 it looks perfect on my low-DPI and high-DPI displays.It has some weird rainbow effect to it on mine, and the background flickers when I scroll.replyteraflop 8 hours ago | root | parent | next [\u2013]Yeah, it looks like the font is scaled slightly wrong along the x-axis, so that the displayed pixels don't quite line up with screen pixels. Specifically, the text is rendered about 0.5% too narrow, causing a moire-type pattern that repeats about every 200 pixels.Adding this custom CSS rule seems to fix it for me:  p { transform: scale(1.005, 1); }replykalleboo 5 hours ago | root | parent | prev | next [\u2013]This seems to be because Firefox has no way to disable text antialiasing (whereas Safari and Chrome support -webkit-font-smoothing), so Firefox is trying to antialias a pixel font which just looks weirdreplylmm 4 hours ago | root | parent | next [\u2013]Nope, I'm using Chromium.replykalleboo 3 hours ago | root | parent | next [\u2013]Digging into it, it looks like the various CSS font smoothing selectors only work on macOS, not Linux or Windows.replythrdbndndn 8 hours ago | root | parent | prev | next [\u2013]Same here, I think it's caused by the font it's using (BitGeneva12 [1], which obviously is a geneva [2] clone but I can't find where it (the font) is from. Maybe the author created it themselves?).[1]  src: url(//www.hypertalking.com/wp-content/themes/hypertalking/fonts/bitgeneva12-webfont.eot);  src: url(//www.hypertalking.com/wp-content/themes/hypertalking/fonts/bitgeneva12-webfont.eot?iefix) format('eot'),url(//www.hypertalking.com/wp-content/themes/hypertalking/fonts/bitgeneva12-webfont.woff) format('woff'),url(//www.hypertalking.com/wp-content/themes/hypertalking/fonts/bitgeneva12-webfont.ttf) format('truetype'),url(//www.hypertalking.com/wp-content/themes/hypertalking/fonts/bitgeneva12-webfont.svg#webfontx0MbJbLm) format('svg');[2] https://en.wikipedia.org/wiki/Geneva_(typeface)replyPrickle 8 hours ago | root | parent | prev | next [\u2013]Same here. Also a more minor issue for people like myself, the site causes some 'glare'(?) and is difficult to look at.I've had this issue since my childhood, now that I think of it. On paper (especially grids) and websites. I should probably figure out what it is.replyadzm 7 hours ago | root | parent | next [\u2013]Do you have astigmatism?replyPrickle 6 hours ago | root | parent | next [\u2013]I just looked it up and based off of anecdotal evidence, I think the answer is yes.I have had glasses for nearsightedness in my left eye but it isn't bad enough for most situations. Never had an eye exam in my life.replydan353hehe 5 hours ago | root | parent | next [\u2013]I have astigmatism. I had the same issue with grids, certain fonts with lots of vertical lines, and other regular high contrast repeating patterns.Got some glasses a few years ago for the first time from an optometrist, and now it doesn\u2019t bother me anymore.So I would recommend getting it checked out.replyPrickle 5 hours ago | root | parent | next [\u2013]Thankyou for the recommendation! I'll go about scheduling that.replyvertis 4 hours ago | parent | prev | next [\u2013]How I miss Escape Velocity and Ambrosia Software. It was the first game I bought. Had to call the US at some weird hour from Australia and pay with Dad's credit card over the phone.I'm aware there are similar games like Endless Sky (which I've played quite a bit).I really wish the people behind Ambrosia could be encouraged to open source everything.replycalibas 6 hours ago | prev | next [\u2013]When viewing the site in Firefox, the font in the paragraphs has a very subtle rainbow effect. Here's a screenshot of it zoomed in: https://i.imgur.com/ir0MmPq.pngI was wondering how they achieved that effect, but it doesn't seem intentional. It's not part of the CSS, and I only see it in FF, doesn't happen in Chrome.It goes away if I switch fonts, it looks like it's some weird result of how Firefox renders the site's \"BitGeneva12\" font. Another odd thing, it goes away when I used FF's \"Take Screenshot\" feature. Also only happens when the font is 12px in size.replywesleychen 5 hours ago | parent | next [\u2013]It's probably due to anti-aliasing. A similar thing happens on some versions of Windows with ClearType turned on: https://en.wikipedia.org/wiki/ClearTypereplylelandfe 5 hours ago | root | parent | next [\u2013]Webkit browsers have `-webkit-font-smoothing: none`. Does an equivalent exist for FF?replygolph 5 hours ago | root | parent | next [\u2013]font-smooth: never Should be working on Firefox.replykalleboo 3 hours ago | root | parent | next [\u2013]caniuse says it only works on macOSreplyMivLives 5 hours ago | parent | prev | next [\u2013]I assumed this was intentional to sorta look weird and retro. Sorta wild it's just Firefox messing it up.replywaboremo 5 hours ago | root | parent | next [\u2013]It's not just Firefox, it's reproducible on Chromium browsers on Windows (10) as well.replybobbylarrybobby 5 hours ago | parent | prev | next [\u2013]Sub pixel antialiasing gone wrong?replyCthulhu_ 2 hours ago | parent | prev | next [\u2013]On your screenshot I can only see the fonts aren't quite sharp, the rainbow effect is probably from your display trying to render these subpixel differences.replyWoodenChair 7 hours ago | prev | next [\u2013]If you're interested in showing photographs and paintings on a classic Mac, I actually made an app for that. It takes modern images, dithers them to 1-bit, and then exports the results to MacPaint format (encoded in MacBinary for easy transport). It works on modern versions of macOS: https://oaksnow.com/retrodither/replytjpnz 3 hours ago | prev | next [\u2013]I took my father to see the original in Tokyo today. It's a sight to behold and worth a look next time you're here. You can also watch a Sumo match nearby.replyperilunar 2 hours ago | parent | next [\u2013]It's a woodblock print \u2014 there were thousands printed, and ~100 known to still exist. I've seen the British Museum's copy.replyrobga 3 hours ago | parent | prev | next [\u2013]It must have been a thrill to see a PowerBook 100!replysmcl 2 hours ago | parent | prev | next [\u2013]I thought he made and sold many prints of each piece, so that identifying the original one wouldn't really be possible.replySomeone 1 hour ago | root | parent | next [\u2013]The original are the woodblocks (it\u2019s multi-colour, so I assume there were multiple blocks). Those wouldn\u2019t show the full picture and would have been worn down, if we still had them. We don\u2019t, though. The next best thing would be prints made by the artist.https://www.britishmuseum.org/blog/great-wave-spot-differenc... has a nice description using wear and tear to distinguish earlier from later prints.Edit: nowadays, artists write things like \u201c3/50\u201d on their prints (meaning they made fifty prints, and this is the third). That informs collectors/drives up prices for the low numbered prints.replysmcl 51 minutes ago | root | parent | next [\u2013]Yep I also saw some in a Hokusai museum in Osube near Naganoreplytgv 1 hour ago | prev | next [\u2013]Of course, you can close the blog post (top left corner of the window), or click the floppy icon, which will reveal more posts. There aren't more Hokusai posts, though.replyrobga 3 hours ago | prev | next [\u2013]Bill Atkinson of Apple developed a new dithering algorithm for early Macs. I wonder if it was used for this rendering.https://beyondloom.com/blog/dither.htmlreplySomeone 1 hour ago | parent | next [\u2013]The author says \u201cSoftware-wise I use Aldus SuperPaint 3.0\u201d, so I expect it was drawn 100% by hand.replydekhn 9 hours ago | prev | next [\u2013]When I was getting started with my laser engraver, I used the Great Wave as my template image. It translates to black and white quite nicely. Since the laser has a power range, you normally use grayscale but dithering also works. The stucki and jarvis options are both very good.To me, dithering reminds me of early Macs (just like the link).replyftxbro 5 hours ago | prev | next [\u2013]I know this isn't the point, but if anyone wants to make pictures like this automatically you can use dithering.replynxpnsv 4 hours ago | parent | next [\u2013]You\u2019re going to miss the pixel perfect lines. There\u2019s a whole subtle esthetic in this version from the careful manipulation of pixels\u2026replynxpnsv 4 hours ago | prev | next [\u2013]I love how it\u2019s still beautiful\u2026replypassion__desire 4 hours ago | parent | next [\u2013]\"Return of the Obra Dinn\" game gives similar vibes.replysph 3 hours ago | root | parent | next [\u2013]The author, Lucas Pope, went into deep detail describing the dithering process and shader used in Return of the Obra Dinn. It's outstanding work.https://forums.tigsource.com/index.php?topic=40832.msg136374...replyasynchronous 5 hours ago | prev | next [\u2013]Very cool drawing, as a side note I\u2019ve seen Stable Diffusion be able to achieve very good pixel art with some Loras and textual embeddings plus some skill. Also seen it able to do amazing img2img art like pictured here.replyinjb 11 hours ago | prev | next [\u2013]I don't understand- in what sense is this \"1 bit\"?replySynaesthesia 11 hours ago | parent | next [\u2013]Every pixel has 1 bit of color depth, basically black or white.replyggm 1 hour ago | parent | prev | next [\u2013]If you transmitted it one pixel at a time left to right top to bottom scan, or boudestrophon l r l r l r if you prefer then the pixel stream would equal a 1 bit value toggling on or off.replysebastianz 11 hours ago | parent | prev | next [\u2013]2 colors per pixel - black or white.replywiz21c 3 hours ago | prev | next [\u2013]When I have a bit of time, I'll compare dither algorithms to that human version. Would be cool to see how they compare !replyselimthegrim 11 hours ago | prev | next [\u2013]Of possible relevance: https://en.m.wikipedia.org/wiki/24_Views_of_Mt._Fuji,_by_Hok...replysgu999 11 hours ago | parent | next [\u2013]Is it worth reading? :)replykaraterobot 11 hours ago | root | parent | next [\u2013]That story rules, as does the collection it's in (Frost and Fire).replyselimthegrim 11 hours ago | root | parent | next [\u2013]I\u2019ll have to find that, rather I used IA to find the back issue of the magazine it was published in.replykaraterobot 10 hours ago | root | parent | next [\u2013]Inspired by this thread, I just reread it. There's a reproduction with the original woodblock print images, which was useful because I didn't have that when I read this story as a teenager.https://fictionbooks.top/24-views-of-mt-fuji-by-hokusai-3016...replyselimthegrim 11 hours ago | root | parent | prev | next [\u2013]Internet archive is your friend here. Yes very much so, especially if you can get the book Zelazny based the story on.replyaaron695 11 hours ago | parent | prev | next [\u2013]Hokusai (1760 - 1849) also did tentacle pornNSFW art -https://en.m.wikipedia.org/wiki/The_Dream_of_the_Fisherman%2...Book -https://pulverer.si.edu/node/277/titlereplypallas_athena 51 minutes ago | root | parent | next [\u2013]This painting was prominently featured in several episodes of \"Mad Men\".replywiz21c 3 hours ago | root | parent | prev | next [\u2013]Damn! That's super cool. I have shown the wave to my kids but I often tell them that artists are not always what we know of them. This is a superb demonstration ! Thanks for posting ! (usually I'd use l' \"origine du monde\" by Courbet)replyrcarmo 12 hours ago | prev [\u2013]Holy cow, that web site takes me back...replytesseract 9 hours ago | parent [\u2013]Holy dogcow, even!replydyno12345 8 hours ago | root | parent [\u2013]moof moof!replyApplications are open for YC Summer 2023Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Some users have issues with font rendering on certain devices, but there are proposed solutions.\n- Comments also discuss related topics like dithering, laser engraving, and the work of Hokusai in general."
  }
]
